Dialogue Act Recognition with Bayesian Networks for Dutch Dialogues
Simon Keizer, Rieks op den Akker and Anton Nijholt
Department of Computer Science
University of Twente
P.O. Box 217, 7500 AE Enschede, The Netherlands
{skeizer,infrieks,anijholt}@cs.utwente.nl
Abstract
This paper presents work on using
Bayesian networks for the dialogue act
recognition module of a dialogue sys-
tem for Dutch dialogues. The Bayesian
networks can be constructed from the
data in an annotated dialogue corpus.
For two series of experiments - using
different corpora but the same anno-
tation scheme - recognition results are
presented and evaluated.
1 Introduction
In several papers (Nijholt, 2000; Luin et al, 2001;
Nijholt et al, 2001) we reported on our virtual
music centre - the VMC - a virtual environment
inhabited by (embodied) agents and on multi-
modal interaction between human users and these
agents. Of these agents Karin is an embodied
agent users can ask for information about theatre
performances (see Figure 1).
A second agent is the navigation agent. Nav-
igation is a) way finding - the user knows where
he wants to go but doesn?t know how to go there;
or b) exploring the environment - the user walks
through the environment to obtain an overview of
the building and the objects, locations, rooms that
are in it. Related to these navigation tasks the nav-
igation assistant has the task to assist the visitor
in a) explaining how to go from his current loca-
tion to a location he is looking for and b) to give
the agent information about objects, and locations
in the environment. The navigation agent is not
present as an avatar in the environment. The user
sees the environment from a first person perspec-
tive and interacts with the agents by means of a
Dutch dialogue. The user has two views of the
environment: a) a first person view of the visible
part of the 3D virtual theatre and b) an abstract
2D map of the floor of the building the user is
visiting. This map is shown in a separate win-
dow. In a multi-modal interaction the user can
point at locations or objects on the 2D map and
either ask information about that object or loca-
tion or he can ask the assistant to bring him to the
location pointed at.
Figure 1: Karin in the VMC.
An important part of our dialogue systems for
natural language interaction with agents is the
module for recognition of the dialogue acts per-
formed by the human user (visitor). This pa-
per discusses the construction of and experiments
with Bayesian networks as implementation of this
module.
Various other work has been presented on us-
ing statistical techniques for dialogue act classi-
fication (Andernach, 1996; Stolcke et al, 2000),
and even some first efforts on using Bayesian net-
works for this task (Pulman, 1996; Keizer, 2001).
Other work on using Bayesian networks in dia-
logue systems aims more at interaction and user
modelling (Paek and Horvitz, 2000) and does not
specifically involve linguistic aspects.
The paper is organised as follows. Section 2
       Philadelphia, July 2002, pp. 88-94.  Association for Computational Linguistics.
                  Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
provides some necessary and general background
about the use of Bayesian networks for speech act
recognition. In Section 3 we discuss experiments
with a Bayesian network for dialogue act classi-
fication based on a dialogue corpus for the Karin
agent. In Section 4 we discuss our current ex-
periments with a network for the navigation dia-
logue system that was automatically created from
a small corpus. Section 5 reflects on our findings
and presents plans for the near future.
2 Bayesian Networks and Speech Act
Recognition
Since Austin and Searle deliberately producing a
linguistic utterance (?locutionary act?) is perform-
ing a speech act (?illocutionary act?). Many re-
searchers have contributed in distinguishing and
categorising types of speech acts we can perform.
See (Traum, 2000) for a valuable discussion on
dialogue act taxonomies and an extensive bibli-
ography.
A dialogue system needs a user model. The
better the user model the better the system is able
to understand the user?s intentions from the locu-
tionary act. We consider the human participant
in a dialogue as a source of communicative ac-
tions. Actions can be some verbal dialogue act
or some non-verbal pointing act (the act of point-
ing at some object). We assume the user is ra-
tional: there is a dependency between the action
performed and the intentional state of the user. If
we restrict to communicative acts that are realized
by uttering (speaking or typing) a sentence we
can model the user by a probability distribution
P (U = u|DA = da): the probability that the user
produces an utterance u (the stochastic variable U
has value u) given that he performs a dialogue act
da ( DA has the value da). Or - maybe better: the
confidence we can have in believing that the user
uses utterance u if we know that the dialogue act
he performs is da. Since there are many distinct
wordings u for performing a given dialogue act
da and on the other hand there are distinct dia-
logue acts that can be performed by the same ut-
terance, we need more than superficial linguistic
information to decide upon the intended dialogue
act given an utterance. The task of the dialogue
act recognition (DAR) module of a dialogue sys-
tem is to answer the question: what is the most
likely dialogue act da intended by the user given
the system has observed the utterance u in a dia-
logue context c. (Notice that we have equated the
utterance produced by the user with the utterance
recognised by the system: there is no information
loss between the module that records the utter-
ance and the input of the dialogue act recognition
module.)
To make this problem tractable we further re-
strict the model by assuming that a) the user en-
gaged in a dialogue can only have the intention
to perform one of a finite number of possible di-
alogue acts; b) each of the possible natural lan-
guage utterances u produced by the user and ob-
served by the system can be represented by a fi-
nite number of feature value pairs (fi = vi); and
c) the dialogue context can be represented by a
finite number of feature value pairs (gi = ci).
Given these restrictions the DAR problem be-
comes to find that value da of DA that maximises
P ( DA = da | f1 = v1, . . . , fn = vn,
g1 = c1, . . . , gm = cm ).
For the probabilistic model from which this can
be computed we use a Bayesian network (Pearl,
1988). A Bayesian network is a directed acyclic
graph in which the nodes represent the stochastic
variables considered, while the structure (given
by the arcs between the nodes) constitutes a set
of conditional independencies among these vari-
ables: a variable is conditionally independent of
its non-descendants in the network, given its par-
ents in the network. Consider the network in Fig-
ure 2: it contains one node representing the di-
alogue act (DA), 3 nodes representing utterance
features (NumWrds, CanYou and IWant) and
a node representing a context feature (PrevDA).
From the network structure follows that for ex-
ample variable DA is conditionally independent
of variable NumWrds, given variable CanYou.
The conditional independencies make the
model computationally more feasible: finding a
specification of the joint probability distribution
(jpd) for the model reduces to finding the condi-
tional probability distributions of each of the vari-
ables given their network parents. In our example
network, the following jpd specification holds:
P (DA, NumWrds,CanYou, IWant,PrevDA) =
P (IWant) ? P (PrevDA|DA) ? P (CanYou) ?
DA
PrevDA
IWant
CanYou
NumWrds
Figure 2: A Bayesian Network for Dialogue Act
Recognition.
? P (DA|CanYou, IWant) ?
? P (NumWrds|CanYou,PrevDA)
The construction of a Bayesian network hence
amounts to choosing a network structure (the con-
ditional independencies) and choosing the condi-
tional probability distributions. In practice, the
probabilities will have to be assessed from em-
pirical data by using statistical techniques. The
structure can generated from data too, but another
option is to choose it manually: the arcs in the
network can be chosen, based on the intuition that
they represent a causal or temporal relationship
between two variables. Strictly spoken however,
a Bayesian network only represents informational
relationships between variables.
Notice that the machine learning technique
known as Naive Bayes Classifier (see for instance
(Mitchell, 1997)) assumes that all variables are
conditionally independent of each other given
the variable that has to be classified. A Naive
Bayes classifier can be seen as a special case of
a Bayesian network classifier, where the network
structure consists of arcs from the class variable
to all variables representing the features: see Fig-
ure 3.
DA
IWant CanYou NumWrdsPrevDA
Figure 3: Naive Bayes classifier as Bayesian Net-
work.
Naive Bayes classifiers will perform as good
as the Bayesian network technique only if indeed
all feature variables are conditionally indepen-
dent, given the class variable. The problem is
of course how do we know that they are condi-
tionally independent? If we don?t have complete
analytical knowledge about the (in)dependencies,
only analysing the data can give an answer to this
question. The advantage of using Bayesian net-
works is that methods exist to construct the net-
work structure as well as the conditional proba-
bilities. Moreover Bayesian networks are more
flexible in their use: unlike Bayesian classifiers
we can retrieve the posterior probabilities of all
the network variables without re-computation of
the model. The same advantage do Bayesian net-
works have over Decision Tree learning methods
like C4.5 that output a decision tree for classi-
fying instances with respect to a given selected
class variable. Experiments have shown that
Naive Bayesian classifiers give results that are as
good as or even better than those obtained by
decision tree classification techniques. Hence,
there are theoretical as well as practical reasons
to use Bayesian networks. However, since there
is hardly any experience in using Bayesian net-
works for dialogue act classification we have to
do experiments to see whether this technique also
performs better than the alternatives mentioned
above for this particular application.
The next two sections describe experiments
with 1) the SCHISMA corpus - elaborating on pre-
vious work described in (Keizer, 2001) - and 2) a
preliminary small corpus of navigation dialogues.
We motivate our choice of dialogue acts and fea-
tures and present some first results in training a
Bayesian network and testing its performance.
3 Experiments with the Schisma corpus
3.1 Dialogue acts and features
The current dialogue system for interacting with
Karin is based on analyses of the SCHISMA cor-
pus. This is a corpus of 64 dialogues, obtained
through Wizard of Oz experiments. The interac-
tion between the wizard - a human simulating the
system to be developed - and the human user was
established through keyboard-entered utterances,
so the dialogues are textual. The task at hand
is information exchange and transaction: users
are enabled to make inquiries about theatre per-
formances scheduled and if desired, make ticket
reservations.
We have manually annotated 20 dialogues
from the SCHISMA corpus, using two layers
of the DAMSL multi-layer annotation scheme
(Allen and Core, 1997), a standard for annotat-
ing task-oriented dialogues in general. The layer
of Forward-looking Functions contains acts that
characterise the effect an utterance has on the
subsequent dialogue, while acts on the layer of
Backward-looking Functions indicate how an ut-
terance relates to the previous dialogue. Because
DAMSL does not provide a refined set of dia-
logue acts concerning information-exchange, we
have added some new dialogue acts. For example,
ref-question, if-question and alts-
question were added as acts that further spec-
ify the existing info-request.
For the experiments, we selected a subset of
forward- and backward-looking functions from
the hierarchy that we judged as the most impor-
tant ones to recognise: those are listed in Table
1. In Figure 4, a fragment of an example dia-
logue between S (the server) and C (the client) is
given, in which we have indicated what forward-
and backward-looking functions were performed
in each utterance.
Forward-looking
Functions
assert
open-option
request
ref-question
if-question
alts-question
action-directive
offer
commit
conventional
expressive
otherff
Backward-looking
Functions
accept
approve
reject
disapprove
hold
acknowledge
not-understood
positive answer
negative answer
feedback
otherbf
Table 1: Dialogue Acts for SCHISMA.
The user utterances have also been tagged man-
ually with linguistic features. We have distin-
guished the features in Table 2, assuming they can
be provided for by a linguistic parser.
The dialogue context features selected include
the backward-looking function of the last system
utterance and the forward-looking function of the
previous user utterance. In the experiment with
S: Hello, how can I help you?
conventional
C: When can I see Herman Finkers?
ref-question; otherbf
S: On Saturday the 12th at 20h.
assert; pos-answer
C: I would like 2 tickets please.
action-directive; otherbf
S: Do you have a discount card?
if-question; hold
. . .
Figure 4: Dialogue fragment with forward- and
backward-looking functions.
Sentence Type
declarative
yn-question
wh-question
imperative
noun phrase
adverbial
adjective
number
interjective
continuation
Subject Type
first person
second person
third person
Punctuation
period
question mark
exclam. mark
comma
none
Table 2: Utterance features for SCHISMA.
the SCHISMA dialogues we have constructed a
network structure (see Figure 5) by hand and then
used the data of the annotated dialogues to train
the required conditional probabilities.
PBFS
FFC
SeTp
SuTp
Punct
PFFC
Figure 5: Bayesian network for DAR to be trained
with the SCHISMA dialogues.
The choice of structure is based on the in-
tuition that the model reflects how a client de-
cides which communicative action to take; al-
though the arcs themselves have no explicit
meaning - they only contribute to the set of
conditional independencies - they can be seen
here as a kind of temporal or causal relation-
ships between the variables (as mentioned ear-
lier in Section 2): given the dialogue context -
defined by the previous forward-looking function
of the client (PFFC) and the previous backward-
looking function of the server (PBFS), the client
decides which forward-looking function to per-
form (FFC); from this decision he/she formulates
a natural language utterance with certain features
including the sentence type (SeTp) the subject
type (SuTp) and punctuation (Punct).
Recalling the notion of conditional indepen-
dence in Bayesian networks described in Section
2, it follows that by choosing the network struc-
ture of Figure 5, we have made the (admittedly,
disputable) assumption that, given the forward-
looking function of the client, the three utterance
features are conditionally independent of each
other.
3.2 Results and evaluation
For assessing the conditional probability distribu-
tions, we have used the Maximum A Posteriori
(MAP) learning technique - see e.g. (Heckerman,
1999). For training we have used 330 data sam-
ples which is 75% of the available data; the re-
maining samples have been used for testing. We
have measured the performance of the network
in terms of the accuracy of estimating the cor-
rect forward-looking function for different cases
of available evidence, varying from having no ev-
idence at all to having evidence on all features.
This resulted in an average accuracy of 43.5%.
Adding complete evidence to the network for ev-
ery test sample resulted in 38.7% accuracy.
As the amount of data from the SCHISMA cor-
pus currently available is rather small, the results
cannot expected to be very good and more data
have to be collected for further experiments. Still,
the testing results show that the accuracy is signif-
icantly better than an expected accuracy of 8.3%
in the case of guessing the dialogue act randomly.
A tighter baseline commonly used is the relative
frequency of the most frequent dialogue act. For
the data used here, this gives a baseline of 32.5%,
which is still less than our network?s accuracy.
4 Experiments with the navigation
corpus
4.1 Dialogue acts and features
A small corpus of dialogues was derived from the
first implementation of a dialogue system for in-
teraction with the navigation agent. For the ex-
periments with the navigation corpus we also use
the DAMSL layers of Forward- and Backward-
looking functions. On each of these two lay-
ers we only distinguish dialogue acts on the first
level of the hierarchies (see Table 3 for the di-
alogue acts used); a more refined subcategorisa-
tion should be performed by a second step in the
DAR module. The dialogue acts in Table 1 can
be found at the deeper levels of the DAMSL hi-
erarchy, e.g. a request is a special case of a
infl addr fut act and an acknowledge
is a special case of an understanding. The
dialogue act recogniser may also use more ap-
plication specific knowledge in further identifi-
cation of the user intention. Information that
may be used is dialogue information concerning
topic/focus.
Forward-looking
Functions
statement
infl addr fut act
info request
comm sp fut act
conventional
expl performative
exclamation
Backward-looking
Functions
agreement
understanding
answer
Table 3: Dialogue Acts for Navigation.
For the navigation dialogues, we have chosen
a set of surface features of what will eventually
be spoken utterances, in contrast to the typed di-
alogues in the SCHISMA corpus. Therefore, we
don?t use a textual feature like punctuation. For
each utterance, the feature values are found au-
tomatically using a tagger (the features in the
SCHISMA dialogues were tagged manually). In
Table 4 we have listed the features with their pos-
sible values we initially consider relevant.
The dialogue context features include the
backward- and forward-looking function of the
previous dialogue act. This is always a dialogue
act performed by the system. The possible dia-
logue acts performed by the system are the same
as those performed by the user.
The network is generated from data that were
obtained by manually annotating the user ut-
terances in the navigation corpus following the
DAMSL instructions as close as possible. As
with every categorisation there are problematic
Features Values
lenq one, few, many
iswh true, false
not in prev true, false
startsWithCanYou true, false
startsWithCanI true, false
startsWithIWant true, false
containsPositive true, false
containsNegative true, false
containsOkay true, false
containsLocativePrep true, false
containsLocativeAdverb true, false
containsTell true, false
containsDo true, false
Table 4: Surface features of user utterances and
their possible values.
border cases, e.g. when to annotate with in-
direct speech acts. We used the criterion that
such an act should be recognised without task-
specific considerations. Therefore the utterance
?I want to make a phone-call? is annotated as a
statement although eventually it should be in-
terpreted as an info request (?where can I
find a phone??) in the context of a navigation di-
alogue.
After the dialogue act has been recognised the
navigation agent will make a plan for further ac-
tions and perform the planned actions. We will
not discuss that here.
4.2 Results and evaluation
In this experiment the data are used for learning
both structure and conditional probabilities of a
Bayesian network. We have used an implementa-
tion of the K2 algorithm (Cooper and Herskovits,
1992) to generate the network structure and then
- like in the SCHISMA experiment - used MAP to
assess the conditional probability distributions.
Starting from the small corpus of navigation
dialogues, a procedure has been planned to iter-
atively enlarge the corpus: given the annotated
corpus, derive a network, use the network in a
dialogue system, test the network and add these
dialogues - with the corrected backward- and
forward-looking functions - to the corpus. This
results in a more extended set of annotated dia-
logues. And we start again. After each of the
cycles we compare the results (in terms of accu-
racies) with the results of the previous cycle. This
should give more insight in the usefulness of the
features and values chosen for the Bayesian net-
work. After deciding to adapt the set of features
we automatically annotate the corpus; we derive
a new network and we test again.
The current corpus is too small to expect good
results from a generated network, especially if the
data are used for learning both the structure and
the probability distributions. From the initial cor-
pus of 81 utterances 75% was used for generating
a Bayesian network. Testing on the remaining
25% resulted in accuracy of 57.1% for classify-
ing the forward-looking function and 81.0% for
classifying the backward-looking function. Af-
ter this first cycle, new data have been generated
interactively, following the procedure described
above. The Bayesian network trained from this
new data set resulted in the improved accuracies
of 76.5% and 88.2% for classifying the forward-
and backward-looking function respectively. Fol-
lowing this training and testing procedure, we
hope to develop Bayesian networks with increas-
ing performance.
5 Discussion and conclusions
In this paper we have discussed the use of
Bayesian networks for dialogue act recognition in
a natural language dialogue system. We have de-
scribed the construction of such networks from
data in two cases: 1) using annotated dialogues
from the SCHISMA corpus - information ex-
change and transaction - and 2) using a small cor-
pus of annotated navigation dialogues.
As the amount of data currently available is
rather small (especially the navigation corpus),
the network performances measured are not too
impressive. In order to get more data, we have de-
veloped a testing environment which at the same
time enables us to enlarge the corpus. With the
increasing amount of data we hope to construct
Bayesian networks with increasing performance.
As for the SCHISMA corpus, there are 44 dia-
logues that remain to be annotated, also resulting
in more data.
One of the first and most important questions
to be answered concerns the selection of a set of
features (and their values) that set up the model.
We started with a set of features selected on in-
tuition. Then the dialogue corpus was annotated.
As a result of experiments we may conclude that
some of the features have no selective value, so
we can leave them out of the model.
In the future we would like to compare the
approach of using Bayesian networks with other
classifiers that can also be constructed from data,
e.g. decision trees or Bayesian classifiers. Figure
5 shows the accuracies of three different classi-
fiers that were generated from the current set of
navigation data.
Class Bayesian Decision Naive
variable network tree Bayes
forw funct 76.5% 50.0% 55.9%
backw funct 88.2% 64.7% 61.8%
Table 5: Accuracies of three different classi-
fiers for classifying the forward-looking func-
tion (forw funct) and backward-looking function
(backw funct), where all classifiers have been
built from the same set of navigation data.
In our future experiments we will take into ac-
count more refined performance measures like
precision and recall and confusion matrices in
which classification results for individual dia-
logue act types are shown. Such results can help
us make decisions w.r.t. the selected dialogue act
types and features.
Furthermore, non-verbal communicative ac-
tions like pointing at objects in the virtual envi-
ronment could be relevant in recognising dialog
acts and should therefore be made available as
possible features in our Bayesian network clas-
sifiers.
Acknowledgement
We would like to thank the referees for their com-
ments on our paper; these have been very useful
to us in preparing this final version.
References
J. Allen and M. Core. 1997. Draft of
DAMSL: Dialog Act Markup in Several Lay-
ers. URL: http://www.cs.rochester.
edu/research/trains/annotation.
T. Andernach. 1996. A machine learning approach to
the classification and prediction of dialogue utter-
ances. In Proceedings of the Second International
Conference on New Methods in Language Process-
ing (NeMLaP-2), pages 98?109, Ankara, Turkey.
G. F. Cooper and E. Herskovits. 1992. A Bayesian
method for the induction of probabilistic networks
from data. Machine Learning, 9:309?347.
D. Heckerman. 1999. A tutorial on learning with
Bayesian networks. In M. Jordan, editor, Learning
in Graphical Models. MIT Press, Cambridge MA.
S. Keizer. 2001. A Bayesian approach to dialogue
act classification. In P. Ku?hnlein, H. Rieser, and
H. Zeevat, editors, BI-DIALOG 2001: Proc. of the
5th Workshop on Formal Semantics and Pragmatics
of Dialogue, pages 210?218.
J. van Luin, R. op den Akker, and A. Nijholt. 2001.
A dialogue agent for navigation support in virtual
reality. In J. Jacko and A. Sears, editors, ACM
SIGCHI Conf. CHI 2001: Anyone. Anywhere, pages
117?118, Seattle. Association for Computing Ma-
chinery.
T.M. Mitchell. 1997. Machine Learning. Computer
Science Series. McGraw-Hill.
A. Nijholt, J. Zwiers, and B. van Dijk. 2001. Maps,
agents and dialogue for exploring a virtual world.
In N. Callaos, S. Long, and M. Loutfi, editors, 5th
World Multiconference on Systemics, Cybernetics
and Informatics (SCI 2001), volume VII of Human
Information and Education Systems, pages 94?99,
Orlando, July.
A. Nijholt. 2000. Multimodal interactions with
agents in virtual worlds. In N. Kasabov, editor,
Future Directions for Intelligent Systems and Infor-
mation Science, Physica-Verlag: Studies in Fuzzi-
ness and Soft Computing, chapter 8, pages 148?
173. Springer.
T. Paek and E. Horvitz. 2000. Conversation as action
under uncertainty. In 16th Conference on Uncer-
tainty in Artificial Intelligence (UAI-2000), pages
455?464, San Francisco, CA, June. Morgan Kauf-
mann Publishers.
J. Pearl. 1988. Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference. Morgan
Kaufmann.
S.G. Pulman. 1996. Conversational games, belief re-
vision and Bayesian networks. In J. Landsbergen,
J. Odijk, K. van Deemter, and G. Veldhuijzen van
Zanten, editors, Computational Linguistics in the
Netherlands.
A. Stolcke et al 2000. Dialogue act modelling for au-
tomatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339?
374.
D.R. Traum. 2000. 20 questions on dialogue act tax-
onomies. Journal of Semantics, 17(1):7?30.
Towards automatic addressee identification in multi-party dialogues
Natasa Jovanovic
Department of Computer Science
University of Twente
PO Box 217 Enschede, the Netherlands
natasa@cs.utwente.nl
Rieks op den Akker
Department of Computer Science
University of Twente
PO Box 217 Enschede, the Netherlands
infrieks@cs.utwente.nl
Abstract
The paper is about the issue of addressing in
multi-party dialogues. Analysis of addressing
behavior in face to face meetings results in
the identification of several addressing mech-
anisms. From these we extract several utter-
ance features and features of non-verbal com-
municative behavior of a speaker, like gaze
and gesturing, that are relevant for observers to
identify the participants the speaker is talking
to. A method for the automatic prediction of
the addressee of speech acts is discussed.
1 Introduction
Communication, between humans or between humans
and conversational computer agents, involves address-
ing. Addressing has received attention in the tradition
of conversation analysis (Clark and Carlson, 1992; Clark
and Schaefer, 1992), but not that much in the commu-
nity of computational dialogue systems. One exception is
(Traum, 2003). An explanation for this lack of attention
may be that most research in computational dialogue sys-
tems concerns systems that were designed for interaction
between one human user and one conversational agent.
In dialogues in which only two participants take part ad-
dressing goes without saying. Addressing becomes a real
issue in multi-party conversations and that is the subject
of this paper.
There are a number of application areas that could ben-
efit from studying addressing behavior in human human
interactions. It can provide valuable data for learning
more about human interaction and the way humans in-
teract with intelligent environments. The result can be
used by those who develop communicative agents in in-
teractive intelligent environments, meeting managers and
presentation assistants. If we could induce from recorded
meetings the ?who said what, when and to whom? we
can use this information for making summarizations of
meetings, and for real-time tracking.
Research on small group discussions (Carletta et al,
2002) has shown that there is a noticeable difference in
the interaction patterns between large and small groups
(up to seven participants). A small group discussion
looks like two-way conversations but conversations oc-
cur between all pairs of members and every member can
initiate conversation. A large group discussion is more
like a series of conversations between a group leader and
various individuals with the rest participants present but
silent. We will focus our research on small group discus-
sions in meetings.
In this paper we propose research that aims at the au-
tomatic determination of the addressee of a speaker in
small meetings. Analysis of the mechanisms that people
use in identifying their addressees leads to a model of a
conversation that describes the features that play a role
in these mechanisms. These features can be of several
types: verbal, non-verbal, and features of the situation.
Our research is partly based on analysis of the IDIAP
multi-modal meeting data corpus made available through
the Media File Server 1.
2 Addressee detection - problem overview
One of the question of interest concerning a meeting is:
?Who talked to whom and about what during the meet-
ing??. This question refers to three very important as-
pects of a conversational event: source of the message
(speaker identification), topic of the message (topic de-
tection) and addressee of the message (addressee identi-
fication).
Speaker and addressee roles are the basic conversa-
tional roles. There are different ways to categorize the
audience of a speech act. We use a taxonomy of con-
versational roles proposed in (Clark and Carlson, 1992).
People around an action are divided in those who re-
1http://mmm.idiap.ch
ally participate in the action (active participants) and
those who do not (non-participants). The active partic-
ipants in a conversation include speaker and addressee as
well as other participants taking part in conversation but
currently not being addressed. Clark called them side-
participants. All other listeners who have no rights to
take part in conversation are called overhearers. Over-
hearers are divided in two groups: bystanders and eaves-
droppers. Bystanders are overhearers who are present and
the speaker is aware of their presence. Eavesdroppers are
those who are listening without the speakers awareness.
In determining the conversational roles in a meeting situ-
ation we will focus on the active participants. The prob-
lem of addressee identification amounts to the problem of
distinguishing the addressee from the side participants in
a conversation.
According to dialogue act theory (Bunt, 2000) an ut-
terance can consist of several segments which carry dif-
ferent dialogue acts. Each of these dialogue acts can have
it?s own addressee. The following example is an example
of multi-addressee utterances.
A: We could use Java as a standard?
[suggestion] addressee B,C
B: yes? but what about C++ ?
[agreement]addressee A? [suggestion]addressee A,C
C: Both is OK for me
[accept] addressee A,B
3 Observation analysis - addressee
detection in meetings
Three main questions considering addressee detections
are: 1. What are the relevant sources of information for
the addressee detection in face-to-face meetings? 2. How
does the speaker express who is the addressee of his ut-
terance? 3. How can we combine all this information in
order to determine the addressee of the speaker utterance?
In order to find answers on these questions we ob-
served meetings recorded at the IDIAP and annotated
several of them. For annotation we used the NITE Work-
bench for Windows (NWB3) annotation tool 2. We de-
fined our annotation scheme based on the initial assump-
tions about the information sources that can be used for
the addressee identification. These assumptions are the
result of our meeting observations.
3.1 Sources of information
When two or more people are engaged in interaction
they communicate using verbal and/or non-verbal ele-
ments. The most natural and powerful human commu-
nication is in combined use of words, gaze, facial and
gestural movements, posture, bodily contact, etc.
2http://nite.nis.sdu.dk/download/. NWB The NITE Work-
bench is a general-purpose natural interactivity coding tool
3.1.1 Speech
Speech is the main communication channel used in the
meeting conversation. Therefore, it is the main source
for addressee detection. The most common heuristics that
may guide the addressee recognition process is the search
for linguistic markers in the utterance. Table 1 contains
linguistic markers that can be used as cues for addressee
detection. For instance, you is the personal pronoun that
refers to the meeting participants excluding the speaker of
the utterance. Usage of quantifying determiners, numer-
als and indefinite pronouns may help in distinguish you
as a particular person from you as a group. If an utter-
ance contains noun phrases like some of you, few of you,
most of you, etc., then it is addressed to all meeting par-
ticipants. The speaker doesn?t know who he is actually
addressing (He saw some of you yesterday).
Name detection is a powerful method for addressee
determination. The name in vocative form is used for di-
rect addressing the person with that name (What about
you, John?). Using the name of the participant the
speaker can claim something about the participant ad-
dressing the utterance to the other addressee (John was
not present et the last meeting).
Dialogue acts. There is a relation between addressees
of an utterances and the type of the dialogue act the
speaker performed. Sometimes the description of a di-
alogue act includes the possible addressees of the act.
Therefore, knowledge about the dialog act is used as a cue
for addressee detection. For dialogue act annotation we
use the Meeting Recorder Dialogue Acts (MRDA) tag set
(Dhillon et al, 2003). The MRDA is a tag set for labeling
multiparty face-to-face meetings. The tags in the MRDA
set are organized into thirteen groups according to syn-
tactic, semantic, pragmatic and functional characteristic
of the utterance they mark. For addressee detection pur-
poses we used a large subset of the MRDA tag set but we
organized them at two levels: forward looking function
(FLF) and backward looking function (BLF). FLF rep-
resents the effect that an utterance has on the subsequent
interaction. BLF indicates how an utterance relates to the
previous discourse. If an utterance has both functions the
corresponding addressee is the addressee of the BLF.
When an utterance is marked with a BLF it is related
to one of the previous utterances in the conversation. The
addressee of the associated dialogue act in most cases is
the speaker of the related utterance. However, it is pos-
sible that the speaker of the related utterance is the same
as the current speaker. For instance, a speaker can repeat
or correct himself. The addressees of these utterances are
addressees of the related utterances. Most of the BLFs are
related to the previous utterances of the other speaker (ac-
ceptance tags, answer tags, etc.). In the multiparty case
there is a number of interesting interaction patterns with
respect to addressee identification.
Word classes Example Example
Personal pronouns PP I/me, you, she/her, he/him, we/us What do you think about that?
Quantifying determiners+PP all of you, some of you, few of you He saw some of you yesterday.
Numerals+PP two of you, three of you, last of you Three of you should prepare a presentation.
Indefinite pronouns+PP anyone of you, someone of you Did anyone of you finish the job?
Possessive pronouns mine, yours, hers, his, ours, theirs Is this yours?
Personal adjectives my, your, his, her, our, their I like your style.
Indefinite pronouns everybody, somebody, anyone Does anyone have any question?
Table 1: Linguistic markers
1.
A: We could use Java as a standard [suggestion]
B: I agree [accept]
C: No [reject]
D: For me, it is OK [accept]
2.
A: I think that we should use Java [suggestion]
B: I propose C++ [suggestion]
C: I don?t agree with you [reject]
In the first conversation all responses are related to A?s
proposal. Therefore, A is the addressee of the utterances
expressed by B, C and D. It means the addressee doesn?t
have to be the previous speaker. In the second example it
is not clear whether C rejects A?s or B?s proposal or both
proposals. Additional information obtained from visual
channels can help in resolving the addressee ambiguity.
Unlike BLFs, FLFs do not provide much information
about the addressee of a speaker?s utterance. Yet, some
assumptions about the utterance?s addressee are possible,
especially if we take in consideration the linguistic mark-
ers mentioned above. For instance, the speaker of an ut-
terance marked with some of the question tags directly
addresses the addressee to provide information. In com-
bination with the use of the personal pronoun we these
questions are addressed to a subgroup of participants or to
all participants rather than to a single person. Very often
questions in meeting discussions are open-ended ques-
tions. An open-ended question is a question that does
not seek a specific answer. Rather, it is asked in a broad
sense. An open-ended question is more likely addressed
to all meeting participants. If an open ended question
contains ?you? than a single person is the most probable
addressee (What about C? questions? What about you?).
Linguistic markers and dialogue acts described above
provide us with starting assumptions about the most
likely addressee. These assumptions are mostly related
to a size of the target group i.e. whether the addressee is
a single participant, a group of participant or all partic-
ipants. Therefore, some other communication channels
are used in combination with speech for addressing the
utterance. In the following sections we will describe the
role of non-verbal communication channels in addressee
detection.
3.1.2 Gaze direction
Gaze is an important aspect of social interaction (Ar-
gyle, 1973). One of the functions of gaze is channel-
control. Mutual gaze is important when people want to
establish relationship. Unless the utterance is very short
the speaker very soon breaks the mutual gaze. When fin-
ishing the utterance, the speaker gazes back to a listener.
If the speaker decided to continue to talk at turn transition
points, or even before, he usually gazes away. Need for
feedback effects the speaker?s gaze direction. Gaze direc-
tion shows a participant?s focus of attention. In the meet-
ing scenario where all participants are around the table
the focus of attention of the current speaker are mostly the
other meeting participants. Since it is almost impossible
to record eye gazing of participants, gaze information is
obtained and induced from head movements. In (Stiefel-
hagen and Zhu, 2002) it is shown that we can predict a
participant focus of attention based on head orientation
with a reliability of 88,7 %.
The contribution of gaze information to addressee de-
tection is dependent on the current meeting action (dis-
cussion, presentation, note-taking, etc.), the participants?
location and the utterance length. During a presentation a
speaker most probably addresses utterances to all meeting
participants. Therefore, information about gaze direction
is less relevant for a presentation than for a discussion
meeting action. When the utterance is short a speaker
usually gazes only at one participant or at no one, ad-
dressing the utterance at a group of people or at the whole
audience. Moreover, information about the visible areas
of the participants and hence the relative positions they
have in the meeting is relevant for interpreting the gaze
behavior in terms of focus of attention and it?s contribu-
tion to addressing. During a turn a speaker mostly looks
at the participant who are in his visible area. On the other
hand if he wants to address someone outside his visual
area he will often move his body towards the addressee.
The result of automatic or manual gaze annotation is
a list of gazed participants or objects, together with time
stamps. For the BLFs the first participant in the list is
of interest. If the participant is not in the speaker?s vis-
ible area then the gazed participant is the most likely
addressee of the speaker utterance. If the participant is
in the speaker?s visible area and he is a candidate from
the speech analysis then the likelihood that he is the ad-
dressee of the speaker utterance is greater. For the FLFs
utterance length and structure of the gaze list play a very
important role. For BLFs the last participant in the gazed
list is of interest.
3.1.3 Gesture
Pointing at a person is a way to address a speech act
to a person. It is usually accompanied with gazing at the
person. Still the addressee of a speaker?s utterance is not
necessarily the same as a person that the speaker points
at. When X talks to Y and points at Z, at the same time
X usually verbally refers to Z using a proper noun (name
of people, group name, etc.), a pronoun (he/she/they,
him/her/them, his/her/their, etc.) or using the role of par-
ticipant (boss, chairman, etc.). This means that X talks
to Y about Z. (Yesterday I met him on the street.)
3.1.4 Context
The categories of the context that contribute to ad-
dressee detection are: interaction history, meeting action
history, user context and spatial context. Interaction his-
tory is related to the conversation history and to the non-
verbal interaction history. Conversation history contains
the temporal sequence of speakers, performed dialogue
acts and their addressees. Meeting action history is a se-
quence of previous meeting actions including the current
meeting action. For instance, if a presentation is fol-
lowed by a discussion, the presenter is the more proba-
ble addressee of the other participants? utterances, espe-
cially those that are marked as questions. Spatial con-
text includes participants? location, locations of the en-
vironmental objects, distance between participants, par-
ticipants? visible area. User context includes participants
names, gender, social roles (status roles and closeness),
institutional roles etc.
3.2 Towards an automatic addressee detection
Although participants or outsiders are most of the time
quite sure about the intended addressee of a speaker this
knowledge is essentially error-prone. Using observa-
tional features obtained from different available sources
they can only predict the most probable addressee of an
utterance. Methods for addressee detection will either be
rule based or follow a statistical approach.
A rule-based algorithm used for computing addressee
in the MRE (Mission Rehearsal Exercise) project is
shown in (Traum, 2003). The rule-based method we in-
tend to apply for addressee identification first processes
information obtained from the utterance. This returns a
list of possible addressees with corresponding probabil-
ities. The probabilities are estimations from annotated
meeting data. The idea is first to eliminate cases where
the addressee is completely determined (names in voca-
tive forms, quantifiers and numerals in combination with
?you?, etc.). According to analysis of the relation between
dialogue acts and addressee, different sets of rules are ap-
plied for FLFs and BLFs. For instance, if an utterance
is marked with a BLF that is related to an utterance of a
previous speaker, the addressee is the speaker of the re-
lated utterance with probability P . The following steps
are related to the processing of information from addi-
tional sources (gaze and gesture) adding the additional
probability values to the possible addressee. Contextual
features are used at each level of processing.
Given all available multi-modal information E about
a conversational situation a statistical addressee identifi-
cation method should classify the addressee for each dia-
logue act in the conversation. As a computational model
we will use Bayesian networks (BN). The nodes in the
Bayesian network will include all observable features as
input variable and one unobservable output variable that
represent the addressee. From some preliminary models,
we concluded that Bayesian network used for addressee
classification of FLFs is more complicated than for BLFs.
We therefore consider using separate models for BLFs
and FLFs.
4 Conclusions and future directions
Addressing is an interesting aspect of communication
and the automatic identification of conversational roles in
multi-party dialogues is an open research problem. We
expect that statistical approaches can be applied at this
domain. Our future work will be based primarily on ob-
taining a huge set of data for training and testing the mod-
els. We will also define new scenario?s for new types of
meetings that will show more interesting phenomena re-
lated to addressing behavior.
References
Michael Argyle. 1973. Social Interaction. Tavistock
Publications.
H. Bunt. 2000. Dialogue pragmatics and context specifi-
cation. In Abduction, Belief and Context in Dialogue;
studies in computational pragmatics. John Benjamins,
Amsterdam.
Jean Carletta, Anne H. Anderson, and S. Garrod. 2002.
Seeing eye to eye: an account of grounding and un-
derstanding in work groups. Bulletin of the Japanese
cognitive sciences, 9(1):1?20.
Herbert H. Clark and Thomas B. Carlson. 1992. Hear-
ers and speech acts. In Arenas of Language Use
(H.H.Clark ed.). University of Chicago Press and
CSLI.
Herbert H. Clark and Edward F. Schaefer. 1992. Deal-
ing with overhearers. In Arenas of Language Use
(H.H.Clark ed.). University of Chicago Press and
CSLI.
R. Dhillon, S Bhagat, H Carvey, and E. Shriberg. 2003.
Meeting recorder project:dialogue act labeling guide,
version 3. Technical report, ICSI.
Rainer Stiefelhagen and Jie Zhu. 2002. Head orienta-
tion and gaze direction in meetings. In Conference on
Human Factors in Computing Systems (CHI2002).
David Traum. 2003. Issues in multi-party dialogues. In
Advances in Agent Communication (F. Dignum, ed.).
Springer-Verlag LNCS.
Proceedings of the Workshop on Embodied Language Processing, pages 17?24,
Prague, Czech Republic, June 28, 2007. c?2007 Association for Computational Linguistics
Computing Backchannel Distributions in Multi-Party Conversations
Dirk Heylen
Human Media Interaction
University of Twente
heylen@cs.utwente.nl
Rieks op den Akker
Human Media Interaction
University of Twente
infrieks@cs.utwente.nl
Abstract
In multi-party conversations it may not al-
ways be obvious who is talking to whom.
Backchannels may provide a partial answer
to this question, possibly in combination
with some other events, such as gaze behav-
iors of the interlocutors. We look at some
patterns in multi-party interaction relating
features of backchannel behaviours to as-
pects of the partipation framework.
1 Introduction
In this paper we present a summary of our investiga-
tions into the distribution of back-channels and some
other forms of feedback and assesments in argumen-
tative multi-party discourse. We are interested in
such expressions for several reasons. First, the sheer
utterance of a backchannel indicates the presence of
an auditor that indicates ?I am here, I am attending?.
The fact that it is being uttered by an auditor indi-
cates intrinsically that the auditor felt addressed in
some way or another by the speaker. For the anal-
ysis of multi-party conversations, it is important to
establish who is talking to whom and backchannels,
at least seem to give away the whom part. Second,
the exact form, the kind of vocalisation, the intona-
tion and the context may further invest the utterance
with additional meanings, expressing various atti-
tudes towards what has been said: skepticism, sur-
prise, liking, agreement, and so on. So, when we
look at back-channels in the context of multi-party
dialogues they may tell us something about the par-
ticipation framework on the one hand (who was talk-
ing to whom) and about the way utterances are being
assessed by their audience.
The qualifier ?in some way or another? with re-
spect to feeling or being addressed is particularly
important in the context of multi-party dialogues
(i.e. dialogues with more than two persons present).
Typically, an utterance by a speaker instantiates the
performance of a speech act with a particular il-
locutionary and perlocutionary force. The speech
act involves a request for uptake. However, as has
been pointed out several times (Goffman (Goffman,
1981), Levinson (Levinson, 1988), Clark and Carl-
son (Clark and Carlson, 1992), Schegloff (Schegloff,
1988)), participants in a multi-party conversation
can have a different role or status and they can be
addressed in different ways.
In this paper we report on some of our investiga-
tions into the distribution of backchannels in mul-
tiparty interactions (for instance in relation to other
phenomena such as gaze) and how this information
can help us to uncover certain features of floor and
stance taking automatically.
We will first describe the corpus and the anno-
tations. Next we look at the annotations of utter-
ances consisting of starting with ?yeah? and try to
see whether we can classify these utterances as con-
tinuers, i.e. neutral with respect to stance taking
(Schegloff, 1981), or as assessments.
2 Corpus
The argumentative discourses that we are study-
ing are part of the meeting corpus collected during
the AMI project (McCowan et al, 2005). From a
computational, technological perspective, the aims
17
of this research is directed at developing automatic
procedures that can help to provide answers to any
query users may have about what goes on in the
meetings. The AMI corpus consists of meetings in
which a group of four people discuss the design of a
new remote control. T
The kinds of queries that we would like our proce-
dures to be able to answer are related to these moves:
what suggestions have been made; what were the ar-
guments given and how much animosity was there
related to the decision. In the AMI corpus, the meet-
ing recordings have been annotated on many levels,
allowing the use of machine learning techniques to
develop appropriate algorithms for answering such
questions. We focus on the dialogue act annotation
scheme. This contains three types of information.
Information on the speech act, the relation between
speech acts and information on addressing.
The dialogue act classes that are distinguished in
our dialogue act annotation schema fall into the fol-
lowing classes:
? Classes for things that are not really dialogue
acts at all, but are present to account for some-
thing in the transcription that doesn?t really
convey a speaker intention. This includes
backchannels, stalls and fragments
? Classes for acts that are about information ex-
change: inform and elicit inform.
? Classes for acts about some action that an indi-
vidual or group might take: suggest, offer, elicit
suggest or offer.
? Classes for acts that are about commenting on
the previous discussion: assess, comment about
understanding, elicit assessment, elicit com-
ment about understanding
? Classes for acts whose primary purpose is to
smooth the social functioning of the group: be-
positive, be-negative.
? A ?bucket? type, OTHER, for acts that do con-
vey a speaker intention, but where the intention
doesn?t fit any of the other classes.
For our studies into feedback in the AMI cor-
pus, the dialogue acts labelled as backchannesl are
clearly important. They were defined in the annota-
tion manual as follows.
In backchannels, someone who has just been
listening to a speaker says something in the
background, without really stopping that speaker.
[...] Some typical backchannels are ?uhhuh?,
?mm-hmm?, ?yeah?, ?yep?, ?ok?, ?ah?, ?huh?,
?hmm?, ?mm? and, for the Scottish speakers in the
data recorded in Edinburgh, ?aye?. Backchannels
can also repeat or paraphrase part or all of what
the main speaker has just said.
The labels assess and comment-about-
understanding are closely related. They were
defined as follows.
An ASSESS is any comment that expresses an
evaluation, however tentative or incomplete, of
something that the group is discussing. [...] There
are many different kinds of assessment; they include,
among other things, accepting an offer, express-
ing agreement/disagreement or any opinion about
some information that?s been given, expressing un-
certainty as to whether a suggestion is a good idea
or not, evaluating actions by members of the group,
such as drawings. [...] An ASSESS can be very
short, like ?yeah? and ?ok?. It is important not to
confuse this type of act with the class BACKCHAN-
NEL, where the speaker is merely expressing, in the
background, that they are following the conversa-
tion.
C-A-U is for the very specific case of comment-
ing on a previous dialogue act where the speaker in-
dicates something about whether they heard or un-
derstood what a previous speaker has said, without
doing anything more substantive. In a C-A-U, the
speaker can indicate either that they did understand
(or simply hear) what a previous speaker said, or
that they didn?t.
The Backchannel class largely conforms to Yn-
gve?s notion of backchannel and is used for the
functions of contact (Yngve, 1970). Assess is used
for the attitudinal reactions, where the speaker ex-
presses his stance towards what is said, either ac-
ceptance or rejection. Comments about understand-
ing are used for explicit signals of understanding or
non-understanding.
In addition to dialogue acts also relation between
dialogue acts are annotated. Relations are anno-
tated between two dialogue acts (a later source act
18
and an earlier target act) or between a dialogue act
(the source of the relation) and some other action, in
which case the target is not specified. Relations are
a more general concept than adjacency pairs, like
question-answer. Relation have one of four types:
positive, negative, partial and uncertain, indicating
that the source expresses a positive, negative, par-
tially positive or uncertain stance of the speaker to-
wards the contents of the target of the related pair.
For example: a ?yes?-answer to a question is an in-
form act that is the source of a positive relation with
the question act, which is the target of the relation.
A dialogue act that assesses some action that is not a
dialogue act, will be coded as the source of a relation
that has no (dialogue act as) target.
A part of the scenario-based meetings (14 meet-
ings) were annotated with addressee labels, i.e. an-
notators had to say who the speaker is talking to.
The addressee tag is attached to the dialogue act. If
a speaker changes his addressee (for instance, from
group to a particular participant) during a turn the
utterance should be split into two dialogue act seg-
ments, even if the type of dialogue act is the same
for both segments.
3 Yeah
In this section we look at the distribution of yeah in
the AMI corpus. ?yeah? utterances make up a sub-
stantial part of the dialogue acts in the AMI meeting
conversations (about 8%). If we try to tell group
addressed dialogue acts from individually addressed
acts then ?yeah? is the best cue phrase for the class
of single addressed dialogue acts; cf. (Stehouwer,
2006).
In order to get information about the stance that
participants take with respect towards the issue dis-
cussed it is important to be able to tell utterances of
?yeah? as a mere backchannel, or a stall, from yeah-
utterances that express agreement with the opinion
of the speaker. The latter will more often be classi-
fied as assessments. We first look at the way anno-
tators used and confused the labels and then turn to
see in what way we can predict the assignments to
the class.
3.1 Annotations of yeah utterances
One important feature of the dialogue act annota-
tion scheme is that the annotators had to decide what
they consider to be the segments that constitute a di-
alogue act. Annotators differ in the way they seg-
ment the transcribed speech of a speaker. Where one
annotator splits ?Yeah. Maybe pear yeah or some-
thing like that.? into two segments labeling ?yeah.?
as a backchannel and the rest as a suggest, an other
may not split it and consider the whole utterance as
a suggest.
In comparing how different annotators labeled
?yeah? occurrences, we compared the labels they as-
signed to the segment that starts with the occurrence
of ?yeah?.
The confusion matrix for 2 annotators of 213
yeah-utterances, i.e. utterances that start with
?yeah?, is given below. It shows that backchan-
nel (38%), assess (37%) and inform (11%) are the
largest categories 1. Each of the annotators has about
80 items in the backchannel class. In about 75% of
the cases, annotators agree on the back-channel la-
bel. In either of the other cases a category deemed
a backchannel is mostly categorized as assessment
by the other and vice versa. For the assessments,
annotators agree on about slightly more than half
of the cases (43 out of 79 and 43 out of 76). The
disagreements are, for both annotators split between
the backchannels, for the larger part, the inform cat-
egory, as second largest, and the other category.
The other category subsumes the following types
of dialogue acts: summing up for both annotators:
be-positive(9), suggest(8), elicit-assess(3), elicit-
inform(2), comment-about-understanding(2). The
dialogue act type of these other labeled utterances
is mostly motivated by the utterances following
?Yeah?. Examples: ?Yeah , it?s a bit difficult? is
labeled as Be-positive. ?Yeah ? Was it a nice way to
create your remote control ?? is labeled as an Elicit-
Assessment .
Out of the 213 Yeah-utterances a number contains
just ?yeah? without a continuation. Below, the con-
fusion matrix for the same two annotators, but now
for only those cases that have text ?yeah? only. In
1As the numbers for each of the classes by both annotators
is about the same, we have permitted ourselves the license to
this sloppy way of presenting the percentages.
19
yeah 0 1 2 3 4 SUM
0 59.0 2.0 17.0 0.0 2.0 80.0
1 0.0 9.0 4.0 2.0 2.0 17.0
2 21.0 3.0 43.0 7.0 5.0 79.0
3 2.0 0.0 7.0 13.0 4.0 26.0
4 1.0 0.0 5.0 0.0 5.0 11.0
SUM 83.0 14.0 76.0 22.0 18.0 213.0
Figure 1: Confusion matrix of two annotations of
all Yeah utterances. labels: 0 = backchannel; 1 =
fragment or stall; 2 = assess; 3 = inform; 4 = other.
p0=0.61 (percentage agreement); kappa=0.44.
yeah-only 0 1 2 SUM
0 50.0 12.0 3.0 65.0
1 13.0 5.0 1.0 19.0
2 2.0 0.0 2.0 4.0
SUM 65.0 17.0 6.0 88.0
Figure 2: labels: 0 = bc 1 = assess 2 = other
(subsuming: be-positive, fragment, comment-about-
understanding). p0=0.65; kappa=0.14
the comparison only those segments were taken into
account that both annotators marked as a segment
i.e. a dialogue act realized by the word ?Yeah? only.2
What do these patterns in the interpretation of
?yeah? expressions tell us about its semantics? It
appears that there is a significant collection of occur-
rences that annotators agree on as being backchan-
nels. For the classes of assessments and other there
also seem to be prototypical examples that are clear
for both annotators. The confusions show that there
is a class of expressions that are either interpreted
as backchannel or assess and a class whose expres-
sions are interpreted as either assessments or some
other label. Annotators often disagree in segmenta-
tion. A segment of speech that only consist of the
word ?yeah? is considered to be either a backchan-
nel or an assess, with very few exceptions. There is
more confusion between annotators than agreement
about the potential assess acts.
2The text segment covered by the dialogue act then contains
?Yeah?, ?Yeah ??, ?Yeah ,? or ?Yeah .?.
3.2 Predicting the class of a yeah utterance
We derived a decision rule model for the assignment
of a dialogue act label to yeah utterances, based
on annotated meeting data. For our exploration we
used decision tree classifiers as they have the advan-
tage over other classifiers that the rules can be inter-
preted.
The data we used consisted of 1122 yeah utter-
ances from 15 meetings. Because of the relative low
inter-annotator agreement, we took meetings that
were all annotated by one and the same annotator,
because we expect that it will find better rules for
classifying the utterances when the data is not too
noisy.
There are 12786 dialogue act segments in the cor-
pus. The number of segments that start with ?yeah?
is 1122, of which 861 are short utterances only con-
taining the word ?yeah?. Of the 1122 yeahs 493 di-
alogue acts were annotated as related to a previous
dialogue act. 319 out of the 861 short yeah utter-
ances are related to a previous act.
The distribution of the 1122 yeah utterances over
dialogue act classes is: assess (407), stall (224),
backchannel (348), inform (95) and other (48 of
which 25 comment-about-understanding). These are
the class variables we used in the classification. The
model consists of five features. We make use of the
notion of conversational state, being an ensemble
of the speech activities of all participants. Since
we have four participants a state is a 4-tuple <
a, b, c, d > where a is the dialogue act performed by
participant A, etc. A conversation is in a particular
state as long as no participant stops or starts speak-
ing. Thus, a state change occurs every time when
some participants starts speaking or stops speaking,
in the sense that the dialogue act that he performs
has finished. The features that we use are:
? lex This feature has value 0 if the utterance con-
sists of the word Yeah only. Otherwise 1.
? continue Has value 1 when the producer of the
utterance also speaks in the next conversational
state. Otherwise 0. This feature models incipi-
ent behavior of the backchanneler.
? samespeaker Has value 1 if the conversational
state in which this utterance happens has the
20
Null 629.0
Assess 81.0
Inform 162.0
Elicit-Comment-Understanding 2.0
Elicit-Assessment 40.0
Elicit-Inform 73.0
Elicit-Offer-Or-Suggestion 2.0
Suggest 114.0
Comment-About-Understanding 13.0
Offer 5.0
Be-Positive 1.0
Figure 3: Distribution of the types of dialogue acts
that yeah utterances are responses to.
same speaker, but different from the backchan-
neler, as the next state. Otherwise 0. This fea-
ture indicates that there is another speaker that
continues speaking.
? overlap There is speaker overlap in the state
where the utterance started.
? source This involves the relation labeling of the
annotation scheme. source refers to the dia-
logue act type of the source of the relation of
the dialogue act that is realized by the Yeah ut-
terance. If the yeah dialogue act is not related
to some other act the value of this feature is
null. The possible values for this feature are:
null, assess, inform, suggest, elicitation (which
covers all elicitations), and other.
The distribution of source types of the 1122 yeah
dialogue acts is shown in table 3.2. The table shows
that 629 out of 1122 yeah utterances were not related
to some other act.
We first show the decision tree computed by
the J48-tree classifier as implemented in the weka-
toolkit, if we do not use the source feature looks as
follows. The tree shows that 392 utterances satisfy
the properties: continued = 1 and short = 1. Of these
158 are misclassified as backchannel.
1. Continued ? 0
(a) lex ? 0: bc(392.0/158.0)
(b) lex > 0: as(56.0/24.0)
2. Continue ? 0
(a) samespkr ? 0
i. overlap ? 0: st(105.0/27.0)
ii. overlap > 0
A. lex ? 0: st(76.0/30.0)
B. lex > 0: bc(16.0/6.0)
(b) samespkr > 0 : ass(477.0/233.0)
In this case the J48 decision tree classifier has an
accuracy of 57%. If we decide that every yeah utter-
ance is a Backchannel, the most frequent class in our
data, we would have an accuracy of 31%. If we in-
clude the source feature, so we know the type of dia-
logue act that the yeah utterance is a response to, the
accuracy of the J48 classifier raises at 80%. Figure
3.2 shows the decision tree for this classifier. The re-
sults were obtained using ten-fold cross-validation.
It is clear from these results that there is a strong
relation between the source type of a Yeah dialogue
act and the way this Yeah dialogue act should be
classified: as a backchannel or as an assess. Note
that since backchannels are never marked as target
of a relation, null as source value is a good indicator
for the Yeah act to be a backchannel or a stall.
We also tested the decision tree classifier on a test
set that consists of 4453 dialogue acts of which 539
are yeah-utterances (219 marked as related to some
source act). Of these 219 are short utterances con-
sisting only of the word ?Yeah? (139 marked as re-
lated). The utterances in this test set were annotated
by other annotators than the annotator that annotated
the training set. The J48 classifier had an accuracy
on the test set of 64%. The classes which are con-
fused most are those that are also confused most by
the human annotators: backchannels and stall, and
assess and inform. One cause of the performance
drop is that in the test corpus the distribution of class
labels differs substantially from that of the training
set. In the test set yeah utterances were very rarely
labelled as stall, whereas this was a frequent label
(about 20%) in the training set. The distribution of
yeah-utterance labels in the test set is: backchannels
241, stalls 4, assessments 186, inform 66 and other
42.
When we merged the train and test meetings and
trained the J48 decision tree classifier, a 10 fold
cross-validation test showed an accuracy of 75%.
Classes that are confused most are again: backchan-
nel and stall, and assessment and inform.
21
Figure 4: Decision tree for classification of yeah utterances when information about the source of the related
dialogue act is used.
4 Measuring Speaker Gaze at
Backchannelors
When thinking about the interaction between
speaker and backchannelor, it seems obvious, as we
said before, that the person backchanneling feels ad-
dressed by the speaker. We were wondering whether
the backchannel was not prompted by an invitation
of a speaker, for example, by gazing at the listener.
Gaze behavior of speaker and backchannelor is
classified by means of the following gaze targets, a
sequence of focus of attention labels that indicates
where the actor is looking at during a period of time:
1. the gaze targets of the speaker in the period
starting some short time (DeltaT ime) before
the start time of the backchannel act till the start
of the backchannel act.
2. the gaze targets of the backchannelor in the pe-
riod starting some short time (DeltaT ime) be-
fore the start time of the backchannel act till the
start of the backchannel act.
3. the gaze targets of the speaker during the
backchannel act.
4. the gaze targets of the backchannelor during the
backchannel act.
We set DeltaT ime at 1 sec, so we observed the gaze
behavior of the speaker in the period from one sec-
ond before the start of the backchannel act. Using
these gaze target sequences, we classified the gaze
behavior of the actor as follows:
0: the gaze before target sequence of the actor
does not contain any person
1: the before gaze target sequence of the actor
does contain a person but not the other ac-
tor involved: for the speaker this means that
he did not look at backchannelor before the
backchannel act started, for the backchannelor
this means that he did not look at the speaker
before the start of the backchannel.
2: the actor did look at the other person involved
before that backchannel act.
22
Figure 4 show a table with counts of these classes
of events. In the 13 meetings we counted 1085
backchannel events. There were 687 events with a
single speaker of a real dialogue act. For this cases
it is clear who the backchannelor was reacting on.
This is the selected speaker. The table shows speaker
data in rows and backchannel data in columns. The
MaxDownTime is 1sec and the MinUpTime is
2 sec. The DeltaT ime for the gaze period is 1sec.
From the table we can infer that:
1. The selected speaker looks at the backchan-
nelor in the period before the backchannelor act
starts in 316 out of the 687 cases.
2. The backchannelor looks at the selected
speaker in the period before the backchannelor
act starts in 430 out of the 687 cases.
3. The selected speaker looks at someone else
than the backchannelor in the period before the
backchannelor act starts in 209 out of the 687
cases.
4. The backchannelor looks at someone else than
the selected speaker in the period before the
backchannelor act starts in 54 out of the 687
cases.
5. In 254 out of the 687 cases the speaker looked
at the backchannelor and the backchannelor
looked at the speaker.
We may conclude that the speakers look more at
the backchannelor than at the other two persons to-
gether (316 against 209). The table also shows that
backchannelors look far more at the selected speaker
than at the two others (430 against 54 instances).
In order to compare gaze of speaker in backchan-
nel events, we also computed for each of the
13 meetings for each pair of participants (X,Y ):
dagaze(X,Y ): how long X looks at Y in those time
frames that X is performing a dialogue act.
dagaze(X,Y ) =
?
OT (gaze(X,Y ), da(X))
?
da(X)
(1)
where summation is over all real dialogue acts
performed by X ,
OT (gaze(X,Y ), da(X)) is the overlap time of the
sp|bc 0 1 2 T
0 103 4 55 162
1 46 42 121 209
2 54 8 254 316
T 203 54 430 687
Figure 5: Gaze table of speaker and backchannelor.
DeltaT ime = 1sec. Total number of backchannel
events is 1085. In the table only those 687 backchan-
nel events with a single speaker are considered (ex-
cluded are those instances where no speaker or more
than one speaker was performing a real dialogue act
in the period with a MinUpTime of 2 sec and a
MaxDownTime of 1 sec.). Speaker data in rows;
backchannelor data in columns. The table shows
for example that in 121 cases the speaker looked
at someone but not the backchannelor, in the period
from 1 sec before the start of the backchannel act till
the start of the backchannel act, while the backchan-
nelor looked in that period at the speaker.
two events: gaze(X,Y ): the time that X gazes at Y ,
and da(X) the time that the dialogue act performed
by X lasts. The numbers are normalized over the to-
tal duration of the dialogue acts during which gaze
behavior was measured.
Next we computed bcgaze(X,Y ): how long X
looks at Y in those time frames that X performs
a real dialogue act and the Y responds with a
backchannel act.
bcgaze(X,Y ) =
?
OT (gaze(X,Y ), dabc(X,Y ))
?
da(X,Y )
(2)
where dabc(X,Y ) is the time that X performs
the dialogue act that Y reacts on by a backchannel.
Here normalization is with the sum of the lengths
of all dialogue acts performed by X that elicited a
backchannel act by Y .
Analysis of pairs of values gaze(X,Y ) and
bcgaze(X,Y ) shows that in a situation where some-
one performs a backchannel the speaker looks
significantly more at the backchannelor than the
speaker looks at the same person in general when
the speaker is performing a dialogue act (t = 8.66,
df = 101, p < 0.0001). The mean values are 0.33
23
and 0.16.3
Perhaps we can use the information on gaze of the
participants in the short period before the backchan-
nel act as features for predicting who the backchan-
nel actor is. For the 687 data points of backchannel
events with a single speaker, we used gaze of partici-
pants, the speaker and the duration of the backchan-
nel act as features. Using a decision tree classifier
we obtained an accuracy of 51% in predicting who
will perform a backchannel act (given that someone
will do that). Note that there are three possible ac-
tors (the speaker is given). This score is 16% above
the a priori likelihood of the most likely participant:
A (36%).
Conclusion
In this paper, we have explored some questions
about the possible use and function of backchan-
nels in multiparty interactions. On the one hand
backchannels can be informative about functions re-
lated to floor and participation: who is talking to
whom. Obviously, a person producing a backchan-
nel was responding to an utterance of speaker.
For the semantic analysis of meeting data an im-
portant question is whether he was just using the
backchannel as a continuer (a sign of attention) or
as an assessment. We also checked our intuition
that backchannels in the kinds of meetings that we
are looking at might often be invited by speakers
through gaze. Obviously, these investigations just
scratch the service of how backchannels work in
conversations and how we can use them to uncover
information from recorded conversations.
References
H. H. Clark and T. B. Carlson. 1992. Hearers and speech
acts. In Herbert H. Clark, editor, Arenas of Language
Use, pages 205?247. University of Chicago Press and
CSLI.
Erving Goffman. 1981. Footing. In Erving Goffman,
editor, Forms of Talk, pages 124?159. University of
Pennsylvania Press, Philadelphia, PA.
Stephen C. Levinson. 1988. Putting linguistics on a
proper footing: explorations in goffman?s concept of
3For 13 meeting and 4 participants we would have 156 pairs
of values. We only used those 102 pairs of which both values
are non-zero.
participation. In Paul Drew and Anthony Wootton, ed-
itors, Erving Goffman. Exploring the Interaction Or-
der, pages 161?227. Polity Press, Cambridge.
I. McCowan, J. Carletta, W. Kraaij, S. Ashby, S. Bour-
ban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec,
V. Karaiskos, M.Kronenthal, G. Lathoud, M. Lincoln,
A. Lisowska, W. Post, D. Reidsma, and P. Wellner.
2005. The ami meeting corpus. In Measuring Be-
haviour, Proceedings of 5th International Conference
on Methods and Techniques in Behavioral Research.
Emanuel A. Schegloff. 1981. Discourse as an interac-
tional achievement: some uses of ?uh huh? and other
things that come between sentences. In Deborah Tan-
nen, editor, Analyzing Discourse: Text and Talk, pages
71?93. Georgetown University Press, Washington.
Emanuel A. Schegloff. 1988. Goffman and the analysis
of conversation. In Paul Drew and Anthony Wootton,
editors, Erving Goffman. Exploring the Interaction Or-
der, pages 89?135. Polity Press, Cambridge.
J.H. Stehouwer. 2006. Cue-phrase selection methods
for textual classification problems. Technical report,
M.Sc. Thesis, Twente University, Human Media Inter-
action, Enschede, the Netherlands.
V.H. Yngve. 1970. On getting a word in edgewise. In
Papers from the sixth regional meeting of the Chicago
Linguistic Society, pages 567?77, Chicago: Chicago
Linguistic Society.
24
Addressee Identification in Face-to-Face Meetings
Natasa Jovanovic, Rieks op den Akker and Anton Nijholt
University of Twente
PO Box 217 Enschede
The Netherlands
{natasa,infrieks,A.Nijholt}@ewi.utwente.nl
Abstract
We present results on addressee identifica-
tion in four-participants face-to-face meet-
ings using Bayesian Network and Naive
Bayes classifiers. First, we investigate
how well the addressee of a dialogue
act can be predicted based on gaze, ut-
terance and conversational context fea-
tures. Then, we explore whether informa-
tion about meeting context can aid classi-
fiers? performances. Both classifiers per-
form the best when conversational context
and utterance features are combined with
speaker?s gaze information. The classifiers
show little gain from information about
meeting context.
1 Introduction
Addressing is an aspect of every form of commu-
nication. It represents a form of orientation and
directionality of the act the current actor performs
toward the particular other(s) who are involved in
an interaction. In conversational communication
involving two participants, the hearer is always the
addressee of the speech act that the speaker per-
forms. Addressing, however, becomes a real issue
in multi-party conversation.
The concept of addressee as well as a vari-
ety of mechanisms that people use in addressing
their speech have been extensively investigated
by conversational analysts and social psycholo-
gists (Goffman, 1981a; Goodwin, 1981; Clark and
Carlson, 1982).
Recently, addressing has received consider-
able attention in modeling multi-party interac-
tion in various domains. Research on au-
tomatic addressee identification has been con-
ducted in the context of mixed human-human
and human-computer interaction (Bakx et al,
2003; van Turnhout et al, 2005), human-human-
robot interaction (Katzenmaier et al, 2004), and
mixed human-agents and multi-agents interaction
(Traum, 2004). In the context of automatic anal-
ysis of multi-party face-to-face conversation, Ot-
suka et al (2005) proposed a framework for
automating inference of conversational structure
that is defined in terms of conversational roles:
speaker, addressee and unaddressed participants.
In this paper, we focus on addressee identifica-
tion in a special type of communication, namely,
face-to-face meetings. Moreover, we restrict our
analysis to small group meetings with four partic-
ipants. Automatic analysis of recorded meetings
has become an emerging domain for a range of
research focusing on different aspects of interac-
tions among meeting participants. The outcomes
of this research should be combined in a targeted
application that would provide users with useful
information about meetings. For answering ques-
tions such as ?Who was asked to prepare a presen-
tation for the next meeting?? or ?Were there any
arguments between participants A and B??, some
sort of understanding of dialogue structure is re-
quired. In addition to identification of dialogue
acts that participants perform in multi-party dia-
logues, identification of addressees of those acts is
also important for inferring dialogue structure.
There are many applications related to meeting
research that could benefit from studying address-
ing in human-human interactions. The results
can be used by those who develop communicative
agents in interactive intelligent environments and
remote meeting assistants. These agents need to
recognize when they are being addressed and how
they should address people in the environment.
This paper presents results on addressee identi-
169
fication in four-participants face-to-face meetings
using Bayesian Network and Naive Bayes classi-
fiers. The goals in the current paper are (1) to
find relevant features for addressee classification
in meeting conversations using information ob-
tained from multi-modal resources - gaze, speech
and conversational context, (2) to explore to what
extent the performances of classifiers can be im-
proved by combining different types of features
obtained from these resources, (3) to investigate
whether the information about meeting context
can aid the performances of classifiers, and (4) to
compare performances of the Bayesian Network
and Naive Bayes classifiers for the task of ad-
dressee prediction over various feature sets.
2 Addressing in face-to-face meetings
When a speaker contributes to the conversation, all
those participants who happen to be in perceptual
range of this event will have ?some sort of partic-
ipation status relative to it?. The conversational
roles that the participants take in a given conversa-
tional situation make up the ?participation frame-
work? (Goffman, 1981b).
Goffman (1976) distinguished three basic kinds
of hearers: those who overhear, whether or not
their unratified participation is unintentional or en-
couraged; those who are ratified but are not specif-
ically addressed by the speaker (also called unad-
dressed recipients (Goffman, 1981a)); and those
ratified participants who are addressed. Ratified
participants are those participants who are allowed
to take part in conversation. Regarding hearers?
roles in meetings, we are focused only on ratified
participants. Therefore, the problem of addressee
identification amounts to the problem of distin-
guishing addressed from unaddressed participants
for each dialogue act that speakers perform.
Goffman (1981a) defined addressees as those
?ratified participants () oriented to by the speaker
in a manner to suggest that his words are particu-
larly for them, and that some answer is therefore
anticipated from them, more so than from the other
ratified participants?. According to this, it is the
speaker who selects his addressee; the addressee is
the one who is expected by the speaker to react on
what the speaker says and to whom, therefore, the
speaker is giving primary attention in the present
act.
In meeting conversations, a speaker may ad-
dress his utterance to the whole group of partici-
pants present in the meeting, or to a particular sub-
group of them, or to a single participant in partic-
ular. A speaker can also just think aloud or mum-
ble to himself without really addressing anybody
(e.g.?What else do I want to say?? (while try-
ing to evoke more details about the issue that he is
presenting)). We excluded self-addressed speech
from our study.
Addressing behavior is behavior that speakers
show to express to whom they are addressing their
speech. It depends on the course of the conver-
sation, the status of attention of participants, their
current involvement in the discussion as well as
on what the participants know about each others?
roles and knowledge, whether explicit addressing
behavior is called for. Using a vocative is the ex-
plicit verbal way to address someone. In some
cases the speaker identifies the addressee of his
speech by looking at the addressee, sometimes ac-
companying this by deictic hand gestures. Ad-
dressees can also be designated by the manner of
speaking. For example, by whispering, a speaker
can select a single individual or a group of people
as addressees. Addressees are often designated by
the content of what is being said. For example,
when making the suggestion ?We all have to de-
cide together about the design?, the speaker is ad-
dressing the whole group.
In meetings, people may perform various group
actions (termed as meeting actions) such as pre-
sentations, discussions or monologues (McCowan
et al, 2003). A type of group action that meeting
participants perform may influence the speaker?s
addressing behavior. For example, speakers may
show different behavior during a presentation than
during a discussion when addressing an individ-
ual: regardless of the fact that a speaker has
turned his back to a participant in the audience
during a presentation, he most probably addresses
his speech to the group including that participant,
whereas the same behavior during a discussion, in
many situations, indicates that that participant is
unaddressed.
In this paper, we focus on speech and gaze as-
pects of addressing behavior as well as on con-
textual aspects such as conversational history and
meeting actions.
3 Cues for addressee identification
In this section, we present our motivation for fea-
ture selection, referring also to some existing work
170
on the examination of cues that are relevant for ad-
dressee identification.
Adjacency pairs and addressing - Adjacency
pairs (AP) are minimal dialogic units that con-
sist of pairs of utterances called ?first pair-part?
(or a-part) and the ?second pair-part? (or b-part)
that are produced by different speakers. Examples
include question-answers or statement-agreement.
In the exploration of the conversational organiza-
tion, special attention has been given to the a-parts
that are used as one of the basic techniques for se-
lecting a next speaker (Sacks et al, 1974). For ad-
dressee identification, the main focus is on b-parts
and their addressees. It is to be expected that the
a-part provides a useful cue for identification of
addressee of the b-part (Galley et al, 2004). How-
ever, it does not imply that the speaker of the a-part
is always the addressee of the b-part. For example,
A can address a question to B, whereas B?s reply
to A?s question is addressed to the whole group. In
this case, the addressee of the b-part includes the
speaker of the a-part.
Dialogue acts and addressing When designing
an utterance, a speaker intends not only to per-
form a certain communicative act that contributes
to a coherent dialogue (in the literature referred
to as dialogue act), but also to perform that act to-
ward the particular others. Within a turn, a speaker
may perform several dialogue acts, each of those
having its own addressee ( e.g. I agree with you
[agreement; addressed to a previous speaker] but
is this what we want [information request; ad-
dressed to the group]). Dialogue act types can
provide useful information about addressing types
since some types of dialogue acts -such as agree-
ments or disagreements- tend to be addressed to
an individual rather than to a group. More infor-
mation about the addressee of a dialogue can be
induced by combining the dialogue act informa-
tion with some lexical markers that are used as ad-
dressee ?indicators? (e.g. you, we, everybody, all
of you) (Jovanovic and op den Akker, 2004).
Gaze behavior and addressing Analyzing
dyadic conversations, researchers into social
interaction observed that gaze in social inter-
action is used for several purposes: to control
communication, to provide a visual feedback, to
communicate emotions and to communicate the
nature of relationships (Kendon, 1967; Argyle,
1969).
Recent studies into multi-party interaction em-
phasized the relevance of gaze as a means of ad-
dressing. Vertegaal (1998) investigated to what ex-
tent the focus of visual attention might function as
an indicator for the focus of ?dialogic attention? in
four-participants face-to-face conversations. ?Di-
alogic attention? refers to attention while listening
to a person as well as attention while talking to
one or more persons. Empirical findings show that
when a speaker is addressing an individual, there
is 77% chance that the gazed person is addressed.
When addressing a triad, speaker gaze seems to be
evenly distributed over the listeners in the situa-
tion where participants are seated around the ta-
ble. It is also shown that on average a speaker
spends significantly more time gazing at an indi-
vidual when addressing the whole group, than at
others when addressing a single individual. When
addressing an individual, people gaze 1.6 times
more while listening (62%) than while speaking
(40%). When addressing a triad the amount of
speaker gaze increases significantly to 59%. Ac-
cording to all these estimates, we can expect that
gaze directional cues are good indicators for ad-
dressee prediction.
However, these findings cannot be generalized
in the situations where some objects of interest are
present in the conversational environment, since
it is expected that the amount of time spent look-
ing at the persons will decrease significantly. As
shown in (Bakx et al, 2003), in a situation where
a user interacts with a multimodal information sys-
tem and in the meantime talks to another person,
the user looks most of the time at the system, both
when talking to the system (94%) and when talk-
ing to the user (57%). Also, another person looks
at the system in 60% of cases when talking to the
user. Bakx et al (2003) also showed that some im-
provement in addressee detection can be achieved
by combining utterance duration with gaze.
In meeting conversations, the contribution of
the gaze direction to addressee prediction is also
affected by the current meeting activity and seat-
ing arrangement (Jovanovic and op den Akker,
2004). For example, when giving a presentation,
a speaker most probably addresses his speech to
the whole audience, although he may only look at
a single participant in the audience. A seating ar-
rangement determines a visible area for each meet-
ing participant. During a turn, a speaker mostly
looks at the participants who are in his visible area.
171
Moreover, the speaker frequently looks at a sin-
gle participant in his visual area when addressing
a group. However, when he wants to address a sin-
gle participant outside his visual area, he will often
turn his body and head toward that participant.
In this paper, we explored not only the effec-
tiveness of the speaker?s gaze direction, but also
the effectiveness of the listeners? gaze directions
as cues for addressee prediction.
Meeting context and addressing As Goff-
man (1981a) has noted, ?the notion of a conver-
sational encounter does not suffice in dealing with
the context in which words are spoken; a social
occasion involving a podium event or no speech
event at all may be involved, and in any case, the
whole social situation, the whole surround, must
always be considered?. A set of various meet-
ing actions that participants perform in meetings is
one aspect of the social situation that differentiates
meetings from other contexts of talk such as ordi-
nary conversations, interviews or trials. As noted
above, it influences addressing behavior as well
as the contribution of gaze to addressee identifi-
cation. Furthermore, distributions of addressing
types vary for different meeting actions. Clearly,
the percentage of the utterances addressed to the
whole group during a presentation is expected to
be much higher than during a discussion.
4 Data collection
To train and test our classifiers, we used a small
multimodal corpus developed for studying ad-
dressing behavior in meetings (Jovanovic et al,
2005). The corpus contains 12 meetings recorded
at the IDIAP smart meeting room in the research
program of the M41 and AMI projects2. The
room has been equipped with fully synchronized
multi-channel audio and video recording devices,
a whiteboard and a projector screen. The seating
arrangement includes two participants at each of
two opposite sides of the rectangular table. The
total amount of the recorded data is approximately
75 minutes. For experiments presented in this pa-
per, we have selected meetings from the M4 data
collection. These meetings are scripted in terms of
type and schedule of group actions, but content is
natural and unconstrained.
The meetings are manually annotated with dia-
logue acts, addressees, adjacency pairs and gaze
1http://www.m4project.org
2http://www.amiproject.org
direction. Each type of annotation is described
in detail in (Jovanovic et al, 2005). Additionally,
the available annotations of meeting actions for the
M4 meetings3 were converted into the corpus for-
mat and included in the collection.
The dialogue act tag set employed for the cor-
pus creation is based on the MRDA (Meeting
Recorder Dialogue Act) tag set (Dhillon et al,
2004). The MRDA tag set represents a modifi-
cation of the SWDB-DAMSL tag set (Jurafsky et
al., 1997) for an application to multi-party meet-
ing dialogues. The tag set used for the corpus cre-
ation is made by grouping the MRDA tags into 17
categories that are divided into seven groups: ac-
knowledgments/backchannels, statements, ques-
tions, responses, action motivators, checks and po-
liteness mechanisms. A mapping between this tag
set and the MRDA tag set is given in (Jovanovic
et al, 2005). Unlike MRDA where each utterance
is marked with a label made up of one or more
tags from the set, each utterance in the corpus is
marked as Unlabeled or with exactly one tag
from the set. Adjacency pairs are labeled by mark-
ing dialogue acts that occur as their a-part and b-
part.
Since all meetings in the corpus consist of four
participants, the addressee of a dialogue act is la-
beled as Unknown or with one of the following
addressee tags: individual Px, a subgroup of par-
ticipants Px,Py or the whole audience Px,Py,Pz.
Labeling gaze direction denotes labeling gazed
targets for each meeting participants. As the only
targets of interest for addressee identification are
meeting participants, the meetings were annotated
with the tag set that contains tags that are linked to
each participant Px and the NoTarget tag that is
used when the speaker does not look at any of the
participants.
Meetings are annotated with a set of six meet-
ing actions described in (McCowan et al, 2003):
monologue, presentation, white-board, discussion,
consensus, disagreement and note-taking.
Reliability of the annotation schema As re-
ported in (Jovanovic et al, 2005), gaze annota-
tion has been reproduced reliably (segmentation
80.40% (N=939); classification ? = 0.95). Table
1 shows reliability of dialogue act segmentation
as well as Kappa values for dialogue act and ad-
dressee classification for two different annotation
3http://mmm.idiap.ch/
172
groups that annotated two different sets of meeting
data.
Group Seg(%) N DA(?) ADD(?)
B&E 91.73 377 0.77 0.81
M&R 86.14 367 0.70 0.70
Table 1: Inter-annotator agreement on DA and ad-
dressee annotation: N- number of agreed segments
5 Addressee classification
In this section we present the results on addressee
classification in four-persons face-to-face meet-
ings using Bayesian Network and Naive Bayes
classifiers.
5.1 Classification task
In a dialogue situation, which is an event which
lasts as long as the dialogue act performed by the
speaker in that situation, the class variable is the
addressee of the dialogue act (ADD). Since there
are only a few instances of subgroup addressing in
the data, we removed them from the data set and
excluded all possible subgroups of meeting par-
ticipants from the set of class values. Therefore,
we define addressee classifiers to identify one of
the following class values: individual Px where
x ? {0,1,2,3} and ALLPwhich denotes the whole
group.
5.2 Feature set
To identify the addressee of a dialogue act we
initially used three sorts of features: conversa-
tional context features (later referred to as contex-
tual features), utterance features and gaze features.
Additionally, we conducted experiments with an
extended feature set including a feature that con-
veys information about meeting context.
Contextual features provide information about
the preceding utterances. We experimented with
using information about the speaker, the addressee
and the dialogue act of the immediately preceding
utterance on the same or a different channel (SP-
1, ADD-1, DA-1) as well as information about
the related utterance (SP-R, ADD-R, DA-R). A re-
lated utterance is the utterance that is the a-part of
an adjacency pair with the current utterance as the
b-part. Information about the speaker of the cur-
rent utterance (SP) has also been included in the
contextual feature set.
As utterance features, we used a subset of lex-
ical features presented in (Jovanovic and op den
Akker, 2004) as useful cues for determining
whether the utterance is single or group addressed.
The subset includes the following features:
? does the utterance contain personal pronouns ?we? or
?you?, both of them, or neither of them?
? does the utterance contain possessive pronouns or pos-
sessive adjectives (?your/yours? or ?our/ours?), their
combination or neither of them?
? does the utterance contain indefinite pronouns such as
?somebody?, ?someone?, ?anybody?, ?anyone?, ?ev-
erybody? or ?everyone??
? does the utterance contain the name of participant Px?
Utterance features also include information about
the utterance?s conversational function (DA tag)
and information about utterance duration i.e.
whether the utterance is short or long. In our ex-
periments, an utterance is considered as a short ut-
terance, if its duration is less than or equal to 1
sec.
We experimented with a variety of gaze fea-
tures. In the first experiment, for each participant
Px we defined a set of features in the form Px-
looks-Py and Px-looks-NT where x,y ? {0,1,2,3}
and x 6= y; Px-looks-NT represents that partici-
pant Px does not look at any of the participants.
The value set represents the number of times that
speaker Px looks at Py or looks away during the
time span of the utterance: zero for 0, one for 1,
two for 2 and more for 3 or more times. In the
second experiment, we defined a feature set that
incorporates only information about gaze direction
of the current speaker (SP-looks-Px and SP-looks-
NT) with the same value set as in the first experi-
ment.
As to meeting context, we experimented with
different values of the feature that represents the
meeting actions (MA-TYPE). First, we used a full
set of speech based meeting actions that was ap-
plied for the manual annotation of the meetings in
the corpus: monologue, discussion, presentation,
white-board, consensus and disagreement. As the
results on modeling group actions in meetings pre-
sented in (McCowan et al, 2003) indicate that
consensus and disagreements were mostly mis-
classified as discussion, we have also conducted
experiments with a set of four values for MA-
TYPE, where consensus, disagreement and dis-
cussion meeting actions were grouped in one cat-
egory marked as discussion.
173
5.3 Results and Discussions
To train and test the addressee classifiers, we used
the hand-annotated M4 data from the corpus. Af-
ter we had discarded the instances labeled with
Unknown or subgroup addressee tags, there were
781 instances left available for the experiments.
The distribution of the class values in the selected
data is presented in Table 2.
ALLP P0 P1 P2 P3
40.20% 13.83% 17.03% 15.88% 13.06%
Table 2: Distribution of addressee values
For learning the Bayesian Network structure,
we applied the K2 algorithm (Cooper and Her-
skovits, 1992). The algorithm requires an ordering
on the observable features; different ordering leads
to different network structures. We conducted ex-
periments with several orderings regarding feature
types as well as with different orderings regarding
features of the same type. The obtained classifi-
cation results for different orderings were nearly
identical. For learning conditional probability dis-
tributions, we used the algorithm implemented in
theWEKA toolbox4 that produces direct estimates
of the conditional probabilities.
5.3.1 Initial experiments without meeting
context
The performances of the classifiers are mea-
sured using different feature sets. First, we mea-
sured the performances of classifiers using utter-
ance features, gaze features and contextual fea-
tures separately. Then, we conducted experiments
with all possible combinations of different types of
features. For each classifier, we performed 10-fold
cross-validation. Table 3 summarizes the accura-
cies of the classifiers (with 95% confidence inter-
val) for different feature sets (1) using gaze infor-
mation of all meeting participants and (2) using
only information about speaker gaze direction.
The results show that the Bayesian Network
classifier outperforms the Naive Bayes classifier
for all feature sets, although the difference is sig-
nificant only for the feature sets that include con-
textual features.
For the feature set that contains only informa-
tion about gaze behavior combined with infor-
mation about the speaker (Gaze+SP), both clas-
sifiers perform significantly better when exploit-
ing gaze information of all meeting participants.
4http://www.cs.waikato.ac.nz/ ml/weka/
In other words, when using solely focus of visual
attention to identify the addressee of a dialogue
act, listeners? focus of attention provides valuable
information for addressee prediction. The same
conclusion can be drawn when adding informa-
tion about utterance duration to the gaze feature
set (Gaze+SP+Short), although for the Bayesian
Network classifier the difference is not significant.
For all other feature sets, the classifiers do not per-
form significantly different when including or ex-
cluding the listeners gaze information. Even more,
both classifiers perform better using only speaker
gaze information in all cases except when com-
bined utterance and gaze features are exploited
(Utterance+Gaze+SP).
The Bayesian network and Naive Bayes clas-
sifiers show the same changes in the perfor-
mances over different feature sets. The re-
sults indicate that the selected utterance fea-
tures are less informative for addressee predic-
tion (BN:52.62%, NB:52.50%) compared to con-
textual features (BN:73.11%; NB:68.12%) or fea-
tures of gaze behavior (BN:66.45%, NB:64.53%).
The results also show that adding the informa-
tion about the utterance duration to the gaze fea-
tures, slightly increases the accuracies of the clas-
sifiers (BN:67.73%, NB:65.94%), which confirms
findings presented in (Bakx et al, 2003). Com-
bining the information from the gaze and speech
channels significantly improves the performances
of the classifiers (BN:70.68%; NB:69.78%) in
comparison to performances obtained from each
channel separately. Furthermore, higher accura-
cies are gained when adding contextual features to
the utterance features (BN:76.82%; NB:72.21%)
and even more to the features of gaze behavior
(BN:80.03%, NB:77.59%). As it is expected, the
best performances are achieved by combining all
three types of features (BN:82.59%, NB:78.49%),
although not significantly better compared to com-
bined contextual and gaze features.
We also explored how well the addressee can be
predicted excluding information about the related
utterance (i.e. AP information). The best perfor-
mances are achieved combining speaker gaze in-
formation with contextual and utterance features
(BN:79.39%; NB:76.06%). A small decrease in
the classification accuracies when excluding AP
information (about 3%) indicates that remaining
contextual, utterance and gaze features capture
most of the useful information provided by AP.
174
Baysian Networks Naive Bayes
Feature sets Gaze All Gaze SP Gaze All Gaze SP
All Features 81.05% (?2.75) 82.59% (?2.66) 78.10% (?2.90) 78.49% (?2.88)
Context 73.11% (?3.11) 68.12% (?3.27)
Utterance+SP 52.62% (?3.50) 52.50% (?3.50)
Gaze+SP 66.45% (?3.31) 62.36% (?3.40) 64.53% (?3.36) 59.02% (?3.45)
Gaze+SP+Short 67.73% (?3.28) 66.45% (?3.31) 65.94% (?3.32) 61.46% (?3.41)
Context+Utterance 76.82% (?2.96) 72.21% (?3.14)
Context+Gaze 79.00% (?2.86) 80.03% (?2.80) 74.90% (?3.04) 77.59% (?2.92)
Utterance+Gaze+SP 70.68% (?3.19) 70.04% (?3.21) 69.78% (?3.22) 68.63% (?3.25)
Table 3: Classification results for Bayesian Network and Naive Bayes classifiers using gaze information
of all meeting participants (Gaze All) and using speaker gaze information (Gaze SP)
Error analysis Further analysis of confusion
matrixes for the best performed BN and NB clas-
sifiers, show that most misclassifications were be-
tween addressing types (individual vs. group):
each Px was more confused with ALLP than with
Py. A similar type of confusion is observed be-
tween human annotators regarding addressee an-
notation (Jovanovic et al, 2005). Out of all mis-
classified cases for each classifier, individual types
of addressing (Px) were, in average, misclassified
with addressing the group (ALLP) in 73% cases
for NB, and 68% cases for BN.
5.3.2 Experiments with meeting context
We examined whether meeting context informa-
tion can aid the classifiers? performances. First,
we conducted experiments using the six values
set for the MA-TYPE feature. Then, we exper-
imented with employing the reduced set of four
types of meeting actions (see Section 5.2). The
accuracies obtained by combining the MA-TYPE
feature with contextual, utterance and gaze fea-
tures are presented in Table 4.
Bayesian Networks Naive Bayes
Features Gaze All Gaze SP Gaze All Gaze SP
MA-6+All 81.82% 82.84% 78.74% 79.90%
MA-4+All 81.69% 83.74% 78.23% 79.13%
Table 4: Classification results combining MA-
TYPE with the initial feature set
The results indicate that adding meeting con-
text information to the initial feature set improves
slightly, but not significantly, the classifiers? per-
formances. The highest accuracy (83.74%) is
achieved using the Bayesian Network classifier by
combining the four-values MA-TYPE feature with
contextual, utterance and the speaker?s gaze fea-
tures.
6 Conclusion and Future work
We presented results on addressee classification
in four-participants face-to-face meetings using
Bayesian Network and Naive Bayes classifiers.
The experiments presented should be seen as pre-
liminary explorations of appropriate features and
models for addressee identification in meetings.
We investigated how well the addressee of a di-
alogue act can be predicted (1) using utterance,
gaze and conversational context features alone as
well as (2) using various combinations of these
features. Regarding gaze features, classifiers? per-
formances are measured using gaze directional
cues of the speaker only as well as of all meeting
participants. We found that contextual informa-
tion aids classifiers? performances over gaze in-
formation as well as over utterance information.
Furthermore, the results indicate that selected ut-
terance features are the most unreliable cues for
addressee prediction. The listeners? gaze direc-
tion provides useful information only in the situa-
tion where gaze features are used alone. Combina-
tions of features from various resources increases
classifiers? performances in comparison to perfor-
mances obtained from each resource separately.
However, the highest accuracies for both classi-
fiers are reached by combining contextual and ut-
terance features with speaker?s gaze (BN:82.59%,
NB:78.49%). We have also explored the ef-
fect of meeting context on the classification task.
Surprisingly, addressee classifiers showed little
gain from the information about meeting actions
(BN:83.74%, NB:79.90%). For all feature sets,
the Bayesian Network classifier outperforms the
Naive Bayes classifier.
In contrast to Vertegaal (1998) and Otsuka et
al. (2005) findings, where it is shown that gaze
can be a good predictor for addressee in four-
participants face-to-face conversations, our results
175
show that in four-participants face-to-face meet-
ings, gaze is less effective as an addressee indi-
cator. This can be due to several reasons. First,
they used different seating arrangements which is
implicated in the organization of gaze. Second,
our meeting environment contains attentional ?dis-
tracters? such as whiteboard, projector screen and
notes. Finally, during a meeting, in contrast to an
ordinary conversation, participants perform vari-
ous meeting actions which may influence gaze as
an aspect of addressing behavior.
We will continue our work on addressee identi-
fication on the large AMI data collection that is
currently in production. The AMI corpus con-
tains more natural, scenario-based, meetings that
involve groups focused on the design of a TV re-
mote control. Some initial experiments on the
AMI pilot data show that additional challenges for
addressee identification on the AMI data are: roles
that participants play in the meetings (e.g. project
manager or marketing expert) and additional at-
tentional ?distracters? present in the meeting room
such as, the task object at first place and laptops.
This means that a richer feature set should be ex-
plored to improve classifiers? performances on the
AMI data including, for example, the background
knowledge about participants? roles. We will also
focus on the development of new models that bet-
ter handle conditional and contextual dependen-
cies among different types of features.
Acknowledgments
This work was partly supported by the European
Union 6th FWP IST Integrated Project AMI (Aug-
mented Multi-party Interaction, FP6-506811, pub-
lication AMI-153).
References
M. Argyle. 1969. Social Interaction. London: Tavis-
tock Press.
I. Bakx, K. van Turnhout, and J. Terken. 2003. Facial
orientation during multi-party interaction with infor-
mation kiosks. In Proc. of INTERACT.
H. H. Clark and B. T. Carlson. 1982. Hearers and
speech acts. Language, 58:332?373.
G. Cooper and E. Herskovits. 1992. Bayesian method
for the induction of probabilistic networks from
data. Machine Learning, 9:309?347.
R. Dhillon, S. Bhagat, H. Carvey, and E. Shriberg.
2004. Meeting recorder project: Dialogue act label-
ing guide. Technical report, ICSI, Berkeley, USA.
M. Galley, K. McKeown, J. Hirschberg, and
E. Shriberg. 2004. Identifying agreement and
disagreement in conversational speech: Use of
bayesian networks to model pragmatic dependen-
cies. In Proc. of 42nd Meeting of the ACL.
E. Goffman. 1976. Replies and responses. Language
in Society, 5:257?313.
E. Goffman. 1981a. Footing. In Forms of Talk, pages
124?159. University of Pennsylvania Press.
E. Goffman. 1981b. Forms of Talk. University of
Pennsylvania Press, Philadelphia.
C. Goodwin. 1981. Conversational Organiza-
tion: Interaction Between Speakers and Hearers.
NY:Academic Press.
N. Jovanovic and R. op den Akker. 2004. Towards
automatic addressee identification in multi-party di-
alogues. In Proc of the 5th SIGDial.
N. Jovanovic, R. op den Akker, and A. Nijholt. 2005.
A corpus for studying addressing behavior in face-
to-face meetings. In Proc. of the 6th SIGDial.
D. Jurafsky, L. Shriberg, and D. Biasca. 1997. Switch-
board swbd-damsl shallow-discourse-function an-
notation coders manual, draft 13. Technical report,
University of Colorado, Institute of Cognitive Sci-
ence.
M. Katzenmaier, R. Stiefelhagen, and T. Schultz. 2004.
Identifying the addressee in human-human-robot in-
teractions based on head pose and speech. In Proc.
of ICMI.
A. Kendon. 1967. Some functions of gaze direction in
social interaction. Acta Psychologica, 32:1?25.
I. McCowan, S. Bengio, D. Gatica-Perez, G. Lathoud,
F. Monay, D. Moore, P. Wellner, and H. Bourlard.
2003. Modeling human interactions in meetings. In
Proc. IEEE ICASSP.
K. Otsuka, Y. Takemae, J. Yamato, and H. Murase.
2005. A probabilistic inference of multiparty-
conversation structure based on markov-switching
models of gaze patterns, head directions, and utter-
ances. In Proc. of ICMI.
H. Sacks, E. A. Schegloff, and G. Jefferson. 1974.
A simplest systematics for the organization of turn-
taking for conversation. Language, 50:696?735.
D. Traum. 2004. Issues in multi-party dialogues. In
F. Dignum, editor, Advances in Agent Communica-
tion, pages 201?211. Springer-Verlag.
K. van Turnhout, J. Terken, I. Bakx, and B. Eggen.
2005. Identifying the intended addressee in
mixed human-human and human-computer interac-
tion from non-verbal features. In Proc. of ICMI.
R. Vertegaal. 1998. Look who is talking to whom.
Ph.D. thesis, University of Twente, September.
176
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 21?28,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
Are You Being Addressed? - real-time addressee detection to support
remote participants in hybrid meetings
Harm op den Akker
Roessingh Research and Development
Enschede
the Netherlands
h.opdenakker@rrd.nl
Rieks op den Akker
Human Media Interaction Twente
Enschede
the Netherlands
infrieks@cs.utwente.nl
Abstract
In this paper, we describe the development
of a meeting assistant agent that helps
remote meeting participants by notifying
them when they are being addressed. We
present experiments that have been con-
ducted to develop machine classifiers to
decide whether ?you are being addressed?
where ?you? refers to a fixed (remote) par-
ticipant in a meeting. The experimental re-
sults back up the choices made regarding
the selection of data, features, and classifi-
cation methods. We discuss variations of
the addressee classification problem that
have been considered in the literature and
how suitable they are for addressee detec-
tion in a system that plays a role in a live
meeting.
1 Introduction
In order to understand what is going on in a meet-
ing, it is important to know who is talking, what
is being said, and who is being addressed (talked
to). Here, we focus on the question of whom the
speech is addressed to. We present results ob-
tained in developing a classifier for real-time ad-
dressee prediction to be used in an assistant for a
remote participant in a hybrid meeting, a meeting
where a number of participants share a common
meeting room and one or more others take part via
teleconferencing software.
It is obvious that in order to effectively par-
ticipate in a meeting, participants need to know
who is being addressed at all times. For remote
participants in hybrid meetings, understanding the
course of the conversation can be difficult due to
the fact that it is hard to figure out who is being
addressed. But it is not only meeting participants
who are interested in addressees. The question
who is being addressed has long been of interest
for science: group therapists (Bales, 1950), small
group research, or outside observers who analyse
recorded meetings.
How speakers address listeners, what kind of
procedures speakers use to designate their audi-
ence and to make clear whom they address has
been the focus of conversational analysis, socio-
linguistics and ethnomethodology for quite some
time. An analysis of addressee selection is pre-
sented in (Lerner, 1996). Addressing as a special
type of multi-modal interactional referring expres-
sion generation behavior is considered in (op den
Akker and Theune, 2008).
The problem of automatic addressee detection
is one of the problems that come up when technol-
ogy makes the move from two-party man-machine
natural dialogue systems to systems for multi-
party conversations. In this context the addressing
problem was raised by Traum (2004).
Since Jovanovic? (2004), presented her research
on addressee prediction in meetings at SigDial,
quite a few publications on the topic appeared. Jo-
vanovic? used a number of multi-modal meeting
corpora developed in the European projects M4
and AMI. In (Jovanovic? et al, 2006b) the first
multi-modal multi-party corpus containing hand
labeled addressee annotations was presented. The
public release of the multi-modal AMI meeting
corpus (Carletta, 2007; McCowan et al, 2005), a
100 hour annotated corpus of small group meet-
ings has already shown to be an important achieve-
ment for research; not only for conversational
speech recognition and tracking of visual elements
21
but also for automatic multi-modal conversational
scene analysis. The M4 and AMI corpora are the
only multi-modal meeting corpora (partly) anno-
tated with addressee labels. Addressee detection
in robot-human interaction is studied in (Katzen-
maier et al, 2004) and in multi-party dialogue
systems in (Knott and Vlugter, 2008; van Turn-
hout et al, 2005; Bakx et al, 2003; Rickel et al,
2002). Addressing in face-to-face conversations is
achieved by multi-modal behavior and addressee
detection is thus a multi-modal recognition task.
This task requires not only speech recognition but
also gaze and gesture recognition, the recognition
of deictic references, and, ideally, the understand-
ing of the ?what?s going on? in the meeting. It
requires the detection of who is involved in cur-
rent (parallel) activities. Speakers show explicit
addressing behavior when they are not confident
that the participants they want to address are pay-
ing attention to their words. Analysis of the re-
mote meetings recorded in the EC project AMIDA
reinforces our experiences that this happens more
in remote meetings than in small group face-to-
face meetings.
In AMIDA, the European follow-up project of
AMI, the two new research goals are: (1) real-time
processing (real-time speech recognition (Hain
et al, 2008), focus of attention recognition (Ba
and Odobez, 2009), real-time dialogue act label-
ing (Germesin et al, 2008) and addressee detec-
tion); and (2) technology for (remote) meeting
support. Technology based on the analysis of
how people behave and converse in meetings is
now going to re-shape the meetings, and hopefully
make them more effective and more engaging. So-
cial interaction graphs that show who is talking to
whom and how frequently in a meeting may help
the group by mirroring its interpersonal relations,
dominance, and group dynamics, and understand
social mechanisms as possible causes of ineffec-
tiveness. Although, feedback about the social in-
teractions may also be useful during meetings, it
doesn?t require the prediction of the speaker?s ad-
dressees in real-time. A participant in a meeting,
however, needs to know who is being addressed by
the speaker at ?the time of speaking?. This holds
for humans as well as for an artificial partner, a
robot or a virtual Embodied Conversational Agent
in a multi-party conversation.
The problem of addressee prediction comes in
different flavors, depending on the relations that
the subject who is in need of an answer, has with
the event itself. Time is one of the aspects that play
a role here: whether the subject needs to know
the addressee of an utterance in real-time or off-
line. But it is not only time that plays a role. The
addressing problem is an interactional problem,
meaning that it is determined by the role that the
subject has in the interaction itself; if and how the
speaker and others communicate with each other
and with the subject. Is he himself a possible
addressee of the speaker or is he an outside ob-
server? What type of communication channels
are available to the subject and which channels of
communication are available to the conversational
partners in the meeting? It is often harder to fol-
low a face-to-face discussion on the radio than to
follow a radio broadcasted multi-party discussion
that was held via a point-to-point telephone con-
nection.
What speakers do to make clear whom they are
addressing depends on the status and capacities of
the communication lines with their interlocutors.
Discussion leaders in TV shows are aware of their
TV audience. Every now and then, they explicitly
address their virtual audience at home. They also
design their questions so as to make clear to the
TV viewer whom their questions are addressed to.
Outside observers in the form of a video camera
will, however, not affect the way speakers make
clear whom they address as long as the camera
is not considered as a participant interested in the
speaker?s intention. Because remote participants
are often out of sight, speakers in the meeting
room do not take them into account when they
converse to others in the meeting room. Remote
participants become a kind of outside observers
and share the same problems that annotators have
when they watch video recordings of meetings to
see what is happening in the meeting and who is
being addressed by the speaker.
In section 2 we will specify the particular type
of addressing problem that we are trying to tackle
here. We make clear how our problem and ap-
proach differ from those of other researchers and
what this means for the applicability of previous
results and available data. In section 3 we present
the data we used for testing and training. We set
a baseline for the performance of our classifiers as
22
well as a hypothesized maximum value, or ceiling,
based on the complexity of the task at hand. In
section 4 we discuss the experiments, for selecting
the optimal features, classifiers, and parameters.
In section 5 we present the experimental results.
In section 6 we discuss how the currently imple-
mented addressing module works in the meeting
assistant and what is required to use all the features
of the addressee predictor in a hybrid meeting.
2 The Addressing Problem Considered
Here
Jovanovic? et al (2004) and Jovanovic? et al
(2006a) describe the classifiers that have been
trained and tested on the M4 and AMI corpora.
The classification problem is to assign an ad-
dressee label to a dialogue act, a hand-labeled and
hand-segmented sequence of words, which is ob-
tained by manual transcription of a speaker?s utter-
ance. The output of the classifier is one of a set of
possible addressee labels: Group, or P0,P1,P2,P3,
which are the four fixed positions around the ta-
ble of the four participants in the meeting. Since
the AMI data contains several meetings of differ-
ent groups of four people, the class value cannot be
the name of a participant, as that is not an invari-
ant of the meeting setting. Positions at the rect-
angular table are invariant. This implies that the
classifiers can only be used for meetings with this
setting and four participants. A comparison of the
statistical classifier of Jovanovic? with a rule-based
method using the same part of the AMI corpus is
presented in (op den Akker and Traum, 2009). The
same data is also used by Gupta et al (2007) in
their study of a related problem: finding the person
the speaker refers to when he uses a second person
pronoun (e.g. ?you? or ?your?) as a deictic referring
expression. Their class values are not positions at
the table but ?virtual positions? in the speaking or-
der (e.g. next speaker, previous speaker), a solu-
tion that generalises to a broader class of conversa-
tions than four participants in a face-to-face meet-
ing. In a more recent study, Frampton et al (2009)
use positions at the table relative to the position
of the speaker as class values: L1, L2, L3. The
reason for this is to alleviate the problem of class
imbalance in the corpus.
We will also use the AMI corpus but we will
look at a different variant of the addressing prob-
lem. This is motivated by our application: to sup-
port a remote participant in a hybrid meeting. The
question that we will try to answer is ?are you
being addressed??, where ?you? refers to an in-
dividual participant in a conversation. The possi-
ble answers we consider are ?yes? or ?no?1. The
addressing classifier that solves this problem is
thus dedicated to a personal buddy. Note that this
makes the method useable for any type of conver-
sational setting. Note also that the addressing pre-
diction problem ?are you being addressed?? for
a meeting assistant who is not himself participat-
ing in the meeting is different from the problem
?am I being addressed?? that a participant himself
may have to solve. The meeting assistant does not
have direct ?internal? knowledge about the pro-
cesses or attentiveness of his buddy participant; he
has to rely on outside observations. Our view on
the problem implies that we have to take another
look at the AMI data and that we will analyse and
use it in a different way for training, testing and
performance measuring. It also implies that we
cannot rely for our binary classification problem
on the results of Jovanovic? (2007) with (dynamic)
Bayesian networks.
3 The Data and How Complex Our Task
Is
We use a subset of the AMI corpus, containing
those fourteen meetings that have not only been
annotated with dialogue acts, but where dialogue
acts are also attributed an addressee label, telling
if the speaker addresses the Group, or the person
sitting at position P0,P1,P2 or P32. They have also
been annotated with visual focus of attention: at
any time it is known for each partner where he is
looking and during what time frame. Annotated
gaze targets are persons in the meeting, white-
board, laptop, table or some other object.
Another level of annotations that we use con-
cerns the topic being discussed during a topic seg-
ment of the meeting. Participants in the AMI cor-
pus play a role following a scenario, the group has
to design a remote TV control and team members
each have one of four roles in the design project:
PM - project manager; UI - user interface de-
signer; ID - industrial designer; or ME - market-
ing expert. For details on the meeting scenario see
1A ?yes? means that the dialogue act is addressed to ?you?
only. Group-addressed dialogue acts are considered to be
?no? (not addressed to you only).
2Annotators could also use label Unknown in case they
could not decide the addressee of the speaker, this is treated
as Group-addressed or ?no?.
23
(Post et al, 2004). In training and testing the clas-
sifiers we alternately take up the position in the
meeting of one of the participants, who is treated
as the target for addressee prediction.
3.1 Base-line and Ceiling-value
Because most of the dialogue acts are not specif-
ically addressed to one and the same meeting
participant, the baseline for the binary classifica-
tion task is already quite high: 89.20%, being
the percentage of all dialogue acts annotated with
addressing information ?not addressed to You?,
which is 5962 out of a total of 6648 dialogue acts.
The performance of a supervised machine
learning method depends on (1) the selection of
features (2) the type of classifier including the
settings of the hyper-parameters of the classi-
fiers (Daelemans et al, 2003), and (3) the quality
and the amount of training data (Reidsma, 2008;
Reidsma and Carletta, 2008). Since we measure
the classifier?s performance with a part of the an-
notated data it is interesting to see how human an-
notators (or, ?human classifiers?) perform on this
task.
One of the AMI meetings3 has been annotated
with addressing information by four different an-
notators. We will use this to measure how am-
biguous the task of addressee labeling is. Table
1 shows the confusion matrix for two annotators:
s95 and vka. This shows the (dis-)agreements for
labelling the 412 dialogue acts as addressed to A,
B, C, D or to the Group. 4 However, because we
use our data differently, we will look at the con-
fusion matrices in a different way. We split it up
into 4 matrices, each from the view of one of the
four meeting participants. Table 2 is an example of
this, taking the view of participant A (i.e. for the
binary decision task ?is Participant A being ad-
dressed??, and having annotator s95 as gold stan-
dard.
Table 2 shows that when taking annotator s95
as gold standard, and considering annotator vka
as the classifier, he achieves an accuracy of 92.23
(380 out of 412 instances classified correctly).
3IS1003d
4Note that the annotators first independently segmented
the speaker?s turns into dialogue act segments; then labeled
them with a dialogue act type label and then labeled the dia-
logue acts with an addressee label. The 412 dialogues acts are
those segments that both annotators identified as a dialogue
act segment.
A B C D Group Total
A 29 10 39
B 14 8 22
C 32 7 39
D 1 1 49 18 69
Group 21 10 19 22 171 243
Total 51 24 52 71 214 412
Table 1: Confusion matrix for one pair of annota-
tors ( = 0.55).
A ?A Total
A 29 10 39
?A 22 351 373
Total 51 361 412
Table 2: Confusion matrix for one pair of anno-
tators, considering addressed to A or not (derived
from the matrix in Table 1).
We can argue that we can use these human an-
notators/classifiers scores as a measure of ?max-
imum performance?, because it indicates a level
of task ambiguity. Classifiers can achieve higher
scores, because they can learn through noise in the
data. Thus, the inter-annotator confusion value is
not an absolute limit of actual performance, but
cases in which the classifier is ?right? and the test-
set ?wrong? would not be reflected in the results.
Since the inter-annotator confusion does also say
something about the inherent task ambiguity, it
can be used as a measure to compare a classifier
score with. Table 3 contains the overall scores
(taken over all 4 individual participants) for the
6 annotator pairs. The average values for Recall,
Precision, F-Measure and Accuracy in Table 3 are
considered as ceiling values for the performance
measures for this binary classification task5. The
Hypothesized Maximum Score (HMS) is the aver-
age accuracy value: 92.47.
Pair Rec Prec F Acc
s-v 73.37 62.63 67.58 92.78
m-s 59.75 70.59 64.72 91.87
m-v 69.92 74.78 72.27 93.11
m-d 37.77 81.61 51.64 91.79
v-d 42.04 80.49 55.23 92.22
s-d 43.68 77.55 55.88 93.02
Average: 54.42 74.61 61.22 92.47
Table 3: Recall, Precision, F-measure and Accu-
racy values for the 6 pairs of annotators.
5Inter-changing the roles of the two annotators, i.e. con-
sider vka as ?gold standard? in Table 2, means inter-changing
the Recall and Precision values. The F-value remains the
same, though.
24
The baseline (89.20 for all dialogue acts anno-
tated with addressing) and the HMS (92.47) accu-
racy values will be used for comparison with the
performance of our classifiers.
4 The Methods and Their Features
In the experiments, four different classifiers were
created:
1. Lexical and Context Classifier
2. Visual Focus of Attention Classifier
3. Combined Classifier
4. Topic and Role Extended Classifier
For each of these classifiers a large number of
experiments were performed with a varying num-
ber of 15 to 30 different machine learning meth-
ods -using Weka (Witten and Frank, 1999)- to se-
lect optimal feature sets. In this section we sum-
marize the most important findings. For a more
detailed analysis refer to (op den Akker, 2009).
Because of the large number of features and clas-
sifiers used, the various classifier hyper parame-
ters have largely been kept to their default val-
ues. Where it was deemed critical (Neural Net-
work training epochs and number of trees in Ran-
domForest classifier) these parameters were varied
afterwards to make sure that the performance did
not deviate too much from using the default val-
ues. It didn?t.
4.1 Lexical and Context Classifier
The lexical and context based classifier uses fea-
tures that can be derived from words and dialogue
acts only. A total of 14 features were defined,
7 of which say something about the dialogue act
(type, number of words, contains 1st person sin-
gular personal pronoun, and so on) and 7 of which
say something about the context of the dialogue
act (how often was I addressed in the previous 6 di-
alogue acts, how often did I speak in the previous
5 dialogue acts, and so on). Of these 14 features,
the optimal feature subset was selected by trying
out all the subsets. This was repeated using 15
different classifiers from the WEKA toolkit. The
best result was achieved with a subset of 10 fea-
tures, by the MultiLayerPerceptron classifier. In
this way an accuracy of 90.93 was reached. Given
the baseline of the used train and test set of 89.20
and the HMS of 92.47, this can be seen as 53% of
what ?can? be achieved.
4.2 Visual Focus of Attention Classifier
The VFOA classifier uses features derived from a
meeting participant?s visual focus of attention. A
total of 8 features were defined, such as: the total
time that the speaker looks at me, the total time
everyone is looking at me, and so on. The optimal
time interval in which to measure who is looking
at you was extensively researched by trying out
different intervals around the start of a dialogue
act, and training and testing a classifier on the fea-
ture. These optimal interval values differ for every
feature, but is usually somewhere between a few
seconds before the start of the dialogue act, to 1
second into the dialogue act. The difference in per-
formance for using the optimal interval compared
to using the start- and end times of the dialogue
act is sometimes as much as 0.93 accuracy (which
is a lot given a base score of 89.20 and HMS of
92.47). This shows, that when looking at VFOA
information, one should take into account the par-
ticipant?s gaze before the dialogue act, instead of
looking at the utterance duration as in (Jovanovic?,
2007; Frampton et al, 2009)6. The representation
of feature values was also varied by either nor-
malizing to the duration of the window or using
the raw values. Again the optimal feature subset
was calculated using brute-force. Because of the
reduced time complexity for 28 possible feature
subsets, 30 different classifiers from the WEKA
toolkit were trained and tested. One of the best re-
sults was achieved with a feature set of 4 features
again with the MultiLayerPerceptron: 90.80 accu-
racy. The train and test sets used for this classifier
are slightly smaller than those used for the Lex-
Cont classifier because not all dialogue acts are
annotated with VFOA. The base score for the data
here is 89.24, and given the HMS of 92.47, this re-
sult can be seen as 48% of what can be achieved.
4.3 Combined Classifier
The third classifier is a combination of the first
two. We tried three different methods of combin-
ing the results of the LexCont and VFOA classi-
fiers. First we tried to train a classifier using all
the features (14 lexical, 8 vfoa) which exploded
the feature subset search space to over 4 million
possibilities. A second approach was to combine
the output of the LexCont and VFOA classifiers
using a simple rule-based approach. The OR-rule
6Note that a dialogue act segment can be preceded by an
other utterance unit of the same speaker.
25
(if either of the two classifiers thinks the DA is ad-
dressed to you, the outcome is ?yes?) performed
the best (91.19% accuracy). But the best results
were achieved by training a rule based (Ridor)
classifier on the output of the first two. For these
experiments the test-set of the previous two clas-
sifiers was split again into a new train (3080 in-
stances) and test set (1540 instances). The features
are the outputs of the VFOA and LexCont classi-
fiers (both class and class-probabilities). For this
task, 35 classifiers have been trained with the best
results coming from the Ridor classifier: 92.53 ac-
curacy. The results of all the different techniques
for combining the classifiers can be seen in Table
4. The baseline score for this smaller test set is
89.87, so given the HMS of 92.47, this result can
be seen as 102% of what can be achieved. Note
that this is not ?impossible?, because the Hypoth-
esized Maximum Score is merely an indication of
how humans perform on the task, not an absolute
ceiling.
4.4 Topic and Role Extended Classifier
As a final attempt to improve the results we used
topic and role information as features to our com-
bined classifier. In the AMI corpus, every meet-
ing participant has a certain role (project manager,
interface designer, etc. . . ) and the meetings were
segmented into broad topic (opening, discussion,
industrial designer presentation). Now the idea is
that participants with certain roles are more likely
to be addressed during certain topics. As an illus-
tration of how much these a-priori chances of be-
ing addressed can change, take the example of an
industrial designer during an ?industrial designer
presentation?. The a-priori probability of you be-
ing addressed as industrial designer in the entire
corpus is 13%. This probability, given also the
fact that the current topic is ?industrial designer
presentation? becomes 46%. This is a huge differ-
ence, and this information can be exploited. For all
combinations of topic and role, the a-priori prob-
ability of you being addressed as having that role
and during that topic, have been calculated. These
values have been added as features to the features
used in the Combined Classifier, and the experi-
ments have been repeated. This time, the best per-
forming classifier is Logistic Model Trees with an
accuracy of 92.99%. Given the baseline of 89.87
and HMS of 92.47, this can be seen as 120% of
what ?can? be achieved, which is better by a fairly
large margin than the results of the inter-annotator
agreement values.
5 Summary of Results
Table 4 summarizes the results for the various
classifiers. The LexCont and VFOA classifiers in-
dividually achieve only about 50% of what can
be achieved, but if combined in a clever way,
their performance seems to reach the limit of what
is possible based on the comparison with inter-
annotator agreement. The fact that the topic-role
extended classifier achieves so much more than
100% can be ascribed to the fact that it is cheating.
It uses pre-calculated a-priori chances of ?you?
being addressed given the circumstances. This
knowledge could be calculated by the machine
learner by feeding it the topic and role features,
and letting it learn these a-priori probabilities for
itself. But the classifier that uses these types of
features can not easily be deployed in any differ-
ent setting, where participants have different roles
and where different topics are being discussed.
Method Acc Rec Prec F PoM
HMS 92.47 54.42 74.61 61.22 -
LexCont 90.93 33.10 66.02 44.09 53
VFoA 90.80 27.77 67.65 39.38 48
CombinedFeat 91.56 36.62 70.82 48.28 72
ClassOfResults 43.68 77.55 55.88 93.02 102
LogComb(AND) 90.24 9.86 94.23 17.85 31
LogComb(OR) 91.19 47.08 61.90 53.48 60
TopicRoleExt 92.99 41.03 80.00 54.24 120
Table 4: Performance values of the Methods dis-
cussed in this paper: Accuracy, Recall, Precision,
F-measure and Percentage of Hypothezised Maxi-
mum Score (PoM).
6 How Does The Assistant Work?
At the time of writing, the assistant that has been
implemented is based on the simple visual focus
of attention classifier. The focus of attention is
inferred from the head pose and head movements
of a participant in the meeting room who is being
observed by a close-up camera. The real-time fo-
cus of attention module sends the coordinates of
the head pose to a central database 15 times per
second (Ba and Odobez, 2009). The coordinates
are translated into targets: objects and persons
in the meeting room. For the addressing module
most important are the persons and in particular
the screen in the meeting room where the remote
26
participant is visible. The addressing module is
notified of updates of who is speaking and decides
whether the remote participant is being looked at
by the speaker.
If the remote participant (RP) is not attentive
(which can be detected automatically based on his
recent activity) he is called when he is addressed
or when the real-time keyword spotter has de-
tected a word or phrase that occurs on the list of
topics of interest to the RP. For a detailed descrip-
tion of the remote meeting assistant demonstrator
developed in the AMIDA project refer to (op den
Akker et al, 2009).
The meeting assistant allows the RP to dis-
tribute his attention over various tasks. The system
can give a transcript of the fragment of the meet-
ing that is of interest to the RP, so he can catch
up with the meeting if he was not following. The
simple focus of attention based addressing module
works fine. The question is now if an addressing
module that uses the output of the real-time dia-
logue act recognizer, which in turn uses the out-
put of the real-time speech recognizer will outper-
form the visual focus of attention based addressee
detector. Experiments make us rather pessimistic
about this: the performance drop of state of the art
real-time dialogue segmentation and labeling tech-
nology based on real-time ASR output is too large
in comparison with those based on hand-annotated
transcripts (Jovanovic?, 2007). For real-time au-
tomatic addressee detection more superficial fea-
tures need to be used, such as: speech/non-speech,
who is speaking, some prosodic information and
visual focus of attention, by means of head orien-
tation.
The most explicit way of addressing is by using
a vocative, the proper name of the addressed per-
son. In small group face-to-face meetings, where
people constantly pay attention and keep track of
others? attentiveness to what is being said and
done, this method of addressing hardly ever oc-
curs. In remote meetings where it is often not clear
to the speaker if others are paying attention, people
call other?s names when they are addressing them.
Other properties of the participant relevant for ad-
dressee detection include his role and his topics
of interest. These can either be obtained directly
from the participant when he subscribes for the
meeting, or they can be recognized during an in-
troduction round that most business meetings start
with. For automatic topic detection further anal-
ysis of the meeting will be needed (Purver et al,
2007). Probability tables for the conditional prob-
abilities of the chance that someone with a given
role is being addressed when the talk is about a
given topic, can be obtained from previous data,
and could be updated on the fly during the meet-
ing. Only when that has been achieved will it
be possible for our extended topic/role addressee
classifier to be fully exploited by a live meeting
assistant.
Acknowledgements
The research of the first author was performed
when he was a Master?s student at the Human Me-
dia Interaction group of the University of Twente.
This work is supported by the European IST Pro-
gramme Project FP6-0033812 (AMIDA). We are
gratefull to the reviewers of SigDial 2009 for their
encouraging comments, and to Lynn Packwood
for correcting our English.
References
Sileye Ba and Jean-Marc Odobez. 2009. Recognizing
human visual focus of attention from head pose in
meetings. In IEEE Transaction on Systems, Man,
and Cybernetics, Part B (Trans. SMC-B), volume 39,
pages 16?33.
I. Bakx, K. van Turnhout, and J. Terken. 2003. Facial
orientation during multi-party interaction with infor-
mation kiosks. In Proceedings of 9th IFIP TC13 In-
ternational Conference on Human-Computer Inter-
action (INTERACT), Zurich, Switzerland.
Robert Freed Bales. 1950. Interaction Process Analy-
sis; A Method for the Study of Small Groups. Addi-
son Wesley, Reading, Mass.
Jean C. Carletta. 2007. Unleashing the killer corpus:
experiences in creating the multi-everything AMI
meeting corpus. Language Resources and Evalua-
tion, 41(2):181?190, May.
Walter Daelemans, Ve?ronique Hoste, Fien De Meul-
der, and Bart Naudts. 2003. Combined opti-
mization of feature selection and algorithm param-
eter interaction in machine learning of language.
In Proceedings of the 14th European Conference
on Machine Learning (ECML-2003), Lecture Notes
in Computer Science 2837, pages 84?95, Cavtat-
Dubrovnik, Croatia. Springer-Verlag.
Matthew Frampton, Raquel Fernndez, Patrick Ehlen,
Mario Christoudias, Trevor Darrell, and Stanley Pe-
ters. 2009. Who is you? combining linguistic and
gaze features to resolve second-person references in
27
dialogue. In Proceedings of the 12th Conference of
the EACL.
Sebastian Germesin, Tilman Becker, and Peter Poller.
2008. Determining latency for on-line dialog act
classification. In Poster Session for the 5th Inter-
national Workshop on Machine Learning for Multi-
modal Interaction, volume 5237.
Surabhi Gupta, John Niekrasz, Matthew Purver, and
Daniel Jurafsky. 2007. Resolving ?you? in multi-
party dialog. In Proceedings of the 8th SIGdial
Workshop on Discourse and Dialogue, Antwerp,
Belgium, September.
Thomas Hain, Asmaa El Hannani, Stuart N. Wrigley,
and Vincent Wan. 2008. Automatic speech recogni-
tion for scientific purposes - webasr. In Proceedings
of the international conference on spoken language
processing (Interspeech 2008).
Natasa Jovanovic? and Rieks op den Akker. 2004. To-
wards automatic addressee identification in multi-
party dialogues. In Proceedings of the 5th SIGdial
Workshop on Discourse and Dialogue, pages 89?
92, Cambridge, Massachusetts, USA. Association
for Computational Linguistics.
Natasa Jovanovic?, Rieks op den Akker, and Anton Ni-
jholt. 2006a. Addressee identification in face-to-
face meetings. In Proceedings of 11th Conference
of the European Chapter of the Association for Com-
putational Linguistics (EACL), Trento, Italy.
Natasa Jovanovic?, Rieks op den Akker, and Anton Ni-
jholt. 2006b. A corpus for studying addressing
behaviour in multi-party dialogues. Language Re-
sources and Evaluation Journal, 40(1):5?23.
Natasa Jovanovic?. 2007. To whom it may con-
cern: adressee identification in face-to-face meet-
ings. Ph.D. thesis, University of Twente.
M. Katzenmaier, R. Stiefelhagen, and T. Schultz. 2004.
Identifying the addressee in human-human-robot in-
teractions based on head pose and speech. In Pro-
ceedings of International Conference on Multimodal
Interfaces (ICMI), pages 144?151, State College,
PA.
A. Knott and P. Vlugter. 2008. Multi-agent human-
machine dialogue: issues in dialogue management
and referring expression semantics. Artificial Intel-
ligence, 172:69?102.
Gene H. Lerner. 1996. On the place of linguistic
resources in the organization of talk-in interaction:
?Second person? reference in multi-party conversa-
tion. Pragmatics, 6(3):281?294.
I. McCowan, J. Carletta, W. Kraaij, S. Ashby, S. Bour-
ban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec,
V. Karaiskos, M. Kronenthal, G. Lathoud, M. Lin-
coln, A. Lisowska, W. Post, D. Reidsma, and
P. Wellner. 2005. The AMI meeting corpus. In
Proceedings of the 5th International Conference on
Methods and Techniques in Behavioral Research.
Rieks op den Akker and Mariet Theune. 2008. How
do I address you? - modelling addressing behavior
based on an analysis of a multi-modal corpus of con-
versational discourse. In Proceedings of the AISB
2008 Symposium on Multimodal Output Generation
(MOG 2008), Aberdeen, UK, pages 10?17.
Rieks op den Akker and David Traum. 2009. A com-
parison of addressee detection methods for multi-
party conversations. In Proceedings of DiaHolmia,
13th Workshop on the Semantics and Pragmatics of
Dialogue.
Rieks op den Akker, Dennis Hofs, Hendri Hondorp,
Harm op den Akker, Job Zwiers, and Anton Nijholt.
2009. Engagement and floor control in hybrid meet-
ings. In Proceedings COST Action Prague 2008 (to
appear), LNCS. Springer Verlag.
Harm op den Akker. 2009. On addressee detection
for remote hybrid meeting settings. Master?s thesis,
University of Twente.
W.M. Post, A.H. Cremers, and O.B. Henkemans. 2004.
A research environment for meeting behavior. In
A. Nijholt, T. Nishida, R. Fruchter, and D. Rosen-
berg, editors, Social Intelligence Design, Enschede,
The Netherlands.
Matthew Purver, John Dowding, John Niekrasz,
Patrick Ehlen, Sharareh Noorbaloochi, and Stanley
Peters. 2007. Detecting and summarizing action
items in multi-party dialogue. In Proceedings of the
8th SIGdial Workshop on Discourse and Dialogue,
Antwerp, Belgium, September.
Dennis Reidsma and Jean C. Carletta. 2008. Relia-
bility measurement without limits. Computational
Linguistics, 34(3):319?326, September.
Dennis Reidsma. 2008. Annotations and Subjective
Machines. Ph.D. thesis, University of Twente.
J. Rickel, S. Marsella, J. Gratch, R. Hill, D. Traum, and
W. Swartout. 2002. Towards a new generation of
virtual humans for interactive experiences. Intelli-
gent Systems, 17:32?36.
David Traum. 2004. Issues in multiparty dialogues. In
Advances in Agent Communication, pages 201?211.
K. van Turnhout, J. Terken, I. Bakx, and B. Eggen.
2005. Identifying the intended addressee in
mixed human-human and human-computer interac-
tion from non-verbal features. In Proceedings of 7th
International Conference on Multimodal Interfaces
(ICMI?05), Trento, Italy.
Ian H. Witten and Eibe Frank. 1999. Data Mining:
Practical Machine Learning Tools and Techniques
with Java Implementations. Morgan Kaufmann, 1st
edition, October.
28
Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics, pages 8?16
Manchester, August 2008
Exploiting ?Subjective? Annotations
Dennis Reidsma
Human Media Interaction
University of Twente, PO Box 217
NL-7500 AE, Enschede, The Netherlands
dennisr@ewi.utwente.nl
Rieks op den Akker
Human Media Interaction
University of Twente, PO Box 217
NL-7500 AE, Enschede, The Netherlands
infrieks@ewi.utwente.nl
Abstract
Many interesting phenomena in conversa-
tion can only be annotated as a subjec-
tive task, requiring interpretative judge-
ments from annotators. This leads to
data which is annotated with lower lev-
els of agreement not only due to errors in
the annotation, but also due to the differ-
ences in how annotators interpret conver-
sations. This paper constitutes an attempt
to find out how subjective annotations with
a low level of agreement can profitably
be used for machine learning purposes.
We analyse the (dis)agreements between
annotators for two different cases in a
multimodal annotated corpus and explic-
itly relate the results to the way machine-
learning algorithms perform on the anno-
tated data. Finally we present two new
concepts, namely ?subjective entity? clas-
sifiers resp. ?consensus objective? classi-
fiers, and give recommendations for using
subjective data in machine-learning appli-
cations.
1 Introduction
Research that makes use of multimodal annotated
corpora is always presented with something of a
dilemma. One would prefer to have results which
are reproducible and independent of the particular
annotators that produced the corpus. One needs
data which is annotated with as few disagreements
between annotators as possible. But labeling a cor-
pus is a task which involves a judgement by the an-
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
notator and is therefore, in a sense, always a sub-
jective task. Of course, for some phenomena those
judgements can be expected to come out mostly
the same for different annotators. For other phe-
nomena the judgements can be more dependent on
the annotator interpreting the behavior being anno-
tated, leading to annotations which are more sub-
jective in nature. The amount of overlap or agree-
ment between annotations is then also influenced
by the amount of intersubjectivity in the judge-
ments of annotators.
This relates to the spectrum of content types
discussed extensively by Potter and Levine-
Donnerstein (1999). One of the major distinctions
that they make is a distinction in annotation of
manifest content (directly observable events), pat-
tern latent content (events that need to be inferred
indirectly from the observations), and projective
latent content (loosely said, events that require a
subjective interpretation from the annotator).
Manifest content is what is directly observable.
Some examples are annotation of instances where
somebody raises his hand or raises an eyebrow,
annotation of the words being said and indicating
whether there is a person in view of the camera.
Annotating manifest content can be a relatively
easy task. Although the annotation task involves
a judgement by the annotator, those judgements
should not diverge a lot for different annotators.
At the other end of the spectrum we find pro-
jective latent content. This is a type of content
for which the annotation schema does not spec-
ify in extreme detail the rules and surface forms
that determine the applicability of classes, but in
which the coding relies on the annotators? exist-
ing mental conception1 of the classes. Such an ap-
1Potter and Levine-Donnerstein use the word ?mental
scheme? for this. We will use ?mental conceptions? in this
8
proach is useful for everyday concepts that most
people understand and to a certain extent share a
common meaning for, but for which it is almost
impossible to provide adequately complete defini-
tions. Potter and Levine-Donnerstein use the ex-
ample ?chair? for everyday concepts that are dif-
ficult to define exhaustively. But this concept is
also especially relevant in an application context
that requires the end user of the data to agree with
the distinctions being made. This is very important
when machine learning classifiers are developed
to be used in everyday applications. For exam-
ple, one can make a highly circumscribed, etholog-
ically founded definition of the class ?dominant? to
guide annotation. This is good for, e.g., research
into social processes in multiparty conversations.
However, in a scenario where an automatic classi-
fier, trained to recognize this class, is to be used
in an application that gives a participant in a meet-
ing a quiet warning when he is being too dominant
(Rienks, 2007) one would instead prefer the class
rather to fit the mental conceptions of dominance
that a ?naive? user may have. When one designs
an annotation scheme for projective latent content,
the focus of the annotation guidelines is on instruc-
tions that trigger the appropriate existing mental
conceptions of the annotators rather than on writ-
ing exhaustive descriptions of how classes can be
distinguished from each other (Potter and Levine-
Donnerstein, 1999).
Interannotator agreement takes on different
roles for the two ends of the spectrum. For mani-
fest content the level of agreement tells you some-
thing about how accurate the measurement in-
strument (schema plus coders) is. Bakeman and
Gottman, in their text book observing interaction:
introduction to sequential analysis (1986, p 57),
say about this type of reliability measurement that
it is a matter of ?calibrating your observers?. For
projective content, we have additional problems;
the level of agreement may be influenced by the
level of intersubjectivity, too. Where Krippen-
dorff (1980) describes that annotators should be
interchangeable, annotations of projective latent
content can sometimes say as much about the men-
tal conceptions of the particular annotator as about
the person whose interactions are being annotated.
The personal interpretations of the data by the an-
notator should not necessarily be seen as ?errors?,
though, even if those interpretations lead to low in-
paper to avoid confusion with the term ?annotation scheme?.
terannotator agreement: they may simply be an un-
avoidable aspect of the interesting type of data one
works with.
Many different sources of low agreement levels,
and many different solutions, are discussed in the
literature. It is important to note that some types of
disagreement are more systematic and other types
are more noise like. For projective latent con-
tent one would expect more consistent structure in
the disagreements between annotators as they are
caused by the differences in the personal ways of
interpreting multimodal interaction. Such system-
atic disagreements are particularly problematic for
subsequent use of the data, more so than noise-
like disagreements. Therefore, an analysis of the
quality of an annotated corpus should not stop at
presenting the value of a reliability metric; instead
one should investigate the patterns in the disagree-
ments and discuss the possible impact they have on
the envisioned uses of the data (Reidsma and Car-
letta, 2008). Some sources of disagreements are
the following.
(1) ?Clerical errors? caused by a limited view
of the interactions being annotated (low quality
video, no audio, occlusions, etc) or by slipshod
work of the annotator or the annotator misunder-
standing the instructions. Some solutions are to
provide better instructions and training, using only
good annotators, and using high quality recordings
of the interaction being annotated.
(2) ?Invalid or imprecise annotation schemas?
that contain classes that are not relevant or do not
contain classes that are relevant, or force the anno-
tator to make choices that are not appropriate to the
data (e.g. to choose one label for a unit where more
labels are applicable). Solutions concern redesign-
ing the annotation schema, for example by merg-
ing difference classes, allowing annotators to use
multiple labels, removing classes, or adding new
classes.
(3) ?Genuinely ambiguous expressions? as de-
scribed by Poesio and Artstein (2005). They dis-
cuss that disagreements caused by ambiguity are
not so easily solved.
(4) ?A low level of intersubjectivity? for the in-
terpretative judgements of the annotators, caused
by the fact that there is less than perfect overlap
between the mental conceptions of the annotators.
The solutions mentioned above for issue (2) partly
also apply here. However, in this article we focus
on an additional, entirely different, way of coping
9
with disagreements resulting from a low level of
intersubjectivity that actively exploits the system-
atic differences in the annotations caused by this.
1.1 Useful results from data with low
agreement
Data with a low interannotator agreement may be
difficult to use, but there are other fields where
partial solutions have been found to the problem,
such as the information retrieval evaluation confer-
ences (TREC). Relevance judgements in TREC as-
sessments (and document relevance in general) are
quite subjective and it is well known that agree-
ment for relevance judgements is not very high
(Voorhees and Harman report 70% three-way per-
cent agreement on 15,000 documents for three
assessors (1997)). Quite early in the history of
the TREC, Voorhees investigated what the conse-
quences of this low level of agreement are for the
usefulness of results obtained on the TREC collec-
tion. It turns out that specifying a few constraints2
is enough to be able to use the TREC assessments
to obtain meaningful evaluation results (Voorhees,
2000). Inspired by this we try to find ways of look-
ing at subjective data that tells us what constraints
and restrictions on the use of it follow from the pat-
terns in the disagreements between annotators, as
also advised by Reidsma and Carletta (2008).
1.2 Related Work
In corpus research there is much work with anno-
tations that need subjective judgements of a more
subjective nature from an annotator about the be-
havior being annotated. This holds for Human
Computer Interaction topics such as affective com-
puting or the development of Embodied Conversa-
tional Agents with a personality, but also for work
in computational linguistics on topics such as emo-
tion (Craggs and McGee Wood, 2005), subjectivity
(Wiebe et al, 1999; Wilson, 2008) and agreement
and disagreement (Galley et al, 2004).
If we want to interpret the results of classifiers in
terms of the patterns of (dis)agreement found be-
tween annotators, we need to subject the classifiers
with respect to each other and to the ?ground truth
data? to the same analyses used to evaluate and
compare annotators to each other. Vieira (2002)
and Steidl et al (2005) similarily remark that it
2Only discuss relative performance differences on differ-
ent (variations of) algorithms/systems run on exactly the same
set of assessments using the same set of topics.
is not ?fair? to penalize machine learning perfor-
mance for errors made in situations where humans
would not agree either. Vieira however only looks
at the amount of disagreement and does not explic-
itly relate the classes where the system and coders
disagree to the classes where the coders disagree
with each other. Steidl et al?s approach is geared
to data which is multiply coded for the whole cor-
pus (very expensive) and for annotations that can
be seen as ?additive?, i.e., where judgements are
not mutually exclusive.
Passonneau et al (2008) present an extensive
analysis of the relation between per-class machine
learning performance and interannotator agree-
ment obtained on the task of labelling text frag-
ments with their function in the larger text. They
show that overall high agreement can indicate a
high learnability of a class in a multiply annotated
corpus, but that the interannotator agreement is not
necessarily predictive of the learnability of a la-
bel from a single annotator?s data, especially in the
context of what we call projective latent content.
1.3 This Paper
This paper constitutes an attempt to find out how
subjective annotations, annotated with a low level
of agreement, can profitably be used for machine
learning purposes. First we present the relevant
parts of the corpus. Subsequently, we analyse the
(dis)agreements between annotators, on more as-
pects than just the value of a reliability metric, and
explicitly relate the results to the way machine-
learning algorithms perform on the annotated data.
Finally we present two new concepts that can be
used to explain and exploit this relation (?subjec-
tive entity? classifiers resp. ?consensus objective?
classifiers) and give some recommendations for
using subjective data in machine-learning applica-
tions.
2 From Agreement to Machine Learning
Performance
We used the hand annotated face-to-face conversa-
tions from the 100 hour AMI meeting corpus (Car-
letta, 2007). In the scenario-based AMI meetings,
design project groups of four players have the task
to design a new remote TV control. Group mem-
bers have roles: project manager (PM), industrial
designer (ID), user interface design (UD), and mar-
keting expert (ME). Every group has four meetings
(20-40 min. each), dedicated to a subtask. Most of
10
the time the participants sit at a square table.
The meetings were recorded in a meeting room
stuffed with audio and video recording devices,
so that close facial views and overview video, as
well as high quality audio is available. Speech
was transcribed manually, and words were time
aligned. The corpus has several layers of anno-
tation for several modalities, such as dialogue acts,
topics, hand gestures, head gestures, subjectivity,
visual focus of attention (FOA), decision points,
and summaries, and is easily extendible with new
layers. The dialogue act (DA) layer segments
speaker turns into dialogue act segments, on top of
the word layer, and they are labeled with one of 15
dialogue act type labels, following an annotation
procedure.
In this section we will inspect (dis)agreements
and machine learning performance for two cor-
pus annotation layers: the addressing annotations
(Jovanovic? et al, 2006) and for a particular type
of utterances in the corpus, the ?Yeah-utterances?
(Heylen and op den Akker, 2007).
2.1 Contextual Addressing
A part of the AMI corpus is also annotated with ad-
dressee information. Real dialogue acts (i.e. all di-
alogue acts but backchannels, stalls and fragments)
were assigned a label indicating who the speaker
addresses his speech to (is talking to). In these
type of meetings most of the time the speaker ad-
dresses the whole group, but sometimes his dia-
logue act is particularly addressed to some indi-
vidual (about 2743 of the 6590 annotated real dia-
logue acts); for example because he wants to know
that individual?s opinion. The basis of the con-
cept of addressing underlying the addressee an-
notation in the AMI corpus originates from Goff-
man (Goffman, 1981). The addressee is the par-
ticipant ?oriented to by the speaker in a manner
to suggest that his words are particularly for them,
and that some answer is therefore anticipated from
them, more so than from the other ratified partic-
ipants?. Sub-group addressing hardly occurs and
was not annotated. Thus, DAs are either addressed
to the group (G-addressed) or to an individual (I-
addressed) (see Jovanovic et al (2006)).
Another layer of the corpus contains focus of at-
tention information derived from head, body and
gaze observations (Ba and Odobez, 2006), so that
for any moment it is known whether a person is
looking at the table, white board, or some other
participant. Gaze and focus of attention are impor-
tant elements of addressing behavior, and therefore
FOA is a strong cue for the annotator who needs to
determine the addressee of an utterance. However,
FOA is not the only cue. Other relevant cues are,
for example, proper names and the use of address-
ing terms such as ?you?. Even when the gaze is
drawn to a projection screen, or the meeting is held
as a telephone conference without visuals, people
are able to make the addressee of their utterances
clear.
From an extensive (dis)agreement analysis of
the addressing and FOA layers the following con-
clusions can be summarized: the visual focus of
attention was annotated with a very high level of
agreement (Jovanovic?, 2007); in the addressee an-
notation there is a large confusion between DAs
being G-addressed or I-addressed; if the annota-
tors agree on an utterance being I-addressed they
typically also agree on the particular individual be-
ing addressed; ?elicit? DAs were easier to annotate
with addressee than other types of dialog act; and
reliability of addressee annotation is dependent on
the FOA context (Reidsma et al, 2008). When the
speaker?s FOA is not directed to any participant the
annotators must rely on other cues to determine the
addressee and will disagree a lot more than when
they are helped by FOA related cues. Some of
these disagreements can be due to systematic sub-
jective differences, e.g. an annotator being biased
towards the ?Group? label for utterances that are
answers to some question. Other disagreements
may be caused by the annotator being forced to
choose an addressee label for utterances that were
not be clearly addressed in the first place.
In this section we will not so much focus on
the subjectivity of the addressee annotation as on
the multimodal context in which annotators agree
more. Specifically, we will look further at the way
the level of agreement with which addressee has
been annotated is dependent on the FOA context
of a set of utterances. We expect this will be re-
flected directly by the machine learning perfor-
mance in these two contexts: the low agreement
might indicate a context where addressee is in-
herently difficult to determine and furthermore the
context with high agreement will result in annota-
tions containing more consistent information that
machine learning can model.
To verify this assumption we experimented with
automatic detection of the addressee of an utter-
11
ance based on lexical and multimodal features.
Compared to Jovanovic? (2007), we use a limited
set of features that does not contain local context
features such as ?previous addressee? or ?previous
dialogue act type?. Besides several lexical fea-
tures we also used features for focus of attention
of the speaker and listeners during the utterance.
Below we describe two experiments with this task.
Roughly 1 out of every 3 utterances is performed
in a context where the speaker?s FOA is not di-
rected at any other participant. This gives us three
contexts to train and to test on: all utterances, all
utterances where the speaker?s FOA is not directed
at any other participant (1/3 of the data) and all
utterances during which the speaker?s FOA is di-
rected at least once at another participant (2/3 of
the data).
First Experiment For the first experiment we
trained a Bayesian Network adapted from Jo-
vanovic? (2007) on a mix of utterances from all
contexts, and tested its performance on utterances
from the three different contexts: (1) all data, (2)
all data in the context ?at least some person in
speaker?s FOA? and (3) all data in the context ?no
person in speaker?s FOA during utterance?. As was
to be expected, the performance in the second con-
text showed a clear gain compared to the first con-
text, and the performance in the third context was
clearly worse. The performance differences, for
different train/test splits, tend to be about five per-
cent.
Second Experiment Because the second con-
text showed such a better performance, we ran a
second experiment where we trained the network
on only data from the second context, to see if
we could improve the performance in that context
even more. In different train/test splits this gave us
another small performance increase.
Conclusions for Contextual Addressing The
performance increases can mostly be attributed
to the distinction between different individual ad-
dressees for I-addressed utterances. Precision and
recall for the G-addressed utterances does not
change so much for the different contexts. This
result is reminiscent of the fact that when the an-
notators agreed on an utterance being I-addressed
they typically also agreed on the particular individ-
ual being addressed.
These results are particularly interesting in the
light of the high accuracy with which FOA was an-
notated. If this accuracy points at the possibility to
also achieve a high automatic recognition rate for
FOA we can exploit these results in a practical ap-
plication context by defining a addressee detection
module which only assigns an addressee to an ut-
terance in the second FOA context (FOA at some
participants), and in all other cases labels an utter-
ance as ?addressee cannot be determined?. Such
a detection module achieves a much higher preci-
sion than a module that tries to assign an addressee
label regardless; of course this happens at the cost
of recall.
2.2 Interannotator Training and Testing
Classifiers behave as they are trained. When two
annotators differ in the way they annotate, i.e. have
different ?mental conceptions? of the phenomenon
being annotated, we can expect that a classifier
trained on the data annotated by one annotator
behaves different from a classifier trained on the
other annotator?s data. As Rienks describes, this
property allows us to use all data in the corpus, in-
stead of just the multiply annotated part of it, for
analyzing differences between annotators (Rienks,
2007, page 105). We can expect that a classifier A
trained on data annotated by A will perform bet-
ter when tested on data annotated by A, than when
tested on data annotated by B. In other words, clas-
sifier A is geared towards modelling the ?mental
conception? of annotator A. In this section we will
try to find out whether it is possible to explicitly
tease apart the overlap and the differences in the
mental conceptions of the annotators as mirrored
in the behavior of classifiers, on a subjective anno-
tation task. Suppose that we build a Voting Clas-
sifier, based on the votes of a number of classifiers
each trained on a different annotator?s data. The
Voting Classifier only makes a decision when all
voters agree on the class label. How good will
the Voting Classifier perform? Is there any rela-
tion between the (dis)agreement of the voters, and
the (dis)agreement of the annotators? Will the re-
sulting Voting Classifier in some way embody the
overlap between the ?mental conceptions? of the
different annotators?
As an illustration and a test case for such a
Voting Classifier, we consider the human annota-
tions and automatic classification of a particular
type of utterances in the AMI corpus, the ?Yeah-
utterances?, utterances that start with the word
?yeah?.
12
class train-tot test-tot DH-train/test S9-train/test VK-train/test
bc 3043 1347 1393/747 670/241 980/359
as 3724 1859 1536/1104 689/189 1499/566
in 782 377 340/229 207/60 235/88
ot 1289 596 316/209 187/38 786/349
Table 1: Sizes of train and test data sets used and the distribution of class labels over these data sets for
the different annotators.
The Data Response tokens like ?yeah?, ?okay?,
?right? and ?no? have the interest of linguists be-
cause they may give a clue about the stance that the
listener takes towards what is said by the speaker
(Gardner, 2004). Jefferson described the differ-
ence between ?yeah? and other backchannels in
terms of speaker recipiency, the willingness of
the speaker to take the floor (Jefferson, 1984).
Yeah utterances make up a substantial part of the
dialogue acts in the AMI meeting conversations
(about eight percent). ?Yeah? is the most ambigu-
ous utterance that occurs in discussion segments in
AMI meetings. In order to get information about
the stance that participants take with respect to-
wards the issue discussed it is important to be able
to tell utterances of ?Yeah? as a mere backchannel,
from Yeah utterances that express agreement with
the opinion of the speaker (see the work of Heylen
and Op den Akker (2007)).
The class variables for dialogue act types of
Yeah utterances that are distinguished are: Assess
(as), Backchannel (bc), Inform (in), and Other (ot).
Table 1 gives a distribution of the labels in our
train and test data sets. Note that for each annota-
tor, a disjunct train and test set have been defined.
The inter-annotator agreement on the Yeah utter-
ances is low. The pairwise alpha values for meet-
ing IS1003d, which was annotated by all three an-
notators, are (in brackets the number of agreed DA
segments that start with ?Yeah?): alpha(VK,DH)
= 0.36 (111), alpha (VK,S9) = 0.36 (132), al-
pha(DH,S9) = 0.45 (160).
Testing for Systematic Differences When one
suspects the annotations to have originated from
different mental conceptions of annotators, the first
step is to test whether these differences are system-
atic. Table 2 presents the intra and inter annota-
tor classification accuracy. There is a clear perfor-
mance drop between using the test data from the
same annotator from which the training data was
taken and using the test data of other annotators
or the mixed test data of all annotators. This sug-
gest that some of the disagreements in the annota-
tion stem from systematic differences in the mental
conceptions of the annotators.
TEST
TRAIN DH S9 VK Mixed
DH 69 64 52 63
S9 59 68 48 57
VK 63 57 66 63
Table 2: Performance of classifiers (in terms of ac-
curacy values ? i.e. percentage correct predictions)
trained and tested on various data sets. Results
were obtained with a decision tree classifier, J48
in the Weka toolkit.
Building the Voting Classifier Given the three
classifiers DH, S9 and VK, each trained on the
train data taken from one single annotator, we have
build a Voting Classifier that outputs a class label
when all three ?voters? (the classifiers DH, S9 and
VK) give the same label, and the label ?unknown?
otherwise. As was to be expected, the accuracy
for this Voting Classifier is much lower than the
accuracy of each of the single voters and than the
accuracy of a classifier trained on a mix of data
from all annotators (see Table 3), due to the many
times the Voting Classifier assigns the label ?un-
known? which is not present in the test data and is
always false. The precision of the Voting Classi-
fier however is higher than that of any of the other
classifiers, for each of the classes (see Table 4).
Conclusions for the Voting Classifier For the
data that we used in this experiment, building a
Voting Classifier as described above gave us a high
precision classifier. Based on our starting point,
this would relate to the classifier in some way em-
bodying the overlap in the mental conceptions of
each of the annotators. If that were true, the cases
in which the Voting Classifier returns an unani-
mous vote would be mostly those cases in which
the different annotators would also have agreed.
13
TRAIN Accuracy
train MIX(8838) 67
DH(3585) 63
S9(1753) 57
VK(3500) 63
VotingClassifier(8838) 43
Table 3: Performance of the MaxEnt classifiers (in
terms of accuracy values ? i.e. percentage cor-
rect predictions) tested on the whole test set, a mix
of three annotators data (4179 ?Yeah? utterances).
The first column between brackets the size of the
train sets.
Classifier
Class Voting DH S9 VK train MIX
BC 71 65 63 71 69
AS 73 62 64 61 66
IN 60 58 34 52 50
OT 86 59 32 57 80
Table 4: Precision values per class label for the
classifiers.
This can be tested quite simply using multiply an-
notated data. Note that not all data needs to be
annotated by more annotators: just enough to test
this hypothesis. Otherwise, it will suffice to have
enough data for each single annotator, be it over-
lapping or not. This is especially advantageous
when the corpus is really large, such as the 100h
AMI corpus. Another way to test the hypothesis
that the voting behavior relates to intersubjectivity
is to look at the type and context of the agreements
between annotators, found in the reliability analy-
sis, and see if that relates to the type and context
of the cases where the Voting Classifier renders an
unanimous judgement. That would be strong cir-
cumstantial evidence in support of the hypothesis.
Note that the gain in precision is obtained at
the cost of recall, because the Voting Classifier ap-
proach explicitly restricts judgements to the cases
where annotators would have agreed and, presum-
ably, therefore to the cases in which users of the
data are able to agree to the judgements as well. It
is possible that you ?lose? a class label in the clas-
sifier by having a high precision but a recall of less
than five percent, which in our example happened
for the ?other? class.
3 The Classifier as Subjective Entity vs
the Classifier as Embodiment of
Consensus Objectivity
Many annotation tasks are subjective to a larger de-
gree. When this is simply taken as a given, and the
systematic disagreements resulting from the differ-
ent mental conceptions of the annotators are not
taken into account while training a machine classi-
fier on the resulting data, there is no simple reason
to assume that the resulting classifier is any less
subjective in the judgements it makes. Without ad-
ditional analyses one cannot suppose the classifier
did not pick up idiosyncrasies from the annotators.
We have seen that machine classifiers can indeed
considered to be subjective in their judgements, a
property they have inherited from the annotations
they have been trained on. A judgement made by
such a classifier should be approached in a simi-
lar manner as a judgement made by another per-
son3. We will call the resulting classifier therefore
a ?subjective entity? classifier.
A careful analysis of the interannotator agree-
ments and disagreements might make it possible
to build classifiers that partly embody the intersub-
jective overlap between the mental conceptions of
the annotators. Because the classifier only tries to
give a judgement in situations where one can ex-
pect annotators or users to agree, one can approach
the judgements made by the classifier as a ?com-
mon sense? of judgements that people can agree
on, despite the subjective quality of the annotation
task. We will call the resulting classifier a ?consen-
sus objective? classifier.
4 Discussion
In the Introduction we distinguished several uses
of data annotation using human annotators. The
analyses and research in this paper mainly con-
cerns the use of annotated data for the training
and development of automatic machine classifiers.
Ideally the annotation schema and the class labels
that are distinguished reflect the use that is made
of the output of the machine classifiers in some
particular application in which the classifier op-
erates as a module. Imagine for example a sys-
tem that detects when meeting participants are too
dominant and signals the chairman of the meet-
3On a side note, letting the machine classifiers judgments
be presented through an embodied conversational agent can
be a way to present this human-like subjectivity for the user
(Reidsma et al, 2007).
14
ing to prevent some participants being dissatisfied
with the decision making processes. Or, a clas-
sifier for addressee detection that signals remote
participants that they are addressed by the speaker.
The way that users of the system interpret the sig-
nals output by the classifier should correspond to
the meanings that were used by the annotators and
that were implemented in the classifier.
When there is a lot of disagreement in the an-
notations this should be taken into account for
machine learning if one does not want to obtain
a ?subjective entity? classifier, the judgements of
which the user will often disagree with. In Sec-
tion 2 we presented two ways to exploit such data
for building machine classifiers. Here we elabo-
rate a bit on a difference between the two cases re-
lating to the different causes of the inter-annotator
disagreement.
For the addressing annotations, the annotators
sometimes had problems with choosing between
G-addressed and I-addressed. The participants
in the conversation usually did not seem to have
any problem with that. There are only a few in-
stances in the data where the participants explic-
itly requested clarification. It is reasonable to ex-
pect that in cases where it really matters ? for the
conversational partners ? who is being addressed,
outside observers will not have a problem to iden-
tify this. Thus, in those cases where the annotators
had problems to decide upon the type of address-
ing there maybe was no reason for the participants
in the conversation to make that clear because it
simply was not an issue. The annotators were then
tripped by the fact that they were forced by the an-
notation guidelines to choose one addressee label.
In the dialogue act classification task something
additional is going on. Here we see that annota-
tors also have problems because many utterances
themselves are ambiguous or poly-interpretable.
Some annotator may prefer to call this act an as-
sess where an other prefers to call it an inform, and
both may have good reason to back up their choice.
A similar situation occurs in the case of the clas-
sification of Yeah utterances. The disagreements
then seem to be caused more explicitly by differ-
ing judgements of a conversational situation.
5 Conclusions
We have argued that dis-agreements between dif-
ferent observers of ?subjective content? is unavoid-
able and an intrinsic quality of the interpretation
and classification process of such type of content.
Any subdivision of these type of phenomena into a
predefined set of disjunct classes suffers from be-
ing arbitrary. There are always cases that can be-
long to this but also to that class. Analysis of an-
notations of the same data by different annotators
may reveal that there are differences in the deci-
sions they make, such as some personal preference
for one class over another.
Instead of throwing away the data as not being
valuable at all for machine learning purposes, we
have shown two ways to exploit such data, both
leading to high precision / low recall classifiers
that in some cases refuse to give a judgement. The
first way was based on the identification of subsets
of the data that show higher inter-annotator agree-
ment. When the events in these subsets can be
identified computationally the way is open to use
classifiers trained on these subsets. We have illus-
trated this with several subsets of addressing events
in the AMI meeting corpus and we have shown that
this leads to an improvement in the accuracy of the
classifiers. Precision is raised in case the classi-
fier refrains from making a decision in those situa-
tion that fall outside the subsets. The second way
is to train a number of classifiers, one for each of
the annotators data part of the corpus, and build
a Voting Classifier that only makes a decision in
case all classifiers agree on the class label. This
approach was illustrated by the problem of classi-
fication of the dialogue act type of Yeah-utterances
in the AMI corpus. The results show that the ap-
proach indeed leads to the expected improvement
in precision, at the cost of a lower recall, because
of the cases in which the classifier doesn?t make a
decision.
Acknowledgements
The authors are in debt to many people for many
fruitful discussions, most prominently Jean Car-
letta, Ron Artstein, Arthur van Bunningen, Hen-
ning Rode and Dirk Heylen. This work is sup-
ported by the European IST Programme Project
FP6-033812 (AMIDA, publication 136). This ar-
ticle only reflects the authors? views and funding
agencies are not liable for any use that may be
made of the information contained herein.
References
Ba, S. O. and J.-M. Odobez. 2006. A study on visual
focus of attention recognition from head pose in a
15
meeting room. In Renals, S. and S. Bengio, editors,
Proc. of the MLMI 2006, volume 4299 of Lecture
Notes in Computer Science, pages 75?87. Springer.
Bakeman, R. and J. M. Gottman. 1986. Observing
Interaction: An Introduction to Sequential Analysis.
Cambridge University Press.
Carletta, J. C. 2007. Unleashing the killer corpus:
experiences in creating the multi-everything AMI
meeting corpus. Language Resources and Evalua-
tion, 41(2):181?190.
Craggs, R. and M. McGee Wood. 2005. Evaluating
discourse and dialogue coding schemes. Computa-
tional Linguistics, 31(3):289?296.
Galley, M., K. McKeown, J. Hirschberg, and
E. Shriberg. 2004. Identifying agreement and
disagreement in conversational speech: Use of
Bayesian networks to model pragmatic dependen-
cies. In Proc. of the 42nd Meeting of the ACL, pages
669?676. ACL.
Gardner, R. 2004. Acknowledging strong ties between
utterances in talk: Connections through right as a re-
sponse token. In Proceedings of the 2004 Confer-
ence of the Australian Linguistic Society, pages 1?
12.
Goffman, E. 1981. Footing. In Forms of Talk, pages
124?159. Philadelphia: University of Pennsylvania
Press.
Heylen, D. and H. op den Akker. 2007. Comput-
ing backchannel distributions in multi-party conver-
sations. In Cassell, J. and D. Heylen, editors, Proc.
of the ACL Workshop on Embodied Language Pro-
cessing, Prague, pages 17?24. ACL.
Jefferson, G. 1984. Notes on a systematic deploy-
ment of the acknowledgement tokens ?yeah? and
?mm hm?. Papers in Linguistics, 17:197?206.
Jovanovic?, N., H. op den Akker, and A. Nijholt. 2006.
A corpus for studying addressing behaviour in multi-
party dialogues. Language Resources and Evalua-
tion, 40(1):5?23.
Jovanovic?, N. 2007. To Whom It May Concern -
Addressee Identification in Face-to-Face Meetings.
Phd thesis, University of Twente.
Krippendorff, K. 1980. Content Analysis: An Intro-
duction to its Methodology, volume 5 of The Sage
CommText Series. Sage Publications, Beverly Hills,
London.
Passonneau, R. J., T. Yano, T. Lippincott, and J. Kla-
vans. 2008. Relation between agreement mea-
sures on human labeling and machine learning per-
formance: Results from an art history image index-
ing domain. In Proc. of the LREC 2008.
Poesio, M. and R. Artstein. 2005. The reliability of
anaphoric annotation, reconsidered: Taking ambigu-
ity into account. In Proc. of the Workshop on Fron-
tiers in Corpus Annotations II: Pie in the Sky, pages
76?83, Ann Arbor, Michigan. ACL.
Potter, J. W. and D. Levine-Donnerstein. 1999. Re-
thinking validity and reliability in content analy-
sis. Journal of applied communication research,
27(3):258?284.
Reidsma, D. and J. C. Carletta. 2008. Reliability mea-
surement without limits. Computational Linguistics,
34(3).
Reidsma, D., Z. M. Ruttkay, and A. Nijholt, 2007.
Challenges for Virtual Humans in Human Comput-
ing, chapter 16, pages 316?338. Number 4451 in
LNAI: State of the Art Surveys. Springer Verlag,
Berlin/Heidelberg.
Reidsma, D., D. Heylen, and H. op den Akker. 2008.
On the contextual analysis of agreement scores. In
Proc. of the LREC Workshop on Multimodal Cor-
pora.
Rienks, R. J. 2007. Meetings in Smart Environments:
Implications of progressing technology. Phd thesis,
SIKS Graduate School / University of Twente, En-
schede, NL.
Steidl, S., M. Levit, A. Batliner, E. No?th, and H. Nie-
mann. 2005. ?of all things the measure is man? auto-
matic classification of emotion and intra labeler con-
sistency. In ICASSP 2005, International Conference
on Acoustics, Speech, and Signal Processing.
Vieira, R. 2002. How to evaluate systems against hu-
man judgment on the presense of disagreement? In
Proc. workshop on joint evaluation of computational
processing of Portugese at PorTAL 2002.
Voorhees, E. M. and D. Harman. 1997. Overview of
the trec-5. In Proc. of the Fifth Text REtrieval Con-
ference (TREC-5), pages 1?28. NIST.
Voorhees, E. M. 2000. Variations in relevance
judgments and the measurement of retrieval effec-
tiveness. Information Processing & Management,
36(5):697?716.
Wiebe, J. M., R. F. Bruce, and T. P. O?Hara. 1999.
Development and use of a gold-standard data set for
subjectivity classifications. In Proc. of the 37th An-
nual Meeting of the ACL, pages 246?253. ACL.
Wilson, T. 2008. Annotating subjective content in
meetings. In Proc. of the Language Resources and
Evaluation Conference (LREC-2008).
16
Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 20?29,
Portland, Oregon, 24 June 2011. c?2011 Association for Computational Linguistics
Generating Varied Narrative Probability Exercises
Marie?t Theune1 Roan Boer Rookhuiszen1 Rieks op den Akker1 Hanneke Geerlings2
Department of Computer Science1
Department of Research Methodology, Measurement and Data Analysis2
University of Twente
Enschede, The Netherlands
m.theune@utwente.nl, a.r.boerrookhuiszen@alumnus.utwente.nl,
h.j.a.opdenakker@utwente.nl, h.geerlings@gw.utwente.nl
Abstract
This paper presents Genpex, a system for au-
tomatic generation of narrative probability ex-
ercises. Generation of exercises in Genpex is
done in two steps. First, the system creates
a specification of a solvable probability prob-
lem, based on input from the user (a researcher
or test developer) who selects a specific ques-
tion type and a narrative context for the prob-
lem. Then, a text expressing the probability
problem is generated. The user can tune the
generated text by setting the values of some
linguistic variation parameters. By varying
the mathematical content of the exercise, its
narrative context and the linguistic parameter
settings, many different exercises can be pro-
duced. Here we focus on the natural language
generation part of Genpex. After describing
how the system works, we briefly present our
first evaluation results, and discuss some as-
pects requiring further investigation.
1 Introduction
Narrative exercises (also called word problems or
story problems) are mathematical exercises embed-
ded in a story or text. They are commonly used as
test items, to assess or train a student?s understand-
ing of the underlying mathematical concepts. When
solving a narrative exercise, the student is required
to derive the underlying mathematical question from
the story and to calculate the correct answer to this
mathematical problem.
This paper presents Genpex, a system for generat-
ing narrative exercises expressing probability prob-
lems. Genpex was created in the context of an inter-
national project on item generation for testing stu-
dent competencies in solving probability problems.
Automatic item generation is an effective way of
constructing many items with controlled difficulties,
based on a set of predefined task parameters (Enright
et al, 2002; Deane and Sheehan, 2003; Arendasy et
al., 2006; Holling et al, 2009). The goal of our item
generation project is to develop a model to support
optimal problem and test construction. A large col-
lection of narrative exercises is needed to test the de-
veloped models in field trials. All of these narrative
exercises should be different, but the properties that
define the difficulty of the exercise should be known.
Genpex was designed to enable easy creation of new
exercises meeting these requirements.
Figure 1 shows a narrative probability exercise
generated by Genpex. The text of the exercise is in
German, because the target group of our project are
German high school students. The texts produced
by Genpex are based on a set of example narrative
exercises that were created earlier within the project
(Zeuch, In preparation).
A property that sets Genpex apart from other
narrative exercise generation systems is that it was
specifically designed to support variation in the gen-
erated exercises. Unlike other systems, it not only
changes the context of the narrative exercise (e.g.,
instead of bikes, the example exercise could also
have been about hotel rooms with different proper-
ties) but it also varies the way the texts are formu-
lated. Most existing systems for narrative exercise
generation use fixed sentence templates to express
mathematical content, which means that the same
content is always expressed in the same way (Fa-
20
In einer gro?en Halle ist eine Mischung von Fahrra?dern. In a big hall there are a variety of bicycles.
Es gibt insgesamt 100 Fahrra?der. There are 100 bicycles in total.
Es gibt 30 gru?ne Fahrra?der und es gibt 70 wei?e. 40
Fahrra?der sind Mountainbikes, 50 sind Rennra?der und
es gibt 10 Hollandra?der. 70 Fahrra?der sind billiger als
500 Euro und 30 Fahrra?der teurer als 500 Euro. 41
Fahrra?der sind billiger als 500 Euro und sind Rennra?der.
There are 30 green bicycles and there are 70 white ones.
40 bicycles are mountain bikes, 50 are road bikes, and
there are 10 Dutch bikes. 70 bicycles are less expensive
than 500 Euros and 30 bicycles more expensive than 500
Euros. 41 bicycles are less expensive than 500 Euros and
are road bikes.
Fahrradtyp und Preis sind abha?ngig voneinander und
alle anderen Merkmale sind unabha?ngig voneinander.
Bicycle type and price are dependent on each other and
all other properties are independent of each other.
Wie gro? ist die Wahrscheinlichkeit, dass ein Fahrrad
nicht sowohl ein Mountainrad als auch gru?n ist?
What is the probability that a bicycle is not both a moun-
tain bike and green?
Wie gro? ist die Wahrscheinlichkeit, dass ein Fahrrad
entweder billiger als 500 Euro oder ein Rennrad ist?
What is the probability that a bicycle is either cheaper
than 500 Euros or a road bike?
Figure 1: The text of an exercise generated by Genpex. (Left: German original, right: English translation.)
iron and Williamson, 2002; Arendasy et al, 2006;
Holling et al, 2009). A system that uses a linguisti-
cally sophisticated approach, thus in principle allow-
ing for similar text variations as Genpex, is Model-
Creator (Deane and Sheehan, 2003; Higgins et al,
2005). However, this system focuses on semantic
factors influencing the expression of events with dif-
ferent participants (e.g., different types of vehicles)
rather than on generating linguistic variations.
Below, we first describe how a probability prob-
lem is constructed by Genpex, based on input by the
user. Then we explain in some detail how the nat-
ural language generation (NLG) module of Genpex
creates a text expressing the probability problem, fo-
cusing on the creation of variation in the generated
texts. We end with a brief discussion of our first
evaluation results and some pointers to future work.
2 Probability Problems
Figure 2 presents the probability problem underly-
ing the narrative exercise of Figure 1. It specifies the
context, the total number of entities (numEntities),
and the distribution of (combinations of) attribute
values over the entities. Number information may be
suppressed so as not to give the answer away; this is
done by inserting a question mark in the place of the
number (e.g., colour[green] = ?). Explicitly listing
such ?hidden? information in the probability prob-
lem ensures that all possible values of each attribute
are mentioned in the text of the exercise. A basic as-
sumption in creating the probability problems is that
all entities have exactly one value for each attribute.
For example, all bikes must have some colour, and
they cannot have two colours at the same time.
In addition to the number statements, the proba-
bility problem also lists which pairs of attributes are
dependent on each other. In the example, these are
type and price. This means that if we look at the
subset of bikes of a specific type, the probability that
one of these bikes has a certain price is not the same
as when we look at the entire collection of bikes (and
vice versa). If a pair of attributes is not specified as
being dependent, it is independent.
Q delineates the question part of the probability
problem; we refer to the other parts (except Con-
text) as ?statements?. All questions require the cal-
culation of a probability. A question of the form Q:
P(A) asks for the probability of event A, which can
be described as ?Someone randomly draws one en-
tity out of a (sub)set of entities and this entity has
property A?. For example, the question could be to
calculate the probability that a bike is black if we
randomly pick one bike from the set of all bikes. We
equate the probability of event A with the relative
frequency of the set A of objects that satisfy prop-
erty A, computed as |A|/|U |, where U is the set of
all entities (that is, |U | = numEntities). In general,
the set we draw from is the entire set of entities, but
this set can be limited by a conditional statement:
the event A|B can be described as ?Someone ran-
domly draws one entity with property A from a sub-
set of entities that have property B?. In this case, the
21
Context: bikes
numEntities: 100
colour[green] = 30
colour[white] = 70
type[mountainbike] = 40
type[sportsbike] = 50
type[hollandbike] = 10
price[<500] = 70
price[>500] = 30
price[<500] ? type[sportsbike] = 41
dependentAttributes: price & type
Q: P(?(type[mountainbike] ? colour[green]))
Q: P(price[<500] ? type[sportsbike])
Figure 2: The probability problem underlying Figure 1.
probability P (A|B) is computed as |A?B|/|B|. All
events involve a single draw of exactly one entity.
Probability problems such as the one in Figure 2
are automatically created by Genpex; the only thing
the user has to do is to select one or more question
types (defining the difficulty of the exercise) and a
context for the exercise. All available question types
are of the form P(A) or P(A|B), where A (but not B)
can be a complex event, i.e., involving a conjunc-
tion or disjunction of properties. For example, Q:
P(A ? B) asks for the probability that an entity has
both property A and property B. Moreover, parts of
a question can be negated.
Currently, Genpex can handle 25 different ques-
tion types. Some restrictions we put on the avail-
able questions are the following. Each question in-
volves at most two different attributes, to avoid com-
plex dependencies. There are no recursive questions
(e.g., double negations) and no conditional questions
about independent attributes. Finally, we exclude
questions that are likely to result in ambiguous lan-
guage. For example, if we try to express the ques-
tion Q: P(? (colour[white]) ? type[sportsbike]) in
English, it will be something like ?What is the prob-
ability that a bike is not white and a road bike??.
Due to scope ambiguity of the negation, this sen-
tence may be misinterpreted as ?What is the prob-
ability that a bike is not white and also not a road
bike??. The same ambiguity is found in the Ger-
man sentence expressing this question.1 Excluding
1Genpex does include a re-ordered, mathematically equi-
these types of questions does not simplify the task
for Genpex; the excluded questions are not more dif-
ficult to generate than the included ones. The main
reason to exclude certain question types was to avoid
creating exercises that might be unclear to the reader.
In addition to selecting one or more question
types as input for Genpex, the user also selects a
context for the exercise. As a resource, Genpex uses
a repository of context files2 with information con-
cerning the entities that the exercise should be about
(?bikes? in our example) and the properties they may
have. Each attribute in the context file is linked to
a lexical lemma for the word that expresses its rela-
tion to the entity (e.g., bikes are of a certain colour
or type but have a certain price). Similarly, for each
attribute, a list of possible attribute values and the
words expressing them is provided. For example,
the type attribute in the bikes context can have the
values ?mountainbike?, ?sportsbike?, ?hollandbike?
and ?seniorbike?, respectively associated with the
words ?Mountainbike? (mountain bike), ?Rennrad?
(road bike), ?Hollandrad? (Dutch bike) and ?Se-
niorenrad? (senior bike). Other NLG-related infor-
mation in the context files is discussed in Section 3.
The context file also specifies world knowledge such
as the range of numEntities (a context about rooms
in a hotel will involve fewer entities than a context
about books in a bookshop) and possible dependen-
cies between attributes (in the bikes context, price is
more likely to be dependent on type than on colour).
Taking the selected question type(s) and context
as input, Genpex automatically constructs a proba-
bility problem. This involves selecting a number of
attributes and values, depending on the question or
questions that need to be answered, and creating a
correct and complete world: an internal represen-
tation of the situation in which all entities are fully
defined (all their properties are known), and there
are no inconsistencies. A part of this world is re-
flected in the statements of the probability problem.
Currently, all statements provide information that is
valent version of the same question: Q: P(type[sportsbike] ?
? (colour[white])). Because the generated questions follow the
order of the attributes in the question specification, this version
can be expressed without ambiguity as ?What is the probability
that a bike is a road bike and not white??
2In the current Genpex prototype, five different contexts are
available. The system comes with an editor for the creation of
new context files.
22
required to solve the exercise; redundant informa-
tion is not included. If the user manually edits the
generated probability problem, Genpex reconstructs
the world, and tries to solve the exercise using the in-
formation in the edited problem. The user is warned
in case of inconsistencies or missing information. A
warning is also issued if the edited problem contains
properties for which no lexical information is avail-
able. See Boer Rookhuiszen (2011) for more details
on how probability problems are constructed.
3 Language Generation
The NLG process of Genpex has two goals: generat-
ing a correct textual representation of a given prob-
ability problem, and enabling variation, so that mul-
tiple runs will result in different texts. The gener-
ated texts should be in grammatically correct Ger-
man, and they must be unambiguous: the formula-
tion of the text should not leave the reader uncertain
about the underlying mathematical exercise.
An overview of the NLG component of Genpex
is given in Figure 3. Its architecture reflects the lan-
guage generation pipeline of Reiter and Dale (2000),
with three modules: Document Planner, Microplan-
ner and Surface Realizer. Information between the
modules is exchanged in the form of a list of sen-
tence trees, each defining the content and grammat-
ical structure of a sentence. The Document Planner
creates basic sentence trees. These are manipulated
by the Microplanner to create variations. The mi-
croplanning stage can in principle be skipped, but
that will result in very monotonous texts. Finally,
the Surface Realizer applies the correct morphology
to the sentence trees and creates the layout of the
text. Below, we discuss each module in turn.
3.1 Document Planning: Creating Basic
Sentence Structures
The input of the Document Planner is a probability
problem, which defines the content and the structure
of the narrative exercise. The output is a document
plan: a structured list of sentence trees expressing
the statements and questions in the probability prob-
lem. The document plan also includes an introduc-
tion: a simple ?canned? text specified in the context
file. If multiple introduction texts are available, one
is randomly selected.
Figure 3: The NLG module of Genpex.
The sentences included in the document plan are
all very simple, with the same basic structure. Take
for example the statement colour[white] = 70. The
Document Planner first creates a subject NP ex-
pressing the number of entities involved, e.g., ?70
Fahrra?der? (70 bicycles). Then it creates a VP ex-
pressing the relation and the attribute value, e.g.,
?sind wei?? (are white). The relevant words and
their parts of speech are looked up in the context
file. For the example statement, this process results
in the following basic tree, shown in a simplified no-
tation. Note that the words in the tree have not yet
been inflected.
[s]
[np grammaticalRole=su]
[det grammaticalRole=num]70[/det]
[noun grammaticalRole=hd]Fahrrad[/noun]
[/np]
[vp]
[verb grammaticalRole=hd]sind[/verb]
[adj grammaticalRole=predc]weiss[/adj]
[/vp]
[/s]
All sentence trees for questions start with the
phrase ?Wie gro? ist die Wahrscheinlichkeit dass?
(What is the probability that), included as canned
text in a tree node with syntactic category ?clause?.
23
This main clause is followed by an indefinite NP re-
ferring to the type of entities discussed in the exer-
cise, e.g., ?ein Fahrrad? (a bicycle). The structure
of the rest of the sentence tree depends on the ques-
tion type. Sentence tree templates are available for
all possible question types. They can be used recur-
sively: slots in the templates can be filled with an
expression for an attribute value, or with one of the
other templates.
Figure 4 shows the construction of a sentence tree
for a fairly complex question of type P(A ? B |
? C), using multiple question templates. For ques-
tions about conditional probabilities Genpex uses
the slightly formal ?vorausgesetzt? (given that), be-
cause simpler phrasings are likely to be ambiguous.
For example, assume we want to ask the question
Q: P(type[mountainbike] | colour[green]). A sim-
ple way to ask this question would be ?Wie gro?
ist die Wahrscheinlichkeit dass ein gru?nes Fahrrad
ein Mountainbike ist?? (What is the probability that
a green bike is a mountain bike?). However, such
a question could be mistakenly interpreted as ask-
ing for a joint probability: Q: P(colour[green] ?
type[mountainbike]). For this reason, the more com-
plex formulation is preferred.
3.2 Microplanning: Creating Variation
The Microplanner modifies the sentence trees pro-
duced by the Document Planner by applying a num-
ber of variation techniques. These techniques
place specific requirements on the sentences to
which they can be applied, and therefore not every
technique can be applied to all sentence trees.
When introducing variation in the narrative form
of the exercise, it is important that variations of the
same exercise should all have the same meaning
and approximately the same difficulty. According to
Deane and Sheehan (2003), it is possible to change
the wording of a text without changing its difficulty.
Reiter and Dale (2000) state that for example ag-
gregating multiple sentences does not change the in-
formation they express, but improves the readabil-
ity and fluency of the text. This is what we want
to achieve: adding variation to the text without af-
fecting its interpretation. Genpex therefore uses
aggregation as well as a number of text variation
techniques, assuming that they do not influence the
meaning or difficulty of an exercise.
Figure 4: Construction of a question combining multiple
templates. Translation, with brackets marking the tem-
plate boundaries: ?What is the probability that a bicycle
[[is either black or white] given that this bicycle [is not a
mountainbike]]??
Below we discuss the operations applied to basic
sentence trees in the Microplanner. They are only
applied to sentences expressing statements, even
though it would be practically possible to apply
some of the variations to the questions too. Given
that understanding the question is crucial for solv-
ing the exercise, and that varying the way the ques-
tions are asked might cause confusion, we chose to
adhere to a fixed format for the questions, cf. Fairon
and Williams (2002).
Aggregation. As a first step, the Microplanner
applies aggregation: grouping multiple simple sen-
tences and combining them into one complex sen-
tence. This process leaves the original order of the
sentences in the Document Plan intact. Sentences
referring to different attributes are never grouped to-
gether, to avoid possible misinterpretations. For ex-
ample, a complex sentence such as ?70 bicycles are
white and 40 bicycles are mountain bikes? might
suggest that the 40 mountain bikes are different en-
tities than the 70 white bikes, excluding the possibil-
ity of white mountain bikes. Since this is not the in-
tended meaning, we avoid creating this kind of com-
plex sentences. Sentences referring to the same at-
tribute can be grouped together without risk, because
there can never be any overlap between the sets of
entities mentioned in these sentences (an entity can-
not have multiple values for the same attribute).
Aggregation is performed on a maximum of three
sentences to prevent the generation of overly large
conjunctions. Groups of four basic sentences are ag-
24
gregated into two new complex sentences. This way
we avoid creating unbalanced texts like example 1
below, preferring to generate sentences that are sim-
ilar in both length and complexity, as in example 2.
1. 42 Fahrra?der sind Mountainbikes, 168 Fahrra?der
sind Rennra?der und 200 Fahrra?der sind Hol-
landra?der. 10 Fahrra?der sind Seniorenra?der.
(42 bicycles are mountain bikes, 168 bicycles are
road bikes, and 200 bicycles are Dutch bikes. 10
bicycles are senior bikes.)
2. 42 Fahrra?der sind Mountainbikes und 168 Fahrra?der
sind Rennra?der. 200 Fahrra?der sind Hollandra?der
und 10 Fahrra?der sind Seniorenra?der.
(42 bicycles are mountain bikes and 168 bicycles
are road bikes. 200 bicycles are Dutch bikes and 10
bicycles are senior bikes.)
Aggregation in Genpex is not optional; it is al-
ways applied under the assumption that this will
make the generated texts more coherent and pleas-
ant to read. Moreover, it enables variation through
ellipsis, as discussed later in this section. Variations
in aggregation can be achieved by manually reorder-
ing the statements in the probability problem. This
will lead to a different Document Plan and as a con-
sequence, to different aggregations, within the re-
strictions stated above.
Adjectivication. The text variation technique we
call ?adjectivication? changes the position and gram-
matical role of the adjective (if any) expressing the
attribute value in a sentence. In basic sentence trees,
attribute values expressed by adjectives are included
as predicative complements in the VP. If we apply
adjectivication to a sentence, the adjective is instead
added as a modifier to the subject NP, and the orig-
inal verb is removed. To make the sentence tree
complete again, the words ?Es gibt? (There are?)
are added in front. For example, the sentence ?30
Fahrra?der sind gru?n? (30 bicycles are green) will be
changed to ?Es gibt 30 gru?ne Fahrra?der? (There are
30 green bikes). In German, adjectivication may
cause the inflection of the adjective to change, be-
cause it gets a different grammatical role: when used
as a modifier its inflection reflects the gender and
case of the noun it modifies. This is taken care of by
the Surface Realizer.
Entity substitution. In case an attribute value
is expressed as a noun, e.g., ?Rennrad? (road bike)
the text variation technique we call ?entity substitu-
tion? can be applied. It involves replacing the noun
that represents the entity in a basic sentence with the
noun that represents the attribute value. As with ad-
jectivication, the original verb is removed and in-
stead ?Es gibt? (There are) is added to the sentence.
For example, entity substitution changes the basic
sentence ?50 Fahrra?der sind Rennra?der? (50 bicycles
are road bikes) to ?Es gibt 50 Rennra?der? (There are
50 road bikes).
Marked word order. Another source of variation
is topicalizing the phrase expressing the attribute
value by moving it to the front of the sentence.
Applying this variation technique changes the ba-
sic sentence ?30 Fahrra?der sind teurer als 500 Euro?
(30 bicycles are more expensive than 500 Euros) to
?Teurer als 500 Euro sind 30 Fahrra?der? (More ex-
pensive than 500 Euros are 30 bicycles). Since using
such a marked word order may come across as un-
natural in a neutral discourse context, this type of
variation should be applied with caution.
Ellipsis. This is the removal of duplicate words
from sentences, which typically applies to aggre-
gated sentences (Harbusch and Kempen, 2009).
Genpex can apply different types of ellipsis, such as
Gapping and Conjunction Reduction. Gapping is the
removal of all except the first verb in an aggregated
sentence. An example from Figure 1 is the sen-
tence ?70 Fahrra?der sind billiger als 500 Euro und
30 Fahrra?der teurer als 500 Euro? (70 bicycles are
less expensive than 500 Euros and 30 bicycles more
expensive than 500 Euros), where the verb ?sind?
(are) has been deleted from the second clause. (For-
ward) Conjunction Reduction deletes the subject of
subsequent clauses if it is identical to the subject of
the first clause. The following sentence is an exam-
ple: ?40 Fahrra?der sind Mountainbikes und 50 sind
Rennra?der? (40 bicycles are mountain bikes and 50
are road bikes). It is possible to combine Gapping
and Conjunction Reduction, e.g., ?40 Fahrra?der sind
Mountainbikes und 50 Rennra?der? (40 bicycles are
mountain bikes and 50 road bikes).
Ellipsis is also possible in sentences with marked
word order. For example, ?Gru?n sind 30 Fahrra?der
und wei? sind 40 Fahrra?der?(Green are 30 bicycles
and white are 40 bicycles) could be reduced to
?Gru?n sind 30 Fahrra?der und wei? sind 40? (Green
25
are 30 bicycles and white are 40). However, in
this sentence, the verb cannot be removed from the
last clause. Genpex currently allows aggregated
sentences in which some of the clauses have
marked word order. In these cases, ellipsis is
not applied, because it will most likely result in
grammatically incorrect sentences. For example, in
the sentence ?30 Fahrra?der sind gru?n und Wei? sind
40 Fahrra?der? (30 bicycles are green and white are
40 bicycles) the system will not apply ellipsis.
For every sentence in the document plan, the sys-
tem will check which of the variation techniques de-
scribed above can be applied to it, by analyzing the
structure of the sentence tree. If a technique is in
principle applicable, the probability of it being ac-
tually applied depends on information in the context
file, and on parameters set by the user through the
GUI of Genpex. For every attribute in the context
file, the author of the file can prevent Genpex from
applying a specific technique by giving it a probabil-
ity of 0, if it is never suitable in the case of this spe-
cific attribute. For example, applying marked word
order to a sentence expressing the ?type? attribute in
the bikes context would lead to odd sentences such
as ?Mountainbikes sind 40 Fahrra?der? (Mountain-
bikes are 40 bicycles). Though grammatically cor-
rect, such sentences would be hard to interpret and
therefore are best avoided.
During generation, the user can directly influ-
ence the probability that certain variations are ap-
plied through sliders in the GUI; see Figure 5. The
probability holds for every sentence that satisfies the
structural requirements of the variation technique
in question, unless the technique is excluded based
on the information in the context file, as explained
above. After having set the variation probabilities,
the user can click ?Update Text? to see the effect.
The user can also choose to have the text automati-
cally updated every time a slider is moved.
When the user saves a generated exercise, infor-
mation about the variation techniques that have been
applied is logged and saved together with the exer-
cise. If further research shows that a certain varia-
tion technique has an unintended influence on exer-
cise difficulty, it will be easy to exclude this tech-
nique from the creation of new exercises by setting
its probability to 0 in the GUI.
3.3 Surface Realisation: the Final Polish
The main task of the Surface Realizer is to convert
the sentence trees that have been manipulated by the
Microplanner to actual text, applying correct mor-
phology and orthography.
Information about German morphology is re-
trieved from a lexicon listing the possible word
forms of each lemma in the context files. German
has a rich inflectional system compared to English,
with suffixes reflecting the gender, number and case
of determiners, adjectives and nouns. Gender can be
masculine, feminine or neuter, number is singular or
plural, and case is nominative, accusative, dative or
genitive. In the type of exercises currently generated
by Genpex, all words are in nominative case. Num-
ber information for nouns and verbs is given in the
sentence tree, while the inflection of determiners and
adjectives in an NP depends on the properties of the
noun. For the inflection of adjectives, Genpex also
has to consider the determiner that is used before
the adjective. In German, so-called ?strong inflec-
tion? has to be used after a cardinal number, ?weak
inflection? after a definite determiner and ?mixed in-
flection? after an indefinite determiner. We currently
use canoonet3 as the source for German morpholog-
ical information in Genpex.
Orthography is the process that converts the sen-
tence trees to text. This is quite easy, because the
word order is already defined by the tree structure.
All values of the nodes in the tree can be joined
together in a sentence in that order, separated by
white spaces. The clauses in aggregated sentences
are joined by a comma, except for the last conjunc-
tion where the word ?und? is used. A characteristic
of German is that all nouns are capitalized. The Sur-
face Realiser takes care of this, and also of the cap-
italization of the first word in each sentence, punc-
tuation and the placement of paragraph boundaries.
The generated texts are marked up with HTML for
easy display in web browsers.
4 Evaluation
Potential users of Genpex (researchers working on
test design) have been involved at different stages
of development of the system, such as requirements
specification and usability testing. Field trials with
3http://www.canoo.net/
26
Figure 5: Screenshot of the GUI of Genpex, showing a variation of the narrative exercise in Figure 1. The introductory
text was taken from Zeuch (In preparation).
students are future work, but we did carry out some
preliminary, qualitative evaluations with a few na-
tive speakers of German (including one item gen-
eration expert) to test the grammaticality and un-
derstandability of the generated exercises. This re-
vealed some small mistakes that have since been cor-
rected, but also a few bigger problems with some of
the variation techniques and other NLG aspects.
One of the things noted by the native speakers was
that applying ellipsis sometimes leads to slightly un-
natural sentences. The preferred type and degree of
ellipsis is different for each type of sentence, but this
is not taken into account by Genpex. As a conse-
quence, the system frequently applies too much or
too little ellipsis to the generated sentences, with less
than ideal (though not ungrammatical) results. The
existence of such preferred formulations is in line
with the results of Cahill and Forst (2010), who car-
ried out an experiment in which native speakers of
German evaluated a number of alternative realisa-
tions of the same sentence. Their subjects accepted
some variation in word order, but showed a clear
preference for some of the alternatives.
Some of the generated question sentences also
sounded a bit forced to the native speakers. For ex-
ample, the question template for joint probabilities
(A?B) uses the formal phrasing ?sowohl... als auch?
(both ... and), whereas a simple ?und? (and) would
be the more natural choice for most questions. How-
ever, in some question contexts, in particular those
involving negations, using the simpler formulation
might lead to the kind of scope ambiguities men-
tioned in Section 2. Therefore, the choice was made
to use ?sowohl... als auch? in all cases, even in those
where it is not strictly necessary. Similarly, ques-
tions asking for a conditional probability were found
to be somewhat difficult to understand. For these
questions, readability might be improved by using
27
two sentences to express them, along the lines of
?Consider the set of bicycles that are not mountain
bikes. What is the probability that one of those bi-
cycles is either black or white?? as an alternative to
the more complex formulation given in Figure 4.
The comments by the native speakers suggest that
in some cases, Genpex goes too far in its ?one size
fits all? approach, and that we should try to add
more flexibility to the NLG component, allowing it
to make finer distinctions in the application of varia-
tion techniques to specific sentences and of question
templates to specific question types.
5 Discussion
The texts currently being generated by Genpex are
grammatical, but our native speakers reported that
some sentences had to be studied carefully before it
was possible to get the information needed to solve
the problem. No actual misinterpretations occurred,
but the increased reading time (as compared to more
preferred formulations) may still increase the diffi-
culty of the exercise. A thorough investigation into
the effect of textual variations on item difficulty is
therefore necessary. Genpex supports this type of
research by enabling the systematic application of
different variations, while logging all textual oper-
ations that have been applied and saving them to-
gether with the generated text. The underlying prob-
ability problem is saved together with the text as
well, so all factors that certainly or potentially in-
fluence item difficulty are known. This makes it rel-
atively easy to test the influence of those factors on
the difficulty of the exercise, for example by carry-
ing out the kind of statistical and cognitive analysis
advocated by Graf et al (2005).
The effect of the main parameters of the proba-
bility problems in Genpex (i.e., the type of question
being asked) was already statistically analyzed by
Holling et al (2009) and Zeuch (In preparation).
They used automatically generated items similar to
the exercises generated by Genpex, except that their
exercises did not have variations in wording apart
from context-related ones. Also, the exercises used
by Holling et al (2009) mentioned probabilities in-
stead of counts in the statements.
Once we know more about the effects of the tex-
tual variations, Genpex can be of great value to test
developers, given that there exists a great need for
large amounts of learning and assessment materi-
als with a controlled level of difficulty (Enright et
al., 2002; Fairon and Williamson, 2002; Deane and
Sheehan, 2003; Arendasy et al, 2006; Holling et al,
2008; Holling et al, 2009). The initial development
and testing of the system is a one-time investment,
which we expect will pay off afterward when large
amounts of test items can be created with little effort.
In particular, we think Genpex can be very useful
in combination with Computerized Adaptive Test-
ing (CAT). The system could be used for on-the-fly
generation of new items for each individual student,
adapted to that student?s skill level estimated from
his or her previous answers. Because every student
gets custom exercises, the risk of frequently used
items becoming known among students is reduced,
thus increasing test security.
In principle, given that the factors influencing
item difficulty are known, generating difficult items
is not more complicated than generating easy ones.
However, as illustrated in Section 2, combining mul-
tiple difficulty factors such as negation and joint
probability may lead to textual formulations that are
ambiguous or hard to understand, and which ? if not
successfully prevented in advance ? may need to be
filtered out or corrected by hand. For that reason,
Genpex seems most suitable for the generation of
exercises up to a moderate level of complexity. Still,
even if the need for hand-crafting will not be com-
pletely eliminated, reducing it to complex items that
require particularly careful wording already repre-
sents a big gain in efficiency.
Acknowledgements
We thank our anonymous reviewers and everybody
who helped testing Genpex. Special thanks go
to our colleagues from the University of Mu?nster
for providing the reference exercises on which
the Genpex output was modelled. This research
was funded by the Deutsche Forschungsgemein-
schaft (DFG), Schwerpunktprogramm ?Kompetenz-
modelle zur Erfassung individueller Lernergebnisse
und zur Bilanzierung von Bildungsprozessen? (SPP
1293), project ?Rule-based Item Generation of Al-
gebra Word Problems Based upon Linear Logistic
Test Models for Item Cloning and Optimal Design?.
28
References
Martin Arendasy, Markus Sommer, Georg Gittler, and
Andreas Hergovich. 2006. Automatic generation of
quantitative reasoning items: A pilot study. Journal of
Individual Differences, 27(1):2?14.
Roan Boer Rookhuiszen. 2011. Generation of German
narrative probability excercises. Master?s thesis, Uni-
versity of Twente.
Aiofe Cahill and Martin Forst. 2010. Human evaluation
of a German surface realisation ranker. In E. Krahmer
and M. Theune, editors, Empirical Methods in Natural
Language Generation, volume 5790 of Lecture Notes
in Computer Science, pages 201?221. Springer, Berlin
/ Heidelberg.
Paul Deane and Kathleen Sheehan. 2003. Automatic
item generation via frame semantics: Natural language
generation of math word problems. Educational Test-
ing Service, Princeton. Paper presented at the Annual
Meeting of the National Council on Measurement in
Education (Chicago, IL, April 22-24, 2003).
Mary K. Enright, Mary Morley, and Kathleen M. Shee-
han. 2002. Items by design: The impact of systematic
feature variation on item statistical characteristics. Ap-
plied Measurement in Education, 15(1):49?74.
Ce?drick Fairon and David M. Williamson. 2002. Auto-
matic item text generation in educational assessment.
In Proceedings of TALN 2002, pages 395?401.
Edith Aurora Graf, Stephen Peterson, Manfred Steffen,
and Rene? Lawless. 2005. Psychometric and cogni-
tive analysis as a basis for the design and revision of
quantitative item models. Technical Report RR-05-25,
Educational Testing Service, Princeton.
Karin Harbusch and Gerard Kempen. 2009. Generating
clausal coordinate ellipsis multilingually: A uniform
approach based on postediting. In Proceedings of the
12th European Workshop on Natural Language Gen-
eration, pages 138?145.
Derrick Higgins, Yoko Futagi, and Paul Deane. 2005.
Multilingual generalization of the ModelCreator soft-
ware for math item generation. Technical Report RR-
05-02, Educational Testing Service, Princeton.
Heinz Holling, Helen Blank, Karoline Kuchenba?cker,
and Jo?rg-Tobias Kuhn. 2008. Rule-based item design
of statistical word problems: A review and first imple-
mentation. Psychology Science Quarterly, 50(3):363?
378.
Heinz Holling, Jonas P. Bertling, and Nina Zeuch. 2009.
Automatic item generation of probability word prob-
lems. Studies In Educational Evaluation, 35(2-3):71?
76.
Ehud Reiter and Robert Dale. 2000. Building Natural
Language Generation Systems. Cambridge University
Press, Cambridge, UK.
Nina Zeuch. In preparation. Rule-based item construc-
tion: Analysis with and comparison of linear logistic
test models and cognitive diagnostic models with two
item types. Ph.D. thesis, University of Mu?nster.
29
