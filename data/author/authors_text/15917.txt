Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 63?68,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Fluid Construction Grammar:
The New Kid on the Block
Remi van Trijp1, Luc Steels1,2, Katrien Beuls3, Pieter Wellens3
1Sony Computer Science 2ICREA Institute for 3 VUB AI Lab
Laboratory Paris Evolutionary Biology (UPF-CSIC) Pleinlaan 2
6 Rue Amyot PRBB, Dr Aiguidar 88 1050 Brussels (Belgium)
75005 Paris (France) 08003 Barcelona (Spain) katrien|pieter@
remi@csl.sony.fr steels@ai.vub.ac.be ai.vub.ac.be
Abstract
Cognitive linguistics has reached a stage
of maturity where many researchers are
looking for an explicit formal grounding
of their work. Unfortunately, most current
models of deep language processing incor-
porate assumptions from generative gram-
mar that are at odds with the cognitive
movement in linguistics. This demonstra-
tion shows how Fluid Construction Gram-
mar (FCG), a fully operational and bidi-
rectional unification-based grammar for-
malism, caters for this increasing demand.
FCG features many of the tools that were
pioneered in computational linguistics in
the 70s-90s, but combines them in an inno-
vative way. This demonstration highlights
the main differences between FCG and re-
lated formalisms.
1 Introduction
The ?cognitive linguistics enterprise? (Evans
et al 2007) is a rapidly expanding research dis-
cipline that has so far avoided rigorous formal-
izations. This choice was wholly justified in the
70s-90s when the foundations of this scientific
movement were laid (Rosch, 1975; Lakoff, 1987;
Langacker, 1987), and it remained so during the
past two decades while the enterprise worked on
getting its facts straight through empirical stud-
ies in various subfields such as language acqui-
sition (Tomasello, 2003; Goldberg et al 2004;
Lieven, 2009), language change and grammati-
calization (Heine et al 1991; Bar?dal and Chel-
liah, 2009), and corpus research (Boas, 2003; Ste-
fanowitsch and Gries, 2003). However, with nu-
merous textbooks on the market (Lee, 2001; Croft
and Cruse, 2004; Evans and Green, 2006), cogni-
tive linguistics has by now established itself as a
serious branch in the study of language, and many
cognitive linguists are looking for ways of explic-
itly formalizing their work through computational
models (McClelland, 2009).
Unfortunately, it turns out to be very difficult
to adequately formalize a cognitive linguistic ap-
proach to grammar (or ?construction grammar?)
using the tools for precision-grammars developed
in the 70s-90s such as unification (Kay, 1979;
Carpenter, 1992), because these tools are typi-
cally incorporated in a generative grammar (such
as HPSG; Ginzburg and Sag, 2000) whose as-
sumptions are incompatible with the foundations
of construction grammar. First, cognitive linguis-
tics blurs the distinction between ?competence?
and ?performance?, which means giving up the
sharp distinction between declarative and proce-
dural representations. Next, construction gram-
marians argue for a usage-based approach (Lan-
gacker, 2000), so the constraints on features may
change and features may emerge or disappear
from a grammar at any given time.
This demonstration introduces Fluid Construc-
tion Grammar (FCG; Steels, 2011, 2012a), a
novel unification-based grammar formalism that
addresses these issues, and which is available as
open-source software at www.fcg-net.org.
After more than a decade of development, FCG
is now ready to handle sophisticated linguistic
issues. FCG revisits many of the technologies
developed by computational linguists and intro-
duces several key innovations that are of inter-
est to anyone working on deep language process-
ing. The demonstration illustrates these innova-
tions through FCG?s interactive web interface.
63
semantic 
pole
syntactic 
pole
transient structure
semantic 
pole
syntactic 
pole
construction
matching phase
first 
merging 
phase
second 
merging 
phase
semantic 
pole
syntactic 
pole
transient structure
semantic 
pole
syntactic 
pole
construction
second
merging
phase
first 
merging 
phase
matching phase
Figure 1: FCG allows the implementation of efficient and strongly reversible grammars. Left: In production,
conditional units of the semantic pole of a construction are matched against a transient structure, before additional
semantic constraints and the syntactic pole are merged with the structure. Right: In parsing, the same algorithm
applies but in the opposite direction.
2 Strong and Efficient Reversibility
Reversible or bidirectional grammar formalisms
can achieve both production and parsing (Strza-
lkowski, 1994). Several platforms, such as the
LKB (Copestake, 2002), already achieve bidirec-
tionality, but they do so through separate algo-
rithms for parsing and production (mainly for effi-
ciency reasons). One problem with this approach
is that there may be a loss of coherence in gram-
mar engineering. For instance, the LKB parser
can handle a wider variety of structures than its
generator.
FCG uses one core engine that handles both
parsing and production with a single linguistic
inventory (see Figure 1). When processing, the
FCG-system builds a transient structure that con-
tains all the information concerning the utterance
that the system has to parse or produce, divided
into a semantic and syntactic pole (both of whom
are feature structures). Grammar rules or ?con-
structions? are coupled feature structures as well
and thus contain a semantic and syntactic pole.
When applying constructions, the FCG-system
goes through three phases. In production, FCG
first matches all feature-value pairs of the seman-
tic pole of a construction with the semantic pole
of the transient structure, except fv-pairs that are
marked for being attributed by the construction
(De Beule and Steels, 2005). Matching is a more
strict form of unification that resembles a sub-
sumption test (see Steels and De Beule, 2006).
If matching is successful, all the marked fv-pairs
of the semantic pole are merged with the tran-
sient structure in a first merge phase, after which
the whole syntactic pole is merged in a second
phase. FCG-merge is equivalent to ?unification?
in other formalisms. The same three-phase algo-
rithm is applied in parsing as well, but this time in
the opposite direction: if the syntactic pole of the
construction matches with the transient structure,
the attributable syntactic fv-pairs and the seman-
tic pole are merged.
3 WYSIWYG Grammar Engineering
Most unification grammars use non-directional
linguistic representations that are designed to be
independent of any model of processing (Sag
and Wasow, 2011). Whereas this may be de-
sirable from a ?mathematical? point-of-view, it
puts the burden of efficient processing on the
shoulders of computational linguists, who have to
find a balance between faithfulness to the hand-
written theory and computational efficiency (Mel-
nik, 2005). For instance, there is no HPSG imple-
mentation, but rather several platforms that sup-
port the implementation of ?HPSG-like? gram-
mars: ALE (Carpenter and Penn, 1995), ALEP
(Schmidt et al 1996), CUF (D?rre and Dorna,
64
top
cxn-applied
top
nominal-adjectival-cxn
sem-subunits  
footprints  
args  
sem-cat  
nominal-adjectival-phrase-1
(word-ballon-1 
word-rouge-1)
(nominal-adjectival-cxn)
(red-ball-15 context-19)
((sem-function 
identifier))
word-
ballon-
1
word-
rouge-
1
word-le-1
sem syn
form  
syn-subunits  
syn-cat  
footprints  
nominal-adjectival-phrase-1
((meets 
word-ballon-1 
word-rouge-1))
(word-ballon-1 
word-rouge-1)
((number singular) 
(gender masculine) 
(syn-function nominal))
(nominal-adjectival-cxn)
word-
rouge-
1
word-
ballon-
1
word-le-1
Figure 2: FCG comes equipped with an interactive web interface for inspecting the linguistic inventory, con-
struction application and search. This Figure shows an example construction where two units are opened up for
closer inspection of their feature structures.
1993), LIGHT (Ciortuz, 2002), LKB (Copestake,
2002), ProFIT (Erbach, 1995), TDL (Krieger and
Sch?fer, 1994), TFS (Emele, 1994), and others
(see Bolc et al 1996, for a survey). Unfortu-
nately, the optimizations and technologies devel-
oped within these platforms are often considered
by theoretical linguists as engineering solutions
rather than scientific contributions.
FCG, on the other hand, adheres to the cogni-
tive linguistics assumption that linguistic perfor-
mance is equally important as linguistic compe-
tence, hence processing becomes a central notion
in the formalism. FCG representations therefore
offer a ?what you see is what you get? approach
to grammar engineering where the representations
have a direct impact on processing and vice versa.
For instance, a construction?s division between a
semantic and syntactic pole is informative with re-
spect to how the construction is applied.
Some grammarians may object that this design
choice forces linguists to worry about process-
ing, but that is entirely the point. It has already
been demonstrated in other unification-based for-
malisms that different grammar representations
have a significant impact on processing efficiency
(Flickinger, 2000). Moreover, FCG-style repre-
sentations can be directly implemented and tested
without having to compromise on either faithful-
ness to a theory or computational efficiency.
Since writing grammars is highly complex,
however, FCG also features a ?design level? on top
of its operational level (Steels, 2012b). On this
level, grammar engineers can use templates that
build detailed constructions. The demonstration
shows how to write a grammar in FCG, switch-
ing between its design level, its operational level
and its interactive web interface (see Figure 2).
The web interface allows FCG-users to inspect the
linguistic inventory, the search tree in processing,
and so on.
4 Robustness and Learning
Unification-based grammars have the reputation
of being brittle when it comes to processing nov-
elty or ungrammatical utterances (Tomuro, 1999).
Since cognitive linguistics adheres to a usage-
based view on language (Langacker, 2000), how-
ever, an adequate formalization must be robust
and open-ended.
A first requirement is that there can be differ-
ent degrees of ?entrenchment? in the grammar:
while some features might still be emergent, oth-
ers are already part of well-conventionalized lin-
guistic patterns. Moreover, new features and con-
structions may appear (or disappear) from a gram-
mar at any given time. These requirements are
hard to reconcile with the type hierarchy approach
of other formalisms, so FCG does not imple-
ment typed feature structures. The demonstra-
tion shows how FCG can nevertheless prevent
over-licensing of linguistic structures through its
matching phase and how it captures generaliza-
tions through its templates ? two benefits typically
associated with type hierarchies.
Secondly, FCG renders linguistic processing
fluid and robust through a meta-level architec-
ture, which consists of two layers of processing,
as shown in Figure 3 (Beuls et al 2012). There
is a routine layer in which constructional process-
ing takes place. At the same time, a meta-layer
65
!"!"
routine processing 
diagnostic 
problem repair 
diagnostic diagnostic diagnostic 
problem 
repair meta-layer processing 
Figure 3: There are two layers of processing in FCG. On the routine level, constructional processing takes place.
At the same time, a meta-layer of diagnostics and repairs try to detect and solve problems that occur in the routine
layer.
is active that runs diagnostics for detecting prob-
lems in routine processing, and repairs for solving
those problems. The demonstration shows how
the meta-layer is used for solving common prob-
lems such as missing lexical entries and coercion
(Steels and van Trijp, 2011), and how its archi-
tecture offers a uniform way of implementing the
various solutions for robustness already pioneered
in the aforementioned grammar platforms.
5 Efficiency
Unification is computationally expensive, and
many technical solutions have been proposed for
efficient processing of rich and expressive fea-
ture structures (Tomuro, 1999; Flickinger, 2000;
Callmeier, 2001). In FCG, however, research
on efficiency takes a different dimension because
performance is considered to be an integral part of
the linguistic theory that needs to be operational-
ized. The demonstration allows conference par-
ticipants to inspect the following research results
on the interplay between grammar and efficiency:
? In line with construction grammar, there is
no distinction between the lexicon and the
grammar. Based on language usage, the lin-
guistic inventory can nevertheless organize
itself in the form of dependency networks
that regulate which construction should be
considered when in processing (Wellens and
De Beule, 2010; Wellens, 2011).
? There is abundant psycholinguistic evidence
that language usage contains many ready-
made language structures. FCG incorporates
a chunking mechanism that is able to cre-
ate such canned phrases for faster processing
(Stadler, 2012).
? Morphological paradigms, such as the Ger-
man case system, can be represented in the
form of ?feature matrices?, which reduce
syntactic and semantic ambiguity and hence
speed up processing efficiency and reliability
(van Trijp, 2011).
? Many linguistic domains, such as spatial lan-
guage, are known for their high degree of
polysemy. By distinguishing between actual
and potential values, such polysemous struc-
tures can be processed smoothly (Spranger
and Loetzsch, 2011).
6 Conclusion
With many well-developed unification-based
grammar formalisms available to the community,
one might wonder whether any ?new kid on the
block? can still claim relevance today. With this
demonstration, we hope to show that Fluid Con-
struction Grammar allows grammar engineers to
unchart new territory, most notably in the relation
between linguistic competence and performance,
and in modeling usage-based approaches to lan-
guage.
66
References
Johanna Bar?dal and Shobhana Chelliah, edi-
tors. The Role of Semantic, Pragmatic and
Discourse Factors in the Development of Case.
John Benjamins, Amsterdam, 2009.
Katrien Beuls, Remi van Trijp, and Pieter
Wellens. Diagnostics and repairs in Fluid Con-
struction Grammar. In Luc Steels, editor, Com-
putational Issues in Fluid Construction Gram-
mar. Springer Verlag, Berlin, 2012.
Hans C. Boas. A Constructional Approach to Re-
sultatives. Stanford Monograph in Linguistics.
CSLI, Stanford, 2003.
Leonard Bolc, Krzysztof Czuba, Anna
Kups?c?, Malgorzata Marciniak, Agnieszka
Mykowiecka, and Adam Przepi?rkowski. A
survey of systems for implementing HPSG
grammars. Research Report 814 of IPI
PAN (Institute of Computer Science, Polish
Academy of Sciences), 1996.
Ulrich Callmeier. Efficient parsing with large-
scale unification grammars. Master?s thesis,
Universit?t des Saarlandes, 2001.
Bob Carpenter. The Logic of Typed Feature Struc-
tures. Cambridge UP, Cambridge, 1992.
Bob Carpenter and Gerald Penn. The Attribute
Logic Engine (Version 2.0.1). Pittsburgh, 1995.
Liviu Ciortuz. LIGHT ? a constraint language and
compiler system for typed-unification gram-
mars. In Proceedings of The 25th German Con-
ferences on Artificial Intelligence (KI 2002),
volume 2479 of LNAI, pages 3?17, Berlin,
2002. Springer-Verlag.
Ann Copestake. Implementing Typed Feature
Structure Grammars. CSLI Publications, Stan-
ford, 2002.
William Croft and D. Alan Cruse. Cognitive Lin-
guistics. Cambridge Textbooks in Linguistics.
Cambridge University Press, Cambridge, 2004.
J. De Beule and L. Steels. Hierarchy in fluid con-
struction grammar. In U. Furbach, editor, Pro-
ceedings of the 28th Annual German Confer-
ence on Artificial Intelligence, volume 3698 of
Lecture Notes in Artificial Intelligence, pages
1?15, Berlin, Germany, 2005. Springer Verlag.
Jochen D?rre and Michael Dorna. CUF ? a
formalism for linguistic knowledge represen-
tation. In Jochen D?rre, editor, Computa-
tional Aspects of Constraint Based Linguistic
Descriptions, volume I, pages 1?22. DYANA-2
Project, Amsterdam, 1993.
Martin C. Emele. The typed feature structure rep-
resentation formalism. In Proceedings of the
International Workshop on Sharable Natural
Language Resources, Ikoma, Nara, 1994.
Gregor Erbach. ProFIT: Prolog with features,
inheritance and templates. In Proceedings of
EACL-95, 1995.
Vyvyan Evans and Melanie Green. Cognitive Lin-
guistics: An Introduction. Lawrence Erlbaum
Associates / Edinburgh University Press, Hills-
dale, NJ/Edinburgh, 2006.
Vyvyan Evans, Benjamin K. Bergen, and J?rg
Zinken. The cognitive linguistics enterprise:
An overview. In V. Evans, B.K. Bergen, and
J. Zinken, editors, The Cognitive Linguistics
Reader. Equinox Publishing, London, 2007.
Daniel P. Flickinger. On building a more efficient
grammar by exploiting types. Natural Lan-
guage Engineering, 6(1):15?28, 2000.
Jonathan Ginzburg and Ivan A. Sag. Interroga-
tive Investigations: the Form, the Meaning, and
Use of English Interrogatives. CSLI Publica-
tions, Stanford, 2000.
Adele E. Goldberg, Devin M. Casenhiser, and
Nitya Sethuraman. Learning argument struc-
ture generalizations. Cognitive Linguistics, 15
(3):289?316, 2004.
Bernd Heine, Ulrike Claudi, and Friederike H?n-
nemeyer. Grammaticalization: A Concep-
tual Framework. University of Chicago Press,
Chicago, 1991.
Martin Kay. Functional grammar. In Proceedings
of the Fifth Annual Meeting of the Berkeley Lin-
guistics Society, pages 142?158. Berkeley Lin-
guistics Society, 1979.
Hans-Ulrich Krieger and Ulrich Sch?fer. TDL ?
a type description language for HPSG. part 1:
Overview. In Proceedings of the 15th Interna-
tional Conference on Computational Linguis-
tics, pages 893?899, Kyoto, 1994.
George Lakoff. Women, Fire, and Danger-
ous Things: What Categories Reveal about
the Mind. The University of Chicago Press,
Chicago, 1987.
67
Ronald W. Langacker. Foundations of Cognitive
Grammar: Theoretical Prerequisites. Stanford
University Press, Stanford, 1987.
Ronald W. Langacker. A dynamic usage-based
model. In Michael Barlow and Suzanne Kem-
mer, editors, Usage-Based Models of Lan-
guage, pages 1?63. Chicago University Press,
Chicago, 2000.
David Lee. Cognitive Linguistics: An Introduc-
tion. Oxford University Press, Oxford, 2001.
Elena Lieven. Developing constructions. Cogni-
tive Linguistics, 20(1):191?199, 2009.
James L. McClelland. The place of modeling in
cognitive science. Topics in Cognitive Science,
1:11?38, 2009.
Nurit Melnik. From ?hand-written? to computa-
tionally implemented HPSG theories. In Ste-
fan M?ller, editor, Proceedings of the HPSG05
Conference, Stanford, 2005. CSLI Publica-
tions.
Eleanor Rosch. Cognitive representations of se-
mantic categories. Journal of Experimental
Psychology: General, 104:192?233, 1975.
Ivan A. Sag and Thomas Wasow. Performance-
compatible competence grammar. In Robert D.
Borsley and Kersti B?rjars, editors, Non-
Transformational Syntax: Formal and Explicit
Models of Grammar, pages 359?377. Wiley-
Blackwell, 2011.
Paul Schmidt, Sibylle Rieder, Axel Theofilidis,
and Thierry Declerck. Lean formalisms, lin-
guistic theory, and applications. grammar de-
velopment in ALEP. In Proceedings of the
16th International Conference on Computa-
tional Linguistics (COLING-96), pages 286?
291, Copenhagen, 1996.
Michael Spranger and Martin Loetzsch. Syntac-
tic indeterminacy and semantic ambiguity: A
case study for German spatial phrases. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar. John Benjamins, Amster-
dam, 2011.
Kevin Stadler. Chunking constructions. In
Luc Steels, editor, Computational Issues in
Fluid Construction Grammar. Springer Verlag,
Berlin, 2012.
Luc Steels, editor. Design Patterns in Fluid Con-
struction Grammar. John Benjamins, Amster-
dam, 2011.
Luc Steels, editor. Computational Issues in
Fluid Construction Grammar. Springer, Berlin,
2012a.
Luc Steels. Design methods for Fluid Construc-
tion Grammar. In Luc Steels, editor, Computa-
tional Issues in Fluid Construction Grammar.
Springer Verlag, Berlin, 2012b.
Luc Steels and Joachim De Beule. Unify and
merge in Fluid Construction Grammar. In
P. Vogt, Y. Sugita, E. Tuci, and C. Nehaniv,
editors, Symbol Grounding and Beyond., LNAI
4211, pages 197?223, Berlin, 2006. Springer.
Luc Steels and Remi van Trijp. How to make con-
struction grammars fluid and robust. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar, pages 301?330. John Ben-
jamins, Amsterdam, 2011.
Anatol Stefanowitsch and Stefan Th. Gries. Col-
lostructions: Investigating the interaction of
words and constructions. International Journal
of Corpus Linguistics, 2(8):209?243, 2003.
Tomek Strzalkowski, editor. Reversible Grammar
in Natural Language Processing. Kluwer Aca-
demic Publishers, Boston, 1994.
Michael Tomasello. Constructing a Language. A
Usage Based Theory of Language Acquisition.
Harvard University Press, 2003.
Noriko Tomuro. Left-Corner Parsing Algorithm
for Unification Grammars. PhD thesis, DePaul
University, Chicago, 1999.
Remi van Trijp. Feature matrices and agree-
ment: A case study for German case. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar, pages 205?236. John Ben-
jamins, Amsterdam, 2011.
Pieter Wellens. Organizing constructions in net-
works. In Luc Steels, editor, Design Patterns in
Fluid Construction Grammar. John Benjamins,
Amsterdam, 2011.
Pieter Wellens and Joachim De Beule. Prim-
ing through constructional dependencies: A
case study in Fluid Construction Grammar.
In A. Smith, M. Schouwstra, Bart de Boer,
and K. Smith, editors, The Evolution of Lan-
guage (EVOLANG8), pages 344?351, Singa-
pore, 2010. World Scientific.
68
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 127?132,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Fluid Construction Grammar for Historical and Evolutionary Linguistics
Pieter Wellens1, Remi van Trijp2, Katrien Beuls1, Luc Steels2,3
1VUB AI Lab 2Sony Computer Science 3 ICREA Institute for
Pleinlaan 2 Laboratory Paris Evolutionary Biology (UPF-CSIC)
1050 Brussels (Belgium) 6 Rue Amyot PRBB, Dr Aiguidar 88
pieter|katrien@ 75005 Paris (France) 08003 Barcelona (Spain)
ai.vub.ac.be remi@csl.sony.fr steels@ai.vub.ac.be
Abstract
Fluid Construction Grammar (FCG) is an
open-source computational grammar for-
malism that is becoming increasingly pop-
ular for studying the history and evolution
of language. This demonstration shows
how FCG can be used to operationalise the
cultural processes and cognitive mecha-
nisms that underly language evolution and
change.
1 Introduction
Historical linguistics has been radically trans-
formed over the past two decades by the ad-
vent of corpus-based approaches. Ever increas-
ing datasets, both in size and richness of anno-
tation, are becoming available (Yuri et al, 2012;
Davies, 2011), and linguists now have more pow-
erful tools at their disposal for uncovering which
changes have taken place. In this demonstration,
we present Fluid Construction Grammar (Steels,
2011, FCG), an open-source grammar formalism
that makes it possible to also address the question
of how these changes happened by uncovering the
cognitive mechanisms and cultural processes that
drive language evolution.
FCG combines the expressive power of fea-
ture structures and unification with the adaptiv-
ity and robustnes of machine learners. In sum,
FCG aims to be an open instrument for de-
veloping robust and open-ended models of lan-
guage processing that can be used for both pars-
ing and production. FCG can be downloaded at
http://www.fcg-net.org.
2 Design Philosophy
Fluid Construction Grammar is rooted in a
cognitive-functional approach to language, which
is quite different from a generative grammar such
as HPSG (Pollard and Sag, 1994). A genera-
tive grammar is a model of language competence
that licenses well-formed structures and rejects ill-
formed utterances. Such grammars often decide
on the well- or ill-formedness of utterances by us-
ing a strong type system that defines a set of fea-
tures and possible values for those features. The
burden of efficient and robust language process-
ing with a generative grammar largely rests on the
shoulders of the language processor.
A cognitive-functional grammar, on the other
hand, functions more like a transducer between
meaning and form. In parsing, such a grammar
tries to uncover as much meaning as possible from
a given utterance rather than deciding on its gram-
maticality. In the other direction, the grammar
tries to produce intelligible utterances, which are
well-formed as a side-effect if the grammar ad-
equately captures the conventions of a particular
language. A cognitive-functional grammar can
best be implemented without a strong type system
because the set of possible features and values for
them is assumed to be open-ended. Efficient and
robust language processing also becomes a joint
responsibility of the grammar and the linguistic
processor.
3 Reversible Language Processing
As a construction grammar, FCG represents all
linguistic knowledge as pairings of function and
form (called constructions). This means that any
linguistic item, be it a concrete lexical item (see
Figure 1) or a schematic construction, shares the
same fundamental representation in FCG.
Each construction consists of two poles (a se-
mantic/functional one and a syntactic/form one),
each represented as a feature structure. By using a
separate semantic and syntactic pole, FCG allows
the same construction to be efficiently parsed and
produced by the same processing engine by sim-
ply changing the direction of application.
127
reset
tag ?meaning-849 
footprints  
?top-unit-1611
(meaning
(==
(identify-person
?kim-1
 
?context-243
?person-119)
(bind
 
person
?person-119
 
[kim])))
(==0
 
kim-lex
 
lex)
footprints  
tag ?form-946 
?top-unit-1611
kim-lex (lex)
?top-unit-1611
(==0
 
kim-lex
 
lex)
(form
(
==
 
(string
 
?word-kim-1
 
"Kim")))
?top-unit-1611
sem syn
args  
sem-cat  
footprints  
?word-kim-1
? ?meaning-849
(?kim-1)
((sem-function
referring)
(sem-class
 
person))
(==1
 
kim-lex
 
lex)
footprints  
syn-cat  
?word-kim-1
? ?form-946
(==1
 
kim-lex
 
lex)
((lex-cat
proper-noun)
(syn-function
nominal))
Babel web interface http://localhost:8000/
1 of 1 12/6/12 11:08 PM
Figure 1: Lexical construction for the proper
noun ?Kim? as shown in the FCG web interface.
All constructions are mappings between semantic
(left) and syntactic feature structures (right).
FCG processing uses two different kinds of uni-
fication called match and merge. The match phase
is a conditional phase which checks for applicabil-
ity of the construction. The merge operation most
closely resembles classical (yet untyped) unifica-
tion. In production (i.e. going from meaning to
form), the processor will consider a construction?s
semantic pole as a set of conditions that need to be
satisfied, and the syntactic pole as additional infor-
mation that can be contributed by the construction.
In parsing (i.e. going from form to meaning), the
roles of the poles are reversed.
Since FCG pays a lot of attention to the inter-
action between linguistic knowledge and process-
ing, it makes it possible to investigate the conse-
quences of particular aspects of grammar with re-
gard to representation, production, parsing, learn-
ing and propagation (in a population of language
users). For example, a small case system may be
easier to represent and produce than a large sys-
tem, but it might also lead to increased ambigu-
ity in parsing and learning that the larger system
would avoid. Fluid Construction Grammar can
bring these differences to the surface for further
computational analysis.
It is exactly this ability to monitor the impact of
grammatical choices, that has sparked the interest
of an increasingly wide audience of historical and
evolutionary linguists. With FCG, different histor-
ical stages can be implemented (which addresses
questions about representation and processing) but
FCG also comes bundled with a reflective learn-
ing framework (Beuls et al, 2012) for learning the
key constructions of each stage. That same archi-
tecture has proven to be adequately powerful to
implement processes of grammaticalization so that
Linguistic system 1
Reconstruction
Individual Learning
Population 
Alignment
Grammaticalization
Linguistic system 2
Reconstruction
Individual Learning
Population 
Alignment
1.
2.
3.
1.
2.
3.
4.
Figure 2: Schematic overview of the experimental
methodology for historical and evolutionary lin-
guists. The example here shows only two linguis-
tic stages but there could be more.
actual linguistic change over time can be modeled
(van Trijp, 2010; Beuls and Steels, 2013; Wellens
and Loetzsch, 2012).
4 How to set up an evolutionary
linguistics experiment in FCG?
As the FCG processor can both produce and
parse utterances it is possible to instantiate not
one but a set or population of FCG processors
(or FCG agents) that can communicatively inter-
act with each other. Experiments in historical or
evolutionary linguistics make use of this multi-
agent approach where all agents engage in situated
pairwise interactions (language games) (Steels,
2012b).
In this systems demo we will focus on a re-
cent experiment in the emergence of grammatical
agreement (Beuls and Steels, 2013). The language
game consists of two agents in which one agent
(the speaker) has to describe one or more (max
three) objects in a scene to the other agent (the
hearer). Each object can be described by one or
more words. It follows that without any grammat-
ical marking it would be difficult (often impossi-
ble) for the hearer to figure out which words de-
scribe the same object and thus to arrive at a suc-
cessful interpretation. The hypothesis is that the
introduction of agreement markers helps solve this
ambiguity.
Next to setting up a language game script the
methodology consists of operationalizing the lin-
guistic strategies required for a population to boot-
strap and maintain a particular linguistic system (in
this case nominal agreement). Examples of lin-
128
!"!"
routine processing 
diagnostic 
problem repair 
diagnostic diagnostic diagnostic 
problem 
repair meta-layer processing 
Figure 3: Reflective meta-layer architecture oper-
ating as part of an FCG agent/processor.
guistic systems already investigated include Ger-
man case (van Trijp, 2012a; van Trijp, 2013),
the grammatical expression of space (Spranger
and Steels, 2012), the emergence of quantifiers
(Pauw and Hilferty, 2012) and the expression of
aspect in Russian (Gerasymova et al, 2012) [for
an overview see (Steels, 2011; Steels, 2012a)].
An experiment generally investigates multi-
ple linguistic systems of increasing complexity
where each system can, but need not, map to a
stage along an attested grammaticalization path-
way. Most often a stage is introduced in order
to gradually increase the complexity of the emer-
gent dynamics. In this demo we posit four sys-
tems/strategies, (1) a baseline purely lexical strat-
egy, (2) a strategy to bootstrap and align formal
(meaningless) agreement markers, (3) a strategy to
bootstrap and align meaningful agreement mark-
ers, and finally (4) a strategy that allows re-use
of existing lexical constructions as markers (gram-
maticalization).
Implementing and linking together all the com-
ponents involved in a single system is a highly
non-trivial undertaking and our methodology pre-
scribes the following four steps to undertake for
each system (see also Figure 2).
Reconstruction: A full operationalization of all
the constructions (lexical and grammatical)
involved in the chosen linguistic phenom-
ena. When multiple agents are initialized
with these constructions they should be able
to communicate successfully with each other.
This stage serves primarily to test and verify
intuitions about the different linguistic sys-
tems.
Individual Learning: Implementation of learn-
ing algorithms (or re-use of existing ones)
Figure 4: Meaningful marker strategy.
so that one agent can learn the constructions
based on the input of another agent. These
learning operations are generally divided into
diagnostics and repair strategies (see Fig-
ure 3). Diagnostics continually monitor FCG
processing for errors or inefficiencies and
generate problems if they are found. Repair
strategies then act on these problems by al-
tering the linguistic inventory (e.g. adding,
removing or changing constructions).
Population Alignment: There exists a large gap
between the cognitive machinary needed for
learning an existing linguistic system (step 2)
and bootstrapping, aligning and maintaining
a complete linguistic system from scratch. In
this step individual learning operators are ex-
tended with alignment strategies.
Grammaticalization: Moving from one linguis-
tic system to another is the final step of the
experiment. The challenge is to find and im-
plement the mechanisms that drive grammat-
icalization (Heine and Kuteva, 2007) in line
with observed grammaticalization pathways.
As an example we?ll give a short sketch of one
possible game as played in the meaningful marker
strategy as schematically shown in Figure 4. The
sketch shows a context of four objects (O1 to O4),
each described by three features. The speaker
chooses topic O1 + O2 which, given his vocab-
ulary (shown top right), results in uttering ?shuq-
fon sizhic zabu?. Words ?shuqfon? and ?sizhic?
both describe parts of O1 and ?zabu? of O2. In
order to explicitly communicate this linking the
speaker attaches the markers ?-ti? and ?-ta? so that
their meaning is compatible with the objects they
are linking as shown in the Figure. This allows
129
Figure 5: A network of constructions. Diamond shaped nodes represent lexical constructions, egg shaped
nodes represent grammatical constructions and rectangular nodes represent semantic categories. Arrows
can be read as ?primes?. For example the preposition between [BETWEEN.PREP] primes the category
LOCATIVE RELATION which in turn primes both the [LOCATIVE RELATION] and [SPATIAL PHRASE]
constructions. Both of these constructions also require a semantic category [REFERENT].
the hearer to arrive at a single non-ambiguous in-
terpretation. For more details we refer the reader
to (Beuls and Steels, 2013) and the web demo at
http://ai.vub.ac.be/materials/plos-agreement/.
5 Features of FCG
A number of key features of FCG have already
been introduced. Reversible bidirectional process-
ing, a single data representation for all linguistic
knowledge, a reflective meta-layer architecture for
learning and a multi-agent component for manag-
ing multiple interacting FCG instances. Other fea-
tures, some of which are unique to FCG, include,
but are not limited to:
Web interface: FCG comes with a rich
HTML/AJAX based web interface (Loet-
zsch, 2012) where it can show fine-grained
information to the user in a user-friendly
manner through the use of expandable
elements. See Figure 6.
Customizable processing: Linguistic process-
ing is implemented as a search process
(Bleys et al, 2011). The user has easy
access to the most important parameters
influencing this process. Examples of these
are the heuristics and the tests that determine
whether a node represents an acceptable
solution. FCG comes bundled with a library
of heuristics and goal tests and with a bit
of programming skills users can add new
primitives easily.
Customizable construction inventory: By de-
fault, FCG stores all constructions in one
large set. FCG however supplies a num-
ber of different taxonomies, both for concep-
tual and efficiency reasons. One popular op-
tion is to organize constructions in smaller
subsets (Beuls, 2011) like lexical, morpho-
logical, functional, etc. Another option is
to use networks (Wellens, 2011) that can
learn co-occurrence relations between con-
structions and ?prime? constructions when
they are likely to apply (see Figure 5).
Interfaces to external repositories: FCG
can connect to external repositories like
Framenet (Baker et al, 1998) and Wordnet
(Miller, 1995) to load thousands of lexical
entries (Micelli et al, 2009; Wellens and
Beule, 2010).
Robustness: FCG continues operation as far as
it can get even if some constructions do not
apply (Steels and van Trijp, 2011). Sup-
plied with appropriate diagnostics and repair
strategies FCG can even recover from errors
(van Trijp, 2012b).
Open source: Best of all, FCG is freely down-
loadable and open source (http://www.fcg-
net.org). It is written in Common Lisp
(CLOS) and compatible with most popu-
lar lisp implementations (SBCL, CCL, Lisp-
works, ...).
130
top
top
Parsing "block"
Applying construction set (70)  in direction 
Found a solution
initialstructure top
applicationprocess
appliedconstructions
resultingstructure
top
Meaning:
((apply-class ?ref-2 ?src-2 ?class-1) (bind object-class ?class-1 block))
sem syn
initial
top
top
cxn-applied
application result
status cxn-applied
sourcestructure top
appliedconstruction
resultingstructure top
resultingbindings ((?form-84 form ((string block-83 "block"))) (?block-unit-2 . block-83) (?top-39 . top))
added infirst merge block-83
added insecondmerge
block-83
cxn supplier :ordered-by-label
remaining labels (cat  gram)
remaining cxns (right-lex speaker-lex unique-lex hearer-lex)
block-morph (morph t)
sem syn
block-morph (morph t)
sem syn block-83 block-lex(lex t)
noun-
cat
(cat t)
noun-cat (cat t) block-lex (lex t) block-morph (morph t)
noun-unit-273
footprints  
meaning  
ref  
sem-cat  
block-83
(block-lex)
((bind object-class ?class-1 block))
?class-1
((sem-function ((value ?sem-function-value-4) (valence (identifier))))(class (object-class)))
sem syn noun-unit-273 block-83
expanded search tree node
expanded unit
Figure 6: An example of parsing the noun ?Block? as shown in the FCG web interface. Users can click
on nearly every element to show an expanded version.
The reader is encouraged to take a look at
http://www.fcg-net.org/projects/design-patterns-
in-fluid-construction-grammar for a selection of
demonstrations of Fluid Construction Grammar.
6 Conclusion
Fluid Construction Grammar is a mature technol-
ogy that can be used by computational linguists
to complement more traditional corpus-based ap-
proaches. FCG builds on many existing and
proven technologies and adds new innovations to
the mix resulting in a user friendly, yet powerful
and extensible framework for in-depth investiga-
tions in natural language phenomena.
Acknowledgments
The FCG formalism is being developed at the Ar-
tificial Intelligence Laboratory of the Vrije Uni-
versiteit Brussel and the Sony Computer Science
Laboratory in Paris. Pieter Wellens has been
supported by the ESF EuroUnderstanding project
DRUST funded by FWO and by the Vrije Uni-
versiteit Brussel. Katrien Beuls received fund-
ing from a strategic basic research grant from the
agency for Innovation by Science and Technol-
ogy (IWT). Remi van Trijp is funded by the Sony
Computer Science Laboratory Paris. We would
also like to thank Michael Spranger for his con-
tributions to the FCG formalism.
131
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of the 17th international conference on Compu-
tational linguistics, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Katrien Beuls and Luc Steels. 2013. Agent-based
models of strategies for the emergence and evo-
lution of grammatical agreement. PLoS ONE,
8(3):e58960, 03.
Katrien Beuls, Remi van Trijp, and Pieter Wellens.
2012. Diagnostics and repairs in Fluid Construc-
tion Grammar. In Luc Steels and Manfred Hild, ed-
itors, Language Grounding in Robots. Springer Ver-
lag, Berlin.
Katrien Beuls. 2011. Construction sets and unmarked
forms: A case study for Hungarian verbal agree-
ment. In Luc Steels, editor, Design Patterns in Fluid
Construction Grammar, pages 237?264. John Ben-
jamins, Amsterdam.
Joris Bleys, Kevin Stadler, and Joachim De Beule.
2011. Search in linguistic processing. In Luc Steels,
editor, Design Patterns in Fluid Construction Gram-
mar, pages 149?179. John Benjamins, Amsterdam.
Mark Davies. 2011. N-grams and word frequency
data from the corpus of historical american english
(coha).
Kateryna Gerasymova, Michael Spranger, and Katrien
Beuls. 2012. A language strategy for aspect: En-
coding aktionsarten through morphology. In Luc
Steels, editor, Experiments in Cultural Language
Evolution, pages 257 ? 276. John Benjamins.
Bernd Heine and Tania Kuteva. 2007. The Genesis
of Grammar: A Reconstruction. Oxford University
Press, October.
Martin Loetzsch. 2012. Tools for grammar engineer-
ing. In Luc Steels, editor, Computational Issues
in Fluid Construction Grammar. Springer Verlag,
Berlin.
V. Micelli, R. van Trijp, and J. De Beule. 2009. Fram-
ing fluid construction grammar. In N.A. Taatgen and
H. van Rijn, editors, the 31th Annual Conference
of the Cognitive Science Society, pages 3023?3027.
Cognitive Science Society.
George A. Miller. 1995. Wordnet: a lexical database
for english. Commun. ACM, 38:39?41, November.
Simon Pauw and Joseph Hilferty. 2012. The emer-
gence of quantifiers. In Luc Steels, editor, Experi-
ments in Cultural Language Evolution, pages 277 ?
304. John Benjamins.
Carl Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. University of Chicago
Press, Chicago.
Michael Spranger and Luc Steels. 2012. Emergent
functional grammar for space. In Luc Steels, editor,
Experiments in Cultural Language Evolution, pages
207 ? 232. John Benjamins, Amsterdam.
Luc Steels and Remi van Trijp. 2011. How to make
construction grammars fluid and robust. In Luc
Steels, editor, Design Patterns in Fluid Construction
Grammar, pages 301?330. John Benjamins, Ams-
terdam.
Luc Steels, editor. 2011. Design Patterns in Fluid
Construction Grammar. John Benjamins.
Luc Steels, editor. 2012a. Computational Issues in
Fluid Construction Grammar, volume 7249 of Lec-
ture Notes in Computer Science. Springer, Berlin.
Luc Steels, editor. 2012b. Experiments in Cultural
Language Evolution. John Benjamins, Amsterdam.
Remi van Trijp. 2010. Grammaticalization and seman-
tic maps: Evidence from artificial language evolu-
tion. Linguistic Discovery, 8:310?326.
Remi van Trijp. 2012a. Not as awful as it seems : Ex-
plaining german case through computational exper-
iments in fluid construction grammar. In Proceed-
ings of the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 829?839.
Remi van Trijp. 2012b. A reflective architecture for
language processing and learning. In Luc Steels,
editor, Computational Issues in Fluid Construction
Grammar. Springer Verlag, Berlin.
Remi van Trijp. 2013. Linguistic assessment crite-
ria for explaining language change: A case study on
syncretism in German definite articles. Language
Dynamics and Change, 3(1).
Pieter Wellens and Joachim De Beule. 2010. Priming
through constructional dependencies: a case study
in fluid construction grammar. In The Evolution
of Language ( EVOLANG8), pages 344?351. World
Scientific.
Pieter Wellens and Martin Loetzsch. 2012. Multi-
dimensional meanings in lexicon formation. In Luc
Steels, editor, Experiments in Cultural Language
Evolution, pages 143?166. John Benjamins, Ams-
terdam.
Pieter Wellens. 2011. Organizing constructions in net-
works. In Luc Steels, editor, Design Patterns in
Fluid Construction Grammar, pages 181?201. John
Benjamins, Amsterdam.
Lin Yuri, Michel Jean-Baptiste, Lieberman Aiden Erez,
Orwant Jon, Brockman Will, and Slav Petrov. 2012.
Syntactic annotations for the google books ngram
corpus. In ACL (System Demonstrations). The As-
sociation for Computer Linguistics.
132
