The Parallel Grammar Project
Miriam Butt
Cent. for Computational Linguistics
UMIST
Manchester M60 1QD GB
mutt@csli.stanford.edu
Helge Dyvik
Dept. of Linguistics
University of Bergen
N5007 Bergen NORWAY
helge.dyvik@lili.uib.no
Tracy Holloway King
Palo Alto Research Center
Palo Alto, CA 94304 USA
thking@parc.com
Hiroshi Masuichi
Corporate Research Center
Fuji Xerox Co., Ltd.
Kanagawa 259-0157, JAPAN
hiroshi.masuichi@fujixerox.co.jp
Christian Rohrer
IMS Universita?t Stuttgart
D-70174 Stuttgart GERMANY
rohrer@ims.uni-stuttgart.de
Abstract
We report on the Parallel Grammar (ParGram)
project which uses the XLE parser and grammar
development platform for six languages: English,
French, German, Japanese, Norwegian, and Urdu.1
1 Introduction
Large-scale grammar development platforms are ex-
pensive and time consuming to produce. As such, a
desideratum for the platforms is a broad utilization
scope. A grammar development platform should be
able to be used to write grammars for a wide variety
of languages and a broad range of purposes. In this
paper, we report on the Parallel Grammar (ParGram)
project (Butt et al, 1999) which uses the XLE parser
and grammar development platform (Maxwell and
Kaplan, 1993) for six languages: English, French,
German, Japanese, Norwegian, and Urdu. All of
the grammars use the Lexical-Functional Gram-
mar (LFG) formalism which produces c(onstituent)-
structures (trees) and f(unctional)-structures (AVMs)
as the syntactic analysis.
LFG assumes a version of Chomsky?s Universal
Grammar hypothesis, namely that all languages are
structured by similar underlying principles. Within
LFG, f-structures are meant to encode a language
universal level of analysis, allowing for cross-
linguistic parallelism at this level of abstraction. Al-
though the construction of c-structures is governed
1We would like to thank Emily Bender, Mary Dalrymple,
and Ron Kaplan for help with this paper. In addition, we would
like to acknowledge the other grammar writers in the Par-
Gram project, both current: Stefanie Dipper, Jean-Philippe Mar-
cotte, Tomoko Ohkuma, and Victoria Rose?n; and past: Caroline
Brun, Christian Fortmann, Anette Frank, Jonas Kuhn, Veronica
Lux, Yukiko Morimoto, Mar??a-Eugenia Nin?o, and Fre?de?rique
Segond.
by general wellformedness principles, this level of
analysis encodes language particular differences in
linear word order, surface morphological vs. syntac-
tic structures, and constituency.
The ParGram project aims to test the LFG formal-
ism for its universality and coverage limitations and
to see how far parallelism can be maintained across
languages. Where possible, the analyses produced
by the grammars for similar constructions in each
language are parallel. This has the computational
advantage that the grammars can be used in simi-
lar applications and that machine translation (Frank,
1999) can be simplified.
The results of the project to date are encouraging.
Despite differences between the languages involved
and the aims and backgrounds of the project groups,
the ParGram grammars achieve a high level of paral-
lelism. This parallelism applies to the syntactic anal-
yses produced, as well as to grammar development
itself: the sharing of templates and feature decla-
rations, the utilization of common techniques, and
the transfer of knowledge and technology from one
grammar to another. The ability to bundle grammar
writing techniques, such as templates, into transfer-
able technology means that new grammars can be
bootstrapped in a relatively short amount of time.
There are a number of other large-scale gram-
mar projects in existence which we mention briefly
here. The LS-GRAM project (Schmidt et al, 1996),
funded by the EU-Commission under LRE (Lin-
guistic Research and Engineering), was concerned
with the development of grammatical resources for
nine European languages: Danish, Dutch, English,
French, German, Greek, Italian, Portuguese, and
Spanish. The project started in January 1994 and
ended in July 1996. Development of grammatical
resources was carried out in the framework of the
Advanced Language Engineering Platform (ALEP).
The coverage of the grammars implemented in LS-
GRAM was, however, much smaller than the cov-
erage of the English (Riezler et al, 2002) or Ger-
man grammar in ParGram. An effort which is closer
in spirit to ParGram is the implemention of gram-
mar development platforms for HPSG. In the Verb-
mobil project (Wahlster, 2000), HPSG grammars for
English, German, and Japanese were developed on
two platforms: LKB (Copestake, 2002) and PAGE.
The PAGE system, developed and maintained in the
Language Technology Lab of the German National
Research Center on Artificial Intelligence DFKI
GmbH, is an advanced NLP core engine that facili-
tates the development of grammatical and lexical re-
sources, building on typed feature logics. To evalu-
ate the HPSG platforms and to compare their mer-
its with those of XLE and the ParGram projects, one
would have to organize a special workshop, partic-
ularly as the HPSG grammars in Verbmobil were
written for spoken language, characterized by short
utterances, whereas the LFG grammars were devel-
oped for parsing technical manuals and/or newspa-
per texts. There are some indications that the Ger-
man and English grammars in ParGram exceed the
HPSG grammars in coverage (see (Crysmann et al,
2002) on the German HPSG grammar).
This paper is organized as follows. We first pro-
vide a history of the project. Then, we discuss how
parallelism is maintained in the project. Finally, we
provide a summary and discussion.
2 Project History
The ParGram project began in 1994 with three lan-
guages: English, French, and German. The gram-
mar writers worked closely together to solidify the
grammatical analyses and conventions. In addition,
as XLE was still in development, its abilities grew
as the size of the grammars and their needs grew.
After the initial stage of the project, more lan-
guages were added. Because Japanese is typolog-
ically very different from the initial three Euro-
pean languages of the project, it represented a chal-
lenging case. Despite this typological challenge, the
Japanese grammar has achieved broad coverage and
high performance within a year and a half. The
South Asian language Urdu also provides a widely
spoken, typologically distinct language. Although it
is of Indo-European origin, it shares many character-
istics with Japanese such as verb-finality, relatively
free word order, complex predicates, and the abil-
ity to drop any argument (rampant pro-drop). Nor-
wegian assumes a typological middle position be-
tween German and English, sharing different prop-
erties with each of them. Both the Urdu and the Nor-
wegian grammars are still relatively small.
Each grammar project has different goals, and
each site employs grammar writers with different
backgrounds and skills. The English, German, and
Japanese projects have pursued the goal of hav-
ing broad coverage, industrial grammars. The Nor-
wegian and Urdu grammars are smaller scale but
are experimenting with incorporating different kinds
of information into the grammar. The Norwegian
grammar includes a semantic projection; their anal-
yses produce not only c- and f-structures, but also
semantic structures. The Urdu grammar has imple-
mented a level of argument structure and is test-
ing various theoretical linguistic ideas. However,
even when the grammars are used for different pur-
poses and have different additional features, they
have maintained their basic parallelism in analysis
and have profited from the shared grammar writing
techniques and technology.
Table (1) shows the size of the grammars. The first
figure is the number of left-hand side categories in
phrase-structure rules which compile into a collec-
tion of finite-state machines with the listed number
of states and arcs.
(1)
Language Rules States Arcs
German 444 4883 15870
English 310 4935 13268
French 132 1116 2674
Japanese 50 333 1193
Norwegian 46 255 798
Urdu 25 106 169
3 Parallelism
Maintaining parallelism in grammars being devel-
oped at different sites on typologically distinct lan-
guages by grammar writers from different linguis-
tic traditions has proven successful. At project meet-
ings held twice a year, analyses of sample sentences
are compared and any differences are discussed; the
goal is to determine whether the differences are jus-
tified or whether the analyses should be changed
to maintain parallelism. In addition, all of the f-
structure features and their values are compared; this
not only ensures that trivial differences in naming
conventions do not arise, but also gives an overview
of the constructions each language covers and how
they are analyzed. All changes are implemented be-
fore the next project meeting. Each meeting also in-
volves discussion of constructions whose analysis
has not yet been settled on, e.g., the analysis of parti-
tives or proper names. If an analysis is agreed upon,
all the grammars implement it; if only a tentative
analysis is found, one grammar implements it and
reports on its success. For extremely complicated or
fundamental issues, e.g., how to represent predicate
alternations, subcommittees examine the issue and
report on it at the next meeting. The discussion of
such issues may be reopened at successive meetings
until a concensus is reached.
Even within a given linguistic formalism, LFG for
ParGram, there is usually more than one way to an-
alyze a construction. Moreover, the same theoreti-
cal analysis may have different possible implemen-
tations in XLE. These solutions often differ in effi-
ciency or conceptual simplicity and one of the tasks
within the ParGram project is to make design deci-
sions which favor one theoretical analysis and con-
comitant implementation over another.
3.1 Parallel Analyses
Whenever possible, the ParGram grammars choose
the same analysis and the same technical solution
for equivalent constructions. This was done, for
example, with imperatives. Imperatives are always
assigned a null pronominal subject within the f-
structure and a feature indicating that they are im-
peratives, as in (2).
(2) a. Jump! Saute! (French)
Spring! (German) Tobe! (Japanese)
Hopp! (Norwegian) kuudoo! (Urdu)
b. PRED jump SUBJ
SUBJ PRED pro
STMT-TYPE imp
Another example of this type comes from the
analysis of specifiers. Specifiers include many dif-
ferent types of information and hence can be ana-
lyzed in a number of ways. In the ParGram analysis,
the c-structure analysis is left relatively free accord-
ing to language particular needs and slightly vary-
ing theoretical assumptions. For instance, the Nor-
wegian grammar, unlike the other grammars, im-
plements the principles in (Bresnan, 2001) concern-
ing the relationship between an X -based c-structure
and the f-structure. This allows Norwegian speci-
fiers to be analyzed as functional heads of DPs etc.,
whereas they are constituents of NPs in the other
grammars. However, at the level of f-structure, this
information is part of a complex SPEC feature in
all the grammars. Thus parallelism is maintained
at the level of f-structure even across different the-
oretical preferences. An example is shown in (3)
for Norwegian and English in which the SPEC con-
sists of a QUANT(ifier) and a POSS(essive) (SPEC
can also contain information about DETerminers and
DEMONstratives).
(3) a. alle mine hester (Norwegian)
all my horses
?all my horses?
b. PRED horse
SPEC
QUANT PRED all
POSS
PRED pro
PERS 1
NUM sg
Interrogatives provide an interesting example be-
cause they differ significantly in the c-structures of
the languages, but have the same basic f-structure.
This contrast can be seen between the German ex-
ample in (4) and the Urdu one in (5). In German,
the interrogative word is in first position with the
finite verb second; English and Norwegian pattern
like German. In Urdu the verb is usually in final po-
sition, but the interrogative can appear in a number
of positions, including following the verb (5c).
(4) Was hat John Maria gegeben? (German)
what has John Maria give.PerfP
?What did John give to Mary??
(5) a. jon=nee marii=koo kyaa diiyaa? (Urdu)
John=Erg Mary=Dat what gave
?What did John give to Mary?
b. jon=nee kyaa marii=koo diiyaa?
c. jon=nee marii=ko diiyaa kyaa?
Despite these differences in word order and hence in
c-structure, the f-structures are parallel, with the in-
terrogative being in a FOCUS-INT and the sentence
having an interrogative STMT-TYPE, as in (6).
(6) PRED give SUBJ,OBJ,OBL
FOCUS-INT
PRED pro
PRON-TYPE int
SUBJ PRED John
OBJ [ ]
OBL PRED Mary
STMT-TYPE int
In the project grammars, many basic construc-
tions are of this type. However, as we will see in
the next section, there are times when parallelism is
not possible and not desirable. Even in these cases,
though, the grammars which can be parallel are;
so, three of the languages might have one analysis,
while three have another.
3.2 Justified Differences
Parallelism is not maintained at the cost of misrepre-
senting the language. This is reflected by the fact that
the c-structures are not parallel because word order
varies widely from language to language, although
there are naming conventions for the nodes. Instead,
the bulk of the parallelism is in the f-structure. How-
ever, even in the f-structure, situations arise in which
what seems to be the same construction in different
languages do not have the same analysis. An exam-
ple of this is predicate adjectives, as in (7).
(7) a. It is red.
b. Sore wa akai. (Japanese)
it TOP red
?It is red.?
In English, the copular verb is considered the syn-
tactic head of the clause, with the pronoun being the
subject and the predicate adjective being an XCOMP.
However, in Japanese, the adjective is the main pred-
icate, with the pronoun being the subject. As such,
these receive the non-parallel analyses seen in (8a)
for Japanese and (8b) for English.
(8) a. PRED red SUBJ
SUBJ PRED pro
b. PRED be XCOMP SUBJ
SUBJ PRED pro
XCOMP
PRED red SUBJ
SUBJ [ ]
Another situation that arises is when a feature
or construction is syntactically encoded in one lan-
guage, but not another. In such cases, the informa-
tion is only encoded in the languages that need it.
The equivalence captured by parallel analyses is not,
for example, translational equivalence. Rather, par-
allelism involves equivalence with respect to gram-
matical properties, e.g. construction types. One con-
sequence of this is that a typologically consistent
use of grammatical terms, embodied in the feature
names, is enforced. For example, even though there
is a tradition for referring to the distinction between
the pronouns he and she as a gender distinction in
English, this is a different distinction from the one
called gender in languages like German, French,
Urdu, and Norwegian, where gender refers to nom-
inal agreement classes. Parallelism leads to the sit-
uation where the feature GEND occurs in German,
French, Urdu, and Norwegian, but not in English
and Japanese. That is, parallelism does not mean
finding the same features in all languages, but rather
using the same features in the same way in all lan-
guages, to the extent that they are justified there. A
French example of grammatical gender is shown in
(9); note that determiner, adjective, and participle
agreement is dependent on the gender of the noun.
The f-structure for the nouns crayon and plume are
as in (10) with an overt GEND feature.
(9) a. Le petit crayon est casse?. (French)
the-M little-M pencil-M is broken-M.
?The little pencil is broken.?
b. La petite plume est casse?e. (French)
the-F little-F pen-F is broken-F.
?The little pen is broken.?
(10)
PRED crayon
GEND masc
PERS 3
PRED plume
GEND fem
PERS 3
F-structures for the equivalent words in English and
Japanese will not have a GEND feature.
A similar example comes from Japanese dis-
course particles. It is well-known that Japanese has
syntactic encodings for information such as honori-
fication. The verb in the Japanese sentence (11a)
encodes information that the subject is respected,
while the verb in (11b) shows politeness from the
writer (speaker) to the reader (hearer) of the sen-
tence. The f-structures for the verbs in (11) are as in
(12) with RESPECT and POLITE features within the
ADDRESS feature.
(11) a. sensei ga hon wo oyomininaru.
teacher Nom book Acc read-Respect
?The teacher read the book.? (Japanese)
b. seito ga hon wo yomimasu.
student Nom book Acc read-Polite
?The student reads the book.? (Japanese)
(12) a. PRED yomu SUBJ,OBJ
ADDRESS RESPECT +
b. PRED yomu SUBJ,OBJ
ADDRESS POLITE +
A final example comes from English progres-
sives, as in (13). In order to distinguish these two
forms, the English grammar uses a PROG feature
within the tense/aspect system. (13b) shows the f-
structure for (13a.ii).
(13) a. John hit Bill. i. He cried.
ii. He was crying.
b. PRED cry SUBJ
SUBJ PRED pro
TNS-ASP
TENSE past
PROG +
However, this distinction is not found in the other
languages. For example, (14a) is used to express
both (13a.i) and (13a.ii) in German.
(14) a. Er weinte. (German)
he cried
?He cried.?
b. PRED weinen SUBJ
SUBJ PRED pro
TNS-ASP TENSE past
As seen in (14b), the German f-structure is left un-
derspecified for PROG because there is no syntactic
reflex of it. If such a feature were posited, rampant
ambiguity would be introduced for all past tense
forms in German. Instead, the semantics will deter-
mine whether such forms are progressive.
Thus, there are a number of situations where hav-
ing parallel analyses would result in an incorrect
analysis for one of the languages.
3.3 One Language Shows the Way
Another type of situation arises when one language
provides evidence for a certain feature space or type
of analysis that is neither explicitly mirrored nor
explicitly contradicted by another language. In the-
oretical linguistics, it is commonly acknowledged
that what one language codes overtly may be harder
to detect for another language. This situation has
arisen in the ParGram project. Case features fall un-
der this topic. German, Japanese, and Urdu mark
NPs with overt case morphology. In comparison,
English, French, and Norwegian make relatively lit-
tle use of case except as part of the pronominal sys-
tem. Nevertheless, the f-structure analyses for all the
languages contain a case feature in the specification
of noun phrases.
This ?overspecification? of information expresses
deeper linguistic generalizations and keeps the f-
structural analyses as parallel as possible. In addi-
tion, the features can be put to use for the isolated
phenomena in which they do play a role. For exam-
ple, English does not mark animacy grammatically
in most situations. However, providing a ANIM +
feature to known animates, such as people?s names
and pronouns, allows the grammar to encode infor-
mation that is relevant for interpretation. Consider
the relative pronoun who in (15).
(15) a. the girl[ANIM +] who[ANIM +] left
b. the box[ANIM +] who[ANIM +] left
The relative pronoun has a ANIM + feature that is as-
signed to the noun it modifies by the relative clause
rules. As such, a noun modified by a relative clause
headed by who is interpreted as animate. In the case
of canonical inanimates, as in (15b), this will result
in a pragmatically odd interpretation, which is en-
coded in the f-structure.
Teasing apart these different phenomena crosslin-
guistically poses a challenge that the ParGram mem-
bers are continually engaged in. As such, we have
developed several methods to help maintain paral-
lelism.
3.4 Mechanics of Maintaining Parallelism
The parallelism among the grammars is maintained
in a number of ways. Most of the work is done dur-
ing two week-long project meetings held each year.
Three main activities occur during these meetings:
comparison of sample f-structures, comparison of
features and their values, and discussions of new or
problematic constructions.
A month before each meeting, the host site
chooses around fifteen sentences whose analysis is
to be compared at the meeting. These can be a ran-
dom selection or be thematic, e.g., all dealing with
predicatives or with interrogatives. The sentences
are then parsed by each grammar and the output is
compared. For the more recent grammars, this may
mean adding the relevant rules to the grammars, re-
sulting in growth of the grammar; for the older gram-
mars, this may mean updating a construction that has
not been examined in many years. Another approach
that was taken at the beginning of the project was to
have a common corpus of about 1,000 sentences that
all of the grammars were to parse. For the English,
French, and German grammars, this was an aligned
tractor manual. The corpus sentences were used for
the initial f-structure comparisons. Having a com-
mon corpus ensured that the grammars would have
roughly the same coverage. For example, they all
parsed declarative and imperative sentences. How-
ever, the nature of the corpus can leave major gaps
in coverage; in this case, the manual contained no in-
terrogatives.
The XLE platform requires that a grammar de-
clare all the features it uses and their possible val-
ues. Part of the Urdu feature table is shown in (16)
(the notation has been simplified for expository pur-
poses). As seen in (16) for QUANT, attributes which
take other attributes as their values must also be de-
clared. An example of such a feature was seen in
(3b) for SPEC which takes QUANT and POSS fea-
tures, among others, as its values.
(16) PRON-TYPE: pers poss null .
PROPER: date location name title .
PSEM: locational directional .
PTYPE: sem nosem .
QUANT: PRED QUANT-TYPE
QUANT-FORM .
The feature declarations of all of the languages are
compared feature by feature to ensure parallelism.
The most obvious use of this is to ensure that the
grammars encode the same features in the same way.
For example, at a basic level, one feature declaration
might have specified GEN for gender while the oth-
ers had chosen the name GEND; this divergence in
naming is regularized. More interesting cases arise
when one language uses a feature and another does
not for analyzing the same phenomena. When this is
noticed via the feature-table comparison, it is deter-
mined why one grammar needs the feature and the
other does not, and thus it may be possible to elim-
inate the feature in one grammar or to add it to an-
other.
On a deeper level, the feature comparison is use-
ful for conducting a survey of what constructions
each grammar has and how they are implemented.
For example, if a language does not have an ADE-
GREE (adjective degree) feature, the question will
arise as to whether the grammar analyzes compar-
ative and superlative adjectives. If they do not, then
they should be added and should use the ADEGREE
feature; if they do, then the question arises as to why
they do not have this feature as part of their analysis.
Finally, there is the discussion of problematic
constructions. These may be constructions that al-
ready have analyses which had been agreed upon in
the past but which are not working properly now that
more data has been considered. More frequently,
they are new constructions that one of the grammars
is considering adding. Possible analyses for the con-
struction are discussed and then one of the gram-
mars will incorporate the analysis to see whether it
works. If the analysis works, then the other gram-
mars will incorporate the analysis. Constructions
that have been discussed in past ParGram meet-
ings include predicative adjectives, quantifiers, par-
titives, and clefts. Even if not all of the languages
have the construction in question, as was the case
with clefts, the grammar writers for that language
may have interesting ideas on how to analyze it.
These group discussions have proven particularly
useful in extending grammar coverage in a parallel
fashion.
Once a consensus is reached, it is the responsi-
bility of each grammar to make sure that its anal-
yses match the new standard. As such, after each
meeting, the grammar writers will rename features,
change analyses, and implement new constructions
into their grammars. Most of the basic work has now
been accomplished. However, as the grammars ex-
pand coverage, more constructions need to be inte-
grated into the grammars, and these constructions
tend to be ones for which there is no standard analy-
sis in the linguistic literature; so, differences can eas-
ily arise in these areas.
4 Conclusion
The experiences of the ParGram grammar writers
has shown that the parallelism of analysis and imple-
mentation in the ParGram project aids further gram-
mar development efforts. Many of the basic deci-
sions about analyses and formalism have already
been made in the project. Thus, the grammar writer
for a new language can use existing technology to
bootstrap a grammar for the new language and can
parse equivalent constructions in the existing lan-
guages to see how to analyze a construction. This
allows the grammar writer to focus on more diffi-
cult constructions not yet encountered in the existing
grammars.
Consider first the Japanese grammar which was
started in the beginning of 2001. At the initial stage,
the work of grammar development involved imple-
menting the basic constructions already analyzed in
the other grammars. It was found that the grammar
writing techniques and guidelines to maintain par-
allelism shared in the ParGram project could be ef-
ficiently applied to the Japanese grammar. During
the next stage, LFG rules needed for grammatical is-
sues specific to Japanese have been gradually incor-
porated, and at the same time, the biannual ParGram
meetings have helped significantly to keep the gram-
mars parallel. Given this system, in a year and a half,
using two grammar writers, the Japanese grammar
has attained coverage of 99% for 500 sentences of a
copier manual and 95% for 10,000 sentences of an
eCRM (Voice-of-Customer) corpus.
Next consider the Norwegian grammar which
joined the ParGram group in 1999 and also empha-
sized slightly different goals from the other groups.
Rather than prioritizing large textual coverage from
the outset, the Norwegian group gave priority to the
development of a core grammar covering all major
construction types in a principled way based on the
proposals in (Bresnan, 2001) and the inclusion of a
semantic projection in addition to the f-structure. In
addition, time was spent on improving existing lexi-
cal resources ( 80,000 lemmas) and adapting them
to the XLE format. Roughly two man-years has been
spent on the grammar itself. The ParGram cooper-
ation on parallelism has ensured that the derived f-
structures are interesting in a multilingual context,
and the grammar will now serve as a basis for gram-
mar development in other closely related Scandina-
vian languages.
Thus, the ParGram project has shown that it is
possible to use a single grammar development plat-
form and a unified methodology of grammar writing
to develop large-scale grammars for typologically
different languages. The grammars? analyses show a
large degree of parallelism, despite being developed
at different sites. This is achieved by intensive meet-
ings twice a year. The parallelism can be exploited in
applications using the grammars: the fewer the dif-
ferences, the simpler a multilingual application can
be (see (Frank, 1999) on a machine-translation pro-
totype using ParGram).
References
Joan Bresnan. 2001. Lexical-Functional Syntax.
Blackwell.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999. A Grammar
Writer?s Cookbook. CSLI Publications.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI Publications.
Berthold Crysmann, Anette Frank, Bernd Keifer, St.
Mu?ller, Gu?nter Neumann, Jakub Piskorski, Ulrich
Scha?fer, Melanie Siegel, Hans Uszkoreit, Feiyu
Xu, Markus Becker, and Hans-Ulrich Krieger.
2002. An integrated architecture for shallow and
deep parsing. In Proceedings of the Annual Meet-
ing of the Association for Computational Linguis-
tics, University of Pennsylvania.
Anette Frank. 1999. From parallel grammar devel-
opment towards machine translation. In Proceed-
ings of MT Summit VII, pages 134?142.
John T. Maxwell, III and Ron Kaplan. 1993. The
interface between phrasal and functional con-
straints. Computational Lingusitics, 19:571?589.
Stefan Riezler, Tracy Holloway King, Ronald Ka-
plan, Dick Crouch, John T. Maxwell, III, and
Mark Johnson. 2002. Parsing the wall street jour-
nal using a lexical-functional grammar and dis-
criminative estimation techniques. In Proceed-
ings of the Annual Meeting of the Association for
Computational Linguistics, University of Penn-
sylvania.
Paul Schmidt, Sibylle Rieder, Axel Theofilidis, and
Thierry Declerck. 1996. Lean formalisms, lin-
guistic theory, and applications: Grammar devel-
opment in alep. In Proceedings of COLING.
Wolfgang Wahlster, editor. 2000. Verbmobil:
Foundations of Speech-to-Speech Translation.
Springer.
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 550?560,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
ParGramBank: The ParGram Parallel Treebank
Sebastian Sulger and Miriam Butt
University of Konstanz, Germany
{sebastian.sulger|miriam.butt}@uni-konstanz.de
Tracy Holloway King
eBay Inc., USA
tracyking@ebay.com
Paul Meurer
Uni Research AS, Norway
paul.meurer@uni.no
Tibor Laczko? and Gyo?rgy Ra?kosi
University of Debrecen, Hungary
{laczko.tibor|rakosi.gyorgy}@arts.unideb.hu
Cheikh Bamba Dione and Helge Dyvik and Victoria Rose?n and Koenraad De Smedt
University of Bergen, Norway
dione.bamba@lle.uib.no, {dyvik|victoria|desmedt}@uib.no
Agnieszka Patejuk
Polish Academy of Sciences
aep@ipipan.waw.pl
O?zlem C?etinog?lu
University of Stuttgart, Germany
ozlem@ims.uni-stuttgart.de
I Wayan Arka* and Meladel Mistica+
*Australian National University and Udayana University, Indonesia
+Australian National University
wayan.arka@anu.edu.au, meladel.mistica@gmail.com
Abstract
This paper discusses the construction of
a parallel treebank currently involving ten
languages from six language families. The
treebank is based on deep LFG (Lexical-
Functional Grammar) grammars that were
developed within the framework of the
ParGram (Parallel Grammar) effort. The
grammars produce output that is maxi-
mally parallelized across languages and
language families. This output forms the
basis of a parallel treebank covering a
diverse set of phenomena. The treebank
is publicly available via the INESS tree-
banking environment, which also allows
for the alignment of language pairs. We
thus present a unique, multilayered paral-
lel treebank that represents more and dif-
ferent types of languages than are avail-
able in other treebanks, that represents
deep linguistic knowledge and that allows
for the alignment of sentences at sev-
eral levels: dependency structures, con-
stituency structures and POS information.
1 Introduction
This paper discusses the construction of a parallel
treebank currently involving ten languages that
represent several different language families, in-
cluding non-Indo-European. The treebank is based
on the output of individual deep LFG (Lexical-
Functional Grammar) grammars that were deve-
loped independently at different sites but within
the overall framework of ParGram (the Parallel
Grammar project) (Butt et al, 1999a; Butt et al,
2002). The aim of ParGram is to produce deep,
wide coverage grammars for a variety of lan-
guages. Deep grammars provide detailed syntactic
analysis, encode grammatical functions as well as
550
other grammatical features such as tense or aspect,
and are linguistically well-motivated. The Par-
Gram grammars are couched within the linguis-
tic framework of LFG (Bresnan, 2001; Dalrymple,
2001) and are constructed with a set of grammati-
cal features that have been commonly agreed upon
within the ParGram group. ParGram grammars are
implemented using XLE, an efficient, industrial-
strength grammar development platform that in-
cludes a parser, a generator and a transfer sys-
tem (Crouch et al, 2012). XLE has been devel-
oped in close collaboration with the ParGram
project. Over the years, ParGram has continu-
ously grown and includes grammars for Ara-
bic, Chinese, English, French, German, Georgian,
Hungarian, Indonesian, Irish, Japanese, Mala-
gasy, Murrinh-Patha, Norwegian, Polish, Spanish,
Tigrinya, Turkish, Urdu, Welsh and Wolof.
ParGram grammars produce output that has
been parallelized maximally across languages ac-
cording to a set of commonly agreed upon uni-
versal proto-type analyses and feature values. This
output forms the basis of the ParGramBank paral-
lel treebank discussed here. ParGramBank is con-
structed using an innovative alignment methodol-
ogy developed in the XPAR project (Dyvik et al,
2009) in which grammar parallelism is presup-
posed to propagate alignment across different pro-
jections (section 6). This methodology has been
implemented with a drag-and-drop interface as
part of the LFG Parsebanker in the INESS infras-
tructure (Rose?n et al, 2012; Rose?n et al, 2009).
ParGramBank has been constructed in INESS and
is accessible in this infrastructure, which also of-
fers powerful search and visualization.
In recent years, parallel treebanking1 has gained
in importance within NLP. An obvious applica-
tion for parallel treebanking is machine transla-
tion, where treebank size is a deciding factor for
whether a particular treebank can support a par-
ticular kind of research project. When conduct-
ing in-depth linguistic studies of typological fea-
tures, other factors such as the number of in-
cluded languages, the number of covered phe-
nomena, and the depth of linguistic analysis be-
come more important. The treebanking effort re-
ported on in this paper supports work of the lat-
ter focus, including efforts at multilingual depen-
dency parsing (Naseem et al, 2012). We have
1Throughout this paper ?treebank? refers to both phrase-
structure resources and their natural extensions to depen-
dency and other deep annotation banks.
created a parallel treebank whose prototype in-
cludes ten typologically diverse languages and re-
flects a diverse set of phenomena. We thus present
a unique, multilayered parallel treebank that rep-
resents more languages than are currently avail-
able in other treebanks, and different types of lan-
guages as well. It contains deep linguistic knowl-
edge and allows for the parallel and simultane-
ous alignment of sentences at several levels. LFG?s
f(unctional)-structure encodes dependency struc-
tures as well as information that is equivalent to
Quasi-Logical Forms (van Genabith and Crouch,
1996). LFG?s c(onstituent)-structure provides in-
formation about constituency, hierarchical rela-
tions and part-of-speech. Currently, ParGramBank
includes structures for the following languages
(with the ISO 639-3 code and language fam-
ily): English (eng, Indo-European), Georgian (kat,
Kartvelian), German (deu, Indo-European), Hun-
garian (hun, Uralic), Indonesian (ind, Austrone-
sian), Norwegian (Bokma?l) (nob, Indo-European),
Polish (pol, Indo-European), Turkish (tur, Altaic),
Urdu (urd, Indo-European) and Wolof (wol, Niger-
Congo). It is freely available for download under
the CC-BY 3.0 license via the INESS treebanking
environment and comes in two formats: a Prolog
format and an XML format.2
This paper is structured as follows. Section
2 discusses related work in parallel treebanking.
Section 3 presents ParGram and its approach to
parallel treebanking. Section 4 focuses on the tree-
bank design and its construction. Section 5 con-
tains examples from the treebank, focusing on ty-
pological aspects and challenges for parallelism.
Section 6 elaborates on the mechanisms for paral-
lel alignment of the treebank.
2 Related Work
There have been several efforts in parallel tree-
banking across theories and annotation schemes.
Kuhn and Jellinghaus (2006) take a mini-
mal approach towards multilingual parallel tree-
banking. They bootstrap phrasal alignments over
a sentence-aligned parallel corpus of English,
French, German and Spanish and report concrete
treebank annotation work on a sample of sen-
tences from the Europarl corpus. Their annotation
2http://iness.uib.no. The treebank is in the
public domain (CC-BY 3.0). The use of the INESS platform
itself is not subject to any licensing. To access the treebank,
click on ?Treebank selection? and choose the ParGram collec-
tion.
551
scheme is the ?leanest? possible scheme in that it
consists solely of a bracketing for a sentence in
a language (where only those units that play the
role of a semantic argument or modifier in a larger
unit are bracketed) and a correspondence relation
of the constituents across languages.
Klyueva and Marec?ek (2010) present a small
parallel treebank using data and tools from two
existing treebanks. They take a syntactically an-
notated gold standard text for one language and
run an automated annotation on the parallel text
for the other language. Manually annotated Rus-
sian data are taken from the SynTagRus treebank
(Nivre et al, 2008), while tools for parsing the cor-
responding text in Czech are taken from the Tec-
toMT framework (Popel and Z?abokrtsky?, 2010).
The SMULTRON project is concerned with con-
structing a parallel treebank of English, German
and Swedish. The sentences have been POS-tagged
and annotated with phrase structure trees. These
trees have been aligned on the sentence, phrase
and word level. Additionally, the German and
Swedish monolingual treebanks contain lemma in-
formation. The treebank is distributed in TIGER-
XML format (Volk et al, 2010).
Megyesi et al (2010) discuss a parallel English-
Swedish-Turkish treebank. The sentences in each
language are annotated morphologically and syn-
tactically with automatic tools, aligned on the
sentence and the word level and partially hand-
corrected.3
A further parallel treebanking effort is Par-
TUT, a parallel treebank (Sanguinetti and Bosco,
2011; Bosco et al, 2012) which provides depen-
dency structures for Italian, English and French
and which can be converted to a CCG (Combina-
tory Categorial Grammar) format.
Closest to our work is the ParDeepBank, which
is engaged in the creation of a highly paral-
lel treebank of English, Portuguese and Bulgar-
ian. ParDeepBank is couched within the linguistic
framework of HPSG (Head-Driven Phrase Struc-
ture Grammar) and uses parallel automatic HPSG
grammars, employing the same tools and imple-
mentation strategies across languages (Flickinger
et al, 2012). The parallel treebank is aligned on
the sentence, phrase and word level.
In sum, parallel treebanks have so far fo-
cused exclusively on Indo-European languages
3The paper mentions Hindi as the fourth language, but
this is not yet available: http://stp.lingfil.uu.
se/?bea/turkiska/home-en.html.
(with Turkish providing the one exception) and
generally do not extend beyond three or four
languages. In contrast, our ParGramBank tree-
bank currently includes ten typologically differ-
ent languages from six different language families
(Altaic, Austronesian, Indo-European, Kartvelian,
Niger-Congo, Uralic).
A further point of comparison with ParDeep-
Bank is that it relies on dynamic treebanks, which
means that structures are subject to change dur-
ing the further development of the resource gram-
mars. In ParDeepBank, additional machinery is
needed to ensure correct alignment on the phrase
and word level (Flickinger et al, 2012, p. 105).
ParGramBank contains finalized analyses, struc-
tures and features that were designed collabora-
tively over more than a decade, thus guaranteeing
a high degree of stable parallelism. However, with
the methodology developed within XPAR, align-
ments can easily be recomputed from f-structure
alignments in case of grammar or feature changes,
so that we also have the flexible capability of
allowing ParGramBank to include dynamic tree-
banks.
3 ParGram and its Feature Space
The ParGram grammars use the LFG formalism
which produces c(onstituent)-structures (trees)
and f(unctional)-structures as the syntactic anal-
ysis. LFG assumes a version of Chomsky?s Uni-
versal Grammar hypothesis, namely that all lan-
guages are structured by similar underlying prin-
ciples (Chomsky, 1988; Chomsky, 1995). Within
LFG, f-structures encode a language universal
level of syntactic analysis, allowing for crosslin-
guistic parallelism at this level of abstraction. In
contrast, c-structures encode language particular
differences in linear word order, surface morpho-
logical vs. syntactic structures, and constituency
(Dalrymple, 2001). Thus, while the Chomskyan
framework is derivational in nature, LFG departs
from this view by embracing a strictly representa-
tional approach to syntax.
ParGram tests the LFG formalism for its uni-
versality and coverage limitations to see how far
parallelism can be maintained across languages.
Where possible, analyses produced by the gram-
mars for similar constructions in each language are
parallel, with the computational advantage that the
grammars can be used in similar applications and
that machine translation can be simplified.
552
The ParGram project regulates the features and
values used in its grammars. Since its inception
in 1996, ParGram has included a ?feature com-
mittee?, which collaboratively determines norms
for the use and definition of a common multilin-
gual feature and analysis space. Adherence to fea-
ture committee decisions is supported technically
by a routine that checks the grammars for com-
patibility with a feature declaration (King et al,
2005); the feature space for each grammar is in-
cluded in ParGramBank. ParGram also conducts
regular meetings to discuss constructions, analy-
ses and features.
For example, Figure 1 shows the c-structure
of the Urdu sentence in (1) and the c-structure
of its English translation. Figure 2 shows the f-
structures for the same sentences. The left/upper
c- and f-structures show the parse from the En-
glish ParGram grammar, the right/lower ones from
Urdu ParGram grammar.4,5 The c-structures en-
code linear word order and constituency and thus
look very different; e.g., the English structure is
rather hierarchical while the Urdu structure is flat
(Urdu is a free word-order language with no evi-
dence for a VP; Butt (1995)). The f-structures, in
contrast, are parallel aside from grammar-specific
characteristics such as the absence of grammati-
cal gender marking in English and the absence of
articles in Urdu.6
(1) ? Aj J
K. Q?K
QK A 	JK @ ?

	
G
	
?A??
kisAn=nE apnA
farmer.M.Sg=Erg self.M.Sg
TrEkTar bEc-A
tractor.M.Sg sell-Perf.M.Sg
?Did the farmer sell his tractor??
With parallel analyses and parallel features, maxi-
mal parallelism across typologically different lan-
guages is maintained. As a result, during the con-
struction of the treebank, post-processing and con-
version efforts are kept to a minimum.
4The Urdu ParGram grammar makes use of a translitera-
tion scheme that abstracts away from the Arabic-based script;
the transliteration scheme is detailed in Malik et al (2010).
5In the c-structures, dotted lines indicate distinct func-
tional domains; e.g., in Figure 1, the NP the farmer and the
VP sell his tractor belong to different f-structures: the former
maps onto the SUBJ f-structure, while the latter maps onto the
topmost f-structure (Dyvik et al, 2009). Section 6 elaborates
on functional domains.
6The CASE feature also varies: since English does not
distinguish between accusative, dative, and other oblique
cases, the OBJ is marked with a more general obl CASE.
Figure 1: English and Urdu c-structures
We emphasize the fact that ParGramBank is
characterized by a maximally reliable, human-
controlled and linguistically deep parallelism
across aligned sentences. Generally, the result of
automatic sentence alignment procedures are par-
allel corpora where the corresponding sentences
normally have the same purported meaning as
intended by the translator, but they do not nec-
essarily match in terms of structural expression.
In building ParGramBank, conscious attention is
paid to maintaining semantic and constructional
parallelism as much as possible. This design fea-
ture renders our treebank reliable in cases when
the constructional parallelism is reduced even at f-
structure. For example, typological variation in the
presence or absence of finite passive constructions
represents a case of potential mismatch. Hungar-
ian, one of the treebank languages, has no produc-
tive finite passives. The most common strategy in
translation is to use an active construction with a
topicalized object, with no overt subject and with
3PL verb agreement:
(2) A fa?-t ki-va?g-t-a?k.
the tree-ACC out-cut-PAST-3PL
?The tree was cut down.?
In this case, a topicalized object in Hungarian has
to be aligned with a (topical) subject in English.
Given that both the sentence level and the phrase
level alignments are human-controlled in the tree-
bank (see sections 4 and 6), the greatest possible
parallelism is reliably captured even in such cases
of relative grammatical divergence.
553
Figure 2: Parallel English and Urdu f-structures
4 Treebank Design and Construction
For the initial seeding of the treebank, we focused
on 50 sentences which were constructed manu-
ally to cover a diverse range of phenomena (tran-
sitivity, voice alternations, interrogatives, embed-
ded clauses, copula constructions, control/raising
verbs, etc.). We followed Lehmann et al (1996)
and Bender et al (2011) in using coverage of
grammatical constructions as a key component for
grammar development. (3) lists the first 16 sen-
tences of the treebank. An expansion to 100 sen-
tences is scheduled for next year.
(3) a. Declaratives:
1. The driver starts the tractor.
2. The tractor is red.
b. Interrogatives:
3. What did the farmer see?
4. Did the farmer sell his tractor?
c. Imperatives:
5. Push the button.
6. Don?t push the button.
d. Transitivity:
7. The farmer gave his neighbor an old
tractor.
8. The farmer cut the tree down.
9. The farmer groaned.
e. Passives and traditional voice:
10. My neighbor was given an old tractor
by the farmer.
11. The tree was cut down yesterday.
12. The tree had been cut down.
13. The tractor starts with a shudder.
f. Unaccusative:
14. The tractor appeared.
g. Subcategorized declaratives:
15. The boy knows the tractor is red.
16. The child thinks he started the tractor.
The sentences were translated from English
into the other treebank languages. Currently, these
languages are: English, Georgian, German, Hun-
garian, Indonesian, Norwegian (Bokma?l), Polish,
Turkish, Urdu and Wolof. The translations were
done by ParGram grammar developers (i.e., expert
linguists and native speakers).
The sentences were automatically parsed with
ParGram grammars using XLE. Since the pars-
ing was performed sentence by sentence, our re-
sulting treebank is automatically aligned at the
sentence level. The resulting c- and f-structures
were banked in a database using the LFG Parse-
banker (Rose?n et al, 2009). The structures were
disambiguated either prior to banking using XLE
or during banking with the LFG Parsebanker and
its discriminant-based disambiguation technique.
The banked analyses can be exported and down-
loaded in a Prolog format using the LFG Parse-
banker interface. Within XLE, we automatically
convert the structures to a simple XML format and
make these available via ParGramBank as well.
The Prolog format is used with applications
which use XLE to manipulate the structures, e.g.
for further semantic processing (Crouch and King,
2006) or for sentence condensation (Crouch et al,
2004).
554
5 Challenges for Parallelism
We detail some challenges in maintaining paral-
lelism across typologically distinct languages.
5.1 Complex Predicates
Some languages in ParGramBank make extensive
use of complex predicates. For example, Urdu uses
a combination of predicates to express concepts
that in languages like English are expressed with
a single verb, e.g., ?memory do? = ?remember?,
?fear come? = ?fear?. In addition, verb+verb com-
binations are used to express permissive or as-
pectual relations. The strategy within ParGram is
to abstract away from the particular surface mor-
phosyntactic expression and aim at parallelism
at the level of f-structure. That is, monoclausal
predications are analyzed via a simple f-structure
whether they consist of periphrastically formed
complex predicates (Urdu, Figure 3), a simple
verb (English, Figure 4), or a morphologically de-
rived form (Turkish, Figure 5).
In Urdu and in Turkish, the top-level PRED
is complex, indicating a composed predicate. In
Urdu, this reflects the noun-verb complex predi-
cate sTArT kar ?start do?, in Turkish it reflects a
morphological causative. Despite this morphosyn-
tactic complexity, the overall dependency struc-
ture corresponds to that of the English simple verb.
(4) ?


?
f
A

KQ ? HPA

J ? ? ? Q

 ? K
Q

K P?

J K
 @P

X
DrAIvar TrEkTar=kO
driver.M.Sg.Nom tractor.M.Sg=Acc
sTArT kartA hE
start.M.Sg do.Impf.M.Sg be.Pres.3Sg
?The driver starts the tractor.?
(5) su?ru?cu? trakto?r-u? c?al?s?-t?r-?yor
driver.Nom tractor-Acc work-Caus-Prog.3Sg
?The driver starts the tractor.?
The f-structure analysis of complex predicates
is thus similar to that of languages which do not
use complex predicates, resulting in a strong syn-
tactic parallelism at this level, even across typo-
logically diverse languages.
5.2 Negation
Negation also has varying morphosyntactic sur-
face realizations. The languages in ParGramBank
differ with respect to their negation strategies.
Languages such as English and German use inde-
pendent negation: they negate using words such as
Figure 3: Complex predicate: Urdu analysis of (4)
Figure 4: Simple predicate: English analysis of (4)
adverbs (English not, German nicht) or verbs (En-
glish do-support). Other languages employ non-
independent, morphological negation techniques;
Turkish, for instance, uses an affix on the verb, as
in (6).
555
Figure 5: Causative: Turkish analysis of (5)
(6) du?g?me-ye bas-ma
button-Dat push-Neg.Imp
?Don?t push the button.?
Within ParGram we have not abstracted away
from this surface difference. The English not in
(6) functions as an adverbial adjunct that modifies
the main verb (see top part of Figure 6) and infor-
mation would be lost if this were not represented
at f-structure. However, the same cannot be said of
the negative affix in Turkish ? the morphological
affix is not an adverbial adjunct. We have there-
fore currently analyzed morphological negation as
adding a feature to the f-structure which marks the
clause as negative, see bottom half of Figure 6.
5.3 Copula Constructions
Another challenge to parallelism comes from co-
pula constructions. An approach advocating a uni-
form treatment of copulas crosslinguistically was
advocated in the early years of ParGram (Butt et
al., 1999b), but this analysis could not do justice to
the typological variation found with copulas. Par-
GramBank reflects the typological difference with
three different analyses, with each language mak-
ing a language-specific choice among the three
possibilities that have been identified (Dalrymple
et al, 2004; Nordlinger and Sadler, 2007; Attia,
2008; Sulger, 2011; Laczko?, 2012).
The possible analyses are demonstrated here
with respect to the sentence The tractor is red.
The English grammar (Figure 7) uses a raising ap-
proach that reflects the earliest treatments of cop-
ulas in LFG (Bresnan, 1982). The copula takes
a non-finite complement whose subject is raised
to the matrix clause as a non-thematic subject of
the copula. In contrast, in Urdu (Figure 8), the
Figure 6: Different f-structural analyses for nega-
tion (English vs. Turkish)
copula is a two-place predicate, assigning SUBJ
and PREDLINK functions. The PREDLINK function
is interpreted as predicating something about the
subject. Finally, in languages like Indonesian (Fig-
ure 9), there is no overt copula and the adjective is
the main predicational element of the clause.
Figure 7: English copula example
556
Figure 8: Urdu copula example
Figure 9: Indonesian copula example
5.4 Summary
This section discussed some challenges for main-
taining parallel analyses across typologically di-
verse languages. Another challenge we face is
when no corresponding construction exists in a
language, e.g. with impersonals as in the English
It is raining. In this case, we provide a translation
and an analysis of the structure of the correspond-
ing translation, but note that the phenomenon be-
ing exemplified does not actually exist in the lan-
guage. A further extension to the capabilities of
the treebank could be the addition of pointers from
the alternative structure used in the translation to
the parallel aligned set of sentences that corre-
spond to this alternative structure.
6 Linguistically Motivated Alignment
The treebank is automatically aligned on the sen-
tence level, the top level of alignment within Par-
GramBank. For phrase-level alignments, we use
the drag-and-drop alignment tool in the LFG Parse-
banker (Dyvik et al, 2009). The tool allows the
alignment of f-structures by dragging the index
of a subsidiary source f-structure onto the index
of the corresponding target f-structure. Two f-
structures correspond if they have translationally
matching predicates, and the arguments of each
predicate correspond to an argument or adjunct in
the other f-structure. The tool automatically com-
putes the alignment of c-structure nodes on the
basis of the manually aligned corresponding f-
structures.7
7Currently we have not measured inter-annotator agree-
ment (IAA) for the f-structure alignments. The f-structure
alignments were done by only one person per language pair.
We anticipate that multiple annotators will be needed for this
This method is possible because the c-structure
to f-structure correspondence (the ? relation) is
encoded in the ParGramBank structures, allow-
ing the LFG Parsebanker tool to compute which c-
structure nodes contributed to a given f-structure
via the inverse (??1) mapping. A set of nodes
mapping to the same f-structure is called a ?func-
tional domain?. Within a source and a target
functional domain, two nodes are automatically
aligned only if they dominate corresponding word
forms. In Figure 10 the nodes in each func-
tional domain in the trees are connected by whole
lines while dotted lines connect different func-
tional domains. Within a functional domain, thick
whole lines connect the nodes that share align-
ment; for simplicity the alignment is only indi-
cated for the top nodes. The automatically com-
puted c-structural alignments are shown by the
curved lines. The alignment information is stored
as an additional layer and can be used to ex-
plore alignments at the string (word), phrase (c-
)structure, and functional (f-)structure levels.
We have so far aligned the treebank pairs
English-Urdu, English-German, English-Polish
and Norwegian-Georgian. As Figure 10 illustrates
for (7) in an English-Urdu pairing, the English ob-
ject neighbor is aligned with the Urdu indirect ob-
ject (OBJ-GO) hamsAyA ?neighbor?, while the En-
glish indirect object (OBJ-TH) tractor is aligned
with the Urdu object TrEkTar ?tractor?. The c-
structure correspondences were computed auto-
matically from the f-structure alignments.
(7) AK
X Q?K
QK A 	K @QK ?? ?
G
A???f ?

	
?K @ ?

	
G
	
?A??
kisAn=nE apnE
farmer.M.Sg=Erg self.Obl
hamsAyE=kO purAnA
neighbor.M.Sg.Obl=Acc old.M.Sg
TrEkTar di-yA
tractor.M.Sg give-Perf.M.Sg
?The farmer gave his neighbor an old tractor.?
The INESS platform additionally allows for the
highlighting of connected nodes via a mouse-over
technique. It thus provides a powerful and flexible
tool for the semi-automatic alignment and subse-
task in the future, in which case we will measure IAA for this
step.
557
Figure 10: Phrase-aligned treebank example English-Urdu: The farmer gave his neighbor an old tractor.
quent inspection of parallel treebanks which con-
tain highly complex linguistic structures.8
7 Discussion and Future Work
We have discussed the construction of ParGram-
Bank, a parallel treebank for ten typologically
different languages. The analyses in ParGram-
Bank are the output of computational LFG Par-
Gram grammars. As a result of ParGram?s cen-
trally agreed upon feature sets and prototypical
analyses, the representations are not only deep
in nature, but maximally parallel. The representa-
tions offer information about dependency relations
as well as word order, constituency and part-of-
speech.
In future ParGramBank releases, we will pro-
vide more theory-neutral dependencies along with
the LFG representations. This will take the form of
triples (King et al, 2003). We also plan to provide
a POS-tagged and a named entity marked up ver-
sion of the sentences; these will be of use for more
general NLP applications and for systems which
use such markup as input to deeper processing.
8One reviewer inquires about possibilities of linking
(semi-)automatically between languages, for example using
lexical resources such as WordNets or Panlex. We agree that
this would be desirable, but unrealizable, since many of the
languages included in ParGramBank do not have a WordNet
resource and are not likely to achieve an adequate one soon.
Third, the treebank will be expanded to include
100 more sentences within the next year. We also
plan to include more languages as other ParGram
groups contribute structures to ParGramBank.
ParGramBank, including its multilingual sen-
tences and all annotations, is made freely avail-
able for research and commercial use under the
CC-BY 3.0 license via the INESS platform, which
supports alignment methodology developed in the
XPAR project and provides search and visualiza-
tion methods for parallel treebanks. We encourage
the computational linguistics community to con-
tribute further layers of annotation, including se-
mantic (Crouch and King, 2006), abstract knowl-
edge representational (Bobrow et al, 2007), Prop-
Bank (Palmer et al, 2005), or TimeBank (Mani
and Pustejovsky, 2004) annotations.
References
Mohammed Attia. 2008. A Unified Analysis of Cop-
ula Constructions. In Proceedings of the LFG ?08
Conference, pages 89?108. CSLI Publications.
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2011. Grammar Engineering and Linguistic Hy-
pothesis Testing: Computational Support for Com-
plexity in Syntactic Analysis. In Emily M. Bender
and Jennifer E. Arnold, editors, Languages from a
Cognitive Perspective: Grammar, Usage and Pro-
cessing, pages 5?30. CSLI Publications.
558
Daniel G. Bobrow, Cleo Condoravdi, Dick Crouch,
Valeria de Paiva, Lauri Karttunen, Tracy Holloway
King, Rowan Nairn, Lottie Price, and Annie Zaenen.
2007. Precision-focused Textual Inference. In Pro-
ceedings of the ACL-PASCAL Workshop on Textual
Entailment and Paraphrasing.
Cristina Bosco, Manuela Sanguinetti, and Leonardo
Lesmo. 2012. The Parallel-TUT: a multilingual and
multiformat treebank. In Proceedings of the Eighth
International Conference on Language Resources
and Evaluation (LREC-2012), pages 1932?1938, Is-
tanbul, Turkey. European Language Resources As-
sociation (ELRA).
Joan Bresnan. 1982. The Passive in Lexical Theory. In
Joan Bresnan, editor, The Mental Representation of
Grammatical Relations, pages 3?86. The MIT Press.
Joan Bresnan. 2001. Lexical-Functional Syntax.
Blackwell Publishing.
Miriam Butt, Stefanie Dipper, Anette Frank, and
Tracy Holloway King. 1999a. Writing Large-
Scale Parallel Grammars for English, French and
German. In Proceedings of the LFG99 Conference.
CSLI Publications.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999b. A Grammar
Writer?s Cookbook. CSLI Publications.
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
Parallel Grammar Project. In Proceedings of the
COLING-2002 Workshop on Grammar Engineering
and Evaluation, pages 1?7.
Miriam Butt. 1995. The Structure of Complex Predi-
cates in Urdu. CSLI Publications.
Noam Chomsky. 1988. Lectures on Government and
Binding: The Pisa Lectures. Foris Publications.
Noam Chomsky. 1995. The Minimalist Program. MIT
Press.
Dick Crouch and Tracy Holloway King. 2006. Seman-
tics via F-structure Rewriting. In Proceedings of the
LFG06 Conference, pages 145?165. CSLI Publica-
tions.
Dick Crouch, Tracy Holloway King, John T. Maxwell
III, Stefan Riezler, and Annie Zaenen. 2004. Ex-
ploiting F-structure Input for Sentence Condensa-
tion. In Proceedings of the LFG04 Conference,
pages 167?187. CSLI Publications.
Dick Crouch, Mary Dalrymple, Ronald M. Kaplan,
Tracy Holloway King, John T. Maxwell III, and
Paula Newman, 2012. XLE Documentation. Palo
Alto Research Center.
Mary Dalrymple, Helge Dyvik, and Tracy Holloway
King. 2004. Copular Complements: Closed or
Open? In Proceedings of the LFG ?04 Conference,
pages 188?198. CSLI Publications.
Mary Dalrymple. 2001. Lexical Functional Gram-
mar, volume 34 of Syntax and Semantics. Academic
Press.
Helge Dyvik, Paul Meurer, Victoria Rose?n, and Koen-
raad De Smedt. 2009. Linguistically Motivated Par-
allel Parsebanks. In Proceedings of the Eighth In-
ternational Workshop on Treebanks and Linguistic
Theories (TLT8), pages 71?82, Milan, Italy. EDU-
Catt.
Dan Flickinger, Valia Kordoni, Yi Zhang, Anto?nio
Branco, Kiril Simov, Petya Osenova, Catarina Car-
valheiro, Francisco Costa, and Se?rgio Castro. 2012.
ParDeepBank: Multiple Parallel Deep Treebank-
ing. In Proceedings of the 11th International Work-
shop on Treebanks and Linguistic Theories (TLT11),
pages 97?107, Lisbon. Edic?o?es Colibri.
Tracy Holloway King, Richard Crouch, Stefan Riezler,
Mary Dalrymple, and Ronald Kaplan. 2003. The
PARC700 Dependency Bank. In Proceedings of the
EACL03: 4th International Workshop on Linguisti-
cally Interpreted Corpora (LINC-03).
Tracy Holloway King, Martin Forst, Jonas Kuhn, and
Miriam Butt. 2005. The Feature Space in Paral-
lel Grammar Writing. In Emily M. Bender, Dan
Flickinger, Frederik Fouvry, and Melanie Siegel, ed-
itors, Research on Language and Computation: Spe-
cial Issue on Shared Representation in Multilingual
Grammar Engineering, volume 3, pages 139?163.
Springer.
Natalia Klyueva and David Marec?ek. 2010. To-
wards a Parallel Czech-Russian Dependency Tree-
bank. In Proceedings of the Workshop on Anno-
tation and Exploitation of Parallel Corpora, Tartu.
Northern European Association for Language Tech-
nology (NEALT).
Jonas Kuhn and Michael Jellinghaus. 2006. Multilin-
gual Parallel Treebanking: A Lean and Flexible Ap-
proach. In Proceedings of the LREC 2006, Genoa,
Italy. ELRA/ELDA.
Tibor Laczko?. 2012. On the (Un)Bearable Lightness
of Being an LFG Style Copula in Hungarian. In Pro-
ceedings of the LFG12 Conference, pages 341?361.
CSLI Publications.
Sabine Lehmann, Stephan Oepen, Sylvie Regnier-
Prost, Klaus Netter, Veronika Lux, Judith Klein,
Kirsten Falkedal, Frederik Fouvry, Dominique Esti-
val, Eva Dauphin, Herve? Compagnion, Judith Baur,
Lorna Balkan, and Doug Arnold. 1996. TSNLP ?
Test Suites for Natural Language Processing. In
Proceedings of COLING, pages 711 ? 716.
Muhammad Kamran Malik, Tafseer Ahmed, Sebastian
Sulger, Tina Bo?gel, Atif Gulzar, Ghulam Raza, Sar-
mad Hussain, and Miriam Butt. 2010. Transliter-
ating Urdu for a Broad-Coverage Urdu/Hindi LFG
Grammar. In Proceedings of the Seventh Con-
ference on International Language Resources and
Evaluation (LREC 2010), Valletta, Malta.
559
Inderjeet Mani and James Pustejovsky. 2004. Tem-
poral Discourse Models for Narrative Structure. In
Proceedings of the 2004 ACL Workshop on Dis-
course Annotation, pages 57?64.
Bea?ta Megyesi, Bengt Dahlqvist, E?va A?. Csato?, and
Joakim Nivre. 2010. The English-Swedish-Turkish
Parallel Treebank. In Proceedings of the Seventh
International Conference on Language Resources
and Evaluation (LREC?10), Valletta, Malta. Euro-
pean Language Resources Association (ELRA).
Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective Sharing for Multilingual Depen-
dency Parsing. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 629?637,
Jeju Island, Korea, July. Association for Computa-
tional Linguistics.
Joakim Nivre, Igor Boguslavsky, and Leonid Iomdin.
2008. Parsing the SynTagRus Treebank. In Pro-
ceedings of COLING08, pages 641?648.
Rachel Nordlinger and Louisa Sadler. 2007. Verb-
less Clauses: Revealing the Structure within. In An-
nie Zaenen, Jane Simpson, Tracy Holloway King,
Jane Grimshaw, Joan Maling, and Chris Manning,
editors, Architectures, Rules and Preferences: A
Festschrift for Joan Bresnan, pages 139?160. CSLI
Publications.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71?106.
Martin Popel and Zdene?k Z?abokrtsky?. 2010. Tec-
toMT: Modular NLP Framework. In Proceedings
of the 7th International Conference on Advances in
Natural Language Processing (IceTAL 2010), pages
293?304.
Victoria Rose?n, Paul Meurer, and Koenraad de Smedt.
2009. LFG Parsebanker: A Toolkit for Building and
Searching a Treebank as a Parsed Corpus. In Pro-
ceedings of the 7th International Workshop on Tree-
banks and Linguistic Theories (TLT7), pages 127?
133, Utrecht. LOT.
Victoria Rose?n, Koenraad De Smedt, Paul Meurer, and
Helge Dyvik. 2012. An Open Infrastructure for Ad-
vanced Treebanking. In META-RESEARCH Work-
shop on Advanced Treebanking at LREC2012, pages
22?29, Istanbul, Turkey.
Manuela Sanguinetti and Cristina Bosco. 2011. Build-
ing the Multilingual TUT Parallel Treebank. In Pro-
ceedings of Recent Advances in Natural Language
Processing, pages 19?28.
Sebastian Sulger. 2011. A Parallel Analysis of have-
Type Copular Constructions in have-Less Indo-
European Languages. In Proceedings of the LFG
?11 Conference. CSLI Publications.
Josef van Genabith and Dick Crouch. 1996. Direct and
Underspecified Interpretations of LFG f-structures.
In Proceedings of the 16th International Conference
on Computational Linguistics (COLING-96), vol-
ume 1, pages 262?267, Copenhagen, Denmark.
Martin Volk, Anne Go?hring, Torsten Marek,
and Yvonne Samuelsson. 2010. SMUL-
TRON (version 3.0) ? The Stock-
holm MULtilingual parallel TReebank.
http://www.cl.uzh.ch/research/paralleltreebanks en.
html.
560
