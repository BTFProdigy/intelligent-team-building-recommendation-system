Towards User-Adaptive Annotation Guidelines
Stefanie Dipper, Michael Go?tze, Stavros Skopeteas
Dept. of Linguistics
D-14415 Potsdam, Germany
{dipper,goetze}@ling.uni-potsdam.de
skopetea@rz.uni-potsdam.de
Abstract
In this paper we address the issue of user-
adaptivity for annotation guidelines. We show
that different user groups have different needs
towards these documents, a fact neglected by
most of current annotation guidelines. We pro-
pose a formal specification of the structure of
annotation guidelines, thus suggesting a mini-
mum set of requirements that guidelines should
fulfill. Finally, we sketch the use of these speci-
fications by exemplary applications, resulting in
user-specific guideline representations.
1 Introduction
Linguistic research nowadays makes heavy use of
annotated corpora. The benefit that researchers may
gain from corpora depends to a large extent on doc-
umentation of the annotation. According to Leech?s
maxims, the guidelines that were applied in the an-
notation of the corpus should be accessible to the
user of the corpus (and thus serve as a kind of doc-
umentation), see Leech (1993).1
In this paper, we argue that annotation guidelines,
which are optimized for use by the annotators of the
corpus, often cannot serve as suitable documenta-
tion for users of the annotated corpus. We illustrate
this claim by different types of prototypical corpus
users, who have different needs with respect to doc-
umentation. Extending the proposal by MATE (Dy-
bkjaer et al, 1998), we sketch a preliminary specifi-
cation for annotation guidelines. We then show how
guidelines that are standardized in this way may be
adapted to different user needs and serve both as
guidelines, applied in the annotation process, and
documentation, used by different corpus users.
1
?The annotation scheme should be based on guide-
lines which are available to the end user. Most corpora
have a manual which contains full details of the annota-
tion scheme and guidelines issued to the annotators. This
enables the user to understand fully what each instance of
annotation represents without resorting to guesswork, and
to understand in cases of ambiguity why a particular an-
notation decision was made at that point.?, Leech (1993),
cited by http://www.ling.lancs.ac.uk/monkey/
ihe/linguistics/corpus2/2maxims.htm.
This paper grew out of our work in the Son-
derforschungsbereich (SFB, collaborative research
center) on information structure at the University of
Potsdam.2 In the context of this SFB, several indi-
vidual projects collect a large amount of data of di-
verse languages and annotate them on various anno-
tation levels: phonetics/phonology, morpho-syntax,
semantics, and information structure.
Within the SFB, guidelines for the different anno-
tation levels are being created. In order to maximize
the profit of these data, we are developing standard
recommendations on the format and content of the
SFB annotation guidelines. These guidelines ought
to serve the SFB annotators as well as the research
community.
The paper is organized as follows. We first
present different user profiles with different needs
towards annotation guidelines (sec. 2). We then ana-
lyze the form and content of selected existing guide-
lines to some detail (sec. 3) and show that these
guidelines fulfill the user needs only inadequately
(sec. 4). Finally, we sketch a formal specification of
the structure of annotation guidelines and indicate
how XML/XSLT technology can be used to support
user-adaptive annotation guidelines (sec. 5).
2 Guideline Users
Annotation guidelines are used by different types of
users with different requirements. These require-
ments depend on (i) the user?s objectives and (ii)
the user?s background.
2.1 User Objectives
People are interested in annotation guidelines for
different reasons. According to their respective ob-
jectives, we define five user profiles.3
The annotator Annotators assign linguistic fea-
tures to language data, according to criteria and
2http://www.ling.uni-potsdam.de/sfb/
3In a similar way, Carletta and Isard (1999) define three
user types: the coder, the coding consumer, and the coding de-
veloper. These classes, however, refer to users of annotation
workbenches rather than annotation guidelines.
instructions specified in the annotation guidelines.
Important annotation criteria are consistency and
speed.
The corpus explorer The group of corpus explor-
ers encompasses all those who aim at exploiting lin-
guistic data in order to find evidence for or against
linguistic hypotheses. These people need to know
(i) how to find instances of specific phenomena they
are interested in, and (ii) how to interpret the anno-
tations of the phenomena in question.
The language engineer Instead of inspecting the
data ?manually?, as the corpus explorer does, the
language engineer applies automatic methods to the
annotated data to process them further. This in-
cludes a variety of tasks, such as statistical evalu-
ations, training and testing of algorithms, and the
extraction of various types of linguistic information.
The guideline explorer The guidelines per se
(i.e., independently of a corpus) are of interest to,
e.g., theoretical linguists who want to know the
principles that underlie the annotation guidelines. In
addition, the guidelines may serve as an example for
authors of other annotation guidelines.
The guideline author The process of writing
guidelines is usually a time-consuming and step-
wise process. Hence, during the process of writ-
ing, the authors themselves make use of their own
guidelines to look up related or similar phenomena
that are already covered therein.
2.2 User Background
A further factor putting constraints on annotation
guidelines is the user?s background. First, (non-)
acquaintance with the language of the corpus is an
important factor: if corpora should be useful also
for people who do not or hardly know the language
of the corpus, annotation guidelines should provide
translations for example sentences and basic infor-
mation about linguistic properties of the object lan-
guage.
Second, (non-)acquaintance with theoretical
analyses of the phenomena has an impact on re-
quirements towards guidelines. People who are ac-
quainted with the linguistic theory that the guide-
lines are based on do not need theoretical introduc-
tions; an example is the Feldertheorie (field theory
of word order) in German, which serves as the basis
of the analyses in the German Verbmobil Treebank
(Stegmann et al, 2000). In addition, people who
know about alternative (competing) analyses of the
phenomena in question may want to know the rea-
sons of the chosen analysis.
3 Form and Content of Guidelines
We consider sample guidelines from different types
of annotation; all sample guidelines are available
via the internet. These guidelines have been cho-
sen to set out the diversity among different lev-
els of linguistic analysis?from morphology to
pragmatics?and among practices established in
different linguists? communities?from typologists
to language engineers.4
Interlinear morphemic transcription EU-
ROTYP (Ko?nig et al, 1993), Leipzig Glossing
Rules (Bickel et al, 2004). These guidelines deal
with the annotation of morpheme boundaries and
morpheme-by-morpheme translation (glossing);
these guidelines have been created by and for
typologists.5
Morphosyntactic annotation Penn Treebank
(POS-tagging guidelines, ?POS?) (Santorini,
1995), STTS (Schiller et al, 1999). These guide-
lines have been developed by language engineers
for (semi-)automatic annotation of morphosyntactic
information.6
Syntactic annotation Penn Treebank (bracketing
guidelines, ?BG?) (Bies et al, 1995), SPARKLE
(Carroll et al, 1997), VerbMobil, German Treebank
(Stegmann et al, 2000).7
Semantic/pragmatic annotation PropBank
(PropBank Project, 2002), Penn Discourse Tree-
bank (Mitsakaki et al, 2004), DAMSL (Dialog
Act Markup in Several Layers, Allen and Core
(1997)). PropBank and Penn Discourse Treebank
are extensions of the Penn Treebank.
We focus on three aspects of annotation guide-
lines: the components of guideline documents
4The sample guidelines also vary with regard to size (e.g.,
the Leipzig Glossing Rules comprise 9 pages, the Penn Tree-
bank Bracketing Guidelines 317 pages) and status (e.g., the
VerbMobil guidelines are completed, whereas guidelines such
as the Penn Discourse Treebank guidelines are still being de-
veloped).
5We consider only the rules for morphemic transcription
and not the glossing abbreviations in these documents.
6EAGLES provides recommendations for the design of
morphosyntactic tagsets (Leech and Wilson, 1996). Tagsets
represent only a component of annotation guidelines. The
STTS tagset can be viewed as an instantiation of the EAGLES
recommendations.
7A very detailed annotation scheme for syntactic, semantic
and speech annotation is available in book form for the SU-
SANNE corpus (Sampson, 1995). These guidelines are ad-
dressed primarily to the guideline explorer rather than the an-
notator. In this vein, the book provides a detailed discussion
of the annotation principles and theoretical background. We do
not include these guideline in our discussion, since they are not
available electronically.
A B C D E F G H I J K L M N O P
EUROTYP + + + + + +
Leipzig Glossing Rules + + + + + + + +
Penn Treebank (POS) + + + + + + + +
STTS + + + + + + +
Penn Treebank (BG) + + + + + + + + +
VerbMobil Treebank + + + + + + + + +
SPARKLE + + + + + + + +
PropBank + + + + + + + +
Penn Discourse Treebank + + + + + +
DAMSL + + + + + +
Document components:
A general principles
B underlying linguistic theory
C tagset declaration
D related annotation schemes
E tag index
F keyword index
Instruction components:
G keywords
H criteria
I examples
J related instructions
K alternative analyses
Instruction ordering:
L alphabetical tags
M alphabetical keywords
N content-based structure
O default?specific/exceptional
P simple?difficult
Figure 1: Features of the sample guidelines
(sec. 3.1), the components of an annotation instruc-
tion (sec. 3.2), and the ordering of instructions with
respect to each other (sec. 3.3).
3.1 Document Components
The document architecture varies to some extent in
the sample guidelines. In general, however, there is
(i) an introductory part, (ii) the main section, and
(iii) appendices. In the following, we sketch pro-
totypical components of these parts; to a large ex-
tent, these components overlap with the elements
proposed by Dybkjaer et al (1998). The table in
fig. 1 presents an overview of most of the guide-
line components considered here. The differences
between the guidelines can (partly) be attributed to
the fact that the guidelines address different types of
users.
Introductory part This part comprises basic in-
formation such as the name of the guidelines, the
annotation goal, the type of source data, the anno-
tation markup (e.g., syntactic annotation can be en-
coded by brackets vs. graphs, etc.). In addition, it
addresses general design principles, including gen-
eral annotation conventions (A8), and the underly-
ing linguistic theory and/or statements about theo-
retical problems (B). A general tagset declaration
in the form of an exhaustive list of all admissible
tags plus a short description is often included (C).
Some guidelines refer to related annotation schemes
or standard recommendations like EAGLES (Leech
and Wilson, 1996) (D). Finally, creation notes in-
form about the authors, creation date, status of the
guidelines, etc.
8The letters refer to the table in fig. 1.
Main section This section is always devoted to
the presentation of the actual annotation guidelines,
which we call ?(annotation) instructions?. These
will be discussed in detail in sec. 3.2 and 3.3.
Appendices Some guidelines provide tutorials in
the form of exercises for practicing the use of the an-
notation guidelines. Different types of indices (i.e.,
listings of items, e.g. tags, and numbers of all pages
that refer to these items) may be included: alpha-
betical index of the tags (E); thematic indices, e.g.
an index of keywords such as ?wh-clefts? (F). In ad-
dition, lists of specific problematic words or con-
structions may be given. Finally, some guidelines
include recommendations for annotation tools and
methods.
3.2 Instruction Components
The core component of annotation guidelines is rep-
resented by the annotation instructions. We first de-
scribe the form and content of an individual instruc-
tion before addressing the question of how the set
of instructions is ordered/structured (sec. 3.3). We
illustrate the description by two annotation instruc-
tions from the Penn Treebank (POS), displayed in
fig. 2.
An individual instruction always refers to one (or
more) tags that represent the information to be an-
notated, e.g., ?VB?. The instruction usually provides
some sort of keywords (G) for the phenomenon in
question, e.g., ?verb, base form? (e.g., headers may
provide such keywords). The guidelines in the sam-
ple include annotation criteria (H) in the form of
a descriptive text (?This tag subsumes . . . ?) and
some illustrative examples (I) (?Do/VB it.?). Some-
Verb, base form?VB
This tag subsumes imperatives, infinitives and subjunctives.
EXAMPLES: Imperative: Do/VB it.
Infinitive: You should do/VB it. [. . . ]
Subjunctive: We suggested that he do/VB it.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
VB or VBP
If you are unsure whether a form is subjunctive (VB) or a present tense verb (VBP), replace the subject by a
third person pronoun. If the verb takes an -s ending, then the original form is a present tense verb (VBP); if
not, it is a subjunctive (VB).
EXAMPLE: I recommended that you do/VB it.
(cf. I recommended that he do/*does it.)
Figure 2: Two instructions from the Penn Treebank POS-tagging guidelines (Santorini, 1995, pp. 5, 21)
times, the guidelines also specify how to segment
the source data.
Often, the instructions make reference to other,
closely related instructions (whose annotation crite-
ria are similar to the current criteria) and emphasize
the differences between them (?If you are unsure
whether . . . ?) (J). Finally, alternative (competing)
analyses may be given (K).9
3.3 Instruction Ordering
Guidelines present annotation instructions in a cer-
tain order. The ordering of instructions is a crucial
aspect of the instructions? presentation: different or-
dering principles implement different perspectives
to the guidelines and, consequently, serve require-
ments of different groups of users (cf. sec. 4).
The sample guidelines make use of the following
ordering principles:
Alphabetical order of the tags (L) In the sec-
tion on problematic cases, the Penn Treebank (POS)
present the tags and their instructions in an alpha-
betical order (from ?CC? to ?WDT?). (Other guide-
lines make use of this type of ordering in an addi-
tional tag index.)
Alphabetical order of keywords (M) Canonical
cases in the Penn Treebank (POS) are ordered al-
phabetically with respect to keywords (from ?Adjec-
tive? to ?Wh-adverb?).
Content-based structure (N) Instructions are of-
ten presented in thematic units, e.g. all tags encod-
ing nominal features are grouped together. More-
over, complex annotation guidelines are usually or-
ganized in an hierarchical structure, with chapters,
sections, etc., which mirror the complex structure of
9The guidelines considered here at most allude implicitely
to alternative analyses: by giving arguments in favour of the
chosen analaysis.
the described phenomena. For instance, the Verb-
Mobil guidelines contain a chapter about the anno-
tation of phrasal constituents, with sections address-
ing NPs, PPs, etc., and PP subsections addressing
prepositions and circum/postpositions. In DAMSL,
criteria in the form of decision trees guide the anno-
tator through the annotation.
From default to specific/exceptional cases (O)
This is an ordering principle that is usually used
in combination with other principles. For instance,
single sentences are presented before multiple sen-
tences in the guidelines of the Penn Discourse Tree-
bank.
Degree of difficulty (P) Similarly, in combina-
tion with other ordering principles, the guidelines
often proceed from easy to difficult cases. For in-
stance, the Leipzig Glossing Rules first introduce
morphemic transcription of prefixes and suffixes.
Only later are infixes and circumfixes addressed;
these represent a problematic case for interlinear
morphemic translations due to the lack of isomor-
phism between the layer of transcription and the
layer of translation.
Usually, guidelines make use of several ordering
principles, e.g., main instructions are structured ac-
cording to content, (embedded) subinstructions are
ordered from default to specific case, and indices are
ordered alphabetically according to keywords.
4 User Requirements
Current annotation projects usually do not provide
separate guideline documents for different types of
users. Usually, annotation documentation emerges
from the annotating practice, supporting the an-
notator in the annotation task. At the publish-
ing stage, this documentation is often transferred
into a more general document, by adding informa-
tion about annotation conventions, format, methods,
etc.?however, the basic structure of the annotations
instructions remains unaltered. The obvious conse-
quence of this practice is that existing guidelines of-
ten ignore the requirements of certain types of users.
We illustrate different user requirements by some
typical examples. These requirements concern (i)
document components, (ii) instruction components,
and (iii) instruction ordering:
Annotator Typical users are annotators who are
confronted with the guidelines for the first time.
(i) Annotators primarily need a tutorial introduction
and maybe information about the annotation goals.
(ii) They have to learn specific instructions, sup-
ported by didactic examples.
(iii) The appropriate order is from default to excep-
tional or from easy to difficult. Orderings in the
form of decision trees may facilitate the acquisition.
Corpus explorer A further sample user is a re-
searcher who looks for a specific phenomenon in
the corpus:
(i) Corpus explorers need an index of phenomena
(keywords) to look up the tags that encode the phe-
nomenon they are interested in. Moreover, when
inspecting the encoding of this phenomenon, they
might come across other tags they are not yet famil-
iar with. Hence, they also need an index of tags (or
a tagset declaration) to look up the meaning of these
tags.
(ii) They need detailed information about the anno-
tation criteria. Take, for instance, a corpus that is
annotated with respect to information-structural cat-
egories and imagine a corpus explorer who is inter-
ested in topic and focus. Before looking for data,
s/he has to know the exact definitions (criteria) of
topic and focus that have been applied in the anno-
tation.
(iii) The easiest way for the corpus explorer to find
annotation criteria of phenomena and tags is by
means of an alphabetic ordering.
Language engineer Finally, language engineers
may undertake a statistical evaluation of the corpus
data:
(i) They primarily need a tagset declaration, with-
out being interested in any details. In addition, the
circumstances of the annotation are relevant (e.g.,
whether the corpus has been annotated manually,
twice, etc.).
(ii), (iii) Probably, the language engineer would not
need any information about annotation instructions.
Comparing these user requirements and the
guideline features in fig. 1, we see that the guide-
lines are more oriented towards the annotator than
the corpus explorer: Features such as indices (E, F)
are often missing, whereas the predominant instruc-
tion ordering is content-based ordering (N).
5 Towards User-Adaptive Annotation
Guidelines
In what follows, we present a preliminary guideline
specification that allows for generating user-adapted
guideline representations. In the second part, we
illustrate the applicability of the specification.
5.1 Guideline Specification
For the specification of user-adaptive guidelines we
adopt ideas from the MATE Markup Framework
(Dybkjaer et al, 1998), which uses so-called Cod-
ing Modules for the specification and representa-
tion of annotation schemes. Building upon MATE,
we define semi-formal class specifications, Guide-
line modules, which we extend with an Instruction
module for the annotation instructions.10 In con-
trast to MATE, we understand the Guideline module
as an underlying specification from which different
representations can be generated. We sketch how
the guidelines can be encoded by XML, which en-
ables the generation of user-adapted representations
through stylesheet technology (e.g. XSLT).
The Guideline module The guideline module
(see fig. 3) constitutes the basis for the specifica-
tion of annotation guidelines. It includes a subset
of the items in the MATE Coding modules and the
document components introduced and explained in
sec. 3.1. Components that can be derived automati-
cally, such as the tagset declaration and indices, are
not part of the specification, since these can be gen-
erated from the information present in the Instruc-
tion module.
The Instruction module Annotation instructions
are specified in the Instruction module. In fig. 4,
we sketch a preliminary XML representation of the
two instructions in fig. 2. The single elements and
attributes specify the instruction components exem-
plified there. In addition, the instruction for the tag
?VB? refers to the second instruction via the ?re-
lated? element, marking it as a ?problematic case?.
The second instruction indeed helps the annotator
to decide between the assignment of two tags, ?VB?
and ?VBP?. For both tags, ?criterion? elements with
application conditions, the respective annotation ac-
tion, and examples are declared.
10The MATE Markup Framework neither addresses the en-
coding of annotation guidelines nor the issue of user-adaptivity
explicitly.
# Component Example
1 Guideline title Part-of-speech tagging guidelines for the Penn Treebank, 3rd Revision
2 Annotated information Part of speech
3 Type of source data English text
4 General principles ...
(annotation conventions & format)
5 Relation to linguistic theories ...
6 Related annotation schemes Bies et al (1995):?Bracketing Guidelines for Treebank II Style?, . . .
7 Annotation instructions ? INSTRUCTION MODULE
8 Creation notes: authors, status, etc. Beatrice Santorini, 1995, 3rd revision
Figure 3: The Guideline module
<instruction tags="VB" keywords="verb, base form" difficulty="easy"
id="instr 1">
<text>This tag subsumes imperatives, infinitives and subjunctives</text>
<criterion>
<condition>verb in base form</condition>
<action>label VB</action>
<example comment="imperative">Do/VB it.</example>
<example comment="infinitive">You should do/VB it.</example>
<example comment="subjunctive">We suggested that he do/VB it.</example>
</criterion>
<related type="problematic case" ref="instr 23"/>
</instruction>
......................................................................................................
<instruction tags="VB, VBP" keywords="verb, subjunctive, present tense"
difficulty="medium" id="instr 23">
<text>If you are unsure whether a form is a subjunctive (VB) or a present
tense verb (VBP), replace the subject by a third person pronoun.</text>
<criterion>
<condition>verb does not take an -s ending</condition>
<action>label VB</action>
<example>I recommended that you do/VB it.</example>
<test>I recommend that he do/*does it.</test>
</criterion>
<criterion>
<condition>verb takes an -s ending</condition>
<action>label VBP</action>
</criterion>
</instruction>
Figure 4: Instructions of fig. 2 as specified in the Instruction module
5.2 Application Examples
The exemplary encoding enables the generation of
a number of various types of user-adapted guideline
representations and document components:
? For all user profiles: The ?tags? and ?keywords?
attributes of the instruction elements in fig. 4 al-
low us to automatically generate indices as lists of
tag:page-number pairs (resp. keyword:page-number
pairs) and tagset declarations as tag:keyword pairs.
? For the annotator: The ?difficulty? attribute can be
used as a guiding principle for the creation of tu-
torial exercises for the annotator, which might start
with easy annotation examples and develop towards
more difficult instructions. Furthermore, when the
annotator annotates a certain tag, the annotation tool
may display the corresponding ?text? element as an
?online help? for the annotator.
? For the guideline author: When the author as-
signs keywords to the instruction s/he is currently
working on, the ?keywords? attribute can be used
to point to related instructions (marked by the same
keywords). The formal specification in general can
be used to support the guideline authors, by com-
pleteness and consistency checks.
6 Conclusions
Current guidelines only provide support for a subset
of the potential users. As we have shown in this pa-
per, different user types, such as annotators, corpus
explorers, language engineers, etc., require different
forms of guidelines in order to fulfill their specific
tasks related to an annotated corpus.
To answer these requirements, we propose a gen-
eral guideline structure which serves as the basis for
generation of user-adapted documents. With the use
of XML/XSLT technology, a broad variety of user-
specific applications can be realized.
It is clear that the detailed specification we pro-
pose make high demands on the guideline authors.
However, forcing the authors to fulfill requirements
such as explicitness (as for the declaration of the
exact annotation action), completeness (keywords,
examples for every instruction), etc., will result
in high-quality standardized annotation guidelines,
which we believe will pay off in greater benefit from
the annotated corpora.
References
James Allen and Mark Core. 1997. DAMSL: Di-
alog Act Markup in Several Layers. Draft;
http://www.cs.rochester.edu/
research/cisd/resources/damsl/
RevisedManual/RevisedManual.html.
Balthasar Bickel, Bernard Comrie, and Martin Haspel-
math. 2004. The Leipzig Glossing Rules. Conven-
tions for interlinear morpheme by morpheme glosses.
Max Planck Institute for Evolutionary Anthropol-
ogy and Department of Linguistics, University of
Leipzig; http://www.eva.mpg.de/lingua/
files/morpheme.html.
Ann Bies, Mark Ferguson, Karen Katz, and Robert
MacIntyre. 1995. Bracketing Guidelines for Tree-
bank II Style, Penn Treebank Project. Department
of Computer and Information Science, University
of Pennsylvania; ftp://ftp.cis.upenn.edu/
pub/treebank/doc/manual/.
Jean Carletta and Amy Isard. 1999. The MATE annota-
tion workbench: User requirements. In Proceedings
of the ACL Workshop Towards Standards and Tools
for Discourse Tagging, University of Maryland.
John Carroll, Ted Briscoe, Nicoletta Calzolari, Stefano
Federici, Simonetta Montemagni, Vito Pirrelli, Greg
Grefenstette, Antonio Sanfilippo, Glenn Carroll, and
Mats Rooth. 1997. SPARKLE Work Package 1: Spec-
ification of Phrasal Parsing. Final Report, 1997-TR-
1; http://dienst.iei.pi.cnr.it/.
Laila Dybkjaer, Niels Ole Bernsen, Hans Dybkjaer,
David McKelvie, and Andreas Mengel. 1998. The
MATE Markup Framework. MATE Deliverable D1.2,
http://mate.nis.sdu.dk/information/
d12/.
Ekkehard Ko?nig, Dik Bakker, ?Oesten Dahl, Mar-
tin Haspelmath, Maria Koptjevskaja-Tamm, Chris-
tian Lehmann, and Anna Siewierska. 1993. EU-
ROTYP Guidelines. European Science Foundation
Programme in Language Typology. http://
www-uilots.let.uu.nl/ltrc/eurotyp/.
Geoffrey Leech and Andrew Wilson. 1996. EAGLES
recommendations for the morphosyntactic annotation
of corpora. Technical Report EAG-TCWG-MAC/R,
ILC-CNR, Pisa; http://www.ilc.cnr.it/
EAGLES96/annotate/annotate.html.
Geoffrey Leech. 1993. Corpus annotation schemes. Lit-
erary and Linguistic Computing, 8(4):275?281.
Eleni Mitsakaki, Rashmi Prasad, Aravind Joshi,
and Bonnie Weber. 2004. Penn Discourse Tree-
bank: Annotation Tutorial. Institute for Research
in Cognitive Science, University of Pennsylva-
nia; http://www.cis.upenn.edu/?pdtb/
dltag-webpage-stuff/pdtb-tutorial.
pdf.
PropBank Project. 2002. PropBank Annotation Guide-
lines. Version 3; http://www.cis.upenn.
edu/?ace/propbank-guidelines-feb02.
pdf.
Geoffrey Sampson. 1995. English for the computer:
The SUSANNE corpus and analytic scheme. Oxford:
Clarendon Press.
Beatrice Santorini. 1995. Part-of-Speech Tagging
Guidelines for the Penn Treebank Project. 3rd
Revision, 2nd printing; ftp://ftp.cis.upenn.
edu/pub/treebank/doc/tagguide.ps.gz;
Department of Computer and Information Science,
University of Pennsylvania.
Anne Schiller, Simone Teufel, Christine Sto?ckert, and
Christine Thielen. 1999. Guidelines fu?r das Tagging
deutscher Korpora mit STTS. http://www.ims.
uni-stuttgart.de/projekte/corplex/
TagSets/stts-1999.pdf.
Rosmary Stegmann, Heike Telljohann, and Erhard
Hinrichs. 2000. Stylebook for the German Treebank
in VERBMOBIL. Technical Report 239, Verbmobil;
http://verbmobil.dfki.de/cgi-bin/
verbmobil/htbin/decode.cgi/share/
VM-depot/FTP-SERVER/vm-reports/
report-239-00.ps.
ANNIS: Complex Multilevel Annotations in a Linguistic Database
Michael Go?tze and Stefanie Dipper
Department of Linguistics, University of Potsdam
14415 Potsdam, Germany
{goetze,dipper}@ling.uni-potsdam.de
Abstract
We present ANNIS, a linguistic database
that aims at facilitating the process of ex-
ploiting richly annotated language data by
naive users. We describe the role of the
database in our research project and the
project requirements, with a special focus
on aspects of multilevel annotation. We
then illustrate the usability of the database
by illustrative examples. We also address
current challenges and next steps.
1 Introduction
Until recently, working with data that is anno-
tated at multiple levels with different types of an-
notation required rather advanced computer skills,
which cannot be expected from the majority of po-
tentially interested users.
We present ANNIS, a linguistic database that
aims at providing the infrastructure for supporting
linguists in their work on multilevel annotations.
We describe and illustrate the current state of our
work and sketch the next steps.
In sec. 2, we present the research scenario AN-
NIS is developed for, show the role of the linguis-
tic database therein, and sketch the major require-
ments it aims to fulfill. We then describe the archi-
tecture and current functionality, and discuss the
way difficult aspects of multidimensional annota-
tions are treated (sec. 3). In sec. 4, we illustrate
the work with the database by three exemplary ap-
proaches. Finally, we sketch our next steps.
2 Background
Research Scenario
The database ANNIS is being developed in the
Collaborative Research Center SFB 632 on Infor-
mation Structure, which consists of 13 individual
research projects from disciplines such as theoret-
ical linguistics, psycholinguistics, first and second
language acquisition, typology and historical lin-
guistics.1 In the research center, data of various
languages is collected and annotated at the levels
of phonology, morphology, syntax, semantics, and
pragmatics?levels that contribute in ways yet to
be determined to the information structural parti-
tioning of discourse and utterances.
For annotation, task-specific tools are being
used, e.g. EXMARaLDA, annotate, RSTTool, and
MMAX.2 Data is then converted into a standoff
data interchange format, which is fed into the lin-
guistic database ANNIS. ANNIS aims at providing
functionalities for exploring and querying the data,
offering suitable means for both visualization and
export.
User Requirements
Central requirements evolving out of the scenario
sketched above and, as we believe, for multilevel
annotation in general are Data heterogeneity, Data
reuse, and Accessibility (cf. (Dipper and Go?tze,
2005)).
Data heterogeneity is a result of: (i) the lan-
guage data to be annotated, varying with respect
to size (single sentences vs. narrations), modal-
ity (monologue vs. dialogue, text vs. speech) and
language; (ii) the annotations, which use different
1http://www.sfb632.uni-potsdam.de/.
For more information about ANNIS, see http://www.
sfb632.uni-potsdam.de/annis/ and (Dipper et al,
2004).
2http://www.rrz.uni-hamburg.de/
exmaralda/
http://www.coli.uni-saarland.de/
projects/sfb378/negra-corpus/
http://www.wagsoft.com/RSTTool
http://mmax.eml-research.de/
61
data structures (attribute-value pairs, trees, point-
ers, etc.); and (iii) data formats that stem from dif-
ferent task-specific annotation tools.
Data reuse must be supported, e.g. for further
or re-annotation, statistical analyses, or reuse of
the data in other tools.
Accessibility of both tools and data is an obvi-
ous prerequisite for data reuse.
In the following section, we will address those
aspects that are particularly relevant for these re-
quirements and discuss their treatment in ANNIS.
3 ANNIS
3.1 Main Features
ANNIS is a Java servlet application that can be ac-
cessed via standard web browsers. In its current
state, it is not database-backed; data is read into
memory and exploited for querying and visualiza-
tion in memory.3
Data format and interoperability The data
model must be suffiently expressive for captur-
ing the data heterogeneity sketched above, includ-
ing the representation of overlapping segments, in-
tersecting hierarchies, and alternative annotations
(e.g., for ambiguous annotations). It should fur-
ther facilitate the addition of new annotations.
In our approach, we use a flexible standoff
XML format, the SFB-standard interchange for-
mat, as the interface format (Dipper, 2005). In this
format, primary data is stored in a file that option-
ally specifies a header, followed by a tag <body>,
which contains the source text. The format makes
use of generic XML elements to encode data struc-
tures and annotations: <mark> (markable) tags
specify text positions or spans of text (or spans of
other markables) that can be annotated by linguis-
tic information. Trees and graphs are encoded by
<struct> (structure) and <rel> (relation) el-
ements, which specify local subtrees. <feat>
(feature) tags specify the information that is an-
notated to markables or structures, which are re-
ferred to by xlink attributes. Each type of anno-
tation is stored in a separate file, hence, competing
or ambiguous annotations can be represented in
a straightforward way: by distributing them over
different files.
Our format allows us to represent different
kinds of annotations in a uniform way. We pro-
3For a more elaborate discussion of the basic concepts of
ANNIS, see (Dipper et al, 2004).
vide importers for the export format of the an-
notation tools annotate, EXMARaLDA, RST Tool,
and MMAX. Our PCC corpus (see sec. 4) im-
ports and synchronizes the following annotations,
which have been annotated by these tools: syn-
tax, information structure, rhetorical structure, and
coreference.
Visualization Suitable means for visualizing in-
formation is crucial for exploring and interpreting
linguistic data. Due to the high degree of data
heterogeneity, special attention has been paid to
the support of visualizing various data structures.
In addition, annotations may refer to segments of
different sizes, e.g. syntax vs. discourse structure.
Furthermore, richness of information in multilevel
annotations has to be taken into account; this re-
quires a certain degree of user-adaptivity, allowing
the user to modify the way information of interest
is displayed.
In ANNIS, we start from a basic interactive tier-
based view, which allows for a compact simulta-
neous representation of many annotation types and
whose appearance can be modified by the user in a
format file. In addition, a discourse view helps the
user to orient him/herself in the discourse. Further
views can be added.
Query support Among the numerous require-
ments for a good query facility for multilevel
annotation, expressiveness, efficiency, and user-
friendly query-formulation appear to be the most
relevant. Even a very brief discussion of these is-
sues would go beyond the limits of this paper, the
reader is instead referred to (Heid et al, 2004).
Currently, ANNIS uses a query language proto-
type which allows the user to query text and anno-
tations, by means of regular expressions and wild-
cards, and various common relational operators
(e.g. for stating relations in tree structures, such as
dominance or sibling relations). However, the set
for querying sequential relations is not sufficiently
expressive, and querying co-reference relations is
not supported yet. Furthermore, user support for
formulating queries is rather poor.
3.2 Open Issues
Data alignment Alignment of annotations cre-
ated by different annotation tools appears to be
most suitable at the level of tokens. However, tools
often come with their own tokenizers and mis-
matches do occur frequently. We currently use a
62
Figure 1: The ANNIS user interface, displaying data from the PCC
simple script that checks for text and token iden-
tity in the standoff files that we generate from the
output of the individual tools. However, all mis-
matches have to be corrected manually. At least
for white-space differences, an automatic fixing
procedure should be feasible (similar to the one
implemented by (Witt et al, 2005)).
Efficient Querying Current querying is re-
stricted to rather small amounts of data, and com-
plex queries may take some time until finishing the
search.
Overlapping elements and intersecting hierar-
chies The query language does not yet support
comfortable searching for overlapping elements.
However, exactly what kinds of queries on over-
lapping segments or intersecting relations should
be supported is an open question.
4 Use Cases
We illustrate the use of ANNIS in linguistic re-
search, exemplified with research questions from
three different linguistic areas.
Historical investigations The project B4: The
role of information structure in the development of
word order regularities in Germanic investigates
the verb-second phenomenon, which occurred in
certain Germanic languages only (e.g., it did in
Modern German, but not in Modern English). One
of their findings is that verb placement in the Old
High German translation of Tatian correlates with
discourse relations: verb-initial sentences usually
occur in narrative contexts and signal continuation
of the story. In contrast, verb-second sentences
indicate subordinative relations (Hinterho?lzl and
Petrova, 2005).
Typological studies In the research project D2:
Typology of Information Structure (cf., e.g.,
(Go?tze et al, To appear)), a typological question-
naire is designed, with which language data can be
elicited using largely language-independent meth-
ods. Currently, data from 13 different languages is
elicited and annotated with information from var-
ious linguistic levels (morphosyntax, phonology,
semantics, and information structure).
An interesting query might look for nominal
phrases (const=np) that are new in the discourse
(given=new) and belong to the (information-) fo-
cus of a sentence (focus=ans), e.g. for inves-
tigating the phonological realization of these.
63
The according query has the form: const=np &
given=new & focus=ans & #1 = #2.4
Queries in ANNIS can be restricted to subsets
of a corpus, by queries such as focus=ans &
doc=*81-11*, which searches for all answer foci
in the data that has been elicited by means of the
task 81-11 in the questionnaire, yielding matching
data from all languages in our database.
Discourse studies The Potsdam Commentary
Corpus, PCC (Stede, 2004), consists of 173 news-
paper commentaries, annotated for morphosyn-
tax, coreference, discourse structure according
to Rhetorical Structure Theory, and information
structure.
A question of interest here is the information-
structural pattern of sentences introducing dis-
course segments that elaborate on another part
of the discourse: elaboration & rel=satellite &
(cat=vroot & aboutness-topic) & #1 > #2 &
#2 = #3. Another research issue is the relation-
ship of coreference and discourse structure. How-
ever, querying for coreference relations is not sup-
ported yet.
5 Future Work
Currently we are working on integrating a native
XML database into our system. To make process-
ing more efficient, we are developing an internal
inline representation of the standoff interchange
format, encoding overlapping segments by means
of milestones or fragments (Barnard et al, 1995).
Furthermore, the query language will be ex-
tended to cover different kinds of queries on se-
quential relations as well as coreference relations.
Finally, we will add basic statistical means to
the query facility, which, e.g., can point to rare
and, hence, potentially interesting feature combi-
nations.
6 Demo
In our demonstration of ANNIS, we will show ex-
ample data from the PCC, Old High German, and
data elicited by the typological questionnaire. We
then illustrate by means of example queries how
the researchers make use of our database in their
daily work, as described above. This includes pre-
senting the visualization and querying facilities of
ANNIS.
4The expression #n refers to the nth constraint stated in
the query; the binary operator = requires extensional iden-
tity (Dipper et al, 2004).
References
David Barnard, Lou Burnard, Jean-Pierre Gaspart,
Lynne A. Price, C. M. Sperberg-McQueen, and Gio-
vanni Batista Varile. 1995. Hierarchical encod-
ing of text: Technical problems and SGML solu-
tions. Text Encoding Initiative: Background and
Context. Special Issue of Computers and the Hu-
manities, 29(211?231).
Stefanie Dipper and Michael Go?tze. 2005. Access-
ing heterogeneous linguistic data ? generic XML-
based representation and flexible visualization. In
Proceedings of the 2nd Language & Technology
Conference 2005.
Stefanie Dipper, Michael Go?tze, Manfred Stede, and
Tillmann Wegst. 2004. ANNIS: A linguistic
database for exploring information structure. In
Shinichiro Ishihara, Michaela Schmitz, and Anne
Schwarz, editors, Interdisciplinary Studies on Infor-
mation Structure (ISIS), volume 1, pages 245?279.
Universita?tsverlag Potsdam, Potsdam, Germany.
Stefanie Dipper. 2005. XML-based stand-off repre-
sentation and exploitation of multi-level linguistic
annotation. In Proceedings of Berliner XML Tage
2005 (BXML 2005), pages 39?50, Berlin, Germany.
Michael Go?tze, Torsten Roloff, Stavros Skopeteas,
and Ruben Stoel. To appear. Exploring a cross-
linguistic production data corpus. In Proceedings of
the Sixth International Tbilisi Symposium on Lan-
guage, Logic and Computation. Batumi, Georgia.
Ulrich Heid, Holger Voormann, Jan-Torsten Milde, Ul-
rike Gut, Katrin Erk, and Sebastian Pado?. 2004.
Querying both time-aligned and hierarchical corpora
with NXT Search. In Proceedings of the Forth In-
ternational Conference on Language Resources and
Evaluation (LREC 2004), pages 1455?1458, Lisbon.
Roland Hinterho?lzl and Svetlana Petrova. 2005.
Rhetorical relations and verb placement in early ger-
manic languages. Evidence from the Old High Ger-
man Tatian translation (9th century). In M. Stede,
C. Chiarcos, M. Grabski, and L. Lagerwerf, edi-
tors, Salience in Discourse. Multidisciplinary Ap-
proaches to Discourse, pages 71?79.
Manfred Stede. 2004. The Potsdam Commentary Cor-
pus. In Proceedings of the ACL Workshop on Dis-
course Annotation, pages 96?102, Barcelona.
Andreas Witt, Daniela Goecke, Felix Sasaki, and Har-
ald Lu?ngen. 2005. Unification of XML documents
with concurrent markup. Literary and Linguistic
Computing, 20(1):103?116.
64
Proceedings of the Linguistic Annotation Workshop, pages 148?155,
Prague, June 2007. c?2007 Association for Computational Linguistics
Standoff Coordination for Multi-Tool Annotation in a Dialogue Corpus
Kepa Joseba Rodr??guez?, Stefanie Dipper?, Michael Go?tze?, Massimo Poesio?,
Giuseppe Riccardi?, Christian Raymond?, Joanna Wisniewska?
?Piedmont Consortium for Information Systems (CSI-Piemonte)
KepaJoseba.Rodriguez@csi.it
?Department of Linguistics. University of Potsdam.
{dipper|goetze}@ling.uni-potsdam.de
?Center for Mind/Brain Sciences. University of Trento.
massimo.poesio@unitn.it
?Department of Information and Communication Technology. University of Trento.
{christian.raymond|riccardi}@dit.unitn.it
?Institute of Computer Science. Polish Academy of Science.
jwisniewska@poczta.uw.edu.pl
Abstract
The LUNA corpus is a multi-lingual, multi-
domain spoken dialogue corpus currently
under development that will be used to de-
velop a robust natural spoken language un-
derstanding toolkit for multilingual dialogue
services. The LUNA corpus will be an-
notated at multiple levels to include an-
notations of syntactic, semantic, and dis-
course information; specialized annotation
tools will be used for the annotation at each
of these levels. In order to synchronize these
multiple layers of annotation, the PAULA
standoff exchange format will be used. In
this paper, we present the corpus and its
PAULA-based architecture.1
1 Introduction
XML standoff markup (Thompson and McKelvie,
1997; Dybkj?r et al, 1998) is emerging as the clean-
est way to organize multi-level annotations of cor-
pora. In many of the current annotation efforts based
on standoff a single multi-purpose tool such as the
NITE XML Toolkit (Carletta et al, 2003) or Word-
Freak (Morton and LaCivita, 2003) is used to anno-
1The members of the LUNA project consortium are: Pied-
mont Consortium for Information Systems (IT), University of
Trento (IT), Loquendo SpA (IT), RWTH-Aachen (DE), Uni-
versity of Avignon (FR), France Telecom R&D Division S.A.
(FR), Polish-Japanese Institute of Information Technology (PL)
and the Institute for Computer Science of the Polish Academy
of Sciences (PL), http://www.ist-luna.eu.
This research was performed in the LUNA project funded by the
EC, DG Infso, Unit E1 and in the Collaborative Research Cen-
ter 632 ?Information Structure?, funded by the German Science
Foundation, http://www.sfb632.uni-potsdam.de.
tate as well as maintain all annotation levels (cf. the
SAMMIE annotation effort (Kruijff-Korbayova? et al,
2006b)).
However, it is often the case that specialized tools
are developed to facilitate the annotation of particu-
lar levels: examples include tools for segmentation
and transcription of the speech signal like PRAAT
(Boersma and Weenink, 2005) and TRANSCRIBER
(Barras et al, 1998), the SALSA tools for FrameNet-
style annotation (Burchardt et al, 2006), and MMAX
(Mu?ller and Strube, 2003) for coreference annota-
tion. Even in these cases, however, it may still be
useful, or even necessary, to be able to visualize
more than one level at once, or to ?knit? together2
multiple levels to create a file that can be used to
train a model for a particular type of annotation.
The Linguistic Annotation Framework by (Ide et al,
2003) was proposed as a unifying markup format to
be used to synchronize heterogeneous markup for-
mats for such purposes.
In this paper, we discuss how the PAULA represen-
tation format, a standoff format inspired by the Lin-
guistic Annotation Framework, is being used to syn-
chronize multiple levels of annotation in the LUNA
corpus, a corpus of spoken dialogues in multiple lan-
guages and multiple domains that is being created to
support the development of robust spoken language
understanding models for multilingual dialogue ser-
vices. The corpus is richly annotated with linguistic
information that is considered relevant for research
on dialogue, including chunks, named entities, argu-
ment structure, coreference, and dialogue acts. We
chose to adopt specialized tools for each level: e.g.,
2In the sense of the knit tool of the LT-XML suite.
148
transcription using TRANSCRIBER, coreference us-
ing MMAX, attributes using SEMANTIZER, etc. To
synchronize the annotation and allow cross-layer op-
erations, the annotations are mapped to a common
representation format, PAULA.
The structure of the paper is as follows. In Sec-
tion 2, we present the LUNA project and the LUNA
corpus with its main annotation levels. In Section 3,
we introduce the PAULA exchange format, focusing
on the representation of time alignment and dialogue
phenomena. Finally we show how PAULA is used in
the LUNA corpus and discuss alternative formats.
2 The LUNA project
The aim of the LUNA project is to advance the state
of the art in understanding conversational speech
in Spoken Dialogue Systems (Gupta et al, 2005),
(Bimbot et al, 2006).
Three aspects of Spoken Language Understand-
ing (SLU) are of particular concern in LUNA: gen-
eration of semantic concept tags, semantic compo-
sition into conceptual structures and context sensi-
tive validation using information provided by the di-
alogue manager. In order to train and evaluate SLU
models, we will create an annotated corpus of spo-
ken dialogues in multiple domains and multiple lan-
guages: French, Italian, and Polish.
2.1 The LUNA corpus
The LUNA corpus is currently being collected, with
a target to collect 8100 human-machine dialogues
and 1000 human-human dialogues in Polish, Italian
and French. The dialogues are collected in the fol-
lowing application domains: stock exchange, hotel
reservation and tourism inquiries, customer support
service/help-desk and public transportation.
2.2 Multilevel annotation
Semantic interpretation involves a number of sub-
tasks, ranging from identifying the meaning of indi-
vidual words to understanding which objects are be-
ing referred to up to recovering the relation between
different semantic objects in the utterance and dis-
course level to, finally, understanding the commu-
nicative force of an utterance.
In some annotation efforts?e.g., in the annotation
of the French MEDIA Corpus (Bonneau-Maynard
and Rosset, 2003)? information about the meaning
of semantic chunks, contextual information about
coreference, and information about dialogue acts are
all kept in a single file. This approach however suf-
fers from a number of problems, including the fact
that errors introduced during the annotation at one
level may make other levels of annotation unusable
as well, and that it is not possible for two anno-
tators to work on different types of annotation for
the same file at the same time. Most current an-
notation efforts, therefore, tend to adopt the ?multi-
level? approach pioneered during the development
of the MAPTASK corpus and then developed as part
of work on the EU-funded MATE project (McKelvie
et al, 2001), in which each aspect of interpreta-
tion is annotated in a separate level, independently
maintained. This approach is being followed, for
instance, in the ONTONOTES project (Hovy et al,
2006) and the SAMMIE project (Kruijff-Korbayova
et al, 2006a).
For the annotation of the LUNA corpus, we de-
cided to follow the multilevel approach as well. That
allows us to achieve more granularity in the anno-
tation of each of the levels and to investigate more
easily dependencies between features that belong to
different levels. Furthermore, we can use different
specialized off-the-shelf annotation tools, splitting
up the annotation task and thus facilitating consis-
tent annotation.
2.3 Annotation levels
The LUNA corpus will contain different types of in-
formation. The first levels are necessary to prepare
the corpus for subsequent semantic annotation, and
include segmentation of the corpus in dialogue turns,
transcription of the speech signal, and syntactic pre-
processing with POS-tagging and shallow parsing.
The next level consists of the annotation of do-
main information using attribute-value pairs. This
annotation will be performed on all dialogues in the
corpus.
The other levels of the annotation scheme are not
mandatory, but at least a part of the dialogues will
be annotated in order to investigate contextual as-
pects of the semantic interpretation. These levels in-
clude the predicate structure, the relations between
referring expressions, and the annotation of dialogue
acts.
149
2.3.1 Segmentation and transcription of the
speech signal
Before transcription and annotation can begin, it
is necessary to segment the speech signal into dia-
logue turns and annotate them with speaker identity
and mark where speaker overlap occurs. The goal
of this segmentation is to be able to perform a tran-
scription and annotation of the dialogue turns with
or without dialogue context. While dialogue context
is preferable for semantic annotation, it slows down
the annotation process.
The tool we will use for the segmentation and
transcription of the speech signal is the open source
tool TRANSCRIBER3 (Barras et al, 1998).
The next step is the transcription of the speech
signal, using conventions for the orthographic tran-
scription and for the annotation of non-linguistic
acoustic events.
2.3.2 Part Of Speech Tagging and Chunking
The transcribed material will be annotated with
POS-tags, morphosyntactic information like agree-
ment features, and segmented based on syntactic
constituency.
For the POS-tags and morphosyntactic features,
we will follow the recommendations made in EA-
GLES (EAGLES, 1996), which allows us to have a
unified representation format for the corpus, inde-
pendently of the tools used for each language.
2.3.3 Domain Attribute Annotation
At this level, semantic segments will be anno-
tated following an approach used for the annotation
for the French MEDIA dialogue corpus (Bonneau-
Maynard and Rosset, 2003).
We specify the domain knowledge in domain on-
tologies. These are used to build domain-specific
dictionaries. Each dictionary contains:
? Concepts corresponding to classes of the ontol-
ogy and attributes of the annotation.
? Values corresponding to the individuals of the
domain.
? Constraints on the admissible values for each
concept.
3http://trans.sourceforge.net
The concept dictionaries are used to annotate se-
mantic segments with attribute-value pairs. The se-
mantic segments are produced by concatenation of
the chunks produced by the shallow parser. A se-
mantic segment is a unit that corresponds unambigu-
ously to a concept of the dictionary.
(1) buongiorno lei [puo` iscriversi]concept1 [agli
esami]concept2 [oppure]concept3 [ottenere
delle informazioni]concept4 come la posso
aiutare4
<concept1 action:inscription>
<concept2 objectDB:examen>
<concept3 conjunctor:alternative>
<concept4 action:obtain info>
2.3.4 Predicate structure
The annotation of predicate structure facilitates
the interpretation of the relation between entities and
events occurring in the dialogue.
There are different approaches to annotate predi-
cate structure. Some of them are based upon syntac-
tic structure, with PropBank (Kingsbury and Palmer,
2003) being one of the most relevant, building the
annotation upon the syntactic representation of the
TreeBank corpus (Marcus et al, 1993). An alter-
native to syntax-driven approaches is the annotation
using semantic roles as in FrameNet (Baker et al,
1998).
For the annotation of predicate structure in the
LUNA corpus, we decided to use a FrameNet-like
approach, rather than a syntax-based approach:
1. Annotation of dialogue interaction has to deal
with disfluencies, non-complete sentences, un-
grammaticality, etc., which complicates the use
of deep syntactic representations.
2. If we start from a syntactic representation, we
have to follow a long way to achieve the seman-
tic interpretation. Syntactic constituents must
be mapped to ?-roles, and then to semantic
roles. FrameNet offers the possibility of anno-
tating using directly semantic criteria.
4Good morning, you can register for the exam or obtain in-
formation. How can I help you?
150
For each domain, we define a set of frames. These
frames are defined based on the domain ontology,
with the named entities providing the frame ele-
ments. For all the frames we introduce the negation
as a default frame element.
For the annotation, first of all we annotate the en-
tities with a frame and a frame element.
Then if the target is overtly realized we make a
pointer from the frame elements to the target. The
next step is putting the frame elements and the target
(if overtly realized) in a set.
(2) buongiorno [lei]fe1 [puo` iscriversi]fe2
[agli esami]fe3 oppure [ottenere delle
informazioni]fe4 come la posso aiutare
set1 = {id1, id2, id3}
frame: inscription
frame-elements:{student, examen, date}
set2 = {id4}
frame = info-request
frame-elements:{student, addressee, topic}
<fe1 frame="inscription"
FE="student" member="set1"
pointer="fe2">
<fe2 frame="inscription"
FE="target" member="set1">
<fe3 frame="inscription"
FE="examen" member="set1"
pointer="fe2">
<fe4 frame="information"
FE="target" member="set2">
2.3.5 Coreference / Anaphoric relations
To annotate anaphoric relations we will use an an-
notation scheme close to the one used in the ARRAU
project (Artstein and Poesio, 2006). This scheme
has been extensively tested with dialogue corpora
and includes instructions for annotating a variety of
anaphoric relations, including bridging relations. A
further reason is the robustness of the scheme that
doesn?t require one single interpretation in the an-
notation.
The first step is the annotation of the information
status of the markables with the tags given and
new. If the markables are annotated with given,
the annotator will select the most recent occurrence
of the object and add a pointer to it. If the mark-
able is annotated with new, we distinguish between
markables that are related to a previously mentioned
object (associative reference) or don?t have such a
relation.
If there are alternative interpretations, which of a
list of candidates can be the antecedent, the annota-
tor can annotate the markable as ambiguous and
add a pointer to each of the possible antecedents.
(3) Wizard: buongiorno [lei]cr1 [puo`
iscriversi]cr2 [agli esami]cr3 oppure ot-
tenere [delle informazioni]cr4 come la posso
aiutare
<cr1 inf status="new" related="no">
<cr2 inf status="new" related="no">
<cr3 inf status="new" related="no">
<cr4 inf status="new" related="no">
Caller: [iscrizione]cr5 [esami]cr65
<cr5 inf status="given"
single phrase antecedent="cr2"
ambiguity="unambiguous">
<cr6 inf status="given"
single phrase antecedent="cr3"
ambiguity="unambiguous">
2.3.6 Dialogue acts
In order to associate the intentions of the speaker
with the propositional content of the utterances, the
segmentation of the dialogue turns in utterances is
based on the annotation of predicate structure. Each
set of frame elements will correspond to an utter-
ance.
Each utterance will be annotated using a multi-
dimensional annotation scheme partially based on
the DAMSL scheme (Allen and Core, 1997) and on
the proposals of ICSI-MRDA (Dhillon et al, 2004).
We have selected nine dialogue acts from the
DAMSL scheme as initial tagset, that can be extended
for the different application domains. Each utter-
ance will be annotated with as many tags as applica-
ble.
(4) Wizard: [buongiorno]utt1 [lei puo` iscriversi
agli esami]utt2 oppure [ottenere delle
5Register for the exam.
151
informzaioni]utt3 [come la posso aiutare]utt4
<utt1 d-act="opening/closing">
<utt2 d-act="statement"
link-frame="set1">
<utt3 d-act="statement"
link-frame="set2">
<utt4 d-act="info-request">
Caller: [iscrizione esami]utt5
<utt5 d-act="answer;statement"
link-frame="set3">
3 PAULA - a Linguistic Standoff Exchange
Format
PAULA stands for Potsdamer Austauschformat fu?r
linguistische Annotation (?Potsdam Interchange
Format for Linguistic Annotation?) and has been de-
veloped for the representation of data annotated at
multiple layers. The application scenario is sketched
in Fig 1: researchers use multiple, specialized off-
the-shelf annotation tools, such as EXMARALDA or
MMAX, to enrich data with linguistic information.
The tools store the data in tool-specific formats and,
hence, it is not straightforward to combine informa-
tion from different sources and, e.g., to search for
correlations across multiple annotation layers.
This is where PAULA comes in: PAULA maps
the tool-specific formats to a common format and
serves as an interchange format between these
tools.6 Moreover, the annotations from the different
sources are merged into one single representation.
PAULA makes this data available for further appli-
cations, such as searching the data by means of the
tool ANNIS7, or to feed statistical applications like
WEKA8.
PAULA is an XML-based standoff format for lin-
guistic annotations, inspired by the ?dump format?
6Currently, we provide PAULA import filters for the follow-
ing tools and formats: Exmaralda, MMAX, RST Tool/URML,
annotate/TIGER XML. Export from PAULA to the tool formats
is at present supported for the original source format only. We
plan to support the export of selected annotations to other tools.
This is, however, not a trivial task since it may involve loss of
information.
7ANNIS: http://www.sfb632.uni-potsdam.de/
annis
8WEKA: http://www.cs.waikato.ac.nz/ml/
weka
Figure 1: PAULA annotation scenario
of the Linguistic Annotation Framework (Ide et al,
2003).9 With PAULA, not only is the primary data
separated from its annotations, but individual anno-
tation layers (such as parts of speech and dialogue
acts) are separated from each other as well. The
standoff approach allows us to mark overlapping
segments in a straightforward way: by distributing
annotations over different files (XML as such does
not easily account for overlapping segments, since
its object model is a hierarchical, tree-like structure).
Moreover, new annotation layers can be added eas-
ily.
PAULA assumes that a representation of the pri-
mary data is stored in a file that optionally spec-
ifies a header with meta information, followed by
a tag <body>, which contains a representation of
the primary data. In Fig. 2, the first box displays
the transcription, with all contributions from the first
speaker coming first, and the contributions from the
other speaker(s) following (put in italics in the Fig-
ure).
The basic type of ?annotation? are markables, en-
coded by the XML element <mark>. Markables
specify ?anchors?, i.e., locations or ranges that can
be annotated by linguistic information. The loca-
tions and ranges are positions or spans in the source
text or timeline, which are referenced by means of
XLinks and XPointer expressions. For instance, the
?Token? markables in Fig. 2 define spans that cor-
9The term ?standoff? describes the situation where primary
data (e.g., the transcription) and annotations of this data are
stored in separate files (Thompson and McKelvie, 1997).
152
 

	
	

