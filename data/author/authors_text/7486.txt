Using Long Runs as Predictors of Semantic Coherence in a 
Partial Document Retrieval System 
Hyopil Shin 
Computing Research Laboratory, NMSU 
PO Box 30001 
Las Cruces, NM, 88003 
hshin@crl.nmsu.edu 
Jerrold F. Stach 
Computer Science Telecommunications, UMKC 
5100 Rockhill Road 
Kansas City, MO, 64110 
stach @cstp.umkc.edu 
Abstract 
We propose a method for dealing with 
semantic complexities occurring in 
information retrieval systems on the basis of 
linguistic observations. Our method follows 
from an analysis indicating that long runs of 
content words appear in a stopped ocument 
cluster, and our observation that these long 
runs predominately originate from the 
prepositional phrase and subject 
complement positions and as such, may be 
useful predictors of semantic coherence. 
From this linguistic basis, we test three 
statistical hypotheses over a small collection 
of documents from different genre. By 
coordinating thesaurus emantic ategories 
(SEMCATs) of the long run words to the 
semantic categories of paragraphs, we 
conclude that for paragraphs containing both 
long runs and short runs, the SEMCAT 
weight of long runs of content words is a 
strong predictor of the semantic oherence 
of the paragraph. 
Introduction 
One of the fundamental deficiencies of current 
information retrieval methods is that the words 
searchers use to construct terms often are not the 
same as those by which the searched information 
has been indexed. There are two components o
this problem, synonymy and polysemy 
(Deerwester et. al., 1990). By definition of 
polysemy, a document containing the search 
terms or indexed with the search terms is not 
necessarily relevant. Polysemy contributes 
heavily to poor precision. Attempts to deal with 
the synonymy problem have relied on 
intellectual or automatic term expansion, or the 
construction of a thesaurus. 
Also the ambiguity of natural language causes 
semantic complexities that result in poor 
precision. Since queries are mostly formulated 
as words or phrases in a language, and the 
expressions of a language are ambiguous in 
many cases, the system must have ways to 
disambiguate the query. 
In order to resolve semantic omplexities in 
information retrieval systems, we designed a 
method to incorporate semantic information into 
current IR systems. Our method (1) adopts 
widely used Semantic Information or 
Categories, (2) calculates Semantic Weight 
based on probability, and (3) (for the purpose of 
verifying the method) performs partial text 
retrieval based upon Semantic Weight or 
Coherence to overcome cognitive overload of 
the human agent. We make two basic 
assumptions: 1. Matching search terms to 
semantic categories hould improve retrieval 
precision. 2. Long runs of content words have a 
linguistic basis for Semantic Weight and can 
also be verified statistically. 
1 A Brief Overview of Previous Approaches 
There have been several attempts to deal with 
complexity using semantic information. These 
methods are hampered by the lack of 
dictionaries containing proper semantic 
categories for classifying text. Semantic 
methods designed by Boyd et. al. (1994) and 
Wendlandt et. al. (1991) demonstrate only 
simple examples and are restricted to small 
numbers of words. In order to overcome this 
6 
deficiency, we propose to incorporate the 
structural information of the thesaurus, emantic 
categories (SEMCATs). However, we must also 
incorporate semantic ategories into current IR 
systems in a compatible manner. The problem 
we deal with is partial text retrieval when all the 
terms of the traditional vector equations are not 
known. This is the case when retrieval is 
associated with a near real time filter, or when 
the size or number of documents in a corpus is 
unknown. In such cases we can retrieve only 
partial text, a paragraph or page. But since there 
is no document wide or corpus wide statistics, it
is difficult to judge whether or not the text 
fragment is relevant. The method we employ in 
this paper identifies semantic "hot spots" in 
partial text. These "hot spots" are loci of 
semantic oherence in a paragraph of text. Such 
paragraphs are likely to convey the central ideas 
of the document. 
We also deal with the computational spects 
of partial text retrieval. We use a simple 
stop/stem ethod to expose long runs of context 
words that are evaluated relative to the search 
terms. Our goal is not to retrieve a highly 
relevant sentence, but rather to retrieve aportion 
of text that is semantically coherent with respect 
to the search terms. This locale can be returned 
to the searcher for evaluation and if it is 
relevant, the search terms can be refined. This 
approach is compatible with Latent Semantic 
Indexing (LSI) for partial text retrieval when the 
terms of the vector space are not known. LSI is 
based on a vector space information retrieval 
method that has demonstrated improved 
performance over the traditional vector space 
techniques. So when incorporating semantic 
information, it is necessary to adopt existing 
mathematical methods including probabilistic 
methods and statistical methods. 
2 Theoretical Background 
2.1 Long Runs 
Partial Information Retrieval has to with 
detection of main ideas. Main ideas are topic 
sentences that have central meaning to the text. 
Our method of detecting main idea paragraphs 
extends from Jang (1997) who observed that 
after stemming and stopping a document, long 
runs of cor/tent words cluster. Content word runs 
are a sequence of content words with a function 
word(s) prefix and suffix. These runs can be 
weighted for density in a stopped ocument and 
vector processed. We observed that these long 
content word runs generally originate from the 
prepositional phrase and subject complement 
positions, providing a linguistic basis for a dense 
neighbourhood of long runs of content words 
signalling a semantic locus of the writing. We 
suppose that these neighbourhoods may contain 
main ideas of the text. In order to verify this, we 
designed a methodology to incorporate semantic 
features into information retrieval and examined 
long runs of content words as a semantic 
predictor. 
We examined all the long runs of the Jang 
(1997) collection and discovered most of them 
originate from the prepositional phrase and 
subject complement positions. According to 
Halliday (1985), a preposition is explained as a 
minor verb. It functions as a minor Predicator 
having a nominal group as its complement. Thus 
the internal structure of 'across the lake' is like 
that of 'crossing the lake', with a non-finite 
verb as Predicator (thus our choice of _> 3 words 
as a long run). When we interpret the 
preposition as a "minor Predicator" and "minor 
Process", we are interpreting the prepositional 
phrase as a kind of minor clause. That is, 
prepositional phrases function as a clause and 
their role is predication. 
Traditionally, predication is what a statement 
says about its subject. A named predication 
corresponds to an externally defined function, 
namely what the speaker intends to say his or 
her subject, i.e. their referent. If long runs 
largely appear in predication positions, it would 
suggest hat the speaker is saying something 
important and the longer runs of content words 
would signal a locus of the speaker's intention. 
Extending from the statistical analysis of Jang 
(1997) and our observations of those long runs 
in the collection, we give a basic assumption of 
our study: 
Long runs of content words contain 
significant semantic information that a 
speaker wants to express and focus, 
and thus are semantic indicators or loci 
or main ideas. 
7 
In this paper, we examine the SEMCAT 
values of long and short runs, extracted from a 
random document of the collection in Jang 
(1997), to determine if the SEMCAT weights of 
long runs of content words are semantic 
predictors. 
2.2 SEMCATs 
We adopted Roget's Thesaurus for our basic 
semantic ategories (SEMCATs). We extracted 
the semantic categories from the online 
Thesaurus for convenience. We employ the 39 
intermediate categories as basic semantic 
information, since the 6 main categories are too 
general, and the many sub-categories are too 
narrow to be taken into account. We refer to 
these 39 categories as SEMCATs. 
Table 1: Semantic Categories (SEMCATs) 
Abbreviation 
1 AFIG 
2 ANT 
3 CAU 
4 CHN 
5 COIV  
6 'CRTH 
7 D IM 
8 EXIS 
9 EXOT 
Io FORM 
11 GINV 
12 INOM 
13 MECO 
14 MFRE 
15 MIG 
16 MOAF 
17 MOCO 
18 MOT 
19 NOIC 
2o NUM 
21 OPIG 
22 ORD 
23 ORGM 
24 PEAF 
Full Description 
Affection in General 
Antagonism 
Causation 
Change 
Conditional Intersocial Volition 
Creative Thought 
Dimensions 
Existence 
Extension of Thought 
Form 
General Inter social Volition 
Inorganic Matter 
Means of Communication 
Materials for Reasoning 
Matter in general 
Moral Affections 
Modes of Communication 
Motion 
Nature of Ideas Communicated 
Number 
Operations of Intelligence 
In General 
Order 
Organic Matter 
Personal Affections 
25 
26 
PORE Possessive Relations 
PRCO 
27 PRVO 
28 QUAN 
29 REAF 
3o RELN 
31 REOR 
32 REPR 
33 ROVO 
34 SIG 
35 SIVO 
36 SYAF 
37 TIME 
38 VOAC 
39 VOIG 
Precursory Conditions and 
Operations 
Prospective Volition 
Quantity 
Religious Affections 
Relation 
Reasoning Organization 
Reasoning Process 
Result of Voluntary Action 
Space in General 
Special Inter social Volition 
Sympathetic Affections 
Time 
Voluntary Action 
Volition in General 
2.3 Indexing Space and Stop Lists 
Many of the most frequently occurring words in 
English, such as "the," "of, .... and," "to," etc. are 
non-discriminators with respect o information 
filtering. Since many of these function words 
make up a large fraction of the text of most 
documents, their early elimination in the 
indexing process speeds processing, saves 
significant amounts of index space and does not 
compromise the filtering process. In the Brown 
Corpus, the frequency of stop words is 551,057 
out of 1,013,644 total words. Function words 
therefore account for about 54.5% of the tokens 
in a document. 
The Brown Corpus is useful in text retrieval 
because it is small and efficiently exposes 
content word runs. Furthermore, minimizing the 
document token size is very important in NLP- 
based methods, because NLP-based methods 
usually need much larger indexing spaces than 
statistical-based methods due to processes for 
tagging and parsing. 
3 Experimental Basis 
In order to verify that long runs contribute to 
resolve semantic omplexities and can be used 
as predictors of semantic intent, we employed a
probabilistic, vector processing methodology. 
3.1 Revised Probability and Vector Processing 
In order to understand the calculation of 
SEMCATs, it is helpful to look at the structure 
8 
of a preprocessed ocument. One document 
"Barbie" in the Jang (1997) collection has a total 
of 1,468 words comprised of 755 content words 
and 713 function words. The document has 17 
paragraphs. Filtering out function words using 
the Brown Corpus exposed the runs of content 
words as shown in Figure 1. 
Figurel: Preprocessed Text Document 
BARBIE * * * * FAVORITE  COMPANION 
DETRACTORS LOVE * * * PLASTIC 
PERFECTION * * FASHION DOLL * * 
IMPOSSIBLE FIGURE * LONG * * * POPULAR 
GIRL * MATTEL * WORLD * TOYMAKER * 
PRODUCTS RANGE * FISHER PRICE INFANT * 
SALES * * * TALL MANNEQUIN * BARBIE * * 
AGE * * * BEST  SELL ING GIRLS  BRAND * * 
POISED * STRUT * * * CHANGE * * MALE 
DOMINATED WORLD * MULTIMEDIA 
SOFTWARE * VIDEO GAMES 
In Figure 1, asterisks occupy positions where 
function words were filtered out. The bold type 
indicates the location of the longest runs of 
content words. The run length distribution of 
Figure 1 is shown below: 
Table 2: Distribution of Content Run Lengths in 
a sample Document 
Run Length 
1 
Frequency 
11 
2 8 
3 2 
4 2 
The traditional vector processing model 
requires the following set of terms: 
? (dO the number of documents in the 
collection that each word occurs in 
? (idf) the inverse document frequency of each 
word determined by logl0(N/df) where N is 
the total number of documents. If a word 
appears in a query but not in a document, its 
idf is undefined. 
? The category probability of each query 
word. 
Wendlandt (1991) points out that it is useful to 
retrieve a set of documents based upon key 
words only, and then considers only those 
documents for semantic category and attribute 
analysis. Wendlandt (1991) appends the s 
category weights to the t term weights of each 
document vector Di and the Query vector Q. 
Since our basic query unit is a paragraph, 
document frequencY (df) and inverse document 
frequency (idf) have to be redefined. As we 
pointed out in Section 1, all terms are not known 
in partial text retrieval. Further, our approach is 
based on semantic weight rather than word 
frequency. Therefore any frequency based 
measures defined by Boyd et al (1994) and 
Wendlandt (1991) need to be built from the 
probabilities of individual semantic categories. 
Those modifications are described below. As a 
simplifying assumption, we assume SEMCATs 
have a uniform probability distribution with 
regard to a word. 
3.2 Calculating SEMCATs 
Our first task in computing SEMCAT values 
was to create a SEMCAT dictionary for our 
method. We extracted SEMCATs for every 
word from the World Wide Web version of 
Roget's thesaurus. SEMCATs give probabilities 
of a word corresponding to a semantic ategory. 
The content word run 'favorite companion 
detractors love' is of length 4. Each word of the 
run maps to at least one SEMCAT. The word 
'favorite' maps to categories 'PEAF and SYAF'. 
'companion' maps to categories 'ANT, MECO, 
NUM, ORD, ORGM, PEAF, PRVO, QUAN, 
and SYAF'. 'detractor' maps to 'MOAF'. 'love' 
maps to 'AFIG, ANT, MECO, MOAF, MOCO, 
ORGM, PEAF, PORE, PRVO, SYAF, and 
VOIG'. We treat the long runs as a semantic 
core from which to calculate SEMCAT values. 
SEMCAT weights are calculated based on the 
following equations. 
Eq.1 Pjk(Probability) - The likelihood of 
SEMCAT Sj occurring due to the K th 
trigger. For example, assuming a 
uniform probability distribution, the 
category PEAF triggered by the word 
favorite above, has the following 
probability: 
PPEAF, favorite ---- 0.5(1/2) 
Eq.2 Swj (SEMCAT Weights in Long runs) 
is the sum of each SEMCAT(j) weight 
of long runs based on their probabilities. 
In the above example, the long run 
9 
'favorite companion detractors love,' ihe 
SEMCAT 'MOAF' has SWMoAv : 
(detractor(l) + love(.09)) = 1.09. We 
can write; 
Swj= ? PO 
i=1 
Eq.3 edwj (Expected data weights in a 
paragraph) - Given a set of N content 
words (data) in a paragraph, the 
expected weight of the SEMCATs of 
long runs in a paragraph is: 
N 
edwj = E Po 
i=1 
Eq.4 idwj (Inverse data weights in a 
paragraph) - The inverse data weight of 
SEMCATs of long runs for a set of N 
content words in a paragraph is
idwj= loglo((e~wj\]) 
Eq.5 Weight(Wj) - The weight of SEMCAT 
Sj in.a paragraph is
Wj = Swjxidwj 
Eq.6 Relevance Weights (Semantic 
Coherence) 
W=? W 0 
i=1 
Our method performs the following steps: 
1. calculate the SEMCAT weight of each long 
content word run in every paragraph (Sw) 
2. calculate the expected ata weight of each 
paragraph (edw) 
3. calculate the inverse xpected ata weight of 
each paragraph (idw) 
4. calculate the actual weight of each 
paragraph (Swxidw) 
5. calculate coherence weights (total relevance) 
by summing the weights of (Swxidw). 
In every paragraph, extraction of SEMCATs 
from long runs is done first. The next step is 
finding the same SEMCATs of long runs 
through every word in a paragraph (expected 
data weight), then calculate idw, and finally 
Sw?idw. The final, total relevance weights are 
an accumulation of all weights of SEMCATs of 
content words in a paragraph. Total relevance 
tells how many SEMCATs of the Query's long 
runs appear in a paragraph. Higher values imply 
that the paragraph is relevant to the long runs of 
the Query. 
The following is a program output for 
calculating SEMCAT weights for an arbitrary 
long run: "SEVEN INTERACTIVE 
PRODUCTS LED" 
SEMCAT: EXOT Sw : 1.00 edw : 1.99 idw : 
1.44 Swxidw : 1.44 
SEMCAT: GINV Sw : 0.33 edw : 1.62 idw : 
1.53 Swxidw : 0.51 
SEMCAT: MOT Sw : 0.20 edw : 0.71 idw : 
1.89 Swxidw : 0.38 
SEMCAT: NUM Sw : 0.20 edw : 1.76 idw : 
1.49 Swxidw : 0.30 
SEMCAT: ORGM Sw : 0.20 edw : 1.67 idw : 
1.52 Sw?idw : 0.30 
SEMCAT: PEAF Sw : 0.53 edw : 1.50 idw : 
1.56 Swxidw : 0.83 
SEMCAT: REAF Sw : 0.20 edw : 0.20 idw : 
2.44 Swxidw : 0.49 
SEMCAT: SYAF Sw : 0.33 edw : 1.19 idw : 
1.66 Swxidw : 0.55 
Total (Swxidw) : 4.79 
4 Experimental Results 
The goal of employing probability and vector 
processing is to prove the linguistic basis that 
long runs of content words can be used as 
predictors of semantic intent But we also want to 
exploit the computational advantage of 
removing the function words from the 
document, which reduces the number of tokens 
processed by about 50% and thus reduces vector 
space and probability computations. If it is true 
that long runs of content words are predictors of 
semantic oherence, we can further reduce the 
complexity of vector computations: (1) by 
eliminating those paragraphs without long runs 
from consideration, (2) within remaining 
paragraphs with long runs, computing and 
summing the semantic oherence of the longest 
runs only, (3) ranking the eligible paragraphs for 
retrieval based upon their semantic weights 
relative to the query. 
Jang (1997) established that the distribution 
of long runs of content words and short runs of 
content words in a collection of paragraphs are 
drawn from different populations. This implies 
10 
that either long runs or short runs are predictors, 
but since all paragraphs contain short runs, i.e. a 
single content word separated by function 
words, only long runs can be useful predictors. 
Furthermore, only long runs as we define them 
can be used as predictors because short runs are 
insufficient to construct the language constructs 
for prepositional phrase and subject complement 
positions. If short runs were discriminators, the 
linguistic assumption of this research would be 
violated. The statistical analysis of Jang (1997) 
does not indicate this to be the case. 
To proceed in establishing the viability of 
our approach, we proposed the following 
experimental hypotheses: 
(HI) The SEMCAT weights for long runs 
of content words are statistically greater 
than weights for short runs of content 
words. Since each content word can map 
to multiple SEMCATs, we cannot 
assume that the semantic weight of a 
long run is a function of its length. The 
semantic oherence of long runs should 
be a more granular discriminator. 
(H2) For paragraphs containing long runs 
and short runs, the distribution of long 
run SEMCAT weights is statistically 
different from the distribution of short 
run SEMCAT weights. 
(H3) There is a positive correlation 
between the sum of long run SEMCAT 
weights and the semantic oherence of a 
paragraph, the total paragraph SEMCAT 
weight. 
A detailed description of these experiments 
and their outcome are described in Shin (1997, 
1999). The results of the experiments and the 
implications of those results relative to the 
method we propose are discussed below. Table 3 
gives the SEMCAT weights for seventeen 
paragraphs randomly chosen from one document 
in the collection of Jang (1997). 
Table 3: SEMCAT Weights of 17 Paragraphs Chosen 
Randomly From 
Paragraph 
a Collection 
2 
3 
Short Runs I Long Runs 
Weight Weight 
29.84 18.60 
31.29 12.81 
23.29 14.25 
4 23.94 11.63 
L 5 34.63 35.00 
I 6 22.85 03.32 
7 21.74 00.00 
I 8 35.84 15.94 
i 
9 30.15 00.00 
! -  
! I 0 13.40 00.00 
i 11 23.01 07.82 
12 31.69 04.79 
13 36.54 00.00 
14 17.91 10.55 
15 19.70 05.83 
16 17.11 00.00 
17 31.86 00.00 
The data was evaluated using a standard two way 
F test and analysis of variance table with ct = .05. 
The analysis of variance table for the paragraphs 
in Table 3 is shown in Table 4. 
Table 4: Analysis of Vari~ 
Variation Degrees 
of 
Between 
Treatments 1 
V R = 2904.51 
Between 
Blocks 16 
Vc = 1502.83 
Residual or 
Random 16 
VE= 677.77 
Total 33 
V = 5085.11 
iance for Table 2 Data 
Freedom 
Mean 
Square F 
2904.51 
93.92 
42.36 
68.56 
2.21 
At the .05 significance level, Fa _ .o5 = 4.49 for 
1,16 degrees of freedom. Since 68.56 > 4.49 we 
reject the assertion that column means (run 
weights) are equal in Table 2. Long run and 
short run weights come from different 
? populations. We accept HI. 
For the between paragraph treatment, he 
row means (paragraph weights) have an F value 
of 2.21. At the .05 significance level, F,~ = 05 = 
2.28 for 16,16 degrees of freedom. Since 2.21 < 
2.28 we cannot reject the assertion that there is 
no significant difference in SEMCAT weights 
between paragraphs. That is, paragraph weights 
do not appear to be taken from different 
populations, as do the long run and short run 
weight distributions. Thus, the semantic weight 
11 
of the content words in a paragraph cannot be 
used to predict the semantic weight of the 
paragraph. We therefore proceed to examine H2. 
Notice that two paragraphs in Table 2 are 
without long runs. We need to repeat the 
analysis of variance for only those paragraphs 
with long runs to see if long runs are 
discriminators. Table 5 summarizes those 
paragraphs. 
Table 5: SEMCAT weights of 11 paragraphs 
containing long runs and short runs 
Paragraph Short Runs Long Runs 
Weight Weight 
1 29.84 18.60 
2 31.29 12.81 
3 23.29 4.25 
4 23.94 11.63 
5 34.63 35.00 
6 22.85 03.32 
8 35.84 15.94 
11 23.01 07.82 
12 31.69 04.79 
14 17.91 10.55 
15 19.70 05.83 
This data was evaluated using a standard two way 
F test and analysis of variance with cx = .05. The 
analysis of variance table for the paragraphs in 
Table 5 follows. 
Table 6: Anal 
Variation 
Between 
Treatments 
V R = 1430.98  
Between 
Blocks 
V c = 944 .08  
Residual or 
Random 
VF= 49.19 
Total 
V = 2424.26 
sis of Variance for Table 5 Data 
Degrees Mean 
of Square 
Freedom 
1 1430.98 
10 94.40 
10 4.91 
21 
F 
291.44 
19.22 
At the .05 significance l vel, F== .05 = 4.10 for 
2,10 degrees of freedom. 4.10 < 291.44. At the 
.05 significance level, F= = .05 = 2.98 for 10,10 
degrees of freedom. 2.98 < 19.22. For 
paragraphs in a collection containing both long 
and short runs, the SEMCAT weights of the 
long runs and short runs are drawn from 
different distributions. We accept H2. 
For paragraphs containing long runs and 
short runs, the distributions of long run 
SEMCAT weights is different from the 
distribution of short run SEMCAT weights. We 
know from the linguistic basis for long runs that 
short runs cannot be used as predictors. We 
therefore proceed to examine the Pearson 
correlation between the long run SEMCAT 
weights and paragraph SEMCAT weights for 
those paragraphs with both long and short 
content word runs. 
Table 7: Correlation of Long Run SEMCAT 
Weights to Paragraph SEMCAT Weight 
Paragraph Long Runs 
Semantic 
Weight 
18.60 
12.81 
Paragraph 
Semantic 
Weight 
48.44 
44.10 
3 4.25 27.54 
4 11.63 35.57 
5 35.00 69.63 
6 03.32 26.17 
8 15.94 51.78 
11 07.82 30.83 
12 04.79 31.69 
14 10.55 28.46 
15 05.83 25.53 
The weights in Table have a positive Pearson 
Product Correlation coefficient of .952. We 
therefore accept H3. There is a positive 
correlation between the sum of long run 
SEMCAT weights and the semantic oherence 
of a paragraph, the total paragraph SEMCAT 
weight. 
5. Conclusion 
This research tested three statistical hypotheses 
extending from two observations: (1) Jang 
(1997) observed the clustering of long runs of 
content words and established the distribution of 
long run lengths and short run lengths are drawn 
from different populations, (2) our observation 
that these long runs of content words originate 
from the prepositional phrase and subject 
complement positions. According to Halliday 
(1985) those grammar structures function as 
12 
minor predication and as such are loci of 
semantic intent or coherence. In order to 
facilitate the use of long runs as predictors, we 
modified the traditional measures of Boyd et al 
(1994), Wendlandt (1991) to accommodate 
semantic categories and partial text retrieval. 
The revised metrics and the computational 
method we propose were used in the statistical 
experiments presented above. The main findings 
of this work are 
1. the distribution semantic coherence 
(SEMCAT weights) of long runs is not 
statistically greater than that of short 
runs, 
2. for paragraphs containing both long runs 
and short runs, the SEMCAT weight 
distributions are drawn from different 
populations 
3. there is a positive correlation between 
the sum of long run SEMCAT weights 
and the total SEMCAT weight of the 
paragraph (its semantic oherence). 
Significant additional work is required to 
validate these preliminary results. The collection 
employed in Jang (1997) is not a standard 
Corpus so we have no way to test precision and 
relevance of the proposed method. The results of 
the proposed method are subject o the accuracy 
of the stop lists and filtering function. 
Nonetheless, we feel the approach proposed 
has potential to improve performance through 
reduced token processing and increased 
relevance through consideration of semantic 
coherence of long runs. Significantly, our 
approach does not require knowledge of the 
collection. 
Halliday M.A.K. (1985) An Introduction to 
Functional Grammar. Edward Arnold, London. 
Jang S. (1997) Extracting Context from Unstructured 
Text Documents by Content Word Density. M.S. 
Thesis, University of Missouri-Kansas City. 
Moffat A., Davis R., Wilkinson, R., and Zobel J. 
(1994) Retrieval of Partial Documents. In 
Proceedings of TREC-2. 
Shin H. (1997) Incorporating Semantic Categories 
(SEMCATs) into a Partial Information Retrieval 
System. M.S. Thesis, University of Missouri- 
Kansas City. 
Shin H., Stach J. (1999) Incorporating Probabilistic 
Semantic Categories (SEMCATs) Into Vector 
Space Techniques for Partial Document Retrieval. 
Journal of Computer Science and Information 
Management, vol. 2, No. 4, December 1999, to 
appear. 
Wendlandt E. and Driscoll R. (1991) Incorporating a 
semantic analysis into a document retrieval 
strategy. CACM 31, pp. 54-48. 
References 
Boyd R., Driscoll J, and Syu I. (1994) Incorporating 
Semantics Within a Connectionist Model and a 
Vector Processing Model. In Proceedings of the 
TREC-2, NIST. 
Deerwester S., Furnas G., Landauer T., and 
Harshman R. (1990) Indexing by Latent Semantic 
Anaysis. Journal of the American Society of 
Information Science 41-6. 
13 
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 115?122,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
KTimeML: 
Specification of Temporal and Event Expressions in Korean Text 
 
 
Seohyun Im 
Dept. of Computer Science 
Brandeis University 
Waltham, MA, USA 
ish97@cs.brandeis.edu 
Hyunjo You, Hayun Jang, Seungho Nam, Hyopil Shin 
Dept. of Linguistics 
Seoul National University 
Seoul, Korea 
youhyunjo, hyan05, nam, hpshin@snu.ac.kr 
 
  
 
Abstract  
TimeML, TimeBank, and TTK (TARSQI 
Project) have been playing an important role 
in enhancement of IE, QA, and other NLP 
applications. TimeML is a specification lan-
guage for events and temporal expressions in 
text. This paper presents the problems and so-
lutions for porting TimeML to Korean as a 
part of the Korean TARSQI Project. We also 
introduce the KTTK which is an automatic 
markup tool of temporal and event-denoting 
expressions in Korean text. 
1 Introduction 
The TARSQI (Temporal Awareness and Reason-
ing systems for QA) Project 1  aims to develop 
technology for annotation, extraction, and rea-
soning of temporal information in natural lan-
guage text. The main result of the TARSQI Pro-
ject consists of TimeML (Pustejovsky et. al., 
2003), TimeBank (Pustejovsky et. al., 2006), and 
TARSQI Toolkit (TTK, Verhagen and Puste-
jovsky, 2008). TimeML is a specification lan-
guage for events and temporal expressions in text. 
TimeBank is an annotated corpus which was 
made as a proof of the TimeML specification. 
TTK is an automatic system to extract events and 
time expressions, creating temporal links be-
tween them2.  
TimeML is an ISO standard of a temporal 
markup language and has been being extended to 
other languages such as Italian, Spanish, Chinese, 
                                               
1
 Refer to www.timeml.org for details on the TARSQI. 
2
 TTK contains GUTime (TIMEX3 tagging, Mani and Wil-
son, 2000), Evita (event extraction, Saur? et. al., 2005), 
Slinket (modal parsing, Saur? et. al., 2006b), S2T, Blinker, 
Classifier, Sputlink, Link Merger, etc.   
 
etc. (ISO/DIS 24617-1: 2008). TempEval-2, a 
task for the Semeval-2010 competition, has been 
proposed (Pustejovsky et. al. 2008). The task for 
the TempEval-2 is evaluating events, time ex-
pressions, and temporal relations. Data sets will 
be provided for English, Italian, Spanish, Chi-
nese, and Korean. 
The necessity of temporal and event expres-
sions markup for any robust performance such as 
QA (for Korean QA system, refer to Han et. al., 
2004), IE, or summarization is applied to Korean 
NLP applications as well. Recently, there have 
been TimeML-related studies for Korean: Jang et. 
al (2004) show an automatic annotation system 
of temporal expressions with Timex2 in Korean 
text. Lee (2008) argues about the semantics of 
Korean TimeML, specially the EVENT tag. Im 
and Saur? (2008) focus on the problems of Ti-
meML application to Korean caused by typo-
logical difference between English and Korean. 
Motivated by them, the Korean TARSQI Project3 
started with the purpose of making TimeML, 
TimeBank and TTK for Korean text4.  
Porting TimeML to other languages can be 
challenging because of typological difference 
between languages. In this paper, we present the 
problems for TimeML application to Korean. 
Our solution is to change TimeML markup phi-
losophy: a change from word-based in-line anno-
tation to morpheme-based stand-off annotation. 
Based on the changed annotation philosophy, we 
decide how to annotate temporal and event-
denoting expressions in Korean text. More spe-
cifically, it is challenging to decide whether we 
use LINK tags or attributes to annotate some 
                                               
3
 See http://word.snu.ac.kr/k-tarsqi/doku.php for more in-
formation about the KTARSQI Project. 
4
 James Pustejovsky gave a talk about TARSQI for KTAR-
SQI Project, visiting Korea for his invited talk at CIL 18 
conference in 2008.  
115
temporal or event-denoting expressions (see ex-
amples in 3.2).  In section 4, we describe the 
specification of Korean TimeML (KTimeML). 
Section 5 introduces Korean TTK (KTTK). Be-
fore discussing the issues of Korean TimeML, 
we briefly introduce TimeML.  
2 The Basics of TimeML 
TimeML features four major data structures: 
EVENT, TIMEX3, SIGNAL, and LINK. The 
EVENT tag encodes event-denoting expressions. 
The TIMEX3 tag annotates temporal expressions 
of different sorts: fully specified dates, times, 
and durations, or just partially specified dates, 
times, and durations. The SIGNAL tag annotates 
elements that indicate how temporal objects are 
related among them (e.g., subordinating connec-
tors such as when or after).  
The LINK tag splits into three main types: (a) 
TLINK, which encodes temporal relations among 
EVENTs and TIMEX3s; (b) ALINK, representing 
aspectual information as expressed between an 
aspectual predicate and its embedded event; and 
(c) SLINK, encoding subordination relations 
conveying evidentiality (e.g. Mary said [she 
bought some wine]), factivity (John regretted 
[Mary bought wine]), or intensionality (Kate 
thought [Mary bought beer]).  
Information relevant to each tag is character-
ized by means of attribute-value pairs (refer to 
Pustejovsky et. al. 2003 about specific attributes-
value pairs). (1) illustrates an annotated sentence 
with the TimeML specification:  
(1)John saide1 that Mary begane2 to worke3 
John 
<EVENT id=?e1? class=?REPORTING?    
tense=?PAST? aspect=?NONE? polar-
ity=?POS?> 
said </EVENT>  
that Mary  
<EVENT id=?e2? class=?ASPECTUAL? 
tense=?PAST? aspect=?NONE? polar-
ity=?POS?> 
began </EVENT>  
to 
<EVENT id=?e3? class=?OCCURRENCE? 
tense=?NONE? aspect=?NONE? polar-
ity=?POS?> 
work </EVENT> 
 
<TLINK eventID=?e1? relatedToEvent=?e2? 
relType=?AFTER?/> 
<SLINK eventID=?e1? subordinatedEvent=?e2? 
relType=?EVIDENTIAL?/> 
<ALINK eventID=?e2? relatedToEvent=?e3? 
relType=?INITIATES?/> 
 
Sentence (1) presents three EVENT expressions 
(said, began, and work). SLINK conveys an evi-
dential relation between e1 (said) and e2 (began). 
TLINK represents a temporal relation ? AFTER- 
between the two same events. ALINK encodes an 
aspectual relation ?initiates? between e2 (be-
gan) and e3 (work).  Due to space limitations, 
some EVENT attributes are obviated. 
3 Porting TimeML to Korean 
3.1 The Characteristics of Korean  
Korean is an agglutinative language whose 
words are formed by joining morphemes to-
gether, where an affix typically represents one 
unit of meaning and bound morphemes are ex-
pressed by affixes. For example, the sentence 
John-i emeni-kkeyse o-si-ess-ta-te-ra ?John-Nom 
mother-Nom come-Hon-Past-Quo-Ret-Dec 5 ? 
means that (I heard) (John said) that his mother 
came. Each morpheme has its own functional 
meaning or content.  
As shown above, consideration of morphemes 
is important for TimeML markup of Korean text. 
Here, we summarize TimeML-related character-
istics of Korean: 
(i) In Korean, functional markers (tense, aspect, 
mood, modality, etc.) are represented morphologically. 
English as an isolating language uses periphrastic 
conjugation to represent functional categories.  
(e.g. ?-keyss-?is a conjectural modal morpheme in pi-
ka o-keyss-ta ?it will rain?. While, ?will? is an auxil-
iary verb in it will rain.) 
(ii) Some subordination is realized morphologically 
via morpheme contraction.  
(e.g. ?-ta-n-ta? is a morphological contraction which 
denotes quotation in the sentence John-i nayil o-n-ta-
n-ta ?John-Nom tomorrow come-Pres-Dec.Quo-Pres-
Dec?. Its English counterpart is represented by subor-
dination: John said that he will come tomorrow) 
 (iii) Some connectives in English correspond to mor-
phemes in Korean.  
(e.g. Korean counterpart of the English connective 
?and? in I ate milk and went to sleep is the morpheme 
?-ko? in the sentence na-nun wuyu-rul masi-ko ca-re 
ka-ss-ta ?I-Top milk-Acc drink-and sleep-ending go-
Past-Dec?) 
(iv) The sentence type of English is represented by 
word order but that of Korean by ending morphemes  
(e.g. Declarative: pi-ka o-n-ta ?it is raining? interroga-
tive: pi-ka o-ni? ?Is it raining??) 
                                               
5
 Nom: nominative case, Hon: honorific morpheme, 
Past: past tense morpheme, Quo: quotative mood 
morpheme, Ret: retrospective mood morpheme, Dec: 
declarative sentence ending 
116
These properties of Korean make the porting of 
TimeML to Korean challenging. In the next sec-
tion, we discuss the basic issues of KTimeML.  
3.2 Basic Issues of Korean TimeML  
3.2.1 Morpheme-based standoff annotation  
TimeML employs word-based in-line annotation. 
It poses a challenge at the representation level, 
since it encodes information mainly based on the 
structure of the target language, and thus content 
equivalences among different languages are hard 
to establish. For example, indirect quotation in 
Korean offers an example of the mismatch of 
linguistic devices employed in different lan-
guages to express the same meaning. Quotation 
constructions in English use two predicates, the 
reporting and the reported, which TimeML 
marks up as independent EVENTs: 
(2) John saide1 he boughte2 a pen.  
  <SLINK eventID=?e1? subordinatedE-
vent=?e2?relType=?EVIDENTIAL?/> 
TimeML uses a subordination link (SLINK) in 
order to convey the evidentiality feature that the 
reporting predicate projects to the event ex-
pressed by its subordinated argument. 
On the other hand, a Korean quotative con-
struction, as in (3), has only one verb stem, 
which corresponds to the subordinated predicate 
in English. Note that there is no reporting predi-
cate such as say in English. Nevertheless, the 
sentence has a reporting interpretation.  
(3) John-i  ku-ka  wine-ul  sa-ss-ta-n-ta 
    J-Nom    he-Nom  wine-Acc  buy-Past-Quo-Pres-Dec 
    ?John said that he bought some wine? 
The quotative expression ?ta-n-ta above is a con-
tracted form of ?ta-ko malha-n-ta ?Dec-Quo say-
Pres-Dec?. Although (3) is a simple sentence in-
volving no subordination at the syntactic level, 
the two tense markers, ?-ss-? and ?-n-?, are evi-
dence of the existence of an implicit reporting 
event. Specifically, the past tense marker ?-ss-? 
applies to the main event here (sa-ss ?buy-past?), 
while the present tense marker ?-n-? is under-
stood as applying to the implicit reporting event 
(ta-n-ta ?report-pres-Dec)6. 
Constructions presented above show a prob-
lem for the standard TimeML treatment of a Ko-
rean quotative sentence. The relationship be-
tween reporting and reported events is expressed 
morphologically, and thus the SLINK mechanism 
                                               
6
 Tense markers of the construction can change: sa-ss-tay-
ss-ta ?buy-past-quo-past-dec: said_bought?; sa-n-ta-n-ta 
?buy-pres-quo-pres-dec: say_buy?, etc.  
for word-based annotation is not adaptable here. 
Because Korean transfers meanings through 
morphological constructions, morpheme-based 
annotation is more effective than word-based for 
TimeML application to Korean7.  
For morpheme-based tagging, we propose 
stand-off annotation for Korean because it needs 
two-level annotation: the MORPH tag 8  and Ti-
meML tags. Standoff annotation separates mor-
phologically-annotated data from primary data 
and saves it in a different file, and then TimeML 
annotation applies to the data. The following is 
the proposed morpheme-based stand-off annota-
tion for (3). 
(4) Morpheme-based stand-off annotation for (3) 
<MORPH id=?m7? pos=?PV?/> 
<MORPH id=?m8? pos=?EFP?/> 
<MORPH id=?m9? pos=?EFP?/> 
<MORPH id=?m10? pos=?EFP?/> 
<MORPH id=?m11? pos=?EF?/> 
<EVENT id=?e1? morph=?m7 m8? yaleRo-
manization=?sa-ss? pred=?buy? 
class=?OCCURRENCE? tense=?PAST? sen-
tenceMood=?DEC?/>       
<EVENT id=?e2? morph=?m9 m10 m11? 
yaleRomanization=?ta-n-ta? pred=?say? 
class=?REPORTING? tense=?PRESENT? sen-
tenceMood=?DEC?/> 
<SLINK eventID=?e2? subordinatedE-
vent=?e1? relType=?EVIDENTIAL?/> 
<TLINK eventID=?e1? relatedToEvent=?e2? 
relType=?BEFORE?/> 
In (4), we show the example annotation of the 
MORPH tag for (3) to help readers to understand 
our proposal. Standoff annotation makes it pos-
sible to extract information about two events 
without using a non-text consuming EVENT tag. 
Moreover, each of the two tense morphemes is 
properly assigned to its related event. Our pro-
posed TimeML annotation scheme is composed 
of two levels ? morphological analysis and Ti-
meML annotation.  
                                               
7
 There can be several ways of annotating morphological 
constructions: morpheme-based, morpho-syntactic unit-
based (refer to MAF: Cl?ment and Clergerie, 2005), charac-
ter-based, and bunsetsu-based. At present, we adopt mor-
pheme-based annotation because it seems to be enough to 
introduce the required units for KTimeML markup and we 
want to avoid the possible redundancy of bunsetsu-based or 
morpho-syntactic unit-based annotation. Moreover, the 
criterion for separation of a morphological construction is 
related with tags such as EVENT, TIMEX3, or attributes like 
tense, aspect, mood, or modality in KTimeML, not with 
syntactic or phonological information. Standoff annotation 
makes it easy to mark up the interval of morphemes. Never-
theless, we consider the possible advantage of morpho-
syntactic analysis positively for future work.  
8
 The values of the POS attribute are based on a Korean 
Part_of_Speech Tag Set version 1.0 (Kim and Seo, 1994).  
 
117
 3.2.2 Surface-based annotation  
KTimeML adopts the surface-based annotation 
philosophy of TimeML (Saur? et. al. 2006a), 
which does not encode the actual interpretation 
of the constructions it marks up, but their gram-
matical features. For example, the leaving event 
in the sentence we are leaving tomorrow is not 
annotated as expressing a future tense, but as 
expressed by means of a present tense form. 
Several considerations motivate this surface-
based approach. As an annotation language, it 
must guarantee the marking up of corpora in an 
efficient and consistent way, ensuring high inter-
annotator agreement. As a representation 
scheme, it needs to be used for training and 
evaluating algorithms for both temporal informa-
tion extraction and temporal reasoning.  
A surface-based approach is the suitable op-
tion for meeting such requirements. Neverthe-
less, it poses a challenge at the representation 
level. How to represent evidentiality in Korean 
and English shows the challenge.  
(5) I sawe1 that John boughte2 some wine. 
   <SLINK lid=?sl1? eventID=?e1? subordinat-
edEvent=?e2? relType=?EVIDENTIAL?/> 
English, as an isolating language, expresses evi-
dentiality in a periphrastic manner. Hence, the 
TimeML treatment of these constructions con-
sists in marking the two involved predicates as 
EVENTs, and introducing an SLINK between 
them. Korean has both periphrastic and morpho-
logical ways for expressing evidentiality. Anno-
tating the periphrastic version with the standard 
TimeML treatment poses no problem because it 
has two predicates denoting events like its Eng-
lish counterpart. Morphological constructions 
however, are harder to handle, because the retro-
spective mood morpheme ?-te-? brings about the 
implicit reference to a seeing event.  
(6) Vietnam-un   tep-te-ra 
    Vietnam-Top  hot-Ret-Dec 
    ?(as I saw) Vietnam was hot? 
They are similar to quotative constructions in the 
sense that, although there is only one predicate 
expressed on the surface, the sentence refers to 
more than one event. Unlike quotative construc-
tions, there is no morphological evidence of the 
implicit event; e.g. tense or sentence mood 
markers independent of those applied to the only 
verbal predicate in the sentence. The issue to 
consider is therefore whether to treat the eviden-
tial constructions by introducing an EVENT tag 
for the retrospective mood marker as in (7) or to 
handle them by specifying the evidential value of 
the main predicate at the MOOD attribute of its 
EVENT tag, as illustrated in (8). 
(7) SLINK tagging for (6) 
<EVENT id=?e1? morph=?m3? yaleRomaniza-
tion=?tep? class=?STATE? pos=?ADJECTIVE? 
tense=?NONE?/> 
<EVENT id=?e2? morph=?m4 m5? yaleRomaniza-
tion=?te-ra? class=?PERCEPTION? pos=?NONE? 
tense=?NONE?/> 
<SLINK lid=?sl1? eventID=?e2? subordinatedE-
vent=?e1? relType=?EVIDENTIAL?/> 
(8) Mood-attribute tagging for (6) 
  <EVENT id=?e1? morph=?m3 m4 m5? yaleRo-
manization=?tep-te-ra? pred=?hot? 
class=?STATE? pos=?ADJECTIVE? 
tense=?NONE? mood=?RETROSPECTIVE?/> 
As in (7), adding an EVENT tag for the retrospec-
tive morpheme corresponds semantically to Eng-
lish-based TimeML. However, it is not surface-
based, because the perception event is an implicit 
event entailed by the retrospective morpheme. 
While, the annotation in (8) is a surface-based 
annotation of the evidential construction which 
uses the MOOD attribute for retrospective mood, 
thus respects the surface-based philosophy of 
TimeML. This is different from the English 
counterpart that presents two EVENTs related 
with a TLINK signaling their relative temporal 
order. KTimeML follows the surface-based an-
notation philosophy of TimeML ((8) here).  
 
3.2.3 Cancellation of the head-only rule 
TimeML employs the head-only markup policy 
in order to avoid problems derived from tagging 
discontinuous sequence (e.g. we are not fully 
prepared). If the event is expressed by a verbal 
phrase, the EVENT tag will be applied only to its 
head, which is marked in bold face in the exam-
ples (e.g. has been scrambling, to buy, did not 
disclose). However, Korean does not have the 
discontinuity problem. See Korean examples: 
(9) a.*na-nun cwunpitoy-e   wanpyekhakey  iss-ta 
        I-Top  prepared-e    fully      exist-Dec 
      ?we are fully prepared? 
    b. *John-un  ca-ko         anh-iss-ta 
        J-Top    sleep-ko      Neg-exist-Dec 
        ?John is not sleeping? 
In the above sentences, ?-e iss-? and ?-ko iss-? are 
respectively perfective and progressive aspect 
markers. No word can make discontinuous se-
quence by being embedded into the middle of the 
verb phrases. As we saw from the examples, Ko-
rean does not have discontinuity problem in ver-
bal phrases. Thus, KTimeML does not need to 
follow the head-only annotation rule. By cancel-
lation of the head-only rule, we annotate various 
118
verbal clusters (main verb + auxiliary verb con-
struction: e.g. mek-ko iss-ta ?eat-progressive-
dec?). It makes the KTimeML more readable by 
showing the progressive aspect-denoting expres-
sion -ko iss- in one unit of annotation.  
4  Specification of the Korean TimeML  
Based on the proposed annotation principles of 
KTimeML, we present the specification of the 
first version of KTimeML (KTimeML 1.1) with 
changed tags, attributes, and their values. We 
assume that the MORPH-tagged data are sepa-
rately saved in a different file. KTimeML con-
tains EVENT, TIMEX3, SIGNAL, and LINK tags. 
Some new attributes such as mood and sType 
are added to the attributes of the EVENT tag. The 
other tags have no changes from the TimeML 
tags9.  
KTimeML 1.1 adds the attributes of predi-
cate_content (pred), mood, verb_form (vForm), 
and sentence type (sType) to the attributes of 
EVENT in TimeML (For Korean grammar, refer 
to Sohn, 1999, Nam and Ko, 2005). The BNF of 
EVENT is shown below: 
attributes ::= id pred morph yaleRomanization  
               class pos tense [aspect][mood] 
              [sType][modality] vForm  
id ::= ID 
{id ::= EventID 
 EventID ::= e<integer>} 
morph ::= IDREF 
{morph ::= MorphID} 
yaleRomanization ::= CDATA 
pred ::= CDATA 
class ::= ?OCCURRENCE?|?ASPECTUAL?|?STATE?|  
          ?PERCEPTION?|?REPORTING?|?I_STATE?| 
          ?I_ACTION? 
pos ::= ?ADJECTIVE?|?NOUN?|?VERB?|?OTHER? 
tense ::= ?PAST?|?NONE?  
aspect ::= ?PROGRESSIVE?|?PERFECTIVE?| 
           ?DURATIVE? | ?NONE? 
mood ::= ?RETROSPECTIVE? | ?NONE? 
   {default, if absent, is ?NONE?} 
sType ::= ?DECLARATIVE?|?INTERROGATIVE?| 
          ?IMPERATIVE?|?PROPOSITIVE?| ?NONE?  
         {default, if absent, is 'DECLARATIVE'} 
modality ::= ?CONJECTUAL?|?NONE? 
          {default, if absent, is 'NONE'} 
vForm ::= ?S_FINAL?|?CONNECTIVE?|?NOMINALIZED?|  
          ?ADNOMINAL? 
          {default, if absent, is 'S_FINAL'} 
polarity ::= ?NEG?|?POS? 
          {default, if absent, is 'POS'} 
KTimeML puts the semantic content of EVENT-
tagged expressions for international communica-
tion. Because mood is not an important gram-
matical category for English, TimeML does not 
                                               
9
 Nevertheless, how to annotate various morphologi-
cal constructions in the specific texts is not trivial. 
The annotation guideline, which will be published on 
the web, will handle the issues in detail. 
markup a mood attribute, but KTimeML adds the 
mood attribute since there are morphemes that 
express mood like many other languages. Unlike 
English, different sentence ending morphemes 
represent sentence types in Korean. Hence, 
KTimeML adds sType to attributes of the 
EVENT tag. We put vForm to distinguish be-
tween different subordinated clauses10.  
Event classes in KTimeML are the same as 
TimeML. Korean tense system does not have 
distinction between present and future unlike 
English, and thus the tense attribute has PAST 
and NONE values. We add DURATIVE to aspect 
attribute values in KTimeML for the durative 
expression such as combination of stative verb + 
progressive aspect marker (e.g. al-ko iss-ta 
?know-durative-Dec?). 
For mood, KTimeML 1.1 puts the retrospective 
mood (?-te-?). The values of vForm attribute are 
S_FINAL, CONNECTIVE, and NOMINALIZED, 
and ADNOMINAL. The sentence types in Korean 
are DECLARATIVE, INTEROGGATIVE, IM-
PERATIVE, and PROPOSITIVE (e.g. cip-ey ka-ca 
?Let?s go home?). KTimeML puts CONJEC-
TURAL (e.g. nayil pi-ka o-keyss-ta ?(I guess) It 
will rain tomorrow?) as a modality value and de-
fault is NONE. The sentence in (10) is an inter-
esting example that includes all attributes of an 
EVENT tag for Korean TimeML except for as-
pect.   
(10)ecey  Seoul-un  pi-ka  o-ass-keyss-te-ra 
     yesterday Seoul-Top rain-Nom come-Past-Conj-Ret-Dec 
      ?(From that I saw), I guess that it rained in Seoul  
           yesterday?  
<EVENT id=?e1? morph=?m6 m7 m8 m9 m10?     
 yaleRomanization=?wa-ss-keyss-te-ra?  
 pred=?come? pos=?VERB?  
 class=?OCCURRENCE? tense=?PAST? 
 aspect=?NONE? mood=?RETROSPECTIVE? 
 modality=?CONJECTURAL? vForm=?S_FINAL?  
 sType=?DECLARATIVE? polarity=?POS?/> 
Each of the morphemes above has its own func-
tional meaning, which is represented as a value 
of an attribute in the EVENT tag. 
The major types of TIMEX3 expressions are: 
(a) Specified Temporal Expressions, 2009-nyen 5-
wol 1-il ?2009-year 5-month 1-day?, (b) Under-
specified Temporal Expressions, wolyoil ?Mon-
day?, caknyen ?last year?, ithul cen ?two days ago?; 
(c) Durations, 2 kaywol ?2 months?, 10 nyen ?ten 
years?.  
attributes ::= tid type [functionInDocument]  
              [temporalFunction] morph  
               yaleRomanization 
              (value|valueFromFunction)  
              [mod][anchorTimeID|anchorEventID]              
                                               
10
 ISO-TimeML also has pred, mood, and vForm. 
119
tid ::= ID 
{tid ::= TimeID 
 TimeID ::= t<integer>} 
morph ::= IDREF  
{morph ::= MorphID} 
yaleRomanization ::= CDATA 
type ::= ?DATE?|?TIME?|?DURATION? 
functionInDocument ::= ?CREATION_TIME?| 
         ?EXPIRATION_TIME?|?MODIFICATION_TIME?| 
         ?PUBLICATION_TIME?|?RELEASE_TIME?| 
         ?RECEPTION_TIME?|?NONE? 
temporalFunction ::= ?true?|?false? 
         {temporalFunction ::= boolean} 
value ::= CDATA 
         {value ::= duration|dateTime| 
                    time|date|gYearMonth| 
                    gYear|gMonthDay|                          
                    gDay|gMonth} 
valueFromFunction ::= IDREF 
{valueFromFunction ::= TemporalFunctionID  
TemporalFunctionID ::= tf<integer>} 
mod ::= ?BEFORE?|?AFTER?|?ON_OR_BEFORE?| 
        ?ON_OR_AFTER?|?LESS_THAN?|?MORE_THAN?| 
        ?EQUAL_OR_LESS?|?EQUAL_OR_MORE?|?START| 
        ?MID?|?END?|?APPROX? 
anchorTimeID ::= IDREF 
        {anchorTimeID ::= TimeID} 
comment ::= CDATA 
Although the BNF of TIMEX3 in Korean Ti-
meML is same as that of TimeML, we point out 
that Korean time expressions also have the issue 
of how to treat morphological representations of 
temporal meaning. For example, pwuthe ?from? 
and kkaci ?to? in 3ilpwuthe 5ilkkaci ?From 3rd to 
5th? both are the counterparts of prepositions in 
English (Jang et. al., 2004). We do not tag tem-
poral morphemes as SIGNALs, in principle. In-
stead, we mark up 3ilpwuthe ?from 3rd? with one 
TIMEX3 tag. However, temporal connectives 
such as ttay ?when? in ku-ka o-ass-ul ttay young-
hee-nun ttena-ss-ta ?When he came, Younghee 
left? are tagged as SIGNALs.  
SIGNAL is used to annotate sections of text - 
typically function words - that indicate how tem-
poral objects are to be related to each other. It 
includes temporal connectives (e.g. ttay ?when?, 
tongan ?during?), and temporal noun (e.g. hwu 
?after?, cen ?before?). See the BNF of SIGNAL 
below: 
attributes ::= sid morph yaleRomanization 
sid ::= ID 
{sid ::= SignalID 
SignalID ::= s<integer>} 
morph ::= IDREF  
{morph ::= MorphID} 
yaleRomanization ::= CDATA 
We show an annotated example which describes 
the difference of Korean TimeML markup from 
the English-based TimeML. The sentence below 
is a compound sentence. 
(11) ku-nun hankwuk panghan-ul maci-n hwu,  
     Ku-Top   Korea      visit-Acc    finish  after 
     onul  cwungkwuk-uro ttena-ss-ta 
      today China-for     leave-Past-Dec 
     ?He finished his visit to Korea   
      and left for China today? 
<Document time: March, 20, 2009> 
<EVENT id=?e1? morph=?m4 m5? yaleRomaniza-
tion=?pangmwun-ul?  
 pred=?visit? class=?OCCURRENCE?/> 
<EVENT id=?e2? morph=?m6 m7? yaleRomaniza-
tion=?machi-n? pred=?finish? 
class=?ASPECTUAL? pos=?VERB? 
tense=?NONE? vForm=?ADNOMINAL?/> 
<SIGNAL sid=?s1? morph=?m8? yaleRomaniza-
tion=?hwu?/> 
<TIMEX3 tid=?t1? morph=?m9? yaleRomaniza-
tion=?onul? type=?DATE? value=?2009-03-
20? temporalFunction=?true?/> 
<EVENT id=?e3? morph=?m14 m15 m16? yaleRo-
manization=?ttena-ss-ta?  
 pred=?leave? class=?OCCURRENCE?  
 tense=?PAST? sType=?DECLARATIVE?   
 vForm=?S_FINAL?/> 
LINK types splits into TLINK, SLINK, and 
ALINK. The BNF of TLINK is as follows: 
attributes ::= [lid] (eventID|timeID)  
               [signalID] (relatedToEvent| 
               relatedToTime) relType [comment]  
lid ::= ID 
{lid ::= LinkID  
 LinkID ::= l<integer>} 
eventID ::= IDREF 
{eventID ::= EventID} 
timeID ::= IDREF 
{timeID ::= TimeID} 
signalID ::= IDREF 
{signalID ::= SignalID} 
relatedToEvent ::= IDREF 
{relatedToEvent ::= EventID} 
relatedToTime ::= IDREF 
{relatedToTime ::= TimeID} 
relType ::= ?BEFORE?|?AFTER?|INCLUDES?| 
            ?IS_INCLUDED?|?DURING?| 
            ?SIMULTANEOUS?|?IAFTER?|?IBEFORE?| 
            ?IDENTITY?|?BEGINS?|?ENDS?| 
            ?BEGUN_BY?|?ENDED_BY?|?DURING_INV? 
comment ::= CDATA 
TLINK is a temporal link among EVENTs and 
TIMEX3s. For example, three TLINKs are tagged 
between the events in (11). We show those to-
gether with other LINKs in (12). Now, we show 
the BNF of SLINK.  
attributes ::= [lid] eventID [signalID]  
               subordinatedEvent relType  
               [comment]  
lid ::= ID 
{lid ::= LinkID  
 LinkID ::= l<integer>} 
eventID ::= IDREF 
{eventID ::= EventID} 
subordinatedEvent ::= IDREF 
{subordinatedEvent ::= EventID} 
signalID ::= IDREF 
{signalID ::= SignalID} 
120
relType ::= ?INTENTIONAL?|?EVIDENTIAL?| 
            ?NEG_EVIDENTIAL?|?FACTIVE?| 
            ?COUNTER_FACTIVE?|?CONDITIONAL? 
comment ::= CDATA 
The subordination link is used for contexts in-
volving modality, evidentials, and factives.  
In Korean, various morphemes bring about 
subordination clauses. Nominal endings such as -
um/-ki make nominal clauses (e.g. na-nun John-i 
o-ass-um-ul al-ko iss-ta ?I-Top John-Nom come-Past-
Nominal ending-Acc know-Durative-Dec?; na-nun 
kongpwuha-ki-ka shilh-ta ?I-Top study-nominal ending-
Nom hate-Dec?). Adnominal endings such as -n/-
un/-nun make adnominal clauses (e.g. na-nun 
John-i kaci-e-o-n kwaca-rul mek-ess-ta ?I-Top 
John-Nom bring-adnominal ending cookies-Acc eat-Past-
Dec?). Conditional clauses are also triggered by 
morphemes (e.g. na-nun John-i o-myen ka-
keyss-ta ?I-Top John-Nom come-Conditional go-Conj-
Dec?). All the above morphemes are not sepa-
rately tagged as SIGNALs. The words with the 
morphemes ? o-ass-um-ul, kongpwuha-ki-ka, 
kaci-e-o-n, and o-myen ? are tagged as EVENTs.  
ALINK is an aspectual link which indicates an 
aspectual connection between two events.   
attributes ::= [lid] eventID [signalID]  
               relatedToEvent relType  
               [comment]  
lid ::= ID 
{lid ::= LinkID  
 LinkID ::= l<integer>} 
eventID ::= IDREF 
{eventID ::= EventID} 
relatedToEvent ::= IDREF 
{relatedToEvent ::= EventID} 
signalID ::= IDREF 
{signalID ::= SignalID} 
relType ::= ?INITIATES?|?CULMINATES?| 
            ?TERMINATES?|?CONTINUES?| 
            ?REINITIATES? 
comment ::= CDATA 
Now we show the ALINK and TLINKs of the sen-
tence in (11).  
(12) LINKs between the events in (11) 
<ALINK eventID=?e2? relatedToEvent=?e1? 
relType=?CULMINATES?/> 
<TLINK eventID=?e3? relatedToEvent=?e2? 
relType=?AFTER?/> 
<TLINK eventID=?e2? relatedToEvent=?e1? 
relType=?ENDS?/> 
<TLINK eventID=?e3? relatedToEvent=?e1? 
relType=?AFTER?/> 
That is, the visiting event and the finishing are 
related aspectually and its relation type is culmi-
nating. The finishing event is related temporally 
with the leaving event by the signal ???(?after?). 
Naturally, the relation type of the TLINK is AF-
TER. From ALINK, additional TLINKs are de-
rived between visiting, finishing, and leaving 
events.  
5  Korean TARSQI ToolKit 
Based on the specification of KTimeML, we 
started to develop KTTK11.  
 
 
 
Figure 1. Korean TARSQI Architecture 
At first, the normalization of the raw document is 
done in the preprocessor module. Here the raw 
text is separated into sentences, wide characters 
are substituted by regular characters, punctuation 
symbols are normalized (specially quotation 
marks), sino-korean characters (hanja) are 
transcribed in hangul, and, the encoding is also 
normalized to unicode. 
The next module is called Pykts (Python 
Wrapper for KTS). Here, sentences are parsed in 
order to get their morphological components, 
which is achieved by means of a program called 
KTS. With the exception of this morphological 
parser, which was programmed in C, all the other 
components of our project are being written in 
Python in order to achieve good results in less 
time. The output of Pykts is a Document object 
composed by a hyerarchical data structure of 
document, sentences, words and morphemes, 
which is passed to the Event Tagger. 
The Event Tagger consists of three modules: a 
preprocessor where the chunking of Time 
Expressions is done; a module called Saken, 
which does the tagging of events; and, a module 
called Sigan for TIMEX3 tagging. Then, LINK 
                                               
11
 The architecture mainly relies on that of TTK. 
However, KTTK introduces a morphological analyzer 
for morpheme-based standoff annotation. KTTK uses 
the Aspectual Verb Lexicon for ALINK extraction.  
121
taggers add TLINK, ALINK, SLINK tags. A 
module S2T changes the annotated SLINKs and 
ALINKs into TLINKs. In the final step, the LINK 
Merger merges all TLINKs with temporal closure. 
6 Conclusion and Future Work 
Temporal and event information extraction is an 
important step for QA and other inference or 
temporal reasoning systems. Korean TARSQI 
Project aims at (1) making KTimeML; (2) build-
ing Korean TimeBank as a gold standard, and (3) 
developing KTTK as an automatic markup tool of 
temporal and event expressions in Korean text.  
In this paper, we presented problems in port-
ing TimeML to Korean and proposed changes of 
TimeML philosophy. Since consideration of 
morphological issues is a basic step for KTi-
meML, we introduce a morpheme-based two-
level stand-off annotation scheme. We adopt the 
surface-based annotation of TimeML, but do not 
follow the head-only annotation.  
The tags of KTimeML are EVENT, TIMEX3, 
TLINK, ALINK, and SLINKs. The morphological 
annotation is saved as separate data. The EVENT 
tag has the attributes such as vForm, sType, 
mood, and modality in addition to the attrib-
utes of TimeML. We showed the architecture of 
KTTK.  
This work will be a help for QA, IE, and other 
robust performance for Korean. In addition, 
KTimeML will be, hopefully, a model for port-
ing TimeML to other agglutinative languages 
such as Japanese.  
Aknowledgements 
The authors wish to thank Kiyong Lee (ISO-
TimeML) and James Pustejovsky, a director of 
the TARSQI Project, for their help for the speci-
fication of KTimeML.  
References 
Lionel Cl?ment and ?ric Villemonte de la Clergerie. 2005. 
MAF: a Morphosyntactic Annotation Framework. In 
Proceedings of the Language and Technology Confer-
ence, Poznan, Poland, pages 90-94. 
Han, Kyoung-Soo, Hoojung Chung, Sang-Bum Kim, 
Young-In Song, Joo-Young Lee, and Hae-Chang Lim. 
2004. TREC 2004 Question Answering System at Ko-
rea University. In Proceedings of the 13rd Text RE-
trieval Conference, Pages 446-455. Gettysburg, USA.  
Im, Seohyun and Roser Saur?. 2008. TimeML Challenges 
for Morphological Lanuages: A Korean Case Study. In 
Proceedings of CIL 18, Seoul, Korea. 
ISO DIS 24617-1:2008. Language resources management 
? Semantic annotation framework (SemAF) ? Part1: 
Time and events. ISO 2008. Unpublished. 
Jang, Seok-Bae, Jennifer Baldwin, and Inderjeet Mani, 
2004. Automatic TIMEX2 Tagging of Korean News. 
In Proceedings of ACM Transactions on Asian Lan-
guage Information Processing. Vol. 3, No. 1, Pages 
51-65. 
Kim, Jae-Hoon and Seo, Jung-yeon. 1994. ms. A Korean 
Part-of-Speech Tag Set for Natural Language Process-
ing Version 1.0. KAIST. Seoul, Korea. 
Kiyong, Lee, 2008. Formal Semantics for Temporal An-
notation, An invited plenary lecture for CIL 18. In Pro-
ceedings of the 18th International Congress of Linguists, 
CIL 18, Seoul, Korea. 
Inderjeet Mani and George Wilson. 2000. Processing of 
News. In Proceedings of the 28th Annual Meeting of the 
Association for Computational Linguistics (ACL 2000), 
Pages 69-76. 
Nam, Ki-Shim and Yong-Kun Ko, 2005. Korean Gram-
mar (phyojwun kwuke mwunpeplon). Top Publisher. 
Seoul, Korea 
Pustejovsky, J., M. Verhagen, X. Nianwen, R. Gaizauskas, 
M. Happle, F. Shilder, G. Katz, R. Saur?, E. Saquete, T. 
Caselli, N. Calzolari, K.-Y. Lee, and S.-H. Im. 2008. 
TempEval2: Evaluating Events Time Expressions and 
Temporal Relations: SemEval Task Proposal.  
James Pustejovsky, Jessica Littman, Roser Saur?, Marc 
Verhagen. 2006. TimeBank 1.2. Documentation.  
James Pustejovsky, Jos? Casta?o, Robert Ingria, Roser 
Saur?, Robert Gaizauskas, Andrea Setzer, and Graham 
Katz. 2003. TimeML: Robust Specification of Event 
and Temporal Expressions in Text. IWCS-5. Fifth In-
ternational Workshop on Computational Semantics.  
 Roser Saur?, Jessica Littman, Bob Knippen, Robert Gai-
zauskas, Andrea Setzer, and James Pustejovsky. 2006a. 
TimeML Annotation Guidelines Version 1.2.1.  
Roser Saur?, Marc Verhagen, and James Pustejovsky. 
2006b. SlinkET: A Partial Modal Parser for Events. In 
Proceedings of LREC 2006. Genova, Italy.  
Roser Saur?, Robert Knippen, Marc Verhagen and James 
Pustejovsky. 2005. Evita: A Robust Event Recognizer 
for QA Systems. In Proceedings of HLT/EMNLP 2005, 
Pages 700-707.  
Sohn, Ho-Min. 1999. The Korean Language. Cambridge 
University Press. 
Marc Verhagen and James Pustejovsky. 2008. Temporal 
Processing with the TARSQI Toolkit. In proceedings 
Coling 2008: Companion volume - Posters and Dem-
onstrations, Pages 189-192. 
122
Coling 2010: Poster Volume, pages 498?506,
Beijing, August 2010
s???????Tz???????Gz????????Gh???????G??Gt??????????????G
y???Gs????????G
Hayeon Jang 
Dept. of Linguistics 
Seoul National University 
hyan05@snu.ac.kr
Hyopil Shin 
Dept. of Linguistics 
Seoul National University 
hpshin@snu.ac.kr
Abstract
In this paper, we propose language-
specific methods of sentiment analysis in 
morphologically rich languages. In con-
trast of previous works confined to statis-
tical methods, we make use of various 
linguistic features effectively. In particu-
lar, we make chunk structures by using 
the dependence relations of morpheme 
sequences to restrain semantic scope of 
influence of opinionated terms. In con-
clusion, our linguistic structural methods 
using chunking improve the results of 
sentiment analysis in Korean news cor-
pus. This approach will aid sentiment 
analysis of other morphologically rich 
languages like Japanese and Turkish. 
1 Introduction 
The Internet is a global forum where citizens of 
the world gather to express their opinions. On-
line services exist for users to share their person-
al thoughts while the use of blogs and Twitter 
substitutes for private diaries. For this reason, 
sentiment analysis which automatically extracts 
and analyzes the subjectivities and sentiments 
(or polarities) in written texts has recently been 
receiving attention in the field of NLP. 
Sentiment analysis of English employs vari-
ous statistical and linguistic methods referencing 
such linguistic resources as The Berkeley Parser 
and SentiWordNet. In the case of Korean, how-
ever, most previous works have been confined to 
statistical methods which focus either on the fre-
quency of words or relevance of co-occurring 
words only. This is because it is hard to find 
proper resources due to the nature of Korean, 
exhibiting such features as rich functional mor-
phemes, a relatively free word-order and fre-
quent deletion of primary elements of sentences 
like the subject and object. The major drawbacks 
of statistical-based approaches are the facts that 
the ?real? meaning of the expressions which we 
feel when we read them cannot be reflected in 
the analysis, and that complex statistical measur-
ing methods are computationally taxing. 
In this paper, in order to overcome previous 
shortcomings, while making use of Korean case 
studies we propose a new approach for morpho-
logically rich languages that makes effective use 
of linguistic information such as the semantic 
classes of words, semantic scope of negation 
terms like not, no, and the functional meaning of 
modal affixes. Especially, this approach makes 
chunk structures by using dependency relation of 
morpheme sequences to limit the semantic scope 
of influence of opinionated terms. This chunking 
method is simpler and more efficient than total 
syntactic parsing. In addition, we utilize subjec-
tivity clues and contextual shifters whose effec-
tiveness is established in previous references. 
The contents of this paper are as follows: 
firstly, we review previous works related to our 
approaches. We follow up by introducing the 
framework and main processes of our approach 
are introduced. Finally, we describe our experi-
ments and show how a linguistic approach is 
feasible in sentiment analysis of Korean as a 
morphologically rich language. 
2 Related Work
Sentiment analysis research has been performed 
to distinguish the authors? polarity (sentiment 
orientation) on certain topics from document-
level (Turney, 2002: Pang et al, 2002; Dave et 
al., 2003) to sentence-level (Hu and Liu, 2004; 
498
Kim and Hovy, 2004).  We will focus on sen-
tence-level sentiment classification with our pre-
supposition that the polarity of sentences in a 
single document can be diversified due to the 
inclusion of various subtopics. 
 Recently, much research has focused on sub-
jectivity1 extraction that divides objective facts 
from subjective opinions in data. Pang and Ri-
loff (2005) and Yu and Hatzivassiloglou (2003) 
trained sentence-level subjectivity classifiers and 
proved that performing sentiment analysis tar-
geting selected subjective sentences only gets 
higher results. We adopt a method of Wiebe and 
Riloff (2005)?s methods which classifies sen-
tences containing more than two lexical items 
associated with subjectivity and compare the 
result of the experiments on full and extracted 
subjective corpora. 
The core of the proposed new approach is the 
use of structural information in morphologically 
rich languages in the process of sentiment analy-
sis. Choi et al (2005) and Mao and Leba-
non(2006) are representative of the structured 
sentiment analysis approach which takes advan-
tage of Conditional Random Fields (CRF) to 
determine sentiment flow. McDonald et al 
(2007) also dealt with sentiment analysis, via the 
global joint-structural approach. Furthermore, 
since there are a lot of good parsers for English 
data, Meena and Prabhakr (2007) and Liu and 
Seneff (2009) utilized sentiment structure infor-
mation by such parsers such as Berkeley Parser.  
1 The term ?subjectivity? is equivalent to Quick et al 
(1985)?s private state which was defined as the words and 
phrases expressing individual mental and emotional states. 
In the case of Korean, much research applies 
dependency grammars for reducing the complex-
ity of sentences to match the characteristics of 
Korean (Kim and Lee, 2005; Nam et al, 2008) 
but this still causes problems which prohibit 
wide use. Therefore we suggest a new morpho-
logical chunking method that binds semantically 
related concatenations of morphemes. This helps 
to define boundaries of semantic scopes of opi-
nionated terms and is faster, simpler and more 
efficient on sentiment analysis than a general full 
parser. 
 Our approach focuses on the role of contex-
tual shifters as well. In this paper, the term ?con-
textual shifter? covers both negation shifters and 
flow shifters: the former refers to the terms 
which can change semantic orientation of other 
terms from positive to negative and vise versa, 
the latter the terms which can control sentiment 
flow in sentences, for example, in English not,
nobody (negation shifters), however, but (flow 
shifters). Kennedy and Inkpen (2006) did senti-
ment analysis of movie and product reviews by 
utilizing the contextual shifter information. 
Miyoshi and Nakagami (2007) also used this 
method to see the advancement of the result on 
sentimental analysis of electric product reviews 
in Japanese. In this work, we make use of the 
functions of each shifter to properly modify the 
value of the terms in the sentences and limit the 
number of the features which have to be ob-
served in the analysis process to increase effi-
ciency. 
Figure 1. Sentiment Analysis Framework 
499
3 Sentiment Analysis Framework 
The process of sentiment analysis in this paper is 
described in Figure 1. In this section, we explain 
each step of the process in detail. 
3.1 Morphological Analysis 
Korean is an agglutinative language where roots 
and affixes which have their own functional 
meaning combine to form complete words. Con-
sequently, sufficient morphological analysis is 
very important to catch the precise and deep 
meaning of such expressions. If a certain sen-
tence is misunderstood by wrong morphological 
analysis, there will be a strong possibility that 
opinionated terms in the sentence cannot be cor-
rectly analyzed.  
We used the KTS 2  which is open-source 
probability based Korean morphological analyz-
er. Although the probabilistic rules established in 
KTS are elaborate, the main source of inaccura-
cy is rooted in the inadequacy of the lexicon. 
After categorizing all listed words in the sen-
tence, the remaining words are mostly classified 
as general nouns. In this case, the terms which 
should play a role as important features in the 
process of sentiment analysis will be probably 
misunderstood. 
(1) ?? ??? ??
nemu cinpuha-n nayyong
    too  stale-AD3  content 
?too stale contents? 
(2) ??/a   ??/ncs  ?/xpa
nemu/a4 cinpu/ncs ha/xpa 
?/exm ??/nc
n/exm nayyong/nc
(3) ?/npp ??/nc ?/nc
ne/npp mucin/nc pu/nc 
?/nc ??/nc
han/nc nayyong/nc 
2 http://kldp.net/projects/kts/ 
3 Abbrebiates: AD(adnominal suffix), NM(nominative  
particle), IN(instrumental particle), SC(subordinative  
conjuctive suffix), CP(conjunctive particle), PST(past  
tense suffix), DC(declarative final suffix), RE(retrospect- 
ive suffix), CN(conjectural suffix), PR(pronoun), PP(pr- 
opositive suffix), AC(auxiliary conjunctive suffix), GE 
(genitive particle) 
4 POS tags of KTS: a(adverb), ncs(stative common noun),  
xpa(adjective-derived suffix), exm(adnominal suffix),nc 
(common noun), npp(personal pronoun) 
?you Mujin(place name) 
wealth resentment con-
tents?
For example, if sentence (1) which has to be 
analyzed as in (2) is incorrectly analyzed as in 
(3). This fault result ignores original spacing and 
randomly conjoins syllables in order to find the 
lexical items included in the dictionary because 
of the lack of lexicon. As the result, we cannot 
grasp the intended sentiment cinbu ?stale? in re-
spect to the object nayyong ?contents? in the sen-
tence. In order to solve such problems, we ex-
panded the lexicon of KTS by adding 53,800 
lexical items which are included in the Sejong5
dictionary. 
3.2 Subjectivity and Polarity Tagging 
News corpora have no marks representing polar-
ity of sentences as exist in the grading systems 
found in movie review corpora. In addition news 
data contain relatively more objective sentences 
which corpora tend to refer to as facts, as com-
pared with reviews. Therefore in the case of 
news corpora there is a need to process the anno-
tation of subjectivity and polarity tags for each 
sentence manually. 
In our work, two native Korean annotators 
manually attached polarity labels to each sen-
tence. Sentences are classified as subjective 
when they contain opinions pertaining to a cer-
tain object. Even if the opinion is not expressed 
on the surface using direct sentiment terms, the 
sentences are classified as subjective when the 
annotator can feel the subjectivity through the 
tone of voice. In the case of sentences containing 
common sense polarity value words such as do-
nation, murder, etc, terms do not work as the 
judgment criterion, rather the annotator?s judg-
ment about the main theme of the sentence is 
applied. Only when the sentences are classified 
as subjective, the polarity tags are attached. The 
agreement rate of the two annotators in the ma-
nual annotation of polarity is 71%. 
5 The 21 st century Sejong Project is one of the Korean in-
formation policies run by the Ministry of Culture and 
Tourism of Korea. The project was named after King Se-
jong the Great who invented Hangeul. 
(http://www.sejong.or.kr/) 
500
3.3 Subjectivity Extraction 
The subjective lexicon used in subjectivity ex-
traction contains 2,469 lexical items which in-
cludes 1,851 nouns, 201 verbs, 247 adjectives, 
124 adverbs, 44 suffixes, and 2 conjunctive par-
ticles. The lemmas of Sejong dictionary are clas-
sified by a total of 581 semantic classes. Among 
them are 23 subjectivity-related semantic classes 
which include Abusive Language, External 
Mental State, Internal Mental State etc. Firstly, 
we have registered those lexical items ?nouns, 
adjectives, verbs- under subjectivity-related se-
mantic classes. Since they will be compared with 
morphologically analyzed data before subjectivi-
ty classification, all items were registered as 
tagged forms. Nouns took the biggest portion in 
the lexicon through this process, since adjectives 
and verbs which consist respectively of stative 
nouns (ncs) and active nouns (nca) plus derived 
suffixes (xpa, xpv) were all registered as nouns. 
In Korean, sentiment can also be judged from 
particles and affixes having modal meaning.  
(4)??? ????? ????
3??? ???.
jengpwu-ka mwuungtap-ulo
tayungha-nci 3il-ina   cina-
ss-ta.
Government-NM no response-IN 
action-SC    3days-CP  pass-
PST-DC
?It already passed 3 days af-
ter government did not re-
sponse?
(5) ? ??? ? ?????
?????.
ku paywu-ka an-nao-ass-te-
lamyen coh-ass-ltheyntey
   the actor-NM not-star-PST-
RE-if nice-PST-CN 
  ?It were nice, if the actor 
would not have starred the 
main character? 
(6) ?? ?? ?????.
ku-ke   cengmal masiss-ess-
keyss-ta
that-PR  really delicious-
PST-CN-DC
?That must have been really 
delicious?
For example, conjunctive particle -(i)na in the 
sentence (4), final suffix -ltheyntey in (5), and
pre-final suffix -keyss in (6) are very influential 
in judging the subjectivity of sentences. There-
fore, we added those functional terms in the sub-
jective lexicon. 
We classified the sentences which contains 
more than two subjective items as subjective. 
When the sentence contained less than five mor-
phemes, however, we manage to judge the sen-
tence as subjective even when only one subjec-
tive item shows. The result of subjectivity ex-
traction is confirmed by the widely used statis-
tical method, TFIDF, in the following section. 
3.4 Term Weighting 
In our process of sentiment analysis, every term 
gets its own values by using polarity dictionaries 
and contextual shifters. In this section we intro-
duce our polarity dictionary and contextual shif-
Label Number of items Lexical items 
Positive 2,285 (1838 nouns, 133 verbs , 314 ad-
jectives)
Coh/pa ?good?, kelcak/nc ?masterpiece?,
chincel/ncs ?kind?
Negative 2,964 (2300 nouns, 359 verbs , 305 ad-
jective)
Nappu/pa ?bad?, ssuleki/nc ?trash?, 
koylophi/pv ?harass? 
Cynical 21 (adverbs) celday/a ?Never?, kyeu/a ?barely?
Intensifier 91 (80 adverbs, 10 nouns, 1 interjections)
acu/a ?very?, hancung/a ?more?,
tanyeonkho/a ?decisively?
Conjectural 19 (13 final suffixes, 4 pre-final suffixes, 
2 adnominal suffixes)
keyss/efp  CN, lthenteyo/ef CN,
l/exm CN
Obligative 6 (4 final suffixes,  2 auxiliary conjunc-
tive suffixes)
eya/ecx ?must?, eyacyo/ef PP
Quotative 5 (final suffixes) ntanunkun/ef  DC, tayyo/ef DC 
Table 1. Polarity Dictionary 
501
ters, and their lexical items. Also, the term- 
weighting methods of our approach is described. 
Polarity dictionary:  Table 1 shows our po-
larity dictionary used in sentiment classification. 
In the same way as a subjective lexicon, all lexi-
cal items are registered in the shape of a tagged 
morpheme. In addition, every item has labels 
with its own functional categories.  
First, Positive and Negative refer to the basic 
polarity value of individual terms of sentences. 
The terms that are neither positive nor negative 
are classified as neutral. We registered nouns, 
adjectives and verbs included in Sejong dictio-
nary?s semantic class related with emotion or 
evaluation such as Positive Property Human, 
Negative Property Human, etc. After that, we 
selected the terms that are generally used to ex-
press polarity from other review corpora and 
added them to the dictionary. Since we deal with 
on-line texts, we also added acronyms, neolog-
isms and new words which are frequently used 
to express opinion online. 
Next we add various functional lexical items 
that are from other parts of speech to the polarity 
dictionary. Cynical items play a role of adding 
negative nuance to sentences. Intensifiers em-
phasize the meaning of following expressions. 
Conjectural, Obligative and Quotative items re-
fer to something other than the author?s opinion. 
Conjectural and Obligative means that the opi-
nion included in the expressions is not actual but 
hypothetical. Quotative means that opinionated 
terms which are in same phrase express another 
person?s opinions. 
To determine the value of the terms, our ap-
proach uses a very simple measuring method. 
Every term initially gets +1 if Positive, -1 if 
Negative. All other words receive a value of 0. 
In the next step, the contexts of the sentences are 
examined and the values are modified. In the 
case of simple classification which does not go 
through the chunking process, we consider the 
distance of content words in Korean sentences 
which have various auxiliaries and affixes, and 
set a [-2, +2] window. In the case of structural 
classification, we take advantage of structures 
made by chunking. If Positives and Negatives 
are neighboring, we modify the values of the 
terms to reflect the fact that they influence each 
other. When Cynical items appear with Positives, 
we multiply by -1 to the value of Positives. 
When Cynicals appear with Negative items, we 
intensify the value of Negative by multiplying 
by 2. If Cynicals appear with neutral terms, we 
change the value of neutral terms to -1. The val-
ue of the terms which are affected by the Inten-
sifier doubles, whereas the values of the terms 
which are in the scope of Conjectural, Obligative 
and Quotative items are reduced to half. In this 
way we control the importance of the terms in 
the sentence. 
Contextual Shifters: contextual shifters in 
Korean consist of 13 negation shifters (adverbs 
such as an/a ?not?, mos/a ?cannot? and  auxiliary 
verbs such as anh/px ?not?, mal/px ?stop?) and 23 
flow shifters (sentence-conjunctive adverbs such 
as kulena/ajs, haciman/ajs ?but, though?, subor-
dinative conjuctive suffixes pnitaman/ecs, 
ntey/ecs CN and conjunctive suffixes such as 
eto/ecx AC).
Since negation shifters play the role of shift-
ing the polarity of the sentiment terms in our 
approach, we multiply them by -1. In the case of 
flow shifters, we limit the number of features to 
the terms after the shifter appears. We deemed it 
more important to understand an author?s empa-
thetic point, rather than to catch full sentiment 
flow in the sentences. Also such emphasized 
contents mostly exist after the flow shifters. 
Therefore we utilize this characteristic to reduce 
the work load and to prevent confusions which 
are caused by other minor sentiment terms.  
(7) ??? ?? ??? ????
???? ????.
umak-to  coh-ko yengsang-to 
coh-ass-nuntey sutholi-ka 
pyello-yess-ta
music-also good-CN image-
also good-CN story-NM not 
so good-PST-DC 
  ?music was good and image al-
so good though, story is
not so good,? 
For example, in the sentence (7) -nuntey func-
tions as a flow shifter. Dealing with the words 
after ?nuntey, we can limit the object mor-
phemes to 5 out of 14. Therefore, measuring 
load is significantly reduced, and furthermore, 
we can prevent the confusion from two positive 
terms coh ?good? before the flow shifter.  
502
3.5 Chunking using morphological depen-
dency relation 
In our approach, instead of complete syntactic 
parsing we use a chunking method based on the 
dependency relation of morpheme sequences in 
terms of the provision that it is important to limit 
the semantic influential scopes of main opinio-
nated expressions. 
Korean is a head-final language: in terms of 
dependency grammar, governors are always lo-
cated after their dependents. We reflect upon this 
characteristic to form a relation if a certain mor-
pheme acts as the governor of a previous mor-
pheme. Chunks (small and mid nodes shown in 
figure 2.) are formed until an unrelated mor-
pheme appears. The terms in a single chunk ex-
ert great semantic influence to control the value 
of each other. After determining the values of 
every morpheme in each chunk, this process is 
replicated at a higher level and finally the ulti-
mate values of every term in the sentence are 
determined. 
For example in Figure 2, the structure 
[[chen+nyen]+uy] [seywel+i] [hulu+eto] 
[kkuthna+ci+anh+nun] [miwan+uy] [sarang]
is the result of the chunking process of the sen-
tence chen-nyen-uy seywel-i hulu-eto kkuthna-ci 
anh-nun miwan-uy salang 1000-year-GE time-
NM flow-CN finish-CN not-AD incomplete-GE 
love ?an incomplete love that has not finished 
even after 1000 years?. If we focus on the terms 
after the flow shifter -eto, the negation shifter 
anh ?not? in the first phrase only influences the 
verb kkuthna- ?finish? in the same chunk. This 
limitation of semantic scope of the negation shif-
ter eliminates the possibility that it excessively 
modifies the values of other unrelated elements. 
Since the simple classification has a [-2, +2] 
window, miwan ?incomplete? is also influenced 
by -anh. Then the value of miwan becomes +1 
which is classified as a positive term, and the 
whole expression miwan-uy salang ?an incom-
plete love? is misclassified as positive. 
4 Experiment
4.1 Corpora
Since movie review data is commonly used for 
sentiment analysis, we primarily collected movie 
reviews. Following the comments of many pre-
vious works that it is hard to separate the sen-
tences which mention the plot of movies from 
opinion sentences, especially short movie re-
views which containing 1~2 sentences delibe-
rately selected. The reason is that short reviews 
having limited space probably include opinions 
only. Movie review data of less than 20 charac-
ters was crawled from a representative movie 
site in Korea, Cine216. It contains 185,405 re-
views ranging from December 31, 2003 to De-
cember 28, 2009 (total 19.5MB). 
Next, we collected 79,390 news articles from 
January 1, 2009 to April 7, 2010 (total 
146.6MB) from the web site of the daily news-
paper, The Hankyoreh7. The news data includes 
both objective and subjective sentences, and is 
categorized into 3 groups by the following cha-
racteristics: 71,612 general news articles, 3,743 
opinionated news articles having subjective sub-
topics such as ?Yuna Kim, terrorism, etc.? and 
3,432 editorial articles including columns and 
contributions. After randomly extracting 100 
articles from each data group a Korean annotator 
attached subjectivity and polarity labels to each 
6 http://www.cine21.com/ 
7 http://www.hani.co.kr/ 
Figure 2. Chunking structure of the below sentence. (A short movie reviews) 
???????????????????
 chen-nyen-uy seywel-i hulu-eto kkuthna-ci anh-nun miwan-uy salang
1000-year-GE time-NM flow-CN finish-CN not-AD incomplete-GE love 
?an incomplete love that has not finished even after 1000 years?
503
sentence. The collection of sample sentences 
consists of 1,225 general news sentences, 1,185 
subtopic news sentences and 2,592 sentences of 
editorial articles. 
4.2 Experiment 1: Short Movie Reviews 
 Table 2 shows the result of a 5-fold cross varia-
tion experiment on the sentiment analysis of 
short movie review data using SVMlight. The 
numbers in bold face are the values being larger 
than the baseline, the results using TFIDF. A 
subjectivity extraction experiment was not car-
ried out because of the presumption that all mov-
ie reviews used in this work are subjective.  
(There were a few reviews containing quotes 
from the movies or meaningless words only. 
Such cases, however, were ignored.)  In the case 
of movie review data, selected subjective data is 
regarded as having stronger subjectivity. 
When subjective data is compared with total 
data by the same experimental methods, there 
are consistent improvements in sentiment analy-
sis for the subjective data. It is no surprise that 
the sentences that contain a more intense level of 
subjectivity can be easily classified as correct 
polarity. 
In addition, contrary to our expectations, the 
application of the simple classification method 
(NO chunking) gets the higher results in compar-
ison with the structural classification method 
(YES chunking) regardless of the use of contex-
8 F-measure = 2*precision*recall/(precision+recall) 
tual shifters. This phenomenon can be analyzed 
based on the limited length of reviews and the 
characteristics of online data. First, most sen-
tences have a simple structure like the sequence 
of nouns or noun phrases due to restricted writ-
ing space. For this reason, the effect of chunking 
and contextual shifters on sentiment classifica-
tion is insignificant. Second, the data includes 
various terms only seen on the Internet, vulgar-
isms and ungrammatical words. Furthermore, 
there are the problems of word spacing and spel-
ling. Because of these drawbacks of online data, 
morphological analysis errors frequently oc-
curred. The errors are further propagated to 
structures as a result of chunking. For this reason, 
when the chunking method is used, contextual 
shifters are ineffective at all as shown the results 
using the chunking method in Table 1. 
4.3 Experiment 2: News articles 
Subjectivity Extraction: The results of a 5-fold 
cross variation experiment of subjectivity extrac-
tion using SVMlight are described in Table 3. In 
this experiment, we use the commonly used sta-
tistical method TFIDF to compare total data with 
subjective data in the three groups in the subjec-
tivity classification task. In conclusion, the cho-
sen subjective data of all groups get higher re-
sults. Especially in the cases of news articles and 
subtopic news articles which are less subjective 
than editorial articles, F-measure value is greatly 
increased. 
Table 2. Sentiment analysis of short movie review corpora 
Method 
total subjective 
Accuracy (%) F-measure8 (%) Accuracy F-measure
TFIDF 87.67 93.431 90.02 94.748 
NO chunking NO shifter 87.676 93.432 90.034 94.757 
NO chunking YES shifters 87.674 93.433 90.018 94.745 
YES chunking NO shifter 83.212 90.835 87.29 93.214 
YES chunking YES shifters 83.212 90.835 87.29 93.214 
Method Data Accuracy (%) F-measure (%) 
TFIDF
News articles 
Total 63.032 28.532 
Subjective 82.00 89.919 
Subtopic News 
articles
Total 61.95 32.287 
Subjective 73.332 84.44 
Editorial articles
Total 57.53 73.04 
Subjective 87.23 93.18 
Table 3. Subjectivity extraction of news corpora 
504
Sentiment Analysis: The results of sentiment 
analysis on the three groups of news data are 
summarized in Figure 3. The white points in 
Figure 3 are the values being larger than the 
baseline, the results using TFIDF. 
First of all, all of our proposed classification 
methods get higher results than TFIDF, except in 
the case of F-measure of subjective News data. 
This shows that using language-specific features 
which inflect the target language?s linguistic 
characteristics well, without complex mathemat-
ical measuring techniques, we could get better 
results than statistical methods in sentiment clas-
sification.
Secondly, similar to the result of movie re-
view corpora, mostly subjective data shows 
greatly improved results in experimental me-
thods overall. This means that our subjectivity 
extraction works successfully. 
Finally, in contrast to the results of experi-
ment 1, we get higher values of sentiment classi-
fication by using chunking and contextual shif-
ters. This implies that the restriction on semantic 
scope of opinionated terms and the methods re-
ducing features and properly modifying values 
of polarity terms by using contextual shifters 
also have merits in sentiment analysis of data 
such as news which has complex sentence struc-
ture like news. Furthermore, this tendency is no-
ticeable particularly in the subjective data of all 
three groups. This confirms the effectiveness of 
utilizing linguistic methods in subjectivity ex-
traction and sentiment analysis for news data 
which tries to maintain objectivity. 
5 Discussion and Further Work 
In this paper, we verified that simple measure-
ments utilizing language-specific features can 
improve the results of sentiment analysis. Partic-
ularly the chunking method using morphological 
dependency relations and the lexicon which con-
tains suffixes and particles having important 
functional meanings is expected to aid the sen-
timent analysis of other agglutinative languages 
such as Turkish and Japanese. In addition, this 
approach of sentiment analysis can be applied to 
various applications for extracting important in-
formation on the Internet to monitor a certain 
brand?s reputations or to make social network for 
peoples who have similar opinions. 
We have plans to confirm the results of this 
paper by experiments on corpora which are ex-
panded in size and type in future work. We will 
also increase the number of lexical items of sub-
jectivity lexicon and polarity dictionary. Fur-
thermore, we will utilize other linguistic infor-
mation such as synonym lists of Korean ontolo-
gy and elaborate measuring methods using lin-
guistic-specific features of morphologically rich 
languages effectively. 
Figure 3. Sentiment analysis of  news corpora 
505
References 
Choi, Y., C. Cardie, E. Riloff, and S. Patwardhan. 
2005. Identifying sources of opinions with condi-
tional random fields and extraction patterns. In 
Proceedings of the HLT/EMNLP.
Dave, K., S. Lawrence, and D. M. Pennock. 2003. 
Mining the peanut gallery: Opinion extraction and 
semantic classification of product reviews. In Pro-
ceedings of the WWW-2003.
Hu, Minqing, and Bing Liu. 2004. Mining and sum-
marizingcustomer reviews. In Proceedings of the 
KDD.
Kennedy, A., and D. Inkpen. 2006. Sentiment Classi-
fication of Movie and Product Reviews Using 
Contextual Valence Shifters. Computational Intel-
ligence, 22(2):110?125. 
Kim, Mi-Yong, and Jong-Hyeok Lee. 2005. Syntactic 
Analysis based on Subject-Clause Segmentation. 
In Proceedings of the KCC 2005, 32(9):936-947. 
In Korean. 
Kim, S. M., and E. Hovy. 2004. Determining the sen-
timent of opinions. In Preceeding of the COLING.
Liu, Jingjing, and Stephanie Seneff. 2009. Review 
sentiment scoring via a parse-and-paraphrase para-
digm. In Proceedings of the 2009 Conference on 
Empirical Methods in Natural Language 
Processing, 1(1). 
Mao, Y., and G. Lebanon. 2006. Isotonic conditional 
random fields and local sentiment flow. In Pro-
ceedings of the NIPS.
McDonald, R., K. Hannan, T. Neylon, M. Wells, and 
J. Reynar. 2007. Structured Models for Fine-to-
Coarse Sentiment Analysis. In Proceedings of the 
45th Annual Meeting of the Association of Compu-
tational Linguistics, 432?439. 
Meena, Arun, and T. V. Prabhakar. 2007. Sentence 
Level Sentiment Analysis in the Presence of Con-
juncts Using Linguistic Analysis. Lecture Notes in 
Computer Science, 573-580. Springer. 
Nam, Sang-Hyub, Seung-Hoon Na, Yeha Lee, Yong-
Hun Lee, Jungi Kim, and Jong-Hyeok Lee. 2008. 
Semi-Supeervised Learning for Sentiment Phrase 
Extraction by Combining Generative Model and 
Discriminative Model. In Proceedings of the 
KCC(Korea Computer Congress) 2008, 35(1):268-
273. in Korean. 
Pang, Bo, Lillian Lee, and Shivakumar Vaithyana-
than. 2002. Thumbs up? Sentiment classification 
using machine learning techniques. In Proceedings 
of the ACL-2002 conference on Empirical methods 
in natural language processing, 10. 
Pang, Bo, and Lillian Lee.  2004. A sentimental edu-
cation: Sentiment analysis using subjectivity sum-
marization based on minimum cuts. In Proceed-
ings of the ACL-2004.
Polanyi, Livia, and Annie Zaenen. 2004. Contextual 
valence shifters. In Proceedings of the AAAI Sym-
posium on Exploring Attitude and Affect in Text: 
Theories and Applications.
Ptaszynski, Michal, Pawel Dybala, Wenhan 
Shi, Rafal Rzepka, and Kenji Araki. 2010. Contex-
tual affect analysis: a system for verification of 
emotion appropriateness supported with Contex-
tual Valence Shifters. International Journal of 
Biometrics, 2(2):134-154. 
Quirk, R., S. Greenbaum, G. Leech, and J. Svartvik. 
1985. A Comprehensive Grammar of the English 
Language. Longman, New York. 
Riloff, Ellen, and Janyce Wiebe. 2003. Learning ex-
traction patterns for subjective expressions. In 
Proceedings of the 2003 Conference on Empirical 
Methods in Natural Language Processing, 105-
112. 
Tetsuya, Miyoshi, and Nakagami Yu. 2007. Senti-
ment classification of customer reviews on electric 
products. In Proceeding of the IEEE International 
Conference on Systems Man and Cybernetics,
2028-2033. 
Turney, P. D. 2002. Thumbs up or thumbs down? 
Semantic orientation applied to unsupervised clas-
sification of reviews. In Proceedings of the 40th 
Annual Meeting of the Association for Computa-
tional Linguistics (ACL'02), 417-424. 
Wiebe, Janyce, Theresa Wilson, Rebecca Bruce, Mat-
thew Bell, and Melanie Martin. 2004. Learning 
subjective language. Computational Linguistics,
30(3). 
Wiebe, Janyce, and E. Riloff. 2005. Creating subjec-
tive and objective sentence classifiers from unan-
notated texts. In Proceedings of the CICLing 2005,
486-497. 
Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann. 
2005. Recognizing Contextual Polarity in Phrase-
Level Sentiment Analysis. In Proceedings of the 
HLT/EMNLP, 347-354. 
Yu, H., and Hatzivassiloglou V. 2003. Towards ans-
wering opinion questions: Separating facts from 
opinions and identifying the polarity of opinion 
sentences. In Proceedings of EMNLP, 32.
506
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 58?68, Dublin, Ireland, August 23-29 2014.
Identification of Implicit Topics in Twitter Data Not Containing Explicit
Search Queries
Suzi Park Hyopil Shin
Department of Linguistics, Seoul National University
1 Gwanak-ro, Gwanak-gu, Seoul, 151-745, Republic of Korea
{mam3b,hpshin}@snu.ac.kr
Abstract
This study aims at retrieving tweets with an implicit topic, which cannot be identified by the
current query-matching system employed by Twitter. Such tweets are relevant to a given query
but do not explicitly contain the term. When these tweets are combined with a relevant tweet
containing the overt keyword, the ?serialized? tweets can be integrated into the same discourse
context. To this end, features like reply relation, authorship, temporal proximity, continuation
markers, and discourse markers were used to build models for detecting serialization. According
to our experiments, each one of the suggested serializing methods achieves higher means of
average precision rates than baselines such as the query matching model and the tf-idf weighting
model, which indicates that considering an individual tweet within a discourse context is helpful
in judging its relevance to a given topic.
1 Introduction
1.1 Limits of the Twitter Query-Matching Search
Twitter search was not a very crucial thing in the past (Stone, 2009a), at least for users in its early
stages who read and wrote tweets only within their curated timelines real-time (Dorsey, 2007; Stone,
2009b; Stone, 2009c). Users? personal interests became one of the motivations to explore a large body
of tweets only after commercial, political and academic demands, but it triggered the current extension
of the Twitter search service. The domain of Twitter search was widened, for example, from tweets in
the recent week to older ones (Burstein, 2013), and from accounts that have a specific term in their name
or username to those that are relevant to that particular subject (Stone, 2007; Stone, 2008; Twitter, 2011;
Kozak, Novermber 19, 2013). However, the standard Twitter search mechanism is based only on the
presence of query terms.
Even though the Twitter Search API provides many operators, the current query matching search does
not guarantee retrieving a complete list of all relevant tweets.
12
The 140-character limit sometimes forces
a tweet not to contain a term, not because of its lack of relevance to the topic represented by the term,
but due to one of the following:
Reduction the query term is written in an abbreviated form or in form of Internet slang,
Expansion the query term is in external text that can be expanded through other services such as Twit-
Longer (http://twitlonger.com) and twtkr (http://twtkr.olleh.com), while the
part exceeding 140 characters is shown only as a link on twitter.com, or
Serialization the query term is contained as an antecedent in some previous tweet.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
?[T]he Search API is focused on relevance and not completeness.? 2 October 2013. Using the Twitter Search API.
https://dev.twitter.com/docs/using-search
2
?[T]he Search API is not meant to be an exhaustive source of Tweets.? 7 March 2013. GET search/tweets https:
//dev.twitter.com/docs/api/1.1/get/search/tweets
58
If these cases are frequent enough, the current query matching search in Twitter will get a low recall rate.
Considering that tweets are usually used to obtain as various views on a topic as possible, in addition to
accurate and reliable information about it, this setback would block attempts to collect diverse opinions
in Twitter.
These three different cases require different approaches. First, reduction, one of the most significant
characteristics of Twitter data in natural language processing, can be solved by building a dictionary
of Internet slang terms or learning them. Second, in case of expansion tweets are always accompanied
with short URLs (http://tl.gd for TwitLonger and http://dw.am for twtkr) and the full text
is reachable through them. In these two cases, tweets correspond one-on-one with documents, whether
reduced internally or expanded externally. This study will focus on the third case, serialization, where
several tweets may be interpreted as a single document.
1.2 Serialization of Tweets: An Overlooked Aspect of Twitter
Though little reported before, serialization of tweets is frequently observed in Korean data.
3
Influential
users like famous journalists, columnists and critics as well as ordinary users often publish multiple
tweets over a short period of time instead of using other media such as blogs or web magazines. Types of
tweets published in this way by Korean users include reports, reviews, and analysis on political or social
affairs, news articles, books, films and dramas. The content users intend to express is longer than a tweet
but shorter than a typical blog post. Examples from our dataset will be introduced in Section 3.
This study aims at retrieving tweets on a topic, which cannot be found by the current query-matching
system. Such tweets are relevant to a given query but do not contain the necessary words. Under the
hypothesis that a considerable number of these tweets not containing the query term are serialized with
one containing it overtly, and that serialized segments are integrated into the same discourse context, we
built a model that allows us, when given a tweet that includes a query or a mentioned topic, to find the
other tweets serialized with it and count them as relevant to the topic. We primarily focused on Korean
Twitter data, but we believe that the methods developed here are also applicable to other languages with
similar phenomena.
2 Previous Studies
Our study is based on the observation that a tweet in a ?serialization? does not necessarily correspond
to a full document. In fact, it has already been reported (Hong and Davison, 2010; Weng et al., 2010;
Mehrotra et al., 2013) that a single tweet is too short to be treated as an individual document, especially
considering that word co-occurrence in a tweet is hardly found. Studies proved that performance of
Latent Dirichlet Allocation (LDA) models for Twitter topic discovery can be improved by aggregating
tweets into a document. In these studies, a ?document ? consists either of all tweets under the same
authorship (Hong and Davison, 2010; Weng et al., 2010), all tweets published in a particular period, or
all tweets sharing a hashtag (Mehrotra et al., 2013). These criteria are useful for finding topics, into
which tweets can be classified, but our purpose requires a different degree of ?documentness.? Our
study deals with a fixed topic and is interested in whether or not only tweets relevant to the topic can
be pooled. All tweets merged into the same document as constructed in the previous studies are not
necessarily coherent or related to the same topic because it is not usually expected that ordinary users
devote their Twitter accounts to a single topic. In this study, we will develop more detailed criteria for
the aggregation of tweets by combining authorship with time intervals and adopting features such as
sentiment consistency and discourse markers.
A method of using discourse markers for microblog data was proposed by Mukherjee and Bhat-
tacharyya (2012). They noted that a dependency parser, on which opinion analyses using discourse
information (Somasundaran, 2010) are usually based, is inadequate for small microblog data, and in-
stead used a ?lightweight? discourse analysis, considering the existence of a discourse marker on each
tweet. The list of discourse markers used in their study was based on the list of conjunctions repre-
senting discourse relations presented by Wolf et al. (2004). This method was successful for sentiment
3
Some Korean users sarcastically call this a ?saga? of tweets.
59
analysis on Twitter data assuming that the relevance of each tweet to a certain topic was already known.
We will take a similar approach of using discourse markers, but with a different assumption and for a
different purpose. In our study, we treat unknown topic relevance of tweets with missing query terms by
aggregating them with a topic-marked tweet using discourse markers.
3 Features
3.1 Properties of Tweet Serialization
Multiple tweets are likely to be consistent with a topic if they form a discourse as in the following
situations, with examples of tweets in Korean translated into English. In each tweet, topic words are in
boldface.
Conversation This is the most typical case.
U1: Wow the neighborhood theater is packed; will Snowpiercer hit ten million?
U2: @U1 My parents and my boss are all gonna watch, and they watch only one film a year. This
is the measure for ten million.
Comment after retweet Users retweet and comment.
U3 RT @U4: Today?s quote. ?It is stupid to concentrate on symbolic meaning in Wang Kar Wai?s
Happy Together. That would be like trying to find political messages and signs in Snow-
piercer.? ? Jung Sung-Il
U3 Master Jung?s sarcasm........?
On-the-spot addition Because a published tweet cannot be edited, users can elaborate or correct it only
by writing a new tweet or deleting the existing tweet.
U5 Is Curtis the epitome of Director Bong?s
4
sinserity
U5 Sincerity, shit
True (intentional) serialization Some users begin to write tweets with a text of more than 140 charac-
ters in mind. They arrive at the length limit and continue to write in a new tweet.
U6 (1) Watched Snowpiercer. It was more interesting than I thought. It felt more like black comedy
than SF. On another note, I was surprised by several oddities, making the film feel more like a
Korean film with foreign actors in it rather than Director Bong?s Hollywood debut.
U6 (2) In many ways the film was ?nineties?... like watching The City of Lost Children all over
again... and the trip from the tail-car to the first car, though I expected some kind of level-up
for each car,
U6 (3) the world connected car to car was not an organic world (a sideways pyramid?) but worlds
too separate car by car, and the front-car people were so lifeless that I was surprised. The scale
of the ?charge? after 17 years felt shrunken.
If this is a characteristic feature of Korean Twitter data, this may be due to reasons such as personal
writing style, the writing system of the Korean language, and Korean Web platforms. First, it may be
simply because these users prefer formal language and are reluctant to use short informal expressions
even in Web writing. Second, it is possibly because CJK writing systems including Hangul, the Korean
alphabet, have more information per character than the Roman alphabet (Neubig and Duh, 2013). Since
a 140-character text in Hangul has generally more information than that in the Roman alphabet, a Korean
(or Japanese) user can more readily tweet about content which an English (or other European) language
user would consider too long to write about on Twitter. Third, for many Korean users Twitter is the most
available medium for publishing their opinions online, as a number of standard blogs have been replaced
4
Director of the film Snowpiercer
60
by microblogs. Some users divide a long public text into multiple length-limited tweets simply because
they do not have a blog to write in.
While Internet slang and abbreviations are common in tweets, ?Serializers? tend to use 1) fully-
spelled forms (unlike ?reducers?), 2) usually without hashtags and emoticons, 3) which are all visible on
twitter.com itself (unlike ?expanders?), so it is not guaranteed that all serialized tweets will contain
the topic word, as in the examples above. This implies that some tweet segments in a single discourse
may not be retrieved even if the discourse is relevant to a given query. Search results may include a
partial document for which it is difficult the full version of which is difficult to find.
3.2 Extralinguistic Criteria
Two tweets are more likely to be a part of a larger document consisting of a series of tweets if
Reply-relation one of them is a reply to the other,
Temporal proximity they are published immediately one after the other, or
Continuation markers they share such markers as numbers, arrows>> and continuation marker ?(con-
tinued).?
Figure 1 shows examples of each case.
Figure 1: Serialized tweets with numbers, an arrow, or a continuation marker ?(continued)?
3.3 Linguistic Clues
Semantic similarity to the query In order to determine the relatedness of two documents, the similarity
between their term distributions is mainly considered. Based on this idea, one of our baseline
methods will represent each tweet as a bag-of-words vector and retrieve a tweet containing no
query term if its tf-idf weighted vector has a high cosine similarity with at least one vector from a
tweet containing a query term.
Discourse markers Users may add a discourse marker when writing a new sentence in a new tweet. If
a tweet begins with a marker that indicates continuation of a discourse, it is likely to be a part of a
larger document. A sentiment analysis in Twitter by Mukherjee and Bhattacharyya (2012) adopted
discourse relations from Wolf et al. (2004). In this paper, we use linguistic characteristics described
by Kang (1999) in order to classify Korean texts, listing their English translations in Table 1. The
discourse marker feature refers to whether or not any marker on the list occurs in the first N words
(set N = 5) of the tweet.
4 Experiments
4.1 Data
We collected 173,271 tweets posted or retweeted by 105 Korean users, including film critics, film stu-
dents, and amateur cinephiles from 27 July to 26 September 2013. Out of the 105 users, 17 users who
had mentioned the film Snowpiercer
5
most often were singled out. In addition, the highest overall oc-
currence of the keyword was found to be between 1 to 15 August, probably due the film?s release on 31
5
http://www.imdb.com/title/tt1706620/
61
Demonstratives this, that, it, here, there
Proverbs be so, do so
Discourse well, now
Conj-Reasoning because, so, therfore, thus, hence
Conj-Conditional then, as long as, in the case, under
Conj-Coordinate and, nor
Conj-Adversative but, yet, however, still, by contrast
Conj-Discourse meanwhile, anyway, by the way
Table 1: List of selected Korean discourse markers used for classifying text types in Kang (1999), trans-
lated into English
July in South Korea. Then we kept all 8,543 tweets posted by those 17 users from the period between 1
to 15 August 2013, in order to construct a labeled data set. This set includes 189 tweets that explicitly
contain the word Snowpiercer. Each tweet in the filtered set was labeled as related or not related to the
movie by three annotators who were Twitter users already following most of the above 17 users and thus
aware of the context of most tweets, and a tweet was considered relevant if two or more of the annota-
tors agreed. Inter-annotator agreement was evaluated by using Fleiss?s kappa statistic flei:71, which was
? = 0.749 (p ? 0). Table 2 shows the annotation results.
Related Not related Total
Explicit 173 15 188
Not explicit 207 8,148 8,355
Total 380 8,163 8,543
Table 2: The number of annotated tweets classified by explicitness and relatedness
Table 2 shows that 8163/8543 = 95.55% of the tweets in the dataset are not relevant to the movie
Snowpiercer. Additional topics are induced from 7?9 manually collected seed words among the 200
most frequently occurring nouns in the dataset, in which each tweet text was POS-tagged by the Korean
morphological and POS tagger Hannanum
6
. Induced topics and their seed words are listed in Table 3.
Topic Seed words
Movie Movie, Snowpiercer, director, The Terror Live, actor, stage, audience, film, theater
Literature Story, book, writing, author, novel, character, work
Gender/relationship Men, women, female, marriage, male, wife, lover
Politics Politics, state, Park Geun-hye, government, president, party, Ahn Cheol-soo
Table 3: Four topics from manually collected seed words
As described in 3.1, it should be noted again that hashtags are not always useful for finding information
in Korean tweets, particularly in this dataset. Among the seed words above, only Snowpiercer was ever
used as a hashtag, and happened only three times (twice in English and once in Korean). Only nine
types of hashtags occurred more than twice in the full dataset (they are presented in Table 4 with their
respective frequencies). This predicts that hashtag-based tweet aggregation would not be very useful to
find tweets relevant to Snowpiercer or one of the four induced topics.
Table 5 shows the number of tweets containing seed words for each topic, where a tweet is allowed to
belong to more than one topic. Since only 1853/8543 = 21.69% of the tweets explicitly contain a topic
or seed word, it is not plausible that each of the remaining 80% tweets belongs to one of the four topics.
Many of the tweets may be related to a topic which was of a too small portion to be induced, or to no
topic at all. So, instead of classifying all of the tweets into the given topics, the experiment seeks to
retrieve any tweet that is relevant to a certain topic, which allows each tweet to belong to more than one
topic at once. In every experiment we regarded tweets that contain a topic or seed word as relevant to the
topic, and restricted the test set to those tweets which did not contain them.
6
http://sourceforge.net/projects/hannanum/
62
#make people cry with a story of two words 13
#lgtwins 10
#quote 7
#changing zero0 to fatty makes things totally depressing 6
#EBSbookcafe 4
#today i feel 4
#blow the whistle on chun doo-hwan 3
#chosundotcom 3
#the name of your bias followed by the name of the food you just ate feels nice 3
Table 4: Korean hashtags occurring more than twice in the dataset, translated into English
Movie Literature Gender Politics Total
716 452 379 306 1853
Table 5: Number of tweets including at least one of the seed words for each induced topic
4.2 Measures
For all models, the authors judged the relevance of each of the retrieved tweets for induced topics until ten
relevant tweets were retrieved. In the Snowpiercer case, precision scores were calculated for all recall
scores. We built a ranking retrieval system for each model and evaluated its performance by average
precision. For models including a randomizing process, we used the mean of average precisions over
1,000 replicated samples. Precision was computed at every percentile of recall levels for Snowpiercer
case and after each retrieved relevant tweet (up to top 10) for induced topics. In sum, the performance of
a model m was defined in two ways as
meanAP@percent(m) :=
1
1000
1000
?
i=1
AP@percent(m
i
)
and
meanAP@10(m) :=
1
1000
1000
?
i=1
AP@10(m
i
)
, where m has 1,000 replicates m
1
, ? ? ?m
1000
whose measures are
AP@percent(m
i
) :=
1
100
100
?
j=1
prec@j%(m
i
)
and
AP@10(m
i
) :=
1
10
10
?
k=1
prec@k%(m
i
).
When m is a tf-idf model, which has a unique ranking without replication, average precision was used.
4.3 Baselines
Query matching method The most obvious baseline method for this study is the current Twitter search
system that treats topic words and seed words as queries and finds documents, or tweets, that are
relevant to the topic. Since only tweets not containing the query terms remained in the test set, there
are no tweets matching them. As the set of retrieved tweets is empty, relevance rank is randomly
assigned to each tweet of the test set.
Tf-idf weighting method One may predict that a tweet is likely to be relevant to a topic if it shows a
similar word distribution to some explicitly relevant tweets. Under this assumption, we represented
each tweet as a tf-idf weighted vector (Salton and Buckley, 1988) after removing all punctuation
marks and user-mention markers (@username). Stopwords were not removed and tf-idf values
were length-normalized. Relevance of each tweet in the test set was defined as the maximum of its
cosine-similarities with all tweets containing a query term.
63
4.4 Tweet Serialization
Examples of Tweet Serialization in Section 3 indicate clues between related tweets other than distribu-
tional similarity. When 1) a tweet is a reply to another one, 2) two tweets are written one after another
by the same user, 3) one tweet following another includes some discourse marker, or 4) two tweets share
a marker, such as numbers, they can be considered to be serialized into a single document rather than
being two separate ones. Tweets serialized together are treated as a single document, and if this docu-
ment contains a a tweet with a query term, then all tweets lacking it but belonging to the same the same
document are retrieved. All retrieved tweets are first ranked in random order, followed by the others also
in random order.
We suggest four criteria for Tweet Serialization:
Reply Two tweets are serialized if one is a reply to the other.
Continuation markers Two tweets are serialized if they are written successively by the same user and
share a marker, such as a number or a phrase ?(cont.)?
Discourse markers Two tweets are serialized if they are written successively by the same user, the latter
contains one of the discourse markers listed in Table 1 in its first 5 words, and neither of them is a
reply to another user.
Time Two tweets are serialized if they are written successively by the same user within a given interval
and neither of them is a reply to another user. The upper boundary for intervals is set in one of the
following ways:
Constant 30 or 60 seconds
User-specific Users may show different densities in their tweets, depending on their tweeting en-
vironment. Distribution of time intervals between successive tweets over users is presented
in Table 6. The smallest 5% and 15% quantiles were selected, corresponding to 30 and 60
seconds respectively.
Quantile U1 U2 U3 U4 U5 U6 U7 U8 U9 U10 U11 U12 U13 U14 U15 U16 U17
0% 3 19 2 1 1 5 10 3 2 3 9 3 2 3 3 2 16
5% 20 42 18 16 13 30 21 18 13 8 43 23 18 15 13 12 110
10% 33 45 25 35 20 43 38 38 28 13 71 35 28 35 21 21 130
15% 47 52 33 57 30 56 67 57 40 23 89 51 37 61 27 40 161
20% 62 67 41 79 41 73 92 74 53 31 111 65 50 84 33 58 197
25% 81 86 55 100 55 92 145 95 69 43 138 84 68 105 38 77 275
50% 237 298 164 322 151 242 1060 297 167 159 297 317 178 258 90 266 725
Table 6: Time intervals (in seconds) by cumulative percentile between consecutive pairs of tweets for
each user
For all criteria, Tweet Serialization is transitive, that is, if t
i
and t
j
are serialized and t
j
and t
k
are
serialized, then t
i
and t
k
are serialized. Table 7 shows the distribution of serialization sizes (number
of serialized tweets) over criteria. Time value of 60 seconds serializes most tweets, as many as (8543-
6464)/8543=24.33%, while continuation markers serialize only (8543-8511)/8543 = .37%. Assuming all
serializations are correct, the relevance of retrieved documents is judged.
4.5 Results
The average precision values of all models are summarized in Table 8 (means calculated over recall
levels) and Figure 2 (means calculated over 1,000 replications). In both Tables 8 and 9, differences
between the tf-idf weighting model and each of the Serialization methods were statistically significant
according to t-test. Figure 2 compares the results of the serialization methods, among which continuation
marker model has the highest precision over 0.8 at the 1% recall level, and Time with 15% quantile has the
average precision score showing the slowest decrease. Even though for all serialization methods average
precision values converge to zero as recall levels increase, each of the method gets higher precision rates
than baselines until some part of relevant tweets are retrieved.
64
Size Repl. Disc. Cohe. T:30s T:60s T:5% T:15%
1 8137 8169 8511 7314 6464 7845 6849
2 88 166 6 465 664 298 610
3 34 14 2 76 149 31 109
4 9 0 0 6 40 1 19
5 3 0 1 5 12 1 8
6 5 0 0 1 6 0 2
7 3 0 0 0 3 0 0
8 1 0 0 2 2 0 1
9 2 0 1 0 0 0 0
10 0 0 0 0 0 0 0
11 0 0 0 0 1 0 1
Table 7: Distribution of serialization size (number of serialized tweets) under each criterion
Recall level (%)
Me
an
 of
 AP
 ov
er 
1,0
00
 re
pli
ca
tio
ns
0.0
0.2
0.4
0.6
0.8
0 20 40 60 80 100
tf-idf match reply disc. cont. 30sec 60sec 5% 15%
Figure 2: Means of average precision rates of all methods for the topic Snowpiercer
Recall Baselines: Repl. Disc. Cont. Time difference threshold
level ? Match tf-idf rela. mark. mark. 30sec 60sec 5% 15%
5% .0342 .0518 .3019 .1266 .2313 .5158 .4178 .6804 .4720
10% .0309 .0588 .1798 .0801 .1324 .3916 .3459 .4050 .3976
25% .0284 .0695 .0920 .0494 .0702 .1824 .1665 .1847 .1894
50% .0273 .0685 .0602 .0382 .0486 .1062 .0986 .1070 .1103
100% .0268 .0556 .0434 .0322 .0375 .0666 .0628 .0669 .0687
Table 8: Means of average precision rates (at recall level up to 5%, 50%, and 100%) on various se-
rialization criteria for the topic Snowpiercer (Results in boldface represent the best results among the
methods.)
Serialization methods also perform better than the tf-idf baseline for induced topics, as shown in Figure
3 and Table 9. In particular, Reply and Discourse markers, which were far from the best for Snowpiercer,
serve well for other topics such as Movie in general, Politics, and Gender/Relationships.
The precision of Reply for the topic Movie is exceptionally high, partly because the data were initially
collected from users who were interested in films. Reply relation is dependent on the choice of the data,
in that it is determined by interaction between users, not by a single user?s tweets. If data are collected
from users friendly with each other, Reply will serialize many tweets. On the contrary, if data contains
some users while leaving out their friends, replies to these friends are not serialized by Reply criteria.
Discourse markers give a precision of higher than 50% for the topic Politics, which is likely to be
discussed in more formal expressions using various conjunctions.
65
Figure 3: Means of average precision rates of all methods for the induced topics
Baselines: Repl. Disc. Cont. Time difference threshold
Match tf-idf rela. mark. mark. 30sec 60sec 5% 15%
Mov. .0134 .1139 .8855 .3925 .1791 .3787 .3123 .4161 .3435
Lit. .0026 .0759 .1804 .0171 .1293 .2005 .1287 .1719 .1601
Gen. .0048 .1287 .0653 .2424 .0050 .1092 .2476 .0187 .2297
Pol. .0090 .2176 .2135 .5762 .0625 .5072 .4453 .5234 .4948
Table 9: Means of Average Precision rates at cutoff k = 10 of baselines and different serialization
criteria for induced topics (Results in boldface represent the most accurate results of the topic among the
methods.)
In the topics Literature and Gender/Relationships, average precision scores are at most 25%, which
possibly results from the fact that the seed words for these topics consist of general terms only, while
those of the other two topics include proper nouns such as movie titles or politicians? names. This is
less a problem of the topic itself but rather one of data selection, which focused on users tweeting about
films, and so the set of seed words will vary according to differences in data collection.
5 Conclusion
In this paper, we found that tweets with an implicit topic can be found more effectively by considering
whether or not they are serialized with some tweet containing the overt keyword. Our experiments show
that Tweet Serialization can be detected using various criteria such as reply relations between users,
presence of discourse or continuation markers, and temporal proximity under the same authorship. Our
66
original purpose was to find as various opinions on a given topic as possible, but we expect the methods
used here will be helpful for other tasks, including topic discovery and sentiment analysis, by setting
more exact document boundaries in microblog data. The method we proposed is for Korean Twitter
data, where tweet serialization is observed frequently, particularly among influential users, but it is also
applicable to other languages with similar phenomena.
In future work, we will investigate methods for the evaluation of the results of Tweet Serialization
and combine tf-idf methods with Tweet Serialization criteria. Furthermore, we aim at verifying the
applicability of the results of this study with regard to more various users and more topics.
References
Paul Burstein. February 7, 2013. Older Tweets in search results. The Official Twitter Blog. https://blog.
twitter.com/2013/now-showing-older-tweets-in-search-results.
Jack Dorsey. September 25, 2007. Tracking Twitter. The Official Twitter Blog. https://blog.twitter.
com/2007/tracking-twitter.
Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin. 76(5):
378?382.
Liangjie Hong and Brian D. Davison. 2010. Empirical study of topic modeling in Twitter. SOMA 2010: The
Proceedings of the First Workshop on Social Media Analytics. 80?88.
Beom-mo Kang. 1999. Hankukeui theksuthu cangluwa ene thukseng [Text genres and linguistic characteristics in
Korean]. Korea University Press, Seoul, Korea.
Esteban Kozak. November 19, 2013. New ways to search on Twitter. The Official Twitter Blog. https:
//blog.twitter.com/2013/new-ways-to-search-on-twitter.
Subhabrata Mukherjee and Pushpak Bhattacharyya. 2012. Sentiment analysis in Twitter with lightweight dis-
course analysis. COLING 2012: The 24th International Conference on Computational Linguistics, Proceedings
of the Conference: Technical Papers. 1847?1864.
Rishabh Mehrotra, Scoot Sanner, Wray Buntine and Lexing Xie. 2013. Improving LDA topic models for mi-
croblogs via tweet pooling and automatic labeling. SIGIR ?13; The 36th International ACM SIGIR Conference
on Research and Development in Information Retrieval. 889?892.
Graham Neubig and Kevin Duh. 2013. How much is said in a Tweet? A multilingual, information-theoretic
perspective. AAAI Spring Symposium: Analyzing Microtext, Volume SS-13-01 of AAAI Technical Report.
Gerard Salton and Christopher Buckley. 1988. Term-weighting approaches in automatic text retrieval. Information
Processing & Management. 24(5): 513?523.
Swapna Somasundaran. 2010. Discourse-level Relations for Opinion Analysis. Ph.D Thesis, University of Pitts-
burgh.
Biz Stone. August 22, 2007. Searching Twitter. The Official Twitter Blog. https://blog.twitter.com/
2007/searching-twitter.
Biz Stone. December 23, 2008. Finding Nemo ? Or, name search is back! The Official Twitter Blog. https:
//blog.twitter.com/2008/finding-nemo%E2%80%94or-name-search-back.
Biz Stone. February 18, 2009. Testing a more integrated search experience. The Official Twitter Blog. https:
//blog.twitter.com/2009/testing-more-integrated-search-experience.
Biz Stone. April 03, 2009. The discovery engine is coming. The Official Twitter Blog. https://blog.
twitter.com/2009/discovery-engine-coming.
Biz Stone. April 30, 2009. Twitter search for everyone! The Official Twitter Blog. https://blog.twitter.
com/2009/twitter-search-everyone.
Twitter. April 4, 2011. Discover new accounts and search like a pro. The Official Twitter Blog. https:
//blog.twitter.com/2011/discover-new-accounts-and-search-pro.
67
Jianshu Weng, Ee-Peng Lim, Jing Jiang, and Qi He. 2010. TwitterRank: Finding topic-sensitive influential
twitterers. WSDM ?10: Proceedings of the Third ACM International Conference on Web Search and Data
Mining. 261?270.
Florian Wolf, Edward Gibson and Timothy Desmet. 2004. Discourse coherence and pronoun resolution. Lan-
guage and Cognitive Processes, 19(6): 665?675.
68
