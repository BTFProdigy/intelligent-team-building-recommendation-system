Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 60?67,
Sydney, July 2006. c?2006 Association for Computational Linguistics
A fast and accurate method for detecting English-Japanese parallel texts
Ken?ichi Fukushima, Kenjiro Taura and Takashi Chikayama
University of Tokyo
ken@tkl.iis.u-tokyo.ac.jp
{tau,chikayama}@logos.ic.i.u-tokyo.ac.jp
Abstract
Parallel corpus is a valuable resource used
in various fields of multilingual natural
language processing. One of the most
significant problems in using parallel cor-
pora is the lack of their availability. Re-
searchers have investigated approaches to
collecting parallel texts from the Web. A
basic component of these approaches is
an algorithm that judges whether a pair
of texts is parallel or not. In this paper,
we propose an algorithm that accelerates
this task without losing accuracy by pre-
processing a bilingual dictionary as well
as the collection of texts. This method
achieved 250,000 pairs/sec throughput on
a single CPU, with the best F1 score
of 0.960 for the task of detecting 200
Japanese-English translation pairs out of
40, 000. The method is applicable to texts
of any format, and not specific to HTML
documents labeled with URLs. We report
details of these preprocessing methods and
the fast comparison algorithm. To the
best of our knowledge, this is the first re-
ported experiment of extracting Japanese?
English parallel texts from a large corpora
based solely on linguistic content.
1 Introduction
?Parallel text? is a pair of texts which is written
in different languages and is a translation of each
other. A compilation of parallel texts offered in a
serviceable form is called a ?parallel corpus?. Par-
allel corpora are very valuable resources in various
fields of multilingual natural language processing
such as statistical machine translation (Brown et
al., 1990), cross-lingual IR (Chen and Nie, 2000),
and construction of dictionary (Nagao, 1996).
However, it is generally difficult to obtain paral-
lel corpora of enough quantity and quality. There
have only been a few varieties of parallel corpora.
In addition, their languages have been biased to-
ward English?French and their contents toward of-
ficial documents of governmental institutions or
software manuals. Therefore, it is often difficult
to find a parallel corpus that meets the needs of
specific researches.
To solve this problem, approaches to collect
parallel texts from the Web have been proposed.
In the Web space, all sorts of languages are used
though English is dominating, and the content of
the texts seems to be as diverse as all activities of
the human-beings. Therefore, this approach has a
potential to break the limitation in the use of par-
allel corpora.
Previous works successfully built parallel cor-
pora of interesting sizes. Most of them uti-
lized URL strings or HTML tags as a clue to ef-
ficiently find parallel documents (Yang and Li,
2002; Nadeau and Foster, 2004). Depending on
such information specific to webpages limits the
applicability of the methods. Even for webpages,
many parallel texts not conforming to the presup-
posed styles will be left undetected. In this work,
we have therefore decided to focus on a generally
applicable method, which is solely based on the
textual content of the documents. The main chal-
lenge then is how to make judgements fast.
Our proposed method utilizes a bilingual dictio-
nary which, for each word in tne language, gives
the list of translations in the other. The method
preprocesses both the bilingual dictionary and the
collection of texts to make a comparison of text
pairs in a subsequent stage faster. A comparison
60
of a text pair is carried out simply by compar-
ing two streams of integers without any dictionary
or table lookup, in time linear in the sum of the
two text sizes. With this method, we achieved
250,000 pairs/sec throughput on a single Xeon
CPU (2.4GHz). The best F1 score is 0.960, for a
dataset which includes 200 true pairs out of 40,000
candidate pairs. Further comments on these num-
bers are given in Section 4.
In addition, to the best of our knowledge,
this is the first reported experiment of extracitng
Japanese?English parallel texts using a method
solely based on their linguistic contents.
2 Related Work
There have been several attempts to collect paral-
lel texts from the Web. We will mention two con-
trasting approaches among them.
2.1 BITS
Ma and Liberman collected English?German par-
allel webpages (Ma and Liberman, 1999). They
began with a list of websites that belong to a do-
main accosiated with German?speaking areas and
searched for parallel webpages in these sites. For
each site, they downloaded a subset of the site
to investigate what language it is written in, and
then, downloaded all pages if it was proved to be
English?German bilingual. For each pair of En-
glish and German document, they judged whether
it is a mutual translation. They made a decision
in the following manner. First, they searched a
bilingual dictionary for all English?German word
pairs in the text pair. If a word pair is found in
the dictionary, it is recognized as an evidence of
translation. Finally, they divided the number of
recognized pairs by the sum of the length of the
two texts and regard this value as a score of trans-
lationality. When this score is greater than a given
threshold, the pair is judged as a mutual transla-
tion. They succeeded in creating about 63MB par-
allel corpus with 10 machines through 20 days.
The number of webpages is considered to have
increased far more rapidly than the performance of
computers in the past seven years. Therefore, we
think it is important to reduce the cost of calcula-
tion of a system.
2.2 STRAND
If we simply make a dicision for all pairs in a col-
lection of texts, the calculation takes ?(n2) com-
parisons of text pairs where n is the number of
documents in the collection. In fact, most re-
searches utilize properties peculiar to certain par-
allel webpages to reduce the number of candidate
pairs in advance. Resnik and Smith focused on the
fact that a page pair tends to be a mutual transla-
tion when their URL strings meet a certain condi-
tion, and examined only page pairs which satisfy
it (Resnik and Smith, 2003). A URL string some-
times contains a substring which indicates the lan-
guage in which the page is written. For example,
a webpage written in Japanese sometimes have a
substring such as j, jp, jpn, n, euc or sjis in
its URL. They regard a pair of pages as a candidate
when their URLs match completely after remov-
ing such language-specific substrings and, only for
these candidates, did they make a detailed com-
parison with bilingual dictionary. They were suc-
cessful in collecting 2190 parallel pairs from 8294
candidates. However, this URL condition seems
so strict for the purpose that they found 8294 can-
didate pairs from as much as 20 Tera bytes of web-
pages.
3 Proposed Method
3.1 Problem settings
There are several evaluation criteria for parallel
text mining algorithms. They include accuracy,
execution speed, and generality. We say an algo-
rithm is general when it can be applied to texts of
any format, not only to webpages with associated
information specific to webpages (e.g., URLs and
tags). In this paper, we focus on developing a fast
and general algorithm for determining if a pair of
texts is parallel.
In general, there are two complementary ways
to improve the speed of parallel text mining. One
is to reduce the number of ?candidate pairs? to be
compared. The other is to make a single compar-
ison of two texts faster. An example of the for-
mer is Resnik and Smith?s URL matching method,
which is able to mine parallel texts from a very
large corpora of Tera bytes. However, this ap-
proach is very specific to the Web and, even if we
restrict our interest to webpages, there may be a
significant number of parallel pages whose URLs
do not match the prescribed pattern and therefore
are filtered out. Our method is in the latter cat-
egory, and is generally applicable to texts of any
format. The approach depends only on the lin-
guistic content of texts. Reducing the number of
61
 




	


	






		






