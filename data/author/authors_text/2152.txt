Proceedings of NAACL HLT 2007, Companion Volume, pages 29?32,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
A Fast Method for Parallel Document Identification
Jessica Enright and Grzegorz Kondrak
Department of Computing Science
University of Alberta
Edmonton, AB, T6G 2E8, Canada
{enright,kondrak}@cs.ualberta.ca
Abstract
We present a fast method to identify
homogeneous parallel documents. The
method is based on collecting counts of
identical low-frequency words between
possibly parallel documents. The candi-
date with the most shared low-frequency
words is selected as the parallel document.
The method achieved 99.96% accuracy
when tested on the EUROPARL corpus
of parliamentary proceedings, failing only
in anomalous cases of truncated or oth-
erwise distorted documents. While other
work has shown similar performance on
this type of dataset, our approach pre-
sented here is faster and does not require
training. Apart from proposing an effi-
cient method for parallel document iden-
tification in a restricted domain, this pa-
per furnishes evidence that parliamentary
proceedings may be inappropriate for test-
ing parallel document identification sys-
tems in general.
1 Introduction
Parallel documents are documents that are mutual
translations. There are a number of reasons one
might want to either identify parallel documents, or
confirm that a pair of documents are in fact parallel.
Most prominently, one could use pairs of automat-
ically detected parallel documents to build parallel
corpora. Parallel corpora have many uses in natural
language processing, and their dearth has been iden-
tified as a major bottleneck (Diab, 2004). They have
been employed in word sense disambiguation (Diab
and Resnik, 2002), automatic construction of bilin-
gual dictionaries (McEwan et al, 2002), and induc-
ing statistical machine translation models (Koehn et
al., 2003). In addition to building parallel corpora,
one can envision other uses for parallel document
identification, such as cross-language information
retrieval (Chen and Nie, 2000).
Much work on identifying pairs of parallel doc-
uments focuses on the use of external features of
the documents, rather than content. Chen and Nie
(2000) describe PTMiner, a cross-language informa-
tion retrieval system. They consider a number of
factors in determining if a pair of documents are par-
allel, including document size, date, URL, and lan-
guage flag. For example, if a document is available
in both French and English, it is common for the
French document?s URL to contain .fr and the En-
glish to contain .en In addition to these measures,
they consider website structure.
McEwan et al (2002) find parallel documents
which they then use to automatically build a bilin-
gual dictionary. In their system, they first gener-
ate a set of candidate pairs based on manual selec-
tion, or advanced search engine use. They then filter
the pairs to remove non-parallel pairs. First, they
confirm that one of each pair is in each of the de-
sired languages using tuned lists of stop-words, then
they compare the documents based on length in to-
kens, and HTML markup. Resnik and Smith (2003)
use a similar idea of candidates and filters in their
STRAND system. STRAND filters the documents
based on aligning them by length in tokens and lo-
cation of HTML markup in the documents.
Apart form the work done on external metrics,
Patry and Langlais (2005) investigated a number of
content-based metrics. They consider several docu-
29
ment features, including the numbers, proper names
and punctuation contained within, as well as docu-
ment length, and alignment scores between candi-
date pairs. The features are then used to train an
Ada-Boost classifier, which makes decisions based
on edit-distance and cosine scores. They experi-
mented with several combinations of features, one
of which achieved 100% correctness when tested on
487 out of 488 parallel documents that constitute the
English-Spanish portion of the EUROPARL corpus.
They conclude that a bag-of-words approach is infe-
rior to one that considers feature order.
In this work, we demonstrate that a much sim-
pler approach can achieve equally good results. Our
method does not depend on hand-coded linguistic
knowledge and requires no training data, which may
be unavailable for some language pairs. In addition,
thanks to its simplicity, our method is very fast.
2 Parallel document identification
One can consider the parallel document identifica-
tion problem to be as follows:
Given one document dA in language A,
and a set of documents DB in language B,
identify exactly one document dB ? DB
that is the parallel, or translation, of dA.
We initially designed a cognate-based approach to
the problem, which employed a combination of or-
thographic word similarity measures to identify cog-
nates such as French nombres and English numbers
between documents. In order to make the method
computationally feasible, potential cognates were
filtered based on word order, location in the docu-
ment, frequency, and length. However, we found
that a faster and simpler procedure, which is de-
scribed below, performed extremely well, eliminat-
ing the need for a more sophisticated approach.
We propose to identify parallel documents by
counting the number of unique words that appear in
both documents. The documents are treated as bags
of words, that is, their word order is not considered.
From each document, we extract a set of words that
are at least 4 characters long and have frequency 1.
Given a document in language A, we select the doc-
ument in language B that shares the largest number
of these words. An implementation based on hash
tables ensures speed.
Since identical words of frequency 1 are almost
certainly cognates, this method can be seen as an
extremely conservative approach to cognate detec-
tion. In practice, most of unique identical words are
proper nouns.
3 Experimental setup
We performed experiments on two different par-
liamentary corpora. The English-French Canadian
Hansards from the 36th sitting of the Canadian
Parliament (Germann, 2001) was selected as the
development dataset. In testing on the Canadian
Hansards, English was used as the Language A, and
French as the Language B. Our approach correctly
identified all parallel documents.
In order to allow for a direct comparison with the
work of Patry and Langlais (2005), we adopted the
EUROPARL corpus of parliamentary proceedings
(Koehn, 2002) as our test dataset. However, rather
than focusing on a single language pair, we per-
formed tests on all 110 language pairs involving the
following 11 languages: German, English, Greek,
Finnish, Swedish, Dutch, French, Danish, Italian,
Spanish and Portuguese. Diacritics were stripped
from the documents of all languages. Since Greek
utilizes a different script from the rest of the docu-
ments. we used a straightforward context-free map-
ping to convert every Greek character to its nearest
roman equivalent.
Some of the 488 documents available in EU-
ROPARL were missing in Finnish, Swedish, Greek
and Danish. In particular, Greek had 392 docu-
ments, Danish had 487 documents, and Swedish and
Finnish had 433 each. In such cases, the parallels
of those missing documents were excluded from the
language A for that test.
The EUROPARL documents range in size from
114 tokens (13 lines) to 138,557 tokens (11,101
lines). The mean number of tokens is 59,387 (2,826
lines). Each orientation of each language pair was
tested. For example, for the language pair English-
Dutch, tests were run twice - once with English as
language A and Dutch as language B, and once
the other way around. The results for a given lan-
guage pair are not necessarily symmetric. Hence-
forth when referring to a language pair, we list the
language A as the first one.
30
For each document and each language pair, an in-
dividual test was run. An individual test consisted
of finding, for a given document in language A, its
parallel in the language B set. Since we did not take
advantage of the pigeon-hole constraint, the individ-
ual tests were independent from each other.
No changes were made to the approach once test-
ing on the EUROPARL corpus began, in order to
avoid adapting it to work on any particular data set.
4 Results
In total, only 20 of the 49872 tests did not pro-
duce the correct result (0.04% error rate). There
was one incorrect selection in the English-Spanish
language pair, one in the English-German pair, as
well as in each of 18 language pairs involving Dan-
ish or English as a Language A. All of the incorrect
results can be traced to mistranslation, or to miss-
ing/truncated documents. In particular, one of the
documents is severely truncated in Danish and En-
glish, one of the German documents missing a por-
tion of its text, and the Spanish version of one of the
documents contains a number of phrases and sen-
tences of English, apparently belonging to the En-
glish version of the text.
Effectively, when this method fails it is because
the input does not match the problem definition. Re-
call that the problem was defined as selecting a doc-
ument dB from a set of documents DB in language
B that is the correct parallel to dA, a document in
language A. Failure cases occurred because there
was no correct parallel to the dA in DB . In fact,
each of the ?incorrect? results is a manifestation of
an editorial error in the EUROPARL corpus. One
could see this approach being used as an aid to iden-
tifying fragmentary documents and mistranslations
in parallel corpora.
Encouraged by the excellent accuracy of our
method, we decided to try an even simpler approach,
which is based on words of frequency 1 in the entire
set of documents in a given language, rather than in
a single document. For every document from a lan-
guage A, we select as its parallel the document from
language B that shares the most of those words with
it. However, the results obtained with this method
were clearly inferior, with the error rates ranging
from 2.9% for Dutch to 27.3% for Finnish.
5 Discussion
The implications of this work are two-fold. First,
it shows a simple, fast, and effective method for
identifying parallel documents. Second, it calls into
question the usefulness of parliamentary proceed-
ings for the evaluation of parallel document identifi-
cation schemes.
The method described in this paper is sufficiently
simple as to be used as a baseline for comparison
with other methods. No information is shared be-
tween trials, no word similarity measures are used,
and word order is ignored. The method does not
incorporate any language-specific linguistic knowl-
edge, and it has shown itself to be robust across lan-
guages without any alterations. The only constraint
is that the languages must share an alphabet, or can
be converted into a common alphabet. Furthermore,
it requires no training phase, which would likely
have to be repeated for every pair of languages.
Our method achieves 99.9% accuracy on the
English-Spanish language pair, which roughly
matches the best result reported by Patry and
Langlais (2005) (who apparently removed one doc-
ument pair from the collection). However, their
method requires a training phase on aligned parallel
documents, making it time consuming and inconve-
nient to adapt their approach to a new language pair,
even in cases where such document-aligned corpora
are available. In addition, their top accuracy value
corresponds to only one of several combination of
features ? the results with classifiers based on other
combinations of features were lower.
We implemented our method using hash tables,
which store the words occurring in a document to-
gether with their frequencies. This makes the entire
search for a parallel document roughly linear in the
total number of words in all the documents. Average
total wall-clock time spent for one test with one lan-
guage A document and 488 language B documents
was 59.4 seconds. on a AMD Athlon(tm) 64 Proces-
sor 3500+. Profiling showed that on average 99.7%
of the wall-clock time was spent on I/O operations,
with the remainder taken by hash table lookups and
string equality checks. Clearly, little speed improve-
ment is possible. In contrast to the speed of our
approach, the approach used by Patry and Langlais
(2005) requires not only the time to train a classifier,
31
but also the time to compute edit distance between
many document pairs.
In addition to yielding a simple, accurate and fast
method for parallel document identification, our re-
sults suggest that relatively ?clean? collections of
parliamentary proceedings of the EUROPARL type
may be inappropriate for testing parallel document
identification schemes in general. If a very simple
approach can achieve near perfect accuracy in such
a domain, perhaps the task is too easy. Future gen-
eral parallel document identification systems should
be tested on more challenging datasets.
6 Future Work
While the approach presented here has been very
successful thus far, there are a number of extensions
that could be made to make it more applicable in
general. More work could allow it to deal with cases
of missing parallel documents, datasets with fewer
proper names, and even yield knowledge of the dif-
ficulty of the problem in general.
First, the problem definition could be expanded to
include cases where there is no valid parallel for a
given language A document in the language B doc-
ument set. This could take the form of establishing
a score or significance threshold. For example, if
there were no document in the language B set that
shared more than the minimum number of unique
words with the document dA in language A, then the
approach might return no parallel for that document.
Second, it might be revealing to run further tests
with this approach on other types of text than parlia-
mentary proceedings. What types of text would re-
quire a more sophisticated approach? The answer to
that question might have implications for the range
of text types that ought to be used to comprehen-
sively test parallel document identification systems.
The exact matching of words is a critical feature
of our approach, which enables it to perform quick
comparisons of documents by representing them as
sets of low-frequency words stored in hash tables.
However, it is also a limitation because many cross-
language cognates are not orthographically identi-
cal. A system relying on non-binary word similar-
ity measures rather than on total identity of words
would be more complex and slower, but also more
robust across different domains of text.
7 Conclusion
We have presented a viable, simple method for
identification of homogeneous parallel documents.
This method uses less resources and time than other
content-based methods, a valuable asset when many
languages lack linguistic resources. In addition to
showing the effectiveness of our approach, the re-
sults of the experiments suggest that parliamentary
proceedings may be inappropriate for parallel docu-
ment identification scheme testing.
Acknowledgments
We would like to thank Colin Cherry and other
members of the NLP research group at University of
Alberta for their helpful comments and suggestions.
This research was supported by the Natural Sciences
and Engineering Research Council of Canada.
References
Jiang Chen and Jian-Yun Nie. 2000. Parallel web text
mining for cross-language IR. In In Proc. of RIAO,
pages 62?77.
Mona Diab and Philip Resnik. 2002. An unsupervised
method for word sense tagging using parallel corpora.
In Proc. of ACL, pages 255?262.
Mona Diab. 2004. Relieving the data acquisition bottle-
neck for word sense disambiguation. In Proc. of ACL,
pages 303?310.
Ulrich Germann. 2001. Aligned Hansards of the
36th Parliament of Canada, Release 2001-1a. Avail-
able at http://www.isi.edu/natural-language/download/
hansard/.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of HLT-NAACL, pages 48?54.
Philipp Koehn. 2002. Europarl: A multilingual cor-
pus for evaluation of machine translation. Available
at http://people.csail.mit.edu/koehn/.
Craig J. A. McEwan, Iadh Ounis, and Ian Ruthven. 2002.
Building bilingual dictionaries from parallel web doc-
uments. In Proc. of ECIR, pages 303?323.
Alexandre Patry and Philippe Langlais. 2005. Auto-
matic identification of parallel documents with light or
without linguistic resources. In Proc. of Canadian AI,
pages 354?365.
Philip Resnik and Noah A. Smith. 2003. The web as a
parallel corpus. Comput. Linguist., 29(3):349?380.
32
Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 42?46,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
A Character-Based Intersection Graph Approach to Linguistic Phylogeny
Jessica Enright
University of Alberta
Edmonton, Alberta, Canada
enright@cs.ualberta.ca
Abstract
Linguists use phylogenetic methods to
build evolutionary trees of languages
given lexical, phonological, and morpho-
logical data. Perfect phylogeny is too re-
strictive to explain most data sets. Con-
servative Dollo phylogeny is more permis-
sive, and has been used in biological ap-
plications. We propose the use of conser-
vative Dollo phylogeny as an alternative
or complementary approach for linguistic
phylogenetics. We test this approach on an
Indo-European dataset.
1 Introduction
1.1 Language Phylogeny
A linguistic phylogenetic tree is a tree describing
the evolution of some set of languages. Usually,
we build such a tree using information given by a
set of characters associated with those languages.
We say that a character back-mutated if after
evolving from 0 state to 1 state, it subsequently
is lost and switches back on the tree from 1 state
to 0 state. We say that a character has parallel
evolution if it evolves twice on the tree from state
0 to state 1 independently. We say that a charac-
ter is borrowed if, on the true evolutionary tree, it
has been transfered from one branch to another by
contact between linguistic groups. Loanwords are
an example of this.
1.2 Perfect phylogeny
Given a set of binary characters C = {c1...cj},
we say that a rooted tree T = (r, VT , ET ) with
languages L = l1...lk as the leaf nodes of T is
a perfect phylogeny if there is a binary labeling
of each character at each node such that the root
node is labeled with a zero for each character, and
for each character both the subtree induced by the
nodes labeled 1 at that character, and the subtree
induced by the nodes labeled 0 at that character
are connected.
This means that each character evolves exactly
once, and that there is no back-mutation or bor-
rowing.
We can recognize whether a set of characters
admits a perfect phylogeny in polynomial time
(Felsenstein, 2004). Unfortunately, often charac-
ter data does not admit a perfect phylogeny.
Usually the question given character data is:
How far away is this data from admitting a perfect
phylogeny? What is the minimum level of bor-
rowing, back mutation or parallel evolution that
we must allow to produce a tree that describes this
data? Answering this question is NP-Hard (Day et
al., 1986).
Many approaches describe and formalize this
question. Nakhleh et al (2005b) provide an ex-
cellent survey of linguistic phylogenetic methods.
Nakhleh et al (2005a) proposed perfect phy-
logeny networks as a way of considering the phy-
logeny problem. A perfect phylogeny network is
a graph that is not required to be a tree such that
every character exhibits a perfect phylogeny on at
least one of the subtrees of that graph.
Unfortunately, even given a phylogenetic tree
and character data, determining the minimum
number of edges one must add to produce a per-
fect phylogeny network is NP-Hard (Day et al,
1986). Nakhleh et al (2005a) mention that ap-
plying the perfect phylogeny network approach to
their Indo-European language dataset is tractable
only because one need only add very few edges to
their tree to produce a perfect phylogeny network.
1.3 Dollo Phylogenies
In contrast to a perfect phylogeny, a Dollo phy-
logeny allows an arbitrary number of back muta-
tions.
Given a set of binary characters C = {c1...cj},
we say that a rooted tree T = (r, VT , ET ) with
42
{1, 1, 0 }
{0, 1, 0 } {0, 0, 1 }
{1, 0, 1 }
{1, 1, 0 }
{1, 1, 0 }
{0, 0, 0 }
{1, 0, 1 }
Figure 1: A tree that is a conservative Dollo phy-
logeny, but not a perfect phylogeny, as charac-
ters one and two back-mutate. The lists at each
node contain the state of characters one, two,
and three in that order.
languages L = l1...lk as the leaf nodes of T is
a Dollo phylogeny if there is a binary labeling of
each character at each node such that the root node
is labeled with a zero for each character, and for
each character the subtree induced by the nodes
labeled 1 is connected.
This means that each character evolves exactly
once but an arbitrary number of back-mutations
are allowed. Unfortunately, every set of charac-
ter data admits a Dollo phylogeny. Clearly Dollo
phylogeny is too permissive to be a useful notion
in linguistic phylogenetics.
Przytycka et al (2006) discussed the idea of a
conservative Dollo phylogeny.
Given a set of binary characters C = {c1...cj},
we say that a rooted tree T = (r, VT , ET ) with
languages L = l1...lk as the leaf nodes of T is a
conservative Dollo phylogeny (CDP) if there is a
binary labeling of each character at each node such
that the root node is labeled with a zero for each
character, for each character the subtree induced
by the nodes labeled 1 is connected, and if two
characters appear together in their 1 states in the
tree at an internal node, they also occur together in
their 1 states in the tree at a leaf node. Recall that
the leaves in this tree are the languages for which
we have data. For an example, see Figure 1.
If two characters existed together in some an-
cestral language, they must also exist together in at
least one leaf language. That is, if they have ever
existed together in the same language, we have ev-
idence of it in the form of a known language that
possessed both of those characters. Is this a rea-
sonable assumption? We have no evidence that
it is. However, it?s certainly a more reasonable
assumption than that required for a perfect phy-
logeny. We expect that often, data sets will not
admit a CDP, and that, like for perfect phylogeny,
the question will be: How far away are the data
from admitting a CDP?
Przytycka et al (2006) prove that a set of char-
acters admit a CDP if and only if their intersection
graph is chordal. Chordal graphs are graphs with
no induced cycles longer than three vertices. Rose
et al (1976) provide a linear-time recognition al-
gorithm for chordal graphs.
Graph G = (V,E) is an intersection graph of a
family of sets S if there is a bijection F between V
and S such that for every two sets s, t ? S F(s)
is adjacent to F(t) if and only if s intersects t.
Set s intersects set t if they share at least one ele-
ment. Given sets, we can compute their intersec-
tion graph in linear time. For an example of an
intersection graph derived from a family of sets,
see Figure 2.
{1, 2},  {2, 3},  {3}, {3, 4}, {5, 3} 
a b c d e
a b
c e
d
Figure 2: An example of a family of sets labeled
a, b, c, d, e on the top and the intersection graph
of those sets on the bottom.
We can then determine if a set of characters ad-
mits a CDP in linear time. This approach to phy-
logeny was used by Przytycka et al (2006) in a
biological phylogenetic application. Here, we use
it for linguistic phylogeny.
2 Methodology
We implemented an algorithm to, given a charac-
ter dataset, compute the intersection graph of those
characters, and determine whether the resulting
graph is chordal as given by Rose et al (1976).
This tells us whether or not the dataset admits a
CDP. We also implemented an exhaustive search
that computes the minimum number of characters
that must be borrowed to otherwise admit a CDP.
43
We ran our program on the Indo-
European character dataset used by Nakhleh
et al (2005a), and available online at
http://www.cs.rice.edu/ nakhleh/CPHL/.
2.1 Language Family Grouping
Nakhleh et al (2005a) combined established lan-
guage groups into a single language during com-
putation to decrease computation time. We use the
same families as they do, and do the same in two
of our experiments.
For example, we consider the Tocharian lan-
guage family, consisting of Tocharian A and
Tocharian B to be a single language when building
our intersection graph. This language grouping is
done as a preprocessing step to the construction of
the intersection graph of the characters.
We expect this transformation to be particularly
useful in the CDP setting, beyond just decreasing
computation time. We expect it will make our data
closer to admitting a CDP in a way consistent with
true evolutionary history.
Consider the difference between the intersec-
tion graph of a set of characters with family group-
ing and without. Let s and t be two characters that,
are considered to intersect with family grouping,
but not without. Then s and t are not present in
any of the same languages, but there are two lan-
guages li, lj such that li has character s but not t
and language lj has character t but not s, and li
and lj are in the same family L.
We use the language family definitions given by
Nakhleh et al (2005a), where these language fam-
ilies are identified as consistent with all characters,
and it is argued that it is very unlikely there is any
borrowing between a portion of the tree inside the
family, and a portion of the tree outside the family.
Therefore, if s and t are both present within
leaves in the language family L, and neither is bor-
rowed from outside the family, then each of s, t is
either present only within language family L, or
is present in at least one internal node ancestral
to language family L. If s and t are only present
within the language family, they are not informa-
tive when language family grouping is used.
However, if both s and t are present at an in-
ternal node ancestral to language family L, then
this is important information that we have derived
by applying family language grouping, and will
make the data closer to admitting a CDP in terms
of number of borrowings required.
2.2 Binary Data
We made the data binary by separating states of
a given character as best indicated by notes pro-
vided by Nakhleh et al (2005a) on their coding of
the characters. In making the data binary, we have
likely lost some constraining information. When
a language (or language family, when that group-
ing was used) has a unique state at a character,
we coded this as having all possible non-ancestral
states. The basis for this is that some of these
codes indicate that there is no data for that char-
acter at that language, or that if that language ac-
tually does have a unique state at that character,
it is uninformative, but could have evolved from
any other state. Data processing by someone more
highly trained in linguistics would either confirm
this decision or provide an alternative approach.
We have tried to remain as close as possible to how
the data is used in Nakhleh et al (2005a).
3 Experiments
We ran four experiments to investigate the use-
fulness of the conservative Dollo parsimony ap-
proach. We ran our implementation on:
1. All characters without language family
grouping
2. All characters with language family grouping
3. Phonological and morphological characters
only without language family grouping
4. Phonological and morphological characters
only with language family grouping
4 Results
We give our results in Table 4
For the morphological and phonological
dataset, both grouped and ungrouped, we ex-
tracted a phylogenetic tree from our program?s
output. These trees were consistent with Tree A
in (Nakhleh et al, 2005a). The fact that we man-
aged to build a tree consistent with expectations
without any input tree is very encouraging.
Recall that when we use language grouping we
combine all languages identified as being from an
established family by Nakhleh et al (2005a) into
a single language. For example, instead of con-
sidering both Tocharian A and Tocharian B, in our
experiments with language grouping we consider
a single language, Tocharian, that has all charac-
teristics of Tocharian A and all characteristics of
Tocharian B.
44
Table 1: The results of conservative Dollo phylogeny checking algorithm on modified versions of the
Indo-European character dataset as used in (Nakhleh et al, 2005a). We ran each program for at most 1
hour. Entries of ?Too slow? indicate that we did not allow the program to halt.
Dataset Admits a CDP? Minimum number of languages
that must borrow
Answer Time Answer Time
Phonological, Morphological Data
without Language Grouping
Yes <1 s 0 <1 s
Phonological, Morphological Data
with Language Grouping
Yes <1 s 0 <1 s
All Data without Language Grouping No <1 s - Too slow
All Data with Language Grouping No <1 s 2 < 1 s
In our experiments without language grouping,
we do not combine languages in this way, and in-
stead consider all 24 languages separately.
5 Discussion
When is the CDP approach useful for linguistic
phylogenetics?
Because a CDP allows back-mutation, it is
likely most useful for datasets that exhibit a lot of
back mutation, and not a lot of borrowing. Phono-
logical and morphological characters are more
likely to fit this requirement than lexical data. This
is reflected in our positive results on the phonolog-
ical and morphological characters alone.
In contrast, when we included the lexical data,
the dataset did not admit a conservative Dollo par-
simony, whether or not we used language family
grouping. We expect this is due to borrowing of
lexical characters.
The full dataset with language family group-
ing was much closer to admitting a conserva-
tive Dollo parsimony than the full dataset with-
out language family grouping. As explained in our
Methodology section, this was expected and rein-
forces our position that language family grouping
is extremely useful when computing conservative
Dollo phylogenies.
Our experiments ran in either negligible time,
or were not allowed to halt. The speed of the fast
experiments suggests that computing conservative
Dollo phylogenies might be useful in construct-
ing a tree when no tree is known, and the amount
of character data causes computing other types of
phylogenies to be intractable.
6 Future Work
We are currently pursuing several extensions to
this work.
First, we are developing an improved heuristic
search for the minimum number of edges that need
to be removed from or added to a graph to make
the resulting graph chordal. This will enable us to
use the Dollo phylogeny approach outlined here
on character data sets that require more borrowing
to fully explain them.
Using this improved search, we will run experi-
ments on other sets of character data.
Nakhleh et al (2005a) started with several pro-
posed trees in their work on perfect phylogenetic
networks. We plan to implement a version of our
CDP approach that takes as input a proposed tree.
This version will calculate the minimum number
of edges that must be added to create a Dollo
phylogeny network, as analogous to Nakhleh et
al.?s perfect phylogenetic network. This minimum
number of edges would be useful as a lower bound
for the required number of edges one must add to
produce a perfect phylogeny network.
7 Conclusion
We have presented an alternative phylogeny that
may be of use in linguistic phylogenetics, par-
ticularly on phonological or morphological data.
We have proposed a number of future extensions
based on our experiments that we hope will im-
prove the performance of this approach.
Acknowledgments
The author would like to acknowledge the helpful
input of reviewers, as well as Dr. Gzegorz Kon-
drak and Dr. Lorna Stewart.
45
References
William Day, David Johnson, and David Sankoff.
1986. The computational complexity of inferring
rooted phylogenies by parsimony. Mathematical
Biosciences, 81:33?42.
Joseph Felsenstein. 2004. Inferring Phyloge-
nies. Number 1. Sinauer Associates, Massachusetts,
USA.
Luay Nakhleh, Don Ringe, and Tandy Warnow. 2005a.
Perfect phylogenetic networks: A new methodology
for reconstructing the evolutionary history of natu-
ral languages. Language (Journal of the Linguistic
Society of America), 81(2):382?420.
Luay Nakhleh, Tandy Warnow, Don Ringe, and
Steven N. Evans. 2005b. A comparison of phyloge-
netic reconstruction methods on an ie dataset. The
Transactions of the Philological Society, 3(2):171 ?
192.
Teresa Przytycka, George Davis, Nan Song, and Dan-
nie Durand. 2006. Graph theoretical insights into
evolution of multidomain proteins. Journal of com-
putational biology : a journal of computational
molecular cell biology, 13(2):351?363.
Donald J. Rose, R. Endre Tarjan, and George S. Leuker.
1976. Algorithmic aspects of vertex elimination on
graphs. SIAM Journal of Computing, 5(2):266?283.
46
