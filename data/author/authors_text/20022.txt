Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 67?70, Dublin, Ireland, August 23-29 2014.
 A Sentence Judgment System for Grammatical Error Detection 
 
Lung-Hao Lee 1,2, Liang-Chih Yu3,4, Kuei-Ching Lee1,2,  
Yuen-Hsien Tseng1, Li-Ping Chang5, Hsin-Hsi Chen2 
1Information Technology Center, National Taiwan Normal University 
2Dept. of Computer Science and Information Engineering, National Taiwan University 
3Dept. of Information Management, Yuen Ze University 
4Innovation Center for Big Data and Digital Convergence, Yuen Ze University 
5Mandarin Training Center, National Taiwan Normal University 
lcyu@saturn.yzu.edu.tw, {lhlee, johnlee, lchang, 
samtseng}@ntnu.edu.tw, hhchen@ntu.edu.tw 
  
 
Abstract 
This study develops a sentence judgment system using both rule-based and n-gram statistical 
methods to detect grammatical errors in Chinese sentences. The rule-based method provides 
142 rules developed by linguistic experts to identify potential rule violations in input sentences. 
The n-gram statistical method relies on the n-gram scores of both correct and incorrect training 
sentences to determine the correctness of the input sentences, providing learners with im-
proved understanding of linguistic rules and n-gram frequencies. 
1 Introduction 
China?s growing global influence has prompted a surge of interest in learning Chinese as a foreign 
language (CFL), and this trend is expected to continue. This has driven an increase in demand for au-
tomated IT-based tools designed to assist CFL learners in mastering the language, including so-called 
MOOCs (Massive Open Online Courses) which allows huge numbers of learners to simultaneously 
access instructional opportunities and resources. This, in turn, has driven demand for automatic proof-
reading techniques to help instructors review and respond to the large volume of assignments and tests 
submitted by enrolled learners. 
However, whereas many computer-assisted learning tools have been developed for use by students 
of English as a Foreign Language (EFL), support for CFL learners is relatively sparse, especially in 
terms of tools designed to automatically detect and correct Chinese grammatical errors. For example, 
while Microsoft Word has integrated robust English spelling and grammar checking functions for 
years, such tools for Chinese are still quite primitive. In contrast to the plethora of research related to 
EFL learning, relatively few studies have focused on grammar checking for CFL learners. Wu et al. 
(2010) proposed relative position and parse template language models to detect Chinese errors written 
by US learner. Yu and Chen (2012) proposed a classifier to detect word-ordering errors in Chinese 
sentences from the HSK dynamic composition corpus. Chang et al. (2012) proposed a penalized prob-
abilistic First-Order Inductive Learning (pFOIL) algorithm for error diagnosis. In summary, although 
there are many approaches and tools to help EFL learners, the research problem described above for 
CFL learning is still under-explored. In addition, no common platform is available to compare differ-
ent approaches and to promote the study of this important issue. 
This study develops a sentence judgment system using both rule-based and n-gram statistical meth-
ods to detect grammatical errors in sentences written by CFL learners. Learners can input Chinese sen-
tences into the proposed system to check for possible grammatical errors. The rule-based method uses 
a set of rules developed by linguistic experts to identify potential rule violations in input sentences. 
 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 
67
The n-gr
tences to
proved u
can also 
assignme
2 A S
Figure 1
http://sjf
shown in
part-of-s
grammat
ods dete
informat
ence, as 
?
( I
The ru
(towards
frequenc
detail the
2.1 Pr
Chinese 
Languag
nese wo
usually s
corpus-b
Ma, 200
ed word
????
?POS:W
words, t
lexicon a
POS tag 
 
am statistica
 determine 
nderstandin
be incorpora
nts and test
entence Ju
 shows the
.itc.ntnu.edu
 the upper 
peech taggi
ical error de
ct grammatic
ion, the exp
shown in the
     ?     ??
      from   he
le-based me
)) cannot be
y of the big
 pre-process
e-processin
is written w
e Processing
rd segmente
uffers from 
ased learnin
2). This is fo
s with parts-
??? (Ob
ord? sequen
he translatio
nd therefore
?SHI? is a ta
l method re
the correctn
g of both lin
ted into onl
s. 
dgement S
 user interf
.tw/demo/. L
part of Fig. 
ng, and then
tection. Fina
al errors. O
lanation of t
 bottom par
    ?     ?
re    go   tow
thod shows
 used after a
ram ?? ?
ing, rule-ba
g 
ithout word 
 (NLP) task
rs are gener
the unknow
g method is 
llowed by a
of-speech (T
ama is the p
ce  shown 
n of a forei
 is extracted
g to represen
Figure 1.
lies on the n
ess of the in
guistic rules 
ine CFL MO
ystem 
ace of the 
earners can
1. Each inp
 passed to 
lly, an inpu
therwise, it w
he matched 
t of Fig. 1. F
         ? 
ads  north. )
a rule violat
 verb (e.g., ?
? (go toward
sed method, 
boundaries.
s, texts mus
ally trained 
n word (i.e.,
used to merg
 reliable and
sai and Che
resident of 
as follows: 
gn proper na
 by the unk
t the be-ver
Screenshot 
-gram scor
put sentence
and n-gram 
OC platform
sentence ju
 submit sing
ut sentence 
both the ru
t sentence w
ill be mark
rules and n-g
or instance, 
 
ion is detec
?? (go)). T
s) is relativ
and n-gram 
 As a result,
t undergo au
by an input 
 the out-of-v
e unknown
 cost-effecti
n, 2004). F
the USA). 
 Nb:???
me ????
nown word 
b ???. 
of the senten
es of both c
s. The syste
frequencies
s to help as
dgment sys
le or multip
is pre-proce
le-based an
ill be marke
ed as correc
ram frequen
the followin
ted and expl
he n-gram fr
e low. The f
statistical m
 prior to the
tomatic wo
lexicon and
ocabulary, o
 words to tac
ve POS-tagg
or example, 
It was segm
  SHI:?  N
? (Obama) 
detection me
ce judgemen
orrect and in
m helps lea
. In addition,
sess and/or 
tem, which 
le sentences
ssed for wo
d n-gram st
d as incorre
t ( ). In ad
cies are als
g sentence i
ains that a p
equencies al
ollowing su
ethod. 
 implementa
rd segmenta
 probability 
r OOV) pro
kle the OOV
ing method 
take the Ch
ented and ta
c:??  Na
is not likely
chanism. In
t system. 
correct train
rners develo
 the propose
score the nu
can be acc
 through th
rd segmenta
atistical met
ct ( ) if bo
dition to the
o presented 
s marked as 
reposition (e
so shows th
bsections de
tion of mos
tion. Autom
models. Ho
blem. In this
 problem (C
to label the 
inese senten
gged in the
:??. Amo
 to be inclu
 this case, th
ing sen-
p an im-
d system 
mbers of 
essed at 
e textbox 
tion and 
hods for 
th meth-
 decision 
for refer-
incorrect: 
.g., ??? 
at the the 
scribe in 
t Natural 
atic Chi-
wever, it 
 study, a 
hen and 
segment-
ce ???
 form of  
ng these 
ded in a 
e special 
 
68
2.2 Rule-based Linguistic Analysis 
Several symbols are used to represent the syntactic rules to facilitate the detection of errors embedded 
in Chinese sentences written by CFL learners: (1) ?*? is a wild card, with ?Nh*? denoting all subordi-
nate tags of ?Nh?, e.g., ?Nhaa,? ?Nhab,? ?Nhac,? ?Nhb,? and ?Nhc?. (2) ?-? means an exclusion from 
the previous representation, with ?N*-Nab-Nbc? indicating that the corresponding word should be any 
noun (N*) excluding countable entity nouns (Nab) and surnames (Nbc). (3) ?/? means an alternative 
(i.e., ?or?), where the expression ???/??/??? (some/these/those) indicates that one of these 
three words satisfies the rule. (4) The rule mx{W1 W2} denotes the mutual exclusivity of the two 
words W1 and W2. (5) ?<? denotes the follow-by condition, where the expression ?Nhb  <  Nep? 
means the POS-tag ?Nep? follows the tag ?Nhb? that can exist several words ahead of the ?Nep?. 
Using such rule symbols, we manually constructed syntactic rules to cover errors that frequently oc-
cur in sentences written by CFL learners. We adopted the ?Analysis of 900 Common Erroneous Sam-
ples of Chinese Sentences? (Cheng, 1997) as the development set to handcraft the linguistic rules with 
syntactic information. If an input sentence satisfies any syntactic rule, the system will report the input 
as suspected of containing grammatical errors, creating a useful tool for autonomous CFL learners.  
2.3 N-gram Statistical Analysis 
Language modeling approaches to grammatical error detection are usually based on a score (log prob-
ability) output by an n-gram model trained on a large corpus. A sentence with grammatical errors usu-
ally has a low n-gram score. However, choosing an appropriate threshold to determine whether a sen-
tence is correct is still a nontrivial task. Therefore, this study proposes the use of n-gram scores of cor-
rect and incorrect sentences to build the respective correct and incorrect statistical models for gram-
matical error detection. That is, a given sentence is denoted as incorrect (i.e., having grammatical er-
rors) if its probability score output by the statistical model of incorrect sentences (i.e., the incorrect 
model) is greater than that of correct sentences (i.e., the correct model).  
To build the incorrect and correct statistical models, a total of 19,080 sentences with grammatical 
errors were extracted from the HSK dynamic composition corpus. These sentences were then manual-
ly corrected. An n-gram (n= 2 and 3) language model was then built from the Sinica corpus released 
by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) using 
the SRILM toolkit (Stolcke, 2002). The trained language model was used to assign an n?gram score 
for each correct and incorrect sentence, which were then used to build the respective correct and incor-
rect models based on a normal probability density function (Manning and Sch?tze, 1999). Both mod-
els can then be used to evaluate each test sentence by transforming its n-gram score into a probability 
score to determine whether the sentence is correct or not. 
3 Performance Evaluation 
The test set included 880 sentences with grammatical errors generated by CSL learners in the NCKU 
Chinese Language Center, and the corresponding 880 manually corrected sentences. For the rule-
based approach, a total of 142 rules were developed to identify incorrect sentences. For the n-gram 
statistical approach, both bi-gram and tri-gram language models were used for the correct and incor-
rect statistical models. In addition to precision, recall, and F1, the false positive rate (FPR) was defined 
as the number of correct sentences incorrectly identified as incorrect sentences divided by the total 
number of correct sentences in the test set. 
Table 1 shows the comparative results of the rule-based and n-gram statistical approaches to gram-
matical error detection. The results show that the rule-based approach achieved high precision, low 
recall and low FPR. Conversely, the n-gram-based approach yielded low precision, high recall and 
high FPR. In addition, the tri-gram model outperformed the bi-gram model for all metrics. Given the 
different results yielded by the rule-based and n-gram statistical approaches, we present different com-
binations of these two methods for comparison. The ?OR? combination means that a given sentence is 
identified as incorrect by only one of the methods, while the ?AND? combination means that a given 
sentence is identified as incorrect by both methods. The results show that the ?OR? combination yield-
ed better recall than the individual methods, and the ?AND? combination yielded better precision and 
FPR than the individual methods. Thus, the choice of methods may depend on application require-
ments or preferences 
69
Method Precision Recall F1 False Positive Rate 
Rule 0.857 0.224 0.356 0.038 
2-gram 0.555 0.751 0.638 0.603 
3-gram 0.585 0.838 0.689 0.595 
Rule OR 2-gram 0.500 1.000 0.667 1.000 
Rule OR 3-gram 0.502 1.000 0.668 0.993 
Rule AND 2-gram 0.924 0.083 0.153 0.007 
Rule AND 3-gram 0.924 0.083 0.153 0.007 
Table 1. Comparative results of the rule-based and n-gram statistical approaches. 
 
Many learner corpora exist for EFL for use in machine learning, including the International Corpus 
of Learner English (ICLE) and Cambridge Learner Corpus (CLC). But collecting a representative 
sample of authentic errors from CFL learners poses a challenge. In addition, English and Chinese 
grammars are markedly different. In contrast to syntax-oriented English language, Chinese is dis-
course-oriented, with meaning often expressed in several clauses to make a complete sentence. These 
characteristics make syntactic parsing difficult, due to long dependency between words in a clause or 
across clauses in a sentence. These difficulties constrain system performance.  
4 Conclusions  
This study presents a sentence judgment system developed using both rule-based and n-gram statisti-
cal methods to detect grammatical errors in sentences written by CFL learners. The system not only 
alerts learners to potential grammatical errors in their input sentences, but also helps them learn about 
linguistic rules and n-gram frequencies. The major contributions of this work include: (a) demonstrat-
ingg the feasibility of detecting grammatical errors in sentences written by CFL learners, (b) develop-
ing a system to facilitate autonomous learning among CFL learners and (c) collecting real grammatical 
errors  from CFL learners for the construction of a Chinese learner corpus. 
Acknowledgments 
This research was partially supported by Ministry of Science and Technology, Taiwan under the grant 
NSC102-2221-E-155-029-MY3, NSC 102-2221-E-002-103-MY3, and the "Aim for the Top Universi-
ty Project" sponsored by the Ministry of Education, Taiwan.  
Reference 
Andreas Stolcke. 2002. SRILM ? An extensible language modeling toolkit. Proceedings of ICSLP?02, pages 
901-904. 
Chi-Hsin Yu and Hsin-Hsi Chen. 2012. Detecting word ordering errors in Chinese sentences for learning Chi-
nese as a foreign language. Proceedings of COLING?12, pages 3003-3018. 
Christopher D. Manning and Hinrich Sch?tze. 1999. Foundations of Statistical Natural Language Processing. 
MIT Press. Cambridge, MA.  
Chung-Hsien Wu, Chao-Hung Liu, Matthew Harris and Liang-Chih Yu. 2010. Sentence correction incorporating 
relative position and parse template language model. IEEE Transactions on Audio, Speech, and Language 
Processing, 18(6):1170-1181. 
Keh-Jiann Chen and Wei-Yun Ma. 2002. Unknown word extraction for Chinese documents. Proceedings of 
COLING?02, pages 169-175. 
M. Cheng. 1997. Analysis of 900 Common Erroneous Samples of Chinese Sentences - for Chinese Learners 
from English Speaking Countries (in Chinese). Beijing, CN: Sinolingua. 
Ru-Ying Chang, Chung-Hsien Wu, and Philips K. Prasetyo. 2012. Error diagnosis of Chinese sentences using 
inductive learning algorithm and decomposition-based testing mechanism. ACM Transactions on Asian Lan-
guage Information Processing, 11(1):Article 3. 
Yu-Fang Tsai and Keh-Jiann Chen. 2004. Reliable and cost-effective pos-tagging. International Journal of 
Computational Linguistics and Chinese Language Processing, 9(1):83-96. 
70
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 12?16,
Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics
Chinese Open Relation Extraction for Knowledge Acquisition Yuen-Hsien Tseng1, Lung-Hao Lee1,2, Shu-Yen Lin1, Bo-Shun Liao1,  Mei-Jun Liu1, Hsin-Hsi Chen2, Oren Etzioni3, Anthony Fader4   1Information Technology Center, National Taiwan Normal University  2Dept. of Computer Science and Information Engineering, National Taiwan University 3Allen Institute for Artificial Intelligence, Seattle, WA 4Dept. of Computer Science and Engineering, University of Washington  {samtseng, lhlee, sylin, skylock, meijun}@ntnu.edu.tw, hhchen@ntu.edu.tw, OrenE@allenai.org, afader@cs.washington.edu  Abstract 
This study presents the Chinese Open Relation Extraction (CORE) system that is able to extract entity-relation triples from Chinese free texts based on a series of NLP techniques, i.e., word segmentation, POS tagging, syntactic parsing, and extraction rules. We employ the proposed CORE techniques to extract more than 13 million entity-relations for an open domain question answering application. To our best knowledge, CORE is the first Chinese Open IE system for knowledge acquisition.  1 Introduction  Traditional Information Extraction (IE) involves human intervention of handcrafted rules or tagged examples as the input for machine learning to recognize the assertion of a particular relationship between two entities in texts (Riloff, 1996; Soderland, 1999). Although machine learning helps enumerate potential relation patterns for extraction, this approach is often limited to extracting the relation sets that are predefined. In addition, traditional IE has focused on satisfying pre-specified requests from small homogeneous corpora, leaving the question open whether it can scale up to massive and heterogeneous corpora such as the Web (Banko and Etzioni, 2008; Etzioni et al., 2008, 2011). Open IE, a new domain-independent knowledge discovery paradigm that extracts a diverse set of relations without requiring any relation-specific human inputs and a pre-specified vocabulary, is especially suited to 
massive text corpora, where target relations are unknown in advance. Several Open IE systems, such as TextRunner (Banko et al., 2007), WOE (Wu and Weld, 2010), ReVerb (Fader et al., 2011), and OLLIE (Mausam et al., 2012) achieve promising performance in open relation extraction on English sentences. However, application of these systems poses challenges to those languages that are very different from English, such as Chinese, as grammatical functions in English and Chinese are realized in markedly different ways. It is not sure whether those techniques for English still work for Chinese. This issue motivates us to extend the state-of-the-art Open IE systems to extract relations from Chinese texts. The relatively rich morpho-syntactic marking system of English (e.g., verbal inflection, nominal case, clausal markers) makes the syntactic roles of many words detectable from their surface forms. A tensed verb in English, for example, generally indicates its main verb status of a clause. The pinning down of the main verb in a Chinese clause, on the other hand, must rely on other linguistic cues such as word context due to the lack of tense markers. In contrast to the syntax-oriented English language, Chinese is discourse-oriented and rich in ellipsis ? meaning is often construable in the absence of explicit linguistic devices such that many obligatory grammatical categories (e.g., pronouns and BE verbs) can be elided in Chinese.  For example, the three Chinese sentences ???????? (?Apples nutritious?), ????????? ? (?Apples are nutritious?), and ???????? 
12
(?Apples are rich in nutrition?) are semantically synonymous sentences, but the first one, which lacks an overt verb, is used far more often than the other two. Presumably, an adequate multilingual IE system must take into account those intrinsic differences between languages. This paper introduces the Chinese Open Relation Extraction (CORE) system, which utilizes a series of NLP techniques to extract relations embedded in Chinese sentences. Given a Chinese text as the input, CORE employs word segmentation, part-of-speech (POS) tagging, and syntactic parsing, to automatically annotate the Chinese sentences. Based on this rich information, the input sentences are chunked and the entity-relation triples are extracted. Our evaluation shows the effectiveness of CORE, and its deficiency as well. 2 Related Work TextRunner (Banko et al., 2007) was the first Open IE system, which trains a Na?ve Bayes classifier with POS and NP-chunk features to extract relationships between entities. The subsequent work showed that employing the classifiers capable of modeling the sequential information inherited in the texts, like linear-chain CRF (Banko and Etzioni, 2008) and Markov Logic Network (Zhu et al., 2009), can result in better extraction performance. The WOE system (Wu and Weld, 2010) adopted Wikipedia as the training source for their extractor. Experimental results indicated that parsed dependency features lead to further improvements over TextRunner.  ReVerb (Fader et al., 2011) introduced another approach by identifying first a verb-centered relational phrase that satisfies their pre-defined syntactic and lexical constraints, and then split the input sentence into an Argument-Verb-Argument triple. This approach involves only POS tagging for English and ?regular expression?-like matching. As such, it is suitable for large corpora, and likely to be applicable to Chinese.  
For multilingual open IE, Gamallo et al. (2012) adopts a rule-based dependency parser to extract relations represented in English, Spanish, Portuguese, and Galician. For each parsed sentence, they separate each verbal clause and then identify each one?s verb participants, including their functions: subject, direct object, attribute, and prepositional complements. A set of rules is then applied on the clause constituents to extract the target triples. For Chinese open IE, we adopt a similar general approach. The main differences are the processing steps specific to Chinese language. 3 Chinese Open Relation Extraction This section describes the components of CORE. Not requiring any predefined vocabulary, CORE?s sole input is a Chinese corpus and its output is an extracted set of relational tuples. The system consists of three key modules, i.e., word segmentation and POS tagging, syntactic parsing, and entity-relation triple extraction, which are introduced as follows: Chinese is generally written without word boundaries. As a result, prior to the implementation of most NLP tasks, texts must undergo automatic word segmentation. Automatic Chinese word segmenters are generally trained by an input lexicon and probability models. However, it usually suffers from the unknown word (i.e., the out-of-vocabulary, or OOV) problem. In CORE, a corpus-based learning method to merge the unknown words is adopted to tackle the OOV problem (Chen and Ma, 2002). This is followed by a reliable and cost-effective POS-tagging method to label the segmented words with part-of-speeches (Tsai and Chen, 2004). Take the Chinese sentence ?????????? (?Edison invented the light bulb?) for instance. It was segmented and tagged as follows: ???/Nb  ??/VC  ?/Di  ??/Na. Among these words, the translation of a foreign proper name ????? (?Edison?) is not likely to be included in a lexicon and therefore is extracted by the unknown word detection method. In this case, 
13
the special POS tag ?Di? is a tag to represent a verb?s tense when its character ??? follows immediately after its precedent verb. The complete set of part-of-speech tags is defined in the technical report (CKIP, 1993). In the above sentence, ?? ? could represent a complete different meaning if it is associate with other character, such as ???? meaning ?understand?. Therefore, ????????? ? (?Edison invented a cure?) would be segmented incorrectly once ?? ? is associated with its following character, instead of its precedent word. We adopt CKIP, the best-performing parser in the bakeoff of SIGHAN 2012 (Tseng et al., 2012), to do syntactic structure analysis. The CKIP solution re-estimates the context-dependent probability for Chinese parsing and improves the performance of probabilistic context-free grammar (Hsieh et al., 2012). For the example sentence above, ????/Nb? and ??? /Na? were annotated as two nominal phrases (i.e., ?NP?), and ???/VC  ?/Di? was annotated as a verbal phrase (i.e., ?VP?). CKIP parser also adopts dependency decision-making and example-based approaches to label the semantic role ?Head?, showing the status of a word or a phrase as the pivotal constituent of a sentence (You and Chen, 2004). CORE adopts the head-driven principle to identify the main relation in a given sentence (Huang et al., 2000). Firstly, a relation is defined by both the ?Head?-labeled verb and the other words in the syntactic chunk headed by the verb. Secondly, the noun phrases preceding/preceded by the relational chunk are regarded as the candidates of the head?s arguments. Finally, the entity-relation triple is identified in the form of (entity1, relation, entity2). Regarding the example sentence described above, the triple (???/Edison, ???/invented, ??/light bulb) is extracted by this approach. Figure 1 shows the parsed tree of a Chinese sentence for the relation extraction by CORE. The Chinese sentence ???????????
????????? (?Democrats on the House Budget Committee released a report on Monday?) is the manual translation of one of the English sentences evaluated by ReVerb (Fader et al., 2011). The first step of CORE involves word-segmentation and POS-tagging, thus returning eight word/POS pairs: ??/Nc, ??/Na, ???/Nc, ?/DE, ???/Nb, ???/Nd, ??/VE, ?? /Na. Next, ???? /Nd ?? /VE? is identified as the verbal phrase that heads the sentence. This verbal phrase is regarded as the center of a potential relation. The two noun phrases before and after the verbal phrase, i.e., the NP ??? ?? ??? ? ???? and NP ???? are regarded as the entities that complete the relation. A potential entity-relation-entity triple (i.e., ??????????? / ????? / ??, ?Democrats on the House Budget Committee / on Monday released / a report?) is extracted accordingly. This triple is chunked from its original sentence fully automatically. Finally, a filtering process, which retains ?Head?-labeled words only, can be applied to strain out from each component of this triple the most prominent word: ???? / ?? / ??? (?Democrats / released / report?). 
 Figure 1: The parsed tree of a Chinese sentence. 4 Experiments and Evaluation We adopted the same test set released by ReVerb for performance evaluation. The test set consists of 500 English sentences randomly sampled from the Web and were annotated using a pooling method. To obtain ?gold standard? relation triples in Chinese, the 500 test sentences were manually translated from English to Chinese by a 
14
trained native Chinese speaker and verified by another. Additionally, two other native Chinese speakers annotated the relation triples for each Chinese sentence. In total, 716 Chinese entity-relation triples with an agreement score of 0.79 between the two annotators were obtained and regarded as gold standard.  Performance evaluation of CORE was conducted based on: 1) exact match; and 2) relation-only match. For exact match, each component of the extracted triple must be identical with the gold standard. For relation-only match, the extracted triple is regarded as a correct case if an extracted relation agreed with the relation of the gold standard.  Without another Chinese Open IE system for performance comparison, we compared CORE with a modification of ReVerb system capable of handling Chinese sentences. The modification of ReVerb?s verb-driven regular expression matching was kept to a minimum to deal with language-specific processing. As such, ReVerb remains mostly the same as its English counterpart so that a bilingual (Chinese/English) Open IE system can be easily implemented. Table 1 shows the experimental results. Our CORE system obviously performs better than ReVerb when recall is considered for both exact and relation-only match. The results suggest that utilizing more sophisticated NLP techniques is effective to extract relations without any specific human intervention. In addition, there is a slight decrease in the precision of exact match for CORE. This reveals that ReVerb?s original syntactic and lexical constraints are also useful to identify the arguments and their relationship precisely. In summary, CORE achieved relatively promising F1 scores. These results imply that CORE method is more suitable for Chinese open relation extraction. 
Chinese Open IE Precision Recall F1 Exact Match ReVerb 0.5820 0.0987 0.1688 CORE 0.5579 0.3291 0.4140 Relation Only ReVerb 0.8361 0.1425 0.2435 CORE 0.8463 0.5000 0.6286 Table 1: Performance evaluation on Chinese Open IE. 
We also analyzed the errors made by the CORE model. Almost all the errors resulted from incorrect parsing. Enhancing the parsing effectiveness is most likely to improve the performance of CORE. The relatively low recall rate also indicates that CORE misses many types of relation expression. Ellipsis and flexibility in Chinese syntax are so difficult not only to fail the parser, but also the extraction attempts to bypass the parsing errors. To demonstrate the applicability of CORE, we implement a Chinese Question-Answering (QA) system based on two million news articles from 2002 to 2009 published by the United Daily News Group (udn.com/NEWS). CORE extracted more than 13 million unique entity-relation triples from this corpus. These extracted relations are useful for knowledge acquisition. Take the question ????????? ? (?What is originated from China??) as an example, the relation is automatically identified as ?? ? (?originate?) that heads the following entity ??? ? (?China?). Our open QA system then searched the triples and returned the first entity as the answers. In addition to the obvious answer ???? (?Chinese medicine?), which is usually considered as common-sense knowledge, we also obtained those that are less known, such as the traditional Japanese food ???? (?natto?) and the musical instrument ????? (?accordion?). 5 Conclusions This work demonstrates the feasibility of extracting relations from Chinese corpus without the input of any predefined vocabulary to IE systems. This work is the first to explore Chinese open relation extraction to our best knowledge.  Acknowledgments 
This research was partially supported by National Science Council, Taiwan under grant NSC102-2221-E-002-103-MY3, and the ?Aim for the Top University Project? of National Taiwan Normal University, sponsored by the Ministry of Education, Taiwan. 
15
References  Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. Proceedings of EMNLP?11, pages 1535-1545. Chu-Ren Huang, Feng-Yi Chen, Keh-Jiann Chen, Zhao-Ming Gao, and Kuang-Yu Chen. 2000. Sinina Treebank: design criteria, annotation guidelines, and on-line interface. Proceedings of SIGHAN?00, pages 29-37. Chinese Knowledge Information Processing (CKIP) Group. 1993. Categorical analysis of Chinese. ACLCLP Technical Report # 93-05, Academia Sinica.  Fei Wu and Daniel S. Weld. 2010. Open information extraction using Wikipedia. Proceedings of ACL?10, pages 118-127. Jia-Ming You, and Keh-Jiann Chen. 2004. Automatic semantic role assignment for a tree structure.  In Proceedings of SIGHAN?04, pages 1-8. Jun Zhu, Zaiqing Nie, Xiaojiang Lium Bo Zhang, and Ji-Rong Wen. 2009. StatSnowball: a statistical approach to extracting entity relationships. In Proceedings of WWW?09, pages 101-110. Keh-Jiann Chen and Wei-Yun Ma. 2002. Unknown word extraction for Chinese documents. In Proceedings of COLING?02, pages 169-175. Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. Proceedings of IJCAI?07, pages 2670-2676. 
Michele Banko, and Oren Etzioni. 2008. The tradeoffs between open and traditional relation extraction. Proceedings of ACL?08, pages 28-26.   Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, and Mausam. 2011. Open information extraction: the second generation. In Proceedings of IJCAI?11, pages 3-10. Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S. Weld. 2008. Open information extraction from the web. Communications of the ACM, 51(12):68-74. Pablo Gamallo, Marcos Garcia, and Santiago Fern?ndez-Lanza. 2012. Dependency-based open information extraction. In Proceedings of ROBUS-UNSUP?12, pages 10-18.  Elleen Riloff. 1996. Automatically constructing extraction patterns from untagged text. In Proceedings of AAAI?96, pages 1044-1049.  Stephen Soderland. 1999. Learning information extraction rules for semi-structured and free text.  Machine Learning, 34(1-3):233-272. Yu-Ming Hsieh, Ming-Hong Bai, Jason S. Chang, and Keh-Jiann Chen. 2012. Improving PCFG Chinese Parsing with Context-Dependent Probability Re-estimation. Proceedings of CLP?12, pages 216-221. Yu-Fang Tsai, and Keh-Jiann Chen. 2004. Reliable and cost-effective pos-tagging. International Journal of Computational Linguistics and Chinese Language Processing, 9(1):83-96. Yuen-Hsien Tseng, Lung-Hao Lee, and Liang-Chih Yu 2012. Traditional Chinese parsing evaluation at SIGHAN Bake-offs 2012. Proceedings of CLP?12, pages 199-205.   
16
