BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 1?9,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
A Graph Kernel for Protein-Protein Interaction Extraction
Antti Airola, Sampo Pyysalo, Jari Bjo?rne, Tapio Pahikkala, Filip Ginter and Tapio Salakoski
Turku Centre for Computer Science
and Department of IT, University of Turku
Joukahaisenkatu 3-5
20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
In this paper, we propose a graph kernel
based approach for the automated extraction
of protein-protein interactions (PPI) from sci-
entific literature. In contrast to earlier ap-
proaches to PPI extraction, the introduced all-
dependency-paths kernel has the capability
to consider full, general dependency graphs.
We evaluate the proposed method across five
publicly available PPI corpora providing the
most comprehensive evaluation done for a ma-
chine learning based PPI-extraction system.
Our method is shown to achieve state-of-the-
art performance with respect to comparable
evaluations, achieving 56.4 F-score and 84.8
AUC on the AImed corpus. Further, we iden-
tify several pitfalls that can make evaluations
of PPI-extraction systems incomparable, or
even invalid. These include incorrect cross-
validation strategies and problems related to
comparing F-score results achieved on differ-
ent evaluation resources.
1 Introduction
Automated protein-protein interaction (PPI) extrac-
tion from scientific literature is a task of significant
interest in the BioNLP field. The most commonly
addressed problem has been the extraction of binary
interactions, where the system identifies which pro-
tein pairs in a sentence have a biologically relevant
relationship between them. Proposed solutions in-
clude both hand-crafted rule-based systems and ma-
chine learning approaches (see e.g. (Bunescu et al,
2005)). A wide range of results have been reported
for the systems, but as we will show, differences in
evaluation resources, metrics and strategies make di-
rect comparison of these numbers problematic. Fur-
ther, the results gained from the BioCreative II eval-
uation, where the best performing system achieved
a 29% F-score (Hunter et al, 2008), suggest that the
problem of extracting binary protein protein interac-
tions is far from solved.
The public availability of large annotated PPI-
corpora such as AImed (Bunescu et al, 2005),
BioInfer (Pyysalo et al, 2007a) and GENIA (Kim
et al, 2008), provides an opportunity for building
PPI extraction systems automatically using machine
learning. A major challenge is how to supply the
learner with the contextual and syntactic informa-
tion needed to distinguish between interactions and
non-interactions. To address the ambiguity and vari-
ability of the natural language expressions used to
state PPI, several recent studies have focused on
the development, adaptation and application of NLP
tools for the biomedical domain. Many high-quality
domain-specific tools are now freely available, in-
cluding full parsers such as that introduced by Char-
niak and Lease (2005). Additionally, a number
of conversions from phrase structure parses to de-
pendency structures that make the relationships be-
tween words more directly accessible have been in-
troduced. These include conversions into represen-
tations such as the Stanford dependency scheme (de
Marneffe et al, 2006) that are explicitly designed for
information extraction purposes. However, special-
ized feature representations and kernels are required
to make learning from such structures possible.
Approaches such as subsequence kernels
(Bunescu and Mooney, 2006), tree kernels (Zelenko
1
interaction of P1 and P2
prep_of> conj_and>prep_of>
P1 is a P2 binding protein
<nn<nn
<det<cop
<nsubj
P1 fails to bind P2
<nsubj <aux dobj>xcomp>
<xsubj
Figure 1: Stanford dependency parses (?collapsed? rep-
resentation) where the shortest path, shown in bold, ex-
cludes important words.
et al, 2003) and shortest path kernels (Bunescu
and Mooney, 2005) have been proposed and suc-
cessfully used for relation extraction. However,
these methods lack the expressive power to consider
representations derived from general, possibly
cyclic, dependency graph structures, such as those
generated by the Stanford tools. The subsequence
kernel approach does not consider parses at all, and
the shortest path approach is limited to representing
only a single path in the full dependency graph,
which excludes relevant words even in many simple
cases (Figure 1). Tree kernels can represent more
complex structures, but are still restricted to tree
representations.
Lately, in the framework of kernel-based machine
learning methods there has been an increased in-
terest in designing kernel functions for graph data.
Building on the work of Ga?rtner et al (2003),
graph representations tailored for the task of depen-
dency parse ranking were proposed by Pahikkala et
al. (2006b). Though the proposed representations
are not directly applicable to the task of PPI extrac-
tion, they offer insight in how to learn from depen-
dency graphs. We develop a graph kernel approach
for PPI extraction based on these ideas.
We next define a graph representation suitable for
describing potential interactions and introduce a ker-
nel which makes efficient learning from a general,
unrestricted graph representation possible. Then we
provide a short description of the sparse regular-
ized least squares (sparse RLS) kernel-based ma-
chine learning method we use for PPI-extraction.
Further, we rigorously assess our method on five
publicly available PPI corpora, providing the first
broad cross-corpus evaluation with a machine learn-
ing approach to PPI extraction. Finally, we discuss
the effects that different evaluation strategies, choice
of corpus and applied metrics have on measured per-
formance, and conclude.
2 Method
We next present our graph representation, formalize
the notion of graph kernels, and present our learning
method of choice, the sparse RLS.
2.1 Graph encoding of sentence structure
As in most recent work on machine learning for PPI
extraction, we cast the task as learning a decision
function that determines for each unordered candi-
date pair of protein names occurring together in a
sentence whether the two proteins interact. In the
following, we first define the graph representation
used to represent an interaction candidate pair. We
then proceed to derive the kernel used to measure
the similarities of these graphs.
We assume that the input of our learning method
is a dependency parse of a sentence where a pair of
protein names is marked as the candidate interac-
tion for which an extraction decision must be made.
Based on this, we form a weighted, directed graph
that consists of two unconnected subgraphs. One
represents the dependency structure of the sentence,
and the other the linear order of the words (see Fig-
ure 2).
The first subgraph is built from the dependency
analysis. One vertex and an associated set of labels
is created in the graph for each token and for each
dependency. The vertices that represent tokens have
as labels the text and part-of-speech (POS) of the
token. To ensure generalization of the learned ex-
traction model, the labels of vertices that correspond
to protein names are replaced with PROT1, PROT2
or PROT, where PROT1 and PROT2 are the pair of
interest. The vertices that represent dependencies
are labeled with the type of the dependency. The
edges in the subgraph are defined so that each de-
pendency vertex is connected by an incoming edge
from the vertex representing its governor token, and
by an outgoing edge to the vertex representing its de-
2
Figure 2: Graph representation generated from an example sentence. The candidate interaction pair is marked as
PROT1 and PROT2, the third protein is marked as PROT. The shortest path between the proteins is shown in bold. In
the dependency based subgraph all nodes in a shortest path are specialized using a post-tag (IP). In the linear order
subgraph possible tags are (B)efore, (M)iddle, and (A)fter. For the other two candidate pairs in the sentence, graphs
with the same structure but different weights and labels would be generated.
pendent token. The graph thus represents the entire
sentence structure.
It is widely acknowledged that the words between
the candidate entities or connecting them in a syn-
tactic representation are particularly likely to carry
information regarding their relationship; (Bunescu
and Mooney, 2005) formalize this intuition for de-
pendency graphs as the shortest path hypothesis. We
apply this insight in two ways in the graph repre-
sentation: the labels of the nodes on the shortest
undirected paths connecting PROT1 and PROT2 are
differentiated from the labels outside the paths us-
ing a special tag. Further, the edges are assigned
weights; after limited preliminary experiments, we
chose a simple weighting scheme where all edges
on the shortest paths receive a weight of 0.9 and
other edges receive a weight of 0.3. The represen-
tation thus allows us to emphasize the shortest path
without completely disregarding potentially relevant
words outside of the path.
The second subgraph is built from the linear struc-
ture of the sentence. For each token, a second ver-
tex is created and the labels for the vertices are de-
rived from the texts, POS-tags and named entity tag-
ging as above. The labels of each word are special-
ized to denote whether the word appears before, in-
between, or after the protein pair of interest. Each
word node is connected by an edge to its succeed-
ing word, as determined by sentence order the of the
words. Each edge is given the weight 0.9.
2.2 The all-dependency-paths graph kernel
We next formalize the graph representation and
present the all-dependency-paths kernel. This ker-
nel can be considered as a practical instantiation of
the theoretical graph kernel framework introduced
by Ga?rtner et al (2003). Let V be the set of ver-
tices in the graph and L be the set of possible labels
vertices can have. We represent the graph with an
adjacency matrix A ? R|V |?|V |, whose rows and
columns are indexed by the vertices, and [A]i,j con-
tains the weight of the edge connecting vi ? V and
vj ? V if such an edge exists, and zero otherwise.
Further, we represent the labels as a label allocation
matrix L ? R|L|?|V | so that Li,j = 1 if the j-th
vertex has the i-th label and Li,j = 0 otherwise. Be-
cause only a very small fraction of all the possible
labels are ever assigned to any single node, this ma-
trix is extremely sparse.
It is well known that when an adjacency matrix is
multiplied with itself, each element [A2]i,j contains
the summed weight of paths from vertex vi to vertex
vj through one intervening vertex, that is, paths of
length two. Similarly, for any length n, the summed
weights from vi to vj can be determined by calculat-
ing [An]i,j .
Since we are interested not only in paths of one
specific length, it is natural to combine the effect of
paths of different lengths by summing the powers
of the adjacency matrices. We calculate the infinite
sum of the weights of all possible paths connecting
3
the vertices using the Neumann Series, defined as
(I ?A)?1 = I + A + A2 + ... =
??
k=0
Ak
if |A| < 1 where |A| is the spectral radius of A
(Meyer, 2000). From this sum we can form a new
adjacency matrix
W = (I ?A)?1 ? I .
The final adjacency matrix contains the summed
weights of all possible paths connecting the ver-
tices. The identity matrix is subtracted to remove
the paths of length zero, which would correspond to
self-loops.
Next, we present the graph kernel that utilizes the
graph representation defined previously. We define
an instance G representing a candidate interaction
as G = LWLT, where L and W are the label al-
location matrix and the final adjacency matrix cor-
responding to the graph representation of the candi-
date interaction.
Following Ga?rtner et al (2003) the graph kernel
is defined as
k(G?, G??) =
|L|?
i=1
|L|?
j=1
G?i,jG
??
i,j ,
where G? and G?? are two instances formed as de-
fined previously. The features can be thought as
combinations of labels from connected pairs of ver-
tices, with a value that represents the strength of
their connection. In practical implementations, the
full G matrices, which consist mostly of zeroes, are
never explicitly formed. Rather, only the non-zero
elements are stored in memory and used when cal-
culating the kernels.
2.3 Scalable learning with Sparse RLS
RLS is a state-of-the-art kernel-based machine
learning method which has been shown to have
comparable performance to support vector machines
(Rifkin et al, 2003). We choose the sparse version
of the algorithm, also known as subset of regressors,
as it allows us to scale up the method to very large
training set sizes. Sparse RLS also has the property
that it is possible to perform cross-validation and
regularization parameter selection so that their time
complexities are negligible compared to the training
complexity. These efficient methods are analogous
to the ones proposed by Pahikkala et al (2006a) for
the basic RLS regression.
We now briefly present the basic sparse RLS al-
gorithm. Let m denote the training set size and
M = {1, . . . ,m} an index set in which the indices
refer to the examples in the training set. Instead of
allowing functions that can be expressed as a linear
combination over the whole training set, as in the
case of basic RLS regression, we only allow func-
tions of the following restricted type:
f(?) =
?
i?B
aik(?, xi), (1)
where k is the kernel function, xi are training data
points, ai ? R are weights, and the set indexing the
basis vectors B ? M is selected in advance. The co-
efficients ai that determine (1) are obtained by min-
imizing
m?
i=1
(yi ?
?
j?B
ajk(xi, xj))
2 + ?
?
i,j?B
aiajk(xi, xj),
where the first term is the squared loss function, the
second term is the regularizer, and ? ? R+ is a reg-
ularization parameter. Note that all the training in-
stances are used for determining the coefficient vec-
tor. The minimizer is obtained by solving the corre-
sponding system of linear equations, which can be
performed in O(m|B|2) time.
We set the maximum number of basis vectors to
4000 in all experiments in this study. The subset
is selected randomly when the training set size ex-
ceeds this number. Other methods for the selection
of the basis vectors were considered by Rifkin et
al. (2003), who however reported that the random
selection worked as well as the more sophisticated
approaches.
3 Experimental evaluation
We next describe the evaluation resources and met-
rics used, provide a comprehensive evaluation of our
method across five PPI corpora, and compare our re-
sults to earlier work. Further, we discuss the chal-
lenges inherent in providing a valid method evalua-
tion and propose solutions.
4
Statistics Graph Kernel Co-occ.
Corpus #POS. #NEG. P R F ?F AUC ?AUC P F
AIMed 1000 4834 0.529 0.618 0.564 0.050 0.848 0.023 0.178 0.301
BioInfer 1370 8924 0.477 0.599 0.529 0.053 0.849 0.065 0.135 0.237
HPRD50 163 270 0.643 0.658 0.634 0.114 0.797 0.063 0.389 0.554
IEPA 335 482 0.696 0.827 0.751 0.070 0.851 0.051 0.408 0.576
LLL 164 166 0.725 0.872 0.768 0.178 0.834 0.122 0.559 0.703
Table 1: Counts of positive and negative examples in the corpora and (P)recision, (R)ecall (F)-score and AUC for the
graph kernel, with standard deviations provided for F and AUC.
3.1 Corpora and evaluation criteria
We evaluate our method using five publicly avail-
able corpora that contain PPI interaction annotation:
AImed (Bunescu et al, 2005), BioInfer (Pyysalo et
al., 2007a), HPRD50 (Fundel et al, 2007), IEPA
(Ding et al, 2002) and LLL (Ne?dellec, 2005). All
the corpora were processed to a common format us-
ing transformations1 that we have introduced ear-
lier (Pyysalo et al, 2008). We parse these cor-
pora with the Charniak-Lease parser (Charniak and
Lease, 2005), which has been found to perform best
among a number of parsers tested in recent domain
evaluations (Clegg and Shepherd, 2007; Pyysalo et
al., 2007b). The Charniak-Lease phrase structure
parses are transformed into the collapsed Stanford
dependency scheme using the Stanford tools (de
Marneffe et al, 2006). We cast the PPI extraction
task as binary classification, where protein pairs that
are stated to interact are positive examples and other
co-occuring pairs negative. Thus, from each sen-
tence,
(n
2
)
examples are generated, where n is the
number of occurrences of protein names in the sen-
tence. Finally, we form the graph representation de-
scribed earlier for each candidate interaction.
We evaluate the method with 10-fold document-
level cross-validation on all of the corpora. This
guarantees the maximal use of the available data,
and also allows comparison to relevant earlier work.
In particular, on the AImed corpus we apply the ex-
act same 10-fold split that was used by Bunescu et
al. (2006) and Giuliano et al (2006). Performance
is measured according to the following criteria: in-
teractions are considered untyped, undirected pair-
wise relations between specific protein mentions,
that is, if the same protein name occurs multiple
1Available at http://mars.cs.utu.fi/PPICorpora.
times in a sentence, the correct interactions must be
extracted for each occurrence. Further, we do not
consider self-interactions as candidates and remove
them from the corpora prior to evaluation.
The majority of PPI extraction system evaluations
use the balanced F-score measure for quantifying the
performance of the systems. This metric is defined
as F = 2prp+r , where p is precision and r recall. Like-
wise, we provide F-score, precision, and recall val-
ues in our evaluation. It should be noted that F-score
is very sensitive to the underlying positive/negative
pair distribution of the corpus ? a property whose
impact on evaluation is discussed in detail below. As
an alternative to F-score, we also evaluate the per-
formance of our system using the area under the re-
ceiver operating characteristics curve (AUC) mea-
sure (Hanley and McNeil, 1982). AUC has the im-
portant property that it is invariant to the class dis-
tribution of the used dataset. Due to this and other
beneficial properties for comparative evaluation, the
usage of AUC for performance evaluation has been
recently advocated in the machine learning commu-
nity (see e.g. (Bradley, 1997)). Formally, AUC can
be defined as
AUC =
?m+
i=1
?m?
j=1H(xi ? yi)
m+m?
,
where m+ and m? are the numbers of positive
and negative examples, respectively, and x1,...,xm+
are the outputs of the system for the positive, and
y1,...,ym? for the negative examples, and
H(r) =
?
?
?
1, if r > 0
0.5, if r = 0
0, otherwise.
The measure corresponds to the probability that
given a randomly chosen positive and negative ex-
5
ample, the system will be able to correctly disin-
guish which one is which.
3.2 Performance across corpora
The performance of our method on the five corpora
for the various metrics is presented in Table 1. For
reference, we show also the performance of the co-
occurrence (or all-true) baseline, which simply as-
signs each candidate into the interaction class. The
recall of the co-occurrence method is trivially 100%,
and in terms of AUC it has a score of 0.5, the ran-
dom baseline. All the numbers in Table 1 are aver-
ages taken over the ten folds. One should note that
because of the non-linearity of the F-score measure,
the average precision and recall will not produce ex-
actly the average F.
The results hold several interesting findings. First,
we briefly observe that on the AImed corpus, which
has recently been applied in numerous evaluations
(S?tre et al, 2008) and can be seen as an emerging
de facto standard for PPI extraction method evalua-
tion, the method achieves an F-score performance of
56.4%. As we argue in more detail below, this level
of performance is comparable to the state-of-the-art
in machine learning based PPI extraction. For the
other large corpus, BioInfer, F-score performance is
slightly lower.
Second, we observe that the F-score performance
of the method varies strikingly between the differ-
ent corpora, with results on IEPA and LLL approx-
imately 20 percentage units higher than on AImed
and BioInfer, despite the larger size of the latter two.
In our previous work we have observed similar re-
sults with a rule-based extraction method (Pyysalo et
al., 2008). As the first broad cross-corpus evaluation
using a state-of-the-art machine learning method for
PPI extraction, our results support and extend the
key finding that F-score performance results mea-
sured on different corpora cannot, in general, be
meaningfully compared.
The co-occurrence baseline numbers indicate one
reason for the high F-score variance between the
corpora. The F-score metric is not invariant to the
distribution of positive and negative examples: for
example, halving the number of negative test exam-
ples is expected to approximately halve the number
of false positives at a given recall point. Thus, the
greater the fraction of true interactions in a corpus
is, the easier it is to reach high performance in terms
of F-score. This is reflected in co-occurrence re-
sults, which range from 24% to 70% depending on
the class distribution of the corpus.
This is a critical weakness of the F-score metric in
cross-corpus comparisons as, for example, the frac-
tion of true interactions out of all candidates is 50%
on the LLL corpus but only 17% on AImed. By
contrast to the large differences in performance mea-
sured using F-score, we find that for the distribution-
invariant AUC measure the performance for all of
the AImed, BioInfer, IEPA, and LLL corpora falls in
the narrow range of 83-85%. In terms of AUC, per-
formance on the HPRD50 corpus is an outlier, being
approximately three percentage units lower than for
any other corpus. Nevertheless, the results provide a
strong argument in favor of applying the AUC met-
ric instead of, or in addition to, F-score. AUC is also
more stable in terms of variance.
Finally, we note that the similar performance in
terms of AUC for corpora with as widely differing
sizes as LLL and BioInfer indicates that past a rel-
atively modest number of examples, increasing cor-
pus size has a surprisingly small effect on the perfor-
mance of the method. A similar finding can be seen,
for example, in the relatively flat learning curve of
Giuliano et al (2006). While the issue requires fur-
ther investigation, these results suggest that there
may be more value in investing effort in develop-
ing better learning methods as opposed to larger cor-
pora.
3.3 Performance compared to other methods
We next discuss the performance of our method
compared to other methods introduced in the liter-
ature and the challenges of meaningful comparison,
where we identify three major issues.
First, as indicated by the results above, differ-
ences in the makeup of different corpora render
cross-corpus comparisons in terms of F-score es-
sentially meaningless. As F-score is typically the
only metric for which results are reported in the PPI
extraction literature, we are limited to comparing
against results on single corpora. We consider the
AImed and BioInfer evaluations to be the most rele-
vant ones, as these corpora are sufficiently large for
training and reliably testing machine learning meth-
ods. As the present study is, to the best of our knowl-
6
P R F
(Giuliano et al, 2006) 60.9% 57.2% 59.0%
All-dependency-paths graph kernel 52.9% 61.8% 56.4%
(Bunescu and Mooney, 2006) 65.0% 46.4% 54.2%
(S?tre et al, 2008) 64.3% 44.1% 52.0%
(Mitsumori et al, 2006) 54.2% 42.6% 47.7%
(Yakushiji et al, 2005) 33.7% 33.1% 33.4%
Table 2: (P)recision, (R)ecall and (F)-score results for methods evaluated on AImed with the correct cross-validation
methodology.
edge, the first to report machine learning method
performance on BioInfer, we will focus on AImed
in the following comparison.
Second, the cross-validation strategy used in eval-
uation has a large impact on measured performance.
In earlier system evaluations, two major strategies
for defining the splits used in cross-validation can
be observed. The approach used by Bunescu and
Mooney (2006), which we consider the correct one,
is to split the data into folds on level of docu-
ments. This guarantees that all pairs generated from
the same document are always either in the train-
ing set or in the test set. Another approach is to
pool all the generated pairs together, and then ran-
domly split them to folds. To illustrate the signifi-
cance of this choice, consider two interaction candi-
dates extracted from the same sentence, e.g. from
a statement of the form ?P1 and P2 [. . . ] P3?,
where ?[. . . ]? is any statement of interaction or non-
interaction. Due to the near-identity of contexts, a
machine learning method will easily learn to predict
that the label of the pair (P1, P2) should match that
of (P1, P3). However, such ?learning? will clearly
not generalize. This approach must thus be consid-
ered invalid, because allowing pairs generated from
same sentences to appear in different folds leads to
an information leak between the training and test
sets. S?tre et al (2008) observed that adopting the
latter cross-validation strategy on AImed could lead
up to 18 F-score percentage unit overestimation of
performance. For this reason, we will not consider
results listed in the ?False 10-fold cross-validation?
table (2b) of S?tre et al (2008).
With these restrictions in place, we now turn to
comparison with relevant results reported in related
research, summarized in Table 2. We note that
Bunescu and Mooney (2006) only applied evalua-
tion criteria where it is enough to extract only one
occurrence of each mention of an interaction from
each abstract, while the other results shown were
evaluated using the same criteria as applied here.
The former approach can produce higher perfor-
mance: the evaluation of Giuliano et al (2006) in-
cludes both alternatives, and their method achieves
an F-score of 63.9% under the former criterion,
which they term One Answer per Relation in a
given Document (OARD). Our method outperforms
most studies using similar evaluation methodology,
with the exception being the approach of Giuliano
et al (2006). This result is somewhat surprising,
as the method proposed by Giuliano does not ap-
ply any form of parsing but relies instead only on
the sequential order of the words. This brings us
to our third point regarding comparability of meth-
ods. As pointed out by S?tre et al (2008), the
AImed corpus allows remarkably different ?inter-
pretations? regarding the number of interacting and
non-interacting pairs. For example, where we have
identified 1000 interacting and 4834 non-interacting
protein pairs in AImed, in the data used by Giuliano
there are eight more interacting and 200 fewer non-
interacting pairs. The corpus can also be prepro-
cessed in a number of ways. In particular we noticed
that whereas protein names are always blinded in our
data, in the data used by Giuliano protein names are
sometimes partly left visible. As Giuliano has gen-
erously made his method implementation available2,
we were able to test the performance of his system
on the data we used in our experiments. This re-
sulted in an F-score of 52.4%.
Finally, there remains an issue of parameter se-
lection. For sparse RLS the values of the regular-
2Available at http://tcc.itc.it/research/
textec/tools-resources/jsre.html.
7
ization parameter ? and the decision threshold sep-
arating the positive and negative classes must be
chosen, which can be problematic when no sepa-
rate data for choosing them is available. Choos-
ing from several parameter values the ones that give
best results in testing, or picking the best point
from a precision/recall curve when evaluating in
terms of F-score, will lead to an overoptimistic eval-
uation of performance. This issue has often not
been addressed in earlier evaluations that do cross-
validation on a whole corpus. We choose the pa-
rameters by doing further leave-one-document-out
cross-validation within each round of 10-fold-cross-
validation, on the nine folds that constitute the train-
ing set.
As a conclusion, we observe the results achieved
with the all-dependency-paths kernel to be state-of-
the-art level. However, differences in evaluation
strategies and the large variance exhibited in the re-
sults make it impossible to state which of the sys-
tems considered can be expected in general to per-
form best. We encourage future PPI-system evalua-
tions to report AUC and F-score results over mul-
tiple corpora, following clearly defined evaluation
strategies, to bring further clarity to this issue.
4 Conclusions and future work
In this paper we have proposed a graph kernel
approach to extracting protein-protein interactions,
which captures the information in unrestricted de-
pendency graphs to a format that kernel based learn-
ing algorithms can process. The method combines
syntactic analysis with a representation of the lin-
ear order of the sentence, and considers all possi-
ble paths connecting any two vertices in the result-
ing graph. We demonstrate state-of-the art perfor-
mance for the approach. All software developed in
the course of this study is made publicly available at
http://mars.cs.utu.fi/PPICorpora.
We identify a number of issues which make re-
sults achieved with different evaluation strategies
and resources incomparable, or even incorrect. In
our experimental design we consider the problems
related to differences across corpora, the effects dif-
ferent cross-validation strategies have, and how pa-
rameter selection can be done. Our recommendation
is to provide evaluations over different corpora, to
use document-level cross-validation and to always
selected parameters on the training set.
We draw attention to the behaviour of the F-score
metric over corpora with differing pair distributions.
The higher the relative frequency of interacting pairs
is, the higher the performance can be expected to
be. This is noticed both for the graph kernel method
and for the naive co-occurrence baseline. Indeed,
the strategy of just stating that all pairs interact leads
to as high result as 70% F-score on one of the cor-
pora. We consider AUC as an alternative measure
that does not exhibit such behaviour, as it is invari-
ant to the distribution of pairs. The AUC metric is
much more stable across all the corpora, and never
gives better results than random for approaches such
as the naive co-occurrence.
Though we only consider binary interactions in
this work, the graph representations have the prop-
erty that they could be used to represent more com-
plex structures than pairs. The availability of cor-
pora that annotate complex interactions, such as the
full BioInfer and GENIA, makes training a PPI ex-
traction system for extracting complex interactions
an important avenue of future research. However,
how to avoid the combinatorial explosion following
from considering triplets, quartets etc. remains an
open question. Also, the performance of the cur-
rent approaches may need to be yet improved before
extending them to recognize complex interactions.
Acknowledgements
We would like to thank Razvan Bunescu, Claudio
Giuliano and Rune S?tre for their generous assis-
tance in providing us with data, software and infor-
mation about their work on PPI extraction. Further,
we thank CSC, the Finnish IT center for science,
for providing us extensive computational resources.
This work has been supported by the Academy of
Finland and the Finnish Funding Agency for Tech-
nology and Innovation, Tekes.
References
Andrew P. Bradley. 1997. The use of the area under
the ROC curve in the evaluation of machine learning
algorithms. Pattern Recognition, 30(7):1145?1159.
Razvan Bunescu and Raymond Mooney. 2005. A short-
est path dependency kernel for relation extraction. In
Proceedings of HLT/EMNLP?05, pages 724?731.
8
Razvan Bunescu and Raymond Mooney. 2006. Subse-
quence kernels for relation extraction. In Proceedings
of NIPS?05, pages 171?178. MIT Press.
Razvan C. Bunescu, Ruifang Ge, Rohit J. Kate, Ed-
ward M. Marcotte, Raymond J. Mooney, Arun Ku-
mar Ramani, and Yuk Wah Wong. 2005. Compar-
ative experiments on learning information extractors
for proteins and their interactions. Artif Intell Med,
33(2):139?155.
Eugene Charniak and Matthew Lease. 2005. Parsing
biomedical literature. In Proceedings of IJCNLP?05,
pages 58?69.
Andrew Brian Clegg and Adrian Shepherd. 2007.
Benchmarking natural-language parsers for biological
applications using dependency graphs. BMC Bioinfor-
matics, 8(1):24.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In Pro-
ceedings of LREC?06, pages 449?454.
J. Ding, D. Berleant, D. Nettleton, and E. Wurtele. 2002.
Mining MEDLINE: abstracts, sentences, or phrases?
In Proceedings of PSB?02, pages 326?337.
Katrin Fundel, Robert Kuffner, and Ralf Zimmer. 2007.
RelEx?Relation extraction using dependency parse
trees. Bioinformatics, 23(3):365?371.
Thomas Ga?rtner, Peter A. Flach, and Stefan Wrobel.
2003. On graph kernels: Hardness results and efficient
alternatives. In COLT?03, pages 129?143. Springer.
Claudio Giuliano, Alberto Lavelli, and Lorenza Romano.
2006. Exploiting shallow linguistic information for re-
lation extraction from biomedical literature. In Pro-
ceedings of EACL?06.
James A. Hanley and B. J. McNeil. 1982. The meaning
and use of the area under a receiver operating charac-
teristic (roc) curve. Radiology, 143(1):29?36.
Lawrence Hunter, Zhiyong Lu, James Firby, William A.
Baumgartner, Helen L Johnson, Philip V. Ogren, and
K. Bretonnel Cohen. 2008. OpenDMAP: An open-
source, ontology-driven concept analysis engine, with
applications to capturing knowledge regarding protein
transport, protein interactions and cell-specific gene
expression. BMC Bioinformatics, 9(78).
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Carl D. Meyer. 2000. Matrix analysis and applied linear
algebra. Society for Industrial and Applied Mathe-
matics.
Tomohiro Mitsumori, Masaki Murata, Yasushi Fukuda,
Kouichi Doi, and Hirohumi Doi. 2006. Extracting
protein-protein interaction information from biomed-
ical text with svm. IEICE - Trans. Inf. Syst., E89-
D(8):2464?2466.
Claire Ne?dellec. 2005. Learning language in logic -
genic interaction extraction challenge. In Proceedings
of LLL?05.
Tapio Pahikkala, Jorma Boberg, and Tapio Salakoski.
2006a. Fast n-fold cross-validation for regularized
least-squares. In Proceedings of SCAI?06, pages 83?
90.
Tapio Pahikkala, Evgeni Tsivtsivadze, Jorma Boberg, and
Tapio Salakoski. 2006b. Graph kernels versus graph
representations: a case study in parse ranking. In Pro-
ceedings of the ECML/PKDD?06 workshop on Mining
and Learning with Graphs.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007a. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Filip Ginter, Veronika Laippala, Ka-
tri Haverinen, Juho Heimonen, and Tapio Salakoski.
2007b. On the unification of syntactic annotations un-
der the stanford dependency scheme: A case study on
BioInfer and GENIA. In Proceedings of BioNLP?07,
pages 25?32.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari
Bjo?rne, Filip Ginter, and Tapio Salakoski. 2008.
Comparative analysis of five protein-protein interac-
tion corpora. BMC Bioinformatics, special issue,
9(Suppl 3):S6.
Ryan Rifkin, Gene Yeo, and Tomaso Poggio, 2003. Reg-
ularized Least-squares Classification, volume 190 of
NATO Science Series III: Computer and System Sci-
ences, chapter 7, pages 131?154. IOS Press.
Rune S?tre, Kenji Sagae, and Jun?ichi Tsujii. 2008. Syn-
tactic features for protein-protein interaction extrac-
tion. In Proceedings of LBM?07, volume 319, pages
6.1?6.14.
Akane Yakushiji, Yusuke Miyao, Yuka Tateisi, and
Jun?ichi Tsujii. 2005. Biomedical information ex-
traction with predicate-argument structure patterns. In
Proceedings of SMBM?05, pages 60?69.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation
extraction. J. Mach. Learn. Res., 3:1083?1106.
9
Proceedings of the Workshop on BioNLP: Shared Task, pages 10?18,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Extracting Complex Biological Events with Rich Graph-Based Feature Sets
Jari Bjo?rne,1 Juho Heimonen,1,2 Filip Ginter,1 Antti Airola,1,2
Tapio Pahikkala1 and Tapio Salakoski1,2
1Department of Information Technology, University of Turku
2Turku Centre for Computer Science (TUCS)
Joukahaisenkatu 3-5, 20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
We describe a system for extracting com-
plex events among genes and proteins from
biomedical literature, developed in context of
the BioNLP?09 Shared Task on Event Extrac-
tion. For each event, its text trigger, class, and
arguments are extracted. In contrast to the pre-
vailing approaches in the domain, events can
be arguments of other events, resulting in a
nested structure that better captures the under-
lying biological statements. We divide the task
into independent steps which we approach as
machine learning problems. We define a wide
array of features and in particular make ex-
tensive use of dependency parse graphs. A
rule-based post-processing step is used to re-
fine the output in accordance with the restric-
tions of the extraction task. In the shared task
evaluation, the system achieved an F-score of
51.95% on the primary task, the best perfor-
mance among the participants.
1 Introduction
In this paper, we present the best-performing system
in the primary task of the BioNLP?09 Shared Task
on Event Extraction (Kim et al, 2009).1 The pur-
pose of this shared task was to competitively eval-
uate information extraction systems targeting com-
plex events in the biomedical domain. Such an eval-
uation helps to establish the relative merits of com-
peting approaches, allowing direct comparability of
results in a controlled setting. The shared task was
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA/SharedTask
the first competitive evaluation of its kind in the
BioNLP field as the extraction of complex events
became possible only recently with the introduction
of corpora containing the necessary annotation: the
GENIA event corpus (Kim et al, 2008a) and the
BioInfer corpus (Pyysalo et al, 2007).
The objective of the primary task (Task 1) was
to detect biologically relevant events such as pro-
tein binding and phosphorylation, given only anno-
tation of named entities. For each event, its class,
trigger expression in the text, and arguments need to
be extracted. The task follows the recent movement
in BioNLP towards the extraction of semantically
typed, complex events the arguments of which can
also be other events. This results in a nested struc-
ture that captures the underlying biological state-
ments more accurately compared to the prevailing
approach of merely detecting binary interactions of
pairs of biological entities.
Our system is characterized by heavy reliance
on efficient, state-of-the-art machine learning tech-
niques and a wide array of features derived from
a full dependency analysis of each sentence. The
system is a pipeline of three major processing steps:
trigger recognition, argument detection and seman-
tic post-processing. By separating trigger recog-
nition from argument detection, we can use meth-
ods familiar from named entity recognition to tag
words as event triggers. Event argument detection
then becomes the task of predicting for each trigger?
trigger or trigger?named entity pair whether it cor-
responds to an actual instantiation of an event argu-
ment. Both steps can thus be approached as classi-
fication tasks. In contrast, semantic post-processing
10
Sentence?splitting
Tokenization
Parsing
Conversion?to?graph?
representation
Trigger?detection
(multi?class?SVM)
System?output
Semantic?post?processing
(rule?based)
Edge?detection
(multi?class?SVM)
Input?data
Figure 1: The main components of the system.
is rule-based, directly implementing argument type
constraints following from the definition of the task.
In the following sections, we present the imple-
mentation of the three stages of our information ex-
traction system in detail, and provide insights into
why we chose the approach we did. We also discuss
alternate directions we followed but that did not im-
prove performance. Finally, we analyze the overall
performance of our system in the shared task as well
as evaluate its components individually.
2 The system description
The overall architecture of the system is shown
in Figure 1. All steps in the system process one
sentence at a time. Since 95% of all annotated
events are fully contained within a single sentence,
this does not incur a large performance penalty but
greatly reduces the size and complexity of the ma-
chine learning problems.
2.1 Graph representation
We represent the extraction target in terms of seman-
tic networks, graphs where the nodes correspond
to named entities and events, and the edges corre-
spond to event arguments. The shared task can then
be viewed as the problem of finding the nodes and
edges of this graph. For instance, nested events are
naturally represented through edges connecting two
event nodes. The graph representation of an exam-
ple sentence is illustrated in Figure 2D.
We have previously used this graph representa-
tion for information extraction (Heimonen et al,
2008; Bjo?rne et al, 2009) as well as for establishing
the connection between events and syntactic depen-
dency parses in the Stanford scheme of de Marneffe
and Manning (2008) (Bjo?rne et al, 2008).
2.2 Trigger detection
We cast trigger detection as a token labeling prob-
lem, that is, each token is assigned to an event class,
or a negative class if it does not belong to a trig-
ger. Triggers are then formed based on the predicted
classes of the individual tokens. Since 92% of all
triggers in the data consist of a single token, adjacent
tokens with the same class prediction form a single
trigger only in case that the resulting string occurs
as a trigger in the training data. An event node is
created for each detected trigger (Figure 2B).
In rare cases, the triggers of events of different
class share a token, thus the token belongs to sev-
eral separate classes. To be able to approach trigger
detection as a multi-class classification task where
each token is given a single prediction, we intro-
duce combined classes as needed. For instance the
class gene expression/positive regulation denotes to-
kens that act as a trigger to two events of the two
respective classes. Note that this implies that the
trigger detection step produces at most one event
node per class for any detected trigger. In the shared
task, however, multiple events of the same class can
share the same trigger. For instance, the trigger in-
volves in Figure 2 corresponds to two separate regu-
lation events. A separate post-processing step is in-
troduced after event argument detection to duplicate
event nodes as necessary (see Section 2.4).
Due to the nature of the GENIA event annota-
tion principles, trigger detection cannot be easily re-
duced to a simple dictionary lookup of trigger ex-
pressions for two main reasons. First, a number of
common textual expressions act as event triggers in
some cases, but not in other cases. For example,
only 28% of the instances of the expression activates
are triggers for a positive regulation event while the
remaining 72% are not triggers for any event. Sec-
ond, a single expression may be associated with var-
ious event classes. For example, the instances of the
token overexpression are evenly distributed among
11
Regulation
Protein
IL-4 gene
Regulation
regulation
Regulation
involves
Protein
NFAT1 and
Protein
NFAT2 .
<Theme <Theme Cause> Cause>
NN NN NN VBZ NN CC .
<nn conj_and><nn dobj><nsubj
NN
Protein
IL-4 gene
Regulation
regulation
Regulation
involves
Protein
NFAT1 and
Protein
NFAT2 .
<Theme <Theme Cause>
Cause><Theme
node duplication
pars
e
T29   Regulation   regulationT30   Regulation   involvesE10   Regulation:T29   Theme:T7E11   Regulation:T30   Theme:E10   Cause:T9E12   Regulation:T30   Theme:E10   Cause:T8
equivalent
D
C
E
T7     Protein   IL-4T8     Protein   NFAT1T9     Protein   NFAT2
Protein
IL-4 gene
Regulation
regulation
Regulation
involves
Protein
NFAT1 and
Protein
NFAT2 .
Protein
IL-4 gene regulation involves
Protein
NFAT1 and
Protein
NFAT2 .
edge detection
trigger recognition
Trai
ning
 Dat
a Pr
epa
ratio
n
B
A
Eve
nt E
xtra
ction
dobj>
Figure 2: An example sentence from Shared Task document 10069428 (simplified). A) Named entities are given.
B) Triggers are detected and corresponding event nodes are created. C) Event argument edges are predicted between
nodes. The result is a sentence-level semantic network. D) One node may denote multiple events of the same class,
therefore nodes are duplicated in the semantic post-processing step. E) The resulting graph can be losslessly trans-
formed into the Shared Task event annotation. Training data for the trigger recognizer includes named entity annotation
(A) and for the edge detector the semantic network with no node duplication (C).
gene expression, positive regulation, and the nega-
tive class. In light of these properties, we address
trigger detection with a multi-class support vector
machine (SVM) classifier that assigns event classes
to individual tokens, one at a time. This is in con-
trast to sequence labeling problems such as named
entity recognition, where a sequential model is typ-
ically employed. The classifier is trained on gold-
standard triggers from the training data and incorpo-
rates a wide array of features capturing the proper-
ties of the token to be classified, both its linear and
dependency context, and the named entities within
the sentence.
Token features include binary tests for capital-
ization, presence of punctuation or numeric charac-
ters, stem using the Porter stemmer (Porter, 1980),
character bigrams and trigrams, and presence of the
token in a gazetteer of known trigger expressions
and their classes, extracted from the training data.
Token features are generated not only for the token
to be classified, but also for tokens in the immediate
linear context and dependency context (tokens that
govern or depend on the token to be classified).
Frequency features include the number of
named entities in the sentence and in a linear win-
dow around the token in question as well as bag-of-
word counts of token texts in the sentence.
Dependency chains up to depth of three are
constructed, starting from the token to be classified.
At each depth, both token features and dependency
type are included, as well as the sequence of depen-
dency types in the chain.
The trigger detector used in the shared task is
in fact a weighted combination of two indepen-
12
dent SVM trigger detectors, both based on the same
multi-class classification principle and somewhat
different feature sets.2 The predictions of the two
trigger detectors are combined as follows. For each
trigger detector and each token, the classifier confi-
dence scores of the top five classes are re-normalized
into the [0, 1] interval. The renormalized confidence
scores of the two detectors are then linearly inter-
polated using a parameter ?, 0 ? ? ? 1, whose
value is set experimentally on the development set,
as discussed below.
Setting the correct precision?recall trade-off in
trigger detection is very important. On one hand,
any trigger left undetected directly implies a false
negative event. On the other hand, the edge detec-
tor is trained on gold standard data where there are
no event nodes without arguments, which creates a
bias toward predicting edges for any event node the
edge detector is presented with. On the develop-
ment set, essentially all predicted event nodes are
given at least one argument edge. We optimize the
precision?recall trade-off explicitly by introducing a
parameter ?, 0 ? ?, that multiplies the classifier
confidence score given to the negative class, that is,
the ?no trigger? class. When ? < 1, the confidence
of the negative class is decreased, thus increasing
the possibility of a given token forming a trigger,
and consequently increasing the recall of the trigger
detector (naturally, at the expense of its precision).
Both trigger detection parameters, the interpola-
tion weight ? and the precision?recall trade-off pa-
rameter ?, are set experimentally using a grid search
to find the globally optimal performance of the en-
tire system on the development set, using the shared
task performance metric. The parameters are thus
not set to optimize the performance of trigger detec-
tion in isolation; they are rather set to optimize the
performance of the whole system.
2.3 Edge detection
After trigger detection, edge detection is used to pre-
dict the edges of the semantic graph, thus extracting
event arguments. Like the trigger detector, the edge
detector is based on a multi-class SVM classifier.
We generate examples for all potential edges, which
2This design should be considered an artifact of the time-
constrained, experiment-driven development of the system
rather than a principled design choice.
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
 50
0 1 2 3 4 5 6 7 8 9 10 >10
Pro
por
tion
 of 
edg
es [%
]
Edge length
dependency distancelinear distance
Figure 3: The distribution of event argument edge lengths
measured as the number of dependencies on the shortest
dependency path between the edge terminal nodes, con-
trasted with edge lengths measured as the linear token
distance.
are always directed from an event node to another
event node (event nesting) or from an event node to
a named entity node. Each example is then classified
as theme, cause, or a negative denoting the absence
of an edge between the two nodes in the given di-
rection. It should be noted that even though event
nodes often require multiple outgoing edges corre-
sponding to multiple event arguments, all edges are
predicted independently and are not affected by pos-
itive or negative classifications of other edges.
The feature set makes extensive use of syntac-
tic dependencies, in line with many recent stud-
ies in biomedical information extraction (see, e.g.
(Kim et al, 2008b; Miwa et al, 2008; Airola et al,
2008; Van Landeghem et al, 2008; Katrenko and
Adriaans, 2008)). The central concept in generat-
ing features of potential event argument edges is the
shortest undirected path of syntactic dependencies
in the Stanford scheme parse of the sentence which
we assume to accurately capture the relationship ex-
pressed by the edge. In Figure 3, we show that the
distances among event and named entity nodes in
terms of shortest dependency path length are con-
siderably shorter than in terms of their linear order in
the sentence. The end points of the path are the syn-
tactic head tokens of the two named entities or event
triggers. The head tokens are identified using a sim-
ple heuristic. Where multiple shortest paths exist,
all are considered. Most features are built by com-
bining the attributes of multiple tokens (token text,
13
POS tag and entity or event class, such as protein or
binding) or dependencies (type such as subject and
direction relative to surrounding tokens).
N-grams are generated by merging the at-
tributes of 2?4 consecutive tokens. N-grams are also
built for consecutive dependencies. Additional tri-
grams are built for each token and its two flank-
ing dependencies, as well as for each dependency
and its two flanking tokens. These N-grams are de-
fined in the direction of the potential event argument
edge. To take into account the varying directions
of the dependencies, each pair of consecutive tokens
forms an additional bigram defining their governor-
dependent relationship.
Individual component features are defined for
each token and edge in a path based on their
attributes which are also combined with the to-
ken/edge position at either the interior or the end of
the path. Edge attributes are combined with their di-
rection relative to the path.
Semantic node features are built by directly
combining the attributes of the two terminal
event/entity nodes of the potential event argument
edge. These features concatenate both the specific
types of the nodes (e.g. protein or binding) as well
as their categories (event or named entity). Finally,
if the events/entities have the same head token, this
self-loop is explicitly defined as a feature.
Frequency features include the length of the
shortest path as an integer-valued feature as well as
an explicit binary feature for each length. The num-
ber of named entities and event nodes, per type, in
the sentence are defined for each example.
We have used this type of edge detector with a
largely similar feature set previously (Bjo?rne et al,
2009). Also, many of these features are standard
in relation extraction studies (see, e.g., Buyko et al
(2008)).
2.4 Semantic post-processing
The semantic graph produced by the trigger and
edge detection steps is not final. In particular, it
may contain event nodes with an improper combi-
nation of arguments, or no arguments whatsoever.
Additionally, as discussed in Section 2.2, if there are
events of the same class with the same trigger, they
are represented by a single node. Therefore, we in-
troduce a rule-based post-processing step to refine
Figure 4: Example of event duplication. A) All theme?
cause combinations are generated for regulation events.
B) A heuristic is applied to decide how theme arguments
of binding events should be grouped.
the graph, using the restrictions on event argument
types and combinations defined in the shared task.
In Task 1, the allowed argument edges in the
graph are 1) theme from an event to a named en-
tity, 2) theme or cause from a regulation event (or its
subclasses) to an event or a named entity. Edges cor-
responding to invalid arguments are removed. Also,
directed cycles are broken by removing the edge
with the weakest classification confidence score.
After pruning invalid edges, event nodes are du-
plicated so that all events have a valid combination
of arguments. For example, the regulation event in-
volves in Figure 2C has two cause arguments and
therefore represents two distinct events. We thus
duplicate the event node, obtaining one regulation
event for each of the cause arguments (Figure 2D).
Events of type gene expression, transcription,
translation, protein catabolism, localization, and
phosphorylation must have exactly one theme argu-
ment, which makes the duplication process trivial:
duplicate events are created, one for each of the ar-
guments. Regulation events must have one theme
and can additionally have one cause argument. For
these classes we use a heuristic, generating a new
event for each theme?cause combination of outgo-
ing edges (Figure 4A). Binding is the only event
class that can have multiple theme arguments. There
is thus no simple way of determining how multi-
ple outgoing theme edges should be grouped (Fig-
ure 4B). We apply a heuristic that first groups the ar-
guments by their syntactic role, defined here as xthe
first dependency in the shortest path from the event
14
to the argument. It then generates an event for each
pair of arguments that are in different groups. In the
case of only one group, all single-argument events
are generated.
Finally, all events with no arguments as well as
regulation events without a theme argument are iter-
atively removed until no such event remains. The
resulting graph is the output of our event extrac-
tion system and can be losslessly converted into the
shared task format (Figure 2D&E).
2.5 Alternative directions
We now briefly describe some of the alternative di-
rections explored during the system development,
which however did not result in increased perfor-
mance, and were thus not included in the final sys-
tem. Whether the reason was due to the considered
approaches being inadequate for the extraction task,
or simply a result of the tight time constraints en-
forced by the shared task is a question only further
research can shed light on.
For the purpose of dividing the extraction prob-
lem into manageable subproblems, we make strong
independence assumptions. This is particularly the
case in the edge detection phase where each edge
is considered in isolation from other edges, some
of which may actually be associated with the same
event. Similar assumptions are made in the trigger
detection phase, where the classifications of individ-
ual tokens are independent.
A common way to relax independence assump-
tions is to use N -best re-ranking where N most-
likely candidates are re-ranked using global features
that model data dependencies that could not be mod-
elled in the candidate generation step. The best can-
didate with respect to this re-ranked order is then
the final prediction of the system. N -best re-ranking
has been successfully applied for example in statisti-
cal parsing (Charniak and Johnson, 2005). We gen-
erated the ten most likely candidate graphs, as de-
termined by the confidence scores of the individual
edges given by the multi-class SVM. A perfect re-
ranking of these ten candidates would lead to 11.5
percentage point improvement in the overall system
F-score on the development set. While we were un-
able to produce a re-ranker sufficiently accurate to
improve the system performance in the time given,
the large potential gain warrants further research.
In trigger word detection, we experimented with
a structural SVM incorporating Hidden Markov
Model type of sequential dependencies (Altun et al,
2003; Tsochantaridis et al, 2004), which allow con-
ditioning classification decisions on decisions made
for previous tokens as well as with a conditional ran-
dom field (CRF) sequence classifier (Lafferty et al,
2001). Neither of these experiments led to a perfor-
mance gain over the multiclass SVM classifier.
As discussed previously, 4.8% of all annotated
events cross sentence boundaries. This problem
could be approached using coreference resolution
techniques, however, the necessary explicit corefer-
ence annotation to train a coreference resolution sys-
tem is not present in the data. Instead, we attempted
to build a machine-learning based system to detect
cross-sentence event arguments directly, rather than
via their referring expression, but were unable to im-
prove the system performance.
3 Tools and resources
3.1 Multi-class SVM
We use a support vector machine (SVM) multi-class
classifier which has been shown to have state-of-
the-art classification performance (see e.g. (Cram-
mer and Singer, 2002; Tsochantaridis et al, 2004)).
Namely, we use the SVMmulticlass implementa-
tion3 which is one of the fastest multi-class SVM
implementations currently available. Analogously
to the binary SVMs, multi-class SVMs have a reg-
ularization parameter that determines the trade-off
between the training error and the complexity of the
learned concept. We select the value of the parame-
ter on the development set. Multi-class SVMs scale
linearly with respect to both the amount of training
data and the average number of nonzero features per
training example, making them an especially suit-
able learning method for our purposes. They also
provide a real-valued prediction for each example
to be classified which is used as a confidence score
in trigger detection precision?recall trade-off adjust-
ment and event argument edge cycle breaking in se-
mantic post-processing. We use the linear kernel,
the only practical choice to train the classifier with
the large training sets available. For example, the
3http://svmlight.joachims.org/svm_
multiclass.html
15
 0
 10
 20
 30
 40
 50
 60
 70
 80
 0  10  20  30  40  50  60  70  80
Re
cal
l [%
]
Precision [%]
Figure 5: Performance of the 24 systems that participated
in Task 1, together with an F-score contour plot for refer-
ence. Our system is marked with a full circle.
final training data of the edge detector (8932 sen-
tences) consists of 31792 training examples with
295034 unique features. Training with even this
amount of data is computationally feasible, typically
taking less than an hour.
All classifiers used in the system are trained as
follows. First we optimize the regularization param-
eter C by training on the shared task training set and
testing on the shared task development set. We then
re-train the final classifier on the union of the train-
ing and development sets, using the best value of C
in the previous step. The same protocol is followed
for the ? and ? parameters in trigger detection.
3.2 Dependency parses
Both trigger detection and edge prediction rely on
a wide array of features derived from full depen-
dency parses of the sentence. We use the McClosky-
Charniak domain-adapted parser (McClosky and
Charniak, 2008) which is among the best perform-
ing parsers trained on the GENIA Treebank corpus.
The native constituency output of the parser is trans-
formed to the ?collapsed? form of the Stanford de-
pendency scheme (de Marneffe and Manning, 2008)
using the Stanford parser tools.4 The parses were
provided by the shared task organizers.
4 Results and discussion
The final evaluation of the system was performed by
the shared task organizers using a test set whose an-
4http://nlp.stanford.edu/software/
notation was at no point available to the task partici-
pants. By the main criterion of Task 1, approximate
span matching with approximate recursive match-
ing, our system achieved an F-score of 51.95%. Fig-
ure 5 shows the performance of all systems partic-
ipating in Task 1. The per-class results in Table 1
show that regulation events (including positive and
negative regulation) as well as binding events are the
hardest to extract. These classes have F-scores in
the 31?44% range, while the other classes fall into
the 50?78% range. This is not particularly surpris-
ing since binding and regulation are the only classes
in which events can have multiple arguments, which
means that for an event to be detected correctly, the
edge detector often must make several correct pre-
dictions. Additionally, these classes have the lowest
trigger recognition performance on the development
set. It is interesting to note that the per-class perfor-
mance in Table 1 shows no clear correlation between
the number of events of a class and its F-score.
Table 2 shows the performance of the system us-
ing various other evaluation criteria defined in the
shared task. The most interesting of these is the
strict matching criterion, which, in order to consider
an event correctly extracted, requires exact trigger
span as well as all its nested events to be recursively
correct. The performance of the system with respect
to the strict criterion is 47.41% F-score, only 4.5 per-
centage points lower than the relaxed primary mea-
sure. As seen in Table 2, this difference is almost
exclusively due to triggers with incorrect span.
To evaluate the performance impact of each sys-
tem component individually, we report in Table 3
overall system performance on the development set,
obtained by progressively replacing the processing
steps with gold-standard data. The results show that
the errors of the system are almost evenly distributed
between the trigger and edge detectors. For instance,
a perfect trigger detector would decrease the overall
system error of 46.5% by 18.58 percentage points,
a relative decrease of 40%. A perfect edge detec-
tor would, in combination with a perfect trigger de-
tector, lead to system performance of 94.69%. The
improvement that could be gained by further devel-
opment of the semantic post-processing step is thus
limited, indicating that the strict argument combina-
tion restrictions of Task 1 are sufficient to resolve the
majority of post-processing cases.
16
Event Class # R P F
Protein catabolism 14 42.86 66.67 52.17
Phosphorylation 135 80.74 74.66 77.58
Transcription 137 39.42 69.23 50.23
Localization 174 49.43 81.90 61.65
Regulation 291 25.43 38.14 30.52
Binding 347 40.06 49.82 44.41
Negative regulation 379 35.36 43.46 38.99
Gene expression 722 69.81 78.50 73.90
Positive regulation 983 38.76 48.72 43.17
Total 3182 46.73 58.48 51.95
Table 1: Per-class performance in terms of Recall, Preci-
sion, and F-score on the test set (3182 events) using ap-
proximate span and recursive matching, the primary eval-
uation criterion of Task 1.
Matching R P F
Strict 42.65 53.38 47.41
Approx. Span 46.51 58.24 51.72
Approx. Span&Recursive 46.73 58.48 51.95
Table 2: Performance of our system on the test set (3182
events) with respect to other evaluation measures in the
shared task.
5 Conclusions
We have described a system for extracting complex,
typed events from biomedical literature, only assum-
ing named entities as given knowledge. The high
rank achieved in the BioNLP?09 Shared Task com-
petitive evaluation validates the approach taken in
building the system. While the performance is cur-
rently the highest achieved on this data, the F-score
of 51.95% indicates that there remains considerable
room for further development and improvement.
We use a unified graph representation of the data
in which the individual processing steps can be for-
mulated as simple graph transformations: adding or
removing nodes and edges. It is our experience that
such a representation makes handling the data fast,
easy and consistent. The choice of graph representa-
tion is further motivated by the close correlation of
these graphs with dependency parses. As we are go-
ing to explore the interpretation and applications of
these graphs in the future, the graph representation
will likely provide a flexible base to build on.
Dividing the task of event extraction into multi-
ple subtasks that can be approached by well-studied
Trig Edge PP R P F ?F
pred pred pred 51.54 55.62 53.50
GS pred pred 71.66 72.51 72.08 18.58
GS GS pred 97.21 92.30 94.69 22.61
GS GS GS 100.0 100.0 100.0 5.31
Table 3: Effect of the trigger detector (Trig), edge detec-
tor (Edge), and post-processing (PP) on performance on
the development set (1789 events). The ?F column in-
dicates the effect of replacing the predictions (pred) of
a component with the corresponding gold standard data
(GS), i.e. the maximal possible performance gain obtain-
able from further development of that component.
methods proved to be an effective approach in de-
veloping our system. We relied on state-of-the-art
machine learning techniques that scale up to the task
and allow the use of a considerable number of fea-
tures. We also carefully optimized the various pa-
rameters, a vital step when using machine learning
methods, to fine-tune the performance of the system.
In Section 2.5, we discussed alternative directions
pursued during the development of the current sys-
tem, indicating possible future research directions.
To support this future work as well as complement
the description of the system in this paper we intend
to publish our system under an open-source license.
This shared task represents the first competi-
tive evaluation of complex event extraction in the
biomedical domain. The prior research has largely
focused on binary interaction extraction, achieving
after a substantial research effort F-scores of slightly
over 60% (see, e.g., Miwa et al (2008)) on AIMed,
the de facto standard corpus for this task. Even if
a direct comparison of these results is difficult, they
suggest that 52% F-score in complex event extrac-
tion is a non-trivial achievement, especially consid-
ering the more detailed semantics of the extracted
events. Further, complex event extraction is still a
new problem ? relevant corpora having been avail-
able for only a few years.
Acknowledgments
This research was funded by the Academy of Fin-
land. Computational resources were provided by
CSC ? IT Center for Science Ltd. We thank the
shared task organizers for their efforts in data prepa-
ration and system evaluation.
17
References
Antti Airola, Sampo Pyysalo, Jari Bjo?rne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008.
All-paths graph kernel for protein-protein interaction
extraction with evaluation of cross-corpus learning.
BMC Bioinformatics, 9(Suppl 11):S2.
Yasemin Altun, Ioannis Tsochantaridis, and Thomas
Hofmann. 2003. Hidden Markov support vector ma-
chines. In Proceedings of the Twentieth International
Conference on Machine Learning (ICML?03), pages
3?10. AAAI Press.
Jari Bjo?rne, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. How complex are complex
protein-protein interactions? In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM?08), pages 125?128. TUCS.
Jari Bjo?rne, Filip Ginter, Juho Heimonen, Sampo
Pyysalo, and Tapio Salakoski. 2009. Learning to ex-
tract biological event and relation graphs. In Proceed-
ings of the 17th Nordic Conference on Computational
Linguistics (NODALIDA?09).
Ekaterina Buyko, Elena Beisswanger, and Udo Hahn.
2008. Testing different ACE-style feature sets for
the extraction of gene regulation relations from MED-
LINE abstracts. In Proceedings of the Third Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 21?28. TUCS.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL?05),
pages 173?180. ACL.
Koby Crammer and Yoram Singer. 2002. On the al-
gorithmic implementation of multiclass kernel-based
vector machines. Journal of Machine Learning Re-
search, 2:265?292.
Marie-Catherine de Marneffe and Christopher Manning.
2008. Stanford typed hierarchies representation. In
Proceedings of the COLING?08 Workshop on Cross-
Framework and Cross-Domain Parser Evaluation,
pages 1?8.
Juho Heimonen, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. Complex-to-pairwise mapping of
biological relationships using a semantic network rep-
resentation. In Proceedings of the Third Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 45?52. TUCS.
Sophia Katrenko and Pieter Adriaans. 2008. A local
alignment kernel in the context of NLP. In Proceed-
ings of the 22nd International Conference on Compu-
tational Linguistics (Coling?08).
Jin-Dong Kim, Tomoko Ohta, and Tsujii Jun?ichi. 2008a.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(1):10.
Seonho Kim, Juntae Yoon, and Jihoon Yang. 2008b.
Kernel approaches for genic interaction extraction.
Bioinformatics, 24(1):118?126.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 shared task on event extraction. In
Proceedings of the NAACL-HLT 2009 Workshop
on Natural Language Processing in Biomedicine
(BioNLP?09). ACL.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning (ICML?01), pages 282?289.
David McClosky and Eugene Charniak. 2008. Self-
training for biomedical parsing. In Proceedings of
ACL-08: HLT, Short Papers, pages 101?104. Associa-
tion for Computational Linguistics.
Makoto Miwa, Rune S?tre, Yusuke Miyao, Tomoko
Ohta, and Jun?ichi Tsujii. 2008. Combining
multiple layers of syntactic information for protein-
protein interaction extraction. In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM?08), pages 101?108. TUCS.
Martin F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130?137.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(1):50.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings of the Twenty-first Inter-
national Conference on Machine Learning (ICML?04),
pages 104?111. ACM.
Sofie Van Landeghem, Yvan Saeys, Bernard De Baets,
and Yves Van de Peer. 2008. Extracting protein-
protein interactions from text using rich feature vec-
tors and feature selection. In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM?08), pages 77?84. TUCS.
18
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 651?659, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
UTurku: Drug Named Entity Recognition and Drug-Drug Interaction
Extraction Using SVM Classification and Domain Knowledge
Jari Bjo?rne, Suwisa Kaewphan and Tapio Salakoski
Turku Centre for Computer Science (TUCS)
Department of Information Technology
University of Turku
Joukahaisenkatu 3-5B, 20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
The DDIExtraction 2013 task in the SemEval
conference concerns the detection of drug
names and statements of drug-drug interac-
tions (DDI) from text. Extraction of DDIs
is important for providing up-to-date knowl-
edge on adverse interactions between co-
administered drugs. We apply the machine
learning based Turku Event Extraction Sys-
tem to both tasks. We evaluate three fea-
ture sets, syntactic features derived from deep
parsing, enhanced optionally with features de-
rived from DrugBank or from both DrugBank
and MetaMap. TEES achieves F-scores of
60% for the drug name recognition task and
59% for the DDI extraction task.
1 Introduction
Drug-drug interactions (DDI) refer to one drug af-
fecting the function of another when they are co-
administered. These interactions are often adverse,
frequently not well known and a source of poten-
tially life-threatening unintended consequences for
the patients. Databases such as DrugBank and Mi-
cromedex have been developed to store informa-
tion about known DDIs, but at present their cover-
age remains limited and there can be inconsistencies
in supplementary information (Knox et al, 2011;
Wong et al, 2008). Text mining has been proposed
as a solution for providing not only lists of DDIs
but also a connection to the scientific evidence and
supplementary information in the literature (Tari et
al., 2010). Several groups of researchers are devel-
oping text-mining techniques to extract DDIs from
literature and pharmaceutical documents (Tari et al,
2010; Segura-Bedmar et al, 2011a).
The DDIExtraction 2013 shared task concerns the
detection of drug mentions and statements of DDIs
from unannotated text (Segura-Bedmar et al, 2013).
The first version of the DDIExtraction shared task
was organized in 2011, with 10 teams participat-
ing from various universities (Segura-Bedmar et al,
2011b). The best result of 65.74% was achieved
by team WBI of Humboldt University of Berlin
(Thomas et al, 2011). University of Turku partic-
ipated also in this task, placing 4th with an F-score
of 62.99%, using the Turku Event Extraction System
(Bjo?rne et al, 2011).
The Turku Event Extraction System (TEES)1 is
an open source program for extracting events and re-
lations from biomedical texts. It was originally de-
veloped for extracting events in the BioNLP Shared
Task scheme, and it models event extraction as a
graph generation task, where keywords are nodes
and the event arguments connecting them are edges.
The system can be directly applied to pairwise re-
lation extraction, representing relations as edges and
the words they connect as nodes. The node detection
system is somewhat similar to named entity recog-
nition (NER) tools, and while quite flexible, can in
many tasks exhibit lower performance and higher
processing requirements than dedicated NER sys-
tems.
In the DDIExtraction 2013 task we apply the
Turku Event Extraction system to detecting both
drug name entities (task 9.1) as well as drug-drug
interactions (task 9.2). We evaluate three different
1http://jbjorne.github.com/TEES/
651
feature sets for both tasks. As a baseline system deep
syntactic parsing is used to generate large graph-
based feature sets. For additional features, we test
the impact of labeling examples with information
from external sources. We test both the DrugBank
Open Data Drug & Drug Target database (Knox et
al., 2011) as well as the MetaMap tool to enrich the
features derived from the corpus text.
MetaMap is a publicly available program devel-
oped at NLM for automatic mapping of texts to
UMLS Metathesaurus concepts (Aronson, 2001).
The UMLS Metathesaurus is an extensive reposi-
tory of biomedical vocabularies that is derived from
NLM databases and other external sources that con-
tain information about biomedical concepts, syn-
onyms and the relationship among them (Bodenrei-
der, 2004).
The version of TEES used in the 2011 DDIEx-
traction task had been publicly available as an open
source project since July 2012, but as small mod-
ifications were required for compatibility with the
2013 task, we published an updated 2.1 version that
task participants could use. To simplify utilization of
the numerous analyses TEES produces we also pro-
vided our drug-drug interaction predictions freely
available for all DDIExtraction 2013 task partici-
pants in the hope of encouraging further participa-
tion in this interesting shared task.
We demonstrate that TEES has good performance
for both drug name detection as well as drug-drug
interaction detection, achieving an F-score of 60%
in the drug name detection task 9.1 and an F-score of
59% in the drug-drug interaction detection task 9.2.
We show that external information from DrugBank
and MetaMap can considerably improve extraction
performance, but observe that the use of such in-
formation must always depend on the exact require-
ments of each text mining task.
2 Methods
We present a unified approach to drug name and
DDI extraction, utilizing largely the same machine
learning approaches in both tasks. We develop three
variants for tasks 9.1 & 9.2 each, testing the base-
line performance of TEES for these tasks, as well as
the impact of using external databases as additional
training data.
2.1 Turku Event Extraction System
The Turku Event Extraction System is described in
detail in Bjo?rne et al (2012). Here we give a gen-
eral overview about applying the system for the cur-
rent task. TEES processes text in a pipeline of com-
ponents, starting from preprocessing tasks such as
NER and parsing and proceeding to the multiple,
consecutive steps of event extraction. As tasks 9.1
and 9.2 are independent of each other the entity and
interaction detection components of TEES are used
independently, and for preprocessing, only the pars-
ing is done (See Figure 1).
2.2 Training data preparation
TEES is a machine learning system based on sup-
port vector machines (SVM) (Tsochantaridis et al,
2005). To train the system for a new task, two
datasets are required: a training set on which the
SVM model is trained, and a development set on
which the newly trained model is tested to deter-
mine parameter settings for optimal performance
(See Figure 2). The optimal model can then be
used to detect what it was trained for on unannotated
datasets, such as the hidden shared task test set.
The DDIExtraction 2013 corpus consists of two
parts: A training corpus used for system develop-
ment and a test corpus for evaluating the participat-
ing systems. The annotation of the test corpus is not
revealed to task participants. To develop the system,
we estimate performance on the training corpus us-
ing 10-fold cross validation. To provide the datasets
TEES requires, the training corpus is randomly di-
vided (on the document level) into ten parts. For
predicting drug names or DDIs for each part, seven
of the remaining nine parts are used as a training
set and two as a development set for parameter opti-
mization. When producing the final models for clas-
sifying the test corpus, five parts of the training cor-
pus are used for training and the other five for pa-
rameter optimization. In both cases, the parameter
optimization set is merged with the training set when
producing the final model for classifying the test set.
The DDIExtraction 2013 corpus is provided in an
XML format originally introduced as a unified for-
mat for several pairwise protein-protein interaction
(PPI) corpora (Pyysalo et al, 2008). TEES uses a
variant of this format as its internal data representa-
652
DrugAminoglutethimide the of Drugcoumarin and Drugvarfarin .diminishes effect
effect effect
A B
NN DT IN NN CC .conj_and><dobj prep_of>
NN
prep_of>
VBZ<nsubj <det NN
punct>
Drug(Aminoglutethimide) Drug(coumarin)effect
Drug(warfarin)
effect neg
Figure 1: TEES graph representation for drug name and interaction extraction, with example sentence DDI-
DrugBank.d372.s2 from the DDIExtraction 2013 training corpus. A) Both the annotation (above the sentence) and the
syntactic parse (below the sentence) are represented as graphs. Tokens form the nodes and dependencies the edges of
the syntactic parse graph. Drug names form the nodes and DDIs the edges of the annotation graph. Drug name entities
are linked to their syntactic head tokens, connecting the two graphs and allowing the parse to be used as a source of
features. For DDI edges, most features are derived from the shortest path of dependencies connecting the two drug
entities. B) For DDI extraction, one example is generated for each interaction type for each undirected pair of drug
entities. The gray neg class edge is a negative example.
A) Corpus
train classify
param.
train classify
parameters
train
devel
model
test
model
test
data
test
data
Training corpus Test corpus
C) Training the Final Model
0 1 2 3 4 5 6 7 8 9
train classify
parameters
train classify
parameters
train
devel
model
test
model
B) 10-fold cross-validation (for each set 0-9, shown for #9)
90 1 2 3 4 5 6 7 8
0 1 2 3 4 5 6 7 8 9
Figure 2: DDIExtraction 2013 corpus. A) To evaluate performance, and to provide analyses for the full training
corpus, the training corpus is divided for 10-fold cross validation. B) Each of the ten parts is classified using seven of
the remaining parts for training the model and the last two for optimizing parameters. After parameter optimization,
all nine parts are used to train the model (with the optimal parameters) for classifying the test set. C) To classify the
hidden DDIExtraction 2013 corpus half of the training corpus is used for training and the other half for determining
optimal parameters. The test corpus is finally classified with a model trained using the full training corpus.
653
tion. While close to the DDIExtraction 2013 format,
some differences exist, so we preprocess the corpora
for compatibility with TEES. Namely, ddi elements
are renamed as interaction elements, entity elements
in task 9.2 are tagged with the given attribute to mark
them as pre-annotated data for TEES and all charac-
ter offsets are converted to the TEES format by in-
creasing the end offset by one, resulting in spans de-
noted with the beginning character and end charac-
ter plus one, a common convention in programming
languages such as Java and Python.
Before use, all DDIExtraction 2013 corpora are
parsed with the TEES preprocessing pipeline, using
the BLLIP parser with David McClosky?s biomodel
to produce a Penn-tree style parse which is con-
verted with the Stanford parser tools to the collapsed
CC processed Stanford dependency scheme (Char-
niak and Johnson, 2005; McClosky, 2010; de Marn-
effe et al, 2006).
2.3 Drug name recognition with TEES
For drug name recognition the TEES entity detector
module is used. Baseline syntactic features (model
1) are generated from the parse, using both informa-
tion on the tokens and their linear context, as well
as dependency chains starting from the entity head
token. External data is added to the head token fea-
tures, from where it is combined into more complex
features. One example is generated for each token in
the sentence, and these are classified into negatives
or one of the positive classes.
As a new feature we generate all substrings start-
ing from the first and last characters of the drug
name, with the intention of detecting common pre-
fixes and suffixes among the drug names.
2.4 Drug-drug interaction detection with TEES
For DDI extraction we use the TEES edge detec-
tor module. DDIs are typed, undirected edges, so
one example is generated for each undirected pair of
drug name entities present in the sentence (See Fig-
ure 1). The baseline syntactic features (model 1) are
generated mostly from the shortest path of depen-
dencies connecting the pair of drug name entities?
head tokens. From this shortest path several feature
groups are generated, including N-grams of various
lengths, governor?dependent information for depen-
dencies etc. External data is added into the two drug
name entities, and combined into the path features.
We also use the TEES modification from DDIEx-
traction 2011 task where conj and dependencies are
ignored when calculating the shortest path, with the
aim of including more of the relevant interaction
words in the path.
2.5 Using DrugBank for Domain Knowledge
DrugBank2 is a public database of information on
drugs and drug targets. We use the downloadable
XML version of the database.
For drug name recognition, for each candidate to-
ken, we add as features its presence as a known
drug name in DrugBank and the synonym, brand,
group and category annotations this drug may have.
We also mark whether the candidate token exactly
equals an annotation of one of these types, indicating
cases where the token is e.g. a known brand name.
For DDI extraction, we mark as a feature whether
the drug name pair is listed in DrugBank as having
interactions or not. We also mark if one of the drug
names is not listed in DrugBank.
2.6 Using MetaMap for Domain Knowledge
The MetaMap program has been used extensively
for a wide array of BioNLP studies, such as auto-
matic indexing of biomedical literature and concept-
based text summarization (Reeve et al, 2007;
Quanzhi and Yi-Fang Brook, 2006). For drug-
related information extraction, two recent applica-
tions demonstrated that integrating the MetaMap
program to their existing systems produces high
overall performance in i.) identification and clas-
sification of the pharmaceutical substances and ii.)
extraction of drug indication information (Segura-
Bedmar et al, 2008; Fung et al, 2013).
MetaMap finds Metathesaurus concepts by per-
forming a shallow syntactic analysis of the input
text, producing a set of noun phrases. The noun
phrases are then used to generate sets of variants
which are consequently looked up from the Metathe-
saurus concepts. Matching concepts are evaluated
against the original text and the strength of the map-
pings are calculated. The candidates are finally
combined and the final scores are computed, where
the highest score of a complete mapping represents
2http://www.drugbank.ca/
654
MetaMap?s interpretation of the text.
The MetaMap program can be run both lo-
cally and remotely3. We ran the current version,
MetaMap2012, remotely via the batch mode facil-
ity by converting the sentences of the DDIExtrac-
tion corpora into the MetaMap input format. Many
of the applications that integrate MetaMap into their
systems use the default settings that are claimed to
be suitable for general purposes. However, we ap-
plied different options with the aim of increasing
the coverage of Metathesaurus concepts found by
MetaMap. The parameter set that influences the
performance of MetaMap included; using a relaxed
model, selecting the NLM2012AB Metathesaurus
version, including all derivational variants, enabling
unique acronym/abbreviation variants only, allow-
ing candidates from one or two character words, pre-
ferring multiple concepts and using word sense dis-
ambiguation.
The Relaxed Model is provided by MetaMap in
addition to the strict model which is offered as a
default setting in which all types of filterings are
applied. However, we chose the relaxed model in
which only manual and lexical filterings are used.
While the strict model is most appropriate for exper-
iments that require the highest accuracy, it covers
only 53% of the Metathesaurus strings. As we con-
sider high coverage of concepts an important factor,
we applied the relaxed model which consists of up
to 83% of Metathesaurus strings.
The versions of Metathesaurus, Base, USAbase
and NLM, provided with MetaMap are different
in their Metathesaurus coverage and the license
type required for using vocabulary sources. The
NLM2012AB version which is offered at no cost
for research purposes and covers all of the provided
Metathesaurus was used in our work.
Variants, such as inflectional and derivational
variants, are computed by MetaMap to account for
the textual variation in the text. With this setting,
many types of variants are generated recursively, and
only acronyms and abbreviations are restricted to the
unique ones. In addition, the candidates also include
words that can be prepositions, conjunctions or de-
terminers if they occur often enough in Metathe-
saurus.
3http://metamap.nlm.nih.gov/
Prefer multiple concepts causes MetaMap to
score the mappings with more concepts higher than
those with fewer concepts. This option is useful for
discovering higher-order relationships among con-
cepts found in the text and as such is assumed to be
helpful for discovering the DDIs.
Word sense disambiguation attempts to solve lex-
ical ambiguities by identifying the correct meaning
of a word based on its context. By using this option
in MetaMap, the program attempts to solve the am-
biguities among equally scoring concepts by choos-
ing the concept(s) based on semantic type.
We use the XML version of the MetaMap out-
put which is post-processed by TEES to extract rel-
evant features; candidate concepts, preferred con-
cepts, CUI (Concepts Unique Identifier), score, se-
mantic types and sources.
For drug name recognition, these are added as bi-
nary features for the candidate token, with the ex-
ception of the score, the value of which is normal-
ized into the [0, 1] range. For DDI extraction, the
binary features are added for the two drug names,
and combined into the shortest path features.
2.7 Public analyses
The TEES 2.0 system used in DDIExtraction 2011
Shared Task has been public since summer 2012.
While only small modifications are needed to make
the DDIExtraction 2013 corpus usable with the
TEES system, these can be complicated for new
users. Therefore, to make sure our public DDIEx-
traction 2011 system is usable not only in theory,
but easy enough to use in practice, we updated the
system into the 2.1 version capable of automatically
converting the DDIExtraction 2013 corpus and pro-
vided with precalculated models for DDI prediction.
To improve usability, we provided fully precal-
culated analysis files for the DDIExtraction 2013
corpus, produced using TEES 2.1. These analyses
contain the TEES drug-drug interaction predictions,
BLLIP Penn tree-bank style parses (using the Mc-
Closky biomodel), Stanford dependency parses (in
the collapsed CC processed format) and syntactic
head offsets for drug entities.
The analyses were calculated with the base-
line TEES 2.1 system, without using the external
datasets which were tested only later. The analy-
ses were provided for task 9.2, which is the direct
655
continuation of the 2011 task for which the public
TEES system was already available.
The analyses for the DDIExtraction 2013 corpus
were made available on February 25th 2013. De-
spite being published quite late in the training pe-
riod there was interest in this supporting data, and
before the task result submission deadline the analy-
ses were downloaded 14 times. The test set analyses
were provided for registered DDIExtraction 2013
participants during the test period.
3 Results and Discussion
Three feature sets were used to produce the results.
The baseline set (model 1) consisted of the TEES
entity and edge detectors which build a large feature
set from syntactic parses. Model 2 adds DrugBank
features to this baseline and model 3 further extends
model 2 with MetaMap information.
Three runs using these models were submitted for
both tasks 9.1 and 9.2. The results indicate the sys-
tem was capable of detecting both drug names and
drug-drug interactions with reasonable performance.
The best F-scores were 60% for task 9.1 drug name
detection and 59% for task 9.2 DDI extraction.
As task 9.1 is completely new, and task 9.2 was
extended from the 2011 DDI extraction task with
typed interactions and MEDLINE abstracts, the cur-
rent results are not directly comparable with the
2011 ones. The evaluation metric closest to the 2011
task is task 9.2 DDI detection regardless of type, us-
ing only the DrugBank subset of the corpus. With
this metric, our system achieved an F-score of 72%
in 2013 vs. 62.99% in 2011, which may indicate
higher baseline performance, potentially influenced
by a larger training dataset.
3.1 Drug name recognition
The decision to not attempt detection of more than
one token per drug entity proved to be not too detri-
mental to the final performance. In the training cor-
pus, there are 14,765 drug name entities of which
only 2,768 (18.7%) consist of more than one to-
ken, and of these only 38 are disjoint (not form-
ing a continuous span). For our best performing
drug name detection model (number 3) typed, par-
tial span matching was at 78% F-score vs. typed,
strict span matching at 65%. Therefore, detecting
only a single token per entity resulted in a maximum
loss of 13 percentage points (pp), but considering
that a scheme designed to detect multi-token entities
would be inherently more complex, potentially hav-
ing lower performance, and that not all of the spans
would be correctly detected, we feel this tradeoff in
performance is worth it for the considerably more
simple system design it allows.
Adding the external datasets to the classifier mod-
els proved to have a considerable impact on the task
performance (See Table 1). The baseline system
reached an F-score of 47% which was increased by
9 percentage points when including DrugBank infor-
mation and a further 4 percentage points when also
MetaMap information was included.
As seen from the type-specific F-scores (on the
training corpus), brand class entity detection was
improved by 30 pp when DrugBank information was
added, and increased slightly further with MetaMap
information (See Table 2). DrugBank lists brand
names for many drugs, and when this information
is added as a feature for each detected drug, deter-
mining the type of the drug is greatly improved.
The official primary metric in both tasks 9.1 and
9.2 is a macro-averaged F-score, which gives equal
weight to performance in each class, emphasizing
the importance of detecting also the difficult, small
classes. In particular, the class drug n (active sub-
stances not approved for use in humans for medical
purposes) was very difficult to detect for our system.
While performance remained low for all three mod-
els, including the MetaMap information gave a large
relative increase in drug n detection performance,
increasing it from 2% F-score to 8% (See Table 2).
With the macro-averaged overall performance, this
resulted in model three with the MetaMap informa-
tion having notably higher performance.
We hypothesized that the drug n category might
be hard to detect as it could contain entities simi-
lar to the drug category, which may differ only by
approval for use in humans, information that is not
likely present in the corpus. Analysis of classifi-
cation errors (See Table 3) confirms this hypothe-
sis, showing that drug n entities are by far the most
commonly misclassified ones. Addition of Drug-
Bank and MetaMap information considerably re-
duces drug n misclassifications into the drug cate-
gory.
656
M task P R F
1 9.1 0.48 (0.70) 0.46 (0.51) 0.47 (0.59)
2 9.1 0.6 (0.77) 0.52 (0.59) 0.56 (0.67)
3 9.1 0.69 (0.76) 0.54 (0.59) 0.6 (0.66)
1 9.2 0.73 (0.69) 0.47 (0.44) 0.57 (0.54)
2 9.2 0.76 (0.69) 0.48 (0.45) 0.59 (0.55)
3 9.2 0.73 (0.68) 0.48 (0.44) 0.58 (0.53)
Table 1: Official results for TEES in the DDIExtrac-
tion 2013 task and in parentheses corresponding 10-fold
cross-validation results on the training corpus. The three
models (M) used are 1) baseline syntactic features, 2)
baseline with DrugBank features and 3) baseline with
both DrugBank and MetaMap features.
Task rules allowed using the test corpus of task
9.2 (with annotated entities) as additional training
data for task 9.1. Due to time constraints we did not
use it for training, but it is likely that performance
could be further enhanced by using it.
3.2 Drug-drug interaction extraction
Performance of the three feature sets in the 9.2 DDI
extraction task are much closer than in the 9.1 drug
name recognition task. Still, additional informa-
tion from DrugBank and MetaMap slightly increase
performance, but DrugBank alone outperforms us-
ing both MetaMap and DrugBank. With the perfor-
mance difference range between the models being
only 2 pp, we think the results remain inconclusive.
That external data did not provide a further in-
crease might indicate that drug-drug interaction de-
tection is mostly a matter of interpreting the syn-
tactic parse, whereas drug-name recognition benefits
more from dictionary matching methods.
As with task 9.1, we analyse the classification er-
rors on the 10-fold classification performed on the
training dataset for which annotations are publicly
available (See Table 4). None of the DDI classes are
as hard to detect as the drug name class drug n, but
the int class has much lower performance than the
other classes, with most examples classified incor-
rectly as negatives.
4 Conclusions
We applied the Turku Event Extraction System 2.1
to detection of both drug names and drug-drug in-
teractions in the DDIExtraction 2013 task. The sys-
model drug brand group drug n
1 0.72 0.6 0.48 0.02
2 0.78 0.9 0.49 0.02
3 0.78 0.91 0.48 0.08
Table 2: Per-class micro-average scores for the drug
name recognition task 9.1.
tem showed good performance for both tasks, but we
must consider that name and interaction detection
were evaluated in isolation. In real world text min-
ing tasks, these steps will be consecutive and as such
result in lower overall performance. TEES achieves
good performance using deep syntactic parsing, but
this is a computationally expensive processing step.
When drug names are detected with TEES, all in-
put sentences need to be parsed, but if some other
method is used for drug name recognition, TEES can
parse just the sentences with drug names, as only
they can potentially contain DDIs, enabling much
faster DDI extraction.
We showed that adding external data from the
DrugBank database and from MetaMap prepro-
cessing can considerably increase extraction perfor-
mance. However, we assume this makes the sys-
tem more dependent on such data being available
for candidate drug names and DDIs in the text be-
ing processed, potentially making it harder to detect
completely new names and interactions. Therefore,
using external data is likely to introduce a tradeoff
of higher performance vs. wider detection. Use of
such data should be chosen according to the task, as
in some cases the goal is to retrieve documents with
known drugs and interactions, in others to maximize
detection of information not yet in the databases.
As with previous TEES versions, we will pro-
vide our source code freely available under an open
source license at the TEES project repository4. We
will also include a wrapper for using the MetaMap
tool via the TEES preprocessing pipeline, allowing
it to be easily integrated into event and relation ex-
traction tasks.
Acknowledgments
We thank CSC ? IT Center for Science Ltd, Espoo,
Finland for providing computational resources.
4http://jbjorne.github.com/TEES/
657
neg brand drug n group drug
neg 99.57
99.60
99.60
0.04
0.03
0.03
0.00
0.00
0.01
0.15
0.14
0.14
0.24
0.22
0.22
brand 21.43
8.91
8.63
67.92
89.70
89.98
0.07
0.07
0.07
0.63
0.21
0.28
9.95
1.11
1.04
drug n 49.70
63.27
65.27
2.79
0.00
0.00
12.18
15.37
15.37
0.40
1.00
1.20
34.93
20.36
18.16
group 13.80
14.13
14.04
0.12
0.00
0.06
0.03
0.03
0.06
85.15
84.97
85.00
0.90
0.87
0.84
drug 6.71
5.60
6.20
0.69
0.27
0.32
0.10
0.08
0.08
0.75
0.79
0.69
91.75
93.27
92.72
Table 3: Task 9.1 drug name classification errors for the training corpus. Each cell in the table lists from top to
bottom results for models one to three (baseline, baseline+DrugBank, baseline+DrugBank+MetaMap). The results
are percentage of SVM examples of each class (vertical) classified into each potential class (horizontal).
neg int advise effect mechanism
neg 97.27
97.32
97.40
0.02
0.03
0.03
0.52
0.49
0.47
1.09
1.06
1.04
1.09
1.09
1.05
int 61.70
61.70
70.74
22.87
23.40
19.15
0.53
0.00
0.00
9.57
8.51
7.45
5.32
6.38
2.66
advise 34.50
34.02
33.54
0.12
0.24
0.24
60.17
60.05
60.77
4.24
4.36
4.36
0.97
1.33
1.09
effect 38.59
38.41
39.18
0.41
0.41
0.41
3.85
3.73
3.68
54.06
54.30
53.59
3.08
3.14
3.14
mechanism 50.34
48.75
52.16
0.15
0.15
0.23
2.05
1.82
1.29
5.08
5.08
5.00
42.38
44.20
41.32
Table 4: Task 9.2 drug-drug interaction classification errors for the training corpus. Each cell in the table lists from top
to bottom results for models one to three (baseline, baseline+DrugBank, baseline+DrugBank+MetaMap). The results
are percentage of SVM examples of each class (vertical) classified into each potential class (horizontal).
658
References
Alan R Aronson. 2001. Effective mapping of biomed-
ical text to the UMLS Metathesaurus: the MetaMap
program. In Proceedings of the AMIA Symposium,
page 17. American Medical Informatics Association.
Jari Bjo?rne, Antti Airola, Tapio Pahikkala, and Tapio
Salakoski. 2011. Drug-drug interaction extraction
from biomedical texts with SVM and RLS classifiers.
In Proc. of the 1st Challenge task on Drug-Drug In-
teraction Extraction (DDIExtraction 2011) at SEPLN
2011, volume 761, pages 35?42, Sept 5.
Jari Bjo?rne, Filip Ginter, and Tapio Salakoski. 2012.
University of Turku in the BioNLP?11 Shared Task.
BMC Bioinformatics, 13(Suppl 11):S4.
Olivier Bodenreider. 2004. The unified medical lan-
guage system (UMLS): integrating biomedical termi-
nology. Nucleic acids research, 32(suppl 1):D267?
D270.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL?05),
pages 173?180. Association for Computational Lin-
guistics.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed depen-
dency parses from phrase structure parses. In Proceed-
ings of LREC-06, pages 449?454.
Kin Wah Fung, Chiang S Jao, and Dina Demner-
Fushman. 2013. Extracting drug indication informa-
tion from structured product labels using natural lan-
guage processing. Journal of the American Medical
Informatics Association.
Craig Knox, Vivian Law, Timothy Jewison, Philip Liu,
Son Ly, Alex Frolkis, Allison Pon, Kelly Banco,
Christine Mak, Vanessa Neveu, Yannick Djoumbou,
Roman Eisner, Anchi Guo, and David S. Wishart.
2011. Drugbank 3.0: a comprehensive resource for
omics research on drugs. Nucleic Acids Research,
39(Database-Issue):1035?1041.
David McClosky. 2010. Any domain parsing: auto-
matic domain adaptation for natural language pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari
Bjo?rne, Filip Ginter, and Tapio Salakoski. 2008.
Comparative analysis of five protein-protein interac-
tion corpora. BMC bioinformatics, 9(Suppl 3):S6.
Li Quanzhi and Wu Yi-Fang Brook. 2006. Identifying
important concepts from medical documents. Journal
of Biomedical Informatics, 39(6):668 ? 679.
Lawrence H Reeve, Hyoil Han, and Ari D Brooks. 2007.
The use of domain-specific concepts in biomedical text
summarization. Information Processing & Manage-
ment, 43(6):1765?1776.
Isabel Segura-Bedmar, Paloma Mart??nez, and Mar??a
Segura-Bedmar. 2008. Drug name recognition and
classification in biomedical texts: a case study out-
lining approaches underpinning automated systems.
Drug discovery today, 13(17):816?823.
Isabel Segura-Bedmar, Paloma Mart??nez, and Ce?sar
de Pablo-Sa?nchez. 2011a. A linguistic rule-based ap-
proach to extract drug-drug interactions from pharma-
cological documents. BMC bioinformatics, 12(Suppl
2):S1.
Isabel Segura-Bedmar, Paloma Mart??nez, and Daniel
Sa?nchez-Cisneros. 2011b. The 1st DDIExtraction-
2011 challenge task: extraction of drug-drug interac-
tions from biomedical texts. In Proceedings of the 1st
Challenge Task on Drug-Drug Interaction Extraction
2011: 7 Sep 2011; Huelva, Spain, pages 1?9.
Isabel Segura-Bedmar, Paloma Mart??nez, and Maria
Herrero-Zazo. 2013. Semeval-2013 task 9: Extrac-
tion of drug-drug interactions from biomedical texts.
In Proceedings of the 7th International Workshop on
Semantic Evaluation (SemEval 2013).
Luis Tari, Saadat Anwar, Shanshan Liang, James Cai,
and Chitta Baral. 2010. Discovering drug?drug inter-
actions: a text-mining and reasoning approach based
on properties of drug metabolism. Bioinformatics,
26(18):i547?i553.
Philippe Thomas, Mariana Neves, Ille?s Solt, Domonkos
Tikk, and Ulf Leser. 2011. Relation extraction for
drug-drug interactions using ensemble learning. In
Proc. of the 1st Challenge task on Drug-Drug Interac-
tion Extraction (DDIExtraction 2011) at SEPLN 2011,
page 11?18, Huelva, Spain, Sept 5.
Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hof-
mann, and Yasemin Altun. 2005. Large margin
methods for structured and interdependent output vari-
ables. Journal of Machine Learning Research (JMLR),
6(Sep):1453?1484.
Chen-May Wong, Yu Ko, and Alexandre Chan. 2008.
Clinically significant drug-drug interactions between
oral anticancer agents and nonanticancer agents: pro-
filing and comparison of two drug compendia. The
Annals of pharmacotherapy, 42(12):1737?1748.
659
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 28?36,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Scaling up Biomedical Event Extraction to the Entire PubMed
Jari Bjo?rne?, ,1,2 Filip Ginter,?,1 Sampo Pyysalo,?,3 Jun?ichi Tsujii,3,4 Tapio Salakoski1,2
1Department of Information Technology, University of Turku, Turku, Finland
2Turku Centre for Computer Science (TUCS), Turku, Finland
3Department of Computer Science, University of Tokyo, Tokyo, Japan
4National Centre for Text Mining, University of Manchester, Manchester, UK
jari.bjorne@utu.fi,ginter@cs.utu.fi,smp@is.s.u-tokyo.ac.jp
tsujii@is.s.u-tokyo.ac.jp,tapio.salakoski@it.utu.fi
Abstract
We present the first full-scale event extrac-
tion experiment covering the titles and ab-
stracts of all PubMed citations. Extraction
is performed using a pipeline composed
of state-of-the-art methods: the BANNER
named entity recognizer, the McClosky-
Charniak domain-adapted parser, and the
Turku Event Extraction System. We an-
alyze the statistical properties of the re-
sulting dataset and present evaluations of
the core event extraction as well as nega-
tion and speculation detection components
of the system. Further, we study in de-
tail the set of extracted events relevant
to the apoptosis pathway to gain insight
into the biological relevance of the result.
The dataset, consisting of 19.2 million oc-
currences of 4.5 million unique events,
is freely available for use in research at
http://bionlp.utu.fi/.
1 Introduction
There has recently been substantial interest in
event models in biomedical information extraction
(IE). The expressive event representation captures
extracted knowledge as structured, recursively
nested, typed associations of arbitrarily many par-
ticipants in specific roles. The BioNLP?09 Shared
Task on Event Extraction (Kim et al, 2009), the
first large scale evaluation of biomedical event
extraction systems, drew the participation of 24
groups and established a standard event represen-
tation scheme and datasets. The training and test
data of the Shared Task comprised 13,623 manu-
ally annotated events in 1,210 PubMed citation ab-
stracts, and on this data the top performing system
of Bjo?rne et al (2009; 2010b) achieved an overall
F-score of 51.95% (Kim et al, 2009).
?Equal contribution by first three authors.
The issue of the scalability and generalization
ability of the introduced event extraction systems
beyond the domain of the GENIA corpus on which
the Shared Task was based has remained largely
an open question. In a prior study, we have es-
tablished on a 1% random sample of PubMed ti-
tles and abstracts that the event extraction system
of Bjo?rne et al is able to scale up to PubMed-
wide extraction without prohibitive computational
time requirements, however, the actual extraction
from the entire PubMed was left as a future work
(Bjo?rne et al, 2010a). Thus, the top-ranking event
extraction systems in the Shared Task have, in fact,
not been used so far for actual mass-scale event ex-
traction beyond the carefully controlled setting of
the Shared Task itself. Further, since an automated
named entity recognition step was not part of the
Shared Task, the interaction of the event extrac-
tion systems with gene/protein name recognizers
remains largely unexplored as well.
In this study, we address some of these ques-
tions by performing a mass-scale event extraction
experiment using the best performing system1 of
the Shared Task (Bjo?rne et al, 2009; Bjo?rne et al,
2010b), and applying it to the entire set of titles
and abstracts of the nearly 18 million citations in
the 2009 distribution of PubMed. The extraction
result, containing 19.2 million event occurrences,
is the largest dataset of its type by several orders
of magnitude and arguably represents the state-of-
the-art in automatic event extraction with respect
to both accuracy and size.
To support emerging community efforts in tasks
that build on event extraction output, such as event
network refinement, hypothesis generation, path-
way extraction, and others, we make the entire
resulting dataset freely available for research pur-
poses. This allows researchers interested in ques-
tions involving text mining, rather than initial in-
1Available at http://bionlp.utu.fi/
28
Event type Example
Gene expression 5-LOX is expressed in leukocytes
Transcription promoter associated with IL-4 gene
transcription
Localization phosphorylation and nuclear translo-
cation of STAT6
Protein catabolism I kappa B-alpha proteolysis by
phosphorylation.
Phosphorylation BCL-2 was phosphorylated at the
G(2)/M phase
Binding Bcl-w forms complexes with Bax and
Bak
Regulation c-Met expression is regulated by Mitf
Positive regulation IL-12 induced STAT4 binding
Negative regulation DN-Rac suppressed NFAT activation
Table 1: Targeted event types with brief example
statements expressing an event of each type. In the
examples, the word or words marked as triggering
the presence of the event are shown in italics and
event participants underlined. The event types are
grouped by event participants, with the first five
types taking one theme, binding events taking mul-
tiple themes and the regulation types theme and
cause participants. Adapted from (Bjo?rne et al,
2009).
formation extraction, to make use of the many fa-
vorable statistical properties of the massive dataset
without having to execute the laborious and time-
consuming event extraction pipeline.
In the following, we describe the Shared Task
event representation applied throughout this study,
the event extraction pipeline itself, and a first set
of analyzes of multiple aspects of the resulting
dataset.
2 Event extraction
The event extraction pipeline follows the model of
the BioNLP?09 Shared Task in its representation
of extracted information. The primary extraction
targets are gene or gene product-related entities
and nine fundamental biomolecular event types in-
volving these entities (see Table 1 for illustration).
Several aspects of the event representation, as
defined in the context of the Shared Task, differ-
entiate the event extraction task from the body of
domain IE studies targeting e.g. protein?protein
interactions and gene?disease relations, including
previous domain shared tasks (Ne?dellec, 2005;
Krallinger et al, 2008). Events can have an ar-
bitrary number of participants with specified roles
(e.g. theme or cause), making it possible to cap-
ture n-ary associations and statements where some
participants occur in varying roles or are only oc-
Regulation
NNP NN VB NNP CC .conj_and>
<nn dobj><nsubj NNP
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
event detectionC
B
A
dobj>
named entity recognition
ProteinSTAT3 phosphorylation involve ProteinVav and ProteinRac-1 .
STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) mayNNP
appos> <auxMD
Ser(727) may
Ser(727) mayEntity
<Theme<Site <Theme
Regulation
ProteinSTAT3 Phosphorylationphosphorylation involve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
speculation and negation detectionD
Ser(727) mayEntity
<Theme<Site <Theme
RegulationSpec
Spec
STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) may
parsing
Figure 1: Event extraction. A multi-stage sys-
tem produces an event graph for each sentence.
Named entities are detected (A) using BANNER.
Independently of named entity detection, sen-
tences are parsed (B) to produce a dependency
parse. Event detection (C) uses the named entities
and the parse in predicting the trigger nodes and
argument edges that form the events. Finally, po-
larity and certainty (D) are predicted for the gen-
erated events. Adapted from (Bjo?rne et al, 2009).
casionally mentioned. A further important prop-
erty is that event participants can be other events,
resulting in expressive, recursively nested struc-
tures. Finally, events are given GENIA Event on-
tology types drawn from the community-standard
Gene Ontology (The Gene Ontology Consortium,
2000), giving each event well-defined semantics.
2.1 Event Extraction Pipeline
The event extraction pipeline applied in this work
consists of three main processing steps: named en-
tity recognition, syntactic parsing, and event ex-
traction. The process is illustrated in Figure 1.
For named entity recognition, we use the BAN-
NER system of Leaman and Gonzales (2008),
which in its current release achieves results close
to the best published on the standard GENETAG
dataset and was reported to have the best perfor-
mance in a recent study comparing publicly avail-
able taggers (Kabiljo et al, 2009). Titles and ab-
stracts of all 17.8M citations in the 2009 distribu-
tion of PubMed are processed through the BAN-
NER system.
Titles and abstracts of PubMed citations in
which at least one named entity was identified, and
29
which therefore contain a possible target for event
extraction, are subsequently split into sentences
using a maximum-entropy based sentence splitter
trained on the GENIA corpus (Kazama and Tsujii,
2003) with limited rule-based post-processing for
some common errors.
All sentences containing at least one named
entity are then parsed with the domain-adapted
McClosky-Charniak parser (McClosky and Char-
niak, 2008; McClosky, 2009), which has achieved
the currently best published performance on the
GENIA Treebank (Tateisi et al, 2005). The con-
stituency parse trees are then transformed to the
collapsed-ccprocessed variant of the Stanford De-
pendency scheme using the conversion tool2 intro-
duced by de Marneffe et al (2006).
Finally, events are extracted using the Turku
Event Extraction System of Bjo?rne et al which
achieved the best performance in the BioNLP?09
Shared Task and remains fully competitive with
even the most recent advances (Miwa et al, 2010).
We use a recent publicly available revision of the
event extraction system that performs also extrac-
tion of Shared Task subtask 2 and 3 information,
providing additional event arguments relevant to
event sites and localization (site, atLoc, and toLoc
role types in the Shared Task) as well as informa-
tion on event polarity and certainty (Bjo?rne et al,
2010b).
2.2 Extraction result and computational
requirements
Named entity recognition using the BANNER sys-
tem required in total roughly 1,800 CPU-hours
and resulted in 36,454,930 named entities identi-
fied in 5,394,350 distinct PubMed citations.
Parsing all 20,037,896 sentences with at least
one named entity using the McClosky-Charniak
parser and transforming the resulting constituency
trees into dependency analyzes using the Stanford
conversion tool required about 5,000 CPU-hours,
thus averaging 0.9 sec per sentence. Even though
various stability and scalability related problems
were met during the parsing process, we were able
to successfully parse 20,020,266 (99.91%) of all
sentences.
Finally, the event extraction step required ap-
proximately 1,500 CPU-hours and resulted in
19,180,827 event instances. In total, the entire cor-
2http://www-nlp.stanford.edu/
downloads/lex-parser.shtml
pus of PubMed titles and abstracts was thus pro-
cessed in roughly 8,300 CPU-hours, or, 346 CPU-
days, the most time-consuming step by far being
the syntactic parsing.
We note that, even though the components used
in the pipeline are largely well-documented and
mature, a number of technical issues directly re-
lated to, or at least magnified by, the untypi-
cally large dataset were met at every point of the
pipeline. Executing the pipeline was thus far from
a trivial undertaking. Due to the computational re-
quirements of the pipeline, cluster computing sys-
tems were employed at every stage of the process.
2.3 Evaluation
We have previously evaluated the Turku Event
Extraction System on a random 1% sample of
PubMed citations, estimating a precision of 64%
for event types and arguments pertaining to sub-
task 1 of the Shared Task (Bjo?rne et al, 2010a),
which compares favorably to the 58% precision
the system achieves on the Shared Task dataset it-
self (Bjo?rne et al, 2009).
To determine precision on subtasks 2 and 3
on PubMed citations, we manually evaluate 100
events with site and location arguments (sub-
task 2) and 100 each of events predicted to be
speculated or negated (subtask 3).
Subtask 2 site and location arguments are
mostly external to the events they pertain to and
therefore were evaluated independently of their
parent event. Their precision is 53% (53/100),
comparable to the 58% precision established on
the BioNLP?09 Shared Task development set, us-
ing the same parent-independent criterion.
To estimate the precision of the negation detec-
tion (subtask 3), we randomly select 100 events
predicted to be negated. Of these, 9 were incor-
rect as events to such an extent that the correct-
ness of the predicted negation could not be judged
and, among the remaining 91 events, the negation
was correctly predicted in 82% of the cases. Sim-
ilarly, to estimate the precision of speculation de-
tection, we randomly select 100 events predicted
to be speculated, of which 20 could not be judged
for correctness of speculation. Among the remain-
ing 80, 88% were correctly predicted as specula-
tive events. The negations were mostly signalled
by explicit statements such as is not regulated, and
speculation by statements, such as was studied,
that defined the events as experimental questions.
30
For comparison, on the BioNLP?09 Shared Task
development set, for correctly predicted events,
precision for negation examples was 83% (with
recall of 53%) and for speculation examples 77%
(with recall of 51%).
In the rest of this paper, we turn our attention to
the extraction result.
3 Term-NE mapping
As the event types are drawn from the Gene On-
tology and the original data on which the system
is trained has been annotated with reference to the
GO definitions, the events targeted by the extrac-
tion system have well-defined biological interpre-
tations. The meaning of complete event struc-
tures depends also on the participating entities,
which are in the primary event extraction task con-
strained to be of gene/gene product (GGP) types,
as annotated in the GENIA GGP corpus (Ohta et
al., 2009a). The simple and uniform nature of
these entities makes the interpretation of complete
events straightforward.
However, the semantics of the entities au-
tomatically tagged in this work are somewhat
more openly defined. The BANNER system was
trained on the GENETAG corpus, annotated for
?gene/protein entities? without differentiating be-
tween different entity types and marking entities
under a broad definition that not only includes
genes and gene products but also related entities
such as gene promoters and protein complexes,
only requiring that the tagged entities be specific
(Tanabe et al, 2005). The annotation criteria of
the entities used to train the BANNER system as
well as the event extraction system also differ in
the extent of the marked spans, with GENIA GGP
marking the minimal name and GENETAG allow-
ing also the inclusion of head nouns when a name
occurs in modifier position. Thus, for example, the
latter may annotate the spans p53 gene, p53 pro-
tein, p53 promoter and p53 mutations in contexts
where the former would in each case mark only
the substring p53.
One promising future direction for the present
effort is to refine the automatically extracted data
into an event network connected to specific entries
in gene/protein databases such as Entrez Gene and
UniProt. To achieve this goal, the resolution of
the tagged entities can be seen to involve two re-
lated but separate challenges. First, identifying
the specific database entries that are referred to
Relation Examples
Equivalent GGP gene, wild-type GGP
Class-Subclass human GGP, HIV-1 GGP
Object-Variant
GGP-Isoform GGP isoform
GGP-Mutant dominant-negative GGP
GGP-Recombinant GGP expression plasmid
GGP-Precursor GGP precursor, pro-GGP
Component-Object
GGP-Amino acid GGP-Ile 729
GGP-AA motif GGP NH2-terminal
GGP-Reg. element GGP proximal promoter
GGP-Flanking region GGP 5? upstream sequence
Object-Component
GGP-Protein Complex GGP homodimers
Place-Area
GGP-Locus GGP loci
Member-Collection
GGP-Group GGP family members
Table 2: Gene/gene product NE-term relation
types with examples. Top-level relations in the re-
lation type hierarchy shown in bold, specific NE
names in examples replaced with GGP. Intermedi-
ate levels in the hierarchy and a number of minor
relations omitted. Relation types judged to allow
remapping (see text) underlined.
by the genes/proteins named in the tagged enti-
ties, and second, mapping from the events involv-
ing automatically extracted terms to ones involv-
ing the associated genes/proteins. The first chal-
lenge, gene/protein name normalization, is a well-
studied task in biomedical NLP for which a num-
ber of systems with promising performance have
been proposed (Morgan and Hirschman, 2007).
The second we believe to be novel. In the follow-
ing, we propose a method for resolving this task.
We base the decision on how to map events ref-
erencing broadly defined terms to ones referencing
associated gene/protein names in part on a recently
introduced dataset of ?static relations? (Pyysalo et
al., 2009) between named entities and terms (Ohta
et al, 2009b). This dataset was created based on
approximately 10,000 cases where GGP NEs, as
annotated in the GENIA GGP corpus (Ohta et al,
2009a), were embedded in terms, as annotated in
the GENIA term corpus (Ohta et al, 2002). For
each such case, the relation between the NE and
the term was annotated using a set of introduced
relation types whose granularity was defined with
reference to MeSH terms (see Table 2, Ohta et al,
2009b). From this data, we extracted prefix and
suffix strings that, when affixed to a GGP name,
produced a term with a predictable relation (within
the dataset) to the GGP. Thus, for example, the
31
term GGP
p53 protein p53
p53 gene p53
human serum albumin serum albumin
wild-type p53 p53
c-fos mRNA c-fos
endothelial NO synthase NO synthase
MHC cl. II molecules MHC cl. II
human insulin insulin
HIV-1 rev.transcriptase rev.transcriptase
hepatic lipase lipase
p24 antigen p24
tr. factor NF-kappaB NF-kappaB
MHC molecules MHC
PKC isoforms PKC
HLA alleles HLA
RET proto-oncogene RET
ras oncogene ras
SV40 DNA SV40
EGFR tyrosine kinase EGFR
Table 3: Examples of frequently applied map-
pings. Most frequent term for each mapping is
shown. Some mention strings are abbreviated for
space.
Mentions Types
Total 36454930 4747770
Mapped 2212357 (6.07%) 547920 (11.54%)
Prefix 430737 (1.18%) 129536 (2.73%)
Suffix 1838646 (5.04%) 445531 (9.38%)
Table 4: Statistics for applied term-GGP map-
pings. Tagged mentions and types (unique men-
tions) shown separately. Overall total given for
reference, for mappings overall for any mapping
shown and further broken down into prefix-string
and suffix-string based.
prefix string ?wild-type? was associated with the
Equivalent relation type and the suffix string ?ac-
tivation sequence? with the GGP-Regulatory ele-
ment type. After filtering out candidates shorter
than 3 characters as unreliable (based on prelim-
inary experiments), this procedure produced a set
of 68 prefix and 291 suffix strings.
To make use of the data for predicting relations
between GGP names and the terms formed by af-
fixing a prefix or suffix string, it is necessary to
first identify name-term pairs. Candidates can be
generated simply by determining the prefix/suffix
strings occurring in each automatically tagged en-
tity and assuming that what remains after remov-
ing the prefixes and suffixes is a GGP name. How-
ever, this naive strategy often fails: while remov-
ing ?protein? from ?p53 protein? correctly identi-
fies ?p53? as the equivalent GGP name, for ?cap-
sid protein? the result, ?capsid? refers not to a
GGP but to the shell of a virus ? ?protein? is prop-
erly part of the protein name. To resolve this is-
sue, we drew on the statistics of the automatically
tagged entities, assuming that if a prefix/suffix
string is not a fixed part of a name, the name will
appear tagged also without that string. As the tag-
ging covers the entire PubMed, this is likely to
hold for all but the very rarest GGP names. To
compensate for spurious hits introduced by tag-
ging errors, we specifically required that to accept
a candidate prefix/suffix string-name pair, the can-
didate name should occur more frequently without
the prefix/suffix than with it. As the dataset is very
large, this simple heuristic often gives the right de-
cision with secure margins: for example, ?p53?
was tagged 117,835 times but ?p53 protein? only
11,677, while ?capsid? was (erroneously) tagged
7 times and ?capsid protein? tagged 1939 times.
A final element of the method is the definition
of a mapping to events referencing GGP NEs from
the given events referencing terms, the NEs con-
tained in the terms, and the NE-term relations. In
this work, we apply independently for each term a
simple mapping based only on the relation types,
deciding for each type whether replacing refer-
ence to a term with reference to a GGP holding
the given relation to the term preserves event se-
mantics (to an acceptable approximation) or not.
For the Equivalent relation this holds by defini-
tion. We additionally judged all Class-Subclass
and Component-Object relations to allow remap-
ping (accepting e.g. P1 binds part of P2 ? P1
binds P2) as well as selected Object-Variant rela-
tions (see Table 2). For cases judged not to allow
remapping, we simply left the event unmodified.
Examples of frequently applied term-GGP map-
pings are shown in Table 3, and Table 4 shows
the statistics of the applied mappings. We find
that suffix-based mappings apply much more fre-
quently than prefix-based, perhaps reflecting also
the properties of the source dataset. Overall, the
number of unique tagged types is reduced by over
10% by this procedure. It should be noted that the
applicability of the method could likely be consid-
erably extended by further annotation of NE-term
relations in the dataset of Ohta et al (2009b): the
current data is all drawn from the GENIA corpus,
drawn from the subdomain of transcription factors
in human blood cells, and its coverage of PubMed
is thus far from exhaustive.
32
4 Event recurrence
Given a dataset of events extracted from the en-
tire PubMed, we can study whether, and to what
extent, events are re-stated in multiple PubMed ci-
tations. This analysis may shed some light ? nat-
urally within the constraints of an automatically
extracted dataset rather than gold-standard anno-
tation ? on the often (informally) discussed hy-
pothesis that a high-precision, low recall system
might be a preferred choice for large-scale extrac-
tion as the lower recall would be compensated by
the redundancy of event statements in PubMed.
In order to establish event recurrence statistics,
that is, the number of times a given event is re-
peated in the corpus, we perform a limited normal-
ization of tagged entities consisting of the Term-
NE mapping presented in Section 3 followed
by lowercasing and removal of non-alphanumeric
characters. Two named entities are then consid-
ered equal if their normalized string representa-
tions are equal. For instance, the two names IL-
2 gene and IL2 would share the same normalized
form il2 and would thus be considered equal.
For the purpose of recurrence statistics, two
events are considered equal if their types are equal,
and all their Theme and Cause arguments, which
can be other events, are recursively equal as well.
A canonical order of arguments is used in the com-
parison, thus e.g. the following events are consid-
ered equal:
regulation(Cause:A, Theme:binding(Theme:B, Theme:C))
regulation(Theme:binding(Theme:C, Theme:B), Cause:A)
In total, the system extracted 19,180,827 instances
of 4,501,883 unique events. On average, an
event is thus stated 4.2 times. The distribution
is, however, far from uniform and exhibits the
?long tail? typical of natural language phenom-
ena, with 3,484,550 (77%) of events being single-
ton occurrences. On the other hand, the most fre-
quent event, localization(Theme:insulin), occurs
as many as 59,821 times. The histogram of the
number of unique events with respect to their oc-
currence count is shown in Figure 2.
The total event count consists mostly of sim-
ple one-argument events. The arguably more
interesting category of events that involve at
least two different named entities constitutes
2,064,278 instances (11% of the 19.2M total)
of 1,565,881 unique events (35% of the 4.5M
total). Among these complex events, recur-
 10
 100
1K
10K
100K
1M
 1  10  100 1K 10KUn
iqu
e e
ven
ts w
ith 
giv
en 
occ
urre
nce
 co
unt
Event occurrence count
Figure 2: Number of unique events (y-axis) with a
given occurrence count (x-axis).
R P N L B E T C H
R 561 173 128 42 63 83 30 16 17
P 173 1227 192 58 99 143 39 20 23
N 128 192 668 46 73 98 31 17 18
L 42 58 46 147 57 75 25 15 15
B 63 99 73 57 1023 134 35 20 21
E 83 143 98 75 134 705 49 22 24
T 30 39 31 25 35 49 79 11 11
C 16 20 17 15 20 22 11 39 7
H 17 23 18 15 21 24 11 7 49
Table 5: Event type confusion matrix. Each el-
ement contains the number of unique events, in
thousands, that are equal except for their type.
The matrix is symmetric and its diagonal sums to
4,5M, the total number of extracted unique events.
The event types are (R)egulation, (P)ositive
regulation, (N)egative regulation, (L)ocalization,
(B)inding, gene (E)xpression, (T)ranscription,
protein (C)atabolism, and p(H)osphorylation.
rence is thus considerably lower, an event be-
ing stated on average 1.3 times. The most
frequent complex event, with 699 occurrences,
is positive-regulation(Cause:GnRG,Theme:local-
ization(Theme:LH)), reflecting the well-known
fact that GnRG causes the release of LH, a hor-
mone important in human reproduction.
To gain an additional broad overview of the
characteristics of the extracted events, we com-
pute an event type confusion matrix, shown in Ta-
ble 5. In this matrix, we record for each pair of
event types T1 and T2 the number of unique events
of type T1 for which an event of type T2 can be
found such that, apart for the type difference, the
events are otherwise equal. While e.g. a posi-
tive regulation-negative regulation pair is at least
unusual, in general these event pairs do not sug-
gest extraction errors: for instance the existence
33
of the event expression(Theme:A) does not in any
way prevent the existence of the event localiza-
tion(Theme:A), and regulation subsumes positive-
regulation. Nevertheless, Table 5 shows a clear
preference for a single type for the events.
5 Case Study: The apoptosis pathway
In this section, we will complement the preceding
broad statistical overview of the extracted events
with a detailed study of a specific pathway, the
apoptosis pathway, determining how well the ex-
tracted events cover its interactions (Figure 3).
To create an event network, the events must be
linked through their protein arguments. In addi-
tion to the limited named entity normalization in-
troduced in Section 4, we make use of a list of syn-
onyms for each protein name in the apoptosis path-
way, obtained manually from protein databases,
such as UniProt. Events whose protein arguments
correspond to any of these known synonyms are
then used for reconstructing the pathway.
The apoptosis pathway consists of several over-
lapping signaling routes and can be defined on
different levels of detail. To have a single, ac-
curate and reasonably high-level definition, we
based our pathway on a concisely presentable sub-
set of the KEGG human apoptosis pathway (entry
hsa04210) (Kanehisa and Goto, 2000). As seen
in Figure 3, the extracted dataset contains events
between most interaction partners in the pathway.
The constructed pathway also shows that the ex-
tracted events are not necessarily interactions in
the physical sense. Many ?higher level? events
are extracted as well. For example, the extracel-
lular signaling molecule TNF? can trigger path-
ways leading to the activation of Nf-?B. Although
the two proteins are not likely to interact directly,
it can be said that TNF? upregulates NF-?B, an
event actually extracted by the system. Such state-
ments of indirect interaction co-exist with state-
ments of actual, physical interactions in the event
data.
6 Conclusions
In this paper, we have presented the result of pro-
cessing the entire, unabridged set of PubMed titles
and abstracts with a state-of-the-art event extrac-
tion pipeline as a new resource for text mining in
the biomedical domain. The extraction result ar-
guably represents the best event extraction output
achievable with currently available tools.
The primary contribution of this work is the set
of over 19M extracted event instances of 4.5M
unique events. Of these, 2.1M instances of 1.6M
unique events involve at least two different named
entities. These form an event network several
orders of magnitude larger than those previously
available. The data is intended to support re-
search in biological hypothesis generation, path-
way extraction, and similar higher-level text min-
ing tasks. With the network readily available in an
easy-to-process format under an open license, re-
searchers can focus on the core tasks of text min-
ing without the need to perform the tedious and
computationally very intensive task of event ex-
traction with a complex IE pipeline.
In addition to the extracted events, we make
readily available the output of the BANNER sys-
tem on the entire set of PubMed titles and abstracts
as well as the parser output of the McClosky-
Charniak domain-adapted parser (McClosky and
Charniak, 2008; McClosky, 2009) further trans-
formed to the Stanford Dependency representa-
tion using the tools of de Marneffe et al (2006)
for nearly all (99.91%) sentences with at least one
named entity identified. We expect this data to be
of use for the development and application of sys-
tems for event extraction and other BioNLP tasks,
many of which currently make extensive use of
dependency syntactic analysis. The generation of
this data having been far from a trivial technical
undertaking, its availability as-is can be expected
to save substantial duplication of efforts in further
research.
A manual analysis of extracted events relevant
to the apoptosis pathway demonstrates that the
event data can be used to construct detailed bio-
logical interaction networks with reasonable accu-
racy. However, accurate entity normalization, in
particular taking into account synonymous names,
seems to be a necessary prerequisite and remains
among the most important future work directions.
In the current study, we take first steps in this di-
rection in the form of a term-NE mapping method
in event context. The next step will be the applica-
tion of a state-of-the-art named entity normaliza-
tion system to obtain biological database identities
for a number of the named entities in the extracted
event network, opening possibilities for combin-
ing the data in the network with other biological
information. A further practical problem to ad-
dress will be that of visualizing the network and
34
ev
n
nv
v
v v
n e t
n n v
v nv
v
vn
n
n
n
n
n
n
n n
n
n
n
n n
n
nn
 
n
d
n
e
n
c
v
n
v
t
n
nvnv
n
n
n
v
t
en
ct
nncv
n
n
n e n v
n
n
vnd
n
 
n
v
n t
n
vv
v
n
v
t
n
t
e t
e n v
e
t
n
v
v
n
v
v
nv
n
n v
v
n v
n
c
n
n
v
n v
nn
c
v
nn
vn
v
v
n
v
v
n
e v
vn
IL-1 TNF? TRAIL Fas-L
IL-1R TNF-R1 TRAIL-R Fas
FADDTRADDRIP1MyD88IRAK
NIK
IKK
I?B? NF-?B
CASP10CASP8
FLIP
CASP3CASP7
dioamayorgsrdapuaporrlpaop
ugugpp
TRAF2
IAP
doiiraii
Figure 3: Extracted apoptosis event network. Events shown in the figure are selected on their
prominence in the data or correspondence to known apoptosis interactions. Events corresponding
to KEGG apoptosis pathway interaction partners are highlighted with a light grey background. The
event types are (P)ositive regulation, (N)egative regulation, (R)egulation, gene (E)xpression, (B)inding,
p(H)osphorylation, (L)ocalization and protein (C)atabolism.
presenting the information in a biologically mean-
ingful manner.
The introduced dataset is freely available for
research purposes at http://bionlp.utu.
fi/.
Acknowledgments
This work was supported by the Academy of
Finland and by Grant-in-Aid for Specially Pro-
moted Research (MEXT, Japan). Computational
resources were provided by CSC ? IT Center for
Science, Ltd., a joint computing center for Finnish
academia and industry. We thank Robert Leaman
for advance access and assistance with the newest
release of BANNER.
35
References
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 10?18, Boulder, Colorado. Association for
Computational Linguistics.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-
jii, and Tapio Salakoski. 2010a. Complex event ex-
traction at PubMed scale. In Proceedings of the 18th
Annual International Conference on Intelligent Sys-
tems for Molecular Biology (ISMB 2010). In press.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2010b. Ex-
tracting contextualized complex biological events
with rich graph-based feature sets. Computational
Intelligence. In press.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In
Proceedings of LREC-06, pages 449?454.
Renata Kabiljo, Andrew Clegg, and Adrian Shepherd.
2009. A realistic assessment of methods for extract-
ing gene/protein interactions from free text. BMC
Bioinformatics, 10(1):233.
M. Kanehisa and S. Goto. 2000. KEGG: kyoto ency-
clopedia of genes and genomes. Nucleic Acids Res.,
28:27?30, Jan.
Jun?ichi Kazama and Jun?ichi Tsujii. 2003. Evalua-
tion and extension of maximum entropy models with
inequality constraints. In Proceedings of the 2003
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 137?144.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9, Boulder, Col-
orado. ACL.
Martin Krallinger, Florian Leitner, Carlos Rodriguez-
Penagos, and Alfonso Valencia. 2008. Overview of
the protein-protein interaction annotation extraction
task of BioCreative II. Genome Biology, 9(Suppl
2):S4.
R. Leaman and G. Gonzalez. 2008. BANNER: an exe-
cutable survey of advances in biomedical named en-
tity recognition. Pacific Symposium on Biocomput-
ing, pages 652?663.
David McClosky and Eugene Charniak. 2008. Self-
Training for Biomedical Parsing. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics - Human Language Technolo-
gies (ACL-HLT?08), pages 101?104.
David McClosky. 2009. Any Domain Parsing: Au-
tomatic Domain Adaptation for Natural Language
Parsing. Ph.D. thesis, Department of Computer Sci-
ence, Brown University.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and
Jun?ichi Tsujii. 2010. Event Extraction With Com-
plex Event Classification Using Rich Features. J
Bioinform Comput Biol, 8:131?146.
Alexander A. Morgan and Lynette Hirschman. 2007.
Overview of BioCreative II gene normalization. In
Proceedings of BioCreative II, pages 101?103.
Claire Ne?dellec. 2005. Learning Language in
Logic - Genic Interaction Extraction Challenge. In
J. Cussens and C. Ne?dellec, editors, Proceedings
of the 4th Learning Language in Logic Workshop
(LLL05), pages 31?37.
Tomoko Ohta, Yuka Tateisi, Hideki Mima, and Jun?ichi
Tsujii. 2002. GENIA corpus: An annotated re-
search abstract corpus in molecular biology domain.
In Proceedings of the Human Language Technology
Conference (HLT?02), pages 73?77.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009a. Incorporating
genetag-style annotation to genia corpus. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 106?
107, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Tomoko Ohta, Sampo Pyysalo, Kim Jin-Dong, and
Jun?ichi Tsujii. 2009b. A re-evaluation of biomedi-
cal named entity - term relations. In Proceedings of
LBM?09.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 1?9,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Lorraine Tanabe, Natalie Xie, Lynne H Thom, Wayne
Matten, and W John Wilbur. 2005. GENETAG: A
tagged corpus for gene/protein named entity recog-
nition. BMC Bioinformatics, 6(Suppl. 1):S3.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun?ichi Tsujii. 2005. Syntax Annotation for the
GENIA corpus. In Proceedings of the IJCNLP
2005, Companion volume, pages 222?227.
The Gene Ontology Consortium. 2000. Gene ontol-
ogy: tool for the unification of biology. Nature ge-
netics, 25:25?29.
36
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 108?116,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Reconstruction of semantic relationships from their projections in
biomolecular domain
Juho Heimonen, Jari Bjo?rne, and Tapio Salakoski
University of Turku
Turku Centre for Computer Science and
Department of Information Technology
Joukahaisenkatu 3?5
20520 Turku, Finland
first.last@utu.fi
Abstract
The extraction of nested, semantically rich
relationships of biological entities has re-
cently gained popularity in the biomed-
ical text mining community. To move
toward this objective, a method is pro-
posed for reconstructing original seman-
tic relationship graphs from projections,
where each node and edge is mapped to
the representative of its equivalence class,
by determining the relationship argument
combinations that represent real relation-
ships. It generalises the limited postpro-
cessing step of the method of Bjo?rne et al
(2010) and hence extends this extraction
method to arbitrarily deep relationships
with unrestricted primary argument com-
binations. The viability of the method is
shown by successfully extracting nested
relationships in BioInfer and the corpus
of the BioNLP?09 Shared Task on Event
Extraction. The reported results, to the
best of our knowledge, are the first for the
nested relationships in BioInfer on a task
in which only named entities are given.
1 Introduction
A recent shared task in biomedical text mining,
the BioNLP?09 Shared Task on Event Extrac-
tion (Kim et al, 2009), showed that the biomed-
ical natural language processing (BioNLP) com-
munity is greatly interested in heading towards
the extraction of deep, semantically rich relation-
ships. The shared task focused on biomolecu-
lar events involving proteins and called for meth-
ods that are capable of identifying nested struc-
tures. Biomolecular events are a major cate-
gory of relationships in the biomedical domain in
which, among others, relationships involving non-
molecular entities such as diseases and static rela-
tions such as protein family memberships are also
of interest.
Earlier, well-studied extraction tasks typically
cast the problem in such a manner that relation-
ships can be considered as mutually independent
atomic units. However, as a nested semantic struc-
ture grows in its depth and in the total number
of relationship arguments, its simultaneous extrac-
tion becomes difficult, if not impossible. Systems
that bypass this problem by identifying atomic
units of nested structures in a mutually indepen-
dent manner must still decide which of the units
collectively comprise a complete structure.
Another problem arises from the fact that a sin-
gle syntactic token can refer to several, distinct re-
lationships each having a unique combination of
arguments. This is typically induced by coordi-
nations which are common in the biomedical do-
main (Pyysalo et al, 2007). As a result, aside
from the identification and classification of rela-
tionships and their potential arguments, extraction
systems have to make decisions about how many
relationships should be generated and how the ar-
guments should be distributed among them. For
example, the sentence ?the binding of A and B to
DNA regulates C and D, respectively? states that
there are two binding events (A?DNA and B?DNA)
the former of which regulates C and the latter D in-
stead of, for example, that both binding events reg-
ulate both C and D or that there is a single binding
event between A, B, and DNA.
This paper focuses on addressing the afore-
mentioned problems in the case of the extrac-
tion method developed by Bjo?rne et al (2010) for
the BioNLP?09 Shared Task and generalises this
method. Bjo?rne et al showed that deep depen-
108
NNP VBZ NNP CC .
conj_and>dobj><nsubj
Protein
Pp60
Phosphorylation
phosphorylates
Protein
CapG
Protein
profilin.
<Cause Theme>
Theme><Cause
pa
rse
A
dobj>
and
NNP
Phosphorylation
Protein
Pp60
Phosphorylation
phosphorylates
Protein
CapG
Protein
profilin.
<Cause Theme>
Theme>
and
B
C
Figure 1: A one-node-per-token constrained graph
(projected, B) cannot express the two distinct
phosphorylation events while an unrestricted se-
mantic graph (deprojected, A) can. A parse in the
SD scheme is illustrated in C.
dency analyses in the well-established Stanford
Dependency (SD) scheme (de Marneffe and Man-
ning, 2008) can successfully be utilised in extract-
ing graphs that express semantic entities as nodes
and relationship arguments as edges but are lim-
ited to one node per syntactic token. Nodes and
edges can be extracted in a mutually independent
manner but the resulting graph cannot necessarily
express all the real relationships. Rather, the graph
can be seen as a projection of the original graph:
each node and edge has been mapped to the rep-
resentative of its equivalence class which is deter-
mined by the node and edge types and the referred
tokens.
The research question of this paper is can the
original semantic graphs be reconstructed from
projected graphs with an independent step in an
information extraction (IE) process? The objec-
tive of deprojection is illustrated as a transforma-
tion of the graph B to the graph A in Figure 1.
To answer the question, the problem of re-
constructing complex, nested semantic structures
from their projections is formulated and a generic
deprojection method is proposed. The method
specifically addresses primary arguments, as de-
fined by the BioNLP?09 Shared Task, while leav-
ing the extension to secondary arguments as a fu-
ture work. The viability of the method is anal-
ysed with BioInfer (Pyysalo et al, 2007) and the
BioNLP?09 Shared Task corpus, both of which
containing nested structures, through an IE task
essentially identical to the BioNLP?09 Shared
Task. It is concluded that the proposed method
Figure 2: The deprojection process.
can successfully augment the method of Bjo?rne
et al (2010) and generalise it to arbitrary graphs
of nested biomolecular relationships without the
strict restrictions of the BioNLP?09 Shared Task
while retaining its performance level. Thus, the
method can improve IE systems that produce rela-
tionships on the one-per-token basis.
2 Method
The proposed approach to deproject semantic
graphs is outlined in Figure 2. In summary, the
first transformation (grouping) alters a projected
graph such that a minimal set of classes is suf-
ficient to describe the behaviour of the nodes
and the edges. Guided by predicted class labels,
the second transformation (deprojection) then pro-
duces a deprojected graph. In the presented
method, the classification problem is solved with
machine-learning (ML) methods. Finally, corpus-
specific constraints are enforced.
2.1 Definitions
The graph representation of semantic annotation
introduced by Heimonen et al (2008) is adopted
with some additional definitions. Semantic knowl-
edge is represented as a directed acyclic graph
(DAG) as follows.
Nodes and edges correspond to semantic en-
tities (such as protein and processes) and rela-
tionship arguments, respectively. The equality of
nodes is determined by the equality of their types
and of their references to text. Similarly, the equal-
ity of edges arises from the equality of their types
and of their end nodes.
Shallow and deep relationships consist of a
node, its outgoing edges, and its direct successors.
The latter also recursively include the successor
relationships. Nodes are equal as shallow relation-
ships if they as well as their outgoing edges are
109
equal. Node equality as a deep relationship im-
poses the further requirement that the successors
are equal as deep relationships.
A valid relationship is one which is valid in
the given corpus-specific annotation scheme. Es-
pecially, it has a valid combination of arguments.
A deprojected graph (see Figure 1A) is one
in which each node represents a valid, real rela-
tionship. Several equal nodes can exist provided
they have unique combinations of outgoing edges.
Note that there is one-to-one correspondence be-
tween nodes and real relationships but many-to-
one between nodes and syntactic tokens.
A projected graph (see Figure 1B) is one
generated by mapping each node and edge of a de-
projected graph to the representative of its equiv-
alence class. That is, each node represents a set
of equal nodes of the deprojected graph, and simi-
larly for edges. As a result, each token is referred
to by at most one node1 and there is a one-to-many
correspondence between nodes and valid, real re-
lationships. Also, the edges that are mapped to
from the outgoing edges of equal nodes of the de-
projected graph are the outgoing edges of a single
node of the projected graph.
The deprojection of a semantic graph is the
task of reproducing the original graph given a pro-
jected graph. This can also be seen as a task of
finding the sets of outgoing edges that represent
all the valid, real relationships.
2.2 Grouping
The objective of the first transformation is accom-
plished with a grouping algorithm: the direct suc-
cessors of each node are grouped by their syntac-
tic and semantic roles relative to the predecessor.
The groups are represented as additional nodes
in the graph. The rationale for this grouping is
that similar arguments tend to either be mutually
exclusive (and be associated with some other ar-
guments) or together form a single relationship.
This behaviour can easily be described with two
classes: distributive and collective. For example,
in the sentence ?A and B regulate C?, the entities A
and B share both the argument type (agent) and the
syntactic role (subject) relative to the relationship
regulate. They form a group and are mutually ex-
clusive (distributive) while this group forms a sin-
gle relationship (collective) together with C. As a
1given that, in the deprojected graph, a token can be re-
ferred to by multiple nodes only if they are of the same type
result, A?C and B?C pairs of regulation are gener-
ated. This approach relates to the collectivity and
distributivity of plurals which have been studied,
among others, by Scha and Stallard (1988) and
Brisson (2003).
Technically, the grouping is a series of trans-
formations in each of which a set of successors
is replaced with a single, newly-created succes-
sor and the original successors become the succes-
sors of this node. The successors are first trivially
grouped by the corresponding edge type. Finally,
they are recursively grouped by syntactic similar-
ity until they form a single group or multiple sin-
gleton groups. As a result, nested groups are gen-
erated.
The groups by syntax are determined by first
mapping both the predecessor and the successors
into the referred tokens in the syntactic graph.
Then, the tokens referred to by the predecessor
are removed if they are not also referred to by
any of the successors. This removal step is recur-
sively applied to the predecessors of the removed
tokens. As a result, the syntactic graph is decom-
posed into several connected components, each of
which representing a group. Thus, two successors
are grouped if their referred tokens belong to the
same connected component.
2.3 Deprojection
The second transformation is guided by node class
labels (Figure 3). A collective node remains un-
changed: its successors are kept together. In con-
trast, a distributive node is duplicated for each out-
going edge and the edges are distributed, one edge
per duplicate. These node classes are enough to
solve most of the cases in the analysed data sets.
However, especially in BioInfer, this is not suf-
ficient since the duplicates of a distributive node
may themselves be either collective or distributive
under their predecessor.
To adequately describe the behaviour of the du-
plicates generated by a single distributive node,
the incoming edges of each distributive node are
classified as collective or distributive (Figure 4).
The duplication of a node also duplicates its in-
coming edges which are then processed by the as-
signed class labels as follows. In the case of a col-
lective edge, the generated duplicates of the edge
share the predecessor and are thus arguments in
a single relationship. In contrast, a distributive
edge induces the duplication of the predecessor re-
110
Figure 3: The effect of assigning collective or dis-
tributive class labels (marked as <?>) to a node in
the deprojection process.
Figure 4: Correct node and edge class labels for
the projected graph of the phrase ?Coexpression
and subsequent DNA-binding of X and Y pro-
teins? (A) and the resulting deprojected graph (B).
lationships such that, as a result, the generated du-
plicate edges do not share any predecessors.
In Figure 4A, the node proteins is distributive
because it represents two distinct nodes: one per-
taining to X, another to Y. These two nodes are
involved in the same coexpression relationship but
in different binding relationships. Hence the in-
coming edges of the node proteins are collective
and distributive, respectively.
Since the two transformation steps do not en-
force corpus-specific constraints, a trivial algo-
rithm is utilised to decompose relationships with
invalid argument combinations into multiple valid
relationships. In an ideal situation, this step makes
no transformations. This is also used as a part of
the baseline method (see Section 3.3).
2.4 Machine-learning and features
For node and edge classifications, the C4.5 deci-
sion tree (Quinlan, 1993), and its J48 implemen-
tation in the Weka package, was utilised because
its models can easily be examined. This facili-
tates the analysis of the problem and the further
development of the solution. The default parame-
ters were used since no improvement was gained
with alternative parameters in preliminary experi-
ments. The applied feature set emphasises higher-
level features obtained from the semantic and syn-
tactic graphs. It consists of three main groups: se-
mantic, syntactic, and morphological.
Semantic features contain information gath-
ered from the semantic graph as well as from the
type hierarchies. For nodes, these features consists
of the node type as well as the presence, count and
combination of outgoing edge types. The count of
successor groups and the distance to the first non-
group predecessor are also included. For edges,
the node features are generated for both the suc-
cessor and the predecessor in addition to the type
of the edge.
Syntactic features include the minimum syn-
tactic distance2 from the predecessor to the suc-
cessors as well as between the successors. Also,
in the case of the unit distance, the corresponding
dependency type is included.
Morphological features consist of the Porter
stems (Porter, 1980) and the part-of-speech tags of
the referred tokens as well as the presence and the
Porter stems of the tokens that are shared between
the successors.
All features are also generated from the first
non-group predecessor (which may be the node it-
self) to capture the original relationship node when
processing a group node. The majority of the fea-
tures are Boolean-valued in order to allow several
values of a single property. This is utilised in fea-
tures representing hierarchical knowledge (such as
node and dependency types) as well as stem fea-
tures. For example, a node receives true for the
node type feature of its actual type as well as of its
supertypes in the hierarchy.
3 Resources and experiments
An array of experiments was performed to anal-
yse the deprojection problem and the proposed
solution. Firstly, the same experiments were
performed on two corpora, BioInfer and the
BioNLP?09 Shared Task corpus in order to eval-
uate the effect of the annotation scheme to the
properties of the problem. Secondly, the deprojec-
tion algorithm was applied to both projected gold-
standard graphs and to predicted graphs in order to
study the effect of the accuracy of the input graph.
Thirdly, the effect of the quality of the parse was
2semantic nodes mapped into the referred tokens
111
examined by employing various parses including
the BioInfer gold-standard annotation.
3.1 Data
BioInfer is a corpus of 1100 sentences selected
from 836 publication abstracts available through
PubMed. For this paper, the abstracts were ran-
domly sampled in the ratio 2:1:1 into the train-
ing, development, and test sets. In contrast, the
BioNLP?09 Shared Task corpus consists of the
training, development, and test sets of 800, 150,
and 260 abstracts, respectively. Since the anno-
tation of the test set is not publicly available and
the evaluation server does not provide the required
details for the analysis, the development set was
used as the test set and a random sample of 150
abstracts was cut from the training set to form the
development set.
In this study, the task 1 annotation with the pro-
tein equivalence relations removed was used as the
BioNLP?09 Shared Task data set. In this anno-
tation, relationships are positively asserted, have
only Theme and Cause arguments and are anno-
tated only for one of the equivalent proteins. Fur-
thermore, each node refers to at least one token
in the syntactic graph. The BioInfer semantic an-
notation was transformed into a similar form by
removing negation (NOT), equivalence (EQUAL),
and reference nodes (COREFER, REL-ENT). Fur-
thermore, to create a fully text-bound subset, fam-
ily memberships relations (MEMBER) were re-
solved into single edges and suitable references to
text were added for the remaining unbound nodes
when possible. In an extreme case, an unbound
relationship was discarded. As a result, the differ-
ences to the BioNLP?09 Shared Task data set were
minimised to additional node and edge types re-
flecting the wider selection of primary arguments.
All employed parses follow the SD scheme.
BioInfer contains uncollapsed gold-standard
parses while the BioNLP?09 Shared Task corpus
includes parses, in the collapsed representation,
generated by the parser of Charniak and Johnson
(2005) using the model of McClosky and Char-
niak (2008). For both corpora, additional parses
were produced with the improved version of the
aforementioned system created by McClosky
(2009). These parses were transformed into
both the collapsed and the conjunct dependency
propagated representations with the tools pro-
vided by de Marneffe et al (2006). All parses
were further augmented by splitting tokens at
non-alphanumeric characters that border named
entities and connecting the newly-created tokens
with dependencies denoting the character.
3.1.1 Predicted graphs
The predicted semantic graphs were obtained as
a result of an extraction task adopted from the
BioNLP?09 Shared Task. In this task, named en-
tities are given as gold-standard annotation and
their relationships are to be extracted by identify-
ing text spans, determining types, and assigning
arguments.
The predicted graphs were produced with the
system developed for the BioNLP?09 Shared Task
by Bjo?rne et al (2010). The system has two
machine-learning steps. First, relationship nodes
are predicted, one per token, based only on the
syntax and the given named entity nodes. Next,
outgoing edges are predicted for the relationship
nodes. As a result, a projected graph is obtained.
With the graph representation, the system can
transparently be trained for both the BioNLP?09
Shared Task corpus and BioInfer regardless of the
differences in their annotation schemes.
The two prediction steps utilise the
SVMmulticlass implementation of a multi-
class support vector machine (Crammer and
Singer, 2002; Tsochantaridis et al, 2004). In this
study, the steps were independently optimised
for model parameters and, in contrast to the
original training procedure, the recall boosting
optimisation was omitted due to limited resources
available. When training the edge prediction, the
gold-standard relationship nodes were used.
In the graph prediction, the conjunct depen-
dency propagated parses produced with the parser
of McClosky (2009) were systematically applied.
3.2 Experiments
Original gold-standard graphs were used in gen-
erating decision tree models as well as subjected
to projection. Predicted graphs and the projected
gold-standard graphs were deprojected with the
models. The evaluation of the deprojected graphs
was performed against the original graphs.
During the system development, the training
and development sets were available and the data
were thoroughly analysed. The progress was esti-
mated by training the system with the former and
testing against the latter. The final results were
obtained on the test sets by applying the system
112
trained on the combined training?development set.
For analysis, also the baseline method and the
method of Bjo?rne et al (2010) were evaluated on
the test sets.
3.3 Baselines
The baselines were designed to reflect an IE sys-
tem following the one-node-per-token principle
without an advanced postprocessing but still en-
forcing the annotation scheme constraints.
With the strict specifications of the BioNLP?09
Shared Task, a sound baseline is obtained sim-
ply by enforcing the constraints through a minimal
set of changes. Nodes with outgoing Cause and
Theme edges are duplicated into all Cause?Theme
pairs. Binding nodes remain unchanged since they
can have several Theme arguments while the oth-
ers are treated as distributive nodes with distribu-
tive incoming edges.
Although BioInfer is less restricted with respect
to valid argument combinations, a feasible base-
line can be obtained by adapting the BioNLP?09
Shared Task baseline algorithm. Cause?Theme is
replaced with agent?patient while Binding is ex-
tended to symmetric relationships (i.e. participant
arguments). In addition, relationships with sub
arguments are treated as collective which reflects
multiple components in a single complex. These
changes were also applied to the method of Bjo?rne
et al (2010) when analysing BioInfer.
3.4 Evaluation
The standard precision?recall?F1 metrics was
used in the evaluation. True/false positive/negative
instances were determined by the equality of the
nodes as relationships: pairs of equal nodes were
true positives while unique nodes in the depro-
jected and the original graph were false positives
and false negatives, respectively.
The equality of references to text was deter-
mined after removing the tokens found in a non-
exhaustive list of common stop-words including
prepositions, articles, and non-alphanumeric char-
acters. This relaxes an unnecessary requirement of
the node prediction step to find also those tokens
in the BioInfer annotation that do not contribute to
the semantics of the nodes. For example, preposi-
tions should be associated with edges rather than
nodes.
The F1-scores were further analysed with the
Wilcoxon signed-rank test (Wilcoxon, 1945), as
implemented in Scipy v. 0.7.0, by considering
BioInfer
gold predicted
method total symm. total symm.
baseline 88.26 63.62 29.38 18.64
Bjo?rne et al 89.15 72.35 29.14 20.37
proposed 92.42 78.79 30.79 24.47
BioNLP?09
gold predicted
method total symm. total symm.
baseline 92.52 64.15 43.70 21.05
Bjo?rne et al 94.51 83.37 45.13 35.21
proposed 95.08 84.32 45.32 36.63
Table 1: The F1-scores on the test sets. Total
is cumulative over all nodes with outgoing edges
while symm. refers to the symmetric types. Gold
and predicted refer to the experiments with gold-
standard and predicted graphs, respectively.
each document as an experiment and using the
95% confidence level.
4 Results and discussion
The following discussion focuses on the deep re-
lationship equality as the evaluation criterion be-
cause it reflects the relationships of interest by re-
quiring the identification of the pertaining named
entities. Also, the discussion only considers the
experiments performed with the conjunct depen-
dency propagated parses obtained with the parser
of McClosky (2009) because switching parses did
not produce statistically significant differences in
performance. Note that the results are not compa-
rable to those of Bjo?rne et al (2010) because the
graph prediction was not fully optimised.
With respect to the deprojection task, BioInfer
was found to be similar to the BioNLP?09 Shared
Task corpus: it contains symmetric relationships
(c.f. Binding), asymmetric relationships (c.f. Reg-
ulation), and single-argument relationships. Only
the symmetric relationships are a challenge in the
deprojection task because they can have an arbi-
trary number of arguments. In contrast, the base-
line F1-scores for the others are above 94% on the
gold-standard graphs.
Table 1 shows the F1-scores on the test sets
of BioInfer and the BioNLP?09 Shared Task cor-
pus for the overall performance as well as for
the symmetric relationships only. The proposed
method outperforms the two other methods in all
113
experiments and the ?F1 against the proposed
method are statistically significant with the ex-
ception of the method of Bjo?rne et al (2010) on
the BioNLP?09 Shared Task corpus. Although
not conclusively better than the earlier, specialised
method in its own task, the proposed method
successfully achieves the intended generalisation
without an adverse effect.
The observed improvement over the method of
Bjo?rne et al (2010) is likely due to two factors.
First, using machine-learning rather than a sim-
ple rule-based system allows for more accurate
modelling of the problem. Second, the proposed
method can handle a wider variety of cases due to
the classification of edges. For example, the graph
in Figure 4A can correctly be deprojected, which
is not possible for the earlier method. However,
the latter factor is only effective on BioInfer, the
more complex of the two corpora, which is con-
sistent with the observed statistical significances.
The proposed deprojection method is currently
limited to the phenomena encountered in the two
analysed corpora since the decision to use binary
classification was based on the experimental ob-
servation that neither class is appropriate only in
rare cases. More classes will be needed to further
generalise and improve the system. One such class
could be respective which denotes a selective pair-
ing of sibling nodes. For example, the sentence
?A and B binds C and D, respectively? currently
results in false positive pairs A?D and B?C. Sim-
ilarly, adding secondary arguments (e.g. location)
and relationship modifiers (e.g. negation) into con-
sideration is likely to necessitate new, more com-
plex transformations and their respective classes.
Also, to filter out incorrectly predicted edges will
require the introduction of additional classes. The
critical question is whether a reasonably small set
of classes with extensive enough a coverage can
be found.
Another limitation is that the approach expects
an annotation scheme in which relationship argu-
ments have the tendency of following syntactic
dependencies as observed for BioInfer by Bjo?rne
et al (2008). This expectation may deteriorate the
performance on highly refined schemes which do
not consider syntax. On the other hand, since it
relies more on the syntactic than on the biolog-
ical properties of the relationships, the proposed
approach should be applicable beyond the domain
of biomolecular events (e.g. to gene?disease rela-
tionships or static relations).
The F1-scores in Table 1 indicate that the
BioNLP?09 Shared Task corpus is easier to ex-
tract than BioInfer. This is likely due to the nar-
rower scope and the stricter constraints of the
former. In absolute terms, the proposed method
yields the largest improvement over the baseline
on the gold-standard graphs which suggests that
it is negatively affected by the presence of false
nodes/edges or that the predicted graphs contain
relatively more relationships that are trivially de-
projected. On the other hand, in relative terms, the
largest improvements are observed for symmetric
relationships in the BioNLP?09 Shared Task cor-
pus but overall in BioInfer. This is likely due to the
differences in the relationship type distributions.
The system recently developed by Miwa et al
(2010), based on the architecture of Bjo?rne et al
(2010), utilises a ML-based deprojection which
enumerates all possible argument combinations
and classifies them as positive or negative. While
this approach may be prohibitively expensive in
more complex schemes in which the number of
arguments and their types is higher, it should out-
perform the proposed method on the BioNLP?09
Shared Task corpus. Since Miwa et al do not
analyse the contribution of the deprojection to the
overall performance, a direct comparison of the
two methods is impossible. In any case, the sys-
tems of Bjo?rne et al (2010) and Miwa et al (2010)
demonstrate the success of the architecture using
deprojection and further motivate the investigation
of deprojection methods.
4.1 Future directions
In the future, the proposed method will be stud-
ied and further improved with two other corpora,
GENIA Event Annotation (Kim et al, 2008) and
Gene Regulation Event Corpus (Thompson et al,
2009), which are similar in their purpose com-
pared to the already-analysed corpora. The former
corpus is interesting because of the co-operativity
of event participants which relaxes the restrictions
on asymmetric relationships while the latter con-
tains an extensive annotation for non-primary ar-
guments. The method could also be examined
with the static relation extraction task recently in-
troduced by Pyysalo et al (2009).
In addition to improving the method and ex-
tending it to non-primary arguments, embedding
114
the presented approach to a joint inference system,
such as Markov Logic Network (MLN), will be
studied. Deprojection is likely to greatly benefit
methods based on Markov Logic which is ?not yet
able to deal with cases where the number and iden-
tity of entities is unknown, while relations/links
between known objects can be readily modelled?
(Riedel et al, 2009). The objective is to combine
the graph prediction and the deprojection steps
as well as to simultaneously enforce task-specific
constraints and adapt to the presence of false pos-
itive nodes and edges. This should be achiev-
able by extending the methods developed for the
BioNLP?09 Shared Task corpus by Riedel et al
(2009) or by Poon and Vanderwende (2010), both
of which determine the correct argument combi-
nations outside of the Markov Logic framework.
Semantic role labelling (SRL) is a task simi-
lar to the graph-based relationship extraction ap-
plied in this paper although the former typically
only concerns shallow predicate?argument struc-
tures (Hacioglu, 2004; Surdeanu et al, 2008). The
similarities between the tasks suggest that explor-
ing them jointly may benefit the development of
information extraction methods.
In the long term, semantic schemes should be
developed such that, ideally, all syntactic tokens
are considered for their semantics and semantic
relationships readily follow from their dependen-
cies. Such schemes, closely following the syn-
tax, could improve both the graph prediction and
the deprojection. In this research direction, graph-
based knowledge representations such as concep-
tual graphs (Sowa, 1976; Chein and Mugnier,
2008) or graphical logical forms such as the one
proposed by Allen et al (2008) could be adopted.
Given the frequency of coordinations in the
biomedical domain, deprojection may prove to
be useful in the development of deep semantic
parsing in the biomedical domain. For example,
with improved semantic schemes, it could provide
a means to generate complete, detailed semantic
graphs directly from deep dependency analyses in
a single-step by applying joint inference to achieve
simultaneous node/edge relabelling and graph de-
projection.
5 Conclusions
This study presents a method for reconstructing
the original semantic graphs from their projections
by determining the correct combinations of rela-
tionship arguments. It generalises the postprocess-
ing step of the system described by Bjo?rne et al
(2010) and extends the extraction capability of this
system to arbitrary graphs of nested biomolecular
relationships. The evaluation of the method on
BioInfer and the BioNLP?09 Shared Task corpus
indicates that the approach is viable for primary
relationship arguments. For BioInfer, the outcome
is, to the best of our knowledge, the first reported
result of the task of extracting the nested relation-
ships in its original version.
The presented method facilitates an IE approach
in which the identification of semantic entities is
performed on the one-entity-per-token basis and
relationship arguments are identified in a mutu-
ally independent manner disregarding the seman-
tics of the argument combinations. The method
handles the selection of the correct argument com-
binations, which is non-trivial particularly when
coordinations are involved, and generates the final
output in which a single token can refer to several
entities. This approach improves the utilisation of
deep dependency analyses by simplifying the cor-
relation between them and semantic graphs. Due
to its independent nature, the method can be cou-
pled to any system identifying relationships on the
one-per-token basis.
The implemented system will be available upon
request.
Acknowledgements
Thanks to Filip Ginter for his help with the
parses. This study was funded by Academy of Fin-
land. Computational resources were provided by
CSC ? IT Center for Science.
References
J. Allen, M. Swift, and W. de Beaumont. 2008. Deep
semantic analysis of text. In Proceedings of the
2008 Conference on Semantics in Text Processing
(STEP?08), pages 343?354.
J. Bjo?rne, S. Pyysalo, F. Ginter, and T. Salakoski. 2008.
How complex are complex protein-protein interac-
tions? In Proceedings of the Third International
Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 125?128.
J. Bjo?rne, J. Heimonen, F. Ginter, A. Airola,
T. Pahikkala, and T. Salakoski. 2010. Extract-
ing contextualized complex biological events with
rich graph-based feature sets. Computational Intel-
ligence. To appear.
115
C. Brisson. 2003. Plurals, all, and the nonuniformity
of collective predication. Linguistics and Philoso-
phy, 26:129?184.
E. Charniak and M. Johnson. 2005. Coarse-to-fine
n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting
of the Association for Computational Linguistics
(ACL?05), pages 173?180.
M. Chein and M.-L. Mugnier. 2008. Graph-based
Knowledge Representation: Computational Foun-
dations of Conceptual Graphs. Springer Publishing
Company Inc.
K. Crammer and Y. Singer. 2002. On the algorith-
mic implementation of multiclass kernel-based vec-
tor machines. Journal of Machine Learning Re-
search, 2:265?292.
M.-C. de Marneffe and C. Manning. 2008. The
stanford typed dependencies representation. In
Proceedings of the Coling?08 Workshop on Cross-
Framework and Cross-Domain Parser Evaluation,
pages 1?8.
M.-C. de Marneffe, B. MacCartney, and C. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In Proceedings of the Fifth
International Conference on Language Resources
and Evaluation (LREC?06), pages 449?454.
K. Hacioglu. 2004. Semantic role labeling using de-
pendency trees. In Proceedings of the 20th Inter-
national Conference on Computational Linguistics
(COLING?04), pages 1273?1276.
J. Heimonen, S. Pyysalo, F. Ginter, and T. Salakoski.
2008. Complex-to-pairwise mapping of biologi-
cal relationships using a semantic network represen-
tation. In Proceedings of the Third International
Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 45?52.
J.-D. Kim, T. Ohta, and J. Tsujii. 2008. Corpus anno-
tation for mining biomedical events from literature.
BMC Bioinformatics, 9:10.
J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsu-
jii. 2009. Overview of bionlp?09 shared task on
event extraction. In Proceedings of the NAACL?
HLT?09 Workshop on BioNLP: Companion Volume
for Shared Task (BioNLP?09), pages 1?9.
D. McClosky and E. Charniak. 2008. Self-training for
biomedical parsing. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, Short
Papers (ACL?08: HLT), pages 101?104.
D. McClosky. 2009. Any Domain Parsing: Au-
tomatic Domain Adaptation for Natural Language
Parsing. Ph.D. thesis, Department of Computer Sci-
ence, Brown University, Providence, Rhode Island,
USA.
M. Miwa, R. Saetre, J.-D. Kim, and J. Tsujii. 2010.
Event extraction with complex event classification
using rich features. Journal of Bioinformatics and
Computational Biology, 8:131?146.
H. Poon and L. Vanderwende. 2010. Joint inference
for knowledge extraction from biomedical literature.
In Proceedings of Human Language Technologies:
The 11th Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL?HLT?10).
M. Porter. 1980. An algorithm for suffix stripping.
Program, 14:130?137.
S. Pyysalo, F. Ginter, J. Heimonen, J. Bjo?rne,
J. Boberg, J. Ja?rvinen, and T. Salakoski. 2007.
BioInfer: a corpus for information extraction in the
biomedical domain. BMC Bioinformatics, 8:50.
S. Pyysalo, T. Ohta, J.-D. Kim, and J. Tsujii.
2009. Static relations: a piece in the biomed-
ical information extraction puzzle. In Proceed-
ings of the NAACL?HLT?09 Workshop on BioNLP
(BioNLP?09), pages 1?9.
J. Quinlan. 1993. C4.5: programs for machine learn-
ing. Morgan Kaufmann Publishers Inc.
S. Riedel, H.-W. Chun, T. Takagi, and J. Tsujii.
2009. A markov logic approach to bio-molecular
event extraction. In Proceedings of the NAACL?
HLT?09 Workshop on BioNLP: Companion Volume
for Shared Task (BioNLP?09), pages 41?49.
R. Scha and D. Stallard. 1988. Multi-level plurals
and distributivity. In Proceedings of the 26th An-
nual Meeting of the Association for Computational
Linguistics (ACL?88), pages 17?24.
J. Sowa. 1976. Conceptual graphs for a data base in-
terface. IBM Journal of Research and Development,
20:336?357.
M. Surdeanu, R. Johansson, A. Meyers, L. Ma`rquez,
and J. Nivre. 2008. The CoNLL 2008 shared
task on joint parsing of syntactic and semantic de-
pendencies. In Proceedings of the Twelfth Confer-
ence on Computational Natural Language Learning
(CoNLL?08), pages 159?177.
P. Thompson, S. Iqbal, J. McNaught, and S. Anani-
adou. 2009. Construction of an annotated corpus
to support biomedical information extraction. BMC
Bioinformatics, 10:349.
I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Al-
tun. 2004. Support vector machine learning for in-
terdependent and structured output spaces. In Pro-
ceedings of the 21st International Machine Learning
Conference (ICML?04), page 104.
F. Wilcoxon. 1945. Individual comparisons by ranking
methods. Biometrics Bulletin, 1:80?83.
116
Proceedings of BioNLP Shared Task 2011 Workshop, pages 183?191,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Generalizing Biomedical Event Extraction
Jari Bjo?rne and Tapio Salakoski
Department of Information Technology, University of Turku
Turku Centre for Computer Science (TUCS)
Joukahaisenkatu 3-5, 20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
We present a system for extracting biomedical
events (detailed descriptions of biomolecular
interactions) from research articles. This sys-
tem was developed for the BioNLP?11 Shared
Task and extends our BioNLP?09 Shared Task
winning Turku Event Extraction System. It
uses support vector machines to first detect
event-defining words, followed by detection
of their relationships. The theme of the
BioNLP?11 Shared Task is generalization, ex-
tending event extraction to varied biomedical
domains. Our current system successfully pre-
dicts events for every domain case introduced
in the BioNLP?11 Shared Task, being the only
system to participate in all eight tasks and all
of their subtasks, with best performance in
four tasks.
1 Introduction
Biomedical event extraction is the process of auto-
matically detecting statements of molecular interac-
tions in research articles. Using natural language
processing techniques, an event extraction system
predicts relations between proteins/genes and the
processes they take part in. Manually annotated cor-
pora are used to evaluate event extraction techniques
and to train machine-learning based systems.
Event extraction was popularised by the
BioNLP?09 Shared Task on Event Extraction
(Kim et al, 2009), providing a more detailed
alternative for the older approach of binary inter-
action detection, where each pair of protein names
co-occurring in the text is classified as interacting or
not. Events extend this formalism by adding to the
relations direction, type and nesting. Events define
the type of interaction, such as phosphorylation,
and commonly mark in the text a trigger word
(e.g. ?phosphorylates?) describing the interaction.
Directed events can define the role of their protein
or gene arguments as e.g. cause or theme, the agent
or the target of the biological process. Finally,
events can act as arguments of other events, creating
complex nested structures that accurately describe
the biological interactions stated in the text. For
example, in the case of a sentence stating ?Stat3
phosphorylation is regulated by Vav?, a phospho-
rylation-event would itself be the argument of a
regulation-event.
We developed for the BioNLP?09 Shared Task the
Turku Event Extraction System, achieving the best
performance at 51.95% F-score (Bjo?rne et al, 2009).
This system separated event extraction into multiple
classification tasks, detecting individually the trig-
ger words defining events, and the arguments that
describe which proteins or genes take part in these
events. Other approaches used in the Shared Task in-
cluded e.g. joint inference (Riedel et al, 2009). An
overall notable trend was the use of full dependency
parsing (Buyko et al, 2009; Van Landeghem et al,
2009; Kilicoglu and Bergler, 2009).
In the following years, event extraction has been
the subject of continuous development. In 2009, af-
ter the BioNLP?09 Shared Task, we extended our
system and improved its performance to 52.85%
(Bjo?rne et al, 2011). In 2010, the system introduced
by Miwa et. al. reached a new record performance of
56.00% (Miwa et al, 2010a).
183
Regulation
NN NN VB NN CC .conj_and>
<nn
dobj>
<nsubj
NN
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
unmerging
D
C
E
edge detection
trigger detection
B
A
dobj>
parsing
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
<Theme Cause> Cause>
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
ProteinSTAT3 phosphorylation involve ProteinVav and ProteinRac-1 .
STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) mayNN
appos> <aux
VB
Ser(727) may
Ser(727) may
Ser(727) may
Ser(727) may
Entity
<Site
Entity
Entity
<Theme
<Theme<Site <Theme
Regulation
ProteinSTAT3 Phosphorylationphosphorylation involve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
speculation and negation detectionF
Ser(727) mayEntity
<Theme<Site <Theme
RegulationSpec
Spec
Figure 1: Event extraction. In most tasks named entities
are given (A). Sentences are parsed (B) to produce a de-
pendency parse. Entities not given are predicted through
trigger detection (C). Edge detection predicts event argu-
ments between entities (D) and unmerging creates events
(E). Finally, event modality is predicted (F). When the
graph is converted to the Shared Task format, site argu-
ments are paired with core arguments that have the same
target protein.
In 2010, we applied the Turku Event Extrac-
tion System to detecting events in all 18 million
PubMed abstracts, showing its scalability and gener-
alizability into real-world data beyond domain cor-
pora (Bjo?rne et al, 2010). In the current BioNLP?11
Shared Task1 (Kim et al, 2011), we demonstrate its
generalizability to different event extraction tasks by
applying what is, to a large extent, the same system
to every single task and subtask.
2 System Overview
Our system divides event extraction into three main
steps (Figure 1 C, D and E). First, entities are
predicted for each word in a sentence. Then, ar-
guments are predicted between entities. Finally,
entity/argument sets are separated into individual
events.
1http://sites.google.com/site/bionlpst/
ProteinSTAT3 Phosphorylationphosphorylation
A: Primary representation
Ser(727)Entity
<Site <Theme
B: EPI representation
ProteinSTAT3 PhosphorylationphosphorylationSer(727)Entity
<Site<Theme
ProteinSTAT3 PhosphorylationphosphorylationSer(727)Entity
<Site <Theme
C: Hypothetical
Figure 2: Site argument representation. Site arguments
add detail to core arguments. (A) In most tasks we
link both core and site arguments to given protein nodes.
This minimizes the number of outgoing edges per trigger
node, simplifying unmerging, but loses the connection
between site and core arguments. (B) In the EPI task, all
events with site-arguments have a single core argument,
so linking sites to the trigger node preserves the site/core
connection. (C) To both limit number of arguments in
trigger nodes and preserve site information, event argu-
ments using sites could be linked to protein nodes through
the site entity. However, in this approach the core argu-
ment would remain undetected if the site wasn?t detected.
2.1 Graph Representation
The BioNLP?11 Shared Task consists of eight sep-
arate tasks. Most of these follow the BioNLP?09
Shared Task annotation scheme, which defines
events as having a trigger entity and one or more ar-
guments that link to other events or protein/gene en-
tities. This annotation can be represented as a graph,
with trigger and protein/gene entities as nodes, and
arguments (e.g. theme) as edges. In our graph repre-
sentation, an event is defined implicitly as a trigger
node and its outgoing edges (see Figure 1 F).
Most of the BioNLP?11 Shared Task tasks define
task-specific annotation terminology, but largely fol-
low the BioNLP?09 definition of events. Some new
annotation schemes, such as the bracket notation in
the CO-task can be viewed simply as alternative rep-
resentations of arguments. The major new feature
is relations or triggerless events, used in the REL,
REN, BB and BI tasks. In our graph representation,
this type of event is a single, directed edge.
Some event arguments have a matching site ar-
gument that determines the part of the protein the
argument refers to (Figure 2). To allow detection of
core arguments independently of site arguments, in
184
most tasks we link site arguments directly to pro-
teins (Figure 2 A). This maximises extraction per-
formance on core events, but losing the connection
between site and core arguments limits performance
on site arguments.
To further simplify event extraction all sentences
are processed in isolation, so events crossing sen-
tence boundaries (intersentence events, Table 2) can-
not be detected. This also limits the theoretical max-
imum performance of the system (see Figure 3).
In the provided data an event is annotated only
once for a set of equivalent proteins. For example, in
the sentence ?Ubiquitination of caspase 8 (casp8)?
a ubiquitination event would be annotated only for
?caspase 8?, ?casp8? being marked as equivalent
to ?caspase 8?. To improve training data consis-
tency, our system fully resolves these equivalences
into new events, also recursively when a duplicated
event is nested in another event (Table 2). Resolved
equivalences were used for event extraction in the
BioNLP?11 GE, ID, EPI and BB tasks, although
based on tests with the GE dataset their impact on
performance was negligible.
2.2 Machine Learning
The machine learning based event detection com-
ponents classify examples into one of the positive
classes or as negatives, based on a feature vector
representation of the data. To make these classifi-
cations, we use the SVMmulticlass support vector
machine2 (Tsochantaridis et al, 2005) with a linear
kernel. An SVM must be optimized for each classi-
fication task by experimentally determining the reg-
ularization parameter C. This is done by training the
system on a training dataset, and testing a number of
C values on a development dataset. When producing
predictions for the test set, the classifier is retrained
with combined training and development sets, and
the test data is classified with the previously deter-
mined optimal value of C.
Unlike in the BioNLP?09 Shared Task where
the three main parameters (trigger-detector, recall-
adjustment and edge-detector) were optimized in an
exhaustive grid search against the final metric, in
the new system only the recall-adjustment param-
2http://svmlight.joachims.org/svm_
multiclass.html
eter (see Section 2.5) is optimized against the final
metric, edge and trigger detector parameters being
optimized in isolation to speed up experiments.
2.3 Syntactic Analyses
The machine learning features that are used in
event detection are mostly derived from the syntac-
tic parses of the sentences. Parsing links together
related words that may be distant in their linear or-
der, creating a parse tree (see Figure 1 B).
We used the Charniak-Johnson parser (Char-
niak and Johnson, 2005) with David McClosky?s
biomodel (McClosky, 2010) trained on the GENIA
corpus and unlabeled PubMed articles. The parse
trees produced by the Charniak-Johnson parser were
further processed with the Stanford conversion tool
(de Marneffe et al, 2006), creating a dependency
parse (de Marneffe and Manning, 2008).
In the supporting tasks (REL, REN and CO) this
parsing was done by us, but in the main tasks the
organizers provided official parses which were used.
All parses for tasks where named entities were given
as gold data were further processed with a pro-
tein name splitter that divides at punctuation tokens
which contain named entities, such as ?p50/p65? or
?GATA3-binding?.
2.4 Feature Groups
To convert text into features understood by the clas-
sifier, a number of analyses are performed on the
sentences, mostly resulting in binary features stating
the presence or absence of some feature. Applica-
ble combinations of these features are then used by
the trigger detection, edge detection and unmerging
steps of the event extraction system.
Token features can be generated for each word
token, and they define the text of the token, its
Porter-stem (Porter, 1980), its Penn treebank part-
of-speech-tag, character bi- and trigrams, presence
of punctuation or numeric characters etc.
Sentence features define the number of named
entities in the sentence as well as bag-of-words
counts for all words.
Dependency chains follow the syntactic depen-
dencies up to a depth of three, starting from a token
of interest. They are used to define the immediate
context of these words.
185
Dependency path N-grams, are built from the
shortest undirected path of tokens and dependencies
linking together two entities, and are used in edge
detection. N-grams join together a token with its two
flanking dependencies as well as each dependency
with its two flanking tokens. While these N-grams
follow the direction of the entire path, the governor-
dependent directions of individual dependencies are
used to define token bigrams.
Trigger features can be built in cases where trig-
gers are already present, such as edge detection and
event construction. These features include the types
and supertypes of the trigger nodes, and combina-
tions thereof.
External features are additional features based
on data external to the corpus being processed. Such
features can include e.g. the presence of a word in
a list of key terms, Wordnet hypernyms, or other
resources that enhance performance on a particular
task. These are described in detail in Section 3.
2.5 Trigger Detection
Trigger words are detected by classifying each token
as negative or as one of the positive trigger classes.
Sometimes several triggers overlap, in which case
a merged class (e.g. phosphorylation?regulation) is
used. After trigger prediction, triggers of merged
classes are split into their component classes.
Most tasks evaluate trigger detection using ap-
proximate span, so detecting a single token is
enough. However, this token must be chosen consis-
tently for the classifier to be able to make accurate
predictions. For multi-token triggers, we select as
the trigger word the syntactic head, the root token of
the dependency parse subtree covering the entity.
When optimizing the SVM C-parameter for trig-
ger and edge detection, it is optimized in isolation,
maximizing the F-score for that classification task.
Edges can be predicted for an event only if its trig-
ger has been detected, but often the C-parameter that
maximizes trigger detection F-score has too low re-
call for optimal edge detection. A recall adjustment
step is used to fit together the trigger and edge de-
tectors. For each example, the classifier gives a con-
fidence score for each potential class, and picks as
the predicted class the one with the highest score. In
recall adjustment, the confidence score of each neg-
ative example is multiplied with a multiplier, and if
the result falls below the score of another class, that
class becomes the new classification. This multiplier
is determined experimentally by optimizing against
overall system performance, using the official task
metric for cases where a downloadable evaluator is
available (GE and BB).
2.6 Edge Detection
Edge detection is used to predict event arguments or
triggerless events and relations, all of which are de-
fined as edges in the graph representation. The edge
detector defines one example per direction for each
pair of entities in the sentence, and uses the SVM
classifier to classify the examples as negatives or as
belonging to one of the positive classes. As with the
trigger detector, overlapping positive classes are pre-
dicted through merged classes (e.g. cause?theme).
Task-specific rules defining valid argument types for
each entity type are used to considerably reduce the
number of examples that can only be negatives.
2.7 Unmerging
In the graph representation, events are defined
through their trigger word node, resulting in over-
lapping nodes for overlapping events. The trigger
detector can however predict a maximum of one trig-
ger node per type for each token. When edges are
predicted between these nodes, the result is a merged
graph where overlapping events are merged into a
single node and its set of outgoing edges. Taking
into account the limits of trigger prediction, the edge
detector is also trained on a merged graph version of
the gold data.
To produce the final events, these merged nodes
need to be ?pulled apart? into valid trigger and argu-
ment combinations. In the BioNLP?09 Shared Task,
this was done with a rule-based system. Since then,
further research has been done on machine learning
approaches for this question (Miwa et al, 2010b;
Heimonen et al, 2010). In our current system, un-
merging is done as an SVM-classification step. An
example is constructed for each argument edge com-
bination of each predicted node, and classified as a
true event or a false event to be removed. Tested on
the BioNLP?09 Shared Task data, this system per-
forms roughly on par with our earlier rule-based sys-
tem, but has the advantage of being more general
and thus applicable to all BioNLP?11 Shared Task
186
GE1 GE2 GE3 EPI ID BB BI CO REL RENTask
0
20
40
60
80
100
F-s
cor
e
Figure 3: Ranking of the systems participating in the
BioNLP?11 Shared Task. Our system is marked with
black dots and the dotted line shows its theoretical maxi-
mum performance (see Section 2.1) with all correct clas-
sifications.
tasks. The unmerging step is not required for trig-
gerless events which are defined by a single edge.
All of the tasks define varied, detailed limits on
valid event type and argument combinations. A final
validation step based on task-specific rules is used to
remove structurally incorrect events left over from
preceding machine learning steps.
2.8 Modality Detection
Speculation and negation are detected indepen-
dently, with binary classification of trigger nodes.
The features used are mostly the same as for trigger
detection, with the addition of a list of speculation-
related words based on the BioNLP?09 ST corpus.
3 Tasks and Results
The BioNLP?11 Shared Task consists of five main
tasks and three supporting tasks. Additionally, many
of these tasks specify separate subtasks. Except
for the GE-task, which defines three main evalua-
tion criteria, all tasks have a single primary evalua-
tion criterion. All evaluations are based on F-score,
the harmonic mean of precision and recall. Perfor-
mance of all systems participating in the BioNLP?11
Shared Task is shown in Figure 3. Our system?s per-
formance on both development and test sets of all
tasks is shown in Table 1.
Corpus Devel F Test F
GE?09 task 1 56.27 53.15
GE?09 task 2 54.25 50.68
GE task 1 55.78 53.30
GE task 2 53.39 51.97
GE task 3 38.34 26.86
EPI 56.41 53.33
ID 44.92 42.57
BB 27.01 26
BI 77.24 77
CO 36.22 23.77
REL 65.99 57.7
REN 84.62 87.0
Table 1: Devel and test results for all tasks. The perfor-
mance of our new system on the BioNLP?09 ST GENIA
dataset is shown for reference, with task 3 omitted due to
a changed metric. For GE-tasks, the Approximate Span
& Recursive matching criterion is used.
3.1 GENIA (GE)
The GENIA task is the direct continuation of the
BioNLP?09 Shared Task. The BioNLP?09 ST cor-
pus consisted only of abstracts. The new version ex-
tends this data by 30% with full text PubMed Central
articles.
Our system applied to the GE task is the most
similar to the one we developed for the BioNLP?09
Shared Task. The major difference is the replace-
ment of the rule-based unmerging component with
an SVM based one.
The GE task has three subtasks, task 1 is detection
of events with their main arguments, task 2 extends
this to detection of sites defining the exact molecu-
lar location of interactions, and task 3 adds the de-
tection of whether events are stated in a negated or
speculative context.
For task 3, speculation and negation detection, we
considered the GE, EPI and ID task corpora simi-
lar enough to train a single model on. Compared
to training on GE alone, example classification F-
score decreased for negation by 8 pp and increased
for speculation by 4 pp. Overall task 3 processing
was considerably simplified.
Our system placed third in task 1, second in task 2
and first in task 3. Task 1 had the most participants,
making it the most useful for evaluating overall per-
formance. Our F-score of 53.30% was within three
percentage points of the best performing system (by
187
Corpus sentences events equiv events nesting events intersentence events neg/spec events
GE?09 8906 11285 7.9% 38.8% 6.0% 12.1%
GE 11581 14496 6.6% 37.2% 6.0% 13.3%
EPI 7648 2684 9.1% 10.2% 9.3% 10.1%
ID 3193 2931 5.3% 21.3% 3.9% 4.9%
BB 1762 5843 79.4% N/A 86.0% 0%
BI 120 458 0% N/A 0% 0%
CO 8906 5284 0% N/A 8.5% N/A
REL 8906 2440 4.2% N/A 0% 0%
REN 13235 373 0% N/A 2.4% 0%
Table 2: Corpus statistics. Numbers are for all available annotated data, i.e. the merged training and development sets.
team FAUST), indicating that our chosen event de-
tection approach still remains competitive. For ref-
erence, we ran our system also on the BioNLP?09
data, reaching an F-score of 53.15%, a slight in-
crease over the 52.85% we previously reported in
Bjo?rne et al (2011).
3.2 Epigenetics and Post-translational
Modifications (EPI)
All events in the EPI task that have additional argu-
ments (comparable to the site-arguments in the GE-
task) have a single core argument. We therefore use
for this task a slightly modified graph representation,
where all additional arguments are treated as core ar-
guments, linking directly to the event node (Figure 2
B). The number of argument combinations per pre-
dicted event node remains manageable for the un-
merging system and full recovery of additional ar-
guments is possible.
Eight of the EPI event types have correspond-
ing reverse events, such as phosphorylation and de-
phosphorylation. Many of these reverse events are
quite rare, resulting in too little training data for the
trigger detector to find them. Therefore we merge
each reverse event type into its corresponding for-
ward event type. After trigger detection, an addi-
tional rule-based step separates them again. Most of
the reverse classes are characterized by a ?de?-prefix
in their trigger word. On the EPI training dataset,
the rule-based step determined correctly whether an
event was reversed in 99.6% of cases (1698 out of
1704 events). Using this approach, primary criterion
F-score on the development set increased 1.33 per-
centage points from 55.08% to 56.41%. Several pre-
viously undetectable small reverse classes became
detectable, with e.g. deubiquitination (8 instances in
the development set) detected at 77.78% F-score.
Our system ranked first on the EPI task, outper-
forming the next-best system (team FAUST) by over
18 percentage points. On the alternative core metric
our system was also the first, but the FAUST system
was very close with only a 0.27 percentage point dif-
ference. Since the core metric disregards additional
arguments, it may be that our alternative approach
for representing these arguments (Figure 2 B) was
important for the primary criterion difference.
3.3 Infectious Diseases (ID)
The annotation scheme for the ID task closely fol-
lows the GE task, except for an additional process
event type that may have no arguments, and for five
different entity types in place of the protein type.
Our approach for the ID task was identical to the
GE task, but performance relative to the other teams
was considerably lower. Primary evaluation metric
F-score was 42.57% vs. 43.44% for the core metric
which disregards additional arguments, indicating
that these are not the reason for low performance.
3.4 Bacteria Biotopes (BB)
The BB task considers detection of events describ-
ing bacteria and their habitats. The task defines only
two event types but a large number of entity types
which fall into five supertypes. All entities must be
predicted and all events are triggerless.
Unlike in the other main tasks, in the BB task ex-
act spans are required for Bacterium-type entities,
which usually consist of more than one token (e.g.
B. subtilis). After trigger detection, a rule-based step
attempts to extend predicted trigger spans forwards
and backwards to cover the correct span. When ex-
tending the spans of BB training set gold entity head
188
tokens, this step produced the correct span for 91%
(399 out of 440) of Bacterium-type entities.
To aid in detecting Bacterium-entities a list of
bacteria names from the List of Prokaryotic names
with Standing in Nomenclature3 was used (Euze?by,
1997) as external features. To help in detecting the
heterogeneous habitat-entities, synonyms and hy-
pernyms from Wordnet were used (Fellbaum, 1998).
The development set lacked some event classes, so
we moved some documents from the training set to
the development set to include these.
Our F-score was the lowest of the three partici-
pating systems, and detailed results show a consis-
tently lower performance in detecting the entities.
The large number of intersentence events (Table 2)
also considerably limited performance (Figure 3).
3.5 Bacteria Gene Interactions (BI)
The BI-task considers events related to genetic pro-
cesses of the bacterium Bacillus subtilis. This task
defines a large number of both entity and event
types, but all entities are given as gold-standard data,
therefore we start from edge detection (Figure 1 D).
All BI events are triggerless.
In this task manually curated syntactic parses are
provided. As also automated parses were available,
we tested them as an alternative. With the Charniak-
Johnson/McClosky parses overall performance was
only 0.65 percentage points lower (76.59% vs.
77.24%). As with the BB task, we moved some doc-
uments from the training set to the development set
to include missing classes.
Despite this task being very straightforward com-
pared to the other tasks we were the only participant.
Therefore, too many conclusions shouldn?t be drawn
from the performance, except to note that a rather
high F-score is to be expected with all the entities
being given as gold data.
3.6 Protein/Gene Coreference (CO)
In the CO supporting task the goal is to extract
anaphoric expressions. Even though our event ex-
traction system was not developed with corefer-
ence resolution in mind, the graph representation
can be used for the coreference annotation, making
coreference detection possible. Anaphoras and An-
3http://www.bacterio.cict.fr/
tecedents are both represented as Exp-type entities,
with Coref -type edges linking Anaphora-entities to
Antecedent-entities and Target-type edges linking
Protein-type entities to Antecedent-entities.
In the CO-task, character spans for detected enti-
ties must be in the range of a full span and minimum
span. Therefore in this task we used an alternative
trigger detector. Instead of predicting one trigger per
token, this component predicted one trigger per each
syntactic phrase created by the Charniak-Johnson
parser. Since these phrases don?t cover most of the
CO-task triggers, they were further subdivided into
additional phrases, e.g. by cutting away determiners
and creating an extra phrase for each noun-token,
with the aim of maximizing the number of included
triggers and minimizing the number of candidates.
Our system placed fourth out of six, reaching an
F-score of 23.77%. Coreference resolution being a
new subject for us and our system not being devel-
oped for this domain, we consider this an encour-
aging result, but conclude that in general dedicated
systems should be used for coreference resolution.
3.7 Entity Relations (REL)
The REL supporting task concerns the detection of
static relationships, Subunit-Complex relations be-
tween individual proteins and protein complexes and
Protein-Component relations between a gene or pro-
tein and its component, such as a protein domain or
gene promoter. In the graph representation these re-
lations are defined as edges that link together given
protein/gene names and Entity-type entities that are
detected by the trigger detector.
To improve entity detection, additional features
are used. Derived from the REL annotation, these
features highlight structures typical for biomolecular
components, such as aminoacids and their shorthand
forms, domains, motifs, loci, termini and promot-
ers. Many of the REL entities span multiple tokens.
Since the trigger detector predicts one entity per to-
ken, additional features are defined to mark whether
a token is part of a known multi-token name.
Our system had the best performance out of four
participating systems with an F-score of 57.7%, over
16 percentage points higher than the next. Develop-
ment set results show that performance for the two
event classes was very close, 66.40% for Protein-
Component and 65.23% for Subunit-Complex.
189
3.8 Bacteria Gene Renaming (REN)
The REN supporting task is aimed at detecting state-
ments of B. Subtilis gene renaming where a syn-
onym is introduced for a gene. The REL task defines
a single relation type, Renaming, and a single entity
type, Gene. All entities are given, so only edge de-
tection is required. Unlike the other tasks, the main
evaluation criterion ignores the direction of the rela-
tions, so they are processed as undirected edges in
the graph representation.
Edge detection performance was improved with
external features based on two sources defining
known B. Subtilis synonym pairs: The Uniprot B.
Subtilis gene list ?bacsu?4 and SubtiWiki5, the B.
Subtilis research community annotation wiki.
For the 300 renaming relations in the REN train-
ing data, the synonym pair was found from the
Uniprot list in 66% (199 cases), from SubtiWiki in
79% (237 cases) and from either resource in 81.3%
(244 cases). For the corresponding negative edge
examples, Uniprot or SubtiWiki synonym pairs ap-
peared in only 2.1% (351 out of 16640 examples).
At 87.0% F-score our system had the highest per-
formance out of the three participants, exceeding the
next highest system by 17.1 percentage points. If
Uniprot and SubtiWiki features are not used, perfor-
mance on the development set is still 67.85%, close
to the second highest performing system on the task.
4 Conclusions
We have developed a system that addresses all tasks
and subtasks in the BioNLP?11 Shared Task, with
top performance in several tasks. With the modular
design of the system, all tasks could be implemented
with relatively small modifications to the processing
pipeline. The graph representation which covered
naturally all different task annotations was a key fea-
ture in enabling fast system development and test-
ing. As with the Turku Event Extraction System de-
veloped for the BioNLP?09 Shared Task, we release
this improved system for the BioNLP community
under an open source license at bionlp.utu.fi.
Of all the tasks, the GE-task, which extends the
BioNLP?09 corpus, is best suited for evaluating ad-
vances in event extraction in the past two years.
4http://www.uniprot.org/docs/bacsu
5http://subtiwiki.uni-goettingen.de/
Comparing our system?s performance on the GE?09
corpus with the current one, we can assume that the
two corpora are of roughly equal difficulty. There-
fore we can reason that overall event extraction
performance has increased about three percentage
points, the highest performance on the current GE-
task being 56.04% by team FAUST. It appears that
event extraction is a hard problem, and that the im-
mediate easy performance increases have already
been found. We hope the BioNLP?11 Shared Task
has focused more interest in the field, hopefully
eventually leading to breakthroughs in event extrac-
tion and bringing performance closer to established
fields of BioNLP such as syntactic parsing or named
entity recognition.
That our system could be generalized to work on
all tasks and subtasks, indicates that the event extrac-
tion approach can offer working solutions for several
biomedical domains. A potential limiting factor cur-
rently is that most task-specific corpora annotate a
non-overlapping set of sentences, necessitating the
development of task-specific machine learning mod-
els. Training on multiple datasets could mean that
positives of one task would be unannotated on text
from the other task, confusing the classifier. On the
other hand, multiple overlapping task annotations on
the same text would permit the system to learn from
the interactions and delineations of different annota-
tions. System generalization has been successfully
shown in the BioNLP?11 Shared Task, but has re-
sulted in a number of separate extraction systems. It
could well be that the future of event extraction re-
quires also the generalization of corpus annotations.
As future directions, we intend to further improve
the scope and usability of our event extraction sys-
tem. We will also continue our work on PubMed-
scale event extraction, possibly applying some of the
new extraction targets introduced by the BioNLP?11
Shared Task.
Acknowledgments
We thank the Academy of Finland for funding, CSC
? IT Center for Science Ltd for computational re-
sources and Filip Ginter and Sofie Van Landeghem
for help with the manuscript.
190
References
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In Proceedings of the BioNLP 2009Work-
shop Companion Volume for Shared Task, pages 10?
18, Boulder, Colorado. Association for Computational
Linguistics.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-
jii, and Tapio Salakoski. 2010. Scaling up biomed-
ical event extraction to the entire PubMed. In Pro-
ceedings of the 2010 Workshop on Biomedical Natural
Language Processing, pages 28?36, Uppsala, Sweden,
July. Association for Computational Linguistics.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2011. Extract-
ing contextualized complex biological events with rich
graph-based feature sets. Computational Intelligence,
Special issue on Extracting Bio-molecular Events from
Literature. To appear, accepted in 2009.
Ekaterina Buyko, Erik Faessler, Joachim Wermter, and
Udo Hahn. 2009. Event extraction from trimmed de-
pendency graphs. In Proceedings of the BioNLP 2009
Workshop Companion Volume for Shared Task, pages
19?27. ACL.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL?05),
pages 173?180. Association for Computational Lin-
guistics.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed depen-
dency parses from phrase structure parses. In Proceed-
ings of LREC-06, pages 449?454.
J. P. Euze?by. 1997. List of bacterial names with standing
in nomenclature: a folder available on the internet. Int
J Syst Bacteriol, 47(2):590?592.
Christiane Fellbaum, editor. 1998. WordNet: an elec-
tronic lexical database. MIT Press.
Juho Heimonen, Jari Bjo?rne, and Tapio Salakoski. 2010.
Reconstruction of semantic relationships from their
projections in biomolecular domain. In Proceedings of
the 2010 Workshop on Biomedical Natural Language
Processing, pages 108?116, Uppsala, Sweden, July.
Association for Computational Linguistics.
Halil Kilicoglu and Sabine Bergler. 2009. Syntactic de-
pendency based heuristics for biological event extrac-
tion. In Proceedings of the BioNLP 2009 Workshop
Companion Volume for Shared Task, pages 119?127.
ACL.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction. In
Proceedings of the BioNLP 2009 Workshop Compan-
ion Volume for Shared Task, pages 1?9, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011. Overview of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Marie-Catherine de Marneffe and Christopher Manning.
2008. The Stanford typed dependencies representa-
tion. In COLING Workshop on Cross-framework and
Cross-domain Parser Evaluation.
David McClosky. 2010. Any Domain Parsing: Auto-
matic Domain Adaptation for Natural Language Pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and
Jun?ichi Tsujii. 2010a. A comparative study of syn-
tactic parsers for event extraction. In Proceedings of
the 2010 Workshop on Biomedical Natural Language
Processing, BioNLP ?10, pages 37?45, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and Jun?ichi
Tsujii. 2010b. Event extraction with complex event
classification using rich features. J Bioinform Comput
Biol, 8:131?146.
Martin F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130?137.
Sebastian Riedel, Hong-Woo Chun, Toshihisa Takagi,
and Jun?ichi Tsujii. 2009. A markov logic approach
to bio-molecular event extraction. In Proceedings of
the Workshop on Current Trends in Biomedical Natu-
ral Language Processing: Shared Task, BioNLP ?09,
pages 41?49, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hof-
mann, and Yasemin Altun. 2005. Large margin
methods for structured and interdependent output vari-
ables. Journal of Machine Learning Research (JMLR),
6(Sep):1453?1484.
Sofie Van Landeghem, Yvan Saeys, Bernard De Baets,
and Yves Van de Peer. 2009. Analyzing text in search
of bio-molecular events: a high-precision machine
learning framework. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 128?136. ACL.
191
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 82?90,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
PubMed-Scale Event Extraction for Post-Translational Modifications,
Epigenetics and Protein Structural Relations
Jari Bjo?rne 1,2, Sofie Van Landeghem 3,4, Sampo Pyysalo 5, Tomoko Ohta 5,
Filip Ginter 2, Yves Van de Peer 3,4, Sophia Ananiadou 5 and Tapio Salakoski 1,2
1Turku Centre for Computer Science (TUCS), Joukahaisenkatu 3-5B, 20520 Turku, Finland
2Department of Information Technology, 20014 University of Turku, Finland
3Department of Plant Systems Biology, VIB, Technologiepark 927, 9052 Gent, Belgium
4Department of Plant Biotechnology and Bioinformatics, Ghent University, Gent, Belgium
5National Centre for Text Mining and University of Manchester,
Manchester Interdisciplinary Biocentre,131 Princess Street, Manchester, UK
Abstract
Recent efforts in biomolecular event extrac-
tion have mainly focused on core event types
involving genes and proteins, such as gene
expression, protein-protein interactions, and
protein catabolism. The BioNLP?11 Shared
Task extended the event extraction approach
to sub-protein events and relations in the Epi-
genetics and Post-translational Modifications
(EPI) and Protein Relations (REL) tasks. In
this study, we apply the Turku Event Ex-
traction System, the best-performing system
for these tasks, to all PubMed abstracts and
all available PMC full-text articles, extract-
ing 1.4M EPI events and 2.2M REL relations
from 21M abstracts and 372K articles. We
introduce several entity normalization algo-
rithms for genes, proteins, protein complexes
and protein components, aiming to uniquely
identify these biological entities. This nor-
malization effort allows direct mapping of
the extracted events and relations with post-
translational modifications from UniProt, epi-
genetics from PubMeth, functional domains
from InterPro and macromolecular structures
from PDB. The extraction of such detailed
protein information provides a unique text
mining dataset, offering the opportunity to fur-
ther deepen the information provided by ex-
isting PubMed-scale event extraction efforts.
The methods and data introduced in this study
are freely available from bionlp.utu.fi.
1 Introduction
Biomedical domain information extraction has in re-
cent years seen a shift from focus on the extraction
of simple pairwise relations (Pyysalo et al, 2008;
Tikk et al, 2010) towards the extraction of events,
represented as structured associations of arbitrary
numbers of participants in specific roles (Ananiadou
et al, 2010). Domain event extraction has been pop-
ularized in particular by the BioNLP Shared Task
(ST) challenges in 2009 and 2011 (Kim et al, 2009;
Kim et al, 2011). While the BioNLP ST?09 em-
phasized protein interactions and regulatory rela-
tionships, the expressive event formalism can also
be applied to the extraction of statements regarding
the properties of individual proteins. Accordingly,
the EPI (Epigenetics and Post-Translational Modi-
fications) subchallenge of the BioNLP ST?11 pro-
vided corpora and competitive evaluations for the
detection of epigenetics and post-translational mod-
ification (PTM) events, while the REL (Entity Re-
lations) subchallenge covers structural and complex
membership relations of proteins (Ohta et al, 2011b;
Pyysalo et al, 2011). The complex memberships
and domains define the physical nature of an indi-
vidual protein, which is closely linked to its func-
tion and biological activity. Post-translational mod-
ifications alter and regulate this activity via struc-
tural or chemical changes induced by the covalent
attachment of small molecules to the protein. In
epigenetic regulation, gene expression is controlled
by the chemical modification of DNA and the his-
tone proteins supporting chromosomal DNA. All of
these aspects are important for defining the biologi-
cal role of a protein, and thus the EPI and REL tasks
enable the development of text mining systems that
can extract a more complete picture of the biomolec-
ular reactions and relations than previously possible
(cf. Table 1). Furthermore, previous work has shown
promising results for improving event extraction by
82
integration of ?static? entity relations (Pyysalo et al,
2009), in particular for the previously only available
PTM event, phosphorylation (Van Landeghem et al,
2010).
Information on protein modifications is avail-
able in general-purpose protein databases such as
UniProt, and there are also a number of dedicated
database resources covering such protein modifica-
tions (Wu and others, 2003; Lee et al, 2006; Li et
al., 2009). While the automatic extraction of PTMs
from text has also been considered in a number of
earlier studies, these have primarily involved single
PTM reactions extracted with special-purpose meth-
ods (Hu et al, 2005; Yuan et al, 2006; Lee et al,
2008). The EPI task and associated work (Ohta et
al., 2010) were the first to target numerous PTM re-
actions in a general framework using retrainable ex-
traction methods. The automatic detection of mod-
ification statements using keyword matching-based
methods has been applied also in support of DNA
methylation DB curation (Ongenaert et al, 2008;
Fang et al, 2011). However, as for PTM, the EPI
task and its preparatory efforts (Ohta et al, 2011a)
were the first to consider DNA methylation using the
general event extraction approach. To the best of our
knowledge, the present study is the first to extend the
event extraction approach to PTM and DNA methy-
lation event extraction to the scale of the entire avail-
able literature.
The Turku Event Extraction System (TEES), first
introduced for the BioNLP ST?09 (Bjo?rne et al,
2009), was updated and generalized for participa-
tion in the BioNLP ST?11, in which it had the best
performance on both the EPI and REL challenges
(Bjo?rne and Salakoski, 2011). With an F-score of
53.33% for the EPI and 57.7% for the REL task, it
performed over 16 pp better than the next best sys-
tems, making it well suited for our study. We apply
this system to the extraction of EPI events and REL
relations from all PubMed abstracts and all PMC
open access articles, using a pipeline of open source
text mining tools introduced in Bjo?rne et al (2010).
We further process the result using a recently
created bibliome-scale gene normalization dataset1.
This normalization effort connects protein and gene
mentions in text to their database IDs, a prerequi-
1Data currently under review.
site for effective use of text mining results for most
bioinformatics applications. In addition to protein
names, the EPI and REL challenges refer to the
protein substructures, modifications and complexes,
which we also need to normalize in order to deter-
mine the biological context of these events. In this
work, we develop a number of rule-based algorithms
for the normalization of such non-protein entities.
With both proteins and other entities normalized,
we can align the set of events extracted from the
literature with biological databases containing an-
notations on protein features, such as UniProt. We
can determine how many known and unknown fea-
tures we have extracted from text, and what percent-
age of various protein feature annotations our text
mining results cover. This association naturally also
works in the other direction, as we can take a gene or
protein and find yet unannotated post-translational
modifications, domains, or other features from sci-
entific articles, a promising use case for supporting
biomedical database curation.
2 Methods
2.1 PMC preprocessing
PMC full texts are distributed in an XML format that
TEES cannot use directly for event extraction. We
convert this XML into a flat ASCII text format with
a pipeline built on top of BioNLP ST?11 supporting
resource tools (Stenetorp et al, 2011). This process-
ing resolves embedded LATEX expressions, separates
blocks of text content (titles, sections, etc.) from
others, maps non-ASCII characters to corresponding
ASCII sequences, and normalizes whitespace. Re-
solving non-ASCII characters avoids increased error
rates from NLP tools trained on ASCII-only data.
2.2 Event Extraction
We use the Turku Event Extraction System for ex-
tracting both REL relations and EPI events. TEES is
a modular event extraction pipeline, that has recently
been extended for all the subtasks of the BioNLP?11
ST, including EPI and REL (Bjo?rne and Salakoski,
2011). TEES performs all supported tasks using
a shared graph scheme, which can represent both
events and relations (Figure 1 D). The system also
provides confidence scores enabling selection of the
most likely correct predictions. Before event extrac-
83
Event/relation type Example
Hydroxylation HIF-alpha proline hydroxylation
Phosphorylation (D) siRNA-mediated ATM depletion blocks p53 Serine-15 phosphorylation.
Ubiquitination K5 ubiquitinates BMPR-II on a Membrane-proximal Lysine
DNA methylation RUNX3 is frequently inactivated by P2 methylation in solid tumors.
Glycosylation Also, two asparagine residues in alpha-hCG were glycosylated.
Acetylation This interaction was regulated by Tat acetylation at lysine 50.
Methylation Methylation of lysine 37 of histone H2B is conserved.
Catalysis GRK2 catalyzed modest phosphorylation of BAC1.
Protein-Component Three enhancer elements are located in the 40 kb intron of the GDEP gene.
Subunit-Complex The most common form is a heterodimer composed of the p65/p50 subunits.
Table 1: Sentences with examples of the eight EPI event and two REL relation types, with highlighted triggers, and
protein and site arguments. Relations have no trigger and Catalysis takes as an argument another event.
Protein
Serine
Phosphorylation
of
Catalysis
is
Protein
mediated by CKI .
Cause>
REL detectionD
C
B
parsing
phosphorylation T-bet
Entity
<Theme
<Site
E
named entity recognition and normalization BANNER + GenNorm
McCJ-parser + Stanford Conversion
TEES
sentence splitting GENIA Sentence Splitter
PubMed Article Data
conversion to ST format and database import
A
Theme>
Serine of is mediated by CKI .phosphorylation T-betProteinEntity
<Protein-Component
Serine of is mediated by CKI .phosphorylation T-betNN VBN NN .NNNN VBZIN IN
<nn prep_of>
<nsubjpass
<auxpass agent>
Serine of is mediated by CKI .phosphorylation T-betProtein Protein
57765 27373
Serine of is mediated by CKI .phosphorylation T-bet
EPI detection
REL EPI
Figure 1: Event and relation extraction. Article text is
split into sentences (A), where gene/protein entities are
detected and normalized to their Entrez Gene IDs (B).
Each sentence with at least one entity is then parsed
(C). EPI events and REL relations are extracted from
the parsed sentences (D) and following conversion to
the BioNLP ST format are imported into a database (E).
(Adapted from Bjo?rne and Salakoski (2011)).
tion, protein/gene names are detected and sentences
are parsed. TEES handles all these preprocessing
steps via a pipeline of tool wrappers for the GE-
NIA Sentence Splitter (Kazama and Tsujii, 2003),
the BANNER named entity recognizer (Leaman and
Gonzalez, 2008), the McClosky-Charniak-Johnson
(McCCJ) parser (Charniak and Johnson, 2005; Mc-
Closky, 2010) and the Stanford tools (de Marneffe
et al, 2006). For a detailed description of TEES
we refer to Bjo?rne and Salakoski (2011) and for the
computational requirements of PubMed-scale event
extraction to Bjo?rne et al (2010).
2.3 Entity normalization
The extraction of events and relations as described in
the previous sections is purely text-based and does
not rely on any domain information from external
resources. This ensures generalizability of the meth-
ods to new articles possibly describing novel inter-
actions. However, practical use cases often require
integration of text mining results with external re-
sources. To enable such an integration, it is crucial to
link the retrieved information to known gene/protein
identifiers. In this section, we describe how we link
text mining data to biomolecular databases by pro-
viding integration with Entrez Gene, UniProt, Inter-
Pro and the Protein Data Bank.
2.3.1 Protein annotations
A crucial step for integrating statements in do-
main text with data records is gene name normaliza-
tion As part of a recent PubMed-scale effort,2 gene
2Data currently under review.
84
normalizations were produced by the GenNorm sys-
tem (Wei and Kao, 2011), assigning unique Entrez
Gene identifiers (Sayers and others, 2010) to am-
biguous gene/protein symbols. The GenNorm sys-
tem represents the state-of-the-art in gene normal-
ization, having achieved first rank by several evalua-
tion criteria in the BioCreative III Challenge (Lu and
others, 2011).
For practical applications, the Entrez Gene iden-
tifiers have been mapped to UniProt (The UniProt
Consortium, 2011) through conversion tables pro-
vided by the NCBI. As Entrez Gene and UniProt
are two of the most authoritative resources for gene
and protein identification, these annotations ensure
straightforward integration with other databases.
2.3.2 Complex annotations
The REL task Subunit-Complex relations all in-
volve exactly one protein complex and one of its
subunits, but the same complex may be involved in
many different Subunit-Complex relations (Pyysalo
et al, 2011). A key challenge for making use
of these relations thus involves retrieving a unique
identification of the correct complex. To identify
protein complexes, we use the Protein Data Bank
(PDB), an archive of structural data of biological
macromolecules (Berman et al, 2000). This re-
source currently contains more than 80,000 3-D
structures, and each polymer of a structure is anno-
tated with its respective UniProt ID.
To assign a unique PDB ID to an entity involved
in one or more Subunit-Complex relations, there
is usually no other lexical context than the protein
names in the sentence, e.g. ?the Rad9-Hus1-Rad1
complex?. Consequently, we rely on the normal-
ized protein names (Section 2.3.1) to retrieve a list
of plausible complexes, using data downloaded from
UniProt to link proteins to PDB entries. Ambiguity
is resolved by selecting the complex with the high-
est number of normalized proteins and giving pref-
erence to so-called representative chains. A list of
representative chains is available at the PDB web-
site, and they are determined by clustering similar
protein chains3 and taking the most confident ones
based on resolution quality.
Each assignment of a PDB identifier is annotated
with a confidence value between 0 and 1, express-
3Requiring at least 40% sequence similarity.
ing the percentage of proteins in the complex that
could be retrieved and normalized in text. For ex-
ample, even if one out of three UniProt identifiers is
wrongly assigned for a mention, the correct complex
might still be assigned with 0.66 confidence.
2.3.3 Domain annotations
Protein-Component relations define a relation be-
tween a gene/protein and one of its components,
such as a gene promoter or a protein domain. To
identify at least a substantial subset of these di-
verse relations, we have integrated domain knowl-
edge extracted from InterPro. InterPro is a rich re-
source on protein families, domains and functional
sites, integrating data from databases like PROSITE,
PANTHER, Pfam, ProDom, SMART and TIGR-
FAMs (Hunter and others, 2012). Over 23,000 dis-
tinct InterPro entries were retrieved, linking to more
than 16.5 million protein identifiers.
To assign an InterPro ID to an entity involved in
one or more Protein-Component relations, a set of
candidates is generated by inspecting the InterPro
associations of each of the proteins annotated with
that domain in text. For each such candidate, the
description of the InterPro entry is matched against
the lexical context around the entity by comparing
the number of overlapping tokens, excluding gen-
eral words, such as domain, and prepositions. The
amount of overlap is normalized against the length
of the InterPro description and expressed as a per-
centage, creating confidence values between 0 and 1.
Additionally, a simple pattern matching algorithm
recognizes statements expressing an amino acid in-
terval, e.g. ?aristaless domain (aa 527-542)?. When
such expressions are found, the intervals as anno-
tated in InterPro are matched against the retrieved
interval from text, and the confidence values express
the amount of overlap between the two intervals.
2.3.4 PTM site normalization
Six of the eight4 EPI event types refer to
post-translational modification of proteins. These
events are Hydroxylation, Phosphorylation, Ubiq-
uitination, Glycosylation, Acetylation and (Protein)
Methylation. To evaluate the events predicted
4As we are interested in PTM sites, we make no distinc-
tion between ?additive? PTMs such as Acetylation and their ?re-
verse? reactions such as Deacetylation.
85
from text, we compare these to annotated post-
translational modifications in UniProt. UniProt is
one of the largest manually curated databases for
protein knowledge, and contains annotations corre-
sponding to each of the EPI PTM event types.
We use the reviewed and manually annotated
UniProtKB/Swiss-Prot dataset (release 2012 02) in
XML format. We take for each protein all feature
elements of types modified residue, cross-link and
glycosylation site. Each of these feature elements
defines the site of the modification, either a single
amino acid, or a sequence of amino acids. We select
only annotations based on experimental findings,
that is, features that do not have a non-experimental
status (potential, probable or by similarity) to avoid
e.g. features only inferred from the sequence.
The modified residue feature type covers the event
types Hydroxylation, Phosphorylation, Acetylation
and Methylation. We determine the class of the mod-
ification with the UniProt controlled vocabulary of
post-translational modifications5. The description
attribute is the ID attribute of an entry in the vocabu-
lary, through which we can determine the more gen-
eral keyword (KW) for that description, if defined.
These keywords can then be connected to the corre-
sponding event types in the case of Hydroxylation,
Phosphorylation, Acetylation and Methylation. For
Ubiquitination events, we look for the presence of
the string ?ubiquitin? in the description attribute of
cross-link features. Finally, features corresponding
to Glycosylation events are determined by their fea-
ture element having the type glycosylation site.
The result of this selection process is a list of in-
dividual modification features, which contain a type
corresponding to one of the EPI PTM event types,
the UniProt ID of the protein, and the position and
amino acid(s) of the modification site. This data can
be compared with extracted events, using their type,
normalized protein arguments and modification site
arguments. However, we also need to normalize the
modification site arguments.
PTM sites are defined with a modification type
and the numbered target amino acid residue. In EPI
events, these residues are defined in the site argu-
ment target entities. To convert these into a form
that can be aligned with UniProt, we apply a set
5http://www.uniprot.org/docs/ptmlist/
Event Type Extracted PMC (%)
Hydroxylation 14,555 34.17
Phosphorylation 726,757 44.00
Ubiquitination 74,027 70.46
DNA methylation 140,531 52.27
Glycosylation 154,523 42.31
Acetylation 114,585 69.40
Methylation 122,015 74.86
Catalysis 45,763 67.86
Total EPI 1,392,756 51.53
Protein-Component 1,613,170 52.59
Subunit-Complex 537,577 51.18
Total REL 2,150,747 52.23
Table 2: Total number of EPI events and REL relations
extracted from PubMed abstracts and PMC full-text arti-
cles, with the fractions extracted from PMC.
of rules that try to determine whether a site is an
amino acid. We start from the main site token, and
check whether it is of the form AA#, where AA is an
amino acid name, or a one or three letter code, and
# an optional site number, which can also be in a to-
ken following the amino acid. For cases where the
site entity is the word ?residue? or ?residues?, we
look for the amino acid definition in the preceding
and following tokens. All strings are canonicalized
with removal of punctuation, hyphens and parenthe-
sis before applying the rules. In total, of the 177,994
events with a site argument, 75,131 could be nor-
malized to an amino acid, and 60,622 of these to a
specific residue number.
3 Results
The source for extraction in this work is the set of 21
million PubMed abstracts and 372 thousand PMC
open-access full-text articles. From this dataset,
1.4M EPI events and 2.2M REL relations were ex-
tracted (Table 2). For both tasks, about half of the
results were extracted from PMC, confirming that
full-text articles are an important source of infor-
mation for these extraction targets. The total num-
bers of events and relations are considerably lower
than e.g. the 21.3M events extracted for the GENIA
task from PubMed abstracts (Bjo?rne et al, 2010;
Van Landeghem et al, 2012), likely relating to the
comparatively low frequency with which EPI and
REL extraction targets are discussed with respect to
the basic GENIA biomolecular reactions.
86
Event type UniProt Events Match Coverage Events (site) Match Coverage
Hydroxylation 1,587 14,555 1,526 19 4,298 130 5
Phosphorylation 57,059 726,757 286,978 4,795 86,974 9,732 748
Ubiquitination 792 74,027 4,994 143 10,562 54 20
Glycosylation 6,708 154,523 18,592 897 22,846 68 31
Acetylation 6,522 114,585 15,470 764 25,689 158 30
Methylation 1,135 122,015 2,178 113 27,625 36 10
Total 73,803 1,206,462 329,738 6,731 177,994 10,178 844
Table 3: PTM events. PTMs that are not marked with non-experimental qualifiers are taken from UniProt. The
Events column lists the total number of predicted events, and the Events (site) the number of events that also have a
predicted site-argument. For these groups, Match is the number of events that matches a known PTM from UniProt,
and Coverage the number of UniProt PTMs for which at least one match exists. For Events matching takes into account
the PTM type and protein id, for Events (site) also the amino acid and position of the modified residue.
Event type AA UP # Highest confidence event Article ID
Phosphorylation S9 ? 2 p53 isolated from ML1, HCT116 and RKO cells, after short
term genotoxic stress, were phosphorylated on Ser 6, Ser 9
PMC:2777442
Acetylation S15 4 phosphorylated (Ser15), acetylated p53(Lys382) PMC:2557062
Methylation S15 1 phosphorylation of p53 at serine 15 and acetylation PM:10749144
Phosphorylation S15 ? 238 Chk2, as well as p53 Ser(15) phosphorylation and its PM:16731759
Phosphorylation T18 ? 12 p53 stabilization and its phosphorylation in Thr18 PMC:3046209
Phosphorylation S20 ? 45 that phosphorylation of p53 at Ser20 leads to PMC:3050855
Phosphorylation S33 ? 14 phosphorylation of p53 at serine 33 may be part of PMC:35361
Phosphorylation S37 ? 20 serine 33 of p53 in vitro when serine 37 is already PMC:35361
Phosphorylation S46 ? 55 phosphorylation of p53, especially at Serine 46 by PMC:2634840
Phosphorylation T55 ? 7 that phosphorylation of p53 at Thr55 inhibits its PMC:3050855
Phosphorylation S99 ? 0
Phosphorylation S183 ? 0
Phosphorylation S269 ? 0
Phosphorylation T284 ? 0
Ubiquitination K291 ? 0
Acetylation K292 ? 0
Ubiquitination K292 ? 0
Acetylation K305 ? 0
Phosphorylation S313 ? 1 hyperphosphorylation of p53, particularly of Ser313 PM:8649812
Phosphorylation S314 ? 0
Phosphorylation S315 ? 6 to require phosphorylation of p53 at serine 315 (35) PMC:2532731
Methylation K370 ? 6 by methylating lysine 370 of p53 PMC:1636665
Acetylation K372 1 for lysine 372 and 383 acetylated p53 (Upstate, PMC:1315280
Methylation K372 ? 5 methylation of p53 by the KMT7(SET7/9) methyltransferase
enzyme on Lys372
PMC:2794343
Acetylation K373 ? 16 p53 and acetylated p53 (lysine-373 and lysine-382) PMC:1208859
Methylation K373 ? 4 EHMT1-mediated p53 methylation at K373 PM:20588255
Acetylation K381 ? 0
Acetylation K382 ? 82 p53 acetylation at lysine 382 was found not PM:17898049
Methylation K382 ? 6 SET8 specifically monomethylates p53 at lysine 382 PM:17707234
Methylation K386 ? 1 that sumoylation of p53 at K386 blocks subsequent PM:19339993
Phosphorylation S392 ? 35 and phosphorylation of p53 at S392 PM:17237827
Table 4: Extracted and known PTM sites of p53. The type and site of the modification are in the first two columns.
UP indicates whether the PTM is present in the UniProt annotation for p53. Column # shows the number of extracted
events, followed by the event with the highest confidence score and the PubMed abstract or PMC full-text article it has
been extracted from.
87
3.1 Extracted PTMs compared to UniProt
The EPI PTM events were compared to annotated
PTMs from UniProt (Table 3). The majority of ex-
tracted PTM events (85%) have only a protein ar-
gument, and no information about the modification
site, so these can only be compared by the protein
id and PTM type. For the subset of proteins that
also have a site, which can be normalized to an
amino acid position, we can make a detailed com-
parison with UniProt. Finding a match for these
normalized amino acids is more difficult, and for
both categories, only a small fraction of proteins
from UniProt is covered. In part this may be due
to the limitations of the gene name normalization, as
finding the exact species-specific protein ID remains
a challenging task (Lu and others, 2011). How-
ever, even if the overall coverage is limited, well-
known protein modifications can be assigned to spe-
cific residues, as we show in the next section.
3.2 Extracted PTMs for a single protein
For an in-depth example of PTM modifications, we
study the protein p53, a central tumor suppressor
protein that is the subject of many studies. p53 is
also among the proteins with the most UniProt PTM
sites for which EPI events were predicted, making it
a good example for a case study (see Table 4).
We take from UniProt all known p53 PTMs corre-
sponding to our EPI event types and list the number
of predicted events for them (see Table 4). When
the number of predicted events is high, the most
confident prediction is usually a correctly extracted,
clear statement about the PTM. All events for PTMs
known in UniProt are correct except for the type
of K386. For events not in UniProt, the two S15
ones are false positives, and K372 acetylation, while
correctly extracted, is most likely a typo in the arti-
cle. For the PTMs for which no event was extracted,
we checked the reference article from UniProt an-
notation. K291, K292 ubiquitination, and K305 are
from abstracts, and thus missed events. S183, S269
and T284 are from a non-open access PMC article,
while S99, K292 acetylation, K305, S314 and K381
are from Excel or PDF format supplementary tables,
sources outside our extraction input.
In total, we have extracted 561 PTM events re-
lated to p53, 554 of which correspond to a PTM an-
Item PubMeth Extracted Recall
PMID+UPID 2776 1698 61.2%
UPID 392 363 92.6%
PMID 1163 1120 96.3%
Table 5: Evaluation of DNA methylation event extraction
recall against PubMeth.
notated in UniProt. Of the 28 EPI-relevant PTMs on
p53, 17 have at least one predicted event. The high-
est confidence events are about equally often from
abstracts as from full texts.
3.3 DNA methylation analysis
Two recently introduced databases, PubMeth (On-
genaert et al, 2008) and MeInfoText (Fang et al,
2011) provide manually curated information on
DNA methylation, primarily as it relates to cancer.
To evaluate the coverage of DNA methylation event
extraction, we focus here on PubMeth, as the full
content of this database could be directly used. Each
PubMeth DB record provides the primary name of
the methylated gene and the PMID of the publica-
tion supporting the curation of the record. We used
these two pieces of information to evaluate the recall
6 of DNA methylation event extraction.
We mapped PubMeth entries to UniProt iden-
tifiers (UPIDs), and extracted all unique (PMID,
UPID) pairs from both PubMeth and the automat-
ically extracted DNA methylation/demethylation
events. The results of comparison of these sets of
ID pairs are given in Table 5. We find that for over
60% of PubMeth entries, the system is able to re-
cover the specific (document, gene) pair. This result
is broadly in line with the recall of the system as
evaluated in the BioNLP ST. However, if the match-
ing constraint is relaxed, asking either 1) can the sys-
tem extract the methylation of each gene in PubMeth
somewhere in the literature or, inversely, 2) can the
system detect some DNA methylation event in each
document included in PubMeth as evidence, recall
is over 90%. In particular, the evaluation indicates
that the system shows very high recall for identify-
ing documents discussing DNA methylation.
6As PubMeth does not aim for exhaustive coverage, preci-
sion cannot be directly estimated in this way. For example, Pub-
Meth covers fewer than 2,000 documents and DNA methylation
events were extracted from over 20,000, but due to differences
in scope, this does not suggest precision is below 10%.
88
REL Type Extracted Match (p) Match (e)
Prot-Cmp 1613.1K 561.8K 150.7K
SU-Cmplx 537.6K 226.5K 99.6K
Table 6: Numbers of extracted entity relations, with the
protein (p) or both protein and entity (e) identified.
3.4 REL statistics
Table 6 presents the amount of extracted entity re-
lations and the coverage of the normalization algo-
rithms assigning protein, domain and complex iden-
tifiers. From a total of 537.6K Subunit-Complex re-
lations, 226.5K (42%) involve a protein that could be
unambiguously identified (Section 2.3.1). From this
subset, 99.6K relations (44%) could be assigned to a
PDB complex identifier (Section 2.3.2), accounting
for 3800 representative 3D protein structures.
The Protein-Component relations are much more
frequent in the data (1.6M relations) and here 35%
of the relations (561.8K) involve a normalized pro-
tein mention. The assignment of InterPro domains
to these Protein-Component relations (Section 2.3.3)
further covers 150.7K relations in this subset (27%),
identifying 5500 distinct functional domains. The
vast majority of these annotations (99%) are pro-
duced by matching the lexical context against the
InterPro descriptions, and only a few cases (200)
matched against the amino-acid pattern.
4 Conclusions
We have combined state-of-the-art methods for
gene/protein name normalization together with the
best available methods for event-based extraction
of protein post-translational modifications, reactions
relating to the epigenetic control of gene expres-
sion, and part-of relations between genes/proteins,
their components, and complexes. These methods
were jointly applied to the entire available litera-
ture, both PubMed abstracts and PMC full-text doc-
uments, creating a text mining dataset unique in both
scope and breadth of analysis. We further performed
a comprehensive analysis of the results of this au-
tomatic extraction process against major biological
database resources covering various aspects of the
extracted information. This analysis indicated that
text mining results for protein complexes, substruc-
tures and epigenetic DNA methylation provides al-
ready quite extensive coverage of relevant proteins.
For post-translational modifications, we note that
coverage still needs to be improved, but conclude
that the extracted events already provide a valuable
link to PTM related literature. In future work we
hope to further extend the event types extracted by
our PubMed-scale approach. The extraction meth-
ods as well as all data introduced in this study are
freely available from bionlp.utu.fi.
Acknowledgments
We thank the Academy of Finland, the Research
Foundation Flanders (FWO) and the UK BBSRC
(reference number: BB/G013160/1) for funding,
and CSC ? IT Center for Science Ltd for compu-
tational resources.
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
Helen M. Berman, John Westbrook, Zukang Feng,
Gary Gilliland, T. N. Bhat, Helge Weissig, Ilya N.
Shindyalov, and Philip E. Bourne. 2000. The protein
data bank. Nucleic Acids Research, 28(1):235?242.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 183?191.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In Proceedings of the BioNLP 2009 Work-
shop, pages 10?18.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,
and Tapio Salakoski. 2010. Scaling up biomedical
event extraction to the entire PubMed. In Proceedings
of the BioNLP 2010 Workshop, pages 28?36.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of
ACL, pages 173?180.
Y.C. Fang, P.T. Lai, H.J. Dai, and W.L. Hsu. 2011. Me-
infotext 2.0: gene methylation and cancer relation ex-
traction from biomedical literature. BMC bioinformat-
ics, 12(1):471.
Z. Z. Hu, M. Narayanaswamy, K. E. Ravikumar,
K. Vijay-Shanker, and C. H. Wu. 2005. Literature
mining and database annotation of protein phospho-
rylation using a rule-based system. Bioinformatics,
21(11):2759?2765.
89
Sarah Hunter et al 2012. Interpro in 2011: new devel-
opments in the family and domain prediction database.
Nucleic Acids Research, 40(D1):D306?D312.
Jun?ichi Kazama and Jun?ichi Tsujii. 2003. Evaluation
and extension of maximum entropy models with in-
equality constraints. In Proceedings of EMNLP 2003,
pages 137?144.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of BioNLP 2009, pages 1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011.
Overview of BioNLP Shared Task 2011. In Proceed-
ings of the BioNLP Shared Task 2011, pages 1?6.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedical
named entity recognition. Pacific Symposium on Bio-
computing, pages 652?663.
Tzong-Yi Lee, Hsien-Da Huang, Jui-Hung Hung, Hsi-
Yuan Huang, Yuh-Shyong Yang, and Tzu-Hao Wang.
2006. dbPTM: an information repository of pro-
tein post-translational modification. Nucleic acids re-
search, 34(suppl 1):D622?D627.
Hodong Lee, Gwan-Su Yi, and Jong C. Park. 2008.
E3Miner: a text mining tool for ubiquitin-protein lig-
ases. Nucl. Acids Res., 36(suppl.2):W416?422.
Hong Li, Xiaobin Xing, Guohui Ding, Qingrun Li, Chuan
Wang, Lu Xie, Rong Zeng, and Yixue Li. 2009.
SysPTM: A Systematic Resource for Proteomic Re-
search on Post-translational Modifications. Molecular
& Cellular Proteomics, 8(8):1839?1849.
Zhiyong Lu et al 2011. The gene normalization task
in BioCreative III. BMC Bioinformatics, 12(Suppl
8):S2+.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed depen-
dency parses from phrase structure parses. In Proceed-
ings of LREC-06, pages 449?454.
David McClosky. 2010. Any domain parsing: auto-
matic domain adaptation for natural language pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, Jin-Dong
Kim, and Jun?ichi Tsujii. 2010. Event extraction
for post-translational modifications. In Proceedings of
BioNLP?10, pages 19?27.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and
Jun?ichi Tsujii. 2011a. Event extraction for
DNA methylation. Journal of Biomedical Semantics,
2(Suppl 5):S2.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011b. Overview of the epigenetics and post-
translational modifications (EPI) task of BioNLP
Shared Task 2011. In Proceedings of BioNLP Shared
Task 2011 Workshop, pages 16?25.
Mate? Ongenaert, Leander Van Neste, Tim De Meyer,
Gerben Menschaert, Sofie Bekaert, and Wim
Van Criekinge. 2008. PubMeth: a cancer methy-
lation database combining text-mining and expert
annotation. Nucl. Acids Res., 36(suppl 1):D842?846.
Sampo Pyysalo, Antti Airola, Juho Heimonen, and Jari
Bjo?rne. 2008. Comparative analysis of five protein-
protein interaction corpora. BMC Bioinformatics,
9(Suppl. 3):S6.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Proceed-
ings of the BioNLP 2009 Workshop, pages 1?9.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii. 2011.
Overview of the entity relations (REL) supporting task
of BioNLP Shared Task 2011. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 83?88.
Eric W. Sayers et al 2010. Database resources of the na-
tional center for biotechnology information. Nucleic
Acids Research, 38(suppl 1):D5?D16.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
Bionlp shared task 2011: Supporting resources. In
Proceedings of BioNLP Shared Task 2011 Workshop,
pages 112?120.
The UniProt Consortium. 2011. Ongoing and future de-
velopments at the universal protein resource. Nucleic
Acids Research, 39(suppl 1):D214?D219.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg
Hakenberg, and Ulf Leser. 2010. A comprehen-
sive benchmark of kernel methods to extract protein-
protein interactions from literature. PLoS Comput
Biol, 6(7):e1000837, 07.
Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,
and Yves Van de Peer. 2010. Integration of static re-
lations to enhance event extraction from text. In Pro-
ceedings of BioNLP?10, pages 144?152.
Sofie Van Landeghem, Kai Hakala, Samuel Ro?nnqvist,
Tapio Salakoski, Yves Van de Peer, and Filip Ginter.
2012. Exploring biomolecular literature with EVEX:
Connecting genes through events, homology and indi-
rect associations. Advances in Bioinformatics.
Chih-Hsuan Wei and Hung-Yu Kao. 2011. Cross-species
gene normalization by species inference. BMC bioin-
formatics, 12(Suppl 8):S5.
Cathy H. Wu et al 2003. The Protein Information Re-
source. Nucl. Acids Res., 31(1):345?347.
X. Yuan, ZZ Hu, HT Wu, M. Torii, M. Narayanaswamy,
KE Ravikumar, K. Vijay-Shanker, and CH Wu. 2006.
An online literature mining tool for protein phospho-
rylation. Bioinformatics, 22(13):1668.
90
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 16?25,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
TEES 2.1: Automated Annotation Scheme Learning in the BioNLP 2013
Shared Task
Jari Bjo?rne and Tapio Salakoski
Department of Information Technology, University of Turku
Turku Centre for Computer Science (TUCS)
Joukahaisenkatu 3-5, 20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
We participate in the BioNLP 2013 Shared
Task with Turku Event Extraction System
(TEES) version 2.1. TEES is a support
vector machine (SVM) based text mining
system for the extraction of events and re-
lations from natural language texts. In ver-
sion 2.1 we introduce an automated an-
notation scheme learning system, which
derives task-specific event rules and con-
straints from the training data, and uses
these to automatically adapt the system
for new corpora with no additional pro-
gramming required. TEES 2.1 is shown to
have good generalizability and good per-
formance across the BioNLP 2013 task
corpora, achieving first place in four out
of eight tasks.
1 Introduction
Biomedical event extraction concerns the detec-
tion of statements of biological relations from sci-
entific texts. Events are a formalism for accu-
rately annotating the content of any natural lan-
guage sentence. They are characterized by typed,
directed arguments, annotated trigger words and
the ability to nest other events as arguments, lead-
ing to flexible, complex structures. Compared to
the more straightforward approach of binary rela-
tion extraction, the aim of event extraction is to
utilize the added complexity to more accurately
depict the content of natural language statements
and to produce more detailed text mining results.
The BioNLP Shared Task is the primary forum
for international evaluation of different event ex-
traction technologies. Organized for the first time
in 2009, it has since been held in 2011 and now in
2013 (Kim et al, 2009; Kim et al, 2011). Starting
from the single GENIA corpus on NF-kB, it has
since been extended to varied domain tasks, such
as epigenetics and bacteria-host interactions. The
theme of the 2013 task is ?knowledge base con-
struction?, defining several domain tasks relevant
for different aspects of this overall goal.
The Turku Event Extraction System (TEES)1
is a generalized biomedical text mining tool, de-
veloped at University of Turku and characterized
by the use of a unified graph representation and
a stepwise machine learning approach based on
support vector machines (SVM). TEES has partic-
ipated in all BioNLP Shared Tasks, achieving first
place in 2009, first place in four out of eight tasks
in 2011 and now in 2013 again first place in four
out of eight tasks (Bjo?rne et al, 2011; Bjo?rne et
al., 2012). It has been available as an open source
project since 2009, and has also been used by other
research groups (Jamieson et al, 2012; Neves et
al., 2013).
The BioNLP Shared Tasks have recorded the
progress of various event extraction approaches.
Where TEES 1.0 achieved an F-score of 51.95%
in 2009, in 2011 the best performing system by
team FAUST on the extended, but similar GENIA
task achieved an F-score of 56.0% (Riedel et al,
2011). Interesting approaches have been demon-
strated also in the interim of the Shared Tasks, for
example with the EventMine system of Miwa et
al. (2010) achieving an F-score of 56.00% on the
2009 GENIA corpus, and with the extremely com-
putationally efficient system of Bui et al (2012)
based on automatically learning extraction rules
from event templates. The GENIA task of 2013
has been considerably extended and the scope of
the corpus is different, so a direct comparison with
the earlier GENIA tasks is not possible.
In the BioNLP 2013 Shared Task the goal of the
TEES project is to continue the generalization of
event extraction techniques introduced in 2011 by
fully automating task-specific adaptation via auto-
1http://jbjorne.github.com/TEES/
16
mated learning of event annotation rules. As an
open source project TEES should also be easily
applicable by any team interested in this task, so
TEES 2.1 analyses were provided for all interested
participants during the system development phase
of the competition.
2 Methods
2.1 Turku Event Extraction System 2.1
TEES is a machine-learning based tool for extract-
ing text-bound graphs from natural language arti-
cles. It represents both binary relations and events
with a unified graph format where named entities
and triggers are nodes and relations and event ar-
guments are edges. This representation is com-
monly stored in the ?interaction XML? format, an
extensible XML representation applicable to var-
ious corpora (Bjo?rne et al, 2012; Pyysalo et al,
2008; Segura-Bedmar et al, 2013).
TEES approaches event extraction as a classi-
fication task, breaking the complex graph genera-
tion task into smaller steps that can be performed
with multiclass classification. The SVMmulticlass
support vector machine2 (Tsochantaridis et al,
2005) with a linear kernel is used as the classifier
in all machine learning steps.
To start with the BioNLP Shared Task, TEES
conversion tools are used to convert the shared
task format (txt/a1/a2) corpora into the interac-
tion XML format. Equivalence annotations are re-
solved into independent events in the process.
Figure 1 shows an overview of the TEES event
extraction process. In real-world applications, ex-
ternal programs are used to split sentences, de-
tect protein/gene named entities and parse text,
but in the BioNLP Shared Tasks these analyses
are provided by the organizers. As in previous
Shared Tasks, we used the tokenisations and the
McCCJ parses converted into the collapsed CC-
processed Stanford dependency scheme (Stene-
torp et al, 2013; McClosky, 2010).
With the preprocessing done, TEES uses three
primary processing steps to detect events. First,
event trigger words are detected by classifying
each non-named entity token into one of the trig-
ger classes or as a negative. Then, for each
(optionally directed) pair of named entity and
trigger nodes a relation/argument edge candidate
2http://svmlight.joachims.org/svm_
multiclass.html
Regulation
NN NN VB NN CC .conj_and>
<nn dobj><nsubj NN
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
unmerging
D
C
E
edge detection
trigger detection
B
A
dobj>
parsing
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
<Theme Cause> Cause>
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
ProteinSTAT3 phosphorylation involve ProteinVav and ProteinRac-1 .
STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) mayNN
appos> <auxVB
Ser(727) may
Ser(727) may
Ser(727) may
Ser(727) may
Entity
<Parent
Entity
Entity
<Theme
<Theme<Theme
Regulation
ProteinSTAT3 Phosphorylationphosphorylation involve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
speculation and negation detectionF
Ser(727) mayEntity
<Theme<Theme
RegulationSpec
Spec
<Site
<Parent <Site
<Parent <Site
Figure 1: TEES event extraction process. Prepro-
cessing steps A?C are achieved in the shared task
with data provided by organizers. Event extraction
steps D?F are all performed as consecutive, inde-
pendent SVM classification steps. (Adapted from
Bjo?rne et. al (2012).)
is generated and classified into one of the rela-
tion/argument classes or as a negative. Finally, for
each event trigger node, for each valid set of out-
going argument edges an unmerging example is
generated and classified as a true event or not, sep-
arating overlapping events into structurally valid
ones. For tasks where events can have modifiers, a
final modifier detection step can be performed. To
better fit the trigger detection step into the overall
task, a recall adjustment parameter is experimen-
tally determined to increase the amount of triggers
generated before edges are detected. The feature
representations and basic approach of the system
are largely unchanged from the 2011 entry, and for
a more detailed overview we refer to Bjo?rne et. al
(2012).
The main change in TEES 2.1, described in this
paper, is the automated annotation scheme learn-
ing system, which enables the optimal use of the
system on any interaction XML format corpus.
This preprocessing step results in an annotation
scheme definition which is used throughout the
machine learning steps and the impact of which
is described in detail in the following sections.
17
2.2 Automated Annotation Scheme Learning
In previous versions of TEES, task specific rules
needed to be defined in code. The most impor-
tant of these were the event annotation schemes of
each task, which define the type and number of ar-
guments that are valid for each event type. This
limited straightforward application of TEES only
to corpora that were part of the shared tasks. In
TEES 2.1, the event scheme rules and constraints
are learned automatically. All event types and ar-
gument combinations seen in the known training
data are considered valid for the current task. The
result of this analysis for the GE (GENIA) task is
shown in Table 1.
The automatically generated annotation scheme
analysis lists all entities, events, relations and
modifiers detected in the corpus. Entities are sim-
ply a type of node and relations can be directed or
undirected but are always defined as a single edge
connecting two nodes. Events consist of a trigger
node whose type is equal to the type of the event
itself and a set of arguments, for which are defined
also valid argument counts.
The interaction XML graph format represents
both event arguments and binary relations as edge
elements. To distinguish these annotations, a pre-
requisite for automated detection of valid event
structures, elements that are part of events are la-
beled as such in the TEES 2.1 interaction XML
graph. Those node and argument types that are
not annotated also for the test set become the pre-
diction targets, and the rest of the annotation can
be used as known data to help in predicting them.
The annotation scheme analysis is stored in the
TEES model file/directory, is available at runtime
via a class interface and is used in the machine
learning steps to enforce task-specific constraints.
The availability of the learned annotation scheme
impacts mostly the edge and unmerging detectors.
2.3 TEES 2.1 Edge Detection
The primary task specific specialization required
in TEES 2.0 was the set of rules defining valid
node combinations for edges. TEES detects edges
(relations or arguments) by defining one edge can-
didate for each directed (or undirected) pair of
nodes. While the system could be used without
task-specific specialization to generate edge candi-
dates for all pairs, due to the potentially large num-
ber of nodes in event-containing sentences this
approach led to an inflated amount of negatives
and reduced SVM performance. In the BioNLP
Shared Task, e.g. the common Protein entities can
only ever have incoming edges, so even such a
simple limitation could considerably reduce the
amount of edge candidates, but these task-specific
rules had to be written into the Python-code. With
the automatically learned annotation scheme, the
edge detector checks for each node pair whether it
constitutes a valid edge candidate as learned from
the training data, automating and generalizing this
task-specific optimization.
2.4 TEES 2.1 Unmerging
The TEES module most affected by the learned
annotation scheme is the unmerging detector,
which takes the merged event graph (where over-
lapping events share the same trigger node) and
attempts to define which node/argument combina-
tions constitute valid events (See Figure 1 E). One
example is generated for each potential event, and
nodes and edges are duplicated as needed for those
classified as positives. In TEES 2.0, only the GE
(GENIA), EPI (Epigenetics and Post-translational
Modifications) and ID (Infectious Diseases) tasks
from 2009 and 2011 were supported, with valid
argument combinations defined in the code. In
TEES 2.1 invalid argument combinations, as de-
termined by the learned annotation scheme, are
automatically removed before classification. Even
if an event is structurally valid, it may of course
not be a correct event, but reducing the number of
negatives by removing invalid ones is an impor-
tant optimization step also in the case of unmerg-
ing classification.
2.5 Unified site-argument representation
Representing the BioNLP Shared Task site-
arguments in the interaction XML format has been
problematic. The sites are arguments of argu-
ments, linking a separate site-entity to a primary
argument. In the graph format all arguments are
edges, and while technically all edges could be
defined as having a central node to which site-
arguments could connect, this would result in
a multi-step edge detection system, where site-
argument edges could only be predicted after pri-
mary argument edges are predicted. To avoid this
situation, in TEES 2.0 site arguments were defined
as edges connecting the site entity either to the
protein node (See Figure 2 A) or to the trigger
node (See Figure 2 B). The second case was the
most straightforward, and we assume closest to the
18
Protein
STAT3
Phosphorylation
phosphorylation
A: TEES 2.0 main representation
Ser(727)
Entity
<Site
<Theme
B: TEES 2.0 EPI representation
Protein
STAT3
Phosphorylation
phosphorylationSer(727)
Entity
<Site
<Theme
Protein
STAT3
Phosphorylation
phosphorylationSer(727)
Entity
<Site
<ThemeC: TEES 2.1 Unified representation
<SiteParent
Figure 2: A unified representation (C) is intro-
duced for site-arguments, replacing the differ-
ent TEES 2.0 representations and enabling site-
arguments to be processed as any other event ar-
guments.
syntactic structure, as demonstrated by the good
performance on the 2011 EPI task (Bjo?rne et al,
2012). However, in tasks where events can have
multiple primary arguments, the approach shown
in Fig. 2 B becomes problematic, as a primary/site
argument pair cannot be determined unambigu-
ously. In the approach shown in Fig. 2 A, the con-
nection between the event and the site argument is
indirect, meaning that the TEES 2.1 automated an-
notation scheme learning system cannot determine
valid site argument constraints for events.
In TEES 2.1 this problem is solved with a uni-
fied approach where regardless of task, the site
arguments are comparable to primary argument
edges in all aspects, enabling consistent event
analysis and simplifying site argument processing
(See Figure 2 C). Additional SiteParent edges are
defined to connect the entity and the protein it be-
longs to. In ambiguous cases, these are used to
connect the right site to the right primary argument
when converting to the final Shared Task format.
2.6 Validating final predictions
The current implementation of the automated an-
notation scheme learning system in TEES 2.1
has a shortcoming occasionally resulting in in-
valid event structures being produced. Consider
an event with multiple optional arguments, such as
Cell differentiation from the CG task with 0?1 At-
Loc arguments and 0?1 Theme arguments. While
it can be possible that such an event can exist with-
out any arguments at all, it is often the case that
at least one of the optional arguments must be
present. This is not detected by the current system,
and would require the addition of learning rules for
such groups of mandatory arguments.
The result of this and other small limitations in
conforming to task rules is the occasional invalid
predicted event. The Shared Task test set evalua-
tion servers will not accept any invalid events, so
these errors had to be resolved in some way. As
this problem was detected at a late stage in the
shared task, there was no more time to fix the un-
derlying causes. However, these errors could not
either be fixed by looking at the test set and cor-
recting the events preventing the acceptance of the
submission, as that would result in de facto man-
ual annotation of the test set and an information
leak. Therefore, we never looked at the document
triggering the error, and used the following, con-
sistent approach to resolve the invalid events. If
the server would both report an invalid argument
and a missing argument for the same event, the
invalid argument was first replaced with the miss-
ing one. This was only the case with the GRN
task. If the server would only report an invalid
argument, we first removed the argument, and if
this did not resolve the conflict, we removed the
entire event. Following this, all events recursively
pointing to removed invalid events were also re-
moved. This approach could be implemented with
a system processing the validation tools? output,
but the better approach which we aim to pursue is
to fix the limitations of the automated annotation
scheme learning system, thus producing a tool us-
able on any corpora. In practice only a few invalid
events were produced for each task where they oc-
curred, so the impact on performance is likely to
be negligible.
2.7 Public dataset
TEES 2.0, published in summer 2012 was a po-
tentially useful tool for the BioNLP 2013 Shared
Task, but at the same time required specific code
extensions to be adapted for the task, leading to a
situation where the program was available, but was
not likely to be of practical value with new cor-
pora. To resolve this problem the automated anno-
tation scheme learning system was developed, tak-
ing the generalization approaches developed for
the 2011 task and making them automatically ap-
plicable for new corpora. As using TEES can still
19
be difficult for people not familiar with the system,
and as re-training the program is quite time con-
suming, we also published our event predictions
for the 2013 task during the system development
period, for other teams to make use of. Develop-
ment set analyses were made available on Febru-
ary 26th, and test set analyses during the test pe-
riod on April 13th. With only a few downloads,
the data did not enjoy wide popularity, and due
to the complexity of the tasks utilizing the data in
other systems could very well have been too time
consuming. TEES was also used to produce public
analyses for the DDIExtraction 2013 Shared Task,
where the data was used more, maybe due to eas-
ier integration into a binary relation extraction task
(Segura-Bedmar et al, 2013; Bjo?rne et al, 2013).
3 Tasks and Results
TEES 2.1 could be applied as is to almost all the
2013 tasks with no task specific development re-
quired. Only subtask 1 of the Bacteria Biotopes
task, concerning the assignment of ontology con-
cepts, falls outside the scope of the current sys-
tem. TEES 2.1 was the system to participate
in most tasks, with good general performance,
demonstrating the utility of abstracting away task-
specific details. Official results for each task are
shown in Table 2 and system performance relative
to other entries in Figure 3.
Task # R P F SER
GE 2/10 46.17 56.32 50.74
CG 1/6 48.76 64.17 55.41
PC 2/2 47.15 55.78 51.10
GRO 1/1 15.22 36.58 21.50
GRN 3/5 33 78 46 0.86
BBT1 0/4
BBT2 1/4 28 82 42
BBT3 1/2 12 18 14
Table 2: Official test set results for the BioNLP
2013 tasks. Performance is shown in (R)ecall,
(P)recision and (F)-score, and also SER for the
GRN task. BB task 1 falls outside the scope of
TEES 2.1. Rank is indicated by #.
3.1 GENIA (GE)
The GENIA task is the central task of the BioNLP
Shared Task series, having been organized in all
three Shared Tasks. It has also enjoyed the largest
number of contributions and as such could be
GE CG PC GRO GRN BBT2 BBT3 BBT1Task0
20
40
60
80
100
F-sco
re / S
ER *
 100
Figure 3: Performance of the systems participat-
ing in the BioNLP?13 Shared Task. Our results
are marked with black dots. Please note that the
performance metric for tasks GRN and BBT1 is
SER*100, where a smaller score is better.
viewed as the primary task for testing different
event extraction approaches. In 2013 the GE-
NIA task annotation has been considerably ex-
tended and the coreference annotation that in 2011
formed its own supporting task is integrated in the
main GENIA corpus (Kim et al, 2013a).
The GENIA task is a good example for demon-
strating the usefulness of automatically learning
the event annotation scheme. The task uses 11
different event types, pairwise binary coreference
relations and modality annotation for both specu-
lation and negation. Previous versions of TEES
would have encoded all of this information in the
program, but with TEES 2.1 the annotation rules
are detected automatically and stored in a sep-
arate datafile external to the program. Table 1
shows the automatically learned event scheme. It
should however be noted that while the learned
scheme accurately describes the known annota-
tion, it may not exactly correspond to the corpus
annotation rules. For example, the Binding event,
when learned from the data, can have one or two
Theme arguments, when in the official rules it sim-
ply has one or more Theme arguments.
In some GENIA Coreference relations (45 out
of 338 in train and devel data) at least one of the
endpoints is an event trigger. While such rela-
tions could indeed be linked to event trigger nodes,
TEES makes no distinction between triggers and
events and would link them to the event annotation
when converting back to the Shared Task format,
20
so we chose to skip them.
TEES 2.1 achieved a performance of 50.74%,
placing second in the GENIA task. The first place
was reached by team EVEX (Hakala et al, 2013),
with a system that utilizes the publicly available
TEES 2.1 program. This result further highlights
the value of open sourcing scientific code and un-
derlines the importance of incorporating existing
solutions into future systems.
3.2 Cancer Genetics (CG)
The CG task is a domain-specific event extrac-
tion task targeting the recovery of information re-
lated to cancer (Pyysalo et al, 2013; Pyysalo et
al., 2012). It is characterized by a large number
of entity and event types. Despite a heterogeneous
annotation scheme, TEES 2.1 achieved a perfor-
mance of 55.41% F-score, placing first in this task.
On some event categories TEES achieved a per-
formance notably higher than usual for it in event
extraction tasks, such as the 77.20% F-score for
the Anatomy-group events. The impact of more
common, and as such more easily detected classes
on the micro-averaged F-score is certainly impor-
tant, but it is interesting to speculate that maybe
the very detailed annotation scheme led to a more
focused and thus more consistent annotation, mak-
ing machine learning easier on this task.
3.3 Pathway Curation (PC)
The PC task aims to produce events suitable for
pathway curation (Ohta et al, 2013). Its extrac-
tion targets are based on existing pathway models
and ontologies such as the Systems Biology On-
tology (SBO). The dataset has only a few entity
types, but similar to the CG task, a large number
of event types. With 51.10% F-score TEES 2.1
placed second, behind team NaCTeM by 1.74 per-
centage points (Miwa and Ananiadou, 2013). On
the CG task team NaCTeM placed second, 3.32
percentage points lower than TEES 2.1. Even with
the only two participants in the PC task having
very close performance, compared to the results
of the same teams on the CG task, we speculate
the PC and CG tasks are of similar complexity.
3.4 Gene Regulation Ontology (GRO)
The GRO task concerns the automatic annota-
tion of documents with Gene Regulation Ontol-
ogy (GRO) concepts (Kim et al, 2013b). The an-
notation is very detailed, with 145 entity and 81
event types. This results in a large number of small
classes which are independent in SVM classifica-
tion and thus hard to learn. TEES did not detect
most of the small classes, and generally, the larger
the class, the higher the performance. It is possible
that classification performance might be improved
by merging some of the smaller classes and disam-
biguating the predictions with a rule-based step,
similar to the TEES approach in the EPI 2011 task.
Overall performance was at 21.50% F-score but
as TEES 2.1 was the only system in this task, not
many conclusions can be drawn from it. However,
the system was also exactly the same as applied
in the other tasks. With decent performance on
some of the larger classes, we speculate that with
a larger training corpus, and with a system adapted
for the GRO task, performance comparable to the
GE, CG and PC tasks could be reached.
3.5 Gene Regulation Network (GRN)
GRN is a task where event extraction is utilized as
an optional, intermediate step in the construction
of a large regulation network (Bossy et al, 2013a).
The annotation consists of 11 entity types, 12 bi-
nary relation types and a single Action event type.
The predicted events can be automatically con-
verted to the regulation network, or the network
can be produced by other means. In either case,
the final evaluation is performed on the network,
using the Slot Error Rate (SER) metric (Makhoul
et al, 1999), where lower is better and a value of
less than one is expected for decent predictions.
TEES 2.1 produced the event format submis-
sion, and with conversion to the regulation net-
work achieved an SER of 0.86, placing in the mid-
dle of the five teams, all of which had an SER of
less than one. A downloadable evaluator program
was provided early enough in the development pe-
riod to be integrated in TEES 2.1, allowing direct
optimization against the official task metrics. As
SER was a metric not used before with TEES, the
relaxed F-score was instead chosen as the opti-
mization target, with the assumption that it would
provide a predictable result also on the hidden test
set. In training it was also observed that the param-
eters for the optimal relaxed F-score also produced
the optimal SER result.
3.6 Bacteria Biotopes (BB)
Along with the GENIA task, the BB task is the
only task to continue from earlier BioNLP Shared
Tasks. The BB task concerns the detection of
statements about bacteria habitats and relevant en-
21
vironmental properties and is divided into three
subtasks (Bossy et al, 2013b).
In task 1 the goal is to detect boundaries of bac-
teria habitat entities and for each entity, assign one
or more terms from 1700 concepts in the Onto-
Biotope ontology. While the TEES entity detector
could be used to detect the entities, assigning the
types falls outside the scope of the system, and is
not directly approachable as the sort of classifica-
tion task used in TEES. Therefore, BB task 1 was
the only task for which TEES 2.1 was not applied.
BB tasks 2 and 3 are a direct continuation of
the 2011 BB task, with the goal being extraction
of relations between bacteria entities and habitat
and geographical places entities. Only three entity
and two relation types are used in the annotation.
In task 2 all entities are provided and only rela-
tions are detected, in task 3 also the entities must
be predicted. The BB task was the only 2013 task
in which we used (limited) task specific resources,
as TEES 2.0 resources developed for the 2011 BB
task were directly applicable to the 2013 tasks. A
dictionary of bacteria name tokens, derived from
the List of Prokaryotic names with Standing in
Nomenclature3 (Euze?by, 1997) was used to im-
prove entity detection performance. Unlike the
2011 task, WordNet features were not used.
TEES 2.1 achieved F-scores of 42% and 14%
for tasks 2 and 3 respectively, reaching first place
in both tasks. The low overall performance is how-
ever indicative of the complexity of these tasks.
4 Conclusions
We applied TEES version 2.1 to the BioNLP 2013
Shared Task. An automated annotation scheme
learning system was built to speed up development
and enable application of the system to novel event
corpora. The system could be used as is in al-
most all BioNLP 2013 tasks, achieving good over-
all performance, including several first places.
The GRO task highlighted the limitations of a
purely classification based approach in situations
with very many small classes, in a sense the same
issue as with the ontology concept application in
BB task 1. Despite these minor limitations, the
basic stepwise SVM based approach of TEES con-
tinues to demonstrate good generalization ability
and high performance.
We made our system public during the task de-
velopment phase and provided precalculated anal-
3http://www.bacterio.cict.fr/
yses to all participants. While we consider it un-
fortunate that these analyses did not enjoy greater
popularity, we are also looking forward to the var-
ied approaches and methods developed by the par-
ticipating teams. However, the encouraging re-
sults of the GENIA task, not to mention earlier
positive reports on system combination (Kano et
al., 2011; Riedel et al, 2011) indicate that there is
untapped potential in merging together the strong
points of various systems.
TEES 2.1 had very good performance on many
tasks, but it must be considered that as an es-
tablished system it was already capable of do-
ing much of the basic processing that many other
teams had to develop for their approaches. In
particular, previous BioNLP Shared Tasks have
shown that the TEES internal micro-averaged
edge-detection F-score provides a very good ap-
proximation of the official metrics of most tasks.
It is unfortunate that official evaluator programs
were only available in some tasks, and often only
at the end of the development period, potentially
leading to a situation where different teams were
optimizing for different goals. In our opinion it
is of paramount importance that in shared tasks
not only the official evaluation metric is known
well ahead of time, but a downloadable evalua-
tor program is provided, as the complexity of the
tasks means that independent implementations of
the evaluation metric are error prone and an un-
necessary burden on the participating teams.
As with previous versions of TEES, the 2.1 ver-
sion is publicly available both as a downloadable
program and as a full, open source code repository.
We intend to continue developing TEES, and will
hopefully in the near future improve the automated
annotation learning system to overcome its cur-
rent limitations. We find the results of the BioNLP
2013 Shared Task encouraging, but as with previ-
ous iterations, note that there is still a long way
to go for truly reliable text mining. We think
more novel approaches, better machine learning
systems and careful utilization of the research so
far will likely lead the field of biomedical event
extraction forward.
Acknowledgments
We thank CSC ? IT Center for Science Ltd,
Espoo, Finland for providing computational re-
sources.
22
Type Name Arguments
ENTITY Anaphora
ENTITY Entity
ENTITY Protein
EVENT Binding Site[0,1](Entity) / Theme[1,2](Protein)
EVENT Gene expression Theme[1,1](Protein)
EVENT Localization Theme[1,1](Protein) / ToLoc[0,1](Entity)
EVENT Negative regulation Cause[0,1](Acetylation, Binding, Gene expression, Negative regulation, Phospho-
rylation, Positive regulation, Protein, Protein catabolism, Regulation, Ubiquitina-
tion) / Site[0,1](Entity) / Theme[1,1](Binding, Gene expression, Localization, Neg-
ative regulation, Phosphorylation, Positive regulation, Protein, Protein catabolism,
Regulation, Transcription, Ubiquitination)
EVENT Phosphorylation Cause[0,1](Protein) / Site[0,1](Entity) / Theme[1,1](Protein)
EVENT Positive regulation Cause[0,1](Acetylation, Binding, Gene expression, Negative regulation, Phospho-
rylation, Positive regulation, Protein, Protein catabolism, Regulation, Ubiquitina-
tion) / Site[0,1](Entity) / Theme[1,1](Binding, Deacetylation, Gene expression, Lo-
calization, Negative regulation, Phosphorylation, Positive regulation, Protein, Pro-
tein catabolism, Protein modification, Regulation, Transcription, Ubiquitination)
EVENT Protein catabolism Theme[1,1](Protein)
EVENT Protein modification Theme[1,1](Protein)
EVENT Regulation Cause[0,1](Binding, Gene expression, Localization, Negative regulation, Phos-
phorylation, Positive regulation, Protein, Protein modification, Regulation) /
Site[0,1](Entity) / Theme[1,1](Binding, Gene expression, Localization, Nega-
tive regulation, Phosphorylation, Positive regulation, Protein, Protein catabolism,
Protein modification, Regulation, Transcription)
EVENT Transcription Theme[1,1](Protein)
EVENT Ubiquitination Cause[0,1](Protein) / Theme[1,1](Protein)
RELATION Coreference, directed Subject(Anaphora) / Object(Anaphora, Entity, Protein)
RELATION SiteParent, directed Arg1(Entity) / Arg2(Protein)
MODIFIER negation Binding, Gene expression, Localization, Negative regulation, Phosphorylation,
Positive regulation, Protein catabolism, Regulation, Transcription
MODIFIER speculation Binding, Gene expression, Localization, Negative regulation, Phosphorylation,
Positive regulation, Protein catabolism, Regulation, Transcription, Ubiquitination
TARGET ENTITY Acetylation, Anaphora, Binding, Deacetylation, Entity, Gene expression,
Localization, Negative regulation, Phosphorylation, Positive regulation, Pro-
tein catabolism, Protein modification, Regulation, Transcription, Ubiquitination
TARGET INTERACTION Cause, Coreference, Site, SiteParent, Theme, ToLoc
Table 1: Automatically learned GENIA 2013 task event annotation scheme. The entities are the nodes
of the graph. Targets define the types of nodes and edges to be automatically extracted. Events and
relations are defined by their type and arguments. Relations are optionally directed, and always have two
arguments, with specific valid target node types. Events can have multiple arguments, and in addition
to valid target node types, the minimum and maximum amount of each argument per event are defined.
Modifiers are binary attributes defined by their type and the types of nodes they can be defined for.
23
References
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2011. Ex-
tracting Contextualized Complex Biological Events
with Rich Graph-Based Feature Sets. Computa-
tional Intelligence, Special issue on Extracting Bio-
molecular Events from Literature. Accepted in
2009.
Jari Bjo?rne, Filip Ginter, and Tapio Salakoski. 2012.
University of Turku in the BioNLP?11 Shared Task.
BMC Bioinformatics, 13(Suppl 11):S4.
Jari Bjo?rne, Suwisa Kaewphan, and Tapio Salakoski.
2013. UTurku: Drug Named Entity Detection and
Drug-drug Interaction Extraction Using SVM Clas-
sification and Domain Knowledge. In Proceedings
of the 7th International Workshop on Semantic Eval-
uation (SemEval 2013).
Robert Bossy, Philippe Bessir`es, and Claire Ne?dellec.
2013a. BioNLP shared task 2013 - an overview of
the genic regulation network task. In Proceedings
of BioNLP Shared Task 2013 Workshop, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.
Robert Bossy, Wiktoria Golik, Zorana Ratkovic,
Philippe Bessir`es, and Claire Ne?dellec. 2013b.
BioNLP shared task 2013 - an overview of the bac-
teria biotope task. In Proceedings of BioNLP Shared
Task 2013 Workshop, Sofia, Bulgaria, August. Asso-
ciation for Computational Linguistics.
Quoc-Chinh Bui and Peter M.A. Sloot. 2012. A robust
approach to extract biomedical events from litera-
ture. Bioinformatics, 28(20):2654?2661, October.
Jean Paul Marie Euze?by. 1997. List of Bacterial
Names with Standing in Nomenclature: a Folder
Available on the Internet. Int J Syst Bacteriol,
47(2):590?592.
Kai Hakala, Sofie Van Landeghem, Tapio Salakoski,
Yves Van de Peer, and Filip Ginter. 2013. EVEX
in ST?13: Application of a large-scale text mining
resource to event extraction and network construc-
tion. In Proceedings of BioNLP Shared Task 2013
Workshop, Sofia, Bulgaria, August. Association for
Computational Linguistics.
Daniel G. Jamieson, Martin Gerner, Farzaneh Sarafraz,
Goran Nenadic, and David L. Robertson. 2012.
Towards semi-automated curation: using text min-
ing to recreate the hiv-1, human protein interaction
database. Database, 2012.
Yoshinobu Kano, Jari Bjo?rne, Filip Ginter, Tapio
Salakoski, Ekaterina Buyko, Udo Hahn, K Bre-
tonnel Cohen, Karin Verspoor, Christophe Roeder,
Lawrence Hunter, Halil Kilicoglu, Sabine Bergler,
Sofie Van Landeghem, Thomas Van Parys, Yves
Van de Peer, Makoto Miwa, Sophia Ananiadou,
Mariana Neves, Alberto Pascual-Montano, Arzu-
can Ozgur, Dragomir Radev, Sebastian Riedel,
Rune Saetre, Hong-Woo Chun, Jin-Dong Kim,
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii.
2011. U-compare bio-event meta-service: compati-
ble bionlp event extraction services. BMC Bioinfor-
matics, 12(1):481.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction. In
Proceedings of the BioNLP 2009 Workshop Com-
panion Volume for Shared Task, pages 1?9, Boulder,
Colorado. ACL.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011. Overview of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association
for Computational Linguistics.
Jin-Dong Kim, Yue Wang, and Yamamoto Yasunori.
2013a. The genia event extraction shared task,
2013 edition - overview. In Proceedings of BioNLP
Shared Task 2013 Workshop, Sofia, Bulgaria, Au-
gust. Association for Computational Linguistics.
Jung-Jae Kim, Xu Han, Vivian Lee, and Dietrich
Rebholz-Schuhmann. 2013b. GRO task: Populat-
ing the gene regulation ontology with events and re-
lations. In Proceedings of BioNLP Shared Task 2013
Workshop, Sofia, Bulgaria, August. Association for
Computational Linguistics.
John Makhoul, Francis Kubala, Richard Schwartz, and
Ralph Weischedel. 1999. Performance measures for
information extraction. In Proceedings of DARPA
Broadcast News Workshop, pages 249?252.
David McClosky. 2010. Any domain parsing: auto-
matic domain adaptation for natural language pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Makoto Miwa and Sophia Ananiadou. 2013. NaCTeM
EventMine for BioNLP 2013 CG and PC tasks. In
Proceedings of BioNLP Shared Task 2013 Work-
shop, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and
Jun?ichi Tsujii. 2010. A comparative study of
syntactic parsers for event extraction. In Proceed-
ings of the 2010 Workshop on Biomedical Natural
Language Processing, BioNLP ?10, pages 37?45,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Mariana Neves, Alexander Damaschun, Nancy
Mah, Fritz Lekschas, Stefanie Seltmann, Harald
Stachelscheid, Jean-Fred Fontaine, Andreas Kurtz,
and Ulf Leser. 2013. Preliminary evaluation of
the cellfinder literature curation pipeline for gene
expression in kidney cells and anatomical parts.
Database, 2013.
24
Tomoko Ohta, Sampo Pyysalo, Rafal Rak, Andrew
Rowley, Hong-Woo Chun, Sung-Jae Jung, Sung-Pil
Choi, and Sophia Ananiadou. 2013. Overview of
the pathway curation (PC) task of bioNLP shared
task 2013. In Proceedings of BioNLP Shared Task
2013 Workshop, Sofia, Bulgaria, August. Associa-
tion for Computational Linguistics.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari
Bjo?rne, Filip Ginter, and Tapio Salakoski. 2008.
Comparative analysis of five protein-protein interac-
tion corpora. BMC Bioinformatics, 9(Suppl 3):S6.
Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, Han-
Cheol Cho, Jun?ichi Tsujii, and Sophia Ananiadou.
2012. Event extraction across multiple levels of bi-
ological organization. Bioinformatics, 28(18):i575?
i581.
Sampo Pyysalo, Tomoko Ohta, and Sophia Ananiadou.
2013. Overview of the cancer genetics (CG) task
of bioNLP shared task 2013. In Proceedings of
BioNLP Shared Task 2013 Workshop, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.
Sebastian Riedel, David McClosky, Mihai Surdeanu,
Andrew McCallum, and Christopher D. Manning.
2011. Model combination for event extraction in
bionlp 2011. In Proceedings of the BioNLP Shared
Task 2011 Workshop, BioNLP Shared Task ?11,
pages 51?55, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Isabel Segura-Bedmar, Paloma Mart??nez, and Maria
Herrero-Zazo. 2013. SemEval-2013 Task 9: Ex-
traction of Drug-Drug Interactions from Biomedical
Texts. In Proceedings of the 7th International Work-
shop on Semantic Evaluation (SemEval 2013).
Pontus Stenetorp, Wiktoria Golik, Thierry Hamon,
Donald C. Comeau, Rezarta Islamaj Dogan, Haibin
Liu, and W. John Wilbur. 2013. BioNLP shared
task 2013: Supporting resources. In Proceedings
of BioNLP Shared Task 2013 Workshop, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.
Ioannis Tsochantaridis, Thorsten Joachims, Thomas
Hofmann, and Yasemin Altun. 2005. Large margin
methods for structured and interdependent output
variables. Journal of Machine Learning Research
(JMLR), 6(Sep):1453?1484.
25
