Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 85?95,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
A Graph-Based Approach to String Regeneration
Matic Horvat
Computer Laboratory
University of Cambridge
15 JJ Thomson Avenue, CB3 0FD, U.K.
mh693@cam.ac.uk
William Byrne
Department of Engineering
University of Cambridge
Trumpington Street, CB2 1PZ, U.K.
wjb31@cam.ac.uk
Abstract
The string regeneration problem is the
problem of generating a fluent sentence
from a bag of words. We explore the N-
gram language model approach to string
regeneration. The approach computes the
highest probability permutation of the in-
put bag of words under an N-gram lan-
guage model. We describe a graph-based
approach for finding the optimal permuta-
tion. The evaluation of the approach on a
number of datasets yielded promising re-
sults, which were confirmed by conduct-
ing a manual evaluation study.
1 Introduction
The string regeneration problem can be stated as:
given a bag of words taken from a fluent grammat-
ical sentence, recover the original sentence. As it
is often difficult to recover the exact original sen-
tence based solely on a bag of words, the problem
is relaxed to generating a fluent version of the orig-
inal sentence (Zhang and Clark, 2011).
The string regeneration problem can generally
be considered a difficult problem even for humans.
Consider the following bag of words:
{ Iraq, list, in, a, third, joins, the, ., of,
Bush?s, of, critics, policy, senator, re-
publican }
and try to recover the original sentence or at least
a fluent grammatical sentence. The original sen-
tence was:
a third republican senator joins the list
of critics of Bush?s policy in Iraq.
The purpose of investigating and developing ap-
proaches to solving the string regeneration prob-
lem is grammaticality and fluency improvement
of machine generated text. The output of sys-
tems generating text, including SMT, abstract-like
text summarisation, question answering, and dia-
logue systems, often lacks grammaticality and flu-
ency (Knight, 2007; Soricut and Marcu, 2005).
The string regeneration problem is used as an
application-independent method of evaluating ap-
proaches for improving grammaticality and flu-
ency of such systems.
The string regeneration can also be viewed as
a natural language realization problem. The basic
task of all realization approaches is to take a mean-
ing representation as input and generate human-
readable output. The approaches differ on how
much information is required from the meaning
representation, ranging from semantically anno-
tated dependency graphs to shallow syntactic de-
pendency trees. A simple bag of words can then be
considered as the least constrained input provided
to a natural language realization system. The bag
of words can be combined with partial constraints
to form a more realistic meaning representation.
Wan et al. (2009) proposed an algorithm for
grammaticality improvement based on depen-
dency spanning trees and evaluated it on the string
regeneration task. They compared its performance
against a baseline N-gram language model genera-
tor. They found that their approach performs better
with regards to BLEU score. The latter approach
does well at a local level but nonetheless often pro-
duces ungrammatical sentences.
We argue that the authors have not fully ex-
plored the N-gram language model approach to
string regeneration. They used a Viterbi-like gen-
erator with a 4-gram language model and beam
pruning to find approximate solutions. Addition-
ally, the 4-gram language model was trained on
a relatively small dataset of around 20 million
words.
The N-gram language model approach finds the
highest probability permutation of the input bag
85
of words under an N-gram language model as the
solution to the string regeneration problem. In
this paper we describe a graph-based approach to
computing the highest probability permutation of
a bag of words. The graph-based approach models
the problem as a set of vertices containing words
and a set of edges between the vertices, whose
cost equals language model probabilities. Finding
the permutation with the highest probability in the
graph formulation is equal to finding the shortest
tour in the graph or, equally, solving the Travelling
Salesman Problem (TSP). Despite the TSP being
an NP-hard problem, state-of-the-art approaches
exist to solving large problem instances. An in-
troduction to TSP and its variants discussed in this
paper can be found in Applegate et al. (2006b).
In contrast to the baseline N-gram approach by
Wan et al. (2009), our approach finds optimal so-
lutions. We built several models based on 2-gram,
3-gram, and 4-gram language models. We exper-
imentally evaluated the graph-based approach on
several datasets. The BLEU scores and example
output indicated that our approach is successful
in constructing a fairly fluent version of the orig-
inal sentence. We confirmed the results of auto-
matic evaluation by conducting a manual evalua-
tion. The human judges were asked to compare the
outputs of two systems and decide which is more
fluent. The results are statistically significant and
confirm the ranking of the systems obtained us-
ing the BLEU scores. Additionally, we explored
computing approximate solutions with time con-
straints. We found that approximate solutions sig-
nificantly decrease the quality of the output com-
pared to optimal ones.
This paper describes work conducted in the
MPhil thesis by Horvat (2013).
2 Graph-Based Approach to String
Regeneration
The underlying idea of the approach discussed in
this paper is to use an N-gram language model to
compute the probabilities of permutations of a bag
of words and pick the permutation with the highest
probability as our solution.
The probability of a sequence of words under an
N-gram language model is computed as:
logP (w
n
1
) =
n
?
k=1
logP (w
k
|w
k?1
k?N+1
)
(1)
2.1 Naive Approach
A naive approach to finding the permutation with
the highest probability is to enumerate all permu-
tations, compute their probabilities using Equa-
tion 1, and choose the permutation with the highest
probability as the solution.
The time complexity of the naive approach is
O(n ? n!) as we are enumerating all permuta-
tions of n words and multiplying n conditional
probabilities for each permutation. This means
that the naive approach is not viable for sen-
tences of even moderate length. For example,
there are 3,628,800 permutations of 10 words and
355,687,428,096,000 of 17 words.
2.2 Bigram Graph-Based Approach
In this section we define the graph-based approach
to finding the highest probability permutation and
consequently our solution to the string regenera-
tion problem. For a bag of words S we define a
set of symbols X , X = S ? {<s>,</s>}, which
contains all the words in S (with indexes appended
to distinguish repeated words) and the start and
end of sentence symbols. For a bigram language
model, N = 2, we define a directed weighted
graph G = (V,E), with the set of vertices defined
as V = {w
i
|w
i
? X}. Therefore, each symbol
in X is represented by a single vertex. Let the set
of edges E be a set of ordered pairs of vertices
(w
i
, w
j
), such that E = {(w
i
, w
j
)|w
i
, w
j
? V }.
The edge cost is then defined as:
c
ij
=
?
?
?
?
?
?
?
?
?
0
if w
i
= </s>
and w
j
= <s>,
? logP (w
j
|w
i
) if w
i
6= w
j
,
? otherwise.
(2)
The conditional log probabilities of the form
logP (w
j
|w
i
) are computed by a bigram language
model. Consequently, finding the sentence permu-
tation with the highest probability under the bi-
gram language model equals finding the shortest
tour in graph G or, equally, solving the Asymmet-
ric Travelling Salesman Problem (ATSP). A gen-
eral example graph for a sentence of length 3 is
shown in Figure 1a.
The individual cases of the edge cost function
presented in Equation 2 ensure that the solution
tour is a valid sentence permutation. The nega-
tion of log probabilities transforms the problem of
86
 -
 
l
o
g
 
P
 
(
 
w
1
 
|
 
<
s
>
)
- log P (</s> | w
3 
)
- log P ( w
2 
| <s>)
-
 
l
o
g
 
P
 
(
 
w
1
 
|
 
w
2
 
)
-
 
l
o
g
 
P
 
(
 
w
2
 
|
w
1
 
)
-
 
l
o
g
 
P
 
(
w
3
 
|
 
w
2
 
)
-
 
l
o
g
 
P
 
(
w
2
 
|
 
w
3
 
)
-
 
l
o
g
 
P
 
(
 
w
3
 
|
 
w
1
 
)
-
 
l
o
g
 
P
 
(
 
w
1
 
|
 
w
3
 
)
-
 
l
o
g
 
P
 
(
<
/
s
>
 
|
 
w
1
 
)
-
 
l
o
g
 
P
 
(
 
w
3
 
|
<
s
>
)
-
 
l
o
g
 
P
 
(
<
/
s
>
 
|
 
w
2
 
)
0
<s>
  w
1
  w
2
 w
3
</s>
(a) A general graph. The edge cost equals the negated bigram
conditional log probability of the destination vertex given the
origin vertex. Only edges with non-infinite edge cost are
shown in the graph. Finding the shortest tour in the graph
equals finding the sentence permutation with the highest prob-
ability.
 
0
3

2
3
0
0
2
