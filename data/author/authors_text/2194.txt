Acquisition System for Arabic Noun Morphology 
 
Saleem Abuleil   Khalid Alsamara      Martha Evens 
                    Information System Department          Computer Science Department 
                           Chicago State University           Illinois Institute of Technology 
                      9501 S. King Drive, Chicago, IL 60628    10 West 31 Street, Chicago IL 60616 
                          s_abuleil@hotmail.com  kalsamara@hotmail.com        evens@iit.edu  
 
 
 
Abstract 
 
Many papers have discussed different 
aspects of Arabic verb morphology. Some of 
them used patterns; others used patterns and 
affixes. But very few have discussed Arabic 
noun morphology particularly for nouns that 
are not derived from verbs. In this paper we 
describe a learning system that can analyze 
Arabic nouns to produce their 
morphological information and their 
paradigms with respect to both gender and 
number using a rule base that uses suffix 
analysis as well as pattern analysis. The 
system utilizes user-feedback to classify the 
noun and identify the group that it belongs 
to. 
 
1 Introduction 
 
A morphology system is the backbone of a 
natural language processing system. No 
application in this field can survive without a 
good morphology system to support it. The 
Arabic language has its own features that are not 
found in other languages. That is why many 
researchers have worked in this area. Al-Fedaghi 
and Al-Anzi (1989) present an algorithm to 
generate the root and the pattern of a given 
Arabic word. The main concept in the algorithm 
is to locate the position of the root?s letters in the 
pattern and examine the letters in the same 
position in a given word to see whether the tri 
graph forms a valid Arabic root or not.  
Al-Shalabi (1998) developed a system 
that removes the longest possible prefix from the 
word where the three letters of the root must lie 
somewhere in the first four or five characters of 
the remainder. Then he generates some 
combinations and checks each one of them with 
all the roots in the file. Al-Shalabi reduced the 
processing, but he discussed this from point of 
view of verbs not nouns. Anne Roeck and 
Waleed Al-Fares (2000) developed a clustering 
algorithm for Arabic words sharing the same 
verbal root. They used root-based clusters to 
substitute for dictionaries in indexing for 
information retrieval. Beesley and Karttunen 
(2000) described a new technique for 
constructing finite-state transducers that 
involves reapplying a regular-expression 
compiler to its own output. They implemented 
the system in an algorithm called compile-
replace. This technique has proved useful for 
handling non-concatenate phenomena, and they 
demonstrate it on Malay full-stem reduplication 
and Arabic stem inter-digitations. 
Most verbs in the Arabic language 
follow clear rules that define their morphology 
and generate their paradigms. Those nouns that 
are not derived from roots do not seem to follow 
a similar set of well-defined rules. Instead there 
are groups showing family resemblances.  
We believe that nouns in Arabic that are 
not derived from roots are governed not only by 
phonological rules but by lexical patterns that 
must be identified and stored for each 
noun. Like irregular verbs in English their forms 
are determined by history and etymology, not 
just phonology.  Among many other examples, 
Pinker (1999) points to the survival of past 
forms became for become and overcame for 
overcome, modeled on came for come, while 
succumb, with the same sound pattern, has a 
regular past form succumbed.  The same kinds 
of phenomena are especially apparent for proper 
nouns in Arabic derived from Indian and Persian 
names. Pinker uses examples like this, as well as 
emerging research in neurophysiology, to argue 
for the coexistence of phonological rules and 
lexical storage of English verb patterns.   
We believe that further work in Arabic 
computational linguistics requires the 
development of a pattern bank for nouns.  This 
paper describes the tool that we have built for 
this purpose.   While the set of patterns for 
common nouns in Arabic may soon be 
established, newspapers and other dynamic 
sources of language will always contain new 
proper names, so we expect our tool to be a 
permanent part of our system, even though we 
may need it less often as time goes on. 
 
2 Nouns in the Arabic Language 
 
A noun in Arabic is a word that indicates a 
meaning by itself without being connected with 
the notion of time. There are two main kinds of 
noun: variable and invariable. Variable nouns 
have different forms for the singular, the dual, 
the plural, the diminutive, and the relative. 
Variable nouns are again divided into two kinds: 
inert and derived. The inert noun is not derived 
from another word, i.e. it does not refer to a 
verbal root. Inert nouns are divided into two 
kinds: concrete nouns (e.g., lion), and abstract 
nouns (e.g., love). Derived nouns are taken from 
another word (usually a verb) (e.g. office); they 
have a root to refer to. A derived noun is usually 
close to its root in meaning. It indicates, besides 
the meaning, the concrete thing that caused its 
formation (case of the agent-noun), or 
underwent its action (case of the patient-noun), 
or any other notions of time, place, or 
instrument. The following are the noun types: 
A genus noun indicates what is 
common to every element of the genus without 
being specific to any one of them. It is the word 
naming a person, an animal, a thing or an idea. 
Example:   ???    man         ????     book 
An agent noun is a derived noun 
indicating the actor of the verb or its behavior. It 
has several patterns according to its root. 
Example: 
             ????         the person who studies 
A patient noun is a derived noun 
indicating the person or thing that undergoes the 
action of the verb. Patient nouns have several 
patterns depending in the verbal root. Example: 
       ?????     the thing that has been studied 
An instrument noun is a noun 
indicating the tool of an action. Some 
instruments are derived; some are inert. 
Example: ?????    key 
An adjective is considered to be a type 
of noun in traditional Arabic grammar. It 
describes the state of the modified noun. 
Example: ????      beautiful         ???        Mr.          
 ?????    Professor          ????   big                    
An adverb is a noun that is not derived 
and that indicates the place or the time of the 
action. Example: 
       ???   Month   ?????   city    ????   north 
A proper noun is the name of a specific 
person, place, organization, thing, idea, event, 
date, time, or other entity. Some of them are 
solid (inert) nouns some of them are derived 
[Abuleil and Evens 1998]. 
 
3 Noun Classification 
 
In this paper we focus on the following nouns: 
genus nouns, agent nouns, instrument nouns, 
adjectives, proper adjectives (adjectives derived 
from proper nouns), proper nouns, and adverbs. 
Some of these nouns are not derived from verbs 
and some are. All of these nouns use the same 
pattern when it comes to the dual form either for 
masculine or feminine, but there are many ways 
to form the plural noun. Some of the nouns have 
both masculine and feminine forms, some of 
them have just feminine forms and some have 
just masculine forms. A few nouns use the same 
format for both the plural and the dual (e.g. 
 ?????? teachers used for both dual and plural) 
For most nouns, when they end with the letter    
(?), this indicates the feminine form of the noun, 
sometimes it does not, but it changes the 
meaning of the noun completely (e.g.  ???? 
office, ????? library). Sometimes the same 
consonant string with different vowels has 
different meanings (e.g.  ????? school, ????? 
teacher). Nouns are not like verbs in the Arabic 
language, there is no clear rule to define the 
morphological information and generate the 
morphology paradigms for them. Instead each 
group of nouns follows its own pattern. 
We have classified the nouns into 84 
groups according to their patterns for singular, 
plural, masculine and feminine. We generated a 
method for each group to be used to find the 
morphological information and to form its 
paradigm. Very few of these groups have a 
unique pattern for plural and singular; and most 
of them share the same pattern with other 
groups. Table 1 shows some examples of these 
groups and their patterns. The digit 9 stands for 
the letter ?ayn [?]?, ? stands for ?hamzh [?]? and 
@ stands for ?ta [?]? since there is no 
corresponding letters in English for these letters. 
 
Table 1. Pattern Classification 
S-M S-F P-M P-F 
f9l X af9al X 
f9l f9l@ af9la? af9la? 
X f9l@ X f9l 
fa9l fa9l@ f9al/f9l@ f9al/f9l@ 
f9al X X af9l@ 
mf9l X mfa9l X 
fa9wl X fwa9el X 
mf9el X mfa9el X 
X fa9l@ X fa9lat 
f9el f9el@ f9la? f9la? 
S: Singular F: Feminine 
P: Plural M: Masculine 
X: not available  
 
4 Acquisition System 
 
The system reads the next noun in the text, 
isolates and analyzes the suffixes of the noun, 
generates its pattern, and uses either the 
Classified Noun Table, the Suffix/Pattern 
Analysis or the User-Feedback Module to find 
the group to which the noun belongs to identify 
the rules that applies to this group to generate all 
morphological paradigms with respect to the 
number and gender and updates the database. 
The system consists of several modules as 
shown in Figure 1. 
 
4.1 Interface Module  
This graphical user interface allows the user 
to interact with the system and handles the 
input/output. This module displays a main 
menu with two main options: collect nouns 
from documents and find morphological 
information. 
 
4.2 Type-Finder Module  
The main function of this module is to read the 
document and find the part of speech of the 
word: noun, verb, adjective, particle or proper 
noun by running several tests: Database lookup, 
particle check, check on adjectives derived from 
proper nouns, parse of noun phrases and verb 
phrases, the affix check and the pattern check 
This module was built by Abuleil and Evens 
(1998, 2001). We use this module in our new 
system to find all nouns and extract them from 
the text. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. The Acquisition System 
 
4.3 Database 
The database includes a Classified Noun Table 
that contains each root noun (singular: 
masculine or feminine) and the number of the 
group to which the noun belongs. Each time the 
system identifies a new noun it adds its root to 
the Classified Noun Table. 
 
4.4 Noun Morphology Analyzer 
Module  
This is the core of the system, it calls different 
modules and performs different tasks to identify 
the noun and find its paradigm. First, it passes 
the noun to the suffix analyzer module to drop 
the suffix. Second, it passes it to the pattern 
generator module to find the pattern. Third, it 
analyzes the pattern to see whether it belongs to 
more than one group. It checks the Classified 
Nouns Table and then the suffix/pattern to 
Interface 
Noun 
Morphology 
Analyzer 
Suffix 
Analyzer
Pattern 
Generator 
User-
Feedback 
Type-
Finder 
Database
DB 
Checker
identify the group that the noun belongs to. If 
the system cannot identify the group then it calls 
the user-Feedback module to produce some 
questions to be answered by the user to reduce 
the number of alternatives to one. Finally, 
depending on the group the noun belongs to, it 
generates the morphological paradigms for 
number and gender and updates the database. 
 
4.5 Suffix Analyzer Module  
This module identifies the suffix, analyzes it and 
produces some lexical information about the 
noun like number and gender. First, it checks if 
any pronoun is concatenated with the noun. 
Second, it checks for a suffix indicating number. 
Third, it checks for a suffix indicating gender.  
When the letter (?) comes at the end of 
the noun there are two cases: it could be a part of 
the noun so we should not drop it, or it could be 
an extra letter as in relative nouns or when the 
pronoun is connected to the noun and it should 
be dropped in this case. When the noun ends 
with the letters (??), most of the time it 
represents dual nouns but some times it 
represents both plural and dual nouns as in the 
following patterns: mfa9l, fa9l, mf9ull. 
Sometimes we have to check the pattern also to 
help in analyzing the suffix. We will handle 
these problems as special cases.  
   
4.6 Pattern Generator Module  
We have collected 62 different patterns used for 
both masculine and feminine, singular and plural 
after the suffix has been dropped see Appendix 
A. We used these patterns to generate a set of 
rules to build a finite-state diagram to be used to 
find the pattern for any noun. The input to this 
module is a noun after its suffix has been 
dropped in the previous step, the output is one or 
more patterns. If more than one pattern is found 
we validate the string by checking the pattern 
table.  
The letter (?) and the letter (?) at the 
beginning of the noun are sometimes the first 
characters of the noun, but sometimes they are 
separate words. We collected the nouns that 
begin with the letter (?) and the letter (?) and 
saved them in a file to help us to distinguish 
between these two cases. 
 
4.7 Database Checker Module  
This module identifies any already classified 
noun or any noun derived from it. It gets the 
noun and its pattern from the noun morphology 
analyzer, finds all groups that contain the 
pattern, finds the singular noun (masculine or 
feminine) in each group and uses it to check the 
Classified Noun Table. If the noun exists it gets 
the group number to which it belongs and passes 
it to the Noun Morphology Analyzer to generate 
the results. For example the noun (????? 
playground) has the pattern (mfa9l). This pattern 
appears in three different groups. See table 2. 
 
Table 2. The Groups of the Noun ? ??????  
Group# Sing. 
Masc. 
Sing 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
1 X mf9l@ X Mfa9l    
2 Mf9l   X X Mfa9l    
3 mfa9l     mf9l@ mf9lun/ 
mf9len 
?????? 
 
The nouns formed from these patterns have the 
following paradigms. See table 3. 
  
Table 3. The Paradigms of the Noun ? ??????   
Group# Sing. 
Masc. 
Sing 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
1 X  ?????        X ?????     
2  ????   X X ?????     
3  ?????? ????? ?????/
?????? 
?????? 
 
If the noun itself or any other noun derived from 
it has been previously classified we will find its 
noun root (singular noun) in the Classified Noun 
Table. The module will find the root (singular 
masculine) ?????? in the table and will get its 
group number ?2? and pass it to Noun 
Morphology Analyzer to find the noun 
paradigms.  
  
4.8 User-Feedback Module  
This module gets all alternatives (groups) from 
the noun morphology analyzer module. It 
analyzes them and generates some questions to 
be answered by the user. It gets the answers, 
analyzes them and finds the group that the noun 
belongs to. The module asks questions like: Is 
the noun a singular? Is the noun a plural? Does 
the noun have a masculine-singular format? 
Does the noun have a feminine-singular format?  
 
Example:  
Input:  The noun (????? playground) 
Pattern: mfa9l 
Number of groups that contain the 
pattern is 3. 
 
Process: 
Step #1: identify the groups  
 
Group# Sing. 
Masc. 
Sing. 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
1 X mf9l@     X mfa9l     
2 mf9l   X X mfa9l     
3 mfa9l     mf9l@     mf9lun / 
mf9len 
mf9lat 
  
Step #2: Replace (X) with ?1, given pattern with 
1 and any thing else with 0.  
 
Group# Sing. 
Masc. 
Sing. 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
1 -1 0  -1 1 
2 0 -1 -1 1 
3 1 0 0 0 
 
Step #3: Add the one?s in each column and 
subtract it from number of groups. Add the (-
1?s) in each column and subtract it from number 
of groups. Add the (0?s) in each column. 
 
Group# Sing. 
Masc. 
Sing. 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
1 -1 0  -1 1 
2 0 -1 -1 1 
3 1 0 0 0 
A = ?1?s 1 0 0 2 
B = ?-1?s 1 1 2 0 
C = ? 0?s 1 2 1 1 
A1 = #G ? A 2 3 3 1 
B1 = #G ? B 2 2 1 3 
 
From the table above we know that: the 
probability that the noun is singular masculine is 
33.3% and the probability that it is a plural 
feminine is 66.6%. 
 
Step #4: Pick the smallest value greater than 0 
from the ?A1? row and the ?B1? row go from 
left to right and from top to bottom. Use the 
column name to form questions. For the ?A1? 
value use the following question: is the noun a 
[column name]? For the ?B1? use the following 
question: does the noun have the [column name] 
format? Get the answer and drop invalid 
group(s).       
 
Group# Sing. 
Masc. 
Sing. 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
1 -1 0 -1 1 
2 0 -1 -1 1 
A = ?1?s 0 0 0 2 
B = ?-1?s 1 1 2 0 
C = ? 0?s 1 1 0 0 
A1 = #G ? A 2 2 2 0 
B1 = #G ? B 1 1 0 2 
 
Step #5: Repeat step 3 and step 4 until you end 
up with one group or all the values in both Row 
A1 and row B1 have the values either zero or the 
number of groups left. 
 
Step #6: if more than one group is left from step 
#5 then find the largest value in the row ?C? 
from left to right and ask the following question: 
which of the following [list all the options in that 
column] is the [column name] of the noun?   
 
Group 
# 
Sing. 
Masc. 
Sing. 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
2 0 -1 -1 1 
A = ?1?s 0 0 0 1 
B = ?-1?s 0 1 1 0 
C = ? 0?s 1 0 0 0 
A1 = #G ? A 1 1 1 0 
B1 = #G ? B 1 0 0 1 
 
The questions the module generated from the 
previous example are:  
Q1: is the noun plural feminine? 
Answer: yes // the system drops group#3 
Q2: does the noun have singular masculine 
format? 
Answer: No  // the system drops group#1 
 
Result:  
Group # 2: The noun (????? playground) is a 
plural Feminine. The singular Masculine format 
is ( ????), the singular Feminine format and 
plural masculine format are not available for this 
noun.   
5 Examples 
 
The following example shows how the system 
works. Assume that the input is the noun ( ??????? 
their trainer), First the system calls the suffix 
analyzer module to drop the extra letter 
(pronoun: their) at the end ( ????? + ??), replace 
the letter (?) with the letter (?), generate the 
noun (????? trainer) and some lexical information 
about the noun. 
Second, it passes the noun (????? trainer) 
to the pattern generator module to generate the 
pattern (mf9l@). Third, it checks the group table 
looking for this pattern (mf9l@). Fourth, if more 
that one group is found it uses the Database 
Checker Module to check the Classified Noun 
Table. Fifth, if the noun does not exist in the 
table, it calls the User-Feedback Module to 
analyze the groups (all alternatives) and asks the 
user some questions to assist in identifying the 
group see Table 4 and Table 5. The question that 
the module generated is: 
 
Question: Does the noun have a masculine-
singular format? 
Answer: Yes 
Result:  drop group # 10 & group # 22 
 
Table 4. First Cycle to Generate Question  
Group # Sing. 
Masc. 
Sing 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
10 -1 1 0 -1 
22 -1 1 0 -1 
38 0 1 0 0 
A = ?1?s 0 3 0 0 
B = ?-1?s 2 0 0 2 
C = ? 0?s 1 0 3 1 
A1 = #G ? A 3 0 3 3 
B1 = #G ? B 1 3 3 1 
 
Table 5. Second Cycle to Generate Question  
Group # Sing. 
Masc. 
Sing 
Fem. 
Plural 
Masc. 
Plural 
Fem. 
38 0 1 0 0 
A = ?1?s 0 1 0 0 
B = ?-1?s 0 0 0 0 
C = ? 0?s 1 0 1 1 
A1 = #G ? A 1 0 1 1 
B1 = #G ? B 1 1 1 1 
 
Fifth, it generates the results: group#38 and 
updates the database. Table 6 shows system 
output for some input. 
 
Table 6. System Output 
Noun ?????? 
keys 
????? 
plane 
????? 
Our 
sound 
?????? 
generous  
Suffix ---- ---- ?? ?? 
 
Pattern ?????? 
mfa9el 
????? 
fa9l@ 
 ???    
f9l 
????    
f9el 
Group # 52 23 3 37 
 
Result Plural 
masc. 
Singular 
Feminine 
Singular 
feminine 
Dual / 
plural 
masc. 
Singular 
/ Masc. 
????? X ???? ??? 
Singular 
/ Fem. 
X ????? X ????? 
Plural / 
Masc. 
X X X ?????  /  
?????? 
Plural / 
Fem. 
?????? ????? ?????? ?????? 
Dual / 
Masc.  
 ???????
???????  
X    ?????
????? 
  ??????
?????? 
Dual / 
Fem. 
X  ???????
??????? 
X   ???????
??????? 
 
6 Results 
 
To test our system we used nouns obtained from 
a corpus developed by Ahmad Hasnah based on 
text given to Illinois Institute of Technology, by 
the newspaper, Al-Raya, published in Qatar. We 
have tested each module in our system: the 
suffix analyzer modules, the pattern generator 
module, and the user-Feedback module. Table 7 
shows the result of testing the system on 500 
nouns. 
 
Table 7. Suffix / Pattern / Noun Morphology 
Analyzer 
 # 
correct 
# 
incorrect 
% 
correct 
% 
incorrect 
Suffix 
Analyzer 
 
490 
 
10 
 
97% 
 
3% 
Pattern 
Analyzer 
 
471 
 
29 
 
93% 
 
8% 
Noun 
Morph 
analyzer 
 
451 
 
49 
 
90.2% 
 
9.8% 
 
As shown in Table 7 there were ten failure 
because of incorrect suffix analysis and 29 due 
to missing patterns. These missing patterns have 
now been added. The suffix analysis problem is 
hard to correct because it arises from underlying 
ambiguities. If the noun has been classified 
previously the system does not have any 
problem to identify it and identify any noun 
derived from it. 
The User-Feedback Module found most 
of the nouns that the Database Checker Module 
failed to identify. Table 8 shows a number of 
nouns identified by suffix/pattern, nouns 
identified by Database Checker Module and 
nouns identified by User-Feedback Modules. 
We believe that the more knowledge that the 
system gains and the more nouns that it adds to 
the Classified Noun Table the fewer questions 
have to be asked. 
 
Table 8. Noun Classifier Methods 
Nouns 
Identified by 
Database 
Checker  
Nouns 
Identified by 
 Suffix/ 
Pattern 
Analysis  
Nouns Identified 
by 
User-Feedback 
Module 
 
144 
 
32 
 
289 
 
28.8% 
 
7.1% 
 
64.1% 
 
7 Conclusion 
 
We have built a learning system that utilizes 
user feedback to identify the nouns in the Arabic 
language, obtain their features and generate their 
paradigms with respect to number and gender. 
We tested the system on 500 nouns from 
newspaper text. The system identified 90.2% of 
them, 7.1% by just analyzing the suffix and the 
pattern of the noun, 28.8% by using the 
Database Checker Module and the Classified 
Noun Table and 64.1% by using User-Feedback 
Module. The system failed on 9.8% of the tested 
nouns. 
 
References 
 
Abuleil, S. and Evens, M., 1998. ?Discovering 
Lexical Information by Tagging Arabic 
Newspaper Text?, Workshop on Semitic 
Language Processing. COLING-ACL?98, 
University of Montreal, Montreal, PQ, Canada, 
Aug 16 1998, pp 1-7. 
 
Abuleil, S. and Evens, M., 2002. Extracting an 
Arabic Lexicon from Arabic Newspaper Text. 
Computers and the Humanities, 36(2), pp. 191-
221. 
 
Al-Fedaghi, Sabah and Al-Anzi, Fawaz, 1989. 
?A New Algorithm to Generate Arabic Root-
Pattern Forms?. Proceedings of the 11th National 
Computer Conference, King Fahd University of 
Petroleum & Minerals, Dhahran, Saudi Arabia., 
pp 4-7. 
 
Al-Shalabi, R. and Evens, M., 1998. ?A 
Computational Morphology System for Arabic?. 
Workshop on Semitic Language Processing. 
COLING-ACL?98, University of Montreal, 
Montreal, PQ, Canada, Aug 16 1998. pp. 66-72.     
 
Beesley, K. and Karttunen, L., 2000. ?Finite-
State Non-Concatenative Morphotactics?. 
Proceedings of the 38th Annual Meeting of the 
Association for Computational Linguistics. 
Hong Kong, Oct 1-8, 2000. pp.191-198. 
   
Hasnah, A., 1996. Full Text Processing and 
Retrieval: Weight Ranking, Text Structuring, 
and Passage Retrieval For Arabic Documents. 
Ph.D. Dissertation, Illinois Institute of 
Technology, Chicago, IL. 
 
Roeck, A. and Al-Fares, W., 2000. ?A 
Morphologically Sensitive Clustering Algorithm 
for Identifying Arabic Roots?. Proceedings of 
the 38th Annual Meeting of the Association for 
Computational Linguistics. Hong Kong, Oct 1-8, 
2000. pp.199-206. 
   
Appendix A. Patterns 
 
Pattern Used for Example 
f9l sing ? masc. ??? 
f9l plural ? masc. ??? 
f9l plural ? fem. / masc. ??? 
f9l plural ? fem. ??? 
f9l sing ? masc. ??? 
f9l@ sing. ? fem. ???? 
mf9al sing. masc. ????? 
Pattern Used for Example 
f9l@ plural ? masc. ???? 
aft9al sing. ? masc. ?????? 
anf9al sing. ? masc. ?????? 
astf9al sing. - masc. ??????? 
af9al plural ? fem. ????? 
af9la? plural ? fem. / masc. ?????? 
af9l@ plural ? fem. ????? 
af9el sing. ? masc. ????? 
afa9el plural ? fem. ?????? 
f9lawat plural ? fem. ??????? 
fwa9l plural ? fem. ????? 
fwa9el plural ? fem. ?????? 
fe9al sing- masc. ????? 
f9lan plural ? fem. ????? 
f9all plural ? fem. ????? 
tf9l@ plural ? fem. ????? 
f9wl@ plural ?fem. ????? 
f9wl sing. ? masc. ???? 
f9ll@ sing- fem. ????? 
f9le@ sing. ? fem. ????? 
f9le sing.- masc. ???? 
f9el sing ? masc. ???? 
f9el@ sing.- fem. ????? 
f9al sing.- masc. ???? 
f9al plural ? fem. ???? 
f9ale plural ? fem. ????? 
fa9l sing. ? masc. ???? 
fa9l@ sing. ? fem. ????? 
f9al@ sing. ? fem. ????? 
f9al plural ? masc. ???? 
f9la? plural ? masc. ????? 
f9la? sing. ? fem. ????? 
f9alel plural ? fem. / masc. ?????? 
fa9wl sing. masc. ????? 
f9a?l plural ? fem. ????? 
tf9el sing. ? masc. ????? 
f9lwl sing. ? masc. ????? 
tfa9el plural ? fem. ?????? 
fw9l@ sing. ? fem. ????? 
f9wal sing. ? masc. ????? 
f9awel plural ? fem. ?????? 
mf9l@ sing. ? fem. ????? 
mfa9l plural ? fem. ????? 
mf9l sing. ? masc. ???? 
mf9l@ sing. ? fem. ????? 
mf9l sing. ? masc. ???? 
mf9l@ sing. ? fem. ????? 
mft9l sing. masc. ????? 
Pattern Used for Example 
Mstf9l sing. ? masc. ?????? 
mf9ll sing. ? masc. ????? 
Mstf9a sing. fem. ?????? 
mf9wl@ sing. ? fem. ?????? 
mf9el sing. masc. ????? 
mfa9el plural ? fem. ?????? 
mf9le@ sing. ? fem. ?????? 
mfa9l sing. ? masc. ????? 
mfa9l@ sing. ? fem. ?????? 
mf9wl sing. ? masc. ????? 
mfa9el plural ? fem. ?????? 
 
 
 
 QARAB: A Question Answering System to Support 
the Arabic Language 
 
Bassam Hammo  Hani Abu-Salem  Steven Lytinen 
 
DePaul University 
School of Computer Science, Telecommunications and Information Systems  
243 S. Wabash Avenue, Chicago IL 60604 
  
bhammo@condor.depaul.edu habusalem@cti.depaul.edu lytinen@cs.depaul.edu 
 
Martha Evens 
Illinois Institute of Technology 
Computer Science Department 
10 West 31st Street, Chicago, IL 60616 
evens@iit.edu 
 
 
 
Abstract 
 
We describe the design and 
implementation of a question answering 
(QA) system called QARAB. It is a 
system that takes natural language 
questions expressed in the Arabic 
language and attempts to provide short 
answers. The system?s primary source 
of knowledge is a collection of Arabic 
newspaper text extracted from Al-Raya, 
a newspaper published in Qatar. During 
the last few years the information 
retrieval community has attacked this 
problem for English using standard IR 
techniques with only mediocre success. 
We are tackling this problem for Arabic 
using traditional Information Retrieval 
(IR) techniques coupled with a 
sophisticated Natural Language 
Processing (NLP) approach. To identify 
the answer, we adopt a keyword 
matching strategy along with matching 
simple structures extracted from both 
the question and the candidate 
documents selected by the IR system. 
To achieve this goal, we use an existing 
tagger to identify proper names and 
other crucial lexical items and build 
lexical entries for them on the fly.  We 
also carry out an analysis of Arabic 
question forms and attempt a better 
understanding of what kinds of answers 
users find satisfactory.  The paucity of 
studies of real users has limited results 
in earlier research. 
 
1 Introduction 
 
In recent years, there has been a marked increase 
in the amount of data available on the Internet.   
Users often have specific questions in mind, for 
which they hope to get answers. They would like 
the answers to be short and precise, and they 
always prefer to express the questions in their 
native language without being restricted to a 
specific query language, query formation rules, or 
even a specific knowledge domain. The new 
approach taken to matching the user needs is to 
carry out actual analysis of the question from a 
linguistic point of view and to attempt to 
understand what the user really means.  
 QARAB is the result of coupling traditional 
Information Retrieval (IR) techniques with a 
sophisticated Natural Language Processing (NLP) 
approach. The approach can be summarized as 
follows: the IR system treats the question as a 
query in an attempt to identify the candidate 
 documents that may contain the answer; then the 
NLP techniques are used to parse the question and 
analyze the top ranked documents returned by the 
IR system. 
 Natural Language Processing (NLP) in the 
Arabic language is still in its initial stage 
compared to the work in the English language, 
which has already benefited from the extensive 
research in this field.  There are some aspects that 
slow down progress in Arabic Natural Language 
Processing (NLP) compared to the 
accomplishments in English and other European 
languages [Al-Daimi & Abdel-Amir, 1994]. 
These aspects include: 
? Arabic is highly inflectional and derivational, 
which makes morphological analysis a very 
complex task. 
? The absence of diacritics (which represent 
most vowels) in the written text creates 
ambiguity and therefore, complex 
morphological rules are required to identify 
the tokens and parse the text. 
? The writing direction is from right-to-left and 
some of the characters change their shapes 
based on their location in the word. 
? Capitalization is not used in Arabic, which 
makes it hard to identify proper names, 
acronyms, and abbreviations. 
 
In addition to the above linguistic issues, there 
is also a lack of Arabic corpora, lexicons, and 
machine-readable dictionaries, which are essential to 
advance research in different areas. 
 
 
2 Background 
 
Advances in natural language processing (NLP), 
information retrieval techniques (IR), information 
extraction (IE), as well as the computer industry, 
have given QA a strong boost. Modern question-
answering systems have started incorporating 
NLP techniques to parse natural language 
documents, extract entities and relations between 
entities, resolve anaphora, and other language 
ambiguities [Harabagiu et al, 2000; Vicedo & 
Ferr?ndez, 2000].   
 Research in Question-Answering (QA) is not 
new.  The QA problem has been addressed in the 
literature since the beginning of computing 
machines.  The AI/NLP communities initiated 
traditional work to address question-answering 
using structural methods. Early experiments in 
this direction implemented systems that operate in 
very restricted domains (e.g. SHRDLU 
[Winogard, 1972] and LUNAR [Woods, 1972]).   
In the QUALM system, Lehnert [1978] took a 
further step, based on the conceptual theories of 
Schank & Abelson [1977], to understand the 
nature of the questions and classify them in a way 
similar to how human beings understand and 
answer questions. SCISOR [Jacobs & Rau 1990] 
aimed at question answering and text extraction 
more than information retrieval. It combined 
natural language processing, knowledge 
representation, and information retrieval 
techniques with lexical analysis and word-based 
text searches. The MURAX system [Kupiec, 
1993] used robust linguistic methods to answer 
closed-class natural language questions. It 
presented the user with relevant text in which 
noun phrases are marked. A less automated 
approach like Ask Jeeves [1996] approached the 
QA problem by pointing the questioner to Web 
links that might contain information relevant to 
the answer to the question. Ask Jeeves benefited 
from advanced natural language processing 
techniques combined with data mining processing 
and a huge expanding knowledge base. Another 
system, with a different approach, is the 
FAQFinder system [Burke et al, 1997], which 
attempted to solve the question-answering 
problem using a database of question-answer pairs 
built from existing frequently asked question 
(FAQ) files.  Two other important systems are the 
START system [Katz, 1997], which is based on 
annotations from the Web and the Q&A system 
[Budzik & Hammond, 1999], which is a 
semiautomatic, natural language question-
answering and referral system. The system is 
based on a huge knowledge base and human 
experts who volunteered their time to respond to 
the users? questions. 
 Recently, attention has begun to be focused 
on developing question-answering systems that do 
 not rely on a knowledge base and that can fetch 
answers from huge unstructured text.  New QA 
systems enhanced with NLP and IR techniques 
have been developed to extract textual answers for 
open-domain questions and provide a framework 
for modern information retrieval [TREC-8, 1999; 
TREC-9, 2000].  
 The overall aim of this QA track was to 
retrieve small pieces of text that contain the actual 
answer to the question rather than the list of 
documents traditionally returned by retrieval 
engines [Voorhees & Tice, 2000].  The TREC-8 
QA track attracted researchers from both industry 
and academia. Twenty organizations participated 
in this track with different approaches and their 
systems were evaluated.  The participating 
systems were tested on a huge set of unstructured 
documents and a set of fact-based questions.   
 Generally speaking, most of the TREC-8 
long-string answer (250-bytes) participants 
attempted to solve the QA problem from the 
information retrieval (IR) point of view by 
locating the most relevant documents from the 
collection and then extracting the sentences most 
relevant to the query from the documents just 
located. The systems relying on this ?bag-of-
words? approach (e.g. [Allan et al, 1999]; 
[Cormack et al, 1999]; [Lin & Chen, 1999]; [Shin 
et al, 1999] and the passage-retrieval run of 
AT&T [Singhal et al, 1999]) deal with the 
question without considering its grammatical or 
semantic characteristics and they apply 
conventional IR techniques to extract the answer.  
Even though the ?bag-of-words? approach was 
commonly used in TREC-8, the systems based on 
this approach were inadequate to handle the short-
string (50-byte) answers. 
 On the contrary, the short string (50-byte) 
participants (e.g. [Breck et al, 1999]; [Ferret et 
al., 1999]; [Hull, 1999]; [Humphreys et al, 1999]; 
[Litkowski, 1999]; [Moldovan et al, 2000]; [Oard 
et al, 1999]; [Singhal et al, 1999]) agreed on the 
importance of applying several natural language 
processing techniques to solve the problem.  
Among these techniques are: part-of-speech 
tagging, shallow parsing, query type identification 
and named entity recognition.  Because the 
number of test documents to be analyzed for each 
query was huge, the majority of the systems in 
this band used the ?bag-of-words? approach as an 
initial step to retrieve the relevant passages that 
contain the possible answer. Another approach to 
the QA problem combines IR techniques with 
Information Extraction (IE) techniques for 
extracting named entities, e.g., [Ogden et al, 
1999]; [Takaki, 1999]; and [Srihari & Li, 1999]. 
A detailed description of the track and the results 
are available at [Voorhees & Tice, 1999]. 
 It is obvious from the increasing number of 
systems participating in TREC-9 and the 
worldwide interest in this research area that 
Question Answering is the most promising 
framework for finding answers to natural 
language questions from a huge amount of textual 
data.  Cardie et al [2000] pointed out that 
building ?open-ended question answering systems 
that allow users to pose questions of any type and 
in any language, without domain restrictions, is 
still beyond the scope of any QA system today? (p. 
180).  Harabagiu et al [2000] indicated that 
advanced tools (such as dialog understanding and 
text mining) are essential for the success of future 
QA systems. Until the advanced tools are 
implemented, she suggested that we keep 
approximating the complexity of Question 
Answering with NLP enhancements of IR and IE 
techniques [Harabagiu et al, 2000]. 
 
 
3 QARAB System 
 
3.1 Overview 
 
In the last decade, the volume of Arabic 
textual data has started growing on the Web and 
Arabic software for browsing the Web is 
improving.  Unfortunately, much of the earlier 
Arabic text available on the Web was posted as 
images, which makes it unsuitable for search or 
processing. As of today, there is an increase in the 
amount of Arabic textual material available on the 
Web in the form of news articles and books.  
 The main goal of the QARAB system is to 
identify text passages that answer a natural 
language question. The task can be summarized as 
follows: Given a set of questions expressed in 
 Arabic, find answers to the questions under the 
following assumptions: 
? The answer exists in a collection of Arabic 
newspaper text extracted from the Al-Raya 
newspaper published in Qatar. 
? The answer does not span through documents 
(i.e. all supporting information for the answer 
lies in one document) 
? The answer is a short passage. 
 
 
The basic QA processing in QARAB is 
composed of three major steps: 
? Processing the input question 
? Retrieving the candidate documents 
(paragraphs) containing answers from the IR 
system 
? Processing each one of the candidate 
documents (paragraphs) in the same way as 
the question is processed and returning 
sentences that may contain the answer. 
 
The QARAB system will be evaluated over a 
wide range of question types provided by Arabic 
users during the testing and the final phases. The 
same users will then assess whether the answers 
produced by the system are satisfactory. 
 
 
3.2 QARAB Structure 
  
The complete QARAB system is depicted in 
Figure 1; it has the following overall structure: 
 
 
3.2.1 The IR System    
 
The IR system, which we are implementing from 
scratch, is based on Salton?s vector space model 
[Salton, 1971]. First, it processes the text 
collection from the Al-Raya newspaper and 
constructs an inverted file system, from which the 
answers to the natural language questions will be 
extracted. The purpose of the IR system is to 
search the document collection to select 
documents containing information relevant to the 
user?s query. 
Implementing the Information Retrieval 
System 
 
Information Retrieval (IR) systems can be 
constructed in many various ways.  Lundquist et 
al. [1999] proposed an Information Retrieval (IR) 
system that can be constructed using a relational 
database management system (RDBMS). Our IR 
system is depicted in Figure 2 and it contains the 
following database relations: 
? ROOT_TABLE (Root_ID, Root) ? to store the 
available distinct roots of the terms extracted 
from the Al-Raya document collection (one 
row per root). 
? STEM_TABLE (Stem_ID, Root_ID, Stem, 
Document_Frequency, IDF) ? to store all 
distinct stems from the document collection.  
The stem frequency in the entire document 
collection and the inverse document 
frequency of each stem are calculated and 
stored (one row per stem). 
? POSTING_TABLE (Posting_ID, Stem_ID, 
Document_ID, Paragraph_ID, Position, 
Length) ? to store all the occurrences of the 
stems extracted from the entire document 
collection (one row per stem).      
? DOCUMENT_TABLE (Document_ID, 
Document_Title, Document_Date, 
Document_Path) ? to store document 
information (one row per document) 
? PARAGRAPH_TABLE (Paragraph_ID, 
Document_ID, Paragraph) ? to store all the 
paragraphs extracted from the document 
collection (one row per paragraph). This 
speeds up the analysis and the processing of 
the relevant passages that might answer to the 
user?s question.  
? QUERY_TABLE (Word, Weight) ? to store 
query information. This includes the original 
query words and the set of expanded words. 
The set of expanded words is obtained by 
extracting the available roots of the original 
query words, finding their equivalent 
Root_ID?s in the ROOT_TABLE, and then 
finding their corresponding terms stored in the 
STEM_TABLE. The weight of each word is 
calculated and stored (one row per word).  
 
 NLP Tools 
Lexicon
Morphology
Analyzer
System
Tokenizer
System
Type Finder
System &
Parsing PNP
System
 Main
 Table
Pronoun
Table
Particle
Table
Noun
Table
Verb
Table
Keyword
Table
Adjective
Table
Propernoun
Table
Category
Table
Product
Table
Time
Table
Political
Location
Natural
Location
Personal
Name
Events
Table
Organization
Table
 
 
 
Figure 1.  System Components 
 
 
3.2.2 The NLP System 
 
The second component of the system (the NLP 
system) shown in Figure 1 was implemented by 
Abuleil [1999] to experiment in building a large 
Arabic lexicon. The NLP system is composed of a 
set of tools to tokenize and tag Arabic text, 
identify some features of the tokens and, most 
important, to identify proper names. The 
following is a description of the overall structure 
and functionality of the NLP system. 
 
 
Figure 2.  Relational Database Information 
Retrieval System 
 
 The tagger was designed to construct a 
comprehensive Arabic lexicon. The system is 
used to parse Arabic words and determine their 
parts of speech (verbs, nouns, particles).  Also it is 
used to figure out the features of each word 
(gender, number, person, tense), mark proper 
nouns in the text and determine their types 
(personal names, locations, organizations, times, 
dates, etc.). 
 The NLP system comprises the following 
modules: 
? The tokenizer, which is used to extract the 
tokens. 
? The type finder, which is used to assign a 
part-of-speech to each token. 
? The feature finder, which is used to determine 
the features of each word.   
? The proper noun phrase parser, which is used 
to mark proper nouns. 
 
The type finder module starts a lexicon lookup 
process for each token. When there is an unknown 
word in the text, the system can apply the proper 
noun phrase parser to tag the word as a proper 
noun. The recognition process occurs in multiple 
stages in which a list of patterns and heuristics 
may be applied to mark the proper noun. When 
the word is tagged as a proper noun, it is added 
automatically to the lexicon with all its possible 
 features. Being able to identify the proper names, 
among other actual entities, in the text is an 
important step in understanding and using the text.  
Unfortunately, this is not a straightforward task in 
Arabic as it is in English and most European 
languages since the uppercase/lowercase 
distinction does not exist in Arabic text. Thus, we 
have to learn more about the common patterns in 
which these entities occur in Arabic contexts.   
 
 
4 The Basic Outline of Processing 
in the IR System 
 
4.1 Document Processing 
 
This step is essential for our system. First, the 
newspaper articles from the Al-Raya newspaper 
are saved in text format using the Arabic Windows 
1256 encoding scheme. This is performed to 
extract all the html tags and to get the pure text 
contents of the articles.  Second, the IR system is 
constructed using the relational database model as 
explained above. This step involves tokenization, 
stop-word removal, root extraction, and term 
weighting. 
 
4.2 Extracting the Root 
 
In general, to extract Arabic roots from their 
words, the stemmer has to process each word in 
the following order [Khoja, 1999]:  
? Removing the Definite Article ?? ?al? 
? Removing the Conjunction Letter ?   ?w? 
? Removing Suffixes  
? Removing Prefixes  
? Pattern Matching  
 
The following example demonstrates the 
whole stemming process applied to the Arabic 
word ?????????  ?wlydrsooha?, which is mapped to 
the complete English sentence ?and they are 
going to study it?. The root of this word can be 
extracted as follows: 
 
(w)-(l)-(y)-drs-(oo)-(ha)      )??)(?(??? -)?( -(?)-(? ) 
 
1. Removing the conjunction letter (w) )?(  
? )??)(?( ???-)?( -(?) 
2. Removing the suffix (ha) )??( , which indicates 
a feminine, singular patient  
? )?(??? -)?(  -(?) 
3. Removing the suffix: (oo) )?( , which indicates 
a masculine third person plural agent  
? )??? -)?  -(?) 
4. Removing the preposition prefix (l) )?(   
 ? )??? -)?  
5. Removing the prefix: (y) )?( , which indicates 
a 3rd person, present tense ? ???   
6. The pattern ??? F9L has the same length as the 
word ??? drs. Then the stemmer detects that 
the word ??? matches the pattern  ????, since 
all the letters of the word match those in the 
pattern (i.e. ?? ?? ? ) 
7. Finally, the stemmer checks the trilateral roots 
table and concludes that the root ??? drs (he 
studied) is a valid root. 
 
 
5 Question Processing in QARAB 
 
Achieving question understanding requires deep 
semantic processing, which is a non-trivial task of 
natural language processing. In fact, Arabic NLP 
does not have solid research at the semantic level. 
Therefore, QARAB uses shallow language 
understanding to process questions and it does not 
attempt to understand the content of the question 
at a deep, semantic level. 
 QARAB treats the incoming question as a 
?bag of words? against which the index file is 
searched to obtain a list of ranked documents that 
possibly contain the answer. The question 
processing begins by performing tokenization to 
extract individual terms. Then, the stop-words are 
removed. The remaining words are tagged for 
part-of-speech in an attempt to highlight the main 
words that should appear in the hypothesized 
answer. The greatest effort should be spent on 
identifying proper names, as they are our best 
guidance to identify the possible answer. The 
interrogative particles that precede the questions 
will determine what types of answers are expected 
as shown in Table 1.  
 
 5.1  Query Expansion 
 
To achieve better search and retrieval results the 
query is expanded to include all the terms (verbs 
and nouns derived from verbs) that occur in the 
index file and have the same roots, which were 
extracted from the original query words. The 
result of the query processing is then passed to the 
IR system to retrieve a ranked list of documents 
that match the terms of the query. 
 
5.2  Query Type 
 
Questions are classified based on a set of known 
?question types?. These question types help us to 
determine the type of processing needed to 
identify and extract the final answer. The QARAB 
system recognizes the following set of question 
types (Table1):   
 
Table 1.  Question Types Processed by the 
QARAB System 
 
Query Starting with Query Type 
?? Who, Whose Person 
??? When Date, Time 
????? ??  What, Which Organization, Product,Event 
??? Where Location (natural,                 political) 
?? How Much, How Many 
Number, Quantity 
 
 There are two other types of question 
particles, namely ??? and ????? (How and Why). 
Although they will form legitimate query 
structures, they require long and procedural 
answers and are beyond the scope of our research. 
It is worth mentioning that the How and the Why 
queries also caused problems for many TREC-8 
participants.  
 
 
5.3  Query Keyword Identification 
 
The remaining words of the query (after removing 
punctuation and stop-words) are tagged for part of 
speech. This process requires using the Type-
Finder  & the Proper Name-Finder system 
implemented by Abuleil [1999]. Verbs, which 
almost always follow clear morphological 
patterns, are the easiest to identify. Nouns, 
especially proper nouns, are considered as our 
best guide to find the expected answer from the 
relevant documents returned by the IR system. 
They have to occur within the selected answer 
passage and must be in the same order as they 
appeared in the original question.   A list of 
keywords to identify personal names, 
organization names, locations, numbers, money 
and dates, has been constructed for Arabic to help 
in identifying proper names.  
 
 
6 Answer Processing in QARAB 
 
The input to the QARAB Answer Generator 
module is a natural language question and a small 
set of ranked documents. The question is first 
processed by tagging all the words. Then the set 
of relevant documents that may contain the 
answer are retrieved by the IR system. In the 
answer generation process, the passages of the 
relevant documents that match (are similar to) the 
query?s ?bag of words? closely are collected for 
further processing. The answer zones usually 
include most of the terms appearing in the original 
query in addition to the proper nouns that should 
appear in the final answer.  The following 
example illustrates the whole process taken by the 
QARAB system to answer a question. 
 
The following document extracted from the 
newspaper Al-Raya published in Qatar was 
processed by the IR system: 
 
 
 ??? ????? ????? ??????? ??????? ????? ???? ??? ??????
 ?????? ??? ?? ????? ??? ????? ????? ???? ???? ??????? ???????
 ???? ??? ??? ????  .???? ?? ????? ???????? ?? ?????????
 ??????? ???? ??????? ?????? ?????????? ?? ??????? ???????
???????. 
? ????? ??????? ?? ???? ???? ?????? ?????? ???? ????? ???? ?
 ??? ??????? ?? ???? ????? ?? . ?????? ????? ?? ?????????
 ???? ????? ?? ????? ??? ??????? ????/??????????? ??? 
 ?????. 
 Translated by ajeeb: www.ajeeb.com 
 
Said the governor of the Kuwaiti central bank is 
sheikh Salem Abd Al-Aziz Al-Sabah yesterday 
that his countries not have her the intention to the 
Kuwaiti dinar devaluation to the restriction from 
the increasing inability in the budget. And 
believed that the dinar devaluation will harm the 
Kuwait economy and her credibility in the 
international exchanges. 
And confirmed the sheikh Salem is that the central 
bank will not reduce the currency value as a 
means to the inability reduction in the budget. 
From it is expected that the inability in a budget 
reaches a year 1998 / 1999 that ends in June is six 
billions dollar. 
  
Assume the user posed the following question to 
QARAB: 
 ?? ?? ????? ????? ??????? ??????? ????? ??? ??? ????? ???
????? ????? ???? ???? ??????? ???? ?? ??? ?????????? 
Translated by ajeeb: www.ajeeb.com 
 
Who he is the governor of the Kuwaiti central 
bank and that believed by that his country not 
have her the intention to the dinar devaluation to 
the restriction from the budget inability? 
 
 
Step 1: The query is processed as shown in 
Table 2 
 
Table 2. Query Processing 
 
Token Stem Part of 
Speech 
Stop 
Word
?? he ?? Pronoun Yes 
????? governor ????? Noun  
????? bank ??? Noun  
??????? central ???? Noun  
??????? Kuwaiti ???? Noun  
? and ? Conjunction Yes 
???? that ???? Pronoun Yes 
??? said ??? Verb  
??? that ??? Particle Yes 
????? his country ???? Noun  
??? not ??? Verb Yes 
????? have ??? Particle Yes 
????? intention ??? Noun  
???? devaluation ??? Noun  
???? value ???? Noun  
???????  dinar ????? Noun  
???? restriction ?? Noun  
?? from ?? Preposition Yes 
??? inability ??? Noun  
????????? budget ??????? Noun  
? ? ? Punctuation Yes 
 
Step 2: QARAB constructs the query as a ?bag 
 of words? and passes it to the IR system  
 
Table 3. Bag of words 
 
????? 
??? 
???? 
???? 
???? 
??? 
??? 
???? 
????? 
?? 
??? 
???????
 
Assume the system returned the following 
document as the top ranked document that closely 
matches the query. 
 
 ?????  ????? ???? ??? ? ????? ????? ??????? ??????? ???
 ???? ???? ???????  ????? ??? ????? ??????????? ??? ?? 
 ??? ???? ???  .????????? ???????? ?? ????? ?? ??????? ????
 ?????????? ?? ??????? ?????? ???? ??????? ???? ??????? 
??????? ???????. 
 ?????? ?????? ???? ???? ?? ????? ??????????? ????? ???? ?? 
?? ???????? ??????? ?? ????  . ????????? ?? ????? ?????? 
???? ????? ?? ????? ??? ??????? ????/???? ??? ??????? 
?????. 
 
Step 3: Determine the expected type of the 
answer 
 
?? ?Who? ? Person Name 
 Step 4: Generating the answer 
 
The Answer Generator looks for keywords that 
might identify a person name using the personal 
names keywords. The input to the Answer 
Generator is the ?bag of words? and the 
paragraphs extracted from the top ranked relevant 
documents. 
 ????? ???? ??? ?????? ??????? ???????  ????? ????? ??? 
 ????? ???? ???? ???????  ??? ????? ??????? ?? ?????? ? 
???  ???? ??? .????????? ???????? ?? ????? ?? ???? ???????
 ?????????? ?? ??????? ?????? ???? ??????? ???? ??????? 
??????? ???????. 
 ?????? ?????? ???? ????  ?? ????? ??????????? ????? ???? ??
 ?? ????? ??? ??????? ?? ???? .????????? ?? ??????????? 
???? ????? ?? ????? ??? ??????? ????/???? ??? ??????? 
?????. 
 
Keywords that might identify personal names: 
 
The keyword ????? sheikh is used to mark an 
Arabic personal name. 
The keyword ??? A?bd is used to mark the 
beginning of a personal name. 
 ?????? ??? ???? ???????? ????? ????? ??????? ??????? 
 ?????? ??? ?? ????? ??? ????? ????? ???? ???? ??????? ???????
???? ??? ??? ???? ???????  .???? ?? ????? ???????? ?? ?????????
??????? ???? ??????? ?????? ?????????? ?? ??????? ??????? . 
 ???? ?? ????? ??????? ?? ???? ???? ?????? ????????? 
 ??? ??????? ?? ???? ????? . ?????? ?????? ????? ?? ?????????
 ???? ????? ?? ????? ??? ??????? ????/?????? ??????? ??? 
 ?????. 
 
The first paragraph has most of the query words 
and the keywords that might identify a personal 
name. Therefore, the first paragraph is returned as 
the potential answer. 
 ????? ???? ??? ?????? ??? ????? ????? ??????? ??????? 
??? ?? ????? ??? ????? ????? ???? ???? ??????? ??????? ?????? 
???? ??? ??? ???? ???????  .???? ?? ????? ???????? ?? ?????????
 ???? ??????? ?????? ?????????? ?? ??????? ??????? ???????. 
 
 
7  Conclusion 
 
We have described an approach to question 
answering system that provides short answers to 
questions expressed in the Arabic language. The 
system utilizes techniques from IR and NLP to 
process a collection of Arabic text documents as 
its primary source of knowledge. An actual 
system named QARAB is implemented and an 
initial ad-hoc analysis seems to be promising. The 
overall success of the system is limited to the 
amount of available tools developed for the 
Arabic language.  Work is undergoing to get 
retrieval integrated into the system and to extend 
the functionality of the NLP system by developing 
more sophisticated algorithms to produce a 
concise answer in a timely manner.  
 
 
References 
 
Abuleil, S., and Evens, M., 1998. ?Discovering 
Lexical Information by Tagging Arabic 
Newspaper Text?, Workshop on Semantic 
Language Processing. COLING-ACL ?98, 
University of Montreal, Montreal, PQ, 
Canada, Aug. 16 1998, pp. 1-7. 
Al-Daimi, K., and Abdel-Amir, M. 1994. ?The 
Syntactic Analysis of Arabic by Machine?. 
Computers and Humanities, Vol. 28, No. 1, 
pp. 29-37. 
Allan, J., Callan, J., Feng, F-F., and Malin D. 
1999. ?INQUERY and TREC-8?. Proceedings 
of the 8th Text REtrieval Conference (TREC-
8), NIST Special Publications 500-246, pp. 
637-645. 
Ask Jeeves. 1996. www.ask.com Site last visited 
 in March 2001. 
Breck, E., Burger, J., Ferro, L., House, D., Light, 
M., and Mani, I. 1999. ?A Sys Called Qanda?. 
Proceedings of the 8th Text REtrieval 
Conference, NIST Special Publications, pp. 
499-507. 
Budzik, J. and Hammond, K. 1999. ?Q&A: A 
System for the Capture, Organization and 
Reuse of Expertise?. Proceedings of the Sixty-
second Annual Meeting of the American 
Society for Information Science. Information 
 Today, Inc., Medford, NJ. Available on the 
Web at 
http://dent.infolab.nwu.edu/infolab/downloads
/papers/paper10061.pdf. Site last visited in 
August 2001. 
Burke, R., Hammond, K., Kulyukin, V., Lytinen, 
S., Tomuro, N., and Schoenberg, S. 1997. 
?Question Answering from Frequently-Asked 
Question Files: Experiences with the FAQ 
Finder System?. AI Magazine, Vol. 18, No.2, 
pp. 57-66. 
Cardie, C., Ng, V., Pierce, D., and Buckley, C. 
2000. ?Examining the Role of Statistical and 
Linguistic Knowledge Sources in a General-
Knowledge Question-Answering System?.  
Proceedings of the Sixth Applied Natural 
Language Processing Conference, pp. 180-
187. 
Cormack, G., Clarke, C., and Kisman, D. 1999. 
?Fast Automatic Passage Ranking (MultiText 
Experiments for TREC-8)?. Proceedings of 
the 8th Text REtrieval Conference (TREC-8), 
NIST Special Publications 500-246, pp. 735-
743. 
Ferret, O., Grau, B., Illouz, G., Jacquemin, C., and 
Masson, N. 1999.  ?QALC - the Question-
Answering Program of the Language and 
Cognition Group at LIMSI-CNRS?. 
Proceedings of the 8th Text REtrieval 
Conference, NIST Special Publications, pp. 
465-475. 
Harabagiu, S., Pasca, M., and Maiorano, S. 2000. 
?Experiments with Open-Domain Textual 
Question Answering?.  Proceedings of 18th 
International Conference on Computational 
Linguistics (COLING-2000), Saarbrucken, 
Germany, pp. 292-298 
Hull, D. 1999. ?Xerox TREC-8 Question 
Answering Track Report?. Proceedings of the 
8thText REtrieval Conference (TREC-8), 
NIST Special Publications 500-246, pp. 743-
751. 
Humphreys, K., Gaizauskas, R., Hepple, M., and 
Sanderson, M. 1999. ?University of Sheffield 
TREC-8 Q & A System?. Proceedings of the 
8th Text REtrieval Conference (TREC-8), 
NIST Special Publications 500-246, pp. 707-
717. 
Jacobs, P., and Rau, L. 1990. ?SCISOR: 
Extracting Information from On-line News?. 
Communications of the ACM, Vol. 33, No.11, 
pp. 88-97. 
Katz, B. 1997. ?From Sentence Processing to 
Information Access on the World Wide Web?. 
Proceedings of the American Association for 
Artificial Intelligence Conference, Spring 
Symposium, NLP for WWW, pp. 77-86. 
Khoja, S. 1999. ?Stemming Arabic Text?.  
Available on the Web at: 
http://www.comp.lancs.ac.uk/computing/users
/khoja/stemmer.ps. Site last visited in March 
2001. 
Kupiec, J. 1993. ?MURAX: A Robust Linguistic 
Approach for Question Answering Using an 
On-line Encyclopedia?. Proceedings of the 
16th Annual Int. ACM SIGIR Conference, pp. 
181-190. 
Lehnert, W. 1978. The Process of Question 
Answering. Lawrence Erlbaum Associates, 
Hillsdale, NJ. 
Lin, C-J, and Chen, H-H. 1999. ?Description of 
Preliminary Results to TREC-8 QA Task?. 
Proceedings of the 8th Text REtrieval 
Conference(TERC-8), NIST Special 
Publications 500-246, pp. 507-513. 
Litkowski, K. 1999.  ?Question-Answering Using 
Semantic Relation Triples?. Proceedings of  
the 8th Text REtrieval Conference (TREC-8), 
NIST Special Publications 500-248, pp. 349-
357 
Lundquist, C., Grossman, D., and Frieder, O. 
1999. "Improving Relevance Feedback in the 
Vector Space Model". Proceedings of 6th 
ACM Annual Conference on Information and 
Knowledge Management (CIKM), pp. 16-23. 
Moldovan, D., Harabagiu, S., Pasca, M., 
Mihalcea, R., Girju, R., Goodrum, R., and 
Rus, V. 2000. ?The Structure and 
Performance of an Open-Domain Question-
Answering System?. Proceedings of the 38th 
Annual Meeting of the Association for 
Computational Linguistics, pp. 563-570. 
Oard, D., Wang, J., Lin, D., and Soboroff, I. 1999. 
?TREC-8 Experiments at Maryland: CLIR, 
QA and Routing?. Proceedings of the 8th Text 
 REtrieval Conference (TERC-8), NIST 
Special Publications 500-246, pp. 623-637. 
Ogden, B., Cowie, J., Ludovik, E. Molina- 
Salgado, H., Nirenburg, S., Sharples, N., and 
Sheremtyeva, S. 1999.  ?CRL's TREC-8 
Systems Cross-Lingual IR, and Q&A?. 
Proceedings of the 8th Text REtrieval 
Conference (TERC-8), NIST Special 
Publications 500-246, pp. 513-523. 
Salton, G. 1971. The SMART Retrieval System 
Experiments in Automatic Document 
Processing. Prentice Hall Inc., Englewood 
Cliffs, NJ. 
Schank, R., and Abelson, R. 1977. Scripts, Plans, 
Goals, and Understanding. Lawrence Erlbaum 
Associates, Hillsdale, NJ. 
Shin, D-H, Kim, Y-H, Kim, S., Eom, J-H, Shin, 
H-J, and Zhang B-T. 1999. ?SCAI TREC-8 
Experiments?. Proceedings of the 8th Text 
REtrieval Conference (TREC-8), NIST 
Special Publications 500-246, pp. 583-591. 
Singhal, A., Abney, S., Bacchiani, M., Collins, 
M., Hindle, D., and  Pereira, F. 1999. ?AT&T 
at TREC-8?.  Proceedings of the 8th Text 
REtrieval Conference, NIST Special 
Publications, pp. 317-331. 
Srihari, R., and Li, W. 1999.  ?Information 
Extraction Supported Question Answering?. 
Proceedings of the 8th Text REtrieval 
Conference (TREC-8), NIST Special 
Publications 500-246, pp. 185-197. 
Takaki, T. 1999. ?NTT DATA: Overview of  
System Approach at TREC-8 ad-hoc and 
Question Answering?. Proceedings of the 8th 
Text REtrieval Conference (TREC-8), NIST 
Special Publications 500-246, pp. 523-531. 
TREC-8. 1999. NIST Special Publication 500- 
246: The Eighth Text REtrieval Conference. 
Available on the Web at: 
http://trec.nist.gov/pubs/trec8/t8_proceedings.
html. Site last visited in August 2001. 
TREC-9. 2000. NIST Special Publication: The 
Ninth Text REtrieval Conference. Available 
on the Web at: 
http://trec.nist.gov/pubs/trec9/t9_proceedings.
html. Site last visited in August 2001. 
Vicedo, J., and Ferr?ndez, A. 2000. ?Importance 
of Pronominal Anaphora Resolution in 
Question- Answering System?. Proceedings 
of the 38th Annual Meeting of the Association 
for Computational Linguistics, pp. 555-562. 
Voorhees, E., and Tice, D. 1999. "The TREC-8 
Question Answering Track Evaluation". 
Proceedings of the 8th Text REtrieval 
Conference (TREC-8), NIST Special 
Publication 500-246, pp. 83-106. 
Voorhees, E., and Tice, D. 2000. ?Building a 
Question Answering Test Collection?. 
Proceedings of the 23rd Annual International 
ACM SIGIR Conference on Research and 
Development in Information Retrieval, 
Athens, Greece, pp. 200-207. 
Winograd, T. 1972. Understanding Natural 
Language. Academic Press, New York, NY. 
Woods, W., Kaplan, R., and Webber, B. 1972. 
?The Lunar Sciences Natural Language 
Information System: Final Report?. Bolt 
Beranek and Newman Inc. (BBN), Report No. 
2378.  
 
 
 
