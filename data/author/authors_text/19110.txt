Proceedings of NAACL-HLT 2013, pages 524?528,
Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational Linguistics
Creating Reverse Bilingual Dictionaries
Khang Nhut Lam
Department of Computer Science
University of Colorado
Colorado Springs, USA
klam2@uccs.edu
Jugal Kalita
Department of Computer Science
University of Colorado
Colorado Springs, USA
jkalita@uccs.edu
Abstract
Bilingual dictionaries are expensive resources
and not many are available when one of the
languages is resource-poor. In this paper, we
propose algorithms for creation of new reverse
bilingual dictionaries from existing bilingual
dictionaries in which English is one of the two
languages. Our algorithms exploit the simi-
larity between word-concept pairs using the
English Wordnet to produce reverse dictionary
entries. Since our algorithms rely on available
bilingual dictionaries, they are applicable to
any bilingual dictionary as long as one of the
two languages has Wordnet type lexical ontol-
ogy.
1 Introduction
The Ethnologue organization1 lists 6,809 distinct
languages in the world, most of which are resource-
poor. Most existing online bilingual dictionaries are
between two resource-rich languages (e.g., English,
Spanish, French or German) or between a resource-
rich language and a resource-poor language. There
are languages for which we are lucky to find a single
bilingual dictionary online. For example, the Uni-
versity of Chicago hosts bilingual dictionaries from
29 Southeast Asian languages2, but many of these
languages have only one bilingual dictionary online.
Existing algorithms for creating new bilingual
dictionaries use intermediate languages or interme-
diate dictionaries to find chains of words with the
same meaning. For example, (Gollins and Sander-
son, 2001) use lexical triangulation to translate in
parallel across multiple intermediate languages and
1http://www.ethnologue.com/
2http://dsal.uchicago.edu/dictionaries/list.html
fuse the results. They query several existing dictio-
naries and then merge results to maximize accuracy.
They use four pivot languages, German, Spanish,
Dutch and Italian, as intermediate languages. An-
other existing approach for creating bilingual dictio-
naries is using probabilistic inference (Mausam et
al., 2010). They organize dictionaries in a graph
topology and use random walks and probabilistic
graph sampling. (Shaw et al, 2011) propose a set
of algorithms to create a reverse dictionary in the
context of single language by using converse map-
ping. In particular, given an English-English dictio-
nary, they attempt to find the original words or terms
given a synonymous word or phrase describing the
meaning of a word.
The goal of this research is to study the feasibility
of creating a reverse dictionary by using only one ex-
isting dictionary and Wordnet lexical ontology. For
example, given a Karbi3-English dictionary, we will
construct an ENG-AJZ dictionary. The remainder of
this paper is organized as follows. In Section 2, we
discuss the nature of bilingual dictionaries. Section
3 describes the algorithms we propose to create new
bilingual dictionaries from existing dictionaries. Re-
sults of our experiments are presented in Section 4.
Section 5 concludes the paper.
2 Existing Online Bilingual Dictionaries
Powerful online translators developed by Google
and Bing provide pairwise translations (including
for individual words) for 65 and 40 languages, re-
spectively. Wiktionary, a dictionary created by vol-
unteers, supports over 170 languages. We find a
3Karbi is an endangered language spoken by 492,000 peo-
ple (2007 Ethnologue data) in Northeast India, ISO 639-3 code
AJZ. ISO 693-3 code for English is ENG.
524
large number of bilingual dictionaries at PanLex4
including an ENG-Hindi5 and a Vietnamese6-ENG
dictionary. The University of Chicago has a number
of bilingual dictionaries for South Asian languages.
Xobdo7 has a number of dictionaries, focused on
Northeast India.
We classify the many freely available dictionaries
into three main kinds.
? Word to word dictionaries: These are dictionar-
ies that translate one word in one language to
one word or a phrase in another language. An
example is an ENG-HIN dictionary at Panlex.
? Definition dictionaries: One word in one lan-
guage has one or more meanings in the second
language. It also may have pronunciation, parts
of speech, synonyms and examples. An exam-
ple is the VIE-ENG dictionary, also at Panlex.
? One language dictionaries: A dictionary of this
kind is found at dictionary.com.
We have examined several hundred online dictionar-
ies and found that they occur in many different for-
mats. Extracting information from these dictionaries
is arduous. We have experimented with five existing
bilingual dictionaries: VIE-ENG, ENG-HIN, and a
dictionary supported by Xobdo with 4 languages:
Assamese8, ENG, AJZ, and Dimasa9. We consider
the last one to be a collection of 3 bilingual dictio-
naries: ASM-ENG, AJZ-ENG, and DIS-ENG. We
choose these languages since one of our goals is to
work with resource-poor languages to enhance the
quantity and quality of resources available.
3 Proposed Solution Approach
A dictionary entry, called LexicalEntry, is a 2-tuple
<LexicalUnit, Definition>. A LexicalUnit is a
word or a phrase being defined, also called definien-
dum (Landau, 1984). A list of entries sorted by
the LexicalUnit is called a lexicon or a dictionary.
Given a LexicalUnit, the Definition associated with
it usually contains its class and pronunciation, its
4http://panlex.org/
5ISO 693-3 code HIN
6ISO 693-3 code VIE
7http://www.xobdo.org/
8Assamese is an Indo-European language spoken by about
30 million people, but it is resource-poor, ISO 693-3 code ASM.
9Dimasa is another endangered language from Northeast In-
dia, spoken by about 115,000 people, ISO 693-3 code DIS.
meaning, and possibly additional information. The
meaning associated with it can have several Senses.
A Sense is a discrete representation of a single aspect
of the meaning of a word. Thus, a dictionary entry
is of the form <LexicalUnit, Sense1, Sense2, ? ? ?>.
In this section, we propose a series of algorithms,
each one of which automatically creates a reverse
dictionary, or ReverseDictionary, from a dictio-
nary that translates a word in language L1 to a word
or phrase in language L2. We require that at least
one of two these languages has a Wordnet type lexi-
cal ontology (Miller, 1995). Our algorithms are used
to create reverse dictionaries from them at various
levels of accuracy and sophistication.
3.1 Direct Reversal (DR)
The existing dictionary has alphabetically sorted
LexicalUnits in L1 and each of them has one or
more Senses in L2. To create ReverseDictionary,
we simply take every pair <LexicalUnit, Sense>
in SourceDictionary and swap the positions of the
two.
Algorithm 1 DR Algorithm
ReverseDictionary := ?
for allLexicalEntryi ? SourceDictionary do
for all Sensej ? LexicalEntryi do
Add tuple <Sensej ,
LexicalEntryi.LexicalUnit> to
ReverseDictionary
end for
end for
This is a baseline algorithm so that we can com-
pare improvements as we create new algorithms.
If in our input dictionary, the sense definitions
are mostly single words, and occasionally a sim-
ple phrase, even such a simple algorithm gives
fairly good results. In case there are long or com-
plex phrases in senses, we skip them. The ap-
proach is easy to implement, and produces a high-
accuracy ReverseDictionary. However, the num-
ber of entries in the created dictionaries are lim-
ited because this algorithm just swaps the posi-
tions of LexicalUnit and Sense of each entry in the
SourceDictionary and does not have any method
to find the additional words having the same mean-
ings.
525
3.2 Direct Reversal with Distance (DRwD)
To increase the number of entries in the output dic-
tionary, we compute the distance between words
in the Wordnet hierarchy. For example, the words
"hasta-lipi" and "likhavat" in HIN have the meanings
"handwriting" and "script", respectively. The dis-
tance between "handwriting" and "script" in Word-
net hierarchy is 0.0, so that "handwriting" and
"script" likely have the same meaning. Thus, each of
"hasta-lipi" and "likhavat" should have both mean-
ings "handwriting" and "script". This approach
helps us find additional words having the same
meanings and possibly increase the number of lexi-
cal entries in the reverse dictionaries.
To create a ReverseDictionary, for every
LexicalEntryi in the existing dictionary,
we find all LexicalEntryj , i 6= j with dis-
tance to LexicalEntryi equal to or smaller
than a threshold ?. As results, we have new
pairs of entries <LexicalEntryi.LexicalUnit,
LexicalEntryj .Sense> ; then we swap positions
in the two-tuples, and add them into the Reverse-
Dictionary. The value of ? affects the number of
entries and the quality of created dictionaries. The
greater the value of ?, the larger the number of
lexical entries, but the smaller the accuracy of the
ReverseDictionary.
The distance between the two LexicalEntrys is the
distance between the two LexicalUnits if the Lexi-
calUnits occur in Wordnet ontology; otherwise, it is
the distance between the two Senses. The distance
between each phrase pair is the average of the to-
tal distances between every word pair in the phrases
(Wu and Palmer, 1994). If the distance between two
words or phrases is 1.00, there is no similarity be-
tween these words or phrases, but if they have the
same meaning, the distance is 0.00.
We find that aReverseDictionary created using
the value 0.0 for ? has the highest accuracy. This ap-
proach significantly increases the number of entries
in the ReverseDictionary. However, there is an is-
sue in this approach. For instance, the word "tuhbi"
in DIS means "crowded", "compact", "dense", or
"packed". Because the distance between the En-
glish words "slow" and "dense" in Wordnet is 0.0,
this algorithm concludes that "slow" has the mean-
ing "tuhbi" also, which is wrong.
Algorithm 2 DRwD Algorithm
ReverseDictionary := ?
for allLexicalEntryi ? SourceDictionary do
for all Sensej ? LexicalEntryi do
for all LexicalEntryu ?
SourceDictionary do
for all Sensev ? LexicalEntryu do
if distance(<LexicalEntryi.LexicalUnit,
Sensej> ,<LexicalEntryu.LexicalUnit,
Sensev> ) 6 ? then
Add tuple <Sensej ,
LexicalEntryu.LexicalUnit>
to ReverseDictionary
end if
end for
end for
end for
end for
3.3 Direct Reversal with Similarly (DRwS)
The DRwD approach computes simply the dis-
tance between two senses, but does not look at
the meanings of the senses in any depth. The
DRwS approach represents a concept in terms of
its Wordnet synset10, synonyms, hyponyms and
hypernyms. This approach is like the DRwD
approach, but instead of computing the distance
between lexical entries in each pair, we calcu-
late the similarity, called simValue. If the sim-
Value of a <LexicalEntryi,LexicalEntryj>, i 6=
j pair is equal or larger than ?, we conclude
that the LexicalEntryi has the same meaning as
LexicalEntryj .
To calculate simValue between two phrases, we
obtain the ExpansionSet for every word in each
phrase from the WordNet database. An Expansion-
Set of a phrase is a union of synset, and/or synonym,
and/or hyponym, and/or hypernym of every word in
it. We compare the similarity between the Expan-
sionSets. The value of ? and the kinds of Expan-
sionSets are changed to create different ReverseDic-
tionarys. Based on experiments, we find that the best
value of ? is 0.9, and the best ExpansionSet is the
union of synset, synonyms, hyponyms, and hyper-
nyms. The algorithm for computing the simValue of
entries is shown in Algorithm 3.
10Synset is a set of cognitive synonyms.
526
Algorithm 3 simValue(LexicalEntryi,
LexicalEntryj)
simWords := ?
if LexicalEntryi.LexicalUnit &
LexicalEntryj .LexicalUnit have a Word-
net lexical ontology then
for all (LexicalUnitu ? LexicalEntryi) &
(LexicalUnitv ? LexicalEntryj) do
Find ExpansionSet of every
LexicalEntry based on LexicalUnit
end for
else
for all (Senseu ? LexicalEntryi) &
(Sensev ? LexicalEntryj) do
Find ExpansionSet of every
LexicalEntry based on Sense
end for
end if
simWords ? ExpansionSet (LexicalEntryi) ?
ExpansionSet(LexicalEntryj)
n?ExpansionSet(LexicalEntryi).length
m?ExpansionSet(LexicalEntryj).length
simValue?min{ simWords.lengthn ,
simWords.length
m }
4 Experimental results
The goals of our study are to create the high-
precision reverse dictionaries, and to increase the
numbers of lexical entries in the created dictio-
naries. Evaluations were performed by volunteers
who are fluent in both source and destination lan-
guages. To achieve reliable judgment, we use the
same set of 100 non-stop word ENG words, ran-
domly chosen from a list of the most common
words11. We pick randomly 50 words from each
created ReverseDictionary for evaluation. Each
volunteer was requested to evaluate using a 5-point
scale, 5: excellent, 4: good, 3: average, 2: fair, and
1: bad. The average scores of entries in the Reverse-
Dictionarys is presented in Figure 1. The DRwS dic-
tionaries are the best in each case. The percentage of
agreements between raters is in all cases is around
70%.
The dictionaries we work with frequently have
several meanings for a word. Some of these mean-
ings are unusual, rare or very infrequently used. The
11http://www.world-english.org/english500.htm
DR algorithm creates entries for the rare or unusual
meanings by direct reversal. We noticed that our
evaluators do not like such entries in the reversed
dictionaries and mark them low. This results in
lower average scores in the DR algorithm compar-
ing to averages cores in the DRwS algorithm. The
DRwS algorithm seems to have removed a number
of such unusual or rare meanings (and entries simi-
lar to the rare meanings, recursively) improving the
average score
Our proposed approaches do not work well for
dictionaries containing an abundance of complex
phrases. The original dictionaries, except the VIE-
ENG dictionary, do not contain many long phrases
or complex words. In Vietnamese, most words
we find in the dictionary can be considered com-
pound words composed of simpler words put to-
gether. However, the component words are sepa-
rated by space. For example, "b?i th?n gi?o" means
"idolatry". The component words are "b?i" mean-
ing "bow low"; "th?n" meaning "deity"; and "gi?o"
meaning "lance", "spear", "to teach", or "to edu-
cate". The presence of a large number of compound
words written in this manner causes problems with
the ENG-VIE dictionary. If we look closely at Fig-
ure 1, all language pairs, except ENG-VIE show
substantial improvement in score when we compare
the DR algorithm with DRwS algorithm.
Figure 1: Average entry score in ReverseDictionary
The DRwD approach significantly increases the
number of entries, but the accuracy of the created
dictionaries is much lower. The DRwS approach us-
ing a union of synset, synonyms, hyponyms, and hy-
pernyms of words, and ? ? 0.9 produces the best re-
verse dictionaries for each language pair. The DRwS
approach increases the number of entries in the cre-
ated dictionaries compared to the DR algorithm as
527
shown in Figure 2.
Figure 2: Number of lexical entries in
ReverseDictionarys generated from 100 common
words
We also create the entire reverse dictionary for
the AJZ-ENG dictionary. The total number of en-
tries in the ENG-AJZ dictionaries created by us-
ing the DR algorithm and DRwS algorithm are
4677 and 5941, respectively. Then, we pick 100
random words from the ENG-AJZ created by us-
ing the DRwS algorithm for evaluation. The av-
erage score of every entry in this created dictio-
nary is 4.07. Some of the reversal bilingual dictio-
naries can be downloaded at http://cs.uccs.edu/ lin-
clab/creatingBilingualLexicalResource.html.
5 Conclusion
We proposed approaches to create a reverse dic-
tionary from an existing bilingual dictionary using
Wordnet. We show that a high precision reverse dic-
tionary can be created without using any other inter-
mediate dictionaries or languages. Using the Word-
net hierarchy increases the number of entries in the
created dictionaries. We perform experiments with
several resource-poor languages including two that
are in the UNESCO?s list of endangered languages.
Acknowledgements
We would like to thank the volunteers evaluating
the dictionaries we create: Morningkeey Phangcho,
Dharamsing Teron, Navanath Saharia, Arnab Phon-
glosa, Abhijit Bendale, and Lalit Prithviraj Jain. We
also thank all friends in the Xobdo project who pro-
vided us with the ASM-ENG-DIS-AJZ dictionaries.
References
Mausam, S. Soderlan, O. Etzioni, D.S. Weld, K. Reiter,
M. Skinner, M. Sammer, and J. Bilmers 2010. Pan-
lingual lexical translation via probabilistic inference,
Artificial Intelligence, 174:619?637.
R. Shaw, A. Datta, D. VanderMeer, and K. Datta 2011.
Building a scalable database - Driven Reverse Dic-
tionary, IEEE Transactions on Knowledge and Data
Engineering, volume 99.
T. Gollins and M. Sanderson. 2001. Improving cross lan-
guage information retrieval with triangulated transla-
tion, SIGIR ?01 Proceedings of the 24th annual in-
ternational ACM SIGIR conference on Research and
development in information retrieval, New York, 90?
95.
S.I. Landau. 1984. Dictionaries, Cambridge Univ Press.
G.A. Miller. 1995. Wordnet: a lexical database
for English, Communications of the ACM, vol-
ume 38(11):39?41.
Z. Wu and P. Palmer. 1994. Verbs semantics and lexical
selection, In proceeding of the 32nd annual meeting
on Association for computaional linguistics, Strouds-
burg, 133?138.
528
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 106?111,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Automatically constructing Wordnet synsets
Khang Nhut Lam, Feras Al Tarouti and Jugal Kalita
Computer Science department
University of Colorado
1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918, USA
{klam2,faltarou,jkalita}@uccs.edu
Abstract
Manually constructing a Wordnet is a dif-
ficult task, needing years of experts? time.
As a first step to automatically construct
full Wordnets, we propose approaches to
generate Wordnet synsets for languages
both resource-rich and resource-poor, us-
ing publicly available Wordnets, a ma-
chine translator and/or a single bilin-
gual dictionary. Our algorithms translate
synsets of existing Wordnets to a target
language T, then apply a ranking method
on the translation candidates to find best
translations in T. Our approaches are ap-
plicable to any language which has at least
one existing bilingual dictionary translat-
ing from English to it.
1 Introduction
Wordnets are intricate and substantive reposito-
ries of lexical knowledge and have become im-
portant resources for computational processing of
natural languages and for information retrieval.
Good quality Wordnets are available only for a
few "resource-rich" languages such as English and
Japanese. Published approaches to automatically
build new Wordnets are manual or semi-automatic
and can be used only for languages that already
possess some lexical resources.
The Princeton Wordnet (PWN) (Fellbaum,
1998) was painstakingly constructed manually
over many decades. Wordnets, except the PWN,
have been usually constructed by one of two ap-
proaches. The first approach translates the PWN
to T (Bilgin et al, 2004), (Barbu and Mititelu,
2005), (Kaji and Watanabe, 2006), (Sagot and
Fi?er, 2008), (Saveski and Trajkovsk, 2010) and
(Oliver and Climent, 2012); while the second ap-
proach builds a Wordnet in T, and then aligns
it with the PWN by generating translations (Gu-
nawan and Saputra, 2010). In terms of popular-
ity, the first approach dominates over the second
approach. Wordnets generated using the second
approach have different structures from the PWN;
however, the complex agglutinative morphology,
culture specific meanings and usages of words and
phrases of target languages can be maintained. In
contrast, Wordnets created using the first approach
have the same structure as the PWN.
One of our goals is to automatically gener-
ate high quality synsets, each of which is a set
of cognitive synonyms, for Wordnets having the
same structure as the PWN in several languages.
Therefore, we use the first approach to construct
Wordnets. This paper discusses the first step of a
project to automatically build core Wordnets for
languages with low amounts of resources (viz.,
Arabic and Vietnamese), resource-poor languages
(viz., Assamese) or endangered languages (viz.,
Dimasa and Karbi)
1
. The sizes and the qualities
of freely existing resources, if any, for these lan-
guages vary, but are not usually high. Hence, our
second goal is to use a limited number of freely
available resources in the target languages as in-
put to our algorithms to ensure that our methods
can be felicitously used with languages that lack
much resource. In addition, our approaches need
to have a capability to reduce noise coming from
the existing resources that we use. For transla-
tion, we use a free machine translator (MT) and
restrict ourselves to using it as the only "dictio-
nary" we can have. For research purposes, we have
obtained free access to the Microsoft Translator,
which supports translations among 44 languages.
In particular, given public Wordnets aligned to the
PWN ( such as the FinnWordNet (FWN) (Lind?n,
2010) and the JapaneseWordNet (JWN) (Isahara et
al., 2008) ) and the Microsoft Translator, we build
Wordnet synsets for arb, asm, dis, ajz and vie.
1
ISO 693-3 codes of Arabic, Assamese, Dimasa, Karbi
and Vietnamese are arb, asm, dis, ajz and vie, respectively.
106
2 Proposed approaches
In this section, we propose approaches to create
Wordnet synsets for a target languages T using ex-
isting Wordnets and the MT and/or a single bilin-
gual dictionary. We take advantage of the fact
that every synset in PWN has a unique offset-POS,
referring to the offset for a synset with a partic-
ular part-of-speech (POS) from the beginning of
its data file. Each synset may have one or more
words, each of which may be in one or more
synsets. Words in a synset have the same sense.
The basic idea is to extract corresponding synsets
for each offset-POS from existing Wordnets linked
to PWN, in several languages. Next, we translate
extracted synsets in each language to T to produce
so-called synset candidates using MT. Then, we
apply a ranking method on these candidates to find
the correct words for a specific offset-POS in T.
2.1 Generating synset candidates
We propose three approaches to generate synset
candidates for each offset-POS in T.
2.1.1 The direct translation (DR) approach
The first approach directly translates synsets in
PWN to T as in Figure 1.
Figure 1: The DR approach to construct Wordnet
synsets in a target language T.
For each offset-POS, we extract words in that
synset from the PWN and translate them to the tar-
get language to generate translation candidates.
2.1.2 Approach using intermediate Wordnets
(IW)
To handle ambiguities in synset translation, we
propose the IW approach as in Figure 2. Publicly
available Wordnets in various languages, which
we call intermediate Wordnets, are used as re-
sources to create synsets for Wordnets. For each
offset-POS, we extract its corresponding synsets
from intermediate Wordnets. Then, the extracted
synsets, which are in different languages, are
translated to T using MT to generate synset candi-
dates. Depending on which Wordnets are used and
the number of intermediate Wordnets, the num-
ber of candidates in each synset and the number
of synsets in the new Wordnets change.
Figure 2: The IW approach to construct Wordnet
synsets in a target language T
2.1.3 Approach using intermediate Wordnets
and a dictionary (IWND)
The IW approach for creating Wordnet synsets de-
creases ambiguities in translations. However, we
need more than one bilingual dictionary from each
intermediate languages to T. Such dictionaries are
not always available for many languages, espe-
cially the ones that are resource poor. The IWND
approach is like the IW approach, but instead of
translating immediately from the intermediate lan-
guages to the target language, we translate synsets
extracted from intermediate Wordnets to English
(eng), then translate them to the target language.
The IWND approach is presented in Figure 3.
Figure 3: The IWND approach to construct Word-
net synsets
107
2.2 Ranking method
For each of offset-POS, we have many translation
candidates. A translation candidate with a higher
rank is more likely to become a word belonging to
the corresponding offset-POS of the new Wordnet
in the target language. Candidates having the same
ranks are treated similarly. The rank value in the
range 0.00 to 1.00. The rank of a word w, the so-
called rank
w
, is computed as below.
rank
w
=
occur
w
numCandidates
?
numDstWordnets
numWordnets
where:
- numCandidates is the total number of trans-
lation candidates of an offset-POS
- occur
w
is the occurrence count of the word w
in the numCandidates
- numWordnets is the number of intermediate
Wordnets used, and
- numDstWordnets is the number of distinct in-
termediate Wordnets that have words trans-
lated to the word w in the target language.
Our motivation for this rank formula is the fol-
lowing. If a candidate has a higher occurrence
count, it has a greater chance to become a cor-
rect translation. Therefore, the occurrence count
of each candidate needs to be taken into account.
We normalize the occurrence count of a word by
dividing it by numCandidates. In addition, if a
candidate is translated from different words hav-
ing the same sense in different languages, this can-
didate is more likely to be a correct translation.
Hence, we multiply the first fraction by numDst-
Wordnets. To normalize, we divide results by the
number of intermediate Wordnet used.
For instance, in our experiments we use 4 in-
termediate Wordnets, viz., PWN, FWN, JWN and
WOLF Wordnet (WWN) (Sagot and Fi?er, 2008).
The words in the offset-POS "00006802-v" ob-
tained from all 4 Wordnets, their translations to
arb, the occurrence count and the rank of each
translation are presented in the second, the fourth
and the fifth columns, respectively, of Figure 4.
2.3 Selecting candidates based on ranks
We separate candidates based on three cases as be-
low.
Case 1: A candidate w has the highest chance
to become a correct word belonging to a specific
synset in the target language if its rank is 1.0. This
means that all intermediate Wordnets contain the
synset having a specific offset-POS and all words
belonging to these synsets are translated to the
Figure 4: Example of calculating the ranks of
candidates translated from words belonging to the
offset-POS "00006802-v" in 4 Wordnets: PWN,
FWN, JWN and WWN. The word
A
, word
B
and
word
C
are obtained from PWN, FWN and WWN,
respectively. The JWN does not contain this offset-
POS. TL presents transliterations of the words in
arb. The numWordnets is 4 and the numCandi-
dates is 7. The rank of each candidate is shown in
the last column of Figure 4.
same word w. The more the number of intermedi-
ate Wordnets used, the higher the chance the can-
didate with the rank of 1.0 has to become the cor-
rect translation. Therefore, we accept all transla-
tions that satisfy this criterion. An example of this
scenario is presented in Figure 5.
Figure 5: Example of Case 1: Using the IW ap-
proach with four intermediate Wordnets, PWN,
FWN, JWN and WWN. All words belonging to
the offSet-POS "00952615-n" in all 4 Wordnets are
translated to the same word "?i?n" in vie. The
word "?i?n" is accepted as the correct word be-
longing to the offSet-POS "00952615-n" in the
Vietnamese Wordnet we create.
Case 2: If an offSet-POS does not have candi-
dates having the rank of 1.0, we accept the candi-
dates having the greatest rank. Figure 6 shows the
example of the second scenario.
Case 3: If all candidates of an offSet-POS has
the same rank which is also the greatest rank, we
108
Figure 6: Example of Case 2: Using the IW ap-
proach with three intermediate Wordnets, PWN,
FWN and WWN. For the offSet-POS "01437254-
v", there is no candidate with the rank of 1.0.
The highest rank of the candidates in "vie" is 0.67
which is the word g?i. We accept "g?i" as the cor-
rect word in the offSet-POS "01437254-v" in the
Vietnamese Wordnet we create.
skip these candidates. Table 1 gives an example of
the last scenario.
Wordnet Words Cand. Rank
PWN act h?nh ??ng 0.33
PWN behave ho?t ??ng 0.33
FWN do l?m 0.33
Table 1: Example of Case 3: Using the DR ap-
proach. For the offSet-POS "00010435-v", there
is no candidate with the rank of 1.0. The highest
rank of the candidates in vie is 0.33. All of 3 can-
didates have the rank as same as the highest rank.
Therefore, we do not accept any candidate as the
correct word in the offSet-POS "00010435-v" in
the Vietnamese Wordnet we create.
3 Experiments
3.1 Publicly available Wordnets
The PWN is the oldest and the biggest available
Wordnet. It is also free. Wordnets in many
languages are being constructed and developed
2
.
However, only a few of these Wordnets are of high
quality and free for downloading. The EuroWord-
net (Vossen, 1998) is a multilingual database with
Wordnets in European languages (e.g., Dutch, Ital-
ian and Spanish). The AsianWordnet
3
provides
a platform for building and sharing Wordnets for
Asian languages (e.g., Mongolian, Thai and Viet-
namese). Unfortunately, the progress in building
most of these Wordnets is slow and they are far
from being finished.
2
http://www.globalWordnet.org/gwa/Wordnet_table.html
3
http://www.asianWordnet.org/progress
In our current experiments as mentioned ear-
lier, we use the PWN and other Wordnets linked
to the PWN 3.0 provided by the Open Multilingual
Wordnet
4
project (Bond and Foster, 2013): WWN,
FWN and JWN. Table 2 provides some details of
the Wordnets used.
Wordnet Synsets Core
JWN 57,179 95%
FWN 116,763 100%
PWN 117,659 100%
WWN 59,091 92%
Table 2: The number of synsets in the Wordnets
linked to the PWN 3.0 are obtained from the Open
Multilingual Wordnet, along with the percentage
of synsets covered from the semi-automatically
compiled list of 5,000 "core" word senses in PWN.
Note that synsets which are not linked to the PWN
are not taken into account.
For languages not supported by MT, we use
three additional bilingual dictionaries: two dictio-
naries Dict(eng,ajz) and Dict(eng,dis) provided by
Xobdo
5
; one Dict(eng,asm) created by integrat-
ing two dictionaries Dict(eng,asm) provided by
Xobdo and Panlex
6
. The dictionaries are of vary-
ing qualities and sizes. The total number of entries
in Dict(eng,ajz), Dict(eng,asm) and Dict(eng,dis)
are 4682, 76634 and 6628, respectively.
3.2 Experimental results and discussion
As previously mentioned, our primary goal is to
build high quality synsets for Wordnets in lan-
guages with low amount of resources: ajz, asm,
arb, dis and vie. The number of Wordnet synsets
we create for arb and vie using the DR approach
and the coverage percentage compared to the
PWN synsets are 4813 (4.10%) and 2983 (2.54%),
respectively. The number of synsets for each
Wordnet we create using the IW approach with
different numbers of intermediate Wordnets and
the coverage percentage compared to the PWN
synsets are presented in Table 3.
For the IWND approach, we use all 4 Wordnets
as intermediate resources. The number of Wordnet
synsets we create using the IWND approach are
presented in Table 4. We only construct Wordnet
synsets for ajz, asm and dis using the IWND ap-
4
http://compling.hss.ntu.edu.sg/omw/
5
http://www.xobdo.org/
6
http://panlex.org/
109
App. Lang. WNs Synsets % coverage
IW arb 2 48,245 41.00%
IW vie 2 42,938 36.49%
IW arb 3 61,354 52.15%
IW vie 3 57,439 48.82%
IW arb 4 75,234 63.94%
IW vie 4 72,010 61.20%
Table 3: The number of Wordnet synsets we create
using the IW approach. WNs is the number of in-
termediate Wordnets used: 2: PWN and FWN, 3:
PWN, FWN and JWN and 4: PWN, FWN, JWN
and WWN.
proach because these languages are not supported
by MT.
App. Lang. Synsets % coverage
IWND ajz 21,882 18.60%
IWND arb 70,536 59.95%
IWND asm 43,479 36.95%
IWND dis 24,131 20.51%
IWND vie 42,592 36.20%
Table 4: The number of Wordnets synsets we cre-
ate using the IWND approach.
Finally, we combine all of the Wordnet synsets
we create using different approaches to generate
the final Wordnet synsets. Table 5 presents the fi-
nal number of Wordnet synsets we create and their
coverage percentage.
Lang. Synsets % coverage
ajz 21,882 18.60%
arb 76,322 64.87%
asm 43,479 36.95%
dis 24,131 20.51%
vie 98,210 83.47%
Table 5: The number and the average score of
Wordnets synsets we create.
Evaluations were performed by volunteers who
use the language of the Wordnet as mother tongue.
To achieve reliable judgment, we use the same
set of 500 offSet-POSs, randomly chosen from the
synsets we create. Each volunteer was requested
to evaluate using a 5-point scale ? 5: excellent, 4:
good, 3: average, 2: fair and 1: bad. The aver-
age score of Wordnet synsets for arb, asm and vie
are 3.82, 3.78 and 3.75, respectively. We notice
that the Wordnet synsets generated using the IW
approach with all 4 intermediate Wordnets have
the highest average score: 4.16/5.00 for arb and
4.26/5.00 for vie. We are in the process of finding
volunteers to evaluate the Wordnet synsets for ajz
and dis.
It is difficult to compare Wordnets because the
languages involved in different papers are differ-
ent, the number and quality of input resources vary
and the evaluation methods are not standard. How-
ever, for the sake of completeness, we make an at-
tempt at comparing our results with published pa-
pers. Although our score is not in terms of percent-
age, we obtain the average score of 3.78/5.00 (or
informally and possibly incorrectly, 75.60% preci-
sion) which we believe it is better than 55.30% ob-
tained by (Bond et al, 2008) and 43.20% obtained
by (Charoenporn et al, 2008). In addition, the av-
erage coverage percentage of all Wordnet synsets
we create is 44.85% which is better than 12% in
(Charoenporn et al, 2008) and 33276 synsets ('
28.28%) in (Saveski and Trajkovsk, 2010) .
The previous studies need more than one dic-
tionary to translate between a target language
and intermediate-helper languages. For exam-
ple, to create the JWN, (Bond et al, 2008) needs
the Japanese-Multilingual dictionary, Japanese-
English lexicon and Japanese-English life sci-
ence dictionary. For asm, there are a number
of Dict(eng,asm); to the best of our knowledge
only two online dictionaries, both between eng
and asm, are available. The IWND approach re-
quires only one input dictionary between a pair of
languages. This is a strength of our method.
4 Conclusion and future work
We present approaches to create Wordnet synsets
for languages using available Wordnets, a public
MT and a single bilingual dictionary. We create
Wordnet synsets with good accuracy and high cov-
erage for languages with low resources (arb and
vie), resource-poor (asm) and endangered (ajz and
dis). We believe that our work has the potential
to construct full Wordnets for languages which do
not have many existing resources. We are in the
process of creating a Website where all Wordnet
synsets we create will be available, along with a
user friendly interface to give feedback on individ-
ual entries. We will solicit feedback from commu-
nities that use these languages as mother-tongue.
Our goal is to use this feedback to improve the
quality of the Wordnet synsets. Some of Word-
net synsets we created can be downloaded from
http://cs.uccs.edu/?linclab/projects.html.
110
References
Antoni Oliver and Salvador Climent. 2012. Parallel
corpora for Wordnet construction: Machine trans-
lation vs. automatic sense tagging. In Proceed-
ings of the 13th International Conference on Com-
putational Linguistics and Intelligent Text Process-
ing (CICLing), volume part II, pages 110-121, New
Delhi, India, March.
Beno?t Sagot and Darja Fi?er. 2008. Building a free
French Wordnet from multilingual resources. In
Proceedings of the Ontolex 2008 Workshop, Mar-
rakech, Morocco, May.
Fellbaum, Christiane. 1998. Wordnet: An electronic
lexical database. MIT Press, Cambridge, Mas-
sachusetts, USA.
Francis Bond and Ryan Foster. 2013. Linking and ex-
tending an open multilingual Wordnet. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (ACL), pages 1352?
1362, Sofia, Bulgaria, August.
Francis Bond, Hitoshi Isahara, Kyoko Kanzaki and
Kiyotaka Uchimoto. 2008. Boot-strapping a Word-
net using multiple existing Wordnets. In Proceed-
ings of the 6th International Conference on Lan-
guage Resources and Evaluation (LREC), pages
1619?1624, Genoa, Italy, May.
Eduard Barbu and Verginica Barbu Mititelu. 2005.
Automatic building of Wordnets. In Proceedings of
the International Conference on Recent Advances in
Natural Language Processing (RANLP), Borovets,
Bulgaria, September.
Gunawan and Andy Saputra. 2010. Building synsets
for Indonesian Wordnet with monolingual lexical re-
sources. In Proceedings of the International Confer-
ence on Asian Language Processing (IALP), pages
297?300, Harbin, China, December.
Hiroyuki Kaji and Mariko Watanabe. 2006. Auto-
matic construction of Japanese Wordnet. In Pro-
ceedings of the 5th International Conference on
Language Resources and Evaluation (LREC), pages
1262?1267, Genoa, Italy, May.
Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto,
Masao Utiyama and Kyoko Kanzaki. 2008. De-
velopment of Japanese Wordnet. In Proceedings of
the 6th International Conference on Language Re-
sources and Evaluation (LREC), pages 2420?2423,
Marrakech, Morocco, May.
Krister Lind?n and Laur Carlson. 2010. FinnWordnet -
WordNet p?finska via ?vers?ttning, LexicoNordica.
Nordic Journal of Lexicography, 17:119?140.
Martin Saveski and Igor Trajkovsk. 2010. Automatic
construction of Wordnets by using machine transla-
tion and language modeling. In Proceedings of the
13th Multiconference Information Society, Ljubl-
jana, Slovenia.
Orhan Bilgin, ?zlem ?entino?glu and Kemal Oflazer.
2004. Building a Wordnet for Turkish. Romanian
Journal of Information Science and Technology, 7(1-
2): 163?172.
Piek Vossen. 1998. A multilingual database with lex-
ical semantic networks. Kluwer Academic Publish-
ers, Dordrecht, Netherlands.
Thatsanee Charoenporn, Virach Sornlertlamvanich,
Chumpol Mokarat and Hitoshi Isahara. 2008. Semi-
automatic compilation of Asian Wordnet, In Pro-
ceedings of the 14th Annual Meeting of the Associa-
tion for Natural Language Processing, pages 1041?
1044, Tokyo, Japan.
111
Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 54?62,
Baltimore, Maryland, USA, 26 June 2014.
c?2014 Association for Computational Linguistics
Creating Lexical Resources for Endangered Languages
Khang Nhut Lam, Feras Al Tarouti and Jugal Kalita
Computer Science department
University of Colorado
1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918, USA
{klam2,faltarou,jkalita}@uccs.edu
Abstract
This paper examines approaches to gener-
ate lexical resources for endangered lan-
guages. Our algorithms construct bilin-
gual dictionaries and multilingual the-
sauruses using public Wordnets and a ma-
chine translator (MT). Since our work re-
lies on only one bilingual dictionary be-
tween an endangered language and an ?in-
termediate helper? language, it is applica-
ble to languages that lack many existing
resources.
1 Introduction
Languages around the world are becoming extinct
at a record rate. The Ethnologue organization
1
re-
ports 424 languages as nearly extinct and 203 lan-
guages as dormant, out a total of 7,106 recorded
languages. Many other languages are becoming
endangered, a state which is likely to lead to their
extinction, without determined intervention. Ac-
cording to UNESCO, ?a language is endangered
when its speakers cease to use it, use it in fewer
and fewer domains, use fewer of its registers and
speaking styles, and/or stop passing it on to the
next generation...?. In America, UNESCO reports
134 endangered languages, e.g., Arapaho, Chero-
kee, Cheyenne, Potawatomi and Ute.
One of the hallmarks of a living and thriving
language is the existence and continued produc-
tion of ?printed? (now extended to online pres-
ence) resources such as books, magazines and ed-
ucational materials in addition to oral traditions.
There is some effort afoot to document record and
archive endangered languages. Documentation
may involve creation of dictionaries, thesauruses,
text and speech corpora. One possible way to re-
suscitate these languages is to make them more
easily learnable for the younger generation. To
1
http://www.ethnologue.com/
learn languages and use them well, tools such as
dictionaries and thesauruses are essential. Dictio-
naries are resources that empower the users and
learners of a language. Dictionaries play a more
substantial role than usual for endangered lan-
guages and are ?an instrument of language main-
tenance? (Gippert et al., 2006). Thesauruses are
resources that group words according to similarity
(Kilgarriff, 2003). For speakers and students of an
endangered language, multilingual thesauruses are
also likely to be very helpful.
This study focuses on examining techniques
that leverage existing resources for ?resource-
rich? languages to build lexical resources for low-
resource languages, especially endangered lan-
guages. The only resource we need is a single
available bilingual dictionary translating the given
endangered language to English. First, we create a
reverse dictionary from the input dictionary using
the approach in (Lam and Kalita, 2013). Then, we
generate additional bilingual dictionaries translat-
ing from the given endangered language to sev-
eral additional languages. Finally, we discuss the
first steps to constructing multilingual thesauruses
encompassing endangered and resources-rich lan-
guages. To handle the word sense ambiguity prob-
lems, we exploit Wordnets in several languages.
We experiment with two endangered languages:
Cherokee and Cheyenne, and some resource-rich
languages such as English, Finnish, French and
Japanese
2
. Cherokee is the Iroquoian language
spoken by 16,000 Cherokee people in Oklahoma
and North Carolina. Cheyenne is a Native Ameri-
can language spoken by 2,100 Cheyenne people in
Montana and Oklahoma.
The remainder of this paper is organized as fol-
lows. Dictionaries and thesauruses are introduced
in Section 2. Section 3 discusses related work. In
2
ISO 693-3 codes for Cherokee, Cheyenne, English,
Finnish, French and Japanese are chr, chy, eng, fin, fra and
jpn, respectively.
54
Section 4 and Section 5, we present approaches
for creating new bilingual dictionaries and multi-
lingual thesauruses, respectively. Experiments are
described in Section 6. Section 7 concludes the
paper.
2 Dictionaries vs. Thesauruses
A dictionary or a lexicon is a book (now, in elec-
tronic database formats as well) that consists of a
list of entries sorted by the lexical unit. A lexical
unit is a word or phrase being defined, also called
definiendum. A dictionary entry or a lexical en-
try simply contains a lexical unit and a definition
(Landau, 1984). Given a lexical unit, the defini-
tion associated with it usually contains parts-of-
speech (POS), pronunciations, meanings, exam-
ple sentences showing the use of the source words
and possibly additional information. A monolin-
gual dictionary contains only one language such
as The Oxford English Dictionary
3
while a bilin-
gual dictionary consists of two languages such as
the English-Cheyenne dictionary
4
. A lexical entry
in the bilingual dictionary contains a lexical unit in
a source language and equivalent words or multi-
word expressions in the target language along with
optional additional information. A bilingual dic-
tionary may be unidirectional or bidirectional.
Thesauruses are specialized dictionaries that
store synonyms and antonyms of selected words
in a language. Thus, a thesaurus is a resource
that groups words according to similarity (Kilgar-
riff, 2003). However, a thesaurus is different from
a dictionary. (Roget, 1911) describes the orga-
nizes of words in a thesaurus as ?... not in alpha-
betical order as they are in a dictionary, but ac-
cording to the ideas which they express.... The
idea being given, to find the word, or words, by
which that idea may be most fitly and aptly ex-
pressed. For this purpose, the words and phrases
of the language are here classed, not according to
their sound or their orthography, but strictly ac-
cording to their signification?. Particularly, a the-
saurus contains a set of descriptors, an indexing
language, a classification scheme or a system vo-
cabulary (Soergel, 1974). A thesaurus also con-
sists of relationships among descriptors. Each de-
scriptor is a term, a notation or another string of
symbols used to designate the concept. Examples
3
http://www.oed.com/
4
http://cdkc.edu/cheyennedictionary/index-
english/index.htm
of thesauruses are Roget?s international Thesaurus
(Roget, 2008), the Open Thesaurus
5
or the one at
thesaurus.com.
We believe that the lexical resources we create
are likely to help endangered languages in sev-
eral ways. These can be educational tools for lan-
guage learning within and outside the community
of speakers of the language. The dictionaries and
thesauruses we create can be of help in developing
parsers for these languages, in addition to assisting
machine or human translators to translate rich oral
or possibly limited written traditions of these lan-
guages into other languages. We may be also able
to construct mini pocket dictionaries for travelers
and students.
3 Related work
Previous approaches to create new bilingual dic-
tionaries use intermediate dictionaries to find
chains of words with the same meaning. Then,
several approaches are used to mitigate the ef-
fect of ambiguity. These include consulting the
dictionary in the reverse direction (Tanaka and
Umemura, 1994) and computing ranking scores,
variously called a semantic score (Bond and
Ogura, 2008), an overlapping constraint score, a
similarity score (Paik et al., 2004) and a con-
verse mapping score (Shaw et al., 2013). Other
techniques to handle the ambiguity problem are
merging results from several approaches: merging
candidates from lexical triangulation (Gollins and
Sanderson, 2001), creating a link structure among
words (Ahn and Frampton, 2006) and building
graphs connecting translations of words in sev-
eral languages (Mausam et al., 2010). Researchers
also merge information from several sources such
as bilingual dictionaries and corpora (Otero and
Campos, 2010) or a Wordnet (Istv?n and Shoichi,
2009) and (Lam and Kalita, 2013). Some re-
searchers also extract bilingual dictionaries from
corpora (Ljube?i
?
c and Fi?er, 2011) and (Bouamor
et al., 2013). The primary similarity among these
methods is that either they work with languages
that already possess several lexical resources or
these approaches take advantage of related lan-
guages (that have some lexical resources) by using
such languages as intermediary. The accuracies of
bilingual dictionaries created from several avail-
able dictionaries and Wordnets are usually high.
However, it is expensive to create such original
5
http://www.openthesaurus.de/
55
lexical resources and they do not always exist for
many languages. For instance, we cannot find any
Wordnet for chr or chy. In addition, these exist-
ing approaches can only generate one or just a few
new bilingual dictionaries from at least two exist-
ing bilingual dictionaries.
(Crouch, 1990) clusters documents first using
a complete link clustering algorithm and gener-
ates thesaurus classes or synonym lists based on
user-supplied parameters such as a threshold sim-
ilarity value, number of documents in a cluster,
minimum document frequency and specification
of a class formation method. (Curran and Moens,
2002a) and (Curran and Moens, 2002b) evaluate
performance and efficiency of thesaurus extrac-
tion methods and also propose an approximation
method that provides for better time complexity
with little loss in performance accuracy. (Ram?rez
et al., 2013) develop a multilingual Japanese-
English-Spanish thesaurus using freely available
resources: Wikipedia and Wordnet. They extract
translation tuples from Wikipedia from articles in
these languages, disambiguate them by mapping
to Wordnet senses, and extract a multilingual the-
saurus with a total of 25,375 entries.
One thing to note about all these approaches is
that they are resource hungry. For example, (Lin,
1998) works with a 64-million word English cor-
pus to produce a high quality thesaurus with about
10,000 entries. (Ram?rez et al., 2013) has the en-
tire Wikipedia at their disposal with millions of
articles in three languages, although for experi-
ments they use only about 13,000 articles in total.
When we work with endangered or low-resource
languages, we do not have the luxury of collecting
such big corpora or accessing even a few thousand
articles from Wikipedia or the entire Web. Many
such languages have no or very limited Web pres-
ence. As a result, we have to work with whatever
limited resources are available.
4 Creating new bilingual dictionaries
A dictionary Dict(S,T) between a source language
S and a target language T has a list of entries. Each
entry contains a word s in the source language S,
part-of-speech (POS) and one or more translations
in the target language T. We call such a transla-
tion t. Thus, a dictionary entry is of the form
<s
i
,POS,t
i1
>, <s
i
,POS,t
i2
>, ....
This section examines approaches to create new
bilingual dictionaries for endangered languages
from just one dictionary Dict(S,I), where S is the
endangered source language and I is an ?inter-
mediate helper? language. We require that the
language I has an available Wordnet linked to
the Princeton Wordnet (PWN) (Fellbaum, 1998).
Many endangered languages have a bilingual dic-
tionary, usually to or from a resource-rich lan-
guage like French or English which is the inter-
mediate helper language in our experiments. We
make an assumption that we can find only one uni-
directional bilingual dictionary translating from a
given endangered language to English.
4.1 Generating a reverse bilingual dictionary
Given a unidirectional dictionary Dict(S,I) or
Dict(I,S), we reverse the direction of the entries
to produce Dict(I,S) or Dict(S,I), respectively. We
apply an approach called Direct Reversal with
Similarity (DRwS), proposed in (Lam and Kalita,
2013) to create a reverse bilingual dictionary from
an input dictionary.
The DRwS approach computes the distance be-
tween translations of entries by measuring their se-
mantic similarity, the so-called simValue. The sim-
Value between two phrases is calculated by com-
paring the similarity of the ExpansionSet for ev-
ery word in one phrase with ExpansionSet of ev-
ery word in the other phrase. An ExpansionSet of
a phrase is a union of the synset, synonym set, hy-
ponym set, and/or hypernym set of every word in
it. The synset, synonym, hyponym and hypernym
sets of a word are obtained from PWN. The greater
is the simValue between two phrases, the more se-
mantically similar are these phrases. According to
(Lam and Kalita, 2013), if the simValue is equal to
or greater than 0.9, the DRwS approach produces
the ?best? reverse dictionary.
For creating a reverse dictionary, we skip en-
tries with multiword expression in the translation.
Based on our experiments, we have found that ap-
proach is successful and hence, it may be an effec-
tive way to automatically create a new bilingual
dictionary from an existing one. Figure 1 presents
an example of generating entries for the reverse
dictionary.
4.2 Building bilingual dictionaries to/from
additional languages
We propose an approach using public Word-
nets and MT to create new bilingual dictionaries
Dict(S,T) from an input dictionary Dict(S,I). As
previously mentioned, I is English in our exper-
56
Figure 1: Example of creating entries for a reverse
dictionary Dict(eng,chr) from Dict(chr,eng). The
simValue between the words "ocean" and "sea" is
0.98, which is greater than the threshold of 0.90.
Therefore, the words "ocean" and "sea" in English
are hypothesized to have both meanings "ame-
quohi" and "ustalanali" in Cherokee. We add these
entries to Dict(eng, chr).
iments. Dict(S,T) translates a word in an endan-
gered language S to a word or multiword expres-
sion in a target language T. In particular, we create
bilingual dictionaries for an endangered language
S from a given dictionary Dict(S,eng). Figure 2
presents the approach to create new bilingual dic-
tionaries.
Figure 2: The approach for creating new bilin-
gual dictionaries from intermediate Wordnets and
a MT.
For each entry pair (s,e) in a given dictionary
Dict(S,eng), we find all synonym words of the
word e to create a list of synonym words in En-
glish: SY N
eng
. SY N
eng
of the word eng is
obtained from the PWN. Then, we find all syn-
onyms of words belonging to SY N
eng
in sev-
eral non-English languages to generate SY N
L
,
L ? {fin, fra, jpn}. SY N
L
in the language L is
extracted from the publicly available Wordnet in
language L linked to the PWN. Next, translation
candidates are generated by translating all words
in SY N
L
, L ? {eng, fin, fra, jpn} to the target
language T using an MT. A translation candidate is
considered a correct translation of the source word
in the target language if its rank is greater than a
threshold. For each word s, we may have many
candidates. A translation candidate with a higher
rank is more likely to become a correct translation
in the target language. The rank of a candidate is
computed by dividing its occurrence count by the
total number of candidates. Figure 3 shows an ex-
ample of creating entries for Dict(chr,vie), where
vie is Vietnamese, from Dict(chr,eng).
Figure 3: Example of generating new entries for
Dict(chr,vie) from Dict(chr,eng). The word "ayvt-
seni" in chr is translated to "throat" in eng. We
find all synonym words for "throat" in English to
generate SY N
eng
and all synonyms in fin, fra and
jpn for all words in SY N
eng
. Then, we translate
all words in all SY N
L
s to vie and rank them. Ac-
cording to rank calculations, the best translations
of "ayvtseni" in chr are the words "c? h?ng" and
"h?ng" in vie.
57
5 Constructing thesauruses
As previously mentioned, we want to generate a
multilingual thesaurus THS composed of endan-
gered and resource-rich languages. For example,
we build the thesaurus encompassing an endan-
gered language S and eng, fin, fra and jpn. Our
thesaurus contains a list of entries. Every entry has
a unique ID. Each entry is a 7-tuple: ID, SY N
S
,
SY N
eng
, SY N
fin
, SY N
fra
, SY N
jpn
and POS.
Each SY N
L
contains words that have the same
sense in language L. All SY N
L
, L ? {S, eng, fin,
fra, jpn} with the same ID have the same sense.
This section presents the initial steps in con-
structing multilingual thesauruses using Wordnets
and the bilingual dictionaries we create. The
approach to create a multilingual thesaurus en-
compassing an endangered language and several
resource-rich languages is presented in Figure 4
and Algorithm 1.
Figure 4: The approach to construct a multilingual
thesaurus encompassing an endangered language
S and resource-rich language.
First, we extract SY N
L
in resource-rich lan-
guages from Wordnets. To extract SY N
eng
,
SY N
fin
, SY N
fra
and SY N
jpn
, we use PWN
and Wordnets linked to the PWN provided by
the Open Multilingual Wordnet
6
project (Bond
and Foster, 2013): FinnWordnet (FWN) (Lind?n,
2010), WOLF (WWN) (Sagot and Fi?er, 2008)
and JapaneseWordnet (JWN) (Isahara et al.,
2008). For each Offset-POS, we extract its cor-
responding synsets from PWN, FWN, WWN and
6
http://compling.hss.ntu.edu.sg/omw/
JWN to generate SY N
eng
, SY N
fin
, SY N
fra
and
SY N
jpn
(lines 7-10). The POS of the entry is
the POS extracted from the Offset-POS (line 5).
Since these Wordnets are aligned, a specific offset-
POS retrieves synsets that are equivalent sense-
wise. Then, we translate all SY N
L
s to the given
endangered language S using bilingual dictionar-
ies we created in the previous section (lines 11-
14). Finally, we rank translation candidates and
add the correct translations to SY N
S
(lines 15-
19). The rank of a candidate is computed by di-
viding its occurrence count by the total number of
candidates. If a candidate has a rank value greater
than a threshold, we accept it as a correct transla-
tion and add it to SY N
S
.
Algorithm 1
Input: Endangered language S, PWN, FWN,
WWN, JWN, Dict(eng,S), Dict(fin,S), Dict(fra,S)
and Dict(jpn,S)
Output: thesaurus THS
1: ID:=0
2: for all offset-POSs in PWN do
3: ID++
4: candidates := ?
5: POS=extract(offset-POS)
6: SY N
S
:= ?
7: SY N
eng
=extract(offset-POS, PWN)
8: SY N
fin
=extract(offset-POS, FWN)
9: SY N
fra
=extract(offset-POS, WWN)
10: SY N
jpn
=extract(offset-POS, JWN)
11: candidates+=translate(SY N
eng
,S)
12: candidates+=translate(SY N
fin
,S)
13: candidates+=translate(SY N
fra
,S)
14: candidates+=translate(SY N
jpn
,S)
15: for all candidate in candidates do
16: if rank(candidate) > ? then
17: add(candidate,SY N
S
)
18: end if
19: end for
20: add ID, POS and all SY N
L
into THS
21: end for
Figure 5 presents an example of creating an en-
try for the thesaurus. We generate entries for the
multilingual thesaurus encompassing of Cherokee,
English, Finnish, French and Japanese.
We extract words belonging to offset-POS
"09426788-n" in PWN, FWN, WWN and JWN
and add them into corresponding SY N
L
. The
POS of this entry is "n", which is a "noun".
Next, we use the bilingual dictionaries we cre-
58
Figure 5: Example of generating an entry in the
multilingual thesaurus encompassing Cherokee,
English, Finnish, French and Japanese.
ated to translate all words in SY N
eng
, SY N
fin
,
SY N
fra
, SY N
jpn
to the given endangered lan-
guage, Cherokee, and rank them. According to the
rank calculations, the best Cherokee translation is
the word ?ustalanali?. The new entry added to the
multilingual thesaurus is presented in Figure 6.
Figure 6: An entry of the multilingual thesaurus
encompassing Cherokee, English, Finnish, French
and Japanese.
6 Experimental results
Ideally, evaluation should be performed by volun-
teers who are fluent in both source and destination
languages. However, for evaluating created dic-
tionaries and thesauruses, we could not recruit any
individuals who are experts in two corresponding
languages. We are in the process of finding vol-
unteers who are fluent in both languages for some
selected resources we create.
6.1 Datasets used
We start with two bilingual dictionaries:
Dict(chr,eng)
7
and Dict(chy,eng)
8
that we
obtain from Web pages. These are unidirectional
bilingual dictionaries. The numbers of entries
in Dict(chr,eng) and Dict(chy,eng) are 3,199
and 28,097, respectively. For entries in these
input dictionaries without POS information, our
algorithm chooses the best POS of the English
word, which may lead to wrong translations. The
Microsoft Translator Java API
9
is used as another
main resource. We were given free access to this
API. We could not obtain free access to the API
for the Google Translator.
The synonym lexicons are the synsets of PWN,
FWN, JWN and WWN. Table 1 provides some de-
tails of the Wordnets used.
Wordnet Synsets Core
JWN 57,179 95%
FWN 116,763 100%
PWN 117,659 100%
WWN 59,091 92%
Table 1: The number of synsets in the Wordnets
linked to PWN 3.0 are obtained from the Open
Multilingual Wordnet, along with the percentage
of synsets covered from the semi-automatically
compiled list of 5,000 "core" word senses in PWN.
Note that synsets which are not linked to the PWN
are not taken into account.
6.2 Creating reverse bilingual dictionaries
From Dict(chr,eng) and Dict(chy,eng), we create
two reverse bilingual dictionaries Dict(eng,chr)
with 3,538 entries and Dict(eng,chy) with 28,072
entries
Next, we reverse the reverse dictionaries we
produce to generate new reverse of the reverse
(RR) dictionaries, then integrate the RR dictio-
naries with the input dictionaries to improve the
sizes of dictionaries. During the process of gen-
erating new reverse dictionaries, we already com-
puted the semantic similarity values among words
to find words with the same meanings. We use a
simple approach called the Direct Reversal (DR)
approach in (Lam and Kalita, 2013) to create
7
http://www.manataka.org/page122.html
8
http://www.cdkc.edu/cheyennedictionary/index-
english/index.htm
9
https://datamarket.azure.com/dataset/bing/microsofttranslator
59
these RR dictionaries. To create a reverse dictio-
nary Dict(T,S), the DR approach takes each entry
<s,POS,t> in the input dictionary Dict(S,T) and
simply swaps the positions of s and t. The new
entry <t,POS,s> is added into Dict(T,S). Figure 7
presents an example.
Figure 7: Given a dictionary Dict(chy,eng), we
create a new Dict(eng,chy) using the DRwS ap-
proach of (Lam and Kalita, 2013). Then, we create
a new Dict(chy,eng) using the DR approach from
the created dictionary Dict(eng,chy). Finally, we
integrate the generated dictionary Dict(chy,eng)
with the input dictionary Dict(chy,eng) to create a
new dictionary Dict(chy,eng) with a greater num-
ber of entries
The number of entries in the integrated dictio-
naries Dict(chr,eng) and Dict(chy,eng) are 3,618
and 47,529, respectively. Thus, the number of en-
tries in the original dictionaries have "magically"
increased by 13.1% and 69.21%, respectively.
6.3 Creating additional bilingual dictionaries
We can create dictionaries from chr or chy to
any non-eng language supported by the Microsoft
Translator, e.g., Arabic (arb), Chinese (cht), Cata-
lan (cat), Danish (dan), German (deu), Hmong
Daw (mww), Indonesian (ind), Malay (zlm), Thai
(tha), Spanish (spa) and vie. Table 2 presents the
number of entries in the dictionaries we create.
These dictionaries contain translations only with
the highest ranks for each word.
Although we have not evaluated entries in the
particular dictionaries in Table 1, evaluation of
dictionaries with non-endangered languages, but
using the same approach, we have confidence that
these dictionaries are of acceptable, if not very
good quality.
Dictionary Entries Dictionary Entries
chr-arb 2,623 chr-cat 2,639
chr-cht 2,607 chr-dan 2,655
chr-deu 2,629 chr-mww 2,694
chr-ind 2,580 chr-zlm 2,633
chr-spa 2,607 chr-tha 2,645
chr-vie 2,618 chy-arb 10,604
chy-cat 10,748 chy-cht 10,538
chy-dan 10,654 chy-deu 10,708
chy-mww 10,790 chy-ind 10,434
chy-zlm 10,690 chy-spa 10,580
chy-tha 10,696 chy-vie 10,848
Table 2: The number of entries in some dictionar-
ies we create.
6.4 Creating multilingual thesauruses
We construct two multilingual thesauruses:
THS
1
(chr, eng, fin, fra, jpn) and THS
2
(chy, eng,
fin, fra, jpn). The number of entries in THS
1
and THS
2
are 5,073 and 10,046, respectively.
These thesauruses we construct contain words
with rank values above the average. A similar
approach used to create Wordnet synsets (Lam
et al., 2014) has produced excellent results. We
believe that our thesauruses reported in this paper
are of acceptable quality.
6.5 How to evaluate
Currently, we are not able to evaluate the dictio-
naries and thesauruses we create. In the future, we
expect to evaluate our work using two methods.
First, we will use the standard approach which is
human evaluation to evaluate resources as previ-
ously mentioned. Second, we will try to find an
additional bilingual dictionary translating from an
endangered language S (viz., chr or chy) to another
?resource-rich? non-English language (viz., fin or
fra), then, create a new dictionary translating from
S to English using the approaches we have intro-
duced. We plan to evaluate the new dictionary we
create, say Dict(chr,eng) against the existing dic-
tionary Dict(chr,eng).
7 Conclusion and future work
We examine approaches to create bilingual dictio-
naries and thesauruses for endangered languages
from only one input dictionary, publicly avail-
able Wordnets and an MT. Taking advantage of
available Wordnets linked to the PWN helps re-
duce ambiguities in dictionaries we create. We
60
run experiments with two endangered languages:
Cherokee and Cheyenne. We have also experi-
mented with two additional endangered languages
from Northeast India: Dimasa and Karbi, spo-
ken by about 115,000 and 492,000 people, respec-
tively. We believe that our research has the po-
tential to increase the number of lexical resources
for languages which do not have many existing re-
sources to begin with. We are in the process of
creating reverse dictionaries from bilingual dictio-
naries we have already created. We are also in
the process of creating a Website where all dic-
tionaries and thesauruses we create will be avail-
able, along with a user friendly interface to dis-
seminate these resources to the wider public as
well as to obtain feedback on individual entries.
We will solicit feedback from communities that
use the languages as mother-tongues. Our goal
will be to use this feedback to improve the qual-
ity of the dictionaries and thesauruses. Some of
resources we created can be downloaded from
http://cs.uccs.edu/?linclab/projects.html
References
Adam Kilgarriff. 2003. Thesauruses for natu-
ral language processing. In Proceedings of the
Joint Conference on Natural Language Processing
and Knowledge Engineering, pages 5?13, Beijing,
China, October.
Benoit Sagot and Darja Fi?er. 2008. Building a free
French Wordnet from multilingual resources. In
Proceedings of OntoLex, Marrakech, Morocco.
Carolyn J. Crouch 1990. An approach to the auto-
matic construction of global thesauri, Information
Processing & Management, 26(5): 629?640.
Christiane Fellbaum. 1998. Wordnet: An Electronic
Lexical Database. MIT Press, Cambridge, Mas-
sachusetts, USA.
Dagobert Soergel. 1974. Indexing languages and the-
sauri: construction and maintenance. Melville Pub-
lishing Company, Los Angeles, California.
Dhouha Bouamor, Nasredine Semmar and Pierre
Zweigenbaum. 2013 Using Wordnet and Semantic
Similarity for Bilingual Terminology Mining from
Comparable Corpora. In Proceedings of the 6th
Workshop on Building and Using Comparable Cor-
pora, pages 16?23, Sofia, Bulgaria, August. Associ-
ation for Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and cluster-
ing of similar words. In Proceedings of the 17th In-
ternational Conference on Computational Linguis-
tics (Volume 2), pages 768?774, Montreal, Quebec,
Canada.
Francis Bond and Kentaro Ogura. 2008 Combin-
ing linguistic resources to create a machine-tractable
Japanese-Malay dictionary. Language Resources
and Evaluation, 42(2): 127?136.
Francis Bond and Ryan Foster. 2013. Linking and
extending an open multilingual Wordnet. In Pro-
ceedings of 51st Annual Meeting of the Association
for Computational Linguistics (ACL 2013), pages
1352?1362, Sofia, Bulgaria, August.
Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto,
Masao Utiyama and Kyoko Kanzaki. 2008. De-
velopment of Japanese Wordnet. In Proceedings
of 6th International Conference on Language Re-
sources and Evaluation (LREC 2008), pages 2420?
2423, Marrakech, Moroco, May.
James R. Curran and Marc Moens. 2002a. Scaling
context space. In Proceedings of the 40th Annual
Meeting of Association for Computational Linguis-
tics (ACL 2002), pages 231?238, Philadelphia, USA,
July.
James R. Curran and Marc Moens. 2002b. Improve-
ments in automatic thesaurus extraction, In Pro-
ceedings of the Workshop on Unsupervised lexical
acquisition (Volume 9), pages 59?66, Philadelphia,
USA, July. Association for Computational Linguis-
tics.
Jessica Ram?rez, Masayuki Asahara and Yuji Mat-
sumoto. 2013. Japanese-Spanish thesaurus con-
struction using English as a pivot. arXiv preprint
arXiv:1303.1232.
Jost Gippert, Nikolaus Himmelmann and Ulrike Mosel,
eds. 2006. Essentials of Lnguage Documenta-
tion. Vol. 178, Walter de Gruyter GmbH & Co. KG,
Berlin, Germany.
Khang N. Lam and Jugal Kalita. 2013. Creating re-
verse bilingual dictionaries. In Proceedings of the
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT), pages 524?
528, Atlanta, USA, June.
Khang N. Lam, Feras A. Tarouti and Jugal Kalita.
2014. Automatically constructing Wordnet synsets.
To appear at the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2014),
Baltimore, USA, June.
Kisuh Ahn and Matthew Frampton. 2006. Automatic
generation of translation dictionaries using interme-
diary languages. In Proceedings of the Interna-
tional Workshop on Cross-Language Knowledge In-
duction, pages 41?44, Trento, Italy, April. European
Chapter of the Association for Computational Lin-
guistics.
Krister Lind?n and Lauri Carlson 2010. FinnWordnet -
WordNet p?finska via ?vers?ttning, LexicoNordica.
Nordic Journal of Lexicography (Volume 17), pages
119?140.
61
Kumiko Tanaka and Kyoji Umemura. 1994. Construc-
tion of bilingual dictionary intermediated by a third
language. In Proceedings of the 15th Conference on
Computational linguistics (COLING 1994), Volume
1, pages 297?303, Kyoto, Japan, August. Associa-
tion for Computational Linguistics.
Kyonghee Paik, Satoshi Shirai and Hiromi Nakaiwa.
2004. Automatic construction of a transfer dictio-
nary considering directionality. In Proceedings of
the Workshop on Multilingual Linguistic Resources,
pages 31?38, Geneva, Switzerland, August . Asso-
ciation for Computational Linguistics.
Mausam, Stephen Soderland, Oren Etzioni, Daniel S.
Weld, Kobi Reiter, Michael Skinner, Marcus Sam-
mer and Jeff Bilmes 2010. Panlingual lexical trans-
lation via probabilistic inference. Artificial Intelli-
gence, 174(2010): 619?637.
Nikola Ljube?i?c and Darja Fi?er. 2011. Bootstrap-
ping bilingual lexicons from comparable corpora for
closely related languages. In Proceedings of the
14th International Conference on Text, Speech and
Dialogue (TSD 2011), pages 91?98. Plze?n, Czech
Republic, September.
Pablo G. Otero and Jos? R.P. Campos. 2010. Auto-
matic generation of bilingual dictionaries using in-
termediate languages and comparable corpora. In
Proceedings of the 11th International Conference on
Computational Linguistic and Intelligent Text Pro-
cessing (CICLing?10 ), pages 473?483, Ias?i, Roma-
nia, March.
Peter M. Roget. 1911. Roget?s Thesaurus of English
Words and Phrases.... Thomas Y. Crowell Com-
pany, New York, USA.
Peter M. Roget. 2008. Roget?s International The-
saurus, 3rd Edition. Oxford & IBH Publishing
Company Pvt, New Delhi, India.
Ryan Shaw, Anindya Datta, Debra VanderMeer and
Kaushik Datta. 2013. Building a scalable database
- Driven Reverse Dictionary. IEEE Transactions on
Knowledge and Data Engineering, 25(3): 528?540.
Sidney I. Landau 1984. Dictionaries: the art and
craft of lexicography. Charles Scribner?s Sons, New
York, USA.
Tim Gollins and Mark Sanderson. 2001. Improving
cross language information retrieval with triangu-
lated translation. In Proceedings of the 24th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, pages
90?95, New Orleans, Louisiana, USA, September.
Varga Istv?n and Yokoyama Shoichi. 2009. Bilin-
gual dictionary generation for low-resourced lan-
guage pairs. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language
Processing (Volume 2), pages 862?870, Singapore,
August. Association for Computational Linguistics.
62
