Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 169?176,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Dependency Parsing of Japanese Spoken Monologue
Based on Clause Boundaries
Tomohiro Ohno?a) Shigeki Matsubara? Hideki Kashioka?
Takehiko Maruyama] and Yasuyoshi Inagaki\
?Graduate School of Information Science, Nagoya University, Japan
?Information Technology Center, Nagoya University, Japan
?ATR Spoken Language Communication Research Laboratories, Japan
]The National Institute for Japanese Language, Japan
\Faculty of Information Science and Technology, Aichi Prefectural University, Japan
a)ohno@el.itc.nagoya-u.ac.jp
Abstract
Spoken monologues feature greater sen-
tence length and structural complexity
than do spoken dialogues. To achieve high
parsing performance for spoken mono-
logues, it could prove effective to sim-
plify the structure by dividing a sentence
into suitable language units. This paper
proposes a method for dependency pars-
ing of Japanese monologues based on sen-
tence segmentation. In this method, the
dependency parsing is executed in two
stages: at the clause level and the sen-
tence level. First, the dependencies within
a clause are identified by dividing a sen-
tence into clauses and executing stochastic
dependency parsing for each clause. Next,
the dependencies over clause boundaries
are identified stochastically, and the de-
pendency structure of the entire sentence
is thus completed. An experiment using
a spoken monologue corpus shows this
method to be effective for efficient depen-
dency parsing of Japanese monologue sen-
tences.
1 Introduction
Recently, monologue data such as a lecture and
commentary by a professional have been consid-
ered as human valuable intellectual property and
have gathered attention. In applications, such as
automatic summarization, machine translation and
so on, for using these monologue data as intel-
lectual property effectively and efficiently, it is
necessary not only just to accumulate but also to
structure the monologue data. However, few at-
tempts have been made to parse spoken mono-
logues. Spontaneously spoken monologues in-
clude a lot of grammatically ill-formed linguistic
phenomena such as fillers, hesitations and self-
repairs. In order to robustly deal with their extra-
grammaticality, some techniques for parsing of di-
alogue sentences have been proposed (Core and
Schubert, 1999; Delmonte, 2003; Ohno et al,
2005b). On the other hand, monologues also have
the characteristic feature that a sentence is gen-
erally longer and structurally more complicated
than a sentence in dialogues which have been dealt
with by the previous researches. Therefore, for
a monologue sentence the parsing time would in-
crease and the parsing accuracy would decrease. It
is thought that more effective, high-performance
spoken monologue parsing could be achieved by
dividing a sentence into suitable language units for
simplicity.
This paper proposes a method for dependency
parsing of monologue sentences based on sen-
tence segmentation. The method executes depen-
dency parsing in two stages: at the clause level
and at the sentence level. First, a dependency rela-
tion from one bunsetsu1 to another within a clause
is identified by dividing a sentence into clauses
based on clause boundary detection and then ex-
ecuting stochastic dependency parsing for each
clause. Next, the dependency structure of the en-
tire sentence is completed by identifying the de-
pendencies over clause boundaries stochastically.
An experiment on monologue dependency pars-
ing showed that the parsing time can be drasti-
1A bunsetsu is the linguistic unit in Japanese that roughly
corresponds to a basic phrase in English. A bunsetsu con-
sists of one independent word and more than zero ancillary
words. A dependency is a modification relation in which a
dependent bunsetsu depends on a head bunsetsu. That is, the
dependent bunsetsu and the head bunsetsu work as modifier
and modifyee, respectively.
169
??
???
??
???
??? ????
???
??
????
?????
?
???
????
???
?
????
????
??
?Dependency relation whose dependent bunsetsu is not the last bunsetsu of a clause
?Dependency relation whose dependent bunsetsu is the last bunsetsu of a clause
?Bunsetsu
?Clause boundary
?Clause
The public opinion poll that the Prime Minister?s Office announced the other day indicates that 
the ratio of people advocating capital punishment is nearly 80%
the other
day
that the 
Prime
Minister?s
Office
announced The 
public
opinion
poll
indicates
that
capital
punishment
advocating the ratio 
of people
nearly
80%
is
Figure 1: Relation between clause boundary and
dependency structure
cally shortened and the parsing accuracy can be
increased.
This paper is organized as follows: The next
section describes a parsing unit of Japanese mono-
logue. Section 3 presents dependency parsing
based on clause boundaries. The parsing experi-
ment and the discussion are reported in Sections
4 and 5, respectively. The related works are de-
scribed in Section 6.
2 Parsing Unit of Japanese Monologues
Our method achieves an efficient parsing by adopt-
ing a shorter unit than a sentence as a parsing unit.
Since the search range of a dependency relation
can be narrowed by dividing a long monologue
sentence into small units, we can expect the pars-
ing time to be shortened.
2.1 Clauses and Dependencies
In Japanese, a clause basically contains one verb
phrase. Therefore, a complex sentence or a com-
pound sentence contains one or more clauses.
Moreover, since a clause constitutes a syntacti-
cally sufficient and semantically meaningful lan-
guage unit, it can be used as an alternative parsing
unit to a sentence.
Our proposed method assumes that a sentence
is a sequence of one or more clauses, and every
bunsetsu in a clause, except the final bunsetsu,
depends on another bunsetsu in the same clause.
As an example, the dependency structure of the
Japanese sentence:
????????????????????
?????????????????????
?????????????The public opinion
poll that the Prime Minister?s Office announced
the other day indicates that the ratio of people
advocating capital punishment is nearly 80%)
is presented in Fig. 1. This sentence consists of
four clauses:
? ?????????????? (that the
Prime Minister?s Office announced the other
day)
? ?????????? (The public opinion
poll indicates that)
? ?????????? (advocating capital
punishment)
? ???????????????????
(the ratio of people is nearly 80%)
Each clause forms a dependency structure (solid
arrows in Fig. 1), and a dependency relation from
the final bunsetsu links the clause with another
clause (dotted arrows in Fig. 1).
2.2 Clause Boundary Unit
In adopting a clause as an alternative parsing unit,
it is necessary to divide a monologue sentence
into clauses as the preprocessing for the follow-
ing dependency parsing. However, since some
kinds of clauses are embedded in main clauses,
it is fundamentally difficult to divide a mono-
logue into clauses in one dimension (Kashioka and
Maruyama, 2004).
Therefore, by using a clause boundary anno-
tation program (Maruyama et al, 2004), we ap-
proximately achieve the clause segmentation of
a monologue sentence. This program can iden-
tify units corresponding to clauses by detecting
the end boundaries of clauses. Furthermore, the
program can specify the positions and types of
clause boundaries simply from a local morpho-
logical analysis. That is, for a sentence mor-
phologically analyzed by ChaSen (Matsumoto et
al., 1999), the positions of clause boundaries are
identified and clause boundary labels are inserted
there. There exist 147 labels such as ?compound
clause? and ?adnominal clause.? 2
In our research, we adopt the unit sandwiched
between two clause boundaries detected by clause
boundary analysis, were called the clause bound-
ary unit, as an alternative parsing unit. Here, we
regard the label name provided for the end bound-
ary of a clause boundary unit as that unit?s type.
2The labels include a few other constituents that do not
strictly represent clause boundaries but can be regarded as be-
ing syntactically independent elements, such as ?topicalized
element,? ?conjunctives,? ?interjections,? and so on.
170
Table 1: 200 sentences in ?Asu-Wo-Yomu?
sentences 200
clause boundary units 951
bunsetsus 2,430
morphemes 6,017
dependencies over clause boundaries 94
2.3 Relation between Clause Boundary Units
and Dependency Structures
To clarify the relation between clause boundary
units and dependency structures, we investigated
the monologue corpus ?Asu-Wo-Yomu 3.? In the
investigation, we used 200 sentences for which
morphological analysis, bunsetsu segmentation,
clause boundary analysis, and dependency pars-
ing were automatically performed and then modi-
fied by hand. Here, the specification of the parts-
of-speech is in accordance with that of the IPA
parts-of-speech used in the ChaSen morphologi-
cal analyzer (Matsumoto et al, 1999), the rules
of the bunsetsu segmentation with those of CSJ
(Maekawa et al, 2000), the rules of the clause
boundary analysis with those of Maruyama et
al. (Maruyama et al, 2004), and the dependency
grammar with that of the Kyoto Corpus (Kuro-
hashi and Nagao, 1997).
Table 1 shows the results of analyzing the 200
sentences. Among the 1,479 bunsetsus in the dif-
ference set between all bunsetsus (2,430) and the
final bunsetsus (951) of clause boundary units,
only 94 bunsetsus depend on a bunsetsu located
outside the clause boundary unit. This result
means that 93.6% (1,385/1,479) of all dependency
relations are within a clause boundary unit. There-
fore, the results confirmed that the assumption
made by our research is valid to some extent.
3 Dependency Parsing Based on Clause
Boundaries
In accordance with the assumption described in
Section 2, in our method, the transcribed sentence
on which morphological analysis, clause bound-
ary detection, and bunsetsu segmentation are per-
formed is considered the input 4. The dependency
3Asu-Wo-Yomu is a collection of transcriptions of a TV
commentary program of the Japan Broadcasting Corporation
(NHK). The commentator speaks on some current social is-
sue for 10 minutes.
4It is difficult to preliminarily divide a monologue into
sentences because there are no clear sentence breaks in mono-
logues. However, since some methods for detecting sentence
boundaries have already been proposed (Huang and Zweig,
2002; Shitaoka et al, 2004), we assume that they can be de-
tected automatically before dependency parsing.
parsing is executed based on the following proce-
dures:
1. Clause-level parsing: The internal depen-
dency relations of clause boundary units are
identified for every clause boundary unit in
one sentence.
2. Sentence-level parsing: The dependency
relations in which the dependent unit is the fi-
nal bunsetsu of the clause boundary units are
identified.
In this paper, we describe a sequence of clause
boundary units in a sentence as C1 ? ? ?Cm, a se-
quence of bunsetsus in a clause boundary unit Ci
as bi1 ? ? ? bini , a dependency relation in which the
dependent bunsetsu is a bunsetsu bik as dep(bik),
and a dependency structure of a sentence as
{dep(b11), ? ? ? , dep(bmnm?1)}.
First, our method parses the dependency struc-
ture {dep(bi1), ? ? ? , dep(bini?1)} within the clause
boundary unit whenever a clause boundary unit
Ci is inputted. Then, it parses the dependency
structure {dep(b1n1), ? ? ? , dep(bm?1nm?1)}, which is a
set of dependency relations whose dependent bun-
setsu is the final bunsetsu of each clause boundary
unit in the input sentence. In addition, in both of
the above procedures, our method assumes the fol-
lowing three syntactic constraints:
1. No dependency is directed from right to left.
2. Dependencies don?t cross each other.
3. Each bunsetsu, except the final one in a sen-
tence, depends on only one bunsetsu.
These constraints are usually used for Japanese de-
pendency parsing.
3.1 Clause-level Dependency Parsing
Dependency parsing within a clause boundary
unit, when the sequence of bunsetsus in an input
clause boundary unit Ci is described as Bi (=
bi1 ? ? ? bini), identifies the dependency structure
Si (= {dep(bi1), ? ? ? , dep(bini?1)}), which max-
imizes the conditional probability P (Si|Bi). At
this level, the head bunsetsu of the final bunsetsu
bini of a clause boundary unit is not identified.
Assuming that each dependency is independent
of the others, P (Si|Bi) can be calculated as fol-
lows:
P (Si|Bi) =
ni?1?
k=1
P (bik rel? bil|Bi), (1)
171
where P (bik
rel? bil|Bi) is the probability that a bun-
setsu bik depends on a bunsetsu bil when the se-
quence of bunsetsus Bi is provided. Unlike the
conventional stochastic sentence-by-sentence de-
pendency parsing method, in our method, Bi is
the sequence of bunsetsus that constitutes not a
sentence but a clause. The structure Si, which
maximizes the conditional probability P (Si|Bi),
is regarded as the dependency structure of Bi and
calculated by dynamic programming (DP).
Next, we explain the calculation of P (bik
rel?
bil|Bi). First, the basic form of independent words
in a dependent bunsetsu is represented by hik, its
parts-of-speech tik, and type of dependency rik,
while the basic form of the independent word in
a head bunsetsu is represented by hil , and its parts-
of-speech til . Furthermore, the distance between
bunsetsus is described as diikl. Here, if a dependent
bunsetsu has one or more ancillary words, the type
of dependency is the lexicon, part-of-speech and
conjugated form of the rightmost ancillary word,
and if not so, it is the part-of-speech and conju-
gated form of the rightmost morpheme. The type
of dependency rik is the same attribute used in
our stochastic method proposed for robust depen-
dency parsing of spoken language dialogue (Ohno
et al, 2005b). Then diikl takes 1 or more than 1,
that is, a binary value. Incidentally, the above
attributes are the same as those used by the con-
ventional stochastic dependency parsing methods
(Collins, 1996; Ratnaparkhi, 1997; Fujio and Mat-
sumoto, 1998; Uchimoto et al, 1999; Charniak,
2000; Kudo and Matsumoto, 2002).
Additionally, we prepared the attribute eil to in-
dicate whether bil is the final bunsetsu of a clause
boundary unit. Since we can consider a clause
boundary unit as a unit corresponding to a sim-
ple sentence, we can treat the final bunsetsu of a
clause boundary unit as a sentence-end bunsetsu.
The attribute that indicates whether a head bun-
setsu is a sentence-end bunsetsu has often been
used in conventional sentence-by-sentence parsing
methods (e.g. Uchimoto et al, 1999).
By using the above attributes, the conditional
probability P (bik
rel? bil|Bi) is calculated as fol-
lows:
P (bik rel? bil|Bi) (2)
?= P (bik rel? bil|hik, hil, tik, til, rik, diikl, eil)
= F (b
i
k
rel? bil, hik, hil, tik, til, rik, diikl, eil)
F (hik, hil, tik, til, rik, diikl, eil)
.
Note that F is a co-occurrence frequency function.
In order to resolve the sparse data problems
caused by estimating P (bik
rel? bil|Bi) with formula
(2), we adopted the smoothing method described
by Fujio and Matsumoto (Fujio and Matsumoto,
1998): if F (hik, hil, tik, til, rik, diikl, eil) in formula (2)
is 0, we estimate P (bik
rel? bil|Bi) by using formula
(3).
P (bik rel? bil|Bi) (3)
?= P (bik rel? bil|tik, til, rik, diikl, eil)
= F (b
i
k
rel? bil, tik, til, rik, diikl, eil)
F (tik, til, rik, diikl, eil)
3.2 Sentence-level Dependency Parsing
Here, the head bunsetsu of the final bunsetsu
of a clause boundary unit is identified. Let
B (=B1 ? ? ?Bn) be the sequence of bunset-
sus of one sentence and Sfin be a set of de-
pendency relations whose dependent bunsetsu is
the final bunsetsu of a clause boundary unit,
{dep(b1n1), ? ? ? , dep(bm?1nm?1)}; then Sfin, which
makes P (Sfin|B) the maximum, is calculated by
DP. The P (Sfin|B) can be calculated as follows:
P (Sfin|B) =
m?1?
i=1
P (bini
rel? bjl |B), (4)
where P (bini
rel? bjl |B) is the probability that a
bunsetsu bini depends on a bunsetsu bjl when the
sequence of the sentence?s bunsetsus, B, is pro-
vided. Our method parses by giving consideration
to the dependency structures in each clause bound-
ary unit, which were previously parsed. That is,
the method does not consider all bunsetsus lo-
cated on the right-hand side as candidates for a
head bunsetsu but calculates only dependency re-
lations within each clause boundary unit that do
not cross any other relation in previously parsed
dependency structures. In the case of Fig. 1,
the method calculates by assuming that only three
bunsetsus ??? (the ratio of people),? or ???
????? (is)? can be the head bunsetsu of the
bunsetsu ???????? (advocating).?
In addition, P (bini
rel? bjl |B) is calculated as in
Eq. (5). Equation (5) uses all of the attributes used
in Eq. (2), in addition to the attribute sjl , which
indicates whether the head bunsetsu of bjl is the
final bunsetsu of a sentence. Here, we take into
172
Table 2: Size of experimental data set (Asu-Wo-
Yomu)
test data learning data
programs 8 95
sentences 500 5,532
clause boundary units 2,237 26,318
bunsetsus 5,298 65,821
morphemes 13,342 165,129
Note that the commentator of each program is different.
Table 3: Experimental results on parsing time
our method conv. method
average time (msec) 10.9 51.9
programming language: LISP
computer used: Pentium4 2.4 GHz, Linux
account the analysis result that about 70% of the
final bunsetsus of clause boundary units depend on
the final bunsetsu of other clause boundary units 5
and also use the attribute ejl at this phase.
P (bini
rel? bjl |B) (5)
?= P (bini
rel?bjl |hini , hjl , tini , tjl , rini , dijnil, e
j
l , sjl )
= F (b
ini
rel?bjl , hini , hjl , tini , tjl , rini , dijnil, e
j
l , sjl )
F (hini , hjl , tini , tjl , rini , dijnil, e
j
l , sjl )
4 Parsing Experiment
To evaluate the effectiveness of our method for
Japanese spoken monologue, we conducted an ex-
periment on dependency parsing.
4.1 Outline of Experiment
We used the spoken monologue corpus? Asu-
Wo-Yomu,?annotated with information on mor-
phological analysis, clause boundary detection,
bunsetsu segmentation, and dependency analy-
sis6. Table 2 shows the data used for the ex-
periment. We used 500 sentences as the test
data. Although our method assumes that a depen-
dency relation does not cross clause boundaries,
there were 152 dependency relations that contra-
dicted this assumption. This means that the depen-
dency accuracy of our method is not over 96.8%
(4,646/4,798). On the other hand, we used 5,532
sentences as the learning data.
To carry out comparative evaluation of our
method?s effectiveness, we executed parsing for
5We analyzed the 200 sentences described in Section 2.3
and confirmed 70.6% (522/751) of the final bunsetsus of
clause boundary units depended on the final bunsetsu of other
clause boundary units.
6Here, the specifications of these annotations are in accor-
dance with those described in Section 2.3.
0
50
100
150
200
250
300
350
400
0 5 10 15 20 25 30
Pa
rs
in
g 
tim
e 
[m
se
c]
Length of sentence [number of bunsetsu]
our method
conv. method
Figure 2: Relation between sentence length and
parsing time
the above-mentioned data by the following two
methods and obtained, respectively, the parsing
time and parsing accuracy.
? Our method: First, our method provides
clause boundaries for a sequence of bunset-
sus of an input sentence and identifies all
clause boundary units in a sentence by per-
forming clause boundary analysis (CBAP)
(Maruyama et al, 2004). After that, our
method executes the dependency parsing de-
scribed in Section 3.
? Conventional method: This method parses
a sentence at one time without dividing it into
clause boundary units. Here, the probability
that a bunsetsu depends on another bunsetsu,
when the sequence of bunsetsus of a sentence
is provided, is calculated as in Eq. (5), where
the attribute e was eliminated. This conven-
tional method has been implemented by us
based on the previous research (Fujio and
Matsumoto, 1998).
4.2 Experimental Results
The parsing times of both methods are shown in
Table 3. The parsing speed of our method im-
proves by about 5 times on average in comparison
with the conventional method. Here, the parsing
time of our method includes the time taken not
only for the dependency parsing but also for the
clause boundary analysis. The average time taken
for clause boundary analysis was about 1.2 mil-
lisecond per sentence. Therefore, the time cost of
performing clause boundary analysis as a prepro-
cessing of dependency parsing can be considered
small enough to disregard. Figure 2 shows the re-
lation between sentence length and parsing time
173
Table 4: Experimental results on parsing accuracy
our method conv. method
bunsetsu within a clause boundary unit (except final bunsetsu) 88.2% (2,701/3,061) 84.7% (2,592/3,061)
final bunsetsu of a clause boundary unit 65.6% (1,140/1,737) 63.3% (1,100/1,737)
total 80.1% (3,841/4,798) 76.9% (3,692/4,798)
Table 5: Experimental results on clause boundary
analysis (CBAP)
recall 95.7% (2,140/2,237)
precision 96.9% (2,140/2,209)
for both methods, and it is clear from this figure
that the parsing time of the conventional method
begins to rapidly increase when the length of a
sentence becomes 12 or more bunsetsus. In con-
trast, our method changes little in relation to pars-
ing time. Here, since the sentences used in the
experiment are composed of 11.8 bunsetsus on av-
erage, this result shows that our method is suitable
for improving the parsing time of a monologue
sentence whose length is longer than the average.
Table 4 shows the parsing accuracy of both
methods. The first line of Table 4 shows the
parsing accuracy for all bunsetsus within clause
boundary units except the final bunsetsus of the
clause boundary units. The second line shows
the parsing accuracy for the final bunsetsus of
all clause boundary units except the sentence-end
bunsetsus. We confirmed that our method could
analyze with a higher accuracy than the conven-
tional method. Here, Table 5 shows the accu-
racy of the clause boundary analysis executed by
CBAP. Since the precision and recall is high, we
can assume that the clause boundary analysis ex-
erts almost no harmful influence on the following
dependency parsing.
As mentioned above, it is clear that our method
is more effective than the conventional method in
shortening parsing time and increasing parsing ac-
curacy.
5 Discussions
Our method assumes that dependency relations
within a clause boundary unit do not cross clause
boundaries. Due to this assumption, the method
cannot correctly parse the dependency relations
over clause boundaries. However, the experi-
mental results indicated that the accuracy of our
method was higher than that of the conventional
method.
In this section, we first discuss the effect of our
method on parsing accuracy, separately for bun-
Table 6: Comparison of parsing accuracy between
conventional method and our method (for bunsetsu
within a clause boundary unit except final bun-
setsu)``````````conv. method
our method
correct incorrect total
correct 2,499 93 2,592
incorrect 202 267 469
total 2,701 360 3,061
setsus within clause boundary units (except the fi-
nal bunsetsus) and the final bunsetsus of clause
boundary units. Next, we discuss the problem of
our method?s inability to parse dependency rela-
tions over clause boundaries.
5.1 Parsing Accuracy for Bunsetsu within a
Clause Boundary Unit (except final
bunsetsu)
Table 6 compares parsing accuracies for bunsetsus
within clause boundary units (except the final bun-
setsus) between the conventional method and our
method. There are 3,061 bunsetsus within clause
boundary units except the final bunsetsu, among
which 2,499 were correctly parsed by both meth-
ods. There were 202 dependency relations cor-
rectly parsed by our method but incorrectly parsed
by the conventional method. This means that our
method can narrow down the candidates for a head
bunsetsu.
In contrast, 93 dependency relations were cor-
rectly parsed solely by the conventional method.
Among these, 46 were dependency relations over
clause boundaries, which cannot in principle be
parsed by our method. This means that our method
can correctly parse almost all of the dependency
relations that the conventional method can cor-
rectly parse except for dependency relations over
clause boundaries.
5.2 Parsing Accuracy for Final Bunsetsu of a
Clause Boundary Unit
We can see from Table 4 that the parsing accuracy
for the final bunsetsus of clause boundary units by
both methods is much worse than that for bunset-
sus within the clause boundary units (except the
final bunsetsus). This means that it is difficult
174
Table 7: Comparison of parsing accuracy between
conventional method and our method (for final
bunsetsu of a clause boundary unit)``````````conv. method
our method
correct incorrect total
correct 1037 63 1,100
incorrect 103 534 637
total 1,140 597 1,737
Table 8: Parsing accuracy for dependency rela-
tions over clause boundaries
our method conv. method
recall 1.3% (2/152) 30.3% (46/152)
precision 11.8% (2/ 17) 25.3% (46/182)
to identify dependency relations whose dependent
bunsetsu is the final one of a clause boundary unit.
Table 7 compares how the two methods parse
the dependency relations when the dependent bun-
setsu is the final bunsetsu of a clause bound-
ary unit. There are 1,737 dependency relations
whose dependent bunsetsu is the final bunsetsu of
a clause boundary unit, among which 1,037 were
correctly parsed by both methods. The number
of dependency relations correctly parsed only by
our method was 103. This number is higher than
that of dependency relations correctly parsed by
only the conventional method. This result might
be attributed to our method?s effect; that is, our
method narrows down the candidates internally for
a head bunsetsu based on the first-parsed depen-
dency structure for clause boundary units.
5.3 Dependency Relations over Clause
Boundaries
Table 8 shows the accuracy of both methods for
parsing dependency relations over clause bound-
aries. Since our method parses based on the as-
sumption that those dependency relations do not
exist, it cannot correctly parse anything. Al-
though, from the experimental results, our method
could identify two dependency relations over
clause boundaries, these were identified only be-
cause dependency parsing for some sentences was
performed based on wrong clause boundaries that
were provided by clause boundary analysis. On
the other hand, the conventional method correctly
parsed 46 dependency relations among 152 that
crossed a clause boundary in the test data. Since
the conventional method could correctly parse
only 30.3% of those dependency relations, we can
see that it is in principle difficult to identify the
dependency relations.
6 Related Works
Since monologue sentences tend to be long and
have complex structures, it is important to con-
sider the features. Although there have been
very few studies on parsing monologue sentences,
some studies on parsing written language have
dealt with long-sentence parsing. To resolve the
syntactic ambiguity of a long sentence, some of
them have focused attention on the ?clause.?
First, there are the studies that focused atten-
tion on compound clauses (Agarwal and Boggess,
1992; Kurohashi and Nagao, 1994). These tried
to improve the parsing accuracy of long sentences
by identifying the boundaries of coordinate struc-
tures. Next, other research efforts utilized the three
categories into which various types of subordinate
clauses are hierarchically classified based on the
?scope-embedding preference? of Japanese subor-
dinate clauses (Shirai et al, 1995; Utsuro et al,
2000). Furthermore, Kim et al (Kim and Lee,
2004) divided a sentence into ?S(ubject)-clauses,?
which were defined as a group of words containing
several predicates and their common subject. The
above studies have attempted to reduce the pars-
ing ambiguity between specific types of clauses in
order to improve the parsing accuracy of an entire
sentence.
On the other hand, our method utilizes all types
of clauses without limiting them to specific types
of clauses. To improve the accuracy of long-
sentence parsing, we thought that it would be more
effective to cyclopaedically divide a sentence into
all types of clauses and then parse the local de-
pendency structure of each clause. Moreover,
since our method can perform dependency pars-
ing clause-by-clause, we can reasonably expect
our method to be applicable to incremental pars-
ing (Ohno et al, 2005a).
7 Conclusions
In this paper, we proposed a technique for de-
pendency parsing of monologue sentences based
on clause-boundary detection. The method can
achieve more effective, high-performance spoken
monologue parsing by dividing a sentence into
clauses, which are considered as suitable language
units for simplicity. To evaluate the effectiveness
of our method for Japanese spoken monologue, we
conducted an experiment on dependency parsing
of the spoken monologue sentences recorded in
the ?Asu-Wo-Yomu.? From the experimental re-
175
sults, we confirmed that our method shortened the
parsing time and increased the parsing accuracy
compared with the conventional method, which
parses a sentence without dividing it into clauses.
Future research will include making a thorough
investigation into the relation between dependency
type and the type of clause boundary unit. After
that, we plan to investigate techniques for identi-
fying the dependency relations over clause bound-
aries. Furthermore, as the experiment described in
this paper has shown the effectiveness of our tech-
nique for dependency parsing of long sentences
in spoken monologues, so our technique can be
expected to be effective in written language also.
Therefore, we want to examine the effectiveness
by conducting the parsing experiment of long sen-
tences in written language such as newspaper arti-
cles.
8 Acknowledgements
This research was supported in part by a contract
with the Strategic Information and Communica-
tions R&D Promotion Programme, Ministry of In-
ternal Affairs and Communications and the Grand-
in-Aid for Young Scientists of JSPS. The first au-
thor is partially supported by JSPS Research Fel-
lowships for Young Scientists.
References
R. Agarwal and L. Boggess. 1992. A simple but use-
ful approach to conjunct indentification. In Proc. of
30th ACL, pages 15?21.
E. Charniak. 2000. A maximum-entropy-inspired
parser. In Proc. of 1st NAACL, pages 132?139.
M. Collins. 1996. A new statistical parser based on
bigram lexical dependencies. In Proc. of 34th ACL,
pages 184?191.
Mark G. Core and Lenhart K. Schubert. 1999. A syn-
tactic framework for speech repairs and other dis-
ruptions. In Proc. of 37th ACL, pages 413?420.
R. Delmonte. 2003. Parsing spontaneous speech. In
Proc. of 8th EUROSPEECH, pages 1999?2004.
M. Fujio and Y. Matsumoto. 1998. Japanese depen-
dency structure analysis based on lexicalized statis-
tics. In Proc. of 3rd EMNLP, pages 87?96.
J. Huang and G. Zweig. 2002. Maximum entropy
model for punctuation annotation from speech. In
Proc. of 7th ICSLP, pages 917?920.
H. Kashioka and T. Maruyama. 2004. Segmentation
of semantic unit in Japanese monologue. In Proc. of
ICSLT-O-COCOSDA 2004, pages 87?92.
M. Kim and J. Lee. 2004. Syntactic analysis of long
sentences based on s-clauses. In Proc. of 1st IJC-
NLP, pages 420?427.
T. Kudo and Y. Matsumoto. 2002. Japanese depen-
dency analyisis using cascaded chunking. In Proc.
of 6th CoNLL, pages 63?69.
S. Kurohashi and M. Nagao. 1994. A syntactic analy-
sis method of long Japanese sentences based on the
detection of conjunctive structures. Computational
Linguistics, 20(4):507?534.
S. Kurohashi and M. Nagao. 1997. Building a
Japanese parsed corpus while improving the parsing
system. In Proc. of 4th NLPRS, pages 451?456.
K. Maekawa, H. Koiso, S. Furui, and H. Isahara. 2000.
Spontaneous speech corpus of Japanese. In Proc. of
2nd LREC, pages 947?952.
T. Maruyama, H. Kashioka, T. Kumano, and
H. Tanaka. 2004. Development and evaluation
of Japanese clause boundaries annotation program.
Journal of Natural Language Processing, 11(3):39?
68. (In Japanese).
Y. Matsumoto, A. Kitauchi, T. Yamashita, and Y. Hi-
rano, 1999. Japanese Morphological Analysis Sys-
tem ChaSen version 2.0 Manual. NAIST Technical
Report, NAIST-IS-TR99009.
T. Ohno, S. Matsubara, H. Kashioka, N. Kato, and
Y. Inagaki. 2005a. Incremental dependency pars-
ing of Japanese spoken monologue based on clause
boundaries. In Proc. of 9th EUROSPEECH, pages
3449?3452.
T. Ohno, S. Matsubara, N. Kawaguchi, and Y. Inagaki.
2005b. Robust dependency parsing of spontaneous
Japanese spoken language. IEICE Transactions on
Information and Systems, E88-D(3):545?552.
A. Ratnaparkhi. 1997. A liner observed time statistical
parser based on maximum entropy models. In Proc.
of 2nd EMNLP, pages 1?10.
S. Shirai, S. Ikehara, A. Yokoo, and J. Kimura. 1995.
A new dependency analysis method based on se-
mantically embedded sentence structures and its per-
formance on Japanese subordinate clause. Jour-
nal of Information Processing Society of Japan,
36(10):2353?2361. (In Japanese).
K. Shitaoka, K. Uchimoto, T. Kawahara, and H. Isa-
hara. 2004. Dependency structure analysis and sen-
tence boundary detection in spontaneous Japanese.
In Proc. of 20th COLING, pages 1107?1113.
K. Uchimoto, S. Sekine, and K. Isahara. 1999.
Japanese dependency structure analysis based on
maximum entropy models. In Proc. of 9th EACL,
pages 196?203.
T. Utsuro, S. Nishiokayama, M. Fujio, and Y. Mat-
sumoto. 2000. Analyzing dependencies of Japanese
subordinate clauses based on statistics of scope em-
bedding preference. In Proc. of 6th ANLP, pages
110?117.
176
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 531?539,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Linefeed Insertion into Japanese Spoken Monologue for Captioning
Tomohiro Ohno
Graduate School of
International Development,
Nagoya University, Japan
ohno@nagoya-u.jp
Masaki Murata
Graduate School of
Information Science,
Nagoya University, Japan
murata@el.itc.nagoya-u.ac.jp
Shigeki Matsubara
Information Technology Center,
Nagoya University, Japan
matubara@nagoya-u.jp
Abstract
To support the real-time understanding of
spoken monologue such as lectures and
commentaries, the development of a cap-
tioning system is required. In monologues,
since a sentence tends to be long, each
sentence is often displayed in multi lines
on one screen, it is necessary to insert
linefeeds into a text so that the text be-
comes easy to read. This paper proposes
a technique for inserting linefeeds into a
Japanese spoken monologue text as an el-
emental technique to generate the read-
able captions. Our method appropriately
inserts linefeeds into a sentence by ma-
chine learning, based on the information
such as dependencies, clause boundaries,
pauses and line length. An experiment us-
ing Japanese speech data has shown the ef-
fectiveness of our technique.
1 Introduction
Real-time captioning is a technique for support-
ing the speech understanding of deaf persons, el-
derly persons, or foreigners by displaying tran-
scribed texts of monologue speech such as lec-
tures. In recent years, there exist a lot of re-
searches about automatic captioning, and the tech-
niques of automatic speech recognition (ASR)
aimed for captioning have been developed (Bou-
lianne et al, 2006; Holter et al, 2000; Imai et
al., 2006; Munteanu et al, 2007; Saraclar et al,
2002; Xue et al, 2006). However, in order to gen-
erate captions which is easy to read, it is important
not only to recognize speech with high recognition
rate but also to properly display the transcribed
text on a screen (Hoogenboom et al, 2008). Es-
pecially, in spoken monologue, since a sentence
tends to be long, each sentence is often displayed
as a multi-line text on a screen. Therefore, proper
linefeed insertion for the displayed text is desired
so that the text becomes easy to read.
Until now, there existed few researches about
how to display text on a screen in automatic cap-
tioning. As the research about linefeed insertion,
Monma et al proposed a method based on pat-
terns of a sequence of morphemes (Monma et
al., 2003). However, the target of the research is
closed-captions of Japanese TV shows, in which
less than or equal to 2 lines text is displayed on
a screen and the text all switches to other text at
a time. In the work, the highest priority concept
on captioning is that one screen should be filled
with as much text as possible. Therefore, a se-
mantic boundary in a sentence is hardly taken into
account in linefeed insertion, and the readability
of the caption is hardly improved.
This paper proposes a technique for inserting
linefeeds into transcribed texts of Japanese mono-
logue speech as an elemental technique to gener-
ate readable captions. We assume that a screen for
displaying only multi-line caption is placed to pro-
vide the caption information to the audience on the
site of a lecture. In our method, the linefeeds are
inserted into only the boundaries between bunset-
sus1, and the linefeeds are appropriately inserted
into a sentence by machine learning, based on the
information such as morphemes, dependencies2,
clause boundaries, pauses and line length.
We conducted an experiment on inserting line-
feeds by using Japanese spoken monologue data.
As the results of inserting linefeeds for 1,714 sen-
tences, the recall and precision of our method were
82.66% and 80.24%, respectively. Our method
improved the performance dramatically compared
1Bunsetsu is a linguistic unit in Japanese that roughly cor-
responds to a basic phrase in English. A bunsetsu consists of
one independent word and zero or more ancillary words.
2A dependency in Japanese is a modification relation in
which a modifier bunsetsu depends on a modified bunsetsu.
That is, the modifier bunsetsu and the modified bunsetsu work
as modifier and modifyee, respectively.
531
Figure 1: Caption display of spoken monologue
with four baseline methods, which we established
for comparative evaluation. The effectiveness of
our method has been confirmed.
This paper is organized as follows: The next
section describes our assumed caption and the pre-
liminary analysis. Section 3 presents our linefeed
insertion technique. An experiment and discussion
are reported in Sections 4 and 5, respectively. Fi-
nally, Section 6 concludes the paper.
2 Linefeed Insertion for Spoken
Monologue
In our research, in an environment in which cap-
tions are displayed on the site of a lecture, we as-
sume that a screen for displaying only captions is
used. In the screen, multi lines are always dis-
played, being scrolled line by line. Figure 1 shows
our assumed environment in which captions are
displayed.
As shown in Figure 2, if the transcribed text of
speech is displayed in accordance with only the
width of a screen without considering the proper
points of linefeeds, the caption is not easy to read.
Especially, since the audience is forced to read
the caption in synchronization with the speaker?s
utterance speed, it is important that linefeeds are
properly inserted into the displayed text in consid-
eration of the readability as shown in Figure 3.
To investigate whether the line insertion facili-
tates the readability of the displayed texts, we con-
ducted an experiment using the transcribed text of
lecture speeches in the Simultaneous Interpreta-
tion Database (SIDB) (Matsubara et al, 2002). We
randomly selected 50 sentences from the data, and
then created the following two texts for each sen-
tence based on two different concepts about line-
feed insertion.
?1?Text into which linefeeds were forcibly in-
serted once every 20 characters
????????????????????
????????????????????
????????????????????
????????????????????
???????????????????
For example, environmental problem, 
population problem, AIDS problem and 
so on, a lot of global-scale problems 
have occurred, and unfortunately, 
these problems seem to continue 
during 21st century or to become 
worse if we look through blue glasses.
Figure 2: Caption of monologue speech
????????
?????????
??????????
???????????????????
????????????
??????????
??????????????
?????????????????
(For example, environmental problem)
(population problem)
(AIDS problem and so on)
a lot of global-scale problems 
have occurred
(and unfortunately, these problems)
(to continue during also 21st century)
(or if we look through blue glasses)
(seems to become worse)
Figure 3: Caption into which linefeeds are prop-
erly inserted
49
50
49
37
40
36
43
48
34
49
1 2 3 4 5 6 7 8 9 10
?1? Forcible insertion of linefeeds
?2? Proper insertion of linefeeds
subject ID
# of sentences
50
45
40
35
30
25
20
15
10
5
0
Figure 4: Result of investigation of effect of line-
feed insertion into transcription
?2?Text into which linefeeds were properly
inserted in consideration of readability by
hand3
Figure 2 and 3 show examples of the text (1) and
(2), respectively. 10 examinees decided which of
the two texts was more readable. Figure 4 shows
the result of the investigation. The ratio that each
examinee selected text (2) was 87.0% on average.
There was no sentence in the text group (1) which
was selected by more than 5 examinees. These
indicates that a text becomes more readable by
proper insertion of linefeeds.
Here, since a bunsetsu is the smallest seman-
tically meaningful language unit in Japanese, our
method adopts the bunsetsu boundaries as the can-
didates of points into which a linefeed is inserted.
In this paper, hereafter, we call a bunsetsu bound-
ary into which a linefeed is inserted a linefeed
point.
33 persons inserted linefeeds into the 50 sentences by dis-
cussing where to insert the linefeeds.
532
Table 1: Size of analysis data
sentence 221
bunsetsu 2,891
character 13,899
linefeed 883
character per line 13.2
3 Preliminary Analysis about Linefeed
Points
In our research, the points into which linefeeds
should be inserted is detected by using machine
learning. To find the effective features, we investi-
gated the spoken language corpus. In our investi-
gation, we used Japanese monologue speech data
in the SIDB (Matsubara et al, 2002). The data
is annotated by hand with information on mor-
phological analysis, bunsetsu segmentation, de-
pendency analysis, clause boundary detection, and
linefeeds insertion. Table 1 shows the size of the
analysis data. Among 2,670 (= 2, 891?221) bun-
setsu boundaries, which are candidates of linefeed
points, there existed 833 bunsetsu boundaries into
which linefeeds were inserted, that is, the ratio of
linefeed insertion was 31.2%.
The linefeeds were inserted by hand so that the
maximum number of characters per line is 20. We
set the number in consideration of the relation be-
tween readability and font size on the display. In
the analysis, we focused on the clause boundary,
dependency relation, line length, pause and mor-
pheme of line head, and investigated the relations
between them and linefeed points.
3.1 Clause Boundary and Linefeed Point
Since a clause is one of semantically meaningful
language units, the clause boundary is considered
to be a strong candidate of a linefeed point. In the
analysis data, there existed 969 clause boundaries
except sentence breaks. Among them, 490 were
the points into which linefeeds were inserted, that
is, the ratio of linefeed insertion was 51.1%. This
ratio is higher than that of bunsetsu boundaries.
This indicates that linefeeds tend to be inserted
into clause boundaries.
We investigated the ratio of linefeed insertion
about 42 types4 of clause boundaries, which were
seen in the analysis data. Table 2 shows the top 10
4In our research, we used the types of clause boundaries
defined by the Clause Boundary Annotation Program (Kash-
ioka and Maruyama, 2004).
Table 2: Ratio of linefeed insertion for clause
boundary type
type of ratio of linefeed
clause boundary insertion (%)
topicalized element-wa 50.8
discourse marker 12.0
quotational clause 22.1
adnominal clause 23.3
compound clause-te 90.2
supplement clause 68.0
compound clause-ga 100.0
compound clause-keredomo 100.0
condition clause-to 93.5
adnominal clause-toiu 27.3
clause boundary types about the occurrence fre-
quency, and each ratio of linefeed insertion. In
the case of ?compound clause-ga? and ?compound
clause-keredomo,? the ratio of linefeed insertion
was 100%. On the other hand, in the case of ?quo-
tational clause,? ?adnominal clause? and ?adnomi-
nal clause-toiu,? the ratio of linefeed insertion was
less than 30%. This means that the likelihood of
linefeed insertion is different according to the type
of the clause boundary.
3.2 Dependency Structure and Linefeed
Point
When a bunsetsu depends on the next bunsetsu, it
is thought that a linefeed is hard to be inserted into
the bunsetsu boundary between them because the
sequence of such bunsetsus constitutes a semanti-
cally meaningful unit. In the analysis data, there
existed 1,459 bunsetsus which depend on the next
bunsetsu. Among the bunsetsu boundaries right
after them, 192 were linefeed points, that is, the
ratio of linefeed insertions was 13.2%. This ra-
tio is less than half of that for all the bunsetsu
boundaries. On the other hand, when the bunsetsu
boundary right after the bunsetsu which does not
depend on the next bunsetsu, the ratio of linefeed
insertion was 52.7%.
Next, we focused on the type of the dependency
relation, by which the likelihood of linefeed inser-
tion is different. For example, when the bunsetsu
boundary right after a bunsetsu on which the final
bunsetsu of an adnominal clause depends, the ra-
tio of linefeed insertion was 43.1%. This ratio is
higher than that for all the bunsetsu boundaries.
In addition, we investigated the relation be-
533
???????????????????
???????????????????
:  dependency relation? bunsetsu
[Dependency structure]
[Result of linefeed insertion in the analysis data]
A writer of the magazine in which 
only old domestic cars are covered
asks to get a story about my car
?? ???
????
???? ??? ??? ?? ?? ??
????
???
?????
only 
domestic cars
in which 
are covered
old
of the 
magazine
a 
writer
my car
to get a
story about
ask
Figure 5: Relation between dependency structure
and linefeed points
tween a dependency structure and linefeed points,
that is, whether the dependency structure is closed
within a line or not. Here, a line whose depen-
dency structure is closed means that all bunsetsus,
except the final bunsetsu, in the line depend on one
of bunsetsus in the line. Since, in many of seman-
tically meaningful units, the dependency structure
is closed, the dependency structure of a line is con-
sidered to tend to be closed. In the analysis data,
among 883 lines, 599 lines? dependency structures
were closed.
Figure 5 shows the relation between depen-
dency structure and linefeed points. In this exam-
ple, linefeeds are not inserted right after bunset-
sus which depend on the next bunsetsu (e.g. ??
? (my)? and ??? (car)?). Instead, a linefeed is
inserted right after a bunsetsu which does not de-
pend on the next bunsetsu (???? (a writer)?).
In addition, the dependency structure in each line
is closed.
3.3 Line Length and Linefeed Point
An extremely-short line is considered to be hardly
generated because the readability goes down if the
length of each line is very different. In the analysis
data, a line whose length is less than or equal to 6
characters occupied only 7.59% of the total. This
indicates that linefeeds tend to be inserted into the
place where a line can maintain a certain length.
3.4 Pause and Linefeed Point
It is thought that a pause corresponds to a syn-
tactic boundary. Therefore, there are possibility
that a linefeed becomes more easily inserted into
a bunsetsu boundary at which a pause exists. In
our research, a pause is defined as a silent interval
equal to or longer than 200ms. In the analysis data,
among 748 bunsetsu boundaries at which a pause
exists, linefeeds were inserted into 471 bunsetsu
boundaries, that is, the ratio of linefeed insertion
was 62.97%. This ratio is higher than that for all
the bunsetsu boundaries, thus, we confirmed that
linefeeds tend to be inserted into bunsetsu bound-
aries at which a pause exists.
3.5 Morpheme Located in the Start of a Line
There exist some morphemes which are unlikely
to become a line head. We investigated the ratio
that each leftmost morpheme of all the bunsetsus
appears at a line head. Here, we focused on the
basic form and part-of-speech of a morpheme. The
morphemes which appeared 20 times and of which
the ratio of appearance at a line head was less than
10% were as follows:
? Basic form:
??? (think) [2/70]?, ??? (problem)
[0/42]?, ??? (do) [3/33]?, ??? (become)
[2/32]????? (necessary) [1/21]?
? Part-of-speech:
noun-non independent-general [0/40]?
noun-nai adjective stem [0/40]?
noun-non independent-adverbial [(0/27]
If the leftmost morpheme of a bunsetsu is one of
these, it is thought that a linefeed is hardly inserted
right after the bunsetsu.
4 Linefeed Insertion Technique
In our method, a sentence, on which morphologi-
cal analysis, bunsetsu segmentation, clause bound-
ary analysis and dependency analysis are per-
formed, is considered the input. Our method de-
cides whether or not to insert a linefeed into each
bunsetsu boundary in an input sentence. Under
the condition that the number of characters in each
line has to be less than or equal to the maximum
number of characters per line, our method identi-
fies the most appropriate combination among all
combinations of the points into which linefeeds
can be inserted, by using the probabilistic model.
In this paper, we describe an input sentence
which consists of n bunsetsus as B = b1 ? ? ? bn,
and the result of linefeeds insertion as R =
r1 ? ? ? rn. Here, ri is 1 if a linefeed is inserted right
after bunsetsu bi, and is 0 otherwise. We describe
a sequence of bunsetsus in the j-th line among the
m lines created by dividing an input sentence as
Lj = bj1 ? ? ? bjnj (1 ? j ? m), and then, r
j
k = 0 if
k ?= nj , and rjk = 1 otherwise.
534
4.1 Probabilistic Model for Linefeed
Insertion
When an input sentenceB is provided, our method
identifies the result of linefeeds insertionR, which
maximizes the conditional probability P (R|B).
Assuming that whether or not a linefeed is inserted
right after a bunsetsu is independent of other line-
feed points except the linefeed point of the start of
the line which contains the bunsetsu, P (R|B) can
be calculated as follows:
P (R|B) (1)
= P (r11 = 0, ? ? ? , r1n1 = 1, ? ? ? , r
m
1 = 0, ? ? ? , rmnm = 1|B)
?= P (r11 = 0|B) ? P (r12 = 0|r11 = 0, B) ? ? ? ?
?P (r1n1 = 1|r
1
n1?1 = 0, ? ? ? , r
1
1 = 0, B) ? ? ? ?
?P (rm1 = 0|rm?1nm?1 = 1, B) ? ? ? ?
?P (rmm = 1|rmnm?1 = 0, ? ? ? , r
m
1 = 0, rm?1nm?1 = 1, B)
where P (rjk = 1|r
j
k?1 = 0, ? ? ? , r
j
1 = 0, rj?1nj?1 =
1, B) is the probability that a linefeed is inserted
right after a bunsetsu bjk when the sequence of
bunsetsus B is provided and the linefeed point of
the start of the j-th line is identified. Similarly,
P (rjk = 0|r
j
k?1 = 0, ? ? ? , r
j
1 = 0, rj?1nj?1 = 1, B)
is the probability that a linefeed is not inserted
right after a bunsetsu bjk. These probabilities are
estimated by the maximum entropy method. The
result R which maximizes the conditional proba-
bility P (R|B) is regarded as the most appropriate
result of linefeed insertion, and calculated by dy-
namic programming.
4.2 Features on Maximum Entropy Method
To estimate P (rjk = 1|r
j
k?1 = 0, ? ? ? , r
j
1 =
0, rj?1nj?1 = 1, B) and P (r
j
k = 0|r
j
k?1 =
0, ? ? ? , rj1 = 0, rj?1nj?1 = 1, B) by the maximum
entropy method, we used the following features
based on the analysis described in Section 2.2.
Morphological information
? the rightmost independent morpheme (a part-
of-speech, an inflected form) and rightmost
morpheme (a part-of-speech) of a bunsetsu bjk
Clause boundary information
? whether or not a clause boundary exists right
after bjk
? a type of the clause boundary right after bjk (if
there exists a clause boundary)
Dependency information
? whether or not bjk depends on the next bun-
setsu
? whether or not bjk depends on the final bun-
setsu of a clause
? whether or not bjk depends on a bunsetsu to
which the number of characters from the start
of the line is less than or equal to the maxi-
mum number of characters
? whether or not bjk is depended on by the final
bunsetsu of an adnominal clause
? whether or not bjk is depended on by the bun-
setsu located right before it
? whether or not the dependency structure of
a sequence of bunsetsus between bjk and b
j
1,
which is the first bunsetsu of the line, is
closed
? whether or not there exists a bunsetsu which
depends on the modified bunsetsu of bjk,
among bunsetsus which are located after bjk
and to which the number of characters from
the start of the line is less than or equal to the
maximum number of characters
Line length
? any of the following is the class into which
the number of characters from the start of the
line to bjk is classified
? less than or equal to 2
? more than 2 and less than or equal to 6
? more than 6
Pause
? whether or not a pause exists right after bjk
Leftmost morpheme of a bunsetsu
? whether or not the basic form or part-of-
speech of the leftmost morpheme of the next
bunsetsu of bjk is one of the morphemes enu-
merated in Section 3.5.
5 Experiment
To evaluate the effectiveness of our method, we
conducted an experiment on inserting linefeeds by
using discourse speech data.
5.1 Outline of Experiment
As the experimental data, we used the transcribed
data of Japanese discourse speech in the SIDB
(Matsubara et al, 2002). All the data are anno-
tated with information on morphological analysis,
clause boundary detection and dependency anal-
ysis by hand. We performed a cross-validation
experiment by using 16 discourses. That is, we
535
repeated the experiment, in which we used one
discourse from among 16 discourses as the test
data and the others as the learning data, 16 times.
However, since we used 2 discourse among 16
discourses as the preliminary analysis data, we
evaluated the experimental result for the other 14
discourses (1,714 sentences, 20,707 bunsetsus).
Here, we used the maximum entropy method tool
(Zhang, 2008) with the default options except ?-i
2000.?
In the evaluation, we obtained recall, precision
and the ratio of sentences into which all linefeed
points were correctly inserted (hereinafter called
sentence accuracy). The recall and precision are
respectively defined as follows.
recall = # of correctly inserted LFs# of LFs in the correct data
precision = # of correctly inserted LFs# of automatically inserted LFs
For comparison, we established the following
four baseline methods.
1. Linefeeds are inserted into the rightmost bun-
setsu boundaries among the bunsetsu bound-
aries into which linefeeds can be inserted so
that the length of the line does not exceed
the maximum number of characters (Line-
feed insertion based on bunsetsu bound-
aries).
2. Linefeeds are inserted into the all clause
boundaries (Linefeed insertion based on
clause boundaries).
3. Linefeeds are inserted between adjacent bun-
setsus which do not depend on each other
(Linefeed insertion based on dependency
relations).
4. Linefeeds are inserted into the all bunsetsu
boundaries in which a pause exists (Linefeed
insertion based on pauses).
In the baseline 2, 3 and 4, if each condition is not
fulfilled within the maximum number of charac-
ters, a linefeed is inserted into the rightmost bun-
setsu boundary as well as the baseline 1.
In the experiment, we defined the maximum
number of characters per line as 20. The cor-
rect data of linefeed insertion were created by ex-
perts who were familiar with displaying captions.
There existed 5,497 inserted linefeeds in the 14
discourses, which were used in the evaluation.
Table 3: Experimental results
recall (%) precision (%) F-measure
our method 82.66 80.24 81.43
(4,544/5,497) (4,544/5,663)
baseline 1 27.47 34.51 30.59
(1,510/5,497) (1,510/4,376)
baseline 2 69.34 48.65 57.19
(3,812/5,497) (3,812/7,834)
baseline 3 89.48 53.73 67.14
(4,919/5,497) (4,919/9,155)
baseline 4 69.84 55.60 61.91
(3,893/5,497) (3,893/6,905)
5.2 Experimental Result
Table 3 shows the experimental results of the base-
lines and our method. The baseline 1 is very sim-
ple method which inserts linefeeds into the bun-
setsu boundaries so that the length of the line does
not exceed the maximum number of characters per
line. Therefore, the recall and precision were the
lowest.
In the result of baseline 2, the precision was
low. As described in the Section 3.1, the degree
in which linefeeds are inserted varies in differ-
ent types of clause boundaries. In the baseline
2, because linefeeds are also inserted into clause
boundaries which have the tendency that linefeeds
are hardly inserted, the unnecessary linefeeds are
considered to have been inserted.
The recall of baseline 3 was very high. This
is because, in the correct data, linefeeds were
hardly inserted between two neighboring bunset-
sus which are in a dependency relation. However,
the precision was low, because, in the baseline
3, linefeeds are invariably inserted between two
neighboring bunsetsus which are not in a depen-
dency relation.
In the baseline 4, both the recall and precision
were not good. The possible reason is that the bun-
setsu boundaries at which a pause exists do not
necessarily correspond to the linefeed points.
On the other hand, the F-measure and the sen-
tence accuracy of our method were 81.43 and
53.15%, respectively. Both of them were highest
among those of the four baseline, which showed
an effectiveness of our method.
5.3 Causes of Incorrect Linefeed Insertion
In this section, we discuss the causes of the in-
correct linefeed insertion occurred in our method.
Among 1,119 incorrectly inserted linefeeds, the
most frequent cause was that linefeeds were in-
536
??????????????????
????????
That is the period which I call
the first period without apology
Figure 6: Example of incorrect linefeed insertion
in ?adnominal clause.?
??????????????
?????
??????????????
??????????????????
(about how detail I can speak)
(I have a concern)
(from serious story to easy story )
(I want to speak)
Figure 7: Example of extra linefeed insertion
serted into clause boundaries of a ?adnominal
clause? type. The cause occupies 10.19% of the
total number of the incorrectly inserted linefeeds.
In the clause boundaries of the ?adnominal clause?
type, linefeeds should rarely be inserted funda-
mentally. However, in the result of our method,
a lot of linefeeds were inserted into the ?adnomi-
nal clause.? Figure 6 shows an example of those
results. In this example, a linefeed is inserted into
the ?adnominal clause? boundary which is located
right after the bunsetsu ????? (call).? The se-
mantic chunk ????????????? (is the
period which I call)? is divided.
As another cause, there existed 291 linefeeds
which divide otherwise one line according to the
correct data into two lines. Figure 7 shows an ex-
ample of the extra linefeed insertion. Although, in
the example, a linefeed is inserted between ???
???????????? (about how detail I
can speak)? and ?????? (I have a concern),?
the two lines are displayed in one line in the cor-
rect data. It is thought that, in our method, line-
feeds tend to be inserted even if a line has space to
spare.
6 Discussion
In this section, we discuss the experimental results
described in Section 5 to verify the effectiveness
of our method in more detail.
6.1 Subjective Evaluation of Linefeed
Insertion Result
The purpose of our research is to improve the read-
ability of the spoken monologue text by our line-
feed insertion. Therefore, we conducted a subjec-
tive evaluation of the texts which were generated
by the above-mentioned experiment.
In the subjective evaluation, examinees looked
at the two texts placed side-by-side between which
the only difference is linefeed points, and then se-
35
34
40
45
39
48
45
47 47
44
1 2 3 4 5 6 7 8 9 10
Baseline 3
Our method
subject ID
# of sentences
50
45
40
35
30
25
20
15
10
5
0
Figure 8: Result of subjective evaluation
lected the one which was felt more readable. Here,
we compared our method with the baseline 3, of
which F-measure was highest among four base-
lines described in Section 5.1. Ten examinees
evaluated 50 pairs of the results generated from
the same 50 randomly selected sentences.
Figure 8 shows the result of subjective evalua-
tion. This graph shows the number of each method
selected by each examinee. The ratio that our
method was selected was 94% in the highest case,
and 68% even in the lowest case. We confirmed
the effectiveness of our method for improving the
readability of the spoken monologue text.
On the other hand, there existed three sentences
for which more than 5 examinees judged that the
results of baseline 3 were more readable than those
of our method. From the analysis of the three sen-
tences, we found the following phenomena caused
text to be less readable
? Japanese syllabary characters (Hiragana) are
successionally displayed across a bunsetsu
boundary.
? The length of anteroposterior lines is ex-
tremely different each other.
Each example of the two causes is shown in
Figure 9 and 10, respectively. In Figure 9, a
bunsetsu boundary existed between Japanese syl-
labary characters ?????? (I)? and ?????
(if truth be told)? and these characters are succes-
sionally displayed in the same line. In these cases,
it becomes more difficult to identify the bunsetsu
boundary, therefore, the text is thought to become
difficult to read. In Figure 10, since the length of
the second line is extremely shorter than the first
line or third line, the text is thought to become dif-
ficult to read.
537
?????????????
???????????????????
????????
(Actually, I, if truth be told, I)
when I was a college student,  
(I) used to dodge  my train fare and
(be caught )
Actually, I, if truth be told, I used to dodge my train fare and be caught
when I was a college student.
Figure 9: Example of succession of hiragana
??????????????????
???
???????????????????
??????????????
I, the energy resources of which 
the remaining amount became little
in which humans who are in the past 
and future fight
(wrote a science-fiction novel)
(over)
I wrote a science-fiction novel, in which humans who are in the past and future 
fight over the energy resources of which the remaining amount became little.
Figure 10: Lines that have extremely different
length
Table 4: Other annotator?s results
recall (%) precision (%) F-measure
by human 89.82 (459/511) 89.82 (459/511) 89.82
our method 82.19 (420/511) 81.71 (420/514) 81.95
6.2 Comparison with Linefeeds Inserted by
Human
The concept of linefeed insertion for making the
caption be easy to read varies by the individual.
When multiple people insert linefeeds for the same
text, there is possibility that linefeeds are inserted
into different points.
Therefore, for one lecture data (128 sentences,
511 bunsetsus) in the experimental data, we con-
ducted an experiment on linefeed insertion by an
annotator who was not involved in the construc-
tion of the correct data. Table 4 shows the re-
call and the precision. The second line shows
the result of our method for the same lecture
data. In F-measure, our method achieved 91.24%
(81.95/89.82) of the result by the human annotator.
6.3 Performance of Linefeed Insertion Based
on Automatic Natural Language Analysis
In the experiment described in Section 5, we used
the linguistic information provided by human as
the features on the maximum entropy method.
However, compared with baseline 1, our method
uses a lot of linguistic information which should
be provided not by human but by natural language
analyzers under the real situation. Therefore, to
fairly evaluate our method and four baselines, we
conducted an experiment on linefeed insertion by
using the automatically provided information on
clause boundaries and dependency structures5.
5We used CBAP (Kashioka and Maruyama, 2004) as
a clause boundary analyzer and CaboCha (Kudo and Mat-
sumoto, 2002) with default learning data as a dependency
parser.
Table 5: Experimental results when information of
features are automatically provided
recall (%) precision (%) F-measure
our method 77.37 75.04 76.18
(4,253/5,497) (4,253/5,668)
baseline 1 27.47 34.51 30.59
(1,510/5,497) (1,510/4,376)
baseline 2 69.51 48.63 57.23
(3,821/5,497) (3,821/7,857)
baseline 3 84.01 52.03 64.26
(4,618/5,497) (4,618/8,876)
baseline 4 69.84 55.60 61.91
(3,893/5,497) (3.893/6,905)
Table 5 shows the result. Compared with Table
3, it shows the decreasing rate of the performance
of our method was more than those of four base-
lines which use simply only basic linguistic infor-
mation. However, the F-measure of our method
was more than 10% higher than those of four base-
lines.
7 Conclusion
This paper proposed a method for inserting line-
feeds into discourse speech data. Our method can
insert linefeeds so that captions become easy to
read, by using machine learning techniques on fea-
tures such as morphemes, dependencies, clause
boundaries, pauses and line length. An experi-
ment by using transcribed data of Japanese dis-
course speech showed the recall and precision was
82.66% and 80.24%, respectively, and we con-
firmed the effectiveness of our method.
In applying the linefeed insertion technique to
practical real-time captioning, we have to consider
not only the readability but also the simultaneity.
Since the input of our method is a sentence which
tends to be long in spoken monologue, in the fu-
ture, we will develop more simultaneous a tech-
nique in which the input is shorter than a sentence.
In addition, we assumed the speech recognition
system with perfect performance. To demonstrate
practicality of our method for automatic speech
transcription, an experiment using a continuous
speech recognition system will be performed in
the future.
Acknowledgments
This research was partially supported by the
Grant-in-Aid for Scientific Research (B) (No.
20300058) and Young Scientists (B) (No.
21700157) of JSPS, and by The Asahi Glass
Foundation.
538
References
G. Boulianne, J.-F. Beaumont, M. Boisvert,
J. Brousseau, P. Cardinal, C. Chapdelaine,
M. Comeau, P. Ouellet, and F. Osterrath. 2006.
Computer-assisted closed-captioning of live TV
broadcasts in French. In Proceedings of 9th Interna-
tional Conference on Spoken Language Processing,
pages 273?276.
T. Holter, E. Harborg, M. H. Johnsen, and T. Svendsen.
2000. ASR-based subtitling of live TV-programs for
the hearing impaired. In Proceedings of 6th Interna-
tional Conference on Spoken Language Processing,
volume 3, pages 570?573.
R. B. Hoogenboom, K. Uehara, T. Kanazawa,
S. Nakano, H. Kuroki, S. Ino, and T. Ifukube. 2008.
An application of real-time captioning system using
automatic speech recognition technology to college
efl education for deaf and hard-of-hearing students.
Gunma University Annual Research Reports, Cul-
tural Science Series, 57.
T. Imai, S. Sato, A. Kobayashi, K. Onoe, and
S. Homma. 2006. Online speech detection
and dual-gender speech recognition for captioning
broadcast news. In Proceedings of 9th International
Conference on Spoken Language Processing, pages
1602?1605.
H. Kashioka and T. Maruyama. 2004. Segmentation of
semantic units in Japanese monologues. In Proceed-
ings of ICSLT2004 and Oriental-COCOSDA2004,
pages 87?92.
T. Kudo and Y. Matsumoto. 2002. Japanese depen-
dency analysis using cascaded chunking. In Pro-
ceedings of 6th Conference on Computational Natu-
ral Language Learning, pages 63?69.
S. Matsubara, A. Takagi, N. Kawaguchi, and Y. Ina-
gaki. 2002. Bilingual spoken monologue corpus
for simultaneous machine interpretation research.
In Proceedings of 3rd International Conference on
Language Resources and Evaluation, pages 153?
159.
T. Monma, E. Sawamura, T. Fukushima, I. Maruyama,
T. Ehara, and K. Shirai. 2003. Automatic closed-
caption production system on TV programs for
hearing-impaired people. Systems and Computers
in Japan, 34(13):71?82.
C. Munteanu, G. Penn, and R. Baecker. 2007. Web-
based language modelling for automatic lecture tran-
scription. In Proceedings of 8th Annual Conference
of the International Speech Communication Associ-
ation, pages 2353?2356.
M. Saraclar, M. Riley, E. Bocchieri, and V. Gof-
fin. 2002. Towards automatic closed captioning:
Low latency real time broadcast news transcription.
In Proceedings of 7th International Conference on
Spoken Language Processing, pages 1741?1744.
J. Xue, R. Hu, and Y. Zhao. 2006. New improvements
in decoding speed and latency for automatic caption-
ing. In Proceedings of 9th International Conference
on Spoken Language Processing, pages 1630?1633.
L. Zhang. 2008. Maximum entropy mod-
eling toolkit for Python and C++. http:
//homepages.inf.ed.ac.uk/s0450736/
maxent toolkit.html. [Online; accessed
1-March-2008].
539
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1186?1196, Dublin, Ireland, August 23-29 2014.
Japanese Word Reordering Integrated with Dependency Parsing
Kazushi Yoshida
1,a)
Tomohiro Ohno
2,b)
Yoshihide Kato
3,c)
Shigeki Matsubara
1,d)
1
Graduate School of Information Science, Nagoya University, Japan
2
Information Technology Center, Nagoya University, Japan
3
Information & Communications, Nagoya University, Japan
a)
yoshida@db.ss.is.nagoya-u.ac.jp
b)
ohno@nagoya-u.jp
c)
yoshihide@icts.nagoya-u.ac.jp
d)
matubara@nagoya-u.jp
Abstract
Although Japanese has relatively free word order, Japanese word order is not completely arbitrary
and has some sort of preference. Since such preference is incompletely understood, even native
Japanese writers often write Japanese sentences which are grammatically well-formed but not
easy to read. This paper proposes a method for reordering words in a Japanese sentence so
that the sentence becomes more readable. Our method can identify more suitable word order
than conventional word reordering methods by concurrently performing dependency parsing and
word reordering instead of sequentially performing the two processing steps. As the result of an
experiment on word reordering using newspaper articles, we confirmed the effectiveness of our
method.
1 Introduction
Japanese has relatively free word order, and thus Japanese sentences which make sense can be written
without having a strong awareness of word order. However, Japanese word order is not completely
arbitrary and has some sort of preference. Since such preference is incompletely understood, even native
Japanese writers often write Japanese sentences which are grammatically well-formed but not easy to
read. The word reordering of such sentences enables the readability to be improved.
There have been proposed some methods for reordering words in a Japanese sentence so that the
sentence becomes easier to read (Uchimoto et al., 2000; Yokobayashi et al., 2004). In addition, there
exist a lot of researches for estimating appropriate word order in various languages (Filippova and Strube,
2007; Harbusch et al., 2006; Kruijff et al., 2001; Ringger et al., 2004; Shaw and Hatzivassiloglou, 1999).
Although most of these previous researches used syntactic information, the sentences they used there
were what had been previously parsed. It is a problem that word reordering suffers the influence of
parsing errors. Furthermore, as the related works, there are various researches on word reordering for
improving the performance of statistical machine translation (Goto et al., 2012; Elming, 2008; Ge, 2010;
Christoph and Hermann, 2003; Nizar, 2007). These researches consider information as to both a source
language and a target language to handle word order differences between them. Therefore, their problem
setting is different from that for improving the readability of a single language.
This paper proposes a method for reordering words in a Japanese sentence so that the sentence becomes
easier to read for revision support. Our proposed method concurrently performs dependency parsing
and word reordering for an input sentence of which the dependency structure is still unknown. Our
method can identify more suitable word order than conventional word reordering methods because it
can concurrently consider the preference of both word order and dependency. An experiment using
newspaper articles showed the effectiveness of our method.
2 Word Order and Dependency in Japanese Sentences
There have been a lot of researches on Japanese word order in linguistics (for example, Nihongo Kijutsu
Bunpo Kenkyukai, 2009; Saeki, 1998), which have marshalled fundamental contributing factors which
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1186
naganen(for years)
sekaiju-no(all over the world)
hitobito-ga(people)
torikun-de-ki-ta(have tackled)
kare-ga(He)
mondai-wo(theproblem)
tsuini(finally)
S1 (inappropriate word order)
kaiketsu-shi-ta(resolved)
?He finally resolved the problem that people all over the world have tackled for years.?
S2 (appropriate word order)
naganen(for years)
sekaiju-no(all over the world)
hitobito-ga(people)
torikun-de-ki-ta(have tackled)
kare-ga(He)
mondai-wo(theproblem)
tsuini(finally) kaiketsu-shi-ta(resolved)
Figure 1: Example of inappropriate/appropriate word order
decide the appropriate word order in detail. In a Japanese sentence, a predicate of the main clause is
fundamentally placed in last position, and thus, case elements, adverbial elements, or subordinate clauses
are located before it. In addition, case elements are basically placed in the order of a nominative, a dative
and an accusative. However, the basic order of case elements is often changed by being influenced from
grammatical and discourse factors. For example, it is pointed out that a long case element has strong
preference to be located at the beginning of a sentence even if the element is not nominative, as shown
in Figure 1.
In Figure 1, a box and an arrow express a bunsetsu
1
and a dependency relation respectively. Both the
sentences S1 and S2 have the same meaning which is translated as ?He finally resolved the problem that
people all over the world have tackled for years? in English. The difference between S1 and S2 is just in
their word orders in Japanese.
The word order of S1 is more difficult to read than that of S2 because the distance between the bun-
setsu ?kare-ga (He)? and its modified bunsetsu ?kaiketsu-shi-ta (resolved)? is large and thus the loads on
working memory become large. This example suggests that if the dependency structure of S1 is iden-
tified, that information is useful to reorder the word order of S1 to that of S2 so that it becomes easier
to read. In fact, most of the conventional word reordering methods have reordered words using the pre-
viously parsed dependency structure. However, the word order of S1 is thought to be more difficult to
parse than that of S2 because dependency parsers are usually trained on syntactically annotated corpora
in which sentences have the appropriate word order such as that in S2. This is why it is highly possible
that dependency parsing can achieve a higher accuracy by changing the word order of S1 to that of S2 in
advance.
The above observations indicate that word reordering and dependency parsing depend on each other.
Therefore, we consider it is more desirable to concurrently perform the two processings than to sequen-
tially perform them.
3 Word Reordering Method
In our method, a sentence, on which morphological analysis and bunsetsu segmentation have been per-
formed, is considered as the input
2
. We assume that the input sentence might have unsuitable word order,
1
Bunsetsu is a linguistic unit in Japanese that roughly corresponds to a basic phrase in English. A bunsetsu consists of one
independent word and zero or more ancillary words. A dependency relation in Japanese is a modification relation in which a
modifier bunsetsu depends on a modified bunsetsu. That is, the modifier bunsetsu and the modified bunsetsu work as modifier
and modifyee, respectively.
2
In order to focus attention on the comparison between our method and the conventional method, we assumed the input on
which the lower layer processings than dependency parsing have been performed. Even if morphological analysis and bunsetsu
segmentation are automatically performed on input sentences which have unsuitable word order, we can expect the accuracies
1187
which is not easy to read but grammatically well-formed. Our method identifies the suitable word order
which is easy to read by concurrently performing dependency parsing.
The simultaneous performing of dependency parsing and word reordering is realized by searching for
the maximum-likelihood pattern of word order and dependency structure for the input sentence. Note our
method reorders bunsetsus in a sentence without paraphrasing and does not reorder morphemes within a
bunsetsu.
3.1 Probabilistic Model for Word Reordering
When a sequence of bunsetsus in an input sentence B = b
1
? ? ?b
n
is provided, our method identifies the
structure S which maximizes P (S|B). The structure S is defined as a tuple S = ?O,D? where O =
{o
1,2
, o
1,3
, ? ? ? , o
1,n
, ? ? ? , o
i,j
, ? ? ? , o
n?2,n?1
, o
n?2,n
, o
n?1,n
} is the word order pattern after reordering
and D = {d
1
, ? ? ? , d
n?1
} is dependency structure. Here, o
i,j
(1 ? i < j ? n) expresses the order
between b
i
and b
j
after reordering. o
i,j
is 1 if b
i
is located before b
j
, and is 0 otherwise. In addition, d
i
expresses the dependency relation whose modifier bunsetsu is b
i
.
P (S|B) for a S = ?O,D? is calculated as follows.
P (S|B) = P (O,D|B)
=
?
P (O|B) ? P (D|O,B) ? P (D|B) ? P (O|D,B) (1)
Formula (1) is obtained for the product of the following two formulas. According to the probability
theory, the calculated result of Formula (1) is equal to those of Formulas (2) and (3). However, in practice,
since each factor in the formulas is estimated based on the corpus used for training, the calculated results
of these formulas are different from each other. We use Formula (1) to estimate P (S|B) by using both
values of P (D|O,B) and P (O|D,B). In fact, we pre-experimentally confirmed that the calculated
result of Formula (1) was better than those of the others.
P (O,D|B) = P (O|B) ? P (D|O,B) (2)
P (O,D|B) = P (D|B) ? P (O|D,B) (3)
Assuming that order o
i,j
between two bunsetsus is independent of that between other two bunsetsus
and that each dependency relation d
i
is independent of the others, each factor in Formula (1) can be
approximated as follows:
P (O|B)
?
=
n?1
?
i=1
n
?
j=i+1
P (o
i,j
|B) (4)
P (D|O,B)
?
=
n?1
?
i=1
P (d
i
|O,B) (5)
P (D|B)
?
=
n?1
?
i=1
P (d
i
|B) (6)
P (O|D,B)
?
=
n?1
?
i=1
n
?
j=i+1
P (o
i,j
|D,B) (7)
where P (o
i,j
|B) is the probability that the order between b
i
and b
j
is o
i,j
whenB is provided, P (d
i
|O,B)
is the probability that the dependency relation whose modifier bunsetsu is b
i
is d
i
when the sentence
generated by reordering B according to O is provided, P (d
i
|B) is the probability that the dependency
relation whose modifier bunsetsu is b
i
is d
i
when B is provided, and P (o
i,j
|D,B) is the probability
that the order between b
i
and b
j
is o
i,j
when B where the dependency relation is D is provided. These
probabilities are estimated by the maximum entropy method.
remain comparatively high. This is because their processings use mainly local information.
1188
To estimate P (d
i
|O,B), we used the features used in Uchimoto et al. (1999) except when eliminating
features about Japanese commas (called toten, which is a kind of punctuation) and quotation marks.
To estimate P (d
i
|B), we used the features which can be obtained without information about the order
of input bunsetsus among the features used in estimating P (d
i
|O,B). To estimate P (o
i,j
|D,B), if b
i
and b
j
modifies the same bunsetsu, we used the features used in Uchimoto et al. (2000), except when
eliminating features about parallel relations and semantic features. Otherwise, we used the features left
after eliminating features about modified bunsetsus from those used in the above-mentioned case. To
estimate P (o
i,j
|B), we used the features which can be obtained without dependency information among
the features used to estimate P (O
i,j
|D,B).
3.2 Search Algorithm
Since there are a huge number of the structures S = ?O,D? which are theoretically possible for an input
sentence B, an efficient algorithm is desired. However, since O and D are dependent on each other,
it is difficult to find the optimal structure efficiently. In our research, we extend CYK algorithm used
in conventional dependency parsing to efficiently find the suboptimal S = ?O,D? which maximizes
P (S|B) efficiently.
Our research assumes that an input sentence, which is grammatically well-formed, is reordered without
changing the meaning so that the sentence becomes much easier to read. From this assumption, we can
use following conditions for efficient search:
1. The dependency structure of an input sentence should satisfy the following Japanese syntactic con-
straints under the input word order:
? No dependency is directed from right to left.
? Dependencies don?t cross each other.
? Each bunsetsu, except the last one, depends on only one bunsetsu.
2. Even after the words are reordered, the dependency structure should satisfy the above-mentioned
Japanese syntactic constraints under the changed word order.
3. The dependency structures of a sentence before and after reordering should be identical.
Using the condition 1 and the condition 3, we can narrow down the search space of D to dependency
structures that satisfy Japanese syntactic constraints under the input word order. Furthermore, the search
space of O can be narrowed down to the word order patterns derived from the above narrowed depen-
dency structures based on the conditions 2 and 3. That is, after dependency structures possible for an
input sentence are narrowed down, we just have to find the word order patterns after reordering so that
each of the dependency structures is maintained and satisfies the Japanese syntactic constraints even
under the changed word order.
On the other hand, it is well known that CYK algorithm can efficiently find the optimal dependency
structure which satisfies Japanese syntactic constraints. Therefore, in our research, we have extended the
CYK algorithm for the conventional dependency parsing so that it can find the suboptimal D and O from
among the dependency structures and word order patterns which satisfy the conditions 1, 2 and 3.
3.2.1 Word Reordering Algorithm
Algorithm 1 shows our word reordering algorithm. In our algorithm, the n?n triangular matrixM
i,j
(1 ?
i ? j ? n) such as the left-side figure in Figure 2 is prepared for an input sentence consisting of n
numbers of bunsetsus. M
i,j
, the element of the triangular matrix M in the i-th row and j-th column, is
filled by argmax
S
i,j
P (S
i,j
|B
i,j
), which is the maximum-likelihood structure for an input subsequence
B
i,j
= b
i
? ? ? b
j
. In this section, for convenience of explanation, we represent S
i,j
as a sequence of
dependency relations d
x
(i ? x ? j). For example, S
i,j
= d
i
d
i+1
? ? ? d
0
j
means that the first bunsetsu
is b
i
, the second is b
i+1
, ? ? ? , the last is b
j
, and the dependency structure is {d
i
, d
i+1
, ? ? ? , d
j?1
}. Here,
if we need to clearly specify the modified bunsetsu, we represent the dependency relation that bunsetsu
1189
Algorithm 1 word reordering algorithm
1: input B
1,n
= b
1
? ? ? b
n
// input sentence
2: set M
i,j
(1 ? i ? j ? n) // triangular matrix
3: set C
i,j
(1 ? i ? j ? n) // set of structure candidates
4: for i = 1 to n do
5: M
i,i
= d
0
i
6: end for
7: for d = 1 to n? 1 do
8: for i = 1 to n? d do
9: j = i+ d
10: for k = i to j ? 1 do
11: C
i,j
= C
i,j
? ConcatReorder(M
i,k
,M
k+1,j
)
12: end for
13: M
i,j
= argmax
S
i,j
?C
i,j
P (S
i,j
|B
i,j
)
14: end for
15: end for
16: return M
1,n
Candidates generated by 
?By the concatenating process
?By the reordering process
M1,1= M1,2= M1,3= M1,4
M2,2= M2,3= M2,4
M3,3= M3,4=
M4,4=
2 2 3
3 4
4
Candidates generated by 
?By the concatenating process
2 3 4
23 4
? By the reordering process
2 3 4
is filled by the structure which maximizes among the following candidates.
Candidate 1:
Candidate 3:
Candidate 2:
? means that is located  before and depends on . For example, i j
?is filled by the maximum-likelihood 
structure for a subsequence from to .
3
1 1 2 2 31
No candidate is generated because has no child in .2 31 means .
by moving after , which is the first child of in 
Figure 2: Execution example of our search algorithm
b
x
modifies b
y
as d
y
x
. In addition, d
0
j
means that the last bunsetsu of the subsequence don?t modify any
bunsetsu.
First, the statements of the lines 4 to 6 fill each of diagonal elements M
i,i
(1 ? i ? n) with d
0
i
. Next,
the statements of the lines 7 to 15 fill M
i,j
in turn toward the upper right M
1,n
along the diagonal line,
starting from the diagonal elements M
i,i
. The maximum-likelihood structure which should fill an M
i,j
is found as follows:
The statements of the lines 10 to 12 repeat the process of generating candidates of the maximum-
likelihood structure from M
i,k
and M
k+1,j
by the function ConcatReorder, and adding them to the set
of structure candidates C
i,j
. The function ConcatReorder takes two arguments ofM
i,k
andM
k+1,j
and
returns the set of candidates of the maximum-likelihood structure which should fill M
i,j
. The function
ConcatReorder is composed of two processes: concatenating process and reordering process. First,
the concatenating process generates a candidate by simply concatenating M
i,k
and M
k+1,j
in turn about
the word order and connecting M
i,k
and M
k+1,j
by the dependency relation between the last bunsetsus
of them about the dependency structure, without changing the internal structure of each of them. For
example, whenM
i,k
= d
i
d
i+1
? ? ? d
k?1
d
0
k
andM
k+1,j
= d
k+1
d
k+2
? ? ? d
j?1
d
0
j
are given as the argument,
the concatenating process generates ?d
i
d
i+1
? ? ? d
k?1
d
j
k
d
k+1
d
k+2
? ? ? d
j?1
d
0
j
.?
1190
Second, the reordering process generates candidates by reordering words in the candidate generated
by the concatenating process. The reordering is executed on the following conditions. The first condition
is that the dependency structure is maintained and satisfies the Japanese syntactic constraints even under
the changed word order. The second condition is that the order of any two words within each of M
i,k
and M
k+1,j
is maintained. Concretely, the first reordered candidate is generated by moving M
i,k
after
the first (leftmost) child
3
of the last bunsetsu of M
k+1,j
among the children in M
k+1,j
. Then, the sec-
ond reordered candidate is generated by moving M
i,k
after the second child. The reordering process is
continued until the last reordered candidate is generated by moving M
i,k
after the last child. That is, the
number of candidates generated by the reordering process is equal to the number of children of the last
bunsetsu in M
k+1,j
. For example, when M
i,k
= d
i
d
i+1
? ? ? d
k?1
d
0
k
and M
k+1,j
= d
j
k+1
d
j
k+2
? ? ? d
j
j?1
d
0
j
,
which means all bunsetsus except the last one depend on the last one, are given, the reordering
process generates the following j ? k? 1 candidates: ?d
j
k+1
d
i
d
i+1
? ? ? d
k?1
d
j
k
d
j
k+2
d
j
k+3
? ? ? d
j
j?1
d
0
j
,?
?d
j
k+1
d
j
k+2
d
i
d
i+1
? ? ? d
k?1
d
j
k
d
j
k+3
d
j
k+4
? ? ? d
j
j?1
d
0
j
,? . . ., and ?d
j
k+1
d
j
k+2
? ? ? d
j
j?1
d
i
d
i+1
? ? ? d
k?1
d
j
k
d
0
j
.?
Therefore, in this case, the function ConcatReorder finally returns the set of candidates of which size
is j?k, which includes the candidates generated by the reordering process and a candidate generated by
the concatenating process. Next, in the line 13, our algorithm fills in argmax
S
i,j
?C
i,j
P (S
i,j
|B
i,j
) which
is the maximum-likelihood structure for a subsequence B
i,j
on M
i,j
.
Finally, our algorithm outputs M
1,n
as the maximum-likelihood structure of word order and depen-
dency structure for the input sentence.
Note that if the function ConcatReorder is changed to the function Concat in the line 11, our algorithm
becomes the same as CYK algorithm used in the conventional dependency parsing. The functionConcat
takes two arguments of M
i,k
and M
k+1,j
and generates a candidate of the maximum-likelihood structure
which should fill M
i,j
by the same way as the concatenating process in the function ConcatReorder.
Then, the function Concat returns the set which has the generated candidate as a element, of which size
is 1.
3.2.2 Execution Example of Word Reordering Algorithm
Figure 2 represents an example of execution of our word reordering algorithm in n = 4. The left side
of Figure 2 represents the triangle diagram which has 4 ? 4 dimensions. The elements of the triangle
diagram M
1,1
,M
2,2
,M
3,3
,M
4,4
,M
1,2
,M
2,3
,M
3,4
, and M
1,3
have already been filled in turn, and M
2,4
is being filled. The right side of Figure 2 shows the process of calculating the maximum-likelihood
structure which should fill M
2,4
. First, in the loop from the line 10 to the line 12 in Algorithm 1,
two structure candidates are generated by ConcatReorder(M
2,2
,M
3,4
). The candidate 1 is generated
by the concatenating process, that is, by simply concatenating M
2,2
and M
3,4
and connecting the last
bunsetsu of M
2,2
and that of M
3,4
. The candidate 2 is generated by the reordering process, that is, by
moving M
2,2
after b
3
, which is the first child of b
4
in M
3,4
. Second, the candidate 3 is generated by
the concatenating process in ConcatReorder(M
2,3
,M
4,4
). On the other hand, the reordering process in
ConcatReorder(M
2,3
,M
4,4
) generates no candidates because b
4
has no child inM
4,4
. Among the three
structures generated in the above way, the structure which maximizes P (S
2,4
|B) = P (O
2,4
, D
2,4
|B
2,4
)
fills M
2,4
.
4 Experiment
To evaluate the effectiveness of our method, we conducted an experiment on word reordering by using
Japanese newspaper articles.
4.1 Outline of Experiment
In the experiment, as the test data, we used sentences generated by only changing the word order of
newspaper article sentences in Kyoto Text Corpus (Kurohashi and Nagao, 1998), maintaining the depen-
dency structure. That is, we artificially generated sentences which made sense but were not easy to read,
3
When b
i
depends on b
j
, we call b
i
as a child of b
j
. Furthermore, if b
j
has more than or equal to one child, the children are
numbered from left to right based on their positions.
1191
kokkai-wo(the Diet)
toot-ta
(passed)
ato-demo(Even after)
seron-chosa-de-wa(according to opinion polls)
shohi-ze-zoze-ga(the consumption tax hike bill)
zoze-hantai-ga(opposing views to the bill)
Original sentence in newspaper articles (correct word order)
taise-da(are in majority)
?Even after the Diet passed the consumption tax hike bill,according to opinion polls opposing views to the bill are in majority.?
Test data (input sentence)
test data generation
kokkai-wo(the Diet)
toot-ta
(passed)
ato-demo(Even after)
seron-chosa-de-wa(according to opinion polls)
shohi-ze-zoze-ga(the consumption tax hike bill)
zoze-hantai-ga(opposing views to the bill)
taise-da(are in majority)
Figure 3: Example of test data generation
in order to focus solely on problems caused by unsuitable word order. Figure 3 shows an example of the
test data generation. The generation procedure is as follows:
1. Find a bunsetsu modified by multiple bunsetsus from the sentence end.
2. Change randomly the order of the sub-trees which modify such bunsetsu.
3. Iterate 1 and 2 until reaching the beginning of the sentence.
In Figure 3, the bunsetsus ?taise-da (are in the majority)? and ?toot-ta (passed)? are found as bunsetsus
modified by multiple bunsetsus. For example, when ?toot-ta (passed)? is found, the order of ?shohi-
ze-zoze-ga (the consumption tax hike bill)? and ?kokkai-wo (the Diet)? is randomly changed. In this
experiment, all Japanese commas (toten) in a sentence, and sentences which have quotation marks were
removed.
In this way, we artificially generated 865 sentences (7,620 bunsetsus) from newspaper articles of Jan.
9 in Kyoto Text Corpus and used them as the test data. As the training data, we used 7,976 sentences in 7
days? newspaper articles (Jan. 1, 3-8). Here, we used the maximum entropy method tool (Zhang, 2008)
with the default options except ?-i 1000.?
In the evaluation of word reordering, we obtained the following two measurements, which are defined
by Uchimoto et al. (2000):
? complete agreement: the percentage of the sentences in which all words? order completely agrees
with that of the original sentence.
? pair agreement: the percentage of the pairs of bunsetsus whose word order agrees with that in the
original sentence. (For example, in Figure 3, if the word order of the input sentence is not changed
after reordering, the pair agreement is 52.4% (= 11/
7
C
2
) because the 11 pairs out of the
7
C
2
pairs
are the same as those in the original sentence.)
In the evaluation of dependency parsing, we obtained the dependency accuracy (the percentage of
correctly analyzed dependencies out of all dependencies) and sentence accuracy (the percentage of
the sentences in which all the dependencies are analyzed correctly), which are defined by Sekine et al.
(2000).
For comparison, we established two baselines. Both of the baselines execute the dependency pars-
ing primarily, and then, perform the word reordering by using the conventional word reordering method
1192
Table 1: Experimental results (word reordering)
pair agreement complete agreement
our method 77.3% (30,190/38,838) 25.7% (222/865)
baseline 1 75.4% (29,279/38,838)
*
23.8% (206/865)
baseline 2 74.8% (29,067/38,838)
*
23.5% (203/865)
no reordering 61.5% (23,886/38,838)
*
8.0% (69/865)
*
Note that the agreements followed by * differ signifi-
cantly from those of our method (p < 0.05).
Table 2: Experimental results (dependency parsing)
dependency accuracy sentence accuracy
our method 78.4% (5,293/6,755) 35.3% (305/865)
baseline 1 79.2% (5,350/6,755) 31.6% (273/865)
*
baseline 2 81.2% (5,487/6,755)
*
32.1% (278/865)
*
Note that the accuracies followed by * differ sig-
nificantly from those of our method (p < 0.05).
(Uchimoto et al., 1999). The difference between the two is the method of dependency parsing. The
baselines 1 and 2 use the dependency parsing method proposed by Uchimoto et al. (2000) and the de-
pendency parsing tool CaboCha (Kudo and Matsumoto, 2002), respectively. The features used for the
word reordering in both the baselines are the same as those used to estimate P (o
i,j
|D,B) in our method.
Additionally, the features used for the dependency parsing in the baseline 1 are the same as those used to
estimate P (d
i
|O,B) in our method.
4.2 Experimental Results
Table 1 shows the experimental results on word reordering of our method and the baselines. Here, the
last row shows the agreements measured by comparing the input word order with the correct word order.
The agreements mean the values which can be achieved with no reordering
4
. The pair and complete
agreements of our method were highest among all. The pair agreement of our method is significantly
different from those of both the baselines (p < 0.05) although there is no significant difference between
the complete agreements of them.
Next, Table 2 shows the experimental results on dependency parsing. The sentence accuracy of our
method is significantly higher than those of both the baselines (p < 0.05). On the other hand, the
dependency accuracy of our method is significantly lower than that of the baseline 2 although there is no
significant difference between the dependency accuracies of our method and the baseline 1 (p > 0.05).
Here, if the input sentences had the correct word order, the dependency accuracies of the baselines 1 and
2 were 86.4% (5,835/6,755) and 88.1% (5,950/6,755), respectively. We can see that the unsuitable word
order caused a large decrease of the accuracies of the conventional dependency parsing methods. This is
why the word order agreements of the baselines were decreased.
Figure 4 shows an example of sentences of which all bunsetsus were correctly reordered and the de-
pendency structure was correctly parsed only by our method. We can see that our method can achieve
the complicated word reordering. On the other hand, Figure 5 shows an example of sentences incorrectly
reordered and parsed by our method. In this example, our method could not identify the correct modified
bunsetsu and the appropriate position of the bunsetsu ?arikata-wo (whole concept).? This is because the
dependency probability between the bunsetsu ?arikata-wo (whole concept)? and the bunsetsu ?fukume
4
Some input sentences were in complete agreement with the original ordering. There were some cases that the randomly
reordered sentences accidentally have the same word order as the original ones. In addition, there were some sentences in
which all bunsetsus except the last one depend on the next bunsetsu. The word order of such sentences is not changed by the
test data generation procedure because the procedure is executed on condition of maintaining the dependency structure.
1193
Input sentence(inappropriate word order) 
?Although I myself do not have an experience with a war, I think any generation should not glorify war.?
Output sentence(correct word order and dependency structure) itsu-no(any) sedai-mo(generation) bika-su-beki-de-nai-to(should not glorify)
senso-wo(with a war)
senso-wo(war)
taiken-shi-ta(have an  experience)
koto-wa(?)
watashi-jishin(I myself)
omou
(think)
itsu-no(any)
sedai-mo
(generation)
bika-su-beki-de-nai-to(should not glorify)
senso-wo(with a war)
senso-wo(war)
taiken-shi-ta(have an  experience)
koto-wa(?)
watashi-jishin(I myself)
nai-ga
(although do not)
omou
(think)
nai-ga
(although do not)
:  shows an alignment of a bunsetsu before and after reordering.:  shows a correct dependency relation.?  :  means there is no English word corresponding to the Japanese word.
Figure 4: Example of sentences correctly reordered and parsed by our method
?Whole concept of the examination of rice should be fundamentally revised including the transfer of control to a private sector or prefectural and city governments.?
Input sentence(inappropriate word order) 
Output sentence(incorrect word order and dependency structure)
kensa-no(of the exami-nation)
arikata-wo(whole concept)
todofuken-ya(or prefectural and city governments)
minkan-e-no(to a private sector)
kome-no(of rice)
ikan-mo(the transferof control)
fukume
(including)
konpon-teki-ni(fundamen-tally)
minaosu-beki-daro(should be revised)
Original sentence(correct word order and dependency structure)
kensa-no(of the exami-nation)
arikata-wo(whole concept)
todofuken-ya(or prefectural and city governments)
minkan-e-no(to a private sector)
kome-no(of rice)
ikan-mo(the transferof control)
fukume
(including)
konpon-teki-ni(fundamen-tally)
minaosu-beki-daro(should be revised)
kensa-no(of the exami-nation)
arikata-wo(whole concept)
todofuken-ya(or prefectural and city governments)
minkan-e-no(to a private sector)
kome-no(of rice)
ikan-mo(the transferof control)
fukume
(including)
konpon-teki-ni(fundamen-tally)
minaosu-beki-daro(should be revised)
: shows an alignment of a bunsetsu before and after reordering.:  shows a correct dependency relation.:  shows an incorrect dependency relation.
Figure 5: Example of sentences incorrectly reordered and parsed by our method
(including)? is higher than the one between the bunsetsu ?arikata-wo (whole concept)? and the bunsetsu
?minaosu-beki-daro (should be revised)?, and the probability that the bunsetsu ?arikata-wo (whole con-
cept)? is located at the left side of ?fukume (including)? is higher than that of the right side. Since the
word order of the output sentence has a strong probability of causing a wrong interpretation like ?The
transfer of control to a private sector or prefectural and city governments should be fundamentally re-
vised including whole concept of the examination of rice.?, this reordering has a harmful influence on
the comprehension. We need to study techniques for avoiding the word order which causes the change
of meanings in an input sentence.
From the above, we confirmed the effectiveness of our method on word reordering and dependency
parsing of a sentence of which the word order is not easy to read.
5 Conclusion
This paper proposed the method for reordering bunsetsus in a Japanese sentence. Our method can identify
suitable word order by concurrently performing word reordering and dependency parsing. Based on the
1194
idea of limiting the search space using the Japanese syntactic constraints, we made the search algorithm
by extending the CYK algorithm used in the conventional dependency parsing, and found the optimal
structure efficiently. The result of the experiment using newspaper articles showed the effectiveness of
our method.
In our future works, we would like to collect sentences written by Japanese subjects who do not have
much writing skills, to conduct an experiment using those sentences. In addition, we would like to
conduct a subjective evaluation to investigate whether the output sentences are indeed more readable
than the input ones.
Acknowledgments
This research was partially supported by the Grant-in-Aid for Young Scientists (B) (No.25730134) and
Challenging Exploratory Research (No.24650066) of JSPS.
References
Tillmann Christoph and Ney Hermann. 2003. Word reordering and a dynamic programming beam search
algorithm for statistical machine translation. Computational Linguistics, 29(1):97?133.
Jakob Elming. 2008. Syntactic reordering integrated with phrase-based SMT. In Proceedings of the
22nd International Conference on Computational Linguistics (COLING2008), pages 209?216.
Katja Filippova and Michael Strube. 2007. Generating constituent order in German clauses. In Proceed-
ings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL2007), pages
320?327.
Niyu Ge. 2010. A direct syntax-driven reordering model for phrase-based machine translation. In
Proceedings of Human Language Technologies: The 11th Annual Conference of the North American
Chapter of the Association for Computational Linguistics (NAACL-HLT2010), pages 849?857.
Geert-Jan M. Kruijff, Ivana Kruijff-Korbayov?a, John Bateman, and Elke Teich. 2001. Linear order as
higher-level decision: Information structure in strategic and tactical generation. In Proceedings of the
8th European Workshop on Natural Language Generation (ENLG2001), pages 74?83.
Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012. Post-ordering by parsing for Japanese-English
statistical machine translation. In Proceedings of the 50th Annual Meeting of the Association for
Computational Linguistics (ACL2012), pages 311?316.
Karin Harbusch, Gerard Kempen, Camiel van Breugel, and Ulrich Koch. 2006. A generation-oriented
workbench for performance grammar: Capturing linear order variability in German and Dutch. In
Proceedings of the 4th International Natural Language Generation Conference (INLG2006), pages
9?11.
Nihongo Kijutsu Bunpo Kenkyukai, editor. 2009. Gendai nihongo bunpo 7 (Contemporary Japanese
Grammar 7), pages 165?182. Kuroshio Shuppan. (In Japanese).
Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Pro-
ceedings of the 6th Conference on Computational Natural Language Learning (CoNLL2002), pages
63?69.
Sadao Kurohashi and Makoto Nagao. 1998. Building a Japanese parsed corpus while improving the
parsing system. In Proceedings of the 1st International Conference on Language Resources and
Evaluation (LREC ?98), pages 719?724.
Habash Nizar. 2007. Syntactic preprocessing for statistical machine translation. In Proceedings of the
11th Machine Translation Summit (MT SUMMIT XI), pages 215?222.
Eric Ringger, Michael Gamon, Robert C. Moore, David Rojas, Martine Smets, and Simon Corston-
Oliver. 2004. Linguistically informed statistical models of constituent structure for ordering in sen-
tence realization. In Proceedings of the 20th International Conference on Computational Linguis-
tics (COLING2004), pages 673?679.
1195
Tetsuo Saeki. 1998. Yosetsu nihonbun no gojun (Survey: Word Order in Japanese Sentences). Kuroshio
Shuppan. (In Japanese).
Satoshi Sekine, Kiyotaka Uchimoto, and Hitoshi Isahara. 2000. Backward beam search algorithm for de-
pendency analysis of Japanese. In Proceedings of the 18th International Conference on Computational
Linguistics (COLING2000), volume 2, pages 754?760.
James Shaw and Vasileios Hatzivassiloglou. 1999. Ordering among premodifiers. In Proceedings of the
37th Annual Meeting of the Association for Computational Linguistics (ACL ?99), pages 135?143.
Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara. 1999. Japanese dependency structure analysis
based on maximum entropy models. In Proceedings of the 9th Conference of the European Chapter
of the Association for Computational Linguistics (EACL ?99), pages 196?203.
Kiyotaka Uchimoto, Masaki Murata, Qing Ma, Satoshi Sekine, and Hitoshi Isahara. 2000. Word order
acquisition from corpora. In Proceedings of the 18th International Conference on Computational
Linguistics (COLING2000), volume 2, pages 871?877.
Hiroshi Yokobayashi, Akira Suganuma, and Rin-ichiro Taniguchi. 2004. Generating candidates for
rewriting based on an indicator of complex dependency and it?s application to a writing tool. Journal
of Information Processing Society of Japan, 45(5):1451?1459. (In Japanese).
Le Zhang. 2008. Maximum entropy modeling toolkit for Python and C++. http://homepages.
inf.ed.ac.uk/s0450736/maxent_toolkit.html. [Online; accessed 1-March-2008].
1196
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 892?901,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Automatic Comma Insertion for Japanese Text Generation
Masaki Murata
Graduate School of
Information Science,
Nagoya University, Japan
murata@el.itc.nagoya-u.ac.jp
Tomohiro Ohno
Graduate School of
International Development,
Nagoya University, Japan
ohno@nagoya-u.jp
Shigeki Matsubara
Graduate School of
Information Science,
Nagoya University, Japan
matubara@nagoya-u.jp
Abstract
This paper proposes a method for automat-
ically inserting commas into Japanese texts.
In Japanese sentences, commas play an im-
portant role in explicitly separating the con-
stituents, such as words and phrases, of a sen-
tence. The method can be used as an ele-
mental technology for natural language gen-
eration such as speech recognition and ma-
chine translation, or in writing-support tools
for non-native speakers. We categorized the
usages of commas and investigated the ap-
pearance tendency of each category. In this
method, the positions where commas should
be inserted are decided based on a machine
learning approach. We conducted a comma
insertion experiment using a text corpus and
confirmed the effectiveness of our method.
1 Introduction
In Japanese sentences, commas are inserted to mark
word boundaries that might be otherwise unclear be-
cause Japanese is a non-segmented language. They
are also inserted at sharp semantic boundaries to im-
prove the readability of a sentence. While there is a
tendency about the positions where commas should
be inserted in a Japanese sentence, there is no clear
standard for these positions. Therefore, it is hard
for non-natives of Japanese such as foreign students
to insert commas properly, and the method for au-
tomatic comma insertion is required to support sen-
tence generation by such people. In addition, this
method is expected to be useful for improving read-
ability of texts generated by automatic speech recog-
nition or machine translation.
This paper proposes a method for automatically
inserting commas into Japanese texts. There are
several usages of commas, and the positions to in-
sert commas depend on these usages. Therefore,
we grouped the usages of commas into nine cate-
gories, and investigated the appearance tendency for
each category to find the effective features of ma-
chine learning by using Japanese newspaper arti-
cles. Based on the analysis of comma positions, our
method decides whether or not to insert a comma
at each bunsetsu1 boundary in an input sentence by
machine learning.
We conducted an experiment on comma insertion
using the Kyoto Text Corpus (Kurohashi and Nagao,
1998), and obtained higher recall and precision than
those of the baseline, leading us to confirm the ef-
fectiveness of our method.
This paper is organized as follows: The next sec-
tion presents related works. Section 3 gives prelim-
inary analyses. Section 4 explains how our comma
insertion method works. An experiment and discus-
sions are presented in Sections 5 and 6, respectively.
2 Related Works
There have been many investigations on comma in-
sertion into output texts of speech recognition sys-
tems to improve the readability (Christensen et al,
2001; Kim and Woodland, 2001; Liu et al, 2006;
Shimizu et al, 2008). Their methods insert commas
using pause information of speakers, based on the
idea that a point at which a speaker takes a breath
partly corresponds to a point where a comma is in-
serted. However, since pause information cannot be
obtained from texts, we cannot use this approach be-
cause our targets are written texts.
In addition, there have been some investigations
1Bunsetsu is a linguistic unit in Japanese that roughly corre-
sponds to a basic phrase in English. A bunsetsu consists of one
independent word and zero or more ancillary words.
892
on comma insertion into non-Japanese written texts
(White and Rajkumar, 2008; Guo et al, 2010). In
Japanese, there are several usages of commas, and
some usages are specific to Japanese due to its lin-
guistic nature. Therefore, just adopting the above
mentioned methods, which have been developed
to process non-Japanese texts, is not sufficient to
enable high-quality comma insertion into Japanese
sentences. Development of a method based on the
detailed analysis of Japanese commas is required.
Furthermore, there have been some investiga-
tions on comma insertion into Japanese written texts
(Hayashi, 1992; Suzuki et al, 1995). These investi-
gations have adopted rule-based methods. However,
the number of their rules is not necessarily sufficient,
and no quantitative evaluation has been performed.
3 Analyses on Comma Usages
There have been several discussions on commas,
including the draft of ?Kutou-hou (punctuation)?
made by Archives Division, Minister?s Secretariat,
Japanese Ministry of Education, Science and Cul-
ture in 1906. There are several usages of commas,
and depending on the usage, the types of positions
where commas are inserted are different. First, we
examined some previous publications on commas
(Honda, 1982; Inukai, 2002; Shogakukan?s editior-
ial department, 2007). Based on the results of the ex-
amination, we classified the usages of commas into
nine categories shown in Table 1. Here, commas
in Japanese sentences and commas in English sen-
tences have some common roles. In Japanese sen-
tences, some commas have the same roles as com-
mas in English sentences, but some commas have
roles specific to Japanese due to its linguistic nature
such as ?Japanese is a non-segmented language? or
?Japanese has kanji characters and katakana charac-
ters.?
In our study, positions where a comma should
be inserted are detected by using machine learning.
We investigated the Kyoto Text Corpus version 4.0
(Kurohashi and Nagao, 1998) to find the effective
features. The Kyoto Text Corpus is a collection of
Japanese articles of Mainichi newspaper. We used
the articles on January 1st and from January 3rd to
11th in 1995 as the analysis data. Table 2 shows
the size of the data. The data had been manually
Table 1: Categorization of usages of commas
# usage of comma
1 commas between clauses
2 commas indicating clear dependency relations
3 commas for avoiding reading mistakes and
reading difficulty
4 commas indicating the subject
5 commas inserted after a conjunction or
adverb at the beginning of a sentence
6 commas inserted between parallel words or
phrases
7 commas inserted after an adverbial phrase to
indicate time
8 commas emphasizing the adjacent word
9 other
Table 2: Size of the analysis data
sentences 11,821
bunsetsus 117,501
characters 503,970
commas 16,595
characters per sentence 42.63
annotated with information on morphological anal-
ysis, bunsetsu segmentation and dependency2 anal-
ysis. Clause boundaries were detected by the clause
boundary detection program CBAP (Kashioka and
Maruyama, 2004).
Out of all the inserted commas, only 1.43%
were inserted at positions which were not bunsetsu
boundaries. Therefore, we analyzed only commas
inserted at bunsetsu boundaries. Of 105,680 bun-
setsu boundaries, commas were inserted at 16,357
bunsetsu boundaries, that is, the rate of comma
insertion was 15.48%. In the following sections,
we focus on morphemes, clause boundaries, depen-
dency relation and the number of characters between
commas, and investigate their relations with com-
mas.
3.1 Commas between Clauses
If a sentence consists of several clauses, inserting
a comma between clauses makes clear the sentence
2A dependency in a Japanese sentence is a modification re-
lation in which a modifier bunsetsu depends on a modified bun-
setsu. That is, the modifier bunsetsu and the modified bunsetsu
work as a modifier and a modifyee, respectively.
893
Table 3: Rates of comma insertion according to the clause
boundary type
type of clause boundary ratio of comma
insertion (%)
topicalized element-wa 16.94 (1,446/8,536)
adnominal clause 0.72 (43/5,960)
continuous clause 84.57 (2,685/3,175)
compound clause-te 23.31 (394/1,690)
quotational clause 4.40 (74/1,680)
supplement clause 17.53 (245/1,398)
discourse marker 60.13 (650/1,081)
compound clause-ga 93.85 (946/1,008)
compound clause-de 84.52 (606/717)
condition clause-to 81.66 (423/518)
structure. Therefore, a clause boundary is consid-
ered to be a strong candidate of a position where a
comma is inserted. For example, in the following
sentence3:
? ??????????????????????
?????????????????????
(Toward lifting the sanctions imposed on Iraq by
United Nations, the aim seems to be to request fur-
ther cooperation from France, which has close ties
to Iraq.)
a comma is inserted at the clause boundary right af-
ter the continuous clause ???????????
??? (Toward lifting the sanctions imposed
on Iraq by United Nations).? Like this example, the
same usage of commas is seen in English as well.
In the analysis data, there existed 29,278 clause
boundaries excluding sentence breaks. Among
them, commas were inserted at 8,805 positions
(30.01%). The rate is higher than that of bunsetsu
boundaries. This indicates that commas tend to be
inserted at clause boundaries.
We investigated the rate of comma insertion about
114 types4 of clause boundaries. Table 3 shows the
top 10 clause boundary types according to the oc-
currence frequency, and the rates of comma inser-
3We underlined commas which we mentioned in the exam-
ple and the corresponding positions in the translation of the ex-
ample.
4In our research, we used the types of clause boundaries de-
fined by the Clause Boundary Annotation Program (Kashioka
and Maruyama, 2004).
!"#$%&'()*+,-./.012345678#9:;1<=>?@ABC6*DE>1FG+HIJKLMBC6N!"#$%&'()*+',+$-.,/0.&$($,.#1.2$/3$1+.$42/*1+$/3$1+.$*/256)$1+.$&12/#4$72.&.#,.$/3$8+'#($#/1$/#59$-2'#4&$+/7.$-:1$(5&/$,(:&.&$6'33',:51$72/-5.0&;<!!"#$%&$" !'%(%#'%#)*+,%-.&/0#
!"#
!"#$%&#'!()*
$%&'()*
+#,&-$&(#!"#$%&#.(!'$%
+,-
/&,!0&1
./.0
2-#312+
12345
1$(!-.
67#
!"#4%2-+
89:
5(&1&-,&
;<=
%!5&
>?@AB5*CD=
-!$#!-)6#/(2-.1
EF+
*2""2,7)$
GHI
5(!/)&01
JKLAB5
,+71&1
Figure 1: Commas making clear dependency relations
tion. In cases of ?continuous clause? and ?com-
pound clause-de,? the rates were higher than 84%.
On the other hand, in cases of ?adnominal clause?
and ?quotational clause,? the rates were lower than
5%. This means that the likelihoods of comma inser-
tion are different according to the clause boundary
type.
3.2 Commas and Dependency Structure
Commas have a role to make dependency relations
clearer. Commas tend to be inserted right after a
bunsetsu that depends on a distant bunsetsu. In Fig-
ure 1, although the bunsetsu ?? ? (in Asia)?
depends on the bunsetsu ?? ? ? (causes),?
if the comma right after the bunsetsu ????? (in
Asia)? is not inserted, the readers might mistakenly
understand that the bunsetsu ????? (in Asia)?
depends on the next bunsetsu ?????? (strong).?
To avoid the mistake, the comma is inserted.
In the analysis data, there existed 66,984 bunset-
sus which depend on the next bunsetsu. Among the
bunsetsu boundaries right after them, 2,302 (3.44%)
were the positions where a comma was inserted. On
the other hand, in the case of a bunsetsu bound-
ary right after a bunsetsu which does not depend on
the next bunsetsu, the rate of comma insertion was
36.32% (14,055/38,696).
In addition, when the modifyee of a bunsetsu is
located outside the clause containing the bunsetsu,
i.e. to the right of the clause end, commas are con-
sidered to be more frequently inserted right after the
bunsetsu because such bunsetsu causes more com-
plex dependency structure. The rate of comma in-
sertion right after such bunsetsu is 54.24%.
894
3.3 Commas for Avoiding Reading Mistakes
and Reading Difficulty
Although, unlike English, Japanese is a non-
segmented language, word boundaries are easy to
detect because Japanese has three types of charac-
ters; hiragana characters, katakana characters, and
kanji characters. However, if the same types of char-
acters appear sequentially, readers may make a read-
ing mistake or feel difficulty in reading them. To
avoid such mistakes and difficulty, there is a usage
of commas specific to Japanese.
In the following example, a comma is inserted
between two sequentially appearing words ??
(burned)? and ?? (ashes)? both of which consist of
only kanji characters.
? ?????????????????????
??????????????????????
??????????(He seemed to acknowledge
that he had carried the corpse of Mr. Kawasaki to an
acquaintance in Hanasaki, Katashina-mura, Tone-
gun, Gunma Prefecture, burned it and abandoned
its ashes in the mountain forest in Katashina-mura.)
The comma was inserted because if there was no
comma, the word boundary would become unclear
and reading difficulty would be caused. Among
2,409 bunsetsu boundaries over which kanji charac-
ters appeared sequentially, commas were inserted at
2,188 (90.83%) bunsetsu boundaries. In the case of
katakana characters, the rate was 97.69% (211/216).
Commas tend to be inserted at most bunsetsu bound-
aries if kanji characters or katakana characters se-
quentially appear over a boundary.
3.4 Commas Indicating the Subject
Commas are considered to be inserted right after a
bunsetsu that represents the subject of a sentence.
For example, in Figure 2, a comma is inserted right
after the bunsetsu ??? (war)? to indicate that the
bunsetsu is the subject of the sentence. Here, we pay
attention to the clause boundary of the type ?topi-
calized element-wa.? The rate that commas were in-
serted at the clause boundaries ?topicalized element-
wa? was 16.94% (1,446/8,536). This rate is almost
the same as that of bunsetsu boundaries. On the
other hand, the commas inserted at the clause bound-
aries ?topicalized element-wa? accounted for 8.84%
(1,446/16,357) of all the inserted commas.
!"#$%&'()*+,-./"01234567-809:;<34=>?@ABC!"#$%&'#()*#+&#,)-.%/+) 0)1#2345#)()6#732%&'#8*%-#)#/393$%4-3&5:#)&/#0)1#+1%$)53/#503#*+93*#8*%-#4%$$;5+%&#35<=>!"#$%&'!"#$%&'()!% ()*("+ *+,,%- -."/./0("+ 01231-(&#%)/2/*(3&/"4 4565%6#0/34#%,%7 7/45/#-!2/- 89:;231-(&#3(**84!("#/49: <=>?@A5%6#!6(*%4/)!!"#$%&$" !'%(%#'%#)*+,%-.&/0#
Figure 2: Comma insertion at the clause boundary ?topi-
calized element-wa?
In the case of the clause boundary ?topicalized
element-wa? right after a bunsetsu which does not
depend on the next bunsetsu (e.g., the bunsetsu ??
? (war)? in Figure 2), the rate of comma inser-
tion was 20.71% (1,426/6,886). The rate is higher
than that of all the clause boundaries ?topicalized
element-wa.? This shows that commas tend to be
especially inserted at the ?topicalized element-wa?
right after bunsetsus which do not depend on the
next bunsetsu.
3.5 Commas after Conjunction or Adverb
Commas tend to be inserted right after a conjunc-
tion or an adverb located at the beginning of a sen-
tence. These commas correspond to English com-
mas which are inserted right after a word such as
?however? and ?furthermore? located at the begin-
ning of a sentence.
? ??????????????????????
(However, I do not feel like agreeing on it.)
In the analysis data, there existed 695 bunset-
sus whose rightmost morpheme is a conjunction
and which are located at the beginning of a sen-
tence. Among them, commas were inserted right
after 498 (71.65%) bunsetsus. In the case of bun-
setsus whose rightmost morpheme is an adverb, the
rate was 30.97% (140/452).
3.6 Commas Inserted between Parallel Words
or Phrases
Commas have a function which makes clear sepa-
ration between parallel words or phrases. The fol-
lowing example shows commas separating parallel
nouns.
895
? ??????????????????????
????????????????????(The
United Nations should play a lot of roles in a broad
range of fields, such as the global environment,
population, and food.)
In this example, commas are inserted to separate
parallel nouns ? ? (environment),? ?? (popula-
tion)? and ? ? (food)?. In English, there are com-
mas which perform the same role. In fact, commas
were inserted between ?environment? and ?popula-
tion? and between ?population? and ?food? in the
translation of the above example. When bunsetsus
whose rightmost morpheme is a noun appear se-
quentially, the rate of comma insertion between such
bunsetsus is 59.39% (3,330/5,607).
Also, commas are inserted to separate parallel
phrases. In the following example,
? ??????????????????????
??????????????????????
????????(The menu is decided by avoid-
ing the menu the Prime Minister ate on the previous
night, and by considering the balance between the
Japanese food and the European food.)
a comma is inserted right after the bunsetsu ???
? (avoiding)? to make clear separation between the
parallel phrases ?????????? (by avoid-
ing the menu)? and ??????????????
?? (by considering the balance between the
Japanese food and the European food).? The rate
of comma insertion between two parallel phrases is
79.89% (751/940). This is much higher than that of
bunsetsu boundaries, indicating that commas tend to
be inserted when phrases are paralleled.
3.7 Number of Characters between Commas
If there are too many commas at a short distance,
the sentence becomes hard to read. Therefore, the
number of characters between commas is expected
to be not too small. Also, because a long sequence
of characters without a comma is generated if the
distance between commas is very long, the occur-
rence frequency of such sequences of characters is
considered to be low.
We investigated the number of characters between
commas and its occurrence frequency. Figure 3
!
"!!
#!!
$!!
%!!
&!!
'!!
(!!
)!!
" $ & ( * "" "$ "& "( "* #" #$ #& #( #* $" $$ $& $( $* %" %$
!"
"#
$%
&"
%'
($
%)
#%
&"
*
!"#$%&'()'*+,&,*-%&.
Figure 3: Number of characters between commas and its
occurrence frequency
shows the results of investigation. When the num-
ber of characters between commas is either large or
small, the occurrence frequency is low.
4 Comma Insertion Method
In our method, a sentence, on which morphologi-
cal analysis, bunsetsu segmentation, clause bound-
ary analysis and dependency analysis have been per-
formed, is considered the input. Our method de-
cides whether or not to insert a comma at each bun-
setsu boundary in an input sentence. Based on the
analysis results in Section 3, our method adopts the
bunsetsu boundaries as candidate positions where a
comma is inserted. Our method identifies the most
appropriate combination among all combinations of
positions where a comma can be inserted, by using
the probabilistic model. In this paper, input sen-
tences which consist of n bunsetsus are represented
by B = b1 ? ? ? bn, and the results of comma inser-
tion by R = r1 ? ? ? rn. Here, ri is 1 if a comma
is inserted right after bunsetsu bi, and 0 otherwise.
We indicate the j-th sequence of bunsetsus created
by dividing an input sentence into m sequences as
Lj = b
j
1 ? ? ? b
j
nj (1 ? j ? m), and then, r
j
k = 0 if
1 ? k < nj , and rjk = 1 if k = nj .
4.1 Probabilistic Model for Comma Insertion
When an input sentence B is provided, our method
identifies the comma insertion R that maximizes
the conditional probability P (R|B). Assuming that
whether or not to insert a comma right after a bun-
setsu is independent of other commas except the
896
Table 4: Features used for the maximum entropy method
morphological the rightmost independent morpheme, i.e. head word, (part-of-speech and inflected form) and
information rightmost morpheme (part-of-speech) of a bunsetsu bjk
the rightmost morpheme (a surface form) of bjk if the rightmost morpheme is a particle
the first morpheme (part-of-speech) of bjk+1
commas inserted whether or not a clause boundary exists right after bjk
between clauses type of a clause boundary right after bjk if there exists a clause boundary
commas indicating whether or not bjk depends on the next bunsetsu
clear dependency whether or not bjk depends on a bunsetsu located after the final bunsetsu of the clause including
relations the next bunsetsu of bjk
whether or not bjk is depended on by the bunsetsu located right before it
whether or not the dependency structure of a sequence of bunsetsus between bjk and b
j
1 is closed
commas avoiding whether or not both the rightmost morpheme of bjk and first morpheme of b
j
k+1 are kanji
reading mistakes and characters
reading difficulty whether or not both the rightmost morpheme of bjk and first morpheme of b
j
k+1 are katakana
characters
commas indicating whether or not there exists a clause boundary ?topicalized element-wa? right after bjk and b
j
k
the subject depends on the next bunsetsu
whether or not there exists a clause boundary ?topicalized element-wa? right after bjk and the
string of characters right before bjk is ? ? (dewa)?
the number of characters in a phrase indicating the subject5 if there exists a clause boundary
?topicalized element-wa? right after bjk
whether or not a clause boundary ?topicalized element-wa? exists right after bjk and a bunsetsu
whose rightmost morpheme is a verb depends on the modified bunsetsu of bjk
commas inserted whether or not bjk appears at the beginning of a sentence and its rightmost morpheme is a
after a conjunction conjunction
or adverb at the be-
ginning of a sentence
whether or not bjk appears at the beginning of a sentence and its rightmost morpheme is an
adverb
commas inserted whether or not both the rightmost morphemes of bjk and b
j
k+1 are nouns
between parallel whether or not a predicate at the sentence end is depended on by bjk whose rightmost
words or phrases independent morpheme is a verb and by any of the bunsetsus which are located after bjk and of
which the rightmost independent morpheme is a verb
number of characters one of the following 4 categories if the number of characters from bj1 to bjk is found there
from bj1 to bjk ([num = 1], [2 ? num ? 3], [4 ? num ? 21], [22 ? num])
one appearing immediately before that bunsetsu,
P (R|B) can be calculated as follows:
P (R|B) (1)
=P (r11 = 0, ? ? ? , r
1
n1?1 = 0, r
1
n1 = 1, ? ? ? ,
rm1 = 0, ? ? ? , r
m
nm?1 = 0, r
m
nm = 1|B)
?=P (r11 = 0|B)? ? ? ?
?P (r1n1?1 = 0|r
1
n1?2 = 0, ? ? ? , r
1
1 = 0, B)
?P (r1n1 = 1|r
1
n1?1 = 0, ? ? ? , r
1
1 = 0, B)? ? ? ?
?P (rm1 = 0|r
m?1
nm?1 = 1, B)? ? ? ?
?P (rmnm?1 = 0|r
m
nm?2= 0,? ? ?, r
m
1 = 0, r
m?1
nm?1= 1, B)
?P (rmnm = 1|r
m
nm?1 = 0, ? ? ? , r
m
1 = 0, r
m?1
nm?1 = 1, B)
where P (rjk = 1|r
j
k?1 = 0, ? ? ? , r
j
1 = 0, r
j?1
nj?1 =
1, B) is the probability that a comma is inserted right
after a bunsetsu bjk when the sequence of bunset-
sus B is provided and the position of j-th comma is
identified. Similarly, P (rjk = 0|r
j
k?1 = 0, ? ? ? , r
j
1 =
0, rj?1nj?1 = 1, B) is the probability that a comma
is not inserted right after a bunsetsu bjk. These
probabilities are estimated by the maximum entropy
method. The result R which maximizes the condi-
tional probability P (R|B) is regarded as the most
appropriate result of comma insertion, and calcu-
lated by dynamic programming.
897
4.2 Features on Maximum Entropy Method
To estimate P (rjk = 1|r
j
k?1 = 0, ? ? ? , r
j
1 =
0, rj?1nj?1 = 1, B) and P (r
j
k = 0|r
j
k?1 = 0, ? ? ? , r
j
1 =
0, rj?1nj?1 = 1, B) by the maximum entropy method,
we used the features in Table 4 based on the analysis
described in Section 3.
5 Experiment
To evaluate the effectiveness of our method, we con-
ducted an experiment using a Japanese text corpus.
5.1 Outline of Experiment
As the experimental data, we used the newspaper ar-
ticles in the Kyoto Text Corpus version 4.0 (Kuro-
hashi and Nagao, 1998). We used the articles from
January 14th to 17th as the test data. The training
data is same as the analysis data. Table 5 shows the
size of the test data. Here, we used the maximum
entropy method tool (Le, 2008) with the default op-
tions except ?-i 2000.?
In the evaluation, we obtained the recall, the pre-
cision and their harmonic mean, i.e., F-measure.
The recall and precision are respectively defined as
follows.
recall=
# of correctly inserted commas
# of commas in the correct data
precision=
# of correctly inserted commas
# of inserted commas
In our research, to realize automatic comma in-
sertion with high quality, we analyzed each usage of
commas and decided the features for the ME method
based on the analysis. To confirm the effectiveness
of our features, we established the baseline method
as a comparative method whereby commas are in-
serted by the ME method in which only simple mor-
phological information is used. The baseline method
uses the morphological information in Table 4 and
the information of the rightmost morpheme (a sur-
face form) of a bunsetsu as features.
5.2 Experimental Results
Table 6 shows the experimental results of the base-
line and our method. The recall and precision
were 69.13% and 84.13% respectively, and we con-
firmed that our method had higher performance than
Table 5: Size of test data
sentences 4,659
bunsetsus 46,511
characters 198,899
commas 6,549
characters per sentence 42.69
Table 6: Experimental results
recall precision F-measure
our 69.13% 84.13% 75.90
method (4,527/6,549) (4,527/5,381)
baseline 51.38% 70.90% 59.58
(3,365/6,549) (3,365/4,746)
the baseline method. The percentage of sentences
wherein all commas were correctly inserted was
55.81%.
Figure 4 shows the comparison between the re-
sults of our method and the baseline method. The
baseline method was not able to insert commas right
after the bunsetsu ???????? (are floated)? or
?? ? ?? (not decided)? but inserted com-
mas at unnatural positions such as between ? ??
(calling himself)? and ?????? (the vice com-
mander).? On the other hand, our method was able
to insert commas properly at such bunsetsu bound-
aries.
6 Discussion
6.1 Error Analysis
Among positions where commas existed in the test
data, there existed 2,022 positions where our method
did not insert commas. Among them, 862 were
clause boundaries, and the clause boundary ?topical-
ized element-wa? accounted for 53.36% (460/862)
of them. There were a lot of clause boundaries of
the type ?topicalized element-wa,? and the number
of commas inserted at such boundaries was large.
But, the rate of comma insertion itself was not very
high. We can say that the four features about ?topi-
calized element-wa? did not always work well. Ta-
5Phrases indicating the subject is a sequence of bunsetsus
consisting of bjk and all bunsetsus that are connected to b
j
k when
we trace their dependency relationship in modifier-to-modifyee
direction.
898
!"#$%&'()*+,-./0-123456789:;<0=>?@ABCD=EFGHIJKLMGNBOPQRSTUO=BV$WUXYGZ[\O]^MWT_`=abcdef
!"#$%#&'()*)+,+-&.)/&0/1%.2&3)*/4&3+$*5/.&(/3,/.+,2-&6/.(%50#
'7+8%5*-&.)/&9+2#,&#4&':%9# 3*.2&*5&;)*9+5/- <%5*# =+.#2+9+-&
.)/&4#,9/,&>+$#,&9*5*(./,&+50&.)/&7,*./,&6+*3)* ;+8+*2+ +,/&
4>#+./0&+(&.)/&3+50*0+./-)#7/?/,-&(*53/&.)/&4,+9/7#,8&#4&
.)/&1,/0*3+./0&1#>*.*3+>&1+,.2&*(&5#.&0/3*0/0- .)/&3##,0*5+.*#5&
9+8/(&>*..>/&)/+07+2@&A
!"#$%&'(!)*
!"#$%&'()*+,-./0-123456789:;<0>?@ABCD=EFGHIJKLMGNBOPQRSTUOBV$WUXYGZ[\O]^MWT_`abcdef
!"#$%#&'()*)+,+-&.)/&0/1%.2&3)*/4&3+$*5/.&(/3,/.+,2-&6/.(%50#
'7+8%5*-&.)/&9+2#,&#4&':%9# 3*.2&*5&;)*9+5/ <%5*# =+.#2+9+-&
.)/&4#,9/,&>+$#,&9*5*(./,&+50&.)/&7,*./,&6+*3)* ;+8+*2+ +,/&
4>#+./0&+(&.)/&3+50*0+./ )#7/?/,-&(*53/&.)/&4,+9/7#,8&#4&
.)/&1,/0*3+./0&1#>*.*3+>&1+,.2&*(&5#.&0/3*0/0 .)/&3##,0*5+.*#5&
9+8/(&>*..>/&)/+07+2@&A
+,-&./0&*
ghij$NkU/lm-Ono:&pUO=qrGlm-cstf
!B)*>/&.)/&?*3/&3#99+50/, 3+>>*5C&)*9(/>4&D+,3#(&+11/+,(&
*5&1%$>*3-&+5&+3.%+>&3#99+50/,&*(&%53/,.+*5@A
!"#$%&'(!)*
ghij$NkU=/lm-Ono:&pUO=qrGlm-cstf
!B)*>/&.)/&?*3/&3#99+50/,- 3+>>*5C&)*9(/>4&D+,3#(&+11/+,(&*5&
1%$>*3-&+5&+3.%+>&3#99+50/,&*(&%53/,.+*5@A
+,-&./0&*
Figure 4: Comparison of the results of our method and
baseline method
ble 7 shows the results of comma insertion at the
clause boundaries ?topicalized element-wa.? While
there existed 601 commas at such boundaries in the
test data, only 141 commas were inserted correctly.
We need to consider more effective features about
?topicalized element-wa.?
As for other cases, there existed 130 bunsetsu
boundaries between parallel words where commas
were not inserted. One example of such case is
shown below.
? correct data:
? ???? ?????????
????????????????????
? (Put pork backfat, garlic, ginger and shredded
green onion in a bowl, and add red bell peppers for
color.)
Table 7: Result of comma insertion at the clause bound-
aries ?topicalized element-wa.?
recall precision F-measure
23.46% 59.49% 33.65
(141/601) (141/237)
? our method:
??????????????????????
??????????????????????
(Put pork backfat garlic, ginger and shredded green
onion in a bowl, and add red bell peppers for color.)
In the correct data, a comma was inserted between
the bunsetsu ?? (backfat)? and ????? (gar-
lic).?
If a comma should be inserted right after the bun-
setsu ?? ? (backfat),? the number of characters be-
tween commas would become too small to be judged
as appropriate by the proposed method. So, the fea-
ture about the number of characters between com-
mas may have had harmful effects there. On the
other hand, a comma was inserted properly between
the bunsetsu ????? (garlic)? and ? ???
(ginger).? This is because katakana characters ap-
peared sequentially in addition to appearing as par-
allel nouns.
6.2 Unnatural Comma Insertion
When commas are inserted at obviously unnatural
positions, they have a major impact on the under-
standing of a sentence by readers. Here, we inves-
tigated how many commas had been inserted at ob-
viously unnatural positions by our method. For the
article on January 14th (217 sentences, 2,349 bun-
setsus) in the test data, we examined 47 commas in-
serted incorrectly. Three persons decided whether
or not the inserted commas were obviously unnat-
ural through consultations. Concretely, when all of
the three persons felt that an inserted comma would
make readers understand wrongly the meaning of
the sentence, the comma was judged to be obviously
unnatural.
Among 47 commas, 4 commas were judged obvi-
ously unnatural. This result shows that our method
is capable of inserting commas at natural positions
on some level.
899
Table 8: Comparison with human judgement
recall precision F-measure
by human 78.30% 80.58% 79.42
(249/318) (249/309)
our method 71.07% 82.78% 76.48
(226/318) (226/273)
6.3 Comparison with Human Judgement
In our experiment, we evaluated the results of
comma insertion of our method by comparing them
with the correct data. However, the sufficient level
to be reached by automatic comma insertion is un-
certain. Here, we evaluated our method by com-
paring them with the results of comma insertion by
another person. By using the same data as used in
the subsection 6.2, we conducted an experiment on
comma insertion by an annotator who was familiar
with writing Japanese documents. Table 8 shows the
recall, the precision and the F-measure. The second
row shows the results of our method for the same
data. As the F-measure of the annotator was 79.42,
it turned out that comma insertion task was diffi-
cult even for humans. For F-measure, our method
achieved 96.30% (76.48/79.42) of the annotator?s re-
sult. Also, the precision of our method was 82.78%.
Although the comma insertion task is difficult, our
method was able to properly insert commas.
7 Conclusion
This paper proposed a method for inserting commas
into Japanese texts. Our method appropriately in-
serts commas based on the machine learning method
using such features as morphemes, dependencies
and clause boundaries. An experiment by using the
Kyoto Text Corpus (Kurohashi and Nagao, 1998)
showed an F-measure of 75.90, and we confirmed
the effectiveness of our method.
The analysis of the experimental results showed
that our method cannot insert commas of the par-
ticular usage. As a future work, it is necessary to
find more useful features for commas of this usage
and improve the recall of our method. Also, we will
examine ?commas emphasizing the adjacent word?
which were not included in our targets.
Acknowledgments
This research was partially supported by the Grant-
in-Aids for Scientific Research (B) (No. 22300051)
and Young Scientists (B) (No. 21700157), and by
the Continuation Grants for Young Researchers of
The Asahi Glass Foundation.
References
Heidi Christensen, Yoshihiko Gotoh, and Steve Renals.
2001. Punctuation annotation using statistical prosody
models. In Proceedings of ISCA Workshop on Prosody
in Speech Recognition and Understanding, pages 35?
40.
Yuqing Guo, Haifeng Wang, and Josef van Genabith.
2010. A linguistically inspired statistical model for
Chinese punctuation generation. ACM Transactions
on Asian Language Information Processing, 9(2):6:1?
6:27.
Yoshihiko Hayashi. 1992. A three-level revision model
for improving Japanese bad-styled expressions. In
Proceeding of 14th International Conference on Com-
putational Linguistics, pages 665?671.
Katsuichi Honda. 1982. Nihongo no sakubun gijutsu
(Japanese writing skill). Asahi Shimbun Publications
Inc. (In Japanese).
Takashi Inukai. 2002. Moji hyouki tankyuhou (Method of
questioning characters and notations). Asakura Pul-
ishing Co., Ltd. (In Japanese).
Hideki Kashioka and Takehiko Maruyama. 2004. Seg-
mentation of semantic unit in Japanese monologue.
In Proceedings of International Conference on Speech
Language Technology and Oriental COCOSDA, pages
87?92.
Ji-hwan Kim and P. C. Woodland. 2001. The use of
prosody in a combined system for punctuation gener-
ation and speech recognition. In Proceedings of 7th
European Conference on Speech Communication and
Technology, pages 2757?2760.
Sadao Kurohashi and Makoto Nagao. 1998. Building
a Japanese parsed corpus while improving the parsing
system. In Proceedings of 1st International Confer-
ence on Language Resources and Evaluation, pages
719?724.
Zhang Le. 2008. Maximum entropy modeling toolkit for
python and c++. http://homepages.inf.ed.
ac.uk/s0450736/maxent toolkit.html.
[Online; accessed 1-March-2008].
Yang Liu, Elizabeth Shriberg, Andreas Stolcke, Dustin
Hillard, Mari Ostendorf, and Mary Harper. 2006. En-
riching speech recognition with automatic detection of
900
sentence boundaries and disfluencies. IEEE Trans-
actions on Audio, Speech, and Language Processing,
14(5):1526?1540.
Tohru Shimizu, Satoshi Nakamura, and Tatsuya Kawa-
hara. 2008. Effect of punctuation marks for speech
translation unit boundary detection. IEICE technical
report. Speech, 108(338):127?131. (In Japanese).
Shogakukan?s editiorial department. 2007. kutoten,
kigou, hugou katuyoujiten (dictionary of punctuations
and symbols ). Shogakukan. (In Japanese).
Eiji Suzuki, Shizuo Shimada, Kunio Kondo, and Hisashi
Sato. 1995. Automatic recognition of optimal punc-
tuation in Japanese documents. In Proceedings of
50th National Convention of IPSJ, 50(3):185?186. (In
Japanese).
Michael White and Rajakrishnan Rajkumar. 2008.
A more precise analysis of punctuation for broad-
coverage surface realization with CCG. In Proceed-
ings of Workshop on Grammar Engineering Across
Frameworks, pages 17?24.
901
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 205?208,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Coherent Back-Channel Feedback Tagging of
In-Car Spoken Dialogue Corpus
Yuki Kamiya
Graduate School of
Information Science,
Nagoya University, Japan
kamiya@el.itc.nagoya-u.ac.jp
Tomohiro Ohno
Graduate School of
International Development,
Nagoya University, Japan
ohno@nagoya-u.jp
Shigeki Matsubara
Graduate School of
Information Science,
Nagoya University, Japan
matubara@nagoya-u.jp
Abstract
This paper describes the design of a back-
channel feedback corpus and its evalua-
tion, aiming at realizing in-car spoken di-
alogue systems with high responsiveness.
We constructed our corpus by annotating
the existing in-car spoken dialogue data
with back-channel feedback timing infor-
mation in an off-line environment. Our
corpus can be practically used in devel-
oping dialogue systems which can pro-
vide verbal back-channel feedbacks. As
the results of our evaluation, we confirmed
that our proposed design enabled the con-
struction of back-channel feedback cor-
pora with high coherency and naturalness.
1 Introduction
In-car spoken dialogue processing is one of the
most prevailing applications of speech technol-
ogy. Until now, to realize the system which can
surely achieve such tasks navigation and informa-
tion retrieval, the development of speech recogni-
tion, speech understanding, dialogue control and
so on has been promoted. Now, it becomes impor-
tant to increase responsiveness of the system not
only for the efficient achievement of the task but
for increasing drivers? comfortableness in a dia-
logue.
One way to increase responsiveness of a sys-
tem is to timely disclose system?s state of under-
standing, by making the system show some kind
of reaction during user?s utterances. In human
dialogues, such disclosure is performed by ac-
tions such as nods, facial expressions, gestures and
back-channel feedbacks. However, since drivers
do not look towards a spoken dialogue system
while driving, the system has to inevitably use
voice responses, that is, back-channel feedbacks.
Furthermore, in the response strategy for realiz-
ing in-car dialogues in which drivers feel com-
fortable, it is necessary for the system to provide
back-channel feedbacks during driver?s utterances
aggressively as well as timely.
This paper describes the design of a back-
channel feedback corpus having coherency (tag-
ging is performed by different annotators equally)
and naturalness, and its evaluation, aiming at re-
alizing in-car spoken dialogue systems with high
responsiveness. Although there have been sev-
eral researches on back-channel feedback timings
(Cathcart et al, 2003; Maynard, 1989; Takeuchi
et al, 2004; Ward and Tsukahara, 2000), in many
of them, back-channel feedback timings in human
dialogues were observed and analyzed by using
a general spoken dialogue corpus. On the other
hand, we constructed our corpus by annotating the
existing in-car spoken dialogue data with back-
channel feedback timing information in an off-line
environment. Our corpus can be practically used
in developing dialogue systems which can provide
back-channel feedbacks.
In our research, the driver utterances (11,181
turns) in the CIAIR in-car spoken dialogue corpus
(Kawaguchi et al, 2005) were used as the existing
data. We created the Web interface for the anno-
tation of back-channel feedbacks and constructed
the corpus including 5,416 back-channel feed-
backs. Experiments have shown that our proposed
corpus design enabled the construction of back-
channel feedback corpora with high coherency and
naturalness.
2 Corpus Design
A back-channel feedback is a sign to inform a
speaker that the listener received the speaker?s ut-
terances. Thus, in an in-car dialogue between a
driver and a system, it is preferable that the sys-
tem provides as many back-channel feedbacks as
possible. However, if back-channel feedbacks are
unnecessarily provided, they can not play the pri-
mary role because the driver wonders if the system
really comprehends the speech.
205
For this reason, the timings at which the sys-
tem provides back-channel feedbacks become im-
portant. Several researches investigated back-
channel feedback timings in human-human dia-
logues (Cathcart et al, 2003; Maynard, 1989;
Takeuchi et al, 2004; Ward and Tsukahara, 2000).
They reported back-channel feedbacks had the fol-
lowing tendencies: ?within or after a pause,? ?after
a conjunction or sentence-final particle,? and ?af-
ter a clause wherein the final pitch descends.?
However, it is difficult to systematize the ap-
propriate timings of back-channel feedbacks since
their detection is intertwined in a complex way
with various acoustic and linguistic factors. Al-
though machine learning using large-scale data
would be a solution to the problem, existing spo-
ken dialogue corpora are not suitable for direct
use as data, because the timings of the back-
channel feedbacks lack coherency due to the in-
fluence of factors such as the psychological state
of a speaker, the environment and so on.
In our research, to create more pragmatic data
in which the above-mentioned problem is solved,
we constructed the back-channel feedback corpus
with coherency. To this end, we established the
following policies for annotation:
? Comprehensive tagging: Back-channel
feedback tags are provided for all timings
which are not unnatural. In human-human
dialogues, there are some cases that even if a
timing is suited for providing a back-channel
feedback, no back-channel feedback is not
provided (Ward and Tsukahara, 2000). On
the other hand, in our corpus, comprehensive
tagging enables coherent tagging.
? Off-line tagging: Annotators tag all tim-
ings at which back-channel feedbacks can be
provided after listening to the target speech
one or more times. Compared with providing
back-channel feedbacks in on-line environ-
ment, the off-line annotation decreases the
chances of tagging wrong positions or failing
in tagging back-channel feedbacks, realizing
coherent tagging.
? Discretization of tagging points: Tagging
is performed for each segment into which
driver?s utterances are divided. In a nor-
mal dialogue, the listener can provide back-
channel feedbacks whenever he/she wants to,
but the inconsistency in the timings to give
such feedbacks becomes larger in exchange
0035 - 03:10:170-03:13:119 F:D:I:D:(F ?) (well?)                   &   to?? (clothes)                  &   fuku-o???????? (I wan to buy, so) &   kai-tai-n-da-kedo??? (somewhere)           &   dok-ka???<H>                  (near here)              &   chikaku-ni<H>0036 - 03:15:132-03:16:623 F:D:I:DI:?? (an inexpensive)     &   yasui?? (shop)                     &   o-mise?????<SB>        (is there)                 &   aru-ka-na<SB>0037 - 03:17:302-03:20:887 F:O:I:AO:?? (here)                      &   kono????? (near)                      &   chikaku-desu-to?????? (ANNEX)               &   anekkusu-to??????? (Nagoya PARCO)  &    nagoya-paruko-ga??????<SB>   (there are)                &   gozai-masu-ga<SB>
Well?, I want to buy clothes, so, is there  an inexpensive shop somewhere near here?
Near here, there are ANNEX and Nagoya PARCO.
driver?s utterance
driver?s turn
operator?s turn
driver?s utterance
operator?s utterance
Figure 1: Sample of transcribed text
for smaller restrictions. The discretization of
tagging points enables not only coherent tag-
ging but also the reduction of tagging cost.
? Elaboration using synthesized sound: An
annotator checks the validity of the anno-
tation by listening to the sounds. In other
words, an annotator elaborates the annotation
by revising it many times by listening to the
automatically created dialogue sound which
includes not only driver?s voices but also
sounds of back-channel feedbacks generated
according to the provided timings. The back-
channel feedbacks had been synthesized by
using a speech synthesizer because our cor-
pus aims to be used for implementing the
systemwhich can provide back-channel feed-
backs.
3 Corpus Construction
We constructed the back-channel feedback corpus
by annotating an in-car speech dialogue corpus.
3.1 CIAIR in-car spoken dialogue corpus
We used the CIAIR in-car spoken dialogue corpus
(Kawaguchi et al, 2005) as the target of annota-
tion. The corpus consists of the speech and tran-
scription data of dialogues between a driver and
an operator about shopping guides, driving direc-
tions, and so on. Figure 1 shows an example of
the transcription. We used only the utterances of
drivers in the corpus. We divided the utterances
into morphemes by using the morphological ana-
lyzer Chasen1. In addition, each morpheme was
provided start and end times estimated by using
the continuous speech recognition system Julius2.
3.2 Tagging of spoken dialogue corpus
We constructed the corpus by providing the back-
channel feedback tags at the proper timings for
the driver?s utterances, according to the design de-
scribed in Section 2.
1http://chasen-legacy.sourceforge.jp
2http://julius.sourceforge.jp
206
sp [short pause](F?) (Well?)? (clothes)? (no translation)sp [short pause]?? (buy)?? (want to)? (no translation)? (no translation)?? (so)?? (somewhere)? (no translation)?? (near hear)? (no translation)sp [short pause]pause [pause]?? (inexpensive)? (no translation)? (shop)?? (is there)? (no translation)?? (no translation)
0.0000.0300.0900.3400.5200.6100.8501.0801.1501.2401.4201.6701.8502.1902.8803.0804.9925.3625.4225.6525.8325.982
0.0300.0900.3400.5200.6100.8501.0801.1501.2401.4201.6701.8502.1902.8803.0804.9925.3625.4225.6525.8325.9826.272
content start time end time
Figure 2: Sample of division of a dialogue turn
into basic segments
For ?comprehensive tagging,? an annotator lis-
tens to each dialogue turn3 from the start and tags
a position where a back-channel feedback can be
provided when the timing is found. Here, the tim-
ing of the last back-channel feedback is also used
for judging whether or not the timing is unnatural.
For ?off-line tagging,? an annotator tags the
transcribed text of each dialogue turn of drivers.
To perform ?discretization of tagging points,? a
dialogue turn is assumed to be a sequence of mor-
phemes or pauses (hereafter, we call them basic
segments), which are continuously arranged on
the time axis, and it is judged whether or not a
back-channel feedback should be provided at each
basic segment. Here, in consideration of the un-
equal pause durations, if the length of a pause is
over 200ms, the pause is divided into the initial
200ms pause and the subsequent pause, each of
which is considered as a basic segment. Figure 2
shows an example of a dialogue turn divided into
basic segments.
Furthermore, for ?elaboration using synthesized
sound,? we prepared the annotation environment
where the dialogue sound including not only
driver?s voice but also back-channel feedbacks
generated according to the provided timings is au-
tomatically created in real time for annotators to
listen to. There are several types of back-channel
feedbacks and in normal conversations, we choose
and use appropriate back-channel feedbacks from
among them according to the scene. In our study,
3A dialogue turn is defined as the interval between the
time at which the driver starts to utter just after the opera-
tor finishes uttering and the time at which the driver finishes
uttering just before the operator starts to utter.
play button
turn ID
driver ID
update button
list of turn IDs
Figure 3: Web interface for tagging
Table 1: Size of back-channel feedback corpus
drivers 346
dialogue turns 11,181
clauses 16,896
bunsetsus4 12,689
morpheme segments 94,030
pause segments 19,142
back-channel feedbacks 5,416
we used the most general form ??? hai (yes)?
for the synthesized speech since our focus was
on the timing of back-channel feedbacks. The
back-channel feedbacks had been created by us-
ing Hitachi?s speech synthesizer ?HitVoice,? and
one feedback was placed 50 milli-seconds after the
start time of a tagged basic segment.
We developed a Web interface for tagging back-
channel feedbacks. Figure 3 shows the Web inter-
face. The interface displays a sequence of basic
segments in a dialogue turn in table format. Anno-
tators perform tagging by checking basic segments
where a back-channel feedback can be provided.
3.3 Size of back-channel feedback corpus
Table 1 shows the size of our corpus constructed
by two trained annotators. The corpus includes
5,416 back-channel feedbacks. This means that a
back-channel feedback is generated at intervals of
about 21 basic segments.
4 Corpus Evaluation
We conducted experiments for evaluating the tag-
ging in the constructed corpus.
4Bunsetsu is a linguistic unit in Japanese that roughly cor-
responds to a basic phrase in English. A bunsetsu consists of
one independent word and zero or more ancillary words.
207
Table 2: Kappa values of the existing corpus
a,c a,d a,b c,d b,c b,d
? 0.536 0.438 0.322 0.311 0.310 0.167
4.1 Coherency of corpus tagging
We conducted an evaluation experiment to con-
firm that the tagging is coherently performed in
the corpus. In the experiment, two different an-
notators performed tagging on the same data, and
then we measured the degree of the agreement be-
tween them. As the indicator, we used Cohen?s
kappa value (Cohen, 1960), calculated as follows:
? = P (O)? P (E)
1? P (E)
where P (O) is the observed agreement between
annotators, and P (E) is the hypothetical proba-
bility of chance agreement. A subject who has
a certain level of knowledge annotated 673 dia-
logue turns. The kappa value was 0.731 (P (O) =
0.975, P (E) = 0.907), and thus we can see the
substantial agreement between annotators.
As the target for comparison, we used the kappa
value in the existing back-channel feedback cor-
pus (Kamiya et al, 2010). The corpus had been
constructed by the way that the recorded driver?s
voice was replayed and 4 subjects independently
produced back-channel feedbacks for the same
sound. This means that the policies for tagging
the existing corpus differ from those of our corpus,
and are ?on-line tagging,? ?tagging on the time
axis? and ?tagging without elaborating.? In the
exisiting corpus, 297 dialogue turns were used as
driver?s sound. Table 2 shows the kappa value be-
tween two among the 4 subjects. The kappa value
of our corpus was higher than that between any
subjects of the existing corpus, substantiating the
high coherency of our corpus.
4.2 Validity of corpus tagging
In our corpus, we discretized the tagging points
to enhance the coherency of tagging. However,
such constraint restricts the points available for
tagging and may make annotators provide tags at
the unnatural timings. Therefore, we conducted
a subjective experiment to evaluate the natural-
ness of the back-channel feedback timings. In
the experiment, one subject listened to the replay
of our back-channel feedback corpus and subjec-
tively judged the naturalness of each timing. The
back-channel feedback sound was generated in the
same way described in Section 3.2.
In the experiment, we used 345 dialogue turns
including 131 back-channel feedbacks. 98.47%
of all the back-channel feedbacks were judged to
be natural. Only 2 back-channel feedbacks were
judged to be unnatural because the intervals be-
tween them and the back-channel feedbacks pro-
vided immediately before them were felt too short.
This showed the validity of our discretization of
tagging points.
5 Conclusion
This paper described the design, construction and
evaluation of the back-channel feedback corpus
which had the coherency of tagged back-channel
feedback timings. We constructed the spoken di-
alogue corpus including 5,416 back-channel feed-
backs in 11,181 dialogue turns. The results of our
evaluation confirmed high coherency and enough
naturalness of our corpus.
In the future, we will use our corpus to see
to what extent the timings of back-channel feed-
backs that have been annotated correlate with the
cues provided by earlier researchers. Then we will
develop a system which can detect back-channel
feedback timings comprehensively.
Acknowledgments: This research was supported
in part by the Grant-in-Aid for Challenging Ex-
ploratory Research (No.21650028) of JSPS.
References
N. Cathcart, J. Carletta, and E. Klein. 2003. A shal-
low model of backchannel continuers in spoken dia-
logue. In Proc. of 10th EACL, pages 51?58.
J. Cohen. 1960. A coefficient of agreement for nom-
inal scales. Educational and Psychological Mea-
surement, 20:37?46.
Y. Kamiya, T. Ohno, S. Matsubara, and H. Kashioka.
2010. Construction of back-channel utterance cor-
pus for responsive spoken dialogue system develop-
ment. In Proc. of 7th LREC.
N. Kawaguchi, S. Matsubara, K. Takeda, and
F. Itakura. 2005. CIAIR in-car speech corpus ?
influence of driving status?. IEICE Trans. on Info.
and Sys., E88-D(3):578?582.
S. K. Maynard. 1989. Japanese conversation :
self-contextualization through structure and interac-
tional management. Ablex.
M. Takeuchi, N. Kitaoka, and S. Nakagawa. 2004.
Timing detection for realtime dialog systems using
prosodic and linguistic information. In Proc. of
Speech Prosody 2004, pages 529?532.
N. Ward and W. Tsukahara. 2000. Prosodic features
which cue back-channel responses in English and
Japanese. Journal of Pragmatics, 32:1177?1207.
208
