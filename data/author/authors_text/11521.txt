Proceedings of the Workshop on BioNLP, pages 142?143,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Using Hedges to Enhance a Disease Outbreak Report Text Mining System
Mike Conway, Nigel Collier
National Institute of Informatics
2-1-2 Hitotsubashi, Chiyoda-ku
Tokyo 101-8430, Japan
{mike|collier}@nii.ac.jp
Son Doan
Vanderbilt University Medical Center
2525 West End Ave., Suite 800
Nashville, TN 37235, USA
son.doan@vanderbilt.edu
1 Introduction
Identifying serious infectious disease outbreaks in
their early stages is an important task, both for na-
tional governments and international organizations
like the World Health Organization. Text mining
and information extraction systems can provide an
important, low cost and timely early warning sys-
tem in these circumstances by identifying the first
signs of an outbreak automatically from online tex-
tual news. One interesting characteristic of disease
outbreak reports ? which to the best of our knowl-
edge has not been studied before ? is their use of
speculative language (hedging) to describe uncertain
situations. This paper describes two uses of hedging
to enhance the BioCaster disease outbreak report
text mining system.
Following a brief description of the BioCaster
system and corpus (section 2), we discuss in section
3 previous uses of hedging in NLP and the meth-
ods used to identify hedges in the current work. In
section 4 we describe some initial classification ex-
periments using hedge features. Section 5 describes
a ?speculative? method of tagging disease outbreak
reports with a metric designed to aid users of the
BioCaster system in identifying articles of inter-
est.
2 BioCaster System & Corpus
The BioCaster system scans online news reports
for stories concerning infectious disease outbreaks
(e.g. H5N1, Ebola) and makes its results available to
registered users as email alerts (Collier et al, 2008).
In addition to this email service, data that has been
filtered through a topic classifier but which is still
uninterpreted is used to populate a Google Map ap-
plication called the Global Health Monitor.1
The BioCaster corpus consists of 1000 news
articles downloaded from the WWW and then man-
ually categorized and annotated with Named Entities
by two PhD students. Articles were collected from
various news sources (e.g. BBC, New York Times
and ProMED-Mail2). Each document is classified
as either relevant (350) or reject (650).3
The corpus is designed to include difficult border-
line cases where more advanced understanding of
the context is required. For example, an article may
be about, say, polio, but not centrally concerned with
specific outbreaks of that disease. Instead, the arti-
cle could report a vaccination campaign or research
breakthrough.
3 Hedges
According to Hyland (1998), in an extensive study
of speculative language in science writing, hedges
?are the means by which writers can present a propo-
sition as an opinion rather than a fact.? More re-
cently, Kilicoglu and Bergler (2008) have presented
a method for automatically identifying hedges in the
biomedical domain. In the current work, we used a
science orientated hedge lexicon derived from Mer-
cer et al (2004). The lexicon consisted of 72 verbs
(including appear, appears, appeared, appearing,
indicate, indicates, indicated, indicating, and so on)
and 32 non-verbs (including, about, quite, poten-
1www.biocaster.org
2ProMED-Mail is a human curated service for monitoring
disease outbreak reports (www.promedmail.org.)
3For copyright reasons, the BioCaster corpus is not pub-
licly available.
142
Rank Hedge Rank Hedge
1 reported 9 suggests
2 suspected 10 estimated
3 probable 11 appeared
4 suspect 12 appearing
5 usually 13 mostly
6 see 14 assumes
7 reports 15 predicted
8 sought 16 suggested
Table 1: Statistically Significant Hedges
Features Naive Bayes SVMAcc F Acc F
9000 ?2 94.8 0.93 92.2 0.89
Unigram 88.4 0.85 90.9 0.87
Unigram+hedge 88.0 0.85 91.7 0.89
Table 2: Classification Results
tially, likely and so on). Preliminary work showed
that the frequency of hedge words differs in the two
categories of the BioCaster corpus (relevant and
reject) at a highly significant level using the ?2 test
(P < 0.01). Table 1 shows the 16 most discriminat-
ing hedge words in the BioCaster corpus (identi-
fied using the ?2 feature selection method.)
4 Classification Experiment
The current BioCaster system uses n-gram based
text classification to identify disease outbreak re-
ports, and reject other online news. We used hedg-
ing features to augment this classifier, and evaluated
the results using a subset of the BioCaster cor-
pus. One binary hedging feature was used. The fea-
ture was ?true? if and only if one of the 105 hedge
lexemes identified by Mercer et al (2004) occurred
in the input document within 5 words of a disease
named entity. Results are shown in Table 2, where it
can be seen that the addition of a single binary hedge
feature to the unigram feature set increases accuracy
by 0.8%. The performance does not however reach
the level achieved by the ?2 9000 n-gram feature set
described in Conway et al (2008).
5 Towards a ?Speculative? Metric
Users of the BioCaster system would benefit
from an indicator of how ?speculative? each news
article is, as breaking news regarding disease out-
breaks is characterized by uncertainty, which is en-
coded using hedging. We use the Mercer list of 105
hedging words as described above, in conjunction
with statistics derived from a 10,000 document sec-
Accept (%) Reject (%)
High 64.2 48.3
Medium 29.5 36.7
Low 6.3 15.0
Table 3: Proportion of Articles in Each Category
tion of the Reuters corpus to provide a ?speculative?
metric.4 We calculated total frequencies for all 105
hedge words in each of the 10,000 Reuters docu-
ments ? that is, the total number of hedge words
per document ? then ranked these frequencies (af-
ter normalizing the frequencies to take account of
document length). The bottom third of documents
had hedge percentages in the range 0% - 0.2544%
(LOW). The middle third had hedge percentages in
the range 0.2545% - 1.0574 (MEDIUM). The range
for the top third was 1.0575% - 100% (HIGH). Doc-
uments inputted to the BioCaster system auto-
matically have their proportion of hedge words cal-
culated and are assigned a value according to their
position on the scale (LOW, MEDIUM or HIGH). Ta-
ble 3 shows that a majority of the documents in the
accept segment of the BioCaster corpus can be
tagged as highly speculative using this method.
References
N. Collier, S. Doan, A. Kawazoe, R. Matsuda-Goodwin,
M. Conway, Y. Tateno, Q-H. Ngo, D. Dien, A. Kaw-
trakul, K. Takeuchi, M. Shigematsu, and K. Tanigu-
ichi. 2008. BioCaster: Detecting Public Health Ru-
mors with a Web-based Text Mining System. Bioin-
formatics, 24(24):2940?2941.
M. Conway, S. Doan, A. Kawazoe, and N. Collier.
2008. Classifying Disease Outbreak Reports Using
N-grams and Semantic Features. Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM 2008), Turku, Finland, pages 29?
36.
K. Hyland. 1998. Hedging in Scientific Research Articles.
John Benjamins, Amsterdam.
H. Kilicoglu and S. Bergler. 2008. Recognizing Spec-
ulative Language in Biomedical Research Articles: a
Linguistically Motivated Perspective. BMC Bioinfor-
matics, 9(Suppl 11):S10.
R. Mercer, C. DiMarco, and F. Kroon. 2004. The Fre-
quency of Hedging Cues in Citation Contexts in Sci-
entific Writing. In Proceedings of the Canadian Con-
ference on AI, pages 75?88.
4Reuters Corpus, Volume 1, English language, 1996-08-20
to 1997-08-19 (Release date 2000-11-03, Format version 1, cor-
rection level 0).
143
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 215?222,
Beijing, August 2010
An ontology-driven system for detecting global health events
Nigel Collier
National Inst. Informatics
collier@nii.ac.jp
Reiko Matsuda Goodwin
Fordham University
reikogoodwin@gmail.com
John McCrae
Bielefeld University
johnmccrae@gmail.com
Son Doan
Vanderbilt University
son.doan@vanderbilt.edu
Ai Kawazoe
Tsuda College
zoeai@tsuda.ac.jp
Mike Conway
University of Pittsburgh
conwaym@pitt.edu
Asanee Kawtrakul
Kasetart University
ak@ku.ac.th
Koichi Takeuchi
Okayama University
koichi@cs.okayama-u.ac.jp
Dinh Dien
VietNam National University
ddien66@yahoo.com
Abstract
Text mining for global health surveillance
is an emerging technology that is gaining
increased attention from public health or-
ganisations and governments. The lack
of multilingual resources such as Word-
Nets specifically targeted at this task have
so far been a major bottleneck. This pa-
per reports on a major upgrade to the
BioCaster Web monitoring system and
its freely available multilingual ontology;
improving its original design and extend-
ing its coverage of diseases from 70 to 336
in 12 languages.
1 Introduction
The number of countries who can sustain teams
of experts for global monitoring of human/animal
health is limited by scarce national budgets.
Whilst some countries have advanced sensor net-
works, the world remains at risk from the health
impacts of infectious diseases and environmen-
tal accidents. As seen by the recent A(H5N1),
A(H1N1) and SARS outbreaks, a problem in one
part of the world can be rapidly exported, leading
to global hardship.
The World Health Organization (WHO) esti-
mates that in the future, between 2 to 7.4 mil-
lion people could be at risk worldwide from a
highly contageous avian flu virus that spreads
rapidly through the international air travel net-
work (WHO, 2005). Pandemics of novel
pathogens have the capacity to overwhelm health-
care systems, leading to widespread morbidity,
mortality and socio-economic disruption (Cox
et al, 2003). Furthermore, outbreaks of live-
stock diseases, such as foot-and-mouth disease or
equine influenza can have a devastating impact on
industry, commerce and human health (Blake et
al., 2003). The challenge is to enhance vigilance
and control the emergence of outbreaks. Whilst
human analysis remains essential to spot complex
relationships, automated analysis has a key role
to play in filtering the vast volume of data in real
time and highlighting unusual trends using reli-
able predictor indicators.
BioCaster (http://born.nii.ac.jp) (Collier et al,
2008) is a Web 2.0 monitoring station for the early
detection of infectious disease events. The sys-
tem exploits a high-throughput semantic process-
ing pipeline, converting unstructured news texts
to structured records, alerting events based on
time-series analysis and then sharing this informa-
tion with users via geolocating maps (Fig. 1(a)),
graphs (Fig. 1(b)) and alerts. Underlying the sys-
tem is a publicly available multilingual applica-
tion ontology. Launched in 2006 (Collier et al,
2006) the BioCaster Ontology (BCO) has been
downloaded by over 70 academic and industrial
groups worldwide. This paper reports on a ma-
jor upgrade to the system and the ontology - ex-
panding the number of languages from 6 to 12,
redefining key relations and extending coverage in
the number of diseases from 70 to 336, including
many veterinary diseases.
215
(a) Bio-geographic map (b) Trend graph analyser
(c) BioCaster processes
Figure 1: (a)BioCaster?s bio-geographic map for a suspected foot-and-mouth outbreak on 22nd March,
2010 with links to the multilingual ontology, NCBI, HighWire, GoPubMed and Google Scholar; (b)
The trends analyser showing aggregated document counts for health events in China between 13nd
March and 12th April, 2010; (c) The system?s pipeline of processes with example semantic markup.
216
2 Background
As the world becomes more interconnected and
urbanized and animal production becomes in-
creasingly intensive, the speed with which epi-
demics spread becomes faster, adding to pressure
on biomedical experts and governments to make
quick decisions. Traditional validation methods
such as field investigations or laboratory analysis
are the mainstay of public health but can require
days or weeks to issue reports. The World Wide
Web with its economical and real time delivery of
information represents a new modality in health
surveillance (Wagner and Johnson, 2006) and has
been shown to be an effective source by the World
Health Organization (WHO) when Public Health
Canada?s GPHIN system detected the SARS out-
break in southern China from news reports dur-
ing November 2002. The recent A(H1N1) ?swine
flu? pandemic highlighted the trend towards agen-
cies using unvalidated sources. The technologi-
cal basis for such systems can be found in sta-
tistical classification approaches and light weight
ontological reasoning. For example, Google Flu
Trends (Ginsberg et al, 2009) is a system that de-
pends almost entirely on automatic statistical clas-
sification of user queries; MedISys-PULS (Yan-
garber et al, 2008), HealthMap (Freifeld et al,
2008) and BioCaster use a mixture of statisti-
cal and ontological classification; and GPHIN
(Mawudeku and Blench, 2006) and Argus (Wil-
son, 2007) rely on a mixture of ontological classi-
fication and manual analysis.
Compared to other similar systems BioCaster
is characterized by its richly featured and pub-
licly downloadable ontology and emphasizes crit-
ical evaluation of its text mining modules. Em-
pirical results have included: topic classification,
named entity recognition, formal concept anal-
ysis and event recognition. In the absence of
a community gold standard, task performance
was assessed on the best available ?silver? stan-
dard - the ProMED-mail network (Madoff and
Woodall, 2005), achieving F-score of 0.63 on 14
disease-country pairs over a 365-day period (Col-
lier, 2010).
Despite initial skepticism within the public
health community, health surveillance systems
based on NLP-supported human analysis of me-
dia reports are becoming firmly established in
Europe, North America and Japan as sources of
health information available to governments and
the public (Hartley et al, 2010). Whilst there is no
substitute for trained human analysts, automated
filtering has helped experts save time by allow-
ing them to sift quickly through massive volumes
of media data. It has also enabled them to sup-
plement traditional sources with a broader base of
information.
In comparison with other areas of biomedical
NLP such as the clinical and genetics? domains, a
relative lack of building block resources may have
hindered the wider participation of NLP groups
in public health applications. It is hoped that the
provision of common resources like the BCO can
help encourage further development and bench-
marking.
3 Method
BioCaster performs analysis of over 9000 news ar-
ticles per day using the NPACI Rocks cluster mid-
dleware (http://www.rockcsclusters.org) on a plat-
form of 48 3.0GHz Xeon cores. Data is ingested
24/7 into a semantic processing pipeline in a short
1 hour cycle from over 1700 public domain RSS
feeds such as Google news, the European Media
Monitor and ProMED-mail. Since 2009, news has
also being gathered under contract from a com-
mercial news aggregation company, providing ac-
cess to over 80,000 sources across the world?s lan-
guages.
The new 2010 version of BioCaster uses ma-
chine translation into English (eleven languages)
to source news stories related to currently oc-
curring infectious and environmental disease out-
breaks in humans, animals and plants.
Access to the site is freely available but lo-
gin registration applies to some functions such as
email alerts. Processing is totally automatic, but
we have the potential within the login system to
enable human moderated alerts which broadcast
to Twitter and RSS.
Below we describe in detail two key aspects of
the system that have been significantly upgraded:
the BCO and the event detection system.
217
3.1 Ontology
3.1.1 Aim
The BioCaster Ontology aims:
? To describe the terms and relations necessary
to detect and risk assess public health events
in the grey literature;
? To bridge the gap between (multilingual)
grey literature and existing standards in
biomedicine;
? To mediate integration of content across lan-
guages;
? To be freely available.
The central knowledge source for BioCaster
is the multilingual ontology containing domain
terms such as diseases, agents, symptoms, syn-
dromes and species as well as domain sensitive
relations such as a disease causing symptoms or
an agent affecting particular host species. This al-
lows the text mining system to have a basic un-
derstanding of the key concepts and relationships
within the domain to fill in gaps not mentioned
explicitly in the news reports. To the best of our
knowledge the BCO is unique as an application
ontology, providing freely available multilingual
support to system developers interested in out-
break surveillance in the language of the open me-
dia.
The BCO however has little to say outside of
its application domain, e.g. in disease-gene in-
teraction or for supporting automatic diagnosis.
As discussed in Grey Cowell and Smith (2010),
there are many other resources available that have
the potential to support applications for infec-
tious disease analysis including controlled vocab-
ularies and ontologies such as the the Unified
Medical Language System (UMLS) (Lindberg et
al., 1993), International Classification of Diseases
(ICD-10) (WHO, 2004), SNOMED CT (Stearns
et al, 2001), Medical Subject Headings (MeSH)
(Lipscomb, 2000) and the Infectious Disease On-
tology (IDO) (Grey Cowell and Smith, 2010). In
(Collier et al, 2006) we discussed how BCO com-
pared to such ontologies so we will focus from
now on the implication of the extensions.
3.1.2 Scope
The new version of the BCO now covers 12 lan-
guages including all the United Nation?s official
languages: Arabic (968 terms), English (4113),
French (1281), Indonesian (1081), Japanese
(2077), Korean (1176), Malaysian (1001), Rus-
sian (1187), Spanish (1171), Thai (1485), Viet-
namese (1297) and Chinese (1142). The multi-
lingual ontology can be used as a direct knowl-
edge source in language-specific text mining mod-
ules, as an indexing resource for searching across
concepts in various languages and as a dictionary
for future translation modules. Currently news in
all 12 languages is available via the Web portal
but news in additional languages such as German,
Italian and Dutch are being added using machine
translation.
3.1.3 Design
Like EuroWordNet (Vossen, 1998), on which
it is loosely based, the BCO adopts a thesaurus-
like structure with synonym sets linking to-
gether terms across languages with similar mean-
ing. Synonym sets are referred to using root
terms. Root terms themselves are fully defined in-
stances that provide bridges to external classifica-
tion schemes and nomenclatures such as ICD10,
MeSH, SNOMED CT and Wikipedia. The central
backbone taxonomy is deliberately shallow and
taken from the ISO?s Suggested Upper Merged
Ontology (Niles and Pease, 2001). To maintain
consistency and computability we kept a single
inheritance structure throughout. 18 core domain
concepts corresponding to named entities in the
text mining system such as DISEASE and SYMP-
TOM were the results of analysis using a formal
theory (Guarino and Welty, 2000).
We have endeavoured to construct definitions
for root terms along Aristotelean principles by
specifying the difference to the parent. For ex-
ample in the case of Eastern encephalitis virus:
Eastern equine encephalitis virus is a
species of virus that belongs to the
genus Alphavirus of the family Togaviri-
dae (order unassigned) of the group
IV ((+)ssRNA) that possesses a positive
single stranded RNA genome. It is the
218
etiological agent of the eastern equine
encephalitis.
We are conscious though that terms used in
the definitions still require more rigorous control
to be considered useful for machine reasoning.
To aid both human and machine analysis root
terms are linked by a rich relational structure
reflecting domain sensitive relations such as
causes(virus,disease), has symptom(disease,
symptom), has associated syndrome(disease,
syndrome), has reservoir(virus, organism).
In such a large undertaking, the order of work
was critical. We proceeded by collecting a list of
notifiable diseases from national health agencies
and then grouped the diseases according to per-
ceived relevance to the International Health Reg-
ulations 2005 (Lawrence and Gostin, 2004). In
this way we covered approximately 200 diseases,
and then explored freely available resources and
the biomedical literature to find academic and lay-
man?s terminology to describe their agents, af-
fected hosts, vector species, symptoms, etc. We
then expanded the coverage to less well known
human diseases, zoonotic diseases, animal dis-
eases and diseases caused by toxic substances
such as sarin, hydrogen sulfide, sulfur dioxide and
ethylene. At regular stages we checked and val-
idated terms against those appearing in the news
media.
As we expanded the number of conditions to in-
clude veterinary diseases we found a major struc-
tural reorganization was needed to support animal
symptoms. For example, a high temperature in
humans would not be the same as one in bovids.
This prompted us in the new version to group dis-
eases and symptoms around major animal familes
and related groups, e.g. high temperature (human)
and high temperature (bovine).
A second issue that we encountered was the
need to restructure the hierarchy under Organi-
cObject which was divided between MicroOrgan-
ism and Animal. The structure of the previous
version meant that the former were doing dou-
ble duty as infecting agents and the later were af-
fected hosts. The MicroOrganism class contained
bacterium, helminth, protozoan, fungus and virus,
which then became the domain in a relation ?x
causes y?. Expansion forced us to accomodate the
fact that some animals such as worms and mites
(e.g. scabies) also infect humans as well as ani-
mals. The result was a restructuring of the organic
classes using the Linnean taxonomy as a guide-
line, although this is probably not free from errors
(e.g. virus is typically not considered to be an or-
ganism).
3.2 Event alerting system
Figure 1(c) shows a schematic of the modular de-
sign used by the BioCaster text mining system.
Following on from machine translation and topic
classification is named entity recognition and tem-
plate recognition which we describe in more detail
below. The final structured event frames include
slot values normalized to ontology root terms for
disease, pathogen (virus or bacterium), country
and province. Additionally we also identify 15 as-
pects of public health events critical to risk assess-
ment such as: spread across international borders,
hospital worker infection, accidental or deliberate
release, food contamination and vaccine contami-
nation.
Latitude and longitude of events down to the
province level are found in two ways: using the
Google API up to a limit of 15000 lookups per
day, and then using lookup on the BCO taxonomy
of 5000 country and province names derived from
open sources such as Wikipedia.
Each hour events are automatically alerted to
a Web portal page by comparing daily aggre-
gated event counts against historical norms (Col-
lier, 2010). Login users can also sign up to receive
emails on specific topics. A topic would normally
specify a disease or syndrome, a country or region
and a specific risk condition.
In order to extract knowledge from docu-
ments, BioCaster maintains a collection of rule
patterns in a regular expression language that
converts surface expressions into structured in-
formation. For example the surface phrase
?man exposes airline passengers to measles?
would be converted into the three templates
?species(human); disease(measles); interna-
tional travel(true)?. Writing patterns to produce
such templates can be very time consuming and
so the BioCaster project has developed its own
219
D3: :- name(disease){ list(@undiagnosed) words(,1) list(@disease) }
S2: :- name(symptom) { list(@severity) list(@symptom)}
CF1: contaminated food(?true?) :- ?caused? ?by? list(@contaminate verbs past)
list(@injested material)
SP4: species(?animal?) :- name(animal,A) words(,3) list(@cull verbs past)
Table 1: Examples of SRL rules for named entity and template recognition. Template rules contain
a label, a head and a body, where the head specifies the template pattern to be output if the body
expression matches. The body can contain word lists, literals, and wild cards. Various conditions can
be placed on each of these such as orthographic matching.
light weight rule language - called the Simple
Rule Language (SRL) and a pattern building inter-
face for maintaining the rule base (McCrae et al,
2009). Both are freely available to the research
community under an open source license. Cur-
rently BioCaster uses approximately 130 rules for
entity recognition, 1000 word lists and 3200 tem-
plate rules (of which half are for location recogni-
tion) to identify events of interest in English. Us-
ing SRL allows us to quickly adapt the system to
newly emerging terminology such as the 11+ des-
ignations given to A(H1N1) during the first stages
of the 2009 pandemic.
The SRL rulebook for BioCaster can recognize
a range of entities related to the task of disease
surveillance such as bacteria, chemicals, diseases,
countries, provinces, cities and major airports.
Many of these classes are recognized using terms
imported from the BCO. The rule book also con-
tains specialised thesauri to recognize subclasses
of entities such as locations of habitation, eater-
ies and medical service centres. Verb lists are
maintained for lexical classes such as detection,
mutation, investigation, causation, contamination,
culling, blaming, and spreading.
Some examples of SRL rules for named entity
recognition are shown in Table 1 and described
below:
Rule D3 in the rulebook tags phrases like ?mys-
tery illness? or ?unknown killer bug? by matching
on strings contained within two wordlists, @un-
diagnosed and @disease, separated by up to one
word.
Rule S2 allows severity indicators such as ?se-
vere? or ?acute? to modify a list of known symp-
toms in order to identify symptom entities.
Rule CF1 is an example of a template rule. If
the body of the rule matches by picking out ex-
pressions such as ?was caused by tainted juice?,
this triggers the head to output an alert for con-
taminated food.
Rule SP4 identifies the victim species as ?ani-
mal? in contexts like ?250 geese were destroyed?.
The rulebook also supports more complex in-
ferences such as the home country of national
public health organizations.
Since BioCaster does not employ systematic
manual checking of its reports, it uses a number of
heuristic filters to increase specificity (the propor-
tion of correctly identified negatives) for reports
that appear on the public Web portal pages. For
example, reports with no identified disease and
country are rejected. Since these heuristics may
reduce sensitivity they are not applied to news that
appears on the user login portal pages.
4 Results and Discussion
Version 3 of the ontology represents a significant
expansion in the coverage of diseases, symptoms
and pathogens on version 2. Table 2 summarizes
the number of root terms for diseases classified by
animal familes.
The thesaurus like structure of the BCO is com-
patible in many respects to the Simple Knowledge
Organization System (SKOS) (Miles et al, 2005).
In order to extend exchange and re-use we have
produced a SKOS version of the BCO which is
available from the BCO site. We have also con-
verted the BCO terms into 12 SRL rule books (1
for each language) for entity tagging. These too
are freely available from the BCO site.
As the ontology expands we will consider
adopting a more detailed typing of diseases such
as hasInfectingPart to indicate the organ affected
220
Species N Example
Avian 22 Fowl pox
Bee 6 Chalk brood
disease
Bovine 24 Bluetongue
Canine 4 Blastomycosis
(Canine)
Caprine 14 Contagious
agalactia
Cervine 2 Chronic wasting
disease
Equine 17 Strangles
Feline 4 Feline AIDS
Fish 2 Viral hemorr
hagic septicemia
Human 216 Scarlet fever
Lagomorph 2 Myxomatosis
Non-human 16 Sylvan
primate yellow fever
Other 2 Crayfish plague
Rodent 8 Colorado tick
fever (Rodent)
Swine 12 Swine erysipelas
Table 2: Major disease groups organized by af-
fected animal family. N represents the number of
root terms.
or hasProtectionMethod to indicate broad classes
of methods used to prevent or treat a condition.
The typology of diseases could also be extended
in a more fine grained manner to logically group
conditions, e.g. West Nile virus encephalitis,
Powassan encephalitis and the Japanese B en-
cephalitis could be connected through a hasType
relation on encephalitis.
5 Conclusion
Multilingual resources specifically targeted at the
task of global health surveillance have so far been
very rare. We hope that the release of version 3
can be used to support a range of applications such
as text classification, cross language search, ma-
chine translation, query expansion and so on.
The BCO has been constructed to provide core
vocabulary and knowledge support to the Bio-
Caster project but it has also been influential
in the construction of other public health ori-
ented application ontologies such as the Syn-
dromic Surveillance Ontology (Okhamatovskaia
et al, 2009). The BCO is freely available from
http://code.google.com/p/biocaster-ontology/ un-
der a Creative Commons license.
Acknowledgements
The authors greatly acknowledge the many co-
workers who have provided comments and feed-
back on BioCaster. Funding support was pro-
vided in part by the Japan Science and Technology
Agency under the PRESTO programme.
References
Blake, A., M. T. Sinclair, and G. Sugiyarto. 2003.
Quantifying the impact of foot and mouth disease on
tourism and the UK economy. Tourism Economics,
9(4):449?465.
Collier, N., A. Kawazoe, L. Jin, M. Shigematsu,
D. Dien, R. Barrero, K. Takeuchi, and A. Kaw-
trakul. 2006. A multilingual ontology for infectious
disease surveillance: rationale, design and chal-
lenges. Language Resources and Evaluation, 40(3?
4). DOI: 10.1007/s10579-007-9019-7.
Collier, N., S. Doan, A. Kawazoe, R. Matsuda Good-
win, M. Conway, Y. Tateno, Q. Ngo, D. Dien,
A. Kawtrakul, K. Takeuchi, M. Shigematsu, and
K. Taniguchi. 2008. BioCaster:detecting public
health rumors with a web-based text mining sys-
tem. Bioinformatics, 24(24):2940?1, December.
doi:10.1093/bioinformatics/btn534.
Collier, N. 2010. What?s unusual in online dis-
ease outbreak news? Biomedical Semantics, 1(1),
March. doi:10.1186/2041-1480-1-2.
Cox, N., S. Temblyn, and T. Tam. 2003. Influenza
pandemic planning. Vaccine, 21(16):1801?1803.
Freifeld, C., K. Mandl, B. Reis, and J. Brownstein.
2008. Healthmap: global infectious disease mon-
itoring through automated classification and visual-
ization of internet media reports. J. American Med-
ical Informatics Association, 15:150?157.
Ginsberg, J., M. Mohebbi, R. Patel, L. Brammer,
M. Smolinski, and L. Brilliant. 2009. Detecting
influenza epidemics using search engine query data.
Nature, 457:1012?1014.
Grey Cowell, L. and B. Smith. 2010. Infectious dis-
ease informatics. In Sintchenko, V., editor, Infec-
tious Disease Informatics, pages 373?395. Springer
New York.
221
Guarino, N. and C. Welty. 2000. A formal ontology
of properties. In Dieng, R. and O. Corby, editors,
EKAW-2000: Proc. 12th Int. Conf. on Knowledge
Engineering and Knowledge Management, pages
97?112.
Hartley, D., N. Nelson, R. Walters, R. Arthur, R. Yan-
garber, L. Madoff, J. Linge, A. Mawudeku, N. Col-
lier, J. Brownstein, G. Thinus, and N. Lightfoot.
2010. The landscape of international biosurveil-
lance. Emerging Health Threats J., 3(e3), January.
doi:10.1093/bioinformatics/btn534.
Lawrence, O. and J. Gostin. 2004. International
infectious disease law - revision of the World
Health Organization?s international health regula-
tions. J. American Medical Informatics Associa-
tion, 291(21):2623?2627.
Lindberg, Donald A.B., L. Humphreys, Betsy, and
T. McCray, Alexa. 1993. The unified medical lan-
guage system. Methods of Information in Medicine,
32:281?291.
Lipscomb, C. 2000. Medical subject headings
(MeSH). Bulletin of the Medical Library Assoca-
tion, 88:256?266.
Madoff, Lawrence C. and John P. Woodall. 2005. The
internet and the global monitoring of emerging dis-
eases: Lessons from the first 10 years of promed-
mail. Archives of Medical Research, 36(6):724 ?
730. Infectious Diseases: Revisiting Past Problems
and Addressing Future Challenges.
Mawudeku, A. and M. Blench. 2006. Global pub-
lic health intelligence network (gphin). In Proc. 7th
Int. Conf. of the Association for Machine Transla-
tion in the Americas, Cambridge, MA, USA, August
8?12.
McCrae, J., M. Conway, and N. Collier. 2009. Simple
rule language editor. Google code project, Septem-
ber. Available from: http://code.google.com/p/srl-
editor/.
Miles, A., B. Matthews, and M. Wilson. 2005. SKOS
Core: Simple knowledge organization for the web.
In Proc. Int. Conf. on Dublin Core and Metadata
Applications, Madrid, Spain, 12?15 September.
Niles, I. and A. Pease. 2001. Towards a standard up-
per ontology. In Welty, C. and B. Smith, editors,
2nd Int. Conf. on Formal Ontology in Information
Systems FOIS-2001, Maine, USA, October 17?19.
Okhamatovskaia, A., W. Chapman, N. Collier, J. Es-
pino, and D. Buckeridge. 2009. SSO: The syn-
dromic surveillance ontology. In Proc. Int. Soc. for
Disease Surveillance, Miami, USA, December 3?4.
Stearns, M. Q., C. Price, K. A. Spackman, and A. Y.
Wang. 2001. SNOMED clinical terms: overview of
the development process and project status. In Proc.
American Medical Informatics Association (AMIA)
Symposium, pages 662?666.
Vossen, P. 1998. Introduction to EuroWordNet. Com-
puters and the Humanities, 32:73?89.
Wagner, M. and H. Johnson. 2006. The internet as
sentinel. In Wagner, M. et al, editor, The Hand-
book of Biosurveillance, pages 375?385. Academic
Press.
WHO. 2004. ICD-10, International Statistical Classi-
fication of Diseases and Related Health Problems,
Tenth Revision. World Health Organization, De-
cember.
WHO. 2005. Avian influenza: assessing the pandemic
threat. Technical Report WHO/CDS/2005.29,
World Health Organization, Geneva, January.
Wilson, J. 2007. Argus: a global detection and track-
ing system for biological events. Advances in Dis-
ease Surveillance, 4.
Yangarber, R., P. von Etter, and R. Steinberger. 2008.
Content collection and analysis in the domain of
epidemiology. In Proc. Int. Workshop on Describ-
ingMedical Web Resources (DRMED 2008), Goten-
burg, Sweden, May 27th.
222
Proceedings of the 6th Workshop on Ontologies and Lexical Resources (Ontolex 2010), pages 58?66,
Beijing, August 2010
Developing a Biosurveillance Application Ontology for
Influenza-Like-Illness
Mike Conway, John Dowling and Wendy Chapman
Department of Biomedical Informatics
University of Pittsburgh
{conwaym|dowling|wec6}@pitt.edu
Abstract
Increasing biosurveillance capacity is a
public health priority in both the devel-
oped and the developing world. Effec-
tive syndromic surveillance is especially
important if we are to successfully iden-
tify and monitor disease outbreaks in their
early stages. This paper describes the
construction and preliminary evaluation
of a syndromic surveillance orientated ap-
plication ontology designed to facilitate
the early identification of Influenza-Like-
Illness syndrome from Emergency Room
clinical reports using natural language
processing.
1 Introduction and Motivation
Increasing biosurveillance capacity is a public
health priority in both the developed and devel-
oping world, both for the early identification of
emerging diseases and for pinpointing epidemic
outbreaks (Chen et al, 2010). The 2009 Mexican
flu outbreak provides an example of how an out-
break of a new disease (in this case a new vari-
ant of H1N1 influenza) can spend some weeks
spreading in a community before it is recognized
as a threat by public health officials.
Syndromic surveillance is vital if we are to de-
tect outbreaks at an early stage (Henning, 2004;
Wagner et al, 2006). The United States Cen-
ter for Disease Control (CDC) defines syndromic
surveillance as ?surveillance using health-related
data that precede diagnosis and signal a sufficient
probability of a case or outbreak to warrant fur-
ther public health response.?1 That is, the focus of
1www.webcitation.org/5pxhlyaxX
syndromic surveillance is the identification of dis-
ease outbreaks before the traditional public health
apparatus of confirmatory laboratory testing and
official diagnosis can be used. Data sources for
syndromic surveillance have included, over the
counter pharmacy sales (Tsui et al, 2003), school
absenteeism records (Lombardo et al, 2003), calls
to NHS Direct (a nurse led information and advice
service in the United Kingdom) (Cooper, 2007),
and search engine queries (Eysenbach, 2006).
However, in this paper we concentrate on min-
ing text based clinical records for outbreak data.
Clinical interactions between health workers and
patients generate large amounts of textual data ?
in the form of clinical reports, chief complaints,
and so on ? which provide an obvious source of
pre-diagnosis information. In order to mine the
information in these clinical reports we are faced
with two distinct problems:
1. How should we define a syndrome of inter-
est? That is, how are signs and symptoms
mapped to syndromes?
2. Given that we have established such a set
of mappings, how then do we map from the
text in our clinical reports to the signs and
symptoms that constitute a syndrome, given
the high level of terminological variability in
clinical reports.
This paper presents an application ontology that
attempts to address both these issues for the do-
main of Influenza-Like-Illness Syndrome (ILI).
The case definition for ILI, as defined by the
United States Center for Disease Control is ?fever
greater than or equal to 100 degrees Fahrenheit
58
and either cough or sore throat.?2 In contrast
to the CDC?s straightforward definition, the syn-
drome is variously described as a cluster of symp-
toms and findings, including fever and cold symp-
toms, cough, nausea, vomiting, body aches and
sore throat (Scholer, 2004). In constructing an ap-
plication specific syndrome definition for this on-
tology, we used a data driven approach to defining
ILI, generating a list of terms through an analysis
of Emergency Room reports.
The remainder of the paper is divided into five
parts. First, we briefly describe related work, be-
fore going on to report on the ontology develop-
ment process. We then set forth an evaluation of
the ontology with respect to its coverage of terms
in the target domain. We go on to outline areas for
future work, before finally presenting some con-
cluding comments.
2 Related Work
In recent years there has been significant progress
in interfacing lexical resources (in particular
WordNet (Miller, 1995)) and upper level ontolo-
gies (like the Descriptive Ontology for Linguistic
and Cognitive Engineering (DOLCE) (Gangemi
et al, 2002) and the Suggested Upper Merged On-
tology (SUMO) (Niles and Pease, 2003)). How-
ever, as our domain of interest employs a highly
specialized terminology, the use of general lin-
guistic resources like WordNet was inappropriate.
Our work has focused on the representation of
ILI relevant concepts that occur in clinical re-
ports in order to facilitate syndromic surveillance.
While the widely used medical taxonomies and
nomenclatures (for example Unified Medical Lan-
guage System3 and the Systematized Nomencla-
ture of Medicine Clinical Terms4) contain many
of the ILI relevant concepts found in clinical texts,
these general resources do not have the specific re-
lations (and lexical information) relevant to syn-
dromic surveillance from clinical reports. Cur-
rently, there are at least four major terminological
resources available that focus on the public health
domain: PHSkb, SSO, and the BioCaster Ontol-
ogy.
2www.webcitation.org/5q22KTcHx
3www.nlm.nih.gov/research/umls/
4www.ihtsdo.org/snomed-ct/
2.1 PHSkb
The Public Health Surveillance knowledge base
PHSkb (Doyle et al, 2005) developed by the CDC
is a coding system for the communication of no-
tifiable disease5 findings for public health profes-
sionals at the state and federal level in the United
States. There are however several difficulties in
using the PHSkb directly in an NLP orientated
syndromic surveillance context:
1. Syndromic surveillance requires that syn-
dromes and signs are adequately represented.
The PHSkb emphasizes diagnosed diseases.
That is, the PHSKb is focused on post diag-
nosis reporting, when laboratory tests have
been conducted and the presence of a disease
is confirmed. This approach is not suitable
for syndromic surveillance where we seek to
identify clusters of symptoms and signs be-
fore a diagnosis.
2. PHSkb is no longer under active develop-
ment.
2.2 SSO
The Syndromic Surveillance Ontology (SSO)
(Okhmatovskaia et al, 2009) was developed to
address a pressing problem for system develop-
ers and public health officials. How can we inte-
grate outbreak information when every site uses
different syndrome definitions? For instance, if
State X defines sore throat as part of ILI, yet State
Y does not, syndromic surveillance results from
each state will not be directly comparable. When
we apply this example to the wider national scene,
with federal regional and provincial public health
agencies attempting to share data with each other,
and international agencies, we can see the scale of
the problem to be addressed.
In order to manage this data sharing problem,
a working group of eighteen researchers, repre-
senting ten functional syndromic surveillance sys-
tems in the United States (for example, Boston
Public Health Department and the US Depart-
ment of Defense) convened to develop standard
5A notifiable disease is a disease (or by extension, con-
dition) that must, by law, be reported to the authorities for
monitoring purposes. In the United States, examples of noti-
fiable diseases are: Shigellosis, Anthrax and HIV infection.
59
definitions for four syndromes of interest (respi-
ratory, gastro-intestinal, constitutional and ILI)6
and constructed an OWL ontology based on these
definitions. While the SSO is a useful starting
points, there are several reasons why ? on its own
? it is insufficient for clinical report processing:
1. SSO is centered on chief complaints. Chief
complaints (or ?presenting complaints?) are
phrases that briefly describe a patient?s pre-
senting condition on first contact with a med-
ical facility. They usually describe symp-
toms, refrain from diagnostic speculation
and employ frequent abbreviations and mis-
spellings (for example ?vom + naus? for
?vomiting and nausea?). Clinical texts ?
the focus of attention in this paper ? are
full length documents, normally using cor-
rect spellings (even if they are somewhat
?telegraphic? in style). Furthermore, clini-
cal reports frequently list physical findings
(that is, physical signs elicited by the physi-
cian, like, for instance reflex tests) which are
not present in symptom orientated chief com-
plaints.
2. The range of syndromes represented in SSO
is limited to four. Although we are starting
out with ILI, we have plans (and data) to ex-
tend our resource to four new syndromes (see
Section 5 for details of further work).
3. The most distinctive feature of the SSO is
that the knowledge engineering process was
conducted in a face-to-face committee con-
text. Currently, there is no process in place
to extend the SSO to new syndromes, symp-
toms or domains.
2.3 BioCaster Ontology
The BioCaster application ontology was built to
facilitate text mining of news articles for disease
outbreaks in several different Pacific Rim lan-
guages (including English, Japanese, Thai and
Vietnamese) (Collier et al, 2006). However, the
6A demonstration chief complaint classifier based on
SSO is available at:
http://onto-classifier.dbmi.pitt.edu
/onto classify.html
ontology, as it stands, is not suitable for support-
ing text mining clinical reports, for the following
reasons:
1. The BioCaster ontology concentrates on the
types of concepts found in published news
outlets for a general (that is, non medical)
readership. The level of conceptual granular-
ity and degree of terminological sophistica-
tion is not always directly applicable to that
found in documents produced by health pro-
fessionals.
2. The BioCaster ontology, while it does repre-
sent syndromes (for example, constitutional
and hemorrhagic syndromes) and symptoms,
does not represent physical findings, as these
are beyond its scope.
In addition to the application ontologies de-
scribed above, the Infectious Disease Ontology
provides an Influenza component (and indeed
wide coverage of many diseases relevant to syn-
dromic surveillance). In Section 5 we describe
plans to link to other ontologies.
3 Constructing the Ontology
Work began with the identification of ILI terms
from clinical reports by author JD (a board-
certified infectious disease physician with thirty
years experience of clinical practice) supported by
an informatician [author MC]. The term identifi-
cation process involved the project?s domain ex-
pert reading multiple reports,7 searching through
appropriate textbooks, and utilizing professional
knowledge. After a provisional list of ILI con-
cepts had been identified, we compared our list
to the list of ILI concepts generated by the SSO
ILI component (see Section 2.2) and attempted to
reuse SSO concepts where possible. The resulting
ILI concept list consisted of 40 clinical concepts
taken from SSO and 15 new concepts. Clinical
concepts were divided into three classes: Disease
(15 concepts), Finding (21 concepts) and Symp-
tom (19 concepts). Figure 1 shows the clinical
7De-identified (that is, anonymized) clinical reports were
obtained through partnership with the University of Pitts-
burgh Medical Center.
60
concepts covered. As part of our knowledge en-
gineering effort, we identified concepts and as-
sociated relations for several different syndromes
which we plan to add to our ontology at a later
date.8
Early on in the project development process, we
took the decision to design our ontology in such a
way as to maintain consistency with the BioCaster
ontology. We adopted the BioCaster ontology as
a model for three reasons:
1. A considerable knowledge engineering effort
has been invested in BioCaster since 2006,
and both the domain (biosurveillance) and
application area (text mining) are congruent
to our own.
2. The BioCaster ontology has proven utility in
its domain (biosurveillance from news texts)
for driving NLP systems.
3. We plan to import BioCaster terms and re-
lations, and thus settled on a structure that
facilitated this goal.
The BioCaster ontology (inspired by the struc-
ture of EuroWordNet9) uses root terms as interlin-
gual pivots for the multiple languages represented
in the ontology.10 One consequence of following
this structure is that all clinical concepts are in-
stances.11 Additionally, all specified relations are
relations between instances.
Relations relevant to the syndromic surveil-
lance domain generally were identified by our
physician in conjunction with an informatician
(MC). Although some of these relations (like
is bioterrorismDisease) are less relevant
to ILI syndrome, they were retained in order to
maintain consistency with planned future work.
Additionally, we have added links to other ter-
minological resources (for example, UMLS and
Snomed-CT)
8Note that finer granularity was used in the initial knowl-
edge acquisition efforts (for example, we distinguished sign
from physical finding).
9http://www.illc.uva.nl/EuroWordNet/
10Note that we are using root term instead of the equivalent
EuroWordNet term Inter Lingual Index.
11Note that from a formal ontology perspective, concepts
are instantiated in text. For example, ?Patient X presents with
nausea and high fever? instantiates the concepts nausea and
high fever.
Lexical resources and regular expressions are
a vital component of our project, as the ontology
has been built with the public health audience in
mind (in practice, state or city public health IT
personnel). These users have typically had lim-
ited exposure to NLP pipelines, named entity rec-
ognizers, and so on. They require an (almost) ?off
the shelf? product that can easily be plugged into
existing systems for text analysis.
The ontology currently includes 484 English
keywords and 453 English regular expression.
The core classes and relations were developed in
Protege-OWL, and the populated ontology is gen-
erated from data stored in a spreadsheet (using a
Perl script). Version control was managed using
Subversion, and the ontology is available from a
public access Google code site.12 Figure 2 pro-
vides a simplified example of relations for the
clinical concept instance fever.
4 Evaluation
In recent years, significant research effort has
centered on the evaluation of ontologies and
ontology-like lexical resources, with a smorgas-
bord of techniques available (Zhu et al, 2009;
Brank et al, 2005). Yet no single evaluation
method has achieved ?best practice? status for all
contexts. As our ontology is an application on-
tology designed to facilitate NLP in a highly con-
strained domain (that is, text analysis and infor-
mation extraction from clinical reports) the notion
of coverage is vital. There are two distinct ques-
tions here:
1. Can we map between the various textual in-
stantiations of ILI concepts clinical reports
and our ontology concepts? That is, are
the NLP resources available in the ontology
(keywords, regular expressions) adequate for
the mapping task?
2. Do we have the right ILI concepts in our on-
tology? That is, do we adequately represent
all the ILI concepts that occur in clinical re-
ports?
Inspired by Grigonyte et al (2010), we at-
tempted to address these two related issues using
12http://code.google.com/p/ss-ontology
61
ClinicalConcept
Disease
SymptomFinding
Instances:
 - athma
 - bronchiolitis
 - croup
 - ili
 - influenza
 - pertussis
 - pharyngitis
 - pneumonia
 - pneumonitis
 - reactiveAirways
 - respiratorySyncytialVirus
Instances:
 - chill
 - conjunctivitis
 - coryza
 - cyanosis
 - dyspnea
 - elevatedTemperature
 - failureToThrive
 - fever
 - hemoptysis
 - infiltrate
 - lethargy
 - nasalObstruction
 - persistentNonProductiveCough
 - photophobia
 - rales
 - rhinorrhea
 - rigor
 - somnolent
 - throatSwelling
 - wheezing
Instances:
 - anorexia
 - arthralgia
 - asthenia
 - bodyAche
 - coldSymptom
 - cough
 - diarrhea
 - fatigue
 - generalizedMuscleAche
 - headache
 - hoarseness
 - malaise
 - myalgia
 - nausea
 - painOnEyeMovement
 - productiveCough
 - soreThroat
 - substernalDiscomfortOrBurning
 - viralSymptom
 
is_a
is_a
is_a
Figure 1: Clinical concepts.
techniques derived from terminology extraction
and corpus linguistics. Our method consisted of
assembling a corpus of twenty Emergency Room
clinical reports which had been flagged by ex-
perts (not the current authors) as relevant to ILI.
Note that these articles were not used in the initial
knowledge engineering phase of the project. We
then identified the ?best? twenty five terms from
these clinical reports using two tools, Termine and
KWExT.
1. Termine (Frantzi et al, 2000) is a term ex-
traction tool hosted by Manchester Univer-
sity?s National Centre for Text Mining which
can be accessed via web services.13 It uses
a method based on linguistic preprocessing
and statistical methods. We extracted 231
terms from our twenty ILI documents (using
Termine?s default configuration). Then we
identified the twenty-five highest ranked dis-
ease, finding and symptom terms (that is, dis-
carding terms like ?hospital visit? and ?chief
complaint?).
13www.nactem.ac.uk/software/termine/
2. KWExT (Keyword Extraction Tool) (Con-
way, 2010) is a Linux based statistical key-
word extraction tool.14 We used KWExT
to extract 1536 unigrams, bigrams and tri-
grams using the log-likelihood method (Dun-
ning, 1993). The log-likelihood method is
designed to identify n-grams that occur with
the most frequency compared to some ref-
erence corpus. We used the FLOB cor-
pus,15 a one million multi-genre corpus con-
sisting of American English from the early
1990s as our reference corpus. We ranked
all n-grams according to their statistical sig-
nificance and then manually identified the
twenty-five highest ranked disease, finding
and symptom terms.
Term lists derived using the Termine and
KWExT tools are presented in Tables 1 and 2 re-
spectively. For both tables, column two (?Term?)
details each of the twenty-five ?best? terms (with
respect to each term recognition algorithm) ex-
14http://code.google.com/p/kwext/
15www.webcitation.org/5q1aKtnf3
62
Thing
ClinicalConcept
Syndrome
Keyword
Link
Regular
Expression
SymptomFinding
Disease
UmlsLink
English
Keyword
EnglishRegular
Expression
ILI
fever
elevated
Temperature
chill
"febrile"
"fever"
\bfiebre\b
\bfeel.*?\s+hot\b
is_a
is_a
is_a
is_a
is_a
is_a
is_a
is_a
i
is_a
is_a
is_a
instance
instance
instance
instance
instance
fever
instance
instance class
is_a
(class to class)
instance
(instance of a class)
relation
(instance to instance relation)
hasAssociatedSyndrome
hasKeyword
hasKeyword
isSynonymous
hasRegularExpression
hasRegularExpression
hasLink
isRelatedTo
instance
instance
instance
Figure 2: Example of clinical concept ?fever? and its important relations (note the diagram is simpli-
fied).
tracted from our twenty document ILI corpus.
Column three (?Concept?) specifies the concept in
our ontology to which the term maps (that is, the
lexical resources in the ontology ? keywords and
regular expressions ? can map the term in col-
umn two to the clinical concept in column three).
For instance the extracted term slight crackles can
be mapped to the clinical concept RALE using the
keyword ?crackles.? Note that ?-? in column three
indicates that no mapping was possible. Under-
lined terms are those that should be mapped to
concepts in the ontology, but currently are not (ad-
ditional concepts and keywords will be added in
the next iteration of the ontology).
There are two ways that mappings can fail here
(mirroring the two questions posed at the begin-
ning of this section). ?Shortness of breath? should
map to the concept DYSPNEA, but there is no key-
word or regular expression that can bridge be-
tween text and concept. For the terms ?edema?
and ?lymphadenopathy? however, no suitable can-
didate concept exists in the ontology.
5 Further Work
While the current ontology covers only ILI, we
have firm plans to extend the current work along
several different dimensions:
? Developing new relations, to include model-
ing DISEASE ? SYMPTOM, and DISEASE
? FINDING relations (for example TONSIL-
LITIS hasSymptom SORE THROAT).
? Extend the application ontology beyond ILI
to several other syndromes of interest to the
biosurveillance community. These include:
? Rash Syndrome
? Hemorrhagic Syndrome
? Botulic Syndrome
? Neurological Syndrome
? Currently, we have links to UMLS (and also
Snomed-CT and BioCaster). We intend to
extend our coverage to the MeSH vocabu-
lary (to facilitate mining PubMed) and also
the Infectious Disease Ontology.
63
Term Concept
1 abdominal pain -
2 chest pain -
3 urinary tract infection -
4 sore throat SORE THROAT
5 renal disease -
6 runny nose CORYZA
7 body ache MYALGIA
8 respiratory distress PNEUMONIA
9 neck stiffness -
10 yellow sputum -
11 mild dementia -
12 copd -
13 viral syndrome VIRAL SYN.
14 influenza INFLUENZA
15 febrile illness FEVER
16 lung problem -
17 atrial fibrillation -
18 severe copd -
19 mild cough COUGH
20 asthmatic bronchitis BRONCHIOLITIS
21 coronary disease -
22 dry cough COUGH
23 neck pain -
24 bronchial pneumonia PNEUMONIA
25 slight crackles RALE
Table 1: Terms generated using the Termine tool
? Currently evaluation strategies have concen-
trated on coverage. We plan to extend our
auditing to encompass both intrinsic evalu-
ation (for example, have our relations eval-
uated by external health professionals using
some variant of the ?laddering? technique
(Bright et al, 2009)) and extrinsic evaluation
(for example, plugging the application ontol-
ogy into an NLP pipeline for Named Entity
Recognition and evaluating its performance
in comparison to other techniques).
In addition to these ontology development and
evaluation goals, we intend to use the ontology as
a ?gold standard? against which to evaluate au-
tomatic term recognition and taxonomy construc-
tion techniques for the syndromic surveillance do-
main. Further, we seek to integrate the resulting
ontology with the BioCaster ontology allowing
the potential for limited interlingual processing in
priority languages (in the United States, Spanish).
Currently we are considering two ontology in-
tegration strategies. First, using the existing map-
pings we have created between the ILI ontology
and BioCaster to access multi-lingual information
(using OWL datatype properties). Second, fully
Term Concept
1 cough COUGH
2 fever FEVER
3 pain -
4 shortness of breath -
5 vomiting -
6 influenza INFLUENZA
7 pneumonia PNEUMONIA
8 diarrhea DIARRHEA
9 nausea NAUSEA
10 chills CHILL
11 abdominal pain -
12 chest pain -
13 edema -
14 cyanosis CYANOSIS
15 lymphadenopathy -
16 dysuria -
17 dementia -
18 urinary tract inf -
19 sore throat SORE THROAT
20 wheezing WHEEZING
21 rhonchi -
22 bronchitis BRONCHIOLITIS
23 hypertension -
24 tachycardia -
25 respiratory distress PNEUMONIA
Table 2: Terms generated using the KWExT tool
integrating ? that is, merging ? the two on-
tologies and creating object property relations be-
tween them.
For example (using strategy 1), we could move
from the string ?flu? in a clinical report (iden-
tified by the \bflu\b regular expression) to
the ILI ontology concept ili:influenza. In
turn, ili:influenza could be linked (using
a datatype property) to the BioCaster root term
biocaster:DISEASE 378 (which has the la-
bel ?Influenza (Human).?) From the BioCaster
root term, we can ? for example ? generate the
translation ?Gripe (Humano)? (Spanish).
6 Conclusion
The ILI application ontology developed from the
need for knowledge resources for the text mining
of clinical documents (specifically, Emergency
Room clinical reports). Our initial evaluation in-
dicates that we have good coverage of our domain,
although we plan to incrementally work on im-
proving any gaps in coverage through a process of
active and regular updating. We have described
our future plans to extend the ontology to new
syndromes in order to provide a general commu-
64
nity resource to facilitate data sharing and inte-
gration in the NLP based syndromic surveillance
domain. Finally, we actively solicit feedback on
the design, scope and accuracy of the ontology.
Acknowledgments
This project was partially funded by Grant Num-
ber 3-R01-LM009427-02 (NLM) from the United
States National Institute of Health.
References
Brank, J., Grobelnik, M., and Mladenic?, D.
(2005). A Survey of Ontology Evaluation Tech-
niques. In Proceedings of the Conference on
Data Mining and Data Warehouses (SiKDD
2005), pages 166?170.
Bright, T., Furuya, E., Kuperman, G., and Bakken,
S. (2009). Laddering as a Technique for On-
tology Evaluation. In American Medical Infor-
matics Symposium (AMIA 2009).
Chen, H., Zeng, D., and Dang, Y. (2010). Infec-
tious Disease Informatics: Syndromic Surveil-
lance for Public Health and Bio-Defense.
Springer, New York.
Collier, N., Shigematsu, M., Dien, D., Berrero,
R., Takeuchi, K., and Kawtrakul, A. (2006).
A Multilingual Ontology for Infectious Dis-
ease Surveillance: Rationale, Design and Chal-
lenges. Language Resources and Evaluation,
40(3):405?413.
Conway, M. (2010). Mining a Corpus of Bio-
graphical Texts Using Keywords. Literary and
Linguistic Computing, 25(1):23?35.
Cooper, D. (2007). Disease Surveillance: A Pub-
lic Health Informatics Approach, chapter Case
Study: Use of Tele-health Data for Syndromic
Surveillance in England and Wales, pages 335?
365. Wiley, New York.
Doyle, T., Ma, H., Groseclose, S., and Hopkins,
R. (2005). PHSkb: A Knowledgebase to Sup-
port Notifiable Disease Surveillance. BMC Med
Inform Decis Mak, 5:27.
Dunning, T. (1993). Accurate Methods for the
Statistics of Surprise and Coincidence. Com-
putational Linguistics, 19(1):61?74.
Eysenbach, G. (2006). Infodemiology: Track-
ing Flu-Related Searches on the Web for Syn-
dromic Surveillance. In American Medical In-
formatics Association Annual Symposium Pro-
ceedings (AMIA 2006), pages 244?248.
Frantzi, K., Ananiadou, S., and Mima, H.
(2000). Automatic Recognition for Multi-word
Terms. International Journal of Digital Li-
braries, 3(2):117?132.
Gangemi, A., Guarino, N., Masolo, C., Oltramari,
A., and Schneider, L. (2002). Sweetening On-
tologies with DOLCE. In Proceedings of the
13th International Conference on Knowledge
Engineering and Knowledge Management. On-
tologies and the Semantic Web, pages 166?181.
Grigonyte, G., Brochhausen, M., Martin, L., Tsik-
nakis, M., and Haller, J. (2010). Evaluating
Ontologies with NLP-Based Terminologies - A
Case Study on ACGT and its Master Ontol-
ogy. In Formal Ontology in Information Sys-
tems: Proceedings of the Sixth International
Conference (FOIS 2010), pages 331?344.
Henning, K. (2004). What is Syndromic Surveil-
lance? MMWR Morb Mortal Wkly Rep, 53
Suppl:5?11.
Lombardo, J., Burkom, H., Elbert, E., Ma-
gruder, S., Lewis, S. H., Loschen, W., Sari,
J., Sniegoski, C., Wojcik, R., and Pavlin, J.
(2003). A Systems Overview of the Electronic
Surveillance System for the Early Notification
of Community-Based Epidemics (ESSENCE
II). J Urban Health, 80(2 Suppl 1):32?42.
Miller, G. (1995). WordNet: A Lexical Database
for English. Communications of the Associa-
tion for Computing Machinary, 38(11):39?41.
Niles, I. and Pease, A. (2003). Linking Lexicons
and Ontologies: Mapping WordNet to the Sug-
gested Upper Merged Ontology. In Proceed-
ings of the 2003 International Conference on
Information and Knowledge Engineering (IKE
03), pages 23?26.
Okhmatovskaia, A., Chapman, W., Collier, N.,
Espino, J., and Buckeridge, D. (2009). SSO:
The Syndromic Surveillance Ontology. In Pro-
ceedings of the International Society for Dis-
ease Surveillance.
65
Scholer, M. (2004). Development of a Syndrome
Definition for Influenza-Like-Illness. In Pro-
ceedings of American Public Health Associa-
tion Meeting (APHA 2004).
Tsui, F., Espino, J., Dato, V., Gesteland, P., Hut-
man, J., and Wagner, M. (2003). Technical De-
scription of RODS: a Real-Time Public Health
Surveillance System. J Am Med Inform Assoc,
10(5):399?408.
Wagner, M., Gresham, L., and Dato, V. (2006).
Handbook of Biosurveillance, chapter Case
Detection, Outbreak Detection, and Outbreak
Characterization, pages 27?50. Elsevier Aca-
demic Press.
Zhu, X., Fan, J.-W., Baorto, D., Weng, C., and
Cimino, J. (2009). A Review of Auditing
Methods Applied to the Content of Controlled
Biomedical Terminologies. Journal of Biomed-
ical Informatics, 42(3):413 ? 425.
66
Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 36?44,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Corpus-Driven Terminology Development: Populating Swedish
SNOMED CT with Synonyms Extracted from Electronic Health Records
Aron Henriksson1, Maria Skeppstedt1, Maria Kvist1,2, Martin Duneld1, Mike Conway3
1Department of Computer and Systems Sciences (DSV), Stockholm University, Sweden
2Department of Learning, Informatics, Management and Ethics (LIME), Karolinska Institute, Sweden
3Division of Biomedical Informatics, University of California San Diego, USA
Abstract
The various ways in which one can re-
fer to the same clinical concept needs to
be accounted for in a semantic resource
such as SNOMED CT. Developing termi-
nological resources manually is, however,
prohibitively expensive and likely to re-
sult in low coverage, especially given the
high variability of language use in clinical
text. To support this process, distributional
methods can be employed in conjunction
with a large corpus of electronic health
records to extract synonym candidates for
clinical terms. In this paper, we exem-
plify the potential of our proposed method
using the Swedish version of SNOMED
CT, which currently lacks synonyms. A
medical expert inspects two thousand term
pairs generated by two semantic spaces ?
one of which models multiword terms in
addition to single words ? for one hundred
preferred terms of the semantic types dis-
order and finding.
1 Introduction
In recent years, the adoption of standardized ter-
minologies for the representation of clinical con-
cepts ? and their textual instantiations ? has en-
abled meaning-based retrieval of information from
electronic health records (EHRs). By identify-
ing and linking key facts in health records, the
ever-growing stores of clinical documentation now
available to us can more readily be processed
and, ultimately, leveraged to improve the qual-
ity of care. SNOMED CT1 has emerged as the
de facto international terminology for represent-
ing clinical concepts in EHRs and is today used
in more than fifty countries, despite only being
1http://www.ihtsdo.org/snomed-ct/
available in a handful of languages2. Translations
into several other languages are, however, under
way3. This translation effort is essential for more
widespread integration of SNOMED CT in EHR
systems globally.
Translating a comprehensive4 terminology such
as SNOMED CT to an additional language is,
however, a massive and expensive undertaking. A
substantial part of this process involves enrich-
ing the terminology with synonyms in the tar-
get language. SNOMED CT has, for instance,
recently been translated into Swedish; however,
the Swedish version does not as yet contain syn-
onyms. Methods and tools that can accelerate the
language porting process in general and the syn-
onym identification task in particular are clearly
needed, not only to lower costs but also to in-
crease the coverage of SNOMED CT in clinical
text. Methods that can account for real-world lan-
guage use in the clinical setting, then, as well as to
changes over time, are particularly valuable.
This paper evaluates a semi-automatic method
for the extraction of synonyms of SNOMED CT
preferred terms using models of distributional se-
mantics to induce semantic spaces from a large
corpus of clinical text. In contrast to most ap-
proaches that exploit the notion of distributional
similarity for synonym extraction, this method ad-
dresses the key problem of identifying synonymy
between terms of varying length: a simple solution
is proposed that effectively incorporates the notion
of paraphrasing in a distributional framework. The
semantic spaces ? and, by extension, the method ?
are evaluated for their ability to extract synonyms
of SNOMED CT terms of the semantic types dis-
order and finding in Swedish.
2SNOMED CT is currently available in US English, UK
English, Spanish, Danish and Swedish.
3http://www.ihtsdo.org/snomed-ct/
snomed-ct0/different-languages/
4SNOMED CT contains more than 300,000 active con-
cepts and over a million relations.
36
2 Background
Synonymy is an aspect of semantics that con-
cerns the fact that concepts can be instantiated
using multiple linguistic expressions, or, viewed
conversely, that multiple linguistic expressions
can refer to the same concept. As synonymous
expressions do not necessarily consist of single
words, we sometimes speak of paraphrasing rather
than synonymy (Androutsopoulos and Malakasio-
tis, 2010). This variability of language use needs
to be accounted for in order to build high-quality
natural language processing (NLP) and text min-
ing systems. This is typically achieved by us-
ing thesauri or encoding textual instantiations of
concepts in a semantic resource, e.g. an ontol-
ogy. Creating such resources manually is, how-
ever, prohibitively expensive and likely to lead
to low coverage, especially in the clinical genre
where language use variability is exceptionally
high (Meystre et al, 2008).
2.1 Synonym Extraction
As a result, the task of extracting synonyms ?
and other semantic relations ? has long been a
central challenge in the NLP research commu-
nity, not least in the biomedical (Cohen and Hersh,
2005) and clinical (Meystre et al, 2008) do-
mains. A wide range of techniques has been pro-
posed for relation extraction in general and syn-
onym extraction in particular ? lexico-syntactic
patterns (Hearst, 1992), distributional semantics
(Dumais and Landauer, 1997) and graph-based
models (Blondel et al, 2004) ? from a variety
of sources, including dictionaries (Blondel et al,
2004), linked data such as Wikipedia (Nakayama
et al, 2007), as well as both monolingual (Hindle,
1990) and multilingual (van der Plas and Tiede-
mann, 2006) corpora. In recent years, ensemble
methods have been applied to obtain better perfor-
mance on the synonym extraction task, combin-
ing models from different families (Peirsman and
Geeraerts, 2009), with different parameter settings
(Henriksson et al, 2012) and induced from differ-
ent data sources (Wu and Zhou, 2003).
In the context of biomedicine, the goal has of-
ten been to extract synonyms of gene and pro-
tein names from the biomedical literature (Yu and
Agichtein, 2003; Cohen et al, 2005; McCrae and
Collier, 2008). In the clinical domain, Conway
and Chapman (2012) used a rule-based approach
to generate potential synonyms from the BioPor-
tal ontology web service, verifying candidate syn-
onyms against a large clinical corpus. Zeng et
al. (2012) used three query expansion methods
for information retrieval of clinical documents and
found that a model of distributional semantics ?
LDA-based topic modeling ? generated the best
synonyms. Henriksson et al (2012) combined
models of distributional semantics ? random in-
dexing and random permutation ? to extract syn-
onym candidates for Swedish MeSH5 terms and
possible abbreviation-definition pairs. In the con-
text of SNOMED CT, distributional methods have
been applied to capture synonymous relations be-
tween terms of varying length: 16-24% of English
SNOMED CT synonyms present in a large clini-
cal corpus were successfully identified in a list of
twenty suggestions (Henriksson et al, 2013).
2.2 Distributional Semantics
Models of distributional semantics (see Cohen and
Widdows (2009) for an overview of methods and
their application in the biomedical domain) were
initially motivated by the inability of the vector
space model to account for synonymy, which had
a negative impact on recall in information retrieval
systems (Deerwester et al, 1990). The theoretical
foundation underpinning such models of seman-
tics is the distributional hypothesis (Harris, 1954),
according to which words with similar meanings
tend to appear in similar contexts. By exploiting
the availability of large corpora, the meaning of
terms can be modeled based on their distribution
in different contexts. An estimate of the semantic
relatedness between terms can then be quantified,
thereby, in some sense, rendering semantics com-
putable.
An obvious application of distributional seman-
tics is the extraction of semantic relations between
terms, such as synonymy, hyp(o/er)nymy and co-
hyponymy (Panchenko, 2013). As synonyms are
interchangeable in some contexts ? and thus have
similar distributional profiles ? synonymy is cer-
tainly a semantic relation that should be captured.
However, since hyp(o/er)nyms and co-hyponyms
? in fact, even antonyms ? are also likely to have
similar distributional profiles, such semantic rela-
tions will be extracted too.
Many models of distributional semantics dif-
fer in how context vectors, representing term
5Medical Subject Headings (http://www.nlm.nih.
gov/mesh).
37
meaning, are constructed. They are typically de-
rived from a term-context matrix that contains
the (weighted, normalized) frequency with which
terms occur in different contexts. Partly due
to the intractability of working with such high-
dimensional data, it is projected into a lower-
dimensional (semantic) space, while approxi-
mately preserving the relative distances between
data points. Methods that rely on computa-
tionally expensive dimensionality reduction tech-
niques suffer from scalability issues.
Random Indexing
Random indexing (RI) (Kanerva et al, 2000) is
a scalable and computationally efficient alterna-
tive in which explicit dimensionality reduction is
avoided: a lower dimensionality d is instead cho-
sen a priori as a model parameter and the d-
dimensional context vectors are then constructed
incrementally. Each unique term in the corpus is
assigned a static index vector, consisting of ze-
ros and a small number of randomly placed 1s
and -1s6. Each term is also assigned an initially
empty context vector, which is incrementally up-
dated by adding the index vectors of the surround-
ing words within a sliding window, weighted by
their distance to the target term. The semantic re-
latedness between two terms is then estimated by
calculating, for instance, the cosine similarity be-
tween their context vectors.
Random Permutation
Random permutation (RP) (Sahlgren et al, 2008)
is a modification of RI that attempts to take into
account term order information by simply permut-
ing (i.e. shifting) the index vectors according to
their direction and distance from the target term
before they are added to the context vector. RP
has been shown to outperform RI on the synonym
part of the TOEFL7 test.
Model Parameters
The model parameters need to be configured for
the task that the semantic space is to be used
for. For instance, with a document-level con-
text definition, syntagmatic relations are mod-
eled, i.e. terms that belong to the same topic
(<car, motor, race>), whereas, with a sliding win-
dow context definition, paradigmatic relations are
6By generating sparse vectors of a sufficiently high di-
mensionality in this way, the context representations will be
nearly orthogonal.
7Test Of English as a Foreign Language
modeled (<car, automobile, vehicle>) (Sahlgren,
2006). Synonymy is an instance of a paradigmatic
relation.
The dimensionality has also been shown to be
potentially very important, especially when the
size of the vocabulary and the number of contexts8
are large (Henriksson and Hassel, 2013).
3 Materials and Methods
The task of semi-automatically identifying syn-
onyms of SNOMED CT preferred terms is here
approached by, first, statistically identifying mul-
tiword terms in the data and treating them as com-
pounds; then, performing a distributional analysis
of a preprocessed clinical corpus to induce a se-
mantic term space; and, finally, extracting the se-
mantically most similar terms for each preferred
term of interest.
The experimental setup can be broken down
into the following steps: (1) data preparation, (2)
term recognition, (3) model parameter tuning and
(4) evaluation. Semantic spaces are induced with
different parameter configurations on two dataset
variants: one with unigram terms only and one that
also includes multiword terms. The model param-
eters are tuned using MeSH, which contains syn-
onyms for Swedish. The best parameter settings
for each of the two dataset variants are then em-
ployed in the final evaluation, where a medical ex-
pert inspects one hundred term lists extracted for
SNOMED CT preferred terms belonging to the se-
mantic types disorder and finding.
3.1 Data Preparation
The data used to induce the semantic spaces is ex-
tracted from the Stockholm EPR Corpus (Dalia-
nis et al, 2009), which contains Swedish health
records from the Karolinska University Hospital
in Stockholm9. The subset (?33 million tokens)
used in these experiments comprises all forms of
text-based records ? i.e., clinical notes ? from
a large variety of clinical practices. The docu-
ments in the corpus are initially preprocessed by
simply lowercasing tokens and removing punctu-
ation and digits. Lemmatization is not performed,
as we want to be able to capture morphological
8The vocabulary size and the number of contexts are
equivalent when employing a window context definition.
9This research has been approved by the Regional Ethical
Review Board in Stockholm (Etikpro?vningsna?mnden i Stock-
holm), permission number 2012/834-31/5.
38
variants of terms; stop-word filtering is not per-
formed, as traditional stop words ? for instance,
high-frequency function words ? could potentially
be constituents of multiword terms.
3.2 Term Recognition
Multiword terms are extracted statistically from
the corpus using the C-value statistic (Frantzi and
Ananiadou, 1996; Frantzi et al, 2000). This tech-
nique has been used successfully for term recog-
nition in the biomedical domain, largely due to
its ability to handle nested terms (Zhang et al,
2008). Using the C-value statistic for term recog-
nition first requires a list of candidate terms, for
which the C-value can then be calculated. Here,
this is simply produced by extracting n-grams ?
unigrams, bigrams and trigrams ? from the corpus
with TEXT-NSP (Banerjee and Pedersen, 2003).
The statistic is based on term frequency and term
length (number of words); if a candidate term is
part of a longer candidate term (as will be the case
for practically all unigram and bigram terms), the
number and frequency of those longer terms are
also taken into account (Figure 1).
In order to improve the quality of the extracted
terms, a number of filtering rules is applied to the
generated term list: terms that begin and/or end
with certain words, e.g. prepositions and articles,
are removed. The term list ? ranked according to
C-value ? is further modified by giving priority to
terms of particular interest, e.g. SNOMED CT dis-
order and finding preferred terms: these are moved
to the top of the list, regardless of their C-value.
As a result, the statistical foundation on which the
distributional method bases its semantic represen-
tation will effectively be strengthened.
The term list is then used to perform exact string
matching on the entire corpus: multiword terms
with a higher C-value than their constituents are
concatenated. We thereby treat multiword terms as
separate (term) types with distinct distributions in
the data, different from those of their constituents.
3.3 Model Parameter Tuning
Term spaces with different parameter configu-
rations are induced from the two dataset vari-
ants: one containing only unigram terms (Uni-
gram Word Spaces) and one containing also mul-
tiword terms (Multiword Term Spaces). The fol-
lowing model parameters are tuned:
? Distributional Model: Random indexing (RI)
vs. Random permutation (RP)
? Context Window Size: 2+2, 4+4, 8+8 sur-
rounding terms (left+right of the target term)
? Dimensionality: 1000, 2000, 3000
As the Swedish version of SNOMED CT cur-
rently does not contain synonyms, it cannot be
used to perform the parameter tuning automat-
ically. This is instead done with the Swedish
version of MeSH, which is one of the very few
standard terminologies that contains synonyms for
medical terms in Swedish. However, as the op-
timal parameter configurations for capturing syn-
onymy are not necessarily identical for all seman-
tic types, the parameter tuning is performed by
evaluating the semantic spaces for their ability to
identify synonyms of MeSH terms that belong to
the categories Disease or Syndrome and Sign or
Symptom. These particular categories are simply
chosen as they, to a reasonable extent, seem to
correspond to the SNOMED CT semantic types
studied in this paper, namely Disorder and Find-
ing. Only synonym pairs that appear at least fifty
times in each of the dataset variants are included
(155 for Unigram Word Spaces and 123 for Mul-
tiword Term Spaces), as the statistical foundation
for terms that only occur rarely in the data may
not be sufficiently solid. In these Multiword Term
Spaces, the MeSH terms ? but not the synonyms
? are given precedence in the term list. A term
is provided as input to a semantic space and the
twenty semantically most similar terms are out-
put, provided that they also appear at least fifty
times in the data. Recall Top 20 is calculated for
each input term: what proportion of the MeSH
synonyms are identified in a list of twenty sugges-
tions? Since each synonym pair must appear at
least fifty times in the corresponding dataset vari-
ant, it should be duly noted that the optimization
sets will not be identical, which in turn means that
the results of the Unigram Word Spaces and the
Multiword Term Spaces are not directly compara-
ble. The optimal parameter configuration, then,
may be different when also multiword terms are
modeled.
3.4 Evaluation
The optimal parameter configuration for each
dataset variant is employed in the final evaluation.
In this Multiword Term Space, the SNOMED CT
39
C-value(a) =
{
log2 |a| ? f(a) if a is not nested
log2 |a| ? (f(a)?
1
P (Ta)
?
bTa f(b)) otherwise
a = candidate term Ta = set of extracted candidate terms that contain a
b = longer candidate terms P (Ta) = number of candidate terms in Ta
f(a) = term frequency of a f(b) = term frequency of longer candidate term b
|a| = length of candidate term (number of words)
Figure 1: C-Value Formula. The formula for calculating C-value of candidate terms.
preferred terms of interest, rather than the MeSH
terms, are prioritized in the term list. The seman-
tic spaces ? and, in effect, the method ? are pri-
marily evaluated for their ability to identify syn-
onyms of SNOMED CT preferred terms, in this
case of concepts that belong to the semantic types
disorder and finding. The need to identify syn-
onyms for these semantic types is clear, as it has
been shown that the coverage of SNOMED CT
for mentions of disorders (38%) and, in particu-
lar, findings (23%) in Swedish clinical text is low
(Skeppstedt et al, 2012). Since the Swedish ver-
sion of SNOMED CT currently lacks synonyms,
the evaluation reasonably needs to be manual, as
there is no reference standard. One option, then,
could be to choose a random sample of preferred
terms to use in the evaluation. A potential draw-
back of such a(n) (unguided) selection is that many
concepts in the English version of SNOMED CT
do not have any synonymous terms, which might
lead to evaluators spending valuable time looking
for something which does not exist. An alterna-
tive approach, which is assumed here, is to inspect
concepts that have many synonyms in the English
version of SNOMED CT. The fact that some con-
cepts have many textual instantiations in one lan-
guage does not necessarily imply that they also
have many textual instantiations in another lan-
guage. This, however, seems to be the case when
comparing the English and Swedish versions of
MeSH: terms10 that have the most synonyms in the
English version tend to have at least one synonym
in the Swedish version to a larger extent than a ran-
dom selection of terms (60% and 62% of the terms
in the Swedish version have at least one synonym
when looking at the top 100 and top 50 terms with
the most synonyms in the English version, com-
pared to 41% overall in the Swedish version).
For the two dataset variants, we thus select 25
SNOMED CT preferred terms for each semantic
10These calculations are based on MeSH terms that belong
to the categories Disease or Syndrome and Sign or Symptom.
type ? disorder and finding ? that (1) have the most
synonyms in the English version and (2) occur at
least fifty times in the data. In total, fifty terms
are input to the Unigram Word Space and another
fifty terms (potentially with some overlap) are in-
put to the Multiword Term Space. A medical ex-
pert inspects the twenty semantically most simi-
lar terms for each input term. Synonymy is here
the primary semantic relation of interest, but the
semantic spaces are also evaluated for their abil-
ity, or tendency, to extract other semantic term re-
lations: hypernyms or hyponyms, co-hyponyms,
antonyms, as well as disorder-finding relations.
4 Results
The term recognition and concatenation of mul-
tiword terms naturally affect some properties of
the dataset variants, such as the vocabulary size
(number of types) and the type-token ratio. The
Unigram Word Space contains 381,553 types and
an average of 86.54 tokens/type, while the Mul-
tiword Term Space contains 2,223,953 types and
an average of 9.72 tokens/type. This, in turn, may
have an effect on which parameter configuration is
?optimal? for the synonym extraction task. In fact,
this seems to be the case when tuning the parame-
ters for the two dataset variants. For the Unigram
Word Spaces, random indexing with a sliding con-
text window of 8+8 terms and a dimensionality of
2000 seems to work best, whereas for the Mul-
tiword Term Spaces, random permutation with a
sliding window context of 4+4 terms and a dimen-
sionality of 3000 works better (Table 1).
When these parameter configurations are ap-
plied to the SNOMED CT terms, a total of 40 syn-
onyms are extracted by the Unigram Word Space
and 33 synonyms by the Multiword Term Space
(Table 2). On average, 0.80 and 0.66 synonyms
are extracted per preferred term, respectively. The
number of identified synonyms per input term
varies significantly: for some, none; for others, up
to ten. Other semantic relations are also extracted
40
Unigram Word Spaces Multiword Term Spaces
RI RP RI RP
Sliding Window? 2+2 4+4 8+8 2+2 4+4 8+8 2+2 4+4 8+8 2+2 4+4 8+8
1000 dimensions 0.43 0.47 0.48 0.41 0.45 0.42 0.21 0.25 0.26 0.25 0.26 0.24
2000 dimensions 0.43 0.48 0.49 0.48 0.48 0.43 0.21 0.24 0.25 0.25 0.25 0.24
3000 dimensions 0.44 0.47 0.48 0.46 0.45 0.43 0.22 0.24 0.24 0.23 0.27 0.25
Table 1: Model Parameter Tuning. Results, reported as recall top 20, for MeSH synonyms that appear
at least 50 times in each of the dataset variants (unigram vs. multiword). Random indexing (RI) and
Random permutation (RP) term spaces were built with different context window sizes (2+2, 4+4, 8+8
surrounding terms) and dimensionality (1000, 2000, 3000).
by the semantic spaces: mainly co-hyponyms,
but also hypernyms and hyponyms, antonyms and
disorder-finding relations. The Unigram Word
Space extracts, on average, 0.52 hypernyms or hy-
ponyms, 1.8 co-hyponyms, 0.1 antonyms and 0.34
disorder-finding relations. The Multiword Term
Space extracts, on average, 0.16 hypernyms or
hyponyms, 1.1 co-hyponyms, 0.14 antonyms and
0.66 disorder-finding relations. In general, more
of the above semantic relations are extracted by
the Unigram Word Space than by the Multiword
Term Space (178 vs. 136). It is, however, inter-
esting to note that almost twice as many disorder-
finding relations are extracted by the latter com-
pared to the former. Of course, none of the re-
lations extracted by the Unigram Word Space in-
volve a multiword term; on the other hand, more
than half (around 57%) of the relations extracted
by the Multiword Term Space involve at least one
multiword term.
Both semantic spaces identify more synonyms
of preferred terms that belong to the semantic type
finding than disorder (in total 56 vs. 39). The same
holds true for hyp(er/o)nyms and co-hypnoyms;
however, the converse is true for antonyms and
disorder-finding relations.
5 Discussion
The results demonstrate that it is indeed possible
to extract synonyms of medical terms by perform-
ing a distributional analysis of a large corpus of
clinical text ? unigram-unigram relations, as well
as unigram-multiword and multiword-unigram re-
lations. It is also clear, however, that other se-
mantically related terms share distributional pro-
files to a similar degree as synonymous terms. The
predominance of the other semantic relations, ex-
cept for antonymy, in the term lists can reason-
ably be explained by the simple fact that there
exist more hypernyms, hyponyms, co-hyponyms
and disorder-finding relations than synonyms (or
antonyms).
It is also evident that more semantic relations,
and indeed more synonyms, are extracted by the
Unigram Word Space than the Multiword Term
Space. Again, it is important to underline that the
results cannot be compared without due qualifica-
tion since the evaluation sets are not identical: the
Unigram Word Space does not contain any mul-
tiword terms, for instance. The ability to model
multiword terms in a distributional framework and
to handle semantic composition ? i.e., how mean-
ing is, and sometimes is not, composed by the
meaning of its constituents ? has long been an en-
deavor in the NLP research community (Sag et al,
2002; Baroni and Zamparelli, 2010; Grefenstette
and Sadrzadeh, 2011; Mitchell, 2011). Treating
multiword terms as compound tokens is a simple
and rather straightforward approach, which also
makes intuitive sense: rather than treat individ-
ual words as clearly delineated bearers of mean-
ing, identify semantic units ? regardless of term
length ? and model their distributional profiles.
Unfortunately, there are problems with this ap-
proach. First, the attendant increase in vocabu-
lary size entails a lower tokens-type ratio, which
in turn means that the statistical foundation for
terms will weaken. In this case, the average token-
type ratio decreased from 86.54 to 9.72. This ap-
proach therefore requires access to a sufficiently
large corpus. Second, the inflation in vocabulary
size entails a corresponding increase in the num-
ber of vectors in the semantic space. This not only
requires more memory; to ensure that the crucial
near-orthogonality property11 of RI-based models
is maintained, the dimensionality has to be suffi-
11Random indexing assumes that the index vectors ? rep-
resenting distinct contexts ? are nearly orthogonal.
41
Unigram Word Space Multiword Term Space
DISORDER FINDING DISORDER FINDING
Synonyms
sum 18 22 16 17
average 0.72 0.88 0.64 0.68
? 1 / preferred term 12 12 8 6
involves mwe - - 10 13
Hyp(er/o)nyms
sum 12 14 4 4
average 0.48 0.56 0.16 0.16
? 1 / preferred term 6 8 4 3
involves mwe - - 3 3
Co-hyponyms
sum 34 56 22 33
average 1.36 2.24 0.88 1.32
? 1 / preferred term 14 17 10 13
involves mwe - - 19 15
Antonyms
sum 3 2 4 3
average 0.12 0.08 0.16 0.12
? 1 / preferred term 3 2 3 3
involves mwe - - 0 1
Disorder-Finding
sum 11 6 28 5
average 0.44 0.24 1.12 0.2
? 1 / preferred term 6 5 12 5
involves mwe - - 11 2
Table 2: Evaluation Results. The types of semantic relations extracted among the twenty most se-
mantically similar terms of 25 DISORDER and 25 FINDING SNOMED CT preferred terms from each
semantic space. Sum is the total number of identified relevant terms. Average is the average number of
relevant terms per preferred term. ? 1 / preferred term is the number of preferred terms for which at
least one relevant term is identified. Involves mwe is the number of relevant relations where either the
preferred term or the relevant term is a multiword expression.
ciently large in relation to the number of contexts
(represented by index vectors). In the Multiword
Term Space the vocabulary size is over two million
(compared to less than 400,000 in the Unigram
Word Space). A dimensionality of 3000 is likely
insufficient to ensure that each term type has an
initial distinct and uncorrelated representation. In
the evaluation, there were several examples where
two groups of terms ? semantically homogenous
within each group, but semantically heterogenous
across groups ? co-existed in the same term list:
these ?topics? had seemingly collapsed into the
same subspace. Despite these problems, it should
be recognized that the Multiword Term Space is, in
fact, able to retrieve 23 synonymous relations that
involve at least one multiword term. The Unigram
Word Space cannot retrieve any such relations.
The ability to extract high-quality terms would
seem to be an important prerequisite for this ap-
proach to modeling multiword terms in a distribu-
tional framework. However, despite employing a
rather simple means of extracting terms ? without
using any syntactic information ? the terms that
actually appeared in the lists of semantically re-
lated terms were mostly reasonable. This perhaps
indicates that the term recognition task does not
need to be perfect: terms of interest, of course,
need to be identified, but some noise in the form
of bad terms might be acceptable. A weakness
of the term recognition part is, however, that too
many terms were identified, which in turn led to
the aforementioned inflation in vocabulary size.
42
Limiting the number of multiword terms in the ini-
tial term list ? for instance by extracting syntactic
phrases as candidate terms ? could provide a pos-
sible solution to this problem.
Overall, more synonyms were identified for the
semantic type finding than for disorder. One pos-
sible explanation for this could be that there are
more ways of describing a finding than a disorder
? not all semantic types can be assumed to have
the same number of synonyms. The same holds
true for all other semantic relations except for dis-
order-finding, where disorders generated a much
larger number of distributionally similar findings
than vice versa. This could perhaps also be ex-
plained by the possible higher number of syn-
onyms for finding than disorder.
When this method was evaluated using the
English version of SNOMED CT, 16-24% of
known synonyms were identified (Henriksson et
al., 2013). In this case, however, we extracted
synonym candidates for terms that may or may
not have synonyms. This is thus a scenario that
more closely resembles how this method would
actually be used in a real-life setting to populate
a terminology with synonyms. Although the com-
parison with MeSH showed that terms with many
synonyms in English also tend to have at least one
synonym in Swedish, approximately 40% of them
did not have any synonyms. It is thus not certain
that the terms used in this evaluation all have at
least one synonym, which was also noted by the
evaluator in this study.
6 Conclusions
In this study, we have demonstrated a method
that could potentially be used to expedite the lan-
guage porting process of terminologies such as
SNOMED CT. With access to a large corpus of
clinical text in the target language and an initial
set of terms, this language-independent method is
able to extract and present candidate synonyms to
the lexicographer, thereby providing valuable sup-
port for semi-automatic terminology development.
A means to model multiword terms in a distri-
butional framework is an important feature of the
method and is crucial for the synonym extraction
task.
Acknowledgments
This work was partly supported by the Swedish
Foundation for Strategic Research through the
project High-Performance Data Mining for Drug
Effect Detection (ref. no. IIS11-0053) at Stock-
holm University, Sweden, and partly funded by
the Stockholm University Academic Initiative
through the Interlock project. Finally, we would
like to thank the reviewers for their constructive
feedback.
References
Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A Survey of Paraphrasing and Textual En-
tailment Methods. Journal of Artificial Intelligence
Research, 38:135?187.
Satanjeev Banerjee and Ted Pedersen. 2003. The De-
sign, Implementation, and Use of the Ngram Statis-
tic Package. In Proceedings of CICLing, pages 370?
381.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are Vectors, Adjectives are Matrices: Representing
Adjective-Noun Constructions in Semantic Space.
In Proceedings of EMNLP, pages 1183?1193.
Vincent D. Blondel, Anah?? Gajardo, Maureen Hey-
mans, Pierre Senellart, and Paul Van Dooren.
2004. A Measure of Similarity between Graph Ver-
tices: Applications to Synonym Extraction and Web
Searching. SIAM Review, 46(4):647?666.
Aaron M. Cohen and William R. Hersh. 2005. A Sur-
vey of Current Work in Biomedical Text Mining.
Briefings in Bioinformatics, 6(1):57?71.
Trevor Cohen and Dominic Widdows. 2009. Empirical
Distributional Semantics: Methods and Biomedical
Applications. J Biomed Inform, 42(2):390?405.
AM Cohen, WR Hersh, C Dubay, and K Spackman.
2005. Using co-occurrence network structure to
extract synonymous gene and protein names from
medline abstracts. BMC Bioinformatics, 6(1):103.
Mike Conway and Wendy W. Chapman. 2012. Dis-
covering Lexical Instantiations of Clinical Con-
cepts using Web Services, WordNet and Corpus Re-
sources. In AMIA Fall Symposium, page 1604.
Hercules Dalianis, Martin Hassel, and Sumithra
Velupillai. 2009. The Stockholm EPR Corpus:
Characteristics and Some Initial Findings. In Pro-
ceedings of ISHIMR, pages 243?249.
Scott Deerwester, Susan T. Dumais, George W Fur-
nas, Thomas K Landauer, and Richard Harshman.
1990. Indexing by Latent Semantic Analysis. Jour-
nal of the American Society for Information Science,
41(6):391?407.
Susan T. Dumais and Thomas K. Landauer. 1997. A
Solution to Plato?s Problem: The Latent Semantic
43
Analysis Theory of Acquisition, Induction and Rep-
resentation of Knowledge. Psychological Review,
104(2):211?240.
Katerina Frantzi and Sophia Ananiadou. 1996. Ex-
tracting Nested Collocations. In Proceedings of
COLING, pages 41?46.
Katerina Frantzi, Sophia Ananiadou, and Hideki
Mima. 2000. Automatic Recognition of Multi-
Word Terms: The C-value/NC-value Method. In-
ternational Journal on Digital Libraries, 3(2):115?
130.
Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental Support for a Categorical Composi-
tional Distributional Model of Meaning. In Pro-
ceedings of EMNLP, pages 1394?1404.
Zellig S. Harris. 1954. Distributional Structure. Word,
10:146?162.
Marti Hearst. 1992. Automatic Acquisition of Hy-
ponyms from Large Text Corpora. In Proceedings
of COLING, pages 539?545.
Aron Henriksson and Martin Hassel. 2013. Optimiz-
ing the Dimensionality of Clinical Term Spaces for
Improved Diagnosis Coding Support. In Proceed-
ings of Louhi.
Aron Henriksson, Hans Moen, Maria Skeppstedt, Ann-
Marie Eklund, and Vidas Daudaravicius. 2012.
Synonym Extraction of Medical Terms from Clini-
cal Text Using Combinations of Word Space Mod-
els. In Proceedings of SMBM, pages 10?17.
Aron Henriksson, Mike Conway, Martin Duneld, and
Wendy W. Chapman. 2013. Identifying Syn-
onymy between SNOMED Clinical Terms of Vary-
ing Length Using Distributional Analysis of Elec-
tronic Health Records. In AMIA Annual Symposium
(submitted).
Donald Hindle. 1990. Noun Classification from
Predicate-Argument Structures. In Proceedings of
ACL, pages 268?275.
Pentti Kanerva, Jan Kristofersson, and Anders Holst.
2000. Random Indexing of Text Samples for Latent
Semantic Analysis. In Proceedings CogSci, page
1036.
John McCrae and Nigel Collier. 2008. Synonym
Set Extraction from the Biomedical Literature by
Lexical Pattern Discovery. BMC Bioinformatics,
9(1):159.
Ste?phane M. Meystre, Guergana K. Savova, Karin C.
Kipper-Schuler, John F. Hurdle, et al 2008. Ex-
tracting Information from Textual Documents in the
Electronic Health Record: A Review of Recent Re-
search. Yearb Med Inform, 35:128?44.
Jeffrey Mitchell. 2011. Composition in Distributional
Models of Semantics. Ph.D. thesis, University of
Edinburgh.
Kotaro Nakayama, Takahiro Hara, and Shojiro Nishio.
2007. Wikipedia Mining for an Association Web
Thesaurus Construction. In Proceedings of WISE,
pages 322?334.
Alexander Panchenko. 2013. Similarity Measures for
Semantic Relation Extraction. Ph.D. thesis, PhD
thesis, Universite? catholique de Louvain & Bauman
Moscow State Technical University.
Yves Peirsman and Dirk Geeraerts. 2009. Predicting
Strong Associations on the Basis of Corpus Data. In
Proceedings of EACL, pages 648?656.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
Expressions: A Pain in the Neck for NLP. In Pro-
ceedings of CICLing, pages 1?15.
Magnus Sahlgren, Anders Holst, and Pentti Kanerva.
2008. Permutations as a Means to Encode Order
in Word Space. In Proceedings of CogSci, pages
1300?1305.
Magnus Sahlgren. 2006. The Word-Space Model:
Using Distributional Analysis to Represent Syntag-
matic and Paradigmatic Relations between Words in
High-Dimensional Vector Spaces. Ph.D. thesis, PhD
thesis, Stockholm University.
Maria Skeppstedt, Maria Kvist, and Hercules Dalianis.
2012. Rule-based Entity Recognition and Coverage
of SNOMED CT in Swedish Clinical Text. In Pro-
ceedings of LREC, pages 1250?1257.
Lonneke van der Plas and Jo?rg Tiedemann. 2006.
Finding Synonyms Using Automatic Word Align-
ment and Measures of Distributional Similarity. In
Proceedings of COLING/ACL, pages 866?873.
Hua Wu and Ming Zhou. 2003. Optimizing Syn-
onym Extraction Using Monolingual and Bilingual
Resources. In Proceedings of the Second Interna-
tional Workshop on Paraphrasing, pages 72?79.
Hong Yu and Eugene Agichtein. 2003. Extracting
Synonymous Gene and Protein Terms from Biolog-
ical Literature. Bioinformatics, 19(suppl 1):i340?
i349.
Qing T Zeng, Doug Redd, Thomas Rindflesch, and
Jonathan Nebeker. 2012. Synonym, Topic Model
and Predicate-Based Query Expansion for Retriev-
ing Clinical Documents. In Proceedings AMIA An-
nual Symposium, pages 1050?9.
Ziqi Zhang, Jose? Iria, Christopher Brewster, and Fabio
Ciravegna. 2008. A Comparative Evaluation of
Term Recognition Algorithms. In Proceedings of
LREC.
44
