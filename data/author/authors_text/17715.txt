Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 784?789,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Building and Evaluating a Distributional Memory for Croatian
Jan S?najder? Sebastian Pado?? Z?eljko Agic??
?University of Zagreb, Faculty of Electrical Engineering and Computing
Unska 3, 10000 Zagreb, Croatia
?Heidelberg University, Institut fu?r Computerlinguistik
69120 Heidelberg, Germany
?University of Zagreb, Faculty of Humanities and Social Sciences
Ivana Luc?ic?a 3, 10000 Zagreb, Croatia
jan.snajder@fer.hr pado@cl.uni-heidelberg.de zagic@ffzg.hr
Abstract
We report on the first structured dis-
tributional semantic model for Croatian,
DM.HR. It is constructed after the model
of the English Distributional Memory (Ba-
roni and Lenci, 2010), from a dependency-
parsed Croatian web corpus, and covers
about 2M lemmas. We give details on the
linguistic processing and the design prin-
ciples. An evaluation shows state-of-the-
art performance on a semantic similarity
task with particularly good performance on
nouns. The resource is freely available.
1 Introduction
Most current work in lexical semantics is based
on the Distributional Hypothesis (Harris, 1954),
which posits a correlation between the degree of
words? semantic similarity and the similarity of
the contexts in which they occur. Using this hy-
pothesis, word meaning representations can be ex-
tracted from large corpora. Words are typically rep-
resented as vectors whose dimensions correspond
to context features. The vector similarities, which
are interpreted as semantic similarities, are used in
numerous applications (Turney and Pantel, 2010).
Most vector spaces in current use are either word-
based (co-occurrence defined by surface window,
context words as dimensions) or syntax-based (co-
occurrence defined syntactically, syntactic objects
as dimensions). Syntax-based models have sev-
eral desirable properties. First, they are model to
fine-grained types of semantic similarity such as
predicate-argument plausibility (Erk et al, 2010).
Second, they are more versatile ? Baroni and Lenci
(2010) have presented a generic framework, the
Distributional Memory (DM), which is applicable
to a wide range of tasks beyond word similarity.
Third, they avoid the ?syntactic assumption? in-
herent in word-based models, namely that context
words are relevant iff they are in an n-word window
around the target. This property is particularly rele-
vant for free word order languages with many long
distance dependencies and non-projective structure
(Ku?bler et al, 2009). Their obvious problem, of
course, is that they require a large parsed corpus.
In this paper, we describe the construction of
a Distributional Memory for Croatian (DM.HR),
a free word order language. To do so, we parse
hrWaC (Ljubes?ic? and Erjavec, 2011), a 1.2B-token
Croatian web corpus. We evaluate DM.HR on a
synonym choice task, where it outperforms the
standard bag-of-word model for nouns and verbs.
2 Related Work
Vector space semantic models have been applied
to a number of Slavic languages, including Bul-
garian (Nakov, 2001a), Czech (Smrz? and Rychly?,
2001), Polish (Piasecki, 2009; Broda et al, 2008;
Broda and Piasecki, 2008), and Russian (Nakov,
2001b; Mitrofanova et al, 2007). Previous work
on distributional semantic models for Croatian
dealt with similarity prediction (Ljubes?ic? et al,
2008; Jankovic? et al, 2011) and synonym detec-
tion (Karan et al, 2012), however using only word-
based and not syntactic-based models.
So far the only DM for a language other than
English is the German DM.DE by Pado? and Utt
(2012), who describe the process of building
DM.DE and the evaluation on a synonym choice
task. Our work is similar, though each language
has its own challenges. Croatian, like other Slavic
languages, has rich inflectional morphology and
free word order, which lead to errors in linguistic
processing and affect the quality of the DM.
784
3 Distributional Memory
DM represents co-occurrence information in a gen-
eral, non-task-specific manner, as a tensor, i.e., a
three-dimensional matrix, of weighted word-link-
word tuples. Each tuple is mapped onto a number
by scoring function ? : W ? L ?W ? R+, that
reflects the strength of the association. When a par-
ticular task is selected, a vector space for this task
can be generated from the tensor by matricization.
Regarding the examples from Section 1, synonym
discovery would use a word by link-word space
(W ? LW ), which contains vectors for words w
represented by pairs ?l, w? of a link and a context
word. Analogy discovery would use a word-word
by link space (WW ? L), which represents word
pairs ?w1, w2? by vectors over links l.
The links can be chosen to model any relation
of interest between words. However, as noted by
Pado? and Utt (2012), dependency relations are the
most obvious choice. Baroni and Lenci (2010) in-
troduce three dependency-based DM variants: De-
pDM, LexDM, and TypeDM. DepDM uses links
that correspond to dependency relations, with sub-
categorization for subject (subj tr and subj intr)
and object (obj and iobj). Furthermore, all prepo-
sitions are lexicalized into links (e.g., ?sun, on,
Sunday?). Finally, the tensor is symmetrized: for
each tuple ?w1, l, w2?, its inverse ?w2, l?1, w1? is
included. The other two variants are more complex:
LexDM uses more lexicalized links, encoding, e.g.,
lexical material between the words, while TypeDM
extends LexDM with a scoring function based on
lexical variability.
Following the work of Pado? and Utt (2012), we
build a DepDM variant for DM.HR. Although Ba-
roni and Lenci (2010) show that TypeDM can out-
perform the other two variants, DepDM often per-
forms at a comparable level, while being much
simpler to build and more efficient to compute.
4 Building DM.HR
To build DM.HR, we need to collect co-occurrence
counts from a corpus. Since no sufficiently large
suitable corpus exists for Croatian, we first explain
how we preprocessed, tagged, and parsed the data.
Corpus and preprocessing. We adopted hrWaC,
the 1.2B-token Croatian web corpus (Ljubes?ic? and
Erjavec, 2011), as starting point. hrWaC was built
with the aim of obtaining a cleaner-than-usual web
corpus. To this end, a conservative boilerplate re-
moval procedure was used; Ljubes?ic? and Erjavec
(2011) report a precision of 97.9% and a recall of
70.7%. Nonetheless, our inspection revealed that,
apart from the unavoidable spelling and grammati-
cal errors, hrWaC still contains non-textual content
(e.g., code snippets and formatting structure), en-
coding errors, and foreign-language content. As
this severely affects linguistic processing, we addi-
tionally filtered the corpus.
First, we removed from hrWaC the content
crawled from main discussion forum and blog web-
sites. This content is highly ungrammatical and
contains a lot of non-diacriticized text, typical for
user-generated content. This step alone removed
one third of the data. We processed the remaining
content with a tokenizer and a sentence segmenter
based on regular expressions, obtaining 66M sen-
tences. Next, we applied a series of heuristic filters
at the document- and sentence-level. At the doc-
ument level, we discard all documents (1) whose
length is below a specified threshold, (2) contain
no diacritics, (3) contain no words from a list of fre-
quent Croatian words, or (4) contain a single word
from lists of distinctive foreign-language words
(for Serbian). The last two steps serve to eliminate
foreign-language content. In particular, the last
step serves to filter out the text in Serbian, which at
the sentence-level is difficult to automatically dis-
criminate from Croatian. At the sentence-level, we
discard sentences that are (1) shorter than a speci-
fied threshold, (2) contain non-standard symbols,
(3) contain non-diacriticized Croatian words, or
(4) contain too many foreign words from a list of
foreign-language words (for English and Slovene).
The last step filters out specifically the sentences
in English and Slovene, as we found that these of-
ten occur mixed with text in Croatian. The final
filtered version of hrWaC contains 51M sentences
and 1.2B tokens. The corpus is freely available for
download, along with a more detailed description
of the preprocessing steps.1
Tagging, lemmatization, and parsing. For mor-
phosyntactic (MSD) tagging, lemmatization, and
dependency parsing of hrWaC, we use freely avail-
able tools with models trained on the new SETimes
Corpus of Croatian (SETIMES.HR), based on the
Croatian part of the SETimes parallel corpus.2 SE-
TIMES.HR and the derived tools are prototypes
1http://takelab.fer.hr/data
2http://www.nljubesic.net/resources/
corpora/setimes/
785
SETIMES.HR Wikipedia
HunPos (POS only) 97.1 94.1
HunPos (full MSD) 87.7 81.5
CST lemmatizer 97.7 96.5
MSTParser 77.5 68.8
Table 1: Tagging, lemmatization, and parsing accu-
racy
that are about to be released as parts of another
work. Here we give a general description and a
re-evaluation that we consider relevant for building
DM.HR.
SETIMES.HR consists of 90K tokens and 4K
sentences, manually lemmatized and MSD-tagged
according to Multext East v4 tagset (Erjavec, 2012),
with the help of the Croatian Lemmatization Server
(Tadic?, 2005). It is used also as a basis for a novel
formalism for syntactic annotation and dependency
parsing of Croatian (Agic? and Merkler, 2013).
On the basis of previous evaluation for Croa-
tian (Agic? et al, 2008; Agic? et al, 2009; Agic?,
2012) and availability and licensing considerations,
we chose HunPos tagger (Hala?csy et al, 2007),
CST lemmatizer (Ingason et al, 2008), and MST-
Parser (McDonald et al, 2006) to process hrWaC.
We evaluated the tools on 100-sentence test sets
from SETIMES.HR and Wikipedia; performance
on Wikipedia should be indicative of the perfor-
mance on a cross-domain dataset, such as hrWaC.
In Table 1 we show lemmatization and tagging ac-
curacy, as well as dependency parsing accuracy
in terms of labeled attachment score (LAS). The
results show that lemmatization, tagging and pars-
ing accuracy improves on the state of the art for
Croatian. The SETIMES.HR dependency parsing
models are publicly available.3
Syntactic patterns. We collect the co-occur-
rence counts of tuples using a set of syntactic pat-
terns. The patterns effectively define the link types,
and hence the dimensions of the semantic space.
Similar to previous work, we use two sorts of links:
unlexicalized and lexicalized.
For unlexicalized links, we use ten syntactic pat-
terns. These correspond to the main dependency re-
lations produced by our parser: Pred for predicates,
Atr for attributes, Adv for adverbs, Atv for verbal
complements, Obj for objects, Prep for preposi-
tions, and Pnom for nominal predicates. We sub-
categorized the subject relation into Sub tr (sub-
3http://zeljko.agic.me/resources/
Link P (%) R (%) F1 (%)
Unlexicalized
Adv 57.3 52.7 54.9
Atr 85.0 89.3 87.1
Atv 75.3 70.9 73.1
Obj 71.4 71.7 71.5
Pnom 55.7 50.8 53.1
Pred 81.8 70.6 75.8
Prep 50.0 28.6 36.4
Sb tr 67.8 73.8 70.7
Sb intr 64.5 64.8 64.7
Verb 61.6 73.6 67.1
Lexicalized
Prepositions 67.2 67.9 67.5
Verbs 61.6 73.6 67.1
All links 73.7 75.5 74.6
Table 2: Tuple extraction performance on SE-
TIMES.HR
jects of transitive verbs) and Sub intr (subject of
intransitive verbs). The motivation for this is better
modeling of verb semantics by capturing diathe-
sis alternations. In particular, for many Croatian
verbs reflexivization introduces a meaning shift,
e.g., predati (to hand in/out) vs. predati se (to
surrender). With subject subcategorization, re-
flexive and irreflexive readings will have differ-
ent tensor representations; e.g., ?student, Subj tr,
zadac?a? (?student, Subj tr, homework?) vs. ?trupe,
Subj intr, napadac?? (?troops, Subj intr, invadors?).
Finally, similar to Pado? and Utt (2012), we use
Verb as an underspecified link between subjects
and objects linked by non-auxiliary verbs.
For lexicalized links, we use two more extraction
patterns for prepositions and verbs. Prepositions
are directly lexicalized as links; e.g., ?mjesto, na,
sunce? (?place, on, sun?). The same holds for non-
auxiliary verbs linking subjects to objects; e.g.,
?drz?ava, kupiti, kolic?ina? (?state, buy, amount?).
Tuple extraction and scoring. The overall qual-
ity of the DM.HR depends on the accuracy of ex-
tracted tuples, which is affected by all preprocess-
ing steps. We computed the performance of tu-
ple extraction by evaluating a sample of tuples
extracted from a parsed version of SETIMES.HR
against the tuples extracted from the SETIMES.HR
gold annotations (we use the same sample as for
tagging and parsing performance evaluation). Ta-
ble 2 shows Precision, Recall, and F1 score. Over-
all, we achieve the best performance on the Atr
links, followed by Pred links. The performance is
generally higher on unlexicalized links than on lex-
icalized links (note that performance on unlexical-
786
Link Word LMI Link Word LMI
Atv moc?i 225107 Adv moguc?e 9669
Atv z?eljeti 22049 Atv namjeravati 9095
Obj stan 19997 Obj karta 8936
po cijena 18534 prije godina 8584
Pred kada 14408 Adv nedavno 7842
Obj dionica 13720 Atv odluc?iti 7578
Atv morati 12097 Adv godina 7496
Obj ulaznica 11126 Obj zemljis?te 7180
Table 3: Top 16 LMI-scored tuples for the verb
kupiti (to buy)
ized Verb links is identical to overall performance
on lexicalized verb links). The overall F1 score of
tuple extraction is 74.6%.
Following DM and DM.DE, we score each
extracted tuple using Local Mutual Information
(LMI) (Evert, 2005):
LMI(i, j, k) = f(i, j, k) log P (i, j, k)P (i)P (j)P (k)
For a tuple (w1, l, w2), LMI scores the association
strength between word w1 and word w2 via link l
by comparing their joint distribution against the dis-
tribution under the independence assumption, mul-
tiplied with the observed frequency f(w1, l, w2) to
discount infrequent tuples. The probabilities are
computed from tuple counts as maximum likeli-
hood estimates. We exclude from the tensor all
tuples with a negative LMI score. Finally, we sym-
metrize the tensor by introducing inverse links.
Model statistics. The resulting DM.HR tensor
consists of 2.3M lemmas, 121M links and 165K
link types (including inverse links). On average,
each lemma has 53 links. This makes DM.HR
more sparse than English DM (796 link types), but
less sparse than German DM (220K link types; 22
links per lemma). Table 3 shows an example of
the extracted tuples for the verb kupiti (to buy).
DM.HR tensor is freely available for download.4
5 Evaluating DM.HR
Task. We present a pilot evaluation DM.HR on a
standard task from distributional semantics, namely
synonym choice. In contrast to tasks like predict-
ing word similarity We use the dataset created by
Karan et al (2012), with more than 11,000 syn-
onym choice questions. Each question consists of
one target word (nouns, verbs, and adjectives) with
4http://takelab.fer.hr/dmhr
Accuracy (%) Coverage (%)
Model N A V N A V
DM.HR 70.0 66.3 63.2 99.9 99.1 100
BOW-LSA 67.2 68.9 61.0 100 100 100
BOW baseline 59.9 65.7 55.9 99.9 99.7 100
Table 4: Results on synonym choice task
four synonym candidates (one is correct). The ques-
tions were extracted automatically from a machine-
readable dictionary of Croatian. An example item
is tez?ak (farmer): poljoprivrednik (farmer), um-
jetnost (art), radijacija (radiation), bod (point).
We sampled from the dataset questions for nouns,
verbs, and adjectives, with 1000 questions each.5
Additionally, we manually corrected some errors
in the dataset, introduced by the automatic extrac-
tion procedure. To make predictions, we compute
pairwise cosine similarities of the target word vec-
tors with the four candidates and predict the can-
didate(s) with maximal similarity (note that there
may be ties).
Evaluation. Our evaluation follows the scheme
developed by Mohammad et al (2007), who define
accuracy as the average number of correct predic-
tions per covered question. Each correct prediction
with a single most similar candidate receives a full
credit (A), while ties for maximal similarity are
discounted (B: two-way tie, C: three-way tie, D:
four-way tie): A+ 12B+ 13C+ 14D. We consider aquestion item to be covered if the target and at least
one answer word are modeled. In our experiments,
ties occur when vector similarities are zero for all
word pairs (due to vector sparsity). Note that a
random baseline would perform at 0.25 accuracy.
As baseline to compare against the DM.HR, we
build a standard bag-of-word model from the same
corpus. It uses a ?5-word within-sentence con-
text window, and the 10,000 most frequent context
words (nouns, adjectives, and verbs) as dimensions.
We also compare against BOW-LSA, a state-of-
the-art synonym detection model from Karan et
al. (2012), which uses 500 latent dimensions and
paragraphs as contexts. We determine the signifi-
cance of differences between the models by com-
puting 95% confidence intervals with bootstrap re-
sampling (Efron and Tibshirani, 1993).
Results. Table 4 shows the results for the three
considered models on nouns (N), adjectives (A),
5Available at: http://takelab.fer.hr/crosyn
787
and verbs (V). The performance of BOW-LSA
differs slightly from that reported by Karan et al
(2012), because we evaluate on a sample of their
dataset. DM.HR outperforms the baseline BOW
model for nouns and verbs (differences are sig-
nificant at p < 0.05). Moreover, on these cate-
gories DM.HR performs slightly better than BOW-
LSA, but the differences are not statistically sig-
nificant. Conversely, on adjectives BOW-LSA per-
forms slightly better than DM.HR, but the differ-
ence is again not statistically significant. All mod-
els achieve comparable and almost perfect cov-
erage on this dataset (BOW-LSA achieves com-
plete coverage because of the way how the original
dataset was filtered).
Overall, the biggest improvement over the base-
line is achieved for nouns. Nouns occur as heads
and dependents of many link types (unlexicalized
and lexicalized), and are thus well represented in
the semantic space. On the other hand, adjectives
seem to be less well modeled. Although the major-
ity of adjectives occur as heads or dependents of
the Atr relation, for which extraction accuracy is
the highest (cf. Table 2), it is likely that a single link
type is not sufficient. As noted by a reviewer, more
insight could perhaps be gained by comparing the
predictions of BOW-LSA and DM.HR models. The
generally low performance on verbs suggests that
their semantic is not fully covered in word- and
syntax-based spaces.
6 Conclusion
We have described the construction of DM.HR, a
syntax-based distributional memory for Croatian
built from a dependency-parsed web corpus. To the
best of our knowledge, DM.HR is the first freely
available distributional memory for a Slavic lan-
guage. We have conducted a preliminary evalua-
tion of DM.HR on a synonym choice task, where
DM.HR outperformed the bag-of-word model and
performed comparable to an LSA model.
This work provides a starting point for a sys-
tematic study of dependency-based distributional
semantics for Croatian and similar languages. Our
first priority will be to analyze how corpus prepro-
cessing and the choice of link types relates to model
performance on different semantic tasks. Better
modeling of adjectives and verbs is also an impor-
tant topic for future research.
Acknowledgments
The first author was supported by the Croatian
Science Foundation (project 02.03/162: ?Deriva-
tional Semantic Models for Information Retrieval?).
We thank the reviewers for their constructive com-
ments. Special thanks to Hiko Schamoni, Tae-Gil
Noh, and Mladen Karan for their assistance.
References
Z?eljko Agic? and Danijela Merkler. 2013. Three syn-
tactic formalisms for data-driven dependency pars-
ing of Croatian. Proceedings of TSD 2013, Lecture
Notes in Artificial Intelligence.
Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.
2008. Improving part-of-speech tagging accuracy
for Croatian by morphological analysis. Informat-
ica, 32(4):445?451.
Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.
2009. Evaluating full lemmatization of Croatian
texts. In Recent Advances in Intelligent Information
Systems, pages 175?184. EXIT Warsaw.
Z?eljko Agic?. 2012. K-best spanning tree dependency
parsing with verb valency lexicon reranking. In Pro-
ceedings of COLING 2012: Posters, pages 1?12,
Bombay, India.
Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional memory: A general framework for
corpus-based semantics. Computational Linguistics,
36(4):673?721.
Bartosz Broda and Maciej Piasecki. 2008. Superma-
trix: a general tool for lexical semantic knowledge
acquisition. In Speech and Language Technology,
volume 11, pages 239?254. Polish Phonetics Asso-
cation.
Bartosz Broda, Magdalena Derwojedowa, Maciej Pi-
asecki, and Stanis?aw Szpakowicz. 2008. Corpus-
based semantic relatedness for the construction of
Polish WordNet. In Proceedings of LREC, Mar-
rakech, Morocco.
Bradley Efron and Robert J. Tibshirani. 1993. An
Introduction to the Bootstrap. Chapman and Hall,
New York.
Tomaz? Erjavec. 2012. MULTEXT-East: Morphosyn-
tactic resources for Central and Eastern European
languages. Language Resources and Evaluation,
46(1):131?142.
Katrin Erk, Sebastian Pado?, and Ulrike Pado?. 2010.
A Flexible, Corpus-driven Model of Regular and In-
verse Selectional Preferences. Computational Lin-
guistics, 36(4):723?763.
788
Stefan Evert. 2005. The statistics of word cooccur-
rences. Ph.D. thesis, PhD Dissertation, Stuttgart
University.
Pe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.
2007. HunPos: An open source trigram tagger. In
Proceedings of ACL 2007, pages 209?212, Prague,
Czech Republic.
Zelig S. Harris. 1954. Distributional structure. Word,
10(23):146?162.
Anton Karl Ingason, Sigru?n Helgado?ttir, Hrafn Lofts-
son, and Eir??kur Ro?gnvaldsson. 2008. A mixed
method lemmatization algorithm using a hierarchy
of linguistic identities (HOLI). In Proceedings of
GoTAL, pages 205?216.
Vedrana Jankovic?, Jan S?najder, and Bojana Dalbelo
Bas?ic?. 2011. Random indexing distributional se-
mantic models for Croatian language. In Proceed-
ings of Text, Speech and Dialogue, pages 411?418,
Plzen?, Czech Republic.
Mladen Karan, Jan S?najder, and Bojana Dalbelo Bas?ic?.
2012. Distributional semantics approach to detect-
ing synonyms in Croatian language. In Proceedings
of the Language Technologies Conference, Informa-
tion Society, Ljubljana, Slovenia.
Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Synthesis Lectures
on Human Language Technologies. Morgan & Clay-
pool.
Nikola Ljubes?ic? and Tomaz? Erjavec. 2011. hrWaC
and slWac: Compiling web corpora for Croatian and
Slovene. In Proceedings of Text, Speech and Dia-
logue, pages 395?402, Plzen?, Czech Republic.
Nikola Ljubes?ic?, Damir Boras, Nikola Bakaric?, and Jas-
mina Njavro. 2008. Comparing measures of seman-
tic similarity. In Proceedings of the ITI 2008 30th
International Conference of Information Technology
Interfaces, Cavtat, Croatia.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a
two-stage discriminative parser. In Proceedings of
CoNLL-X, pages 216?220, New York, NY.
Olga Mitrofanova, Anton Mukhin, Polina Panicheva,
and Vyacheslav Savitsky. 2007. Automatic word
clustering in Russian texts. In Proceedings of Text,
Speech and Dialogue, pages 85?91, Plzen?, Czech
Republic.
Saif Mohammad, Iryna Gurevych, Graeme Hirst, and
Torsten Zesch. 2007. Cross-lingual distributional
profiles of concepts for measuring semantic distance.
In Proceedings of EMNLP/CoNLL, pages 571?580,
Prague, Czech Republic.
Preslav Nakov. 2001a. Latent semantic analysis
for Bulgarian literature. In Proceedings of Spring
Conference of Bulgarian Mathematicians Union,
Borovets, Bulgaria.
Preslav Nakov. 2001b. Latent semantic analysis for
Russian literature investigation. In Proceedings of
the 120 years Bulgarian Naval Academy Confer-
ence.
Sebastian Pado? and Jason Utt. 2012. A distributional
memory for German. In Proceedings of the KON-
VENS 2012 workshop on lexical-semantic resources
and applications, pages 462?470, Vienna, Austria.
Maciej Piasecki. 2009. Automated extraction of lexi-
cal meanings from corpus: A case study of potential-
ities and limitations. In Representing Semantics in
Digital Lexicography. Innovative Solutions for Lexi-
cal Entry Content in Slavic Lexicography, pages 32?
43. Institute of Slavic Studies, Polish Academy of
Sciences.
Pavel Smrz? and Pavel Rychly?. 2001. Finding semanti-
cally related words in large corpora. In Text, Speech
and Dialogue, pages 108?115. Springer.
Marko Tadic?. 2005. The Croatian Lemmatization
Server. Southern Journal of Linguistics, 29(1):206?
217.
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37:141?188.
789
Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 48?57,
Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational Linguistics
Lemmatization and Morphosyntactic Tagging of Croatian and Serbian
Z?eljko Agic?? Nikola Ljubes?ic?? Danijela Merkler?
?Department of Information and Communication Sciences
?Department of Linguistics
Faculty of Humanities and Social Sciences, University of Zagreb
Ivana Luc?ic?a 3, 10000 Zagreb, Croatia
zagic@ffzg.hr nljubesi@ffzg.hr dmerkler@ffzg.hr
Abstract
We investigate state-of-the-art statistical
models for lemmatization and morphosyn-
tactic tagging of Croatian and Serbian.
The models stem from a new manually
annotated SETIMES.HR corpus of Croa-
tian, based on the SETimes parallel cor-
pus. We train models on Croatian text
and evaluate them on samples of Croat-
ian and Serbian from the SETimes corpus
and the two Wikipedias. Lemmatization
accuracy for the two languages reaches
97.87% and 96.30%, while full morphosyn-
tactic tagging accuracy using a 600-tag
tagset peaks at 87.72% and 85.56%, respec-
tively. Part of speech tagging accuracies
reach 97.13% and 96.46%. Results indicate
that more complex methods of Croatian-to-
Serbian annotation projection are not re-
quired on such dataset sizes for these par-
ticular tasks. The SETIMES.HR corpus, its
resulting models and test sets are all made
freely available.
1 Introduction
Part of speech tagging (POS tagging) is an natu-
ral language processing task in which words are
annotated with the corresponding grammatical cate-
gories ? parts of speech: verb, noun, adjective, pro-
noun, etc. ? in a given context. It is also frequently
called morphosyntactic tagging (MSD tagging, i.e.,
tagging with morphosyntactic descriptions), espe-
cially when addressing highly inflected languages,
for which the tagging process often includes as-
signing additional subcategories to words, such as
gender and case for nouns or tense and person for
verbs. POS/MSD tagging is a well-known task and
an important preprocessing step in natural language
processing. It is often preceded or followed by
lemmatization ? the process of mapping inflected
word forms to corresponding base forms or lemmas.
State of the art in POS/MSD tagging and lemma-
tization across languages is generally achieved ?
both in terms of per token accuracy and speed and
robustness ? by statistical methods, which involve
training annotation models on manually annotated
corpora.
In this paper, we investigate the possibility of uti-
lizing statistical models trained on corpora of Croa-
tian in lemmatization and MSD tagging of Croatian
and Serbian. We present a new manually annotated
corpus of Croatian ? the SETIMES.HR corpus. We
test a number of lemmatizers and MSD taggers on
Croatian and Serbian test sets from two different
domains and consider options of annotation trans-
fer between the two languages. We also outline a
first version of the Multext East v5 tagset and three
usable reductions of this tagset. Special emphasis
is given to rapid resource development and public
availability of our research. Thus, the SETIMES.HR
corpus, the test sets and the best lemmatization and
MSD tagging models are made publicly available.1
In the following section, we discuss related work
on lemmatization and tagging of Croatian and Ser-
bian. We then present the SETIMES.HR corpus and
the test sets, selected lemmatizers and morphosyn-
tactic taggers and the experimental method. Finally
we provide a discussion of the evaluation results
and indicate future work directions.
2 Related work
The task of tagging English sentences with parts of
speech is generally considered a closed issue. This
is due to the fact that, over the course of the past 11
years, from (Brants, 2000) to (S?gaard, 2011), the
current state of the art in tagging English has im-
proved by 1.04 ? to 97.50% in terms of per token
accuracy. This is, however, not the case for lan-
guages with richer morphology and free sentence
1http://nlp.ffzg.hr/resources/models/
48
word order, such as Croatian and Serbian.
Current state of the art for statistical MSD tag-
ging of Croatian is reported at 86.05% (Agic? et
al., 2008). It involves a hidden Markov model tri-
gram tagger CroTag, trained on the Croatia Weekly
100 thousand wordform (100 kw) subcorpus of
Croatian newspaper text from Croatian National
Corpus (Tadic?, 2009), manually MSD-tagged and
lemmatized using the Multext East v3 tagset (MTE
v3) (Erjavec, 2004) and Croatian Lemmatization
Server (Tadic?, 2005) for guided annotation. The
tagger is not publicly available. Just recently, the
Croatia Weekly corpus has been made publicly
available through META-SHARE.2 Another line of
research reports on a prototype constraint grammar
tagger for Croatian (Peradin and S?najder, 2012),
which scores at 86.36% using a MTE-based tagset.
This tagger is also not publicly available as it is in
prototype stage and it currently does not analyze
out-of-vocabulary word forms. The top score for
lemmatizing Croatian text is reported at 96.96%
by combining CroTag and Croatian Morphological
Lexicon (Agic? et al, 2009). The lemmatizer is not
publicly available.
Lemmatization and tagging of Serbian text
was recently addressed in (Gesmundo and
Samardz?ic?, 2012a; Gesmundo and Samardz?ic?,
2012b). It involves BTagger, a combined bidirec-
tional tagger-lemmatizer tool which implements a
lemmatization-as-tagging paradigm. Models are
trained on the Serbian Multext East 1984 corpus,
they are publicly available3 under a permissive li-
cense, reaching overall accuracies of 97.72% for
lemmatization and 86.65% for MSD tagging. It
should be noted, however, that BTagger evaluation
in terms of spatial and temporal complexity was not
documented and that the results provided for Ser-
bian are obtained on specific in-domain data, i.e.,
a corpus of fiction and are thus not directly com-
parable to, e.g., results for Croatian on the Croatia
Weekly newspaper corpus.
Other lines of research in Serbian lemmatization
and tagging exists. Delic? et al (2009) deals with
transformation-based tagging of Serbian text, but
it does not provide state-of-the-art results or freely
available resources. Rule-based approaches to pro-
cessing Serbian using NooJ 4 and similar linguistic
development environments have been thoroughly
2http://metashare.elda.org/
3https://github.com/agesmundo/BTagger
4http://www.nooj4nlp.net/
explored (Vitas et al, 2003). Several resources rel-
evant for Serbian lemmatization and tagging are
provided to the public. The Serbian version of
Jules Verne 60 kw manually lemmatized and MTE-
tagged corpus implements a small deviation from
MTE v4 and deals with specific fictional closed-
vocabulary data. SrpLemKor is a 3.7 Mw corpus of
Serbian newspaper text, automatically lemmatized
and POS-tagged using TreeTagger (Schmid, 1995)
with a tagset of 16 POS tags. A morphological dic-
tionary of 85 thousand Serbian lemmas with sligtly
deviated MTE v4 tagset is available through NooJ.
Public availability of these resources is enabled
through META-SHARE, with somewhat more re-
strictive licensing that involves non-commercial
use in all cases and for some of them it also im-
poses no redistribution.
Related work on lemmatizer and tagger compar-
ison exists for many languages. Restraining the
search to closely related Slavic languages, exten-
sive work in this domain has been done for Bul-
garian (Georgiev et al, 2012), Czech (Spoustova?
et al, 2007) and Slovene (Erjavec and Dz?eroski,
2004; Rupnik et al, 2008). For Croatian, prelim-
inary work on tagger evaluation for tagger voting
has been conducted (Agic? et al, 2010).
3 SETIMES.HR corpus
SETIMES.HR is a new manually lemmatized and
MSD-tagged corpus of Croatian. It is built on top
of the SETimes parallel newspaper corpus involv-
ing 10 languages from the SEE region,5 Croatian
and Serbian included. This initial dataset selection
was deliberate in terms of enabling us with possibil-
ity of cross-lingual annotation projection and other
cross-lingual experiments. SETIMES.HR was anno-
tated by experts using the Croatian Lemmatization
Server (HML)6 (Tadic?, 2005) to facilitate the pro-
cess. We made a number of changes to the initial
annotation provided by human annotators. Namely,
HML provides MSD tags using an undocumented
alteration of the initial MTE tagset, which we cor-
rected to conform entirely to the MTE v4 standard
(Erjavec, 2012). Also, for certain lemmas HML
provides lemmatization with morphosemantic cues
encoded by lemma numbering ? e.g. biti1 (en. to
be) and biti2 (en. to beat) ? which we omitted as
they are used only in the process of generating the
morphological lexicon (Tadic? and Fulgosi, 2003)
5http://www.nljubesic.net/resources/corpora/setimes/
6http://hml.ffzg.hr
49
Corpus Sent?s Tokens Types Lemmas
SETIMES.HR 4 016 89 785 18 089 8 930
set.test.hr 100 2 297 1 270 991
set.test.sr 100 2 320 1 251 981
wiki.test.hr 100 1 887 1 027 802
wiki.test.sr 100 1 953 1 055 795
Table 1: Stats for SETIMES.HR and test sets
and are thus not required for purposes of lemmati-
zation and MSD tagging. We make the resulting 90
kw SETIMES.HR corpus, along with the four test
sets, publicly available under the CC-BY-SA-3.0
license.7 Corpus stats are given in Table 1.
For purposes of this experiment, we propose an
alteration of the baseline MTE v4 tagset in form
of a first version for the MTE v5 standard.8 The
biggest changes in the new version are participal ad-
jectives and adverbs moving from the verbal subset
? which was very complex in v4 ? to the adjectival
and adverbial subsets. Additionally, acronyms are
moved from the abbreviation subset to the noun
subset. A general shrinking of the length of many
tags was performed as well because from v4 on-
wards the MTE standard does not require one tagset
for all languages in the standard. We also suggest
three reductions of the suggested MTE v5 tagset:
1. without adjective definiteness (v5r1),
2. without common (Nc) vs. proper (Np) distinc-
tion for nouns (v5r2) and
3. without both (v5r3).
Adjectival definiteness is a category which is easy
to implement in a morphological lexicon, but is
very hard to distinguish in context as many of its
variants are homographs. We question the distinc-
tion between common and proper nouns as well
since they are contextually very hard to discrimi-
nate. On the other hand, some foreign proper nouns
are inflected by specific paradigms and suffix tries
used on unknown words could profit from this dis-
tinction. Stats for the MTE v5 and the reduced
tagset versions in comparison with the baseline
MTE v4 tagset version of SETIMES.HR are given
in Table 2. They reflect the design choices we
made: MTE v5 has a comparable amount of tags
as MTE v4, gaining additional tags in the adjective
subset, but losing tags in the verb and abbreviation
subsets, while the reductions subsequently lower
the overall MSD tag count.
7http://creativecommons.org/licenses/by-sa/3.0/
8http://nl.ijs.si/ME/V5/msd/html/
set.test wiki.test
Tagset SETIMES.HR hr sr hr sr
MTE v4 660 235 236 188 192
MTE v5 663 233 234 192 195
MTE v5r1 618 213 216 176 180
MTE v5r2 634 216 217 178 181
MTE v5r3 589 196 199 162 166
Table 2: Tagset variation in tag counts
4 Experiment setup
In this section, we define specific experiment goals
and the experiment design. We also present the
datasets and tools used in the experiment.
4.1 Objectives
The principal goal of this experiment is to provide
prospective users with freely available ? download-
able, retrainable and usable, both for research pur-
poses and for commercial use ? state-of-the-art
lemmatization and tagging modules for Croatian
and Serbian. An additional goal of our experi-
ment is to inspect lemmatization and tagging tools
available under permissive licenses and give an
overview regarding their accuracy and time com-
plexity when used on languages of morphological
complexity such as Croatian and Serbian.
Regarding the previously discussed constraints
on existing corpora and tools for Croatian and Ser-
bian tagging and lemmatization, our objective im-
plies exclusive usage of the SETIMES.HR corpus in
the experiment.9 Since SETIMES.HR is part of the
SETimes parallel corpus which, among other lan-
guages, includes both Croatian and Serbian, manu-
ally annotated SETIMES.HR text has a freely avail-
able Serbian equivalent. Our first course of action
was thus to train a number of taggers and lemma-
tizers on SETIMES.HR and test it on Croatian and
Serbian held out text to verify state-of-the-art ac-
curacy on Croatian text and to observe whether
the expected decline in accuracy on Serbian text is
substantial or not.
In case of substantial decrease in accuracy for
lemmatizing and tagging Serbian using Croatian
models, we designed multiple schemes for project-
ing annotation from SETIMES.HR to its Serbian
9Considering corpora of Croatian and Serbian stated in
related work, we chose not to use non-MTE resources and
corpora of fiction as an experiment basis. Importance of en-
coding the full set of morphological features from the MTE
tagset is illustrated by its benefits for dependency parsing of
Croatian (Agic? and Merkler, 2013).
50
equivalent from the SETimes parallel corpus. The
general directions for identifying the bitext sub-
set for annotation projection were using parallel
sentences which have the highest longest common
subsequence or using statistical machine transla-
tion to produce Serbian sentences with minimum
difference to the Croatian counterpart. Projecting
tags on a bitext of high similarity would include
heuristics of annotating the variation with the same
morphosyntactic category if the variation was one
token long or annotating it with the existing model
for tagging if the variation was longer than that.
Lemmatization of the single-token variation would
be reapplied if the token ending in both languages
was identical while other cases would be annotated
with the existing lemmatization model.
4.2 Experiment workflow
We do four batches of experiments:
1. to identify the best available tool and underly-
ing paradigm for lemmatization and tagging
of both languages by observing overall accu-
racy and execution time,
2. to establish the need for annotation projec-
tion from Croatian SETIMES.HR corpus to its
Serbian counterpart,
3. to select the best of the proposed MTE-based
tagsets for both tasks and
4. to provide in-depth evaluation of the selected
top-performing lemmatizer and tagger on both
languages by using the top-performing tagset.
In the first experiment batch, we test the tools only
on Croatian data from SETimes. The second batch
establishes the need for ? or needlessness of ? an-
notation projection for improved processing of Ser-
bian text by testing the tools selected in the first
batch on both languages. The in-depth evaluation
of the third and fourth experiment batch includes,
for both languages and all test sets, observing the
influence of tagset selection to overall accuracy and
investigating tool performance in more detail. We
measure precision, recall and F1 scores for selected
parts of speech and inspect lemmatization and tag-
ging confusion matrices for detailed analysis and
possible prediction of tool operation in real-world
language processing environments.
We aim for the experiment to serve as underly-
ing documentation for enabling prospective users
in implementing more complex natural language
processing systems for Croatian and Serbian by us-
ing these resources. Additionally, the overview of
the usability of tools available is informative for re-
searchers developing basic language technologies
for other languages. We test statistical significance
of observed differences in our results by using the
approximate randomization test.
4.3 Datasets
All models are trained on SETIMES.HR. To at
least partially avoid the possible pitfall of exclu-
sive in-domain testing, we define two test sets for
each language. The first test set consists of 100
Croatian-Serbian parallel sentence pairs taken by
random sampling from the relative complement
of the SETimes parallel corpus and SETIMES.HR.
The second test set is taken from the Croatian and
Serbian Wikipedia by manually selecting 20 match-
ing Wikipedia articles and manually extracting 100
approximate sentence pairs. We chose manual over
random sampling from Wikipedia to account for
the fact that a certain number of articles is virtu-
ally identical between the two Wikipedias due to
language similarity and mutual copying between
Wikipedia users. All four test sets were manually
annotated using the same procedure that was used
for SETIMES.HR. The stats are given in Table 1. In
addition, we have verified the difference between
language test sets by measuring lexical coverage
using HML as a high-coverage morphological lex-
icon of Croatian. For the Croatian SETimes and
Wikipedia samples, we detected 5.2% and 3.9%
out-of-vocabulary word forms and 11.40% and
8.86% were observed for the corresponding Ser-
bian samples, supporting well-foundedness of the
test sets in terms of maintaining the differences
between the two languages.
4.4 Lemmatizers and taggers
As lemmatizers and taggers with permissive licens-
ing schemes and documented cross-lingual state-of-
the-art performance have become largely available,
we chose not to implement our own but to obtain a
set of tools and test them using our data, i.e., train
them on the SETIMES.HR corpus and test them
on Croatian and Serbian SETimes and Wikipedia
test samples. We selected the tools on the basis of
availability and underlying stochastic paradigms as
to identify the best tools and best paradigms.
We tested hidden Markov model trigram taggers
HunPos10 (Hala?csy et al, 2007) and lemmatization-
capable PurePos11 (Orosz and Nova?k, 2012),
10https://code.google.com/p/hunpos/
11https://github.com/ppke-nlpg/purepos
51
Tool Lem. MSD Train (sec) Test (sec)
BTagger 96.22 86.63 24 864.47 87.01
CST 97.78 ? 1.80 0.03
+ lex 97.04 ? 1.87 0.12
HunPos ? 87.11 1.10 0.11
+ lex ? 84.81 10.79 0.45
PurePos 74.40 86.63 5.49 4.42
SVMTool ? 84.99 1 897.08 3.28
TreeTagger 90.51 85.07 7.49 0.19
+ lex 94.12 87.01 17.48 0.31
Table 3: Preliminary evaluation
lemmatization-capable decision-tree-based Tree-
Tagger12 (Schmid, 1995), support vector machine
tagger SVMTool13 (Gime?nez and Ma`rquez, 2004)
and CST?s14 data-driven rule-based lemmatizer (In-
gason et al, 2008). Keeping in mind the previously
mentioned state-of-the-art scores on Serbian 1984
corpus and statistical lemmatization capability, we
also tested BTagger (Gesmundo and Samardz?ic?,
2012a; Gesmundo and Samardz?ic?, 2012b). Since
some lemmatizers and taggers are capable of using
an external morphological lexicon, we used a MTE
v5r1 version of Apertium?s lexicon of Croatian15
(Peradin and Tyers, 2012) where applicable.16 All
tools are well-documented and successfully applied
across languages, as indicated in related work.
5 Results and discussion
A discussion of the experiment results follows in
the next four subsections. Each subsection repre-
sents one batch of experiments. First we select the
best lemmatizer and tagger, next we check for a
need of annotation projection to the Serbian corpus,
then the best MTE-based tagset using the best tool
combination. Finally we provide a more detailed
insight into the results of the top-performing pair
of selected tools and tagset.
5.1 Tool selection
Results of the first experimental batch, consisting
of testing the selected set of lemmatizers and tag-
gers on the MTE v5r1 version of Croatian SETimes
test set, are given in Table 3. In terms of lemmati-
12http://www.cis.uni-muenchen.de/ schmid/tools/TreeTagger/
13http://www.lsi.upc.edu/ nlp/SVMTool/
14http://cst.dk/online/lemmatiser/uk/
15http://www.apertium.org/
16As with already existing Croatian annotated corpora,
HML is not fully MTE compliant. For future work, we might
utilize a compliant version in our experiment and resulting
models, being that its coverage is generally greater than the
one of Apertium?s lexicon due to size difference.
set.test wiki.test
POS hr sr hr sr
HunPos 97.04 95.47 94.25 96.46
+ lex 96.60 95.09 94.62 95.58
MSD
HunPos 87.11 85.00 80.83 82.74
+ lex 84.81 81.59 78.49 79.20
Table 4: Overall tagging accuracy with and without
the inflectional lexicon
set.test wiki.test
Model hr sr hr sr
CST 97.78 95.95 96.59 96.30
+ lex 97.04 95.52 96.38 96.61
Table 5: Overall lemmatization accuracy with and
without the inflectional lexicon
zation and tagging accuracy as well as processing
speed in both training and testing, the top perform-
ing tools are CST lemmatizer and HunPos tagger.
Thus, we chose these two for further investigation
in the following batches of experiments. It should
be noted that, even though its performance is com-
parable to the one of CST and HunPos, BTagger
was not chosen for the other batches primarily be-
cause of its temporal complexity, as it is orders of
magnitude higher than for the selected tools. Given
that lemmatization and tagging are considered pre-
requisites for further processing of text tata, the
data itself often being fed to these modules in large
quantities (e.g., web corpora), we insist on the sig-
nificance of temporal complexity in tool selection.
The other results are comparable with previous re-
search in tagging Croatian. Where applicable, we
tried assisting the tools by providing Apertium?s
lexicon as an optional input for improved lemma-
tization and tagging. Only TreeTagger lemmatiza-
tion and tagging benefited from lexicon inclusion.
However, it should be noted that TreeTagger imple-
ments a very simple approach to lemmatization, as
it only performs dictionary matching and does not
lemmatize unknown words. Inclusion of a larger
lexicon such as HML might be more beneficial for
all the tools.
5.2 Annotation projection
HunPos tagging accuracy on all Croatian and Ser-
bian test sets for both POS only and full MSD is
given in Table 4 for the default variant and for the
52
Tagset set.test wiki.test
POS hr sr hr sr
MTE v4 96.08 94.61 93.96 95.85
MTE v5 97.04 95.52 94.30 96.40
MTE v5r1 97.04 95.47 94.25 96.46
MTE v5r2 97.00 95.60 94.20 96.30
MTE v5r3 97.13 95.56 94.09 96.15
MSD
MTE v4 86.24 83.45 80.45 81.98
MTE v5 86.77 84.48 80.46 82.43
MTE v5r1 87.11 85.00 80.83 82.74
MTE v5r2 87.11 84.96 81.20 82.38
MRE v5r3 87.72 85.56 81.52 82.79
Table 6: HunPos POS and MSD tagging accuracy
for all tagsets
set.test wiki.test
Tagset hr sr hr sr
MTE v4 97.78 95.82 96.66 96.11
MTE v5 97.82 95.86 96.81 96.30
MTE v5r1 97.78 95.95 96.59 96.30
MTE v5r2 97.87 95.99 96.75 96.20
MTE v5r3 97.74 95.99 96.54 96.20
Table 7: CST lemmatization accuracy for all tagsets
one using Apertium?s lexicon. These results serve
as the first decision point regarding the need for
Croatian-to-Serbian annotation projection, the sec-
ond one being the lemmatization scores in Table
5. Here we observed an unsubstantial decrease
in POS and MSD tagging between Croatian and
Serbian test sets ? the observed difference is, in
fact, more substantial across domains than across
languages. Overall, Croatian and Serbian scores
differ less than 3%. Results for Serbian Wikipedia
sample are even consistently better than for Croa-
tian Wikipedia, emphasizing domain significance
over language difference. The tagger does not ben-
efit from the inclusion of the inflectional lexicon
in POS tagging and it even incurs a substantial 2%
to 4% penalty in MSD tagging. Since such obser-
vations were not made while including the lexicon
with the TreeTagger tool ? which implements the
simplest form of dictionary lemmatization ? we
performed a small results analysis and noticed an
unnaturally high percentage of categories that are
as expected present in the lexicon, but very rare in
the training corpus (like the vocative case) point-
ing to a na??ve implementation of the procedure.
Thus we chose not to use the lexicon in further
observations. Lack of more substantial differences
Tagsets v5 v5r1 v5r2 v5r3
v4 0.268 <0.05 <0.05 <0.01
v5 / <0.01 <0.05 <0.01
v5r1 / / 0.877 <0.05
v5r2 / / / <0.01
Table 8: Statistical significance of differences in
full MSD tagging between tagsets (p-values using
approximate randomization)
in tagging scores between Croatian and Serbian
for this specific test scenario implied no need for
annotation projection.
This is further supported by overall lemmatiza-
tion scores in Table 5. Even with the observed
lexical differences between the languages, as we
indicated in the description of the test sets by mea-
suring lexical coverage using HML, the learned
CST lemmatizer rules are more robust consider-
ing language alteration than the trigram tagging
model of HunPos. Lemmatization accuracy stays
in the margins of approximately 97%?1% for both
languages. Average accuracy on Croatian is less
than 2% higher than for Serbian and the domain
patterns observed for tagging are also observed for
lemmatization. Benefits of an inflectional lexicon
for lemmatization are minor, if any, which can be
followed back to the small size of the lexicon and
high quality of the CST lemmatizer. On the con-
trary, TreeTagger?s simple lemmatization does gain
four points by using the lexicon, but it initially
performs seven points worse than CST.
5.3 Tagset selection
Tables 6 and 7 show the influence of tagset de-
sign on tagging and lemmatization accuracy. They
are accompanied by Table 8, i.e., results of testing
statistical significance of differences between the
tagsets in the task of full MSD tagging from Table 6.
Statistical significance is calculated with all test
sets merged into one. Differences in lemmatization
accuracy are virtually non-existent regarding the
tagset choice. Full MSD tagging follows the usual
pattern of inverse proportionality between tagset
size and overall accuracy. It should be noted that
MTE v5 accuracy is not significantly higher than
MTE v4 accuracy (p = 0.268), but we consider the
new tagset to be easier to use for humans since its
tags are shortened by removing placehodlers for
features used in other MTE languages. Consider-
ing that only tagging accuracy using the MTE v5r3
tagset is significantly better than tagging using all
53
Croatian Serbian
POS P R F1 P R F1
Adj 94.33 90.14 92.19 94.34 93.98 94.16
66.80 63.83 65.28 66.79 66.54 66.66
Adv 84.56 82.73 83.63 82.57 73.77 77.92
84.56 82.73 83.63 82.57 73.77 77.92
Conj 95.29 93.82 94.55 97.92 95.29 96.59
94.12 92.66 93.38 96.89 94.28 95.57
Noun 95.70 96.34 96.02 95.42 96.59 96.00
76.78 77.30 77.04 75.38 76.30 75.84
Num 94.57 97.75 96.13 96.51 93.26 94.86
91.30 94.38 92.81 94.19 91.01 92.57
Prep 98.10 99.72 98.90 98.45 98.70 98.57
95.93 97.52 96.72 94.30 94.55 94.42
Pron 95.97 97.54 96.75 95.78 97.42 96.59
81.85 83.20 82.52 81.43 82.83 82.12
Verb 95.88 98.07 96.96 95.23 95.72 95.47
93.81 95.96 94.87 93.36 93.84 93.60
Table 9: Precision (P), recall (R) and F1 score for
POS only (1st column) and full MSD (2nd column)
on Croatian and Serbian
other suggested tagsets, we chose this tagset and
tagging model for further observation of lemmatiza-
tion and tagging properties in the remainder of the
paper. Still, in this section, we present the results
on all tagsets to serve as underlying documentation
of the observed differences, mainly because of the
fact that only MTE v4 is officially supported at
this moment and MTE v5 is a newly-introduced
prototype that displays better performance in this
specific experiment.
5.4 In-depth analysis
In Table 9 we merge SETimes and Wikipedia test
sets by language and provide POS and MSD tag-
ging precision, recall and F1 score for selected
Croatian and Serbian parts of speech. In terms of
POS only, the most difficult-to-tag part of speech
is the adverb, followed by the adjective in both
Croatian and Serbian. The other categories are
consistently POS-tagged with an F1 score of ap-
proximately 95% or higher. The decrease for ad-
verbs and adjectives is somewhat more evident in
precision than in recall and the POS confusion ma-
trix for both languages, given in Table 10, shows
that these two parts of speech are often mistaken
for each other by the tagger. Regarding full MSD
tagging using the MTE v5r3 tagset, for both lan-
guages, the lowest F1 scores are observed for ad-
jectives (approximately 66%), nouns (76%) and
pronouns (82%). This is most likely due to the fact
that these parts of speech have the largest tagset
subsets, making it easier for the tagger to get con-
fused.17 Performance for other parts of speech is
satisfactory, especially for verbs, keeping in mind,
e.g., possible subsequent dependency parsing of the
two languages. The absolute difference between
POS and MSD tagging score is most substantial
for adjectives (approximately 27%), indicating that
certain MSD features might be triggering the de-
crease. This is partially supported by our tagset
design investigation as dropping adjective definite-
ness atribute yielded substantial overall tagging
accuracy increase when compared with the tagsets
in which this attribute is still encoded.
In Table 10 we provide a part of speech confu-
sion matrix for Croatian and Serbian on test sets
merged by language. In Croatian test sets, the most
frequent confusions are those between adjectives
and nouns (28.9%), nouns and verbs (14.5%), ad-
jectives and adverbs (11.6%) and nouns and ad-
verbs (6.9%). In Serbian text, the tagger most fre-
quently confuses nouns ? for adjectives (21.1%),
verbs (20%) and adverbs (16%). Merging the test
sets by language mostly evens out the tagging dif-
ferences as there is a total of 173 MSD confusions
in Croatian test sets and only 3 more, i.e., 175 in
the Serbian test sets.
POS scores for both languages neared the level
of human error in our experiment. Keeping that
in mind, upon observing the confusion instances
themselves, we spotted a confusion between adjec-
tives and nouns (e.g. names of countries (Hrvatska
(en. Croatia, Croatian)), homographic forms
(strana (en. foreign, side), svet (en. world, holy))
and confusion between adjectives and adverbs. Ad-
verbs and prepositions are sometimes confused
with nouns, especially for nouns in instrumental
case (e.g. godinama (en. year, yearly), tijekom
(en. duration, during)). Conjuctions are at times
incorrently tagged because various words can have
a conjuctional function, most frequently pronouns
and adverbs: s?to (en. what), kako (en. how), kada
(en. when). Interestingly, there is some confusion
between nouns and verbs in Wikipedia test sets,
while in SETimes test sets there are almost none.
This confusion arises from the homographic forms
? e.g. mora (en. must, seas) ? or from nouns with
17There are 589 MTE v5r3 tags in SETIMES.HR. Out of
these, 164 are used for tagging adjectives, 42 for nouns and
268 for pronouns, thus accounting for 80.47% of the tagset.
There are also 50 verb tags.
54
POS Abbr Adj Adv Conj Noun Num Part Prep Pron Res Verb
Abbr 0 0 0 1 3 0 0 0 0 0
Adj 0 20 0 50 0 1 0 3 1 4
Adv 0 10 9 12 0 0 2 0 0 2
Conj 0 0 5 2 0 5 5 7 0 0
Noun 0 37 28 0 4 0 1 5 7 25
Num 2 4 0 0 2 0 0 0 0 0
Part 0 0 0 3 0 0 0 0 0 3
Prep 0 0 2 3 2 0 1 0 0 0
Pron 0 2 1 9 3 0 1 0 0 1
Res 0 0 1 0 4 0 0 2 0 0
Verb 0 9 4 0 35 1 2 1 0 1
Table 10: POS confusion matrix for Croatian (top right) and Serbian (bottom left)
Figure 1: Learning curves for Croatian and Serbian lemmatization and tagging
suffixes -la and -lo, which are used for denoting
participles in feminine and neuter gender, or with
suffix -ti, which is also a suffix for infinitive.
Most MSD tag confusions arise from the fact that
the same suffix can denote different cases in dif-
ferent declensions. We observed confused number
and gender category (mostly in adjectives in mas-
culine and neuter gender), but the most frequent
confusion occurs for accusative forms in masculine
gender, which have different suffixes when they de-
note animacy (suffix is the same as in the genitive
case: pobjednika (en. winner), kandidata (en. can-
didate)) and when they denote inanimacy (suffix
is the same as in the nominative case: metak (en.
bullet), bubnjar (en. drummer)).
In lemmatization, as in POS tagging, errors are
generally very infrequent. Some occur with adjec-
tives, when an assigned lemma represents a definite
form of an adjective, instead of an indefinitive form
(and less frequently vice versa). Besides, adjec-
tives are sometimes confused with adverbs (e.g.,
target lemma is znac?ajno (en. significantly), but
the lemma znac?ajan (en. significant) is assigned,
and vice versa). Other less frequent examples in-
clude cases in which the assigned lemma is not in
its canonical form, but a case other than the nomi-
native case, or when the assigned lemma is a word
stem. A small number of errors also occurs due
to slight differences in Croatian and Serbian word-
forms, e.g., when a Serbian nominative form is not
a nominative form in Croatian (planeta as Serbian
nominative and Croatian genitive, planet being the
Croatian nominative).
Figure 1 provides lemmatization, POS and MSD
tagging learning curves for both languages on
merged test sets. Apart from the slight difference
in lemmatization scores in favor of Croatian, the
learning curves and overall scores on merged test
sets are virtually identical. The easiest task to learn
is lemmatization while the most complex one is
applying MSD.
6 Conclusions and future work
In this paper, we have addressed the issue of lemma-
tization and morphosyntactic tagging of two gener-
ally under-resourced languages, Croatian and Ser-
bian. Our goal was to provide the general public
with freely available language resources and state-
55
of-the-art models for lemmatization and tagging of
these two languages in terms of accuracy, robust-
ness and speed. We also aimed at using lemmati-
zation and tagging as a platform for implicit com-
parison of the two languages in natural language
processing terms, as to provide partial insight to
how difficult and lossy ? or, more desireably, how
easy and straightforward ? would it be to port lin-
guistic resources and language processing tools
from one language to another.
While developing the models, we completed a
series of experiments. We used the Croatian text
from the freely available SETimes parallel corpus
to create a new manually lemmatized and mor-
phosyntactically tagged corpus of Croatian ? the
SETIMES.HR corpus. Beside the Multext East v4
morphosyntactic tagset specification for Croatian
which was used for initial corpus annotation, we
designed and implemented a first version of the
Multext East v5 tagset and its three reductions and
applied these to SETIMES.HR. Using SETimes
and Wikipedia as starting point resources, we cre-
ated two gold standard test sets for each language
in order to test existing state-of-the-art lemmatiz-
ers and taggers. We ran preliminary tests on a
number of tools to select CST lemmatizer and
HunPos tagger as tools of choice considering ob-
served accuracy, training time and text processing
time. In an in-depth evaluation of these tools, we
obtained peak overall lemmatization accuracy of
97.87% and 96.30% for Croatian and Serbian and
full morphosyntactic tagging accuracy of 87.72%
and 85.56%, with basic part of speech tagging ac-
curacy at 97.13% and 96.46%. In this specific test
scenario and with this specific training set, we have
shown the differences in results between Croatian
and Serbian not to be significant enough to justify
an effort in more elaborate strategy of adapting
Croatian models to Serbian data ? simply training
the models on Croatian text from SETIMES.HR
corpus and using them on Serbian text provided
state-of-the-art results in lemmatization and tag-
ging, while maintaining and even topping previ-
ously documented state of the art for Croatian.
The SETIMES.HR corpus, Croatian and Serbian
test sets and top-performing lemmatization and tag-
ging models are publicly available and freely down-
loadable18 under the CC-BY-SA-3.0 license.
Our future work plans include both enlarging
and enhancing SETIMES.HR. The presented learn-
18http://nlp.ffzg.hr/resources/models/
ing curves show significant room for improvement
by annotating additional data. The dataset aleady
serves as a basis for the SETIMES.HR treebank of
Croatian (Agic? and Merkler, 2013), implementing
a novel dependency syntactic formalism and en-
abling experiments with joint dependency parsing
of Croatian and Serbian. Should dependency pars-
ing experiments show the need for more elaborate
language adaptation strategies, we will most likely
implement them also on the level of lemmas and
morphosyntactic tags before addressing syntactic
issues. This will possibly be helped by statistical
machine translation between Croatian and Serbian
to enhance bitext similarity and empower projec-
tion strategies. An effort could be made to adapt
existing Croatian and Serbian resources and subse-
quently to attempt achieving better lemmatization
and tagging performance by combining these with
SETIMES.HR. We will use the models presented in
this paper to annotate the web corpora of Croatian
and Serbian (Ljubes?ic? and Erjavec, 2011) ? hrWaC
and srWaC.
Acknowledgement
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme FP7/2007-2013 un-
der grant agreement n? PIAP-GA-2012-324414
(project Abu-MaTran).
References
Z?eljko Agic? and Danijela Merkler. 2013. Three Syn-
tactic Formalisms for Data-Driven Dependency Pars-
ing of Croatian. In Text, Speech and Dialogue. Lec-
ture Notes in Computer Science. Springer.
Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.
2008. Improving Part-of-Speech Tagging Accuracy
for Croatian by Morphological Analysis. Informat-
ica, 32(4):445?451.
Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.
2009. Evaluating Full Lemmatization of Croatian
Texts. In Recent Advances in Intelligent Information
Systems, pages 175?184. Exit Warsaw.
Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.
2010. Tagger Voting Improves Morphosyntactic
Tagging Accuracy on Croatian Texts. In Proceed-
ings of ITI, pages 61?66.
Thorsten Brants. 2000. TnT: A Statistical Part-of-
Speech Tagger. In Proceedings of ANLP, pages 224?
231.
56
Vlado Delic?, Milan Sec?ujski, and Aleksandar Ku-
pusinac. 2009. Transformation-Based Part-of-
Speech Tagging for Serbian Language. In Proceed-
ings of CIMMACS.
Tomaz? Erjavec and Sas?o Dz?eroski. 2004. Machine
Learning of Morphosyntactic Structure: Lemmatiz-
ing Unknown Slovene Words. Applied Artificial In-
telligence, 18:17?41.
Tomaz? Erjavec. 2004. MULTEXT-East Version 3:
Multilingual Morphosyntactic Specifications, Lexi-
cons and Corpora. In Proceedings of LREC.
Tomaz? Erjavec. 2012. MULTEXT-East: Morphosyn-
tactic Resources for Central and Eastern European
Languages. Language Resources and Evaluation,
46(1):131?142.
Georgi Georgiev, Valentin Zhikov, Kiril Simov, Petya
Osenova, and Preslav Nakov. 2012. Feature-Rich
Part-of-speech Tagging for Morphologically Com-
plex Languages: Application to Bulgarian. In Pro-
ceedings of EACL, pages 492?502.
Andrea Gesmundo and Tanja Samardz?ic?. 2012a. Lem-
matisation as a Tagging Task. In Proceedings of
ACL.
Andrea Gesmundo and Tanja Samardz?ic?. 2012b. Lem-
matising Serbian as Category Tagging with Bidirec-
tional Sequence Classification. In Proceedings of
LREC.
Jesu?s Gime?nez and Llu??s Ma`rquez. 2004. SVMTool:
A general POS Tagger Generator Based on Support
Vector Machines. In Proceedings of LREC.
Pe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.
2007. HunPos: An Open Source Trigram Tagger.
In Proceedings of ACL, pages 209?212.
Anton Karl Ingason, Sigru?n Helgado?ttir, Hrafn Lofts-
son, and Eir??kur Ro?gnvaldsson. 2008. A Mixed
Method Lemmatization Algorithm Using a Hierar-
chy of Linguistic Identities (HOLI). In Proceedings
of GoTAL, pages 205?216.
Nikola Ljubes?ic? and Tomaz? Erjavec. 2011. hrWaC
and slWaC: Compiling Web Corpora for Croatian
and Slovene. In Text, Speech and Dialogue, pages
395?402. Springer.
Gyo?rgy Orosz and Attila Nova?k. 2012. PurePos ?
An Open Source Disambiguator. In Proceedings of
NLPCS.
Hrvoje Peradin and Jan S?najder. 2012. Towards a
Constraint Grammar Based Morphological Tagger
for Croatian. In Text, Speech and Dialogue, pages
174?182. Springer.
Hrvoje Peradin and Francis M. Tyers. 2012. A Rule-
Based Machine Translation System from Serbo-
Croatian to Macedonian. In Proceedings of
FREERBMT12, pages 55?65.
Jan Rupnik, Miha Grc?ar, and Tomaz? Erjavec. 2008.
Improving Morphosyntactic Tagging of Slovene
Language Through Meta-Tagging. Informatica,
32(4):437?444.
Helmut Schmid. 1995. Improvements in Part-of-
Speech Tagging With an Application to German. In
Proceedings of ACL SIGDAT Workshop.
Anders S?gaard. 2011. Semi-Supervised Condensed
Nearest Neighbor for Part-of-Speech Tagging. In
Proceedings of ACL-HLT, pages 48?52.
Drahom??ra ?johanka? Spoustova?, Jan Hajic?, Jan
Votrubec, Pavel Krbec, and Pavel Kve?ton?. 2007.
The Best of Two Worlds: Cooperation of Statistical
and Rule-Based Taggers for Czech. In Proceedings
of BSNLP, pages 67?74.
Marko Tadic? and Sanja Fulgosi. 2003. Building the
Croatian Morphological Lexicon. In Proceedings of
EACL 2003 Workshop on Morphological Processing
of Slavic Languages, pages 41?46.
Marko Tadic?. 2005. Croatian Lemmatization Server.
Southern Journal of Linguistics, 29(1):206?217.
Marko Tadic?. 2009. New Version of the Croatian Na-
tional Corpus. After Half a Century of Slavonic Nat-
ural Language Processing, pages 199?205.
Dus?ko Vitas, Cvetana Krstev, Ivan Obradovic?,
Ljubomir Popovic?, and Gordana Pavlovic?-Laz?etic?.
2003. An Overview of Resources and Basic Tools
for Processing of Serbian Written Texts. In Pro-
ceedings of the Workshop on Balkan Language Re-
sources, 1st Balkan Conference in Informatics.
57
Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 22?33,
Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational Linguistics
Parsing Croatian and Serbian by Using Croatian Dependency Treebanks
Z?eljko Agic?? Danijela Merkler? Das?a Berovic??
?Department of Information and Communication Sciences
?Department of Linguistics
Faculty of Humanities and Social Sciences, University of Zagreb
Ivana Luc?ic?a 3, 10000 Zagreb, Croatia
zagic@ffzg.hr dmerkler@ffzg.hr dberovic@ffzg.hr
Abstract
We investigate statistical dependency parsing
of two closely related languages, Croatian and
Serbian. As these two morphologically com-
plex languages of relaxed word order are gen-
erally under-resourced ? with the topic of de-
pendency parsing still largely unaddressed, es-
pecially for Serbian ? we make use of the
two available dependency treebanks of Croa-
tian to produce state-of-the-art parsing models
for both languages. We observe parsing accu-
racy on four test sets from two domains. We
give insight into overall parser performance
for Croatian and Serbian, impact of prepro-
cessing for lemmas and morphosyntactic tags
and influence of selected morphosyntactic fea-
tures on parsing accuracy.
1 Introduction
Croatian and Serbian are very closely related South
Slavic languages with complex morphology and rel-
atively free word order. They are mutually intel-
ligible with one another, as well as with Bosnian
and Montenegrin, amounting for more than 20 mil-
lion native speakers.1 Regarding language technol-
ogy support, they are considered to be generally
under-resourced. More specifically, while a cor-
pus of research on processing Croatian and Ser-
bian on the morphosyntactic and shallow syntactic
1Bekavac et al (2008) provide a corpus-based comparison
of Bosnian, Croatian and Serbian, observing similarities and
differences in morphology, syntax and semantics. For further
insight regarding Croatian and Serbian morphosyntax, see the
respective contemporary grammars (Silic? and Pranjkovic?, 2005;
Stanojc?ic? and Popovic?, 2008).
layer does exist (Tadic? et al, 2012; Vitas et al,
2012), approaches to full syntactic analysis of the
two languages were up to this point very sparse
and very recent (Agic? and Merkler, 2013). As lin-
guistic tradition supports dependency-based syntac-
tic formalisms for the two languages (Bo?hmova? et
al., 2003; Tadic?, 2007), it should be noted that
they have not participated in the previous collabo-
rative research efforts in dependency parsing, such
as the CoNLL shared tasks (Buchholz and Marsi,
2006; Nivre et al, 2007). Furthermore, regardless of
the specific research topic, the communities dealing
with natural language processing of Croatian, Ser-
bian and other closely related languages from their
group are still to reach the common level of aware-
ness with respect to public availability of their re-
search. Contributions to availability of Croatian and
Serbian resources have once again been very few
and recent (Tadic? and Varadi, 2012), especially for
free culture licensing.
Through the line of research we propose here,2 we
seek to provide state-of-the-art in dependency pars-
ing for both Croatian and Serbian. In this first group
of experiments, we build on the fact of their close
relatedness by using the two Croatian treebanks ?
Croatian Dependency Treebank (Tadic?, 2007) and
SETIMES.HR Treebank (Agic? and Merkler, 2013) ?
to build unified parsing models and evaluate them
across the languages and domains. As we deal with
highly inflectional languages, we also investigate
the influence of morphological preprocessing and
morphosyntactic feature selection on parsing perfor-
2This work was partly financed by the EU FP7 STREP
project XLike (FP7-288342).
22
mance. We aim to use this first inquiry as a decision
point regarding further advancements in resource in-
terchangeability in terms of, e.g., annotation projec-
tion (Yarowsky et al, 2001) and domain adaptation
(S?gaard, 2013). Availability is highly emphasized,
as we provide our resources and models to the public
under the CC-BY-SA-3.0 license.3 We stress the es-
sential role of free culture licensing in enabling and
maturing NLP for under-resourced languages.
In the following section, we give an overview of
related work in computational processing of Croat-
ian and Serbian morphology and syntax. Further, we
define the experiment objectives and describe the re-
sources and experiment workflow. We elaborate on
the obtained results and conclude by sketching pos-
sible future research plans.
2 Related work
Two overviews of current state of language technol-
ogy development have appeared just recently for the
two languages we investigate in this paper.
The Croatian overview (Tadic? et al, 2012) states
that a few underperforming shallow parsing proto-
types for Croatian do exist (Vuc?kovic? et al, 2008),
while deep parsing is left completely unaddressed.
In contrast, it indicates that the more basic re-
sources ? manually annotated corpora, inflectional
lexicons, lemmatizers, morphosyntactic and named
entity taggers ? are of higher quality and availability.
Most of these are available through META-SHARE
(Tadic? and Varadi, 2012). However, in terms of
mandatory preprocessing for dependency parsing, to
the best of our knowledge, the only freely avail-
able and standard-compliant lemmatization, part-of-
speech (POS) or morphosyntactic (MSD) tagging
resources are those by (Agic? et al, 2013).4 Their
elaboration contains a more substantial overview of
preprocessing. Relevant to our research, these mod-
els provide the state of the art in preprocessing for
both Croatian and Serbian.
Croatian Dependency Treebank (HOBS) project
was initiated by (Tadic?, 2007). However, its suffi-
ciency in size increase, followed by the first experi-
ments with dependency parsing of Croatian, did not
appear soon enough to be included in the CoNLL
3http://creativecommons.org/licenses/by-sa/3.0/
4http://nlp.ffzg.hr/resources/models/tagging/
shared tasks and the overview of (Tadic? et al,
2012). Preliminary experiments in transition-based
(Berovic? et al, 2012) and graph-based parsing have
been augmented by a hybrid approach which in-
cluded integrating a graph-based parser (Hall, 2007)
and a valency lexicon (Agic?, 2012). Due to uncov-
ered partial inadequacies of the HOBS formalism
at describing certain syntactic properties of Croa-
tian, a new line of research was initiated, aiming
at creating a more simplistic dependency-based for-
malism for data-driven parsing of Croatian (Agic?
and Merkler, 2013). It provided a new freely avail-
able dependency treebank, the SETIMES.HR Tree-
bank, and derived state-of-the-art dependency pars-
ing models.5 On the downside, SETIMES.HR is a
prototype with currently less than 2 500 sentences
and a documented need for addressing certain an-
notation challenges, such as consistent annotation
of complex predicates, an issue that was previously
observed and partially resolved in HOBS as well
(Berovic? et al, 2012).
The overview of Serbian language technologies
(Vitas et al, 2012) explicitly denotes a satisfac-
tory development level for Serbian preprocessing
based on large electronic dictionaries, manually an-
notated corpora and hand-crafted transducer gram-
mars. These are available through META-SHARE,
even if mostly coupled with restrictive licensing.
Further, the overview lists some preliminary re-
search in shallow syntactic analysis, while it clearly
states that the absence of a formalised syntax of Ser-
bian restricts the development of syntactically anno-
tated corpora and thus hinders the research in full
parsing of Serbian, making the creation of a syntac-
tic formalism for Serbian a very urgent task.
Similar to Croatian, research in Serbian shallow
parsing deals exclusively with the manual design of
rule-based modules (Nenadic?, 2000; Nenadic? et al,
2003; Vitas et al, 2003) in linguistic development
enviroments such as Intex and NooJ (Silberztein,
2004). We also inquired into a case study on the pos-
sibilities of resource transfer from English to Ser-
bian (Martinovic?, 2008), only to conclude that it
does not provide any empirical results. Hence, to
the best of our knowledge, no experiments in de-
pendency treebank construction and data-driven de-
5http://nlp.ffzg.hr/resources/corpora/setimes-hr/
23
pendency parsing ? or, for that matter, any other ap-
proaches to deep syntactic modeling and processing
? currently exist for Serbian.
3 Experiment setup
In this section, we present the experimental setup by
which we aim at subsequently addressing the pre-
viously outlined issues with dependency parsing of
Croatian and Serbian. We define our goals, describe
the utilized resources and lay out the workflow.
3.1 Objectives
We identify the main issues unaddressed by previous
research in Croatian and Serbian syntactic process-
ing and use these to define our research objectives.
They are listed here as follows.
1. No empirical research was conducted in de-
pendency parsing of Serbian. Even if this fact
was justified by the lack of applied research in
creating formalisms targeted exclusively at de-
scribing syntactic properties of Serbian, we fol-
low the underspecification approach that was
successfully implemented in HOBS for Croa-
tian. Namely, as the Prague Dependency Tree-
bank (PDT) formalism for Czech (Bo?hmova?
et al, 2003) was altogether ported to Croatian
by simply using the PDT annotation manual
for annotating Croatian sentences due to mi-
nor differences in syntactic structure between
Croatian and Czech, we reflect this to the
even greater similarity between Croatian and
Serbian on all levels of linguistic description.
Hence, we use Croatian data to parse Serbian
and to serve as a baseline in Serbian parsing.
2. Using Croatian syntactic models for parsing
Serbian text serves to establish the need for ad-
vanced approaches to porting resources among
languages, such as annotation projection.
3. The best dependency parsing models for Croa-
tian are created and tested using a small pro-
totype treebank. SETIMES.HR currently pro-
vides state of the art in Croatian dependency
parsing. To serve our experiment, we enlarge
it by 50% by following the annotation guide-
lines (Merkler et al, 2013) and provide its new
version to the public.
4. Previous experiments were conducted by ten-
fold cross-validation on treebank data. This is
a standard approach to dependency parser eval-
uation, especially in under-resourced environ-
ments. In this setting, observations are posi-
tively biased by text domain and phrase trans-
fer due to randomization. We seek to partially
account for these effects by designing a set of
language- and domain-aware test samples. By
these we also target at establishing the need for
domain adaptation for parsing.
5. No research was done in investigating the ef-
fects of preprocessing and linguistic feature se-
lection to dependency parsing for these lan-
guages. As these are highly inflectional, hav-
ing very large morphosyntactic tagsets, we seek
to inspect the impact of preprocessing choices
on their dependency parsing. There is am-
ple research on the effect preprocessing has
on dependency parsing (Goldberg and Elhadad,
2009; Mohamed, 2011) and on joint morpho-
logical and syntactic processing (Bohnet and
Nivre, 2012), but none of it included any of the
South Slavic languages.
3.2 Workflow
We define three batches of experiments to meet the
research objectives:
1. to select the best Croatian dependency formal-
ism with respect to its overall parsing accuracy
on Croatian and Serbian ? with an emphasis
on the most important syntactic categories that
match across formalisms ? and incidentally to
establish the need for annotation projection,
2. to inspect the impact of state-of-the-art auto-
matic preprocessing on dependency parsing of
both languages and
3. to establish the importance of specific Croat-
ian and Serbian morphosyntactic features of the
most frequent parts of speech in modeling syn-
tactic fenomena for dependency parsing.
In the first batch, we use HOBS in two instances
and SETIMES.HR to create parsing models and test
them on Croatian and Serbian test samples. Draw-
ing from previous research, we use a standard non-
projective graph-based MSTParser generator with
second-order features (McDonald et al, 2006), as
this setting favors Croatian (Agic?, 2012) and re-
24
lated languages such as Czech and Slovene (Buch-
holz and Marsi, 2006). We are aware of the exis-
tence of novel dependency parsers that implement
approaches to handling non-local dependencies and
outperform MSTParser on a set of languages, such
as (Bohnet and Nivre, 2012). They are not included
here due to temporal constraints and the fact that
we were provided with prebuilt MSTParser models
for the HOBS instances and needed to ensure their
comparability with SETIMES.HR. As we mainly
deal with the concept of resource sharing between
closely related languages, we assign a more elabo-
rated parser selection for future research.
For the second batch, we redo the experiments
from the first batch in a realistic scenario regard-
ing preprocessing. We use the publicly available
state-of-the-art tagging and lemmatization models
for Croatian and Serbian (Agic? et al, 2013) instead
of manual annotation to observe the incurred ef-
fects. We do both batches for all three formalisms
(two HOBS instances and SETIMES.HR) and pro-
vide learning curves.
The third batch of experiments deals with ob-
serving the impact of certain morphosyntactic fea-
tures by removing them from training and test data.
We inspect all features involved in subspecification
of adjectives, nouns and verbs in compliance with
the Multext East specification (Erjavec, 2012), i.e.,
MTE v5 as its fifth release.6
In all batches, we observe labeled (LAS) and un-
labeled (UAS) attachment scores. We use approxi-
mate randomization for statistical significance test-
ing where applicable and meaningful.
3.3 Treebanks
Two Croatian dependency treebanks are used in this
experiment: HOBS (Tadic?, 2007) and SETIMES.HR
(Agic? and Merkler, 2013).
HOBS is available in two instances or implemen-
tations. The first one closely follows the PDT anno-
tation guidelines (Bo?hmova? et al, 2003) with several
adaptations of predicate annotation (Berovic? et al,
2012). The second one introduces a set of additional
syntactic tags used for the introduction and subclas-
sification of subordinate clauses. It also alters the
head attachment rules for subordinating conjunc-
6http://nl.ijs.si/ME/V5/msd/html/
Features HOBS HOBS + Sub SETIMES.HR
Sentences 4 626 4 626 3 853
Tokens 117 369 117 369 86 991
Types 25 038 25 038 17 723
Lemmas 12 388 12 388 8 773
MSD tags 914 911 662
Syn. tags 27 (70) 28 (81) 15
Table 1: Basic treebank statistics. Syntactic tag counts
are given for the basic and the full tagset (the latter inside
brackets) for the two HOBS treebanks.
set.test wiki.test
Features hr sr hr sr
Sentences 100 100 100 100
Tokens 2 285 2 308 1 878 1 947
Types 1 265 1 246 1 027 1 055
Lemmas 989 979 803 797
MSD tags
MTE v4 tags 236 237 189 193
MTE v5 tags 233 234 192 195
Syntactic tags
HOBS 22(37) 23(37) 22(41) 22(44)
HOBS + Sub 22(46) 24(49) 23(49) 22(50)
SETIMES.HR 15 15 15 15
Table 2: Basic statistics for the four test sets. Morphosyn-
tactic and syntactic tag counts are given with respect to
the formalism used.
tions. This addition enabled consistency in predicate
annotation in clauses and an increase in dependency
parsing accuracy (Agic? and Merkler, 2013), while
taking a turn away from the PDT guidelines and to-
wards specifics of Croatian syntax. In the paper,
we refer to this instance of HOBS as HOBS + Sub.
Both of them are based on Croatian newspaper text
and manually preprocessed. They implement a mor-
phosyntactic tagset based on, but slightly deviated
from MTE v4 (Erjavec, 2012). HOBS is available
from META-SHARE for research purposes, but its
syntactic tags are stripped from this version. HOBS
+ Sub is not publicly available. Both have been
made available to us in whole for conducting this
experiment, along with prebuilt MSTParser models
compatible with our experimental settings.
SETIMES.HR is based on Croatian newspaper text
25
from the SETimes parallel corpus.7 It implements a
simplistic new formalism (Merkler et al, 2013) tar-
geting and reaching increased dependency parsing
performance while maintaining the information on
the main syntactic categories and compliance with
the general guidelines for HOBS for these categories
(Agic? and Merkler, 2013). It is also manually pre-
processed, but using the newer MTE v5 morphosyn-
tactic tagset. SETIMES.HR is fully compliant with
this tagset. As mentioned, it is freely available for all
purposes. With this in mind, following the annota-
tion guidelines, we have expanded its 2 500 sentence
prototype by introducing 1 365 new sentences.
Treebank statistics are given in Table 1. HOBS
treebanks are larger than SETIMES.HR by approxi-
mately 800 sentences, i.e., 30 thousand tokens (30
kw). The morphosyntactic tagsets also differ, favor-
ing SETIMES.HR and MTE v5 by 250 tags if we are
to consider the smaller tagset as better in terms of
the expressivity vs. preprocessing accuracy balanc-
ing. Syntactic tagset of SETIMES.HR has only 15
tags. Tag counts for HOBS treebanks are given by
two figures: the first one represents the basic tagset,
while the second one includes the subclassification
tags. For example, a coordinated predicate is anno-
tated as Pred using the basic tagset and as Pred Co
in the full tagset. Here, we use only the basic tagset.
As we anticipated given the properties of Croat-
ian syntax, non-projectivity is amply present in both
treebanks. Approximately 2% of all dependency re-
lations and more than 20% of all sentences are non-
projective, supporting our parser selection.
As the three treebanks ? HOBS, HOBS + Sub and
SETIMES.HR? formally do implement different ap-
proaches to syntactic modeling, issues may be raised
regarding the comparability of dependency parsing
scores. However, since HOBS and HOBS + Sub are
both based on the PDT formalism and SETIMES.HR
implements a simplistic formalism that is still based
on the PDT and HOBS annotation guidelines and
syntactic tagset reduction (Merkler et al, 2013), we
consider the comparison to be valid. Moreover, all
three formalisms encode the main Croatian syntactic
categories by closely following the general guide-
lines for describing the Croatian syntax (Silic? and
Pranjkovic?, 2005), thus indicating that comparisons
7http://opus.lingfil.uu.se/SETIMES2.php
for the main syntactic categories ? such as predi-
cates, subjects, objects, prepositional and adverbial
phrases ? should hold true for the task of depen-
dency parsing irregardless of the formal differences
between the models.
3.4 Test sets
The publicly available test sets are obtained from an
experiment in lemmatization and tagging of Croat-
ian and Serbian (Agic? et al, 2013). They were avail-
able in MTE v4 and v5. As HOBS uses the former
and SETIMES.HR the latter tagset, they were well-
suited for our experiment. We syntactically anno-
tated the test sets threefold, i.e., by using the HOBS,
HOBS + Sub and SETIMES.HR formalisms. There
are four test samples: Croatian and Serbian paral-
lel sentences from newspaper sources (set.test) and
Wikipedia (wiki.test). Their suitability for testing
models on closely related languages was thoroughly
elaborated by (Agic? et al, 2013), where their dif-
ferences were measured by using inflectional lexi-
cons of Croatian and Serbian and were found to be
significant in supporting the difference between the
languages. Namely, lexical coverage differed by ap-
proximately 10 percentage points in favor of Croat-
ian across the two domains.
Statistics for the test set are given in Table 2. Each
sample has 100 sentences or approximately 2 000
tokens. Slight variations in token, type and lemma
counts are present and reflect the domain differ-
ences. MSD tag and syntactic tag counts reflect the
respective formalisms, as not all HOBS and HOBS
+ Sub syntactic tags are utilized, while all 15 SE-
TIMES.HR tags are present in all the samples. HOBS
tag counts are once again given separately for the
basic and the full tagset, while only the basic subset
was used in the experiment.
Inter-annotator agreement for HOBS, HOBS +
Sub and SETIMES.HR is investigated in (Agic? and
Merkler, 2013). It favors SETIMES.HR over HOBS
+ Sub and HOBS + Sub over HOBS with a statis-
tically significant difference. The CoNLL shared
tasks in dependency parsing (Buchholz and Marsi,
2006; Nivre et al, 2007) used test sets of approx-
imately 5 000 tokens. This may raise an issue re-
garding the relatively small size of our domain test
samples. However, in the experiment, we combine
the test sets by domain and by language and also
26
set.test wiki.test
LAS hr sr hr sr overall
HOBS 59.9 58.7 55.5 55.4 57.6
HOBS + Sub 68.3 66.9 62.4 62.7 65.3
SETIMES.HR 76.7 75.4 71.9 72.4 74.3
UAS
HOBS 73.7 75.9 72.3 72.6 73.8
HOBS + Sub 78.1 79.0 76.5 76.5 77.6
SETIMES.HR 81.6 80.6 80.0 80.6 80.8
Table 3: Parsing accuracy (LAS, UAS) with manual pre-
processing. Results are given for each test set and overall,
i.e., with all four test sets merged into one.
merge them into a single test set, thus accounting
for the size of the individual samples.
3.5 Parser setup
Here we use MSTParser with the non-projective
maximum spanning tree parsing algorithm and sec-
ond order features (decode-type:non-proj
order:2 training-k:5 iters:10), as it
was previously established as the optimal set-
ting for parsing Croatian using MSTParser (Agic?,
2012) with a statistically significant margin over
the transition-based approach. In training and test-
ing, we separate the MTE v5 MSD tags into POS
(CPOSTAG) and full MSD (POSTAG). We do not
separate the MSD tags into atomic features, i.e., we
do not utilize the FEATS column of the CoNLL-X
format. Thus the MSD tags themselves are consid-
ered as atomic features in the experiment, both for
the full MTE v5 tagset and its reductions.
4 Results and discussion
Here we report and discuss the obtained results. We
discuss the results in batches, as in the experiment
workflow description. In addition, we give a brief
linguistic analysis of the parsing errors considering
the difference between the two languages and the
fact that Croatian models were used for parsing both
Croatian and Serbian text.
4.1 Formalism selection
In the first experiment batch, we trained the parsing
models using three treebanks, HOBS, HOBS + Sub
and SETIMES.HR, and tested them on our Croatian
and Serbian test sets from Wikipedia and newspa-
per text. We present the overall scores in Table 3,
the learning curves are plotted in the first diagram
of Figure 1 and the accuracy for selected syntactic
categories are given in Table 4.
Regarding the formalism selection process, in-
specting the overall observed LAS and UAS, it is
evident that models based on SETIMES.HR outper-
form HOBS-based models by a large margin. They
outperform HOBS + Sub by approximately 9 LAS
and 3 UAS points, while their overall advantage is
even more substantial in comparison with the scores
of basic HOBS models ? approximately 17 LAS
and 7 UAS points. Benefits of explicit annotation
of predicates by introducing tags for subordinating
syntactic conjunctions are also evident as HOBS
+ Sub parsers outperform HOBS by 8 LAS and 4
UAS points. These observations maintain the con-
clusions about the three formalisms given in previ-
ous research (Agic? and Merkler, 2013).8 Moreover,
the introduction of a held-out test set further steep-
ens these differences, as the previous tests were per-
formed by tenfold cross-validation using treebank
data only. The observed differences in overall LAS
and UAS scores are shown to be significant by the
approximate randomization test (p < 0.01).9
As stated in the presentation of treebanks in the
previous section, since the three formalisms are
closely related to one another and to the general
guidelines for describing the properties of Croatian
dependency syntax, we find this comparison to hold
true regardless of the formal differences between
the models. Moreover, since the accuracy for the
PDT-based formalisms in this and previous experi-
ments with Croatian dependency parsing (Agic? and
Merkler, 2013) is below the margins set by similar
languages such as Czech and Slovene (Buchholz and
8Importance of standard compliance should be noted regard-
ing the morphosyntactic tagset impact on the observed results.
Namely, HOBS ?slightly deviates? from MTE v4 by design,
while still claiming de facto compliance. As the test sets fully
comply with MTE v4 and v5, this has an effect on parsing.
9We test by randomly (prob = 0.5) inserting alternate syn-
tactic annotations for entire test set sentences and evaluating
with respect to annotation style, i.e., selecting to match the sen-
tence annotations against HOBS, HOBS + Sub or SETIMES.HR
layer in the gold standard annotation.
27
Figure 1: Labeled attachment learning curves for the three treebanks using gold standard and automatic lemmatization
and morphosyntactic tagging
Marsi, 2006)10, we argue that HOBS requires thor-
ough further revision if it is to be the Croatian coun-
terpart of PDT in terms of expressivity and usability
in research and practical applications. This is further
supported by the data in Table 4, where the assign-
ment of specific syntactic tags is explored. However,
extrinsic evaluation would also be beneficial.
The differences in LAS and UAS scores between
the two languages are virtually non-existent across
formalisms and domains. The parsing models fa-
vor Croatian newspaper text by less than 2 LAS
points for all three formalisms, while UAS is ap-
proximately 1 UAS point higher in Serbian newspa-
per text for HOBS and HOBS + Sub, in contrast with
SETIMES.HR, which scores 1 UAS point higher for
the Croatian sample. In the Wikipedia samples, LAS
and UAS may be approximated as identical. In total,
as a top-performer, the SETIMES.HR model scored
74.5 LAS and 80.9 UAS on Croatian samples and
74.1 LAS and 80.6 UAS on Serbian samples. We be-
lieve this indicates that the parsing models trained on
Croatian treebank data can be used reliably for both
Croatian and Serbian text. We also use these figures
to imply no need for syntactic annotation projection
between Croatian and Serbian in this test scenario.
The cross-domain differences in LAS and UAS
are, in contrast with the cross-language differences,
10This holds even with the Slovene treebank of the CoNLL
2006 shared task having more than 2 000 sentences less than
HOBS, with both using the PDT formalism
much more substantial. As all treebanks were built
on top of Croatian newspaper text, scores are ex-
pectedly higher for these test samples in comparison
with the Wikipedia samples? scores. This difference
amounts to approximately 5 LAS points and 2 UAS
points in favor of the newspaper text samples across
the two languages and three formalisms.
We plotted the LAS learning curves by merging
the test samples into a single mixed-language test
set, incrementally creating 8 parsing models per for-
malism (12.5% to 100% of full size) and testing
them on this merged test set. The left plot of Figure 1
represents the learning curves for the three treebanks
peaking at previously discussed scores from Table 3.
The curves clearly reflect the overall differences in
scores. Their rate of increase is consistently com-
parable, with the overall difference in favor of SE-
TIMES.HR due to its smaller yet still informative
syntactic tagset and its formalism better suited for
Croatian syntax. With this fact now once again
empirically supported, we select the top-performing
SETIMES.HR parsing model for further inspection.
Thus, our further discussion deals exclusively with
parsing using SETIMES.HR.
First we observe parsing accuracy regarding syn-
tactic categories, where we still do compare SE-
TIMES.HR with HOBS + Sub as a final reference
point. We merged our test sets by language to pro-
vide Croatian and Serbian cross-domain test sam-
ples and calculate the LAS per syntactic category for
28
HOBS + Sub SETIMES.HR
Syntactic tag hr sr hr sr
Adverb 50.4 46.6 50.4 47.2
Attribute 81.4 82.3 87.9 88.4
Object 56.4 51.3 68.9 70.2
Predicate 75.1 71.9 80.7 81.2
Preposition 65.5 66.4 66.4 64.0
Subject 70.3 71.3 74.8 77.6
Table 4: LAS for main syntactic tags separated for Croat-
ian and Serbian test set. Manual preprocessing was used.
Best scores are boldfaced and split by language.
set.test wiki.test
MTE v4 hr sr hr sr overall
Lemma 96.1 94.6 93.9 95.8 95.1
POS 95.2 92.3 91.5 90.8 92.5
MSD 86.2 83.4 80.2 81.8 83.1
MTE v5
Lemma 95.6 94.2 94.3 96.1 95.1
POS 96.4 93.0 92.2 91.8 93.5
MSD 86.7 84.4 80.5 82.4 83.7
Table 5: Lemmatization, POS and MSD tagging accuracy
on the test sets and overall. Scores are given separately
for the two morphosyntactic tagsets used.
the two languages. This data is presented in Table 4.
Once again, the language variety is seen to be of no
significance to the parsing models. The scores ac-
tually alternate in favoring the two languages. SE-
TIMES.HR substantially outperforms HOBS + Sub
on the most frequent and arguably the most infor-
mative categories, such as predicate and subject (at
least 5 LAS points), object (almost 20 LAS points)
and attribute (6 points LAS).
4.2 Preprocessing and features
Here we discuss the impact of automatic preprocess-
ing, i.e., lemmatization and MSD tagging on depen-
dency parsing in our test framework. As announced,
this discussion deals exclusively with SETIMES.HR.
We lemmatize and tag the test samples by using
freely available state-of-the-art models for Croatian
and Serbian (Agic? et al, 2013), parse them using
our best SETIMES.HR model and observe LAS and
UAS. Preprocessing performance is given in Table 5
set.test wiki.test
LAS hr sr hr sr overall
HOBS 57.2 55.9 49.9 51.0 53.8
HOBS + Sub 65.2 62.5 56.7 58.0 60.9
SETIMES.HR 73.4 70.4 65.3 67.4 69.4
UAS
HOBS 71.6 71.8 67.4 69.0 70.1
HOBS + Sub 76.2 74.4 71.8 72.5 73.9
SETIMES.HR 79.4 76.9 75.2 77.8 77.4
Table 6: Parsing accuracy (LAS, UAS) with automatic
preprocessing
as a reference point while, more importantly, the de-
pendency parsing scores are given in Table 6. The
second plot of Figure 1 provides the learning curves
for the automatically preprocessed test sets.
Table 6 scores are easily elaborated using the pre-
viously discussed scores with manual, i.e., gold or
perfect preprocessing. Namely, the impact of differ-
ences between manual and automatic preprocessing
on parsing quality basically amounts to a very sim-
ple formula: LAS is reduced by 3-4 points and UAS
by 2 points when introducing preprocessing noise
by automatic lemmatization and tagging. This ob-
servation is valid across the languages and domains
of our test set and thus applies generally. Keeping
in mind the more complex prospective NLP systems
for Croatian and Serbian, we consider this fact to
be very favorable as the observed 16% error rate in
full MSD tagging, 5-6% for POS and lemmatization,
amounts for a significantly smaller decrease in pars-
ing quality as quantified by LAS and UAS.
To further support this observation, we conducted
an experiment with purposely corrupting lemmatiza-
tion and tagging. In this, as previously for learning
curves, we use the single merged test sample. For
lemmatization, we randomly drop lemmas from the
manually annotated test sample, replacing them with
empty features.11 For MSD tagging, we implement
two procedures. The first is identical with the one for
lemmatization, while in the second we replace the
valid tag with a randomly selected Croatian tag from
the full MTE v5 morphosyntactic tagset. For each
11In terms of the CoNLL-X format, we simply replace the
valid entry from the LEMMA field by an underscore.
29
Croatian Serbian
Features LAS UAS LAS UAS
Adjective
Type 74.3 80.7 74.6 81.2
Degree 74.3 80.7 73.7 80.2
Gender 74.1 80.7 74.5 81.0
Number 74.5 81.0 74.3 80.8
Case 75.0 81.5 74.4 81.1
Noun
Type 74.3 80.8 72.9 80.0
Gender 74.4 80.8 74.1 80.7
Number 74.1 80.7 74.0 80.7
Case 73.3 81.0 72.3 80.0
Verb
Type 74.6 81.3 74.3 80.8
Form 74.3 80.9 74.3 81.0
Person 74.3 81.0 73.5 80.0
Number 74.4 80.8 74.1 80.6
Gender 74.4 80.8 74.4 81.0
Full feature set 74.5 80.9 74.1 80.6
Table 7: Impact of morphosyntactic feature exclusion on
parsing. Improvements boldfaced and split by language.
of these scenarios, we provide 11 test sets: step-
ping by 10% of removals or random insertions, from
0% to 100% preprocessing accuracy. The results
are plotted in Figure 2. Evidently, lemmatization
is of no influence to dependency parsing using our
model. This is an important observation to consider
in, e.g., the future tasks of parsing large web cor-
pora of Croatian and Serbian. The large impact of
morphosyntactic tagging, i.e., morphosyntactic fea-
tures on parsing is also evident from the figure. It
is also supported by previous research in parsing us-
ing SETIMES.HR (Agic? and Merkler, 2013), where
a significant bias towards MSD-based parsing mod-
els was found over the POS-only-based models. Tag
removal and tag randomization appear to induce a
very similar effect of near-linear functional depen-
dency between tagging and parsing. We note that
this is not entirely supported by our realistic prepro-
cessing test scenario. It is purely due to the fact that
our noise introduction procedure does not relate to
the modus in which the stochastic tagger errs in pro-
cessing unseen text. Namely, MSD tagging errors
Figure 2: Overall SETIMES.HR parsing accuracy in rela-
tion with lemmatization and morphosyntactic tagging
tend to occur on certain morphosyntactic features,
corrupting these much more often than entire tags.
Thus, even when it yields a feature error, the tagger
still provides the parser with other valid features to
work with. This consideration of MSD features, in
pair with the following set of results, sketches our
plans for further research.
Following the previous note on MSD tagset and
features, we also implemented a simple experiment
in feature weight assessment. In it, we used the SE-
TIMES.HR treebank with full MTE v5 tagset and
created from it several instances, each with its own
reduced MTE v5 tagset. Each reduction was de-
fined by dropping one MSD feature from one part
of speech. More precisely, we dropped all MSD
features of adjectives (5 features), nouns (4) and
verbs (5). This amounted at 14 different MTE v5
reductions. We trained 14 parsing models using SE-
TIMES.HR with the reduced tagsets and tested them
on the test samples merged by language and imple-
menting the respective tagset reductions.
The results are given in Table 7. Most notably,
we observed an increase in parsing accuracy when
dropping adjective case and verb type. The most
substantial decrease occurred with the removal of
noun case, indicating the importance of this feature
in parsing the two languages. We consider the ad-
jective case removal gain an important observation
for future work, as adjectives are the most difficultly
30
Adv Ap Atr Atv Aux Co Elp Obj Oth Pnom Pred Prep Punc Sb Sub
Adv 0 15 1 0 2 2 5 13 2 1 3 0 2 2
Ap 1 10 0 0 0 2 3 0 1 0 0 0 5 0
Atr 23 9 6 1 0 14 23 3 3 3 0 0 25 2
Atv 0 1 6 0 0 0 0 0 1 26 0 0 1 0
Aux 0 0 0 0 1 0 0 0 0 28 0 0 0 1
Co 0 0 1 0 0 0 0 5 0 0 2 11 0 0
Elp 1 2 12 0 0 0 0 4 3 2 0 0 4 0
Obj 6 3 16 3 0 0 1 0 1 1 0 0 2 0
Oth 14 4 3 0 0 12 1 1 0 0 1 0 1 24
Pnom 3 0 8 0 0 0 3 0 0 24 1 0 3 0
Pred 1 0 2 5 26 0 0 1 1 23 0 0 0 0
Prep 1 0 0 0 1 1 0 0 2 0 0 0 0 0
Punc 0 0 0 0 0 17 0 0 0 0 0 0 1 1
Sb 2 11 26 1 0 0 5 1 4 4 1 0 0 1
Sub 1 0 0 0 0 0 0 0 2 0 0 0 0 0
Table 8: Confusion matrices for LAS (Croatian: bottom left, Serbian: top right)
tagged category for Croatian and Serbian.
4.3 Error analysis
Here we provide a brief insight to the error instances.
We discuss LAS errors for both languages, i.e., in-
stances of invalid head attachments paired with tag
misassignments. These are given in Table 8 in the
form of two confusion matrices for LAS.
We isolate several clusters of errors with shared
linguistic properties. Firstly, the subject-attribute-
apposition group (Sb-Atr-Ap), in which we find
the error instances to be closely related to the or-
der of attachment and assignment in multi-word
units representing foreign personal names, titles or
functions and occupations of persons. Next, the
attribute-adverb-object group (Atr-Adv-Obj) expect-
edly appears as these are inherently ambiguous cat-
egories.12 The predicate-nominal-auxiliary group of
errors (Pred-Pnom-Aux) reflects the interaction of
MSD annotation choices and syntactic annotation
principles, as participes are MSD-tagged as adjec-
tives, thus confusing the parser in predicate annota-
tion. Moreover, SETIMES.HR has documented is-
sues with consistency in complex predicate anno-
tation that seek resolution and negatively influence
the parsing scores. Lastly, the only error group sub-
stantially reflecting the language difference is the
one involving predicates and predicate complements
(Pred-Atv), as it appears only in the Serbian confu-
sions. Namely, the infinitive predicate complement
is frequent in Croatian and non-existent in Serbian.
Infinitives in Serbian only appear for the future tense
paired with auxiliary verbs, confusing the parser to
12PDT, e.g., has an AtrAdv, AdvAtr, AtrObj and ObjAtr am-
biguity classes to address this. However, the sum of their fre-
quencies in HOBS is negligibly small (< 0.03%).
annotate these infinitives as predicate complements
as observed in the Croatian training data.
5 Conclusions and future work
We have described an experiment with dependency
parsing of two closely related and under-resourced
languages, Croatian and Serbian, by using parsing
models trained on Croatian treebanks. We investi-
gated three different parsing formalisms, the effects
of lemmatization, morphosyntactic tagging and fea-
ture selection on parsing quality for both languages.
We observed state-of-the-art parsing scores. All re-
sources used in the experiment are made publicly
available under a permissive license.13
The results of this experiment sketch the path for
our future research. Experiments with syntactic pro-
jection between Croatian and Serbian are not feasi-
ble given the negligible differences in the observed
scores. In contrast, domain adaptation for pars-
ing the two languages should be investigated given
the observed accuracy decrease when moving from
newspaper text to Wikipedia. We have already initi-
ated further enlargements of the SETIMES.HR tree-
bank and the test sets with Croatian data from other
domains. Experiments with newer and more ad-
vanced dependency parsers (Koo and Collins, 2010;
Bohnet and Nivre, 2012; Zhang and McDonald,
2012; Martins et al, 2013) should be conducted to
provide up-to-date scores.
We are currently experimenting with morphosyn-
tactic tagset design for improved dependency pars-
ing of Croatian and Serbian. We aim at finding the
optimal tagset by closely investigating morphosyn-
tactic feature influences and dependencies.
13http://nlp.ffzg.hr/
31
References
Z?. Agic?. 2012. K-Best Spanning Tree Dependency Pars-
ing With Verb Valency Lexicon Reranking. In: Pro-
ceedings of COLING 2012: Posters, pp. 1?12. COL-
ING 2012 Organizing Committee.
Z?. Agic?, D. Merkler. 2013. Three Syntactic Formalisms
for Data-Driven Dependency Parsing of Croatian. In:
Text, Speech and Dialogue. Lecture Notes in Computer
Science, 8082:560?567. Springer.
Z?. Agic?, N. Ljubes?ic?, D. Merkler. 2013. Lemmatization
and Morphosyntactic Tagging of Croatian and Serbian.
In: Proceedings of BSNLP 2013. ACL.
B. Bekavac, S. Seljan, I. Simeon. 2008. Corpus-Based
Comparison of Contemporary Croatian, Serbian and
Bosnian. In: Proceedings of FASSBL 2008, pp. 33?39.
Croatian Language Technologies Society.
D. Berovic?, Z?. Agic?, M. Tadic?. 2012. Croatian Depen-
dency Treebank: Recent Development and Initial Ex-
periments. In: Proceedings of LREC 2012, pp. 1902?
1906. ELRA.
A. Bo?hmova?, J. Hajic?, E. Hajic?ova, B. Hladka?. 2003.
The Prague Dependency Treebank: A Three-Level
Annotation Scenario. In: Treebanks: Building and Us-
ing Parsed Corpora. Springer.
B. Bohnet, J. Nivre. 2012. A Transition-Based System
for Joint Part-of-Speech Tagging and Labeled Non-
Projective Dependency Parsing. In: Proceedings of
EMNLP-CoNLL 2012, pp. 1455?1465. ACL.
S. Buchholz, E. Marsi. 2006. CoNLL-X Shared Task on
Multilingual Dependency Parsing. In: Proceedings of
CoNLL-X, pp. 149?164. ACL.
T. Erjavec. 2012. MULTEXT-East: Morphosyntac-
tic Resources for Central and Eastern European Lan-
guages. Language Resources and Evaluation, 46 (1),
131?142. Springer.
Y. Goldberg, M. Elhadad. 2009. Hebrew Dependency
Parsing: Initial Results. In: Proceedings of IWPT
2009, pp. 129?133. ACL.
K. Hall. 2007. K-Best Spanning Tree Parsing. In: Pro-
ceedings of ACL 2007, pp. 392?399. ACL.
T. Koo, M. Collins. 2010. Efficient Third-Order De-
pendency Parsers. In: Proceedings of ACL 2010, pp.
1?11. ACL.
M. Martinovic?. 2008. Transfer Of Natural Lan-
guage Processing Technology: Experiments, Possibil-
ities and Limitations ? Case Study: English to Serbian.
Infotheca ? Journal of Informatics and Librarianship,
9 (1-2):11?20.
A. Martins, M. Almeida, N. Smith. 2013. Turning
on the Turbo: Fast Third-Order Non-Projective Turbo
Parsers. In: Proceedings of ACL 2013. ACL.
R. McDonald, K. Lerman, F. Pereira. 2006. Multilingual
Dependency Parsing With a Two-Stage Discriminative
Parser. In: Proceedings of CoNLL-X, pp. 216?220.
ACL.
D. Merkler, Z?. Agic?, A. Agic?. 2013. Babel Treebank of
Public Messages in Croatian. In: Proceedings of CILC
2013. Proceedia ? Social and Behavioral Sciences, in
press. Elsevier.
E. Mohamed. 2011. The Effect of Automatic Tok-
enization, Vocalization, Stemming, and POS Tagging
on Arabic Dependency Parsing. In: Proceedings of
CoNLL 2011, pp. 10?18. ACL.
G. Nenadic?. 2000. Local Grammars and Parsing Coor-
dination of Nouns in Serbo-Croatian. In: Text, Speech
and Dialogue. Lecture Notes in Computer Science,
1902:57?62. Springer.
G. Nenadic?, I. Spasic?, S. Ananiadou. 2003. Morphosyn-
tactic Clues for Terminological Processing in Serbian.
In: Proceedings of the EACL Workshop on Morpho-
logical Processing of Slavic Languages, pp. 79?86.
ACL.
J. Nivre, J. Hall, S. Ku?bler, R. McDonald, J. Nils-
son, S. Riedel, D. Yuret. The CoNLL 2007 Shared
Task on Dependency Parsing. In: Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007,
pp. 915?932. ACL.
M. Silberztein. 2004. NooJ : An Object-Oriented Ap-
proach. In: INTEX pour la Linguistique et le Traite-
ment Automatique des Langue, pp. 359?369. Presses
Universitaires de Franche-Comte?.
J. Silic?, I. Pranjkovic?. 2005. Gramatika hrvatskoga
jezika za gimnazije i visoka uc?ilis?ta. S?kolska knjiga,
Zagreb.
A. S?gaard. 2013. Semi-Supervised Learning and Do-
main Adaptation for NLP. Morgan & Claypool Pub-
lishers.
Z?. Stanojc?ic?, Lj. Popovic?. 2008. Gramatika srp-
skog jezika: za gimnazije i srednje s?kole. Zavod za
udz?benike i nastavna sredstva, Beograd.
M. Tadic?. 2007. Building the Croatian Dependency
Treebank: The Initial Stages. Suvremena lingvistika,
63 (1), 85?92. Hrvatsko filolos?ko drus?tvo.
M. Tadic?, D. Brozovic?-Ronc?evic?, A. Kapetanovic?. 2012.
The Croatian Language in the Digital Age. META-
NET White Paper Series. Springer.
M. Tadic?, T. Va?radi. 2012. Central and South-East Euro-
pean Resources in META-SHARE. In: Proceedings of
COLING 2012: Demonstration Papers, pp. 431?438.
COLING 2012 Organizing Committee.
D. Vitas, C. Krstev, I. Obradovic?, Lj. Popovic?, G.
Pavlovic?-Laz?etic?. 2003. An Overview of Resources
and Basic Tools for Processing of Serbian Written
Texts. In: Proceedings of the Workshop on Balkan
Language Resources, First Balkan Conference in In-
formatics.
32
D. Vitas, Lj. Popovic?, C. Krstev, I. Obradovic?, G.
Pavlovic?-Laz?etic?, M. Stanojevic?. 2012. The Serbian
Language in the Digital Age. META-NET White Pa-
per Series. Springer.
K. Vuc?kovic?, M. Tadic?, Z. Dovedan. 2008. Rule-Based
Chunker for Croatian. In: Proceedings of LREC 2008,
pp. 2544?2549. ELRA.
D. Yarowsky, G. Ngai, Richard Wicentowski. 2001. In-
ducing Multilingual Text Analysis Tools via Robust
Projection Across Aligned Corpora. In: Proceedings
of HLT 2001, pp. 1?8. ACL.
H. Zhang, R. McDonald. 2012. Generalized Higher-
Order Dependency Parsing With Cube Pruning. In:
Proceedings of EMNLP 2012. ACL.
33
