Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 20?29,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
?Love ya, jerkface?: using Sparse Log-Linear Models to Build
Positive (and Impolite) Relationships with Teens
William Yang Wang, Samantha Finkelstein, Amy Ogan, Alan W Black, Justine Cassell
School of Computer Science, Carnegie Mellon University
{yww, slfink, aeo, awb, justine}@cs.cmu.edu
Abstract
One challenge of implementing spoken di-
alogue systems for long-term interaction is
how to adapt the dialogue as user and sys-
tem become more familiar. We believe this
challenge includes evoking and signaling as-
pects of long-term relationships such as rap-
port. For tutoring systems, this may addi-
tionally require knowing how relationships are
signaled among non-adult users. We therefore
investigate conversational strategies used by
teenagers in peer tutoring dialogues, and how
these strategies function differently among
friends or strangers. In particular, we use an-
notated and automatically extracted linguis-
tic devices to predict impoliteness and posi-
tivity in the next turn. To take into account
the sparse nature of these features in real data
we use models including Lasso, ridge estima-
tor, and elastic net. We evaluate the predictive
power of our models under various settings,
and compare our sparse models with stan-
dard non-sparse solutions. Our experiments
demonstrate that our models are more ac-
curate than non-sparse models quantitatively,
and that teens use unexpected kinds of lan-
guage to do relationship work such as signal-
ing rapport, but friends and strangers, tutors
and tutees, carry out this work in quite differ-
ent ways from one another.
1 Introduction and Related Work
Rapport, the harmonious synchrony between in-
terlocutors, has numerous benefits for a range of
dialogue types, including direction giving (Cas-
sell et al, 2007) or contributing to patient recov-
ery (Vowles and Thompson, 2012). In peer tutor-
ing, an educational paradigm in which students of
similar ability tutor one another, friendship among
tutors and tutees leads to better learning (Gartner et
al., 1971). With the burgeoning use of spoken dia-
logue systems in education, understanding the pro-
cess by which two humans build and signal rapport
during learning becomes a vital step for implement-
ing spoken dialogue systems (SDSs) that can initi-
ate (and, as importantly, maintain) a successful re-
lationship with students over time. However, im-
plementing a tutorial dialogue system that appropri-
ately challenges students in the way that peers do
so well (Sharpley et al, 1983), while still demon-
strating the rapport that peers can also provide, calls
for understanding the differences in communication
between peer tutors just meeting and those who are
already friends.
The Tickle-Degnen and Rosenthal (1990) model
provides a starting point by outlining the compo-
nents of rapport, including the finding that positiv-
ity decreases over the course of a relationship. The
popularity of this model, however, has not dimin-
ished the disproportionate attention that positivity
and politeness receive in analyses of rapport (Brown
and Levinson, 1978), including in the vast majority
of computational approaches to rapport-building in
dialogue (Stronks et al, 2002; Johnson and Rizzo,
2004; Bickmore and Picard, 2005; Gratch et al,
2006; McLaren et al, 2007; Cassell et al, 2007;
Baker et al, 2008; Bickmore et al, 2011). The
creation and expression of rapport is complex, and
can also be signaled through negative, or impolite,
exchanges (Straehle, 1993; Watts, 2003; Spencer-
Oatey, 2008) that communicate affection and re-
lationship security among intimates who can flout
common social norms (Culpeper, 2011; Kienpoint-
ner, 1997).
However, it is an open question as to whether such
rudeness is likely to impress a new student on the
first day of class. We must better understand how
and when impoliteness and other negative dialogue
moves can contribute to the development and ex-
pression of the rapport that is so important in educa-
tional relationships. In this analysis, then, we begin
with a corpus of tutoring chat data annotated with
a set of affectively-charged linguistic devices (e.g.
complaining, emoticons), and then differentiate be-
tween the linguistic devices that friend and stranger
interlocutors employ (with friendship standing as a
proxy for pre-existent rapport) and the resulting so-
cial effects or functions of those devices on the part-
ners.
Since our ultimate goal is to build an SDS that
can adapt to the user?s language in real time, we
also automatically extract lexical and syntactic fea-
tures from the conversations. And, in order to deter-
mine what the system should say to evoke particular
20
responses, we predict social effects in partner two
from the use of the linguistic devices in partner one.
Since we want to understand how the system can
deal with newly met peers as well as peers who
have become friends, we develop and evaluate our
model on dyads of friends and then evaluate the
same model with dyads of strangers, to examine
whether dyads with less a priori rapport react dif-
ferently to the same linguistic devices.
Of course, in addition to understanding the phe-
nomenon of rapport in all of its complexity, a major
challenge for building rapport-signaling SDS is to
construct a compact feature space that capture only
reliable rapport signals and generalizes well across
different speakers. Of course phenomena such as in-
sults, complaints and pet names, no matter how im-
portant, appear relatively rarely in data of this sort.
Training discriminative models with maximum like-
lihood estimators (MLE) on such datasets usually re-
sults in assigning too much weight on less frequent
signals. This standard MLE training method not
only produces dense models, but may also overes-
timates lower frequency features that might be unre-
liable signals and overfit to a particular set of speak-
ers. In recent studies on speaker state prediction that
use lexical features, it has been shown that MLE
estimators demonstrate large performance gaps be-
tween non-overlapping speaker datasets (Jeon et al,
2010; Wang et al, 2012a).
On the other hand, recent studies on `1/`2
based group penalty for evaluating dialogue systems
(Gonza?lez-Brenes and Mostow, 2011), structured
sparsity for linguistic structure prediction (Mar-
tins et al, 2011), and discovering historical legal
opinions with a sparse mixed-effects latent vari-
able model (Wang et al, 2012b) have all shown
concrete benefits of modeling sparsity in language-
related predictive tasks. We therefore apply sparsity-
sensitive models that can prevent less frequent
features from overfitting. We start with the `1-
regularized Lasso (Tibshirani, 1994) model, since,
compared to other covariance matrix based sparse
models, such as sparse Principal Component Anal-
ysis (PCA) and sparse Canonical Correlation Anal-
ysis (CCA), the Lasso model is straightforward and
requires fewer computing resources when the fea-
ture dimension is high. Hence, we compare the con-
tributions of both automated features and annotated
features using the proposed Lasso model to predict
impoliteness and positivity.
In addition to Lasso and a logistic regression base-
line, we introduce two alternative penalty models:
the non-sparse ridge (le Cessie and van Houwelin-
gen, 1992) estimator, and an elastic net model (Zou
and Hastie, 2005). The ridge estimator applies a
quadratic penalty for feature selection, resulting in
a smooth objective function and a non-sparse fea-
ture space, which can be seen as a strong non-sparse
penalty model. We investigate the elastic net model,
because it balances the pros and cons of Lasso and
ridge estimators, and enforces composite penalty. In
addition to the model comparisons, by varying the
different sizes of feature windows (number of turns
in the dialogue history), we empirically show that
our proposed sparse log-linear model is flexible, en-
abling the model to capture long-range dependency.
This approach also allows us to extend previous
work on speaker state prediction. Although speaker
state prediction has attracted much attention in the
dialogue research community, most studies have fo-
cused on the analysis of anger, frustration, and other
classic emotions (Litman and Forbes-Riley, 2004;
Liscombe et al, 2005; Devillers and Vidrascu, 2006;
Ai et al, 2006; Grimm et al, 2007; Gupta and Ni-
tendra., 2007; Metallinou et al, 2011). Recently,
Wang and Hirschberg (2011) proposed a hierarchi-
cal model that detects level of interest of speakers
in dialogue, using a multistream prediction feedback
technique. However, to the best of our knowledge,
we are among the first to study the problem of auto-
matic impoliteness and positivity prediction in dia-
logue. Because our ultimate goal is to build an SDS
that responds to users? language use over time, the
features from the user?s target turn that the model is
aiming to predict are not observable, which renders
the task more difficult than previous speaker state
detection tasks.
Our main contributions are three-fold: (1) analy-
sis of linguistic devices that function to signal rap-
port among friends - and their effects on non-friend
dyads; (2) detailed analyses of language behavior
features that predict these rapport behaviors - both
impoliteness and positivity - in the next turn of
teenagers? peer tutoring sessions; (3) an evaluation
of non-sparse and sparse log-linear models for pre-
dicting impoliteness and positivity.
By understanding the signals of rapport that a per-
son is likely to display in response to various lin-
guistic devices, we can begin to build an SDS that
can anticipate the social response and adapt to the
rapport-signaling efforts of its partner, both as a
newly introduced technology, and, over time, as a
system with whom the user has a rapport.
2 The Corpus
We use the data from a previous study evaluating the
impact of a peer tutoring intervention that monitored
students? collaboration and in some cases provided
adaptive support (Walker et al, 2011). In the inter-
vention, peer tutors observed the work of their tutee
21
and supported them through a chat interface as they
completed algebra problems. The system logged all
chat and other information about the problem steps.
Participants were 130 high school students (81 fe-
male) in grades 7-12 from one American high school
with some prior knowledge of the algebra material.
Participants were asked to sign up for the study with
a friend. Those who were interested but were un-
able to participate with a friend, were matched with
another unmatched participant. In an after-school
session, participants first took a 20-minute pre-test
on the math concepts, and then spent 20 minutes
working alone with the computer to prepare for tu-
toring. One student in each dyad was then randomly
assigned the role of tutor, while the other was given
the role of tutee, regardless of relative ability. They
spent the next 60 minutes engaging in tutoring. Fi-
nally, students were given a domain posttest isomor-
phic to the pretest.
54 dyads signed up as friends and 6 were un-
matched strangers. To compare behavior between
friends and strangers in the face of very different
data set sizes we use 48 friend dyads for training,
and select 6 friend and 6 stranger dyads as two sep-
arate test sets. The total number of utterances in the
friend training set, friend test set, and stranger test
set are 4538, 468 and 402. To perform turn-based
prediction experiments, we concatenate the text in
the utterances by the same speaker into a single turn,
and perform an ?OR? operation1 on features (See
Section 3 for details) in multiple utterances of the
same speaker to generate the turn-based binary fea-
tures.
3 Feature Engineering
In this section, we describe both the annotated and
automatically extracted features analyzed.
3.1 Annotated Features and Labels2
To understand what linguistic devices participated in
positivity and impoliteness during tutoring, we an-
notated all 60 dyads for surface-level language be-
haviors such as complaints, challenges (Culpeper,
1996) and praise. We also automatically identi-
fied chat features that socially color the communi-
cation, such as excessive punctuation[P] or capital-
ization[Ca]. Utterances could receive more than one
code, and inter-rater reliability ranged from K=.71
to K=1.
Because these linguistic behaviors may serve a
range of different functions in context, such as rude
1If any of the utterances within one turn has this feature
turned on, then we say that we have observed this feature in
this turn.
2We thank Erin Walker for data collection and annotation.
language serving to cement a relationship (Arding-
ton, 2006), or teasing to increase rapport (Straehle,
1993), we also annotate the social functionality
of each utterance in context, in terms of positivity
(K=.79)3 and impoliteness (K=.76), which are seen
as holding down opposite kinds of social functional-
ity (Terkourafi, 2008). Details of annotation can be
found in our recent work (Ogan et al, 2012).
Language Behavior Features
Language behavior features were annotated by
two raters, based on previous work on impo-
liteness (Culpeper, 1996), positivity (Boyer et
al., 2008), and computer-mediated communica-
tion (Herring and Zelenkauskaite, 2009), as fol-
lows:.
? Insults[Di] (?=1): Personalized negative voca-
tives or references. eg. ?you are so weird.?
? Challenges[Ch] (? =.91): Directly questioning
partner?s decision or ability. eg. Partner 1:
?see I am helping?, Partner 2: ?barely.?
? Condescensions / brags[C] (?=1): Asserting
authority or partner?s inferiority. eg. Tutee:
?nothing you have done has affected me what
so ever.?
? Message enforcer[Ef] (?=.85): Emphasizing
text or attracting partner?s attention. eg. ?Earth
to Erin.?
? Dismissal / Silencer / Curse[Cu] (? =.76): As-
serting unimportance of contribution/partner.
eg. ?shuttttt up computer.?
? Pet name[Pe] (? = .9): Vocatives that may or
may not be insulting. eg. ?whats up homie??
? Criticisms / exclusive complaints[EC] (?=.8):
Negative evaluation of partner. eg. ?You are so
bad at this dude.?
? Inclusive complaints[I] (?=.78): Complaints
directed outside the partner, such as at the task,
computers, or study. eg. ?This is really dumb,
ya think??
? Laughter[L] (?=1): eg. ?haha?, ?lol?
? Off-task[O] (?=.71): Doesn?t pertain to or ad-
vance tutorial dialogue. eg. ?Coming over after
this??
Impoliteness and Positivity Labels
While the surface-level features were coded based
on a single utterance, context determined the labels
for impoliteness and positivity, including the recent
tone of the dialogue and the partner?s response to
the utterance. Utterances were coded as positivity
(?=.79) when they included goals that directly added
positive affect into the exchange through praise, em-
pathy, reassurance, cooperative talk (McLaren et al,
3We use Cohen?s kappa in this study.
22
2011), task enthusiasm, and making or responding
to jokes. Impoliteness (?=.76) included both coop-
eratively rude utterances such as teasing (typical eg.
?hahah you?re the worst tutor ever?) and uncooper-
atively rude utterances that may cause offense (typ-
ical eg. ?um why don?t you try actually explainin
urself..?) (Kienpointner, 1997).
3.2 Automated Features
To compare the performance between what could be
automatically extracted from dialogue and hand an-
notation, we extracted 2,872 unigram and 12,016 bi-
gram features from the text corpus. Using the Stan-
ford PoS tagger4 with its attached model, we also
extracted 46 common part-of-speech tags from the
text. In addition to the above lexical and syntac-
tic features, we automatically extracted the capital-
ization features[Ca] that have at least one full word
(eg. ?CALM DOWN?) (Chovanec, 2009). Since
a recent text prediction task (Wang and McKeown,
2010) observed benefits from modeling punctua-
tion features[P], we extracted the expressive punc-
tuation that included at least one exclamation point
or more than one question-mark (eg. ?I don?t get
it?!??!?) (Crystal, 2001). We used a smiley dictio-
nary5 to extract the emoticons[E] that convey emo-
tional states (Sa?nchez et al, 2006) from text.
4 Sparse Log-Linear Models
We formulate our impoliteness and positivity predic-
tion problems as binary classifications. To do this,
we estimate the label y?t ? Bernoulli(??). First, we
introduce a standard log-linear parametrization6 to
our predictive tasks:
??~yt =
exp
?
i ~wi ~fi(~yt)
1 + exp
?
i ~wi ~fi(~yt)
, (1)
where ~f(~yt) is a set of feature functions computed
on the observation vector ~yt. The term ~wi puts a
weight on feature i for predicting impoliteness, and
our estimation problem is now to set these weights.
The log-likelihood and the gradient are:
` =
?
t
yt log ??~yt + (1? yt) log(1? ??~yt) (2)
?`
? ~w =
?
t
(
???~yt
? ~w
)(
yt
??~yt
? 1? yt
1? ??~yt
)
(3)
???~yt
? ~w =
(
??~yt ? (??~yt)2
)
~f(~yt), (4)
4http://nlp.stanford.edu/software/tagger.shtml
5http://www.techdictionary.com/emoticon.html
6We thank Jacob Eisenstein for the formulation of logistic
regression model.
so the parameters can be set using gradient as-
cent. To control the overall complexity, we can ap-
ply regularized models on the elements of ~w. A
sparsity-inducing model, such as the Lasso (Tibshi-
rani, 1994) or elastic net (Zou and Hastie, 2005)
model, will drive many of these weights to zero, re-
vealing important interactions between the impolite-
ness/positivity label and other features. Instead of
maximizing the log-likelihood, we can minimize the
following Lasso model that consists of the negative
log-likelihood loss function:
min
(
? `+
?
i
?1||~wi||
)
(5)
Since the Lasso penalty can introduce discontinu-
ities to the original convex function, we can also
consider an alternative non-sparse ridge estima-
tor (le Cessie and van Houwelingen, 1992) that has
the convex property:
min
(
? `+
?
i
?2||~wi||2
)
(6)
In addition to the Lasso and ridge estimators, the
composite penalty based elastic net model balances
the sparsity and smoothness properties of both Lasso
and ridge estimators:
min
(
? `+
?
i
?1||wi||+
?
i
?2||wi||2
)
(7)
Our log-linear model is quite flexible; by compar-
ing various restrictions, we can test different features
when modeling impoliteness and positivity. In addi-
tion, the model can incorporate features from previ-
ous time windows, which requires much less compu-
tational complexity compared to standard high order
Markov models. We use the L-BFGS method (Liu
and Nocedal, 1989) for the numerical optimization.
5 Empirical Experiments
We predict impoliteness vs. non-impoliteness and
positivity vs. non-positivity of an interlocutor in the
immediate future turn, given only information from
current/previous turns. Because accuracy, precision,
recall and F-measure are threshold-based point esti-
mation metrics that might prevent one from observ-
ing the big picture of system performance, we con-
sider the Receiver Operating Characteristic (ROC)
metric to evaluate the dynamics of the true posi-
tive rate vs. the false positive rate (Hanley and Mc-
Neil, 1982) in our system. We mainly use Area Un-
der Curve (AUC) as a metric to compare classifiers,
since it maps the ROC metric to a single scalar value
representing expected performance. A random clas-
sifier will have an AUC of 0.5 (Fawcett, 2006).
23
Models P Ca E L O Ef Pe Di C EC Ch Cu I
Impoliteness Prediction
Tr-Te .44 -1.10 .62 .72 .09 .64 .09 1.29 .96 .89 .69 .77 -0.19
Te-Tr -2.48 .54 -0.26 0.15 .59 1.62 .24 .22 .89 .72 .75 .04 -0.18
Positivity Prediction
Tr-Te -0.87 .19 .36 .55 1.06 -0.62 .69 -1.63 -1.57 .16 -0.41 1.22 .86
Te-Tr -1.39 -0.46 .70 .48 .46 .33 .62 -0.71 .70 -0.65 -0.47 -0.54 .78
Table 1: Comparing the Learned Weights of Different Features when Predicting the Partner?s Impoliteness in a Non-
Sparse Log-Linear Model. Tr-Te: predict tutee turn with tutor turn. Te-Tr: predict tutor turn with tutee turn. For full
name of features, see Section 3.
5.1 Comparing the Learned Weights of
Different Features
In our previous analysis of these data (Ogan et al,
2012), a PCA method allowed us to group linguistic
behaviors in order to address the issue of data spar-
sity. With the use of log-linear models, we are able
to investigate the contributions of individual lan-
guage behaviors in one student?s turn to the predic-
tion of social functions in their partner?s next turn. In
this experiment, we evaluate the weights of various
linguistic devices in a standard logistic regression
model. We found that behaviors commonly asso-
ciated with impoliteness were predictors of partner
impoliteness in the next turn, while positive behav-
iors such as laughter were predictors of upcoming
positivity. SDSs can leverage this knowledge to take
the partners lead during a tutoring session, using the
partners positivity or impoliteness to determine the
affect of the systems upcoming move. As we intend
to develop a system that acts as a tutee, however, we
further divided the analysis by tutoring role, inves-
tigating how partners in different roles employ lan-
guage features differently, such that the system can
act in accordance with its given role. Table 1 shows
the results.
Similarly to the collapsed factors in our previous
work, we found here that tutors and tutees do in
fact use language behaviors differently, and to ac-
complish different social functions. Effectively, this
means that certain language behaviors may instigate
impoliteness when said by one partner, but lead to
positivity when expressed by the other. For exam-
ple, tutee bragging predicts a response of positiv-
ity on behalf of the tutor (~w(TE)C = .7), perhaps be-cause the tutor wants to be supportive of a prote?ge??s
self-efficacy and success. Conversely, when the tu-
tor brags during a peer tutoring dialogue, the tu-
tee, who may feel threatened by the tutors bravado,
is extremely likely to respond with impoliteness (
~w(TR)C = .96). In a peer tutoring paradigm, whenthe more powerful partner (the tutor) expresses dom-
inance through self-inflation, the subordinate part-
ner may use impoliteness to regain some social con-
trol. On the other hand, some language behaviors
actively work to tear down this power imbalance,
such as inclusive complaining, where the partners
take an us against the task approach, building sol-
idarity through complaining about the experiment.
These utterances predict positivity whether used by
the tutor ( ~w(TR)I = .86) or tutee ( ~w(TE)I = .78).Other comparisons between weighted features by
role demonstrate similarly theoretically-motivated
findings that shed light on how language is used to
achieve social functions.
5.2 Comparing the Contributions of Different
Features on Friend and Stranger Datasets
A previous study (Ogan et al, 2012) on these same
data seemed to indicate that negative conversational
strategies composed of linguistic devices such as
complaining and insults were correlated with learn-
ing in the friend dyads and negatively correlated
with learning in strangers. However the small num-
ber of stranger dyads prevented them from draw-
ing conclusions about particular linguistic devices
from the data. Here, we empirically show the pre-
dictive performance of different feature sets on both
friend and stranger test sets in Table 2 , using a
sparse Lasso model with features from only the
current turn. In the impoliteness prediction task,
when predicting on the test set that consists of only
friends, we observe statistically significant improve-
ment over a random baseline, using surface-level
language behavior features, lexical, lexical + syn-
tactic, all automatic, and all features. When com-
bining all features, the best AUC is .621. The auto-
matic features, mainly including n-grams and part-
of-speech tags, have emerged as a useful automated
feature space. On the other hand, we do not observe
any significant results on the stranger datasets, sug-
gesting that strangers do not respond with impolite-
ness in the same way that friends do. When pre-
dicting positivity on the friend dataset, we see that
24
the performance of surface-level language behavior
features has dropped from the first task, and the sta-
tistical t-test is non-significant when comparing to
a random baseline. This is not surprising, because
we have shown in the previous section that surface-
level language behavior features are strong indica-
tors of impoliteness, but might not have advantages
in predicting positivity for friends. Interestingly, the
automated features outperform the combination of
all features, indicating a promising future for the ac-
tual deployment of an SDS that can interact using
appropriate positivity and impoliteness.
When predicting positivity in the stranger dataset,
we find the opposite trend. In contrast to the impo-
liteness prediction task, the overall performance on
the stranger dataset improved, and the lexical, lexi-
cal+syntactic, and all feature combination have sig-
nificantly outperformed the chance baseline. These
results suggest that positivity is a predictable behav-
ior among strangers, who may all express uniform
positivity across all dyads, while it is the impolite-
ness that is predictable among friends. Perhaps it
is that through the development of a rapport with a
partner, the particular ways in which positivity is ex-
pressed becomes personalized to the dyad, and can
no longer be applied to other groups who have their
own expressions of positivity. In other words, un-
like in Tolstoy?s world, here unhappy families are all
alike; every happy family is happy in its own way.
We must look to the easily-predictable impoliteness
among friends instead, arguing strongly for the in-
clusion of impoliteness in a model of rapport.
5.3 Comparing Logistic Regression, Lasso,
Ridge, and Elastic Net
While our previous work (Ogan et al, 2012) demon-
strated that PCA is a useful feature selection method
when there are only a dozen features, in this experi-
ment, the dimension of our feature space is substan-
tially higher, which aligns to the size of vocabulary.
Thus, covariance-based feature selection methods,
such as PCA, might be too slow. Here we compare
the performances of standard MLE trained logistic
regression, Lasso, non-sparse ridge, and elastic net
models. In particular, we demonstrate the predic-
tive power of Lasso and elastic net models, varying
distinct levels of sparsity. In the Figure 1, we show
the comparison of three different models in the im-
politeness prediction task. The horizontal axis rep-
resents different values of regularization coefficient
?. For the Lasso model and the elastic net model,
increasing the value ? will result in a sparser feature
space, and we set the ? = ?1 = ?2 in the elastic net
model to promote same level of sparsity and smooth-
ness. The result at ? = 0 represents the standard
Feature Sets F-AUC p S-AUC p
Impoliteness Prediction
Random .500 - .500 -
Behavior .596 .017 .505 .473
Lex .599 .014 .435 .819
Lex + POS .605 .009 .425 .857
All Auto .591 .022 .451 .751
All Features .621 .003 .427 .850
Positivity Prediction
Random .500 - .500 -
Behavior .549 .141 .527 .302
Lex .623 .003 .601 .025
Lex + POS .646 .001 .587 .047
All Auto .651 .001 .577 .070
All Features .641 .001 .608 .019
Table 2: Comparing contributions of different feature
streams on both friend and stranger testsets with Lasso
model when predicting impoliteness and positivity of the
next turn using only features from the current turn. ( F-:
the friend test set. S: the stranger test set. p: one-tailed
p-value by comparing to a random classifier. Behavior:
detailed surface-level language behavior features defined
in Section 3. Lex: unigram and bigram. POS: part-of-
speech features. All Auto: all automatically extracted
features (Lex + POS + punctuation + caps + emoti-
cons).)
non-sparse logistic regression model, which obtains
an AUC of .563. When introducing penalty for large
weights in this standard model, .4 to .5 significant
improvements (p = .003 for Lasso, p = .007 for
ridge, and p = .004 for elastic net) of AUC are
observed from Lasso, ridge and elastic net models
when ? = 1. The elastic net model that balances
sparsity and smoothness, has obtain the best result
in this experiment. The best result of elastic net
model is .63 when ? = 7. This experiment shows
that all three penalty models have outperformed the
non-sparse logistic regression model. The elastic net
model, which balances sparisty and smoothness, ob-
tains the best results when predicting impoliteness.
Figure 2 shows the comparison of three models on
the friend dataset in the positivity prediction task.
When ? = 0, the standard logistic regression model
has an AUC of .638. When increasing the ? to 1,
both Lasso and elastic net models have shown sig-
nificant improvements (both p < .001) in AUC, but
not the non-sparse ridge estimator. The Lasso model
is found to be the best model in this task: we obtain
better results when the model gets sparser until the
model is too sparse when ? = 6. In contrast to the
experiment in Figure 1, we see that both the ridge
and elastic net models do not very strong advantages
25
in this positivity prediction task. We hypothesize
that the reason why Lasso works better in the pos-
itivity task is that the frequency of positivity labels
is substantially higher than the impoliteness labels in
our corpus, so that a Lasso model that enforces full
`1 penalty fits better in this task. In contrast, since
the impoliteness label is less frequent, a denser elas-
tic net composite penalty model that preserve critical
features, works the best in the impoliteness predic-
tion task. In general, we can see that sparse log-
linear models outperform standard log-linear mod-
els as well as non-sparse ridge estimators in the two
tasks.
Figure 1: Comparing Impacts of Different Levels of Spar-
sity on the Friend Dataset When Predicting Impoliteness
with Lasso, Ridge, and Elastic Net Models
Figure 2: Comparing Impacts of Different Levels of Spar-
sity on the Friend Dataset When Predicting Positivity
with Lasso, Ridge, and Elastic Net Models
5.4 Comparing Impacts of Different Feature
Window Sizes
A practical problem for parameter estimation in both
generative and discriminative models for dialogue
processing is to evaluate how much history the sys-
tem should take into account, so that it can have
enough information to make correct predictions. In
this experiment, we investigate the impact of using
different feature window sizes using the elastic net
model. We compare the two-tailed student t-test be-
tween the baseline that only uses features from the
current turn and models that use current + previous
n turn(s). For the friend dataset, when only using
the features from the current turn to predict the im-
politeness in the immediate next turn, we observe
an AUC of .619. The best result is obtained when
we combine the previous two turns together with the
current feature turn: an AUC of .635, significantly
better (p = .03) than only using the current turn win-
dow. The patterns on the non-friend dataset are less
clear, while the model obtains the best result when
window size is +3 previous turns, the improvement
is not significant (p = .962). In the positivity task,
we also observe benefits to incorporating larger fea-
ture windows. The AUC on the friend test set starts
at .638, when only using the current feature window
in the elastic net model. After incorporating larger
feature windows, we obtain the best result of .675 at
the +4 window (p = .04). Similarly, the AUC on
non-friend test set initializes at .618, but climbs to
.632 at the +4 window.
6 Error Analysis and Discussion
We performed an error analysis to understand the
contexts under which our model failed to accurately
predict a students? social response, and discuss the
implications of these examples based on a theoret-
ical understanding of the roles of tutors and tutees
as well as friends and strangers. The following is
an example error produced when looking only at the
previous turn to predict the current turn:
? Tutee (impolite): ?dude thats def wrong i gotta
subract 16m not just 16? (the current turn)
? Tutor (non-impolite): ?16m is what has to be
subtracted from both sides? (the next turn, pre-
dicted incorrectly)
In the segment above the tutee challenges the tutor
by pointing out a ?def? mistake; the tutor responds
with a task-oriented contribution that moves the di-
alogue forward, but does not escalate the face threat
(Ogan et al, 2012). And, in fact, if we look one
more turn back in the history, the tutor once again
uses calm language: ?wait it says youre wrong i dont
know why ust wait?. The increased window size
is implicitly evoking the differential conversational
strategies of tutors vs. tutees. And while the current
data set is too small to build separate models for tu-
tors and tutees, in this case (and based on the prior
work in Ogan et al, 2012), accounting for role dis-
tinctions that differentiate strategies taken by tutors
and tutees is the likely reason behind the improve-
ment due to window size.
Conversely to the friend data set, the false nega-
tives that occur when predicting impoliteness in the
stranger data set are not improved by increasing the
26
window size, as is demonstrated in the following ex-
change:
? Tutor (non-impolite): ?subtract ym from both
sides.?
? Tutee (non-impolite): ?first step? first Step??
? Tutor (non-impolite): ?subtract hb from both
sides? (the current turn)
? Tutee (impolite): ?first step? FIRST
STEP??????????? (the next turn, predicted in-
correctly)
The impolite tutee utterance at turn 4 is predicted
to be non-impolite when analysis is limited to the
previous turn, as is also shown in the first example
in this section. However, unlike the previous ex-
ample which improved with an expanding window
size, looking back to turns 1 and 2 does not improve
the model. While we do not have enough stranger
dyads to completely explore this phenomenon, it
seems clear that strangers? responses do not follow
the same patterns as friends. The current unpre-
dictability of strangers can be due to a number of
social phenomena, such as less affect (both posi-
tive and negative) overall, which results in a differ-
ent conversational flow. Less overall affect means
that there is less likely to be useful information in
the previous utterances. This is an important dis-
tinction between designing models for dyads with
rapport and those without, which is a primary con-
cern in the development of social SDSs. Among
strangers, other techniques may need to be used to
increase model accuracy, such as looking at the con-
tent of the utterances to determine whether or not a
speaker had been repeating themselves, as is shown
in this example, which could likely be an indicator
of rudeness.
As a final example of how the error analysis
can reveal important phenomena for future study,
when examining the prediction of positivity on the
stranger test set, we first observe that emoticons
are useful indicators of positivity. However, some-
times emoticons serve quite different social func-
tions, which leads to false positives:
? Tutor (non-positivity): ?Simplify ! :)? (the cur-
rent turn)
? Tutee (non-positivity): ?y didnt it chang? (the
next turn, predicted incorrectly)
Here, the smiley face is used by the tutor primarily
to mitigate the face threat of an impolite command.
However, since the experiment reported in Section
6.1 shows that our model attributes more weight to
emoticons when predicting positivity, the model errs
on this utterance. Here the error analysis suggests
that in fact we might need to investigate more com-
plicated latent variable models to capture the subtle
social functionality of some language use in context.
7 Conclusion
Long-term relationships involve the expression of
both positive and negative sentiments and, paradox-
ically, both can serve to increase closeness. In this
paper, we have addressed the novel task of predict-
ing impoliteness and positivity in teenagers? peer tu-
toring conversations, and our results shed light on
what kinds of behaviors evoke these social functions
for friends and for strangers, and for tutors and tu-
tees. Our investigation has successfully predicted
impoliteness and positivity on the basis of both an-
notated and automatically extracted features, sug-
gesting that a dialogue system will one day be able to
employ analyses such as these to signal relationships
with users. And while social features such as those
we annotated are naturally quite rare in dialogue, our
quantitative experiments have demonstrated the ca-
pabilities of modeling sparsity in log-linear models:
elastic net and Lasso models outperformed standard
logistic regression model and the non-sparse ridge
penalty model.
We found that positivity is much more predictable
for strangers than is impoliteness, while the oppo-
site was true for friends. This could lend support for
the importance of positivity as a rapport-signaling
function in the early stages of a relationship (as
in (Tickle-Degnen and Rosenthal, 1990)), and indi-
cating the need for further research on the increasing
importance of impoliteness as a rapport signal over
the course of relationship development.
We also found that performance on the prediction
tasks increased with larger feature window sizes,
particularly for impoliteness among friends and pos-
itivity among strangers. From our error analysis,
we see that this improvement may arise because dif-
ferent behaviors predict impoliteness and positivity
based on the social role of the speaker. Thus tu-
tee bragging predicts positivity in tutors, while tu-
tor bragging negatively predicts positivity among tu-
tees. The power differential between the two may
lead tutees to want to take tutors ?down a peg? while
tutors struggle to maintain the position of power in
the dyad.
While results such as these may seem specific to
teenage peer tutors, the general conclusion remains,
that linguistic devices have different social functions
in different contexts, and dialogue systems that in-
tend to spend a lifetime on the job will do well to
adapt their language to the stage of relationship with
a user, and the social role they play.
27
References
Hua Ai, Diane J. Litman, Kate Forbes-Riley, Mihai Ro-
taru, Joel Tetreault, and Amruta Purandare. 2006.
Using system and user performance features to im-
prove emotion detection in spoken tutoring dialogs. In
Proceedings of the Ninth International Conference on
Spoken Language Processing (Interspeech 2006).
Angela M. Ardington. 2006. Playfully negotiated activ-
ity in girls talk. Journal of Pragmatics, 38(1):73 ? 95.
Rachel E. Baker, Alastair J. Gill, and Justine Cassell.
2008. Reactive redundancy and listener comprehen-
sion in direction-giving. In Proceedings of the 9th
SIGdial Workshop on Discourse and Dialogue.
Timothy W. Bickmore and Rosalind W. Picard. 2005.
Establishing and maintaining long-term human-
computer relationships. ACM Transactions on
Computer-Human Interaction.
Timothy Bickmore, Laura Pfeifer, and Daniel Schulman.
2011. Relational agents improve engagement and
learning in science museum visitors. In Proceedings
of the 10th international conference on Intelligent vir-
tual agents, IVA?11.
Kristy Elizabeth Boyer, Robert Phillips, Michael Wallis,
Mladen Vouk, and James Lester. 2008. Balancing
cognitive and motivational scaffolding in tutorial di-
alogue. In Proceedings of the 9th international con-
ference on Intelligent Tutoring Systems, ITS ?08.
Penelope Brown and Stephen Levinson. 1978. Uni-
versals in language usage: Politeness phenomena. In
Questions and politeness: Strategies in social interac-
tion.
Justine Cassell, Alastair J. Gill, and Paul A. Tepper.
2007. Coordination in conversation and rapport. In
Proceedings of the Workshop on Embodied Language
Processing, EmbodiedNLP ?07, pages 41?50, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Jan Chovanec. 2009. Simulation of spoken interaction in
written online media texts. Brno Studies in English.
David Crystal. 2001. Language and the internet. Cam-
bridge University Press.
Jonathan Culpeper. 1996. Towards an anatomy of impo-
liteness. In Journal of Pragmatics.
Jonathan Culpeper. 2011. Impoliteness: Using language
to cause offence.
Laurence Devillers and Laurence Vidrascu. 2006. Real-
life emotions detection with lexical and paralinguistic
cues on human-human call center dialogs. In Proceed-
ings of the Ninth International Conference on Spoken
Language Processing (Interspeech 2006).
A Gartner, M Kohler, and F Riessman. 1971. Children
teach children: Learning by teaching. In New York and
London: Harper and Row.
Jose? Gonza?lez-Brenes and Jack Mostow. 2011. Which
system differences matter? using l1/l2 regulariza-
tion to compare dialogue systems. In Proceedings of
the SIGDIAL 2011 Conference, pages 8?17, Portland,
Oregon, June. Association for Computational Linguis-
tics.
Jonathan Gratch, Anna Okhmatovskaia, Francois
Lamothe, Stacy Marsella, Mathieu Morales, Rick J.
van der Werf, and Louis-Philippe Morency. 2006.
Virtual rapport. In Proceedings of the International
Conference on Intelligent Virtual Agents (IVA 2006).
M. Grimm, E. Mower K. Kroschel, and S. Narayanan.
2007. Primitives-based evaluation and estimation of
emotions in speech. In Speech Communication.
P. Gupta and R. Nitendra. 2007. Two-stream emo-
tion recognition for call center monitoring. In Pro-
ceedings of the 8th Annual Conference of the Inter-
national Speech Communication Association (Inter-
speech 2007).
Susan C. Herring and Asta Zelenkauskaite. 2009. Sym-
bolic capital in a virtual heterosexual market. In Writ-
ten Communication.
Je Hun Jeon, Rui Xia, and Yang Liu. 2010. Level of in-
terest sensing in spoken dialog using multi-level fusion
of acoustic and lexical evidence. In Proceedings of the
11th Annual Conference of the International Speech
Communication Association (Interspeech 2010), IN-
TERSPEECH 2010.
W. Lewis Johnson and Paola Rizzo. 2004. Politeness in
tutoring dialogs: run the factory, thats what id do. In
Intelligent Tutoring Systems, Lecture Notes in Com-
puter Science.
Manfred Kienpointner. 1997. Varieties of rudeness:
types and functions of impolite utterances. In Func-
tions of Language.
S. le Cessie and J.C. van Houwelingen. 1992. Ridge
estimators in logistic regression. Applied Statistics,
41(1):191?201.
Jackson Liscombe, Julia Hirschberg, and Jennifer J. Ven-
ditti. 2005. Detecting certainness in spoken tutorial
dialogues. In Proceedings of the 6th Annual Confer-
ence of the International Speech Communication As-
sociation (Interspeech 2005).
D. Litman and K. Forbes-Riley. 2004. Predicting stu-
dent emotions in computer-human tutoring dialogues.
In Proceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics (ACL 2004).
Dong C. Liu and Jorge Nocedal. 1989. On the lim-
ited memory bfgs method for large scale optimization.
Mathematical Programming, 45:503?528.
Andre Martins, Noah Smith, Mario Figueiredo, and Pe-
dro Aguiar. 2011. Structured sparsity in structured
prediction. In Proceedings of the 2011 Conference on
28
Empirical Methods in Natural Language Processing,
pages 1500?1511, Edinburgh, Scotland, UK., July. As-
sociation for Computational Linguistics.
Bruce M. McLaren, Sung-Joo Lim, David Yaron, and
Ken Koedinger. 2007. Can a polite intelligent tutor-
ing system lead to improved learning outside of the
lab? In Proceedings of the 2007 conference on Arti-
ficial Intelligence in Education: Building Technology
Rich Learning Contexts That Work.
Bruce McLaren, DeLeeuwm Krista E., and Richard E.
Mayer. 2011. Polite web-based intelligent tutors: Can
they im-prove learning in classrooms? In Computers
and Education.
Angeliki Metallinou, Martin Wollmer, Athanasios
Katsamanis, Florian Eyben, Bjorn Schuller, and
Shrikanth S. Narayanan. 2011. Context-sensitive
learning for enhanced audiovisual emotion classifica-
tion. IEEE Transactions on Affective Computing.
Amy Ogan, Samantha Finkelstein, Erin Walker, Ryan
Carlson, and Justine Cassell. 2012. Rudeness and
rapport: Insults and learning gains in peer tutoring. In
Proceedings of the 11 International Conference on In-
telligence Tutoring Systems (ITS 2012).
J. Alfredo Sa?nchez, Norma P. Herna?ndez, Julio C. Pena-
gos, and Yulia Ostro?vskaya. 2006. Conveying mood
and emotion in instant messaging by using a two-
dimensional model for affective states. In Proceedings
of VII Brazilian symposium on Human factors in com-
puting systems, IHC ?06, pages 66?72, New York, NY,
USA. ACM.
A. Sharpley, J. Irvine, and C. Sharpley. 1983. An exami-
nation of the effectiveness of a cross-age tutoring pro-
gram in mathematics for elementary school children.
In American Educational Research Journal.
Helen Spencer-Oatey. 2008. Face (im)politeness and
rapport. In Culturally Speaking: Culture, Communi-
cation and Politeness Theory.
Carolyn A. Straehle. 1993. ?samuel?? ?yes dear?? teas-
ing and conversatrion rapport. In Framing in Dis-
course.
Bas Stronks, Anton Nijholt, Paul van Der Vet, Dirk
Heylen, and Aaron Machado. 2002. Designing for
friendship: Becoming friends with your eca. In Pro-
ceedings of Embodied conversational agents - let?s
specify and evaluate (AAMAS).
Marina Terkourafi. 2008. Toward a unified theory of po-
liteness, impoliteness, and rudeness. Impoliteness in
language: studies on its interplay with power in the-
ory and practice.
Robert Tibshirani. 1994. Regression shrinkage and se-
lection via the lasso. Journal of the Royal Statistical
Society, Series B, 58:267?288.
Linda Tickle-Degnen and Robert Rosenthal. 1990. The
nature of rapport and its nonverbal correlates. In Psy-
chological Inquiry.
Kevin E. Vowles and Miles Thompson. 2012. The
patient-provider relationship in chronic pain. In Psy-
chiatric Management of Pain.
Erin Walker, Nikol Rummel, and Kenneth R. Koedinger.
2011. Is it feedback relevance or increased account-
ability that matters? In Proceedings of the 10th Inter-
national Conference on Computer-Supported Collab-
orative Learning (CSCL 2011).
William Yang Wang and Julia Hirschberg. 2011. Detect-
ing levels of interest from spoken dialog with multi-
stream prediction feedback and similarity based hier-
archical fusion learning. In Proceedings of the 12th
annual SIGdial Meeting on Discourse and Dialogue
(SIGDIAL 2011), Portland, OR., USA, June. ACL.
William Yang Wang and Kathleen McKeown. 2010. ?got
you!?: Automatic vandalism detection in wikipedia
with web-based shallow syntactic-semantic modeling.
In Proceedings of the 23rd International Conference
on Computational Linguistics (Coling 2010), pages
1146?1154, Beijing, China, August. Coling 2010 Or-
ganizing Committee.
William Yang Wang, Fadi Biadsy, Andrew Rosenberg,
and Julia Hirschberg. 2012a. Automatic detection
of speaker state: Lexical, prosodic, and phonetic ap-
proaches to level-of-interest and intoxication classifi-
cation. Computer Speech & Language.
William Yang Wang, Elijah Mayfield, Suresh Naidu, and
Jeremiah Dittmar. 2012b. Historical analysis of le-
gal opinions with a sparse mixed-effects latent vari-
able model. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2012).
Richard J. Watts. 2003. Politeness. Cambridge Univer-
sity Press.
Hui Zou and Trevor Hastie. 2005. Regularization and
variable selection via the elastic net. Journal of the
Royal Statistical Society, Series B, 67:301?320.
29
Proceedings of the SIGDIAL 2013 Conference, pages 51?60,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Automatic Prediction of Friendship via Multi-model Dyadic Features 
Zhou Yu, David Gerritsen, Amy Ogan, Alan W Black, Justine Cassell 
School of Computer Science, Carnegie Mellon University 
{zhouyu, dgerrits, aeo, awb, justine }@cs.cmu.edu 
 
Abstract 
In this paper we focus on modeling 
friendships between humans as a way of 
working towards technology that can initiate 
and sustain a lifelong relationship with users. 
We do this by predicting friendship status in a 
dyad using a set of automatically harvested 
verbal and nonverbal features from videos of 
the interaction of students in a peer tutoring 
study. We propose a new computational 
model used to model friendship status in our 
data, based on a group sparse model (GSM) 
with L2,1 norm which is designed to 
accommodate the sparse and noisy properties 
of the multi-channel features. Our GSM model 
achieved the best overall performance 
compared to a non-sparse linear model (NLM) 
and a regular sparse linear model (SLM), as 
well as outperforming human raters. Dyadic 
features, such as number and length of 
conversational turns and mutual gaze, in 
addition to low level features such as F0 and 
gaze at task, were found to be good predictors 
of friendship status. 
1 Introduction and Related Work 
While significant advances have been made in 
detecting the speech and nonverbal social signals 
emitted by individuals (see Vinciarelli, Pantic & 
Bourlard, 2009, for a review), and research has 
addressed the social roles and states of 
individuals in groups (see Gatica-Perez, 2009, 
for a review), considerably less computational 
work has focused on the automatic detection of 
speech or nonverbal correlates of specifically 
dyadic states, such as rapport. And yet rapport 
has been shown to have important effects on 
interactions as diverse as survey interviewing 
(Berg, 1989), sales (Brooks, 1989), and health 
(Harrigan et al, 1985).  If we are to build 
interactive systems that are successful, then, we 
believe that the ability to build rapport with a 
human user will be essential. 
Rapport can be instantaneous and can also 
build over time. Granovetter (1973) describes the 
strength of an interpersonal ?tie? as a function of 
the time, emotional intensity, and reciprocity that 
accumulates between people. These ties mediate 
effects in myriad domains such as learning 
(Azmitia & Montgomery, 1993) and healthcare 
(Harrigan & Rosenthal, 1983).  
Accordingly, analysis of initial exchanges and 
those after many years of interaction suggests 
that the behavioral signals that indicate rapport 
change over time. For example, in Tickle-
Degnen and Rosenthal?s highly cited model 
(1990), rapport consists of mutual attention, 
positivity, and coordination. High levels of 
positivity between conversational partners are 
common in the initial phases of a relationship, 
but positivity has been shown to decline, without 
a loss in rapport, as the number of interactions 
increases. In fact, Ogan et al (2012) gave 
evidence that the use of playful rudeness 
between friends during peer tutoring correlates to 
greater learning. This leads to an associated 
challenge of spoken dialogue system 
development: creating systems that can develop 
social ties, and increase rapport with the user 
over repeated interactions to maximize beneficial 
outcomes. 
While little work has addressed automatic 
detection, some prior work has addressed the 
problem of emitting signals to build rapport in 
dialogue and agent systems (Stronks et al, 2002; 
Bickmore & Picard, 2005; Gratch et al, 2006; 
Cassell et al, 2007; Bickmore et al, 2011), and 
we turn to this research for what cues might be 
important in rapport. The majority of this prior 
work, however, has addressed harmony ? or 
instant rapport ? rather than rapport over time. 
For those systems that have addressed friendship 
or the growth of rapport, most commonly the 
number of interactions has been used as a meter 
of relationship progression, instigating changes 
in the dialogue system as the social odometer 
scrolls onward (Cassell & Bickmore, 2003; 
Vardoulakis et al, 2012). Counting the times a 
dyad has interacted is a crude approximation of a 
relationship state, however; being able to detect 
the behavioral signals that people actually use to 
indicate relationship status would be superior. 
In our own prior work (Cassell et al,2007) we 
looked at particular hand-annotated nonverbal 
signals (such as nodding and mutual gaze) as 
operationalizations of rapport, and found that 
friends and non-friends indeed show differing 
distributions of each signal as a function of 
relationship state. In the current study, we move 
to the next step and automatically harvest a set of 
multimodal dyadic and time contingent features 
to identify those features that play a significant 
role in predicting friendship state. A major 
51
challenge for predicting relational states such as 
these is to construct a compact feature space that 
captures only reliable rapport signals and also 
generalizes across different users. To provide 
strength to our model (as well as to fit the 
multimodal nature of embodied conversational 
agents), we look at both acoustic and visual 
features. Such an approach takes advantage of 
the fact that multimodal aspects of 
communication are not redundant, but often 
complementary (Cassell, 2000).  
    However, dyadic behaviors such as 
conversational turns, mutual/non-mutual smile, 
mutual/non-mutual gaze, and mutual/non-mutual 
lean forward provide an additional challenge in 
modeling; no matter how important, they appear 
relatively rarely in conversational data. Thus 
standard non-sparse linear models, normally 
trained on high frequency factors, might assign 
too much weight to low frequency (i.e., sparse) 
features. In order to address issues of this sort 
Yuan and Lin (2007) introduced the group 
lasso.   To address the sparse nature of our 
features in real-world data and the noise that 
occurs from different production sources, we 
propose an extension to this genre of technique 
in the form of a Group Sparse Model (GSM) 
which enforces sparsity with a L2,1 norm instead 
of the group lasso penalty (Chen, et  al., 2011), 
due to the relatively efficient optimization 
process of L2,1 norms (Liu, et al, 2009). Unlike 
a straightforward sparse linear model (SLM) 
(Yang et al, 2010), which treats each feature 
independently, GSMs group features which share 
the same production source in the optimization 
process. In the GSM linear model, the removal of 
the assumption of independence between 
features means that the penalty is on group rather 
than individual features. Thus the model has 
general robustness to noise, since grouping 
features from the same production source can 
increase the overall confidence of the feature 
group. 
Our contributions in this work, then, are three-
fold: we (1) designed and implemented a method 
for automatic dyadic feature extraction which is 
based on low level features, and which yields 
strong predictive power of friendship status, (2) 
propose a new Group Sparse Model (GSM) with 
L2,1 norm, that deals with the noisy and sparse 
nature of the feature sets, and (3) illuminate, 
from this model, the nature of verbal and 
nonverbal behavior between friends and non-
friends in a peer tutoring setting. 
The remainder of the paper is organized as 
follows. We first describe the data set and 
introduce the features used in our experiments. 
We then describe the performance of the three 
computational models we evaluated. Finally, we 
discuss the contributions of different features to 
friendship prediction and provide an error 
analysis of our proposed model.  
2 The Data Set 
  
Figure 1: Camera View 1 and Camera View 2 
We collected data from dyads of students 
engaged in a reciprocal peer tutoring task. We 
chose peer tutoring as it is a domain in which 
friendship has been shown to have a positive 
effect on student learning (see e.g. Ogan et al 
2012). In addition, tutoring systems that rely on 
dialogue are common, and peer tutoring dialogue 
systems are increasingly common. Thus, being 
able to assess friendship state in this domain is a 
useful step on the path to creating a peer tutoring 
agent that can use rapport to increase learning 
gains.  
    Each dyad consisted of two American English 
speakers with a mean age of 13.3 years (range = 
12 ? 15). We collected data from 12 dyads, of 
which 6 dyads were already friends. Dyads were 
either both girls or both boys, and each condition 
contained 3 boy dyads and 3 girl dyads.  
Each dyad came to the lab for 3 sessions, with 
an average interval between visits of 4.6 days 
(SD = 3.1), totaling 36 sessions across all dyads. 
Each session consisted of about 90 minutes of 
interaction recorded from three camera views (a 
frontal view of each participant and a side view 
of the two participants). With close talk 
microphones, we also recorded the participants? 
speech in separate audio channels for the purpose 
of automatic dyadic acoustic feature extraction. 
The setting is shown in Figure 1. 
Each session began with a short period of time 
for participants to become acquainted. After that, 
using a standard reciprocal tutoring procedure 
(see Fantuzzo et al, 1989), participants tutored 
each other on procedural and conceptual aspects 
of an algebra topic in which both participants 
were relatively novice. Order of seating and 
assignment of tutoring roles (tutor or tutee) was 
determined in the first session by alphabetical 
order of participant name. Tutoring roles 
alternated from that point on, such that both 
participants had the opportunity to take on the 
role of ?expert? during each session. After a 
period of individual study time to familiarize 
52
themselves with the material, the first tutoring 
period began and lasted approximately 25 
minutes. This was followed by a 5 minute break, 
after which students? tutoring roles were reversed 
for a second tutoring period of 25 minutes. 
Finally, each student answered a survey about 
the interaction.  
The current study examines only the tutoring 
sections of each session, which were divided into 
30-second clips or ?thin slices? (Ambady et al, 
2006). In total, the data points used for modeling 
comprise 2259 clips from the 12 dyads. 
3 Multimodal Information  
In our analyses, low-level audio and visual 
features were automatically extracted using three 
off-the-shelf toolkits. Dyadic features, which are 
a second order derivative of the low level 
features, and which capture the interaction of two 
participants, are also automatically produced. 
Taken together, analysis of these features allows 
us to determine if the verbal and nonverbal 
behaviors of the participants index their 
friendship status in any significant way.  
3.1 Low Level Audio Features (LA)  
Type # of Features 
Prosodic Features 
  F0 72 
  Energy 38 
  Duration 154 
Voice Quality Features 
  Jitter 68 
  Shimmer 34 
  Voicing 38 
Spectral Features 
  MFCC 570 
Total 974 
 
Table 1: Acoustic Feature Groups 
 
For acoustic feature extraction, a large set of 
acoustic low-level descriptors (LLD) and 
derivatives of LLDs combined with appropriate 
statistical functionals, i.e., maxPos (the absolute 
position of the maximum value in frames), 
minPos (the absolute position of the minimum 
value in frames), amean (The arithmetic mean of 
the contour), etc., were extracted for each of the 
split channel recordings. The ?INTERSPEECH 
2010 Paralinguistic Challenge Feature Set? in the 
openSMILE toolkit (Schuller et al, 2012) was 
used as our basic acoustic feature set. For 
spectral features, Mel Spectrum and LSP were 
excluded due to the possible overlap with 
MFCC. The set contained 974 features which 
resulted from a base of 32 low-level descriptors 
(LLD) with 32 corresponding delta coefficients, 
and 21 functionals applied to each of these 68 
LLD contours. In addition, 19 functionals were 
applied to the 4 pitch-based LLD and their four 
delta coefficient contours. Finally the number of 
pitch onsets (pseudo syllables) and the total 
duration of the input were included. The 
dimension of each feature group is shown in 
Table 1. 
3.2 Low Level Vision Features (LV) 
Type # of Features 
Face Position Feature 10 
38 Face Interest Points 114 
Gaze Features 3 
Face Direction  Features 4 
Mouth and Eye Openness 6 
Smile Intensity 1 
Discretized Smile 1 
Total 139 
 
Table 2: Vision Feature Groups 
 
Since participants were facing the camera 
directly most of the time, as seen in Fig 1, 
current technology for facial tracking can 
efficiently be applied to our dataset. OMRON?s 
OKAO Vision System was used in face 
detection, facial feature extraction, and basic face 
related features extrapolation. For each frame, 
the vision software returns a smile intensity (0-
100) and the gaze direction, using both 
horizontal and vertical angles expressed in 
degrees. Apart from gaze direction, the software 
also provides information about head orientation: 
horizontal, vertical, and roll (in or out). 38 
additional face interest points, position and 
confidence, were also extracted. These were 
normalized to pixel coordinates, which turned 
out to lead to quite noisy data, and hence to 
diminished utility of these 38 points (in the 
future we will consider normalizing to face 
coordinates). We also calculated the openness of 
the left eye, right eye, mouth, and the location of 
the face. Details are shown in Table 2. Similar to 
our audio feature extraction method, one static 
feature vector per 30 second video clip was 
produced. All the features were computed at the 
same rate as the original videos: 30 Hz. 
Altogether, 139 dimensions were extracted in 
each frame from each camera view. 
3.3 Dyadic Features (DF) 
All of the features discussed above are low-level 
acoustic and visual features, extracted with 
53
respect to individual participants. While 
individual behavior may index friendship state, 
we posit that patterns of interaction will be more 
effective. For example, prior research (Baker et 
al., 2008) suggests that the number and length of 
conversational turns (Cassell et al, 2007), 
presence of mutual smiles and non-mutual smiles 
(Prepin et al, 2012), mutual gaze and non-
mutual gaze (Nakano et al, 2010), as well as 
posture shifting (Cassell, et al, 2001; Tickle-
Degnen & Rosenthal, 1990), are important 
features to investigate in dyadic data. While 
other features such as gestures and mutual pitch 
shift may also play a role in indexing relationship 
state, these are not yet a part of the dyadic 
features we address here.  
3.3.1 Number and Average Length of 
Conversational Turns   
We recorded individual audio channels for each 
participant, which makes the automatic 
extraction of conversational turns possible. First, 
we extracted intervals of silence with toolbox 
SoX which produced speech chunks, and then 
identified the speaker by comparing the speech 
energy (loudness) in each audio channel, as 
speech from each speaker is carried by the 
other?s microphone. After that we combined the 
speech chunks and speaker ID to approximate 
conversational turns. The approximation quality 
is not perfect, given the variability of the audio 
recording, but noise can be mediated during 
model building. 
3.3.2 Mutual Smile and Non Mutual Smile  
Prepin et al (2012) describe the role of mutual 
smiles (smiles that occur during the same time 
period) in ?stance alignment? and make the point 
that interactional alignment of this behavior 
reflects synchronization of internal states. Such 
synchrony predicts mutual understanding and 
increased quality of interaction, and as such is a 
fundamental quality in the formation of 
adolescent friendships (Youniss, 1982). Cappella 
& Pelachaud (2002) likewise describe 
?mutuality? as the precondition for how smiles 
function in contingent ways in a dyad. Smiles are 
clearly therefore important to assess in data such 
as ours. We defined a maximum window of 500 
milliseconds between the end of one participant?s 
smile and the beginning of the next for smiles to 
be considered mutual.  
3.3.3 Mutual Gaze and Non-mutual Gaze 
Nakano & Ishii (2010) describe eye gaze as a 
clue to engagement, and integrate mutual gaze 
into their conversational agents. There is no 
feature for direct gaze at partner provided in the 
OKAO vision toolkit. Mutual gaze was therefore 
approximated by annotating a gaze ?in front,? 
achieved by combining the information from 
three directions of gaze: vertical, horizontal, and 
depth. Gaze ?in front?, or at the partner, was 
recorded only if the participant gaze had less 
than a 15 degree angle from straight forward in 
all of these three directions. A maximum window 
of 500 milliseconds for gaze to be considered 
mutual was also employed here.  
3.3.4 Mutual Lean Forward and Non-Mutual 
Lean Forward 
Forward leaning has been shown to be a 
significant predictor of the ability to establish 
rapport in a dyad (Harrigan et al, 1985). In fact, 
friends who lean in are seen as more socially 
competent, while strangers are seen as less 
socially competent when they lean in (Burgoon 
& Hale, 1988). For our study, lean forward was 
approximated by detecting the smooth trend of 
face enlargement within the video frame. In 
order to improve precision of the feature, the 
segments with high confidence in face detection 
were processed. Furthermore, posture shifting, 
i.e., forward leaning, is not as quickly executed 
as changes in gaze or smile. We therefore used a 
1 second sample window for lean forward, rather 
than a 500 millisecond window.  
3.3.5 Mutual Gaze followed by Mutual Smile 
Mutual gaze followed by mutual smile is also 
approximated using a similar approach as above. 
It is a relatively dense feature compared to all the 
other possible combinations of nonverbal 
behaviors, thus it is the only combination that is 
included in the feature set in this paper. The 
window within which mutual gaze is considered 
to be followed by mutual smile is set to be within 
2 seconds. 
4 Computational Model  
We formulate friendship prediction as a set of 
binary classifications. In order to have the least 
variance and make sure no participant appeared 
in both the training and testing set, a leave-one-
out cross-validation setting was adopted in all of 
our experiments. Each session had approximately 
180 30-second video clips, totaling 2259 data 
points. Z-score normalization by dyad was used 
to scale all the features into the same range. 
Early fusion, which is simple concatenation of 
feature vectors, was adopted throughout our 
experiments to combine different features. We 
evaluated our group sparse model (GSM), along 
with a non-sparse linear model (NLM) and 
sparse linear model (SLM). 
54
4.1 Non-sparse Linear Model (NLM) 
We began with a standard non-sparse linear 
model (NLM), which is a Support Vector 
Machine (SVM) (Cortes & Vapnik, 1995) with a 
linear kernel. The libsvm (Fan et al, 2008) 
package was used in our experiment, and the 
parameter, the slack value of SVM that controls 
the scale of the soft margin, was obtained by 
cross validation.  
4.2 Sparse Linear Model (SLM)  
In order to prevent over-fitting on rare dyadic 
features, a sparse sensitive model SLM was 
introduced. As well as preventing over-fitting, 
through weight shrinkage the sparse model can 
also exclude redundant features. In our 
experiment, an L2,1 norm sparse model with 
linear kernel (Yang et al, 2012) was selected as 
our baseline sparse model. 
4.3 Group Sparse Model (GSM) 
Based on the SLM, we propose a group-sparse 
model (GSM) with the novel use of an L2,1 
norm. Instead of assuming every feature is 
uncorrelated to other features, the GSM groups 
some of the features together and utilizes their 
correlated information to mediate the noise of the 
data. For an arbitrary matrix        , its 
          is defined as  
         ? ??    
  
   
 
     
Suppose that we have n training data indicated 
by            and sampled from c classes. In 
our setting, c = 2, friends or non-friends.     
{   }          is the corresponding label. 
The total scatter matrix    and between class 
scatter matrix    are defined as follows.  
         ?             
           
         ?               
              
where ? is the mean of all samples,    is the 
mean of samples in the i-th class.    is the 
number of samples in the i-th class,   
            . 
           
              
G is the scaled label matrix. A well-known 
method to utilize discriminate information is to 
find a low dimensional subspace in which     is 
maximized while    is minimized (Fukunaga et 
al., 1990). So the object function could be easily 
written as follows  
    ( 
 (    
  ) )            
           
The optimization of the above object function 
was introduced in Yang et al (2012). It is an 
adaptation of iterative singular value 
decomposition. In GSM, a block-wise constraint 
is imposed on the diagonal matrix (D) which is 
the intermediate result of the iterative single 
value decomposition. 
      (
 
       
     
 
       
  ) 
W in the equation is the weight function,    is 
the ith feature group in W, and there are a total 
number of G sub diagonal matrices 
corresponding to G groups of features. 
     For acoustic features, Steidl et al, (2012) 
designed a grouping schema which consists of 
Prosodic Features, Voice Quality Features and 
Spectral features which we adopted. For visual 
features, based on our observation of the highly 
unstable performance of the 38 feature points of 
the face, we introduced group bondage for the 
entire group to prevent single face features over-
fitting the classifier. Detailed group information 
is shown in Table 1 and Table 2. 
5 Human Baseline 
 
Figure 2: Boxplot of human rating accuracy with 
respect to gender. 
In order to establish a baseline of the difficulty 
of predicting friendship, we conducted an 
experiment with humans, rating whether two 
people in a video were friends or not, after 
watching a 30-second video/audio clip taken 
from the first session of tutoring (in which the 
behaviors of strangers are most likely to be 
distinct from friends). We recruited 14 people 
and screened out participants with prior 
theoretical knowledge of nonverbal behavior, 
gesture, friendship, and rapport, or who rated all 
12 clips in under 8 minutes, leaving 10 
participants, half male, with an average age of 23 
(SD 4.8). Each participant was asked to watch 
one 30-second clip per dyad, taken from 3 
minutes after tutoring began. The mean accuracy 
of their friendship prediction was 0.717 (SD 
0.119), which is significantly lower than our best 
GSM model (trained on all three sessions) 
applied to those same 12 clips, with a 
55
performance of 0.837 (t(11) = -2.1381 p.<.05). 
When we split the ratings by gender, we found 
females on average were more accurate than 
males (see Figure 2). According to Hall et al, 
(1979) females are generally better decoders of 
nonverbal behaviors, which may lead to better 
judgment of friendship. 
6 Results: Models  
 
 Human NLM SLM GSM 
LV  0.743 0.768 0.792* 
LA  0.674 0.664 0.682* 
LV+DF  0.752 0.769 0.801* 
LA+DF  0.679 0.681 0.683 
LV+LA  0.744 0.780 0.803* 
LV+LA+DF  0.717 0.749 0.782 0.814# 
 
Table 3: The classification accuracy of the three 
algorithms on different features sets. Feature sets 
were combined with early fusion (+). Values marked 
* are significantly better (p<.05, pairwise t-test) than 
other results in the same row. Values marked # are 
significantly better (p<.001, pairwise t-test) than other 
results in the same column. 
Our group sparse model (GSM) along with the 
non-sparse linear model (NLM) and sparse linear 
model (SLM) were evaluated on different 
combinations of three sets of features: low-level 
vision features (LV), low-level audio features 
(LA) and dyadic features (DF), and their 
performance is presented in Table 3. We did not 
evaluate dyadic features (DF) alone due to their 
sparse nature. 
     In particular, we found that adding the 
automatically extracted DF to LV and LA with 
early fusion improved the performance (t(2258)= 
-3.12,p<.001) of the GSM model. When using 
fewer modalities, our newly proposed GSM 
outperformed NLM and SLM (t(2258)=-1.65, 
p<0.05). However, when the number of feature 
sets increased, there was no statistical difference 
in performance between GSM and the other two 
models. We suspect that when features are 
abundant, the information that the features 
provide reaches a ceiling. The advantage of the 
GSM was gained by mediating the noise and 
sparseness of the data, which resulted in better 
weight assignment for each feature. Alternatively, 
when features are abundant, even NLM can have 
a comparative weight assignment by performing 
a greedy high dimensional feature space search. 
Thus there is limited room for further 
improvement by better weight assignment among 
the group features which GSM assumes. 
    When we looked at the top features selected 
by NLM using the vision modality alone, two 
(out of 38) face features, which had an unstable 
nature, appeared high in rank, which suggests the 
possibility of NLM over-fitting the noise of these 
features. Surprisingly, when more modalities are 
added, NLM stops picking single face features as 
top informative features. In GSM, none of the 38 
face features are listed in the top ranked features 
for any of the modalities, which demonstrates its 
ability in noise mediation. 
In real world applications, data sets which 
produce ideal, abundant, and accurate features 
are rarely encountered. We often end up with 
data that are poor in video quality, e.g. with no 
split channels for each participant or no frontal 
face view. Our newly proposed GSM may 
therefore be more robust when features are noisy 
or certain modalities are not available.  
7 Results: Contributions of Features 
Feature Name Weight 
Number of Conversational Turns & 
Average Length of Turns 
0.041 
Gaze Down -0.036 
Mutual Gaze 0.014 
F0 0.013 
Non-mutual Gaze -0.013 
Voicing 0.014 
MFCC -0.007 
Non-mutual Smile 0.004 
Non-mutual Lean Forward 0.004 
Mutual Gaze followed by Mutual 
Smile 
0.001 
 
Table 4:  The top 10 informative features and their 
weights as trained by GSM. Positive weight is 
associated with friends while negative weight is 
associated with non-friends. 
After building the model and ranking the 
features, we looked into the weights learned for 
each feature. This weight comprises not only the 
magnitude, which tells us if the feature is 
important, but also the polarity. A detailed list of 
the most informative features and their weights is 
shown in Table 4.  
The strongest feature is number and length of 
conversational turns which is grouped in the 
table and should be interpreted as meaning that 
friends have more and shorter conversational 
turns. This is consistent with previous research 
on direction giving (Cassell et al, 2007), and 
mirrors the fact that friends are more likely to 
interrupt one another. 
We expected that unfamiliar participants, 
seated about two feet across from one another, 
would maintain a low level of eye contact 
(Argyle & Dean, 1965). In fact we found that 
non-friends tend to gaze down more often. In 
this context, non-friends spend more time 
56
looking down at their study materials. In turn, 
mutual gaze is higher among friends. 
Among the audio features, F0, which captures 
pitch related information such as range and 
mean, has been shown to differ between 
conversational and non-conversational speech 
(Bolinger, 1986). Here, friends show that more 
conversational style in their speech, despite the 
tutoring nature of the interaction.  
In order to further examine the lessons to be 
learned from this GSM model about verbal and 
nonverbal behavior in friends and strangers, we 
also ran a repeated measures ANOVA, including 
both gender and friendship status as factors. 
There were no significant effects for gender, 
however, and so that factor was collapsed for 
further analysis. The four features described 
above were all significantly different between 
friends and strangers (although gaze down was 
simply a trend, at p<.08). 
The following features were also important to 
the model, but did not show significance in the 
ANOVA, perhaps because of their sparse nature 
in our data. MFCC (Mel-Frequency Cepstral 
Coefficients) was associated with strangers and 
the similar audio feature of voicing was 
associated with friends. Both of these features 
have been described as approximating speech 
style ? voicing, for example, may indicate more 
backchannels, such as ?uh huh? and ?hmm? 
(Ward, 2006). 
     In Nakano et al (2003), listener gaze at the 
speaker is interpreted as evidence of non-
understanding. We found similar results whereby 
non-friends were more likely to engage in non-
mutual gaze ? looking at one another when the 
other person was not looking back.  Mutual smile 
did not distinguish between friends and non-
friends, while non-mutual smile, on the other 
hand, provided indicative strength, in spite of its 
sparse nature, for friendship. This may relate to 
our prior work (Ogan et al, 2012) which found 
significant teasing and other behavior whereby 
friends appear comfortable enjoying themselves 
at the expense of the other.  
    Mutual lean forward lacked predictive power 
in our model, while non-mutual lean forward 
was more salient between friends. We often 
found, for example, that friends maintained very 
different postures, with a tutor leaning back 
much of the time, leaning forward only to answer 
a direct question from the tutee. Non-friends, on 
the other hand, tended to remain fixed on the 
study material. This may have been a display of 
formality, where a casual attitude would have 
been perceived as either impolite or 
inappropriate. In either relationship state, the 
tutee tended to sit hunched over the worksheet, 
and since we did not enter tutor state into the 
model, this may have washed out some tutor-
specific results.  
     For the time contingent feature, mutual gaze 
followed by mutual smile is informative and 
predictive of friends. 
8 Error Analysis and Discussion 
Dyad  
ID 
LA+DF LV+DF LA+LV+DF 
     1 0.732 0.809 0.819 
     2* 0.703 0.793 0.804 
     3* 0.574 0.771 0.778 
     4* 0.713 0.708 0.762 
     5 0.653 0.879 0.880 
     6 0.728 0.827 0.835 
     7 0.624 0.873 0.882 
     8* 0.712 0.861 0.852 
     9* 0.698 0.820 0.830 
    10 0.606 0.834 0.854 
    11* 0.700 0.682 0.743 
    12 0.749 0.780 0.785 
 
Table 5: The average accuracy of classification in 
each dyad using the group sparse model (GSM) with 
different combination of feature sets. Dyads marked 
with * are friends 
We performed an error analysis to understand the 
contexts under which our model failed to 
accurately predict friendship states, and here we 
discuss the implications of these examples for 
our work. Table 5 shows the average accuracy of 
each dyad using audio, visual, and dyadic 
features to predict friendship. Dyads 2, 3, 4, 8, 9 
and 11 are friend dyads, and the rest are 
strangers.  
Dyad 3 (friends) showed very low accuracy in 
audio and dyadic features alone, which might be 
explained by the fact that in one early session for 
this dyad, most of the 30-second clips contain 
very sparse numbers of low-level audio features 
(LA). An examination of the audio recording 
reveals that one of the participants was more 
aggressive than in the other sessions. The student 
told his friend, ?Just be quiet?I am trying to 
work,? and ?Shh, you don?t understand, so I 
basically have to teach you how to work that, but 
I'm trying to work.? At this point in the 
interaction, his partner stopped participating in 
the task and said virtually nothing for the rest of 
the session. This lack of speech led to a lower 
number of turns ? a pattern with a closer 
resemblance to strangers than friends. 
It seems that such rude behavior would be 
more likely between friends than strangers, 
meaning that ultimately our model will need to 
57
be sensitive to this kind of variance. With more 
pairs of friends, different styles of friendship can 
be further distinguished. However, this specific 
phenomenon signals that in the future, lexical 
information which could be obtained by 
automatic speech recognition could further 
improve performance. 
Dyad 11 also showed low relative accuracy in 
predication, particularly when the model used 
vision features. We found that one of the 
participants often tilted her head, which partially 
blocked the frontal camera view of the other 
participant, thus resulting in less confidence in 
automatically extracted visual features. In the 
future we will set our cameras in a better position 
in order to reach higher feature extraction 
accuracy.  
When we combined all our features, the 
prediction accuracy of Dyad 3 and 11 improved, 
further demonstrating that multimodal 
information improves friendship modeling. 
9 Conclusion and Future Work 
As a first step towards predicting the state of 
friendship between two interlocutors, we 
analyzed a set of automatically harvested low-
level and dyadic features from dialogues in a 
peer-tutoring task. Both low level features and 
dyadic features were shown to be useful in 
discriminating between those who are friends 
and those who are not.  
     To perform the analysis, we introduced a new 
computational group sparse model (GSM) in 
order to accommodate the sparse and noisy 
properties of multi-channel features. GSM 
outperformed a baseline of human raters who 
make these types of social judgments in 
everyday interactions. GSM also statistically 
outperformed a non-sparse linear model (NLM) 
and a sparse linear model (SLM) when the 
analysis used only a single set of low level 
features or single set of low level features 
combined with dyadic features. When all 
features were used, the distinctions between 
models decreased, since in a huge multimodal 
feature space, even a na?ve model could greedy 
search for a good weight assignment. Thus our 
newly proposed model did not significantly 
outperform the others in this scenario. And in 
general, more features produced more accurate 
prediction. 
    Based on the outcomes of the GSM model, we 
investigated differences between verbal and 
nonverbal behavior cues as a function of 
different friendship states. While much research 
on rapport detection and building in ECAs has 
focused on low level features, we found that 
dyadic features provided some of the most 
distinguishing differences between friends and 
non-friends. For example, mutual gaze and non-
mutual gaze were both indicative, as friends are 
comfortable looking directly at one another while 
non-friends may have used direct gaze only to 
signal non-understanding. This comfort between 
friends was also notable in other salient dyadic 
features; i.e., while non-friends often work in 
concert looking down at the task, friends were 
relaxed such that one partner could lean back, 
interrupt to take more conversational turns, and 
smile at the other without needing to reciprocate 
the smile each time. 
In future work we will look at temporal 
contingency more closely, examining whether 
participants? actions are contingent on the 
behavior of their partner. We will also examine 
whether the behavior of friends and strangers 
changes over multiple sessions. In this context, 
we include one suggestive graph, which shows 
that strangers increase their mutual gaze over 
sessions but friends decrease it. We are currently 
collecting further sessions for each dyad so as to 
be able to further analyze the nature of these 
relationships over time. 
 
Figure 3: Weight of the mutual gaze in each 
session, by friendship status 
 
To date we have found that the inclusion of 
automatically extracted dyadic features can lead 
to better prediction of friendship state. Both 
verbal and nonverbal behaviors were discovered 
that distinguish between different friendship 
status and that suggest how to design embodied 
dialogue systems that intend to spend a lifetime 
on the job. 
Acknowledgements 
Thanks to Angela Ng, Rachel Marino and Marissa 
Cross for data collection, Giota Stratou for visual 
feature extraction, Yi Yang, Louis-Philippe Morency, 
Shoou-I Yu, William Wang, and Eric Xing for 
valuable discussions, and the NSF IIS for generous 
funding. 
References  
Ambady, N., Krabbenhoft, M. A. & Hogan, D. 
(2006). The 30-sec sale: Using thin-slice 
0
2
4
6
1 2 3
Session Number 
Mutual gaze per clip 
strangers
friends
58
judgments to evaluate sales effectiveness. 
Journal of Consumer Psychology, 16(1), 4?13. 
Argyle, M. & Dean, J. (1965). Eye-contact, distance 
and affiliation. Sociometry, 28(3), 289?304. 
Azmitia, M. & Montgomery, R. (1993). Friendship, 
transactive dialogues, and the development of 
scientific reasoning. Social Development, 2(3), 
202?221.  
Baker, R. E., Gill, A. J., & Cassell, J. (2008). Reactive 
redundancy and listener comprehension in 
direction-giving. In Proceedings of the 9th 
SIGdial Workshop on Discourse and Dialogue 
(pp. 37?45). 
Brooks, M. (1989). Instant rapport (p. 205). New 
York: Warner Books. 
Berg, B. L. (1989). Qualitative research methods for 
the social sciences. Boston: Allyn and Bacon. 
Bernieri, F. J. (1988). Coordinated movement and 
rapport in teacher-student interactions. Journal 
of Nonverbal Behavior, 12(2), 120?138. 
Bickmore, T. W. & Picard, R. W. (2005). Establishing 
and maintaining long-term human-computer 
relationships. ACM Transactions on Computer-
Human Interaction, 12(2), 293?327. 
Bickmore, T. W., Pfeifer, L., & Schuman, D. (2011). 
Relational agents improve engagement and 
learning in science museum visitors. In 
Intelligent Virtual Agents (pp. 55?67). 
Reykjavik. 
Bolinger, D. (1986). Intonation and its parts: Melody 
in spoken English. Stanford, CA: Stanford 
University Press. 
Burgoon, J. K. & Hale, J. L. (1988). Nonverbal 
expectancy violations: Model elaboration and 
application to immediacy behaviors. 
Communications Monographs, (May 2013), 37?
41. 
Cappella, J. N.  & Pelachaud, C. (2002). Rules for 
responsive robots: Using human interactions to 
build virtual interactions. In Reis, Firzpatrick, & 
Vangelisti (Eds.), Stability and change in 
relationships. New York, NY: Cambridge 
University Press. 
Cassell, J. (2000). Nudge nudge wink wink: Elements 
of face-to-face conversation for embodied 
conversational agents. In J. Cassell, J. Sullivan, 
S. Prevost, & E. Churchill (Eds.), Embodied 
conversational agents (pp. 1?27). MIT Press. 
Cassell, J., Gill, A. J., & Tepper, P. A. (2007). 
Coordination in conversation and rapport. 
Proceedings of the ACL Workshop on Embodied 
Natural Language, 40 ?50. 
Cassell, J., Bickmore, T. W., Campbell, L., 
Vilhj?lmsson, H. H., & Yan, H. (2001). More 
than just a pretty face: Conversational protocols 
and the affordances of embodiment. Knowledge-
Based Systems, 14(1-2), 55?64. 
Cassell, J. & Bickmore, T. W. (2003). Negotiated 
collusion: Modeling social language and its 
relationship effects in intelligent agents. User 
Modeling and User-Adapted Interaction, 13(1), 
89?132. 
Chen, X., Lin, Q., Kim, S., Carbonell, J. G., & Xing, 
E. P. (2012). Smoothing proximal gradient 
method for general structured sparse regression. 
The Annals of Applied Statistics, 6(2), 719?752. 
Cortes, C. & Vapnik, V. (1995). Support-vector 
networks. Machine Learning, 20(3), 273?297. 
Fan, R., Chang, K., Hsieh, C., Wang, X., & Lin, C. 
(2008). LIBLINEAR: A library for large linear 
classification. The Journal of Machine Learning 
Research, 9, 1871?1874. 
Fantuzzo, J., Riggio, R., Connelly, S., & Dimeff, L. 
(1989). Effects of reciprocal peer tutoring on 
academic achievement and psychological 
adjustment: A component analysis. Journal of 
Educational Psychology, 81(2), 173-177. 
Fukunaga, K. (1990). Introduction to Statistical 
Pattern Recognition, Second Edition (2nd ed., p. 
592). San Diego, CA: Academic Press. 
Gatica-Perez, D. (2009). Automatic nonverbal 
analysis of social interaction in small groups: A 
review. Image and Vision Computing, 27(12), 
1775?1787. 
Granovetter, M. S. (1973). The strength of weak ties. 
American Journal of Sociology, 78(6), 1360?
1380.  
Gratch, J., Okhmatovskaia, A., Lamothe, F., Marsella, 
S.,  Morales, M., van der Werf, R. J., & 
Morency, L.-P. (2006). Virtual rapport. In 
Intelligent Virtual Agents (pp. 14?27). Springer 
Berlin/Heidelberg. 
Hall, J. A., DiMatteo, M. R., Rogers, P. L., & Archer, 
D. (1979). Sensitivity to nonverbal 
communication: The PONS test. Baltimore, MD: 
Johns Hopkins University Press. 
Harrigan, J. A., Oxman, T. E., & Rosenthal, R. 
(1985). Rapport expressed through nonverbal 
behavior. Journal of Nonverbal Behavior, 9, 
95?110. 
Harrigan, J. A. & Rosenthal, R. (1983). Physicians? 
head and body positions as determinants of 
perceived rapport. Applied Social Psychology, 
13(6), 496?509. 
Liu, J., Ji, S., & Ye, J. (2009). Multi-task feature 
learning via efficient l2, 1-norm minimization. 
In Proceedings of the Twenty-Fifth Conference 
on Uncertainty in Artificial Intelligence (pp. 
339?348). AUAI Press. 
Nakano, Y. I., Reinstein, G., Stocky, T., & Cassell, J. 
(2003). Towards a model of face-to-face 
grounding. In Proceedings of the 41st Annual 
Meeting on Association for Computational 
Linguistics. ACL?03 (Vol. 1, pp. 553?561). 
Sapporo: Association for Computational 
Linguistics. 
Nakano, Y. I. & Ishii, R. (2010). Estimating user?s 
engagement from eye-gaze behaviors in human-
agent conversations. In Proceedings of the 15th 
international conference on Intelligent user 
59
interfaces. IUI?10 (pp. 139?148). Hong Kong: 
ACM Press. 
Ogan, A., Finkelstein, S., Walker, E., Carlson, R., & 
Cassell, J. (2012). Rudeness and rapport: Insults 
and learning gains in peer tutoring. In 
Proceedings of the 11 International Conference 
on Intelligence Tutoring Systems (ITS 2012). 
Prepin, K., Ochs, M., & Pelachaud, C. (2012). Mutual 
stance building in dyad of virtual agents: Smile 
alignment and synchronisation. In Privacy, 
Security, Risk and Trust (PASSAT), 2012 
International Conference on Social Computing 
(SocialCom) (pp. 938?943). 
Schuller, B., Steidl, S., Batliner, A., N?th, E., 
Vinciarelli, A., Burkhardt, F., ? Weiss, B. 
(2012). The INTERSPEECH 2012 speaker trait 
challenge. In Proceedings of the 13th Annual 
Conference of the International Speech 
Communication Association (INTERSPEECH 
2012). Portland, OR: ISCA. 
Steidl, S., Polzehl, T., Bunnell, H. T., Dou, Y., 
Muthukumar, P. K., Perry, ? Metze, F. (2012). 
Emotion identification for evaluation of 
synthesized emotional speech. In Proceedings of 
the 6th International Conference on Speech 
Prosody 2012 (pp. 4?7). Shanghai: Tongji 
University Press. 
Stronks, B., Nijholt, A., van Der Vet, P., Heylen, D., 
& Machado, A. (2002). Designing for 
friendship: Becoming friends with your ECA. In 
A. Marriott, C. Pelachaud, T. Rist, Z. M. 
Ruttkay, & H. Vilhjalmsson (Eds.), Workshop 
on Embodied Conversational Agents - Let?s 
specify and evaluate them!, AMAAS 2002 (pp. 
91?96). Bologna: AMAAS. 
Tickle-Degnen, L. & Rosenthal, R. (1990). The nature 
of rapport and its nonverbal correlates. 
Psychological Inquiry, 1(4), 285?293. 
Vardoulakis, L. P., Ring, L., Barry, B., Sidner, C. L., 
& Bickmore, T. W. (2012). Designing relational 
agents as long term social companions for older 
adults. In Y. Nakano, M. Neff, A. Paiva, & M. 
Walker (Eds.), Intelligent Virtual Agents (pp. 
289?302). Santa Cruz, CA: Springer Berlin 
Heidelberg. 
Vinciarelli, A., Pantic, A., Bourlard, H. (2009) Social 
signal processing: Survey of an emerging 
domain. Image and Vision Computing, (27)12, 
1743-1759. 
Ward, N. (2006). Non-Lexical Conversational Sounds 
in American English. Pragmatics and 
Cognition, (14)1, 113-184. 
Wang, W. Y., Finkelstein, S., Ogan, A., Black, A. W., 
& Cassell, J. (2012). ?Love ya, jerkface?: Using 
sparse log-linear models to build positive (and 
impolite) relationships with teens. In 
Proceedings of the 13th Annual SIGDIAL 
Meeting on Discourse and Dialogue (pp. 20?
29). Seoul, South Korea. 
Yang, Y., Shen, H. T., Ma, Z., Huang, Z., & Zhou, X. 
(2010). l2,1-regularized discriminative feature 
selection for unsupervised learning. In 
Proceedings of the Twenty-Second International 
Joint Conference on Artificial Intelligence (pp. 
1589?1594). AAAI Press.  
Youniss, J. (1982). Parents and peers in social 
development: A Sullivan-Piaget perspective. 
University of Chicago Press. 
Yuan, M. & Lin, Y. (2007), Model selection and 
estimation in regression with grouped variables. 
Journal of the Royal Statistical Society, Series B 
68(1), 49-67. 
 
60
