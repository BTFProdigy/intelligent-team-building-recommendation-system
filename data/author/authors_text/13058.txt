Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1038?1046,
Beijing, August 2010
Modeling Socio-Cultural Phenomena in Discourse 
Tomek Strzalkowski1,2, George Aaron Broadwell1, Jennifer Stromer-Galley1, Samira Shaikh1, Sarah Taylor3 and Nick Webb1 1ILS Institute, University at Albany, SUNY 2IPI, Polish Academy of Sciences 3Lockheed Martin Corporation tomek@albany.edu 
 
Abstract In this paper, we describe a novel ap-proach to computational modeling and understanding of social and cul-tural phenomena in multi-party dia-logues. We developed a two-tier ap-proach in which we first detect and classify certain social language uses, including topic control, disagreement, and involvement, that serve as first order models from which presence the higher level social constructs such as leadership, may be inferred.  1. Introduction We investigate the language dynamics in small group interactions across various set-tings. Our focus in this paper is on English online chat conversations; however, the mod-els we are developing are more universal and applicable to other conversational situations: informal face-to-face interactions, formal meetings, moderated discussions, as well as interactions conducted in languages other than English, e.g., Urdu and Mandarin.  Multi-party online conversations are particu-larly interesting because they become a per-vasive form of communication within virtual communities, ubiquitous across all age groups. In particular, a great amount of communica-tion online occurs in virtual chat-rooms, typi-cally conducted using a highly informal text dialect. At the same time, the reduced-cue environment of online interaction necessitates more explicit linguistic devices to convey social and cultural nuances than is typical in face-to-face or even voice conversations.  Our objective is to develop computational models of how certain social phenomena such as leadership, power, and conflict are signaled and reflected in language through the choice of lexical, syntactic, semantic and conversa-tional forms by discourse participants. In this 
paper we report the results of an initial phase of our work during which we constructed a prototype system called DSARMD-1 (De-tecting Social Actions and Roles in Multi-party Dialogue). Given a representative seg-ment of multiparty task-oriented dialogue, DSARMD-1 automatically classifies all dis-course participants by the degree to which they deploy selected social language uses, such as topic control, task control, involve-ment, and disagreement. These are the mid-level social phenomena, which are de-ployed by discourse participants in order to achieve or assert higher-level social con-structs, including leadership. In this work we adopted a two-tier empirical approach where social language uses are modeled through observable linguistic features that can be automatically extracted from dialogue. The high-level social constructs are then inferred from a combination of language uses attrib-uted to each discourse participant; for exam-ple, a high degree of influence and a high de-gree of involvement by the same person may indicate a leadership role. In this paper we limit our discussion to the first tier only: how to effectively model and classify social lan-guage uses in multi-party dialogue.  2. Related Research Issues related to linguistic manifestation of social phenomena have not been systemati-cally researched before in computational lin-guistics; indeed, most of the effort thus far was directed towards the communicative di-mension of discourse. While the Speech Acts theory (Austin, 1962; Searle, 1969) provides a generalized framework for multiple levels of discourse analysis (locution, illocution and perlocution), most current approaches to dia-logue focus on information content and structural components (Blaylock, 2002; Car-berry & Lambert, 1999; Stolcke, et al, 2000) in dialogue; few take into account the effects that speech acts may have upon the social 
1038
roles of discourse participants. Also relevant is research on modeling sequences of dia-logue acts ? to predict the next one (Samuel et al 1998; Ji & Bilmes, 2006 inter alia) ? or to map them onto subsequences or ?dialogue games? (Carlson 1983; Levin et al, 1998), which are attempts to formalize participants? roles in conversation (e.g., Linell, 1990; Poe-sio &?Mikheev, 1998; Field et al, 2008). There is a body of literature in anthropology, linguistics, sociology, and communication on the relationship between language and power, as well as other social phenomena, e.g., con-flict, leadership; however, existing ap-proaches typically look at language use in situations where the social relationships are known, rather than using language predic-tively. For example, conversational analysis (Sacks et al, 1974) is concerned with the structure of interaction: turn-taking, when interruptions occur, how repairs are signaled, but not what they reveal about the speakers. Research in anthropology and communication has concentrated on how certain social norms and behaviors may be reflected in language (e.g., Scollon and Scollon, 2001; Agar, 1994) with few systematic studies attempting to ex-plore the reverse, i.e., what the linguistic phenomena tell us about social norms and behaviors.  3. Data & Annotation Our initial focus has been on on-line chat dialogues. While chat data is plentiful on-line, its adaptation for research purposes presents a number of challenges that include users? pri-vacy issues on the one hand, and their com-plete anonymity on the other. Furthermore, most data that may be obtained from public chat-rooms is of limited value for the type of modeling tasks we are interested in due to its high-level of noise, lack of focus, and rapidly shifting, chaotic nature, which makes any longitudinal studies virtually impossible. To derive complex models of conversational be-havior, we need the interaction to be reasona-bly focused on a task and/or social objectives within a group. Few data collections exist covering multiparty dialogue, and even fewer with on-line chat. Moreover, the few collections that exist were built primarily for the purpose of training dialogue act tagging and similar linguistic phenomena; few if any of these corpora are 
suitable for deriving pragmatic models of conversation, including socio-linguistic phe-nomena. Existing resources include a multi-person meeting corpus ICSI-MRDA and the AMI Meeting Corpus (Carletta, 2007), which contains 100 hours of meetings cap-tured using synchronized recording devices. Still, all of these resources look at spoken language rather than on-line chat. There is a parallel interest in the online chat environ-ment, although the development of useful re-sources has progressed less. Some corpora exist such as the NPS Internet chat corpus (Forsyth and Martell, 2007), which has been hand-anonymized and labeled with part-of-speech tags and dialogue act labels. The StrikeCom corpus (Twitchell et al, 2007) consists of 32 multi-person chat dialogues between players of a strategic game, where in 50% of the dialogues one participant has been asked to behave ?deceptively?. It is thus more typical that those interested in the study of Internet chat compile their own corpus on an as needed basis, e.g., Wu et al (2002), Khan et al (2002), Kim et al (2007).  Driven by the need to obtain a suitable dataset we designed a series of experiments in which recruited subjects were invited to participate in a series of on-line chat sessions in a spe-cially designed secure chat-room. The ex-periments were carefully designed around topics, tasks, and games for the participants to engage in so that appropriate types of behav-ior, e.g., disagreement, power play, persuasion, etc. may emerge spontaneously. These ex-periments and the resulting corpus have been described elsewhere (Shaikh et al, 2010b), and we refer the reader to this source. Ulti-mately a corpus of 50 hours of English chat dialogue was collected comprising more than 20,000 turns and 120,000 words. In addition we also assembled a corpus of 20 hours of Urdu chat.  A subset of English language dataset has been annotated at four levels: communication links, dialogue acts, local topics and meso-topics (which are essentially the most persistent lo-cal topics). Although full details of these an-notations are impossible to explain within the scope of this article, we briefly describe them below. Annotated datasets were used to de-velop and train automatic modules that detect and classify social uses of language in dis-course. It is important to note that the annota-
1039
tion has been developed to support the objec-tives of our project and does not necessarily conform to other similar annotation systems used in the past.  ? Communicative links. In a multi-party dia-logue an utterance may be directed towards a specific participant, a subgroup of par-ticipants or to everyone.  ? Dialogue Acts. We developed a hierarchy of 15 dialogue acts for annotating the func-tional aspect of the utterance in discussion.  The tagset we adopted is based on DAMSL (Allen & Core, 1997) and SWBD (Jurafsky et al, 1997), but compressed to 15 tags tuned significantly towards dialogue prag-matics and away from more surface char-acteristics of utterances (Shaikh et al, 2010a).  ? Local topics. Local topics are defined as nouns or noun phrases introduced into dis-course that are subsequently mentioned again via repetition, synonym, or pronoun.  ? Topic reference polarity. Some topics, which we call meso-topics, persist through a number of turns in conversation. A selec-tion of meso-topics is closely associated with the task in which the discourse par-ticipants are engaged. Meso-topics can be distinguished from the local topics because the speakers often make polarized state-ments about them.  4. Socio-linguistic Phenomena We are interested in modeling the social phe-nomena of Leadership and Power in discourse. These high-level phenomena (or Social Roles, SR) will be detected and attributed to dis-course participants based on their deployment of selected Language Uses (LU) in multi-party dialogue. Language Uses are mid-level socio-linguistic devices that link linguistic components deployed in discourse (from lexical to pragmatic) to social con-structs obtaining for and between the partici-pants. The language uses that we are currently studying are Agenda Control, Disagreement, and Involvement (Broadwell et al, 2010). Our research so far is focused on the analysis of English-language synchronous chat, and we are looking for correlations between vari-ous metrics that can be used to detect LU in multiparty dialogue. We expect that some of these correlations may be culturally specific or language-specific, as we move into the 
analysis of Urdu and Mandarin discourse in the next phase of this project. 4.1 Agenda Control in Dialogue Agenda Control is defined as efforts by a member or members of the group to advance the group?s task or goal. This is a complex LU that we will model along two dimensions: (1) Topic Control and (2) Task Control. Topic Control refers to attempts by any discourse participants to impose the topic of conversa-tion. Task Control, on the other hand, is an effort by some members of the group to de-fine the group?s project or goal and/or steer the group towards that goal. We believe that both behaviors can be detected using scalar measures per participant based on certain linguistic features of their utterances. For example, one hypothesis is that topic control is indicated by the rate of local topic introductions (LTI) per participant (Givon, 1983). Local topics may be defined quite simply as noun phrases introduced into dis-course, which are subsequently mentioned again via repetition, synonym, pronoun, or other form of co-reference. Thus, one meas-ure of topic control is the number of local topics introduced by each participant as per-centage of all local topics in a discourse.  Using an LTI index we can construct asser-tions about topic control in a discourse. For example, suppose the following information is discovered about the speaker LE in a multi-party discussion dialogue-11 where 90 local topics are identified: 1. LE introduces 23/90 (25.6%) of local top-ics in this dialogue. 2. The mean rate of local topic introductions is this dialogue is 14.29%, and standard deviation is 8.01. 3. LE is in the top quintile of participants for introducing new local topics We can now claim the following, with a de-gree of confidence (to be determined): TopicControlLTI (LE, 5, dialogue-1) We read this as follows: speaker LE exerts the highest degree of topic control in dialogue-1. Of course, LTI is just one source of evidence and we developed other metrics to comple-ment it. We mention three of them here:                                                 1 Dialogue-1 refers to an actual dataset of 90-minute chat among 7 participants, covering approximately 700 turns. The task is to select a candidate for a job given a set of resumes. 
1040
? SMT Index. This is a measure of topic con-trol suggested in (Givon, 1983) and it is based on subsequent mentions of already introduced local topics. Speakers who in-troduce topics that are discussed at length by the group tend to control the topic of the discussion. The subsequent mentions of lo-cal topics (SMT) index calculates the per-centage of second and subsequent refer-ences to the local topics, by repetition, synonym, or pronoun, relative to the speakers who introduced them.  ? Cite Score. This index measures the extent to which other participants discuss topics introduced by that speaker. The difference between SMT and CiteScore is that the lat-ter reflect to what degree a speaker?s efforts to control the topic are assented to by other participants in a conversation. ? TL Index (TL). This index stipulates that more influential speakers take longer turns than those who are less influential. The TL index is defined as the average number of words per turn for each speaker. Turn length also reflects the extent to which other participants are willing to ?yield the floor? in conversation. Like LTI, all the above indices are mapped into a degree of topic control, based on quin-tiles in normal distribution (Table 1).   
 
LTI SMT CS TL AVG LE 5 5 5 5 5.00 JR 4 4 4 3 3.75 KI 4 3 3 1 2.75 KN 3 5 4 4 4.00 KA 2 2 2 4 2.50 CS 2 2 2 2 2.00 JY 1 1 1 2 1.25 Table 1: Topic Control distribution in dialogue-1. Each row represents a speaker in the group (LE, JR, etc.). Columns show indices used, with degrees per speaker on 5-point scale based on quintiles in normal distribu-tion, and the average value. Ideally, all the above indices (and others yet to be defined) should predict the same out-come, i.e., for each dialogue participant they should assign the same degree of topic control, relative to other speakers. This is not always the case, and where the indices divert in their predictions, our level of confidence in the generated claims decreases. We are currently 
working on how these different metrics cor-relate to each other and how they should be weighted to maximize accuracy of making Topic Control claims. Nonetheless, we can already output a Topic Control map (shown in Table 1) that captures a sense of internal so-cial dynamics within the group.  The other aspect of Agenda Control phe-nomenon is Task Control. It is defined as an effort to determine the group's goal and/or steer the group towards that goal. Unlike Topic Control, which is imposed by influenc-ing the subject of conversation, Task Control is gained by directing other participants to perform certain tasks or accept certain opin-ions. Consequently, Task Control is detected by observing the usage of certain dialogue acts, including Action-Directive, Agree-Accept, Disagree-Reject, and related categories. Here again, we define several in-dices that allow us to compute a degree of Task Control in dialogue for each participant: ? Directive Index (DI). The participant who directs others is attempting to control the course of the task that the group is per-forming. We count the number of directives, i.e., utterances classified as Ac-tion-Directive, made by each participant as a percentage of all directives in discourse. ? Directed Topic Shift Index (DTSI). When a participant who controls the task offers a directive on the task, then the topic of con-versation shifts. In order to detect this con-dition, we calculate the ratio of coincidence of directive dialogue acts by each partici-pant with topic shifts following them.  ? Process Management index (PMI). Another measure of Task Control is the proportion of turns each participant has that explicitly address the problem solving process. This includes utterances that involve coordinat-ing the activities of the participants, plan-ning the order of activities, etc. These fall into the category of Task (or Process) Management in most DA tagging systems.  ? Process Management Success Index (PMSI). This index measures the degree of success by each speaker at controlling the task. A credit is given to the speaker whose suggested curse of action is supported by other speakers for each response that sup-ports the suggestion. Conversely, a credit is taken away for each response that rejects or 
1041
qualifies the suggestion. PMSI is computed as distribution of task management credits among the participants over all dialogue utterances classified as Task/Process Man-agement. 2 As an example, let?s consider the following information computed for the PMI index over dialogue-1:  1. Dialogue-1 contains 246 utterances classi-fied as Task/Process Management rather than doing the task. 2. Speaker KI makes 65 of these utterances for a PMI of 26.4%. 3. Mean PMI for participants is 14.3%; 80th percentile is >21.2%. PMI for KI is in the top quintile for all participants. Based on this evidence we may claim (with yet to be determined confidence) that: TaskControlPMI(KI, 5, dialogue-1) This may be read as follows: speaker KI ex-erts the highest degree of Task Control in dialogue-1. We note that Task Control and Topic Control do not coincide in this dis-course, at least based on the PMI index. Other index values for Task Control may be com-puted and tabulated in a way similar to LTI in Table 1. We omit these here due to space limitations. 4.2 Disagreement in Dialogue Disagreement is another language use that correlates with speaker?s power and leader-ship. There are two ways in which disagree-ment is realized: expressive disagreement and topical disagreement (Stromer-Galley, 2007; Price, 2002). Both can be detected using sca-lar measures applied to subsets of participants, typically any two participants. In addition, we can also measure for each participant the rate with which he or she generates disagreement (with any and all other speakers). Expressive Disagreement is normally understood at the level of dialogue acts, i.e., when discourse participants make explicit utterances of dis-agreement, disapproval, or rejection in re-sponse to a prior speaker?s utterance. Here is an example (KI and KA are two speakers in a multiparty dialogue in which participants                                                 2 The exact structure of the credit function is still being deter-mined experimentally. For example, more credit may be given to first supporting response and less for subsequent responses; more credit may be given for unprompted suggestions than for those that were responding to questions from others. 
discuss candidates for a youth counselor job): KA: CARLA... women are always better with kids KI: That?s not true! KI: Men can be good with kids too While such exchanges are vivid examples of expressive disagreement, we are interested in more sustained phenomenon where two speakers repeatedly disagree, thus revealing a social relationship between them. Therefore, one measure of Expressive Disagreement that we consider is the number of Disagree-Reject dialogue acts between any two speakers as a percentage of all utterances exchanged be-tween these two speakers. This becomes a basis for the Disagree-Reject Index (DRX). In dialogue-1 we have: 1. Speakers KI and KA have 47 turns between them. Among these there are 8 turns classi-fied as Disagree-Reject, for the DRX of 15.7%. 2. The mean DRX for speakers who make any Disagree-Reject utterances is 9.5%. The pair of speakers KI-KA is in the top quin-tile (>13.6%). Based on this evidence we can conclude the following:   ExpDisagreementDRX (KI,KA, 5, dialogue-1) which may be read as follows: speakers KI and KA have the highest level of expressive disagreement in dialogue-1. This measure is complemented by a Cumulative Disagreement Index (CDX), which is computed for each speaker as a percentage of all Disagree-Reject utterances in the discourse that are made by this speaker. Unlike DRX, which is computed for pairs of speakers, the CDX values are as-signed to each group participant and indicate the degree of disagreement that each person generates. While Expressive Disagreement is based on the use of more overt linguistic devices, Topical Disagreement is defined as a differ-ence in referential valence in utterances (statements, opinions, questions, etc.) made on a topic. Referential valence of an utterance is determined by the type of statement made about the topic in question, which can be positive (+), negative (?), or neutral (0). A positive statement is one in favor of (express advocacy) or in support of (supporting infor-mation) the topic being discussed. A negative statement is one that is against or negative on 
1042
the topic being discussed. A neutral statement is one that does not indicate the speaker?s po-sition on the topic. Here is an example of op-posing polarity statements about the same topic in discourse: Sp-1: I like that he mentions ?Volunteerism and Leadership? Sp-2: but if they?re looking for someone who is experienced then I?d cross him off Detecting topical disagreement in discourse is more complicated because its strength may vary from one topic in a conversation to the next. A reasonable approach is thus to meas-ure the degree of disagreement between two speakers on one topic first, and then extrapo-late over the entire discourse. Accordingly, our measure of topical disagreement is valua-tion differential between any two speakers as expressed in their utterances about a topic. Here, the topic (or an ?issue?) is understood more narrowly than the local topic defined in the previous section (as used in Topic Control, for example), and may be assumed to cover only the most persistent local topics, i.e., top-ics with the largest number of references in dialogue, or what we call the meso-topics. For example, in a discussion of job applicants, each of the applicants becomes a meso-topic, and there may be additional meso-topics pre-sent, such as qualifications required, etc.  The resulting Topical Disagreement Metric (TDM) captures the degree to which any two speakers advocate the opposite sides of a meso-topic. TDM is computed as an average of P-valuation differential for one speaker (advocating for a meso-topic) and (?P)-valuation differential for the other speaker (advocating against the meso-topic).  Using TDM we can construct claims related to disagreement in a given multiparty dia-logue of sufficient duration (exactly what constitutes a sufficient duration is still being researched). Below is an example based on a 90-minute chat dialogue-1 about several job candidates for a youth counselor. The discus-sion involved 7 participants, including KI and KA. Topical disagreement is measured on 5 points scale (corresponding to quintiles in normal distribution): TpDisAgreeTDM(KI,KA,?Carla?,4,dialogue-1) This may be read as follows: speakers KI and KA topically disagree to degree 4 on topic [job candidate] ?Carla? in dialogue-1. In or-
der to calculate this we compute the value of TDM index between these two speakers. We find that KA makes 30% of all positive utter-ances made by anyone about Carla (40), while KI makes 45% of all negative utterances against Carla. This places these two speakers in the top quintiles in the ?for Carla? polarity distribution and ?against Carla? distribution, respectively. Taking into account any oppos-ing polarity statements made by KA against Carla and any statements made by KI for Carla, we calculate the level of topical dis-agreement between KA and KI to be 4 on the 1-5 scale. TDM allows us to compute topical disagree-ment between any two speakers in a discourse, which may also be represented in a 2-dimensional table revealing another inter-esting aspect of internal group dynamics.  4.3 Involvement in Dialogue The third type of social language use that we discuss in this paper is Involvement. In-volvement is defined as a degree of engage-ment or participation in the discussion of a group. It is an important element of leader-ship, although its importance is expected to differ between cultures; in Western cultures, high involvement and influence (topic control) often correlates with group leadership. In order to measure Involvement we designed several indices based on turn characteristics for each speaker. Four of the indices are briefly explained below:  ? The NP index (NPI) is a measure of gross informational content contributed by each speaker in discourse. NPI counts the ratio of third-person nouns and pronouns used by a speaker to the total number of nouns and pronouns in the discourse.  ? The Turn index (TI) is a measure of inter-actional frequency; it counts the ratio of turns per participant to the total number of turns in the discourse.  ? The Topic Chain Index (TCI) counts the degree to which participants discuss of the most persistent topics. In order to calculate TCI values, we define a topic chains for all local topics. We compute frequency of mentions of these longest topics for each participant.  ? The Allotopicality Index (ATP) counts the number of mentions of local topics that were introduced by other participants. An 
1043
ATP value is the proportion of a speaker's allotopical mentions, i.e., excluding ?self-citations?, to all allotopical mentions in a discourse.  As an example, we may consider the follow-ing situation in dialogue-1: 1. Dialogue-1 contains 796 third person nouns and pronouns, excluding mentions of participants? names. 2. Speaker JR uses 180 nouns and pronouns for an NPI of 22.6%.  3. The median NPI is 14.3%; JR are in the upper quintile of participants (> 19.9%). From the above evidence we can draw the following claim: InvolvementNPI(JR, 5, dialogue-1) This may be read as: speaker JR is the most involved participant in dialogue-1. As with other language uses, multiple indices for Involvement can be combined into a 2-dimensional map capturing the group in-ternal dynamics.  5. Implementation & Evaluation We developed a prototype automated DSARMD system that comprises a series of modules that create automated annotation of the source dialogue for all the language ele-ments discussed above, including communi-cative links, dialogue acts, local/meso topics, and polarity. Automatically annotated dia-logue is then used to generate language use degree claims. In order to evaluate accuracy of the automated process we conducted a pre-liminary evaluation comparing the LU claims generated from automatically annotated data to the claims generated from manually coded dialogues. Below we briefly describe the methodology and metrics used. Each language use is asserted per a partici-pant in a discourse (or per each pair of par-ticipants, e.g., for Disagreement) on a 5-point ?strength? scale. This can be represented as an ordered sequence LUX(d1, d2, ? dn), where LU is the language use being asserted, X is the index used, di is the degree of LU attrib-uted to speaker i. This assignment is therefore a 5-way classification of all discourse par-ticipants and its correctness is measured by dividing the number of correct assignments by the total number of elements to be classi-fied, which gives the micro-averaged preci-sion. The accuracy metric is computed with 
several variants as follows: 1. Strict mapping: each complete match is counted as 1; all mismatches are counted as 0. For example, the outputs LUX (5,4,3,2,1) and LUX (4,5,3,1,1) produce two exact matches (for the third and the last speaker) for a precision of 0.4. 2. Weighted mapping: since each degree value di in LUX(d1, d2, ? dn) represents a quintile in normal distribution, we consider the po-sition of the value within the quintile. If two mismatched values are less than ? quintile apart we assign a partial credit (currently 0.5). 3. Highest ? Rest: we measure accuracy with which the highest LU degree (but not nec-essarily the same degree) is assigned to the right speaker vs. any other score. This re-sults in binary classification of scores. The sequences in (1) produce 0.6 match score. 4. High ? Low: An alternative binary classifi-cation where scores 5 and 4 are considered High, while the remaining scores are con-sidered Low. Under this metric, the se-quences in (1) match with 100% precision. The process of automatic assignment of lan-guage uses derived from automatically proc-essed dialogues was evaluated against the control set of assignments based on hu-man-annotated data. In order to obtain a reli-able ?ground truth?, each test dialogue was annotated by at least three human coders (linguistics and communication graduate stu-dents, trained). Since human annotation was done at the linguistic component level, a strict inter-annotator agreement was not required; instead, we were interested whether in each case a comparable statistical distribution of the corresponding LU index was obtained. Annotations that produced index distributions dissimilar from the majority were eliminated. Automated dialogue processing involved the following modules: ? Local topics detection identifies first men-tions by tracking occurrences of noun phrases. Subsequent mentions are identi-fied using fairly simple pronoun resolution (based mostly on lexical features), with Wordnet used to identify synonyms, etc. ? Meso-topics are identified as longest-chain local topics. Their polarity is assessed at the utterance level by noting presence of positive or negative cue words and phrases. ? Dialogue acts are tagged based on presence 
1044
of certain cue phrases derived from a train-ing corpus (Webb et al, 2008).  ? Communicative links are mapped by com-puting inter-utterance similarity based on n-gram overlap. Preliminary evaluation results are shown in Tables 3-5 with average performance over 3 chat sessions (approx 4.5 hours) involving three groups of speakers and different tasks (job candidates, political issues). Topic Con-trol and Involvement tables show average accuracy per index. For example, the LTI in-dex, computed over automatically extracted local topics, produces Topic Control assign-ments with the average precision of 80% when compared to assignments derived from human-annotated data using the strict accu-racy metric. However, automated prediction of Involvement based on NPI index is far less reliable, although we can still pick the most involved speaker with 67% accuracy. We omit the indices based on turn length (TL) and turn count (TI) because their values are trivially computed. At this time we do not combine indices into a single LU prediction. Addi-tional experiments are needed to determine how much each of these indices contributes to LU prediction. Topic  Control LTI? SMT? CS?Strict? 0.80? 0.40? 0.40?Weighted? 0.90? 0.53? 0.53?Highest?Rest? 0.90? 0.67? 0.67?High?Low? 1.00? 0.84? 0.90?Table 3: Topic Control LU assignment performance averages of selected indices over a subset of data cov-ering three dialogues with combined duration of 4.5 hours with total of 19 participants (7, 5, 7 per session). 
Involvement NPI? TCI? ATP?Strict? 0.31? 0.42? 0.39?Weighted? 0.46? 0.49? 0.42?Highest?Rest? 0.67? 0.77? 0.68?High?Low? 0.58? 0.74? 0.48?Table 4: Involvement LU assignment performance av-erages for selected indices over the same subset of data as in Table 3. Topical Disagreement performance is shown in Table 5. We calculated precision and recall of assigning a correct degree of disagreement 
to each pair of speakers who are members of a group. Precision and recall averages are then computed over all meso-topics identified in the test dataset, which consists of three separate 90-minute dialogues involving 7, 5 and 7 speakers, respectively. Our calculation includes the cases where different sets of meso-topics were identified by the system and by the human coder. A strict mapping of levels of disagreement between speakers is hard to compute accurately; however, finding the speakers who disagree the most, or the least, is significantly more robust. 
Topical Disagreement Prec.? Recall?Strict? 0.33? 0.32?Weighted? 0.54? 0.54?Highest?Rest? 0.89? 0.85?High?Low? 0.77? 0.73?Table 5: Topical Disagreement LU assignment per-formance averages over 13 meso-topics discussed in three dialogues with combined duration of 4.5 hours with total of 19 participants (7, 5, and 7 per session). 6. Conclusion In this paper we presented a preliminary design for modeling certain types of social phenomena in multi-party on-line dialogues. Initial, limited-scale evaluation indicates that the model can be effectively automated. Much work lies ahead, including large scale evaluation, testing index stability and resilience to NL component level error. Current performance of the system is based on only preliminary versions of linguistic modules (topic extraction, polarity assignments, etc.) which perform at only 70-80% accuracy, so these need to be improved as well. Research on Urdu and Chinese dialogues is just starting. Acknowledgements This research was funded by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the U.S. Army Research Lab. All statements of fact, opinion or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of IARPA, the ODNI or the U.S. Government. 
1045
References Agar, Michael. 1994. Language Shock, Under-standing the Culture of Conversation. Quill, William Morrow, New York. Allen, J. M. Core. 1997. Draft of DAMSL: Dialog Act Markup in Several Layers. www.cs. roch-ester.edu/research/cisd/resources/damsl/  Anderson, A., et al 1991. The HCRC Map Task Corpus. Language and Speech 34(4), 351--366. Austin, J. L. 1962. How to do Things with Words. Clarendon Press, Oxford. Bird, Steven, et al 2009. Natural Language Proc-essing with Python: Analyzing Text with the Natural Language Toolkit. O'Reilly Media.  Blaylock, Nate. 2002. Managing Communicative Intentions in Dialogue Using a Collaborative Problem-Solving Model. Technical Report 774, University of Rochester, CS Dept. Broadwell, G. A et al (2010). Social Phenomena and Language Use. ILS Technical report. Carberry, Sandra and Lynn Lambert. 1999. A Process Model for Recognizing Communicative Acts and Modeling Negotiation Dialogue. Computational Linguistics, 25(1), pp. 1-53. Carletta, J. (2007). Unleashing the killer corpus: experiences in creating the multi-everything AMI Meeting Corpus. Language Resources and Evaluation Journal 41(2): 181-190 Carlson, Lauri. 1983. Dialogue Games: An Ap-proach to Discourse Analysis. D. Reidel. Eric N. Forsyth and Craig H. Martell. 2007. Lexi-cal and Discourse Analysis of Online Chat Dia-log. First IEEE International Conference on Semantic Computing (ICSC 2007), pp. 19-26. Field, D., et al 2008. Automatic Induction of Dia-logue Structure from the Companions Dialogue Corpus, 4th Int. Workshop on Human-Computer Conversation, Bellagio. Givon, Talmy. 1983. Topic continuity in discourse: A quantitative cross-language study. Amster-dam: John Benjamins.  Ivanovic, Edward. 2005. Dialogue Act Tagging for Instant Messaging Chat Sessions. In Proceed-ings of the ACL Student Research Workshop. 79?84. Ann Arbor, Michigan. Ji, Gang Jeff Bilmes. 2006. Backoff Model Train-ing using Partially Observed Data: Application to Dialog Act Tagging. HLT-NAACL Jurafsky, Dan, Elizabeth Shriberg, and Debra Bi-asca. 1997. Switchboard SWBD-DAMSL Shal-low-Discourse-Function Annotation Coders Manual. http://stripe.colorado.edu/~jurafsky/ manual.august1.html Jurafsky, D., et al 1997. Automatic detection of discourse structure for speech recognition and understanding. IEEE Workshop on Speech Recognition and Understanding, Santa Barbara. Khan, Faisal M., et al 2002. Mining Chat-room Conversations for Social and Semantic Interac-
tions. Computer Science and Engineering, Le-high University. Kim, Jihie., et al 2007. An Intelligent Discus-sion-Bot for Guiding Student Interactions in Threaded Discussions. AAAI Spring Sympo-sium on Interaction Challenges for Intelligent Assistants Levin, L., et al (1998). A discourse coding scheme for conversational Spanish. Interna-tional Conference on Speech and Language Processing. Levin, L., et al (2003). Domain specific speech acts for spoken language translation. 4th SIG-dial Workshop on Discourse and Dialogue. Linell, Per. 1990. The power of dialogue dynamics. In Ivana Markov?a and Klaus Foppa, editors, The Dynamics of Dialogue. Harvester, 147?177. Poesio, Massimo and Andrei Mikheev. 1998. The predictive power of game structure in dialogue act recognition. International Conference on Speech and Language Processing (ICSLP-98). Price, V., Capella, J. N., & Nir, L. (2002). Does disagreement contribute to more deliberative opinion? Political Communication, 19, 95-112. Sacks, H. and Schegloff, E., Jefferson, G. 1974. A simplest systematic for the organization of turn-taking for conversation. In: Language 50(4), 696-735.  Samuel, K. et al 1998. Dialogue Act Tagging with Transformation-Based Learning. 36th Annual Meeting of the ACL. Scollon, Ron and Suzanne W. Scollon. 2001. Intercultural Communication, A Discourse Ap-proach. Blackwell Publishing, Second Edition. Searle, J. R. 1969. Speech Acts. Cambridge Uni-versity Press, London-New York. Shaikh, S. et al 2010. DSARMD Annotation Guidelines, V. 2.5. ILS Technical Report.  Shaikh S. et al 2010. MPC: A Multi-Party Chat Corpus for Modeling Social Phenomena in Discourse, Proc. LREC-2010, Malta. Stolcke, Andreas et al 2000. Dialogue Act Mod-eling for Automatic Tagging and Recognition of Conversational Speech. Computational Linguis-tics, 26(3). Stromer-Galley, J. 2007. Measuring deliberation?s content: A coding scheme. Journal of Public Deliberation, 3(1).  Tianhao Wu, et al 2002. Posting Act Tagging Us-ing Transformation-Based Learning. Founda-tions of Data Mining and Discovery, IEEE In-ternational Conference on Data Mining Twitchell, Douglas P., Jay F. Nunamaker Jr., and Judee K. Burgoon. 2004. Using Speech Act Profiling for Deception Detection. Intelligence and Security Informatics, LNCS, Vol. 3073 Webb, N., T. Liu, M. Hepple and Y. Wilks. 2008. Cross-Domain Dialogue Act Tagging. 6th In-ternational Conference on Language Resources and Evaluation (LREC-2008), Marrakech. 
1046
Proceedings of the First Workshop on Metaphor in NLP, pages 67?76,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
Robust Extraction of Metaphors from Novel Data   Tomek Strzalkowski1, George Aaron Broadwell1, Sarah Taylor2, Laurie Feldman1, Boris Yamrom1, Samira Shaikh1, Ting Liu1, Kit Cho1, Umit Boz1, Ignacio Cases1 and Kyle El-liott3 1State University of New York 2Sarah M. Taylor Consulting LLC 3Plessas Experts University at Albany 121 South Oak St.  Network Inc. Albany NY USA 12222 Falls Church VA USA 22046 Herndon VA 20171 tomek@albany.edu talymail59@gmail.com  kelliot@plessas.net     Abstract 
This article describes our novel approach to the automated detection and analysis of meta-phors in text. We employ robust, quantitative language processing to implement a system prototype combined with sound social science methods for validation. We show results in 4 different languages and discuss how our methods are a significant step forward from previously established techniques of metaphor identification. We use Topical Structure and Tracking, an Imageability score, and innova-tive methods to build an effective metaphor identification system that is fully automated and performs well over baseline.  1 Introduction The goal of this research is to automatically identi-fy metaphors in textual data.  We have developed a prototype system that can identify metaphors in naturally occurring text and analyze their seman-tics, including the associated affect and force. Met-aphors are mapping systems that allow the semantics of a familiar Source domain to be ap-plied to a Target domain so that new frameworks of reasoning can emerge in the Target domain. Metaphors are pervasive in discourse, used to con-vey meanings indirectly. Thus, they provide criti-cal insights into the preconceptions, assumptions and motivations underlying discourse, especially valuable when studied across cultures. When met-aphors are thoroughly understood within the con-text of a culture, we gain substantial knowledge about cultural values. These insights can help bet-ter shape cross-cultural understanding and facili-
tate discussions and negotiations among different communities.  A longstanding challenge, however, is the large-scale, automated identification of metaphor in vol-umes of data, and especially the interpretation of their complex, underlying semantics.  We propose a data-driven computational ap-proach that can be summarized as follows: Given textual input, we first identify any sentence that contains references to Target concepts in a given Target Domain (Target concepts are elements that belong to a particular domain; for instance ?gov-ernment bureaucracy? is a Target concept in the ?Governance? domain). We then extract a passage of length 2N+1, where N is the number of sentenc-es preceding (or succeeding) the sentence with Target Concept. We employ dependency parsing to determine the syntactic structure of each input sen-tence. Topical structure and imageability analysis are then combined with dependency parsing output to locate the candidate metaphorical expressions within a sentence. For this step, we identify nouns and verbs in the passage (of length 2N+1) and link their occurrences ? including repetitions, pronomi-nal references, synonyms and hyponyms. This linking uncovers the topical structure that holds the narrative together.  We then locate content words that are outside the topical structure and compute their imageability scores. Any nouns or adjectives outside the main topical structure that also have high imageability scores and are dependency-linked in the parse structure to the Target Concept are identified as candidate source relations, i.e., expressions borrowed from a Source domain to describe the Target concept. In addition, any verbs that have a direct dependency on the Target Con-
67
cept are considered as candidate relations. These candidate relations are then used to compute and rank proto-sources. We search for their arguments in a balanced corpus, assumed to represent stand-ard use of the language, and cluster the results. Proto-source clusters and their ranks are exploited to determine whether the candidate relations are metaphorical or literal. Finally, we compute the affect and force associated with the metaphor.    Our approach is shown to work in four lan-guages ? American English, Mexican Spanish, Russian Russian and Iranian Farsi. We detail in this paper the application of our approach to detec-tion of metaphors using specific examples from the ?Governance? domain. However, our approach can be expanded to work on extracting metaphors in any domain, even unspecified ones. We shall brief-ly explain this in Section 5; we defer the details of the expanded version of the algorithm to a separate larger publication. In addition, we shall primarily present examples in English to illustrate details of our algorithms. However, modules for all four lan-guages have the same implementation in our sys-tem.  The rest of the paper is organized as follows: in Section 2, we discuss related research in this field. Section 3 presents our approach in detail; Section 4 describes our evaluation and results. In Section 5 we discuss our conclusions and future directions.  2 Related Work Most current research on metaphor falls into three groups: (1) theoretical linguistic approaches (as defined by Lakoff & Johnson, 1980; and their fol-lowers) that generally look at metaphors as abstract language constructs with complex semantic prop-erties; (2) quantitative linguistic approaches (e.g., Charteris-Black, 2002; O?Halloran, 2007) that at-tempt to correlate metaphor semantics with their usage in naturally occurring text but generally lack robust tools to do so; and (3) social science ap-proaches, particularly in psychology and anthro-pology that seek to explain how people deploy and understand metaphors in interaction, but which lack the necessary computational tools to work with anything other than relatively isolated exam-ples.     Metaphor study in yet other disciplines has in-cluded cognitive psychologists (e.g., Allbritton, McKoon & Gerrig, 1995) who have focused on the 
way metaphors may signify structures in human memory and human language processing. Cultural anthropologists, such as Malkki in her work on refugees (1992), see metaphor as a tool to help out-siders interpret the feelings and mindsets of the groups they study, an approach also reflective of available metaphor case studies, often with a Polit-ical Science underpinning (Musolff, 2008; Lakoff, 2001).      In computational investigations of metaphor, knowledge-based approaches include MetaBank (Martin, 1994), a large knowledge base of meta-phors empirically collected. Krishnakumaran and Zhu (2007) use WordNet (Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al(2006) identify a system that can recognize metaphor. However their approach is only shown to work in a narrow domain (Wall Street Journal, for example).     Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feld-man & Narayan, 2004; Shutova & Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al(2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However they self-report their work to be an initial explora-tion and hence, inconclusive. Shutova et al(2010a) employ an unsupervised method of metaphor iden-tification using nouns and verb clustering to auto-matically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quanti-ties and may not be easily generated in different languages.  By contrast, we propose an approach that is fully automated and can be validated using empirical social science methods. Details of our algorithm follow next.  3 Our Approach In this section, we walk through the steps of meta-phor identification in detail. Our overall algorithm 
68
consists of five main steps from obtaining textual input to classification of input as metaphorical or literal.  3.1 Passage Identification The input to our prototype system is a piece of text. This text may be taken from any genre ? news articles, blogs, magazines, official announcements, broadcast transcripts etc.  Given the text, we first identify sentences that contain Target concepts in the domain we are in-terested in. Target concepts are certain keywords that occur within the given domain and represent concepts that may be targets of metaphor. For in-stance, in the ?Governance? domain, concepts such as ?federal bureaucracy? and ?state mandates? serve as Target concepts. We keep a list of Target concepts to search through when analyzing given input. This list can be automatically created by mining Target Concepts from resource such as Wikipedia, given the Target domain, or manually constructed. Space limits the discussion of how such lists may be automatically created; a separate larger publication addresses our approach to this task in greater detail.  In Figure 1, we show a piece of text drawn from a 2008 news article. The sentence in italics con-tains one of our Target concepts: ?federal bureau-cracy?. We extract the sentence containing Target concepts that match any of those in our list, includ-ing N sentences before and N sentences after the sentence if they exist, to yield a passage of at most 2N+1 sentences. For the example shown in Figure 1, the Target concept is ?federal bureaucracy?. In current system prototype, N=2. Hence, we extract two sentences prior to the sentence containing ?federal bureaucracy? (in Figure 1 example, these are omitted for ease of presentation) and two sen-tences following the given sentence.       Once this passage is extracted, we need to de-termine whether a metaphor is present in the mid-dle sentence. To accomplish that, we follow the steps as described in the next section.    
 Figure 1. Excerpt from news article. Passage containing target concept highlighted in italics. The callouts 1, 2 etc., indicate topic chains (see next section).      3.2 Topical Structure and Imageability Anal-ysis Our hypothesis is that metaphorically used terms are typically found outside the topical structure of the text. This is an entirely novel method of effec-tively selecting candidate relations. It draws on  Broadwell et al (2012), who proposed a method to establish the topic chains in discourse as a means of modeling associated socio-linguistic phenomena such as topic control and discourse cohesiveness. We adapted this method to identify and exclude any words that serve to structure the core discus-sion, since the metaphorical words, except in the cases of extended and highly elaborated meta-phors, are not the main subject, and thus unlikely to be repeated or referenced in the context sur-rounding the sentence.  We link the occurrences of each noun and verb in the passage (5 sentence length). Repetitions via synonyms, hyponyms, lexical variants and pronoun references are linked together. These words, as elements of the several topic chains in a text, are then excluded from further consideration. WordNet (Felbaum, 1998) is used to look up synonyms and hyponyms of the remaining content words. We 
These qualities1 have helped him4 navigate the labyrinthine federal bureaucracy in his demand-ing $191,300-a-year job as the top federal offi-cial3 responsible for bolstering airline, border2, port and rail security against a second cata-strophic terrorist attack.  But those same personal qualities1 also explain why the 55-year-old Cabinet officer3 has alienat-ed so many Texans along the U.S.-Mexico bor-der2 with his4 relentless implementation of the Bush administration's hard-nosed approach to immigration enforcement - led by his unyielding push to construct 670 miles of border2 fencing by the end of the year.  Some Texas officials are so exasperated that they say they'll just await the arrival of the next presi-dent before revisiting border enforcement with the federal government.  Copyright 2008. The Houston Chronicle Publishing Company. All Rights Reserved.  
69
illustrate this in Figure 1. We show the two sen-tences that form the latter context in the example passage. We show four of the topic chains discov-ered in this passage. These have been labeled via superscripts in Figure 1. 1 and 2 are the repetitions of word ?qualities? and ?border?. The 3 identifies repetition via lexical variants ?officer? and ?offi-cial? and 4 identifies the pronoun co-references  ?him? and ?his?. We shall exclude these words from consideration when searching for candidate metaphorical relations in the middle sentence of the passage.  To further narrow the pool of candidate relations in this sentence, we compute the imageability scores of the remaining words. The hypothesis is metaphors use highly imageable words to convey their meaning. The use of imageability scores for the primary purpose of metaphor detection distin-guishes our approach from other research on this problem. While Turney et al (2011) explored the use of word concreteness (a concept related but not identical to imageability) in an attempt to disam-biguate between abstract and concrete verb senses, their method was not specifically applied to detec-tion of metaphors; rather it was used to classify verb senses for the purpose of resolving textual entailment. Broadwell et al (2013) present a de-tailed description of our approach and how we use imageability scores to detect metaphors. Our assertion is that any highly imageable word is more likely to be a metaphorical relation. We use the MRCPD (Coltheart 1981, Wilson 1988) expanded lexicon to look up the imageability scores of words not excluded via the topic chains. Although the MRCPD contains data for over 150,000 words, a major limitation of the database for our purposes is that the MRCPD has imageabil-ity ratings (i.e., how easily and quickly the word evokes a mental image) for only ~9,240  (6%) of the total words in its database. To fill this gap, we expanded the MRCPD database by adding imagery ratings for an further 59,989 words. This was done by taking the words for which the MRCPD data-base has an imageability rating and using that word as an index to synsets determined using WordNet (Miller, 1995). The expansion and validation of the expanded MRCPD imageability rating is presented in a separate, future publication.  Words that have an imageability rating lower than an experimentally determined threshold are further excluded from consideration. In the exam-
ple shown in Figure 1, words that have sufficiently high imageability scores are ?labyrinthine?, ?port?, ?rail? and ?airline?. We shall consider them as candidate relations, to be further investigated, as explained in the dependency parsing step described next.   3.3 Relation Extraction Dependency parsing reveals the syntactic structure of the sentence with the Target concept. We use the Stanford parser (Klein and Manning, 2003) for English language data. We identify candidate met-aphorical relations to be any verbs that have the Target concept in direct dependency path (other than auxiliary and modal verbs). We exclude verbs of attitude (?think?, ?say?, ?consider?), since these have been found to be more indicative of metony-my than of metaphor. This list of attitude verbs is automatically derived from WordNet. From the example shown in Figure 1, one of the candidate relations extracted would be the verb ?navigate?.      In addition, we have a list of candidate relations from Step 3.2, which are the highly imageable nouns and adjectives that remain after topical structure analysis. Since ?port?, ?rail? and ?airline? do not have a direct dependency path to our Target concept of ?federal bureaucracy?, we drop these from further consideration. The highly imageable word remaining in this list is ?labyrinthine?.      Thus, two candidate relations are extracted from this passage ? ?navigate? and ?labyrinthine?. We shall now show how we use these to discover pro-to-sources for the potential metaphor.  3.4 Discovery of Proto-sources Once candidate relations are identified, we exam-ine whether the usage of these relations is meta-phorical or literal. To determine this, we search for all uses of these relations in a balanced corpus and examine in which contexts the candidate relations occur. To demonstrate this via our example, we shall consider one of the candidate relations identi-fied in Figure 1 ? ?navigate?; the search method is the same for all candidate relations identified. In the case of the verb ?navigate? we search a bal-anced corpus for the collocated words, that is, those that occur within a 4-word window following the verb, with high mutual information (>3) and occurring together in the corpus with a frequency 
70
at least 3. This search returns a list of words, most-ly nouns in this case, that are the objects of the verb ?navigate?, just as ?federal bureaucracy? is the object in the given example. However, since the search occurs in a balanced corpus, given the parameters we search for, we discover words where the objects are literally navigated. Given these search parameters, the top results we get are generally literal uses of the word ?navigate?. We cluster the resulting literal uses as semantically related words using WordNet and corpus statistics. Each such cluster is an emerging prototype source domain, or a proto-source, for the potential meta-phor. In Figure 2, we show three of the clusters ob-tained when searching for the literal usage of the verb ?navigate?. We use elements of the clusters to give names or label the proto-source domains. WordNet hypernyms or synonyms are used in most cases. The clusters shown in Figure 2 represent three potential source domains for the given exam-ple, the labels ?MAZE?, ?WAY? and ?COURSE? are derived from WordNet.  
 Figure 2. Three of several clusters obtained from bal-anced corpus search for objects of verb ?navigate?.       We rank the clusters according to the combined frequency of cluster elements in the balanced cor-pus. In a similar fashion, clusters are obtained for the candidate relation ?labyrinthine?; however here we search for the nouns modified by the adjective ?labyrinthine?.       
3.5 Estimation of Linguistic Metaphor A ranked list of proto-sources from the previous step serves as evidence for the presence of a meta-phor.   If any Target domain elements are found in the top two ranked clusters, we consider the phrase being investigated to be literal. This eliminates examples where one of the most frequently en-countered sources is within the target domain.  If neither of the top two most frequent clusters contains any elements from the target domain, we then compute the average imageability scores for each cluster from the mean imageability score of the cluster elements. If no cluster has a sufficiently high imageability score (experimentally deter-mined to be >.50 in the current prototype), we again consider the given input to be literal. This step reinforces the claim that metaphors use highly imageable language to convey their meaning. If a proto-source cluster is found to meet both criteria, we consider the given phrase to be metaphorical. For the example shown in Figure 1, our system finds ?navigate the ?federal bureaucracy? to be metaphorical. One of the top Source domains iden-tified for this metaphor is ?MAZE?. Hence the conceptual metaphor output for this example can be: ?FEDERAL BUREAUCRACY IS A MAZE?. Our system can thus classify input sentences as metaphorical or literal by the series of steps out-lined above. In addition, we have modules that can determine a more complex conceptual metaphor, based upon evidence of one or more metaphorical passages as identified above. We do not discuss those modules in this article. Once a metaphor is identified, we compute associated Mappings, Af-fect and Force. 3.6 Mappings In the current prototype system, we assign meta-phors to one of three types of mappings. Propertive mappings ? which state what the domain objects  
1. Proto-source Name: MAZE Proto-source Elements: [mazes, system, net-works] IMG Score: 0.74 2. Proto-source Name: WAY Proto-source Elements: [way, tools] IMG Score: 0.60 3. Proto-source Name: COURSE Proto-source Elements: [course, streams] IMG: 0.55 
Table 1. Algorithm assigns affect of metaphor based upon mappings. 
Rel  < Negative Rel  = Neutral 
Rel ? Positive 
71
are and descriptive features; Agentive mappings ? which describe what the domain elements do to other objects in the same or different domains; and Patientive mappings ? which describe what is done to the objects in these domains. These are broad categories to which relations can, with some ex-ceptions be assigned at the linguistic metaphor lev-el by the parse tag of the relation. Relations that take Target concepts as objects are usually Pa-tientive relations. Similarly, relations that are Agentive take Target concepts as subjects. Proper-tive relations are usually determined by adjectival relations.     Once mappings are assigned, we can use them to group linguistic metaphors. A set of linguistic met-aphors on the same or semantically equivalent Target concepts can be grouped together if the re-lations are all agentive, patientive or propertive. The mapping assigned to set of examples in Figure 3 is Patientive.      One immediate consequence of the proposed approach is the simplicity with which we can rep-resent domains, their elements, and the metaphoric mappings between domains. Regardless of what specific relations may operate within a domain (be it Source or Target), they can be classified into just 3 categories. We are further expanding this module to include semantically richer distinctions within the mappings. This includes the determination of the sub-dimensions of mappings i.e. assigning groups of relations to a semantic category.  3.7 Affect and Force  Affect of a metaphor may be positive, negative or neutral. Our affect estimation module computes an affect score taking into account the relation, Target concept and the subject or object of the relation based on the dependency between relation and Target concept. The algorithm is applied according to the categories shown in Table 1.      The expanded ANEW lexicon (Bradley and Lang, 2010) is used to look up affect scores of words. ANEW assigns scores from 0 (highly nega-tive) to 9 (highly positive); 5 being neutral. We compute the affect of a metaphorical phrase within a sentence by summing the affect scores of the re-lation and its object or subject.  If the relation is agentive, we then look at the object in source do-main that the Target concept is acting upon. If the object (denoted in above table as X) has an affect 
score that is greater than neutral, and the relation itself has an affect score that is greater than neutral, then a POSITIVE affect is assigned to the meta-phor. This is denoted by the cell at the intersection of the row labeled ?Rel > Positive? and the 3rd col-umn in Table 1. Similarly affect for the other map-ping categories can be assigned.   
 Figure 3. Four metaphors for the Target concept ?feder-al bureaucracy?.   We also seek to determine the impact of metaphor on the reader. This is explored using the concept of Force in our system. The force of a metaphor is estimated currently by the commonness of the ex-pression in the given Target domain. We compute the frequency of the relation co-occurring with Target concept in a corpus of documents in the given Target domain. This frequency represents the commonness of expression, which is the in-verse of Force. The more common a metaphorical expression is, the lesser its force.     For the example shown below in Figure 4, the affect is computed to be positive (?navigate? and ?veterans? are both found to have positive affect scores, the relation is patientive). The force of this expression is low, since its commonness is 742 (commonness score > 100 is high commonness, determined experimentally).   
 Figure 4. Example of metaphor with positive affect and low force. 
1. His attorney described him as a family man who was lied to by a friend and who got tangled in federal bureaucracy he knew nothing about. 2. The chart, composed of 207 boxes illustrates the maze of federal bureaucracy that would have been created by then-President Bill Clinton's rela-tion health reform plan in the early 1990s. 3. "Helping my constituents navigate the federal bureaucracy is one of the most important things I can do," said Owens. 4. A Virginia couple has donated $1 million to help start a center at Arkansas State University meant to help wounded veterans navigate the federal bureaucracy as they return to civilian life.  
A Virginia couple has donated $1 million to help start a center at Arkansas State University meant to help wounded veterans navigate the federal bureaucracy as they return to civilian life.  
72
   The focus of this article is the automatic identifi-cation of metaphorical sentences in naturally oc-curring text. Affect and force modules are utilized to understand metaphors in context and contrast them across cultures, if feasible. We defer more detailed discussion of affect and force and their implications to a future, larger article.  4 Evaluation and Results In order to determine the efficacy of our system in classifying metaphors as well as to validate various system modules such as affect and force, we per-formed a series of experiments to collect human validation of metaphors in a large set of examples.  4.1 Experimental Setup  We constructed validation tasks that aimed at per-forming evaluation of linguistic metaphor extrac-tion accuracy. The first task ? Task 1, consists of a series of examples, typically 50, split more or less equally between those proposed by the system to be metaphorical and those proposed to be literal. This task was designed to elicit subject and expert judgments on several aspects related to the pres-ence or absence of linguistic metaphors in text. Subjects are presented with brief passages where a Target concept and a relation are highlighted. They are asked to rank their responses on a 7-point scale for the following questions:  Q1: To what degree does the above passage use metaphor to describe the highlighted concept? Q2: To what degree does this passage convey an idea that is either positive or negative?  Q3: To what degree is it a common way to express this idea?      There are additional questions that ask subjects to judge the imageability and arousal of a given pas-sage, which we do not discuss in this article. Q1 deals with assessing the metaphoricity of the ex-ample, Q2 deals with affect and Q3 deals with force.   Each instance of Task 1 consists of a set of instruc-tions, training examples, and a series of passages to be judged. Instructions provide training examples whose ratings fall at each end the rating continu-um. Following the task, participants take a gram-
mar test to demonstrate native language proficien-cy in the target language. All task instances are then posted on Amazon?s Mechanical Turk. The goal is to collect at least 30 valid judgments per task instance. We typically collect ~50 judgments from Mechanical Turkers, so that after filtering for invalid data which includes turkers selecting items at random, taking too little time to complete the task, grammar test failures, and other inconsistent data, we would still retain 30 valid judgments per passage. In addition to grammar test and time fil-ter, we also inserted instance of known metaphors and known literal passages randomly within the Task. Any turker judgments that classify these known instance incorrectly more than 30% of the total known instance size are discarded.     The valid turker judgments are then converted to a binary judgment for the questions we presented. For example, for question Q1, the anchors to 7-point scale are 0 (none at all i.e. literal) to 7 (highly i.e metaphorical). We take [0, 2] as a literal judg-ment and [4, 6] as metaphorical and take a majority vote. If the majority vote is 3, we discard that pas-sage from our test set, since it is undetermined whether the passage is literal or metaphorical.         We have collected human judgments on hun-dreds of metaphors in all four languages of inter-est. In Section 4.3, we explain our performance and compare our results to baseline where appro-priate.  4.2 Test Reliability The judgments collected from subjects are tested for reliability and validity. Reliability among the raters is computed by measuring intra-class corre-lation (ICC) (McGraw & Wong, 1996; Shrout & Fleiss, 1979). A coefficient value above 0.7 indi-cates strong reliability.  Table 3 shows the current reliability coefficients established for the selected Task 1 questions in all 4 languages. In general, our analyses have shown that with approximately 30 or more subjects we obtain a reliability coefficient of at least 0.7. We note that Russian and Farsi reliability scores are low in some categories, primarily due to lack of sufficient subject rating data. However, reliability of subject ratings for metaphor question (Q1) is sufficiently high in three of the four languages we are interested in.  
73
Dimension English Spanish Russian  Farsi Metaphor .908 .882 .838 .606 Affect  .831 .776 .318 .798 Commonness .744 .753 .753 .618 Table 3. Intraclass correlations for linguistic metaphor assessment by Mechanical Turk subjects (Task 1) 4.3 Results In Table 4, we show our performance at classifying metaphors across four different languages. The baseline in this table assigns all given examples in the test set to be metaphorical. We note that per-formance of the system at the linguistic metaphor level when compared to human gold standard is significantly over baseline for all four languages. The system performances cited in Table 4 validate the system against test sets that contain the distri-bution of metaphorical vs. literal examples as out-lined in Table 5.   English Spanish Russian Farsi Baseline 45.8% 41.7% 56.4% 50% System 71.3% 80% 69.2% 78% Table 4. Performance accuracy of system when com-pared to baseline for linguistic metaphor classification.   English Spanish Russian Farsi Metaphor 50 50 22 25 Literal 59 70 17 25 Total 109 120 39 50 Table 5. Number of metaphorical and literal examples in test sets across all four languages.  Table 6 shows the accuracy in classification by the Affect and Force modules. We note that the low performance of affect and force for languages oth-er than English. Our focus has been on improving NLP tools for Spanish, Russian and Farsi, so that a similar robust performance for those language can be achieved as we can demonstrate in English.  Accuracy English Spanish Russian Farsi Affect  72% 54% 51% 40% Force 67% 50% 33% 66% Table 6. Affect and force performance of system on linguistic metaphor level.  5 Discussion and Future Work In this article, we described in detail our approach to detecting metaphors in text. We have developed 
an automated system that does not require the ex-istence of annotated training data or a knowledge base of predefined metaphors. We have described the various steps for detecting metaphors from re-ceiving an input, to selecting candidate relations, to the discovery of prototypical source domains, and leading to the identification of a metaphor as well as the discovery of the potential source domain being applied in the metaphor. We presented two novel concepts that have heretofore not been fully explored in computational metaphor identification systems. The first is the exclusion of words that form the thread of the discussion in the text, by the application of a Topic Tracking module. The se-cond is the application of Imageability scores in the selection of salient candidate relations.  Our evaluation consists first of validating the eval-uation task itself. Once we ensure that sufficient reliability has been established on the various di-mensions we seek to evaluate ? metaphoricity, af-fect and force ? we compare our system performance to the human gold standard. The per-formance of our system as compared to baseline is quite high, across all four languages of interest when measured against human assessed gold standard.  In this article, we discuss examples of metaphors belonging to a specific Target domain ? ?Govern-ance?. However, we can run our system through data in any domain perform the same kind of met-aphor identification. In cases where the Target do-main is unknown, we plan to use our Topic tracking module to recognize content words that may form part of a metaphorical phrase. This is essentially a process that is the reverse of that de-scribed in Section 3.3. We will find the salient Target concepts where there are directly dependent relations with the imageable verbs or adjectives.  In a separate larger publication, we plan to discuss in detail revisions to our Mapping module as well as the discovery and analyses of more complex conceptual metaphors. Such complex metaphors are based upon evidence from one or more instance of linguistic metaphors. Additional modules would recognize the manifold mappings, affect and force associated with the complex conceptual metaphors.   Acknowledgments This research is supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of 
74
Defense US Army Research Laboratory contract num-ber W911NF-12-C-0024. The U.S. Government is au-thorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.  Disclaimer: The views and conclu-sions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Govern-ment. References  Allbritton, David W., Gail McKoon, and Richard J. Gerrig. 1995. Metaphor-Based Schemas and Text Representations: Making Connections Through Con-ceptual Metaphors, Journal of Experimental Psy-chology: Learning, Memory, and Cognition, Vol. 21, No. 3, pp. 612-625. Baumer, Erik. P.S., White, James., Tomlinson, Bill. 2010. Comparing Semantic Role Labeling with Typed Dependency Parsing in Computational Meta-phor Identification. Proceedings of the NAACL HLT 2010 Second Workshop on Computational Ap-proaches to Linguistic Creativity, pages 14?22, Los Angeles, California, June 2010.  Bradley, M.M. & Lang, P.J. 2010. Affective Norms for English Words (ANEW): Instruction manual and af-fective ratings. Technical Report C-2. University of Florida, Gainesville, FL. Broadwell George A., Jennifer Stromer-Galley, Tomek Strzalkowski, Samira Shaikh, Sarah Taylor, Umit Boz, Alana Elia, Laura Jiao, Ting Liu and Nick Webb. 2012. Modeling Socio-Cultural Phenomena in Discourse. Journal of Natural Language Engineer-ing, Cambridge Press. Broadwell, George A., Umit Boz, Ignacio Cases, Tomek Strzalkowski, Laurie Feldman, Sarah Taylor, Samira Shaikh, Ting Liu, Kit Cho, aand Nick Webb. 2013. Using imageability and topic chaining to locate met-aphors in linguistic corpora. in Ariel M. Greenberg, William G. Kennedy, Nathan D. Bos and Stephen Marcus, eds. Proceedings of the 6th International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction SBP 2013. Carbonell, Jaime. 1980. Metaphor: a key to extensible semantic analysis. Proceedings of the 18th Annual Meeting on Association for Computational Linguis-tics. Charteris-Black, Jonathan 2002 Second Language Fig-urative Proficiency: A Comparative Study of Malay and English. Applied Linguistics 23/1: 104-133. 
Coltheart, M. 1981. The MRC Psycholinguistic Data-base. Quarterly Journal of Experimental Psychology, 33A, 497-505. Fass, Dan. 1991. met*: A Method for Discriminating Metonymy and Metaphor by Computer. Computa-tional Linguistics, Vol 17:49-90 Feldman, J. and S. Narayanan. 2004. Embodied mean-ing in a neural theory of language. Brain and Lan-guage, 89(2):385?392. Fellbaum, C. editor. 1998. WordNet: An Electronic Lexical Database (ISBN: 0-262-06197-X). MIT Press, first edition. Gedigian, M., Bryant, J., Narayanan, S., & Ciric, B. (2006). Catching Metaphors. Proceedings of the Third Workshop on Scalable Natural Language Un-derstanding ScaNaLU 06 (pp. 41-48). Association for Computational Linguistics. Klein, Dan and Manning, Christoper D. 2003. Accurate Unlexicalized Parsing. Proceedings of the 41st Meeting of the Association for Computational Linguistics, pp. 423-430. Krishnakumaran, S. and X. Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computational Approaches to Fig-urative Language, pages 13?20, Rochester, NY. Lakoff, George and Johnson, Mark. 1980. Metaphors We Live By. University Of Chicago Press. Lakoff, George. 2001. Moral Politics: what Conserva-tives Know that Liberals Don?t. University of Chica-go Press. Malkki, Liisa. 1992. National Geographic: The Rooting of People and the Territorialization of National Iden-tity Among Scholars and Refugees. Society for Cul-tural Anthropology 7(1):24-44 Martin, James. 1988. A Computational Theory of Meta-phor. PH.D. Dissertation McGraw, K. O., & Wong, S. P. 1996. Forming infer-ences about some intraclass correlation coefficients. Psychological Methods, 1(1), 30-46. Musolff, Andreas. 2008. What can Critical Metaphor Analysis Add to the Understanding of Racist Ideolo-gy? Recent Studies of Hitler?s Anti-Semitic Meta-phors, Critical Approaches to Discourse Analysis across Disciplines, http://cadaad.org/ejournal, Vol. 2(2): 1-10. O?Halloran, Kieran. 2007. Critical Discourse Analysis and the Corpus-informed Interpretation of Metaphor at the Register Level. Oxford University Press 
75
Shrout, P. E., & Fleiss, J. L. 1979. Intraclass correla-tions: Uses in assessing rater reliability. Psychologi-cal Bulletin, 86 (2), 420-428. Shutova, E. 2010. Models of Metaphors in NLP. In Proceedings of ACL 2010, Uppsala, Sweden. Shutova, E. and S. Teufel. 2010a. Metaphor corpus an-notated for source - target domain mappings. In Pro-ceedings of LREC 2010, Malta. Shutova, E., T. Van de Cruys and A. Korhonen. 2012. Unsupervised Metaphor Paraphrasing Using a Vector Space Model, In Proceedings of COLING 2012, Mumbai, India Turney, Peter., Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identifi-cation through concrete and abstract context. In Pro-ceedings of EMNLP, pages 680?690, Edinburgh, UK Wilks, Yorick. 1975. Preference semantics. Formal Semantics of Natural Language, E. L. Keenan, Ed. Cambridge University Press, Cambridge, U.K., 329--348. Wilson, M.D. (1988) The MRC Psycholinguistic Data-base: Machine Readable Dictionary, Version 2. Be-havioural Research Methods, Instruments and Computers, 20(1), 6-11.     
76
Proceedings of the Second Workshop on Metaphor in NLP, pages 42?51,
Baltimore, MD, USA, 26 June 2014. c?2014 Association for Computational Linguistics
Computing Affect in Metaphors 
Tomek Strzalkowski1,2, Samira Shaikh1, Kit Cho1, George Aaron Broadwell1, Laurie Feldman1, Sarah Taylor3, Boris Yamrom1, Ting Liu1, Ignacio Cases1, Yuliya Peshkova1 and Kyle Elliot4 1State University of New York - Univer-sity at Albany  
2Polish Academy of Sciences 3Sarah M. Taylor Consulting LLC 4Plessas Experts Network tomek@albany.edu     Abstract 
This article describes a novel approach to automated determination of affect associ-ated with metaphorical language. Affect in language is understood to mean the at-titude toward a topic that a writer at-tempts to convey to the reader by using a particular metaphor. This affect, which we will classify as positive, negative or neutral with various degrees of intensity, may arise from the target of the meta-phor, from the choice of words used to describe it, or from other elements in its immediate linguistic context. We attempt to capture all these contributing elements in an Affect Calculus and demonstrate experimentally that the resulting method can accurately approximate human judgment. The work reported here is part of a larger effort to develop a highly ac-curate system for identifying, classifying, and comparing metaphors occurring in large volumes of text across four differ-ent languages: English, Spanish, Russian, and Farsi. 1 Introduction We present an approach to identification and val-idation of affect in linguistic metaphors, i.e., metaphorical expressions occurring in written language. Our method is specifically aimed at isolating the affect conveyed in metaphors as opposed to more broad approaches to sentiment classification in the surrounding text. We demonstrate experimentally that our basic Affect Calculus captures metaphor-related affect with a high degree of accuracy when applied to neutral metaphor targets. These are targets that them-selves do not carry any prior valuations. We sub-
sequently expanded and refined this method to properly account for the contribution of the prior affect associated with the target as well as its immediate linguistic context.  2 Metaphor in Language Metaphors are mapping systems that allow the semantics of a familiar Source domain to be ap-plied to a new Target domain so as to invite new frameworks for reasoning (usually by analogy) to emerge in the target domain. The purpose of a metaphor is (a) to simplify or enable reasoning and communication about the target domain that would otherwise be difficult (because of tech-nical complexity) or impossible (due to lack of agreed upon vocabulary) (e.g., Lakoff & John-son, 1980; 2004); or (b) to frame the target do-main in a particular way that enables one form of reasoning while inhibiting another (e.g., Thibodeau & Boroditsky, 2011). The two rea-sons for using metaphors are not necessarily mu-tually exclusive, in other words, (a) and (b) can operate at the same time. The distinction sug-gested above has to do with affect: a metaphor formed through (a) alone is likely to be neutral (e.g., client/server, messenger DNA), while a metaphor formed using (b) is likely to have a polarizing affect (e.g., tax?s burden).  The Source and Target domains that serve as endpoints of a metaphoric mapping can be repre-sented in a variety of ways; however, in a nut-shell they are composed of two kinds of things: concepts and relations. In a Target domain the concepts are typically abstract, disembodied, of-ten fuzzy concepts, such as crime, mercy, or vio-lence, but may also include more concrete, novel, or elaborate concepts such as democracy or eco-nomic inequality. In a Source domain, the con-cepts are typically concrete and physical; howev-er, mapping between two abstract domains is 
42
also possible. (E.g., crime may be both a target and a source domain.)  The relations of interest are those that operate between the concepts within a Source domain and can be ?borrowed? to link concepts within the Target domain, e.g., ?Crime(TARGET) spread to(RELATION) previously safe areas? may be bor-rowing from a DISEASE or a PARASITE source domain.  3 Related Research: metaphor detection Most current research on metaphor falls into three groups: (1) theoretical linguistic approach-es (as defined by Lakoff & Johnson, 1980; and their followers) that generally look at metaphors as abstract language constructs with complex semantic properties; (2) quantitative linguistic approaches (e.g., Charteris-Black, 2002; O?Halloran, 2007) that attempt to correlate met-aphor semantics with their usage in naturally oc-curring text but generally lack robust tools to do so; and (3) social science approaches, particular-ly in psychology and anthropology that seek to explain how people produce and understand met-aphors in interaction, but which lack the neces-sary computational tools to work with anything other than relatively isolated examples. In computational investigations of metaphor, knowledge-based approaches include MetaBank (Martin, 1994), a large knowledge base of meta-phors empirically collected. Krishnakumaran and Zhu (2007) use WordNet (Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the ex-istence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a sys-tem that can recognize metaphor; however their approach is only shown to work in a narrow do-main (The Wall Street Journal, for example).  Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman & Narayan, 2004; Shutova & Teufel, 2010; inter alia, also Shutova, 2010b for an over-view). Baumer et al. (2010) used semantic role labels and typed dependency parsing in an at-tempt towards computational metaphor identifi-cation. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute met-
aphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generated in different languages. Several other similar approaches were recently reported at the Meta4NLP 1  workshop, e.g., (Mohler et al., 2013; Wilks et al., 2013; Hovy et al., 2013). Most recently, a significantly different ap-proach to metaphor understanding based on lexi-cal semantics and discourse analysis was intro-duced by Strzalkowski et al. (2013). Space con-straints limit our discussion about their work in this article, however in the foregoing, our discus-sion is largely consistent with their framework. 4 Affect in Metaphors Affect in language is understood to mean the atti-tude toward a topic that a speaker/writer attempts to convey to the reader or audience via text or speech (van der Sluis and Mellish 2008).  It is expressed through multiple means, many of which are unrelated to metaphor. While affect in text is often associated, at least in theory, with a variety of basic emotions (anger, fear, etc.), it is generally possible to classify the set of possible affective states by polarity: positive, negative, and sometimes neutral. Affect is also considered to have a graded strength, sometimes referred to as intensity.  Our approach to affect in metaphor has been vetted not only by our core linguistic team but also by an independent team of linguist-analysts with whom we work to understand metaphor across several language-culture groups. Our re-search continues to show no difficulties in com-prehension or disagreement across languages concerning the concept of linguistic affect, of its application to metaphor, and of its having both polarity and intensity.  5 Related Research: sentiment and af-fect There is a relatively large volume of research on sentiment analysis in language (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; inter alia) that aim at detecting polarity of text, but is not specifically concerned with metaphors. A number of systems were de-veloped to automatically extract writer?s senti-                                                1 The First Workshop on Metaphor in NLP. http://aclweb.org/anthology//W/W13/W13-09.pdf 
43
ment towards specific products or services such as movies or hotels, from online reviews (e.g., Turney, 2002; Pang and Lee, 2008) or social me-dia messages (e.g., Thelwall et al., 2010). None of these techniques has been applied specifically to metaphorical language, and it is unclear if the-se alone would be sufficient due to the relatively complex semantics involved in metaphor inter-pretation. Socher et al. (2013 cite) have recently used recursive neural tensor networks to classify sentences into positive/negative categories. However, the presence of largely negative con-cepts such as ?poverty? in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2.  While presence of affect in metaphorical lan-guage is well documented in linguistic and psy-cholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who pro-posed various models of metaphor affect classifi-cation based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approach-es, which are closely related to sentiment analy-sis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual context around it.  In contrast, our objective is to isolate affect due to the metaphor itself, independently of its particular context, and also to determine how various elements of the metaphoric expression contribute to its polarity and strength. For exam-ple, we may want to know what is the affect conveyed about the Government as a target con-cept of the metaphor in ?Government regulations are crushing small businesses.? and how it dif-fers in  ?Government programs help to eradicate poverty in rural areas.? or in ?Feds plan to raise the tax on the rich.? In all these examples, there is a subtle interplay between the prior affect as-sociated with certain words (e.g., ?crush?, ?pov-erty?) and the semantic role they occupy in the sentence (e.g., agent vs. patient vs. location, etc.). Our objective is to develop an approach that can better explain such differences. Not sur-prisingly, in one of the target domains we are investigating, the Economic Inequality domain,                                                 2 https://www.cs.york.ac.uk/semeval-2013/task2/ 
there is considerable agreement on the basic atti-tudes across cultures towards the key target con-cepts: poverty is negative, wealth is positive, taxation is largely negative, and so on. This is in a marked contrast with another Target domain, the Governance domain where the target con-cepts tend to be neutral (e.g. bureaucracy, regula-tions etc.) Another important motivation in developing our approach (although not discussed in this pa-per) is to obtain a model of affect that would help to explain empirically why metaphorically rich language is considered highly influential. Persua-sion and influence literature (Soppory and Dillard, 2002) indicates messages containing metaphorical language produce somewhat great-er attitude change than messages that do not. However, some recent studies (e.g., Broadwell et al., 2012) found that lexical models of affect, sentiment, or emotion in language do not corre-late with established measures of influence, con-trary to expectations. Therefore, a different ap-proach to affect is needed based both on lexical and semantic features. We describe this new model below, and show some preliminary results in applications to metaphors interpretation. 6 Basic Affect Calculus The need for a new approach to affect arises from the inability of the current methods of sen-timent analysis to capture the affect that is con-veyed by the metaphor itself, which may be only a part of the overall affect expressed in a text. Affect conveyed in metaphors, while often more polarized than in literal language, is achieved using subtler, less explicit, and more modulated expressions. This presents a challenge for NLP approaches that base affect determination upon the presence of explicit sentiment markers in language that may mask affect arising from a metaphor. This problem becomes more challeng-ing when strong, explicit sentiment markers are present in a surrounding context or when the atti-tude of the speaker/writer towards the target con-cept is considered.  Our initial objective is thus to detect and clas-sify the portion of affect that the speaker/writer is trying to convey by choosing a specific meta-phor. The observables here are the linguistic metaphors that are actually uttered or written; therefore, our method must be able to determine affect present in the linguistic metaphors first and then extrapolate to the conceptual metaphor based on evidence across multiple uses of the 
44
same metaphor. Conceptual metaphors are posit-ed by instances of linguistic metaphors that point to the same source domain. We choose initially to model the speaker/writer perspective; howev-er, it may also be important to determine the ef-fect that a metaphor has on the reader/listener, which we do not address here. Affect in metaphor arises from the juxtaposi-tion of a Source and a Target domain through the relations explicated in linguistic metaphors. The-se relations typically involve one or more predi-cates from the source domain that are applied to a target concept. For example, in ?Government regulations are crushing small businesses.? the relation ?crushing? is borrowed from a concrete source domain (e.g., Physical Burden), and used with an abstract target concept of ?government regulation? which becomes the agentive argu-ment, i.e., crushed(GovReg, X), where X is an optional patientive argument, in this case ?small businesses?. Thus, government regulation is said to be doing something akin to ?crushing?, a harmful and negative activity according to the Affective Norms in English (ANEW) psycholin-guistic database (Bradley and Lang, 1999). Since ?government regulation? is doing something negative, the polarity of affect conveyed about it is also negative. The ANEW lexicon we are us-ing contains ratings of ~100K words. The origi-nal ANEW lexicon by Bradley and Lang was expanded following the work done by Liu et al. (2014) in expanding the MRC imageability lexi-con. While other sources of valence judgments exist such as NRC (Mohammad et al., 2013) and MPQA (Weibe and Cardie, 2005), there are limi-tations ? for instance ? NRC lexicon rates each words on a positive or negative scale, which does not allow for more fine-grained analysis of strength of valence.  Calculation from Table 1 is further general-ized by incorporating the optional second argu-ment of the relation and the role of the target concept (i.e., agentive or patientive). Thus, if X=?small business? as in the example above, the complete relation becomes crushed(GovReg, 
SmBus), which retains negative affect assuming that ?small business? is considered positive or at least neutral, an assessment that needs to be es-tablished independently. The above calculations are captured in the Af-fect Calculus (AC), which was derived from the sociolinguistic models of topical positioning and disagreement in discourse (Broadwell et al., 2013).     The Affect Calculus was conceived as a hypo-thetical model of metaphorical affect, involving the metaphor target, the source relation, as well as the arguments of this relation, one of which is the target itself. The basic version of the AC is shown in Table 1. We should note that the AC allows us to make affect inferences about any of the elements of the metaphoric relation given the values of the remaining elements. We should also note that this calculus does not yet incorpo-rate any discernable prior affect that the target concept itself may carry. When the target con-cept may be considered neutral (as is ?govern-ment regulation? when taken out of context) this table allows us to compute the affect value of any linguistic metaphor containing it. This is un-like the target concepts such as ?poverty? which bring their prior affect into the metaphor. We will return to this issue later. In the Affect Calculus table, Relation denotes a unary or binary predicate (typically a verb, an adjective, or a noun). In the extended version of the AC (Section 6) Relation may also denote a compound consisting of a predicate and one or more satellite arguments, i.e., arguments other than AGENT or PATIENT, such as ORIGIN or DES-TINATION for motion verbs, etc.  7 Extended Affect Calculus The basic Affect Calculus does not incorporate any prior affect that the target concept might bring into a metaphor. This is fine in some do-mains (e.g., Government), where most target concepts may be considered neutral. But in other target domains, such as the Economic Inequality domain, many of the target concepts have a 
Relation type Type 1 (proper-tive) Rel(Target) Type 2 (agentive) Rel (Target, X) Type 3 (patientive) Rel(X, Target) Relation/X  X ? neutral X < neutral X ? neutral X < neutral Positive POSITIVE POSITIVE ? UNSYMP POSITIVE ? SYMPAT Negative NEGATIVE ? UNSYMP ? SYMPAT ? SYMPAT ? SYMPAT Neutral NEUTRAL NEUTRAL ? NEUTRAL NEUTRAL ? NEUTRAL Table 1.  A simple affect calculus specifies affect polarity for linguistic metaphors using a 5-point polar-ity scale [negative < unsympathetic < neutral < sympathetic < positive]. X is the second argument. 
45
strong prior affect in most cultures (e.g., ?pov-erty? is universally considered negative). We thus need to incorporate this prior affect into our calculation whenever an affect-loaded target concept is invoked in a metaphor. Where the basic Affect Calculus simply imposes a context-borne affect upon a neutral target concept, the Advanced Affect Calculus must combine it with the prior affect carried by the target concept, de-pending upon the type of semantic context. As already discussed, we differentiate 3 basic se-mantic contexts (and additional contexts in the extended Affect Calculus discussed in the next section) where the target concept is positioned with respect to other arguments in a metaphorical expression:  ? Propertive context is when a property of a Target is specified (e.g. deep poverty, sea of wealth) ? Agentive context is when the Target appears as an agent of a relation that may involve an-other concept (Argument X) in the patient role (e.g. Government regulations are crush-ing?, Government programs help?) ? Patientive context is when the Target ap-pears in the patient role that involves another concept (possibly implicit, Argument X) in the agent role. (e.g. ?eradicate poverty., ?.navigate government bureaucracy)  Table 1 (in the previous section) specifies how to calculate the affect expressed towards the tar-get depending upon the affect associated with the Relation and the Argument X. In the Advanced Affect Calculus, this table specifies the context-borne affect that interacts with the affect associ-ated with the target. When the target prior affect is unknown or assumed neutral, the AC table is applied directly, as explained previously. When the target has a known polarized affect, either positive or negative, the values in the AC table are used to calculate the final affect by combin-ing the prior affect of the target with an appro-priate value from the table. This is necessary for affect-loaded target concepts such as ?poverty? or ?wealth? that have strong prior affect and can-not be considered neutral.  In order to calculate the combined affect we define two operators ? and ?. These operators form simple polarity algebra shown in Table 2. When the Target is in a Patientive relation, we use ?  to combine its affect with the context val-ue from the AC table; otherwise, we use ? .  In the table for ? operator, we note that combining opposing affects from the Target and the Rela-
tion causes the final affect to be undetermined (UND). In such cases we will take the affect of the stronger element (more polarized score) to prevail. ?  pos neg neu  ?  pos neg neu 
pos pos neg pos pos pos UND pos 
neg neg pos neg neg UND neg neg 
neu pos neg neu neu pos neg neu Table 2: Polarity algebra for extended affect calculus  More specifically, in order to determine the combined polarity score in these cases, we com-pute the distance between each element?s ANEW score and the closest boundary of the neutral range of scores. For example, ANEW scores are assigned on a 10-point continuum (derived from human judgments on 10-point Likert scale) from most negative (0) to most positive (9). Values in the range of 3.0 to 5.0 may be considered neutral (this range can be set differently for target con-cepts and relations): ? Poverty affect score = 1.67 (ANEW) ? 3 (neutral lower) = -1.33 ? Grasp affect score = 5.45 (ANEW) ? 5 (neutral upper)= +0.45 Consider the expression ?poverty?s grasp?. Since poverty is a polarized target concept in Propertive position, we use ? operator to com-bine its affect value with that of Relation (grasp). The result is negative: ? ?Poverty?s grasp? affect score (via AC?) = -1.33 + 0.45 = -0.82 (negative) When the combined score is close to 0 (-0.5 to +0.5) the final affect is neutral. 7.1 Exceptions The above calculus works in a majority of cases, but there are exceptions requiring specialized handling. An incomplete list of these is below (and cases will be added as we encounter them): Reflexive relations. In some cases the target is in the agentive position but semantically it is also a patient, as in ?poverty is spreading?. These cases need to be handled carefully ? although the current AC may be able to handle them in some contexts. When interpreted as an agentive rela-
46
tion, the affect of ?poverty is spreading? comes out as undetermined but would likely be output as negative on the basis of the strong negative affect associated with poverty (vs. weaker posi-tive affect of ?spreading?). When handled as a patientive relation (an unknown force is spread-ing poverty), it comes out clearly and strongly negative. Similarly, ?wealth is declining? is best handled through patientive relation. Therefore, for this AC we will treat intransitive relations as patientive.  Causative relations. Some relations denoted by causative verbs such as ?alleviate?, ?mitigate? or ?ease? appear to presuppose that their patient argument has negative affect, and their positive polarity already incorporates this assumption. Thus, ?alleviate? is best interpreted as ?reduce the negative of?, which inserts an extra negation into the calculation. Without considering this extra negation we would calculate ?alleviate(+) poverty(-)? as negative (doing something posi-tive to a negative concept), which is not the ex-pected reading. Therefore, the proposed special handling is to treat ?alleviate? and similar rela-tions as always producing positive affect when applied to negative targets.  8 Extensions to Basic Affect Calculus The basic model presented in the preceding sec-tion oversimplifies certain more complex cases where the metaphoric relation involves more than 2 arguments. Consequently, we are consid-ering several extensions to the basic Affect Cal-culus as suggested below. The foregoing should be treated as hypotheses subject to validation.  One possible extension involves relations rep-resented by verbs of motion (which is a common source domain) that involve satellite arguments such as ORIGIN and DESTINATION in addition to the main AGENT and PATIENT roles. Any polarity associated with these arguments may impact af-fect directed at the target concept appearing in one of the main role positions. Likewise, we need a mechanism to calculate affect for target concepts found in one of the satellite roles. In ?Federal cuts could push millions into poverty? the relation ?push into? involves three arguments: AGENT (Federal cuts), PATIENT (millions [peo-ple]) and DESTINATION (poverty). In calculating affect towards ?Federal cuts? it is not sufficient to consider the polarity of the predicate ?push? (or ?push into?), but instead one must consider the polarity of ?push into (poverty)? as the compo-site agentive relation involving ?federal cuts?. 
The polarity of this composite, in turn, depends upon the polarity of its destination argument. In other words: polarity(Rel(DEST)) = polarity (DEST) Thus, if ?poverty? is negative, then pushing someone or something into poverty is a harmful relation. Assuming that ?millions [people]? is considered at least neutral, we obtain negative affect for ?Federal cuts? from the basic Affect Calculus table. An analogous situation holds for the ?ORIGIN? argument, with the polarity reversed. Thus: polarity (Rel (ORIGIN)) = ~polarity (ORIGIN) In other words, the act of removing something from a bad place is helpful and positive. For ex-ample, in ?Higher retail wages would lift Ameri-cans out of poverty? the relation compound ?lift out of (poverty)? is considered helpful/positive. Again, once the polarity of the relation com-pound is established, the basic affect calculus applies as usual, thus we obtain positive affect towards ?higher retail wages?. In situations when both arguments are present at the same time and point towards potentially conflicting outcomes, we shall establish a precedence order based on the evidence from human validation data. Another class of multi-argument relations we are considering includes verbs that take an IN-STRUMENT argument, typically signaled by ?with? preposition. In this case, affect inference for the relation compound is postulated as fol-lows: polarity (Rel (INSTR))    = polarity (INSTR) if polarity(INSTR) < neutral   = polarity (Rel) otherwise In other words, using a negative (bad) instru-ment always makes the relation harmful, while using a positive or neutral instrument has no ef-fect on the base predicate polarity.  Other types of multi-argument relations may require similar treatment, and we are currently investigating further possible extensions. In all cases not explicitly covered in the extended Af-fect Calculus, we shall assume the default condi-tion that other satellite arguments (such as TIME, LOCATION, etc.) will have no impact on the po-larity of the source relation compound. In other words: polarity (Rel (s-role)) =default polarity (Rel) 9 Evaluation and Results For an evaluation, our objective is to construct a test that can evaluate the ability of an automated system to correctly identify and classify the af-
47
fect associated with linguistic and conceptual metaphors. A series of naturally occurring text samples containing a linguistic metaphor about a target concept are presented as input to the sys-tem. The system outputs the affect associated with the metaphor, as positive, negative, or neu-tral. The system output is then compared to hu-man generated answer key resulting in an accu-racy score. The evaluation thus consists of two components:  1. Determining the ground truth about affect in test samples;  2. Measuring the automated system?s ability to identify affect correctly.  Step 1 is done using human assessors who judge affect in a series of test samples. Assessors are presented with brief passages where a target concept and a relation are highlighted. They are asked to rank their responses on a 7-point scale for the following questions, among others: ? To what degree does the above passage use metaphor to describe the highlighted concept? ? To what degree does this passage convey an idea that is either positive or negative? It is strictly necessary that input to the system be metaphorical sentences, since affect may be associated with non-metaphoric expressions as well; in fact, some direct expressions may carry stronger affect than subtle and indirect meta-phors. This is why both questions on the survey are necessary: the first focuses the assessor?s at-tention on the highlighted metaphor before ask-ing about affect. If the purpose of the test is to measure the accuracy of assigning affect to a metaphor, then accuracy should be measured against the subset of expressions judged to be metaphorical.  The judgments collected from human asses-sors are tested for reliability and validity. Relia-bility among the raters is computed by measuring intra-class correlation (ICC) (McGraw & Wong, 1996; Shrout & Fleiss, 1979). Typically, a coef-ficient value above 0.7 indicates strong agree-ment. In general, our analyses have shown that we need approximately 30 or more subjects in order to obtain a reliability coefficient of at least 0.7. In addition, certain precautions were taken to ensure quality control in the data. We used the following criteria to discard a subject?s data: (1) completed the task too quickly (i.e., averaged fewer than 10 seconds for each passage); (2) gave the same answer to 85% or more of the test items; (3) did not pass a simple language profi-ciency test; or (4) did not provide correct an-swers to a set of randomly inserted control pas-
sages which have been previously judged by ex-perts to be unequivocally literal or metaphorical. Human judgments are collected using Amazon?s Mechanical Turk services. For each passage in surveys, we would collect at least 30 viable judgments. In addition, we have native language speakers who have been rigorously trained to provide expert judgments on metaphor and affect identification task. Table 3 shows the intra-class correlations for affect determination amongst Mechanical Turk subjects. Experiments were conducted in 4 languages: English, Spanish, Rus-sian, and Farsi.   English Spanish Russian Farsi Metaphor 0.864 0.853 0.916 0.720 Affect 0.924 0.791 0.713 0.797 Table 3: Intra-class correlations for metaphor and affect assessment by Mechanical Turk sub-jects In Figure 1, we present partial evidence that the human assessment collection method cap-tures the phenomenon of affect associated with metaphors. The chart clearly shows that affect tends to be more polarized in metaphors than in literal expressions. The chart is based on more than 11,000 affect judgments for English linguis-tic metaphors and literal expressions about Gov-ernance concepts. We see a highly pronounced tendency towards the polarization of affect (both positive and negative). Ratings of affect (y-axis) in metaphoric expressions (columns 5-7) are judged to be stronger, and in particular more negative than the literal expressions (columns 1-3). A similar trend occurs with other target con-cepts as well as other languages, although the data are less reliable due to smaller test samples. Once an answer key is established using the aforementioned procedures, system accuracy can be determined from a confusion matrix as shown in Table 4. In Table 4, we show system assign-ment of affect versus answer key for English Governance and Economic Inequality target metaphors. Overall accuracy across positive, negative and neutral affect for English test set of 220 samples is 74.5%. Analogous confusion ma-trices have been constructed for Spanish, Russian and Farsi. NLP resources such as parser and lex-icons for the languages other than English are not as robust or well rounded; therefore affect classi-fication accuracy in those languages is impacted.   
48
 Figure 1: Distribution of affect polarity in hu-man judgment of English literal and metaphori-cal expressions from the Governance domain. Metaphoricity of an expression (x-axis) is judged from highly literal (1) to highly metaphorical (7)   Table 5 shows the accuracy of affect detection for expressions that the system determined to be metaphors across all four languages under inves-tigation. Evaluation set for numbers reported in Table 5 contains a total of 526 linguistic meta-phors in these four languages.   English Affect Sample size = 220 System identified as Positive Negative Neutral 
Answ
er Key 
Positive 40 16 3 Nega-tive 12 109 1 Neutral 10 14 15  Table 4: Confusion matrix for affect classifi-cation in English linguistic metaphors in Gov-ernance and Economic Inequality Domain. Accu-racy is 74.5%   English Spanish Russian Farsi 
Accuracy 74.5% 71% 59% 64% Table 5: Performance on affect classification for linguistic metaphors in four languages 10 Conclusion In this paper we presented a new approach to automatic computing of affect in metaphors that exploits both lexical and semantic information in metaphorical expressions. Our method was eval-uated through a series of rigorous experiments 
where more than several dozen of qualified as-sessors judged hundreds of sentences (extracted from online sources) that contained metaphorical expressions. The objective was to capture affect associated with the metaphor itself. Our system can approximate human judgment with accuracy ranging from 59% for Russian to 74% for Eng-lish. These results are quite promising. The dif-ferences are primarily due to varied robustness of the language processing tools (such as parsers and morphological analyzers) that are available for each language. We note that a direct compar-ison to lexical approaches such as described by Kozareva (2013) is not possible at this time due to differences in assessment methodology, alt-hough it remains one of our objectives.  Our next step is to demonstrate that the new way of calculating affect can lead to a reliable model of affective language use that correlates with other established measures of influence.  Acknowledgements Supported by the Intelligence Advanced Re-search Projects Activity (IARPA) via Depart-ment of Defense US Army Research Laboratory contract number W911NF-12-C-0024. The U.S. Government is authorized to reproduce and dis-tribute reprints for Governmental purposes not-withstanding any copyright annotation thereon.  Disclaimer: The views and conclusions con-tained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either ex-pressed or implied, of IARPA, DoD/ARL, or the U.S. Government. References David W. Allbritton, Gail McKoon, and Richard J. Gerrig. 1995. Metaphor-based schemas and text Representations: making connections through conceptual metaphors, Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(3):612-625. Eric P. S. Baumer, James P. White, and Bill Tomlin-son. 2010. Comparing semantic role labeling with typed dependency parsing in computational meta-phor identification. In Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 14?22, Los Angeles, California.  Margaret M. Bradley, and Peter Lang. 1999. Affective norms for English words (ANEW): Instruction manual and affective ratings. Technical Report C-2. University of Florida, Gainesville, FL. George Aaron Broadwell, Umit Boz, Ignacio Cases, Tomek Strzalkowski, Laurie Feldman, Sarah Tay-
49
lor, Samira Shaikh, Ting Liu, Kit Cho, and Nick Webb. 2013. Using imageability and topic chain-ing to locate metaphors in linguistic corpora. In Proceedings of International Conference on So-cial Computing, Behavioral-Cultural Modeling, & Prediction, pages 102?109. Washington D.C. George Aaron Broadwell, Jennifer Stromer-Galley, Tomek Strzalkowski, Samira Shaikh, Sarah Tay-lor, Umit Boz, Alana Elia, Laura Jiao, Ting Liu and Nick Webb. 2012. Modeling socio-cultural phenomena in discourse. Journal of Natural Lan-guage Engineering, pages 1?45. Cambridge Press. Claudia Caffi, and Richard W. Janney. 1994. Towards a pragmatics of emotive communication. Jour-nal of Pragmatics, 22:325?373. Jaime Carbonell. 1980. Metaphor: A key to extensible semantic analysis. In Proceedings of the 18th An-nual Meeting on Association for Computational Linguistics. Jonathan, Charteris-Black. 2002. Second language figurative proficiency: A comparative study of Malay and English. Applied Linguistics 23(1):104?133. Dan, Fass. 1991. met*: A Method for Discriminating Metonymy and Metaphor by Computer. Computa-tional Linguistics, 17:49-90 Jerome Feldman, and Srinivas Narayanan. 2004. Em-bodied meaning in a neural theory of language. Brain and Language, 89(2):385?392. Christiane D. Fellbaum. 1998. WordNet: An electron-ic lexical database (1st ed.). MIT Press. Matt Gedigian, John Bryant, Srini Narayanan and Branimir Ciric. 2006. Catching Metaphors. In Proceedings of the Third Workshop on Scalable Natural Language Understanding ScaNaLU 2006, pages 41?48. New York City: NY. Dirk Hovy, Shashank Shrivastava, Sujay Kumar Jau-har, Mrinmaya Sachan, Kartik Goyal, Huying Li, Whitney Sanders and Eduard Hovy. 2013. Identi-fying Metaphorical Word Use with Tree Kernels. In the Proceedings of the First Workshop on Met-aphor in NLP, (NAACL). Atlanta. Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the 20th international conference on Computational Linguistics, COLING ?04. Zornitsa Kozareva. 2013. Multilingual Affect Polarity and   Valence Prediction in Metaphor-Rich Texts. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013) Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computation-al Approaches to Figurative Language, pages 13?20. Rochester, NY. George Lakoff, and Mark Johnson. 1980. Metaphors we live by. University Of Chicago Press, Chicago, Illinois. 
George, Lakoff. 2001. Moral politics: what conserva-tives know that liberals don?t. University of Chi-cago Press, Chicago, Illinois. Ting Liu, Kit Cho, George Aaron Broadwell, Samira Shaikh, Tomek Strzalkowski, John Lien, Sarah Taylor, Laurie Feldman, Boris Yamrom, Nick Webb, Umit Boz and Ignacio Cases. 2014. Auto-matic Expansion of the MRC Psycholinguistic Da-tabase Imageability Ratings. In Proceedings of 9th Language Resources and Evaluation Conference, (LREC 2014)Reykjavik, Iceland. Liisa, Malkki.  1992. National geographic: The root-ing of people and the territorialization of national identity among scholars and refugees. Society for Cultural Anthropology, 7(1):24?44. James Martin. 1988. A computational theory of meta-phor. Ph.D. Dissertation. Kenneth O. McGraw and S. P. Wong. 1996. Forming inferences about some intraclass correlation coef-ficients. Psychological Methods, 1(1): 30?46. Mohammad, S.M., S. Kiritchenko, and X. Zhu. 2013. NRC-Canada: Building the state-of-the-art insen-timent analysis of tweets. In Proceedings of the Seventh International Workshop on Semantic Evaluation Exercises (SemEval-2013), Atlanta, Georgia, USA, June 2013. Michael Mohler, David Bracewell, David Hinote, and Marc Tomlinson. 2013. Semantic signatures for example-based linguistic metaphor detection. In The Proceedings of the First Workshop on Meta-phor in NLP, (NAACL), pages 46?54. Musolff, Andreas. 2008. What can critical metaphor analysis add to the understanding of racist ideolo-gy? Recent studies of Hitler?s anti-semitic meta-phors, critical approaches to discourse analysis across disciplines. Critical Approaches to Dis-course Analysis Across Disciplines, 2(2):1?10. Kieran, O?Halloran. 2007. Critical discourse analysis and the corpus-informed interpretation of meta-phor at the register level. Oxford University Press Charles E. Osgood. 1981. The cognitive dynamics of synaesthesia and metaphor. In Proceedings of the National Symposium for Research in Art. Learn-ing in Art: Representation and Metaphor, pages 56-80. University of Illinois Press. Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1?135, January. Allan Pavio and Mary Walsh. 1993. Psychological processes in metaphor comprehension and memory. In Andrew Ortony, editor, Meta-phor and thought (2nd ed.). Cambridge: Cambridge University Press. Patrick E Shrout and Joseph L Fleiss. 1979. Intraclass correlations: Uses in assessing rater reliability. Psychological Bulletin, 86(2):420?428. Ekaterina Shutova. 2010. Models of metaphors in NLP. In Proceedings of ACL 2010. Uppsala, Swe-den. 
50
Ekaterina Shutova and Simone Teufel. 2010a. Meta-phor corpus annotated for source - target domain mappings. In Proceedings of Language Resources and Evaluation Conference 2010. Malta. Ekaterina Shutova. 2010b. Models of metaphor in nlp. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ?10, pages 688?697. Ekaterina Shutova, Tim Van de Cruys, and Anna Korhonen. 2012. Unsupervised metaphor para-phrasing using a vector space model In Proceed-ings of COLING 2012, Mumbai, India Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. 2013. In Proceedings Conference on Empir-ical Methods in Natural Language Processing (EMNLP 2013). Seattle, USA.  Sopory, P. and Dillard, J. P. (2002), The Persuasive Effects of Metaphor: A Meta-Analysis. Human Communication Research, 28: 382?419. doi: 10.1111/j.1468-2958.2002.tb00813.x Gerard Steen. 1994. Understanding metaphor in lit-erature: An empirical approach. London: Long-man. Carlo, Strapparava, and Rada Mihalcea. 2007. Semeval-2007 task 14: Affective text. In Proceed-ings of the Fourth International Workshop on Se-mantic Evaluations, pages 70?74. Association for Computational Linguistics. Tomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Boris Yamrom, Samira Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases and Kyle Elliott. 2013. Robust extraction of metaphor from novel data. In Proceedings of Workshop on Metaphor in NLP, NAACL. Atlanta. Mike Thelwall, Kevan Buckley, and Georgios Pato-glou. Sentiment in Twitter events. 2011. Journal of the American Society for Information Science and Technology, 62(2):406?418. Paul H. Thibodeau and Lera Boroditsky. 2011. Meta-phors We Think With: The Role of Metaphor in Reasoning. PLoS ONE 6(2): e16782. Peter D, Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised clas-sification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ?02, pages 417?424. Ielka van der Sluis,  and C. Mellish 2008. Toward affective natural language deneration: Empirical investigations. affective language in human and machine. AISB 2008 Proceedings Volume 2. Tony Veale and Guofu Li. 2012. Specifying view-point and information need with affective meta-phors: a system demonstration of the metaphor magnet web app/service. In Proceedings of the ACL 2012 System Demonstrations, ACL ?12, pag-es 7?12. Janyce, Wiebe and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. In Language Resources and Evaluation. 
Yorick, Wilks. 1975. Preference semantics. Formal Semantics of Natural Language, E. L. Keenan, Ed. Cambridge University Press, Cambridge, U.K., 329?348. Yorick Wilks, Lucian Galescu, James Allen, Adam Dalton. 2013. Automatic Metaphor Detection us-ing Large-Scale Lexical Resources and Conven-tional Metaphor Extraction. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta.  Wiebe, J., Wilson, T., and Cardie, C.: Annotating expressions of opinions and emotions in  lan-guage. Language Resources and Evaluation, 39(2-3), pp. 165-210 (2005). Li Zhang and John Barnden. 2010. Affect and meta-phor sensing in virtual drama. International Journal of Computer Games Technology. Vol. 2010.  
51
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 210?220,
Dublin, Ireland, August 23, 2014.
Discovering Conceptual Metaphors Using Source Domain Spaces 
  Samira Shaikh1, Tomek Strzalkowski1, Kit Cho1, Ting Liu1, George Aaron Broadwell1, Laurie Feldman1, Sarah Taylor2, Boris Yamrom1, Ching-Sheng Lin1, Ning Sa1, Ignacio Cases1, Yuli-ya Peshkova1 and Kyle Elliot3  1State University of New York  ? University at Albany 2Sarah M. Taylor Consulting LLC samirashaikh@gmail.com     
3Plessas Experts Network 
 Abstract This article makes two contributions towards the use of lexical resources and corpora; specifically making use of them for gaining access to and using word associations. The direct application of our approach is for detecting linguistic and conceptual metaphors automatically in text. We describe our method of building conceptual spaces, that is, defining the vocabulary that characterizes a Source Domain (e.g., Disease) of a conceptual metaphor (e.g., Poverty is a Disease). We also describe how these conceptual spaces are used to group linguistic metaphors into conceptual metaphors. Our method works in multiple languages, including English, Spanish, Russian and Farsi. We provide details of how our method can be evaluated and evaluation results that show satisfactory performance across all languages. 1 Introduction Metaphors are communicative devices that are pervasive in discourse. When understood in a cultural context, they provide insights into how a culture views certain salient concepts, typically broad, abstract concepts such as poverty or democracy. In our research, we are focusing on metaphors on targets of governance, economic inequality and democracy, although our approach works for metaphors on any target. Suppose it is found in a culture that its people use metaphors when speaking of poverty; for example, they may talk about ?symptom of poverty? or that ?poverty infects areas of the city?. These expressions are linguistic metaphors that are instances of a broader conceptual metaphor: Poverty is a Disease. Similarly, if it is found that common linguistic metaphors about poverty for peoples of a culture include ?deep hole of poverty? and ?fall into poverty?, it would lead to the conceptual metaphor: Poverty is an Abyss. A communicator wishing to speak of ways to deal with poverty would use metaphors such as ?treat poverty? and ?cure poverty? to make their framing consistent with the conceptual metaphor of Disease, whereas she would use metaphors such as ?lift out of poverty? when speaking to people who are attuned to the Abyss conceptual metaphor. Here Disease and Abyss are source domains, and poverty is the target domain. Relations, like ?symptom of?, ?infect? and ?fall into? from the respective source domains are mapped onto the target domain of poverty. In order to discover conceptual metaphors and group linguistic metaphors together, we make use of corpora to define the conceptual space that characterizes a source domain. We wish to discover the set of relations that are used literally for a given source domain, and would create metaphors if applied to some other target domain. That is, we wish to automatically discover that relations such as ?symptom?, ?infect?, ?treat? and ?cure? characterize the source domain of Disease, for example. To create the conceptual spaces, we employ a fully automated method in which we search a balanced corpus using specific search patterns. Search patterns are so created as to look for co-occurence of                                                 This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/  
210
relations with members of a given source domain. Relations could be nouns, verbs, verb phrases and adjectives that are frequently used literally within a source domain. In addition, we calculate the frequency with which relations occur in a given source domain, or Relation Frequency. We then calculate the Inverse Domain Frequency (IDF), a variant of the inverse document frequency measure quite commonly used in field of information retrieval; the IDF captures the degree of distribution of relations across all source domains under consideration. Using these two measures, the relation frequency and inverse domain frequency, we are able to rank relations within a source domain. This ranked list of relations are then used to group linguistic metaphors belonging to the same source domain together. A group of linguistic metaphors so formed is a conceptual metaphor.  2 Related Research Most current research on metaphor falls into three groups: (1) theoretical linguistic approaches (as de-fined by Lakoff & Johnson, 1980; and their followers) that generally look at metaphors as abstract language constructs with complex semantic properties; (2) quantitative linguistic approaches (e.g., Charteris-Black, 2002; O?Halloran, 2007) that attempt to correlate metaphor semantics with their us-age in naturally occurring text but generally lack robust tools to do so; and (3) social science ap-proaches, particularly in psychology and anthropology that seek to explain how people deploy and understand metaphors in interaction, but which lack the necessary computational tools to work with anything other than relatively isolated examples.     Metaphor study in yet other disciplines has included cognitive psychologists (e.g., Allbritton, McKoon & Gerrig, 1995) who have focused on the way metaphors may signify structures in human memory and human language processing. Cultural anthropologists, such as Malkki in her work on ref-ugees (1992), see metaphor as a tool to help outsiders interpret the feelings and mindsets of the groups they study, an approach also reflective of available metaphor case studies, often with a Political Sci-ence underpinning (Musolff, 2008; Lakoff, 2001).      In computational investigations of metaphor, knowledge-based approaches include MetaBank (Mar-tin, 1994), a large knowledge base of metaphors empirically collected. Krishnakumaran and Zhu (2007) use WordNet (Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfacto-rily robust in different languages. Gedigan et al (2006) identify a system that can recognize metaphor. However their approach is only shown to work in a narrow domain (Wall Street Journal, for example).     Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman & Narayan, 2004; Shutova & Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they self-report their work to be an initial exploration and hence, inconclusive. Shutova et al (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is diffi-cult to produce in large quantities and may not be easily generated in different languages.  More recently, several important approaches to metaphor extraction have emerged from the IARPA Metaphor program, including Broadwell et al (2013), Strzalkowski et al. (2014), Wilks et al (2013), Hovy et al (2013) inter alia. These papers concentrate on the algorithms for detection and classification of individual linguistic metaphors in text rather than formation of conceptual metaphors in a broader cultural context. Taylor et al (2014) outlines the rationale why conceptual level metaphors may provide important insights into cross-cultural contrasts. Our work described here is a first attempt at automatic discovery of conceptual metaphors operating within a culture directly from the linguistic evidence in language. 3 Our Approach The process of discovering conceptual metaphors is necessarily divided into two phases: (1) collecting evidence about potential source domains that may be invoked when metaphorical expressions are used; and (2) building a conceptual space for each sufficiently evidenced source domain so that linguistic metaphors can be accurately classified as instances of appropriate conceptual metaphors. In 
211
this paper, we concentrate on the second phase only. Strzalkowski et al (2013) in their work have described a data-driven linguistic metaphor extraction method and our approach builds upon their work. During the source domain evidencing phase, we established a set of 50 source domains that operate frequently with the target concepts we are focusing on (government, bureaucracy, poverty, wealth, taxation, democracy and elections). These domains were a joint effort of several teams participating in the Metaphor program and we are taking this set as a starting point. These are shown in Table 1.   A_GOD	 ? CONFINEMENT	 ? GAME	 ? MONSTER	 ? PLANT	 ?A_RIGHT	 ? CRIME	 ? GAP	 ? MORAL_DUTY	 ? PORTAL	 ?ABYSS	 ? CROP	 ? GEOGRAPHIC_FEATURE	 ? MOVEMENT	 ? POSITION	 ?AND	 ?CHANGE	 ?OF	 ?	 ?POSITION	 ?ON	 ?A	 ?SCALE	 ?ADDICTION	 ? DARKNESS	 ? GREED	 ? NATURAL_PHYSICAL_FORCE	 ? RACE	 ?ANIMAL	 ? DESTROYER	 ?	 ? HUMAN_BODY	 ? OBESITY	 ? RESOURCE	 ?BATTLE	 ? DISEASE	 ? IMPURITY	 ? PARASITE	 ? STAGE	 ?BLOOD_STREAM	 ? ENERGY	 ? LIGHT	 ? PATHWAY	 ? STRUGGLE	 ?BODY_OF_WATER	 ? ENSLAVEMENT	 ? MACHINE	 ? PHYSICAL_BURDEN	 ? THEFT	 ?BUILDING	 ? FOOD	 ? MAZE	 ? PHYSICAL_HARM	 ? VISION	 ?COMPETITION	 ? FORCEFUL_EXTRACTION	 ? MEDICINE	 ? PHYSICAL_LOCATION	 ? WAR	 ?Table 1. Set of 50 source domains that operate frequently with target concepts being investigated. Only English names are shown for ease of presentation, equivalent sets in Spanish, Russian and Farsi have been created. Some of the domains are self explanatory, while others require a further specification since the labels are sometimes ambiguous. For example, PLANT represents things that grow in the soil, not factories; similarly, BUILDING represents artifacts such as houses or edifices, but not the act of constructing something; RACE refers to a running competition, not skin color, etc.  Consequently, each of these domains need to be seeded with the prototypical representative elements to make the meaning completely clear. This seeding occurs during the first phase of the process when a linguistic expression, such as ?cure poverty? is classified as a linguistic metaphor. This process of classifying ?cure poverty? as metaphorical is described in detail in Strzalkowski et al. (2013). Part of the seeding process is to establish that a source domain different than the target domain (here: poverty) is invoked by the relation (here: cure). To find the source domain where ?cure? is typically used literally, we form a linguistic pattern [cure [OBJ: X/nn]] (derived automatically from the parsed metaphoric expression) which is subsequently run through a balanced language corpus. Arguments matching the variable X are then clustered into semantic categories, using lexical resources such as Wordnet (Felbaum, 1998) and the most frequent and concrete category is selected as a possible source domain (proto-source domain). From the balanced language corpus, it is possible to compute the frequency with which the arguments resulting from search appear with relation (?cure?). We determine concreteness by looking up concreteness score in MRC psycholinguistic database (Coltheart 1981, Wilson 1988). As may be expected, the initial elements of the proto-source obtained from the above patterns will include: disease, cancer, plague, etc. These become the seeds of the source domain DISEASE in our list. The same process was performed for each of the 50 domains listed here, for each of the 4 languages under consideration. Additional Source Domains are continously generated bottom-up fashion by this phase 1 process elaborated above. In Table 2, we show seeds so obtained for a few source domains.    DISEASE	 ? disease,	 ?cancer,	 ?plague	 ?ABYSS	 ? abyss,	 ?chasm,	 ?crevasse	 ?BODY_OF_WATER	 ? ocean,	 ?lake	 ?river,	 ?pond,	 ?sea	 ?PLANT	 ? plant,	 ?tree,	 ?flower,	 ?weed,	 ?shrub,	 ?vegetable	 ?GEOGRAPHIC_FEATURE	 ? land,	 ?land	 ?form,	 ?earth,	 ?mountain,	 ?plateau,	 ?island,	 ?valley	 ?Table 2. Example of seeds corresponding to a few source domains 
212
Once such seeds are obtained, we perform another search through a balanced corpus in the corresponding language to discover relations that characterize the source domains. The purpose of source domain spaces in our research is two-fold: a) to provide a sufficiently complete characterization of a source domain via a list of relations ; and b) such a list of relations should sufficiently distinguish between different source domains. Creating these spaces is phase 2 of the conceptual metaphor discovery process. We search for nouns, verbs and verb phrases, and adjectives that co-occur with seeds of given source domain with sufficiently high frequency and sufficiently high mutual information. Our goal with this process is to approximate normal usage patterns of relations within source domains. The results of balanced corpora search form our conceptual spaces. The balanced corpora we use are English: Corpus of Contemporary American English (Davies, 2008), Spanish:  Corpus del Espa?ol Actual (Davies, 2002), Russian: Russian National Corpus2 and Farsi: Bijankhan Corpus (Oroumchian et al., 2006). In addition to retrieving the relations, we retrieve the frequency with which these relations can be found to co-occur with seeds of a source domain, Relation Frequency (RF). We calculate Inverse Domain Frequency (IDF) of all relations across all 50 source domains using a variant of the inverse document frequency measure. The formula for IDF is as given below:  IDF = log (total number of source domains / total number of source domains a relation appears in)  For example, if a relation such as ?dive into? is found to appear in two source domains, BODY_OF_WATER and GEOGRAPHIC_FEATURE, then the IDF for ?dive into? would be log (50/2). The rank of a relation is computed as the product of RF and IDF. However, computing rank using RF without normalization results in inflated ranks for relations that are quite common across domains even when they do not sufficiently disambiguate between the domains. We assume a normal distribution of frequencies of relations within a source domain and normalize RF by taking its logarithm. We also normalize with respect to seeds within a source domain. If a relation frequency is disproportionately high with a specific seed, we disregard that frequency. For example, one of the seeds for the source domain of BUILDING is ?house?. A search through balanced corpus for nouns adjacent to ?house? revealed a disproportionately large number for ?white?, which is meant to be the White House, and would be disregarded.  In Table 3, we show a few top ranked relations for the source domains DISEASE and BODY_OF_WATER. In columns 1 and 2, we show the source domain and the relation. Column 3 shows the relation frequency and column 4 shows the part of speech of relation (V=verb or verb phrase, N=noun, ADJ=adjective). An RF score of 800 for row 1 indicates that the relation ?diagnose with? appears 800 times with one or more of the seeds we search for source domain DISEASE (?diagnose with cancer?, ?diagnose with disease? and so on. In column 5, we show the position where the relation is commonly found to co-occur with the source domain. For example, ?afflict? in row 2 has a position ?after? which means it appears after DISEASE: ?DISEASE afflict(s)?; whereas row 3 would be read as ?affict with DISEASE? since it appears ?before?. In column 6, we show the normalized RF*IDF score. The highest RF*IDF score for a relation across our spaces is 2.165. From Table 3, we can see that even if  frequency for some relations may be relatively low, their rank would be high if they are strongly associated with a single source domain.    	 ? 1.	 ?Source	 ?Domain	 ? 2.	 ?Relation	 ? 3.	 ?RF	 ? 4.	 ?Type	 ? 5.	 ?Position	 ? 6.	 ?Norm	 ?RF*IDF	 ?1	 ? DISEASE	 ? diagnose	 ?with	 ? 800	 ? V	 ? before	 ? 1.94	 ?2	 ? DISEASE	 ? afflict	 ? 85	 ? V	 ? after	 ? 1.67	 ?3	 ? DISEASE	 ? afflict	 ?with	 ? 33	 ? V	 ? before	 ? 1.52	 ?4	 ? DISEASE	 ? cure	 ?of	 ? 29	 ? N	 ? before	 ? 1.46	 ?5	 ? BODY_OF_WATER	 ? dive	 ?into	 ? 49	 ? V	 ? before	 ? 2.01	 ?6	 ? BODY_OF_WATER	 ? wade	 ?through	 ? 44	 ? V	 ? before	 ? 1.88	 ?7	 ?	 ? BODY_OF_WATER	 ? wade	 ?into	 ? 42	 ? V	 ? before	 ? 1.84	 ?8	 ? BODY_OF_WATER	 ? rinse	 ?in	 ? 41	 ? V	 ? before	 ? 1.80	 ?Table 3. A few top ranking relations for the source domains DISEASE and BODY_OF_WATER. Relations are ranked by their normalized RF*IDF score.                                                 2 http://ruscorpora.ru/en/ 
213
With the conceptual spaces defined in this manner, we can now use them to group linguistic metaphors together. Shaikh et al (2014) have created a repository of thousands of automatically extracted lingusitic metaphors in all four languages, which we are using to create conceptual metaphors. To discover which conceptual metaphors exist within such large sets of linguistic metaphors would be quite challenging, if not impossible, for a human expert. We automatically assign each linguistic metaphor to ranked list of source domains.  Consider the linguistic metaphor ?plunge into poverty?, where the relation is ?plunge into?. We search through our conceptual spaces and retrieve a list of source domains where the relation ?plunge into? may appear. From this list, only the domains that have this relation RF*IDF score higher than a threshold are considered. This threshold is currently assigned to be 0.40, although it is subject to further experimentation. The source domain where the RF*IDF score of ?plunge into? is the highest is chosen as the source domain, along with the next source domains only if the difference in scores is 5% or lower. Tables 4 and 5 depicts this part of algorithm for two relations, ?plunge into? and ?explorar? (from Spanish ? ?explore?). The relation ?plunge into? is thus assigned to BODY_OF_WATER source domain. ?explorar? is assigned to GEOGRAPHIC_FEATURE and BODY_OF_WATER since difference in RF*IDF scores is less than 5%.  Relation	 ? Source	 ?Domains	 ? RF*IDF	 ?	 ? 	 ? Relation	 ? Source	 ?Domains	 ? RF*IDF	 ?
plunge	 ?into	 ?	 ?
BODY_OF_WATER	 ? 1.82	 ? 	 ?
explorar	 ?
GEOGRAPHIC_FEATURE	 ? 0.77	 ?DARKNESS	 ? 1.28	 ? 	 ? BODY_OF_WATER	 ? 0.76	 ?ABYSS	 ? 0.68	 ? 	 ? PHYSICAL_LOCATION	 ? 0.56	 ?WAR	 ? 0.57	 ? 	 ? PATHWAY	 ? 0.56	 ?GEOGRAPHIC_FEATURE	 ? 0.48	 ? 	 ? BUILDING	 ? 0.41	 ?Table 4 and Table 5. Assigning relations of linguistic metaphor to source domains. ?plunge into? is assigned to BODY_OF_WATER; ?explorar? is assigned to GEOGRAPHIC_FEATURE and BODY_OF_WATER Once this process of assigning linguistic metaphors to source domains is accomplished for all linguistic metaphors in our repository, we validate the resulting conceptual metaphors. A small percentage of metaphors cannot be assigned to any of the 50 Source Domains. We explain the validation process in Section 4. In Tables 6 and 7, we show sample conceptual metaphors in English and Spanish. Our validation process revealed an interesting insight regarding forming conceptual metaphor, wherein they should contain relations that are anchors for that given source domain that we shall describe next.  
 Table 6. A conceptual metaphor in English: POVERTY is a BODY_OF_WATER 
214
 Table 7. A conceptual metaphor in Spanish: POVERTY is a DISEASE 3.1 Anchor relations in Conceptual Metaphors When human assessors are presented with a set of linguistic metaphors and the task to assign them into a source domain, some relations will have stronger impact on their decision that others. For example, ?cure? would almost invariably be assigned to DISEASE domain, while ?dive in? would invoke BODY_OF_WATER domain. Other relations, such as ?spread? or ?fall into? are less specific, however, when paired with highly evocative relations above are likely to be classified the same way. Thus, there are two types of metaphorical relations in linguistic metaphors: (1) the highly evocative relations that unambigously point to a specific source domain ? we shall call them anchors; and (2) the relations that are compatible with the anchor but are not anchors themselves. We can add another class: (3) the relations that are not compatible with a given anchor. Thus, a set of linguistic metaphors that provides evidence for a conceptual metaphor should contain at least some anchor relations and the balance of the set may be composed of anchor-compatible relations. Our current hypothesis is that there should be at least one anchor for each 7 anchor compatible relations for a group of linguistic metaphors to provide a sufficient evidence for a conceptual metaphor.  As part of our validation process, we conducted a series of experiments with human assessors. One of the tasks was to assign a single linguistic metaphor to one of 50 source domains. As an illustrative example, we show in Table 8, one linguistic metaphor. When presented with this example, a majority of assessors chose ENEMY source domain, while DISEASE was selected second. Additionally, there was greater variance among their selections, only 31% chose the top source domain of ENEMY.  Subsequently, human assessors were presented a set of linguistic metaphors where at least one anchor relation was present. In this case, the majority of assessors chose the DISEASE source domain. Even though the ?fight against poverty? example was included in the set, the presence of anchors such as ?cure poverty? and ?treat poverty? lead assessors to choose DISEASE source domain. The variance in selection was also less, a 70% majority choosing DISEASE. We show the conceptual metaphor in Table 9.  The	 ?summit	 ?has	 ?proven	 ?that	 ?there	 ?is	 ?a	 ?renewed	 ?appetite	 ?for	 ?the	 ?fight	 ?against	 ?poverty.	 ?	 ?ENEMY:	 ?31%;	 ?DISEASE:	 ?17%;	 ?ANIMAL,	 ?MONSTER,?.<10%	 ?Table 8. A single linguistic metaphor was assigned a varied number of source domains by human assessors.   Of	 ?course,	 ?many	 ?government	 ?programs	 ?aim	 ?to	 ?alleviate	 ?poverty.	 ?We	 ?seek	 ?to	 ?stimulate	 ?true	 ?prosperity	 ?rather	 ?than	 ?simply	 ?treat	 ?poverty.	 ?Unless	 ?the	 ?fight	 ?against	 ?poverty	 ?is	 ?honestly	 ?addressed	 ?by	 ?the	 ?West,	 ?there	 ?will	 ?be	 ?many	 ?more	 ?Afghanistans.	 ?Above	 ?all,	 ?he	 ?knows	 ?that	 ?the	 ?only	 ?way	 ?to	 ?cure	 ?poverty	 ?is	 ?to	 ?grow	 ?the	 ?economy.	 ?	 ?DISEASE:	 ?70%;	 ?ENEMY:	 ?30%	 ?Table 9. A conceptual metaphor containing anchors. When sample metaphor from Table 8 is included in this set, human assessors still choose the source domain to be DISEASE. 
215
4 Evaluation and Results A group of human experts who are native speakers and have been substantively trained to achieve high levels of agreement (0.78 Krippendorf?s alpha (1970) or higher) form our validation team. In addition, we aim to run crowd-sourced experiments on Amazon Mechanical Turk. In Figure 1, we show a web interface we built to present our human assessors. The task shown here is the assignment of a single linguistic metaphor to one of 50 source domains. Then, we present our validation team with conceptual metaphors we created. Each conceptual metaphor is validated by at least two language experts. This interface is shown in Figure 2. These interfaces are carefully created by our team of social scientists and psychologists, designed to elicit proper responses from native speakers of the language.  
 Figure 1. Interface of task where human assessors select source domain for a single linguistic metaphor.  
216
 Figure 2. Interface of task where human assessors select source domains for a conceptual metaphor. Assessors provide their top two choices along with a description detailing how they made their decision.  In Table 10, we show the number of conceptual metaphors currently in the repository and the accuracy of our method across four languages, as computed by using validation data. We show the number of conceptual metaphors present in the Governance target domain (metaphors about government and bureaucracy), Economic Inequality (dealing with metaphors of poverty, wealth and taxation) and Democracy (democracy and elections metaphors). These conceptual metaphors on the three target domains of Governace, Economic Inequality and Democracy, when compared across cultures could provide deep insight about peoples? perceptions regarding salient concepts. We note that Russian and Farsi performance is lower than that in English and Spanish. The size of balanced corpus and accuracy of lexical tools such as stemmers and morphological analyzers affect performance of our algorithm.  The Farsi balanced corpus is relatively small when compared to English balanced corpus. The smaller size affects computation of statistics such as Relation Frequency and subsequently the thresholds of RF*IDF scores. One improvement we are currently investigating is that the thresholds may be set specifically for a language.   	 ? ENGLISH	 ? SPANISH	 ? RUSSIAN	 ? FARSI	 ?#	 ?of	 ?Governance	 ?Conceptual	 ?Metaphors	 ? 27	 ? 7	 ? 8	 ? 7	 ?#	 ?of	 ?Economic	 ?Inequality	 ?Conceptual	 ?Metaphors	 ? 32	 ? 26	 ? 57	 ? 7	 ?#	 ?of	 ?Democracy	 ?	 ?Conceptual	 ?Metaphors	 ? 51	 ? 16	 ? 18	 ? 8	 ?Total	 ?#	 ?of	 ?	 ?Conceptual	 ?Metaphors	 ? 110	 ? 49	 ? 83	 ? 22	 ?Accuracy	 ?(%)	 ?	 ? 85%	 ? 76%	 ? 67%	 ? 62%	 ?Table 10. Number of conceptual metaphors discovered thus far and performance of our approach across four languages. 
217
5 Conclusion and Future Work In this article, we presented our approach towards automatic discovery of conceptual metaphors directly from linguistic evidence in a given language. We make use of corpora in two unique ways: the first is to discover prototypical seeds that form the basis of source domains and second is to create conceptual spaces that allow us to characterize the relations that operate within source domains automatically. In addition, our approach also allows us to distinguish between source domains as necessary. The validation results show that this is indeed a promising first attempt of tackling a challenging research problem.  We note that the assignment of source domains is limited to the set of 50 in our current prototype. This assumes a closed set of 50 source domains, whereas in reality, there might be many others that operate in the realm of metaphors we are investigating. Although additional source domains are continually being discovered in a bottom-up fashion by the linguistic metaphor extraction process, we cannot account for every source domain that may be relevant. One way of overcoming this limitation would be to define a source domain ?OTHER? that would be the all-encompassing domain accounting for any yet undiscovered domains. The details of how it would be represented are still under investigation.  Another potential improvement to our method is to experimentally refine the threshold score of RF*IDF. Through large scale validation experiments, we could learn the optimal thresholds automatically by using machine learning. 6 Acknowledgements This paper is based on work supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense US Army Research Laboratory contract number W911NF-12-C-0024. The U.S. Government is authorized to reproduce and distribute reprints for Governmental pur-poses notwithstanding any copyright annotation thereon.  Disclaimer: The views and conclusions con-tained herein are those of the authors and should not be interpreted as necessarily representing the of-ficial policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Gov-ernment. References David W. Allbritton, Gail McKoon, and Richard J. Gerrig. 1995. Metaphor-based schemas and text Representa-tions: making connections through conceptual metaphors, Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(3):612-625. Jonathan, Charteris-Black. 2002. Second language figurative proficiency: A comparative study of Malay and English. Applied Linguistics 23(1):104?133. George Aaron Broadwell, Umit Boz, Ignacio Cases, Tomek Strzalkowski, Laurie Feldman, Sarah Taylor, Samira Shaikh, Ting Liu and Kit Cho. 2013. Using Imageability and Topic Chaining to Locate Metaphors in Linguis-tic Corpora. In Proceedings of The 2013 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction (SBP 2013), Washington D.C., USA. Jaime Carbonell. 1980. Metaphor: A key to extensible semantic analysis. In Proceedings of the 18th Annual Meeting on Association for Computational Linguistics. M. Coltheart. 1981. The MRC Psycholinguistic Database. Quarterly Journal of Experimental Psychology, 33A: 497-505. Davies, Mark. 2008-. The Corpus of Contemporary American English: 450 million words, 1990-present. Availa-ble online at http://corpus.byu.edu/coca/. Davies, Mark. 2002-. Corpus del Espa?ol: 100 million words, 1200s-1900s. Available online at http://www.corpusdelespanol.org. Dan, Fass. 1991. met*: A Method for Discriminating Metonymy and Metaphor by Computer. Computational Linguistics, 17:49-90 Jerome Feldman, and Srinivas Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385?392. 
218
Christiane D. Fellbaum. 1998. WordNet: An electronic lexical database (1st ed.). MIT Press. Matt Gedigian, John Bryant, Srini Narayanan and Branimir Ciric. 2006. Catching Metaphors. In Proceedings of the Third Workshop on Scalable Natural Language Understanding ScaNaLU 2006, pages 41?48. New York City: NY. Dirk Hovy, Shashank Shrivastava, Sujay Kumar Jauhar, Mrinmaya Sachan, Kartik Goyal, Huying Li, Whitney Sanders and Eduard Hovy. 2013. Identifying Metaphorical Word Use with Tree Kernels. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta. Krippendorff, Klaus. 1970. Estimating the reliability, systematic error, and random error of interval da-ta. Educational and Psychological Measurement, 30 (1),61-70. Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Pro-ceedings of the Workshop on Computational Approaches to Figurative Language, pages 13?20. Rochester, NY. George Lakoff, and Mark Johnson. 1980. Metaphors we live by. University Of Chicago Press, Chicago, Illinois. George, Lakoff. 2001. Moral politics: what conservatives know that liberals don?t. University of Chicago Press, Chicago, Illinois. Liisa, Malkki.  1992. National geographic: The rooting of people and the territorialization of national identity among scholars and refugees. Society for Cultural Anthropology, 7(1):24?44. James Martin. 1988. A computational theory of metaphor. Ph.D. Dissertation. Musolff, Andreas. 2008. What can critical metaphor analysis add to the understanding of racist ideology? Recent studies of Hitler?s anti-semitic metaphors, critical approaches to discourse analysis across disciplines. Critical Approaches to Discourse Analysis Across Disciplines, 2(2):1?10. Kieran, O?Halloran. 2007. Critical discourse analysis and the corpus-informed interpretation of metaphor at the register level. Oxford University Press Farhad Oroumchian, Samira Tasharofi, Hadi Amiri, Hossein Hojjat, Fahime Raja. 2006. Creating a Feasible Corpus for Persian POS Tagging.Technical Report, no. TR3/06, University of Wollongong in Dubai. Samira Shaikh, Tomek Strzalkowski, Ting Liu, George Aaron Broadwell, Boris Yamrom, Sarah Taylor, Laurie Feldman, Kit Cho, Umit Boz, Ignacio Cases, Yuliya Peshkova and Ching-Sheng Lin. 2014. A Multi-Cultural Repository of Automatically Discovered Linguistic and Conceptual Metaphors. In Proceedings of the The 9th edition of the Language Resources and Evaluation Conference , Reykjavik, Iceland.  Ekaterina Shutova and Simone Teufel. 2010a. Metaphor corpus annotated for source - target domain mappings. In Proceedings of Language Resources and Evaluation Conference 2010. Malta. Ekaterina Shutova. 2010b. Models of metaphor in nlp. In Proceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, ACL ?10, pages 688?697. Ekaterina Shutova, Tim Van de Cruys, and Anna Korhonen. 2012. Unsupervised metaphor paraphrasing using a vector space model In Proceedings of COLING 2012, Mumbai, India Tomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Boris Yamrom, Samira Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases and Kyle Elliott. 2013. Robust extraction of metaphor from novel data. In Proceedings of Workshop on Metaphor in NLP, NAACL. Atlanta. Tomek Strzalkowski, Samira Shaikh, Kit Cho, George Aaron Broadwell, Laurie Feldman, Sarah Taylor, Boris Yamrom, Ting Liu, Ignacio Cases, Yuliya Peshkova and Kyle Elliot. 2014. Computing Affect in Metaphors. In Proceedings of the Second Workshop on Metaphor in NLP, Baltimore Maryland.  Sarah Taylor, Laurie Beth Feldman, Kit Cho, Samira Shaikh, Ignacio Cases,Yuliya  Peshkiva, George Aaron Broadwell Ting Liu, Umit Boz, Kyle Elliott. Boris Yamrom, and Tomek Strzalkowski. 2014. Extracting Un-derstanding from automated metaphor identification: Contrasting Concepts of Poverty across Cultures and Languages. AHFE Conference, Cracow, Poland. Yorick, Wilks. 1975. Preference semantics. Formal Semantics of Natural Language, E. L. Keenan, Ed. Cam-bridge University Press, Cambridge, U.K., 329?348. Yorick Wilks, Lucian Galescu, James Allen, Adam Dalton. 2013. Automatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta.  
219
Wilson, M. D. 1988. The MRC Psycholinguistic Database: Machine Readable Dictionary, Version 2. Behav-ioural Research Methods, Instruments and Computers, 20(1): 6-11. 
220
