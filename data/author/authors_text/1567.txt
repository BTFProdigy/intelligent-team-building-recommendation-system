Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 123?130,
Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language Processing
Speech to speech machine translation:
Biblical chatter from Finnish to English
David Ellis
Brown University
Providence, RI 02912
Mathias Creutz Timo Honkela
Helsinki University of Technology
FIN-02015 TKK, Finland
Mikko Kurimo
Abstract
Speech-to-speech machine translation is in
some ways the peak of natural language pro-
cessing, in that it deals directly with our
original, oral mode of communication (as
opposed to derived written language). As
such, it presents challenges that are not to be
taken lightly. Although existing technology
covers each of the steps in the process, from
speech recognition to synthesis, deriving a
model of translation that is effective in the
domain of spoken language is an interesting
and challenging task. If we could teach our
algorithms to learn as children acquire lan-
guage, the result would be useful both for
language technology and cognitive science.
We propose several potential approaches, an
implementation of a multi-path model that
translates recognized morphemes alongside
words, and a web-interface to test our speech
translation tool as trained for Finnish to En-
glish. We also discuss current approaches to
machine translation and the problems they
face in adapting simultaneously to morpho-
logically rich languages and to the spoken
modality.
1 Introduction
Effective and fluent machine translation poses many
challenges, and often requires a variety of resources.
Some are language-specific, some domain-specific,
and others manage to be relatively independent (one
might even say context-free), and thus generally ap-
plicable in a wide variety of circumstances. There
are still untapped resources, however, that might
benefit machine translation systems. Most statistical
approaches do not take into account any similarities
in word forms, so words that share a common root,
(like ?blanche? and ?bianca?, meaning ?white? in
French and Italian respectively) are no more likely to
be aligned than others (like ?vache? and ?guardare?,
meaning ?cow? and ?to watch? respectively). Such
a root is sometimes subject to vowel shift and conso-
nant gradation, and may not be reflected in orthog-
raphy, since it is often purely phonetic.
This means we are not taking advantage of every-
thing that normally benefits human speakers, hear-
ers and translators. It may be that a more natural
approach to translation would first involve under-
standing of the input, stored in some mental rep-
resentation (an interlingua), and then generation of
an equivalent phrase in the target language, directly
from the knowledge sources.
In order to allow for more dramatic differences
in grammar like agglutinativity, it seems that the
statistical machine translation (SMT) system must
be more aware of sub-word units (morphemes) and
features (phonetic similarity). This general sort of
morphological approach could potentially benefit
any language pair, but might be crucial for a sys-
tem that handles Finnish, Turkish, Hungarian, Es-
tonian or any other highly inflectional language. In
the following section we discuss the confounds pre-
sented by agglutinative languages, and how aware-
ness of morphemes might improve the situation.
This is followed by a brief foray into semantics
and natural language generation as a component of
123
SMT. Capturing phonetic features is most applicable
to speech-to-speech translation, which will be dis-
cussed in the penultimate section. A description of
the Bible conversation experiment and some of its
results can be found in the final section.
2 Agglutinative Confounds
Traditional n-gram language models and phrase-
based translation models do not work terribly well
for Finnish because each lexical item can appear in
dozens of inflected or declined forms. If an SMT
system is presented with ?taloosi? (to your house), it
will not know if that is another form of a word it saw
in training (like ?taloissaan?, in their houses). Align-
ment data are thus unnaturally sparse and test sen-
tences often contain several unknown items, which
share their stems with trained words. It has been
assumed that morphological analysis would be es-
sential for handling agglutinative languages. How-
ever, although several effective segmenters and an-
alyzers for specific languages exist, and even unsu-
pervised language-neutral versions such as Morfes-
sor (Creutz and Lagus, 2007), only recently have
similar approaches been successfully used in the
context of machine translation to improve the BLEU
score (Oflazer and El-Kahlout, 2007), and none yet
in Finnish.
In our experience, building a translation model
through stemmed (truncated) word-alignment out-
performs full-form alignment, or any morph-
segmented alignment. But once one has generated
such a translation model, including phrase tables
where stemmed forms (keys in source language)
are associated with full forms (values in target lan-
guage), is there anything to be gained from induction
of morphology? Our research in this area has yet to
reveal any positive results, but we are still working
on it. It is also worth considering the effectiveness of
the evaluation metrics. Does BLEU accurately cap-
ture the accuracy of a translation, particularly in an
agglutinative language? Unfortunately not.
We think the word segmentation in the BLEU
metric is biased against progress in morpheme-level
translation. Some other metrics have been set forth,
but none is widely accepted, in part due to inertia,
but also because translation cannot be objectively
evaluated, unless both the communicative intent and
its effectiveness can be quantified. The same prob-
lem occurs for teachers grading essays ? what was
the student intending to convey, was the phrasing
correct, the argument sound, and where does all this
diverge from the underlying power of words, written
or well said, to transmit information? Translation is
an art, and maybe in addition to human evaluation
by linguists and native speakers of the language, we
should consider the equivalent of an art or literary
critic. On the other hand, that might only be worth-
while for poetry, wherein automated translation is
perhaps not the best approach.
One might think that the stemmed model de-
scribed above would lose track of closed-class func-
tion items (like prepositions), particularly when they
are represented as inflectional morphemes in one
language but as separate words in the other. How-
ever, it seems that the language model for the target
takes care of that quite well in most cases. There
are some languages (like Japanese) with underspec-
ified noun phrases, in which efforts to preserve def-
initeness (i.e., the book, kirjan; a book, kirjaa) seem
futile, but given the abundance of monolingual data
to train LM?s on, these are contextually inferred and
corrected at the tail end of the production line. Ag-
glutinative confounds are thus very closely related to
other issues found throughout machine translation,
and perhaps an integrated solution (including a new
evaluation metric) is necessary.
3 Knowledge-Based Approaches
Incorporating statistical natural language generation
into a machine translation system involves some
modifications to the above. First, the source lan-
guage is translated or parsed into ontological rep-
resentations. This is similar to sentence parsing
techniques that can be used to induce a context-free
grammar for a language (Charniak, 1997), and could
in fact be considered one of their more useful appli-
cations. The parsing generally depends on a proba-
bilistic model trained on sentences aligned with their
syntactic and semantic representations, often in a
tree that could be generated by a context-free gram-
mar. The resulting semantic representation can then
be used as the source of a target-language generation
process.
The algorithm that generates such a representa-
124
tion from raw input could be trained on a tree-
bank, and an annotated form of the same corpus
(where the derivations in the generation space are
associated with counts for each decision made) can
be used to train the output component to generate
language. (Belz, 2005) To incorporate the statisti-
cal component, which allows for robust generaliza-
tion, per (Knight and Hatzivassiloglou, 1995), the
NLG on the target side is filtered through a language
model (described above). This helps address many
of the knowledge gap problems introduced by lin-
guistic differences or in a component of the system
- the analyzer or generator.
This approach does have significant advantages,
particularly in that it is more focused on semantics
(as opposed to statistical cooccurrence), so it may
be less likely to distort meaning. On the other hand,
it could misinterpret or miscommunicate (or both),
just like a human translator. Perhaps the crucial dif-
ference is that, while machine learning often has lit-
tle to do with our understanding of cognitive pro-
cesses, this sort of machine translation has greater
potential for illuminating mysterious areas of the hu-
man process. It is not an ersatz brain, nor neural
network, but in many ways it has more in common
with those technologies (particularly in that they
model cognition) than many natural language pro-
cessing algorithms. That is because, if we can get
a semantically-aware machine translation system to
work, it may more closely mirror human cognition.
Humans certainly do not ignore meaning when they
translate, but today?s statistical machine translation
has no awareness of it at all.
Potential disadvantages of the system include its
dependence on more resources. However, this is
less of a problem with WordNet(Miller, 1995) and
other such semantic webs. It is also worth men-
tioning again that humans always have an incred-
ible amount of information at their disposal when
translating. Not only all of their past experience and
word-knowledge, but their interlocutor?s demeanor,
manner, intonation, facial expressions, gestures, and
so on. There are often things that would be obvi-
ous in the context of a conversation, but are missing
from the transcribed text. For instance, the referent
of many pronouns is ambiguous, but usually there is
a unique individual or item picked out by the speak-
ers? shared information. This is true for simple sen-
tences like ?He hit him,? which are normally dis-
ambiguated by conversational context, but a purely
statistical, pseudo-syntactic interpretation would get
little of the meaning a human would glean from that
utterance.
4 Spoken Features
Speech-to-speech machine translation is in some
ways the peak of natural language processing, in that
it deals directly with our (humans?) original, oral
mode of communication (as opposed to derived writ-
ten language). As such, it presents challenges that
are not to be taken lightly. Much of the pipeline in-
volved is at least relatively straightforward: acoustic
modeling and language modeling on the input side
can take advantage of the latest advances without
extensive adaptation; similarly, speech synthesis on
the output can be directly connected with the system
(i.e., not work with text output, but a richer repre-
sentation).
Although such a system might seem quite com-
plicated, it could better take advantage of all the
available data. Natural language understanding and
generation could even be incorporated to an extent,
perhaps to add further confidence measures based
on semantic equivalence. Designing it in this way
also allows for a variety of methods to be tried with
ease, in a modular fashion. It may be that yet an-
other source of information can be found to improve
the translation by adding features to the translation
model ? perhaps leveraging multilingual corpora in
other languages, segmenting into morphemes earlier
in the process, or even incorporating intonation in
some fashion. Weights for all such features could
be learned during training, such that no language-
specific tuning would be necessary. This framework
would certainly not make speech-to-speech transla-
tion simple, but its flexibility might make research
and improvement in this area more tractable.
Efficiency is crucial in online translation of con-
versation, so a word alignment model with collapsed
Gibbs sampling, rather than EM, at its core is worth
experimenting with. We have written up a bare-
bones IBM Model 1 in both C++ and Python, us-
ing the standard EM approach and a Gibbs sampling
one. The latter allows for optimizations using lin-
ear algebra, and although it does not quite match the
125
perplexity or log-likelihood achieved by EM, it is
significantly faster, particularly on longer sentences.
Since morpheme segmentation is at least somewhat
helpful in speech recognition (Creutz, 2006; Creutz
et al, 2007), it should still be considered a potential
component in speech-to-speech translation. In terms
of incorporating the knowledge-based approach into
such a system, we think it may yet be too early,
but if existing understanding-and-generation frame-
works for machine translation could be adapted to
this use, it could be very fruitful, in particular since
spoken language generation might be more effective
from a knowledge base, since it would know what
it was trying to say, instead of relying on statistics
alone, hoping the phonemes end up in a meaningful
order.
The critical step of SST is, of course, transla-
tion. In an integrated system, as described above,
the translation model could be trained on a parallel
spoken corpus (perhaps tokenized into phonemes, or
segmented into morphemes), since there might be
advantages to limiting the intermediate steps in the
process. The Bible is a massively multilingual publi-
cation, and as it happens, its text is available aligned
between Finnish and English, and it is possible to
find corresponding recordings in both languages.
So, this corpus would enable a direct approach
to speech-to-speech translation. Alternatively, one
could treat the speech recognition and synthesis as
distinct from the translation, in which case text cor-
pora corresponding to the style and genre of speech
would be necessary. This would be particularly fea-
sible when, for instance, translating UN parliamen-
tary proceedings from a recording, for which trans-
lated transcripts are readily available. For a more
general and robust solution, we might advocate a
combined approach, in the hope that some potential
weaknesses of one might be avoided or compensated
for by using whatever limited resources are available
to add features from the other. Thus, a direct trans-
lation from speech to speech could be informed, in a
sense, by a derived translation from the recognized
text.
5 Biblical Chatter
Here, we present a system for translating Finnish to
English speech, in a restricted and ancient domain:
the Bible.
5.1 Introduction
Speech to speech translation attacks a variety of
problems at once, from speech recognition to syn-
thesis, and can similarly be used for several pur-
poses. If a system is efficient enough to be used
without introducing significant delay, it can trans-
late conversational speech online, acting as an in-
terpreter in place of (or in cooperation with) a hu-
man professional. On the other hand, a slow speech
translation system is still useful because it can make
news broadcasts (radio or television) accessible to
wider audiences through offline multilingual dub-
bing, allowing international viewers to enjoy a de-
layed broadcast.
5.2 System Description
The domain selected for our experiments was heav-
ily influenced by the available data. We needed a
bilingual (Finnish and English) and bimodal (text
and speech) corpus, and unfortunately none is read-
ily available, but we put one together using the
Bible. Both Old and New Testaments were used,
with one book from each left out for testing pur-
poses. We used multiple editions of the Bible to
train the translation model: the American Standard
Version (first published in 1901, updated 1997),
and Finnish translations (from 1992 and 1933,38).
The spoken recordings used were the World English
Bible (1997) and Finnish Bible (Raamattu) readings
(recorded at TKK 2004).
Our approach was to use existing components,
and try weaving them together in an optimal way.
First, there is the open vocabulary automatic speech
recognition (ASR) task, where the goal is to de-
tect phonemes in an acoustic signal and map them
to words. Here, we use an ?unlimited vocabu-
lary? continuous speech recognizer (Hirsima?ki et al,
2006), trained on a multi-speaker Finnish acoustic
model with a varigram (Siivola et al, 2007) lan-
guage model that includes Bible n-grams. Then,
for translation, Moses (Koehn et al, 2007) is trained
on words and morphemes (derived from Morfessor
Baseline (Creutz and Lagus, 2005)). For speech syn-
thesis, we used Festival (Taylor, 1999), including the
built-in English voice and a Finnish voice developed
at Helsinki University.
126
5.3 Results
The following is an example fragment, taken from
the test corpus.
Niin Daavid meni David slept with his
lepoon isiensa? luo, fathers, and was
ja ha?nethaudattiin buried in the
Daavidin kaupunkiin. city of David. The days
Nelja?kymmenta? vuotta that David reigned
ha?n oli ollut over Israel were
Israelin kuninkaana. forty years; seven
Hebronissa ha?n years reigned he
hallitsi seitsema?n in Hebron, and
vuotta, Jerusalemissa thirty-three years
kolmenkymmenenkolmen reigned he
vuoden ajan. in Jerusalem.
Salomo nousi Solomon sat on
isa?nsa? Daavidin the throne of David
valtaistuimelle,ja his father; and
ha?nen kuninkuutensa his kingdom was
vahvistui lujaksi. established greatly.
A translation of the reference text skips recogni-
tion, and runs the system from translation to synthe-
sis. The following shows how the sample text was
translated by our system (BLEU = 0.735):
Niin Daavid meni so david slept with his
lepoon isiensa? luo, fathers and was
ja ha?net haudattiin buried in the
Daavidin kaupunkiin. city of david
Nelja?kymmenta? vuotta forty years he
ha?n oli ollut was king over
Israelin kuninkaana. israel and in
Hebronissa ha?n hebron he reigned
hallitsi seitsema?n seven years
vuotta, Jerusalemissa in jerusalem
kolmenkymmenenkolmen thirty and three
vuoden ajan. years solomon
Salomo nousi went up to
isa?nsa? Daavidin the throne of
valtaistuimelle, ja david his father
ha?nen kuninkuutensa and his kingdom
vahvistui lujaksi. was strong for luja
The following recognized translation (BLEU =
0.541) represents a complete run of the system. The
recognition (on the left) had a LER of 12.9% and a
WER of 56.8%.
niintaa meni niintaa went
lepoon isiensa?lla isiensa?lla rest and was
ja ha?net haudattiin buried in the
daavidin kaupunkiin city of david the king
nelja?kymmenta? of israel was
vuotta ha?n oli ollut forty years he was
israelin kuninkaan in hebron he
hebronissa ha?n reigned seven years
hallitsi seitsema?n in jerusalem
vuotta jerusalemissa kymmenenkolmen
kolmen kymmenenkolmen three years
vuoden ajan after the new
salomon uusi on the throne of david
isa?nsa? daavidin and solomon
valtaistuimelle ja his father
ha?nenkuninkuutensa ha?nenkuninkuutensa
valmistulujaksi valmistulujaksi
Here we have an alternative path through the sys-
tem, which uses Morfessor on the recognized text,
and then translates using a model trained on the
morpheme-segmented corpus. This results in a re-
duced score (BLEU = 0.456), but fewer unknown
words.
n iin taa# meni# iin behind went to
lepo on# isi ensa? lla# the sabbath that
ja# ha?n et# hauda ttiin# is with ensa? and he
daavid in# kaupunki in# shall not at the grave of abner
nelja?kymmenta?# vuotta# was forty years of the
ha?n# oli# ollut# city of david and
israeli n kuninkaan# he was israeli to
hebron issa# ha?n# the king of hebron
hallitsi# seitsema?n# and he reigned
vuotta# jerusalem seven years in
issa# kolmen# jerusalem three tenth
kymmenen kolmen# three years of
vuoden# ajan# the new solomon his
salomo n# uusi# isa? istuim to david
nsa?# daavid in# my father of the
valta istuim elle# kingdoms of
ja# ha?n en kun ink ink and he
uutensa# valmistu luja ksi# uutensa valmistu to luja
The morphemes might have been more effective
in translation if they had been derived through rule-
based morphological analysis. Or, they could still be
statistical, but optimized for the translation phase by
minimizing perplexity during word alignment.
A significant barrier to thorough and concrete
evaluation of our system involves segmentation of
the speech stream into sentences (or verses) to match
the text. In the above examples, we manually
clipped the audio files. Evaluating performance on
the entire test set reduced the BLEU score if the
data were streamed through each component unseg-
mented. When the recognizer was set to insert a pe-
riod for detected pauses of a certain length, or at sen-
tence boundaries identified by its language model,
127
input to the translation phase became considerably
more problematic. In particular, the lattice input
ought to be split into sentences, but there would usu-
ally be a period in every time slice (but with low
probability).
5.4 Discussion
There were significant difficulties in the process,
particularly in the English to Finnish direction.
Whereas Finnish speech recognition is relatively
straightforward, since its orthography is consistent,
English speech recognition is more dependent on
a pronunciation dictionary. Although many such
dictionaries are available, and the pronunciation of
novel words can be estimated, neither of these re-
sources is terribly effective within the Bible domain,
where there are many archaic words and names. In
the second step, translation into Finnish is demon-
strably difficult from any source language, and re-
sults in consistently lower BLEU scores (Virpioja
et al, 2007). And although using morphemes can
reduce the frequency of unknown words, it also re-
duces the BLEU score.
It might improve translation quality if we use the
recognizer lattice as translator input, since acous-
tically improbable segments may lead to the most
fluent translation. Having access to many possibili-
ties might help the translation model, but then again,
second-guessing the recognizer might not be help-
ful. There were some difficulties with the Moses in-
tegration, in part because the word-sausage format
varies from SRILM?s. Also, the recognizer output
indicates word boundaries as <w>, not string-final
hash-marks (#). This is problematic since the for-
mer are separate symbols, occupying a node in the
lattice, whereas the latter are appended to another
symbol (e.g., ?<w> morph eme </w>?, 4 nodes,
versus ?morph eme#?, 2 nodes). Using the lattice,
final output from Moses tends to be more fluent,
but less on-topic, and often truncated. Although we
have no improvements thus far, it is likely that with
further parameter tuning, we could achieve better re-
sults. On the other hand, we seek a general, robust,
domain-independent solution, so focusing on Bible
translation may not be worthwhile.
Our speech-to-speech translation system is
accessible through a web interface.
http://www.cis.hut.fi/projects/speech/
translate/
It accepts a sound file, with recorded Finnish
bible-style chatter, an optional reference text and
translation, and within a half hour (usually much
less) sends a detailed report, including a sound file
with the synthesized English.
Ideas for future research include online speech-
to-speech translation, which must be efficient, light-
weight and robust. A potential barrier to this and
other applications is the lack of spoken language
training texts. It might be possible to adaptively train
to new speakers and contexts, perhaps taking advan-
tage of an efficient alternative to EM in word align-
ment (see discussion of Gibbs sampling). As men-
tioned elsewhere, it might be worth using prosodic
features captured during recognition as factors in
translation. Adapting existing resources to new lan-
guage pairs is particularly essential in an area where
so much is necessary, and so little available.
6 Conclusion
We cannot yet say for sure whether linguistic or
statistically optimized morphemes derived from text
corpora could be useful somehow in machine trans-
lation, but it has been demonstrated helpful in
speech recognition. Awareness of sub-word units
could benefit a speech-to-speech translation system,
and it may in fact help to maintain information
from the speech recognizer about morpheme seg-
mentation throughout the translation process, even
in speech generation. Incorporating natural lan-
guage understanding may also be fruitful, but for
compact, efficient systems (like a handheld transla-
tor) might not have access to the necessary resources
or computational power to support that. On the other
hand, it is our duty as researchers to stay ahead of the
technology and push its limits.
We are by no means the first to imagine this, but
perhaps we will soon be speaking into wrist watches
that understand our query, seemingly instantly shift
through more information than Google has currently
indexed, and reply in fluent English, Finnish, or Pun-
jabi with as much detail as could be hoped for after
hours of painstaking research with current technol-
ogy. In this case (and computational linguists must
always be optimistic), knowledge-based natural lan-
guage processing certainly has a crucial place.
128
Morphemes and agglutinative languages do pose
unique problems for computational linguists, but
many of the general techniques developed for lan-
guages like Arabic and Chinese, which are equally
far from English in grammar (and even orthogra-
phy), might surmount those problems without any
manual adaptation. Discriminative training of fea-
tures used in the translation model allows for such
solutions to be molded automatically to whatever
language pair (and set of corpora) they are being
used for. There is, as always, much more to be done
in this area, and we hope our research into efficient,
online Bible-conversational translation ? a modern
Babelfish in an ancient genre? is fruitful, and helps
to shed light on lemmatization.
Acknowledgments
Many thanks to Teemu Hirsima?ki, Antti Puurula,
Sami-Virpioja and Jaakko J. Va?yrynen for their
help with components of the system and for their
thoughts and comments at various stages of the
project.
References
Anja Belz. 2005. Statistical generation: Three methods
compared and evaluated. In Proceedings of the 10th
European Workshop on Natural Language Generation
(ENLG05), pages 15?23.
Eugene Charniak. 1997. Statistical parsing with
a context-free grammar and word statistics. In
AAAI/IAAI, pages 598?603.
Mathias Creutz and Krista Lagus. 2005. Unsupervised
morpheme segmentation and morphology induction
from text corpora using Morfessor 1.0. Technical Re-
port A81, Publications in Computer and Information
Science, Helsinki University of Technology.
Mathias Creutz and Krista Lagus. 2007. Unsupervised
models for morpheme segmentation and morphology
learning. ACM Transactions on Speech and Language
Processing, 4(1), January.
Mathias Creutz, Teemu Hirsim?ki, Mikko Kurimo, Antti
Puurula, Janne Pylkknen, Vesa Siivola, Matti Var-
jokallio, Ebru Arisoy, Murat Saraclar, and Andreas
Stolcke. 2007. Analysis of morph-based speech
recognition and the modeling of out-of-vocabulary
words across languages. In Proceedings of Hu-
man Language Technologies / The Annual Conference
of the North American Chapter of the Association
for Computational Linguistics (HLT-NAACL 2007),
Rochester, NY, USA.
Mathias Creutz. 2006. Morfessor in the morpho chal-
lenge. In Mikko Kurimo, Mathias Creutz, and Krista
Lagus, editors, Proceedings of the PASCAL Challenge
Workshop on Unsupervised Segmentation of Words
into Morphemes, Venice, Italy.
T. Hirsima?ki, M. Creutz, V. Siivola, M. Kurimo, S. Vir-
pioja, and J. Pylkko?nen. 2006. Unlimited vocabu-
lary speech recognition with morph language models
applied to Finnish. Computer Speech and Language,
20(4):515?541.
Kevin Knight and Vasileios Hatzivassiloglou. 1995.
Two-level, many-paths generation. In Proceedings of
the 33rd annual meeting on Association for Compu-
tational Linguistics, pages 252?260, Morristown, NJ,
USA. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Ondrej Bojar, Alexandra Constantin, and Evan
Herb. 2007. Moses: Open source toolkit for statistical
machine translation. In Proceedings of the ACL 2007
Demo and Poster Sessions, pages 177?180.
George A. Miller. 1995. Wordnet: a lexical database for
English. Commun. ACM, 38(11):39?41.
Kemal Oflazer and Ilknur Durgar El-Kahlout. 2007. Ex-
ploring different representational units in English-to-
Turkish statistical machine translation. In Proceedings
of the ACL 2007 Demo and Poster Sessions, pages 25?
32.
Vesa Siivola, Teemu Hirsima?ki, and Sami Virpioja. 2007.
On growing and pruning Kneser-Ney smoothed n-
gram models. IEEE Transactions on Audio, Speech
and Language Processing, 15(5):1617?1624.
Paul Taylor. 1999. The Festival Speech Architecture.
Web page.
Sami Virpioja, Jaakko J. Va?yrynen, Mathias Creutz, and
Markus Sadeniemi. 2007. Morphology?aware statis-
tical machine translation based on morphs induced in
an unsupervised manner. In Proceedings of the Ma-
chine Translation Summit XI, Copenhagen, Denmark.
To appear.
129
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
130
Proceedings of NAACL HLT 2007, pages 380?387,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Analysis of Morph-Based Speech Recognition and the Modeling of
Out-of-Vocabulary Words Across Languages
Mathias Creutz?, Teemu Hirsima?ki?, Mikko Kurimo?, Antti Puurula?, Janne Pylkko?nen?,
Vesa Siivola?, Matti Varjokallio?, Ebru Ar?soy?, Murat Sarac?lar?, and Andreas Stolcke?
? Helsinki University of Technology, <firstname>.<lastname>@tkk.fi,
? Bog?azic?i University, arisoyeb@boun.edu.tr, murat.saraclar@boun.edu.tr,
? SRI International / International Computer Science Institute, stolcke@speech.sri.com
Abstract
We analyze subword-based language
models (LMs) in large-vocabulary
continuous speech recognition across
four ?morphologically rich? languages:
Finnish, Estonian, Turkish, and Egyptian
Colloquial Arabic. By estimating n-gram
LMs over sequences of morphs instead
of words, better vocabulary coverage
and reduced data sparsity is obtained.
Standard word LMs suffer from high
out-of-vocabulary (OOV) rates, whereas
the morph LMs can recognize previously
unseen word forms by concatenating
morphs. We show that the morph LMs
generally outperform the word LMs and
that they perform fairly well on OOVs
without compromising the accuracy
obtained for in-vocabulary words.
1 Introduction
As automatic speech recognition systems are being
developed for an increasing number of languages,
there is growing interest in language modeling ap-
proaches that are suitable for so-called ?morpholog-
ically rich? languages. In these languages, the num-
ber of possible word forms is very large because
of many productive morphological processes; words
are formed through extensive use of, e.g., inflection,
derivation and compounding (such as the English
words ?rooms?, ?roomy?, ?bedroom?, which all stem
from the noun ?room?).
For some languages, language modeling based on
surface forms of words has proven successful, or at
least satisfactory. The most studied language, En-
glish, is not characterized by a multitude of word
forms. Thus, the recognition vocabulary can sim-
ply consist of a list of words observed in the training
text, and n-gram language models (LMs) are esti-
mated over word sequences. The applicability of the
word-based approach to morphologically richer lan-
guages has been questioned. In highly compounding
languages, such as the Germanic languages German,
Dutch and Swedish, decomposition of compound
words can be carried out to reduce the vocabulary
size. Highly inflecting languages are found, e.g.,
among the Slavic, Romance, Turkic, and Semitic
language families. LMs incorporating morphologi-
cal knowledge about these languages can be applied.
A further challenging category comprises languages
that are both highly inflecting and compounding,
such as the Finno-Ugric languages Finnish and Es-
tonian.
Morphology modeling aims to reduce the out-
of-vocabulary (OOV) rate as well as data sparsity,
thereby producing more effective language mod-
els. However, obtaining considerable improvements
in speech recognition accuracy seems hard, as is
demonstrated by the fairly meager improvements
(1?4 % relative) over standard word-based models
accomplished by, e.g., Berton et al (1996), Ordel-
man et al (2003), Kirchhoff et al (2006), Whit-
taker and Woodland (2000), Kwon and Park (2003),
and Shafran and Hall (2006) for Dutch, Arabic, En-
glish, Korean, and Czech, or even the worse perfor-
mance reported by Larson et al (2000) for German
and Byrne et al (2001) for Czech. Nevertheless,
clear improvements over a word baseline have been
achieved for Serbo-Croatian (Geutner et al, 1998),
Finnish, Estonian (Kurimo et al, 2006b) and Turk-
ish (Kurimo et al, 2006a).
In this paper, subword language models in the
recognition of speech of four languages are ana-
380
lyzed: Finnish, Estonian, Turkish, and the dialect
of Arabic spoken in Egypt, Egyptian Colloquial
Arabic (ECA). All these languages are considered
?morphologically rich?, but the benefits of using
subword-based LMs differ across languages. We at-
tempt to discover explanations for these differences.
In particular, the focus is on the analysis of OOVs:
A perceived strength of subword models, when con-
trasted with word models, is that subword models
can generalize to previously unseen word forms by
recognizing them as sequences of shorter familiar
word fragments.
2 Morfessor
Morfessor is an unsupervised, data-driven, method
for the segmentation of words into morpheme-like
units. The general idea is to discover as com-
pact a description of the input text corpus as possi-
ble. Substrings occurring frequently enough in sev-
eral different word forms are proposed as morphs,
and the words in the corpus are then represented
as a concatenation of morphs, e.g., ?hand, hand+s,
left+hand+ed, hand+ful?. Through maximum a pos-
teriori optimization (MAP), an optimal balance is
sought between the compactness of the inventory of
morphs, i.e., the morph lexicon, versus the compact-
ness of the representation of the corpus.
Among others, de Marcken (1996), Brent (1999),
Goldsmith (2001), Creutz and Lagus (2002), and
Creutz (2006) have shown that models based on
the above approach produce segmentations that re-
semble linguistic morpheme segmentations, when
formulated mathematically in a probabilistic frame-
work or equivalently using the Minimum Descrip-
tion Length (MDL) principle (Rissanen, 1989).
Similarly, Goldwater et al (2006) use a hierarchical
Dirichlet model in combination with morph bigram
probabilities.
The Morfessor model has been developed over
the years, and different model versions exist. The
model used in the speech recognition experiments of
the current paper is the original, so-called Morfes-
sor Baseline algorithm, which is publicly available
for download.1. The mathematics of the Morfessor
Baseline model is briefly outlined in the following;
consult Creutz (2006) for details.
1http://www.cis.hut.fi/projects/morpho/
2.1 MAP Optimization Criterion
In slightly simplified form, the optimization crite-
rion utilized in the model corresponds to the maxi-
mization of the following posterior probability:
P (lexicon | corpus) ?
P (lexicon) ? P (corpus | lexicon) =
?
letters ?
P (?) ?
?
morphs ?
P (?). (1)
The lexicon consists of all distinct morphs spelled
out; this forms a long string of letters ?, in which
each morph is separated from the next morph using
a morph boundary character. The probability of the
lexicon is the product of the probability of each let-
ter in this string. Analogously, the corpus is repre-
sented as a sequence of morphs, which corresponds
to a particular segmentation of the words in the cor-
pus. The probability of this segmentation equals the
product of the probability of each morph token ?.
Letter and morph probabilities are maximum likeli-
hood estimates (empirical Bayes).
2.2 From Morphs to n-Grams
As a result of the probabilistic (or MDL) approach,
the morph inventory discovered by the Morfessor
Baseline algorithm is larger the more training data
there is. In some speech recognition experiments,
however, it has been desirable to restrict the size of
the morph inventory. This has been achieved by set-
ting a frequency threshold on the words on which
Morfessor is trained, such that the rarest words will
not affect the learning process. Nonetheless, the
rarest words can be split into morphs in accordance
with the model learned, by using the Viterbi algo-
rithm to select the most likely segmentation. The
process is depicted in Figure 1.
2.3 Grapheme-to-Phoneme Mapping
The mapping between graphemes (letters) and
phonemes is straightforward in the languages stud-
ied in the current paper. More or less, there is
a one-to-one correspondence between letters and
phonemes. That is, the spelling of a word indicates
the pronunciation of the word, and when splitting the
word into parts, the pronunciation of the parts in iso-
lation does not differ much from the pronunciation
of the parts in context. However, a few exceptions
381
Morph
inventory
+ probs
n?grams
Train
cut?off
Frequency
Viterbi
segm.
Text with words
segmented into
LM
morphs
MorfessorExtractwords
Text corpus
Figure 1: How to train a segmentation model using
the Morfessor Baseline algorithm, and how to fur-
ther train an n-gram model based on morphs.
have been treated more rigorously in the Arabic ex-
periments: e.g., in some contexts the same (spelled)
morph can have multiple possible pronunciations.
3 Experiments and Analysis
The goal of the conducted experiments is to com-
pare n-gram language models based on morphs to
standard word n-gram models in automatic speech
recognition across languages.
3.1 Data Sets and Recognition Systems
The results from eight different tests have been an-
alyzed. Some central properties of the test config-
urations are shown in Table 1. The Finnish, Esto-
nian, and Turkish test configurations are slight vari-
ations of experiments reported earlier in Hirsima?ki
et al (2006) (Fin1: ?News task?, Fin2: ?Book task?),
Kurimo et al (2006a) (Fin3, Tur1), and Kurimo et
al. (2006b) (Fin4, Est, Tur2).
Three different recognition platforms have been
used, all of which are state-of-the-art large vocab-
ulary continuous speech recognition (LVCSR) sys-
tems. The Finnish and Estonian experiments have
been run on the HUT speech recognition system de-
veloped at Helsinki University of Technology.
The Turkish tests were performed using the
AT&T decoder (Mohri and Riley, 2002); the acous-
tic features were produced using the HTK front end
(Young et al, 2002). The experiments on Egyptian
Colloquial Arabic (ECA) were carried out using the
SRI DecipherTM speech recognition system.
3.1.1 Speech Data and Acoustic Models
The type and amount of speech data vary from
one language to another. The Finnish data con-
sists of news broadcasts read by one single female
speaker (Fin1), as well as an audio book read by an-
other female speaker (Fin2, Fin3, Fin4). The Finnish
acoustic models are speaker dependent (SD). Mono-
phones (mon) were used in the earlier experiments
(Fin1, Fin2), but these were later replaced by cross-
context triphones (tri).
The Estonian speech data has been collected from
a large number of speakers and consists of sen-
tences from newspapers as well as names and dig-
its read aloud. The acoustic models are speaker-
independent triphones (SI tri) adapted online using
Cepstral Mean Subtraction and Constrained Maxi-
mum Likelihood Linear Regression. Also the Turk-
ish acoustic training data contains speech from hun-
dreds of speakers. The test set is composed of news-
paper text read by one female speaker. Speaker-
independent triphones are used as acoustic models.
The Finnish, Estonian, and Turkish data sets con-
tain planned speech, i.e., written text read aloud.
By contrast, the Arabic data consists of transcribed
spontaneous telephone conversations,2 which are
characterized by disfluencies and by the presence
of ?non-speech?, such as laugh and cough sounds.
There are multiple speakers in the Arabic data, and
online speaker adaptation has been performed.
3.1.2 Text Data and Language Models
The n-gram language models are trained using
the SRILM toolkit (Stolcke, 2002) (Fin1, Fin2,
Tur1, Tur2, ECA) or similar software developed
at HUT (Siivola and Pellom, 2005) (Fin3, Fin4,
Est). All models utilize the Modified Interpolated
Kneser-Ney smoothing technique (Chen and Good-
man, 1999). The Arabic LM is trained on the
same corpus that is used for acoustic training. This
data set is regrettably small (160 000 words), but it
matches the test set well in style, as it consists of
transcribed spontaneous speech. The LM training
corpora used for the other languages contain fairly
large amounts of mainly news and book texts and
conceivably match the style of the test data well.
In the morph-based models, words are split into
morphs using Morfessor, and statistics are collected
for morph n-grams. As the desired output of the
2LDC CallHome corpus of Egyptian Colloquial Ara-
bic: http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC97S45
382
Table 1: Test configurations
Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA
Recognizer HUT HUT HUT HUT HUT AT&T AT&T SRI
Speech data
Type of speech read read read read read read read spont.
Training set [kwords] 20 49 49 49 790 230 110 160
Speakers in training set 1 1 1 1 1300 550 250 310
Test set [kwords] 4.3 1.9 1.9 1.9 3.7 7.0 7.0 16
Speakers in test set 1 1 1 1 50 1 1 57
Text data
LM training set [Mwords] 36 36 32 150 53 17 27 0.16
Models
Acoustic models SD mon SD mon SD tri SD tri SI tri SI tri SI tri SI tri
Morph lexicon [kmorphs] 66 66 120 25 37 52 34 6.1
Word lexicon [kwords] 410 410 410 ? 60 120 50 18
Out-of-vocabulary words
OOV LM training set [%] 5.0 5.0 5.9 ? 14 5.3 9.6 0.61
OOV test set [%] 5.0 7.2 7.3 ? 19 5.5 12 9.9
New words in test set [%] 2.7 3.0 3.1 1.5 3.4 1.6 1.5 9.8
speech recognizer is a sequence of words rather than
morphs, the LM explicitly models word breaks as
special symbols occurring in the morph sequence.
For comparison, word n-gram models have been
tested. The vocabulary cannot typically include ev-
ery word form occurring in the training set (because
of the large number of different words), so the most
frequent words are given priority; the actual lexicon
sizes used in each experiment are shown in Table 1.
Any word not contained in the lexicon is replaced by
a special out-of-vocabulary symbol.
As words and morphs are units of different length,
their optimal performance may occur at different or-
ders of the n-gram. The best order of the n-gram
has been optimized on development test sets in the
following cases: Fin1, Fin2, Tur1, ECA (4-grams
for both morphs and words) and Tur2 (5-grams for
morphs, 3-grams for words). The models have ad-
ditionally been pruned using entropy-based pruning
(Tur1, Tur2, ECA) (Stolcke, 1998). In the other
experiments (Fin3, Fin4, Est), no fixed maximum
value of n was selected. n-Gram growing was per-
formed (Siivola and Pellom, 2005), such that those
n-grams that maximize the training set likelihood
are gradually added to the model. The unrestricted
growth of the model is counterbalanced by an MDL-
type complexity term. The highest order of n-grams
accepted was 7 for Finnish and 8 for Estonian.
Note that the optimization procedure is neutral
with respect to morphs vs. words. Roughly the
same number of parameters are allowed in the result-
ing LMs, but typically the morph n-gram LMs are
smaller than the corresponding word n-gram LMs.
3.1.3 Out-of-Vocabulary Words
Table 1 further shows statistics on out-of-
vocabulary rates in the data sets. This is relevant
for the assessment of the word models, as the OOV
rates define the limits of these models.
The OOV rate for the LM training set corresponds
to the proportion of words replaced by the OOV
symbol in the LM training data, i.e., words that were
not included in the recognition vocabulary. The high
OOV rates for Estonian (14 %) and Tur2 (9.6 %) in-
dicate that the word lexicons have poor coverage of
these sets. By contrast, the ECA word lexicon cov-
ers virtually the entire training set vocabulary.
Correspondingly, the test set OOV rate is the pro-
portion of words that occur in the data sets used
for running the speech recognition tests, but that are
missing from the recognition lexicons. This value
is thus the minimum error that can be obtained by
the word models, or put differently, the recognizer
is guaranteed to get at least this proportion of words
wrong. Again, the values are very high for Estonian
(19 %) and Tur2 (12 %), but also for Arabic (9.9 %)
because of the insufficient amount of training data.
Finally, the figures labeled ?new words in test set?
denote the proportion of words in the test set that do
not occur in the LM training set. Thus, these values
indicate the minimum error achievable by any word
model trained on the training sets available.
383
Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA0
10
20
30
40
50
60
70
80
90
100
76.6
71.9
79.1
67.8
89.8
82.2
92.8
66.7
51.9
68.667.466.7
61.2
40.141.8
W
or
d 
ac
cu
ra
cy
 [%
]
 
 
Morphs
Words
Figure 2: Word accuracies for the different speech
recognition test configurations.
3.2 Results and Analysis
The morph-based and word-based results of the con-
ducted speech recognition experiments are shown in
Figure 2 (for Fin4, no comparable word experiment
has been carried out). The evaluation measure used
is word accuracy (WAC): the number of correctly
recognized words minus the number of incorrectly
inserted words divided by the number of words in
the reference transcript. (Another frequently used
measure is the word error rate, WER, which relates
to word accuracy as WER = 100 % ? WAC.)
Figure 2 shows that the morph models perform
better than the word models, with the exception
of the Arabic experiment (ECA), where the word
model outperforms the morph model. The statisti-
cal significance of these differences is confirmed by
one-tailed paired Wilcoxon signed-rank tests at the
significance level of 0.05.
Overall, the best performance is observed for the
Finnish data sets, which is explained by the speaker-
dependent acoustic models and clean noise condi-
tions. The Arabic setup suffers from the insufficient
amount of LM training data.
3.2.1 In-Vocabulary Words
For a further investigation of the outcome of the
experiments, the test sets have been partitioned into
regions based on the types of words they contain.
The recognition output is aligned with the refer-
ence transcript, and the regions aligned with in-
vocabulary (IV) reference words (words contained
in the vocabulary of the word model) are put in
one partition and the remaining words (OOVs) are
put in another partition. Word accuracies are then
computed separately for the two partitions. Inserted
words, i.e., words that are not aligned with any word
in the reference, are put in the IV partition, unless
they are adjacent to an OOV region, in which case
they are put in the OOV partition.
Figure 3a shows word accuracies for the in-
vocabulary words. Without exception, the accuracy
for the IVs is higher than that of the entire test set vo-
cabulary. One could imagine that the word models
would do better than the morph models on the IVs,
since the word models are totally focused on these
words, whereas the morph models reserve modeling
capacity for a much larger set of words. The word
accuracies in Fig. 3a also partly seem to support this
view. However, Wilcoxon signed-rank tests (level
0.05) show that the superiority of the word model is
statistically significant only for Arabic and for Fin3.
With few exceptions, it is thus possible to draw
the conclusion that morph models are capable of
modeling a much larger set of words than word
models without, however, compromising the perfor-
mance on the limited vocabulary covered by the
word models in a statistically significant way.
3.2.2 Out-of-Vocabulary Words
Since the word model and morph model perform
equally well on the subset of words that are included
in the lexicon of the word model, the overall supe-
riority of the morph model needs to come from its
successful coping with out-of-vocabulary words.
In Figure 3b, word accuracies have been plot-
ted for the out-of-vocabulary words contained in the
test set. It is clear that the recognition accuracy for
the OOVs is much lower than the overall accuracy.
Also, negative accuracy values are observed. This
happens when the number of insertions exceeds the
number of correctly recognized units.
In Figure 3b, if speaker-dependent and speaker-
independent setups are considered separately (and
Arabic is left out), there is a tendency for the morph
models to recognize the OOVs more accurately, the
higher the OOV rate is. One could say that a morph
model has a double advantage over a correspond-
ing word model: the larger the proportion of OOVs
384
Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA0
10
20
30
40
50
60
70
80
90
100
79.979.781.977.9
92.594.6
73.374.771.872.671.771.9
45.6
48.1
W
or
d 
ac
cu
ra
cy
 fo
r i
n?
vo
ca
bu
la
ry
 w
or
ds
 [%
]
 
 
Morphs
Words
(a)
Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA?100
?80
?60
?40
?20
0
20
40
60
80
100
76.671.9
79.1
67.8
89.8
82.2
92.8
66.7
51.9
68.667.466.7
61.2
40.141.8
15.1
?74.8
43.2
?62.6
55.1
?76.1
38.0
?47.7
13.2
?21.8
29.2
?19.4
?10.1
?14.6
W
or
d 
ac
cu
ra
cy
 fo
r O
O
Vs
 [%
]
 
 
Morphs
Words
(b)
Figure 3: Word accuracies computed separately for those words in the test sets that are (a) included in and
(b) excluded from the vocabularies of the word vocabulary; cf. figures listed on the row ?OOV test set? in
Table 1. Together these two partitions make up the entire test set vocabulary. For comparison, the results for
the entire sets are shown using gray-shaded bars (also displayed in Figure 2).
in the word model is, the larger the proportion of
words that the morph model can recognize but the
word model cannot, a priori. In addition, the larger
the proportion of OOVs, the more frequent and more
?easily modelable? words are left out of the word
model, and the more successfully these words are
indeed learned by the morph model.
3.2.3 New Words in the Test Set
All words present in the training data (some of
which are OOVs in the word models) ?leave some
trace? in the morph models, in the n-gram statistics
that are collected for morph sequences. How, then,
about new words that occur only in the test set, but
not in the training set? In order to recognize such
words correctly, the model must combine morphs in
ways it has not observed before.
Figure 4 demonstrates that the new unseen words
are very challenging. Now, also the morph mod-
els mostly obtain negative word accuracies, which
means that the number of insertions adjacent to new
words exceeds the number of correctly recognized
new words. The best results are obtained in clean
acoustic conditions (Fin2, Fin3, Fin4) with only few
foreign names, which are difficult to get right using
typical Finnish phoneme-to-grapheme mappings (as
the negative accuracy of Fin1 suggests).
3.3 Vocabulary Growth and Arabic
Figure 5 shows the development of the size of
the vocabulary (unique word forms) for growing
amounts of text in different corpora. The corpora
used for Finnish, Estonian, and Turkish (planned
speech/text), as well as Arabic (spontaneous speech)
are the LM training sets used in the experiments.
Additional sources have been provided for Arabic
and English: Arabic text (planned) from the FBIS
corpus of Modern Standard Arabic (a collection
of transcribed radio newscasts from various radio
stations in the Arabic speaking world), as well as
text from the New York Times magazine (English
planned) and spontaneous transcribed English tele-
phone conversations from the Fisher corpus.
The figure illustrates two points: (1) The faster
the vocabulary growth is, the larger the potential ad-
vantage of morph models is in comparison to stan-
dard word models, because of OOV and data spar-
sity problems. The obtained speech recognition re-
sults seem to support this hypothesis; the applied
morph LMs are clearly beneficial for Finnish and
Estonian, mostly beneficial for Turkish, and slightly
detrimental for ECA. (2) A more slowly growing
vocabulary is used in spontaneous speech than in
planned speech (or written text). Moreover, the
Arabic ?spontaneous? curve is located fairly close
385
Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA?100
?80
?60
?40
?20
0
20
40
60
80
100
76.671.9
79.1
67.8
89.8
82.2
92.8
66.7
51.9
68.667.466.7
61.2
40.141.8
?8.7
?93.0
20.7
?75.9
31.0
?81.0
17.9
?32.3
?64.6
?6.1
?24.6
?5.9
?24.5
?10.1
?14.6
W
or
d 
ac
cu
ra
cy
 fo
r u
ns
ee
n 
wo
rd
s 
[%
]
 
 
Morphs
Words
Figure 4: Word accuracies computed for the words
in the test sets that do not occur at all in the train-
ing sets; cf. figures listed on the row ?new words
in test set? in Table 1. For comparison, the gray-
shaded bars show the corresponding results for the
entire test sets (also displayed in Figure 2).
to the English ?planned? curve and much below
the Finnish, Estonian, and Turkish curves. Thus,
even though Arabic is considered a ?morphologi-
cally rich? language, this is not manifested through
a considerable vocabulary growth (and high OOV
rate) in the Egyptian Colloquial Arabic data used in
the current speech recognition experiments. Conse-
quently, it may not be that surprising that the morph
model did not work particularly well for Arabic.
Arabic words consist of a stem surrounded by pre-
fixes and suffixes, which are fairly successfully seg-
mented out by Morfessor. However, Arabic also
has templatic morphology, i.e., the stem is formed
through the insertion of a vowel pattern into a ?con-
sonantal skeleton?.
Additional experiments have been performed us-
ing the ECA data and Factored Language Models
(FLMs) (Kirchhoff et al, 2006). The FLM is a
powerful model that makes use of several sources
of information, in particular a morphological lexi-
con of ECA. The FLM incorporates mechanisms for
handling templatic morphology, but despite its so-
phistication, it barely outperforms the standard word
model: The word accuracy of the FLM is 42.3 % and
that of the word model is 41.8 %. The speech recog-
nition implementation of both the FLM and the word
0 20 40 60 80 100 120 140 160 1800
5
10
15
20
25
30
35
40
45
50
Corpus size [1000 words]
Un
iq
ue
 w
or
ds
 [1
00
0 w
ord
s]
Fin
nish
 (pla
nned
)
Est
onia
n (pl
anne
d)
Turk
ish (pl
anned
)
Arabic 
(spontan
eous)Ara
bic (plann
ed)
English (plann
ed)
English (spontaneous)
Figure 5: Vocabulary growth curves for the differ-
ent corpora of spontaneous and planned speech (or
written text). For growing amounts of text (word
tokens) the number of unique different word forms
(word types) occurring in the corpus are plotted.
model is based on whole words (although subword
units are used for assigning probabilities to word
forms in the FLM). This contrasts these models with
the morph model, which splits words into subword
units also in the speech recognition implementation.
It seems that the splitting is a source of errors in this
experimental setup with very little data available.
4 Discussion
Alternative morph-based and word-based ap-
proaches exist. We have tried some, but none of
them has outperformed the described morph models
for Finnish, Estonian, and Turkish, or the word and
FLM models for Egyptian Arabic (in a statistically
significant way). The tested models comprise
more linguistically accurate morph segmentations
obtained using later Morfessor versions (Categories-
ML and Categories-MAP) (Creutz, 2006), as well
as analyses obtained from morphological parsers.
Hybrids, i.e., word models augmented with
phonemes or other subword units have been pro-
posed (Bazzi and Glass, 2000; Galescu, 2003;
Bisani and Ney, 2005). In our experiments, such
models have outperformed the standard word mod-
els, but not the morph models.
Simply growing the word vocabulary to cover the
386
entire vocabulary of large training corpora could be
one (fairly ?brute-force?) approach, but this is hardly
feasible for languages such as Finnish. The en-
tire Finnish LM training data of 150 million words
(used in Fin4) contains more than 4 million unique
word forms, a value ten times the size of the rather
large word lexicon currently used. And even if a 4-
million-word lexicon were to be used, the OOV rate
of the test set would still be relatively high: 1.5 %.
Judging by the Arabic experiments, there seems
to be some potential in Factored Language Models.
The FLMs might work well also for the other lan-
guages, and in fact, to do justice to the more ad-
vanced morph models from later versions of Mor-
fessor, FLMs or some other refined techniques may
be necessary as a complement to the currently used
standard n-grams.
Acknowledgments
We are most grateful to Katrin Kirchhoff and Dimitra Vergyri
for their valuable help on issues related to Arabic, and to the EU
AMI training program for funding part of this work. The work
was also partly funded by DARPA under contract No. HR0011-
06-C-0023 (approved for public release, distribution is unlim-
ited). The views herein are those of the authors and do not nec-
essarily reflect the views of the funding agencies.
References
I. Bazzi and J. R. Glass. 2000. Modeling out-of-vocabulary
words for robust speech recognition. In Proc. ICSLP, Bei-
jing, China.
A. Berton, P. Fetter, and P. Regel-Brietzmann. 1996. Com-
pound words in large-vocabulary German speech recognition
systems. In Proc. ICSLP, pp. 1165?1168, Philadelphia, PA,
USA.
M. Bisani and H. Ney. 2005. Open vocabulary speech recog-
nition with flat hybrid models. In Proc. Interspeech, Lisbon,
Portugal.
M. R. Brent. 1999. An efficient, probabilistically sound algo-
rithm for segmentation and word discovery. Machine Learn-
ing, 34:71?105.
W. Byrne, J. Hajic?, P. Ircing, F. Jelinek, S. Khudanpur, P. Kr-
bec, and J. Psutka. 2001. On large vocabulary continuous
speech recognition of highly inflectional language ? Czech.
In Proc. Eurospeech, pp. 487?489, Aalborg, Denmark.
S. F. Chen and J. Goodman. 1999. An empirical study of
smoothing techniques for language modeling. Computer
Speech and Language, 13:359?394.
M. Creutz and K. Lagus. 2002. Unsupervised discovery of
morphemes. In Proc. ACL SIGPHON, pp. 21?30, Philadel-
phia, PA, USA.
M. Creutz. 2006. Induction of the Morphology of Natural
Language: Unsupervised Morpheme Segmentation with Ap-
plication to Automatic Speech Recognition. Ph.D. thesis,
Helsinki University of Technology. http://lib.tkk.fi/
Diss/2006/isbn9512282119/.
C. G. de Marcken. 1996. Unsupervised Language Acquisition.
Ph.D. thesis, MIT.
L. Galescu. 2003. Recognition of out-of-vocabulary words
with sub-lexical language models. In Proc. Eurospeech, pp.
249?252, Geneva, Switzerland.
P. Geutner, M. Finke, and P. Scheytt. 1998. Adaptive vocabu-
laries for transcribing multilingual broadcast news. In Proc.
ICASSP, pp. 925?928, Seattle, WA, USA.
J. Goldsmith. 2001. Unsupervised learning of the mor-
phology of a natural language. Computational Linguistics,
27(2):153?198.
S. Goldwater, T. L. Griffiths, and M. Johnson. 2006. Contex-
tual dependencies in unsupervised word segmentation. In
Proc. Coling/ACL, pp. 673?680, Sydney, Australia.
T. Hirsima?ki, M. Creutz, V. Siivola, M. Kurimo, S. Virpioja, and
J. Pylkko?nen. 2006. Unlimited vocabulary speech recogni-
tion with morph language models applied to Finnish. Com-
puter Speech and Language, 20(4):515?541.
K. Kirchhoff, D. Vergyri, J. Bilmes, K. Duh, and A. Stol-
cke. 2006. Morphology-based language modeling for Ara-
bic speech recognition. Computer Speech and Language,
20(4):589?608.
M. Kurimo, M. Creutz, M. Varjokallio, E. Ar?soy, and
M. Sarac?lar. 2006a. Unsupervised segmentation of words
into morphemes ? Morpho Challenge 2005, Application to
automatic speech recognition. In Proc. Interspeech, Pitts-
burgh, PA, USA.
M. Kurimo, A. Puurula, E. Ar?soy, V. Siivola, T. Hirsima?ki,
J. Pylkko?nen, T. Aluma?e, and M. Sarac?lar. 2006b. Un-
limited vocabulary speech recognition for agglutinative lan-
guages. In Proc. NAACL-HLT, New York, USA.
O.-W. Kwon and J. Park. 2003. Korean large vocabulary con-
tinuous speech recognition with morpheme-based recogni-
tion units. Speech Communication, 39(3?4):287?300.
M. Larson, D. Willett, J. Koehler, and G. Rigoll. 2000. Com-
pound splitting and lexical unit recombination for improved
performance of a speech recognition system for German par-
liamentary speeches. In Proc. ICSLP.
M. Mohri and M. D. Riley. 2002. DCD library, Speech
recognition decoder library. AT&T Labs Research. http:
//www.research.att.com/sw/tools/dcd/.
R. Ordelman, A. van Hessen, and F. de Jong. 2003. Compound
decomposition in Dutch large vocabulary speech recogni-
tion. In Proc. Eurospeech, pp. 225?228, Geneva, Switzer-
land.
J. Rissanen. 1989. Stochastic complexity in statistical inquiry.
World Scientific Series in Computer Science, 15:79?93.
I. Shafran and K. Hall. 2006. Corrective models for speech
recognition of inflected languages. In Proc. EMNLP, Syd-
ney, Australia.
V. Siivola and B. Pellom. 2005. Growing an n-gram model. In
Proc. Interspeech, pp. 1309?1312, Lisbon, Portugal.
A. Stolcke. 1998. Entropy-based pruning of backoff language
models. In Proc. DARPA BNTU Workshop, pp. 270?274,
Lansdowne, VA, USA.
A. Stolcke. 2002. SRILM ? an extensible language modeling
toolkit. In Proc. ICSLP, pp. 901?904. http://www.speech.
sri.com/projects/srilm/.
E. W. D. Whittaker and P. C. Woodland. 2000. Particle-based
language modelling. In Proc. ICSLP, pp. 170?173, Beijing,
China.
S. Young, D. Ollason, V. Valtchev, and P. Woodland. 2002.
The HTK book (for version 3.2 of HTK). University of Cam-
bridge.
387
Unsupervised Segmentation of Words Using Prior Distributions of Morph
Length and Frequency
Mathias Creutz
Neural Networks Research Centre, Helsinki University of Technology
P.O.Box 9800, FIN-02015 HUT, Finland
Mathias.Creutz@hut.fi
Abstract
We present a language-independent and
unsupervised algorithm for the segmenta-
tion of words into morphs. The algorithm
is based on a new generative probabilis-
tic model, which makes use of relevant
prior information on the length and fre-
quency distributions of morphs in a lan-
guage. Our algorithm is shown to out-
perform two competing algorithms, when
evaluated on data from a language with
agglutinative morphology (Finnish), and
to perform well also on English data.
1 Introduction
In order to artificially ?understand? or produce nat-
ural language, a system presumably has to know the
elementary building blocks, i.e., the lexicon, of the
language. Additionally, the system needs to model
the relations between these lexical units. Many ex-
isting NLP (natural language processing) applica-
tions make use of words as such units. For in-
stance, in statistical language modelling, probabil-
ities of word sequences are typically estimated, and
bag-of-word models are common in information re-
trieval.
However, for some languages it is infeasible to
construct lexicons for NLP applications, if the lexi-
cons contain entire words. In especially agglutina-
tive languages,1 such as Finnish and Turkish, the
1In agglutinative languages words are formed by the con-
catenation of morphemes.
number of possible different word forms is simply
too high. For example, in Finnish, a single verb
may appear in thousands of different forms (Karls-
son, 1987).
According to linguistic theory, words are built
from smaller units, morphemes. Morphemes are the
smallest meaning-bearing elements of language and
could be used as lexical units instead of entire words.
However, the construction of a comprehensive mor-
phological lexicon or analyzer based on linguistic
theory requires a considerable amount of work by
experts. This is both time-consuming and expen-
sive and hardly applicable to all languages. Further-
more, as language evolves the lexicon must be up-
dated continuously in order to remain up-to-date.
Alternatively, an interesting field of research lies
open: Minimally supervised algorithms can be de-
signed that automatically discover morphemes or
morpheme-like units from data. There exist a num-
ber of such algorithms, some of which are entirely
unsupervised and others that use some knowledge of
the language. In the following, we discuss recent un-
supervised algorithms and refer the reader to (Gold-
smith, 2001) for a comprehensive survey of previous
research in the whole field.
Many algorithms proceed by segmenting (i.e.,
splitting) words into smaller components. Often
the limiting assumption is made that words con-
sist of only one stem followed by one (possibly
empty) suffix (De?jean, 1998; Snover and Brent,
2001; Snover et al, 2002). This limitation is reduced
in (Goldsmith, 2001) by allowing a recursive struc-
ture, where stems can have inner structure, so that
they in turn consist of a substem and a suffix. Also
prefixes are possible. However, for languages with
agglutinative morphology this may not be enough.
In Finnish, a word can consist of lengthy sequences
of alternating stems and affixes.
Some morphology discovery algorithms learn re-
lationships between words by comparing the ortho-
graphic or semantic similarity of the words (Schone
and Jurafsky, 2000; Neuvel and Fulop, 2002; Baroni
et al, 2002). Here a small number of components
per word are assumed, which makes the approaches
difficult to apply as such to agglutinative languages.
We previously presented two segmentation algo-
rithms suitable for agglutinative languages (Creutz
and Lagus, 2002). The algorithms learn a set of
segments, which we call morphs, from a corpus.
Stems and affixes are not distinguished as sepa-
rate categories by the algorithms, and in that sense
they resemble algorithms for text segmentation and
word discovery, such as (Deligne and Bimbot, 1997;
Brent, 1999; Kit and Wilks, 1999; Yu, 2000). How-
ever, we observed that for the corpus size studied
(100 000 words), our two algorithms were somewhat
prone to excessive segmentation of words.
In this paper, we aim at overcoming the problem
of excessive segmentation, particularly when small
corpora (up to 200 000 words) are used for training.
We present a new segmentation algorithm, which is
language independent and works in an unsupervised
fashion. Since the results obtained suggest that the
algorithm performs rather well, it could possibly be
suitable for languages for which only small amounts
of written text are available.
The model is formulated in a probabilistic
Bayesian framework. It makes use of explicit prior
information in the form of probability distributions
for morph length and morph frequency. The model
is based on the same kind of reasoning as the proba-
bilistic model in (Brent, 1999). While Brent?s model
displays a prior probability that exponentially de-
creases with word length (with one character as the
most common length), our model uses a probabil-
ity distribution that more accurately models the real
length distribution. Also Brent?s frequency distribu-
tion differs from ours, which we derive from Man-
delbrot?s correction of Zipf?s law (cf. Section 2.5).
Our model requires that the values of two param-
eters be set: (i) our prior belief of the most common
morph length, and (ii) our prior belief of the pro-
portion of morph types2 that occur only once in the
corpus. These morph types are called hapax legom-
ena. While the former is a rather intuitive measure,
the latter may not appear as intuitive. However, the
proportion of hapax legomena may be interpreted as
a measure of the richness of the text. Also note that
since the most common morph length is calculated
for morph types, not tokens, it is not independent of
the corpus size. A larger corpus usually requires a
higher average morph length, a fact that is stated for
word lengths in (Baayen, 2001).
As an evaluation criterion for the performance
of our method and two reference methods we use
a measure that reflects the ability to recognize
real morphemes of the language by examining the
morphs found by the algorithm.
2 Probabilistic generative model
In this section we derive the new model. We fol-
low a step-by-step process, during which a morph
lexicon and a corpus are generated. The morphs in
the lexicon are strings that emerge as a result of a
stochastic process. The corpus is formed through
another stochastic process that picks morphs from
the lexicon and places them in a sequence. At two
points of the process, prior knowledge is required
in the form of two real numbers: the most common
morph length and the proportion of hapax legomena
morphs.
The model can be used for segmentation of words
by requiring that the corpus created is exactly the
input data. By selecting the most probable morph
lexicon that can produce the input data, we obtain a
segmentation of the words in the corpus, since we
can rewrite every word as a sequence of morphs.
2.1 Size of the morph lexicon
We start the generation process by deciding the num-
ber of morphs in the morph lexicon (type count).
This number is denoted by n? and its probability
p(n?) follows the uniform distribution. This means
that, a priori, no lexicon size is more probable than
another.3
2We use standard terminology: Morph types are the set of
different, distinct morphs. By contrast, morph tokens are the
instances (or occurrences) of morphs in the corpus.
3This is an improper prior, but it is of little practical signif-
icance for two reasons: (i) This stage of the generation process
2.2 Morph lengths
For each morph in the lexicon, we independently
choose its length in characters according to the
gamma distribution:
p(l?i) =
1
?(?)?? l?i
??1e?l?i/?, (1)
where l?i is the length in characters of the ith morph,
and ? and ? are constants. ?(?) is the gamma func-
tion:
?(?) =
? ?
0
z??1e?zdz. (2)
The maximum value of the density occurs at l?i =
(? ? 1)?, which corresponds to the most common
morph length in the lexicon. When ? is set to one,
and ? to one plus our prior belief of the most com-
mon morph length, the pdf (probability density func-
tion) is completely defined.
We have chosen the gamma distribution for
morph lengths, because it corresponds rather well to
the real length distribution observed for word types
in Finnish and English corpora that we have stud-
ied. The distribution also fits the length distribution
of the morpheme labels used as a reference (cf. Sec-
tion 3). A Poisson distribution can be justified and
has been used in order to model the length distri-
bution of word and morph tokens [e.g., (Creutz and
Lagus, 2002)], but for morph types we have chosen
the gamma distribution, which has a thicker tail.
2.3 Morph strings
For each morph ?i, we decide the character string it
consists of: We independently choose l?i characters
at random from the alphabet in use. The probabil-
ity of each character cj is the maximum likelihood
estimate of the occurrence of this character in the
corpus:4
p(cj) =
ncj
?
k nck
, (3)
where ncj is the number of occurrences of the char-
acter cj in the corpus, and
?
k nck is the total num-
ber of characters in the corpus.
only contributes with one probability value, which will have a
negligible effect on the model as a whole. (ii) A proper prob-
ability density function would presumably be very flat, which
would hardly help guiding the search towards an optimal model.
4Alternatively, the maximum likelihood estimate of the oc-
currence of the character in the lexicon could be used.
2.4 Morph order in the lexicon
The lexicon consists of a set of n? morphs and it
makes no difference in which order these morphs
have emerged. Regardless of their initial order, the
morphs can be sorted into a uniquely defined (e.g.,
alphabetical) order. Since there are n?! ways to or-
der n? different elements,5 we multiply the proba-
bility accumulated so far by n?!:
p(lexicon) = p(n?)
n?
?
i=1
[
p(l?i)
l?i
?
j=1
p(cj)
]
?n?! (4)
2.5 Morph frequencies
The next step is to generate a corpus using the morph
lexicon obtained in the previous steps. First, we in-
dependently choose the number of times each morph
occurs in the corpus. We pursue the following line
of thought:
Zipf has studied the relationship between the fre-
quency of a word, f , and its rank, z.6 He suggests
that the frequency of a word is inversely proportional
to its rank. Mandelbrot has refined Zipf?s formula,
and suggests a more general relationship [see, e.g.,
(Baayen, 2001)]:
f = C(z + b)?a, (5)
where C, a and b are parameters of a text.
Let us derive a probability distribution from Man-
delbrot?s formula. The rank of a word as a func-
tion of its frequency can be obtained by solving for
z from (5):
z = C 1a f? 1a ? b. (6)
Suppose that one wants to know the number of
words that have a frequency close to f rather than
the rank of the word with frequency f . In order to
obtain this information, we choose an arbitrary in-
terval around f : [(1/?)f . . . ?f [, where ? > 1, and
compute the rank at the endpoints of the interval.
The difference is an estimate of the number of words
5Strictly speaking, our probabilistic model is not perfect,
since we do not make sure that no morph can appear more than
once in the lexicon.
6The rank of a word is the position of the word in a list,
where the words have been sorted according to falling fre-
quency.
that fall within the interval, i.e., have a frequency
close to f :
nf = z1/? ? z? = (?
1
a ? ?? 1a )C 1a f? 1a . (7)
This can be transformed into an exponential pdf
by (i) binning the frequency axis so that there are
no overlapping intervals. (This means that the fre-
quency axis is divided into non-overlapping inter-
vals [(1/?)f? . . . ?f? [, which is equivalent to having
f? values that are powers of ?2: f?0 = ?0 = 1, f?1 =
?2, f?2 = ?4, . . . All frequencies f are rounded to
the closest f? .) Next (ii), we normalize the number
of words with a frequency close to f? with the to-
tal number of words
?
f? nf? . Furthermore (iii), f?
is written as elog f? , and (iv) C must be chosen so
that the normalization coefficient equals 1/a, which
yields a proper pdf that integrates to one. Note also
the factor log ?2. Like f? , log f? is a discrete variable.
We approximate the integral of the density function
around each value log f? by multiplying with the dif-
ference between two successive log f? values, which
equals log ?2:
p(f ? [(1/?)f? . . . ?f? [) = ?
1
a ? ?? 1a
?
f? nf?
C 1a e? 1a log f?
= 1ae
? 1a log f? ? log ?2. (8)
Now, if we assume that Zipf?s and Madelbrot?s
formulae apply to morphs as well as to words, we
can use formula (8) for every morph frequency f?i ,
which is the number of occurrences (or frequency)
of the morph ?i in the corpus (token count). How-
ever, values for a and ?2 must be chosen. We set
?2 to 1.59, which is the lowest value for which no
empty frequency bins will appear.7 For f?i = 1, (8)
reduces to log ?2/a. We set this value equal to our
prior belief of the proportion of morph types that are
to occur only once in the corpus (hapax legomena).
2.6 Corpus
The morphs and their frequencies have been set. The
order of the morphs in the corpus remains to be de-
cided. The probability of one particular order is the
inverse of the multinomial:
7Empty bins can appear for small values of f?i due to f?i ?s
being rounded to the closest f??i , which is a power of ?2.
p(corpus) =
((
?n?
i=1 f?i)!
?n?
i=1 f?i !
)?1 =
( N !
?n?
i=1 f?i !
)?1.
(9)
The numerator of the multinomial is the factorial of
the total number of morph tokens, N , which equals
the sum of frequencies of every morph type. The de-
nominator is the product of the factorial of the fre-
quency of each morph type.
2.7 Search for the optimal model
The search for the optimal model given our input
data corresponds closely to the recursive segmen-
tation algorithm presented in (Creutz and Lagus,
2002). The search takes place in batch mode, but
could as well be done incrementally. All words in
the data are randomly shuffled, and for each word,
every split into two parts is tested. The most proba-
ble split location (or no split) is selected and in case
of a split, the two parts are recursively split in two.
All words are iteratively reprocessed until the prob-
ability of the model converges.
3 Evaluation
From the point of view of linguistic theory, it is pos-
sible to come up with different plausible sugges-
tions for the correct location of morpheme bound-
aries. Some of the solutions may be more elegant
than others,8 but it is difficult to say if the most el-
egant scheme will work best in practice, when real
NLP applications are concerned.
We utilize an evaluation method for segmentation
of words presented in (Creutz and Lagus, 2002). In
this method, segments are not compared to one sin-
gle ?correct? segmentation. The evaluation criterion
can rather be interpreted from the point of view of
language ?understanding?. A morph discovered by
the segmentation algorithm is considered to be ?un-
derstood?, if there is a low-ambiguity mapping from
the morph to a corresponding morpheme. Alterna-
tively, a morph may correspond to a sequence of
morphemes, if these morphemes are very likely to
occur together. The idea is that if an entirely new
word form is encountered, the system will ?under-
stand? it by decomposing it into morphs that it ?un-
derstands?. A segmentation algorithm that segments
8Cf. ?hop + ed? vs. ?hope + d? (past tense of ?to hope?).
words into too small parts will perform poorly due to
high ambiguity. At the other extreme, an algorithm
that is reluctant at splitting words will have bad gen-
eralization ability to new word forms.
Reference morpheme sequences for the words are
obtained using existing software for automatic mor-
phological analysis based on the two-level morphol-
ogy of Koskenniemi (1983). For each word form,
the analyzer outputs the base form of the word to-
gether with grammatical tags. By filtering the out-
put, we get a sequence of morpheme labels that ap-
pear in the correct order and represent correct mor-
phemes rather closely. Note, however, that the mor-
pheme labels are not necessarily orthographically
similar to the morphemes they represent.
The exact procedure for evaluating the segmenta-
tion of a set of words consists of the following steps:
(1) Segment the words in the corpus using the au-
tomatic segmentation algorithm.
(2) Divide the segmented data into two parts of
equal size. Collect all segmented word forms from
the first part into a training vocabulary and collect
all segmented word forms from the second part into
a test vocabulary.
(3) Align the segmentation of the words in the
training vocabulary with the corresponding refer-
ence morpheme label sequences. Each morph must
be aligned with one or more consecutive morpheme
labels and each morpheme label must be aligned
with at least one morph; e.g., for a hypothetical seg-
mentation of the English word winners?:
Morpheme labels win -ER PL GEN
Morph sequence w inn er s?
(4) Estimate conditional probabilities for the
morph/morpheme mappings computed over the
whole training vocabulary: p(morpheme |morph).
Re-align using the Viterbi algorithm and employ the
Expectation-Maximization algorithm iteratively un-
til convergence of the probabilities.
(5) The quality of the segmentation is evaluated
on the test vocabulary. The segmented words in the
test vocabulary are aligned against their reference
morpheme label sequences according to the condi-
tional probabilities learned from the training vocab-
ulary. To measure the quality of the segmentation
we compute the expectation of the proportion of
correct mappings from morphs to morpheme labels,
E{p(morpheme |morph)}:
1
N
N
?
i=1
pi(morpheme |morph), (10)
where N is the number of morph/morpheme map-
pings, and pi(?) is the probability associated with
the ith mapping. Thus, we measure the proportion
of morphemes in the test vocabulary that we can ex-
pect to recognize correctly by examining the morph
segments.9
4 Experiments
We have conducted experiments involving (i) three
different segmentation algorithms, (ii) two corpora
in different languages (Finnish and English), and
(iii) data sizes ranging from 2000 words to 200 000
words.
4.1 Segmentation algorithms
The new probabilistic method is compared to two
existing segmentation methods: the Recursive MDL
method presented in (Creutz and Lagus, 2002)10
and John Goldsmith?s algorithm called Linguistica
(Goldsmith, 2001).11 Both methods use MDL (Min-
imum Description Length) (Rissanen, 1989) as a cri-
terion for model optimization.
The effect of using prior information on the dis-
tribution of morph length and frequency can be as-
sessed by comparing the probabilistic method to Re-
cursive MDL, since both methods utilize the same
search algorithm, but Recursive MDL does not make
use of explicit prior information.
Furthermore, the possible benefit of using the
two sources of prior information can be compared
against the possible benefit of grouping stems and
suffixes into signatures. The latter technique is em-
ployed by Linguistica.
4.2 Data
The Finnish data consists of subsets of a news-
paper text corpus from CSC,12 from which non-
words (numbers and punctuation marks) have been
9In (Creutz and Lagus, 2002) the results are reported less
intuitively as the ?alignment distance?, i.e., the negative logprob
of the entire test set: ? log? pi(morpheme |morph).
10Online demo at http://www.cis.hut.fi/projects/morpho/.
11The software can be downloaded from http://humanities.
uchicago.edu/faculty/goldsmith/Linguistica2000/.
12http://www.csc.fi/kielipankki/
removed. The reference morpheme labels have been
filtered out from a morphosyntactic analysis of the
text produced by the Connexor FDG parser.13
The English corpus consists of mainly newspaper
text (with non-words removed) from the Brown cor-
pus.14 A morphological analysis of the words has
been performed using the Lingsoft ENGTWOL an-
alyzer.15
For both languages data sizes of 2000, 5000,
10 000, 50 000, 100 000, and 200 000 have been
used. A notable difference between the morpholog-
ical structure of the languages lies in the fact that
whereas there are about 17 000 English word types
in the largest data set, the corresponding number of
Finnish word types is 58 000.
4.3 Parameters
In order to select good prior values for the prob-
abilistic method, we have used separate develop-
ment test sets that are independent of the final data
sets. Morph length and morph frequency distribu-
tions have been computed for the reference mor-
pheme representations of the development test sets.
The prior values for most common morph length and
proportion of hapax legomena have been adjusted in
order to produce distributions that fit the reference
as well as possible.
We thus assume that we can make a good guess of
the final morph length and frequency distributions.
Note, however, that our reference is an approxima-
tion of a morpheme representation. As the segmen-
tation algorithms produce morphs, not morphemes,
we can expect to obtain a larger number of morphs
due to allomorphy. Note also that we do not op-
timize for segmentation performance on the devel-
opment test set; we only choose the best fit for the
morph length and frequency distributions.
As for the two other segmentation algorithms, Re-
cursive MDL has no parameters to adjust. In Lin-
guistica we have used Method A Suffixes + Find pre-
fixes from stems with other parameters left at their
default values. We are unaware whether another
configuration could be more advantageous for Lin-
guistica.
13http://www.connexor.fi/
14The Brown corpus is available at the Linguistic Data Con-
sortium at http://www.ldc.upenn.edu/.
15http://www.lingsoft.fi/
2 5 10 50 100 2000
10
20
30
40
50
60
Finnish
Corpus size [1000 words]  (log. scaled axis)
Ex
pe
ct
at
io
n(r
ec
og
niz
ed
 m
orp
he
me
s) 
[%
]
Probabilistic
Recursive MDL
Linguistica
No segmentation
Figure 1: Expectation of the percentage of recog-
nized morphemes for Finnish data.
4.4 Results
The expected proportion of morphemes recognized
by the three segmentation methods are plotted in
Figures 1 and 2 for different sizes of the Finnish
and English corpora. The search algorithm used
in the probabilistic method and Recursive MDL in-
volve randomness and therefore every value shown
for these two methods is the average obtained over
ten runs with different random seeds. However, the
fluctuations due to random behaviour are very small
and paired t-tests show significant differences at the
significance level of 0.01 for all pair-wise compar-
isons of the methods at all corpus sizes.
For Finnish, all methods show a curve that mainly
increases as a function of the corpus size. The prob-
abilistic method is the best with morpheme recogni-
tion percentages between 23.5% and 44.2%. Lin-
guistica performs worst with percentages between
16.5% and 29.1%. None of the methods are close
to ideal performance, which, however, is lower than
100%. This is due to the fact that the test vocabu-
lary contains a number of morphemes that are not
present in the training vocabulary, and thus are im-
possible to recognize. The proportion of unrecog-
nizable morphemes is highest for the smallest corpus
size (32.5%) and decreases to 8.8% for the largest
corpus size.
The evaluation measure used unfortunately scores
2 5 10 50 100 2000
10
20
30
40
50
60
English
Corpus size [1000 words]  (log. scaled axis)
Ex
pe
ct
at
io
n(r
ec
og
niz
ed
 m
orp
he
me
s) 
[%
]
Probabilistic
Recursive MDL
Linguistica
No segmentation
Figure 2: Expectation of the percentage of recog-
nized morphemes for English data.
a baseline of no segmentation fairly high. The no-
segmentation baseline corresponds to a system that
recognizes the training vocabulary fully, but has no
ability to generalize to any other word form.
The results for English are different. Linguistica
is the best method for corpus sizes below 50 000
words, but its performance degrades from the max-
imum of 39.6% at 10 000 words to 29.8% for the
largest data set. The probabilistic method is con-
stantly better than Recursive MDL and both methods
outperform Linguistica beyond 50 000 words. The
recognition percentages of the probabilistic method
vary between 28.2% and 43.6%. However, for cor-
pus sizes above 10 000 words none of the three
methods outperform the no-segmentation baseline.
Overall, the results for English are closer to ideal
performance than was the case for Finnish. This
is partly due to the fact that the proportion of un-
seen morphemes that are impossible to recognize is
higher for English (44.5% at 2000 words, 19.0% at
200 000 words).
As far as the time consumption of the algorithms
is concerned, the largest Finnish corpus took 20 min-
utes to process for the probabilistic method and Re-
cursive MDL, and 40 minutes for Linguistica. The
largest English corpus was processed in less than
three minutes by all the algorithms. The tests were
run on a 900 MHz AMD Duron processor with
256 MB RAM.
5 Discussion
For small data sizes, Recursive MDL has a tendency
to split words into too small segments, whereas Lin-
guistica is much more reluctant at splitting words,
due to its use of signatures. The extent to which the
probabilistic method splits words lies somewhere in
between the two other methods.
Our evaluation measure favours low ambiguity as
long as the ability to generalize to new word forms
does not suffer. This works against all segmentation
methods for English at larger data sizes. The En-
glish language has rather simple morphology, which
means that the number of different possible word
forms is limited. The larger the training vocabu-
lary, the broader coverage of the test vocabulary, and
therefore the no-segmentation approach works sur-
prisingly well. Segmentation always increases am-
biguity, which especially Linguistica suffers from as
it discovers more and more signatures and short suf-
fixes as the amount of data increases. For instance,
a final ?s? stripped off its stem can be either a noun
or a verb ending, and a final ?e? is very ambiguous,
as it belongs to orthography rather than morphology
and does not correspond to any morpheme.
Finnish morphology is more complex and there
are endless possibilities to construct new word
forms. As can be seen from Figure 1, the proba-
bilistic method and Recursive MDL perform better
than the no-segmentation baseline for all data sizes.
The segmentations could be evaluated using other
measures, but for language modelling purposes,
we believe that the evaluation measure should not
favour shattering of very common strings, even
though they correspond to more than one morpheme.
These strings should rather work as individual vo-
cabulary items in the model. It has been shown that
increased performance of n-gram models can be ob-
tained by adding larger units consisting of common
word sequences to the vocabulary; see e.g., (Deligne
and Bimbot, 1995). Nevertheless, in the near fu-
ture we wish to explore possibilities of using com-
plementary and more standard evaluation measures,
such as precision, recall, and F-measure of the dis-
covered morph boundaries.
Concerning the length and frequency prior dis-
tributions in the probabilistic model, one notes that
they are very general and do not make far-reaching
assumptions about the behaviour of natural lan-
guage. In fact, Zipf?s law has been shown to ap-
ply to randomly generated artificial texts (Li, 1992).
In our implementation, due to the independence as-
sumptions made in the model and due to the search
algorithm used, the choice of a prior value for the
most common morph length is more important than
the hapax legomena value. If a very bad prior value
for the most common morph length is used perfor-
mance drops by twelve percentage units, whereas
extreme hapax legomena values only reduces per-
formance by two percentage units. But note that the
two values are dependent: A greater average morph
length means a greater number of hapax legomena
and vice versa.
There is always room for improvement. Our cur-
rent model does not represent contextual dependen-
cies, such as phonological rules or morphotactic lim-
itations on morph order. Nor does it identify which
morphs are allomorphs of the same morpheme, e.g.,
?city? and ?citi + es?. In the future, we expect to ad-
dress these problems by using statistical language
modelling techniques. We will also study how the
algorithms scale to considerably larger corpora.
6 Conclusions
The results we have obtained suggest that the per-
formance of a segmentation algorithm can indeed be
increased by using prior information of general na-
ture, when this information is expressed mathemati-
cally as part of a probabilistic model. Furthermore,
we have reasons to believe that the morph segments
obtained can be useful as components of a statistical
language model.
Acknowledgements
I am most grateful to Krista Lagus, Krister Linde?n,
and Anders Ahlba?ck, as well as the anonymous re-
viewers for their valuable comments.
References
R. H. Baayen. 2001. Word Frequency Distributions.
Kluwer Academic Publishers.
M. Baroni, J. Matiasek, and H. Trost. 2002. Unsuper-
vised learning of morphologically related words based
on orthographic and semantic similarity. In Proc. ACL
Workshop Morphol. & Phonol. Learning, pp. 48?57.
M. R. Brent. 1999. An efficient, probabilistically sound
algorithm for segmentation and word discovery. Ma-
chine Learning, 34:71?105.
M. Creutz and K. Lagus. 2002. Unsupervised discovery
of morphemes. In Proc. ACL Workshop on Morphol.
and Phonological Learning, pp. 21?30, Philadelphia.
H. De?jean. 1998. Morphemes as necessary concept
for structures discovery from untagged corpora. In
Workshop on Paradigms and Grounding in Nat. Lang.
Learning, pp. 295?299, Adelaide.
S. Deligne and F. Bimbot. 1995. Language modeling
by variable length sequences: Theoretical formulation
and evaluation of multigrams. In Proc. ICASSP.
S. Deligne and F. Bimbot. 1997. Inference of variable-
length linguistic and acoustic units by multigrams.
Speech Communication, 23:223?241.
J. Goldsmith. 2001. Unsupervised learning of the mor-
phology of a natural language. Computational Lin-
guistics, 27(2):153?198.
F. Karlsson. 1987. Finnish Grammar. WSOY, 2nd ed.
C. Kit and Y. Wilks. 1999. Unsupervised learning of
word boundary with description length gain. In Proc.
CoNLL99 ACL Workshop, Bergen.
K. Koskenniemi. 1983. Two-level morphology: A gen-
eral computational model for word-form recognition
and production. Ph.D. thesis, University of Helsinki.
W. Li. 1992. Random texts exhibit Zipf?s-Law-like word
frequency distribution. IEEE Transactions on Infor-
mation Theory, 38(6):1842?1845.
S. Neuvel and S. A. Fulop. 2002. Unsupervised learn-
ing of morphology without morphemes. In Proc. ACL
Workshop on Morphol. & Phonol. Learn., pp. 31?40.
J. Rissanen. 1989. Stochastic Complexity in Statistical
Inquiry, vol. 15. World Scientific Series in Computer
Science, Singapore.
P. Schone and D. Jurafsky. 2000. Knowledge-free induc-
tion of morphology using Latent Semantic Analysis.
In Proc. CoNLL-2000 & LLL-2000, pp. 67?72.
M. G. Snover and M. R. Brent. 2001. A Bayesian model
for morpheme and paradigm identification. In Proc.
39th Annual Meeting of the ACL, pp. 482?490.
M. G. Snover, G. E. Jarosz, and M. R. Brent. 2002. Un-
supervised learning of morphology using a novel di-
rected search algorithm: Taking the first step. In Proc.
ACL Worksh. Morphol. & Phonol. Learn., pp. 11?20.
H. Yu. 2000. Unsupervised word induction using MDL
criterion. In Proc. ISCSL, Beijing.
Unsupervised Discovery of Morphemes
Mathias Creutz and Krista Lagus
Neural Networks Research Centre
Helsinki University of Technology
P.O.Box 9800, FIN-02015 HUT, Finland
{Mathias.Creutz, Krista.Lagus}@hut.fi
Abstract
We present two methods for unsupervised
segmentation of words into morpheme-
like units. The model utilized is espe-
cially suited for languages with a rich
morphology, such as Finnish. The first
method is based on the Minimum Descrip-
tion Length (MDL) principle and works
online. In the second method, Max-
imum Likelihood (ML) optimization is
used. The quality of the segmentations is
measured using an evaluation method that
compares the segmentations produced to
an existing morphological analysis. Ex-
periments on both Finnish and English
corpora show that the presented methods
perform well compared to a current state-
of-the-art system.
1 Introduction
According to linguistic theory, morphemes are con-
sidered to be the smallest meaning-bearing ele-
ments of language, and they can be defined in a
language-independent manner. However, no ade-
quate language-independent definition of the word
as a unit has been agreed upon (Karlsson, 1998,
p. 83). If effective methods can be devised for the
unsupervised discovery of morphemes, they could
aid the formulation of a linguistic theory of mor-
phology for a new language.
It seems that even approximative automated mor-
phological analysis would be beneficial for many
natural language applications dealing with large vo-
cabularies. For example, in text retrieval it is cus-
tomary to preprocess texts by returning words to
their base forms, especially for morphologically rich
languages.
Moreover, in large vocabulary speech recognition,
predictive models of language are typically used for
selecting the most plausible words suggested by an
acoustic speech recognizer (see, e.g., Bellegarda,
2000). Consider, for example the estimation of the
standard n-gram model, which entails the estima-
tion of the probabilities of all sequences of n words.
When the vocabulary is very large, say 100 000
words, the basic problems in the estimation of the
language model are: (1) If words are used as ba-
sic representational units in the language model, the
number of basic units is very high and the estimated
word n-grams are poor due to sparse data. (2) Due
to the high number of possible word forms, many
perfectly valid word forms will not be observed at
all in the training data, even in large amounts of text.
These problems are particularly severe for languages
with rich morphology, such as Finnish and Turkish.
For example, in Finnish, a single verb may appear in
thousands of different forms (Karlsson, 1987).
The utilization of morphemes as basic representa-
tional units in a statistical language model instead of
words seems a promising course. Even a rough mor-
phological segmentation could then be sufficient.
On the other hand, the construction of a comprehen-
sive morphological analyzer for a language based
on linguistic theory requires a considerable amount
of work by experts. This is both slow and expen-
sive and therefore not applicable to all languages.
                     July 2002, pp. 21-30.  Association for Computational Linguistics.
        ACL Special Interest Group in Computational Phonology (SIGPHON), Philadelphia,
       Morphological and Phonological Learning: Proceedings of the 6th Workshop of the
Table 1: The morphological structure of the Finnish
word for ?also for [the] coffee drinker?.
Word kahvinjuojallekin
Morphs kahvi n juo ja lle kin
Transl. coffee of drink -er for also
The problem is further compounded as languages
evolve, new words appear and grammatical changes
take place. Consequently, it is important to develop
methods that are able to discover a morphology for
a language based on unsupervised analysis of large
amounts of data.
As the morphology discovery from untagged cor-
pora is a computationally hard problem, in practice
one must make some assumptions about the struc-
ture of words. The appropriate specific assumptions
are somewhat language-dedependent. For example,
for English it may be useful to assume that words
consist of a stem, often followed by a suffix and pos-
sibly preceded by a prefix. By contrast, a Finnish
word typically consists of a stem followed by multi-
ple suffixes. In addition, compound words are com-
mon, containing an alternation of stems and suf-
fixes, e.g., the word kahvinjuojallekin (Engl.
?also for [the] coffee drinker?; cf. Table 1)1. More-
over, one may ask, whether a morphologically com-
plex word exhibits some hierarchical structure, or
whether it is merely a flat concatenation of stems
and suffices.
1.1 Previous Work on Unsupervised
Segmentation
Many existing morphology discovery algorithms
concentrate on identifying prefixes, suffixes and
stems, i.e., assume a rather simple inflectional mor-
phology.
De?jean (1998) concentrates on the problem of
finding the list of frequent affixes for a language
rather than attempting to produce a morphological
analysis of each word. Following the work of Zellig
Harris he identifies possible morpheme boundaries
by looking at the number of possible letters follow-
ing a given sequence of letters, and then utilizes fre-
quency limits for accepting morphemes.
1For a comprehensive view of Finnish morphology, see
(Karlsson, 1987).
Goldsmith (2000) concentrates on stem+suffix-
languages, in particular Indo-European languages,
and tries to produce output that would match as
closely as possible with the analysis given by a hu-
man morphologist. He further assumes that stems
form groups that he calls signatures, and each sig-
nature shares a set of possible affixes. He applies an
MDL criterion for model optimization.
The previously discussed approaches consider
only individual words without regard to their con-
texts, or to their semantic content. In a different ap-
proach, Schone and Jurafsky (2000) utilize the con-
text of each term to obtain a semantic representa-
tion for it using LSA. The division to morphemes
is then accepted only when the stem and stem+affix
are sufficiently similar semantically. Their method
is shown to improve on the performance of Gold-
smith?s Linguistica on CELEX, a morphologically
analyzed English corpus.
In the related field of text segmentation, one can
sometimes obtain morphemes. Some of the ap-
proaches remove spaces from text and try to identify
word boundaries utilizing e.g. entropy-based mea-
sures, as in (Redlich, 1993).
Word induction from natural language text with-
out word boundaries is also studied in (Deligne
and Bimbot, 1997; Hua, 2000), where MDL-based
model optimization measures are used. Viterbi or
the forward-backward algorithm (an EM algorithm)
is used for improving the segmentation of the cor-
pus2.
Also de Marcken (1995; 1996) studies the prob-
lem of learning a lexicon, but instead of optimiz-
ing the cost of the whole corpus, as in (Redlich,
1993; Hua, 2000), de Marcken starts with sentences.
Spaces are included as any other characters.
Utterances are also analyzed in (Kit and Wilks,
1999) where optimal segmentation for an utterance
is sought so that the compression effect over the seg-
ments is maximal. The compression effect is mea-
sured in what the authors call Description Length
Gain, defined as the relative reduction in entropy.
The Viterbi algorithm is used for searching for the
optimal segmentation given a model. The input ut-
2The regular EM procedure only maximizes the likelihood
of the data. To follow the MDL approach where model cost is
also optimized, Hua includes the model cost as a penalty term
on pure ML probabilities.
terances include spaces and punctuation as ordinary
characters. The method is evaluated in terms of pre-
cision and recall on word boundary prediction.
Brent presents a general, modular probabilistic
model structure for word discovery (Brent, 1999).
He uses a minimum representation length criterion
for model optimization and applies an incremental,
greedy search algorithm which is suitable for on-line
learning such that children might employ.
1.2 Our Approach
In this work, we use a model where words may con-
sist of lengthy sequences of segments. This model
is especially suitable for languages with agglutina-
tive morphological structure. We call the segments
morphs and at this point no distinction is made be-
tween stems and affixes.
The practical purpose of the segmentation is
to provide a vocabulary of language units that is
smaller and generalizes better than a vocabulary
consisting of words as they appear in text. Such a
vocabulary could be utilized in statistical language
modeling, e.g., for speech recognition. Moreover,
one could assume that such a discovered morph vo-
cabulary would correspond rather closely to linguis-
tic morphemes of the language.
We examine two methods for unsupervised learn-
ing of the model, presented in Sections 2 and 3. The
cost function for the first method is derived from the
Minimum Description Length principle from classic
information theory (Rissanen, 1989), which simul-
taneously measures the goodness of the representa-
tion and the model complexity. Including a model
complexity term generally improves generalization
by inhibiting overlearning, a problem especially se-
vere for sparse data. An incremental (online) search
algorithm is utilized that applies a hierarchical split-
ting strategy for words. In the second method the
cost function is defined as the maximum likelihood
of the data given the model. Sequential splitting is
applied and a batch learning algorithm is utilized.
In Section 4, we develop a method for evaluat-
ing the quality of the morph segmentations produced
by the unsupervised segmentation methods. Even
though the morph segmentations obtained are not in-
tended to correspond exactly to the morphemes of
linguistic theory, a basis for comparison is provided
by existing, linguistically motivated morphological
analyses of the words.
Both segmentation methods are applied to the
segmentation of both Finnish and English words.
In Section 5, we compare the results obtained from
our methods to results produced by Goldsmith?s Lin-
guistica on the same data.
2 Method 1: Recursive Segmentation and
MDL Cost
The task is to find the optimal segmentation of the
source text into morphs. One can think of this as
constructing a model of the data in which the model
consists of a vocabulary of morphs, i.e. the code-
book and the data is the sequence of text. We try to
find a set of morphs that is concise, and moreover
gives a concise representation for the data. This is
achieved by utilizing an MDL cost function.
2.1 Model Cost Using MDL
The total cost consists of two parts: the cost of the
source text in this model and the cost of the code-
book. Let M be the morph codebook (the vocab-
ulary of morph types) and D = m1m2 . . .mn the
sequence of morph tokens that makes up the string
of words. We then define the total cost C as
C = Cost(Source text) + Cost(Codebook)
=
?
tokens
? log p(mi) +
?
types
k ? l(mj)
The cost of the source text is thus the negative log-
likelihood of the morph, summed over all the morph
tokens that comprise the source text. The cost of the
codebook is simply the length in bits needed to rep-
resent each morph separately as a string of charac-
ters, summed over the morphs in the codebook. The
length in characters of the morph mj is denoted by
l(mj) and k is the number of bits needed to code a
character (we have used a value of 5 since that is suf-
ficient for coding 32 lower-case letters). For p(mi)
we use the ML estimate, i.e., the token count of mi
divided by the total count of morph tokens.
2.2 Search Algorithm
The online search algorithm works by incremen-
tally suggesting changes that could improve the cost
function. Each time a new word token is read
from the input, different ways of segmenting it into
morphs are evaluated, and the one with minimum
cost is selected.
Recursive segmentation. The search for the opti-
mal morph segmentation proceeds recursively. First,
the word as a whole is considered to be a morph and
added to the codebook. Next, every possible split of
the word into two parts is evaluated.
The algorithm selects the split (or no split) that
yields the minimum total cost. In case of no split,
the processing of the word is finished and the next
word is read from input. Otherwise, the search for a
split is performed recursively on the two segments.
The order of splits can be represented as a binary tree
for each word, where the leafs represent the morphs
making up the word, and the tree structure describes
the ordering of the splits.
During model search, an overall hierarchical data
structure is used for keeping track of the current
segmentation of every word type encountered so
far. Let us assume that we have seen seven in-
stances of linja-auton (Engl. ?of [the] bus?)
and two instances of autonkuljettajalla-
kaan (Engl. ?not even by/at/with [the] car driver?).
Figure 1 then shows a possible structure used for
representing the segmentations of the data. Each
chunk is provided with an occurrence count of the
chunk in the data set and the split location in this
chunk. A zero split location denotes a leaf node, i.e.,
a morph. The occurrence counts flow down through
the hierachical structure, so that the count of a child
always equals the sum of the counts of its parents.
The occurrence counts of the leaf nodes are used for
computing the relative frequencies of the morphs.
To find out the morph sequence that a word consists
of, we look up the chunk that is identical to the word,
and trace the split indices recursively until we reach
the leafs, which are the morphs.
Note that the hierarchical structure is used only
during model search: It is not part of the final model,
and accordingly no cost is associated with any other
nodes than the leaf nodes.
Adding and removing morphs. Adding new
morphs to the codebook increases the codebook
cost. Consequently, a new word token will tend to
be split into morphs already listed in the codebook,
which may lead to local optima. To better escape lo-
cal optima, each time a new word token is encoun-
13:2
0:210:2
0:2
5:2
kuljettajallakaan
kuljettajalla
kuljettaja lla
kaan
0:2
6:7
0:7
0:9
linja?
n
4:9
0:9
linja?auton
auton
auto
autonkuljettajallakaan
Figure 1: Hierarchical structure of the segmenta-
tion of the words linja-auton and autonkul-
jettajallakaan. The boxes represent chunks.
Boxes with bold text are morphs, and are part of the
codebook. The numbers above each box are the split
location (to the left of the colon sign) and the occur-
rence count of the chunk (to the right of the colon
sign).
tered, it is resegmented, whether or not this word has
been observed before. If the word has been observed
(i.e. the corresponding chunk is found in the hierar-
chical structure), we first remove the chunk and de-
crease the counts of all its children. Chunks with
zero count are removed (remember that removal of
leaf nodes corresponds to removal of morphs from
the codebook). Next, we increase the count of the
observed word chunk by one and re-insert it as an
unsplit chunk. Finally, we apply the recursive split-
ting to the chunk, which may lead to a new, different
segmentation of the word.
?Dreaming?. Due to the online learning, as the
number of processed words increases, the quality
of the set of morphs in the codebook gradually im-
proves. Consequently, words encountered in the be-
ginning of the input data, and not observed since,
may have a sub-optimal segmentation in the new
model, since at some point more suitable morphs
have emerged in the codebook. We have therefore
introduced a ?dreaming? stage: At regular intervals
the system stops reading words from the input, and
instead iterates over the words already encountered
in random order. These words are resegmented and
thus compressed further, if possible. Dreaming con-
tinues for a limited time or until no considerable de-
crease in the total cost can be observed. Figure 2
shows the development of the average cost per word
as a function of the increasing amount of source text.
0 20 40 60 80 10020
25
30
35
40
45
50Corpus: Finnish newspaper text 100 000 words
Number of words read [x 1000 words]
Ave
rage
 cost
 per 
word
 [bits
]
Figure 2: Development of the average word cost
when processing newspaper text. Dreaming, i.e., the
re-processing of the words encountered so far, takes
place five times, which can be seen as sudden drops
on the curve.
3 Method 2: Sequential Segmentation and
ML Cost
3.1 Model Cost Using ML
In this case, we use as cost function the likelihood
of the data, i.e., P (data|model). Thus, the model
cost is not included. This corresponds to Maximum-
Likelihood (ML) learning. The cost is then
Cost(Source text) =
?
morph tokens
? log p(mi), (1)
where the summation is over all morph tokens in the
source data. As before, for p(mi) we use the ML
estimate, i.e., the token count of mi divided by the
total count of morph tokens.
3.2 Search Algorithm
In this case, we utilize batch learning where an EM-
like (Expectation-Maximization) algorithm is used
for optimizing the model. Moreover, splitting is not
recursive but proceeds linearly.
1. Initialize segmentation by splitting words into
morphs at random intervals, starting from the
beginning of the word. The lengths of intervals
are sampled from the Poisson distribution with
? = 5.5. If the interval is larger than the num-
ber of letters in the remaining word segment,
the splitting ends.
2. Repeat for a number of iterations:
(a) Estimate morph probabilities for the given
splitting.
(b) Given the current set of morphs and their
probabilities, re-segment the text using the
Viterbi algorithm for finding the segmen-
tation with lowest cost for each word.
(c) If not the last iteration: Evaluate the seg-
mentation of a word against rejection cri-
teria. If the proposed segmentation is not
accepted, segment this word randomly (as
in the Initialization step).
Note that the possibility of introducing a random
segmentation at step (c) is the only thing that allows
for the addition of new morphs. (In the cost function
their cost would be infinite, due to ML probability
estimates). In fact, without this step the algorithm
seems to get seriously stuck in suboptimal solutions.
Rejection criteria. (1) Rare morphs. Reject the
segmentation of a word if the segmentation contains
a morph that was used in only one word type in the
previous iteration. This is motivated by the fact that
extremely rare morphs are often incorrect. (2) Se-
quences of one-letter morphs. Reject the segmenta-
tion if it contains two or more one-letter morphs in
a sequence. For instance, accept the segmentation
halua + n (Engl. ?I want?, i.e. present stem of
the verb ?to want? followed by the ending for the first
person singular), but reject the segmentation halu
+ a + n (stem of the noun ?desire? followed by
a strange sequence of endings). Long sequences of
one-letter morphs are usually a sign of a very bad
local optimum that may even get worse in future it-
erations, in case too much probability mass is trans-
ferred onto these short morphs3.
3Nevertheless, for Finnish there do exist some one-letter
morphemes that can occur in a sequence. However, these mor-
phemes can be thought of as a group that belongs together: e.g.,
4 Evaluation Measures
We wish to evaluate the method quantitatively from
the following perspectives: (1) correspondence with
linguistic morphemes, (2) efficiency of compression
of the data, and (3) computational efficiency. The ef-
ficiency of compression can be evaluated as the total
description length of the corpus and the codebook
(the MDL cost function). The computational effi-
ciency of the algorithm can be estimated from the
running time and memory consumption of the pro-
gram. However, the linguistic evaluation is in gen-
eral not so straightforward.
4.1 Linguistic Evaluation Procedure
If a corpus with marked morpheme boundaries is
available, the linguistic evaluation can be computed
as the precision and recall of the segmentation. Un-
fortunately, we did not have such data sets at our dis-
posal, and for Finnish such do not even exist. In ad-
dition, it is not always clear exactly where the mor-
pheme boundary should be placed. Several alterna-
tives may be possible, cf. Engl. hope + d vs. hop
+ ed, (past tense of to hope).
Instead, we utilized an existing tool for providing
a morphological analysis, although not a segmenta-
tion, of words, based on the two-level morphology
of Koskenniemi (1983). The analyzer is a finite-state
transducer that reads a word form as input and out-
puts the base form of the word together with gram-
matical tags. Sample analyses are shown in Figure 3.
The tag set consists of tags corresponding to
morphological affixes and other tags, for example,
part-of-speech tags. We preprocessed the analyses
by removing other tags than those corresponding
to affixes, and further split compound base forms
(marked using the # character by the analyzer) into
their constituents. As a result, we obtained for each
word a sequence of labels that corresponds well to
a linguistic morphemic analysis of the word. A la-
bel can often be considered to correspond to a single
word segment, and the labels appear in the order of
the segments.
The following step consists in retrieving the seg-
mentation produced by one of the unsupervised seg-
mentation algorithms, and trying to align this seg-
the Finnish talo + j + a (plural partitive of ?house?); can
also be thought of as talo + ja.
Input Output
Word Base form Tags
easily EASY <DER:ly> ADV
bigger BIG A CMP
hours? HOUR N PL GEN
auton AUTO N SG GEN
puutaloja PUU#TALO N PL PTV
tehnyt TEHDA? V ACT PCP2 SG
Figure 3: Morphological analyses for some English
and Finnish word forms. The Finnish words are au-
ton (car?s), puutaloja ([some] wooden houses)
and tehnyt ([has] done). The tags are A (adjec-
tive), ACT (active voice), ADV (adverb), CMP (com-
parative), GEN (genitive), N (noun), PCP2 (2nd par-
ticiple), PL (plural), PTV (partitive), SG (singular),
V (verb), and <DER:ly> (-ly derivative).
mentation with the desired morphemic label se-
quence (cf. Figure 4).
A good segmentation algorithm will produce
morphs that align gracefully with the correct mor-
phemic labels, preferably producing a one-to-one
mapping. A one-to-many mapping from morphs
to labels is also acceptable, when a morph forms a
common entity, such as the suffix -ja in puutaloja,
which contains both the plural and partitive element.
By contrast, a many-to-one mapping from morphs
to a label is a sign of excessive splitting, e.g., t +
alo for talo (cf. English h + ouse for house).
Correct labels BIG CMP
Morph sequence bigg er
Correct labels HOUR PL GEN
Morph sequence hour s ?
Correct labels PUU TALO PL PTV
Morph sequence puu t alo ja
Figure 4: Alignment of obtained morph sequences
with their respective correct morphemic analyses.
We assume that the segmentation algorithm has
split the word bigger into the morphs bigg + er,
hours? into hour + s + ? and puutaloja into
puu + t + alo + ja.
Alignment procedure. We align the morph se-
quence with the morphemic label sequence using
dynamic programming, namely Viterbi alignment,
to find the best sequence of mappings between
morphs and morphemic labels. Each possible pair
of morph/morphemic label has a distance associated
with it. For each segmented word, the algorithm
searches for the alignment that minimizes the to-
tal alignment distance for the word. The distance
d(M,L) for a pair of morph M and label L is given
by:
d(M,L) = ? log
cM,L
cM
, (2)
where cM,L is the number of word tokens in which
the morph M has been aligned with the label L; and
cM is the number of word tokens that contain the
morph M in their segmentation. The distance mea-
sure can be thought of as the negative logarithm of a
conditional probability P (L|M). This indicates the
probability that a morph M is a realisation of a mor-
pheme represented by the label L. Put another way,
if the unsupervised segmentation algorithm discov-
ers morphs that are allomorphs of real morphemes, a
particular allomorph will ideally always be aligned
with the same (correct) morphemic label, which
leads to a high probability P (L|M), and a short dis-
tance d(M,L)4. In contrast, if the segmentation al-
gorithm does not discover meaningful morphs, each
of the segments will be aligned with a number of dif-
ferent morphemic labels throughout the corpus, and
as a consequence, the probabilities will be low and
the distances high.
We then utilize the EM algorithm for iteratively
improving the alignment. The initial alignment that
is used for computing initial distance values is ob-
tained through a string matching procedure: String
matching is efficient for aligning the stem of the
word with the base form (e.g., the morph puu with
the label PUU, and the morphs t + alo with the
label TALO). The suffix morphs that do not match
well with the base form labels will end up aligned
somehow with the morphological tags (e.g., the
morph ja with the labels PL + PTV).
4This holds especially for allomorphs of ?stem morphemes?,
e.g., it is possible to identify the English morpheme easy with
a probability of one from both its allomorphs: easy and easi.
However, suffixes, in particular, can have several meanings,
e.g., the English suffix s can mean either the plural of nouns
or the third person singular of the present tense of verbs.
Comparison of methods. In order to compare two
segmentation algorithms, the segmentation of each
is aligned with the linguistic morpheme labels, and
the total distance of the alignment is computed.
Shorter total distance indicates better segmentation.
However, one should note that the distance mea-
sure used favors long morphs. If a particular ?seg-
mentation? algorithm does not split one single word
of the corpus, the total distance can be zero. In such
a situation, the single morph that a word is com-
posed of is aligned with all morphemic labels of the
word. The morph M , i.e., the word, is unique, which
means that all probabilities P (L|M) are equal to
one: e.g., the morph puutaloja is always aligned
with the labels PUU + TALO + PL + PTV and no
other labels, which yields the probabilities P (PUU |
puutaloja) = P (TALO | puutaloja) = P (PL |
puutaloja) = P (PTV | puutaloja) = 1.
Therefore, part of the corpus should be used as
training data, and the rest as test data. Both data sets
are segmented using the unsupervised segmentation
algorithms. The training set is then used for estimat-
ing the distance values d(M,L). These values are
used when the test set is aligned. The better seg-
mentation algorithm is the one that yields a better
alignment distance for the test set.
For morph/label pairs that were never observed in
the training set, a maximum distance value is as-
signed. A good segmentation algorithm will find
segments that are good building blocks of entirely
new word forms, and thus the maximum distance
values will occur only rarely.
5 Experiments and Results
We compared the two proposed methods as well as
Goldsmith?s program Linguistica5 on both Finnish
and English corpora. The Finnish corpus consisted
of newspaper text from CSC6. A morphosyntac-
tic analysis of the text was performed using the
Conexor FDG parser7. All characters were con-
verted to lower case, and words containing other
characters than a through z and the Scandinavian
letters a?, a? and o? were removed. Other than mor-
phemic tags were removed from the morphological
5http://humanities.uchicago.edu/faculty/goldsmith/Linguist-
ica2000/
6http://www.csc.fi/kielipankki/
7http://www.conexor.fi/
analyses of the words. The remaining tags corre-
spond to inflectional affixes (i.e. endings and mark-
ers) and clitics. Unfortunately the parser does not
distinguish derivational affixes. The first 100 000
word tokens were used as training data, and the fol-
lowing 100 000 word tokens were used as test data.
The test data contained 34 821 word types.
The English corpus consisted of mainly newspa-
per text from the Brown corpus8. A morphologi-
cal analysis of the words was performed using the
Lingsoft ENGTWOL analyzer9. In case of multi-
ple alternative morphological analyses, the shortest
analysis was selected. All characters were converted
to lower case, and words containing other characters
than a through z, an apostrophe or a hyphen were
removed. Other than morphemic tags were removed
from the morphological analyses of the words. The
remaining tags correspond to inflectional or deriva-
tional affixes. A set of 100 000 word tokens from the
corpus sections Press Reportage and Press Editorial
were used as training data. A separate set of 100 000
word tokens from the sections Press Editorial, Press
Reviews, Religion, and Skills Hobbies were used as
test data. The test data contained 12 053 word types.
Test results for the three methods and the two lan-
guages are shown in Table 2. We observe different
tendencies for Finnish and English. For Finnish,
there is a correlation between the compression of
the corpus and the linguistic generalization capac-
ity to new word forms. The Recursive splitting with
the MDL cost function is clearly superior to the Se-
quential splitting with ML cost, which in turn is su-
perior to Linguistica. The Recursive MDL method
is best in terms of data compression: it produces the
smallest morph lexicon (codebook), and the code-
book naturally occupies a small part of the total cost.
It is best also in terms of the linguistic measure, the
total alignment distance on test data. Linguistica, on
the other hand, employs a more restricted segmenta-
tion, which leads to a larger codebook and to the fact
that the codebook occupies a large part of the total
MDL cost. This also appears to lead to a poor gen-
eralization ability to new word forms. The linguis-
tic alignment distance is the highest, and so is the
percentage of aligned morph/morphemic label pairs
8The Brown corpus is available at the Linguistic Data Con-
sortium at http://www.ldc.upenn.edu/
9http://www.lingsoft.fi/
that were never observed in the training set. On the
other hand, Linguistica is the fastest program10.
Also for English, the Recursive MDL method
achieves the best alignment, but here Linguistica
achieves nearly the same result. The rate of com-
pression follows the same pattern as for Finnish,
in that Linguistica produces a much larger morph
lexicon than the methods presented in this pa-
per. In spite of this fact, the percentage of unseen
morph/morphemic label pairs is about the same for
all three methods. This suggests that in a morpho-
logically poor language such as English a restrictive
segmentation method, such as Linguistica, can com-
pensate for new word forms ? that it does not rec-
ognize at all ? with old, familiar words, that it ?gets
just right?. In contrast, the methods presented in this
paper produce a morph lexicon that is smaller and
able to generalize better to new word forms but has
somewhat lower accuracy for already observed word
forms.
Visual inspection of a sample of words. In an
attempt to analyze the segmentations more thor-
oughly, we randomly picked 1000 different words
from the Finnish test set. The total number of occur-
rences of these words constitute about 2.5% of the
whole set. We inspected the segmentation of each
word visually and classified it into one of three cat-
egories: (1) correct and complete segmentation (i.e.,
all relevant morpheme boundaries were identified),
(2) correct but incomplete segmentation (i.e., not all
relevant morpheme boundaries were identified, but
no proposed boundary was incorrect), (3) incorrect
segmentation (i.e., some proposed boundary did not
correspond to an actual morpheme boundary).
The results of the inspection for each of the three
segmentation methods are shown in Table 3. The
Recursive MDL method performs best and segments
about half of the words correctly. The Sequential
ML method comes second and Linguistica third with
a share of 43% correctly segmented words. When
considering the incomplete and incorrect segmenta-
tions the methods behave differently. The Recursive
MDL method leaves very common word forms un-
split, and often produces excessive splitting for rare
10Note, however, that the computing time comparison with
Linguistica is only approximate since it was a compiled pro-
gram run on Windows whereas the two other methods were im-
plemented as Perl scripts run on Linux.
Table 2: Test results for the Finnish and English corpus. Method names are abbreviated: Recursive seg-
mentation and MDL cost (Rec. MDL), Sequential segmentation and ML cost (Seq. ML), and Linguistica
(Ling.). The total MDL cost measures the compression of the corpus. However, the cost is computed accord-
ing to Equation (1), which favors the Recursive MDL method. The final number of morphs in the codebook
(#morphs in codebook) is a measure of the size of the morph ?vocabulary?. The relative codebook cost
gives the share of the total MDL cost that goes into coding the codebook. The alignment distance is the total
distance computed over the sequence of morph/morphemic label pairs in the test data. The unseen aligned
pairs is the percentage of all aligned morph/label pairs in the test set that were never observed in the training
set. This gives an indication of the generalization capacity of the method to new word forms.
Language Finnish English
Method Rec. MDL Seq. ML Ling. Rec. MDL Seq. ML Ling.
Total MDL cost [bits] 2.09M 2.27M 2.88M 1.26M 1.34M 1.44M
#morphs in codebook 6302 10 977 22 075 3836 4888 8153
Relative codebook cost 10.16% 15.27% 36.81% 9.42% 10.90% 19.14%
Alignment distance 768k 817k 1111k 313k 444k 332k
Unseen aligned pairs 23.64% 20.20% 37.22% 18.75% 19.67% 20.94%
Time [sec] 620 390 180 130 80 30
Table 3: Estimate of accuracy of morpheme bound-
ary detection based on visual inspection of a sample
of 2500 Finnish word tokens.
Method Correct Incomplete Incorrect
Rec. MDL 49.6% 29.7% 20.6%
Seq. ML 47.3% 15.3% 37.4%
Linguistica 43.1% 24.1% 32.8%
words. The Sequential ML method is more prone to
excessive splitting, even for words that are not rare.
Linguistica, on the other hand, employs a more con-
servative splitting strategy, but makes incorrect seg-
mentations for many common word forms.
The behaviour of the methods is illustrated by ex-
ample segmentations in Table 4. Often the Recur-
sive MDL method produces complete and correct
segmentations. However, both it and the Sequential
ML method can produce excessive splitting, as is
shown for the latter, e.g. affecti + on + at
+ e. In contrast, Linguistica refrains from splitting
words when they should be split, e.g., the Finnish
compound words in the table.
6 Discussion of the Model
Regarding the model, there is always room for im-
provement. In particular, the current model does
not allow representation of contextual dependencies,
i.e., that some morphs appear only in particular con-
texts (allomorphy). Moreover, languages have rules
regarding the ordering of stems and affixes (morpho-
tax). However, the current model has no way of rep-
resenting such contextual dependencies.
7 Conclusions
In the experiments the online method with the MDL
cost function and recursive splitting appeared most
successful especially for Finnish, whereas for En-
glish the compared methods were rather equal in
performance. This is likely to be partially due to
the model structure of the presented methods which
is especially suitable for languages such as Finnish.
However, there is still room for considerable im-
provement in the model structure, especially regard-
ing the representation of contextual dependencies.
Considering the two examined model optimiza-
tion methods, the Recursive MDL method per-
formed consistently somewhat better. Whether this
is due to the cost function or the splitting strategy
cannot be deduced based on these experiments. In
the future, we intend to extend the latter method to
utilize an MDL-like cost function.
Table 4: Some English and Finnish word segmentations produced by the three methods. The Finnish words
are ela?inla?a?ka?ri (veterinarian, lit. animal doctor), ela?inmuseo (zoological museum, lit. animal
museum), ela?inpuisto (zoological park, lit. animal park), and ela?intarha (zoo, lit. animal garden).
The suffixes -lle, -n, -on, and -sta are linguistically correct. (Note that in the Sequential ML method
the rejection criteria mentioned are not applied on the last round of Viterbi segmentation. This is why two
one letter morphs appear in a sequence in the segmentation ela?in + tarh + a + n.)
Recursive MDL Sequential ML Linguistica
affect affect affect
affect + ing affect + ing affect + ing
affect + ing + ly affect + ing + ly affect + ing + ly
affect + ion affecti + on affect + ion
affect + ion + ate affecti + on + at + e affect + ion + ate
affect + ion + s affecti + on + s affect + ion + s
affect + s affect + s affect + s
ela?in + la?a?ka?ri ela?in + la?a?ka?ri ela?inla?a?ka?ri
ela?in + la?a?ka?ri + lle ela?in + la?a?ka?ri + lle ela?inla?a?ka?ri + lle
ela?in + museo + n ela?in + museo + n ela?inmuseo + n
ela?in + museo + on ela?in + museo + on ela?inmuseo + on
ela?in + puisto + n ela?in + puisto + n ela?inpuisto + n
ela?in + puisto + sta ela?in + puisto + sta ela?inpuisto + sta
ela?in + tar + han ela?in + tarh + a + n ela?intarh + an
References
Jerome Bellegarda. 2000. Exploiting latent semantic in-
formation in statistical language modeling. Proceed-
ings of the IEEE, 88(8):1279?1296.
Michael R. Brent. 1999. An efficient, probabilistically
sound algorithm for segmentation and word discovery.
Machine Learning, 34:71?105.
Carl de Marcken. 1995. The unsupervised acquisition
of a lexicon from continuous speech. Technical Re-
port A.I. Memo 1558, MIT Artificial Intelligence Lab.,
Cambridge, Massachusetts.
Carl de Marcken. 1996. Linguistic structure as compo-
sition and perturbation. In Meeting of the Association
for Computational Linguistics.
Herve? De?jean. 1998. Morphemes as necessary con-
cept for structures discovery from untagged corpora.
In Workshop on Paradigms and Grounding in Natural
Language Learning, pages 295?299, Adelaide, Jan.
22.
Sabine Deligne and Fre?de?ric Bimbot. 1997. Inference of
variable-length linguistic and acoustic units by multi-
grams. Speech Communication, 23:223?241.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguistics, 27(2):153?198.
Yu Hua. 2000. Unsupervised word induction using MDL
criterion. In Proceedings of ISCSL, Beijing.
Fred Karlsson. 1987. Finnish Grammar. WSOY, Juva,
second edition.
Fred Karlsson. 1998. Yleinen kielitiede.
Yliopistopaino/Helsinki University Press.
Chunyu Kit and Yorick Wilks. 1999. Unsupervised
learning of word boundary with description length
gain. In Proceedings of CoNLL99 ACL Workshop,
Bergen.
Kimmo Koskenniemi. 1983. Two-level morphology:
A general computational model for word-form recog-
nition and production. Ph.D. thesis, University of
Helsinki.
A. Norman Redlich. 1993. Redundancy reduction as a
strategy for unsupervised learning. Neural Computa-
tion, 5:289?304.
Jorma Rissanen. 1989. Stochastic complexity in statis-
tical inquiry. World Scientific Series in Computer Sci-
ence, 15:79?93.
Patrick Schone and Daniel Jurafsky. 2000. Knowledge-
free induction of morphology using latent semantic
analysis. In Proceedings of CoNLL-2000 and LLL-
2000, pages 67?72, Lisbon.
Induction of a Simple Morphology for Highly-Inflecting Languages
Mathias Creutz and Krista Lagus
Neural Networks Research Centre
Helsinki University of Technology
P.O.Box 5400, FIN-02015 HUT, Finland
{Mathias.Creutz, Krista.Lagus}@hut.fi
Abstract
This paper presents an algorithm for the unsuper-
vised learning of a simple morphology of a nat-
ural language from raw text. A generative prob-
abilistic model is applied to segment word forms
into morphs. The morphs are assumed to be gener-
ated by one of three categories, namely prefix, suf-
fix, or stem, and we make use of some observed
asymmetries between these categories. The model
learns a word structure, where words are allowed
to consist of lengthy sequences of alternating stems
and affixes, which makes the model suitable for
highly-inflecting languages. The ability of the al-
gorithm to find real morpheme boundaries is eval-
uated against a gold standard for both Finnish and
English. In comparison with a state-of-the-art al-
gorithm the new algorithm performs best on the
Finnish data, and on roughly equal level on the En-
glish data.
1 Introduction
We are intrigued by the endeavor of devising artifi-
cial systems that are capable of learning natural lan-
guage in an unsupervised manner. As untagged text
data is available in large quantities for a large num-
ber of languages, unsupervised methods may be ap-
plied much more widely, or with much lower cost,
than supervised ones.
Some languages, such as Finnish, Turkish, and
Swahili, are highly-inflecting. We wish to use this
term in a wide sense including many kinds of pro-
cesses for word forming, e.g., compounding and
derivation. Their essential challenge for natural lan-
guage applications arises from the very large num-
ber of possible word forms, which causes problems
of data sparsity. For instance, creating extensive
word lists is not a feasible strategy for obtaining
good coverage on the vocabulary necessary for a
general dictation task in automatic speech recogni-
tion. Instead, a model of the language should in-
corporate regularities of how words are formed; cf.
e.g., (Siivola et al, 2003; Hacioglu et al, 2003).
We will now focus on methods that try to induce
the morphology of a natural language from raw text,
that is, on algorithms that learn in an unsupervised
manner how words are formed. If a human were to
learn a language in an analogous way, this would
correspond to being exposed to a stream of large
amounts of language without observing or interact-
ing with the world where this language is produced.
This is clearly not a realistic assumption about lan-
guage learning in humans. However, Saffran et
al. (1996) show that adults are capable of discov-
ering word units rapidly in a stream of a nonsense
language, where there is no connection to a meaning
of the discovered word-like units. This suggests that
humans do use distributional cues, such as transition
probabilities between sounds, in language learning.
And these kinds of statistical patterns in language
data can be successfully exploited by appropriately
designed algorithms.
Existing morphology learning algorithms are
commonly based on the Item and Arrangement
model, i.e., words are formed by a concatenation
of morphemes, which are the smallest meaning-
bearing units in language. The methods segment
words, and the resulting segments are supposed to
be close to linguistic morphemes. In addition to
producing a segmentation of words the aim is of-
ten to discover structure, such as knowledge of
which word forms belong to the same inflectional
paradigm.
Typically, generative models are used, either for-
mulated in a Bayesian framework, e.g., (Brent,
1999; Creutz, 2003); or applying the Minimum De-
scription Length (MDL) principle, e.g., (de Mar-
cken, 1996; Goldsmith, 2001; Creutz and Lagus,
2002). There is another approach, inspired by the
works of Zellig Harris, where a morpheme bound-
ary is suggested at locations where the predictability
of the next letter in a letter sequence is low, cf. e.g.,
(De?jean, 1998).
As it is necessary to learn both which segments
are plausible morphemes and what sequences of
morphemes are possible, the learning task is al-
                                                                  Barcelona, July 2004
                                              Association for Computations Linguistics
                       ACL Special Interest Group on Computational Phonology (SIGPHON)
                                                    Proceedings of the Workshop of the
huumori n taju ttom uute nne
humor of sense -less -ness your
Figure 1: Morpheme segmentation of the Finnish
word ?huumorintajuttomuutenne? (?your lack of
sense of humor?).
leviated by making simplifying assumptions about
word structure. Often words are assumed to con-
sist of one stem followed by one, possibly empty,
suffix as in, e.g., (De?jean, 1998; Snover and Brent,
2001). In (Goldsmith, 2001) a recursive struc-
ture is proposed, such that stems can consist of a
sub-stem and a suffix. Also prefixes are possible.
Other algorithms (Creutz and Lagus, 2002; Creutz,
2003) have been developed for highly-inflecting
languages, such as Finnish, where words can con-
sist of lengthy sequences of alternating stems and
affixes (see Fig. 1 for an example). These resem-
ble algorithms that segment text without blanks (or
transcribed speech) into words, e.g., (de Marcken,
1996; Brent, 1999), in that they do not distinguish
between stems and affixes, but split words into so
called morphs, which carry no explicit category in-
formation.
Some algorithms do not rely on the Item and Ar-
rangement (IA) model, but learn relationships be-
tween words by comparing the orthographic sim-
ilarity of pairs of words. In (Neuvel and Fulop,
2002), a morphological learner based on the theory
of Whole Word Morphology is outlined. Full words
are related to other full words, and complex word
forms are analyzed into a variable and non-variable
component. Conceivably, in this framework non-
concatenative morphological processes, such as um-
laut in German, should not be as problematic as in
the IA model.
Other algorithms combine information of both
orthographic and semantic similarity of words
(Schone and Jurafsky, 2000; Baroni et al, 2002).
Semantic similarity is measured in terms of sim-
ilar word contexts. If two orthographically simi-
lar words occur in the context of roughly the same
set of other words they probably share the same
base form, e.g. German ?Vertrag? vs. ?Vertra?gen?
(treaty).
Further cues for morphological learning are
presented in (Schone and Jurafsky, 2001) and
(Yarowsky and Wicentowsky, 2000). The latter uti-
lizes frequency distributions over different inflec-
tional forms (e.g., how often an English verb oc-
curs in its past tense form in comparison to its base
form). The algorithm is not entirely unsupervised.
However, none of these non-IA models suits
highly-inflecting languages as they assume only two
or three constituents per word, analogous to stem
and suffix. In order to cope with a broader range
of languages we would need the following: On the
one hand, words should be allowed to consist of any
number of alternating stems and affixes, making the
model more flexible than, e.g., the model in (Gold-
smith, 2001). On the other hand, in contrast with
(Creutz and Lagus, 2002; Creutz, 2003), sequential
dependencies between morphs, i.e., morphotactics,
should be taken into account in order to reduce the
error rate.
We present a model that incorporates both of
these aspects. Experiments show that the new al-
gorithm is able to obtain considerable improve-
ments over the segmentation produced by the al-
gorithm described in (Creutz, 2003). Moreover, it
performs better than a state-of-the-art morphology-
learning algorithm, Linguistica (Goldsmith, 2001),
when evaluated on Finnish data. In the evaluation,
the ability of the algorithms to detect morpheme
boundaries are measured against a gold standard for
both Finnish and English, languages with rather dif-
ferent types of word structure.
2 A probabilistic category-learning
algorithm
2.1 Linguistic assumptions
We use a Hidden Markov Model (HMM) to model
morph sequences. Previously, HMM?s have been
used extensively for, e.g., segmentation or tagging
purposes. The challenge in this task lies in knowing
neither the segments (morphs), nor their tags (cat-
egories) in advance. To make the task easier, we
utilize the following linguistic assumptions, formu-
lated probabilistically:
(a) Categorial assumption. We assume that with
respect to sequential behavior, morphs fall into two
main categories, stems and affixes. Affixes are fur-
ther divided into prefixes and suffixes.
(b) Impossible category sequences. We want to
be able to cope with languages with extensive com-
pounding and many consecutive affixes, but not
with just any sequence. In particular, we do not wish
to allow that a suffix may start a word, or that a pre-
fix end it. Moreover, a prefix should not be followed
directly by a suffix. These restrictions are captured
by the following regular expression:
word = ( prefix* stem suffix* )+
(1)
Note that no assumptions are made regarding
whether the language is more likely to employ pre-
fixation or suffixation.
(c) Likely properties of morphs in each category.
Grammatical affixes mainly carry syntactic infor-
mation. We therefore assume that affixes are likely
to be common ?general-purpose? morphs that can
be used in connection with a large number of other
morphs. By contrast, the set of stems is much larger
and there are a considerable number of rare stems
that mainly carry semantic information. In order for
all stems to be distinguishable from each other they
are not likely to be very short morphs.
2.2 Probabilistic generative model for word
formation
We use an HMM to assign probabilities to each pos-
sible segmentation of a word form. The word is
segmented into morphs, each of which belongs to
one category: prefix, suffix, or stem. We assume a
first-order Markov chain, i.e., a bigram model, for
the morph categories. For each category, there is a
separate probability distribution over the set of pos-
sible morphs. The probability of a particular seg-
mentation of the word w into the morph sequence
?1?2 . . . ?k is thus:
p(?1?2 . . . ?k | w) = (2)
[
k
?
i=1
p(Ci | Ci?1) ? p(?i | Ci)
]
? p(Ck+1 | Ck).
The bigram probability of a transition from
one morph category to another is expressed by
p(Ci | Ci?1). For instance, the probability of
observing a stem after a prefix would be written
as p(STM | PRE). The probability of observing
the morph ?i when the category Ci is given is ex-
pressed by p(?i | Ci). The categories C0 and
Ck+1 represent word boundaries. That is, we take
into account the transition from a word boundary to
the first morph in the word, as well as the transition
from the last morph to a word boundary.
Note also that a morph can be generated from sev-
eral categories, e.g., a particular morph can function
as a stem or a suffix depending on the context.
2.3 The algorithm step by step
The algorithm involves the following steps: (i) pro-
duction of a baseline segmentation, (ii) initialization
of p(?i | Ci) and p(Ci | Ci?1), (iii) removal of re-
dundant morphs, and (iv) removal of noise morphs.
All steps involve a modification of the morph seg-
mentations, except step (ii), where the probability
distributions are initialized.
Steps (ii)?(iv) are all concluded with a re-
estimation of the probabilities by means of
Expectation-Maximization (EM): The words seg-
mented into morphs are re-tagged using the Viterbi
algorithm by maximizing Equation 2. The proba-
bilities p(?i | Ci) and p(Ci | Ci?1) are then
re-estimated from the tagged data. This is repeated
until convergence of the probabilities.
Step (iv) is further followed by a final pass of
the Viterbi algorithm, which re-splits and tags the
words. Viterbi re-splitting improves the segmen-
tation somewhat, but it is much slower than mere
tagging. Therefore Viterbi re-splitting is only per-
formed at the final stage.
2.3.1 Baseline segmentation
A good initial morph segmentation is obtained by
the baseline segmentation method (Creutz and La-
gus, 2002). The choice of baseline segmentation
was motivated by the fact that we wanted the best
possible segmentation that suits highly-inflecting
languages. The baseline algorithm is based on a
probabilistic model that learns a set of morphs, or a
morph lexicon, that contains the most likely ?build-
ing blocks? of the word forms observed in the cor-
pus used as data. The learning process is guided
by two prior probability distributions, a prior dis-
tribution on morph lengths and a prior distribution
on morph frequencies, i.e., the balance between fre-
quent and rare morphs.
2.3.2 Initialization of the probability
distributions
Given an initial baseline morph segmentation
and initial category membership probabilities
p(Ci | ?k) for each segment (morph), random
sampling of this distribution can be utilized to ob-
tain specific tags for the morphs. From the tagged
segmentation we can estimate the desired values
p(Cj | Ci) and p(?k | Ci).
Below we describe how the initial category mem-
bership probabilities p(Ci | ?k) emerge. These are
probabilities that a particular morph is a prefix, suf-
fix, or stem. In addition, during the process a tem-
porary noise category is utilized, to hold segments
that cannot be considered as prefix, suffix, or stem.
Identifying plausible affixes and stems. To iden-
tify plausible affixes in our corpus we take the base-
line splitting and collect information on the contexts
that every discovered morph occurs in. More specif-
ically, we assume that a morph is likely to be a prefix
if it is difficult to predict what the following morph
is going to be. That is, there are many possible right
contexts of the morph. Correspondingly, a morph is
likely to be a suffix if it is difficult to predict what
the preceding morph can be.
We use perplexity to measure the predictability
of the preceding or following morph in relation to
a specific target morph. The following formula can
be used for calculating the left perplexity of a target
morph ?:
Left-ppl(?) =
[
?
?i ? Left-of(?)
p(?i | ?)
]? 1N? . (3)
There are N? occurrences of the target morph ? in
the corpus. The morph tokens ?i occur to the left of,
immediately preceding, the occurrences of ?. The
probability distribution p(?i | ?) is calculated over
all such ?i. Right perplexity can be computed anal-
ogously.
Next, we implement a graded threshold of suffix-
likeness by applying a sigmoid function to the left
perplexity of the morphs.
Suffix-like(?) = [1 + e?a?(Left-ppl(?)?b)]?1. (4)
The parameter b is the perplexity threshold, which
indicates the point where a morph ? is as likely to be
a suffix as a non-suffix. The parameter a governs the
steepness of the sigmoid. The equations for prefix
are identical except that right perplexity is applied
instead of left perplexity.
As for stems, we assume that the stem-likeness
of a morph correlates positively with the length in
letters of the morph. We employ a sigmoid function
as above, which yields:
Stem-like(?) = [1 + e?c?(Length(?)?d)]?1, (5)
where d is the length threshold and c governs the
steepness of the curve.
Initial probability of a morph belonging to a cat-
egory. Prefix-, suffix- and stem-likeness assume
values between zero and one, but they are no prob-
abilities, since they usually do not sum up to one.
In order to create a probability distribution, we
first introduce a fourth category besides prefixes,
suffixes and stems. This category is the noise cat-
egory and corresponds to cases where none of the
proper morph classes is likely. Typically noise
morphs arise as a consequence of over-segmentation
of rare word forms in the baseline word splitting.
We set the probability of a morph being noise
(NOI) to:
p(NOI | ?) = [1 ? Prefix-like(?)]
?[1 ? Suffix-like(?)] ? [1 ? Stem-like(?)]. (6)
We then distribute the remaining probability mass
proportionally between prefix (PRE), suffix (SUF),
and stem (STM), e.g.:
p(SUF | ?) =
Suffix-like(?) ? [1 ? p(NOI | ?)]
Prefix-like(?) + Suffix-like(?) + Stem-like(?) . (7)
2.3.3 Removal of redundant morphs
As a result of applying the baseline segmentation al-
gorithm, there are possibly many redundant morphs,
that is, morphs that consist of other discovered
morphs. Each morph is studied. If it is possible
to split it into two other known morphs, the most
probable split is selected and the redundant morph
is removed. The most probable split is determined
as:
arg max
?1,C1,?2,C2
p(?1 | C1) ? p(C2 | C1) ? p(?2 | C2),
(8)
where C1 and C2 are morph categories, and ?1 and
?2 are substrings of the redundant morph ?, such
that the concatenation of ?1 and ?2 yields ?.
However, some restrictions apply: Splitting into
?noise morphs? is not allowed. Furthermore, forbid-
den category transitions are not allowed to emerge,
such as a direct transition from a prefix to a suffix
without going through a stem. Nor is splitting into
sub-morphs with very low probability accepted.
2.3.4 Removal of noise morphs
As noise morphs are mainly very short morphs and
a product of over-segmentation in the baseline split-
ting algorithm, they are removed by joining with ei-
ther of the adjacent morphs. The new morph is then
labeled as noise. This is repeated until the resulting
morph can qualify as a stem, which is determined
by the Equation 5. The following heuristics are ap-
plied: Joining with shorter morphs is preferred, and
joining noise with noise or a stem is always pre-
ferred to joining with a prefix or a suffix. These pri-
orities are motivated by the observation that noise
morphs tend to be fragments of what should be a
stem.
3 Evaluation
We have produced gold standard segmentations
with marked morpheme boundaries for 1.4 mil-
lion Finnish and 36 000 English word forms. We
evaluate the segmentations produced by our split-
ting algorithm against the gold standard, and com-
pute precision and recall on discovered morpheme
boundaries. Precision is the proportion of correct
boundaries among all morph boundaries suggested
by the algorithm. Recall is the proportion of correct
boundaries discovered by the algorithm in relation
to all morpheme boundaries in the gold standard.
The gold standard was created semi-
automatically, by first running all words through
a morphological analyzer based on the two-level
morphology of Koskenniemi (1983).1 For each
1The software was licensed from Lingsoft, Inc. <http:
word form, the analyzer outputs the base form of
the word together with grammatical tags indicating,
e.g., the part-of-speech, case, or derivational type
of the word form. In addition, the boundaries
between the constituents of compound words are
often marked. We thoroughly investigated the
correspondence between the grammatical tags
and the corresponding morphemes and created a
rule-set for segmenting the original word forms
with the help of the output of the analyzer.
As there can sometimes be many plausibly cor-
rect segmentation of a word we supplied several
alternatives when needed, e.g., English ?evening?
(time of day) vs. ?even+ing? (verb). We also intro-
duced so called ?fuzzy? boundaries between stems
and endings, allowing some letter to belong to ei-
ther the stem or ending, when both alternatives are
reasonable, e.g., English ?invite+s? vs. ?invit+es?
(cf. ?invit+ing?), or Finnish ?ta?hde+n? vs. ?ta?hd+en?
(?of the star?; the base form is ?ta?hti?).2
4 Experiments
We report experiments on Finnish and English cor-
pora. The new category-learning algorithm is com-
pared to two other algorithms, namely the baseline
segmentation algorithm presented in (Creutz, 2003),
which was also utilized for initializing the segmen-
tation in the category-learning algorithm, and the
Linguistica algorithm (Goldsmith, 2001).3
4.1 Data sets
The Finnish corpus consists of mainly news texts
from the CSC (The Finnish IT Center for Science)4
and the Finnish News Agency. The corpus consists
of 32 million words and it was divided into a devel-
opment set and a test set, each containing 16 million
words. For experiments on English we have used
the Brown corpus5. It contains one million words,
divided into a development set of 250 000 words and
a test set of 750 000 words.
The development sets were utilized for optimiz-
ing the algorithms and for selecting parameter val-
ues, whereas the test sets were used solely in the
final evaluation.
//www.lingsoft.fi>.
2Our gold standard segmentations for Finnish and English
words are not public, but we are currently investigating the pos-
sibility of making them public.
3We used the December 2003 version of the soft-
ware, available at <http://humanities.uchicago.
edu/faculty/goldsmith/Linguistica2000/>.
4<http://www.csc.fi/kielipankki/>
5Available at the Linguistic Data Consortium: <http://
www.ldc.upenn.edu>
Finnish English
Word tokens Word types Word types
10 000 5 500 2 400
50 000 20 000 7 400
250 000 65 000 20 000
16 000 000 1 100 000 ?
Table 1: Sizes of the Finnish and English test sets.
The algorithms were evaluated on different sub-
sets of the test set to produce the precision-recall
curves in Figure 2. The sizes of the subsets are
shown in Table 1. As can be seen, the Finnish and
English data sets contain the same number of word
tokens (words of running text), but the number of
word types (distinct word forms) is higher in the
Finnish data. The word type figures are important,
since what was referred to as a ?corpus? in the pre-
vious sections is actually a word list. That is, one
occurrence of each distinct word form in the data is
picked for the morphology learning task.
The word forms in the test sets for which there
are no gold standard segmentations are simply left
out of the evaluation. The proportions of such word
forms are 5%, 6%, 8%, and 15% in the Finnish
sets of size 10 000, 50 000, 250 000 and 16 million
words, respectively. For English the proportions are
5%, 9%, and 14% for the data sets (in growing or-
der).
4.2 Parameters
The development sets were used for setting the val-
ues of the parameters of the algorithms. As a cri-
terion for selecting the optimal values, we used
the (equally weighted) F-measure, which is the
harmonic mean of the precision and recall of de-
tected morpheme boundaries. For each data size
and language separately, we selected the configura-
tion yielding the best F-measure on the development
set. These values were then fixed and utilized when
evaluating the performance of the algorithms on the
test set of corresponding size.
In the Baseline algorithm, we optimized the prior
morph length distribution. The prior morph fre-
quency distribution was left at its default value.
The Category algorithm has four parameters: a,
b, c, and d; cf. Equations 4, and 5. The constant val-
ues c = 2, d = 3.5 work well for every data set size
and language, as does the relation a = 10/b. The
perplexity threshold, b, assumes values between 5
and 100 depending on the data set. Conveniently,
the algorithm is robust with respect to the value of b
and the result is always better than that of the Base-
line algorithm, except for values of b that are orders
30 40 50 60 70
40
50
60
70
80
90
Recall [%]
Pr
ec
is
io
n 
[%
]
Finnish
10k
50k
250k
10k
50k
250k 16M
10k
50k
250k
16M
Baseline
Categories
Linguistica
(a)
60 70 80
40
50
60
70
80
90
Recall [%]
Pr
ec
is
io
n 
[%
]
English
10k
50k
250k
10k
50k 250k
10k
50k 250k
(b)
Figure 2: Precision and recall of the three algorithms on test sets of increasing sizes on both Finnish (a) and
English (b) data. Each data point is an average of 4 runs on separate test sets, with the exception of the 16M
(16 million) words for Finnish (with 1 test set), and the 250k (250 000) words for English (3 test sets). In
these cases the lack of test data constrained the number of runs. The standard deviations of the averages are
shown as intervals around the data points. There is no 16M data point for Linguistica on Finnish, because
the algorithm is very memory-consuming and we could not run it on larger data sizes than 250 000 words
on our PC. In most curves, when the data size is increased, recall also rises. An exception is the Baseline
curve for Finnish, where precision rises, while recall drops.
of magnitude too large.
In the Linguistica algorithm, we used the com-
mands ?Find suffix system? and ?Find prefixes of
suffixal stems?.
4.3 Results
Figure 2 depicts the precision and recall of the algo-
rithms on test sets of different sizes.
When studying the curves for Finnish (Fig. 2a),
we observe that the Baseline and Category algo-
rithms perform on a similar level on the smallest
data set (10k). However, from there the perfor-
mances diverge: the Category algorithm improves
on both precision and recall, whereas the Baseline
algorithm displays a strong increase in precision
while recall actually decreases. This means that
words are split less often but the proposed splits are
more often correct. This is due to measuring the cost
of both the lexicon and the data in the optimization
function: with a much larger corpus (more data) the
optimal solution contains a much larger morph lex-
icon. Hence, less splitting ensues. The effect is not
seen on the English data (Fig. 2b), but this might be
due to the smaller corpus sizes.
For Linguistica, an increase in the amount of data
is reflected in higher recall, but lower precision.
Linguistica only suggests a morpheme boundary be-
tween a stem and an affix, if the same stem has been
observed in combination with at least one other af-
fix. This leads to a ?conservative word-splitting be-
havior?, with a rather low recall for small data sets,
but with high precision. As the amount of data in-
creases, the sparsity of the data decreases, and more
morpheme boundaries are suggested. This results
in higher recall, but unfortunately lower precision.
As Linguistica was not designed for discovering
the boundaries within compound words, it misses
a large number of them.
For Finnish, the Category algorithm is better than
the other two algorithms when compared on data
sets of the same size. We interpret a result to be
better, even though precision might be somewhat
lower, if recall is significantly higher (or vice versa).
As an example, for the 16 million word set, the cate-
gory algorithm achieves 79.0% precision and 71.0%
recall. The Baseline achieves 88.5% precision but
only 45.9% recall. T-tests show significant differ-
ences at the level of 0.01 between all algorithms
on Finnish, except for Categories vs. Baseline at
10 000 words.
For English, the Baseline algorithm generally
performs worst, but it is difficult to say which of
the other two algorithm performs best. According
to T-tests there are no significant differences at the
level of 0.05 between the following: Categories vs.
Linguistica (50k & 250k), and Categories vs. Base-
line (10k). However, if one were to extrapolate
from the current trends to a larger data set, it would
seem likely that the Category algorithm would out-
perform Linguistica.
4.4 Computational requirements
The Baseline and Category algorithms are imple-
mented as Perl scripts. On the Finnish 250 000 word
set, the Baseline algorithm runs in 45 minutes, and
the Category algorithm additionally takes 20 min-
utes on a 900 MHz AMD Duron processor with
a maximum memory usage of 20 MB. The Lin-
guistica algorithm is a compiled Windows program,
which uses 500 MB of memory and runs in 90 min-
utes, of which 80 minutes(!) are taken up by the
saving of the results.
5 Discussion
It is worth remembering that the gold standard split-
ting used in these evaluations is based on a tradi-
tional morphology. If the segmentations were eval-
uated using a real-world application, perhaps some-
what different segmentations would be most useful.
For example, the tendency to keep common words
together, seen in the Baseline model and generally
in Bayesian or MDL-based models, might not be at
all troublesome, e.g., in speech recognition or ma-
chine translation applications. In contrast, excessive
splitting might be a problem in both applications.
When compared to the gold standard segmen-
tation used here, the Baseline algorithm produces
three types of errors that are prominent: (i) exces-
sive segmentation especially when trained on small
amounts of data, (ii) too little segmentation espe-
cially with large amounts of data, and (iii) erroneous
segments suggested in the beginning of words due
to the fact that the same segments frequently occur
at the end of words (e.g. ?s+wing?). The Category
algorithm is able to clearly reduce these types of er-
rors due to its following properties: (i) the joining
of noise morphs with adjacent morphs, (ii) the re-
moval of redundant morphs by splitting them into
sub-morphs, and (iii) the simple morphotactics in-
volving three categories (stem, prefix, and suffix)
implemented as an HMM. Furthermore, (iii) is nec-
essary for being able to carry out (i) and (ii).
The Category algorithm does a good job in find-
ing morpheme boundaries and assigning categories
to the morphs, as can be seen in the examples in Fig-
ure 3, e.g., ?photograph+er+s?, ?un+expect+ed+ly?,
?aarre+kammio+i+ssa? (?in treasure chambers?; ?i?
is a plural marker and ?ssa? marks the inessive case),
?bahama+saar+et? (?[the] Bahama islands?; ?saari?
means ?island? and ?saaret? is the plural form). The
reader interested in the analyses of other words can
try our on-line demo at http://www.cis.hut.
fi/projects/morpho/.
It is nice to see that the same morph can be
tagged differently in different contexts, e.g. ?pa?a??
is a prefix in ?pa?a?+aihe+e+sta? (?about [the] main
topic?), whereas ?pa?a?? is a stem in ?pa?a?+ha?n? (?in
[the] head?). In this case the morph categories
also resolve the semantic ambiguity of the morph
?pa?a??. Occasionally, the segmentation is correct, but
the category tagging differs from the linguistic con-
vention, e.g., ?taka+penkki+la?is+et? (?[the] ones in
[the] back seat?), where ?la?is? is tagged as a stem
instead of a suffix.
The segmentation of ?pa?a?aiheesta? is not entirely
correct: ?pa?a?+aihe+e+sta? contains an superfluous
morph (?e?), which should be part of the stem, i.e.,
?pa?a?+aihee+sta?. This mistake is explained by a
comparison with the plural form ?pa?a?+aihe+i+sta?,
which is correct. As the singular and plural only dif-
fer in one letter, ?e? vs. ?i?, the algorithm has found
a solution, where the alternating letter is treated as
an independent ?number marker?: ?e? for singular,
?i? for plural.
In the Linguistica algorithm, stems and suffixes
are grouped into so called signatures, which can be
thought of as inflectional paradigms: a certain set
of stems goes together with a certain set of suffixes.
Words will be left unsplit unless the potential stem
and suffix fit into a signature. As a consequence, if
there is only the plural of some particular English
noun in the data, but not the singular, Linguistica
will not split the noun into a stem and the plural
?s?, since this does not fit into any signature. In
this respect, our category-based algorithm is better
at coping with data sparsity. For highly-inflecting
languages, such as Finnish, this is especially impor-
tant.
In contrast with Linguistica, our algorithms can
incorrectly ?overgeneralize? and suggest a suffix,
aarre + kammio + i + ssa ja?a?dy + tta? + a? abandon long + est
aarre + kammio + i + sta ja?a?dy + tta? + a? + kseen abandon + ed long + fellow + ?s
aarre + kammio + ita ja?a?dy + tta? + isi abandon + ing longish
aarre + kammio + nsa maclare + n abandon + ment long + itude
aarre + kammio + on nais + auto + ili + ja beauti + ful master + piece + s
aarre + kammio + t nais + auto + ili + ja + a beauti + fully micro + organ + ism + s
aarre + kammio + ta nais + auto + ili + joista beauty + ?s near + ly
bahama + saar + et prot + e + iin + eja calculat + ed necess + ary
bahama + saari + en prot + e + iin + i calculat + ion + s necess + ities
bahama + saari + lla prot + e + iin + ia con + figur + ation necess + ity
bahama + saari + lle pa?a? + aihe + e + sta con + firm + ed photograph
bahama + saar + ten pa?a? + aihe + i + sta express + ion + ist photograph + er + s
edes + autta + isi + vat pa?a? + ha?n express + ive + ness photograph + y
edes + autta + ko + on pa?a? + kin fanatic + ism phrase + d
edes + autta + maan pa?a? + ksi invit + ation + s phrase + ology
edes + autta + ma + ssa taka + penkki + la? + in+ en invit + e phrase + s
haap + a + koske + a taka + penkki + la?is + et invit + ed sun + rise
haap + a + koske + en voida + kaan invit + e + es thanks + giving
haap + a + koske + lla voi + mme + ko invit + es un + avail + able
haap + a + koski voisi + mme invit + ing un + expect + ed + ly
Figure 3: Examples of segmentations learned from the large Finnish data set and a small English data set.
Discovered stems are underlined, suffixes are slanted, and prefixes are rendered in the standard font.
where there is none, e.g., ?maclare+n? (?Mac-
Laren?). Furthermore, nonsensical sequences of
suffixes (which in other contexts are true suffixes)
can be suggested, e.g., ?prot+e+iin+i?, which should
be ?proteiini? (?protein?). A model with more fine-
grained categories might reduce such shortcomings
in that it could model morphotactics more accu-
rately.
Another aspect requiring attention in the future
is allomorphy. Currently each discovered segment
(morph) is assigned a role (prefix, stem, or suf-
fix), but no further ?meaning? or relation to other
morphs. In Figure 3 there are some examples
of allomorphs, morphs representing the same mor-
pheme, i.e., morphs having the same meaning but
used in complementary distributions. The current
algorithm has no means for discovering that ?on?
and ?en? mark the same case, namely illative, in
?aarre+kammio+on? (?into [the] treasure chamber?)
and ?haap+a+koske+en? (?to Haapakoski?). 6 To
enable such discovery in principle, one would prob-
ably need to look at contexts of nearby words,
not just the word-internal context. Additionally,
one should allow the learning of a model with
richer category structure. Moreover, ?on? and ?en?
do not always mark the illative case. In ?ba-
6Furthermore the algorithm cannot deduce that the illative
is actually realized as a vowel lengthening + ?n?: ?kammioon?
vs. ?koskeen?.
hama+saari+en? the genitive is marked as ?en?, and
in ?edes+autta+ko+on? (?may he/she help?) ?on?
marks the third person singular. Similar examples
can be found for English, e.g., ?ed? and ?d? are al-
lomorphs in ?invit+ed? vs. ?phrase+d?, and so are
?es? and ?s? in ?invit+es? vs. ?phrase+s?. However,
the meaning of ?s? is often ambiguous. It can mark
either the plural of a noun or the third person sin-
gular of a verb in the present tense. But this kind
of ambiguity is in principle solvable in the current
model; the Category algorithm resolves similar, also
semantic, ambiguities occurring between the three
current categories: prefix, stem, and suffix.
6 Conclusions
We described an algorithm that differs from earlier
morpheme segmentation algorithms in that it mod-
els dependencies between morph categories in se-
quences of arbitrary length. Even a simple model
with few categories, namely prefix, suffix, and stem
is able to capture relevant dependencies that consid-
erably improve the obtained segmentation on both
Finnish and English, languages with rather different
types of word structure. An interesting future di-
rection is whether the application of more complex
model structures may lead to improvements in the
morphology induction task.
Acknowledgments
We are grateful to Krister Linde?n, as well as the
anonymous reviewers for their valuable and thor-
ough comments on the manuscript.
References
M. Baroni, J. Matiasek, and H. Trost. 2002. Un-
supervised learning of morphologically related
words based on orthographic and semantic sim-
ilarity. In Proc. Workshop on Morphological &
Phonological Learning of ACL?02, pages 48?57.
M. R. Brent. 1999. An efficient, probabilistically
sound algorithm for segmentation and word dis-
covery. Machine Learning, 34:71?105.
M. Creutz and K. Lagus. 2002. Unsupervised dis-
covery of morphemes. In Proc. Workshop on
Morphological and Phonological Learning of
ACL?02, pages 21?30, Philadelphia, Pennsylva-
nia, USA.
M. Creutz. 2003. Unsupervised segmentation of
words using prior distributions of morph length
and frequency. In Proc. ACL?03, pages 280?287,
Sapporo, Japan.
C. G. de Marcken. 1996. Unsupervised Language
Acquisition. Ph.D. thesis, MIT.
H. De?jean. 1998. Morphemes as necessary con-
cept for structures discovery from untagged cor-
pora. In Workshop on Paradigms and Grounding
in Natural Language Learning, pages 295?299,
Adelaide.
J. Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computa-
tional Linguistics, 27(2):153?198.
K. Hacioglu, B. Pellom, T. Ciloglu, O. Ozturk,
M. Kurimo, and M. Creutz. 2003. On lexi-
con creation for Turkish LVCSR. In Proc. Eu-
rospeech?03, pages 1165?1168, Geneva, Switzer-
land.
K. Koskenniemi. 1983. Two-level morphology:
A general computational model for word-form
recognition and production. Ph.D. thesis, Uni-
versity of Helsinki.
S. Neuvel and S. A. Fulop. 2002. Unsupervised
learning of morphology without morphemes. In
Proc. Workshop on Morphological & Phonologi-
cal Learning of ACL?02, pages 31?40.
J. R. Saffran, E. L. Newport, and R. N. Aslin. 1996.
Word segmentation: The role of distributional
cues. Journal of Memory and Language, 35:606?
621.
P. Schone and D. Jurafsky. 2000. Knowledge-free
induction of morphology using Latent Semantic
Analysis. In Proc. CoNLL-2000 & LLL-2000,
pages 67?72.
P. Schone and D. Jurafsky. 2001. Knowledge-free
induction of inflectional morphologies. In Proc.
NAACL-2001.
V. Siivola, T. Hirsima?ki, M. Creutz, and M. Kurimo.
2003. Unlimited vocabulary speech recognition
based on morphs discovered in an unsupervised
manner. In Proc. Eurospeech?03, pages 2293?
2296, Geneva, Switzerland.
M. G. Snover and M. R. Brent. 2001. A Bayesian
model for morpheme and paradigm identifica-
tion. In Proc. 39th Annual Meeting of the ACL,
pages 482?490.
D. Yarowsky and R. Wicentowsky. 2000. Mini-
mally supervised morphological analysis by mul-
timodal alignment. In Proc. ACL-2000, pages
207?216.
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 157?165,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Web augmentation of language models for continuous speech recognition
of SMS text messages
Mathias Creutz1, Sami Virpioja1,2 and Anna Kovaleva1
1Nokia Research Center, Helsinki, Finland
2Adaptive Informatics Research Centre, Helsinki University of Technology, Espoo, Finland
mathias.creutz@nokia.com, sami.virpioja@tkk.fi, annakov@gmx.de
Abstract
In this paper, we present an efficient query
selection algorithm for the retrieval of web
text data to augment a statistical language
model (LM). The number of retrieved rel-
evant documents is optimized with respect
to the number of queries submitted.
The querying scheme is applied in the do-
main of SMS text messages. Continuous
speech recognition experiments are con-
ducted on three languages: English, Span-
ish, and French. The web data is utilized
for augmenting in-domain LMs in general
and for adapting the LMs to a user-specific
vocabulary. Word error rate reductions
of up to 6.6 % (in LM augmentation) and
26.0 % (in LM adaptation) are obtained in
setups, where the size of the web mixture
LM is limited to the size of the baseline
in-domain LM.
1 Introduction
An automatic speech recognition (ASR) system
consists of acoustic models of speech sounds and
of a statistical language model (LM). The LM
learns the probabilities of word sequences from
text corpora available for training. The perfor-
mance of the model depends on the amount and
style of the text. The more text there is, the better
the model is, in general. It is also important that
the model be trained on text that matches the style
of language used in the ASR application. Well
matching, in-domain, text may be both difficult
and expensive to obtain in the large quantities that
are needed.
A popular solution is to utilize the World Wide
Web as a source of additional text for LM train-
ing. A small in-domain set is used as seed data,
and more data of the same kind is retrieved from
the web. A decade ago, Berger and Miller (1998)
proposed a just-in-time LM that updated the cur-
rent LM by retrieving data from the web using re-
cent recognition hypotheses as queries submitted
to a search engine. Perplexity reductions of up to
10 % were reported.1 Many other works have fol-
lowed. Zhu and Rosenfeld (2001) retrieved page
and phrase counts from the web in order to update
the probabilities of infrequent trigrams that occur
in N-best lists. Word error rate (WER) reductions
of about 3 % were obtained on TREC-7 data.
In more recent work, the focus has turned to
the collection of text rather than n-gram statistics
based on page counts. More effort has been put
into the selection of query strings. Bulyko et al
(2003; 2007) first extend their baseline vocabulary
with words from a small in-domain training cor-
pus. They then use n-grams with these new words
in their web queries in order to retrieve text of a
certain genre. For instance, they succeed in ob-
taining conversational style phrases, such as ?we
were friends but we don?t actually have a relation-
ship.? In a number of experiments, word error
rate reductions of 2-3 % are obtained on English
data, and 6 % on Mandarin. The same method for
web data collection is applied by C?etin and Stolcke
(2005) in meeting and lecture transcription tasks.
The web sources reduce perplexity by 10 % and
4.3 %, respectively, and word error rates by 3.5 %
and 2.2 %, respectively.
Sarikaya et al (2005) chunk the in-domain text
into ?n-gram islands? consisting of only content
words and excluding frequently occurring stop
words. An island such as ?stock fund portfolio? is
then extended by adding context, producing ?my
stock fund portfolio?, for instance. Multiple is-
lands are combined using and and or operations to
form web queries. Significant word error reduc-
tions between 10 and 20 % are obtained; however,
the in-domain data set is very small, 1700 phrases,
1All reported percentage differences are relative unless
explicitly stated otherwise.
157
which makes (any) new data a much needed addi-
tion.
Similarly, Misu and Kawahara (2006) obtain
very good word error reductions (20 %) in spo-
ken dialogue systems for software support and
sightseeing guidance. Nouns that have high tf/idf
scores in the in-domain documents are used in the
web queries. The existing in-domain data sets
poorly match the speaking style of the task and
therefore existing dialogue corpora of different do-
mains are included, which improves the perfor-
mance considerably.
Wan and Hain (2006) select query strings by
comparing the n-gram counts within an in-domain
topic model to the corresponding counts in an out-
of-domain background model. Topic-specific n-
grams are used as queries, and perplexity reduc-
tions of 5.4 % are obtained.
It is customary to postprocess and filter the
downloaded web texts. Sentence boundaries are
detected using some heuristics. Text chunks with a
high out-of-vocabulary (OOV) rate are discarded.
Additionally, the chunks are often ranked accord-
ing to their similarity with the in-domain data, and
the lowest ranked chunks are discarded. As a sim-
ilarity measure, the perplexity of the sentence ac-
cording to the in-domain LM can be used; for in-
stance, Bulyko et al (2007). Another measure
for ranking is relative perplexity (Weilhammer et
al., 2006), where the in-domain perplexity is di-
vided by the perplexity given by an LM trained
on the web data. Also the BLEU score familiar
from the field of machine translation has been used
(Sarikaya et al, 2005).
Some criticism has been raised by Sethy et al
(2007), who claim that sentence ranking has an
inherent bias towards the center of the in-domain
distribution. They propose a data selection algo-
rithm that selects a sentence from the web set, if
adding the sentence to the already selected set re-
duces the relative entropy with respect to the in-
domain data distribution. The algorithm appears
efficient in producing a rather small subset (1/11)
of the web data, while degrading the WER only
marginally.
The current paper describes a new method for
query selection and its applications in LM aug-
mentation and adaptation using web data. The
language models are part of a continuous speech
recognition system that enables users to use
speech as an input modality on mobile devices,
such as mobile phones. The particular domain of
interest is personal communication: The user dic-
tates a message that is automatically transcribed
into text and sent to a recipient as an SMS text
message. Memory consumption and computa-
tional speed are crucial factors in mobile applica-
tions. While most studies ignore the sizes of the
LMs when comparing models, we aim at improv-
ing the LM without increasing its size when web
data is added.
Another aspect that is typically overlooked is
that the collection of web data costs time and com-
putational resources. This applies to the querying,
downloading and postprocessing of the data. The
query selection scheme proposed in this paper is
economical in the sense that it strives to download
as much relevant text from the web as possible us-
ing as few queries as possible avoiding overlap be-
tween the set of pages found by different queries.
2 Query selection and web data retrieval
Our query selection scheme involves multiple
steps. The assumption is that a batch of queries
will be created. These queries are submitted to
a search engine and the matching documents are
downloaded. This procedure is repeated for multi-
ple query batches.
In particular, our scheme attempts to maximize
the number of retrieved relevant documents, when
two restrictions apply: (1) queries are not ?free?:
each query costs some time or money; for in-
stance, the number of queries submitted within a
particular period of time is limited, and (2) the
number of documents retrieved for a particular
query is limited to a particular number of ?top
hits?.
2.1 N-gram selection and prospection
querying
Some text reflecting the target domain must be
available. A set of the most frequent n-grams oc-
curring in the text is selected, from unigrams up to
five-grams. Some of these n-grams are character-
istic of the domain of interest (such as ?Hogwarts
School of Witchcraft and Wizardry?), others are
just frequent in general (?but they did not say?);
we do not know yet which ones.
All n-grams are submitted as queries to the web
search engine. Exact matches of the n-grams are
required; different inflections or matches of the
words individually are not accepted.
158
The search engine returns the total number of
hits h(q
s
) for each query q
s
as well as the URLs
of a predefined maximum number of ?top hit? web
pages. The top hit pages are downloaded and post-
processed into plain text, from which duplicate
paragraphs and paragraphs with a high OOV rate
are removed.
N-gram language models are then trained sep-
arately on the in-domain text and the the filtered
web text. If the amount of web text is very large,
only a subset is used, which consists of the parts
of the web data that are the most similar to the
in-domain text. As a similarity measure, relative
perplexity is used. The LM trained on web data is
called a background LM to distinguish it from the
in-domain LM.
2.2 Focused querying
Next, the querying is made more specific and tar-
geted on the domain of interest. New queries are
created that consist of n-gram pairs, requiring that
a document contain two n-grams (?but they did not
say?+?Hogwarts School of Witchcraft and Wiz-
ardry?).2
If all possible n-gram pairs are formed from
the n-grams selected in Section 2.1, the number
of pairs is very large, and we cannot afford using
them all as queries. Typical approaches for query
selection include the following: (i) select pairs that
include n-grams that are relatively more frequent
in the in-domain text than in the background text,
(ii) use some extra source of knowledge for select-
ing the best pairs.
2.2.1 Extra linguistic knowledge
We first tested the second (ii) query selection ap-
proach by incorporating some simple linguistic
knowledge: In an experiment on English, queries
were obtained by combining a highly frequent n-
gram with a slightly less frequent n-gram that had
to contain a first- or second-person pronoun (I,
you, we, me, us, my, your, our). Such n-grams
were thought to capture direct speech, which is
characteristic for the desired genre of personal
communication. (Similar techniques are reported
in the literature cited in Section 1.)
Although successful for English, this scheme is
more difficult to apply to other languages, where
person is conveyed as verbal suffixes rather than
single words. Linguistic knowledge is needed for
2Higher order tuples could be used as well, but we have
only tested n-gram pairs.
every language, and it turns out that many of the
queries are ?wasted?, because they are too specific
and return only few (if any) documents.
2.2.2 Statistical approach
The other proposed query selection technique (i)
allows for an automatic identification of the n-
grams that are characteristic of the in-domain
genre. If the relative frequency of an n-gram is
higher in the in-domain data than in the back-
ground data, then the n-gram is potentially valu-
able. However, as in the linguistic approach, there
is no guarantee that queries are not wasted, since
the identified n-gram may be very rare on the In-
ternet. Pairing it with some other n-gram (which
may also be rare) often results in very few hits.
To get out the most of the queries, we pro-
pose a query selection algorithm that attempts to
optimize the relevance of the query to the target
domain, but also takes into account the expected
amount of data retrieved by the query. Thus, the
potential queries are ranked according to the ex-
pected number of retrieved relevant documents.
Only the highest ranked pairs, which are likely to
produce the highest number of relevant web pages,
are used as queries.
We denote queries that consist of two n-grams
s and t by q
s?t
. The expected number of retrieved
relevant documents for the query q
s?t
is r(q
s?t
):
r(q
s?t
) = n(q
s?t
) ? ?(q
s?t
|Q), (1)
where n(q
s?t
) is the expected number of retrieved
documents for the query, and ?(q
s?t
|Q) is the ex-
pected proportion of relevant documents within all
documents retrieved by the query. The expected
proportion of relevant documents is a value be-
tween zero and one, and as explained below, it is
dependent on all past queries, the query history Q.
Expected number of retrieved documents
n(q
s?t
). From the prospection querying phase
(Section 2.1), we know the numbers of hits for
the single n-grams s and t, separately: h(q
s
) and
h(q
t
). We make the operational, but overly simpli-
fying, assumption that the n-grams occur evenly
distributed over the web collection, independently
of each other. The expected size of the intersection
q
s?t
is then:
h?(q
s?t
) =
h(q
s
) ? h(q
t
)
N
, (2)
where N is the size of the web collection that our
n-gram selection covers (total number of docu-
159
ments). N is not known, but different estimates
can be used, for instance, N = max
?q
s
h(q
s
),
where it is assumed that the most frequent n-gram
occurs in every document in the collection (prob-
ably an underestimate of the actual value).
Ideally, the expected number of retrieved doc-
uments equals the expected number of hits, but
since the search engine returns a limited maximum
number of ?top hit? pages, M , we get:
n(q
s?t
) = min(h?(q
s?t
),M). (3)
Expected proportion of relevant documents
?(q
s?t
|Q). As in the case of n(q
s?t
), an inde-
pendence assumption can be applied in the deriva-
tion of the expected proportion of relevant docu-
ments for the combined query q
s?t
: We simply
put together the chances of obtaining relevant doc-
uments by the single n-gram queries q
s
and q
t
in-
dividually. The union equals:
?(q
s?t
|Q) =
1 ?
(
1 ? ?(q
s
|Q)
)
?
(
1 ? ?(q
t
|Q)
)
. (4)
However, we do not know the values for
?(q
s
|Q) and ?(q
t
|Q). As mentioned earlier, it is
straightforward to obtain a relevance ranking for a
set of n-grams: For each n-gram s, the LM prob-
ability is computed using both the in-domain and
the background LM. The in-domain probability is
divided by the background probability and the n-
grams are sorted, highest relative probability first.
The first n-gram is much more prominent in the
in-domain than the background data, and we wish
to obtain more text with this crucial n-gram. The
opposite is true for the last n-gram.
We need to transform the ranking into ?(?) val-
ues between zero and one. There is no absolute di-
vision into relevant and irrelevant documents from
the point of view of LM training. We use a proba-
bilistic query ranking scheme, such that we define
that of all documents containing an x% relevant
n-gram, x% are relevant. When the n-grams have
been ranked into a presumed order of relevance,
we decide that the most relevant n-gram is 100 %
relevant and the least relevant n-gram is 0 % rele-
vant; finally, we scale the relevances of the other
n-grams according to rank.
When scoring the remaining n-grams, linear
scaling is avoided, because the majority of the n-
grams are irrelevant or neutral with respect to our
domain of interest, and many of them would ob-
tain fairly high relevance values. Instead, we fix
the relevance value of the ?most domain-neutral?
n-gram (the one with the relative probability value
closest to one); we might assume that only 5 % of
all documents containing this n-gram are indeed
relevant. We then fit a polynomial curve through
the three points with known values (0, 0.05, and 1)
to get the missing ?(?) values for all q
s
.
Decay factor ?(s |Q). We noticed that if con-
stant relevance values are used, the top ranked
queries will consist of a rather small set of top
ranked n-grams that are paired with each other in
all possible combinations. However, it is likely
that each time an n-gram is used in a query, the
need for finding more occurrences of this partic-
ular n-gram decreases. Therefore, we introduced
a decay factor ?(s |Q), by which the initial ?(?)
value, written ?
0
(q
s
), is multiplied:
?(q
s
|Q) = ?
0
(q
s
) ? ?(s |Q), (5)
The decay is exponential:
?(s |Q) = (1 ? )
P
?s?Q
1. (6)
 is a small value between zero and one (for in-
stance 0.05), and ?
?s?Q
1 is the number of times
the n-gram s has occurred in past queries.
Overlap with previous queries. Some queries
are likely to retrieve the same set of documents
as other queries. This occurs if two queries share
one n-gram and there is strong correlation be-
tween the second n-grams (for instance, ?we wish
you?+?Merry Christmas? vs. ?we wish you?+
?and a Happy New Year?). In principle, when as-
sessing the relevance of a query, one should esti-
mate the overlap of that query with all past queries.
We have tested an approximate solution that al-
lows for fast computing. However, the real effect
of this addition was insignificant, and a further de-
scription is omitted in this paper.
Optimal order of the queries. We want to max-
imize the expected number of retrieved relevant
documents while keeping the number of submitted
queries as low as possible. Therefore we sort the
queries best first and submit as many queries we
can afford from the top of the list. However, the
relevance of a query is dependent on the sequence
of past queries (because of the decay factor). Find-
ing the optimal order of the queries takes O(n2)
operations, if n is the total number of queries.
A faster solution is to apply an iterative algo-
rithm: All queries are put in some initial order. For
160
each query, its r(q
s?t
) value is computed accord-
ing to Equation 1. The queries are then rearranged
into the order defined by the new r(?) values, best
first. These two steps are repeated until conver-
gence.
Repeated focused querying. Focused querying
can be run multiple times. Some ten thousands of
the top ranked queries are submitted to the search
engine and the documents matching the queries
are downloaded. A new background LM is trained
using the new web data, and a new round of fo-
cused querying can take place.
2.2.3 Comparison of the linguistic and
statistical focused querying schemes
On one language (German), the statical focused
querying algorithm (Section 2.2.2) was shown
to retrieve 50 % more unique web pages and
70 % more words than the linguistic scheme (Sec-
tion 2.2.1) for the same number of queries. Also
results from language modeling and speech recog-
nition experiments favored statistical querying.
2.3 Web collections obtained
For the speech recognition experiments described
in the current paper, we have collected web texts
for three languages: US English, European Span-
ish, and Canadian French.
As in-domain data we used 230,000 English
text messages (4 million words), 65,000 Spanish
messages (2 million words), and 60,000 French
messages (1 million words). These text messages
were obtained in data collection projects involving
thousand of participants, who used a web interface
to enter messages according to different scenarios
of personal communication situations.3 A few ex-
ample messages are shown in Figure 1.
The queries were submitted to Yahoo!?s web
search engine. The web pages that were retrieved
by the queries were filtered and cleaned and di-
vided into chunks consisting of single paragraphs.
For English, we obtained 210 million paragraphs
and 13 billion words, for Spanish 160 million
paragraphs and 12 billion words, and for French
44 million paragraphs and 3 billion words.
3Real messages sent from mobile phones would be the
best data, but are hard to get because of privacy protection.
The postprocessing of authentic messages would, however,
require proper handling of artifacts resulting from the limited
input capacities on keypads of mobile devices, such as spe-
cific acronyms: i?ll c u l8er. In our setup, we did not have to
face such issues.
I hope you have a long and happy marriage.
Congratulations!
Remember to pick up Billy at practice at five
o?clock!
Hey Eric, how was the trip with the kids over
winter vacation? Did you go to Texas?
Figure 1: Example text messages (US English).
The linguistic focused querying method was ap-
plied in the US English task (because the statisti-
cal method did not yet exist). The Spanish and
Canadian French web collections were obtained
using statistical querying. Since the French set
was smaller than the other sets (?only? 3 billion
words), web crawling was performed, such that
those web sites that had provided us with the most
valuable data (measured by relative perplexity)
were downloaded entirely. As a result, the num-
ber of paragraphs increased to 110 million and the
number of words to 8 billion.
3 Speech Recognition Experiments
We have trained language models on the in-
domain data together with web data, and these
models have been used in speech recognition ex-
periments. Two kinds of experiments have been
performed: (1) the in-domain LM is augmented
with web data, and (2) the LM is adapted to a user-
specific vocabulary utilizing web data as an addi-
tional data source.
One hundred native speakers for each language
were recorded reading held-out subsets of the in-
domain text data. The speech data was partitioned
into training and test sets, such that around one
fourth of the speakers were reserved for testing.
We use a continuous speech recognizer opti-
mized for low memory footprint and fast recog-
nition (Olsen et al, 2008). The recognizer
runs on a server (Core2 2.33 GHz) in about
one fourth of real time. The LM probabilities
are quantized and precompiled together with the
speaker-independent acoustic models (intra-word
triphones) into a finite state transducer (FST).
3.1 Language model augmentation
Each paragraph in the web data is treated as a po-
tential text message and scored according to its
similarity to the in-domain data. Relative perplex-
ity is used as the similarity measure. The para-
graphs are sorted, lowest relative perplexity first,
161
US English
FST size [MB] 10 20 40 70
In-domain 42.7 40.1 39.1 ?
Web mixture 42.0 37.6 35.7 33.8
Ppl reduction [%] 1.6 6.2 8.7 13.6
European Spanish
FST size [MB] 10 20 25 40
In-domain 68.0 64.6 64.3 ?
Web mixture 63.9 58.4 55.0 52.1
Ppl reduction [%] 6.0 9.6 14.5 19.0
Canadian French
FST size [MB] 10 20 25 50
In-domain 57.6 ? ? ?
Web mixture 51.7 47.9 45.9 44.6
Ppl reduction [%] 10.2 16.8 20.3 22.6
Table 1: Perplexities.
In the tables, the perplexity and word error rate reductions of the web mixtures are computed with
respect to the in-domain models of the same size, if such models exist; otherwise the comparison is
made to the largest in-domain model available.
and the highest ranked paragraphs are used as LM
training data. The optimal size of the set depends
on the test, but the largest chosen set contains 15
million paragraphs and 500 million words.
Separate LMs are trained on the in-domain data
and web data. The two LMs are then linearly
interpolated into a mixture model. Roughly the
same interpolation weights (0.5) are obtained for
the LMs, when the optimal value is chosen based
on a held-out in-domain development test set.
3.1.1 Test set perplexities
In Table 1, the prediction abilities of the in-domain
and web mixture language models are compared.
As an evaluation measure we use perplexity cal-
culated on test sets consisting of in-domain text.
The comparison is performed on FSTs of differ-
ent sizes. The FSTs contain the acoustic models,
language model and lexicon, but the LM makes up
for most of the size. The availability of data varies
for the different languages, and therefore the FST
sizes are not exactly the same across languages.
The LMs have been created using the SRI LM
toolkit (Stolcke, 2002). Good-Turing smoothing
with Katz backoff (Katz, 1987) has been used, and
the different model sizes are obtained by pruning
down the full models using entropy-based prun-
ing (Stolcke, 1998). N-gram orders up to five have
been tested: 5-grams always work best on the mix-
US English
FST size [MB] 10 20 40 70
In-domain 17.9 17.5 17.3 ?
Web mixture 17.5 16.7 16.4 15.8
WER reduction 2.2 4.4 5.2 8.4
European Spanish
FST size [MB] 10 20 25 40
In-domain 18.9 18.7 18.6 ?
Web mixture 18.7 17.9 17.4 16.8
WER reduction 1.4 4.1 6.6 9.7
Canadian French
FST size [MB] 10 20 25 50
In-domain 22.6 ? ? ?
Web mixture 22.1 21.7 21.3 20.9
WER reduction 2.3 4.1 5.8 7.5
Table 2: Word error rates [%].
ture models, whereas the best in-domain models
are 4- or 5-grams.
For every language and model size, the web
mixture model performs better than the corre-
sponding in-domain model. The perplexity reduc-
tions obtained increase with the size of the model.
Since it is possible to create larger mixture mod-
els than in-domain models, there are no in-domain
results for the largest model sizes.
Especially if large models can be afforded, the
perplexity reductions are considerable. The largest
improvements are observed for French (between
10.2 % and 22.6 % relative). This is not surprising,
as the French in-domain set is the smallest, which
leaves much room for improvement.
3.1.2 Word error rates
Speech recognition results for the different LMs
are given in Table 2. The results are consistent in
the sense that the web mixture models outperform
the in-domain models, and augmentation helps
more with larger models. The largest word error
rate reduction is observed for the largest Span-
ish model (9.7 % relative). All WER reductions
are statistically significant (one-sided Wilcoxon
signed-rank test; level 0.05) except the 10 MB
Spanish setup.
Although the observed word error rate reduc-
tions are mostly smaller than the corresponding
162
perplexity reductions, the results are actually very
good, when we consider the fact that consider-
able reductions in perplexity may typically trans-
late into meager word error reductions; see, for in-
stance, Rosenfeld (2000), Goodman (2001). This
suggests that the web texts are very welcome com-
plementary data that improve on the robustness of
the recognition.
3.1.3 Modified Kneser-Ney smoothing
In the above experiments, Good-Turing (GT)
smoothing with Katz backoff was used, although
modified Kneser-Ney (KN) interpolation has been
shown to outperform other smoothing methods
(Chen and Goodman, 1999). However, as demon-
strated by Siivola et al (2007), KN smoothing
is not compatible with simple pruning methods
such as entropy-based pruning. In order to make
a meaningful comparison, we used the revised
Kneser pruning and Kneser-Ney growing tech-
niques proposed by Siivola et al (2007). For the
three languages, we built KN models that resulted
in FSTs of the same sizes as the largest GT in-
domain models. The perplexities decreased 4?8%,
but in speech recognition, the improvements were
mostly negligible: the error rates were 17.0 for En-
glish, 18.7 for Spanish, and 22.5 for French.
For English, we also created web mixture mod-
els with KN smoothing. The error rates were 16.5,
15.9 and 15.7 for the 20 MB, 40 MB and 70 MB
models, respectively. Thus, Kneser-Ney outper-
formed Good-Turing, but the improvements were
small, and a statistically significant difference was
measured only for the 40 MB LMs. This was ex-
pected, as it has been observed before that very
simple smoothing techniques can perform well on
large data sets, such as web data (Brants et al,
2007).
For the purpose of demonstrating the usefulness
of our web data retrieval system, we concluded
that there was no significant difference between
GT and KN smoothing in our current setup.
3.2 Language model adaptation
In the second set of experiments we envisage a
system that adapts to the user?s own vocabulary.
Some words that the user needs may not be in-
cluded in the built-in vocabulary of the device,
such as names in the user?s contact list, names of
places or words related to some specific hobby or
other focus of interest.
Two adaptation techniques have been tested:
(1) Unigram adaptation is a simple technique, in
which user-specific words (for instance, names
from the contact list) are added to the vocabulary.
No context information is available, and thus only
unigram probabilities are created for these words.
(2) In message adaptation, the LM is augmented
selectively with paragraphs of web data that con-
tain user-specific words. Now, higher order n-
grams can be estimated, since the words occur
within passages of running text. This idea is not
new: information retrieval has been suggested as a
solution by Bigi et al (2004) among others.
In our message adaptation, we have not created
web queries dynamically on demand. Instead, we
used the large web collections described in Sec-
tion 2.3, from which we selected paragraphs con-
taining user-specific words. We have tested both
adaptation by pooling (adding the paragraphs to
the original training data), and adaptation by in-
terpolation (using the new data to train a sepa-
rate LM, which is interpolated with the original
LM). One million words from the web data were
selected for each language. The adaptation was
thought to take place off-line on a server.
3.2.1 Data sets
For each language, the adaptation takes place on
two baseline models, which are the in-domain
and web mixture LMs of Section 3.1; however,
the amount of in-domain training data is reduced
slightly (as explained below).
In order to evaluate the success of the adapta-
tion, a simulated user-specific test set is created.
This set is obtained by selecting a subset of a
larger potential test set. Words that occur both in
the training set and the potential test set and that
are infrequent in the training set are chosen as the
user-specific vocabulary. For Spanish and French,
a training set frequency threshold of one is used,
resulting in 606 and 275 user-specific words, re-
spectively. For English the threshold is 5, which
results in 99 words. All messages in the potential
test set containing any of these words are selected
into the user-specific test set. Any message con-
taining user-specific words is removed from the
in-domain training set. In this manner, we obtain
a test set with a certain over-representation of a
specific vocabulary, without biasing the word fre-
quency distribution of the training set to any no-
ticeable degree.
For comparison, performance is additionally
computed on a generic in-domain test set, as be-
163
US English, 23 MB models
Model WER (reduction)
user-specific in-domain
In-domain 29.1 (?) 17.9 (?)
+unigram adapt. 24.4 (16.3) 17.1 (4.7)
+message adapt. 21.6 (26.0) 16.8 (6.0)
Web mixture 25.7 (11.8) 16.9 (5.9)
+unigram adapt. 23.1 (20.6) 16.3 (8.8)
+message adapt. 22.2 (23.8) 16.4 (8.5)
European Spanish, 23 MB models
Model WER (reduction)
user-specific in-domain
In-domain 25.3 (?) 18.6 (?)
+unigram adapt. 23.4 (7.7) 18.5 (0.3)
+message adapt. 21.7 (14.4) 18.0 (3.2)
Web mixture 21.9 (13.7) 17.5 (5.8)
+unigram adapt. 21.5 (15.3) 17.7 (5.0)
+message adapt. 21.2 (16.5) 17.7 (4.7)
Canadian French, 21 MB models
Model WER (reduction)
user-specific in-domain
In-domain 30.3 (?) 22.6 (?)
+unigram adapt. 28.3 (6.4) 22.5 (0.4)
+message adapt. 26.6 (12.1) 22.2 (1.8)
Web mixture 26.7 (11.8) 21.4 (5.1)
+unigram adapt. 26.0 (14.3) 21.4 (5.4)
+message adapt. 26.0 (14.2) 21.6 (4.3)
Table 3: Adaptation, word error rates [%]. Six
models have been evaluated on two types of test
sets: a user-specific test set with a higher number
of user-specific words and a generic in-domain test
set. The numbers in brackets are relative WER re-
ductions [%] compared to the in-domain model.
WER values for the unigram adaptation are ren-
dered in italics, if the improvement obtained is sta-
tistically significant compared to the correspond-
ing non-adapted model. WER values for the mes-
sage adaptation are in italics, if there is a statisti-
cally significant reduction with respect to unigram
adaptation.
fore. User-specific and generic development test
sets are used for the estimation of optimal interpo-
lation weights.
3.2.2 Results
The adaptation experiments are summarized in Ta-
ble 3. Only medium sized FSTs (21?23 MB)
have been tested. The two baseline models have
been adapted using the simple unigram reweight-
ing scheme and using selective web message aug-
mentation. For the in-domain baseline, pooling
works the best, that is, adding the web messages
to the original in-domain training set. For the web
mixture baseline, a mixture model is the only op-
tion; that is, one more layer of interpolation is
added.
In the adaptation of the in-domain LMs, mes-
sage selection is almost twice as effective as uni-
gram adaptation for all data sets. Also the perfor-
mance on the generic in-domain test set is slightly
improved, because more training data is available.
Except for English, the best results on the user-
specific test sets are produced by the adaptation of
the web mixture models. The benefit of using mes-
sage adaptation instead of simple unigram adapta-
tion is smaller when we have a web mixture model
as a baseline rather than an in-domain-only LM.
On the generic test sets, the adaptation of the
web mixture makes a difference only for English.
Since there were practically no singleton words
in the English in-domain data, the user-specific
vocabulary consists of words occurring at most
five times. Thus, the English user-specific words
are more frequent than their Spanish and French
equivalents, which shows in larger WER reduc-
tions for English in all types of adaptation.
4 Discussion and conclusion
Mobile applications need to run in small memory,
but not much attention is usually paid to memory
consumption in related LM work. We have shown
that LM augmentation using web data can be suc-
cessful, even when the resulting mixture model is
not allowed to grow any larger than the initial in-
domain model. Yet, the benefit of the web data is
larger, the larger model can be used.
The largest WER reductions were observed in
the adaptation to a user-specific vocabulary. This
can be compared to Misu and Kawahara (2006),
who obtained similar accuracy improvements with
clever selection of web data, when there was ini-
tially no in-domain data available with both the
correct topic and speaking style.
We used relative perplexity ranking to filter the
downloaded web data. More elaborate algorithms
could be exploited, such as the one proposed by
Sethy et al (2007). Initially, we have experi-
mented along those lines, but it did not pay off;
maybe future refinements will be more successful.
164
References
Adam Berger and Robert Miller. 1998. Just-in-time
language modeling. In In ICASSP-98, pages 705?
708.
Brigitte Bigi, Yan Huang, and Renato De Mori. 2004.
Vocabulary and language model adaptation using in-
formation retrieval. In Proc. Interspeech 2004 ? IC-
SLP, pages 1361?1364, Jeju Island, Korea.
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.
Och, and Jeffrey Dean. 2007. Large language
models in machine translation. In Proceedings
of the 2007 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 858?867.
Ivan Bulyko, Mari Ostendorf, and Andreas Stolcke.
2003. Getting more mileage from web text sources
for conversational speech language modeling using
class-dependent mixtures. In NAACL ?03: Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Lin-
guistics on Human Language Technology, pages 7?
9, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Ivan Bulyko, Mari Ostendorf, Manhung Siu, Tim Ng,
Andreas Stolcke, and ?Ozgu?r C?etin. 2007. Web
resources for language modeling in conversational
speech recognition. ACM Trans. Speech Lang. Pro-
cess., 5(1):1?25.
?Ozgu?r C?etin and Andreas Stolcke. 2005. Lan-
guage modeling in the ICSI-SRI spring 2005 meet-
ing speech recognition evaluation system. Technical
Report 05-006, International Computer Science In-
stitute, Berkeley, CA, USA, July.
S. F. Chen and J. Goodman. 1999. An empirical
study of smoothing techniques for language model-
ing. Computer Speech and Language, 13:359?394.
Joshua T. Goodman. 2001. A bit of progress in lan-
guage modeling. Computer Speech and Language,
15:403?434.
Slava M. Katz. 1987. Estimation of probabilities
from sparse data for the language model compo-
nent of a speech recognizer. IEEE Transactions
on Acoustics, Speech and Signal Processing, ASSP-
35(3):400?401, March.
Teruhisa Misu and Tatsuya Kawahara. 2006. A boot-
strapping approach for developing language model
of new spoken dialogue systems by selecting web
texts. In Proc. INTERSPEECH ?06, pages 9?13,
Pittsburgh, PA, USA, September, 17?21.
Jesper Olsen, Yang Cao, Guohong Ding, and Xinxing
Yang. 2008. A decoder for large vocabulary contin-
uous short message dictation on embedded devices.
In Proc. ICASSP 2008, Las Vegas, Nevada.
Ronald Rosenfeld. 2000. Two decades of language
modeling: Where do we go from here? Proceedings
of the IEEE, 88(8):1270?1278.
Ruhi Sarikaya, Augustin Gravano, and Yuqing Gao.
2005. Rapid language model development using ex-
ternal resources for new spoken dialog domains. In
Proc. IEEE International Conference on Acoustics,
Speech, and Signal Processing (ICASSP ?05), vol-
ume I, pages 573?576.
Abhinav Sethy, Shrikanth Narayanan, and Bhuvana
Ramabhadran. 2007. Data driven approach for lan-
guage model adaptation using stepwise relative en-
tropy minimization. In Proc. IEEE International
Conference on Acoustics, Speech, and Signal Pro-
cessing (ICASSP ?07), volume IV, pages 177?180.
Vesa Siivola, Teemu Hirsima?ki, and Sami Virpi-
oja. 2007. On growing and pruning Kneser-
Ney smoothed n-gram models. IEEE Transac-
tions on Audio, Speech and Language Processing,
15(5):1617?1624.
A. Stolcke. 1998. Entropy-based pruning of backoff
language models. In Proc. DARPA BNTU Work-
shop, pages 270?274, Lansdowne, VA, USA.
A. Stolcke. 2002. SRILM ? an extensible
language modeling toolkit. In Proc. ICSLP,
pages 901?904. http://www.speech.sri.com/
projects/srilm/.
Vincent Wan and Thomas Hain. 2006. Strategies for
language model web-data collection. In Proc. IEEE
International Conference on Acoustics, Speech, and
Signal Processing (ICASSP ?06), volume I, pages
1069?1072.
Karl Weilhammer, Matthew N. Stuttle, and Steve
Young. 2006. Bootstrapping language models for
dialogue systems. In Proc. INTERSPEECH 2006
- ICSLP Ninth International Conference on Spo-
ken Language Processing, Pittsburgh, PA, USA,
September 17?21.
Xiaojin Zhu and R. Rosenfeld. 2001. Improving tri-
gram language modeling with the world wide web.
In Proc. IEEE International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP ?01).,
volume 1, pages 533?536.
165
