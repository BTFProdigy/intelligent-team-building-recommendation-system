Building A Large Chinese Corpus 
Annotated With Semantic Dependency 
 
LI Mingqin 
Department of Electronic Engineering, 
Tsinghua University,  
Beijing 100084, China 
lmq@thsp.ee.tsinghua
.edu.cn  
LI Juanzi 
Department of Computer Science 
and Technology,  
Tsinghua University, 
 Beijing 100084, China
 
ljz@thsp.ee.tsinghu
a.edu.cn 
DONG Zhendong 
Research Centre of Computer & 
Language Engineering, 
Chinese Academy of Sciences, 
Beijing, 100084,China
 
dzd@keenage.com 
WANG Zuoying 
Department of Electronic Engineering,  
Tsinghua University, 
 Beijing 100084, China 
wzy-dee@tsinghua.edu.cn  
LU Dajin 
Department of Electronic Engineering,  
Tsinghua University, 
 Beijing 100084, China 
ludj@mail.tsinghua.edu.cn 
 
 
 
Abstract 
At present most of corpora are annotated 
mainly with syntactic knowledge. In this 
paper, we attempt to build a large corpus 
and annotate semantic knowledge with 
dependency grammar. We believe that 
words are the basic units of semantics, 
and the structure and meaning of a 
sentence consist mainly of a series of 
semantic dependencies between 
individual words. A 1,000,000-word-
scale corpus annotated with semantic 
dependency has been built. Compared 
with syntactic knowledge, semantic 
knowledge is more difficult to annotate, 
for ambiguity problem is more serious. In 
the paper, the strategy to improve 
consistency is addressed, and congruence 
is defined to measure the consistency of 
tagged corpus.. Finally, we will compare 
our corpus with other well-known 
corpora. 
1   Introduction 
As basic research tools for investigators in natural 
language processing, large annotated corpora play 
an important role in investigating diverse lan-
guage phenomena, building statistical language 
models, evaluating and comparing kinds of pars-
ing models. At present most of corpora are anno-
tated mainly with syntactic knowledge, though 
some function tags are added to annotate semantic 
knowledge. For example, the Penn Treebank 
(Marcus et al, 1993) was annotated with skeletal 
syntactic structure, and many syntactic parsers 
were evaluated and compared on the corpus. For 
Chinese, some corpora annotated with phrase 
structure also have been built, for instance the 
Penn Chinese Treebank (Xia et al, 2000) and Sina 
Corpus (Huang and Chen, 1992). A syntactic an-
notation scheme based on dependency was pro-
posed by (Lai and Huang, 2000), and a small 
corpus was built for testing. However, very lim-
ited work has been done with annotation semantic 
knowledge in all languages. From 1999, Berkeley 
started FrameNet project (Baker et al, 1998), 
which produced the frame-semantic descriptions 
of several thousand English lexical items and 
backed up these description with semantically an-
notated attestations from contemporary English 
corpus. Although few corpora annotated with se-
mantic knowledge are available now, there are 
some valuable lexical databases describing the 
lexical semantics in dictionary form, for example 
English WordNet (Miller et al, 1993) and Chinese 
HowNet (Dong and Dong, 2001). 
For Chinese, many attentions have been natu-
rally paid to researches on semantics, because 
Chinese is a meaning-combined language, its syn-
tax is very flexible, and semantic rules are more 
stable than syntactic rules. For instance, in Chi-
nese it is very pervasive that more than one part-of 
-speeches a word has, and a word does not have 
tense or voice flectional transition under different 
tenses or voices. Nevertheless, no large Chinese 
corpus annotated with semantic knowledge has 
ever been built at present. In Semantic Depend-
ency Net (SDN), we try to describe deeper seman-
tic dependency relationship between individual 
words and represent the meaning and structure of 
a sentence by these dependencies. 
Compared with syntactic corpus, it is more dif-
ficult to build a semantic corpus, for the granular-
ity of semantic knowledge is smaller, and 
behaviors of different words differ more greatly. 
Furthermore, ambiguity in semantics is commoner. 
Different people may have different opinions on 
understanding the same word in the same sentence, 
and even the same people may have different 
opinions on understanding the same word in dif-
ferent occasions. In this paper, we emphatically 
discuss the strategy to improve the consistency of 
Semantic Dependency Net. 
The paper is organized as follows. The tagging 
scheme is discussed in Section 2, which describes 
the semantic dependency grammar and the tag set 
of semantic relations. In section 3, we describe the 
tagging task. First, we briefly introduce the text of 
this corpus, which has been tagged with semantic 
classes. Second, we describe the strategy to im-
prove consistency during tagging and checking. 
At last, congruence is defined to measure the con-
sistency of tagged corpus. In Section 4, we briefly 
introduce some of the works on the corpus, and 
indicate the directions that the project is likely to 
take in the future. Finally, we compare SDN cor-
pus with some other well-known corpora.   
  
 
Figure 1:  A sample sentence from the corpus. (a) The sentence tagged with semantic classes; (b) The sen-
tence annotated with semantic dependency; (c) The semantic dependency tree of the sentence, headwords 
are linked with bold lines, and modifier words are linked with arrow lines. 
2 The tagging scheme of semantic depend-
ency 
2.1 Semantic dependency grammar 
Like Word grammar (Hudson, 1998), We believe 
that words are the basic units of semantics, and 
the structure and meaning of a sentence consist 
mainly of semantic dependencies between indi-
vidual words. So a sentence could be annotated 
with a series of semantic dependency relations (Li 
Juanzi and Wang, 2002). Let S be a sentence 
composed of words tagged with semantic classes, 
},,,,,,{ 2211 ><><><= nn swswswS L
. A 
list of semantic dependency relations is defined as: 
)}(,),2(),1({ nSRSRSRSRL L=
, 
where ),()( ii rhiSR = . SR stands for ? semantic 
relation?. ),()( ii rhiSR =  states that the ih -th 
word is the headword to the i-th word with seman-
tic relation ir . If the word j is the root, )( jSR  is 
defined to be (-1, ?kernel word?).  
For example, a sample sentence from the cor-
pus is shown in Figure 1 (a). The semantic de-
pendency relation list and semantic dependency 
tree are shown in Figure 1 (b) and (c) respectively. 
More samples will be seen in Appendix A. 
In semantic dependency grammar, the head-
word of sentence represents the main meaning of 
the whole sentence, and the headword of constitu-
ent represents the main meaning of the constituent. 
In a compound constituent, the headword inherits 
the headword of the head sub-constituent, and 
headwords of other sub-constituents are dependent 
on that headword. We select the word that can 
represent the meaning of the constituent to the 
most extent as headword. For example, the verb is 
the headword of verb phrase, the object is the 
headword of preposition phrase, and the location 
noun is the headword of the location phrase.  
At the same time, semantic dependency rela-
tions do not damage the phrase structure, that is, 
all words in the same phrase are in the same sub-
tree whose root is the headword of the phrase. 
Therefore, when tagging dependency relations, 
semantic and syntactic restrictions are both taken 
into account. The structures of dependency tree 
are mainly determined by syntactic restrictions, 
and the semantic relations are mainly determined 
by semantic restrictions. For example, in Figure 1 
the phrase ??( of his invention pro-
duction) modifies the phrase ?	
? (popu-
larization and application) in syntax, so the word 
?? (popularization) governs the word ?? 
(production).  However, the production is the con-
tent of the action popularization in semantics, so 
the relation between them is ?content?. 
Our tagging scheme is more concise compared 
with phrase structure grammar, in which the 
boundaries of all phrases have to be marked and 
the corresponding labels have to be tagged. In the 
semantic dependency grammar, phrases are im-
plicit, but play no part in grammar. More empha-
sis is paid to the syntactic and semantic functions 
of the word, especially of the headword. 
2.2 The dependency relation tag set 
The dependency relation tag set mainly consists of 
three kinds of relations: semantic relations, syn-
tactic relations and special relations. Semantics is 
the main content of this corpus, so semantic rela-
tions are in the majority, and syntactic relations 
are used to annotate the special structures that do 
not have exact sense in terms of semantics. In ad-
dition, there are two special relations: ?kernel 
word? is to indicate the headword of a sentence, 
and ?failure? is to indicate the word that cannot be 
annotated with dependency relations because the 
sentence is not completed. 
The selections of semantic relations were re-
ferred to HowNet (Dong and Dong, 2001). 
HowNet is a lexical database, which describes the 
relations among words and concepts as a network. 
In HowNet, senventy-six semantic relations are 
defined to describe all relations among various 
concepts, and most of them describe the semantic 
relations between action and other concepts. With 
these semantic relations, necessary role frame is 
further defined. The roles in the necessary role 
frame must take part in the action in real word, 
while these roles may not appear in the same sen-
tence. Hong Kong Technology University has 
successfully tagged a news corpus with the neces-
sary role frame (Yan and Tan, 1999), which 
shows that these roles can describe all semantic 
phenomena in real texts. 
 In order to make tagging task easier and the 
corpus more suitable for statistical learning, we 
have pared down some relations in HowNet and 
got fifty-nine semantic relations. Some HowNet 
relations seldom occurred in the corpus, and their 
semantic functions are somewhat similar, so they 
are merged. Some relations are ambiguous, for 
example ?degree? and ?range?. In order to im-
prove the consistency, we also merge these two 
relations. 
Semantic relations can describe the relations 
between notional words, but they cannot annotate 
function words in some special phrase structures. 
So nine syntactic relations are added. 
The tag set is listed in table 1. Full definition 
of each dependency relation can be seen in (Li 
Mingqin et al, 2002). 
   

	


	

		

	


	 

	Coling 2010: Demonstration Volume, pages 53?56,
Beijing, August 2010
HowNet and Its Computation of Meaning 
Zhendong Dong 
Research Center of Computer 
& Language Engineering, CAS 
dzd@keenage.com 
Qiang Dong 
Canada Keentime Inc. 
dongqiang@keenage.com 
Changling Hao 
Canada Keentime Inc. 
support@keenage.com 
 
Abstract 
The presentation will mainly cover (1) 
What is HowNet? HowNet is an on-line 
common-sense knowledgebase unveiling 
inter-conceptual relationships and inter-
attribute relationships of concepts as 
connoting in lexicons of the Chinese and 
their English equivalents. (2) How it 
functions in the computation of meaning 
and as a NLP platform? The presentation 
will show 9 HowNet-based application 
tools. All of them are not merely demon-
stration of some methodology or algo-
rithm, but are real application tools that 
can be tested by users themselves. Apart 
from the tools that are specially designed 
to deal with Chinese, most of the tools 
are bilingual, even the WSD tool. 
1  What is HowNet 
HowNet is an on-line common-sense knowled-
gebase unveiling inter-conceptual relationships 
and inter-attribute relationships of concepts as 
connoting in lexicons of the Chinese and their 
English equivalents. To put it simply, relation-
ship is the soul of HowNet, as well as the world 
knowledge. The relationships that represent 
knowledge can be divided into two categories: 
Concept Relationship (CR) and Attribute Rela-
tionship (AR). 
It is believed that concept relationships fall in-
to a net, which is called Concept Relation Net 
(CRN) and attribute relationships fall into a net 
too, called Attribute Relation Net (ARN). Dif-
ferent individual has different CRN, even of the 
same concept. This reflects different levels of 
knowledge among people. CRN is elastic or ex-
tendable as it varies with individual persons. The 
more knowledge one has, the more concepts he 
will master, and what is more, the larger or more 
complicated CRN of the concepts he will know. 
It can be imagined that a 6-year child may know 
?doctor? but his CRN of ?doctor? would be far 
from that as shown in Fig. 1, which is believed 
to be mastered by an ordinary adult. The same 
case goes with mankind as a whole. Mankind 
increases his knowledge with each passing year 
when he enlarges his volume of concepts and at 
the same time, the CRN of the concepts. 
Careful observations find that the meaning of 
concepts is displayed not only by its CRN but 
also by the relationships among attributes of the 
concepts, as called Attribute Relation Net. In 
many cases it is the attributes of a concept that 
act in the role of meaning representation. Fig. 2 
reveals that it is not ?paper? as a whole that is 
related to ?write?, but only one of its attributes, 
say ?color?, is related to ?write? with ?contrast? 
as the condition. Therefore in a strict sense, ?pa-
per? is not necessarily related to ?write?. We can 
sometimes even write on the sand with a twig or 
on the table with our wet finger. On the contrary, 
we cannot write on a piece of white paper with a 
chalk or on the blackboard in black ink. There-
fore, for writing, what affects may not be the 
whole lot of the concept like ?paper?, but some 
attributes of the concept. Besides, we can use 
?paper? to wrap up something because of its 
attributes of the material, which are almost the 
same as cloth or plastic. HowNet is unique in its 
four peculiarities: (1) Use of sememes: HowNet 
uses sememes to interpret concepts. Sememes 
are regarded as the basic unit of the meaning. (2) 
Definition in a structuralized language: Each 
concept in HowNet lexicon is defined in a lan-
guage, called Knowledge Database Markup 
Language (KDML). The KDML is mainly com-
posed of sememes and semantic roles. The  
53
 Figure 1 Concept Relation Net (CRN) of ?doctor? 
 
 
Figure 2 Attribute Relation Net (ARN) of ?paper? 
 
Knowledge Database Mark-up Language uses 
2089 sememes, 128 secondary features and 94 
semantic roles as its vocabulary and adopts an 
extended BNF as its syntax. The concept of 
?doctor (medical)? is defined in HowNet as:   
DEF={human|?:HostOf={Occupation|??}, 
condition 
value value value value 
material material instrument 
patient 
instrument 
attribute attribute attribute attribute 
paper 
color thickness hardness 
white thin flammable soft 
write 
contrast 
shopping bag 
make burn 
flammableness 
54
domain={medical|?},{doctor|??:agent={~}}} 
All the computation of meaning in HowNet 
is based on the definitions of the concepts.  
(3) Self-sufficiency: Systematic integration 
of hierarchical taxonomies, axiomatic inference, 
KDML-defined concepts. 
(4) Language independence: In the final 
analysis, HowNet is not word-oriented as 
WordNet, but concept-oriented. Only with the 
HowNet?s shared definitions can we achieve a 
shared ontology for all languages. 
Table 1 shows the latest statistics of the basic 
data of HowNet. 
 
Chinese Character 7182 
Chinese Word & Expression 100385 
English Word & Expression 96565 
Chinese Meaning 115278 
English Meaning 121262 
Definition 30014 
Record 192191 
Semantics Chinese English 
Event 14554 12881 
Attribute 4351 4879 
AttributeValue 10160 10140 
Things 72016 72016 
Time 2683 2683 
Space 1244 1244 
Component 8577 8577 
Table 1 statistics of the basic data of HowNet 
2 HowNet functions as a NLP platform 
HowNet is developing toward a NLP platform. 
HowNet is a powerful tool for the computation 
of meaning. To date, 9 HowNet-based applica-
tion tools have been developed. They are: 
1. HowNet_Browser (E/C bilingual) 
2. HowNet_Relevance (E/C bilingual) 
3. HowNet_Similarity (E/C bilingual) 
4. HowNet_Inference_Pool (E/C bilingual) 
5. HowNet_SenseColonyTester (E/C bilin-
gual) 
6. HowNet_Translate (E-to-C) 
7.HowNet_Morpho_Processor (Chinese mo-
nolingual) 
8. HowNet_VN ? disambiguator for Chinese 
V-N structure (Chinese monolingual) 
9. HowNet_VXY -- disambiguator for Chi-
nese V-N-?-N structure  (Chinese monolingual) 
The purpose for developing these tools is (1) 
to check the HowNet?s data and framework for 
its accuracy and coverage so as to test the 
soundness of its philosophy and design; (2) to 
push HowNet near to end applications so as to 
provide evidence of its value as knowledge re-
sources; 
Of all these tools, HowNet Browser is the 
key. The Browser contains all HowNet basic 
data and provides various kinds of elementary 
or shallow computation of meanings. The basic 
data in HowNet can be divided into two parts: 
firstly, the basic lexical data and secondly tax-
onomies. In the lexical database, each concept 
is described in a fixed structure, for example, 
 
NO.=046048 
W_C=? 
G_C=adj [fu4] 
S_C=PlusSentiment|???? 
E_C=~??~??~??~????~????
???~?~??~????~?????~? 
W_E=rich 
G_E=adj  
S_E=PlusSentiment|???? 
E_E= 
DEF={rich|?} 
RMK= 
 
With the browser the user can retrieve all 
kinds of basic relations between concepts, such 
as synonym, hypernym, hyponym, etc. It should 
be noticed that these kinds of relations in How-
Net are not coded manually as the way as done 
in WordNet, but are computed on the basis of 
concept definitions. The browser can give all 
sorts of semantic roles for a given verb concept. 
To take ?treat? as a given event, we retrieve all 
its ?agents?, ?locations?, ?patients?, ?instru-
ments?. This is regarded as the shallow rela-
tions between verb concepts and their relevant 
noun concepts. 
Particular attention should be given to our 
newly developed tool, HowNet Inference Pool 
(E/C bilingual). With the help of an activator of 
the tool we can build a senses pool for any con-
cept in HowNet. The pool covers all sorts of 
relationships under the key concept, for instance, 
when the concept of ?money? as the key, it has 
a pool with 2600 concepts, including ?bank?, 
?deposit?, ?borrow?, ?buy?, ?steal?, etc. Hence 
55
suppose a question like ?can we borrow money 
from a bank?? is raised to an inference machine, 
we are sure that the machine can give a correct 
answer with correct selection of meanings, like 
?bank? as ?financial bank?. Moreover based on 
the inference machine we have developed a 
word sense disambiguation tool called HowNet 
SenseColony Tester (E/C bilingual). The tool is 
designed to be skilled in tackling the ambiguity 
of discourse type both in Chinese and English. 
The words ?governor?, ?state? in the following 
paragraph are so-called those of discourse-
ambiguity type: 
?We provided $250 in relief to more than 5 
million California seniors -- many whose life 
savings had taken a big hit in the financial crisis. 
And we provided emergency assistance to our 
governors to prevent teachers and police 
officers and firefighters from being laid off as a 
result of state budget shortfalls. At a time when 
California is facing a fiscal crisis, we know that 
this has saved the jobs of tens of thousands of 
educators and other needed public servants just 
in this state. And what was true in California 
was true all across the country.? 
The tool is language independent; it employs 
the data resources and the algorithm of the same 
type. 
HowNet English-Chinese MT system is a 
rule-based system. It uses HowNet basic data as 
its English-Chinese bilingual dictionary. It is 
powerful in its strongly semantic basis. The sys-
tem will surely have a bright future in its appli-
cation to PDA products and Chinese language 
learning aids. 
All the HowNet tools are not merely a demo 
of certain methodology, but are real applica-
tions that can be tested by users themselves. 
References 
Keh-Jiann Chen, Shu-Ling Huang, Yueh-Yin Shih, 
Yi-Jun Chen, 2005, Extended-HowNet: A Repre-
sentational Framework for concepts, Proceedings 
of Second International Joint Conference 2005 
Keh-Jiann Chen, 2009, E-HowNet- a Lexical Se-
mantic Representation System and its Relation to 
Morphology, Syntax and Semantics, (keynote talk, 
at ROCLING XXI 2009) 
Zhendong Dong and Qiang Dong, 2006. HowNet 
and the Computation of Meaning, World Scientif-
ic Publishing Co. Pte. Ltd., Singapore 
Fellbaum, 1998, WordNet: An Electronic Lexical 
Datbase. Ed. Cristiane Fellbaum, The MIT Press, 
Cambridge, London, England, 1998. 
Nagao, Makoto, 1997 Machine Translation Through 
Language Understanding, MT Summit VI Pro-
ceedings 
Yarowsky, D. (1993) One sense per collocation. In 
Proceedings, ARPA Human Language Technolo-
gy Workshop, pp. 266-271. 
???, ??, 2001, ???????, ?????, 
???, ?1?, pp.33-44 
???, 2001, ???????, ??, ?????. 
56
Word Segmentation needs change 
? From a linguist?s view 
Zhendong Dong 
Research Center of Computer 
& Language Engineering, CAS 
dzd@keenage.com 
Qiang Dong 
Canada Keentime Inc. 
dongqiang@keenage.com
Changling Hao 
Canada Keentime Inc. 
support@keenage.com
 
Abstract 
The authors propose that we need some 
change for the current technology in 
Chinese word segmentation. We should 
have separate and different phases in the 
so-called segmentation. First of all, we 
need to limit segmentation only to the 
segmentation of Chinese characters in-
stead of the so-called Chinese words. In 
character segmentation, we will extract 
all the information of each character. 
Then we start a phase called Chinese 
morphological processing (CMP). The 
first step of CMP is to do a combination 
of the separate characters and is then fol-
lowed by post-segmentation processing, 
including all sorts of repetitive structures, 
Chinese-style abbreviations, recognition 
of pseudo-OOVs and their processing, 
etc. The most part of post-segmentation 
processing may have to be done by some 
rule-based sub-routines, thus we need 
change the current corpus-based meth-
odology by merging with rule-based 
technique. 
1 Introduction 
Chinese word segmentation seems to be an old 
grandma?s story. We very often hear some con-
tradictory remarks about its advance. Most of 
reports from the evaluation tasks always gave us 
positive, or even impressive results, such as over 
96% accuracy, but some reports were rather 
negative and expressed their deep concern. They 
claimed that word segmentation was still entan-
gled in a difficult situation and no breakthrough 
in real applications. By careful and longtime ob-
servation, the incompetence is usually caused by 
the coarseness in the currently prevalent tech-
nology. 
We carefully observed some Chinese-English 
MT systems and found some errors were caused 
even in the very early stage of the processing, 
that is, in the stage of word segmentation. No 
matter the MT is statistics-based or rule-based, 
they have their Achilles' heel in the segmenta-
tion stage. Can today?s prevalent technology 
effectively cope with the problem? Or do we 
need some change? The present technology is 
characterized by its ?trilogy?, that is, ?corpora + 
statistics (ML) + evaluation?. We regret to say 
that many researchers today may be indulged in 
methodology itself rather than the language they 
have to target. They are enchanted by the scores 
and ranks, but they forget the object they are 
processing. 
Therefore we propose that a Chinese morpho-
logical processing (CMP) should be taken to 
replace the current Chinese word segmentation. 
CMP includes the following components: 
? Chinese character processing (CCP) 
? Initial combination of Chinese multi-
character expressions (CMEs) 
? Morphological structure processing 
(MSP) 
2 Chinese character processing 
2.1 ?Word? in Chinese 
?Word or no word? may be an even older story 
in Chinese linguistic circle. One assertion about 
Chinese words may be quite popular, even to 
most of western researchers in the NLP circle, 
that is, different from English or other western 
languages, there is no space between Chinese 
words and thus segmentation of a running text 
into words is necessary for Chinese processing. 
However, do words really exist in Chinese? It is 
still a vexing and controversial issue. Some 
Chinese grammarians argue that in Chinese there 
are no words at all, but there are only characters 
instead and some express their strong objection. 
What is a Chinese ?word?? It was reported 
that the concept of ?word? had not been intro-
duced into China until the very beginning of the 
last century. In fact word is alien to Chinese. At 
least the concept of word in Chinese is rather 
vague. In Chinese there are no clear-cut distinc-
tion between characters and so-called word, ei-
ther between multi-character words and those 
that are similar to English MWE. Ordinary Eng-
lish people may be surprised if they are told that 
even in popular Chinese dictionaries there are no 
entries equivalent to English ?pork (??)?, 
?beef ??)?, ?egg (??)?, ?rain (verb ??)?, 
?snow (verb ??)?, but there are entries equiva-
lent to English ?lower limbs(??)?, ?give or-
ders (??)?, ?appendicitis (???)?. There is 
somewhat arbitrariness in recognition of Chinese 
?words?, so the vocabulary in different Chinese 
dictionaries may vary very greatly. Does a dic-
tionary take usage frequency into account when 
it decides on its entries? Let?s compare their oc-
currence with the following entries in the dic-
tionary as shown in Table 1. Let?s compare the 
occurrence with the following entries in different 
dictionaries and in reference to Google?s results. 
In Table 1, ?-? indicates that the entry does not 
occur and ?+? indicates the entry occurs. 
 
Entries 3 Popular dictionaries Results in 
Google 
?? -  ??1 
- ??  2
- ?????  3
32,500,000 
?? -  ?? 
+ ??   
- ?????   
24,300,000 
?? -  ?? 
+??  
- ?????   
16,600,000 
                                                 
1 Modern Chinese Dictionary 
2 Modern Chinese Standard Dictionary 
3 New Age Chinese-English Dictionary 
?? +  ?? 
- ??   
+ ?????   
6,760,000 
??   +  ?? 
+ ??   
+ ?????   
497,000 
?? -  ?? 
+ ??   
+ ?????   
409,000 
??   +  ?? 
+ ??   
+ ?????   
900,000 
Table 1. Comparison of entry occurrence in 
dictionaries 
 
In a word, since ?word? in Chinese is rather 
vague, what is a better tactics we should take 
then? The present word segmentation is bur-
dened too heavily. In comparison with English 
tokenization, it goes too far. Does English to-
kenization deal with MWEs, such as ?United 
nations?, ?free of charge?, ?first lady?? Why 
does Chinese word segmentation have to deal 
with Chinese multi-character ?word?? 
2.2 Chinese character processing (CCP) 
We propose that the real task of so-called Chi-
nese word segmentation is to segment a running 
text into single characters with spaces between. 
We call this processing Chinese character proc-
essing (CCP). CCP is in parallel with English 
tokenization. In most cases CCP can achieve 
100% accuracy. The most important task for 
CCP is not only to segment a text, but also to 
obtain various kinds of information (syntactic, 
semantic) of every character. What will be fol-
lowed depends on the tasks to be designated. 
Usually a demand-led morphological processing 
will be taken. 
3 Initial combination 
In most cases, what we called initial combina-
tion of Chinese multi-character expressions 
(CMEs) should be followed indispensably. It 
may be either shallow or deep, and may be done 
either with the help of a lexical database or a 
corpus, and the longest matching may be the 
frequently-used technique.   
4 Morphological structure processing 
(MSP) 
4.1 Pseudo-OOVs 
The first task of MSP is to recognize and process 
Chinese OOVs. What are OOVs in English? 
Normally if a string between two spaces in a 
running text does not exist in the lexical 
database or the corpus the processing system is 
using, this string is taken as an OOV. However, 
what is an OOV in Chinese then? It is really not 
so easy to define an OOV in Chinese as in 
English. The recognition of English OOVs may 
be done in the phase of tokenization, but the 
recognition of Chinese OOVs should, in a strict 
sense, not be done in so-called word 
segmentation. It should be regarded as a special 
phase of the morphological processing. It is 
commonly acknowledged that OOV recognition 
is the most serious factor that impairs the 
performance of current Chinese word 
segmentation.  
We may first look at some instances of ma-
chine translation results and find the actual prob-
lems. The reason why we use MT systems to test 
and evaluate segmentation is because this will 
make it explicit and easy for human to assess. 
One error in segmentation makes a 100% failure 
in translation. In our examples, the translation (a) 
is done by a statistical MT system and the trans-
lation (b) by a rule-based MT system. (C) is hu-
man translation, which may help make compari-
son and find the errors made by MT. 
 
1. ?????????? 2020????? 
(a) Americans even behind the bid to host 
the 2020 Olympic Games in Nanjing. 
(b) American people's strength holds out 
in Nanjing and bids for the 2020 Olympic 
Games. 
(c) Americans fully backed up Nanjing?s 
bid to host the 2020 Olympic Games. 
 
Chinese OOVs can be roughly categorized 
into two classes, one is true OOVs and the other 
is pseudo-OOVs. The recognition and process-
ing of true OOVs can be done as English OOVs 
are treated in English.  However, the recognition 
and processing of Chinese pseudo-OOVs should 
be done by a special processing module. Chinese 
pseudo-OOVs includes two types: plain pseudo-
OOVs, such as ????, ????, ????, ????, 
????, ????, and abbreviated pseudo-OOVs, 
such as ????, ????, ????, ????, ???
???, ?????, ?????, ?????, ???
??, ?????, ??????. 
? Plain pseudo-OOVs 
A pseudo-OOV is a combinatory string of 
Chinese characters in which each character car-
ries one of its original meanings and the way of 
combination conforms to Chinese grammatical 
pattern. In the above Chinese sentence the word 
???? is a typical pseudo-OOV. ???? is a 
combination of two characters, ??? and ???. 
??? has four meanings, one of which is ?do 
one?s best?. ??? has six meanings, one of which 
is ?back up?. Originally in Chinese dictionaries 
we can find the following expressions similar to 
the pattern of ????, such as ????, ????, 
????, ????, ????, ????, ????, ??
??, ????, ????, ????, ????. In all 
these expressions the character ??? carries the 
same meaning as that in ????, and the second 
characters in the combinations are all actions. 
Therefore the expression ???? is a grammati-
cal and meaningful pseudo-OOV. It should be 
noticed that this kind of pseudo-OOV is highly 
productive in Chinese. In addition to all the dic-
tionary entries that we listed above, we found 
???(to strongly state)?and ???(to strongly 
resist)? are already used in the web. Its highly 
occurrence in real texts calls our special atten-
tion. Let?s see how MT will tackle them poorly. 
 
2. ?????????? 
(a) Chen multiple defense of human 
doubt. 
(b) Many old doubtful points of the man-
power of pleading. 
(c) The pleader argued and showed many 
doubtful points. 
We wonder how the current technique of 
segmentation tackles the problem. We are not 
sure how one error in a segmentation effect the 
score in Bakeoff.  
Let?s look at two more examples and have a 
brief discussion of them. 
 
3.?????????????????
??????????? 
(a) According to neighbors reflected the 
incident that day at noon there is a fast food 
take-Lang came to the victim's home.  
(b) According to the information of 
neighbour's, a fast food takes out the my 
darling to been to victim's home at noon on 
the day when the case happened. 
(c) According to the neighbors, at noon on 
the same day a fast food takeout boy came 
to the victim?s house. 
 
4. ???????????? 
(a) One officer was stabbed to death the 
women pedicure. 
(b) An officer is trimmed the foot daughter 
and assassinated.  
(c) An official was stabbed to death by the 
girl pedicurist. 
 
All the four erroneous MT translations above 
originate from the so-called recognition of 
OOVs ????? and ????? in the segmenta-
tion. The MT systems might make out ??
??and ??? or ???? and ??? separately, but 
fail to recognize their combinations. The combi-
nation pattern of these two plain pseudo-OOVs 
is a very typical and popular one in Chinese, just 
similar to the suffix ?-er? or ?-or? in English to 
derive a noun of a doer. ????? is a combina-
tion of ????(takeout) and ???(boy). When a 
MT failed to tackle it, the translation would be 
so poor. 
? Abbreviated pseudo-OOVs 
Different from English abbreviations or acro-
nyms, Chinese abbreviations in essence are con-
tracted forms of words and expressions. The 
contraction is mainly related to three factors: (1) 
maximal preservation of the original meaning; (2) 
possible maintenance of Chinese grammatical 
structural pattern; (3) consideration of accept-
ableness of rhythm. Let?s take ????? for ex-
ample. ????? is the contraction of 
?????????. The literal translation of the 
expression is ?maintain stability office?. Thus 
the first part of the expression ?????? is 
contracted to ????, and the second part is con-
tracted to ???. ?????? grammatically is a 
?verb + object? structure while ???? can be 
regarded as the same grammatical structure. 
Grammatically ????? is modified by 
??????, and in the contraction the word 
??? is also modified by the contraction ????. 
As for acceptableness of rhythm, ????? is a 
three-character expression, in which the first two 
are a ?verb + object structure and the last is sin-
gle. The structure of ?2-character verb + 1-
character noun? is a highly-productive pattern of 
noun expression in Chinese. So it is desirable to 
process this type of structures before syntactic 
processing. As the structure can usually be pat-
ternized, it is possible to have them well-
processed. We propose that we should deal with 
it in the morphological processing stage. 
4.2 Repetitive structures 
First let?s look at a MT translation and see what 
has happened when a Chinese repetitive struc-
ture is ill-processed. 
 
5. ?????????? 
(a) Come see Chuan Chuan, too small. 
(b) You come to wear looking, it is too 
small. 
(c) Come and try on, it is too small. 
 
The above two erroneous MT translations (a) 
and (b) originate from the failure in dealing with 
a typical verb structural pattern for expression to 
urge someone to have a try. This pattern is: 
??VV ?, its actual meaning is ?have a try? and 
?to see if ??. The literal translation of the above 
???instance ? ? may be ?put on, put on and 
let?s have a look?. Similarly we can have 
???? ? (which can be literally translated as 
?taste, taste, and let?s see?). 
Chinese is unique with its various types of re-
petitive structures. They are by no means rare 
phenomena in real texts. Any negligence or fail-
ure in the processing of repetitive structures will 
surely spoil the succedent tasks. Unfortunately 
this problem has not caught enough attention of 
researchers and developers of word segmenta-
tion tools. Most of neglecters usually leave the 
problem to the vocabulary that they collect. 
Let?s compare the following two groups of 
translations: 
Group A 
????????????????? 
???????????? 
Group B 
???????????????? 
????????????? 
Group A1 
You listen carefully, is not where the leak 
was. 
He looked at the stop next to the train. 
Group B1 
Carefully you chew a chewing is not a 
mint flavor. 
He sat down, then back by the by. 
 
The English translations of the repetitive 
structures in Group A1 are acceptable for the 
??? ???structures ? ? and ? ? are no doubt 
in the vocabulary. And the translations of Group 
B are messy enough to show that the repetitive 
structures become OOVs and are not well-
processed.  
Generally most of Chinese repetitive struc-
tures originate from three word classes: 
? Verb repetitive patterns: 
AA   ??, ?? ??,  
ABAB  ???? ????,  
? ?A / A  ??? ??? ,  
?AA   ??? ???,  
A??/?A  ???? ????????, ,  
 
? Adjective repetitive patterns: 
AA   ?? ?? ?? ??, , ,  
AABB  ???? ???? , ,???? 
ABAB  ???? ????,  
 
? Classifier repetitive patterns: 
AA  ??????? ,  
????????? 
?AA ??? ??? ??? , , ,  
??? 
?A?A ???? ???????? , ,  
?A??A  ????? ?????, ,  
????? 
 
All these patterns are highly productive in 
Chinese. It will be impracticable for any Chinese 
parsing or MT systems to leave all the resolu-
tions of them to the vocabulary rather than spe-
cial processing module. 
4.3 Plain classifier and unit structures 
Chinese is featured by its plenty of classifiers. In 
many cases a concrete noun occurs idiomatically 
with its particular classifier especially when 
modified a numeral, for example, ?????(a 
person), ?????(two cars), ???????(3 
kilos of apples). The processing of this type of 
structures will surely benefit the succeeding 
parsing and even word sense disambiguation. 
Besides the processing is comparatively easy 
even in the early stage. 
4.4 Chinese verb aspect processing 
The verb aspect in Chinese is different from that 
in English. In general, by using Chinese aspects, 
we add some procedural tune to a verb rather 
than relating to time. In other words Chinese 
verb aspects give hints of the developmental 
phases or results, or the capability or possibility 
of the events. Chinese verb aspects are expressed 
by the aspect markers, such as simple markers 
???, ???, ???, ???, ???, ???, ???, ???, 
??? and compound markers ????, ????, 
etc.  
Again let?s look at two pair of Chinese-to-
English MT translations. 
(6) ?????????????????
???? 
(a) To dry too much work, a person in-
deed dry However come. 
(b) The ones that should do have too 
much work, one can not really be dry. 
(c) I have too much work to do, I can 
hardly cope with it. 
 
(7) ??????????? 
(a) Said the girl spoke to cry. 
(b) The girl has cried saying. 
(c) The girl began to weep while talking. 
 
The messy translations tell us how serious the 
impairment of the translation will be if we fail to 
process the Chinese verb aspects. 
Table 2 shows the meanings conveyed by 
most Chinese aspect and its corresponding ?as-
pect markers? and examples. Finally, when 
speaking about Chinese aspect, one point we 
would like to invite readers? attention that dif-
ferent from the aspect of English. It is known 
that English aspect is usually closely related to 
tenses, for example, English verbs can be used in 
progressive aspect with various tenses, such as 
present progressive, progressive and future pro-
gressive tenses. However, Chinese aspects are 
related to the development of the event itself, but 
not related to the time when the event happens. 
5 Conclusion 
Is it time for Chinese NLP circle to rethink what 
we have actually achieved in the word segmen-
tation and consider some radical change? How 
much room left is there for the current trilogy to 
improve? We propose that we should have mor-
phological processing to replace the so-called 
word segmentation. We have designated new 
tasks for the processing. In addition, we hope 
that we should design and use a new evaluation 
method. The general idea of new evaluation is to 
use a post-segmentation, or post-morphological-
processing task, say, chunking, to evaluate, 
rather than the present method of isochronous 
self-testing.  
 
sememe in 
HowNet meaning marker examples 
{Vsuppose|
??} presupposing 
?? ?~?? 
?? ????~ {Vstart| ?
?} inceptive ? ????~?
? ~??? 
? ~??? 
?? ~?? {Vgoingon|??} progressive ? ?~?~??
? 
{Vcontinue|
??} protractive 
?? ?~????
{Vend|??} terminative ? ?~????
? ?~??? 
?? ?~?? 
? ?~??? 
? ??~? 
?? ?????~
?? ???~? 
? ???~? 
? ?~????
~ 
? ?~????
? ?~????
{Vachieve|
??} perfective 
? ?~????
?? ?~ 
?? ?~ 
??? ?~ 
?? ????~ 
?? ?~ 
?? ?~ 
? ?~??~ 
{Vable| ?
?} capable 
? ???~3 ?
? 
?? ???~ 
?? ?~? 
??? ????~ 
?? ?????~
?? ??~ 
{Vincapable|
???} incapable 
?? ?~ 
{Vpossible|
??} possible 
? ???~??
~ 
{Vtry|??} Trying ? ??~ 
Table 2.  Chinese aspect markers and their 
meanings 
References 
Hai Zhao and Chunyu Kit, 2008. Unsupervised 
Segmentation Helps Supervised Learning of Chi-
nese Tagging for Word Segmentation and Named 
Entity Recognition. In Prceedings of the Sixth 
SIGHAN Workshop on Chinese Language Proc-
essing, 2008, Hyderbad, India. 
Hwee Tou Ng and Jin Kiat Low, 2004. Chinese Part-
of-speech Tagging: One-at-a-Time or All-at-once? 
Word-Based or Character-Based? In Proceedings 
EMNLP. 
Nianwen Xue, 2003. Chinese Word Segmentation as 
Character Tagging. International Journal of Com-
putational Lnguistics and Chinese Language Proc-
essing, 8(1):29-48 
Wenbin Jiang and Haitao Mi and Liang Huang and 
Qun Liu, 2008b. Wird Lattice Reranking for Chi-
nese Word Segmentation and Part-of-speech Tag-
ging. In Proceedings of COLING 
Xinnian Mao, Yuan Dong and Saike He, Sencheng 
Bao and Haila Wang, Chinese Word Segmentation 
and Name Entity Recognition Based on Condition 
Random Fields, In Prceedings of the Sixth 
SIGHAN Workshop on Chinese Language Proc-
essing, 2008, Hyderbad, India. 
Zhendong Dong and Qiang Dong, 2006. HowNet and 
the Computation of Meaning, World Scientific 
Publishing Co. Pte. Ltd., Singapore 
??? ??, , 2007, ????????. 
??????, 2007, 21(3):8-20. 
???, 2009, ?? ?? ??? , , : 
??????????. In Proceedings of  
CNCCL-2009, Yantai 
