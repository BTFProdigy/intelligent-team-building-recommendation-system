Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1475?1483,
Singapore, 6-7 August 2009.
c
?2009 ACL and AFNLP
Chinese Semantic Role Labeling with Shallow Parsing
Weiwei Sun and Zhifang Sui and Meng Wang and Xin Wang
Institute of Computational Linguistics
Peking University
Key Laboratory of Computational Linguistics
Ministry of Education, China
weiwsun@gmail.com;{szf,wm}@pku.edu.cn;xinwang.cpku@gmail.com;
Abstract
Most existing systems for Chinese Seman-
tic Role Labeling (SRL) make use of full
syntactic parses. In this paper, we evalu-
ate SRL methods that take partial parses as
inputs. We first extend the study on Chi-
nese shallow parsing presented in (Chen
et al, 2006) by raising a set of addi-
tional features. On the basis of our shal-
low parser, we implement SRL systems
which cast SRL as the classification of
syntactic chunks with IOB2 representation
for semantic roles (i.e. semantic chunks).
Two labeling strategies are presented: 1)
directly tagging semantic chunks in one-
stage, and 2) identifying argument bound-
aries as a chunking task and labeling their
semantic types as a classification task. For
both methods, we present encouraging re-
sults, achieving significant improvements
over the best reported SRL performance
in the literature. Additionally, we put
forward a rule-based algorithm to auto-
matically acquire Chinese verb formation,
which is empirically shown to enhance
SRL.
1 Introduction
In the last few years, there has been an increas-
ing interest in Semantic Role Labeling (SRL) on
several languages, which consists of recognizing
arguments involved by predicates of a given sen-
tence and labeling their semantic types. Nearly
all previous Chinese SRL research took full syn-
tactic parsing as a necessary pre-processing step,
such as (Sun and Jurafsky, 2004; Xue, 2008; Ding
and Chang, 2008). Many features are extracted to
encode the complex syntactic information. In En-
glish SRL research, there have been some attempts
at relaxing the necessity of using full syntactic
parses; better understanding of SRL with shallow
parsing is achieved by CoNLL-2004 shared task
(Carreras and M`arquez, 2004). However, it is still
unknown how these methods perform on other lan-
guages, such as Chinese.
To date, the best SRL performance reported on
the Chinese Proposition Bank (CPB) corresponds
to a F-measure is 92.0, when using the hand-
crafted parse trees from Chinese Penn Treebank
(CTB). This performance drops to 71.9 when a
real parser is used instead
1
(Xue, 2008). Com-
paratively, the best English SRL results reported
drops from 91.2 (Pradhan et al, 2008) to 80.56
(Surdeanu et al, 2007). These results suggest that
as still in its infancy stage, Chinese full parsing
acts as a central bottleneck that severely limits our
ability to solve Chinese SRL. On the contrary, Chi-
nese shallow parsing has gained a promising re-
sult (Chen et al, 2006); hence it is an alternative
choice for Chinese SRL.
This paper addresses the Chinese SRL problem
on the basis of shallow syntactic information at
the level of phrase chunks. We first extend the
study on Chinese chunking presented in (Chen et
al., 2006) by raising a set of additional features.
The new set of features yield improvement over
the strong chunking system described in (Chen et
al., 2006). On the basis of our shallow parser, we
implement lightweight systems which solve SRL
as a sequence labeling problem. This is accom-
plished by casting SRL as the classification of syn-
tactic chunks (e.g. NP-chunk) into one of semantic
labels with IOB2 representation (?). With respect
to the labeling strategy, we distinguish two differ-
ent approaches. The first one directly recognizes
semantic roles by an IOB-type sequence tagging.
The second approach divides the problem into two
independent subtasks: 1) Argument Identification
(AI) and 2) Semantic Role Classification (SRC).
1
This F-measure is evaluated on the basis of hand-crafted
word segmentation and POS tagging.
1475
A Chinese word consists of one or more char-
acters, and each character, in most cases, is a mor-
pheme. The problem of how the words are con-
structed from morphemes, known as word for-
mation, is very important for a majority of Chi-
nese language processing tasks. To capture Chi-
nese verb formation information, we introduce a
rule-based algorithm with a number of heuristics.
Experimental results indicate that word formation
features can help both shallow parsing and SRL.
We present encouraging SRL results on CPB
2
.
The best F-measure performance (74.12) with
gold segmentation and POS tagging can be
achieved by the first method. This result yield
significant improvement over the best reported
SRL performance (71.9) in the literature (Xue,
2008). The best recall performance (71.50) can be
achieved by the second method. This result is also
much higher than the best reported recall (65.6) in
(Xue, 2008).
2 Related Work
Previous work on Chinese SRL mainly focused on
how to implement SRL methods which are suc-
cessful on English, such as (Sun and Jurafsky,
2004; Xue and Palmer, 2005; Xue, 2008; Ding
and Chang, 2008). Sun and Jurafsky (2004) did
the preliminary work on Chinese SRL without
any large semantically annotated corpus of Chi-
nese. Their experiments were evaluated only on
ten specified verbs with a small collection of Chi-
nese sentences. This work made the first attempt
on Chinese SRL and produced promising results.
After the CPB was built, (Xue and Palmer, 2005)
and (Xue, 2008) have produced more complete
and systematic research on Chinese SRL. Ding
and Chang (2008) divided SRC into two sub-tasks
in sequence. Under the hierarchical architecture,
each argument should first be determined whether
it is a core argument or an adjunct, and then be
classified into fine-grained categories. Chen et
al. (2008) introduced an application of transduc-
tive SVM in Chinese SRL. Because their experi-
ments took hand-crafted syntactic trees as input,
how transductive SVMs perform in Chinese SRL
in realistic situations is still unknown.
Most existing systems for automatic Chinese
SRL make use of a full syntactic parse of the sen-
tence in order to define argument boundaries and
2
Our system is available at
http://code.google.com/p/csrler/
to extract relevant information for training clas-
sifiers to disambiguate between role labels. On
the contrary, in English SRL research, there have
been some attempts at relaxing the necessity of us-
ing syntactic information derived from full parse
trees. For example, Hacioglu and Ward (2003)
considered SRL as a chunking task; Pradhan et
al. (2005) introduced a new procedure to incor-
porate SRL results predicted respectively on full
and shallow syntactic parses. Previous work on
English suggests that even good labeling perfor-
mance has been achieved by full parse based SRL
systems, partial parse based SRL systems can still
enhance their performance. Though better under-
standing of SRL with shallow parsing on English
is achieved by CoNLL-2004 shared task (Carreras
and M`arquez, 2004), little is known about how
these SRL methods perform on Chinese.
3 Chinese Shallow Parsing
There have been some research on Chinese shal-
low parsing, and a variety of chunk defini-
tions have been proposed. However, most of
these studies did not provide sufficient detail.
In our system, we use chunk definition pre-
sented in (Chen et al, 2006), which provided
a chunk extraction tool. The tool to extract
chunks from CTB was developed by modify-
ing the English tool used in CoNLL-2000 shared
task, Chunklink
3
, and is publicly available at
http://www.nlplab.cn/chenwl/chunking.html. The
definition of syntactic chunks is illustrated in Line
CH in Figure 1. For example, ?????/the in-
surance company?, consisting of two nouns, is a
noun phrase.
With IOB2 representation (Ramshaw and Mar-
cus, 1995), the problem of Chinese chunking can
be regarded as a sequence labeling task. In this
paper, we first implement the chunking method
described in (Chen et al, 2006) as a strong base-
line. To conveniently illustrate, we denote a word
in focus with a fixed window w
?2
w
?1
ww
+1
w
+2
,
where w is current token. The baseline features
includes:
? Uni-gram word/POS tag feature: w
?2
, w
?1
,
w, w
+1
, w
+2
;
? Bi-gram word/POS tag feature: w
?2
w
?1
,
w
?1
w, w w
+1
, w
+1
w
+2
;
3
http://ilk.uvt.nl/team/sabine/chunklink/chunklink 2-2-
2000 for conll.pl
1476
WORD: ?? ?? ?? ?? ? ? ?? ?? ?? ?? ??
POS: [P] [NT] [NN NN] [AD] [P] [NR] [NN] [VP] [NN NN]
CH: [PP NP] [NP] [ADVP] [PP NP NP ] [VP] [NP]
M1: B-A* I-A*
4
B-A0 B-AM-ADV B-A2 I-A2 I-A2 B-V B-A1
M2-AI: B-A I-A B-A B-A B-A I-A I-A B-V B-A
M2-SRC: AM-TMP A0 AM-ADV A2 Rel A1
Until now, the insurance company has provided insurance services for the Sanxia Project.
Figure 1: An example from Chinese PropBank.
That means 18 features are used to represent a
given token. For instance, the bi-gram Word fea-
tures at 5th word position (???/company?) in
Figure 1 are ?? ???, ??? ???, ??? ??,
?? ??.
To improve shallow parsing, we raised an addi-
tional set of features. We will discuss these fea-
tures in section 5.
4 SRL with Shallow Parsing
The CPB is a project to add predicate-argument
relations to the syntactic trees of the CTB. Similar
to English PropBank, the semantic arguments of a
predicate are labeled with a contiguous sequence
of integers, in the form of AN (i.e. ArgN ); the ad-
juncts are annotated as such with the label AM (i.e.
ArgM) followed by a secondary tag that represents
the semantic classification of the adjunct. The as-
signment of argument labels is illustrated in Figure
1, where the predicate is the verb ???/provide?.
For example, the noun phrase ?????/the in-
surance company? is labeled as A0, meaning that it
is the proto-Agent of ??; the preposition phrase
?????/until now? is labeled as AM-TMP, in-
dicating a temporal component.
4.1 System Architecture
SRL is a complex task which has to be decom-
posed into a number of simpler decisions and tag-
ging schemes in order to be addressed by learn-
ing techniques. Regarding the labeling strategy,
we can distinguish at least two different strategies.
The first one consists of performing role identifi-
cation directly as IOB-type sequence tagging. The
second approach consists of dividing the problem
into two independent subtasks.
4
The semantic chunk labels here are B-AM-TMP and I-
AM-TMP. Limited to the document length, we cannot put all
detailed chunk labels in one line in Figure 1.
4.1.1 One-stage Strategy
In the one-stage strategy, on the basis of syntac-
tic chunks, we define semantic chunks which do
not overlap nor embed using IOB2 representation.
Syntactic chunks outside a chunk receive the tag
O. For syntactic chunks forming a chunk of type
A*, the first chunk receives the B-A* tag (Begin),
and the remaining ones receive the tag I-A* (In-
side). Then a SRL system can work directly by
using sequence tagging techinique. Since the se-
mantic annotation in the PropBank corpus does
not have any embedded structure, there is no loss
of information in this representation. The line M1
in Figure 1 illustrates this semantic chunk defini-
tion.
4.1.2 Two-stage Strategy
In the two-stage architecture, we divide Chinese
SRL into two subtasks: 1) semantic chunking for
AI, in which the argument boundaries are pre-
dicted, and 2) classification for SRC, in which the
already recognized arguments are assigned role la-
bels. In the first stage, we define semantic chunks
B-A which means begin of an argument and I-A
which means inside of an argument. In the second
stage, we solve SRC problem as a multi-class clas-
sification. The lines M2-AI and M2-SRC in Fig-
ure 1 illustrate this two-stage architecture. For ex-
ample, the noun phrase ?????/the insurance
company? is proto-Agent, and thus should be la-
beled as B-A in the AI chunking phase, and then
be tagged as A0. The phrase ??????/for the
Sanxia Project? consists of three chunks, which
should be labeled as B-A, I-A, and I-A respectively
in the AI chunking phase, then these three chunks
as a whole argument should be recognized as A2.
4.1.3 Chunk-by-Chunk
There is also another semantic chunk definition,
where the basic components of a semantic chunk
are words rather than syntactic chunks. A good
election for this problem is chunk-by-chunk pro-
1477
cessing instead of word-by-word. The motivation
is twofold: 1) phrase boundaries are almost always
consistent with argument boundaries; 2) chunk-
by-chunk processing is computationally less ex-
pensive and allows systems to explore a relatively
larger context. This paper performs a chunk-by-
chunk processing, but admitting a processing by
words within the target verb chunks.
4.2 Features
Most of the feature templates are ?standard?,
which have been used in previous SRL research.
We give a brief description of ?standard? features,
but explain our new features in detail.
5
4.2.1 Features for Semantic Chunking
In the semantic chunking tasks, i.e. the one-stage
method and the first step in the two-stage method,
we use the same set of features. The features
are extracted from three types of elements: syn-
tactic chunks, target verbs, links between chunks
and target verbs. They are formed making use
of words, POS tags and chunks of the sentence.
Xue (2008) put forward a rough verb classifica-
tion where verb classes are automatically derived
from the frame files, which are verb lexicon for
the CPB annotation. This kind of verb class in-
formation has been shown very useful for Chinese
SRL. Our system also includes this feature. In our
experiments, we represent a verb in two dimen-
sions: 1) number of arguments, and 2) number of
framesets. For example, a verb may belong to the
class ?C1C2,? which means that this verb has two
framesets, with the first frameset having one argu-
ment and the second having two arguments.
To conveniently illustrate, we de-
note a token chunk with a fixed context
w
i?1
[
c
k
w
i
...w
h
...w
j
]w
j+1
, where w
h
is the
head word of this chunk c
k
. The complete list of
features is listed here.
Extraction on Syntactic Chunks
Chunk type: c
k
.
Length: the number of words in a chunk.
Head word/POS tag. The rules described in
(Sun and Jurafsky, 2004) are used to extract head
word.
IOB chunk tag of head word: chunk tag of head
word with IOB2 representation (e.g. B-NP, I-NP).
5
The source code of our system also provides lots of com-
ments for implementation of all features.
Chunk words/POS tags context. Chunk con-
text includes one word before and one word after:
w
i?1
and w
j+1
.
POS tag chain: sequential containers of each
word?s POS tag: w
i
... w
j
. For example, this fea-
ture for ?????? is ?NN NN?.
Position: the position of the phrase with respect
to the predicate. It has three values as before, after
and here.
Extraction on Target Verbs Given a target verb
w
v
and its context, we extract the following fea-
tures.
Predicate, its POS tag, and its verb class.
Predicate IOB chunk tag context: the chain of
IOB2 chunk tags centered at the predicate within
a window of size -2/+2.
Predicate POS tag context: the POS tags of
the words that immediately precede and follow the
predicate.
Number of predicates: the number of predicates
in the sentence.
Extraction on Links To capture syntactic prop-
erties of links between the chunks and the verbs,
we use the following features.
Path: a flat path is defined as a chain of base
phrases between the token and the predicate. At
both ends, the chain is terminated with the POS
tags of the predicate and the headword of the to-
ken.
Distance: we have two notions of distance. The
first is the distance of the token from the predicate
as a number of base phrases, and the second is the
same distance as the number of VP chunks.
Combining Features We also combine above
features as some new features.
Conjunctions of position and head word, tar-
get verb, and verb class, including: position w
h
,
position w
v
, position w
h
w
v
, position class,
and position w
h
class.
Conjunctions of position and POS tag of
head word, target verb, and verb class, in-
cluding: position w
h
w
v
, position w
h
, and
position w
h
class.
4.2.2 Features for SRC
In the SRC stage of the two-stage method, dif-
ferent from previous work, our system only uses
word-based features, i.e. features extracted from
words and POS tags, to represent a given argu-
ment. Experiments show that a good semantic
1478
role classifier can be trained by using only word-
based features. To gather all argument position
information predicted in AI stage, we design a
coarse frame feature, which is a sequential collec-
tion of arguments. So far, we do not know the
detailed semantic type of each argument, and we
use XP as each item in the frame. To distinguish
the argument in focus, we use a special symbol
to indicate the corresponding frame item. For in-
stance, the Frame feature for argument ???
? is XP+XP+XP+XP+V+!XP, where !XP means
that it is the argument in focus.
Denote 1) a given argument
w
i?2
w
i?1
[w
i
w
i+1
...w
j?1
w
j
]w
j+1
w
j+2
, and
2) a given predicate w
v
. The features for SRC are
listed as follows.
Words/POS tags context of arguments: the con-
tents and POS tags of the following words: w
i
,
w
i?1
, w
i?2
, w
i+1
, w
i+2
, w
j
, w
j+1
, w
j?1
, w
j?2
,
w
j+1
, w
j+2
; the POS tags of the following words:
w
i+1
, w
i+2
, w
j+1
, w
j+2
.
Token Position.
Predicate, its POS, and its verb class.
Coarse Frame.
Combining features: conjunctions of bound-
ary words, including w
i?1
w
j+1
and w
i?2
w
j+2
;
conjunction of POS tags of boundary words, in-
cluding w
i?1
w
j+1
and w
i?2
w
j+2
; conjunction
of token position, boundary words, and predi-
cate word, including position w
i
w
j
, w
i
w
j
w
v
;
position w
i
w
j
w
v
; conjunction of token posi-
tion, boundary words? POS tags, and predicate
word, also including position w
i
w
j
, w
i
w
j
w
v
;
position w
i
w
j
w
v
; conjunction of predicate and
frame; conjunction of target verb class and frame;
conjunction of boundary words? POS tags, and
predicate word.
5 Automatic Chinese Verb Formation
Analyzing
5.1 Introduction to Chinese Word Formation
Chinese words consist of one or more charac-
ters, and each character, in most cases, is a mor-
pheme which is the smallest meaningful unit of
the language. According to the number of mor-
phemes, the words can be grouped into two sets,
simple words (consisting of one morpheme) and
compound words (consisting of two morphemes
or more). There are 9 kinds of word formation in
Chinese compound words, and table 1 shows the
detail with examples. Note that, attributive-head
and complementarity are not for Chinese verbs.
Types Examples
reduplication ??(look)??(think)
affixation ??(intensify)??(feel)
subject-verb ??(hear)??(dictate)
verb-object ??(quit smoking)
??(haircut)
verb-complement ??(inform)??(plant)
verb-result ??(exceed)??(boil)
adverbial-head ??(retreat)??(misuse)
coordinate ??(cherish)??(chase)
attributive-head* ??(rumor)??(hospital)
complementarity* ??(paper)??(horse)
Table 1: Example Words with Formation
The internal structure of a word constraints its
external grammatical behavior, and the formation
of a verb can provide very important information
for Chinese SRL. Take ???/exceed? as an ex-
ample, the two characters are both verbal mor-
phemes, and the character ??? means ?pass? and
the character ??? with the meaning of ?over?
shows the complement of the action of ???. In
this word, ??? is usually collocated with an ob-
ject, and hence a Patient role should comes af-
ter the verb ????. Note that, the verb ???,
however, is unlikely to have an object. Take ??
?/haircut? as another example, the first charac-
ter ??? is a verbal morpheme with the meaning
of ?cut? and the second character ??? is a nomi-
nal morpheme with the meaning of ?hair?. In this
word, ??? acts as the object of ???, and the word
???? is unlikely to have an Patient any more in
the sentential context.
5.2 Verb Formation Analyzing Method
To automatically analyze verb formation, we in-
troduce a rule-based algorithm. Pseudo code in
Algorithm 1 illustrates our algorithm. This algo-
rithm takes three string (one or more Chinese char-
acters) sets as lexicon knowledge:
? adverbial suffix set A: strings in A are usu-
ally realized as the modifier in a adverbial-
head type word, e.g. ?/not, ?/not,
?/always,?/both,?/all.
? object head setO: strings inO are usually re-
alized as the head in a verb-object type word,
e.g. ?/change,?/get,?/talk,?/send.
1479
Algorithm 1: Verb Formation Analyzing.
Data: adverbial suffix set A, object head set
O, complement suffix set C
input : word W = c
1
...c
n
and its POS P
output: head character h, adverbial character
a, complement character c, object
character o
begin
h = c = a = o = null;
if n = 4 and c
1
= c
3
and c
2
= c
4
then
return Verb formation of W
?
= c
1
c
3
;
else if n = 3 and c
2
= c
3
then
h = c
1
, c = c
2
;
else if n = 2 and c
1
= c
2
then
h = c
1
;
else if n = 1 then
h = c
1
;
else if c
n
? C and c
n?1
c
n
? C and
P=?VV? then
h = c
1
, c = c
n
/c
n?1
c
n
;
else if c
1
? A then
a = c
1
, h = c
2
...c
n
;
else if c
1
? O and P=?VV? then
h = c
1
, o = c
2
...c
n
;
end
? complement suffix set C: strings in C are
usually realized as complement in a verb-
complement type word: e.g. ?/out, ?/in,
?/finish,?/come,??/not.
Note that, to date there is no word formation
annotation corpus, so direct evaluation of our rule-
based algorithm is impossible. This paper makes
task-oriented evaluation which measures improve-
ments in SRL.
5.3 Using Word Formation Information to
improve Shallow Parsing
The majority of Chinese nouns are of type
attributive-head. This means that for most nouns
the last character provides very important infor-
mation indicating the head of the noun. For ex-
ample, the word formations of ???/peach?, ??
?/willow? and ????/boxtree? (three different
kinds of trees), are attributive-head and they have
the same head word ??/tree?. While for verbs, the
majority are of three types: verb-object, coordi-
nate and adverbial-head. For example, words ??
?/enlarge?, ???/make more drastic? and ??
?/accelerate? have the same head ??/add?. The
head morpheme is very useful in alleviating the
data sparseness in word level. However, for any
given word, it is very hard to accurately find the
head. In the shallow paring experiments, we use
a very simple rule to get a pseudo head character:
1) extracting the last word for a noun, and 2) ex-
tracting the first word for a verb. The new features
include:
Pattern 1: conjunction of pseudo head of w
i?1
and POS tags of w
i?1
and w
i
.
Pattern 2: conjunction of pseudo head of w
i
and
POS tags of w
i?1
and w
i
.
Pattern 3: conjunction of length/POS tags of
w
i?1
, w
i
, w
i+1
.
5.4 Using Verb Formation Information to
improve SRL
We use some new verb formation features to im-
prove our SRL system. The new features are listed
as follows. The first four are used in semantic
chunking task, and all are used in SRC task.
First/last characters.
Word length.
Conjunction of word length and first/last char-
acter.
Conjunction of token position and first/last
character.
The head string of a verb (e.g. ??? in ????).
The adverbial string of a verb (e.g. ??? in ??
??).
The complement string of a verb (e.g. ??? in
????).
The object string of a verb (e.g. ??? in ??
??).
6 Results and Discussion
6.1 Experimental Setting
6.1.1 Data
Experiments in previous work are mainly based on
CPB and CTB, but the experimental data prepar-
ing procedure does not seem consistent. For ex-
ample, the sum of each semantic role reported in
(Ding and Chang, 2008) is extremely smaller than
the corresponding occurrence statistics in origi-
nal data files in CPB. In this paper, we mod-
ify CoNLL-2005 shared task software
6
to pro-
cess CPB and CTB. In our experiments, we use
the CPB 1.0 and CTB 5.0. The data is divided
into three parts: files from chtb 081 to chtb 899
are used as training set; files from chtb 041 to
6
http://www.lsi.upc.edu/?srlconll/soft.html
1480
chtb 080 as development set; files from chtb 001
to chtb 040, and chtb 900 to chtb 931 as test set.
The data setting is the same as (Xue, 2008). The
results were evaluated for precision, recall and F-
measure numbers using the srl-eval.pl script pro-
vided by CoNLL-2005 shared task.
6.1.2 Classifier
For both syntactic and semantic chunking, we
used TinySVM along with YamCha
7
(Kudo and
Matsumoto, 2000; Kudo and Matsumoto, 2001).
In the chunking experiments, all SVM classifiers
were realized with a polynomial kernel of de-
gree 2. Pair-wise strategy is used to solve multi-
class classification problem. For the SRC ex-
periments, we use a linear SVM classifier, along
with One-Vs-All approach for multi-class classifi-
cation. SVM
lin
8
, a fast linear SVM solvers, is used
for supervised learning. l
2
-SVM-MFN (modified
finite newton) method is used to solve the opti-
mization problem (Keerthi and DeCoste, 2005).
6.2 Shallow Parsing Performance
P(%) R(%) F
?=1
Baseline 93.54 93.00 93.27
Ours 93.83 93.39 93.61
Table 2: Shallow parsing performance
Table 2 summarizes the overall shallow pars-
ing performance on test set. The first line shows
the performance of baseline. Comparing the best
system performance 94.13 F-measure of CoNLL
2000 shared task (Syntactic Chunking on English),
we can see Chinese shallow parsing has reached
a comparable result, tough the comparison of nu-
meric performance is not very fair, because of dif-
ferent languages, different chunk definition, dif-
ferent training data sizes, etc.. The second line
Ours shows the performance when new features
are added, from which we can see the word for-
mation based features can help shallow parsing.
Table 3 shows the detailed performance of noun
phrase (NP) and verb phrase (VP), which make up
most of phrase chunks in Chinese. Our new fea-
tures help NP more, whereas the effect of new fea-
tures for VP is not significant. That is in part be-
cause most VP chunk recognition error is caused
by long dependency, where word formation fea-
7
http://chasen.org/?taku/index.html.en
8
http://people.cs.uchicago.edu/?vikass/svmlin.html
P(%) R(%) F
?=1
NP(Baseline) 90.84 90.05 90.44
NP(Ours) 91.42 90.78 91.10
VP(Baseline) 94.44 94.55 94.50
VP(Ours) 94.65 94.74 94.69
Table 3: Performance of NP-chunk and VP-chunk
tures do not work. Take the sentences below for
example:
1. [
V P
??????]? (Therefore (we)
achieve victory.)
2. [
ADV P
??] [
V P
????] ?????
????? (Therefore the major changes
have not been met before.)
The contexts of the word ???/therefore? in the
two sentences are similar, where ???? is fol-
lowed by verbal components. In the second sen-
tence, the word ???/therefore? will be correctly
recognized as an adverbial phrase unless classifier
knows the following component is a clause. Un-
fortunately, word formation features cannot sup-
ply this kind of information.
6.3 SRL Performance
P(%) R(%) A(%) F
?=1
(Xue, 2008) 79.5 65.6 ? 71.9
M1? 79.02 69.12 ? 73.74
M1+ 79.25 69.61 ? 74.12
M2?/AI 80.34 75.11 ? 77.63
M2+/AI 80.01 75.15 ? 77.51
M2?/SRC ? ? 92.57 ?
M2+wf/SRC ? ? 93.25 ?
M2+/SRC ? ? 93.42 ?
M2?AI+SRC 76.48 71.50 ? 73.90
Table 4: Overall SRL performance of different
methods
Table 4 lists the overall SRL performance num-
bers on test set using different methods mentioned
earlier; these results are based on features com-
puted from gold standard segmentation and POS
tagging, but automatic recognized chunks, which
is parsed by our improved shallow parsing sys-
tem. For the AI and the whole SRL tasks, we
report the precision (P), recall (R) and the F
?=1
-
measure scores, and for the SRC task we report
the classification accuracy (A). The first line (Xue,
1481
2008) shows the SRL performance reported in
(Xue, 2008). To the authors? knowledge, this re-
sult is best SRL performance in the literature. Line
2 and 3 shows the performance of the one-stage
systems: 1) Line M1? is the performance without
word formation features; 2) Line M1+ is the per-
formance when verb formation features are added.
Line 4 to 8 shows the performance of the two-stage
systems: 1) Line M2?/AI and M2+/AI shows the
performance of AI phase without and within word
formation features respectively; 2) Line M2?/SRC
shows the SRC performance with trivial word-
based features (i.e. frame features and verb forma-
tion features are not used); 3) Line M2+wf/SRC is
the improved SRC performance when coarse verb
formation features are added; 4) Line M2+/SRC
is the SRC performance with all features; 5) Line
M2?AI+SRC shows the performance of SRL sys-
tem, which uses baseline features to identify argu-
ments, and use all features to classify arguments.
6.4 Discussion
The results summarized in Table 4 indicate that
according to the-state-of-the-art in Chinese pars-
ing, SRL systems based on shallow parsing out-
performs the ones based on full parsing. Com-
parison between one-stage strategy and two-stage
strategy indicates 1) that there is no significant dif-
ference in the F-measure; and 2) that two-stage
strategy method can achieve higher recall while
one-stage strategy method can achieve higher pre-
cision. Both the one-stage strategy and two-stage
strategy methods yield significant improvements
over the best reported SRL performance in the lit-
erature, especially in terms of recall performance.
Comparison SRL performance with full parses
and partial parses indicates that both models have
strong and weak points. The full parse based
method can implement high precision SRL sys-
tems, while the partial parse based methods can
implement high recall SRL systems. This is fur-
ther justification for combination strategies that
combine these independent SRL models.
Generally, Table 4 shows that verb formation
features can enhance Chinese SRL, especially for
fine-grained role classification. The effect of word
formation in formation in both shallow parsing
and SRL suggests that automatic word formation
analyzing is very important for Chinese language
processing. The rule-based algorithm is just a pre-
liminary study on this new topic, which requires
Num of words P (%) R (%) F
?=1
Length = 1 84.69% 75.48% 79.82
Length = 2 82.14% 74.21% 77.97
Length = 3 75.43% 63.98% 69.24
Length = 4 75.71% 65.63% 70.32
Length = 5 72.46% 64.38% 68.18
Length = 6 72.97% 66.21% 69.43
Length = 7 77.03% 67.65% 72.04
Length = 8 74.39% 57.28% 64.72
Length = 9 66.67% 51.16% 57.89
Length = 10 68.08% 58.28% 62.80
Length = 11+ 67.40% 57.71% 62.18
Table 5: SRL performance with arguments of dif-
ferent length
more research effort.
Though our SRC module does not use any pars-
ing information, our system can achieve 93.42%
accuracy, comparing the best gold parse based re-
sult 94.68% in the literature. This result suggests
that Chinese SRC system, even without parsing,
can reach a considerable good performance. The
main reason is that in Chinese, arguments with dif-
ferent semantic types have discriminative bound-
ary words, which can be extracted without pars-
ing. It is very clear that the main bottleneck for
Chinese SRL is to accurately identify arguments
rather than to disambiguate their detailed seman-
tic types.
Table 5 summarizes the labeling performance
for argument of different length. It is not surpris-
ing that arguments are more and more difficult to
rightly recognize as the increase of their length.
But the performance decline slows up when the
length of arguments is larger than 10. In other
words, some of the arguments that are composed
of many words can still be rightly identified. The
main reason for this point is that these arguments
usually have clear collocation words locating at ar-
gument boundaries. Take the sentences below for
example,
3. ??[A1 . . . . . .?] (including ... etc.)
the object of the verb ???/include? has a defi-
nite collocation word ??/etc.?, and therefore this
object is easy to be recognized as a A1.
7 Conclusion
In this paper, we discuss Chinese SRL on the ba-
sis of partial syntactic structure. Our systems ad-
vance the state-of-the-art in Chinese SRL. We first
1482
extend the study on Chinese shallow parsing and
implement a good shallow parser. On the ba-
sis of partial parses, SRL are formulated as a se-
quence labeling problem, performing IOB2 deci-
sions on the syntactic chunks of the sentence. We
exploit a wide variety of features based on words,
POS tags, and partial syntax. Additionally, we
discuss a language special problem, i.e. Chinese
word formation. Experimental results show that
coarse word formation information can help shal-
low parsing, especially for NP-chunk recognition.
A rule-based algorithm is put forward to automat-
ically acquire Chinese verb formation, which is
empirically shown to enhance SRL.
Acknowledgments
This work is supported by NSFC Project
60873156, 863 High Technology Project of
China 2006AA01Z144 and the Project of Toshiba
(China) R&D Center.
We would like to thank Weiwei Ding for his
good advice on this research.
We would also like to thank the anonymous re-
viewers for their helpful comments.
References
Xavier Carreras and Llu??s M`arquez. 2004. Introduc-
tion to the conll-2004 shared task: Semantic role
labeling. In Hwee Tou Ng and Ellen Riloff, edi-
tors, HLT-NAACL 2004 Workshop: Eighth Confer-
ence on Computational Natural Language Learn-
ing (CoNLL-2004), pages 89?97, Boston, Mas-
sachusetts, USA, May 6 - May 7. Association for
Computational Linguistics.
Wenliang Chen, Yujie Zhang, and Hitoshi Isahara.
2006. An empirical study of Chinese chunking.
In Proceedings of the COLING/ACL 2006 Main
Conference Poster Sessions, pages 97?104, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Yaodong Chen, Ting Wang, Huowang Chen, and Xis-
han Xu. 2008. Semantic role labeling of Chinese
using transductive svm and semantic heuristics. In
Proceedings of the Third International Joint Confer-
ence on Natural Language Processing: Volume-II.
Weiwei Ding and Baobao Chang. 2008. Improv-
ing Chinese semantic role classification with hier-
archical feature selection strategy. In Proceedings
of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 324?333, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.
Kadri Hacioglu and Wayne Ward. 2003. Target word
detection and semantic role chunking using support
vector machines. In NAACL ?03: Proceedings of
the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 25?27, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
S. Sathiya Keerthi and Dennis DeCoste. 2005. A mod-
ified finite newton method for fast solution of large
scale linear svms. J. Mach. Learn. Res., 6:341?361.
Taku Kudo and Yuji Matsumoto. 2000. Use of support
vector learning for chunk identification. In Proceed-
ings of the 2nd workshop on Learning language in
logic and the 4th conference on Computational natu-
ral language learning, pages 142?144, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Taku Kudo and Yuji Matsumoto. 2001. Chunking
with support vector machines. In NAACL ?01: Sec-
ond meeting of the North American Chapter of the
Association for Computational Linguistics on Lan-
guage technologies 2001, pages 1?8, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Sameer Pradhan, Kadri Hacioglu, Wayne Ward,
James H. Martin, and Daniel Jurafsky. 2005. Se-
mantic role chunking combining complementary
syntactic views. In Proceedings of the Ninth Confer-
ence on Computational Natural Language Learning
(CoNLL-2005), pages 217?220, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Sameer S. Pradhan, Wayne Ward, and James H. Mar-
tin. 2008. Towards robust semantic role labeling.
Comput. Linguist., 34(2):289?310.
L. A. Ramshaw and M. P. Marcus. 1995. Text chunk-
ing using transformation-based learning. In Pro-
ceedings of the 3rd ACL/SIGDAT Workshop on Very
Large Corpora, Cambridge, Massachusetts, USA,
pages 82?94.
Honglin Sun and Daniel Jurafsky. 2004. Shallow se-
mantc parsing of Chinese. In Daniel Marcu Su-
san Dumais and Salim Roukos, editors, HLT-NAACL
2004: Main Proceedings.
Mihai Surdeanu, Llu??s M`arquez, Xavier Carreras, and
Pere Comas. 2007. Combination strategies for se-
mantic role labeling. J. Artif. Intell. Res. (JAIR),
29:105?151.
Nianwen Xue and Martha Palmer. 2005. Automatic
semantic role labeling for Chinese verbs. In in Pro-
ceedings of the 19th International Joint Conference
on Artificial Intelligence, page 2005.
Nianwen Xue. 2008. Labeling chinese predicates
with semantic roles. Computational Linguistics,
34(2):225?255.
1483
Coling 2010: Poster Volume, pages 312?319,
Beijing, August 2010
Chinese Sentence-Level Sentiment Classification Based on Fuzzy Sets 
Guohong Fu and Xin Wang 
School of Computer Science and Technology, Heilongjiang University 
ghfu@hlju.edu.cn,wangxincs@hotmail.com 
 
Abstract 
This paper presents a fuzzy set theory 
based approach to Chinese sentence-level 
sentiment classification. Compared with 
traditional topic-based text classification 
techniques, the fuzzy set theory provides 
a straightforward way to model the 
intrinsic fuzziness between sentiment 
polarity classes. To approach fuzzy 
sentiment classification, we first propose 
a fine-to-coarse strategy to estimate 
sentence sentiment intensity. Then, we 
define three fuzzy sets to represent the 
respective sentiment polarity classes, 
namely positive, negative and neutral 
sentiments. Based on sentence sentiment 
intensities, we further build membership 
functions to indicate the degrees of an 
opinionated sentence in different fuzzy 
sets. Finally, we determine sentence-level 
polarity under maximum membership 
principle. We show that our approach can 
achieve promising performance on the 
test set for Chinese opinion analysis pilot 
task at NTCIR-6. 
1 Introduction 
With the explosive growth of the user-generated 
content on the web over the past years, opinion 
mining has been attracting an ever-increasing 
amount of attention from the natural language 
processing community. As a key issue in 
opinions mining, sentiment classification aims to 
classify opinionated documents or sentences as 
expressing positive, negative or neutral opinions, 
and plays a critical role in many opinion mining 
applications such as opinion summarization and 
opinion question answering. 
Although recent years have seen a great 
progress in sentiment analysis, it is still 
challenging to develop a practical sentiment 
classifier for open applications. This is largely 
due to the particularities of subjective languages. 
Unlike factual text, opinion text is usually 
expressed in a more subtle or arbitrary manner 
(Pang and Lee, 2008). Moreover, the sentiment 
orientation of a subjective expression is often 
context, domain and/or even order-dependent 
(Pang and Lee, 2008). This makes it hard to 
explore informative cues for sentiment 
classification. In particular, the final semantic 
orientation of an opinionated sentence often 
depends on the synthetic effects of all sentiment 
units (e.g. sentiment words or phrases) within it. 
Therefore, sentiment granularity selection and 
polarity aggregation are two important factors 
that affect sentiment classification performance. 
In addition, real opinion texts do not contain 
precisely-defined criteria of membership with 
respect to polarity classes. Most current work 
employs supervised machine learning techniques 
like naive Bayesian models and support vector 
machines to perform sentiment classification. 
While they have shown a good performance in 
traditional topic-based text classification tasks 
(Wang, 2006), their applications in sentiment 
classification are far from satisfactory (Pang et 
al., 2002). The reason might be the intrinsic 
fuzziness between sentiment polarity classes. 
Relative to the concept of objective topics like 
sports and politics in traditional text 
classification, the division between positive 
sentiments and negative sentiments is rather 
vague, which does not make clear boundary 
between their conceptual extensions. Such vague 
conceptual extension in sentiment polarity 
inevitably raises another challenge to sentiment 
classification.  
312
To address the above problems, in this paper 
we exploit fuzzy set theory to perform Chinese 
sentiment classification at sentence level. To 
approach this task, we first consider multiple 
sentiment granularities, including sentiment 
morphemes, sentiment words and sentiment 
phrases, and develop a fine-to-coarse strategy for 
computing sentence sentiment intensity. Then, 
we reformulate the three classes of sentiment 
orientations, namely positive, negative and 
neutral sentiments, as three fuzzy sets, 
respectively. To describe the membership of an 
opinion sentence in a special sentiment fuzzy set, 
we further construct membership functions based 
on sentence sentiment intensity, and thus 
determine the final semantic orientation of a 
given opinionated sentence under the principle of 
maximum membership. We show that the 
proposed approach can achieve a promising 
performance on the test set for Chinese opinion 
analysis pilot task at NTCIR-6. 
The remainder of the paper is organized as 
follows: Section 2 provides a brief review of the 
literature on sentiment classification. In Section 3, 
we describe the fine-to-coarse strategy for 
estimating sentiment intensity of opinionated 
sentences. Section 4 details how to apply fuzzy 
set theory in sentiment classification. Section 5 
reports our experimental results on NTCIR-6 
Chinese opinion data. Finally, section 6 
concludes our work and discusses some possible 
directions for future research. 
2 Related Work 
Sentiment classification has been extensively 
studied at different granularity levels. At lexical 
level, Andreevskaia and Bergler (2006) exploit 
an algorithm for extracting sentiment-bearing 
adjectives from the WordNet based on fuzzy 
logic. Following (Turney, 2002), Yuen et al 
(2004) investigate the association between 
polarity words and some strongly-polarized 
morphemes in Chinese, and present a method for 
inferring sentiment orientations of Chinese words. 
More recently, Ku et al (2009) consider eight 
morphological types that constitute Chinese 
opinion words, and develop a machine learning 
based classifier for Chinese word-level sentiment 
classification. They show that using word 
structural features can improve performance in 
word-level polarity classification. At phase level, 
Turney (2002) presents a technique for inferring 
the orientation and intensity of a phrase 
according to its PMI-IR statistical association 
with a set of strongly-polarized seed words. 
More recently, Wilson et al (2009) distinguish 
prior and contextual polarity, and thus describe a 
method to phrase-level sentiment analysis. At 
sentence level, Yu and Hatzivassiloglou (2003) 
propose to classify opinion sentences as positive 
or negative in terms of the main perspective 
being expressed in opinionated sentences. Kim 
and Hovy (2004) try to determine the final 
sentiment orientation of a given sentence by 
combining sentiment words within it. However, 
their system is prone to produce error sentiment 
classification because they only consider 
sentiment words near opinion holders and ignore 
some important words like adversative 
conjunctions. To compute sentiment intensity of 
opinionated sentences, in this study we propose a 
fine-to-coarse strategy, which take into account 
multiple granularity sentiments, from sentiment 
morphemes, sentiment words to sentiment 
phrases, and can thus handle both unknown 
lexical sentiments and contextual sentiments in 
sentiment classification. 
Most recent studies apply machine learning 
techniques to perform sentiment classification. 
Pang et al (2002) attempt three machine learning 
methods, namely naive Bayesian models, 
maximum entropy and support vector machines 
in sentiment classification. They conclude that 
the traditional machine learning methods do not 
perform well enough in sentiment analysis. 
Wilson et al (2009) further employ several 
machine learning algorithms to explore important 
features for contextual polarity identification. 
Different from most existing works that focus on 
traditional text classification techniques, in this 
study we attempt to resolve sentiment 
classification problems under the framework of 
fuzzy set theory. We choose fuzzy set theory 
because it provides a more straightforward way 
to represent the intrinsic fuzziness in sentiment. 
3 Sentence-Level Sentiment Intensity 
In this section, we describe a fine-to-coarse 
strategy to compute sentence-level sentiment 
intensity. After a brief discussion of the 
relationship between Chinese sentiment words 
and their component morphemes in Section 3.1, 
313
we extract a dictionary of sentiment morphemes 
from a sentiment lexicon, and compute their 
opinion scores using a modified chi-square 
technique. Then, we develop two rule-based 
strategies for word-level and phrase-level 
polarity identification, respectively. Finally, we 
calculate the final sentiment intensity of an 
opinionated sentence by summing the opinion 
score of all phrases within it. 
3.1 Sentiment words and morphemes 
As shown in Table 1, Chinese sentiment words 
can be categorized into static polar words and 
dynamic polar words. The polarity of a static 
polar word remains unchanged while a dynamic 
polar word may have different polarity in 
different contexts or domains.  
 
Type Example 
Positive 
?? ?beautiful?, ?? ?gentle? 
Negative 
?? ?beggary?, ???wrong? 
Static 
polar 
word Neutral 
??? ?acceptable? 
Dynamic polar words 
??big?, ??high? 
Table 1. Types of Chinese sentiment words 
 
For a static polar word, its polarity can be 
easily determined by referring to a sentiment 
lexicon. However, a precompiled dictionary 
cannot cover all sentiment words in real text, 
which raises an issue of predicting the polarity of 
out-of-vocabulary (OOV) sentiment words. To 
address this problem, we introduce sentiment 
morphemes. As Table 2 shows, here we consider 
two types of sentiment morphemes, namely 
positive morphemes and negative morphemes.  
 
Morpheme 
types 
Sentiment 
morphemes 
Sentiment words 
composed by sentiment 
morphemes 
??beauty? ?? ?exquisite? 
?? ?graceful? Positive 
morphemes 
??love? ?? ?like? 
?? ?adoration? 
??dirty? ?? ?pollution? 
?? ?corruption? Negative 
morphemes 
??fail? ?? ?corruption? 
?? ?undermine? 
Table 2. Types of Chinese sentiment morphemes 
 
In most cases, the polarity of a sentiment word 
is closely related to the semantic orientation of 
its component morphemes. In other words, word-
level polarity can often be determined by some 
key component sentiment morphemes within 
sentiment words. Take the following three 
sentiment words for example, ?? ?undermine?, 
?? ?corruption?, and ?? ?degenerate?. They 
share a same negative sentiment morpheme ? 
?fail?, and thus have the same negative 
orientation. Based on this observation, here we 
use morpheme-level polarity, rather than a 
sentiment lexicon, to predict the polarity of static 
sentiment words, particularly the OOV sentiment 
words in real text. 
As for dynamic sentiment words, traditional 
lexicon-based methods do not work for their real 
polarity changes with contexts. We will discuss 
the problem of dynamic polarity identification in 
Section 3.4.  
3.2 Identifying morpheme-level polarity 
Sentiment morphemes prove to be helpful in 
dealing with OOV polarity (Ku et al 2009). 
However, there is not a dictionary of sentiment 
morphemes available for sentiment analysis. To 
avoid this, we propose to automatically extract 
sentiment morphemes from some existing 
sentiment lexicon using chi-square (?2) technique. 
Formula (1) presents the ?2 of a morpheme m 
within a sentiment word of category c. 
))()()((
)(),(
2212211122211211
2
211222112
nnnnnnnn
nnnnn
cm
++++
????
=? (1) 
where m denotes a sentiment morpheme. c? 
{positive, negative} denotes the polarity of a 
certain sentiment word w that contain m. n is the 
total number of sentiment words in the lexicon. 
To calculate ?2, we need to construct a 2?2 
contingency table from the sentiment lexicon. As 
shown in Table 3, n11, n12, n21 and n22 denote the 
observed frequencies, respectively. 
 
Polar word w belong to c not belong to c 
contain m n11 n12 
not contain m n21 n22 
Table 3. The 2?2 contingency table for ?2 
 
The traditional ?2 statistics in Formula (1) can 
demonstrate the degree of contributions that a 
sentiment morpheme forms a special group of 
sentiment words. However, it cannot indicate 
whether the morpheme and the sentiment 
category are either positively- or anti-correlated. 
314
Such information is very important for inferring 
word-level polarity from sentiment morphemes. 
To compensate for this deficiency, we modify 
the traditional ?2 by injecting positive correlation 
and anti-correlation. Following (Wang, 2006), 
we introduce the following two rules in 
determining the sign of correlation between the 
sentiment category of words and their component 
sentiment morphemes. 
 If n11?n22-n12?n21>0, the morpheme and 
the sentiment category are positively 
correlated. In this case, a larger ?2 implies 
a higher likelihood that the morpheme 
belongs to the sentiment category. 
 If n11?n22-n12?n21<0, the morpheme and 
the sentiment category are anti-correlated. 
In this case, a larger ?2 value implies a 
higher likelihood that the morpheme does 
not belong to the sentiment category. 
Thus, we obtain a modified ?2 statistics as 
follows. 
))()()((
)()('
2212211122211211
2
21122211
21122211
2
nnnnnnnn
nnnnn
nnnnsign
++++
????
???=? (2) 
With the ?2' statistic, we can build a dictionary 
of sentiment morphemes from a source sentiment 
lexicon, and further determine the polarity of 
each sentiment morpheme using the two rules as 
shown in Definitions 1 and 2.  
Definition 1 (positive sentiment morphemes). 
If the ?2' statistic between a morpheme m and 
positive sentiment words is greater than zero, 
then m can be identified as positive. 
Definition 2 (negative sentiment morphemes). 
If the ?2' statistic between a morpheme m and 
positive sentiment words is smaller than zero, 
then m can be identified as is negative. 
Table 4 illustrates some extracted sentiment 
morphemes and their ?2' values. 
 
Types of morphemes Examples 
?
2
? 
??beautiful? 111.78 
??love? 65.88 Positive morphemes 
??happy? 40.72 
??die? -104.97 
??failed? -45.28 Negative morphemes 
??evil? -72.37 
Table 4. ?2? values of sentiment morphemes 
3.3 Identifying word-level polarity 
To determine word-level polarity, we employ 
morpheme-based rules. First of all, we normalize 
the ?2' value of each sentiment morpheme m into 
[-1, 1] by dividing it with the maximum absolute 
value. Such normalized chi-square, denoted by 
chi(m), is further viewed as the opinion score of 
the sentiment morpheme m. Thus, we can 
determine whether a word is a sentiment or not 
using a simple rule: if a word contains sentiment 
morphemes, it is a sentiment word. Finally, we 
can calculate the opinion score of a word w 
consisting of morphemes mi, (1?i?2)1, using the 
following two rules. 
 If m1 is a negation, e.g. ? ?not? and ? 
?non-?, then Score(w)= -1? chi(m2). 
 If m1 is not a negation morpheme, then 
Score(w)=Sign(chi(mi))?Max(|chi(mi)|). 
Where, Max(|chi(mi)|) is the largest 
absolute value among the opinion scores 
of morphemes within a word w, 
Sign(chi(mi)) denotes the positive or 
negative sign of m, namely ?-? and ?+?. 
3.4 Identifying phrase-level polarity 
To handle contextual polarity, we apply lexical 
polarity to determine the sentiment orientation of 
phrases within an opinionated sentence. Based on 
(Hatzivassiloglou and Wiebe, 2000) and (Turney, 
2002), we consider four types of structures (as 
shown in Table 5) during sentiment phrase 
extraction. To simplify the process, we reduce 
some function words like ? ??s? and ? ?and? 
from the input sentences before extraction in that 
they have no influence on sentiment orientation 
determination, and focus on extracting two 
consecutive words. Different from (Turney, 
2002), we consider phrases with negations as 
their initial words. In this way, we can handle the 
local negation that may reverse polarity. 
 
Phrase structures Examples 
Phases containing a 
adjective ???? ?high success rate? 
Phrases containing a 
verb ?????carefully discuss? 
Phrase containing an 
idiom 
?????? /?intent to 
deceive the public? 
Phrases beginning with 
a negation ?????no evidence? 
Table 5. Structures of opinion phrases 
                                               
1
 For words that contain three or more characters, 
particularly the four-character idioms, their polarity 
can be determined using the second rule. 
315
After opinion phrase extraction, we continue 
to calculate the opinion score of the extracted 
phrases using rules that are similar to (Hu and 
Liu, 2004). Before going to the details of phrase-
level opinion score calculation, we need to give 
some definitions in advance. 
Definition 3 (increased dynamic polar words). 
An increased dynamic polarity word can increase 
the orientation strength of sentiment words that it 
modifies without changing their polarity. For 
example, the word ?  ?serious? in the phrase 
??? ?serious pollution? and the word ? 
?high? in  the phrase ??? ?high benefit?. 
Definition 4 (decreased dynamic polar word). 
A decreased dynamic polarity word can decrease 
the orientation strength of sentiment words that it 
modifies and at the same time, reverse their 
polarity. For example, the word ??? ?little? in 
the phrase??? ?little pollution? and the word 
? ?low? in the phrase ??? ?low benefit?.  
To calculate phrase-level opinion scores, we 
construct a dictionary of dynamic polar words by 
extracting adjectives and verbs that contain a 
single-character seed morpheme like ? ?little? 
from the training corpus. Table 6 illustrates some 
increased and decreased dynamic polar words 
and their signs for changing polarity.  
 
Dynamic 
polar word Example Polarity sign 
Increased 
? ?high?  
?? ?increase? 
?? ?upgrade? 
Sign(increased)=1 
Decreased 
?? ?down? 
?? ?reduce?  
?? ?diminish? 
Sign(decreased)=-1 
Table 6. Dynamic words and their polarity sign 
 
With these dynamic polar words, we can then 
calculate the opinion score of a given opinion 
phrase pi that consists of two words (denoted by 
wj, j?{1,2}), using three rules as follows. 
 If w1 is a negation, e.g. ? ?no? and ?? 
?without?, then Score(pi) =  -1?Score(w2). 
 If pi involves a dynamic word wd, then  
Score(pi) = Sign(wd) ? Score(wj). Where, 
Sign(wd) denotes the polarity sign of 
dynamic words shown in Table 6.  
 Otherwise, Score(pi) = Sign(wj) ? Max 
(|Score(wj)|). Where Max(|Score(wordj)|) 
is the largest absolute value among the 
word-level opinion scores. 
4 Sentence Sentiment Classification 
4.1 Sentiment fuzzy sets and membership 
functions 
As we have mentioned above, sentiment polarity 
is vague with regard to its conceptual extension. 
There is not a clear boundary between the 
concepts of ?positive?, ?neutral? and ?negative?. 
To better handle such intrinsic fuzziness in 
sentiment polarity, we apply the fuzzy set theory 
by (Zadeh, 1965) to sentiment classification. To 
do so, we first redefine sentiment classes as three 
fuzzy sets, and then apply existing fuzzy 
distributions to construct membership functions 
for the three sentiment fuzzy sets.  
In our formulation, all the opinionated 
sentences under discussion are represented as a 
sorted set, denoted by X, in terms of their opinion 
scores. Thus, we have X = [Min(Opinion  
Score(Si)), ?, Max(Opinion Score(Si))]. Where, 
i={1,?,n}, Min(Opinion Score(Si)) and 
Max(Opinion Score(Si)) denotes the respective 
minimum and maximum opinion scores. The 
details of the fuzzy sets and their membership 
functions are given in Definitions 5, 6 and 7, 
respectively. 
Definition 5 (positive sentiment fuzzy set). if X 
is a collection of sentiment opinions (denoted by 
x), then a positive sentiment fuzzy set P~ in X can 
be defined as a set of ordered pairs, namely 
}|))(,{(~ ~ XxxxP P ?= ? , 
where )(~ xP?  denotes the membership function of 
x in P~  that maps X to the membership space M. 
We choose the rise semi-trapezoid distribution 
(Zimmermann, 2001) as the membership 
function of the positive sentiment fuzzy set, 
namely 
            
?
?
?
?
?
?
?
>
??
?
?
<
=
bx
bxa
ab
ax
ax
xP
,1
,
,0
)(~?              (3) 
where x denotes the opinion score of a sentence 
under discussion. The adjustable parameters a 
and b can be defined as a = Min(xi) + ?1(Max(xi) 
- Min(xi)/k) and b = Min(xi) + ?2(Max(xi) - 
Min(xi)/k), respectively. Max(xi) and Min(xi) 
316
denote the respective minimum and maximum 
values within X. ?1, ?2 and k are parameters. Here 
we set ?1= 5.2, ?2 = 5.4, and k = 10. 
Definition 6 (neutral sentiment fuzzy set). if X 
is a collection of sentiment opinions (denoted by 
x), then a neutral sentiment fuzzy set E~ in X can 
be defined as a set of ordered pairs, namely 
}|))(,{(~ ~ XxxxE E ?= ? , 
where )(~ xE?  denotes the membership function of 
x in E~  that maps X to the membership space M. 
As shown in Formula (4), we also select the 
semi-trapezoid distribution (Zimmermann, 2001) 
as the membership function of the neutral 
sentiment fuzzy set. 
         
?
?
?
?
?
?
?
?
?
?
?
?
<?
?
?
<?
<?
?
?
<
=
dx
dxc
cd
xd
cxb
bxa
ab
ax
ax
xE
,0
,
,1
,
,0
)(~?           (4) 
where x denotes the opinion score of a sentence 
under test. a, b, c and d are adjustable parameters 
that can be defined as a = Min(xi) + ?1(Max(xi)- 
Min(xi)/k), b=Min(xi) +m1(Max(xi) - Min(xi)/k), 
c = Min(xi) + m2(Max(xi) - Min(xi)/k) and d= 
Min(xi) + ?2(Max(xi) - Min(xi)/k), respectively. 
Max(xi) and Min(xi) denotes the respective 
minimum and maximum values within X. ?1, ?2, 
m1, m2  and k are parameters, Here  we set ?1 = 
5.2, ?2 = 5.5, m1 = 5.26, m2 = 5.33, and k = 10. 
Definition 7 (negative sentiment fuzzy set). if X 
is a collection of sentiment opinions (denoted by 
x), then a negative sentiment fuzzy set N~ in X 
can be defined as a set of ordered pairs, namely 
}|))(,{(~ ~ XxxxN N ?= ? , 
where )(~ xN?  denotes the membership function 
of x in N~  that maps X to membership space M. 
To represent the membership function of the 
negative sentiment fuzzy set, we employ the drop 
semi-trapezoid distribution (Zimmermann, 2001), 
namely 
           
?
?
?
?
?
?
?
>
??
?
?
<
=
bx
bxa
ab
xb
ax
xN
,0
,
,1
)(~?                (5) 
where x denotes the opinion score of a subjective 
sentence under discussion. The adjustable 
parameters a and b can be defined as a = Min(xi) 
+ ?1(Max(xi) - Min(xi)/k) and b = Min(xi) + 
?2(Max(xi) - Min(xi)/k), respectively. Max(xi) and 
Min(xi) refer to the corresponding minimum and 
maximum values in X. ?1, ?2, and k are 
parameters. Here we set ?1=5.2, ?2=5.3 and k=10. 
4.2 Determining sentence polarity 
Based on the above membership functions, we 
can now calculate the grade of membership of a 
given opinionated sentence in each sentiment 
fuzzy set, and thus determine its polarity under 
the principle of maximum membership. The 
basic idea is as follows: Let ?1, ?2, ?, ?n  be the 
fuzzy sets of X. ?x
0
?X, if 
~ ~
0 01
( ) max{ ( )}k ii nA x A x? ?=
 
then x0 is a membership of the fuzzy set ?k.  
5 Experiments and Results 
To assess the effectiveness of our approach, we 
implemented a classification system for Chinese 
sentence-level sentiment analysis. The system 
involves three main modules, namely a lexical 
analysis module, a subjectivity detection module 
and a sentiment classification module. To 
explore lexical cues for sentiment analysis, the 
morpheme-based chunking technique by (Fu, Kit 
and Webster, 2008) is employed in the lexical 
analysis module to carry out word segmentation 
and part-of-speech tagging tasks. To conform to 
the NTCIR-6 evaluation, a sentiment density-
based naive Bayesian classifier is also embedded 
in the second module to perform opinionated 
sentence detection. The details of this classifier 
can be seen in (Wang and Fu, 2010). To evaluate 
our system, we conducted experiments on the 
NTCIR-6 Chinese opinion data. This section 
reports the experimental results. 
5.1 Experimental setup 
In our experiments, we use the same test set for 
the Chinese opinion analysis tasks at NTCIR-6. 
The basic statistics is presented in Table 7. For 
comparison, the performance is reported in terms 
of the same metrics as used in NTCIR-6. They 
are F-score (F), recall (R), precision (P) under 
the LWK evaluation with lenient standard. 
317
 Item Number 
Topics 32 
Documents 843 
Sentences 11907 
Opinionated sentences under the 
lenient standard 
62% 
Table 7. Basic statistics of the test set for 
Chinese opinion tasks at NTCIR-6 
 
The basic sentiment lexicon used in our 
system contains a total of 17138 sentiment words, 
which is built from the CUHK and NTU 
sentiment lexica by excluding some derived 
opinion words like ??? ?not beautiful?. In 
addition, we also construct a list of 95 dynamic 
polarity words using the method described in 
Section 3.4. 
5.2 Experimental results 
The experiments are designed to examine the 
following two issues: 
(1) As we have discussed above, it is a key 
issue to select a proper granularity for sentiment 
classification. To determine the sentiment 
orientation of an opinionated sentence, we use a 
fine-to-coarse strategy that considers three types 
of sentiment units, namely sentiment morphemes, 
sentiment words and sentiment phrases. 
Therefore, the first intention of our experiments 
is to investigate how the use of different 
sentiment granularity affects the performance of 
Chinese sentence-level sentiment classification. 
To do this, we take the above three sentiment 
granularity as the basic units for computing 
sentence-level sentiment intensity, respectively, 
and examine the relevant sentiment classification 
results.  
(2) To the best of our knowledge, this study 
may be the first attempt to apply the fuzzy set 
theory in Chinese sentiment classification. 
Therefore, our second motivation is to examine 
whether it is feasible to apply fuzzy set theory in 
sentiment classification by comparing our system 
with other public systems for Chinese opinion 
analysis pilot task at NTCIR-6.  
Table 8 presents the experimental results with 
different sentiment granularities. It can be 
observed that the system with word as the basic 
sentiment units slightly performs better than the 
system based on sentiment morphemes. But a 
prominent improvement of performance can be 
obtained after using sentiment phrases. This 
reason may be that under the fine-to-coarse 
framework, sentiment classification based on 
sentiment phrases can handle both internal and 
external contextual sentiment information, and 
can thus result in performance improvement. 
 
Granularity P R F 
Morpheme 0.389 0.480 0.430 
Word 0.393 0.485 0.434 
Phrase 0.415 0.512 0.458 
Table 8. Performance on sentiment classification 
with different sentiment granularity 
 
Table 9 illustrates the comparison of our 
system with the best system for Chinese opinion 
analysis pilot task at NTCIR-6, namely the 
CUHK system (Seki et al, 2007; Xu, Wong and 
Xia, 2007). As can be seen from Table 9, our 
system outperforms the CUHK system by 5 
percents with regard to F-score, showing the 
feasibility of using fuzzy set theory in sentiment 
classification. 
 
System P R F 
CUHK 0.522 0.331 0.405 
Our system 0.415 0.512 0.458 
Table 9. Comparison of our system with the best 
system at NTCIR-6 under lenient standard 
6 Conclusion and Future Work 
In this paper, we have described a fuzzy set 
theory based framework for Chinese sentence-
level sentiment classification. To handle 
unknown polarity and contextual polarity as well, 
we consider three types of sentiment 
granularities, namely sentiment morphemes, 
words and phrases in calculating sentiment 
intensity of opinionated sentenced. Furthermore, 
we define three fuzzy sets to represent polarity 
classes and construct the relevant membership 
functions, respectively. Compared with most 
existing work, the proposed approach provides a 
straightforward way to model the vagueness in 
conceptual division of sentiment polarity. The 
experimental results show that our system 
outperforms the best system for Chinese opinion 
analysis pilot task at NTCIR-6 under the lenient 
evaluation standard.  
The encouraging results of the fuzzy set-based 
approach suggest several possibilities for future 
318
research. Our experiments demonstrate that the 
incorporation of multiple granularity polarity has 
a positive effect on sentiment classification 
performance. To further enhance our system, in 
future we intend to exploit more tailored 
techniques for aggregating multiple-granularity 
polarity within opinionated sentences. Moreover, 
we plan to optimize the proposed membership 
functions for fuzzy sentiment classification. 
Acknowledgments 
The authors would like to thank Chinese 
University of Hong Kong, National Taiwan 
University and NTCIR for their data. This study 
was supported by National Natural Science 
Foundation of China under Grant No.60973081, 
the Returned Scholar Foundation of Educational 
Department of Heilongjiang Province under 
Grant No.1154hz26, and Harbin Innovative 
Foundation for Returnees under Grant 
No.2009RFLXG007, respectively. 
References 
Alina Andreevskaia, and Sabine Bergler. 2006. 
Mining WordNet for a fuzzy sentiment: Sentiment 
tag extraction from WordNet glosses. In 
Proceedings of EACL-06, pages 209-216. 
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A 
holistic lexicon-based approach to opinion mining. 
In Proceedings of the International Conference on 
Web Search and Web Data Mining, pages 231-240. 
Guohong Fu, Chunyu Kit, and Jonathan J. Webster. 
2008. Chinese word segmentation as morpheme-
based lexical chunking. Information Sciences, 
7(1):2282?2296. 
Vasileios Hatzivassiloglou, and Janyce Wiebe. 2000. 
Effects of adjective orientation and gradability on 
sentence subjectivity. In Proceedings of ACL-00, 
pages 299-305. 
Soo-Min Kim, and Eduard Hovy. 2004. Determining 
the sentiment of opinions. In Proceedings of 
COLING-04, pages 1267-1373. 
Lun-Wei Ku, Ting-Hao Huang, and Hsin-Hsi Chen. 
2009. Using morphological and syntactic structures 
for Chinese opinion. In Proceedings of EMNLP-09, 
pages 1260-1269. 
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.  
2002. Thumps up? Sentiment classification using 
machine learning techniques. In Proceedings of 
EMNLP-02, pages 79-86. 
Bo Pang, and Lillian Lee. 2008. Opinion mining and 
sentiment analysis. Foundations and Trends in 
Information Retrieval, 2(1-2): 1-135. 
Yohei Seki, David Kirk Evans, Lun-Wei Ku, Hsin-
Hsi Chen, Noriko Kando, and Chin-Yew Lin. 2007. 
Overview of opinion analysis pilot task at NTCIR-
6. In Proceedings of NTCIR-6 Workshop Meeting, 
pages 265-278. 
Peter D. Turney. 2002. Thumbs up or thumbs down? 
Semantic orientation applied to unsupervised 
classification of reviews. In Proceedings of ACL-
03, pages 417-424. 
Xin Wang, and Guohong Fu. 2010. Chinese 
subjectivity detection using a sentiment density-
based na?ve Bayesian classifier. In Proceedings of 
IWWIP-10.  
Yu Wang. 2006. Research on text categorization 
based on decision tree and K-nearest neighbors. 
PhD thesis, Tianjin University. 
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 
2009. Recognizing contextual polarity: An 
exploration of features for phrase-level sentiment 
analysis. Computational Linguistics, 35(3):99-433. 
Ruifeng Xu,  Kam-Fai Wong, and Yunqing Xia. 2007. 
Opinmine: Opinion mining system by CUHK for 
NTCIR-06 Pilot Task. In Proceedings of NTCIR-6 
Workshop Meeting, pages 350-357. 
Hong Yu, and Vasileios Hatzivassiloglou. 2003. 
Towards answering opinion questions: Separating 
facts from opinions and identifying the polarity of 
opinion sentences. In Proceedings of EMNLP-03, 
pages 129-136. 
Raymond W.M. Yuen, Terence Y.W. Chan, Tom B.Y. 
Lai, O.Y. Kwong, and Benjamin K.Y. T'sou. 2004. 
Morpheme-based Derivation of Bipolar Semantic 
Orientation of Chinese Words. In Proceedings of 
COLING-04, pages 1008-1014. 
Lotfi A. Zadeh. 1965. Fuzzy sets. Information and 
Control, 8:338-353. 
Hans-J?rgen Zimmermann. 2001. Fuzzy set theory 
and its applications. Kluwer Academic Publishers, 
Norwell, MA, USA. 
319
