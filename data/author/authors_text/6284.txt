Informed Parsing for Coordination 
with Combinatory Categorial Grammar 
Jong C. Park  Hyung Joon  Cho 
parkOc s. ka is t ,  ac .  k r  hj cho@nlp, ka is t ,  ac .  k r  
(~,oI\[li)llt;er Science Division and 
Advanced Intbrmat ion Technology Research Center 
Korea Advanced Inst i tute of Science and Teclmology 
373-1 ( \ ]usung-dong, Yusong-gu, Da(don 305-701, K()IREA 
Abst rac t  
Coordination in natural language hamlmrs e f  
tieient parsing, especially due to the mul- 
tiple and mostly unintended candidate con- 
juncts/disjmmts in a given sentence that shows 
structural aml)iguity. The l)rol)lem gets more 
serious in a coml)inatory categorial grammar 
framework, which is well known \[or its coral)e- 
tent treatment; of coordination, as tlm tlexil)ility 
of syntactic analysis ofl;en strikes back as Sl)U- 
rious amt)iguity. We t)rot)ose to address these 
ambiguities with predicate argument structures 
and semantic ('o-occurrence similarity intbrma- 
tion, and present encouraging results. 
1 In t roduct ion  
Sentences with eoor(lination (:ontaill multil)le 
phrases of like syntacti(; tyl)e. When the given 
sentence shows structm'al ambig'lfit;y, tiler(; may 
1)e multii)le pairs of candidates tbr l)ossil)le con- 
juncts/disjuncts, usually a single pair of which 
is identified as intended by human language un- 
derstanders, l?arsing for coordination should 
thus find the exact syntactic t)oundaries of these 
"intended" conjuncts/(lisjuncts. Previous work 
elnployed a 1)reproccssing module for parsing to 
work on a constrained range of the candidate 
conjmwts/disjuncts (Kurohashi & Nagao, 1994; 
Yang, 1995; Okmnura & Muraki, 1994). 
Coml)inatory categorial grammars (Steed- 
man, 1990; 2000) arc known to explain a wide 
range of syntactic phenonmna, such as coor- 
dination, extraction and long distance depen- 
dency, without employing the no~ions of move- 
ment and empty categories. While CCGs oiler 
explanations ibr various natural language phe- 
nomena with limited combinatory rules such ms 
type raising and flmction composition, these are 
also well known to increase the complexity of 
parsing, giving rise to quite a few irrelevant syn- 
tactic analyses as well as relewmt ones~ a phe- 
nomenon often called as spm'ious ambiguity. 
In this paper, we propose to address  the 
two types of ambiguity with predicate argument 
structures and semantic co-occurrence similar- 
ity intbrmation. 1 For a more concrete discus- 
sion, we focus in this paper on coordination in 
Korean. First, related work is reviewed in {i2. 
The two types of anfl)iguity arc then discussed 
in !}3. We also examine the characteristics of 
coordination in a (:ortms in ?4. In ?5, we show 
ore: proposal to enhance t)arsing efficiency, with 
encouraging ext)erimental results. 
2 Re la ted  Work  
2.1 Conjunct I dent i f i ca t ion  
First, we review three of the techniques that at- 
tempt to narrow down the candidate con.juncts. 
2.1.1 Complex Information 
At)t)roaches that use conlplex information are 
baaed on the assmnl)tion that there are vari- 
ous clues for morphological and semantic sire- 
ilarity between the pair of matching con- 
juncts/disjuncts. The usual measure tbr such 
similarity includes the part-of-st)eech (pos) tea- 
ture intbrmation. The proposal by Agarwal and 
Boggess (1992) for English coordination uti- 
lizes a semi-parser ibr the assignment of perti- 
nent semantic and morphologicM inibrmation to 
each lexical item in a given sentence. The pro- 
cedure for the conjunct/disjunct identification 
with this infbrmation is sunnnarized below. 
1. Keel) pushing the lexical items in a given sentence 
into the stack until a coordination item such as and, 
or, but, etc, is encountered. 
1This work was supported by the Korea Science and 
Engineering Foundation (KOSEF) through AITrc. The 
second author is now with SK Telctcch in Korea. 
593 
2. With the coordination item, treat he immediately 
following phrase as the post-conjunct/disjuuct. 
3. Pop the lexical items fi'om the stack one by one, 
comparing their morphological nd/or semantic 
tbatures with those of the post-conjunet/disjunct. 
The reported precision is 81%, but the method 
identifies only tile starting positions of the con- 
juncts/disjuncts. 
The method proposed by Okumura and Mu- 
ram (1994) for English coordination looks into 
the symmetric patterns of conjuncts/disjuncts. 
These symmetric patterns are classified into 
tbur categories: phrasal/clausal patterns, lexi- 
cal patterns, morphological patterns, and com- 
plex patterns. The first; three patterns are de- 
fined in terms of the respective features in lex- 
ical items. The best match among all the pos- 
sible word sequences with these features before 
and after the coordination item is passed over 
to the parser. The reported precision is 75%. 
This method assigns various weights to the fea- 
tures tbr the measure of the symmetric pat- 
terns. It is not (:lear if the weight assigmnent 
method is principled and if it can also address 
conjuncts/disjuncts with ellipsis. 
2.1.2 Co-Occurrence Information 
Yang (1995) utilized co-occurrence information 
tbr the resolution of structural ambiguity in Ko- 
rean noun phrase coordination. The method 
looks ut) the related pair of nouns and verbs 
ti'om a large corpus and uses the statistics on 
the case inibnnation of the nouns with respect 
to the given verb for the similarity informa- 
tion among nouns. The co-occurrence similarity 
DSim(rq,  n2) between the nouns n, and n2 is 
defined as tbllows, which incorporates tile pre- 
diction that the similarity of the two nouns is 
higher when they are more frequently used with 
the same verb of the same syntactic ategory. 
2. n2)l 
DSim(n l ,u2)  - +  .calVg(n2)l 
where  2 
? G =- {subj, obj, loca, last, modi} 
? Vg(n) =- {v\[v is a verb such that fg(n,v) > 1} 
? I~( ,~) l  = E~v.(,,)f.(~, v) 
2fe(n, v) is the nunlber of times that noun n of type 
g occurs with verb v in tlm stone sentence in a corpus. 
? IC~,(,~,,,~=)l- Emin{f~(ni,v), fg(n2,v)} 
veCVg (at,n2) 
This method makes it; possible to resolve the 
syntactic ambiguity due to coordination i  Ko- 
rean as illustrated in (1) and (2). a DSim is 
used to predict correctly that 'suthayk' (stack) 
is in coordination with 'khyu' (queue) and not 
with 'yey' (example). Likewise, 'kyesan' (com- 
putation) and 'thmnsayk' (search) are correctly 
identified to be in coordination with each other. 
(1) suthayk-~-?\] khyu-uy ey 
stack-co queue-poss exmnplc 
exaInple(s) of stack(s) and queue(s) 
DSim(suttr,~yk,khyu) = 0.319 
DSim(suthayk,yey) = 0.053 
(2) haysing hamswu-uy kyeysan- \ [~ pekheys-uy 
thamsayk-ey soyotoynun sikan 
hashing fimction-poss comlmtation-co bucket-poss 
search-loc spending time 
the time spent for the comtmtation of the hashing 
thnction and the sem-ch for the bucket 
DSim(kyeysan,pekheys) = 0.024 
DSim(kyeysan,thamsayk) = 0.303 
DSim(kyeysan,sikan) = 0.067 
In addition to the fact that the method may sn f  
fer from data sparseness, it is also not directly 
~pplicable when nouns are polysemous or when 
the conjunct/disjunct nouns have weak seman- 
tic similarity (cf. (3)). 
(3) i notu-nun teyitha yoso- \ [~ lisutu-uy tamn wenso- 
hfl cisiha-nun phointhe-lul phohamha-n-ta 
this node-nora data element-co list-poss next 
element-ace indieate-un pointer-ace ontain-pres- 
decl 
'this node contains the data element and the pointer 
that indicates the next element in the list' 
Its reported precision is 85.8%, and the recall 
95.9%. We note that this co-occurrence simi- 
larity information is useful when large-scale lin- 
guistic knowledge bases such as WordNet are 
not available for the language in question. 
2.1.3 Part -Of -Speech Patterns 
The method with pos patterns (Park, 1998) 
extracts sentences with coordination from a 
pos-tagged corpus, trains the system with 
the pos patterns of the left- and right- 
conjuncts/disjuncts, and resolves the ambiguity 
with trained pos patterns (cf. (4)). 
3Coordination items are shown in a box. We use the 
Yale notation for transcribing Korean alphabets. 
594 
(4) ha-nun \[kemjeng ppang- \ [~ huyn plmngl-ul :,tel:- 
un salam-ul poass-ta 
I-nora \[black bread-co white bread\]-acc eat-un 
person-acc see-past-decl 
~I saw the person who ate black bread and white 
bread' 
The longest pattern is selected when there are 
multiple candidate pos-patterns. The reported 
precision is 71.6%. When there is structural 
anfl)iguity ms shown in (5) below, however, it 
is difficult to identi\[y the right conjunct if the 
system considers only pos inibrmation, where 
the longest match is 'mangko-lul swuipha-mm 
nala' (the nation that imports mangos), not the 
intended hnangko' (mango). 
(5) phainayphul-~ mangko-lul swuipha-nun ala 
pineaplfle-eo mango-ace import-un ation 
'the nation that iml)ort;s pineaptfles or mangos'  
2.2 Combinatory  Categor ia l  Grammar  
for Korean  
Examples of coordination in Korean are. shown 
below. 
(6) \[chelswu-nul: uysa-ka\]\[7\] yenghi-nun sensayngniin-i\] 
toy-ess-ta 
\[chelswu-to I, doetor-comp\], \[yenghi-top teach-comp\] 
become-past-decl 
~Chelswu becmne a doctor, and Yenghi a teacher' 
(7) \[kochwukapsi olu-myen kochwu-lul\]\[~\] \[tway- 
cikokikapsi oht-myen twaycikoki-hfl\] swuipha-n-ta. 
\[peplmr-price-nom rise-if pepimr-acc\], [pork-price- 
n01n rise.-if pork-ace\] import-pres-decl 
'(The govermnent) imports 1)epl)ers if the price for 
pel)l)ers rises, and i)ork if the 1)rice for pork rises' 
In CCGs, tyl)e raising and function comt)o- 
sition ruh's are typically utilized to corn(; up 
with single categories for those ti'agments above 
in square t)rackets, often called qmn-standard' 
constituents. ~D~ble 1 shows the reduction rules 
proposed tbr Korean (Cho, 2000; Cho and Park, 
2000). Figure 1 shows a sample syntactic and 
semantic deriw, tion of part of (6). Space pre- 
cludes further explanation of the tbrmalism. 
3 Two Types  of Ambigu i ty  
3.1 Spurious Ambiguity 
CCGs provide two syntactic derivations tbr 
the semantically unaml)iguous sentence (8), as 
shown in (9) and (10). 
(8) chelswu-l:a sakwa-hfl mel:-ess-ta 
Chelswu-nom at)pie-ace eat-past-decl 
1. \[\[chelswu-nun sakwa-lul\] mek\]-ko 
\[\[yenghi-nun ttalki-hfl\] mekl-nunta 
2. \[\[chelswu-nun sakwa-lul\] illekl-ko 
\[yenghi-nun \[ttalki-hd mek\]l-nunta 
a. \[a,elswu-::.,, \[sakwa-ha ,1:ek\]l-ko 
\[\[yenghi-nun ttalki-hfl\] mekl-nu,:ta 
4. \[chelswu-mm \[sakwa-lul mek\]\]-ko 
\[yenghi-nun \[ttalki-lul mekll-nunta 
Table 2: Example Spurious Ambiguity 
'Chelswu ate an apl)le/at)l)les' 
(9) \[\[chelswu-ka sakwa-lul\] mek-e.ss-ta\] 
(10) \[chelswu-ka \[sakwa-M mek-ess-ta\]\] 
These distinct syntactic derivations make it 1)os- 
sible tbr a CCG to correctly analyze sentences 
with coordination, as shown in (11) and (12). 
(11) \[\[chelswu-ka sakw>lul\]\[~ \[ycnghi-ka ttalki-hfl\]\] 
mek-ess-ta\] 
'Chelswu ate al)l)les and Yenghi strawberries' 
(12) \[chelswu-ka \[\[son-ul ssis\]-~ \[sakwa-hfl mek-ess\]- 
ta\]\] 
'Chelswu washed his hands and ate apples' 
Spurious anfl)iguity retbrs to the phellomenon of
this kind in which there are multiple, syntactic 
derivations, as in (9) and (10), tot' a ti'agment 
that is semantically unmnbiguous. 4 While de- 
scriptively justifiable, it; nevertheless results in 
a repeated comput.at:ion of the stone fragments 
that are semanticMly indistinct, adversely af- 
fecting parsing efIiciency. This prot)lem gets 
more serious with coordination (of. (13)). 
(13) chelswu-mm sakwa-h:l rock-Jim\] yenghi-nun ttalld- 
hfl mek-nun-ta 
'Chelswu eats apples and Yenghi strawberries' 
Table 2 shows four syntactic derivations tbr 
(13), all with identical semantics. 
3.2 Struetural Ambiguity 
The spurious ambiguity as discussed above does 
not give rise to wrong syntactic analyses, but 
the structural ambiguity may, as shown in (14). 
(14) cengchi-uy canglay-F~ \] nongmintul-uy 
saynghwalsang-uy mwuncay-wa-nun keli-ka 
mel-ta 
4Note that there are arguments  that some of these 
syntactic derivations are associated with distinct prag- 
matic, fimctions, so that the ambiguity might not be en- 
tirely 'slmrious' (Prevost, 1995). 
595 
Reduction Rule Rule Name Rule Symbol 
X/Y  Y ~ X Forward Al)plication > 
Y X \Y  -+ X Backward Application < 
X conj X -+ X Coordination < </~'~ >
X/Y  Y /Z  --+ X /Z  Forward Composition > B 
Y\Z  X \Y  -~ X \Z  Backward Composition </3  
X/Y  Y \Z  ~ X \Z  Forward Crossed Composition > Bz 
X --+ T / (T \X)  Forward Type Raising > T 
X -+ T \ (T /X)  Backward Type Raising < T 
Table 1: Reduction Rules in a CCG tbr Korean 
chelswu - nun 
: A I . I  ehe lswu 
uysa - ka 
(S,,\NP,,)/(S~\NP},\NP~) 
: Xf.f doctor 
> B 
S~/(S,,\NP,,\NP~) , 
: Af.f doctor chelswu 
, yenghi - nun sensayngnim - i
conj S~/(S,~\NP,, I (S,,\NP,,)/(S,~\NP@NP~) 
: and'(X, Y) : Af.f yenghi : Af.f teacher 
> B 
S,,/(S.\Nn~\NP~) 
: Af.f teaeh, er yenghi <?> 
, , : Af.and' (f doctor chelswu , f teacher yenghi )
Figure 1: Sample CCG Derivation 
politics-poss fllture-co farmers-poss life-poss 
problem-wa-top distance-nora far-deel 
'(It is) far from the problems of the fllt, ure of politics 
or the lives of farmers' 
Table 3 shows six of the syntactic derivations. 
While the semantics makes it clear that only 
the derivation 2 is the intended one, it is im- 
possible for a parser with only syntactic infor- 
mation to tell the difference. Notice that this 
problem is not mfique to a CCG-based parser. 
While the general solution would obviously re- 
quire not only semantic infbrmation but, also 
pragmatic and discourse information, we exam- 
ine approaches that take into account only se- 
mantic information in this paper. 
4 Coordinat ion in Corpus 
In an attempt o assess the coordination phe- 
nolnenon in ~t realistic manner, we examine a 
pos-tagged corpus available at KAIST. The cor- 
pus contains newspaper articles (40,428 eojeol), 
essays (41,666 eojeol), textbooks (50,208 eo- 
jeol), technical documents (2,729 eojeol), novels 
(40,498 eojeol), with the total of 175,524 eojeol 
and 17,123 sentences. ~ Table 4 shows the types 
5Eojeol is a unit in Korean that roughly corresponds 
to space-delimited words in English. Each eojeol con- 
tains both the stem and its morphological endings. 
1. \[cengchi-uy canglay\]-na \[nongmintul\]-uy 
saynghwalsang-uy mwuncey 
2. \[cengchi-uy canglay\]-lm \[nongmintul-uy 
saynghwalsang\]-uy mwuncey 
3. \[eengehi-uy canglay\]-na \[nongmintul-uy 
saynghwalsang-uy mwuneey\] 
4. cengchi-uy \[canglay\]-na \[nongmintul\]-uy 
saynghwalsang-uy mwuncey 
5. cengchi-uy \[eanglay\]-na \[ ongmintul-uy 
saynghwalsang\]-uy mwuncey 
6. cengchi-uy \[canglay\]-na \[ ongmintul-uy 
s~tynghwalsmlg-uy mwuneey\] 
Table 3: Example Structural Ambiguity 
and frequencies of sentences containing coordi- 
nation in this corpus. We used PERL scripts 
to narrow down the sentences meeting certain 
basic conditions for coordination and manually 
identified sentences with coordination among 
those chosen. G Table 4 indicates that coordi- 
nation is used quite often in Korean. 
5 Parsing for Coordinat ion 
In this section, we present echniques of dealing 
with coordination for efficient: parsing. 
6A pos-tagged corpus does not, give sufficient infor- 
mation for the fully automatic dentification ofsentences 
with coordination, since we also need to take the senten- 
tial semantics into account. 
596 
Coordination Item I1 
ending 
l) OStl)osition 
adverb 
C() l l l l l l{~ 
Articles 
728 (21.4%) 
671 (19.7%) 
91 (2.7%) 
154 (4.5%) 
Essays 
1092 (33.7%) 
352 (10.7%) 
22 (0.68%) 
126 (3.9%) 
Textbooks 
1101 (20.1%) 
812 (14.8%) 
58 (1.1%) 
216 (3.9%) 
Documents 
46 (40%) 
23 (2o%) 
6 (5.2%) 
21 (18.3%) 
Novels 
2174 (44.5%) 
320 (6.6%) 
17 (0.35%) 
43 (0.88%) 
Total 
5142 (30.o%) 
2178 (12.7%) 
194 (1%) 
605 (3.5%) 
Total Sentences \]\[ 3403 3239 5485 115 4881 17123 (100%) 
Tal)le 4: Characterist ics of Coordinat ion in Korean 
5.1 P red icate  Argument  S t ructure  
We used the CKY algor i thm to imt)lement a 
CCG parser. As discussed, the l)resence of Slm- 
rious ambiguity in a given sentence ibrces re- 
t)eated syntact ic analyses for fragments with 
identical semantics. This can be avoided if we 
use the same cell to record the synta(:tie anal- 
yses with the same semantics. 7 CCG makes 
this 1)ossit)le, as both the syntact ic and semantic 
derivations are constructed in tmldeln. Table 5 
shows part  of the t)arsing table for (13). The tbl- 
lowing shows the relevant syntact ic categories. 
? chelswu-mm, yenghi-nun : .s/(.~\npu) 
? sakwa-lul, ttalki-hfl : (s/np,,)/(.~\npu\np,) 
? reek:  s\np,-~\np,~ 
? ko : conj 
The cells (C1,R3) and (C5,R3) each contain 
two syntact ic analyses with the same semantics, 
resulting in tbur syntact ic analyses with the 
sanle semantics in the cell (CI ,R7).  We can 
1)revent su(:h multil)le analyses 1)y not writ ing 
into the cell a synta(:tic analysis with the same 
recorded semantics. We thus have one syntact ic 
analysis for each of the cells (C1,R3), (C5,R3) 
and (C1,R7). 1,br longer sentences, we ext)e('t a 
significant redu('t ion in the number  of derived 
syntact ic analyses, as also part ly  verilied by 
our experiments.  
5.2 Co-Occur rence  S imi lar i ty  
5.2.1 The  .A lgor i thm 
Among the pairs of head nouns of can- 
didal;e conjuncts/d is juncts,  al)out 88.1% 
pairs are identified as semantical ly related 
in our corpus. It is thus reasonable to 
consider only those candidates with some 
semantic relation. We use the following mod- 
itication of Yang's (1995) original proposal. 
rCL Ka,rttmmn, 1989; Eisner, 1996; Komagata, 1999 
1 Whenever the coordination reduction rule is in- 
voked, check the syntactic ategories of the can- 
didate conjuncts. 
2 If they are nouns or noun phrases, skip to the next 
step. Otherwise write them to n cell. 
3 Locate the head nouns in the candidate conjuncts. 
4 Comlmte the co-occurrence similarity of the head 
l tO l l l lS .  
5 If the coordinatioi~ reduction rule has already 
been applied to the he.ad noun of the left candidate 
conjunct~ compare the co-occurrence siinilarity of 
the recorded and the new. If the co-occurrence 
similarity of the newly identified candidate con- 
j,mcts is stronger, write them to a cell, and delete 
the existing candidates in the cell. Otherwise, dis- 
card the new and retain the old. 
6 U1)datc the list of conjuncts whenever there is a 
newly recorded candidate conjunct. 
For the co-occurrence similarity intbrmation 
between llOilllS, we used another  KA IST  cor- 
tins that  is lna,mMly tree-tagged (Lee, 1998). It 
contains al)out 31,000 sentences with 352,730 
eojeol. The average sentence length is 11.35 
words. The domains include newst)at)er edito- 
rials, economy, religion, science fiction, exl)edi- 
tion, novels, and history. We have considered 
only nominative, accusative, adverbial,  comple- 
ment, and adnominal  cases in relation to the 
verbs tbr the extract ion of co-occm:rence simi- 
larity intbrmation, which is then recorded into a 
dict ionary and is looked ll t3 \[)y the parser when 
it deals with coordination. 
5.2.2 Thesaurus  
The use of co-occurrence similarity information 
as in (Yang, 1995) suffers ti'om data sparseness, 
especially since we have a relatively small corpus 
with fairly unrestr icted omains, s For instance, 
(15) and (16) below show examples of wrong 
co-occurrence similarity intbrmation. 
(15) kimchi-wa 1)al)(0)-man CiV l l - I l l l n  kes(0.002252)-ita 
kimchee-co steamed rice-only give-top thing-decl. 
'(They) served only kimchee and steamed rice' 
kimchi: 3 verbs, pal): 9 verbs, kes: 2083 verbs 
sin contrast, Yang used a corpus with one inillion 
eojeol and restricted to a comImter science domain. 
597 
I~7 
R3 
R2 
11,1 
II 
s 
and'mekta'sakwa'chelswu' 
mekta'ttMki'yenghi' 
\[\[chelswu-ka sakwa-lul\] mek\]ko 
\[\[yenghl-ka tt lki-lul\] reek\] 
\[\[chelswu-ka sakwa-lul\] mek\]ko 
\[yenghi-ka \[ttMki-lul reek\]\] 
\[chelswu-ka \[sakwa-luI mek\]\]ko 
\[\[yenghi-ka tt lki-lul\] reek\] 
\[chelswu-ka \[sakwa-lul mek\]\]ko 
\[yenghl-ka \[ttMki-lul reek\]\] 
(ez,aa)+(es,na) 
8 
mekta'sakw~t'chelswu' 
\[\[chelswu-ka sakwa-lul\]mek\], 
\[chelswu-ktt \[sakwa-lul reek\]\] 
(C1,R2)+(ca,R1), 
((Jl,II,1)+(C2,R2) 
s\npn 
hy.mckta'sakwa'y 
\[sakwa-lul rock\] 
(C2,Ftl)+(Ca,R1) 
)~ f.sakwa'chelswu' 
\[chelswu-ka s kwa-hll\] 
(O,,lU)+(c2,ttl) 
chelswu-ka sakwa-lul 
C1 C2 
lnek ko 
I ca leV I  0,5 
s\npn 
.ky.mekta%talki'y 
\[ttalki-lul rock\] 
(06,m)+(07,i~ 1)
ttMki-lul rock 
cG I c r  I 
8 
mekt ,'C t t alld'yenghi' 
\[\[yenghl-ka tt lki-lul\]mek\], 
\[yenghi-ka \[ttalki-lul rock\]\] 
(C5,R2)q-(cr,R.1), 
(cs,rtl)+(c6,R2) 
s / (s \npn \npa ) 
5,f.ttalki'yenghi' 
\[yenghi-ka ttMki-lul\] 
(c5,m)+(ca,R1) 
ycnghi4<a 
Table 5: Sample CKY Parsing Table 
(16) os--kwa cangsingkwu(0)-hll yenkwuha-nun 
kes(0.008647)-iess-suImit a- 
os: 46 verbs, cangsinkwu: 2 verbs, kes: 2O83 verbs 
In (15), there are three verbs that occur with 
'kimchi' (kimchee), and nine verbs that occur 
with 'pap' (steamed rice), significantly fewer 
than those verbs that occur with 'kes' (thing). 
And in (16), the number of verbs that occur 
with 'cangsinkwu' (accessory) is smaller than 
that of the verbs that occur with other nouns. 
Both result in a wrong analysis. We can use a 
thesaurus to address this problem. 
In a thesaurus, words in the same class are 
assumed to have related meanings. We can use 
these class-mate words to compensate tbr data 
sparseness. In constructing a lexicon, we con- 
sult the thesaurus when the nmnber of verbs 
that occur with a given noun falls below a 
threshold, and let the noun share the data with 
those in the same class. The thesaurus has the 
'word-meaning code' tbrmat. The present he- 
saurus contains lightly more than 1000 nouns 
that are mammlly constructed. The classifi- 
cation follows the NTT hierarchy. We have 
assigned meaning codes to only the most fre- 
quently used meanings tbr polysemous entries. 
The depth of the hierarchy is 6. The following 
shows adjusted results with our thesarus. 
(17) kimchi-wa pap(0.768942)-man cwu-nun 
kes(0.008380)-ita. 
kimchi: 62 verbs, pat): 64 verbs, kes: 2083 verbs 
(18) os-kwa cangsinkwu(0.648276)-hfl yenkwuha-mm 
kes(0.008647)iess-supnita. 
os: 46 verbs, eangsinkwu: 69 verbs, kes: 2083 verbs 
Table 6 shows the comparison of the meth- 
ods with w~rious co-occurrence similarity dic- 
tionaries using 84 sentences containing nomi 
phrase coordination and structural ambiguity. 9 
It shows that a thesaurus is indeed usefifl in 
dealing with data sparseness. In this experi- 
\[\[ Nil M2 
Precision 84.1% 88.5% 
Recall 95.3% 92.7% 
Table 6: Comparison of l)ifferent Methods 
ment, we have shared the nouns that are asso- 
ciated with fewer than 20 verbs. We have also 
set the maximum shared examples to 70 and 
tuned the figures for maximum precision. 
5.3 Resu l ts  
For tile pertbrmance evaluation, we have con> 
pared three kinds of parsers. A employs only 
the CKY algorithm. B has tile additional mod- 
ule for spurious ambiguity. C utilizes the afore- 
mentioned ictionary, in addition to the module 
for spurious ambiguity. We tbund out that the 
9~{1 utilizes only the similariy dictionary as defined 
by Yang (1995). M2 has tile extra information from 
KAIST tree-tagged corpus and the thesaurus. 
598 
t)rilmtry t:';~ctors for (;he extra 1)re:sing (:Oml)lex- 
ity include the nuntber of right COlljUlle(; candi- 
dates, (;he presence of mo(liiiers in th(: left con- 
junct,  and the type of sen(;ences (simph: or com- 
plex) with noun phrase (:oordination. 
In order to check for the inthlen('e of struc- 
tural anfl)iguity on parsing efficiency, we have 
(:\[assitie(t 53 sentences into d types, considering 
modifiers in the left conjmm(; (of. g'~fl)le 7). H) 
'.l'M)le, 8 shows l;he mmfl)er of semantic sl;rllc- 
Sentences Modiliers (range) ://: of candidates 
Type 1 no < 3 
Tyl)e 2 yes (mmmMguous) > <I 
Tyl)e 3 yes (anfl)iguous) < 3 
Type 4 yes (alnl)iguous) > 4 
3hble, 7: Tyl)es of Sentences 
(;ures as derived by each l)~rser. ~ The ~wer- 
age numbers of semantic structures derived by 
B mM C a.re 26.2 and 7.;), resl)e('l;ively, result~ 
ing in t;he reduct ion of 72.1%. \[l?d)le 9 shows 
I-- 
\] 89.8 4.3 
963 32.3 
245.1 13.4 
83.3 
TM)h: 8: Derived Semmlti(: S(;rllt;l;llres 
the t)arsing time (i)r each m(~tho(t. I~ Tim reason 
(;hnt B ~q)t)em:s generMly faster (;lmn C (ex('ei)(; 
for type d) is tha,t () sl)ends extra time on con- 
sull;ing the (tiction~ry dai;at):~se for the similar- 
ity. But the av(:r;~g(: analysis time by B is 298.79 
ms, whereas C takes 228.92 ms, m~king pars- 
iug more efficient in time reduction of 23.39%. 
Albeit premature,  we l)elieve that these results 
are encouraging. 
6 Conc lud ing  Remarks  
' l 'hrough ext)eriments , we h~we confirnled thai; 
we cm~ address spurious ambiguity in a CCG 
(?The ~werage sentence lengths of tyl)es 1 through 4 
are 12.4, 16.7, 13.3, and 20.5 morph(,mes, respectively. 
J 1 A was not at)le to 1)roduee results at all for any of the 
sentences of tyl)e 4, and t'ailed on half of the sentences 
of type 2 due to insuflMent lnemory. The tigures in the 
table retlect only the successflfl ones. 
12loVe llsed tit(: statis(;ics t)ackage of SICS(,us Prolog, 
under Sun Enterl)rise 250 with 512MB RAM. There wer(; 
23, 10, 10, mM 10 sentences of types \] through 4, resl). 
L I A 1 u I 
Tyt)e 1 1168 228 277~ 
Type 2 5789 1001 1377  
TyI)e 3 1284 3(/5 335~ 
Tyt)e 4 - 4504 2504~ 
r Fable 9: Average Parsing Tilnes (in ms) 
framework by incorl)or~fing predicate ~rgmne.nt 
structures into t;he parsing module, and shown 
that co-occurrence simil~ri(;y information mlg- 
mented with a tlmsaurus helps the parser to (teal 
with strueturM aml)iguity. We leave open the 
problem of addressing those conjunct, s/disj uncts 
thai; m:e ncil;her semantically related nor mltic- 
ip~ted by a corpus. 
References  
R. Agarwal and L. Boggess. 1992. A simple lint usefifl 
api)roach to COl\jUlt(:t i(hmtitieal;ion. A CL, pp. 15-21, 
l\]. J. Cho. 2000. Coordinate Constructions i~l, Ko'rcan 
and Parsing /ssucs in Combinatory Catcgorial Gram- 
mar. KAIS\]? MS thesis. 
Ill..\]. Cho an(t J. C. Pa.rk. 2000. Conll)inat;ory Cal;egorial 
Grammar fin' the Synt;actic~ Semantic, and Discourse 
Analyses of Coordinal;ion in Korean. Journal of KISS: 
Software and Applications, 27(4), pp. 448-462. 
,J. Eisner. 1996. Efficient normal-tbrm parsing for Coml)i- 
natory CaCegorial Grammar. A CL. pp. 79-86. 
L. Karl;tunnen. 1989. RadicM Lexicalism. In Altcrna, tive 
Conceptions of Ph'rasc St, ruct'urc. U of Chi(:ago Press. 
N. Komagata. 1999. l'nJbrmatio'n, St, ruct,u, rc in 7'czts: A 
Comput, ational Analysis of Contcztual Appropriateness 
in English and ,lapa~tws~:. U of l)ennsylvauia Ph\]) thesis. 
S. Kurohashi and M. Nagao. 1994. A synl;a(:(,ic analysis 
m('tlmd of long Jal)anes(: s(mten(:(:s based on (letection 
of (:onjun(:tive structures. CL 20(4), pp. 507-534. 
K. J. Lee. 1998. Stochastic Syntactic Analysis of Korean 
'with Linguistic 1)~vpertics. KAIST PhD thesis. 
A. Okumura and K. Muraki. 1994. Symmetric pattern 
matching analysis tbr English coordinnte structures. 
ANLP, pp. 41-46. 
J. S. Park. 1998. Anab, lsis of Coordinate Constructions 
in Korean with Fart-@Specch Patterns. KAIST MS 
thesis. 
S. Prevost. 1995. A Semantics of Contrast and \]nfof 
marion Structure for SpeciJyin9 Intonation in Spoken 
Language Generation. U of Pennsylvania PhD thesis. 
M. St(,cdman. 1990. Gal)l)ing as Constituent Coordina- 
(;ion. Linguistics and l)hilosophy 13, Pl)- 207-263. 
M. Steedman. 200(/. The Syntactic Process, MIT Press. 
J. It. Yang. 1995. Structural Ambiguity l{esolution in Ko- 
rean Noun Phrase Conjmmtions Using Co-occurrence 
Similarity. Jo~t~'nal of KISS (B), 23(3), I'P. 311-321. 
599 
 
	
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 169?172,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
Toward finer-grained sentiment identification in product reviews 
through linguistic and ontological analyses 
 
 
Hye-Jin Min 
Computer Science Department 
KAIST, Daejeon, KOREA 
hjmin@nlp.kiast.ac.kr 
Jong C. Park 
Computer Science Department 
KAIST, Daejeon, KOREA 
park@nlp.kaist.ac.kr 
 
  
 
Abstract 
 
We propose categories of finer-grained polari-
ty for a more effective aspect-based sentiment 
summary, and describe linguistic and ontolog-
ical clues that may affect such fine-grained po-
larity. We argue that relevance for satisfaction, 
contrastive weight clues, and certain adver-
bials work to affect the polarity, as evidenced 
by the statistical analysis. 
1 Introduction 
Sentiment analysis have been widely conducted 
in several domains such as movie reviews, prod-
uct reviews, news and blog reviews (Pang et al, 
2002; Turney, 2002). The unit of the sentiment 
varies from a document level to a sentence level 
to a phrase-level, where a more fine-grained ap-
proach has been receiving more attention for its 
accuracy. Sentiment analysis on product reviews 
identifies or summarizes sentiment from reviews 
by extracting relevant opinions about certain 
attributes of products such as their parts, or prop-
erties (Hu and Liu, 2004; Popescu and Etzioni, 
2005). Aspect-based sentiment analysis summa-
rizes sentiments with diverse attributes, so that 
customers may have to look more closely into 
analyzed sentiments (Titov and McDonald, 
2008). However, there are additional problems.  
First, it is rather hard to choose the right level 
of detail. If concepts corresponding to attributes 
are too general, the level of detail may not be so 
much finer than the ones on a document level. 
On the other hand, if concepts are too specific, 
there may be some attributes that are hardly men-
tioned in the reviews, resulting in the data 
sparseness problem. Second, there are cases 
when some crucial information is lost. For ex-
ample, suppose that two product attributes are 
mentioned in a sentence with a coordinated or 
subordinated structure. In this case, the informa-
tion about their relation may not be shown in the 
summary if they are classified into different up-
per-level attributes. Consider (1).  
 
(1) a. ?? ???/?? ??, ??? ?? 
????. osun macciman, sayksangi nemwu 
etwuweyo. ?It fits me okay, but the color is too 
dark.? (size: barely positive, color: negative)  
b. ???? ? ???, ?? ?? ?? 
??? ?? ???? ???. sayngkakpota 
com yalpciman, aney patchye ipnun kenikka 
nalum kwaynchanhunke kathayo. ?It?s a bit 
thinner than I thought, but it is good enough 
for layering.? (thickness: negative but accepta-
ble, overall: positive) 
 
Example (1) shows sample customer reviews 
about clothes, each first in Korean, followed by a 
Yale Romanized form, and an English translation. 
Note that the weight of the polarity in the senti-
ment about size e.g. in (1a) is overcome by the 
one about color. However, if the overall senti-
ment is computed by considering only the num-
ber of semantically identical phrases in the re-
views, it misses the big picture.  
In particular, when opinions regarding 
attributes are described with respect to expres-
sions whose polarities are dependent on the spe-
cific contexts such as the weather or user prefe-
rence, an overestimated or underestimated 
weight of the sentiment for each attribute may be 
assigned. In our example, ??/yalpta/?thin? has 
an ambiguous polarity, i.e., either positive or 
negative, whose real value depends on the ex-
pected utility of the clothes. In this case, the neg-
ative polarity is the intended one, as shown in 
(1b). In order to reflect this possibility, we need 
to adjust the weight of each polarity accordingly.   
In this paper, we propose to look into the kind 
of linguistic and ontological clues that may in-
169
fluence the use of polarities, or the relevance for 
?satisfaction of purchase? inspired by Kano?s 
theory of quality element classification (Huisko-
nen and Pirttila, 1998), the conceptual granulari-
ties, and such syntactic and lexical clues as con-
junction items and adverbs. They may play sig-
nificant roles in putting together the identified 
polarity information, so as to assess correctly 
what the customers consider most important. We 
conducted several one-way Analysis of Variance 
(ANOVA) tests to identify the effects of each 
clue on deriving categories of polarity and quan-
tification method 2 to see whether these clues 
can distinguish fine-grained polarities correctly.  
Section 2 introduces categories of polarity. 
Section 3 analyzes ontological and linguistic 
clues for identifying the proper category. Section 
4 describes our method to extract such clues for a 
statistical analysis. Section 5 discusses the results 
of the analysis and implications of the results. 
Section 6 concludes the paper. 
2 Categories of polarity 
We suggest two more fine-grained categories of 
polarity, or ?barely positive? (BP) and ?accepta-
bly negative? (AN), in addition to positive (P), 
negative (N) and neutral (NEU). We distinguish 
?barely positive? from normal positive and dis-
tinguish ?acceptably negative? from normal nega-
tive in order to derive finer-grained sentiments. 
Wilson and colleagues (2006) identified the 
strength of news articles in the MPQA corpus, 
where they separated intensity (low, medium, 
high) from categories (private states). For the 
purpose of identifying each attribute?s contribu-
tion to the satisfaction after purchase, we believe 
that it is not necessary to have so many degrees 
of intensity. We argue that the polarity of ?barely 
positive? may hold attributes that must be satis-
fied and that ?acceptably negative? may hold 
those that are somewhat optional.  
3 Linguistic and Ontological Analyses  
In this section, we discuss linguistic and ontolog-
ical clues that influence the process of identify-
ing finer-grained polarity. For the purpose of ex-
position, we build hierarchical and aspect-based 
review structure as shown in Figure 1. Major 
aspects include Price, Delivery, Service, and 
Product. If we go down another level, Product is 
divided into Quality and Comfortableness. In 
defining relevant attributes, we consider all the 
lower-level concepts of major aspects, which 
contain the characteristics of the product with a 
description of the associated sentiment. 
 
 
Figure 1. Review structure 
 
Relevance for Satisfaction: We consider re-
levant attributes that affect the quality and satis-
faction of the products as one of the important 
clues. Quality elements classified by Kano as 
shown in Table 1 can be base indicators of rele-
vant attributes for satisfaction in real review text. 
For example, while completeness of the product 
may become crucial if the product has a defect, it 
is usually not the case that it would contribute 
much to the overall satisfaction of the customer.  
 
Quality Elements  Example features 
Must-be Quality (MQ) Durability, Completeness
1-dimension Quality (1DQ) Design, Color, Material 
Attractive Quality (AQ) Luxurious look 
Table 1. Kano's Quality Elements  
 
Conceptual Granularity: The concepts cor-
responding to attributes have a different level of 
detail. If the customer wants to comment on 
some attributes in detail, she could use a fine-
grained concept (e.g., the width of the thigh part 
of the pants) rather than a coarse-grained one 
(e.g., just the size of the pants). To deal properly 
with the changing granularity of such concepts, 
we constructed a domain specific semi-
hierarchical network for clothes of the Clothing-
Type structure, in addition to the Review struc-
ture, by utilizing hierarchical category informa-
tion in online shopping malls.  Figure 2 shows an 
example for ?pants?.  
 
ClothingType
Bottom
Pants
Sub_f Sub_p
Thigh CalfWaistHip
Length+
Material+
Design:
Line+
Design:
Pattern*
Design:
Style*
Color
Size
Design:
Detail*
 
Figure 2. ClothingType structure for pants 
 
Syntactic and Lexical Clues: Descriptions of 
each attribute in the reviews are often expressed 
170
in a phrase or clause, so that conjunctions, or 
endings of a word with a conjunctive marker in 
Korean, play a significant role in connecting one 
attribute to another. They also convey a subtle 
meaning of the sentiment about relations be-
tween two or more connected attributes. We 
classified such syntactic clues into 4 groups of 
likeness (L), contrary (C), cause-effect (CE), and 
contrary with contrastive markers (CC).  
Wilson and colleagues (2006) selected some 
syntactic clues as features for intensity classifica-
tion. The selected features are shown to improve 
the accuracy, but the set of clues may vary to the 
nature of the given corpus, so that some other-
wise useful clues that reflect a particular focused 
structure may not be selected. We argue that 
some syntactic clues such as the use of certain 
conjunctions can be identified manually to make 
up for the limitation of feature selection.    
Adverbs modifying adjectives or verbs such as 
too, and very also strengthen the polarity of a 
given sentiment, so such clues work to differen-
tiate normal positive or negative from ?barely 
positive? and ?acceptably negative?. Table 2 
summarizes linguistic clues in the present analy-
sis. 
 
Clues  Examples 
CONJ/ 
END 
L -? -ko ?and? 
C -?? -ciman ?but?, 
??? kulena ?however? 
CE -?? -ese ?so?, ??? 
kulayse ?therefore? 
CC -? ??? -kin -ciman  ?It?s 
?, ?but?, ?though? 
ADV Strong ?? maywu ?very?, 
?? nemwu ?too?  
Mild ? com ?a little? 
Table 2. Syntactic and Lexical Clues 
 
All these three types of clue that appear in the 
review text may interact with one another. For 
example, attributes with ?barely positive? tend to 
be described with a concept on a coarse level, 
and may belong to Must-be Quality (e,g.,  size in 
(1a)). However, if such attributes are negative, 
customers may explain them with a very fine-
grained concept (e.g., the width of thigh is okay, 
but the calf part is too wide; interaction between 
relevance for satisfaction and conceptual granu-
larity). They may also use adverbs such as ?too? 
to emphasize such unexpected polarity informa-
tion. For emphasis, a contrastive structure can be 
used to indicate which attribute has a more 
weight (e.g., ?A but B?; interaction between syn-
tactic clues and relevance for satisfaction). In 
addition, an unfocused attribute A may be the 
attribute with ?acceptably negative? if the polari-
ty of the attribute B is positive. We believe that 
the interaction between lexical and syntactic 
clues and relevance for satisfaction are the most 
important and that this correlation information 
may be utilized with such fine-grained polarity 
as ?barely positive? or ?acceptably negative?.  
4 Clue Acquisition 
We acquired data semi-automatically for each 
clue from the extracted attributes and their de-
scriptions from 500 product reviews of several 
types of pants and annotated polarities manually. 
We obtained raw text reviews from one of the 
major online shopping malls in Korea1 and per-
formed a morphology analysis and POS-tagging. 
After POS-tagging, we collected all the noun 
phrases as candidates of attributes. We regarded 
some of them as attributes with the following 
guidelines and filtered out the rest: 1) NP with 
frequent adjectives 2) NP with frequent non-
functional and intransitive verbs. In the case of 
subject omission, we converted adjectives or 
verbs into their corresponding nouns, such as 
?thin? into ?thickness?. Hu and Liu (2004) identi-
fied attributes of IT products based on frequent 
noun phrases and Popescu and Etzioni (2005) 
utilized PMI values between product class (ho-
tels and scanners) and some phrases including 
product. In our case, we used attributes that be-
long only to the Product concept in the Review 
structure, because most attributes we consider 
are sub-types or sub-attribute of Product. The 
total number of <attribute, polarity> pairs is 474. 
For relevance for satisfaction, we converted 
extracted attributes into one of the types of Ka-
no?s quality elements by the mapping table we 
built. For conceptual granularity we regarded all 
the attributes with a depth less than 2 as ?coarse? 
and those more than 2 as ?fine?. Syntactic and 
lexical clues are identified from the context in-
formation around extracted adjective or verbs by 
the patterns based on POS information. 
5 Statistical Analysis and Discussion 
We conducted one-way Analysis of Variance 
(ANOVA) tests using relevance for satisfaction 
(ReV), conceptual granularity (Granul), and two 
linguistic clues, ADV and CONJ/END, in order 
to assess the effects of each clue on identifying 
categories of polarity. The ANOVA suggests 
                                                 
1 http://www.11st.co.kr 
171
reliable effects of ReV (F(2,474) = 22.2; p 
= .000), ADV (F(2, 474) = 41.3; p = .000), and 
CONJ/END (F(3, 474) = 6.1; p = .000).  We also 
performed post-hoc tests to test significant dif-
ferences. For ReV, there are significant differ-
ences between ?MQ? and ?1DQ? (p=.000), and 
between ?MQ? and ?AQ? (p =.032). AQ is related 
to ?positive? and MQ to ?acceptably negative? by 
the result. For ADV, there are significant differ-
ences between all pairs (p <.05). For CONJ/END, 
there are significant differences between ?like-
ness? and ?contrary? (p = .015), and between 
?likeness? and ?contrary with contrastive mark-
ers? (p = .025).  The ?contrary? and ?contrary 
with contrastive markers? types of conjunctions 
are related to ?acceptably negative?.  
We also conducted Quantification method 2 to 
see if these clues can discriminate between BP 
and P and discriminate between AN and N. The 
regression equation for distinguishing AN from 
N is statistically significant at the 5% level 
(F(7,177) = 12,2; R2=0.335; Std. error of the es-
timate =  0.821; error rate for discriminant = 
0.21). The coefficients for ?mild? (t2=30.8), ?con-
trary? (t2=17.8) and ?contrary with contrastive 
markers? (t2=14.1) are significant.  
The results lead us to conclude that we can 
identify ?acceptably negative? from the clothes 
reviews by extracting the particular lexical clue, 
adverbs of ?mild? category and syntactic clue, 
such as conjunctions of ?contrary?, and ?contrary 
with contrastive markers?, or contrastive weight. 
This clue may convey the customer?s argumenta-
tive intention toward the product, or argumenta-
tive orientation, for instance, A and B in ?A but B. 
C? have different influence on the following dis-
course C (Elhadad and McKeown, 1990). 
Although ?contrary with contrastive markers? 
plays an important role in identifying ?acceptably 
negative?, it could also be used to identify anoth-
er type of ?positive? as shown in  example (2).  
 
(2) ? ???? ??? ???. ??? 
???? ???. com twukkeptanun sayng-
kaki tupnita. kulayto ttattushakin haneyyo. ?It 
is a bit thick, but it keeps me warm.? 
 
It is a positive feature, but neither fully positive 
nor barely positive. It seems to be somewhere in-
between. The order of appearance in reviews 
may also affect the strength of polarity.  In addi-
tion, particular cue phrases such as ~?? 
??/kesman ppayko/?except that ?? can also 
convey ?acceptably negative?, too.  
  In the future, we need to assess the importance 
of each proposed clue relative to others and to 
the existing ones. We also need to investigate the 
nature of interactions among linguistic, ontologi-
cal and relevance for satisfaction clues, which 
may influence the actual performance for identi-
fying finer-grained polarity.  
6 Conclusion and Future Work 
We proposed further categories of polarity in 
order to make aspect-based sentiment summary 
more effective. Our linguistic and ontological 
analyses suggest that there are clues, such as ?re-
levance for satisfaction?, ?contrastive weight? and 
certain adverbials, that work to affect polarity in 
a more subtle but crucial manner, as evidenced 
also by the statistical analysis.  We plan to find 
out product attributes that contribute most to 
modeling the interaction among the proposed 
clues in effective sentiment summarization. 
 
Acknowledgments 
This work was funded in part by the Intelligent 
Robotics Development Program, a 21st Century 
Frontier R&D Program by the Ministry of 
Knowledge Economy in Korea, and in part by 
the 2nd stage of the Brain Korea 21 project. 
References  
Ana-Maria Popescu and Oren Etzioni 2005. Extract-
ing Product Features and Opinions from Reviews. 
Proc. HLT/EMNLP 2005, 339-346. 
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 
2002. Thumbs up? Sentiment classification using 
machine learning techniques. Proc. EMNLP. 
Ivan Titov and Ryan McDonald  2008. A Joint Model 
of Text and Aspect Ratings for Sentiment Summari-
zation. Proc.  ACL-08: HLT, 308-316. 
Janne Huiskonen and Timo Pirttila. 1998. Sharpening 
logistic customer service strategy planning by ap-
plying Kano?s quality element classification. Inter-
national Journal of Producion Economics, 56-57, 
253-260, Elsevier Science B.V. 
Michael Elhadad and Kathleen R. McKeown. 1990. 
Generating Connectives. Proc. COLING?97-101. 
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. Proc. ACM SIGKDD, 
168?177. ACM Press. 
Peter D. Turney. 2002. Thumbs up or thumbs down? 
Sentiment orientation applied to unsupervised 
classification of reviews. Proc. ACL, 417-424. 
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 
2006. Recognizing Strong and Weak Opinion 
Clauses. Computational Linguistics, 22 (2): 73-99. 
172
Automatic Augmentation of Translation Dictionary with
Database Terminologies in Multilingual Query Interpretation
Hodong Lee and Jong C. Park
Computer Science Division and AITrc
Korea Advanced Institute of Science and Technology
373-1 Gusung-dong, Yusong-gu, Daejon 305-701, South KOREA
fhdlee,parkg@nlp.kaist.ac.kr
Abstract
In interpreting multilingual queries
to databases whose domain informa-
tion is described in a particular lan-
guage, we must address the problem
of word sense disambiguation. Since
full-fledged semantic classification in-
formation is difficult to construct ei-
ther automatically or manually for this
purpose, we propose to disambiguate
the senses of the source lexical items
by automatically augmenting a simple
translation dictionary with database
terminologies and describe an imple-
mented multilingual query interpreta-
tion system in a combinatory catego-
rial grammar framework.1
1 Introduction
In interpreting multilingual queries to databases
with domain information such as objects, table
names, and attribute names that are described in
a particular language, we must address the prob-
lem of word sense disambiguation. For exam-
ple, if we wish to interpret a query in English
to a database with domain information described
in Korean, lexical items in English must be dis-
ambiguated to the matching senses in Korean.
This problem is similar to that of lexical selec-
tion in machine translation domain (Lee et al,
1This work was supported by the Korea Science and En-
gineering Foundation (KOSEF) through AITrc.
ip-ta person body color ...
Mary oy-twu kal-sayk ...
... ... ... ...
sin-ta person foot status ...
John sin-bal nalk-ta ...
... ... ... ...
sa-ta person object status ...
John ca-tong-cha nalk-ta ...
Mary sin-bal nalk-ta ...
Manny ko-yang-i nulk-ta ...
... ... ... ...
Table 1: Sample Database
1999; Palmer et al, 1999), except that the target
is different in the sense that one is a formal query
language and the other is another natural lan-
guage. This difference prompts us to make use of
database information, such as domain database
objects, table names, and attribute names, instead
of the general semantic classifications (Palmer et
al., 1999) for disambiguating the senses of lex-
ical items in the query. Example queries are
shown below:
(1) (a) Which shoes does Mary buy?
(b) Who wears a brown coat?
(c) Who wears old shoes and buys an old car?
Query 1a shows a query made up of unambigu-
ous words having a unique target interpretation.
But in 1b, wears may have several interpretations
in Korean such as ?ip-ta?, ?ssu-ta?, ?sin-ta?, and
?tti-ta? (cf. Table 3). And old in query 1c also
contains several senses2. If we assume a simple
database made up of tables such as ?ip-ta? (to put
on the body), ?sin-ta? (to put on the foot), and
2We notate Korean alphabets in Yale form.
?sa-ta? (buy) in Table 1, wears in 1b can be dis-
ambiguated by a lexical item ?coat? and its tar-
get ?oy-twu?, since ?oy-twu? only appears in the
table as related to ?ip-ta?. And wears in 1c is
also restricted by ?shoes?, but ?shoes? appears in
the table as related to ?sin-ta? and ?sa-ta?. As
shown, these senses can be disambiguated with
the translation dictionary. Since ?sa-ta?, or ?buy?,
is not registered in the translation dictionary, it
is simply discarded. old in a query 1c can be
interpreted into ?nalk-ta? (not new) and ?nulk-ta?
(not young) because it appears in the same table
entries for ?sa-ta?. Since it is difficult to disam-
biguate the senses only with database informa-
tion, we may utilize co-occurrence information
between the collocated words such as (old,shoes)
and (old,car) (Park and Cho, 2000; Lee et al,
1999).
In this paper, we propose a disambiguation
method with the database information and co-
occurrence information (Park and Cho, 2000;
Palmer et al, 1999) for the interpretation of nat-
ural language queries (Lee and Park, 2001) in
multilingual query interpretation. Although we
propose to construct the system without an inter-
mediate representation language, we show that
our Combinatory Categorial Grammar (CCG)
framework is compatible with the approaches
with an intermediate representation (Nelken and
Francez, 2000; Androutsopoulos et al, 1998;
Klein et al, 1998). We also discuss the advan-
tages and disadvantages of these two approaches.
The rest of the paper is organized as fol-
lows. A brief introduction to CCGs and natu-
ral language database interfaces (NLDBs) will
be shown in Section 2. We show the translation
process with and without an intermediate repre-
sentation using CCG in Section 3. The proposed
system with multilingual translation is described
in Sections 4 and 5.
2 Related Work
In this paper, we propose to interpret natural lan-
guage queries in English and Korean with CCGs
and argue that word selection problem must be
resolved for multilingual query interpretation.
Rule Rule Name (Symbol)
X=Y Y ! X F/W Application (>)
Y XnY ! X B/W Application (<)
X conj X ! X Coordination (< n >)
X=Y Y=Z ! X=Z F/W Composition (> B)
Y nZ XnY ! XnZ B/W Composition (< B)
X=Y Y nZ ! XnZ F/W Crossed Comp. (> B
x
)
X ! T=(TnX) F/W Type Raising (> T )
X ! Tn(T=X) B/W Type Raising (< T )
Table 2: CCG Rules for Korean
2.1 Combinatory Categorial Grammar
Combinatory Categorial Grammars (CCGs) are
combinatory extensions to the categorial gram-
mars (Steedman, 2000). CCGs are among the
lexicalized grammars, such as linear indexed
grammars and tree adjoining grammars, and are
generally known to provide a wide linguistic
coverage and a way of processing sentences in-
crementally.
Table 2 shows the CCG reduction rules pro-
posed for Korean (Park and Cho, 2000). (Steed-
man, 2000) suggested the reduction rules for En-
glish which include backward crossed composi-
tion and backward substitution. We adopt this
rule set for the processing of the queries in En-
glish.
(2) Who wears old shoes?
np (snnp)=np np=np np
>
np
>
snnp
<
s
Example 2 shows a syntactic derivation for an
example query using CCG. Transitive verbs like
?wears? are assigned the category (snnp)/np,
which receives a phrase of category np on its
right (the second np and the directionality is indi-
cated by the slash /, that is, to the right) and then
receives another np on its left (the first np and
the directionality is indicated by the backslash n,
that is, to the left), to give rise to the phrase of
category s. Such a computation is done by sim-
ple function application. Example 3 shows the
CCG derivation for a query with coordination.
(3) Who wears old shoes and a brown coat?
np (snnp)=np np conj np
<
n
>
np
>
snnp
<
s
In addition to function application utilized in ex-
amples 2 and 3, CCGs use rules for a limited
set of combinators such as B (function compo-
sition), T (type raising), and S (function substi-
tution) to model natural language. The reader is
referred to (Steedman, 2000) for further details.
2.2 Multilingual Database Interfaces
There have been many proposals for NLDBs
since the 1960?s3. In this section, we review
some of the more recent ones. (Androutsopou-
los et al, 1998; Nelken and Francez, 2000) focus
on queries in English with temporal expressions,
with a specialized semantic representation lan-
guage that can handle temporality. Examples are
shown below.
(4) (a) Did any flight circle while runway 2 was open?
(b) Which companies serviced BA737 in 1990?
(c) During which years did Mary work in marketing?
The system in (Klein et al, 1998) interprets noun
phrase queries such as 5 in German:
(5) Ersatzzeiten wegen Kindererziehung
(Exemption times because of child raising)
While the system can analyze noun phrases with
various adverbial phrases, it is not reported to
handle more complex noun phrase queries such
as those with subordinate or coordinate construc-
tions.
None of these work deals with multilingual
issues. Nor is there much related work in the
field of NLDBs. (Thompson and Mooney, 1999)
presents a system that automatically constructs
the lexicon for NLDBs, in various languages
such as English, Spanish, Japanese, and Turkish,
which represents the lexical entries with a pair of
the phrases and the corresponding semantic rep-
resentation in first-order logic. Since the seman-
tic representation for lexical items is determined
using the frequency of the general terms of the
semantic representation in the corpus made up
of the query sentences annotated by their logical
representation, the system makes it difficult to
incorporate various linguistic considerations on
natural language.
3The reader is referred to (Androutsopoulos et al, 1995)
for a survey.
3 Translation with CCG
In this section, we discuss the translation with
and without an intermediate language. The
translation based on CCG can derive the tar-
get database language expressions/queries such
as SQL, TSQL, and QUBE, as well as expres-
sions in intermediate representation languages.
We show the translation into both languages with
examples (Nelken and Francez, 2000).
3.1 Indirect vs. Direct Translation
Most NLDBs use an intermediate representa-
tion which does not make use of expressions
that correspond directly to real database objects.
The intermediate representations are usually no-
tated as logic expressions such as a quasi-logical
form (Klein et al, 1998) and a customized lan-
guage (Androutsopoulos et al, 1998; Nelken and
Francez, 2000). These representations provide a
way to translate indirectly to the target database
languages.
For example, query 6a is translated into
6b with the intermediate representation L
Allen
(Nelken and Francez, 1999; Toman, 1996),
and into 6c with the SQL/Temporal expressions
(Nelken and Francez, 2000).
(6) (a) During which years did Mary work in marketing?
(b) year(I) ^ 9J(work(mary;marketing; J) ^ J 
past ^ J  I
(c) NONSEQUENCED VALIDTIME
SELECT DISTINCT a0.c1 AS c1
FROM work? AS a1,year? AS a0
WHERE VALIDTIME(a0) contains VALIDTIME(a1)
AND a1.c1 = ?mary? AND a1.c2 = ?marketing?
AND PERIOD(TIMESTAMP ?beginning?, TIMESTAMP
?now?) contains VALIDTIME(a1)
The translation using an intermediate represen-
tation has several advantages, including (a) the
availability of an independent linguistic front-
end, (b) the separation of domain dependent
knowledge from the system engine, and (c)
the relative easiness of augmenting the sys-
tem with an extra inference module for disam-
biguation (cf. Androutsopoulos et al, 1995).
The points (a) and (b) indicate the separation
of domain-dependent resources such as lexicon,
database mapping information, and other knowl-
edge bases. (c) arises from the modularity of the
translation process.
During which year; did mary work in marketing?
(s=s)=np : np : year(I) s=s : np : mary
0
snnp : (snnp)n(snnp) :
(x; I)(y; J):x ^ y ^ J  I (x; J):x ^ J  past xy:9Jwork(x;y; J) marketing
0
> <
s=s : (y; J):year(I) ^ y ^ J  I snnp : y:9Jwork(y;marketing
0
; J)
<
s : 9Jwork(mary
0
; marketing
0
; J)
>
s : 9Jwork(mary
0
; marketing; J) ^ J  past
>
s : year(I) ^ 9Jwork(mary
0
; marketing; J) ^ J  past ^ J  I
Figure 1: A Derivation of Example 6a to an Intermediate Representation
When we use an intermediate language, we do
not need to concern ourselves with the syntac-
tic details of the target query language during the
mapping process, so that we can pay more at-
tention to the differences in syntax between the
two source languages (i.e. English and Korean),
making the resulting interpretation more reliable.
In addition, the use of an intermediate language
gives rise to a more flexible query interpretation
system as the queries can be translated into mul-
tiple target query languages without further pro-
cessing at the stage of the source query interpre-
tation. However, the use of the same intermedi-
ate language for source query languages such as
English and Korean that are known to have very
different linguistic characteristics makes it dif-
ficult to capture subtle differences between the
queries of the different source languages unless
the intermediate language is quite expressive.
And much of the expressiveness of the interme-
diate language for the translation of the queries
in one language may not be what is needed in the
translation of the queries in the other.
The translation without an intermediate repre-
sentation has a simpler and more straightforward
process. And there is no extra effort on devel-
opment of a formal intermediate representation
which is difficult to ensure the full coverage on
linguistic expressiveness and the soundness of
the proposed formalism. Nevertheless, the three
points mentioned above are thought to be dif-
ficult to overcome in this approach. However,
the points (a) and (b) can be equally achieved by
separating domain-dependent elements from the
query processing module using lexicalized gram-
mars such as CCG. In this case, the construction
of a domain-dependent lexicon can be a prob-
lem, but it can be resolved to some extent with
an automatic construction method. The point
(c) is difficult to address, since the translation
without an intermediate representation usually is
done in a single module. The inference mod-
ule, however, can be complemented by disam-
biguation using co-occurrence information (Park
and Cho, 2000) and disambiguation of domain-
dependent word senses with consideration for the
context-dependent information such as informa-
tion structure (Steedman, 2000). (Nelken and
Francez, 2000) use an intermediate representa-
tion because the compositional construction of
formulae during parsing becomes easier. How-
ever, we show that database queries can be in-
terpreted compositionally during parsing without
such an intermediate representation through di-
rect translation.
3.2 Translation to an Intermediate
Representation
While our approach does not make use of an in-
termediate representation, the CCG framework
itself allows queries to be interpreted into an in-
termediate representation. Figure 1 shows the
translation process from the query 6a to the form
6b which is in L
Allen
. Since we are only showing
the possibility of translation, we use an exam-
ple from (Nelken and Francez, 2000). In Figure
1, we slightly modified the semantics in (Nelken
and Francez, 2000; Nelken and Francez, 1999)
for the convenience of translation. And for the
same reason, we devised the operator (x; I)
where x is an argument and I represents a time
interval variable.
3.3 Translation to a Target Language
Figure 2 shows the translation process from the
query 6a to SQL/Temporal expression 6c, also
indicating the need for post-processing. For in-
Word Relation Collocation Word sense Target words
wear object coat,glasses put on $? "(ip-ta), bh"(ssu-ta), '? "(sin-ta), ""(cha-ta)
expression express $"(tti-ta), BioAR: Anaphora Resolution for Relating Protein Names to Proteome
Database Entries
Jung-jae Kim   and Jong C. Park 
Computer Science Division & AITrc
Korea Advanced Institute of Science and Technology
373-1, Guseong-dong, Yuseong-gu, Daejeon 305-701, South Korea
 
jjkim@nlp.kaist.ac.kr

park@cs.kaist.ac.kr
Abstract
The need for associating, or ground-
ing, protein names in the literature with
the entries of proteome databases such
as Swiss-Prot is well-recognized. The
protein names in the biomedical litera-
ture show a high degree of morpholog-
ical and syntactic variations, and vari-
ous anaphoric expressions including null
anaphors. We present a biomedical
anaphora resolution system, BioAR, in or-
der to address the variations of protein
names and to further associate them with
Swiss-Prot entries as the actual entities in
the world. The system shows the per-
formance of 59.5%  75.0% precision and
40.7%  56.3% recall, depending on the
specific types of anaphoric expressions.
We apply BioAR to the protein names
in the biological interactions as extracted
by our biomedical information extraction
system, or BioIE, in order to construct
protein pathways automatically.
1 Introduction
The need for identifying the antecedents of
anaphoric expressions in the literature is well-
recognized. Most previous approaches assume that
anaphoric expressions and their antecedents would
appear in the same documents. However, further
work is called for when such antecedents need to be
associated with actual entities in the world, where
the task of establishing the denotation of a named
entity with respect to the world or a model is known
as named entity grounding (Leidner et al, 2003).
In the biomedical domain where the phrases in the
literature tend to refer to actual biological entities
such as proteins, the phrases should be associated
with the actual entries of external resources (Hachey
et al, 2004). In this paper, we present a biomedi-
cal anaphora resolution system, BioAR, in order to
identify the actual referents of those phrases in the
biomedical literature and to annotate the phrases, es-
pecially those that refer to proteins, with the entries
of proteome databases such as Swiss-Prot by suit-
able anaphora resolution.
Anaphora resolution indicates the process of de-
termining the antecedent of an anaphoric expres-
sion. Traditional approaches to anaphora resolu-
tion in general domain utilize various constraints
or preferences from the morphological, syntactic,
and semantic points of view. The most promi-
nent proposal for anaphora resolution is a center-
ing theory (Grosz et al (1995)), which identifies the
antecedents of pronouns with respect to discourse
structures, based on the observation that those en-
tities that have already been mentioned and are
more central than others tend to be referred back
by pronouns subsequently. Byron (2002) proposed
to identify the antecedents of pronominal references
in spoken dialogues by utilizing discourse struc-
tures with discourse entities and semantic filter-
ing. Castano et al (2002) adopted a knowledge-
poor method, which focuses on resolving pronouns
robustly, for example with part-of-speech informa-
tion, positions of the candidate antecedents, agree-
(1) The yeast and mammalian branchpoint se-
quence binding proteins (BBP and mBBP/
SF1) contain both KH domain and Zn
knuckle RNA-binding motifs.  There-
fore, we propose that all three of these
accessory RNA-binding modules bind
the phosphate backbone, whereas the KH
domain interacts specifically with the bases
of the BPS. (PMID:9701290)
Table 1: A protein domain-referring phrase example
ments and lexical features, in addressing problems
in the biomedical domain (cf. Mitkov et al (1998)).
In the biomedical literature, an anaphoric expres-
sion works as the device of making an abbrevi-
ated and indirect reference to some biological ob-
ject or objects. This notion can be applied to all the
phrases in the literature which refer to proteins, in
that the phrases can be associated (or grounded) with
the protein entries in proteome databases, which bi-
ologists generally regard as the identities of pro-
teins. The protein-referring phrases in the litera-
ture include not only gene/protein names but also
anaphoric expressions and missing arguments of bi-
ological interactions (or null anaphors) which refer
to proteins.1
As for anaphoric expressions, previous ap-
proaches to anaphora resolution often stop at an-
tecedent noun phrases in the same documents, but
we propose to further identify the proteins that
are composed of protein domains referred to by
anaphoric expressions. For example, the anaphoric
expression the KH domain in the last sentence in Ta-
ble 1 refers to the domain shared by the proteins ?the
yeast and mammalian branchpoint sequence binding
proteins (BBP and mBBP/SF1).?2
While previous approaches have dealt only with
the resolution of pronouns (e.g. it, they) and sortal
1As for anaphora resolution, there are three related kinds of
objects in biomedical domain, that is, pronouns, antecedents,
and real entities in the world, where pronouns and antecedents
are the phrases in the literature. Among antecedents, there can
be ?anaphoric? ones, referring to other antecedents. Both pro-
nouns and antecedents eventually refer to real entities in the
world, so the protein-referring phrases in the literature include
both pronouns and antecedents in the literature.
2Hereafter, the italicized string is an anaphoric expression
and the underlined string is its antecedent.
(2) MOB1 exhibits genetic interaction with
three other yeast genes required for the
completion of mitosis, LTE1, CDC5, and
CDC15 (the latter two encode essential pro-
tein kinases). (PMID:9436989)
(3) Screening for the emerin binding protein and
immunopr ecipitation analysis showed that
lamin A binds to emerin specifically. We
also used the yeast two-hybrid system to
clarify that this interaction requires the top
half of the tail domain (amino acid 384-566)
of lamin A. (PMID:11173535)
Table 2: Missing argument examples of biological
interactions
anaphoric noun phrases (e.g. the protein, both en-
zymes), we can also restore the missing arguments of
the biological interactions, mostly represented with
nominal interaction keywords such as interaction
with or without determiners, by utilizing the con-
text (cf. Hong and Park (2004)). For example, the
omitted argument of interaction in the first exam-
ple in Table 2 is the sentential subject, or ?MOB1.?
In the second example in Table 2, the two omit-
ted participants of the interaction represented by the
anaphoric expression this interaction are ?lamin A?
and ?emerin,? which are also the syntactic argu-
ments of the verb binds.
In this paper, we present a biomedical anaphora
resolution system, BioAR, to ground the protein-
referring phrases in the biological interactions ex-
tracted by our biomedical information extraction
system, BioIE (Kim and Park, 2004; Park et al,
2001), with Swiss-Prot entries. BioIE is a sys-
tem that extracts general biological interactions
of arbitrary types from the biomedical literature.
This system shows the performance of 88  92%
precision and 55  57% recall, or the F-scores of
68  70. While the output of BioIE includes com-
plex linguistic phenomena, such as anaphoric ex-
pressions, conjunctions, prepositional phrases, and
relative clauses, many of the noun phrases in the
results of BioIE refer to proteins since the rel-
evant interaction keywords, such as interact and
bind, mostly represent protein-protein interactions
Anaphoric expression Count
Pronouns 53
Anaphoric DNPs 26
Missing arguments 8
Table 3: Statistics of anaphoric expressions
and the interactions among them.3 BioAR grounds
those protein-referring phrases with Swiss-Prot en-
tries which work as the protein nodes in the protein
pathways that can be automatically built by incorpo-
rating the biological interactions extracted by BioIE.
2 Methods
BioAR identifies the antecedents of anaphoric ex-
pressions that appear in the results of BioIE and
annotates the protein-referring phrases with Swiss-
Prot entries. The system first locates pronouns,
noun phrases with determiners (DNPs), and bio-
logical interactions as the candidates of anaphoric
expressions. Table 3 shows the statistics of these
anaphoric expressions.4 The rest of the system is
implemented in the following four steps: 1) pro-
noun resolution, 2) resolution of anaphoric DNPs,
3) restoration of missing arguments in the biological
interactions, and 4) grounding the protein-referring
phrases with Swiss-Prot entries.
2.1 Pronoun resolution
We adopt the centering theory of Grosz et al (1995)
for the anaphora resolution of pronouns. In par-
ticular, we follow the observation that the entities
which have already been mentioned and are more
central than others tend to be referred back by pro-
nouns subsequently. For example, the candidate an-
tecedent in the sentential subject is preferred to that
in the sentential object (cf. Table 4).
As for possessive pronouns such as its and their,
we have found that the antecedents of these posses-
sive pronouns are mostly located in the same or pre-
ceding sentences and that possessive pronouns can
be classified into the following two types accord-
ing to the sentential locations of their antecedents,
3There are 232 noun phrases which can be associated with
Swiss-Prot entries, among 1,645 noun phrases in 516 biological
interactions extracted by BioIE from a subset of yeast corpus.
4We have counted the anaphoric expressions among 1,645
noun phrases in the subset of yeast corpus.
(4) Finally, SpNAC can bind to X-junctions that
are already bound by a tetramer of the Es-
cherichia coli RuvA protein, indicating that
it interacts with only one face of the junc-
tion. (PMID:11243781)
Table 4: A subjective pronoun resolution example
where 1) the antecedent of a possessive pronoun is
the protein name which is nearest to the left of the
possessive pronoun in the same sentence and 2) the
antecedent of another possessive pronoun is the left-
most protein name in the subject phrase of the same
or preceding sentence (cf. Table 5). We have also
found that the local context of a possessive pronoun
of the second type mostly shows syntactic paral-
lelism with that of its antecedent, as in the two they
of the second example in Table 5, while that of the
first type does not show parallelism where the an-
tecedents of such possessive pronouns are mostly
the protein names nearest to the left of the posses-
sive pronouns.5 Since the antecedents of possessive
pronouns of the second type can be detected with
the patterns that encode the parallelism between the
local context of a possessive pronoun and that of its
antecedent in the same sentence (cf. Table 6),6 we
have set the protein names, those nearest to the left
of the possessive pronouns in the same sentences, as
the default antecedents of possessive pronouns and
utilized the patterns, such as those in Table 6, in rec-
ognizing the possessive pronouns of the second type
and in locating their antecedents.
2.2 Noun phrase resolution
In the process of resolving anaphoric noun phrases,
BioAR first locates the noun phrases with determin-
ers (DNPs), especially those with definites (i.e. the)
and demonstratives (i.e. this, these, and those), as
5Among the 1,000 biological interactions, there are 31 pos-
sessive pronouns of the first type and 17 possessive pronouns of
the second type.
6POSS indicates a possessive pronoun; ANT indicates its
antecedent; NP which follows POSS indicates the rest of the
noun phrase which starts with POSS; and BeV indicates a be-
verb. VB, VBN, and PP are POS tags, indicating main verbs,
past particles, and prepositions, respectively. ?A  B? indicates
that either A or B should occur. ?  ? can be matched to any
sequence of words.
(5) Using the Yeast Two-Hybrid system and fur-
ther in vitro and in vivo studies, we identi-
fied the regulatory beta-subunit of casein ki-
nase II (CKII), which specifically binds to
the cytoplasmic domain of CD163 and its
isoforms. (PMID:11298324)
(6) F-box proteins are the substrate-recognition
components of SCF (Skp1-Cullin-F-box
protein) ubiquitin-protein ligases. They bind
the SCF constant catalytic core by means
of the F-box motif interacting with Skp1,
and they bind substrates through their vari-
able protein-protein interaction domains.
(PMID:11099048)
Table 5: Possessive pronoun resolution examples
1. via  through  due to POSS NP
2. ANT BeV VBN  and VBN PP POSS NP
3. ANT BeV VBN and POSS NP VBN PP
4. ANT BeV VBN  and POSS NP BeV VBN
5. VB that ANT VB  ,  and that POSS NP
6. ANT VB  , and POSS NP VB
7. ANT?s NP VB  and POSS NP VB
Table 6: Example patterns for parallelism
the candidates of anaphoric noun phrases.7 Among
the noun phrases with definites, the noun phrases
that do not have antecedents in the context, i.e. non-
anaphoric DNPs, mostly belong to the classes in Ta-
ble 7.8 9 The system filters out those non-anaphoric
DNPs belonging to those classes in Table 7, by uti-
lizing a list of cellular component names, a list of
species names, and the patterns in Table 7 which rep-
resent the internal structures of some non-anaphoric
DNPs. We have also developed modules to identify
appositions and acronyms in order to filter out re-
maining non-anaphoric DNPs.
BioAR scores each candidate antecedent of an
7We also deal with other anaphoric noun phrases with ?both?
or ?either?, as in ?both proteins? and ?either protein?.
8GENE, PROTEIN, and DOMAIN indicate a gene name,
a protein name, and a generic term indicating protein domain
such as domain and subunit, respectively. DEFINITE indicates
the definite article the.
9The digit in parentheses indicates the number of non-
anaphoric DNPs in each class, among 117 DNPs in 390 bio-
logical interactions.
1. (39) DNP modified by a prepositional
phrase or a relative clause (Ex. the C-
terminal of AF9)
2. (24) DNP of the pattern ?DEFINITE
GENE protein? (Ex. the E6 protein)
3. (16) DNP with appositive structure (Ex.
the yeast transcriptional activator
Gcn4)
4. (10) DNP ending with acronyms (Ex. the
retinoid X receptor (RXR))
5. (6) DNP of the pattern ?DEFINITE PRO-
TEIN DOMAIN? (Ex. the DNA-PK
catalytic subunit)
6. (4) DNP indicating a cellular component
(Ex. the nucleus)
7. (2) DNP indicating a species name (Ex.
the yeast Saccharomyces cerevisiae)
Table 7: Non-anaphoric DNP examples
anaphoric DNP with various salience measures and
identifies the candidate antecedent with the highest
score as the antecedent of the anaphoric DNP (cf.
Castano et al (2002)). For example, the system as-
signs penalties to the candidate antecedents whose
numbers do not agree with those of anaphoric DNPs.
Among the candidate antecedents of anaphoric
DNPs, the candidate antecedents in the sentential
subjects are preferred to those in the sentential ob-
jects or other noun phrases, following the center-
ing theory (Grosz et al, 1995). We have also
adopted salience measures to score each candidate
antecedent according to the morphological, syntac-
tic, and semantic characteristics of candidate an-
tecedents (cf. Castano et al (2002)). For example,
when a DNP refers to a protein, its candidate an-
tecedents which refer to protein domains get nega-
tive scores, and when a DNP refers to a protein do-
main, its candidate antecedents which refer to pro-
tein domains get positive scores. Furthermore, when
a DNP refers to an enzyme, its candidate antecedents
which end with ?-ase? get positive scores.
In the process of resolving the anaphoric DNPs
referring to protein domains, the system identifies
the proteins which contain the domains referred to
by the anaphoric expressions. We have constructed
several syntactic patterns which describe the rela-
1. DOMAIN of  in PROTEIN
2. PROTEIN BeV NN composed of DOMAIN
3. PROTEIN BeV NN comprising DOMAIN
4. PROTEIN contain DOMAIN
5. the PROTEIN DOMAIN
Table 8: Example patterns of proteins and their do-
mains
tionships between proteins and their domains as ex-
emplified in Table 8.
The system locates the coordinate noun phrases
with conjunction items such as ?and?, ?or?, and
?as well as? as the candidate antecedents of plural
anaphoric expressions. The system also locates the
proteins in the same protein family in the same doc-
ument, as in MEK1 and MEK2, as the candidate
antecedent of a plural anaphoric expression such as
these MEKs (PMID:11134045).
2.3 Biological interaction resolution
BioAR also restores some of the missing argu-
ments of interaction keywords by utilizing the con-
text. When one or more syntactic arguments of
biological interactions in the results of BioIE are
elided, it is essential to identify the antecedents of
the omitted arguments of the interactions, or null
anaphora, as well. We have focused on resolving the
missing arguments of nominal interaction keywords,
such as interaction, association, binding, and co-
immunoprecipitate,10 based on the observation that
those keywords mostly represent protein-protein in-
teractions, and thus their omitted arguments refer to
proteins or protein domains in the previous context.
In case only one argument of an interaction keyword
is elided as in the first example in Table 2, the pro-
teins in the sentential subjects are preferred as an-
tecedents to those in other noun phrases of the sen-
tences which contain the interaction keyword. In
case both arguments of an interaction keyword are
elided as in the second example in Table 2, both the
sentences, whose main verbs are in the verbal form
10The interaction keywords of interest, interaction, asso-
ciation, binding, and co-immunoprecipitate, indicate physical
binding between two proteins, and thus they can be replaced
with one another. In addition to them, the interaction keywords
phosphorylation and translocation also often indicate protein-
protein interactions.
1. interaction of A with B
2. association of A with B
3. co-immunoprecipitation of A with B
4. binding of A to B
5. interaction between  among A and B
6. association between  among A and B
7. co-immunoprecipitation between  among A and B
8. binding between  among A and B
Table 9: Example patterns of nominal interaction
keywords
(7) Interactions among the three MADS domain
proteins were confirmed by in vitro exper-
iments using GST-fused OsMADS1
expressed in Escherichia coli and in vitro
translated proteins of OsMADS14 and
-15.  While the K domain was essential
for protein-protein interaction, a region
preceded by the K domain augmented this
interaction. (PMID:11197326)
Table 10: An example antecedent of a nominal in-
teraction keyword
of the interaction keyword, and the noun phrases of
the patterns in Table 9, whose headwords are the
same as the interaction keyword, can be the candi-
date antecedents of the interaction keyword with its
two missing arguments. Table 10 shows an example
antecedent with a nominal interaction keyword.
2.4 Protein name grounding
We have constructed around 0.7 million gene and
protein names from the gene name (GN) and de-
scription (DE) fields of Swiss-Prot in order to rec-
ognize protein names in the literature. We have also
developed several patterns to deal with the variations
of protein names (cf. Table 11). Table 12 shows
several examples of grounding protein names with
Swiss-Prot entries.11
Taking into account the fact that many Swiss-
Prot entries actually indicate certain domains of
bigger proteins, for example Casein kinase II beta
chain (KC2B YEAST) and Ribonuclease P protein
11The terms of the form A B, where B indicates the species
information, are Swiss-Prot entries.
Swiss-Prot term Variation
D(2) D2
S-receptor kinase S receptor kinase
RNase P protein RNase P
Thioredoxin h-type 1 Thioredoxin h (THL1)
Table 11: Term variation examples
Protein name Swiss-Prot entries
Filamin A FLNA HUMAN, FLNA MOUSE
Pop1p POP1 HUMAN, POP1 SCHPO,
POP1 YEAST
D3 dopamine D3DR CERAE, D3DR HUMAN,
receptor D3DR MOUSE, D3DR RAT
Table 12: Protein name grounding examples
component (RPM2 YEAST), BioAR grounds the
phrases in the results of BioIE, which refer to pro-
tein domains, with the descriptions of Swiss-Prot
entries, by converting those phrases into the struc-
tures as utilized by Swiss-Prot. For example, the
phrase ?the regulatory beta-subunit of casein kinase
II (CKII)? can be grounded with KC2B YEAST,
and the phrase ?the individual protein subunits of
eukaryotic RNase P? with RPM2 YEAST. Further-
more, the information about the domains of a pro-
tein is sometimes described in the SUBUNIT field of
Swiss-Prot. For example, the protein domain name
?the RNA subunit of RNase P? can be grounded with
RPM1 in the SUBUNIT field of RPM2 YEAST, i.e.
?Consists of a RNA moiety (RPM1) and the protein
component (RPM2). Both are necessary for full en-
zymatic activity.? We leave the problem of looking
up the SUBUNIT field of Swiss-Prot as future work.
Since a protein name can be grounded with multi-
ple Swiss-Prot entries as shown in Table 12, BioAR
tries to choose only one Swiss-Prot entry, the most
appropriate one for the protein name among the
candidate entries, by identifying the species of the
protein from the context (cf. Hachey et al (2004)).
For example, while the protein name Rpg1p/Tif32p
can be grounded with two Swiss-Prot entries, or
	 IF3A SCHPO, IF3A YEAST 
 , the noun phrase
?Saccharomyces cerevisiae Rpg1p/Tif32p? should
be grounded only with IF3A YEAST. Similar-
ily, the system grounds the protein name Sla2p
(8) The yeast two-hybrid system was used to
screen for proteins that interact in vivo with
Saccharomyces cerevisiae Rpg1p/Tif32p,
the large subunit of the translation initia-
tion factor 3 core complex (eIF3). Eight
positive clones encoding portions of the
SLA2/END4/MOP2 gene were isolated.
Subsequent deletion analysis of Sla2p
showed that amino acids 318-373 were
essential for the two-hybrid protein-protein
interaction. (PMID:11302750)
Table 13: An annotation example for the necessity
of species information
only with SLA2 YEAST among candidate Swiss-
Prot entries, or 	 SLA2 HUMAN, SLA2 MOUSE,
SLA2 YEAST 
 , when the protein name occurs to-
gether with the species name Saccharomyces cere-
visiae in the same abstract as in Table 13.
In summary, BioAR first locates anaphoric noun
phrases, such as pronouns and anaphoric DNPs, and
interaction keywords that appear in the results of
BioIE, while it filters out non-anaphoric DNPs and
the interaction keywords with two explicit syntac-
tic arguments. The system identifies the antecedents
of pronouns by utilizing patterns for parallelism and
by following the observation in the centering theory.
The system identifies the antecedents of anaphoric
DNPs by utilizing various salience measures. In
particular, the system identifies the proteins which
contain the protein domains referred to by anaphoric
expressions. The system restores the missing argu-
ments of biological interactions from the context.
Finally, the system grounds the protein-referring
phrases in the results of BioIE with the most appro-
priate Swiss-Prot entry or entries.
3 Experimental results
We have developed BioAR with a training corpus
consisting of 7,570 biological interactions that are
extracted by BioIE from 1,505 MEDLINE abstracts
on yeast (cf. Kim and Park (2004)). BioAR takes
24 seconds to process 1,645 biological interactions
in the training corpus. We have constructed a test
corpus which is extracted from MEDLINE with a
different MeSH term, or topoisomerase inhibitors.
SOURCE
PMID 10022855
Sentence Gadd45 could potentially mediate
this effect by destabilizing histone-
DNA interactions since it was
found to interact directly with the
four core histones.
INTERACTION
Keyword interact
Argument1 it
Argument2 the four core histones
PRONOUN RESOLUTION
Anaphor it
Antecedent Gadd45
PROTEIN NAME GROUNDING
Phrase Gadd45
S-P entry GA45 HUMAN
Table 14: An example result of BioAR
Precision Recall
Pronoun resolution 75.0% 56.3%
(9/12) (9/16)
Noun phrase resolution 75.0% 52.2%
(12/16) (12/23)
Protein name grounding 59.5% 40.7%
(22/37) (22/54)
Table 15: Experimental results of test corpus
The test corpus includes 120 unseen biological in-
teractions extracted by BioIE. Table 15 shows the
experimental results of the modules of BioAR on the
test corpus.12 Table 14 shows an example result of
BioAR.
4 Discussion
We have analyzed the errors from each module of
BioAR. All the incorrect antecedents of pronouns
12While the missing arguments of biological interactions of-
ten occur in the training corpus, there was only one missing ar-
gument in the test corpus, which is correctly restored by BioAR.
This result is included into those of noun phrase resolution.
Moreover, the rules and patterns utilized by BioAR show a
low coverage in the test corpus. It would be helpful to uti-
lize a machine-learning method to construct such rules and pat-
terns from the training corpus, though there are few available
anaphora-tagged corpora.
(10) These triterpenoids were not only mam-
malian DNA polymerase inhibitors but
also inhibitors of DNA topoisomerases I
and II even though the enzymic charac-
teristics of DNA polymerases and DNA
topoisomerases, including their modes of
action, amino acid sequences and three-
dimensional structures, differed markedly.
... Because the three-dimensional struc-
tures of fomitellic acids were shown by
computer simulation to be very similar
to that of ursolic acid, the DNA-binding
sites of both enzymes, which compete
for the inhibitors, might be very similar.
(PMID:10970789)
Table 16: Incorrect resolution example of pronoun
resolution module
in the test corpus produced by the pronoun resolu-
tion module are due to incorrect named entity recog-
nition, as in the incorrectly identified named en-
tity ?DNA double-strand? from the phrase ?DNA
double-strand break (DSB)? and ?-II? in ?topo-I or
-II.? This problem can be dealt with by a domain-
specific POS tagger and a named entity recog-
nizer. Further semantic analysis with the help of
the context is needed to deal with the errors of
noun phrase resolution module. For example, ?these
triterpenoids? in Table 16 are inhibitors, and thus it
can be a candidate antecedent of the anaphoric DNP
the inhibitors.
In the process of protein name grounding,
BioAR grounds 8 abbreviations among 15 incor-
rectly grounded protein-referring phrases with irrel-
evant Swiss-Prot entries. Furthermore, among 32
protein-referring phrases not grounded by BioAR,
14 phrases are the same as the string topoisomerase
where the string always indicates ?DNA topoiso-
merase? in the corpus of topoisomerase inhibitors.
To address this problem, we need domain-specific
knowledge, which we leave as future work.
Castano et al (2002) presented a knowledge-poor
method to utilize salience measures, including parts-
of-speech, positions of the candidate antecedents,
agreements and lexical features. While the method
reportedly shows a relatively high performance of
77% precision and 71% recall, we note that the
method is unable to deal with domain-specific
anaphora resolution, for example the task of identi-
fying the proteins which contain the protein domains
referred to by anaphoric expressions.
Leidner et al (2003) presented the method of
grounding spatial named entities by utilizing two
minimality heuristics, that is, that of assuming one
referent per discourse and that of selecting the
smallest bounding region in geographical maps.
Hachey et al (2004) presented a method for ground-
ing gene names with respect to gene database identi-
fiers by dealing with various kinds of term variations
and by removing incorrect candidate identifiers with
statistical methods and heuristics. These methods
are similar to BioAR in that they also aim to ground
the phrases in texts with respect to the entities in the
real world. However, BioAR further contributes to
biomedical named entity grounding by dealing with
the relationships between proteins and their domains
and by identifying the species information of protein
names from the context.
5 Conclusion
BioAR identifies the antecedents of anaphoric noun
phrases that appear in the results of BioIE. The sys-
tem further identifies the proteins which contain the
domains referred to by anaphoric expressions by
utilizing several patterns which describe their rela-
tions. The system also identifies the missing argu-
ments of biological interactions by utilizing biologi-
cal interaction patterns. Finally, the system grounds
the protein-referring phrases with the most relevant
Swiss-Prot entries by consulting the species infor-
mation of the proteins.
We believe that anaphora resolution with database
entries may not be addressed in other domains as
straightforwardly as in this paper, since there are
quite few comprehensive resources with actual en-
tities. The task of grounding the protein-referring
phrases in the results of BioIE with Swiss-Prot en-
tries is crucial to building up incorporated protein
pathways consisting of the biological interactions
extracted by BioIE. We are currently working on in-
tegrating BioIE, BioAR, and other systems for on-
tology manipulation and information visualization
for synergistic knowledge discovery.
Acknowledgement
We are grateful to the anonymous reviewers and to
Bonnie Webber for helpful comments. This work
has been supported by the Korea Science and Engi-
neering Foundation through AITrc.
References
Byron, D.K. 2002. Resolving pronominal reference to
abstract entities. Proc. ACL, 80?87.
Castano, J., Zhang, J., and Pustejovsky, J. 2002.
Anaphora resolution in biomedical literature. Int?l
Symp. Reference Resolution in NLP, Alicante, Spain.
Grosz, B.J., Joshi, A.K., and Weinstein, S. 1995. Center-
ing: A framework for modelling the local coherence of
discourse. Computational Linguistics, 203?225.
Hachey, B., Nguyen, H., Nissim, M., Alex, B., and
Grover, C. 2004. Grounding gene mentions with re-
spect to gene database identifiers. Proc. the BioCre-
ative Workshop, Granada, Spain.
Hong, K.W. and Park, J.C. 2004. Anaphora Resolution
in Text Animation. Proc. the IASTED International
Conference on Artificial Intelligence and Applications
(AIA), pp. 347?352, Innsbruck, Austria.
Kim, J.-J. and Park, J.C. 2004. BioIE: retargetable in-
formation extraction and ontological annotation of bi-
ological interactions from the literature. J. Bioinfor-
matics and Computational Biology. (to appear)
Leidner, J.L., Sinclair, G., and Webber, B. 2003.
Grounding spatial named entities for information
extraction and question answering. Proc. the
HLT/NAACL?03 Workshop on the Analysis of Geo-
graphic References, Edmonton, Alberta, Canada, May.
Mitkov, Rulsan. 1998. Robust pronoun resolution with
limited knowledge. Proc. COLING/ACL, 869?875.
Ono, T., Hishigaki, H., Tanigami, A., and Takagi,
T. 2001. Automated extraction of information on
protein-protein interactions from the biological liter-
ature. Bioinformatics, 17(2):155?161.
Park, J.C., Kim, H.S., and Kim, J.J. 2001. Bidirectional
incremental parsing for automatic pathway identifica-
tion with Combinatory Categorial Grammar. Proc.
PSB, 396?407.
