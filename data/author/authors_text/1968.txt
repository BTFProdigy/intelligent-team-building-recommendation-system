A Spoken Dialogue Interface to a Geologist?s Field Assistant
John Dowding and James Hieronymus
Mail Stop T-27A-2
NASA Ames Research Center
Moffett Field, CA 94035-1000
{jdowding,jimh}@riacs.edu
Abstract
We will demonstrate a spoken dialogue inter-
face to a Geologist?s Field Assistant that is
being developed as part of NASA?s Mobile
Agents project. The assistant consists of a
robot and an agent system which helps an as-
tronaut wearing a planetary space suit while
conducting a geological exploration. The pri-
mary technical challanges relating to spoken
dialogue systems that arise in this project are
speech recognition in noise, open-microphone,
and recording voice annotations. This system
is capable of discriminating between speech in-
tended for the system and for other purposes.
1 Introduction
The Geologist?s Field Assistant is one component of Mo-
bile Agents, a NASA project studying technologies, tech-
niques, and work practices for sophisticated human-agent
and human-robot cooperation in space and planetary ex-
ploration environments, such as the surface of Mars. The
evolution, development and evaluation of this project oc-
curs in a series of increasingly complex field tests in Mars
analog environments (deserts and artic sites) on Earth.
The Spoken Dialogue component assists an astronaut
wearing a space suit while conducting a geological ex-
ploration, by tagging samples by spoken discriptions,
commanding the taking of pictures, recording descriptive
voice annotations, and tracking the associations between
these samples, images, and annotations. The assistant
will also help track the astronaut?s location and progress
though the survey, and help track their body exertion level
(heart and respiration rate).
The Spoken Dialogue interface is one of several of Mo-
bile Agents, each with different goals and evaluation met-
rics. Other components include: Brahms work-practice
modelling and simulation system (NASA Ames); MEX
mobile wireless networking (Ames); robots (Johnson
Space Center (JSC) and Georgia Tech); Spacesuits (JSC)
Start tracking my g p s coordinates.
Start logging my bio sensors every fifteen seconds.
Where is my my current location?
Call this location Asparagus.
Create a new sample bag and label it sample bag three.
Take a voice note
Please begin recording voice note now:
This sample originated in a dry creek bed. [pause]
Would you like to continue recording the voice note?
no
Voice note has been created.
Associate that voice note with sample bag three.
Play the voice note associated with sample bag three.
Table 1: Example utterances
and Biomedical sensors (Stanford University); Satellite
Internet services (Goddard Space Flight Center); and Ge-
ologists (US Geological Survey).
The primary technical challanges relating to spoken
dialogue systems that arise in this project are open-
microphone speech recognition and understanding which
decides which agent receives, and responds to a particular
utterance and space suit noise.
2 Example Dialogue
The language capabilities developed so far are largely di-
rect commanding with the user controlling task initiative.
A sample of user commands is given in Table 1. A system
response is always given, but is usually omitted below for
the sake of brevity. When given, the system response ap-
pears in italics.
3 Architecture
This spoken dialogue system shares a common architec-
ture with several prior systems: CommandTalk (Stent et
al., 1999), PSA (Rayner et al, 2000), WITAS (Lemon et
al., 2001), and the Intelligent Procedure Assistant (Aist
et al, 2002). The architecure has been well described in
                                                               Edmonton, May-June 2003
                                                             Demonstrations , pp. 9-10
                                                         Proceedings of HLT-NAACL 2003
prior work. The critical feature of the architecture rel-
evant to this work is the use of a grammar-based lan-
guage model for speech recognition that is automatically
derived from the same Unification Grammar that is used
for parsing and interpretation.
4 Data Collection
The Mobile Agents project conducted two field tests in
2002: a one week dress rehearsal at JSC in the Mars yard
in May, and a two week field test in the Arizona desert
in September, split between two sites of geological inter-
est, one near the Petrified Forest National Park, and the
other on the ejecta field at Meteor Crater. We collected
approxmimately 5,000 recorded sound files from 8 sub-
jects during the September tests, some from space-suit
subjects, and the rest in shirt-sleeve walk-throughs (still
a high wind condition). We transcribed 1059 wave files.
All conditions were performed open-mic and all sounds
that were picked up by the microphone were recorded, so
not all of these files contained within-domain utterances
intended. Of the transcribed sound files, 208 contained
no speech (mostly wind noise) and 243 contained out-of-
domain speech that was intended for other hearers. That
left 608 within-domain utterances that were split 80%-
20% into test and training utterances.
5 Technical Challanges
The Geologist?s Field Assitant requires the ability to
make voice notes that can be stored and transmitted.
We implemented this by adding a recording mode to
the speech recognizer agent, and temporarily increas-
ing the speech end-pointing interval. This allows us to
record multi-sentence voice notes without treating inter-
sentence pauses as end-of-voice-note markers. Entering
recording mode is triggered by specific speach acts like
Take a voice note or Annotate sample bag one.
When considering recognition accuracy in the open-
mic condition, we consider additional metrics beyond
word-error rate (WER). Since the recognizer can fail to
find a hypothesis for an utterance, we compute the false-
rejection rate (FREJ) for within-domain utterances and
adjusted word-error (AWER) counting only the word er-
rors on the non-rejected utterances. We also consider
misrecognitions of out-of-domain utterance as within-
domain, and compute the false-accept rate (FACC). Table
2 gives the performance results for the grammar-based
language model that was used in the September test. This
model gives reasonable performance on within-domain
utterances, but falsely accepts 25.5% of out-of-domain
utterances. After the September test, we used the training
data we had collected to build a Probabilistic Context-
Free Grammar using the compute-grammar-probs
tool that comes with Nuance (Nuance, 2002). Using only
485 utterances of training data, there was improvement
in both the AWER and FACC rates, resulting in a lan-
guage model where both FREF and FACC were under
10%. There was also a substantial improvement in recog-
nition speed, as measured in multiples of CPU real-time.
Version WER FREJ AWER FACC xCPUrt
(%) (%) (%) (%) (%)
Baseline CFG Language Model
Training 12.56 4.54 7.72 ? 58.9
Test 9.5 3.25 7.5 25.5 57.5
Probabilistic CFG Language Model
Training 9.97 5.57 4.6 ? 19.4
Test 8.99 7.32 3.7 9.09 19.0
Table 2: Comparing Baseline and Probabilistic CFG
6 Conclusions
We will demonstrate a dialogue system that has an im-
proved ability to discriminate between speech that is in-
tended for different purposes, treating some as data ob-
jects to be saved, and others identified as being out-of-
domain. With probabilities on the rules the system has an
acceptably low false accept rate and is fast and accurate.
References
G. Aist, J. Dowding, B.A. Hockey, and J. Hieronymus.
2002. An intelligent procedure assistant for astro-
naut training and support. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics (demo track), Philadelphia, PA.
O. Lemon, A. Bracy, A. Gruenstein, and S. Peters. 2001.
Multimodal dialogues with intelligent agents in dy-
namic environments: the WITAS conversational in-
terface. In Proceedings of 2nd Meeting of the North
American Association for Computational Linguistics,
Pittsburgh, PA.
Nuance, 2002. http://www.nuance.com. As of 15
November 2002.
M. Rayner, B.A. Hockey, and F. James. 2000. A com-
pact architecture for dialogue management based on
scripts and meta-outputs. In Proceedings of the 6th Ap-
plied Natural Language Processing Conference, Seat-
tle, WA.
A. Stent, J. Dowding, J. Gawron, E. Bratt, and R. Moore.
1999. The CommandTalk spoken dialogue system. In
Proceedings of the Thirty-Seventh Annual Meeting of
the Association for Computational Linguistics, pages
183?190.
Building a Robust Dialogue System with Limited Data * 
Sharon  J .  Go ldwater ,  E l i zabeth  Owen Brat t ,  Jean  Mark  Gawron ,  and  John  Dowdingt  
, .  SR I  In ternat iona l  
333 Ravenswood Avenue 
Men lo  Park ,  CA 94025 
{goldwater, owen, gawron, dowding} @ai.sri.cora 
Abst ract  
We describe robustness techniques used in the Com- 
mandTalk system at: the recognition level, the pars- 
ing level, and th~ dia16gue level, and how these were 
influenced by the lack of domain data. We used 
interviews with subject matter experts (SME's) to 
develop a single grammar for recognition, under- 
standing, and generation, thus eliminating the need 
for a robust parser. We broadened the coverage of 
the recognition grammar by allowing word insertions 
and deletions, and we implemented clarification and 
correction subdialogues to increase robustness at the 
dialogue level. We discuss the applicability of these 
techniques to other domains. 
1 I n t roduct ion  
Three types of robustness must be considered when 
designing a dialogue system. First, there is robust- 
ness at the recognition level. When plentiful data 
is available, a robust n-gram language model can be 
produced, but when data is limited, producing a ro- 
bust language model for recognition can be prob- 
lematic. Second, there is robustness at the level 
of the parser. Robust parsing is often achieved by 
combining a full parser with a partial parser and 
fragment-combining rules, but even then some utter- 
ances may be correctly recognized, only to be parsed 
incorrectly or not at all. Finally, there is robustness 
at the dialogue level. Utterances may be uninter- 
pretable within the context of the dialogue due to 
errors on the part of either the system or the user, 
and the dialogue manager should be able to handle 
such problems gracefully. 
Our CommandTalk dialogue system was designed 
for a highly specialized omain with little available 
data, so finding ways to build a robust system with 
* This research was supported by the Defense Advanced Re- 
search Projects Agency under Contract N66001-94-C-6046 
with the Space and Naval Warfare Systems Center. The views 
and conclusions contained in this document are those of the 
authors and should not be interpreted asnecessarily repre- 
senting the official policies, either express or implied, of the 
Defense Advanced Research Projects Agency of the U.S. Gov- 
ernment. 
? Currently affiliated with GO.corn 
limited data was a major concern. In this paper, 
we discuss our methods and their applicability to 
other domains. Section 2 gives a brief overview of 
the CommandTalk system. In Section 3, we discuss 
the approach we took to building recognition, under- 
standing, and generaffon models for CommandTalk, 
and how it relates to the first two types of robustness 
mentioned. Section 4 discusses additional robust- 
ness techniques at the recognizer level, and Section 5 
describes dialogue-level robustness techniques. Sec- 
tion 6 discusses the applicability of our methods to 
other domains. 
2 CommandTa lk  
CommandTalk is a spoken-language interface to the 
ModSAF (Modular Semi-Automated Forces) battle- 
field simulator, developed with the goal of allow- 
ing military commanders to interact with simulated 
forces in a manner as similar as possible to the way 
they would command actual forces. CommandTalk 
allows the use of ordinary English commands and 
mouse gestures to 
? Create forces and control measures (points and 
lines) 
? Assign missions to forces 
? Modify missions during execution 
? Control ModSAF system functions, such as the 
map display 
? Get information about the state of the simula- 
tion 
CommandTalk consists of a number of indepen- 
dent, cooperating agents interacting through SRI's 
Open Agent Architecture (OAA) (Martin et al, 
1998). OAA uses a facilitator agent that plans and 
coordinates interactions among agents during dis- 
tributed computation. An introduction to the basic 
CommandTalk agents can be found in Moore et al 
(1997). CommandTalk's dialogue component is de- 
scribed in detail in Stent et al (1999), and its use 
of linguistic and situational context is described in 
Dowding et al (1999). 
61 
3 The  One-Grammar  Approach  
In a domain with limited data, the inability to col- 
lect a sufficient corpus for training a statistical lan- 
guage model can be a significant problem. For 
CommandTalk, we did not create a statistical lan- 
guage model. Instead, with information gathered 
from interviews of subject matter experts (SME's), 
we developed a handwritten grammar using Gemini 
(Dowding et al, 1993), a unification-based gram- 
mar formalism. We used this unification grammar 
for both natural language understanding and gener- 
ation, and, using a grammar compiler we developed, 
compiled it into a context-free form suitable for the 
speech recognizer as well. 
The effe~s_ of this single-grammar pproach on 
the robustness of the CommandTalk system were 
twofold. On the negative side, we presumably ended 
up with a recognition language model with less cov- 
erage than a statistical model would have had. Our 
attempts to deal with this are discussed in the next 
section. On the positive side, we eliminated the 
usual discrepancy incoverage between the recognizer 
and the natural language parser. This was advanta- 
geous, since no fragment-combining or other parsing 
robustness techniques were needed. 
Our approach ad other advantages a well. Any 
changes we made to the understanding grammar 
were automatically reflected in the recognition and 
generation grammars, making additions and modifi- 
cations efficient. Also, anecdotal evidence suggests 
that the language used by the system often influ- 
ences the language used by speakers, o maintaining 
consistency between the input and output of the sys- 
tem is desirable. 
4 Ut terance-Leve l  Robustness  
It is difficult o write a grammar that is constrained 
enough to be useful without excluding some rea- 
sonable user utterances. To alleviate this prob- 
lem, we modified the speech recognition grammar 
and natural language parser to allow certain "close- 
to-grammar" utterances. Utterances with inserted 
words, such as Center on Checkpoint 1 now or zoom 
way out (where Center on Checkpoint 1 and zoom 
out are grammatical) were permitted by allowing 
the recognizer to skip unknown words. We also al- 
lowed utterances with deleted words, as long as those 
words did not contribute to the semantics of the ut- 
terance as determined by the Gemini semantic rules 
constraining logical forms. For example, a user could 
say, Set speed, 40 kph rather than Set speed to 40 kph. 
The idea behind these modifications was to allow ut- 
terances with a slightly broader ange of wordings 
than those in the grammar, but with essentially the 
same meanings: 
We began by testing the effects of these modi- 
fications on in-grammar utterances, to ensure that 
Time, CPURT 
SRR 
AWER 
SER 
Non-Robust Robust 
0.664 : 1.05 
2.56% 1.70% 
1.68% 2.94% 
10.00% ~ 12.07% 
Table 1: In-Grammar Recognition Results 
they did not significantly decr egse recognition per- 
formance. We used a small test corpus of approxi- 
mately 800 utterances read by SRI employees. We 
collected four measures of performance: 
? Recognition time, measured, in multiples of 
CPU real time (CPURT). A recognition time 
of lxCPURT means that on,our CPU (a Sun 
Ultra2), recognition took exactly as~ long as the 
duration of the utterance. : 
? Sentence reject rate (SRR).' The percentage of 
sentences that the recognizer rejects. 
? Adjusted word error rate (A:WER). The per- 
centage of words in non:rejected sentences that 
are misrecognized. 
? Sentence rror rate (SER). The percentage of 
sentences in which some sort of error occurred, 
either a complete rejection or misrecognized 
word. 
Several parameters affected the results, most no- 
tably the numerical penalties assigned for inserting 
or deleting words, and the pruning threshold of the 
recognizer. Raising the pruning threshold caused 
both reject and error rates to go down, but slowed 
recognition. Lowering the penalties caused rejection 
rates to go down, but word and Sentence rror rates 
to go up, since some sentences which had been re- 
jected were now recognized partially correctly, and 
some sentences which had been recognized correctly 
now included some errors. Lowering the penalties 
also led to slower recognition. 
Table 1 shows recognition results for the non- 
robust and robust versions 0f the recognition gram- 
mar on in-grammar utterances: Th e pruning thresh- 
old is the same for both versions and the insertion 
and deletion penalties are set to intermediate val- 
ues. Recognition times for the robust grammar are 
about 60% slower than those of the control gram- 
mar, but still at acceptable l vels. Reject and error 
rates are fairly close for the two grammars. Overall, 
adding robustness to the recognition grammar did 
not severely penalize in-grammar recognition per- 
formance. 
We had very little out-of-grammar data for Com- 
mandTalk, and finding subjects in this highly spe- 
cialized domain would have been difficult and ex- 
pensive. To test our robustness techniques on out- 
62 
of-grammar utterances, we decided to port them 
to another domain with easily accessible users and 
data; namely, the ATIS air travel domain. We wrote 
a small grammar covering part of the ATIS data 
and ,compiled it into a recognition grammar using 
the same techniques as in CommandTalk. Unfortu- 
nately, we were unable to carry out any experiments, 
because the recognition grammar we derived yielded 
recognition times that were so slow as to be imprac- 
tical. We discuss these results further in Section 6. 
5 Diaiogue-Level Robustness 
To be considered robust at the dialogue level, a sys- 
tem must be able to deal with situations where an 
utterance is recognized and parsed, but cannot be in- 
terpreted withi~4he current system state or dialogue 
context. In addition~it must be easy for the user to 
correct faulty interpretations on the part of the sys- 
tem. Contextual interpretation problems may occur 
for a variety of reasons, including misrecognitions, 
incorrect reference resolution, and confusion or in- 
completeness on the part of the user. 
The CommandTalk dialogue manager maintains 
a Stack to ~keep 'track of the current discourse con- 
text and uses small finite-state machines to represent 
different~ types of subdialogues. Below we illustrate 
some types of  subdialogues and other techniques 
which provide robustness at the dialogue level. Note 
that for each utterance, we write what the system 
recognizes, not what the user actually says. 
5.1 Correction Subdlalogues 
Sx? 1: 
U 1 :Create a CEV at 76 53 
S 2 ?. 
U 3 Put Objective Golf here <click> 
S 4 ? I will locate Objective Golf at FQ 
? 658 583 
U 5 I said Objective Alpha 
S 6 ? I will locate Objective Alpha at FQ 
658 853 
Allowing the user to correct full or partial utterances 
can remedy interpretation problems caused by mis- 
recognitions, incorrect reference resolution, or user 
error. 
In Example 1, the system responds to the user's 
first utterance by producing a rising tone, illustrated 
by the ? symbol, to indicate successful interpreta- 
tion and execution of the command, in this case cre- 
ation of a CEV, a type of vehicle. (Unsuccessful 
interpretation is indicated by a falling tone, illus- 
trated by the ? symbol.) In utterances 3 through 
6, a misrecognition causes the system to perform 
the wrong behavior. The user initiates a correction 
subdialogue, and the system goes on to correctly re- 
interpret he full utterance. 
5.2 Impl ic i t  Conf i rmat ion  
Ex. 2: 
U 7 CEV, advance to Checkpoint 1 
S 8 ? 100All will proceed to Checkpoint 
1 
Use of implicit confirmation in combination with 
correction subdialogues makes it easy to correct 
faulty interpretations as soon as possible by alert- 
ing the user to possible sources of error. 
In utterances 7 and 8, the system must resolve 
the user's reference, "CEV", to a particular unit. 
It therefore choes the user's command using the 
CEV's unique call sign. This makes explicit the sys- 
tem's interpretation of the user's utterance, giving 
the user a chance to correct he system if necessary. 
Note that utterance 4 also contains an implicit 
confirmation, since the system has resolved the 
user's gesture to a set of coordinates. 
5.3 C lar i f i ca t ion  Subd ia logues  
Ex.  3: 
U 9 
S 10 
U 11 
Create a CEV at 72 69 
? 
CEV, conduct crater breach facing- 
south 
S 12 ? There are two CEV's. Do you mean 
100All or 100A12? 
U 13 A12 
S 14 ? Which point should 100A12 conduct 
crater breach oriented south at? 
U 15 Checkpoint 2 
S 16 ? There is no Checkpoint 2. Which 
point should 100A12 conduct crater 
breach oriented south at? 
U 17 I meant Checkpoint 1 
S 18 ? 100A12 will conduct crater breach 
oriented south at Checkpoint 1 
Clarification subdialogues are generally initiated by 
the system as a result of errors or incomplete com- 
mands on the part of the user. 
Example 3 illustrates three different ypes of prob- 
lems that can be corrected by system questions. 
First, the user's reference to "CEV" in utterance 
11 is ambiguous, so the system asks a question to 
determine which CEV the user is referring to. Next, 
the system asks the user to supply a missing piece 
of information that is required to carry out the com- 
mand. Finally, when the user makes an error by 
referring to a point that doesn't exist, the system 
prompts for a correction. 
6 Discussion and Conclusions 
CommandTalk is an example of a successful and ro- 
bust dialogue system in a domain with limited ac- 
63 
cess to both data and subjects. The pre-dialogue 
version of CommandTalk was used in the STOW 
(Synthetic Theater of War) '97 ACTD (Advanced 
Concept Technology Demonstration) exercise, an in- 
tensive 48-hour continuous military simulation by 
all four U.S. military services, and received high 
praise. The dialogue portion of the system has in- 
creased CommandTalk's usefulness and robustness. 
Nevertheless, everal questions remain, not the least 
of which is whether the robustness techniques used 
for CommandTalk can be successfully transferred to 
other domains. 
We have no doubt that our methods for adding ro- 
bustness at the dialogue level can and should be im- 
plemented in other domains, but this is not as clear 
for our parsing a-nd recognition robustness methods. 
The one-grammar approach is key to our elimi- 
nating the necessity for robust parsing, renders a 
large corpus for generating a recognition model un- 
necessary, and has other advantages as well. Yet 
our experience in the ATIS domain suggests that 
further research into this approach is needed. Our 
ATIS grammar is based on a grammar of general 
English and has a very different structure from that 
of CommandTalk's semantic grammar, but we were 
unable to isolate the factor or factors responsible for 
its poor recognition performance. Recent research 
(Rayner et al, 2000) suggests that it may be pos- 
sible to compile a useful recognition model from a 
general English unification grammar if the gram- 
mar is constructed carefully and a few compromises 
are made. We also believe that using an appropri- 
ate grammar approximation algorithm to reduce the 
complexity of the recognition model may prove fruit- 
ful. This would reintroduce some discrepancy be- 
tween the recognition and understanding language 
models, but maintain the other advantages of the 
one-grammar pproach. 
In either case, the effectiveness of our recognition 
robustness techniques remains an open question. We 
know they have no significant negative impact on in- 
grammar ecognition, but whether they are helpful 
in recognizing and~ more importantly, interpreting 
out-of-grammar utterances is unknown. We have 
been unable to evaluate them so far in the Com- 
mandTalk or any other domain, although we hope 
to do so in the future. 
Another possible solution to the problem of 
producing a workable robust recognition grammar 
would return to a statistical approach rather than 
using word insertions and deletions. Stolcke and 
Segal (1994) describe a method for combining a 
context-free grammar with an n-gram model gen- 
erated from a small corpus of a few hundred utter- 
ances to create a more accurate n-gram model. This 
method would provide a robust recognition model 
based on the context-free grammar compiled from 
64 
our unification grammar. We would'still have to 
write only one grammar for the system, it would still 
influence the recognition model, and we could still 
be sure that the system would never say anything it 
couldn't recognize. This approach Would require us- 
ing robust parsing methods, but might be the best 
solution for other domains if compiling a practical 
recognition grammar proves too difficult. 
Despite the success of the CommandTalk system, 
it is clear that more investigation is called for to 
determine how best to develop dialogue systems in 
domains with limited data. Researchers must de- 
termine which types of unification grammars can be 
compiled into practical recognition grammars using 
existing technology, whether grammar approxima- 
tions or other techniques can produce good results 
for a broader range of grammars, whether allow- 
ing word insertions and deletions is an effective ro- 
bustness technique, orwhether we should use other 
methods altogether. 
Re ferences  
J. Dowding, J. Gawron, D. Appelt, L. Cherny, 
R. Moore, and D. Moran. 1993. Gemini: A Natu- 
ral Language System for Spoken Language Under- 
standing. In Proceedings of the Thirty-First An- 
nual Meeting of the ACL, Columbus, OH. Associ- 
ation for Computational Linguistics. 
J. Dowding, E. Owen Bratt, and S. Goldwater. 
1999. Interpreting Language in Context in Com- 
mandTalk. In Communicative Agents: The Use 
of Natural Language in Embodied Systems, pages 
63-67. 
D. Martin, A. Cheyer, and D. Moran. 1998. Build- 
ing Distributed Software Systems with the Open 
Agent Architecture. In Proceedings of the Third 
International Conference on the Practical Appli- 
cation of Intelligent Agents and Multi-Agent Tech- 
nology, Blackpool, Lancashire, UK. The Practical 
Application Company Ltd. 
R. Moore, J. Dowding, H. Bratt, J. Gawron, 
Y. Gorfu, and A. Cheyer. 1997. CommandTalk: 
A Spoken-Language Interface for Battlefield Sim- 
ulations. In Proceedings of the Fifth Conference 
on Applied Natural Language Processing, pages 
1-7, Washington, DC. Association for Computa- 
tional Linguistics. 
M. Rayner, B. A. Hockey, F. James, E. Owen Bratt, 
S. Goldwater, and J. M. Gawron. 2000. Compil- 
ing Language Models from a Linquistically Moti- 
vated Unification Grammar. Submitted to COL- 
ING '00. 
A. Stent, J. Dowding, J. Gawron, E. Owen Bratt, 
and R. Moore. 1999. The CommandTalk Spoken 
Dialogu.e System. In Proceedings of the 37th An- 
nual Meeting of the A CL. Association of Compu- 
tational Linguistics. 
A. Stolcke and J. Segal. 1994. Precise N-Gram 
Probabilities from Stochastic Context-free Gram- 
mar.: In Proceedings of the 32nd Annual Meeting 
off :the ~Association for Computational Linguistics, 
pages 74~-79, 
65 
147
148
149
150
151
152
153
154
187
188
189
190
223
224
225
226
 
	ffPractical Issues in Compiling Typed Unification Grammars for Speech
Recognition
John Dowding Beth Ann Hockey
RIACS RIALIST Group
NASA Ames Research Center
Moffett Field, CA 94035
jdowding@riacs.edu
bahockey@riacs.edu
Jean Mark Gawron
Dept. of Linguistics
San Diego State University
San Diego, CA
gawron@mail.sdsu.edu
Christopher Culy
SRI International
333 Ravenswood Avenue
Menlo Park, CA 94025
culy@ai.sri.com
Abstract
Current alternatives for language mod-
eling are statistical techniques based
on large amounts of training data, and
hand-crafted context-free or finite-state
grammars that are difficult to build
and maintain. One way to address
the problems of the grammar-based ap-
proach is to compile recognition gram-
mars from grammars written in a more
expressive formalism. While theoreti-
cally straight-forward, the compilation
process can exceed memory and time
bounds, and might not always result in
accurate and efficient speech recogni-
tion. We will describe and evaluate two
approaches to this compilation prob-
lem. We will also describe and evalu-
ate additional techniques to reduce the
structural ambiguity of the language
model.
1 Introduction
Language models to constrain speech recogni-
tion are a crucial component of interactive spo-
ken language systems. The more varied the lan-
guage that must be recognized, the more critical
good language modeling becomes. Research in
language modeling has heavily favored statisti-
cal approaches (Cohen 1995, Ward 1995, Hu et
al. 1996, Iyer and Ostendorf 1997, Bellegarda
1999, Stolcke and Shriberg 1996) while hand-
coded finite-state or context-free language models
dominate the commercial sector (Nuance 2001,
SpeechWorks 2001, TellMe 2001, BeVocal 2001,
HeyAnita 2001, W3C 2001). The difference re-
volves around the availability of data. Research
systems can achieve impressive performance us-
ing statistical language models trained on large
amounts of domain-targeted data, but for many
domains sufficient data is not available. Data may
be unavailable because the domain has not been
explored before, the relevant data may be con-
fidential, or the system may be designed to do
new functions for which there is no human-human
analog interaction. The statistical approach is un-
workable in such cases for both the commercial
developers and for some research systems (Moore
et al 1997, Rayner et al 2000, Lemon et al
2001, Gauthron and Colineau 1999). Even in
cases for which there is no impediment to col-
lecting data, the expense and time required to col-
lect a corpus can be prohibitive. The existence
of the ATIS database (Dahl et al 1994) is no
doubt a factor in the popularity of the travel do-
main among the research community for exactly
this reason.
A major problem with grammar-based finite-
state or context-free language models is that they
can be tedious to build and difficult to maintain,
as they can become quite large very quickly as
the scope of the grammar increases. One way
to address this problem is to write the gram-
mar in a more expressive formalism and gener-
ate an approximation of this grammar in the for-
mat needed by the recognizer. This approach
has been used in several systems, CommandTalk
(Moore et al 1997), RIALIST PSA simula-
tor (Rayner et al 2000), WITAS (Lemon et al
2001), and SETHIVoice (Gauthron and Colin-
eau 1999). While theoretically straight-forward,
this approach is more demanding in practice, as
each of the compilation stages contains the po-
tential for a combinatorial explosion that will ex-
ceed memory and time bounds. There is also no
guarantee that the resulting language model will
lead to accurate and efficient speech recognition.
We will be interested in this paper in sound ap-
proximations (Pereira and Wright 1991) in which
the language accepted by the approximation is
a superset of language accepted by the original
grammar. While we conceed that alternative tech-
niques that are not sound (Black 1989, (Johnson
1998, Rayner and Carter 1996) may still be useful
for many purposes, we prefer sound approxima-
tions because there is no chance that the correct
hypothesis will be eliminated. Thus, further pro-
cessing techniques (for instance, N-best search)
will still have an opportunity to find the optimal
solution.
We will describe and evaluate two compilation
approaches to approximating a typed unification
grammar with a context-free grammar. We will
also describe and evaluate additional techniques
to reduce the size and structural ambiguity of the
language model.
2 Typed Unification Grammars
Typed Unification Grammars (TUG), like HPSG
(Pollard and Sag 1994) and Gemini (Dowding et
al. 1993) are a more expressive formalism in
which to write formal grammars1. As opposed to
atomic nonterminal symbols in a CFG, each non-
terminal in a TUG is a complex feature structure
(Shieber 1986) where features with values can be
attached. For example, the rule:
s[]   np:[num=N] vp:[num=N]
can be considered a shorthand for 2 context free
rules (assuming just two values for number):
s
 
np singular vp singular
s
 
np plural vp plural
1This paper specifically concerns grammars written in
the Gemini formalism. However, the basic issues involved in
compiling typed unification grammars to context-free gram-
mars remain the same across formalisms.
This expressiveness allows us to write grammars
with a small number of rules (from dozens to a
few hundred) that correspond to grammars with
large numbers of CF rules. Note that the approx-
imation need not incorporate all of the features
from the original grammar in order to provide a
sound approximation. In particular, in order to de-
rive a finite CF grammar, we will need to consider
only those features that have a finite number of
possible values, or at least consider only finitely
many of the possible values for infinitely valued
features. We can use the technique of restriction
(Shieber 1985) to remove these features from our
feature structures. Removing these features may
give us a more permissive language model, but it
will still be a sound approximation.
The experimental results reported in this pa-
per are based on a grammar under development
at RIACS for a spoken dialogue interface to a
semi-autonomous robot, the Personal Satellite
Assistant (PSA). We consider this grammar to be
medium-sized, with 61 grammar rules and 424
lexical entries. While this may sound small, if
the grammar were expanded by instantiating vari-
ables in all legal permutations, it would contain
over 	 context-free rules.
3 The Compilation Process
We will be studying the compilation process
to convert typed unification grammars expressed
in Gemini notation into language models for
use with the Nuance speech recognizer (Nuance,
2001). We are using Nuance in part because it
supports context-free language models, which is
not yet industry standard.2 Figure 1 illustrates the
stages of processing: a typed unification grammar
is first compiled to a context-free grammar. This
is in turn converted into a grammar in Nuance?s
Grammar Specification Language (GSL), which
is a form of context-free grammar in a BNF-like
notation, with one rule defining each nonterminal,
and allowing alternation and Kleene closure on
the right-hand-side. Critically, the GSL must not
contain any left-recursion, which must be elimi-
nated before the GSL representation is produced.
2The standard is moving in the direction of context-
free language models, as can be seen in the draft standard
for Speech Recognition Grammars being developed by the
World Wide Web Consortium (W3C 2001).
Context Free Grammar
TUG to CFG Compiler
nuance_compiler
GSL Grammar
CFG to GSL Conversion
Recognition System
        Package
Typed Unification Grammar (TUG)
Figure 1: Compilation Process
The GSL representation is then compiled into a
Nuance package with the nuance compiler.
This package is the input to the speech recognizer.
In our experience, each of the compilation stages,
as well as speech recognition itself, has the po-
tential to lead to a combinatorial explosion that
exceeds practical memory or time bounds.
We will now describe implementations of the
first stage, generating a context-free grammar
from a typed unification grammar, by two differ-
ent algorithms, one defined by Kiefer and Krieger
(2000) and one by Moore and Gawron, described
in Moore (1998) The critical difficulty for both
of these approaches is how to select the set of
derived nonterminals that will appear in the final
CFG.
3.1 Kiefer&Krieger?s Algorithm
The algorithm of Kiefer&Krieger (K&K) divides
this compilation step into two phases: first, the
set of context-free nonterminals is determined by
iterating a bottom-up search until a least fixed-
point is reached; second, this least fixed-point is
used to instantiate the set of context-free produc-


 for each l 
An Intelligent Procedure Assistant
Built Using REGULUS 2 and ALTERF
Manny Rayner, Beth Ann Hockey, Jim Hieronymus, John Dowding, Greg Aist
Research Institute for Advanced Computer Science (RIACS)
NASA Ames Research Center
Moffet Field, CA 94035
{mrayner,bahockey,jimh,jdowding,aist}@riacs.edu
Susana Early
DeAnza College/NASA Ames Research Center
searly@mail.arc.nasa.gov
Abstract
We will demonstrate the latest version of
an ongoing project to create an intelli-
gent procedure assistant for use by as-
tronauts on the International Space Sta-
tion (ISS). The system functionality in-
cludes spoken dialogue control of nav-
igation, coordinated display of the pro-
cedure text, display of related pictures,
alarms, and recording and playback of
voice notes. The demo also exempli-
fies several interesting component tech-
nologies. Speech recognition and lan-
guage understanding have been devel-
oped using the Open Source REGULUS
2 toolkit. This implements an approach
to portable grammar-based language mod-
elling in which all models are derived
from a single linguistically motivated uni-
fication grammar. Domain-specific CFG
language models are produced by first
specialising the grammar using an au-
tomatic corpus-based method, and then
compiling the resulting specialised gram-
mars into CFG form. Translation between
language centered and domain centered
semantic representations is carried out by
ALTERF, another Open Source toolkit,
which combines rule-based and corpus-
based processing in a transparent way.
1 Introduction
Astronauts aboard the ISS spend a great deal of their
time performing complex procedures. This often in-
volves having one crew member reading the proce-
dure aloud, while while the other crew member per-
forms the task, an extremely expensive use of as-
tronaut time. The Intelligent Procedure Assistant is
designed to provide a cheaper alternative, whereby a
voice-controlled system navigates through the pro-
cedure under the control of the astronaut perform-
ing the task. This project has several challenging
features including: starting the project with no tran-
scribed data for the actual target input language, and
rapidly changing coverage and functionality. We
are using REGULUS 2 and ALTERF to address these
challenges. Together, they provide an example-
based framework for constructing the portion of the
system from recognizer through intepretation that
allows us to make rapid changes and take advan-
tage of both rule-base and corpus-based information
sources. In this way, we have been able to extract
maximum utility out of the small amounts of data
initial available to the project and also smoothly ad-
just as more data has been accumulated in the course
of the project.
The following sections describe the procedure as-
sistant application and domain, REGULUS 2 and AL-
TERF.
2 Application and domain
The system, an early version of which was described
in (Aist et al, 2002), is a prototype intelligent voice
enabled personal assistant, intended to support astro-
nauts on the International Space Station in carrying
out complex procedures. The first production ver-
sion is tentatively scheduled for introduction some
time during 2004. The system reads out each pro-
cedure step as it reaches it, using a TTS engine, and
also shows the corresponding text and supplemen-
tary images in a visual display. Core functionality
consists of the following types of commands:
? Navigation: moving to the following step or
substep (?next?, ?next step?, ?next substep?),
going back to the preceding step or substep
(?previous?, ?previous substep?), moving to a
named step or substep (?go to step three?, ?go
to step ten point two?).
? Visiting non-current steps, either to preview fu-
ture steps or recall past ones (?read step four?,
?read note before step nine?). When this func-
tionality is invoked, the non-current step is dis-
played in a separate window, which is closed
on returning to the current step.
? Recording, playing and deleting voice notes
(?record voice note?, ?play voice note on step
three point one?, ?delete voice note on substep
two?).
? Setting and cancelling alarms (?set alrm for
five minutes from now?, ?cancel alarm at ten
twenty one?).
? Showing or hiding pictures (?show the small
waste water bag?, ?hide the picture?).
? Changing the TTS volume (?increase/decrease
volume?).
? Querying status (?where are we?, ?list voice
notes?, ?list alarms?).
? Undoing and correcting commands (?go back?,
?no I said increase volume?, ?I meant step
four?).
The system consists of a set of modules, written
in several different languages, which communicate
with each other through the SRI Open Agent Ar-
chitecture (Martin et al, 1998). Speech recogni-
tion is carried out using the Nuance Toolkit (Nuance,
2003).
3 REGULUS 2
REGULUS 2 (Rayner et al, 2003; Regulus, 2003)
is an Open Source environment that supports effi-
cient compilation of typed unification grammars into
speech recognisers. The basic intent is to provide
a set of tools to support rapid prototyping of spo-
ken dialogue applications in situations where little
or no corpus data exists. The environment has al-
ready been used to build over half a dozen appli-
cations with vocabularies of between 100 and 500
words.
The core functionality provided by the REGU-
LUS 2 environment is compilation of typed unifi-
cation grammars into annotated context-free gram-
mar language models expressed in Nuance Gram-
mar Specification Language (GSL) notation (Nu-
ance, 2003). GSL language models can be con-
verted into runnable speech recognisers by invoking
the Nuance Toolkit compiler utility, so the net result
is the ability to compile a unification grammar into
a speech recogniser.
Experience with grammar-based spoken dialogue
systems shows that there is usually a substantial
overlap between the structures of grammars for dif-
ferent domains. This is hardly surprising, since they
all ultimately have to model general facts about the
linguistic structure of English and other natural lan-
guages. It is consequently natural to consider strate-
gies which attempt to exploit the overlap between
domains by building a single, general grammar valid
for a wide variety of applications. A grammar of this
kind will probably offer more coverage (and hence
lower accuracy) than is desirable for any given spe-
cific application. It is however feasible to address
the problem using corpus-based techniques which
extract a specialised version of the original general
grammar.
REGULUS implements a version of the grammar
specialisation scheme which extends the Explana-
tion Based Learning method described in (Rayner
et al, 2002). There is a general unification gram-
mar, loosely based on the Core Language Engine
grammar for English (Pulman, 1992), which has
been developed over the course of about ten individ-
ual projects. The semantic representations produced
by the grammar are in a simplified version of the
Core Language Engine?s Quasi Logical Form nota-
tion (van Eijck and Moore, 1992).
A grammar built on top of the general grammar is
transformed into a specialised Nuance grammar in
the following processing stages:
1. The training corpus is converted into a ?tree-
bank? of parsed representations. This is done
using a left-corner parser representation of the
grammar.
2. The treebank is used to produce a specialised
grammar in REGULUS format, using the EBL
algorithm (van Harmelen and Bundy, 1988;
Rayner, 1988).
3. The final specialised grammar is compiled into
a Nuance GSL grammar.
4 ALTERF
ALTERF (Rayner and Hockey, 2003) is another Open
Source toolkit, whose purpose is to allow a clean
combination of rule-based and corpus-driven pro-
cessing in the semantic interpretation phase. There
is typically no corpus data available at the start
of a project, but considerable amounts at the end:
the intention behind ALTERF is to allow us to shift
smoothly from an initial version of the system which
is entirely rule-based, to a final version which is
largely data-driven.
ALTERF characterises semantic analysis as a task
slightly extending the ?decision-list? classification
algorithm (Yarowsky, 1994; Carter, 2000). We start
with a set of semantic atoms, each representing a
primitive domain concept, and define a semantic
representation to be a non-empty set of semantic
atoms. For example, in the procedure assistant do-
main we represent the utterances
please speak up
show me the sample syringe
set an alarm for five minutes from now
no i said go to the next step
respectively as
{increase volume}
{show, sample syringe}
{set alrm, 5, minutes}
{correction, next step}
where increase volume, show,
sample syringe, set alrm, 5, minutes,
correction and next step are semantic
atoms. As well as specifying the permitted semantic
atoms themselves, we also define a target model
which for each atom specifies the other atoms with
which it may legitimately combine. Thus here, for
example, correction may legitimately combine
with any atom, but minutes may only combine
with correction, set alrm or a number.1.
Training data consists of a set of utterances, in
either text or speech form, each tagged with its in-
tended semantic representation. We define a set of
feature extraction rules, each of which associates an
utterance with zero or more features. Feature ex-
traction rules can carry out any type of processing.
In particular, they may involve performing speech
recognition on speech data, parsing on text data, ap-
plication of hand-coded rules to the results of pars-
ing, or some combination of these. Statistics are
then compiled to estimate the probability p(a | f)
of each semantic atom a given each separate feature
f , using the standard formula
p(a | f) = (Naf + 1)/(Nf + 2)
where Nf is the number of occurrences in the train-
ing data of utterances with feature f , and N af is the
number of occurrences of utterances with both fea-
ture f and semantic atom a.
The decoding process follows (Yarowsky, 1994)
in assuming complete dependence between the fea-
tures. Note that this is in sharp contrast with the
Naive Bayes classifier (Duda et al, 2000), which as-
sumes complete independence. Of course, neither
assumption can be true in practice; however, as ar-
gued in (Carter, 2000), there are good reasons for
preferring the dependence alternative as the better
option in a situation where there are many features
extracted in ways that are likely to overlap.
We are given an utterance u, to which we wish to
assign a representation R(u) consisting of a set of
semantic atoms, together with a target model com-
prising a set of rules defining which sets of seman-
1The current system post-processes Alterf semantic atom
lists to represent domain dependancies between semantic
atoms more directly before passing on the result. e.g.
(correction, set alrm, 5, minutes) is repack-
aged as (correction(set alrm(time(0,5))))
tic atoms are consistent. The decoding process pro-
ceeds as follows:
1. Initialise R(u) to the empty set.
2. Use the feature extraction rules and the statis-
tics compiled during training to find the set of
all triples ?f, a, p? where f is a feature associ-
ated with u, a is a semantic atom, and p is the
probability p(a | f) estimated by the training
process.
3. Order the set of triples by the value of p, with
the largest probabilities first. Call the ordered
set T .
4. Remove the highest-ranked triple ?f, a, p? from
T . Add a to R(u) iff the following conditions
are fulfilled:
? p ? pt for some pre-specified threshold
value pt.
? Addition of a to R(u) results in a set
which is consistent with the target model.
5. Repeat step (4) until T is empty.
Intuitively, the process is very simple. We just
walk down the list of possible semantic atoms, start-
ing with the most probable ones, and add them to
the semantic representation we are building up when
this does not conflict with the consistency rules in
the target model. We stop when the atoms suggested
are too improbable, that is, they have probabilies be-
low a cut-off threshold.
5 Summary and structure of demo
We have described a non-trivial spoken language di-
alogue application built using generic Open Source
tools that combine rule-based and corpus-driven
processing. We intend to demo the system with par-
ticular reference to these tools, displaying intermedi-
ate results of processing and showing how the cover-
age can be rapidly reconfigured in an example-based
fashion.
References
G. Aist, J. Dowding, B.A. Hockey, and J. Hieronymus.
2002. An intelligent procedure assistant for astro-
naut training and support. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics (demo track), Philadelphia, PA.
D. Carter. 2000. Choosing between interpretations. In
M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and
M. Wire?n, editors, The Spoken Language Translator.
Cambridge University Press.
R.O. Duda, P.E. Hart, and H.G. Stork. 2000. Pattern
Classification. Wiley, New York.
D. Martin, A. Cheyer, and D. Moran. 1998. Building
distributed software systems with the open agent ar-
chitecture. In Proceedings of the Third International
Conference on the Practical Application of Intelligent
Agents and Multi-Agent Technology, Blackpool, Lan-
cashire, UK.
Nuance, 2003. http://www.nuance.com. As of 25 Febru-
ary 2003.
S.G. Pulman. 1992. Syntactic and semantic process-
ing. In H. Alshawi, editor, The Core Language En-
gine, pages 129?148. MIT Press, Cambridge, Mas-
sachusetts.
M. Rayner and B.A. Hockey. 2003. Transparent com-
bination of rule-based and data-driven approaches in a
speech understanding architecture. In Proceedings of
the 10th EACL, Budapest, Hungary.
M. Rayner, B.A. Hockey, and J. Dowding. 2002. Gram-
mar specialisation meets language modelling. In Pro-
ceedings of the 7th International Conference on Spo-
ken Language Processing (ICSLP), Denver, CO.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
M. Rayner. 1988. Applying explanation-based general-
ization to natural-language processing. In Proceedings
of the International Conference on Fifth Generation
Computer Systems, pages 1267?1274, Tokyo, Japan.
Regulus, 2003. http://sourceforge.net/projects/regulus/.
As of 24 April 2003.
J. van Eijck and R. Moore. 1992. Semantic rules for
English. In H. Alshawi, editor, The Core Language
Engine, pages 83?116. MIT Press.
T. van Harmelen and A. Bundy. 1988. Explanation-
based generalization = partial evaluation (research
note). Artificial Intelligence, 36:401?412.
D. Yarowsky. 1994. Decision lists for lexical ambiguity
resolution. In Proceedings of the 32nd Annual Meet-
ing of the Association for Computational Linguistics,
pages 88?95, Las Cruces, New Mexico.
A procedure assistant for astronauts
in a functional programming architecture,
with step previewing and spoken correction of dialogue moves
Gregory Aist
1
, Manny Rayner
1
, John Dowding
1
,
Beth Ann Hockey
1
, Susana Early
2
, and Jim Hieronymus
3
1
Research Institute for Advanced Computer Science
2
Foothill/DeAnza College
3
NASA Ames Research Center
M/S T35B-1, Moffett Field CA 94035
{aist, mrayner, jdowding, bahockey, jimh}@riacs.edu; searly@mail.arc.nasa.gov
Abstract
We present a demonstration of a proto-
type system aimed at providing support
with procedural tasks for astronauts on
board the International Space Station.
Current functionality includes navigation
within the procedure, previewing steps,
requesting a list of images or a particular
image, recording voice notes and spoken
alarms, setting parameters such as audio
volume. Dialogue capabilities include
handling spoken corrections for an entire
dialogue move, reestablishing context in
response to a user request, responding to
user barge-in, and help on demand. The
current system has been partially reim-
plemented for better efficiency and in re-
sponse to feedback from astronauts and
astronaut training personnel. Added fea-
tures include visual and spoken step pre-
viewing, and spoken correction of
dialogue moves. The intention is to intro-
duce the system into astronaut training as
a prelude to flight on board the Interna-
tional Space Station.
1 Introduction
Astronauts on board the International Space Sta-
tion engage in a wide variety of tasks on orbit in-
cluding medical procedures, extra vehicular
activity (E V A), scientific payloads, and station
repair and maintenance. These human space flight
activities require extensive and thorough proce-
dures. These procedures are written down in the
form of a number of steps and, with various notes,
cautions, and warnings interspersed throughout the
procedure. Each step may have one or more sub
steps.  Procedures also include branch points, call-
outs to other procedures, and instructions to com-
municate with mission control.  Since December
2001, the RIALIST group has been developing a
spoken dialogue system for providing assistance
with space station procedures. Aist and Hockey
(2002) and Aist et al (2002) described the first
version of the system, which operated on a simpli-
fied (and invented) procedure for unpacking and
operating a digital camera and included speech
input and speech output only. Aist et al (2003)
described a second version of the system with an
XML-based display, and that included support for
not only procedures, but also voice notes and re-
corded alarms, and parameter settings such as in-
creasing and decreasing volume. In this paper, we
describe the third version of the system, with a
reimplemented architecture based on a functional
specification of the domain-specific aspects of the
system combined with an event-driven generic ar-
chitectural framework. We also describe two new
features: previewing of steps, and spoken correc-
tion of dialogue moves.
2 System Description
The March 2003 version of the Intelligent Proce-
dure Assistant is shown in Figure 1, just after
loading a procedure. The March 2003 version pro-
vides the following functions:
Loading a procedure by specifying its name, for
example, ?Load water procedure.?
Sequential navigation through individual steps, for
example, ?Next step? or ?Previous step.?
Navigation to arbitrary steps, for example, ?Go to
step two point one.?
Setting system parameters, such as ?Increase vol-
ume? or ?Decrease volume.?
Handling annotations, such as voice notes or
alarms (?Record a voice note?), or pictures (?Show
the small waste water bag.?).
Previewing steps; for example, ?Read step three?.
Issuing spoken corrections (of entire commands),
for example, ?I meant go to step two.?
We will discuss previewing steps and issuing spo-
ken corrections in turn.
2.1 Previewing steps (Reading mode)
Besides acting on the current step, astronauts indi-
cated that they would like a spoken preview of the
next step. Currently this functionality is imple-
mented as displaying a second procedure window
in the upper right corner of the screen. Further-
more, steps are prefixed with a spoken indication
of previewing, for example, ?Reading mode. Note
before step two?? To transition back into normal
(execution) mode, the user may say ?Stop read-
ing.? Figure 2 shows the resulting display for the
reading mode.  
2.2 Issuing spoken corrections
In the March 2003 version of the Checklist system,
the user may issue a spoken correction in the case
of an incorrectly given command, or in the case of
a speech recognition error (e.g. ?read me step
three? ? ?repeat step three?). The dialogue history
is represented as a list of the prior dialogue states.
Currently we model a correction as a change in the
information state, a rollback of the previous action
plan, and then an application of the new action
plan. Figure 3 shows the display after issuing a
correction, ?I meant the wash cloth?. Reading
mode has been exited, and a picture of the wash-
cloth is displayed.
Figure 1. Loading a procedure.
Figure 2. Preview mode, step three.
Figure 3. A subsequent correction, resulting in a
return to execution mode, and the implementation
of the other command.
Figure 4. Checklist dialogue system architecture.
3  Architecture, or, How to write
a dialogue system in three easy steps
There are three main sections to the dialogue han-
dling code: the input manager, dialogue manager,
and the output manager (Figure 4). These are
similar divisions to those proposed in Allen et al
(2000). Here, we also adopt a further division of
the code into application-specific code and generic
code. Application-specific code computes the fol-
lowing function for each component, as a compila-
tion step:
Input manager: Input ? Event
Dialogue manager: (Event, State)
? (Action, State)
Output manager: Action ? (Output, Inverse)
The Output and Inverse computed by the Input
manager are the multimodal output plans and their
multimodal inverses, respectively.  The multi-
modal inverses are used when applying a correc-
tion ? in conjunction with a return to a previous
state on the history list.
The generic code is an interpretation (or execu-
tion) step; the input manager?s code collects in-
coming events and dispatches the events to the
dialogue manager. The dialogue manager?s code
collects the incoming events, retrieves the previous
state, applies the application-specific function,
saves the new state, and then dispatches the new
action. The output manager takes the action, ap-
plies the application-specific function to compute
the output and its inverse, and then dispatches the
output plan one action at a time. Each action is rep-
resented as an OAA solvable, and dispatched se-
quentially to be handled by the appropriate agent
such as the text-to-speech agent.
The entire dialogue manager is side-effectfree.
(With the minor exception of loading a procedure
file, which causes a change in the ?last accessed?
time of the file.) In a more typical dialogue system
architecture such as that shown in Figure 5, the
side effects are represented separately. The inte-
gration of side effects into the output plan has
positive benefits for robustness, since they will be
represented in one place (and thus modified at the
same time when programming changes are made).
Figure 5.  A more typical dialogue system ar-
chitecture, with the side effects executed separately
from the spoken output.
4 Related Research and Future Work
Rudnicky, Reed, and Thayer (1996) describe a
system for supporting vehicle maintenance with
speech interfaces. Schreckenghost et al (2003)
describe a scenario involving similar tasks (life
Speech
Recognizer
Parser
Input
Manager
Output
Manager
Speech
Synthesizer
Visual
Display
Dialogue
Manager
I: input ? event
D: (event, state)
? (action, state)
O: action
? (output, inverse)
Speech
Recognizer
Parser Input
Manager
Output
Manager
Speech
Synthesizer
DB
Dialogue
Manager
support / maintenance related) but with the com-
puter in more control of the actual task. S & K
Electronics (n.d.) mention a procedure develop-
ment environment for rapidly developing and veri-
fying on-orbit procedures
(http://sk-web.sk-tech.com/proj.html).
Possible future work includes adding procedures
involving inventory management and robot arm
assistance, automating dialogue system construc-
tion from XML procedures, integrating with te-
lemetry to monitor execution of the procedure and
develop error recovery options, improving natural-
ness of the speech output, modeling dialogue to
include dialogue moves and expected user re-
sponses, and improving speech recognition to be
robust to ISS noise.
References
G. Aist. J. Dowding, B. A. Hockey, and J. Hieronymus.
2002. An intelligent procedure assistant for astronaut
training and support. Proceedings of the 40
th
 Annual
Meeting of the Association for Computational Lin-
guistics, refereed demonstration track.
G. Aist and B. A. Hockey. 2002. Generating Training
and Assistive Dialogues for Astronauts from Interna-
tional Space Station Technical Documentation. ITS
2002 Workshop on Integrating Technical and Train-
ing Documentation. Presented along with system
demonstration.
G. Aist, J. Dowding, B. A. Hockey, M. Rayner, J. Hi-
eronymus, D. Bohus, B. Boven, N. Blaylock, E.
Campana, S. Early, G. Gorrell, and S. Phan. 2003.
European Association for Computational Linguistics
(EACL) 2003 meeting, Software Demonstration, Bu-
dapest, Hungary, April 2003.
J. Allen, D. Byron, M. Dzikovska, G. Ferguson, L.
Galescu, and A. Stent. 2000. An architecture for a
generic dialogue shell. Natural Language Engineer-
ing, Special issue on Best Practice in Spoken Lan-
guage Dialogue Systems Engineering, pp. 323-340.
A. Rudnicky, S. Reed, and E. H. Thayer. 1996.
SpeechWear: A mobile speech system.
http://www.speech.cs.cmu.edu/air/papers/speechwear.ps
D. Schreckenghost, C. Thronesbery, P. Bonasso, D.
Kortenkamp and C. Martin, Intelligent Control of
Life Support for Space Missions, in IEEE Intelligent
Systems Magazine, September/October, 2002.
Portions of the dialogue systems described in this paper
were constructed with Rayner, Hockey, and Dowding?s
Regulus open source toolkit. Interested readers may find
the toolkit and supporting documentation online at:
http://sourceforge.net/projects/regulus/.
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 235?243,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
Extracting decisions from multi-party dialogue using directed graphical
models and semantic similarity
Trung H. Bui1, Matthew Frampton1, John Dowding2, and Stanley Peters1
1Center for the Study of Language and Information, Stanford University
{thbui|frampton|peters}@stanford.edu
2University of California/Santa Cruz
jdowding@ucsc.edu
Abstract
We use directed graphical models (DGMs)
to automatically detect decision discus-
sions in multi-party dialogue. Our ap-
proach distinguishes between different di-
alogue act (DA) types based on their role
in the formulation of a decision. DGMs
enable us to model dependencies, includ-
ing sequential ones. We summarize deci-
sions by extracting suitable phrases from
DAs that concern the issue under discus-
sion and its resolution. Here we use a
semantic-similarity metric to improve re-
sults on both manual and ASR transcripts.
1 Introduction
In work environments, people share information
and make decisions in multi-party conversations
known as meetings. The demand for systems that
can automatically process, understand and sum-
marize information contained in audio and video
recordings of meetings is growing rapidly. Our
own research, and that of other contemporary
projects (Janin et al, 2004), aim at meeting this
demand.
At present, we are focusing on the automatic
detection and summarization of decision discus-
sions. Our approach for detecting decision dis-
cussions involves distinguishing between differ-
ent dialogue act (DA) types based on their role
in the decision-making process. Two of these
types are DAs which describe the Issue under dis-
cussion, and DAs which describe its Resolution.
To summarize a decision discussion, we identify
words and phrases in the Issue and Resolution
DAs, which can be used to produce a concise, de-
scriptive summary.
This paper describes new experiments in both
detecting and summarizing decision discussions.
In the detection stage, we investigate the use of
Directed Graphical Models (DGMs). DGMs are
attractive because they can be used to model se-
quence and dependencies between predictor vari-
ables. In the summarization stage, we attempt to
improve phrase selection with a new feature that
measures the level of semantic similarity between
candidate Issue phrases and Resolution utterances,
and vice-versa. The feature is generated by a
semantic-similarity metric which uses WordNet as
a knowledge source. The motivation is that ordi-
narily, the Issue and Resolution components in a
decision summary should be semantically similar.
The paper proceeds as follows. Firstly, Sec-
tion 2 describes related work, and Section 3, our
data-set and annotation scheme for decision dis-
cussions. Section 4 then reports our decision de-
tection experiments using DGMs, and Section 5,
the summarization experiments. Finally, Section
6 draws conclusions and proposes ideas for future
work.
2 Related Work
User studies (Banerjee et al, 2005) have con-
firmed that meeting participants consider deci-
sions to be one of the most important meeting
outputs, and (Whittaker et al, 2006) found that
the development of an automatic decision detec-
tion component is critical to the re-use of meet-
ing archives. With the new availability of substan-
tial meeting corpora such as the AMI corpus (Mc-
Cowan et al, 2005), recent years have therefore
seen an increasing amount of research on decision-
making dialog. This research has tackled issues
such as the automatic detection of agreement and
disagreement (Galley et al, 2004), and of the
235
level of involvement of conversational participants
(Gatica-Perez et al, 2005). In addition, (Verbree
et al, 2006) created an argumentation scheme in-
tended to support automatic production of argu-
ment structure diagrams from decision-oriented
meeting transcripts. As yet, there has been rela-
tively little work which specifically addresses the
automatic detection and summarization of deci-
sions.
Decision discussion detection: (Hsueh and
Moore, 2007) used the AMI Meeting Corpus, and
attempted to automatically identify DAs in meet-
ing transcripts which are ?decision-related?. For
each meeting, two manually created summaries
were used to judge which DAs were decision-
related: an extractive summary of the whole meet-
ing, and an abstractive summary of its decisions.
Those DAs in the extractive summary which sup-
port any of the decisions in the abstractive sum-
mary were manually tagged as decision-related.
(Hsueh and Moore, 2007) then trained a Maxi-
mum Entropy classifier to recognize this single
DA class, using a variety of lexical, prosodic, DA
and conversational topic features. They achieved
an F-score of 0.35.
Unlike (Hsueh and Moore, 2007), (Ferna?ndez et
al., 2008b) made an attempt at modelling the struc-
ture of decision-making dialogue. The authors de-
signed an annotation scheme that takes account of
the different roles which utterances can play in the
decision-making process?for example it distin-
guishes between DDAs (decision DAs) which ini-
tiate a discussion by raising an issue, those which
propose a resolution, and those which express
agreement for a proposed resolution. The authors
annotated a portion of the AMI corpus, and then
applied what they refer to as ?hierarchical classi-
fication?. Here, one sub-classifier per DDA class
hypothesizes occurrences of that DDA class, and
then based on these hypotheses, a super-classifier
determines which regions of dialogue are deci-
sion discussions. All of the classifiers, (sub and
super), were linear kernel binary Support Vec-
tor Machines (SVMs). Results were better than
those obtained with (Hsueh and Moore, 2007)?s
approach?the F1-score for detecting decision dis-
cussions in manual transcripts was .58 vs. .50.
Note that (Purver et al, 2007) had previously pur-
sued the same basic approach as (Ferna?ndez et al,
2008b) in order to detect action items.
In this paper, we build on the promising results
of (Ferna?ndez et al, 2008b), by using Directed
Graphical Models (DGMs) in place of SVMs.
DGMs are attractive because they provide a natu-
ral framework for modelling sequence and depen-
dencies between variables including the DDAs.
We are especially interested in whether DGMs
better exploit non-lexical features. (Ferna?ndez et
al., 2008b) obtained much more value from lexi-
cal than non-lexical features (and indeed no value
at all from prosodic features), but lexical features
have disadvantages. In particular, they can be do-
main specific, increase the size of the feature space
dramatically, and deteriorate more than other fea-
tures in quality when ASR is poor.
Decision summarization: Recent years have
seen research on spoken dialogue summarization
(e.g. (Zechner, 2002)). Most has attempted to gen-
erate summaries of full dialogues, but some very
recent research has focused on specific dialogue
events, namely action items (Purver et al, 2007),
and decisions (Ferna?ndez et al, 2008a).
(Ferna?ndez et al, 2008a) used the DDA an-
notation scheme mentioned above, and began by
extracting the DDAs which raise issues or pro-
vide accepted resolutions. Only manual tran-
scripts were used and the DDAs were extracted
by hand rather than automatically. The next step
was to parse each DDA with a general rule-based
parser (Dowding et al, 1993), producing multi-
ple short fragments rather than one full utterance
parse. Then, for each DDA, an SVM regression
model used various features (including parse, se-
mantic and lexical features) to select the fragment
which was most likely to appear in a gold-standard
extractive decision summary. The entire manual
utterance transcriptions were used as the baseline,
and although the SVM?s precision was high, it was
not enough to offset the baseline?s perfect recall,
and so its F-score was lower. The ?Oracle?, which
always chooses the fragment with the highest F1-
score produced very good results. This motivates
deeper investigation into how to improve the frag-
ment/parse selection phase, and so we assess the
usefulness of a semantic-similarity feature for the
SVM. We conduct experiments with ASR as well
as manual transcripts.
3 Data
For the experiments reported in this study, we used
17 meetings from the AMI Meeting Corpus (Mc-
Cowan et al, 2005), a freely available corpus of
236
multi-party meetings with both audio and video
recordings, and a wide range of annotated in-
formation including DAs and topic segmentation.
Conversations are in English, but some partici-
pants are non-native English speakers. The meet-
ings last around 30 minutes each, and are scenario-
driven, wherein four participants play different
roles in a company?s design team: project man-
ager, marketing expert, interface designer and in-
dustrial designer.
3.1 Modelling Decision Discussions
We use the same annotation scheme as (Ferna?ndez
et al, 2008b) to model decision-making dialogue.
As stated in Section 2, this scheme distinguishes
between a small number of DA types based on the
role which they perform in the formulation of a de-
cision. Apart from improving the initial detection
of decision discussions (Ferna?ndez et al, 2008b),
such a scheme also aids their subsequent summa-
rization, because it indicates which utterances con-
tain particular types of information.
The annotation scheme is based on the observa-
tion that a decision discussion contains the follow-
ing main structural components: (a) a topic or is-
sue requiring resolution is raised, (b) one or more
possible resolutions are considered, (c) a particular
resolution is agreed upon and so becomes the de-
cision. Hence the scheme distinguishes between
three main decision dialogue act (DDA) classes:
issue (I), resolution (R), and agreement (A). Class
R is further subdivided into resolution proposal
(RP) and resolution restatement (RR). I utterances
introduce the topic of the decision discussion, ex-
amples being ?Are we going to have a backup??
and ?But would a backup really be necessary??
in Dialogue 1. On the other hand, R utterances
specify the resolution which is ultimately adopted
as the decision. RP utterances propose this reso-
lution (e.g. ?I think maybe we could just go for
the kinetic energy. . . ?), while RR utterances close
the discussion by confirming/summarizing the de-
cision (e.g. ?Okay, fully kinetic energy?) . Finally,
A utterances agree with the proposed resolution,
signalling that it is adopted as the decision, (e.g.
?Yeah?, ?Good? and ?Okay?). Note that an utter-
ance can be assigned to more than one DDA class,
and within a decision discussion, more than one
utterance can be assigned to the same DDA class.
We use both manual and ASR one-best tran-
scripts1 in the experiments described here. DDA
annotations were first made on the manual tran-
scripts, and then transferred onto the ASR tran-
scripts. Inter-annotator agreement was satisfac-
tory, with kappa values ranging from .63 to .73 for
the four DDA classes. Due to different segmen-
tation, the manual and ASR transcripts contain a
total of 15,680 and 8,357 utterances respectively,
and on average, 40 and 33 DDAs per meeting.
Hence DDAs are slightly less sparse in the ASR
transcripts: for all DDAs, 6.7% vs. 4.3% of the to-
tal number of utterances, for I, 1.6% vs. 0.9%, for
RP, 2% vs. 1%, for RR, 0.5% vs. 0.4%, and for A,
2.6% vs. 2%.
(1) A: Are we going to have a backup? Or we do
just?
B: But would a backup really be necessary?
A: I think maybe we could just go for the
kinetic energy and be bold and innovative.
C: Yeah.
B: I think? yeah.
A: It could even be one of our selling points.
C: Yeah ?laugh?.
D: Environmentally conscious or something.
A: Yeah.
B: Okay, fully kinetic energy.
D: Good.2
4 Decision Discussion Detection using
Directed Graphical Models
A directed graphical model (DGM) M, (see Mur-
phy (2002)), is a directed acyclic graph consisting
of nodes which represent random variables, arcs
which represent dependencies among these vari-
ables, and a probability distribution P over the
variables. Let X = {X1, X2, ..., Xn} be a set of
random variables that are associated with nodes in
a DGM and Pa(Xi) be parents of Xi. The proba-
bility distribution of the model M satisfies:
P (X1, X2, ..., Xn) =
n?
i=1
(P (Xi)|Pa(Xi))
When a DGM is used as a classifier, the goal is to
correctly infer the value of the class node Xc ? X
given a vector of values for the observed node(s)
1We used SRI?s Decipher for which (Stolcke et al, 2008)
reports a word error rate of 26.9% on AMI meetings.
2This example was extracted from the AMI dialogue
ES2015c and has been modified slightly for presentation pur-
poses.
237
Xo ? X\Xc. This is done by using M to find the
value of Xc which gives the highest conditional
probability P (Xc|Xo).
To detect each individual DDA class, we ex-
amined the four simple DGMs in Figure 1 (see
Appendix). The DDA node is binary where
value 1 indicates the presence of a DDA and 0
its absence. The evidence node (E) is a multi-
dimensional vector of observed values of non-
lexical features. These include utterance features
(UTT) such as length in words, duration in mil-
liseconds, position within the meeting (as percent-
age of elapsed time), manually annotated dialogue
act (DA) features3 such as inform, assess, suggest,
and prosodic features (PROS) such as energy and
pitch. These features are the same as the non-
lexical features used by Ferna?ndez et al (2008b).
The hidden component node (C) represents the
distribution of observable evidence E as a single
Gaussian in the -sim models, and a mixture in the
-mix models. For the -mix models, the number
of Gaussian components is hand-tuned during the
training phase.
More complex models are constructed from the
four simple models in Figure 1 to allow for depen-
dencies between different DDAs. For example, the
model in Figure 2 (see Appendix) generalizes Fig-
ure 1c with arcs connecting the DDA classes based
on analysis of the annotated AMI data.
4.1 Experiments
The DGM classifiers in Figures 1 and 2 were im-
plemented in Matlab using the BNT software4.
Since the current BNT version does not sup-
port multiple time series training for fully observ-
able Dynamic Bayesian Networks (DBNs), we ex-
tended the software for training models using this
structure (e.g., Figure 1c and Figure 2).
A DGM classifier is considered to have hy-
pothesized a DDA if the marginal probability of
its DDA node is above a hand-tuned threshold.
We tested the DGMs on manual and ASR tran-
scripts in a 17-fold cross-validation, and evaluated
their performance on both a per-utterance basis,
and also with the same lenient-match metric as
Ferna?ndez et al (2008b). This allows a margin
of 20 seconds preceding and following a hypoth-
esized DDA, and so we refer to it as the 40 sec-
ond metric. In addition, we hypothesized decision
3We use the AMI DA annotations. These are only avail-
able for manual transcripts.
4http://www.cs.ubc.ca/?murphyk/Software/BNT/bnt.html
discussion regions using the DGM output and the
following two simple rules:
? A decision discussion region begins with an
Issue DDA.
? A decision discussion region contains at least
one Issue DDA and one Resolution DDA.
To evaluate the accuracy of these hypothesized re-
gions, like Ferna?ndez et al (2008b), we divided
the dialogue into 30-second windows and evalu-
ated on a per window basis.
4.2 Results
Tables 1 and 2 show the F1-scores for each
DGM when using the best feature sets (I:
UTT+DA+PROS, RP: UTT+DA, RR: UTT, A:
UTT+DA). The BN-mix model gives the highest
F1-score for A on both evaluation metrics, and the
DBN-mix model, the highest for I, RP, and RR,
but there are no statistically significant differences
between any of the alternative DGMs.
Classifier I RP RR A
BN-mix .09 .09 .04 .19
DBN-mix .16 .14 .05 .17
BN-sim .12 .09 .04 .17
DBN-sim .15 .11 .04 .16
Table 1: F1-score (per utterance) of the DGMs us-
ing the best combination of non-lexical features.
Classifier I RP RR A
BN-mix .19 .24 .07 .38
DBN-mix .27 .24 .07 .32
BN-sim .23 .22 .06 .36
DBN-sim .25 .22 .06 .31
Table 2: F1-score (40 seconds) of the DGMs using
the best combination of non-lexical features.
To determine whether modeling dependencies
between DDAs improves performance, we exper-
imented with the DGMs that are generalized from
the DBN-sim (Figure 2) and DBN-mix models.
The F1-scores did not improve for I, RP, and RR,
while for A, the DGM generalized from DBN-sim
gave a .03 improvement according to the 40 sec-
onds metric, but this was not statistically signifi-
cant.
For each DDA, Table 3 compares the results of
the best DGM and the hierarchical SVM classi-
fication method of Ferna?ndez et al (2008b) (see
238
Section 2). The DGM performs better for all
DDAs on both evaluation metrics (p < 0.005).
Note that while prosodic features proved useless
to SVM classifiers (Ferna?ndez et al (2008b)), with
DGMs, they have some predictive power.
Per utterance 40 seconds
Classifier DDA Pr Re F1 Pr Re F1
SVM I .03 .62 .05 .04 .89 .08
DGM .11 .28 .16 .20 .44 .27
SVM RP .03 .60 .07 .05 .90 .10
DGM .09 .35 .14 .16 .57 .24
SVM RR .01 .49 .02 .01 .80 .03
DGM .02 .42 .05 .04 .58 .07
SVM A .05 .70 .10 .07 .90 .13
DGM .13 .31 .19 .29 .55 .38
Table 3: Performance of the DGM classifier vs.
the SVM classifier. Both use the best combination
of non-lexical features.
We also generated results without DA features.
Here, the best F1-scores for I, RP, and A degrade
between .07 and .09 (p < 0.05), but they are still
higher than the equivalent SVM results with DA
features. Since (Ferna?ndez et al, 2008b) report
that lexical features are the most useful for the
SVM classifiers, it will be interesting to see how
well the DGMs perform when they use lexical as
well as non-lexical features.
Detecting DDAs in ASR transcripts: Table 4
compares the DGM F1-scores when using ASR
one-best and manual transcripts. The DGMs per-
form well on ASR output. For I and RP, the results
on ASR are actually higher, perhaps because the
DDAs are less sparse. In the absence of DA fea-
tures, prosodic features improve the performance
for A in both sources.
UTT UTT+PROS
I RP RR A I RP RR A
ASR .20 .21 .06 .24 .16 .24 .07 .28
Man .18 .17 .07 .27 .16 .15 .05 .30
Table 4: F1-scores (40 seconds) computed using
ASR one-best vs. manual transcriptions.
Detecting decision discussion regions: Table 5
shows that according to the 30-second window
metric, rule-based classification with DGM output
compares well with hierarchical SVM classifica-
tion (Ferna?ndez et al, 2008b). In fact, even when
the latter uses lexical as well as non-lexical fea-
tures, its F1-score is still about the same as the
DGM-based classifier. Our future work will in-
volve dispensing with the rule-based approach and
designing a DGM which can detect decision dis-
cussion regions.
Classifier Pr Re F1
SVM .35 .88 .50
DGM .39 .93 .55
Table 5: Results in detecting decision discussion
regions for the SVM super-classifier and rule-
based DGM classifier, both using the best com-
bination of non-lexical features.
5 Decision Summarization
We now turn to the task of extracting useful
phrases for summarization. Since a summary of a
decision discussion should minimally contain the
issue under discussion, and its resolution, we leave
Agreement (A) utterances aside, and concentrate
on extracting phrases from Issues (I) and Resolu-
tions (R).
Our basic approach is the same taken in
(Ferna?ndez et al, 2008a): The WCN5 of each I
and R utterance is parsed by the Gemini parser
(Dowding et al, 1993) to produce multiple short
fragments, and then an SVM regression model
uses certain features in order to select the parse
that is most likely to match a gold-standard extrac-
tive summary. Our work is new in two respects:
summarizing from ASR output in addition to man-
ual transcriptions, and using a semantic-similarity
feature in the SVM. This new feature is generated
using Ted Pedersen?s semantic-similarity package
(Pedersen, 2002), and is motivated by the fact that
ordinarily the Issue summary should be semanti-
cally similar to the Resolution and vice versa.
The next section describes the lexical resources
used by Gemini, and Section 5.2, the metric for
calculating semantic similarity.
5.1 Open-Domain Semantic Parser
Since human-human spoken dialogue, especially
after being processed by an imperfect recognizer,
is likely to be highly ungrammatical, we have de-
veloped a semantic parser that only attempts to
find basic predicate-argument structures of the ma-
jor phrase types (S, VP, NP, and PP) and has access
to a broad-coverage lexicon. To build a broad-
coverage lexicon, we used publicly available lex-
ical resources for English, including COMLEX,
5When using manual transcripts, we create ?dummy
WCNs?: WCNs with a single path.
239
VerbNet, WordNet, and NOMLEX.
COMLEX provides detailed syntactic informa-
tion for the 40k most common words of En-
glish, and VerbNet, detailed semantic information
for verbs, including verb class, verb frames, the-
matic roles, mappings of syntactic position to the-
matic roles, and selection restrictions on thematic
role fillers. From WordNet we extracted another
15K nouns and the semantic class information for
all nouns. These semantic classes were hand-
aligned to the selectional classes used in Verb-
Net, based on the upper ontology of EuroWord-
Net. NOMLEX provides syntactic information for
event nominalizations, and information for map-
ping the noun arguments to the corresponding verb
syntactic positions.
These resources were combined and converted
to the Prolog-based format used in the Gemini
framework, which includes a fast bottom-up ro-
bust parser in which syntactic and semantic in-
formation is applied interleaved. Gemini can
compute parse probabilities on the context-free
skeleton of the grammar. In the experiments de-
scribed here these parse probabilities are trained
on Switchboard tree-bank data.
5.2 Semantic Similarity Metric: Normalized
Path Length
Ted Pedersen?s semantic similarity package (Ped-
ersen, 2002) can be used to apply a number of
different metrics that use WordNet as a knowl-
edge base. The metric used here, Normalized Path
Length (Leacock and Chodorow, 1998), defines
the semantic similarity sim between words w1 and
w2 as:
simc1,c2 = ? log
len(c1, c2)
2?D (1)
where c1 and c2 are concepts corresponding to w1
and w2, len(c1, c2) is the length of the shortest
path between them, and D is the maximum depth
of the taxonomy.
5.3 Experiments
Data: For the manual transcripts in our sub-
corpus, the average length in words of I and R ut-
terances is 12.2 and 11.9 respectively, and for the
ASR, 22.4 and 18.1. To provide a gold-standard,
phrases from I and R utterances in the man-
ual transcriptions were annotated as summary-
worthy. The aim was to select those phrases
which should appear in an extractive summary, or
could be the basis of a generated abstractive sum-
mary. As a general guideline, we tried to select
the phrase(s) which describe the issue/resolution
as succinctly as possible. This does not include
phrases which express the speaker?s attitude to-
wards the issue/resolution. Dialogue 2 is an exam-
ple where square brackets indicate which phrases
were selected as summary-worthy.
(2) A:(I) So we we?re looking at [sliders for both
volume and channel change]
B:(R)I was thinking kind of [just for the
volume]
Regression models: We use SVMlight
(Joachims, 1999) to learn separate SVM re-
gression models for Issues and Resolutions.
These rank the Gemini parses for each utterance
according to their likelihood of matching the
gold-standard summary. The top-ranked parse
is then entered into the automatically-generated
decision summary.
Features: We train the regression models with
various types of feature (see Table 6), including
properties of the WCN paths, parse, semantic and
lexical features. As lexical features are likely to be
more domain-specific, and they dramatically in-
crease size of the feature space, we prefer to avoid
them if possible.
To generate the semantic-similarity feature for
an I/R parse, we compute its semantic similarity
with the full transcripts of each of the R/I utter-
ances within the same decision discussion. The
feature?s value is then equal to the greatest of the
resulting semantic-similarity scores. Since Ted
Pedersen?s package operates on the noun portion
of WordNet, we must first extract all of the nouns
in the parse/utterance transcription. Next, we form
all of the possible pairs containing one noun from
the parse, and one from the utterance transcrip-
tion. Then we compute the semantic similarity
for each pair, and take their sum to be the level
of semantic similarity between the parse and the
utterance transcription. We experimented with av-
eraging rather than summing these scores, but the
resulting semantic-similarity feature was less pre-
dictive.
Evaluation: The models are evaluated in 10-
fold cross-validations using the same metric as
(Ferna?ndez et al, 2008a): Recall is the total pro-
portion of the gold-standard extractive summary
240
WCN phrase length (WCN arcs)
start/end point (absolute & percentage)
Parse parse probability
phrase type (S/VP/NP/PP)
Semantic main verb VerbNet class
head noun WordNet synset
Sem-sim Normalized Path Length
Lexical main verb, head noun
Table 6: Features for parse fragment ranking
Issue Resolution
Re Pr F1 Re Pr F1
Baseline 1.0 .50 .67 1.0 .60 .75
Oracle .77 .96 .85 .74 .99 .84
WCN,parse,sem .63 .69 .66 .61 .66 .64
+ sem-sim .65 .71 .68 .64 .69 .67
+ lexical .65 .67 .66 .65 .70 .67
Table 7: Parse ranking results for I & R Utterances
using manual transcriptions.
covered by the selected parse; precision is the to-
tal proportion of the chosen parse which overlaps
with the gold-standard summary. The baseline is
the entire transcription, and we also compare to
an ?oracle? that always chooses a parse with the
highest F1-score. Note that we use the extractive
summaries from the manual transcriptions as the
gold-standard for the evaluation of the results ob-
tained with ASR.
Results and analysis: Results with manual tran-
scriptions are shown in Table 7, and those with
ASR, in Table 8. In all cases, when starting with
a feature set containing WCN, parse and seman-
tic features, the F1-score is improved by adding
the semantic-similarity feature. For Issues, the F1-
score improves from .66 to .68 with manual tran-
scripts, and from .30 to .32 with ASR. The im-
provements for Resolutions are highly significant:
with manual transcripts, the F1 score increases
from .64 to .67 (p < 0.005), and with ASR, from
.33 to .37 (p < 0.005). Note that the further addi-
tion of lexical features only produces a significant
improvement in the case of I summarization with
ASR.
Compared to the full transcript baseline, we
achieve higher F1-scores for Issues?.68 vs. .67
with manual transcriptions, and .35 vs. .31 with
ASR?but slightly lower for Resolutions. There
remains a fairly large gap between our best scores
and their corresponding oracles (especially with
ASR), and so there may still be potential for sub-
stantial improvement.
Issue Resolution
Re Pr F1 Re Pr F1
Baseline .77 .20 .31 .80 .27 .40
Oracle .61 .87 .72 .59 .91 .72
WCN,parse,sem .28 .33 .30 .31 .35 .33
+ sem-sim .30 .34 .32 .35 .38 .36
+ lexical .35 .35 .35 .34 .39 .37
Table 8: Parse ranking results for I & R Utterances
using ASR.
6 Conclusions and Future Work
This paper has presented work on the detec-
tion and summarization of decision discussions
in multi-party dialogue. In the detection experi-
ments, we investigated the use of directed graph-
ical models (DGMs), and found that when us-
ing non-lexical features, the DGMs outperform
the hierarchical SVM classification method of
Ferna?ndez et al (2008b). The F1-score for the
four DDA classes increased between .04 and .19
(p < .005), and for identifying decision discus-
sion regions, by .05. This is encouraging because
lexical features have disadvantages?for example
they can be domain specific and greatly increase
the feature space. In addition, modelling the de-
pendencies between the DDA classes increased
performance for Agreement utterances, and the
DGMs were robust to ASR.
In the summarization experiments, we sum-
marized decision discussions by extracting key
words/phrases from their Issue (I) and Resolu-
tion (R) utterances. Each utterance?s Word Confu-
sion Network was parsed with an open-domain se-
mantic parser, thus producing multiple candidate
phrases, and then an SVM regression model se-
lected one of these phrases to enter into the sum-
mary. The experiments here investigated the use-
fulness of a new SVM feature which measures the
level of semantic similarity between candidate I
parses and R utterances, and vice-versa. This fea-
ture was generated with a semantic-similarity met-
ric which uses WordNet as a knowledge source.
It was found to improve performance with both
manual transcripts and ASR, and for R summa-
rization, the improvements were highly significant
(p < .005).
In future work, we plan to integrate lexical fea-
tures into our DGMs by using a switching Dy-
namic Bayesian Network similar to that reported
in (Ji and Bilmes, 2005). We also plan to extend
the decision discussion annotation scheme so that
we can try to automatically extract supporting ar-
241
guments for decisions.
Acknowledgements This material is based
upon work supported by the Defense Advanced
Research Projects Agency (DARPA) under Con-
tract No. FA8750-07-D-0185/0004, and by the
Department of the Navy Office of Naval Research
(ONR) under Grants No. N00014-05-1-0187 and
N00014-09-1-0106. Any opinions, findings and
conclusions or recommendations expressed in
this material are those of the authors and do not
necessarily reflect the views of DARPA or ONR.
References
Satanjeev Banerjee, Carolyn Rose?, and Alex Rudnicky.
2005. The necessity of a meeting recording and
playback system, and the benefit of topic-level anno-
tations to meeting browsing. In Proceedings of the
10th International Conference on Human-Computer
Interaction.
John Dowding, Jean Mark Gawron, Doug Appelt, John
Bear, Lynn Cherny, Robert Moore, and Douglas
Moran. 1993. GEMINI: a natural language system
for spoken-language understanding. In Proceedings
of the 31st Annual Meeting of the Association for
Computational Linguistics (ACL).
Raquel Ferna?ndez, Matthew Frampton, John Dowding,
Anish Adukuzhiyil, Patrick Ehlen, and Stanley Pe-
ters. 2008a. Identifying relevant phrases to summa-
rize decisions in spoken meetings. In Proceedings
of Interspeech.
Raquel Ferna?ndez, Matthew Frampton, Patrick Ehlen,
Matthew Purver, and Stanley Peters. 2008b. Mod-
elling and detecting decisions in multi-party dia-
logue. In Proceedings of the 9th SIGdial Workshop
on Discourse and Dialogue.
Michel Galley, Kathleen McKeown, Julia Hirschberg,
and Elizabeth Shriberg. 2004. Identifying agree-
ment and disagreement in conversational speech:
Use of Bayesian networks to model pragmatic de-
pendencies. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
Daniel Gatica-Perez, Ian McCowan, Dong Zhang, and
Samy Bengio. 2005. Detecting group interest level
in meetings. In Proceedings of ICASSP.
Pey-Yun Hsueh and Johanna Moore. 2007. Automatic
decision detection in meeting speech. In Proceed-
ings of MLMI 2007, Lecture Notes in Computer Sci-
ence. Springer-Verlag.
Adam Janin, Jeremy Ang, Sonali Bhagat, Rajdip
Dhillon, Jane Edwards, Javier Marc??as-Guarasa,
Nelson Morgan, Barbara Peskin, Elizabeth Shriberg,
Andreas Stolcke, Chuck Wooters, and Britta Wrede.
2004. The ICSI meeting project: Resources and re-
search. In Proceedings of the 2004 ICASSP NIST
Meeting Recognition Workshop.
Gang Ji and Jeff Bilmes. 2005. Dialog act tagging
using graphical models. In Proceedings of ICASSP.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In B. Scho?lkopf, C. Burges, and
A. Smola, editors, Advances in Kernel Methods ?
Support Vector Learning. MIT Press.
Claudia Leacock and Martin Chodorow, 1998. Word-
Net: An Electronic Lexical Database, chapter Com-
bining local context and WordNet similarity for
word sense identification. University of Chicago
Press.
Iain McCowan, Jean Carletta, W. Kraaij, S. Ashby,
S. Bourban, M. Flynn, M. Guillemot, T. Hain,
J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lathoud,
M. Lincoln, A. Lisowska, W. Post, D. Reidsma, and
P. Wellner. 2005. The AMI Meeting Corpus. In
Proceedings of Measuring Behavior, the 5th Inter-
national Conference on Methods and Techniques in
Behavioral Research, Wageningen, Netherlands.
Kevin Murphy. 2002. Dynamic Bayesian Networks:
Representation, Inference and Learning. Ph.D. the-
sis, University of California Berkeley.
Ted Pedersen. 2002. Semantic similarity package.
http:/www.d.umn.edu/ tpederse/similarity.
Matthew Purver, John Dowding, John Niekrasz,
Patrick Ehlen, Sharareh Noorbaloochi, and Stanley
Peters. 2007. Detecting and summarizing action
items in multi-party dialogue. In Proceedings of the
8th SIGdial Workshop on Discourse and Dialogue,
Antwerp, Belgium.
Andreas Stolcke, Xavier Anguera, Kofi Boakye, O?zgu?r
C?etin, Adam Janin, Matthew Magimai-Doss, Chuck
Wooters, and Jing Zheng. 2008. The ICSI-SRI
spring 2007 meeting and lecture recognition system.
In Proceedings of CLEAR 2007 and RT2007.
Daan Verbree, Rutger Rienks, and Dirk Heylen. 2006.
First steps towards the automatic construction of
argument-diagrams from real discussions. In Pro-
ceedings of the 1st International Conference on
Computational Models of Argument, volume 144,
pages 183?194. IOS press.
Steve Whittaker, Rachel Laban, and Simon Tucker.
2006. Analysing meeting records: An ethnographic
study and technological implications. In S. Renals
and S. Bengio, editors, Machine Learning for Multi-
modal Interaction: Second International Workshop,
MLMI 2005, Revised Selected Papers, volume 3869
of Lecture Notes in Computer Science, pages 101?
113. Springer.
Klaus Zechner. 2002. Automatic summarization of
open-domain multiparty dialogues in diverse genres.
Computational Linguistics, 28(4):447?485.
242
Appendix
DDA
E
a) BN-sim
DDA
E
b) BN-mix
C
DDA
time t-1 time t
E
DDA
E
c) DBN-sim
DDA
time t-1 time t
E
DDA
E
d) DBN-mix
CC
Figure 1: Simple DGMs for individual decision
detection. During training, the shaded nodes are
hidden, and the clear nodes are observable.
A
time t-1 time t
E
A
E
I I
RP RP
RR RR
Figure 2: A DGM that takes the dependencies be-
tween decisions into account.
243
