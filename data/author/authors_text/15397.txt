Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 433?440
Manchester, August 2008
Generation of Referring Expressions: Managing Structural
Ambiguities
?
Imtiaz Hussain Khan and Kees van Deemter and Graeme Ritchie
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, U.K.
{i.h.khan,k.vdeemter,g.ritchie}@abdn.ac.uk
Abstract
Existing algorithms for the Generation
of Referring Expressions tend to gen-
erate distinguishing descriptions at the
semantic level, disregarding the ways
in which surface issues can affect their
quality. This paper considers how these
algorithms should deal with surface am-
biguity, focussing on structural ambi-
guity. We propose that not all ambigu-
ity is worth avoiding, and suggest some
ways forward that attempt to avoid un-
wanted interpretations. We sketch the
design of an algorithm motivated by our
experimental findings.
1 Introduction
A Noun Phrase (np) is a referring expression
if its communicative purpose is to identify an
object to a hearer. The Generation of Refer-
ring Expressions (gre) is an integral part of
most Natural Language Generation (nlg) sys-
tems (Reiter and Dale, 2000). The gre task
can informally be stated as follows. Given an
intended referent (i.e., the object to be identi-
fied) and a set of distractors (i.e., other objects
that can be confused with the referent), find a
description that allows a hearer to identify its
referent uniquely (Dale, 1992). Such a descrip-
tion is called a Distinguishing Description
(dd). In practice, however, most gre algo-
rithms build sets of semantic properties avail-
able in a Knowledge Base (kb), rather than
descriptions in natural language; surface issues
are often ignored (exceptions are: (Stone and
?
This work is supported by a University of Ab-
erdeen Sixth Century Studentship, and EPSRC grant
EP/E011764/1.
?
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported.
Some rights reserved.
Webber, 1998; Krahmer and Theune, 2002;
Siddharthan and Copestake, 2004)). This is
an important limitation, for example because
ambiguities can be introduced in the step from
properties to language descriptions. Such ?sur-
face ambiguities? take centerstage in this pa-
per. More specifically, we shall be investigating
situations where they lead to referential ambi-
guity, that is, unclarity as to what the intended
referent of a referring expression is.
Example 1: Consider a scenario in which
there are sheep and goats along with other an-
imals, grazing in a meadow; some of the sheep
and goats are black while others are either
brown or yellow. Suppose our task is to single
out the black sheep and black goats from the
rest of the animals. Suppose an algorithm has
generated the logical form
1
(Black ? Sheep) ?
(Black ? Goats), which could be realised as
either the black sheep and the black goats or,
more briefly, as the black sheep and goats. The
latter np expresses two non-equivalent logical
formulae: (i) (Black ? Sheep) ? Goats, and
(ii) (Black ? Sheep) ? (Black ? Goats). Since
both formulae correspond with a set of animals
in the domain, referential ambiguity can result.
On the other hand, the black sheep and goats
is shorter and possibly more fluent. This ex-
ample highlights the possible tension between
brevity and lack of ambiguity. The question
facing us in this paper is how to balance them.
This paper examines how gre should deal
with structural ambiguity, focussing on ambi-
guity of the form the Adj Noun1 and Noun2,
also known as coordination ambiguity. We
call referring expressions of this form scopally
ambiguous, as the scope of Adj is unclear be-
tween wide scope (Adj applies to both nouns)
and narrow scope (Adj applies only to Noun1).
1
In this paper, we use set-theoretic operators instead
of logical connectives to represent logical forms.
433
2 Approach
A cursory view of corpora such as the British
National Corpus (bnc) reveals that there are
many instances of coordination ambiguity:
1. the black cats and dogs
2. the bearded men and women
3. the old men and women in the hats
Psycholinguistic evidence suggests that, in
many cases, these ambiguities could cause con-
fusion for a hearer (Tanenhaus and Trueswell,
1995). Hence, it seems justifiable to have gre
avoid such kind of ambiguities. However, it
also seems plausible that some readings may
be very unlikely. For example, in (2) a wide-
scope reading is, arguably, very unlikely. Ab-
ney and others have argued that every sentence
is potentially ambiguous between many parses,
even though we may not even notice this ambi-
guity (Abney, 1996; Wasow et al, 2005). This
suggests that, in gre as well, it might not be
feasible to avoid all referential ambiguities all
the time, and that the choice of referring ex-
pression should sometimes involve a balancing
act in which degree of ambiguity is balanced
against other properties of the generated ex-
pression, such as its length or fluency.
Building on earlier work by Inui et al (Inui
et al, 1992), Neumann (Neumann, 1994) sug-
gested a general generate-parse-revise model
for nlg, based on a reversible grammar. His
generator generates a string which is then
parsed to detect any structural ambiguities. If
a string is found to be ambiguous then revi-
sion is used to produce an alternative, non-
ambiguous string instead (if such a string ex-
ists). The likelihood of the different interpre-
tations is not taken into account, however.
Our approach to the problem is to find out
the likelihood of each interpretation of an np,
and to tailor gre to avoid all distractor in-
terpretations (i.e., interpretations that can
be confused with the intended one) as sug-
gested in (van Deemter, 2004). An interpre-
tation can be confused with the intended one
if it is more likely or almost as likely as the in-
tended one. The problem is, how to determine
the likelihood of different interpretations.
3 Getting likelihood from the bnc
In scopally ambiguous referring expressions,
there is a tension between wide- and narrow-
scope interpretations. This can be viewed in
terms of two competing forces: a Coordination
Force, whereby Noun1 and Noun2 attract each
other to form a syntactic unit, and a Modifi-
cation Force, whereby Adj and Noun1 attract
each other to form a syntactic unit. Computa-
tional linguists have proposed using language
corpora to estimate the likelihood of an inter-
pretation (Wu and Furugori, 1998; Chantree
et al, 2006). Chantree et al used information
from the Sketch Engine database (Kilgarriff,
2003) operating on the bnc to resolve coor-
dination ambiguity. The Sketch Engine con-
tains grammatical triples in the form of Word
Sketches for each word, with each triple ac-
companied by a salience value indicating the
likelihood of occurrence of the word with its
argument in a grammatical relation. Word
Sketches summarise the words? grammatical
and collocational behavior.
Chantree et al gathered a dataset of am-
biguous phrases from a corpus of requirements
specifications, and collected human judge-
ments about their interpretations. They then
used machine learning techniques combined
with various heuristics to determine the most
likely interpretation of a coordination. They
identified two heuristics as particularly useful.
One was the Coordination-Matches Heuristic:
if a coordination between two head nouns oc-
curs (at all) within the corpus, then a wide-
scope reading is likely. The other was the
Collocation-Frequency Heuristic: if a modi-
fier is collocated more frequently with the near-
est head word than with the head word further
away, then a narrow-scope reading is likely.
The best performance was achieved by combin-
ing the two heuristics: wide-scope reading is
likely if Coordination-Matches heuristic gives
a positive result and Collocation-Frequency
heuristic gives a negative result. We decided
to modify Chantree et al?s approach in two
ways and apply the modified approach to nlg.
Firstly, it seemed unlikely to us in the gen-
eral case that the deciding factor is always
whether two words co-occur at all. We there-
fore decided to separate cooccurence percent-
ages into ones that are very high and ones
that are very low. Secondly, we observed that
Chantree et al take Coordination Force into
account when they predict wide scope, but not
434
when they predict narrow scope. It would
be more systematic ? and more useful to an
nlg system, which has to cope with all possi-
ble inputs ? to consider all four combinations,
of strong and weak, coordination and modifi-
cation force. We define that there will be a
Strong Coordination Force (SCF) if the collo-
cational frequency between the two nouns is
high, and a Weak Coordination Force (WCF)
otherwise. Similarly, we define that there
will be a Strong Modification Force (SMF) if
the collocational frequency of Adj is high with
Noun1 and low with Noun2, and a Weak Mod-
ification Force (WMF) otherwise.
After a preliminary investigation of the data,
we decided to operationalise high collocational
frequency between two words as meaning that
either of the two words appears among the top
30% collocates of the other word in a gram-
matical relation (of interest); low collocational
frequency means that neither of the two words
appears among the top 70% collocates of the
other word in a grammatical relation. The hy-
potheses resulting from the above changes are
investigated in the following section.
4 Empirical Studies
We conducted three experiments. The first
two experiments ask what interpretation of
a scopally ambiguous np is the most plau-
sible, thereby testing our generalisation of
Chantree?s hypotheses. Knowing how an np
is interpreted is useful for an nlg system but
not sufficient, because ambiguity needs to be
traded off against other factors. For this rea-
son, our third experiment asks which of several
nps are preferred by a reader.
4.1 Interpreting nps
We use all four possible combinations of coor-
dination and modification forces to predict an
interpretation of a scopally ambiguous refer-
ring expression (see Table-1). An SMF would
make a wide-scope reading highly unlikely (cf.
(Wu and Furugori, 1998)). For instance, in the
bearded men and women there is an SCF and
an SMF, but in fact this phrase would be in-
terpreted as a narrow-scope reading because of
the scarcity of bearded women. On the other
hand, a WMF could be in favor of a wide-scope
reading. We expect that human readers would
opt for wide- and narrow-scope readings ac-
cording to Table 1.
Table 1: Predicting an interpretation
Hypothesis 1: SCF ? SMF ? NS
Hypothesis 2: SCF ? WMF ? WS
Hypothesis 3: WCF ? SMF ? NS
Hypothesis 4: WCF ? WMF ? WS
WS: Wide scope; NS: Narrow scope
To test these hypotheses, we conducted two
interpretation experiments, and rather than
asking expert linguists to annotate the strings,
we examined how ordinary readers interpret
structurally ambiguous strings. In these ex-
periments, given a referential domain and an
English np which attempts to identify a sub-
set of objects in the domain, participants were
asked to find the referent set of the np.
4.1.1 Experiment 1
In this experiment, referential domains were
constructed using real photographs of animals
with some of the features printed alongside
each photograph. Features were printed be-
cause 1) in a pilot study, we observed that
some participants had difficulty in discerning
some features in some of the photographs, and
2) we attribute some unusual features to some
objects, e.g., we attributed cats with the fea-
ture barking although cats don?t bark in re-
ality. Two pairs of nouns were used: one with
SCF, and the other with WCF. For each pair
of nouns, four different adjectives were used:
two with SMF, and two with WMF. A trial
in this experiment consists of a set of 9 pic-
tures (placed in a 3 x 3 grid), and an English
np underneath these pictures. A sample trial
is shown in Figure 1. Participants? task was
to remove the pictures (by mouse clicks on the
pictures) that were referred to by the np. A
removed picture was immediately replaced by
a blank rectangle (of the same size).
In each trial, we made sure that both wide-
and narrow-scope readings are applicable. For
example, for the instruction Please, remove the
red lions and horses, in the domain there were
2 red lions, 2 red horses, and some (at least
one) non-red horses. If a participant removes
2 red lions and 2 red horses, we count it as a
wide-scope reading. However, if (s)he removes
all the horses we count it as a narrow-scope
reading. We also used 8 fillers, which do not
435
Figure 1: Interpreting an np (using pictures)
contain a coordination in the np (e.g., the dogs
on the left). 60 self-reported native or fluent
speakers of English, students from various UK
universities, did the experiment on the web.
2
Results and Discussion: Results were anal-
ysed according to whether a participant opted
for a wide- or narrow-scope reading. The par-
ticipants? responses are shown in Table 2. A
two-tailed sign binomial test was used to cal-
culate statistical significance. The data indi-
cate that word distribution information can re-
liably predict a wide-scope reading. However,
our predictions for a narrow-scope reading are
not confirmed. This may have been because
of an intrinsic bias in favour of wide-scope in-
terpretations. Another potential problem with
the experiment is that some of the nps shown
to participants were rather unusual, involving
bearded women, etc. Although the printed fea-
tures underneath the pictures forced partici-
pants to take these unusual cases seriously, the
clash between the picture (of a woman) and the
printed feature (?bearded?) that arose in such
cases may have made participants? responses
unreliable. To avoid this problem we now turn
to an experimental setup where we use Euler
diagrams instead of iconic pictures.
4.1.2 Experiment 2
This experiment mirrors experiment 1, but
we used Euler diagrams instead of pictures
2
Here and in the other experiments reported in this
paper, we ascertained that no important differences ex-
isted between the two groups of subjects. Focussing on
Experiment 1, for example, no significant difference in
the percentages of wide scope interpretations was found
between native speakers and subjects who were merely
fluent in English.
Table 2: Response proportions: Experiment 1
Force PR PJ p-value
SCF SMF NS NS (25/60) 0.52
SCF WMF WS WS (57/60) < 0.001
WCF SMF NS NS (26/60) 0.12
WCF WMF WS WS (53/60) < 0.001
PR: Predicted Reading; PJ: Participants? Judgement
to represent domain entities. Participants re-
ceived a mini-tutorial on our version of Eu-
ler diagrams, where shaded areas denote the
sets to which an NP might refer. The pur-
pose of this tutorial was to make sure that
the participants understand the semantics of
these diagrams. A sample trial is shown in
Figure 2 (where we expect that participants
would remove the diagram on the right, which
is counted as a wide-scope response). 60 self-
reported native or fluent speakers of English,
students from various UK universities, took
part in this web-based experiment.
Figure 2: Interpreting an np (Euler diagrams)
Results and Discussion: Results were
recorded according to whether a participant
opted for a wide- or narrow-scope reading. The
participants? responses are shown in Table 3.
A two-tailed sign binomial test was used to
calculate statistical significance of the results.
This time, all four hypotheses are confirmed.
We also observed, however, that in scopally
ambiguous expressions, a narrow-scope read-
ing tends to be particularly frequent in the ex-
treme case where Adj has a zero co-occurrence
with Noun2 (in the bnc). We note that these
results are in line with Chantree et al
A critic might argue that the problem that
was noted in connection with Experiment 1
applies to Experiment 2 as well, because it
shows diagrams involving a ?problematic? in-
436
Table 3: Response proportions: Experiment 2
Force PR PJ p-value
SCF SMF NS NS (51/60) < 0.001
SCF WMF WS WS (55/60) < 0.001
WCF SMF NS NS (46/60) < 0.001
WCF WMF WS WS (54/60) < 0.001
tersection between, for example, bearded and
women. The fact that women (arguably) can-
not be bearded could cause subjects to re-
ject these diagrams (choosing the other dia-
gram instead, as in the diagram included in
Fig. 3, which does not involve such an inter-
section). We would argue, however, that this
does not cause an unwanted bias. The scarcity
of bearded women is a legitimate reason for
subjects to believe that a diagram that asserts
their existence cannot be a proper interpreta-
tion of ?bearded men and women?; it is just
one of the many things that the corpus-based
approach captures indirectly, without repre-
senting it explicitly. It is equally applicable to
expressions like ?handsome men and women?,
where the corpus tells us that ?handsome? and
?women? do not go together well (even though
one probably would not say they do not exist).
We have seen that Word Sketches can make
reasonable predictions concerning the likeli-
hood of the different interpretations of the nps.
But an np that is clear (i.e., not likely to be
misunderstood) may have other disadvantages.
For example, it may lack fluency or it may be
perceived as unnecessarily lengthy. For this
reason, we also conducted an additional exper-
iment in which we tested readers? preferences.
4.2 Choosing the best np
The question of how to choose between differ-
ent nps could be approached in a number of
different ways: asking hearers which of sev-
eral descriptions they prefer, asking hearers
to rate several descriptions, measuring inter-
pretation effort (time), measuring hearers? er-
rors etc.. We conducted a readers? preference
experiment where participants were asked to
compare pairs of natural language descriptions
of one and the same target set, selecting the
one they found more appropriate. Brief de-
scriptions took the form the Adj Noun1 and
Noun2. Non-brief descriptions took the forms
the Adj Noun1 and the Noun2 (for NS) and the
Adj Noun1 and the Adj Noun2 (for WS). A de-
scription is said to be clear if its predicted read-
ing is the same as the intended one. By def-
inition a non-brief description is always clear.
Each description could either be brief or not
(?b) and also clear or not (?c) (but not (?b,
?c), as this combination is not applicable in
the present setting). We expected to find that:
Hypothesis 5: (+c,+b) descriptions are pre-
ferred over ones that are (+c,?b).
Hypothesis 6: (+c,?b) descriptions are pre-
ferred over ones that are (?c,+b).
4.2.1 Experiment 3
In this experiment, referential domains were
represented using Euler diagrams. In each
trial, participants were shown an Euler dia-
gram, with some of its area filled to indicate
the target referent. They were also shown two
English nps, which attempted to identify the
filled area. A sample trial, where the intended
reading is narrow scope, is shown in Figure
3. Each hypothesis was tested under two con-
Figure 3: Sample Trial: Choosing the best np
ditions: 1) where the intended reading (IR)
was WS; and 2) where the IR was NS. The 4
comparisons thus corresponded to 4 conditions
(where PR stands for predicted reading):
C1. IR = WS & PR = WS
(+c,+b) vs. (+c,?b)
C2. IR = NS & PR = NS
(+c,+b) vs. (+c,?b)
C3. IR = WS & PR = NS
(?c,+b) vs. (+c,?b)
C4. IR = NS & PR = WS
(?c,+b) vs. (+c,?b)
46 self-reported native or fluent speakers of En-
437
glish, students from various UK universities,
did the experiment on the web.
Results and Discussion: Results were
coded according to whether a participant?s
choice was ?b and/or ?c. Table 4 displays
response proportions. A two-tailed sign bino-
mial test was used to calculate statistical sig-
nificance of the results. The results confirm
our hypotheses in all conditions, being highly
statistically significant (p < 0.001).
Table 4: Response proportions: Experiment 3
C1 C2 C3 C4
+b 91.3% 67.9% 26.1 14.5
+c - - 73.9% 88.5%
4.3 Summary of the Empirical Data
As hypothesised, Kilgarriff?s Word Sketches
can be used to predict the most likely read-
ing of a scopally ambiguous expression. It is
also important to note that it is the Modifi-
cation Force which is the deciding factor for
a particular reading. Moreover, other things
being equal, brief descriptions are preferred
over longer ones. Since Experiment 2 (and,
to an extent, Experiment 1) confirmed our hy-
potheses, we could have based our algorithm
on these. As was noted in section 4.1.2, how-
ever, our data also suggest a slight modifica-
tion of Hypotheses 1 and 3, because a pref-
erence for narrow scope existed mainly when
the Adjective and the second Noun co-occurred
very rarely. Therefore, we shall use a modified
version of Strong Modification Force (SMF):
SMF
?
will mean that Adj and Noun2 have zero
(rather than below 30%) cooccurrence in the
bnc.
5 Applying results to gre
In this section, we show how the results of
the previous sections can be exploited in gre.
The patterns explored in the above correspond
to disjunctive plural references. Disjunction is
required whenever there is no conjunction of
atomic properties that sets the elements of a
set of referents apart from all the other ob-
jects in the domain. Recall example 1 (from
?1), where the aim is to single out the black
sheep and black goats from the rest of the an-
imals. This task cannot be performed by a
simple conjunction (i.e., of the form ?the X?,
where X contains adjectives and nouns only),
so disjunctions become unavoidable.
Various proposals have been made for al-
lowing gre algorithms to produce referring
expressions of this kind (Stone, 2000; van
Deemter, 2002; Gardent, 2002; Horacek,
2004). Here we take as our starting point the
approach of (Gatt, 2007) (henceforth Gatt?s
Algorithm with Partitioning or gap). gap is
the only algorithm that produces a dd in Dis-
junctive Normal Form (dnf) while also guar-
anteeing that every ?part? of the partition
contains a noun. The dnf takes the form:
S
1
? S
2
... ? S
n
, where each S
i
itself expresses
a conjunction of atomic properties. (For ex-
ample, S
1
might be Sheep ? Black, while S
2
is Goat ? Black.) We sketch two extensions of
this approach: the first, purely formal exten-
sion ensures that a set of such logical formulae
is generated, rather than just one formula; all
of these formulae are unambiguous, and logi-
cally equivalent with each other; but they all
map to different strings of words. This is be-
cause we assume a very direct Linguistic Real-
isation strategy in which, for example, ((Black
? Sheep) ? Goats) is worded as the black sheep
and goats; syntactic ambiguity results from the
lack of brackets in the English np. The sec-
ond, empirically based extension is to choose
the ?best? element of the set (of formulae) by
making use of our experimental outcomes so as
to balance clarity and brevity.
Since our predictions are based on words,
we propose a model that constructs descrip-
tions from words and in which the description
building process is driven by words. We com-
pute the extension (where the extension of a
word w consists of all objects to which w ap-
plies) of a potentially ambiguous word by uni-
fying the extensions of all its interpretations.
Let p
1
, p
2
, ..., p
n
be the properties that a word
w can express. Then the extension of w is:
[[ w ]] =
i=n
?
i=1
[[ p
i
]] (1)
In what follows, a domain consists of a set D
of objects, and a set P of properties applicable
to objects in D. Given a set of target referents
R ? D, the proposed algorithm will:
? lexicalise each p ? P into words; Lexi-
calisation takes a property as input and
438
returns the set of possible realisations of
that property. For example, a property,
say, aged will be realised as (a set of)
words {old, aged, senior}.
? build a dd in dnf using words, where the
extension of a word is computed as indi-
cated in equation 1. Each S
i
must contain
a head noun. For example, in the sce-
nario presented in Example 1 under ?1, it
would produce a dd like: (black ? sheep)
? (black ? goats).
? apply transformation rules on the dd to
construct a set of dds that are logically
equivalent to the dd. (See below.)
? realise each description in the set as En-
glish nps using appropriate syntax. Each
description is realised as one and only one
np, using the above realisation strategy.
? determine the most likely reading of each
np, by making use of Word Sketches.
? select the np that is optimal given our em-
pirical findings. (See below.)
Transformation Rules: In connection with
reference to sets, it has been proposed to use
the Q-M algorithm (McCluskey, ) to find the
shortest formula equivalent to a given input
formula (van Deemter, 2002). In the present
setting, the shortest formula might lead to a
confusing np after linguistic realisation. For
example, the formula Black ? (Cats ? Dogs)
might be realised as the black cats and dogs,
which could easily be misunderstood as (Black
? Cats) ? Dogs. For this purpose, we propose
to use a set of transformation rules that allow
us to find a set of formulae logically equivalent
to the original formula; the aim is to make the
set large enough that all the relevant expres-
sive choices (as investigated in this paper) are
represented. In particular, we need the follow-
ing rules that operate on dnfs (where A is an
adjective; B
1
and B
2
are nouns; X and Y are
combinations of adjectives and nouns).
1. ((A ?B
1
) ? (A ?B
2
)) ? (A ? (B
1
?B
2
))
2. (X ? Y ) ? (Y ?X)
After application of these transformation
rules, the original description ? (i.e., the for-
mula produced by an algorithm such as gap)
is replaced by a set of formulae F all of whose
elements are logically equivalent to ?. The el-
ements of F are then realised as nps. The clar-
ity of each np is determined as follows (where
PR and IR stand for predicted reading and in-
tended reading, respectively).
If SMF? then PR is NS
Else If WMF then PR is WS
Else PR is {NS, WS}
EndIf
If (PR = IR) then NP is clear
Else NP is unclear
EndIf
If, after transformations, several of the re-
sulting descriptions are clear then the choice
between them needs to be taken on other
grounds. To do this, we give preference to the
shortest of all descriptions that are clear (mea-
sured in terms of number of words in the np).
If ties still arise then we suggest that fluency
is taken into account, for example by prefer-
ring np whose structure is most frequent in
the bnc. This procedure will often result in
nps that are ?clear? even though they are syn-
tactically ambiguous.
Example 2: Let the domain be repre-
sented as: {man(e
1
, e
2
, e
6
), woman(e
3
, e
4
, e
5
),
young(e
5
, e
6
), old(e
1
, e
2
, e
3
, e
4
)}. Our task
is to single out {e
1
, e
2
, e
3
, e
4
} from rest of
the entities. First, properties are lexicalised
into words. Suppose the relevant words are
the ones in the list Q = ?man, woman, old,
young?. Then, the algorithm takes each word
w ? Q in turn and constructs a dd: (old ?
man) ? (old ? woman). The transformation
rules then produce {old?(man?woman), old?
(woman?man), (old?man)? (old?woman),
(old?woman)? (old?man)}. These formulae
are realised as: (1) the old men and women, (2)
the old women and men, (3) the old men and
the old women and (4) the old women and the
old men. The nps (1) and (2) are structurally
ambiguous, but the Word Sketches rule out the
unintended reading of both nps (with narrow
scope for the adjective), so they are both clear.
The nps (3) and (4) are structurally unam-
biguous. All nps are therefore clear, but (1)
and (2) are preferred because they are shorter
than (3) and (4). Corpus frequency suggests
that the tie between (1) and (2) is resolved by
opting for the more frequent pattern (1).
6 Conclusions and future work
We highlighted that structural ambiguity,
which is often ignored in the gre could cause
439
confusion for a hearer and, therefore, should be
dealt with. Based on psycholinguistic evidence
that avoidance of all ambiguity is hard, we sug-
gested an approach that avoids referring ex-
pressions that have distractor interpretations.
We did: (1) interpretation experiments and
found that Word Sketches can be used to make
distractor interpretation precise; and (2) an
experiment with human readers that trades-
off clarity and brevity. A gre algorithm is
sketched that balances these factors based on
our experimental findings.
We aim to extend this work in two direc-
tions. First, we hypothesise that our ap-
proach can help nlg systems handle other sur-
face ambiguities, for instance involving PP-
attachment. Second, we realise that contex-
tual factors are likely to affect people?s inter-
pretive and generative inclinations. Therefore,
in light of the work reported in this paper, it
would be interesting to explore the effect of
co-occurrences in a given text upon the inter-
pretation of nps occurring later in that same
text, since the effect of such earlier occurrences
on readers? interpretation could conceivably
?drown out? the generic likelihoods based on
Word Sketches that have formed the main sub-
ject matter of this paper.
References
Abney, S. 1996. Statistical methods and linguis-
tics. In Klavans, Judith and Philip Resnik, ed-
itors, The Balancing Act: Combining Symbolic
and Statistical Approaches to Language, pages 1?
26. The MIT Press, Cambridge, Massachusetts.
Chantree, F., B. Nuseibeh, A. de Roeck, and
A. Willis. 2006. Identifying nocuous ambigui-
ties in requirements specifications. In Proceed-
ings of 14th IEEE International Requirements
Engineering conference, Minnesota, U.S.A.
Dale, R. 1992. Generating Referring Expressions:
Building Descriptions in a Domain of Objects
and Processes. MIT Press.
Gardent, C. 2002. Generating minimal definite
descriptions. In Proceedings of the 40th Annual
Meeting of the ACL, Philadelphia, USA.
Gatt, A. 2007. Generating Coherent References
to Multiple Entities. Ph.D. thesis, University of
Aberdeen, Aberdeen, Scotland.
Horacek, H. 2004. On referring to sets of objects
naturally. In Proceedings of the 3rd International
Conference on NLG, pages 70?79, UK.
Inui, K., T. Tokunaga, and H. Tanaka. 1992. Text
revision: A model and its implementation. In
Proceedings of the 6th International Workshop
on NLG, pages 215?230, Berlin, Heidelberg.
Kilgarriff, A. 2003. Thesauruses for natural lan-
guage processing. In Proceedings of NLP-KE,
pages 5?13, Beijing, China.
Krahmer, E. and M. Theune. 2002. Efficient
context-sensitive generation of referring expres-
sions. In van Deemter, K. and R. Kibble, editors,
Information Sharing: Reference and Presupposi-
tion in Language Generation and Interpretation,
CSLI Publications, pages 223?264.
McCluskey, E. J. Introduction to the Theory of
Switching Circuits. McGraw-Hill Book Co.
Neumann, G. 1994. A Uniform Computational
Model for Natural Language Parsing and Gener-
ation. Ph.D. thesis, University of the Saarland.
Reiter, E. and R. Dale. 2000. Building Natural
Language Generation Systems. Cambridge Uni-
versity Press.
Siddharthan, A. and A. Copestake. 2004. Gener-
ating referring expressions in open domains. In
Proceedings of the 42nd Annual Meeting of the
ACL, Barcelona, Spain.
Stone, M. and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics.
In Proceedings of the 9th International Workshop
on NLG, pages 178?187, New Brunswick, New
Jersey.
Stone, M. 2000. On identifying sets. In Proceed-
ings of the 1st INLG Conference, pages 116?123,
Mitzpe Ramon.
Tanenhaus, M.K. and J.C. Trueswell. 1995. Sen-
tence comprehension. In Miller, J. and P. Eimas,
editors, Handbook of Perception and Cognition,
Vol. 11: Speech, Language and Communication,
pages 217?262. New York: Academic Press.
van Deemter, K. 2002. Generating referring ex-
pressions: Boolean extensions of the incremental
algorithm. Comp. Linguistics, 28(1):37?52.
van Deemter, K. 2004. Towards a probabilistic
version of bidirectional OT syntax and seman-
tics. Journal of Semantics, 21(3):251?281.
Wasow, T., A. Perfors, and D. Beaver. 2005. The
puzzle of ambiguity. In Orgun, O. and P. Sells,
editors, Morphology and The Web of Grammar:
Essays in Memory of Steven G. Lapointe. CSLI
Publications.
Wu, H. and T. Furugori. 1998. A computational
method for resolving ambiguities in coordinate
structures. In Proceedings of PACLIC-12, pages
263?270, National University of Singapore.
440
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 102?111, Prague, June 2007. c?2007 Association for Computational Linguistics
Incremental generation of plural descriptions: Similarity and partitioning
Albert Gatt and Kees van Deemter
Department of Computing Science
University of Aberdeen
{agatt,kvdeemte}@csd.abdn.ac.uk
Abstract
Approaches to plural reference generation
emphasise descriptive brevity, but often lack
empirical backing. This paper describes
a corpus-based study of plural descrip-
tions, and proposes a psycholinguistically-
motivated algorithm for plural reference
generation. The descriptive strategy is based
on partitioning and incorporates corpus-
derived heuristics. An exhaustive evaluation
shows that the output closely matches hu-
man data.
1 Introduction
Generation of Referring Expressions (GRE) is a
well-studied sub-task of microplanning in Natural
Language Generation. Most algorithms in this area
view GRE as a content determination problem, that
is, their emphasis is on the construction of a se-
mantic representation which is eventually mapped
to a linguistic realisation (i.e. a noun phrase). Con-
tent Determination for GRE starts from a Knowledge
Base (KB) consisting of a set of entities U and a set
of properties P represented as attribute-value pairs,
and searches for a description D ? P which distin-
guishes a referent r ? U from its distractors. Under
this view, reference is mainly about identification of
an entitiy in a given context (represented by the KB),
a well-studied pragmatic function of definite noun
phrases in both the psycholinguistic and the compu-
tational literature (Olson, 1970).
For example, the KB in Table 1 represents 8 en-
tities in a 2D visual domain, each with 6 attributes,
including their location, represented as a combina-
tion of horizontal (X) and vertical (Y) numerical co-
TYPE COLOUR ORIENTATION SIZE X Y
e1 desk red back small 3 1
e2 sofa blue back small 5 2
e3 desk red back large 1 1
e4 desk red front large 2 3
e5 desk blue right large 2 4
e6 sofa red back large 4 1
e7 sofa red front large 3 3
e8 sofa blue back large 3 2
Table 1: A visual domain
ordinates. To refer to an entity an algorithm searches
through values of the different attributes.
GRE has been dominated by Dale and Reiter?s
(1995) Incremental Algorithm (IA), one version
of which, generalised to deal with non-disjunctive
plural references, is shown in Algorithm 1 (van
Deemter, 2002). A non-disjunctive reference to a
set R is possible just in case all the elements of R
can be distinguished using the same attribute-value
pairs. Such a description is equivalent to the logical
conjunction of the properties in question. This al-
gorithm, IAplur, initialises a description D and a set
of distractors C [1.1?1.2], and traverses an ordered
list of properties, called the preference order (PO)
[1.3], which reflects general or domain-specific pref-
Algorithm 1 IAplur(R,U,PO
1: D ? ?
2: C ? U ?R
3: for ?A : v? ? PO do
4: if R ? [[ ?A : v? ]] ? [[ ?A : v? ]]? C 6= ? then
5: D ? D ? {?A : v?}
6: C ? C ? [[ ?A : v? ]]
7: if [[ D ]] = R then
8: return D
9: end if
10: end if
11: end for
12: return D
102
erences for attributes. For instance, with the PO in
the top row of the Table, the algorithm first consid-
ers values of TYPE, then COLOUR, and so on, adding
a property to D if it is true of the intended referents
R, and has some contrastive value, that is, excludes
some distractors [1.4]. The description and the dis-
tractor set C are updated accordingly [1.5?1.6], and
the description returned if it is distinguishing [1.7].
Given R = {e1, e2}, this algorithm would return the
following description:
(1) ?ORIENTATION : back? ? ?SIZE : small?
This description is overspecified, because ORI-
ENTATION is not strictly necessary to distinguish
the referents (?SIZE : small? suffices). Moreover,
the description does not include TYPE, though it
has been argued that this is always required, as it
maps to the head noun of an NP (Dale and Re-
iter, 1995). We will adopt this assumption here, for
reasons explained below. Due to its hillclimbing
nature, the IA avoids combinatorial search, unlike
some predecessors which searched exhaustively for
the briefest possible description of a referent (Dale,
1989), based on a strict interpretation of the Gricean
Maxim of Quantity (Grice, 1975). Given that, un-
der the view proposed by Olson (1970) among oth-
ers, the function of a referential NP is to identify, a
strict Gricean interpretation holds that it should con-
tain no more information than necessary to achieve
this goal.
The Incremental Algorithm constitutes a depar-
ture from this view given that it can overspecify
through its use of a PO. This has been justified
on psycholinguistic grounds. Speakers overspecify
their descriptions because they begin their formula-
tion of a reference without exhaustively scanning a
domain (Pechmann, 1989; Belke and Meyer, 2002).
They prioritise the basic-level category (TYPE) of an
object, and salient, absolute properties like COLOUR
(Pechmann, 1989; Eikmeyer and Ahlse`n, 1996), as
well as locative properties in the vertical dimen-
sion (Arts, 2004). Relative attributes like SIZE
are avoided unless absolutely required for identi-
fication (Belke and Meyer, 2002). This evidence
suggests that speakers conceptualise referents as
gestalts (Pechmann, 1989) whose core is their basic-
level TYPE (Murphy, 2002) and some other salient
attributes like COLOUR. For instance, according to
Schriefers and Pechmann (1988), an NP such as the
large black triangle reflects a conceptualisation of
the referent as a black triangle, of which the SIZE
property is predicated. Thus, the TYPE+COLOUR
combination is not mentally represented as two sep-
arable dimensions.
In what follows, we will sometimes refer to this prin-
ciple as theConceptual Gestalts Principle. Note that
the IA does not fully mirror these human tendencies,
since it only includes preferred attributes in a de-
scription if they remove some distractors given the
current state of the algorithm, whereas psycholin-
guistic research suggests that people include them
irrespective of contrastiveness (but cf. van der Sluis
and Krahmer (2005)).
More recent research on plural GRE has de-
emphasised these issues, especially in case of dis-
junctive plural reference. Disjunction is required
whenever elements of a set of referents R do not
have identical distinguishing properties. For exam-
ple, {e1, e3} can be distinguished by the following
Conjunctive Normal Form (CNF) description1:
(2) ?TYPE : desk??
`
?COLOUR : red?? ?COLOUR : blue?
?
?
`
?ORIENTATION : right? ? ?ORIENTATION : back?
?
Such a description would be returned by a gen-
eralised version of Algorithm 1 proposed by van
Deemter (2002). This generalisation, IAbool (so
called because it handles all Boolean operators, such
as negation and disjunction), first tries to find a non-
disjunctive description using Algorithm 1. Failing
this, it searches through disjunctions of properties
of increasing length, conjoining them to the descrip-
tion. This procedure has three consequences:
1. Efficiency: Searching through disjunctive
combinations results in a combinatorial explo-
sion (van Deemter, 2002).
2. Gestalts and content: The notion of a ?pre-
ferred attribute? is obscured, since it is dif-
ficult to apply the same reasoning that moti-
vated the PO in the IA to combinations like
(COLOUR ? SIZE).
1Note that logical disjunction is usually rendered as linguis-
tic coordination using and. Thus, the table and the desk is the
union of things which are desks or tables.
103
3. Form: Descriptions can become logically very
complex (Gardent, 2002; Horacek, 2004).
Proposals to deal with (3) include Gardent?s
(2002) non-incremental, constraint-based algorithm
to generate the briefest available description of a
set, an approach extended in Gardent et al (2004).
An alternative, by Horacek (2004), combines best-
first search with optimisation to reduce logical com-
plexity. Neither approach benefits from empiri-
cal grounding, and both leave open the question of
whether previous psycholinguistic research on sin-
gular reference is applicable to plurals.
This paper reports a corpus-based analysis of plu-
ral descriptions elicited in well-defined domains, of
which Table 1 is an example. This study falls within
a recent trend in which empirical issues in GRE have
begun to be tackled (Gupta and Stent, 2005; Jordan
andWalker, 2005; Viethen and Dale, 2006). We then
propose an efficient algorithm for the generation of
references to arbitrary sets, which combines corpus-
derived heuristics and a partitioning-based proce-
dure, comparing this to IAbool. Unlike van Deemter
(2002), we only focus on disjunction, leaving nega-
tion aside. Our starting point is the assumption that
plurals, like singulars, evince preferences for certain
attributes as predicted by the Conceptual Gestalts
Principle. Based on previous work in Gestalt per-
ception (Wertheimer, 1938; Rock, 1983), we pro-
pose an extension of this to sets, whereby plural de-
scriptions are preferred if (a) they maximise the sim-
ilarity of their referents, using the same attributes to
describe them as far as possible; (b) prioritise salient
(?preferred?) attributes which are central to the con-
ceptual representation of an object. We address (3)
above by investigating the logical form of plurals in
the corpus. One determinant of logical form is the
basic-level category of objects. For example, to re-
fer to {e1, e2} in the Table, an author has at least the
following options:
(3) (a) the small desk and sofa
(b) the small red desk and the small blue sofa
(c) the small desk and the small blue sofa
(d) the small objects
These descriptions exemplify three possible sources
of variation:
Disjunctive/Non-disjunctive: The last description,
(3d), is non-disjunctive (i.e. it is logically a conjunc-
tion of properties). This, however, is only achiev-
able through the use of a non-basic level value for
the TYPE of the entities (objects). Using the basic-
level would require the disjunction (?TYPE : desk??
?TYPE : sofa?), which is the case in (3a?c). Given
that basic-level categories are preferred on indepen-
dent grounds (Rosch et al, 1976), we would expect
examples like (3d) to be relatively infrequent.
Aggregation: If a description is disjunctive, it may
be aggregated, with properties common to all ob-
jects realised as wide-scope modifiers. For instance,
in (3a), small modifies desk and sofa. By contrast,
(3b) is non-aggregated: small occurs twice (modi-
fying each coordinate in the NP). Non-aggregated,
disjunctive descriptions are logically equivalent to a
partition of a set. For instance, (3c) partitions the
set R = {e1, e2} into {{e1}, {e2}}, describing each
element separately. Descriptions like (3b) are more
overspecified than their aggregated counterparts due
to the repetition of information.
Paralellism/Similarity: Non-aggregated, disjunc-
tive descriptions (partitions) may exhibit semantic
parallelism: In (3b), elements of the partition are
described using exactly the same attributes (that is,
TYPE, COLOUR, and SIZE). This is not the case in
(3c), which does represent a partition but is non-
parallel. Parallel structures maximise the similarity
of elements of a partition, using the same attributes
to describe both. The likelihood of propagation of an
attribute across disjuncts is probably dependent on
its degree of salience or preference (e.g. COLOUR is
expected to be more likely to be found in a parallel
structure than SIZE).
2 The data
The data for our study is a subset of the TUNA Cor-
pus (Gatt et al, 2007), consisting of 900 references
to furniture and household items, collected via a
controlled experiment involving 45 participants. In
addition to their TYPE, objects in the domains have
COLOUR, ORIENTATION and SIZE (see Table 1). For
each subset of these three attributes, there was an
equal number of domains in which the minimally
distinguishing description (MD) consisted of values
of that subset. For example, Table 1 represents a do-
main in which the intended referents, {e1, e2}, can
104
<DESCRIPTION num=?pl?>
<DESCRIPTION num=?sg?>
<ATTRIBUTE name=?size? value=?small?>small</ATTRIBUTE>
<ATTRIBUTE name=?colour? value=?red?>red</ATTRIBUTE>
<ATTRIBUTE name=?type? value=?desk?>desk</ATTRIBUTE>
</DESCRIPTION>
and
<DESCRIPTION num=?sg?>
<ATTRIBUTE name=?size? value=?small?>small</ATTRIBUTE>
<ATTRIBUTE name=?colour? value=?blue?>blue</ATTRIBUTE>
<ATTRIBUTE name=?type? value=?sofa?>sofa</ATTRIBUTE>
</DESCRIPTION>
</DESCRIPTION>
(?SIZE : small? ? ?COLOUR : red? ? ?TYPE : desk?)
?
(?SIZE : small? ? ?COLOUR : blue? ? ?TYPE : sofa?)
Figure 1: Corpus annotation examples
be minimally distinguished using only SIZE2. Thus,
overspecified usage of attributes can be identified
in authors? descriptions. Domain objects were ran-
domly placed in a 3 (row) ? 5 (column) grid, rep-
resented by X and Y in Table 1. These are relevant
for a subset of descriptions which contain locative
expressions.
Corpus descriptions are paired with an explicit
XML domain representation, and annotated with se-
mantic markup which makes clear which attributes
a description contains. This markup abstracts away
from differences in lexicalisation, making it an ideal
resource to evaluate content determination algo-
rithms, because it is semantically transparent, in
the sense of this term used by van Deemter et al
(2006). This markup scheme also enables the com-
positional derivation of a logical form from a natural
language description. For example, the XML repre-
sentation of (3b) is shown in Figure 1, which also
displays the LF derived from it. Each constituent NP
in (3b) is annotated as a set of attributes enclosed by
a DESCRIPTION tag, which is marked up as singular
(sg). The two coordinates are further enclosed in
a plural DESCRIPTION; correspondingly, the LF is a
disjunction of (the LFs of) the two internal descrip-
tions.
Descriptions in the corpus were elicited in 7 do-
mains with one referent, and 13 domains with 2
referents. Plural domains represented levels of a
Value Similarity factor. In 7 Value-Similar (VS)
domains, referents were identifiable using identical
values of the minimally distinguishing attributes. In
the remaining 6 Value-Dissimilar (VDS) domains,
the minimally distinguishing values were different.
Table 1 represents a VS domain, where {e1, e2} can
2TYPE was not included in the calculation of MD.
VS VDS
+Disj ?Disj +Disj ?Disj
+aggr 20.2 15.5 2.4 3.7
?aggr 64.3 ? 93.9 ?
% overall 84.5 15.5 96.3 3.7
Table 2: % disjunctive and non-disjunctive plurals
be minimally distinguished using the same value of
SIZE (small).
In terms of our introductory discussion, referents
in Value-Similar conditions could be minimally dis-
tinguished using a conjunction of properties, while
Value-Dissimilar referents required a disjunction
since, if two referents could be minimally distin-
guished by different values v and v? of an attribute
A, then MD had the form ?A : v? ? ?A : v??. How-
ever, even in the VS condition, referents had differ-
ent basic-level types. Thus, an author faced with a
domain like Table 1 had at least the descriptive op-
tions in (3a?d). If they chose to refer to entities using
basic-level values of TYPE, their description would
be disjunctive (e.g. 3a). A non-disjunctive descrip-
tion would require the use of a superordinate value,
as in (3d).
Our analysis will focus on a stratified random
sample of 180 plural descriptions, referred to as PL1,
generated by taking 4 descriptions from each author
(2 each from VS and VDS conditions). We also use
the singular data (SG; N = 315). The remaining
plural descriptions (PL2; N = 405) are used for
evaluation.
3 The logical form of plurals
Descriptions in PL1 were first classified according to
whether they were non-disjunctive (cf. 3d) or dis-
junctive (3a?c). The latter were further classified
into aggregated (3a) and non-aggregated (3b). Ta-
ble 2 displays the percentage of descriptions in each
of the four categories, within each level of Value
Similarity. Disjunctive descriptions were a major-
ity in either condition, and most of these were non-
aggregated. As noted in ?1, these descriptions cor-
respond to partitions of the set of referents.
Since referents in VS had identical properties ex-
cept for TYPE values, the most likely reason for the
majority of disjunctives in VS is that people?s de-
scriptions represented a partition of a set of refer-
ents induced by the basic-level category of the ob-
105
Non-Parallel Parallel ?2 (p ? .001)
overspec. 24.6 75.4 92.467
underspec. 5.3 94.7 42.217
well-spec. 11 89 26
Table 3: Parallelism: % per description type
jects. This is strengthened by the finding that the
likelihood of a description being disjunctive or non-
disjunctive did not differ as a function of Value Sim-
ilarity (?2 = 2.56, p > .1). A ?2 test on overall fre-
quencies of aggregated versus non-aggregated dis-
junctives showed that the non-aggregated descrip-
tions (?true? partitions) were a significant major-
ity (?2 = 83.63, p < .001). However, the
greater frequency of aggregation in VS compared
to VDS turned out to be significant (?2 = 15.498,
p < .001). Note that the predominance of non-
aggregated descriptions in VS implies that proper-
ties are repeated in two disjuncts (resp. coordinate
NPs), suggesting that authors are likely to redun-
dantly propagate properties across disjuncts. This
evidence goes against some recent proposals for plu-
ral reference generation which emphasise brevity
(Gardent, 2002).
3.1 Conceptual gestalts and similarity
Allowing for the independent motivation for set par-
titioning based on TYPE values, we suggested in ?1
that parallel descriptions such as (3b) may be more
likely than non-parallel ones (3c), since the latter
does not use the same properties to describe the two
referents. Similarity, however, should also interact
with attribute preferences.
For this part of the analysis, we focus exclusively
on the disjunctive descriptions in PL1 (N = 150) in
both VS and VDS. The descriptions were categorised
according to whether they had parallel or non-
parallel semantic structure. Evidence for Similarity
interacting with attribute preferences is strongest if
it is found in those cases where an attribute is over-
specified (i.e. used when not required for a distin-
guishing description). In those cases where corpus
descriptions do not contain locative expressions (the
X and/or Y attributes), such an overspecified usage
is straightforwardly identified based on the MD of
a domain. This is less straightforward in the case of
locatives, since the position of objects was randomly
determined in each domain. Therefore, we divided
Actual Predicted
p(A, SG) p(A, PPS) p(A, PPS)
COLOUR .680 .835 .61
SIZE .290 .359 .28
ORIENTATION .280 .269 .26
X-DIMENSION .440 .517 .52
Y-DIMENSION .630 .647 .65
Table 4: Actual and predicted usage probabilities
descriptions into three classes, whereby a descrip-
tion is considered to be:
1. underspecified if it does not include a locative
expression and omits some MD attributes;
2. overspecified if either (a) it does not omit any
MD attributes, but includes locatives and/or
non-required visual attributes; or (b) it omits
some MD attributes, but includes both a locative
expression and other, non-required attributes;
3. well-specified otherwise.
Proportions of Parallel and Non-Parallel descrip-
tions for each of the three classes are are shown
in Table 3. In all three description types, there is
an overwhelming majority of Parallel descriptions,
confirmed by a ?2 analysis. The difference in pro-
portions of description types did not differ between
VS and VDS (?2 < 1, p > .8), suggesting that the
tendency to redundantly repeat attributes, avoiding
aggregation, is independent of whether elements of
a set can be minimally distinguished using identical
values.
Our second prediction was that the likelihood
with which an attribute is used in a parallel structure
is a function of its overall ?preference?. Thus, we
expect attributes such as COLOUR to feature more
than once (perhaps redundantly) in a parallel de-
scription to a greater extent than SIZE. To test this,
we used the SG sample, estimating the overall prob-
ability of occurrence of a given attribute in a singu-
lar description (denoted p(A, SG)), and using this in
a non-linear regression model to predict the likeli-
hood of usage of an attribute in a plural partitioned
description with parallel semantic structure (denoted
p(A, PPS)). The data was fitted to a regression equa-
tion of the form p(A, PPS) = k? p(A, SG)S . The re-
sulting equation, shown in (4), had a near-perfect fit
106
to the data (R2 = .910)3. This is confirmed by com-
paring actual probability of occurrence in the second
column of Table 4, to the predicted probabilities in
the third column, which are estimated from singular
probabilities using (4).
p(A, PPS) = .713 p(A, SG).912 (4)
Note that the probabilities in the Table con-
firm previous psycholinguistic findings. To the ex-
tent that probability of occurrence reflects salience
and/or conceptual importance, an order over the
three attributes COLOUR, SIZE and ORIENTATION
can be deduced (C>>O>>S), which is compatible
with the findings of Pechmann (1989), Belke and
Meyer (2002) and others. The locative attributes
are also ordered (Y>>X), confirming the findings
of Arts (2004) that vertical location is preferred. Or-
derings deducible from the SG data in turn are ex-
cellent predictors of the likelihood of ?propagating?
an attribute across disjuncts in a plural description,
something which is likely even if an attribute is re-
dundant, modulo the centrality or salience of the at-
tribute in the mental gestalt corresponding to the set.
Together with the earlier findings on logical form,
the data evinces a dual strategy whereby (a) sets
are partitioned based on basic-level conceptual cat-
egory; (b) elements of the partitions are described
using the same attributes if they are easily perceived
and conceptualised. Thus, of the descriptions in (3)
above, it is (3b) that is the norm among authors.
4 Content determination by partitioning
In this section we describe IApart, a partitioning-
based content determination algorithm. Though pre-
sented as a version of the IA, the basic strategy is
generalisable beyond it. For our purposes, the as-
sumption of a preference order will be maintained.
IApart is distinguished from the original IA and
IAbool (cf. ?1) in two respects. First, it induces par-
titions opportunistically based on KB information,
and this is is reflected in the way descriptions are
represented. Second,, the criteria whereby a prop-
erty is added to a description include a consideration
of the overall salience or preference of an attribute,
and its contribution to the conceptual cohesiveness
3A similar analysis using linear regression gave essentially
the same results.
of the description. Throughout the following discus-
sion, we maintain a running example from Table 1,
in which R = {e1, e2, e5}.
4.1 Partitioned descriptions
IApart generates a partitioned description (Dpart) of
a set R, corresponding to a formula in Disjunctive
Normal Form. Dpart is a set of Description Frag-
ments (DFs). A DF is a triple ?RDF, TDF,MDF?, where
RDF ? R, TDF is a value of TYPE, and MDF is a pos-
sibly empty set of other properties. DFs refer to dis-
joint subsets of R. As the representation suggests,
TYPE is given a special status. IApart starts by se-
lecting the basic-level values of TYPE, partitioning
R and creating a DF for each element of the partition
on this basis. In our example, the selection of TYPE
results in two DFs, with MDF initialised to empty:
(5) DF1
?
{e1, e5}, ?TYPE : desk?, ?
?
DF2
?
{e2}, ?TYPE : sofa?, ?
?
Although neither DF is distinguishing, RDF indicates
which referents a fragment is intended to identify.
In this way, the algorithm incorporates a ?divide-
and-conquer? strategy, splitting up the referential in-
tention into ?sub-intentions? to refer to elements of
a partition. Following the initial step of selecting
TYPE, the algorithm considers other properties in
PO. Suppose ?COLOUR : blue? is considered first.
This property is true of e2 and e5. Since DF2 refers to
e2, the new property can be added to MDF2 . Since e5
is not the sole referent of DF1, the property induces
a further partitioning of this fragment, resulting in a
new DF. This is identical to DF1 except that it refers
only to e5 and contains ?COLOUR : blue?. DF1 it-
self now refers only to e1. Once ?COLOUR : red? is
considered, it is added to the latter, yielding (6).
(6) DF1
?
{e1}, ?TYPE : desk?, {?COLOUR : red?}
?
DF2
?
{e2}, ?TYPE : sofa?, {?COLOUR : blue?}
?
DF3
?
{e5}, ?TYPE : desk?, {?COLOUR : blue?}
?
The procedure updateDescription, which cre-
ates and updates DFs, is formalised in Algorithm 2.
When some property ?A : v? is found to be ?use-
ful? in relation to R (in a sense to be made precise),
this function is called with two arguments: ?A : v?
itself, and R? = [[ ?A : v? ]] ? R, the referents of
which ?A : v? is true. The procedure iterates through
107
Algorithm 2 updateDescription(?A : v?, R?)
1: for ?RDF, TDF,MDF? ? Dpart do
2: if R? = ? then
3: return
4: else if RDF ? R? then
5: MDF ?MDF ?
?
?A : v?
?
6: R? ? R? ?RDF
7: else if RDF ?R? 6= ? then
8: Rnew ? RDF ?R?
9: DFnew ?
?
Rnew, TDF,MDF ? {?A : v?}
?
10: Dpart ? Dpart ?
?
DFnew
?
11: RDF ? RDF ?Rnew
12: R? ? R? ?Rnew
13: end if
14: end for
15: if A = TYPE then
16: Dpart ? Dpart ?
??
R?, ?A : v?, ?
??
17: else
18: Dpart ? Dpart ?
?
?R?,?, {?A : v?}?
?
19: end if
the DFs in Dpart, adding the property to any DF such
thatRDF?R? 6= ?, untilR? is empty and all referents
in it have been accounted for [2.2]. As indicated in
the informal discussion, there are two cases to con-
sider for each DF:
1. RDF ? R? [2.4]. This corresponds to our exam-
ple involving ?COLOUR : blue? and DF2. The
property is simply added to MDF [2.5] and R?
is updated by removing the elements thus ac-
counted for [2.6].
2. Suppose RDF 6? R?. If RDF ? R? is empty, then
?A : v? is not useful. Suppose on the other hand
that RDF ? R? 6= ? [2.7]. This occurred with
?COLOUR : red? in relation to DF1. The proce-
dure initialises Rnew, a set holding those refer-
ents in RDF which are also in R? [2.8]. A new
DF (DFnew) is created, which is a copy of the
old DF, except that (a) it contains the new prop-
erty; and (b) its intended referents are Rnew
[2.9]. The new DF is included in the description
[2.10], while the old DF is altered by removing
Rnew from RDF [2.11]. This ensures that DFs
denote disjoint subsets of R.
Two special cases arise when Dpart is empty, or
there are some elements of R? for which no DF ex-
ists. Both cases result in the construction of a new
DF. An example of the former case is the initial state
of the algorithm, when TYPE is added. As in exam-
ple (5), the TYPE results in a new DF [2.16]. If a
property is not a TYPE, the new DF has T set to null
(?) and the property is included in M [2.18]4. Note
that this procedure easily generalises to the singular
case, where Dpart would only contain one DF.
4.2 Property selection criteria
IApart?s content determination strategy maximises
the similarity of a set by generating semantically
parallel structures. Though contrastiveness plays a
role in property selection, the ?preference? or con-
ceptual salience of an attribute is also considered in
the decision to propagate it across DFs.
Candidate properties for addition need only be
true of at least one element of R. Because of the
partitioning strategy, properties are not equally con-
strastive for all referents. For instance, in (5), e2
needs to be distinguished from the other sofas in Ta-
ble 1, while {e1, e5} need to be distinguished from
the desks. Therefore, distractors are held in an as-
sociative array C, such that for all r ? R, C[r] is
the set of distractors for that referent at a given stage
in the procedure. Contrastiveness is defined via the
following Boolean function:
contrastive(?A : v?, R) ?
?r ? R : C[r] ? [[ ?A : v? ]] 6= ? (7)
We turn next to salience and similarity. Let
A(Dpart) be the set of attributes included in Dpart.
A property is salient with respect to Dpart if it satis-
fies the following:
salient(?A : v?, Dpart) ?
A ? A(Dpart) ? (.713 p(A, SG)
.912 > 0.5) (8)
that is, the attribute is already included in the de-
scription, and the predicted probability of its be-
ing propagated in more than one fragment of a de-
scription is greater than chance. A potential prob-
lem arises here. Consider the description in (5)
once more. At this stage, IApart begins to consider
COLOUR. The value red is true of e1, but non-
contrastive (all the desks which are not inR are red).
If this is the first value of COLOUR considered, (8)
returns false because the attribute has not been
used in any part of the description. On later con-
sidering ?COLOUR : blue?, the algorithm adds it to
4This only occurs if the KB is incomplete, that is, there some
entities have no TYPE, so that R is not fully covered by the
intended referents of the DFs when TYPE is initially added.
108
Dpart, since it is contrastive for {e2, e5}, but will
have failed to propagate COLOUR across fragments.
As a result, IApart considers values of an attribute in
order of discriminatory power (Dale, 1989), defined
in the present context as follows:
|[[ ?A : v? ]] ?R| + |[[ ?A : v? ]] ? (U ?R)|
|[[ ?A : v? ]]|
(9)
Discriminatory power depends on the number of ref-
erents a property includes in its extension, and the
number of distractors (U?R) it removes. By priori-
tising discriminatory values, the algorithm first con-
siders and adds ?COLOUR : blue?, and subsequently
will include red because (8) returns true.
To continue with the example, at the stage repre-
sented by (6), only e5 has been distinguished. ORI-
ENTATION, the next attribute considered, is not con-
trastive for any referent. On considering SIZE, small
is found to be contrastive for e1 and e2, and added to
DF1 and DF2. However, SIZE is not added to DF3, in
spite of being present in two other fragments. This
is because the probability function p(SIZE, PPS) re-
turns a value below 0.5 (see Table 4, reflecting the
relatively low conceptual salience of this attribute.
The final description is the blue desk, the small red
desk and the small blue sofa. This example illus-
trates the limits set on semantic parallelism and sim-
ilarity: only attributes which are salient enough are
redundantly propagated across DFs.
4.3 Complexity
An estimate of the complexity of IApart must ac-
count for the way properties are selected (?4.2) and
the way descriptions are updated (Algorithm 2).
Property selection involves checking properties
for contrastive value and salience, and updating the
ordering of values of each attribute based on dis-
criminatory power (9). Clearly, the number of times
this is carried out is bounded by the number of prop-
erties in the KB, which we denote np. Every time a
property is selected, the discriminatory power of val-
ues changes (since the number of remaining distrac-
tors changes). Now, in the worst case, all np proper-
ties are selected by the algorithm 5. Each time, the
algorithm must compare the remaining properties
5Only unique properties need to be considered, as each prop-
erty is selected at most once, though it can be included in more
than one DF.
Mean Mode PRP
IAbool
+ LOC 7.716 7 .7
? LOC 8.335 7 3.5
IApart
+ LOC 4.345 4 6.8
? LOC 1.93 0 44.7
Table 5: Edit distance scores
pairwise for discriminatory power, a quadratic op-
eration with complexity O(n2p). With respect to the
procedure updateDescription, we need to consider
the number of iterations in the for loop starting at
line [2.1]. This is bounded by nr = |R| (there can be
no more DFs than there are referents). Once again,
if at most np properties are selected, then the algo-
rithm makes at most nr iterations np times, yield-
ing complexity O(npnr). Overall, then, IApart has a
worst-case runtime complexity O(n3pnr).
5 Evaluation
IApart was compared to van Deemter?s IAbool (?1)
against human output in the evaluation sub-corpus
PL2 (N = 405). This was considered an ade-
quate comparison, since IAbool shares with the cur-
rent framework a genetic relationship with the IA.
Other approaches, such as Gardent?s (2002) brevity-
oriented algorithm, would perform poorly on our
data. As shown in ?3, overspecification is extremely
common in plural descriptions, suggesting that such
a strategy is on the wrong track (but see ?6).
IApart and IAbool were each run over the domain
representation paired with each corpus description.
The output logical form was compared to the LF
compiled from the XML representation of an au-
thor?s description (cf. Figure 1). LFs were repre-
sented as and-or trees, and compared using the tree
edit distance algorithm of Shasha and Zhang (1990).
On this measure, a value of 0 indicates identity.
Because only a subset of descriptions con-
tain locative expressions, PL2 was divided into
a +LOC dataset (N = 148) and a ?LOC
dataset (N = 257). The preference orders for
both algorithms were (C>>O>>S) for ?LOC and
(Y>>C>>X>>S>>O) for +LOC. These are sug-
gested by the attribute probabilities in Table 4. Ta-
ble 5 displays the mean Edit score obtained by
each algorithm on the two datasets, the modal (most
frequent) value, and the perfect recall percentage
(PRP), the proportion of Edit scores of 0, indicating
109
perfect agreement with an author.
As the means and modes indicate, IApart outper-
formed IAbool on both datasets, with a consistently
higher PRP (this coincides with the modal score in
the case of ?LOC). Pairwise t?tests showed that
the trends were significant in both +LOC (t(147) =
9.28, p < .001) and ?LOC (t(256) = 10.039,
p < .001).
IAbool has a higher (worse) mean on ?LOC, but a
better PRP than on+LOC. This apparent discrepancy
is partly due to variance in the edit distance scores.
For instance, because the Y attribute was highest in
the preference order for +LOC, there were occasions
when both referents could be identified using the
same value of Y, which was therefore included by
IAbool at first pass, before considering disjunctions.
Since Y was highly preferred by authors (see Table
4), there was higher agreement on these cases, com-
pared to those where the values of Y were different
for the two referents. In the latter case, Y was only
when disjunctions were considered, if at all. The
worse performance of IApart on +LOC is due to a
larger choice of attributes, also resulting in greater
variance, and occasionally incurring higher Edit cost
when the algorithm overspecified more than a hu-
man author. This is a potential shortcoming of the
partitioning strategy outlined here, when it is applied
to more complex domains.
Some example outputs are given below, in a do-
main where COLOUR sufficed to distinguish the ref-
erents, which had different values of this attribute
(i.e. an instance of the VDS condition). The formula
returned by IApart (10a) is identical to the (LF of)
the human-authored description (with Edit score of
0). The output of IAbool is shown in (10b).
(10) (a)
`
fan ? green
?
?
`
sofa ? blue
?
?the green fan and the big sofa?
(b)
`
sofa ? fan
?
? small ? front ?
`
blue ? green
?
?the small, blue and green sofa and fan?
As a result of IAbool?s requiring a property or dis-
junction to be true of the the entire set of refer-
ents, COLOUR is not included until disjunctions are
considered, while values of SIZE and ORIENTATION
are included at first pass. By contrast, IApart in-
cludes COLOUR before any other attribute apart from
TYPE. Though overspecification is common in our
data, IAbool overspecifies with the ?wrong? attributes
(those which are relatively dispreferred). The ratio-
nale in IApart is to overspecify only if a property
will enhance referent similarity, and is sufficiently
salient. As for logical form, the Conjunctive Nor-
mal Form output of IAbool increases the Edit score,
given the larger number of logical operators in (10b)
compared to (10a).
6 Summary and conclusions
This paper presented a study of plural reference,
showing that people (a) partition sets based on the
basic level TYPE or category of their elements and
(b) redundantly propagate attributes across disjuncts
in a description, modulo their salience. Our algo-
rithm partitions a set opportunistically, and incor-
porates a corpus-derived heuristic to estimate the
salience of a property. Evaluation results showed
that these principles are on the right track, with sig-
nificantly better performance over a previous model
(van Deemter, 2002). The partitioning strategy is
related to a proposal by van Deemter and Krah-
mer (2007), which performs exhaustive search for
a partition of a set whose elements can be described
non-disjunctively. Unlike the present approach, this
algorithm is non-incremental and computationally
costly.
IApart initially performs partitioning based on the
basic-level TYPE of objects, in line with the evi-
dence. However, later partitions can be induced by
other properties, possible yielding partitions even
with same-TYPE referents (e.g. the blue chair and
the red chair). Aggregation (the blue and red chairs)
may be desirable in such cases, but limits on syntac-
tic complexity of NPs are bound to play a role (Ho-
racek, 2004). Another possible limitation of IApart
is that, despite strong evidence for overspecifica-
tion, complex domains could yield very lengthy out-
puts. Strategies to avoid them include the utilisation
of other boolean operators like negation (the desks
which are not red) (Horacek, 2004). These issues
are open to future empirical research.
7 Acknowledgements
Thanks to Ehud Reiter and Ielka van der Sluis for
useful comments. This work forms part of the TUNA
project (www.csd.abdn.ac.uk/research/tuna/),
supported by EPSRC grant GR/S13330/01.
110
References
A. Arts. 2004. Overspecification in Instructive Texts.
Ph.D. thesis, Univiersity of Tilburg.
E. Belke and A. Meyer. 2002. Tracking the time course
of multidimensional stimulus discrimination: Analy-
sis of viewing patterns and processing times during
same-different decisions. European Journal of Cog-
nitive Psychology, 14(2):237?266.
R. Dale and E. Reiter. 1995. Computational interpreta-
tion of the Gricean maxims in the generation of refer-
ring expressions. Cognitive Science, 19(8):233?263.
Robert Dale. 1989. Cooking up referring expressions. In
Proceedings of the 27th Annual Meeting of the Associ-
ation for Computational Linguistics, ACL-89.
H. J. Eikmeyer and E. Ahlse`n. 1996. The cognitive pro-
cess of referring to an object: A comparative study of
german and swedish. In Proceedings of the 16th Scan-
dinavian Conference on Linguistics.
C. Gardent, H. Manue?lian, K. Striegnitz, and M. Amoia.
2004. Generating definite descriptions: Non-
incrementality, inference, and data. In T. Pechman
and C. Habel, editors, Multidisciplinary Approaches
to Language Production. Mouton de Gruyter.
C. Gardent. 2002. Generating minimal definite descrip-
tions. In Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics, ACL-
02.
A. Gatt, I. van der Sluis, and K. van Deemter. 2007.
Evaluating algorithms for the generation of referring
expressions using a balanced corpus. In Proceedings
of the 11th European Workshop on Natural Language
Generation, ENLG-07. To appear.
H.P. Grice. 1975. Logic and conversation. In P. Cole and
J.L. Morgan, editors, Syntax and Semantics: Speech
Acts., volume III. Academic Press.
S. Gupta and A. J. Stent. 2005. Automatic evaluation
of referring expression generation using corpora. In
Proceedings of the 1st Workshop on Using Corpora in
NLG, Birmingham, UK.
H. Horacek. 2004. On referring to sets of objects natu-
rally. In Proceedings of the 3rd International Confer-
ence on Natural Language Generation, INLG-04.
P. W. Jordan and M. Walker. 2005. Learning content se-
lection rules for generating object descriptions in di-
alogue. Journal of Artificial Intelligence Research,
24:157?194.
G. L. Murphy. 2002. The big book of concepts. MIT
Press, Cambridge, Ma.
D. R. Olson. 1970. Language and thought: Aspects of a
cognitive theory of semantics. Psychological Review,
77:257?273.
Thomas Pechmann. 1989. Incremental speech pro-
duction and referential overspecification. Linguistics,
27:89?110.
I. Rock. 1983. The Logic of Perception. MIT Press,
Cambridge, Ma.
E. Rosch, C. B. Mervis, W. Gray, D. Johnson, and
P. Boyes-Braem. 1976. Basic objects in natural cat-
egories. Cognitive Psychology, 8:382?439.
H. Schriefers and T. Pechmann. 1988. Incremental pro-
duction of referential noun phrases by human speak-
ers. In M. Zock and G. Sabah, editors, Advances in
Natural Language Generation, volume 1. Pinter, Lon-
don.
D. Shasha and K. Zhang. 1990. Fast algorithms for unit
cost editing distance between trees. Journal of Algo-
rithms, 11:581?621.
K. van Deemter and E. Krahmer. 2007. Graphs and
booleans: On the generation of referring expressions.
In H. Bunt and R. Muskens, editors, Computing Mean-
ing, volume III. Springer, Berlin.
K. van Deemter, I. van der Sluis, and A. Gatt. 2006.
Building a semantically transparent corpus for the
generation of referring expressions. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation (Special Session on Data Sharing
and Evaluation), INLG-06.
K. van Deemter. 2002. Generating referring expres-
sions: Boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37?52.
I. van der Sluis and E. Krahmer. 2005. Towards the gen-
eration of overspecified multimodal referring expres-
sions. In Proceedings of the Symposium on Dialogue
Modelling and Generation, 15th Annual Meeting of
the Society for Text and Discourse, STD-05.
J. Viethen and R. Dale. 2006. Algorithms for generat-
ing referring expressions: Do they do what people do?
In Proceedings of the 4th International Conference on
Natural Language Generation, INLG-06.
M. Wertheimer. 1938. Laws of organization in per-
ceptual forms. In W. Ellis, editor, A Source Book of
Gestalt Psychology.Routledge &Kegan Paul, London.
111
Squibs and Discussions
Real versus Template-Based Natural Language
Generation: A False Opposition?
Kees van Deemter
University of Aberdeen
Emiel Krahmer.
Tilburg University
Marie?t Theune-
University of Twente
This article challenges the received wisdom that template-based approaches to the generation of
language are necessarily inferior to other approaches as regards their maintainability, linguistic
well-foundedness, and quality of output. Some recent NLG systems that call themselves
??template-based?? will illustrate our claims.
1. Introduction
Natural language generation (NLG) systems are sometimes partitioned into application-
dependent systems which lack a proper theoretical foundation, on the one hand, and
theoretically well-founded systems which embody generic linguistic insights, on the
other. Template-based systems are often regarded as automatically falling into the first
category. We argue against this view. First, we describe the received view of both
template-based and ??standard?? NLG systems (section 2). Then we describe a class of
recent template-based systems (section 3) that will serve as a basis for a comparison
between template-based and other NLG systems with respect to their potential for
performing NLG tasks (section 4). We ask what the real difference between template-
based and other systems is and argue that the distinction between the two is becoming
increasingly blurred (section 5). Finally, we discuss the implications of engineering
shortcuts (Mellish 2000) and corpus-based methods (section 6).
2. Templates versus Real NLG: The Received View
Before we can argue against the distinction between template-based and ??real?? NLG
systems, we should first sketch how these two classes are commonly understood. It is
surprisingly difficult to give a precise characterization of the difference between them
(and we will later argue against the usefulness of such a characterization), but the idea
is the following. Template-based systems are natural-language-generating systems
that map their nonlinguistic input directly (i.e., without intermediate representations)
to the linguistic surface structure (cf. Reiter and Dale 1997, pages 83?84). Crucially, this
linguistic structure may contain gaps; well-formed output results when the gaps are
* 2005 Association for Computational Linguistics
 Computing Science Department, King?s College, University of Aberdeen, United Kingdom.
E-mail: KvDeemter@csd.abdn.ac.uk.
. Communication and Cognition/Computational Linguistics, Faculty of Arts, Tilburg University,
Tilburg, The Netherlands. E-mail: E.J.Krahmer@uvt.nl.
- Human Media Interaction Group, Computer Science, University of Twente, The Netherlands.
E-mail: M.Theune@ewi.utwente.nl.
filled or, more precisely, when all the gaps have been replaced by linguistic structures
that do not contain gaps. (Canned text is the borderline case of a template without
gaps.) Adapting an example from Reiter and Dale (1997), a simple template-based
system might start out from a semantic representation saying that the 306 train leaves
Aberdeen at 10:00 AM:
Departure?train306; locationabdn; time1000?
and associate it directly with a template such as
?train is leaving ?townnow
where the gaps represented by [train] and [town] are filled by looking up the relevant
information in a table. Note that this template will be used only when the time referred
to is close to the intended time of speaking; other templates must be used for
generating departure announcements relating to the past or future. ??Real?? or, as we
shall say, standard NLG systems, by contrast, use a less direct mapping between input
and surface form (Reiter 1995; Reiter and Dale 1997). Such systems could start from
the same input semantic representation, subjecting it to a number of consecutive
transformations until a surface structure results. Various NLG submodules would
operate on it (determining, for instance, that 10:00 AM is essentially the intended time
of speaking), jointly transforming the representation into an intermediate representa-
tion like
Leavepresent ?traindemonstrative; Aberdeen; now?
where lexical items and style of reference have been determined while linguistic
morphology is still absent. This intermediate representation may in turn be transformed
into a proper sentence, for example: This train is leaving Aberdeen now. Details vary; in
particular, many systems will contain more intermediate representations.
Template-based and standard NLG systems are said to be ??Turing equivalent??
(Reiter and Dale 1997); that is, each of them can generate all recursively enumerable
languages. However, template-based systems have been claimed to be inferior with
respect to maintainability, output quality and variation, and well-foundedness. Reiter
and Dale (1997) state that template-based systems are more difficult to maintain and
update (page 61) and that they produce poorer and less varied output (pages 60, 84)
than standard NLG systems. Busemann and Horacek (1998) go even further by
suggesting that template-based systems do not embody generic linguistic insights
(page 238). Consistent with this view, template-based systems are sometimes over-
looked. In fact, the only current textbook on NLG (Reiter and Dale 2000) does not
pay any attention to template-based generation, except for a passing mention of the
ECRAN system (Geldof and van de Velde 1997). Another example is a recent overview
of NLG systems in the RAGS project (Cahill et al 1999). The selection criteria employed
by the authors were that the systems had to be fully implemented, complete (i.e.,
generating text from nontextual input), and accepting non-hand-crafted input; al-
though these criteria appear to favor template based systems, none of the 19 systems
investigated were template-based. In what follows, we claim that the two types of
systems have more in common than is generally thought and that it is counter-
productive to treat them as distant cousins instead of close siblings. In fact, we argue
that there is no crisp distinction between the two.
16
Computational Linguistics Volume 31, Number 1
17
3. Template-Based NLG Systems in Practice
In recent years, a number of new template-based systems have seen the light,
including TG/2 (Busemann and Horacek 1998), D2S (van Deemter and Odijk 1997;
Theune et al 2001), EXEMPLARS (White and Caldwell 1998), YAG (McRoy, Channarukul,
and Ali 2003), and XTRAGEN (Stenzhorn 2002). Each of these systems represents a
substantial research effort, achieving generative capabilities beyond what is usually
expected from template-based systems, yet they call themselves template-based,
and they clearly fall within the characterization of template-based systems offered
above.
In this article we draw on our own experiences with a data-to-speech method
called D2S. D2S has been used as the foundation of a number of language-generating
systems, including GOALGETTER, a system that generates soccer reports in Dutch.1 D2S
consists of two modules: (1) a language generation module (LGM) and (2) a speech
generation module (SGM) which turns the generated text into a speech signal. Here
we focus on the LGM and in particular on its use of syntactically structured templates
to convert a typed data structure into a natural language text (annotated with prosodic
information). Data structures in GOALGETTER are simple representations describing
lists of facts, such as

goal-event
TEAM Ajax
PLAYER Kluivert
MINUTE 38
GOAL-TYPE penalty

Besides goal events, there are several other types of events, such as players receiving
yellow or red cards. Figure 1 shows a simple template, which the LGM might use to
express the above fact as, for instance, Kluivert scored a penalty in the 38th minute.
1 See http://www.cs.utwente.nl/?theune/GG/GG_index.html for some example reports.
Figure 1
Sample syntactic template from the GOALGETTER system.
van Deemter, Krahmer, and Theune Real versus Template-Based NLG
Formally, a syntactic template s = bS, E, C, T?, where S is a syntax tree (typically for
a sentence) with open slots in it, E is a set of links to additional syntactic structures
(typically NPs and PPs) which may be substituted in the gaps of S, C is a condition on
the applicability of s, and T is a set of topics. We discuss the four components of a
template in more detail, starting with the syntax tree, S. All S?s interior nodes are
labeled by nonterminal symbols, while the nodes on the frontier are labeled by
terminal or nonterminal symbols: the nonterminal nodes (??gaps??) are open for
substitution and they are marked by a ,. The second element of a syntactic template is
E: the slot fillers. Each open slot in the tree S is associated with a call of some Express
function (ExpressTime, ExpressObject, etc.), which generates a set of expressions that
can be used to fill the slot. The right-hand side of Figure 2 shows an example Express
function, namely, ExpressObject, which generates a set of NP trees and is used to
generate fillers for the player and goal slots in the template of Figure 1. The first, for
example, leads to the generation of NPs such as Kluivert (proper name), the forward
Kluivert, Ajax player Kluivert, Ajax? Kluivert, the striker, and he, depending on the context
in which the NP is generated.
The left-hand side of Figure 2 shows the function ApplyTemplate, which handles
the choice among all possible combinations of slot fillers. ApplyTemplate first calls
FillSlots to obtain the set of all possible trees (all_trees) that can be generated from the
template, using all possible combinations of slot fillers generated by the Express
functions associated with the slots. For each tree in this set, it is checked (1) whether it
does not violate a version of the Chomskyan binding theory and (2) whether it is
compatible with the context model, which is a record containing all the objects
introduced so far and the anaphoric relations among them. From the resulting set of
allowed_trees, one is selected randomly (using the function PickAny) and returned to
the main generation algorithm. The random-choice option was chosen to maximize the
variety of sentences produced by the system.
The mechanisms described so far take care of sentence planning and language
realization. Text planning is performed by components C and T. C is a Boolean
condition. A template s is applicable only if its associated condition is true. An
example is the condition from Figure 1 saying that the template can be used only if
the result of the current match has been conveyed to the user (i.e., is known) and
the current goal is the first one which has not been conveyed (i.e., is not known). To
cater to aspects of text planning that allow a less knowledge-intensive approach,
GOALGETTER associates every template with a set of topics T, which the LGM algo-
rithm uses to group sentences together into coherent chunks of text. For example, any
18
Figure 2
Functions ApplyTemplate (left) and ExpressObject (right).
Computational Linguistics Volume 31, Number 1
19
template associated with the topic of goal scoring can ??fire?? throughout the opening
paragraph of the report.
4. Template-Based NLG: Deep or Shallow?
How do template-based systems measure up against the criteria mentioned in
section 2? When dealing with this question, we are interested as much in what could
be done in principle as in what has been achieved in practice. After some preliminary
remarks, we focus on the criterion of linguistic well-foundedness.
It is far from obvious that template-based systems should always score low on
maintainability. Several template-based systems such as TG/2, EXEMPLARS, and
XTRAGEN have been reused for generation in different languages or in different
domains (cf. Kittredge et al 1994). In the case of D2S, the basic generation algorithm
and such functions as ApplyTemplate and ExpressObject have been used for different
application domains (music, soccer games, route descriptions, and public transport)
and different languages (English, Dutch, and German); D2S has been used for the
generation of both monologues and dialogue contributions (van Deemter and Odijk
1997; Theune et al 2001). When a template-based system is applied to a new domain or
language, many of the templates will have to be written anew (much as new grammar
fragments need to be developed for standard NLG systems), but the underlying
generation mechanisms generally require little or no modification.
As for the output quality and variability of the output, if template-based systems
have the same generative power as standard NLG systems (Reiter and Dale 1997),
there cannot be a difference between the types of output that they are able to generate
in principle. The fact that templates can be specified by hand gives template-based
systems an advantage in cases in which good linguistic rules are not (yet) available or
for constructions which have unpredictable meanings or highly specific conditions of
use. Some template-based systems have variability as one of their central design
specifications: Current D2S-based systems rely mainly on random choice to achieve
variation, but more context-sensitive variations (e.g., varying the output depending on
user characteristics) can also be achieved through the use of parametrized templates
(XTRAGEN) or template specialization hierarchies (EXEMPLARS).
The most crucial question, in our view, is whether a template-based NLG system
can be linguistically well-founded (or ??deep?? in terms of Busemann and Horacek
[1998]), in the sense that the choices inherent in its mapping from input to output are
based on sound linguistic principles. To judge the well-foundedness of template-based
systems, let us look at the different types of decisions that an NLG system needs to
make, as distinguished by Cahill et al (1999) and Reiter and Dale (2000).
4.1 Content Determination
During content determination, it is decided what information is to be conveyed. Since
content determination precedes language generation proper, it is clear that in principle,
template-based systems can treat it in the exact same ways as standard NLG systems.
In practice, template-based systems tend to take their departure from ??flat data?? (e.g.,
database records), whereas standard systems often use richer input, in which some
decisions concerning the linguistic structure of the output (e.g., decisions about
quantificational or rhetorical structure) have already been made. To the extent that this
is the case, the ??generation gap?? to be bridged by template-based systems is actually
wider than the one to be bridged by standard NLG systems.
van Deemter, Krahmer, and Theune Real versus Template-Based NLG
4.2 Referring Expressions
As for the generation of referring expressions, template-based systems vary widely:
The simplest of them (e.g., MSWord-based systems for mail merge) can fill their gaps
with only a limited number of phrases, but more sophisticated systems (called
??hybrid?? systems in Reiter [1995]) have long existed; these effectively use standard
NLG to fill their gaps. Recent systems have moved further in this direction. D2S, for
example, uses well-established rules for constraining the use of anaphors (see, e.g., the
Chomskyan ViolateBindingTheory and Wellformed in ApplyTemplate) and a new
variant of Dale and Reiter?s (1995) algorithm for the generation of referring expressions
that takes contextual salience into account (MakeReferringExp in ExpressObject)
(Krahmer and Theune 2002). A similar range of approaches can be found among NLG
systems that are not template-based; in fact, several systems from the RAGS inventory
do not really address referring expression generation at all (Cahill et al 1999).
4.3 Aggregation
Aggregation is an NLG task in which differences between the two types of systems
may be expected. After all, every template contains a ??fixed?? part, and surely this part
cannot be recombined with other parts? The reality is slightly more complex. The
GOALGETTER system, for instance, uses the following approach: In order to generate a
subject-aggregated sentence of the form A and B got a red card, a separate template is
called of the form X got a red card [syntactic structure omitted], subject to conditions
requiring that the gap X be filled with an appropriate conjoined noun phrase, referring
to the set {A, B}. Other approaches are possible. For example, the system could first
generate A got a red card and B got a red card, then aggregate these two structures (whose
syntactic and semantic structure is known) into the desired conjunctive structure (van
Deemter and Odijk 1997). Whether a system is able to perform operations of this kind
does not depend on whether the system is template based, but on whether it possesses
the required syntactic and semantic information.
4.4 Lexicalization
The same point is relevant for lexicalization. Let us suppose (perhaps rather charitably;
Cahill et al 1999) that a variety of near-synonymous verbs are present in the lexicon of
the NLG system (e.g., give, offer, donate, entrust, present to). How would a standard NLG
system choose among them? Typically, the system does not have a clue, because our
understanding of the differences among these verbs is too imperfect. (The input to the
system might prejudge such decisions by pairing each of these verbs with different
input relations, but that would be cheating.) As with the previous tasks, it is not clear
that standard NLG systems are in a better position to perform them than template-
based ones: The latter could use templates that vary in the choice of words and
stipulate that they are applicable under slightly different conditions (cf. the use of
specialization hierarchies in EXEMPLARS). The condition C for X kicked the ball in the net,
for example (as opposed to X scored or X nudged the ball in) might require that the ball
did not touch the ground after departing the previous player.
4.5 Linguistic Realization
It is in linguistic realization that the most obvious differences between standard and
template-based approaches appear to exist. Many template-based approaches lack a
general mechanism for gender, number, and person agreement, for example. Systems
in the D2S tradition avoid errors by letting functions like ExpressObject use handmade
rules, but this approach becomes cumbersome when coverage increases; general-
20
Computational Linguistics Volume 31, Number 1
21
izations are likely to be missed and portability is reduced, for example, if different
templates are used for John walks and John and Mary walk. One should not, however, let
one?s judgment depend on accidental properties of one or two systems: Nothing keeps
the designer of a template-based system from adding morphological rules; witness
systems like YAG (McRoy, Channarukul, and Ali 2003) and XTRAGEN (Stenzhorn 2002).
The YAG system, for example, allows the subject and verb of a template to be
underspecified for number and person, while using attribute grammar rules to
complete the specification: Returning to the example above, the number attribute of
John and Mary is inferred to be plural (unlike, e.g., John and I); a subject-verb
agreement rule makes the further inference that the verb must be realized as walk,
rather than walks.
5. Templates: An Updated View
A new generation of systems that call themselves template-based have blurred the line
between template-based and standard NLG. This is not only because some systems
combine standard NLG with templates and canned text (Piwek 2003), but also because
modern template-based systems tend to use syntactically structured templates and
allow the gaps in them to be filled recursively (i.e., by filling a gap, a new gap may
result). Some ??template-based?? systems, finally, use grammars to aid linguistic
realization. These developments call into question the very definition of ??template
based?? (section 2), since the systems that call themselves template-based have come to
express their nonlinguistic input with varying degrees of directness.
??Template-based?? systems vary in terms of linguistic coverage, the amount of
syntactic knowledge used, and the number of steps involved in filling the templates,
among other things. Here, we highlight one particular dimension, namely, the size of
(the fixed part of) the templates. A comparison with tree-adjoining grammar (TAG)?
based-approaches to NLG may be useful (Joshi 1987; see also Becker 2002). Joshi (1987,
page 234) points out that ??The initial . . . trees are not constrained in any other manner
than. . . . The idea, however, is that [they] will be minimal in some sense.?? Minimality is
usually interpreted as saying that a tree should not contain more than the lexical head
plus its arguments. Initial trees may be likened to templates. Nonminimal templates/
elementary trees are essential for the treatment of idioms and special collocations.
Generally speaking, however, the larger the templates/elementary trees, the less sys-
tematic the treatment, the less insight it gives into the compositional structure of lan-
guage, and the larger the number of templates/elementary trees needed. Again, the
history of D2S is instructive: The earliest D2S-based NLG system (DYD; van Deemter and
Odijk 1997) used long templates, but the majority of the templates in GOALGETTER are
minimal in the sense explicated above (Theune et al 2001).
6. Discussion: Shortcuts and Statistics in NLG
Let us compare our views with those of Mellish (2000). Mellish points out that NLG
systems often use shortcuts, whereby one or more modules are trivialized, either by
bypassing them (and the representations that they create) or by letting their operations
be dictated by what the other modules expect (e.g., lexical choice may be trivialized
by using a one-to-one mapping between semantic relations/predicates and lexical
items). Mellish argues that shortcuts have a legitimate role in practical NLG when
linguistic rules are missing, provided the existence of the shortcuts is acknowledged:
Even though they lead to diminished generality and maintainability, the unavailability
van Deemter, Krahmer, and Theune Real versus Template-Based NLG
of ??deep?? rules means that there is no alternative (yet). For instance, there is little
added value in using abstract representations from which either a passive or an active
sentence can be generated if we are unable to state a general rule that governs the
choice, in which case one can be forgiven for explicitly specifying which sentences
should be active and which ones passive, avoiding a pretense of linguistic sophis-
tication. It is shortcuts of this kind that a template-based system is well placed to make,
of course. But crucially, template-based systems do not have to use shortcuts any more
than standard NLG systems: Where linguistic rules are available, both types of sys-
tems can use them, as we have seen.
Another response to the absence of linguistic rules is the use of statistical
information derived from corpora, as is increasingly more common in realization, but
also for instance in aggregation (e.g., Walker, Rambow, and Rogati 2002). The point we
want to make here, however, is that ??template-based?? systems may profit from such
corpus-based approaches just as much as ??standard?? NLG systems. The approach of
Langkilde and Knight (1998), for example, in which corpus-derived n-grams are used
for selecting the best ones from among a set of candidates produced by overgenera-
tion, can also be applied to template-based systems (witness the mixed template/
stochastic system of Galley, Fosler-Lussier, and Potamianos [2001]).
We have argued that systems that call themselves template based can, in principle,
perform all NLG tasks in a linguistically well-founded way and that more and more
actually implemented systems of this kind deviate dramatically from the stereotypical
systems that are often associated with the term template. Conversely, most standard
NLG systems perform many NLG tasks in a less than well-founded fashion (e.g.,
relying heavily on shortcuts, and nontransparent ones at that). We doubt that there is
still any important difference between the two classes of systems, since the variation
within each of them is as great as that between them.
22
Acknowledgments
This is a remote descendant of a paper
presented at the workshop ??May I Speak
Freely??? (Becker and Busemann 1999). We
thank three reviewers for comments.
References
Becker, Tilman. 2002. Practical,
template-based natural language
generation with TAG. In Proceedings
of TAG+6, Venice.
Becker, Tilman and Stephan Busemann,
editors. 1999. ??May I Speak Freely??? Between
Templates and Free Choice in Natural
Language Generation: KI-99 Workshop.
DFKI, Saarbru?cken, Germany.
Busemann, Stephan and Helmut
Horacek. 1998. A flexible shallow
approach to text generation. In Proceedings
of the Ninth International Workshop on
Natural Language Generation,
pages 238?247: Niagara-on-the-Lake,
Ontario, Canada.
Cahill, Lynn, Christy Doran, Roger Evans,
Chris Mellish, Daniel Paiva, Mike Reape,
and Donia Scott. 1999. In search of a
reference architecture for NLG systems.
In Proceedings of the Seventh European
Workshop on Natural Language Generation,
pages 77?85: Toulouse, France.
Dale, Robert and Ehud Reiter. 1995.
Computational interpretations of the
Gricean maxims in the generation of
referring expressions. Cognitive Science,
18:233?263.
Galley, Michel, Eric Fosler-Lussier, and
Alexandros Potamianos. 2001. Hybrid
natural language generation for spoken
dialogue systems. In Proceedings of
the Seventh European Conference on
Speech Communication and Technology.
Aalborg, Denmark.
Geldof, Sabine and Walter van de Velde.
1997. An architecture for template based
(hyper)text generation. In Proceedings of
the Sixth European Workshop on Natural
Language Generation, pages 28?37,
Duisburg, Germany.
Joshi, Aravind. 1987. The relevance of
tree adjoining grammar to generation.
In Gerard Kempen, editor. Natural Language
Computational Linguistics Volume 31, Number 1
23
Generation, Martinus Nijhoff, Leiden,
The Netherlands, pages 233?252.
Kittredge, Richard, Eli Goldberg, Myunghee
Kim, and Alain Polgue`re. 1994.
Sublanguage engineering in the FOG
system. In Fourth Conference on Applied
Natural Language Processing, pages 215?216,
Stuttgart, Germany.
Krahmer, Emiel and Marie?t Theune. 2002.
Efficient context-sensitive generation of
descriptions in context. In Kees van
Deemter and Rodger Kibble, editors,
Information Sharing. CSLI Publications,
Stanford, CA, pages 223?264.
Langkilde, Irene and Kevin Knight. 1998.
Generation that exploits corpus-based
statistical knowledge. In Proceedings of
the ACL, pages 704?710, Montreal,
Quebec, Canada.
McRoy, Susan W., Songsak Channarukul,
and Syed S. Ali. 2003. An augmented
template-based approach to text
realization. Natural Language Engineering,
9(4):381?420.
Mellish, Chris. 2000. Understanding shortcuts
in NLG systems. In Proceedings of Impacts in
Natural Language Generation: NLG between
Technology and Applications, pages 43?50,
Dagstuhl, Germany.
Piwek, Paul. 2003. A flexible
pragmatics-driven language generator for
animated agents. In Proceedings of EACL03
(Research Notes), pages 151?154,
Budapest, Hungary.
Reiter, Ehud. 1995. NLG vs. templates. In
Proceedings of the Fifth European Workshop on
Natural Language Generation, pages 95?105,
Leiden, The Netherlands.
Reiter, Ehud and Robert Dale. 1997. Building
applied natural language generation
systems. Natural Language Engineering,
3(1):57?87.
Reiter, Ehud and Robert Dale. 2000.
Building Natural Language Generation
Systems. Cambridge University
Press, Cambridge.
Stenzhorn, Holger. 2002. A natural language
generation system using XML- and
Java-technologies. In Proceedings of the
Second Workshop on NLP and XML,
Taipei, Taiwan.
Theune, Marie?t, Esther Klabbers, Jan-Roelof
de Pijper, Emiel Krahmer, and Jan Odijk.
2001. From data to speech: A general
approach. Natural Language Engineering,
7(1):47?86.
van Deemter, Kees and Jan Odijk. 1997.
Context modelling and the generation of
spoken discourse. Speech Communication,
21(1/2):101?121.
Walker, Marilyn, Owen Rambow, and
Monica Rogati. 2002. Training a sentence
planner for spoken dialogue using
boosting. Computer Speech and Language,
16:409?433.
White, Michael and Ted Caldwell. 1998.
EXEMPLARS: A practical, extensible
framework for dynamic text generation.
In Proceedings of the Ninth International
Workshop on Natural Language Generation,
pages 266?275, Niagara-on-the-Lake,
Ontario, Canada.
van Deemter, Krahmer, and Theune Real versus Template-Based NLG

Generating Referring Expressions
that Involve Gradable Properties
Kees van Deemter?
University of Aberdeen
This article examines the role of gradable properties in referring expressions from the perspective
of natural language generation. First, we propose a simple semantic analysis of vague de-
scriptions (i.e., referring expressions that contain gradable adjectives) that reflects the context-
dependent meaning of the adjectives in them. Second, we show how this type of analysis can
inform algorithms for the generation of vague descriptions from numerical data. Third, we ask
when such descriptions should be used. The article concludes with a discussion of salience and
pointing, which are analyzed as if they were gradable adjectives.
1. Introduction: Vagueness of Gradable Adjectives
1.1 Vague Descriptions
Vague or gradable expressions pose problems to models of language, caused by their
context dependence, and by the fact that they are applicable to different degrees. This
article focuses on gradable adjectives, also called degree adjectives.1 More specifically,
we shall explore how referring expressions containing gradable adjectives can be pro-
duced by a Natural Language Generation (NLG) program. Following Pinkal (1979), such
expressions will be called vague descriptions even though, as we shall see, the vagueness
of the adjective does not extend to the description as a whole. It will be useful to gen-
eralize over different forms of the adjective, covering the superlative form (e.g., largest)
and the comparative form (larger), as well as the positive or base form (large) of the
adjective. Vague descriptions are worth studying because they use vagueness in a
comparatively transparent way, often combining clarity of reference with indeterminacy
of meaning; as a result, they allow us to make inroads into the difficult area of research
on vagueness. Generation offers an interesting perspective because it forces one to ask
when it is a good idea to use these descriptions, in addition to asking what they mean.
Gradability is especially widespread in adjectives. A search of the British National
Corpus (BNC), for example, shows at least seven of the ten most frequent adjectives
(last, other, new, good, old, great, high, small, different, large) to be gradable. Children use
vague adjectives among their first dozens of words (Peccei 1994) and understand some
of their intricacies as early as their 24th month (Ebeling and Gelman 1994). These
? Computing Science Department, King?s College, University of Aberdeen, United Kingdom, E-mail:
kvdeemter@csd.abdn.ac.uk.
1 We take such adjectives to be ones that have comparative and superlative forms, and which can be
premodified by intensifiers such as very (Quirk et al 1972, Section 5.4).
Submission received: 7 July 2004; revised submission received: 19 October 2005; accepted for
publication: 24 November 2005.
? 2006 Association for Computational Linguistics
Computational Linguistics Volume 32, Number 2
intricacies include what Ebeling and Gelman call perceptual context dependence, as
when a set of objects is perceptually available and the adjective is applied to an element
or subset of the set (e.g., Is this hat big or is it little?, when two hats of different sizes are
visible).
1.2 Vagueness in NLG
Some NLG systems produce gradable adjectives. The FOG weather-forecast system, for
example, uses numerical input (Rain[Tuesday] = 45 mm) to generate vague output
(Heavy rain fell on Tuesday, Goldberg, Driedger, and Kitteridge 1994). FOG does not
appear to have generic rules governing the use of gradable notions: it does not compute
the meaning of a vague term based on the context, but uses fixed boundary values
instead. A more flexible approach is used by Reiter and Sripada (2002), where users can
specify boundary values for attributes like rainfall, specifying, for example, rain counts
as moderate above 7 mm/h, as heavy above 20 mm/h, and so on. A third approach was
implemented in Dial Your Disc (DYD), where the extension of a gradable adjective like
famous was computed rather than specified by hand (van Deemter and Odijk 1997). To
determine, for example, whether one of Mozart?s piano sonatas could be called a famous
sonata, the system looked up the number x of compact disc recordings of this sonata (as
listed in an encyclopedia) and compared it to the average number y of CD recordings of
each of Mozart?s sonatas. The sonata was called a famous sonata if x >> y. Like DYD, the
work reported in this article will abandon the use of fixed boundary values for gradable
adjectives, letting these values depend on the context in which the adjective is used.
Sometimes we are forced to be vague because the information we have (e.g., based on
perception or verbal reports) is itself inexact. Such cases can be modeled by letting NLG
systems take vague information (e.g., Rain[Wednesday] = heavy) as their input. We
shall focus on the more challenging case where the output of the generator is less precise
than the input, as is the case in FOG and DYD. This can be a hazardous affair, since vague
expressions tend to be interpreted in different ways by different people (Toogood 1980),
sometimes in stark contrast with the intention of the speaker/writer (Berry, Knapp,
and Raynor 2002). We shall therefore focus?unlike earlier computational accounts?on
vague descriptions, that is, vague expressions in definite descriptions. Here, the context
tends to obliterate the vagueness associated with the adjective. Suppose you enter a
vet?s surgery in the company of two dogs: a big one on a leash, and a tiny one in your
arms. The vet asks ?Who?s the patient??, and you answer ?the big dog.? This answer
will allow the vet to pick out the patient just as reliably as if you had said ?the one on
the leash?; the fact that big is a vague term is irrelevant. You omit the exact size of the
dog, just like some of its other properties (e.g., the leash), because they do not improve
the description. This shows how vague properties can contribute to the precise task of
identifying a referent.
1.3 Plan of This Article
We will show how existing algorithms for the generation of referring expressions (GRE)
can do justice to gradable properties, whether they originate from the gradable adjec-
tives in a vague description, or from some entirely different source (such as the degree of
salience of the referent). Considerable attention will be paid to the many open questions
in this area, which will have to be resolved before NLG can be said to contain a proper
treatment of vague expressions. We start with two preliminary sections, containing a
semantic analysis of vague descriptions (Section 2) and a version of the Incremental
196
van Deemter GRE with Gradable Properties
Algorithm that generates references to sets (Section 3). Section 4 describes the core of
one particular algorithm for generating vague descriptions. Section 5 discusses prag-
matic constraints that let such an algorithm avoid descriptions that are semantically
correct but clumsy. Section 6 discusses linguistic realization. Section 7 summarizes
some empirical results. Section 8 explores non-incremental versions of our algorithm.
Section 9 shows how our approach can be extended to include nouns, salience, and
pointing. Section 10 sums up our main findings.
2. The Meaning of Vague Descriptions
2.1 Linguistic Motivation
We shall be studying vague descriptions of various forms: They may or may not contain
a numeral n (positioned before or after the adjective); and the gradable adjective (Adj)
may at least be in base (large) or superlative form (largest):
(1) The (n) Adj(est) N (singular/plural)
(2) The Adj(est) (n) N (singular/plural)
If Adj is in the base form, we focus on the word order (1); if Adj is superlative, we focus
on (2). (Little will hinge on this decision.) We are limiting ourselves to referential uses of
these expressions, excluding cases like This must be the largest tree in the world, in which
the expression ascribes a property to an already-identified object. Likewise, we exclude
intensional ones (e.g., Consider the smallest element of this set, in a mathematical proof,
when the identity of the element may not be known).
Many different analyses are possible of what it means to be large: larger than
average, larger than most, larger than some given baseline, and so on. It is doubtful that
any one of these analyses makes sense for all definite descriptions. To see this, consider
a domain of three mice, sized 5, 8, and 10 cm.2 Here one can speak of
(3) The large mouse (= the one whose size is 10 cm)
(4) The two large mice (= the two whose sizes are 8 and 10 cm)
Clearly, what it takes for the adjective to be applicable has not been cast in stone,
but is open to fiat: the speaker may decide that 8 cm is enough, or the speaker may
set the standards higher (cf., Kennedy 1999). The numeral (whether it is implicit, as
in (3), or explicit) can be construed as allowing the reader to draw inferences about
the standards employed (Kyburg and Morreau 2000; DeVault and Stone 2004): (3), for
example, implies a standard that counts 10 cm as large and 8 cm as not large. Our
own proposal will abstract away from the effects of linguistic context. We shall ask
how noun phrases like the ones in (3) and (4) can be generated, without asking how
they constrain, and are constrained by, other uses of large and related words. This will
allow us to make the following simplification: In a definite description that expresses
only properties that are needed for singling out a referent, we take the base form of
2 The reader is asked to focus on any reasonable size measurement, for example, the maximal horizontal or
vertical distance, or some combination of dimensions (Kamp 1975; also Section 8.1 of the present article).
197
Computational Linguistics Volume 32, Number 2
the adjective to be semantically equivalent to the superlative form (and, analogously, the
comparative):
The n large mice = The largest n mice
The large mice = The largest mice
The large mouse = The largest mouse.
Viewed in this way, gradable adjectives are an extreme example of the ?efficiency of
language? (Barwise and Perry 1983): Far from meaning something concrete like ?larger
than 8 cm??a concept that would have very limited applicability?or even something
more general like ?larger than the average N,? a word like large is applicable across a
wide range of different situations.
2.2 Caveat: Full NP Anaphora
Having said this, there are pragmatic differences between the base form and the superla-
tive (Section 5). For example, the equivalence does not take anaphoric uses into account,
such as when the large mouse is legitimized by the fact that the mouse has been called
large before, as in
(5) I was transfixed by a large mouse on the chimney; then suddenly, dozens
of mice were teeming on the ground. The large mouse was running away.
where the mouse on the chimney may be smaller than those on the ground. We focus on
Ebeling and Gelman?s (1994) perceptual context dependence (Section 1), pretending that
the only contextually relevant factor is the ?comparison set?: those elements of the noun
denotation that are perceptually available. We disregard functional context dependence,
as when the small hat is the one too small to fit on your head.
2.3 Caveat: Evaluative Adjectives
What we said above has also disregarded elements of the ?global? (i.e., not immediately
available) context. For some adjectives, including the ones that Bierwisch (1989) called
evaluative (as opposed to dimensional), this is clearly inadequate. He argued that evalu-
ative adjectives (such as beautiful and its antonym ugly; smart and its antonym stupid,
etc.) can be recognized by the way in which they compare with antonyms. For example
(after Bierwisch 1989),
(6a) Hans is taller than Fritz ? Fritz is shorter than Hans.
(6b) Hans is smarter than Fritz ? Fritz is more stupid than Hans.
We could require that the referent of an evaluative description fall into the correct
segment of the relevant dimension. (For Fritz to be the stupid man, it is not enough
for him to be the least intelligent male in the local context; he also has to be a fairly
stupid specimen in his own right.) If this is done, it is not evident that dimensional
adjectives should be treated differently: If Hans?s and Fritz?s heights are 210 and
198
van Deemter GRE with Gradable Properties
205 cm, respectively, then it seems questionable to describe Fritz as the short man, even if
Hans is the only other man in the local context (but see Sedivy et al 1999, discussed in
Section 7.2). Be this as it may, we shall henceforth focus on local context, assuming that
additional requirements on the global context can be made if necessary.
With these qualifications in place, let us say more precisely what we will assume
the different types of expressions to mean. For ease of reading, concrete examples (e.g.,
large) will replace abstract labels (e.g., ?Adj?), but the analysis is meant to be general.
The largest n mouse/mice; The n large mice. Imagine a set C of contextually relevant
animals. Then these noun phrases (NPs) presuppose that there is a subset S of C that
contains n elements, all of which are mice, and such that (1) C?S =  (i.e., not all
elements of C are elements of S) and (2) every mouse in C?S (i.e., every contextually
relevant mouse not in S) is smaller than every mouse in S. If such a set S exists then the
NP denotes S. The case where n = 1, realized as The large(st) mouse, falls out
automatically.
The large(st) mice. This account can be extended to cover cases of the form the
[Adj]-(est) [Npl] (pl = plural), where the numeral n is suppressed: They will be taken to
be ambiguous between all expressions the [Adj]-(est) n [Npl], where n > 1. Sometimes,
this leaves only one possibility. For instance, in a domain where there are five mice, of
sizes 4, 4, 4, 5, and 6 cm, the only possible value of n is 2, causing the NP to denote the
two mice of 5 and 6 cm in size.
Pragmatic refinements are discussed in Section 5. Our analysis is limited to NPs that
contain only one vague adjective. Doubly-graded descriptions tend to cause ambiguity,
since they involve a trade-off between several dimensions. An NP like the tall fat giraffe,
for example, might describe a referent that is neither the tallest nor the fattest giraffe,
as long as a combination of height and fatness singles it out. Some of the problems that
come up in such cases will be discussed in Section 9.1.
3. Generation of Crisp Descriptions
Arguably the most fundamental task in the generation of referring expressions (GRE),
content determination (CD) requires finding a set of properties that jointly identify the in-
tended referent. Various CD algorithms have been proposed, most of which approximate
the minimal number of properties that are needed to identify the target. Approxima-
tions differ in terms of their computational complexity and the degree to which they
match the way in which people use referring expressions (see Dale and Reiter [1995] for
a survey). As we shall see in Section 8, any one of these algorithms could be used as
a basis for our task. For concreteness, we focus here on Dale and Reiter?s Incremental
Algorithm (IA). We shall use a form of the IA that can refer to sets as well as individuals,
as long as the sets are individuated via their elements (i.e., distributively, as opposed to
collectively, cf., Stone [2000]). This version of the IA will be called IAPlur. (For motivation
and extensions, see van Deemter 2000, 2002.)
3.1 The Incremental Algorithm
Put simply, IA accumulates semantic properties until the target objects are the only ones
in the domain of which all the accumulated properties are true. This can be done by
arranging the properties in a list and by checking, for each property in the list, whether
it is useful (in the sense that it removes one or more distractors); if a property is useful, it
199
Computational Linguistics Volume 32, Number 2
is included in the description, after which the next property is given the same treatment.
This process of checking and including goes on until the target objects are the only ones
of which all the properties in the list are true (i.e., until there are no distractors left).
For reasons that will become apparent later, we complicate matters slightly: Fol-
lowing Dale and Reiter, we view each property as consisting of an Attribute (e.g.,
color) and a Value (e.g., white), written ?Attribute,Value?. (Attributes can be viewed
as grouping together a number of related properties.) Attributes are ordered in a
list A, and this preference order determines the order in which properties are examined
(and possibly added to the description) by the algorithm. Suppose S is the target set,
and C the set of all objects that play a role at a given stage of the algorithm (we call
these the confusables). The algorithm iterates through A; for each Attribute, it checks
whether, by specifying a Value for it, one can rule out at least one member of C that has
not yet been ruled out; if so then the Attribute is added to a set L, with the best possible
Value (as determined by FindBestValue). Confusables that are ruled out are removed
from C. The expansion of L and the contraction of C continue until C = S:
L := 
C := Domain
For each Ai  A do
Vi = FindBestValue(S, Ai)
If S ? [[?Ai, Vi?]] & C ? [[?Ai, Vi?]] then do
L := L ? {?Ai, Vi?}
C := C ? [[?Ai, Vi?]]
If C = S then Return L
Return Failure
FindBestValue selects the ?best value? from among the Values of a given Attribute,
assuming that these are linearly ordered in terms of specificity. The function selects the
Value that removes most distractors, but in case of a tie, the least specific contestant
is chosen, as long as it is not less specific than the basic-level Value (i.e., the most
commonly occurring and psychologically most fundamental level, Rosch 1978). IAPlur
can refer to individuals as well as sets, since reference to a target individual r can be
modeled as reference to the singleton set {r}.
3.2 The Existing Treatment of Gradables
IAPlur deals with vague properties in essentially the same way as FOG: Attributes like
size are treated as if they were not context dependent: Their Values always apply to the
same objects, regardless of what other properties occur in the description. In this way,
IA could never describe the same animal as the large chihuahua and the small brown dog,
for example. This approach does not do justice to gradable adjectives, whether they are
used in the base form, the superlative, or the comparative. Suppose, for example, one set
a fixed quantitative boundary, making the word large true of everything above it, and
false of everything below it. Then IA would tend to have little use for this property
at all since, presumably, every chihuahua would be small and every alsatian large,
making each of the combinations {large, chihuahua} (which denotes the empty set) and
{large, alsatian} (the set of all alsatians) useless. In other words, existing treatments of
gradables in GRE fail to take the ?efficiency of language? into account (Barwise and
Perry 1983; see our Section 2).
200
van Deemter GRE with Gradable Properties
4. The Generation of Vague Descriptions
We now turn to the question of how vague descriptions may be generated from nu-
merical data. We focus on semantic issues, postponing discussion of pragmatics until
Section 5, and linguistic realization until Section 6. We shall make occasional reference
to a PROLOG program called VAGUE, designed by Richard Power, which implements a
version of the algorithm described in this section. Code and documentation for VAGUE
can be found at http://www.csd.abdn.ac.uk/?kvdeemte/vague.html.
4.1 Expressing One Vague Property
4.1.1 Numerical Properties. We shall assume that gradable properties are stored in
the Knowledge Base (KB) as Attributes with (decimal) numerical Values, where the
numbers can be the result of physical measurements. We will sometimes speak of
these numerical Values as if they represented exact Values even though they typically
represent approximations.3 For concreteness, we shall take them to be of the form n cm,
where n is a positive real number. For example,
type = rodent, mouse
color = black, blue, yellow
size = 3 cm, 4 cm, ..., 10 cm.
Making use of this KB, the IA is able to generate a description involving a list of
properties like L = {yellow, mouse, 9 cm}, for example, exploiting the Attribute size.
The result could be the NP The 9-cm yellow mouse, for example. The challenge formulated
in Section 1, however, is to avoid unnecessary precision by avoiding numerical values
unless they are necessary for the individuation of the target. This challenge will be
answered using a replacement strategy. Numerical Values such as 9 cm, in L, will be
replaced by a superlative Value (?being the unique largest element of C?) whenever all
distractors happen to have a smaller size. This list can then be realized in several ways,
using either the superlative, the comparative, or the base form (e.g., the largest yellow
mouse, the larger yellow mouse, or the large yellow mouse).
4.1.2 Exploiting Numerical Properties, Singular. To (almost4) ensure that every descrip-
tion contains a property expressible as a noun, we shall assume that the type Attribute
is more highly preferred than all others. Suppose also, for now, that properties related
to size are less preferred than others. As a result, all other properties that turn up in the
NP are already in the list L when size is added. Suppose the target is c4:
type(c1) = type(c2) = type(c3) = type(c4) = mouse
type(p5) = rat
size(c1) = 6 cm
3 The degree of precision of the measurement (James et al 1996, Section 1.5) determines which objects can
be described by the GRE algorithm, since it determines which objects count as having the same size.
4 To turn this likelihood into a certainty, one can add a test at the end of the algorithm, which adds a
type-related property if none is present yet (cf., Dale and Reiter 1995). VAGUE uses both of these devices.
201
Computational Linguistics Volume 32, Number 2
size(c2) = 10 cm
size(c3) = 12 cm
size(c4) = size(p5) = 14 cm
Since gradable properties are (for now at least) assumed to be dispreferred, the first
property that makes it into L is ?mouse,? which removes p5 from the context set. (Result:
C = {c1, ..., c4}.) Now size is taken into account, and size(x) = 14 cm singles out c4.
The resulting list is
L = {mouse, 14 cm}
This might be considered the end of the matter, since the target has been singled out. But
we are interested in alternative lists, to enable later modules to use gradable adjectives.
One way in which such a list can be computed is as follows. Given that 14 cm happens to
be the greatest size of any mouse, size(x) = 14 cm can be replaced, in L, by the property
of ?being the sole object larger than all other elements of C? (notation: size(x) = max1;
note that C is the set of mice). Since this property is only applicable because of the
properties earlier-introduced into L, it becomes essential that L is an ordered list:
L = ?mouse, size(x) = max1? (?the largest mouse?)
4.1.3 Exploiting Numerical Properties, Plural. If plural descriptions were generated us-
ing the replacement strategy sketched above, it would be impossible to characterize sets
whose elements have different sizes. To make this possible, we have to use inequalities,
that is, Values of the form ?> ?? or ?< ??, instead of Values of the form ?= ??. Therefore,
we compile the KB into a more elaborate form by replacing equalities by inequalities of
the form size(x) > ? or size(x) < ?. The new KB can be limited to relevant inequalities
only: for every n such that the old KB contains an equality of the form size(x) = n cm,
the new KB contains all those inequalities whose truth follows from the equalities in the
old KB. For example,
size(c4), size(p5) > 12 cm
size(c3), size(c4), size(p5) > 10 cm
size(c2), size(c3), size(c4), size(p5) > 6 cm,
where ?size? is an Attribute, ?> 12 cm?, ?> 10 cm?, and ?> 6 cm? are Values, and c2, c3,
c4, c5, p5 are domain objects of which a given ?Attribute, Value? combination is true. The
procedure is analogous to the treatment of negations and disjunctions in van Deemter
(2002): Properties that are implicit in the KB are made available for GRE.
The representation of inequalities is not entirely trivial. For one thing, it is conve-
nient to view properties of the form size(x) < ? as belonging to a different Attribute
than those of the form size(x) > ?, because this causes the Values of an Attribute to be
linearly ordered: Being larger than 12 cm implies being larger than 10 cm, and so on.
More importantly, it will now become normal for an object to have many Values for the
same Attribute; c4, for example, has the Values > 6 cm, > 10 cm, and > 12 cm. Each of
these Values has equal status, so the notion of a basic-level Value cannot play a role (cf.,
Dale and Reiter 1995). If we abstract away from the role of basic-level Values, then Dale
and Reiter?s FindBestValue chooses the most general Value that removes the maximal
202
van Deemter GRE with Gradable Properties
number of distractors, as we have seen. The problem at hand suggests a simpler ap-
proach that will always prefer logically stronger inequalities over logically weaker ones,
even when they do not remove more distractors.5 (Thus, size(x) > m is preferred over
size(x) > n iff m > n; conversely, size(x) < m is preferred over size(x) < n iff m < n.)
This is reflected by the order in which the properties are listed above: Once a size-
related property is selected, later size-related properties do not remove any distractors
and will therefore not be included in the description.
Let us return to our example. Suppose the target set S is {c3, c4}. The KB models
its two elements as having different sizes (12 cm and 14 cm, respectively), hence they
do not share a property of the form size(x) = ?. They do, however, share the property
size(x) > 10 cm. This property is exploited by IAPlur to construct the list
L1 = ?mouse, >10 cm?,
first selecting the property ?mouse,? then the property size(x) > 10 cm. (The property
size(x) > 12 cm is attempted first but rejected.) Since L succeeds in distinguishing
the two target elements, it follows that they are the only mice greater than 10 cm.
Consequently, this inequality can be replaced by the property ?being a set of cardinality
2, whose elements are larger than all others? (notation: size(x) = max2), leading to NPs
such as the largest (two) mice:
L2 = ?mouse, size(x) = max2?.
Note that size(x) = max2 is true of a pair of mice: Strictly speaking, the step from L1 to L2
translates a distributive property (?being larger than 10 cm?) into a collective one. The
case in which the numeral is 1 corresponds with the singular (e.g., the largest mouse).
Optionally, we can go a step further and replace size(x) = max2 by the less specified
property size(x) = max, which abbreviates ?being a set of cardinality greater than 1, all
of whose elements are larger than all other elements in C.? The result may be realized
as the largest mice.
L3 = ?mouse, size(x) = max?.
4.1.4 Ordering of Properties. Even if comparative properties are at the bottom of the
preference order, while stronger inequalities precede weaker ones, the order is not fixed
completely. Suppose, for example, that the KB contains information about height as
well as width, then we have inequalities of the forms (a) height > x, (b) height < x, (c)
width > x, and (d) width < x. Which of these should come first? Hermann and Deutsch
(1976; also reported in Levelt 1989) show that greater differences are most likely to be
chosen, presumably because they are more striking. In experiments involving candles
of different heights and widths, if the referent is both the tallest and the fattest candle,
subjects tended to say ?the tall candle? when the tallest candle is much taller than all
others whereas the same candle is only slightly wider than the others; if the reverse is
the case, the preference switches to ?the fat candle.? Hermann and Deutsch?s findings
may be implemented as follows. First, the Values of the different Attributes should be
normalized to make them comparable. Second, preference order should be calculated
5 A statement p is logically stronger than q if p has q as a logical consequence (i.e., p |= q), whereas the
reverse is not true (i.e., q |= p).
203
Computational Linguistics Volume 32, Number 2
dynamically (i.e., based on the current value of C, and taking the target into account),
preferring larger gaps over smaller ones. (It is possible, e.g., that width is most suitable
for singling out a black cat, but height for singling out a white cat.) The rest of the
algorithm remains unchanged.
4.1.5 Beyond Content Determination (CD). Assuming the analysis of Section 2.1, the
n large mouse/mice is semantically equivalent to the n largest mouse/mice. Consequently,
there is no need to distinguish between the two at the level of CD. Representations like
the ones in L2 and L3 are neutral between the superlative and the base form. Pragmatic
constraints determine which of these expressions [the (n) largest, the (n) larger, the (n)
large] is most appropriate in a given situation (Section 5).
4.1.6 Inference. The replacement strategy, whereby one list of properties is transformed
into another, is essentially a simple kind of logical inference. L1 and L2, for instance, are
guaranteed to single out the same set, given that exactly two mice are larger than 10 cm;
given the content of the KB, the two lists are co-extensive. Once the numeral is dropped,
however, as in L3, there is real loss of information: L3 can be used for characterizing
a number of sets, including the one characterized by L2. In any case, the properties in
these lists are logically distinct, so the choice between them belongs to CD.
4.2 Expressing Several Vague Properties
If the KB contains several gradable Attributes, a description can make use of several of
them, as in example (7). Even if only one gradable Attribute is represented, descriptions
may contain different adjectives, expressing opposites, as in example (8).
(7) The tallest two of the smallest three mice.
(8) The mice that are taller than 2 cm but shorter than 4 cm.
(The latter may be better expressed as the mice that are between 2 and 4 cm tall.) Let us see
how the algorithm of the previous sections can be extended to these cases.
4.2.1 Descriptions Using (In)equalities. When opposites are part of the KB, there is no
need for representing equalities separately, since they arise automatically, as combina-
tions of opposites. Every equality of the form ?size(x) = m cm? is equivalent to the com-
bination of a property of the form ?size(x) > i cm? and one of the form ?size(x) < j cm.?
Given the content of the following KB, for example, saying that the size of an object is
between 6 and 12 cm amounts to saying that its size is 10 cm, and this is implemented
by adding appropriate transformations to the generator.
size(c1) < 10 cm
size(c1), size(c2) < 12 cm
size(c1), size(c2), size(c3) < 14 cm
size(c4), size(p5) > 12 cm
size(c3), size(c4), size(p5) > 10 cm
size(c2), size(c3), size(c4), size(p5) > 6 cm
204
van Deemter GRE with Gradable Properties
Different measures have to be taken when several vague Attributes are involved. Sup-
pose height has these Values:
height(c1) = 7 cm
height(p5) = 8 cm
height(c3) = 9 cm
height(c2) = height(c4) = 10 cm.
After recompiling these into the form of inequalities (reiterating types):
type(c1) = type(c2) = type(c3) = type(c4) = mouse
type(p5) = rat
height(c1) < 8 cm
height(c1), height(p5) < 9 cm
height(c1), height(c3), height(p5) < 10 cm
height(c2), height(c4) > 9 cm
height(c2), height(c3), height(c4) > 8 cm
height(c2), height(c3), height(c4), height(p5) > 7 cm
Suppose the target set is {c2, c3}. The algorithm will first select the property mouse,
since crisp properties are more preferred than vague ones (Result: C = {c1, c2, c3, c4}).
The sequel depends on preference order. Omitting the property of being a mouse for
brevity, possible results include the following:
(a) La = ?size < 14 cm , height > 8 cm?, to be realized as, e.g., the mice
taller than 8 cm but smaller than 14 cm.
(b) Lb = ?height > 8 cm, size > 6 cm, < 14 cm?, e.g., the mice that are taller
than 8 cm and sized between 6 and 14 cm.
Analogous to Section 4.1, one might stop here. But there is scope here for logical
inference, even more so than before; likewise, there are pitfalls, more than before.
4.2.2 Adjectives in Superlative and Base Form. To generate descriptions like the ones
in examples (7) and (8), we need to transform a comparative property into a superlative
property, moving from properties of the form ?height> x? to properties of the form ?the
tallest n.? This can be done in different ways. For example, La may give rise to
(i) ?size < 14 cm, height(x) = max2?,
(?The tallest two of the mice that are smaller than 14 cm?)
(ii) ?size(x) = min3, height(x) = max2?
(?The tallest two of the smallest three mice?)
205
Computational Linguistics Volume 32, Number 2
Once we know which of these outcomes is preferable, the algorithm may be fine-tuned.
(If brevity is an issue, e.g., then one might let a generation program vary the preference
order used by the IA, then choose the outcome that is shortest.) The transformations
described so far rest on logical equivalence (modulo the KB). If numerals are omitted as
well, the result is usually no longer equivalent of course, and the description is at risk
of becoming almost entirely uninformative (e.g., L2):
L1 = ?size(x) = min3, height(x) = max?
L2 = ?size(x) = min, height(x) = max?
The algorithm outlined in this and the previous section can be summarized as follows:
GRE for Vague Descriptions (using IA):
1. Construct KB using Attributes and Values, assigning numerical Values to
Gradable Attributes.
2. Recompile the KB, replacing equalities by inequalities, for all gradable
Attributes.
3. Determine the preference order between the different groups of Attributes.
(A safe approach is to give all gradable Attributes lower preference than
all nongradable ones.)
4. Run IAPlur (Section 3.2), resulting in a list of properties that jointly identify
the target.
5. Apply inferences to the list of properties. For example, replace
combinations of inequalities by one exact Value; replace inequalities by
properties that involve a cardinality; and so on.
6. Perform linguistic realization (Section 6).
If gradable properties are less preferred than crisp ones (point 3) then this algorithm will
only use gradable properties if an entirely crisp distinguishing description is impossible.
This may well cause gradable properties to be underused. For this and other reasons,
we shall consider non-incremental versions of these ideas in Section 8.
4.3 Computational Complexity
We will examine the worst-case complexity of interpretation as well as generation to
shed some light on the hypothesis that vague descriptions are more difficult to process
than others because they involve a comparison between objects (Beun and Cremers
1998, Krahmer and Theune 2002). Before we do this, consider the tractability of the
original IA. If the running time of FindBestValue(r, Ai) is a constant times the number of
Values of the Attribute Ai, then the worst-case running time of IA (and IAPlur) is O(nvna),
where na equals the number of Attributes in the language and nv the average number
of Values of all Attributes. This is because, in the worst case, all Values of all Attributes
need to be attempted (van Deemter 2002). As for the new algorithm, we focus on the
crucial phases 2, 4, and 5.
206
van Deemter GRE with Gradable Properties
Phase 2: Recompilation of the KB forces one to compare all domain elements with each
other. This takes at most quadratic time (i.e., O(n2), where n is the number of elements
in the domain). This can be done off-line, once and for all.
Phase 4: Content Determination. The initial list of properties, which contains inequal-
ities (e.g., L = ?mouse > 5 cm?), is calculated by IAPlur. The algorithm has to take more
Attribute/Value pairs into account as a result of the recompilation of the KB, but this
does not change its theoretical complexity (using nv and na as variables): It is O(nvna).
Phase 5: Inference. The only inference step described so far replaces an inequality (e.g.,
height > n cm) by a ?superlative? property (e.g., height = max2). This step requires
no computation to speak of: For any given inequality that appears in the description,
the value of m can be read off the input to the generator in O(nd) steps, where nd is the
number of distractors. (This comes down to counting the number of elements in the
extension of the inequality.) Therefore, if the number of inequalities in the description is
ni then the complexity is O(ndni).
Thus, the complexity of GRE in the gradable case is determined by three steps: The
first is quadratic and can be performed off-line, the second has a worst-case running
time of O(nvna), and the third one has a worst-case running time of O(ndni). Thus,
gradable GRE takes only polynomial time, and if we focus on the part that cannot be
done off-line, it takes only linear time. In other words, gradable GRE does take more
time than nongradable GRE, but the difference seems modest.
The intuition that vague descriptions are more difficult than others is also confirmed
(though again only to a modest extent) when we focus on the hearer. First, consider a
non-vague description consisting of a combination of n properties, P1, ..., Pn. To discover
its referent, the denotation of the Boolean expression P1 ? .. ? Pn needs to be calculated,
which takes just n?1 calculations of the form
Intersect ?P1? ? ... ? ?Pi?1? (a set that has been computed already)
with ?Pi? (the extension of the next property in the description).
If computing the intersection of two sets takes constant time then this makes the com-
plexity of interpreting non-vague descriptions linear: O(nd), where nd is the number of
properties used. In a vague description, the property last added to the description is
context dependent. Worst case, calculating the set corresponding with such a property,
of the form size(x) = maxm, for example, involves sorting the distractors as to their
size, which may amount to O(n2d) or O(nd log nd) calculations (depending on the sorting
algorithm: cf. [Aho et al 1983] Chapter 8). Once again, the most time-consuming
part of the calculation can be performed off-line, since it is the same for all referring
expressions.
Thus, the worst-case time complexity of interpretation is as follows: The part that can
be computed off-line takes O(nd log nd) calculations. The part that has to be computed
for each referring expression separately takes O(nd) calculations. Once again, there is a
difference with the nongradable case, but the difference is modest, especially regarding
the part that cannot be done off-line. One should bear in mind that worst-case theo-
retical complexity is not always a good measure of the time that a program takes in
the kinds of cases that occur most commonly, let alne the difficulty for a person. For
example, it seems likely that hearers and speakers will have most difficulty dealing with
differences that are too small to be obvious (e.g., two mice that are very similar in size).
207
Computational Linguistics Volume 32, Number 2
5. Pragmatic Constraints
NLG has to do more than select a distinguishing description (i.e., one that unambigu-
ously denotes its referent; Dale 1989): The selected expression should also be felicitous.
Consider the question, discussed in the philosophical logic literature, of whether it is
legitimate, for a gradable adjective, to distinguish between ?observationally indifferent?
entities: Suppose two objects x and y, are so similar that it is impossible to distinguish
their sizes; can it ever be reasonable to say that x is large and y is not? A positive
answer would not be psychologically plausible, since x and y are indistinguishable;
but a negative answer would prohibit any binary distinction between objects that are
large and objects that are not, given that one can always construct objects x and y, one of
which falls just below the divide while the other falls just above it. This is the strongest
version of the sorites paradox (e.g., Hyde 2002).
Our approach to vague descriptions allows a subtle response: that the offending
statement may be correct yet infelicitous. This shifts the problem from asking when
vague descriptions are ?correct? to the question of when they are used felicitously.
Felicity is naturally thought of as a gradable concept. There is therefore no need for a
generator to demarcate precisely between felicitous and infelicitous expressions, as long
as all the utterances generated are felicitous enough. When in doubt, a generator should
avoid the expression in question. If x and y are mice of sizes 10 and 9.9 cm, for example,
then it is probably better to describe x as the largest mouse than as the large mouse.
Prior to carrying out the experiments to be reported in Section 7, we believed that
the following constraints should be taken into account:
Small Gaps. Expressions of the form the (n) large [N] are infelicitous when the gap
between (1) the smallest element of the designated set S (henceforth, s?) and (2) the
largest N smaller than all elements of S (henceforth, s+) is small in comparison with the
other gaps (Thorisson 1994; Funakoshi et al 2004). If this gap is so small as to make the
difference between the sizes of s? and s+ impossible to perceive, then the expression is
also infelicitous.
Dichotomy. When separating one single referent from one distractor, the comparative
form is often said to be favored (Use the comparative form to compare two things). We
expected this to generalize to situations where all the referents are of one size, and all
the distractors of another.
Minimality. Unless Small Gaps and Dichotomy forbid it, we expected that preference
should be given to the base form. In English, where the base form is morphologically
simpler than the other two, this rule could be argued to follow from Gricean principles
(Grice 1975).
To keep matters simple, linguistic realization could choose the base form if and only if
the gap between s? and s+ surpasses a certain value, which is specified interactively by
the user. (This approach was chosen for the VAGUE program.)
As for the presence/absence of the numeral in the description, there appear to be
different ?believable? patterns of linguistic behavior. A cautious generator might only
omit the numeral when the pragmatic principles happen to enforce a specific extension
(e.g., the large mice, when the mice are sized 3, 2.8, 2.499, and 2.498 cm). This would allow
the generator to use vague expressions, but only where they result in a description that
is itself unambiguous.
We shall see in Section 7 that it has not been easy to confirm the pragmatic con-
straints of the present section experimentally.
208
van Deemter GRE with Gradable Properties
6. Linguistic Realization
Some recent GRE algorithms have done away with the separation between content de-
termination and linguistic realization, interleaving the two processes instead (Stone and
Webber 1998; Krahmer and Theune 2002). We have separated the two phases because,
in the case of vague descriptions, interleaving would tend to be difficult. Consider, for
instance, the list of properties L = ?size > 3 cm, size < 9 cm?. If interleaving forced
us to realize the two properties in L one by one, then it would no longer be possible to
combine them into, for example, the largest mouse but one (if the facts in the KB support
it), or even into the mice between 3 and 9 cm (since size > 3 cm is realized before size
< 9 cm). Clearly, sophisticated use of gradable adjectives requires a separation between
CD and linguistic realization, unless one is willing to complicate linguistic realization
considerably.
Having said this, the distinction between CD and linguistic realization is not always
easy to draw. We propose to think of it as separating the language-independent, logical
aspect of referring expressions generation from its language-dependent, linguistic as-
pect. Our algorithm suggests a distinction into three phases, the first two of which can
be thought of as part of CD:
1. CD proper, that is, the production of a distinguishing list of properties L;
2. An inference phase, during which the list L is transformed;
3. A realization phase, during which the choice between base, superlative,
and comparative forms is made, among other things.
One area of current interest concerns the left-to-right arrangement of premodifying
adjectives within an NP (e.g., Shaw and Hatzivassiloglou 1999; Malouf 2000). Work
in this area is often based on assigning adjectives to a small number of categories
(e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives? relative
position. Interestingly, vague properties tend to be realized before others. Quirk et al
(1985), for example, report that ?adjectives denoting size, length, and height normally
precede other nonderived adjectives? (e.g., the small round table is usually preferred to
the round small table).
Semantically, this does not come as a surprise. In a noun phrase of the form the three
small(-est) [N], for example, the words preceding N select the three smallest elements of
[N]. It follows that, to denote the three smallest elements of the set of round tables, the
only option is to say the three small round tables, rather than the three round small tables.
The latter would mean something else, namely, the three round ones among the n small(est)
tables (where n is not specified). It actually seems quite possible to say this, but only
when some set of small tables is contextually salient (e.g., I don?t mean those small tables,
I mean the three round ones). Given that n is unspecified, the noun phrase would tend to
be very unclear in any other context.
The VAGUE program follows Quirk?s rule by realizing gradable properties before
nongradable ones, choosing some simple (and sometimes stilted) syntactic patterns.
7. Empirical Grounding
A full validation of a GRE program that generates vague descriptions would address
the following questions: (1) When is it natural to generate a vague description (i.e., a
209
Computational Linguistics Volume 32, Number 2
qualitative description as opposed to a purely quantitative one)? (2) Given that a vague
description is used, which form of the description is most natural? and (3) Are the
generated descriptions properly understood by hearers and readers? Much is unknown,
but we shall summarize the available results in these three areas very briefly, referring
readers to the literature for details.
7.1 Human Speakers? Use of Vague Descriptions
Common sense (as well as the Gricean maxims; Grice 1975) suggests that vague de-
scriptions are preferred by speakers over quantitative ones whenever the additional
information provided by a quantitative description is irrelevant to the purpose of the
communication. We are not aware of any empirical validation of this idea, but the fact
that vague descriptions are frequent is fairly well documented. Dale and Reiter (1995),
for example, discussed the transcripts of a dialogue between people who assemble
a piece of garden furniture (originally recorded by Candy Sidner). They found that,
while instructional texts tended to use numerical descriptions like the 3 14 ? bolt, human
assemblers ?unless they were reading or discussing the written instructions, in all cases used
relative modifiers, such as the long bolt? (Dale and Reiter 1995).6
Our own experiments (van Deemter 2004) point in the same direction. In one ex-
periment, for example, 34 students at the University of Brighton were shown six pieces
of paper, each of which showed two isosceles and approximately equilateral triangles.
Triangles of three sizes were shown, with bases of 5, 8, and 16 mm respectively. On
each sheet, one of the two triangles had been circled with a pencil. We asked subjects to
imagine themselves on the phone to someone who held a copy of the same sheet, but
not necessarily with the same orientation (e.g., possibly upside down), and to complete
the answers in the following:
Q: Which triangle on this sheet
was circled?
A: The ............ triangle.
This setup was used for testing a number of hypotheses. What is relevant for current
purposes is that all except one subject used qualitative size-related descriptions (the big
triangle, the largest triangle, etc.) in the majority of cases. As many as 27 of the 34 subjects
used such descriptions in all cases.
It seems likely that qualitative descriptions would be less frequent if speakers
were offered an easy way to determine the relevant measurements (e.g., if a ruler was
provided). As it was, subjects went for the easy option, relying on a comparison of sizes
rather than on an estimation of their absolute values. Further experiments are needed
before we can say with more confidence under what circumstances vague descriptions
are favored over absolute ones.
It is normally perhaps unlikely that people produce language on the basis of the
kind of numerical representations that our algorithm has used as input. Although psy-
chological plausibility is not our aim, it is worth noting that the inequalities computed
as step 2 of the algorithm of Section 4 might be psychologically more plausible, since
they are essentially no more than comparisons between objects.
6 Presumably, Beun and Cremers (1998) found vague adjectives to be rare because, in their experiments,
referents could always be identified using nongradable dimensions.
210
van Deemter GRE with Gradable Properties
7.2 Testing the Correctness of the Generated Expressions
Sedivy et al (1999) asked subjects to identify the target of a vague description in a visual
scene. Consider the tall cup. The relevant scene would contain three distractors: (1) a less
tall object of the same type as the target (e.g., a cup that is less tall), (2) a different kind
of object that previous studies had shown to be intermediate in height (e.g., a pitcher
that, while being taller than both cups, was neither short nor tall for a pitcher), and (3)
a different type of object to which the adjective is inapplicable (e.g., a door key). Across
the different conditions under which the experiment was done (e.g., allowing subjects
to study the domain before or after the onset of speech), it was found not to matter
much whether the adjective applied ?intrinsically? to the target object (i.e., whether the
target was tall for a cup): Hearers identifed the target without problems in both types
of situations. The time subjects took before looking at the target for the first time was
measured, and although these latency times were somewhat greater when the referent
were not intrinsically tall than when they were, the average difference was tiny at 554
versus 538 miliseconds. Since latency times are thought to be sensitive to most of the
problems that hearers may have in processing a text, these results suggest that, for
dimensional adjectives, it is forgivable to disregard global context.
To get an idea of whether our plural descriptions are understood correctly by human
readers, we showed subjects sequences of numbers, exactly two of which appeared in
brackets, along with the following instructions:
Suppose you want to inform a hearer *which numbers in
a given list appear in brackets*, where the hearer
knows what the numbers are, but not which of them appear
in brackets. Forexample, the hearer knows that the
list is
1 2 1 7 7 1 1 3 1
You, as a speaker, know that only the two occurrences
of the number 7 appear in brackets:
1 2 1 (7) (7) 1 1 3 1
Our question to you is: Would it be *correct* to convey
this information by saying ??The two high numbers appear
in brackets???
The outcomes of the experiment suggested that readers understand plural vague de-
scriptions in accordance with the semantics of Section 2 (van Deemter 2000). In other
words, they judged the description to be correct if and only if the two highest numbers
in the sequence appeared in brackets.
Assessing the evidence, it seems that vague descriptions are largely unproblematic
from the point of view of interpretation.
7.3 Testing the Felicity of the Generated Expressions
How can we choose between the different forms that a vague description can take?
Reiter and Sripada (2002) showed that the variation in corpora based on expert authors
211
Computational Linguistics Volume 32, Number 2
can be considerable, especially in their use of vague expressions (e.g., by evening, by late
evening, around midnight). We confirmed these findings using experiments with human
subjects (van Deemter 2004), focusing on the choice between the different forms of the
adjective. Informally:
1. The dichotomy constraint of Section 5 did not hold up well: Even when
comparing two things, the superlative form was often preferred over the
comparative.
2. When base forms were used, the gap was almost invariably large.
3. Yet, the Minimality constraint of Section 5 turned out to be difficult to
confirm: Even when the gap was large, base forms were often dispreferred.
The validity of these results can be debated (van Deemter 2004) but, taking them at face
value, one could base different generation strategies on them. For example, one might
use the superlative all the time, since this was?surprisingly?the most frequent form
overall. Based on point (2), however, one might also defend using the base form when-
ever the gap is large enough (as was done in the VAGUE program). Future experiments
should allow us to refine this position, perhaps depending on factors such as genre,
communicative goal, and type of audience.
8. Incrementality: Help or Hindrance?
The account sketched in Section 4 was superimposed on an incremental GRE algorithm,
partly because incrementality is well established in this area (Appelt 1985; Dale and
Reiter 1995). But IA may be replaced by any other reasonable7 GRE algorithm, for
example, one that always exactly minimizes the number of properties expressed, or
one that always ?greedily? selects the property that removes the maximum number of
distractors. Let G be any such GRE algorithm, then we can proceed as follows:
GRE for Vague Descriptions (version not relying on IA):
1. Construct KB using Attributes and Values, assigning numerical Values to
gradable Attributes.
2. Recompile the KB, replacing equalities by inequalities.
3. Let G deliver an unordered set of properties which jointly distinguish the
target if such a set exists. (One or more of these properties may be
inequalities.)
4. Impose a linear ordering on the properties produced by (3). (If one wishes
to generate the same descriptions as in Sections 4.1 and 4.2, then
inequalities go last.) Delete any inequalities that do not remove any
distractors.
7 Concretely, we require of a reasonable GRE algorithm that it avoid combining logically comparable
inequalities, such as size(x) > 10 and size(x) > 20, inside one description. All GRE algorithms
that we know of fulfill this requirement.
212
van Deemter GRE with Gradable Properties
5. Apply inferences (in the style of Section 4.1) to the list of properties.
6. Perform linguistic realization.
Imposing a linear order (4) is a necessary preparation for (5) because the super-
lative properties resulting from (5), unlike the inequalities resulting from (4), are
context dependent. For example, ?mouse, size(x) = max2? (the largest two mice,
{c3, c4}) does not equal ?size(x) = max2, mouse? (the mouse among the largest two
elements, {c4}). Deletion of superfluous inequalities avoids saying, for example, the
short(est) black mouse if there is only one black mouse, because this might invite false
implicatures.
8.1 Problems with Incrementality
While IA is generally thought to be consistent with findings on human language pro-
duction (Hermann and Deutsch 1976; Levelt 1989; Pechmann 1989; Sonnenschein 1982),
the hypothesis that incrementality is a good model of human GRE seems unfalsifiable
until a preference order is specified for the properties on which it operates. (Wildly
redundant descriptions can result if the ?wrong? preference order are chosen.) We shall
see that vague descriptions pose particular challenges to incrementality.
One question emerges when the IA is combined with findings on word order and
incremental interpretation. If human speakers and/or writers perform CD incrementally,
then why are properties not expressed in the same order in which they were selected?
This question is especially pertinent in the case of vague expressions, since gradable
properties are selected last, but realized first (Section 6). This means that the linguistic
realization cannot start until CD is concluded, contradicting eye-tracking experiments
suggesting that speakers start speaking while still scanning distractors (Pechmann
1989). A similar problem is discussed in the psycholinguistics of interpretation (Sedivy
et al 1999): Interpretation is widely assumed to proceed incrementally, but vague de-
scriptions resist strict incrementality, since an adjective in a vague description can only
be fully interpreted when its comparison set is known. Sedivy and colleagues resolve
this quandary by allowing a kind of revision, whereby later words allow hearers to
refine their interpretation of gradable adjectives. Summarizing the situation in gener-
ation and interpretation, it is clear that the last word on incrementality has not been
said.
8.2 Low Preference for Gradable Properties?
It has been argued that, in an incremental approach, gradable properties should be
given a low preference ranking because they are difficult to process (Krahmer and
Theune 2002). We have seen in Section 4.3 that generation and interpretation of vague
descriptions does have a slightly higher computational complexity than that of non-
vague descriptions. Yet, by giving gradable properties a low ranking, we might cause
the algorithm to underuse them, for example, in situations where gradable properties
are highly relevant to the purpose of the discourse (e.g., a fist fight between people of
very different sizes). Luckily, there are no semantic or algorithmic reasons for giving
gradables a low ranking. Let us see how things would work if they were ranked more
highly.
Suppose comparative properties do not go to the end of the preference list. After
transformation into superlative properties, this alternative preference ranking could
213
Computational Linguistics Volume 32, Number 2
lead to a list like ?mouse, size(x) = min4, brown, weight(x) = max2?, where two or-
dinary properties are separated by a superlative one. A direct approach to realization
might word this as the two heaviest brown ones among the smallest four mice. To avoid such
awkward expressions, one can change the order of properties after CD (mirroring step
4 above), moving the inequalities to the end of the list before they are transformed into
the appropriate superlatives. The effect would be to boost the number of occurrences of
gradable properties in generated descriptions while keeping CD incremental.
9. Extensions of the Approach
9.1 Relational Descriptions
Some generalizations of our method are fairly straightforward. For example, consider
a relational description (cf., Dale and Haddock 1991) involving a gradable adjective, as
in the dog in the large shed. CD for this type of descriptions along the lines of Section 4 is
not difficult once relational descriptions are integrated with a standard GRE algorithm
(Krahmer and Theune 2002, Section 8.6.2): Suppose an initial description is generated
describing the set of all those dogs that are in sheds over a given size (say, size 5); if this
description happens to distinguish an individual dog then this legitimizes the use of the
noun phrase the dog in the large shed. Note that this is felicitous even if the shed is not
the largest one in the domain, as is true for d2 in the following situation (contains-a=b
means that a is contained by b):
type(d1) = type(d2) = dog
type(c) = cat
type(s1) = type(s2) = type(s3) = shed
size(d1) = size(d2) = size(c) = 1m
size(s1) = 3m
size(s2) = 5m
size(s3) = 6m
contains-d1 = s1
contains-d2 = s2
contains-c = s3
In other words, the dog in the large shed denotes ?the dog such that there is no other shed
that is equally large or larger and that contains a dog?. Note that it would be odd, in the
above-sketched situation, to say the dog in the largest shed.
9.2 Boolean Combinations
Generalizations to complex Boolean descriptions involving negation and disjunction
(van Deemter 2004) appear to be largely straightforward, except for issues to do with
214
van Deemter GRE with Gradable Properties
opposites and markedness. For example, the generator will have to decide whether to
say the patients that are old or the patients that are not young.
9.3 Multidimensionality
9.3.1 Combinations of Adjectives. When objects are compared in terms of several
dimensions, these dimensions can be weighed in different ways (e.g., Rasmusen 1989).
Let us focus on references to an individual referent r, starting with a description that
contains more than one gradable adjective. The NP the tall fat giraffe, for example,
can safely refer to an element b in a situation like the one below, where b is the only
element that exceeds all distractors with respect to some dimension (a different one
for a than for c, as it happens) while not being exceeded by any distractors in any
dimension:
height(a) = 5 m
height(b) = height(c) = 15 m
width(a) = width(b) = 3 m
width(c) = 2 m
Cases like this would be covered if the decision-theoretic property of Pareto optimality
(e.g., Feldman 1980) was used as the sole criterion: Formally, an object r ? C has a
Pareto-optimal combination of Values V iff there is no other x ? C such that
1. ?Vi ? V : Vi(x) > Vi(r) and
2. ??Vj ? V : Vj(x) < Vj(r)
In our example, b is the only object that has a Pareto-optimal combination of Values,
predicting correctly that b can be called the tall fat giraffe. It seems likely, however, that
people use doubly graded descriptions more liberally. For example, if the example is
modified by letting width(a) = 3.1 m, making a slightly fatter than b, then b might still
be the only reasonable referent of the tall fat giraffe. Many alternative strategies are pos-
sible. The Nash arbitration plan, for example, would allow a doubly graded description
whenever the product of the Values for the referent r exceeds that of all distractors (Nash
1950; cf. Gorniak and Roy 2003; Thorisson 1994, for other plans).
9.3.2 Multidimensional Adjectives (and Color). Multidimensionality can also slip in
through the backdoor. Consider big, for example, when applied to 3D shapes. If there
exists a formula for mapping three dimensions into one (e.g., length ? width ? height)
then the result is one dimension (overall-size), and the algorithm of Section 4 can be
applied verbatim. But if big is applied to a person then it is far from clear that there is one
canonical formula for mapping the different dimensions of your body into one overall
dimension, and this complicates the situation. Similar things hold for multifaceted
properties like intelligence (Kamp 1975).
Color terms are a case apart. If color is modeled in terms of saturation, hue, and lumi-
nosity, for instance, then an object a may be classified as greener than b on one dimension
(e.g., saturation), but less green than b on another (e.g., hue). This would considerably
complicate the application of our algorithm to color terms, which is otherwise mostly
215
Computational Linguistics Volume 32, Number 2
straighforward (Section 9.3). (The green chair, said in the presence of two greenish chairs,
would refer to the one that is closest to prototypical green.) A further complication
is that different speakers can regard very different values as prototypical, making it
difficult to assess which of two objects is greener even on one dimension (Berlin and Kay
1969, pages 10?12). (Ideally, GRE should also take into account that the meaning of color
words can differ across different types of referent. Red as in red hair, e.g., differs from
red as in red chair.)
Different attitudes towards multidimensionality are possible. One possibility is to
be cautious and to keep aiming for distinguishing descriptions in the strict sense. In
this case, the program should limit the use of vague descriptions to situations where
there exists a referent that has a Pareto-optimal combination of Values. Alternatively,
one could allow referring expressions to be ambiguous. It would be consistent with this
attitude, for example, to map multiple dimensions into one overall dimension, perhaps
by borrowing from principles applied in perceptual grouping, where different perceptual
dimensions are mapped into one (e.g., Thorisson 1994). The empirical basis of this line
of work, however, is still somewhat weak, so the risk of referential unclarity looms large.
Also, this attitude would go against the spirit of GRE, where referring expressions have
always been assumed to be distinguishing.
9.4 Salience as a Gradable Property
We shall see that a natural treatment of salience falls automatically out of our treatment
of vague descriptions. As we shall see, this will allow us to simplify the structure of GRE
algorithms, and it will explain why many definite descriptions that look as if they were
distinguishing descriptions are actually ambiguous.
9.4.1 A New Perspective on Salience. Krahmer and Theune (2002) have argued that
Dale and Reiter?s (1995) dichotomy between salient and nonsalient objects (where the
objects in the domain are the salient ones) should be replaced by an account that takes
degrees of salience into account: No object can be too unsalient to be referred to, as long
as the right properties are available. In effect, this proposal (which measured salience
numerically) analyzes the black mouse as denoting the unique most salient object in the
domain that is both black and a mouse. Now suppose we let GRE treat salience just like
other gradable Attributes. Suppose there are ten mice, five of which are black, whose
degrees of salience are 1, 1, 3, 4, and 5 (the last one being most salient), while the other
objects in the domain (cats, white mice) all have a higher salience. Then our algorithm
might generate this list of properties:
L = ?mouse, black, salience > 4?.
This is a distinguishing description for the black mouse whose salience is 5: the most
salient black mouse. The simpler description the black mouse can be derived by stipulating
that the property of being most salient can be left implicit in English. The salience
Attribute has to be taken into account by CD, however, and this can be ensured in various
ways. For example, instead of testing whether C ? [[?Ai, Vi?]] = {r}, one tests whether r
is the most salient element of C ? [[?Ai, Vi?]]. Alternatively, the algorithm might proceed
as usual, performing the usual test (involving C ? [[?Ai, Vi?]] = {r}) but starting with
a reduced domain, consisting of the things that are at least as salient as the target r:
216
van Deemter GRE with Gradable Properties
Domain := {x ? Domain: salience(x) ? r}. The two approaches are equivalent in many
situations.
9.4.2 Salience + Plurality = Ambiguity. It is now easy to see why plural descriptions
are often ambiguous. Taking salience into account as suggested above, the singular the
black mouse can only refer to the most salient mouse. But the mice can refer to the most
salient two (sized 5 and 4), the most salient three (sized 5, 4, and 3), or to all of them. To
disambiguate the description, something like a number can be used (e.g., the two mice),
just as in the case of vague descriptions.
When salience is combined with other gradable notions, the likelihood of unclarity
is even greater. Consider the large(st) dog. Our analysis predicts ambiguity when size
and salience do not go hand in hand.
Type: d1 (dog), d2 (dog), d3 (dog), d4 (dog), c5 (cat)
Size: d1 (20 cm), d2 (50 cm), d3 (70 cm), d4 (60 cm), c5 (50 cm)
Salience: d1 (6), d2 (4), d3 (3), d4 (5), c5 (6).
If we are interested in the three most salient dogs (d1, d2, and d4) then the large(est) dog
designates d4, but if we are interested in the four most salient ones (d1, d2, d3, and d4),
then it designates d3, for example. In other words, the description is ambiguous between
d3 and d4, depending on whether we attach greater importance to salience or size. This
is borne out by our generation algorithm. Consider the simpler of the two treatments of
salience, for example, which starts out with a reduced domain. If d4 is the target then the
reduced domain (consisting of all things at least as salient as the target) is {d1, d2, d4, c5};
dog narrows this down to {d1, d2, d4}, after which size = max1 generates the large dog.
But if d3 is the target then the same procedure applies, this time starting with the full
domain (since no element is less salient that d3) and the same description is generated
to refer to a different animal. For a reader, clearly, salience and gradable adjectives are
a problematic combination. This should come as no surprise, since salience itself is a
gradable property, and combinations of gradable properties are always problematic, as
we have seen in the previous section.
9.4.3 Salience as a Multidimensional Property. Note that salience itself is multidimen-
sional. Consider two people talking about the railway station, when one railway station
is near but of only minor importance (e.g., only few trains stop there), while another is
further afield but of greater significance for travel. In such a situation, it can be unclear
which of the two railway stations is intended. Without more empirical research, we
cannot know how people combine salience with other dimensions.
GRE has usually assumed that distinguishing descriptions are the norm, but once
salience is taken into account (especially in combination with plurals and/or other
gradable dimensions) it becomes difficult to generate descriptions that are immune to
being misunderstood.
9.5 Beyond Vague Descriptions: Nouns, and Pointing
9.5.1 Nouns. Two other generalizations are worth mentioning. The first involves a
class of descriptions that do not involve any overt gradable adjectives. Color terms,
for example (cf., Section 9.1), are applicable to different degrees, and the same is true
217
Computational Linguistics Volume 32, Number 2
for many other nouns, such as girl, which involves a vaguely defined age. Similar
claims can be made about less obvious cases. Consider a gathering containing one
famous professor (a), one junior lecturer (b), one Ph.D. student (c), and a policewoman
(e). Then the word academic might denote (a), but also (b) or (c). Accordingly, each
of the following referring expressions appears viable, mirroring examples 3 and 4 of
Section 2:
1. the academic (Can only refer to a)
2. both academics (Can only refer to {a, b})
3. the three academics (Can only refer to {a, b, c})
These descriptions are easily generated on the basis of a KB that involves Values rep-
resenting degrees of being an academic, the more so because our approach generalizes
to ordinal measurements (except for Small Gaps (Section 5), which requires an inter-
val or ratio scale, since it involves an assessment of the size of the gap between
Values). Note that this treatment could cover all those nouns that are used with various
degrees of strictness. It is difficult to say how many nouns fall in this category, but the
phenomenon is believed to be widespread. This is, for example, one of the central tenets
of Prototype Theory (Rosch 1975). An uncomfortable consequence of these observations
is that it is no longer obvious which words denote a crisp property, and which a gradable
property. (For example, it is not clear whether GRE should treat academic as gradable.)
9.5.2 Pointing. To show that vagueness is also inherent in multimodal communication,
imagine the same gathering, but with some more people present. Suppose someone
points at the centre of the gathering. (See below, where W denotes women.) If the distance
between pointer and pointee is considerable then the boundaries of the region pointed
to are not exactly defined: e is definitely pointed at, but d and f might be doubtful:
[W] [W] [W] [W]
a b c d e f g h i
^^^^^^^^^^
||||||||||
Here, {e} is a possible referent, and so are {d, e, f} and perhaps {c, d, e, f, g}. The set {d, f}
is not, since there is a gap between its two elements. If precise pointing is represented
as a crisp property whose denotation equals the set of elements pointed at (Krahmer
and Van der Sluis 2003), then vague pointing can be incorporated in our algorithm
by representing it by a gradable property: We let the generator use a KB that involves
numerical degrees of being pointed at, where this degree is highest for e, next highest
for d and f , and so on. If this is done, the generator can generate these two women, along
with a pointing gesture like the one in our example, to refer to {e, f}. No changes to
the algorithm of Section 4 are necessary. A variant of this approach arises if pointing
is modeled as a way of establishing degrees of salience (i.e., the closer to the center of
pointing, the higher the value for the attribute SALIENCE) in the style of Section 9.2.
218
van Deemter GRE with Gradable Properties
10. Conclusion
If the usefulness of NLG resides in its ability to present data in human-accessible form,
then vagueness must surely be one of its central instruments, because it allows the
suppression of irrelevant detail. In principle, this might be done by providing the gen-
erator with vague input?in which case no special algorithms are needed?but suitably
contextualized vague input is often not available (Mellish 2000). The only practical
alternative is to provide the generator with ?crisp? (i.e., quantitative) input, allowing the
generator to be hooked on to a general-purpose database. It is this avenue that we have
explored in this article, in combination with various (incremental and other) approaches
to GRE.
Far from being a peculiarity of a few adjectives, vagueness is widespread. We
believe that our approach can be applied to a variety of situations in which vagueness
affects referring expressions including, for example,
 color terms (Section 9.3);
 nouns that allow different degrees of strictness (Section 9.5);
 degrees of salience (Section 9.4); and
 imprecise pointing (Section 9.5).
On the other hand, we have also met some considerable obstacles on our way:
Expressive choice (Sections 4 and 7). By enabling the generator to produce more
referring expressions, we have made it harder to choose between them. For example,
when is a qualitative description preferable over a quantitative one? At a more detailed
level, the generator must choose between descriptions like the heaviest two of the
smallest three mice, the mice that weigh between 40 and 60 grams, and so on, each of which
may single out the same individuals. Section 7.3 has summarized some experimental
evidence related to such choices, focusing on the different forms of the adjective, but the
evidence is far from conclusive. Much is still unknown, differences between speakers
abound, and the experimental methodology for advancing the state of the art in this
area is not without its problems (van Deemter 2004).
Architecture (Section 6). The inference rules that were necessary to convert one list
of properties into another do not sit comfortably within the received NLG pipeline
model (e.g., Reiter and Dale 2000). An example of such an inference rule is the one
that transforms a list of the form ?mouse, >10 cm? into one of the form ?mouse,
size(x) = max2? if only two mice are larger than 10 cm. The same issues also make
it difficult to interleave CD and linguistic realization as proposed by various authors,
because properties may need to be combined before they are expressed.
Incrementality (Section 8). Gradable adjectives complicate the notion of incrementality,
in generation as well as interpretation. Focusing on generation, for example, they force
us to reexamine the idea that properties can be put into words more or less as soon
as they have been selected by content determination (even apart from the issue noted
under Architecture).
219
Computational Linguistics Volume 32, Number 2
Adjectives and presuppositions (Section 2). Our generation-oriented perspective
sheds some doubt on Bierwisch?s (1989) claim that dimensional adjectives are
insensitive to standards provided by the global context: If a man?s height is 205 cm,
then surely no local context can make it felicitous (as opposed to just humorous) to
refer to him as the short man. A related issue that we have not touched upon is the fact
that adjectives are often used partly to pass judgement: One and the same car might
be designated as the expensive car by a hesitant customer and as the luxury car by an
eager salesman: Even if expense and luxury go hand in hand, the two adjectives have
different connotations, and this is something that a generator would ideally be aware of.
Multidimensionality (Section 9.3). We know roughly how to deal with one gradable
dimension: the short man, for example, is the shortest man around. But in practice, we
often juggle several dimensions. This happens, for example, when two adjectives are
used (the short thin man), or when salience is taken into account (e.g., the short man,
when the shortest man is not the most salient one), threatening to make irrefutably
distinguishing descriptions something of an exception. (For a study of approaches to
multidimensionality in a different area, see Masthoff 2004.) At some point, GRE may
have to abandon the strategy of aiming for unambiguous descriptions in all situations.
Acknowledgments
I thank Hua Cheng, Roger Evans, Albert
Gatt, Markus Guhe, Imtiaz Khan, Emiel
Krahmer, Judith Masthoff, Chris Mellish,
Oystein Nilsen, Manfred Pinkal, Paul Piwek,
Ehud Reiter, Graeme Ritchie, Ielka van der
Sluis, Rosemary Stevenson, Matthew Stone,
and Sebastian Varges for helpful comments. I
am especially grateful to Richard Power, for
inspiration as well as for implementing the
VAGUE program at great speed. Thanks are
due to four anonymous reviewers for some
very substantial contributions. This work has
been supported by the EPSRC (GR/S13330,
TUNA project).
References
Aho, Alfred V., John E. Hopcroft, and Jeffrey
D. Ullman. 1983. Data Structures and
Algorithms. Addison-Wesley Publishing
Company, Reading, MA.
Appelt, Doug. Planning English referring
expressions. Artificial Intelligence, 26:1?33.
Reprinted in: B. J. Grosz, K. Sparck Jones,
and B. L. Webber, editors (1986). Readings
in Natural Language Processing. Morgan
Kaufmann, Los Altos, CA.
Barwise, Jon and John Perry. 1983. Situations
and Attitudes. MIT Press, Cambridge, MA.
Berlin, Brent and Paul Kay. 1969. Basic Color
Terms. University of California Press,
Berkeley.
Berry, Dianne C., Peter R. Knapp, and Theo
Raynor. 2002. Is 15 percent very common?
Informing people about the risks of
medication side effects. International
Journal of Pharmacy Practice, 10:145?151.
Beun, Robbert-Jan and Anita Cremers. 1998.
Object reference in a shared domain of
conversation. Pragmatics and Cognition,
6(1/2):121?152.
Bierwisch, Manfred. 1989. The semantics of
gradation. In M. Bierwisch and E. Lang,
editors, Dimensional Adjectives. Springer
Verlag, Berlin, pages 71?261.
Dale, Robert. 1989. Cooking up referring
expressions. In Proceedings of the 27th
Annual Meeting of the Association for
Computational Linguistics (ACL-89),
pages 68?75.
Dale, Robbert and Nickolas Haddock. 1991.
Generating referring expressions
containing relations. Proceedings of the 5th
Conference of the European Chapter of the
ACL, EACL-91, pages 161?166, Berlin,
Germany.
Dale, Robbert and Ehud Reiter. 1995.
Computational interpretations of the
Gricean maximes in the generation of
referring expressions. Cognitive Science,
18:233?263.
DeVault, David and Matthew Stone. 2004.
Interpreting vague utterances in context.
In Proceedings of COLING 2004,
pages 1247?1253, Geneva.
Ebeling, K. S. and S. A. Gelman. 1994.
Children?s use of context in interpreting
?big? and ?little?. Child Development,
65(4):1178-1192.
Feldman, Allan M. 1980. Welfare Economics
and Social Choice Theory. Kluwer, Boston.
220
van Deemter GRE with Gradable Properties
Funakoshi, Kotaro, Satoru Watanabe, Naoko
Kuriyama, and Takenobu Takunaga.
2004. Generating referring expressions
using perceptual groups. In Proceedings
of 3rd International Conference on Natural
Language Generation (INLG) 2004,
pages 51?60. Brockenhurst, UK.
Gaiffe, Bertrand and Laurent Romary. 1997.
Constraints on the use of language,
gesture, and speech for multimodal
dialogues. In Proceedings of ACL Workshop
Referring Phenomena in a Multimedia Context
and Their Computational Treatment,
pages 94?98, Madrid, Spain.
Goldberg, Eli, Norbert Driedger, and Richard
Kitteridge. 1994. Using natural-language
processing to produce weather forecasts.
IEEE Expert, 9(2):45?53.
Gorniak, Peter and Deb Roy. 2003.
Understanding complex visually
referring utterances. In Proceedings of
HLT-NAACL03 Workshop on Learning
Word Meaning from Non-Linguistic Data,
pages 14?21. Edmonton, Canada,
May 2003.
Grice, Paul. 1975. Logic and conversation. In
P. Cole and J. Morgan, editors, Syntax and
Semantics, volume 3, Speech Acts. Academic
Press, New York, pages 43?58.
Hermann, Tony and Roland Deutsch. 1976.
Psychologie der Objektbenennung. Huber
Verlag, Bern.
Hyde, Dominic. 2002. Sorites Paradox.
In Edward Zalta, editor, The Stanford
Encyclopedia of Philosophy (Fall 2002
Edition), http://plato.stanford.edu/
archives/fall2002/entries/sorites-
paradox/.
James, Glyn, David Burley, Dick Clements,
Phil Dyke, John Searl, and Jerry Wright.
1996. Modern Engineering Mathematics,
second edition. Addison-Wesley Longman
Ltd., Harlow, UK.
Kamp, Hans. 1975. Two theories about
adjectives. In E. Keenan, editor, Semantics
for Natural Language. Cambridge
University Press, Cambridge, UK.
Kennedy, Christopher. 1999. Projecting the
Adjective: The syntax and Semantics of
Gradability and Comparison. Ph.D. thesis,
UC Santa Cruz.
Krahmer, Emiel and Marie?t Theune. 2002.
Efficient context-sensitive generation of
referring expressions. In K. van Deemter
and R. Kibble, editors, Information Sharing:
Reference and Presupposition in Language
Generation and Interpretation, CSLI
Publications, CSLI, Stanford,
pages 223?264.
Krahmer, Emiel and Ielka van der Sluis. 2003.
A new model for generating multimodal
referring expressions. In Proceedings of 9th
European Workshop on Natural Language
Generation (ENLG-2003), pages 47?54,
Budapest.
Kyburg, Alice and Michael Morreau.
2000. Fitting Words: vague language in
context. Linguistics and Philosophy,
23:577?597.
Levelt, William J. M. 1989. Speaking: From
Intention to Articulation. MIT Press,
Cambridge, MA.
Malouf, Rob. 2000. The order of prenominal
adjectives in natural language generation.
In Proceedings of ACL-2000, pages 85?92,
Hong Kong.
Masthoff, Judith. 2004. Group modeling:
Selecting a sequence of television items to
suit a group of viewers. User Modeling and
User Adapted Interaction, 14:37?85.
Mellish, Chris. 2000. Understanding
shortcuts in NLG systems. In Proceedings of
Workshop ?Impacts in Natural Language
Generation?, pages 43?50, Dagstuhl,
Germany.
Nash, John. 1950. The bargaining problem.
Econometrica, 18:155?162.
Peccei, Jean Stillwell. 1994. Child Language,
Routledge.
Pechmann, Thomas. 1989. Incremental
speech production and referential
overspecification. Linguistics, 27:98?110.
Pinkal, Manfred. 1979. How to refer with
vague descriptions. In R. Ba?uerle, U. Egli,
and A. von Stechow, editors, Semantics
from Different Points of View. Springer
Verlag, Berlin, pages 32?50.
Quirk, Randolph, Sidney Greenbaum,
Geoffrey Leech, and Jan Svartvik. 1972. A
Grammar of Contemporary English.
Longman, Harlow, Essex.
Quirk, Randolph, Sidney Greenbaum,
Geoffrey Leech, and Jan Svartvik. 1985. A
Comprehensive Grammar of the English.
Longman, Harlow, Essex.
Rasmusen, Eric. 1989. Games and Information:
An Introduction to Game Theory. Blackwell
Publishing.
Reiter, Ehud and Robert Dale. 2000. Building
Natural Language Generation Systems.
Cambridge University Press, Cambridge,
UK.
Reiter, Ehud and Somayajulu (Yaji) Sripada.
2002. Should corpora texts be gold
standards for NLG? In Proceedings of
Second International Conference on Natural
Language Generation (INLG-2002),
pages 97?104, New York.
221
Computational Linguistics Volume 32, Number 2
Rosch, Eleanor. 1975. Cognitive reference
points. Cognitive Psychology, 7:532?547.
Rosch, Eleanor. 1978. Principles of
categorization. In E. Rosch and B. Lloyd,
editors, Cognition and Categorization,
Lawrence Erlbaum, Hillsdale, NJ,
pages 27?48.
Sedivy, Julie, Michael Tanenhaus, Craig
Chambers, and Gregory Carlson. 1999.
Achieving incremental semantic
interpretation through contextual
representation. Cognition, 71:109?147.
Shaw, James and Vasileios Hatzivassiloglou.
1999. Ordering among premodifiers. In
Proceedings of ACL99, pages 135?143,
University of Maryland, College Park.
Sonnenschein, Susan. 1982. The effects of
redundant communications on listeners:
When more is less. Child Development,
53:717?729.
Sripada, Yaji, Ehud Reiter, and Ian Davy.
2003. SumTime-Mousam: Configurable
marine weather forecast generator. Expert
Update, 6(3):4?10.
Stone, Matthew. 2000. On identifying sets. In
Proceedings of INLG-2000, pages 116?123,
Mitzpe Ramon, Israel.
Stone, Matthew and Bonnie Webber. 1998.
Textual Economy through close coupling
of syntax and semantics. In Proceedings of
INLG-1998, pages 178?187.
Tho?risson, Kristinn R. 1994. Simulated
perceptual grouping: An application to
human-computer interaction. In
Proceedings of 6th Annual Conference of the
Cognitive Science Society, pages 876?881.
Toogood, John H. 1980. What do we mean by
?usually?? Lancet, 1:1094.
van Deemter, Kees. 2000. Generating vague
descriptions. In Proceedings of International
Conference on Natural Language Generation
(INLG-2000), pages 179?185, Mitzpe
Ramon, Israel.
van Deemter, Kees. 2002. Generating
referring expressions: Boolean extensions
of the incremental algorithm.
Computational Linguistics, 28(1):37?52.
van Deemter, Kees. 2004. Finetuning an
NLG system through experiments with
human subjects: The case of vague
descriptions. In Proceedings of 3rd
International Conference on Natural
Language Generation (INLG-04),
pages 31?40, Brockenhurst, UK.
van Deemter, Kees and Jan Odijk. 1997.
Context modeling and the generation of
spoken discourse. Speech Communication,
21:101?121.
222
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 255?262,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Conceptual Coherence in the Generation of Referring Expressions
Albert Gatt
Department of Computing Science
University of Aberdeen
agatt@csd.abdn.ac.uk
Kees van Deemter
Department of Computing Science
University of Aberdeen
kvdeemte@csd.abdn.ac.uk
Abstract
One of the challenges in the automatic
generation of referring expressions is to
identify a set of domain entities coher-
ently, that is, from the same conceptual
perspective. We describe and evaluate
an algorithm that generates a conceptually
coherent description of a target set. The
design of the algorithm is motivated by the
results of psycholinguistic experiments.
1 Introduction
Algorithms for the Generation of Referring Ex-
pressions (GRE) seek a set of properties that dis-
tinguish an intended referent from its distractors
in a knowledge base. Much of the GRE litera-
ture has focused on developing efficient content
determination strategies that output the best avail-
able description according to some interpretation
of the Gricean maxims (Dale and Reiter, 1995),
especially Brevity. Work on reference to sets has
also proceeded within this general framework (van
Deemter, 2002; Gardent, 2002; Horacek, 2004).
One problem that has not received much atten-
tion is that of conceptual coherence in the genera-
tion of plural references, i.e. the ascription of re-
lated properties to elements of a set, so that the
resulting description constitutes a coherent cover
for the plurality. As an example, consider a ref-
erence to {e1, e3} in Table 1 using the Incremen-
tal Algorithm (IA) (Dale and Reiter, 1995). IA
searches along an ordered list of attributes, select-
ing properties of the intended referents that re-
move some distractors. Assuming the ordering in
the top row, IA would yield the postgraduate and
the chef, which is fine in case occupation is the
relevant attribute in the discourse, but otherwise is
arguably worse than an alternative like the italian
and the maltese, because it is more difficult to see
what a postgraduate and a chef have in common.
type occupation nationality
e1 man postgraduate maltese
e2 man undergraduate greek
e3 man chef italian
Table 1: Example domain
Such examples lead us to hypothesise the follow-
ing constraint:
Conceptual Coherence Constraint
(CC): As far as possible, describe
objects using related properties.
Related issues have been raised in the formal
semantics literature. Aloni (2002) argues that an
appropriate answer to a question of the form ?Wh
x?? must conceptualise the different instantiations
of x using a perspective which is relevant given the
hearer?s information state and the context. Kron-
feld (1989) distinguishes a description?s functional
relevance ? i.e. its success in distinguishing a ref-
erent ? from its conversational relevance, which
arises in part from implicatures. In our example,
describing e1 as the postgraduate carries the im-
plicature that the entity?s academic role is relevant.
When two entities are described using contrasting
properties, say the student and the italian, the con-
trast may be misleading for the listener.
Any attempt to port these observations to the
GRE scenario must do so without sacrificing logi-
cal completeness. While a GRE algorithm should
attempt to find the most coherent description avail-
able, it should not fail in the absence of a coher-
ent set of properties. This paper aims to achieve
a dual goal. First (?2), we will show that the CC
can be explained and modelled in terms of lexi-
cal semantic forces within a description, a claim
supported by the results of two experiments. Our
focus on ?low-level?, lexical, determinants of ad-
equacy constitutes a departure from the standard
Gricean view. Second, we describe an algorithm
255
motivated by the experimental findings (?3) which
seeks to find the most coherent description avail-
able in a domain according to CC.
2 Empirical evidence
We take as paradigmatic the case where a plural
reference involves disjunction/union, that is, has
the logical form ?x (p(x) ? q(x)), realised as a
description of the form the N1 and the N2. By hy-
pothesis, the case where all referents can be de-
scribed using identical properties (logically, a con-
junction), is a limiting case of CC.
Previous work on plural anaphor processing has
shown that pronoun resolution is easier when an-
tecedents are ontologically similar (e.g. all hu-
mans) (Kaup et al, 2002; Koh and Clifton, 2002).
Reference to a heterogeneous set increases pro-
cessing difficulty.
Our experiments extended these findings to full
definite NP reference. Throughout, we used a dis-
tributional definition of similarity, as defined by
Lin (1998), which was found to be highly corre-
lated to people?s preferences for disjunctive de-
scriptions (Gatt and van Deemter, 2005). The sim-
ilarity of two arbitrary objects a and b is a function
of the information gained by giving a joint descrip-
tion of a and b in terms of what they have in com-
mon, compared to describing a and b separately.
The relevant data in the lexical domain is the
grammatical environment in which words occur.
This information is represented as a set of triples
?rel, w,w??, where rel is a grammatical relation,
w the word of interest and w? its co-argument
in rel (e.g. ? premodifies, dog, domestic ?). Let
F (w) be a list of such triples. The information
content of this set is defined as mutual information
I(F (w)) (Church and Hanks, 1990). The similar-
ity of two words w1 and w2, of the same grammat-
ical category, is:
?(w1, w2) =
2 ? I(F (w1) ? F (w2))
I(F (w1)) + I(F (w2))
(1)
For example, if premodifies is one of the rele-
vant grammatical relations, then dog and cat might
occur several times in a corpus with the same pre-
modifiers (tame, domestic, etc). Thus, ?(dog, cat)
is large because in a corpus, they often occur in
the same contexts and there is considerable infor-
mation gain in a description of their common data.
Rather than using a hand-crafted ontology to in-
fer similarity, this definition looks at real language
Condition a b c distractor
HDS spanner chisel plug thimble
LDS toothbrush knife ashtray clock
Figure 1: Conditions in Experiment 1
use. It covers ontological similarity to the extent
that ontologically similar objects are talked about
in the same contexts, but also cuts across ontolog-
ical distinctions (for example newspaper and jour-
nalist might turn out to be very similar).
We use the information contained in the
SketchEngine database1 (Kilgarriff, 2003), a
largescale implementation of Lin?s theory based
on the BNC, which contains grammatical triples
in the form of Word Sketches for each word, with
each triple accompanied by a salience value in-
dicating the likelihood of occurrence of the word
with its argument in a grammatical relation. Each
word also has a thesaurus entry, containing a
ranked list of words of the same category, ordered
by their similarity to the head word.
2.1 Experiment 1
In Experiment 1, participants were placed in a sit-
uation where they were buying objects from an on-
line store. They saw scenarios containing four pic-
tures of objects, three of which (the targets) were
identically priced. Participants referred to them by
completing a 2-sentence discourse:
S1 The object1 and the object 2 cost amount.
S2 The object3 also costs amount.
If similarity is a constraint on referential coher-
ence in plural references, then if two targets are
similar (and dissimilar to the third), a plural refer-
ence to them in S1 should be more likely, with the
third entity referred to in S2.
Materials, design and procedure All the pic-
tures were artefacts selected from a set of draw-
ings normed in a picture-naming task with British
English speakers (Barry et al, 1997).
Each trial consisted of the four pictures ar-
ranged in an array on a screen. Of the three targets
(a, b, c), c was always an object whose name in
the norms was dissimilar to that of a and b. The
semantic similarity of (nouns denoting) a and b
was manipulated as a factor with two levels: High
Distributional Similarity (HDS) meant that b oc-
curred among the top 50 most similar items to a in
its Sketchengine thesaurus entry. Low DS (LDS))
1http://www.sketchengine.co.uk
256
meant that b did not occur in the top 500 entries
for a. Examples are shown in Figure 2.1.
Visual Similarity (VS) of a and b was also con-
trolled. Pairs of pictures were first normed with a
group who rated them on a 10-point scale based
on their visual properties. High-VS (HVS) pairs
had a mean rating ? 6; Low-VS LVS) pairs had
mean ratings ? 2. Two sets of materials were con-
structed, for a total of 2 (DS) ? 2 (V S) ? 2 = 8
trials.
29 self-reported native or fluent speakers of En-
glish completed the experiment over the web. To
complete the sentences, participants clicked on the
objects in the order they wished to refer to them.
Nouns appeared in the next available space2.
Results and discussion Responses were coded
according to whether objects a and b were referred
to in the plural subject of S1 (a + b responses) or
not (a? b responses). If our hypothesis is correct,
there should be a higher proportion of a + b re-
sponses in the HDS condition. We did not expect
an effect of VS. In what follows, we report by-
subjects Friedman analyses (?21); by-items analy-
ses (?22); and by-subjects sign tests (Z) on propor-
tions of responses for pairwise comparisons.
Response frequencies across conditions differed
reliably by subjects (?21 = 46.124, p < .001).
The frequency of a + b responses in S1 was re-
liably higher than that of a ? b in the HDS condi-
tion (?22 = 41.371, p < .001), but not the HVS
condition (?22 = 1.755, ns). Pairwise compar-
isons between HDS and LDS showed a signif-
icantly higher proportion of a + b responses in
the former (Z = 4.48, p < .001); the differ-
ence was barely significant across VS conditions
(Z = 1.9, p = .06).
The results show that, given a clear choice of
entities to refer to in a plurality, people are more
likely to describe similar entities in a plural de-
scription. However, these results raise two further
questions. First, given a choice of distinguishing
properties for individuals making up a target set,
will participants follow the predictions of the CC?
(In other words, is distributional similarity rele-
vant for content determination?) Second, does the
similarity effect carry over to modifiers, such as
adjectives, or is the CC exclusively a constraint on
types?
2Earler replications involving typing yielded parallel re-
sults and high conformity between the words used and those
predicted by the picture norms.
Three millionaires with a passion for antiques were spotted
dining at a London restaurant.
e1 One of the men, a Rumanian, is a dealeri .
e2 The second, a princej , is a collectori .
e3 The third, a dukej , is a bachelor.
The XXXX were both accompanied by servants, but the
bachelor wasn?t .
Figure 2: Example discourses
2.2 Experiment 2
Experiment 2 was a sentence continuation task,
designed to closely approximate content determi-
nation in GRE. Participants saw a series of dis-
courses, in which three entities (e1, e2, e3) were
introduced, each with two distinguishing proper-
ties. The final sentence in each discourse had a
missing plural subject NP referring to two of these.
The context made it clear which of the three en-
tities had to be referred to. Our hypothesis was
that participants would prefer to use semantically
similar properties for the plural reference, even if
dissimilar properties were also available.
Materials, design and procedure Materials
consisted of 24 discourses, such as those in Fig-
ure 2.2. After an initial introductory sentence, the
3 entities were introduced in separate sentences.
In all discourses, the pairs {e1, e2} and {e2, e3}
could be described using either pairwise similar or
dissimilar properties (similar pairs are coindexed
in the figure). In half the discourses, the dis-
tinguishing properties of each entity were nouns;
thus, although all three entities belonged to the
same ontological category (e.g. all human), they
had distinct types (e.g. duke, prince, bachelor). In
the other half, entities were of the same type, that
is the NPs introducing them had the same nominal
head, but had distinguishing adjectival modifiers.
For counterbalancing, two versions of each dis-
course were constructed, such that, if {e1, e2} was
the target set in Version 1, then {e2, e3} was the
target in Version 2. Twelve filler items requiring
singular reference in the continuation were also in-
cluded. The order in which the entities were intro-
duced was randomised across participants, as was
the order of trials. The experiment was completed
by 18 native speakers of English, selected from the
Aberdeen NLG Group database. They were ran-
domly assigned to either Version 1 or 2.
Results and discussion Responses were coded
1 if the semantically similar properties were used
(e.g. the prince and the duke in Fig. 2.2); 2 if the
257
similar properties were used together with other
properties (e.g. the prince and the bachelor duke);
3 if a superordinate term was used to replace the
similar properties (e.g. the noblemen); 4 otherwise
(e.g. The duke and the collector).
Response types differed significantly in the
nominal condition both by subjects (?21 =
45.89, p < .001) and by items (?22 = 287.9, p <
.001). Differences were also reliable in the mod-
ifier condition (?21 = 36.3, p < .001, ?22 =
199.2, p < .001). However, the trends across con-
ditions were opposed, with more items in the 1 re-
sponse category in the nominal condition (53.7%)
and more in the 4 category in the modifier condi-
tion (47.2%). Recoding responses as binary (?sim-
ilar? = 1,2,3; ?dissimilar? = 4) showed a significant
difference in proportions for the nominal category
(?2 = 4.78, p = .03), but not the modifier cate-
gory. Pairwise comparisons showed a significantly
larger proportion of 1 (Z = 2.7, p = .007) and
2 responses (Z = 2.54, p = .01) in the nominal
compared to the modifier condition.
The results suggest that in a referential task, par-
ticipants are likely to conform to the CC, but that
the CC operates mainly on nouns, and less so on
(adjectival) modifiers. Nouns (or types, as we shall
sometimes call them) have the function of cate-
gorising objects; thus similar types facilitate the
mental representation of a plurality in a concep-
tually coherent way. According to the definition
in (1), this is because similarity of two types im-
plies a greater likelihood of their being used in
the same predicate-argument structures. As a re-
sult, it is easier to map the elements of a plural-
ity to a common role in a sentence. A related
proposal has been made by Moxey and Sanford
(1995), whose Scenario Mapping Principle holds
that a plural reference is licensed to the extent that
the elements of the plurality can be mapped to a
common role in the discourse. This is influenced
by how easy it is to conceive of such a role for the
referents. Our results can be viewed as providing
a handle on the notion of ?ease of conception of a
common role?; in particular we propose that likeli-
hood of occurrence in the same linguistic contexts
directly reflects the extent to which two types can
be mapped to a single plural role.
As regards modifiers, while it is probably pre-
mature to suggest that CC plays no role in modifier
selection, it is likely that modifiers play a different
role from nouns. Previous work has shown that
id base type occupation specialisation girth
e1 woman professor physicist plump
e2 woman lecturer geologist thin
e3 man lecturer biologist plump
e4 man chemist thin
Table 2: An example knowledge base
restrictions on the plausibility of adjective-noun
combinations exist (Lapata et al, 1999), and that
using unlikely combinations (e.g. the immaculate
kitchen rather than the spotless kitchen) impacts
processing in online tasks (Murphy, 1984). Unlike
types, which have a categorisation function, mod-
ifiers have the role of adding information about an
element of a category. This would partially ex-
plain the experimental results: When elements of
a plurality have identical types (as in the modifier
version of our experiment), the CC is already satis-
fied, and selection of modifiers would presumably
depend on respecting adjective-noun combination
restrictions. Further research is required to ver-
ify this, although the algorithm presented below
makes use of the Sketch Engine database to take
modifier-noun combinations into account.
3 An algorithm for referring to sets
Our next task is to port the results to GRE. The
main ingredient to achieve conceptual coherence
will be the definition of semantic similarity. In
what follows, all examples will be drawn from the
domain in Table 3.
We make the following assumptions. There is
a set U of domain entities, properties of which
are specified in a KB as attribute-value pairs. We
assume a distinction between types, that is, any
property that can be realised as a noun; and modi-
fiers, or non-types. Given a set of target referents
R ? U , the algorithm described below generates a
description D in Disjunctive Normal Form (DNF),
having the following properties:
1. Any disjunct in D contains a ?type? property,
i.e. a property realisable as a head noun.
2. If D has two or more disjuncts, each a con-
junction containing at least one type, then the
disjoined types should be as similar as pos-
sible, given the information in the KB and
the completeness requirement: that the algo-
rithm find a distinguishing description when-
ever one exists.
258
We first make our interpretation of the CC more
precise. Let T be the set of types in the KB, and
let ?(t, t?) be the (symmetrical) similarity between
any two types t and t?. These determine a seman-
tic space S = ?T, ??. We define the notion of a
perspective as follows.
Definition 1. Perspective
A perspective P is a convex subset of S, i.e.:
?t, t?, t?? ? T :
{t, t?} ? P ? ?(t, t??) ? ?(t, t?) ? t?? ? P
The aims of the algorithm are to describe ele-
ments of R using types from the same perspective,
failing which, it attempts to minimise the distance
between the perspectives from which types are se-
lected in the disjunctions of D. Distance between
perspectives is defined below.
3.1 Finding perspectives
The system makes use of the SketchEngine
database as its primary knowledge source. Since
the definition of similarity applies to words, rather
than properties, the first step is to generate all pos-
sible lexicalisations of the available attribute-value
pairs in the domain. In this paper, we simplify by
assuming a one-to-one mapping between proper-
ties and words.
Another requirement is to distinguish between
type properties (the set T ), and non-types (M )3.
The Thesaurus is used to find pairwise similarity
of types in order to group them into related clus-
ters. Word Sketches are used to find, for each type,
the modifiers in the KB that are appropriate to the
type, on the basis of the associated salience values.
For example, in Table 3, e3 has plump as the value
for girth, which combines more felicitously with
man, than with biologist.
Types are clustered using the algorithm de-
scribed in Gatt (2006). For each type t, the al-
gorithm finds its nearest neighbour nt in seman-
tic space. Clusters are then found by recursively
grouping elements with their nearest neighbours.
If t, t? have a common nearest neighbour n, then
{t, t?, n} is a cluster. Clearly, the resulting sets are
convex in the sense of Definition 1. Each modi-
fier is assigned to a cluster by finding in its Word
Sketch the type with which it co-occurs with the
greatest salience value. Thus, a cluster is a pair
3This is determined using corpus-derived information.
Note that T and M need not be disjoint, and entities can have
more than one type property
T: {lecturer, professor}
T: {woman, man}
M: {plump, thin}
T: {geologist, physicist,
biologist, chemist}32
1
1 0.6
1
Figure 3: Perspective Graph
?P,M ?? where P is a perspective, and M ? ? M .
The distance ?(A,B) between two clusters A and
B is defined straightforwardly in terms of the dis-
tance between their perspectives PA and PB:
?(A,B) = 1
1 +
P
x?PA,y?PB
?(x,y)
|PA?PB |
(2)
Finally, a weighted, connected graph G =
?V,E, ?? is created, where V is the set of clus-
ters, and E is the set of edges with edge weights
defined as the semantic distance between perspec-
tives. Figure 3.1 shows the graph constructed for
the domain in Table 3.
We now define the coherence of a description
more precisely. Given a DNF description D, we
shall say that a perspective P is realised in D if
there is at least one type t ? P which is in D.
Let PD be the set of perspectives realised in D.
Since G is connected, PD determines a connected
subgraph of G. The total weight of D, w(D) is the
sum of weights of the edges in PD.
Definition 2. Maximal coherence
A description D is maximally coherent iff there
is no description D? coextensive with D such that
w(D) > w(D?).
(Note that several descriptions of the same ref-
erent may all be maximally coherent.)
3.2 Content determination
The core of the content determination procedure
maintains the DNF description D as an associa-
tive array, such that for any r ? R, D[r] is a con-
junction of properties true of r. Given a cluster
?P,M?, the procedure searches incrementally first
through P, and then M , selecting properties that
are true of at least one referent and exclude some
distractors, as in the IA (Dale and Reiter, 1995).
By Definition 2, the task of the algorithm is
to minimise the total weight w(D). If PD is the
259
set of perspectives represented in D on termina-
tion, then maximal coherence would require PD
to be the subgraph of G with the lowest total cost
from which a distinguishing description could be
constructed. Under this interpretation, PD corre-
sponds to a Shortest Connection, or Steiner, Net-
work. Finding such networks is known to be NP-
Hard. Therefore, we adopt a weaker (greedy) in-
terpretation. Under the new definition, if D is
the only description for R, then it trivially satis-
fies maximal coherence. Otherwise, the algorithm
aims to maximise local coherence.
Definition 3. Local coherence
A description D is locally coherent iff:
a. either D is maximally coherent or
b. there is no D? coextensive with D, obtained
by replacing types from some perspective in
PD with types from another perspective such
that w(D) > w(D?).
Our implementation of this idea begins the
search for distinguishing properties by identifying
the vertex of G which contains the greatest num-
ber of referents in its extension. This constitutes
the root node of the search path. For each node
of the graph it visits, the algorithm searches for
properties that are true of some subset of R, and
removes some distractors, maintaining a set N of
the perspectives which are represented in D up to
the current point. The crucial choice points arise
when a new node (perspective) needs to be visited
in the graph. At each such point, the next node n
to be visited is the one which minimises the total
weight of N , that is:
min
n?V
?
u?N
w(u, n) (3)
The results of this procedure closely approxi-
mate maximal coherence, because the algorithm
starts with the vertex most likely to distinguish
the referents, and then greedily proceeds to those
nodes which minimise w(D) given the current
state, that is, taking all previously used nodes into
account.
As an example of the output, we will take
R = {e1, e3, e4} as the intended referents in Table
3. First, the algorithm determines the cluster with
the greatest number of referents in its extension.
In this case, there is a tie between clusters 2 and
3 in Figure 3.1, since all three entities have type
properties in these clusters. In either case, the
entities are distinguishable from a single cluster.
If cluster 3 is selected as the root, the output is
?x [physicist(x) ? biologist(x) ? chemist(x)].
In case the algorithm selects cluster 2 as the
root node the final output is the logical form
?x [man(x) ? (woman(x) ? plump(x))].
There is an alternative description that the
algorithm does not consider. An algorithm
that aimed for conciseness would generate
?x [professor(x) ?man(x)] (the professor and
the men), which does not satisfy local coherence.
These examples therefore highlight the possible
tension between the avoidance of redundancy and
achieving coherence. It is to an investigation of
this tension that we now turn.
4 Evaluation
It has been known at least since Dale and Reiter
(1995) that the best distinguishing description is
not always the shortest one. Yet, brevity plays a
part in all GRE algorithms, sometimes in a strict
form (Dale, 1989), or by letting the algorithm ap-
proximate the shortest description (for example, in
the Dale and Reiter?s IA). This is also true of refer-
ences to sets, the clearest example being Gardent?s
constraint based approach, which always finds the
description with the smallest number of logical op-
erators. Such proposals do not take coherence (in
our sense of the word) into account. This raises
obvious questions about the relative importance of
brevity and coherence in reference to sets.
The evaluation took the form of an experiment
to compare the output of our Coherence Model
with the family of algorithms that have placed
Brevity at the centre of content determination. Par-
ticipants were asked to compare pairs of descrip-
tions of one and the same target set, selecting the
one they found most natural. Each description
could either be optimally brief or not (?b) and also
either optimally coherent or not (?c). Non-brief
descriptions, took the form the A, the B and the C.
Brief descriptions ?aggregated? two disjuncts into
one (e.g. the A and the D?s where D comprises the
union of B and C). We expected to find that:
H1 +c descriptions are preferred over ?c.
H2 (+c,?b) descriptions are preferred over ones
that are (?c,+b).
H3 +b descriptions are preferred over ?b.
Confirmation of H1 would be interpreted as ev-
idence that, by taking coherence into account, our
260
Three old manuscripts were auctioned at Sotheby?s.
e1 One of them is a book, a biography of a composer.
e2 The second, a sailor?s journal, was published
in the form of a pamphlet. It is a record of a voyage.
e3 The third, another pamphlet, is an essay by Hume.
(+c,?b) The biography, the journal and the essay were sold to a col-
lector.
(+c, +b) The book and the pamphlets were sold to a collector.
(?c, +b) The biography and the pamphlets were sold to a collector.
(?c,?b) The book, the record and the essay were sold to a collector.
Figure 4: Example domain in the evaluation
algorithm is on the right track. If H3 were con-
firmed, then earlier algorithms were (also) on the
right track by taking brevity into account. Con-
firmation of H2 would be interpreted as meaning
that, in references to sets, conceptual coherence is
more important than brevity (defined as the num-
ber of disjuncts in a disjunctive reference to a set).
Materials, design and procedure Six dis-
courses were constructed, each introducing three
entities. Each set of three could be described
using all 4 possible combinations of ?b ? ?c
(see Figure 4). Entities were human in two of
the discourses, and artefacts of various kinds in
the remainder. Properties of entities were intro-
duced textually; the order of presentation was ran-
domised. A forced-choice task was used. Each
discourse was presented with 2 possible continua-
tions consisting of a sentence with a plural subject
NP, and participants were asked to indicate the one
they found most natural. The 6 comparisons cor-
responded to 6 sub-conditions:
C1. Coherence constant
a. (+c,?b) vs. (+c,+b)
b. (?c,?b) vs. (?c,+b)
C2. Brevity constant
a. (+c,?b) vs. (?c,?b)
b. (+c,+b) vs. (?c,+b)
C3. Tradeoff/control
a. (+c,?b) vs. (?c,+b)
b. (?c,?b) vs. (+c,+b)
Participants saw each discourse in a single con-
dition. They were randomly divided into six
groups, so that each discourse was used for a dif-
ferent condition in each group. 39 native English
speakers, all undergraduates at the University of
Aberdeen, took part in the study.
Results and discussion Results were coded ac-
cording to whether a participant?s choice was ?b
C1a C1b C2a C2b C3a C3b
+b 51.3 43.6 ? ? 30.8 76.9
+c ? ? 82.1 79.5 69.2 76.9
Table 3: Response proportions (%)
and/or ?c. Table 4 displays response propor-
tions. Overall, the conditions had a significant
impact on responses, both by subjects (Friedman
?2 = 107.3, p < .001) and by items (?2 =
30.2, p < .001). When coherence was kept con-
stant (C1a and C1b), the likelihood of a response
being +b was no different from ?b (C1a: ?2 =
.023, p = .8; C1b: ?2 = .64, p = .4); the con-
ditions C1a and C1b did not differ significantly
(?2 = .46, p = .5). By contrast, conditions
where brevity was kept constant (C2a and C2b)
resulted in very significantly higher proportions of
+c choices (C2a: ?2 = 16.03, p < .001; C2b:
?2 = 13.56, p < .001). No difference was ob-
served between C2a and C2b (?2 = .08, p = .8).
In the tradeoff case (C3a), participants were much
more likely to select a +c description than a +b
one (?2 = 39.0, p < .001); a majority opted
for the (+b,+c) description in the control case
(?2 = 39.0, p < .001).
The results strongly support H1 and H2, since
participants? choices are impacted by Coherence.
They do not indicate a preference for brief de-
scriptions, a finding that echoes Jordan?s (2000),
to the effect that speakers often relinquish brevity
in favour of observing task or discourse con-
straints. Since this experiment compared our al-
gorithm against the current state of the art in ref-
erences to sets, these results do not necessarily
warrant the affirmation of the null hypothesis in
the case of H3. We limited Brevity to number of
disjuncts, omitting negation, and varying only be-
tween length 2 or 3. Longer or more complex de-
scriptions might evince different tendencies. Nev-
ertheless, the results show a strong impact of Co-
herence, compared to (a kind of) brevity, in strong
support of the algorithm presented above, as a re-
alisation of the Coherence Model.
5 Conclusions and future work
This paper started with an empirical investigation
of conceptual coherence in reference, which led
to a definition of local coherence as the basis for
a new greedy algorithm that tries to minimise the
semantic distance between the perspectives repre-
261
sented in a description. The evaluation strongly
supports our Coherence Model.
We are extending this work in two directions.
First, we are investigating similarity effects across
noun phrases, and their impact on text readabil-
ity. Finding an impact of such factors would make
this model a useful complement to current theories
of discourse, which usually interpret coherence in
terms of discourse/sentential structure.
Second, we intend to relinquish the assumption
of a one-to-one correspondence between proper-
ties and words (cf. Siddharthan and Copestake
(2004)), making use of the fact that words can be
disambiguated by nearby words that are similar.
To use a well-worn example: the ?financial institu-
tion? sense of bank might not make the river and
its bank lexically incoherent as a description of a
piece of scenery, since the word river might cause
the hearer to focus on the aquatic reading of the
word anyway.
6 Acknowledgements
Thanks to Ielka van der Sluis, Imtiaz
Khan, Ehud Reiter, Chris Mellish, Graeme
Ritchie and Judith Masthoff for useful com-
ments. This work is part of the TUNA
project (http://www.csd.abdn.ac.uk/
research/tuna), supported by EPSRC grant
no. GR/S13330/01
References
M. Aloni. 2002. Questions under cover. In D. Barker-
Plummer, D. Beaver, J. van Benthem, and P. Scotto
de Luzio, editors, Words, Proofs, and Diagrams.
CSLI, Stanford, Ca.
C. Barry, C. M. Morrison, and A. W. Ellis. 1997.
Naming the snodgrass and vanderwart pictures.
Quarterly Journal of Experimental Psychology,
50A(3):560?585.
K. W. Church and P. Hanks. 1990. Word association
norms, mutual information and lexicography. Com-
putational Linguistics, 16(1):22?29.
R. Dale and E. Reiter. 1995. Computational interpre-
tation of the Gricean maxims in the generation of re-
ferring expressions. Cognitive Science, 19(8):233?
263.
Robert Dale. 1989. Cooking up referring expressions.
In Proc. 27th Annual Meeting of the Association for
Computational Linguistics.
C. Gardent. 2002. Generating minimal definite de-
scriptions. In Proc. 40th Annual Meeting of the As-
sociation for Computational Linguistics.
A. Gatt and K. van Deemter. 2005. Semantic simi-
larity and the generation of referring expressions: A
first report. In Proceedings of the 6th International
Workshop on Computational Semantics, IWCS-6.
A. Gatt. 2006. Structuring knowledge for reference
generation: A clustering algorithm. In Proc. 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics.
H. Horacek. 2004. On referring to sets of objects natu-
rally. In Proc. 3rd International Conference on Nat-
ural Language Generation.
P. W. Jordan. 2000. Can nominal expressions achieve
multiple goals? In Proceedings of the 38th Annual
Meeting of the Association for Computational Lin-
guistics.
B. Kaup, S. Kelter, and C. Habel. 2002. Represent-
ing referents of plural expressions and resolving plu-
ral anaphors. Language and Cognitive Processes,
17(4):405?450.
A. Kilgarriff. 2003. Thesauruses for natural language
processing. In Proc. NLP-KE, Beijing.
S. Koh and C. Clifton. 2002. Resolution of the an-
tecedent of a plural pronoun: Ontological categories
and predicate symmetry. Journal of Memory and
Language, 46:830?844.
A. Kronfeld. 1989. Conversationally relevant descrip-
tions. In Proc. 27th Annual Meeting of the Associa-
tion for Computational Linguistics.
M. Lapata, S. McDonald, and F. Keller. 1999. Deter-
minants of adjective-noun plausibility. In Proc. 9th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics.
D. Lin. 1998. An information-theoretic definition
of similarity. In Proc. International Conference on
Machine Learning.
L. Moxey and A. Sanford. 1995. Notes on plural refer-
ence and the scenario-mapping principle in compre-
hension. In C.Habel and G.Rickheit, editors, Focus
and cohesion in discourse. de Gruyter, Berlin.
G.L. Murphy. 1984. Establishing and accessing refer-
ents in discourse. Memory and Cognition, 12:489?
497.
A. Siddharthan and A. Copestake. 2004. Generat-
ing referring expressions in open domains. In Proc.
42nd Annual Meeting of the Association for Compu-
tational Linguistics.
K. van Deemter. 2002. Generating referring expres-
sions: Boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37?52.
262
Proceedings of the Fourth International Natural Language Generation Conference, pages 55?62,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Overspecified reference in hierarchical domains:
measuring the benefits for readers
Ivandre? Paraboni
University of Sao Paulo
EACH - Av.Arlindo Bettio, 1000
03828-000 Sao Paulo, Brazil
ivandre@usp.br
Judith Masthoff
University of Aberdeen
Dep.of Computing Science
Aberdeen AB24 3UE, Scotland, UK
jmasthoff@csd.abdn.ac.uk
Kees van Deemter
University of Aberdeen
Dep.of Computing Science
Aberdeen AB24 3UE, Scotland, UK
kvdeemte@csd.abdn.ac.uk
Abstract
It is often desirable that referring expres-
sions be chosen in such a way that their
referents are easy to identify. In this paper,
we investigate to what extent identification
becomes easier by the addition of logically
redundant properties.We focus on hierar-
chically structured domains, whose con-
tent is not fully known to the reader when
the referring expression is uttered.
Introduction
Common sense suggests that speakers and writ-
ers who want to get their message across should
make their utterances easy to understand. Broadly
speaking, this view is confirmed by empirical
research (Deutsch 1976, Mangold 1986, Levelt
1989, Sonnenschein 1984, Clark 1992, Cremers
1996, Arts 2004, Paraboni and van Deemter 2002,
van der Sluis, 2005). The present paper follows in
the footsteps of Paraboni and van Deemter (2002)
by focussing on hierarchically structured domains
and asking whether any benefits are obtained when
an algorithm for the generation of referring ex-
pressions (GRE) builds logical redundancy into the
descriptions that it generates. Where Paraboni and
van Deemter (2002) reported on the results of a
simple experiment in which subjects were asked
to say which description they preferred in a given
context, the present paper describes a much more
elaborate experiment, measuring how difficult it is
for subjects to find the referent of a description.
1 Background
Let us distinguish between two aspects of the ?un-
derstanding? of a referring expression, which we
shall denote by the terms interpretation and reso-
lution. We take interpretation to be the process
whereby a hearer/reader determines the meaning
or logical form of the referring expression; we take
resolution to be the identification of the referent of
the expression once its meaning has been deter-
mined. It is resolution that will take centerstage in
our investigation.
Difficulty of resolution and interpretation do not
always go hand in hand. Consider sentences (1a)
and (1b), uttered somewhere in Brighton but not
on Lewes Road.
(1a) 968 Lewes Road
(1b) number 968
Assume that (1a) refers uniquely. If other streets
in Brighton do not have numbers above 900, then
even (1b) is a unique description ? but a pretty
useless one, since it does not help you to find the
house unless your knowledge of Brighton is ex-
ceptional. The description in (1a) is longer (and
might therefore take more time to read and in-
terpret) than (1b), but the additional material in
(1a) makes resolution easier once interpretation is
successfully completed. We explore how an GRE
program should make use of logically redundant
properties so as to simplify resolution (i.e., the
identification of the referent).
In corpus-based studies, it has been shown that
logically redundant properties tend to be included
when they fulfill one of a number of pragmatic
functions, such as to indicate that a property is of
particular importance to the speaker, or to high-
light the speaker?s awareness that the referent has
the property in question (Jordan 2000). However,
redundancy has been built into GRE algorithms
55
only to a very limited extent. Perhaps the most in-
teresting account of overspecification so far is the
one proposed by Horacek (2005), where logically
redundant properties enter the descriptions gener-
ated when the combined certainty of other prop-
erties falls short of what is contextually required.
Uncertainty can arise, for example, if the hearer
does not know about a property, or if she does not
know whether it applies to the target referent.
Our own work explores the need for overspecifi-
cation in situations where each of the properties
in question is unproblematic (i.e., certain) in prin-
ciple, but where the reader has to make an effort
to discover their extension (i.e., what objects are
truthfully described by the property). We ask how
a generator can use logically redundant informa-
tion to reduce the search space within which a
reader has to ?find? a referent. (Cf., Edmonds 1994
for a related set of problems.)
2 Hierarchical domains
Existing work on GRE tends to focus on fairly
simple domains, dominated by one-place proper-
ties. When relations (i.e., two-place properties)
are taken into account at all (e.g., Dale and Had-
dock 1991, Krahmer and Theune 2002), the mo-
tivating examples are kept so small that it is rea-
sonable to assume that speaker and hearer know
all the relevant facts in advance. Consequently,
search is not much of an issue (i.e., resolution is
easy): the hearer can identify the referent by sim-
ply intersecting the denotations of the properties
in the description. While such simplifications per-
mit the study of many aspects of reference, other
aspects come to the fore when larger domains are
considered.
Interesting questions arise, for example, when a
large domain is hierarchically ordered. We con-
sider a domain to be hierarchically ordered if its
inhabitants can be structured like a tree in which
everything that belongs to a given node n be-
long to at most one of n?s children, while every-
thing that belongs to one of n?s children belongs
to n. Examples include countries divided into
provinces which, in turn, may be divided into re-
gions, etc.; years into months then into weeks
and then into days; documents into chapters then
sections then subsections; buildings into floors
then rooms. Clearly, hierarchies are among our
favourite ways of structuring the world.
A crucial question, in all such cases, is what
knowledge is shared between speaker and hearer
at utterance time. It will be convenient to start by
focussing on the extreme case where, before the
start of resolution, knows nothing about the do-
main. When the utterance is made, the hearer?s
blindfold is removed, so to speak, and resolution
can start. No similar assumption about the speaker
is made: we assume that the speaker knows every-
thing about the domain, and that he knows that the
hearer can achieve the same knowledge. Many of
our examples will be drawn from a simple model
of a University campus, structured into buildings
and rooms; the intended referent will often be a
library located in one of the rooms. The location
of the library is not known to the hearer, but it is
known to the speaker. Each domain entity r will be
(d)
   library                                         
Watts building                                                        Cockcroft building
  room100       ...       room120     ...        room140  room100       ...       room110     ...        room120   
University of Brighton
Figure 1: A hierarchically structured domain.
associated with a TYPE (e.g., the type ?room?), and
with some additional attributes such as its ROOM
NUMBER or NAME, and we will assume that it is
always possible to distinguish r from its siblings
in the tree structure by using one or more of these
properties. (For example, ?R.NUMBER=102? iden-
tifies a room uniquely within a given building) 1.
3 Obstacles for resolution
Generating a uniquely referring expression is not
always enough, because such an expression can
leave the hearer with an unnecessarily large search
space. But the issue is an even starker one, es-
pecially when the locations of speaker and hearer
are taken into account. (For simplicity, we assume
that the locations coincide.)
Suppose a hierarchically-ordered domain D con-
tains only one entity whose TYPE is LIBRARY.
Consider the following noun phrases, uttered in
the position marked by d in Figure 1. (The first
three have the same intended referent.)
1This is a useful assumption, since the existence of a dis-
tinguishing description cannot be otherwise guaranteed.
56
(2a) the library, in room 120 in the Cockcroft bld.
(2b) the library, in room 120
(2c) the library
(2d) room 120
Utterances like (2a) and (2b) make use of the hi-
erarchical structure of the domain. Their content
can be modelled as a list
L = ?(x1, P1), (x2, P2)...(xn, Pn)?,
where x1 = r is the referent of the referring ex-
pression and, for every j > 1, xj is an ances-
tor (not necessarily the parent) of xj?1 in D. For
every j, Pj is a set of properties that jointly iden-
tify xj within xj+1 or, if j = n, within the whole
domain. For example, (2a) is modelled as
L = ?(r, {type = library}),
(x2, {type = room, r.number = 120}),
(x3, {type = building,
name = Cockcroft})?
We focus on the search for xn because, under the
assumptions that were just made this is the only
place where problems can occur (since no parent
node is available).
Even though each of (2a)-(2d) succeeds in char-
acterising their intended referent uniquely, some
of these descriptions can be problematic for the
hearer. One such problem occurs in (2d). The
expression is logically sufficient. But, intuitively
speaking, the expression creates an expectation
that the referent may be found nearby, within the
Watts building whereas, in fact, a match can only
be found in another building. In this case we will
speak of Lack of Orientation (LO).
Even more confusion might occur if another li-
brary was added to our example, e.g., in Watts 110,
while the intended referent was kept constant. In
this case, (2c) would fail to identify the referent, of
course. The expression (2b), however, would suc-
ceed, by mutually using two parts of the descrip-
tion (?the library? and ?room 120?) to identify an-
other: there are two libraries, and two rooms num-
bered 120, but there is only one pair (a, b) such
that a is a library and b is a room numbered 120,
while a is located in b. Such cases of mutual iden-
tification are unproblematic in small, transparent,
domains where search is not an issue, but in large
hierarchical domains, they are not. For, like (2d),
(2b) would force a reader to search through an un-
necessarily large part of the domain; worse even,
the search ?path? that the reader is likely to follow
leads via an obstacle, namely room 120 Watts, that
matches a part of the description, while not being
the intended referent of the relevant part of the de-
scription (i.e., room 120 Cockcroft). Confusion
could easily result. In cases like this, we speak of
a Dead End (DE).
In section 5 we will present evidence suggesting
that instances of Dead End and Lack of Orienta-
tion may disrupt search in a sufficiently large or
complex domain. For a theoretical discussion we
refer to Paraboni and van Deemter (2002).
4 Generation algorithms
What kinds of expression would existing GRE al-
gorithms produce in the situations of interest?
Since hierarchies involve relations, the first al-
gorithm that comes to mind is the one pro-
posed by Dale and Haddock (1991). Essen-
tially, this algorithm combines one- and two-
place predicates, until a combination is found that
pins down the target referent. A standard ex-
ample involves a domain containing two tables
and two bowls, while only one of the two tables
has a bowl on it. In this situation, the combi-
nation {bowl(x), on(x, y), table(y)} identifies x
(and, incidentally, also y) uniquely, since only one
value of x can be used to verify the three pred-
icates; this justifies the description ?the bowl on
the table?. This situation can be ?translated? di-
rectly into our university domain. Consider Fig-
ure 2, with one additional library in room 110
of the Watts building. In this situation, the com-
University of Brighton
   
  room100       ...       room110     ...        room120   room100       ...       room120     ...        room140
Watts building                                                        Cockcroft building
   library                                         
(d)
   library                                         
Figure 2: A university campus with two libraries.
bination {library(x), in(x, y), room(y), room ?
number(y) = 2} identifies x (and, incidentally,
also y) uniquely, because no other library is lo-
cated in a room with number 120 (and no other
room numbered 120 contains a library). Thus, the
standard approach to relational descriptions allows
precisely the kinds of situation that we have de-
scribed as DE. Henceforth, we shall describe this
57
as the Minimal Description (MD) approach to ref-
erence because, in the situations of interest, it uses
the minimum number of properties by which the
referent can be distinguished.
Paraboni and van Deemter (2002) have sketched
two GRE algorithms, both of which are guaran-
teed to prevent DE and LO by including logi-
cally redundant information into the generated de-
scriptions so as to reduce the reader?s search space.
These algorithms, called Full Inclusion (FI) and
Scope-Limited (SL), are not the only ways in
which resolution may be aided, but we will see that
they represent two natural options. Both take as
input a hierarchical domain D, a location d where
the referring expression will materialise, and an
intended referent r.
Briefly, the FI algorithm represents a straightfor-
ward way of reducing the length of search paths,
without particular attention to DE or LO. It lines
up properties that identify the referent uniquely
within its parent node, then moves up to identify
this parent node within its parent node, and so on
until reaching a subtree that includes the starting
point d 2. Applied to our earlier example of a ref-
erence to room 120, FI first builds up the list
L = ?(r, {type = room, r.number = 120})?,
then expands it to
L = ?(r, {type = room, r.number = 120}),
(x1, {type = building,
buildingname = Cockcroft})?.
Now that Parent(X) includes d , r has been iden-
tified uniquely within D and we reach STOP. L
might be realised as e.g., ?room 120 in Cockcroft?.
FI gives maximal weight to ease of resolution.
But something has to give, and that is brevity:
By conveying logical redundancy, descriptions are
lengthened, and this can have drawbacks. The
second algorithm in Paraboni and van Deemter
(2002), called SCOPE-LIMITED (SL), constitutes
a compromise between brevity and ease of resolu-
tion. SL prevents DE and LO but opts for brevity
when DE and LO do not occur. This is done
by making use of the notion of SCOPE, hence the
name of the algorithm.
2The idea behind not moving up beyond this subtree is
a natural extension of Krahmer and Theune?s treatment of
salience in GRE: see Paraboni and van Deemter (2002).
The difference between FI and SL becomes ev-
ident when we consider a case in which the min-
imally distinguishing description does not lead to
DE or LO. For example, a reference to r = li-
brary would be realised by FI as ?the library in
room 120 in Cockcroft?. By using SL, however,
the same description would be realised by the SL
algorithm simply as ?the library?, since there is no
risk of DE or LO. With the addition of a second
library in the Watts building, the behaviour of the
SL algorithm would change accordingly, produc-
ing ?the library in Cockcroft?. Similarly, had we
instead included the second library under another
room of Cockcroft, SL would describe r as ?the li-
brary in room 120 of Cockcroft?, just like FI . For
details of both algorithms we refer to Paraboni and
van Deemter (2002).
5 The new experiment
In Paraboni and van Deemter (2002) an experi-
ment was described to find out what types of ref-
erences are favoured by human judges when their
opinion about these references is asked. As an
example of a hierarchically ordered domain, the
experiment made use of a document structured in
sections and subsections. This allowed Paraboni
and van Deemter (2002) to show their subjects the
domain itself, rather than, for example, a pictorial
representation (as it would be necessary in most
other cases such as that of a University campus,
which motivated many of our examples so far).
The experiment investigated the choice of so-
called document-deictic references, such as ?the
picture in part x of section y? made by authors of
documents to check whether they choose to avoid
potential DE and LO situations by adding redun-
dant properties (favouring ease of resolution) and,
conversely, whether they choose shorter descrip-
tions when there is no such risk (favouring ease
of interpretation). The results suggested that hu-
man authors often prefer logically redundant ref-
erences, particularly when DE and LO can arise.
While this approach had the advantage that sub-
jects could compare different expressions (per-
haps balancing ease of interpretation with ease
of resolution), the method is limited in other re-
spects. For example, meta-linguistic judgements
are sometimes thought to be an unreliable pre-
dictor of people?s linguistic behaviour (e.g., van
Deemter 2004). Perhaps more seriously, the ex-
58
periment fails to tell us how difficult a given type
of reference (for example, one of the DE type)
would actually be for a reader. Therefore, in this
paper we report on a second experiment investigat-
ing the effect of the presence or absence of logical
redundancy on the performance of readers. We are
primarily interested in understanding the search
process, so resolution rather than interpretation.
5.1 Experiment design
Subjects: Forty-two computing science students
participated in the experiment, as part of a sched-
uled practical.
Procedure: A within-subjects design was used.
Each subject was shown twenty on-line docu-
ments, in a random order. The entire document
structure was always visible, and so was the con-
tent of the current document part. A screenshot of
an example document providing this level of infor-
mation is shown in Figure 3. Each document was
Figure 3: Fragment of the experiment interface.
initially opened in Part B of either Section 2 or
3, where a task was given of the form ?Let?s talk
about [topic]. Please click on [referring expres-
sion]? . For instance ?Let?s talk about elephants.
Please click on picture 5 in part A?. Subjects
could navigate through the document by clicking
on the names of the parts (e.g. Part A as visi-
ble under Section 3). As soon as the subject had
correctly clicked on the picture indicated, the next
document was presented. Subjects were reminded
throughout the document about the task to be ac-
complished, and the location at which the task
was given. All navigation actions were recorded.
At the start of the experiment, subjects were in-
structed to try to accomplish the task with a mini-
mal number of navigation actions.
We assume that readers do not have complete
knowledge of the domain. So, they do not know
which pictures are present in each part of each sec-
tion. If readers had complete knowledge, then a
minimal description would suffice. We do, how-
ever, not assume readers to be completely ignorant
either3: we allowed them to see the current doc-
ument part (where the question is asked) and its
content, as well as the hierarchical structure (sec-
tions and parts) of the remainder of the document
as in Figure 3 above.
Research Questions: We want to test whether
longer descriptions indeed help resolution, partic-
ularly in so-called problematic situations. Table 1
shows the types of situation (potential DE, LO,
and non-problematic)4 , reader and referent loca-
tion, and descriptions used.
Hypothesis 1: In a problematic (DE/LO) situ-
ation, the number of navigation actions required
for a long (FI /SL) description is smaller than
that required for a short (MD) description.
We will use the DE and LO situations in Ta-
ble 1 to test this hypothesis, comparing for each
situation the number of navigation actions of the
short, that is, minimally distinguishing (MD) and
long (FI/SL) expressions. In Paraboni and van
Deemter (2002) there was an additional hypothe-
sis about non-problematic situations, stating that
MD descriptions would be preferred to long de-
scriptions in non-problematic situations. We can-
not use this hypothesis in this experiment, as it is
highly unlikely that a shorter description will lead
to fewer navigation actions. (Note that the experi-
ment in Paraboni and van Deemter (2002) looked
at the combination of interpretation and resolution,
while we are now focussing on resolution only).
Instead, we will look at gain: the number of navi-
gation actions required for a short description mi-
nus the number required for a long description.
3Readers will always have some knowledge: if in Part B
of Section 2, then they would know (by convention) that there
will also be a Section 1, and a Part A in Section 2 etc.
4In DE situations, there is another picture with the same
number as the referent, but not in a part with the same name
as the part in which the referent is. In LO situations, there
is no other picture with the same number as the referent, and
the reader location contains pictures. In non-problematic sit-
uations, there is another picture with the same number as the
referent, but not in a part with the same name as the part in
which the referent is.
59
Sit. Type Reader Loc. Referent Loc. Short (MD) Long (FI/SL) Long (other)
1 DE Part B Sec 3 Part A Sec 2 Pic 3 in Part A Pic 3 in Part A Sec 2
2 DE Part B Sec 2 Part C Sec 3 Pic 4 in Part C Pic 4 in Part C Sec 3
3 LO Part B Sec 3 Part A Sec 3 Pic 5 Pic 5 in Part A Pic 5 in Part A Sec 3
4 LO Part B Sec 2 Part C Sec 2 Pic 4 Pic 4 in Part C Pic 4 in Part C Sec 2
5 LO Part B Sec 3 Part A Sec 4 Pic 5 Pic 5 in Part A Sec 4 Pic 5 in Part A
6 LO Part B Sec 2 Part C Sec 1 Pic 4 Pic 4 in Part C Sec 1 Pic 4 in Part C
7 NONE Part B Sec 2 Part A Sec 2 Pic 3 in Part A Pic 3 in Part A Sec 2
8 NONE Part B Sec 3 Part C Sec 3 Pic 4 in Part C Pic 4 in Part C Sec 3
Table 1: Situations of reference
Hypothesis 2: The gain achieved by a long
description over an MD description will be
larger in a problematic situation than in a non-
problematic situation.
We will use the DE and non-problematic situa-
tions in Table 1 to test this hypothesis, comparing
the gain of situation 1 with that of situation 7, and
the gain of situation 2 with that of situation 8.
Longer descriptions may always lead to fewer nav-
igation actions, and it can be expected that com-
plete descriptions of the form picture x in Part y of
Section z will outperform shorter descriptions in
any situation. So, from a resolution point of view,
an algorithm that would always give a complete
description may produce better results than the al-
gorithms we proposed, which do not always give
complete descriptions (e.g. situation 3 in Table 1).
The aim of our algorithms is to make the descrip-
tions complete enough to prevent DE and LO in
resolution, but not overly redundant as this may
affect interpretation. We would like to show that
the decisions taken by FI and SL are sensible, i.e.
that they produce descriptions that are neither too
short nor too long. Therefore:
S1: We want to consider situations in which FI
and SL have produced an incomplete descrip-
tion, and investigate how much gain could have
been made by using a complete description in
those cases. We would like this gain to be negli-
gible. We will use situations 3 and 4 for this, cal-
culating the gain of the long, complete descrip-
tions (namely, long (other) in Table 1) over the
short, incomplete descriptions generated by our
algorithms (long (FI /SL) in Table 1).
S2: We want to consider situations in which FI
and SL have produced a complete description,
and investigate how much gain has been made by
using this compared to a less complete descrip-
tion that is still more complete than MD. We
would like this gain to be large. We will use situ-
ations 5 and 6 for this, calculating the gain of the
long complete descriptions generated by our al-
gorithms (long (FI /SL) in Table 1) over the less
complete descriptions (long (other) in Table 1).
Introducing separate hypotheses for cases S1 and
S2 poses the problem of defining when a gain is
?negligible? and when a gain is ?large?. Instead,
we will compare the gain achieved in S1 with the
gain achieved in S2, expecting that the gain in S2
(which we believe to be large) will be larger than
the gain in S1 (which we believe to be negligible).
Hypothesis 3: The gain of a complete descrip-
tion over a less complete one will be larger for
situations in which FI and SL generated the
complete one, than for situations in which they
generated the less complete one.
Materials: Twenty on-line documents were pro-
duced, with the same document structure (sec-
tions 1 to 5 with parts A to C) and containing
10 pictures. Documents had a unique background
colour, title and pictures appropriate for the title.
The number of pictures in a section or part varied
per document. All of this was done to prevent sub-
jects relying on memory.
Documents were constructed specifically for the
experiment. Using real-world documents might
have made the tasks more realistic, but would have
posed a number of problems. Firstly, documents
needed to be similar enough in structure to allow
a fair comparison between longer and shorter de-
scriptions. However, the structure should not al-
low subjects to learn where pictures are likely to be
(for instance, in patient information leaflets most
pictures tend to be at the beginning). Secondly,
the content of documents should not help subjects
find a picture: e.g., if we were using a real docu-
ment on animals, subjects might expect a picture
of a tiger to be near to a picture of a lion. So,
60
Short Long (FI/SL) Long (Other)
Sit. Type Mean STDEV Mean STDEV Mean STDEV
1 DE 3.58 2.14 1.10 0.50
2 DE 3.85 3.28 1.30 1.31
3 LO 5.60 4.84 1.93 1.29 1.23 1.27
4 LO 2.50 1.97 1.60 1.28 1.38 2.07
5 LO 8.53 4.15 1.15 0.53 5.65 6.74
6 LO 7.38 5.49 1.25 1.03 4.08 2.35
7 NONE 1.58 0.98 1.63 2.61
8 NONE 1.48 0.96 1.05 0.32
Table 2: Number of clicks used to complete the tasks.
Sit. Type Mean STDEV
1 DE 2.48 2.24
7 NONE -0.05 2.77
2 DE 2.55 3.62
8 NONE 0.43 1.04
Table 3: Gain as used for Hypothesis 2.
we do not want subjects to use semantic informa-
tion or their background knowledge of the domain.
Thirdly, real documents might not have the right
descriptions in them, so we would need to change
their sentences by hand.
5.2 Results and discussion
Forty subjects completed the experiment. Table
2 shows descriptive statistics for the number of
clicks subjects made to complete each task. To
analyse the results with respect to Hypothesis 1,
we used a General Linear Model (GLM ) with re-
peated measures. We used two repeated factors:
Situation (sit. 1 to 6) and Description Length
(short and long(FI/SL) ). We found a highly sig-
nificant effect of Description Length on the num-
ber of clicks used to complete the task (p<.001).
In all potential problematic situations the number
of clicks is smaller for the long than for the short
description. This confirms Hypothesis 1.
Table 3 shows descriptive statistics for the gain as
used for Hypothesis 2. We again used a GLM
with repeated measures, using two repeated fac-
tors: Descriptions Content (that of situations 1 and
7, and that of situations 2 and 8) and Situation
Type (potential DE and non-problematic). We
found a highly significant effect of Situation Type
on the gain (p<.001). In the non-problematic situ-
ations the gain is smaller than in the potential DE
situations. This confirms Hypothesis 2.
Table 4 shows descriptive statistics for the gain as
used for Hypothesis 3. We again used a GLM
Sit. FI Decision Mean STDEV
3 NOT COMPLETE 0.70 1.40
5 COMPLETE 4.50 6.67
4 NOT COMPLETE 0.23 2.51
6 COMPLETE 2.83 2.16
Table 4: Gain as used for Hypothesis 3.
with repeated measures, using two repeated fac-
tors: Descriptions Content (that of situations 3 and
5, and that of 4 and 6) and FI Decision (with 2
levels: complete and not complete). We found
a highly significant effect of FI Decision on the
gain (p<.001). The gain is smaller for situations
were our algorithm decided to use an incomplete
description than in situations were it chose a com-
plete description. This confirms Hypothesis 3.
6 Conclusion
We have discussed generation strategies that facil-
itate resolution of referring expressions by adding
logically redundant information to the descriptions
generated. Redundancy has a role to play in dif-
ferent kinds of situation (see Introduction for ref-
erences), but we have focussed on a class of cases
that we believe to be widespread, namely where
the domain is hierarchical. We have argued that,
in such situations, minimally distinguishing de-
scriptions can sometimes be useless. Various al-
gorithms for generating logically redundant ref-
erences have been implemented. The extensive
experiment of section 5 indicates that these algo-
rithms are fundamentally on the right track.
The new algorithms discussed in this paper are an
alternative to classical GRE algorithms. This raises
the question how one knows whether to use the
new FI or SL instead of one of its competitors?
Let us compare the predictions made by our al-
gorithms with those made by Dale and Haddock
(1991). Suppose their description ?the bowl on the
table? was said when there are two tables and two
61
bowls, while (only) the table furthest away from
the hearer has a bowl on it. In this situation, FI
and SL would generate something redundant like
the bowl on the far-away table. Which of the two
descriptions is best? We submit that it depends on
the situation: when all the relevant facts are avail-
able to the hearer without effort (e.g., all the do-
main objects are visible at a glance) then minimal
descriptions are fine. But in a huge room, where
it is not obvious to the hearer what is on each ta-
ble, search is required. It is this type of situation
that there is a need for the kind of ?studied? redun-
dancy embodied in FI and SL, because the min-
imally ?the bowl on the table? would not be very
helpful. The new algorithms are designed for situ-
ations where the hearer may have to make an effort
to uncover the relevant facts.
By focussing on the benefits for the reader (in
terms of the effort required for identifying the ref-
erent), we have not only substantiated the claims
in Paraboni and van Deemter (2002), to the effect
that it can be good to add logically redundant in-
formation to a referring expression; we have also
been able to shed light on the reason why redun-
dant descriptions are sometimes preferred (com-
pared with the experiment in Paraboni and van
Deemter (2002), which did not shed light on the
reason for this preference): we can now say with
some confidence that, in the circumstances speci-
fied, the generated redundant descriptions are re-
solved with particular ease. By counting the num-
ber of clicks that subjects need to find the referent,
we believe that we may have achieved a degree of
insight into the ?resolution? processes in the head
of the reader, not unlike the insights coming out
of the kind of eye-tracking experiments that have
been popular in psycholinguistics for a number of
years now. It would be interesting to see whether
our ideas can be confirmed using such a more en-
trenched experimental paradigm.
7 References
Arts, Anja. 2004. Overspecification in instructive
texts. PhD. Tilburg University, The Netherlands.
Wolf Publishers, Nijmegen.
Cremers, Anita. 1996. Reference to Objects;
an empirically based study of task-oriented dia-
logues. Ph.D. thesis, University of Eindhoven.
Dale, Robert and Nicholas Haddock. 1991. Gen-
erating Referring Expressions involving Relations.
EACL, Berlin, pp.161-166.
Dale, Robert and Ehud Reiter. 1995. Computa-
tional Interpretations of the Gricean Maxims in the
Generation of Referring Expressions. Cognitive
Science 18:pp.233-263.
Deutsch, W. 1976. ?Sprachliche Redundanz und
Objectidentifikation.? Unpublished PhD disserta-
tion, University of Marburg.
Edmonds, Philip G. 1994. Collaboration on ref-
erence to objects that are not mutually known.
COLING-1994, Kyoto, pp.1118-1122.
Krahmer, E. and Theune, M. 2002. Efficient
Context-Sensitive Generation of Referring Ex-
pressions. In K. van Deemter and R. Kibble (eds.)
Information Sharing. CSLI Publ., Stanford.
Horacek, Helmut. 2005. Generating referential
descriptions under conditions of uncertainty. 10th
European workshop on Natural Language Gener-
ation (ENLG-2005). Aberdeen, pp.58-67.
Jordan, Pamela W. 2000. Can Nominal Expres-
sions Achieve Multiple Goals?: An Empirical
Study. ACL-2000, Hong Kong.
Levelt, W.J.M. 1989. Speaking: From Intention to
Articulation. MIT Press, Cambridge.
Mangold, Roland. 1986. Sensorische Faktoren
beim Verstehen ueberspezifizierter Objektbenen-
nungen. Frankfurt: Peter Lang Verlag.
Paraboni, Ivandre. 2000. An algorithm for gen-
erating document-deictic references. INLG-2000
Workshop Coherence in Generated Multimedia,
Mitzpe Ramon, pp.27-31.
Paraboni, Ivandre and van Deemter, K. (2002).
Generating Easy References: the Case of Docu-
ment Deixis. INLG-2002, New York, pp.113-119.
Sonnenschein, Susan. 1984. The effect of redun-
dant communication on listeners: Why different
types may have different effects. Journal of Psy-
cholinguistic Research 13, pp.147-166.
van Deemter, Kees. 2004. Finetuning an NLG
system through experiments with human subjects:
the case of vague descriptions. INLG-04, Brock-
enhurst, UK, pp.31-40.
van der Sluis, I. 2005. Multimodal Reference,
Studies in Automatic Generation of Multimodal
Referring Expressions. Ph.D. thesis, Tilburg Uni-
versity, the Netherlands.
62
Proceedings of the Fourth International Natural Language Generation Conference, pages 89?91,
Sydney, July 2006. c?2006 Association for Computational Linguistics
The Clarity-Brevity Trade-off in Generating Referring Expressions ?
Imtiaz Hussain Khan and Graeme Ritchie and Kees van Deemter
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, U.K.
{ikhan,gritchie,kvdeemte}@csd.abdn.ac.uk
Abstract
Existing algorithms for the Generation of
Referring Expressions (GRE) aim at gen-
erating descriptions that allow a hearer to
identify its intended referent uniquely; the
length of the expression is also considered,
usually as a secondary issue. We explore
the possibility of making the trade-off be-
tween these two factors more explicit, via
a general cost function which scores these
two aspects separately. We sketch some
more complex phenomena which might be
amenable to this treatment.
1 Introduction
Until recently, GRE algorithms have focussed on
the generation of distinguishing descriptions that
are either as short as possible (e.g. (Dale, 1992;
Gardent, 2002)) or almost as short as possible (e.g.
(Dale and Reiter, 1995)). Since reductions in am-
biguity are achieved by increases in length, there
is a tension between these factors, and algorithms
usually resolve this in some fixed way. However,
the need for a distinguishing description is usually
assumed, and typically built in to GRE algorithms.
We will suggest a way to make explicit this bal-
ance between clarity (i.e. lack of ambiguity) and
brevity, and we indicate some phenomena which
we believe may be illuminated by this approach.
The ideas in this paper can be seen as a loosen-
ing of some of the many simplifying assumptions
often made in GRE work.
?This work is supported by a University of Aberdeen
Sixth Century Studentship, and the TUNA project (EPSRC,
UK) under grant number GR/S13330/01. We thank Ielka van
der Sluis and Albert Gatt for valuable comments.
2 Clarity, Brevity and Cost
We consider only simple GRE, where the aim is to
construct a conjunction of unary properties which
distinguish a single target object from a set of po-
tential distractors. Our notation is as follows. A
domain consists of a set D of objects, and a set P
of properties applicable to objects in D. A descrip-
tion is a subset of P. The denotation of S, written
[[ S ]], is {x ? D | ?p ? S : p(x)}.
(Krahmer et al, 2003) describe an approach to
GRE in which a cost function guides search for a
suitable description, and show that some existing
GRE algorithms fit into this framework. However,
they follow the practice of concentrating solely on
distinguishing descriptions, treating cost as a mat-
ter of brevity. We suggest that decomposing cost
into two components, for the clarity and brevity
of descriptions, permits the examination of trade-
offs. For now, we will take the cost of a description
S to be the sum of two terms:
cost(S) = fC(S) + fB(S).
where fC counts ambiguity (lack of clarity) and
fB counts size (lack of brevity). Even with this
decomposition of cost, some existing algorithms
can still be seen as cost-minimisation. For exam-
ple, the cost functions:
fC(S) =| P | ? | [[ S ]] |
fB(S) = | S |
allow the Full Brevity algorithm (Dale, 1992) to
be viewed as minimising cost(S), and the in-
cremental algorithm (Dale and Reiter, 1995) as
hill-climbing (strictly, hill-descending), guided by
the property-ordering which that algorithm re-
quires. Whereas Krahmer et al?s cost functions
are (brevity-based) heuristic guidance functions,
our alternative here is a global quantity for opti-
misation. Hence their simulation of Full Brevity
89
relies on the details of their algorithm (rather than
cost) to ensure clarity, while our own cost function
ensures both brevity and clarity.
3 Exploring the Trade-off
3.1 Varying penalties for distractors
Imagine the following situation. You are prepar-
ing a meal in a friend?s house, and you wish to
obtain, from your own kitchen, a bottle of Italian
extra virgin olive oil which you know is there. The
only way open to you is to phone home and ask
your young child to bring it round for you. You
know that also in your kitchen cupboard are some
distractors: one bottle each of Spanish extra virgin
olive oil, Italian non-virgin olive oil, cheap veg-
etable oil, linseed oil (for varnishing) and cam-
phorated oil (medicinal). It is imperative that you
do not get the linseed or camphorated oil, and
preferable that you receive olive oil. A full ex-
pression, Italian extra virgin olive oil, guarantees
clarity, but may overload your helper?s abilities. A
very short expression, oil, is risky. You might well
settle for the intermediate olive oil.
To model this situation, fC could take a much
higher value if [[ S ]] contains a distractor which
must not be selected (e.g. varnish rather than cook-
ing oil). That is, instead of a simple linear function
of the size of [[ S ]], there is a curve where the cost
drops more steeply as the more undesirable dis-
tractors are excluded. For example, each object
could be assigned a numerical rating of how unde-
sirable it is, with the target having a score of zero,
and the fC value for a set A could be the maxi-
mum rating of any element of A. (This would, of
course, require a suitably rich domain model.)
The brevity cost function fB could still be a rel-
atively simple linear function, providing fB values
do not mask the effect of the shape of the fC curve.
3.2 Fuzziness of target
Suppose Mrs X has dropped a piece of raw
chicken meat on the kitchen table, and immedi-
ately removed the meat. She would now like Mr
X to wipe the area clean. The meat leaves no visi-
ble stain, so she has to explain where it was. In this
case, it appears that there is no such thing as a dis-
tinguishing description (i.e. a description that pins
down the area precisely), although Mrs X can ar-
bitrarily increase precision, by adding properties:
? the edge of the table,
? the edge of the table, on the left (etc.)
The ideal description would describe the dirty area
and nothing more, but a larger area will also do,
if not too large. Here, the domain D is implic-
itly defined as all conceivable subareas of the ta-
ble, the target is again one element of D, but ? un-
like the traditional set-up with discrete elements ?
a description (fuzzily) defines one such area, not
a disjoint collection of individual items. Our fC
operates on the description S, not just on the num-
ber of distractors, so it can assess the aptness of
the denotation of any potential S. However, it has
to ensure that this denotation (subarea of the sur-
face) contains the target (contaminated area), and
does not contain too much beyond that. Hence,
we may need to augment our clarity cost function
with another argument: the target itself. In gen-
eral, more complex domains may need more com-
plicated functions.
3.3 Underspecification in dialogue
Standard GRE algorithms assume that the speaker
knows what the hearer knows (Dale and Reiter,
1995). In practice, speakers can often only guess.
It has been observed that speakers sometimes pro-
duce referring expressions that are only disam-
biguated through negotiation with the hearer, as
exemplified in the following excerpt (quoted in
(Hirst, 2002)).
1. A: What?s that weird creature over there?
2. B: In the corner?
3. A: [affirmative noise]
4. B: It?s just a fern plant.
5. A: No, the one to the left of it.
6. B: That?s the television aerial. It pulls out.
A and B are in the same room, in an informal set-
ting, so A can be relatively interactive in convey-
ing information. Also, the situation does not ap-
pear to be highly critical, in comparison to a mil-
itary officer directing gunfire, or a surgeon guid-
ing an incision. Initially, A produces an expres-
sion which is not very detailed. It may be that he
thinks this is adequate (the object is sufficiently
salient that B will uniquely determine the refer-
ent), or he doesn?t really know, but is willing to
make an opening bid in a negotiation to reach the
goal of reference. In the former case, a GRE algo-
rithm which took account of salience (e.g. (Krah-
mer and Theune, 1999)), operating withA?s model
of B?s knowledge, should produce this sort of ef-
fect. (A dialogue model might also be needed.) In
the latter case, we need an algorithm which can
90
relax the need for complete clarity. This could be
arranged by having fC give similar scores to deno-
tations where there are no distractors and to deno-
tations where there are just a few distractors, with
fB making a large contribution to the cost.
3.4 Over-specification
Recently, interest has been growing in ?overspec-
ified? referring expressions, which contain more
information than is required to identify their in-
tended referent. Some of this work is mainly or ex-
clusively experimental (Jordan and Walker, 2000;
Arts, 2004), but algorithmic consequences are also
being explored (Horacek, 2005; Paraboni and van
Deemter, 2002; van der Sluis and Krahmer, 2005).
Over-specification could also arise in a dialogue
situation (comparable to that in Section 3.3) if a
speaker is unclear about the hearer?s knowledge,
and so over-specifies (relative to his own knowl-
edge) to increase the chances of success.
This goes beyond the classical algorithms,
where the main goal is total clarity, with no rea-
son for the algorithm to add further properties to
an already unambiguous expression. That is, such
algorithms assume that every description S for
which | [[ S ]] |= 1 has the same level of clarity
(fC value). This assumption could be relaxed. For
example, the approach of (Horacek, 2005) to GRE
allows degrees of uncertainty about the effective-
ness of properties to affect their selection. Within
such a framework, one could separately compute
costs for clarity (e.g. likelihood of being under-
stood) and brevity (which might include the com-
plexity of expressing the properties).
4 Conclusion and Future Work
We have argued that the GRE task becomes very
different when some commonly-made assump-
tions are abandoned: some distractors might be
worse than others (section 3.1); the target may be
impossible to distinguish precisely (section 3.2);
the speaker may be unsure what the hearer knows
(section 3.3); or there may be a need for over-
specification (section 3.4)). As a result, it may be
necessary to consider other aspects of the descrip-
tions and their denotations, not simply counting
distractors or numbers of properties. Some effects
could perhaps be modelled using costs which are
not simple linear functions, but which give varying
importance to particular aspects of the denotation
of a description, or of its content. We hope that
this approach will ultimately shed light not only
on the effect of the discourse situation, but also
some aspects of generating indefinite descriptions.
References
Anja Arts. 2004. Overspecification in Instructive Text.
Ph.D. thesis, Tilburg University, The Netherlands.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
18:233?263.
Robert Dale. 1992. Generating Referring Expres-
sions: Building Descriptions in a Domain of Objects
and Processes. MIT Press.
Claire Gardent. 2002. Generating minimal distin-
guishing descriptions. In Proceedings of the 40th
Annual Meeting of the ACL (ACL?02), Philadelphia,
USA.
Graeme Hirst. 2002. Negotiation, compromise, and
collaboration in interpersonal and human?computer
conversations. In Proceedings of Workshop on
Meaning Negotiation, 18th National Conference
on Artificial Intelligence, pages 1?4, Edmonton,
Canada.
Helmut Horacek. 2005. Generating referential de-
scriptions under conditions of uncertainty. In Gra-
ham Wilcock, Kristiina Jokinen, Chris Mellish, and
Ehud Reiter, editors, Proceedings of the 10th Eu-
ropean Workshop on Natural Language Generation
(ENLG-05), pages 58?67.
Pamela Jordan and Marilyn Walker. 2000. Learning
attribute selections for non-pronominal expressions.
In Proceedings of the 38th Annual Meeting of the
ACL (ACL-00), pages 181?190.
Emiel Krahmer and Marie?t Theune. 1999. Efficient
generation of descriptions in context. In Proceed-
ings of the ESSLLI workshop on the generation of
nominals, Utrecht, The Netherlands.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Ivandre? Paraboni and Kees van Deemter. 2002. Gener-
ating easy references: the case of document deixis.
In Proceedings of the Second International Confer-
ence on Natural Language Generation, New York,
USA.
Ielka van der Sluis and Emiel Krahmer. 2005. Towards
the generation of overspecified multimodal referring
expressions. In Proceedings of the Symposium on
Dialogue Modelling and Generation at the 15th An-
nual Meeting of the ST & D (STD-05), Amsterdam,
The Netherlands.
91
Proceedings of the Fourth International Natural Language Generation Conference, pages 130?132,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Building a semantically transparent corpus
for the generation of referring expressions
Kees van Deemter and Ielka van der Sluis and Albert Gatt
Department of Computing Science
University of Aberdeen
{kvdeemte,ivdsluis,agatt}@csd.abdn.ac.uk
Abstract
This paper discusses the construction of
a corpus for the evaluation of algorithms
that generate referring expressions. It is
argued that such an evaluation task re-
quires a semantically transparent corpus,
and controlled experiments are the best
way to create such a resource. We address
a number of issues that have arisen in an
ongoing evaluation study, among which is
the problem of judging the output of GRE
algorithms against a human gold standard.
1 Creating and using a corpus for GRE
A decade ago, Dale and Reiter (1995) published
a seminal paper in which they compared a num-
ber of GRE algorithms. These algorithms included
a Full Brevity (FB) algorithm which generates de-
scriptions of minimal length, a greedy algorithm
(GA), and an Incremental Algorithm (IA). The
authors argued that the latter was the best model
of human referential behaviour, and versions of
the IA have since come to represent the state
of the art in GRE. Dale and Reiter?s hypothe-
sis was motivated by psycholinguistic findings,
notably that speakers tend to initiate references
before they have completely scanned a domain.
However, this finding affords different algorithmic
interpretations. Similarly, the finding that basic-
level terms in referring expressions allow hearers
to form a psychological gestalt could be incorpo-
rated into practically any GRE algorithm.1
We decided to put Dale and Reiter?s hypothesis
to the test by an evaluation of the output of dif-
1A separate argument for IA involves tractability, but al-
though some alternatives (such as FB) are intractable, others
(such as GA) are only polynomial, and can therefore not eas-
ily be dismissed on purely computational grounds.
ferent GRE algorithms against human production.
However, it is notoriously difficult to obtain suit-
able corpora for a task that is as semantically in-
tensive as Content Determination (for GRE). Al-
though existing corpora are valuable resources,
NLG often requires information that is not avail-
able in text. Suppose, for example, that a corpus
contained articles about politics, how would the
output of a GRE algorithm be evaluated against the
corpus? It would be difficult to infer from an ar-
ticle exactly which representatives in the British
House of Commons are Liberal Democrats, or
Scottish. Combining multiple texts is hazardous,
since facts could alter across sources and time.
Moreover, the conditions under which such texts
were produced (e.g. fault-critical or not, as ex-
plained below) are hard to determine.
A recent GRE evaluation by Gupta and Stent
(2005) focused on dialogue corpora, using MAP-
TASK and COCONUT, both of which have an as-
sociated domain. Their results show that referent
identification in MAPTASK often requires no more
than a TYPE attribute, so that none of the algo-
rithms performed better than a baseline. In con-
trast to MAPTASK, COCONUT has a more elabo-
rate domain, but it is characterised by a collabora-
tive task, and references frequently go beyond the
identification criterion that is typically invoked in
GRE2. Mindful of the limitations of existing cor-
pora, and of the extent to which evaluation de-
pends on the corpus under study, we are using
controlled experiments to create a corpus whose
construction will ensure that existing algorithms
can be adequately differentiated on an identifica-
tion task.
2Jordan and Walker (2000) have demonstrated a signifi-
cantly better match to the human data when task-related con-
straints are taken into account.
130
2 Setup of the experiment
Like Dale and Reiter (1995), we focused on first-
mention descriptions. However, we decided to in-
clude simple ?disjunctive? references to sets (as
in ?the red chair and the black table?), in addi-
tion to conjunctions of atomic properties, since
these can be handled by essentially the same al-
gorithms (van Deemter, 2002). For generality, we
looked at two very different domains. One of these
involved artificially constructed pictures of furni-
ture, where the available attributes and values are
relatively easy to determine. The other involved
real photographs of individuals, which provide a
richer range of options to subjects. To date, data
has been collected from 19 participants, and anal-
ysis is in progress.
Our first challenge was to make the experiment
naturalistic. Subjects were shown 38 randomised
trials, each depicting a set of objects, one or two
of which were the targets, surrounded by 6 dis-
tractors (Figure 1). In each case, a minimal distin-
guishing description of the targets was available.
Subjects were led to believe that they would be
describing the targets for an interlocutor. Once a
description was typed, the system removed from
the screen what it took to be the referents.
Figure 1: A stimulus example from the furniture domain.
Three groups performed the task in different
conditions, namely: ??FaultCritical?, where
half the subjects in the ?+FaultCritical? case
could use location (?in the top left corner?). The
?+FaultCritical? group was told: ?Our program
will eventually be used in situations where it is
crucial that it understands descriptions accurately.
In these situations, there will often be no option to
correct mistakes. Therefore, (...) you will not get
the chance to revise (your description)?. By con-
trast, the ??FaultCritical? subjects were given
the opportunity to revise their description should
the system have got it wrong. Subjects in the
??Location? condition were told that their inter-
locutor could see exactly the same pictures as they
could, but these had been jumbled up; by con-
trast, ?+Location? subjects were led to believe
that their addressee could see the pictures in ex-
actly the same position.
The second main challenge was to create tri-
als that would distinguish between all the algo-
rithms. For instance, if trials involved only one at-
tribute, say an object?s TYPE (e.g., chair or table),
they would not allow us to distinguish IA from
FB, as both would always generate the shortest de-
scription. Subtler issues arise with local brevity
(Reiter, 1990), an optimisation strategy which re-
quires sufficiently complex trials to make a differ-
ence.
3 How to analyse the data?
Our semantically transparent corpus can be
used for testing various hypotheses, for in-
stance about when an algorithm should
overspecify descriptions (e.g. more in
?+FaultCritical,+Location? (Arts, 2004),
and/or when the target is a set). Here, we focus on
the issue raised in Section 1, namely, which of the
algorithms discussed in Dale and Reiter (1995)
matches human behaviour best.
The first problem is determining the relevant al-
gorithms. The IA comes in different flavours, be-
cause its output depends on the order in which
the different properties are attempted (commonly
called the preference order). It is possible to
consider all different IAs (trying every conceiv-
able preference order), but this would increase the
number of statistical hypotheses to be tested, im-
pacting the validity of the results and requiring a
Bonferroni correction. Instead, we are using a pre-
test to find the optimal version of IA, comparing
only that version to the other algorithms.
The second question is how to assess algorithm
performance. Since our production experiment
does not yield a single gold standard (GS), an al-
gorithm might match subjects better in one con-
dition (e.g. ?+FaultCritical), or perform bet-
ter in one domain (e.g. furniture). Moreover, it
might match subjects poorly overall due to sam-
ple variation, while evincing a perfect match with
a single individual. Using both a by-subjects and a
by-items analysis will partially control for sample
131
dispersion.
How should we calculate the match between an
algorithm and a GS? Once again, there are two
facets to this problem. Since we are focusing on
Content Determination, each human description
could be viewed as associating, with the relevant
trial, a set of properties. Our approach will be to
annotate each human description with the set of at-
tributes it contains. However, the real data is often
messy. For example, when one subject called an
object ?the non-coloured table?, and another called
it ?the grey desk?, both may be expressing the same
attributes (i.e. TYPE and COLOUR). Also, while it
is often assumed that the output of GRE is a def-
inite noun phrase, this is not always the case in
our corpus, which contains indefinite distinguish-
ing descriptions such as ?a red chair, facing to
the right?, and telegraphic messages such as ?red,
right-facing?.
The second aspect to the problem concerns the
actual human-algorithm comparison. Suppose the
GS equals the output of one subject, and we are
comparing two algorithms, x and y. Suppose our
subject produced ?the two huge red sofas?, which
the GS associates with the set {sofa, red, large}.
Suppose our algorithms describe the target as:
Output from x : {sofa, red, top}
Output from y : {sofa, red, large, top}
Which of these algorithms matches the GS best?
Algorithm y adds a property (perhaps overspecify-
ing even more than the GS). Algorithm x has the
same length as the GS, but replaces one property
by another. Several reasonable ways of assess-
ing the differences can be devised, one of which is
Levenshtein distance (which suggests preferring y
over x, since the latter involves a deletion and an
addition) (Levenshtein, 1966). We also intend to
examine how often the GS over- or underspecifies
where the algorithm does not.
4 Conclusion
Corpora can be an invaluable resource for NLG
as long as the necessary contextual information
and the conditions under which the texts in a cor-
pus were produced are known. We believe that
controlled and balanced experiments are needed
for building semantically transparent resources,
whose construction we have discussed. As shown
in this paper, evaluation of algorithms against the
number of gold standards obtained with such a
corpus needs careful consideration.
Evaluation of GRE ? and NLG systems more
generally ? would benefit from more investiga-
tion of the differences between readers and pro-
ducers. In future work, we intend to follow up
with a reader-oriented experiment in which we test
the speed and/or accuracy with which the output
of different GRE algorithms is understood by sub-
jects. The dependent variables here will be non-
linguistic (perhaps involving subjects clicking on
pictures of presumed target referents). This illus-
trates a more general issue in this area, namely
that corpora should, in our view, only be a start-
ing point, with which data of different kinds can
be associated.
5 Acknowledgments
Thanks to Ehud Reiter, Richard Power
and Emiel Krahmer for useful comments.
This work is part of the TUNA project
(http://www.csd.abdn.ac.uk/
research/tuna/), funded by the EPSRC
in the UK (GR/S13330/01).
References
[Arts2004] A. Arts. 2004. Overspecification in Instruc-
tive Texts. Ph.D. thesis, Tilburg University.
[Dale and Reiter1995] R. Dale and E. Reiter. 1995.
Computational interpretations of the Gricean max-
ims in the generation of referring expressions. Cog-
nitive Science, 18:233?263.
[van Deemter2002] K. van Deemter. 2002. Generat-
ing referring expressions: Boolean extensions of the
incremental algorithm. Computational Linguistics,
28(1):37?52.
[Gupta and Stent2005] S. Gupta and A. J. Stent. 2005.
Automatic evaluation of referring expression gener-
ation using corpora. In Proceedings of the 1st Work-
shop on Using Corpora in NLG, Birmingham, UK.
[Jordan and Walker2000] P. Jordan and M. Walker.
2000. Learning attribute selections for non-
pronominal expressions. In Proceedings of the 38th
Annual Meeting of the Association for Computa-
tional Linguistics.
[Levenshtein1966] V. Levenshtein. 1966. Binary codes
capable of correcting deletions, insertions and rever-
sals. Soviet Physics Doklady, 10(8):707?710.
[Reiter1990] E. Reiter. 1990. The computational com-
plexity of avoiding conversational implicatures. In
Proceedings of the 28th ACL Meeting, pages 97?
104. MIT Press.
132
Proceedings of the 12th European Workshop on Natural Language Generation, pages 98?101,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
A Hearer-oriented Evaluation of Referring Expression Generation ?
Imtiaz H. Khan, Kees van Deemter, Graeme Ritchie, Albert Gatt, Alexandra A. Cleland
University of Aberdeen, Aberdeen, Scotland, United Kingdom
{i.h.khan,k.vdeemter,g.ritchie,a.gatt,a.cleland}@abdn.ac.uk
Abstract
This paper discusses the evaluation of a
Generation of Referring Expressions algo-
rithm that takes structural ambiguity into
account. We describe an ongoing study
with human readers.
1 Introduction
In recent years, the NLG community has seen a
substantial number of studies to evaluate Gener-
ation of Referring Expressions (GRE) algorithms,
but it is still far from clear what would constitute
an optimal evaluation method. Two limitations
stand out in the bulk of existing work. Firstly,
most existing evaluations are essentially speaker-
oriented, focussing on the degree of ?human-
likeness? of the generated descriptions, disre-
garding their effectiveness (e.g. Mellish and Dale
(1998), Gupta and Stent (2005), van Deemter et al
(2006), Belz and Kilgarriff (2006), Belz and Re-
iter (2006), Paris et al (2006), Viethen and Dale
(2006), Gatt and Belz (2008)). The limited num-
ber of exceptions to this rule indicate that the dif-
ferences between the two approaches to evaluation
can be substantial (Gatt and Belz, 2008). Sec-
ondly, most evaluations have focussed on the se-
mantic content of the generated descriptions, as
produced by the Content Determination stage of
a GRE algorithm; this means that linguistic re-
alisation (i.e. the choice of words and linguistic
constructions) is usually not addressed (exceptions
are: Stone and Webber (1998), Krahmer and The-
une (2002), Siddharthan and Copestake (2004)).
Our aim is to build GRE algorithms that produce
referring expressions that are of optimal benefit to
a hearer. That is, we are interested in generating
descriptions that are easy to read and understand.
But the readability and intelligibility of a descrip-
tion can crucially depend on the way in which it is
? This work is supported by a University of Aberdeen
Sixth Century Studentship, and EPSRC grant EP/E011764/1.
worded. This happens particularly when there is
potential for misunderstanding, as can happen in
the case of attachment and scope ambiguities.
Suppose, for example, one wants to make it
clear that all radical students and all radical teach-
ers are in agreement with a certain idea. It might
be risky to express this as ?the radical students and
teachers are agreed?, since the reader1 might be
inclined to interpret this as pertaining to all teach-
ers rather than only the radical ones. For this rea-
son, a GRE program might opt for the longer noun
phrase ?the radical students and the radical teach-
ers?. But because this expression is lengthier, the
choice involves a compromise between compre-
hensibiliity and brevity, a special case of a diffi-
cult trade-off that is typical of generation as well
as interpretation of language (van Deemter, 2004).
We previously reported the design of an algo-
rithm (based on an earlier work on expressions re-
ferring to sets (Gatt, 2007)), which was derived
from experiments in which readers were asked to
express their preference between different descrip-
tions and to respond to instructions which used a
variety of phrasings (Khan et al, 2008). Here we
discuss the issues that arise when such an algo-
rithm is evaluated in terms of its benefits for read-
ers.
2 Summary of the algorithm
In order to study specific data, we have focussed
on the construction illustrated in Section 1 above:
potentially ambiguous Noun Phrases of the gen-
eral form the Adj Nouni and Nounj . For such
phrases, there are potentially two interpretations:
wide scope (Adj modifies both Nouni and Nounj)
or narrow scope (Adj modifies Nouni but not
Nounj).
Our algorithm starts from an unambiguous set-
theoretic formula over lexical items (i.e. words
1In this paper, we use the word reader and hearer inter-
changeably.
98
have already been chosen), and thus has to choose
between a number of different realisations. The
possible phrasings for the wide scope meaning are:
(1) the Adj Noun1 and Noun2, (2) the Adj Noun2
and Noun1, (3) the Adj Noun1 and the Adj Noun2,
and (4) the Adj Noun2 and the Adj Noun1. For nar-
row scope, the possibilities are: (1) the Adj Noun1
and Noun2, (2) the Noun2 and Adj Noun1, (3) the
Adj Noun1 and the Noun2, and (4) the Noun2 and
the Adj Noun1. For our purposes, (1) and (2) are
designated as ?brief?, (3) and (4) as ?non-brief?
(that is, ?brevity? has a specialised sense involv-
ing the presence/absence of ?the? and possibly Adj
before the second Noun). Importantly, the ?non-
brief? expressions are syntactically unambiguous,
but the ?brief? NPs are potentially ambiguous, and
hence are the focus of attention in this work.
Our algorithm is based on certain specific hy-
potheses (from the earlier experiments) which
make crucial use of corpus data concerning the
frequency of two types of collocations: the col-
location between an adjective and a noun, and the
collocation between two nouns. At a broader level,
we hypothesise: the most likely reading of an NP
can be predicted using corpus data (Word Sketches
(Kilgarriff, 2003)). The more specific hypotheses
derive from earlier work by Kilgarriff (2003) and
Chantree et al (2006), and were further developed
and tested in our previous experiments. The cen-
tral idea is that this statistical information can be
used to predict a ?most likely? scoping (and hence
interpretation) for the adjective in the ?brief? (i.e.
potentially ambiguous) NPs. We define an NP to
be predictable if our model predicts a single read-
ing for it; otherwise it is unpredictable. Hence, all
?non-brief? NPs are predictable (being unambigu-
ous), but only some of the ?brief? ones are pre-
dictable.
In a nutshell, the model underlying our algo-
rithm prefers predictable expressions to unpre-
dictable ones, but if several of the expressions are
predictable then brief expressions are preferred
over non-brief.
3 Aims of the study
We want to find out whether our generator
makes the best possible choices (for hearers) from
amongst the different ways in which a given de-
scription can be realised. But although our al-
gorithm uses sophisticated strategies for avoiding
noun phrases that it believes to be liable to mis-
understanding, misunderstandings cannot be ruled
out, and if a hearer misunderstands a noun phrase
then secondary aspects such as reading (and/or
comprehension) speed are of little consequence.
We therefore plan first to find out the likelihood of
misunderstanding. For this reason, we will report
on the degree of accuracy, as a percentage of times
that a participant?s understanding of an expression
that we label as predictable fails to match the in-
terpretation assigned by our model. Additionally,
we shall statistically test two hypotheses:
Comprehension Accuracy 1: Predictable ex-
pressions are more often interpreted in
agreement than in disagreement with the
model.
Comprehension Accuracy 2: There is more
agreement among participants on the inter-
pretation of predictable expressions than of
unpredictable expressions.
We will not only test the comprehensibility of the
expressions generated by our algorithm, but their
readability and intelligibility as well. This is nec-
essary because the experiments which led to the
algorithm design considered only certain aspects
of the hearer?s reaction to NPs (e.g. metalinguistic
judgements about a participant?s preferences) and
we wish to check these comprehensibility/brevity
facets from a different, perhaps psycholinguisti-
cally more valid, perspective. It is also necessary
because avoidance of misunderstandings is not the
only decisive factor: if several of the expressions
are predictable then our algorithm chooses be-
tween them by preferring brevity. But why is brief
better than non-brief? Taking readability and intel-
ligibility together as ?processing speed?, our third
hypothesis is:
Processing speed: Subjects process
predictable brief expressions more
quickly than predictable non-brief ones.
Confirmation of this hypothesis would be a strong
indication that our algorithm is on the right track,
particularly if the degree of accuracy (see above)
turns out to be high. Processing speed is a com-
plex concept, but we could decompose it as ?read-
ing speed? and ?comprehension speed?, permitting
us to examine reading and comprehension sepa-
rately. We intend to see what evidence there is for
the following additional propositions, which will
be tested solely to aid our understanding.
99
Reading Speed:
RS1: Subjects read predictable brief NPs more
quickly than unpredictable brief ones.
RS2: Subjects read unpredictable brief NPs more
quickly than predictable non-brief ones.
RS3: Subjects read predictable brief NPs more
quickly than predictable non-brief ones.
Comprehension Speed:
CS1: Subjects comprehend predictable brief NPs
more quickly than unpredictable brief ones.
CS2: Subjects comprehend predictable non-brief
NPs more quickly than unpredictable brief ones.
CS3: Subjects do not comprehend predictable
non-brief NPs more quickly than predictable brief
ones.
(Remember that, in our restricted set of NPs, a
phrase cannot be both ?unpredictable? and ?non-
brief?.) Rejection of any of these statements will
not count against our algorithm.
4 Sketch of experimental procedure
Participants will be presented with a sequence of
trials (on a computer screen), each of which con-
sists of a lead-in sentence followed by a target sen-
tence and a comprehension question that relates to
the two sentences together. The target sentence
might for example say ?the radical students and
teachers were waving their hands?. The compre-
hension question in this case could be ?Were the
moderate teachers waving their hands??. As both
the target sentence and the comprehension ques-
tion make use of definite NPs (e.g. ?the moderate
teachers?), it is necessary to ensure any presuppo-
sitions about the existence of the referent set are
met, without biasing the answer. For this reason,
the target sentence is preceded by a lead-in sen-
tence to establish the existence of the sets within
the discourse (here, ?there were radical and mod-
erate people in a rally?).
Given this set-up we are confident that we
can identify, from a participant?s yes/no answer,
whether the NP in the target sentence was assigned
a narrow-scope or a wide-scope reading for the ad-
jective. The computer will record the participant?s
response as well as the length of time that the par-
ticipant took to answer the question. We will use
Linger2 for presentation of stimuli. Pilots sug-
gest that the complexity of the trials makes it ad-
visable to use masked sentence-based self-paced
2http://tedlab.mit.edu/?dr/Linger/
reading, in which every press of the space bar re-
veals the next sentence and the previous sentence
is replaced by dashes.
The choice of nouns and adjectives (to construct
NPs) is motivated by the fact that there is a bal-
anced distribution of NPs in each of the follow-
ing three classes. Wide scope class is the one for
which our model predicts a wide-scope reading;
narrow scope class is the one for which our model
predicts a narrow-scope reading; and ambiguous
class is the one for which our model fails to pre-
dict a single reading (Khan et al, 2008).
5 Issues emerging from this study
The design of this experiment raised some difficult
questions, some quite unexpected:
1. The quality of the output of a generation al-
gorithm might appear to be a simple and well-
understood concept. However, output quality is
multi-faceted, because an expression may be easy
to read but difficult to process semantically, or the
other way round. A thorough output evaluation
should address both aspects of quality, in our view.
2. If both reading and understanding are ad-
dressed, this raises the question of how these
two dimensions should be traded off against each
other. If one algorithm?s output was read more
quickly than that of another, but understood more
slowly than the second, which of the two should be
preferred? Perhaps there is a legitimate role here
for metalinguistic judgments after all, in which
participants are asked to express their preference
between expressions (see Paraboni et al (2006) for
discussion)? An alternative point of view is that
these questions are impossible to answer indepen-
dent of a realistic setting in which participants ut-
ter sentences with a concrete communicative pur-
pose in mind. If utterances were made in order to
accomplish a concrete task (e.g., to win a game)
then task-based evaluation would be possible.
3. Even though this paper has not focussed on de-
tails of experimental design and analysis, one diffi-
culty is worth mentioning: given the grammatical
options between which the generator is choosing,
only three types of situations are represented: a de-
scription can be brief and predictable (e.g. using
?the old men and women? to convey wide scope,
since the adjective is predicted by our algorithm
to have wide scope), brief and unpredictable (e.g.
?the rowing boats and ships? for wide scope, given
100
a prediction of narrow scope), or non-brief and
predictable (e.g. ?the old men and the old women?
for wide scope). It might appear that there exists
a fourth option: non-brief and unpredictable. But
this is ruled out by our technical sense of ?non-
brief?: as noted earlier, ?non-brief? NPs do not
have the scope ambiguity. Because of this ?miss-
ing cell?, it will not be possible to analyse our data
using an ANOVA test, which would have automat-
ically taken care of all possible interactions be-
tween comprehensibility and brevity. A number
of different tests will be used instead, with Bon-
ferroni corrections where necessary.
6 Conclusion
Human-based evaluation is gaining considerable
popularity in the NLG community. Whereas eval-
uation of GRE has mostly been speaker-oriented,
the present paper has explored a plan for an ex-
perimental hearer-oriented evaluation. The main
conclusion is that hearer-based evaluation is diffi-
cult because the quality of a generated expression
can be measured in different ways, whose results
cannot be assumed to match. One factor we have
not examined is the notion of fluency: it is possible
that our algorithm will sometimes choose a word
order (e.g. ?the women and old men?) that is rela-
tively infrequent, and therefore lacking in fluency.
Such situations might lead to longer reading times.
References
A. Belz and A. Kilgarriff. 2006. Shared-task evalu-
ations in HLT: Lessons for NLG. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation, pages 133?135.
A. Belz and E. Reiter. 2006. Comparing automatic
and human evaluation of NLG systems. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 313?320, Trento, Italy, 3-7 April.
F. Chantree, B. Nuseibeh, A. de Roeck, and A. Willis.
2006. Identifying nocuous ambiguities in require-
ments specifications. In Proceedings of 14th IEEE
International Requirements Engineering conference
(RE?06), Minneapolis/St. Paul, Minnesota, U.S.A.
A. Gatt and A. Belz. 2008. Attribute selection for re-
ferring expression generation: New algorithms and
evaluation methods. In Proceedings of the 5th Inter-
national Conference on NLG.
A. Gatt. 2007. Generating Coherent References to
Multiple Entities. Ph.D. thesis, University of Ab-
erdeen, Aberdeen, Scotland.
S. Gupta and A. Stent. 2005. Automatic evaluation
of referring expression generation using corpora. In
Proceedings of the Workshop on Using Corpora for
Natural Language Generation, pages 1?6.
I. H. Khan, K. van Deemter, and G. Ritchie. 2008.
Generation of referring expressions: Managing
structural ambiguities. In Proceedings of the 22nd
International Conference on Computational Lin-
guistics (COLING-8), pages 433?440, Manchester.
A. Kilgarriff. 2003. Thesauruses for natural language
processing. In Proceedings of NLP-KE, pages 5?13,
Beijing, China.
E. Krahmer and M. Theune. 2002. Efficient context-
sensitive generation of referring expressions. In
K. van Deemter and R. Kibble, editors, Information
Sharing: Reference and Presupposition in Language
Generation and Interpretation, CSLI Publications,
pages 223?264.
C. Mellish and R. Dale. 1998. Evaluation in the
context of natural language generation. Computer
Speech and Language, 12(4):349?373.
I. Paraboni, J. Masthoff, and K. van Deemter. 2006.
Overspecified reference in hierarchical domain:
measuring the benefits for readers. In Proceedings
of the Fourth International Conference on Natural
Language Generation(INLG), pages 55?62.
C. Paris, N. Colineau, and R. Wilkinson. 2006. Eval-
uations of NLG systems: Common corpus and tasks
or common dimensions and metrics? In Proceed-
ings of the 4th International Conference on Natural
Language Generation, pages 127?129.
A. Siddharthan and A. Copestake. 2004. Generating
referring expressions in open domains. In Proceed-
ings of the 42nd Meeting of the Association for Com-
putational Linguistics Annual Conference (ACL-04).
M. Stone and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics. In
Proceedings of the Ninth International Workshop on
Natural Language Generation, pages 178?187, New
Brunswick, New Jersey.
K. van Deemter, I. van der Sluis, and A. Gatt. 2006.
Building a semantically transparent corpus for the
generation of referring expressions. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation, pages 130?132.
K. van Deemter. 2004. Towards a probabilistic version
of bidirectional OT syntax and semantics. Journal
of Semantics, 21(3):251?281.
J. Viethen and R. Dale. 2006. Towards the evaluation
of referring expression generation. In Proceedings
of the 4th Australasian Language Technology Work-
shop, pages 115?122, Sydney, Australia.
101
Proceedings of the 12th European Workshop on Natural Language Generation, pages 154?161,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
What Game Theory can do for NLG: the case of vague language
Kees van Deemter
University of Aberdeen
k.vdeemter@abdn.ac.uk
Abstract
This informal position paper brings to-
gether some recent developments in for-
mal semantics and pragmatics to argue
that the discipline of Game Theory is well
placed to become the theoretical back-
bone of Natural Language Generation. To
demonstrate some of the strengths and
weaknesses of the Game-Theoretical ap-
proach, we focus on the utility of vague
expressions. More specifically, we ask
what light Game Theory can shed on the
question when an NLG system should
generate vague language.
1 NLG as a choice problem
Natural Language Generation (NLG) is the area
of computational linguistics that is concerned with
the mapping from non-linguistic to linguistic ex-
pressions (e.g. Reiter and Dale 2000). This formu-
lation might be taken to suggest that NLG is best
viewed as a kind of translation problem, where the
challenge is to find a way to convert a formal ex-
pression into (for example) an English one. In its
early years, this may have been a fruitful way to
think about NLG but, these days, a better perspec-
tive is of NLG as a choice problem. For after the
advances of recent years, the problem is no longer
such much ?How on Earth can this information be
expressed in English??, but rather ?From all the
possible ways to express this information in En-
glish, which one is the most effective choice??
Let us try to say this a bit more precisely. It is
usually fair to assume that the formal expressions
from which NLG takes its departure are them-
selves clear and unambiguous. Let us call the
inputs to the generator Meanings. Now suppose
we have a grammar that tells us how each given
Meaning can be expressed in a language such as
English. The task for NLG now is to choose, for
each of these Meanings, which of all the different
linguistic Forms that can express it (according to
the grammar) is the best expression of this partic-
ular Meaning. Ultimately, this choice is likely to
depend on a number of other parameters, such as
the identity of the hearer, and the words that have
earlier been used. In the present paper, these ?con-
textual? issues will largely be ignored, allowing us
to simplify by thinking in terms of a mapping from
Meanings to Forms.
The perspective that views NLG as a choice
problem is far from new (see e.g. McDonald
1987, where it takes a central position); in fact,
it forms the methodological spine of Systemic-
Functional Grammar, with its AND/OR graphs
(Bateman 1997). Given this perspective, the ques-
tion comes up what factors determine the choice
between different linguistic Forms. This question
is difficult to answer in detail, but at the most ab-
stract level, the answer is likely to have something
to do with the ?utility?of the different Forms that
can be generated, and perhaps such additional fac-
tors as the cost to the speaker of generating them,
and the cost to the hearer of processing (e.g., pars-
ing and interpreting) them. To utter a sentence is to
perform an action, and the choice between differ-
ent actions is naturally thought of as governed by
utility, understood in the broadest possible sense.
2 Game Theory
The analysis of NLG as driven by the utility of ut-
terances feels natural to people familiar with prac-
tical applications of NLG, where texts are gener-
ated for a real-life setting. More generally, this
type of analysis suits anyone who is interested in
the effects of an utterance on an audience (e.g.,
Mellish and Van der Sluis 2009). To see how
NLG systems could be amenable to a decision-
theoretical analysis, in which the expected pay-
offs associated with different texts are compared,
consider an NLG system that informs roadgrit-
154
ters? decisions about the condition of the roads
in Scotland, to help them decide which ones are
icy enough to require treatment (e.g. Turner et al
2008).
Computerised weather forecasts can tell road
gritters which roads are likely to be icey, and hence
dangerous. There can be thousands of dangerous
roads on a given night, and it is often impossible to
say in a few words exactly which road are danger-
ous (Turner et al 2008). One summary produced
by the generator might approximate the data by
saying ?Roads in the Highlands are icey? while an-
other might say ?Roads above 500 metres are icey?
(assume this covers a larger set of roads). It mat-
ters which of these summaries is generated, be-
cause each summary will lead to a different set of
roads being treated with salt (i.e., gritted). The
first summary may have 10 false positives (i.e.,
roads gritted unnecessarily) and 10 false negatives
(i.e., dangerous roads not gritted); the second sum-
mary might have 100 false positives and only 2
false negatives. In a situation of this kind, which
involves a tradeoff between safety on the one hand,
and money and environmental damage (from salt)
on the other, decision theory would be a natural
framework in which to compare the utility of the
two summaries. If a false positive has a negative
utility of ?0.1 and a false negative one of ?0.5,
for example, then the first summary wins the day.
(Needless to say, the choice of these constants is
crucial, and tricky to justify.)
More specifically, many NLG systems invite
a game-theoretical analysis ? or an Optimality-
Theoretic analysis, which can come down to the
same thing (Dekker and Van Rooij 2000; Van
Deemter 2004 for an application to NLG). Sup-
pose I want to state that all old people are entitled
to certain benefits (cf. Khan et al 2009):
a. Old men and old women are entitled
to benefits.
b. Old men and women are entitled to
benefits.
Which of these two linguistic Forms should I
choose? This depends on the strategy of the
hearer. If the hearer interprets (b) as concerning
all women (rather only the old ones) then my ut-
terance will have misfired to an extent. The suc-
cess (for speaker and/or hearer!) of the speaker?s
generation strategy, in other words, depends on the
hearer?s interpretation strategy.1
1For a game-theoretical perspective on the generation of
This interaction means that decision theory is
not the best tool for analysing the situation, for
whereever different agents? strategies interact, De-
cision Theory gives way to Game Theory. Game
Theory was conceived in the nineteen fourties
(Von Neumann and Morgenstern 1944) and has
since come to be used extensively by economists,
sociologists, biologists, and others. Far from be-
ing limited to games in a limited sense of the word,
Game Theory is the mathematical study of rational
social interaction and, as such, it is reasonable to
expect it to be able to shed light on language use as
well. Perhaps more than anything, it promises to
have the potential to explain why communication
works the way it does. For if we could show that
people?s linguistic behaviour conforms with what
it would be rational for them to do, then this would
have substantial explanatory value.
Work by David Lewis and other on communica-
tion and coordination games helped to make Game
Theory relevant for situations where the players
are not in conflict with each other (Lewis 1969).
A classic example is where two generals are both
intent on attacking an enemy, but while each gen-
eral individually is weaker than the enemy, they
can beat him if they attack at the same time. Com-
munication (?I am going to attack now!?) can help
the generals to cooperate and win the battle. Es-
sentially the same things happens when you try to
meet a friend: neither of you may care where and
when to meet, as long as the two of you end up in
the same place at the same time; communication,
of course, can help you achieve this goal.
Applications of Game Theory to language now
come in many flavours (see e.g. Klabunde 2009,
this conference). In this paper I want to engage
in a small case study: the expression of quanti-
tative information in English. More specifically,
I will focus on the fact that quantitative informa-
tion is often only communicated vaguely. When
a thermometer, for example, measures your body
temperature as 39.82 Celcius, your doctor might
express this by saying that your temperature is
?39.8 degrees?, but he might also round this off
even further, saying that it is ?approximately 40
degrees?. Even more vaguely, she might tell you
that you have ?a high fever?. Which of these lin-
guistic Forms is preferable, and why?
Questions of this kind have led to a lively dis-
referring expressions, where success depends on alignment
between hearer and speaker strategies, see Kibble 2003.
155
cussion among linguists, philosophers, and the-
oretical economists (Lipman 2000, 2006; De
Jaegher 2003; Van Rooij 2003), focussing on the
question under what circumstances vagueness can
lead to a higher utility than crispness. The ques-
tion is important for understanding human com-
munication, because vagueness plays such a cen-
tral role in it. Vague adjectives, for example,
are prevalent among the words first learned by
a typical infant (Peccei 1994) and many of their
subtleties are understood by children of only 24
months old (Ebeling and Gelman 1994). In my
opinion, the understanding of vagueness is equally
important for the NLG community, and particu-
larly for those of us who work on ?data to speech?
(Theune 2001) or ?data to text? (Reiter 2008) sys-
tems, where the expression of quantitative data
plays such a crucial role. For this reason, I have
chosen it as the topic of an informal case study on
the relevance of game theory for NLG.
3 Vagueness in situations of conflict
First, let us focus on a type of situations where it
is relatively easy to understand what the differen-
tial benefits of vagueness can be. We start by ex-
amining a game-theoretic study of a different phe-
nomenon: ambiguity.
3.1 The utility of ambiguity: Aragone`s and
Neeman
Like others who have discussed these issues, we
take vagueness to arise if an expression allows
borderline cases. The word ?tall?, for example,
is vague because in a typical context there can be
people who are difficult to categorise as either tall
or not tall: they are somewhat in between, one is
tempted to say. Ambiguity is something else. It
arises when an expression can be meant in a lim-
ited number of different ways. The word ?letter?,
for example, is ambiguous because it can refer to
one individual character or to the sort of mean-
ingful arrangement of characters that people once
used to communicate long distance. In 1994, two
game theorists asked whether a Game Theoreti-
cal explanation might be given for strategic use of
ambiguity (i.e., where ambiguity is used on pur-
pose), and they came up with the following answer
(Aragone`s and Neeman 1994).
Suppose two unscrupulous politicians position
themselves for an election. Not burdened with
any convictions, they are free to choose between
three different idiologies (left, right, center), de-
pending on what gives them the highest utility; ad-
ditionally, they can choose between two commit-
ment2 levels, chigh and clow, both representable as
real numbers with chigh > clow. Unfortunately,
Aragone`s and Neeman do not say what a commit-
ment level is, but one might think of a more and a
less extreme version of their chosen ideology.
What combination of an ideology and an com-
mitment level should each politician choose? This
depends on the electorate, of course. Suppose
there are three blocs of voters: V(left), V(right)
and V(center). A leftist voter prefers a leftist
politician, and preferably one with a high commit-
ment level. Confronted with a choice between two
rightwing politicians, our leftist voter will prefer
one with a low commitment. A rightwing voter be-
haves as the mirror-image of the leftist voter, while
the neutral voter is neutral between the two idiolo-
gies but, weary of ideology, she prefers low com-
mitment over high commitment. Commitment, in
other words, is only relevant for a choice between
politicians of the same ideology.
If this is the whole story then politicians will
choose an ideology and commitment level based
on their estimates of the numbers of voters in
each bloc, trying to maximise their expected pay-
off, formulated solely in terms of the likelihood of
winning the election. The task for Game Theory is
to work out what combination of strategies might
give both politicians the highest possible payoff,
for example in the sense that a policy change by
just one of the two politicans can never improve
his expected payoff.
But Aragone`s and Neeman?s model allows
politicians to look beyond the election, towards
their anticipated time in government. Surely, a
low commitment is easier to fulfil than a high
commitment, particularly in view of unforeseen
contingencies, so it is nicer to be elected on a
low-commitment platform that does not tie one?s
hands too much. To model this, Aragone`s and
Neeman formulate utility in a way that multi-
plies the probability of a politician?s winning the
elections with a constant that is negatively cor-
related to his commitment. Let Ui(I1, c1; I2, c2)
be the utility for politician i given that politician
1 chooses ideology I1 with commitment level c1,
2Aragone`s and Neeman call these ambiguity levels, but
since the relation with ambiguity is debatable we opt for a
more neutral term. Low commitment equals high ambiguity
and conversely.
156
while politician 2 chooses I2 with level c2. Fur-
thermore, Pi(I1, c1; I2, c2) represents the proba-
bility of i winning the elections given this same
constellation of choices. Let k ? chigh.
Utility formula: Ui(I1, c1; I2, c2) =
Pi(I1, c1; I2, c2)(k ? ci)
Under these assumptions one can show that a low
commitment level (i.e., clow) can sometimes give
a politician a slightly lower probability of winning
the elections (because his core voters will be less
inclined to vote for him), yet a higher overall util-
ity (because his time in office will be easier). For
details see Aragone`s and Neeman (1994).
3.2 The utility of vagueness
It is often thought that Aragone`s and Neeman?s
model demonstrates how ambiguity can be used
strategically, but that it fails to shed light on vague-
ness (e.g. De Jaegher 2003). I do not see, however,
how this view stands up to linguistic scrutiny. To
see why, let me construct what strikes me as a pos-
sible example.
Suppose the ideology in question ? a leftist, or
perhaps a populist one ? is to take away money
from the 10% of richest people and give it to the
10% poorest. Commitment level, in this case,
could be a way of making explicit what percent-
age of the top 10% to give away. One position
might assert that this has to be, say, 50% of their
income, while another position might put this fig-
ure at 5%. But if we identified high commitment
with the 50% position and low commitment with
the 5% position then none of the two commitment
levels would be ambiguous. To make one of them
ambiguous, we would need something like the fol-
lowing:
The ambiguous politicians? game:
? I: take money from the 10% of rich-
est people and divide it equally over the
10% poorest.
? c50: do I with 50% of the money of
each of the richest people.
? cambiguous: do I with either 5% or
50% of the money of each of the rich-
est people.
But this must be a simplification, for we are deal-
ing with a continuum: there is nothing to exclude
percentages in between 25% and 5%, for exam-
ple. It seems, therefore, perfectly possible to con-
struct a version of Aragone`s and Neeman?s game
? an even more plausible version, I believe ? that
hinges on vagueness. For example:
The vague politicians? game:
? I and c50: (as above).
? cvague: do I with a large portion of the
money of each of the richest people
Clearly, cvague involves vagueness, because ?a
large portion? admits borderline cases. In all im-
portant respects the vague politicians? game is
isomorphic to the ambiguous politicians? game:
fierce advocates of redistribution would favour c50
over cvague, for example, because the latter leaves
them uncertain over the amount of redistribution.
It is also plausible that politicians would prefer to
avoid a commitment as clear as c50, because fu-
ture contingencies might make it difficult for them
to honour this promise. In fact, one could ex-
tend the game with a second election, in which the
electorate could give their verdict on a politician?s
time in office, and to adapt the utility formula with
a third term which represents the probability of
winning that second election. Surely, the break-
ing of promises doesn?t do much for a politician?s
changes of being re-elected, and a precise promise
is easier to break than a vague one.
With help from Aragone`s and Neeman, we have
found a situation in which vagueness has a higher
utility than precision.3 It should be noted, how-
ever, that this model (and that of De Jaegher 2003
likewise) hinges on the fact that the interests of the
speaker and the hearer differ: what?s good for the
politician may be bad for his voters. NLG sys-
tems can be faced with similar asymmetries, for
example when an artificial doctor decides to keep
its predictions vague to avoid being contradicted
by the facts; a doctor who says ?These symptoms
will disappear fairly soon? is less likely to get
complaints than one who says ?These symptoms
will have disappeared by midnight next Sunday?.
Something similar holds for a roadgritting system
(like the one in Turner et al 2008), which might
easily face lawsuits if it gets things too evidently
wrong. Advertisements also come to mind, be-
3Another game with this property was described in De
Jaegher (2003), involving a more complex version of the
game of the two generals (section 2). De Jaegher?s game lets
one general tell the other about the preparedness of the en-
emy. The utility of vagueness hinges on a subtle asymmetry
between the generals, only one of whom will suffer if the en-
emy turns out to be prepared. Intriguing though it is, I find it
difficult to see how De Jaegher?s game is relevant to everyday
communication or NLG.
157
cause the interests of the advertiser may not coin-
cide with those of the customer. ? Examples where
vagueness can save money or face are plentiful,
yet one wonders whether vagueness can also be
advantageous in situations where it is one?s honest
aim to inform an audience as well as one can.
4 Vagueness when there is no conflict
So, let us investigate the advantages of vagueness
in situations that are typical for today?s NLG sys-
tems, where the system tries, unselfishly, to assist
a user to the best of its ability.
4.1 Lipman?s questions
The question why vagueness is used strategically
in situations where the interests of speakers and
hearers are essentially aligned was asked perhaps
most forcefully by the economist Barton Lipman.
First he did this in a brief response to an essay by
the famous game theorist Ariel Rubinstein (Lip-
man 2000), and later in a growing but still unfin-
ished discussion paper (Lipman 2006). Lipman
uses what we shall call an airport scenario, where
player 1 asks player 2 to go to the airport to pick
up an acquaintance of player 1. In its simplest
form, the scenario lets player 1 know the referent?s
height with full precision (assuming that such a
thing is possible), while player 2 carries a perfect
measuring device. There are two other people at
the airport, and it is assumed that heights are dis-
tributed uniformly between a maximum denoted
by 1 and a minimum denoted by 0. The payoff for
both players ? please note the symmetry! ? is 1
if player 2 successfully picks the referent, while it
is 0 if she fails (i.e., the first person she addresses
turns out to be someone else).
Lipman observes that, under these assumptions,
vagueness would be bad: why would player 2 say
?He is tall?, for example, if he can say ?He is
183.721cm?? By stating his acquaintance?s exact
height, player 1 will allow player 2 to identify this
person with almost complete certainty, given that
the chance of two people having the exact same
height is almost nil. Lipman also wonders what
would happen if only one predicate was available
to player 1. He proves that, under these assump-
tions, optimal communication arises if a word is
used in accordance with the following rule:
Say ?the tall person? if height(person) >
1/2, else say ?the short person?.
Lipman observes that this concept of ?tall? does
not involve vagueness, because the rule does not
allow any borderline cases: everyone is either tall
or short. In other words, no rationale for vague-
ness has yet been found.
Note that Lipman is not questioning that vague
utterances can be useful, which they evidently can
be (see e.g. Parikh 1994 for a convincing demon-
stration using a game-theoretic approach). He is
asking whether vague expressions can be more
useful than any non-vague expression.
4.2 Answering Lipman
First, let us consider a possible modification of
Lipman?s scenario. In this modified airport sce-
nario the speaker knows the heights of all three
people at the airport. Suddenly it becomes eas-
ier to understand why vagueness can be useful.
For suppose your acquaintance happens to be the
tallest person of the three. You can then identify
him as ?the tall guy?. Arguably, this is safer than
citing the person?s height in centimeters, because
?the tall guy? (meaning, in this case, the same as
tallest guy) does not require the players to make
any measurements: comparisons between heights
can often be made in an instant, and with more
confidence than absolute measurements. I dealt
with cases of this type in my paper on vague de-
scriptions (van Deemter 2006), where a generator
takes numerical height measurements to produce
noun phrases that involve gradable adjectives: ?the
tall guy?, ?the fastest one of the three heavy tor-
toises?. In cases like this, one can argue that
vagueness is only local, in the same way that am-
biguity can be merely local, for example when the
sentence as a whole allows one to disambiguate
an ambiguous word in it (e.g. when a pronoun
gets resolved or a lexical item disambiguated). In
the modified airport scenario, the noun phrase as
a whole (e.g., ?the tall guy?) allows no borderline
cases, so there is no global vagueness here.
Local vagueness is wide-spread and can make
use of different ?precisification? mechanisms.
When I say of a gymnastic exercise, for example,
that it is ?good for young and old?, for example,
then there is nothing vague about my description
of the people involved: I am using vague words
to say that this exercise is good for everyone, re-
gardless of age. Although local vagueness consti-
tutes some kind of answer to Lipman, most lin-
guists assume that globally vague utterances exist
158
as well (even when the interests of the speaker and
the hearer are aligned). Let us assume they are
right and continue to look for a rationale.
Secondly, it has been suggested that strategic
vagueness can arise from a desire to reduce the
?cost? of the utterances involved (e.g. Van Rooij
2003, Ja?ger 2008). One might amplify this idea
by arguing that vague words are part of a highly
efficient mechanism that makes their meaning de-
pendent on the context in which they are used.
The size constraints on ?a small elephant?, for ex-
ample, are very different from those on ?a small
mouse?; this suggests that vague words may not
only be efficient to use but also efficient to learn
(Van Deemter, in preparation). All this seems true
enough but, as an answer to the question ?Why
vagueness?? it does not stand up to Lipman-style
scrutiny. Let me explain why not.
Consider the earlier-mentioned doctor, who
measures your body temperature as 39.82 Celcius.
By stating that you have ?a high fever? (instead of
?thirty eight point eighty two degrees?) the doctor
is pruning away details that are of questionable rel-
evance in the situation at hand. But this does not
force him to use language that is vague: language
that allows borderline cases, in other words. He
could have achieved a similar economy by round-
ing, saying that your temperature is ?(about) forty
degrees?; in this way, he would have reduced in-
formation without being vague. The benefits of
information reduction can be modelled in a game
where communication informs action: if ?38.82
Celcius? and ?39 Celcius? are associated with the
same medical action (e.g., to take an aspirin) then
the fact that ?39 Celcius? is ?cheaper? to produce
and to process will tend to give this expression a
better utility than ?38.82 Celcius?. But informa-
tion reduction does not imply vagueness, so we are
back at square one: Why vagueness?
It might be thought that things change when un-
certainty is taken into account: a measurement of
39.82 Celcius is not as exact as it sounds, for ex-
ample, because errors are likely. The result of the
measurement is perhaps best conveyed by a nor-
mal distribution of which 39.82 is the mean value,
and such a complex curve is difficult to put in just
a few words. Still, the argument of the previous
paragraph continues to apply, because the curve
can be summarised without vagueness: the figure
of 38.82 Celcius is one such summary.
A third suggestion (e.g. Veltman 2002) is that
vague expressions such as ?high fever? do more
than just reduce the information obtained from a
measurement. The expression ?high fever? also
adds bias or evaluation to the raw data, namely
the information that the temperature in question is
worrisome. You do not need domain knowledge
to understand the medical implications: hearing
that something medical is ?high? tells you that you
should be worried.
Once again, this sounds like an excellent rea-
son for using vagueness, particularly in situations
where an understanding of the metric in question
cannot be taken for granted (such as oxygen sat-
uration, the metrics for which mean little to most
of us). Still, it is not evident that this justifies the
use of vagueness. If bias needs to be expressed,
then why not simply add it? Why not state the
exact temperature (or an approximation of it) and
say that this reading should be considered worri-
some? One might respond that this would have
been time and space consuming, but if that is a
problem then why have no conventions arisen for
expressing quantities in two ways, a worrisome
and a non-worrisome one? Why should bias nec-
essarily be coupled with vagueness only, given
that it is as easy to think of a crisp expression that
contains bias as it is to think of a vague expression
that does not (e.g., in the case of an adjective like
?tall?)? A good example of crispness + bias is the
word ?obese?, in the sense of having a Body Mass
Index of over 30. For the reason why obesity was
defined in this way is precisely that this degree of
overweight is considered medically worrisome.
5 Discussion: vagueness and game theory
5.1 Vagueness is harder to justify
than you think
Let us first summarise our findings about vague-
ness, some of which will be discussed more fully
in Van Deemter (in preparation).
It is often easy to see why vague words come in
handy; the modified airport scenario demonstrates
how vague words can create an information loss
that is only local: by making a vague word part
of a referring expression, a crisp borderline is en-
forced on a vague concept, resulting in a beauti-
fully efficient description (e.g., ?the tall guy?) that
is arguably clearer than any expression that relies
on absolute values. This means that the utterance
as a whole is not vague at all: it is only locally
vague. Whether we speak of vagueness in such
159
situations seems a matter of taste.
It is also clear why vagueness can have differ-
ential benefits in communication between agents
whose interests differ more than just minimally
(cf., Horton and Keysar 1996 for experimental ev-
idence of speaker?s laziness in situations where
their interests are approximately aligned), such as
a politician and his potential voters, or like a pro-
fessional who does not wish to be sued by his
clients. In situations of this kind it can be benefi-
cial for a speaker or an NLG system to obfuscate,
exploiting the borderline cases inherent in vague
expressions.
Beyond this, it is suprisingly difficult to see how
vagueness can be advantageous for NLG. This is
partly because there appear to exist some linguistic
issues that NLG researchers are able to disregard.
It seems plausible, for example, that vagueness is
unavoidable in situations where no commonly un-
derstood metrics are available, for instance when
we judge how beautiful a sunset is, how wise a per-
son, or how dismal the weather. As long as NLG
systems use tangible input data (about millimetres
rainfall, for example, or body temperature), these
reasons for vagueness seem irrelevant. Similarly,
there is much that is unknown about the working
of perception even in simple domains. What is it
that allows me to talk about the height of someone
I see, for example? The input to my personal ?gen-
erator? (as opposed to the input to a typical NLG
system) might not be equivalent to a tidy number.
(Could it be some inherently vague percept, per-
haps?) These difficult questions (see also Lipman
2006) must remain unanswered here.
5.2 The utility of utility
Confronted with the claim that Game Theory
should be the theoretical backbone to NLG, some
people might respond that no new backbone is
needed, because the theory of formal languages,
conjoined with a properly expressive variant of
Symbolic Logic, provides sufficient backbone al-
ready. I believe this objection to be misguided.
Admittedly, the disciplines in question are well
suited for saying which Forms can express which
Meanings. But it is far less clear that these disci-
plines have anything to say about the key problem
of NLG: how to choose the most effective way to
express a given Meaning in (for example) English.
This is a vacancy that Game Theory would be well
placed to fulfill, in my opinion. The present paper
has illustrated this claim by discussing the ques-
tion when and why a generator should choose a
vague expression. The fact that this discussion has
yet to produce a clear conclusion is, in my opin-
ion, not due to any shortcomings of Game Theory,
but to the intrinsic difficulty of the problem.
There is, of course, a caveat. The use of game
theory in empirical sciences has, with proper mod-
estly, been described as ?modelling by example?
(e.g. Rasmussen 2001): a mathematical game
shows us an example of how things might be, not
necessarily how things are. The situation is famil-
iar to linguists, of course, and from applications
of mathematics more generally. By inspecting a
formal grammar, for example, one does not learn
much about language, unless there exists evidence
that the lingistic Forms and Meanings pair up as
specified by the grammar. In similar fashion, one
learns little from a Game Theoretical model un-
less one has reason to accept the assumptions that
were built into it: the choices that it assumes avail-
able to the players, and the payoffs related to each
outcome of the game, for example. This means
that Game Theory can come to the aid of linguis-
tic pragmatics and NLG, but that only empirical
research can tell us what games people actually
play when they communicate.
Acknowledgments
Thanks are due to my colleagues Ehud Reiter, Al-
bert Gatt and Hans van Ditmarsch, for useful dis-
cussions on the theme of this paper. Funding from
the EPSRC under the Platform Grant ?Affecting
People with Natural Language? (EP/E011764/1) is
gratefully acknowledged.
References
Aragone`s and Neeman 2000. Enriqueta Aragone`s
and Zvika Neeman. Strategic ambiguity in elec-
toral competition. Journal of Theoretical Politics
12, pp.183-204.
Bateman 1997. John Bateman. Sentence gen-
eration and systemic grammar: an introduction.
Iwanami Lecture Series: Language Sciences.
Iwanami Shoten Publishers, Tokyo.
de Jaegher 2003. Kris de Jaegher. A game-
theoretical rationale for vagueness. Linguistics
and Philosophy 26: pp.637-659.
Dekker and Van Rooij 2000. Bi-directional Op-
timality Theory: an application of Game Theory.
160
Journal of Semantics 17: 217-242.
Ebeling and Gelman 1994. K.S.Ebeling and
S.A.Gelman. Children?s use of context in inter-
preting ?big? and ?little?. Child Development 65
(4): 1178-1192.
Horton and Keysar 1996. William S. Horton and
Boaz Keysar. When do speakers take into account
common ground? Cognition 59, pp.91-117.
Ja?ger 2008. Gerhard Ja?ger. Applications of Game
Theory in Linguistics. Language and Linguistics
Compass 2/3.
Khan et al2009. Imtiaz Khan, Kees van Deemter,
Graeme Ritchie, Albert Gatt, and Alexandra
A.Cleland. A hearer oriented evaluation of refer-
ring expression generation. Proc. of 12th Euro-
pean Workshop on Natural Language Generation
(ENLG-2009).
Kibble 2003. Rodger Kibble. Both sides now:
predictive reference resolution in generation and
resolution. Proc. of Fifth International Work-
shop on Computational Semantics (IWCS-2003).
Tilburg, The Netherlands.
Klabunde 2009. Ralph Klabunde. Towards a
game-theoretic approach to content determination.
Proc. of 12th European Workshop on Natural Lan-
guage Generation (ENLG-2009).
Lewis 1969. David Lewis. Convention ? A Philo-
sophical Study. Harvard University Press.
Lipman 2000. Barton L.Lipman. Economics
and Language. ?Comments? section, Rubinstein
(2000).
Lipman 2006. Barton L.Lipman. Why is language
vague? Working paper, December 2006, Depart-
ment of Economics, Boston University.
McDonald 1987. Natural Language Generation.
In S.Shapiro Encyclopaedia of Artificial Intelli-
gence, Volume 1. John Wiley, New York.
Mellish and Van der Sluis 2009. Chris Mellish
and Ielka van der Sluis. Towards empirical evalua-
tion of affective tactical NLG. Proc. of 12th Euro-
pean Workshop on Natural Language Generation
(ENLG-2009)
Von Neumann and Morgenstern 1944. John von
Neumann and Oskar Morgenstern. Theory of
games and economic behavior. Wiley & Sons,
Princeton, New Jersey.
Parikh 1994. Rohit Parikh. Vagueness and utility:
the semantics of common nouns. Linguistics and
Philosophy 17: 521-535.
Peccei 1994. Jean Stilwell Peccei. Child Lan-
guage. Routledge.
Rasmussen 2001. Eric Rasmussen. Games & In-
formation: an introduction to game theory. Third
Edition. Blackwell Publishing.
Reiter and Dale 2000. Ehud Reiter and Robert
Dale. Building natural language generation sys-
tems. Cambridge University Press. Cambridge.
Reiter 2007. Ehud Reiter. An architecture for
data-to-text systems. In Procs. of 11th Euro-
pean Workshop on Natural Language Generation
(ENLG-2007): pp.97-104.
Rubinstein 1998. Ariel Rubinstein. Modeling
Bounded Rationality. MIT Press, Cambridge
Mass.
Rubinstein 2000. Ariel Rubinstein. Economics
and Language: Five Essays. Cambridge Univer-
sity Press. Cambridge.
Theune et al 2001. M.Theune, E.Klabbers, J.R.
de Pijper and E.Krahmer. From data to speech a
general approach. Natural Languag Engineering
7 (1): 47-86.
Turner et al 2008. R.Turner, S.Sripada, E.Reiter
and I.P.Davy. Using spatial reference frames to
generate grounded textual summaries of georefer-
enced data. In Proceedings of INLG-2008. Salt
Fork, Ohio, USA.
Van Deemter 2004. Kees van Deemter. Towards
a probabilistic version of bidirectional OT syntax
and semantics. Journal of Semantics 21 (3).
Van Deemter 2006. Kees van Deemter. Gener-
ating referring expressions that involve gradable
properties. Computational Linguistics 32 (2).
Van Deemter (in preparation). Kees van Deemter.
Not Exactly: in Praise of Vagueness. To appear
with Oxford University Press.
Van Rooij 2003. Robert van Rooij. Being polite is
a handicap: towards a game theoretical analysis of
polite linguistic behavior. In Procs. of Theoretical
Aspects of Rationality and Knowledge (TARK-9),
Bloomington, Indiana.
Veltman 2002. Frank Veltman. Het verschil tussen
?vaag? en ?niet precies?. (The difference between
?vague? and ?not precise?.) Inaugural lecture. Vos-
siuspers, University of Amsterdam.
161
Authoring Multimedia Documents using WYSIWYM Editing 
Kees  van  Deemter  and  R ichard  Power  
Infbrmat ion Technology Research Inst i tute 
UIfiversity of Brighton, Brighton, UK, 
{Kees. van. Deemter, Richard. Power}@itri. brighton, ac. uk 
Abst ract  
(1) This paper outlines a future 'ideal' nmlti- 
media document authoring system that allows 
authors to speci\[y content and form of the docu- 
ment independently of each other and at a h igt~ 
level of abstraction; 
(2) It describes a working system that imple- 
ments a small but significant part of the flmc- 
tionality of such an ideal system, based on se- 
mantic modeling of tile pictures as well as the 
text of the docunmnt; and 
(3) It explains what needs to be done to bridge 
the gap between the implemented system and 
the ideal one. 
1 A Future  ~Ideal' Mu l t imed ia  
Document  Author ing  System 
A Document Authoring System is a tool that 
helps an author to writ(; docmnents. If the sys- 
tem supports tile authoring of documents that 
combine 'presentations' in diflb.rent media (text 
and images, for example), we will speak of a 
multimedia document authoring system. Ide- 
ally, a multimedia document authoring system 
would allow authors to speci(y the content and 
fbrm of a high-quality document in ways that 
are both simple and etiicient. More specifically, 
an ideal system would aftbrd the tbllowing op- 
tions to the author: 
1. Easy determination of content. ~Content' 
is taken to mean the factual (i.e., proposi- 
tional) content of the docmnent - in other 
words, the content of the Knowledge Base 
(KB) that forms the input to tilt document 
authoring system. 
2. Easy determination of style and layout. In 
the absence of specific instructions from the 
author, style and layout should be deter- 
mined using intelligent defimlts. (For ex- 
ample, tile standard settings may require 
tilt document o be infi)rmal, with avoid- 
ancc of technical terms, lists and footnotes, 
without nlaximum paragraph length, and 
with numbered sections.) Defaults can be 
overridden by the author, whereupon other 
defaults mw become relevant. 
3. Easy allocation oJ' media. As in the case 
of style and layout, the system has to use 
judiciously chosen de.faults: perhaps using 
illustrative pictures wherever suitable pic- 
turks are available, and graphs or tables 
wherever large amomlts of homogeneously 
structured quantitative information are in- 
volved. As above, defaults may be over- 
ruled by specific requests from the author; 
if a request is impossible to fifllfil, an appro- 
priate error message should tm generatc(t. 
4. Easy annotation of non-generated presen- 
tations. In some cases, it will be possible 
tbr the system to generate presentations. In
other cases, this mw be impossible: Liter- 
ally quoted texts, for example, or historic 
photogral)hs , m~y predate the use of the 
system, in which case it may be necessary 
to treat them as 'canned' and to annotate 
thenl to allow the system to make intelli- 
gent use of them. 
5. Easy post-editin.q. Once tile system has 
produced a document according to the 
specifications of the author, the ideal sys- 
tem would oiler tools to address remaining 
ilmdequacies using post-editing. 
'Easy' means efficient, protected against incon- 
sistencies, and not requiring specialist skills or 
knowledge. A domain specialist, - who may not 
know anything about knowledge representation, 
logic, or linguistics - could use such a system to 
222 
build KBS that l;he sysl;elll call turn into docu- 
menl;s in any desired bmguage using any desired 
(:olnbination of media. The 1)reduction and ut)- 
(b~ting of (;omplex documents would l)e greatly 
simplitied as a result. 
In present-day practice, these requirements end 
to be far from realized: authoring docuxnents by 
means of such l;oots as MS WORD or POWER,- 
POINT requires much low-level int;eraction, such 
as the typing of (:haracters (m a keyl)o;trd anti 
the dragging of figures from one plwsic~d lo- 
cal;ion t;o m~other. In SOllle cases, all h~telli- 
gent Mult, inledia l)resentation Systc, ln (IMMPS 
e.g., Bordegoni et al 1.997) can be used (see 
AIR 1995, Maybury and Wahlster 1998 for some 
surveys), which (nnploys techniques from Arti- 
ficial Intelligence to allow higher-lew~l intera('- 
l;ion. Present IMMI'S, howev(,r, meel; few of the 
\]'e(luirenmnl;s nenl;ioned al)ove. Most ()f l;hem, 
fi)r exmnl)le ~ require intmt ()t' a highly Sl)e(:ial- 
ize.d 11al;llre (e.g., the (;omt)lex logical fornm- 
las ent;ere(t in the wIP sysl;em, An(trd and II.isI; 
1995) 1 and l;hey allow an author little (:ontrol 
over the tbnn (e.g., layout, textual style, me(lia 
allocation) of the (loellnlenl;. The issue of easy 
amlol.ation (d) is never even ad(lress(',(t, to tim 
be, st of our knowledge. 
The, next section descril)es an iml)hnnented sys- 
tem tbr l;he authoring of teztual (lo(:uinents l,hal. 
can |)e ~rgue(l to fltllill requirements (1) and 
(2) and which tbrms n suitnbh: st~rtin g point 
for working towards the 'ideal' multimedia sys- 
l;e111 outlined above,. Section 3 des(:ril)es ~tll ex- 
tension of this system in which signiticallt as- 
1)ect;s of re(luireln('nt;s 3-5 h~we also been ilnl)le- 
menl;ed. Key features of l;his new sysl;em nre its 
ability to use .semantic 'repre.s'entatio'n.s l;hat are. 
common to the different media, and the abil- 
ity to construct natural language feedback texts 
to help the author understand the contenl; and 
the form of |;lie document while it is still raider 
eonsl;ruction. The concluding section exl)lains 
what needs to be done to till the gap |)el, ween 
the iml)lemenl;ed sysl;eln and |,tie ideal one. 
1An exception is AIA,Tes(:o whit:h takes natural lan- 
guage input~ requiring the system to interpret uncon- 
strained natural language (Stock 1991). Avoiding the 
need for doing this is an important design motivation 
for WYSlWYM-based syst;enis. 
2 A WYSIWYM-based  System tbr 
the  Author ing  o f  Textua l  
Documents  
Elsewhere (Power mid Scott 1998, Scott el; al. 
1998, Scott 1999), a new knowledge-editing 
1net;hod called ~WYSIWYM editing' has been in- 
troduced and motivated. WYSIWYM editing 
allows a domain expert to edit a knowledge 
base (KB) by inl;er~wl;ing with a .\[~edbaek ic.:rt,, 
generated by the system, which pl'esents both 
the knowledge, already defined and the options 
for exl;ending and modit~ying it. Knowledge is 
added or modified by return-based choices which 
directly Mti;et the knowledge base; the result is 
displayed to the author by means of an auto- 
matic~lly generated feedback text: thus ~What 
You See ls What You Meant'. WYSIWYM in- 
stant|ares a general recent trend in dialogue sys- 
l;ems |;owards moving some of the initiative from 
the user to the sysl;em, ~dlowing such systenls to 
avoid the (titli(;ulties of t)ro(;essing %t)cn ~ (i.e., 
tureens|rained) input. 
Of parti(:ular importance, here, m:e at)plieations 
of WYSIWYM to the generation of documents 
(:ont~dning text mid 1)ietures; the t)resent sec- 
tion tbcuses on (multilingual) tezt generation: 
l;he KB (:re~Lted with the help of WYSIWYM is 
used as input to a natural language generation 
(NLG) l)rogrmn, pro(hu:ing as output a docu- 
ment of some sort, for I;he benelit of ~m end 
user. Present apt)lications of WYSIWYM \[;o i;exl; 
generation use a KL-ONE-I,yl)e knowledge rep- 
resentation language as input to two NLG sys- 
\[;elliS. ()lie NLG sys|;elll generates tb.edback texts 
(for l;he raft;her) ml(t I;h(' other gener~d;es on|trot 
l;exi;s (for all ell(t l lser). Ol le at)plication cur-  
rent ly  under develotmmnl; has 1;11(; creation of 
Patient Informal;ion Leaflets (PILLS) aS its do- 
main. The present vt;rsion of this PILLs system 
allows authors to enter information about pos- 
sible side eft'cots ( ' i f  you are either pre.qnant o1" 
allergic to penicillin, then tell your doctor') and 
how to handle lnedical devices such as inhalers, 
inoculators, etc. By interacting with the feed- 
back texts generated by the system, the author 
can detine a procedure for perfornfing a task, 
e.g. preparing an inhaler for use. A llew KB 
leads to the creation of a procedure instance, 
e.g. p. The permanent part of the KB (i.e., 
the T-Box) spt, eifies l;haI; procedures ma, y be 
223 
complex or atomic, and lists a number of op- 
tions in both cases. In the atomic case, the op- 
tions include Clean, S tore ,  Remove, etc., and 
these are made visible by means of a metal from 
which tile author can select, say, Remove. Tile 
program responds by adding a new instance, of 
type Remove, to the KB: 
Remove(p) 
('There is a procedure p whose type is Remove.') 
th'om the updated knowledge base, the genera- 
for produces a feedback text 
Remove this device or device-part 
from this device or device-part,  
making use of the infbrmation, in the T-Box of 
the system, that Remove procedures require an 
Actee and a Source. Such not yet defined at- 
tributes are shown through mouse-sensitive an- 
chors. By clicking on all anchor, the author 
obtains a pop-up metal listing the pernfissible 
values of the attrilmte; by selecting one of these 
options, the author updates the knowledge base. 
Clicking on this device or device part yields 
a pop-up menu that lists all the types of devices 
and their parts that the systenl knows about, in- 
eluding a Cover (which, according to the T-Box 
must have a Device as Owner). By continuing 
to make choices at anchors, the author might 
expand the knowledge base in the tbllowing se- 
quence: 
? Remove a device's  cover from a device 
or device-part  
? Remove a device's  cover from an inhaler 
of a person 
? Remove a device's  cover from your inhaler 
? Remove your inhaler's cover from your in- 
haler 
At this point the knowledge base is potentially 
complete, so a (less stilted) outp'ut tczt can be 
generated and incorporated into the leaflet, e.g. 
Please remove the cover of your ill- 
haler. 
Longer output texts can be obtained by expand- 
ing the feedback text fitrther. A numl)er of 
proi)erties of the PILLS system are worth stress- 
ing. First, the system sut)ports a high-level di- 
alogue, allowing the author to disregard low- 
level details, such as the exact words used in the 
output text. This makes it possible to interact 
with the system using, say, French (provided a 
generator tbr French feedback texts is available), 
for the i)roduction of leatlets in Japanese (pro- 
vided a generator for Japanese output texts is 
available). The semantic model in the T-Box 
guarantees that many types of inconsistencies 
(e.g., a medicine that has to be taken both once 
and twice a day) are prevented. Second, a sire- 
ple version of WYSIWYM has also been applied 
to the tbrm of the text, allowing the author to 
specit) it separately from its content. This is 
done by allowing the author to use WYSIWYM 
tbr building a second, form-related KB which 
describes the st~.tlc and layo'ut of the docmnent. 
Th is  KB, for example, may state that the maxi- 
mum paragraph length is 10 sentences and that 
there are no tbotnotes. (A second, form-related 
T-Box deternfines what the options determining 
layout are.) This form-related KB constrains the 
texts that are generated. By interacting with 
feedback texts describing the tbrm-related KB, 
the author changes the stylistic/layout proper- 
ties of the document. 
A WYSIWYM-based  System for 
the  Author ing  o f  Mu l t imed ia  
Documents  
ILLUSTrl, ATE is ai1 extension of PILLS produc- 
ing documents that contain pictures as well as 
words. Consider a toy exalnl)le, adapted from 
ABPI (1997). Suppose the document says Re- 
move the cover of your inhaler. An instruction 
of this kind may be illustrated by the picture 
below. How can a document authoring system 
produce a document in which appropriate pic- 
tnres illustrate the text when this is desired? 
ILLUSTRATE does this by allowing an author to 
ask tbr pictorial il lustration of the intbrmation 
in the document by interacting with the feed- 
back texts. The author can indicate, fbr a given 
mouse-sensitive stretch s of the feedback text, 
whether she would like to see the part of the 
document hat corresponds to s illustrated. If 
so, the system searches its library to find a pic- 
ture that matches the meaning of s. In Fig.2, 
the author has requested illustration of the in- 
224 
i . . . . . . .  1_/ 
I 
Figure 1: One of the picture.s ill the lit)rary of 
the a, uthoring system 
struction (:orresl)onding with tim text 'Remove 
your inhaler's cov(,r fi'om your inhaler'. (The 
otlmr four options are irrelevant for t)resent pur-  
poses . )  In domains where all the pictures are 
, i  
\[:Jle ;%.'.ture f,.',oda!~t? C,srltr0l 
\ ]{en lova  your  inha le r '  s cover  h ' ,  . . . . . .  , . , , , .  ; , .h  . I . . , .  
ti i i l i  i:. ' .t 2c . . fvs , : l : t ;  
C,:,I>'~ 
CLR 
(gel)ell : t~,  a 
,%i.: !!,,,,d,, di, r ~ 
Figur(' 2: Screen(hunt): Author makes a re-. 
quests for illustration 
variations on a common theme, suitnble pic- 
tures can be generated. Ill the case. of l)atient; 
Information LeMtets, however, this was not a 
practical option because of the many ditDrent 
kinds of things depicted in the leaflets: medicine 
packages, body parts, medical at)l)licmmes, var-. 
ious t;yl)eS of actions, etc. Pictures, moreover, 
are he,wily reused in the diit'erent leatlets writ- 
tell \])y the S&lilO company. For these reasons, 
IIAAJSTRATt?, llses ~tii alternative al)proaeh, se- 
lecting pictures from a library, each of which is 
;tnnol;at,ed with ~t formal rel)r(;sentation of its 
meaning. We will explain the workings of IL- 
LUSTRATE by answering three questions: (\]) 
What kinds of rei)resent~tions are used ill the li- 
brary to annotate the pictures with relevant as- 
l)ects of their meaning'? (2) How is the .~;emanti- 
(:ally annotated library of t)i(:tures created'? and 
(3) What selection algorithm is employed to re- 
trieve all optimally approt)riate illustration for a 
given part of the, KB frolll the library? We shall 
assmne that the information whose illustration 
is requested con'esponds with the following for- 
mul~t in the KB, which tel)resents the metaling 
of the feedback text ill Fig. 2. 
R,'~,,,,o~,,'.(t,) ,V Acto,'(p) = .',: 
I~,.a~.,'(.~:) g So,,,,.,:c~(;,) = v a~ 
Inhalcr(y) ~ Actce(p) = z 
g = v. 
('There exists a 'Remove.' action whose Sere'co 
is an Inhah'.r and who.~e Ad, ee is a Cover of the 
same inhaler.') 
1. What  k inds  of  representat ions  are  
used?  Representations say what information 
each pictm'e intends to convey. Irrelewmt de- 
tails shouht be omitted. It has been observed 
that photographic pictures express 'vivid' in- 
formation and that this intbrmation can be 
expressed by a conjmmtion of positive, literals 
(Levesque 1!)86}. In line with this obserwttion, 
ILLUSTI/ATE rei)resents the lllea, nillg of the pic- 
ture in Fig. 1, for example, as follows: 
;~+.',,,.o~,+.'(p) *+ So',,.r',:+.'(p) = :\] 
H-I*",'(V) ,V A,tc~;(~,) = 
a C,,',.',,'(~) a O',,,,,. ', '(~) = :,j. 
(The leattet.~; (le,~mril)e Inhalers, Autohale.rs, and 
Aerohalers.) If any of the wtriables c, :r, y, z has 
&Ii oc('urrelice ill the llle;tlling rel)resentation of
mlother 1)i(:ture thei~ these occurrences coref'er. 
This ~:dlows the systmn to know wh(.'n two pi(:- 
tm'es depict the same. i)erson, for examt)le (Vail 
Demrd:er and Power 1999). 
2. How is the  l ib rary  c reated?  This is a 
question of great imi)ortmlce because the library 
contains emantic representations that m'e lIlltCh 
more detailed than those in current picture re- 
t r ieval  systems (e.g. Van de ~vVaal \]995) nml this 
couht potentially nmke the &llllOtat;iOll t;ask ex- 
tremely })ur(lensome (Enser 1995). The an,~wer 
to this t)rol)lem may be unext)e(:t;e(l: ILLUS- 
TI1ATE u.qi'.s WYSIWYM it;self to emtl)le authors 
t.t) associate ;t given t)icture with a novel rep- 
resenl;;tl;ion. The class of representations tlmt 
225 
are suitable for expressing the meaning of a pic- 
ture is, alter all, a ('vivid') subset of tile class 
of representations allowed by the T-Box tbr tim 
text of the document, and consequently, tim 
same WYSIWYM interlhce can be used to create 
snch representations. Fig. 3 contains a screen- 
dump of the annotation process, wtmre the cnr- 
rent annotation corresponds with the formula 
Cover(z) & Owner(z) = y. Note that this 
formula is still incomplete because the nature 
of the Source is undefined. (When it is finished, 
the feedback text will be eqniwtlent o that in 
Figure 2.) The top of the screendump shows the 
accompanying feedback text containing anchors 
tbr flsrther additions. 
Figure 3: Screendump: A stage during tile an- 
notation of a picture 
3. What  is the select ion algorithm? A pic- 
ture can illustrate ass item of information with- 
out expressing everything in it. For example, 
Fig. 1 does not show that the Actor is the 
Reader and it leaves the type of 'Haler' unspec- 
ified. (They all look alike.) So, a selection rule 
must allow pictures to omit intbrmation: 
Select ion Rule: Use the logically 
s t rongest  picture whose representa- 
tion is logically impl ied  by  the infor- 
mation to be illustrated. (Van Deemter 
1999) 
Logical strength is determined on the basis of 
the two semantic representations alone. Deter- 
mining whether one representation logically ira- 
lilies tim other, where one is an instance in the 
KB and tim other a representation of a picture, 
is easy, given that both are conjunctions of pos- 
itive literals. 
This brief description should suffice to highlight 
the following advantages of ILLUSTRATE: 
? One unifbrm interface is employed for all 
actions that involve the editing of semantic 
representations, regardless of the type of 
presentation i volved (i.e., its media). 
? When used for the construction of anno- 
tations of pictures, the T-Box of the sys- 
tem snakes sure that only those properties 
can enter an annotation that are relevant in 
connection with it. In the present domain, 
for example, the height of the patient is ir- 
relevant, and consequently the T-Box does 
not make height all attribnte of a person. 
,, Pictures are retrieved by a reasoning pro- 
cess involving classical ogic; since a match 
between a picture and a piece of the KB 
can never be inexact, there is no need tbr 
the retriewfl process to be probabilistic, as 
has to be done when the system has less 
control over the form of annotations (Van 
Rijsl)ergen 1985, Van Deesnter 1999). 
Specific aspects of ILLUSTRATE have been de- 
scribed elsewhere, but the assumptions belfind 
the system as a whole have not beess tated be- 
fore. (For tlm representation scheme and the 
selection scheme see Van Deemter 1999; tbr 
the treatment of sequences of pictures see Van 
Deemter and Power 1999.) We have so t'nr sin> 
plified by assuming there to be only one au- 
thor. In fact, however, an intelligent authoring 
system is most useflfl when there are several au- 
thors (each of which can be allowed to work in a 
different langnage). More specifically, it is plan- 
sible that the person anthoring the annotations 
in the library is not the santo as the person(s) 
who author(s) the document itself. 
4 Future  Work  Towards  the  I dea l  
The PILLS system (section 2) makes a first 
stab at fnlfilling text-related requirements 1 and 
2 nmntioned in section 1. The ILLUSTRATE 
demonstrator goes beyond this, fulfilling impor- 
tant aspects of requirements 3 and 4 as well. 
226 
Yet, there is a considerable ga t) l)etween the im- 
i)hmlented system and the ideal one of section 
1. Possit)le improvements do not only concern 
the (:overage of the sysl;em, but matters of sys- 
tem arehitectm:e as well. Three (titti;rent sets of 
improvements may l)e dis(:erned. Firstly, there 
is rcquirelnent 5 of section 1, whi(:h requires 
easy postediting. It is easy to allow at%hers to 
make h)w-levcl corrections in the document a.f- 
let the interaction with WYSIWYM, HIlL unless 
the system 'understands' the, meaning of the 
editing actions, i)ostediting destroys tlm con- 
ne(:tion t)etween the edited document an(l the 
(:ontent of l;he various knowledge l)nses. Conse- 
quenl;ly, l)OSt-editing is not a t)ractieal t)ossit)il- 
ity yet, giv(;n the state of the, m:t in text- and 
picture understanding. 
Other imt)rovements would 1)e less t)rol)lem- 
atic. On the one hand, there are issues that 
have been t~mkled by other research groups and 
whose sohltions we inten(t to (:arty over to a 
WYSlWYM-l)ased setl;ing. These (:on(:ern the 
generation ot' gral)hies Kern underlying rel)re- 
sentations (Wahlster et; al. 1993) and the 1)rot)- 
lem of ot)timizing tim layout of text & \])i(:ture 
do(:uments (e.g. Grat)h et al 1996), l'or in- 
stall(;e. Three remaining imt)rovements , (m the 
Ot\]ler \]lall(t~ ~LFe lllal;t(~rs for fill;tire l;('.s(?~l;(;ll: 
? Media alloc,,tio'n,. \]LLUSTRATF eml)o(li(',s 
one way in whi(:h media may be allocated. 
Other mechanisms (:ould give the system 
more autonomy. For example, l;he system 
may use rules (e.g. I/.oth and Hettey 1.!)93) 
to decide alltOllOnlOllsly what illforlllation 
is in need of illustration. Simih~rly, authors 
may 1)e enabled to 1)oint at thmnlmail 1)ie- 
tures, whereul)On the system tries to fin(t a 
suitable place in the document o include 
them, based on the ret)resentation of their 
meaning and making use, of the Se lect ion  
Ru le  of section 3. By thus allowing the au- 
thor and the system to coot)crate on media 
allocation, this ditiicult task will t)e lnade 
more tractable (see the recent discussions 
ill ETAI 1997-8). 
? Other media. Little in ILLUSTRATE hinges 
on the fact that the ol)jects in the lil)rary 
are t)ictures. The Salll(. ~ system, for exam- 
t)le, can be used tbr ammtating somul or 
canned tez t  (for examl)le, a complex t)it of 
btw {:ode, which needs to be rendered liter- 
ally). Of great practical interest, finally, is 
the 1)ossil)ility of including docunlents au- 
thored previously (and possibly by a dif- 
ferent author), leading to iterative applica- 
tions of WYSIWYM. 
? bttcract ion bctwc.cn media. Ide~flly, the 
words in a text should be Ml'ected by the 
inclusion of a picture: First, and most obvi- 
ously, texts im~y be cnlauicd by retbrences 
to 1)ictures (e.g., references like ~See Fig. 
3' may l}e.adde{t, {:f Paraboni an{t Van 
l)eemter 1999). Secondly, texts may 1)e 
red,uccd because information expressed in 
the 1)ictme can l)e shortened (or left out 
all;ogether). One type of situation where 
this h~q)l)ens i  cxempliiied by t;he text '12,o- 
move the ('al)sule frolll the foil as shown 
in the \])i(:ture' (ABPI 1997), a(:(:omt)anie(t 
1)y a t)i(:ture showing how this may be 
done. Oth(;r tyt)es of situation in(:lude the 
case where quantil;ative inforln~ttion is ex- 
1)resse(t through a vague textual descril)l;ion 
('a blol) of (:ream', ~a tingertip of ointmead:') 
that is made more l)re(:ise by means of a 
picture showing t\]w, required amount. 
It should 1)e noted that each of these extensions 
del)ends ('ru('ially on ILLUSTRA'I'E:s at)ility to 
ma.nil)ulate the semanti(: rel)resentations ass()- 
('iated with multimedia objc(:ts, whoxc' one mid 
the same rel)resental;ion language is used fbr 
the difl'erent media: a lmfltimedia qnterlingua' 
(e.g. Barkcr-Plummer and Greeves 1995). 
In the ('ase of an author selecting a t)icturc 
using tlmmbnails, tbr exami)le , the semantic 
rel)resentation cnal)les the author to (a) t inda  
suitabh; local;ion for the t)ieture and (1)) adat)t 
the, (;ext l)y omitting fl'om i(; information that 
is now expressed by the picture. 
A final extension of the ideas outlined in this 
t)aper would involve completing the symmetry 
between feedl)ack and outl)ut: all t)resent 
WYSIWYM systems IlSe Imrely textual feedback. 
In prin(:it)le, however, feedt)ack can l)e as 
multimodal as the target document. We are 
currently exploring the 1)ossibility of allowing 
an author to express some of her choices by 
clicking on a mouse-sensitive part of a picture; 
the system could generate an ui)dated feedback 
text (possibly along with an updated t)icture) 
227 
as a result. Iu some technologically complex 
domains, for example, where a brief description 
of an object may be difficult to obtain, this 
might lead to a fllrther improvement of the 
WYSIWYM technique. 
References  
ABPI (1997). The Association of the British 
Pharmaceutical Industry, 1996-1997 ABPI 
Compendium of Patient Information Leaflets. 
Am (1995). Special Issue, edited by P. Mc 
Kevitt, on Integration of Natural Language 
and Vision Processing: Intelligent Multimedia. 
Artificial Intelligence Review 9, Nos.2-3. 
E. Andr6 and Th. Rist (1995). Generating 
Coherent Presentations Employing Textual and 
Visual Material. Art{ficial Intelligence Review 
9:147-165. 
D. Barker-Hummer and M. Greeves (1995). 
Architectures for Heterogeneous Reasoning. 
In J.Lee (Ed.) Prec. of First International 
Workshop on Intelligence and Multimodality in 
Mnltimedia Inte1:faces: Research and Applica- 
lions (IMMI- 1), Edinburgh. 
M. Bordegoni, G. Faconti, S. Feiner, M.T. 
Maybury, T. I{ist, S. Ruggieri, P. Trahanias, 
and M. Wilson (1997). A Standard Reference 
Model for Intelligent Multimedia Presentation 
Systems. Computer Standards & Interfaces 18, 
pp. 477-496. 
P. Enser (1995). Progress in Docmnentation; 
Pictorial hffbrmation II,etrieval. Journal of 
Documentation, Vol.51, No.2, pp.126-170. 
ETM (1997, 1998). ETAI News Journal on 
Intelligent User Interfaces, Vol 1, No's 1 and 2. 
W.H. Graf, S. Neurohr, and R. Goebel (1996). 
A Constraint-Based Tool for the Pagination of 
Yellow-Page Directories. In U. Geske and H. 
Simonis (Eds.) Procs. of KI96 workshop on 
declarative constraint programnfing. GMD- 
Studien 297, St. Augustin. 
H.J. Levesque (1986). Ma~king Believers out of 
Computers. Artificial Intelligence 30, pp.81-108 
M. Maybury and W. Wahlster (1998). Read- 
ings in Intelligent User Interthces. Morgan 
Kaufmmm Publ., San Francisco. 
I. Paraboni and K. van Deemter (1999). Issues 
for Generation of Document Deixis. Ill E. 
Andrd c ta l .  (Eds) Procs. of workshop on 
Deixis, Demonstration and Deictic Belief in 
Multimedia Contexts, ill association with tile 
l l th  European Smnmers School in Logic, 
Language and Information (ESSLLI99). 
R. Power and D. Scott (1998). Multilingual 
Authoring using Feedback Texts. In Prec. of 
COLING/A CL co#:ference, Montreal. 
S. Roth and W. Hefley (1993). Intelligent 
Multimedia Presentation Systems: Research 
and Principles. In M.Maybury (Ed.) Intelligent 
Multimedia Interlaces, AAAI Press, pp.13-58. 
D. Scott, R. Power, and R. Evans (1998). 
"Generation as a Solution to its own Problem", 
Accepted for Prec. of 9th International Work- 
shop on Natural Language Generation. 
D. Scott (1999). The Multilingual Generation 
Game: authoring fluent texts in unfamiliar lan- 
guages. Proceedings of the 16th International 
Joint Conference on Artificial Intelligence 
(IJCAI'99). 
O. Stock (1991). Natural Language and Explo- 
ration of an Information Space: the aLFfl'esco 
Interactive Systein. In M. Maytmry and W. 
Wahlster (1998). 
K. van Deemter (1999). Docunlent Geueration 
and Picture Retrieval. In Prec. of Third 
Int. Conf. on Visual hfformation Systems, 
Amsterdam, Springer Lecture Notes. 
K. van Deemter and R. Power (1999). Inclusion 
of Picture Sequences in Generated Docmnents. 
In Prec. of iburth Portuguese Conf. on 
Artificial Intelligence, Evora, Springer Lecture 
Notes. 
H. van de Waal (1995). ICONGLASS; An leone- 
graphic classification system. Amsterdam 1973- 
1985 (17 vols). ISBN 0-7204-8264-X. See also 
<http : / / i cone lass .  leg .  ruu. n l /home, html>. 
C.J. van Rijsbergen (1989). Towards an inibr- 
mation logic. In: Prec. ACM SIGIR. 
W. Wahlster, E. Andrd, W. Finkler, H.-J. 
Profitlich, and Th.Rist (1993). Plan-based 
Integration of Natural Language and Graph- 
ics Generation. Artificial Intelligence 63, 
p.387-427. 
228 
Squibs and Discussions 
On Coreferring: Coreference in MUC and 
Related Annotation Schemes 
Kees  van  Deemter*  
University of Brighton 
Rodger Kibble* 
Goldsmiths College 
In this paper, it is argued that "coreference" annotations, as performed in the MUC community 
for example, go well beyond annotation of the relation of coreference proper. As a result, it is not 
always clear what semantic relation these annotations are encoding. The paper discusses a number 
of problems with these annotations and concludes that rethinking of the coreference task is needed 
before the task is expanded. In particular, it suggests a division of labor whereby annotation of the 
coreference r lation proper is separated from other tasks such as annotation of bound anaphora 
and of the relation between asubject and a predicative NP. 
1. Introduction: Coreference Annotation 
Various practical tasks requiring language technology including, for example, infor- 
mation extraction and text summarization, can be performed more reliably if it is 
possible to automatically find parts of the text containing information about a given 
topic. For example, if a text summarizer has to select the most important informa- 
tion, in a given text, about the 1984 Wall Street crash, then the summarization task 
is greatly helped if a program can automatically spot all the clauses in the text that 
contain information about this crash. To evaluate a program of this kind, extensive 
language corpora have been prepared in which human readers have annotated what 
has been called the coreference relation. These annotated corpora are then used as a 
gold standard against which the program's achievements can be compared. The re- 
lation of coreference has been defined as holding between two noun phrases if they 
"refer to the same entity" (Hirschman et al 1997). More precisely, let us assume that 
al and a2 are occurrences of noun phrases (NPs) and let us assume that both have 
a unique referent in the context in which they occur (i.e., their context in the corpus 
makes them unambiguous). Under these assumptions we can use a functional nota- 
tion, e.g. Referent(a), as short for "the entity referred to by a"  and define (suppressing 
the role of context): 
Definition 
al and a2 corefer if and only if Referent(a1) =Referent(a2). 
Putting it simply: to determine whether al and a2 corefer, first determine Referent(a1) 
and Referent(a2), then see if they are equal. 
Ideally, of course, one would like to annotate many other semantic relations that 
hold between parts of a text, because they are also relevant for text interpretation. One 
candidate is the relation of anaphora. Loosely speaking--and glossing over some dif- 
ficulties regarding the precise delimitation of anaphora (Sidner 1979; Partee 1989; van 
* Information Technology Research Institute, University of Brighton, Lewes Road, Brighton BN2 4GJ, 
UK. E-mail: Kees.van.Deemter@itri.bton.ac.uk 
t Mathematical and Computing Science, Goldsmiths College, University of London, London SE14 6NW, 
UK. E-mail: R.Kibble@gold.ac.uk 
(~) 2001 Association for Computational Linguistics 
Computational Linguistics Volume 26, Number 4 
Deemter 1992)--an NP O~ 1 is said to take an NP a2 as its anaphoric antecedent if and 
only if al depends on Oz2 for its interpretation (e.g., Kamp and Reyle 1993). It follows 
that anaphora nd coreference are different hings. Coreference, for example, is an 
equivalence r lation; anaphora, by contrast, is irreflexive, nonsymmetrical, nd non- 
transitive. Secondly, anaphora, as it has just been defined, implies context-sensitivity 
of interpretation, and this is not true for coreference. For example, a name (President 
W. I. Clinton) and a description (Hillary Rodham's husband) can corefer without either 
of the two depending on the other for its interpretation. Anaphoric and coreferential 
relations can coincide, of course, but not all coreferential relations are anaphoric, nor 
are all anaphoric relations coreferential. (An example of the latter is bound anaphora, 
see Section 2.1.) 
Coreference annotation has been a focus of the Sixth and Seventh Message Under- 
standing Conferences (MUC-6, MUC-7) and various other annotation exercises (e.g., 
Passoneau 1997; Garside, Leech, and McEnery 1997; Davies et al 1998; Poesio 2000). In 
this squib, we intend to point at some fundamental problems with many of these an- 
notation exercises, which are caused by a failure to distinguish properly between coref- 
erence, anaphora, and other, related phenomena. Because the MUC project is the best- 
known example of coreference annotation, on which much subsequent work is based, 
and because of the public availability of the MUC Task Definition (TD, Hirschman 
and Chinchor \[1997\]), we will focus on MUC. 
Four criteria are listed for the MUC TD, in order of their priority (Hirschman and 
Chinchor 1997): 
. 
2. 
3. 
4. 
The MUC information extraction tasks should be supported by the 
annotations 
Good (defined as ca. 95%) interannotator agreement should be achievable 
It should be possible to annotate texts quickly and cheaply 
A corpus should be created that can be used as a tool for linguists 
outside MUC. 
The TD makes it clear that the annotation task has been simplified in a number of 
ways. For example, only NPs were annotated. Such eminently sensible simplifica- 
tions notwithstanding, wewill argue that the above-mentioned criteria have not been 
achieved and that a rethinking of the coreference annotation enterprise is in order be- 
fore it ventures into new domains involving speech, noisy data, etc. (see for example, 
Bagga, Baldwin, and Shelton \[1999\]), or before it extends the relation of coreference 
to cover whole/part and class/instance r lations (e.g. Popescu-Belis 1998; Hirschman 
and Chinchor 1997). 
2. Problems with Coreference Annotation 
In this section, some unclarities and inconsistencies will be discussed that we found 
in the literature on coreference annotation, and which appear to stem from confusion 
about what reference and coreference are. In Section 2.1, we will explore the tendency 
to apply coreference annotation to nonreferring NPs and bound anaphora, and we 
will argue that this tendency is problematic. In Section 2.2, we will argue that existing 
annotation enterprises still fail to respond properly to the well-known problem of how 
to annotate NPs that are used intensionally. In Section 2.3, we turn to a suggestion 
for the improvement of the actual process of annotation that has been made in the 
630 
van Deemter and Kibble On Coreferring 
literature, namely to separate the task of determining the "markables" from that of 
establishing coreference r lations between them, showing that this separation is hard 
to maintain. At the end of each subsection, some suggestions (Remedies) will be made 
on how the problems may be tackled. These suggestions will be elaborated in Section 3. 
2.1 Annotating Nonreferring NPs and Bound Anaphora 
The notion of reference is common to a broad variety of semantic theories (see Gamut 
\[1991\], Chapter 1, for discussion). When speakers/writers use an NP to refer to an 
object or a set of objects, they try to single out the entity uniquely. Thus, when someone 
utters the NP the tenant of the house, the speaker may aim to single out a unique person, 
say Mr. X. Even when this is the case (i.e., the NP is used referentially rather than 
attributively1), the notion of referring has its problems. For example, the speaker may 
be mistaken in her belief that Mr. X is the tenant of the house (Donnellan 1966). In 
such cases it is unclear who is being referred to. Such problems notwithstanding, work 
on coreference annotation has usually taken the notion of reference for granted, on the 
assumption that clear cases, where the referent of an NP is clearly defined, outnumber 
the problematic ones, at least in some important ypes of discourse. 
Let us, for now, buy into the assumption that reference is a straightforward notion. 
Then, following Bach (1987) (especially Sections 3.2 and 12.2), for example, one thing 
that is clear about reference is that some NPs do not refer. When someone says 
(1) a. No solution emerged from our discussions, or 
b. Whenever a solution emerged, we embraced it, 
the solution NPs do not refer to any single solution, nor to any definite set of solutions. 
Most theorists would agree that they do not have a referent. Nonreferring NPs can 
enter anaphoric relations. (For example, the NP a solution is the (bound) anaphoric 
antecedent to it in (lb).) But if they do not refer, the c0reference r lation as defined in 
Section i (which presupposes that Referent(olD and Referent(o~2) are defined) is not ap- 
plicable to them. Even so, the MUC TD asks annotators to treat them as if it was appli- 
cable. It acknowledges (page 10) that "one may argue that \[a bound anaphor and its an- 
tecedent\] are not coreferential in the usual sense," but falls short of explaining explicitly 
what types of anaphora re to be annotated and how (Hirschman and Chinchor 1997). 2
The annotation of bound anaphora merits some further elaboration. Consider, for 
example, quantifying NPs such as Every TV network (or, even more problematic, Most 
computational linguists \[Hirschman and Chinchor 1997\], see also Section 3). If Every TV 
network refers at all, then presumably it refers to the set of all TV networks (relevant to a 
certain domain). The TD, however, asks annotators to let Every TV network corefer with 
its in (lc). According to the definition of coreference, this means that Referent(Every 
TV network) = Referent(its) so that Referent(its) is the set of all TV networks, predicting 
incorrectly that (lc) means (ld): 
(1) c. Every TV network reported its proyqts 
c p. Every TV network reported every TV network's proyqts, 
1 See Donnellan (1966). For an interesting class of attributively used NPs, see van der Sandt (1992); 
examples include hypotheticals like If this house has a tenant then the tenant isprobably Dutch, where one 
might ask whether atenant and the tenant corefer. 
2 Sometimes the term "cospecification" has been employed to replace coreference (e.g. Sidner 1983; 
Davies et al 1998). It is unclear, however, whether abound anaphor and its antecedent cospecify, or
how the notion should be applied to intensional constructions (Section 2.2). 
631 
Computational Linguistics Volume 26, Number 4 
(Incidentally, coreference and anaphora re not only different; they are also extremely 
difficult o combine into a proper equivalence r lationship that allows us to recognize 
different clauses as being "about he same thing." Consider, for example, the relation, 
say R, which holds between NP1 and NP2 if and only if 
either NP1 and NP2 corefer (in the sense of the definition in Section 1) 
or NP1 is an anaphoric antecedent of NP2 
or NP2 is an anaphoric antecedent of NP1 
Note that R is not an equivalence r lation. The subject of (lc), for example, can corefer 
with a plural pronoun in the next sentence, .g., (...) They are now required to do this, 
but They and it (in (lc)) do not stand in the relation R.) 
Predicative NPs are another category of NPs whose referentiality is problematic 
and yet the MUC TD instructs annotators to let them corefer with other NPs. In (2a) 
and (2b), for example, the predicative NP the/a president off DD cannot be replaced 
by the proper name Higgins without changing the meaning of the sentence beyond 
recognition, indicating that the relation between the two NPs must be something other 
than coreference: 
(2) a. Higgins was~became th /a president of DD 
b. Higgins, once the president of DD, is now a humble university lecturer 
We will have more to say about predicative NPs in the next section. 
To sum up, MUC's annotators have been instructed to let NPs of all major classes 
(definite, quantificational, nd indefinite) "corefer" liberally with other NPs, even when 
it is far from clear that the NPs in question have been used referentially. As a result, 
the relation actually annotated in MUC--henceforth called the IDENT relation, fol- 
lowing Hirschman and Chinchor (1997)--must be distinguished from the coreference 
relation. The TD admits that certain instructions may be incompatible with the defini- 
tion of coreference but no reason is given for these incompatibilities and no intuitive 
motivation for the relation IDENT is offered. As a result, the annotator is left with a 
long series of instructions that fail to be held together by a common rationale. 
Remedy. Go back to basics: start from a definition of coreference and write a TD that 
implements he definition. We suggest that it is not until this has been done success- 
fully that extensions into the area of bound anaphora become a risk worth taking. 
2.2 Problems of Intensionality and Predication 
Problems posed to coreference annotation by intensionality (Hirschman et al 1997) 
have motivated considerable complications in the TD. Consider Section 6.4, which 
discusses the implications of "change over time." The TD says that "two markables 
should be recorded as coreferential if the text asserts them to be coreferential tANY 
TIME" (Hirschman and Chinchor 1997, page 11). Thus, for example, the TD points out 
that in a case like 
(3) Henry Higgins, who was formerly sales director off Sudsy Soaps, became president 
of Dreamy Detergents 
annotators are expected to mark (1) Henry Higgins, (2) sales director of Sudsy Soaps, 
and (3) president of Dreamy Detergents as coreferential. (Similar strategies seem to be 
632 
van Deemter and Kibble On Coreferring 
adopted by most practitioners of coreference annotation, e.g., Cristea et al \[1999\]). But 
since coreference is generally agreed to be a equivalence relation (e.g. Hirschman and 
Chinchor 1997, Section 1.3), this implies that the sales director of Sudsy Soaps and the 
president of Dreamy Detergents are the same person. Clearly, this cannot be right. 
Luckily, there are other parts of the same TD that do a better job of applying the 
notion of coreference to sentences involving change over time. Consider, for example, 
Section 1.3, where the sentence the stock price fell from $4.02 to $3.85 is discussed. Here 
annotators are asked to consider the stock price as standing in the IDENT relation with 
$3.85 but not with $4.02, because $3.85 is "the more recent value" (p. 3). (If both 
coreferred with the stock price, it would have followed that $4.02 and $3.85 are equal.) 
This solution, however, is still problematic. What, for instance, if the price continues 
to fall? 
(4) a. The stock price fell from $4.02 to $3.85; 
b. Later that day, it fell to an even lower value, at $3.82. 
Does the annotator have to go back to (4a), deciding that $3.82 is an even more recent 
value and the stock price does not stand in the IDENT relation with $3.85 after all? 
Remedy. At least three different strategies are conceivable. Perhaps most obviously, 
one might decide that coreference between a functional description like those in (3) or 
(4) and an NP denoting a value requires this value to be the present (rather than the 
most recent) value of the function. But, the text does not always say what the present 
value is. Moreover, functional descriptions do not always pertain to the present. In 
Last year, the president resigned, for example, the subject refers to last year's president, and 
consequently, it does not corefer with NPs referring to the present president. A second 
strategy, consistent with Dowty, Wall, and Peters (1981, Appendix iii) might be to say 
that The stock price refers only to a Montague-type individual concept, that is, a function 
from times to numbers. It would follow that The stock price does not corefer with either 
$4.02 or $3.85 and no problem would arise. Analogously, president of Dreamy Detergents, 
in (3) above, where it is used predicatively, might denote an individual concept rather 
than an individual. If the next sentence goes on to say He died within a week, then he 
is coreferential with Henry Higgins; if, instead, the text proceeds This is an influential 
position, but the pay is lousy, then This is coreferential with president of Dreamy Detergents. 
If both these analyses prove to be too complex to be used in large-scale annotation 
exercises, one might have to take the point of view that such descriptions simply do 
not refer. This would amount to a third strategy, which excludes these descriptions 
from entering coreference r lations altogether and leaving their analysis to the other 
tasks. 
2.3 What's Markable? 
It has been proposed that annotation can profitably be broken down into two more 
manageable steps: annotation of markables (step 1) is to be carried out before (step 2) 
partitioning the set of markables into equivalence classes of coreferring elements (e.g., 
Hirschman and Chinchor 1997). It turns out, however, that a strict distinction between 
the two steps is difficult to maintain, because, in principle, almost anything is mark- 
able. In the MUC-7 TD, this is sensibly acknowledged by letting annotators mark up 
certain elements only if they corefer with an existing markable: these include conjuncts 
and prenominal modifiers. In the following example, the first occurrence of aluminum 
is only considered to be markable because it corefers with the occurrence of this noun 
633 
Computational Linguistics Volume 26, Number 4 
as a bare NP in the second clause. 
(5) The price of aluminum siding has steadily increased, as the market for 
aluminum reacts to the strike in Chile. (Hirschman and Chinchor 1997) 
In other words: coreference (step 2) helps to determine what the markables are (step 1). 
Finding all the NPs that might participate in coreference becomes even harder if the 
annotation scheme is extended to cover event coreference (noted in the "wish list" in 
Section 1.4 of the TD) since it is often extremely difficult to determine which events 
can serve as antecedents (Hirschman and Chinchor 1997): 
(6) Be careful not to get the gel in your eyes. If this happens, rinse your eyes with 
clean water and tell your doctor. (ABPI, 1997) 
Examples of this kind suggest that one markable (e.g., an event) can give rise to 
another (e.g., the negation of the event). A complication of a similarly algebraic flavor 
arises if "discontinuous elements, including conjoined elements" are covered, as when 
a plural pronoun corefers with a combination ofpreviously occurring NPs (Hirschman 
and Chinchor 1997, section 1.4; see Garside, Leech, and McEnery \[1997\] for a proposal). 
Note especially that annotators would have to be on guard for the possibility of different 
combinations of markables coreferring to each other. A corpus, for example, can easily 
contain NPs A,B,C, and D for which Referent(A) U Referent(B) = Referent(C) U 
Referent(D). Even assuming that each of A, B, C, and D has been properly identified 
as a markable during step 1, this is little guarantee that annotators of step 2 will realize 
the complex coreference r lation between the combination of A and B and that of C 
and D. (Recall that coreference r lations are to be annotated even in the absence of an 
anaphoric relationship.) The number of possible combinations of markables (some 2 n 
when there are n markables) will often be too large to handle. 
Remedy. One alternative is to have a first pass where only referring expressions that 
look like anaphors are marked up, such as pronouns and definite NPs. Subsequent 
passes would look for antecedents for these expressions and link coreferring elements. 
An intermediate approach would be to mark up a core set of referring expressions on 
the first pass, allowing for further eferring expressions to be identified on subsequent 
passes if this is necessary to resolve coreference. The extent o which each strategy 
would contribute to accuracy and speed of annotation remains to be determined. 
3. Conclus ion 
Current "coreference" annotation practice, as exemplified by MUC, has overextended 
itself, mixing elements of genuine coreference with elements of anaphora nd predica- 
tion in unclear and sometimes contradictory ways. As a result, the annotated corpus 
emerging from MUC is unlikely to be as useful for the computational linguistics re- 
search community as one might hope (Criterion 4, see Section 1), the more so because 
generalization to other domains is bound to make problems worse. In many domains, 
for example, other sources of intensionality han change over time occur prominently. 
An example is epistemic modality: 
(7) Henry Higgins might be the man you have talked to. 
634 
van Deemter and Kibble On Coreferring 
The relation between Henry Higgins and the man you have talked to is analogous to that 
between Henry Higgins and sales director of Sudsy Soaps in (3), with possible worlds 
taking the place of points in time: the two NPs refer to the same individual in some 
possible worlds only (see Groenendijk, StokhoL and Veltman \[1996\] for relevant theo- 
retical work). Modality, of course, interacts with tense (as in Henry Higgins might become 
the president of Dreamy Detergents), leading to further complications. 
The MUC TD has addressed many of the difficult problems in the area of reference 
and coreference, but if its success is judged by the criteria in Hirschman and Chinchor 
(1997) (see Introduction), the results are mixed at best. Criterion 4 has been discussed 
above. Concerning Criterion 3, it appears doubtful that the present task definition can 
be applied "quickly and cheaply." Hirschman et al (1997), when discussing this issue, 
note that interannotator agreement, at the time of writing, was in the low eighties. 
This figure, which falls markedly short of the 95% required by Criterion 2, does not 
seem to have improved substantially since (Breck Baldwin, personal communication). 
Concerning Criterion 1, finally, it has been observed that the figures for recall in the 
MUC information extraction algorithm are rather discouraging (Appelt 1998). The 
material in Section 2 suggests that this relative lack of success is no accident and that 
unclarities in the TD are to blame. Repairs are not always easy to find. Given this 
situation, we suggest that a rethinking of the coreference task is required. 
Firstly, one needs a consistent story of what reference and coreference are taken 
to be. Theoretical work on reference does not show a consensus on some crucial ques- 
tions in this area (Bach 1987; Kronfeld and Roberts 1998). Different answers have been 
suggested, each with its own advantages and disadvantages. For example, one might 
identify the notion of a referring NP with that of a semantically definite NP in the sense 
of Barwise and Cooper (1981). 3This would include proper names, extensional definite 
descriptions, universally quantified NPs, and specifically used indefinites (e.g., a com- 
pany whose name is withheld), but it would exclude nonspecifically used indefinites such 
as at least n companies, most computational linguists. A more liberal approach along the 
lines of Kamp and Reyle (1993, Chapter 4), would predict hat a quantifying NP such 
as the subject of Most computational linguists use a parser refers to the set of those com- 
putational linguists who use a parser: the VP helps to determine the referent of the NP. 
The first approach would make annotation easier to perform and the results would be 
likely to be more reliable as a result, but it would feed less information i to the infor- 
mation extraction task. Trade-offs of this kind are unavoidable, and experimentation 
will be required to determine which option provides the best results. 
Secondly, we suggest a further division of labor whereby those phenomena that 
are no longer accounted for in the new TD are covered by other tasks (Kibble and 
van Deemter 2000). For example, the two NPs Henry Higgins and president of Sudsy 
Soaps (example (3)) do not corefer, and the relation between them should be irrelevant 
to coreference annotation. If it is imperative that information about Henry's previous 
jobs be saved for posterity then some other annotation task has to be defined, with 
its own very different TD, involving the notion of individuals having properties at 
certain times or intervals only. Something analogous is true for the annotation of 
bound anaphora. 
The issue under discussion illustrates a more general point. It is now widely 
agreed that linguistic theorizing is sometimes insufficiently informed by observational 
data. Conversely, we would like to submit that corpus-based research is sometimes 
3 A semantically definite NP c~ is one whose set-theoretic denotation takes the form of a principal filter 
(Partee, ter Meulen, and Wall 1990), i.e., a set of the form {X: Y C X} for some set of individuals Y. 
635 
Computational Linguistics Volume 26, Number 4 
insufficiently informed by theory. It follows, in our opinion, that there is scope for 
more collaboration between theoretical and corpus-based linguists in this area. This 
squib attempts to be a small step in this direction. 
Acknowledgments 
The authors wish to thank Christy Doran, 
Renate Henschel, Adam Kilgarriff, Paul 
Piwek, Massimo Poesio, Richard Power, and 
four anonymous referees for their 
comments on an earlier draft of this paper. 
We are grateful to Lynette Hirschman and 
Breck Baldwin for their very constructive 
responses to a predecessor f this paper 
(van Deemter and Kibble 1999). Kibble's 
work on this paper was funded by the UK's 
EPSRC as part of the GNOME (GR/L51126) 
and RAGS (GR/L77102) projects. 
References 
ABPI. 1997. 1996-1997 ABPI Compendium of 
Patient Information Leaflets. Association of 
the British Pharmaceutical Industry. 
Appelt, Douglas. 1998. An overview of 
information extraction technology and its 
application to information retrieval. In 
Proceedings ofTWLT14, Language Technology 
in Multimedia Information Retrieval, 
pages 49-58, Twente. 
Bach, Kent. 1987. Thought and Reference. 
Clarendon Press, Oxford. 
Bagga, Amit, Breck Baldwin, and Sara 
Shelton. 1998. Coreference and its 
applications. Call for papers for workshop 
associated with the 37th Annual Meeting 
of the Association for Computational 
Linguistics, University of Maryland, 1999. 
See www.cs.duke.edu/,-~amit / acc99- 
wkshp.html. 
Barwise, Jon and Robin Cooper. 1981. 
Generalized quantifiers and natural 
language. Linguistics and Philosophy, 
4:159-219. 
Cristea, Dan, Nancy Ide, Daniel Marcu, and 
Valentin Tablan. 1999. Discourse structure 
and coreference: An empirical study. In 
Dan Cristea, Nancy Ide, and Daniel 
Marcu, editors, Proceedings ofACL'99 Ws: 
The Relation of Discourse~Dialogue Structure 
and Reference, pages 46-53. 
Davies, Sarah, Massimo Poesio, Florence 
Bruneseaux, and Laurent Romary. 1998. 
Annotating coreference in dialogues: 
Proposal for a scheme for MATE. See 
www.cogsci.ed.ac.uk/~poesio/MATE/anno- 
manual.html. 
Donnellan, Keith. 1966. Reference and 
definite descriptions. Philosophical Review, 
75:281-304. 
Dowty, David, Robert Wall, and Stanley 
Peters. 1981. Introduction to Montague 
Semantics. Kluwer, Dordrecht. 
Gamut, L. T. F. 1991. Logic, Language and 
Meaning, Volume 2. University of Chicago 
Press, Chicago. 
Garside, Roger, Geoffrey Leech, and Tony 
McEnery. 1997. Corpus Annotation. 
Longman, London. 
Groenendijk, Jeroen, Martin Stokhof, and 
Frank Veltman. 1996. Coreference and 
modality. In Shalom Lappin, editor, The 
Handbook of Contemporary Semantic Theory. 
Blackwell, Cambridge, MA, pages 
179-214. 
Hirschman, Lynette and Nancy Chinchor. 
1997. MUC-7 coreference task definition. 
In MUC-7 Proceedings. Science 
Applications International Corporation. 
See www.muc.saic.com. 
Hirschman, Lynette, Patricia Robinson, John 
Burger, and Marc Vilain. 1997. 
Automating coreference: The role of 
annotated training data. In Proceedings of
AAAI Spring Symposium on Applying 
Machine Learning to Discourse Processing. 
Kamp, Hans and Uwe Reyle. 1993. From 
Discourse to Logic. Kluwer, Dordrecht. 
Kibble, Rodger and Kees van Deemter. 2000. 
Coreference annotation: Whither? In 
Maria Gavrilidou et al, editors, 
Proceedings ofthe 2nd International 
Conference on Language Resources and 
Evaluation, pages 1,281-1,286, Athens. 
Kronfeld, Ami and Lawrence Roberts. 1998. 
Special Issue on Reference, Pragmatics and 
Cognition 6. John Benjamins, Amsterdam 
and Philadelphia. 
Partee, Barbara. 1989. Binding implicit 
variables in quantified contexts. 
Proceedings ofthe Chicago Linguistic Society, 
25:342-365. 
Partee, Barbara, Alice ter Meulen, and 
Robert Wall. 1990. Mathematical Methods in 
Linguistics. Kluwer, Dordrecht. 
Passoneau, Rebecca. 1997. Instructions for 
applying discourse reference annotation 
for multiple applications (DRAMA). 
Unpublished manuscript. 
Poesio, Massimo. 2000. Annotating a corpus 
to develop and evaluate discourse ntity 
realization algorithms: Issues and 
preliminary results. In Maria Gavrilidou 
et al, editors, Proceedings ofthe 2nd 
International Conference on Language 
636 
van Deemter and Kibble On Coreferring 
Resources and Evaluations, pages 211-218, 
Athens. 
Popescu-Belis, Andrei. 1998. How corpora 
with annotated coreference links improve 
reference resolution. In Antonio Rubio et 
al., editors, First International Conference on 
Language Resources and Evaluation, 
pages 567-572, Granada. European 
Language Resources Association. 
Sidner, Candace. 1979. Towards 
a Computational Theory ofDeJinite Anaphora 
Comprehension in English Discourse. Ph.D. 
dissertation, AI Lab, MIT, Cambridge, MA. 
Sidner, Candace. 1983. Focusing in the 
comprehension f definite anaphora. In 
Michael Brady and Robert Berwick, 
editors, Computational Models of Discourse. 
MIT Press, Cambridge, MA, 
pages 267-330. 
van Deemter, Kees. 1992. Towards a 
generalization of anaphora. Journal of 
Semantics, 9:27-51. 
van Deemter, Kees and Rodger Kibble. 1999. 
What is coreference and what should 
coreference annotation be? In Amit 
Bagga, Breck Baldwin, and Sara Shelton, 
editors, Proceedings ofACL workshop on 
Coreference and Its Applications, 
pages 90-96, Maryland. 
van der Sandt, Rob. 1992. Presupposition 
projection as anaphora resolution. Journal 
of Semantics, 9:333-37. 
637 
Generating Referring Expressions:
Boolean Extensions of the Incremental
Algorithm
Kees van Deemter
University of Brighton
This paper brings a logical perspective to the generation of referring expressions, addressing
the incompleteness of existing algorithms in this area. After studying references to individual
objects, we discuss references to sets, including Boolean descriptions that make use of negated
and disjoined properties. To guarantee that a distinguishing description is generated whenever
such descriptions exist, the paper proposes generalizations and extensions of the Incremental
Algorithm of Dale and Reiter (1995).
1. Introduction
Generation of referring expressions (GRE) is a key task of most natural language gener-
ation (NLG) systems (e.g., Reiter and Dale 2000, Section 5.4). Regardless of the type of
knowledge base (KB) forming the input to the generator, many objects will not be des-
ignated in it via an ordinary proper name. A person like Mr. Jones, for example, may
be designated using an artificial name like # Jones083, if the name Jones is not uniquely
distinguishing. The same is true for a piece of furniture, a tree, or an atomic particle,
for instance, for which no proper name is in common use at all, or (in most cases) if
the generator tries to refer to an entire set of objects. In all such cases, the generator
has to ?invent? a description that enables the hearer to identify the intended referent.
In the case of Mr. Jones, for example, the program could identify him by providing his
full name and address; in the case of a tree, some longer description may be necessary.
Henceforth, we will call the intended referent the target of the GRE algorithm.
The question that we set out to answer is whether existing GRE algorithms pro-
duce adequate descriptions whenever such descriptions exist: in short, whether these
algorithms are, as we shall say, complete. The paper brings a degree of formal preci-
sion to this issue and reveals a number of reasons why current GRE algorithms are
incomplete; we sketch remedies and discuss their consequences in terms of linguistic
coverage and computational tractability. We take the Incremental Algorithm (Dale and
Reiter 1995) to represent the state of the art in this area, and we minimize the devi-
ations from this algorithm. As a result, this paper might be read as an investigation
into how widely the ideas underlying the Incremental Algorithm can be used, and
the extent to which they may be generalized. The main generalization that we will
investigate involves complex Boolean combinations of properties, that is, descriptions
that involve more than a merely intersective (i.e., logically conjunctive) combination
of properties. Such generalizations are natural because the properties involved are im-
plicitly present in the KB, as we will explain; they become especially relevant when the
 Information Technology Research Institute (ITRI), University of Brighton, Lewes Road, Brighton BN2
4GJ, UK. E-mail: Kees.van.Deemter@itri.brighton.ac.uk.
c? 2002 Association for Computational Linguistics
Computational Linguistics Volume 28, Number 1
algorithms are also generalized to generate references to sets, rather than individual
objects. But, before we arrive at these generalizations, we will identify and confront a
number of cases in which current GRE algorithms are incomplete even with respect
to merely intersective descriptions.
In this paper, we will deal with ?first mention? descriptions only (unlike Dale
1992, Chapter 5; Mittal et al 1998; Kibble 1999), assuming that the information used
for generating the description is limited to a KB containing complete information about
which properties are true of each object. Also, we focus on ?one shot? descriptions,
disregarding cases where an object is described through its relations with other ob-
jects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001).
More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content
of a description (i.e., the problem of content determination, for short), assuming that
any combination of properties can be expressed by the NLG module responsible for
linguistic realization. This modular approach allows us to separate logical aspects of
generation (which are largely language independent) from purely linguistic aspects,
and it allows the realization module to base its decisions on complete information
about which combination of properties is to be realized. Accordingly, when we write
Generation of Referring Expressions or GRE, we will refer specifically to determination of
the semantic content of a description. Analogously, the word description will refer to
the semantic content of a linguistic expression only. Note that our modular approach
makes it unnatural to assume that a description is always expressed by a single noun
phrase: if several sentences are needed, then so be it.
After summarizing the Incremental Algorithm in Section 2, in Section 3 we take a
closer look at the algorithm in its standard, ?intersective? form, in which it identifies
an object by intersecting a number of atomic properties. We discuss cases in which
this algorithm fails to find an adequate description even though such a description
exists, and we propose a number of possible remedies. Having extablished a com-
pleteness result for a version of the intersective Incremental Algorithm, we turn to
questions of completeness that involve more complex Boolean combinations in Sec-
tion 4. In Section 5, we summarize the main results of our exploration and put them
in perspective.
2. Dale and Reiter (1995): The Incremental Algorithm
The Incremental Algorithm of Dale and Reiter (1995) singles out a target object from
among some larger domain of entities. It does this by logically conjoining a num-
ber of properties found in a part of the KB that represents information shared be-
tween speaker and hearer. The authors observed that the problem of finding a (?Full
Brevity?) description that contains the minimum number of properties is computation-
ally intractable (i.e., NP Hard). They combined this with the known fact that speakers
often produce nonminimal descriptions anyway (e.g., Pechman 1989). Accordingly,
they proposed an algorithm that only approximates Full Brevity, while being of only
linear complexity. Our summary of the algorithm glosses over many details, yet still
allows us to discuss completeness. In particular, we disregard any special provisions
that might be made for the selection of head nouns because, arguably, this has to
involve realizational issues.1
1 Compare Dale and Reiter (1995), where head nouns are taken into account during content
determination. Head nouns can also be selected during linguistic realization or by interleaving of
content determination and realization (e.g., Horacek 1997; Stone and Webber 1998; Krahmer and
Theune 1999).
38
van Deemter Generating Referring Expressions
The Incremental Algorithm produces a set L of properties P1, : : : , Pn such that their
logical conjunction forms a ?distinguishing description? (Dale 1989) of the target object
r. In other words, writing [[Q]] for the extension of Q (i.e., the set of objects that have
the property Q), the intersection [[P1]] \    \ [[Pn]] must equal the singleton set frg.
It is a ?hillclimbing? algorithm, which finds better and better approximations of the
target set frg by accumulating more and more properties?hence the term Incremental.
There is no backtracking. Consequently, if some property Pi in L is made redundant
by later additions (i.e., when ([[P1]] \    \ [[Pi ? 1]] \ [[Pi + 1]] \    \ [[Pn]])  [[Pi]]),
then Pi is retained as a member of L nevertheless.
In the full algorithm (see below, D&RAtt), properties are analyzed as pairs consist-
ing of an Attribute and a Value. Attributes are ordered in a list A. If Ai precedes Aj in
A, then Ai is ?more preferred than? Aj; as a consequence, Ai will be considered before
Aj by the algorithm. Suppose r is the target object, and D (the ?domain?) is the set
of elements from which r is to be selected. The algorithm iterates through A; for each
Attribute Ai, it checks whether specifying a Value for that Attribute would rule out
at least one object that has not already been ruled out; if so, the Attribute is added
to L, with a suitable Value (FindBestValue, below). C is the set of ?confusables? at
any given stage of the algorithm.2 Objects that are ruled out are removed from C. The
process of expanding L and contracting C continues until C = frg; if and when this
condition is met, L is a distinguishing set of properties.
For easy generalizability, the algorithm will be cast in set-theoretic terms. We first
present a version that focuses on properties, without separating these into Attributes
and Values, and assume the properties themselves are ordered in a list P (cf. Reiter
and Dale 2000). This version of the algorithm will be called D&RProp, or D&R when
there is no risk of confusion. We assume that the domain contains one or more objects
other than the target object, the so-called distractors: thus, r 2 D but frg 6= D.
L :=  fL is initialized to the empty setg
C := D fC is initialized to the domaing
For each Pi 2 P do
If r 2 [[Pi]] & C 6 [[Pi]] fPi removes distractors from Cg then do
L := L [ fPig fProperty Pi is added to Lg
C := C \ [[Pi]] fAll elements outside [[Pi]] are removedg
If C = frg then Return L fSuccessg
Return Failure fAll properties in P have been tested, and still C 6= frgg
Assuming (as do Dale and Reiter [1995]) that the tests in the body of the loop take
some constant amount of time, the worst-case running time is on the order of na (i.e.,
O(na)), where na is the total number of properties. So, the algorithm has only linear
complexity.
A slightly closer approximation of Full Brevity can be achieved if Attributes and
Values are separated (Dale and Reiter 1995), allowing the algorithm to choose the
?best? Value for each Attribute. Given an Attribute, FindBestValue selects the Value
that removes most distractors while still including the target r. If no Value includes r,
the function returns nil. In case of a tie (i.e., no Value removes more distractors than
all others), FindBestValue chooses the least specific of the contestants. For example,
2 Thus, C contains r, unlike in Dale and Reiter (1995). The difference is purely presentational.
39
Computational Linguistics Volume 28, Number 1
when dog rules out as many distractors as chihuahua, chihuahua cannot be chosen. A
is the list of Attributes; L is the set of Attribute/Value combinations returned by the
algorithm. A further notational convention will be useful: Values will be identified
by two indices, the first of which identifies the Attribute. Thus, to denote Value j of
Attribute Ai, we write Vi,j. This version of the algorithm will be called D&RAtt . The
initializations of L and D are omitted for brevity.
For each Ai 2 A do
Vi,j = FindBestValue(r, Ai)
If r 2 [[Vi,j]]& C 6 [[Vi,j]] then do
L := L [ fVi,jg
C := C \ [[Vi,j]]
If C = frg then Return L
Return Failure
We will switch back and forth between D&R and D&RAtt, depending on what is
at stake. Like D&R, D&RAtt has linear complexity. This can be made precise in the
following way.3 If the running time of a call of FindBestValue(r, Ai) is a constant
times the number of Values of the Attribute Ai, then the worst-case running time of
D&RAtt is O(nvna), where na equals the number of Attributes in the language and nv
the average number of Values of all Attributes.
3. Completeness of the Incremental Algorithm
Some new definitions will be useful. A GRE algorithm is successful with respect to a
given situation (i.e., with respect to a KB and a target) if it produces a distinguishing
description of r in that situation. We will call an algorithm complete if it is successful
in every situation in which a distinguishing description exists. Success is not always
possible: the properties in the KB may not be sufficient for individuating a given object.
Such no-win situations will not be held against an algorithm.
The Incremental Algorithm generates descriptions that contain set intersection as
their only Boolean operation. We define a GRE algorithm to be intersectively complete
if it has the following property: whenever an object can be characterized by intersecting
a finite number of properties, the algorithm will find such an intersection. We would
like to prove the Incremental Algorithm to be intersectively complete, but we will
meet a few obstacles before we get there.
3.1 Completeness and Overlapping Values
One assumption without which the Incremental Algorithm cannot be proven to be
intersectively complete concerns the semantic relation between different Values of a
given Attribute: their extensions should not ?overlap? in the following precise sense:
Values Vi,j and Vi,k (and equally, their extensions) overlap iff
Vi,j \ Vi,k, Vi,j ? Vi,k, and Vi,k ? Vi,j are all nonempty.
3 Dale and Reiter arrived at linearity via the difficult concept of typical running time. They assumed that,
typically, nl (i.e., the number of properties in the description) is proportional to the number of
Attributes examined by the algorithm (Ehud Reiter, personal communication). This allowed them to
argue that the typical running time is O(ndnl), where nd is the number of distractors (Dale and Reiter
1995, Section 3.1). Our own worst-case assessment does not rely on assumptions of typicality.
40
van Deemter Generating Referring Expressions
(If Vi,j and Vi,k do not overlap, then either [[Vi,j]]  [[Vi,k]], or [[Vi,k]]  [[Vi,j]], or [[Vi,j]]
and [[Vi,k]] have an empty intersection.) Values can overlap for different reasons. Some
Attributes (e.g., COLOR) have ?vague? Values (e.g., RED, ORANGE), which may be mod-
eled as overlapping: some objects may count as both red and orange. Also, Values may
derive from particular parts or aspects of an object; for example, if an object counts as
METAL (PLASTIC) because it has some METAL (PLASTIC) parts, then it may be listed as both
METAL and PLASTIC. Further examples arise if the KB models relations through unana-
lyzed properties. For example, a desk, or a particular type of desk, can stand in a given
relation (e.g., ?being considered by? or ?being bought by?) to more than one other
company. To see the problems arising from overlapping Values, consider a KB that
models which customer bought which types of desks, and where C = fa, b, c, d, e, fg:
BOUGHT-BY: PHILIPS (fa, b, eg), SONY (fa, c, d, fg)
COLOR: BROWN (fa, bg), YELLOW (fc, dg)
(Desks of types a, b, and e were bought by Philips, and so on. Note that desks of
type a were bought by two different companies.) Suppose a is the target, while the
Attribute BOUGHT-BY is more ?preferred? than COLOR. The Value PHILIPS (being the
BestValue of BOUGHT-BY, since it removes more distractors than the Value SONY) is
chosen first, reducing the initial set C to fa, b, eg. Now, the algorithm is doomed to end
in Failure, since the different Values of COLOR are unable to remove the unwanted b
without also sacrificing a. None of this can be corrected, since the algorithm does not
use backtracking. Note that a uniquely identifying description of a would have been
possible if only SONY had been chosen instead of PHILIPS, leading to a description like
the brown desk bought by Sony. The algorithm does not just fail: it fails in a situation
where Success was perfectly achievable!
How can this limitation be remedied? One might introduce a limited kind of back-
tracking, which ?remembers? where the algorithm has encountered overlapping Val-
ues and, when it results in Failure, goes back to the last-encountered situation where
it has made a choice between overlapping Values; if this does not lead to Success,
the algorithm backtracks to the previous choice situation, and so on until no more
choice situations are left (Failure) or a distinguishing description has been reached
(Success). Unfortunately, this algorithm becomes intractable if Values overlap too of-
ten: in the worst case, we are back to having to check all combinations of properties.
A simpler and computationally more efficient algorithm would include all over-
lapping Values that are true of the target while also removing some distractors. This
could be done as follows: whenever a Value Vi,j of an Attribute Ai is selected for in-
clusion in L, search for other Values of the same Attribute that have the target r as an
element; if such a Value Vi,k is found, check whether it stands in the subset relation to
Vi,j (i.e., either [[Vi,j]] From RAGS to RICHES: exploiting the potential of a flexible generation
architecture  
Lynne Cahill  , John Carroll  , Roger Evans  , Daniel Paiva  ,
Richard Power

, Donia Scott  and Kees van Deemter 

ITRI, University of Brighton
Brighton, BN2 4GJ, UK
Firstname.Lastname@itri.bton.ac.uk
 School of Cognitive and Computing Sciences, University of Sussex
Brighton, BN1 9QH, UK
johnca@cogs.susx.ac.uk
Abstract
The RAGS proposals for generic speci-
fication of NLG systems includes a de-
tailed account of data representation,
but only an outline view of processing
aspects. In this paper we introduce a
modular processing architecture with a
concrete implementation which aims to
meet the RAGS goals of transparency
and reusability. We illustrate the model
with the RICHES system ? a generation
system built from simple linguistically-
motivated modules.
1 Introduction
As part of the RAGS (Reference Architecture for
Generation Systems) project, Mellish et al(2000)
introduces a framework for the representation of
data in NLG systems, the RAGS ?data model?.
This model offers a formally well-defined declar-
ative representation language, which supports the
complex and dynamic data requirements of gen-
eration systems, e.g. different levels of repre-
sentation (conceptual to syntax), mixed represen-
tations that cut across levels, partial and shared
structures and ?canned? representations. However

We would like to acknowledge the financial support of
the EPSRC (RAGS ? Reference Architecture for Generation
Systems: grant GR/L77102 to Donia Scott), as well as the
intellectual contribution of our partners at Edinburgh (Chris
Mellish and Mike Reape: grant GR/L77041 to Mellish) and
other colleagues at the ITRI, especially Nedjet Bouayad-
Agha. We would also like to acknowledge the contribution
of colleagues who worked on the RICHES system previ-
ously: Neil Tipper and Rodger Kibble. We are grateful to
our anonymous referees for their helpful comments.
RAGS, as described in that paper, says very little
about the functional structure of an NLG system,
or the issues arising from more complex process-
ing regimes (see for example Robin (1994), Inuie
et al, (1992) for further discussion).
NLG systems, especially end-to-end, applied
NLG systems, have many functionalities in com-
mon. Reiter (1994) proposed an analysis of such
systems in terms of a simple three stage pipeline.
More recently Cahill et al(1999) attempted to re-
peat the analysis, but found that while most sys-
tems did implement a pipeline, they did not im-
plement the same pipeline ? different functional-
ities occurred in different ways and different or-
ders in different systems. But this survey did
identify a number of core functionalities which
seem to occur during the execution of most sys-
tems. In order to accommodate this result, a ?pro-
cess model? was sketched which aimed to support
both pipelines and more complex control regimes
in a flexible but structured way (see (Cahill et al,
1999),(RAGS, 2000)). In this paper, we describe
our attempts to test these ideas in a simple NLG
application that is based on a concrete realisation
of such an architecture1 .
The RAGS data model aims to promote com-
parability and re-usability in the NLG research
community, as well as insight into the organisa-
tion and processing of linguistic data in NLG. The
present work has similar goals for the processing
aspects: to propose a general approach to organis-
ing whole NLG systems in a way which promotes
1More details about the RAGS project, the
RICHES implementation and the OASYS subsys-
tem can be found at the RAGS project web site:
http://www.itri.bton.ac.uk/projects/rags.
the same ideals. In addition, we aim to test the
claims that the RAGS data model approach sup-
ports the flexible processing of information in an
NLG setting.
2 The RAGS data model
The starting point for our work here is the RAGS
data model as presented in Mellish et al(2000).
This model distinguishes the following five levels
of data representation that underpin the genera-
tion process:
Rhetorical representations (RhetReps) define how propo-
sitions within a text are related. For example, the sen-
tence ?Blow your nose, so that it is clear? can be con-
sidered to consist of two propositions: BLOW YOUR
NOSE and YOUR NOSE IS CLEAR, connected by a re-
lation like MOTIVATION.
Document representations (DocReps) encode information
about the physical layout of a document, such as tex-
tual level (paragraph, orthographic sentence, etc.),
layout (indentation, bullet lists etc.) and their relative
positions.
Semantic representations (SemReps) specify information
about the meaning of individual propositions. For
each proposition, this includes the predicate and its
arguments, as well as links to underlying domain ob-
jects and scoping information.
Syntactic representations (SynReps) define ?abstract?
syntactic information such as lexical features (FORM,
ROOT etc.) and syntactic arguments and adjuncts
(SUBJECT, OBJECT etc.).
Quote representations These are used to represent literal
unanalysed content used by a generator, such as
canned text, pictures or tables.
The representations aim to cover the core com-
mon requirements of NLG systems, while avoid-
ing over-commitment on less clearly agreed is-
sues relating to conceptual representation on the
one hand and concrete syntax and document ren-
dering on the other. When one considers process-
ing aspects, however, the picture tends to be a lot
less tidy: typical modules in real NLG systems
often manipulate data at several levels at once,
building structures incrementally, and often work-
ing with ?mixed? structures, which include infor-
mation from more than one level. Furthermore
this characteristic remains even when one consid-
ers more purely functionally-motivated ?abstract?
NLG modules. For example, Referring Expres-
sion Generation, commonly viewed as a single
task, needs to have access to at least rhetorical and
document information as well as referencing and
adding to the syntactic information.
To accommodate this, the RAGS data model in-
cludes a more concrete representational proposal,
called the ?whiteboard? (Calder et al, 1999), in
which all the data levels can be represented in
a common framework consisting of networks of
typed ?objects? connected by typed ?arrows?. This
lingua franca allows NLG modules to manipulate
data flexibly and consistently. It also facilitates
modular design of NLG systems, and reusability
of modules and data sets. However, it does not in
itself say anything about how modules in such a
system might interact.
This paper describes a concrete realisation of
the RAGS object and arrows model, OASYS,
as applied to a simple but flexible NLG system
called RICHES. This is not the first such re-
alisation: Cahill et al, (2000) describes a par-
tial re-implementation of the ?Caption Generation
System? (Mittal et al, 1999) which includes an
objects and arrows ?whiteboard?. The OASYS
system includes more specific proposals for pro-
cessing and inter-module communication, and
RICHES demonstrates how this can be used to
support a modular architecture based on small
scale functionally-motivated units.
3 OASYS
OASYS (Objects and Arrows SYStem) is a soft-
ware library which provides:
  an implementation of the RAGS Object and
Arrows (O/A) data representation,
  support for representing the five-layer RAGS
data model in O/A terms,
  an event-driven active database server for
O/A representations.
Together these components provide a central core
for RAGS-style NLG applications, allowing sepa-
rate parts of NLG functionality to be specified in
independent modules, which communicate exclu-
sively via the OASYS server.
The O/A data representation is a simple
typed network representation language. An O/A
database consists of a collection of objects, each
of which has a unique identifier and a type, and
arrows, each of which has a unique identifier,
a type, and source and target objects. Such a
database can be viewed as a (possibly discon-
nected) directed network representation: the fig-
ures in section 5 give examples of such networks.
OASYS pre-defines object and arrow types re-
quired to support the RAGS data model. Two ar-
row types, el (element) and el(<integer>),
are used to build up basic network structures ?
el identifies its target as a member of the set rep-
resented by its source, el(3), identifies its tar-
get as the third element of the tuple represented
by its source. Arrow type realised by re-
lates structures at different levels of representa-
tion. for example, indicating that this SemRep
object is realised by this SynRep object. Arrow
type revised to provides for support for non-
destructive modification of a structure, mapping
from an object to another of the same type that
can be viewed as a revision of it. Arrow type
refers to allows an object at one level to indi-
rectly refer to an object at a different level. Object
types correspond to the types of the RAGS data
model, and are either atomic, tuples, sets or se-
quences. For example, document structures are
built out of DocRep (a 2-tuple), DocAttr (a set
of DocFeatAtoms ? feature-value pairs), DocRe-
pSeq (a sequence of DocReps or DocLeafs) and
DocLeafs.
The active database server supports multiple
independent O/A databases. Individual modules
of an application publish and retrieve objects and
arrows on databases, incrementally building the
?higher level?, data structures. Modules com-
municate by accessing a shared database. Flow
of control in the application is event-based: the
OASYS module has the central thread of execu-
tion, calls to OASYS generate ?events?, and mod-
ules are implemented as event handlers. A mod-
ule registers interest in particular kinds of events,
and when those events occur, the module?s hander
is called to deal with them, which typically will
involve inspecting the database and adding more
structure (which generates further events).
OASYS supports three kinds of events: pub-
lish events occur whenever an object or arrow is
published in a database, module lifecycle events
occur whenever a new module starts up or termi-
nates, and synthetic events ? arbitrary messages
passed between the modules, but not interpreted
by OASYS itself ? may be generated by mod-
ules at any time. An application starts up by ini-
tialising all its modules. This generates initialise
events, which at least one module must respond
to, generating further events which other modules
may respond to, and so on, until no new events
are generated, at which point OASYS generates
finalise events for all the modules and terminates
them.
This framework supports a wide range of archi-
tectural possibilities. Publish events can be used
to make a module wake up whenever data of a
particular sort becomes available for processing.
Lifecycle events provide, among other things, an
easy way to do pipelining: the second module in a
pipeline waits for the finalise event of the first and
then starts processing, the third waits similarly
for the second to finalise etc. Synthetic events
allow modules to tell each other more explicitly
that some data is ready for processing, in situa-
tion where simple publication of an object is not
enough.
RICHES includes examples of all three
regimes: the first three modules are pipelined us-
ing lifecycle events; LC and RE, FLO and REND
interact using synthetic events; while SF watches
the database specifically for publication events.
4 RICHES
The RICHES system is a simple generation sys-
tem that takes as input rhetorical plans and pro-
duces patient advice texts. The texts are intended
to resemble those found at the PharmWeb site
(http://www.pharmweb.net). These are
simple instructional texts telling patients how to
use certain types of medicines, such as nosedrops,
eye drops, suppositories etc.. An example text
from PharmWeb is shown in figure 1, alongside
the corresponding text produced by RICHES.
The main aim of RICHES is to demonstrate
the feasibility of a system based on both the RAGS
data model and the OASYS server model. The
modules collectively construct and access the data
representations in a shared blackboard space and
this allows the modules to be defined in terms of
their functional role, rather than say, the kind of
data they manipulate or their position in a pro-
cessing pipeline. Each of the modules in the sys-
 How to Use Nose Drops
1. Blow your nose gently, so that it is clear. 
  
2. Wash your hands. 
  
3. Unscrew the top of the bottle and draw some liquid into the dropper. 
  
4. Tilt your head back. 
  
5. Hold the dropper just above your nose and put the correct number of drops into your nostril. 
  
6. DO NOT let the dropper touch the inside of your nose. 
  
7. Keep your head tilted back for two to three minutes to help the drops run to the back of your nose. 
  
8. Replace the top on the bottle. 
 
KEEP ALL MEDICINES OUT OF THE REACH OF CHILDREN 
PharmWeb - Copyright?1994-2001. All rights reserved
  
  
Blow your nose so that it is clear. 
Wash your hands
Unscrew the top. Then draw the liquid into the dropper. 
Tilt your head back
Hold the dropper above your nose. Then put the drops into your nostril.
The dropper must not touch the inside.
Keep your head tilted back for two to three minutes so that the drops run to the back.
Replace the top on the bottle
Generated by RICHES version 1.0 (9/5/2001) on 9/5/2001 
?2001, ITRI, University of Brighton 
Figure 1: An example text from PharmWeb, together with the corresponding text generated by RICHES
tem is in itself very simple ? our primary interest
here is in the way they interact.
Figure 2 shows the structure of the system2.
The functionality of the individual modules is
briefly described below.
Rhetorical Oracle (RO) The input to the sys-
tem is a RhetRep of the document to be gen-
erated: a tree with internal nodes labelled with
(RST-style) rhetorical relations and RhetLeaves
referring to semantic proposition representations
(SemReps). RO simply accesses such a represen-
tation from a data file and initialises the OASYS
database.
Media Selection (MS) RICHES produces doc-
uments that may include pictures as well as text.
As soon as the RhetRep becomes available, this
module examines it and decides what can be il-
lustrated and what picture should illustrate it. Pic-
2The dashed lines indicate flow of information, solid ar-
rows indicate approximately flow of control between mod-
ules, double boxes indicate a completely reused module
(from another system), while a double box with a dashed
outer indicates a module partially reused. Ellipses indicate
information sources, as opposed to processing modules.
tures, annotated with their SemReps, are part of
the picture library, and Media Selection builds
small pieces of DocRep referencing the pictures.
Document Planner (DP) The Document Plan-
ner, based on the ICONOCLAST text planner
(Power, 2000) takes the input RhetRep and pro-
duces a document structure (DocRep). This
specifies aspects such as the text-level (e.g.,
paragraph, sentence) and the relative or-
dering of propositions in the DocRep. Its
leaves refer to SynReps corresponding to syntac-
tic phrases. This module is pipelined after MS,
to make sure that it takes account of any pictures
that have been included in the document.
Lexical Choice (LC) Lexical choice happens in
two stages. In the first stage, LC chooses the lex-
ical items for the predicate of each SynRep. This
fixes the basic syntactic structure of the proposi-
tion, and the valency mapping between semantic
and syntactic arguments. At this point the ba-
sic document structure is complete, and the LC
advises REND and SF that they can start pro-
cessing. LC then goes into a second phase, in-
TEXT
SENTENCE
RHETORICAL 
ORACLE
LEXICAL
FINALISER
RENDERER
LINGO
PICTURE
LIBRARY
SELECTION
MEDIUM FLO
LEXICON
CHOICE
OASYS
REFERRING
EXPRESSIONS
DOCUMENT
PLANNER
Figure 2: The structure of the RICHES system
terleaved with RE and FLO: for each sentence,
RE determines the referring expressions for each
noun phrase, LC then lexicalises them, and when
the sentence is complete FLO invokes LinGO to
realise them.
Referring Expressions (RE) The Referring
Expression module adapts the SynReps to add in-
formation about the form of a noun phrase. It de-
cides whether it should be a pronoun, a definite
noun phrase or an indefinite noun phrase.
Sentence Finaliser (SF) The Sentence Fi-
naliser carries out high level sentential organisa-
tion. LC and RE together build individual syntac-
tic phrases, but do not combine them into whole
sentences. SF uses rhetorical and document struc-
ture information to decide how to complete the
syntactic representations, for example, combin-
ing main and subordinate clauses. In addition, SF
decides whether a sentence should be imperative,
depending on who the reader of the document is
(an input parameter to the system).
Finalise Lexical Output (FLO) RICHES uses
an external sentence realiser component with its
own non-RAGS input specification. FLO provides
the interface to this realiser, extracting (mostly
syntactic) information from OASYS and convert-
ing it to the appropriate form for the realiser. Cur-
rently, FLO supports the LinGO realiser (Carroll
et al, 1999), but we are also looking at FLO mod-
ules for RealPro (Lavoie and Rambow, 1997) and
FUF/SURGE (Elhadad et al, 1997).
Renderer (REND) The Renderer is the module
that puts the concrete document together. Guided
by the document structure, it produces HTML for-
matting for the text and positions and references
the pictures. Individual sentences are produced
for it by LinGO, via the FLO interface. FLO actu-
ally processes sentences independently of REND,
so when REND makes a request, either the sen-
tence is there already, or the request is queued,
and serviced when it becomes available.
LinGO The LinGO realiser uses a wide-
coverage grammar of English in the LKB HPSG
framework, (Copestake and Flickinger, 2000).
The tactical generation component accepts in-
put in the Minimal Recursion Semantics formal-
ism and produces the target text using a chart-
driven algorithm with an optimised treatment of
modification (Carroll et al, 1999). No domain-
specific tuning of the grammar was required for
the RICHES system, only a few additions to the
lexicon were necessary.
5 An example: generation in RICHES
In this section we show how RICHES generates
the first sentence of the example text, Blow your
nose so that it is clear and the picture that accom-
panies the text.
The system starts with a rhetorical represen-
tation (RhetRep) provided by the RO (see Fig-
ure 3)3. The first active module to run is MS
3In the figures, labels indicate object types and the sub-
script numbers are identifiers provided by OASYS for each
which traverses the RhetRep looking at the se-
mantic propositions labelling the RhetRep leaves,
to see if any can be illustrated by pictures in the
picture library. Each picture in the library is en-
coded with a semantic representation. Matching
between propositions and pictures is based on the
algorithm presented in Van Deemter (1999) which
selects the most informative picture whose repre-
sentation contains nothing that is not contained in
the proposition. For each picture that will be in-
cluded, a leaf node of document representation is
created and a realised by arrow is added to it
from the semantic proposition object (see Figure
4).
  	


  



el(1) el(2)
  		
(motivation)
  	ffGenerating Vague Descriptions 
Kees  van  Deemter  
ITR I ,  Univers i ty  of  Br ighton  
Lewes Road,  Wat ts  Bu i ld ing 
Br ighton  BN2 4G J, Un i ted  K ingdom 
Kees. van. Deemter~itri. brighton, ac. uk 
Abst ract  
This paper deals with the generation of definite 
(i.e., uniquely referring) descriptions containing se- 
mantically vague expressions ('large', 'small', etc.). 
Firstly, the paper proposes a semantic analysis of 
vague descriptions that does justice to the context- 
dependent meaning of the vague expressions in 
them. Secondly, the paper shows how this semantic 
analysis can be implemented using a modification of 
the Dale and Reiter (1995) algorithm for the gener- 
ation of referring expressions. A notable feature of 
the new algorithm is that, unlike Dale and Reiter 
(1995), it covers plural as well as singular NPs. This 
algorithm has been implemented in an experimental 
NLG program using ProFIT. The paper concludes by 
formulating some pragmatic onstraints that could 
allow a generator to choose between different seman- 
tically correct descriptions. 
1 In t roduct ion :  Vague proper t ies  
and  Gradab le  Ad jec t ives  
Some properties can apply to an object to a greater 
or lesser degree. Such continuous, or vague proper- 
ties, which can be expressed by, among other pos- 
sibilities, gradable adjectives (e.g., 'small', 'large', 
e.g. Quirk et al 1972 sections 5.5 and 5.39), pose a 
difficult challenge to existing semantic theories, the- 
oretical as well as computational. The problems are 
caused partly by the extreme context-dependence of 
the expressions involved, and partly by the resis- 
tance of vague properties to discrete mathematical 
modeling (e.g., Synthese 1975, Pinkal 1995). The 
weight of these problems is increased by fact that 
vague expressions are ubiquitous in many domains. 
The present paper demonstrates how a Natural Lan- 
guage Generation (NLG) program can be enabled to 
-generate uniquely referring descriptions containing 
one gradable adjective, despite the vagueness of the 
adjective. Having presented a semantic analysis for 
such vague descriptions, we describe the semantic 
core of an NLG algorithm that has numerical data as 
input and vague (uniquely referring) descriptions as 
output. 
One property setting our treatment of vagueness 
apart from that in other NLC programs-(e.g. Gold- 
berg 1994) is that it uses ??vague properties for an 
exact task, namely the ruling out of distractors in 
referring expressions (Dale and Reiter 1995). An- 
other distinctive property is that our account allows 
the 'meaning' of vague expressions to be determined 
by a combination of linguistic ontext (i.e., the Com- 
mon Noun following the adjective) and nonlinguistic 
context (i.e., the properties of the elements in the 
domain). 
2 The  Mean ing  o f  Vague 
Descr ip t ions  
Several different analyses are possible of what it 
means to be, for example, 'large': larger than aver- 
age, larger than most, etc. But there is not necess- 
rily just one correct analysis. Consider a domain of 
four mice, sized 2,5,7, and 10cm. 1 In this case, for 
example, one can speak of 
1. The large mouse 
(= the one whose size is lOcm), and of 
2. The two large mice 
(= the two whose sizes are 7 and lOcm). 
Clearly, what it takes to be large has not been writ- 
ten in stone: the speaker may decide that 7cm is 
enough (as in (2)), or she may set the standards 
higher (as in (1)). A numeral (explicit, or implicit 
as in (1)), allows the reader to make inferences about 
the standards employed by the speaker3 More pre- 
cisely, it appears that in a definite description, the 
absolute form of the adjective is semantically equiv- 
alent with the superlative form: 
The n large mice - The largest n mice 
The large mice - The largest mice 
The large mouse - The largest mouse. 
1For simplicity, the adjectives involved will be assumed 
to be one-dimensional. Note that the degree of precision re- 
flected by the units of measurement affects the descriptions 
generated, and even the objects (or sets) that can  be de- 
scribed, since it determines which objects count as having 
the same size. 
2Thanks are due to Matthew Stone for this observation. 
179 
This claim, which has been underpinned by a small 
experiment with human subjects (see Appendix), 
means that if a sentence containing .one element of 
a pair is true then so is the corresponding sentence 
containing the other. There are bound to be differ- 
ences between the two forms, but these will be taken 
to be of a pragmatic nature, having to do with felic- 
ity rather than truth (see section 5.2). 
An important qualification must be made with re- 
spect to the analysis that we propose: to simplify 
matters, we assume that the entire domain of rele- 
vant individuals is: available -and ~ha'g it-is-:this d~:  
main alone which is taken into account when the ad- 
jective is applied. In the case of the example above, 
this means that all mice are irrelevant except the 
four that are mentioned: no other knowledge about 
the size of mice is assumed to be available. 3 
2.1 A Formal Semantics for Vague 
Descriptions 
Let us be more precise. In our presentation, we will 
focus on the adjective 'large', without intended loss 
of generality. For simplicity, 'large' will be treated 
as semantically one-dimensional. 
i. ' The  largest n mouse/mice ' .  Imagine a set 
C of contextually relevant animals. Then the NP 
'The largest n mouse/mice' (n > 0) presupposes 
that there is an S C_ C that contains n elements, 
all of which are mice, and such that (1) C - S ? ? 
and (2) every mouse in C - S is smaller than ev- 
ery mouse in S. If such a set S exists then the NP 
denotes S. The case where n = 1, realized as 'The 
\[Adj\]-est \[CN~g\]' (sg = singular), falls out automat- 
ically. 
ii. ' The  largest mice' .  This account can be 
extended to cover cases of the form 'The \[Adj\]-est 
\[CNpt\]' (pl = plural), where the numeral n is sup- 
pressed: these will be taken to be ambiguous be- 
tween all expressions of the form 'The \[Adj\]-est n 
\[CN\]' where n > 1. Thus, in a domain where there 
are five mice, of sizes 4,4,4,5,6 cm, the only possible 
value of n. is 2, causing the NP to denote the two 
mice of 5 and 6 cm size. 
iii. ' The  n large mouse/mice ' .  We analyse 'The 
n \[Adj\] \[CN\]' (n > 0) as semantically equivalent with 
the corresponding NP of the form 'The \[Adj\]-est n 
\[CN\]'. The two large mice', for example, denotes a 
set of two mice, each of which is bigger than all other 
contextually relevant mice. 
iv. ' The  large mice' .  Expressions of this form can 
be analysed as being of the form 'The n \[Adj\] \[CN\]' 
for some value of n. In other words, we will take 
aln other words, only perceptual context-dependence is 
taken into account, as opposed to no,'maltve or functional 
context-dependence Ebeling and Gehnan (1994). 
them to be ambiguous or unspecific - the difference 
will not matter for present purposes - between 'The 
.2 large mice', 'The 3. large mice', etc. 
3 Generation of Crisp Descriptions 
Generation of descriptions covers a number of tasks, 
one of which consists of finding a set L of properties 
which allows a reader to pick out a given unique in- 
dividual or set of individuals. The state of the art 
is discussed in Dale and Reiter (1995), who present 
a computationally tractable algorithm for character- 
:. izing~i~dividuods.x This,algorithm-(henceforth_D&R), 
deals with vague properties, such as size, to some 
extent, but these are treated as if they were context- 
independent: always applying to the same sets of 
objects. 
In many cases, generating vague descriptions in- 
volves generating a plural and no generally accepted 
account of the generation of plural descriptions has 
been advanced so far. In the following section, there- 
fore, a generalization or D&R will be offered, called 
D& RPlur, which focuses on sets of individuals. Char- 
acterization of an individual will fall out as a special 
case of the algorithm. 
3.1 Plural  Descriptions: Dale and Reiter 
general ized 
The properties which form the basis of D&Rpt~r are 
modeled as pairs of the form {Attribute,Value). In 
our presentation of the algorithm, we will focus on 
complete properties (i.e., (Attribute,Value) pairs) 
rather than attributes, as in Dale and Reiter (1995), 
since this facilitates the use of set-theoretic termi- 
nology. Suppose S is the 'target' set of individu- 
als (i.e., the set of individuals to be characterized) 
and C (where S C_ C) is the set of individuals from 
which S is to be selected. 4 Informally - and for- 
getting about the special treatment of head nouns - 
what happens is the following: Tile algorithm iter- 
ates through a list P in which the properties appear 
in order of 'preference'; for each attribute, it checks 
whether specifying a value for that attribute would 
rule out at least one additional member of C; if so, 
the attribute is added to L, with a suitable value. 
(The value can be optimized using some further con- 
straints but these will be disregarded here.) Individ- 
uals that are ruled out by a property are removed 
from C. The process of expanding L and contracting 
C continues until C = S. The properties in L can 
be used by a linguistic realization module to pro- 
duce NPs such as 'The white mice', 'The white mice 
? that arepregnant', etc. Schematically, the algorithm 
goes as follows: (Notation: Given a property Q, the 
set of objects that have the property Q is denoted 
\[\[o\]\].) 
? 1Note that C contains r, unlike Dale and Reiter's 'contrast 
set'  C, which consists of those elements of the domain from 
which r is set apart. 
180 
L := (D {# L is initialized to the empty set #} 
For each Pie P do 
If S C_ \[\[Pi\]\] ~ :C ~ '\[l~Pi\]\] {# Adding Pi 
would remove distractors from C #} 
then do 
L := L O {Pi} {# Property Pi is added 
to L #} 
C := C n \[\[P~\]\] {# All elements outside 
\[\[Pi\]\] are removed from C #} 
If C = S then Return L {# Success #} 
Return Failure-'{S,d: All-properties in Phave  been 
tested, yet C -7= S ~ } 
of one vague property. Case i of section 2.1, 'The 
largest n chihuahuas' will be discussed in some de- 
tail. All the others are minor variations. 
'Success' means that the properties in L are suffi- 
cient to characterize S. Thus, ~{\[\[Pi\]\] : Pie L} = S. 
The case in which S is a singleton set amounts to 
the generation of a singular description: D~RPIur 
becomes equivalent to D&R (describing the individ- 
ual r) when S in D&aPlur is replaced by {r}. 
D&RPlu r uses hill climbing: an increasingly good 
approximation of S is achieved with every contrac- 
tion of C. Provided the initial C is finite, D&apt~,- 
finds a suitable L if there exists one. Each property 
is considered at most once, in order of 'preference'. 
As a consequence, L can contain semantically redun- 
dant properties - causing the descriptions to become 
more natural, of. Dale and Reiter 1995 - and the al- 
gorithm is polynomial in the cardinality of P. 
Caveats. D&RPtur does not allow a generator to in- 
clude collective properties in a description, as in 'the 
two neighbouring houses', for example. Furthermore, 
D~l-tPlur cannot be employed to generate conjoined 
NPs: It generates NPs like 'the large white mouse' 
but not 'tile black cat and the large white mouse'. 
From a general viewpoint of generating descriptions, 
this is an important limitation which is, moreover, 
difficult to overcome in a computationally tractable 
account. In the present context, however, the lim- 
itation is inessential, since what is crucial here is 
the interaction between an Adjective and a (possibly 
complex) Common Noun following it: in more com- 
plex constructs of the form 'NP and the Adj CN', 
only CN affects the meaning of Adj. 5 There is no 
need for us to solve the harder problem of finding an 
efficient algorithm for generating NPs uniquely de- 
scribing arbitrary sets of objects, but only the easier 
problem of doing this whenever a (nonconjunctive) 
NP of the form 'tile Adj CN' is possible. 
4 Generat ion  o f  Vague Descr ip t ions  
\Ve nOw turn our attention to extensions of D&RPlur 
that generate descriptions containing the expression 
~\[n "The elephant and the big mous(,', for example, the 
mouse does not have to be bigger than any elephant. 
Super la t ive  adject ives.  First, 'The largest chi- 
huahua'. We will assume that s i ze  is stored (in the 
KB that forms the input to the generator) as an at- 
tribute with exact numerical values. We will take 
them to be of the form n crn, where n is a positive 
natural number. For example, 
type = dog, chihuahua 
? co.lou_v ~_blac, k~ blue, yellow 
s i ze  = lcm, 2cm, ..., 10cm. 
With this KB as input, D~R allows us to generate 
NPs based on L = {yellow,chihuahua,9~n}, for ex- 
ample, exploiting the number-valued attribute s ize.  
The result could be the NP 'The 9cm yellow chi- 
huahua', for example. The challenge, however, is 
to generate superlatives like 'The largest yellow chi- 
huahua' instead. 
There are several ways in which this challenge 
may be answered. One possibility is to replace 
an exact value like 9cm, in L, by a superlative 
value whenever all distractors happen to have a 
smaller size. The result would be a new list L = 
{yellow,chihuahua,largestl}, where ' largestt' is the 
property 'being the unique largest element of C'. 
This list can then be realized as a superlative NP. 
We will present a different approach that is more 
easily extended to plurals, given that a plural de- 
scription like 'the 2 large mice' does not require the 
two mice to have the same size. 
Suppose s i ze  is the only vague property in the KB. 
Vague properties are less 'preferred' (in the sense 
of section 3.1) than others (Krahmer and Theune 
1999).6 As a result, when they are taken into consid- 
eration, all tile other relevant properties are already 
in L. For instance, assume that this is the KB, and 
that the object to be described is c4: 
type(cl, c~. c3, c,l) =chihuahua 
type(ph) =poodle 
size(c1 )=3cnl  
size(c.2)=hcnl 
size(ca)=8cm 
size(c4) =size(ps) =9cm 
At this point, inequalities of tile form size(x) > 
m cm are added to the KB. For every value of 
,the form n ~n oecuring in-the oldKB, all..inequat- 
ities of the form size(x) > n an are added whose 
truth follows from the old I<B. Inequalities are more 
6Note, by contrast, that vague properties tend to be real- 
ized first (Greenbaum et al 1985, Shaw and Hatzivassiloglou 
1999). Surface realization, however, is not the topic of lids 
paper. 
181 
preferred than equalities, while logicaUy stronger in- 
equalities are more preferred than logically weaker 
ones. 7 Thus, in order of preference . . . .  
size(c4),size(ps) > 8cm 
size(c3),size(c4),size(ps) > 5cm 
size (c2),size(ca ),size(c4 ),size(p5) > 3cm. 
The first property that makes it into L is 'chi- 
huahua', which removes Ps but not ca from the con- 
text set. (Result: C = {cl,...,c4}.) Now size is 
taken into account, and the property size(x) > 8cm 
singles out c4..The .resulting.listA s L =,~cchihuahua , 
> 8cm}. This implies that c4 is the only chihuahua 
in the KB that is greater than 8cm and consequently, 
the property size(x) > 8cm can be replaced, in L, by 
the property of 'being larger than all other elements 
of C'. The result is a list that may be written as 
L = {chihuahua, largesh }, which can be employed 
to generate the description 'the largest chihuahua'. 
Plurals can be treated along analogous lines. Sup- 
pose, for example, the facts in the KB are the same 
as above and the target set S is {ca, c4}. Its two ele- 
ments share the property size(x) > 5cm. This prop- 
erty is exploited by n&Rm~ to construct he list 
L = {chihuahua,>5cm}. Analogous to the singular 
case, the inequality can be replaced by the property 
'being a set al of whose elements are larger than 
all other elements of C' (largestm for short), leading 
to NPs such as 'the largest chihuahuas'. Optionally, 
the numeral may be included in the NP ('the two 
largest chihuahuas'). 
- 'Abso lu te '  adject ives.  The step from the su- 
perlative descriptions of case i to the analogous 'ab- 
solute' descriptions i a small one. Let us first turn 
to case iii, 'The n large mouse/mice'. Assuming the 
correctness of the semantic analysis in section 2, the 
NP 'The n large mouse/mice' is semantically equiv- 
alent to the one discussed under i. Consequently, 
an obvious variant of the algorithm that was just 
described can be used for generating it. (For prag- 
matic issues, see section 5.2) 
Finally. case iv, 'The large mice'. Semantically, 
this does not introduce an 3" new problems, since 
it is to case i i i  what case i i  is to case i. Accord- 
ing to the semantic analysis of section 2.1 'The 
large mice' should be analysed just like 'The n large 
mouse/mice', except that the muneral n is sup- 
pressed. This means that a simplified version (i.e., 
without a cardinality check) of the algorithm that 
takes care of case i i i  will be sufificient to generate 
descriptions of this kind. 
rE .g ,  size(x) > m is preferred over sZze(x) > n iff m > n. 
The  preference for inequal i t ies  causes the generator  to avoid  
the ment ion ing  of measurements  unless they are needed for 
the ident i f icat ion ~ff the target  object .  
5 Conc lus ions  and  loose  ends  
We have shown how vague descriptions can be gen- 
.. ~erated .that'.make.use-of-one vague-propeift~. We be- 
lieve our account o be an instructive model of how 
the 'raw data' in a standard knowledge base can be 
presented in English expressions that have a very dif- 
ferent structure. The numerical data that are the in- 
put to our algorithm, for example, take a very differ- 
ent form in the descriptions generated, and yet there 
is, in an interesting sense, no loss of information: a 
description has the same reference, whether it uses 
? ...:,..exaet~.anforroataon:(~he:3c~zz.mouse.) ~or ...~ague:. m,-- 
formation ('The large mouse'), s 
5.1 L imi ta t ions  o f  the  semant ic  ana lys i s  
Our proposal covers the generation of vague descrip- 
tions 'from absolute values', which is argued in Dale 
and Reiter (1995, section 5.1.2) to be most practi- 
cally useful. When vague input is available (e.g., in 
the generation component of a Machine Translation 
system, or in WVSlWYM-style generation (Power and 
Scott 1998)), simpler methods can be used. Our own 
account is limited to the generation of definite de- 
scriptions and no obvious generalization to indefinite 
or quantified NPs exists. Other limitations include 
a. Descriptions that contain properties for other 
than individuating reasons (as when someone 
asks you to clean 'the dirty table cloth' when 
only one table cloth is in sight). This limitation 
is inherited directly from the D&R algorithm 
that our own algorithm extends. 
b. Descriptions containing more than one vague 
property, such as 'The fat tall bookcase', whose 
meaning is more radically unclear than that of 
definite descriptions containing only one vague 
term. (The bookcase may be neither the fattest 
nor the tallest, and it is not clear how the two 
dimensions are weighed.) 
c. Descriptions that rely on the salience of con- 
textually available objects. Krahmer and The- 
une (1998) have shown that a contextually 
more adequate version of D~:R can  be obtained 
when degrees of salience are taken into account. 
Their account can be summarized as analysing 
'the black dog' as denoting the unique most 
salient object in the domain that is both black 
and a dog. (Generalizations of this idea to 
D&Rmu~ are conceivable but nontrivial since 
not all elements of the set S have to be equally 
salient.) Our own extensions of D&R (and per- 
haps O&Rmu~) could be 'contextualized' if the 
SThis  may be contrasted w i th  the vague express ions  gem 
crated in (Goldberg et al 1994), where  there is a real -- and 
intended Ioss of in format ion.  (E.g. ,  'Heavy  rain fell on Tues- 
day',  bmsed on the in format ion  that  the rainfal l  on 'lhlesday 
equal led ,15rnm.) 
182 
role of salience is changed slightly: focusing on 
the singular case, the algorithm can, for exam- 
ple, be adapted, to, legislate.that:'the, large(est) : 
mouse' denotes the largest of all those mice 
that are salient (according to some standard of 
salience). Note that this analysis predicts am- 
biguity when the largest mouse that is salient 
according to one standard is smaller than the 
largest mouse that is salient according to a more 
relaxed standard. Suppose, for example, 
then 'the large(est) mouse' may designate i- 
ther m2 or m3 depending on the standards 
of salience used. What this illustrates is that 
salience and size are both vague properties, and 
that - as we have seen under point b - combin- 
ing vague properties is a tricky business. 
5.2 Pragmatics 
An experimental ProFIT (Erbach 1995) program has 
implemented the algorithms described so far, gen- 
erating different descriptions, each of which would 
allow a reader/hearer to identify an object or a set 
of objects. But of course, an NLG program has to do 
more than determine under what circumstances the 
use of a description leads to a true statement: an 
additional problem is to choose the most appropri- 
ate description from those that are semantically cor- 
rect. This makes NLG an ideal setting for exploring 
issues that have plagued semanticists and philoso- 
phers when they studied the meaning of vague ex- 
pressions, such as whether it can be true for two 
objects x and y which are indistinguishable in size 
that x is large and y is not (e.g. Synthese 1975). 
The present setting allows us to say that a statement 
of this kind may be true yet infelicitous (because 
they conflict with certain pragmatic onstraints), 
and consequently to be avoided by a generator. 
As for the choice between the 'absolute'/superlative 
forms of the gradable adjective, we conjecture that 
the following constraints apply: 
C1. Dist inguishabi l i ty .  Expressions of the form 
'The (n) large \[CN\]'  are infelicitous when the 
smallest element of the designated set S (named 
x) and the largest CN smaller than all elements 
of S (named y) are perceptually indistinguish- 
able. 
C2. Natura l  Group ing .  Expressions of the form 
'The (n) large \[CN\]' are better avoided when the 
difference in size between x and y is 'compara- 
t i veh  small. One way of making this precise is 
by requiring that the difference hetween x and 
C3. 
y cannot be smaller than that between either 
x or y and one of their neighbouring elements. 
Consider, for. example,.: a domain .consisting .of 
mice that are lcm, lcm, 2cm, 7cm, 9cm and 
9cm large; then C2 predicts that the only felic- 
itous use of 'the large mice' refers to the largest 
three of the group. 
Min imal i ty .  Otherwise, preference is given to 
the absolute form. This implies that when ob- 
jects of only two sizes are present, and the differ- 
Salient (strict): ence is perceptually distinguishable, the abso- 
ml  (2em);,m~.(Scm) . . . . . . . . . . . . . . . .  ~ ? : .,~.~Ante~formds~pr.eferEedover:t~hes~perta'~iv~fovm. 
Salient ( re laxed):  (For example, in a domain where there are two 
ml (2cm), m2 (5cm), m3 (7cm); sizes of pills, we are much more likely to speak 
of 'the large pills' than of 'the largest pills'.) 
In languages in which the superlative form is 
morphologically more complex than the abso- 
lute form, constraint C3 can be argued to follow 
from general Gricean principles (Grice 1975)). 
As for the presence/absence of the numeral, we 
conjecture that the disambiguating numeral (as 
in 'the n large mice' or 'the n largest mice') can 
be omitted under two types of circumstances: (1) 
when any ambiguity resulting from different values 
of n is likely to be inconsequential (see Van Deemter 
and Peters (1996) for various perspectives); (2) 
when the domain allows only one 'natural grouping' 
(in the sense of C2). Before and until a more 
accurate version of the notion of a natural grouping 
is available (perhaps using fuzzy logic as in Zim- 
mermann 1985), generators could be forbidden to 
omit the numeral, except in the case of a definite 
description in the singular. 
Append ix :  A Suppor t ing  Exper iment  
Human subjects were asked to judge the correctness 
of an utterance in a variety of situations. The ex- 
periment was set up to make plausible that, in a sit- 
uation in which only perceptual context-dependence 
(see section 1) is relevant, expressions of the form 
'the n. large CN' can be used whenever certain sim- 
ple conditions are fullfilled. Note that this (0 )  di- 
rection of the hypothesis is most directly relevant 
to the design of a generator, since we expect a gen- 
erator to avoid mistakes rather than ahvays use an 
expression whenever it is legitimate. 
Hypothesis (=>): In a situation in which 
the domain D represents the set of percep- 
tually relevant objects, an expression of the 
form 'the n large CN' (where n 2 1), can 
be used to refer to a set S of cardinality n 
if all objects in D - S are smaller than anv 
of the n.. 
183 
The experiment explores whether 'the n large CN' 
can refer to the n largest objects in the domain, 
whether or not this set of objects is held together by 
spatial position or other factors. Subjects were pre- 
sented with 26 different situations, in each of which 
they had to say whether the sentence 
The two high numbers appear in brackets 
would constitute a correct utterance. The literal text 
of our question was: 
Suppose you want to inform a hearer 
*.which numbers:.,irr~'a:,gi~ren.list:,appeav in- 
brackets*, where the hearer knows what 
the numbers are, but not which of them ap- 
pear in brackets. For example, the hearer 
knows that the list is 1 2 1 7 7 1 1 3 1. 
You, as a speaker, know that only the 
two occurrences of the number 7 appear 
in brackets: 1 2 1 (7) (7) 1 1 3 1. Our 
question to you is: Would it be *correct* 
to convey this information by saying "The 
two high numbers appear in brackets"? 
(...). 
All subjects were shown the 26 situations in the 
same, arbitrary, order. Each situation presented to 
the subjects contained a list of nine numbers. In 24 
cases, the lists had the following form: 
l l l xyz l l l ,  
where each of x, y, z equalled either 6 or 9, and where 
there were always two numbers among x, y, z that 
appear in brackets. In 16 out of 24 cases, the two 
bracketed positions are right next to each other, al- 
lowing us to test whether spatial contiguity' plays 
any role. Subjects were presented with two addi- 
tional situations, namely 1 1 1 (6) 1 (7) 1 1 1 and 
1 1 1 (7) 1 (6) 1 1 1 in which, unlike the other 24 
situations, the two largest numbers are not equally 
large, to make sure that the descriptions do not re- 
quire the elements in their denotation to be similar 
in that respect. Our questions were presented via 
email to 30 third-year psychology/cognitive science 
students at the University of Durham. UK. all of 
whom were native speakers of English and ten of 
which responded. 
Resu l ts :  Eight subjects responded in exact confor- 
mance with the analysis of section 2.1, marking all 
and only those five sequences in which the highest 
2 numbers appeared in brackets. Only two subjects 
deviated slightly from this analysis: one of the two 
(subject 9) described all the expected situations as 
'correct' plus the two cases in which two contiguous 
6-es appeared in brackets: the other subject (subject 
10) appears to have made a typing err~n, confusing 
two subsequent situations in the experiment? All 
other responses of subjects 9 and 10 were as pre- 
dicted. This means: tha t all .sub.jects except subject 
10 were consistent with our '=#' hypothesis. The ex- 
periment suggests that the converse of the hypoth- 
esis might also be true, in which it is claimed that 
expressions of the form 'the n large CN' cannot be 
employed to refer to the set S unless S consists of 
the n largest objects in D: 
Hypothesis (.?=): In a situation in which 
the domain D represents the set of percep- 
t_..: .......... ~ ~.t.ually: relevmtt, ob_jects>a~:-expressionof t~he.
form 'the n large CN' (where n _> 1), can 
only be used to refer to a set S of cardi- 
nality n if all objects in D - S are smaller 
than any of the n. 
Again disregarding subject 10, eight out of nine 
subjects act in accordance with Hypothesis .?=, 
while only one appears to follow a somewhat more 
liberal rule. Given these findings, it appears to 
be safe to build a generator that implements both 
hypotheses, since none of our subjects would be 
likely to disagree with any of the descriptions 
generated by it. 
This experiment has evident limitations. In partic- 
ular, it has no bearing on the pragmatic onstraints 
suggested in section 5.2, which might be tested in a 
follow-up experiment. 
Acknowledgements 
Thanks are due to: Richard Power for discussions 
and implementation; Emiel Krahmer, Ehud Reiter 
and Matthew Stone for comments on an earlier 
draft; Hua Cheng for observations on linguistic 
realization; Rosemary Stevenson and Paul Piwek 
for their help with the experiment described in the 
Appendix. 
6 References  
- Dale and Reiter 1995. R. Dale and E. Reiter. Con> 
putationat Interpretations of the Gricean Maximes 
in the Geueration of Referring Expressions. Co.qni- 
tive Science 18: 233-263. 
- Ebeling and Gelrnan 1994. Ebeling, K.S.. Gehnan 
S.A. 1994. Children's use of context in interpreting 
"big" and "little". Child Development 65(4): 1178- 
1192. 
- Erbach 1995. G. Erbach. Web page on the ProFIT 
9The s i tuat ions  that  we suspect  to  have  been confused  are  
1 1 1 (9) (9) 9 1 1 1, wh ich  was  marked  as cor rec t  (a l though,  
remarkab ly ,  none of the  o ther  ' th ree  n ines '  s i tuat ions  were  
marked  as cor rec t )  and  1 I 1 (9) (9} 6 1 1 I. 
184 
programming language, http://coli.uni-sb.de/ r- 
bach/formal/profit/profit.html. 
.... Goldberg et al 1994. E .  Goldberg,.tN. Driedger, 
and R. Kitteridge. Using Natural-Language Pro- 
cessing to Produce Weather Forecasts. mEE Expert 
9 no.2: 45-53. 
- Greenbaum et al 1985. "A Comprehensive Gram- 
mar of the English Language". Longman, Harlow, 
Essex. 
- Grice 1975. P. Grice. Logic and Conversation. 
In P. Cole and J. Morgan (Eds.), "Syntax and Se- 
mantics: Vol 3, Speech Acts"!- 43~-58. New Ym'k, 
Academic Press. 
- Krahmer and Theune 1999. E. Krahmer and M. 
Theune. Generating Descriptions in Context. In 
R. Kibble and K. van Deemter (Eds.), Procs. of 
workshop The Generation of Nominal Expressions, 
associated with the l l th  European Summer School 
in Logic, Language, and Information (ESSLLI'99). 
- Pinkal 1995. M. Pinkal. "Logic and Lexicon". Ox- 
ford University Press. 
- Power and Scott 1998. R. Power and D. Scott. 
Multilingual Authoring using Feedback Texts. In 
Proc. COLING/ACL, Montreal. 
- Quirk et al 1972. R. Quirk, S. Greenbaum, and 
G. Leech. "A Grammar of Contemporary English". 
Longman, Harlow, Essex. 
- Shaw and Hatzivassiloglou 1999. Ordering Among 
Premodifiers. In Proes. of ACL99, Univ. Maryland. 
- Synthese 1975. Special issue of the journal Syn- 
these on semantic vagueness. Synthese 30. 
- Van Deemter and Peters 1996. K. van Deemter 
and S. Peters (Eds.) "Semantic Ambiguity and Un- 
derspecification". CSLI Publications, Stanford. 
- Zimmermann 1985. H. J. Zimmermann. "Fuzzy 
Set Theory - and its Applications". Kluwer Aca- 
demic Publishers, Boston/Dordrecht/Lancaster. 
185 
Logical Form Equivalence:
the Case of Referring Expressions Generation
Kees van Deemter
ITRI
University of Brighton
Brighton BN2 4GJ
United Kingdom
Kees.van.Deemter@itri.brighton.ac.uk
Magnu?s M. Halldo?rsson
Computer Science Dept.
University of Iceland,
Taeknigardur, 107 Reykjavik, Iceland
and Iceland Genomics Corp., Reykjavik
mmh@hi.is
Abstract
We examine the principle of co-
extensivity which underlies current al-
gorithms for the generation of referring
expressions, and investigate to what ex-
tent the principle allows these algo-
rithms to be generalized. The discus-
sion focusses on the generation of com-
plex Boolean descriptions and sentence
aggregation.
1 Logic in GRE
A key question regarding the foundations of Nat-
ural Language Generation (NLG) is the problem
of logical form equivalence (Appelt 1987). The
problem goes as follows. NLG systems take se-
mantic expressions as input, usually formulated
in some logical language. These expressions are
governed by rules determining which of them
count as ?equivalent?. If two expressions are
equivalent then, ideally, the NLG program should
verbalize them in the same ways. (Being equiv-
alent, the generator would not be warranted in
distinguishing between the two.) The question
is: what is the proper relation of equivalence?
Appelt argued that classical logical equivalence
(i.e., having the same truth conditions) is not a
good candidate. For example,    is logi-
cally equivalent with      , yet ? so the argu-
ment goes ? an NLG system should word the two
formulas differently. Shieber (1993) suggested
that some more sophisticated notion of equiva-
lence is needed, which would count fewer seman-
tic expressions as equivalent.1 In the present pa-
per, a different response to the problem is ex-
plored, which keeps the notion of equivalence
classical and prevents the generator from distin-
guishing between inputs that are logically equiva-
lent (i.e., inputs that have the same truth condi-
tions). Pragmatic constraints determine which
of all the logically equivalent semantic expres-
sions is put into words by the NLG program.
Whereas this programme, which might be called
?logic-oriented? generation, would constitute a
fairly radical departure from current practice if
applied to all of NLG (Krahmer & van Deemter
(forthcoming); Power 2000 for related work), the
main aim of the present paper is modest: to show
that logic-oriented generation is standard prac-
tice in connection with the generation of referring
expressions (GRE). More specifically, we show
the semantics of current GRE algorithms to be
guided by a surprisingly simple principle of co-
extensivity, while their pragmatics is guided by
Gricean Brevity.
Our game plan is as follows. In section 2, we
illustrate the collaboration between Brevity and
co-extensivity, focussing on ?simple? referring ex-
pressions, which intersect atomic properties (e.g.,
?dog? and ?black?). Section 3 proceeds by show-
ing how other algorithms use the principle to le-
gitimize the creation of more elaborate structures
involving, for example, complex Boolean combi-
nations (e.g., the union of some properties, each
of which is the intersection of some atomic prop-
1See also van Deemter (1990) where, on identical
grounds, a variant of Carnap-style intensional isomorphism
was proposed as an alternative notion of equivalence.
erties). This part of the paper will borrow from
van Deemter (2001), which focusses on compu-
tational aspects of GRE. Section 4 asks how the
principle of co-extensivity may be generalized be-
yond GRE and questions its validity.
2 Intersective reference to sets of
domain objects
The Knowledge Base (KB) forming the input to
the generator will often designate objects using
the jargon of computerized databases, which is
not always meaningful for the reader/hearer. This
is true, for example, for an artificial name (i.e.,
a database key) like ?  
	 ? when a per-
son?s proper name is not uniquely distinguishing;
it is also true for objects (e.g., furniture, trees,
atomic particles) for which no proper names are
in common usage. In all such cases, the NLG pro-
gram has to ?invent? a description that enables the
hearer to identify the target object. The program
transforms the original semantic structure in the
KB into some other structure.
Let us examine simple references first. Assume
that the information used for interpreting a de-
scription is stored in a KB representing what
properties are true of each given object. In ad-
dition to these properties, whose extensions are
shared between speaker and hearer, there are
other properties, which are being conveyed from
speaker to hearer. For example, the speaker may
say ?The white poodle is pregnant?, to convey the
new information that the referent of ?the white
poodle? is pregnant. GRE ?sees? the first, shared
KB only. We will restrict attention to the prob-
lem of determining the semantic content of a de-
scription, leaving linguistic realization aside. (Cf.
Stone and Webber 1998, Krahmer and Theune
1999, which interleave linguistic realization and
generation.) Accordingly, ?Generation of Refer-
ring Expressions? (GRE) will refer specifically to
content determination. We will call a GRE algo-
rithm complete if it is successful whenever an in-
dividuating description exists. Most GRE algo-
rithms are limited to individual target objects (for
an exception, Stone 2000), but we will present
ones that refer to sets of objects (Van Deemter
2000); reference to an individual  will equal ref-
erence to the singleton set  .
2.1 The Incremental Algorithm
Dale and Reiter (1995) proposed an algorithm
that takes a shared KB as its input and delivers a
set of properties which jointly identify the target.
Descriptions produced by the algorithm fullfill
the criterion of co-extensivity. According to this
principle, a description is semantically correct if
it has the target as its referent (i.e., its extension).
The authors observed that a semantically correct
description can still be unnatural, but that natural-
ness is not always easy to achieve. In particular,
the problem of finding a (?Full Brevity?) descrip-
tion that contains the minimum number of prop-
erties is computationally intractable, and human
speakers often produce non-minimal descriptions.
Accordingly, they proposed an algorithm that ap-
proximates Full Brevity, while being of only lin-
ear complexity. The algorithm produces a finite
set  of properties Generating Referring Expressions:
Making Referents Easy to Identify
Ivandre? Paraboni?
EACH, University of Sa?o Paulo
Kees van Deemter??
Computing Science Department,
University of Aberdeen
Judith Masthoff?
Computing Science Department,
University of Aberdeen
It is often desirable that referring expressions be chosen in such a way that their referents are easy
to identify. This article focuses on referring expressions in hierarchically structured domains,
exploring the hypothesis that referring expressions can be improved by including logically
redundant information in them if this leads to a significant reduction in the amount of search
that is needed to identify the referent. Generation algorithms are presented that implement this
idea by including logically redundant information into the generated expression, in certain well-
circumscribed situations. To test our hypotheses, and to assess the performance of our algorithms,
two controlled experiments with human subjects were conducted. The first experiment confirms
that human judges have a preference for logically redundant expressions in the cases where our
model predicts this to be the case. The second experiment suggests that readers benefit from the
kind of logical redundancy that our algorithms produce, as measured in terms of the effort needed
to identify the referent of the expression.
1. Introduction
Common sense suggests that speakers and writers who want to get their message across
should make their utterances easy to understand. Broadly speaking, this view is con-
firmed by empirical research (Deutsch 1976; Mangold 1986; Levelt 1989; Sonnenschein
1982, 1984; Clark 1992; Cremers 1996; Arts 2004). The present article will examine its
consequences for the generation of referring expressions (GRE). In doing this, we dis-
tinguish between two aspects of the ?understanding? of a referring expression, which
we shall denote by the terms interpretation and resolution. We take interpretation to
be the process whereby a hearer/reader determines the meaning or logical form of the
? Av.Arlindo Bettio, 1000 - 03828-000, Sa?o Paulo, Brazil. E-mail: ivandre@usp.br.
?? King?s College, Meston building, Aberdeen AB24 3UE, Scotland, UK. E-mail: kvdeemte@csd.abdn.ac.uk.
? King?s College, Meston building, Aberdeen AB24 3UE, Scotland, UK. E-mail: jmasthoff@csd.abdn.ac.uk.
Submission received: 17 February 2004; revised submission received: 27 July 2006; accepted for publication:
7 December 2006.
? 2007 Association for Computational Linguistics
Computational Linguistics Volume 33, Number 2
referring expression; we take resolution to be the identification of the referent of the
expression once its meaning has been determined. It is resolution that will take center
stage in our investigation.
Difficulty of resolution and interpretation do not always go hand in hand. Consider
sentences (1a)?(1c), uttered somewhere in Brighton but not on Lewes Road. The de-
scription in (1a) is longer (and might take more time to read and interpret) than (1b), but
the additional material in (1a) makes resolution easier once interpretation is successfully
completed.
(1a) 968 Lewes Road, Moulsecoomb area
(1b) 968 Lewes Road
(1c) number 968
The first two of these descriptions refer uniquely. As for the third: Lewes Road is a long
street. Supposing that other streets in Brighton do not have numbers above 900, then
even (1c) is a unique description?but a pretty useless one, because it does not help you
to find the house unless your knowledge of Brighton is exceptional. We will explore how
a natural-language-generation (NLG) program should make use of logically redundant
properties so as to simplify resolution (i.e., the identification of the referent). When we
write about identifying or ?finding? the referent of a referring expression, we mean this
in the sense of determining which object is the intended referent. This conceptual goal
may or may not require the hearer to make a physical effort, for example by turning the
pages of a book, or more dramatically by walking and waiting for traffic lights.
The fact that referring expressions tend to contain logically redundant information
has been observed in many empirical studies. Levelt (1989), for example, mentions
the need for redundancy in situations of ?degraded communication? (e.g., background
noise); and even in normal situations, redundant nondiscriminating information can
help the addressee identify the referent (Deutsch 1976; Mangold 1986; Sonnenschein
1982, 1984; Arts 2004). In Levelt?s words, psycholinguistic experiments show that
[l]isteners apparently create a ?gestalt? of the object for which they have to search. It is
harder to search for ?something red? than for ?a big red bird?, even if the color would be
sufficiently discriminating. Information about the kind of object to be looked for (e.g., a
bird) is especially helpful for constructing such a gestalt. (Levelt 1989, page 131)
Although early GRE algorithms have often followed the Gricean maxim, ?be brief?
(Grice 1975), by minimizing the number of properties in a generated description, Dale
and Reiter (1995) proposed an algorithm that allows certain redundancies, for example,
by guaranteeing that each generated description expresses the ontological ?type? of the
referent, in the form of a noun, a move that addresses Levelt?s claim to some extent.1
In corpus-based studies, it has been shown that logically redundant properties tend
to be included when their inclusion fulfils one of a number of pragmatic functions,
such as to indicate that a property is of particular importance to the speaker (i.e., it
constitutes one of her reasons for being interested in the referent) or to highlight the
1 Dale and Reiter (1995, Section 5) also mention the use of ?navigational? (or ?attention-directing?)
information in referring expressions, which they distinguish from ?discrimination information,? and
whose function appears to be to move the attention of the reader/hearer towards an object. The concept
is not defined precisely and it is not clear how navigational information should be used in GRE.
230
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
speaker?s awareness that the referent has the property in question (Jordan 2000, 2002).
Implementations of such findings in NLG are not difficult to envisage.
The present article takes this reader-oriented perspective on the redundancy of
referring expressions a step further, by asking how a generator can use logically re-
dundant information to reduce the search space within which a reader has to ?find? a
referent; this will be specifically useful when referents need to be found in situations
where the extensions of some of the properties are not known to the reader/hearer
in advance (cf., Edmonds [1994] for a related set of problems) and where some effort
may be needed to identify the referent. By focusing on the information needs of the
hearer/reader, our work, a further development of Paraboni and van Deemter (2002a)
that also takes the results of Paraboni, Masthoff, and van Deemter (2006) into account,
addresses an issue that lies close to the heart of NLG as a practical enterprise, whose
purpose is, after all, to make information accessible to people. These issues originally
came to the fore while studying references to parts of documents (Paraboni 2000, 2003;
Paraboni and van Deemter 2002a, 2002b) but their relevance extends to many other
situations. Our findings will also shed light on the egocentricity debate among psy-
cholinguists about the extent to which speakers take hearer?s knowledge into account
when they speak (Keysar, Lin, and Barr 2003). Throughout the article, we shall focus
on issues of Content Determination (as opposed to, for example Lexical Choice), and
on the situations in which individuals are first mentioned (as opposed to ones in
which linguistic context allows them to be shortened [e.g., Krahmer and Theune 2002;
Siddharthan and Copestake 2004]).
2. Ease of Resolution in the Incremental Algorithm
Generation of referring expressions (GRE) is a key task of NLG systems (e.g., Reiter and
Dale 2000, Section 5.4). An important aspect of GRE is to find combinations of properties
that allow the generator to refer uniquely to an entity, called the target. Crucially, GRE
algorithms only use properties whose denotations are part of the common knowledge
of writer and reader.2 These algorithms are typically designed in such a way that gener-
ation is performed quickly (e.g., their worst-case running time tends to be linear [Dale
and Reiter 1995; van Deemter 2002]) but the processing effort of the reader is not taken
into account. Some algorithms do make a point of generating descriptions that are as
brief as possible (Dale 1989), and this can be argued to make interpretation easier. As we
have seen, however, in relation to Examples (1a?c), brevity can make resolution difficult.
For concreteness, let us focus on one of the best-known algorithms in this area. The
Incremental Algorithm (Dale and Reiter 1995) starts by arranging attributes in a list, af-
ter which they are considered one by one, to see if any of their values contributes some-
thing to the description, by removing ?distractors? (i.e., objects other than the referent);
if an attribute (e.g., COLOR) can contribute something, then a suitable value (e.g., RED)
for this attribute is selected as part of the description. This is repeated incrementally un-
til the logical conjunction of all selected attribute?value combinations results in a unique
identification of the referent. There is no backtracking, and this is what keeps the com-
plexity of the algorithm linear; it is also what causes the algorithm to sometimes express
a property P even when properties that are added later make P logically redundant.
2 A good example of a description failing this requirement occurs in Get off one stop before I do, in an
exchange between two people who have just met, as a description of where the hearer should get off the
bus (Appelt 1985, cited in Dale and Reiter 1995).
231
Computational Linguistics Volume 33, Number 2
Suppose a referring expression identifies its referent uniquely. Then at least two
things can stand in the way of finding its referent: the ?difficulty? of the individual
properties used in the description (i.e., the fact that it may be difficult to ascertain which
objects have the property in question [Horacek 2005]), or the size and structure of the
search space. To exemplify the first factor, suppose you are queuing up for a concert and
want to explain to a friend that a girl further ahead in the queue has his ticket. Color is
an attribute that speakers like to use, even if it leads to logical redundancy (Pechmann
1989). This might be done by describing the referent as the girl in a yellow dress, or as
the girl with green eyes, for example. But arguably, the first property contributes more
towards your friend?s search, because the color of a person?s eyes may not leap out
at him from afar. In the Incremental Algorithm, the fact that DRESS COLOR is more
useful than EYE COLOR could be tackled by letting it precede EYE COLOR in the list
of attributes. As a consequence, EYE COLOR would only be considered if the referent
cannot be identified uniquely without using a combination of more preferred attributes,
including DRESS COLOR. Arguably, this is exactly as it should be, and it shows much of
what is good about the Incremental Algorithm. It is not so obvious, however, how the
algorithm should deal with the second of the two possible obstacles to resolution: the
size and structure of the domain.
3. Problems for Resolution
In this section we shall introduce a class of domains (Section 3.1) and a class of problems
for resolution that can arise when objects in these domains are identified using a distin-
guishing description (Section 3.2). Section 4 will relate these problems to a simple model
of the resolution process and propose a remedy, which consists of generating logically
redundant descriptions (in two different ways). Sections 5 and 6 provide examples of
putting our ideas to the test: first, by investigating what kind of description is preferred
by subjects who are given the choice (Section 5); then, more elaborately, by investigating
the effect of redundant descriptions on readers (Section 6).
3.1 Hierarchical Domains
Existing work on GRE tends to focus on fairly simple domains, dominated by one-place
properties. When relations (i.e., two-place properties) are taken into account at all (e.g.,
Dale and Haddock 1991; Krahmer and Theune 2002), the motivating examples are kept
so small that it is reasonable to assume that speaker and hearer know all the relevant
facts in advance. Consequently, search is not much of an issue (i.e., resolution is easy):
The hearer can identify the referent by simply intersecting the denotations of the proper-
ties in the description, for example, intersecting the set of girls with the set of individuals
who wear a yellow dress (both in the domain). Although such simplifications permit
the study of many aspects of reference, other aspects come to the fore when larger, and
subtly structured, domains are considered.
Interesting questions arise, for example, when a large domain is hierarchically
ordered. For the purpose of this article, we consider a domain to be hierarchically
ordered if its inhabitants can be structured like a tree in which everything that belongs
to a given node n belongs to at most one of n?s children, and everything that belongs
to one of n?s children belongs to n. Examples include countries divided into provinces,
which, in turn, may be divided into regions, and so on; years into months, then into
weeks, and then into days; documents into chapters, then sections, then subsections;
232
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
buildings into floors, then rooms. Clearly, hierarchies are among our favorite ways of
structuring the world.3
A crucial question, in all such cases, is what knowledge is shared between speaker
and hearer at utterance time. Later on (most explicitly in Section 6), we shall focus on
more realistic situations but, to get the idea, it will be useful to think about the extreme
case where, before the start of resolution (i.e., before consulting the ?knowledge in the
world,? as opposed to the hearer?s ?knowledge in the head? [Norman 1988]), the hearer
knows nothing about the domain. When the utterance is made, the hearer?s blindfold is
removed, so to speak, and resolution can start. No similar assumption about the speaker
is made: We assume that the speaker knows everything about the domain, and that he
knows that the hearer can achieve the same knowledge. Many of our examples will
be drawn from a simple model of a University campus, structured into buildings and
rooms; the intended referent will often be a library located in one of the rooms. The
location of the library is not known to the hearer, but it is known to the speaker.
Each domain entity r will be associated with a TYPE (e.g., the type ?room?), and with
some additional attributes such as its ROOM NUMBER or NAME, and we will assume
that it is always possible to distinguish r from its siblings in the tree structure by
using one or more of these properties. (For example, ROOM NUMBER = 120 identifies
a room uniquely within a given building; BUILDINGNAME = Watts identifies a building
within the university.) This is a useful assumption, because without it, the existence of
a distinguishing description cannot be guaranteed.
The kinds of referring expression that we are interested in (see Section 5 for motiva-
tion) take the form of a list
L = ?(x1, P1), (x2, P2) . . . (xn, Pn)?
where x1 = r is the referent of the referring expression and, for every j > 1, xj is an
ancestor (not necessarily the parent) of xj?1 in the domain D. For every j, Pj is a set of
properties that jointly identify xj within xj+1 or, if j = n, within the whole domain. The
reference the library in room 120 of Cockcroft building, for example, is modeled as
L = ?(r, {type = library}), (x2, {type = room, roomnumber = 120}), (x3, {type =
building, buildingname = Cockcroft})?
3.2 Obstacles for Resolution
We have argued that generating a uniquely referring expression is not always enough,
because such an expression can leave the hearer with an unnecessarily large search
space. But the issue is an even starker one, especially?as we shall soon see?when
it is taken into account that references in hierarchically structured domains can make
use of the position of the speaker and hearer in the domain. (For simplicity, we assume
that these two locations coincide.)
Let us start with some informal observations, to be corroborated in Section 4. Sup-
pose a hierarchically ordered domain D contains only one entity whose TYPE is LIBRARY.
3 If everything that belongs to a given node n belongs to exactly one of n?s children, then nodes can be
thought of as being partitioned by its children. Note that this is not always the case. Not everything
on a given floor of a building, for example, has to be in a room (the corridors are not).
233
Computational Linguistics Volume 33, Number 2
Figure 1
A hierarchically structured domain; d is where the reference is uttered.
Consider the following noun phrases, uttered in the position marked by d in Figure 1.
(The first three have the same intended referent.)
(2a) the library, in room 120 in the Cockcroft building
(2b) the library, in room 120
(2c) the library
(2d) room 140
Utterances like Examples (2a) and (2b) make use of the hierarchical structure of the
domain.4 We focus on the search for xn (i.e., the highest hierarchical level referred to
in the description) because, under the assumptions that were just made (in particular
the fact that xj be identified uniquely in xj+1 by the properties Pj), this is the only place
where problems can be expected (because no parent node is available).
Even though each of Examples (2a)?(2d) succeeds in characterizing their intended
referent uniquely, some of these descriptions can be problematic for the hearer. One
type of problem occurs in Example (2d). The expression is logically sufficient (i.e., there
is only one room labeled 140 in the entire university). But, intuitively speaking, the ex-
pression creates an expectation that the referent may be found nearby, within the
Watts building, whereas, in fact, a match can only be found in another building. In a
case like this, we will speak of Lack of Orientation (LO). Even more confusion might
occur if another library was added to our example, for instance in Watts 110, whereas
the intended referent was the other library (i.e., in room 120 Cockcroft). In this case,
Example (2c) would misfire, of course. The expression (2b), however, would succeed, by
mutually using two parts of the description (the library and room 120) to identify another:
There are two libraries, and two rooms numbered 120, but there is only one pair (a, b)
such that a is a library and b is a room numbered 120, with a located in b. Such cases of
4 Recall that we focus on Content Determination, bypassing issues to do with lexical choice, linguistic
realization, and so on. For example, we shall not worry whether it is better to say (i) the library, in room
120, (ii) the library in room 120 (without a comma), or (iii) the library (room 120). The difference is not trivial,
because (ii), for example, might be viewed as having the unwanted implicature that there is more than
one library in the Watts building (Robert Dale, personal communication, August 2005.)
234
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
mutual identification5 are unproblematic in small, transparent, domains where search is
not an issue, but in large hierarchical domains, they are awkward (see the Conclusion).
For, like Example (2d), (2b) would force a reader to search through an unnecessarily
large part of the domain; worse even, the search ?path? that the reader is likely to follow
leads via an obstacle (namely, room 120 Watts) that matches a part of the description, al-
though not being the intended referent of the relevant part of the description (i.e., room
120 Cockcroft). Confusion could easily result. For even if the reader eventually finds the
library, she has no simple way of knowing whether it is the right one. (Perhaps a library
in Watts 120 has been overlooked.) In cases like this, we speak of a Dead End (DE).
Suppose the domain D is represented as a finite tree whose nodes have attributes
associated with them, one of which is the TYPE attribute. As before, we shall assume
that the attributes and values suffice to identify every node within its parent node.
Before defining LO and DE more precisely, we describe the related notions of SCOPE and
SCOPEGROUP, and the notion of a search path. We write x ? D to say that x is a node in
the tree D; if A is an attribute applicable to x then A(x) denotes the value of A for x.
Scope: Suppose x ? D, and A1, . . . , An are attributes associated with x.
Then SCOPE(x, {A1, . . .An}) is the largest subtree S of D such that x ? S
while, for every y, z ? S, the conjunction A1(y) = A1(z) & . . .& An(y) =
An(z) implies y = z.
SCOPE(x, {A1, . . .An}) is the largest subtree of D in which the values for the attributes
A1, . . . An jointly succeed in pinning down the referent. In practice, we shall usually
focus on situations where n = 1, in which case we shall write SCOPE(x, A1), omitting the
brackets. In our University domain, let x be room 140 of Cockcroft, then SCOPE(x, ROOM
NUMBER) is the subtree rooted in Cockcroft, because within Cockcroft, all room numbers
are unique, whereas at the level of the entire university (the next level up), this is not
the case (even though the room number 140 itself happens to be unique at that level).
The notion of SCOPE gives rise to the notion of SCOPEGROUP in a straightforward
way. Assuming, once again, that x ? D, and letting U stand for a set of attributes
associated with x, we define:
SCOPEGROUP(x, U) = {y ? D | y ? SCOPE(x, U) & TYPE(x) = TYPE(y)}
Thus, SCOPEGROUP (x, {A1, . . .An}) is the set of those elements of SCOPE(x, {A1, . . .
An}) that are of the same TYPE as x. Again, we shall focus on cases where n = 1, and
omit brackets. Thus, in the example domain, SCOPEGROUP(x,ROOM NUMBER), where x
is any room in Cockcroft, is the set of all the rooms in Cockcroft. TYPE is kept constant in
the definition of SCOPEGROUP because it tends to be the only non-structural attribute
that is used to identify domain objects (i.e., the only attribute that is not intended for
designating a node of the domain tree).6 Non-structural attributes will be assumed to
be unproblematic, operating like a filter on the set of possible referents. For example,
a reader of the description the library in room 110 will only be looking for libraries
(although they might be looking for them in the wrong building).
5 A well-known example is the description the bowl on the table, in a domain that contains several tables and
several bowls, but only one bowl on a table (Dale and Haddock 1991).
6 For example, we have seldom found descriptions like ?the section containing tables,? ?the italicized
section? in the PILs corpus (ABPI 1997).
235
Computational Linguistics Volume 33, Number 2
We are now in a position to define DE and LO more precisely, relative to a search
path. A search path is a series of steps in the search for a referent, representing
visits to nodes in the domain tree D. The path will be modeled by an ordered list
of visited nodes: O = ?n1, n2, . . . nm?. The node n1 is visited first, then n2, and so on,
until either the referent is found (success) or the reader gives up (failure). As before,
let L = ?(x1, P1), (x2, P2) . . . (xn, Pn)? model the semantic structure of the description, in
which xn is the entity of highest hierarchical level referred to in L. Furthermore, let
A1,. . . ,Aj be the set of all attributes in Pn. Then we predict problems for resolution
to occur if some y occurs prior to xn in O, for which TYPE(xn) = TYPE(y) and y 	?
SCOPEGROUP(xn, A1, . . .Aj). Calling such y an obstacle, there are two types of obstacle:
the obstacles for which all the properties in Pn are true (these are perhaps the worst
kind, because they can be mistaken for the intended referent), and the ones for which
this is not the case. If only obstacles of the latter kind arise then we will speak of
Lack of Orientation (LO). If there is at least one obstacle of the former, more serious
kind, we will speak of Dead End (DE). For example, in the case of the DE Exam-
ple (2b) (the library in room 120), the description itself can be modeled as the list L =
?(r, {type = library}), (x2, {type = room, roomnumber = 120})?, where Pn is the property
ROOM NUMBER = 120 and xn is the room where the library is. Suppose that the search
path for xn corresponds to the following sequence (because referents are always found
in leaf nodes, other nodes appear in brackets):
O = ?Watts100, (Watts, )Watts110, (Watts, )Watts120, (Watts, )(University, )
(Cockcroft, )Cockcroft100, (Cockcroft, )Cockcroft120?
Part of this sequence is the obstacle y = Watts 120, which is of the same TYPE as xn (i.e.,
both are rooms), and which does not belong to SCOPEGROUP(xn, ROOM NUMBER) (i.e.,
it does not belong to the Cockcroft building).
Because the property Pn (ROOM NUMBER = 120) is true of y, this constitutes a case
of DE. If the room Watts 120 is removed from the domain, there no longer exists an
obstacle of the most serious kind (because there is only one room whose room number
is 120), but rooms 100 and 110 in the Watts building are obstacles of the less serious kind,
making this an example of LO.
It seems likely that DEs and LO can disrupt search in sufficiently large or complex
domain structures. In principle, DE and LO could result even in the most unlikely
regions of the domain. Suppose the cup on the table is uttered in a room d, which
contains the intended referent. Now suppose (rather perversely perhaps) the hearer
started searching in another room, say the kitchen, before looking at the nearest table
(in d). If the kitchen happens to contain a table as well, and this table does not support
any cups, DE would result. Search, however, seems unlikely to proceed in this way.
To make testable predictions, we will make some assumptions concerning the way in
which referring expressions are resolved by hearers. To explain what these assumptions
are, let us return to the examples in Section 3, repeated here for convenience.
(2a) the library in room 120 in the Cockcroft building
(2b) the library in room 120
(2c) the library
(2d) room 140
236
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
We assume that these sentences are uttered in the University, say at the location d, and
that d determines the starting point of the search for a referent. Henceforth the starting
point s will be assumed to be the parent node of d. The intuition behind this assumption
is simple: When searching, start looking nearby.
It will often be useful to assume that resolution adheres to a principle that we will
call Ancestral Search. In formulating this principle, we will use d? as a name for the
referring expression (which, as we know, takes place at location d); we will use Ref(d?)
as short for the intended referent of d?.
Ancestral Search: First, search for Ref(d?) in the subtree dominated by the starting point
s. If Ref(d?) is not found there then search for Ref(d?) in the subtree dominated by the
parent of s, which is called s?. If Ref(d?) is not found there then move up to the parent s??
of s?,. . . , and so forth, until the root is reached. [If, at this point, Ref(d?) is still not found,
search fails.]
Ancestral Search (AS) says that the hearer of a referring expression searches exhaus-
tively through the current search space (e.g., the building in which the expression is
uttered, or the current document section containing the expression) before inspecting a
larger subtree. AS does not say how the search within each subtree (i.e., the one dominated
by s or s?) is carried out. We do not claim that readers always adhere exactly to AS,
especially not when they are confronted with unusual situations (as we shall see in our
second experiment). Rather, AS can be seen as an ?ideal model,? much like a straight line
could be seen as an ideal model of how a pedestrian walks from one point to another.
We shall see later that AS makes surprisingly accurate predictions in terms of what
references are found difficult by readers.
4. Generation Algorithms
What kinds of expression would existing GRE algorithms produce in the situations of
interest? Because hierarchies involve relations, the first algorithm that comes to mind
is the one proposed by Dale and Haddock (1991). Essentially, this algorithm combines
one- and two-place predicates, until a combination is found that pins down the target
referent. A standard example involves a domain containing two tables and two bowls,
although only one of the two tables has a bowl on it. In this situation, the combination
{bowl(x), on(x, y), table(y)} identifies x (and y as well), because only one value of x can
verify the three predicates, and this justifies the description the bowl on the table. Now
consider Figure 2, with one additional library in room 110 of the Watts building. Here
the combination {library(x), in(x, y), room(y), roomnumber(y) = 120} identifies x (and y
too), because no other library is located in a room with room number 120 (and no
other room numbered 120 contains a library). Thus, the standard approach to relational
descriptions allows precisely the kinds of situation that we have described as DE.
Henceforth, we shall describe this as the Minimal Description (MD) approach to refer-
ence because, in the situations of interest, it uses the minimum number of properties by
which the referent can be distinguished.
Another option would be to treat a relation like ?being in room 120? as a one-place
property of the library, and to use the Incremental Algorithm (Dale and Reiter 1995) to
generate the descriptions in question. This, however, would not produce results that are
interestingly different from MD. Suppose, for example, that the TYPE attribute is most
preferred (i.e., considered first by the algorithm), with values such as ?library?, ?room?,
and so on. Suppose, furthermore, that the attribute ROOM NUMBER is preferred over
237
Computational Linguistics Volume 33, Number 2
Figure 2
A university campus with two libraries in different buildings.
the attribute BUILDING NAME and, crucially, that a property such as ROOM NUMBER =
x is interpreted as true of all those objects in the university (regardless in which building)
that are located in something whose room number is x. Then the Incremental Algorithm
starts selecting TYPE = library, followed by ROOM NUMBER = 120, at which stage
a distinguishing description is reached. In other words, the same description would
be generated by this algorithm as by Dale and Haddock (1991) and, once, again, the
infamous LO and DE would occur. Choosing a preference order in which building
names are preferred over room numbers would produce the library in Cockcroft. Al-
though this description seems defensible in this case, it is easy to see that this preference
order would produce excessively lengthy descriptions in other situations. No single
preference order produces acceptable results in all cases.
We will now sketch two GRE algorithms, both of which are guaranteed to prevent
DE and LO if AS holds. (These algorithms will be investigated empirically in Sections 5
and 6.) They operate by reducing the reader?s search space, including logically redun-
dant information into the descriptions that they generate. These algorithms, called Full
Inclusion (FI) and Scope-Limited (SL), are not the only ways in which resolution may
be aided, but we will see that they represent two natural options. Both take as input a
hierarchical domain D, a location d where the referring expression will materialize, and
an intended referent r. The output is a list of properties L to be turned into an English
description by a language realization program.
The first algorithm, FI, represents a straightforward way of reducing the length
of search paths, without particular attention to LO or DE. It lines up properties that
identify the referent uniquely within its parent node, then moves up to identify this
parent node within its parent node, and so on until reaching a subtree that includes
the starting point d.7 FI may be likened to existing treatments of salience. In Krahmer
and Theune?s (2002) approach to GRE, for example, distractors that have lower salience
than the intended referent do not have to be removed. We apply this idea to hierarchical
domains using the assumption that from the point d where the utterance was made all
nodes within d?s parent node are as salient as d itself, while more ?distant? nodes are
gradually less salient. As in Krahmer and Theune, salience sometimes allows for shorter
7 ?Includes? is taken to be reflexive: a includes b iff a is an ancestor of b or a = b.
238
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
descriptions, as when room 110 replaces room 110 in Watts when said in Watts building
(but outside room 110).
Full Inclusion(r):
L := ?? { Initialize L as the empty list }
FI.Identify(r)
The function FI.Identify is defined recursively: (For simplicity, L does not contain the
individual referents x1,. . . ,xj, but only their properties.)
FI.Identify(X):
L := L + P, where P identifies X uniquely within Parent(X)
X := Parent(X)
IF X includes d THEN STOP ELSE FI.Identify(X)
Applied to our earlier example of a reference to room 120, FI first builds up the list L =
?(type = room, roomnumber = 120)?, then expands it to L = ?(type = room, roomnumber =
120), (buildingname = Cockcroft)?. Now that Parent(X) includes d , r has been identified
uniquely within D and we reach STOP. L might be realized as room 120 in Cockcroft, for
example.
FI gives maximal weight to ease of resolution. But something has to give, and that
is brevity: By conveying logically redundant information, descriptions are lengthened,
and this can have drawbacks, most evidently when there are limitations of space or
time. The second algorithm, called SL, constitutes a compromise between brevity and
ease of resolution. SL prevents DE and LO but opts for brevity when DE and LO do
not occur. Put differently, SL favors ease of resolution when there is a risk of DE or
LO, but ease of interpretation when there is no such risk. This is done by making use
of the notion of SCOPE, which was used in the definition of DE and LO. It may be
recalled that a description (x, P) in which P conveys attributes A1, . . . Aj leads to DE or
LO when its hearer comes across a node of the same type as x that is not a member
of SCOPEGROUP(x, {A1, . . .Aj}). It follows that when the hearer is searching within
SCOPE(x, {A1, . . .Aj}), the description (x, P), even if minimally distinguishing, cannot
lead to DE or LO. Consequently, (x, P) can be uttered in any position d within the subtree
denoted by SCOPE(x, {A1, . . .Aj}) with no risk of leading to DE or LO situations. In other
words, if SCOPE(x, {A1, . . .An}) contains d, and if A1, . . .An are the attributes conveyed
in a description (x, P), then this description does not lead to DE or LO. This allows SL to
use logically redundant properties more sparingly:
Scope-Limited(r):
L := ?? { Initialize L as the empty list }
SL.Identify(r)
SL.Identify(X):
L := L + P, where P identifies X uniquely within Parent(X)
239
Computational Linguistics Volume 33, Number 2
X := Root(Scope(X, {A1, . . . , Aj})), where A1, . . . , Aj are the attributes
associated with P
IF X includes d THEN STOP ELSE SL.Identify(X)
Whereas FI only terminates the generation of the description when a node that includes
d is reached, SL concludes potentially much earlier, when an attribute (or a combination
of attributes) is used that is guaranteed to identify all objects of the relevant type
uniquely throughout a tree that includes d. By taking scope into account, SL avoids
the inclusion of any hierarchical levels not strictly required for preventing DE and LO.
Consider a description uttered in the position d = room 100 of Watts, with r =
room 140 (in Cockcroft) as the intended referent. Existing GRE approaches such as Dale
and Reiter (1995) would tend to produce a minimally distinguishing description such
as room 140, causing LO. SL, by contrast, would produce the description room 140 in
Cockcroft,8 which in this case is the same description produced by FI. The difference
between FI and SL becomes evident when we consider a case in which the minimally
distinguishing description does not lead to DE/LO?that is, when AS predicts that
the reader will meet no DE or LO obstacles. For example, let?s return to the situation
depicted in Figure 1, from Section 3.1, where there is only one library in the whole
university. A reference to r = library would be realized by FI as the library in room 120 in
Cockcroft. By using SL, however, the same description would be realized simply as the
library, because the SCOPE of the attribute TYPE is the whole domain tree [more precisely,
SCOPE(LIBRARY,ROOM NUMBER)= D] because there is only one entity of TYPE ?library?
in the domain and hence no other properties are added. Note that the addition of a
second library in the Watts building would reduce SCOPE(r,TYPE) to the subtree rooted
in the ?building? node (i.e., each library would be defined by the building to which it
belongs). The behavior of the SL algorithm would change accordingly, producing the
library in Cockcroft. Similarly, had we instead included the second library under another
room of Cockcroft, the SCOPE would have been reduced even further, causing SL to
describe r as the library in room 120 of Cockcroft, just like the FI algorithm.
5. First Experiment: Measuring Reader?s Preferences
In this section we start putting the intuition that LO and DE are better avoided to the
test. We report on a small experiment with human subjects, which involved a document
structured in sections and subsections as an example of a hierarchically ordered domain.
We chose this domain because, unlike most other domains, it allows us to show subjects
the domain itself (i.e., a real document), rather than, for example, a pictorial represen-
tation of it. More specifically, we investigated the choice of so-called document-deictic
references, such as the picture in part x of section y (Paraboni 2003), to check whether
they avoid potential DE and LO situations by adding logically redundant properties
(favoring ease of resolution) and, conversely, whether they choose shorter descriptions
when there is no such risk (favoring ease of interpretation).
8 The reason is that Root(Scope(r,ROOM NUMBER)) = Cockcroft, which does not include d. This causes the
algorithm to have to identify the Cockcroft building before the algorithm stops.
240
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
5.1 Experiment Design
Subjects. 15 academics with considerable practice in the authoring of papers on compu-
tational linguistics.
Procedure. A within-subjects design was used. All subjects were shown a printed doc-
ument containing 18 incomplete statements. Subjects were asked to put themselves in
the shoes of the author and to choose the description that they found more suitable for
each situation:
Suppose you and a colleague are currently collaborating on this document. Fortunately
he/she did almost all the work for you, and now all that you have to do is complete
certain parts of the existing text [. . . ]
Subjects completed the statements by choosing one of two alternatives provided: one
?minimally distinguishing? description and the other conveying logical redundancy
(corresponding to the output of the FI or SL algorithms). Both alternatives are un-
ambiguous references to the same object. Figure 3 shows a number of descriptions
of this kind (whose intended referents are elsewhere in the document) and objects
(referred to by descriptions elsewhere). Statement 11 gives a choice between a logically
redundant description as generated by FI or SL (Part C of Section 2) and its minimally
distinguishing alternative Part C. Both alternatives are unambiguous because there is
only one part labeled as ?C? in the document, but the shorter one may potentially lead
to LO because the current document section does not contain a part labeled as ?C?.
Similarly, Statement 12 gives a choice between a minimally distinguishing description
as generated by MD or SL, and a logically redundant alternative as generated by
FI, but in this case none of the alternatives can lead to DE or LO because there is
only one ?table 2? in the entire document. The presentational order of alternatives
Figure 3
Fragment of the document used in the experiment.
241
Computational Linguistics Volume 33, Number 2
Table 1
Situations of reference for Experiment 1.
Sit. Type Reader Loc. Referent Loc. MD Redundant
2 DE Part A Sec 1 Part B Sec 3 Pic 2 in Part B Pic 2 in Part B Sec 3
9 DE Part C Sec 2 Part B Sec 3 Pic 3 in Part B Pic 3 in Part B Sec 3
13 DE Part B Sec 3 Part A Sec 2 Pic 4 in Part A Pic 4 in Part A Sec 2
15 DE Part B Sec 3 Part A Sec 2 Pic 3 in Part A Pic 3 in Part A Sec 2
5 LO Part B Sec 1 Part A Sec 2 Pic 5 Pic 5 in Part A Sec 2
7 LO Part B Sec 1 Part C Sec 2 Part C Part C Sec 2
11 LO Part A Sec 3 Part C Sec 2 Part C Part C Sec 2
16 LO Part B Sec 3 Part A Sec 2 Pic 6 Pic 6 in Part A Sec 2
4 NONE Part A Sec 1 Part B Sec 3 Table 6 Table 6 in Part B Sec 3
10 NONE Part C Sec 2 Part A Sec 3 Table 5 Table 5 in Part A Sec 3
12 NONE Part A Sec 3 Part B Sec 2 Table 2 Table 2 in Part B Sec 2
18 NONE Part B Sec 3 Part A Sec 1 Table 1 Table 1 in Part A Sec 1
(i.e., short versus redundant descriptions) was evenly distributed, to control for order
effects.
Research questions. We were interested in seeing whether readers prefer longer (i.e.,
logically redundant) descriptions when there is a risk of DE or LO and, conversely,
whether they prefer minimally distinguishing descriptions when there is no such risk.
Table 1 shows the type of situation (potential DE, LO, and non-problematic), the reader
and referent location, and the descriptions used. To break the monotony of the task
and to disguise the purpose of the experiment, another six situations were used that
were not relevant to the experiment. Half of the situations, in each of the types,
involved backward references, the other half involved forward references. Pictures were
enumerated per part so that we could compare short and long versions of potentially
problematic descriptions (e.g., Picture 5 in which the intended referent is not in the
current document part, which may or may not contain other pictures). Within the LO
situations, two of the four statements involved references to pictures, whereas the other
two involved references to sections. This was done in order to test whether the type of
referent had any influence on the choices made by the subjects. All the questions related
to potential DE situations involved references to pictures, because using DE references
to sections would have led to highly artificial structures.
Hypothesis 1.1: In a problematic DE situation, descriptions generated by FI or SL are
preferred over minimally distinguishing (MD) descriptions.
We will use the DE situations in Table 1 to test this hypothesis, investigating how often
subjects prefer FI/SL descriptions to MD ones.
Hypothesis 1.2: In a problematic LO situation, descriptions generated by FI or SL are
preferred over minimally distinguishing (MD) descriptions.
We will use the LO situations in Table 1 to test this hypothesis, investigating how often
subjects prefer FI/SL descriptions to MD ones. Note that in problematic situations, SL
generates the same descriptions as FI.
242
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
We also wanted to investigate whether subjects would prefer descriptions gen-
erated by FI or SL in non-problematic situations (i.e., those not involving potential
DE or LO). We did not use pictures as we did in the problematic cases because in
these cases both FI and SL would produce the same descriptions (e.g., Picture 5).9
In order to compare these algorithms in non-problematic situations we used tables
enumerated throughout the document, in which case descriptions produced by SL are
short (e.g., Table 5) and descriptions produced by FI are longer (e.g., Table 5 in Part C of
Section 2).
Hypothesis 1.3: In a non-problematic situation (i.e., a situation not involving DE or
LO), SL or MD descriptions are preferred over those generated by FI.
We will use the non-problematic situations in Table 1 to test this hypothesis, investigat-
ing how often subjects prefer FI descriptions to MD/SL ones. Note that in these non-
problematic situations, SL generates the same descriptions as MD.
Hypotheses 1.1 and 1.2 investigate whether ease of resolution (as in logically re-
dundant descriptions generated by FI or SL) is favored over ease of interpretation (as
in minimally distinguishing descriptions) when the description may lead to DE or LO.
Hypothesis 1.3 investigates whether ease of interpretation (as in MD or SL descriptions)
is favored over ease of resolution (as in descriptions generated by FI) when the former
does not lead to DE or LO situations.
Materials. DEs and LO can only occur in fairly complex domains. Instead of trying to
find a large number of such documents, we made use of a specially designed schematic
document. The document was presented in a printed version (3 pages long), divided
into sections (1?3) and subsections (?A? and ?B?); Section 2 contained also a subsection
labelled ?C?.10
References to pictures can be realized in many different ways. For example, the
referent can be called Picture or Figure or just Fig.; the reference can be constructed from
the bottom up (Picture 3 in Section 4) or from the top downwards (Section 4, Picture 3);
punctuation varies as well, as does the use of capitals. In our experiments, we have
made one fairly arbitrary choice from among all these possibilities, motivated by the
types of reference that we observed most frequently in an informal study of a collection
of patient information leaflets from the PILs corpus (ABPI 1997): We always used the
word Picture, we constructed the references bottom up (going up one level at a time),
and never used commas or semicolons. Thus, for example, we asked subjects to compare
Picture 3 in Part B of Section 3 with Picture 3 in Part B.11 Even though it is possible that a
different realization choice would produce different experimental outcomes, this does
not seem likely.
Every description d and its referent r were always on different pages. Had d and r
occurred on the same page then physical proximity might have obscured navigational
9 In the second experiment reported in Section 6 this was no longer an issue as we focus on ease of
resolution only, that is, it did not compare FI with SL.
10 See Paraboni (2003), appendix 1, for the actual document.
11 To get a feeling for the frequency of the expressions involved, one might enter ?picture OR figure OR fig
1. . . 9 in part OR section 1. . . 9? into Google, using Advanced Search. In July 2006, this produced as many as
77, 000 hits, the great majority of which are of the intended kind. (Because Advanced Search disregards
punctuation and capitalization, this includes a very small percentage of false positives, for example of the
form ?Figure x. In section y . . . ?.) The materials of our second experiment (Section 6) were essentially the
same as the present ones, except for the use of capitals.
243
Computational Linguistics Volume 33, Number 2
issues, causing a bias towards the shortest alternative. Reference d and referent r were
always in document parts whose layout properties differed from each other (e.g., not
both in subsections labeled as ?C? in different sections of the document). Had d and r
occurred in document parts with similar layout properties, there might have been a bias
towards the most complete (i.e., the longest) description.
5.2 Results
Hypotheses 1.1 and 1.2 were confirmed; hypothesis 1.3 was not. In fact, DE was
avoided in 100% of all subjects? decisions. In situations involving LO, the FI version
was chosen on average in 93% of cases (stdev = 15%), which is highly significant
(Wilcoxon signed ranks test, Z = ?3.56, p < .0001). In the cases not involving DE or
LO, there was no significant preference for or against logical redundancy (Wilcoxon
signed ranks test Z = ?0.51, p = .61). The trend is in the predicted direction (mean
of 57% for MD descriptions), but the variation between subjects was very large
(stdev = 41%).
5.3 Discussion of First Experiment
This first experiment supported the hypothesis that subjects prefer references that
include logically redundant information where there is a risk of DE/LO. Arguably,
it is precisely this kind of information that is needed for the construction of NLG
algorithms. Where logically redundant information does not make the referent easier
to identify, the results of the experiment are less clear, with the subjects being divided
between logically minimal and logically redundant descriptions. In other words, while
supporting the informal observations reported in Sections 2 and 3, the experiment
does not point to a generic preference of one of the two GRE algorithms presented in
Section 4.
Evidently, there are many factors that this experiment did not address, such as
the ?distance? between objects. For example, if tables are enumerated throughout the
document, is the brief, SL-type description Table 5 easy enough to resolve? It depends:
If there are tables on virtually every page then resolution is easy, because the table
numbers support browsing not unlike page numbers; if tables are sparse, however,
then searching through the entire document may take unacceptably long, and a more
redundant, FI-type description such as Table 5 in Section 4.3 is likely to be preferred. The
nature of the domain is bound to matter as well. For example, in a large spatial domain
in which navigation requires physical effort, short, SL-style descriptions are probably
less acceptable than in a situation where the domain can be surveyed at a glance. To
exemplify the first type of situation, let us return briefly to Examples (1a)?(1c), assuming
that a city is divided into areas, and an area into streets:
(1a) 968 Lewes Road, Moulsecoomb area (FI-style)
(1b) 968 Lewes Road (SL-style)
(1c) number 968 (MD-style)
If these are uttered somewhere in Brighton but not on Lewes Road then AS predicts
that utterance (1c) leads to LO, because the hearer will start looking for a number 968 in
the street where the description is uttered. Consequently, utterance (1c) is infelicitous
244
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
anywhere except on Lewes Road. But how about Examples (1a) and (1b)? Both descrip-
tions avoid LO and DE, because Brighton has only one Lewes Road. Yet if the hearer
does not know that Lewes Road is in Moulsecoomb, then the resolution of Example (1b)
may involve more work than Example (1a).
This experiment attempted to find out what types of references are favored by
human judges when their opinion about these references is asked. Although this has the
advantage that subjects were in a position to make trade-offs between the advantages
and disadvantages of the different expressions (perhaps balancing ease of interpreta-
tion with ease of resolution), the method is limited in other respects. One limitation
arises from the fact that meta-linguistic judgments are sometimes thought to be an
unreliable predictor of people?s linguistic behavior (e.g., van Deemter 2004). Perhaps
more seriously, the experiment fails to tell us how difficult a given type of reference (for
example, one of the DE type) would actually be for a reader, and whether the difficulty
is a matter of interpretation or resolution. For these reasons, we decided to perform
another experiment.
6. Second Experiment: Measuring Search Effort
In the previous experiment, we found that human authors often prefer logically redun-
dant references, particularly when DE and LO can arise. In a follow-up experiment,
we investigate the effect of logical redundancy on the performance of readers. We
are primarily interested in understanding the search process, so resolution rather than
interpretation. It will become clear that the new experiment necessitates a more careful
design and a more complex analysis than the previous one.
6.1 Experiment Design
Subjects. Forty-two students on a first-year Computing Science course participated in
the experiment as part of a scheduled practical.
Procedure. A within-subjects design was used. All subjects were shown 20 on-line
documents. The order of the documents was randomized per subject, to control for
order effects. The document structure was always visible, and so was the content of
the current document part. A screenshot of an example document providing this level
of information is shown in Figure 4. Each document was initially opened in Part B
of either Section 2 or 3, where a task was given of the form ?Let?s talk about [topic].
Please click on [referring expression];? for instance: Let?s talk about elephants. Please click
on picture 5 in part A. Subjects could navigate through the document by clicking on the
names of the parts (e.g. Part A as visible under Section 3). As soon as the subject had
correctly clicked on the picture indicated, the next document was presented. Subjects
were reminded throughout the document about the task to be accomplished, and the
location at which the task was given. All navigation actions were recorded. At the start
of the experiment, subjects were instructed to try to accomplish the task with a minimal
number of navigation actions.
Reader?s Knowledge. We assume that readers do not have complete knowledge of the
domain. So, they do not know which pictures are present in each part of each section.
If readers had complete knowledge, then a minimal description would suffice: For
example, if readers knew that there is only one picture 5 in the document, located in
245
Computational Linguistics Volume 33, Number 2
Figure 4
Fragment of the experiment interface.
part B of section 3, then the description picture 5 would probably be completely clear.
We do not, however, assume readers to be completely ignorant, either. We assume that
they have some knowledge of the domain, particularly of its hierarchical structure. This
brings us to the question of how much knowledge we should assume our readers to
have. In practice (unlike Section 3.1, where the hearer was pictured as blindfolded until
the description is uttered) readers will always have some knowledge: If in Part B of
Section 2, then they would know (by convention) that there will also be a Section 1, and
a Part A in Section 2, and so on. It is also likely that being in Part B of Section 2 and
seeing pictures 1, 2, 3, readers will infer that sections can have parts, that parts can
contain pictures, and that pictures are numbered (though not necessarily per part).
Because of these kinds of consideration, it seems appropriate to give our readers
knowledge about the entire document structure (the 5 sections and their parts) and
the content (i.e., the existing pictures) in the current document part (but crucially, no
knowledge about pictures elsewhere in the document, which require navigation to be
discovered). A navigation structure like the one in Figure 4 provides this knowledge to
the readers.
Research Questions. We want to test whether longer descriptions indeed help resolution,
particularly in so-called problematic situations. Table 2 shows the types of situation
(potential DE, LO, and non-problematic),12 reader and referent location, and descrip-
tions used.
Hypothesis 2.1: In a problematic (DE/LO) situation, the number of navigation actions
required for a long (FI/SL) description is smaller than that required for a short (MD)
description.
12 In DE situations, there is another picture with the same number as the referent, but not in a part with the
same name as the part in which the referent is. In LO situations, there is no other picture with the same
number as the referent, and the reader location contains pictures. In non-problematic situations, there is
another picture with the same number as the referent, but not in a part with the same name as the part in
which the referent is.
246
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
Table 2
Situations of reference for Experiment 2.
Sit. Type Reader Loc. Referent Loc. Short (MD) Long (FI/SL) Long (other)
1 DE Part B Part A Pic 3 in Pic 3 in Part A
Sec 3 Sec 2 Part A Sec 2
2 DE Part B Part C Pic 4 in Pic 4 in Part C
Sec 2 Sec 3 Part C Sec 3
3 LO Part B Part A Pic 5 Pic 5 in Part A Pic 5 in Part A
Sec 3 Sec 3 Sec 3
4 LO Part B Part C Pic 4 Pic 4 in Part C Pic 4 in Part C
Sec 2 Sec 2 Sec 2
5 LO Part B Part A Pic 5 Pic 5 in Part A Pic 5 in Part A
Sec 3 Sec 4 Sec 4
6 LO Part B Part C Pic 4 Pic 4 in Part C Pic 4 in Part C
Sec 2 Sec 1 Sec 1
7 NONE Part B Part A Pic 3 in Pic 3 in Part A
Sec 2 Sec 2 Part A Sec 2
8 NONE Part B Part C Pic 4 in Pic 4 in Part C
Sec 3 Sec 3 Part C Sec 3
This hypothesis is similar to hypotheses 1.1 and 1.2 of the previous experiment. We
will use the DE and LO situations in Table 2 to test this hypothesis, comparing for each
situation the number of navigation actions of the short, that is, minimally distinguishing
(MD) and long (FI/SL) expressions.
In the previous experiment, we had an additional hypothesis about non-
problematic situations, stating that MD descriptions would be preferred to long de-
scriptions in non-problematic situations. This is not a natural hypothesis in the new
experiment, because it might not happen very often that a shorter description will lead
to fewer navigation actions (pace Cremers 1996). (Note that in the previous experiment
we looked at the combination of interpretation and resolution, whereas we are now
focusing on resolution only). Instead, we will look at gain: the number of navigation
actions required for a short description minus the number of navigation actions required
for a long description.
For situation s, short description sd of s, and long description ld of s, Gain(s, sd, ld) = the
number of navigation actions required in s for description sd minus the number of
navigation actions required in s for description ld.
Hypothesis 2.2: The gain achieved by a long description over an MD description will
be larger in a problematic situation than in a non-problematic situation, that is, for
problematic situation ps, non-problematic situation nps, MD description md of both ps
and nps, and long description ld of ps and nps: Gain(ps, md, ld) > Gain(nps, md, ld).
We will use the DE and non-problematic situations in Table 2 to test this hypothesis,
comparing the gain of situation 1 with that of situation 7, and the gain of situation 2
with that of situation 8.
Longer descriptions may always lead to fewer navigation actions, and it can be
expected that complete descriptions of the form picture x in part y of section z will
outperform shorter descriptions in any situation. So, from a resolution point of view,
an algorithm that would always give a complete description may produce better results
247
Computational Linguistics Volume 33, Number 2
than the algorithms we proposed (e.g., situations 3 and 4 in Table 2). The aim of our
algorithms is to make the descriptions complete enough to prevent DE and LO in
resolution, but not overly redundant as this may affect interpretation. We would like
to show that the decisions taken by FI and SL are sensible, that is, that they produce
descriptions that are neither too short nor too long. Therefore:
S1: We want to consider situations in which FI and SL have produced an incomplete
description, and investigate how much gain could have been made by using a complete
description in those cases. We would like this gain to be negligible. We will use
situations 3 and 4 for this, calculating the gain of the long, complete descriptions
(namely, long (other) in Table 2) over the shorter, incomplete descriptions generated by
our algorithms (long (FI/SL) in Table 2).
S2: We want to consider situations in which FI and SL have produced a complete
description, and investigate how much gain has been made by using this compared to a
less complete description that is still more complete than MD. We would like this gain
to be large. We will use situations 5 and 6 for this, calculating the gain of the long
complete descriptions generated by our algorithms (long (FI/SL) in Table 2) over the
less complete descriptions (long (other)).
Introducing separate hypotheses for cases S1 and S2 poses the problem of defining
when a gain is ?negligible? and when a gain is ?large.? Instead, we will compare the
gain achieved in S1 with the gain achieved in S2, expecting that the gain in S2 (which we
believe to be large) will be larger than the gain in S1 (which we believe to be negligible).
Hypothesis 2.3: The gain of a complete description over a less complete one will be
larger for situations in which FI and SL generated the complete one, than for situations
in which they generated the less complete one. More formally, for situations S1 and S2,
descriptions cd and ld, with cd a complete description of S1 and S2 that has been
generated by FI and SL for S2, and with ld an incomplete but longer-than-MD
description of S1 and S2 that has been generated by FI and SL for S1:
Gain(S1, ld, cd) < Gain(S2, ld, cd).
Materials. Twenty on-line documents were produced,13 with the same document struc-
ture (sections 1 to 5 with parts A to C) and containing 10 pictures. Documents had
a unique background color, title, and pictures appropriate for the title. The number
of pictures in a section or part varied per document. All of this was done to prevent
subjects relying on memory. For instance, if we had used the same document for all
tasks, subjects might have remembered where a particular picture was located. If we had
used documents that looked similar, subjects might have assumed that they were the
same. If we had kept the distribution of images the same, subjects might have learned
that a particular part always contained many pictures.
Controlled experiments have advantages and disadvantages. Instead of using arti-
ficial, hand-crafted materials, we could have used real-world documents, like patient
information leaflets, in order to make the tasks as realistic as possible. However, it
would have been extremely difficult to find real-world documents that contain the
right phenomena in a well-balanced way. Firstly, real documents might not have the
right descriptions in them, so we would probably have needed to change sentences
in the documents by hand. Secondly, we need a set of documents that are sufficiently
13 http://www.csd.abdn.ac.uk/?jmasthof/RefStudy/Intro.php.
248
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
Table 3
Number of clicks used to complete the tasks.
Short Long (FI/SL) Long (Other)
Sit. Type Mean STDEV Mean STDEV Mean STDEV
1 DE 3.58 2.14 1.10 0.50
2 DE 3.85 3.28 1.30 1.31
3 LO 5.60 4.84 1.93 1.29 1.23 1.27
4 LO 2.50 1.97 1.60 1.28 1.38 2.07
5 LO 8.53 4.15 1.15 0.53 5.65 6.74
6 LO 7.38 5.49 1.25 1.03 4.08 2.35
7 NONE 1.58 0.98 1.63 2.61
8 NONE 1.48 0.96 1.05 0.32
similar in structure that one can make a fair comparison between longer and shorter
descriptions. Moreover, the structure should not allow subjects to learn where in the
document pictures are most likely to be located. Thirdly, semantic information or their
background knowledge of the domain should be irrelevant. (For example, if we were
using a real document on animals, and subjects read a section on lions, then they might
expect a picture of a tiger to be in a nearby section, and a picture of an elephant to be
closer than a picture of a pigeon.)
6.2 Results
Forty subjects completed the experiment. Table 3 shows descriptive statistics for the
number of clicks subjects made to complete each task. To analyze the results with respect
to Hypothesis 2.1, we used a General Linear Model (GLM) with repeated measures. We
used two repeated factors: Situation (situations 1 to 6) and Description Length (short
and long(FI/SL) ). We found a highly significant effect of Description Length on the
number of clicks used to complete the task (F1,39 = 262.46, p < .001, ?2p = .87). In all
potentially problematic situations, the number of clicks is smaller for the long than for
the short description. This confirms Hypothesis 2.1. We also found significant effects
of Situation (F5,35 = 13.11, p < .001, ?2p = .65), and of the interaction between Situation
and Description Length (F5,35 = 18.02, p < .001, ?2p = .72).
Table 4 shows descriptive statistics for the gain as used for Hypothesis 2.2. We again
used a GLM with repeated measures, using two repeated factors: Description Content
(that of situations 1 and 7, and that of situations 2 and 8) and Situation Type (potential
DE and non-problematic).14 We found a highly significant effect of Situation Type on
the gain (F1,39 = 26.62, p < .001, ?2p = .41). In the non-problematic situations the gain is
smaller than in the potential DE situations. This confirms Hypothesis 2.2.
Table 5 shows descriptive statistics for the gain as used for Hypothesis 2.3. We again
used a GLM with repeated measures, using two repeated factors: Description Content
(that of situations 3 and 5, and that of situations 4 and 6) and FI Decision (with 2 levels:
14 There were no significant effects of Description Content and of the interaction between Description
Content and Situation Type. From here on, we will focus on effects that were significant.
249
Computational Linguistics Volume 33, Number 2
Table 4
Gain as used for Hypothesis 2.2.
Sit. Type Mean STDEV
1 DE 2.48 2.24
7 NONE ?0.05 2.77
2 DE 2.55 3.62
8 NONE 0.43 1.04
complete and not complete). We found a highly significant effect of FI Decision on
the gain (F1,39 = 24.10, p < .001, ?2p = .38). The gain is smaller for situations where our
algorithm decided to use an incomplete description than in situations where it chose a
complete one. This confirms Hypothesis 2.3.
6.3 Discussion of Second Experiment
What does the second experiment teach us, over and above what we learned from the
first one? First of all, the experiment suggests an explanation of why it was that, in
problematic situations, subjects (in the first experiment) preferred redundant descrip-
tions: The new experiment suggests that the reason may lie in the fact that, in the
potentially problematic situations, the addition of structural information reduces the
effort involved in resolution. This is, of course, exactly in line with the way in which
DE and LO were introduced in Section 3, and with the assumptions about ease of
resolution that were formulated in Paraboni and Van Deemter (2002a) and in the present
Section 2.
Do our experiments, taken together, tell us how much redundancy is optimal in any
given situation? In answering this question, let us first realize that pragmatic factors
relating to the utterance situation are likely to affect how much redundancy is needed.
At one end of the spectrum, there may be highly fault-critical settings, where flawless
understanding is essential; at the other end, there may be discourse settings where
accurate understanding is not important, and where the speaker/writer is under time
pressure. Surely, redundant information must be more common in the former than in
the latter. No one algorithm can cater to all types of settings.
On the other hand, our data do suggest quite strongly that, at least in the situation in
which our subjects found themselves, a law of diminishing returns is in operation. To see
this, let us first focus on the two non-problematic situations (Table 2): Averaging numbers
Table 5
Gain as used for Hypothesis 2.3.
Sit. FI Decision Mean STDEV
3 NOT COMPLETE 0.70 1.40
5 COMPLETE 4.50 6.67
4 NOT COMPLETE 0.23 2.51
6 COMPLETE 2.83 2.16
250
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
of clicks of all subjects over all relevant situations, short descriptions required a mere
1.53 clicks; by adding redundant information (unlike SL/FI), this number gets reduced
to an average of 1.34 clicks (long(other), in situations 7 and 8). This very slight gain
(0.19 clicks) is not statistically significant (F1,39 = .60, p = .44, ?2p = .02) and is bought at
the price of a description that is one and a half times longer, which makes it likely to
take more time during interpretation. As for the more interesting problematic situations,
perhaps the best comparison is between situations 3 and 4 (where long(other) exists and
is longer than long(FI/SL)). Here, short descriptions lead to a pretty dismal average
of 4.05 clicks. If we lengthen the descriptions as prescribed by FI/SL (long(FI/SL))
then this figure is lowered drastically to what looks like a pretty acceptable 1.77 clicks,
which constitutes a gain of 2.28. By adding even more information (as in long(other)),
the figure is lowered further, to 1.31 clicks. Although this does represent a gain, it is
not statistically significant (F1,39 = 2.94, p = .095, ?2p = .07), and besides it is so small
(at 0.46 clicks) that it seems likely to be more than offset by the disadvantages for
interpretation that are implied by the increased length of the description. Needless to say,
these effects can only become stronger if more complex documents are considered, and
with descriptions that are even longer. Really excessive redundancy might have detri-
mental effects on resolution as well as interpretation, because it confuses hearers. (A
hearer might wonder, along Gricean lines, ?Why are they saying ?Picture 5 in Part A of
Section 3, printed in black and white?. Surely if they have to give so much information,
they cannot simply mean Picture 5??.)
Finally, we also explored the searching behavior of our subjects, focusing on the
12 documents in which incomplete descriptions were given. Ancestral Search predicts
that subjects will search the current section (where the question is asked) exhaustively,
before moving on to another section. Figure 5 shows subjects? compliance with An-
cestral Search in their first navigation action. (Eight of the 12 documents contained a
description of the form Picture 5 in Part A, so for these it suffices to look at the first
navigation action.) Four subjects complied perfectly. Half the subjects complied almost
perfectly, deviating in at most 2 of the 12 cases. However, five subjects deviated almost
completely (10 or more times). Closer inspection showed that these latter subjects
seemed to navigate randomly, not following any obvious pattern (e.g., top to bottom).
It may well be that these subjects did not take the experiment seriously. Nevertheless,
we still have more deviation from Ancestral Search than expected.
There are two possible explanations. First, some subjects may have started using
Ancestral Search, and then found that it was not effective when they encountered
some documents in which the referent turned out to be in some far-away section, after
which they changed to a more random strategy. (Recall that our experiment deliberately
Figure 5
Compliance with Ancestral Search during first navigation action.
251
Computational Linguistics Volume 33, Number 2
included some unreasonably short descriptions.) Our data seem to confirm this. For
instance, subject S11 started in compliance with Ancestral Search until encountering a
document asking, in Section 2, to find a picture in Part C. The subject clicked as many
as 6 times on Part C of Section 2, before finally finding the referent in Section 3. He went
on to deviate four times from Ancestral Search.
A second explanation for deviating from Ancestral Search is the kind of navigation
that we allowed. Subjects could go directly from, say, Part C in Section 2, to part A in
Section 3, without an extra navigation step to go into Section 3. In fact, it may even
be faster to navigate to another section than within the current one, depending on
the position of the mouse pointer. (This contrasts with the university domain, where
one could not go directly from room 120 in Watts building to room 140 in Cockcroft
building without first having to walk between the buildings.) It should be noted that
this problem may be more pronounced after the first navigation action has been made.
For instance, if one clicks on Part A in Section 2, then the mouse pointer is about as
close to Part C in Section 1 as to Part C in Section 2. To explore this idea, we looked at
the four documents in which a description of the form picture 5 was given. In 83 cases,
subjects who complied with Ancestral Search for the first navigation action needed to
perform a second action; in 77% of these cases, they also complied with Ancestral Search
in the second action. Now in as many as 68% of the cases in which they did not comply,
they clicked on the closest link in an adjacent section (e.g., Part A of the next section
after having first clicked on Part C). This confirms our suspicion that the lack of effort
required to deviate may have been a reason for deviation. With hindsight, we should
probably have made the distance between the relevant sections larger.
7. Conclusion
This article has discussed generation strategies that facilitate resolution of a referring
expression by adding logically redundant properties. We have shown that this can
be of crucial importance, especially in large domains, where minimally distinguishing
descriptions can sometimes be completely useless (witness, e.g., Example [1c]). Two
algorithms for generating logically redundant references along the lines described in
this article have been implemented. The experiments reported in the previous sections
indicate that these algorithms are fundamentally on the right track.
We recently learned of an interesting series of experiments that investigate the role
of logically redundant properties in referring expressions (Arts 2004). One of the out-
comes of these experiments was that certain types of logically redundant information
almost consistently led to accelerated resolution. This was particularly true for informa-
tion concerning the location of an object. For example, a logically minimal description
like the white button on the left took readers longer to resolve than a redundant one like
the white button at the top left (our emphasis). It is interesting to note that these results
were obtained in situations where neither LO nor DE could occur.
This article has described an alternative to classical algorithms for GRE. Suppose you
are designing an NLG system and want to give it a GRE component; how do you know
whether to use the new algorithm, instead of one of its predecessors? Redundancy has
a role to play in different kinds of situations (see the Introduction of this article), but
our algorithms focus on a class of cases that we believe to be particularly widespread,
namely where the domain is hierarchical in the sense of Section 3. Because hierarchies
involve relations, let us once again compare the predictions made by our algorithms
with those made by Dale and Haddock (1991). Suppose their description the bowl on the
252
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
table was said when there are two tables and two bowls, while (only) the table furthest
away from the hearer has a bowl on it. FI and SL, by contrast, would generate something
redundant like the bowl on the far-away table. Which of the two descriptions is best?
The answer is that it depends on the situation: When all the relevant facts are
available to the reader without effort (e.g., all the domain objects are visible at a glance)
then Dale and Haddock?s minimal descriptions are fine, but when search is required,
the kind of ?studied? redundancy embodied in FI and SL becomes necessary. Consider
the example again. If the tables and bowls are visible at a glance, then resolving the
DE-inducing description the bowl on the table is unproblematic, because there is nothing
here to discover: The crucial part of the domain is directly available, and no search is
needed. Consequently, it is superfluous to say anything about the location of the table.
But suppose we are in a huge room, where it is not obvious for the hearer what is on
each table. In this situation, the bowl on the table would be a rather unhelpful description,
compared to the bowl on the far-away table (or the bowl on the table in the corner), as
would be consistent with our algorithms. (The example can be made more dramatic
by hiding the table with the bowl on it in another room.) What this example highlights
is the distinction between the things that speaker and hearer know when a referring
expression is uttered, and the things they can discover. It is in the latter case that search
becomes an issue. We have shown how this idea can be made precise and incorporated
into a GRE algorithm, and we have demonstrated that this can improve the generated
descriptions from the perspective of the hearer.
Recent work in psycholinguistics, focusing on spontaneous speech in dialogue,
has shown that speakers and hearers often act as if they are completely oblivious of
the epistemic limitations of their interlocutors, even when these limitations have been
made perfectly obvious to them (e.g., Keysar, Lin, and Barr 2003). These widely known
results have caused some researchers to expect language users to behave with unbridled
descriptive ?egocentricity? in all situations. The first of our two experiments suggests
that human writers (as opposed, perhaps, to speakers) can be highly altruistic in their
descriptions of objects. The second experiment demonstrates how descriptive altruism
can benefit readers.
By exploring the benefits for the hearer (in terms of the effort required for identify-
ing the referent), we have not only shown that it can be good to add logically redundant
information to a referring expression; we have arguably also shed some light on the
reason why redundant descriptions are sometimes preferred. By counting the number of
clicks that subjects need in order to find the referent, and relating these to predictions
stemming from our Ancestral Search model, we believe that we have achieved a degree
of insight into the ?resolution? processes in the head of the reader, not unlike the
way in which insights in human language processing can be produced by eye-tracking
experiments. It would be interesting to see whether the ideas discussed here can be
confirmed using such a more entrenched psycholinguistic paradigm.
Acknowledgments
The authors are grateful for insightful
comments from Emiel Krahmer, Richard
Power, Sebastian Varges, the Aberdeen NLG
group, and the anonymous reviewers. The
second author acknowledges support from
the UK?s EPSRC TUNA project, grant
GR/S13330/01.
References
Appelt, Douglas E. 1985. Planning English
referring expressions. Artificial Intelligence,
26:1?33.
Arts, Anja. 2004. Overspecification in
Instructive Texts. Ph.D. thesis, Tilburg
University, The Netherlands. Wolf
Publishers, Nijmegen.
253
Computational Linguistics Volume 33, Number 2
Association of the British Pharmaceutical
Industry (ABPI). 1997. 1996?1997 ABPI
Compendium of Patient Information Leaflets.
ABPI, London.
Clark, Herbert. 1992. Arenas of Language Use.
CSLI Publications, Stanford, CA.
Cremers, Anita. 1996. Reference to Objects; an
Empirically Based Study of Task-oriented
Dialogues. PhD. thesis, University of
Eindhoven.
Dale, Robert. 1989. Cooking up referring
expressions. In Proceedings of the 27th
Annual Meeting of the Association for
Computational Linguistics (ACL-1989),
pages 68?75, Vancouver, Canada.
Dale, Robert and Nicholas Haddock. 1991.
Generating referring expressions involving
relations. In Proceedings of EACL-1991,
pages 161?166, Berlin.
Dale, Robert and Ehud Reiter. 1995.
Computational interpretations of the
Gricean maxims in the generation of
referring expressions. Cognitive Science,
18:233?263.
Deutsch, W. 1976. Sprachliche Redundanz
und Objectidentifikation. Ph.D.
dissertation, University of Marburg.
Edmonds, Philip G. 1994. Collaboration on
reference to objects that are not mutually
known. In Proceedings of COLING-1994,
pages 1118?1122, Kyoto.
Grice, Herbert P. 1975. Logic and conversation.
In P. Cole and J. Morgan, editors, Syntax
and Semantics: Vol 3, Speech Acts. Academic
Press, New York, pages 43?58.
Horacek, Helmut. 2005. Generating
referential descriptions under conditions
of uncertainty. In 10th European Workshop
on Natural Language Generation (ENLG-2005),
pages 58?67, Aberdeen, Scotland.
Jordan, Pamela W. 2000. Can nominal
expressions achieve multiple goals?
An empirical study. In ACL-2000,
pages 142?149, Hong Kong.
Jordan, Pamela W. 2002. Contextual influences
on attribute selection for repeated
descriptions. In K. van Deemter and
R. Kibble, editors, Information Sharing. CSLI
Publications, Stanford, CA, pages 295?328.
Keysar, Boaz, Shuhong Lin, and Dale J. Barr.
2003. Limits on theory of mind use in
adults. Cognition 89:25?41.
Krahmer, Emiel and Marie?t Theune. 2002.
Efficient context-sensitive generation of
referring expressions. In K. van Deemter
and R. Kibble, editors, Information
Sharing. CSLI Publications, Stanford, CA,
pages 223?264.
Levelt, Willem J. M. 1989. Speaking: From
Intention to Articulation. MIT Press,
Cambridge, MA.
Mangold, Roland. 1986. Sensorische Faktoren
beim Verstehen ueberspezifizierter
Objektbenennungen. Peter Lang Verlag,
Frankfurt.
Norman, Donald. 1988. The Design of
Everyday Things. Doubleday, London.
Paraboni, Ivandre?. 2000. An algorithm for
generating document-deictic references. In
Proceedings of INLG-2000, ?Coherence in
Generated Multimedia,? pages 27?31,
Mitzpe Ramon, Israel.
Paraboni, Ivandre?. 2003. Generating References
in Hierarchical Domains: The Case of
Document Deixis. Ph.D thesis, University of
Brighton, U.K.
Paraboni, Ivandre?, Judith Masthoff, and Kees
van Deemter. 2006. Overspecified reference
in hierarchical domains: Measuring the
benefits for readers. In Proceedings of
INLG-2006, pages 55?62, Sydney.
Paraboni, Ivandre? and Kees van Deemter.
2002a. Generating easy references: the case
of document deixis. In Proceedings of
INLG-2002, pages 113?119, New York.
Paraboni, Ivandre? and Kees van Deemter.
2002b. Towards the generation of
document-deictic references. In K. van
Deemter and R. Kibble, editors, Information
Sharing. CSLI Publications, Stanford,
pages 329?354.
Pechmann, Thomas. 1989. Incremental
speech production and referential
overspecification. Linguistics, 27:98?110.
Reiter, Ehud and Robert Dale. 2000. Building
Natural Language Generation Systems.
Cambridge University Press, Cambridge.
Siddharthan, Advaith and Ann Copestake.
2004. Generating referring expressions in
open domains. In Proceedings of 42nd ACL,
pages 408?415, Barcelona, Spain.
Sonnenschein, Susan. 1982. The effects of
redundant communications on listeners:
When more is less. Child Development,
53:717?729.
Sonnenschein, Susan. 1984. The effect of
redundant communication on listeners:
Why different types may have different
effects. Psycholinguistic Research, 13:147?166.
van Deemter, Kees. 2002. Generating
referring expressions: Boolean
extensions of the incremental algorithm.
Computational Linguistics, 28(1):37?52.
van Deemter, Kees. 2004. Finetuning an NLG
system through experiments with human
subjects: The case of vague descriptions.
In Proceedings of INLG-2004, pages 31?40,
Brockenhurst, UK.
254
Proceedings of NAACL-HLT 2013, pages 1174?1184,
Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational Linguistics
Generating Expressions that Refer to Visible Objects
Margaret Mitchell
Johns Hopkins HLTCOE
m.mitchell@jhu.edu
Kees van Deemter
University of Aberdeen
k.vdeemter@abdn.ac.uk
Ehud Reiter
University of Aberdeen
e.reiter@abdn.ac.uk
Abstract
We introduce a novel algorithm for generat-
ing referring expressions, informed by human
and computer vision and designed to refer to
visible objects. Our method separates abso-
lute properties like color from relative proper-
ties like size to stochastically generate a di-
verse set of outputs. Expressions generated
using this method are often overspecified and
may be underspecified, akin to expressions
produced by people. We call such expressions
identifying descriptions. The algorithm out-
performs the well-known Incremental Algo-
rithm (Dale and Reiter, 1995) and the Graph-
Based Algorithm (Krahmer et al, 2003; Vi-
ethen et al, 2008) across a variety of images
in two domains. We additionally motivate
an evaluation method for referring expression
generation that takes the proposed algorithm?s
non-determinism into account.
1 Introduction
Referring expression generation (REG) is the task
of generating an expression that can identify a ref-
erent to a listener. These expressions generally take
the form of a definite noun phrase such as ?the large
orange plate? or ?the furry running dog?. Research
in REG primarily focuses on the subtask of select-
ing a set of properties that may be used to construct
the final surface expression, e.g., ?color:orange,
size:large, type:plate?. This property selection task
is optimized to meet different goals: for example,
to be identical to those a person would generate in
the same situation, or to be unique to the intended
referent and no other item in the discourse.
We focus on the task of generating referring ex-
pressions for visible objects, specifically with the
goal of generating descriptive, human-like referring
expressions. We are motivated by the desire to con-
nect this algorithm to input from a computer vision
system, and discuss how this may work through-
out the paper. Computer vision (CV) does not yet
reliably provide features for some of the most fre-
quent properties that people use in visual descrip-
tion (in particular, size-based features), and so we
use a gold-standard visual input, evaluating purely
on REG. The proposed algorithm, which we call
the Visible Objects Algorithm, is designed to ap-
proximate human variation identifying an object in
a group of visible, real world objects.
Our primary contributions are the following.
Background for each issue is provided in Section 2:
1. An approach accounting for overspecification,
underspecification, and some of the known ef-
fects of vision on reference.
2. A function to approximate the stochastic nature
of reference. This reflects that people will pro-
duce different references to the same object.
3. A separation between absolute properties like
color, which may be detected directly by CV,
from relative properties like size and loca-
tion, which require reasoning over visual fea-
tures to determine an appropriate form (e.g.,
height/width and distance features between
pixels are available from a visual input; saying
an object is ?tall? requires further reasoning).
4. An evaluation method for non-deterministic
REG that aligns generated and observed data
and calculates accuracy over alignments.
1174
2 Motivation & Overview
Most implemented algorithms for referring expres-
sion generation focus on unique identification of a
referent, determining the set of properties that dis-
tinguish a particular target object from the other ob-
jects in the scene (the contrast set) (Dale, 1989; Re-
iter and Dale, 1992; Dale and Reiter, 1995; Krahmer
et al, 2003; Areces et al, 2008). This view of refer-
ence was first outlined by Olson (1970), ?the spec-
ification of an intended referent relative to a set of
alternatives?. A substantial body of evidence now
shows that contrastive value relative to alternatives
is not the only factor motivating speakers? property
choices, specifically in visual domains. The phe-
nomena of overspecification and redundancy, where
speakers select properties that have little or no con-
trastive value, was observed in early developmen-
tal studies in visual domains (Ford and Olson, 1975;
Whitehurst, 1976; Sonnenschein, 1985) as well as
later studies on adult speakers in visual domains
(Pechmann, 1989; Engelhardt et al, 2006; Koolen et
al., 2011). The related phenomenon of underspecifi-
cation, where speakers select a set of properties that
do not linguistically specify the referent, has also re-
ceived some attention, particularly in visual domains
(Clark et al, 1983; Kelleher et al, 2005).
These findings make sense in light of visual ev-
idence that some properties ?pop out? in the scene
(Treisman and Gelade, 1980), and speakers may be-
gin referring before scanning the full set of scene ob-
jects (Pechmann, 1989), selecting those properties
that are salient for them (Horton and Keysar, 1996;
Bard et al, 2009) without spending a great amount
of cognitive effort considering the perception of a
hearer (Keysar and Henly, 2002).
We take this evidence to suggest an approach for
a visual reference algorithm that generates natural,
human-like reference by generating visual proper-
ties that are salient for a speaker.1 We can under-
stand what is salient visually (what does the visual
system first respond to, what guides attention?), lin-
guistically (what do people tend to mention in visual
scenes?), and cognitively, which we will not have
room to discuss in this paper (what is atypical for
1We can also add functionality to ensure that a referent is
uniquely identified against the contrast set (whether or not that
reflects what a person would do), which we will describe.
Figure 1: Relative properties, like size and location, are
difficult to obtain from a two-dimensional image. We find
it easy to perceive the background object as larger than
the one in the front; but they are technically the same size
in the image (from Murray et al (2006)).
this object?); as well as in terms of broader notions
of salience, e.g., discourse salience (Krahmer and
Theune, 2002).
This suggests a paradigm shift in the generation
task when referring to visible objects, if the goal is
to produce human-like reference. In particular, this
suggests moving from selecting properties that rule
out other scene objects to selecting properties that
are salient for the speaker (visually, conversation-
ally, based on previous experiences, etc.). This mir-
rors related research on the tradeoff between audi-
ence design and egocentrism in language production
(Clark and Murphy, 1982; Horton and Keysar, 1996;
Bard et al, 2009; Gann and Barr, 2013). Under-
and overspecification naturally fall out from such an
approach, with no need to specifically model either
phenomenon.
Perhaps unsurprisingly, the set of properties that
are visually salient and the set of properties that are
linguistically salient largely overlap. Color is the
first property our visual system processes, followed
soon after by size (Murray et al, 2006; Fang et al,
2008; Schwarzkopf et al, 2010); and people tend
to use color (Pechmann, 1989; Viethen et al, 2012)
and size when identifying objects, with size com-
mon when there is another object of the same type
in the scene (Brown-Schmidt and Tanenhaus, 2006).
Following this, our algorithm gives a privileged
position to these properties, processing them first.
Using computer vision techniques to determine an
object?s color works reasonably well (Berg et al,
2011), and the relevant visual features for this task
may be useful in future work to return several pos-
sible color labels that capture differences in lexical
choice (cf. Reiter and Sripada (2002)).
Detecting size does not work well (Forsyth,
1175
2011); and when it does, it will likely not take the
form supposed in recent generation work. Most
REG algorithms use a predefined single-featured
value, such as ?big?; however, given an image-based
input, obtaining such a value requires (1) determin-
ing how the object is situated in a three-dimensional
space, difficult to obtain from a two-dimensional im-
age (see Figure 1); and (2) determining what the
value should be: object detectors currently can pro-
vide the height and width of the location where an
object is likely to exist (its bounding box), as well as
the x- and y-axis locations of the pixels within the
object detection; but a value from these features like
?big?, ?tall?, or ?long? requires further reasoning.
As such, we incorporate the top-performing size al-
gorithm introduced in Mitchell et al (2011), which
takes as input the height and widths of objects in the
image and outputs a size value or NONE, indicating
that size should not be used to describe the object.
In addition to color and size, location and orien-
tation begin to be processed early on in the visual
system (Treisman, 1985; Itti and Koch, 2001), with
our first perception of location corresponding to ba-
sic cues of where an object is relative to our focus
of attention. For an input image, this simple type of
location corresponds to surface forms such as, e.g.,
?on the right of the image? or ?at the top of the im-
age?. Along with size, location and orientation make
up the three primary relative properties that we aim
to generate language for.
After the simple forms for color, size, location,
and orientation properties are processed, our visual
system feeds forward to two parallel pathways, the
so-called ?what? and ?where? pathways (Ungerlei-
der and Mishkin, 1982), which process properties
with growing complexity. The ?what? pathway in-
cludes absolute properties like shape and material,
which computer vision has had some success de-
tecting (Ferrari and Zisserman, 2007; Farhadi et al,
2009) while the ?where? pathway corresponds to
more complex spatial orientation and location infor-
mation, such as where objects are relative to one an-
other and which way they are facing.
To begin connecting this process to the genera-
tion of human-like descriptions of visible objects,
we start with the following simplification: Color and
size have a privileged status, the first properties pro-
cessed. These are followed by the relative properties
Figure 2: Initial model for generating visual reference.
of location and orientation, which may feed forward
to more complex location and orientation properties
in one pathway; and absolute properties following
color, like material and shape, which may be pro-
cessed in another pathway.
This gives us the basic model for generating ref-
erence to visible objects shown in Figure 2. To gen-
erate reference in this model, nodes correspond to
general visual attributes and may generate forms for
visual properties (attribute:value pairs). That is, a
property such as color:red is generated from the at-
tribute node color and a property such as size:tall is
generated from the attribute node size. We are lim-
ited by existing REG corpora in which properties we
can evaluate; in this paper, we examine the effect of
the independent selection of color and size, followed
by location and orientation.2
Generating human-like expressions in this setting
begins to be possible by adopting recent propos-
als that REG handle speaker variation (Viethen and
Dale, 2010) and the non-deterministic nature of ref-
erence (van Gompel et al, 2012; van Deemter et
al., 2012b). We can capture such variation simply
by estimating ?att, the likelihood that an attribute
att generates a corresponding visual property. Dur-
ing generation, the algorithm passes through each at-
tribute node, and uses this estimate to stochastically
add each property to the output property set.
Such a non-deterministic process means that the
algorithm will not return the same output every time,
which offers new challenges for evaluation. If we
run the algorithm 1,000 times, we have a distribu-
tion over several possible output property sets. From
this we can obtain the majority set and check if it
matches the majority observed set. Similarly, we can
2We have also built an algorithm and corpus with more com-
plex properties in order to tease out further details of visual ref-
erence, but must leave these details for follow up work; for now,
we focus on the properties common to REG corpora.
1176
run the algorithm for as many instances as we have
in our test data, and see how well the property sets
it produces aligns to the observed property sets. We
discuss evaluation using both methods in Section 6.
3 The State of the Art in REG
3.1 Algorithms
In order to understand how this approach compares
to the state of the art in REG, we evaluate against
two of the most well-known algorithms, the Incre-
mental Algorithm (Dale and Reiter, 1995) and the
Graph-Based Algorithm (Krahmer et. al, 2003, as
implemented in Viethen et al, 2008). Details on
these algorithms are available in their corresponding
papers. As a brief summary, both algorithms formal-
ize the objects in the discourse as a set of properties
(attribute:value pairs). For example, one object may
be represented as ?type:box, color:red, size:large?.
The task is to find the set of properties that uniquely
specify the referent. This is known as a content se-
lection problem, and the set of properties chosen by
the algorithm is called a distinguishing description.
The Incremental Algorithm (IA) proceeds by it-
erating through attributes in a predefined order (a
preference order), and for each attribute, it checks
whether specifying a value would rule out at least
one item in the contrast set that has not already been
ruled out. If it will, the attribute:value is added to
the distinguishing description. This process contin-
ues until all contrast items (distractors) are ruled out
or all available properties have been checked. We
use the implementation of the IA available from the
NLTK (Bird et al, 2009).3
In the Graph-Based Algorithm (GB), the objects
in the discourse are represented within a labeled di-
rected graph, and content selection is a subgraph
construction problem. Each object is represented as
a vertex, with properties for an object represented as
self-edges on the object vertex, and spatial relations
between objects represented as edges between ver-
tices. The algorithm seeks to find the cheapest sub-
graph, calculated from the edge costs. We use the
implementation available from Viethen et al (2008),
which adds a preference order to decide between
edges with the same cost during search. This has
3https://github.com/nltk/nltk contrib/blob/master/
nltk contrib/referring.py retrieved 1.Aug.2012.
been one of the best-performing systems in recent
generation challenges (Gatt and Belz, 2008; Gatt et
al., 2009).
An important commonality between these algo-
rithms, and much of the work on REG that they
have influenced, is the focus on unique identifica-
tion and operating deterministically. Both produce
one property set (and only one), and stop once a tar-
get item has been uniquely identified (or else fail).
Their driving goal is to rule out distractor objects.
In the approach introduced here, the algorithm
produces a distribution over several possible out-
puts, and the initial driving mechanism is based on
likelihood estimates for each attribute independent
of the other objects in the scene, rather than ruling
out all distractors. This offers a way to capture some
aspects of human-like reference, including under-
and overspecification and speaker variation. Due to
the fundamentally different objective of this algo-
rithm, we will call the kind of expression it generates
an identifying description, following Searle (1969).
This is a description that the system finds (1) useful
to describe the referent and (2) true of the referent.
4 The Algorithm
The Visible Objects Algorithm iterates through lists
of visible attributes, stochastically adding properties
to the property set it will generate. After this initial
search, the algorithm then scans through the objects
in the scene, roughly corresponding to how people
scan a scene when referring (Pechmann, 1989). The
target referent type, corresponding to the head noun
in the final generated description, is added to the
property set at the end of the algorithm.
We represent the basic components of the algo-
rithm graphically in Figure 3. Full code is available
online.4 After START, the algorithm proceeds in par-
allel through a list of absolute attributes and a list
of relative attributes. The likelihood of generating a
property is a function of the prior likelihood ?att and
?, a penalty on the length of the constructed prop-
erty set up to that point. This ensures that only a few
properties are generated for a referent, and the ex-
pression will not be too complex. This is also in line
with recent research suggesting that there are rarely
more than three adjectives in a visual noun phrase
4https://github.com/itallow/VisibleObjectsAlgorithm.
1177
(Berg et al, 2011). Once the algorithm hits END,
it scans through the objects in the scene. If it finds
an object that is the same type as the referent object,
the algorithm checks through the attributes again in
a preference order akin to the IA, comparing the ob-
ject?s properties against the referent?s and generating
properties as a function of the length penalty alone.
If the algorithm does not find an object that it is the
same type, no further properties are added.
4.1 Requirements
The algorithm requires the following:
1. Prior likelihood estimates on the inclusion of
different attributes. Represented as ?att.
2. Ordered list of absolute attributes beyond color.
Represented as AP.
3. Ordered list of relative attributes beyond size.
Represented as RP.
4. Ordered list of all attributes. Represented as P.
5. Ordered list specifying the order in which to
scan through other scene objects. The current
implementation uses the order in which the ob-
jects are listed in the corpora it is run on.
(1) is similar to the cost functions for GB, but
attributes are selected non-deterministically using
prior likelihoods. (2), (3), and (4) are similar to
the IA?s and GB?s preference order. For our eval-
uation corpora, AP is empty and RP contains loca-
tion and orientation. (5) is novel to this algorithm,
defining an order in which to compare the target ob-
ject against other objects in the scene. This is in-
spired by the process of incremental speech produc-
tion (Pechmann, 1989), where speakers scan objects
during naming, incrementally producing properties.
4.2 The Stochastic Process
Generally speaking, we want to penalize longer de-
scriptions and encourage the attributes that we know
people are likely to use. We can encourage a likely
attribute by using its prior likelihood as an estimate
of whether to include it. We can penalize longer de-
scriptions with a penalty proportional to the length
of the property set under construction. In other
words, given a prior likelihood estimate for includ-
ing an attribute att, ?att, and the property set con-
structed so farA, we compute whether to add a prop-
a. b.
TUNA corpus GRE3D3 corpus
Figure 4: Example scenes from corpora.
erty for att toA as a function of ?att and the length-
based penalty ?:
f(A ? {x}) = ??att
where
? =
{
1
?|A| if |A| > 0
1 otherwise
and ? is an empirically determined weight. The
algorithm then chooses a random number n, 0 ?
n ? 1. If n < f(A ? {x}), it adds the property.
4.3 Scanning Through Objects
After the initial pass through the properties, the al-
gorithm compares each object in the scene that is
the same type as the target. If the values for an
attribute are different, then the corresponding prop-
erty is added to the property set based on the length
penalty alone; when the goal is unique identification,
the algorithm can use no penalty. In development,
we found that incrementally scanning through ob-
jects after initially adding properties resulted in bet-
ter performance than an algorithm that did not con-
tain this step.
4.4 Worked Example
Suppose the input in Figure 6 (visualized in Figure
4a), with the goal of referring to obj1 by producing
a property set A. First, the algorithm scans through
color and size in parallel. For color, it finds the cor-
responding value grey; with a computer vision in-
put, this would be possible using the object pixels
as features. There is no length penalty at this point
(|A|=0), so it adds the property color:grey to A with
likelihood ?color. For our evaluation domains, ?color
is around .90 across folds, and so a color property is
usually added.
For size, the algorithm finds an appropriate value
using the Size Algorithm from Mitchell et al (2011).
The Size Algorithm uses the average height and
1178
Figure 3: Basic model for generating visual reference.
width of all objects that are the same type as the ref-
erent object; in this case, obj2, obj3, obj4. This re-
turns a size value large, and so the property size:large
is added toAwith likelihood ?size (around .40 to .70
across folds, depending on the domain).
The most likely property set at this point is sim-
ply ?color:grey?. The next most likely is ?color:grey,
size:large?, then ?size:large?. There are no fur-
ther absolute properties in this example, but there
are values for the relative attributes loc (location)
and ori (orientation). Assuming RP=?location,
orientation?, the algorithm first analyzes location,
then orientation. A location property is added to A
with likelihood ?loc multiplied by the length penalty
?= 1(??1) if A=?color:grey?; ?=
1
(??2) if A=?color:grey,
size:large?, etc.; and an orientation property is added
to A with likelihood ?ori multiplied by the length
penalty ?= 1(??1) if the property set is ?color:grey?,
etc. At this point, the likelihood of adding further
properties quickly diminishes.
Once all properties have been analyzed, the algo-
rithm scans through the objects in the scene. For
each object obj2. . . objn, if the object is the same
type as the target object obj1, then any different
property of the target referent is added to A with
a likelihood based on the length penalty alone ?.
?type:desk? is added at the end.
For this example scene, the algorithm will gen-
erate the property sets ?color:grey, type:desk?,
?color:grey, size:large, type:desk?, ?size:large,
type:desk?, ?color:grey, ori:front, type:desk?,
?color:grey, loc:(3, 1), type:desk?, etc., with dif-
ferent frequencies. Due to the length penalty,
generated property sets will almost never have more
than 3 properties.
tg color:yellow size:(63,63) type:ball loc:right-hand
lm color:red size:(345,345) type:cube loc:right-hand
obj3 color:yellow size:(70,70) type:cube loc:left-hand
Figure 5: Example input scene: GRE3D3 corpus. For IA
And GB, gold-standard size values are provided rather
than measurements (small, large).
obj1 colour:grey size:(454,454) type:desk loc:(3,1) ori:front
obj2 colour:blue size:(454,454) type:desk loc:(2,1) ori:front
obj3 colour:red size:(454,454) type:desk loc:(3,2) ori:back
obj4 colour:green size:(254,254) type:desk loc:(4,1) ori:left
obj5 colour:blue size:(454,454) type:fan loc:(1,1) ori:front
obj6 colour:red size:(454,454) type:fan loc:(5,1) ori:back
obj7 colour:green size:(254,254) type:fan loc:(2,2) ori:left
Figure 6: Example input scene: TUNA corpus. For IA
And GB, gold-standard size values are provided rather
than measurements (small, large).
As such, although ?color:grey, type:desk? would
sufficiently distinguish the intended referent, we
instead produce a variety of sets, overspecify-
ing in some instances (e.g., ?color:grey, ori:front,
type:desk?), and with a small chance of underspec-
ifying in others (e.g., ?size:large, type:desk?).
5 Evaluation Algorithms & Corpora
5.1 Corpora
We evaluate on two well-known REG corpora, the
GRE3D3 corpus (Viethen and Dale, 2008) and the
singular furniture section of the TUNA corpus (van
Deemter et al, 2006). Both corpora contain expres-
sions elicited to computer-generated objects, and so
provide a reasonable starting point for evaluating
reference to visible objects. For all algorithms, we
evaluate on the selection of referent attributes. Lex-
ical choice and word order are not taken into ac-
count. Example images from GRE3D3 and TUNA
are shown in Figure 4, and example algorithm input
1179
from these corpora are shown in Figures 5 and 6.
In GRE3D3, we evaluate on the selection of type,
color, size, and location, but leave aside proper-
ties of relatum objects, which are not currently ad-
dressed by this algorithm or the IA. In TUNA, we
evaluate on the selection of type, color, size and
orientation.5
5.2 Algorithms
5.2.1 The Incremental Algorithm
The Incremental Algorithm requires a preference
order list (PO) specifying the order to iterate through
scene attributes. We determine the preference or-
der from corpus frequencies using cross-validation
to hold out a test scene and list attributes from the
training scenes in descending order. We find that
color precedes size in the preference orders, in line
with recent research showing that this allows the al-
gorithm to perform optimally on the TUNA corpus
(van Deemter et al, 2012a). In development, we find
that IA performs best with type as the last attribute
in the PO, and report on numbers with this approach.
5.2.2 The Graph-Based Algorithm
The version of the Graph-Based Algorithm that
we use is available from Viethen et al (2008). This
algorithm requires (1) a set of cost functions for each
edge, and (2) a PO for deciding between properties
in the case of a tie. For (1), we use the method from
Theune et al (2011) to assign two costs (0, 1) to
the edges. We first determine the relative frequency
with which each property is mentioned for a target
object, and then create costs for each property using
k-means clustering (k=2) in the Weka toolkit (Hall
et al, 2009). We refer interested readers to the The-
une et al paper for further details. For (2), we follow
the same method as for the Incremental Algorithm.
5.2.3 The Visual Objects Algorithm
The proposed algorithm requires ?att, which we
estimate as the relative frequency of each attribute
att in the training data. The ordered attribute lists for
the algorithm (AP, RP and P) are built in the same
way as the preference order list for the IA and GB,
listing attributes from the training data in order of
5We remove location from evaluation in this corpus. Lo-
cation is not annotated directly, but split such that only x-
dimension or y-dimension may be marked for a reference.
descending frequency. For these corpora, there are
not absolute properties beyond color, so AP is empty.
6 Evaluation
Previous evaluation of REG algorithms have used
measurements such as Uniqueness, Minimality,
Dice (Belz and Gatt, 2008), and Accuracy (Gatt et
al., 2009; Reiter and Belz, 2009). Uniqueness is
the proportion of outputs that identify the referent
uniquely, and Minimality is the proportion of out-
puts that are both minimal and unique. As our goal
is to mimic human reference, these metrics are not
as useful for the evaluations as the others.
The Dice metric provides a value for the similar-
ity between a generated description and a human-
produced description, and therefore serves as a rea-
sonable objective measure for how human-like the
produced sets are. Given the generated property set
(DS) and the human-produced property set (DH ),
Dice is calculated as:
2? |DS ?DH |
|DS |+ |DH |
For each input domain, we evaluate over boolean
values (included or excluded) for the attributes D
(see Table 1). Note that this means the specific val-
ues for the attributes are not compared. In this for-
mulation based on boolean values, |DS |=|DH |=|D|
and Dice reduces to:
|DS ?DH |
|D|
Calculating Dice over the same number of at-
tributes for both the observed and generated data
has the nice mathematical property of making Dice
equal to other common metrics for evaluating a
model, including Accuracy, Precision, and Recall.6
Since the proposed algorithm is stochastic, this in-
troduces a problem in using a metric that compares
single expressions. We therefore seek to find the
best alignment between the set of expressions pro-
duced by the algorithm and the set of expressions
produced by people. We formulate this alignment as
an assignment problem weighted by Dice. For the
corpus of observed property sets H and the corpus
of generated property sets S, we find the best align-
6A false positive is a false negative, and there are no true
negatives, so all four metrics are equivalent.
1180
Example Corresponding Evaluated
Expression Property Set Property Set
the red ball ?color:red, type:ball? type:1 color:1
size:0 loc:0
Table 1: Example human expression and corresponding
boolean-valued property set for evaluation in GRE3D3,
with D={type, color, size, and location}.
ment x out of all possible alignmentsX between the
corpora:
argmaxx?X
?
(S,H)?x
Dice(DS , DH )
This may be solved in polynomial time using the
Hungarian method (Kuhn, 1955; Munkres, 1957).
Note that because IA and GB are deterministic, find-
ing an optimal alignment is trivial. We call this
method ALIGNED DICE.
It is an open question whether an alignment-based
evaluation is fair: the proposed algorithm has more
than one chance to match the human descriptions.
In the second evaluation method (MAJORITY) we
address this issue, comparing how often the most
frequent generated set compares with the most fre-
quent observed set. We run the proposed algorithm
1,000 times, and the generated property sets are or-
dered by frequency. The most frequent generated
set is compared against the most frequent human-
produced set. The majority score is the percentage
of folds where these two sets match. For IA and FB,
the most frequent generated set is the only gener-
ated set. This is a simple way to fairly compare the
output of deterministic and non-deterministic algo-
rithms. There are no ties in the generated sets, but
in the case of a tie in the observed data, we count a
match if any match the most frequent generated set.
6.1 GRE3D3
We randomly select two scenes (7, 9) from Set 1
and their mirrored counterparts in Set 2 (17, 19) for
development. We empirically determine ?=5 for the
length-based penalty ? in the proposed algorithm.
We use the eight remaining scenes in each Set
for eight-fold cross-validation, estimating parame-
ters for the algorithms on the seven training scenes
in each fold, as discussed in Section 5.2.
For ALIGNED DICE, we run the proposed algo-
rithm five times in each fold and report the average
Algorithm
ALIGNED DICE MAJORITY
Set 1 Set 2 Set 1 Set 2
Proposed Alg. 88.23 90.06 62.50 50.00
IA 87.71 85.13 62.50 25.00
GB 87.71 88.73 62.50 50.00
Table 2: GRE3D3: Results (in %).
Algorithm
ALIGNED DICE MAJORITY
+LOC -LOC +LOC -LOC
Proposed Alg. 88.75 86.07 40.00 40.00
IA 81.79 81.55 0.00 100.00
GB 75.36 66.04 20.00 20.00
Table 3: TUNA: Results (in %).
score. Results are shown in Table 2.7
The proposed Visible Objects Algorithm achieves
higher accuracy than either version of the Incremen-
tal Algorithm or the Graph-Based Algorithm using
ALIGNED DICE. In MAJORITY, the Graph-Based
and the Visible Objects Algorithm both predict the
majority property set in this evaluation at least 50%
of the time. The algorithm is competitive with the
state of the art on this corpus.
6.2 TUNA
TUNA is split into two conditions: subjects discour-
aged to use location (-LOC) or not (+LOC). We ran-
domly hold out two scenes from both conditions (1
and 2), and find a value of ?=5 again works well on
the development data.
As in the GRE3D3 corpus, we use the TUNA
scenes in five-fold cross-validation, estimating pa-
rameters on the four training scenes in each fold. For
ALIGNED DICE, we average over five runs of the al-
gorithm, and for MAJORITY, we run the proposed
algorithm 1,000 times for each test scene.
Results are shown in Table 3. Again we see that
the proposed Visible Objects Algorithm is compet-
itive with the IA and GB for both ALIGNED DICE
and MAJORITY. GB performs poorly here, and this
may be due to the data sparsity issue that arises when
requiring the algorithm to train on properties.8 In
7We do not report statistical significance; the proposed algo-
rithm produces several possible outputs for one input, while the
IA and GB produce only one.
8The original property-based weighting approach (Theune
et al, 2011; Koolen et al, 2012, see Section 5.2) trained on ob-
ject collections that were identical to their test data in all proper-
ties except x- and y-dimension, and so this was less of an issue.
We hope to explore whether basing weights on attributes alone
1181
MAJORITY, the Visible Objects Algorithm is rela-
tively stable across conditions, generating the ma-
jority property set in 40% of the test scenes. It does
not outperform the IA in the -LOC condition, but the
IA has a large range across the two conditions (0%
and 100%).
7 Conclusions and Future Work
We have introduced a new algorithm for generating
referring expressions, inspired by human and com-
puter vision and aiming to refer in a human-like way
to visible objects. The algorithm successfully gener-
ates the most common attributes that people choose
for different objects, and offers a varied output to
capture speaker variation. In contrast to most algo-
rithms for the generation of referring expressions,
which have aimed to produce distinguishing descrip-
tions when these exist (Krahmer and van Deemter,
2012), the core idea behind this algorithm is to gen-
erate what is likely for a speaker in a visual domain.
Since the driving mechanism behind the algorithm
is not to uniquely identify the object, but rather to
pipeline the analysis of properties in a way similar
to human visual processing, the generated expres-
sion may be overspecified or underspecified.
We are limited by available REG corpora to re-
liably assess methods for generating more com-
plex absolute properties like shape and material, but
adding such properties would help advance the gen-
eration of human-like reference in visual scenes and
offers further points of connection between the gen-
eration process and computer vision property detec-
tion. Models for generating more complex spatial
relations are currently available, and are a natural
extension to this framework (e.g., those of Kelleher
and Costello (2009)) as object detection becomes
more robust.
We may also be able to build more sophisticated
graphical models as larger corpora become avail-
able. For example, modeling the conditional proba-
bility of generating reference for a property vn given
the previously generated context p(vn|v1 . . . vn?1)
may bring us closer to human-like output.
There are several additional issues that do not
arise in this evaluation, but we expect must be ac-
counted for when referring to naturalistic objects in
improves performance.
visual domains. These include:
? The interconnected nature of properties, where
some properties entail others; for example, a
wooden object is likely to be called wooden, re-
ferring to its material, rather than tan or brown.
? The role of typicality, where properties are se-
lected because they are atypical for the object.
? Referring to more complex properties, e.g., ma-
terial, texture, etc., and object parts.
? Better methods for determining the length
penalty and attribute likelihoods.
We hope to discuss extensions to this algorithm
covering these aspects of reference in future work.
Acknowledgments
Funding for this research has been provided by
SICSA and ORSAS. We thank the anonymous re-
viewers for useful comments on this paper.
References
Carlos Areces, Alexander Koller, and Kristina Striegnitz.
2008. Referring expressions as formulas of descrip-
tion logic. Proceedings of the 5th International Nat-
ural Language Generation Conference (INLG 2008),
pages 42?29.
Ellen Gurman Bard, Robin Hill, Manabu Arai, and
Mary Ellen Foster. 2009. Accessibility and attention
in situated dialogue: Roles and regulations. Proceed-
ings of the Workshop on the Production of Referring
Expressions (PRE-CogSci 2009).
Anja Belz and Albert Gatt. 2008. Intrinsic vs. extrin-
sic evaluation measures for referring expression gen-
eration. Proceedings of the 46th Annual Meeting of
the Association for Computational Linguistics (ACL
2008), pages 197?200.
Alexander C. Berg, Tamara L. Berg, Hal Daume? III,
Jesse Dodge, Amit Goyal, Xufeng Han, Alyssa Men-
sch, Margaret Mitchell, Karl Stratos, and Kota Yam-
aguchi. 2011. An exploration of how to learn from
visually descriptive text. JHU-CLSP Summer Work-
shop Whitepaper.
Steven Bird, Edward Loper, and Ewan Klein. 2009. Nat-
ural Language Processing with Python. O?Reilly Me-
dia Inc., Sebastopol, CA.
Sarah Brown-Schmidt and Michael K. Tanenhaus. 2006.
Watching the eyes when talking about size: An investi-
gation of message formulation and utterance planning.
Journal of Memory and Language, 54:592?609.
1182
Herbert H. Clark and Gregory L. Murphy. 1982. Audi-
ence Design in Meaning and Reference. In J. F. LeNy
and W. Kintsch, editors, Language and Comprehen-
sion, volume 9 of Advances in Psychology, pages 287?
299. North-Holland, Amsterdam.
Herbert H. Clark, Robert Schreuder, and Samuel But-
trick. 1983. Common ground and the understanding
of demonstrative reference. Journal of Verbal Learn-
ing and Verbal Behavior, 22:245?258.
Robert Dale and Ehud Reiter. 1995. Computational in-
terpretations of the gricean maxims in the generation
of referring expressions. Cognitive Science, 19:233?
263.
Robert Dale. 1989. Cooking up referring expressions.
Proceedings of the 27th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL 1989).
P. E. Engelhardt, K. Bailey, and F. Ferreira. 2006. Do
speakers and listeners observe the gricean maxim of
quantity? Journal of Memory and Language, 54:554?
573.
Fang Fang, Huseyin Boyaci, Daniel Kersten, and Scott O.
Murray. 2008. Attention-dependent representation
of a size illusion in human V1. Current biology,
18(21):1707?1712.
Ali Farhadi, Ian Endres, Derek Hoiem, and David
Forsyth. 2009. Describing objects by their attributes.
Proceedings of IEEE Conference on Computer Vision
and Pattern Recognition (CVPR 2009).
V. Ferrari and A. Zisserman. 2007. Learning visual at-
tributes. Advances in Neural Information Processing
Systems (NIPS 2007).
William Ford and David Olson. 1975. The elabora-
tion of the noun phrase in children?s description of ob-
jects. The Journal of Experimental Child Psychology,
19:371?382.
David A. Forsyth. 2011. Personal communica-
tion. Video clip of communication available from:
http://vimeo.com/40553150. At 1:06:46.
T. M. Gann and D. J. Barr. 2013. Speaking from expe-
rience: Audience design as expert performance. Lan-
guage and Cognitive Processes. In press.
Albert Gatt and Anja Belz. 2008. Attribute selec-
tion for referring expression generation: New algo-
rithms and evaluation methods. Proceedings of 5th In-
ternational Natural Language Generation Conference
(INLG 2008), pages 50?58.
Albert Gatt, Anja Belz, and Eric Kow. 2009. The TUNA
REG challenge 2009: Overview and evaluation results.
Proceedings of the 12th European Workshop on Natu-
ral Language Generation (ENLG 2009), pages 174?
182.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: An update.
SIGKDD Explorations, 11(1).
William S. Horton and Boaz Keysar. 1996. When do
speakers take into account common ground? Cogni-
tion, 59(1):91?117.
Laurent Itti and Christof Koch. 2001. Computational
modelling of visual attention. Nature Reviews Neuro-
science, 2:194?203.
John Kelleher and Fintan Costello. 2009. Applying
computational models of spatial prepositions to vi-
sually situated dialog. Computational Linguistics,
35(2):271?306.
John Kelleher, Fintan Costello, and Josef van Genabith.
2005. Dynamically structuring, updating and interre-
lating representations of visual and linguistic discourse
context. Artificial Intelligence, 167:62?102.
Boaz Keysar and Anne S. Henly. 2002. Speakers? over-
estimation of their effectiveness. Psychological Sci-
ence, 13(3):207?212.
Ruud Koolen, Martijn Goudbeek, and Emiel Krahmer.
2011. Effects of scene variation on referential over-
specification. Proceedings of the 33rd Annual Meeting
of the Cognitive Science Society (CogSci 2011).
Ruud Koolen, Emiel Krahmer, and Marie?t Theune. 2012.
Learning preferences for referring expression genera-
tion: Effects of domain, language and algorithm. Pro-
ceedings of the 7th International Workshop on Natural
Language Generation (INLG 2012).
Emiel Krahmer and Marie?t Theune. 2002. Efficient
context-sensitive generation of referring expressions.
Information Sharing: Reference and Presupposition
in Language Generation and Interpretation, 143:223?
263.
Emiel Krahmer and Kees van Deemter. 2012. Compu-
tational generation of referring expressions: A survey.
Computational Linguistics, 38:173?218.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
H. W. Kuhn. 1955. The hungarian method for the assign-
ment problem. Naval Research Logistics Quarterly,
2:83?97.
Margaret Mitchell, Kees van Deemter, and Ehud Reiter.
2011. Two approaches for generating size modifiers.
Proceedings of the 13th European Workshop on Natu-
ral Language Generation (ENLG 2011).
James Munkres. 1957. Algorithms for the assignment
and transportation problems. Journal of Industrial and
Applied Mathematics, 5(1):32?38.
Scott O. Murray, Huseyin Boyaci, and Daniel Kersten.
2006. The representation of perceived angular size in
human primary visual cortex. Nature Neuroscience,
9(3):429?434.
1183
David R. Olson. 1970. Language and thought: Aspects
of a cognitive theory of semantics. Psychological Re-
view, 77:257?273.
Thomas Pechmann. 1989. Incremental speech pro-
duction and referential overspecification. Linguistics,
27:89?110.
Ehud Reiter and Anja Belz. 2009. An investigation into
the validity of some metrics for automatically evalu-
ating natural language generation systems. Computa-
tional Linguistics, 35(4):529?558.
Ehud Reiter and Robert Dale. 1992. A fast algorithm
for the generation of referring expressions. Proceed-
ings of the 14th International Conference on Compu-
tational Linguistics (COLING 1992), 1:232?238.
Ehud Reiter and Somayajulu Sripada. 2002. Human
variation and lexical choice. Computational Linguis-
tics, 28:545?553.
D. Samuel Schwarzkopf, Chen Song, and Geraint Rees.
2010. The surface area of human V1 predicts the
subjective experience of object size. Nature Neuro-
science, 14(1):28?30.
J. R. Searle. 1969. Speech Acts: An Essay in the Philos-
ophy of Language. Cambridge University Press, Cam-
bridge.
Susan Sonnenschein. 1985. The development of referen-
tial communication skills: Some situations in which
speakers give redundant messages. Journal of Psy-
cholinguistic Research, 14:489?508.
Marie?t Theune, Ruud Koolen, Emiel Krahmer, and
Sander Wubben. 2011. Does size matter ? how much
data is required to train a REG algorithm? Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics (ACL 2011).
Anne M. Treisman and Garry Gelade. 1980. A feature
integration theory of attention. Cognitive Psychology,
12:97?13.
Anne Treisman. 1985. Preattentive processing in vi-
sion. Computer Vision, Graphics, and Image Process-
ing, 31:156177.
L. G. Ungerleider and M. Mishkin. 1982. Two Corti-
cal Visual Systems. In D. J. Ingle, M. Goodale, and
R. J. W. Mansfield, editors, Analysis of Visual Be-
haviour, chapter 18, pages 549?586. The MIT Press.
Kees van Deemter, Ielka van der Sluis, and Albert Gatt.
2006. Building a semantically transparent corpus for
the generation of referring expressions. Proceedings
of the 4th International Conference on Natural Lan-
guage Generation (INLG 2006).
Kees van Deemter, Albert Gatt, Ielka van der Sluis, and
Richard Power. 2012a. Generation of referring ex-
pressions: Assessing the incremental algorithm. Cog-
nitive Science, 36(5):799?836.
Kees van Deemter, Emiel Krahmer, Roger van Gompel,
and Albert Gatt. 2012b. Towards a computational psy-
cholinguistics of reference production. TopiCS: Pro-
duction of Referring Expressions - Bridging the Gap
between Computational and Empirical Approaches to
Reference.
Roger P. G. van Gompel, Albert Gatt, Emiel Krahmer,
and Kees van Deemter. 2012. PRO: A computational
model of referential overspecification. Architectures
and Mechanisms for Language Processing (AMLaP
2012).
Jette Viethen and Robert Dale. 2008. The use of spatial
relations in referring expression generation. Proceed-
ings of the 5th International Natural Language Gener-
ation Conference (INLG 2008), pages 59?67.
Jette Viethen and Robert Dale. 2010. Speaker-dependent
variation in content selection for referring expression
generation. Proceedings of the 8th Australasian Lan-
guage Technology Workshop (ALTW 2010), pages 81?
89.
Jette Viethen, Robert Dale, Emiel Krahmer, Marie?t The-
une, and Pascal Touset. 2008. Controlling redundancy
in referring expressions. Proceedings of the 6th In-
ternational Conference on Language Resources and
Evaluation (LREC 2008).
Jette Viethen, Martijn Goudbeek, and Emiel Krahmer.
2012. The impact of colour difference and coloure
codability on reference production. Proceedings of the
34th Annual Meeting of the Cognitive Science Society
(CogSci 2012).
G. J. Whitehurst. 1976. The development of communi-
cation: Changes with age and modeling. Child Devel-
opment, 47:473?482.
1184
Natural Reference to Objects in a Visual Domain
Margaret Mitchell
Computing Science Dept.
University of Aberdeen
Scotland, U.K.
Kees van Deemter
Computing Science Dept.
University of Aberdeen
Scotland, U.K.
{m.mitchell, k.vdeemter, e.reiter}@abdn.ac.uk
Ehud Reiter
Computing Science Dept.
University of Aberdeen
Scotland, U.K.
Abstract
This paper discusses the basic structures
necessary for the generation of reference
to objects in a visual scene. We construct
a study designed to elicit naturalistic re-
ferring expressions to relatively complex
objects, and find aspects of reference that
have not been accounted for in work on
Referring Expression Generation (REG).
This includes reference to object parts,
size comparisons without crisp measure-
ments, and the use of analogies. By draw-
ing on research in cognitive science, neu-
rophysiology, and psycholinguistics, we
begin developing the input structure and
background knowledge necessary for an
algorithm capable of generating the kinds
of reference we observe.
1 Introduction
One of the dominating tasks in Natural Language
Generation (NLG) is the generation of expressions
to pick out a referent. In recent years there has
been increased interest in generating referential
expressions that are natural, e.g., like those pro-
duced by people. Although research on the gener-
ation of referring expressions has examined differ-
ent aspects of how people generate reference, there
has been surprisingly little research on how people
refer to objects in a real-world setting. This paper
addresses this issue, and we begin formulating the
requirements for an REG algorithm that refers to
visible three-dimensional objects in the real world.
Reference to objects in a visual domain pro-
vides a straightforward extension of the sorts of
reference REG research already tends to consider.
Toy examples outline reference to objects, peo-
ple, and animals that are perceptually available
before the speaker begins generating an utterance
(Dale and Reiter, 1995; Krahmer et al, 2003; van
Deemter et al, 2006; Areces et al, 2008). Exam-
ple referents may be referred to by their color, size,
type (?dog? or ?cup?), whether or not they have a
beard, etc.
Typically, the reference process proceeds by
comparing the properties of the referent with the
properties of all the other items in the set. The
final expression roughly conforms to the Gricean
maxims (Grice, 1975).
However, when the goal is to generate natural
reference, this framework is too simple. The form
reference takes is profoundly affected by modality,
task, and audience (Chapanis et al, 1977; Cohen,
1984; Clark and Wilkes-Gibbs, 1986), and even
when these aspects are controlled, different people
will refer differently to the same object (Mitchell,
2008). In light of this, we isolate one kind of nat-
ural reference and begin building the algorithmic
framework necessary to generate the observed lan-
guage.
Psycholinguistic research has examined refer-
ence in a variety of settings, which may inform
research on natural REG, but it is not always clear
how to extend this work to a computational model.
This is true in part because these studies favor an
analysis of reference in the context of collabora-
tion; reference is embedded within language, and
language is often a joint activity. However, most
research on referring expression generation sup-
poses a solitary generating agent.1 This tacitly
assumes that reference will be taking place in a
monologue setting, rather than a dialogue or group
setting. Indeed, the goal of most REG algorithms
is to produce uniquely distinguishing, one-shot re-
ferring expressions.
Studies on natural reference usually use a
two person (speaker-listener) communication task
(e.g., Flavell et al, 1968; Krauss and Glucksberg,
1969; Ford and Olson, 1975). This research has
1A notable exception is Heeman and Hirst (1995).
shown that reference is more accurate and efficient
when it incorporates things like gesture and gaze
(Clark and Krych, 2004). There is a trade-off in
effort between initiating a noun phrase and refash-
ioning it so that both speakers understand the ref-
erent (Clark and Wilkes-Gibbs, 1986), and speak-
ers communicate to form lexical pacts on how
to refer to an object (Sacks and Schegloff, 1979;
Brennan and Clark, 1996). Mutual understanding
of referents is achieved in part by referring within
a subset of potential referents (Clark et al, 1983;
Beun and Cremers, 1998). A few studies have
compared monologue to dialogue reference, and
have shown that monologue references tend to be
harder for a later listener to disambiguate (Clark
and Krych, 2004) and that subsequent references
tend to be longer than those in dialogues (Krauss
and Weinheimer, 1967).
Aiming to generate natural reference in a mono-
logue setting raises questions about what an algo-
rithm should use to produce utterances like those
produced by people. In a monologue setting, the
speaker (or algorithm) gets no feedback from the
listener; the speaker?s reference is not tied to in-
teractions with other participants. The speaker
is therefore in a difficult position, attempting to
clearly convey a referent without being able to
check if the reference is understood along the way.
Recent studies that have focused on monologue
reference do so rather explicitly, which may af-
fect participant responses. These studies utilize
2D graphical depictions of simple 3D objects (van
Deemter et al, 2006; Viethen and Dale, 2008),
where a small set of properties can be used to dis-
tinguish one item from another. The expressions
are elicited in isolation, typed and then submitted,
which may hide some of the underlying referen-
tial processes. None of these studies utilize actual
objects. It is therefore difficult to use these data
to draw conclusions about how reference works in
naturalistic settings. It is unclear if these experi-
mental settings are natural enough, i.e., if they get
at reference as it may occur every day.
The study in this paper attempts to bring out in-
formation about reference in a number of ways.
First, we conduct the study in-person, using real-
world objects. This design invites referential phe-
nomena that may not have been previously ob-
served in simpler domains. Second, the refer-
ring expressions are produced orally. This allows
us access to reference as it is generated, without
the participants revising and so potentially obscur-
ing information about their reference. Third, we
use a relatively complicated task, where partici-
pants must explain how to use pieces to put to-
gether a picture of a face. The fact that we are
looking at reference is not made explicit, which
lessens any experimental effects caused by sub-
jects guessing the purpose of the study. This ap-
proach also situates reference within a larger task,
which may draw out aspects of reference not usu-
ally seen in experiments that elicit reference in iso-
lation. Fourth, the objects used display a variety
of different features: texture, material, color, size
along several dimensions, etc. This brings the data
set closer to objects that people interact with every
day. A monologue setting offers a picture of the
phenomena at play during a single individual?s re-
ferring expression generation.
The referring expressions gathered in this study
exhibit several aspects of reference that have not
yet been addressed in REG. This includes (1) part-
whole modularity; (2) size comparisons across
three dimensions; and (3) analogies. Work in cog-
nitive sciences suggests that these phenomena are
interrelated, and may be possible to represent in a
computational framework. This research also of-
fers connections to further aspects of natural refer-
ence that were not directly observed in the study,
but will need to be accounted for in future work on
naturalistic referring expression generation. Us-
ing these ideas, we begin formulating the struc-
tures that an REG algorithm would need in order
to produce reference to real-world objects in a vi-
sual setting.
Approaching REG in this way allows us to tie
research in the generation of referring expressions
to computational models of visual perception and
cognitively-motivated computer vision. Moving in
this direction offers the prospect of eventually de-
veloping an application for the generation of nat-
ural reference to objects automatically recognized
by a computer vision system.
In the next section, we describe our study. In
Section 3, we analyze the results and discuss what
they tell us about natural reference. In Section 4,
we draw on our results and cognitive models of ob-
ject recognition to begin building the framework
for a referring expression algorithm that generates
naturalistic reference to objects in a visual scene.
In Section 5, we offer concluding remarks and out-
line areas for further study.
Figure 1: Object Board.
2 Method
2.1 Subjects
The subjects were 20 residents of Aberdeen, Scot-
land, and included undergraduates, graduates, and
professionals. All were native speakers of English,
had normal or corrected vision, and had no other
known visual issues (such as color-blindness).
Subjects were paid for their participation. Two
recordings were left out of the analysis: one par-
ticipant?s session was not fully recorded due to a
software error, and one participant did not pick out
many objects in each face and so was not included.
The final set of participants included 18 people, 10
female and 8 male.
2.2 Materials
A board was prepared with 51 craft objects. The
objects were chosen from various craft sets, and
included pom-poms, pipe-cleaners, beads, and
feathers (see Table 1). The motley group of objects
had different colors, textures, shapes, patterns, and
were made of different materials. Similar objects
were grouped together on the board, with a label
placed underneath. This was done to control the
head noun used in each reference. The objects
were used to make up 5 different craft ?face? pic-
tures. Subjects sat at a desk facing the board and
the stack of pictures. A picture of the board is
shown in Figure 1.
Subjects were recorded on a head-mounted mi-
crophone, which fed directly into a laptop placed
on the left of the desk. The open-source audio-
recording program Audacity (Mazzoni, 2010) was
used to record the audio signal and export it to
wave format.
2.3 Procedure
Subjects were told to give instructions on how to
construct each face using the craft supplies on the
board. They were instructed to be clear enough for
a listener to be able to reconstruct each face with-
out the pictures, with only the board items in front
of them. A pilot study revealed that such open-
ended instructions left some subjects spending an
inordinate amount of time on the exact placement
of each piece, and so in the current study sub-
jects were told that each face should take ?a cou-
ple? minutes, and that the instructions should be
as clear as possible for a listener to use the same
objects in reconstructing the pictures without be-
ing ?overly concerned? with the details of exactly
how each piece is angled in relation to the other.
Subjects were first given a practice face to de-
scribe. This face was the same face for all subjects.
They were then allowed to voice any concerns or
ask questions, but the experimenter only repeated
portions of the original instructions; no new infor-
mation was given. The subject could then proceed
to the next four faces, which were in a random or-
der for each subject. A transcript of a single face
from a session is provided in Figure 2.
2.4 Analysis
The recordings of each monologue were tran-
scribed, including disfluencies, and each face sec-
tion (?eyes?, ?chin?, etc.) was marked. First refer-
ence to items on the board were annotated with
their corresponding item numbers, yielding 722
references.2 Initial references to single objects
were extracted, creating a final data set with 505
references to single objects.
3 Results
Each reference was annotated in terms of the prop-
erties used to pick out the referent. For exam-
ple, ?the red feather? was annotated as contain-
ing the <ATTRIBUTE:value> pairs <COLOR:red,
TYPE:feather>. Discerning properties from the
modifiers used in reference is generally straight-
forward, and all of the references produced may
be partially deconstructed using such properties.
2This corpus is available at
http://www.csd.abdn.ac.uk/?mitchema/craft corpus.
14 foam shapes 2 large red hearts 2 small red hearts 2 small neon green hearts
2 small blue hearts 1 small green heart 1 green triangle 1 red circle
1 red square 1 red rectangle 1 white rectangle
11 beads 4 large round wooden beads 2 small white plastic beads 2 brown patterned beads
1 gold patterned bead 1 shiny gold patterned heart 1 red patterned heart
9 pom poms 2 big green pom-poms 2 small neon green pom-poms 2 small silver pom-poms
1 small metallic green pom-pom 1 large white pom-pom 1 medium white pom-pom
8 pipe cleaners 1 gold pipe-cleaner 1 gold pipe-cleaner in half 1 silver pipe-cleaner
1 circular neon yellow soft pipe-cleaner 1 neon orange puffy pipe-cleaner 1 grey puffy pipe-cleaner
1 purple/yellow striped pipe-cleaner 1 brown/grey striped pipe-cleaner
5 feathers 2 purple feathers 2 red feathers 1 yellow feather
3 ribbons 1 gold sequined wavy ribbon 1 silver wavy ribbon 1 small silver wavy ribbon
1 star 1 gold star
Table 1: Board items.
<CHIN> Okay so this face again um this face has um uh
for the chin, it uses (10 a gold pipe-cleaner in a V shape)
where the bottom of the V is the chin. </CHIN>
<MOUTH> The mouth is made up of (9 a purple feather).
And the mouth is slightly squint, um as if the the person
is smiling or even smirking. So this this smile is almost
off to one side. </MOUTH>
<NOSE> The nose is uh (5 a wooden bead, a medium-
sized wooden bead with a hole in the center). </NOSE>
<EYES> And the eyes are made of (2,3 white pom-poms),
em just uh em evenly spaced in the center of the face.
</EYES>
<FOREHEAD> Em it?s see the person?s em top of the per-
son?s head is made out of (1 another, thicker pipe-cleaner
that?s uh a grey color, it?s kind of uh a knotted blue-type
pipe-cleaner). So that that acts as the top of the person?s
head. </FOREHEAD>
<HAIR> And down the side of the person?s face, there are
(7,8 two ribbons) on each side. (7,8 And those are silver
ribbons). Um and they just hang down the side of the face
and they join up the the grey pipe-cleaner and the top um
of the person?s head to the to the chin and then hang down
either side of the chin. </HAIR>
<EARS> And the person?s ears are made up of (4,6 two
beads, which are um love-heart-shaped beads), where the
points of the love-hearts are facing outwards. And those
are just placed um around same em same em horizontal
line as the nose of the person?s face is. </EARS>
Figure 2: Excerpt Transcript.
Using sets of properties to distinguish referents
is nothing new in REG. Algorithms for the genera-
tion of referring expressions commonly use this as
a starting point, proposing that properties are orga-
nized in some linear order (Dale and Reiter, 1995)
or weighted order (Krahmer et al, 2003) as input.
However, we find evidence that more is at play. A
breakdown of our findings is listed in Table 2.
3.1 Spatial Reference
In addition to properties that pick out referents,
throughout the data we see reference to objects
as they exist in space. Size is compared across
different dimensions of different objects, and ref-
erence is made to different parts of the objects,
picking out pieces within the whole. These two
phenomena ? relative size comparisons and part-
whole modularity ? point to an underlying spatial
object representation that may be utilized during
reference.
3.1.1 Relative Size Comparisons
A total of 122 (24.2%) references mention size
with a vague modifier (e.g., ?big?, ?wide?). This
includes comparative (e.g, ?larger?) and superla-
tive (e.g., ?largest?) size modifiers, which occur 40
(7.9%) times in the data set. Examples are given
below.
(1) ?the bigger pom-pom?
(2) ?the green largest pom-pom?
(3) ?the smallest long ribbon?
(4) ?the large orange pipe-cleaner?
Of the references that mention size, 35 (6.9%)
use a vague modifier that applies to one or two di-
mensions. This includes modifiers for height (?the
short silver ribbon?), width (?quite a fat rectan-
gle?), and depth (?the thick grey pipe-cleaner?).
87 (17.2%) use a modifier that applies to the over-
all size of the object (e.g., ?big? or ?small?). Table
3 lists these values. Crisp measurements (such as
?1 centimeter?) occur only twice (0.4%), with both
produced by the same participant.
Comparative/Superlative: 40 (7.9%)
Base: 82 (16.2%)
Height/Width/Depth: 35 (6.9%)
Overall size: 87 (17.2%)
Table 3: Size Modifier Breakdown.
Part-whole modularity Relative size Analogies
?a green pom-pom. . . ?a red foam-piece. . . ?a natural-looking piece
with the tinsel on the outside? which is more square of pipe-cleaner, it looks
?your gold twisty ribbon. . . in shape rather than a bit like a rope?
with sequins on it? the longer rectangle? ?a pipe-cleaner that
?a wooden bead. . . ?the grey pipe-cleaner. . . looks a bit like. . .
with a hole in the center? which is the thicker one. . . a fluffy caterpillar?
?one of the green pom-poms. . . ?the slightly larger one? ?the silver ribbon
with the sort of strands ?the smaller silver ribbon? that?s almost like
coming out from it.? ?the short silver ribbon? a big S shape.?
?the silver ribbon. . . with the chainmail ?quite a fat rectangle? ?a. . . pipe-cleaner
detail down through the middle of it.? ?thick grey pipe-cleaner? that looks like tinsel.?
11 References 122 References 16 References
Table 2: Examples of Observed Reference.
Participants produce such modifiers without
sizes or measurements explicitly given; with an
input of a visual object presentation, the output
includes size modifiers. Such data suggests that
natural reference in a visual domain utilizes pro-
cesses comparing the length, width, and height of
a target object with other objects in the set. Indeed,
5 references (1.0%) in our data set include explicit
comparison with the size of other objects.
(5) ?a red foam-piece. . . which is more square in
shape rather than the longer rectangle?
(6) ?the grey pipe-cleaner. . . which is the thicker
one. . . of the selection?
(7) ?the shorter of the two silver ribbons?
(8) ?the longer one of the ribbons?
(9) ?the longer of the two silver ribbons?
In Example (5), height and width across two
different objects are compared, distinguishing a
square from a rectangle. In (6) ?thicker? marks
the referent as having a larger circumference than
other items of the same type. (7) (8) and (9) com-
pare the height of the target referent to the height
of similar items.
The use of size modifiers in a domain without
specified measurements suggests that when peo-
ple refer to an object in a visual domain, they
are sensitive to its size and structure within a di-
mensional, real-world space. Without access to
crisp measurements, people compare relative size
across different objects, and this is reflected in the
expressions they generate. These comparisons are
not only limited to overall size, but include size
in each dimension. This suggests that objects?
structures within a real-world space are relevant
to REG in a visual domain.
3.1.2 Part-Whole Modularity
The role that a spatial object understanding has
within reference is further detailed by utterances
that pick out the target object by mentioning an ob-
ject part. 11 utterances (2.2%) in our data include
mention of an object part within reference to the
whole object. This is spread across participants,
such that half of the participants make reference
to an object part at least once.
(10) ?a green pom-pom, which is with the tinsel
on the outside?
(11) ?your gold twisty ribbon...with sequins on
it?
(12) ?a wooden bead...with a hole in the center?
In (10), pieces of tinsel are isolated from the
whole object and specified as being on the outside.
In (11), smaller pieces that lay on top of the ribbon
are picked out. And in (12), a hole within the bead
is isolated.
The use of part-whole modularity suggests an
understanding that parts of the object take up their
own space within the object. An object is not only
viewed as a whole during reference, but parts in,
on, and around it may be considered as well. For
an REG algorithm to generate these kinds of ref-
erences, it must be provided with a representation
that details the structure of each object.
3.2 ANALOGIES
The data from this study also provide information
on what can be expected from a knowledge base
in an algorithm that aims to generate naturalistic
reference. Reference is made 16 times (3.2%) to
objects not on the board, where the intended refer-
ent is compared against something it is like. Some
examples are given below.
(13) ?a gold. . . pipe-cleaner. . . completely
straight, like a ruler?
(14) ?a natural-looking piece of pipe-cleaner, it
looks a bit like a rope?
(15) ?a pipe-cleaner that looks a bit like. . . a
fluffy caterpillar. . . ?
In (13), a participant makes reference to a
SHAPE property of an object not on the board. In
(14) and (15), participants refer to objects that may
share a variety of properties with the referent, but
are also not on the board.
Reference to these other items do not pick out
single objects, but types of objects (e.g., an object
type, not token). They correspond to some pro-
totypical idea of an object with properties similar
to those of the referent. Work by Rosch (1975)
has examined this tendency, introducing the idea
of prototype theory, which proposes that there may
be some central, ?prototypical? notions of items. A
knowledge base with stored prototypes could be
utilized by an REG algorithm to compare the tar-
get referent to item prototypes. Such representa-
tions would help guide the generation of reference
to items not in the scene, but similar to the target
referent.
4 Discussion
We have discussed several different aspects of ref-
erence in a study where referring expressions are
elicited for objects in a spatial, visual scene. Ref-
erence in this domain draws on object forms as
they exist in a three-dimensional space and uti-
lizes background knowledge to describe referents
by analogy to items outside of the scene. This
is undoubtedly not an exhaustive account of the
phenomena at play in such a domain, but offers
some initial conclusions that may be drawn from
exploratory work of this kind.
Before continuing with the discussion, it is
worthwhile to consider whether some of our data
might be seen as going beyond reference. Perhaps
the participants are doing something else, which
could be called describing. How to draw the line
between a distinguishing reference and a descrip-
tion, and whether such a line can be drawn at all, is
an interesting question. If the two are clearly dis-
tinct, then both are interesting to NLG research.
If the two are one in the same, then this sheds
some light on how REG algorithms should treat
reference. We leave a more detailed discussion of
this for future work, but note recent psycholinguis-
tic work suggesting that referring establishes (1)
an individual as the referent; (2) a conceptualiza-
tion or perspective on that individual (Clark and
Bangerter, 2004). Schematically, referring = indi-
cating + describing.
We now turn to a discussion of how the ob-
served phenomena may be best represented in an
REG algorithm. We propose that an algorithm ca-
pable of generating natural reference to objects in
a visual scene should utilize (1) a spatial object
representation; (2) a non-spatial feature-based rep-
resentation; and (3) a knowledge base of object
prototypes.
4.1 Spatial and Visual Properties
It is perhaps unsurprising to find reference that ex-
hibits spatial knowledge in a study where objects
are presented in three-dimensional space. Hu-
man behavior is anchored in space, and spatial in-
formation is essential for our ability to navigate
the world we live in. However, referring expres-
sion generation algorithms geared towards spa-
tial representations have oversimplified this ten-
dency, keeping objects within the realm of two-
dimensions and only looking at the spatial rela-
tions between objects.
For example, Funakoshi et al (2004) and Gatt
(2006) focus on how objects should be clustered
together to form groups. This utilizes some of
the spatial information between objects, but does
not address the spatial, three-dimensional nature
of objects themselves. Rather, objects exist as en-
tities that may be grouped with other entities in a
set or singled out as individual objects; they do not
have their own spatial characteristics. Similarly,
one of the strengths of the Graph-Based Algorithm
(Krahmer et al, 2003) is its ability to generate ex-
pressions that involve relations between objects,
and these include spatial ones (?next to?, ?on top
of?, etc.). In all these approaches, however, ob-
jects are essentially one-dimensional, represented
as individual nodes.
Work that does look at the spatial information
of different objects is provided by Kelleher et al
(2005). In this approach, the overall volume of
each object is calculated to assign salience rank-
ings, which then allow the Incremental Algorithm
(Dale and Reiter, 1995) to produce otherwise ?un-
derspecified? reference. The spatial properties of
the objects are kept relatively simple. They are
not used in constructing the referring expression,
but one aspect of the object?s three-dimensional
shape (volume) affects the referring expression?s
final form. To the authors? knowledge, the cur-
rent work is the first to suggest that objects them-
selves should have their spatial properties repre-
sented during reference.
Research in cognitive modelling supports the
idea that we attend to the spatial properties of ob-
jects when we view them (Blaser et al, 2000), and
that we have purely spatial attentional mechanisms
operating alongside non-spatial, feature-based at-
tentional mechanisms (Treue and Trujillo, 1999).
These feature-based attentional mechanisms pick
out properties commonly utilized in REG, such as
texture, orientation, and color. They also pick out
edges and corners, contrast, and brightness. Spa-
tial attentional mechanisms provide information
about where the non-spatial features are located in
relation to one another, size, and the spatial inter-
relations between component parts.
Applying these findings to our study, an REG
algorithm that generates natural reference should
utilize a visual, feature-based representation of ob-
jects alongside a structural, spatial representation
of objects. A feature-based representation is al-
ready common to REG, and could be represented
as a series of <ATTRIBUTE:value> pairs. A spa-
tial representation is necessary to define how the
object is situated within a dimensional space, pro-
viding information about the relative distances be-
tween object components, edges, and corners.
With such information provided by a spatial
representation, the generation of part-whole ex-
pressions, such as ?the pom-pom with the tinsel on
the outside?, is possible. This also allows for the
generation of size modifiers (?big?, ?small?) with-
out the need for crisp measurements, for example,
by comparing the difference in overall height of
the target object with other objects in the scene, or
against a stored prototype (discussed below). Rel-
ative size comparisons across different dimensions
would also be possible, used to generate size mod-
ifiers such as ?wide? and ?thick? that refer to one
dimensional axis.
4.2 Analogies
A feature-based and a spatial representation may
also play a role in analogies. When we use analo-
gies, as in ?the pipe-cleaner that looks like a cater-
pillar?, we use world knowledge about items that
are not themselves visible. Such an expression
draws on similarity that does not link the referent
with a particular object, but with a general type of
object: the pipe-cleaner is caterpillar-like.
To generate these kinds of expressions, an REG
algorithm would first need a knowledge base with
prototypes listing prototypical values of attributes.
For example, a banana prototype might have a pro-
totypical COLOR of yellow. With prototypes in the
knowledge base, the REG algorithm would need
to calculate similarity of a target referent to other
known items. This would allow a piece of yellow
cloth, for example, to be described as being the
color of a banana.
Implementing such similarity measures in an
REG algorithm will be challenging. One difficulty
is that prototype values may be different depend-
ing on what is known about an item; a prototypical
unripe banana may be green, or a prototypical rot-
ten banana brown. Another difficulty will be in
determining when a referent is similar enough to
a prototype to warrant an analogy. Additional re-
search is needed to explore how these properties
can be reasoned about.
4.3 Further Implications
A knowledge base containing prototypes opens up
the possibility of generating many other kinds of
natural references. In particular, such knowledge
would allow the algorithm to compute which prop-
erties a given kind of referent may be expected
to have, and which properties may be unexpected.
Unexpected properties may therefore stand out as
particularly salient.
For example, a dog missing a leg may be de-
scribed as a ?three-legged dog? because the pro-
totypical dog has four legs. We believe that this
perspective, which hinges on the unexpectedness
of a property, suggests a new approach to at-
tribute selection. Unlike the Incremental Algo-
rithm, the Preference Order that determines the or-
der in which attributes are examined would not be
fixed, but would depend on the nature of the refer-
ent and what is known about it.
Approaching REG in this way follows work in
cognitive science and neurophysiology that sug-
gests that expectations about objects? visual and
spatial characteristics are derived from stored rep-
resentations of object ?prototypes? in the infe-
rior temporal lobe of the brain (Logothetis and
- A spatial representation (depicting size, inter-
relations between component parts)
- A non-spatial, propositional representation
(describing color, texture, orientation, etc.)
- A knowledge base with stored prototypical ob-
ject propositional and spatial representations
Table 4: Requirements for an REG algorithm that
generates natural reference to visual objects.
Sheinberg, 1996; Riesenhuber and Poggio, 2000;
Palmeri and Gauthier, 2004). Most formal theo-
ries of object perception posit some sort of cate-
gory activation system (Kosslyn, 1994), a system
that matches input properties of objects to those
of stored prototypes, which then helps guide ex-
pectations about objects in a top-down fashion.3
This appears to be a neurological correlate of the
knowledge base we propose to underlie analogies.
Such a system contains information about pro-
totypical objects? component parts and where they
are placed relative to one another, as well as rele-
vant values for material, color, etc. This suggests
that the spatial and non-spatial feature-based rep-
resentations proposed for visible objects could be
used to represent prototype objects as well. In-
deed, how we view and refer to objects appears to
be influenced by the interaction of these structures:
Expectations about an object?s spatial properties
guide our attention towards expected object parts
and non-spatial, feature-based properties through-
out the scene (Kosslyn, 1994; Itti and Koch, 2001).
This affects the kinds of things we are most likely
to generate language about (Itti and Arbib, 2005).
We can now outline some general requirements
for an algorithm capable of generating naturalis-
tic reference to objects in a visual scene: Input to
such an algorithm should include a feature-based
representation, which we will call a propositional
representation, with values for color, texture, etc.,
and a spatial representation, with symbolic infor-
mation about objects? size and the spatial relation-
ships between components. A system that gener-
ates naturalistic reference must also use a knowl-
edge base storing information about object proto-
types, which may be represented in terms of their
own propositional/spatial representations.
3Note that this is not the only proposed matching structure
in the brain ? an exemplar activation system matches input to
stored exemplars.
5 Conclusions and Future Work
We have explored the interaction between view-
ing objects in a three-dimensional, spatial domain
and referring expression generation. This has led
us to propose structures that may be used to con-
nect vision in a spatial modality to naturalistic ref-
erence. The proposed structures include a spatial
representation, a propositional representation, and
a knowledge base with representations for object
prototypes. Using structures that define the propo-
sitional and spatial content of objects fits well with
work in psycholinguistics, cognitive science and
neurophysiology, and may provide the basis to
generate a variety of natural-sounding references
from a system that recognizes objects.
It is important to note that any naturalistic ex-
perimental design limits the kinds of conclusions
that can be drawn about reference. A study that
elicits reference to objects in a visual scene pro-
vides insight into reference to objects in a visual
scene; these conclusions cannot easily be extended
to reference to other kinds of phenomena, such as
reference to people in a novel. We therefore make
no claims about reference as a whole in this paper;
generalizations from this research can provide hy-
potheses for further testing in different modalities
and with different sorts of referents.
Our data leave open many areas for further
study, and we hope to address these in future work.
Experiments designed specifically to elicit relative
size modifiers, reference to object components,
and reference to objects that are like other things
would help further detail the form our proposed
structures take.
What is clear from our data is that both a spa-
tial understanding and a non-spatial feature-based
understanding appear to play a role in reference
to objects in a visual scene, and further, refer-
ence in such a setting is bolstered by a knowl-
edge base with stored prototypical object repre-
sentations. Utilizing structures representative of
these phenomena, we may be able to extend ob-
ject recognition research into object reference re-
search, generating natural-sounding reference in
everyday settings.
Acknowledgements
Thanks to Advaith Siddarthan for thought-
provoking discussions and to the anonymous re-
viewers for useful suggestions.
References
Carlos Areces, Alexander Koller, and Kristina Strieg-
nitz. 2008. Referring expressions as formulas of
description logic. Proceedings of the Fifth Inter-
national Natural Language Generation Conference,
pages 42?29.
Robbert-Jan Beun and Anita H. M. Cremers. 1998.
Object reference in a shared domain of conversation.
Pragmatics and Cognition, 6:121?52.
Erik Blaser, Zenon W. Pylyshyn, and Alex O. Hol-
combe. 2000. Tracking an object through feature
space. Nature, 408:196?199.
Susan E. Brennan and Herbert H. Clark. 1996. Con-
ceptual pacts and lexical choice in conversation.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 22:1482?93.
Alphonse Chapanis, Robert N. Parrish, Robert B.
Ochsman, and Gerald D. Weeks. 1977. Studies
in interactive communication: II. the effects of four
communication modes on the linguistic performance
of teams during cooperative problem solving. Hu-
man Factors, 19:101?125.
Herbert H. Clark and Adrian Bangerter. 2004. Chang-
ing ideas about reference. In Ira A. Noveck and Dan
Sperber, editors, Experimental pragmatics, pages
25?49. Palgrave Macmillan, Basingstoke, England.
Herbert H. Clark and Meredyth A. Krych. 2004.
Speaking while monitoring addressees for under-
standing. Journal of Memory and Language, 50:62?
81.
Herbert H. Clark and Deanna Wilkes-Gibbs. 1986. Re-
ferring as a collaborative process. Cognition, 22:1?
39.
Herbert H. Clark, Robert Schreuder, and Samuel But-
trick. 1983. Common ground and the understand-
ing of demonstrative reference. Journal of Verbal
Learning and Verbal Behavior, 22:1?39.
Philip R. Cohen. 1984. The pragmatics of referring
and the modality of communication. Computational
Linguistics, 10(2):97?146.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
18:233?263.
J. H. Flavell, P. T. Botkin, D. L. Fry Jr., J. W. Wright,
and P. E. Jarvice. 1968. The Development of Role-
Taking and Communication Skills in Children. John
Wiley, New York.
William Ford and David Olson. 1975. The elaboration
of the noun phrase in children?s description of ob-
jects. The Journal of Experimental Child Psychol-
ogy, 19:371?382.
Kotaro Funakoshi, Satoru Watanabe, Naoko Kuriyama,
and Takenobu Tokunaga. 2004. Generating refer-
ring expressions using perceptual groups. In Pro-
ceedings of the 3rd International Conference on Nat-
ural Language Generation, pages 51?60.
Albert Gatt. 2006. Structuring knowledge for refer-
ence generation: A clustering algorithm. Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL-06), pages 321?328.
Paul H. Grice. 1975. Logic and conversation. Syntax
and Semantics, 3:41?58.
Peter A. Heeman and Graeme Hirst. 1995. Collabo-
rating on referring expressions. Computational Lin-
guistics, 21.
Laurent Itti and Michael A. Arbib. 2005. Attention and
the minimal subscene. In Michael A. Arbib, editor,
Action to Language via the Mirror Neuron System.
Cambridge University Press.
Laurent Itti and Christof Koch. 2001. Computational
modelling of visual attention. Nature Reviews Neu-
roscience.
J. Kelleher, F. Costello, and J. van Genabith. 2005.
Dynamically structuring, updating and interrelating
representations of visual and linguistic discourse
context. Artificial Intelligence, 167:62?102.
Stephen M. Kosslyn. 1994. Image and Brain: The
Resolution of the Imagery Debate. MIT Press, Cam-
bridge, MA.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Robert M. Krauss and Sam Glucksberg. 1969. The
development of communication: Competence as a
function of age. Child Development, 40:255?266.
Robert M. Krauss and Sidney Weinheimer. 1967. Ef-
fect of referent similarity and communication mode
on verbal encoding. Journal of Verbal Learning and
Verbal Behavior, 6:359?363.
Nikos K. Logothetis and David L. Sheinberg. 1996.
Visual object recognition. Annual Review Neuro-
science, 19:577?621.
Dominic Mazzoni. 2010. Audacity.
Margaret Mitchell. 2008. Towards the generation
of natural reference. Master?s thesis, University of
Washington.
Thomas J. Palmeri and Isabel Gauthier. 2004. Vi-
sual object understanding. Nature Reviews Neuro-
science, 5:291?303.
Maximilian Riesenhuber and Tomaso Poggio. 2000.
Models of object recognition. Nature Neuroscience
Supplement, 3:1199?1204.
Eleanor Rosch. 1975. Cognitive representation of
semantic categories. Journal of Experimental Psy-
chology, 104:192?233.
Harvey Sacks and Emanuel A. Schegloff. 1979. Two
preferences in the organization of reference to per-
sons in conversation and their interaction. In George
Psathas, editor, Everyday Language: Studies in Eth-
nomethodology, pages 15?21. Irvington Publishers,
New York.
Stegan Treue and Julio C. Martinez Trujillo. 1999.
Feature-based attention influences motion process-
ing gain in macaque visual cortex. Nature, 399:575?
579.
Kees van Deemter, Ielka van der Sluis, and Albert Gatt.
2006. Building a semantically transparent corpus
for the generation of referring expressions. In Pro-
ceedings of the 4th International Conference on Nat-
ural Language Generation, Sydney, Australia. ACL.
Jette Viethen and Robert Dale. 2008. The use of spatial
descriptions in referring expressions. In Proceed-
ings of the 5th International Conference on Natural
Language Generation, INLG-08, Salt Fork, Ohio.
ACL.
Charting the Potential of Description Logic
for the Generation of Referring Expressions
Yuan Ren and Kees van Deemter and Jeff Z. Pan
Department of Computing Science
University of Aberdeen
Aberdeen, UK
Abstract
The generation of referring expressions
(GRE), an important subtask of Natural
Language Generation (NLG) is to gener-
ate phrases that uniquely identify domain
entities. Until recently, many GRE algo-
rithms were developed using only simple
formalisms, which were taylor made for
the task. Following the fast development
of ontology-based systems, reinterpreta-
tions of GRE in terms of description logic
(DL) have recently started to be studied.
However, the expressive power of these
DL-based algorithms is still limited, not
exceeding that of older GRE approaches.
In this paper, we propose a DL-based ap-
proach to GRE that exploits the full power
of OWL2. Unlike existing approaches, the
potential of reasoning in GRE is explored.
1 GRE and KR: the story so far
Generation of Referring Expressions (GRE) is the
subtask of Natural Language Generation (NLG)
that focuses on identifying objects in natural lan-
guage. For example, Fig.1 depicts the relations
between several women, dogs and cats. In such
a scenario, a GRE algorithm might identify d1 as
?the dog that loves a cat?, singling out d1 from
the five other objects in the domain. Reference
has long been a key issue in theoretical linguis-
tics and psycholinguistics, and GRE is a crucial
component of almost every practical NLG sys-
tem. In the years following seminal publications
such as (Dale and Reiter, 1995), GRE has be-
come one of the most intensively studied areas of
NLG, with links to many other areas of Cogni-
tive Science. After plan-based contributions (e.g.,
(Appelt, 1985)), recent work increasingly stresses
the human-likeness of the expressions generated
in simple situations, culminating in two evalua-
tion campaigns in which dozens of GRE algo-
rithms were compared to human-generated ex-
pressions (Belz and Gatt, 2008; Gatt et al, 2009).
Figure 1: An example in which edges from women
to dogs denote feed relations, from dogs to cats
denote love relations.
Traditional GRE algorithms are usually based
on very elementary, custom-made, forms of
Knowledge Representation (KR), which allow
little else than atomic facts (with negation of
atomic facts left implicit), often using a simple
?Attribute : V alue? format, e.g ?Type : Dog?.
This is justifiable as long as the properties ex-
pressed by these algorithms are simple one-place
predicates (e.g., being a dog), but when logically
more complex descriptions are involved, the po-
tential advantages of ?serious? KR become over-
whelming. (This point will become clearer in later
sections.) This realisation is now motivating a
modest new line of research which stresses logi-
cal and computational issues, asking what proper-
ties a KR framework needs to make it suitable to
generate all the referring expressions that people
can produce (and to generate them in reasonable
time). In this new line of work, which is proceed-
ing in tandem with the more empirically oriented
work mentioned above, issues of human-likeness
are temporarily put on the backburner. These and
other empirical issues will be brought to bear once
it is better understood what types of KR system are
best suitable for GRE, and what is the best way to
pursue GRE in them.
A few proposals have started to combine GRE
with KR. Following on from work based on la-
belled directed graphs (cf. (Krahmer et al, 2003))
? a well-understood mathematical formalism that
offers no reasoning support ? (Croitoru and van
Deemter, 2007) analysed GRE as a projection
problem in Conceptual Graphs. More recently,
(Areces et al, 2008) analysed GRE as a problem in
Description Logic (DL), a formalism which, like
Conceptual Graphs, is specifically designed for
representing and reasoning with potentially com-
plex information. The idea is to produce a for-
mula such as Dog u ?love.Cat (the set of dogs
intersected with the set of objects that love at least
one cat); this is, of course, a successful reference
if there exists exactly one dog who loves at least
one cat. This approach forms the starting point for
the present paper, which aims to show that when a
principled, logic based approach is chosen, it be-
comes possible to refer to objects which no exist-
ing approach to GRE (including that of Areces et
al.) has been able to refer to. To do this, we de-
viate substantially from these earlier approaches.
For example, while Areces et al use one finite in-
terpretation for model checking, we consider arbi-
trary (possibly infinite) interpretations, hence rea-
soning support becomes necessary.
We shall follow many researchers in focussing
on the semantic core of the GRE problem: we
shall generate descriptions of semantic content,
leaving the decision of what words to use for ex-
pressing this content (e.g., ?the ancient dog?, or
?the dog which is old?) to later stages in the NLG
pipeline. Furthermore, we assume that all domain
objects are equally salient (Krahmer and Theune,
2002). As explained above, we do not consider
here the important matter of the naturalness or ef-
ficacy of the descriptions generated. We shall be
content producing uniquely referring expressions
whenever such expressions are possible, leaving
the choice of the optimal referring expression in
each given situation for later.
In what follows, we start by explaining how DL
has been applied in GRE before (Sec. 2) , point-
ing out the limitations of existing work. In Sec.3
we discuss which kinds of additional expressivity
are required and how they can be achieved through
modern DL. In Sec.4 we present a generic algo-
rithm to compute these expressive REs. Sec.5
concludes the paper by comparing its aims and
achievements with current practise in GRE.
2 DL for GRE
2.1 Description Logics
Description Logic (DLs) come in different
flavours, based on decidable fragments of first-
order logic. A DL-based KB represents the
domain with descriptions of concepts, relations,
and their instances. DLs underpin the Web On-
tology Language (OWL), whose latest version,
OWL2 (Motik et al, 2008), is based on DL
SROIQ (Horrocks et al, 2006).
An SROIQ ontology ? usually consists of a
TBox T and an ABox A. T contains a set of con-
cept inclusion axioms of the formC v D, relation
inclusion axioms such as R v S (the relation R is
contained in the relation S), R1 ? . . . ? Rn v S,
and possibly more complex information, such as
the fact that a particular relation is functional, or
symmetric; A contains axioms about individuals,
e.g. a : C (a is an instance of C), (a, b) : R (a has
an R relation with b).
Given a set of atomic concepts, the entire set
of concepts expressible by SROIQ is defined re-
cursively. First, all atomic concepts are concepts.
Furthermore, if C and D are concepts, then so are
> | ? | ?C | C uD | C unionsqD | ?R.C | ?R.C | ?
nR.C | ? nR.C | ?R.Self | {a1, . . . , an},
where > is the top concept, ? the bottom con-
cept, n a non-negative integer number, ?R.Self
the self-restriction ((i.e., the set of those x such
that (x, x) : R holds)), ai individual names and
R a relation which can either be an atomic rela-
tion or the inverse of another relation (R?). We
call a set of individual names {a1, . . . , an} a nom-
inal, and use CN , RN and IN to denote the set
of atomic concept names, relation names and indi-
vidual names, respectively.
An interpretation I is a pair ??I , I? where ?I
is a non-empty set and I is a function that maps
atomic concept A to AI ? ?I , atomic role r to
rI ? ?I ? ?I and individual a to aI ? ?I .
The interpretation of complex concepts and ax-
ioms can be defined inductively based on their se-
mantics, e.g. (C uD)I = CI ?DI , etc.
I is a model of ?, written I |= ?, iff all the ax-
ioms in ? are satisfied in I. It should be noted
that one ? can have multiple models. For ex-
ample when T = ?,A = {a : A unionsq B}, there
can be a model I1 s.t. ?I1 = {a}, aI1 =
a,AI1 = {a}, BI1 = ?, and another model I2
s.t. ?I2 = {a}, aI2 = a,BI2 = {a}, AI2 = ?.
In other words, the world is open. For details, see
(Horrocks et al, 2006).
The possibly multiple models indicate that an
ontology is describing an open world. In GRE,
researchers usually impose a closed world. From
the DL point of view, people can (partially) close
the ontology with a DBox D (Seylan et al, 2009),
which is syntactically similar to the ABox, except
that D contains only atomic formulas. Further-
more, every concept or relation appearing in D
is closed. Its extension is exactly defined by the
contents of D, i.e. if D 6|= a : A then a : ?A,
thus is the same in all the models. The concepts
and relations not appearing in D can still remain
open. DL reasoning can be exploited to infer
implicit information from ontologies. For exam-
ple, given T = {Dog v ?feed?.Woman} (ev-
ery dog is fed by some woman) and A = {d1 :
Dog,w1 : Woman}, we know that there must be
some Woman who feeds d1. When the domain
is closed as D = A we can further infer that this
Woman is w1 although there is no explicit rela-
tion between w1 and d1. Note that the domain ?I
in an interpretation ofD is not fixed, but it includes
all the DBox individuals.
However, closing ontologies by means of the
DBox can restrict the usage of implicit knowledge
(from T ). More precisely, the interpretations of
the concepts and relations appearing inD are fixed
therefore no implicit knowledge can be inferred.
To address this issue, we introduce the notion of
NBox to support Negation as Failure (NAF): Un-
der NAF, an ontology is a triple O = (T ,A,N ),
where T is a TBox, A an ABox and N is a subset
of CNorRN . We callN an NBox. NAF requires
that O satisfy the following conditions:
1. Let x ? IN and A ? N uCN . Then
(T ,A) 6|= x : A implies O |= x : ?A.
2. Let x, y ? IN and r ? N u RN .
Then (T ,A) 6|= (x, y) : r implies O |=
(x, y) : ?r.
Like the DBox approach, the NBox N defines
conditions in which ?unknown? should be treated
as ?failure?. But, instead of hard-coding this, it
specifies a vocabulary on which such treatment
should be applied. Different from the DBox ap-
proach, inferences on this NAF vocabulary is still
possible. An example of inferring implicit knowl-
edge with NAF will be shown in later sections.
2.2 Background Assumptions
When applying DL to GRE, people usually im-
pose the following assumptions.
? Individual names are not used in REs. For
example, ?the Woman who feeds d1? would
be invalid, because d1 is a name. Names are
typically outlawed in GRE because, in many
applications, many objects do not have names
that readers/hearers would be familiar with.
? Closed World Assumption (CWA): GRE re-
searchers usually assume a closed world,
without defining what this means. As ex-
plained above, DL allows different interpre-
tations of the CWA. Our solution does not de-
pend on a specific definition of CWA. In what
follows, however, we use NAF to illustrate
our idea. Furthermore, the domain is usually
considered to be finite and consists of only
individuals appearing in A.
? Unique Name Assumption (UNA): Different
names denote different individuals. If, for
example, w1 and w2 may potentially be the
same woman, then we can not distinguish one
from the other.
We follow these assumptions when discussing ex-
isting works and presenting our approach. In ad-
dition, we consider the entire KB, including A,
T and N . It is also worth mentioning that, in
the syntax of SROIQ, negation of relations are
not allowed in concept expressions, e.g. you can-
not compose a concept ??feed.Dog. However,
if feed ? N , then we can interpret (?feed)I =
?I ??I \ feedI . In the rest of the paper, we use
this as syntactic sugar.
2.3 Motivation: DL Reasoning and GRE
Every DL concept can be interpreted as a set. If
the KB allows one to prove that this set is a sin-
gleton then the concept is a referring expression.
It is this idea (Gardent and Striegnitz, 2007) that
(Areces et al, 2008) explored. In doing so, they
say little about the TBox, appearing to consider
only the ABox, which contains only axioms about
instances of atomic concepts and relations. For ex-
ample, the domain in Fig.1 can be described as
KB1: T1 = ?, A1 = {w1 : Woman,
w2 : Woman, d1 : Dog, d2 : Dog,
c1 : Cat, c2 : Cat, (w1, d1) : feed,
(w2, d1) : feed, (w2, d2) : feed,
(d1, c1) : love}
Assuming that this represents a Closed World,
Areces et al propose an algorithm that is able
to generate descriptions by partitioning the do-
main.1 More precisely, the algorithm first finds
out which objects are describable through increas-
ingly large conjunctions of (possibly negated)
atomic concepts, then tries to extend these con-
junctions with complex concepts of the form
(?)?R1.Concept, then with concepts of the form
(?)?R2.(Concept u (?)?R1.Concept), and so
on. At each stage, only those concepts that have
been acceptable through earlier stages are used.
Consider, for instance, KB1 above. Regardless of
what the intended referent is, the algorithm starts
partitioning the domain stage by stage as follows.
Each stage makes use of all previous stages. Dur-
ing stage (3), e.g., the object w2 could only be
identified because d2 was identified in stage (2):
1. Dog = {d1, d2},
?Dog uWoman = {w1, w2},
?Dog u ?Woman = {c1, c2}.
2. Dog u ?love.(?Dog u ?Woman) = {d1},
Dogu??love.(?Dogu?Woman) = {d2}.
3. (?Dog u Woman) u ?feed.(Dog u
??love.(?Dog u ?Woman)) = {w2},
(?Dog u Woman) u ??feed.(Dog u
??love.(?Dog u ?Woman)) = {w1}.
As before, we disregard the important question
of the quality of the descriptions generated, other
than whether they do or do not identify a given
referent uniquely. Other aspects of quality depend
in part on details, such as the question in which
order atomic concepts are combined during phase
(1), and analogously during later phases.
However this approach does not extend the ex-
pressive power of GRE. This is not because of
some specific lapse on the part of the authors: it
seems to have escaped the GRE community as a
whole that relations can enter REs in a variety of
alternative ways.
Furthermore, the above algorithm considers
only the ABox, therefore background information
1Areces et al (Areces et al, 2008) consider several DL
fragments (e.g., ALC and EL). Which referring expressions
are expressible, in their framework, depends on which DL
fragment is chosen. Existential quantification, however, is
the only quantifier that was used, and inverse relations are
not considered.
will not be used. It follows that the domain al-
ways has a fixed single interpretation/model. Con-
sequently the algorithm essentially uses model-
checking, rather than full reasoning. We will
show that when background information is in-
volved, reasoning has to be taken into account.
For example, suppose we extend Fig.1 with back-
ground (i.e., TBox) knowledge saying that one
should always feed any animal loved by an ani-
mal whom one is feeding, while also adding a love
edge (Fig.2) between d2 and c2:
Figure 2: An extended example of Fig.1. Edges
from women to cats denote feed relations.
Dashed edges denote implicit relations.
If we close the domain with NAF, the ontology
can be described as follows:
KB2: T2 = {feed ? love v feed},
A2 = A1 ? {(d2, c2) : love}, N2 =
{Dog,Woman, feed, love}
The TBox axiom enables the inference of implicit
facts: the facts (w1, c2) : feed, (w2, c1) : feed,
and (w2, c2) : feed can be inferred using DL rea-
soning under the above NBox N2. Axioms of this
kind allow a much more natural, insightful and
concise representation of information than would
otherwise be possible.
Continuing to focus on the materialised KB2,
we note another limitation of existing works: if
only existential quantifiers are used then some ob-
jects are unidentifiable (i.e., it is not possible to
distinguish them uniquely). These objects would
become identifiable if other quantifiers and inverse
relations were allowed. For example,
? The cat which is fed by at least 2 women =
Catu ? 2feed?.Woman = {c1},
? The woman feeding only those fed by at
least 2 women = Woman u ?feed. ?
2.feed?.Woman = {w1},
? The woman who feeds all the dogs = {w2}.
It thus raises the question: which quantifiers
would it be natural to use in GRE, and how might
DL realise them?
3 Beyond Existential Descriptions
In this section, we show how more expressive DLs
can make objects referable that were previously
unreferable. This will amount to a substantial re-
formulation which allows the approach based on
DL reasoning to move well beyond other GRE al-
gorithms in its expressive power.
3.1 Expressing Quantifiers in OWL2
Because the proposal in (Areces et al, 2008) uses
only existential quantification, it fails to identify
any individual in Fig.2. Before filling this gap,
we pause to ask what level of expressivity ought
to be achieved. In doing so, we make use of
a conceptual apparatus developed in an area of
formal semantics and mathematical logic known
as the theory of Generalized Quantifiers (GQ),
where quantifiers other than all and some are stud-
ied (Mostowski, 1957). The most general format
for REs that involves a relation R is, informally,
the N1 who R Q N2?s, where N1 and N2
denote sets, R denotes a relation, and Q a gener-
alized quantifier. (Thus for example the women
who feed SOME dogs.) An expression of this
form is a unique identifying expression if it corre-
sponds to exactly one domain element. Using a
set-theoretic notation, this means that the follow-
ing set has a cardinality of 1:
{y ? N1 : Qx ? N2 | Ryx}
where Q is a generalized quantifier. For example,
if Q is the existential quantifier, while N1 denotes
the set of women, N2 the set of dogs, and R the
relation of feeding, then this says that the number
of women who feed SOME dog is one. If Q is the
quantifier at least two, then it says that the num-
ber of women who feed at least two dogs is one.
It will be convenient to write the formula above
in the standard GQ format where quantifiers are
cast as relations between sets of domain objects
A,B. Using the universal quantifier as an exam-
ple, instead of writing ?x ? A | x ? B, we write
?(AB). Thus, the formula above is written
{y ? N1 : Q(N2{z : Ryz)}}.
Instantiating this as before, we get {y ?Woman :
?(Dog{z : Feed yz)}}, or ?women who feed a
dog?, where Q is ?, A = Dog and B = {z :
Feed yz} for some y.
Mathematically characterising the class of all
quantifiers that can be expressed in referring
expressions is a complex research programme
to which we do not intend to contribute here,
partly because this class includes quantifiers that
are computationally problematic; for example, a
quantifiers such as most (in the sense of more than
50%), which is not first-order expressible, as is
well known.
To make transparent which quantifiers are ex-
pressible in the logic that we are using, let us think
of quantifiers in terms of simple quantitative con-
straints on the sizes of the sets A?B, A?B, and
B?A, as is often done in GQ theory, asking what
types of constraints can be expressed in referring
expressions based on SROIQ. The findings are
summarised in Tab.1. OWL2 can express any of
the following types of descriptions, plus disjunc-
tions and conjunctions of anything it can express.
Table 1: Expressing GQ in DL
QAB DL
1 ? nN2{z : Ryz} y :? nR.N2
2 ? nN2?{z : Ryz} y :? n?R.N2
3 ? n?N2{z : Ryz} y :? nR.?N2
4 ? n?N2?{z : Ryz} y :? n?R.?N2
5 ? nN2{z : Ryz} y :? nR.N2
6 ? nN2?{z : Ryz} y :? n?R.N2
7 ? n?N2{z : Ryz} y :? nR.?N2
8 ? n?N2?{z : Ryz} y :? n?R.?N2
When n = 1, for example, type 1 becomes
?R.N2, i.e. the existential quantifier. When n = 0
type 7 becomes ?R.N2, i.e. the quantifier only.
When n = 0 type 6 becomes ??R.?N2, i.e. the
quantifier all. In types 2, 4, 6 and 8, negation of
a relation is used. This is not directly supported
in SROIQ but, as we indicated earlier, given
R ? N , ?R can be used in concepts.
Together, this allows the expression of a de-
scription such as ?women who feed at least one
but at most 7 dogs?, by conjoining type 1 (with
n = 1) with type 5 (with n = 7). Using nega-
tion, it can say ?women who do not feed all dogs
and who feed at least one non-dog? (Woman u
???Feed.?Dog u ?Feed.?Dog). In addition
to Tab.1, SROIQ can even represent reflexive
relation such as ?the dog who loves itself? by
Dogu?love.Self , which was regarded infeasible
in (Gardent and Striegnitz, 2007).
Comparing the quantifiers that become express-
ible through OWL2?s apparatus with classes of
quantifiers studied in the theory of GQ, it is clear
that OWL2 is highly expressive: it does not only
include quantifiers expressible in the binary tree
of numbers, e.g. (van Benthem, 1986) ? which is
generally regarded as highly general ? but much
else besides. Even wider classes of referring ex-
pressions can certainly be conceived, but these are
not likely to have overwhelming practical utility in
today?s NLG applications.
4 Generating SROIQ-enabled REs
In this section, we present an algorithm that com-
putes the descriptions discussed in sect.3. A GRE
algorithm should have the following behaviour: if
an entity is distinguishable from all the others, the
algorithm should find a unique description; oth-
erwise, the algorithm should say there exists no
unique description. In this paper, we follow Are-
ces et al?s strategy of generating REs for all ob-
jects simultaneously, but we apply it to a much
larger search space, because many more constructs
are taken into account.
4.1 GROWL: an algorithm for Generating
Referring expressions using OWL-2.
In this section we show how the ideas of pre-
vious sections can be implemented. To do this,
we sketch an algorithm scheme called GROWL.
GROWL applies a generate-and-test strategy that
composes increasingly complicated descriptions
and uses DL reasoning to test whether a de-
scription denotes a singleton w.r.t. the KB. To
avoid considering unnecessarily complicated de-
scriptions, the algorithm makes use of the (syntac-
tic) depth of a description, defined as follows:
Definition 1 (Depth) Given a description d, its
depth |d| is calculated as follows:
1. |d| = 1 for d := >|?|A|?A, where A is
atomic.
2. |d u d?| = |d unionsq d?| = max(|d|, |d?|) + 1.
3. |?r.d| = |?r.d| = | ? nr.d| = | ? nr.d| =
| = nr.d| = |d|+ 1.
Different descriptions can mean the same of
course, e.g. ??R.A ? ?R.?A. We do not know
which syntactic variant should be used but focus,
for simplicity, on generating their unique negated
normal form (NNF). The NNF of a formula ?
can be obtained by pushing all the ? inward un-
til only before atomic concepts (including > and
?), atomic relations, nominals or self restrictions
(e.g. ?r.Self ). Without loss of generality, in what
follows we assume all the formulas are in their
NNF. To avoid confusion, the NNF of negation
of a formula ? is denoted by ~? instead of ??.
For example ~(A unionsq B) = ?A u ?B if A and B
are atomic. Obviously, ~(~A) = A, ~(~R) = R,
(R?)? = R, and (~R)? =~R?. The use of NNF
substantially reduces the redundancies generated
by the algorithm. For example, we won?t generate
both ??R.A and ?R.?A but only the later.
Given an ontology ?, we initialise GROWL
with the following sets:
1. The relation name set RN is the minimal set
satisfying:
? if R is an atomic relation in ?, then R ?
RN ;
? if R ? RN , then ~R ? RN ;
? if R ? RN , then R? ? RN ;
2. The concept name set CN is the minimal set
satisfying:
? > ? CN ;
? if A is an atomic concept in ?, then A ?
CN ;
? if R ? RN , then ?R.Self ? CN ;
? if A ? CN , then ~A ? CN ;
3. The natural number set N contains
1, 2, . . . , n where n is the number of
individuals in ?.
4. The construct set S contains all the con-
structs supported by a particular language.
For SROIQ, S = {?,u,unionsq,?,?,?,?,=}.
We assume here that nominals are disallowed
(cf. sect.2).
Algorithm GROWL:
Construct? description(?, CN,RN,N, S)
INPUT: ?, CN,RN,N, S
OUTPUT: Description Queue D
1: D := ?
2: for e ? CN do
3: D := Add(D, e)
4: for d = fetch(D) do
5: for each s ? S do
6: if s = u or s = unionsq then
7: for each d? ? D do
8: D := Add(D, d s d?)
9: if s = ? or s = ? then
10: for each r ? RN do
11: D := Add(D, s r.d)
12: if s =? or s =? or s is = then
13: for each r ? RN , each k ? N do
14: D := Add(D, s k r.d)
15: return D
Algorithm ADD:Add(D, e)
INPUT: D, e
OUTPUT: (Extended) Description Queue D
1: for d ? D do
2: if |d| < |e| and d v? e then
3: return D
4: else if |d| = |e| and d v? e and e u ?d is
satisfiable then
5: return D
6: if e is satisfiable in ? then
7: D := D ? {e}
8: return D
GROWL takes an ontology ? as its input and
output a queue D of descriptions by adding in-
creasingly complex concepts e to D, using the
function Add(D, e), which is implemented as the
algorithm ADD. Because of the centrality of ADD
we start by explaining how this function works.
In the simple algorithm we are proposing in this
paper ? which represents only one amongst many
possibilities ? addition is governed by the heuris-
tic that more complex descriptions should have
smaller extensions. To this end, a candidate de-
scription e is compared with each existing descrip-
tion d ? D. Step 2 ensures that if there exists a
simpler description d (|d| < |e|) whose extension
is no larger than e (d v? e), then e is not added
into D (because the role of e can be taken by the
simpler description d). Similarly, step 4 ensures
that if there exists d with same depth (|d| = |e|)
but smaller extension (d v? e and e u ?d is satis-
fiable), then e should not be added into D. The
subsumption checking in Step 2 and 4, and the
instance retrieval in Step 6, must be realised by
DL reasoning, in which TBox, ABox and NBox
must all be taken into account. ADD guaran-
tees that when the complexity of descriptions in-
creases, their extensions are getting smaller.
We now turn to the main algorithm, GROWL. In
Step 1 of this algorithm,D is initialised to ?. Steps
2 to 3 add all satisfiable elements of CN to D.
From Steps 4 to 14, we recursively ?process? ele-
ments ofD one by one, by which we mean that the
constructors in S are employed to combine these
elements with other elements of D (e.g., an ele-
ment is intersected with all other elements, and so
on). We use fetch(D) to retrieve the first unpro-
cessed element of D. New elements are added to
the end of D. Thus D is a first-come-first-served
queue (note that processed elements are not re-
moved from D).
To see in more detail how elements of D are
processed, consider Steps 5-14 once again. For
each element d of D, Step 5 uses a construct s to
extend it:
1. If s is u or unionsq, in Step 7 and 8, we extend d
with each element ofD and add new descrip-
tions to D.
2. If s is ? or ?, in Step 10 and 11, we extend
d with all relations of RN and add new de-
scriptions to D. In Areces et el.?s work, ? is
also available when using ? and ? together,
however due to their algorithm they can never
generates descriptions like ?r.A.
3. If s is ?,? or =, in Step 13 and 14, we ex-
tend d with all relations in RN and all num-
bers in N , and add new descriptions to D.
Because the = construct can be equivalently
substituted by the combination of?,? and u
constructs (= kr.d is semantically equivalent
to ? kr.du ? kr.d), it is a modelling choice
to use either ?,?, or only =, or all of them.
In this algorithm we use them all.
Because we compute only the NNF and we
disallow the use of individual identifiers, nega-
tion ? appears only in front of atomic concept
names. For this reason, processing does not con-
sider s = ?. Note that GROWL leaves some
important issues open. In particular, the or-
der in which constructs, relations, integers and
conjuncts/disjuncts are chosen is left unspecified.
Note that D,RN,N, S are all assumed to be fi-
nite, hence Steps 5 to 14 terminate for a given
d ? D. Because Steps 5 to 14 generate descrip-
tions whose depth increases with one constructor
at a time, there are finitely many d ? D such that
|d| = n (for a given n).
GROWL extends the algorithm presented by
Areces et al The example in Fig.2 shows that
many referring expressions generated by our algo-
rithm cannot be generated by our predecessors; in
fact, some objects that are not referable for them
are referable by GROWL. For example, if we ap-
ply the algorithm to the KB in Fig.2, a possible
solution is as follows:
1. {w1} = Womanu??feed.Cat, the woman
that does not feed all cats.
2. {w2} =? 0?feed.Cat , the woman that
feeds all cats.
3. {d1} = Dogu ? 0?feed?.Woman, the
dog that is fed by all women.
4. {d2} = Dog u ??feed?.Woman, the dog
that is not fed by all women.
5. {c1} = Catu ? 0?feed?.Woman, the cat
that is fed by all women.
6. {c2} = Cat u ??feed?.Woman, the cat
that is not fed by all women.
It is worth reiterating here that our algorithm fo-
cusses on finding uniquely referring expressions,
leaving aside which of all the possible ways in
which an object can be referred to is ?best?. For
this reason, empirical validation of our algorithm
? a very sizable enterprise in itself, which should
probably be based on descriptions elicited by hu-
man speakers ? is not yet in order.
4.2 Discussion
Let us revisit the basic assumptions of Sec.2.2, to
see what can be achieved if they are abandoned.
1. In natural language, people do using names,
e.g. ?the husband of Marie Curie?. To allow
REs of this kind, we can extend our Algo-
rithm A-1 by including singleton classes such
as {Maria Curie} in CN .
2. Traditional GRE approaches have always as-
sumed a single model with complete knowl-
edge. Without this assumption, our approach
can still find interesting REs. For example,
if a man?s nationality is unknown, but he is
known to be the Chinese or Japanese, we can
refer to him/her as Chinese unionsq Japanese.
However, models should be finite to guaran-
tee that N is finite.
3. Individuals with multiple names. DL im-
poses the UNA by explicitly asserting the
inequality of each two individuals. With-
out UNA, reasoning can still infer some re-
sults, e.g. {Woman uMan v ?, David :
Man,May : Woman} |= David 6= May.
Thus we can refer to David as ?the man? if
the domain is closed.
5 Widening the remit of GRE
This paper has shown some of the benefits that
arise when the power of KR is brought to bear
on an important problem in NLG, namely the gen-
eration of referring expressions (GRE). We have
done this by using DL as a representation and
reasoning formalism, extending previous work in
GRE in two ways. First, we have extended GRE
by allowing the generation of REs that involve
quantifiers other than ?. By relating our algo-
rithm to the theory of Generalised Quantifiers, we
were able to formally characterise the set of quan-
tifiers supported by our algorithm, making exact
how much expressive power we have gained. Sec-
ondly, we have demonstrated the benefits of im-
plicit knowledge through inferences that exploit
TBox-information, thereby allowing facts to be
represented more efficiently and elegantly, and al-
lowing GRE to tap into kinds of generic (as op-
posed to atomic) knowledge that it had so far left
aside, except for hints in (Gardent and Striegnitz,
2007) and in (Croitoru and van Deemter, 2007).
Thirdly, we have allowed GRE to utilise incom-
plete knowledge, as when we refer to someone as
?the man of Japanese or Chinese nationality?.
Current work on reference is overwhelmingly
characterised by an emphasis on empirical accu-
racy, often focussing on very simple referring ex-
pressions, which are constituted by conjunctions
of 1-place relations (as in ?the grey poodle?), and
asking which of these conjunctions are most likely
to be used by human speakers (or which of these
would be most useful to a human hearer). The
present work stresses different concerns: we have
focussed on questions of expressive power, fo-
cussing on relatively complex descriptions, asking
what referring expressions are possible when re-
lations between domain objects are used. We be-
lieve that, at the present stage of work in GRE, it
is of crucial importance to gain insight into ques-
tions of this kind, since this will tell us what types
of reference are possible in principle. Once such
insight, we hope to explore how the newly gained
expressive power can be put to practical use.
References
Douglas Appelt. 1985. Planning English Sentences.
Cambridge University Press, Cambridge, UK.
Carlos Areces, Alexander Koller, and Kristina Strieg-
nitz. 2008. Referring expressions as formulas of
description logic. In Proceedings of the 5th INLG,
Salt Fork, Ohio.
Anja Belz and Albert Gatt. 2008. Intrinsic vs. extrinsic
evaluation measures for referring expression gener-
ation. In HLT ?08: Proceedings of the 46th Annual
Meeting of the Association for Computational Lin-
guistics on Human Language Technologies, pages
197?200.
Madalina Croitoru and Kees van Deemter. 2007. A
conceptual graph approach to the generation of re-
ferring expressions. In Proceedings of the 20th IJ-
CAI.
Robert Dale and Ehud Reiter. 1995. Computational in-
terpretations of the gricean maxims in the generation
of referring expressions. CoRR, cmp-lg/9504020.
Claire Gardent and Kristina Striegnitz. 2007. Gen-
erating bridging definite descriptions. Computing
Meaning, 3:369?396.
Albert Gatt, Anja Belz, and Eric Kow. 2009. The
TUNA-REG Challenge 2009: Overview and eval-
uation results. In Proceedings of the 12th ENLG
(ENLG 2009), pages 174?182, Athens, Greece,
March. Association for Computational Linguistics.
Ian Horrocks, Oliver Kutz, and Ulrike Sattler. 2006.
The Even More Irresistible SROIQ. In KR 2006.
Emiel Krahmer and Mariet Theune. 2002. Efficient
context-sensitive generation of descriptions in con-
text. Information Sharing: Givenness and Newness
in Language, pages 223?264.
Emiel Krahmer, Sebastiaan van Erk, and Andr Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
A Mostowski. 1957. On a generalization of quanti-
fiers. Fund. Math., 44:235?273.
Boris Motik, Bernardo Cuenca Grau, Ian Horrocks,
Zhe Wu, Achille Fokoue, and Carsten Lutz. 2008.
Owl 2 web ontology language: Profiles. W3c work-
ing draft, W3C, October.
Inanc? Seylan, Enrico Franconi, and Jos de Bruijn.
2009. Effective query rewriting with ontologies over
dboxes. In IJCAI 2009.
Johan van Benthem. 1986. Essays in Logical Seman-
tics. Reidel.
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 120?124,
Utica, May 2012. c?2012 Association for Computational Linguistics
Blogging birds: Generating narratives about reintroduced species to
promote public engagement
Advaith Siddharthan, Matthew Green, Kees van Deemter, Chris Mellish & Rene? van der Wal
{advaith, mjgreen, k.vdeemter, c.mellish, r.vanderwal}@abdn.ac.uk
University of Aberdeen
Abstract
This paper proposes the use of NLG to en-
hance public engagement during the course of
species reintroductions. We examine whether
ecological insights can be effectively commu-
nicated through blogs about satellite-tagged
individuals, and whether such blogs can help
create a positive perception of the species in
readers? minds, a requirement for successful
reintroduction. We then discuss the impli-
cations for NLG systems that generate blogs
from satellite-tag data.
1 Introduction
Conservation of wildlife is an objective to which
considerable effort is devoted by governments and
NGOs across the world. A variety of web-based
approaches can help make the natural world more
accessible to the public, which in turn may trans-
late into greater public support for nature conserva-
tion initiatives. The present paper explores the role
of Natural Language Generation (NLG) in bringing
up-to-date information about wild animals in their
natural environment to nature enthusiasts.
We focus on the reintroduction of the red kite
to the UK. This member of the raptor family was
once widespread in the UK, but prolonged and in-
tense persecution led to its near extinction. Since
1989, efforts have been ongoing to reintroduce this
species in various locations across the country. We
are working together with one of the largest na-
ture conservation charities in Europe to use NLG
for public engagement around a small number of
satellite-tagged reintroduced red kites.
The public engagement activities surrounding this
reintroduction initiative have two subtly different
objectives: (i) to communicate ecological insights to
increase awareness about the species, and (ii) to cre-
ate a positive image of the reintroduced species to
harness public support for the reintroduction. Cur-
rently, data from these satellite tags are being used
by the charity to manually create blogs such as:
...Ruby (Carrbridge) had an interesting flight
down to Loch Duntelchaig via Dochfour on
the 6th March before flying back to the
Drumsmittal area, spending the 10th March in
the Loch Ussie area (possibly also attracted by
the feeding potential there!) and then back to
Drumsmittal for the 13th...
Such blogs are used by schools which have
adopted individual kites, and pupils can read these
texts alongside a map plotting the GPS locations of
?their? kite. As can already be seen from the above,
there is currently little ecological information about
the species in these blogs. Because of the perceived
importance of education to the success of reintro-
ductions, there is a clear desire to include more eco-
logical insights. Yet, time and resource limitations
have prevented the charity from doing so; they per-
ceive the writing of such blogs already as very time
consuming, and indeed, rather mundane.
In this paper, we explore the use of blogs based on
satellite tag data for communicating ecological in-
sights and creating a positive image of a species. We
consider both aspects, deemed essential for a suc-
cessful species reintroduction, and focus on how the
blogs can be made more informative than those cur-
rently being written by the charity.
2 Related work
Data-to-text systems (e.g., Goldberg et al (1994);
Theune et al (2001); Portet et al (2009)) have typ-
120
(a) (b)
Figure 1: Plot of (a) distance from nest as a function of time, and (b) clusters of visited locations.
ically been used to generate summaries of technical
data for professionals, such as engineers, nurses and
oil rig workers. There is some work on the use of
data-to-text for lay audiences; e.g., generating nar-
ratives from sensor data for automotive (Reddington
et al, 2011) and environmental (Molina et al, 2011)
applications, generating personal narratives to help
children with complex communication needs (Black
et al, 2010), and summarising neonatal intensive
care data for parents (Mahamood et al, 2008).
Our application differs from the above-mentioned
data-to-text applications, in that we aim to gener-
ate inspiring as well as informative texts. It bears
some resemblance to NLG systems that offer ?info-
tainment?, such as Dial Your Disc (Van Deemter and
Odijk, 1997) and Ilex (O?Donnell et al, 2001). In
fact, Dial Your Disc, which generates spoken mono-
logues about classical music, focused emphatically
on generating engaging texts, and achieved linguis-
tic variation through the use of recursive, syntacti-
cally structured templates (see also, Theune et al
(2001)). We intend to extend a data-to-text system
in similar ways, using ecological insights to make
narratives engaging for non-experts.
3 Overall Goals
Our overall aim is to bring satellite tagged animals
(in this case study, red kites) ?to life? by construct-
ing narratives around their patterns of movement.
We require individual locations of a bird to be ex-
plained in the context of its wider spatial use, and
the ecological interpretations thereof. This paper has
the following goals:
1. To illustrate how satellite tag data can be analysed to
identify behavioural patterns for use in generating
blogs (content selection);
2. To test whether blogs written by an ecologist based
on such data analysis can be used to educate as well
as create a positive perception of the species;
3. To investigate the challenges for NLG in automat-
ing the generation of such blogs.
4 Data analysis for identifying behaviours
From an NLG perspective, our interest in automat-
ing the generation of blogs from satellite tag data
is in making these narratives more interesting, by
using the data to illustrate key aspects of red kite
behaviour. To illustrate how we can relate the data
to behaviours, we provide two graphical views of
GPS fixes from a tagged red kite. Fig. 1(a) shows
how far a focal kite is located from its nest over the
course of a year. We propose to use such data to con-
struct narratives around ecological insights regard-
ing the exploratory behaviours of red kites during
their first year after fledgling. Fig. 1(b) shows the
same GPS data, but now spatially, thereby plotting
latitude against longitude of all fixes without regard
to time. This portrayal highlights the kite?s favoured
locations (indicated in different colours based on a
MATLAB cluster analysis which automatically esti-
mates the parameters of a Gaussian mixture model,
121
even when clusters overlap substantially), as well as
its broad range.
These plots illustrate two key aspects of kite be-
haviour: exploration and site-fidelity (the presence
of favoured locations that the kite tends to return to).
In addition, we are interested in communicating var-
ious feeding behaviours as well as that, unlike many
other birds of prey, red kites are social birds, often
found in groups. Feeding and social behaviours can-
not be directly identified from the data. However,
they can often be inferred; for instance, a red kite
spending its time by the side of a main road is likely
to be looking to scavenge on road kill.
5 Study on engaging readers using blogs
We now report a study that explores whether such
ecological insights can be effectively communicated
through blogs constructed around an individual of
the species, and whether such blogs can help create a
positive perception of the species in a reader?s mind.
This study was based on a text manually con-
structed by an ecologist based on five weeks of
data such as in Fig 1 from a red kite named ?Red
Baroness?. For this study, the data was mapped onto
a simplified world with seven features: a lake, a
shoreline, fields, a road, a moor, a forest and a river.
A sample of the text is shown in Figure 2 for illus-
tration.
Week 2: How different the pattern of movements
of Red Baroness was this week! On Monday, she
shot off past Bleak Moor, on her longest journey
so far north-east of the lake. She appeared not to
find much of interest there, and on the next day
she was observed combing the edges of Green
Park, possibly in search of a group of birds rest-
ing in the top half of the trees. The bird was
clearly restless however, as on Thursday she was
observed following River Rapid, downstream for
further than she had been last month, finally stop-
ping when she reached Blue Lake again.
Figure 2: Sample material showing week 2 from the five
week blog
5.1 Experimental Design
80 participants were shown the material: a five week
blog on the movements of the focal red kite, named
Red Baroness, alongside a picture of a red kite and a
schematic map marking the seven features of inter-
est. Participants were students at the University of
Aberdeen. The experiment was conducted in a lab in
a supervised setting. After reading and returning the
blog, each participant was asked to (a) summarise
the blog they had just read in 5 lines, (b) state what
they found most interesting, and (c) state what they
did not like about the blog. These textual responses
were manually coded for whether the four behaviour
types (site fidelity, exploration, feeding and social)
were identified by each participant.
To gauge the participants? perceptions of the kite,
we used two methods. First, we asked the participant
to answer four questions that tested various aspects
of their willingness to engage with red kite conser-
vation:
Q1 Would you be willing to contribute money to a char-
ity that tries to protect kites?
Q2 The use of rat poison also leads to the death of kites
that feed on the bodies of these rats. Would you be
willing to sign a campaign against rat poison?
Q3 Should governments allocate more money than they
do currently to protect kites from extinction?
Q4 Write your email if you wish to be sent more blogs.
Further to this, participants were asked to assess
the red kite?s personality. We follow (Gosling et al,
2003), who use the 44 question Big Five Inventory
(BFI) (John et al, 1991; John et al, 2008) to as-
sess the personality of dogs. We are interested in
whether readers did assign personalities to the red
kite in the blog and, if so, what these personality
profiles looked like.
5.2 Results
We now analyse the extent to which our participants
were informed about red kite ecology as well as how
willing they were to engage with conservation ef-
forts and how they perceived the species.
5.2.1 Informativeness
More than half the participants identified feed-
ing behaviour (61%) and social (54%) behaviour.
The other two ecological concepts were not men-
tioned explicitly in the blog that participants read,
but needed to be inferred. Around a quarter of par-
ticipants managed to infer the notion of site fidelity
122
(23%), the most difficult of the concepts, and 41%
inferred exploratory behaviour.
5.2.2 Engagement
39% provided their email address to receive fur-
ther blogs (the only real commitment), and an equal
number expressed willingness to contribute money
for red kite conservation efforts. 85% expressed
willingness to sign a campaign against rat poisoning,
and 61% wanted increased government spending for
red kite conservation.
We detected a correlation between re-
call/inference of behaviours and willingness to
engage (plotting total number of behaviours re-
called/inferred by each participant against the total
number of engagement questions answered affirma-
tively, rpearson = 0.31; p < 0.005; n = 80). One
interpretation of this result is that greater insights
into the life of this bird has positively influenced
the reader?s perceptions of it. Further qualitative
studies are needed to substantiate this, but we view
this result as evidence in favour of incorporating
ecological insights into the blogs.
5.2.3 Perception
Table 1 shows the big five personality traits as-
signed to Red Baroness by participants. The BFI is
constructed such that being non-committal about the
44 trait questions would result in scores of 3. The
ability of readers to assign human personality traits
(significantly different from 3.0) to the red kite indi-
cates a willingness to anthromorphise the bird. The
last column shows the average personality of 21 year
old humans (from Srivastava et al (2003)), which is
the same age group as our participants. The values
for extroversion, agreeableness and conscientious-
ness are very similar, and the kite has lower neu-
roticism and openness.
6 Implications for NLG
The above study indicates that it is possible to use
narratives based on satellite tag data to communi-
cate ecological insights as well as create a positive
perception of the species in the readers? minds. To
generate texts that are fluent and engaging enough
that readers will be both informed and entertained
by them poses challenges that are sharply differ-
ent from the ones facing most data-to-text systems,
Trait Red Kite Conf. Int. 21 yo
Extroversion 3.28 3.07?3.48 3.25
Agreeableness 3.64 3.47?3.80 3.64
Conscientiousness 3.48 3.26?3.69 3.45
Neuroticism 2.60 2.41?2.80 3.32
Openness 3.29 3.11?3.47 3.92
Table 1: Big five personality traits of Red Baroness with
99.9% confidence intervals, compared to average 21 year
olds (6076 people) (Srivastava et al, 2003)
whose primary purpose is to offer decision support.
Our goals are more similar to those of Dial Your
Disc (Van Deemter and Odijk, 1997), with the added
requirement that texts should be easy to read. For
instance, ecological concepts (such as site fidelity)
could be communicated by explicitly defining them.
However, we would prefer these to be inferred from
more engaging narratives.
The blogs currently created by the charity (cf.
Section 1) are, stripped down to their essence, a se-
quence of locations. We propose to interlay these
sequences of locations with descriptions of red kite
behaviours, broadly categorised as fidelity, explo-
ration, feeding or social. Algorithm 1 outlines the
planning process. We have developed an initial pro-
totype that implements this for our simplified world.
Using template based generation, we can automati-
cally generate blogs such as the following for arbi-
trary sequences of locations in our simplified world:
This week Red Baroness continued to feel like
stretching her wings. On Monday she was
seen in the fields by the lake, calling out to
other kites. On Tuesday and Wednesday she
stayed along the road, looking for roadkill on
the country lanes. On Thursday she returned
to the fields by the lake ? clearly there was
plenty to eat there.
To scale this up to the real world, work is in
progress to augment our data analysis component by
using a variety of GIS data to map geo-coordinates
to habitat, terrain and demographic features from
which we can identify relevant kite behaviours.
Our remaining challenges are to (a) compile a
large list of red kite behaviours, (b) use paraphras-
ing approaches to create variety in descriptions of
behaviour and (c) develop means to interweave more
123
1. Identify place names of interest to the user among
the many GIS locations frequented by the red kite
2. For each place of interest (ordered by time):
(a) describe place in terms of relevant geographi-
cal features
(b) describe one or two behaviours (feeding or so-
cial) associated with any of these features
(c) make a reference to any exploratory behaviour
or site fidelity if identified from previous se-
quence.
Algorithm 1: Generate a blog about a red kite
complex behaviours, such as mating, into the narra-
tives. There is ongoing interdisciplinary work into
each of the above. Variation is likely to be critical to
the endeavour as these blogs are aimed at engaging
the reader, not just at presenting information. This
can be achieved both by expanding the range of be-
haviours we describe, and the range of ways we can
realise these through language.
7 Conclusions
This paper reports a study that informs the appli-
cation of NLG technologies to conservation efforts
centred around public engagement. We report on
findings which indicate that it is possible to use nar-
ratives loosely based on satellite tag data to com-
municate ecological insights as well as to create a
positive perception of the species in readers? minds.
This informs an approach to automating the creation
of blogs from satellite-tagged red kites by interleav-
ing sequences of locations with descriptions of be-
haviour. A proof of concept system has been devel-
oped for a simplified world, and is in the process of
being scaled up to the real world, using GIS data.
Acknowledgments
This research is supported by an award made by
the RCUK Digital Economy programme to the
dot.rural Digital Economy Hub; award reference:
EP/G066051/1.
References
R. Black, J. Reddington, E. Reiter, N. Tintarev, and
A. Waller. 2010. Using nlg and sensors to support
personal narrative for children with complex commu-
nication needs. In Proceedings of the NAACL HLT
2010 Workshop on Speech and Language Processing
for Assistive Technologies, pages 1?9. Association for
Computational Linguistics.
E. Goldberg, N. Driedger, and R.I. Kittredge. 1994. Us-
ing natural-language processing to produce weather
forecasts. IEEE Expert, 9(2):45?53.
S.D. Gosling, V.S.Y. Kwan, and O.P. John. 2003. A
dog?s got personality: a cross-species comparative
approach to personality judgments in dogs and hu-
mans. Journal of Personality and Social Psychology,
85(6):1161.
O.P. John, E.M. Donahue, and R.L. Kentle. 1991. The
big five inventoryversions 4a and 54. Berkeley: Uni-
versity of California, Berkeley, Institute of Personality
and Social Research.
O.P. John, L.P. Naumann, and C.J. Soto. 2008. Paradigm
shift to the integrative big five trait taxonomy. Hand-
book of personality: Theory and research, pages 114?
158.
S. Mahamood, E. Reiter, and C. Mellish. 2008. Neona-
tal intensive care information for parents an affec-
tive approach. In Computer-Based Medical Systems,
2008. CBMS?08. 21st IEEE International Symposium
on, pages 461?463. IEEE.
M. Molina, A. Stent, and E. Parodi. 2011. Generating
automated news to explain the meaning of sensor data.
Advances in Intelligent Data Analysis X, pages 282?
293.
M. O?Donnell, C. Mellish, J. Oberlander, and A. Knott.
2001. Ilex: an architecture for a dynamic hypertext
generation system. Natural Language Engineering,
7(3):225?250.
F. Portet, E. Reiter, A. Gatt, J. Hunter, S. Sripada,
Y. Freer, and C. Sykes. 2009. Automatic generation of
textual summaries from neonatal intensive care data.
Artificial Intelligence, 173(7-8):789?816.
J. Reddington, E. Reiter, N. Tintarev, R. Black, and
A. Waller. 2011. ?Hands Busy, Eyes Busy?: Generat-
ing Stories from Sensor Data for Automotive applica-
tions. In Proceedings of IUI Workshop on Multimodal
Interfaces for Automotive Applications.
S. Srivastava, O.P. John, S.D. Gosling, and J. Potter.
2003. Development of personality in early and middle
adulthood: Set like plaster or persistent change?. Jour-
nal of Personality and Social Psychology, 84(5):1041.
M. Theune, E. Klabbers, J.R. de Pijper, E. Krahmer, and
J. Odijk. 2001. From data to speech: a general ap-
proach. Natural Language Engineering, 7(01):47?86.
K. Van Deemter and J. Odijk. 1997. Context modeling
and the generation of spoken discourse. Speech Com-
munication, 21(1-2):101?121.
124
Proceedings of the 14th European Workshop on Natural Language Generation, pages 157?161,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Generation of Quantified Referring Expressions:
Evidence from Experimental Data
Dale Barr
Dept. of Psychology
University of Glasgow
dale.barr@glasgow.ac.uk
Kees van Deemter
Computing Science Dept.
University of Aberdeen
k.vdeemter@abdn.ac.uk
Raquel Ferna?ndez
ILLC
University of Amsterdam
raquel.fernandez@uva.nl
Abstract
We present the results from an elicitation
experiment in which human speakers were
asked to produced quantified referring ex-
pressions (QREs), as in ?The crate with
10 apples?, ?The crate with many apples?,
etc. These results suggest that some sub-
tle contextual factors govern the choice be-
tween different types of QREs, and that
numerals are highly preferred for subitiz-
able quantities despite the availability of
coarser-grained expressions.
1 Introduction
Speakers can express quantities in different ways.
For instance, a speaker may specify a meeting time
with the expression ?in the morning? or with the
more precise, numeric expression ?at 10:30am??;
she may choose to specify a temperature as ?5 de-
grees Celsius? or instead use the less precise but
more qualifying expression ?cold?. One area of
NLG where these choices are important is the gen-
eration of referring expressions. In particular, a
referent may be identified by means of some quan-
titative value or other (e.g., ?the tall man; ?the man
who is 198cm tall?), or by means of the number
of other entities to which it is related. Hence-
forth, let?s call these quantified referring expres-
sions (QREs). An example of a QRE arises, for
instance, when a person is identified by means of
the number of his children (?the man with 5 daugh-
ters?), when a directory is identified by means
of the number of files in it (?the directory with
520/many PDF files in it?), or when a crate is iden-
tified by means of the number of apples in it (?the
crate with 7 /a few apples?).
Green and van Deemter (2011) asked under
what circumstances it might be beneficial, for
a reader or hearer, for referring expressions of
this kind to contain vague expressions (e.g., like
many). The present paper addresses the same phe-
nomena focussing, more broadly, on all the differ-
ent ways in which reference may be achieved; un-
like these previous authors, we shall address this
question from the point of view of the speaker,
asking how human speakers refer in such cases,
rather than how useful a given referring expression
is to a hearer (e.g., as measured by their response
times in a manipulation task).
We start by making our research questions more
precise in the next section. We then describe the
production experiment we run online in Section 3
and present an analysis of the data in Section 4.
We end with some pointers on how our results
could inform an NLG module for QREs.
2 Research Questions
Suppose you want to point out one crate amongst
several crates with different numbers of apples.
You may use a numeral (?the crate with seven ap-
ples?) or, if the crate in question is the one with
the largest or smallest amount of apples, you may
use superlatives (?the crate with the most apples?),
comparatives (?with more apples?) or vague quan-
tifiers (?with many apples?); if your crate is the
only one with any apples in it at all, you might
simply say ?the crate with apples?). In many situ-
ations, several of these options are applicable. It
is not obvious, however, which of these is pre-
ferred. The Gricean Maxim of Quantity (Grice,
1975) urges speakers to make their contribution as
informative as, but not more informative than, it is
required for the current purposes of the exchange.
This might be taken to predict that speakers will
tend to use the most coarsely grained expression
that identifies the referent (unless they want some
nontrivial implicatures to be inferred). This would
predict, for example that it is odd to say ?the box
with 27 apples? when ?the box with apples? suf-
fices, because the latter contains a boolean prop-
erty (contains apples), whereas the former relies
157
Figure 1: Sample stimuli in contexts X , XY , XYY with big gap, and XYZ with small gap.
on a special case on what is essentially much more
finely grained property (contains x apples).
Our hunch, however, was that this is not the
whole story. For example, the literature on human
number processing suggests that numbers below 5
or 6 are handled almost effortlessly; these num-
bers are called subitizable (Kaufman et al, 1949)
Furthermore, we hypothesized that it matters to
what extent the number of apples in the target crate
?stands out?. We had the following expectations:
1. Speakers do not always use the coarsest-
grained level that is sufficient.
2. Whether a quantity is subitizable or not inter-
feres with the speakers? choice.
3. The frequency of vague forms (such as ?many?)
will be higher in contexts where the gap be-
tween the target quantity and the quantities in
the distractors is large than when it is small.1
We wanted to put these ideas to the test and, more
generally, find out how human speakers use QREs
in different contexts. Our interest was also in cre-
ating a corpus of human-produced QREs that can
serve future research.
3 Experimental Setup
The elicitation experiment was run online. Sub-
jects first encountered a screen with instructions.
They were told that they would be presented with
situations consisting of three squares, with each of
them having none, one or more shapes in it. In
each of these situations, one of the three squares
would be highlighted and subjects were asked to
describe this target square in a way that would en-
able a reader of their expression to identify it. Sub-
jects were told that the recipient of their descrip-
tion may see the three squares arranged differently
on the screen with their contents possibly being
scrambled around. That is, they were indirectly
asked to concentrate on the quantity of shapes in
1Later on we refer to vague forms as ?base?, a common
term used to describe the vague, unmodified form of relative
scalar adjectives (e.g., tall) as opposed to their comparative
(taller) and superlative (tallest) forms.
the squares (rather than on their relative position or
on the spatial configuration of the shapes in them).
Figure 1 shows some sample stimuli.
The experiment included a total of 20 items,
generated according to the following parameters:
? Subitizability: the amount of shapes in the tar-
get is within the subitizable range (SR) (1-4
shapes) or within a non-subitizable range (NR);
we included three non-subitizable ranges, with
around 10, 20, and 30 shapes, respectively.
? Context: we considered four types of scenarios:
1. X : only the target square is filled.
2. XY : two squares are filled.
3. XYY: all squares filled; with two ranges.
4. XYZ: all squares filled; with three ranges.
The symbol X in the first position stands for the
referent square, while the symbols in the other
two positions indicate for each of the other two
squares whether it contains a number of shapes
within the same range as the referent square
(X), within a different range (Y/Z), or whether
it does not contain any shapes at all ( ).
? Relative Size: the target contains either the
smallest or the largest amount of shapes.
? Gap Size: there is either a big or a small quan-
tity difference between the target and other
squares. A big gap size is only possible with
target squares that contain the largest amount of
shapes within a non-subitizable range and those
that contain the smallest amount of shapes
within a subitizable range.
Participants were recruited by publishing a call
in the Linguist List. A total of 82 subjects par-
ticipated in the experiment, including participants
who only responded to some items. We eliminated
6 sessions where the participant had responded to
less than 10 items. The final dataset includes 76
participants and a total of 1508 descriptions.
4 Results
Each description produced by the participants was
annotated with one of the categories in Table 1.
158
Category Examples
ABS [absolute] the one with pacmans / the square that?s not blank
BASE [base] the square with lots of dark dashes / it has a few crosses in it
COMP [comparative] the one with fewer dashes / the square with more crosses in it
NUM [numeric] the square with 11 black dots / 3 grey ovals
SUP [superlative] it has the largest number of purple squares / the square with the least minuses
OTH [other] about a dozen blue diamonds / big droup of circles in the centre
Table 1: Categories used to code the expressions produced by the participants.
The classification was first done automatically by
pattern matching and then revised manually.
To analyse the data, we used mixed-effects lo-
gistic regression with crossed random effects for
subjects and items (Baayen et al, 2008). All
models had by-subject and by-item random in-
tercepts, and by-subject random slopes for the
within-subject factors of context and range (subiti-
zability). The models were fit using maximum
likelihood estimation with p-values derived from
likelihood ratio tests. Model estimation was per-
formed using the lme4 package (Bates et al, 2013)
of R statistical software (R Core Team, 2013).
Table 2 shows the overall distribution of expres-
sion types used by the participants. As can be
seen, numerical expressions were the most com-
mon type of expression used overall (65%). We
found, however, that there was a strong subiti-
zability effect in the use of these expressions:
for non-subitizable targets, subjects used numer-
ical expressions only 39% of the time, while for
subitizable targets they did so 90% of the time.
This main effect of subitizability was significant
(?2(1) = 47.92, p < .001). There was high
variability across subjects in the effect (?2(1) =
25.00, p < .001), with a higher rate of numeri-
cal expressions associated with a smaller effect of
subitizability (r = ?.61). Note that 17 of the 82
subjects (? 20%) always used numerical expres-
sions, even when the target was not subitizable. Of
the remaining 65 subjects, 64 show a very signif-
icant preference for using numeric expressions to
describe targets within the subitizable range.
Figure 2 shows the proportion of expression
types for each type of context and subitizabil-
ABS BASE COMP NUM SUP OTH Total
NR 73 33 26 294 308 17 751
SR 51 1 0 684 21 0 757
Total 124 34 26 978 329 17 1508
Table 2: Row counts of expression types for non-
subitizable (NR) and subitizable (SR) targets.
ity condition.2 Sensitivity to context differed for
subitizable and non-subitizable targets, supported
by a reliable interaction between these factors
(?2(1) = 17.31, p < .001). Despite the strong
overall preference for numerical expressions with
subitizable targets, the effect of context was still
reliable (?2(1) = 22.63, p < .001). For subiti-
zable targets (Figure 2, bottom row), numeric ex-
pressions were almost always used (96%) except
in contexts where the target was the only filled
square (X ). In this context, participants occa-
sionally used absolute expressions instead (e.g. the
one with shapes) 33% of the time. In sum, subiti-
zable targets overwhelmingly triggered the use of
numerals, predominating even when a Gricean ac-
count would prefer coarser-grained expressions.
For non-subitizable targets (first row of plots
in Figure 2), in contexts without distractors (X )
absolute expressions were preferred over numer-
ical ones; this differed from the behaviour of
subitizable targets in this context, where numer-
ical expressions predominated (?2(1) = 4.25,
p = .039). In contexts with non-empty distrac-
tors (XY , XYY, and XYZ), expressions other than
numeric are used significantly more often than
they were for subitizable targets (?2(1) = 52.93,
p < .001). Superlative expressions (e.g. the
square with the least dots) were preferred in con-
texts where the three squares were filled (?2(1) =
7.74, p = .005). In contexts with one distractor
(XY ), superlatives were also rather common, and
comparative expressions (e.g. the one with fewer
dashes) occurred at higher rates than in other types
of context (?2(1) = 42.34, p < .001).
The comparison between the contexts with two
distractors (XYY and XYZ) suggests that they dif-
fered largely in the use of vague expressions
(BASE; e.g. the one with many diamonds), which
had a higher rate in context XYY where there
were only two quantity ranges (?2(1) = 5.01,
2Category OTH (other) is not shown in Figure 2 to avoid
clutter. Table 2 shows the row counts for all categories.
159
ABS BASE COMP NUM SUP
X__
non?s
ubitizab
le range
0.00
.10.2
0.30
.40.5
0.6
ABS BASE COMP NUM SUP
XY_
0.00
.10.2
0.30
.40.5
0.6
ABS BASE COMP NUM SUP
XYY
0.00
.10.2
0.30
.40.5
0.6
ABS BASE COMP NUM SUP
XYZ
0.00
.10.2
0.30
.40.5
0.6
ABS BASE COMP NUM SUP
subitiza
ble rang
e
0.0
0.2
0.4
0.6
0.8
1.0
ABS BASE COMP NUM SUP0.0
0.2
0.4
0.6
0.8
1.0
ABS BASE COMP NUM SUP0.0
0.2
0.4
0.6
0.8
1.0
ABS BASE COMP NUM SUP0.0
0.2
0.4
0.6
0.8
1.0
Figure 2: Proportion of expression types in each context for subitizable and non-subitizable targets.
p = .025). For this context we also found an ef-
fect of gap size (see Figure 3): the relative odds
of choosing a vague expression over a numeric or
superlative one is significantly higher when there
is a big difference between the target quantity and
the distractor quantities (?2(1) = 5.68, p = .017);
that is, when the chance of there being borderline
cases is reduced. A small gap between the quanti-
ties makes the preference for superlative (and thus
non-vague) expressions stronger.
Figure 3: The effect of gap size.
5 Conclusions
In line with our expectations (see Section 2), our
data are not easy to reconcile with the type of
Gricean account that predicts a preference for the
most coarsely grained QRE that identifies the tar-
get. The most obvious deviation from this Gricean
account arises from the subitizable items in our
study, where numerical expressions turned out to
be much preferred over other QREs. The natu-
ral explanation seems to be that such expressions
come naturally to speakers (and to hearers too as
shown by Green and van Deemter (2011)). In
other words, our study suggests an intriguing vari-
ant on Grice, in which the most relevant factor is
not one of informativeness ? as Grice?s writings
suggest ? but one of effort. It suggests that speak-
ers tend to produce expressions that identify the
referent with least effort.
Our expectation 3 was also confirmed: vague
forms (BASE) are more frequent with big gap
sizes, although they are not produced with high
frequency. (The same pattern of results was found
by van Deemter (2004)). Thus, in the scenarios
we considered vague QREs are never the most
favoured option. The high frequency of superla-
tives over comparatives is also noteworthy. Com-
paratives are used very seldom overall but are
more frequent in contexts with only one distractor
(XY ). This indicates that some speakers opt for
a less strong expression than a superlative (an ex-
pression that means more than x rather than more
than any other x) in contexts where this does not
lead to ambiguity. However, numerals and su-
perlatives are still largely preferred in those con-
texts.
These observations suggest that a given type of
situation (i.e., a given context + subitizability con-
dition) should not always map to the same type of
QRE. If human QRE behaviour is to be mimicked,
the best approach seems to be to use a stochastic
NLG program that seeks to replicate the frequen-
cies that are found in human usage.
The collected data is freely available at http:
//www.illc.uva.nl/?raquel/xprag/.
160
References
R. Baayen, D. Davidson, and D. Bates. 2008. Mixed-
effects modeling with crossed random effects for
subjects and items. Journal of memory and lan-
guage, 59(4):390?412.
D. Bates, M. Maechler, and B. Bolker, 2013. lme4:
Linear mixed-effects models using S4 classes. R
v. 0.999999-2.
M. Green and K. van Deemter. 2011. Vagueness
as cost reduction: An empirical test. In Proc. of
Production of Referring Expressions workshop at
CogSci 2011.
H. P. Grice. 1975. Logic and conversation. In The
Logic of Grammar, pages 64?75. Dickenson.
E. Kaufman, M. Lord, T. Reese, and J. Volkmann.
1949. The discrimination of visual number. Ameri-
can Journal of Psychology, 62(4):498?525.
R Core Team, 2013. R: A Language and Environment
for Statistical Computing. R Foundation. v. 3.0.0.
K. van Deemter. 2004. Finetuning NLG through ex-
periments with human subjects: the case of vague
descriptions. In Proc. of the 3rd INLG Conference.
161
Proceedings of the 14th European Workshop on Natural Language Generation, pages 208?209,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Content Selection Challenge - University of Aberdeen Entry
Roman Kutlak
Chris Mellish
Kees van Deemter
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, UK
r.kutlak, c.mellish, k.vdeemter @abdn.ac.uk
1 Introduction
Bouayad-Agha et al (2012) issued a content de-
termination challenge in which researchers were
asked to create systems that can automatically
select content suitable for a first paragraph in a
Wikipedia article from an RDF knowledge base
of information about people. This article is a de-
scription of the system built at the University of
Aberdeen.
Our working assumption is that the target text
should contain information that is commonly
known about the target person. The Wikipedia?s
manual of style mentions that ?The lead [section]
serves as an introduction to the article and a sum-
mary of its most important aspects1.? What is most
important about a person is likely to be often men-
tioned in biographies and hence it is more likely to
be commonly known.
Our system was motivated by the notion of
common ground, especially the way it was ac-
counted for by (Clark and Marshall, 1981). Clark
and Marshall (1981) introduce two categories of
common ground: personal common ground shared
by a small group of individuals and communal
common ground shared by a community of peo-
ple. We are most interested in the concept of com-
munal common ground, which arises from the ex-
posure to the same information within a commu-
nity. For example, if there is a statue in front of
your work place, you expect your colleagues to
also know about this statue and so the information
that there is a statue in front of you workplace be-
comes a part of the community knowledge (where
the community are people who work at the same
place).
Our hypothesis is that if we take a corpus of
documents produced by some large community
(e.g., English speakers), we should be able to ap-
1http://en.wikipedia.org/wiki/
Wikipedia:Manual_of_Style/Lead_section
proximate the community?s knowledge of certain
facts by counting how frequently they are men-
tioned in the corpus. For example, if a corpus con-
tains 1000 articles about Sir Isaac Newton and 999
of the examined documents mention the property
of him being a physicist and only 50 documents
mention that he held the position as the warden
of the Royal Mint in 1696 we should expect more
people to know that he was a physicist.
We implemented the heuristic for approximat-
ing communal common ground and tested it in
an experiment with human participants to measure
whether there is a correlation between the heuris-
tic?s predictions and actual knowledge of people
(Kutlak et al, 2012). In our implementation, we
used the Internet as a corpus of documents and we
used the Google search engine for counting the
number of documents containing the properties.
Although the number of hits is only an estimate
of the actual number of documents containing a
particular term, the heuristic achieved a Spearman
correlation of 0.639 with p < 0.001 between the
knowledge of people and the numbers of hits re-
turned by Google.
Although there are some issues with the use of a
proprietary search engine such as Google (for ex-
ample, the search engine can perform stemming;
see Kilgarriff (2007) for a discussion) search en-
gines have been successfully used previously (Tur-
ney, 2001; Goudbeek and Krahmer, 2012).
2 Algorithm
The submitted system employs the heuristic out-
lined in in the previous section. The input is a col-
lection of files containing information about peo-
ple and a collection of human readable strings for
each of the files. The data were taken from Free-
base - a community created repository of informa-
tion about people, places and other things. Each
file is a small knowledge base containing a set of
RDF triples describing the entity.
208
The data is encoded in machine-readable form
(e.g., the fact that Newton was an astronomer
is encoded as ns:m.03s9v ns:type.object.type
ns:astronomy.astronomer .) so in order to find
collocations in a human written text, each RDF
triple has to be ?lexicalised.? This is done by map-
ping the RDF values to human produced strings
provided by Freebase. After substituting the lexi-
calisations and removing some unnecessary infor-
mation the algorithm adds the name of the target,
which results in text such as Isaac Newton type
Astronomer.
The algorithm reads one file at a time and cre-
ates a human readable string for each of the prop-
erties in the file. In the second step, the system re-
moves disambiguations (text in brackets) and fil-
ters out properties that have the same string rep-
resentation (duplicates). Additionally, properties
with certain attributes are filtered out to reduce the
number of queries2.
In the third step, the system uses Google cus-
tom search API (a programming interface to the
search engine) to estimate the score of each prop-
erty. Properties that contain the name of the entity
are penalised. This is done to reduce the impor-
tance of properties such as the target?s parents or
relatives. For example, if the algorithm was rank-
ing properties of Sir Isaac Newton and a property
contained the string Newton, the score assigned to
that property was multiplied by 0.75. The prop-
erties were then ordered by the number of corre-
sponding hits in descending order.
In the last step the algorithm selects the top
ranked properties. The number of properties to
select was calculated by the following equation
5 ? log(|properties|). This equation was chosen
by intuition so that a larger proportion of proper-
ties was selected for entities with a small number
of properties than for entities with a large number
of properties. The set of properties in the above
equation is the set obtained after the filtering.
To prevent the system from selecting too many
properties with the same attribute and to intro-
duce variation, the system selected only five prop-
erties with the same attribute (e.g., five films, five
books).
2For example, the knowledge base describing Anton??n
Dvor?a?k contains 5670 properties of which 5154 have the at-
tribute music.artist.track.
3 Concluding Remarks
The implemented system uses a simple document-
based collocation heuristic to decide what prop-
erties to select. This makes it prone to favour-
ing properties that contain common words or the
name of the described entity. The advantage is
that the system is relatively simple and versatile.
The ?common ground? heuristic could be com-
bined with another heuristic that assigns negative
score to properties that contain common words or
a heuristic that estimates how interesting the prop-
erty is.
Finally, we do not expect the system to perform
better than machine learning based approaches
such as that of Duboue and McKeown (2003) but
it will certainly be interesting to see how far one
can get with a simple heuristic.
References
Nadjet Bouayad-Agha, Gerard Casamayor, Leo Wan-
ner, and Chris Mellish. 2012. Content selection
from semantic web data. In Proceedings of INLG
2012, pages 146?149, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Herbert H. Clark and Catherine Marshall. 1981. Def-
inite reference and mutual knowledge. In A. K.
Joshi, B. L. Webber, and I. A. Sag, editors, El-
ements of discourse understanding, pages 10?63.
Cambridge University Press, New York.
Pablo A. Duboue and Kathleen R. McKeown. 2003.
Statistical acquisition of content selection rules for
natural language generation. In Proceedings of
the 2003 EMNLP, pages 121?128, Morristown, NJ,
USA. Association for Computational Linguistics.
Martijn Goudbeek and Emiel Krahmer. 2012. Align-
ment in interactive reference production: Con-
tent planning, modifier ordering, and referential
overspecification. Topics in Cognitive Science,
4(2):269?289.
Adam Kilgarriff. 2007. Googleology is bad science.
Comput. Linguist., 33:147?151, March.
Roman Kutlak, Kees van Deemter, and Chris Mellish.
2012. Corpus-based metrics for assessing commu-
nal common ground. Proceedings of the 34th An-
nual Meeting of the Cognitive Science Society.
P. Turney. 2001. Mining the web for synonyms: PMI-
IR versus LSA on TOEFL. In Proceedings of the
twelfth european conference on machine learning
(ecml-2001).
209
