Proceedings of the 12th Conference of the European Chapter of the ACL, pages 424?432,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
N-gram-based Statistical Machine Translation versus Syntax Augmented
Machine Translation: comparison and system combination
Maxim Khalilov and Jos? A.R. Fonollosa
Universitat Polit?cnica de Catalunya
Campus Nord UPC, 08034
Barcelona, Spain
{khalilov,adrian}@talp.upc.edu
Abstract
In this paper we compare and contrast
two approaches to Machine Translation
(MT): the CMU-UKA Syntax Augmented
Machine Translation system (SAMT) and
UPC-TALP N-gram-based Statistical Ma-
chine Translation (SMT). SAMT is a hier-
archical syntax-driven translation system
underlain by a phrase-based model and a
target part parse tree. In N-gram-based
SMT, the translation process is based on
bilingual units related to word-to-word
alignment and statistical modeling of the
bilingual context following a maximum-
entropy framework. We provide a step-
by-step comparison of the systems and re-
port results in terms of automatic evalu-
ation metrics and required computational
resources for a smaller Arabic-to-English
translation task (1.5M tokens in the train-
ing corpus). Human error analysis clari-
fies advantages and disadvantages of the
systems under consideration. Finally, we
combine the output of both systems to
yield significant improvements in transla-
tion quality.
1 Introduction
There is an ongoing controversy regarding
whether or not information about the syntax of
language can benefit MT or contribute to a hybrid
system.
Classical IBM word-based models were re-
cently augmented with a phrase translation ca-
pability, as shown in Koehn et al (2003), or in
more recent implementation, the MOSES MT sys-
tem1 (Koehn et al, 2007). In parallel to the phrase-
based approach, the N -gram-based approach ap-
peared (Mari?o et al, 2006). It stemms from
1www.statmt.org/moses/
the Finite-State Transducers paradigm, and is ex-
tended to the log-linear modeling framework, as
shown in (Mari?o et al, 2006). A system follow-
ing this approach deals with bilingual units, called
tuples, which are composed of one or more words
from the source language and zero or more words
from the target one. The N -gram-based systems
allow for linguistically motivated word reordering
by implementing word order monotonization.
Prior to the SMT revolution, a major part
of MT systems was developed using rule-based
algorithms; however, starting from the 1990?s,
syntax-driven systems based on phrase hierar-
chy have gained popularity. A representative
sample of modern syntax-based systems includes
models based on bilingual synchronous grammar
(Melamed, 2004), parse tree-to-string translation
models (Yamada and Knight, 2001) and non-
isomorphic tree-to-tree mappings (Eisner, 2003).
The orthodox phrase-based model was en-
hanced in Chiang (2005), where a hierarchical
phrase model allowing for multiple generaliza-
tions within each phrase was introduced. The
open-source toolkit SAMT2 (Zollmann and Venu-
gopal, 2006) is a further evolution of this ap-
proach, in which syntactic categories extracted
from the target side parse tree are directly assigned
to the hierarchically structured phrases.
Several publications discovering similarities
and differences between distinct translation mod-
els have been written over the last few years. In
Crego et al (2005b), the N -gram-based system
is contrasted with a state-of-the-art phrase-based
framework, while in DeNeefe et al (2007), the
authors seek to estimate the advantages, weak-
est points and possible overlap between syntax-
based MT and phrase-based SMT. In Zollmann et
al. (2008) the comparison of phrase-based , "Chi-
ang?s style" hirearchical system and SAMT is pro-
2www.cs.cmu.edu/?zollmann/samt
424
vided.
In this study, we intend to compare the differ-
ences and similarities of the statistical N -gram-
based SMT approach and the SAMT system. The
comparison is performed on a small Arabic-to-
English translation task from the news domain.
2 SAMT system
A criticism of phrase-based models is data sparse-
ness. This problem is even more serious when the
source, the target, or both languages are inflec-
tional and rich in morphology. Moreover, phrase-
based models are unable to cope with global re-
ordering because the distortion model is based
on movement distance, which may face computa-
tional resource limitations (Och and Ney, 2004).
This problem was successfully addressed when
the MT system based on generalized hierarchi-
cally structured phrases was introduced and dis-
cussed in Chiang (2005). It operates with only two
markers (a substantial phrase category and "a glue
marker"). Moreover, a recent work (Zollmann and
Venugopal, 2006) reports significant improvement
in terms of translation quality if complete or par-
tial syntactic categories (derived from the target
side parse tree) are assigned to the phrases.
2.1 Modeling
A formalism for Syntax Augmented Translation
is probabilistic synchronous context-free grammar
(PSynCFG), which is defined in terms of source
and target terminal sets and a set of non-terminals:
X ?? ??, ?,?, ??
where X is a non-terminal, ? is a sequence of
source-side terminals and non-terminals, ? is a se-
quence of target-side terminals and non-terminals,
? is a one-to-one mapping from non-terminal to-
kens space in ? to non-terminal space in ?, and ?
is a non-negative weight assigned to the rule.
The non-terminal set is generated from the syn-
tactic categories corresponding to the target-side
Penn Treebank set, a set of glue rules and a spe-
cial marker representing the "Chiang-style" rules,
which do not span the parse tree. Consequently, all
lexical mapping rules are covered by the phrases
mapping table.
2.2 Rules annotation, generalization and
pruning
The SAMT system is based on a purely lexi-
cal phrase table, which is identified as shown in
Koehn et al (2003), and word alignment, which is
generated by the grow-diag-final-and method (ex-
panding the alignment by adding directly neigh-
boring alignment points and alignment points in
the diagonal neighborhood) (Och and Ney, 2003).
Meanwhile, the target of the training corpus is
parsed with Charniak?s parser (Charniak, 2000),
and each phrase is annotated with the constituent
that spans the target side of the rules. The set of
non-terminals is extended by means of conditional
and additive categories according to Combinatory
Categorical Grammar (CCG) (Steedman, 1999).
Under this approach, new rules can be formed. For
example, RB+VB, can represent an additive con-
stituent consisting of two synthetically generated
adjacent categories 3, i.e., an adverb and a verb.
Furthermore, DT\NP can indicate an incomplete
noun phrase with a missing determiner to the left.
The rule recursive generalization procedure co-
incides with the one proposed in Chiang (2005),
but violates the restrictions introduced for single-
category grammar; for example, rules that contain
adjacent generalized elements are not discarded.
Thus, each rule
N ?? f1 . . . fm/e1 . . . en
can be extended by another existing rule
M ?? fi . . . fu/ej . . . ev
where 1 ? i < u ? m and 1 ? j < v ? n, to
obtain a new rule
N ?? f1 . . . fi?1Mkfu+1 . . . fm/
e1 . . . ej?1Mkev+1 . . . en
where k is an index for the non-terminal M that in-
dicates a one-to-one correspondence between the
new M tokens on the two sides.
Figure 1 shows an example of initial rules ex-
traction, which can be further extended using the
hierarchical model, as shown in Figure 2 (conse-
quently involving more general elements in rule
description).
Rules pruning is necessary because the set of
generalized rules can be huge. Pruning is per-
formed according to the relative frequency and
the nature of the rules: non-lexical rules that
have been seen only once are discarded; source-
conditioned rules with a relative frequency of ap-
pearance below a threshold are also eliminated.
3Adjacent generalized elements are not allowed in Chi-
ang?s work because of over-generation. However, over-
generation is not an issue within the SAMT framework due
to restrictions introduced by target-side syntax
425
Rules that do not contain non-terminals are not
pruned.
2.3 Decoding and feature functions
The decoding process is accomplished using a top-
down log-linear model. The source sentence is de-
coded and enriched with the PSynCFG in such a
way that translation quality is represented by a set
of feature functions for each rule, i.e.:
? rule conditional probabilities, given a source,
a target or a left-hand-side category;
? lexical weights features, as described in
Koehn et al (2003);
? counters of target words and rule applica-
tions;
? binary features reflecting rule context (purely
lexical and purely abstract, among others);
? rule rareness and unbalancedness penalties.
The decoding process can be represented as
a search through the space of neg log probabil-
ity of the target language terminals. The set of
feature functions is combined with a finite-state
target-side n-gram language model (LM), which
is used to derive the target language sequence dur-
ing a parsing decoding. The feature weights are
optimized according to the highest BLEU score.
For more details refer to Zollmann and Venu-
gopal (2006).
3 UPC n-gram SMT system
A description of the UPC-TALP N -gram transla-
tion system can be found in Mari?o et al (2006).
SMT is based on the principle of translating a
source sentence (f ) into a sentence in the target
language (e). The problem is formulated in terms
of source and target languages; it is defined ac-
cording to equation (1) and can be reformulated as
selecting a translation with the highest probability
from a set of target sentences (2):
Figure 1: Example of SAMT and N-gram elements extraction.
Figure 2: Example of SAMT generalized rules.
426
e?I1 = argmaxeI1
{
p(eI1 | fJ1 )
}
= (1)
= argmax
eI1
{
p(fJ1 | eI1) ? p(eI1)
}
(2)
where I and J represent the number of words in
the target and source languages, respectively.
Modern state-of-the-art SMT systems operate
with the bilingual units extracted from the parallel
corpus based on word-to-word alignment. They
are enhanced by the maximum entropy approach
and the posterior probability is calculated as a log-
linear combination of a set of feature functions
(Och and Ney, 2002). Using this technique, the
additional models are combined to determine the
translation hypothesis, as shown in (3):
e?I1 = argmaxeI1
{ M?
m=1
?mhm(eI1, fJ1 )
}
(3)
where the feature functions hm refer to the system
models and the set of ?m refers to the weights cor-
responding to these models.
3.1 N-gram-based translation system
The N -gram approach to SMT is considered to
be an alternative to the phrase-based translation,
where a given source word sequence is decom-
posed into monolingual phrases that are then trans-
lated one by one (Marcu and Wong, 2002).
The N -gram-based approach regards transla-
tion as a stochastic process that maximizes the
joint probability p(f, e), leading to a decomposi-
tion based on bilingual n-grams. The core part of
the system constructed in this way is a translation
model (TM), which is based on bilingual units,
called tuples, that are extracted from a word align-
ment (performed with GIZA++ tool4) according to
certain constraints. A bilingual TM actually con-
stitutes an n-gram LM of tuples, which approxi-
mates the joint probability between the languages
under consideration and can be seen here as a LM,
where the language is composed of tuples.
3.2 Additional features
The N -gram translation system implements a log-
linear combination of five additional models:
? an n-gram target LM;
4http://code.google.com/p/giza-pp/
? a target LM of Part-of-Speech tags;
? a word penalty model that is used to compen-
sate for the system?s preference for short out-
put sentences;
? source-to-target and target-to-source lexicon
models as shown in Och and Ney (2004)).
3.3 Extended word reordering
An extended monotone distortion model based
on the automatically learned reordering rules was
implemented as described in Crego and Mari?o
(2006). Based on the word-to-word alignment, tu-
ples were extracted by an unfolding technique. As
a result, the tuples were broken into smaller tuples,
and these were sequenced in the order of the target
words. An example of unfolding tuple extraction,
contrasted with the SAMT chunk-based rules con-
struction, is presented in Figure 1.
The reordering strategy is additionally sup-
ported by a 4-gram LM of reordered source POS
tags. In training, POS tags are reordered according
to the extracted reordering patterns and word-to-
word links. The resulting sequence of source POS
tags is used to train the n-gram LM.
3.4 Decoding and optimization
The open-source MARIE5 decoder was used as a
search engine for the translation system. Details
can be found in Crego et al (2005a). The de-
coder implements a beam-search algorithm with
pruning capabilities. All the additional fea-
ture models were taken into account during the
decoding process. Given the development set
and references, the log-linear combination of
weights was adjusted using a simplex optimization
method and an n-best re-ranking as described in
http://www.statmt.org/jhuws/.
4 Experiments
4.1 Evaluation framework
As training corpus, we used the 50K first-lines ex-
traction from the Arabic-English corpus that was
provided to the NIST?086 evaluation campaign
and belongs to the news domain. The corpus
statistics can be found in Table 1. The develop-
ment and test sets were provided with 4 reference
translations, belong to the same domain and con-
tain 663 and 500 sentences, respectively.
5http://gps-tsc.upc.es/veu/soft/soft/marie/
6www.nist.gov/speech/tests/mt/2008/
427
Arabic English
Sentences 50 K 50 K
Words 1.41 M 1.57 K
Average sentence length 28.15 31.22
Vocabulary 51.10 K 31.51 K
Table 1: Basic statistics of the training corpus.
Evaluation conditions were case-insensitive and
sensitive to tokenization. The word alignment is
automatically computed by using GIZA++ (Och
and Ney, 2004) in both directions, which are made
symmetric by using the grow-diag-final-and oper-
ation.
The experiments were done on a dual-processor
Pentium IV Intel Xeon Quad Core X5355 2.66
GHz machine with 24 G of RAM. All computa-
tional times and memory size results are approxi-
mated.
4.2 Arabic data preprocessing
Arabic is a VSO (SVO in some cases) pro-
drop language with rich templatic morphology,
where words are made up of roots and affixes
and clitics agglutinate to words. For prepro-
cessing, a similar approach to that shown in
Habash and Sadat (2006) was employed, and the
MADA+TOKAN system for disambiguation and
tokenization was used. For disambiguation, only
diacritic unigram statistics were employed. For to-
kenization, the D3 scheme with -TAGBIES option
was used. The scheme splits the following set of
clitics: w+, f+, b+, k+, l+, Al+ and pronominal cl-
itics. The -TAGBIES option produces Bies POS
tags on all taggable tokens.
4.3 SAMT experiments
The SAMT guideline was used to perform
the experiments and is available on-line:
http://www.cs.cmu.edu/?zollmann/samt/.
Moses MT script was used to create the
grow ? diag ? final word alignment and
extract purely lexical phrases, which are then used
to induce the SAMT grammar. The target side
(English) of the training corpus was parsed with
the Charniak?s parser (Charniak, 2000).
Rule extraction and filtering procedures were
restricted to the concatenation of the development
and test sets, allowing for rules with a maximal
length of 12 elements in the source side and with a
zero minimum occurrence criterion for both non-
lexical and purely lexical rules.
Moses-style phrases extracted with a phrase-
based system were 4.8M , while a number of gen-
eralized rules representing the hierarchical model
grew dramatically to 22.9M . 10.8M of them were
pruned out on the filtering step.
The vocabulary of the English Penn Treebank
elementary non-terminals is 72, while a number of
generalized elements, including additive and trun-
cated categories, is 35.7K.
The FastTranslateChart beam-search de-
coder was used as an engine of MER training aim-
ing to tune the feature weight coefficients and pro-
duce final n-best and 1-best translations by com-
bining the intensive search with a standard 4-gram
LM as shown in Venugopal et al (2007). The it-
eration limit was set to 10 with 1000-best list and
the highest BLEU score as optimization criteria.
We did not use completely abstract rules (with-
out any source-side lexical utterance), since these
rules significantly slow down the decoding process
(noAllowAbstractRules option).
Table 2 shows a summary of computational time
and RAM needed at each step of the translation.
Step Time Memory
Parsing 1.5h 80Mb
Rules extraction 10h 3.5Gb
Filtering&merging 3h 4.0Gb
Weights tuning 40h 3Gb
Testing 2h 3Gb
Table 2: SAMT: Computational resources.
Evaluation scores including results of system
combination (see subsection 4.6) are reported in
Table 3.
4.4 N-gram system experiments
The core model of the N -gram-based system is a
4-gram LM of bilingual units containing: 184.345
1-grams7, 552.838 2-grams, 179.466 3-grams and
176.221 4-grams.
Along with this model, an N -gram SMT sys-
tem implements a log-linear combination of a 5-
gram target LM estimated on the English portion
of the parallel corpus, as well as supporting 4-
gram source and target models of POS tags. Bies
7This number also corresponds to the bilingual model vo-
cabulary.
428
BLEU NIST mPER mWER METEOR
SAMT 43.20 9.26 36.89 49.45 58.50
N-gram-based SMT 46.39 10.06 32.98 48.47 62.36
System combination 48.00 10.15 33.20 47.54 62.27
MOSES Factored System 44.73 9.62 33.92 47.23 59.84
Oracle 61.90 11.41 28.84 41.52 66.19
Table 3: Test set evaluation results
POS tags were used for the Arabic portion, as
shown in subsection 4.2; a TnT tool was used for
English POS tagging (Brants, 2000).
The number of non-unique initially extracted
tuples is 1.1M , which were pruned according to
the maximum number of translation options per
tuple on the source side (30). Tuples with a NULL
on the source side were attached to either the pre-
vious or the next unit (Mari?o et al, 2006). The
feature models weights were optimized according
to the same optimization criteria as in the SAMT
experiments (the highest BLEU score).
Stage-by-stage RAM and time requirements are
presented in Table 4, while translation quality
evaluation results can be found in Table 3.
Step Time Memory
Models estimation 0.2h 1.9Gb
Reordering 1h ?
Weights tuning 15h 120Mb
Testing 2h 120Mb
Table 4: Tuple-based SMT: Computational re-
sources.
4.5 Statistical significance
A statistical significance test based on a bootstrap
resampling method, as shown in Koehn (2004),
was performed. For the 98% confidence interval
and 1000 set resamples, translations generated by
SAMT and N -gram system are significantly dif-
ferent according to BLEU (43.20?1.69 for SAMT
vs. 46.42? 1.61 for tuple-based system).
4.6 System combination
Many MT systems generate very different trans-
lations of similar quality, even if the models
involved into translation process are analogous.
Thus, the outputs of syntax-driven and purely sta-
tistical MT systems were combined at the sentence
level using 1000-best lists of the most probable
translations produced by the both systems.
For system combination, we followed a Mini-
mum Bayes-risk algorithm, as introduced in Ku-
mar and Byrne (2004). Table 3 shows the results
of the system combination experiments on the test
set, which are contrasted with the oracle transla-
tion results, performed as a selection of the transla-
tions with the highest BLEU score from the union
of two 1000-best lists generated by SAMT and N -
gram SMT.
We also analyzed the percentage contribution of
each system to the system combination: 55-60%
of best translations come from the tuples-based
system 1000-best list, both for system combina-
tion and oracle experiments on the test set.
4.7 Phrase-based reference system
In order to understand the obtained results com-
pared to the state-of-the-art SMT, a reference
phrase-based factored SMT system was trained
and tested on the same data using the MOSES
toolkit. Surface forms of words (factor ?0?), POS
(factor ?1?) and canonical forms of the words
(lemmata) (factor ?2?) were used as English fac-
tors, and surface forms and POS were the Arabic
factors.
Word alignment was performed according to
the grow-diag-final algorithm with the GIZA++
tool, a msd-bidirectional-fe conditional reordering
model was trained; the system had access to the
target-side 4-gram LMs of words and POS. The 0-
0,1+0-1,2+0-1 scheme was used on the translation
step and 1,2-0,1+1-0,1 to create generation tables.
A detailed description of the model training can
be found on the MOSES tutorial web-page8. The
results may be seen in Table 3.
5 Error analysis
To understand the strong and weak points of both
systems under consideration, a human analysis of
8http://www.statmt.org/moses/
429
the typical translation errors generated by each
system was performed following the framework
proposed in Vilar et al (2006) and contrasting the
systems output with four reference translations.
Human evaluation of translation output is a time-
consuming process, thus a set of 100 randomly
chosen sentences was picked out from the corre-
sponding system output and was considered as a
representative sample of the automatically gener-
ated translation of the test corpus. According to
the proposed error topology, some classes of errors
can overlap (for example, an unknown word can
lead to a reordering problem), but it allows finding
the most prominent source of errors in a reliable
way (Vilar et al, 2006; Povovic et al, 2006). Ta-
ble 5 presents the comparative statistics of errors
generated by the SAMT and the N -gram-based
SMT systems. The average length of the generated
translations is 32.09 words for the SAMT transla-
tion and 35.30 for the N -gram-based system.
Apart from unknown words, the most important
sources of errors of the SAMT system are missing
content words and extra words generated by the
translation system, causing 17.22 % and 10.60 %
of errors, respectively. A high number of missing
content words is a serious problem affecting the
translation accuracy. In some cases, the system
is able to construct a grammatically correct
translation, but omitting an important content
word leads to a significant reduction in translation
accuracy:
SAMT translation: the ministers of arab
environment for the closure of the Israeli dymwnp
reactor .
Ref 1: arab environment ministers demand the
closure of the Israeli daemona nuclear reactor .
Ref 2: arab environment ministers demand the
closure of Israeli dimona reactor .
Ref 3: arab environment ministers call for Israeli
nuclear reactor at dimona to be shut down .
Ref 4: arab environmental ministers call for the
shutdown of the Israeli dimona reactor .
Extra words embedded into the correctly trans-
lated phrases are a well-known problem of MT
systems based on hierarchical models operating on
the small corpora. For example, in many cases
the Arabic expression AlbHr Almyt is trans-
lated into English as dead sea side and not
as dead sea, since the bilingual instances con-
tain only the whole English phrase, like following:
AlbHr Almyt#the dead sea side#@NP
The N -gram-based system handles miss-
ing words more correctly ? only 9.40 % of
the errors come from the missing content
Type Sub-type SAMT N-gram
Missing words 152 (25.17 %) 92 (15.44 %)
Content words 104 (17.22 %) 56 (9.40 %)
Filler words 48 (7.95 %) 36 (6.04 %)
Word order 96 (15.89 %) 140 (23.49 %)
Local word order 20 (3.31 %) 68 (11.41 %)
Local phrase order 20 (3.31 %) 20 (3.36 %)
Long range word order 32 (5.30 %) 48 (8.05 %)
Long range phrase order 24 (3.97 %) 4 (0.67 %)
Incorrect words 164 (27.15 %) 204 (34.23 %)
Sense: wrong lexical choice 24 (3.97 %) 60 (10.07 %)
Sense: incorrect disambiguation 16 (2.65 %) 8 (1.34 %)
Incorrect form 24 (3.97 %) 56 (9.40 %)
Extra words 64 (10.60 %) 56 (9.40 %)
Style 28 (4.64 %) 20 (3.36 %)
Idioms 4 (0.07 %) 4 (0.67 %)
Unknown words 132 (21.85 %) 104 (17.45 %)
Punctuation 60 (9.93 %) 56 (9.40 %)
Total 604 596
Table 5: Human made error statistics for a representative test set.
430
words; however, it does not handle local and
long-term reordering, thus the main problem
is phrase reordering (11.41 % and 8.05 %
of errors). In the example below, the un-
derlined block (Circumstantial Complement:
from local officials in the tour-
ism sector) is embedded between the verb
and the direct object, while in correct translation
it must be placed in the end of the sentence.
N-gram translation: the winner received
from local officials in the tourism sector three
gold medals .
Ref 1: the winner received three gold medals
from local officials from the tourism sector .
Ref 2: the winner received three gold medals
from the local tourism officials .
Ref 3: the winner received his prize of 3 gold
medals from local officials in the tourist industry .
Ref 4: the winner received three gold medals
from local officials in the tourist sector .
Along with inserting extra words and wrong
lexical choice, another prominent source of
incorrect translation, generated by the N -
gram system, is an erroneous grammatical
form selection, i.e., a situation when the sys-
tem is able to find the correct translation but
cannot choose the correct form. For example,
arab environment minister call for
closing dymwnp Israeli reactor,
where the verb-preposition combination
call for was correctly translated on the
stem level, but the system was not able to generate
a third person conjugation calls for. In spite
of the fact that English is a language with nearly
no inflection, 9.40 % of errors stem from poor
word form modeling. This is an example of the
weakest point of the SMT systems having access
to a small training material; the decoder does not
use syntactic information about the subject of
the sentence (singular) and makes a choice only
concerning the tuple probability.
The difference in total number of errors is neg-
ligible, however a subjective evaluation of the sys-
tems output shows that the translation generated
by the N -gram system is more understandable
than the SAMT one, since more content words are
translated correctly and the meaning of the sen-
tence is still preserved.
6 Discussion and conclusions
In this study two systems are compared: the UPC-
TALP N -gram-based and the CMU-UKA SAMT
systems, originating from the ideas of Finite-State
Transducers and hierarchical phrase translation,
respectively. The comparison was created to be as
fair as possible, using the same training material
and the same tools on the preprocessing, word-
to-word alignment and language modeling steps.
The obtained results were also contrasted with the
state-of-the-art phrase-based SMT.
Analyzing the automatic evaluation scores, the
N -gram-based approach shows good performance
for the small Arabic-to-English task and signifi-
cantly outperforms the SAMT system. The results
shown by the modern phrase-based SMT (factored
MOSES) lie between the two systems under con-
sideration. Considering memory size and compu-
tational time, the tuple-based system has obtained
significantly better results than SAMT, primarily
because of its smaller search space.
Interesting results were obtained for the PER
and WER metrics: according to the PER,
the UPC-TALP system outperforms the SAMT
by 10%, while the WER improvement hardly
achieves a 2% difference. The N -gram-based
SMT can translate the context better, but pro-
duces more reordering errors than SAMT. This
may be explained by the fact that Arabic and En-
glish are languages with high disparity in word
order, and the N -gram system deals worse with
long-distance reordering because it attempts to use
shorter units. However, by means of introducing
the word context into the TM, short-distance bilin-
gual dependencies can be captured effectively.
The main conclusion that can be made from
the human evaluation analysis is that the systems
commit a comparable number of errors, but they
are distributed dissimilarly. In case of the SAMT
system, the frequent errors are caused by missing
or incorrectly inserted extra words, while the N -
gram-based system suffers from reordering prob-
lems and wrong words/word form choice
Significant improvement in translation quality
was achieved by combining the outputs of the two
systems based on different translating principles.
7 Acknowledgments
This work has been funded by the Spanish Gov-
ernment under grant TEC2006-13964-C03 (AVI-
VAVOZ project).
431
References
T. Brants. 2000. TnT ? a statistical part-of-speech tag-
ger. In Proceedings of the 6th Applied Natural Lan-
guage Processing (ANLP-2000).
E. Charniak. 2000. A maximum entropy-inspired
parser. In Proceedings of NAACL 2000, pages 132?
139.
D. Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL 2005, pages 263?270.
J. M. Crego and J. B. Mari?o. 2006. Improving statis-
tical MT by coupling reordering and decoding. Ma-
chine Translation, 20(3):199?215.
J. M. Crego, J. Mari?o, and A. de Gispert. 2005a. An
Ngram-based Statistical Machine Translation De-
coder. In Proceedings of INTERSPEECH05, pages
3185?3188.
J.M. Crego, M.R. Costa-juss?, J.B. Mari?o, and J.A.R.
Fonollosa. 2005b. Ngram-based versus phrase-
based statistical machine translation. In Proc. of the
IWSLT 2005, pages 177?184.
S. DeNeefe, K. Knight, W. Wang, and D. Marcu. 2007.
What can syntax-based MT learn from phrase-based
MT? In Proceedings of EMNLP-CoNLL 2007,
pages 755?763.
J. Eisner. 2003. Learning non-isomorphic tree map-
pings for machine translation. In Proceedings of
ACL 2003 (companion volume), pages 205?208.
N. Habash and F. Sadat. 2006. Arabic preprocessing
schemes for statistical machine translation. In Pro-
ceedings of HLT/NAACL 2006, pages 49?52.
Ph. Koehn, F.J. Och, and D. Marcu. 2003. Statistical
phrase-based machine translation. In Proceedings of
HLT-NAACL 2003, pages 48?54.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: open-source toolkit
for statistical machine translation. In Proceedings
of ACL 2007, pages 177?180.
P. Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP 2004, pages 388?395.
S. Kumar and W. Byrne. 2004. Minimum bayes-risk
decoding for statistical machine translation. In Pro-
ceedings of HLT/NAACL 2004.
D. Marcu and W. Wong. 2002. A Phrase-based, Joint
Probability Model for Statistical Machine Transla-
tion. In Proceedings of EMNLP02, pages 133?139.
J. B. Mari?o, R. E. Banchs, J. M. Crego, A. de Gispert,
P. Lambert, J. A. R. Fonollosa, and M. R. Costa-
juss?. 2006. N-gram based machine translation.
Computational Linguistics, 32(4):527?549, Decem-
ber.
I.D. Melamed. 2004. Statistical machine translation by
parsing. In Proceedings of ACL 2004, pages 111?
114.
F. J. Och and H. Ney. 2002. Discriminative Train-
ing and Maximum Entropy Models for Statistical
Machine Translation. In Proceedings of ACL 2002,
pages 295?302.
F. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?51.
F. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Compu-
tational Linguistics, 30(4):417?449.
M. Povovic, A. de Gispert, D. Gupta, P. Lambert, J.B.
Mari?o, M. Federico, H. Ney, and R. Banchs. 2006.
Morpho-syntactic information for automatic error
analysis of statistic machine translation output. In
In Proceeding of the HLT-NAACL Workshop on Sta-
tistical Machine Translation, pages 1?6.
M. Steedman. 1999. Alternative quantifier scope in
ccg. In Proceedings of ACL 1999, pages 301?308.
A. Venugopal, A. Zollmann, and S. Vogel. 2007.
An Efficient Two-Pass Approach to Synchronous-
CFG Driven Statistical MT. In Proceedings of
HLT/NAACL 2007, pages 500?507.
D. Vilar, J. Xu, L. F. D?Haro, and H. Ney. 2006. Error
Analysis of Machine Translation Output. In Pro-
ceedings of LREC?06, pages 697?702.
K. Yamada and K. Knight. 2001. A syntax-based sta-
tistical translation model. In Proceedings of ACL
2001, pages 523?530.
A. Zollmann and A. Venugopal. 2006. Syntax aug-
mented machine translation via chart parsing. In
Proceedings of NAACL 2006.
A. Zollmann, A. Venugopal, F. Och, and J. Ponte.
2008. Systematic comparison of Phrase-based, Hi-
erarchical and Syntax-Augmented Statistical mt. In
Proceedings of Coling 2008, pages 1145?1152.
432
Proceedings of the Workshop on Statistical Machine Translation, pages 142?145,
New York City, June 2006. c?2006 Association for Computational Linguistics
TALP Phrase-based statistical translation system for European language
pairs
Marta R. Costa-jussa`
Patrik Lambert
Jose? B. Marin?o
Josep M. Crego
Maxim Khalilov
Jose? A. R. Fonollosa
Department of Signal Theory and Communications
TALP Research Center (UPC)
Barcelona 08034, Spain
(mruiz,jmcrego,agispert,lambert,khalilov,canton,adrian, rbanchs)@gps.tsc.upc.edu
Adria` de Gispert
Rafael E. Banchs
Abstract
This paper reports translation results for
the ?Exploiting Parallel Texts for Statis-
tical Machine Translation? (HLT-NAACL
Workshop on Parallel Texts 2006). We
have studied different techniques to im-
prove the standard Phrase-Based transla-
tion system. Mainly we introduce two re-
ordering approaches and add morphologi-
cal information.
1 Introduction
Nowadays most Statistical Machine Translation
(SMT) systems use phrases as translation units. In
addition, the decision rule is commonly modelled
through a log-linear maximum entropy framework
which is based on several feature functions (in-
cluding the translation model), hm. Each feature
function models the probability that a sentence e in
the target language is a translation of a given sen-
tence f in the source language. The weights, ?i,
of each feature function are typically optimized to
maximize a scoring function. It has the advantage
that additional features functions can be easily in-
tegrated in the overall system.
This paper describes a Phrase-Based system
whose baseline is similar to the system in Costa-
jussa` and Fonollosa (2005). Here we introduce
two reordering approaches and add morphological
information. Translation results for all six trans-
lation directions proposed in the shared task are
presented and discussed. More specifically, four
different languages are considered: English (en),
Spanish (es), French (fr) and German (de); and
both translation directions are considered for the
pairs: EnEs, EnFr, and EnDe. The paper is orga-
nized as follows: Section 2 describes the system;
0This work has been supported by the European Union
under grant FP6-506738 (TC-STAR project) and the TALP
Research Center (under a TALP-UPC-Recerca grant).
Section 3 presents the shared task results; and, fi-
nally, in Section 4, we conclude.
2 System Description
This section describes the system procedure fol-
lowed for the data provided.
2.1 Alignment
Given a bilingual corpus, we use GIZA++ (Och,
2003) as word alignment core algorithm. During
word alignment, we use 50 classes per language
estimated by ?mkcls?, a freely-available tool along
with GIZA++. Before aligning we work with low-
ercase text (which leads to an Alignment Error
Rate reduction) and we recover truecase after the
alignment is done.
In addition, the alignment (in specific pairs of
languages) was improved using two strategies:
Full verb forms The morphology of the verbs
usually differs in each language. Therefore, it is
interesting to classify the verbs in order to address
the rich variety of verbal forms. Each verb is re-
duced into its base form and reduced POS tag as
explained in (de Gispert, 2005). This transforma-
tion is only done for the alignment, and its goal
is to simplify the work of the word alignment im-
proving its quality.
Block reordering (br) The difference in word
order between two languages is one of the most
significant sources of error in SMT. Related works
either deal with reordering in general as (Kanthak
et al, 2005) or deal with local reordering as (Till-
mann and Ney, 2003). We report a local reorder-
ing technique, which is implemented as a pre-
processing stage, with two applications: (1) to im-
prove only alignment quality, and (2) to improve
alignment quality and to infer reordering in trans-
lation. Here, we present a short explanation of the
algorithm, for further details see Costa-jussa` and
Fonollosa (2006).
142
Figure 1: Example of an Alignment Block, i.e. a
pair of consecutive blocks whose target translation
is swapped
This reordering strategy is intended to infer the
most probable reordering for sequences of words,
which are referred to as blocks, in order to mono-
tonize current data alignments and generalize re-
ordering for unseen pairs of blocks.
Given a word alignment, we identify those pairs
of consecutive source blocks whose translation is
swapped, i.e. those blocks which, if swapped,
generate a correct monotone translation. Figure 1
shows an example of these pairs (hereinafter called
Alignment Blocks).
Then, the list of Alignment Blocks (LAB) is
processed in order to decide whether two consec-
utive blocks have to be reordered or not. By using
the classification algorithm, see the Appendix, we
divide the LAB in groups (Gn, n = 1 . . . N ). In-
side the same group, we allow new internal com-
bination in order to generalize the reordering to
unseen pairs of blocks (i.e. new Alignment Blocks
are created). Based on this information, the source
side of the bilingual corpora are reordered.
In case of applying the reordering technique for
purpose (1), we modify only the source training
corpora to realign and then we recover the origi-
nal order of the training corpora. In case of using
Block Reordering for purpose (2), we modify all
the source corpora (both training and test), and we
use the new training corpora to realign and build
the final translation system.
2.2 Phrase Extraction
Given a sentence pair and a corresponding word
alignment, phrases are extracted following the cri-
terion in Och and Ney (2004). A phrase (or
bilingual phrase) is any pair of m source words
and n target words that satisfies two basic con-
straints: words are consecutive along both sides
of the bilingual phrase, and no word on either side
of the phrase is aligned to a word out of the phrase.
We limit the maximum size of any given phrase to
7. The huge increase in computational and storage
cost of including longer phrases does not provide
a significant improvement in quality (Koehn et al,
2003) as the probability of reappearance of larger
phrases decreases.
2.3 Feature functions
Conditional and posterior probability (cp, pp)
Given the collected phrase pairs, we estimate the
phrase translation probability distribution by rela-
tive frequency in both directions.
The target language model (lm) consists of an
n-gram model, in which the probability of a trans-
lation hypothesis is approximated by the product
of word n-gram probabilities. As default language
model feature, we use a standard word-based 5-
gram language model generated with Kneser-Ney
smoothing and interpolation of higher and lower
order n-grams (Stolcke, 2002).
The POS target language model (tpos) con-
sists of an N-gram language model estimated over
the same target-side of the training corpus but us-
ing POS tags instead of raw words.
The forward and backwards lexicon mod-
els (ibm1, ibm1?1) provide lexicon translation
probabilities for each phrase based on the word
IBM model 1 probabilities. For computing the
forward lexicon model, IBM model 1 probabili-
ties from GIZA++ source-to-target algnments are
used. In the case of the backwards lexicon model,
target-to-source alignments are used instead.
The word bonus model (wb) introduces a sen-
tence length bonus in order to compensate the sys-
tem preference for short output sentences.
The phrase bonus model (pb) introduces a con-
stant bonus per produced phrase.
2.4 Decoding
The search engine for this translation system is de-
scribed in Crego et al (2005) which takes into ac-
count the features described above.
Using reordering in the decoder (rgraph) A
highly constrained reordered search is performed
by means of a set of reordering patterns (linguisti-
cally motivated rewrite patterns) which are used to
143
extend the monotone search graph with additional
arcs. See the details in Crego et al (2006).
2.5 Optimization
It is based on a simplex method (Nelder and
Mead, 1965). This algorithm adjusts the log-
linear weights in order to maximize a non-linear
combination of translation BLEU and NIST: 10 ?
log10((BLEU ? 100) + 1) + NIST. The max-
imization is done over the provided development
set for each of the six translation directions under
consideration. We have experimented an improve-
ment in the coherence between all the automatic
figures by integrating two of these figures in the
optimization function.
3 Shared Task Results
3.1 Data
The data provided for this shared task corresponds
to a subset of the official transcriptions of the
European Parliament Plenary Sessions, and it
is available through the shared task website at:
http://www.statmt.org/wmt06/shared-task/.
The development set used to tune the system
consists of a subset (500 first sentences) of the
official development set made available for the
Shared Task.
We carried out a morphological analysis of the
data. The English POS-tagging has been carried
out using freely available TNT tagger (Brants,
2000). In the Spanish case, we have used the
Freeling (Carreras et al, 2004) analysis tool
which generates the POS-tagging for each input
word.
3.2 Systems configurations
The baseline system is the same for all tasks and
includes the following features functions: cp, pp,
lm, ibm1, ibm1?1, wb, pb. The POStag target
language model has been used in those tasks for
which the tagger was available. Table 1 shows the
reordering configuration used for each task.
The Block Reordering (application 2) has been
used when the source language belongs to the Ro-
manic family. The length of the block is lim-
ited to 1 (i.e. it allows the swapping of single
words). The main reason is that specific errors are
solved in the tasks from a Romanic language to
a Germanic language (as the common reorder of
Noun + Adjective that turns into Adjective +
Noun). Although the Block Reordering approach
Task Reordering Configuration
Es2En br2
En2Es br1 + rgraph
Fr2En br2
En2Fr br1 + rgraph
De2En -
En2De -
Table 1: Additional reordering models for each
task: br1 (br2) stands for Block Reordering ap-
plication 1 (application 2); and rgraph refers to
the reordering integrated in the decoder
does not depend on the task, we have not done
the corresponding experiments to observe its ef-
ficiency in all the pairs used in this evaluation.
The rgraph has been applied in those cases
where: we do not use br2 (there is no sense in
applying them simultaneously); and we have the
tagger for the source language model available.
In the case of the pair GeEn, we have not exper-
imented any reordering, we left the application of
both reordering approaches as future work.
3.3 Discussion
Table 2 presents the BLEU scores evaluated on the
test set (using TRUECASE) for each configuration.
The official results were slightly better because a
lowercase evaluation was used, see (Koehn and
Monz, 2006).
For both, Es2En and Fr2En tasks, br helps
slightly. The improvement of the approach de-
pends on the quality of the alignment. The better
alignments allow to extract higher quality Align-
ment Blocks (Costa-jussa` and Fonollosa, 2006).
The En2Es task is improved when adding both
br1 and rgraph. Similarly, the En2Fr task seems to
perform fairly well when using the rgraph. In this
case, the improvement of the approach depends on
the quality of the alignment patterns (Crego et al,
2006). However, it has the advantage of delay-
ing the final decision of reordering to the overall
search, where all models are used to take a fully
informed decision.
Finally, the tpos does not help much when trans-
lating to English. It is not surprising because it was
used in order to improve the gender and number
agreement, and in English there is no need. How-
ever, in the direction to Spanish, the tpos added
to the corresponding reordering helps more as the
Spanish language has gender and number agree-
ment.
144
Task Baseline +tpos +rc +tpos+rc
Es2En 29.08 29.08 29.89 29.98
En2Es 27.73 27.66 28.79 28.99
Fr2En 27.05 27.06 27.43 27.23
En2Fr 26.16 - 27.80 -
De2En 21.59 21.33 - -
En2De 15.20 - - -
Table 2: Results evaluated using TRUECASE on
the test set for each conguration: rc stands for
Reordering Conguration and refers to Table 1.
The bold results were the congurations submit-
ted.
4 Conclusions
Reordering is important when using a Phrase-
Based system. Although local reordering is sup-
posed to be included in the phrase structure, per-
forming local reordering improves the translation
quality. In fact, local reordering, provided by the
reordering approaches, allows for those general-
izations which phrases could not achieve. Re-
ordering in the DeEn task is left as further work.
References
T. Brants. 2000. Tnt - a statistical part-of-speech tag-
ger. Proceedings of the Sixth Applied Natural Lan-
guage Processing.
X. Carreras, I. Chao, L. Padro?, and M. Padro?. 2004.
Freeling: An open-source suite of language analyz-
ers. 4th Int. Conf. on Language Resources and Eval-
uation, LREC?04.
M. R. Costa-jussa` and J.A.R. Fonollosa. 2005. Im-
proving the phrase-based statistical translation by
modifying phrase extraction and including new fea-
tures. Proceedings of the ACL Workshop on Build-
ing and Using Parallel Texts: Data-Driven Machine
Translation and Beyond.
M. R. Costa-jussa` and J.A.R. Fonollosa. 2006. Using
reordering in statistical machine translation based on
alignment block classification. Internal Report.
J.M. Crego, J. Marin?o, and A. de Gispert. 2005.
An Ngram-based statistical machine translation de-
coder. Proc. of the 9th Int. Conf. on Spoken Lan-
guage Processing, ICSLP?05.
J. M. Crego, A. de Gispert, P. Lambert, M. R.
Costa-jussa`, M. Khalilov, J. Marin?o, J. A. Fonol-
losa, and R. Banchs. 2006. Ngram-based smt
system enhanced with reordering patterns. HLT-
NAACL06 Workshop on Building and Using Paral-
lel Texts: Data-Driven Machine Translation and Be-
yond, June.
A. de Gispert. 2005. Phrase linguistic classification for
improving statistical machine translation. ACL 2005
Students Workshop, June.
S. Kanthak, D. Vilar, E. Matusov, R. Zens, and H.
Ney. 2005. Novel reordering approaches in phrase-
based statistical machine translation. Proceedings
of the ACL Workshop on Building and Using Par-
allel Texts: Data-Driven Machine Translation and
Beyond, pages 167?174, June.
P. Koehn and C. Monz. 2006. Manual and automatic
evaluation of machine translation between european
languages. June.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. Proc. of the Human Lan-
guage Technology Conference, HLT-NAACL?2003,
May.
J.A. Nelder and R. Mead. 1965. A simplex method
for function minimization. The Computer Journal,
7:308?313.
F.J. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Compu-
tational Linguistics, 30(4):417?449, December.
F.J. Och. 2003. Giza++ software. http://www-
i6.informatik.rwth-aachen.de/?och/ soft-
ware/giza++.html.
A. Stolcke. 2002. Srilm - an extensible language mod-
eling toolkit. Proc. of the 7th Int. Conf. on Spoken
Language Processing, ICSLP?02, September.
C. Tillmann and H. Ney. 2003. Word reordering and
a dynamic programming beam search algorithm for
statistical machine translation. Computational Lin-
guistics, 29(1):97?133, March.
A Appendix
Here we describe the classification algorithm used
in Section 1.
1. Initialization: set n? 1 and LAB ? ? LAB.
2. Main part: while LAB ? is not empty do
? Gn = {(?k, ?k)} where (?k, ?k) is any
element of LAB ?, i.e. ?k is the first
block and ?k is the second block of the
Alignment Block k of the LAB ?.
? Recursively, move elements (?i, ?i)
from LAB? to Gn if there is an element
(?j , ?j) ? Gn such that ?i = ?j or
?i = ?j
? Increase n (i.e. n? n + 1)
3. Ending: For each Gn, construct the two sets
An and Bn which consists on the first and
second element of the pairs in Gn, respec-
tively.
145
Proceedings of the Workshop on Statistical Machine Translation, pages 162?165,
New York City, June 2006. c?2006 Association for Computational Linguistics
N-gram-based SMT System Enhanced with Reordering Patterns
Josep M. Crego
Marta R. Costa-jussa`
Jose? B. Marin?o
Adria` de Gispert
Maxim Khalilov
Jose? A. R. Fonollosa
Department of Signal Theory and Communications
TALP Research Center (UPC)
Barcelona 08034, Spain
{jmcrego,agispert,lambert,mruiz,khalilov,rbanchs,canton,adrian}@gps.tsc.upc.edu
Patrik Lambert
Rafael E. Banchs
Abstract
This work presents translation results for
the three data sets made available in the
shared task ?Exploiting Parallel Texts for
Statistical Machine Translation? of the
HLT-NAACL 2006 Workshop on Statisti-
cal Machine Translation. All results pre-
sented were generated by using the N-
gram-based statistical machine translation
system which has been enhanced from the
last year?s evaluation with a tagged target
language model (using Part-Of-Speech
tags). For both Spanish-English transla-
tion directions and the English-to-French
translation task, the baseline system al-
lows for linguistically motivated source-
side reorderings.
1 Introduction
The statistical machine translation approach used
in this work implements a log-linear combination
of feature functions along with a translation model
which is based on bilingual n-grams (de Gispert and
Marin?o, 2002).
This translation model differs from the well
known phrase-based translation approach (Koehn
et al, 2003) in two basic issues: first, training data
is monotonously segmented into bilingual units; and
second, the model considers n-gram probabilities in-
stead of relative frequencies. This translation ap-
proach is described in detail in (Marin?o et al, 2005).
For those translation tasks with Spanish or En-
glish as target language, an additional tagged (us-
ing POS information) target language model is used.
Additionally a reordering strategy that includes POS
information is described and evaluated.
Translation results for all six translation directions
proposed in the shared task are presented and dis-
cussed. Both translation directions are considered
for the pairs: English-Spanish, English-French,
and English-German.
The paper is structured as follows: Section 2
briefly outlines the baseline system. Section 3 de-
scribes in detail the implemented POS-based re-
ordering strategy. Section 4 presents and discusses
the shared task results and, finally, section 5 presents
some conclusions and further work.
2 Baseline N-gram-based SMT System
As already mentioned, the translation model used
here is based on bilingual n-grams. It actually con-
stitutes a language model of bilingual units, referred
to as tuples, which approximates the joint probabil-
ity between source and target languages by using
bilingual n-grams (de Gispert and Marin?o, 2002).
Tuples are extracted from a word-to-word aligned
corpus according to the following two constraints:
first, tuple extraction should produce a monotonic
segmentation of bilingual sentence pairs; and sec-
ond, no smaller tuples can be extracted without vi-
olating the previous constraint. See (Crego et al,
2004) for further details.
For all experiments presented here, the translation
model consisted of a 4-gram language model of tu-
ples. In addition to this bilingual n-gram translation
model, the baseline system implements a log linear
combination of five feature functions.
162
These five additional models are:
? A target language model. 5-gram of the target
side of the bilingual corpus.
? A word bonus. Based on the number of tar-
get words in the partial-translation hypothesis,
to compensate the LM preference for short sen-
tences.
? A Source-to-target lexicon model. Based on
IBM Model 1 lexical parameters(Brown et al,
1993), providing a complementary probability
for each tuple in the translation table. These
parameters are obtained from source-to-target
alignments.
? A Target-to-source lexicon model. Analo-
gous to the previous feature, but obtained from
target-to-source alignments.
? A Tagged (POS) target language model. This
feature implements a 5-gram language model
of target POS-tags. In this case, each trans-
lation unit carried the information of its target
side POS-tags, though this is not used for trans-
lation model estimation (only in order to eval-
uate the target POS language model at decod-
ing time). Due to the non-availability of POS-
taggers for French and German, it was not pos-
sible to incorporate this feature in all transla-
tion tasks considered, being only used for those
translation tasks with Spanish and English as
target languages.
The search engine for this translation system is
described in (Crego et al, 2005) and implements
a beam-search strategy based on dynamic program-
ming, taking into account all feature functions de-
scribed above, along with the bilingual n-gram trans-
lation model. Monotone search is performed, in-
cluding histogram and threshold pruning and hy-
pothesis recombination.
An optimization tool, which is based on a down-
hill simplex method was developed and used for
computing log-linear weights for each of the feature
functions. This algorithm adjusts the weights so that
a non-linear combination of BLEU and NIST scores
is maximized over the development set for each of
the six translation directions considered.
This baseline system is actually very similar to
the system used for last year?s shared task ?Exploit-
ing Parallel Texts for Statistical Machine Transla-
tion? of ACL?05 Workshop on Building and Us-
ing Parallel Texts: Data-Driven Machine Translation
and Beyond (Banchs et al, 2005), whose results
are available at: http://www.statmt.org/wpt05/
mt-shared-task/. A more detailed description of
the system can be found in (2005).
The tools used for POS-tagging were Freel-
ing (Carreras et al, 2004) for Spanish and
TnT (Brants, 2000) for English. All language mod-
els were estimated using the SRI language mod-
eling toolkit. Word-to-word alignments were ex-
tracted with GIZA++. Improvements in word-to-
word alignments were achieved through verb group
classification as described in (de Gispert, 2005).
3 Reordering Framework
In this section we outline the reordering framework
used for the experiments (Crego and Marin?o, 2006).
A highly constrained reordered search is performed
by means of a set of reordering patterns (linguisti-
cally motivated rewrite patterns) which are used to
extend the monotone search graph with additional
arcs.
To extract patterns, we use the word-to-word
alignments (the union of both alignment directions)
and source-side POS tags. The main procedure con-
sists of identifying all crossings produced in the
Figure 1: Reordering patterns are extracted using
word-to-word alignments. The generalization power
is achieved through the POS tags. Three instances of
different patterns are extracted using the sentences
in the example.
163
word-to-word alignments. Once a crossing has been
detected, its source POS tags and alignments are
used to account for a new instance of pattern. The
target side of a pattern (source-side positions after
reordering), is computed using the original order
of the target words to which the source words are
aligned. See figure 1 for a clarifying example of
pattern extraction.
The monotone search graph is extended with re-
orderings following the patterns found in training.
The procedure identifies first the sequences of words
in the input sentence that match any available pat-
tern. Then, each of the matchings implies the ad-
dition of an arc into the search graph (encoding the
reordering learnt in the pattern). However, this ad-
dition of a new arc is not performed if a translation
unit with the same source-side words already exists
in the training. Figure 2 shows an example of the
procedure.
Figure 2: Three additional arcs have been added
to the original monotone graph (bold arcs) given
the reordering patterns found matching any of the
source POS tags sequence.
Once the search graph is built, the decoder tra-
verses the graph looking for the best translation.
Hence, the winner hypothesis is computed using
all the available information (the whole SMT mod-
els). The reordering strategy is additionally sup-
ported by a 5-gram language model of reordered
source POS-tags. In training, POS-tags are re-
ordered according with the extracted reordering pat-
terns and word-to-word links. The resulting se-
quence of source POS-tags are used to train the n-
gram LM.
Notice that this reordering framework has only
been used for some translation tasks (Spanish-
to-English, English-to-Spanish and English-to-
French). The reason is double: first, because we
did not have available a French POS-tagger. Second,
because the technique used to learn reorderings (de-
tailed below) does not seem to apply for language
pairs like German-English, because the agglutina-
tive characteristic of German (words are formed by
joining morphemes together).
Table 1: BLEU, NIST and mWER scores (com-
puted using two reference translations) obtained for
both translation directions (Spanish-to-English and
English-to-Spanish).
Conf BLEU NIST mWER
Spanish-to-English
base 55.23 10.69 34.40
+rgraph 55.59 10.70 34.23
+pos 56.39 10.75 33.75
English-to-Spanish
base 48.03 9.84 41.18
+rgraph 48.53 9.81 41.15
+pos 48.91 9.91 40.29
Table 1 shows the improvement of the original
baseline system described in section 2 (base), en-
hanced using reordering graphs (+rgraph) and pro-
vided the tagged-source language model (+pos).
The experiments in table 1 were not carried out over
the official corpus of this shared task. The Spanish-
English corpus of the TC-Star 2005 Evaluation was
used. Due to the high similarities between both cor-
pus (this shared task corpus consists of a subset of
the whole corpus used in the TC-Star 2005 Evalua-
tion), it makes sense to think that comparable results
would be obtained.
It is worth mentioning that the official corpus of
the shared task (HLT-NAACL 2006) was used when
building and tuning the present shared task system.
4 Shared Task Results
The data provided for this shared task corresponds
to a subset of the official transcriptions of the Euro-
pean Parliament Plenary Sessions. The development
set used to tune the system consists of a subset (500
first sentences) of the official development set made
available for the Shared Task.
164
Table 2 presents the BLEU, NIST and mWER
scores obtained for the development-test data set.
The last column shows whether the target POS lan-
guage model feature was used or not. Computed
scores are case sensitive and compare to one refer-
ence translation. Tasks in bold were conducted al-
lowing for the reordering framework. For French-
to-English task, block reordering strategy was used,
which is described in (Costa-jussa` et al, 2006). As it
can be seen, for the English-to-German task we did
not use any of the previous enhancements.
Table 2: Translation results
Task BLEU NIST mWER tPOS
en ? es 29.50 7.32 58.95 yes
es ? en 30.29 7.51 57.72 yes
en ? fr 30.23 7.40 59.76 no
fr ? en 30.21 7.61 56.97 yes
en ? de 17.40 5.61 71.18 no
de ? en 23.78 6.70 65.83 yes
Important differences can be observed between
the German-English and the rest of translation tasks.
They result from the greater differences in word
order present in this language pair (the German-
English results are obtained under monotone decod-
ing conditions). Also because the greater vocabulary
of words of German, which increases sparseness in
any task where German is envolved. As expected,
differences in translation accuracy between Spanish-
English and French-English are smaller.
5 Conclusions and Further Work
As it can be concluded from the presented results,
although in principle some language pairs (Spanish-
English-French) seem to have very little need for re-
orderings (due to their similar word order), the use
of linguistically-based reorderings proves to be use-
ful to improve translation accuracy.
Additional work is to be conducted to allow for
reorderings when translating from/to German.
6 Acknowledgments
This work was partly funded by the European Union
under the integrated project TC-STAR1: Technology
and Corpora for Speech to Speech Translation (IST-
2002-FP6-506738) and the European Social Fund.
1http://www.tc-star.org
References
R. E. Banchs, J. M. Crego, A. de Gispert, P. Lambert, and
J. B. Marin?o. 2005. Statistical machine translation of
euparl data by using bilingual n-grams. Proc. of the
ACL Workshop on Building and Using Parallel Texts
(ACL?05/Wkshp), pages 67?72, June.
T. Brants. 2000. TnT ? a statistical part-of-speech tag-
ger. In Proc. of the Sixth Applied Natural Language
Processing (ANLP-2000), Seattle, WA.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.
1993. The mathematics of statistical machine transla-
tion. Computational Linguistics, 19(2):263?311.
X. Carreras, I. Chao, L. Padro?, and M. Padro?. 2004.
Freeling: An open-source suite of language analyzers.
4th Int. Conf. on Language Resources and Evaluation,
LREC?04, May.
M.R. Costa-jussa`, J.M. Crego, A. de Gispert, P. Lam-
bert, M. Khalilov, R. Banchs, J.B. Marin?o, and J.A.R.
Fonollosa. 2006. Talp phrase-based statistical transla-
tion system for european language pairs. Proc. of the
HLT/NAACL Workshop on Statistical Machine Trans-
lation, June.
J. M. Crego and J. Marin?o. 2006. A reordering frame-
work for statistical machine translation. Internal Re-
port.
J. M. Crego, J. Marin?o, and A. de Gispert. 2004. Finite-
state-based and phrase-based statistical machine trans-
lation. Proc. of the 8th Int. Conf. on Spoken Language
Processing, ICSLP?04, pages 37?40, October.
J. M. Crego, J. Marin?o, and A. Gispert. 2005. An ngram-
based statistical machine translation decoder. Proc. of
the 9th European Conference on Speech Communica-
tion and Technology, Interspeech?05, September.
A. de Gispert and J. Marin?o. 2002. Using X-grams
for speech-to-speech translation. Proc. of the 7th
Int. Conf. on Spoken Language Processing, ICSLP?02,
September.
A. de Gispert. 2005. Phrase linguistic classification and
generalization for improving statistical machine trans-
lation. Proc. of the ACL Student Research Workshop
(ACL?05/SRW), June.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statisti-
cal phrase-based translation. Proc. of the Human
Language Technology Conference, HLT-NAACL?2003,
May.
J.B. Marin?o, R Banchs, J.M. Crego, A. de Gispert,
P. Lambert, M. R. Costa-jussa`, and J.A.R. Fonollosa.
2005. Bilingual n?gram statistical machine transla-
tion. Proc. of the MT Summit X, September.
165
Proceedings of the Second Workshop on Statistical Machine Translation, pages 167?170,
Prague, June 2007. c?2007 Association for Computational Linguistics
Ngram-based statistical machine translation enhanced with multiple
weighted reordering hypotheses
Marta R. Costa-jussa`, Josep M. Crego, Patrik Lambert, Maxim Khalilov
Jose? A. R. Fonollosa, Jose? B. Marin?o and Rafael E. Banchs
Department of Signal Theory and Communications
TALP Research Center (UPC)
Barcelona 08034, Spain
(mruiz,jmcrego,lambert,khalilov,adrian,canton,rbanchs)@gps.tsc.upc.edu
Abstract
This paper describes the 2007 Ngram-based sta-
tistical machine translation system developed at
the TALP Research Center of the UPC (Uni-
versitat Polite`cnica de Catalunya) in Barcelona.
Emphasis is put on improvements and extensions
of the previous years system, being highlighted
and empirically compared. Mainly, these include
a novel word ordering strategy based on: (1) sta-
tistically monotonizing the training source cor-
pus and (2) a novel reordering approach based
on weighted reordering graphs. In addition, this
system introduces a target language model based
on statistical classes, a feature for out-of-domain
units and an improved optimization procedure.
The paper provides details of this system par-
ticipation in the ACL 2007 SECOND WORK-
SHOP ON STATISTICAL MACHINE TRANSLA-
TION. Results on three pairs of languages are
reported, namely from Spanish, French and Ger-
man into English (and the other way round) for
both the in-domain and out-of-domain tasks.
1 Introduction
Based on estimating a joint-probability model between
the source and the target languages, Ngram-based SMT
has proved to be a very competitive alternatively to
phrase-based and other state-of-the-art systems in previ-
ous evaluation campaigns, as shown in (Koehn and Monz,
2005; Koehn and Monz, 2006).
Given the challenge of domain adaptation, efforts have
been focused on improving strategies for Ngram-based
SMT which could generalize better. Specifically, a novel
reordering strategy is explored. It is based on extending
the search by using precomputed statistical information.
Results are promising while keeping computational ex-
penses at a similar level as monotonic search. Addition-
ally, a bonus for tuples from the out-of-domain corpus is
introduced, as well as a target language model based on
statistical classes. One of the advantages of working with
statistical classes is that they can easily be used for any
pair of languages.
This paper is organized as follows. Section 2 briefly
reviews last year?s system, including tuple definition and
extraction, translation model and feature functions, de-
coding tool and optimization criterion. Section 3 delves
into the word ordering problem, by contrasting last year
strategy with the novel weighted reordering input graph.
Section 4 focuses on new features: both tuple-domain
bonus and target language model based on classes. Later
on, Section 5 reports on all experiments carried out for
WMT 2007. Finally, Section 6 sums up the main conclu-
sions from the paper and discusses future research lines.
2 Baseline N-gram-based SMT System
The translation model is based on bilingual n-grams. It
actually constitutes a language model of bilingual units,
referred to as tuples, which approximates the joint proba-
bility between source and target languages by using bilin-
gual n-grams.
Tuples are extracted from a word-to-word aligned cor-
pus according to the following two constraints: first, tu-
ple extraction should produce a monotonic segmentation
of bilingual sentence pairs; and second, no smaller tuples
can be extracted without violating the previous constraint.
For all experiments presented here, the translation
model consisted of a 4-gram language model of tuples.
In addition to this bilingual n-gram translation model, the
baseline system implements a log linear combination of
four feature functions. These four additional models are:
a target language model (a 5-gram model of words);
a word bonus; a source-to-target lexicon model and a
target-to-source lexicon model, both features provide a
complementary probability for each tuple in the transla-
tion table.
The decoder (called MARIE) for this translation sys-
167
tem is based on a beam search 1.
This baseline system is actually the same system used
for the first shared task ?Exploiting Parallel Texts for Sta-
tistical Machine Translation? of the ACL 2005 Work-
shop on Building and Using Parallel Texts: Data-Driven
Machine Translation and Beyond. A more detailed de-
scription of the system can be found in (Marin?o et al,
2006).
3 Baseline System Enhanced with a
Weighted Reordering Input Graph
This section briefly describes the statistical machine re-
ordering (SMR) technique. Further details on the archi-
tecture of SMR system can be found on (Costa-jussa` and
Fonollosa, 2006).
3.1 Concept
The SMR system can be seen as a SMT system which
translates from an original source language (S) to a re-
ordered source language (S?), given a target language
(T). The SMR technique works with statistical word
classes (Och, 1999) instead of words themselves (partic-
ularly, we have used 200 classes in all experiments).
Figure 1: SMR approach in the (A) training step (B) in
the test step (the weight of each arch is in brackets).
3.2 Using SMR technique to improve SMT training
The original source corpus S is translated into the re-
ordered source corpus S? with the SMR system. Fig-
ure 1 (A) shows the corresponding block diagram. The
reordered training source corpus and the original training
target corpus are used to build the SMT system.
The main difference here is that the training is com-
puted with the S?2T task instead of the S2T original task.
Figure 2 (A) shows an example of the alignment com-
puted on the original training corpus. Figure 2 (B) shows
the same links but with the source training corpus in a
different order (this training corpus comes from the SMR
output). Although, the quality in alignment is the same,
the tuples that can be extracted change (notice that the
tuple extraction is monotonic). We are able to extract
1http://gps-tsc.upc.es/veu/soft/soft/marie/
smaller tuples which reduces the translation vocabulary
sparseness. These new tuples are used to build the SMT
system.
Figure 2: Alignment and tuple extraction (A) original
training source corpus (B) reordered training source cor-
pus.
3.3 Using SMR technique to generate multiple
weighted reordering hypotheses
The SMR system, having its own search, can generate ei-
ther an output 1-best or an output graph. In decoding, the
SMR technique generates an output graph which is used
as an input graph by the SMT system. Figure 1 (B) shows
the corresponding block diagram in decoding: the SMR
output graph is given as an input graph to the SMT sys-
tem. Hereinafter, this either SMR output graph or SMT
input graph will be referred to as (weighted) reordering
graph. The monotonic search in the SMT system is ex-
tended with reorderings following this reordering graph.
This reordering graph has multiple paths and each path
has its own weight. This weight is added as a feature
function in the log-linear framework. Figure 3 shows the
weighted reordering graph.
The main difference with the reordering technique for
WMT06 (Crego et al, 2006) lies in (1) the tuples are ex-
tracted from the word alignment between the reordered
source training corpus and the given target training cor-
pus and (2) the graph structure: the SMR graph provides
weights for each reordering path.
4 Other features and functionalities
In addition to the novel reordering strategy, we consider
two new features functions.
4.1 Target Language Model based on Statistical
Classes
This feature implements a 5-gram language model of tar-
get statistical classes (Och, 1999). This model is trained
by considering statistical classes, instead of words, for
168
Figure 3: Weighted reordering input graph for SMT sys-
tem.
the target side of the training corpus. Accordingly, the tu-
ple translation unit is redefined in terms of a triplet which
includes: a source string containing the source side of
the tuple, a target string containing the target side of the
tuple, and a class string containing the statistical classes
corresponding to the words in the target strings.
4.2 Bonus for out-of-domain tuples
This feature adds a bonus to those tuples which comes
from the training of the out-of-domain task. This feature
is added when optimizing with the development of the
out-of-domain task.
4.3 Optimization
Finally, a n-best re-ranking strategy is implemented
which is used for optimization purposes just as pro-
posed in http://www.statmt.org/jhuws/. This procedure
allows for a faster and more efficient adjustment of model
weights by means of a double-loop optimization, which
provides significant reduction of the number of transla-
tions that should be carried out. The current optimization
procedure uses the Simplex algorithm.
5 Shared Task Framework
5.1 Data
The data provided for this shared task corresponds to a
subset of the official transcriptions of the European Par-
liament Plenary Sessions 2. Additionally, there was avail-
able a smaller corpus called News-Commentary. For all
tasks and domains, our training corpus was the catenation
of both.
2http://www.statmt.org/wmt07/shared-task/
5.2 Processing details
Word Alignment. The word alignment is automati-
cally computed by using GIZA++ 3 in both directions,
which are symmetrized by using the union operation. In-
stead of aligning words themselves, stems are used for
aligning. Afterwards case sensitive words are recovered.
Spanish Morphology Reduction. We implemented a
morphology reduction of the Spanish language as a pre-
processing step. As a consequence, training data sparse-
ness due to Spanish morphology was reduced improving
the performance of the overall translation system. In par-
ticular, the pronouns attached to the verb were separated
and contractions as del or al are splited into de el or a
el. As a post-processing, in the En2Es direction we used
a POS target language model as a feature (instead of the
target language model based on classes) that allowed to
recover the segmentations (de Gispert, 2006).
Language Model Interpolation. In other to better
adapt the system to the out-of-domain condition, the
target language model feature was built by combining
two 5-gram target language models (using SRILM 4).
One was trained from the EuroParl training data set, and
the other from the available, but much smaller, news-
commentary data set. The combination weights for the
EuroParl and news-commentary language models were
empirically adjusted by following a minimum perplexity
criterion. A relative perplexity reduction around 10-15%
respect to original EuroParl language model was achieved
in all the tasks.
5.3 Experiments and Results
The main difference between this year?s and last year?s
systems are: the amount of data provided; the word align-
ment; the Spanish morphology reduction; the reordering
technique; the extra target language model based on sta-
tistical classes (except for the En2Es); and the bonus for
the out-of-domain task (only for the En2Es task).
Among them, the most important is the reordering
technique. That is why we provide a fair comparison be-
tween the reordering patterns (Crego and Marin?o, 2006)
technique and the SMR reordering technique. Table 1
shows the system described above using either reorder-
ing patterns or the SMR technique. The BLEU calcula-
tion was case insensitive and sensitive to tokenization.
Table 2 presents the BLEU score obtained for the 2006
test data set comparing last year?s and this year?s systems.
The computed BLEU scores are case insensitive, sensi-
tive to tokenization and uses one translation reference.
The improvement in BLEU results shown from UPC-jm
3http://www.fjoch.com/GIZA++.html
4http://www.speech.sri.com/projects/srilm/
169
Task Reordering patterns SMR technique
es2en 31.21 33.34
en2es 31.67 32.33
Table 1: BLEU comparison: reordering patterns vs. SMR
technique.
Task UPC-jm 2006 UPC 2007
in-d out-d in-d out-d
es2en 31.01 27.92 33.34 32.85
en2es 30.44 25.59 32.33 33.07
fr2en 30.42 21.79 32.44 26.93
en2fr 31.75 23.30 32.30 27.03
de2en 24.43 17.57 26.54 21.63
en2de 17.73 10.96 19.74 15.06
Table 2: BLEU scores for each of the six translation di-
rections considered (computed over 2006 test set) com-
paring last year?s and this year?s system results (in-
domain and out-domain).
2006 Table 2 and reordering patterns Table 1 in the En-
glish/Spanish in-domain task comes from the combina-
tion of: the additional corpora, the word alignment, the
Spanish morphology reduction and the extra target lan-
guage model based on classes (only in the Es2En direc-
tion).
6 Conclusions and Further Work
This paper describes the UPC system for the WMT07
Evaluation. In the framework of Ngram-based system, a
novel reordering strategy which can be used for any pair
of languages has been presented and it has been showed
to significantly improve translation performance. Ad-
ditionally two features has been added to the log-lineal
scheme: the target language model based on classes and
the bonus for out-of-domain translation units.
7 Acknowledgments
This work has been funded by the European Union un-
der the TC-STAR project (IST-2002-FP6-506738) and
the Spanish Government under grant TEC2006-13964-
C03 (AVIVAVOZ project).
References
M.R. Costa-jussa` and J.A.R. Fonollosa. 2006. Statistical
machine reordering. In EMNLP, pages 71?77, Sydney,
July. ACL.
J.M. Crego and J.B. Marin?o. 2006. Reordering experi-
ments for n-gram-based smt. In SLT, pages 242?245,
Aruba.
Josep M. Crego, Adria` de Gispert, Patrik Lambert,
Marta R. Costa-jussa`, Maxim Khalilov, Rafael Banchs,
Jose? B. Marin?o, and Jose? A. R. Fonollosa. 2006. N-
gram-based smt system enhanced with reordering pat-
terns. In WMT, pages 162?165, New York City, June.
ACL.
Adria` de Gispert. 2006. Introducing Linguistic Knowl-
edge in Statistical Machine Translation. Ph.D. thesis,
Universitat Polite`cnica de Catalunya, December.
Philipp Koehn and Christof Monz. 2005. Shared task:
Statistical machine translation between european lan-
guages. In WMT, pages 119?124, Michigan, June.
ACL.
Philipp Koehn and Christof Monz. 2006. Manual and
automatic evaluation of machine translation between
european languages. In WMT, pages 102?121, New
York City, June. ACL.
J.B. Marin?o, R.E. Banchs, J.M. Crego, A. de Gispert,
P. Lambert, J.A.R. Fonollosa, and M.R. Costa-jussa`.
2006. N-gram based machine translation. Computa-
tional Linguistics, 32(4):527?549, December.
F.J. Och. 1999. An efficient method for determin-
ing bilingual word classes. In EACL, pages 71?76,
Bergen, Norway, June.
170
Proceedings of the Third Workshop on Statistical Machine Translation, pages 127?130,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
The TALP-UPC Ngram-based statistical machine translation system for
ACL-WMT 2008
Maxim Khalilov, Adolfo Hern?ndez H., Marta R. Costa-juss?,
Josep M. Crego, Carlos A. Henr?quez Q., Patrik Lambert,
Jos? A. R. Fonollosa, Jos? B. Mari?o and Rafael E. Banchs
Department of Signal Theory and Communications
TALP Research Center (UPC)
Barcelona 08034, Spain
(khalilov, adolfohh, mruiz, jmcrego, carloshq, lambert, adrian, canton, rbanchs)@gps.tsc.upc.edu
Abstract
This paper reports on the participation of the TALP
Research Center of the UPC (Universitat Polit?cnica
de Catalunya) to the ACL WMT 2008 evaluation
campaign.
This year?s system is the evolution of the one we em-
ployed for the 2007 campaign. Main updates and
extensions involve linguistically motivated word re-
ordering based on the reordering patterns technique.
In addition, this system introduces a target language
model, based on linguistic classes (Part-of-Speech),
morphology reduction for an inflectional language
(Spanish) and an improved optimization procedure.
Results obtained over the development and test sets
on Spanish to English (and the other way round)
translations for both the traditional Europarl and
a challenging News stories tasks are analyzed and
commented.
1 Introduction
Over the past few years, the Statistical Machine Transla-
tion (SMT) group of the TALP-UPC has been develop-
ing the Ngram-based SMT system (Mari?o et al, 2006).
In previous evaluation campaigns the Ngram-based ap-
proach has proved to be comparable with the state-of-
the-art phrase-based systems, as shown in Koehn and
Monz(2006), Callison-Burch et al (2007).
We present a summary of the TALP-UPC Ngram-
based SMT system used for this shared task. We dis-
cuss the system configuration and novel features, namely
linguistically motivated reordering technique, which is
applied on the decoding step. Additionally, the reorder-
ing procedure is supported by an Ngram language model
(LM) of reordered source Part-of-Speech tags (POS).
In this year?s evaluation we submitted systems for
Spanish-English and English-Spanish language pairs for
the traditional (Europarl) and challenging (News) tasks.
In each case, we used only the supplied data for each lan-
guage pair for models training and optimization.
This paper is organized as follows. Section 2 briefly
outlines the 2008 system, including tuple definition and
extraction, translation model and additional feature mod-
els, decoding tool and optimization procedure. Section 3
describes the word reordering problem and presents the
proposed technique of reordering patterns learning and
application. Later on, Section 4 reports on the experi-
mental setups of the WMT 2008 evaluation campaign. In
Section 5 we sum up the main conclusions from the pa-
per.
2 Ngram-based SMT System
Our translation system implements a log-linear model in
which a foreign language sentence fJ1 = f1, f2, ..., fJ
is translated into another language eI1 = f1, f2, ..., eI by
searching for the translation hypothesis e?I1 maximizing a
log-linear combination of several feature models (Brown
et al, 1990):
e?I1 = argmax
eI1
{ M
?
m=1
?mhm(eI1, fJ1 )
}
where the feature functions hm refer to the system models
and the set of ?m refers to the weights corresponding to
these models.
The core part of the system constructed in that way
is a translation model, which is based on bilingual n-
grams. It actually constitutes an Ngram-based LM of
bilingual units (called tuples), which approximates the
joint probability between the languages under consider-
ation. The procedure of tuples extraction from a word-
to-word alignment according to certain constraints is ex-
plained in detail in Mari?o et al (2006).
The Ngram-based approach differs from the phrase-
based SMT mainly by distinct representating of the bilin-
gual units defined by word alignment and using a higher
127
order HMM of the translation process. While regular
phrase-based SMT considers context only for phrase re-
ordering but not for translation, the N-gram based ap-
proach conditions translation decisions on previous trans-
lation decisions.
The TALP-UPC 2008 translation system, besides the
bilingual translation model, which consists of a 4-gram
LM of tuples with Kneser-Ney discounting (estimated
with SRI Language Modeling Toolkit1), implements a
log-linear combination of five additional feature models:
? a target language model (a 4-gram model of words,
estimated with Kneser-Ney smoothing);
? a POS target language model (a 4-gram model of
tags with Good-Turing discounting (TPOS));
? a word bonus model, which is used to compensate
the system?s preference for short output sentences;
? a source-to-target lexicon model and a target-to-
source lexicon model, these models use word-to-
word IBM Model 1 probabilities (Och and Ney,
2004) to estimate the lexical weights for each tuple
in the translation table.
Decisions on the particular LM configuration and
smoothing technique were taken on the minimal-
perplexity and maximal-BLEU bases.
The decoder (called MARIE), an open source tool2,
implementing a beam search strategy with distortion ca-
pabilities was used in the translation system.
Given the development set and references, the log-
linear combination of weights was adjusted using a sim-
plex optimization method (with the optimization criteria
of the highest BLEU score ) and an n-best re-ranking
just as described in http://www.statmt.org/jhuws/. This
strategy allows for a faster and more efficient adjustment
of model weights by means of a double-loop optimiza-
tion, which provides significant reduction of the number
of translations that should be carried out.
3 Reordering framework
For a great number of translation tasks a certain reorder-
ing strategy is required. This is especially important
when the translation is performed between pairs of lan-
guages with non-monotonic word order. There are var-
ious types of distortion models, simplifying bilingual
translation. In our system we use an extended monotone
reordering model based on automatically learned reorder-
ing rules. A detailed description can be found in Crego
and Mari?o (2006).
1http://www.speech.sri.com/projects/srilm/
2http://gps-tsc.upc.es/veu/soft/soft/marie/
Apart from that, tuples were extracted by an unfold-
ing technique: this means that the tuples are broken into
smaller tuples, and these are sequenced in the order of the
target words.
3.1 Reordering patterns
Word movements are realized according to the reordering
rewrite rules, which have the form of:
t1, ..., tn 7? i1, ..., in
where t1, ..., tn is a sequence of POS tags (relating a
sequence of source words), and i1, ..., in indicates which
order of the source words generate monotonically the tar-
get words.
Patterns are extracted in training from the crossed links
found in the word alignment, in other words, found in
translation tuples (as no word within a tuple can be linked
to a word out of it (Crego and Mari?o, 2006)).
Having all the instances of rewrite patterns, a score for
each pattern on the basis of relative frequency is calcu-
lated as shown below:
p(t1, ..., tn 7? i1, ..., in) =
N(t1, ..., tn 7? i1, ..., in)
NN(t1, ..., tn)
3.2 Search graph extension and source POS model
The monotone search graph is extended with reorderings
following the patterns found in training. Once the search
graph is built, the decoder traverses the graph looking for
the best translation. Hence, the winning hypothesis is
computed using all the available information (the whole
SMT models).
Figure 1: Search graph extension. NC, CC and AQ stand re-
spectively for name, conjunction and adjective.
The procedure identifies first the sequences of words
in the input sentence that match any available pattern.
Then, each of the matchings implies the addition of an arc
into the search graph (encoding the reordering learned in
the pattern). However, this addition of a new arc is not
128
Task BL BL+SPOS
Europarl News Europarl News
es2en 32.79 36.09 32.88 36.36
en2es 32.05 33.91 32.10 33.63
Table 1: BLEU comparison demonstrating the impact of the
source-side POS tags model.
performed if a translation unit with the same source-side
words already exists in the training. Figure 1 shows how
two rewrite rules applied over an input sentence extend
the search graph given the reordering patterns that match
the source POS tag sequence.
The reordering strategy is additionally supported by
a 4-gram language model (estimated with Good-Turing
smoothing) of reordered source POS tags (SPOS). In
training, POS tags are reordered according with the ex-
tracted reordering patterns and word-to-word links. The
resulting sequence of source POS tags is used to train the
Ngram LM.
Table 1 presents the effect of the source POS LM in-
troduction to the reordering module of the Ngram-based
SMT. As it can be seen, the impactya le h of the source-
side POS LM is minimal, however we decided to consider
the model aiming at improving it in future. The reported
results are related to the Europarl and News Commen-
tary (News) development sets. BLEU calculation is case
insensitive and insensitive to tokenization. BL (baseline)
refers to the presented Ngram-based system considering
all the features, apart from the target and source POS
models.
4 WMT 2008 Evaluation Framework
4.1 Corpus
An extraction of the official transcriptions of the 3rd re-
lease of the European Parliament Plenary Sessions3 was
provided for the ACL WMT 2008 shared translation task.
About 40 times smaller corpus from news domain (called
News Commentary) was also available. For both tasks,
our training corpus was the catenation of the Europarl and
News Commentary corpora.
TALP UPC participated in the constraint to the
provided training data track for Spanish-English and
English-Spanish translation tasks. We used the same
training material for the traditional and challenging tasks,
while the development sets used to tune the system were
distinct (2000 sentences for Europarl task and 1057
for News Commentary, one reference translation for
each of them). A brief training and development corpora
statistics is presented in Table 2.
3http://www.statmt.org/wmt08/shared-task.html
Spanish English
Train
Sentences 1.3 M 1.3 M
Words 38.2 M 35.8 K
Vocabulary 156 K 120 K
Development Europarl
Sentences 2000 2000
Words 61.8 K 58.7 K
Vocabulary 8 K 6.5 K
Development News Commentary
Sentences 1057 1057
Words 29.8 K 25.8 K
Vocabulary 5.4 K 4.9 K
Table 2: Basic statistics of ACL WMT 2008 corpus.
4.2 Processing details
The training data was preprocessed by using provided
tools for tokenizing and filtering.
POS tagging. POS information for the source and the
target languages was considered for both translation tasks
that we have participated. The software tools available
for performing POS-tagging were Freeling (Carreras et
al., 2004) for Spanish and TnT (Brants, 2000) for En-
glish. The number of classes for English is 44, while
Spanish is considered as a more inflectional language,
and the tag set contains 376 different tags.
Word Alignment. The word alignment is automati-
cally computed by using GIZA++4(Och and Ney, 2000)
in both directions, which are symmetrized by using the
union operation. Instead of aligning words themselves,
stems are used for aligning. Afterwards case sensitive
words are recovered.
Spanish Morphology Reduction. We implemented a
morphology reduction of the Spanish language as a pre-
processing step. As a consequence, training data sparse-
ness due to Spanish morphology was reduced improving
the performance of the overall translation system. In par-
ticular, the pronouns attached to the verb were separated
and contractions as del or al were splitted into de el or
a el. As a post-processing, in the En2Es direction we
used a POS target LM as a feature (instead of the target
language model based on classes) that allowed to recover
the segmentations (de Gispert, 2006).
4.3 Experiments and Results
In contrast to the last year?s system where statistical
classes were used to train the target-side tags LM, this
year we used linguistically motivated word classes
4http://code.google.com/p/giza-pp/
129
Task BL+SPOS BL+SPOS+TPOS
(UPC 2008)
Europarl News Europarl News
es2en 32.88 36.36 32.89 36.31
en2es 31.52 34.13 30.72 32.72
en2es "clean"5 32.10 33.63 32.09 35.04
Table 3: BLEU scores for Spanish-English and English-Spanish
2008 development corpora (Europarl and News Commentary).
Task UPC 2008
Europarl News
es2en 32.80 19.61
en2es 31.31 19.28
en2es "clean"5 32.34 20.05
Table 4: BLEU scores for official tests 2008.
(POS) which were considered to train the POS target LM
and extract the reordering patterns. Other characteristics
of this year?s system are:
? reordering patterns technique;
? source POS model, supporting word reordering;
? no LM interpolation. For this year?s evaluation, we
trained two separate LMs for each domain-specific
corpus (i.e., Europarl and News Commentary tasks).
It is important to mention that 2008 training material is
identical to the one provided for the 2007 shared transla-
tion task.
Table 3 presents the BLEU score obtained for the 2008
development data sets and shows the impact of the target-
side POS LM introduction, which can be characterized as
highly corpus- and language-dependent feature. BL refers
to the same system configuration as described in subsec-
tion 3.2. The computed BLEU scores are case insensitive,
insensitive to tokenization and use one translation refer-
ence.
After submitting the systems we discovered a bug re-
lated to incorrect implementation of the target LMs of
words and tags for Spanish, it caused serious reduction
of translation quality (1.4 BLEU points for development
set in case of English-to-Spanish Europarl task and 2.3
points in case of the corresponding News Commentary
task). The last raw of table 3 (en2es "clean") repre-
sents the results corresponding to the UPC 2008 post-
evaluation system, while the previous one (en2es) refers
to the "bugged" system submitted to the evaluation.
The experiments presented in Table 4 correspond to the
2008 test evaluation sets.
5Corrected post-evaluation results (see subsection 4.3.)
5 Conclusions
In this paper we introduced the TALP UPC Ngram-based
SMT system participating in the WMT08 evaluation.
Apart from briefly summarizing the decoding and opti-
mization processes, we have presented the feature mod-
els that were taken into account, along with the bilingual
Ngram translation model. A reordering strategy based on
linguistically-motivated reordering patterns to harmonize
the source and target word order has been presented in
the framework of the Ngram-based system.
6 Acknowledgments
This work has been funded by the Spanish Government
under grant TEC2006-13964-C03 (AVIVAVOZ project).
The authors want to thank Adri? de Gispert (Cambridge
University) for his contribution to this work.
References
T. Brants. 2000. TnT ? a statistical part-of-speech tagger. In
Proceedings of the 6th Applied Natural Language Processing
(ANLP-2000).
P. Brown, J. Cocke, S. Della Pietra, V. Della Pietra, F. Jelinek,
J. D. Lafferty, R. Mercer, and P. S. Roossin. 1990. A sta-
tistical approach to machine translation. Computational Lin-
guistics, 16(2):79?85.
C. Callison-Burch, C. Fordyce, P. Koehn, C. Monz, and
J. Schroeder. 2007. (Meta-) evaluation of machine trans-
lation. In Proceedings of the ACL 2007 Workshop on Statis-
tical and Hybrid methods for Machine Translation (WMT),
pages 136?158.
X. Carreras, I. Chao, L. Padr?, and M. Padr?. 2004. Freeling:
An open-source suite of language analyzers. In Proceedings
of the 4th Int. Conf. on Language Resources and Evaluation
(LREC?04).
J. M. Crego and J. B. Mari?o. 2006. Improving statistical MT
by coupling reordering and decoding. Machine Translation,
20(3):199?215.
A. de Gispert. 2006. Introducing linguistic knowledge into
statistical machine translation. Ph.D. thesis, Universitat
Polit?cnica de Catalunya, December.
P. Koehn and C. Monz. 2006. Manual and automatic eval-
uation of machine translation between european languages.
In Proceedings of the ACL 2006 Workshop on Statistical and
Hybrid methods for Machine Translation (WMT), pages 102?
121.
J. B. Mari?o, R. E. Banchs, J. M. Crego, A. de Gispert, P. Lam-
bert, J. A. R. Fonollosa, and M. R. Costa-juss?. 2006. N-
gram based machine translation. Computational Linguistics,
32(4):527?549, December.
F. J. Och and H. Ney. 2000. Improved statistical alignment
models. In Proceedings of the the 38th Annual Meeting
on Association for Computational Linguistics (ACL), pages
440?447.
F. Och and H. Ney. 2004. The alignment template approach to
statistical machine translation. 30(4):417 ? 449, December.
130
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 85?89,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
The TALP-UPC phrase-based translation system for EACL-WMT 2009
Jos? A.R. Fonollosa and Maxim Khalilov and Marta R. Costa-juss? and
Jos? B. Mari?o and Carlos A. Henr?quez Q. and Adolfo Hern?ndez H. and
Rafael E. Banchs
TALP Research Center
Universitat Polit?cnica de Catalunya, Barcelona 08034
{adrian,khalilov,mruiz,canton,carloshq,adolfohh,rbanchs}@talp.upc.edu
Abstract
This study presents the TALP-UPC sub-
mission to the EACL Fourth Worskhop
on Statistical Machine Translation 2009
evaluation campaign. It outlines the ar-
chitecture and configuration of the 2009
phrase-based statistical machine transla-
tion (SMT) system, putting emphasis on
the major novelty of this year: combina-
tion of SMT systems implementing differ-
ent word reordering algorithms.
Traditionally, we have concentrated on
the Spanish-to-English and English-to-
Spanish News Commentary translation
tasks.
1 Introduction
TALP-UPC (Center of Speech and Language
Applications and Technology at the Universitat
Polit?cnica de Catalunya) is a permanent par-
ticipant of the ACL WMT shared translations
tasks, traditionally concentrating on the Spanish-
to-English and vice versa language pairs. In this
paper, we describe the 2009 system?s architecture
and design describing individual components and
distinguishing features of our model.
This year?s system stands aside from the
previous years? configurations which were per-
formed following an N -gram-based (tuple-based)
approach to SMT. By contrast to them, this
year we investigate the translation models (TMs)
interpolation for a state-of-the-art phrase-based
translation system. Inspired by the work pre-
sented in (Schwenk and Est?ve, 2008), we attack
this challenge using the coefficients obtained for
the corresponding monolingual language models
(LMs) for TMs interpolation.
On the second step, we have performed
additional word reordering experiments, com-
paring the results obtained with a statisti-
cal method (R. Costa-juss? and R. Fonollosa,
2009) and syntax-based algorithm (Khalilov and
R. Fonollosa, 2008). Further the outputs of
the systems were combined selecting the trans-
lation with the Minimum Bayes Risk (MBR) al-
gorithm (Kumar, 2004) that allowed significantly
outperforming the baseline configuration.
The remainder of this paper is organized as
follows: Section 2 presents the TALP-UPC?09
phrase-based system, along with the translation
models interpolation procedure and other minor
novelties of this year. Section 3 reports on the ex-
perimental setups and outlines the results of the
participation in the EACL WMT 2009 evaluation
campaign. Section 4 concludes the paper with dis-
cussions.
2 TALP-UPC phrase-based SMT
The system developed for this year?s shared
task is based on a state-of-the-art SMT sys-
tem implemented within the open-source MOSES
toolkit (Koehn et al, 2007). A phrase-based trans-
lation is considered as a three step algorithm:
(1) the source sequence of words is segmented
in phrases, (2) each phrase is translated into tar-
get language using translation table, (3) the target
phrases are reordered to be inherent in the target
language.
A bilingual phrase (which in the context of SMT
do not necessarily coincide with their linguistic
analogies) is any pair of m source words and n
target words that satisfies two basic constraints:
(1) words are consecutive along both sides of the
bilingual phrase and (2) no word on either side of
the phrase is aligned to a word outside the phrase.
Given a sentence pair and a corresponding word-
to-word alignment, phrases are extracted follow-
ing the criterion in (Och and Ney, 2004). The
probability of the phrases is estimated by relative
frequencies of their appearance in the training cor-
pus.
85
Classically, a phrase-based translation system
implements a log-linear model in which a foreign
language sentence fJ1 = f1, f2, ..., fJ is trans-
lated into another language eI1 = e1, e2, ..., eI by
searching for the translation hypothesis e?I1 maxi-
mizing a log-linear combination of several feature
models (Brown et al, 1990):
e?I1 = argmaxeI1
{ M?
m=1
?mhm(eI1, fJ1 )
}
where the feature functions hm refer to the system
models and the set of ?m refers to the weights cor-
responding to these models.
2.1 Translation models interpolation
We implemented a TM interpolation strategy fol-
lowing the ideas proposed in (Schwenk and Es-
t?ve, 2008), where the authors present a promis-
ing technique of target LMs linear interpolation;
in (Koehn and Schroeder, 2007) where a log-linear
combination of TMs is performed; and specifi-
cally in (Foster and Kuhn, 2007) where the authors
present various ways of TM combination and ana-
lyze in detail the TM domain adaptation.
In the framework of the evaluation campaign,
there were two Spanish-to-English parallel train-
ing corpora available: Europarl v.4 corpus (about
50M tokens) and News Commentary (NC) corpus
(about 2M tokens). The test dataset provided by
the organizers this year was from the news do-
main, so we considered the Europarl training cor-
pus as "out-of-domain" data and the News Com-
mentary as "in-domain" training material. Unfor-
tunately, the in-domain corpus is much smaller in
size, however the Europarl corpus can be also used
to increase the final translation and reordering ta-
bles in spite of its different nature.
A straightforward approach to the TM interpo-
lation would be an iterative TM reconstruction ad-
justing scale coefficients on each step of the loop
with use of the highest BLEU score as a maxi-
mization criterion.
However, we did not expect a significant gain
from this time-consumption strategy and we de-
cided to follow a simpler approach. In the pre-
sented results, we obtained the best interpola-
tion weight following the standard entropy-based
optimization of the target-side LM. We adjust
the weight coefficient ?Europarl (?NC = 1 ?
?Europarl) of the linear interpolation of the target-
side LMs:
P (w) = ?Europarl ? PwEuroparl + ?NC ? PwNC (1)
where PwEuroparl and PwNC are probabilities as-
signed to the word sequence w by the LM esti-
mated on Europarl and NC data, respectively.
The scale factor values are automatically opti-
mized to obtain the lowest perplexity ppl(w) pro-
duced by the interpolated LM P (w). We used the
standard script compute ? best ? mix from the
SRI LM package (Stolcke, 2002) for optimization.
On the next step, the optimized coefficients
?Europarl and ?NC are generalized on the interpo-
lated translation and reordering models. In other
words, reordering and translation models are in-
terpolated using the same weights which yield the
lowest perplexity for LM interpolation.
The word-to-word alignment was obtained from
the joint (merged) database (Europarl + NC).
Then, we separately computed the translation and
reordering tables corresponding to the in- and out-
of-domain parts of the joint alignment. The final
tables, as well as the final target LM were obtained
using linear interpolation. The weights were se-
lected using a minimum perplexity criterion esti-
mated on the corresponding interpolated combina-
tion of the target-side LMs.
The optimized coefficient values are: for Span-
ish: NC weight = 0.526, Europarl weight = 0.474;
for English: NC weight = 0.503, Europarl weight
= 0.497. The perplexity results obtained using
monolingual LMs and the 2009 development set
(English and Spanish references) can be found in
Table 1, while the corresponding improvement in
BLEU score is presented in Section 3.3 and sum-
mary of the obtained results (Table 4).
Europarl NC Interpolated
English 463.439 489.915 353.305
Spanish 308.802 347.092 246.573
Table 1: Perplexity results obtained on the Dev
2009 corpus and the monolingual LMs.
Note that the corresponding reordering models
are interpolated with the same weights.
2.2 Statistical Machine Reordering
The idea of the Statistical Machine Reordering
(SMR) stems from the idea of using the power-
ful techniques developed for SMT and to translate
86
the source language (S) into a reordered source
language (S?), which more closely matches the
order of the target language. To infer more re-
orderings, it makes use of word classes. To cor-
rectly integrate the SMT and SMR systems, both
are concatenated by using a word graph which of-
fers weighted reordering hypotheses to the SMT
system. The details are described in (?).
2.3 Syntax-based Reordering
Syntax-based Reordering (SBR) approach deals
with the word reordering problem and is based on
non-isomorphic parse subtree transfer as described
in details in (Khalilov and R. Fonollosa, 2008).
Local and long-range word reorderings are
driven by automatically extracted permutation pat-
terns operating with source language constituents.
Once the reordering patterns are extracted, they
are further applied to monotonize the bilingual
corpus in the same way as shown in the previ-
ous subsection. The target-side parse tree is con-
sidered as a filter constraining reordering rules to
the set of patterns covered both by the source- and
target-side subtrees.
2.4 System Combination
Over the past few years the MBR algorithm uti-
lization to find the best consensus outputs of dif-
ferent translation systems has proved to improve
the translation accuracy (Kumar, 2004). The sys-
tem combination is performed on the 200-best
lists which are generated by the three systems:
(1) MOSES-based system without pre-translation
monotonization (baseline), (2) MOSES-based
SMT enhanced with SMR monotonization and (3)
MOSES-based SMT augmented with SBR mono-
tonization. The results presented in Table 4 show
that the combined output significantly outperforms
the baseline system configuration.
3 Experiments and results
We followed the evaluation baseline instructions 1
to train the MOSES-based translation system.
In some experiments we used MBR decod-
ing (Kumar and Byrne, 2004) with the smoothed
BLEU score as a similarity criteria, that al-
lowed gaining 0.2 BLEU points comparing to the
standard procedure of outputting the translation
with the highest probability (HP). We applied the
Moses implementation of this algorithm to the list
1http://www.statmt.org/wmt09/baseline.html
of 200 best translations generated by the TALP-
UPC system. The results obtained over the official
2009 Test dataset can be found in Table 2.
Task HP MBR
EsEn 24.48 24.62
EnEs 23.46 23.64
Table 2: MBR versus MERT decoding.
The "recase" script provided within the base-
line was supplemented with and additional mod-
ule, which restore the original case for unknown
words (many of them are proper names and loos-
ing of case information leads to a significant per-
formance degradation).
3.1 Language models
The target-side language models were estimated
using the SRILM toolkit (Stolcke, 2002). We tried
to use all the available in-domain training mate-
rial: apart from the corresponding portions of the
bilingual NC corpora we involved the following
monolingual corpora:
? News monolingual corpus (49M tokens for
English and 49M for Spanish)
? Europarl monolingual corpus (about 504M
tokens for English and 463M for Spanish)
? A collection of News development and test
sets from previous evaluations (151K tokens
for English and 175K for Spanish)
? A collection of Europarl development and
test sets from previous evaluations (295K to-
kens for English and 311K for Spanish)
Five LMs per language were estimated on the
corresponding datasets and interpolated follow-
ing the maximum perplexity criteria. Hence, the
larger LMs incorporating in- and out-of-domain
data were used in decoding.
3.2 Spanish enclitics separation
For the Spanish portion of the corpus we imple-
mented an enclitics separation procedure on the
preprocessing step, i.e. the pronouns attached to
the verb were separated and contractions as del
or al were splitted into de el or a el. Conse-
quently, training data sparseness due to Spanish
morphology was reduced improving the perfor-
mance of the overall translation system. As a
87
post-processing, the segmentation was recovered
in the English-to-Spanish direction using target-
side Part-of-Speech tags (de Gispert, 2006).
3.3 Results
The automatic scores provided by the WMT?09
organizers for TALP-UPC submissions calculated
over the News 2009 dataset can be found in Ta-
ble 3. BLEU and NIST case-insensitive (CI) and
case-sensitive (CS) metrics are considered.
Task Bleu CI Bleu CS NIST CI NIST CS
EsEn 25.93 24.54 7.275 7.017
EnEs 24.85 23.37 6.963 6.689
Table 3: BLEU and NIST scores for preliminary
official test dataset 2009 (primary submission)
with 500 sentences excluded.
The TALP-UPC primary submission was
ranked the 3rd among 28 presented translations
for the Spanish-to-English task and the 4th for the
English-to-Spanish task among 9 systems.
The following system configurations and the in-
ternal results obtained are reported:
? Baseline: Moses-based SMT, as proposed
on the web-page of the evaluation campaign
with Spanish enclitics separation and modi-
fied version of ?recase? tool,
? Baseline+TMI: Baseline enhanced with TM
interpolation as described in subsection 2.1,
? Baseline+TMI+MBR: the same as the latter
but with MBR decoding,
? Baseline+TMI+SMR: the same as Base-
line+TMI but with SMR technique applied to
monotonize the source portion of the corpus,
as described in subsection 2.2,
? Baseline+SBR: the same as Baseline but with
SBR algorithm applied to monotonize the
source portion of the corpus, as described in
subsection 2.3,
? System Combination: a combined output of
the 3 previous systems done with the MBR
algorithm, as described in subsection 2.4.
Impact of TM interpolation and MBR decod-
ing is more significant for the English-to-Spanish
translation task, for which the target-side mono-
lingual corpus is smaller than for the Spanish-to-
English translation.
We did not have time to meet the evalua-
tion deadline for providing the system combi-
nation output. Nevertheless, during the post-
evaluation period we performed the experiments
reported in the last three lines of Table 4 (Base-
line+TMI+SMR, Baseline+SBR and System com-
bination).
Note that the results presented in Table 4 differ
from the ones which can be found the Table 3 due
to selective conditions of preliminary evaluation
done by the Shared Task organizers.
System News 2009 Test CI News 2009 Test CS
Spanish-to-English
Baseline 25.82 24.37
Baseline+TMI 25.84 24.47
Baseline+TMI+MBR (Primary) 26.04 24.62
Baseline+SMR 24.95 23.62
Baseline+SBR 24.24 22.89
System combination 26.44 25.00
English-to-Spanish
Baseline 24.56 23.05
Baseline+TMI 25.01 23.41
Baseline+TMI+MBR (Primary) 25.16 23.64
Baseline+SMR 24.09 22.65
Baseline+SBR 23.52 22.05
System combination 25.39 23.86
Table 4: Experiments summary.
88
4 Conclusions
In this paper, we present the TALP-UPC phrase-
based translation system developed for the EACL-
WMT 2009 evaluation campaign. The major nov-
elties of this year are translation models interpola-
tion done in linear way and combination of SMT
systems implementing different word reordering
algorithms. The system was ranked pretty well for
both translation tasks in which our institution has
participated.
Unfortunately, the promising reordering tech-
niques and the combination of their outputs were
not applied within the evaluation deadline, how-
ever we report the obtained results in the paper.
5 Acknowledgments
This work has been funded by the Spanish Gov-
ernment under grant TEC2006-13964-C03 (AVI-
VAVOZ project).
References
P. Brown, J. Cocke, S. Della Pietra, V. Della Pietra,
F. Jelinek, J.D. Lafferty, R. Mercer, and P.S.
Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, 16(2):79?
85.
A. de Gispert. 2006. Introducing linguistic knowledge
into Statistical Machine Translation. Ph.D. thesis,
Universitat Polit?cnica de Catalunya, December.
G. Foster and R. Kuhn. 2007. Mixture-model adap-
tation for SMT. In In Annual Meeting of the Asso-
ciation for Computational Linguistics: Proc. of the
Second Workshop on Statistical Machine Transla-
tion (WMT), pages 128?135, Prague, Czech Repub-
lic, June.
M. Khalilov and J. R. Fonollosa. 2008. A new subtree-
transfer approach to syntax-based reordering for sta-
tistical machine translation. Technical report, Uni-
versitat Polit?cnica de Catalunya.
Ph. Koehn and J. Schroeder. 2007. Experiments in do-
main adaptation for statistical machine translation.
In In Annual Meeting of the Association for Compu-
tational Linguistics: Proc. of the Second Workshop
on Statistical Machine Translation (WMT), pages
224?227, Prague, Czech Republic, June.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: open-source
toolkit for statistical machine translation. In Pro-
ceedings of the Association for Computational Lin-
guistics (ACL) 2007, pages 177?180.
Sh. Kumar and W. Byrne. 2004. Minimum bayes-risk
decoding for statistical machine translation. In In
HLTNAACL?04, pages 169?176.
Sh. Kumar. 2004. Minimum Bayes-Risk Techniques in
Automatic Speech Recognition and Statistical Ma-
chine Translation. Ph.D. thesis, Johns Hopkins Uni-
versity.
F. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Compu-
tational Linguistics, 3(4):417?449, December.
M. R. Costa-juss? and J. R. Fonollosa. 2009. An
Ngram reordering model. Computer Speech and
Language. ISSN 0885-2308, accepted for publica-
tion.
H. Schwenk and Y. Est?ve. 2008. Data selection and
smoothing in an open-source system for the 2008
nist machine translation evaluation. In Proceedings
of the Interspeech?08, pages 2727?2730, Brisbane,
Australia, September.
A. Stolcke. 2002. SRILM: an extensible language
modeling toolkit. In Proceedings of the Int. Conf.
on Spoken Language Processing, pages 901?904.
89
Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation, pages 78?86,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Coupling hierarchical word reordering and decoding in phrase-based
statistical machine translation
Maxim Khalilov and Jos? A.R. Fonollosa
Universitat Polit?cnica de Catalunya
Campus Nord UPC, 08034,
Barcelona, Spain
{khalilov,adrian}@gps.tsc.upc.edu
Mark Dras
Macquarie University
North Ryde NSW 2109,
Sydney, Australia
madras@ics.mq.edu.au
Abstract
In this paper, we start with the existing idea of
taking reordering rules automatically derived
from syntactic representations, and applying
them in a preprocessing step before translation
to make the source sentence structurally more
like the target; and we propose a new approach
to hierarchically extracting these rules. We
evaluate this, combined with a lattice-based
decoding, and show improvements over state-
of-the-art distortion models.
1 Introduction
One of the big challenges for the MT community is
the problem of placing translated words in a natural
order. This issue originates from the fact that dif-
ferent languages are characterized by different word
order requirements. The problem is especially im-
portant if the distance between words which should
be reordered is high (global reordering); in this case
the reordering decision is very difficult to take based
on statistical information due to dramatic expansion
of the search space with the increase in number of
words involved in the search process.
Classically, statistical machine translation (SMT)
systems do not incorporate any linguistic analysis
and work at the surface level of word forms. How-
ever, more recently MT systems are moving towards
including additional linguistic and syntactic infor-
mative sources (for example, source- and/or target-
side syntax) into word reordering process. In this pa-
per we propose using a syntactic reordering system
operating with fully, partially and non- lexicalized
reordering patterns, which are applied on the step
prior to translation; the novel idea in this paper is in
the derivation of these rules in a hierarchical manner,
inspired by Imamura et al(2005). Furthermore, we
propose generating a word lattice from the bilingual
corpus with the reordered source side, extending the
search space on the decoding step. A thorough study
of the combination of syntactical and word lattice re-
ordering approaches is another novelty of the paper.
2 Related work
Many reordering algorithms have appeared over the
past few years. Word class-based reordering was a
part of Och?s Alignment Template system (Och et
al., 2004); the main criticism of this approach is that
it shows bad performance for the pair of languages
with very distinct word order. The state-of-the-art
SMT system Moses implements a distance-based re-
ordering model (Koehn et al, 2003) and a distor-
tion model, operating with rewrite patterns extracted
from a phrase alignment table (Tillman, 2004).
Many SMT models implement the brute force ap-
proach, introducing several constrains for the re-
ordering search as described in Kanthak et al (2005)
and Crego et al (2005). The main criticism of such
systems is that the constraints are not lexicalized.
Recently there has been interest in SMT exploiting
non-monotonic decoding which allow for extension
of the search space and linguistic information in-
volvement. The variety of such models includes a
constrained distance-based reordering (Costa-juss?
et al, 2006); and a constrained version of distortion
model where the reordering search problem is tack-
led through a set of linguistically motivated rules
used during decoding (Crego and Mari?o, 2007).
78
A quite popular class of reordering algorithms is
a monotonization of the source part of the parallel
corpus prior to translation. The first work on this
approach is described in Nie?en and Ney (2004),
where morpho-syntactic information was used to ac-
count for the reorderings needed. A representative
set of similar systems includes: a set of hand-crafted
reordering patterns for German-to-English (Collins
et al, 2005) and Chinese-English (Wang et al,
2007) translations, emphasizing the distinction be-
tween German/Chinese and English clause struc-
ture; and statistical machine reordering (SMR) tech-
nique where a monotonization of the source words
sequence is performed by translating them into the
reordered one using well established SMT mecha-
nism (Costa-juss? and Fonollosa, 2006). Coupling
of SMR algorithm and the search space extension
via generating a set of weighted reordering hypothe-
ses has demonstrated a significant improvement, as
shown in Costa-juss? and Fonollosa (2008).
The technique proposed in this study is most
similar to the one proposed for French-to-English
translation task in Xia and McCord (2004), where
the authors present a hybrid system for French-
English translation based on the principle of auto-
matic rewrite patterns extraction using a parse tree
and phrase alignments. We propose using a word
distortion model not only to monotonize the source
part of the corpus (using a different approach to
rewrite rule organization from Xia and McCord), but
also to extend the search space during decoding.
3 Baseline phrase-based SMT systems
The reference system which was used as a transla-
tion mechanism is the state-of-the-art Moses-based
SMT (Koehn et al, 2007). The training and weights
tuning procedures can be found on the Moses web
page1.
Classical phrase-based translation is considered
as a three step algorithm: (1) the source sequence
of words is segmented into phrases, (2) each phrase
is translated into the target language using a transla-
tion table, (3) the target phrases are reordered to fit
the target language. The probabilities of the phrases
are estimated by relative frequencies of their appear-
ance in the training corpus.
1http://www.statmt.org/moses/
In baseline experiments we used a phrase depen-
dent lexicalized reordering model, as proposed in
Tillmann (2004). According to this model, mono-
tonic or reordered local orientations enriched with
probabilities are learned from training data. During
decoding, translation is viewed as a monotone block
sequence generation process with the possibility to
swap a pair of neighbor blocks.
4 Syntax-based reordering coupled with
word graph
Our syntax-based reordering system requires access
to source and target language parse trees and word
alignments intersections.
4.1 Notation
Syntax-based reordering (SBR) operates with source
and target parse trees that represent the syntactic
structure of a string in source and target languages
according to a Context-Free Grammar (CFG).
We call this representation "CFG form". We
formally define a CFG in the usual way as G =
?N,T,R, S?, where N is a set of nonterminal sym-
bols (corresponding to source-side phrase and part-
of-speech tags); T is a set of source-side terminals
(the lexicon), R is a set of production rules of the
form ? ? ?, with ? ? N and ?, which is a sequence
of terminal and nonterminal symbols; and S ? N is
the distinguished symbol.
The reordering rules then have the form
?0@0 . . . ?k@k ?
?d0@d0 . . . ?dk@dk|Lexicon|p1 (1)
where ?i ? N for all 0 ? i ? k; (do . . . dk) is
a permutation of (0 . . . k); Lexicon comes from the
source-side set of words for each ?i; and p1 is a prob-
ability associated with the rule. Figure 1 gives two
examples of the rule format.
4.2 Rules extraction
Concept. Inspired by the ideas presented in Imamura
et al (2005), where monolingual correspondences of
syntactic nodes are used during decoding, we extract
a set of bilingual patterns allowing for reordering as
described below:
79
(1) align the monotone bilingual corpus with
GIZA++ (Och and Ney, 2003) and find
the intersection of direct and inverse word
alignments, resulting in the construction
of the projection matrix P (see below));
(2) parse the source and the target parts of the
parallel corpus;
(3) extract reordering patterns from the par-
allel non-isomorphic CFG-trees based on
the word alignment intersection.
Step 2 is straightforward; we explain aspects of
Steps 1 and 3 in more detail below. Figures 1 and 2
show an example of the extraction of two lexicalized
rules for a parallel Arabic-English sentence:
Arabic:
English:
h*A
this
hW
is
fndq
your
+k
hotel
We use this below in our explanations.
Figure 2: Example of subtree transfer and reordering
rules extraction.
Projection matrix. Bilingual content can be rep-
resented in the form of words or sequences of words
depending on the syntactic role of the corresponding
grammatical element (constituent or POS).
Given two parse trees and a word alignment in-
tersection, a projection matrix P is defined as an
M ?N matrix such that M is the number of words
in the target phrase; N is the number of words in
the source phrase; and a cell (i, j) has a value based
on the alignment intersection ? this value is zero
if word i and word j do not align, and is a unique
non-zero link number if they do.
For the trees in Figure 2,
P =
?
???
1 0 0 0
0 2 0 0
0 0 0 3
0 0 4 0
?
???
Unary chains. Given an unary chain of the form
X ? Y , rules are extracted for each level in this
chain. For example given a rule
NP@0ADV P@1 ? ADV P@1NP@0
and a unary chain "ADV P ? AD", a following
equivalent rule will be generated
NP@0AD@1 ? AD@1NP@0.
The role of target-side parse tree. Although re-
ordering is performed on the source side only, the
target-side tree is of great importance: the reorder-
ing rules can be only extracted if the words covered
by the rule are entirely covered by both a node in
the source and in the target trees. It allows the more
accurate determination of the covering and limits of
the extracted rules.
4.3 Rules organization
Once the list of fully lexicalized reordering patterns
is extracted, all the rules are progressively processed
reducing the amount of lexical information. These
initial rules are iteratively expanded such that each
element of the pattern is generalized until all the lex-
ical elements of the rule are represented in the form
of fully unlexicalized categories. Hence, from each
NN@0 NP@1 ? NP@1 NN@0 | NN@0 << fndq >> NP@1 << +k >> | p
NN@0 NNP@1 ? NNP@1 NN@0 | NN@0 << fndq >> NNP@1 << +k >> | p?
Figure 1: Directly extracted rules.
80
initial pattern with N lexical elements, 2N ? 2 par-
tially lexicalized rules and 1 general rule are gener-
ated. An example of the process of delexicalization
can be found in Figure 3.
Thus, finally three types of rules are available: (1)
fully lexicalized (initial) rules, (2) partially lexical-
ized rules and (3) unlexicalized (general) rules.
On the next step, the sets are processed separately:
patterns are pruned and ambiguous rules are re-
moved. All the rules from the fully lexicalized, par-
tially lexicalized and general sets that appear fewer
than k times are directly discarded (k is a shorthand
for kful, kpart and kgener). The probability of a
pattern is estimated based on relative frequency of
their appearance in the training corpus. Only one
the most probable rule is stored. Fully lexicalized
rules are not pruned (kful = 0); partially lexicalized
rules that have been seen only once were discarded
(kpart = 1); the thresholds kgener was set to 3: it
limits the number of general patterns capturing rare
grammatical exceptions which can be easily found
in any language.
Only the one-best reordering is used in other
stages of the algorithm, so the rule output function-
ing as an input to the next rule can lead to situa-
tions reverting the change of word order that the
previously applied rule made. Therefore, the rules
that can be ambiguous when applied sequentially
during decoding are pruned according to the higher
probability principle. For example, for the pair of
patterns with the same lexicon (which is empty for
a general rule leading to a recurring contradiction
NP@0 VP@1 ? VP@1 NP@0 p1, VP@0 NP@1
? NP@1 VP@0 p2 ), the less probable rule is re-
moved.
Finally, there are three resulting parameter tables
analogous to the "r-table" as stated in (Yamada and
Knight, 2001), consisting of POS- and constituent-
based patterns allowing for reordering and mono-
tone distortion (examples can be found in Table 5).
4.4 Source-side monotonization
Rule application is performed as a bottom-up parse
tree traversal following two principles:
(1) the longest possible rule is applied, i.e. among
a set of nested rules, the rule with a longest left-side
covering is selected. For example, in the case of the
appearance of an NN JJ RB sequence and presence
of the two reordering rules
NN@0 JJ@1 ? ... and
NN@0 JJ@1 RB@2 ? ...
the latter pattern will be applied.
(2) the rule containing the maximum lexical infor-
mation is applied, i.e. in case there is more than one
alternative pattern from different groups, the lexical-
ized rules have preference over the partially lexical-
ized, and partially lexicalized over general ones.
Figure 4: Reordered source-side parse tree.
Once the reordering of the training corpus is
ready, it is realigned and new more monotonic align-
ment is passed to the SMT system. In theory, the
word links from the original alignment can be used,
however, due to our experience, running GIZA++
again results in a better word alignment since it is
easier to learn on the modified training example.
Example of correct local reordering done with the
SBR model can be found in Figure 4.
Initial rule: NN@0 NP@1 ? NP@1 NN@0 | NN@0 << fndq >> NP@1 << +k >> | p1
Part. lexic. rules: NN@0 NP@1 ? NP@1 NN@0 | NN@0 << fndq >> NP@1 << - >> | p2
NN@0 NP@1 ? NP@1 NN@0 | NN@0 << - >> NP@1 << +k >> | p3
General rule: NN@0 NP@1 ? NP@1 NN@0 | p4
Figure 3: Example of a lexical rule expansion.
81
4.5 Coupling with decoding
In order to improve reordering power of the transla-
tion system, we implemented an additional reorder-
ing as described in Crego and Mari?o (2006).
Multiple word segmentations is encoded in a lat-
tice, which is then passed to the input of the de-
coder, containing reordering alternatives consistent
with the previously extracted rules. The decoder
takes the n-best reordering of a source sentence
coded in the form of a word lattice. This approach
is in line with recent research tendencies in SMT, as
described for example in (Hildebrand et al, 2008;
Xu et al, 2005). Originally, word lattice algorithms
do not involve syntax into reordering process, there-
fore their reordering power is limited at representing
long-distance reordering. Our approach is designed
in the spirit of hybrid MT, integrating syntax trans-
fer approach and statistical word lattice methods to
achieve better MT performance on the basis of the
standard state-of-the-art models.
During training a set of word permutation patterns
is automatically learned following given word-to-
word alignment. Since the original and monotonized
(reordered) alignments may vary, different sets of
reordering patterns are generated. Note that no in-
formation about the syntax of the sentence is used:
the reordering permutations are motivated by the
crossed links found in the word alignment and, con-
S 1 2 3 4 5 6 7 8 9 1 0 1 1 1 2 1 3 1 4 L
> n
+ h
+ h
> n
m T E m m T E m
* w
E r y q
> n
* w
E r y q
t A r y x
m T E m
E r y q
* w
E r y q
t A r y x
* w
* w
E r y q
m T E m
t A r y x
E r y q
* w
S 1 2 3 4 5 6 7 8 9
> n
+ h
+ h
> n
m T E m m T E m
> n
* w
t A r y x
* w
m T E m
t A r y x
1 0 L
E r y q
m T E m
E r y q
t A r y x
> n  + h  m T E m  * w  t A r y x  E r y q  W o r d  l a t t i c e ,  p l a i n  t e x t :
W o r d  l a t t i c e ,  r e o r d e r e d  t e x t : > n  + h  m T E m  * w  E r y q  t A r y x  ( c )
( b )
S 1 2 3 4 5> n + h m T E m * w Lt A r y x E r y q
> n  + h  m T E m  * w  t A r y x   E r y qM o n o t o n i c  s e a r c h ,  p l a i n  t e x t :( a )
Figure 5: Comparative example of a monotone search (a), word lattice for a plain (b) and reordered (c) source
sentences.
82
sequently, the generalization power of this frame-
work is limited to local permutations.
On the step prior to decoding, the system gen-
erates word reordering graph for every source sen-
tence, expressed in the form of a word lattice. The
decoder processes word lattice instead of only one
input hypothesis, extending the monotonic search
graph with alternative paths.
Original sentence in Arabic, the English gloss and
reference translation are:
Ar.:
Gl.:
>n +h
this
mTEm
restaurant
*w
has
Eryq
history
tAryx
illustrious
Ref: ?this restaurant has an illustrious history?
The monotonic search graph (a) is extended with
a word lattice for the monotonic train set (b) and re-
ordered train sets (c). Figure 5 shows an example
of the input word graph expressed in the form of a
word lattice. Lattice (c) differ from the graph (b) in
number of edges and provides more input options to
the decoder. The decision about final translation is
taken during decoding considering all the possible
paths, provided by the word lattice.
5 Experiments and results
5.1 Data
The experiments were performed on two Arabic-
English corpora: the BTEC?08 corpus from the
tourist domain and the 50K first-lines extraction
from the corpus that was provided to the NIST?08
evaluation campaign and belongs to the news do-
main (NIST50K). The corpora differ mainly in the
average sentence length (ASL), which is the key cor-
pus characteristic in global reordering studies.
A training set statistics can be found in Table 1.
BTEC NIST50K
Ar En Ar En
Sentences 24.9 K 24.9 K 50 K 50 K
Words 225 K 210 K 1.2 M 1.35 M
ASL 9.05 8.46 24.61 26.92
Voc 11.4 K 7.6 K 55.3 36.3
Table 1: Basic statistics of the BTEC training corpus.
The BTEC development dataset consists of 489
sentences and 3.8 K running words, with 6 human-
made reference translations per sentence; the dataset
used to test the translation quality has 500 sentences,
4.1 K words and is also provided with 6 reference
translations.
The NIST50K development set consists of 1353
sentences and 43 K words; the test data contains
1056 sentences and 33 K running words. Both
datasets have 4 reference translations per sentence.
5.2 Arabic data preprocessing
We took a similar approach to that shown in Habash
and Sadat (2006), using the MADA+TOKAN sys-
tem for disambiguation and tokenization. For dis-
ambiguation only diacritic unigram statistics were
employed. For tokenization we used the D3 scheme
with -TAGBIES option. The scheme splits the fol-
lowing set of clitics: w+, f+, b+, k+, l+, Al+ and
pronominal clitics. The -TAGBIES option produces
Bies POS tags on all taggable tokens.
5.3 Experimental setup
We used the Stanford Parser (Klein and Man-
ning, 2003) for both languages, Penn English Tree-
bank (Marcus et al, 1993) and Penn Arabic Tree-
bank set (Kulick et al, 2006). The English Treebank
is provided with 48 POS and 14 syntactic tags, the
Arabic Treebank has 26 POS and 23 syntactic cate-
gories.
As mentioned above, specific rules are not pruned
away due to a limited amount of training material we
set the thresholds kpart and kgener to relatively low
values, 1 and 3, respectively.
Evaluation conditions were case-insensitive and
with punctuation marks considered. The target-
side 4-gram language model was estimated using
the SRILM toolkit (Stolcke, 2002) and modified
Kneser-Ney discounting with interpolation. The
highest BLEU score (Papineni et al, 2002) was cho-
sen as the optimization criterion. Apart from BLEU,
a standard automatic measure METEOR (Banerjee
and Lavie, 2005) was used for evaluation.
5.4 Results
The scores considered are: BLEU scores obtained
for the development set as the final point of the
MERT procedure (Dev), and BLEU and METEOR
scores obtained on test dataset (Test).
We present BTEC results (Tables 2), character-
ized by relatively short sentence length, and the re-
83
sults obtained on the NIST corpus (Tables 3) with
much longer sentences and much need of global re-
ordering.
Dev Test
BLEU BLEU METEOR
Plain 48.31 45.02 65.98
BL 48.46 47.10 68.10
SBR 48.75 47.52 67.33
SBR+lattice 48.90 48.78 68.85
Table 2: Summary of BTEC experimental results.
Dev Test
BLEU BLEU METEOR
Plain 41.83 43.80 62.03
BL 42.68 43.52 62.17
SBR 42.71 44.01 63.29
SBR+lattice 43.05 44.89 63.30
Table 3: Summary of NIST50K experimental results.
Four SMT systems are contrasted: BL refers to
the Moses baseline system: the training data is not
reordered, lexicalized reordering model (Tillman,
2004) is applied; SBR refers to the monotonic sys-
tem configuration with reordered (SBR) source part;
SBR+lattice is the run with reordered source part, on
the translation step the input is represented as a word
lattice.
We also compare the proposed approach with a
monotonic system configuration (Plain). It shows
the effect of source-reordering and lattice input, also
decoded monotonically.
Automatic scores obtained on the test dataset
evolve similarly when the SBR and word lattice rep-
resentation applied to BTEC and NIST50K tasks.
The combined method coupling two reordering
techniques was more effective than the techniques
applied independently and shows an improvement
in terms of BLEU for both corpora. The METEOR
score is only slightly better for the SBR configura-
tions in case of BTEC task; in the case of NIST50K
the METEOR improvement is more evident. The
general trend is that automatic scores evaluated on
the test set increase with the reordering model com-
plexity.
Application of the SBR algorithm only (without
a word lattice decoding) does not allow achieving
statistical significance threshold for a 95% confi-
dence interval and 1000 resamples (Koehn, 2004)
for either of considered corpora. However, the
SBR+lattice system configuration outperforms the
BL by about 1.7 BLEU points (3.5%) for BTEC task
and about 1.4 BLEU point (3.1%) for NIST task.
These differences is statistically significant.
Figure 6 demonstrates how two reordering tech-
niques interact within a sentence with a need for
both global and local word permutations.
5.5 Syntax-based rewrite rules
As mentioned above, the SBR operates with three
groups of reordering rules, which are the product
of complete or partial delexicalization of the origi-
nally extracted patterns. The groups are processed
and pruned independently. Basic rules statistics for
both translation tasks can be found in Table 4.
The major part of reordering rules consists of
two or three elements (for BTEC task there are
no patterns including more than three nodes). For
NIST50K there are a few rules with higher size in
words of the move (up to 8). In addition, there are
some long lexicalized rules (7-8), generating a high
number of partially lexicalized patterns.
Table 5 shows the most frequent reordering rules
with non-monotonic right part from each group.
Ar. plain.:
En. gloss:
AElnt
announced
Ajhzp
press
AlAElAm
release
l
by
bEvp
mission
AlAmm AlmtHdp
nations united
fy
in
syrAlywn
sierra leone
An
that
...
...
En. ref.: ?a press release by the united nations mission to sierra leone announced that ...?
Ar. reord.: Ajhzp AlAElAm l bEvp AlmtHdp AlAmm fy syrAlywn AElnt An ...
Figure 6: Example of SBR application (highlited bold) and local reordering error corrected with word lattice reorder-
ing (underlined).
84
6 Conclusions
In this study we have shown how the translation
quality can be improved, coupling (1) SBR al-
gorithm and (2) word alignment-based reordering
framework applied during decoding. The system
automatically learns a set of syntactic reordering
patterns that exploit systematic differences between
word order of source and target languages.
Translation accuracy is clearly higher when al-
lowing for SBR coupled with word lattice input rep-
resentation than standard Moses SMT with existing
(lexicalized) reordering models within the decoder
and one input hypothesis condition. We have also
compared the reordering model a monotonic system.
The method was tested translating from Arabic to
English. Two corpora and tasks were considered:
the BTEC task with much need of local reordering
and the NIST50K task requiring long-distance per-
mutations caused by longer sentences.
The reordering approach can be expanded for any
other pair of languages with available parse tools.
We also expect that the method scale to a large train-
ing set, and that the improvement will still be kept,
however, we plan to confirm this assumption exper-
imentally in the near future.
Acknowledgments
This work has been funded by the Spanish Gov-
ernment under grant TEC2006-13964-C03 (AVI-
VAVOZ project) and under a FPU grant.
Group # of rules Voc 2-element 3-element 4-element [5-8]-element
BTEC experiments
Specific rules 703 413 406 7 0 0
Partially lexicalized rules 1,306 432 382 50 0 0
General rules 259 5 259 0 0 0
NIST50K experiments
Specific rules 517 399 193 109 72 25
Partially lexicalized rules 17,897 14,263 374 638 1,010 12,241
General rules 489 372 180 90 72 30
Table 4: Basic reordering rules statistics.
Specific rules
NN@0 NP@1 -> NP@1 NN@0 | NN@0 ? Asm ? NP@1 ? +y ? | 0.0270
DTNN@0 DTJJ@1 -> DTJJ@1 DTNN@0 | DTNN@0 ? AlAmm ?DTJJ@1 ? AlmtHdp ? | 0.0515
Partially lexicalized rules
DTNN@0 DTJJ@1 -> DTJJ@1 DTNN@0 | DTNN@0 ? NON ?DTJJ@1 ? AlmtHdp ? | 0.0017
NN@0 NNP@1 -> NNP@1 NN@0 | NN@0 ? NON ?NNP@1 ? $rm ? | 0.0017
General rules
PP@0 NP@1 -> PP@0 NP@1 | 0.0432
NN@0 DTNN@1 DTJJ@2 -> NN@0 DTJJ@2 DTNN@1 |0.0259
Table 5: Examples of Arabic-to-English reordering rules.
85
References
S. Banerjee and A. Lavie. 2005. METEOR: An auto-
matic metric for MT evaluation with improved corre-
lation with human judgments. In Proceedings of the
ACL Workshop on Intrinsic and Extrinsic Evaluation
Measures for Machine Translation and/or Summariza-
tion, pages 65?72.
M. Collins, Ph. Koehn, and I. Kuc?erov?. 2005. Clause
restructuring for statistical machine translation. In
Proceedings of the 43rd Annual Meeting on ACL 2005,
pages 531?540.
M.R. Costa-juss? and J.A.R. Fonollosa. 2006. Sta-
tistical machine reordering. In Proceedings of the
HLT/EMNLP 2006.
M.R. Costa-juss? and J.A.R. Fonollosa. 2008. Comput-
ing multiple weighted reordering hypotheses for a sta-
tistical machine translation phrase-based system. In In
Proc. of the AMTA?08, Honolulu, USA, October.
M.R. Costa-juss?, J.M. Crego, A. de Gispert, P. Lambert,
M. Khalilov, J. A. Fonollosa, J.B. Mari no, and R.E.
Banchs. 2006. TALP phrase-based system and TALP
system combination for IWSLT 2006. In Proceedings
of the IWSLT 2006, pages 123?129.
J.M. Crego and J. B Mari?o. 2006. Reordering experi-
ments for N-gram-based SMT. In SLT?06, pages 242?
245.
J.M. Crego and J.B. Mari?o. 2007. Syntax-enhanced N-
gram-based smt. In Proceedings of MT SUMMIT XI.
J.M. Crego, J. B. Mari?o, and A. de Gispert. 2005. Re-
ordered search and tuple unfolding for ngram-based
smt. In In Proc. of MT SUMMIT X, pages 283?289,
September.
S. Nie?en and H. Ney. 2004. Statistical machine transla-
tion with scarce resources using morpho-syntactic in-
formation. volume 30, pages 181?204.
N. Habash and F. Sadat. 2006. Arabic preprocessing
schemes for statistical machine translation. In Pro-
ceedings of the Human Language Technology Confer-
ence of the NAACL, pages 49?52.
A.S. Hildebrand, K. Rottmann, M. Noamany, Q. Gao,
S. Hewavitharana, N. Bach, and S. Vogel. 2008. Re-
cent improvements in the cmu large scale chinese-
english smt system. In Proceedings of ACL-08: HLT
(Companion Volume), pages 77?80.
K. Imamura, H. Okuma, and E. Sumita. 2005. Practical
approach to syntax-based statistical machine transla-
tion. In Proceedings of MT Summit X, pages 267?274.
S. Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney.
2005. Novel reordering approaches in phrase-based
statistical machine translation. In In Proc. of the ACL
Workshop on Building and Using Parallel Texts, pages
167?174, June.
D. Klein and C. Manning. 2003. Accurate unlexicalized
parsing. In Proceedings of the 41st Annual Meeting of
the ACL 2003, pages 423?430.
Ph. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based machine translation. In Proceedings of
the HLT-NAACL 2003, pages 48?54.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: open-source toolkit for
statistical machine translation. In Proceedings of ACL
2007, pages 177?180.
Ph. Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP 2004, pages 388?395.
S. Kulick, R. Gabbard, and M. Marcus. 2006. Parsing the
Arabic Treebank: Analysis and improvements. Tree-
banks and Linguistic Theories.
M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational Linguistics,
19(2):313?330.
F. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?51.
F.J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Ya-
mada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng,
V. Jain, Z. Jin, and D. Radev. 2004. A Smorgasbord of
Features for Statistical Machine Translation. In Pro-
ceedings of HLT/NAACL04, pages 161?168.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of ACL 2002, pages 311?
318.
A. Stolcke. 2002. SRILM: an extensible language mod-
eling toolkit. In Proceedings of the Int. Conf. on Spo-
ken Language Processing, pages 901?904.
C. Tillman. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL?04.
C. Wang, M. Collins, and P. Koehn. 2007. Chinese syn-
tactic reordering for statistical machine translation. In
Proceedings of the Joint Conference on EMNLP.
F. Xia and M. McCord. 2004. Improving a statistical mt
system with automatically learned rewrite patterns. In
Proceedings of the COLING 2004.
J. Xu, E. Matusov, R. Zens, and H. Ney. 2005. In-
tegrated chinese word segmentation in statistical ma-
chine translation. In Proc. of IWSLT 2005.
K. Yamada and K. Knight. 2001. A syntax-based statis-
tical translation model. In Proceedings of ACL 2001,
pages 523?530.
86
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 262?267,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
English?Russian MT evaluation campaign
Pavel Braslavski
Kontur Labs /
Ural Federal
University,Russia
pbras@yandex.ru
Alexander Beloborodov
Ural Federal University
Russia
xander-beloborodov
@yandex.ru
Maxim Khalilov
TAUS Labs
The Netherlands
maxim
@tauslabs.com
Serge Sharoff
University of Leeds
UK
s.sharoff
@leeds.ac.uk
Abstract
This paper presents the settings and the re-
sults of the ROMIP 2013 MT shared task
for the English?Russian language direc-
tion. The quality of generated translations
was assessed using automatic metrics and
human evaluation. We also discuss ways
to reduce human evaluation efforts using
pairwise sentence comparisons by human
judges to simulate sort operations.
1 Introduction
Machine Translation (MT) between English and
Russian was one of the first translation directions
tested at the dawn of MT research in the 1950s
(Hutchins, 2000). Since then the MT paradigms
changed many times, many systems for this lan-
guage pair appeared (and disappeared), but as far
as we know there was no systematic quantitative
evaluation of a range of systems, analogous to
DARPA?94 (White et al, 1994) and later evalua-
tion campaigns. The Workshop on Statistical MT
(WMT) in 2013 has announced a Russian evalua-
tion track for the first time.1 However, this evalu-
ation is currently ongoing, it should include new
methods for building statistical MT (SMT) sys-
tems for Russian from the data provided in this
track, but it will not cover the performance of ex-
isting systems, especially rule-based (RBMT) or
hybrid ones.
Evaluation campaigns play an important role
in promotion of the progress for MT technolo-
gies. Recently, there have been a number of
MT shared tasks for combinations of several Eu-
ropean, Asian and Semitic languages (Callison-
Burch et al, 2011; Callison-Burch et al, 2012;
Federico et al, 2012), which we took into account
in designing the campaign for the English-Russian
direction. The evaluation has been held in the
1http://www.statmt.org/wmt13/
context of ROMIP,2 which stands for Russian In-
formation Retrieval Evaluation Seminar and is a
TREC-like3 Russian initiative started in 2002.
One of the main challenges in developing MT
systems for Russian and for evaluating them is the
need to deal with its free word order and com-
plex morphology. Long-distance dependencies
are common, and this creates problems for both
RBMT and SMT systems (especially for phrase-
based ones). Complex morphology also leads
to considerable sparseness for word alignment in
SMT.
The language direction was chosen to be
English?Russian, first because of the availabil-
ity of native speakers for evaluation, second be-
cause the systems taking part in this evaluation are
mostly used in translation of English texts for the
Russian readers.
2 Corpus preparation
In designing the set of texts for evaluation, we
had two issues in mind. First, it is known that
the domain and genre can influence MT perfor-
mance (Langlais, 2002; Babych et al, 2007), so
we wanted to control the set of genres. Second,
we were aiming at using sources allowing distri-
bution of texts under a Creative Commons licence.
In the end two genres were used coming from two
sources. The newswire texts were collected from
the English Wikinews website.4 The second genre
was represented by ?regulations? (laws, contracts,
rules, etc), which were collected from the Web
using a genre classification method described in
(Sharoff, 2010). The method provided a sufficient
accuracy (74%) for the initial selection of texts un-
der the category of ?regulations,? which was fol-
lowed by a manual check to reject texts clearly
outside of this genre category.
2http://romip.ru/en/
3http://trec.nist.gov/
4http://en.wikinews.org/
262
The initial corpus consists of 8,356 original
English texts that make up 148,864 sentences.
We chose to retain the entire texts in the cor-
pus rather than individual sentences, since some
MT systems may use information beyond isolated
sentences. 100,889 sentences originated from
Wikinews; 47,975 sentences came from the ?reg-
ulations? corpus. The first 1,002 sentences were
published in advance to allow potential partici-
pants time to adjust their systems to the corpus for-
mat. The remaining 147,862 sentences were the
corpus for testing translation into Russian. Two
examples of texts in the corpus:
90237 Ambassadors from the United States of
America, Australia and Britain have all met
with Fijian military officers to seek insur-
ances that there wasn?t going to be a coup.
102835 If you are given a discount for booking
more than one person onto the same date and
you later wish to transfer some of the dele-
gates to another event, the fees will be recal-
culated and you will be asked to pay addi-
tional fees due as well as any administrative
charge.
For automatic evaluation we randomly selected
947 ?clean? sentences, i.e. those with clear sen-
tence boundaries, no HTML markup remains, etc.
(such flaws sometimes occur in corpora collected
from the Web). 759 sentences originated from
the ?news? part of the corpus, the remaining 188
came from the ?regulations? part. The sentences
came from sources without published translations
into Russian, so that some of the participating sys-
tems do not get unfair advantage by using them for
training. These sentences were translated by pro-
fessional translators. For manual evaluation, we
randomly selected 330 sentences out of 947 used
for automatic evaluation, specifically, 190 from
the ?news? part and 140 from the ?regulations? part.
The organisers also provided participants with
access to the following additional resources:
? 1 million sentences from the English-Russian
parallel corpus released by Yandex (the same
as used in WMT13)5;
? 119 thousand sentences from the English-
Russian parallel corpus from the TAUS Data
Repository.6
These resources are not related to the test corpus
of the evaluation campaign. Their purpose was
5https://translate.yandex.ru/corpus?
lang=en
6https://www.tausdata.org
to make it easier to participate in the shared task
for teams without sufficient data for this language
pair.
3 Evaluation methodology
The main idea of manual evaluation was (1) to
make the assessment as simple as possible for a
human judge and (2) to make the results of evalu-
ation unambiguous. We opted for pairwise com-
parison of MT outputs. This is different from
simultaneous ranking of several MT outputs, as
commonly used in WMT evaluation campaigns.
In case of a large number of participating sys-
tems each assessor ranks only a subset of MT out-
puts. However, a fair overall ranking cannot be al-
ways derived from such partial rankings (Callison-
Burch et al, 2012). The pairwise comparisons
we used can be directly converted into unambigu-
ous overall rankings. This task is also much sim-
pler for human judges to complete. On the other
hand, pairwise comparisons require a larger num-
ber of evaluation decisions, which is feasible only
for few participants (and we indeed had relatively
few submissions in this campaign). Below we also
discuss how to reduce the amount of human efforts
for evaluation.
In our case the assessors were asked to make a
pairwise comparison of two sentences translated
by two different MT systems against a gold stan-
dard translation. The question for them was to
judge translation adequacy, i.e., which MT output
conveys information from the reference translation
better. The source English sentence was not pre-
sented to the assessors, because we think that we
can have more trust in understanding of the source
text by a professional translator. The translator
also had access to the entire text, while the asses-
sors could only see a single sentence.
For human evaluation we employed the multi-
functional TAUS DQF tool7 in the ?Quick Com-
parison? mode.
Assessors? judgements resulted in rankings for
each sentence in the test set. In case of ties the
ranks were averaged, e.g. when the ranks of the
systems in positions 2-4 and 7-8 were tied, their
ranks became: 1 3 3 3 5 6 7.5 7.5. To
produce the final ranking, the sentence-level ranks
were averaged over all sentences.
Pairwise comparisons are time-consuming: n
7https://tauslabs.com/dynamic-quality/
dqf-tools-mt
263
Metric OS1 OS2 OS3 OS4 P1 P2 P3 P4 P5 P6 P7
Automatic metrics ALL (947 sentences)
BLEU 0.150 0.141 0.133 0.124 0.157 0.112 0.105 0.073 0.094 0.071 0.073
NIST 5.12 4.94 4.80 4.67 5.00 4.46 4.11 2.38 4.16 3.362 3.38
Meteor 0.258 0.240 0.231 0.240 0.251 0.207 0.169 0.133 0.178 0.136 0.149
TER 0.755 0.766 0.764 0.758 0.758 0.796 0.901 0.931 0.826 0.934 0.830
GTM 0.351 0.338 0.332 0.336 0.349 0.303 0.246 0.207 0.275 0.208 0.230
Automatic metrics NEWS (759 sentences)
BLEU 0.137 0.131 0.123 0.114 0.153 0.103 0.096 0.070 0.083 0.066 0.067
NIST 4.86 4.72 4.55 4.35 4.79 4.26 3.83 2.47 3.90 3.20 3.19
Meteor 0.241 0.224 0.214 0.222 0.242 0.192 0.156 0.127 0.161 0.126 0.136
TER 0.772 0.776 0.784 0.777 0.768 0.809 0.908 0.936 0.844 0.938 0.839
GTM 0.335 0.324 0.317 0.320 0.339 0.290 0.233 0.201 0.257 0.199 0.217
Table 1: Automatic evaluation results
cases require n(n?1)2 pairwise decisions. In thisstudy we also simulated a ?human-assisted? in-
sertion sort algorithm and its variant with binary
search. The idea is to run a standard sort algo-
rithm and ask a human judge each time a compar-
ison operation is required. This assumes that hu-
man perception of quality is transitive: if we know
that A < B and B < C, we can spare evaluation
of A and C. This approach also implies that sen-
tence pairs to judge are generated and presented to
assessors on the fly; each decision contributes to
selection of the pairs to be judged in the next step.
If the systems are pre-sorted in a reasonable way
(e.g. by an MT metric, under assumption that au-
tomatic pre-ranking is closer to the ?ideal? ranking
than a random one), then we can potentially save
even more pairwise comparison operations. Pre-
sorting makes ranking somewhat biased in favour
of the order established by an MT metric. For ex-
ample, if it favours one system against another,
while in human judgement they are equal, the final
ranking will preserve the initial order. Insertion
sort of n sentences requires n? 1 comparisons in
the best case of already sorted data and n(n?1)2 inthe worst case (reversely ordered data). Insertion
sort with binary search requires? n log n compar-
isons regardless of the initial order. For this study
we ran exhaustive pairwise evaluation and used its
results to simulate human-assisted sorting.
In addition to human evaluation, we also ran
system-level automatic evaluations using BLEU
(Papineni et al, 2001), NIST (Doddington,
2002), METEOR (Banerjee and Lavie, 2005),
TER (Snover et al, 2009), and GTM (Turian et
al., 2003). We also wanted to estimate the correla-
tions of these metrics with human judgements for
the English?Russian pair on the corpus level and
on the level of individual sentences.
4 Results
We received results from five teams, two teams
submitted two runs each, which totals seven par-
ticipants? runs (referred to as P1..P7 in the pa-
per). The participants represent SMT, RBMT,
and hybrid approaches. They included established
groups from academia and industry, as well as new
research teams. The evaluation runs also included
the translations of the 947 test sentences produced
by four free online systems in their default modes
(referred to as OS1..OS4). For 11 runs automatic
evaluation measures were calculated; eight runs
underwent manual evaluation (four online systems
plus four participants? runs; no manual evaluation
was done by agreement with the participants for
the runs P3, P6, and P7 to reduce the workload).
ID Name and information
OS1 Phrase-based SMT
OS2 Phrase-based SMT
OS3 Hybrid (RBMT+statistical PE)
OS4 Dependency-based SMT
P1 Compreno, Hybrid, ABBYY Corp
P2 Pharaon, Moses, Yandex&TAUS data
P3,4 Balagur, Moses, Yandex&news data
P5 ETAP-3, RBMT, (Boguslavsky, 1995)
P6,7 Pereved, Moses, Internet data
OS3 is a hybrid system based on RBMT with
SMT post-editing (PE). P1 is a hybrid system with
analysis and generation driven by statistical evalu-
ation of hypotheses.
264
All (330 sentences)
OS3 (highest) P1 OS1 OS2 OS4 P5 P2 P4 (lowest)
3.159 3.350 3.530 3.961 4.082 5.447 5.998 6.473
News (190 sentences)
OS3 (highest) P1 OS1 OS2 OS4 P5 P2 P4 (lowest)
2.947 3.450 3.482 4.084 4.242 5.474 5,968 6,353
Regulations (140 sentences)
P1 (highest) OS3 OS1 OS2 OS4 P5 P2 P4 (lowest)
3.214 3.446 3.596 3.793 3.864 5.411 6.039 6.636
Simulated dynamic ranking (insertion sort)
P1 (highest) OS1 OS3 OS2 OS4 P5 P4 P2 (lowest)
3.318 3.327 3.588 4.221 4.300 5.227 5.900 6.118
Simulated dynamic ranking (binary insertion sort)
OS1 (highest) P1 OS3 OS2 OS4 P5 P2 P4 (lowest)
2.924 3.045 3.303 3.812 4.267 5.833 5.903 6.882
Table 2: Human evaluation results
Table 1 gives the automatic scores for each
of participating runs and four online systems.
OS1 usually has the highest overall score (except
BLEU), it also has the highest scores for ?regula-
tions? (more formal texts), P1 scores are better for
the news documents.
14 assessors were recruited for evaluation (par-
ticipating team members and volunteers); the to-
tal volume of evaluation is 10,920 pairwise sen-
tence comparisons. Table 2 presents the rankings
of the participating systems using averaged ranks
from the human evaluation. There is no statisti-
cally significant difference (using Welch?s t-test at
p ? 0.05) in the overall ranks within the follow-
ing groups: (OS1, OS3, P1) < (OS2, OS4) < P5
< (P2, P4). OS3 (mostly RBMT) belongs to the
troika of leaders in human evaluation contrary to
the results of its automatic scores (Table 1). Sim-
ilarly, P5 is consistently ranked higher than P2 by
the assessors, while the automatic scores suggest
the opposite. This observation confirms the well-
known fact that the automatic scores underesti-
mate RBMT systems, e.g., (B?char et al, 2012).
To investigate applicability of the automatic
measures to the English-Russian language direc-
tion, we computed Spearman?s ? correlation be-
tween the ranks given by the evaluators and by
the respective measures. Because of the amount
of variation for each measure on the sentence
level, robust estimates, such as the median and
the trimmed mean, are more informative than
the mean, since they discard the outliers (Huber,
1996). The results are listed in Table 3. All mea-
sures exhibit reasonable correlation on the corpus
level (330 sentences), but the sentence-level re-
sults are less impressive. While TER and GTM
are known to provide better correlation with post-
editing efforts for English (O?Brien, 2011), free
word order and greater data sparseness on the sen-
tence level makes TER much less reliable for Rus-
sian. METEOR (with its built-in Russian lemma-
tisation) and GTM offer the best correlation with
human judgements.
The lower part of Table 2 also reports the results
of simulated dynamic ranking (using the NIST
rankings as the initial order for the sort operation).
It resulted in a slightly different final ranking of
the systems since we did not account for ties and
?averaged ranks?. However, the ranking is prac-
tically the same up to the statistically significant
rank differences in reference ranking (see above).
The advantage is that it requires a significantly
lower number of pairwise comparisons. Insertion
sort yielded 5,131 comparisons (15.5 per sentence;
56% of exhaustive comparisons for 330 sentences
and 8 systems); binary insertion sort yielded 4,327
comparisons (13.1 per sentence; 47% of exhaus-
tive comparisons).
Out of the original set of 330 sentences for
human evaluation, 60 sentences were evaluated
by two annotators (which resulted in 60*28=1680
pairwise comparisons), so we were able to calcu-
late the standard Kohen?s ? and Krippendorff?s ?
scores (Artstein and Poesio, 2008). The results of
inter-annotator agreement are: percentage agree-
ment 0.56, ? = 0.34, ? = 0.48, which is simi-
265
Sentence level Corpus
Metric Median Mean Trimmed level
BLEU 0.357 0.298 0.348 0.833
NIST 0.357 0.291 0.347 0.810
Meteor 0.429 0.348 0.393 0.714
TER 0.214 0.186 0.204 0.619
GTM 0.429 0.340 0.392 0.714
Table 3: Correlation to human judgements
lar to sentence ranking reported in other evaluation
campaigns (Callison-Burch et al, 2012; Callison-
Burch et al, 2011). It was interesting to see the
agreement results distinguishing the top three sys-
tems against the rest, i.e. by ignoring the assess-
ments for the pairs within each group, ? = 0.53,
which indicates that the judges agree on the dif-
ference in quality between the top three systems
and the rest. On the other hand, the agreement re-
sults within the top three systems are low: ? =
0.23, ? = 0.33, which is again in line with the re-
sults for similar evaluations between closely per-
forming systems (Callison-Burch et al, 2011).
5 Conclusions and future plans
This was the first attempt at making proper
quantitative and qualitative evaluation of the
English?Russian MT systems. In the future edi-
tions, we will be aiming at developing a new
test corpus with a wider genre palette. We
will probably complement the campaign with
Russian?English translation direction. We hope
to attract more participants, including interna-
tional ones and plan to prepare a ?light version?
for students and young researchers. We will also
address the problem of tailoring automatic evalu-
ation measures to Russian ? accounting for com-
plex morphology and free word order. To this
end we will re-use human evaluation data gath-
ered within the 2013 campaign. While the cam-
paign was based exclusively on data in one lan-
guage direction, the correlation results for auto-
matic MT quality measures should be applicable
to other languages with free word order and com-
plex morphology.
We have made the corpus comprising the source
sentences, their human translations, translations
by participating MT systems and the human eval-
uation data publicly available.8
8http://romip.ru/mteval/
Acknowledgements
We would like to thank the translators, asses-
sors, as well as Anna Tsygankova, Maxim Gubin,
and Marina Nekrestyanova for project coordina-
tion and organisational help. Research on corpus
preparation methods was supported by EU FP7
funding, contract No 251534 (HyghTra). Our spe-
cial gratitude goes to Yandex and ABBYY who
partially covered the expenses incurred on corpus
translation. We?re also grateful to the anonymous
reviewers for their useful comments.
References
Ron Artstein and Massimo Poesio. 2008. Inter-coder
agreement for computational linguistics. Computa-
tional Linguistics, 34(4):555?596.
Bogdan Babych, Anthony Hartley, Serge Sharoff, and
Olga Mudraya. 2007. Assisting translators in in-
direct lexical transfer. In Proc. of 45th ACL, pages
739?746, Prague.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with im-
proved correlation with human judgments. In Pro-
ceedings of the ACL Workshop on Intrinsic and Ex-
trinsic Evaluation Measures for Machine Transla-
tion and/or Summarization, pages 65?72, Ann Ar-
bor, Michigan, June.
Hanna B?char, Rapha?l Rubino, Yifan He, Yanjun Ma,
and Josef van Genabith. 2012. An evaluation
of statistical post-editing systems applied to RBMT
and SMT systems. In Proceedings of COLING?12,
Mumbai.
Igor Boguslavsky. 1995. A bi-directional Russian-to-
English machine translation system (ETAP-3). In
Proceedings of the Machine Translation Summit V,
Luxembourg.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar F Zaidan. 2011. Findings of the 2011
workshop on statistical machine translation. In
Proceedings of the Sixth Workshop on Statistical
Machine Translation, pages 22?64. Association for
Computational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical ma-
chine translation. In Proceedings of the Seventh
Workshop on Statistical Machine Translation, pages
10?51, Montr?al, Canada, June.
George Doddington. 2002. Automatic evaluation
of machine translation quality using n-gram co-
occurrence statistics. In Proceedings of the second
international conference on Human Language Tech-
nology, pages 138?145, San Diego, CA.
266
Marcelo Federico, Mauro Cettolo, Luisa Bentivogli,
Michael Paul, and Sebastian Stuker. 2012.
Overview of the IWSLT 2012 evaluation campaign.
In Proceedings of the International Workshop on
Spoken Language Translation (IWSLT), pages 12?
34, Hong Kong, December.
Peter J. Huber. 1996. Robust Statistical Procedures.
Society for Industrial and Applied Mathematics.
John Hutchins, editor. 2000. Early years in ma-
chine translation: Memoirs and biographies of pi-
oneers. John Benjamins, Amsterdam, Philadel-
phia. http://www.hutchinsweb.me.uk/
EarlyYears-2000-TOC.htm.
Philippe Langlais. 2002. Improving a general-purpose
statistical translation engine by terminological lexi-
cons. In Proceedings of Second international work-
shop on computational terminology (COMPUTERM
2002), pages 1?7, Taipei, Taiwan. http://acl.
ldc.upenn.edu/W/W02/W02-1405.pdf.
Sharon O?Brien. 2011. Towards predicting
post-editing productivity. Machine translation,
25(3):197?215.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a method for automatic
evaluation of machine translation. Technical Re-
port RC22176 (W0109-022), IBM Thomas J. Wat-
son Research Center.
Serge Sharoff. 2010. In the garden and in the jun-
gle: Comparing genres in the BNC and Internet.
In Alexander Mehler, Serge Sharoff, and Marina
Santini, editors, Genres on the Web: Computa-
tional Models and Empirical Studies, pages 149?
166. Springer, Berlin/New York.
Matthew Snover, Nitin Madnani, Bonnie Dorr, and
Richard Schwartz. 2009. Fluency, adequacy, or
HTER? Exploring different human judgments with
a tunable MT metric. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
259?268, Athens, Greece, March.
Joseph Turian, Luke Shen, and I. Dan Melamed. 2003.
Evaluation of machine translation and its evaluation.
In Proceedings of Machine Translation Summit IX,
New Orleans, LA, USA, September.
John S. White, Theresa O?Connell, and Francis
O?Mara. 1994. The ARPA MT evaluation method-
ologies: Evolution, lessons, and further approaches.
In Proceedings of AMTA?94, pages 193?205.
267
Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 92?100,
COLING 2010, Beijing, August 2010.
A Discriminative Syntactic Model for Source Permutation
via Tree Transduction
Maxim Khalilov and Khalil Sima?an
Institute for Logic, Language and Computation
University of Amsterdam
{m.khalilov,k.simaan}@uva.nl
Abstract
A major challenge in statistical machine
translation is mitigating the word or-
der differences between source and tar-
get strings. While reordering and lexical
translation choices are often conducted in
tandem, source string permutation prior
to translation is attractive for studying re-
ordering using hierarchical and syntactic
structure. This work contributes an ap-
proach for learning source string permu-
tation via transfer of the source syntax
tree. We present a novel discriminative,
probabilistic tree transduction model, and
contribute a set of empirical upperbounds
on translation performance for English-
to-Dutch source string permutation under
sequence and parse tree constraints. Fi-
nally, the translation performance of our
learning model is shown to outperform the
state-of-the-art phrase-based system sig-
nificantly.
1 Introduction
From its beginnings, statistical machine transla-
tion (SMT) has faced a word reordering challenge
that has a major impact on translation quality.
While standard mechanisms embedded in phrase-
based SMT systems, e.g. (Och and Ney, 2004),
deal efficiently with word reordering within a lim-
ited window of words, they are still not expected
to handle all possible reorderings that involve
words beyond this relatively narrow window, e.g.,
(Tillmann and Ney, 2003; Zens and Ney, 2003;
Tillman, 2004). More recent work handles word
order differences between source and target lan-
guages using hierarchical methods that draw on
Inversion Transduction Grammar (ITG), e.g., (Wu
and Wong, 1998; Chiang, 2005). In principle,
the latter approach explores reordering defined by
the choice of swapping the order of sibling sub-
trees under each node in a binary parse-tree of the
source/target sentence.
An alternative approach aims at minimizing the
need for reordering during translation by permut-
ing the source sentence as a pre-translation step,
e.g., (Collins et al, 2005; Xia and McCord, 2004;
Wang et al, 2007; Khalilov, 2009). In effect,
the translation process works with a model for
source permutation (s ? s?) followed by trans-
lation model (s? ? t), where s and t are source
and target strings and s? is the target-like permuted
source string. In how far can source permutation
reduce the need for reordering in conjunction with
translation is an empirical question.
In this paper we define source permutation as
the problem of learning how to transfer a given
source parse-tree into a parse-tree that minimizes
the divergence from target word-order. We model
the tree transfer ?s ? ?s? as a sequence of local,independent transduction operations, each trans-
forming the current intermediate tree ?s?i into thenext intermediate tree ?s?i+1 , with ?s0 = ?s and
?s?n = ?s? . A transduction operation merely per-mutes the sequence of n > 1 children of a single
node in an intermediate tree, i.e., unlike previous
work, we do not binarize the trees. The number
of permutations is factorial in n, and learning a
sequence of transductions for explaining a source
permutation can be computationally rather chal-
lenging (see (Tromble and Eisner, 2009)). Yet,
92
from the limited perspective of source string per-
mutation (s ? s?), another challenge is to inte-
grate a figure of merit that measures in how far s?
resembles a plausible target word-order.
We contribute solutions to these challenging
problems. Firstly, we learn the transduction
operations using a discriminative estimate of
P (pi(?x) |Nx, ?x, contextx), where Nx is the la-
bel of node (address) x, Nx ? ?x is the context-
free production under x, pi(?x) is a permutation of
?x and contextx represents a surrounding syntac-
tic context. As a result, this constrains {pi(?x)}
only to those found in the training data, and it
conditions the transduction application probabil-
ity on its specific contexts. Secondly, in every se-
quence s?0 = s, . . . , s?n = s? resulting from a tree
transductions, we prefer those local transductions
on ?s?i?1 that lead to source string permutation s
?
i
that are closer to target word order than s?i?1; we
employ s? language model probability ratios as a
measure of word order improvement.
In how far does the assumption of source per-
mutation provide any window for improvement
over a phrase-based translation system? We con-
duct experiments on translating from English into
Dutch, two languages which are characterized
by a number of systematic divergences between
them. Initially, we conduct oracle experiments
with varying constraints on source permutation
to set upperbounds on performance relative to
a state-of-the-art system. Translating the oracle
source string permutation (obtained by untangling
the crossing alignments) offers a large margin of
improvement, whereas the oracle parse tree per-
mutation provides a far smaller improvement. A
minor change to the latter to also permute con-
stituents that include words aligned with NULL,
offers further improvement, yet lags bahind bare
string permutation. Subsequently, we present
translation results using our learning approach,
and exhibit a significant improvement in BLEU
score over the state-of-the-art baseline system.
Our analysis shows that syntactic structure can
provide important clues for reordering in trans-
lation, especially for dealing with long distance
cases found in, e.g., English and Dutch. Yet, tree
transduction by merely permuting the order of sis-
ter subtrees might turn out insufficient.
2 Baseline: Phrase-based SMT
Given a word-aligned parallel corpus, phrase-
based systems (Och and Ney, 2002; Koehn et al,
2003) work with (in principle) arbitrarily large
phrase pairs (also called blocks) acquired from
word-aligned parallel data under a simple defi-
nition of translational equivalence (Zens et al,
2002). The conditional probabilities of one phrase
given its counterpart are interpolated log-linearly
together with a set of other model estimates:
e?I1 = argmaxeI1
{ M?
m=1
?mhm(eI1, fJ1 )
}
(1)
where a feature function hm refer to a system
model, and the corresponding ?m refers to the rel-
ative weight given to this model. A phrase-based
system employs feature functions for a phrase pair
translation model, a language model, a reordering
model, and a model to score translation hypothesis
according to length. The weights ?m are usually
optimized for system performance (Och, 2003) as
measured by BLEU (Papineni et al, 2002). Two
reordering methods are widely used in phrase-
based systems.
Distance-based A simple distance-based re-
ordering model default for Moses system is the
first reordering technique under consideration.
This model provides the decoder with a cost lin-
ear to the distance between words that should be
reordered.
MSD A lexicalized block-oriented data-driven
reordering model (Tillman, 2004) considers three
different orientations: monotone (M), swap (S),
and discontinuous (D). The reordering probabili-
ties are conditioned on the lexical context of each
phrase pair, and decoding works with a block se-
quence generation process with the possibility of
swapping a pair of blocks.
3 Related Work on Source Permutation
The integration of linguistic syntax into SMT
systems offers a potential solution to reordering
problem. For example, syntax is successfully
integrated into hierarchical SMT (Zollmann and
93
Venugopal, 2006). Similarly, the tree-to-string
syntax-based transduction approach offers a com-
plete translation framework (Galley et al, 2006).
The idea of augmenting SMT by a reordering
step prior to translation has often been shown to
improve translation quality. Clause restructuring
performed with hand-crafted reordering rules for
German-to-English and Chinese-to-English tasks
are presented in (Collins et al, 2005) and (Wang
et al, 2007), respectively. In (Xia and McCord,
2004; Khalilov, 2009) word reordering is ad-
dressed by exploiting syntactic representations of
source and target texts.
Other reordering models operate provide the
decoder with multiple word orders. For ex-
ample, the MaxEnt reordering model described
in (Xiong et al, 2006) provides a hierarchi-
cal phrasal reordering system integrated within
a CKY-style decoder. In (Galley and Manning,
2008) the authors present an extension of the fa-
mous MSD model (Tillman, 2004) able to handle
long-distance word-block permutations. Coming
up-to-date, in (PVS, 2010) an effective application
of data mining techniques to syntax-driven source
reordering for MT is presented.
Recently, Tromble and Eisner (2009) define
source permutation as learning source permuta-
tions; the model works with a preference matrix
for word pairs, expressing preference for their two
alternative orders, and a corresponding weight
matrix that is fit to the parallel data. The huge
space of permutations is then structured using a
binary synchronous context-free grammar (Binary
ITG) with O(n3) parsing complexity, and the per-
mutation score is calculated recursively over the
tree at every node as the accumulation of the
relative differences between the word-pair scores
taken from the preference matrix. Application to
German-to-English translation exhibits some per-
formance improvement.
Our work is in the general learning direction
taken in (Tromble and Eisner, 2009) but differs
both in defining the space of permutations, using
local probabilistic tree transductions, as well as in
the learning objective aiming at scoring permuta-
tions based on a log-linear interpolation of a lo-
cal syntax-based model with a global string-based
(language) model.
4 Pre-Translation Source Permutation
Given a word-aligned parallel corpus, we define
the source string permutation as the task of learn-
ing to unfold the crossing alignments between
sentence pairs in the parallel corpus. Let be given
a source-target sentence pair s ? t with word
alignment set a between their words. Unfold-
ing the crossing instances in a should lead to as
monotone an alignment a? as possible between a
permutation s? of s and the target string t. Con-
ducting such a ?monotonization? on the parallel
corpus gives two parallel corpora: (1) a source-
to-permutation parallel corpus (s ? s?) and
(2) a source permutation-to-target parallel corpus
(s? ? t). The latter corpus is word-aligned au-
tomatically again and used for training a phrase-
based translation system, while the former corpus
is used for training our model for pre-translation
source permutation via parse tree transductions.
Figure 1: Example of crossing alignments and
long-distance reordering using a source parse tree.
In itself, the problem of permuting the source
string to unfold the crossing alignments is compu-
tationally intractable (see (Tromble and Eisner,
2009)). However, different kinds of constraints
can be made on unfolding the crossing alignments
in a. A common approach in hierarchical SMT is
to assume that the source string has a binary parse
tree, and the set of eligible permutations is defined
by binary ITG transductions on this tree. This de-
fines permutations that can be obtained only by
at most inverting pairs of children under nodes of
the source tree. Figure 1 exhibits a long distance
reordering of the verb in English-to-Dutch transla-
tion: inverting the order of the children under the
VP node would unfold the crossing alignment.
94
4.1 Oracle Performance
As has been shown in the literature (Costa-jussa`
and Fonollosa, 2006; Khalilov and Sima?an, 2010;
Wang et al, 2007), source and target texts mono-
tonization leads to a significant improvement in
terms of translation quality. However it is not
known how many alignment crossings can be un-
folded under different parse tree conditions. In or-
der to gauge the impact of corpus monotonization
on translation system performance, we trained a
set of oracle translation systems, which create
target sentences that follow the source language
word order using the word alignment links and
various constraints.
(a) Word alignment.
(b) Parse tree and corre-
sponding alignment.
(c) Word alignment
and ADJP span.
Figure 2: Reordering example.
The set-up of our experiments and corpus char-
acteristics are detailed in Section 5. Table 1 re-
ports translation scores of the oracle systems. No-
tice that all the numbers are calculated on the re-
aligned corpora. Baseline results are provided for
informative purposes.
String permutation The first oracle system
under consideration is created by traversing
the string from left to right and unfolding all
crossing alignment links (we call this system
oracle-string). For example in Figure 2(a),
the oracle-string system generates a string ?do
so gladly? swapping the words ?do? and
?gladly? without considering the parse tree.
The first line of the table shows the performance
of the oracle-string system with monotone source
and target portions of the corpus.
Oracle under tree constraint We use a syntac-
tic parser for parsing the English source sentences
that provide n-ary constituency parses. Now we
constrain unfolding crossing alignments only to
those alignment links which agree with the struc-
ture of the source-side parse tree and consider the
constituents which include aligned tokens only.
Unfolding a crossing alignment is modeled as per-
muting the children of a node in the parse tree. We
refer to this oracle system as oracle-tree. For ex-
ample provided in Figure 2(b), there is no way to
construct a monotonized version of the sentence
since the word ?so? is aligned to NULL and im-
pedes swapping the order of VB and ADJP under
the VP.
Oracle under relaxed tree constraint The
oracle-tree system does not permute the words
which are both (1) not found in the alignment and
(2) are spanned by the sub-trees sibling to the re-
ordering constituents. Now we introduce a re-
laxed version of the parse tree constraint: the or-
der of the children of a node is permuted when
the node covers the reordering constituents and
also when the frontier contains leaf nodes aligned
with NULL (oracle-span). For example, in Fig-
ure 2(c) the English word ?so? is not aligned, but
according to the relaxed version, must move to-
gether with the word ?gladly? since they share
a parent node (ADJP).
Source BLEU NIST
baseline dist 24.04 6.29
baseline MSD 24.04 6.28
oracle? string 27.02 6.51
oracle? tree 24.09 6.30
oracle? span 24.95 6.37
Table 1: Translation scores of oracle systems.
The main conclusion which can be drawn from
the oracle results is that there is a possibility for
relatively big (?3 BLEU points) improvement
with complete unfolding of crossing alignments
and very limited (?0.05 BLEU points) with the
same done under the parse tree constraint. A tree-
based system that allows for permuting unaligned
words that are covered by a dominating parent
node shows more improvement in terms of BLEU
and NIST scores (?0.9 BLEU points).
The gap between oracle-string and oracle-tree
performance is due to alignment crossings which
95
cannot be unfolded under trees (illustrated in Fig-
ure 3), but possibly also due to parse and align-
ment errors.
Figure 3: Example of alignment crossing that does
not agree with the parse tree.
4.2 Source Permutation via Syntactic
Transfer
Given a parallel corpus with string pairs s ? t
with word alignment a, we create a source per-
muted parallel corpus s ? s? by unfolding the
crossing alignments in a: this is done by scanning
the string s from left to right and moving words in-
volved in crossing alignments to positions where
the crossing alignments are unfolded). The source
strings s are parsed, leading to a single parse tree
?s per source string.
Our model aims at learning from the source
permuted parallel corpus s ? s? a probabilistic
optimization argmaxpi(s) P (pi(s) | s, ?s). We as-
sume that the set of permutations {pi(s)} is de-
fined through a finite set of local transductions
over the tree ?s. Hence, we view the permutations
leading from s to s? as a sequence of local tree
transductions ?s?0 ? . . . ? ?s?n , where s
?
0 = s
and s?n = s? , and each transduction ?s?i?1 ? ?s?iis defined using a tree transduction operation that
at most permutes the children of a single node in
?s?i?1 as defined next.
A local transduction ?s?i?1 ? ?s?i is modelledby an operation that applies to a single node with
address x in ?s?i?1 , labeled Nx, and may permutethe ordered sequence of children ?x dominated by
node x. This constitutes a direct generalization of
the ITG binary inversion transduction operation.
We assign a conditional probability to each such
local transduction:
P (?s?i | ?s?i?1) ? P (pi(?x) | Nx ? ?x, Cx) (2)
where pi(?x) is a permutation of ?x (the ordered
sequence of node labels under x) and Cx is a local
tree context of node x in tree ?s?i?1 . One wrin-kle in this definition is that the number of possi-
ble permutations of ?x is factorial in the length
of ?x. Fortunately, the source permuted training
data exhibits only a fraction of possible permuta-
tions even for longer ?x sequences. Furthermore,
by conditioning the probability on local context,
the general applicability of the permutation is re-
strained.
Given this definition, we define the probabil-
ity of the sequence of local tree transductions
?s?0 ? . . . ? ?s?n as
P (?s?0 ? . . . ? ?s?n) =
n?
i=1
P (?s?i | ?s?i?1) (3)
The problem of calculating the most likely per-
mutation under this transduction model is made
difficult by the fact that different transduction se-
quences may lead to the same permutation, which
demands summing over these sequences. Fur-
thermore, because every local transduction condi-
tions on local context of an intermediate tree, this
quickly risks becoming intractable (even when we
use packed forests). In practice we take a prag-
matic approach and greedily select at every inter-
mediate point ?s?i?1 ? ?s?i the single most likelylocal transduction that can be conducted on any
node of the current intermediate tree ?s?i?1 usingan interpolation of the term in Equation 2 with
string probability ratios as follows:
P (pi(?x) | Nx ? ?x, Cx)?
P (s?i?1)
P (s?i)
The rationale behind this log-linear interpolation
is that our source permutation approach aims at
finding the optimal permutation s? of s that can
serve as input for a subsequent translation model.
Hence, we aim at tree transductions that are syn-
tactically motivated that also lead to improved
string permutation. In this sense, the tree trans-
duction definitions can be seen as an efficient and
96
syntactically informed way to define the space of
possible permutations.
We estimate the string probabilities P (s?i) us-
ing 5-gram language models trained on the s?
side of the source permuted parallel corpus s ?
s? . We estimate the conditional probability
P (pi(?x) | Nx ? ?x, Cx) using a Maximum-
Entropy framework, where feature functions are
defined to capture the permutation as a class, the
node label Nx and its head POS tag, the child
sequence ?x together with the corresponding se-
quence of head POS tags and other features corre-
sponding to different contextual information.
We were particularly interested in those linguis-
tic features that motivate reordering phenomena
from the syntactic and linguistic perspective. The
features that were used for training the permuta-
tion system are extracted for every internal node
of the source tree that has more than one child:
? Local tree topology. Sub-tree instances that
include parent node and the ordered se-
quence of child node labels.
? Dependency features. Features that deter-
mine the POS tag of the head word of the cur-
rent node, together with the sequence of POS
tags of the head words of its child nodes.
? Syntactic features. Three binary features
from this class describe: (1) whether the par-
ent node is a child of the node annotated with
the same syntactic category, (2) whether the
parent node is a descendant of the node an-
notated with the same syntactic category, and
(3) if the current subtree is embedded into a
?SENT-SBAR? sub-tree. The latter feature in-
tends to model the divergence in word order
in relative clauses between Dutch and En-
glish which is illustrated in Figure 1.
In initial experiments we piled up all feature func-
tions into a single model. Preliminary results
showed that the system performance increases if
the set of patterns is split into partial classes con-
ditioned on the current node label. Hence, we
trained four separate MaxEnt models for the cate-
gories with potentially high number of crossing
alignments, namely VP, NP, SENT, and SBAR.
For combinatory models we use the following no-
tations: M4 = ?i?[ NP, VP, SENT, SBAR] Mi and M2 =?
i?[VP, SENT] Mi.
5 Experiments and results
The SMT system used in the experiments was
implemented within the open-source MOSES
toolkit (Koehn et al, 2007). Standard train-
ing and weight tuning procedures which were
used to build our system are explained in details
on the MOSES web page1. The MSD model
was used together with a distance-based reorder-
ing model. Word alignment was estimated with
GIZA++ tool2 (Och, 2003), coupled with mk-
cls3 (Och, 1999), which allows for statistical word
clustering for better generalization. An 5-gram
target language model was estimated using the
SRI LM toolkit (Stolcke, 2002) and smoothed
with modified Kneser-Ney discounting. We use
the Stanford parser4 (Klein and Manning, 2003)
as a source-side parsing engine. The parser was
trained on the English treebank set provided with
14 syntactic categories and 48 POS tags. The
evaluation conditions were case-sensitive and in-
cluded punctuation marks. For Maximum En-
tropy modeling we used the maxent toolkit5.
Data The experiment results were obtained us-
ing the English-Dutch corpus of the European Par-
liament Plenary Session transcription (EuroParl).
Training corpus statistics can be found in Table 2.
Dutch English
Sentences 1.2 M 1.2 M
Words 32.9 M 33.0 M
Average sentence length 27.20 27.28
Vocabulary 228 K 104 K
Table 2: Basic statistics of the English-Dutch Eu-
roParl training corpus.
The development and test datasets were ran-
domly chosen from the corpus and consisted of
1http://www.statmt.org/moses/
2code.google.com/p/giza-pp/
3http://www.fjoch.com/mkcls.html
4http://nlp.stanford.edu/software/
lex-parser.shtml
5http://homepages.inf.ed.ac.uk/
lzhang10/maxent_toolkit.html
97
500 and 1,000 sentences, respectively. Both were
provided with one reference translation.
Results Evaluation of the system performance
is twofold. In the first step, we analyze the qual-
ity of reordering method itself. In the next step
we look at the automatic translation scores and
evaluate the impact which the choice of reorder-
ing strategy has on the translation quality. In
both stages of evaluation, the results are con-
trasted with the performance shown by the stan-
dard phrase-based SMT system (baseline) and
with oracle results.
Source reordering analysis Table 3 shows the
parameters of the reordered system allowing to as-
sess the effectiveness of reordering permutations,
namely: (1) a total number of crossings found in
the word alignment (#C), (2) the size of the re-
sulting phrase table (PT), (3) BLEU, NIST, and
WER scores obtained using monotonized parallel
corpus (oracle) as a reference.
All the numbers are calculated on the re-aligned
corpora. Calculations are done on the basis of the
100,000 line extraction from the corpus6 and cor-
responding alignment matrix. The baseline rows
show the number of alignment crossings found in
the original (unmonotonized) corpus.
System #C PT ScoresBLEU NIST WER
Oracle
string 54.6K 48.4M - - -
tree 187.3K 30.3M 71.73 17.01 16.77
span 146.9K 33.0M 73.41 17.11 15.73
Baselines
baselines 187.0K 29.8M 71.70 17.07 16.55
Category models
MNP 188.9K 29.7M 71.63 17.07 16.52
MV P 168.1K 29.8M 73.17 17.16 15.99
MSENT 171.0K 29.8M 73.08 17.08 16.10
MSBAR 188.6K 29.8M 72.89 16.90 16.41
Combinatory models
M4 193.2K 29.1M 70.98 16.85 16.78
M2 165.4K 29.9M 73.07 16.92 15.88
Table 3: Main parameters of the tree-based re-
ordering system.
6A smaller portion of the corpus is used for analysis in
order to reduce evaluation time.
Translation scores The evaluation results for
the development and test corpora are reported in
Table 4. They include two baseline configurations
(dist and MSD), oracle results and contrasts them
with the performance shown by different combi-
nations of single-category tree-based reordering
models. Best scores within each experimental sec-
tion are placed in cells filled with grey.
System Dev TestBLEU BLEU NIST
baseline dist 23.88 24.04 6.29
baseline MSD 24.07 24.04 6.28
oracle-string 26.28 27.02 6.50
oracle-tree 23.84 24.09 6.30
oracle-span 24.79 24.95 6.35
MNP 23.79 23.81 6.27
MV P 24.16 24.55 6.29
MSENT 24.27 24.56 6.32
MSBAR 23.99 24.12 6.27
M4 23.50 23.86 6.29
M2 24.28 24.64 6.33
Table 4: Experimental results.
Analysis The number of crossings
found in word alignment intersection and
BLEU/NIST/WER scores estimated on reordered
data vs. monotonized data report the reordering
algorithm effectiveness. A big gap between num-
ber of crossings and total number of reorderings
per corpus found in oracle-string system7 and
baseline systems demonstrates the possible reduc-
tion of system?s non-monotonicity. The difference
in number of crossings and BLEU/NIST/WER
scores between the oracle-span and the best
performing MaxEnt models (namely, M2) shows
the level of performance of the prediction module.
A number of distinct phrase translation pairs in
the translation table implicitly reveals the general-
ization capabilities of the translation system since
it simplifies the translation task. From the other
hand, increased number of shorter phrases can add
noise in the reordered data and makes decoding
more complex. Hence, the size of phrase table it-
self can not be considered as a robust indicator of
its translation potential.
7The number of crossings for oracle configuration is not
zero since this parameter is calculated on the re-aligned cor-
pus.
98
Table 4 shows that three of six MaxEnt re-
ordering systems outperform baseline systems by
about 0.5-0.6 BLEU points, that is statistically
significant8. The combination of NP, NP, SENT,
and SBAR models do not show good performance
possibly due to increased sparseness of reorder-
ing patterns. However, the system that consider
only the MV P and MSENT models achieves 0.62
BLEU score gain over the baseline configurations.
The main conclusion which can be drawn from
analysis of Tables 3 and 4 is that there is an
evident correlation between characteristics of re-
ordering system and performance demonstrated
by the translation system trained on the corpus
with reordered source part.
Example Figure 4 exemplifies the sentences
that presumably benefits from the monotonization
of the source part of the parallel corpus. The ex-
ample demonstrates a pervading syntactic distinc-
tion between English and Dutch: the reordering of
verb-phrase subconstituents VP NP PP within the
relative clause into PP NP VP.
6 Conclusions and future work
We introduced a tree-based reordering model that
aims at monotonizing the word order of source
8All statistical significance calculations are done for a
95% confidence interval and 1 000 resamples, following the
guidelines from (Koehn, 2004).
and target languages as a pre-translation step. Our
model avoids complete generalization of reorder-
ing instances by using tree contexts and limit-
ing the permutations to data instances. From a
learning perspective, our work shows that navigat-
ing a large space of intermediate tree transforma-
tions can be conducted effectively using both the
source-side syntactic tree and a language model
of the idealized (target-like) source-permuted lan-
guage.
We have shown the potential for translation
quality improvement when target sentences are
created following the source language word or-
der (?3 BLEU points over the standard phrase-
based SMT) and under parse tree constraint (?0.9
BLEU points). As can be seen from these re-
sults, our model exhibits competitive translation
performance scores compared with the standard
distance-based and lexical reordering.
The gap between the oracle and our system?s
results leaves room for improvement. We intend
to study extensions of the current tree transfer
model to narrow this performance gap. As a first
step we are combining isolated models for con-
crete syntactic categories and aggregating more
features into the MaxEnt model. Algorithmic im-
provements, such as beam-search and chart pars-
ing, could allow us to apply our method to full
parse-forests as opposed to a single parse tree.
(a) Original parse tree. (b) Reordered parse tree.
Src: that ... to lead the Commission during the next five-year term
Ref.: dat ... om de komende vijf jaar de Commissie te leiden
Baseline MSD: dat ... om het voortouw te nemen in de Commissie tijdens de komende vijf jaar
Rrd src: that ... during the next five-year term the Commission to lead
M2 : dat ... om de Commissie tijdens de komende vijf jaar te leiden
(c) Translations.
Figure 4: Example of tree-based monotonization.
99
References
D. Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings
of ACL?05, pages 263?270.
M. Collins, P. Koehn, and I. Kuc?erova?. 2005. Clause
restructuring for statistical machine translation. In
Proceedings of ACL?05, pages 531?540.
M. R. Costa-jussa` and J. A. R. Fonollosa. 2006.
Statistical machine reordering. In Proceedings of
HLT/EMNLP?06, pages 70?76.
M. Galley and Ch. D. Manning. 2008. A simple and
effective hierarchical phrase reordering model. In
Proceedings of EMNLP?08, pages 848?856.
M. Galley, J. Graehl, K. Knight, D. Marcu, S. De-
Neefe, W. Wang, and I. Thaye. 2006. Scalable in-
ference and training of context-rich syntactic trans-
lation models. In Proc. of COLING/ACL?06, pages
961?968.
M. Khalilov and K. Sima?an. 2010. Source reordering
using maxent classifiers and supertags. In Proc. of
EAMT?10, pages 292?299.
M. Khalilov. 2009. New statistical and syntactic mod-
els for machine translation. Ph.D. thesis, Universi-
tat Polite`cnica de Catalunya, October.
D. Klein and C. Manning. 2003. Accurate unlexi-
calized parsing. In Proceedings of the 41st Annual
Meeting of the ACL?03, pages 423?430.
Ph. Koehn, F. Och, and D. Marcu. 2003. Statistical
phrase-based machine translation. In Proceedings
of the HLT-NAACL 2003, pages 48?54.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: open-source
toolkit for statistical machine translation. In Pro-
ceedings of ACL 2007, pages 177?180.
Ph. Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP?04, pages 388?395.
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical ma-
chine translation. In Proceedings of ACL?02, pages
295?302.
F. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Compu-
tational Linguistics, 30(4):417?449.
F. Och. 1999. An efficient method for determin-
ing bilingual word classes. In Proceedings of ACL
1999, pages 71?76.
F. Och. 2003. Minimum error rate training in statisti-
cal machine translation. In Proceedings of ACL?03,
pages 160?167.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of ACL?02, pages 311?
318.
A. PVS. 2010. A data mining approach to
learn reorder rules for SMT. In Proceedings of
NAACL/HLT?10, pages 52?57.
A. Stolcke. 2002. SRILM: an extensible language
modeling toolkit. In Proceedings of SLP?02, pages
901?904.
C. Tillman. 2004. A unigram orientation model for
statistical machine translation. In Proceedings of
HLT-NAACL?04, pages 101?104.
C. Tillmann and H. Ney. 2003. Word reordering and
a dynamic programming beam search algorithm for
statistical machine translation. Computational Lin-
guistics, 1(29):93?133.
R. Tromble and J. Eisner. 2009. Learning linear order-
ing problems for better translation. In Proceedings
of EMNLP?09, pages 1007?1016.
C. Wang, M. Collins, and Ph. Koehn. 2007. Chinese
syntactic reordering for statistical machine transla-
tion. In Proceedings of EMNLP-CoNLL?07, pages
737?745.
D. Wu and H. Wong. 1998. Machine translation wih a
stochastic grammatical channel. In Proceedings of
ACL-COLING?98, pages 1408?1415.
F. Xia and M. McCord. 2004. Improving a statistical
MT system with automatically learned rewrite pat-
terns. In Proceedings of COLING?04, pages 508?
514.
D. Xiong, Q. Liu, and S. Lin. 2006. Maximum en-
tropy based phrase reordering model for statistical
machine translation. In Proceedings of ACL?06,
pages 521?528.
R. Zens and H. Ney. 2003. A comparative study on
reordering constraints in statistical machine transla-
tion. In Proceedings of ACL?03, pages 144?151.
R. Zens, F. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Proceedings of KI:
Advances in Artificial Intelligence, pages 18?32.
A. Zollmann and A. Venugopal. 2006. Syntax aug-
mented machine translation via chart parsing. In
Proceedings of NAACL?06, pages 138?141.
100
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 413?419,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
ILLC-UvA translation system for EMNLP-WMT 2011
Maxim Khalilov and Khalil Sima?an
Institute for Logic, Language and Computation
University of Amsterdam
P.O. Box 94242
1090 GE Amsterdam, The Netherlands
{m.khalilov,k.simaan}@uva.nl
Abstract
In this paper we describe the Institute for
Logic, Language and Computation (Uni-
versity of Amsterdam) phrase-based statisti-
cal machine translation system for English-
to-German translation proposed within the
EMNLP-WMT 2011 shared task. The main
novelty of the submitted system is a syntax-
driven pre-translation reordering algorithm
implemented as source string permutation via
transfer of the source-side syntax tree.
1 Introduction
For the WMT 2011 shared task, ILLC-UvA submit-
ted two translations (primary and secondary) for the
English-to-German translation task. This year, we
directed our research toward addressing the word
order problem for statistical machine translation
(SMT) and discover its impact on output translation
quality. We reorder the words of a sentence of the
source language with respect to the word order of
the target language and a given source-side parse
tree. The difference from the baseline Moses-based
translation system lies in the pre-translation step, in
which we introduce a discriminative source string
permutation model based on probabilistic parse tree
transduction.
The idea here is to permute the order of the source
words in such a way that the resulting permutation
allows as monotone a translation process as possible
is not new. This approach to enhance SMT by using
a reordering step prior to translation has proved to be
successful in improving translation quality for many
translation tasks, see (Genzel, 2010; Costa-jussa` and
Fonollosa, 2006; Collins et al, 2005), for example.
The general problem of source-side reordering is
that the number of permutations is factorial in n, and
learning a sequence of transductions for explaining
a source permutation can be computationally rather
challenging. We propose to address this problem by
defining the source-side permutation process as the
learning problem of how to transfer a given source
parse tree into a parse tree that minimizes the diver-
gence from target word order.
Our reordering system is inspired by the direction
taken in (Tromble and Eisner, 2009), but differs in
defining the space of permutations, using local prob-
abilistic tree transductions, as well as in the learn-
ing objective aiming at scoring permutations based
on a log-linear interpolation of a local syntax-based
model with a global string-based (language) model.
The reordering (novel) and translation (standard)
components are described in the following sections.
The rest of this paper is structured as follows. After a
brief description of the phrase-based translation sys-
tem in Section 2, we present the architecture and de-
tails of our reordering system (Section 3), Section 4
reviews related work, Section 5 reports the experi-
mental setup, details the submissions and discusses
the results, while Section 6 concludes the article.
2 Baseline system
2.1 Statistical machine translation
In SMT the translation problem is formulated as se-
lecting the target translation t with the highest prob-
ability from a set of target hypothesis sentences for
413
the source sentence s: t? = argmaxt { p(t|s) } =
argmaxt { p(s|t) ? p(t) }.
2.2 Phrase-based translation
While first systems following this approach per-
formed translation on the word level, modern state-
of-the-art phrase-based SMT systems (Och and Ney,
2002; Koehn et al, 2003) start-out from a word-
aligned parallel corpus working with (in principle)
arbitrarily large phrase pairs (also called blocks) ac-
quired from word-aligned parallel data under a sim-
ple definition of translational equivalence (Zens et
al., 2002).
The conditional probabilities of one phrase given
its counterpart is estimated as the relative frequency
ratio of the phrases in the multiset of phrase-pairs
extracted from the parallel corpus and are interpo-
lated log-linearly together with a set of other model
estimates:
e?I1 = argmaxeI1
{ M?
m=1
?mhm(eI1, fJ1 )
}
(1)
where a feature function hm refer to a system model,
and the corresponding ?m refers to the relative
weight given to this model.
A phrase-based system employs feature func-
tions for a phrase pair translation model, a lan-
guage model, a reordering model, and a model
to score translation hypothesis according to length.
The weights ?m are optimized for system perfor-
mance (Och, 2003) as measured by BLEU (Papineni
et al, 2002).
Apart from the novel syntax-based reordering
model, we consider two reordering methods that
are widely used in phrase-based systems: a simple
distance-based reordering and a lexicalized block-
oriented data-driven reordering model (Tillman,
2004).
3 Architecture of the reordering system
We approach the word order challenge by including
syntactic information in a pre-translation reordering
framework. This section details the general idea of
our approach and details the reordering model that
was used in English-to-German experiments.
3.1 Pre-translation reordering framework
Given a word-aligned parallel corpus, we define the
source string permutation as the task of learning
to unfold the crossing alignments between sentence
pairs in the parallel corpus. Let be given a source-
target sentence pair s ? t with word alignment set
a between their words. Unfolding the crossing in-
stances in a should lead to as monotone an align-
ment a? as possible between a permutation s? of s
and the target string t. Conducting such a ?mono-
tonization? on the parallel corpus gives two par-
allel corpora: (1) a source-to-permutation parallel
corpus (s ? s?) and (2) a source permutation-to-
target parallel corpus (s? ? t). The latter corpus is
word-aligned automatically again and used for train-
ing a phrase-based translation system, while the for-
mer corpus is used for training our model for pre-
translation source permutation via parse tree trans-
ductions.
In itself, the problem of permuting the source
string to unfold the crossing alignments is com-
putationally intractable (see (Tromble and Eisner,
2009)). However, different kinds of constraints can
be made on unfolding the crossing alignments in a.
A common approach in hierarchical SMT is to as-
sume that the source string has a binary parse tree,
and the set of eligible permutations is defined by bi-
nary ITG transductions on this tree. This defines
permutations that can be obtained only by at most
inverting pairs of children under nodes of the source
tree.
3.2 Conditional tree reordering model
Given a parallel corpus with string pairs s ? t with
word alignment a, the source strings s are parsed,
leading to a single parse tree ?s per source string. We
create a source permuted parallel corpus s ? s? by
unfolding the crossing alignments in a without/with
syntactic tree to provide constraints on the unfold-
ing.
Our model aims at learning from the source per-
muted parallel corpus s ? s? a probabilistic op-
timization argmaxpi(s) P (pi(s) | s, ?s). We as-
sume that the set of permutations {pi(s)} is defined
through a finite set of local transductions over the
tree ?s. Hence, we view the permutations leading
from s to s? as a sequence of local tree transduc-
414
tions ?s?0 ? . . . ? ?s?n , where s
?
0 = s and s
?
n = s
? ,
and each transduction ?s?i?1 ? ?s?i is defined using a
tree transduction operation that at most permutes the
children of a single node in ?s?i?1 as defined next.A local transduction ?s?i?1 ? ?s?i is modelled byan operation that applies to a single node with ad-
dress x in ?s?i?1 , labeled Nx, and may permute theordered sequence of children ?x dominated by node
x. This constitutes a direct generalization of the ITG
binary inversion transduction operation. We assign a
conditional probability to each such local transduc-
tion:
P (?s?i | ?s?i?1) ? P (pi(?x) | Nx ? ?x, Cx) (2)
where pi(?x) is a permutation of ?x (the ordered
sequence of node labels under x) and Cx is a lo-
cal tree context of node x in tree ?s?i?1 . One wrin-kle in this definition is that the number of possible
permutations of ?x is factorial in the length of ?x.
Fortunately, the source permuted training data ex-
hibits only a fraction of possible permutations even
for longer ?x sequences. Furthermore, by condition-
ing the probability on local context, the general ap-
plicability of the permutation is restrained.
In principle, if we would disregard the computa-
tional cost, we could define the probability of the se-
quence of local tree transductions ?s?0 ? . . . ? ?s?nas
P (?s?0 ? . . . ? ?s?n) =
n?
i=1
P (?s?i | ?s?i?1) (3)
The problem of calculating the most likely permu-
tation under this kind of transduction probability
is intractable because every local transduction con-
ditions on local context of an intermediate tree1.
Hence, we disregard this formulation and in practice
we take a pragmatic approach and greedily select at
every intermediate point ?s?i?1 ? ?s?i the single mostlikely local transduction that can be conducted on
any node of the current intermediate tree ?s?i?1 . The
1Note that a single transduction step on the current tree
?s?i?1 leads to a forest of trees ?s?i because there can be mul-
tiple alternative transduction rules. Hence, this kind of a model
demands optimization over many possible sequences of trees,
which can be packed into a sequence of parse-forests with trans-
duction links between them.
individual steps are made more effective by interpo-
lating the term in Equation 2 with string probability
ratios:
P (pi(?x) | Nx ? ?x, Cx)?
(
P (s?i?1)
P (s?i)
)
(4)
The rationale behind this interpolation is that our
source permutation approach aims at finding the op-
timal permutation s? of s that can serve as input for
a subsequent translation model. Hence, we aim at
tree transductions that are syntactically motivated
that also lead to improved string permutations. In
this sense, the tree transduction definitions can be
seen as an efficient and syntactically informed way
to define the space of possible permutations.
We estimate the string probabilities P (s?i) using
5-gram language models trained on the s? side of
the source permuted parallel corpus s ? s? . We es-
timate the conditional probability P (pi(?x) | Nx ?
?x, Cx) using a Maximum-Entropy framework,
where feature functions are defined to capture the
permutation as a class, the node label Nx and its
head POS tag, the child sequence ?x together with
the corresponding sequence of head POS tags and
other features corresponding to different contextual
information.
We were particularly interested in those linguistic
features that motivate reordering phenomena from
the syntactic and linguistic perspective. The features
that were used for training the permutation system
are extracted for every internal node of the source
tree that has more than one child:
? Local tree topology. Sub-tree instances that in-
clude parent node and the ordered sequence of
child node labels.
? Dependency features. Features that determine
the POS tag of the head word of the current
node, together with the sequence of POS tags
of the head words of its child nodes.
? Syntactic features. Two binary features from
this class describe: (1) whether the parent node
is a child of the node annotated with the same
syntactic category, (2) whether the parent node
is a descendant of a node annotated with the
same syntactic category.
415
4 Related work
The integration of linguistic syntax into SMT sys-
tems offers a potential solution to reordering prob-
lem. For example, syntax is successfully integrated
into hierarchical SMT (Zollmann and Venugopal,
2006). In (Yamada and Knight, 2001), a set of tree-
string channel operations is defined over the parse
tree nodes, while reordering is modeled by permuta-
tions of children nodes. Similarly, the tree-to-string
syntax-based transduction approach offers a com-
plete translation framework (Galley et al, 2006).
The idea of augmenting SMT by a reordering step
prior to translation has often been shown to improve
translation quality. Clause restructuring performed
with hand-crafted reordering rules for German-to-
English and Chinese-to-English tasks are presented
in (Collins et al, 2005) and (Wang et al, 2007), re-
spectively. In (Xia and McCord, 2004; Khalilov,
2009) word reordering is addressed by exploiting
syntactic representations of source and target texts.
In (Costa-jussa` and Fonollosa, 2006) source and
target word order harmonization is done using well-
established SMT techniques and without the use of
syntactic knowledge. Other reordering models op-
erate provide the decoder with multiple word or-
ders. For example, the MaxEnt reordering model
described in (Xiong et al, 2006) provides a hierar-
chical phrasal reordering system integrated within
a CKY-style decoder. In (Galley and Manning,
2008) the authors present an extension of the famous
MSD model (Tillman, 2004) able to handle long-
distance word-block permutations. Coming up-to-
date, in (PVS, 2010) an effective application of data
mining techniques to syntax-driven source reorder-
ing for MT is presented.
Different syntax-based reordering systems can be
found in (Genzel, 2010). In this system, reorder-
ing rules capable to capture many important word
order transformations are automatically learned and
applied in the preprocessing step.
Recently, Tromble and Eisner (Tromble and Eis-
ner, 2009) define source permutation as the word-
ordering learning problem; the model works with a
preference matrix for word pairs, expressing pref-
erence for their two alternative orders, and a cor-
responding weight matrix that is fit to the parallel
data. The huge space of permutations is then struc-
tured using a binary synchronous context-free gram-
mar (Binary ITG) with O(n3) parsing complexity,
and the permutation score is calculated recursively
over the tree at every node as the accumulation of
the relative differences between the word-pair scores
taken from the preference matrix. Application to
German-to-English translation exhibits some perfor-
mance improvement.
5 Experiments and submissions
Design, architecture and configuration of the trans-
lation system that we used in experimentation co-
incides with the Moses-based translation system
(Baseline system) described in details on the
WMT 2011 web page2.
This section details the experiments carried out to
evaluate the proposed reordering model, experimen-
tal set-up and data.
5.1 Data
In our experiments we used EuroParl v6.0 German-
English parallel corpus provided by the organizers
of the evaluation campaign.
A detailed statistics of the training, development,
internal (test int.) and official (test of.) test datasets
can be found in Table 1. The development corpus
coincides with the 2009 test set and for internal test-
ing we used the test data proposed to the participants
of WMT 2010.
?ASL? stands for average sentence length. All the
sets were provided with one reference translation.
Data Sent. Words Voc. ASL
train En 1.7M 46.0M 121.3K 27.0
train Ge 1.7M 43.7M 368.5K 25.7
dev En 2.5K 57.6K 13.2K 22.8
test int. En 2.5K 53.2K 15.9K 21.4
test of. En 3.0K 74.8K 11.1K 24.9
Table 1: German-English EuroParl corpus (version 6.0).
Apart from the German portion of the EuroParl
parallel corpus, two additional monolingual corpora
from news domain (the News Commentary corpus
(NC) and the News Crawl Corpus 2011 (NS)) were
2http://www.statmt.org/wmt11/baseline.
html
416
used to train a language model for German. The
characteristics of these datasets can be found in Ta-
ble 2. Notice that the data were not de-duplicated.
Data Sent. Words Voc. ASL
NC Ge 161.8M 3.9G 136.7M 23.9
NS Ge 45.3M 799.4M 3.0M 17.7
Table 2: Monolingual German corpora used for target-
side language modeling.
5.2 Experimental setup
Moses toolkit (Koehn et al, 2007) in its standard
setting was used to build the SMT systems:
? GIZA++/mkcls (Och, 2003; Och, 1999) for
word alignment.
? SRI LM (Stolcke, 2002) for language model-
ing. A 3-gram target language model was es-
timated and smoothed with modified Kneser-
Ney discounting.
? MOSES (Koehn et al, 2007) to build an un-
factored translation system.
? the Stanford parser (Klein and Manning,
2003) was used as a source-side parsing en-
gine3.
? For maximum entropy modeling we used the
maxent toolkit4.
The discriminative syntactic reordering model is
applied to reorder training, development, and test
corpora. A Moses-based translation system (corpus
realignment included5) is then trained using the re-
ordered input.
5.3 Internal results and submissions
The outputs of two translation system were submit-
ted. First, we piled up all feature functions into a sin-
gle model as described in Section 3. It was our ?sec-
ondary? submission. However, our experience tells
3The parser was trained on the English treebank set provided
with 14 syntactic categories and 48 POS tags.
4http://homepages.inf.ed.ac.uk/lzhang10/
maxent_toolkit.html
5Some studies show that word re-alignment of a mono-
tonized corpus gives better results than unfolding of alignment
crossings (Costa-jussa` and Fonollosa, 2006).
that the system performance can increase if the set
of patterns is split into partial classes conditioned on
the current node label (Khalilov and Sima?an, 2010).
Hence, we trained three separate MaxEnt models for
the categories with potentially high reordering re-
quirements, namely NP , SENT and SBAR(Q).
It was defines as our ?primary? submission.
The ranking of submission was done according to
the results shown on internal testing, shown in Ta-
ble 3.
System BLEU dev BLEU test NIST test
Baseline 11.03 9.78 3.78
Primary 11.07 10.00 3.79
Secondary 10.92 9.91 3.78
Table 3: Internal testing results.
5.4 Official results and discussion
Unfortunately, the results of our participation this
year were discouraging. The primary submission
was ranked 30th (12.6 uncased BLEU-4) and the
secondary 31th (11.2) out of 32 submitted systems.
It turned out that our preliminary idea to extrapo-
late the positive results of English-to-Dutch transla-
tion reported in (Khalilov and Sima?an, 2010) to the
WMT English-to-German translation task was not
right.
Analyzing the reasons of negative results during
the post-evaluation period, we discovered that trans-
lation into German differs from English-to-Dutch
task in many cases. In contrast to English-to-Dutch
translation, the difference in terms of automatic
scores between the internal baseline system (without
external reordering) and the system enhanced with
the pre-translation reordering is minimal. It turns
out that translating into German is more complex
in general and discriminative reordering is more ad-
vantageous for English-to-Dutch than for English-
to-German translation.
A negative aspect influencing is the way how the
rules are extracted and applied according to our ap-
proach. Syntax-driven reordering, as described in
this paper, involves large contextual information ap-
plied cumulatively. Under conditions of scarce data,
alignment and parsing errors, it introduces noise to
the reordering system and distorts the feature prob-
417
ability space. At the same time, many reorderings
can be performed more efficiently based on fixed
(hand-crafted) rules (as it is done in (Collins et al,
2005)). A possible remedy to this problem is to
combine automatically extracted features with fixed
(hand-crafted) rules. Our last claims are supported
by the observations described in (Visweswariah et
al., 2010).
During post-evaluation period we analyzed the
reasons why the system performance has slightly
improved when separate MaxEnt models are ap-
plied. The outline of reordered nodes for
each of syntactic categories considered (SENT ,
SBAR(Q) and NP ) can be found in Table 4 (the
size of the corpus is 1.7 M of sentences).
Category # of applications
NP 497,186
SBAR(Q) 106,243
SENT 221,568
Table 4: Application of reorderings for separate syntactic
categories.
It is seen that the reorderings for NP nodes is
higher than for SENT and SBAR(Q) categories.
While SENT and SBAR(Q) reorderings work anal-
ogously for Dutch and German, our intuition is that
German has more features that play a role in reorder-
ing of NP structures than Dutch and there is a need
of more specific features to model NP permutations
in an accurate way.
6 Conclusions
This paper presents the ILLC-UvA translation sys-
tem for English-to-German translation task pro-
posed to the participants of the EMNLP-WMT 2011
evaluation campaign. The novel feature that we
present this year is a source reordering model in
which the reordering decisions are conditioned on
the features from the source parse tree.
Our system has not managed to outperform the
majority of the participating systems, possibly due
to its generic approach to reordering. We plan to in-
vestigate why our approach works well for English-
to-Dutch and less well for the English-to-German
translation in order to discover more generic ways
for learning discriminative reordering rules. One
possible explanation of the bad results is a high
sparseness of automatically extracted rules that does
not allow for sufficient generalization of reordering
instances.
In the future, we plan (1) to perform deeper anal-
ysis of the dissimilarity between English-to-Dutch
and English-to-German translations from SMT
perspective, and (2) to investigate linguistically-
motivated ideas to extend our model such that we
can bring about some improvement to English-to-
German translation.
7 Acknowledgements
Both authors are supported by a VIDI grant (nr.
639.022.604) from The Netherlands Organization
for Scientific Research (NWO).
References
M. Collins, P. Koehn, and I. Kuc?erova?. 2005. Clause re-
structuring for statistical machine translation. In Pro-
ceedings of ACL?05, pages 531?540.
M. R. Costa-jussa` and J. A. R. Fonollosa. 2006.
Statistical machine reordering. In Proceedings of
HLT/EMNLP?06, pages 70?76.
M. Galley and Ch. D. Manning. 2008. A simple and ef-
fective hierarchical phrase reordering model. In Pro-
ceedings of EMNLP?08, pages 848?856.
M. Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe,
W. Wang, and I. Thaye. 2006. Scalable inference and
training of context-rich syntactic translation models.
In Proc. of COLING/ACL?06, pages 961?968.
D. Genzel. 2010. Aumotatically learning source-side re-
ordering rules for large scale machine translation. In
Proc. of COLING?10, pages 376?384, Beijing, China.
M. Khalilov and K. Sima?an. 2010. A discriminative
syntactic model for source permutation via tree trans-
duction. In Proc. of the Fourth Workshop on Syn-
tax and Structure in Statistical Translation (SSST-4) at
COLING?10, pages 92?100, Beijing (China), August.
M. Khalilov. 2009. New statistical and syntactic mod-
els for machine translation. Ph.D. thesis, Universitat
Polite`cnica de Catalunya, October.
D. Klein and C. Manning. 2003. Accurate unlexicalized
parsing. In Proceedings of the 41st Annual Meeting of
the ACL?03, pages 423?430.
Ph. Koehn, F. Och, and D. Marcu. 2003. Statistical
phrase-based machine translation. In Proceedings of
the HLT-NAACL 2003, pages 48?54.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
418
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: open-source toolkit for
statistical machine translation. In Proceedings of ACL
2007, pages 177?180.
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. In Proceedings of ACL?02, pages 295?
302.
F. Och. 1999. An efficient method for determining bilin-
gual word classes. In Proceedings of ACL 1999, pages
71?76.
F. Och. 2003. Minimum error rate training in statistical
machine translation. In Proceedings of ACL?03, pages
160?167.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of ACL?02, pages 311?
318.
A. PVS. 2010. A data mining approach to learn reorder
rules for SMT. In Proceedings of NAACL/HLT?10,
pages 52?57.
A. Stolcke. 2002. SRILM: an extensible language mod-
eling toolkit. In Proceedings of SLP?02, pages 901?
904.
C. Tillman. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL?04, pages 101?104.
R. Tromble and J. Eisner. 2009. Learning linear order-
ing problems for better translation. In Proceedings of
EMNLP?09, pages 1007?1016.
K. Visweswariah, J. Navratil, J. Sorensen, V. Chenthama-
rakshan, and N. Kambhatla. 2010. Syntax based
reordering with automatically derived rules for im-
proved statistical machine translation. In Proc. of
COLING?10, pages 1119?1127, Beijing, China.
C. Wang, M. Collins, and Ph. Koehn. 2007. Chinese
syntactic reordering for statistical machine translation.
In Proceedings of EMNLP-CoNLL?07, pages 737?745.
F. Xia and M. McCord. 2004. Improving a statistical MT
system with automatically learned rewrite patterns. In
Proceedings of COLING?04, pages 508?514.
D. Xiong, Q. Liu, and S. Lin. 2006. Maximum entropy
based phrase reordering model for statistical machine
translation. In Proceedings of ACL?06, pages 521?
528.
K. Yamada and K. Knight. 2001. A syntax-based sta-
tistical translation model. In Proceedings of ACL?01,
pages 523?530.
R. Zens, F. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Proceedings of KI: Ad-
vances in Artificial Intelligence, pages 18?32.
A. Zollmann and A. Venugopal. 2006. Syntax aug-
mented machine translation via chart parsing. In Pro-
ceedings of NAACL?06, pages 138?141.
419
Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, page 69,
Gothenburg, Sweden, April 27, 2014. c?2014 Association for Computational Linguistics
Machine translation for LSPs: strategy and implementation 
 
Maxim Khalilov 
 
bmmt GmbH 
 
Alt-Moabit 92 
10559 Berlin 
Germany 
maxim.khalilov@machine-
translation.eu 
  
 
Abstract 
Over the last few years, machine translation (MT) has transformed from an academic research 
platform into a productivity or gisting tool adopted by several end users. In this talk, I will describe 
some of the business and technical MT-related challenges faced by language service providers 
nowadays. I will describe the approach we take at bmmt GmbH to create innovative industry solutions 
driven by MT. 
69
