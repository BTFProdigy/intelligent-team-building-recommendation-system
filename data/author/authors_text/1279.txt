Chinese Deterministic Dependency Analyzer: Examining Effects of 
Global Features and Root Node Finder 
Yuchang CHENG, Masayuki ASAHARA and Yuji MATSUMOTO 
Nara Institute of Science and Technology
8916-5 Takayama, Ikoma, Nara 630-0192, Japan 
{yuchan-c, masayu-a, matsu}@is.naist.jp
Abstract
We present a method for improving 
dependency structure analysis of Chi-
nese. Our bottom-up deterministic ana-
lyzer adopt Nivre?s algorithm (Nivre 
and Scholz, 2004). Support Vector Ma-
chines (SVMs) are utilized to deter-
mine the word dependency relations. 
We find that there are two problems in 
our analyzer and propose two methods 
to solve them. One problem is that 
some operations cannot be solved only 
using local feature. We utilize the 
global features to solve this. The other 
problem is that this bottom-up analyzer 
doesn?t use top-down information. We 
supply the top-down information by 
constructing SVMs based root node 
finder to solve this problem. Experi-
mental evaluation on the Penn Chinese 
Treebank Corpus shows that the pro-
posed extensions improve the parsing 
accuracy significantly. 
1 Introduction 
Many syntactic analyzers for English have been 
implemented and have demonstrated good per-
formance (Charniak, 2000; Collins, 1997; Rat-
naparkhi, 1999). However, implementation of 
Chinese syntactic structure analyzers is still lim-
ited, since the structure of the Chinese language 
is quite different from other languages. There-
fore the experience in processing western lan-
guages cannot be guaranteed that it can apply to 
Chinese language directly (Lee, 1991). Chinese 
language has many special syntactic phenomena 
substantially different from western languages. 
Discussions about such characteristics of Chi-
nese language can be found in the literature 
(Chao 1968; Li and Thompson 1981; Huang 
1982).
About the previous work of Chinese depend-
ency structure analysis, Zhou proposed a rule 
based approach (Zhou, 2000). Lai et al pro-
posed a span-based statistical probability ap-
proach (Lai, 2001). Ma et al proposed a statistic 
dependency parser by using probabilistic model 
(Ma, 2004). Using machine learning-based ap-
proaches for dependency analysis of Chinese is 
still limited. In this paper, we propose a deter-
ministic Chinese syntactic structure analyzer by 
using global features and a root node finder.  
Our analyzer is a dependency structure ana-
lyzer. We utilize a deterministic method for de-
pendency relation construction. First, a 
dependency relation matrix is constructed, in 
which each element corresponds to a pair of to-
kens. A likelihood value is assigned to the de-
pendency relation of each pair of tokens.  
Second, the optimal dependency structure is es-
timated using the likelihood of the whole sen-
tence, provided there is no crossing between 
dependencies. A bottom-up algorithm proposed 
by (Nivre and Scholz, 2004) is use for a deter-
ministic dependency structure analysis. Our de-
pendency relations are composed by machine 
learners. SVMs (Vapnik, 1998) deterministically 
estimate if there is a dependency relation be-
tween a pair of words in the methods. 
However, this method has two problems. First, 
some operations in the algorithm needs long 
distance information. However, the long dis-
tance information cannot be available if we as-
sume a context of a fixed size in all operations. 
17
The second problem is that the top-down infor-
mation isn?t used in the bottom-up approach. 
We use the global features to solve the first 
problem and we construct a SVM-based root 
node finder in our system to supplement the top-
down information. 
Our analyzer is trained on the Penn Chinese 
Treebank 5.0 (Xue et al, 2002), which is a phrase 
structure annotated corpus. The phrase structure 
is converted into a dependency structure accord-
ing to the head rules. We perform experimental 
evaluation in several settings on this corpus. 
In the next section, we describe our determi-
nistic dependency structure analysis algorithm. 
Section 3 shows the global features and the two-
step process. Section 4 describes the use of the 
root node finder. Section 5 describes the ex-
perimental setting and the results. Finally, we 
summarize our findings in the conclusion. 
2 Parsing method 
This chapter presents a basic parsing algorithm 
proposed by (Nivre and Scholz, 2004). The al-
gorithm is the base of our dependency analyzer. 
This algorithm is based on a deterministic ap-
proach, in which the dependency relations are 
constructed by a bottom-up deterministic 
schema. While Nivre?s method uses memory-
based learning, we use SVMs instead. The algo-
rithm consists of two major procedures:  
(i) Extract the surrounding features for the 
focused node (or node pair). 
(ii) Estimate the dependency relation opera-
tion for the focused node by a machine 
learning method. 
Example: ???????????? (The great triumph that Cheng Cheng-Kung recaptured Taiwan.)
Fig. 1. The operations of the Nivre algorithm
??
recaptured
VV
???
(name)
NR
S I
??
recaptured
VV
???
(name)
NR
S I
Right
S I
??
recaptured
VV
???
(name)
NR
S I
Left
S I S I
Reduce
S I S I
Shift
??
recaptured
VV
???
(name)
NR
??
Taiwan
NR
??
Taiwan
NR
??
recaptured
VV
???
(name)
NR
??
Taiwan
NR
??
recaptured
VV
???
(name)
NR
??
Taiwan
NR
?
DE
DEG
?
DE
DEG
??
recaptured
VV
???
(name)
NR
??
Taiwan
NR
??
recaptured
VV
???
(name)
NR
??
Taiwan
NR
??
great
VA
?
DE
DEG
??
great
VA
?
DE
DEG
??
Triumph
NN
??
great
VA
??
great
VA
?
DE
DEG
?
DE
DEG
??
great
VA
??
Taiwan
NR
??
Taiwan
NR
position t-1 position n position n+1position t
t-1 n n+1t
t-1 n n+1t
t-1 n n+1t t-1 n n+1t
t-1 n n+1t
t-1 n n+1t
t-1 n n+1t
A{    } A{??? ->?? }
A{??? ->??} A{??? ->?? ,?? ->?? }
A{??? ->?? ,
?? ->?? }
A{??? ->?? ,
?? ->?? }
A{??? ->?? ,
?? ->?? }
A{??? ->?? ,
?? ->?? }
18
2.1   Algorithm 
We utilize a bottom-up deterministic algorithm 
proposed by (Nivre and Scholz, 2004) in our 
analyzer. In the algorithm, the states of analyzer 
are represented by a triple AIS ,, . S and I are 
stacks, S keeps the words being in consideration, 
and I keeps the words to be processed. A is a list 
of dependency relations decide during the algo-
rithm. Given an input word sequence W, the 
analyzer is initialized by the triple ?,,Wnil .
The analyzer estimates the dependency relation 
between two words (the top elements of stack S
and stack I). The algorithm iterates until the list 
I becomes empty. Then, the analyzer outputs the 
word dependency relations A.
There are four possible operations for the con-
figuration at hand: 
Right: Suppose the current triple is 
AInSt ,|,| (t and n are the top elements, S and 
I are the remaining elements in the stacks), if 
there is a dependency relation that the word t
depends on word n, add the new dependency 
relation ( )nt ?  into A, remove t from S. The 
configuration now becomes ( ){ }ntAInS ?,|, .
Left: In the current triple is AInSt ,|,|  , if 
there is a dependency relation that the word n
depends on the word t, adds the new dependency 
relation ( )tn ?  into A, push n onto the stack S.
The configuration now becomes 
( ){ }tnAIStn ?,,|| .
Suppose the current triple is AInSt ,|,| , if 
there is no dependency relation between n and t, 
check the following conditions. 
Reduce: If there are no more words 'n ( In ?' )
which may depend on t, and t has a parent on its 
left side, the analyzer removes t from the stack S.
The configuration now becomes AInS ,|, .
Shift: If there is no dependency between n and t, 
and the triple doesn?t satisfy the conditions for 
Reduce, then push n onto the stack S. The con-
figuration now becomes AIStn ,,|| .
These operations are depicted in Fig. 1. Given 
an input sentence of length N (words), the ana-
lyzer is guaranteed to terminate after at most 2N
actions. The dependency structure given at the 
termination is well-formed if and only if the re-
lations in A constitute a single connected tree. 
This means that the algorithm produces a well-
formed dependency graph.  
2.2   Machine learning method 
A classification task usually involves with train-
ing and testing data which consist of annotated 
data instances. Each instance in the training set 
contains one ?target value? (class label) and 
several ?attributes? (features). The goal of a 
classifier is to produce a model which predicts 
target value of data instances in the testing set 
which only give the attributes. 
SVMs are binary classifiers based on the 
maximal margin strategy. Suppose we have a set 
of training data for a binary classification prob-
lem: )y)...(y( nn11 ,, ZZ , where nR?iZ  is the fea-
ture vector of the i-th sample in the training data 
and }1,1{ ?+?iy is the class label of the sample. 
The goal is to find a decision function 
))(()( ?
?
+=
SV
ii
i
bKyasignxf
\
i,\Z  for an input vec-
tor Z . The vectors SV?K\  are called support 
vectors, which are representative examples. 
Support vectors and other constants are deter-
mined by solving a quadratic programming 
problem. )( zx,K is a kernel function which maps 
vectors into a higher dimensional space. We use 
the polynomial kernel: dK )1()( zxzx, ?+= . The 
performance of SVMs is better than using other 
machine learning methods, such as memory 
based learning or maximum entropy method, in 
our analyzer. This is because that SVMs can 
adopt combining features automatically (using 
the polynomial kernel), whereas other method 
cannot. To extend binary classifiers to multi-
class classifiers, we use the pair-wise method, 
which utilizes 2Cn  binary classifiers between all 
pairs of the classes (Kreel, 1998). We use 
Libsvm (Lin et al, 2001) in our experiments. 
2.3   Features (Local features) 
 It should be noted that we use a different ma-
chine learner from the original method (Nivre, 
2004). Nivre?s work used memory based learn-
ing in their analyzer, we utilize SVMs in our 
analyzer. Therefore, the features of our analyzer 
are different from the original Nivre?s method.  
In our method, the analyzer considers the de-
pendency of two nodes (n,t) which are in current 
19
triple. The nodes include the word, the POS-tag 
and the information of its children. The context 
features we use are 2 preceding nodes of node t
(and t itself), 2 succeeding nodes of node n (and
n itself), and their child nodes. The distance be-
tween nodes n and t is also used as a feature.  
We call these features as local features.
3 Global features and two-step process 
In the algorithm, the operation Reduce needs 
the condition that the node n should have no 
child in I. However, it is difficult to check this 
condition. In a long sentence, the modifier of the 
focused node n may be far away from n. More-
over, some non-local dependency may cause this 
kind of error. In this section, we will describe 
this problem and a solution to it. 
3.1   Global features 
The analyzer selects features for deciding the 
optimum operation, and then gives these fea-
tures to machine learner. The machine learner 
uses the same information to decide the opti-
mum operation even when these operations es-
sentially disagree. However, the different 
operation consists of different condition. In the 
deterministic bottom-up dependency analysis, 
we can generally consider the process as two 
tasks:
Task 1: Does the focused word depend on a 
neighbor node? 
Task 2: Does the focused word may have a 
child in the remaining token sequence? 
In the Task 1, the problem can be resolved by 
using the information of the neighbor nodes. 
This information is possibly the same as the fea-
tures that we described in section 2.3. However, 
these features may not be able to resolve the 
problem in task 2. For resolving the problem in 
task 2, we need the information of long distance 
dependency. In Fig. 2, for example, the analyzer 
is considering the relation between focused 
words ??? (tell)? and ?? (he)?. The features 
used in this original analysis are the information 
of words ?? (please)?, ??? (tell)?, ??(he)?, 
??? (what time)? and ??? (prepare)?. These 
features are ?local features?. The correct answer 
in this situation is the operation ?Shift?. It is 
because the word ??? (tell)? has a child ???
(start)? which is not yet analyzed and the fo-
cused words don?t depend on each other. How-
ever, the local features do not include the 
information of word ??? (start)?. Therefore, 
the analyzer possibly estimates the answer as the 
operation ?Reduce?. The results make a mistake 
in this situation because of the lack of long dis-
tance information. To resolve this problem, we 
should refer some information of long distance 
dependency in machine learning. The informa-
tion about long distance relations is defined as 
?global features?. In this paper, we select the 
words which remain in stack I but don?t be con-
sider in local features as global features. 
Fig. 2. An example of the ambiguity of deciding the long distance dependency relation and using two-
steps classification dependency relation 
??
prepare
?
please
?
you
??
tell
?
I
??
What time
??
start
?
He
S I
(Please  tell me what time he will prepare to start.)
Classification 
with local 
features
Output :shift
Local features
Global features
Classification 
with  global 
features
Output :
reduce
20
3.2   two-step process 
To use the global features, we cannot use them 
immediately because the global features are not 
effective in all operations. For using global fea-
tures efficiently, we propose a two-step process 
in our analyzer. The analysis processes are di-
vided to two processes. First, the analyzer uses 
only the local features (as described in Section 
2.3) to decide the optimum operation. If the re-
sult is ?Reduce? or ?Shift?, it means that the 
focused words do not have any dependency rela-
tion. The analyzer leaves the decision to another 
machine learner that makes use of global fea-
tures. The analyzer will select global features for 
analyzing the Task 2. Then the analyzer outputs 
the final answer of this analysis process.  
Fig. 2 describes an example of using two-step 
classification for analyzing dependency relation. 
In this example, the focused words are ?? (I)?
and ?? (He)?. The word ?? (I)? depends on 
the word ??? (tell)?. The local features are 
surrounded by dotted line and the global features 
are surrounded by solid line. The analyzer used 
local features to analyze the operation of this 
situation. The result is the operation ?shift?. The 
analyzer then selected the global features to ana-
lyze again and the output is the operation ?re-
duce?. The final result of this situation is the 
operation ?reduce?.
4 The root node finder 
In Isozaki?s work (Isozaki et. al, 2004), they 
adopted a root finder in their system to find the 
root word of the input sentence. Their method 
used the information of the root word as a new 
feature for machine learning. Their experiments 
showed that information of root word was a 
beneficial feature. However, we think the infor-
mation of root word can be used not only as the 
feature of machine learning, but also can be used 
to divide the sentence. Therefore, the complex-
ity of the sentence can be alleviated by dividing 
the input sentence. 
4.1   Root node and dividing sentence by 
using root finder 
In the fundamental definition of dependency 
structure, there is one and only one head word in 
a dependency structure. An element cannot have 
dependents lying on the other side of its own 
governor.  
These peculiarities imply that the head word 
divides the phrase into two independent parts 
and each part does not cross the head word. As 
in Fig. 3, the original input sentence has a root 
word (the head word of phrase) ?? (and)?. 
There are not any dependency relation which 
crosses the root word. Therefore we can divide 
this sentence into two sub-sentence ??? (exo-
dus) / ? (do) / ?? (study) / ? (and)? and ??
(and) / ? (go) / ?? (foreign country) / ?(do)
/ ?? (visit)?. Both these sub-sentences have 
their root word and the root word is ??(and)?.
We can conceive that to analyze the dependency 
structure of the full sentence is to analyze the 
dependency structure of two sub-sentences. 
Combining structures of two sub-sentences, we 
can get the full structure of original sentence. 
Our dependency analyzer is a bottom-up deter-
ministic analyzer. Instinctively, the accuracy of 
analyzing short sentence is significantly better 
than analyzing long sentence. Thus the perform-
ance of the dependency analyzer can be im-
proved by this method. 
4.2   Constructing a root finder 
To use the root node, we should construct the 
root finder. Similarly to Isozaki?s work, we use 
machine learner (SVMs) to construct the root 
finder. We refer to the features which are used 
in Isozaki?s work and investigate other effective 
features. The performance of our root node 
finder is 90.71%. This is better than the root ac-
curacy of our analyzer (86.22%, see Table 2).
Fig. 3. Dividing the phrase as two phrases by the root 
word 
?? ? ?? ? ? ?? ? ??
(To Leave native country to study and to visit other country.)
The root word
?? ? ?? ? ? ? ?? ? ??
The root word The root word
Original input 
sentence:
Divide by the 
root word:
Part 1 Part 2
21
Therefore, using the root finder can give the de-
pendency analyzer more top-down information.  
The tags and features of the root finding are 
shown in Fig. 4. We extract all root words in the 
training data and tagging every word to show 
that it is root word or not. For example, the root 
word in Fig. 4 is ??? (get)?. The root finder 
analyzes each word in the sentence and gives the 
tag ?true? or ?false? to indicate the root word. 
The features for machine learning of root finder 
include the contextual features (the information 
about the focused word, the two preceding 
words, and two succeeding words) and the word 
relation features (the words which are in the out-
side of the window). Other effectual features 
include the Boolean features ?root word is 
found? and ?the focus word is the first/last word 
of sentence?. For example, the contextual fea-
tures of the word ???  (economic)? include 
information of the focused (n) word ??? (eco-
nomic)?, the ?n-1?th word ??? (wide)?, the 
?n-2?th word ?? (DE)?, the ?n+1?th word? ?
?  (environment)? and the ?n+2?th word ??
(will)?. The word relation features include the 
preceding word set {??  (China)}, the suc-
ceeding word set {??, ???, ?, ??} and 
the Boolean features are: 
?root_word_is_found=false?,  
?first_word=false? ,?last_word=false?.  
When we use the root finder to analyze the 
root word of the sentence, we do not know the 
structure of input sentence (either the phrase 
structure or the dependency structure). It may 
look odd that the root finder can analyzes the 
root word without any information of the struc-
ture. However, this analysis is practicable. Natu-
rally, the root word of a sentence is usually a 
verb (about 61% of sentences have a verb as the 
root word in our testing corpus). For example, in 
the example 1 of Fig. 5 ?? / ? / ?? (I go to 
school)?, we know the POS-tags are ?noun, verb, 
noun? thus we can find that the root word is ??
(go)?. However, many sentences include more 
then one verb or the root word is not verb (in NP 
or PP?etc.). We can not only choose the verbs 
as root word directly. To decide the root word of 
complex sentences, there are some special 
word/POS relations that can be used to estimate 
the root node of a sentence. Considering the root 
finder in Fig. 4, the root finder gives the root tag 
to each word of the sentence. 
The processes of analyzing the root word can 
be thought as two tasks:  
Task 1: Does the focus word depend on a 
neighbor word?  
Task 2: Are there any special relation in the sen-
tence? 
 In Fig. 4, the contextual features (two pre-
ceding words and two succeeding words) can be 
used to process the Task 1, and the word rela-
tion features can be used to process the Task 2.
If the focused word possibly depends on  
neighbor words, it is impossible that the focused 
word is the root word. Therefore these words 
will be tagged as ?false?. 
Alternately, considering the example 2 in Fig.
5, the sentence has a verb ??? (recapture)?,
but the special word ?? (DE)? is in the right 
side of the verb ??? (recapture)?. Therefore, 
the verb ??? (recapture)? is possibly in the?
(DE)-phrase and the verb cannot be the root 
word. The special word ?? (DE)? resembles a 
preposition and it is always the last word of DE-
phrase. Therefore, although we do not know the 
structure of sentence, we can identify which 
words can be the root word by the relation and 
position of the features. If the features of the 
focused word include the special word relations 
Fig. 4. The features and tag of root finder 
Word POS Tag
?? NR false
? DEG false
?? JJ false
?? NN false
?? NN false
? AD false
?? VV true
??? JJ false
? DEG false
?? NN false
EOS
Position 0
Position -1
Position -2
Position 1
Position 2
Focus word
Contextual 
feature
Word 
relation Fig. 5. The examples of analyzing the root word 
of sentences 
Root
??? ?? ?? ? ?? ??
NR       VV       NR      DEG   VA        NN
(The great triumph that Cheng Cheng-Kung recaptured 
Taiwan. )
? ? ??
DT      VV      NN
(I go school.) Root
Example 1:
Example 2:
22
(for example, the focused word is in the preposi-
tional phrase), it isn?t the root word. The fea-
tures ?word relations? in Fig. 5 can consider this 
situation.
5 Experiments 
5.1 Corpus and estimation 
We use Penn Chinese Treebank 5.0 (Xue et al, 
2002) in our experiments. This Treebank is rep-
resented by phrase structure and doesn?t include 
the head information of each phrase. The first 
step of using Penn Chinese Treebank is to derive 
the head rules for deciding the head word of 
each phrase. Some examples of head rules are 
shown in Table 1. We convert the Treebank by 
using these head rules. The training corpus in-
cludes about 377,408 words for learning and 
63,886 words for testing. It should be noted that 
the punctuation mark ??? marks the end of a 
sentence in the Treebank. However, the punc-
tuation mark ??? also can be the end of a sen-
tence. It is hard to determine the dependency 
rule of the clauses on the both side of comma. 
Therefore, to decide the dependency relation 
which crosses a punctuation mark ??? is difficult. 
We do not deal with the ambiguity of commas 
and divide the sentence by the punctuation mark 
???.
Phrase The order of deciding the head 
of phrase (from left) 
ADJP CC PZ ADJP JJ 
ADVP CC PZ AD 
CLP PZ CLP M LC 
DP DP CLP QP DT 
DVP DEV DEC DEG 
VCP VC VV 
Table 1. Some examples of head rules 
The performance of our dependency structure 
analyzer is evaluated by the following three 
measures:  
Dependency Accuracy: 
relationsdependencyofnumber
relationsdependencyanalyzedcorrectlyofnumber
=
Root Accuracy:  
clausesofnumber
nodesrootanalyzedcorrectlyofnumber
=
Sentence Accuracy: 
clausesofnumber
clauseanalyzedcorrectlyfullyofnumber
=
5.2 Results and discussion 
Our experimental results are shown in Table. 2.
First row in the table is the result of our basic 
analyzer (Nivre algorithm with SVMs), second 
and third row show the effects of the proposed 
extensions. The last row is the result of combin-
ing the two extensions. We had used McNemar 
test to confirm the significance of the methods. 
The McNemar test proves that using the pro-
posed methods improve the analyzers signifi-
cantly. Comparing the results of our basic 
analyzer to related works, our analyzer (dep. 
Accuracy: 87.64) is better than (Ma et al, 2004, 
dep. Accuracy: 80.38) and (Zhou, 2000, dep. 
Accuracy of newspaper: 67.7). However, these 
researches used different corpus. We cannot 
compare the performances directly.  
According to the second row of Table. 2, di-
viding the process of classification as two steps 
can improve the performance of dependency 
analyzer. However, the improvement of using 
this method is limited. This is because that long 
distance relations are not many in the corpus. 
The absence of global information does not oc-
cur in the sentences without long distance rela-
tions. Another reason is the distribution of 
operations. The instances of operations in our 
experimental corpus are not balanced. The op-
eration ?reduce? is the least (7.8%) and it is far 
less than other operations. Therefore the in-
stances for creating the model of operation ?re-
duce? are not satisfactory. These facts result in   
that our experiment of using two step classifica-
tion cannot improve the analyzer remarkably. 
About the experiment of utilizing root finder 
in our analyzer, we tried to adopt the root infor-
mation to the analyzer (using the information as 
features for machine learning). However, the 
performance is worse than the baseline (the fun-
damental analyzer ?Nivre+SVMs?). Therefore, 
we use our method to improve the analyzer by 
using root information (dividing the sentence 
according to root node). 
According to the third row of Table. 2, divid-
ing the sentence into two sub-sentences can im-
prove the performance of dependency analyzer. 
However, the sentence accuracy cannot increase 
reliably. This result shows that using root finder 
and dividing sentence can reconstruct some mis-
takes in sentences. Certainly, the performance of 
the root finder influences the analyzer strongly. 
If we use a perfect root node finder into our ana-
lyzer, the performance will improve signifi-
cantly. 
23
The last row of Table. 2 shows the results of 
combining the two proposed methods (using 
global features and root node finder) to improve 
our analyzer. Combining two methods can in-
crease the dependency accuracy better than us-
ing either one of the methods. It means that 
some analysis errors of fundamental analyzer 
can be resolved by using both improvement 
methods. Therefore using combined method 
cannot supply higher improvement. 
 Dep. 
Acc.
Root
Acc.
Sent.
Acc.
Baseline
(Nivre with 
SVMs)
85.25 86.18 59.98 
Baseline with 
two-step
process
85.44 86.22 60.1 
Baseline with 
root node 
finder
86.13 90.94 61.33 
Baseline with 
two-step
process and 
root node 
finder
86.18 90.94 61.33 
Table 2. The experimental results 
6 Conclusion and future work 
In this paper, we present two methods to im-
prove a deterministic dependency structure ana-
lyzer for Chinese. This basic analyzer 
implements a bottom-up deterministic algorithm 
with SVMs. We convert a phrase structure anno-
tated corpus (Penn Chinese Treebank) to de-
pendency tagged corpus by using head rules. 
According to the properties of Chinese language 
and dependency structure, we try to add a root 
finder in our dependency analyzer to improve 
the analyzer. Moreover, considering the machine 
learning process of our analyzer, we divide the 
process into two processes to improve the per-
formance of analyzer. The improving methods 
(using root finder and dividing machine learning 
process) showed to improve the analyzer. 
Future work includes three points. First, we 
should improve the performance of the root 
finder. Second, we should construct a useful 
prepositional phrase chunker, because the 
prepositional phrase is a major error source of 
our basic analyzer. The original analyzer tends 
to let the preposition governing a partial subtree 
of the full phrase. According to the properties of 
Chinese language, the prepositional phrases in 
Chinese are head-initial. Intuitively, if we can 
extract the prepositional phrases from sentence, 
the complexity of the sentence will decrease. 
Thus an important task is how to chunk the 
prepositional phrase in the sentence.  
Finally, we should deal with the ambiguity of 
the meaning of punctuation mark ?,?.  The defi-
nition of ?sentence? is ambiguous in Chinese. In 
Chinese articles, the normal ending mark of a 
sentence is the punctuation mark ???. However, 
the mark ??? is often used at the end of a sen-
tence. To distinguish the meaning of the punc-
tuation mark ??? is difficult. Therefore, we 
should adopt semantic analysis in our analyzer. 
References
1. Eugene Charniak, 2001. Immediate-Head Parsing 
for Language Models. pages 124-131, NAACL-
2001. 
2. Yuen Ren Chao, 1968. A Grammar of Spoken 
Chinese. Berkeley, CA: University of California 
Press.  
3. Michael Collins, Brian Roark, 2004, Incremental 
parsing with the Perceptron algorithm. Pages 112-
119, ACL-2004. 
4. J. Huang, 1982. Logical relations in Chinese and 
the theory of grammar Doctoral dissertation, Mas-
sachusetts Institute of Technology, Cambridge. 
5. Ulrich. H.-G. Kre?el, 1998. Pairwise classification 
and support vector machines. In Advances in 
Kernel Methods, pages 255?268. The MIT Press. 
6. Chih Jen Lin, 2001. A practical guide to support 
vector classification, http://www.csie.ntu.edu.tw/
~cjlin/libsvm/. 
7. Lai, Bong Yeung Tom, Huang, Changning, 1994. 
Dependency Grammar and the Parsing of Chinese 
Sentences.  PACLIC 1994 
8. Hideki Isozaki, Hideto Kazawa, Tsutomu Hirao, 
2004. A Deterministic Word Dependency Ana-
lyzer Enhanced With Preference Learning, pages 
275-281, COLING-2004 
9. Charles Li, and Thompson Sandra A., 1981. Man-
darin Chinese. University of California Press.  
10. Lin-Shan Lee, Long-Ji Lin, Keh-Jiann Chen, and 
James Huang, 1991. An Efficient Natural Lan-
guage Processing System Specially Designed for 
the Chinese Language. ComputationaI Linguistics, 
Volume 17, Number 4. 
11. Ma Jinshan, Zhang yu, Liu ting, and Li sheng, 
2004. A Statistical Dependency Parser of Chinese-
under Small Training Data. IJCNLP 2004 Work-
shop: Beyond shallow analyses, Formalisms and 
statistical modeling for deep analyses. 
12. Joakim Nivre and Mario Scholz, 2004. Determi-
nistic Dependency Parsing of English Text. Pages 
64-70, COLING-2004. 
13. Adwait Ratnaparkhi, 1999. Learning to parse 
natural language with maximum entropy models. 
Machine Learning, 34(1-3) pages151?175. 
14. Vladimir N. Vapnik, 1998. Statistical Learning 
Theory.  A Wiley-Interscience Publication. 
15. Nianwen Xue, Fu-Dong Chiou, Martha Stone 
Palmer, 2002. Building a Large-Scale Annotated 
Chinese Corpus. COLING 2002 
16. Ming Zhou, 2000. A block-based robust depend-
ency parser for unrestricted Chinese text. The sec-
ond Chinese Language Processing Workshop 
attached to ACL-2000. 
24
Use of Event Types for Temporal Relation Identification in Chinese 
Text 
Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto 
Graduate School of Information Science 
Nara Institute of Science and Technology 
8916-5 Takayama, Ikoma, Nara 630-0192, Japan 
{yuchan-c,masayu-a,matsu}@is.naist.jp 
Abstract 
This paper investigates a machine learning 
approach for identification of temporal re-
lation between events in Chinese text. We 
proposed a temporal relation annotation 
guideline (Cheng, 2007) and constructed 
temporal information annotated corpora. 
However, our previous criteria did not deal 
with various uses of Chinese verbs. For 
supplementing the previous version of our 
criteria, we introduce attributes of verbs 
that describe event types. We illustrate the 
attributes by the different examples of verb 
usages. We perform an experiment to 
evaluate the effect of our event type attrib-
utes in the temporal relation identification. 
As far as we know, this is the first work of 
temporal relation identification between 
verbs in Chinese texts. The result shows 
that the use of the attributes of verbs can 
improve the annotation accuracy. 
1 Introduction 
Extracting temporal information in documents is a 
useful technique for many NLP applications such 
as question answering, text summarization, ma-
chine translation, and so on. The temporal informa-
tion is coded in three types of expressions: 1. tem-
poral expressions, which describe time or period in 
the actual or hypothetical world; 2. event or situa-
tion expressions that occur at a time point or that 
last for a period of time; 3. temporal relations, 
which describe the ordering relation between an 
event expression and a temporal expression, or be-
tween two event expressions.  
There are many researches dealing with the 
temporal expressions and event expressions. Ex-
tracting temporal expressions is a subtask of 
Named Entity Recognition (IREX committee, 1999) 
and is widely studied in many languages. Normal-
izing temporal expressions is investigated in 
evaluation workshops (Chinchor, 1997). Event se-
mantics is investigated in linguistics and AI fields 
(Bach, 1986). However, researches at temporal 
relation extraction are still limited. Temporal rela-
tion extraction includes the following issues: iden-
tifying events, anchoring events on the timeline, 
ordering events, and reasoning with contextually 
underspecified temporal expressions. To extract 
temporal relations, several knowledge resources 
are necessary, such as tense and aspect of verbs, 
temporal adverbs, and world knowledge (Mani, et 
al., 2006).  
In English, TimeBank (Pustejovsky, et al, 2006), 
a temporal information annotated corpus, is avail-
able to machine learning approaches for automati-
cally extracting temporal relation. In Chinese, Li 
(2004) proposed a machine learning based method 
for temporal relation identification, but they con-
sidered the relation between adjacent verbs in a 
small scale corpus. There is no publicly available 
Chinese resource for temporal information proc-
essing. We proposed (Cheng, 2007) a dependency 
structure based method to annotate temporal rela-
tions manually on a limited set of event pairs and 
extend the relations using inference rules. In our 
previous research, the dependency structure helps 
to detect subordinate and coordinate structures in 
sentences. Our proposed criteria can reduce the 
manual effort for annotating the temporal relation 
tagged corpus. 
Our research focuses on the relations between 
events where they are assumed to be described by 
verbs. Verbs in an article can represent events in 
actual world (which describe actual situations or 
actions) and events in hypothetical world (which 
describe possible situations, imagination or back-
ground knowledge). However, our previous re-
search does not define the class of event types. Our 
31
Sixth SIGHAN Workshop on Chinese Language Processing
previous annotation guideline requires annotators 
to decide the attributes of temporal relations of a 
verb by annotators? own judgment but does not 
describe the difference between events (verbs) in 
actual and hypothetical world. 
In this paper, we attempt to give the definition 
of actual / hypothetical world events (verbs). We 
collect usages of verbs in Penn Chinese treebank 
and classify them to actual / hypothetical worlds. 
We add another attribute to our previous criteria. 
Then we train the temporal relation annotated cor-
pus to investigate the effect of using the event 
types for automatic annotation.  
In the next section, we describe the criteria of 
temporal relations between events that are pro-
posed in our previous research (Cheng, 2007). In 
section 3, we discuss the event types of verbs and 
define the actual / hypothetical world events. In 
section 4, we perform an experiment of a machine 
learning based temporal relation identifier with and 
without the event type information. Finally, we 
discuss the results of experiments and our future 
direction. 
2 Temporal relations between events 
We propose an annotation guideline for developing 
a Chinese temporal relation annotated corpus. The 
guideline is based on TimeML (Saur?, 2005) and 
focuses on the temporal relations between events. 
To reduce manual effort, we introduce several con-
straints on the original TimeML. First, we restrict 
the definition of events to verbs. Second, we focus 
on three types of event pairs according to syntactic 
dependency structure. 
2.1 The definition of the events 
According to the TimeML guideline for English, 
verbs, nominalized verbs, adjectives, predicative 
and prepositional phrases can represent events. 
However, to recognize an instance of nominalized 
verb represents whether an event or not is difficult 
in Chinese articles. Chunking phrases and clauses 
is another difficult process in Chinese. To simplify 
the process of recognizing events, the criteria only 
regard verbs as events.  
2.2 Three types of event pairs 
The criteria of temporal relation between events 
include three types of event pairs in the complete 
graph as follows:  
 RLP (Relation to Linear Preceding event): 
Relation between the focus event and the ad-
jacent event at the immediately proceeding 
position. (Relation of adjacent event pair). 
 RTA (Relation to Tree Ancestor event): 
Relation between the focus event and the 
ancestor event in a dependency structure 
(Relation of Head-modifier event pair). 
 RTP (Relation to Tree Preceding event): 
Relation between the focus event and its sib-
ling event in a dependency structure (Rela-
tion of Sibling event pair). 
The first type stands for the adjacent event pairs. 
The second and third types are the head-modifier 
event pairs and the sibling event pairs in depend-
ency tree representation of a sentence. Figure 1 
describes the relation of three types of event pairs 
in an article. There are two sentences with twelve 
events (from e1 to e12) in the figure and the poly-
gons with dashed-lines show the boundary of sen-
tences. The angle-line links show adjacent event 
pairs (from Ll-1 to Ll-11). The dotted-line links 
show head-modifier event pairs (from Hl-1 to Hl-
10) and the curve links show sibling event pairs 
(from Sl-1 to Sl-6). The first type (adjacent event 
Figure 1: The example of annotating the temporal relations between events. 
e5
e2 e4 e6
e1 e3 e7
e11
e9 e10 e12
e8
Legend:
Sl-1
Sl-3
Sl-4
Sl-6
Hl-1 Hl-2
Hl-3 Hl-4 Hl-5
Hl-6 Hl-7
Hl-8 Hl-9 Hl-10
Ll-1 Ll-2 Ll-3
Ll-4 Ll-5
Ll-6 Ll-7 Ll-8
Ll-9 Ll-10 Ll-11
Adjacent event pair: Ll-X
Head-modifier event pair: Hl-X
Sibling event pair: Sl-X
Sentence 1 Sentence 2
Sl-5
Sl-2
32
Sixth SIGHAN Workshop on Chinese Language Processing
pairs) and the other two types (head-modifier or 
sibling event pairs) are not exclusive. An event 
pair can be a head-modifier event pairs and can be 
a head-modifier event at the same time. 
The adjacent event pair links and the sibling 
event pair links can be used to connect the tempo-
ral relations between sentences. The links Sl-4 and 
Ll-7 span two sentences in the example.  
Subordinate event pairs are head-modifier rela-
tions and coordinate event pairs are sibling rela-
tions. Using dependency structure can help to ex-
tract subordinate relations and coordinate relations 
in a sentence. 
2.3 Deficiency of our previous criteria 
Our criteria can reduce manual effort of temporal 
relation annotation. However, our previous guide-
line does not distinguish actual world and hypo-
thetical world events. Because all verbs in the pre-
vious guideline are regarded as events, verbs of 
hypothetical world events are also included in the 
events. For example: (the italicized words in our 
examples indicate verbs) 
 (a) ???/??/?/??/??/?? (after 
the industrial estate was established, it at-
tracted a great deal of foreign capital) 
 (b) ???/??/?/??/??/??/??
(after the industrial estate is established, it 
can attract a great deal of foreign capital) 
The difference between examples (a) and (b) is 
only with or without the word ??? (can)?, which 
governs a verb phrase and explains a possible 
situation. It should be noted that verbs in Chinese 
do not have morphological change. The complete 
meaning of verbs in the examples should consider 
the global context in the article. The example (a) 
explains an actual world event that the industrial 
estate attracted a great deal of foreign capital. 
However, in example (b), the word ??? (can)? 
changes  the phrase ???/??/?? (to attract a 
great deal of foreign capital)? into a hypothetical 
world event. This clause presents a possibility and 
does not indicate an event in the actual world.  
Considering the temporal relation between the 
verbs ???(establish)? and ???(attract)?,  the 
temporal relation in the example (a) means that  
the event ??(establish) occurs before the event 
??(attract). On the other hand, in the example 
(b), the verb ???(attract)? indicates a possibility. 
We cannot make sure if it could really happen. We 
regard that the temporal relation in the example (b) 
is unidentifiable. In the previous guideline, we re-
quest annotators to decide the temporal relation 
between them. However we do not classify the dif-
ference between actual and hypothetical worlds. 
The annotators annotate even some incomprehen-
sible temporal relations (such as the relation in ex-
ample (b)) with the tag ?unknown?. We clarify the 
issue by introducing event types to verbs.  
Aside form the problem of actual and hypotheti-
cal world events, verbs in our temporal relation 
annotated corpus still include some incomprehen-
sible events (We consider these in the next section). 
For solving these problems, we investigated differ-
ent types of events (verbs) in the Penn Chinese 
Treebank (Palmer, 2005) then give a clear classifi-
cation of event types. We use this classification of 
events to annotate events in the temporal relation 
tagged corpus. 
3 Event types of verbs 
Our criteria restrict events to verbs according to the 
POS-tag of Penn Chinese Treebank. Therefore, all 
the words tagged with the POS-tags (Xia, 2000), 
?VA?, ?VE?, ?VC?, and ?VV? are the ?event can-
didates?. However, these POS-tags include not 
only actual world events but also hypothetical 
world events, modifiers of nouns, and sub-
segments of named entities. We will exemplify 
these situations in this section. 
3.1 Verbs of actual world events 
The ?event? that we want to annotate is an action 
or situation that has happened or will definitely 
happen in the actual world. We define these events 
as actual world events. For example: 
 (c) ??/??/?? (A fire occurred in the 
market.) 
 (d) ???/??/??/??/?? (The 
construction work of the city hall will finish 
at the end of the year.) 
 (e) ??/??/??/?? (The function of 
financial market is smooth.)
The verbs in these examples represent actual 
world events. We want to distinguish between 
these events and hypothetical world events. 
The example (c) is a general instance of an ac-
tual world event. The verb ??? (happen)? in the 
33
Sixth SIGHAN Workshop on Chinese Language Processing
sentence indicates an occurrence of an event. The 
verb ??? (finish)? in example (d) is a confirma-
tive result that definitely happens. The word ???
(will)? indicates that the sentence describes a fu-
ture statement. If there is no other statement that 
describes an accident event in the context, we can 
trust the event in the example (d) is an actual world 
event. 
In Chinese, an adjective can be a predicate with-
out a copula (corresponding to the verb ?be?). The 
example (e) contains no copula. Still, the adjective 
??? (smooth)? is a predicate and represents an 
actual world situation. This kind of adjective is the 
POS-tag ?VA? in Penn Chinese Treebank and also 
can represent an actual world event.  
3.2 Verbs of hypothetical world events 
Sometime verbs indicate hypothetical world events. 
In such situations, verbs describe a possibility, a 
statement of ability, anticipation, a request or an 
inconclusive future. For example: 
 (b) ???/??/?/??/??/??/??
(after the industrial estate is established, it 
can attract a great deal of foreign capital) 
 (g) ???/?/??/???? (A big oil 
tanker can berth at the new port) 
 (h) ?? /?? /?? /?? /?? /??
(They wish the government to legislate 
against affiliated bill) 
 (i) ??/??/??/??/?? (The gov-
ernment requires the factory to amend their 
equipments) 
 (j) ?/??/???/??/??/?? (this 
technology can help to develop a new kind 
of medicine) 
The verb ??? (attract)? in example (b) ex-
plains a possibility that ?may? occur after a con-
firmative result ??? (establish)? in future. We 
cannot decide the temporal relation between the 
actual world event ??? (establish)? and the pos-
sible event ??? (attract)? in the example (b), be-
cause we do not know if the event ??? (attract)? 
will realize. 
The verb ??? (berth)? in example (g) explains 
the capacity of the new port. The verb ???
(berth)? does not indicate truth or a confirmative 
result. We cannot confirm when an oil tanker will 
berth at the new port. This verb represents a hypo-
thetical world event. The verb ??? (legislate)? in 
the example (h) and the verb ???(amend)? in the 
example (i) explain a wish and a request. Even the 
sentences describe that the government (in the ex-
ample (h)) or the factory (in the example (i)) was 
required to do something; the descriptions do not 
show any evidence that the request will be exe-
cuted. Although the wish and request will be real-
ized in future, we cannot identify the time point of 
the realization of these events. Therefore we 
should consider that these verbs represent hypo-
thetical world events. 
The verb ??? (develop)? in the example (j) 
explains an inconclusive plan in future. The devel-
oped technology can be used for a new develop-
ment plan. However, we also cannot make sure if 
the development plan will be realized or not. We 
cannot identify the verb ??? (develop)? on a 
timeline. Since the verb represents a hypothetical 
world event. 
These examples (from the examples (b), (g) to 
(j)) indicate hypothetical world events. However, 
as we introduced in section 2.3 (the examples (a) 
and (b)), the instances with different types of 
events have the same context in local structure (the 
phrase ???/??/?? (to attract a great deal of 
foreign capital)?). The difference between the ex-
ample (a) and the example (b) is that the word ??
? (can)? exists or not. To distinguish an actual 
world event and a hypothetical world event with 
similar local context, the dependency structure 
analysis is quite helpful. 
3.3 Copula verbs  
There are two special POS-tags of verbs in Penn 
Chinese Treebank, VC and VE. These verbs are 
copulas in Chinese. The copula verb (such as the 
verb ?? (be)?) indicates existence and corre-
sponds to ?be? in English. In TimeML, these copu-
las are not considered as an independent verb. It is 
included in another verb phrase or in a nominal 
phrase that represents an event. However, the cop-
ula verb ?? (be)? is an independent verb in Penn 
Chinese Treebank. We should investigate how to 
deal with this copula verb. For example: 
 (k) ?/??/?/???/??/? (The older 
version of bill was legislated at three years 
ago.) 
34
Sixth SIGHAN Workshop on Chinese Language Processing
 (l) ?/??/?/???/??/?/????
(The company is the largest electric power 
company in the world.) 
Considering the use of copula in Penn Chinese 
Treebank, sentences that include copula verbs can 
be distinguished to two types. The copula verbs 
describe existence. The existence could be a verb 
phrase (the example (k)) or a nominal phrase (the 
example (l)). In the example (k), the verb phrase 
????/?? (was legislated at three years ago)? 
represents an event that the copula verb accentu-
ates the existence of  the verb phrase. Although 
there are two verbs in the example (k), the sentence 
only includes an event which is the verb phrase 
????/?? (was legislated at three years ago)?.  
According to the dependency structure of sen-
tence, copula verbs represent the root of the de-
pendency structure and the head of a verb phrase 
that modifies a copula verb. We define a pair of a 
copula and a verb that modifies the copula as a 
?copula phrase?. Therefore we regard the copula 
verb in the example (k) as the main verb of the 
verb phrase ??? (legislate)? and it represents an 
actual world event1.
The copula verb ?? (be)? in the example (l) ac-
centuates the truth of the nominal phrase ????/
??/?/???? (the largest electric power com-
pany in the world)?. According to the discussion in 
the previous paragraph, the meaning of this copula 
comes from the nominal phrase. We can recognize 
the nominal phrase as a truth at the time point 
?NOW? (the company is largest in the world now). 
However, this phrase does not indicate any specific 
period of time that the fact holds. We can regard it 
as the background knowledge and it does not in-
clude an event. To identify the temporal relation 
between this noun phrase and other actual world 
event is impossible2. We also regard this copula 
verb as a hypothetical world event. 
3.4 Non-event verbs 
 
1 Whether the copula verbs are actual world events or hypo-
thetical world events depend on the modifier verb phrases. 
2 We cannot know when the company became the largest one 
on the world. And other events in the context distribute in a 
shorter period on a timeline. Therefore to compare the exis-
tence period of the truth and other events is impossible. How-
ever, if a temporal expression with a passed time period in the 
context, the truth could have a boundary of occurrence time. 
Then the copula can be recognized as an actual world event. 
There are several types of words that have a verbal 
POS-tag but do not represent events. These words 
include non-event predicative adjectives and 
named entities. 
In Chinese, adjectives can be predicates of a 
sentence without verbs. This kind of adjectives are 
predicative adjective and have a POS-tag ?VA? in 
Penn Chinese Treebank. These predicative adjec-
tives indicate situations. However, some instances 
in the Treebank are close to normal adjectives. We 
should distinguish the difference between the 
predicative adjectives that describe situations and 
predicative adjectives that are normal adjectives. 
For example: 
 (e) ??/??/??/?? (The function of 
financial market is smooth.)
 (n)?? /? /?/?? (To provide a new 
kind of power) 
The adjective ??? (smooth)? in the example 
(e) indicates a situation. We regard this adjective 
as an actual world event. However, the adjective 
?? (new)? in the example (n) is a modifier of the 
noun ??? (power)?. This adjective do not indi-
cate a situation, therefore it dose not represent an 
event. 
Another situation of non-event verbs is a verb in 
a named entity. Because of the strategy of the 
POS-tagging of Penn Chinese Treebank, a named 
entity is separated to several words and these 
words are tagged independently. For example: 
 (o) ???/??/??/?? (Alliance of 
Democratic Forces for Liberating Congo-
Zaire)? 
The example (o) shows a named entity that in-
cludes a word ??? (liberate)? has the POS-tag 
?VV?. However, this verb does not represent an 
actual event or a hypothetical event. It is a sub-
string of the named entity. We define this kind of 
verbs as non-event verbs. 
3.5 Attribute of event types 
Figure 2 summarizes the event types of verbs in 
section 3.1-3.4. We divide the verbs roughly into 
two types ?actual world? and ?hypothetical world?. 
Each type includes several sub-types. We annotate 
these two event types of verbs to our previous 
temporal relation annotated corpus. The definition 
of these event types in previous sections is a guide-
line for our annotators. This new attribute has two 
35
Sixth SIGHAN Workshop on Chinese Language Processing
values ?actual world? and ?hypothetical world?. 
Although the types of values are coarse-grained, 
this attribute can describe whether a verb can be 
recognized as an event with understandable tempo-
ral relation on the timeline or not. 
However, the value ?hypothetical world? of the 
event types means not only that the verbs with this 
value are temporal relation un-recognizable events, 
but also that the verbs with this value are ?locally 
recognizable? events. For example: 
 (p) ??/??/??/??/??/?/??/
?? (They wish the government to in-
crease budget to repair the bank) 
The verb ??? (wish)? governs the verb phrase 
???/??/??/?/??/?? (the government 
increases budget to repair the bank)?. Therefore the 
verb phrase represents a hypothetical world event 
(because we do not know if the government will do 
it or not). However, considering the local context 
of the verb phrase, it includes two verbs that have a 
causal relation between them. The event ???
(increase)? should occur before the event ???
(repair)?3. The temporal relation between the two 
verbs exists in the local context. We do not ignore 
this kind of temporal relations and annotate them. 
The temporal relation between the verb ??? (in-
crease)? and the verb ??? (repair)? is not un-
known but the temporal relation between the verbs 
??? (increase)? and the verb ??? (wish)? is 
unknown. 
Therefore, we regard the attribute of event type 
as a ?bridge? between an actual world and a hypo-
thetical world. The event in the actual world means 
that we can identify the temporal relation between 
 
3 The government must increase the budget and pass the delib-
eration in the congress, and then the budget can be used to 
repair the bank. 
an event and the other occurred events in an actual 
world. The temporal relations between a hypo-
thetical world event and an actual world event can 
only be identified in a hypothetical world. Figure 3 
describes this concept. The index on each event 
indicates the linear ordering of the event mention 
in the article. The two events with rectangles rep-
resent the actual world and the four events with 
diamond shapes represent the hypothetical world. 
There is no understandable temporal relation be-
tween actual and hypothetical worlds (for example 
the relation between the event 1 and event 2). The 
events in hypothetical world have their temporal 
relation with other events in the same hypothetical 
world. However, a hypothetical world is independ-
ent to other hypothetical worlds. Therefore, the 
temporal relation between event 2 and event 3 un-
derstandable but the relation between event 3 and 
event 4 are unknown. We ask our annotators to 
annotate the understandable temporal relations in 
each hypothetical world because the instances of 
the local context are useful in analyzing the tempo-
ral relation between events in actual world by ma-
chine learning. 
4 Evaluation Experiments 
Figure 3: The actual world and hypothetical 
worlds 
HYPOTHETICAL WORLD 2
ACTUAL WORLD
HYPOTHETICAL WORLD 1
Event 1 Event 5
Event 
2
Event 
3
Event 
4
Event 
6
UNKNOWN
UNKNOWN
UNKNOWN UNKNOWN
UNKNOWNRELATION RELATION
RELATION
Figure 2: The classifications of event types 
EVENT
hypothetical worldactual world
happened 
truth
uncertain 
future (b), (j)
certain 
future (d)
wish 
(h)requisition (i),(p)
ability (g)non-event
happened truth as a 
modifier of copula 
(k)
normal occurrence 
(a),(c)
modifier without 
event (n)
back ground 
knowledge (l)
uncertain 
desire
name entity 
(o)
Note: the characters in the brackets refer to the examples of each event type
statement 
(e)
36
Sixth SIGHAN Workshop on Chinese Language Processing
After we manually annotate the event type of verbs 
on our temporal relation tagged corpus, we use 
support vector machines as machine learner to 
compose a temporal relation identifier. We per-
form an experiment to investigate the effect of the 
event type information.  
4.1 The data set 
We annotated a part of Penn Chinese Treebank 
with our previous criteria. The temporal relation 
tagged corpus includes 7520 verbs. Each verb has 
three types of temporal relation that we introduce 
in section 2.3. We annotate the event type informa-
tion manually and refine some ambiguous in-
stances. For efficiency, we introduce grouping on 
the temporal relation classes. Our criteria defined 
ten classes of temporal relation values. We com-
pose three types of temporal relation identifiers 
(RLP, RTA and RTP) and an event type classifier.  
To discriminate the event types of verbs, we add 
two possible values of temporal relations, the value 
?hypothetical? and ?copula-existence?. The value 
?hypothetical? is introduced in the temporal rela-
tion type ?RTA?. If the verb represents a hypo-
thetical world event or non-event, the verb is en-
closed into the hypothetical world. The verb in hy-
pothetical world cannot have a RLP relation (Rela-
tion of adjacent event pair) between hypothetical 
and actual worlds. However, for recognizing the 
verb that is the root event of the hypothetical world, 
we annotate the RTA relation (Relation of adjacent 
event pair) of the root event in hypothetical world 
as the value ?hypothetical?. The value ?copula-
existence? is introduced to annotate the event em-
phasized by the copula verb. If the copula verb 
governs a verb phrase with several verbs, the root 
event of the verb phrase has the value ?copula-
existence?. 
The possible values of three types of temporal 
relations and event types in our experiment are 
summarized as follows: 
 Event types: actual world and hypothetical 
world 
 RLP: after (includes the values ?after? and 
?begun-by? in our criteria), before (includes 
the values ?before? and ?end-by? in our cri-
teria), simultaneous, overlap (includes the 
values ?overlap?, ?overlapped-by?, ?in-
clude?, ?during? our criteria) 
 RTA: after, before, simultaneous, overlap, 
unknown, copula-existence, hypothetical 
 RTP: after, before, simultaneous, overlap 
The training data for SVMs includes 151 articles 
with 49620 words and 7520 verbs and the testing 
data is collected from articles in Penn Chinese 
Treebank other than training data (testing data in-
cludes 50 short articles with 5010 words and 732 
verbs). The basic information of our corpus and the 
distribution of the value of attributes in our training 
and testing data are shown in Table 1. It should be 
noted that the number of the attributes of the data 
ignore some negligible instances. Such as, if a verb 
does not have sibling verbs in the dependency 
structure, to consider the attribute ?RTP (Relation 
between focus event and its sibling event)? is un-
necessary. Therefore the total numbers of the at-
tribute ?RTA? and the attribute ?RTP? are less 
than the number of all verbs. 
4.2 Experiment 
We train each classifier (event types, RLP, RTA 
and RTP) by an independent model. The features 
for machine learning are also tuned independently. 
We evaluate the accuracy of automatic annotation 
of event types and temporal relations with and 
without our event types. We use our event type tag 
as a feature of the three temporal relations. Other 
features for SVM analyzer to annotate the three 
types of temporal relations include the morpho-
logical information of the focus event pair and the 
dependency structure of the sentence. These fea-
tures can be extracted from the dependency struc-
tures automatically. 
The results are shown in Table 2. The abbrevia-
tions ?R?, ?P? and ?F? mean ?Recall?, ?Precision? 
and ?F-measure?. The row ?Accuracy w/o event 
type? means the results of the temporal relations 
annotating without using the event type as a feature. 
Other rows use the event type which is annotated 
Table 1: The distribution of our data set 
actual world: 453
hypothetical world: 279
actual world: 4584
hypothetical world: 
2936
Test Test TestTrainTrainTrain
Test (732 verbs)
234
75
2
20
36
101
552
39
163
15
63
191
81
732
216
24
75
139
278
261155537520Total
Train (7520 verbs)Event Types
7042157Unknown
417
1587
96
1011
1864
580
RTA
copula-
existence
85212overlap
3721273before
525
925
RTP
1391
2487
hypothetical
after
simultaneous
RLP
37
Sixth SIGHAN Workshop on Chinese Language Processing
by a machine learning-based analyzer as a feature. 
Because there is no similar related research that 
analyzes temporal relation between Chinese verbs 
based on machine learning, we cannot make any 
comparison. We discuss the accuracy of temporal 
relation annotating with and without using our 
event type according to the result of our experi-
ment.  
4.2 Discussions 
Table 2 shows that the model with the result of the 
event type classifier is better than that without us-
ing the result of the event type classifier. However, 
the improvement of using event types is limited. 
The reason might be the accuracy of event type is 
as low as 83%. To improve the performance of 
event type annotation helps to improve the relation 
annotation. 
There is no research based on the same data set 
and corpus guideline, therefore we can not com-
pare the result to other research. However, in the 
shared task: ?TempEval4 Temporal Relation Identi-
fication? (Verhagen, 2007), the task ?temporal re-
lations between matrix verbs? resembles the goal 
of our corpus. The F-measure in TempEval shared 
task distribute between 40%~50%. The result of 
the shared task also shows the difficulty of auto-
matic temporal relation analysis. 
5 Conclusions  and future directions 
We propose a machine learning-based temporal 
relation identification method. This is the first 
work of the temporal relation identification be-
tween verbs in Chinese texts. To deal with the de-
ficiency in our previous temporal relation annotat-
 
4 This shared task deals with English news articles.(TimeBank 
1.2)  
ing criteria, we newly introduce the event types of 
Chinese verb. The result of evaluation experiments 
shows that the event type information helps to im-
prove the accuracy of the identifier.  
A deficient of our experiment is that we do not 
use semantic information as features for machine 
learner. Semantic information of temporal and 
event expressions is important for recognizing 
temporal relations between events. As a future re-
search, we would like to introduce causal relation 
knowledge of verbs (this is similar to VerbOcean 
(Chklovski, 2004)). We are collecting this kind of 
verb pairs and expect that this causal relation helps 
to improve the performance of automatic annota-
tion. 
References 
Emmon Bach. 1986. the algebra of events. Linguistics 
and Philosophy 9. 
Yuchang Cheng, et al 2007. Constructing a Temporal 
Relation Tagged Corpus of Chinese based on De-
pendency Structure Analysis. TIME 2007. 
Timothy Chklovski and Patrick Pantel. 2004. VerbO-
cean: Mining the Web for Fine-Grained Semantic 
Verb Relations. EMNLP 2004. 
Nancy Chinchor. 1997. MUC-7 named entity task defi-
nition.
http://www.itl.nist.gov/iaui/894.02/related_projects/
muc/proceedings/muc_7_proceedings/overview.html. 
Wenjie Li, et al 2004. Applying Machine Learning to 
Chinese Temporal Relation Resolution. ACL 2004. 
Inderjeet Mani, et al 2006. Machine Learning of Tem-
poral Relations. COLING/ACL 2006. 
IREX Committee. 1999. Named entity extraction task 
definition. http://nlp.cs.nyu.edu/irex/NE/df990214.txt, 
1999. 
Martha Palmer, et al 2005. Chinese Treebank 5.1.
http://www.ldc.upenn.edu/.  LDC. 
James Pustejovsky, et al 2006. TimeBank 1.2.
http://www.ldc.upenn.edu/. LDC. 
Roser Saur?, et al 2005. TimeML Annotation Guidelines.
http://www.timeml.org/. 
Marc Verhagen, et al 2007. SemEval-2007 Task 15: 
TempEval Temporal Relation Identification. ACL 
2007 Workshop: SemEval-2007. 
Fei Xia. 2000. The Part-Of-Speech Tagging Guidelines 
for the Penn Chinese Treebank.
http://www.cis.upenn.edu/~chinese/ctb.html. 
Table 2: The results of our experiment 
0.610.600.61Accuracy w/o 
Event type
0.70
0.45
0.33
0.46
0.67
F
0.72
0.62
0.69
0.32
0.73
0.52
F
0.71
0.51
0.33
0.50
0.65
FP P PRRR
0.68
1
0.35
0.52
0.63
0.67
0.68
0.81
0.32
0.68
0.64
0.69
1
0.35
0.51
0.62
0.610.630.62Accuracy
0.740.73unknown
0.80
0.57
0.6
0.31
0.81
0.45
RTA
copula-existence
0.290.45overlap
0.420.45before
0.32
0.71
RTP
0.32
0.70
hypothetical
after
simultaneous
RLP
0.83Accuracy
0.770.760.780.920.910.93R /P /F
hypothetical worldactual worldEvent Types
38
Sixth SIGHAN Workshop on Chinese Language Processing
Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),
pages 191?195, New York City, June 2006. c?2006 Association for Computational Linguistics
Multi-lingual Dependency Parsing at NAIST 
Yuchang CHENG, Masayuki ASAHARA and Yuji MATSUMOTO 
Nara Institute of Science and Technology  
8916-5 Takayama, Ikoma, Nara 630-0192, Japan  
{yuchan-c, masayu-a, matsu}@is.naist.jp 
 
Abstract 
In this paper, we present a framework for 
multi-lingual dependency parsing. Our 
bottom-up deterministic parser adopts 
Nivre?s algorithm (Nivre, 2004) with a 
preprocessor. Support Vector Machines 
(SVMs) are utilized to determine the word 
dependency attachments. Then, a maxi-
mum entropy method (MaxEnt) is used 
for determining the label of the depend-
ency relation. To improve the perform-
ance of the parser, we construct a tagger 
based on SVMs to find neighboring at-
tachment as a preprocessor. Experimental 
evaluation shows that the proposed exten-
sion improves the parsing accuracy of our 
base parser in 9 languages. (Haji? et al, 
2004; Simov et al, 2005; Simov and 
Osenova, 2003; Chen   et al, 2003; B?h-
mov? et al, 2003; Kromann, 2003;    van 
der Beek et al, 2002; Brants et al, 
2002;   Kawata and Bartels, 2000; Afonso 
et al, 2002;   D?eroski et al, 2006; Civit 
and Mart?, 2002; Nilsson   et al, 2005; 
Oflazer et al, 2003; Atalay et al, 2003). 
1 Introduction 
The presented dependency parser is based on our 
preceding work (Cheng, 2005a) for Chinese. The 
parser is a bottom-up deterministic dependency 
parser based on the algorithm proposed by (Nivre, 
2004). A dependency attachment matrix is con-
structed, in which each element corresponds to a 
pair of tokens. Each dependency attachment is in-
crementally constructed, with no crossing con-
straint. In the parser, SVMs (Vapnik, 1998) 
deterministically estimate whether a pair of words 
has either of four relations: right, left, shift and 
reduce. While dependency attachment is estimated 
by SVMs, we use a MaxEnt (Ratnaparkhi, 1999) 
based tagger with the output of the parser to esti-
mate the label of dependency relations. This tagger 
uses the same features as for the word dependency 
analysis. 
In our preceding work (Cheng, 2005a), we not 
only adopted the Nivre algorithm with SVMs, but 
also tried some preprocessing methods. We inves-
tigated several preprocessing methods on a Chi-
nese Treebank. In this shared task (Buchholz et. al, 
2006), we also investigate which preprocessing 
method is effective on other languages. We found 
that only the method that uses a tagger to extract 
the word dependency attachment between two 
neighboring words works effectively in most of the 
languages. 
2 System Description 
The main part of our dependency parser is based 
on Nivre?s algorithm (Nivre, 2004), in which the 
dependency relations are constructed by a bottom-
up deterministic schema. While Nivre?s method 
uses memory-based learning to estimate the de-
pendency attachment and the label, we use SVMs 
to estimate the attachment and MaxEnt to estimate 
Fig. 1 The architecture of our parser 
(i)Preprocessor (neighboring 
relation tagger)
(ii)Get contextual features
(iii)Estimate dependency
attachment by SVM
(iv)Tag label by MaxEnt
Construct Subtree
No more construction
Dependency tree
False
True
Left or Right attachment
None
Input sentence (word tokens)
191
Fig. 2. The features for dependency analysis 
BOS
-
BOS
BOS
-
??
-
VC
V
-
??
-
Nb
N
-
?
-
DE
DE
-
??
-
VH
V
-
??
-
Nac
N
-
???
-
Na
N
-
S I
position t-1position t-2
The child of the position t-1
position n position n+1position n+2position t
A feature: the distance between the position t and n
FORM 
LEMMA 
CPOSTAG 
POSTAG 
FEATS 
Key: The features for machine 
learning of each token
the label. The architecture of the parser consists of 
four major procedures and as in Fig.1:  
(i) Decide the neighboring dependency at-
tachment between all adjacent words in the 
input sentence by SVM-based tagger (as a 
preprocessing) 
(ii) Extract the surrounding features for the 
focused pair of nodes. 
(iii) Estimate the dependency attachment op-
eration of the focused pair of nodes by 
SVMs. 
(iv) If there is a left or right attachment, esti-
mate the label of dependency relation by 
MaxEnt. 
We will explain the main procedures (steps (ii)-
(iv)) in sections 2.1 and 2.2, and the preprocessing 
in section 2.3. 
2.1   Word dependency analysis 
In the algorithm, the state of the parser is repre-
sented by a triple AIS ,, . S and I are stacks, S 
keeps the words being in consideration, and I 
keeps the words to be processed. A is a list of de-
pendency attachments decided in the algorithm. 
Given an input word sequence W, the parser is ini-
tialized by the triple ?,,Wnil . The parser esti-
mates the dependency attachment between two 
words (the top elements of stacks S and I). The 
algorithm iterates until the list I becomes empty. 
There are four possible operations (Right, Left, 
Shift and Reduce) for the configuration at hand.  
Right or Left: If there is a dependency relation 
that the word t or n attaches to word n or t, add the 
new dependency relation ( )nt ?  or ( )tn ? into A, 
remove t or n from S or I. 
If there is no dependency relation between n and 
t, check the following conditions. 
Reduce: If there is no word 'n  ( In ?' ) which may 
depend on t, and t has a parent on its left side, the 
parser removes t from the stack S. 
Shift: If there is no dependency between n and t, 
and the triple does not satisfy the conditions for 
Reduce, then push n onto the stack S. 
In this work, we adopt SVMs for estimating the 
word dependency attachments. SVMs are binary 
classifiers based on the maximal margin strategy.  
We use the polynomial kernel: dK )1()( zxzx, ?+=  
with d =2. The performance of SVMs is better than 
that of the maximum entropy method in our pre-
ceding work for Chinese dependency analysis 
(Cheng, 2005b). This is because that SVMs can 
combine features automatically (using the polyno-
mial kernel), whereas the maximum entropy 
method cannot. To extend binary classifiers to 
multi-class classifiers, we use the pair-wise method, 
in which we make 2Cn
1  binary classifiers between 
all pairs of the classes (Kre?el, 1998). We use 
Libsvm (Lin et al, 2001) in our experiments. 
In our method, the parser considers the depend-
ency attachment of two nodes (n,t). The features of 
a node are the word itself, the POS-tag and the in-
formation of its child node(s). The context features 
are 2 preceding nodes of node t (and t itself), 2 suc-
ceeding nodes of node n (and n itself), and their 
child nodes. The distance between nodes n and t is 
also used as a feature. The features are shown in 
Fig.2. 
2.2   Label tagging 
We adopt MaxEnt to estimate the label of depend-
ency relations. We have tried to use linear-chain 
conditional random fields (CRFs) for estimating 
the labels after the dependency relation analysis. 
This means that the parser first analyzes the word 
dependency (head-modifier relation) of the input 
sentence, then the CRFs model analyzes the most 
suitable label set with the basic information of in-
put sentence (FORM, LEMMA, POSTAG??etc) 
and the head information (FORM and POSTAG) 
of each word. However, as the number of possible 
labels in some languages is large, training a CRF 
model with these corpora (we use CRF++ (Kudo, 
2005)) cost huge memory and time. 
Instead, we combine the maximum entropy 
method in the word dependency analysis to tag the 
label of dependency relation. As shown in Fig. 1, 
the parser first gets the contextual features to esti-
mate the word dependency. If the parsing operation 
                                                          
1  To estimate the current operation (Left, Right, Shift and 
Reduce) by SVMs, we need to build 6 classifiers(Left-Right, 
Left-Shift, Left-Reduce, Right-Shift, Right-Reduce and Shift-
Reduce).  
192
is ?Left? or ?Right?, the parser then use MaxEnt 
with the same features to tag the label of relation. 
This strategy can tag the label according to the cur-
rent states of the focused word pair. We divide the 
training instances according to the CPOSTAG of 
the focused word n, so that a classifier is con-
structed for each of distinct POS-tag of the word n. 
2.3 Preprocessing 
2.3.1   Preceding work 
In our preceding work (Cheng, 2005a), we dis-
cussed three problems of our basic methods (adopt 
Nivre?s algorithm with SVMs) and proposed three 
preprocessing methods to resolve these problems. 
The methods include: (1) using global features and 
a two-steps process to resolve the ambiguity be-
tween the parsing operations ?Shift? and ?Reduce?. 
(2) using a root node finder and dividing the sen-
tence at the root node to make use of the top-down 
information. (3) extracting the prepositional phrase 
(PP) to resolve the problem of identifying the 
boundary of PP. 
We incorporated Nivre?s method with these 
preprocessing methods for Chinese dependency 
analysis with Penn Chinese Treebank and Sinica 
Treebank (Chen   et al, 2003). This was effective 
because of the properties of Chinese: First, there is 
no multi-root in Chinese Treebank. Second, the 
boundary of prepositional phrases is ambiguous. 
We found that these methods do not always im-
prove the accuracy of all the languages in the 
shared task.  
We have tried the method (1) in some lan-
guages to see if there is any improvement in the 
parser. We attempted to use global features and 
two-step analysis to resolve the ambiguity of the 
operations. In Chinese (Chen   et al, 2003) and 
Danish (Kromann, 2003), this method can improve 
the parser performance. However, in other lan-
guages, such as Arabic (Haji? et al, 2004), this 
method decreased the performance. The reason is 
that the sentence in some languages is too long to 
use global features. In our preceding work, the 
global features include the information of all the 
un-analyzed words. However, for analyzing long 
sentences, the global features usually include some 
useless information and will confuse the two-step 
process. Therefore, we do not use this method in 
this shared task. 
In the method (2), we construct an SVM-based 
root node finder to identify the root node and di-
vided the sentence at the root node in the Chinese 
Treebank. This method is based on the properties 
of dependency structures ?One and only one ele-
ment is independent? and ?An element cannot have 
modifiers lying on the other side of its own head?. 
However, there are some languages that include 
multi-root sentences, such as Arabic, Czech, and 
Spanish (Civit and Mart?, 2002), and it is difficult 
to divide the sentence at the roots. In multi-root 
sentences, deciding the head of the words between 
roots is difficult. Therefore, we do not use the 
method (2) in the share task.  
The method (3) ?namely PP chunker? can iden-
tify the boundary of PP in Chinese and resolve the 
ambiguity of PP boundary, but we cannot guaran-
tee that to identify the boundary of PP can improve 
the parser in other languages. Even we do not un-
derstand construction of PP in all languages. 
Therefore, for the robustness in analyzing different 
languages, we do not use this method. 
2.3.2   Neighboring dependency attachment 
tagger 
In the bottom-up dependency parsing approach, the 
features and the strategies for parsing in early stage 
(the dependency between adjacent2 words) is dif-
ferent from parsing in upper stage (the dependency 
between phrases). Parsing in upper stage needs the 
information at the phrases not at the words alone. 
The features and the strategies for parsing in early 
and upper stages should be separated into distinct. 
Therefore, we divide the neighboring dependency 
attachment (for early stage) and normal depend-
ency attachment (for upper stage), and set the 
neighboring dependency attachment tagger as a  
preprocessor. 
When the parser analyzes an input sentence, it 
extracts the neighboring dependency attachments 
first, then analyzes the sentence as described be-
fore. The results show that tagging the neighboring 
dependency word-pairs can improve 9 languages 
out of 12 scoring languages, although in some lan-
guages it degrades the performance a little. Poten-
tially, there may be a number of ways for 
decomposing the parsing process, and the current 
method is just the simplest decomposition of the 
process. The best method of decomposition or dy-
namic changing of parsing models should be inves-
tigated as the future research. 
                                                          
2 We extract all words that depend on the adjacent word (right 
or left). 
193
3 Experiment 
3.1 Experimental setting 
Our system consists of three parts; first, the SVM-
based tagger extracts the neighboring attachment 
relations of the input sentence. Second, the parser 
analyzes further dependency attachments. If a new 
dependency attachment is generated, the MaxEnt 
based tagger estimates the label of the relation. The 
three parts of our parser are trained on the avail-
able data of the languages. 
In our experiment, we used the full information 
of each token (FORM, LEMMA, CPOSTAG, 
POSTAG, FEATS) when we train and test the 
model. Fig. 2 describes the features of each token. 
Some languages do not include all columns; such 
that the Chinese data does not include LEMMA 
and FEATURES, these empty columns are shown 
by the symbol ?-? in Fig. 2. The features for the 
neighboring dependency tagging are the informa-
tion of the focused word, two preceding words and 
two succeeding words. Fig. 2 shows the window 
size of our features for estimating the word de-
pendency in the main procedures. These features 
include the focused words (n, t), two preceding 
words and two succeeding words and their children. 
The features for estimating the relation label are 
the same as the features used for word dependency 
analysis. For example, if the machine learner esti-
mates the operation of this situation as ?Left? or 
?Right? by using the features in Fig. 2, the parser 
uses the same features in Fig. 2 and the depend-
ency relation to estimate the label of this relation.  
For training the models efficiently, we divided 
the training instances of all languages at the 
CPOSTAG of the focused word n in Fig .2. In our 
preceding work, we found this procedure can get 
better performance than training with all the in-
stances at once. However, only the instances in 
Czech are divided at the CPOSTAG of the focused 
word-pair t-n3. The performance of this procedure 
is worse than using the CPOSTAG of the focused 
word n, because the training instances of each 
CPOSTAG-pair will become scarce. However, the 
data size of Czech is much larger than other lan-
guages; we couldn?t finish the training of Czech 
using the CPOSTAG of the focused word n, before 
the deadline for submitting. Therefore we used this 
procedure only for the experiment of Czech. 
                                                          
3 For example, we have 15 SVM-models for Arabic according 
to the CPOSTAG of Arabic (A, C, D, F, G?etc.). However, 
we have 139 SVM-models for Czech according the 
CPOSTAG pair of focused words (A-A, A-C, A-D?etc.) 
All our experiments were run on a Linux ma-
chine with XEON 2.4GHz and 4.0GB memory. 
The program is implemented in JAVA. 
3.2   Results 
Table 1 shows the results of our parser. We do not 
take into consideration the problem of cross rela-
tion. Although these cross relations are few in 
training data, they would make our performance 
worse in some languages. We expect that this is 
one reason that the result of Dutch is not good. The 
average length of sentences and the size of training 
data may have affected the performance of our 
parser. Sentences of Arabic are longer and training 
data size of Arabic is smaller than other languages; 
therefore our parser is worse in Arabic. Similarly, 
our result in Turkish is also not good because the 
data size is small. 
     We compare the result of Chinese with our pre-
ceding work. The score of this shared task is better 
than our preceding work. It is expected that we 
selected the FORM and CPOSTAG of each nodes 
as features in the preceding work. However, the 
POSTAG is also a useful feature for Chinese, and 
we grouped the original POS tags of Sinica Tree-
bank from 303 to 54 in our preceding work. The 
number of CPOSTAG(54) in our preceding work 
is more than the number of CPOSTAG(22) in this 
shared task, the training data of each CPOSTAG in 
our preceding work is smaller than in this work.  
Therefore the performance of our preceding work 
in Sinica Treebank is worse than this task. 
     The last column of the Table 1 shows the unla-
beled scores of our parser without the preprocess-
ing. Because our parser estimates the label after the 
dependency relation is generated. We only con-
sider whether the preprocessing can improve the 
unlabeled scores. Although the preprocessing can 
not improve some languages (such as Chinese, 
Spanish and Swedish), the average score shows 
that using preprocessing is better than parsing 
without preprocessing. 
     Comparing the gold standard data and the sys-
tem output of Chinese, we find the CPOSTAG 
with lowest accuracy is ?P (preposition)?, the accu-
racy that both dependency and head are correct is 
71%. As we described in our preceding work and 
Section 2.3, we found that boundaries of preposi-
tional phrases are ambiguous for Chinese. The bot-
tom-up algorithm usually wrongly parses the 
prepositional phrase short. The parser does not  
capture the correct information of the children of 
the preposition. According to the results, this prob-
lem does not cause the accuracy of head of  
194
CPOSTAG ?P? decrease. Actually, the head accu-
racy of ?P? is better than the CPOSTAG ?C? or 
?V?. However, the dep. accuracy of ?P? is worse. 
We should consider the properties of prepositions 
in Chinese to resolve this question. In Chinese, 
prepositions are derived from verbs; therefore 
some prepositions can be used as a verb. Naturally, 
the dependency relation of a preposition is differ-
ent from that of a verb. Important information for 
distinguishing whether the preposition is a verb or 
a preposition is the information of the children of 
the preposition. The real POS tag of a preposition 
which includes few children is usually a verb; on 
the other hand, the real POS tag of a preposition is 
usually a preposition.  
If our parser considers the preposition which 
leads a short phrase, the parser will estimate the 
relation of the preposition as a verb. At the same 
time, if the boundary of prepositional phrase is 
analyzed incorrectly, other succeeding words will 
be wrongly analyzed, too.  
Error analysis of Japanese data (Kawata and  
Bartels, 2000) shows that CNJ (Conjunction) is a 
difficult POS tag. The parser does not have any 
module to detect coordinate structures. (Kurohashi, 
1995) proposed a method in which coordinate 
structure with punctuation is detected by a coeffi-
cient of similarity. Similar framework is necessary 
for solving the problem. 
 Another characteristic error in Japanese is seen 
at adnominal dependency attachment for a com-
pound noun. In such dependency relations, adjec-
tives and nouns with "no" (genitive marker) can be 
a dependent and compound nouns which consist of 
more than one consecutive nouns can be a head. 
The constituent of compound nouns have same 
POSTAG, CPOSTAG and FEATS. So, the ma-
chine learner has to disambiguate the dependency 
attachment with sparce feature LEMMA and 
FORM. Compound noun analysis by semantic fea-
ture is necessary for addressing the issue. 
4 Conclusion 
This paper reported on multi-lingual dependency 
parsing on combining SVMs and MaxEnt. The 
system uses SVMs for word dependency attach-
ment analysis and MaxEnt for the label tagging 
when the new dependency attachment is generated. 
We discussed some preprocessing methods that are 
useful in our preceding work for Chinese depend-
ency analysis, but these methods, except one, can-
not be used in multi-lingual dependency parsing. 
Only using the SVM-based tagger to extract the 
neighbor relation could improve many languages 
in our experiment, therefore we use the tagger in 
the parser as its preprocessing. 
References 
S. Buchholz, E. Marsi, A. Dubey and Y. Krymolowski. 2006. 
CoNLL-X: Shared Task on Multilingual Dependency Pars-
ing, CoNLL 2006. 
Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto. 
2005a. Chinese Deterministic Dependency Parser: Exam-
ining Effects of Global Features and Root Node Finder, 
Fourth SIGHAN Workshop, pp.17-24. 
Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto. 
2005b. Machine Learning-based Dependency Parser for 
Chinese, the International Conference on Chinese Comput-
ing, pp.66-73. 
Ulrich. H.-G. Kre?el, 1998. Pairwise classification and sup-
port vector machines. In Advances in Kernel Methods, pp. 
255-268. The MIT Press. 
Taku Kudo. CRF++: Yet Another CRF toolkit, 
http://www.chasen.org/~taku/software/CRF++/. 
Sadao Kurohashi. 1995. Analyzing Coordinate Structures 
Including Punctuation in English, In IWPT-95, pp. 136-147. 
Chih Jen Lin, 2001. A practical guide to support vector classi-
fication, http://www.csie.ntu.edu.tw/~cjlin/libsvm/. 
Joakim Nivre, 2004. Incrementality in Deterministic Depend-
ency Parsing, In Incremental Parsing: Bringing Engineer-
ing and Cognition Together. Workshop at ACL-2004, pp. 
50-57. 
Adwait Ratnaparkhi, 1999. Learning to parse natural lan-
guage with maximum entropy models. Machine Learning, 
34(1-3):151-175. 
Vladimir N. Vapnik, 1998. Statistical Learning Theory.  A 
Wiley-Interscience Publication. 
Language: LAS: UAS: LAcc. UAS with out preprocessing:
Arabic 65.19 77.74 79.02 76.74 
Chinese 84.27 89.46 86.42 90.03 
Czech 76.24 83.4 83.52 82.88 
Danish 81.72 88.64 86.11 88.45 
Dutch 71.77 75.49 75.83 74.97 
German 84.11 87.66 90.67 87.53 
Japanese 89.91 93.12 92.40 92.99 
Portugese 85.07 90.3 88.00 90.21 
Slovene 71.42 81.14 80.96 80.43 
Spanish 80.46 85.15 88.90 85.19 
Swedish 81.08 88.57 83.99 88.83 
Turkish 61.22 74.49 73.91 74.3 
AV: 77.7 84.6 84.1 84.38 
SD: 8.67 6.15 5.78 6.42 
Bulgarian 86.34 91.3 89.27 91.44 
Table 1: Results 
195
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 245?248,
Prague, June 2007. c?2007 Association for Computational Linguistics
NAIST.Japan: Temporal Relation Identification Using Dependency Parsed
Tree
Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto
Graduate School of Informatino Science,
Nara Institute of Science and Technology
8916-5 Takayama, Ikoma, Nara, 630-0192, Japan
 yuchan-c, masayu-a, matsu@is.naist.jp
Abstract
In this paper, we attempt to use a sequence
labeling model with features from depen-
dency parsed tree for temporal relation iden-
tification. In the sequence labeling model,
the relations of contextual pairs can be used
as features for relation identification of the
current pair. Head-modifier relations be-
tween pairs of words within one sentence
can be also used as the features. In our pre-
liminary experiments, these features are ef-
fective for the temporal relation identifica-
tion tasks.
1 Overview of our system
This paper presents a temporal relation identifier by
the team NAIST.Japan. Our identifier has two char-
actaristics: sequence labeling model and use of de-
pendency parsed tree.
Firstly, we treated each problem a sequence la-
beling problem, such that event/time pairs were or-
dered by the position of the events and times in the
document. This idea is for task B and C. In task
B, the neighbouring relations between an EVENT
and DCT-TIMEX3 tend to interact. In task C, when
EVENT-a, EVENT-b, and EVENT-c are linearly or-
dered, the relation between EVENT-a and EVENT-
b tends to affect the one between EVENT-b and
EVENT-c.
Secondly, we introduced dependency features
where each word was annotated with a label indi-
cating its tree position to the event and the time, e.g.
?descendant? of the event and ?ancestor? of the time.
The dependency features are introduced for our ma-
chine learning-based relation identifier. In task A,
we need to label several different event-time pairs
within the same sentence. We can use information
from TIMEX3, which is a descendent of the target
EVENT in the dependency tree.
Section 2 shows how to use a sequence labeling
model for the task. Section 3 shows how to use
the dependency parsed tree for the model. Section
4 presents the results and discussions.
2 Temporal Relation Identification by
Sequence Labeling
Our approach to identify temporal relation is based
on a sequence labeling model. The target pairs are
linearly ordered in the texts.
Sequence labeling model can be defined as a
method to estimate an optimal label sequence    
  
 
  

      
 
 over an observed sequence   
 
 
 

     
 
. We consider, -parameterized
function
   	
 

      	
 
   
Here,  denotes all possible label combinations over
 ;    denotes a feature expression over   .
Introducing a kernel function:
   	 	       	 	 
we have a dual representation:

     

 
 





 
 

   
245
given a training data set


 
 
 
 
     


 
 

. We use
HMM SVM (Altun et al, 2003) as the sequence
labeling model, in which the training is performed
to maximize a margin


  
 


 
 

  
  
  

 


  
The sequence labeling approach is natural for task
B and C. In task B, if a document is about affairs in
the past, the relations between events and a docu-
ment creation time tend to be ?BEFORE?. All rela-
tions in task B depend on each other. In task C, if a
relation between the preceding event and the current
one is ?AFTER?, the current one is in the past. The
information helps to determine the relation between
the current and succeeding one. Whereas we have
reasonable explanation to introduce sequence label-
ing for task B and C, we cannot for task A. However,
in our preliminary experiments with trial data, the
sequence labeling model outperformed point-wise
models for task A. Thus, we introduce the sequence
labeling model for task A.
Now, we present the sequence labeling approach
for each task in detail by figure 1, 2 and 3. The
left parts of figures are the graphical models of the
sequence labeling. The right parts are the tagged
corpus:  S and  S are sentence boundaries; a
EVENT-nn denotes an EVENT; a TIME-nn de-
notes a TIMEX3; a TIME-DCT in figure 2 de-
notes a TIMEX3 with document creation time; a
boxed EVENT-nn in figure 3 denotes a matrix verb
EVENT.
For task A (figure 1),  is a sequence of pairs be-
tween an EVENT and a TIMEX3 within the same
sentence.   is a sequence of corresponding relations.
Event-time pairs are ordered first by sentence posi-
tion, then by event position and finally by time posi-
tion. For task B (figure 2),  is a sequence of pairs
between an EVENT and a DCT-TIMEX3.   is a se-
quence of corresponding relations. All pairs in the
same text are linearly ordered and connected. For
task C (figure 3),  is a sequence of pairs between
two matrix verb EVENTs in the neighboring sen-
tences.   is a sequence of corresponding relations.
All pairs in the same text are linearly ordered and
connected, even if the two relations are not in the
adjacent sentences.
xy
EVENT_01?TIME_01 ......................
..............TIME_02..........................
.................EVENT_02????..
......TIME_03 .........EVENT_03.......
EVENT_01?TIME_01
<s>
.
.
.
<s>
</s>
</s>
.
.
.
Before
Before
After
Overlap
Overlap
EVENT_01?TIME_02
EVENT_02?TIME_01
EVENT_02?TIME_02
EVENT_03?TIME_03
Figure 1: Sequence Labeling Model for Task A
xy
EVENT_01..................................
.................EVENT_02
.........EVENT_03...........
EVENT_01?TIME_DCT
EVENT_02?TIME_DCT
EVENT_03?TIME_DCT
EVENT_04?TIME_DCT
EVENT_05?TIME_DCT
<s>
.
.
.
<s>
</s>
</s>
Before
Before
Overlap
Before
Before
TIME_DCT
.................EVENT_04.................
.................EVENT_05
<s>
</s>
Figure 2: Sequence Labeling Model for Task B
xy EVENT_01 ..................................
................. EVENT_02
......... EVENT_03 ...........
EVENT_01?EVENT_03
EVENT_03?EVENT_04
EVENT_04?EVENT_06
<s>
<s>
</s>
</s>Before
After
Overlap
................. EVENT_04 ............... EVENT_05
<s>
</s>
......... EVENT_06 ...........
<s>
</s>
Figure 3: Sequence Labeling Model for Task C
3 Features from Dependency Parsed Tree
A dependency relation is a head-modifier relation on
a syntactic tree. Figure 4 shows an example de-
pendency parsed tree of the following sentence ?
?The warrants may be exercised until 90 days after
their issue date?. We parsed the TimeEval data us-
ing MSTParser v0.2 (McDonald and Pereira, 2006),
which is trained with all Penn Treebank (Marcus et
al., 1993) without dependency label.
We introduce tree position labels between an tar-
get node and another node on the dependency parsed
tree: ANC (ancestor), DES (descendant), SIB (sib-
ling), and TARGET (target word). Figure 5 shows
the labels, in which the box with double lines is the
target node. The tree position between the target
EVENT and a word in the target TIMEX3 is used
as a feature for our machine learning-based relation
identifier.
We also use the words in the sentence including
the target entities as features. Each word is anno-
246
The
warrants
may
be
exercised
until
90
days
after
their
issue
date
Figure 4: An example of dependency parsed tree
ANC
ANC
TARGET
DES
ANC
SIB
DESDES
SIB
ANC
Figure 5: Tree position labels
The
warrants
may
be
exercised
until
90
days
after
their
issue
date
ANC
ANC
ANC
ANC
DES
DES
DES
DES
DES
DES
DES
TARGET The
warrants
may
be
exercised
until
90
days
after
their
issue
date
ANC
ANC
ANC
ANC
ANC
ANC
TARGET
TARGET
SIB
SIB
SIB
ANC The
warrants
may
be
exercised
until
90
days
after
their
issue
date
ANC/ANC
ANC/ANC
ANC/ANC
ANC/ANC
DES/ANC
DES/ANC
DES/TARGET
DES/TARGET
DES/SIB
DES/SIB
DES/SIB
TARGET/ANC
TARGET node: ?exercised? TARGET nodes: ?90? and ?days? TARGET-A node: ?exercised?
TARGET-B nodes: ?90? and ?days?
(1) EVENT-based (2) TIMEX3-based (3) JOINT
Figure 6: Tree position labels on the example dependency parsed tree
tated with (1) its tree position to the EVENT, (2)
its tree position to the TIMEX3, and (3) the com-
bination of the labels from (1) and (2). Fig. 6
shows the labels of tree positions. The left picture
shows (1) EVENT-based labels of the tree position
with the target EVENT ?exercised?. The center pic-
ture shows (2) TIMEX3-based ones with the target
TIMEX3 ?90 days?. The right picture shows (3)
JOINT ones which are combinations of the relation
label with the EVENT and with the TIMEX3. We
perform feature selection on the words in the cur-
rent sentence according to the tree position labels.
Note that, when MSTparser outputs more than one
trees for a sentence, we introduce a meta-root node
to bundle the ones in a tree.
4 Results and Discussions
We use HMM SVM 1as a sequence labeling model
with features in Table 1, 2 and 3 for task A, B and
C, respectively. The attributes value in TIMEX3
1http://svmlight.joachims.org/svm_
struct.html
is encoded as the relation with DCT-TIMEX3:
BEFORE, OVERLAP, AFTER, VAGUE. In
task A, only words in the current sentence with
JOINT relation labels ?TARGET/? or ?ANC/? or
?*/DES?2 were used. In task C, attributes in the
TIMEX3 are annotated with the flag whether the
TIMEX3 entity is the highest (namely the nearest
to the root node) in the tree. Some adverbs and con-
junctions in the succeeding sentence help to deter-
mine the adjacent two relations. Thus, we introduce
all words in the succeeding sentence for Task A and
B. These features are determined by our preliminary
experiments with the trial data .
Table 4 is our results on the test data. Whereas,
our system is average rank in task A and B, it is
worst mark in task C. The features from dependency
parsed trees are effective for task A and B. However,
these are not for task C.
Now, we focus on what went wrong instead of
what went right in our preliminary experiments in
trial data. We tried point-wise methods with other
2
? ? stands for wild cards.
247
Table 1: Features for Task A
all attributes in the target EVENT
all attributes in the target TIMEX3
the attributes value is encoded as the relation with
DCT-TIMEX3
all words in the current sentence with TIMEX3-based
label (2) of tree position
words in the current sentence with JOINT label (3) of
tree position
 only relation label with ?TARGET/ ? or ?ANC/ ? or
?*/DES? (  stands for wild cards)
label (1) of tree position from the EVENT to the
TIMEX3
all words in the succeeding sentence
Table 2: Features for Task B
all attributes in the target EVENT
all attributes in the target TIMEX3 of in the current sen-
tence with EVENT-based label (1) of tree position
all attributes in the target TIMEX3 of in the preceding
and succeeding sentence
all words in the current sentence with EVENT-based la-
bel (1) of tree position
all words in the succeeding sentence
Table 3: Features for Task C
all attributes in the target two EVENTs (EVENT-1 and
EVENT-2)
all attributes in the TIMEX3 in the sentence including
EVENT-1 with the label (1) of tree position to EVENT-
1
all attributes in the TIMEX3 in the sentence including
EVENT-2 with the label (1) of tree position to EVENT-
2
all words in the sentence including EVENT-1 with the
label (1) of tree position to EVENT-1
all words in the sentence including EVENT-2 with the
label (1) of tree position to EVENT-2
machine learners such as maximum entropy and
multi-class support vector machines. However, se-
quence labeling method with HMM SVM outper-
formed other point-wise methods in the trial data.
We have dependency parsed trees of the sen-
tences. Naturally, it would be effective to intro-
duce point-wise tree-based classifiers such as Tree
Kernels in SVM (Collins and Duffy, 2002; Vish-
wanathan and Smola, 2002) and boosting for clas-
sification of trees (Kudo and Matsumoto, 2004). We
tried a boosting learner 3which enables us to perform
subtree feature selection for the tasks. However, the
boosting learner selected only one-node subtrees as
useful features. Thus, we perform simple vector-
based feature engineering on HMM SVM.
3http://chasen.org/?taku/software/bact/
Table 4: Results
Task P R F Rank
Task A (strict) 0.61 0.61 0.61 2/6
Task A (relaxed) 0.63 0.63 0.63 2/6
Task B (strict) 0.75 0.75 0.75 2/6
Task B (relaxed) 0.76 0.76 0.76 2/6
Task C (strict) 0.49 0.49 0.49 5/6
Task C (relaxed) 0.56 0.56 0.56 6/6
We believe that it is necessary for solving task C
to incorporate knowledge of verb-verb relation. We
also tried to use features in verb ontology such as
VERBOCEAN (Chklovsky and Pantel, 2004) which
is used in (Mani et al, 2006). It did not improved
performance in our preliminary experiments with
trial data.
References
Y. Altun, I. Tsochantaridis, and T. Hofmann. 2003. Hid-
den markov support vector machines. In Proc. of
ICML-2003.
T. Chklovsky and P. Pantel. 2004. Verbocean: Mining
the web for fine-grained semantiv verb relations. In
Proc. of EMNLP-2004.
M. Collins and N. Duffy. 2002. New ranking algorithms
for parsing and tagging: Kernels over discrete struc-
tures, and the voted perceptron. In Proc. of ACL-2002.
T. Kudo and Y. Matsumoto. 2004. A boosting algorithm
for classification of semi-structured text. In Proc. of
EMNLP-2004.
I. Mani, M. Verhagen, B. Wellner, C. M. Lee, and
J. Pustejovsky. 2006. Machine learning of temporal
relations. In Proc. of ACL-2006.
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a large annotated corpus of English: the Penn
Treebank. 19(2):313?330.
R. McDonald and F. Pereira. 2006. Online learning of
approximate dependency parsing algorithms. In Proc.
of EACL-2006.
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,
and J. Pustejovsky. 2007. Semeval-2007 task 15:
Tempeval temporal relation identification. In Proc. of
SemEval-2007.
S. V. N. Vishwanathan and A. J. Smola. 2002. Fast ker-
nels on strings and trees. In Proc. of NIPS-2002.
248
