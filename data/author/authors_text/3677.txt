Boost ing Variant Recognit ion with Light Semantics 
C5c i le  Fabre 
ERSS / \]Ddpt de Sciences du Langage 
Univ. Toulouse-Le Mirail 
5 alldes A. Machado 
31058 Toulouse Cedex, France 
c fabreOun iv - t l se2 ,  f r  
Chr i s t ian  Jacquemin 
CNRS-LIMSI  
BP 133 
91403 ORSAY Cedex 
FI'&IICe 
j acquemin@limsi, fr 
Abst ract  
A reasonably simple, domain-independent, 
large-scale approach of lexictd semantics to 
paraphrase recognition is presented in this pa- 
per. It relies on the enrichment of morpho- 
syntactic rules and the addition of fbur boolean 
syntactico-semantic features to a set of 1.,(}23 
words. It results in a significant enhancement 
of precision of 30% with a slight decrease in re- 
call of 10%. 
1 Overv iew 
The recognition ,of paraphrases and variants is 
an important issue in several areas of infornm- 
tion retrieval and text mlderstanding. Merging 
paraphrastic sentences ilnproves ummarization 
by avoiding redundancy (Barzilay et al, 1999). 
Term variant conilation enhances recall in in- 
tbrmation retrieval by pointing at documents 
that contain linguistic variants of (tuery terms 
(Arampatzis et al, 1998). 
In (Jacquemin and Tzoukermann, 1999), a 
technique is proposed for the conflation of 
morpho-syntactic variants that relies solely on 
morphological and low-level syntactic features 
(part-of-speech category, munber agreement, 
morphological relationships, and phrase struc- 
ture). An analysis of these results shows the 
limitation of this approach: correct and incor- 
rect variants cannot be separated satisfactorily 
on a purely morpho-syntactic basis. Sonic addi- 
tional lexical semantics must be taken into con- 
sideration. 
In this study we propose a reasonably sim- 
ple, domain-independent, large-scale approach 
of lexical semantics to noun-to-verb variant 
recognition. It relies on the mere addition of 
two t)oolean syntactic features to 449 verbs and 
two boolean morpho-semantic features to 574 
nouns. It result,; in a significant enhancement 
of precision of 30% with a slight decrease in re- 
call of 10%. This new al)proaeh to semantics-- 
human-based, ettlcient, involving simple linguis- 
tic tbatures --convincingly illustrates the posi- 
tive role of linguistic knowledge in information 
processing. It confirms that verbs and their se- 
mantics play a significant role in document anal- 
ysis (Klavans and Kan, 1998). 
2 Morpho-syntactic Approach to 
Nomino-verba l  Var ia t ion  
In order to illustrate the contribution of se- 
mantics to the detection of paraphrastic struc- 
tures, we focus on a specific type of wtriation: 
the vo.rl)al varbmts of Noun-Preposition-Noun 
terms o1" compounds in French. For example, 
les corttraintes rdsiduellcs darts les coques sont 
anaIysdes (the residual constraints in the shells 
~re mialyzed) is such a vert)al variant of analyse 
de corttraintc (constraint analysis). 
As a baseline tbr the extr~mtion of these vari- 
ants, we use a set of five morpho-syntactic rans- 
tbrmations fbr Noun-Preposition-Noun terms 
reported in (Jacquemin and Tzoukernlann, 
1999) (see Table 1). 1 We use the no- 
tation Ad(Ni)v for |;tie inorphological ink 
between the initial term and the trans- 
ibrmed structure. It rel)resents any verb 
in the same morphological fanfily as Ni. 
For instance, in English, and according 
to the CELEX database, Ad(analysis)v = 
{to analyze, to psychoanalyze}. 
Given a NI P2 N8 structure, these transt'ornm- 
tions are obtained through corpus-based tuning 
1The following symbols are used for syntactic ate- 
gories: N (nouI0, A (adjective), Av (adverb), V (verb), C 
(coordinating conjunction), P (pret}osition), and D (de- 
tcrminer). In the regular exl}ressions, ? denotes option- 
ality and I disjunction. Morphologically related words 
are underlined. 
264 
Tal)le 1: Mort)he-syntactic (MS) Variants of N1 P2 Na Terms 
NheadToV: Ad(N~ )v (Av: (P'? \]) \[P D '?) A:) N:~ 
stabilisation de priz (price sl;al)ilization) ~ stabiliser le'm's priz (stal)ilize their prices) 
NheadToVRev:  Na(A? (PA?N(A(CA)?)?)? (CI)': Av': A'?NA?)'?V':V': Av':)A4(N1)v 
abattage d'arbre (tree cutting) -+ m'bres oat dtd abattus (trees have been cut down) 
Nmodi fToV l :  N1 ((Av ? A (C av '? A)'?) ': V': P) fl4(Na)v 
mdth, ode d'.dvaluatio~ (method of evaluatio~ 0 ~ mdth, ode pour d'valuer (method tbr ewduating) 
NmodifToV2: Nj (A': (V\[ (l) D "? (Av': A) '? N) '?) (Av '? A)': Av':) Ad(Na)v 
zone de ddstabilisation (region of destal)ilization) --+ zone d&tabilisde (destat)ilized region) 
Nmodi fToVRev:  Ad(Ua)v (Av '? (P'? l)) \[ (P D':)A':) N~ 
tcrnpdrat,ure de chau./.\[age (temi)erature fi)r heating_') 
-+ chau/.\]~s a h, aute tempdrat'urc, (heated at high teml)eratures) 
and correspond basically to tbur configurations: 
1. either N1 or Na (re, st)cct;ivcly head and 
modifier of the initial term) is I;r~msformed 
into a morphologically related verb V, 
2. the order of the two content words is re- 
tained or reversed, 
3. the dependency relation 1)etween 1;11(; two 
initial 11011118 is preserved. 
For instance, rule NheadqlbVl/,ev corresl)onds 
to transfi)rmations in whi(:h the, head noun 
is morphologically re,1;~t(;d to the verl) and 
t:h(; ord('r of the two words is re, verse(l; rul(; 
Nmodit'FoV (modifier transfi)rmed, order r(;- 
rained) has been divided into two sul)ruh;s: the 
first one - Nmo(tifYoV1 - re, quires the insertion 
of a pr(;positiou just 1)eft)re th(; verbal form. 
3 The L imi ts  o f  the  
Morpho-syntact i c  A I )p roach  
In the tirst step of this work, we ext)e(:ted th(, 
precision of wu:iant recoglfition to be controlled 
in two ways: firstty, by searching fi)r multi- 
term variants in which the two content words of 
the initial term are foulM, directly or via mor- 
1)hological transformation. Se(:ondly, by dell1> 
ing morpho-syntacti(: pa|;te.rns of variation in 
I;erms of l)art-of-sl)eech strings that are allowed 
to come in 1)e.tween these t;wo COlll;eltt words. 
Yet, the sequences found on su(;h a morl)ho- 
synl;acti(: basis prove to 1)e of wtrying quality 
regarding their at/ility to t)rovide t)arat)hrases 
of the initial l;erm. Consider for instance some 
of l;he vm:imlts del, eeted for the term comparai- 
son de rds'ultat (comparison of results), in which 
only t;11(; \[irst; |;we sequences are good variants: 
compare les rdsultats ((:onlpare the results) 
(rule Nhead~lbV, pattern A4 (N1)vDNa) 
r&ultats ezpdrirnc.ntauz sent compar& (exI)er- 
imental results are compared) (rule Nhead- 
toVRev, 1)atte.rn NaAVA4 (N~)v) 
com, pard.s a'ux 'rds'.,ltats (COmlmred to 
the results) (rule NheadToV, pattern 
Jt4(N1)vPN:{) 
rds'ultd d"unc eomparaison (resulted from ;t 
comparison) (rule NModiiToVRev, pattern 
J~d (Na)vPDN1 )
Such examples show that morpho-syntactie 
patterns ;~re 1;oo coarse-gr~tined to ensure l;hat 
the dependency relation between the two piv- 
ots (results is the object of the prediea?e com- 
parison) is maintained. When trying to detine 
linguistic criteria to ewfluate such w~riants, it; 
apt)ears that the frontier between good and load 
variants lies between those that preserve the ar- 
gument relation 1)etween the two content words 
and those that disrupt it. This means that, in 
the verbal wtriant, the. argument relation be- 
tween the verb and l;he noun must be l;he same 
as t;he relal;io11 between the deverl)al lOUll add 
the othe.r noun in the nominal term. 
None of the five rules ensures that the subcat- 
egorization frame is preserved. For instance, if 
we consider t;11o rule NModifI'oVl{ev, we find se- 
265 
quences that obey this constraint and sequences 
that violate it2: 
cr'itdrc d'&aluation (evaluation criterion) -+ 
dvalv, dselon les crit~r'cs (evahmted according to 
the criteria) 
syst~me d'dvaluation (evaluation system) *--+ 
dvaht6 lc syst&ne (evaluated the system) 
In the second case, the transtbrmation is un- 
acceptable because the instrumental relation ex- 
pressed in the nonfinal term becomes an ob- 
ject relation in the verbal sequence. Even 
when word order is preserved, the relation be- 
tween the pivots can be totally different in the 
term and its transformation, as i.u: contrgIe 
d'installation (installation control) and contrgle 
ccntralisd installd (installed centralized control) 
(rule NModitToV2). 
Our aim was to tbrmulate additional con- 
straints in order to control argument structure 
preservation. We thus had to cope with prob- 
lem of handling nonfinal t)hrases (NP) in which 
one of the elements is morphologically inked to 
a verb. In French, as in English, the seman- 
tics of these nominal phrases is an issue tbr lin- 
guistic description: the two nouns can be linked 
by the whole range of argmnent-predicate rela- 
tions, and very few linguistic elements can be 
used to decide what relation is expressed. Here 
is a brief list of the configurations that are likely 
to appear in such NPs: 
- the second noun is the object of the first; one: 
comparaison de rdsultat (comparison of result) 
- the second noun is the subject of the first 
one: augmentation de I'intcv, sitd (increase in in- 
tensity) 
- the second noun is an adjunct: tr'aitcment g
la chaleur (treating with heat) 
the first noun is an adjunct: taux 
d'augmentation (increase rate) 
Our aim was to find a way to use surface lin- 
guistic knowledge, as required in such an area 
of NLP, to deal with the interpretation of these 
phrases. 
4 Light Semant ics  for 
Nomino-verba l  Variat ions 
Our approach consisted of two steps: firstly, 
defining semantic lues tbr accepting or discard- 
sin what follows~ the symbols --~ and *----> respectively 
indicate correct and incorrect ransformations 
ing variants and, secondly, defining new varia- 
tion patterns based oll these features. 
4.1 F i l ter ing  Cr i te r ia  
First, using linguistic results on the semantics 
of French NPs (Fabre, 1996; Bartning, 1990), 
we identified predicate-argument configurations 
that cannot be matched by a given pattern ('re- 
ject' heuristics in the sense of (Lapata, 1999)). 
For example, when rule NmodifToVRev applies, 
N1 de N3 terms cannot be i)araphrased by ver- 
bal sequences in which N1 is the ol)ject of the 
verb, as in: ezp&iencc d'utilisation (experiment 
of use) *-+ utilisait 'uric ezpdrier~,cc (used an ex- 
periment). In such a configuration, only non-- 
thematic arguments (adjuncts) of the deverbal 
noun may be tbund inside the NP. 
Similarly, when rule NheadToVRev applies, 
N\] de N3 terms cannot be paraphrased by ver- 
bal sequences in which N\] is the subject of a 
transitive verb, as in: utilisation de l'ezp&'icnce 
(use of experiment) *-+ czpdriencc utilisant (ex- 
t)eriment using). 
This configuration provides variants only 
when the verb is intransitive or ergative: erga- 
tive verbs allow tbr alternations of the tbrm: NP 
V (la dcnsitd au.qrncntc) / one V NP (on awl- 
monte la dcnsitd). 
In this case, the tbllowing transtbrmation is 
correct: augmentation de densitd (density in- 
crease) / de,,,,s'itd av,9'mentc (density increases). 
4.2 Enriched Metarules 
Once it has 1)een established wtfich transforma- 
tions should be rejected, we searched tbr sur- 
face linguistic clues that could help us to fil- 
ter out these undesirable variants. It led us to 
the redefinition of the metarules, in two ways: 
putting additional constraints on the part-of  
speech strings that can intervene between the 
two pivots, and defining new features to add lin- 
guistic control upon the application of the rules. 
These t~atures are: the prepositional form, the 
morphological type of the noun, the transitivity 
of the verb, and the voice (active versus pas- 
sive). 
Here are two examples tbr the redefinition of 
the metarules (fllrther details and examples are 
given in table 3): 
ru le Nmodi fToVRev In this case, the 
metarule is transtbrmed into a single 
266 
17elilled rule, in whi('h the ('oml)ilm|:ion 
of parts of sl)eech is mot(; res|;riel;ed: a 
preposition is required to elinfinate object 
rein|ions from the verbal phrase. In ~ul- 
dition, the morphologic~dly comt)lex nora1 
must be ~ \])recessive deverl)M. %'anstbr- 
martens such a.s czpdricnce d',utili.srltion 
*-> ul, ili.sa, it. 'u, ne  c.zpdricncc, a.re filtered 
()u|;. 
rule NheadToVRev Here, the initial 
metarule is refined into three em'iched 
rules, mainly by means of lexical con- 
straints on the verb tbrm. Only N1 P2 Na 
t;(;171118 whe, re 1)2 = dc m:e |;real;ed. \]if the 
v(;rl) is transitive, l;helt the verb forln nlUSI; 
l)e ;t past t)m;l;i(;il)le (rule Nlw, a(tt()Vl/.('v- 
\])ass), so l;ha, t 1;t1(', object relation still hol(ls 
in the vm'iant, if the verl) is intrnnsitive 
or ergative, then the verl) fornl nms|; 
l)e active, st) |;h~l; the sut)je(:t; rel~d;ion 
holds (rule Nhea(ltoVll.ev-A(:tSiml) (resp. 
NheadtoV\]l,ev-ActComp) for simt)le (resl). 
(:omt)h;x) verb fornls). '.l~:allSl'orm~tions 
such as uti l isation dc l'c.zp(;ric'nce *-+ 
czpd'ricncc 'utilisant ~r('~ filtered ()tiC;. 
The r(;iinenlenl; of the mel;m'ul(',s introduced 
four linguistic \]b&i;llr(*,s whi('h had to 1)e encode(t 
in the h',xi('on (see Table 2), nmn(',ty: 
? 1;11(', morl)hologi(:al nature of the noun: th(! 
noun is either non (h:verl)al or devert)~d. In 
the l~d;ter ease, it; may (:orrest)on(t () ;m 
agent deverbal, which reihrs to the agent 
of the verb, e.g. 'utili,sateur (user), or to ~ 
t)rocessive deverbM, whMt reibrs to the a(:- 
|ion (tenoted by the verb, e.g. uti l isat ion 
(.se). 
? the transitivity of the verb: intr;msitive 
mid ergative verbs are marked in the lexi- 
(;Oll. 
This mine|at|on task is not tinm-(:onsuming 
(al)otd; 3 hours for 1.,023 words) and could be 
parl;ly automated: characteristic endings (:ould 
hell) to detect processive mid agent deverb~fls. 
In addition, intrmlsitive mid ergative verbs form 
a sm~fll set of the vert)al lexicon (8% of the 
ver|)s) which is likely to 1)(', l)artly (lom~dn- 
indel)endent. 
5 Exper iments  and  Eva luat ions  
In this section, we ew~luate the variations pro- 
duced fl'om the two preceding sets of metarules: 
initial morpho-synt~mti(" wn'iations (henceforth 
MS) m~d new wn:i~tions enriched through light; 
semantics (henceforl;h MS+S). i 
The wtriald;s ",u:e ot)t~dne(1 Kern a 13.2 million- 
word (:orpus (:omposed of s(:ientiti(: al)stracl;s 
in the agricultural dora;fin (in French) ;rod a 
set of 11,452 terms. :~ The corlms is mlnlyzed 
through SYLEX, a shallow parser l;h~t buihts 
limited 1)hrase structures and associ~tes each 
word with mt unambiguous yntactic (:ategory 
and a, l(;mma. ~Ibrms are acquired from the out- 
|;ltl'es a,l:e sele,(:ted nn(t only terms that occur ~l: 
lea.st three times in the ('ortms m:e retained. 
The nunll)ers of variants exi;r&c|;ed through 
MS nnd MS+S ~u'e reporl;ed in ~l~fl)le el. 
They are re:ranged in su('h ;~ w~y (;hat ('or- 
responding wu'iations are aligned horizontnlly. 
For instance, each of the three MS+S vari- 
ations Nhea(lToV-Conq), NheadToV-SimI) or 
NheadtoV-l)rel ) is a refinenmnt of the MS vari~> 
|ion Nhea(lToV. In other words, the set of wtri- 
ants extracted by these three rich llle|;a, ru\]es is 
in('hl(led into the set of variants exl;ra~cl;ed l)y 
th(', 1)oor met;re'nit. These two sets are not eqmd 
since the rich metm:uh'~s are mnde more sele(:tive 
th;m the origimfl me(mule fl:om whi(:h they m:e 
derived. 
In addition to the oul;tm(; of ri(:h mid poor 
met~mfles, T;fl)le 4 shows, in |;he third col- 
umn, the mnnber of co-occurrences associated 
with these metarules. Co-occurrences m'e the 
least selective filters associated with morpho- 
syn|;~mti(: varimlts; they nre ext/ected to extract 
all the l)Ossible ('orrect nomino-verb:fl variations 
(recall value 1.0). Given a N1 Pu Na term, these 
co-occurrences corresl)ond to a configuration in 
which N1 co-occurs with a verb that is roof  
phologically related to Na or Na co-occurs with 
~r verb related to N~. Co-occurrences are ex- 
tra(:ted from a l l -word window (9 intervening 
words). These co-occurrences are used to eval- 
m~te the recall wflues of the tiltering metarules. 
awe arc grateflfl to Xavier Polanco, Jean Royautd and 
Lmncnt Schmitt (INIST-CNRS) for t)roviding us with 
this s(:icntitic orpus. 
267 
Table 2: Semantically Enriched Lexicon. 
Word Process ive  Deverba l  Agent  Deverba l  Int rans i t ive  Ergat ive 
abaisser - D - A - I - E 
abaissement +D -A  - I  -E  
absorber -D  -A  - I  -E  
absorbe'ar +D +A - I  -E  
accorder - D - A - I - E 
accord +D -A  - I  -E  
accumuler - D - A - I - E 
aceumulateur +D +A - I - E 
accumulation ? D - A - I - E 
accdl&'er -D  -A  - I  +E 
Table 3: Semantically Enriched Morpho-syntactic (MS+S) Variants of N1 P2 N:t Terms 
NheadToV-  Comp: avoir Av '~ 34 (N 1 ) V Av ? D A t N3 
{(N1 d,,ev) = proeessive A P2 =- d,e A (34(NI )v  tense)= pastpartieiple} 
comparaison de rdsultats (comparison of' results) 
--~ a compard les rdsultats (has compared results) 
NheadToV-Simp:  34(N1)v Av ? D A ? N3 
{(N1 dev) = proeess fve  A P2 = de A (34(N1)v tense) ? pastpar t ic ip le}  
dvaluation de risques (ewduntion of risks) --+ (~valv, er les risques (to ewfluate risks) 
NheadtoV-Prep:  34(Nl)v Av ? P2 D A ? N.~ 
{(Nt dev) = process ive} 
exposition d la lumi&'e (exposure to light) --+ ezposdes it la lumidre (exposed to light) 
NheadtoVRev-Pass :  N3 (A ? (P A ? N (A (C A)?)?) ': (C D ? Av ? A ? N A?) ? V ? dtre': Av ?) 2td(N1)v 
{(N3 agreement) = (3.d(N1)v agreement) A P2 = de A (N1 de',,) =-proces,sive A 
(34(N )v tense) = p ,,stp rtie,:ple A (M(N )v = 
r@artit ion de ch, ar.qe (weight distribution) --+ eh, arge @alement r@artie (equally distributed weight) 
NheadtoVRev-ActS imp:  Na(A?(PA?N(A(CA)? )? )? (CD'~Av?A?NA?)? )Ad(N1)v  
{P2 = de A = p,'o essi e A (34(N )v tense)?p stpo, rtie',:ple A 
(Jbl (N1)v valence) = (er.qativelintransitive) } 
chute de tempdrature (drop in temt, erature ) --+ tempdrature ch,'ute (temperature drops) 
NheadtoVRev-ActComp:  Na (n ? (P A t N (A (C A)?)':) ? (C D ? Av': A': N A':)': avoir ? Av ?) 3d(N1 )v 
{P2 = de A (N1 dev} = process ive  A {3d(N1)v tense) = pastpar t ic ip le  A 
{3d (N1)v valence) = (ergat ive l in t rans i t ive)  } 
fermentat ion  de jus (juice fermentatio,t) --+ jus de raisins fermentds (fermented grape juice) 
Prec is ion and Recal l  
In order to calculate the precision and recall of 
the rich and poor metarules and to estimate the 
gains of semantic enrichment, a set of 1,000 co- 
occurrences has been randomly chosen among 
the 159,898 co-occurrences retrieved by the sys- 
tem. They have been divided into three sets: 
S1 (500 co-occurrences) and S2 and S~ (250 co- 
occurrences). S~ has been evaluated indepen- 
dently by the two judges (i.e. the two authors) 
268 
Tabh; 4: Counts of varinnts of NI P2 Na terms 
MS MS+S Co-occurrences 
874 NheadToV-Coml) 
38,693 NheadToV 15,583 NheadToV-Silnp 
7,644 NheadtoV-Prep 
14,24:8 NheadtoVRev-Pass 69,056 NIN2toV1N2 
20,453 Nhead2bVI/.ev 197 Nhea(ltoVI{ev-ActSimp 
26 NheadtoVll.ev-Act Coral) 
6,803 NlnodifPoV1 2,749 NlnoctitWoV1-Ppr 42,882 NIN2toN2V1 
1,160 Nmodif\]}oV2-Infl }
2,588 Nmodif?oV2 0 NmoclitXbV2-Inf2 26,971 N1N2toNIV2 
1 NmodifYoV2-hff3 
~( 9,363 NmoditToVI/.ev 1,892 Nmo(tifPoVIl.ev-Prep 20,989 NIN2toV2N1 
77,900 44,374 159,898 
ill order to test the level of agrcelnent and $2 
and S. 5 have been ewfluated separately by only 
one judge each. Each cooccurreuce has been 
marked as t)ositive (~ correct variation), nega- 
tive (an incorrect variation) or inevaluable. In- 
ewfluable cases correspond either to tagging er- 
rors or to i?l(;orrect erms such ;ts (:oq'ttc de form(. 
(shell of shape) wlfich is an incoml)lete tca'm 
structure \])ec~utse it shouht t0e followed by an 
adjective such as coqu, c dcform, c oval(', (oval- 
shaped shell). Only the cases of ;tgreeul(u,t l)e- 
|;ween the two judges are used for the COml)uta- 
tion of rex:all and t)recision values. 
The achtition of semantics results in an in- 
(:,'ease of precision of 0.29: from 0.499 fbr MS 
to 0.789 for MS+S. The corresl)onding decrease 
of recall is nm(:h smaller: 0.11 from 0.696 for 
MS to 0.586 for MS+S. Pre(:ision and recall can 
t)e (:onfloine(t into a single me,mute such as the 
eifeetiveness measure E~ given by Fonmfla (1) 
in which t~ is a parameter (0 _< a < 1) (van 
Rijsbergen, 1975): 
Ea = 1 - (1) 
E~ varies fl:om 0 to 1.0. Low wflues of Ea cor- 
respond to combined high recall and high preci- 
I in order to assign an equal sion. If we use oe = 
trot)or|ante to precision and recall, the E1 val- 
ues are 0.419 fi)r MS and 0.327 for MS+S. They 
indicate that the addition of semantics has sig- 
nificantly improved the quality of w~riant ex- 
traction. Detailed values of recall and precision 
arc; showll ill Table 5. 
Agreement  on Judgment  
Agreement on ~ classification task can 1)e mea- 
sured through the kappa coefficient (K). It 
ewduato.s the pairwise agreement mnong a set; 
of coders making category .iudgment, correcting 
tbr expected chance agreement (Carletta, 1996). 
In our case the results of the ternary class|It- 
cation task are given by Table 6. The simple 
kappa cecil|(tent is 
Po-  P,! 
K : - -  (2 )  
I -P~.  
7232. in which P0 = E i~ and < = Ei( ,/ ~2~-) (Co- 
hen, 1960). P0 is the proportion of times the 
coders agree and I~, is the proportion of tiines 
we would expect them to agree by chance. The 
value of the kappa coetficient is 0.91 indicating 
a good reliability of the evaluation pertbrmed 
by the two independent .judges. 
6 Conc lus ion  
On a linguistic point of view, this experiment 
demonstrates that NLP applications can pro- 
vide new issues tbr the description of linguis- 
269 
Tab le  5: Precision and recall in variant extract ion for MS and MS+S variations 
PMS PMS+S RMS RMS+S 
0.438 NheadToV 
0.735 NheadToVRev 
0.111 Nmodi f roV1 
0.769 NmodifToV2 
0.448 Nmodi fToVRev 
{ 
{ 
0.875 
0.938 
0.565 
0.902 
1.000 
0.308 
1.000 
O.O00 
NheadToV-Comp 
NheadToV-Sim t)
NheadtoV-Prep 
NheadtoVRev-Pass 0.806 0.664 
NheadtoVRev-ActS imp 
NheadtoVRev-ActComp 
Nmodi fToVl -Pt ) r  0.674 0.578 
Nmodi iToV2-hf f l  } 
NmoditToV2-hff2 0.357 0.214 
NmoditToV2-Inf3 
NmoditToVI{ev-Prep 0.765 0.765 
0.499  0 .789  0 .696  0 .586  
Table 6: Frequencies of t)airwise judgments  for 
the ternary  classification of nomino-verbal w~ri- 
ations ( ,  = inevahmble, + = correct;, - = in- 
correct). 
ni j  * + - hi. 
. 120 9 1 130 
? 1 184 6 191 
- 4 10 165 179 
n.j 125 203 172 500 
tic phenomena.  The problem of linguistic vari- 
at ion in information processing forces the lin- 
guist to reconsider parat)hrase and trm~sf'orma- 
tion mechanisms in a new perspective, based 
on real l inguistic data  and on systematic ort)us 
exploration. The  paraphrase judgment  is eval- 
uated in a new way, from a practical point of 
view: two sequences are said to be a paraphrase 
of each other if the user of an information sys- 
tem considers that  they bring identical or sin> 
ilar informat ion content. Regarding linguistic 
methodology, this work led us to find "l ight" so- 
lutions in terms of lexical encoding to describe 
complex semantic t)henomena. This approach is 
pronfising because it demonstrates that  linguis- 
tic knowledge can really enhance the results of 
term recognit ion beyond the ,norphology level, 
and that  semantics can be taken into account 
to sonm extent. 
References  
A. T. Arampatzis, T. Tsoris, C. H. A. Koster, and 
Tit. P. van der V~reide. 1998. Phrase-based infof 
mation retrieval. Information Proccssin9 '~ Mana.qe- 
ment, 34(6):693 707. 
Inge Bartning. 1990. Los syntagmes l)inoininaux en de - 
les types interprdtatifs subjectifs et agentifs. In Pro- 
cecdings, dixidmc congr~s des romanistcs .scandinavcs. 
Regina Barzilay, Kathleen McKeown, and Michael E1- 
hadad. 1999. hff'ormational fusion in the context 
of multi-document summarization. In Prvccedings of 
ACL'99, pages 55() 557, University of Mawland. 
Jean Carletta. 1996. Asessing agreement on classifica- 
tion tasks: The kappa statistics. Computational Lin- 
guistics, 22(2):249 254. 
J. Cohen. 1960. A coefficient of agreement for nominal 
scales. Educational and P.sychological Measurement, 
20(1):37-46. 
Cdcile Fabre. 1996. Intcrprdtation automatiquc des 
sdquences binominales en fran~:ais et en an.qlais. 
Ph.D. thesis, Universit5 Returns I. 
Christiml Jacquemin and Evelyne Tzoukermmm. 1999. 
NLP ibr term variant extraction: A synergy of mor- 
phology, lexicon, and syntax. In Tomek Strzalkowski, 
editor, Natural Language Information Retrieval, pages 
25-74. Kluwer, Boston, MA. 
Judith Klavans and Min-Yen Kan. 1998. Role of verbs 
in document analysis. In Proceedings of COLING- 
ACL'98, pages 680-686, Universitd e Montrdal, Mort- 
treal, Canada. 
Maria Lapata. 1999. Acquiring lexical generalizations 
from corpora: A case study ibr diathesis alternations. 
In Proceedings of ACL'99, pages 397-404, University 
of Maryland. 
C. J. van Rijsbergen. 1975. In\]ormation Retrieval. But- 
terworth, London. 
270 
Combining Lexical and Formatting Cues for Named Entity 
Acquisition from the Web 
Chr i s t ian  Jacquera in  1 and Caro l ine  Bush  1'2 
1CNRS-LIMSI, BP 133, F-91403 ORSAY Cedex, FRANCE 
2UMIST, Dept of Language Engineering, PO Box 88, Manchester M60 1QD, UK 
{j acquemin, caroline}@lims?, fr 
Abst ract  
Because of their constant renewal, it is nec- 
essary to acquire fresh named entities (NEs) 
from recent ext sources. We present a tool 
for the acquisition and the typing of NEs from 
the Web that associates a harvester and three 
parallel shallow parsers dedicated to specific 
structures (lists, enumerations, and anchors). 
The parsers combine lexical indices such as 
discourse markers with formatting instruc- 
tions (HTML tags) for analyzing enumera- 
tions and associated initializers. 
1 Overv iew 
Lexical acquisition from large corpora has 
long been considered as a means for enrich- 
ing vocabularies (Boguraev and Pustejovsky, 
1996). Depending on the studies, different is- 
sues are considered: the acquisition of terms 
(Daille, 1996), the acquisition of subcatego- 
rization frames (Basili et al, 1993), the acqui- 
sition of semantic links (Grefenstette, 1994), 
etc. While traditional electronic orpora such 
as journal articles or corpus resources (BNC, 
SUSANNE, Brown corpus) are satisfactory for 
classical lexical acquisition, Web corpora are 
another source of knowledge (Crimmins et al, 
1999) that can be used to acquire NEs because 
of the constant updating of online data. 
The purpose of our work is to propose a 
technique for the extraction of NEs from the 
Web through the combination of a harvester 
and shallow parsers. Our study also belongs 
to corpus-based acquisition of semantic re- 
lationships through the analysis of specific 
lexico-syntactic contexts (Hearst, 1998) be- 
cause hypernym relationships are acquired to- 
gether with NEs. The unique contribution 
of our technique is to offer an integrated ap- 
proach to the analysis of HTML documents 
that associates lexical cues with formatting 
instructions in a single and cohesive frame- 
work. The combination of structural informa- 
tion and linguistic patterns is also found in 
wrapper induction, an emerging topic of re- 
search in artificial intelligence and machine 
learning (Kushmerick et al, 1997). 
Our work differs from the MUC-related NE 
tagging task and its possible extension to 
name indexing of web pages (Aone et al, 
1997) for the following reasons: 
? The purpose of our task is to build lists of 
NEs, not to tag corpora. For this reason, 
we only collect non-ambiguous context- 
independent NEs; partial or incomplete 
occurrences such as anaphora re consid- 
ered as incorrect. 
? The types of NEs collected here are much 
more accurate than the four basic types 
defined in MUC. The proposed tech- 
nique could be extended to the collec- 
tion of any non-MUC names which can 
be grouped under a common hypernym: 
botanic names, mechanical parts, book 
titles, events... 
? We emphasize the role of document s ruc- 
ture in web-based collection. 
2 Focus ing  on Def in i to ry  Contexts  
Two issues are addressed in this paper: 
1. While traditional electronic orpora can 
be accessed irectly and entirely through 
large-scale filters such as shallow parsers, 
access to Web pages is restricted to 
the narrow and specialized medium of a 
search engine. In order to spot and re- 
trieve relevant ext chunks, we must fo- 
cus on linguistic ues that can be used to 
access pages containing typed NEs with 
high precision. 
2. While Web pages are full of NEs, only a 
small proportion of them are relevant for 
the acquisition of public, fresh and well- 
known NEs (the name of someone's cat 
181 
is not relevant o our purpose). So that 
automatically acquired NEs can be used 
in a NE recognition task, they are asso- 
ciated with types such as actor (PER- 
SON), lake (LOCATION), or university 
(ORGANIZATION). 
The need for selective linguistic ues (wrt to 
the current facilities offered by search engines) 
and for informative and typifying contexts has 
led us to focus on collections, a specific type of 
definitory contexts (Pdry-Woodley, 1998). Be- 
cause they contain specific linguistic triggers 
such as following or such as, definitory con- 
texts can be accessed through phrase queries 
to a search engine. In addition, these contexts 
use the classical scheme genus/differentia to 
define NEs, and thus provide, through the 
genus, a hypernym of the NEs they define. 
Our study extends (Hearst, 1998) to Web- 
based and spatially formatted corpora. 
3 Arch i tec ture  and  Pr inc ip les  
To acquire NEs from the Web, we have devel- 
oped a system that consists of three sequential 
modules (see Figure 1): 
1. A harvester that downloads the pages re- 
trieved by a search engine from the four 
following query strings 
(1.a) following (NE) (1.c) (NE) such as 
(1.b) list of (NE) (1.d) such (NE) as 
in which (NE) stands for a typifying 
hypernym of NEs such as Universities, 
politicians, or car makers (see list in 4). 
. Three parallel shallow parsers Pc, P1 and 
Pa which extract candidate NEs respec- 
tively from enumerations, lists and ta- 
bles, and anchors. 
. A post-filtering module that cleans up the 
candidate NEs from leading determiners 
or trailing unrelated words and splits co- 
ordinated NEs into unitary items. 
Corpus Harvesting 
The four strings (1.a-d) given above are used 
to query a search engine. They consist of an 
hypernym and a discourse marker. They are 
expected to be followed by a collection of NEs. 
Figure 2 shows five prototypical examples 
of collections encountered in HTML pages re- 
Queries WWW 
I 
1  arch Eogioe I
H'I'ML corpus 
. . . . .  \[ - ~ ;  - ~ L . z ~ " ~ < z - 1 2 .  - ~ i  - - -~2r ; J2  
' 1 1  " I I -  
! 
Enumeration ~ List and tables II Anchor I 
. . . . . . .  . . . . . . . . . . . .  t t  . . . . . . . .  . . . . . . . . . .  
Candidate NEs Initializers and Candtdate 
ate~ Index pages 
I Filter I 
Typed NEs 
Figure 1: Architecture 
trieved through one of the strings (1.a-d)3 
The first collection is an enumerat ion  and 
consists of a coordination of three NEs. The 
second collection is a list organized into two 
sublists. Each sublist is introduced by a hy- 
pernym. The third structure is a list marked 
by bullets. Such lists can be constructed 
through an HTML table (this example), or 
by using enumeration marks (<ul> or <ol>). 
The fourth example is also a list built by us- 
ing a table structure but displays a more com- 
plex spatial organization and does not em- 
ploy graphical bullets. The fifth example is 
an anchor  to a collection ot provided to the 
reader within the document, but which can be 
reached by following an hyperlink instead. 
The corpus of HTML pages is collected 
through two search engines with different ca- 
pabilities: AltaVista (AV) and Northern Light 
(NL).2 AV offers the facility of double-quoting 
the query strings in order to search for exact 
strings (also called phrases in IR). NL does 
not support phrase search. However, in AV, 
the number of retrievable documents i  limited 
to the 200 highest ranked documents while it 
is potentially unlimited in NL. For NL, the 
1 (NE) is international organzzations, here. The ty- 
pographical mark-up of the query string in the figure 
is ours. The hypernym is in bold italics and the dis- 
course marker is in bold. 
2The harvester that retrieves Web pages through a 
search engine is a combination of wget available from 
ftp://sunsite, auc. dk/pub/infosystems/wget/ and 
Perl scripts. 
182 
It's development is due to the support gwen by the Ministry of Pubhc Health, aided by 
international organizations uch as the Pan American Health Organization (PAHO), the 
United Nations Development program, and the Caribbean and Latin American Medical Science 
Information Center. 
7. The session was also attended by observers from the following international organizations: 
(a) United Nations organs 
International Bank for Reconstruction a d Development (World Bank) 
(b) lntergovernmental organizations 
Asian-African Legal Consultative Committee (AALCC) 
Inter-American Development Bank 
Internauonal Institute for the Umficauon of Private Law (UNIDROIT) 
International Organizations 
The following international organizations are collaborating on the Project: 
lp International Commission on Non-Ionizing Radiation Protection (ICNIRP) 
1~ International Agency for Research on Cancer (IARC) 
United Nations Environment Programme (UNEP) 
Below is the list of international organizations that we distribute: 
EU (European Union) 
Books, documentation, periodicals on European legislation, 
economy, agriculture, industry, educatmn, norms, ocial 
pohtics, law. For more information publicauons, COM 
documents and to subscribe tothe Officml Journal please 
contact Dunya Infotel. 
UN (United Nations) 
Peace and security, economics, statistics, energy, natural 
resources, nvironment, i ernational law, human rights, 
polmcal ffairs and disarmament, social questions. 1997 
periodicals include: Development Business, East-West 
Investment News, Transnattonal Corporations, Monthly 
Bulletin of Stat~stms, etc. 
An agency may detail or transfer an employee to any orgamzaUon which the Office of 
Personnel Management has designated asan international organization (see list of international 
organizations). 
Figure 2: Five different ypes of formatting used for enumerating NEs. 
number of retrieved ocuments was however 
restricted to 2000 in order to limit process- 
ing times. The choice of these two search en- 
gines is intended to evaluate whether a poorer 
query mode (bags of words in NL instead of 
strings in AV) can be palliated by accessing 
more documents (2000 max. for NL instead 
of 200 max. for AV). 
The corpus collected by the two search 
engines and the four f~.milies of queries is 
2,958Mb large (details are given in Section 4). 
Acquis i t ion of  Candidate  NEs  
Three parallel shallow parsers Pc, P\]. and Pa 
are used to extract NEs from the corpora col- 
lected by the harvester. The parsers rely on 
the query string to detect he sentence intro- 
ducing the collection of NEs (the initializer in 
(P~ry-Woodley, 1998)). The text and HTML 
marks after the initializer are parsed jointly 
in order to retrieve one of the following three 
spatio-syntactic structures: 
1. a textual enumeration (parser Pc, top- 
183 
most example in Figure 2), 
2. a list or a table (parser Pl, the next three 
examples in Figure 2), 
3. an anchor toward a page containing a list 
(parser Pa, bottom example in Figure 2). 
In brief, these parsers combine string 
matching (the initial lexical cue), syntactic 
analysis (enumerations in Pe), analysis of for- 
matting instructions (lists and tables in Pl), 
and access to linked documents through an- 
chors detected by Pa. The results presented in
this paper only concern the first two parsers. 
Since anchors raise specific problems in lin- 
guistic analysis (Amitay, 1999), they will be 
analyzed in another pubhcation. The result- 
ing candidate NEs are cleaned up and filtered 
by a post-filtering module that splits associa- 
tions of NEs, suppresses initial determiners or
trailing modifiers and punctuations, and re- 
jects incorrect NEs. 
The  Enumerat ion  Parser  Pe 
The enumerations are expected to occur in- 
side the sentences containing the query string. 
Pe uses a traditional approach to parsing 
through conjunction splitting in which a NE 
pattern NE is given by (3) and an enumera- 
tion by (4). 3 
NE = (\[A-Z \ &\]\[a-zA-Z \-\'\]* )+ (3) 
Enum = (NE, )*WE(, ?) (andlor) WE (4) 
The List Parser  P1 
The lists are expected to occur no further than 
four lines after the sentence containing the 
query string. The lists are extracted through 
one of the following three patterns. They cor- 
respond to three alternatives commonly used 
by HTML authors in order to build a spa- 
tial construction of aligned items (lists, line 
breaks, or tables). They are expressed by 
case-insensitive r gular expressions in which 
the selected string is the shortest  acceptable 
underlined pattern: 
<li> ? (</ti> I<ti> I</ot> I</~t>?5) 
<~> ? </~> (6) 
(<td> I<th>) ._" (<td> \[<th> I</td> (7) 
I</th> I</table> ) 
3The patterns are slightly more complicated in or- 
der to accept diacriticized letters, and possible abbre- 
viations composed of a single letter followed by a dot. 
In addition, after the removal of the HTML 
mark-up tags, only the longest subpart of the 
string accepted by (3) is produced as output 
to the final filter. These patterns do not cover 
all the situations in which a formatted text de- 
notes a list. Some specific ases of lists such as 
pre-formatted text in a verbatim environment 
(<we>), or items marked by a paragraph tag 
(<p>) are not considered here. They would 
produce too inaccurate results because they 
are not typical enough of lists. 
Postf i l ter lng 
The pre-candidate NEs produced by the shal- 
low parsers are processed by filters before be- 
ing proposed as candidate NEs. The roles of 
the filters are (in this order): 
? removal of trailing lower-case words, 
? deletion of the determiner the and the co- 
ordinating conjunctions and and or and 
the words which follow them, 
? rejection of pre-candidates that contain 
the characters @, {, # , ", $, ! or ?. 
? suppression of item marks such as 1., - - ,  
? or a), 
? suppression of HTML markups, 
? suppression of leading coordinating con- 
junctions, 
? suppression of appositive sequences after 
a comma or a hyphen, 
? transformation f upper-case words into 
initial upper-case in non-organization 
candidate NEs because only organization 
names are expected to contain acronyms, 
? rejection of NEs containing words in a 
stop list such as Next, Top, Web, or Click. 
Postfiltering is completed by discarding 
single-word candidates, that are described as 
common words in the CELEX 4 database, and 
multi-word candidates that contain more than 
5 words. 
4 Exper iments  and  Eva luat ions  
Data  Co l lec t ion  
The acquisition of NEs is performed on 34 
types of NEs chosen arbitrarily among three 
subtypes of the MUC typology: 
4The CELEX database for the English language is 
available from the Consortium for Lexical Resources at
~.  Idc. upenn, edu/readme_files/celex, readme, html. 
184 
ORGANIZATION (American companies, 
international organizations, universities, po- 
litical organizations, international agencies, 
car makers, terrorist groups, financial insti- 
tutions, museums, international companies, 
holdings, sects, and realtors), 
PERSON (politicians, VIPs, actors, man- 
agers, celebrities, actresses, athletes, authors, 
film directors, top models, musicians, singers, 
and journalists), and 
LOCATION (countries, regions, states, 
lakes, cities, rivers, mountains, and islands). 
Each of these 34 types (a (NE) string) 
is combined with the four discourse mark- 
ers given in (1.a-d), yielding 136 queries for 
the two search engines. Each of the 272 cor- 
pora collected through the harvester is made 
of the 200 documents downloadable through 
AV for the phrase search (or less if less are 
retrieved) and 2,000 documents though NL. 
Each of these corpora is parsed by the enu- 
meration and the list parsers. 
Two aspects of the data are evaluated. 
First, the size of the yield is measured in order 
to compare the productivity of the 272 queries 
according to the type of query (type of NE 
and type of discourse marker) and the type 
.of search engine (rich versus plain queries and 
low versus high number of downloaded ocu- 
ments). Second, the quality of the candidate 
NEs is measured through uman inspection of 
accessible Web pages containing each NE. 
Corpus Size 
The 272 corpora are 2,958 Mb large: 368 
Mb for the corpora collected through AV and 
2,590 Mb for those obtained through NL. De- 
tailed sizes of corpora are shown in Table 1. 
The corpora collected through NL for the pat- 
tern list o/ (NE / represent more than a half 
of the NL collection (1,307 Mb). The most 
productive pattern for AV is (NE) such as 
through which 41% of the AV collection is 
downloaded (150 Mb). 
The sizes of the corpora also depends on 
the type of NEs. For each search engine, the 
total sizes are reported for each pattern (1.a- 
d). In addition, the largest corpus for each 
of the three types of NEs is indicated in the 
last three lines. The variety of sizes and dis- 
tribution among the types of NEs shows that 
using search engines with different capabili- 
ties yields different figures for the collections 
of pages. Therefore, the subsequent process of 
NE acquisition heavily depends on the means 
used to collect the basic textual data from 
which knowledge is acquired. 
Quantitative Evaluation of Acquisition 
Table 2 presents, for each pattern and each 
search engine, the number of candidates, the 
productivity, the ratios of the number of enu- 
merations to lists, and the rate of redundancy. 
In all, 17,176 candidates are produced 
through AV and 34,978 through NL. The low- 
est accuracy of the NL query mode is well pal- 
liated by a larger collection of pages. 
P roduct iv i ty .  The productivity is the ra- 
tio of the number of candidates to the size 
of the collection. Using a unit of number of 
candidates per Mb, the productivity of AV is 
46.7 while it is 3.5 times lower for NL (13.5). 
Thus, collecting NEs from a coarser search en- 
gine, such as NL, requires downloading 3.5 
times larger corpora for the same yield. A 
finer search engine with phrase query facili- 
ties, such as AV, is more economical with re- 
spect to knowledge acquisition based on dis- 
course markers. 
As was the case for the size of the col- 
lection, the productivity of the corpora also 
depends on the types of NEs. Universi- 
ties (28.1), celebrities (53.0) and countries 
(36.5) are the most productive NEs in their 
categories while international agencies (4.0), 
film directors (4.4) and states (8.7) are the 
less productive ones. These discrepancies 
certainly depend on the number of existing 
names in these categories. For instance, there 
are many more names of celebrities than .film 
directors. In fact, the productivity of NL is 
significantly lower than the productivity of AV 
only for the pattern list of NE. Since this pat- 
tern corresponds to the largest corpus (see Ta- 
ble 1), its poor performance in acquisition has 
a strong impact on the overall productivity 
of NL. Avoiding this pattern would make NL 
more suitable for acquisition with a produc- 
tivity of 23.2 (only 2 times lower than AV). 
Rat ios  enumerat ions / l i s t s .  The ratios 
in the third lines of the tables correspond to 
the quotient of the number of candidates ac- 
quired by analyzing enumerations (Pe parser) 
to the number of candidates obtained from 
the analysis of lists (P1 parser). Following 
NE mainly yields NEs through the analysis 
of lists, probably because numerations u ing 
coordinations are better introduced by such 
as. The outcome is more balanced for list 
of NE. It could be expected that this pat- 
185 
Table h Size of the corpora of HTML pages (in Mb) collected on the four patterns (1.a-d) 
through AltaVista (AV) and Northern Light (NL). 
AV engine following NE (AV) list of NE (AV) NE such as (AV) such NE as (AV) 
Largest corpus 6.1 6.4 11.3 5.8 
ORGANIZATIONS int. organizations universities int. organizations int. organizations 
Largest corpus 5.8 4.3 7.3 2.8 
PERSON managers journalists pohticians musicians 
Largest corpus 6.8 4.9 13.6 7.3 
LOCATION countries countries states states 
Total size 85.9 64.9 150.4 66.3 
NL engine following NE (NL) list of NE (NL) NE such as (NL) such NE as (NL) 
Largest corpus 10.0 75.1 58.5 19.5 
ORGANIZATIONS museums int. agencies holdings universities 
Largest corpus 10.2 60.0 44.1 48.6 
PERSON actors pohticians actors authors 
Largest corpus 23.0 61.2 34.4 118.3 
LOCATION rivers islands rivers states 
Total size 172.8 1,306.9 652.7 458.1 
Table 2: Size of the number of candidate NEs acquired from the web-based corpora described 
in Table 1. 
AV engine bZlowing NE (AV) list of NE (AV) NE such as (AV) such NE as (AV) 
# candidates 4,747 3,112 5,738 3,579 
Productivity 55.2 48.0 38.2 53.9 
Ratio enum./list 0.28 0.83 12.5 43.74 
Redundancy 2.12 2.15 1.77 1.69 
NL engine following NE (NL) list of NE (NL) NE such as (NL) such NE as (NL) 
# candidates 5,667 5,176 14,800 9,335 
Productivity 32.8 4.0 22.7 20.4 
Ratio enura./list 0.31 0.49 10.41 14.72 
Redundancy 2.12 2.34 2.13 2.20 
AV & NL following NE list of NE NE such as such NE as Total 
# candidates 8,673 7,380 18,005 10,566 44,624 
Overlap 16.7% 11.0% 12.3% 18.2% 15 .0~ 
186 
tern tends to introduce only lists, but there 
are only 1.66 times more NEs obtained from 
lists than from enumerations through list off 
NE. The large number of NEs produced from 
enumerations after this pattern certainly re- 
lies on the combination of linguistics and for- 
matting cues in the construction of meaning. 
The writer avoids using (the word) list when 
the text is followed by a (physical) list. Lastly, 
in all, 11 times more NEs are obtained from 
enumerations than from lists after the pattern 
NE such as, and 18 times more after such NE 
as. This shows that the linguistic pattern such 
as preferably introduces textual enumerations 
through coordinations (Hearst, 1998). 
Redundancy .  There are two main causes 
of redundancy in acquisition. A first cause is 
that the same NE can be acquired from sev- 
eral collections in the same corpus. Redun- 
dancy in the fourth lines of the tables is the 
ratio of duplicates among the yield of can- 
didate NEs for each search engine and each 
query. This value is relatively stable what- 
ever the search engine or the query pattern. 
On average, redundancy is 2.09: each candi- 
date is acquired slightly more than two times. 
Acquisition through NL is slightly more re- 
.~:dundant (2.18) than through AV (1.92). This 
difference is not significant since the number 
of NEs acquired through NL is twice as large 
as the number of NEs acquired through AV. 
Over lap.  Another cause of multiple acqui- 
sition is due to the concurrent exploitation of 
two search engines. If these engines were using 
similar techniques to retrieve documents, the 
overlap would be large. Since we have chosen 
two radically different modes of query (phrase 
vs. bag-of-word technique), the overlap---the 
ratio of the number common candidates to 
the number of total candidates--is low (15%). 
The two search engines seem to be comple- 
mentary rather than competitive because they 
retrieve different sets of documents. 
P rec i s ion  of Acqu is i t ion  
In all, 31,759 candidates are produced by 
postfiltering the acquisition from the corpora 
retrieved by the two search engines. A set of 
504 candidates i randomly chosen for the pur- 
pose of evaluation. For each candidate, AV is 
queried with a phrase containing the string of 
the NE. The topmost 20 pages retrieved by 
AV are downloaded and then used for manual 
inspection in case of doubt about the actual 
status of the candidate. We assume that if 
a candidate is correct, an unambiguous refer- 
ence with the expected type should be found 
at least in one of the topmost 20 pages. 
Two levels of precision are measured: 
1. A NE is correct if its full name is re- 
trieved and if its fine-grained type (the 34 
types given at the beginning of this sec- 
tion) is correct. The manual inspection 
of the 504 candidates indicates a preci- 
sion of 62.8%. 
2. A NE is correct if its full name is retrieved 
and if its MUC type (ORGANIZATION, 
PERSON, or LOCATION) is correct. In 
this case, the precision is 73.6%. 
The errors can be classified into the follow- 
ing categories: 
Wrong type  Many errors in NE typing are 
due to an incorrect connection between a
query pattern and a collection in a doc- 
ument. For instance, Ashley Judd is in- 
correctly reported as an athlete (she is an 
actress) from the occurrence 
His clientele includes stars and 
athletes uch as Ashley Judd 
(below) and Mats Sundin. 
The error is due to a partial analysis of 
the initializer (underlined above). Only 
athletes is seen as the hypernym while 
stars is also part of it. A correct anal- 
ysis of the occurrence would have led to 
a type ambiguity. In this context, there is 
no clue for deciding whether Ashley Judd 
is a star or an athlete. 
Other wrong types are due to poly- 
semy. For instance, HorseFlySwarm is 
extracted from a list of actors in a page 
describing the commands and procedures 
for programming a video game. Here ac- 
tors has the meaning of a virtual actor, 
a procedure in a programming environ- 
ment, and not a movie star. 
Incomplete  Partial extraction of candidates 
is mainly due to parsing errors or to col- 
lections containing partial names of enti- 
ties. 
As an illustration of the second case, the 
author's name Goffman is drawn from 
the occurrence 
Readings are drawnf rom the 
work o\] such authors as Laing, 
187 
Szasz, Goffman, Sartre, Bate- 
son, and Freud. 
Since this enumeration ,does not contain 
the first names of the authors, it is not 
appropriate for an acquisition of unam- 
biguous author's names. 
Other names such as Lucero are ambigu- 
ous even though they are completely ex- 
tracted because they correspond to a first 
name or to a name that is part of sev- 
eral other ones. They are also counted 
as errors since they will be responsible of 
spurious identifications in a name tagging 
task. 
Over -complete  Excessive extractions are 
due to parsing errors or to collections that 
contain words accompanying names that 
are incorrectly collected together with 
the name. For instance, Director Lewis 
Burke FFrumkes is extracted as an au- 
thor's name from a list in which the ac- 
tual name Lewis Burke Frumkes is pre- 
ceded by the title Director. 
Misce l laneous  Other types of errors do not 
show clear connection between the ex- 
tracted sequence and a NE. They are 
mainly due to errors in the analysis of 
the web page. 
These types of errors are distributed as fol- 
lows: wrong type 25%, incomplete 24%, over- 
complete 8% and miscellaneous 43%. 
5 Ref inement  o f  the  Types  o f  NEs  
So far, the type of the candidate NEs is pro- 
vided by the NE hypernym given in (1.a-d). 
However, the initializer preceding the collec- 
tion of NEs to be extracted can contain more 
information on the type of the following NEs. 
In fact the initializer fulfills four distinct func- 
tions: 
1. introduces the presence and the proxim- 
ity of the collection, e.g. Here is 
2. describes the structure of the collection, 
e.g. a list of 
3. gives the type of each item of the collec- 
tion, e.g. universities 
4. specifies the particular characteristics of 
each item. e.g. universities in Vietnam 
The cues used by the harvester are elements 
which either introduce the collection (e.g. the 
.following) or describe the structure (e.g. a 
list of). In initializers in general, these first 
2 functions need not be expressed explicitly 
by lexical means, as the layout itself indi- 
cates the presence and type of the collection. 
Readers exploit the visual properties of writ- 
ten text to aid the construction of meaning 
(P6ry-Woodley, 1998). 
However it is necessary to be explicit when 
defining the items of the collection as this 
information is not available to the reader 
via structural properties. Initializers gener- 
ally contain additional characteristics of the 
items which provide the differentia (under- 
lined here): 
This is a list off American companies 
with business interests in Latvia. 
This example is the most explicit form an ini- 
tializer can take as it contains a lexical ele- 
ment which corresponds to each of the four 
functions outlined above. It is fairly simple to 
extract the details of the items from initializ- 
ers with this basic form, as the modification 
of the hypernym takes the form of a relative 
clause, a prepositional phrase or an adjectival 
phrase. A detailed grammar of this form of 
initializer is as shown in Figure 3. 5 
Initializer 
The following is NP 
(det) (adj) Ns PP 
P NP 
\] (adj) l~/pl (PP \ [~. )  
list of universities in Indonesia: 
Figure 3: The structure of a basic initializer 
We tag the collection by part of speech us- 
ing the TreeTagger (Schmid, 1999). The el- 
ements which express the differentia are ex- 
tracted by means of pattern matching: they 
are always the modifiers of the plural noun in 
the string, which is the hypernym of the items 
of the collection. 
5pp = prepositional phrase, Ns = noun (singular), 
Npl = noun (plural), Vp = verb in present tense, rel.cl. 
= relative clause. 
188 
Initializers containing the search string such 
as behave somewhat differently. They are 
syntactically incomplete, and the missing con- 
stituent is provided by each item of the col- 
lection (Virbel, 1985). These phrases vary 
considerably in structure and can require rela- 
tively complex syntactic rearrangement to ex- 
tract the properties of the hypernym. We will 
not discuss these in more detail here. 
One type of error in this system occurs 
when a paragraph containing the search string 
is followed by an unrelated list. For example 
the harvester recognizes 
Ask the long list of American com- 
panies who have unsuccessfully mar- 
keted products in Japan. 
as an initializer when in fact it is not related to 
any collection. If it happened to be followed 
on the page by an collection of any kind the 
system would mistakenly collect the items as 
NEs of the type specified by the search string. 
The cue list of is commonly used in dis- 
cursive texts, so some filtering is required to 
identify collections which are not employed as 
initializers and to reduce the collection of er- 
roneous items. Analyzing the syntactic forms 
h:has allowed us to construct a set of regular 
expressions which are used to eliminate non- 
initializers and disregard any items collected 
following them. 
We have extracted 1813 potential initial- 
izers from the corpus of HTML pages col- 
lected via AV & NL for the query string list 
of NE. Using lexico-syntactic patterns in or- 
der to identify correct initializers, we have de- 
signed a shallow parser for filtering and ana- 
lyzing the strings. This parser consists of 14 
modules, 4 of which carry out pre-filtering to 
prepare and tag the corpus, and 10 of which 
carry out a fine-grained syntactic analysis, re- 
moving collections that do not function as ini- 
tializers. After filtering, the corpus contains 
520 collections. The process has a precision 
of 78% and a recall of 90%. 
6 Conc lus ion  
This study is another application that demon- 
strates the usability of the WWW as a re- 
source for NLP (see, for instance, (Grefen- 
stette, 1999) for an application of using 
WWW frequencies in selecting translations). 
It also confirms the interest of non-textual lin- 
guistic features, such as formatting markups, 
inNLP for structured ocuments such as Web 
pages. Further work on Web-based NE acqui- 
sition could take advantage of machine learn- 
ing techniques as used for wrapper induction 
(Kushmerick et al, 1997). 
Re ferences  
E. Amitay. 1999. Anchors in context: A corpus 
analysis of web pages authoring conventions. In 
L. Pemberton and S. Shurville, editors, Words 
on the Web - Computer Mediated Communica- 
tion, page 192. Intellect Books, UK. 
C. Aone, N. Charocopos, and J. Gorlinski. 
1997. An intelligent multilingual information 
browsing and retrieval system using Informa- 
tion Extraction. In Proceedings, Fifth Confer- 
ence on Applied Natural Language Processing 
(ANLP'97), pages 332-39, Washington, DC. 
R. Basili, M.T. Pazienza, and P. Velardi. 1993. 
Acquisition of selectional patterns in sublan- 
guages. Machine Translation, 8:175-201. 
B. Boguraev and J. Pustejovsky, editors. 1996. 
Corpus Processing for Lexical Acquisition. MIT 
Press, Cambridge, MA. 
F. Crimmins, A.F. Smeaton, T. Dkaki, and 
J Mothe. 1999. T@trafusion: Information dis- 
covery on the internet. IEEE Intelligent Sys- 
tems and Their Applications, 14(4):55-62. 
B. Daille. 1996. Study and implementation of 
combined techniques for automatic extraction 
of terminology. In J.L. Klavans and P. Resnik, 
editors, The Balancing Act, pages 49-66. MIT 
Press, Cambridge, MA. 
G. Grefenstette. 1994. Explorations in Automatic 
Thesaurus Discovery. Kluwer Academic Pub- 
lisher, Boston, MA. 
G. Grefenstette. 1999. The WWW as a resource 
for example-based MT tasks. In Proc., ASLIB 
Translating and the Computer 21 Conference, 
London. 
M.A. Hearst. 1998. Automated discovery of 
WordNet relations. In C. Fellbaum, editor, 
WordNet: An Electronic Lexical Database. MIT 
Press, Cambridge, MA. 
N. Kushmerick, D.S. Weld, and R. Doorenbos. 
1997. Wrapper induction for information ex- 
traction. In Proc., IJCAI'97, pages 729-735, 
Nagoya. 
M.-P. P@ry-Woodley. 1998. Signalling in written 
text: a corpus based approach. In Workshop on 
Discourse Relations and Discourse Markers at . 
COLING-ALC'98, pages 79-85. 
H. Schmid. 1999. Improvements in part-of- 
speech tagging with an application to german. 
In S. Armstrong, K.W. Church, P. Isabelle, 
S. Manzi, E. Tzoukermann, and D. Yarowski, 
editors, Natural Language Processing Using 
Very Large Corpora. Kluwer, Dordrecht. 
J. Virbel. 1985. Mise en forme des documents. 
Cahiers de Grammaire, 17. - -  
189 
Terminological variants for document selection and
question/answer matching
Olivier Ferret Brigitte Grau Martine Hurault-Plantet
Gabriel Illouz Christian Jacquemin
LIMSI-CNRS
Bat.508 Universit? ParisXI
91403 Orsay, France
{ferret, grau, mhp, gabrieli, jacquemin}@limsi.fr
Abstract
Answering precise questions requires
applying Natural Language techniques
in order to locate the answers inside
retrieved documents. The QALC
system, presented in this paper,
participated to the Question Answering
track of the TREC8 and TREC9
evaluations. QALC exploits an analysis
of documents based on the search for
multi-word terms and their variations.
These indexes are used to select a
minimal number of documents to be
processed and to give indices when
comparing question and sentence
representations. This comparison also
takes advantage of a question analysis
module and recognition of numeric and
named entities in the documents.
1 Introduction
The Question Answering (QA) track at TREC8
and TREC9 is due to the recent need for more
sophisticated paradigms in Information
Retrieval (IR). Question answering generally
refers to encyclopedic or factual questions that
require concise answers. But current IR
techniques do not yet enable a system to give
precise answers to precise questions. Question
answering is thus an area of IR that calls for
Natural Language Processing (NLP) techniques
that can provide rich linguistic features as
output. Such NLP modules should be deeply
integrated in search and matching components
so that answer selection can be performed on
such linguistic features and take advantage of
them. In addition, IR and NLP techniques have
to collaborate in the resulting system in order to
cope with large-scale and broad coverage text
databases while deriving benefit from added
knowledge.
We developed a system for question
answering, QALC, evaluated in the framework
of the QA tracks at TREC8 and TREC9. The
QALC system comprises NLP modules for
multi-word term and named entity extraction
with a specific concern for term conflation
through variant recognition. Since named entity
recognition has already been described
extensively in other publications (Baluja 1999),
we present the contribution of terminological
variants to adding knowledge to our system.
The two main activities involving
terminology in NLP are term acquisition and
term recognition. Basically, terms can be viewed
as a particular type of lexical data. Term
variation may involve structural, morphological,
and semantic transformations of single or multi-
words terms (Fabre and Jacquemin, 2000).
In this paper, we describe how QALC uses
high level indexes, made of terms and variants,
to select among documents the most relevant
ones with regard to a question, and then to
match candidate answers with this question. In
the selection process, the documents first
retrieved by a search engine, are then
postfiltered and ranked through a weighting
scheme based on high level indexes, in order to
retain the top ranked ones. Similarly, all systems
that participated in TREC9 have a search engine
component that firstly selects a subset of the
provided database of about one million
documents. Since a search engine produces a
ranked list of relevant documents, systems then
have to define the highest number of documents
to retain. Indeed, having too many documents
leads to a question processing time that is too
long, but conversely, having too few documents
reduces the possibility of obtaining the correct
answer. For reducing the amount of text to
process, one approach consists of keeping one or
more relevant text paragraphs from each
document retrieved. Kwok et al(2000), for
instance use an IR engine that retrieves the top
300 sub-documents of about 300-550 words and,
on the other hand, the FALCON system
(Harabagiu et al 2000) performs a paragraph
retrieval stage after the application of a boolean
retrieval engine. These systems work on the
whole database and apply a bag-of-words
technique to select passages whereas QALC first
retains a large subset of documents, among
which it then selects relevant documents by
applying richer criteria based on the use of the
linguistic structures of the words.
QALC indexes, used for document selection,
are made of single and multi-word terms
retrieved by a 2-step procedure: (1)?automatic
term extraction from questions through part-of-
speech tagging and pattern matching and
(2)?automatic document indexing through term
recognition and variant conflation. As a result,
linguistic variation is explicitly addressed
through the exploitation of word paradigms,
contrarily to other approaches like the one taken
in COPSY (Schwarz 1988) where an
approximate matching technique between the
query and the documents implicitly takes it into
account. Finally, terms acquired at step?(1) and
indexes from step?(2) are also used by the
matching procedure between a question and the
relevant document sentences.
In the next section, we describe the
architecture of the QALC system. Then, we
present the question processing for term
extraction. We continue with the description of
FASTR, a transformational shallow parser that
recognizes and marks the extracted terms as well
as their linguistic variants within the documents.
The two following sections present the modules
of the QALC system where terms and variants
are used, namely the document selection and
question/answer matching modules. Finally, we
present the results obtained by the QALC
system as well as an evaluation of the
contribution of this NLP technique to the QA
task through the use of the reference collections
for the QA track. In conclusion, suggestions for
more ambitious, but still realistic, developments
using NLP are outlined.
2 System Overview
Natural Language Processing components in the
QALC system (see Figure 1) enrich the selected
documents with terminological indexes in order
to go beyond reasoning about single words. Rich
linguistic features are also used to deduce what a
question is about.
Tagged Questions:
Named entity tags
Vocabulary &
  frequencies
Named entity
 recognition
Candidate
terms
Retrieved
documents
Tagged sentences: named entity
    tags and term indexation
Ordered sequences of 250 and
           50 characters
Question analysis Search engine
Questions
Subset of ranked documents
Corpus
Re-indexing and selection of
      documents (FASTR)
Question/Sentence pairing
Figure 1. The QALC system
The analysis of a question relies on a shallow
parser which spots discriminating patterns and
assigns categories to the question. The
categories correspond to the types of entities that
are likely to constitute the answer to the
question.
In order to select the best documents from
the results given by the search engine and to
locate the answers inside them, we work with
terms and their variants, i.e. morphologic,
syntactic and semantic equivalent expressions.
A term extractor has been developed, based on
syntactic patterns which describe complex
nominal phrases and their subparts. These terms
are used by FASTR (Jacquemin 1999), a
shallow transformational natural language
analyzer that recognizes their occurrences and
their variants. Each occurrence or variant
constitutes an index that is subsequently used in
the processes of document ranking and
question/document matching.
Documents are ordered according to a weight
computed thanks to the number and the quality
of the terms and variants they contain. For
example, original terms with proper names are
considered more reliable than semantic variants.
An analysis of the weight graph enables the
system to select a relevant subpart of the
documents, whose size varies along the
questions. This selection takes all its importance
when applying the last processes which consist
of recognizing named-entities and analyzing
each sentence to decide whether it is a possible
answer or not. As such processes are time
consuming we attempt to limit their application
to a minimal number of documents.
Named entities are recognized in the
documents and used to measure the similarity
between the document sentences and a question.
Named entities receive one of the following
types: person, organization, location (city or
place), number (a time expression or a number
expression). They are defined in a way similar to
the MUC task and recognized through a
combination of lexico-syntactic patterns and
significantly large lexical data.
Finally, the question/answer matching
module uses all the data extracted from the
questions and the documents by the preceding
modules. We developed a similarity measure
that attributes weights to each characteristic, i.e.
named entity tags and terms and variants, and
makes a combination of them. The QALC
system proposes long and short answers.
Concerning the short ones, the system focuses
on parts of sentences that contain the expected
named entity tags, when they are known, or on
the largest subpart without any terms of the
question.
3 Terms and Variants
3.1 Term extraction
For automatic acquisition of terms from
questions, we use a simple technique of filtering
through patterns of part-of-speech categories.
No statistical ranking is possible because of the
small size of the questions from which terms are
extracted. First, questions are tagged with the
help of the TreeTagger (Schmid 1999). Patterns
of syntactic categories are then used to extract
terms from the tagged questions. They are very
close to those described by Justeson and
Katz?(1995), but we do not include post-posed
prepositional phrases. The pattern used for
extracting terms is:
(((((JJ | NN | NP | VBG)) ? (JJ | NN | NP | VBG) (NP
| NN))) | (VBD) | (NN) | (NP) | (CD))
where NN are common nouns, NP proper nouns,
JJ adjectives, VBG gerunds, VBD past
participles and CD numeral determiners.
The longest string is acquired first and
substrings can only be acquired if they do not
begin at the same word as the superstring. For
instance, from the sequence nameNN ofIN theDT
USNP helicopterNN pilotNN shotVBD downRP,
the following four terms are acquired: U S
helicopter pilot, helicopter pilot, pilot, and
shoot.
The mode of acquisition chosen for terms
amounts to considering only the substructures
that correspond to an attachment of modifiers to
the leftmost constituents (the closest one). For
instance, the decomposition of US helicopter
pilot into helicopter pilot and pilot is equivalent
to extracting the subconstituents of the structure
[US [helicopter [pilot]]].
3.2 Variant recognition through FASTR
The automatic indexing of documents is
performed by FASTR (Jacquemin 1999), a
transformational shallow parser for the
recognition of term occurrences and variants.
Terms are transformed into grammar rules and
the single words building these terms are
extracted and linked to their morphological and
semantic families.
The morphological family of a single word w
is the set M(w) of terms in the CELEX database
(CELEX 1998) which have the same root
morpheme as w. For instance, the morphological
family of the noun maker is made of the nouns
maker, make and remake, and the verbs to make
and to remake.
The semantic family of a single word w is the
union S (w ) of the synsets  of WordNet1.6
(Fellbaum 1998) to which w belongs. A synset is
a set of words that are synonymous for at least
one of their meanings. Thus, the semantic family
of a word w is the set of the words w' such that
w' is considered as a synonym of one of the
meanings of w. The semantic family of maker,
obtained from WordNet1.6, is composed of
three nouns: maker, manufacturer, shaper and
the semantic family of c a r is car, auto,
automobile, machine, motorcar.
Variant patterns that rely on morphological
and semantic families are generated through
metarules. They are used to extract terms and
variants from the document sentences in the
TREC corpus. For instance, the following
pattern, named NtoSemArg, extracts the
occurrence making many automobiles as a
variant of the term car maker:
VM('maker') RP? PREP? (ART (NN|NP)? PREP)?
ART? (JJ?|?NN?|?NP |?VBD?|?VBG)[0-3] NS('car')
where RP are particles, PREP prepositions, ART
articles, and VBD, VBG verbs. VM('maker') is
any verb in the morphological family of the
noun maker and NS('car') is any noun in the
semantic family of car.
Relying on the above morphological and
semantic families, auto maker, auto parts
maker , car manufacturer, make autos, and
making many automobiles are extracted as
correct variants of the original term car maker
through the set of metarules used for the QA
track experiment. Unfortunately, some incorrect
variants are extracted as well, such as make
those cuts in auto produced by the preceding
metarule.
3.3 Document selection
The output of NLP-based indexing is a list of
term occurrences composed of a document
identifier d, a term identifier?a pair t(q,i)
composed of a question number q and a unique
index i?, a text sequence, and a variation
identifier v (a metarule). For instance, the
following index :
LA092690-0038 t(131,1)
making many automobiles NtoVSemArg
means that the occurrence making many
automobiles from document d=LA092690-0038
is obtained as a variant of term i=1 in question
q=131 (car maker) through the variation
NtoVSemArg given in Section 3.2.
Each document d selected for a question q is
associated with a weight. The weighting scheme
relies on a measure of quality of the different
families of variations described by
Jacquemin?(1999): non-variant occurrences are
weighted 3.0, morphological and morpho-
syntactic variants are weighted 2.0, and
semantic and morpho-syntactico-semantic
variants are weighted 1.0.
Since proper names are more reliable indices
than common names, each term t(q,i) receives a
weight P(t(q , i )) between 0 and 1.0
corresponding to its proportion of proper names.
For instance, President Cleveland's wife is
weighted 2/3=0.66. Since another factor of
reliability is the length of terms, a factor |t(q,i)|
in the weighting formula denotes the number of
words in term t(q,i). The weight Wq(d) of a
query q  in a document d  is given by the
following formula (1). The products of the
weightings of each term extracted by the indexer
are summed over the indices I(d) extracted from
document d and normalized according to the
number of terms |T(q)| in query q.
  
W (d)
( ) ( ( ( , ))) ( , )
( )
q
( ( , ), ) ( )
=
? + ?
?
? w v P t q i t q i
T q
t q i v I d
1 2
         (1)
Mainly two types of weighting curves are
observed for the retrieved documents: curves
with a plateau and a sharp slope at a given
threshold (Figure 2.a) and curves with a slightly
decreasing weight (Figure 2.b).
The edge of a plateau is detected by examining
simultaneously the relative decrease of the slope
with respect to the preceding one, and the
relative decrease of the value with respect to the
preceding one. When a threshold is detected, we
only select documents before this threshold,
otherwise a fixed cutoff threshold is used. In our
experiments, for each query q, the 200 best
ranked documents retrieved by the search
engine1 were subsequently processed by the re-
indexing module. Our studies (Ferret et al 2000)
show that 200 is a minimum number such as
almost all the relevant documents are kept.
When no threshold was detected, we fixed the
value of the threshold to 100.
0
0
10
10
20
20
30
30
40
40
50
50
60
60
70
70
80
80
90
90
100
100
0
0
1
1
2
2
3
3
4
4
5
5
6
6
7
8
9
10
rank of the document
w
ei
gh
t
Question #87
rank of the document
Truncation of the ranked list
Question #86
w
ei
gh
t
(a)
(b)
Figure 2. Two types of weighting curve.
Through this method, the cutoff threshold is
8 for question #87 (Who followed Willy Brandt
as chancellor of the Federal Republic of
Germany?, Figure 2(a))2 and 100 for question
#86 (Who won two gold medals in skiing in the
Olympic Games in Calgary?, Figure 2(b)). As
indicated by Figure??2(a), there is an important
difference of weight between documents #8 and
#9. The weight of document #8 is 9.57 while the
                                                           
1 We used in particular Indexal (Loupy et al1998), a search
engine provided by Bertin Technologie.
2 Questions come from the TREC8 data.
weight of document #9 is 7.29 because the term
Federal Republic only exists in document #8.
This term has a high weight because it is
composed of two proper names.
4 Question-Answer Matching
4.1 Question type categorization
Question type categorization is performed in
order to assign features to questions and use
these features for the similarity measurement
between a question and potential answer
sentences. Basically, question categorization
allows the prediction of the kind(s) of answer,
called target (for instance, NUMBER).
Sentences inside the retrieved documents are
labeled with the same tags as questions. During
the similarity measurement, the more the
question and a sentence share the same tags, the
more they are considered as involved in a
question-answer relation. For example:
Question:
How many people live in the Falklands?
?> target = NUMBER
Answer:
F a l k l a n d s  p o p u l a t i o n  o f  <bnumex
TYPE=NUMBER> 2,100 <enumex> is
concentrated.
We established 17 types of answer. Some
systems define more categories. For instance
Prager et al (2000) identify about 50 types of
answer.
4.2 Answer Selection
In the QALC system, we have taken the
sentence as a basic unit because it is large
enough to contain the answer to questions about
simple facts and to give a context that permits
the user to judge if the suggested answer is
actually correct. The module associates each
question with the Na most similar sentences (Na
is equal to 5 for the QA task at TREC).
The overall principle of the selection process
is the following: each sentence from the
documents selected for a question is compared
with this question. To perform this comparison,
sentences and questions are turned into vectors
that contain three kinds of elements: content
words, term identifiers and named entity tags. A
specific weight (between 0 and 1.0) is associated
with each of these elements in order to express
their relative importance.
The content words are the lemmatized forms
of mainly adjectives, verbs and nouns such as
they are given by the TreeTagger. Each content
word in a vector is weighted according to its
degree of specificity in relation to the corpus in
which answers are searched through the tf.idf
weighting scheme. For questions, the term
identifiers refer to the terms extracted by the
term extractor described in Section?3.1 and
receive a fixed weight. In sentence vectors, term
identifiers are associated with the normalized
score from the ranking module (see Section 3.3).
The named entity tags correspond to the possible
types of answers, provided by the question
analysis module. In each sentence these tags
delimit the named entities that were recognized
by the corresponding module of the QALC
system and specify their type. Unlike term
identifiers, named entity tags are given the same
fixed weight in both sentence and question
vectors because the matching module uses the
types of the named entities and not their values.
In our experiments, the linguistic features
(terms and named entities) are used to favor
appropriate sentences when they have not
enough content words in common with the
question or when the question only contains a
few content words. Thus, the weights of term
identifiers or named entity tags are reduced by
applying a coefficient in order to be globally
lower than the weights of the content words.
Finally, the comparison between a sentence
vector Vd and a question vector Vq is achieved
by computing the following similarity measure:
?
?
=
j j
i i
dq
wq
wd
VVsim ),( (2)
where wqj is the weight of an element in the
question vector and wdi is the weight of an
element in a sentence vector that is also in the
question vector. This measure evaluates the
proportion and the importance of the elements in
the question vector that are found in the
sentence vector with regards to all the elements
of the question vector. Moreover, when the
similarity value is nearly the same for two
sentences, we favor the one in which the content
words of the question are the least scattered.
The next part gives an example of the
matching operations for the TREC8 question
Q16 What two US biochemists won the Nobel
Prize in medicine in 1992? This question is
turned into the following vector:
two (1.0) US (1.0) biochemist (0.9)
nobel (1.0) prize (0,6) medicine (0,5)
win (0,3) 1992 (1.0) <PERSON> (0.5)
16.01 (0.5) 16.04 (0.5)
where <PERSON> is the expected type of the
answer, 16.01 is the identifier of the U S
biochemist term and 16.04 is the identifier of the
Nobel Prize term.
The same kind of vector is built for the
sentence <NUMBER> Two </NUMBER> US
biochemists, <PERSON> Edwin Krebs
</PERSON> and <CITY> Edmond </CITY>
Fischer, jointly won the <NUMBER> 1992
</NUMBER> Nobel Medicine Prize for work
that could advance the search for an anti-cancer
drug, coming from the document FT924-14045
that was selected for the question Q163 :
two (1.0) US (1.0) biochemist (0.9)
nobel (1.0) prize (0,6) medicine (0,5)
win (0,3) 1992 (1.0) Edwin (0.0)
Krebs (0.0) Edmond (0.0) Fischer (0.0)
work (0.0) advance (0.0) search (0.0)
anti-cancer (0.0) jointly (0.0) drug (0.0)
<PERSON> (0.5) <NUMBER> (0.0) <CITY>(0.0)
16.01 (0.5) 16.04 (0.3)
where the weight 0.0 is given to the elements
that are not part of the question vector. The term
US biochemist is found with no variation and
Nobel Prize appears as a syntactic variant.
Finally, according to (2), the similarity measure
between theses two vectors is equal to 0.974.
5 Results and Evaluation
We sent to TREC9 three runs whose variations
concern the searched engine used and the length
of the answer (250 or 50 characters). Among
those runs, the best one obtained a score of
0.407 with 375 correct answers among 682
questions, for answers of 250 characters length.
The score computed by NIST is the reciprocal
mean of the rank, from 1 to 5, of the correct
                                                           
3 This sentence is taken from the output of the named entity
recognizer.
answer. With this score, the QALC system was
ranked 6th among 25 participants at TREC 9
QA task.
Document selection relies on a quantitative
measure, i.e. the document weight, whose
computation is based on syntactic and semantic
indices, i.e. the terms and the terminological
variants. Those indices allow the system to take
into account words as well as group of words
and their internal relations within the
documents. Following examples, that we have
got from selected documents for TREC9 QA
task, show what kind of indices are added to the
question words.
For the question 252 When was the first flush
toilet invented? , one multi-word extracted term
is flush toilet. This term is marked by FASTR
when recognized in a document, but it is also
marked when a variant is found, as for instance
low-flush toilet in the following document
sentence where low-flush is recognized as
equivalent to flush:
Santa Barbara , Calif. , is giving $ 80 to
anyone who converts to a low-flush toilet.
252.01   flush toilet[JJ][NN]
             low-flush[flush][JJ] toilet[toilet][NN]
             1.00
In the given examples, after the identification
number of the term, appears the reference term,
made of the lemmatized form of the words and
their syntactic category, followed by the variant
found in the sentence, with each word, its
lemmatized form and its category, and finally its
weight.
In the example above, the term found in the
sentence is equivalent to the reference term, and
thus its weight is 1.00.
The second example shows a semantic
variant. Salary and average salary are terms
extracted from the question 337, What's the
average salary of a professional baseball player
?. The semantic variant pay, got from WordNet,
was recognized in the following sentence?:
Did the NBA union opt for the courtroom
because its members, whose average pay tops
$500000 a year, wouldn't stand still for a
strike over free agency ?
337.01    salary[NN] pay[pay][NN] 0.25
337.00    average [JJ]salary[NN]
               average[average][JJ] pay[pay][NN]
               0.40
In order to evaluate the efficiency of the
selection process, we proceeded to several
measures. We apply our system on the material
given for the TREC8 evaluation, one time with
the selection process, and another time without
this process. At each time, 200 documents were
returned by the search engine for each of the 200
questions. When selection was applied, at most
100 documents were selected and subsequently
processed by the matching module. Otherwise,
the 200 documents were processed. The system
was scored by 0.463 in the first case, and by
0.452 in the second case. These results show
that the score increases when processing less
documents above all because it is just the
relevant documents that are selected.
The benefit from performing such a selection
is also illustrated by the results given in Table 1,
computed on the TREC9 results.
Number of documents selected
by ranking
100 <<100
Distribution among the
questions
342
(50%)
340
(50%)
Number of correct answers 175
(51%)
200
(59%)
Number of correct answer at
rank 1
88
(50%)
128
(64%)
Table 1. Evaluation of the ranking process
We see that the selection process discards a
lot of documents for 50% of the questions (340
questions are processed from less than 100
documents). The document set retrieved for
those questions had a weighting curve with a
sharp slope and a plateau as in Figure 2(a).
QALC finds more often the correct answer and
in a better position for these 340 questions than
for the 342 remaining ones. The average number
of documents selected, when there are less than
100, is 37. These results are very interesting
when applying such time-consuming processes
as  named ent i ty  recogni t ion and
question/sentence matching. Document selection
will also enable us to apply later on syntactic
and semantic sentence analysis.
6 Conclusion
The goal of a question-answering system is to
find an answer to a precise question, with a
response time short enough to satisfy the user.
As the answer is searched within a great amount
of documents, it seems relevant to apply mainly
numerical methods because they are fast. But, as
we said in the introduction, precise answers
cannot be obtained without adding NLP tools to
IR techniques. In this paper, we proposed a
question answering system which uses
terminological variants first to reduce the
number of documents to process while
increasing the system performance, and then to
improve the matching between a question and its
potential answers. Furthermore, reducing the
amount of text to process will afterwards allow
us to apply more complex methods such as
semantic analysis. Indeed, TREC organizers
foresee a number of possible improvements for
the future?: real-time answering, evaluation and
justification of the answer, completeness of the
answer which could result from answers
distributed along multiple documents, and
finally interactive question answering so that the
user could specify her/his intention. All those
improvements require more data sources as well
as advanced reasoning about pragmatic and
semantic knowledge.
Thus, the improvements that we now want to
bring to our system will essentially pertain to a
semantic and pragmatic approach. For instance,
WordNet that we already use to get the semantic
variants of a word, will be exploited to refine
our set of question types. We also plan to use a
shallow syntactico-semantic parser in order to
construct a semantic representation of both the
potential answer and the question. This
representation will allow QALC to select the
answer not only from the terms and variants but
also from the syntactic and semantic links that
terms share with each other.
References
Baluja, S., Vibhu O. M., Sukthankar, R. 1999
Applying machine learning for high performance
named-entity extraction. P r o c e e d i n g s
PACLING'99 Waterloo, CA. 365-378.
CELEX. 1998.
http://www.ldc.upenn.edu/readme_files/celex.read
me.html. Consortium for Lexical Resources,
UPenns, Eds.
Fabre C., Jacquemin C, 2000. Boosting variant
recognition with light semantics. Proceedings
COLING?2000, pp. 264-270, Luxemburg.
Fellbaum, C. 1998. WordNet: An Electronic Lexical
Database. Cambridge, MA, MIT Press.
Ferret O., Grau B., Hurault-Plantet M., Illouz G.,
Jacquemin C. (2000), QALC ? the Question-
Answering system of LIMSI-CNRS, pre-
proceedings of TREC9, NIST, Gaithersburg, CA.
Harabagiu S., Pasca M., Maiorano J. 2000.
Experiments with Open-Domain Textual Question
Answering. Proceedings of  Coling'2000,
Saarbrucken, Germany.
Jacquemin C. 1999. Syntagmatic and paradigmatic
representations of term variation. Proceedings of
ACL'99. 341-348.
Justeson J., Katz S. 1995. Technical terminology:
some linguistic properties and an algorithm for
identification in texte. Natural Language
Engineering. 1: 9-27.
Kwok K.L., Grunfeld L., Dinstl N., Chan M. 2000.
TREC9 Cross Language, Web and Question-
Answering Track experiments using PIRCS. Pre-
proceedings of TREC9, Gaithersburg, MD, NIST
Eds. 26-35.
Loupy C. , Bellot P., El-B?ze M., Marteau P.-F..
Query Expansion and Classification of Retrieved
Documents, TREC (1998), 382-389.
Prager J., Brown, E., Radev, D., Czuba, K. (2000),
One Search Engine or two for Question-
Answering, NISTs, Eds., Proceedings of TREC9,
Gaithersburg, MD. 250-254.
Schmid H. 1999. Improvments in Part-of-Speech
Tagging with an Application To German.
Natural?Language Processing Using Very Large
Corpora, Dordrecht, S. Armstrong, K. W. Chuch,
P. Isabelle, E. Tzoukermann,  D. Yarowski, Eds.,
Kluwer Academic Publisher.
Schwarz C. 1988. The TINA Project: text content
analysis at the Corporate Research Laboratories at
Siemens. Proceedings of Intelligent Multimedia
Information Retrieval Systems and Management
(RIAO?88) Cambridge, MA. 361-368.
