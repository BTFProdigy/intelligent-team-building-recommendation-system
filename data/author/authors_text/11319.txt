Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1105?1112
Manchester, August 2008
Automatic Generation of Parallel Treebanks
Ventsislav Zhechev
NCLT, School of Computing
Dublin City University
Dublin, Ireland
vzhechev@computing.dcu.ie
Andy Way
NCLT, School of Computing
Dublin City University
Dublin, Ireland
away@computing.dcu.ie
Abstract
The need for syntactically annotated data 
for use in natural language processing has 
increased dramatically in recent years. This 
is true especially for parallel treebanks, of 
which very few exist. The ones that exist 
are mainly hand-crafted and too small for 
reliable use in data-oriented applications. 
In this paper we introduce a novel platform 
for fast and robust automatic generation of 
parallel treebanks. The software we have 
developed based on this platform has been 
shown to handle large data sets. We also 
present evaluation results demonstrating 
the quality of the derived treebanks and 
discuss some possible modifications and 
improvements that can lead to even better 
results. We expect the presented platform 
to help boost research in the field of data-
oriented machine translation and lead to 
advancements in other fields where paral-
lel treebanks can be employed.
1 Introduction
In recent years much effort has been made to make 
use of syntactic information in statistical machine 
translation (MT) systems (Hearne and Way, 2006, 
Nesson et al, 2006). This has led to increased in-
terest in the development of parallel treebanks as 
the source for such syntactic data. They consist 
of a parallel corpus, both sides of which have 
been parsed and aligned at the sub-tree level.
So far parallel treebanks have been created 
manually or semi-automatically. This has proven 
to be a laborious and time-consuming task that is 
prone to errors and inconsistencies (Samuelsson 
and Volk, 2007). Because of this, only a few paral-
lel treebanks exist and none are of sufficient size for 
productive use in any statistical MT application.
In this paper we present a novel platform for 
the automatic generation of parallel treebanks 
from parallel corpora and discuss several meth-
ods for the evaluation of the results. We discuss 
algorithms both for cases in which monolingual 
parsers exist for both languages and for cases in 
which such parsers are not available. The parallel 
treebanks created with the methods described in 
this paper can be used by different statistical MT 
applications and for translation studies.
We start in section 2 by introducing the tech-
niques for automatic generation of parallel tree-
banks. The evaluation methods and results are 
introduced in section 3 and in section 4 we give 
suggestions for possible improvements to the 
generation technology and to the evaluation algo-
rithms. Finally, in section 5 we present existing 
parallel treebanks and conclude in section 6.
2 Automatic Generation of
Parallel Treebanks
In this section we introduce a method for the auto-
matic generation of parallel treebanks from paral-
lel corpora. The only tool that is required besides 
the software presented in this paper is a word 
alignment tool. Such tools exist and some are freely 
available (eg. GIZA++ (Och and Ney, 2003)). If 
monolingual phrase-structure parsers1  or at least 
POS taggers exist for both languages, their use for 
pre-processing the data is highly recommended.
In all cases, a word alignment tool is used to 
first obtain word-alignment probabilities for the 
? 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license 
(http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved.
1 Henceforth, we will use ?parser? to mean ?monolingual phrase-structure parser?, unless stated otherwise.
1105
parallel corpus in question for both language di-
rections. We will start with the description of the 
case in which parsers are available for both lan-
guages, as this is the core of the system. The 
parsers are used to parse both sides of the paral-
lel corpus. The resulting parsed data and word-
alignment probability tables are then used as the 
input to a sub-tree alignment algorithm that in-
troduces links between nodes in corresponding 
trees according to their translational equivalence 
scores. The output of the sub-tree aligner is the 
desired parallel treebank.
If there is no parser available for at least one 
of the languages, the parallel corpus ? together 
with the word-alignment tables ? is fed directly 
to a modified version of the sub-tree aligner. In 
this modification of the alignment algorithm, all 
possible binary phrase-structure trees are hy-
pothesised for each sentence in a sentence pair. 
Afterwards ? during the induction of alignments 
? only those tree nodes are left intact that take 
part in the alignments or are necessary for the 
production of connected trees. Thus, the output is 
again a parallel treebank with unambiguous 
phrase-structure trees for each language side.
In the present version of our software, if a 
parser or a POS tagger exists only for one of the 
languages in the parallel corpus you want to 
work with, they cannot be made use of. With the 
tree-to-tree and string-to-string modules in place, 
it is a minor task to add a tree-to-string and 
string-to-tree modules that will allow for the 
maximum utilisation of any available resources. 
We plan to start the development and evaluation 
of these new modules shortly.
We will now look at the currently available 
alignment algorithms in greater detail, starting 
with the tree-to-tree alignment and then moving 
on to the string-to-string case.
2.1 Tree-to-Tree Alignment
First, the tree-to-tree aligner has to follow certain 
principles to fit in the framework described above:
? Independence with respect to language pair, 
constituent-labelling scheme and POS tag 
set. Any language-dependence would re-
quire human input to adjust the aligner to a 
new language pair.
? Preservation of the original tree structures. 
We regard these structures as accurate en-
codings of the languages, and any change to 
them might distort the encoded information.
? Dependence on a minimal number of external 
resources, so that the aligner can be used even 
for languages with few available resources.
? The word-level alignments should be guided 
by links higher up the trees, where more 
context information is available.
These principles guarantee the usability of the 
algorithm for any language pair in many different 
contexts. Additionally, there are a few well-
formedness criteria that have to be followed to 
enforce feasible alignments:
? A node in a tree may only be linked once.
? Descendants / ancestors of a source linked 
node may only be linked to descendants / 
ancestors of its target linked counterpart.
Links produced according to these criteria en-
code enough information to allow the inference 
of complex translational patterns from a parallel 
treebank, including some idiosyncratic transla-
tional divergences, as discussed in (Hearne et al, 
2007). In what follows, a hypothesised alignment 
is regarded as incompatible with the existing 
alignments if it violates any of these criteria.
The sub-tree aligner operates on a per sentence-
pair basis and each sentence-pair is processed in 
two stages. First, for each possible hypothetical 
link between two nodes, a translational equiva-
lence score is calculated. Only the links for 
which a nonzero score is calculated are stored for 
further processing. Unary productions from the 
original trees, if available, are collapsed to single 
nodes, preserving all labels. Thus the aligner will 
consider a single node ? instead of several 
nodes ? for the same lexical span. This does not 
reduce the power of the aligner, as the transla-
tional equivalence scores are based on the sur-
face strings and not on the tree structures.
During the second stage, the optimal combina-
tion of links is selected from among the available 
nonzero links. The selection can be performed 
using either a greedy search, or a full search for 
the best combination.
Translational Equivalence
Given a tree pair S, T and a hypothesis s, t, we 
first compute the strings in (1), where si?six and 
tj?tjy denote the terminal sequences dominated 
by s and t respectively, and S1?Sm and T1?Tn 
denote the terminal sequences dominated by S and 
T. Here, inside are the strings that represent the 
spans of the nodes being linked and outside are the 
strings that lay outside the spans of those nodes.
1106
(1)
inside outside
sl = si?six sl = S1?si  1six + 1?Sm
tl = t j?t jy tl = T1?t j  1t jy + 1?Tn
(2)  s, t =  sl tl  tl sl  sl tl  tl sl
(3)  x y = P xi y jj
y
yi
x
The score for the given hypothesis s, t  is 
computed using (2) and (3). According to the 
formula in (3), the word-alignment probabilities 
are used to get an average vote by the source to-
kens for each target token. Then the product of 
the votes for the target words gives the alignment 
probability for the two strings. The final transla-
tional equivalence score is the product of the 
alignment probabilities for the inside and outside 
strings in both language directions as in (2).
Greedy-Search Algorithm
The greedy-search algorithm is very simple. The 
set of nonzero-scoring links is processed itera-
tively by linking the highest-scoring hypothesis 
at each iteration and discarding all hypotheses 
that are incompatible with it until the set is empty.
Problems arise when there happen to be several 
hypotheses that share the same highest score. There 
are two distinct cases that can be observed here: 
these top-scoring hypotheses may or may not repre-
sent incompatible links. If all such hypotheses are 
compatible, they are all linked at the same time and 
all remaining unprocessed hypotheses that are 
incompatible with any of those links are discarded. 
In case even one among the top-scoring hypothe-
ses is incompatible with the others, these hypothe-
ses are skipped and processed at a later stage.
The sub-tree aligner can be built to use one of 
two possible skipping strategies, which we will 
call skip1  and skip2. According to the skip1 strat-
egy, hypotheses are simply skipped until a score 
is reached, for which only one hypothesis exists. 
This hypothesis is then linked and the selection 
algorithm continues as usual.
The skip2 strategy is more complex, in that we 
also keep track of which nodes take part in the 
skipped hypotheses. Then, when a candidate for 
linking is found, it is only linked if it does not 
include any of these nodes. The motivation be-
hind this strategy is that a situation may occur in 
which a low-scoring hypothesis for a given con-
stituent is selected in the same iteration as 
higher-scoring hypotheses for the same constitu-
ent were skipped, thereby preventing one of the 
competing higher-scoring hypotheses from being 
selected and resulting in an undesired link.
Regardless of whether skip1 or skip2 is used, 
sometimes a situation occurs in which the only 
hypotheses remaining unprocessed are equally 
likely candidates for linking according to the se-
lection strategy. In such ambiguous cases our 
decision is not to link anything, rather than make 
a decision that might be wrong.
During initial testing of the aligner we found 
that often lexical links would get higher scores 
than the non-lexical links,2  which sometimes re-
sulted in poor lexical links preventing the selec-
tion of bona fide non-lexical ones. To address 
this issue, an extension to the selection algorithm 
was developed, which we call span1. When en-
abled, this extension results in the set of nonzero 
hypotheses being split in two subsets: one con-
taining all hypotheses for lexical links, and one 
containing the hypotheses for non-lexical links. 
Links are then first selected from the second sub-
set, and only when it is exhausted does the selec-
tion continue with the lexical one. This division 
does not affect the discarding of incompatible 
links after linking; incompatible links are dis-
carded in whichever set they are found.
Full-Search Algorithm
This is a backtracking recursive algorithm that 
enumerates all possible combinations of non-
crossing links. All maximal combinations3  found 
during the search are stored for further process-
ing. After the search is complete, the probability 
mass of each combination is calculated by sum-
ming the translational equivalence scores for all 
the links in the combination. The maximal com-
bination of non-crossing links that has the high-
est probability mass is selected as the best align-
ment for the sentence pair.
Often, there are several distinct maximal combi-
nations that share the highest probability mass; for 
longer sentences this number can rise to several 
hundred. The disambiguation strategy that we cur-
rently employ is to take the largest common subset 
of all maximal combinations. Another strategy 
would be to output all possible combinations and 
mark them as relating to the same sentence pair, 
thus leaving the disambiguation to the applica-
tion that uses the resulting parallel treebank.
2 lexical are such links, for which at least one of the linked nodes spans over only one word. All other links are non-lexical.
3 A maximal combination of non-crossing links is a combination of links for which any newly added link would be 
incompatible with at least one of the links already in the combination.
1107
2.2 String-to-String Alignment
The string-to-string aligner can accept as its in-
put plain or POS-tagged data. For a pair of sen-
tences, all possible binary trees are first con-
structed for each sentence. All nodes in these 
trees have the same label (X) and are then used as 
available link targets. In the case of POS-tagged 
data, the pre-terminal nodes receive the POS tags 
as labels. Here it is obvious that the number of 
links will be much higher than for the sub-tree 
alignment case, so the string-to-string aligner 
will operate much more slowly.
After all link-hypothesis scores have been cal-
culated, the string-to-string aligner continues 
with the selection of links in the same manner as 
the sub-tree aligner, with one extension; after a 
link has been selected ? besides all incompati-
ble links ? all binary trees that do not include 
the linked nodes are discarded with any nonzero 
hypotheses attached to them. In this way, only 
those binary trees that are compatible with the 
selected links remain after the linking process.
In an additional step for the string-to-string 
aligner, all non-linked nodes (except for the root 
nodes) are discarded, thus allowing for the construc-
tion of unambiguous n-ary trees for the source and 
target sentences. If necessary, non-linked nodes are 
left intact to provide supporting structure in the trees.
3 Evaluation and Results
The quality of a parallel treebank depends directly 
on the quality of the sub-tree alignments that it 
contains. Because of this, we use the evaluation 
results mainly as a metric for the improvements 
in the sub-tree aligner during development. Of 
course, the evaluation presented in this section 
also presents an insight into the usability of the 
parallel treebanks produced using our method.
For the evaluation of the aligner, a battery of in-
trinsic and extrinsic tests was developed. As a refer-
ence for the tests, a hand-crafted parallel treebank 
was used (HomeCentre (Hearne and Way, 2006)). 
This treebank consists of 810 English?French sen-
tence pairs. As discussed in section 5, we are not 
aware of an existing parallel treebank besides the 
HomeCentre that can be used directly for cross 
evaluation and comparison to versions automati-
cally generated using the sub-tree aligner.
The word-alignment probabilities required by 
our system were obtained by running the Moses 
decoder4 (Koehn et al, 2007) on the plain sentences 
from the HomeCentre in both language directions.
We will first describe the intrinsic testing and 
then go into the details of the extrinsic evaluation.
3.1 Intrinsic Evaluation
The intrinsic evaluation is performed by compar-
ing the links induced by the automatic aligner to 
the manually annotated links in the HomeCentre 
treebank. This evaluation can only be performed 
for the result of the tree-to-tree alignment, as the 
string-to-string alignment produces different 
trees. The metrics used for the comparison are 
precision and recall for all alignments and lexical 
and non-lexical alignments alone. The results of 
the evaluation are shown in Table 1.5
all links lexical links non-lexical links
Configura-
tions
skip1
skip2
skip1_span1
skip2_span1
preci-
sion
recall preci-
sion
recall preci-
sion
recall
61,29% 77,46% 51,06% 79,99% 80,75% 75,69%
61,54% 77,50% 51,29% 80,03% 80,75% 75,70%
61,56% 78,44% 51,53% 80,51% 78,67% 77,22%
61,79% 78,49% 51,76% 80,60% 78,73% 77,22%
Table 1. Intrinsic evaluation results
Looking first to the all links column, it is imme-
diately apparent that recall is significantly higher 
than precision for all configurations. In fact, all 
aligner variations consistently induce on average 
two more links than exist in the manual version. 
Considering the lexical links and non-lexical links 
columns, apparently the bulk of the automatically 
induced links that do not occur in the manual an-
notation are at the lexical level, as attested by the 
low precision at the lexical level and balanced 
precision and recall at the non-lexical level.
If the manual alignments in the HomeCentre 
are regarded as a gold standard, it would seem 
that fewer lexical links should be produced, 
while the quality of the non-lexical links needs 
improvement. We will try to judge whether this 
is really the case using the extrinsic evaluation 
techniques described below.
3.2 Extrinsic Evaluation
For extrinsic evaluation, we trained and tested a 
DOT system (Hearne and Way, 2006) using the 
manually aligned HomeCentre treebank and 
evaluated the output translations to acquire base-
line scores. We then trained the system on the 
automatically generated treebank and repeated 
4 We found that using the Moses word-alignment probabilities yielded better results than those output directly by GIZA++.
5 Throughout the paper we use boldface to highlight the best results and italics for the worst.
1108
the same tests, such that the only difference 
across runs are the alignments.
For testing, we used the six English?French 
training / test splits for the HomeCentre used in 
(Hearne and Way, 2006). Each test set contains 80 
test sentences and each training set contains 730 
tree pairs. We evaluated the translation output 
using three automatic evaluation metrics: BLEU 
(Papineni et al, 2002), NIST (Doddington, 2002) 
and METEOR (Banerjee and Lavie, 2005). We 
averaged the results over the six splits. We also 
measured test-data coverage of the translation sys-
tem, i.e. the percentage of test sentences for which 
full trees were generated during translation.
We performed this evaluation using both the 
tree-to-tree algorithm and the string-to-string 
algorithm, employing greedy-search selection. 
For the latter case we extracted POS-tagged sen-
tences from the HomeCentre and used them as 
input for the aligner. The results for the tree-to-
tree case are presented in Table 2 and for the 
string-to-string case in Table 3.
Configurations BLEU NIST METEOR Coverage
manual
skip1
skip2
skip1_span1
skip2_span1
0,5222 6,8931 71,8531% 68,5417%
0,5236 6,8412 72,2485% 72,0833%
0,5233 6,8617 72,2847% 71,8750%
0,5296 6,8570 72,9833% 72,0833%
0,5334 6,9210 72,9736% 71,8750%
Table 2. Tree-to-tree extrinsic evaluation
Let us first look at the results from the tree-to-
tree aligner. Overall, the scores obtained when 
using the manual alignments are very competitive 
with those derived using the manually aligned 
data. In fact, NIST is the only metric for which the 
performance is below the baseline. An important 
observation is that the coverage of the translation 
system is up to 3.5% higher when using the auto-
matic alignments. Another observation is that skip2 
leads to better performance on the NIST metric 
over skip1, but the results from the other metrics are 
not so conclusive. The use of span1 leads to better 
translation scores. Ths results seem to point at 
the skip1_span1 and skip2_span1 configurations 
as the best-suited for further development.
Unexpectedly, the results of the extrinsic 
evaluation do not strictly follow the trends found 
in the intrinsic evaluation. Further analysis of the 
data revealed that direct comparison of the man-
ual and automatic alignments is not appropriate, 
especially regarding the lexical alignments. The 
manual alignments were produced with the aim 
of maximising precision, but the coverage-based 
automatic alignments lead to higher translation 
scores. This is the result of having many fewer 
manual word-alignments than automatic ones, as 
the low precision scores in the intrinsic evalua-
tion show. From this we conclude that the im-
provement of the automatic aligner should not be 
aimed at better matching the manual alignments, 
but rather at improving the quality of the transla-
tions produced using the automatic alignments.
Configurations BLEU NIST METEOR Coverage
manual
skip1
skip2
skip1_span1
skip2_span1
0,5222 6,8931 71,8531% 68,5417%
0,4939 6,6321 72,5192% 92,5000%
0,4886 6,5777 72,8241% 92,2917%
0,4661 6,3090 73,1017% 92,2917%
0,4683 6,3353 73,2828% 92,2917%
Table 3. String-to-string extrinsic evaluation
If we now look at the evaluation of the string-
to-string aligner, we see quite peculiar results. 
There is more than 20% increase in coverage 
compared to the tree-to-tree aligner, but the only 
other metric that sees improvement ? albeit 
modest ? is METEOR. It is also the only metric 
that follows the trends observed in the tree-to-
tree evaluation results. Not only are the results 
for the BLEU and NIST metrics lower, but they 
also seem to follow reversed trends. It is unclear 
what the reason for such an outcome is, and fur-
ther investigation ? including on other data sets 
? is needed. Still, as far as the METEOR metric 
is concerned, the use of the string-to-string algo-
rithm for the generation of parallel treebanks 
seems to be warranted.
The results obtained from the intrinsic and ex-
trinsic evaluations show that the methods de-
scribed in this paper produce high quality parallel 
treebanks. Using the automatically generated tree-
banks, a DOT system produces results with simi-
lar translation quality and better coverage com-
pared to its performance using manually aligned 
data. This makes our methods a good alternative 
to the manual construction of parallel treebanks.
3.3 Using the Full-Search Algorithm
as an Evaluation Metric
The full-search selection algorithm is combinato-
rial in nature and for sentence pairs with more 
than 100 nonzero link hypotheses its time re-
quirements become prohibitive. Still, this algo-
rithm can be used in its current form for devel-
opment purposes.
It is reasonable to ask whether the greedy-search 
algorithm produces the best set of alignments for 
a given sentence pair. It could be that it picks a 
local maximum differing greatly from the absolute 
maximal set of alignments, thus producing either 
low quality links or a small number of links.
1109
The full-search selection algorithm can be used 
to test the performance of the greedy search, as it by 
definition produces the best available set of align-
ments. We decided to use the rate of coincidence 
between the alignments induced using both selec-
tion algorithms as a metric for the quality of the 
links derived using the greedy search: the higher the 
number of cases in which the greedy-search algo-
rithm matches the result of the full-search algo-
rithm, the better the quality of the greedy search.
We ran this coincidence evaluation for all four 
configurations of the aligner. The results are pre-
sented in Table 4. It should be noted that 30 sen-
tence pairs from the HomeCentre could not be 
handled by the full-search algorithm within a 
reasonable timeframe and were skipped.
all links lexical links non-lexical links
Configura-
tions
skip1
skip2
skip1_span1
skip2_span1
preci-
sion
recall preci-
sion
recall preci-
sion
recall
98,71% 99,18% 98,36% 99,14% 99,57% 99,21%
99,23% 99,21% 99,06% 99,17% 99,57% 99,23%
95.78% 97,00% 95.92% 96,33% 95.19% 99,21%
96,27% 97,09% 96,58% 96,44% 95,25% 99,21%
Table 4. Evaluation against full-search results
The outcome of this test seems to be unex-
pected and a little disconcerting in view of the 
results obtained from the extrinsic evaluation. It 
does not seem reasonable that the configurations 
including span1 should obtain scores that are 
relatively much worse than the scores for the 
other configurations, when we saw them perform 
better at the extrinsic evaluation tests.
The reason for this discrepancy might not be 
obvious, but it is fairly simple and lies in the na-
ture of the span1 extension. As discussed in sec-
tion 2.1, span1 introduces a separation in the in-
duction of lexical and non-lexical links. The full-
search algorithm, however, derives the maximal 
link set from a common pool of all nonzero 
alignment hypotheses. This suggests that an ex-
tension to the full-search algorithm similar to 
span1 should be developed to allow for the 
evaluation of configurations using this feature.
Nevertheless, this evaluation shows some very 
important results. Besides the fact that configura-
tions using skip2 perform slightly better than 
those using skip1, we see that the greedy search 
comes very close to the best maximal link set. 
Our tests show that in over 95% of the cases the 
greedy search finds the best maximal link set 
available for the particular sentence pair.
The results are very encouraging and show 
that the fast greedy-search algorithm produces 
the desired results and there is no need to use the 
prohibitively slow full-search algorithm, except 
for comparison purposes.
4 A Review of Possible Enhancements
Here, we discuss possible avenues for the im-
provement of the quality of the parallel treebanks 
produced using the methods presented in this paper.
As already stated in section 3, the quality of a 
parallel treebank is to be judged by the quality of 
the induced sub-tree alignments. Thus, all effort 
should be directed at producing better alignments. 
There are two possible ways to address this: one 
option is to work on improving the alignment 
algorithm, and the other option is to improve the 
scoring mechanism used by the aligner.
Improvements to the alignment algorithm can 
be evaluated against the full-search selection al-
gorithm. The evaluation results from section 3.3 
suggest, however, that the margin for improve-
ment here is very small. Thus, we do not expect any 
improvements here to bring serious boosts in over-
all performance. Nevertheless, we plan to investi-
gate one possible modification to the greedy search.
It can be argued that each newly induced link in 
a sentence pair should affect the decisions regard-
ing which links to select further in the alignment 
process for this sentence pair. This can be simulated 
to a certain extent by the introduction of a simple 
re-scoring module to the aligner. Each time a new 
link has been selected, this module will be used to 
recalculate the scores of the remaining links, con-
sidering the restrictions on the possible word-level 
alignments introduced by this link, e.g. that words 
within the spans of the nodes being linked cannot 
be aligned to words outside those spans.
The effects of changes to the scoring mecha-
nism used can only be evaluated using extrinsic 
methods, as such changes also influence the op-
eration of the full-search selection. On this front, 
we plan to investigate a maximum-entropy-based 
scoring mechanism. We expect such a mecha-
nism to better encode mathematically the de-
pendence of the translational equivalence scores 
on the word-alignment probabilities.
Besides the improvements to the sub-tree 
aligner, we plan to extend the whole generation 
framework with two additional modules: for 
string-to-tree and tree-to-string alignment. This 
would allow for better utilisation of all available 
resources for the derivation of a parallel treebank 
from a parallel corpus.
We also plan to perform large-scale extrinsic 
evaluation experiments. Though the evaluation re-
sults presented in section 3 are very promising, they 
1110
were performed on a very small set of data. (John 
Tinsley (p.c.) reports successfully deriving a paral-
lel treebank with over 700 000 sentence-pairs using 
our software.) Further experiments on larger data 
sets ? from different languages, as well as from 
different domains ? should help better understand 
the real qualities of the methods presented here.
5 Existing Parallel Treebanks
In this section we look at several attempts at the 
creation of parallel treebanks besides the Home-
Centre treebank presented earlier.
Closest to the material presented in this paper 
comes the parallel treebank presented in (Sam-
uelsson and Volk, 2006). This manually created 
treebank aligns three languages ? German, Eng-
lish and Swedish ? consisting of over 1000 sen-
tences from each language. The main difference 
compared to our method is that they allow many-
to-many lexical alignments and one-to-many non-
lexical alignments. The authors also allow unary 
productions in the trees, which, as stated in section 
2.1, does not provide any additional useful infor-
mation. Another difference is that they deepen the 
original German and Swedish trees before align-
ment, rather than preserve their original form.
A further attempt to align phrase-structure 
trees is presented in (Uibo et al, 2005). The 
authors develop a rule-based method for aligning 
Estonian and German sentences. The parallel 
treebank consist of over 500 sentences, but in the 
version presented only NPs are aligned.
In (Han et al, 2002) the authors claim to have built 
a Korean?English parallel treebank with over 5000 
phrase-structure tree pairs, but at the time of writing 
we were unable to find details about this treebank.
Although the Prague Czech?English Depend-
ency Treebank (PCEDT (mejrek et al, 2004)) can 
be used as a parallel treebank, it is not such per se. 
The authors do not use phrase-structure trees. In-
stead, tectogrammatical dependency structures are 
used (Hajiov?, 2000). Either a word alignment 
tool like GIZA++ or a probabilistic electronic dic-
tionary (supplied with the treebank) can be used to 
automatically align the dependency structures. The 
presented version contains over 21000 sentence 
pairs that can be aligned. Because of its nature, this 
treebank can only be used by MT systems that em-
ploy tectogrammatical dependency structures.
We are also aware of the existence of the LinES 
(Ahrenberg, 2007), CroCo (Hansen-Schirra et al, 
2006) and FuSe (Cyrus, 2006) parallel corpora. 
Although it seems possible to use them as parallel 
treebanks, they have been designed to serve as 
resources for the study of translational phenomena 
and it does not appear that they can be used effec-
tively for other natural language processing tasks.
An attempt to develop an automatic tree-to-
tree aligner is described in (Groves et al, 2004). 
The authors present a promising rule-based sys-
tem. Further testing, however, has shown that the 
rules are only applicable to a particular treebank 
and language pair. This means that the set of 
rules has to be adjusted for each particular case.
Thus, the methods presented in this paper are 
the only available ones that can be used to pro-
duce a sufficiently large parallel treebank appro-
priate for use by state-of-the-art statistical MT 
applications (eg. DOT (Hearne and Way, 2006)).6
6 Conclusions
We have presented a novel platform for the fast 
and robust automatic generation of parallel tree-
banks. The algorithms described are completely 
language-pair-independent and require a minimal 
number of resources; besides a parallel corpus, a 
word alignment tool is the only extra software 
required. If available, POS taggers or monolin-
gual phrase-structure parsers can be used to pre-
process the data. Certain extensions to the cur-
rent software are planned that will assure the op-
timal use of any available resources.
A series of evaluations have shown promising 
results. The quality of the automatically generated 
parallel treebanks is very high, even improving on 
a manually created treebank on certain metrics. 
We plan to carry out extensive large-scale testing 
on a range of language pairs, which we expect to 
corroborate the results reported in this paper. The 
planned improvements to the algorithms discussed 
in section 4 are expected to further increase the 
quality of the generated parallel treebanks.
Currently existing treebanks are small and re-
quire extensive human resources to be created and 
extended, which has limited their use for data-
oriented tasks. The platform presented in this pa-
per provides a means to circumvent these prob-
lems by allowing for the fast automatic genera-
tion of very large parallel treebanks with very little 
human effort, thus overcoming this hurdle for 
research in tree-based machine translation.
6 An alternative methodology is described in (Lavie et al, to appear), but this work was not available at the time of writing.
1111
Acknowledgements
We would like to thank Khalil Sima'an, Mary 
Hearne and John Tinsley for many insightful dis-
cussions. This work was generously supported by 
Science Foundation Ireland (grant no. 05/RF/
CMS064) and the Irish Centre for High-End 
Computing (http://www.ichec.ie).
References
Ahrenberg, Lars. 2007. LinES: An English-Swedish 
Parallel Treebank. In Proceedings of the 16th 
Nordic Conference of Computational Linguistics 
(NODALIDA ?07), pp. 270?274. Tartu, Estonia.
Banerjee, Satanjeev and Alon Lavie. 2005. 
METEOR: An Automatic Metric for MT 
Evaluation with Improved Correlation with 
Human Judgements. In Proceedings of the 
Workshop on Intrinsic and Extrinsic Evalua-
tion Measures for MT and/or Summarization 
at the 43rd Annual Meeting of the Association 
for Computational Linguistics (ACL ?05), 
pp. 65?72. Ann Arbor, MI.
mejrek, Martin, Jan Cu
?n, Ji
? Havelka, Jan 
Haji and Vladislav Kubo	. 2004. Prague 
Czech-English Dependency Treebank: Syntac-
tically Annotated Resources for Machine 
Translation. In Proceedings of the 4th Interna-
tional Conference on Language Resources and 
Evaluation (LREC?04). Lisbon, Portugal.
Cyrus, Lea. 2006. Building a resource for studying 
translation shifts. In Proceedings of the 5th Con-
ference of Language Resources and Evaluation 
(LREC ?06), pp.1240?1245. Genoa, Italy.
Doddington, George. 2002. Automatic Evaluation 
of Machine Translation Quality Using N-Gram 
Co-Occurrence Statistics. In Proceedings of the 
ARPA Workshop on Human Language Technol-
ogy, pp. 128?132. San-Diego, CA.
Groves, Declan, Mary Hearne and Andy Way. 
2004. Robust Sub-Sentential Alignment of 
Phrase-Structure Trees. In Proceedings of the 
20th International Conference on Computa-
tional Linguistics (CoLing?04), pp. 1072?1078. 
Geneva, Switzerland: COLING.
Hajiov?, Eva. 2000. Dependency-Based Underlying-
Structure Tagging of a Very Large Czech Corpus. 
TAL (Special Issue Grammaires de D?pendance / 
Dependency Grammars), 41 (1): 47?66.
Han, Chung-hye, Na-Rare Han, Eon-Suk Ko and 
Martha Palmer. 2002. Development and 
Evaluation of a Korean Treebank and its Appli-
cation to NLP. In Proceedings of the 3rd Inter-
national Conference on Language Resources 
and Evaluation (LREC  ?02), pp. 1635?1642. 
Las Palmas, Canary Islands, Spain.
Hansen-Schirra, Silvia, Stella Neumann and Mi-
haela Vela. 2006. Multi-dimensional Annota-
tion and Alignment in an English-German 
Translation Corpus. In Proceedings of the 
workshop on Multi-dimensional Markup in 
Natural Language Processing (NLPXML ?06), 
pp. 35?42. Trento, Italy.
Hearne, Mary and Andy Way. 2006. Disambigua-
tion Strategies for Data-Oriented Translation. 
In Proceedings of the 11th Conference of the 
European Association for Machine Translation 
(EAMT?06), pp. 59?68. Oslo, Norway.
Hearne, Mary, John Tinsley, Ventsislav Zhechev and 
Andy Way. 2007. Capturing Translational Diver-
gences with a Statistical Tree-to-Tree Aligner. In 
Proceedings of the 11th International Conference 
on Theoretical and Methodological Issues in Ma-
chine Translation (TMI ?07), pp. 85?94. Sk?vde, 
Sweden: Sk?vde University Studies in Informatics.
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Ber-
toldi, Brooke Cowan, Wade Shen, Christine Mo-
ran, Richard Zens, Chris Dyer, Ond
ej Bojar, Al-
exandra Constantin and Evan Herbst. 2007. 
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In Proceedings of the Demo 
and Poster Sessions of the 45th Annual Meeting of 
the Association for Computational Linguistics 
(ACL ?07), pp. 177?180. Prague, Czech Republic.
Lavie, Alon, Alok Parlikar and Vamshi Ambati. to 
appear. Syntax-driven Learning of Sub-sentential 
Translation Equivalents and Translation Rules 
from Parsed Parallel Corpora. In Proceedings of 
the 2nd Workshop on Syntax and Structure in Sta-
tistical Translation (SSST?08). Columbus, OH.
Nesson, Rebecca, Stuart M. Shieber and Alexander 
Rush. 2006. Induction of Probabilistic Synchro-
nous Tree-Insertion Grammars for Machine 
Translation. In Proceedings of the 7th Conference 
of the Association for Machine Translation in the 
Americas (AMTA?06), pp. 128?137. Boston, MA.
Och, Franz Josef and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment 
Models. Computational Linguistics, 29 (1): 19?51.
Papineni, Kishore, Salim Roukos, Todd Ward 
and Wei-Jing Zhu. 2002. BLEU: A Method for 
Automatic Evaluation of Machine Translation. 
In Proceedings of the 40th Annual Meeting of 
the Association of Computational Linguistics 
(ACL ?02), pp. 311?318. Philadelphia, PA.
Samuelsson, Yvonne and Martin Volk. 2006. 
Phrase Alignment in Parallel Treebanks. In 
Proceedings of the 5th Workshop on Treebanks 
and Linguistic Theories (TLT ?06), pp. 91?102. 
Prague, Czech Republic.
Samuelsson, Yvonne and Martin Volk. 2007. 
Alignment Tools for Parallel Treebanks. In 
Proceedings of the GLDV Fr?hjahrstaggung. 
T?bingen, Germany.
Uibo, Heli, Krista Liin and Martin Volk. 2005. Phrase 
alignment of Estonian-German parallel treebanks. 
Paper presented at Workshop ?Exploiting parallel 
corpora in up to 20 languages?, Arona, Italy.
1112
Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 43?51,
COLING 2010, Beijing, August 2010.
Seeding Statistical Machine Translation with Translation Memory 
Output through Tree-Based Structural Alignment
Ventsislav Zhechev Josef van Genabith
EuroMatrixPlus, CNGL
School of Computing, Dublin City University
EuroMatrixPlus, CNGL
School of Computing, Dublin City University
contact@VentsislavZhechev.eu josef@computing.dcu.ie
Abstract
With the steadily increasing demand for 
high-quality translation, the localisation 
industry is constantly searching for tech-
nologies that would increase translator 
throughput, with the current focus on the 
use of high-quality Statistical Machine 
Translation (SMT) as a supplement to the 
established Translation Memory (TM) 
technology. In this paper we present a 
novel modular approach that utilises 
state-of-the-art sub-tree alignment to pick 
out pre-translated segments from a TM 
match and seed with them an SMT sys-
tem to produce a final translation. We 
show that the presented system can out-
perform pure SMT when a good TM 
match is found. It can also be used in a 
Computer-Aided Translation (CAT) envi-
ronment to present almost perfect transla-
tions to the human user with markup 
highlighting the segments of the transla-
tion that need to be checked manually for 
correctness.
1. Introduction
As the world becomes increasingly intercon-
nected, the major trend is to try to deliver ideas 
and products to the widest audience possible. 
This requires the localisation of products for as 
many countries and cultures as possible, with 
translation being one of the main parts of the lo-
calisation process. Because of this, the amount of 
data that needs professional high-quality transla-
tion is continuing to increase well beyond the 
capacity of the world?s human translators.
Thus, current efforts in the localisation indus-
try are mostly directed at the reduction of the 
amount of data that needs to be translated from 
scratch by hand. Such efforts mainly include the 
use of Translation Memory (TM) systems, where 
earlier translations are stored in a database and 
offered as suggestions when new data needs to 
be translated. As TM systems were originally 
limited to providing translations only for (al-
most) exact matches of the new data, the integra-
tion of Machine Translation (MT) techniques is 
seen as the only feasible development that has 
the potential to significantly reduce the amount 
of manual translation required.
At the same time, the use of SMT is frowned 
upon by the users of CAT tools as they still do 
not trust the quality of the SMT output. There are 
two main reasons for that. First, currently there is 
no reliable way to automatically ascertain the 
quality of SMT-generated translations, so that the 
user could at a glance make a judgement as to the 
amount of effort that might be needed to post-
edit the suggested translation (Simard and Isa-
belle, 2009). Not having such automatic quality 
metrics also has the side effect of it being impos-
sible for a Translation-Services Provider (TSP) 
company to reliably determine in advance the 
increase in translator productivity due to the use 
of MT and to adjust their resources-allocation 
and cost models correspondingly.
The second major problem for users is that SMT-
generated translations are as a rule only obtained 
for cases where the TM system could not produce 
a good-enough translation (cf. Heyn, 1996). Given 
that the SMT system used is usually trained only 
on the data available in the TM, expectedly it also 
has few examples from which to construct the 
translation, thus producing low quality output.
43
In this paper, we combine a TM, SMT and an 
automatic Sub-Tree Alignment (STA) backends 
in a single integrated tool. When a new sentence 
that needs to be translated is supplied, first a 
Fuzzy-Match Score (FMS ? see Section 2.2) is 
obtained from the TM backend, together with the 
suggested matching sentence and its translation. 
For sentences that receive a reasonably high 
FMS, the STA backend is used to find the corre-
spondences between the input sentence and the 
TM-suggested translation, marking up the parts 
of the input that are correctly translated by the 
TM. The SMT backend is then employed to ob-
tain the final translation from the marked-up in-
put sentence. In this way we expect to achieve a 
better result compared to using pure SMT.
In Section 2, we present the technical details 
of the design of our system, together with moti-
vation for the particular design choices. Section 3 
details the experimental setup and the data set 
used for the evaluation results in Section 4. We 
present improvements that we plan to investigate 
in further work in Section 5, and provide con-
cluding remarks in Section 6.
2. System Framework
We present a system that uses a TM-match to 
pre-translate parts of the input sentence and 
guide an SMT system to the generation of a 
higher-quality translation.
2.1. Related Approaches
We are not aware of any published research 
where TM output is used to improve the per-
formance of an SMT system in a manner similar 
to the system presented in this paper.
Most closely related to our approach are the 
systems by Bi?ici and Dymetman (2008) and 
Simard and Isabelle (2009), where the authors 
use the TM output to extract new phrase pairs 
that supplement the SMT phrase table. Such an 
approach, however, does not guarantee that the 
SMT system will select the TM-motivated 
phrases even if a heavy bias is applied to them.
Another related system is presented in (Smith 
and Clark, 2009). Here the authors use a syntax-
based EBMT system to pre-translate and mark-
up parts of the input sentence and then supply 
this marked-up input to an SMT system. This 
differs to our system in two ways. First, Smith 
and Clark use EMBT techniques to obtain partial 
translations of the input from the complete ex-
ample base, while we are only looking at the best 
TM match for the given input. Second, the authors 
use dependency structures for EMBT matching, 
while we employ phrase-based structures.
2.2. Translation Memory Backend
Although the intention is to use a full-scale TM 
system as the translation memory backend, to 
have complete control over the process for this 
initial research we decided to build a simple pro-
totype TM backend ourselves.
We employ a database setup using the Post-
greSQL v.8.4.3
1
 relational database management 
(RDBM) system. The segment pairs from a given 
TM are stored in this database and assigned 
unique IDs for further reference. When a new 
sentence is supplied for translation, the database 
is searched for (near) matches, using an FMS 
based on normalised character-level Levenshtein 
edit distance (Levenshtein, 1965).
Thus for each input sentence, from the data-
base we obtain the matching segment with the 
highest FMS, its translation and the score itself.
2.3. Sub-Tree Alignment Backend
The system presented in this paper uses phrase-
based sub-tree structural alignment (Zhechev, 
2010) to discover parts of the input sentence that 
correspond to parts of the suggested translation 
extracted from the TM database. We chose this 
particular tool, because it can produce aligned 
phrase-based-tree pairs from unannotated (i.e. 
unparsed) data. It can also function fully auto-
matically without the need for any training data. 
The only auxiliary requirement it has is for a 
probabilistic dictionary for the languages that are 
being aligned. As described later in this section, 
in our case this is obtained automatically from the 
TM data during the training of the SMT backend.
The matching between the input sentence and 
the TM-suggested translation is done in a three-
step process. First, the plain TM match and its 
1
 http://www.postgresql.org/
44
translation are aligned, which produces a sub-
tree-aligned phrase-based tree pair with all non-
terminal nodes labelled ?X? (cf. Zhechev, 2010). 
As we are only interested in the relations be-
tween the lexical spans of the non-terminal 
nodes, we can safely ignore their labels. We call 
this first step of our algorithm bilingual alignment.
In the second step, called monolingual align-
ment, the phrase-based tree-annotated version of 
the TM match is aligned to the unannotated input 
sentence. The reuse of the tree structure for the 
TM match allows us to use it in the third step as 
an intermediary to establish the available sub-
tree alignments between the input sentence and 
the translation suggested from the TM.
During this final alignment, we identify 
matched and mismatched portions of the input 
sentence and their possible translations in the 
TM suggestion and, thus, this step is called 
matching. Additionally, the sub-tree alignments 
implicitly provide us with reordering informa-
tion, telling us where the portions of the input 
sentence that we translate should be positioned in 
the final translation.
The alignment process is exemplified in Figure 1. 
The tree marked ?I? corresponds to the input sen-
tence, the one marked ?M? to the TM match and 
the one marked ?T? to the TM translation. Due to 
space constraints, we only display the node ID 
numbers of the non-terminal nodes in the phrase-
structure trees???in reality all nodes carry the 
label ?X?. These IDs are used to identify the sub-
sentential alignment links. The lexical items cor-
responding to the leaves of the trees are pre-
sented in the table below the graph.
The alignment process can be visually repre-
sented as starting at a linked node in the I tree 
and following the link to the M tree. Then, if 
available, we follow the link to the T tree and 
this leads us to the T-tree node corresponding to 
the I-tree node we started from. In Figure 1, this 
results in the I?T alignments I1?T18, I2?T2, I3?
T1, I4?T32 and I6?T34. The first three links are 
matches, because the lexical items covered by 
the I nodes correspond exactly to the lexical 
items covered by their M node counterparts. 
Such alignments provide us with direct TM 
translations for our input. The last two links in 
the group are mismatched, because there is no 
lexical correspondence between the I and M 
nodes (node I4  corresponds to the phrase sender 
email, while the linked node M10  corresponds to 
sender ?s email). Such alignments can only be 
used to infer reordering information. In particular 
in this case, we can infer that the target word or-
der for the input sentence is address email 
sender, which produces the translation adresse 
?lectronique de l? exp?diteur.
15
13
10 4
6 3
1 2
5
36
34 8
1 32
2 24 7
18 6
3 4 5
6
4
1 2
3
T
I
M
I
input
M
match
T
trans-
lation
1 2 3
sender email address
1 2 3 4 5
sender ?s email address .
1 2 3 4 5 6 7 8
adresse
?lectro-
nique
de l?
exp?-
diteur
du
mes-
sage
.
Figure 1. Example of sub-tree alignment between 
an input sentence, TM match and TM translation
We decided to use sub-tree-based alignment, 
rather than plain word alignment (e.g. GIZA++ ? 
Och and Ney, 2003), due to a number of factors. 
First, sub-tree-based alignment provides much 
better handling of long-distance reorderings, 
while word? and phrase-based alignment models 
always have a fixed limit on reordering distance 
that tends to be relatively low to allow efficient 
computation.
The alignments produced by a sub-tree align-
ment model are also precision-oriented, rather 
than recall-oriented (cf. Tinsley, 2010). This is 
important in our case, where we want to only 
extract those parts of the translation suggested by 
the TM for which we are most certain that they 
are good translations.
45
As stated earlier, the only resource necessary 
for the operation of this system is a probabilistic 
bilingual dictionary covering the data that needs 
to be aligned. For the bilingual alignment step, 
such a bilingual dictionary is produced as a by-
product of the training of the SMT backend and 
therefore available. For the monolingual align-
ment step, the required probabilistic dictionary is 
generated by simply listing each unique token 
seen in the source-language data in the TM as 
translating only as itself with probability 1.
2.4. Statistical Machine Translation Backend
Once the matching  step is completed, we have 
identified and marked-up the parts of the input 
sentence for which translations will be extracted 
from the TM suggestions, as well as the parts 
that need to be translated from scratch. The 
lengths of the non-translated segments vary de-
pending on the FMS, but are in general relatively 
short (one to three tokens).
The further processing of the input relies on a 
specific feature of the SMT backend we use, 
namely the Moses system (Koehn et al, 2007). 
We decided to use this particular system as it is 
the most widely adopted open-source SMT sys-
tem, both for academic and commercial pur-
poses. In this approach, we annotate the seg-
ments of the input sentence for which transla-
tions have been found from the TM suggestion 
using XML tags with the translation correspond-
ing to each segment given as an attribute to the 
encapsulating XML tag, similarly to the system 
described in (Smith and Clark, 2009). The SMT 
backend is supplied with marked-up input in the 
form of a string consisting of the concatenation 
of the XML-enclosed translated segments and 
the plain non-translated segments in the target-
language word order, as established by the 
alignment process. The SMT backend is in-
structed to translate this input, while keeping the 
translations supplied via the XML annotation. 
This allows the SMT backend to produce transla-
tions informed by and conforming to actual ex-
amples from the TM, which should result in im-
provements in translation quality.
2.5. Auxilliary Tools
It must be noted that in general the SMT backend 
sees the data it needs to translate in the target-
language word order (e.g. it is asked to translate 
an English sentence that has French word order). 
This, however, does not correspond to the data 
found in the TM, which we use for deriving the 
SMT models. Because of this discrepancy, we 
developed a pre-processing tool that goes over 
the TM data performing bilingual alignment and 
outputting reordered versions of the sentences it 
processes by using the information implicitly 
encoded in the sub-tree alignments. In this way 
we obtain the necessary reordered data to train a 
translation model where the source language al-
ready has the target-language word order. In our 
system we than use this model???together with 
the proper-word-order model???for translation.
One specific aspect of real-world TM data that 
we need to deal with is that they often contain 
meta-tag annotations of various sorts. Namely, 
annotation tags specific to the file format used for 
storing the TM data, XML tags annotating parts 
of the text as appearing in Graphical User Inter-
face (GUI) elements, formatting tags specific to 
the file format the TM data was originally taken 
from, e.g. RTF, OpenDoc, etc. Letting any MT 
system try to deal with these tags in a probabilis-
tic manner can easily result in ill-formed, mis-
translated and/or out-of-order meta-tags in the 
translation.
This motivates the implementation of a rudi-
mentary handling of meta-tags in the system pre-
sented in this paper, in particular handling the 
XML tags found in the TM data we work with, 
as described in Section 3. The tool we developed 
for this purpose simply builds a map of all 
unique XML tags per language and replaces 
them in the data with short placeholders that are 
designed in such a way that they would not inter-
fere with the rest of the TM data.
2
 A special case 
that the tool has to take care of is when an XML 
tag contains an attribute whose value needs to be 
translated. In such situations, we decided to not 
perform any processing, but rather leave the 
XML tag as is, so that all text may be translated 
as needed. A complete treatment of meta-tags, 
however, is beyond the scope of the current paper.
2
 In the current implementation, the XML tags are replaced with the string ?<tag_id>?, where <tag_id> is a unique nu-
meric identifier for the XML tag that is being replaced.
46
We also had to build a dedicated tokeniser/de-
tokeniser pair to handle real world TM data con-
taining meta-tags, e-mail addresses, file paths, 
etc., as described in Section 3. Both tools are 
implemented as a cascade of regular expression 
substitutions in Perl.
Finally, we use a tool to extract the textual 
data from the TM. That is, we strip all tags spe-
cific to the format in which the TM is stored, as 
they can in general be recreated and thus do not 
need to be present during translation. In our par-
ticular case the TM is stored in the XML-based 
TMX format.
3
2.6. Complete Workflow
Besides the components described above, we 
also performed two further transformations on 
the data. First, we lowercase the TM data before 
using it to train the SMT backend models. This 
also means that the alignment steps from Section 
2.3 are performed on lowercased data, as the bi-
lingual dictionary used there is obtained during 
the SMT training process.
4
Additionally, the SMT and sub-tree alignment 
systems that we use cannot handle certain char-
acters, which we need to mask in the data. For 
the SMT backend, this includes ?|?, ?<? and ?>? 
and for the sub-tree aligner, ?(? and ?)?. The rea-
son these characters cannot be handled is that the 
SMT system uses ?|? internally to separate data 
fields in the trained models and ?<? and ?>? can-
not be handled whilst using XML tags to anno-
tate pre-translated portions of the input. The sub-
tree aligner uses ?(? and ?)? to represent the 
phrase-based tree structures it generates and the 
presence of these characters in the data may cre-
ate ambiguity when parsing the tree structures. 
All these characters are masked by substituting 
in high-Unicode counterparts, namely ???, ???, 
???, ??? and ???. Visually, there is a very slight 
distinction and this is intentionally so to simplify 
debugging. However, the fact that the character 
codes are different alleviates the problems dis-
cussed above. Of course, in the final output, the 
masking is reversed and the translation contains 
the regular versions of the characters.
Extract Textual Data 
from TMX Format
TMX Data
Meta-Tag Handling
Tokenisation and 
Masking of Special 
Characters
Start
Lowercasing
Generation of Probabilistic 
Dictionary for 
Monolingual Alignment
Language-Model 
Training and 
Binarisation
Automatic 
Word-Alignment
SMT Model 
Training and 
Binarisation
Language Models
Probabilistic Dictionary 
for Monolingual 
Alignment
Probabilistic Dictionary 
for Bilingual Alignment
SMT Model with
Normal Word Order
Generation of 
Bilingual Parallel 
Treebank
Bilingual Parallel 
Treebank
TM 
Database
Reorder Source-
Language Data
Normal 
Word Order
Reordered Source-
Language Data
Automatic 
Word-Alignment
SMT Model 
Training and 
Binarisation
SMT Model with
Target Word Order
Stop
T
a
r
g
e
t
 
W
o
r
d
 
O
r
d
e
r
Sub-Tree Alignment 
Input Data
Meta-Tag 
Substitution Maps
Figure 2. Pre-Processing Workflow
The complete pre-processing workflow is pre-
sented in Figure 2, where the rectangles with ver-
tical bars represent the use of open-source tools, 
while the plain rectangles represent tools devel-
oped by the authors of this paper.
First, the textual data is extracted from the 
original TM format, producing one plain-text file 
for each language side. These data can either be 
pre-loaded in a PostgreSQL database at this time, 
or during the first run of the translation system.
Next, the meta-tag-handling tool is used to 
generate the substitution tables for the source and 
target languages, as well as new files for each 
language with the tags substituted by the corre-
sponding identifiers (cf. Section 2.5). These files 
are then tokenised, lowercased and all conflicting 
characters are masked, as described above.
The pre-processed files are then used to pro-
duce a file containing pairs of sentences in the 
input format of the sub-tree aligner, as well as to 
generate the probabilistic dictionary required for 
3
 http://www.lisa.org/fileadmin/standards/tmx1.4/tmx.htm
4
 Currently, we do not use a recaser tool and the translations produced are always in lowercase. This component, however, 
will be added in a future version of the system.
47
the monolingual alignment and to train the SMT 
model on the data in the proper word order. The 
SMT training produces the necessary bilingual 
dictionary for use by the sub-tree aligner, which 
is run to obtain a parallel-treebank version of the 
TM data. The parallel treebank is then used to 
retrieve bilingual alignments for the TM data, 
rather than generate them on the fly during trans-
lation. This is an important design decision, as 
the complexity of the alignment algorithm is high 
for plain-text alignment (cf. Zhechev, 2010).
Once we have generated the bilingual parallel 
treebank, we run the reordering tool, which gen-
erates a new plain-text file for the source lan-
guage, where the sentences are modified to con-
form to the target-language word order, as im-
plied by the data in the parallel treebank. This is 
then matched with the proper-order target-
language file to train the SMT backend for the 
actual use in the translation process.
SMT Model with
Normal Word Order
SMT Backend
(normal word order)
SMT Backend
(both word orders)
TM 
Database
Find TM Match with 
Highest FMS
Meta-Tag Handling, 
Tokenisation and 
Masking of Special 
Characters for I, M, T
Bilingual Parallel 
Treebank
Extract Bilingual 
Alignment for M, T
Generate Mono-
lingual Alignment
for M, I
Output T
(tm)
Perform Alignment 
Matching
xml Approach
Output 
Translation
(xml)
SMT Model with
Target Word Order
Output 
Translation
(direct)
FMS >= 50
Probabilistic Dictionary 
for Monolingual 
Alignment
Read Input 
Sentence
Meta-Tag Handling, 
Detokenisation and 
Unmasking of Special 
Characters for Output
yes
no
Language Models
Meta-Tag 
Substitution Maps
 
Figure 3. Translation Workflow
Once all the necessary files have been gener-
ated and all pre-processing steps have been com-
pleted, the system is ready for use for translation. 
The translation workflow is shown in Figure 3, 
?I?, ?M? and ?T? having the same meanings as in 
Figure 1. Here, the first step after an input sen-
tence has been read in is to find the TM match 
with the highest FMS. This is done using the 
original plain non-pre-processed data to simulate 
real-life operation with a proper TM backend.
After the best TM match and its translation are 
extracted from the TM, they???together with the 
input sentence???are pre-processed by tokenisa-
tion, lowercasing, meta-tag and special-character 
substitution. Next, the corresponding tree pair is 
extracted from the bilingual parallel treebank to 
establish the tree structure for the TM source-
language match. This tree structure is then used 
to perform the monolingual alignment, which 
allows us to perform the matching step next. Af-
ter the matching is complete, we generate a final 
translation as described in Section 2.4. Finally, 
the translations are de-tokenised and the XML 
tags and special characters are unmasked.
3. Experimental Setup
We use real-life TM data from an industrial part-
ner. The TM was generated during the translation 
of RTF-formatted customer support documenta-
tion. The data is in TMX format and originally 
contains 108 ? 967 English?French translation 
segments, out of which 14 segments either have 
an empty language side or have an extreme dis-
crepancy in the number of tokens for each lan-
guage side and were therefore discarded.
A particular real-life trait of the data is the 
presence of a large number of XML tags. Run-
ning the tag-mapping tool described in Section 
2.6, we gathered 2?049 distinct tags for the Eng-
lish side of the data and 2 ?653 for the French 
side. Still, there were certain XML tags that in-
cluded a label argument whose value was trans-
lated from one language to the other. These XML 
tags were left intact so that our system could 
handle the translation correctly.
The TM data also contain a large number of 
file paths, e-mail addresses, URLs and others, 
which makes bespoke tokenisation of the data 
necessary. Our tokenisation tool ensures that 
none of these elements are tokenised, keeps RTF 
formatting sequences non-tokenised and properly 
handles non-masked XML tags, minimising their 
fragmentation.
As translation segments rarely occur more than 
once in a TM, we observe a high number of unique 
tokens (measured after pre-processing)???41?379 
for English and 49 ? 971 for French???out of 
48
108 ?953 segment pairs. The average sentence 
length is 13.2 for English and 15.0 for French.
For evaluation, we use a data set of 4977 Eng-
lish?French segments from the domain of the 
TM. The sentences in the test set are significantly 
shorter on average, compared to the TM???9.2 
tokens for English and 10.9 for French.
It must be noted that we used SMT models 
with maximum phrase length of 3 tokens, rather 
than the standard 5 tokens, and for decoding we 
used a 3-gram language model. This results in 
much smaller models than the ones usually used 
in mainstream SMT applications. (The standard 
for some tools goes as far as 7-token phase-
length limit and 7-gram language models)
4. Evaluation Results
For the evaluation of our system, we used a 
number of widely accepted automatic metrics, 
namely BLEU (Papineni et al, 2002), METEOR 
(Banerjee and Lavie, 2005), TER (Snover et al, 
2006) and inverse F-Score based on token-level 
precision and recall.
We setup our system to only fully process in-
put sentences for which a TM match with an 
FMS over 50% was found, although all sen-
tences were translated directly using the SMT 
backend to check the overall pure SMT perform-
ance. The TM-suggested translations were also 
output for all input sentences.
The results of the evaluation are given in Fig-
ure 4, where the tm and direct scores are also 
given for the FMS range [0%; 50%)?{100%}. 
Across all metrics we see a uniform drop in the 
quality of TM-suggested translations, which is 
what we expected, given that these translations 
contain one or more wrong words. We believe 
that the relatively high scores recorded for the 
TM-suggested translations at the high end of the 
FMS scale are a result of the otherwise perfect 
word order and lexical choice. For n-gram-
match-based metrics like the ones we used such a 
result is expected and predictable. Although the 
inverse F-score results show the potential of our 
setup to translate the outstanding tokens in a 
90%?100% TM match, it appears that the SMT 
system produces word order that does not corre-
spond to the reference translation and because of 
this receives lower scores on the other metrics.
The unexpected drop in scores for perfect TM 
matches is due to discrepancies between the ref-
erence translations in our test set and the transla-
tions stored in the TM. We believe that this issue 
Figure 4. Evaluation results for English-to-French translation, broken down by FMS range
      0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/165
   
0,1
0,2
0,3
0,4
0,5
0,6
0,7
0,8
FMS Range/Segments
BLEU
tm
direct
xml
      0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/165
   
   
0,3
0,4
0,5
0,6
0,7
0,8
0,9
FMS Range/Segments
ME
TE
OR
xml
direct
tm
      0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/165
   
0,1
0,2
0,3
0,4
0,5
0,6
0,7
0,8
0,9
FMS Range/Segments
TER
xml
direct
tm
      0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/165
   
   
0,2
0,3
0,4
0,5
0,6
0,7
FMS Range/Segments
Inv
ers
e F
-Sc
ore
tm
direct
xml
49
affects all FMS ranges, albeit to a lower extent 
for non-perfect matches. Unfortunately, the exact 
impact cannot be ascertained without human 
evaluation.
We observe a significant drop-off in translation 
quality for the direct output below FMS 50%. 
This suggests that sentences with such low FMS 
should be translated either by a human translator 
from scratch, or by an SMT system trained on 
different/more data.
Our system (i.e. the xml setup) clearly outper-
forms the direct SMT translation for FMS be-
tween 80 and 100 and has comparable perform-
ance between FMS 70 and 80. Below FMS 70, 
the SMT backend has the best performance. Al-
though these results are positive, we still need to 
investigate why our system has poor perform-
ance at lower FMS ranges. Theoretically, it 
should outperform the SMT backend across all 
ranges, as its output is generated by supplying 
the SMT backend with good pre-translated frag-
ments. The Inverse F-Score graph suggest that 
this is due to worse lexical choice, but only man-
ual evaluation can provide us with clues for solv-
ing the issue.
The discrepancy in the results in the Inverse F-
Score graph with the other metrics suggest that 
the biggest problem for our system is producing 
output in the expected word-order.
5. Future Work
There are a number of possible directions for 
improvement that can be explored.
As mentioned earlier, we plan to integrate our 
system with a full-featured open-source or com-
mercial TM product that will supply the TM 
matches and translations. We expect this to im-
prove our results, as the quality of the TM matches 
will better correspond to the reported FMS.
Such an integration will also be the first neces-
sary step to perform a user study evaluating the 
effect of the use of our system on post-editing 
speeds. We expect the findings of such a study to 
show a significant increase of throughput that 
will significantly reduce the costs of translation 
for large-scale projects.
It would be interesting to also conduct a user 
study where our system is used to additionally 
mark up the segments that need to be edited in 
the final SMT translation. We expect this to pro-
vide additional speedup to the post-editing proc-
ess. Such a study will require tight integration 
between our system and a CAT tool and the 
modular design we presented will facilitate this 
significantly.
The proposed treatment of meta-tags is cur-
rently very rudimentary and may be extended 
with additional features and to handle additional 
types of tags. The design of our system currently 
allows the meta-tag-handling tool to be devel-
oped independently, thus giving the user the 
choice of using a different meta-tag tool for each 
type of data they work with.
In addition, the reordering tool needs to be 
developed further, with emphasis on properly 
handling situations where the appropriate posi-
tion of an input-sentence segment cannot be re-
liably established. In general, further research is 
needed into the reordering errors introduced by 
the SMT system into otherwise good translations.
6. Conclusions
In this paper, we presented a novel modular ap-
proach to the utilisation of Translation Memory 
data to improve the quality of Statistical Machine 
Translation.
The system we developed uses precise sub-
tree-based alignments to reliably determine and 
mark up correspondences between an input sen-
tence and a TM-suggested translation, which en-
sures the utilisation of the high-quality transla-
tion data stored in the TM database. An SMT 
backend then translates the marked-up input sen-
tence to produce a final translation with im-
proved quality.
Our evaluation shows that the system pre-
sented in this paper significantly improves the 
quality of SMT output when using TM matches 
with FMS above 80 and produces results on par 
with the pure SMT output for SMT between 70 
and 80. TM matches with FMS under 70 seem to 
provide insufficient reordering information and 
too few matches to improve on the SMT output. 
Still, further investigation is needed to properly 
diagnose the drop in quality for FMS below 70.
We expect further improvements to the reor-
dering functionality of our system to result in 
higher-quality output even for lower FMS ranges.
50
Acknowledgements
This research is funded under the 7
th
 Framework 
Programme of the European Commission within 
the EuroMatrixPlus project (grant ? 231720). 
The data used for evaluation was generously pro-
vided by Symantec Ireland.
References
Banerjee, Satanjeev and Alon Lavie. 2005. METEOR: 
An Automatic Metric for MT Evaluation with 
Improved Correlation with Human Judgements.
In Proceedings of the Workshop on Intrinsic and 
Extrinsic Evaluation Measures for MT and/or 
Summarization at the 43rd Annual Meeting of the 
Association for Computational Linguistics
(ACL ?05), pp. 65?72. Ann Arbor, MI.
Bi?ici, Ergun and Marc Dymetman. 2008. Dynamic 
Translation Memory: Using Statistical Machine 
Translation to improve Translation Memory Fuzzy 
Matches. In Proceedings of the 9th International 
Conference on Intelligent Text Processing and 
Computational Linguistics (CICLing??08),
ed. Alexander F. Gelbukh, pp. 454?465. Vol. 4919 
of Lecture Notes in Computer Science. Haifa, 
Israel: Springer Verlag.
Heyn, Matthias. 1996. Integrating Machine 
Translation into Translation Memory Systems.
In Proceedings of the EAMT Machine Translation 
Workshop, TKE??96, pp. 113?126. Vienna, Austria.
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola 
Bertoldi, Brooke Cowan, Wade Shen, Christine 
Moran, Richard Zens, Chris Dyer, Ond?ej Bojar, 
Alexandra Constantin and Evan Herbst. 2007. 
Moses: Open Source Toolkit for Statistical 
Machine Translation. In Proceedings of the Demo 
and Poster Sessions of the 45th Annual Meeting of 
the Association for Computational Linguistics 
(ACL ?07), pp. 177?180. Prague, Czech Republic.
Levenshtein, Vladimir I. 1965. ???????? ???? ? 
???????????? ?????????, ??????? ? ????????? 
???????? (Binary Codes Capable of Correcting 
Deletions, Insertions, and Reversals). ??????? 
???????? ???? ????, 163 (4): 845?848. 
[reprinted in: Soviet Physics Doklady, 10: 707?710.].
Och, Franz Josef and Hermann Ney. 2003.
A Systematic Comparison of Various Statistical 
Alignment Models. Computational Linguistics,
29 (1): 19?51.
Papineni, Kishore, Salim Roukos, Todd Ward and 
Wei-Jing Zhu. 2002. BLEU: A Method for 
Automatic Evaluation of Machine Translation.
In Proceedings of the 40th Annual Meeting of the 
Association of Computational Linguistics 
(ACL??02), pp. 311?318. Philadelphia, PA.
Simard, Michel and Pierre Isabelle. 2009. Phrase-
based Machine Translation in a Computer-assisted 
Translation Environment. In The Twelfth Machine 
Translation Summit (MT Summit XII), pp. 120?127. 
Ottawa, ON, Canada.
Smith, James and Stephen Clark. 2009. EBMT for 
SMT: A New EBMT?SMT Hybrid. In Proceedings 
of the 3rd International Workshop on Example-
Based Machine Translation (EBMT??09),
eds. Mikel L. Forcada and Andy Way, pp. 3?10.
Dublin, Ireland.
Snover, Matthew, Bonnie J. Dorr, Richard Schwartz, 
Linnea Micciulla and John Makhoul. 2006.
A Study of Translation Edit Rate with Targeted 
Human Annotation. In Proceedings of the
7th Conference of the Association for Machine 
Translation in the Americas (AMTA??06),
pp. 223?231. Cambridge, MA.
Tinsley, John. 2010. Resourcing Machine Translation 
with Parallel Treebanks. School of Computing, 
Dublin City Univercity: PhD Thesis. Dublin, Ireland.
Zhechev, Ventsislav. 2010. Automatic Generation of 
Parallel Treebanks. An Efficient Unsupervised 
System: Lambert Academic Publishing.
51
