Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 203?212, Dublin, Ireland, August 23-29 2014.
Time-aware Personalized Hashtag Recommendation on Social Media
Qi Zhang, Yeyun Gong, Xuyang Sun, Xuanjing Huang
Shanghai Key Laboratory of Intelligent Information Processing
School of Computer Science, Fudan University
825 Zhangheng Road, Shanghai, P.R.China
{qz, 12110240006, 13210240106, xjhuang}@fudan.edu.cn
Abstract
The task of recommending hashtags for microblogs has been received considerable attention in
recent years, and many applications can reap enormous benefits from it. Various approaches have
been proposed to study the problem from different aspects. However, the impacts of temporal and
personal factors have rarely been considered in the existing methods. In this paper, we propose a
novel method that extends the translation based model and incorporates the temporal and personal
factors. To overcome the limitation of only being able to recommend hashtags that exist in the
training data of the existing methods, the proposed method also incorporates extraction strategies
into it. The results of experiments on the data collected from real world microblogging services
by crawling demonstrate that the proposed method outperforms state-of-the-art methods that do
not consider these aspects. The relative improvement of the proposed method over the method
without considering these aspects is around 47.8% in F1-score.
1 Introduction
Over the past few years, social media services have become one of the most important communication
channels for people. According to the statistic reported by the Pew Research Center?s Internet &
American Life Project in Aug 5, 2013, about 72% of adult internet users are also members of at least
one social networking site. Hence, microblogs have also been widely used as data sources for public
opinion analyses (Bermingham and Smeaton, 2010; Jiang et al., 2011), prediction (Asur and Huberman,
2010; Bollen et al., 2011), reputation management (Pang and Lee, 2008; Otsuka et al., 2012), and many
other applications (Sakaki et al., 2010; Becker et al., 2010; Guy et al., 2010; Guy et al., 2013). In
addition to the limited number of characters in the content, microblogs also contain a form of metadata
tag (hashtag), which is a string of characters preceded by the symbol (#). Hashtags are used to mark the
keywords or topics of a microblog. They can occur anywhere in a microblog, at the beginning, middle, or
end. Hashtags have been proven to be useful for many applications, including microblog retrieval (Efron,
2010), query expansion (A.Bandyopadhyay et al., 2011), sentiment analysis (Davidov et al., 2010; Wang
et al., 2011). However, only a few microblogs contain hashtags provided by their authors. Hence, the
task of recommending hashtags for microblogs has become an important research topic and has received
considerable attention in recent years.
Existing works have studied discriminative models (Ohkura et al., 2006; Heymann et al., 2008) and
generative models (Krestel et al., 2009; Blei and Jordan, 2003; Ding et al., 2013) based on textual
information from a single microblog. However, from a dataset containing 282.2 million microblogs
crawled from Sina Weibo
1
, we observe that different users may have different perspectives when picking
hashtags, and the perspectives of users are impacted by their own interests or the global topic trend.
Meanwhile,the global topic distribution is likely to change over time. To better understand how the
topics vary over time, we aggregate the microblog posts published in a month as a document. Then, we
use a Latent Dirichlet Allocation (LDA) to estimate their topics. Figure 1 illustrates an example, where
ten active topics are selected. We can observe that the topics distribution varies greatly over time.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
http://www.weibo.com. It is one of the most popular microblog services in China.
203
2012-04 2012-06 2012-08 2012-10 2012-12 2013-02 2013-04
0
200
400
600
800
1000
1200
pay 
official 
staff 
support 
ministry 
statistics 
tomorrow
reproduce 
research
financial 
network 
Japanese 
culture 
together 
yourself life
incentive street
Pisces AriesLeo Horoscope
Pluto
iphoneAppledesign
food 
water
Taurus
Venus
charges
 life
universities 
education
husband
  own
  women
  home
  
successson like
saint 
sunday
employees
film 
loyalty husbandchildren
parent
happyness
like
egg  pumpkin
Figure 1: An example of the topics of retweets in each month. Each colored stripe represents a topic,
whose height is the number of words assigned to the topic. For each topic, the top words of this topic in
each month are placed on the stripe.
Motivated by the methods proposed to handle the vocabulary gap problem for keyphrase extrac-
tion (Liu et al., 2012) and hashtag suggestion (Ding et al., 2013), in this work, we also assume that
the hashtags and textual content in a microblog are parallel descriptions of the same thing in different
languages. To model the document themes, in this paper, we adopt the topical translation model to
facilitate the translation process. Topic-specific word triggers are used to bridge the gap between the
words and hashtags. Since existing topical translation models can only recommend hashtags learned
from the training data, we also incorporate an extraction process into the model.
This work makes three main contributions. First, we incorporate temporal and personal factors into
considerations. Most of the existing works on hashtag recommendation tasks have focused on textual
information. Second, we adopt a topical translation model to combine extraction and translation methods.
This makes it possible to suggest hashtags that are not included in the training data. Third, to evaluate
the task, we construct a large collection of microblogs from a real microblogging service. All of the
microblogs in the collection contain textual content and hashtags labeled by their authors. This can
benefit other researchers investigating the same task or other topics using author-centered data.
The remaining part of this paper is structured as follows: We briefly review existing methods in
related domains in Section 2. Section 3 gives an overview of the proposed generation model. Section
4 introduces the dataset construction, experimental results and analyses. In Section 5, we will conclude
the paper.
2 Related Works
Due to the usefulness of tag recommendation, many methods have been proposed from different
perspectives (Heymann et al., 2008; Krestel et al., 2009; Rendle et al., 2009; Liu et al., 2012; Ding et al.,
2013). Heymann et al. (Heymann et al., 2008) investigated the tag recommendation problem using the
data collected from social bookmarking system. They introduced an entropy-based metric to capture the
generality of a particular tag. In (Song et al., 2008), a Poisson Mixture Model based method is introduced
to achieve the tag recommendation task. Krestel et al. (Krestel et al., 2009) introduced a Latent Dirichlet
Allocation to elicit a shared topical structure from the collaborative tagging effort of multiple users for
recommending tags. Based on the the observation that similar webpages tend to have the same tags, Lu et
al. proposed a method taking both tag information and page content into account to achieve the task (Lu
et al., 2009). Ding et al. proposed to use translation process to model this task (Ding et al., 2013). They
extended the translation based method and introduced a topic-specific translation model to process the
various meanings of words in different topics. In (Tariq et al., 2013), discriminative-term-weights were
used to establish topic-term relationships, of which users? perception were learned to suggest suitable
hashtags for users. To handle the vocabulary problem in keyphrase extraction task, Liu et al. proposed a
204
topical word trigger model, which treated the keyphrase extraction problem as a translation process with
latent topics (Liu et al., 2012).
Most of the works mentioned above are based on textual information. Besides these methods,
personalized methods for different recommendation tasks have also been paid lots of attentions (Liang
et al., 2007; Shepitsen et al., 2008; Garg and Weber, 2008; Li et al., 2010; Liang et al., 2010; Rendle and
Schmidt-Thieme, 2010). Shepitsen et al. (2008) proposed to use hierarchical agglomerative clustering
to take into account personalized navigation context in cluster selection. In (Garg and Weber, 2008),
the problem of personalized, interactive tag recommendation was also studied based on the statics of the
tags co-occurrence. Liang et al. (2010) proposed to the multiple relationships among users, items and
tags to find the semantic meaning of each tag for each user individually and used this information for
personalized item recommendation.
From the brief descriptions given above, we can observe that most of the previous works on hashtag
suggestion focused on textual information. In this work, we propose to incorporate temporal and personal
information into the generative methods. Further more, to over the limitation that translation based
method can only recommend hashtags learned from the training data, we also propose to incorporate an
extraction process into the model.
3 The Proposed Methods
In this section, we firstly introduce the notation and generation process of the proposed method. Then,
we describe the method used for learning parameters. Finally, we present the methods of how do we
apply the learned model to achieve the hashtag recommendation task.
3.1 The Generation Process
We use D to represent the number of microblogs in the given corpus, and the microblogs have been
divided into T epoches. Let t = 1, 2, ..., T be the index of an epoches, ?
t
is the topic distribution of the
epoch t. Each microblog is generated by a user u
i
, where u
i
is an index between 1 and U , and U is the
total number of users. A microblog is a sequence of N
d
words denoted by w
d
= {w
d1
, w
d2
, ..., w
dN
d
}.
Each microblog contains a set of hashtags denoted by h
d
= {h
d1
, h
d2
, ..., h
dM
d
}. A word is defined as
an item from a vocabulary with W distinct words indexed by w = {w
1
, w
2
, ..., w
W
}. Each hashtag is
from the vocabulary with V distinct hashtags indexed by h = {h
1
, h
2
, ..., h
V
}. The notations in this
paper are summarized in Table 1.
The original LDA assumes that a document is contains a mixture of topics, which is represented by a
topic distribution, and each word has a hidden topic label. Although, it is sensible for long document,
due to the limitations of the length of characters in a single microblog, it tends to be about a single topic.
Hence, we associate a single hidden variable with each microblog to indicate its topic. Similar idea of
assigning a single topic to a short sequence of words has also been used for modeling Twitters (Zhao et
al., 2011)
The hashtag recommendation task is to discover a list of hashtags for each unlabeled microblog, In
our method, we first learn a topical translation model, and then we estimate the latent variables for each
microblog, finaly recommending hashtags accord to the learned model.
Fig. 2 shows the graphical representation of the generation process. The generative story for each
microblog is as follows:
3.2 Learning
To learn the parameters of our model, we use collapsed Gibbs sampling (Griffiths and Steyvers, 2004) to
sample the topics assignment z, latent variables assignment x and y.
Given the current state of all but the variable x
d
and z
d
for the dth microblog, we can jointly sample
205
1. Draw pi ? Beta(?), ? ? Beta(?)
2. Draw background word distribution ?
B
? Dirichlet(?
w
)
3. Draw global trendy topic distribution ?
t
? Dirichlet(?) for each time epoch t = 1, 2, ..., T
4. Draw personal topic distribution ?
u
? Dirichlet(?) for each user u = 1, 2, ..., U
5. Draw word distribution ?
z
? Dirichlet(?
w
) for each topic z = 1, 2, ...,K
6. Draw hashtag distribution ?
z,w
? Dirichilet(?
h
) for each topic z = 1, 2, ...,K and each word
w = 1, 2, ...,W
7. For each microblog d = 1, 2, ..., D
a. Draw x
d
? Bernoulli(?)
b. If x
d
= 0 then
Draw a topic z
d
?Multinomial(?
u
)
End if
If x
d
= 1 then
Draw a topic z
d
?Multinomial(?
t
)
End if
c. For each word n = 1, ..., N
d
i. Draw y
dn
? Bernoulli(pi)
ii. If y
dn
= 0 then
Draw a word w
dn
?Multinomial(?
B
)
End if
If y
dn
= 1 then
Draw a word w
dn
?Multinomial(?
z
d
)
End if
d. For each hashtag m = 1, ...,M
d
i. Draw h
dm
? P (h
dm
|w
d
, z
d
, ?
z
d
,w
d
)
w
dn
z
d
?
t
?
u
t
d
u
d
x
d
?
?
? ?
h
dm
y
dn
pi
?
?
z
?
B
?
w
?
w
?
z,w
?
h
T
M
d
N
d
D
K
U
W
K
Figure 2: The graphical representation of the proposed model. Shaded circles are observations or
constants. Unshaded ones are hidden variables.
206
Table 1: The notations used in this work.
D The number of training data set
W The number of unique word in the corpus
V The number of unique hashtag in the corpus
K The number of topics
T The total number of time epoches
U The total number of users
N
d
The number of words in the dth microblog
M
d
The number of hashtags in the dth microblog
z
d
The topic of the dth microblog
x
d
The latent variable decided the distribution category of z
d
y
dn
The latent variable decided the distribution category of w
dn
pi The distribution of latent variable y
dn
? The distribution of latent variable x
d
?
z
The distribution of topic words
?
B
The distribution of background words
?
t
The distribution of topics for time epoch t
?
u
The distribution of topics for user u
t
d
The time epoch for microblog d
u
d
The user of the microblog d
? The topic-specific word alignment table between word and hashtag or itself
x
d
and z
d
, the conditional probability of x
d
= p,z
d
= k is calculated as follows:
Pr(x
d
= p, z
d
= k|z
?d
,x
?d
,y,w,h)
?
N
?
p
+ ?
N
?
(.)
+ 2?
?
N
l
k
+ ?
N
l
(.)
+K?
?
N
d
?
n=1
N
k
w
dn
+ ?
w
N
k
(.)
+W?
w
?
M
d
?
m=1
N
d
?
n=1
M
w
dn
,h
dm
?d,k
+ ?
h
M
w
dn
,(.)
?d,k
+ V ?
h
,
(1)
where l = u
d
when p = 0 and l = t
d
when p = 1. N
?
0
is the number of microblog generated by personal
interests, while N
?
1
is the number of microblog coming from global topical trends, N
?
(.)
= N
?
0
+ N
?
1
.
N
u
d
k
is the number of microblogs generated by user u
d
and under topic k. N
u
d
(.)
is the total number of
microblogs generated by user u
d
. N
t
d
k
=
?
t
d
t
?
=1
e
?t
?
?
N
?
t?t
?
k
,N
?
t?t
?
k
is the number of microblogs assigned
to topic k at time epoch t ? t
?
, e
?t
?
?
is decay factory, and N
t
d
(.)
=
?
K
k=1
N
t
d
k
. N
k
w
dn
is the times of word
w
dn
assigned to topic k, N
k
(.)
is the times of all the word assigned to topic k, M
w
dn
,h
dm
?d,k
is the number of
occurrences that word w
dn
is translated to hashtag h
dm
given topic k. All the counters mentioned above
are calculated with the dth microblog excluded.
We sample y
dn
for each word w
dn
in the dth microblog using the following equation:
Pr(y
dn
= q|z,x,y
?dn
,w,h) ?
N
pi
q
+ ?
N
pi
(.)
+ 2?
?
N
l
w
dn
+ ?
w
N
l
(.)
+W?
w
,
(2)
where l = B when q = 0 and l = z
d
when q = 1. N
pi
0
is the number of words assigned to background
words and N
pi
1
is the number of words under any topic respectively. N
pi
(.)
= N
pi
0
+N
pi
1
, N
B
w
dn
is a count
of word w
dn
occurs as a background word. N
z
d
w
dn
is the number of word w
dn
is assigned to topic z
d
, and
N
z
d
(.)
is the total number of words assigned to topic z
d
. All counters are calculated with taking no account
of the current word w
dn
.
In many cases, hashtag dose not appear in the training data, to solve this problem, we assume that each
word in the microblog can translate to a hashtag in the training data or itself. We assume that each word
207
have aligned ? (we set ? = 1 in this paper after trying some number) times with itself under the specific
topic. After all the hidden variables become stable, we can estimate the alignment probability as follows:
?
h,w,z
=
?
?
?
N
h
z,w
+?
h
N
(.)
z,w
+?+(V+1)?
h
if h is a hashtag in the training data
?+?
h
N
(.)
z,w
+?+(V+1)?
h
if h is the word itself
(3)
where N
h
z,w
is the number of the hashtag h co-occurs with the word w under topic z in the microblogs.
For the probability alignment ? between hashtag and word, the potential size is W ? V ? K. The
data sparsity poses a more serious problem in estimating ? than the topic-free word alignment case.
To remedy the problem, we use interpolation smoothing technique for ?. In this paper, we emplogy
smoothing as follows:
?
?
h,w,z
= ??
h,w,z
+ (1? ?)P (h|w),
(4)
where ?
?
h,w,z
is the smoothed topical alignment probabilities, ?
h,w,z
is the original topical alignment
probabilities. P (h|w) is topic-free word alignment probability. Here we obtain P (h|w) by exploring
IBM model-1 (Brown et al., 1993). ? is trade-off of two probabilities ranging from 0.0 to 1.0. When
? = 0.0, ?
?
h,w,z
will be reduce to topic-free word alignment probability; and when ? = 1.0, there will be
no smoothing in ?
?
h,w,z
. For the word itself there are no smoothing, because it is a pseudo-count.
3.3 Hashtag Extraction
We perform hashtag extraction as follows. Suppose given an unlabeled dataset, we perform Gibbs
Sampling to iteratively estimate the topic and determine topic/background words for each microblog.
The process is the same as described in Section 3.2. After the hidden variables of topic/background
words and the topic of each microblog become stable, we can estimate the distribution of topics for the
dth microblog in unlabeled data by:?
?
dk
=
p(k)p(w
d1
|k)...p(w
dN
d
|k)
Z
where p(w
dn
|k) =
N
pi
1
+?
N
pi
(.)
+2?
?
N
k
w
dn
+?
w
N
k
(.)
+W?
w
and N
k
w
dn
is the number of words w
dn
that are assigned to topic k in the corpus, and p(k) =
N
?
0
+?
N
?
(.)
+2?
?
N
u
k
+?
N
u
(.)
+K?
+
N
?
1
+?
N
?
(.)
+2?
?
N
t
k
+?
N
t
(.)
+K?
is regarded as a prior for topic distribution, Z is the normalized
factor. With topic distribution ?
?
and topical alignment table ?
?
, we can rank hashtags for the dth
microblog in unlabeled data by computing the scores:
P (h
dm
|w
d
, ?
?
d
, ?
?
) ?
K
?
z
d
=1
N
d
?
n=1
P (h
dm
|z
d
, w
dn
, ?
?
) ? P (z
d
|?
?
d
) ? P (w
dn
|w
d
),
(5)
where h
dm
can be a hashtag in the training data or a word in the dth microblog, p(w
dn
|w
d
) is the weight
of the word w
dn
in the microblog, which can be estimated by the IDF score of the word. According to
the ranking scores, we can suggest the top-ranked hashtags for each microblog to users.
4 Experiments
In this section, we introduce the experimental results and the data collection we constructed for training
and evaluation. Firstly, we describe how do we construct the collection and statics of it. Then we
introduce the experiment configurations and baseline methods. Finally, the evaluation results and
analysis are given.
4.1 Data Collection
We use a dataset collected from Sina Weibo to evaluate the proposed approach and alternative methods.
We random select 166,864 microblogs from Aug. 2012 to June 2013. The unique number of hashtags
in the corpus is 17,516. We use the microblogs posted from Aug. 2012 to May 2013 as the training
data. The other microblogs are used for evaluation. The hashtags marked in the original microblogs are
considered as the golden standards.
208
Figure 3: Precision-recall curves of different
methods on this task.
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.45
0.50
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Prec
ision
Recall
TWTMTTMT-TTMU-TTMTU-TTMK-TTMTUK-TTM
Table 2: Evaluation results of different methods
on the evaluation collection.
Methods Precision Recall F
1
TWTM 0.231 0.202 0.215
SVM 0.418 0.366 0.390
TTM 0.319 0.279 0.297
T-TTM 0.338 0.301 0.319
U-TTM 0.341 0.307 0.323
K-TTM 0.386 0.337 0.360
TU-TTM 0.355 0.310 0.331
TUK-TTM 0.452 0.415 0.433
4.2 Experiment Configurations
We use precision (P ), recall (R), and F1-score (F
1
) to evaluate the performance. Precision is calculated
based on the percentage of ?hashtags truly assigned? among ?hashtags assigned by system?. Recall
is calculated based on the ?hashtags truly assigned? among ?hashtags manually assigned?. F1-score
is the harmonic mean of precision and recall. We do 500 iterations of Gibbs sampling to train the
model. For optimize the hyperparmeters of the proposed method and alternative methods, we use 5-fold
cross-validation in the training data to do it. The number of topics is set to 70. The other settings of
hyperparameters are as follows: ? = 50/K, ?
w
= 0.1, ?
h
= 0.1, ? = 0.01, and ? = 0.01. The
smoothing factor ? in Eq.(3) is set to 0.6. For estimating the translation probability without topical
information, we use GIZA++ 1.07 to do it (Och and Ney, 2003).
For baselines, we compare the proposed model with the following alternative models.
? TWTM: Topical word trigger model (TWTM) was proposed by Liu et al. for keyphrase extraction
using only textual information (Liu et al., 2012). We implemented the model and used it to achieve
the task.
? TTM: Ding et al. (2013) proposed the topical translation model (TTM) for hash tag extraction. We
implemented and extended their method for evaluating it on the corpus constructed in this work.
4.3 Experimental Results
Table 2 shows the comparisons of the proposed method with the state-of-the-art methods on the
constructed evaluation dataset. ?TUK-TTM? denotes the method proposed in this paper. ?T-TTM?
and ?U-TTM? represent the methods incorporating temporal and personal information respectively. ?K-
TTM? represents the method incorporating the extraction factor. From the results, we can observe that
the proposed method is significantly better than other methods at 5% significance level (two-sided).
Comparing to results of the TTM, we can observe that the temporal information, personal information
and extraction strategy can all benefit the task. Among the three additional factors, the extraction strategy
achieves the best result. The limitation of only being able to recommend hashtags that exist in the training
data can be overcome in some degree by the proposed method. The relative improvement of proposed
TUK-TTM over TTM is around 47.8% in F1-score.
Table 3 shows the comparisons of the proposed method with the method ?K-TTM? in two corpus NE-
Corpus and E-Corpus. NE-Corpus include microblogs whose hashtags are not contained in the training
data. E-Corpus include the microblogs whose hashtags appear in the training data. We can observe that
the proposed method significantly better than ?K-TTM? in the E-Corpus. Another observation is that
the method incorporating the extraction factor achieves better performances on the NE-Corpus than E-
Corpus. We think that the reason is that the fewer times hashtag appear, the greater weight it has. Hence,
we can extract this kind of hashtags more easier.
Figure 3 shows the precision-recall curves of TWTW, TTM, T-TTM, U-TTM, TU-TTM, K-TTM,
and TUK-TTM on the evaluation dataset. Each point of a precision-recall curve represents extracting
209
Table 3: Evaluation results of two different corpus.
Corpus Methods P R F
NE-Corpus
K-TTM 0.631 0.553 0.589
TUK-TTM 0.641 0.561 0.598
E-Corpus
K-TTM 0.172 0.162 0.167
TUK-TTM 0.288 0.271 0.279
Table 4: The influence of the number of topics
K of TUK-TTM.
K Precision Recall F
1
10 0.410 0.382 0.396
30 0.435 0.380 0.406
50 0.448 0.413 0.430
70 0.452 0.415 0.433
100 0.439 0.404 0.421
Table 5: The influence of the smoothing
parameter ? of TUK-TTM.
? Precision Recall F
1
0.0 0.379 0.354 0.366
0.2 0.405 0.372 0.388
0.4 0.433 0.398 0.415
0.6 0.452 0.415 0.433
0.8 0.426 0.386 0.405
1.0 0.423 0.381 0.401
different number of hashtags ranging from 1 to 5 respectively. In the figure, curves which are close
to the upper right-hand corner of the graph indicate the better performance. From the results, we can
observe that the performance of TUK-TTM is in the upper right-hand corner. It also demonstrates that
the proposed method achieves better performances than other methods.
From the description of the proposed model, we can know that there are several hyperparameters in
the proposed TUK-TTM. To evaluate the impacts of them, we evaluate two crucial ones, the number of
topics K and the smoothing factor ?. Table 4 shows the influence of the number of topics. From the
table, we can observe that the proposed model obtains the best performance when K is set to 70. And
performance decreases with more number of topics. We think that data sparsity may be one of the main
reasons. With much more topic number, the data sparsity problem will be more serious when estimating
topic-specific translation probability. Table 5 shows the influence of the translation probability smoothing
parameter ?. When ? is set to 0.0, it means that the topical information is omitted. Comparing the results
of ? = 0.0 and other values, we can observe that the topical information can benefit this task. When ? is
set to 1.0, it represents the method without smoothing. The results indicate that it is necessary to address
the sparsity problem through smoothing.
5 Conclusions
In this paper, we propose a novel method which incorporates temporal and personal factors into the
topical translation model for hashtag recommendation task. Since existing translation model based
methods for this task can only recommend hashtags that exist in the training data of the topical translation
model, we also incorporate extraction strategies into the model. To evaluate the proposed method, we
also construct a dataset from real world microblogging services. The results of experiments on the dataset
demonstrate that the proposed method outperforms state-of-the-art methods that do not consider these
aspects.
6 Acknowledgement
The authors wish to thank the anonymous reviewers for their helpful comments. This work was
partially funded by 973 Program (2010CB327900), National Natural Science Foundation of China
(61003092,61073069), Shanghai Leading Academic Discipline Project (B114) and ?Chen Guang?
project supported by Shanghai Municipal Education Commission and Shanghai Education Development
Foundation(11CG05).
210
References
A.Bandyopadhyay, M. Mitra, and P. Majumder. 2011. Query expansion for microblog retrieval. In Proceedings
of The Twentieth Text REtrieval Conference, TREC 2011.
S. Asur and B.A. Huberman. 2010. Predicting the future with social media. In WI-IAT?10, volume 1, pages
492?499.
Hila Becker, Mor Naaman, and Luis Gravano. 2010. Learning similarity metrics for event identification in social
media. In Proceedings of WSDM ?10.
Adam Bermingham and Alan F. Smeaton. 2010. Classifying sentiment in microblogs: is brevity an advantage? In
Proceedings of CIKM?10.
D.M. Blei and M.I. Jordan. 2003. Modeling annotated data. In Proceedings of SIGIR, pages 127?134.
Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011. Twitter mood predicts the stock market. Journal of
Computational Science, 2(1):1 ? 8.
Peter F Brown, Vincent J Della Pietra, Stephen A Della Pietra, and Robert L Mercer. 1993. The mathematics of
statistical machine translation: Parameter estimation. Computational linguistics, 19(2):263?311.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Enhanced sentiment learning using twitter hashtags and
smileys. In Proceedings of COLING ?10.
Zhuoye Ding, Xipeng Qiu, Qi Zhang, and Xuanjing Huang. 2013. Learning topical translation model for
microblog hashtag suggestion. In Proceedings of IJCAI 2013.
Miles Efron. 2010. Hashtag retrieval in a microblogging environment. In Proceedings of SIGIR ?10.
Nikhil Garg and Ingmar Weber. 2008. Personalized, interactive tag recommendation for flickr. In Proceedings of
RecSys ?08.
T. L. Griffiths and M. Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences.
Ido Guy, Naama Zwerdling, Inbal Ronen, David Carmel, and Erel Uziel. 2010. Social media recommendation
based on people and tags. In Proceedings of SIGIR ?10.
Ido Guy, Uri Avraham, David Carmel, Sigalit Ur, Michal Jacovi, and Inbal Ronen. 2013. Mining expertise and
interests from social media. In Proceedings of WWW ?13.
Paul Heymann, Daniel Ramage, and Hector Garcia-Molina. 2008. Social tag prediction. In Proceedings of SIGIR
?08.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment
classification. In Proceedings of ACL 2011, Portland, Oregon, USA.
Ralf Krestel, Peter Fankhauser, and Wolfgang Nejdl. 2009. Latent dirichlet allocation for tag recommendation. In
Proceedings of RecSys ?09.
Lihong Li, Wei Chu, John Langford, and Robert E Schapire. 2010. A contextual-bandit approach to personalized
news article recommendation. In Proceedings of the 19th international conference on World wide web, pages
661?670. ACM.
Ting-Peng Liang, Hung-Jen Lai, and Yi-Cheng Ku. 2007. Personalized content recommendation and user
satisfaction: Theoretical synthesis and empirical findings. Journal of Management Information Systems,
23(3):45?70.
Huizhi Liang, Yue Xu, Yuefeng Li, Richi Nayak, and Xiaohui Tao. 2010. Connecting users and items with
weighted tags for personalized item recommendations. In Proceedings of the 21st ACM conference on Hypertext
and hypermedia, pages 51?60. ACM.
Zhiyuan Liu, Chen Liang, and Maosong Sun. 2012. Topical word trigger model for keyphrase extraction. In
Proceedings of COLING.
Yu-Ta Lu, Shoou-I Yu, Tsung-Chieh Chang, and Jane Yung-jen Hsu. 2009. A content-based method to enhance
tag recommendation. In Proceedings of IJCAI?09.
211
Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1):19?51.
Tsutomu Ohkura, Yoji Kiyota, and Hiroshi Nakagawa. 2006. Browsing system for weblog articles based on
automated folksonomy. Workshop on the Weblogging Ecosystem Aggregation Analysis and Dynamics at WWW.
Takanobu Otsuka, Takuya Yoshimura, and Takayuki Ito. 2012. Evaluation of the reputation network using realistic
distance between facebook data. In Proceedings of WI-IAT ?12.
Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1?135,
January.
Steffen Rendle and Lars Schmidt-Thieme. 2010. Pairwise interaction tensor factorization for personalized tag
recommendation. In Proceedings of the third ACM international conference on Web search and data mining,
pages 81?90. ACM.
Steffen Rendle, Leandro Balby Marinho, Alexandros Nanopoulos, and Lars Schmidt-Thieme. 2009. Learning
optimal ranking with tensor factorization for tag recommendation. In Proceedings of KDD ?09.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes twitter users: real-time event
detection by social sensors. In Proceedings of WWW ?10.
Andriy Shepitsen, Jonathan Gemmell, Bamshad Mobasher, and Robin Burke. 2008. Personalized
recommendation in social tagging systems using hierarchical clustering. In Proceedings of the 2008 ACM
Conference on Recommender Systems, RecSys ?08, pages 259?266, New York, NY, USA. ACM.
Yang Song, Ziming Zhuang, Huajing Li, Qiankun Zhao, Jia Li, Wang-Chien Lee, and C. Lee Giles. 2008. Real-
time automatic tag recommendation. In Proceedings of SIGIR ?08.
Amara Tariq, Asim Karim, Fernando Gomez, and Hassan Foroosh. 2013. Exploiting topical perceptions over
multi-lingual text for hashtag suggestion on twitter. In FLAIRS Conference.
Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou, and Ming Zhang. 2011. Topic sentiment analysis in twitter:
a graph-based hashtag sentiment classification approach. In Proceedings of CIKM ?11.
Wayne Xin Zhao, Jing Jiang, Jing He, Yang Song, Palakorn Achananuparp, Ee-Peng Lim, and Xiaoming Li.
2011. Topical keyphrase extraction from twitter. In Proceedings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language Technologies-Volume 1, pages 379?388. Association for
Computational Linguistics.
212
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 688?697, Dublin, Ireland, August 23-29 2014.
A Generative Model for Identifying Target Companies of Microblogs
Yeyun Gong, Yaqian Zhou, Ya Guo, Qi Zhang, Xuanjing Huang
Shanghai Key Laboratory of Intelligent Information Processing
School of Computer Science, Fudan University
825 Zhangheng Road, Shanghai, P.R.China
{12110240006, zhouyaqian, 13210240002, qz, xjhuang}@fudan.edu.cn
Abstract
Microblogging services have attracted hundreds of millions of users to publish their status, ideas
and thoughts, everyday. These microblog posts have also become one of the most attractive and
valuable resources for applications in different areas. The task of identifying the main targets of
microblogs is an important and essential step for these applications. In this paper, to achieve this
task, we propose a novel method which converts the target company identification problem to
the translation process from content to targets. We introduce a topic-specific generative method
to model the translation process. Topic specific trigger words are used to bridge the vocabulary
gap between the words in microblogs and targets. We examine the effectiveness of our approach
via datasets gathered from real world microblogs. Experimental results demonstrate a 20.2%
improvement in terms of F1-score over the state-of-the-art discriminative method.
1 Introduction
With the rapid growth of social media, about 72% of adult internet users are also members of
a social networking site
1
. Over the past few years, microblogging has become one of the most
popular services. Meanwhile, microblogs have also been widely used as sources for analyzing public
opinions (Bermingham and Smeaton, 2010; Jiang et al., 2011), prediction (Asur and Huberman, 2010;
Bollen et al., 2011), reputation management (Pang and Lee, 2008; Otsuka et al., 2012), and many other
applications (Bian et al., 2008; Sakaki et al., 2010; Becker et al., 2010; Guy et al., 2010; Lee and Croft,
2013; Guy et al., 2013). For most of these applications, identifying the microblogs that are relevant to
the targets of interest is one of the basic steps (Lin and He, 2009; Amig?o et al., 2010; Qiu et al., 2011;
Liu et al., 2013). Let us firstly consider the following example:
Example 1: 11? MacBook Air can run for up to five hours on a single charge.
?MacBook Air? can be considered to be the target being discussed on the microblog, and we can also
infer from the microblog that it is related to Apple Inc. The ability to discriminate which company is
being referred to in a microblog is required by many applications.
Previous studies on fine-grained sentiment analysis and aspect-based opinion mining proposed
supervised (Popescu and Etzioni, 2005; Liu et al., 2012a; Liu et al., 2013) and unsupervised methods (Hu
and Liu, 2004; Wu et al., 2009; Zhang et al., 2010) to extract targets of opinion expressions. Based on
the associations between opinion targets and opinion words, some methods were also introduced to
simultaneously solve the opinion expression and target extraction problems (Qiu et al., 2011; Liu et al.,
2012a). However, most of the existing methods in this area only focus on extracting items about which
opinions are expressed in a given domain. The implicated information of targets is rarely considered.
Moreover, domain adaptation is another big challenge for these fine-grained methods in processing
different domains.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
It is reported by the Pew Research Center?s Internet & American Life Project in Aug 5, 2013.
688
The WePS-3
2
(Amig?o et al., 2010) and RepLab 2013
3
(Amig?o et al., 2013) evaluation campaigns also
addressed the problem from the perspective of the disambiguation of company names in microblogs.
Microblogs that contain company names at a lexical level are classified based on whether it refers
to the company or not. Various approaches have been proposed to address the task with different
methods (Pedersen et al., 2006; Yerva et al., 2010; Zhang et al., 2012; Spina et al., 2012; Spina et
al., 2013). However, the microblogs that do not contain company names cannot be correctly processed
using these methods. From analyzing the data, we observe that a variety of microblog posts belong to
this type. They only contain products names, slang terms, and other related company content.
To achieve this task, in this paper, we propose the use of a translation based model to identify the targets
of microblogs. We assume that the microblog posts and targets describe the same topic using different
languages. Hence, the target identification problem can be regarded as a translation process from the
content of the microblogs to the targets. We integrate latent topical information into the translation
model to facilitate the translation process. Because product names, series, and other related information
are important indicators for this task, we also incorporate this background knowledge into the model. To
evaluate the proposed method, we collect a large number of microblogs and manually annotate a subset
of these as golden standards. We compare the proposed method with state-of-the-art methods using the
constructed dataset. Experimental results demonstrate that the proposed approach can achieve better
performance than the other approaches.
2 The Proposed Method
2.1 The Generation Process
Given a corpus D = {d
i
, 1 ? i ? |D|}, which contains a list of microblogs {d
i
}. A microblog is a
sequence of N
d
words denoted by w
d
= {w
d1
, w
d2
, ..., w
dN
d
}. Each microblog contains a set of targets
denoted by c
d
= {c
d1
, c
d2
, ..., c
dM
d
}. A word is defined as an item from a vocabulary with V distinct
words indexed by w = {w
1
, w
2
, ..., w
V
}. The nth word in the dth microblog is associated with not only
one topic z
dn
, but also an indicator variable l
dn
which indicates whether w
dn
belongs to the ontology
(l
dn
= 1), which contains company names, product names, series, and other related information, or is a
common word (l
dn
= 0). Each target is from the vocabulary with C distinct company names indexed by
c = {c
1
, c
2
, ..., c
C
}. The mth target in the dth microblog is associated with a topic z
dm
. The notations
used in this paper are summarized in Table 1. Fig. 1 shows the graphical representation of the generation
process. The generative story for each microblog is as follows:
1. Sample word distribution ?
t,l
fromDir(?
l
) for each topic t = 1, 2, ..., T and each label l = 1, ..., L.
2. For each microblog d=1,2,...,|D|
a. Sample topic distribution ?
d
from Dir(?)
b. For each word n = 1, 2, ..., N
d
i. Sample a topic z
dn
= t from Multinomial(?
d
)
ii. Sample a label l
dn
= l from the distribution over labels, v
d,n
iii. Sample a wordw according to multinomial distribution P (w
dn
= w|z
dn
= t, l
dn
= l, ?
t,l
)
c. For each target m = 1, 2, ...,M
d
i. Sample a topic z
dm
= t from Multinomial(?
d
)
ii. Sample a target c
dm
= c according to probability P (c
dm
= c|w
d
, l
d
, z
dm
= t, B)
As described above, we use l
dn
to incorporate the ontology information into the model. In this work,
we construct an ontology which contains 4,926 company names, 7,632 abbreviations, and 26,732 product
names. These companies names are collected based on the top search queries in different categories
4
.
We propose to use the distribution v
d,n
to indicate the probability of variable l
dn
. We set v
d,n
by applying
2
http://nlp.uned.es/weps/weps-3
3
http://www.limosine-project.eu/events/replab2013
4
http://top.baidu.com/boards
689
wdn
z
dn
?
d
?
c
dm
z
dm
B
?
t,l
?
l
l
dn
v
d,n
f
dn
?
M
d
N
d
|D|
V
T
L
Figure 1: The graphical representation of the proposed model. Shaded circles are observations or
constants. Unshaded ones are hidden variables.
various sources of ontology (presented by ?) and the context features of the word w
dn
(presented by f
dn
).
In this work, we only consider the word itself as its context feature. This information is encoded into
the hyperparameters {?
w
|w ? {w
1
, w
2
, ..., w
V
}}, where ?
w
is hyperparameter for the word w, and
?
w
0
+ ?
w
1
= 1. For each word w in the ontology, we set ?
w
1
to a value 0.9, ?
w
0
to a value 0.1. For each
word w not contained by ontology, we set ?
w
1
to a value 0 and ?
w
0
to a value 1. Based on the ontology,
v
d,n
could be set as follows:
P (l
dn
= l|w
dn
= w) = v
d,n
l
=
?
w
l
?
w
1
+ ?
w
0
, l ? {0, 1}
(1)
2.2 Model Inference
We use collapsed Gibbs sampling (Griffiths and Steyvers, 2004) to obtain samples of hidden variable
assignment and to estimate the model parameters from these samples.
On the microblog content side, the conditional probability of a latent topic and label for the nth word
in the dth microblog is:
Pr(z
dn
= t, l
dn
= l|w
dn
= w,w
?n
, z
?n
, l
?n
) ?
?
w
l
?
w
1
+ ?
w
0
?
N
w,?n
t,l
+ ?
l
N
?n
t,l
+ V ?
l
?
N
t,?n
d
+ ?
N
?n
d
+ T?
,
(2)
where N
w,?n
t,l
is the number of the word w that are assigned to topic t under the label l; N
?n
t,l
is the
number of all the words that are assigned to topic t under the label l; N
t,?n
d
is the number of topic t in
the microblog d; N
?n
d
is the number of all the topics in the document d; ?n indicates taking no account
of the current position n.
Given the conditional probability of z
dn
= t, l
dn
= l, we formalize the marginal probability of z
dn
= t
as follows:
Pr(z
dn
= t|w
dn
= w,w
?n
, z
?n
, l
?n
) ?
L?1
?
l=0
?
w
l
?
w
1
+ ?
w
0
?
N
w,?n
t,l
+ ?
l
N
?n
t,l
+ V ?
l
?
N
t,?n
d
+ ?
N
?n
d
+ T?
(3)
690
Table 1: The notation used in the proposed model.
|D| The number of microblogs in the data set
V The number of unique words in the vocabulary
C The number of companies
T The number of topics
L The number of labels
N
d
The number of words in the dth microblog
M
d
The number of companies in the dth microblog
w
d
All the words in the dth microblog
c
d
All the targets in the dth microblog
z
d
The topic of the words in the dth microblog
l
d
The label of the words in the dth microblog
B The topic-specific word alignment table between a word and a target
?
t,l
Distribution of words for each topic t and each label l
?
d
Distribution of topics in microblog d
v
d,n
Distribution of labels for word w
dn
N
w,?n
t,l
The number of the word w that is assigned to topic t under the label l except the position n
N
?n
t,l
The number of all the words that are assigned to topic t under the label l. except the position n
N
t,?n
d
The number of topic t in the microblog d except the position n
N
?n
d
The number of all the topics in the microblog d except the position n
N
c,w
t,l
The number of the target c that co-occurs with the word w labeled as l under topic t
After re-assigning the topic z
dn
= t for the current word, the conditional probability of ontology label
for the nth word in the dth microblog is:
Pr(l
dn
= l|w
dn
= w, z
dn
= t,w
?n
, z
?n
, l
?n
) ?
?
w
l
?
w
1
+ ?
w
0
?
N
w,?n
t,l
+ ?
l
N
?n
t,l
+ V ?
l
(4)
On the target side, we perform topic assignments for each target as follows:
Pr(z
dm
= t|c
dm
= c, c
?m
,w, l, z
?m
) ?
N
d
?
n=1
?
l
dn
N
c,w
dn
,?m
t,l
dn
N
w
dn
t,l
dn
+ ?C
?
N
t,?m
d
+ ?
N
?m
d
+ T?
,
(5)
where ?
l
dn
is the weight for the label (?
1
> 1, ?
0
= 1); N
c,w
dn
,?m
t,l
dn
is the number of the company c that
co-occurs with the word w
dn
labeled as l
dn
under topic t; ?C is a smoothing part; N
w
dn
t,l
dn
is the number of
the word w
dn
labeled as l
dn
under topic t; N
t,?m
d
is the number of occurrences of topic t in the document
d; N
?m
d
is the number of occurrences of all the topics in the document d; ?m indicates taking no account
of the current position m.
Based on the above equations, after enough sampling iterations, we can estimate word alignment table
B, B
c,w,t,l
= ?
l
N
c,w
t,l
N
w
t,l
+?C
. Some companies just occur few times, and most of the words co-occur with
them also alignment with other companies, for this case, we use ?C to smooth, where C represent the
number of company c. And also we can estimate topic distribution ? for each document, and word
distribution ? for each topic and each label, as follows:
?
t
d
=
N
t
d
+ ?
N
d
+ T?
, ?
t,l
w
=
N
w
t,l
+ ?
l
N
t,l
+ V ?
l
The possibility table B
c,w,t,l
has a potential size of V ?C ?T ?L. The data sparsity may pose a problem
in estimating B
c,w,t,l
. To reduce the data sparsity problem, we introduce the remedy in our model. We
691
employ a linear interpolation with topic-free word alignment probability to avoid data sparsity problem:
B
?
c,w,t,l
= ?B
c,w,t,l
+ (1? ?)P (c|w),
(6)
where P (c|w) is topic-free word alignment probability between the word w and the company c. ? is
trade-off of two probabilities ranging from 0.0 to 1.0.
2.3 Target Company Extraction
Just like standard LDA, the proposed method itself finds a set of topics but does not directly extract
targets. Suppose we have a dataset which contains microblogs without targets, we can use the collapsed
Gibbs sampling to estimate the topic and label for the words in each microblog. The process is the same
as described in Section 3.2.
After the hidden topics and label of the words in each microblog become stable, we can estimate the
distribution of topics for the dth microblog by: P (t|w
d
) = ?
t
d
=
N
t
d
+?
N
d
+T?
. With the word alignment table
B
?
, we can rank companies for the dth microblog in unlabeled data by computing the scores:
Pr(c
dm
|w
d
) ?
T
?
t=1
N
d
?
n=1
P (c
dm
|t, w
dn
, l
dn
, B
?
) ? P (t|w
d
)P (w
dn
|w
d
),
(7)
where P (w
dn
|w
d
) is the weight of the word w
dn
in the microblog content w
d
. In this paper, we use
inverse document frequency (IDF) score to estimate it. Based on the ranking scores calculated by Eq.(7),
we can extract the top-ranked targets for each microblog to users.
3 Experiments
In this section, we will introduce the experimental results and datasets we constructed for training and
evaluation. We will firstly describe the how we construct the datasets and their statistics. Then we
will introduce the experiment configurations and baseline methods. Finally, the evaluation results and
analysis will be given.
3.1 Datasets
We started by using Sina Weibo?s API
5
to collect public microblogs from randomly selected users. The
dataset contains 282.2M microblogs published by 1.1M users. We use RAW-Weibo to represent it in the
following sections. Based on the collected raw microblogs, we constructed three datasets for evaluation
and training.
3.1.1 Training data
Since social media users post thoughts, ideas, or status on various topics in social medias, there are a
huge number of related companies. Manually constructing training data is a time consuming and cost
process. In this work, we propose a weakly manual method based on ontology and hashtag. A hashtag is
a string of characters preceded by the symbol #. In most cases, hashtags can be viewed as an indication
to the context of the tweet or as the core idea expressed in the tweet. Hence, we can use hashtag as the
targets.
We extract the microblogs whose hashtags contain ontology items as training data and the
corresponding ontology items as targets. Obviously, the training data constructed based on this method
is not perfect. However, since this method can effectively generate a great quantity of data, we think
that general characteristics can be modeled with the generated training data. To evaluate the corpus,
we randomly selected 100 microblogs from the training data and manually labeled their targets. The
accuracy of the sampled dataset is 91%. It indicates that the proposed training data generation method
is effective. From the RAW-Weibo dataset, we extracted a total of 1.79M microblogs whose hashtags
contain more than one target. Training instances for 2,574 target companies are included in the training
data.
5
http://open.weibo.com/
692
3.1.2 Test data
For evaluation, we manually constructed a dataset RAN-Weibo, which contains 2,000 microblogs selected
from RAW-Weibo. Three annotators were asked to label the target companies for each microblog. To
evaluate the quality of annotated dataset, we validate the agreements of human annotations using Cohen?s
kappa coefficient. The average ? among all annotators is 0.626. It indicates that the annotations are
reliable.
Since some targets are ambiguous, inspired by the evaluation campaigns WePS-3 and RepLab 2013,
we also constructed a dataset AMB-Weibo, where microblogs include 10 popular company names which
may cause ambiguity. For each target, we randomly selected and annotated 200 microblogs as golden
standards. Three annotators were also asked to label whether the microblog is related the given target or
not. The agreements of human annotations were also validated through Cohen?s kappa coefficient. The
average ? among all annotators is 0.692.
3.2 Experiment Configurations
We use precision (P ), recall (R), and F1-score (F
1
) to evaluate the performance. We ran our model
with 500 iterations of Gibbs sampling. We use 5-fold cross-validation in the training data to optimize
hyperparameters. The number of topics is set to 30. The other settings of hyperparameters are as follows:
? = 50/T , ? = 0.1, ? = 20, ? = 0.5. The smoothing parameter ? is set to 0.8.
For baselines, we compare the proposed model with the following baseline methods.
? Naive Bayes (NB): The target identification task can be easily formalized as a classification task,
where each target is considered as a classification label. Hence, we applied Naive Bayes to model
the posterior probability of each target given a microblog.
? Support Vector Machine (SVM): The content of microblogs are represented as vectors and SVM
is used to model the classification problem.
? IBM1: Translation model (IBM model-1) is applied to obtain the alignment probability between
words and targets.
? TTM: Topical translation model (TTM) was proposed by Ding et al. (2013) to achieve microblog
hashtag suggestion task. We adopted it to estimate the alignment probability between words and
targets.
3.3 Experimental Results
We evaluate the proposed method from the following perspectives: 1) comparing the proposed method
with the state-of-the-art methods on the two evaluation datasets; 2) identifying the impacts of parameters.
Table 2 shows the comparisons of the proposed method with the state-of-the-arts discriminative
and generative methods on the evaluation dataset RAN-Weibo. ?Our? denotes the method proposed
in previous sections. ?Our w/o BG? represents the proposed method without background knowledge.
From the results, we can observe that the proposed method is better than other methods. Discriminative
methods achieve worse results than generative methods. We think that the large number of targets is
one of the main reasons of the low performances. The results of the proposed models with and without
ontology information also show that background knowledge can benefit both the precision and recall.
TTM achieves better performance than IBM1. It indicates that topical information is useful for this
task. The performances of our method are significantly better than TTM. It illustrates that our smoothing
method and incorporation of background knowledge are effective.
From the description of the proposed model, we can know that there are several hyperparameters in
the proposed model. To evaluate the impacts of them, we evaluate two crucial ones among all of them,
the number of topics T and the smoothing factor ?. Table 3 shows the influence of the number of topics.
From the table, we can observe that the proposed model obtains the best performance when T is set to
30. And performance decreases with more number of topics. We think that data sparsity may be one of
the main reasons. With much more topic number, the data sparsity problem will be more serious when
693
Table 2: Evaluation results of NB, SVM, IBM1, TTM, and our method on the evaluation dataset RAN-
Weibo.
Methods Precision Recall F
1
NB 0.168 0.154 0.161
SVM 0.312 0,286 0.298
IBM1 0.236 0.214 0.220
TTM 0.356 0.327 0.341
Our w/o BG 0.488 0.448 0.467
Our 0.522 0.479 0.500
Table 3: The influence of the number of topics T of the proposed method.
T Precision Recall F
1
10 0.516 0.473 0.493
30 0.522 0.479 0.500
50 0.508 0.466 0.486
70 0.489 0.449 0.468
100 0.488 0.448 0.467
estimating topic-specific translation probability. Table 4 shows the influence of the translation probability
smoothing parameter ?. When ? is set to 0.0, it means that the topical information is omitted. Comparing
the results of ? = 0.0 and other values, we can observe that the topical information can benefit this task.
When ? is set to 1.0, it represents the method without smoothing. The results indicate that it is necessary
to address the sparsity problem through smoothing.
Figure 2 shows the results of different methods on the dataset AMB-Weibo. All the models are trained
with same dataset as the above experiments. From the results, we can observe that the F1-scores vary
from less than 0.40 up to almost 0.60. The performances? variations of other methods are also huge. We
think that training data size and difficulty level are two main reasons. The size of training data of different
targets vary greatly in the dataset. However, comparing with other method, the proposed method is the
most stable one. Comparing with other methods, the proposed method achieves better performance than
other methods for all targets.
4 Related Work
Organization name disambiguation task is fundamental problems in many NLP applications. The task
aims to distinguish the real world relevant of a given name with the same surface in context. WePS-
3
6
(Amig?o et al., 2010) and RepLab 2013
7
(Amig?o et al., 2013) evaluation campaigns have also addressed
the problem from the perspective of disambiguation organization names in microblogs. Pedersen et
al. (2006) proposed an unsupervised method for name discrimination. Yerva et al. (2010) used support
vector machines (SVM) classifier with various external resources, such as WordNet, metadata profile,
category profile, Google set, and so on. Kozareva and Ravi (2011) proposed to use latent dirichlet
allocation to incorporate topical information. Zhang et al. (2012) proposed to use adaptive method for
this task. However, most of these methods focused on the text with predefined surface words. The
documents which do not contain organization names or person names can not be well processed by these
methods.
To bridge the vocabulary gap between content and hashtags, Liu et al. (2012b) proposed to use
translation model to handle it. They modeled the tag suggestion task as a translation process from
6
http://nlp.uned.es/weps/weps-3
7
http://www.limosine-project.eu/events/replab2013
694
Table 4: The influence of the smoothing parameter ? of the propose method.
? Precision Recall F
1
0.0 0.471 0.432 0.451
0.2 0.490 0.449 0.469
0.4 0.495 0.454 0.474
0.6 0.511 0.468 0.489
0.8 0.522 0.479 0.500
1.0 0.519 0.476 0.496
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
1 2 3 4 5 6 7 8 9 10
F1
-S
co
re
NB SVM IBM1 TTM Our w/o BG Our
Figure 2: Evaluation results of NB, SVM, IBM1, TTM, and our method on the different companies in
the test dataset AMB-Weibo.
document content to tags. Ding et al. (2013) extended the translation based method and introduced a
topic-specific translation model to process the multiple meanings of words in different topics. Motivated
by these methods, we also propose to use topic-specific translation model to handle vocabulary problem.
Based on the model, in this work, we incorporate the background knowledge information into the model.
5 Conclusions
To identify target companies of microblogs, in this paper, we propose a novel topical translation
model to achieve the task. The main assumption is that the microblog posts and targets describe
the same thing with different languages. We convert the target identification problem to a translation
process from content of microblogs to targets. We integrate latent topical information into translation
model to hand the themes of microblogs in facilitating the translation process. We also incorporate
background knowledge (such as product names, series, et al.) into the generation model. Experimental
results on a large corpus constructed from a real microblog service and a number of manually labeled
golden standards of easily ambiguous entities demonstrate that the proposed method can achieve better
performance than other approaches.
6 Acknowledgement
The authors wish to thank the anonymous reviewers for their helpful comments. This work was
partially funded by 973 Program (2010CB327900), National Natural Science Foundation of China
(61003092,61073069), Shanghai Leading Academic Discipline Project (B114) and ?Chen Guang?
project supported by Shanghai Municipal Education Commission and Shanghai Education Development
Foundation(11CG05).
695
References
Enrique Amig?o, Javier Artiles, Julio Gonzalo, Damiano Spina, Bing Liu, and Adolfo Corujo. 2010.
Weps3 evaluation campaign: Overview of the on-line reputation management task. In CLEF (Notebook
Papers/LABs/Workshops).
Enrique Amig?o, Jorge Carrillo de Albornoz, Irina Chugur, Adolfo Corujo, Julio Gonzalo, Tamara Mart??n, Edgar
Meij, Maarten Rijke, and Damiano Spina. 2013. Overview of replab 2013: Evaluating online reputation
monitoring systems. In Information Access Evaluation. Multilinguality, Multimodality, and Visualization,
volume 8138 of Lecture Notes in Computer Science, pages 333?352. Springer Berlin Heidelberg.
S. Asur and B.A. Huberman. 2010. Predicting the future with social media. In Proceedings of WI-IAT 2010.
Hila Becker, Mor Naaman, and Luis Gravano. 2010. Learning similarity metrics for event identification in social
media. In Proceedings of WSDM ?10.
Adam Bermingham and Alan F. Smeaton. 2010. Classifying sentiment in microblogs: is brevity an advantage? In
Proceedings of CIKM ?10.
Jiang Bian, Yandong Liu, Eugene Agichtein, and Hongyuan Zha. 2008. Finding the right facts in the crowd:
factoid question answering over social media. In Proceedings of WWW ?08.
Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011. Twitter mood predicts the stock market. Journal of
Computational Science, 2(1):1 ? 8.
Zhuoye Ding, Xipeng Qiu, Qi Zhang, and Xuanjing Huang. 2013. Learning topical translation model for
microblog hashtag suggestion. In Proceedings of IJCAI 2013.
Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. In Proceedings of the National Academy
of Sciences, volume 101, pages 5228?5235.
Ido Guy, Naama Zwerdling, Inbal Ronen, David Carmel, and Erel Uziel. 2010. Social media recommendation
based on people and tags. In Proceedings of SIGIR ?10.
Ido Guy, Uri Avraham, David Carmel, Sigalit Ur, Michal Jacovi, and Inbal Ronen. 2013. Mining expertise and
interests from social media. In Proceedings of WWW ?13.
Minqing Hu and Bing Liu. 2004. Mining opinion features in customer reviews. In Proceedings of AAAI?04.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment
classification. In Proceedings of ACL-HLT 2011, Portland, Oregon, USA.
Zornitsa Kozareva and Sujith Ravi. 2011. Unsupervised name ambiguity resolution using a generative model.
In Proceedings of the First Workshop on Unsupervised Learning in NLP, EMNLP ?11, pages 105?112,
Stroudsburg, PA, USA. Association for Computational Linguistics.
Chia-Jung Lee and W. Bruce Croft. 2013. Building a web test collection using social media. In Proceedings of
SIGIR ?13, SIGIR ?13.
Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of CIKM
?09.
Kang Liu, Liheng Xu, and Jun Zhao. 2012a. Opinion target extraction using word-based translation model. In
Proceedings of EMNLP-CoNLL ?12.
Zhiyuan Liu, Chen Liang, and Maosong Sun. 2012b. Topical word trigger model for keyphrase extraction. In
Proceedings of COLING.
Kang Liu, Liheng Xu, and Jun Zhao. 2013. Syntactic patterns versus word alignment: Extracting opinion targets
from online reviews. In Proceedings of ACL 2013, Sofia, Bulgaria.
Takanobu Otsuka, Takuya Yoshimura, and Takayuki Ito. 2012. Evaluation of the reputation network using realistic
distance between facebook data. In Proceedings of WI-IAT ?12, Washington, DC, USA.
Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1?135,
January.
696
Ted Pedersen, Anagha Kulkarni, Roxana Angheluta, Zornitsa Kozareva, and Thamar Solorio. 2006. An
unsupervised language independent method of name discrimination using second order co-occurrence features.
In Computational Linguistics and Intelligent Text Processing, pages 208?222.
Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In
Proceedings of HL-EMNLP 2005, Vancouver, British Columbia, Canada.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through
double propagation. Comput. Linguist., 37(1):9?27, March.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes twitter users: real-time event
detection by social sensors. In Proceedings of the 19th international conference on World wide web, WWW
?10, pages 851?860, New York, NY, USA. ACM.
Damiano Spina, Edgar Meij, Maarten de Rijke, Andrei Oghina, Minh Thuong Bui, and Mathias Breuss. 2012.
Identifying entity aspects in microblog posts. In Proceedings of SIGIR ?12.
Damiano Spina, Julio Gonzalo, and Enrique Amig?o. 2013. Discovering filter keywords for company name
disambiguation in twitter. Expert Systems with Applications, 40(12):4986 ? 5003.
Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining.
In Proceedings of EMNLP 2009, Singapore.
Surender Reddy Yerva, Zoltn Mikls, and Karl Aberer. 2010. It was easy, when apples and blackberries
were only fruits. In Martin Braschler, Donna Harman, and Emanuele Pianta, editors, CLEF (Notebook
Papers/LABs/Workshops).
Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn O?Brien-Strain. 2010. Extracting and ranking product features
in opinion documents. In Proceedings of COLING ?10.
Shu Zhang, Jianwei Wu, Dequan Zheng, Yao Meng, and Hao Yu. 2012. An adaptive method for organization name
disambiguation with feature reinforcing. In Proceedings of the 26th Pacific Asia Conference on Language,
Information, and Computation, pages 237?245, Bali,Indonesia, November. Faculty of Computer Science,
Universitas Indonesia.
697
