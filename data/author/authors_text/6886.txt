A Large Scale Terminology Resource for Biomedical Text Processing
Henk Harkema, Robert Gaizauskas, Mark Hepple, Angus Roberts,
Ian Roberts, Neil Davis, Yikun Guo
Department of Computer Science, University of Sheffield, UK
biomed@dcs.shef.ac.uk
Abstract
In this paper we discuss the design, implemen-
tation, and use of Termino, a large scale termi-
nological resource for text processing. Dealing
with terminology is a difficult but unavoidable
task for language processing applications, such
as Information Extraction in technical domains.
Complex, heterogeneous information must be
stored about large numbers of terms. At the
same time term recognition must be performed
in realistic times. Termino attempts to recon-
cile this tension by maintaining a flexible, ex-
tensible relational database for storing termino-
logical information and compiling finite state
machines from this database to do term look-
up. While Termino has been developed for
biomedical applications, its general design al-
lows it to be used for term processing in any
domain.
1 Introduction
It has been widely recognized that the biomedical litera-
ture is now so large, and growing so quickly, that it is be-
coming increasingly difficult for researchers to access the
published results that are relevant to their research. Con-
sequently, any technology that can facilitate this access
should help to increase research productivity. This has
led to an increased interest in the application of natural
language processing techniques for the automatic capture
of biomedical content from journal abstracts, complete
papers, and other textual documents (Gaizauskas et al,
2003; Hahn et al, 2002; Pustejovsky et al, 2002; Rind-
flesch et al, 2000).
An essential processing step in these applications is
the identification and semantic classification of techni-
cal terms in text, since these terms often point to enti-
ties about which information should be extracted. Proper
semantic classification of terms also helps in resolving
anaphora and extracting relations whose arguments are
restricted semantically.
1.1 Challenge
Any technical domain generates very large numbers of
terms ? single or multiword expressions that have some
specialised use or meaning in that domain. For exam-
ple, the UMLS Metathesaurus (Humphreys et al, 1998),
which provides a semantic classification of terms from a
wide range of vocabularies in the clinical and biomedical
domain, currently contains well over 2 million distinct
English terms.
For a variety of reasons, recognizing these terms in
text is not a trivial task. First of all, terms are often
long multi-token sequences, e.g. 3-methyladenine-DNA
glycosylase I. Moreover, since terms are referred to re-
peatedly in discourses there is a benefit in their being
short and unambiguous, so they are frequently abbre-
viated and acronymized, e.g. CvL for chromobacterium
viscosum lipase. However, abbreviations may not al-
ways occur together with their full forms in a text, the
method of abbreviation is not predictable in all cases, and
many three letter abbreviations are highly overloaded.
Terms are also subject to a high degree of orthographic
variation as a result of the representation of non-Latin
characters, e.g. a-helix vs. alpha-helix, capitalization,
e.g. DNA vs. dna, hyphenation, e.g. anti-histamine vs. an-
tihistamine, and British and American spelling variants,
e.g. tumour vs. tumor. Furthermore, biomedical science
is a dynamic field: new terms are constantly being in-
troduced while old ones fall into disuse. Finally, certain
classes of biomedical terms exhibit metonomy, e.g. when
a protein is referred to by the gene that expresses it.
To begin to address these issues in term recognition, we
are building a large-scale resource for storing and recog-
nizing technical terminology, called Termino. This re-
source must store complex, heterogeneous information
about large numbers of terms. At the same time term
recognition must be performed in realistic times. Ter-
mino attempts to reconcile this tension by maintaining a
                                            Association for Computational Linguistics.
                   Linking Biological Literature, Ontologies and Databases, pp. 53-60.
                                                HLT-NAACL 2004 Workshop: Biolink 2004,
flexible, extensible relational database for storing termi-
nological information and compiling finite state machines
from this database to do term look-up.
1.2 Context
Termino is being developed in the context of two ongoing
projects: CLEF, for Clinical E-Science Framework (Rec-
tor et al, 2003) and myGrid (Goble et al, 2003). Both
these projects involve an Information Extraction compo-
nent. Information Extraction is the activity of identifying
pre-defined classes of entities and relationships in natural
language texts and storing this information in a structured
format enabling rapid and effective access to the informa-
tion, e.g. Gaizauskas and Wilks (1998), Grishman (1997).
The goal of the CLEF project is to extract information
from patient records regarding the treatment of cancer.
The treatment of cancer patients may extend over several
years and the resulting clinical record may include many
documents, such as clinic letters, case notes, lab reports,
discharge summaries, etc. These documents are gener-
ally full of medical terms naming entities such as body
parts, drugs, problems (i.e. symptoms and diseases), in-
vestigations and interventions. Some of these terms are
particular to the hospital from which the document origi-
nates. We aim to identify these classes of entities, as well
as relationships between such entities, e.g. that an investi-
gation has indicated a particular problem, which, in turn,
has been treated with a particular intervention. The infor-
mation extracted from the patient records is potentially of
value for immediate patient care, but can also be used to
support longitudinal and epidemiological medical stud-
ies, and to assist policy makers and health care managers
in regard to planning and clinical governance.
The myGrid project aims to present research biolo-
gists with a unified workbench through which component
bioinformatic services can be accessed using a workflow
model. These services may be remotely located from the
user and will be exploited via grid or web-service chan-
nels. A text extraction service will form one of these ser-
vices and will facilitate access to information in the sci-
entific literature. This text service comprises an off-line
and an on-line component. The off-line component in-
volves pre-processing a large biological sciences corpus,
in this case the contents of Medline, in order to identify
various biological entities such as genes, enzymes, and
proteins, and relationships between them such as struc-
tural and locative relations. These entities and relation-
ships are referred to in Medline abstracts by a very large
number of technical terms and expressions, which con-
tributes to the complexity of processing these texts. The
on-line component supports access to the extracted infor-
mation, as well as to the raw texts, via a SOAP interface
to an SQL database.
Despite the different objectives for text extraction
within the CLEF and myGrid projects, many of the tech-
nical challenges they face are the same, such as the
need for extensive capabilities to recognize and classify
biomedical entities as described using complex techni-
cal terminology in text. As a consequence we are con-
structing a general framework for the extraction of infor-
mation from biomedical text: AMBIT, a system for ac-
quiring medical and biological information from text. An
overview of the AMBIT logical architecture is shown in
figure 1.
The AMBIT system contains several engines, of which
Termino is one. The Information Extraction Engine pulls
selected information out of natural language text and
pushes this information into a set of pre-defined tem-
plates. These are structured objects which consists of one
or more slots for holding the extracted entities and rela-
tions. The Query Engine allows users to access informa-
tion through traditional free text search and search based
on the structured information produced by the Informa-
tion Extraction Engine, so that queries may refer to spe-
cific entities and classes of entities, and specific kinds of
relations that are recognised to hold between them. The
Text Indexing Engine is used to index text and extracted,
structured information for the purposes of information re-
trieval. The AMBIT system contains two further compo-
nents: an interface layer, which provides a web or grid
channel to allow user and program access to the system;
and a database which holds free text and structured infor-
mation that can be searched through the Query Engine.
Termino interacts with the Query Engine and the Text
Indexing Engine to provide terminological support for
query formulation and text indexation. It also provides
knowledge for the Information Extraction Engine to use
in identifying and classifying biomedical entities in text.
The Terminology Engine can furthermore be called by
users and remote programs to access information from
the various lexical resources that are integrated in the ter-
minological database.
2 Related Work
Since identification and classification of technical terms
in biomedical text is an essential step in information
extraction and other natural language processing tasks,
most natural language processing systems contain a
terminological resource of some sort. Some systems
make use of existing terminological resources, notably
the UMLS Metathesaurus, e.g. Rindflesch et al (2000),
Pustejovski et al (2002); other systems rely on re-
sources that have been specifically built for the applica-
tion, e.g. Humphreys et al (2000), Thomas et al (2000).
The UMLS Metathesaurus provides a semantic classi-
fication of terms drawn from a wide range of vocabularies
in the clinical and biomedical domain (Humphreys et al,
1998). It does so by grouping strings from the source vo-
from Hospital 1
Clinical Records
Journals
On?line
Abstracts
Medline
Literature
Biomedical
Engine
Indexing
Text
Engine
Extraction
...
(Termino)
Engine
Terminology
Ambit
from Hospital 2
Clinical Records
Web GRID
Interface layer
Raw text
(entities / relations)
Structured InfoFree text
  search
Engine
Query
Information
SOAP /
     HTTP
& Annotations
Structured Info
Figure 1: AMBIT Architecture
cabularies that are judged to have the same meaning into
concepts, and mapping these concepts onto nodes or se-
mantic types in a semantic network. Although the UMLS
Metathesaurus is used in a number of biomedical natural
language processing applications, we have decided not to
adopt the UMLS Metathesaurus as the primary terminol-
ogy resource in AMBIT for a variety of reasons.
One of the reasons for this decision is that the Metathe-
saurus is a closed system: strings are classified in terms
of the concepts and the semantic types that are present
in the Metathesaurus and the semantic network, whereas
we would like to be able to link our terms into multi-
ple ontologies, including in-house ontologies that do not
figure in any of the Metathesaurus? source vocabularies
and hence are not available through the Metathesaurus.
Moreover, we would also like to be able to have access to
additional terminological information that is not present
in the Metathesaurus, such as, for example, the annota-
tions in the Gene Ontology (The Gene Ontology Con-
sortium, 2001) assigned to a given human protein term.
While the terms making up the the tripartite Gene On-
tology are present in the UMLS Metathesaurus, assign-
ments of these terms to gene products are not recorded
in the Metathesaurus. Furthermore, as new terms appear
constantly in the biomedical field we would like to be
able to instantly add these to our terminological resource
and not have to wait until they have been included in the
UMLS Metathesaurus. Additionally, some medical terms
appearing in patient notes are hospital-specific and are
unlikely to be included in the Metathesaurus at all.
With regard to systems that do not use the UMLS
Metathesaurus, but rather depend on terminological re-
sources that have been specifically built for an applica-
tion, we note that these terminological resources tend to
be limited in the following two respects. First, the struc-
ture of these resources is often fixed and in some cases
amounts to simple gazetteer lists. Secondly, because of
their fixed structure, these resources are usually popu-
lated with content from just a few sources, leaving out
many other potentially interesting sources of terminolog-
ical information.
Instead, we intend for Termino to be an exten-
sible resource that can hold diverse kinds of termi-
nological information. The information in Termino
is either imported from existing, outside knowledge
sources, e.g. the Enzyme Nomenclature (http://www.
chem.qmw.ac.uk/iubmb/enzyme/), the Structural Classi-
fication of Proteins database (Murzin et al, 1995), and
the UMLS Metathesaurus, or it is induced from on-line
raw text resources, e.g. Medline abstracts. Termino thus
provides uniform access to terminological information
aggregated across many sources. Using Termino re-
moves the need for multiple, source-specific terminolog-
ical components within text processing systems that em-
ploy multiple terminological resources.
3 Architecture
Termino consists of two components: a database holding
terminological information and a compiler for generating
term recognizers from the contents of the database. These
two components will be discussed in the following two
sections.
STRINGS
string str id
. . . . . .
neurofibromin str728
abdomen str056
mammectomy str176
mastectomy str183
. . . . . .
TERMOID STRINGS
trm id str id
. . . . . .
trm023 str056
trm656 str056
trm924 str728
trm369 str728
trm278 str176
trm627 str183
. . . . . .
PART OF SPEECH
trm id pos
. . . . . .
trm023 N
. . . . . .
SYNONYMY
syn id trm id scl id
. . . . . . . . .
syn866 trm278 syn006
syn435 trm627 syn006
. . . . . . . . .
GO ANNOTATIONS
trm id annotation version
. . . . . . . . .
trm924 GO:0004857 9/2003
trm369 GO:0008285 9/2003
. . . . . . . . .
UMLS
trm id cui lui sui version
. . . . . . . . . . . . . . .
trm278 C0024881 L0024669 S0059711 2003AC
trm656 C0000726 L0000726 S0414154 2003AC
. . . . . . . . . . . . . . .
Figure 2: Structure of the terminological database
3.1 Terminological Database
The terminological database is designed to meet three re-
quirements. First of all, it must be capable of storing large
numbers of terms. As we have seen, the UMLS Metathe-
saurus contains over 2 million distinct terms. However,
as UMLS is just one of many resources whose terms may
need to be stored, many millions of terms may need to
be stored in total. Secondly, Termino?s database must
also be flexible enough to hold a variety of information
about terms, including information of a morpho-syntactic
nature, such as part of speech and morphological class;
information of a semantic nature, such as quasi-logical
form and links to concepts in ontologies; and provenance
information, such as the sources of the information in the
database. The database will also contain links to connect
synonyms and morphological and orthographic variants
to one another and to connect abbreviations and acronyms
to their full forms. Finally, the database must be orga-
nized in such a way that it allows for fast and efficient
recognition of terms in text.
As mentioned above, the information in Termino?s
database is either imported from existing, outside knowl-
edge sources or induced from text corpora. Since these
sources are heterogeneous in both information content
and format, Termino?s database is ?extensional?: it stores
strings and information about strings. Higher-order con-
cepts such as ?term? emerge as the result of interconnec-
tions between strings and information in the database.
The database is organized as a set of relational tables,
each storing one of the types of information mentioned
above. In this way, new information can easily be in-
cluded in the database without any global changes to the
structure of the database.
Terminological information about any given string is
usually gathered from multiple sources. As information
about a string accumulates in the database, we must make
sure that co-dependencies between various pieces of in-
formation about the string are preserved. This considera-
tion leads to the fundamental element of the terminologi-
cal database, a termoid. A termoid consists of a string to-
gether with associated information of various kinds about
the string. Information in one termoid holds conjunc-
tively for the termoid?s string, while multiple termoids
for the same string express disjunctive alternatives.
For instance, taking an example from UMLS, we may
learn from one source that the string cold as an adjective
refers to a temperature, whereas another source may tell
us that cold as a noun refers to a disease. This informa-
tion is stored in the database as two termoids: abstractly,
?cold, adjective, temperature? and ?cold, noun, disease?.
A single termoid ?cold, adjective, noun, temperature, dis-
ease? would not capture the co-dependency between the
part of speech and the ?meaning? of cold.1 This example
illustrates that a string can be in more than one termoid.
1Note that the UMLS Metathesaurus has no mechanism for
storing this co-dependency between grammatical and semantic
information.
Each termoid, however, has one and only one string.
Figure 2 provides a detailed example of part of the
structure of the terminological database. In the table
STRINGS every unique string is assigned a string iden-
tifier (str id). In the table TERMOID STRINGS each string
identifier is associated with one or more termoid iden-
tifiers (trm id). These termoid identifiers then serve as
keys into the tables holding terminological information.
Thus, in this particular example, the database includes
the information that in the Gene Ontology the string
neurofibromin has been assigned the terms with identi-
fiers GO:0004857 and GO:0008285. Furthermore, in the
UMLS Metathesaurus version 2003AC, the string mam-
mectomy has been assigned the concept-unique identifier
C0024881 (CUI), the lemma-unique identifier L0024669
(LUI), and the string-unique identifier S0059711 (SUI).
Connections between termoids such as those arising
from synonymy and orthographic variation are recorded
in another set of tables. For example, the table SYN-
ONYMY in figure 2 indicates that termoids 278 and
627 are synonymous, since they have the same syn-
onymy class identifier (scl id).2 The synonymy identifier
(syn id) identifies the assignment of a termoid to a partic-
ular synonymy class. This identifier is used to record the
source on which the assignment is based. This can be a
reference to a knowledge source from which synonymy
information has been imported into Termino, or a refer-
ence to both an algorithm by which and a corpus from
which synonyms have been extracted. Similarly there are
tables containing provenance information for strings, in-
dexed by str id, and termoids, indexed by trm id. These
tables are not shown in he example.
With regard to the first requirement for the design of
the terminological database mentioned at the beginning
of this section ? scalability ?, an implementation of Ter-
mino in MySQL has been loaded with 427,000 termoids
for 363,000 strings (see section 4 for more details). In it
the largest table, STRINGS, measures just 16MB, which is
nowhere near the default limit of 4GB that MySQL im-
poses on the size of tables. Hence, storing a large num-
ber of terms in Termino is not a problem size-wise. The
second requirement, flexibility of the database, is met by
distributing terminological information over a set of rela-
tively small tables and linking the contents of these tables
to strings via termoid identifiers. In this way we avoid the
strictures of any one fixed representational scheme, thus
making it possible for the database to hold information
from disparate sources. The third requirement on the de-
sign of the database, efficient recognition of terms, will
2The function of synonymy class identifiers in Termino is
similar to the function of CUIs in the UMLS Metathesaurus.
However, since we are not bound to a classification into UMLS
CUIs, we can assert synonymy between terms coming from ar-
bitrary sources.
be addressed in the next section.
3.2 Term Recognition
To ensure fast term recognition with Termino?s vast ter-
minological database, the system comes equipped with
a compiler for generating finite state machines from the
strings in the terminological database discussed in the
previous section. Direct look-up of strings in the database
is not an option, because it is unknown in advance at
which positions in a text terms will start and end. In order
to be complete, one would have to look up all sequences
of words or tokens in the text, which is very inefficient.
Compilation of a finite state recognizer proceeds in
the following way. First, each string in the database is
broken into tokens, where a token is either a contigu-
ous sequence of alpha-numeric characters or a punctu-
ation symbol. Next, starting from a single initial state, a
path through the machine is constructed, using the tokens
of the string to label transitions. For example, for the
string Graves? disease the machine will include a path
with transitions on Graves, ?, and disease. New states are
only created when necessary. The state reached on the fi-
nal token of a string will be labeled final and is associated
with the identifiers of the termoids for that string.
To recognize terms in text, the text is tokenized and the
finite state machine is run over the text, starting from the
initial state at each token in the text. For each sequence
of tokens leading to a final state, the termoid identifiers
associated with that state are returned. These identifiers
are then used to access the terminological database and
retrieve the information contained in the termoids. Where
appropriate the machine will produce multiple termoid
identifiers for strings. It will also recognize overlapping
and embedded strings.
Figure 3 shows a small terminological database and a
finite state recognizer derived from it. Running this rec-
ognizer over the phrase . . . thyroid dysfunction, such as
Graves? disease . . . produces four annotations: thyroid
is assigned the termoid identifiers trm1 and trm2; thyroid
dysfunction, trm3; and Graves? disease, trm4.
It should be emphasised at this point that term recog-
nition as performed by Termino is in fact term look-up
and not the end point of term processing. Term look-up
might return multiple possible terms for a given string,
or for overlapping strings, and subsequent processes may
apply to filter these alternatives down to the single option
that seems most likely to be correct in the given context.
Furthermore, more flexible processes of term recognition
might apply over the results of look-up. For example, a
term grammar might be provided for a given domain, al-
lowing longer terms to be built from shorter terms that
have been identified by term look-up.
The compiler can be parameterized to produce finite
state machines that match exact strings only, or that ab-
STRINGS
string str id
thyroid str12
thyroid disfunction str15
Graves? disease str25
TERMOID STRINGS
trm id str id
trm1 str12
trm2 str12
trm3 str15
trm4 str25
? trm4disease
thyroid
Graves
trm3
trm2
trm1
disfunction
Figure 3: Sample terminological database and finite state term recognizer
stract away from morphological and orthographical vari-
ation. At the moment, morphological information about
strings is supplied by a component outside Termino. In
our current term recognition system, this component ap-
plies to a text before the recognition process and asso-
ciates all verbs and nouns with their base form. Similarly,
the morphological component applies to the strings in the
terminological database before the compilation process.
The set-up in which term recognizers are compiled
from the contents of the terminological database turns
Termino into a general terminological resource which is
not restricted to any single domain or application. The
database can be loaded with terms from multiple domains
and compilation can be restricted to particular subsets of
strings by selecting termoids from the database based on
their source, for example. In this way one can produce
term recognizers that are tailored towards specific do-
mains or specific applications within domains.
4 Implementation & Performance
A first version of Termino has been implemented. It uses
a database implemented in MySQL and currently con-
tains over 427,000 termoids for around 363,000 strings.
Content has been imported from various sources by
means of source-specific scripts for extracting relevant
information from sources and a general script for load-
ing this extracted information into Termino. More specif-
ically, to support information extraction from patient
records, we have included in Termino strings from the
UMLS Metathesaurus falling under the following seman-
tic types: pharmacologic substances, anatomical struc-
tures, therapeutic procedure, diagnostic procedure, and
several others. We have also loaded a list of hu-
man proteins and their assignments to the Gene Ontol-
ogy as produced by the European Bioinformatics Insti-
tute (http://www.ebi.ac.uk/GOA/) into Termino. Further-
more, we have included several gazetteer lists containing
terms in the fields of molecular biology and pharmacol-
ogy that were assembled for previous information extrac-
tion projects in our NLP group. A web services (SOAP)
API to the database is under development. We plan to
make the resource available to researchers as a web ser-
vice or in downloadable form.3
The compiler to construct finite state recognizers from
the database is fully implemented, tested, and integrated
into AMBIT. The compiled recognizer for the 363,000
strings of Termino has 1.2 million states and an on-disk
size of around 80MB. Loading the matcher from disk
into memory requires about 70 seconds (on an UltraSparc
900MHz), but once loaded recognition is a very fast pro-
cess. We have been able to annotate a corpus of 114,200
documents, drawn from electronic patient records from
the Royal Marsden NHS Trust in London and each ap-
proximately 1kB of text, in approximately 44 hours ? an
average rate of 1.4 seconds per document, or 42 docu-
ments per minute. On average, about 30 terms falling un-
der the UMLS ?clinical? semantic types mentioned above
were recognized in each document. We are currently an-
notating a bench-mark corpus in order to obtain precision
and recall figures. We are also planning to compile rec-
ognizers for differently sized subsets of the terminologi-
cal database and measure their recognition speed over a
given collection of texts. This will provide some indica-
tion as to the scalability of the system.
Since Termino currently contains many terms imported
from the UMLS Metathesaurus, it is interesting to com-
pare its term recognition performance against the per-
formance of MetaMap. MetaMap is a program avail-
able from at the National Library of Medicine ? the de-
velopers of UMLS ? specifically designed to discover
UMLS Metathesaurus concepts referred to in text (Aron-
son, 2001). An impressionistic comparison of the per-
formance of Termino and MetaMap on the CLEF patient
records shows that the results differ in two ways. First,
MetaMap recognizes more terms than Termino. This
is simply because MetaMap draws on a comprehensive
version of UMLS, whereas Termino just contains a se-
lected subset of the strings in the Metathesaurus. Sec-
ondly, MetaMap is able to recognize variants of terms,
e.g. it will map the verb to treat and its inflectional forms
onto the term treatment, whereas Termino currently does
not do this. To recognize term variants MetaMap re-
lies on UMLS?s SPECIALIST lexicon, which provides
3Users may have to sign license agreements with third par-
ties in order to be able to use restricted resources that have been
integrated into Termino.
syntactic, morphological, and orthographic information
for many of the terms occurring in the Metathesaurus.
While the performance of both systems differs in favor
of MetaMap, it is important to note that the source of
these differences is unrelated to the actual design of Ter-
mino?s terminological database or Termino?s use of fi-
nite state machines to do term recognition. Rather, the
divergence in performance follows from a difference in
breadth of content of both systems at the moment. With
regard to practical matters, the comparison showed that
term recognition with Termino is much faster than with
MetaMap. Also, compiling a finite state recognizer from
the terminological database in Termino is a matter of min-
utes, whereas setting up MetaMap can take several hours.
However, since MetaMap?s processing is more involved
than Termino?s, e.g. MetaMap parses the input first, and
hence requires more resources, these remarks should be
backed up with a more rigorous comparison between Ter-
mino and MetaMap, which is currently underway.
The advantage of term recognition with Termino over
MetaMap and UMLS or any other recognizer with a sin-
gle source, is that it provides immediate entry points
into a variety of outside ontologies and other knowledge
sources, making the information in these sources avail-
able to processing steps subsequent to term recognition.
For example, for a gene or protein name recognized in a
text, Termino will return the database identifiers of this
term in the HUGO Nomenclature database (Wain et al,
2002) and the OMIM database (Online Mendelian Inher-
itance in Man, OMIM (TM), 2000). These identifiers
give access to the information stored in these databases
about the gene or protein, including alternative names,
gene map locus, related disorders, and references to rele-
vant papers.
5 Conclusions & Future Work
Dealing with terminology is an essential step in natural
language processing in technical domains. In this paper
we have described the design, implementation, and use of
Termino, a large scale terminology resource for biomedi-
cal language processing.
Termino includes a relational database which is de-
signed to store a large number of terms together with
complex, heterogeneous information about these terms,
such as morpho-syntactic information, links to concepts
in ontologies, and other kinds of annotations. The
database is also designed to be extensible: it is easy to
include terms and information about terms found in out-
side biological databases and ontologies. Term look-up
in text is done via finite state machines that are compiled
from the contents of the database. This approach allows
the database to be very rich without sacrificing speed at
look-up time. These three features make Termino a flexi-
ble tool for inclusion in a biomedical text processing sys-
tem.
As noted in section 3.2, Termino has not been designed
to be used as a stand-alone term recognition system but
rather as the first component, the lexical look-up com-
ponent, in a multi-component term processing system.
Since Termino may return multiple terms for a given
string, or for overlapping strings, some post-filtering of
these alternatives is necessary. Secondly, it is likely that
better term recognition performance will be obtained by
supplementing Termino look-up with a term parser which
uses a grammar to give a term recognizer the generative
capacity to recognize previously unseen terms. For ex-
ample, many terms for chemical compounds conform to
grammars that allow complex terms to be built out of sim-
pler terms prefixed or suffixed with numerals separated
from the simpler term with hyphens. It does not make
sense to attempt to store in Termino all of these variants.
Termino provides a firm basis on which to build large-
scale biomedical text processing applications. However,
there are a number of directions where further work can
be done. First, as noted in 3.2, morphological informa-
tion is currently not held in Termino, but rather resides
in an external morphological analyzer. We are working
to extend the Termino data model to enable information
about morphological variation to be stored in Termino,
so that Termino serves as a single source of information
for the terms it contains. Secondly, we are working to
build term induction modules to allow Termino content
to be automatically acquired from corpora, in addition
to deriving it from manually created resources such as
UMLS. Finally, while we have already incorporated Ter-
mino into the AMBIT system where it collaborates with
a term parser to perform more complete term recogni-
tion, more work can be done to with respect to such an
integration. For example, probabilities could be incorpo-
rated into Termino to assist with probabilistic parsing of
terms; or, issues of trade-off between what should be in
the term lexicon versus the term grammar could be fur-
ther explored by looking to see which compound terms
in the lexicon contain other terms as substrings and at-
tempt to abstract away from these to grammar rules. For
example, in the example thyroid disfunction above, both
thyroid and disfunction are terms, the first of class ?body
part?, the second of class ?problem?. Their combination
thyroid disfunction is a term of class ?problem?, suggest-
ing a rule of the form ?problem?   ?body part? ?problem?.
References
A.R. Aronson. 2001. Effective mapping of biomedical
text to the UMLS Metathesaurus: the MetaMap pro-
gram. In Proceedings of the American Medical Infor-
matics Association Symposium, pages 17?21.
R. Gaizauskas and Y. Wilks. 1998. Information extrac-
tion: Beyond document retrieval. Journal of Docu-
mentation, 54(1):70?105.
R. Gaizauskas, G. Demetriou, P. Artymiuk, and P. Wil-
lett. 2003. Protein structures and information extrac-
tion from biological texts: The PASTA system. Jour-
nal of Bioinformatics, 19(1):135?143.
C.A. Goble, C.J. Wroe, R. Stevens, and the my-
Grid consortium. 2003. The myGrid project:
Services, architecture and demonstrator. In
S. Cox, editor, Proceedings of UK e-Science
All Hands Meeting 2003, Nottingham, UK.
http://www.nesc.ac.uk/events/ahm2003/AHMCD/.
R. Grishman. 1997. Information extraction: Techniques
and challenges. In Maria Teresa Pazienza, editor, In-
formation Extraction, pages 10?27. Springer Verlag.
U. Hahn, M. Romacker, and S. Schulz. 2002. Creating
knowledge repositories from biomedical reports: the
medSynDiKATe text mining system. In Proceedings
of the Pacific Symposium on Biocomputing, pages 338?
349.
L. Humphreys, D.A.B. Lindberg, H.M. Schoolman, and
G.O. Barnett. 1998. The Unified Medical Language
System: An informatics research collaboration. Jour-
nal of the American Medical Informatics Association,
1(5):1?13.
K. Humphreys, G. Demetriou, and R. Gaizauskas. 2000.
Two applications of information extraction to biolog-
ical science journal articles: Enzyme interactions and
protein structures. In Proceedings of the Pacific Sym-
posium on Biocomputing, pages 505?516.
A.G. Murzin, S.E. Brenner, T. Hubbard, and C. Chothia.
1995. SCOP: A structural classification of proteins
database for the investigation of sequences and struc-
tures. Journal of Molecular Biology, (247):536?540.
(http://scop.mrc-lmb.cam.ac.uk/scop/).
Online Mendelian Inheritance in Man, OMIM (TM).
2000. McKusick-Nathans Institute for Genetic
Medicine, Johns Hopkins University (Baltimore, MD)
and National Center for Biotechnology Informa-
tion, National Library of Medicine (Bethesda, MD).
http://www.ncbi.nlm.nih.gov/omim/.
J. Pustejovsky, J. Castan?o, R. Saur??, A. Rumshisky,
J. Zhang, and W. Luo. 2002. Medstract: Creat-
ing large-scale information servers for biomedical li-
braries. In Proceedings of the Workshop on Natural
Language Processing in the Biomedical Domain, As-
sociation for Computational Linguistics 40th Anniver-
sary Meeting (ACL-02), pages 85?92.
A. Rector, J. Rogers, A. Taweel, D. Ingram, D. Kalra,
J. Milan, R. Gaizauskas, M. Hepple, D. Scott,
and R. Power. 2003. Joining up health care
with clinical and post-genomic research. In
S. Cox, editor, Proceedings of UK e-Science
All Hands Meeting 2003, Nottingham, UK.
http://www.nesc.ac.uk/events/ahm2003/AHMCD/.
C.T. Rindflesch, J.V. Rajan, and L. Hunter. 2000. Ex-
tracting molecular binding relationships from biomed-
ical text. In Proceedings of the 6th Applied Natu-
ral Language Processing conference / North American
chapter of the Association for Computational Linguis-
tics annual meeting, pages 188?915.
The Gene Ontology Consortium. 2001. Creating the
gene ontology resource: design and implementation.
Genome Research, 11(8):1425?1433.
J. Thomas, D. Milward, C. Ouzounis, and S. Pulman.
2000. Automatic extraction of protein interactions
from scientific abstracts. In Proceedings of the Pacific
Symposium on Biocomputing, pages 538?549.
H.M. Wain, M. Lush, F. Ducluzeau, and S. Povey.
2002. Genew: The human nomenclature
database. Nucleic Acids Research, 30(1):169?171.
(http://www.gene.ucl.ac.uk/nomenclature/).
Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 97?100,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
The GATE Crowdsourcing Plugin: Crowdsourcing Annotated Corpora
Made Easy
Kalina Bontcheva, Ian Roberts, Leon Derczynski, Dominic Rout
University of Sheffield
{kalina,ian,leon,d.rout}@dcs.shef.ac.uk
Abstract
Crowdsourcing is an increasingly popu-
lar, collaborative approach for acquiring
annotated corpora. Despite this, reuse
of corpus conversion tools and user in-
terfaces between projects is still problem-
atic, since these are not generally made
available. This demonstration will intro-
duce the new, open-source GATE Crowd-
sourcing plugin, which offers infrastruc-
tural support for mapping documents to
crowdsourcing units and back, as well as
automatically generating reusable crowd-
sourcing interfaces for NLP classification
and selection tasks. The entire work-
flow will be demonstrated on: annotating
named entities; disambiguating words and
named entities with respect to DBpedia
URIs; annotation of opinion holders and
targets; and sentiment.
1 Introduction
Annotation science (Hovy, 2010; Stede and
Huang, 2012) and general purpose corpus anno-
tation tools (e.g. Bontcheva et al. (2013)) have
evolved in response to the need for creating high-
quality NLP corpora. Crowdsourcing is a popu-
lar collaborative approach that has been applied
to acquiring annotated corpora and a wide range
of other linguistic resources (Callison-Burch and
Dredze, 2010; Fort et al., 2011; Wang et al., 2012).
Although the use of this approach is intensifying,
especially paid-for crowdsourcing, the reuse of an-
notation guidelines, task designs, and user inter-
faces between projects is still problematic, since
these are generally not made available, despite
their important role in result quality (Khanna et
al., 2010).
A big outstanding challenge for crowdsourc-
ing projects is that the cost to define a single
annotation task remains quite substantial. This
demonstration will introduce the new, open-source
GATE Crowdsourcing plugin, which offers in-
frastructural support for mapping documents to
crowdsourcing units, as well as automatically gen-
erated, reusable user interfaces
1
for NLP classi-
fication and selection tasks. Their use will be
demonstrated on annotating named entities (selec-
tion task), disambiguating words and named enti-
ties with respect to DBpedia URIs (classification
task), annotation of opinion holders and targets
(selection task), as well as sentiment (classifica-
tion task).
2 Crowdsourcing Stages and the Role of
Infrastructural Support
Conceptually, the process of crowdsourcing anno-
tated corpora can be broken down into four main
stages, within which there are a number of largely
infrastructural steps. In particular, data prepara-
tion and transformation into CrowdFlower units,
creation of the annotation UI, creation and upload
of gold units for quality control, and finally map-
ping judgements back into documents and aggre-
gating all judgements into a finished corpus.
The rest of this section discusses in more de-
tail where reusable components and infrastructural
support for automatic data mapping and user inter-
face generation are necessary, in order to reduce
the overhead of crowdsourcing NLP corpora.
2.1 Project Definition
An important part of project definition is the map-
ping of the NLP problem into one or more crowd-
sourcing tasks, which are sufficiently simple to be
carried out by non-experts and with a good qual-
ity. What are helpful here are reusable patterns
for how best to crowdsource different kinds of
NLP corpora. The GATE Crowdsourcing plugin
1
Currently for CrowdFlower, which unlike Amazon Me-
chanical Turk is available globally.
97
currently provides such patterns for selection and
classification tasks.
This stage also focuses on setup of the task pa-
rameters (e.g. number of crowd workers per task,
payment per task) and piloting the project, in order
to tune in its design. With respect to task param-
eters, infrastructural support is helpful, in order
to enable automatic splitting of longer documents
across crowdsourcing tasks.
2.2 Data Preparation
This stage, in particular, can benefit significantly
from infrastructural support and reusable compo-
nents, in order to collect the data (e.g. crawl
the web, download samples from Twitter), pre-
process it with linguistic tools (e.g. tokenisation,
POS tagging, entity recognition), and then map
automatically from documents and sentences to
crowdsourcing micro-tasks.
2.3 Running the Crowdsourcing Project
This is the main phase of each crowdsourcing
project. It consists of three kinds of tasks: task
workflow and management, contributor manage-
ment (including profiling and retention), and qual-
ity control. Paid-for marketplaces like Amazon
Mechanical Turk and CrowdFlower already pro-
vide this support. As with conventional corpus an-
notation, quality control is particularly challeng-
ing, and additional NLP-specific infrastructural
support can help.
2.4 Data Evaluation and Aggregation
In this phase, additional NLP-specific, infrastruc-
tural support is needed for evaluating and aggre-
gating the multiple contributor inputs into a com-
plete linguistic resource, and in assessing the re-
sulting overall quality.
Next we demonstrate how these challenges have
been addressed in our work.
3 The GATE Crowdsourcing Plugin
To address these NLP-specific requirements,
we implemented a generic, open-source GATE
Crowdsourcing plugin, which makes it very easy
to set up and conduct crowdsourcing-based corpus
annotation from within GATE?s visual interface.
3.1 Physical representation for documents
and annotations
Documents and their annotations are encoded in
the GATE stand-off XML format (Cunningham
Figure 1: Classification UI Configuration
et al., 2002), which was chosen for its support
for overlapping annotations and the wide range of
automatic pre-processing tools available. GATE
also has support for the XCES standard (Ide et al.,
2000) and others (e.g. CoNLL) if preferred. An-
notations are grouped in separate annotation sets:
one for the automatically pre-annotated annota-
tions, one for the crowdsourced judgements, and
a consensus set, which can be considered as the fi-
nal resulting corpus annotation layer. In this way,
provenance is fully tracked, which makes it possi-
ble to experiment with methods that consider more
than one answer as potentially correct.
3.2 Automatic data mapping to
CrowdFlower
The plugin expects documents to be pre-
segmented into paragraphs, sentences and word
tokens, using a tokeniser, POS tagger, and sen-
tence splitter ? e.g. those built in to GATE (Cun-
ningham et al., 2002). The GATE Crowdsourcing
plugin allows choice between these of which to
use as the crowdsourcing task unit; e.g., to show
one sentence per unit or one paragraph. In the
demonstration we will show both automatic map-
ping at sentence level (for named entity annota-
tion) and at paragraph level (for named entity dis-
ambiguation).
3.3 Automatic user interface generation
The User Interfaces (UIs) applicable to various
task types tend to fall into a set of categories, the
most commonly used being categorisation, selec-
tion, and text input. The GATE Crowdsourcing
plugin provides generalised and re-usable, auto-
matically generated interfaces for categorisation
98
Figure 2: Classification Interface: Sense Disambiguation Example
Figure 3: Sequential Selection Interface: Named Entity Recognition Example
and selection.
In the first step, task name, instructions, and
classification choices are provided, in a UI config-
uration dialog (see Figure 1). In this example, the
instructions are for disambiguating named entities.
We have configured three fixed choices, which ap-
ply to each entity classification task.
For some categorisation NLP annotation tasks
(e.g. classifying sentiment in tweets into posi-
tive, negative, and neutral), fixed categories are
sufficient. In others, where the available category
choices depend on the text that is being classi-
fied (e.g. the possible disambiguations of Paris
are different from those of London), choices are
defined through annotations on each of the clas-
sification targets. In this case case, the UI gen-
erator then takes these annotations as a parame-
ter and automatically creates the different category
choices, specific to each crowdsourcing unit. Fig-
ure 2 shows an example for sense disambiguation,
which combines two unit-specific classes with the
three fixed classification categories shown before.
Figure 3 shows the CrowdFlower-based user in-
terface for word-constrained sequential selection,
which in this case is parameterised for named en-
tity annotation. In sequential selection, sub-units
are defined in the UI configuration ? tokens, for
this example. The annotators are instructed to
click on all words that constitute the desired se-
quence (the annotation guidelines are given as a
parameter during the automatic user interface gen-
eration).
Since the text may not contain a sequence to be
annotated, we also generate an explicit confirma-
tion checkbox. This forces annotators to declare
that they have made the selection or there is noth-
ing to be selected in this text. CrowdFlower can
then use gold units and test the correctness of the
selections, even in cases where no sequences are
selected in the text. In addition, requiring at least
some worker interaction and decision-making in
every task improves overall result quality.
3.4 Quality control
The key mechanism for spam prevention and qual-
ity control in CrowdFlower is test data, which
we also refer to as gold units. These are com-
pleted examples which are mixed in with the un-
processed data shown to workers, and used to
evaluate worker performance. The GATE Crowd-
sourcing plugin supports automatic creation of
gold units from GATE annotations having a fea-
ture correct. The value of that feature is then
taken to be the answer expected from the human
annotator. Gold units need to be 10%?30% of the
units to be annotated. The minimum performance
threshold for workers can be set in the job config-
uration.
3.5 Automatic data import from
CrowdFlower and adjudication
On completion, the plugin automatically imports
collected multiple judgements back into GATE
99
Figure 4: CrowdFlower Judgements in GATE
and the original documents are enriched with the
crowdsourced information, modelled as multiple
annotations (one per contributor). Figure 4 shows
judgements that have been imported from Crowd-
Flower and stored as annotations on the original
document. One useful feature is the trust metric,
assigned by CrowdFlower for this judgement.
GATE?s existing tools for calculating inter-
annotator agreement and for corpus analysis are
used to gain further insights into the quality of the
collected information. If manual adjudication is
required, GATE?s existing annotations stack edi-
tor is used to show in parallel the annotations im-
ported from CrowdFlower, so that differences in
judgement can easily be seen and resolved. Alter-
natively, automatic adjudication via majority vote
or other more sophisticated strategies can be im-
plemented in GATE as components.
4 Conclusion
This paper described the GATE Crowdsourcing
plugin
2
and the reusable components that it pro-
vides for automatic mapping of corpora to micro-
tasks and vice versa, as well as the generic se-
quence selection and classification user interfaces.
These are easily configurable for a wide range
of NLP corpus annotation tasks and, as part of
this demonstration, several example crowdsourc-
ing projects will be shown.
Future work will focus on expanding the num-
ber of reusable components, the implementation
of reusable automatic adjudication algorithms,
and providing support for crowdsourcing through
games-with-a-purpose (GWAPs).
Acknowledgments This was part of the uComp
project (www.ucomp.eu). uComp receives the
funding support of EPSRC EP/K017896/1, FWF
1097-N23, and ANR-12-CHRI-0003-03, in the
framework of the CHIST-ERA ERA-NET.
2
It is available to download from http://gate.ac.uk/ .
References
Kalina Bontcheva, Hamish Cunningham, Ian Roberts,
Angus. Roberts, Valentin. Tablan, Niraj Aswani, and
Genevieve Gorrell. 2013. GATE Teamware: A
Web-based, Collaborative Text Annotation Frame-
work. Language Resources and Evaluation,
47:1007?1029.
Chris Callison-Burch and Mark Dredze. 2010. Cre-
ating speech and language data with Amazon?s Me-
chanical Turk. In Proceedings of the NAACL HLT
2010 Workshop on Creating Speech and Language
Data with Amazon?s Mechanical Turk, pages 1?12.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. GATE:
an Architecture for Development of Robust HLT
Applications. In Proceedings of the 40th An-
nual Meeting on Association for Computational
Linguistics, 7?12 July 2002, ACL ?02, pages
168?175, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Karen Fort, Gilles Adda, and K. Bretonnel Cohen.
2011. Amazon mechanical turk: Gold mine or coal
mine? Computational Linguistics, 37(2):413 ?420.
Eduard Hovy. 2010. Annotation. In Tutorial Abstracts
of ACL.
N. Ide, P. Bonhomme, and L. Romary. 2000. XCES:
An XML-based Standard for Linguistic Corpora.
In Proceedings of the second International Confer-
ence on Language Resources and Evaluation (LREC
2000), 30 May ? 2 Jun 2000, pages 825?830,
Athens, Greece.
Shashank Khanna, Aishwarya Ratan, James Davis, and
William Thies. 2010. Evaluating and improving the
usability of Mechanical Turk for low-income work-
ers in India. In Proceedings of the first ACM sympo-
sium on computing for development. ACM.
Manfred Stede and Chu-Ren Huang. 2012. Inter-
operability and reusability: the science of annota-
tion. Language Resources and Evaluation, 46:91?
94. 10.1007/s10579-011-9164-x.
A. Wang, C.D.V. Hoang, and M. Y. Kan. 2012. Per-
spectives on Crowdsourcing Annotations for Natu-
ral Language Processing. Language Resources and
Evaluation, Mar:1?23.
100
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 19?24,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
AnnoMarket: An Open Cloud Platform for NLP
Valentin Tablan, Kalina Bontcheva
Ian Roberts, Hamish Cunningham
University of Sheffield,
Department of Computer Science
211 Portobello, Sheffield, UK
Initial.Surname@dcs.shef.ac.uk
Marin Dimitrov
Ontotext AD
47A Tsarigradsko Shosse, Sofia, Bulgaria
marin.dimitrov@ontotext.com
Abstract
This paper presents AnnoMarket, an open
cloud-based platform which enables re-
searchers to deploy, share, and use lan-
guage processing components and re-
sources, following the data-as-a-service
and software-as-a-service paradigms. The
focus is on multilingual text analysis re-
sources and services, based on an open-
source infrastructure and compliant with
relevant NLP standards. We demonstrate
how the AnnoMarket platform can be used
to develop NLP applications with little
or no programming, to index the results
for enhanced browsing and search, and
to evaluate performance. Utilising Anno-
Market is straightforward, since cloud in-
frastructural issues are dealt with by the
platform, completely transparently to the
user: load balancing, efficient data upload
and storage, deployment on the virtual ma-
chines, security, and fault tolerance.
1 Introduction
Following the Software-as-a-Service (SaaS)
paradigm from cloud computing (Dikaiakos et al,
2009), a number of text processing services have
been developed, e.g. OpenCalais1 and Alchemy
API2. These provide information extraction ser-
vices, accessible programmatically and charged
per number of documents processed.
However, they suffer from two key technical
drawbacks. Firstly, document-by-document pro-
cessing over HTTP is inefficient on large datasets
and is also limited to within-document text pro-
cessing algorithms. Secondly, the text process-
ing algorithms are pre-packaged: it is not pos-
sible for researchers to extend the functional-
1http://www.opencalais.com
2http://www.alchemyapi.com
ity (e.g. adapt such a service to recognise new
kinds of entities). Additionally, these text pro-
cessing SaaS sites come with daily rate limits,
in terms of number of API calls or documents
that can be processed. Consequently, using these
services for research is not just limited in terms
of text processing functionality offered, but also
quickly becomes very expensive on large-scale
datasets. A moderately-sized collection of tweets,
for example, comprises small but numerous docu-
ments, which can lead to unfeasibly high process-
ing costs.
Platform-as-a-Service (PaaS) (Dikaiakos et al,
2009) are a type of cloud computing service which
insulates developers from the low-level issues of
utilising cloud infrastructures effectively, while
providing facilities for efficient development, test-
ing, and deployment of software over the Inter-
net, following the SaaS model. In the context
of traditional NLP research and development, and
pre-dating cloud computing, similar needs were
addressed through NLP infrastructures, such as
GATE (Cunningham et al, 2013) and UIMA (Fer-
rucci and Lally, 2004). These infrastructures ac-
celerated significantly the pace of NLP research,
through reusable algorithms (e.g. rule-based pat-
tern matching engines, machine learning algo-
rithms), free tools for low-level NLP tasks, and
support for multiple input and output document
formats (e.g. XML, PDF, DOC, RDF, JSON).
This demonstration introduces the AnnoMar-
ket3 open, cloud-based platform, which has
been developed following the PaaS paradigm.
It enables researchers to deploy, share, and
use language processing components and re-
sources, following the Data-as-a-Service (DaaS)
and Software-as-a-Service (SaaS) paradigms. It
gives researchers access to an open, standard-
compliant NLP infrastructure and enables them
3At the time of writing, a beta version of AnnoMarket is
available at http://annomarket.com
19
to carry out large-scale NLP experiments by har-
nessing the vast, on-demand compute power of
the Amazon cloud. It supports not only NLP al-
gorithm development and execution, but also on-
demand collaborative corpus annotation and per-
formance evaluation. Important infrastructural is-
sues are dealt with by the platform, completely
transparently for the researcher: load balancing,
efficient data upload and storage, deployment on
the virtual machines, security, and fault tolerance.
AnnoMarket differs from previous work (e.g.
(Zhou et al, 2010; Ramakrishnan et al, 2010))
in that it requires no programming in order to
run a GATE-compliant NLP application on a large
dataset. In that sense, it combines the ease of
use of an NLP SaaS with the openness and com-
prehensive facilities of the GATE NLP infras-
tructure. AnnoMarket offers a growing number
of pre-packaged services, in multiple languages.
Additionally, as a specialised NLP PaaS, it also
supports a bring-your-own-pipeline option, which
can be built easily by reusing pre-existing GATE-
compatible NLP components and adding some
new ones. Moreover, in addition to offering entity
extraction services like OpenCalais, our NLP PaaS
also supports manual corpus annotation, semantic
indexing and search, and performance evaluation.
The contributions of this paper are as follows:
1. A demonstration of running AnnoMarket
multilingual NLP services on large datasets,
without programming. The new service
deployment facilities will also be shown,
including how services can optionally be
shared with others.
2. A demonstration on shared research corpora
via the AnnoMarket platform, following the
data-as-a-service model (the sharer is respon-
sible for ensuring no copyright violations).
3. A demonstration of the large-scale search and
browsing interface, which uses the results of
the NLP SaaS to offer enhanced, semantic-
based functionality.
2 The AnnoMarket NLP PaaS
This section first discusses the methodology
underpinning the AnnoMarket platform, then
presents its architecture and key components.
2.1 Development and Deployment
Methodology
The development of text analysis algorithms and
pipelines typically follows a certain methodolog-
ical pattern, or lifecycle. A central problem is
to define the NLP task, such that human anno-
tators can perform it with a high level of agree-
ment and to create high quality training and evalu-
ation datasets. It is common to use double or triple
annotation, where several people perform the an-
notation task independently and we then measure
their level of agreement (Inter-Annotator Agree-
ment, or IAA) to quantify and control the quality
of this data (Hovy, 2010).
The AnnoMarket platform was therefore de-
signed to offer full methodological support for all
stages of the text analysis development lifecycle:
1. Create an initial prototype of the NLP
pipeline, testing on a small document collec-
tion, using the desktop-based GATE user in-
terface (Cunningham et al, 2002);
2. If required, collect a gold-standard corpus for
evaluation and/or training, using the GATE
Teamware collaborative corpus annotation
service (Bontcheva et al, 2013), running in
AnnoMarket;
3. Evaluate the performance of the automatic
pipeline on the gold standard (either locally
in the GATE development environment or on
the cloud). Return to step 1 for further devel-
opment and evaluation cycles, as needed.
4. Upload the large datasets and deploy the NLP
pipeline on the AnnoMarket PaaS;
5. Run the large-scale NLP experiment and
download the results as XML or a standard
linguistic annotation format (Ide and Ro-
mary, 2004). AnnoMarket alo offers scal-
able semantic indexing and search over the
linguistic annotations and document content.
6. Analyse any errors, and if required, iterate
again over the earlier steps.
AnnoMarket is fully compatible with the GATE
open-source architecture (Cunningham et al,
2002), in order to benefit from GATE?s numerous
reusable and multilingual text processing compo-
nents, and also from its infrastructural support for
linguistic standards and diverse input formats.
2.2 Architecture
The architecture of the AnnoMarket PaaS com-
prises of four layers (see Figure 1), combining
20
Figure 1: The AnnoMarket Architecture
components with related capabilities. Addition-
ally, we have identified three aspects, which span
across multiple layers.
The Data Layer is described in Section 2.3, the
Platform Layer ? in Section 2.4, and the Annota-
tion Services ? in Section 2.5.
The fourth, web user interface layer, contains a
number of UI components that allow researchers
to use the AnnoMarket platform in various ways,
e.g. to run an already deployed text annotation ser-
vice on a large dataset, to deploy and share a new
service on the platform, or to upload (and option-
ally share) a document collection (i.e. a corpus).
There is also support for finding relevant services,
deployed on the AnnoMarket platform. Lastly,
due to the platform running on the Amazon cloud
infrastructure, there are account management in-
terfaces, including billing information, payments,
and usage reports.
The first vertical aspect is cloud deployment on
Amazon. This covers support for automatic up and
down-scaling of the allocated Amazon resources,
detection of and recovery from Amazon infras-
tructure failures and network failures, and data
backup.
Usage monitoring and billing is the second
key vertical aspect, since fine-grained pay-as-
you-go ability is essential. Even in the case of
freely-available annotations services, Amazon us-
age charges are incurred and thus such function-
ality is needed. Various usage metrics are mon-
itored and metered so that proper billing can be
guaranteed, including: storage space required by
language resources and data sets; CPU utilisation
of the annotation services; number and size of doc-
uments processed.
Security aspects also have impact on all the lay-
ers of the AnnoMarket platform:
? Data Layer ? data encryption and access con-
trol;
? Platform Layer ? data encryption, authentica-
tion and access control;
? Service layer ? authentication and transport
level encryption;
? User Interface layer ? authentication and
transport level encryption.
In addition, we have implemented a REST pro-
gramming API for AnnoMarket, so that data up-
load and download and running of annotation ser-
vices can all be done automatically, outside of
the web interface. This allows tighter integration
within other applications, as well as support for
synchronous (i.e. document-by-document) calling
of the annotation services.
2.3 The Data Layer
The Data Layer stores various kinds of content,
e.g. crawled web content, users? own corpora (pri-
vate or shared with others), results from running
the annotation services, etc.
Input documents can be in all major formats
(e.g., XML, HTML, JSON, PDF, DOC), based
on GATE?s comprehensive format support. In all
cases, when a document is being processed by An-
noMarket, the format is analysed and converted
into a single unified, graph-based model of an-
notation: the one of the GATE NLP framework
(Cunningham et al, 2002). Then this internal an-
notation format is also used by the collaborative
corpus annotation web tool, and for annotation in-
dexing and search. Annotations produced can be
exported as in-line or stand-off XML, including
XCES (Ide and Romary, 2004).
In implementation terms, Amazon S3 is used to
store content on the platform. S3 provides a REST
service for content access, as well as direct HTTP
access, which provides an easy way for AnnoMar-
ket users to upload and download content.
While stored on the cloud, data is protected by
Amazon?s security procedures. All transfers be-
tween the cloud storage, the annotation services,
and the user?s computer are done via an encrypted
channel, using SSL.
2.4 The Platform Layer
The AnnoMarket platform provides an environ-
ment where text processing applications can be de-
ployed as annotation services on the cloud. It al-
lows processing pipelines that were produced on a
21
Figure 2: Web-based Job Editor
developer?s stand-alone computer to be deployed
seamlessly on distributed hardware resources (the
compute cloud) with the aim of processing large
amounts of data in a timely fashion. This process
needs to be resilient in the face of failures at the
level of the cloud infrastructure, the network com-
munication, errors in the processing pipeline and
in the input data.
The platform layer determines the optimal num-
ber of virtual machines for running a given NLP
application, given the size of the document collec-
tion to be processed and taking into account the
overhead in starting up new virtual machines on
demand. The implementation is designed to be ro-
bust in the face of hardware failures and process-
ing errors. For technical details on the way this
was implemented on Amazon EC2 see (Tablan et
al., 2013).
The GATE plugin-based architecture (Cunning-
ham et al, 2002) is the basis for the platform en-
vironment. Users can upload any pipelines com-
pliant with the GATE Processing Resource (PR)
model and these are automatically deployed as an-
notation services on the AnnoMarket platform.
2.5 Annotation Services
As discussed above, the platform layer in An-
noMarket addresses most of the technical and
methodological requirements towards the NLP
PaaS, making the deployment, execution, and
sharing of annotation services (i.e. pipelines and
algorithms) a straightforward task. From a re-
searcher?s perspective, executing an annotation
service on a dataset involves a few simple steps:
? Upload the document collection to be pro-
cessed or point the system to a shared dataset
on the platform;
? Upload a GATE-based processing pipeline to
be used (or choose an already deployed anno-
tation service);
? Set any required parameter values;
? Press the ?Start? button.
While the job is running, a regularly updated
execution log is made available in the user?s dash-
board. Upon job completion, an email notification
is also sent. Most of the implementation details are
hidden away from the user, who interacts with the
system through a web-based job editor, depicted
in Figure 2, or through a REST API.
The number of already deployed annotation ser-
vices on the platform is growing continuously.
Figure 3 shows a subset of them, as well as the
metadata tags associated with these services, so
that users can quickly restrict which types of ser-
vices they are after and then be shown only the
relevant subset. At the time of writing, there are
services of the following kinds:
? Part-of-Speech-Taggers for English, German,
Dutch, and Hungarian.
? Chunking: the GATE NP and VP chunkers
and the OpenNLP ones;
? Parsing: currently the Stanford Parser 4, but
more are under integration;
? Stemming in 15 languages, via the Snowball
stemmer;
? Named Entity Recognition: in English, Ger-
man, French, Arabic, Dutch, Romanian, and
Bulgarian;
? Biomedical taggers: the PennBio5 and the
AbGene (Tanabe and Wilbur, 2002) taggers;
? Twitter-specific NLP: language detection, to-
kenisation, normalisation, POS tagging, and
4http://nlp.stanford.edu/software/lex-parser.shtml
5http://www.seas.upenn.edu/?strctlrn/BioTagger/BioTagger.html
22
Figure 3: Pre-deployed Text Annotation Services
Figure 4: Creating a New Annotation Service
NER.
The deployment of new annotation services is
done via a web interface (see Figure 4), where an
administrator needs to configure some basic de-
tails related to the utilisation of the platform layer
and provide a self-contained GATE-compatible
application. Platform users can only publish their
own annotation services by contacting an adminis-
trator, who can validate the provided pipeline be-
fore making it publicly available to the other users.
This step is intended to protect the users commu-
nity from malicious or poor quality pipelines.
3 Search and Browsing of Annotated
Corpora
The AnnoMarket platform also includes a service
for indexing and searching over a collection of se-
mantically annotated documents. The output of an
annotation service (see Figure 2) can be fed di-
rectly into a search index, which is created as the
service is run on the documents. This provides fa-
cilities for searching over different views of doc-
ument text, for example one can search the docu-
ment?s words, the part-of-speech of those words,
or their morphological roots. As well as searching
the document text, we also support searches over
the documents? semantic annotations, e.g. named
entity types or semantic roles.
Figure 5 shows a semantic search over 80,000
news web pages from the BBC. They have
first been pre-processed with the POS tagging,
morphological analysis, and NER services on
the platform and the output indexed automat-
ically. The search query is for documents,
where entities of type Person are followed by
any morphological form of the verb say, i.e.
{Person} root:say.
4 Conclusion
This paper described a cloud-based open platform
for text mining, which aims to assist the develop-
ment and deployment of robust, large-scale text
processing applications. By supporting the shar-
ing of annotation pipelines, AnnoMarket alo pro-
23
Figure 5: Example Semantic Search Results
motes reuse and repeatability of experiments.
As the number of annotation services offered by
the platform has grown, we identified a need for
service search, so that users can locate useful NLP
services more effectively. We are currently devel-
oping a new UI, which offers search and brows-
ing functionality, alongside various criteria, such
as functionality (e.g. POS tagger, named entity
recogniser), user ratings, natural language sup-
ported). In the medium- to long-term we have
also planned to support UIMA-based pipelines,
via GATE?s UIMA compatibility layer.
A beta version is currently open to researchers
for experimentation. Within the next six months
we plan to to solicit more shared annotation
pipelines to be deployed on the platform by other
researchers.
Acknowledgments
This work was supported by the European Union
under grant agreement No. 296322 AnnoMarket,6
and a UK EPSRC grant No. EP/I004327/1.
References
Kalina Bontcheva, Hamish Cunningham, Ian Roberts,
Angus. Roberts, Valentin. Tablan, Niraj Aswani, and
Genevieve Gorrell. 2013. GATE Teamware: A
Web-based, Collaborative Text Annotation Frame-
work. Language Resources and Evaluation.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. Gate: an
architecture for development of robust hlt applica-
tions. In Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, 7?12
July 2002, ACL ?02, pages 168?175, Strouds-
burg, PA, USA. Association for Computational
Linguistics.
Hamish Cunningham, Valentin Tablan, Angus Roberts,
and Kalina Bontcheva. 2013. Getting more out of
biomedical documents with gate?s full lifecycle open
6See http://www.annomarket.eu/.
source text analytics. PLoS Computational Biology,
9(2):e1002854, 02.
Marios D Dikaiakos, Dimitrios Katsaros, Pankaj
Mehra, George Pallis, and Athena Vakali. 2009.
Cloud computing: Distributed internet computing
for IT and scientific research. IEEE Internet Com-
puting, 13(5):10?13.
David Ferrucci and Adam Lally. 2004. UIMA: An
Architectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327?348.
Eduard Hovy. 2010. Annotation. In Tutorial Abstracts
of ACL.
Nancy Ide and Laurent Romary. 2004. Standards for
language resources. Natural Language Engineer-
ing, 10:211?225.
C. Ramakrishnan, W. A. Baumgartner, J. A. Blake,
G. A. P. C. Burns, K. Bretonnel Cohen, H. Drabkin,
J. Eppig, E. Hovy, C. N. Hsu, L. E. Hunter, T. Ingulf-
sen, H. R. Onda, S. Pokkunuri, E. Riloff, C. Roeder,
and K. Verspoor. 2010. Building the scientific
knowledge mine (SciKnowMine): a community-
driven framework for text mining tools in direct ser-
vice to biocuration. In New Challenges for NLP
Frameworks (NLPFrameworks 2010), LREC 2010,
pages 9?14, Valletta, Malta, May. ELRA.
Valentin Tablan, Ian Roberts, Hamish Cunningham,
and Kalina Bontcheva. 2013. GATECloud.net: a
Platform for Large-Scale, Open-Source Text Pro-
cessing on the Cloud. Philosophical Transactions
of the Royal Society A: Mathematical, Physical &
Engineering Sciences, 371(1983):20120071.
Lorraine Tanabe and W. John Wilbur. 2002. Tag-
ging Gene and Protein Names in Full Text Articles.
In Proceedings of the ACL-02 workshop on Natural
Language Processing in the biomedical domain, 7?
12 July 2002, volume 3, pages 9?13, Philadelphia,
PA. Association for Computational Linguistics.
Bin Zhou, Yan Jia, Chunyang Liu, and Xu Zhang.
2010. A distributed text mining system for online
web textual data analysis. In Cyber-Enabled Dis-
tributed Computing and Knowledge Discovery (Cy-
berC), 2010 International Conference on, pages 1?
4, Los Alamitos, CA, USA, October. IEEE Com-
puter Society.
24
