Coling 2010: Poster Volume, pages 214?222,
Beijing, August 2010
Hybrid Decoding: Decoding with Partial Hypotheses Combination over
Multiple SMT Systems?
Lei Cui?, Dongdong Zhang?, Mu Li?, Ming Zhou?, and Tiejun Zhao?
?School of Computer Science and Technology
Harbin Institute of Technology
{cuilei,tjzhao}@mtlab.hit.edu.cn
?Microsoft Research Asia
{dozhang,muli,mingzhou}@microsoft.com
Abstract
In this paper, we present hybrid decod-
ing ? a novel statistical machine transla-
tion (SMT) decoding paradigm using mul-
tiple SMT systems. In our work, in ad-
dition to component SMT systems, sys-
tem combination method is also employed
in generating partial translation hypothe-
ses throughout the decoding process, in
which smaller hypotheses generated by
each component decoder and hypotheses
combination are used in the following de-
coding steps to generate larger hypothe-
ses. Experimental results on NIST evalu-
ation data sets for Chinese-to-English ma-
chine translation (MT) task show that our
method can not only achieve significant
improvements over individual decoders,
but also bring substantial gains compared
with a state-of-the-art word-level system
combination method.
1 Introduction
In recent years, system combination for SMT has
been known to be quite effective with translation
consensus information built from multiple SMT
systems. The combination approaches can be
classified into two types. One is the combination
with each system?s outputs, which can be seen as
full hypotheses combination. The other is the par-
tial hypotheses (PHS) combination during the de-
coding phase.
A lot of impressive work has been done to im-
prove the performance of the SMT systems by uti-
?This work has been done while the first author was vis-
iting Microsoft Research Asia.
lizing consensus statistics which come from sin-
gle system or multiple systems. For example,
Minimum Bayes Risk (MBR) (Kumar and Byrne,
2004) decoding over n-best list finds a translation
that has lowest expected loss with all the other hy-
potheses, and it shows that improvement over the
Maximum a Posteriori (MAP) decoding. Several
word-based methods (Rosti et al, 2007a; Sim et
al., 2007) have also been proposed. Usually, these
methods take n-best list from different SMT sys-
tems as inputs, and construct a confusion network
for second-pass decoding. There are also a lot of
research work to advance the confusion network
construction by finding better alignment between
the skeleton and the other hypotheses (He et al,
2008; Ayan et al, 2008). Typically, all the ap-
proaches above only use full hypotheses but have
no access to the PHS information.
Moreover, some dedicated efforts have been
tried by manipulating PHS between multiple MT
systems. Collaborative decoding (co-decoding)
(Li et al, 2009) leverages translation consensus
by exchanging partial translation results and re-
ranking both full and partial hypotheses explored
in decoding. However, no new PHS are generated
compared to the individual decoding but only the
ranking is affected. Liu et al (2009) proposes
joint decoding, a method that integrates multiple
translation models in one decoder. Although joint
decoding is able to generate new translations com-
pared to single decoder, it has to use the PHS
existed in one of its component decoder at each
step. Different from their work, we propose a
new perspective which leverages outputs from lo-
cal word-level combination. This will potentially
bring much benefit of performance since word-
214
level combination can produce more promising
PHS.
The word-level system combination method is
employed to generate partial translation hypothe-
ses in our hybrid decoding framework. In this
sense, full hypotheses word-level combination
(FH-Comb) method(Rosti et al, 2007a; Sim et al,
2007; He et al, 2008; Ayan et al, 2008) can be
considered as a special case of hybrid decoding,
where their combinations are only performed on
the largest hypotheses. Similar with FH-Comb,
hybrid decoding also uses word alignment infor-
mation. However, challenge exists in hybrid de-
coding as word alignment needs to be carefully
conducted through the decoding process. Obvi-
ously, document-level word alignment methods
such as GIZA++(Och and Ney, 2000) are quite
time consuming and unpractical to be embedded
into hybrid decoding. We propose a heuristic
method that can conduct word alignment of par-
tial hypotheses based on word alignment informa-
tion of phrase pairs learnt automatically from the
model training process. In this way, more PHS are
generated and the search space is enlarged sub-
stantially, which brings better translation results.
The rest of the paper is organized as follows:
Section 2 gives a formal description of hybrid
decoding, including framework overview, word-
level PHS combination and parameter estimation.
We conduct experiments with different settings
and make comparison between our method and
baseline, as well as a state-of-the-art word-level
system combination method in Section 3. Exper-
imental results discussion is presented in Section
4. Section 5 concludes the paper.
2 Hybrid Decoding
2.1 Overview
Different system combination methods (Li et al,
2009; Liu et al, 2009) offer different frameworks
to coordinate multiple SMT decoders. Hybrid de-
coding provides a new scheme to organize mul-
tiple decoders to work synchronously. As the
decoding algorithms may differ in multiple de-
coders1, hybrid decoding has some difficulty in
1In the SMT area, some decoders use left-right decod-
ing to generate the hypothesis and?Pharaoh?(Koehn et al,
integrating different decoding algorithms. With-
out loss of generality, we assume that bottom-up
CKY-based decoding is adopted in each individ-
ual decoder, which is the same as co-decoding
(Li et al, 2009) and joint decoding (Liu et al,
2009). Hybrid decoding collects n-best PHS of a
source span2 from multiple decoders, then results
from word-level PHS combination of that span are
given back to each decoder, mixed with the origi-
nal PHS. After that, we re-rank the hybrid list and
continue the decoding. In an example with two
decoders, parts of the whole decoding process are
illustrated in Figure 1 and can be summarized as
follows:
3-5 6-6 3-4 5-6
3-6 3-6
1-2 3-6 1-2
1-6 1-6
1-6
Decoder1 Decoder2
Local decoding layer
Local decoding layer
Local decoding layer
Local combination layer
Local combination layer
3-6 3-6
1-6 1-6
Figure 1: Hybrid decoding with two decoders,
where the string ?s-e?means the source span
starts from position s and ends at position e. The
blank rectangles represent the n-best partial trans-
lations of each decoder, and the shaded rectan-
gles illustrate the n-best local combination out-
puts. The ovals denote bottom-up CKY-based de-
coding results.
2003) is one of them, while others adopt bottom-up decoding
which is represented by?Hiero?(Chiang, 2007).
2The word ?span?is used to represent translation unit
in CKY-based decoders, which denotes one or more consec-
utive words in the source sentence.
215
1. Individual decoding. Each individual de-
coder should maintain the n-best PHS of
each span from the bottom. After all the in-
dividual decoders finish translating the same
span, they feed their own partial translations
into a public container which can be used for
word-level PHS combination, then get back
the partial combination outputs for step 3.
2. Local word-level combination. After fed
with PHS from multiple decoders, a confu-
sion network is built and word-level combi-
nation for PHS is conducted. The obtained
new partial translations are given back to
each individual decoder to continue the de-
coding.
3. Mix new PHS with the original ones. The
span in each individual decoder will receive
the corresponding new PHS from the local
combination outputs. The feature space of
the new PHS is not exactly the same with that
of the original ones. It has to be mapped in
some way then the mixed hypotheses are re-
ranked.
In the following sub-sections, we first present
the background of word-level combination for
PHS, then introduce hybrid decoding algorithm in
detail, as well as the feature definition and param-
eter estimation.
2.2 Word-Level Combination for Partial
Hypotheses
Most word-level system combination methods are
based on confusion network decoding. In con-
fusion network construction, one hypothesis has
to be selected as the skeleton which determines
the word order of the combination results. Other
hypotheses are aligned against the skeleton. Ei-
ther votes or some word confidence scores are as-
signed to each word in the network.
Most of the research on confusion network con-
struction focuses on seeking better word align-
ment between the skeleton and the other hypothe-
ses. So far, several word alignment procedures are
used for SMT system combination, which mainly
are GIZA++ alignments (Matusov et al, 2006),
TER alignments (Sim et al, 2007) and IHMM
??||| political ||| 0-0
????||| political and economic ||| 0-0 1-2
??||| economic ||| 0-0
????||| economic interests ||| 0-0 1-1
?? [X1] ||| political and [X1] ||| 0-0 1-2
Figure 2: The example of translation alignment
from phrase-table and rule-table
alignments (He et al, 2008). Similar with general
word-level system combination method, word-
level PHS combination also uses word alignment
information. However, in hybrid decoding, it is
quite time-consuming and impractical to conduct
word alignment like GIZA++ for each span. For-
tunately, unit hypotheses word alignment can be
obtained from the model training process, which
is shown in Figure 2. We devise a heuristic
approach for PHS alignment that leverages the
translation derivations from the sub-phrases. The
derivation information ultimately comes from the
phrase table in phrase-based systems (Koehn et
al., 2003; Xiong et al, 2006) or the rule table in
syntactic-based systems (Chiang, 2007; Liu et al,
2007; Galley et al, 2006).
The derivation is built in a phrase-based sys-
tem as follows. For example, we have two phrase
translations ??? ? ||| our ||| 0-0 1-0?and
????? ||| economic interests ||| 0-0 1-1?,
where string ?m-n?means the mth word in the
source phrase is aligned to the nth word in the tar-
get phrase. When combining the two phrases for
generating ??? ? ?? ???, we obtain
the translation hypothesis as ?our economic in-
terests?and also integrate the alignment fragment
to get ?0-0 1-0 2-1 3-2?. The case is similar in
syntactic-based system for non-terminal substitu-
tion, which we will not discuss further here.
Next, we introduce the skeleton-to-hypothesis
word alignment algorithm in detail. With the
translation derivations, the skeleton-to-hypothesis
(sk2hy) word alignment can be performed based
on the source-to-skeleton (so2sk) and source-to-
hypothesis (so2hy) word alignment as they share
the same source sentence. The basic idea is to
construct the sk2hy word alignment with the min-
imum correspondence subsets (MCS). A MCS is
defined as a triple < SK,HY, SO > where the
216
SK is the subset of skeleton words, HY is the
subset of the hypothesis words, and SO is the
minimum source word set that all target words in
both SK and HY are aligned to. Figure 3 shows
the algorithm for skeleton-to-hypothesis align-
ment. Most of the pseudo-code is self-explained
except for some subroutines, which are listed in
Table 1.
1: procedure SKEHYPALIGN(so2sk, so2hy)
2: repeat
3: Fetch out a source word to SO
4: SO1 = SO2 = SO
5: repeat
6: SO=UNION(SO1, SO2)
7: SK=GETALIGN(SO, so2sk)
8: HY =GETALIGN(SO, so2hy)
9: SO1=GETALIGN(SK, so2sk)
10: SO2=GETALIGN(HY, so2hy)
11: until |SO1| == |SO2| == |SO|
12: simmax = ?infinity
13: for all sk ? SK do
14: for all hy ? HY do
15: sim =SIM(sk, hy)
16: if sim ? simmax then
17: simmax = sim
18: skmax = sk
19: hymax = hy
20: end if
21: end for
22: end for
23: ADDALIGN(skmax, hymax)
24: until all the source words are fetched out
25: end procedure
Figure 3: Algorithm for skeleton-to-hypothesis
alignment
Subroutines Description
UNION(A,B) the union of set A and set B
GETALIGN(S,align) get the words aligned to
S based on align
SIM(w1,w2) similarity between w1 and w2,
we use edit distance here
ADDALIGN(w1,w2) align w1 with w2
Table 1: Description for subroutines
Due to the variety of the word order in n-
best outputs, skeleton selection becomes essen-
tial in confusion network construction. The sim-
plest way is to use the top-1 PHS from any indi-
vidual decoder with the best performance under
some criteria. However, this cannot always lead
to better performance on some evaluation met-
rics (Rosti et al, 2007a). An alternative would
be MBR method with some loss function such as
TER (Snover et al, 2006) or BLEU (Papineni et
al., 2002). We show the experimental results of
two skeleton selection methods for PHS combina-
tion in Section 3.
2.3 Hybrid Decoding Model
For a given source sentence f , any individual de-
coder in hybrid decoding finds the best transla-
tion e? among the possible translation hypotheses
?(f) in terms of a ranking function F :
e? = argmaxe??(f)F(e) (1)
Suppose we have n individual decoders. The
ranking function Fn of the nth decoder can be
written as:
Fn(e) =
m?
i=1
?n,ihn,i(f, e) (2)
where each hn,i(f, e) is a feature function of the
nth decoder, and ?n,i is the corresponding feature
weight. m is the number of features in each de-
coder.
The final result of hybrid decoder is the top-
1 translation from the confusion network, which
is constructed on multiple decoders with the last
layer?s output of CKY-based decoding.
2.4 Hybrid Decoding Algorithm
The hybrid decoder acts as a control unit which
controls the synchronization of multiple individ-
ual decoders. The algorithm is fully demonstrated
in Figure 4. The hybrid decoder pushes the same
span f ji to different decoders and gets back the n-
best PHS (lines 2-6). When the span?s length is
too small, both word alignment and partial com-
bination results are not accurate. We predefine a
fixed threshold ? which is used for determining the
start-up of combination (line 7). When the length
condition holds, the n-best PHS of each individual
217
decoder are stored in container G (lines 8). Con-
fusion network is constructed and new PHS can be
extracted from it and are further mixed and sorted
with the original ones (lines 11-15).
1: procedure HYBRIDDECODING(fn1 , D)
2: for l? 1...n do
3: for all i, j s.t. j ? i = l do
4: G? ?
5: for all d ? D do
6: nbest =DECODING(d, i, j)
7: if j ? i ? ? then
8: ADD(G,nbest)
9: end if
10: end for
11: cn =CONNETBUILD(G)
12: nbest? =GETPARHYP(cn)
13: for all d ? D do
14: MIXSORT(nbestd, nbest?)
15: end for
16: end for
17: end for
18: end procedure
Figure 4: Hybrid decoding algorithm
2.5 Hybrid Decoding Features
Next we present the PHS word-level combination
feature functions for hybrid decoding. Following
(Rosti et al, 2007b), four features are utilized to
model the PHS as:
Word Confidence Feature hwc(e)
The word confidence feature is computed as
hwc(e) =
?n
i=1 ?iciw, where n is the num-
ber of the systems, ?i is the system confi-
dence of system i, and ciw is the word confi-
dence of word w in system i.
Word Penalty Feature hwp(e)
Word penalty feature is the number of words
in the partial hypothesis (PH).
Null Penalty Feature hnp(e)
For null penalty feature, we mean the number
of NULL links along the PH when extracted
from the confusion network.
Language Model Feature hlm(e)
Different from the above three combination
features, which can be obtained during the
confusion network construction or hypothe-
ses extraction, the language model feature
cannot be summed up on the fly. Instead,
it must be re-computed when building each
new PH.
2.6 Feature Space Mapping
The features used in hybrid decoding can be clas-
sified into two categories: features for individual
decoders (FID) and features for PHS word-level
combination (FComb), and they are independent.
When mixing the new PHS with the original ones
of individual decoders, FComb space has to be
mapped to a FID space. However, several features
in FID are not defined in FComb, such as source
to target (S2T) phrase probability, target to source
(T2S) phrase probability, S2T lexical probability,
T2S lexical probability and other model specific
features. A mapping function H needs to be de-
fined as follows:
Ffid = H(Ffcomb) (3)
where Ffcomb denotes the feature vector from
FComb space, while Ffid is the feature vector
from FID space.
An easy mapping function is implemented with
an intuitive motivation: PHS combination results
are better than the ones in individual decoder and
we prefer not to disorder the original search space.
Thus, the undefined feature values of PHS from
FComb space are assigned by corresponding fea-
ture values of the top-1 PH in original decoder.
Experiments show that our method is not only
practical but also quite effective.
2.7 Parameter Estimation
Minimum Error Rate Training (MERT) (Och,
2003) algorithm is adopted to estimate feature
weights for hybrid decoding. As hybrid decoder
makes use of PHS from both individual decoders
and combination results as a whole, we devise
a new feature vector representation. The feature
vectors from FID space and FComb space are sim-
ply concatenated to form a longer vector without
overlapping. The weights are tuned simultane-
ously in order to reach a relatively global optima.
218
3 Experiment
3.1 Data and Metric
We conducted our experiments on the test data
of NIST 2005 and NIST 2006 Chinese-to-English
machine translation tasks. The NIST 2003 test
data is used as the development data to tune the
parameters. Statistics of the data sets are shown in
Table 2. Translation performances are measured
with case-insensitive BLEU4 score (Papineni et
al., 2002). Statistical significance test is per-
formed using the bootstrap re-sampling method
proposed by Koehn (2004).
The bilingual training corpora we used are
listed in Table 3, which contains 498K sentence
pairs, 12.1M Chinese words and 13.8M English
words after pre-processing. Word alignment is
performed by GIZA++ (Och and Ney, 2000) in
both directions with the default setting, and the
intersect-diag-grow method is used to refine the
symmetric word alignment.
Data Set # Sentences
NIST 2003(dev) 919
NIST 2005(test) 1,082
NIST 2006(test) 1,664
Table 2: Statistics of test/dev data sets
LDC ID Description
LDC2003E07 Ch/En Treebank Par Corpus
LDC2003E14 FBIS Multilanguage Texts
LDC2005T06 Ch News Translation Text Part 1
LDC2005T10 Ch/En News Magazine Par Text
LDC2005E83 GALE Y1 Q1 Release - Translations
LDC2006E26 GALE Y1 - En/Ch Par Financial News
LDC2006E34 GALE Y1 Q2 Release - Translations
V2.0
LDC2006E85 GALE Y1 Q3 Release - Translations
LDC2006E92 GALE Y1 Q4 Release - Translations
Table 3: Training corpora for Chinese-English
translation
The language model used for hybrid decoding
and all the baseline systems is a 5-gram model
trained with the Xinhua portion of LDC English
Gigaword Version 3.0 plus the English part of
bilingual training data.
3.2 Implementation
We use two baseline systems. The first one
(SYS1) is re-implementation of Hiero, a hi-
erarchical phrase-based system (Chiang, 2007)
based on Synchronous Context Free Grammar
(SCFG). Phrasal translation rules and hierarchi-
cal translation rules with nonterminals are ex-
tracted from all the bilingual sentence pairs.
The second one (SYS2) is a phrase-based sys-
tem (Xiong et al, 2006) based on Bracketing
Transduction Grammar (Wu, 1997) with a lex-
icalized reordering model (Zhang et al, 2007)
under maximum entropy framework, where the
phrasal translation rules are exactly the same
with that of SYS1. The lexicalized reorder-
ing model is trained using the MaxEnt toolkit
(Zhang, 2006) where the training instances are
extracted from subset of the training corpora,
which contains LDC2003E07, LDC2003E14,
LDC2005T06, LDC2005T10. Both systems use
the bottom-up CKY-based decoding with cube-
pruning (Chiang, 2007) and the beam size is set
to 10 for decoding efficiency.
For hybrid decoder, we set ? to be
sentence.length ? 3, meaning that the PHS of
individual decoders only perform local combi-
nation in the last three layers. The reason why
we adopt this setting is because we find that
starting local combination on short spans hurts
the performance badly on test data. Experimental
results are shown in the next section.
3.3 Translation Results
We present the overall results of hybrid decod-
ing over two baseline systems on both test sets.
We also implement an IHMM-based word-level
system combination method (He et al, 2008) to
make comparison with hybrid decoding system,
and the n-best candidates used for IHMM-based
word-level system combination is set to 10. Pa-
rameters for all the systems are tuned on NIST
2003 test set. The results are shown in Table 4.
In Table 4, we find that the hybrid decoding per-
forms significantly better than SYS1 and SY2 on
both test sets. Besides, compared to IHMM word-
level system combination method, hybrid decod-
ing also brings substantial gains with 0.63% and
0.92% points respectively.
219
NIST 2005 NIST 2006
SYS1 0.3745 0.3346
SYS2 0.3699 0.3296
IHMM Word-Comb 0.3821? 0.3421?
Hybrid 0.3884?+ 0.3513?+
Table 4: Hybrid decoding results on test sets,
*:significantly better than SYS1 and SYS2 with
p<0.01, +:significantly better than IHMM Word-
Comb with p<0.01
We also try different layers for determining
the start-up of local word-level PHS combination.
Figure 5 gives the intuitive BLEU results.
 
0.32
0.33
0.34
0.35
0.36
0.37
0.38
0.39
0.4
Figure 5: Performance of hybrid decoding with
different start-up settings on NIST 2005 test set,
where the ?lastM? means to conduct local word-
level PHS combination in the last M layers from
the perspective of CKY-based decoding.
As shown in Figure 5, the performance drops
drastically if we start to conduct word-level PHS
combination too early. After considering about ef-
ficiency and performance, we determine to do that
in the last three layers.
We then investigate the effects on hybrid de-
coding with different beam sizes, and compare the
trend with two baseline systems and IHMM-based
word-level system combination method as well.
The results are illustrated in Figure 6.
From what we see in Figure 6, the performance
of each system is monotonically increasing as the
beam size becomes larger. Hybrid decoding per-
forms consistently better than IHMM Word-Comb
when the beam size is small, and the largest im-
provement (+0.63% points) is obtained when the
beam size is set to 10. However, as the beam size
 
0.355
0.36
0.365
0.37
0.375
0.38
0.385
0.39
0.395
0.4
10 20 50 100
SYS1
SY S2
IHMM
Hybrid
Figure 6: Performance of hybrid decoding with
different beam sizes on NIST 2005 test set
increases, the performance gap is getting narrow.
One intuitive observation is that hybrid decoding
performs slightly worse than IHMM Word-Comb
when the beam size is set to 100. One possible
reason for this phenomenon is that, the alignment
noise may be introduced to hybrid decoding since
we have to generate monolingual alignments with
many poor translation derivations.
The confusion network for PHS of each system
can be built independently. We would like to eval-
uate the performance of single system hybrid de-
coding. Table 5 gives the results on both Hiero
and BTG decoders.
NIST 2005 NIST 2006
SYS1 SYS2 SYS1 SYS2
baseline 0.3745 0.3699 0.3346 0.3296
self-comb 0.3770 0.3758? 0.3358 0.3355?
Table 5: Hybrid decoding for single system,
*:significantly better than baseline with p<0.05
Table 5 shows that BTG decoder (SYS2) has
more potential for so-called ?self-boosting?.
The self-combination of BTG decoder improves
the performance substantially over the baseline.
However, we did not observe any significant im-
provement for Hiero decoder (SYS1).
Finally, we examine the impacts of skeleton se-
lection for PHS in hybrid decoding. The results in
Table 6 demonstrate that, compared to the top-1
selection method, translation performance can be
improved significantly with MBR-based skeleton
selection method. It strongly suggests that choos-
ing the skeleton with more consistent word order
220
will lead to better translation results.
NIST 2005 NIST 2006
Top-1 0.3817 0.3415
MBR 0.3884? 0.3513?
Table 6: Skeleton selection in hybrid decoding,
*:significantly better than top-1 skeleton selection
method with p<0.01
4 Discussion
System combination methods have been widely
used in SMT to improve the performance. For
example, in (Rosti et al, 2007a), several combi-
nation methods have been proposed to make use
of different kinds of consensus information. In
(He et al, 2008), better word alignment method is
adopted to advance the word-level system combi-
nation. Our method is different from these meth-
ods in the sense that we do not exclusively rely
on the n-best full hypotheses from each individual
decoder, but emphasize the importance of word-
level combination for PHS. Thus, it enlarges the
search space and is more prone to find better trans-
lations. Experimental results have shown the ef-
fectiveness of our method.
The idea of multiple systems collaborative de-
coding (Li et al, 2009) works well on re-ranking
the outputs of each system using n-gram agree-
ment statistics. However, no new translation re-
sults are generated compared to individual decod-
ing. Our method takes advantage of confusion
network to give PHS which cannot be seen before.
Although (Liu et al, 2009) also work on PHS,
we explore the cooperation of multiple systems
from a new perspective. They use translation
derivations from different decoders jointly as a
bridge to connect different models. Different from
their work, we devise a heuristic method to ob-
tain word alignment information from the deriva-
tion of each decoder, which can be embedded
for word-level PHS combination easily and effi-
ciently.
5 Conclusion and Future Work
In this paper, we propose a new SMT decoding
framework named hybrid decoding, in which mul-
tiple decoders work synchronously to conduct lo-
cal decoding and local word-level PHS combina-
tion in turn. We also devise a heuristic method to
obtain word alignment information directly from
the translation derivations, which is both intuitive
and efficient. Experimental results show that with
hybrid decoding the overall performance can be
improved significantly over both the individual
baseline decoder and the state-of-the-art system
combination method.
In the future, we will involve more individual
SMT decoders into hybrid decoding. In addition,
we would like to keep on this work in two direc-
tions. On the one hand, start-up threshold of PHS
combination will be explored in detail to find its
underlying impact on hybrid decoding. On the
other hand, we will try to employ a more theoreti-
cally sound approach to conduct the feature space
mapping from the feature space of confusion net-
work to that of individual decoders.
References
Ayan, Necip Fazil, Jing Zheng, and Wen Wang. 2008.
Improving alignments for better confusion networks
for combining machine translation systems. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics, pages 33-40
Chiang, David. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associ-
ation for Computational Linguistics, pages 263-270
Chiang, David. 2007. Hierarchical phrase-based
translation. Computational Linguistics, 33(2):
pages 201-228
Galley, Michel, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Pro-
ceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 961-968
He, Xiaodong, Mei Yang, Jianfeng Gao, Patrick
Nguyen, and Robert Moore. 2008. Indirect-hmm-
based hypothesis for combining outputs from ma-
chine translation systems. In Proceedings of the
2008 Conference on Empirical Methods in Natural
Language Processing, pages 98-107
Koehn, Phillip, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceed-
221
ings of the 2003 Human Language Technology Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics, pages 48-54
Koehn, Phillip. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing, pages 388-395
Kumar, Shankar and William Byrne. 2004. Minimum
bayes-risk decoding for statistical machine trans-
lation. In Proceedings of the 2004 Human Lan-
guage Technology Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics, pages 169-176
Li, Mu, Nan Duan, Dongdong Zhang, Chi-Ho Li, and
Ming Zhou. 2009. Collaborative decoding: par-
tial hypothesis re-ranking using translation consen-
sus between decoders. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP, pages 585-
592
Liu, Yang, Yun Huang, Qun Liu, and Shouxun Lin.
2007. Forest-to-string statistical translation rules.
In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics, pages
704-711
Liu, Yang, Haitao Mi, Yang Feng, and Qun Liu. 2009.
Joint decoding with multiple translation models. In
Proceedings of the Joint Conference of the 47th An-
nual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing
of the AFNLP, pages 576-584
Matusov, Evgeny, Nicola Ueffing, and Hermann Ney.
2006. Computing consensus translation from mul-
tiple machine translation systems using enhanced
hypotheses alignment. In 11th Conference of the
European Chapter of the Association for Computa-
tional Linguistics, pages 33-40
Och, Franz Josef. and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association for Compu-
tational Linguistics, pages 440-447
Och, Franz Josef. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proceed-
ings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 160-167
Papineni, Kishore, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 311-318
Rosti, Antti-Veikko, Necip Fazil Ayan, Bing Xiang,
Spyros Matsoukas, Richard Schwartz, and Bonnie
Dorr. 2007. Combining outputs from multiple ma-
chine translation systems. In Proceedings of the
2007 Human Language Technology Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 228-235
Rosti, Antti-Veikko, Spyros Matsoukas, and Richard
Schwartz. 2007. Improved word-level system com-
bination for machine translation. In Proceedings of
the 45th Annual Meeting of the Association of Com-
putational Linguistics, pages 312-319
Sim, K.C., W. Byrne, M. Gales, H. Sahbi, and P.
Woodland. 2007. Consensus network decoding
for statistical machine translation combinnation. In
32nd IEEE International Conference on Acoustics,
Speech, and Signal Processing
Snover, Matthew, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciula, and John Makhoul. 2006. A study of
translation edit rate with targeted human annota-
tion. In the 7th conference of the Association for
Machine Translation in the Americas, pages 223-
231
Wu, Dekai. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel cor-
pora. Computational Linguistics, 23(3): pages 377-
404
Xiong, Deyi, Qun Liu, and Shouxun Lin. 2006.
Maximum entropy based phrase reordering model
for statistical machine translation. In Proceedings
of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, pages
521-528
Zhang, Dongdong, Mu Li, Chi-Ho Li, Ming Zhou.
2007. Phrase Reordering Model Integrating Syn-
tactic Knowledge for SMT. In Proceedings of the
2007 Joint Conference on Empirical Methods in
Natural Language Processing and Computational
Natural Language Learning, pages 533-540
Zhang, Le. 2006. Maximum entropy model-
ing toolkit for python and c++. available at
http://homepages.inf.ed.ac.uk/
lzhang10/maxent_toolkit.html.
222
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1055?1065,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Multi-domain Adaptation for SMT Using Multi-task Learning?
Lei Cui1, Xilun Chen2, Dongdong Zhang3, Shujie Liu3, Mu Li3, and Ming Zhou3
1Harbin Institute of Technology, Harbin, P.R. China
leicui@hit.edu.cn
2Cornell University, Ithaca, NY, U.S.
xlchen@cs.cornell.edu
3Microsoft Research Asia, Beijing, P.R. China
{dozhang,shujliu,muli,mingzhou}@microsoft.com
Abstract
Domain adaptation for SMT usually adapts
models to an individual specific domain.
However, it often lacks some correlation
among different domains where common
knowledge could be shared to improve the
overall translation quality. In this paper, we
propose a novel multi-domain adaptation ap-
proach for SMT using Multi-Task Learning
(MTL), with in-domain models tailored for
each specific domain and a general-domain
model shared by different domains. The pa-
rameters of these models are tuned jointly via
MTL so that they can learn general knowledge
more accurately and exploit domain knowl-
edge better. Our experiments on a large-
scale English-to-Chinese translation task val-
idate that the MTL-based adaptation approach
significantly and consistently improves the
translation quality compared to a non-adapted
baseline. Furthermore, it also outperforms the
individual adaptation of each specific domain.
1 Introduction
Domain adaptation is an active topic in statisti-
cal machine learning and aims to alleviate the do-
main mismatch between training and testing data.
Like many machine learning tasks, Statistical Ma-
chine Translation (SMT) assumes that the data dis-
tributions of training and testing domains are sim-
ilar. However, this assumption does not hold for
real world SMT systems since training data for
SMT models may come from a variety of domains.
The translation quality is often unsatisfactory when
?This work was done while the first and second authors were
visiting Microsoft Research Asia.
translating texts from a specific domain using a gen-
eral model that is trained over a hotchpotch of bilin-
gual corpora. Therefore, domain adaptation is cru-
cial for SMT systems to achieve better performance.
Previous research on domain adaptation for SMT
includes data selection and weighting (Eck et al,
2004; Lu? et al, 2007; Foster et al, 2010; Moore and
Lewis, 2010; Axelrod et al, 2011), mixture mod-
els (Foster and Kuhn, 2007; Koehn and Schroeder,
2007; Sennrich, 2012; Razmara et al, 2012), and
semi-supervised transductive learning (Ueffing et
al., 2007), etc. Most of these methods adapt SMT
models to a specific domain according to testing data
and have achieved good performance. It is natural
that real world SMT systems should adapt the mod-
els to multiple domains because the input may be
heterogeneous, so that the overall translation qual-
ity can be improved. Although we can easily ap-
ply these methods to multiple domains individually,
it is difficult to use the common knowledge across
different domains. To leverage the common knowl-
edge, we need to devise a multi-domain adaptation
approach that jointly adapts the SMT models.
Multi-domain adaptation has been proved quite
effective in sentiment analysis (Dredze and Cram-
mer, 2008) and web ranking (Chapelle et al, 2011),
where the commonalities and differences across
multiple domains are explicitly addressed by Multi-
task Learning (MTL). MTL is an approach that
learns one target problem with other related prob-
lems at the same time, using a shared feature repre-
sentation. The key advantage of MTL is to enable
implicit data sharing and regularization. Therefore,
it often leads to a better model for each task. Anal-
ogously, we expect that the overall translation qual-
ity can be further improved by using an MTL-based
1055
TM1
S1 S2 S3
Multiple In-domain 
Translation Models
& Language Models
One General-domain 
Translation Model
& Language Model
T1
LM1
TM2
LM2
TM3
LM3
Domain-specific 
SMT Systems
In-domain
Training Data T2 T3
T
MTL-based Tuning
Entire
Training Data
TM-G
LM-G
TMN
LMN
TN
SN
...
...
...
...
Figure 1: An example with N pre-defined domains, where T is the entire training corpus. Ti is the in-domain training
data for the i-th domain selected from T using the bilingual cross-entropy based method (Axelrod et al, 2011). The
in-domain TMi and LMi are trained using the in-domain training data Ti. The general-domain models TM-G and LM-
G are trained using the entire training corpus T . Si is the domain-specific SMT system for the i-th domain, leveraging
the in-domain models and the general-domain models as features.
multi-domain adaptation approach.
In this paper, we use MTL to jointly adapt SMT
models to multiple domains. Specifically, we de-
velop multiple SMT systems based on mixture mod-
els, where each system is tailored for one specific
domain with an in-domain Translation Model (TM)
and an in-domain Language Model (LM). Mean-
while, all the systems share a same general-domain
TM and LM. These SMT systems are considered as
several related tasks with a shared feature represen-
tation, which fits well into a unified MTL frame-
work. With the MTL-based joint tuning, general
knowledge can be better learned by the general-
domain models, while domain knowledge can be
better exploited by the in-domain models as well.
By using a distributed stochastic learning approach
(Simianer et al, 2012), we can estimate the fea-
ture weights of multiple SMT systems at the same
time. Furthermore, we modify the algorithm to treat
in-domain and general-domain features separately,
which brings regularization to multiple SMT sys-
tems in an efficient way. Experimental results have
shown that our method can significantly improve the
translation quality on multiple domains over a non-
adapted baseline. Moreover, the MTL-based adap-
tation also outperforms the conventional individual
adaptation approach towards each domain.
The rest of the paper is organized as follows: The
proposed approach is explained in Section 2. Exper-
imental results are presented in Section 3. Section 4
introduces some related work. Section 5 concludes
the paper and suggests future research directions.
2 The Proposed Approach
Figure 1 gives an example with N pre-defined do-
mains to illustrate the main idea. There are three
steps in the training phase. First, in-domain train-
ing data is selected according to the pre-defined do-
mains (Section 2.1). Second, in-domain models and
general-domain models are trained to develop the
domain-specific SMT systems (Section 2.2). Third,
multiple domain-specific SMT systems are tuned
jointly by using an MTL-based approach (Section
2.3).
2.1 In-domain Data Selection
In the first step, in-domain bilingual data is selected
from all the bilingual data to train in-domain TMs.
We use the bilingual cross-entropy based approach
(Axelrod et al, 2011) to obtain the in-domain data:
[HI?src(s)?HG?src(s)]+[HI?tgt(t)?HG?tgt(t)] (1)
1056
where {s,t} is a bilingual sentence pair in the entire
bilingual corpus. HI?xxx(?) and HG?xxx(?) repre-
sent the cross-entropy of a string according to an in-
domain LM and a general-domain LM, respectively.
?xxx? denotes either the source language (src) or the
target language (tgt). HI?src(s)?HG?src(s) is the
cross-entropy difference of string s between the in-
domain and general-domain source-side LMs, and
HI?tgt(t) ? HG?tgt(t) is the cross-entropy differ-
ence of string t between the in-domain and general-
domain target-side LMs. This criterion biases to-
wards sentence pairs that are like the in-domain cor-
pus but unlike the general-domain corpus. There-
fore, the sentence pairs with lower scores (larger dif-
ferences) are presumed to be better.
Now, the question is how to find sufficient mono-
lingual data to train in-domain LMs. A straight-
forward solution is to collect the data from the in-
ternet. There are a large number of monolingual
webpages with domain information from web por-
tal sites1, which can be collected to train in-domain
LMs. In large-scale real world SMT systems, practi-
cal domain adaptation techniques should target more
domains rather than just one due to heterogeneous
input. Therefore, we use a web crawler to collect
monolingual webpages ofN domains from web por-
tal sites, for both the source language and the tar-
get language. The statistics of web-crawled data is
given in Section 3.1. We use the web-crawled mono-
lingual documents to train N in-domain source-side
LMs and N in-domain target-side LMs. Addition-
ally, we also train the source-side and target-side
general-domain LMs with all the web-crawled doc-
uments from different domains. Finally, these in-
domain and general-domain LMs are used to select
in-domain bilingual data for different domains ac-
cording to Formula (1).
2.2 SMT Systems with Mixture Models
In the second step, with the selected in-domain train-
ing data, we develop SMT systems based on mix-
ture models. In particular, we use the mixture model
based approach proposed by Koehn and Schroeder
1Many web portal sites contain domain information
for webpages, such as ?www.yahoo.com? in English and
?www.sina.com.cn? in Chinese and etc. The webpages are of-
ten categorized by human editors into different domains, such
as politics, sports, business, etc.
(2007). Specifically, we have developed N SMT
systems for N domains respectively, where each
system is a typical log-linear model. For each sys-
tem, the best translation candidate f? is given by:
f? = argmax
f
{P (f |e)} (2)
where the translation probability P (f |e) is given by:
P (f |e) ?
?
i
wi ? log ?i(f, e)
=
?
j?I
wj ? log ?j(f, e)
? ?? ?
In-domain
+
?
k?G
wk ? log ?k(f, e)
? ?? ?
General domain
(3)
where ?j(f, e) is the in-domain feature function and
wj is the corresponding feature weight. ?k(f, e) is
the general-domain feature function and wk is the
feature weight. The detailed feature description is
as follows:
In-domain features
? An in-domain TM, including phrase translation
probabilities and lexical weights for both direc-
tions (4 features)
? An in-domain target-side LM (1 feature)
? word count (1 feature)
? phrase count (1 feature)
? NULL penalty (1 feature)
? Number of hierarchical rules used (1 feature)
General-domain features
? A general-domain TM, including phrase trans-
lation probabilities and lexical weights for both
directions (4 features)
? A general-domain target-side LM (1 feature)
The feature description indicates that each SMT
system contains two TMs and two LMs. The in-
domain TMs are trained using the selected bilin-
gual training data according to Formula (1), and the
general-domain TM is trained using the entire bilin-
gual training data. For the LMs, we re-use the target-
side in-domain LMs and general-domain LM trained
1057
for data selection (Section 2.1). Compared with a
normal single-model system, the system with mix-
ture models can balance the contributions from the
general-domain and in-domain knowledge. Hence it
potentially benefits from both.
2.3 MTL-based Tuning
In the third step, the feature weights in multiple
domain-specific SMT systems are estimated. In-
stead of tuning each domain-specific system sepa-
rately, we treat different systems as related tasks and
tune them jointly in an MTL framework. There are
two main reasons for MTL-based tuning:
1. Domain-specific translation tasks share the
same general-domain LM and TM. MTL often
leads to better performance by leveraging com-
monalities among different tasks.
2. By enforcing that the general-domain LM and
TM perform equally across different domains,
MTL provides a kind of regularization to pre-
vent over-fitting.
Formally, the objective function of the proposed
MTL-based approach is described as follows:
min
W
{
N?
i=1
Loss(Ei, e?(Fi,wi))
}
(4)
where N is the number of pre-defined domains.
{Fi,Ei} is the in-domain development dataset for the
i-th domain. Fi denotes the source sentences and Ei
denotes the reference translations. wi is a D-length
feature weight column vector for the i-th domain,
where D is the dimension of the feature space. W is
a N -by-D matrix, representing [w1|w2| . . . |wN ]T .
e?(Fi,wi) are the best translations obtained for Fi
with parameters wi. Loss(?, ?) denotes the loss be-
tween the system?s output and the reference trans-
lations. The basic idea of the objective function is
to minimize the sum of loss functions for all the do-
mains, rather than one domain at a time. Therefore,
by adjusting the in-domain and general-domain fea-
ture weights, the translation quality is expected to be
good across different domains.
To effectively tune SMT systems jointly, we mod-
ify the asynchronous Stochastic Gradient Descend
(SGD) Algorithm (Simianer et al, 2012) to optimize
objective function (4). We follow the pairwise rank-
ing approach with the perceptron algorithm (Shen
and Joshi, 2005) to update feature weights. Let a
translation candidate be denoted by its feature vector
v ? RD, the pairwise preference for training is con-
structed by ranking two candidates according to the
smoothed sentence-level BLEU (Liang et al, 2006).
For a preference pair v[j]=(v(1), v(2)) where v(1) is
preferred, a hinge loss is used:
L(wi) = (??wi, v(1) ? v(2)?)+ (5)
where (x)+ = max(0, x) and ??, ?? denotes the in-
ner product of two vectors. With the perceptron al-
gorithm (Shen and Joshi, 2005), the gradient of the
hinge loss is:
?L(wi) =
{
v(2) ? v(1) if?wi, v(1) ? v(2)? ? 0
0 otherwise
(6)
The training instances for the discriminative
learning in pairwise ranking are made by comparing
the N-best list of the translation candidates scored
by the smoothed sentence-level BLEU (Liang et al,
2006). Following Simianer et al (2012), the N-best
list is divided into three bins: the top 10% (High),
the middle 80% (Middle), and the last 10% (Low).
These bins are used for pairwise ranking where the
translation preference pairs are built between the
candidates in High-Middle, Middle-Low, and High-
Low, but not the candidates within the same bin,
which is shown in Figure 2. The idea is to guar-
antee that the ranker is more discriminative to prefer
the good translations to the bad ones.
High: 10%
Middle: 80%
Low: 10%
N-best list
Figure 2: Training instances for pairwise ranking.
1058
Algorithm 1 Modified Asynchronous SGD
1: Distribute N domain-specific decoders to N ma-
chines
2: Initialize w1,w2, . . . ,wN ? 0
3: for epochs t? 0 . . . T ? 1 do
4: for all domains d ? {1 . . . N}: parallel do
5: ud,t,0,0 = wd
6: S = |Fd|
7: for all i ? {0 . . . S ? 1} do
8: Decode i-th sentence with ud,t,i,0
9: P = No. of pairs built from the N-best list
10: for all pairs v[j], j ? {0 . . . P ? 1} do
11: ud,t,i,j+1 ? ud,t,i,j ? ??L(ud,t,i,j)
12: end for
13: ud,t,i+1,0 ? ud,t,i,P
14: end for
15: end for
16: for all domains d ? {1 . . . N} do
17: wd = ud,t,S,0
18: end for
19: WG ? [wG1 | . . . |w
G
N ]
T
20: for all domains d ? {1 . . . N} do
21: for k ? 1 . . . |wGd | do
22: wGd [k] =
1
N
?N
n=1 W
G[n][k]
23: end for
24: wd ?
[wId
wGd
]
25: end for
26: end for
27: return w1,w2, . . . ,wN
Our modified algorithm is illustrated in Algorithm
1. Each column vector wi is further split into two
parts wIi and w
G
i , representing the In-domain and
General-domain feature weights respectively. In Al-
gorithm 1, we first distribute the domain-specific
SMT decoders to different machines and initialize
the feature weights (line 1-2). Typically, the SGD al-
gorithm runs in several iterations (In this study, we
set the number of epochs T to 20) (line 3). Multi-
ple SMT decoders run in parallel and each decoder
updates its feature weights individually using its in-
domain development data (line 4-15). For each do-
main, the domain-specific decoder translates each
in-domain development sentence and determines the
N-best translations (line 4-8). The preference pairs
are built and used to update the parameters by gra-
dient descent with ? = 0.0001 (line 9-13). Each
domain-specific decoder translates its in-domain de-
velopment data multiple times. After each itera-
tion, feature weights from all decoders are collected
(line 16-19). In contrast to the original algorithm
(Simianer et al, 2012), we only average the general-
domain feature weights wG1 , . . . ,w
G
N , but do not av-
erage the in-domain feature weights (line 20-25).
The reason is we hope to leverage the commonalities
among these systems. Meanwhile, general knowl-
edge is enforced to be conveyed equally across dif-
ferent domains. Finally, the algorithm returns all
the domain-specific feature weights w1,w2, . . . ,wN
that are used for testing (line 27).
After the joint MTL-based tuning, the feature
weights tailored for domain-specific SMT systems
are used to translate the testing data. We collect in-
domain testing data for each domain to evaluate the
domain-specific systems. Although this is not al-
ways the case in real applications where the testing
domain is known, this study mainly focuses on the
effectiveness of the MTL-based tuning approach.
3 Experiments
3.1 Data
We evaluated our MTL-based domain adaptation
approach on a large-scale English-to-Chinese ma-
chine translation task. The training data consisted
of two parts: monolingual data and bilingual data.
The monolingual data was used to train the source-
side and target-side LMs, both of which were used
for data selection in Section 2.1. In addition, the
target-side LMs were re-used in the SMT systems
as features. As mentioned in Section 2.1, we built a
web crawler to collect a large number of webpages
from web portal sites in English and Chinese respec-
tively. In the experiments, we mainly focused on six
popular domains, namely Business, Entertainment,
Health, Science & Technology, Sports, and Politics.
For both English and Chinese webpages, the HTML
tags were removed and the main content was ex-
tracted. The data statistics are shown in Table 1.
The bilingual data we used was mainly mined
from the web using the method proposed by Jiang
et al (2009), with a post-processing step using our
bilingual data cleaning method (Cui et al, 2013).
Therefore, the data quality is pretty good. In addi-
tion, we also used the English-Chinese parallel cor-
pus released by LDC2. In total, the bilingual data
2LDC2003E07, LDC2003E14, LDC2004E12,
LDC2005T06, LDC2005T10, LDC2005E83, LDC2006E26,
1059
Domain
English Chinese
Docs Words Docs Words
Business 21M 10.4B 7.91M 2.73B
Ent. 18.3M 8.29B 4.16M 1.31B
Health 8.7M 4.73B 0.9M 0.42B
Sci&Tech 10.9M 5.33B 5.28M 1.6B
Sports 18.9M 9.58B 2.49M 0.59B
Politics 10.3M 5.56B 1.67M 0.39B
Table 1: Statistics of web-crawled monolingual data, in
numbers of documents and words (main content). ?M?
refers to million and ?B? refers to billion.
contained around 30 million sentence pairs, with
404M words in English and 329M words in Chi-
nese. For each domain, we used the cross-entropy
based method in Section 2.1 to rank the entire bilin-
gual data, and the top 10% sentence pairs from the
ranked bilingual data were selected as the in-domain
data to train the in-domain TM. Moreover, we pre-
pared 2,000 in-domain sentences for development
and 1,000 in-domain sentences for testing in each
domain. The details are shown in Table 2.
Domain
Train Dev Test
En Ch En Ch En Ch
Business 30M 28M 36K 35K 19K 19K
Ent. 25M 22M 21K 18K 13K 12K
Health 23M 20M 33K 33K 21K 22K
Sci&Tech 28M 26M 46K 45K 27K 27K
Sports 19M 16M 18K 14K 10K 9K
Politics 28M 24M 19K 17K 13K 12K
Table 2: Statistics of in-domain training, development
and testing data, in number of words.
3.2 Setup
An in-house hierarchical phrase-based SMT de-
coder was implemented for our experiments. The
CKY decoding algorithm was used and cube prun-
ing was performed with the same default parameter
settings as in Chiang (2007). We used a 100-best
list from the decoder for the pairwise ranking al-
gorithm. Translation models were trained over the
bilingual data that was automatically word-aligned
using GIZA++ (Och and Ney, 2003) in both direc-
tions, and the diag-grow-final heuristic was used to
LDC2006E34, LDC2006E85, LDC2006E92.
refine the symmetric word alignment. The phrase
tables were filtered to retain top-20 translation can-
didates for each source phrase for efficiency. An
in-house language modeling toolkit was used to
train the 4-gram language models with modified
Kneser-Ney smoothing (Kneser and Ney, 1995) over
the web-crawled data. The evaluation metric for
the overall translation quality was case-insensitive
BLEU4 (Papineni et al, 2002). A statistical sig-
nificance test was performed using the bootstrap re-
sampling method (Koehn, 2004).
3.3 Baseline
We have two baselines. The first baseline is a non-
adapted Hiero using our implementation. It con-
tained the general-domain TM and LM, as well as
other standard features. In addition, the fix-discount
method (Foster et al, 2006) for phrase table smooth-
ing was also used. The system was general-domain
oriented and it was tuned by using MERT (Och,
2003) with a combination of six in-domain develop-
ment datasets. The second baseline is Google Online
Translation Service3. We obtained the English-to-
Chinese translations of the testing data from Google
Translation to have a more solid comparison.
Moreover, we also compared our method with the
adapted systems towards each domain individually
(Koehn and Schroeder, 2007). This is to demon-
strate the superiority of our MTL-based tuning ap-
proach across different domains.
3.4 Results
The end-to-end translation performance is shown in
Table 3. We found that the baseline has a similar
performance to Google Translation, with certain do-
mains performed even better (Business, Sci&Tech,
Sports, Politics). This demonstrates that the transla-
tion quality of our baseline is state-of-the-art. More-
over, we can answer three questions according to the
experimental results as follow:
First, is domain mismatch a significant prob-
lem for a real world SMT system? We used the
same system only with general-domain TM and LM,
but tuned towards each domain individually using
in-domain dev data. Table 3 shows that the setting
?[A] G-TM + G-LM? performs much better than
3http://translate.google.com
1060
Business Ent. Health Sci&Tech Sports Politics
[N] Baseline (G-TM + G-LM) 27.19 17.87 25.79 25.34 25.53 23.01
Google Translation 26.01 18.44 27.71 25.07 24.08 22.97
[A] G-TM + G-LM 29.58 19.08 28.80 26.84 30.28 25.64
[A] I-TM + I-LM 28.20 17.25 27.20 25.41 30.12 22.97
[A] (G+I)-TM + G-LM 29.45 19.22 28.93 27.01 31.01 25.40
[A] (G+I)-TM + I-LM 29.60 19.43 28.94 27.05 34.36 25.98
[A] (G+I)-LM + G-TM 29.66 19.50 29.00 27.10 33.60 26.03
[A] (G+I)-LM + I-TM 28.50 17.66 27.58 25.99 30.44 23.30
[A] (G+I)-TM + (G+I)-LM 29.82 19.53 29.03 26.94 33.77 26.09
[A,MTL] (G+I)-TM + (G+I)-LM 30.26 19.94 29.08 27.17 34.11 26.50
Table 3: End-to-end experimental results (BLEU4%) with large-scale training data (p < 0.05). ?[N]? means the system
is non-adapted and tuned using MERT on general-domain dev data. ?[A]? denotes that the system is adapted towards
each domain individually using MERT on in-domain dev data. ?[A,MTL]? indicates that the system was tuned using
our MTL-based approach on in-domain dev data. ?I-TM? and ?G-TM? denote the in-domain and general-domain
translation model. ?I-LM? and ?G-LM? denote the in-domain and general-domain language model. We also obtained
translations of the testing data using Google Translation for comparison.
the non-adapted baseline across all domains with at
least 1.2 BLEU points. In addition, the setting ?[A]
G-TM + G-LM? also outperforms Google Transla-
tion on all domains. Analogous to previous research,
this confirms that the domain mismatch indeed ex-
ists and the parameter estimation using in-domain
dev data is quite useful.
Second, does the mixture models based adap-
tation work for a variety of domains? We experi-
mented with different settings with multiple TMs or
LMs, or both. It is interesting to note that for large-
scale SMT systems, using in-domain models alone
is inferior to using the general models alone. The
setting ?[A] G-TM + G-LM? is better than the set-
ting ?[A] I-TM + I-LM? across different domains.
The reason is the data for general models has already
included the in-domain data and the data coverage is
much larger, thus the probability estimation is more
reliable and the translation quality is much better.
For the LM, the in-domain LM performs better
than the general-domain LM because our mono-
lingual data (Table 1) for each domain is already
sufficient for training an in-domain LM with good
performance. From Table 3, we observed that the
setting ?[A] (G+I)-TM + I-LM? outperforms ?[A]
(G+I)-TM + G-LM?, with the ?Sports? domain be-
ing the most significant. For the TM, the per-
formance of the in-domain TM is inferior to the
general-domain TM. The results show that the set-
ting ?[A] (G+I)-LM + G-TM? is significantly better
than ?[A] (G+I)-LM + I-TM?. The main reason is
the data coverage for in-domain TM is much smaller
than the general model. When each system uses two
TMs and two LMs, it consistently results in better
performance, indicating that mixture models are cru-
cial for domain adaptation in SMT.
Third, can MTL further improve the transla-
tion quality? We used the MTL-based approach to
jointly tune multiple domain-specific systems, lever-
aging the commonalities among different but related
tasks. From Table 3, the MTL-based approach sig-
nificantly improve the translation quality over the
non-adapted baseline, and also outperforms conven-
tional mixture models based methods. In particular,
the ?Sports? domain benefits the most from the in-
domain knowledge, which confirms that domain dis-
crepancy should be addressed and may bring large
improvements on certain domains.
3.5 Discussion
According to our experiments, only averaging over
the out-of-domain feature weights returned robust
and converged results. We do not have theoreti-
cally grounded guarantee. However, we observed
that the BLEU score of our method on DEV data
was slightly lower than that in the baseline system,
which indicates the out-of-domain features are less
over-fitting on the domain-specific DEV data since
1061
SOURSE A point begins with a player serving the ball. This means one player hits
the ball towards the other player. (The serve must be played from behind the
baseline and must
::::
land in the service box . Players get two attempts to make
a good serve.)
REF ? ? ? ? ???? ? ? ? ? ? ? ? ? ???? ? ? ????
??(??????????????????
::::
????? ??? ??
????????????)
[N] Baseline (G-TM + G-LM) ????????????????????????????
(???????????????
:::::::
??? ??? ????????
????????)
[A] (G+I)-TM + (G+I)-LM ???????????????? ????????(???
???????? ??? ?
:::::
????????????????
????)
[A,MTL](G+I)-TM + (G+I)-LM ????????????? ???????????(????
??????????
:::::::
??? ??? ????????????
????)
Table 4: Examples illustrating some different translations, where the Chinese phrases are translated from the English
phrases with the same symbols (e.g., underline, wavy-line, and box). The details are explained in Section 3.5.
we enforced them to play the same role across dif-
ferent domains. It seems that averaging the out-of-
domain feature weights can be considered as a kind
of regularization.
An example sentence from the Sports domain
with translations from different methods is shown
in Table 4. In this sentence, the baseline always
translates ?player? to ???? (game player), which
should be ???? (ball player). And, the base-
line translates ?serve? to ???? (work for), which
should be ???? (put the ball into play). The phrase
?service box? here means ?????, which denotes
the zone where the ball is to be served. However, the
baseline incorrectly splits them into two words, then
translates ?service? to ???? and ?box? to ???.
In contrast, the approaches with adapted models are
able to translate these words very well.
Both our MTL-based approach and the conven-
tional adaptation methods leverage the mixture mod-
els. A natural question is why our MTL-based ap-
proach performs better than the individual adapta-
tion. To answer this question, we looked into the
details of the tuning and decoding procedures in the
MTL-based approach. We observed that the BLEU
score on the development data for each system was
lower than the score when conducting individual
adaptation. Considering that the algorithm enforc-
ing the general features play the same role across
different domains, we suspect that MTL-based ap-
proach introduces a kind of regularization for each
domain-specific system. The regularization prevents
the general features from biasing towards certain do-
mains to the extreme. This property is quite impor-
tant for real world SMT systems. Usually, a sen-
tence is composed of some domain-specific words
and some general words, so it is often improper to
translate every word in the sentence using the in-
domain knowledge. For the example in Table 4,
the individual adaptation method ?[A] (G+I)-TM +
(G+I)-LM? translates ?land? to ???? (zone) im-
properly, because ???? appears more often in the
Sports text than the general-domain text. This shows
that the individual adaptation methods tend to over-
fit the in-domain development data. In contrast, the
MTL-based approach ?[A,MTL](G+I)-TM + (G+I)-
LM? just translates ?land? to ????? (fall on),
which is more appropriate.
4 Related Work
4.1 Domain Adaptation
One direction of domain adaptation explored the
data selection and weighting approach to improve
the performance of SMT on specific domains. Eck
1062
et al (2004) first decoded the testing data with a
general TM, and then used the translation results
to train an adapted LM, which was in turn used to
re-decode the testing data. Lu? et al (2007) tried
to weight the training data according to the similar-
ity with test data using information retrieval mod-
els, while Foster et al (2010) trained a discrimina-
tive model to estimate a weight for each sentence
in the training corpus. Other methods conducted
data selection based on cross-entropy (Moore and
Lewis, 2010), and Axelrod et al (2011) further ex-
tended their cross-entropy based method to the se-
lection of bilingual corpus in the hope that more rel-
evant corpus to the target domain could yield smaller
models with better performance. Other methods
included using semi-supervised transductive learn-
ing techniques to exploit the monolingual in-domain
data (Ueffing et al, 2007).
Adaptation methods also involved the utiliza-
tion of mixture models. Foster and Kuhn (2007)
explored a number of variants of utilizing multi-
ple TMs and LMs by interpolation. Koehn and
Schroeder (2007) used MERT to simultaneously
tune two TMs or LMs. Sennrich (2012) investi-
gated the TM perplexity minimization as a method
to set model weights in mixture modeling. In ad-
dition, inspired by system combination approaches,
Razmara et al (2012) used the ensemble decoding
method to mix multiple translation models, which
outperformed a variety of strong baselines.
Generally, most previous methods merely con-
ducted domain adaption for a single domain, rather
than multiple domains at the same time. One could
also simply build multiple SMT systems that were
adapted to multiple domains, but they were often
separated and not tuned together. So far, there has
been little research into the multi-domain adaptation
problem over mixture models for SMT systems, as
proposed in this paper.
4.2 Multi-task Learning
In machine learning, MTL is an approach to learn
one target problem with other related problems at
the same time. This often leads to a better model for
the main task because it allows the learner to use the
commonality among the tasks. MTL is performed
by learning tasks in parallel while using a shared
representation. Therefore, what is learned for each
task can help other tasks be learned better.
MTL was successfully applied in some Natu-
ral Language Processing (NLP) tasks. For exam-
ple, Blitzer et al (2006) extended the MTL ap-
proach (Ando and Zhang, 2005) to domain adapta-
tion tasks in part-of-speech tagging. Collobert and
Weston (2008) proposed using deep neural networks
to train a set of tasks, including part-of-speech tag-
ging, chunking, named entity recognition, and se-
mantic roles labeling. They reported that jointly
learning these tasks led to superior performance.
MTL was also applied in sentiment analysis (Dredze
and Crammer, 2008) and web ranking (Chapelle
et al, 2011) to address the multi-domain learning
and adaptation. In SMT, Duh et al (2010) pro-
posed using MTL for N-best re-ranking on sparse
feature sets, where each N-best list corresponded to
a distinct task. Simianer et al (2012) proposed dis-
tributed stochastic learning with feature selection in-
spired by MTL. The distributed learning approach
outperformed several other training methods includ-
ing MIRA and SGD.
Inspired by these methods, we used MTL to tune
multiple SMT systems at the same time, where each
system was composed of in-domain and general-
domain models. Through a shared feature represen-
tation, the commonalities among the SMT systems
were better learned by the general models. In ad-
dition, domain-specific translation knowledge was
also better characterized by the in-domain models.
5 Conclusion and Future Work
In this paper, we propose an MTL-based approach to
address multi-domain adaptation for SMT. We first
use the cross-entropy based data selection method
to obtain in-domain bilingual data. After that, in-
domain TMs and LMs are trained for each domain-
specific SMT system. In addition, the general-
domain TM and LM are also trained and shared
across different systems. Finally, MTL is lever-
aged to tune multiple systems jointly. Experimen-
tal results have shown that our approach is quite
promising for the multi-domain adaptation problem,
and it brings significant improvement over both the
non-adapted baselines and the conventional domain
adaptation methods with mixture models.
We assume the domain information for testing
1063
data is known beforehand in this study. However,
this is not always the case for real world SMT sys-
tems. Therefore, to apply our approach in real appli-
cations, the domain information needs to be identi-
fied automatically. In the future, we will pre-define
more popular domains and develop automatic do-
main classifiers. For those domains that are iden-
tified with high confidence, we use the domain-
specific system to translate the texts. For other texts,
we use the general system to translate them. Fur-
thermore, since our approach is a general training
method, we may also combine this approach with
other domain adaptation methods to get more per-
formance improvement.
Acknowledgments
We are especially grateful to Nan Yang, Yajuan
Duan, Hong Sun and Danran Chen for the helpful
discussions. We also thank the anonymous review-
ers for their insightful comments.
References
Rie Kubota Ando and Tong Zhang. 2005. A framework
for learning predictive structures from multiple tasks
and unlabeled data. The Journal of Machine Learning
Research, 6:1817?1853.
Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 2011.
Domain adaptation via pseudo in-domain data selec-
tion. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing,
pages 355?362, Edinburgh, Scotland, UK., July. As-
sociation for Computational Linguistics.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of the 2006 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 120?128, Sydney, Australia, July. As-
sociation for Computational Linguistics.
Olivier Chapelle, Pannagadatta Shivaswamy, Srinivas
Vadrevu, Kilian Weinberger, Ya Zhang, and Belle
Tseng. 2011. Boosted multi-task learning. Machine
learning, 85(1-2):149?173.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
Ronan Collobert and Jason Weston. 2008. A unified ar-
chitecture for natural language processing: deep neu-
ral networks with multitask learning. In Proceedings
of the 25th international conference onMachine learn-
ing, pages 160?167. ACM.
Lei Cui, Dongdong Zhang, Shujie Liu, Mu Li, and Ming
Zhou. 2013. Bilingual data cleaning for smt using
graph-based random walk. In Proceedings of the 51st
Annual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), pages 340?345,
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics.
Mark Dredze and Koby Crammer. 2008. Online methods
for multi-domain learning and adaptation. In Proceed-
ings of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 689?697, Hon-
olulu, Hawaii, October. Association for Computational
Linguistics.
Kevin Duh, Katsuhito Sudoh, Hajime Tsukada, Hideki
Isozaki, and Masaaki Nagata. 2010. N-best reranking
by multitask learning. In Proceedings of the Joint Fifth
Workshop on Statistical Machine Translation and Met-
ricsMATR, pages 375?383, Uppsala, Sweden, July.
Association for Computational Linguistics.
Matthias Eck, Stephan Vogel, and Alex Waibel. 2004.
Language model adaptation for statistical machine
translation based on information retrieval. In In Proc.
of LREC.
George Foster and Roland Kuhn. 2007. Mixture-model
adaptation for SMT. In Proceedings of the Second
Workshop on Statistical Machine Translation, pages
128?135, Prague, Czech Republic, June. Association
for Computational Linguistics.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable smoothing for statistical machine
translation. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
pages 53?61, Sydney, Australia, July. Association for
Computational Linguistics.
George Foster, Cyril Goutte, and Roland Kuhn. 2010.
Discriminative instance weighting for domain adapta-
tion in statistical machine translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 451?459, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Long Jiang, Shiquan Yang, Ming Zhou, Xiaohua Liu, and
Qingsheng Zhu. 2009. Mining bilingual data from the
web with adaptively learnt patterns. In Proceedings
of the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP, pages
870?878, Suntec, Singapore, August. Association for
Computational Linguistics.
Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. In Acous-
tics, Speech, and Signal Processing, 1995. ICASSP-
95., 1995 International Conference on, volume 1,
pages 181?184. IEEE.
1064
Philipp Koehn and Josh Schroeder. 2007. Experiments
in domain adaptation for statistical machine transla-
tion. In Proceedings of the Second Workshop on Sta-
tistical Machine Translation, pages 224?227, Prague,
Czech Republic, June. Association for Computational
Linguistics.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388?395, Barcelona, Spain, July. Association
for Computational Linguistics.
Percy Liang, Alexandre Bouchard-Co?te?, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative ap-
proach to machine translation. In Proceedings of the
21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Association
for Computational Linguistics, pages 761?768, Syd-
ney, Australia, July. Association for Computational
Linguistics.
Yajuan Lu?, Jin Huang, and Qun Liu. 2007. Improving
statistical machine translation performance by train-
ing data selection and optimization. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
343?350, Prague, Czech Republic, June. Association
for Computational Linguistics.
Robert C. Moore and William Lewis. 2010. Intelligent
selection of language model training data. In Pro-
ceedings of the ACL 2010 Conference Short Papers,
pages 220?224, Uppsala, Sweden, July. Association
for Computational Linguistics.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics, pages 160?167, Sapporo, Japan,
July. Association for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311?318, Philadelphia, Pennsylva-
nia, USA, July. Association for Computational Lin-
guistics.
Majid Razmara, George Foster, Baskaran Sankaran, and
Anoop Sarkar. 2012. Mixing multiple translation
models in statistical machine translation. In Proceed-
ings of the 50th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 940?949, Jeju Island, Korea, July. Association
for Computational Linguistics.
Rico Sennrich. 2012. Perplexity minimization for trans-
lation model domain adaptation in statistical machine
translation. In Proceedings of the 13th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 539?549, Avignon, France,
April. Association for Computational Linguistics.
Libin Shen and Aravind K Joshi. 2005. Ranking and
reranking with perceptron. Machine Learning, 60(1-
3):73?96.
Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012.
Joint feature selection in distributed stochastic learn-
ing for large-scale discriminative training in smt. In
Proceedings of the 50th Annual Meeting of the Associ-
ation for Computational Linguistics (Volume 1: Long
Papers), pages 11?21, Jeju Island, Korea, July. Asso-
ciation for Computational Linguistics.
Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar.
2007. Transductive learning for statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 25?32, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
1065
Proceedings of the ACL 2010 Conference Short Papers, pages 6?11,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
A Joint Rule Selection Model for Hierarchical Phrase-based Translation?
Lei Cui?, Dongdong Zhang?, Mu Li?, Ming Zhou?, and Tiejun Zhao?
?School of Computer Science and Technology
Harbin Institute of Technology, Harbin, China
{cuilei,tjzhao}@mtlab.hit.edu.cn
?Microsoft Research Asia, Beijing, China
{dozhang,muli,mingzhou}@microsoft.com
Abstract
In hierarchical phrase-based SMT sys-
tems, statistical models are integrated to
guide the hierarchical rule selection for
better translation performance. Previous
work mainly focused on the selection of
either the source side of a hierarchical rule
or the target side of a hierarchical rule
rather than considering both of them si-
multaneously. This paper presents a joint
model to predict the selection of hierar-
chical rules. The proposed model is esti-
mated based on four sub-models where the
rich context knowledge from both source
and target sides is leveraged. Our method
can be easily incorporated into the prac-
tical SMT systems with the log-linear
model framework. The experimental re-
sults show that our method can yield sig-
nificant improvements in performance.
1 Introduction
Hierarchical phrase-based model has strong ex-
pression capabilities of translation knowledge. It
can not only maintain the strength of phrase trans-
lation in traditional phrase-based models (Koehn
et al, 2003; Xiong et al, 2006), but also char-
acterize the complicated long distance reordering
similar to syntactic based statistical machine trans-
lation (SMT) models (Yamada and Knight, 2001;
Quirk et al, 2005; Galley et al, 2006; Liu et al,
2006; Marcu et al, 2006; Mi et al, 2008; Shen et
al., 2008).
In hierarchical phrase-based SMT systems, due
to the flexibility of rule matching, a huge number
of hierarchical rules could be automatically learnt
from bilingual training corpus (Chiang, 2005).
SMT decoders are forced to face the challenge of
?This work was finished while the first author visited Mi-
crosoft Research Asia as an intern.
proper rule selection for hypothesis generation, in-
cluding both source-side rule selection and target-
side rule selection where the source-side rule de-
termines what part of source words to be translated
and the target-side rule provides one of the candi-
date translations of the source-side rule. Improper
rule selections may result in poor translations.
There is some related work about the hierarchi-
cal rule selection. In the original work (Chiang,
2005), the target-side rule selection is analogous to
the model in traditional phrase-based SMT system
such as Pharaoh (Koehn et al, 2003). Extending
this work, (He et al, 2008; Liu et al, 2008) in-
tegrate rich context information of non-terminals
to predict the target-side rule selection. Different
from the above work where the probability dis-
tribution of source-side rule selection is uniform,
(Setiawan et al, 2009) proposes to select source-
side rules based on the captured function words
which often play an important role in word re-
ordering. There is also some work considering to
involve more rich contexts to guide the source-side
rule selection. (Marton and Resnik, 2008; Xiong
et al, 2009) explore the source syntactic informa-
tion to reward exact matching structure rules or
punish crossing structure rules.
All the previous work mainly focused on either
source-side rule selection task or target-side rule
selection task rather than both of them together.
The separation of these two tasks, however, weak-
ens the high interrelation between them. In this pa-
per, we propose to integrate both source-side and
target-side rule selection in a unified model. The
intuition is that the joint selection of source-side
and target-side rules is more reliable as it conducts
the search in a larger space than the single selec-
tion task does. It is expected that these two kinds
of selection can help and affect each other, which
may potentially lead to better hierarchical rule se-
lections with a relative global optimum instead of
a local optimum that might be reached in the pre-
6
vious methods. Our proposed joint probability
model is factored into four sub-models that can
be further classified into source-side and target-
side rule selection models or context-based and
context-free selection models. The context-based
models explore rich context features from both
source and target sides, including function words,
part-of-speech (POS) tags, syntactic structure in-
formation and so on. Our model can be easily in-
corporated as an independent feature into the prac-
tical hierarchical phrase-based systems with the
log-linear model framework. The experimental re-
sults indicate our method can improve the system
performance significantly.
2 Hierarchical Rule Selection Model
Following (Chiang, 2005), ??, ?? is used to repre-
sent a synchronous context free grammar (SCFG)
rule extracted from the training corpus, where ?
and ? are the source-side and target-side rule re-
spectively. Let C be the context of ??, ??. For-
mally, our joint probability model of hierarchical
rule selection is described as follows:
P (?, ?|C) = P (?|C)P (?|?,C) (1)
We decompose the joint probability model into
two sub-models based on the Bayes formulation,
where the first sub-model is source-side rule se-
lection model and the second one is the target-side
rule selection model.
For the source-side rule selection model, we fur-
ther compute it by the interpolation of two sub-
models:
?Ps(?) + (1? ?)Ps(?|C) (2)
where Ps(?) is the context-free source model
(CFSM) and Ps(?|C) is the context-based source
model (CBSM), ? is the interpolation weight that
can be optimized over the development data.
CFSM is the probability of source-side rule se-
lection that can be estimated based on maximum
likelihood estimation (MLE) method:
Ps(?) =
?
? Count(??, ??)
Count(?)
(3)
where the numerator is the total count of bilin-
gual rule pairs with the same source-side rule that
are extracted based on the extraction algorithm in
(Chiang, 2005), and the denominator is the total
amount of source-side rule patterns contained in
the monolingual source side of the training corpus.
CFSM is used to capture how likely the source-
side rule is linguistically motivated or has the cor-
responding target-side counterpart.
For CBSM, it can be naturally viewed as a clas-
sification problem where each distinct source-side
rule is a single class. However, considering the
huge number of classes may cause serious data
sparseness problem and thereby degrade the clas-
sification accuracy, we approximate CBSM by a
binary classification problem which can be solved
by the maximum entropy (ME) approach (Berger
et al, 1996) as follows:
Ps(?|C) ? Ps(?|?,C)
=
exp[
?
i ?ihi(?, ?,C)]?
?? exp[
?
i ?ihi(?
? , ?, C)]
(4)
where ? ? {0, 1} is the indicator whether the
source-side rule is applied during decoding, ? = 1
when the source-side rule is applied, otherwise
? = 0; hi is a feature function, ?i is the weight
of hi. CBSM estimates the probability of the
source-side rule being selected according to the
rich context information coming from the surface
strings and sub-phrases that will be reduced to
non-terminals during decoding.
Analogously, we decompose the target-side rule
selection model by the interpolation approach as
well:
?Pt(?) + (1? ?)Pt(?|?,C) (5)
where Pt(?) is the context-free target model
(CFTM) and Pt(?|?,C) is the context-based tar-
get model (CBTM), ? is the interpolation weight
that can be optimized over the development data.
In the similar way, we compute CFTM by the
MLE approach and estimate CBTM by the ME
approach. CFTM computes how likely the target-
side rule is linguistically motivated, while CBTM
predicts how likely the target-side rule is applied
according to the clues from the rich context infor-
mation.
3 Model Training of CBSM and CBTM
3.1 The acquisition of training instances
CBSM and CBTM are trained by ME approach for
the binary classification, where a training instance
consists of a label and the context related to SCFG
rules. The context is divided into source context
7
Figure 1: Example of training instances in CBSM and CBTM.
and target context. CBSM is trained only based
on the source context while CBTM is trained over
both the source and the target context. All the
training instances are automatically constructed
from the bilingual training corpus, which have la-
bels of either positive (i.e., ? = 1) or negative (i.e.,
? = 0). This section explains how the training in-
stances are constructed for the training of CBSM
and CBTM.
Let s and t be the source sentence and target
sentence,W be the word alignment between them,
rs be a source-side rule that pattern-matches a
sub-phrase of s, rt be the target-side rule pattern-
matching a sub-phrase of t and being aligned to rs
based on W , and C(r) be the context features re-
lated to the rule r which will be explained in the
following section.
For the training of CBSM, if the SCFG rule
?rs, rt? can be extracted based on the rule extrac-
tion algorithm in (Chiang, 2005), ?? = 1, C(rs)?
is constructed as a positive instance, otherwise
?? = 0, C(rs)? is constructed as a negative in-
stance. For example in Figure 1(a), the context of
source-side rule ?X1 hezuo? that pattern-matches
the phrase ?youhao hezuo? produces a positive
instance, while the context of ?X1 youhao? that
pattern-matches the source phrase ?de youhao? or
?shuangfang de youhao? will produce a negative
instance as there are no corresponding plausible
target-side rules that can be extracted legally1.
For the training of CBTM, given rs, suppose
there is a SCFG rule set {?rs, rkt ?|1 ? k ? n}
extracted from multiple distinct sentence pairs in
the bilingual training corpus, among which we as-
sume ?rs, rit? is extracted from the sentence pair
?s, t?. Then, we construct ?? = 1, C(rs), C(rit)?
1Because the aligned target words are not contiguous and
?cooperation? is aligned to the word outside the source-side
rule.
as a positive instance, while the elements in {?? =
0, C(rs), C(r
j
t )?|j 6= i ? 1 ? j ? n} are viewed
as negative instances since they fail to be applied
to the translation from s to t. For example in Fig-
ure 1(c), Rule (1) and Rule (2) are two different
SCFG rules extracted from Figure 1(a) and Figure
1(b) respectively, where their source-side rules are
the same. As Rule (1) cannot be applied to Fig-
ure 1(b) for the translation and Rule (2) cannot
be applied to Figure 1(a) for the translation either,
?? = 1, C(ras ), C(r
a
t )? and ?? = 1, C(r
b
s), C(r
b
t )?
are constructed as positive instances while ?? =
0, C(ras ), C(r
b
t )? and ?? = 0, C(r
b
s), C(r
a
t )? are
viewed as negative instances. It is noticed that
this instance construction method may lead to a
large quantity of negative instances and choke the
training procedure. In practice, to limit the size
of the training set, the negative instances con-
structed based on low-frequency target-side rules
are pruned.
3.2 Context-based features for ME training
ME approach has the merit of easily combining
different features to predict the probability of each
class. We incorporate into the ME based model
the following informative context-based features
to train CBSM and CBTM. These features are
carefully designed to reduce the data sparseness
problem and some of them are inspired by pre-
vious work (He et al, 2008; Gimpel and Smith,
2008; Marton and Resnik, 2008; Chiang et al,
2009; Setiawan et al, 2009; Shen et al, 2009;
Xiong et al, 2009):
1. Function word features, which indicate
whether the hierarchical source-side/target-
side rule strings and sub-phrases covered by
non-terminals contain function words that are
often important clues of predicting syntactic
structures.
8
2. POS features, which are POS tags of the
boundary source words covered by non-
terminals.
3. Syntactic features, which are the constituent
constraints of hierarchical source-side rules
exactly matching or crossing syntactic sub-
trees.
4. Rule format features, which are non-
terminal positions and orders in source-
side/target-side rules. This feature interacts
between source and target components since
it shows whether the translation ordering is
affected.
5. Length features, which are the length
of sub-phrases covered by source non-
terminals.
4 Experiments
4.1 Experiment setting
We implement a hierarchical phrase-based system
similar to the Hiero (Chiang, 2005) and evaluate
our method on the Chinese-to-English translation
task. Our bilingual training data comes from FBIS
corpus, which consists of around 160K sentence
pairs where the source data is parsed by the Berke-
ley parser (Petrov and Klein, 2007). The ME train-
ing toolkit, developed by (Zhang, 2006), is used to
train our CBSM and CBTM. The training size of
constructed positive instances for both CBSM and
CBTM is 4.68M, while the training size of con-
structed negative instances is 3.74M and 3.03M re-
spectively. Following (Setiawan et al, 2009), we
identify function words as the 128 most frequent
words in the corpus. The interpolation weights are
set to ? = 0.75 and ? = 0.70. The 5-gram lan-
guage model is trained over the English portion
of FBIS corpus plus Xinhua portion of the Giga-
word corpus. The development data is from NIST
2005 evaluation data and the test data is from
NIST 2006 and NIST 2008 evaluation data. The
evaluation metric is the case-insensitive BLEU4
(Papineni et al, 2002). Statistical significance in
BLEU score differences is tested by paired boot-
strap re-sampling (Koehn, 2004).
4.2 Comparison with related work
Our baseline is the implemented Hiero-like SMT
system where only the standard features are em-
ployed and the performance is state-of-the-art.
We compare our method with the baseline and
some typical approaches listed in Table 1 where
XP+ denotes the approach in (Marton and Resnik,
2008) and TOFW (topological ordering of func-
tion words) stands for the method in (Setiawan et
al., 2009). As (Xiong et al, 2009)?s work is based
on phrasal SMT system with bracketing transduc-
tion grammar rules (Wu, 1997) and (Shen et al,
2009)?s work is based on the string-to-dependency
SMT model, we do not implement these two re-
lated work due to their different models from ours.
We also do not compare with (He et al, 2008)?s
work due to its less practicability of integrating
numerous sub-models.
Methods NIST 2006 NIST 2008
Baseline 0.3025 0.2200
XP+ 0.3061 0.2254
TOFW 0.3089 0.2253
Our method 0.3141 0.2318
Table 1: Comparison results, our method is signif-
icantly better than the baseline, as well as the other
two approaches (p < 0.01)
As shown in Table 1, all the methods outper-
form the baseline because they have extra mod-
els to guide the hierarchical rule selection in some
ways which might lead to better translation. Ap-
parently, our method also performs better than the
other two approaches, indicating that our method
is more effective in the hierarchical rule selection
as both source-side and target-side rules are se-
lected together.
4.3 Effect of sub-models
Due to the space limitation, we analyze the ef-
fect of sub-models upon the system performance,
rather than that of ME features, part of which have
been investigated in previous related work.
Settings NIST 2006 NIST 2008
Baseline 0.3025 0.2200
Baseline+CFSM 0.3092? 0.2266?
Baseline+CBSM 0.3077? 0.2247?
Baseline+CFTM 0.3076? 0.2286?
Baseline+CBTM 0.3060 0.2255?
Baseline+CFSM+CFTM 0.3109? 0.2289?
Baseline+CFSM+CBSM 0.3104? 0.2282?
Baseline+CFTM+CBTM 0.3099? 0.2299?
Baseline+all sub-models 0.3141? 0.2318?
Table 2: Sub-model effect upon the performance,
*: significantly better than baseline (p < 0.01)
As shown in Table 2, when sub-models are inte-
9
grated as independent features, the performance is
improved compared to the baseline, which shows
that each of the sub-models can improve the hier-
archical rule selection. It is noticeable that the per-
formance of the source-side rule selection model
is comparable with that of the target-side rule se-
lection model. Although CFSM and CFTM per-
form only slightly better than the others among
the individual sub-models, the best performance is
achieved when all the sub-models are integrated.
5 Conclusion
Hierarchical rule selection is an important and
complicated task for hierarchical phrase-based
SMT system. We propose a joint probability
model for the hierarchical rule selection and the
experimental results prove the effectiveness of our
approach.
In the future work, we will explore more useful
features and test our method over the large scale
training corpus. A challenge might exist when
running the ME training toolkit over a big size
of training instances from the large scale training
data.
Acknowledgments
We are especially grateful to the anonymous re-
viewers for their insightful comments. We also
thank Hendra Setiawan, Yuval Marton, Chi-Ho Li,
Shujie Liu and Nan Duan for helpful discussions.
References
Adam L. Berger, Vincent J. Della Pietra, and Stephen
A. Della Pietra. 1996. A Maximum Entropy Ap-
proach to Natural Language Processing. Computa-
tional Linguistics, 22(1): pages 39-72.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc.
ACL, pages 263-270.
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 New Features for Statistical Machine Trans-
lation. In Proc. HLT-NAACL, pages 218-226.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training of
Context-Rich Syntactic Translation Models. In Proc.
ACL-Coling, pages 961-968.
Kevin Gimpel and Noah A. Smith. 2008. Rich Source-
Side Context for Statistical Machine Translation. In
Proc. the Third Workshop on Statistical Machine
Translation, pages 9-17.
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving Statistical Machine Translation using Lexi-
calized Rule Selection. In Proc. Coling, pages 321-
328.
Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proc. EMNLP.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proc. HLT-
NAACL, pages 127-133.
Qun Liu, Zhongjun He, Yang Liu, and Shouxun Lin.
2008. Maximum Entropy based Rule Selection
Model for Syntax-based Statistical Machine Trans-
lation. In Proc. EMNLP, pages 89-97.
Yang Liu, Yun Huang, Qun Liu, and Shouxun Lin.
2007. Forest-to-String Statistical Translation Rules.
In Proc. ACL, pages 704-711.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine
Translation. In Proc. ACL-Coling, pages 609-616.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proc. EMNLP, pages 44-52.
Yuval Marton and Philip Resnik. 2008. Soft Syntactic
Constraints for Hierarchical Phrased-Based Trans-
lation. In Proc. ACL, pages 1003-1011.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
Based Translation. In Proc. ACL, pages 192-199.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proc. ACL,
pages 311-318.
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In Proc. HLT-NAACL,
pages 404-411.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
Dependency Treelet Translation: Syntactically In-
formed Phrasal SMT. In Proc. ACL, pages 271-279.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
New String-to-Dependency Machine Translation Al-
gorithm with a Target Dependency Language Model.
In Proc. ACL, pages 577-585.
Libin Shen, Jinxi Xu, Bing Zhang, Spyros Matsoukas,
and Ralph Weischedel. 2009. Effective Use of Lin-
guistic and Contextual Information for Statistical
Machine Translation. In Proc. EMNLP, pages 72-
80.
Hendra Setiawan, Min Yen Kan, Haizhou Li, and Philip
Resnik. 2009. Topological Ordering of Function
Words in Hierarchical Phrase-based Translation. In
Proc. ACL, pages 324-332.
10
Dekai Wu. 1997. Stochastic Inversion Transduction
Grammars and Bilingual Parsing of Parallel Cor-
pora. Computational Linguistics, 23(3): pages 377-
403.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum Entropy Based Phrase Reordering Model for
Statistical Machine Translation. In Proc. ACL-
Coling, pages 521-528.
Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li.
2009. A Syntax-Driven Bracketing Model for
Phrase-Based Translation. In Proc. ACL, pages
315-323.
Kenji Yamada and Kevin Knight. 2001. A Syntax-
based Statistical Translation Model. In Proc. ACL,
pages 523-530.
Le Zhang. 2006. Maximum entropy mod-
eling toolkit for python and c++. avail-
able at http://homepages.inf.ed.ac.uk/
lzhang10/maxent_toolkit.html.
11
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 340?345,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Bilingual Data Cleaning for SMT using Graph-based Random Walk?
Lei Cui?, Dongdong Zhang?, Shujie Liu?, Mu Li?, and Ming Zhou?
?School of Computer Science and Technology
Harbin Institute of Technology, Harbin, China
leicui@hit.edu.cn
?Microsoft Research Asia, Beijing, China
{dozhang,shujliu,muli,mingzhou}@microsoft.com
Abstract
The quality of bilingual data is a key factor
in Statistical Machine Translation (SMT).
Low-quality bilingual data tends to pro-
duce incorrect translation knowledge and
also degrades translation modeling per-
formance. Previous work often used su-
pervised learning methods to filter low-
quality data, but a fair amount of human
labeled examples are needed which are
not easy to obtain. To reduce the re-
liance on labeled examples, we propose
an unsupervised method to clean bilin-
gual data. The method leverages the mu-
tual reinforcement between the sentence
pairs and the extracted phrase pairs, based
on the observation that better sentence
pairs often lead to better phrase extraction
and vice versa. End-to-end experiments
show that the proposed method substan-
tially improves the performance in large-
scale Chinese-to-English translation tasks.
1 Introduction
Statistical machine translation (SMT) depends on
the amount of bilingual data and its quality. In
real-world SMT systems, bilingual data is often
mined from the web where low-quality data is in-
evitable. The low-quality bilingual data degrades
the quality of word alignment and leads to the in-
correct phrase pairs, which will hurt the transla-
tion performance of phrase-based SMT systems
(Koehn et al, 2003; Och and Ney, 2004). There-
fore, it is very important to exploit data quality in-
formation to improve the translation modeling.
Previous work on bilingual data cleaning often
involves some supervised learning methods. Sev-
eral bilingual data mining systems (Resnik and
?This work has been done while the first author was visit-
ing Microsoft Research Asia.
Smith, 2003; Shi et al, 2006; Munteanu and
Marcu, 2005; Jiang et al, 2009) have a post-
processing step for data cleaning. Maximum en-
tropy or SVM based classifiers are built to filter
some non-parallel data or partial-parallel data. Al-
though these methods can filter some low-quality
bilingual data, they need sufficient human labeled
training instances to build the model, which may
not be easy to acquire.
To this end, we propose an unsupervised ap-
proach to clean the bilingual data. It is intuitive
that high-quality parallel data tends to produce
better phrase pairs than low-quality data. Mean-
while, it is also observed that the phrase pairs that
appear frequently in the bilingual corpus are more
reliable than less frequent ones because they are
more reusable, hence most good sentence pairs are
prone to contain more frequent phrase pairs (Fos-
ter et al, 2006; Wuebker et al, 2010). This kind of
mutual reinforcement fits well into the framework
of graph-based random walk. When a phrase pair
p is extracted from a sentence pair s, s is consid-
ered casting a vote for p. The higher the number
of votes a phrase pair has, the more reliable of the
phrase pair. Similarly, the quality of the sentence
pair s is determined by the number of votes casted
by the extracted phrase pairs from s.
In this paper, a PageRank-style random walk al-
gorithm (Brin and Page, 1998; Mihalcea and Ta-
rau, 2004; Wan et al, 2007) is conducted to itera-
tively compute the importance score of each sen-
tence pair that indicates its quality: the higher the
better. Unlike other data filtering methods, our
proposed method utilizes the importance scores
of sentence pairs as fractional counts to calculate
the phrase translation probabilities based on Maxi-
mum Likelihood Estimation (MLE), thereby none
of the bilingual data is filtered out. Experimen-
tal results show that our proposed approach sub-
stantially improves the performance in large-scale
Chinese-to-English translation tasks.
340
2 The Proposed Approach
2.1 Graph-based random walk
Graph-based random walk is a general algorithm
to approximate the importance of a vertex within
the graph in a global view. In our method, the ver-
tices denote the sentence pairs and phrase pairs.
The importance of each vertex is propagated to
other vertices along the edges. Depending on dif-
ferent scenarios, the graph can take directed or
undirected, weighted or un-weighted forms. Start-
ing from the initial scores assigned in the graph,
the algorithm is applied to recursively compute the
importance scores of vertices until it converges, or
the difference between two consecutive iterations
falls below a pre-defined threshold.
2.2 Graph construction
Given the sentence pairs that are word-aligned
automatically, an undirected, weighted bipartite
graph is constructed which maps the sentence
pairs and the extracted phrase pairs to the ver-
tices. An edge between a sentence pair vertex and
a phrase pair vertex is added if the phrase pair can
be extracted from the sentence pair. Mutual re-
inforcement scores are defined on edges, through
which the importance scores are propagated be-
tween vertices. Figure 1 illustrates the graph struc-
ture. Formally, the bipartite graph is defined as:
G = (V,E)
where V = S ? P is the vertex set, S = {si|1 ?
i ? n} is the set of all sentence pairs. P =
{pj |1 ? j ? m} is the set of all phrase pairs
which are extracted from S based on the word
alignment. E is the edge set in which the edges
are between S and P , thereby E = {?si, pj?|si ?
S, pj ? P, ?(si, pj) = 1}.
?(si, pj) =
{
1 if pj can be extracted from si
0 otherwise
2.3 Graph parameters
For sentence-phrase mutual reinforcement, a non-
negative score r(si, pj) is defined using the stan-
dard TF-IDF formula:
r(si, pj) =
{ PF (si,pj)?IPF (pj)?
p??{p|?(si,p)=1} PF (si,p
?)?IPF (p?) if ?(si, pj) = 1
0 otherwise
Sentence Pair Vertices
Phrase Pair Vertices
s1
s2
s3
p1
p3
p4
p5
p6
p2
Figure 1: The circular nodes stand for S and
square nodes stand for P . The lines capture the
sentence-phrase mutual reinforcement.
where PF (si, pj) is the phrase pair frequency in
a sentence pair and IPF (pj) is the inverse phrase
pair frequency of pj in the whole bilingual corpus.
r(si, pj) is abbreviated as rij .
Inspired by (Brin and Page, 1998; Mihalcea
and Tarau, 2004; Wan et al, 2007), we com-
pute the importance scores of sentence pairs and
phrase pairs using a PageRank-style algorithm.
The weights rij are leveraged to reflect the rela-
tionships between two types of vertices. Let u(si)
and v(pj) denote the scores of a sentence pair ver-
tex and a phrase pair vertex. They are computed
iteratively by:
u(si) = (1?d)+d?
?
j?N(si)
rij?
k?M(pj) rkj
v(pj)
v(pj) = (1?d) +d?
?
j?M(pj)
rij?
k?N(si) rik
u(si)
where d is empirically set to the default value 0.85
that is same as the original PageRank, N(si) =
{j|?si, pj? ? E}, M(pj) = {i|?si, pj? ? E}.
The detailed process is illustrated in Algorithm 1.
Algorithm 1 iteratively updates the scores of sen-
tence pairs and phrase pairs (lines 10-26). The
computation ends when difference between two
consecutive iterations is lower than a pre-defined
threshold ? (10?12 in this study).
2.4 Parallelization
When the random walk runs on some large bilin-
gual corpora, even filtering phrase pairs that ap-
pear only once would still require several days of
CPU time for a number of iterations. To over-
come this problem, we use a distributed algorithm
341
Algorithm 1 Modified Random Walk
1: for all i ? {0 . . . |S| ? 1} do
2: u(si)(0) ? 1
3: end for
4: for all j ? {0 . . . |P | ? 1} do
5: v(pj)(0) ? 1
6: end for
7: ? ? Infinity
8: ? threshold
9: n? 1
10: while ? >  do
11: for all i ? {0 . . . |S| ? 1} do
12: F (si)? 0
13: for all j ? N(si) do
14: F (si)? F (si) + rij?
k?M(pj) rkj
? v(pj)(n?1)
15: end for
16: u(si)(n) ? (1? d) + d ? F (si)
17: end for
18: for all j ? {0 . . . |P | ? 1} do
19: G(pj)? 0
20: for all i ?M(pj) do
21: G(pj)? G(pj) + rij?
k?N(si) rik
? u(si)(n?1)
22: end for
23: v(pj)(n) ? (1? d) + d ?G(pj)
24: end for
25: ? ? max(4u(si)||S|?1i=1 ,4v(pj)||P |?1j=1 )26: n? n+ 1
27: end while
28: return u(si)(n)||S|?1i=0
based on the iterative computation in the Sec-
tion 2.3. Before the iterative computation starts,
the sum of the outlink weights for each vertex
is computed first. The edges are randomly par-
titioned into sets of roughly equal size. Each
edge ?si, pj? can generate two key-value pairs
in the format ?si, rij? and ?pj , rij?. The pairs
with the same key are summed locally and ac-
cumulated across different machines. Then, in
each iteration, the score of each vertex is up-
dated according to the sum of the normalized
inlink weights. The key-value pairs are gener-
ated in the format ?si, rij?
k?M(pj) rkj
? v(pj)? and
?pj , rij?
k?N(si) rik
? u(si)?. These key-value pairs
are also randomly partitioned and summed across
different machines. Since long sentence pairs usu-
ally extract more phrase pairs, we need to normal-
ize the importance scores based on the sentence
length. The algorithm fits well into the MapRe-
duce programming model (Dean and Ghemawat,
2008) and we use it as our implementation.
2.5 Integration into translation modeling
After sufficient number of iterations, the impor-
tance scores of sentence pairs (i.e., u(si)) are ob-
tained. Instead of simple filtering, we use the
scores of sentence pairs as the fractional counts to
re-estimate the translation probabilities of phrase
pairs. Given a phrase pair p = ?f? , e??, A(f?) and
B(e?) indicate the sets of sentences that f? and e?
appear. Then the translation probability is defined
as:
PCW(f? |e?) =
?
i?A(f?)?B(e?) u(si)? ci(f? , e?)?
j?B(e?) u(sj)? cj(e?)
where ci(?) denotes the count of the phrase or
phrase pair in si. PCW(f? |e?) and PCW(e?|f?) are
named as Corpus Weighting (CW) based transla-
tion probability, which are integrated into the log-
linear model in addition to the conventional phrase
translation probabilities (Koehn et al, 2003).
3 Experiments
3.1 Setup
We evaluated our bilingual data cleaning ap-
proach on large-scale Chinese-to-English machine
translation tasks. The bilingual data we used
was mainly mined from the web (Jiang et al,
2009)1, as well as the United Nations parallel cor-
pus released by LDC and the parallel corpus re-
leased by China Workshop on Machine Transla-
tion (CWMT), which contain around 30 million
sentence pairs in total after removing duplicated
ones. The development data and testing data is
shown in Table 1.
Data Set #Sentences Source
NIST 2003 (dev) 919 open test
NIST 2005 (test) 1,082 open test
NIST 2006 (test) 1,664 open test
NIST 2008 (test) 1,357 open test
CWMT 2008 (test) 1,006 open test
In-house dataset 1 (test) 1,002 web data
In-house dataset 2 (test) 5,000 web data
In-house dataset 3 (test) 2,999 web data
Table 1: Development and testing data used in the
experiments.
A phrase-based decoder was implemented
based on inversion transduction grammar (Wu,
1997). The performance of this decoder is simi-
lar to the state-of-the-art phrase-based decoder in
Moses, but the implementation is more straight-
forward. We use the following feature functions
in the log-linear model:
1Although supervised data cleaning has been done in the
post-processing, the corpus still contains a fair amount of
noisy data based on our random sampling.
342
dev NIST 2005 NIST 2006 NIST 2008 CWMT 2008 IH 1 IH 2 IH 3
baseline 41.24 37.34 35.20 29.38 31.14 24.29 22.61 24.19
(Wuebker et al, 2010) 41.20 37.48 35.30 29.33 31.10 24.33 22.52 24.18
-0.25M 41.28 37.62 35.31 29.70 31.40 24.52 22.69 24.64
-0.5M 41.45 37.71 35.52 29.76 31.77 24.64 22.68 24.69
-1M 41.28 37.41 35.28 29.65 31.73 24.23 23.06 24.20
+CW 41.75 38.08 35.84 30.03 31.82 25.23 23.18 24.80
Table 2: BLEU(%) of Chinese-to-English translation tasks on multiple testing datasets (p < 0.05), where
?-numberM? denotes we simply filter number million low scored sentence pairs from the bilingual data
and use others to extract the phrase table. ?CW? means the corpus weighting feature, which incorporates
sentence scores from random walk as fractional counts to re-estimate the phrase translation probabilities.
? phrase translation probabilities and lexical
weights in both directions (4 features);
? 5-gram language model with Kneser-Ney
smoothing (1 feature);
? lexicalized reordering model (1 feature);
? phrase count and word count (2 features).
The translation model was trained over the
word-aligned bilingual corpus conducted by
GIZA++ (Och and Ney, 2003) in both directions,
and the diag-grow-final heuristic was used to re-
fine the symmetric word alignment. The language
model was trained on the LDC English Gigaword
Version 4.0 plus the English part of the bilingual
corpus. The lexicalized reordering model (Xiong
et al, 2006) was trained over the 40% randomly
sampled sentence pairs from our parallel data.
Case-insensitive BLEU4 (Papineni et al, 2002)
was used as the evaluation metric. The parame-
ters of the log-linear model are tuned by optimiz-
ing BLEU on the development data using MERT
(Och, 2003). Statistical significance test was per-
formed using the bootstrap re-sampling method
proposed by Koehn (2004).
3.2 Baseline
The experimental results are shown in Table 2. In
the baseline system, the phrase pairs that appear
only once in the bilingual data are simply dis-
carded because most of them are noisy. In ad-
dition, the fix-discount method in (Foster et al,
2006) for phrase table smoothing is also used.
This implementation makes the baseline system
perform much better and the model size is much
smaller. In fact, the basic idea of our ?one count?
cutoff is very similar to the idea of ?leaving-one-
out? in (Wuebker et al, 2010). The results show
?? ?? ? ? ??
uncharted waters
?? ?? ? ? ??
unexplored new areas
weijing tansuo de xin lingyu
Figure 2: The left one is the non-literal translation
in our bilingual corpus. The right one is the literal
translation made by human for comparison.
that the ?leaving-one-out? method performs al-
most the same as our baseline, thereby cannot
bring other benefits to the system.
3.3 Results
We evaluate the proposed bilingual data clean-
ing method by incorporating sentence scores into
translation modeling. In addition, we also com-
pare with several settings that filtering low-quality
sentence pairs from the bilingual data based on
the importance scores. The last N = { 0.25M,
0.5M, 1M } sentence pairs are filtered before the
modeling process. Although the simple bilin-
gual data filtering can improve the performance on
some datasets, it is difficult to determine the bor-
der line and translation performance is fluctuated.
One main reason is in the proposed random walk
approach, the bilingual sentence pairs with non-
literal translations may get lower scores because
they appear less frequently compared with those
literal translations. Crudely filtering out these data
may degrade the translation performance. For ex-
ample, we have a sentence pair in the bilingual
corpus shown in the left part of Figure 2. Although
the translation is correct in this situation, translat-
ing the Chinese word ?lingyu? to ?waters? appears
very few times since the common translations are
?areas? or ?fields?. However, simply filtering out
this kind of sentence pairs may lead to some loss
of native English expressions, thereby the trans-
343
lation performance is unstable since both non-
parallel sentence pairs and non-literal but parallel
sentence pairs are filtered. Therefore, we use the
importance score of each sentence pair to estimate
the phrase translation probabilities. It consistently
brings substantial improvements compared to the
baseline, which demonstrates graph-based random
walk indeed improves the translation modeling
performance for our SMT system.
3.4 Discussion
In (Goutte et al, 2012), they evaluated phrase-
based SMT systems trained on parallel data with
different proportions of synthetic noisy data. They
suggested that when collecting larger, noisy par-
allel data for training phrase-based SMT, clean-
ing up by trying to detect and remove incor-
rect alignments can actually degrade performance.
Our experimental results confirm their findings
on some datasets. Based on our method, some-
times filtering noisy data leads to unexpected re-
sults. The reason is two-fold: on the one hand,
the non-literal parallel data makes false positive in
noisy data detection; on the other hand, large-scale
SMT systems is relatively robust and tolerant to
noisy data, especially when we remove frequency-
1 phrase pairs. Therefore, we propose to integrate
the importance scores when re-estimating phrase
pair probabilities in this paper. The importance
scores can be considered as a kind of contribution
constraint, thereby high-quality parallel data con-
tributes more while noisy parallel data contributes
less.
4 Conclusion and Future Work
In this paper, we develop an effective approach
to clean the bilingual data using graph-based ran-
dom walk. Significant improvements on several
datasets are achieved in our experiments. For
future work, we will extend our method to ex-
plore the relationships of sentence-to-sentence and
phrase-to-phrase, which is beyond the existing
sentence-to-phrase mutual reinforcement.
Acknowledgments
We are especially grateful to Yajuan Duan, Hong
Sun, Nan Yang and Xilun Chen for the helpful dis-
cussions. We also thank the anonymous reviewers
for their insightful comments.
References
Sergey Brin and Lawrence Page. 1998. The anatomy
of a large-scale hypertextual web search engine.
Computer networks and ISDN systems, 30(1):107?
117.
Jeffrey Dean and Sanjay Ghemawat. 2008. Mapre-
duce: simplified data processing on large clusters.
Communications of the ACM, 51(1):107?113.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable smoothing for statistical machine
translation. In Proceedings of the 2006 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 53?61, Sydney, Australia, July. As-
sociation for Computational Linguistics.
Cyril Goutte, Marine Carpuat, and George Foster.
2012. The impact of sentence alignment errors on
phrase-based machine translation performance. In
Proceedings of AMTA 2012, San Diego, California,
October. Association for Machine Translation in the
Americas.
Long Jiang, Shiquan Yang, Ming Zhou, Xiaohua Liu,
and Qingsheng Zhu. 2009. Mining bilingual data
from the web with adaptively learnt patterns. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP, pages 870?878, Suntec, Singapore, August.
Association for Computational Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT-NAACL 2003 Main Papers, pages
48?54, Edmonton, May-June. Association for Com-
putational Linguistics.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388?395, Barcelona, Spain, July. Association
for Computational Linguistics.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into texts. In Dekang Lin and Dekai
Wu, editors, Proceedings of EMNLP 2004, pages
404?411, Barcelona, Spain, July. Association for
Computational Linguistics.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving machine translation performance by exploit-
ing non-parallel corpora. Computational Linguis-
tics, 31(4):477?504.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. Computational Linguistics, 30(4):417?449.
344
Franz Josef Och. 2003. Minimum error rate train-
ing in statistical machine translation. In Proceed-
ings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 160?167, Sap-
poro, Japan, July. Association for Computational
Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311?318, Philadelphia,
Pennsylvania, USA, July. Association for Computa-
tional Linguistics.
Philip Resnik and Noah A Smith. 2003. The web
as a parallel corpus. Computational Linguistics,
29(3):349?380.
Lei Shi, Cheng Niu, Ming Zhou, and Jianfeng Gao.
2006. A dom tree alignment model for mining paral-
lel data from the web. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics, pages 489?496, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2007.
Towards an iterative reinforcement approach for si-
multaneous document summarization and keyword
extraction. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 552?559, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Joern Wuebker, Arne Mauser, and Hermann Ney.
2010. Training phrase translation models with
leaving-one-out. In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics, pages 475?484, Uppsala, Sweden, July. As-
sociation for Computational Linguistics.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Max-
imum entropy based phrase reordering model for
statistical machine translation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 521?528,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
345
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 133?143,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Learning Topic Representation for SMT with Neural Networks
?
Lei Cui
1
, Dongdong Zhang
2
, Shujie Liu
2
, Qiming Chen
3
, Mu Li
2
, Ming Zhou
2
, and Muyun Yang
1
1
School of Computer Science and Technology, Harbin Institute of Technology, Harbin, P.R. China
leicui@hit.edu.cn, ymy@mtlab.hit.edu.cn
2
Microsoft Research, Beijing, P.R. China
{dozhang,shujliu,muli,mingzhou}@microsoft.com
3
Shanghai Jiao Tong University, Shanghai, P.R. China
simoncqm@gmail.com
Abstract
Statistical Machine Translation (SMT)
usually utilizes contextual information
to disambiguate translation candidates.
However, it is often limited to contexts
within sentence boundaries, hence broader
topical information cannot be leveraged.
In this paper, we propose a novel approach
to learning topic representation for paral-
lel data using a neural network architec-
ture, where abundant topical contexts are
embedded via topic relevant monolingual
data. By associating each translation rule
with the topic representation, topic rele-
vant rules are selected according to the dis-
tributional similarity with the source text
during SMT decoding. Experimental re-
sults show that our method significantly
improves translation accuracy in the NIST
Chinese-to-English translation task com-
pared to a state-of-the-art baseline.
1 Introduction
Making translation decisions is a difficult task in
many Statistical Machine Translation (SMT) sys-
tems. Current translation modeling approaches
usually use context dependent information to dis-
ambiguate translation candidates. For exam-
ple, translation sense disambiguation approaches
(Carpuat and Wu, 2005; Carpuat and Wu,
2007) are proposed for phrase-based SMT sys-
tems. Meanwhile, for hierarchical phrase-based
or syntax-based SMT systems, there is also much
work involving rich contexts to guide rule selec-
tion (He et al, 2008; Liu et al, 2008; Marton
and Resnik, 2008; Xiong et al, 2009). Although
these methods are effective and proven successful
in many SMT systems, they only leverage within-
?
This work was done while the first and fourth authors
were visiting Microsoft Research.
sentence contexts which are insufficient in explor-
ing broader information. For example, the word
driver often means ?the operator of a motor ve-
hicle? in common texts. But in the sentence ?Fi-
nally, we write the user response to the buffer, i.e.,
pass it to our driver?, we understand that driver
means ?computer program?. In this case, people
understand the meaning because of the IT topical
context which goes beyond sentence-level analy-
sis and requires more relevant knowledge. There-
fore, it is important to leverage topic information
to learn smarter translation models and achieve
better translation performance.
Topic modeling is a useful mechanism for dis-
covering and characterizing various semantic con-
cepts embedded in a collection of documents. At-
tempts on topic-based translation modeling in-
clude topic-specific lexicon translation models
(Zhao and Xing, 2006; Zhao and Xing, 2007),
topic similarity models for synchronous rules
(Xiao et al, 2012), and document-level translation
with topic coherence (Xiong and Zhang, 2013). In
addition, topic-based approaches have been used
in domain adaptation for SMT (Tam et al, 2007;
Su et al, 2012), where they view different topics
as different domains. One typical property of these
approaches in common is that they only utilize
parallel data where document boundaries are ex-
plicitly given. In this way, the topic of a sentence
can be inferred with document-level information
using off-the-shelf topic modeling toolkits such
as Latent Dirichlet Allocation (LDA) (Blei et al,
2003) or Hidden Topic Markov Model (HTMM)
(Gruber et al, 2007). Most of them also assume
that the input must be in document level. However,
this situation does not always happen since there is
considerable amount of parallel data which does
not have document boundaries. In addition, con-
temporary SMT systems often works on sentence
level rather than document level due to the effi-
ciency. Although we can easily apply LDA at the
133
sentence level, it is quite difficult to infer the topic
accurately with only a few words in the sentence.
This makes previous approaches inefficient when
applied them in real-world commercial SMT sys-
tems. Therefore, we need to devise a systematical
approach to enriching the sentence and inferring
its topic more accurately.
In this paper, we propose a novel approach to
learning topic representations for sentences. Since
the information within the sentence is insufficient
for topic modeling, we first enrich sentence con-
texts via Information Retrieval (IR) methods using
content words in the sentence as queries, so that
topic-related monolingual documents can be col-
lected. These topic-related documents are utilized
to learn a specific topic representation for each
sentence using a neural network based approach.
Neural network is an effective technique for learn-
ing different levels of data representations. The
levels inferred from neural network correspond to
distinct levels of concepts, where high-level rep-
resentations are obtained from low-level bag-of-
words input. It is able to detect correlations among
any subset of input features through non-linear
transformations, which demonstrates the superior-
ity of eliminating the effect of noisy words which
are irrelevant to the topic. Our problem fits well
into the neural network framework and we expect
that it can further improve inferring the topic rep-
resentations for sentences.
To incorporate topic representations as trans-
lation knowledge into SMT, our neural network
based approach directly optimizes similarities be-
tween the source language and target language in a
compact topic space. This underlying topic space
is learned from sentence-level parallel data in or-
der to share topic information across the source
and target languages as much as possible. Addi-
tionally, our model can be discriminatively trained
with a large number of training instances, without
expensive sampling methods such as in LDA or
HTMM, thus it is more practicable and scalable.
Finally, we associate the learned representation to
each bilingual translation rule. Topic-related rules
are selected according to distributional similarity
with the source text, which helps hypotheses gen-
eration in SMT decoding. We integrate topic simi-
larity features in the log-linear model and evaluate
the performance on the NIST Chinese-to-English
translation task. Experimental results demonstrate
that our model significantly improves translation
accuracy over a state-of-the-art baseline.
2 Background: Deep Learning
Deep learning is an active topic in recent years
which has triumphed in many machine learning
research areas. This technique began raising pub-
lic awareness in the mid-2000s after researchers
showed how a multi-layer feed-forward neural
network can be effectively trained. The train-
ing procedure often involves two phases: a layer-
wise unsupervised pre-training phase and a su-
pervised fine-tuning phase. For pre-training, Re-
stricted Boltzmann Machine (RBM) (Hinton et
al., 2006), auto-encoding (Bengio et al, 2006)
and sparse coding (Lee et al, 2006) are most fre-
quently used. Unsupervised pre-training trains the
network one layer at a time and helps guide the pa-
rameters of the layer towards better regions in pa-
rameter space (Bengio, 2009). Followed by fine-
tuning in this parameter region, deep learning is
able to achieve state-of-the-art performance in var-
ious research areas, including breakthrough results
on the ImageNet dataset for objective recognition
(Krizhevsky et al, 2012), significant error reduc-
tion in speech recognition (Dahl et al, 2012), etc.
Deep learning has also been successfully ap-
plied in a variety of NLP tasks such as part-of-
speech tagging, chunking, named entity recog-
nition, semantic role labeling (Collobert et al,
2011), parsing (Socher et al, 2011a), sentiment
analysis (Socher et al, 2011b), etc. Most NLP
research converts a high-dimensional and sparse
binary representation into a low-dimensional and
real-valued representation. This low-dimensional
representation is usually learned from huge
amount of monolingual texts in the pre-training
phase, and then fine-tuned towards task-specific
criterion. Inspired by previous successful re-
search, we first learn sentence representations us-
ing topic-related monolingual texts in the pre-
training phase, and then optimize the bilingual
similarity by leveraging sentence-level parallel
data in the fine-tuning phase.
3 Topic Similarity Model with Neural
Network
In this section, we explain our neural network
based topic similarity model in detail, as well as
how to incorporate the topic similarity features
into SMT decoding procedure. Figure 1 sketches
the high-level overview which illustrates how to
134
?? = ?(?) ?? = ?(?) 
cos(?? , ??) 
???(?, ?) 
 ?  ? 
 English document collection 
 ??  ?? 
Parallel sentence  
IR IR 
? ? 
 Chinese document collection 
Neural Network Training 
Data Preprocessing 
Figure 1: Overview of neural network based topic
similarity model.
learn topic representations using sentence-level
parallel data. Given a parallel sentence pair ?f, e?,
the first step is to treat f and e as queries, and
use IR methods to retrieve relevant documents to
enrich contextual information for them. Specifi-
cally, the ranking model we used is a Vector Space
Model (VSM), where the query and document are
converted into tf-idf weighted vectors. The most
relevant N documents d
f
and d
e
are retrieved and
converted to a high-dimensional, bag-of-words in-
put f and e for the representation learning
1
.
There are two phases in our neural network
training process: pre-training and fine-tuning. In
the pre-training phase (Section 3.1), we build two
neural networks with the same structure but differ-
ent parameters to learn a low-dimensional repre-
sentation for sentences in two different languages.
Then, in the fine-tuning phase (Section 3.2), our
model directly optimizes the similarity of two low-
dimensional representations, so that it highly cor-
relates to SMT decoding. Finally, the learned rep-
resentation is used to calculate similarities which
are integrated as features in SMT decoding proce-
dure (Section 3.3).
3.1 Pre-training using denoising
auto-encoder
In the pre-training phase, we leverage neural
network structures to transform high-dimensional
sparse vectors to low-dimensional dense vectors.
The topic similarity is calculated on top of the
learned dense vectors. This dense representation
should preserve the information from the bag-of-
1
We use f and e to denote the n-of-V vector converted
from the retrieved documents.
words input, meanwhile alleviate data sparse prob-
lem. Therefore, we use a specially designed mech-
anism called auto-encoder to solve this problem.
Auto-encoder (Bengio et al, 2006) is one of the
basic building blocks of deep learning. Assum-
ing that the input is a n-of-V binary vector x rep-
resenting the bag-of-words (V is the vocabulary
size), an auto-encoder consists of an encoding pro-
cess g(x) and a decoding process h(g(x)). The
objective of the auto-encoder is to minimize the
reconstruction error L(h(g(x)), x). Our goal is to
learn a low-dimensional vector which can preserve
information from the original n-of-V vector.
One problem with auto-encoder is that it treats
all words in the same way, making no distinguish-
ment between function words and content words.
The representation learned by auto-encoders tends
to be influenced by the function words, thereby it
is not robust. To alleviate this problem, Vincent et
al. (2008) proposed the Denoising Auto-Encoder
(DAE), which aims to reconstruct a clean, ?re-
paired? input from a corrupted, partially destroyed
vector. This is done by corrupting the initial in-
put x to get a partially destroyed version
?
x. DAE
is capable of capturing the global structure of the
input while ignoring the noise. In our task, for
each sentence, we treat the retrieved N relevant
documents as a single large document and convert
it to a bag-of-words vector x in Figure 2. With
DAE, the input x is manually corrupted by apply-
ing masking noise (randomly mask 1 to 0) and get-
ting
?
x. Denoising training is considered as ?filling
in the blanks? (Vincent et al, 2010), which means
the masking components can be recovered from
the non-corrupted components. For example, in
IT related texts, if the word driver is masked, it
should be predicted through hidden units in neural
networks by active signals such as ?buffer?, ?user
response?, etc.
In our case, the encoding process transforms
the corrupted input
?
x into g(
?
x) with two layers:
a linear layer connected with a non-linear layer.
Assuming that the dimension of the g(
?
x) is L,
the linear layer forms a L ? V matrix W which
projects the n-of-V vector to a L-dimensional hid-
den layer. After the bag-of-words input has been
transformed, they are fed into a subsequent layer
to model the highly non-linear relations among
words:
z = f(W
?
x + b) (1)
where z is the output of the non-linear layer, b is a
135
? ?? 
?(??) 
(?? ??) 
?(?? ?? ,?) 
Figure 2: Denoising auto-encoder with a bag-of-
words input.
L-length bias vector. f(?) is a non-linear function,
where common choices include sigmoid function,
hyperbolic function, ?hard? hyperbolic function,
rectifier function, etc. In this work, we use the
rectifier function as our non-linear function due to
its efficiency and better performance (Glorot et al,
2011):
rec(x) =
{
x if x > 0
0 otherwise
(2)
The decoding process consists of a linear layer
and a non-linear layer with similar network struc-
tures, but different parameters. It transforms the
L-dimensional vector g(
?
x) to a V -dimensional
vector h(g(
?
x)). To minimize reconstruction error
with respect to
?
x, we define the loss function as
the L2-norm of the difference between the uncor-
rupted input and reconstructed input:
L(h(g(
?
x)), x) = ?h(g(
?
x))? x?
2
(3)
Multi-layer neural networks are trained with the
standard back-propagation algorithm (Rumelhart
et al, 1988). The gradient of the loss function
is calculated and back-propagated to the previous
layer to update its parameters. Training neural net-
works involves many factors such as the learning
rate and the length of hidden layers. We will dis-
cuss the optimization of these parameters in Sec-
tion 4.
3.2 Fine-tuning with parallel data
In the fine-tuning phase, we stack another layer on
top of the two low-dimensional vectors to maxi-
mize the similarity between source and target lan-
guages. The similarity scores are integrated into
the standard log-linear model for making transla-
tion decisions. Since the vectors from DAE are
trained using information from monolingual train-
ing data independently, these vectors may be in-
adequate to measure bilingual topic similarity due
to their different topic spaces. Therefore, in this
stage, parallel sentence pairs are used to help con-
necting the vectors from different languages be-
cause they express the same topic. In fact, the ob-
jective of fine-tuning is to discover a latent topic
space which is shared by both languages as much
as possible. This shared topic space is particularly
useful when the SMT decoder tries to match the
source texts and translation candidates in the tar-
get language.
Given a parallel sentence pair ?f, e?, the DAE
learns representations for f and e respectively, as
z
f
= g(f) and z
e
= g(e) in Figure 1. We then take
two vectors as the input to calculate their similar-
ity. Consequently, the whole neural network can
be fine-tuned towards the supervised criteria with
the help of parallel data. The similarity score of
the representation pair ?z
f
, z
e
? is defined as the co-
sine similarity of the two vectors:
sim(f, e) = cos(z
f
, z
e
)
=
z
f
? z
e
?z
f
??z
e
?
(4)
Since a parallel sentence pair should have the
same topic, our goal is to maximize the similar-
ity score between the source sentence and target
sentence. Inspired by the contrastive estimation
method (Smith and Eisner, 2005), for each paral-
lel sentence pair ?f, e? as a positive instance, we
select another sentence pair ?f
?
, e
?
? from the train-
ing data and treat ?f, e
?
? as a negative instance. To
make the similarity of the positive instance larger
than the negative instance by some margin ?, we
utilize the following pairwise ranking loss:
L(f, e) = max{0, ? ? sim(f, e) + sim(f, e
?
)}
(5)
where ? =
1
2
? sim(f, f
?
). The rationale behind
this criterion is, the smaller sim(f, f
?
) is, the more
we should penalize negative instances.
To effectively train the model in this task, neg-
ative instances must be selected carefully. Since
different sentences may have very similar topic
distributions, we select negative instances that are
dissimilar with the positive instances based on the
following criteria:
1. For each positive instance ?f, e?, we select e
?
which contains at least 30% different content
words from e.
136
2. If we cannot find such e
?
, remove ?f, e? from
the training instances for network learning.
The model minimizes the pairwise ranking loss
across all training instances:
L =
?
?f,e?
L(f, e) (6)
We used standard back-propagation algorithm
to further fine-tune the neural network parameters
W and b in Equation (1). The learned neural net-
works are used to obtain sentence topic representa-
tions, which will be further leveraged to infer topic
representations of bilingual translation rules.
3.3 Integration into SMT decoding
We incorporate the learned topic similarity scores
into the standard log-linear framework for SMT.
When a synchronous rule ??, ?? is extracted from
a sentence pair ?f, e?, a triple instance I =
(??, ??, ?f, e?, c) is collected for inferring the
topic representation of ??, ??, where c is the count
of rule occurrence. Following (Chiang, 2007), we
give a count of one for each phrase pair occurrence
and a fractional count for each hierarchical phrase
pair. The topic representation of ??, ?? is then cal-
culated as the weighted average:
z
?
=
?
(??,??,?f,e?,c)?T
{c? z
f
}
?
(??,??,?f,e?,c)?T
{c}
(7)
z
?
=
?
(??,??,?f,e?,c)?T
{c? z
e
}
?
(??,??,?f,e?,c)?T
{c}
(8)
where T denotes all instances for the rule ??, ??,
z
?
and z
?
are the source-side and target-side topic
vectors respectively.
By measuring the similarity between the source
texts and bilingual translation rules, the SMT de-
coder is able to encourage topic relevant transla-
tion candidates and penalize topic irrelevant candi-
dates. Therefore, it helps to train a smarter transla-
tion model with the embedded topic information.
Given a source sentence s to be translated, we de-
fine the similarity as follows:
Sim(z
s
, z
?
) = cos(z
s
, z
?
) (9)
Sim(z
s
, z
?
) = cos(z
s
, z
?
) (10)
where z
s
is the topic representation of s. The
similarity calculated against z
?
or z
?
denotes the
source-to-source or the source-to-target similarity.
We also consider the topic sensitivity estimation
since general rules have flatter distributions while
topic-specific rules have sharper distributions. A
standard entropy metric is used to measure the sen-
sitivity of the source-side of ??, ?? as:
Sen(?) = ?
|z
?
|
?
i=1
z
?i
? log z
?i
(11)
where z
?i
is a component in the vector z
?
. The
target-side sensitivity Sen(?) can be calculated in
a similar way. The larger the sensitivity is, the
more topic-specific the rule manifests.
In addition to traditional SMT features, we add
new topic-related features into the standard log-
linear framework. For the SMT system, the best
translation candidate e? is given by:
e? = argmax
e
P (e|f) (12)
where the translation probability is given by:
P (e|f) ?
?
i
w
i
? log ?
i
(f, e)
=
?
j
w
j
? log ?
j
(f, e)
? ?? ?
Standard
+
?
k
w
k
? log ?
k
(f, e)
? ?? ?
Topic related
(13)
where ?
j
(f, e) is the standard feature function and
w
j
is the corresponding feature weight. ?
k
(f, e)
is the topic-related feature function and w
k
is the
feature weight. The detailed feature description is
as follows:
Standard features: Translation model, includ-
ing translation probabilities and lexical weights
for both directions (4 features), 5-gram language
model (1 feature), word count (1 feature), phrase
count (1 feature), NULL penalty (1 feature), num-
ber of hierarchical rules used (1 feature).
Topic-related features: rule similarity scores
(2 features), rule sensitivity scores (2 features).
4 Experiments
4.1 Setup
We evaluate the performance of our neural net-
work based topic similarity model on a Chinese-
to-English machine translation task. In neural net-
work training, a large number of monolingual doc-
uments are collected in both source and target lan-
guages. The documents are mainly from two do-
mains: news and weblog. We use Chinese and
137
English Gigaword corpus (Version 5) which are
mainly from news domain. In addition, we also
collect weblog documents with a variety of top-
ics from the web. The total data statistics are
presented in Table 1. These documents are built
in the format of inverted index using Lucene
2
,
which can be efficiently retrieved by the paral-
lel sentence pairs. The most relevant N docu-
ments are collected, where we experiment with
N = {1, 5, 10, 20, 50}.
Domain
Chinese English
Docs Words Docs Words
News 5.7M 5.4B 9.9M 25.6B
Weblog 2.1M 8B 1.2M 2.9B
Total 7.8M 13.4B 11.1M 28.5B
Table 1: Statistics of monolingual data, in num-
bers of documents and words (main content). ?M?
refers to million and ?B? refers to billion.
We implement a distributed framework to speed
up the training process of neural networks. The
network is learned with mini-batch asynchronous
gradient descent with the adaptive learning rate
procedure called AdaGrad (Duchi et al, 2011).
We use 32 model replicas in each iteration during
the training. The model parameters are averaged
after each iteration and sent to each replica for the
next iteration. The vocabulary size for the input
layer is 100,000, and we choose different lengths
for the hidden layer as L = {100, 300, 600, 1000}
in the experiments. In the pre-training phase, all
parallel data is fed into two neural networks re-
spectively for DAE training, where network pa-
rameters W and b are randomly initialized. In
the fine-tuning phase, for each parallel sentence
pair, we randomly select other ten sentence pairs
which satisfy the criterion as negative instances.
These training instances are leveraged to optimize
the similarity of two vectors.
In SMT training, an in-house hierarchical
phrase-based SMT decoder is implemented for our
experiments. The CKY decoding algorithm is
used and cube pruning is performed with the same
default parameter settings as in Chiang (2007).
The parallel data we use is released by LDC
3
. In
total, the datasets contain nearly 1.1 million sen-
tence pairs. Translation models are trained over
the parallel data that is automatically word-aligned
2
http://lucene.apache.org/
3
LDC2003E14, LDC2002E18, LDC2003E07,
LDC2005T06, LDC2005T10, LDC2005E83, LDC2006E34,
LDC2006E85, LDC2006E92, LDC2006E26, LDC2007T09
using GIZA++ in both directions, and the diag-
grow-final heuristic is used to refine symmetric
word alignment. An in-house language modeling
toolkit is used to train the 5-gram language model
with modified Kneser-Ney smoothing (Kneser and
Ney, 1995). The English monolingual data used
for language modeling is the same as in Table
1. The NIST 2003 dataset is the development
data. The testing data consists of NIST 2004,
2005, 2006 and 2008 datasets. The evaluation
metric for the overall translation quality is case-
insensitive BLEU4 (Papineni et al, 2002). The
reported BLEU scores are averaged over 5 times
of running MERT (Och, 2003). A statistical sig-
nificance test is performed using the bootstrap re-
sampling method (Koehn, 2004).
4.2 Baseline
The baseline is a re-implementation of the Hiero
system (Chiang, 2007). The phrase pairs that ap-
pear only once in the parallel data are discarded
because most of them are noisy. We also use
the fix-discount method in Foster et al (2006)
for phrase table smoothing. This implementation
makes the system perform much better and the
translation model size is much smaller.
We compare our method with the LDA-based
approach proposed by Xiao et al (2012). In (Xiao
et al, 2012), the topic of each sentence pair is ex-
actly the same as the document it belongs to. Since
some of our parallel data does not have document-
level information, we rely on the IR method to
retrieve the most relevant document and simulate
this approach. The PLDA toolkit (Liu et al, 2011)
is used to infer topic distributions, which takes
34.5 hours to finish.
4.3 Effect of retrieved documents and length
of hidden layers
We illustrate the relationship among translation
accuracy (BLEU), the number of retrieved docu-
ments (N ) and the length of hidden layers (L) on
different testing datasets. The results are shown in
Figure 3. The best translation accuracy is achieved
when N=10 for most settings. This confirms that
enriching the source text with topic-related doc-
uments is very useful in determining topic repre-
sentations, thereby help to guide the synchronous
rule selection. However, we find that as N be-
comes larger in the experiments, e.g. N=50, the
translation accuracy drops drastically. As more
documents are retrieved, less relevant information
138
0 5 10 20 5042
42.2
42.4
42.6
42.8
43
Number of Retrieved Documents (N)
BLE
U
NIST 2004
 
 L=100L=300L=600L=1000
0 5 10 20 5041
41.2
41.4
41.6
41.8
42
Number of Retrieved Documents (N)
BLE
U
NIST 2005
 
 L=100L=300L=600L=1000
0 5 10 20 5037.8
38
38.2
38.4
38.6
38.8
39
39.2
Number of Retrieved Documents (N)
BLE
U
NIST 2006
 
 L=100L=300L=600L=1000
0 5 10 20 5031
31.2
31.4
31.6
31.8
32
Number of Retrieved Documents (N)
BLE
U
NIST 2008
 
 L=100L=300L=600L=1000
Figure 3: End-to-end translation results (BLEU%) using all standard and topic-related features, with
different settings on the number of retrieved documents N and the length of hidden layers L.
is also used to train the neural networks. Irrel-
evant documents bring so many unrelated topic
words hence degrade neural network learning per-
formance.
Another important factor is the length of hid-
den layers L in the network. In deep learning, this
parameter is often empirically tuned with human
efforts. As shown in Figure 3, the translation accu-
racy is better when L is relatively small. Actually,
there is no obvious distinction of the performance
when L is less than 600. However, when L equals
1,000, the translation accuracy is inferior to other
settings. The main reason is that parameters in
the neural networks are too many to be effectively
trained. As we know when L=1000, there are a
total of 100, 000? 1, 000 parameters between the
linear and non-linear layers in the network. Lim-
ited training data prevents the model from getting
close to the global optimum. Therefore, the model
is likely to fall in local optima and lead to unac-
ceptable representations.
4.4 Effect of topic related features
We evaluate the performance of adding new topic-
related features to the log-linear model and com-
pare the translation accuracy with the method in
(Xiao et al, 2012). To make different methods
comparable, we set the dimension of topic rep-
resentation as 100 for all settings. This takes 10
hours in pre-training phase and 22 hours in fine-
tuning phase. Table 2 shows how the accuracy is
improved with more features added. The results
confirm that topic information is indispensable for
SMT since both (Xiao et al, 2012) and our neural
network based method significantly outperforms
the baseline system. Our method improves 0.86
BLEU points at most and 0.76 BLEU points on
average over the baseline. We observe that source-
side similarity is more effective than target-side
similarity, but their contributions are cumulative.
This proves that bilingually induced topic repre-
sentation with neural network helps the SMT sys-
tem disambiguate translation candidates. Further-
more, rule sensitivity features improve SMT per-
formance compared with only using similarity fea-
tures. Because topic-specific rules usually have a
larger sensitivity score, they can beat general rules
when they obtain the same similarity score against
the input sentence. Finally, when all new fea-
tures are integrated, the performance is the best,
preforming substantially better than (Xiao et al,
2012) with 0.39 BLEU points on average.
It is worth mentioning that the performance
of (Xiao et al, 2012) is similar to the settings
with N=1 and L=100 in Figure 3. This is not
simply coincidence since we can interpret their
approach as a special case in our neural net-
work method: when a parallel sentence pair has
139
Settings NIST 2004 NIST 2005 NIST 2006 NIST 2008 Average
Baseline 42.25 41.21 38.05 31.16 38.17
(Xiao et al, 2012) 42.58 41.61 38.39 31.58 38.54
Sim(Src) 42.51 41.55 38.53 31.57 38.54
Sim(Trg) 42.43 41.48 38.4 31.49 38.45
Sim(Src+Trg) 42.7 41.66 38.66 31.66 38.67
Sim(Src+Trg)+Sen(Src) 42.77 41.81 38.85 31.73 38.79
Sim(Src+Trg)+Sen(Trg) 42.85 41.79 38.76 31.7 38.78
Sim(Src+Trg)+Sen(Src+Trg) 42.95 41.97 38.91 31.88 38.93
Table 2: Effectiveness of different features in BLEU% (p < 0.05), with N=10 and L=100. ?Sim?
denotes the rule similarity feature and ?Sen? denotes rule sensitivity feature. ?Src? and ?Trg? means
utilizing source-side/target-side rule topic vectors to calculate similarity or sensitivity, respectively. The
?Average? setting is the averaged result of four datasets.
document-level information, that document will
be retrieved for training; otherwise, the most rel-
evant document will be retrieved from the mono-
lingual data. Therefore, our method can be viewed
as a more general framework than previous LDA-
based approaches.
4.5 Discussion
In this section, we give a case study to explain
why our method works. An example of transla-
tion rule disambiguation for a sentence from the
NIST 2005 dataset is shown in Figure 4. We find
that the topic of this sentence is about ?rescue af-
ter a natural disaster?. Under this topic, the Chi-
nese rule ??? X? should be translated to ?de-
liver X? or ?distribute X?. However, the baseline
system prefers ?send X? rather than those two can-
didates. Although the translation probability of
?send X? is much higher, it is inappropriate in this
context since it is usually used in IT texts. For
example, ?????, send emails?, ?????,
send messages? and ?????, send data?. In
contrast, with our neural network based approach,
the learned topic distributions of ?deliver X? or
?distribute X? are more similar with the input sen-
tence than ?send X?, which is shown in Figure 4.
The similarity scores indicate that ?deliver X? and
?distribute X? are more appropriate to translate the
sentence. Therefore, adding topic-related features
is able to keep the topic consistency and substan-
tially improve the translation accuracy.
5 Related Work
Topic modeling was first leveraged to improve
SMT performance in (Zhao and Xing, 2006; Zhao
and Xing, 2007). They proposed a bilingual
topical admixture approach for word alignment
and assumed that each word-pair follows a topic-
specific model. They reported extensive empir-
ical analysis and improved word alignment ac-
curacy as well as translation quality. Follow-
ing this work, (Xiao et al, 2012) extended topic-
specific lexicon translation models to hierarchical
phrase-based translation models, where the topic
information of synchronous rules was directly in-
ferred with the help of document-level informa-
tion. Experiments show that their approach not
only achieved better translation performance but
also provided a faster decoding speed compared
with previous lexicon-based LDA methods.
Another direction of approaches leveraged topic
modeling techniques for domain adaptation. Tam
et al (2007) used bilingual LSA to learn latent
topic distributions across different languages and
enforce one-to-one topic correspondence during
model training. They incorporated the bilingual
topic information into language model adaptation
and lexicon translation model adaptation, achiev-
ing significant improvements in the large-scale
evaluation. (Su et al, 2012) investigated the rela-
tionship between out-of-domain bilingual data and
in-domain monolingual data via topic mapping
using HTMM methods. They estimated phrase-
topic distributions in translation model adaptation
and generated better translation quality. Recently,
Chen et al (2013) proposed using vector space
model for adaptation where genre resemblance is
leveraged to improve translation accuracy. We
also investigated multi-domain adaptation where
explicit topic information is used to train domain
specific models (Cui et al, 2013).
Generally, most previous research has leveraged
conventional topic modeling techniques such as
LDA or HTMM. In our work, a novel neural net-
work based approach is proposed to infer topic
representations for parallel data. The advantage of
140
S
rc
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
R
ef
(1
)
th
e
un
it
ed
na
ti
on
s
ch
il
dr
en
?s
fu
nd
ha
s
al
so
be
gu
n
de
li
ve
ri
ng
ba
si
c
m
ed
ic
al
ki
ts
(2
)
th
e
un
ic
ef
ha
s
al
so
st
ar
te
d
to
di
st
ri
bu
te
ba
si
c
m
ed
ic
al
ki
ts
(3
)
th
e
un
it
ed
na
ti
on
s
ch
il
dr
en
?s
fu
nd
ha
s
al
so
be
gu
n
di
st
ri
bu
ti
ng
ba
si
c
m
ed
ic
al
ki
ts
(4
)
th
e
un
it
ed
na
ti
on
s
ch
il
dr
en
?s
fu
nd
ha
s
be
gu
n
de
li
ve
ri
ng
ba
si
c
m
ed
ic
al
ki
ts
B
as
el
in
e
th
e
un
it
ed
na
ti
on
s
ch
il
dr
en
?s
fu
nd
be
ga
n
to
se
nd
ba
si
c
m
ed
ic
al
ki
ts
O
ur
s
th
e
un
it
ed
na
ti
on
s
ch
il
dr
en
?s
fu
nd
ha
s
be
gu
n
to
di
st
ri
bu
te
ba
si
c
m
ed
ic
al
ki
ts
T
ab
le
4:
A
ck
n
ow
le
d
gm
en
ts
T
he
ac
kn
ow
le
dg
m
en
ts
sh
ou
ld
go
im
m
ed
ia
te
ly
be
-
fo
re
th
e
re
fe
re
nc
es
.
D
o
no
t
nu
m
be
r
th
e
ac
kn
ow
l-
ed
gm
en
ts
se
ct
io
n.
D
o
no
t
in
cl
ud
e
th
is
se
ct
io
n
w
he
n
su
bm
it
ti
ng
yo
ur
pa
pe
r
fo
r
re
vi
ew
.
R
ef
er
en
ce
s
Y
os
hu
a
B
en
gi
o,
P
as
ca
l
L
am
bl
in
,
D
an
P
op
ov
ic
i,
an
d
H
ug
o
L
ar
oc
he
ll
e.
20
06
.
G
re
ed
y
la
ye
r-
w
is
e
tr
ai
n-
in
g
of
de
ep
ne
tw
or
ks
.
In
B
.
S
ch
o?l
ko
pf
,
J.
P
la
tt
,
an
d
T
.
H
of
fm
an
,
ed
it
or
s,
A
dv
an
ce
s
in
N
eu
ra
l
In
fo
rm
a-
ti
on
P
ro
ce
ss
in
g
Sy
st
em
s
19
,
pa
ge
s
15
3?
16
0.
M
IT
P
re
ss
,C
am
br
id
ge
,M
A
.
Y
os
hu
a
B
en
gi
o.
20
09
.
L
ea
rn
in
g
de
ep
ar
ch
it
ec
tu
re
s
fo
r
ai
.
Fo
un
d.
Tr
en
ds
M
ac
h.
L
ea
rn
.,
2(
1)
:1
?1
27
,
Ja
n-
ua
ry
.
D
av
id
M
.
B
le
i,
A
nd
re
w
Y
.
N
g,
an
d
M
ic
ha
el
I.
Jo
rd
an
.
20
03
.
L
at
en
t
di
ri
ch
le
t
al
lo
ca
ti
on
.
J.
M
ac
h.
L
ea
rn
.
R
es
.,
3:
99
3?
10
22
,M
ar
ch
.
M
ar
in
e
C
ar
pu
at
an
d
D
ek
ai
W
u.
20
07
.
C
on
te
xt
-
de
pe
nd
en
t
ph
ra
sa
l
tr
an
sl
at
io
n
le
xi
co
ns
fo
r
st
at
is
ti
ca
l
m
ac
hi
ne
tr
an
sl
at
io
n.
P
ro
ce
ed
in
gs
of
M
ac
hi
ne
Tr
an
s-
la
ti
on
Su
m
m
it
X
I,
pa
ge
s
73
?8
0.
D
av
id
C
hi
an
g.
20
07
.
H
ie
ra
rc
hi
ca
l
ph
ra
se
-b
as
ed
tr
an
s-
la
ti
on
.
C
om
pu
ta
ti
on
al
L
in
gu
is
ti
cs
,3
3(
2)
:2
01
?2
28
.
R
on
an
C
ol
lo
be
rt
,J
as
on
W
es
to
n,
L
e?o
n
B
ot
to
u,
M
ic
ha
el
K
ar
le
n,
K
or
ay
K
av
uk
cu
og
lu
,
an
d
P
av
el
K
uk
sa
.
20
11
.
N
at
ur
al
la
ng
ua
ge
pr
oc
es
si
ng
(a
lm
os
t)
fr
om
sc
ra
tc
h.
J.
M
ac
h.
L
ea
rn
.
R
es
.,
12
:2
49
3?
25
37
,
N
ov
em
be
r.
G
.
E
.
D
ah
l,
D
on
g
Y
u,
L
i
D
en
g,
an
d
A
.
A
ce
ro
.
20
12
.
C
on
te
xt
-d
ep
en
de
nt
pr
e-
tr
ai
ne
d
de
ep
ne
ur
al
ne
tw
or
ks
fo
r
la
rg
e-
vo
ca
bu
la
ry
sp
ee
ch
re
co
gn
it
io
n.
Tr
an
s.
A
u-
di
o,
Sp
ee
ch
an
d
L
an
g.
P
ro
c.
,2
0(
1)
:3
0?
42
,J
an
ua
ry
.
Jo
hn
D
uc
hi
,
E
la
d
H
az
an
,
an
d
Y
or
am
S
in
ge
r.
20
11
.
A
da
pt
iv
e
su
bg
ra
di
en
t
m
et
ho
ds
fo
r
on
li
ne
le
ar
ni
ng
an
d
st
oc
ha
st
ic
op
ti
m
iz
at
io
n.
J.
M
ac
h.
L
ea
rn
.
R
es
.,
12
:2
12
1?
21
59
,J
ul
y.
G
eo
rg
e
F
os
te
r,
R
ol
an
d
K
uh
n,
an
d
H
ow
ar
d
Jo
hn
so
n.
20
06
.
P
hr
as
et
ab
le
sm
oo
th
in
g
fo
r
st
at
is
ti
ca
l
m
ac
hi
ne
tr
an
sl
at
io
n.
In
P
ro
ce
ed
in
gs
of
th
e
20
06
C
on
fe
re
nc
e
on
E
m
pi
ri
ca
l
M
et
ho
ds
in
N
at
ur
al
L
an
gu
ag
e
P
ro
-
ce
ss
in
g,
pa
ge
s
53
?6
1,
S
yd
ne
y,
A
us
tr
al
ia
,
Ju
ly
.
A
s-
so
ci
at
io
n
fo
r
C
om
pu
ta
ti
on
al
L
in
gu
is
ti
cs
.
A
m
it
G
ru
be
r,
M
ic
ha
lR
os
en
-z
vi
,a
nd
Y
ai
r
W
ei
ss
.
20
07
.
H
id
de
n
to
pi
c
m
ar
ko
v
m
od
el
s.
In
In
P
ro
ce
ed
in
gs
of
A
rt
ifi
ci
al
In
te
ll
ig
en
ce
an
d
St
at
is
ti
cs
.
Z
ho
ng
ju
n
H
e,
Q
un
L
iu
,
an
d
S
ho
ux
un
L
in
.
20
08
.
Im
-
pr
ov
in
g
st
at
is
ti
ca
lm
ac
hi
ne
tr
an
sl
at
io
n
us
in
g
le
xi
ca
l-
iz
ed
ru
le
se
le
ct
io
n.
In
P
ro
ce
ed
in
gs
of
th
e
22
nd
In
-
te
rn
at
io
na
l
C
on
fe
re
nc
e
on
C
om
pu
ta
ti
on
al
L
in
gu
is
-
ti
cs
(C
ol
in
g
20
08
),
pa
ge
s
32
1?
32
8,
M
an
ch
es
te
r,
U
K
,
A
ug
us
t.
C
ol
in
g
20
08
O
rg
an
iz
in
g
C
om
m
it
te
e.
G
eo
ff
re
y
E
.
H
in
to
n,
S
im
on
O
si
nd
er
o,
an
d
Y
ee
-W
hy
e
T
eh
.
20
06
.
A
fa
st
le
ar
ni
ng
al
go
ri
th
m
fo
r
de
ep
be
li
ef
ne
ts
.
N
eu
ra
l
C
om
pu
t.
,1
8(
7)
:1
52
7?
15
54
,J
ul
y.
R
ei
nh
ar
d
K
ne
se
r
an
d
H
er
m
an
n
N
ey
.
19
95
.
Im
-
pr
ov
ed
ba
ck
in
g-
of
f
fo
r
m
-g
ra
m
la
ng
ua
ge
m
od
el
in
g.
In
A
co
us
ti
cs
,
Sp
ee
ch
,
an
d
Si
gn
al
P
ro
ce
ss
in
g,
19
95
.
IC
A
SS
P
-9
5.
,1
99
5
In
te
rn
at
io
na
lC
on
fe
re
nc
e
on
,v
ol
-
um
e
1,
pa
ge
s
18
1?
18
4.
IE
E
E
.
P
hi
li
pp
K
oe
hn
.
20
04
.
S
ta
ti
st
ic
al
si
gn
ifi
ca
nc
e
te
st
s
fo
r
m
ac
hi
ne
tr
an
sl
at
io
n
ev
al
ua
ti
on
.
In
D
ek
an
g
L
in
an
d
D
ek
ai
W
u,
ed
it
or
s,
P
ro
ce
ed
in
gs
of
E
M
N
L
P
20
04
,
pa
ge
s
38
8?
39
5,
B
ar
ce
lo
na
,
S
pa
in
,
Ju
ly
.
A
ss
oc
ia
ti
on
fo
r
C
om
pu
ta
ti
on
al
L
in
gu
is
ti
cs
.
A
le
x
K
ri
zh
ev
sk
y,
Il
ya
S
ut
sk
ev
er
,
an
d
G
eo
ff
H
in
to
n.
20
12
.
Im
ag
en
et
cl
as
si
fi
ca
ti
on
w
it
h
de
ep
co
nv
ol
u-
ti
on
al
ne
ur
al
ne
tw
or
ks
.
In
P.
B
ar
tl
et
t,
F.
C
.N
.P
er
ei
ra
,
C
.J
.C
.
B
ur
ge
s,
L
.
B
ot
to
u,
an
d
K
.Q
.
W
ei
nb
er
ge
r,
ed
-
it
or
s,
A
dv
an
ce
s
in
N
eu
ra
l
In
fo
rm
at
io
n
P
ro
ce
ss
in
g
Sy
st
em
s
25
,p
ag
es
11
06
?1
11
4.
H
on
gl
ak
L
ee
,
A
le
xi
s
B
at
tl
e,
R
aj
at
R
ai
na
,
an
d
A
n-
dr
ew
Y
.
N
g.
20
06
.
E
ffi
ci
en
t
sp
ar
se
co
di
ng
al
go
-
ri
th
m
s.
In
B
.
S
ch
o?l
ko
pf
,
J.
P
la
tt
,
an
d
T
.
H
of
fm
an
,
ed
it
or
s,
A
dv
an
ce
s
in
N
eu
ra
l
In
fo
rm
at
io
n
P
ro
ce
ss
in
g
Sy
st
em
s
19
,p
ag
es
80
1?
80
8.
M
IT
P
re
ss
,C
am
br
id
ge
,
M
A
.
Q
un
L
iu
,
Z
ho
ng
ju
n
H
e,
Y
an
g
L
iu
,
an
d
S
ho
ux
un
L
in
.
20
08
.
M
ax
im
um
en
tr
op
y
ba
se
d
ru
le
se
le
ct
io
n
m
od
el
fo
r
sy
nt
ax
-b
as
ed
st
at
is
ti
ca
l
m
ac
hi
ne
tr
an
sl
at
io
n.
In
P
ro
ce
ed
in
gs
of
th
e
20
08
C
on
fe
re
nc
e
on
E
m
pi
ri
ca
l
M
et
ho
ds
in
N
at
ur
al
L
an
gu
ag
e
P
ro
ce
ss
in
g,
pa
ge
s
89
?9
7,
H
on
ol
ul
u,
H
aw
ai
i,
O
ct
ob
er
.
A
ss
oc
ia
ti
on
fo
r
C
om
pu
ta
ti
on
al
L
in
gu
is
ti
cs
.
Z
hi
yu
an
L
iu
,
Y
uz
ho
u
Z
ha
ng
,
E
dw
ar
d
Y
.
C
ha
ng
,
an
d
M
ao
so
ng
S
un
.
20
11
.
P
ld
a+
:
P
ar
al
le
l
la
te
nt
di
ri
ch
le
t
al
lo
ca
ti
on
w
it
h
da
ta
pl
ac
em
en
ta
nd
pi
pe
li
ne
pr
oc
es
s-
in
g.
A
C
M
Tr
an
sa
ct
io
ns
on
In
te
ll
ig
en
t
Sy
st
em
s
an
d
Te
ch
no
lo
gy
,
sp
ec
ia
l
is
su
e
on
L
ar
ge
Sc
al
e
M
ac
hi
ne
L
ea
rn
in
g.
S
of
tw
ar
e
av
ai
la
bl
e
at
h
t
t
p
:
/
/
c
o
d
e
.
g
o
o
g
l
e
.
c
o
m
/
p
/
p
l
d
a
.
0
20
40
60
80
100
00.020.040.060.080.1???
???
???
???
???
???
0
20
40
60
80
100
00.020.040.060.080.1
<?? 
X , de
liver 
X>
0
20
40
60
80
100
00.020.040.060.080.1
<?? 
X , di
stribu
te X>
0
20
40
60
80
100
00.020.040.060.080.1
<?? 
X , se
nd X>
S
et
ti
n
gs
N
IS
T
20
04
N
IS
T
20
05
N
IS
T
20
06
N
IS
T
20
08
A
ve
ra
ge
B
as
el
in
e
42
.2
5
41
.2
1
38
.0
5
31
.1
6
38
.1
7
(X
ia
o
et
al
.,
20
12
)
42
.5
8
41
.6
1
38
.3
9
31
.5
8
38
.5
4
S
im
(S
rc
)
42
.5
1
41
.5
5
38
.5
3
31
.5
7
38
.5
4
S
im
(T
rg
)
42
.4
3
41
.4
8
38
.4
31
.4
9
38
.4
5
S
im
(S
rc
+
T
rg
)
42
.7
41
.6
6
38
.6
6
31
.6
6
38
.6
7
S
im
(S
rc
+
T
rg
)+
S
en
(S
rc
)
42
.7
7
41
.8
1
38
.8
5
31
.7
3
38
.7
9
S
im
(S
rc
+
T
rg
)+
S
en
(T
rg
)
42
.8
5
41
.7
9
38
.7
6
31
.7
38
.7
8
S
im
(S
rc
+
T
rg
)+
S
en
(S
rc
+
T
rg
)
42
.9
5
41
.9
7
38
.9
1
31
.8
8
38
.9
3
T
ab
le
2:
E
ff
ec
ti
ve
ne
ss
of
di
ff
er
en
t
fe
at
ur
es
in
B
L
E
U
%
(p
<
0.
05
),
w
it
h
N
=
10
an
d
L
=
10
0.
?S
im
?
de
no
te
s
th
e
ru
le
si
m
il
ar
it
y
fe
at
ur
e
an
d
?S
en
?
de
no
te
s
ru
le
se
ns
it
iv
it
y
fe
at
ur
e.
?S
rc
?
an
d
?T
rg
?
m
ea
ns
ut
il
iz
in
g
so
ur
ce
-s
id
e/
ta
rg
et
-s
id
e
ru
le
to
pi
c
ve
ct
or
s
to
ca
lc
ul
at
e
si
m
il
ar
it
y
or
se
ns
it
iv
it
y,
re
sp
ec
ti
ve
ly
.
T
he
?A
ve
ra
ge
?
se
tt
in
g
is
th
e
av
er
ag
ed
re
su
lt
s
of
fo
ur
da
ta
se
ts
.
pa
re
d
w
it
h
on
ly
us
in
g
si
m
il
ar
it
y
fe
at
ur
es
.
B
ec
au
se
to
pi
c-
sp
ec
ifi
c
ru
le
s
us
ua
ll
y
ha
ve
a
la
rg
er
se
ns
it
iv
-
it
y
sc
or
e,
th
ey
ca
n
be
at
ge
ne
ra
l
ru
le
s
w
he
n
th
ey
ob
ta
in
th
e
sa
m
e
si
m
il
ar
it
y
sc
or
e
ag
ai
ns
t
th
e
in
pu
t
se
nt
en
ce
.
F
in
al
ly
,
w
he
n
al
l
ne
w
fe
at
ur
es
ar
e
in
-
te
gr
at
ed
,
th
e
pe
rf
or
m
an
ce
is
th
e
be
st
,
pr
ef
or
m
in
g
su
bs
ta
nt
ia
ll
y
be
tt
er
th
an
(X
ia
o
et
al
.,
20
12
)
w
it
h
0.
39
B
L
E
U
po
in
ts
on
av
er
ag
e.
O
ne
in
te
re
st
in
g
ob
se
rv
at
io
n
is
,t
he
pe
rf
or
m
an
ce
of
(X
ia
o
et
al
.,
20
12
)
is
qu
it
e
si
m
il
ar
to
th
e
se
t-
ti
ng
s
w
it
h
N
=
1
an
d
L
=
10
0
in
F
ig
ur
e
3.
T
hi
s
is
no
t
si
m
pl
y
co
in
ci
de
nc
e
si
nc
e
w
e
ca
n
in
te
rp
re
t
th
ei
r
ap
pr
oa
ch
as
a
sp
ec
ia
l
ca
se
in
ou
r
ne
ur
al
ne
t-
w
or
k
m
et
ho
d.
W
he
n
a
pa
ra
ll
el
se
nt
en
ce
pa
ir
ha
s
do
cu
m
en
t-
le
ve
l
in
fo
rm
at
io
n,
th
at
do
cu
m
en
t
w
il
l
be
re
tr
ie
ve
d
fo
r
tr
ai
ni
ng
.
O
th
er
w
is
e,
th
e
m
os
ts
im
-
il
ar
do
cu
m
en
t
w
il
l
be
ob
ta
in
ed
fr
om
th
e
m
on
ol
in
-
gu
al
da
ta
.
O
ur
m
et
ho
d
ca
n
be
vi
ew
ed
as
a
m
or
e
ge
ne
ra
l
fr
am
ew
or
k
th
an
pr
ev
io
us
L
D
A
-b
as
ed
ap
-
pr
oa
ch
es
.
4.
5
D
is
cu
ss
io
n
In
ou
r
ex
pe
ri
m
en
ts
,
In
pr
ev
io
us
L
D
A
-b
as
ed
m
et
ho
d,
if
a
do
cu
m
en
t
D
oc
co
nt
ai
ns
M
se
nt
en
ce
s,
al
l
M
se
nt
en
ce
s
w
il
l
sh
ar
e
th
e
sa
m
e
to
pi
c
di
st
ri
bu
ti
on
of
D
oc
.
A
l-
th
ou
gh
di
ff
er
en
t
se
nt
en
ce
s
m
ay
ex
pr
es
s
sl
ig
ht
ly
di
ff
er
en
t
im
pl
ic
at
io
ns
an
d
th
e
to
pi
c
w
il
l
ch
an
ge
,
th
e
co
nv
en
ti
on
al
L
D
A
-b
as
ed
ap
pr
oa
ch
do
es
no
t
ta
ke
th
e
to
pi
c
tr
an
si
ti
on
in
to
co
ns
id
er
at
io
n.
In
co
n-
tr
as
t,
ou
r
ap
pr
oa
ch
di
re
ct
ly
le
ar
ns
th
e
to
pi
c
re
p-
re
se
nt
at
io
n
w
it
h
an
ab
un
da
nc
y
of
re
la
te
d
do
cu
-
m
en
ts
.
In
ad
di
ti
on
al
to
th
e
or
ig
in
al
do
cu
m
en
tf
ro
m
w
hi
ch
th
e
se
nt
en
ce
is
ex
tr
ac
te
d,
th
e
IR
m
et
ho
d
al
so
re
tr
ie
ve
s
ot
he
r
re
le
va
nt
do
cu
m
en
ts
w
hi
ch
pr
o-
vi
de
co
m
pl
em
en
ta
ry
to
pi
c
in
fo
rm
at
io
n.
T
he
re
fo
re
,
th
e
to
pi
c
re
pr
es
en
ta
ti
on
s
le
ar
ne
d
ar
e
m
or
e
fi
ne
-
gr
ai
ne
d
an
d
th
us
m
or
e
ac
cu
ra
te
.
R
u
le
s
P
(?
|?
)
S
im
(z
s
,z
?
)
??
?
X
,d
el
iv
er
X
?
0.
02
37
0.
84
69
??
?
X
,d
is
tr
ib
ut
e
X
?
0.
05
46
0.
82
68
??
?
X
,s
en
d
X
?
0.
24
64
0.
61
19
T
ab
le
3:
D
ev
el
op
m
en
ta
nd
te
st
in
g
da
ta
us
ed
in
th
e
ex
pe
ri
m
en
ts
.
5
R
el
at
ed
W
or
k
T
op
ic
m
od
el
in
g
w
as
fi
rs
t
le
ve
ra
ge
d
to
im
pr
ov
e
S
M
T
pe
rf
or
m
an
ce
in
(Z
ha
o
an
d
X
in
g,
20
06
;Z
ha
o
an
d
X
in
g,
20
07
).
T
he
y
pr
op
os
ed
a
bi
li
ng
ua
l
to
pi
ca
l
ad
m
ix
tu
re
ap
pr
oa
ch
fo
r
w
or
d
al
ig
nm
en
t
an
d
as
su
m
ed
th
at
ea
ch
w
or
d-
pa
ir
fo
ll
ow
s
a
to
pi
c-
sp
ec
ifi
c
m
od
el
.
T
he
y
re
po
rt
ed
ex
te
ns
iv
e
em
pi
r-
ic
al
an
al
ys
is
an
d
im
pr
ov
ed
w
or
d
al
ig
nm
en
t
ac
-
cu
ra
cy
as
w
el
l
as
tr
an
sl
at
io
n
qu
al
it
y.
F
ol
lo
w
-
in
g
th
is
w
or
k,
(X
ia
o
et
al
.,
20
12
)
ex
te
nd
ed
to
pi
c-
sp
ec
ifi
c
le
xi
co
n
tr
an
sl
at
io
n
m
od
el
s
to
hi
er
ar
ch
ic
al
ph
ra
se
-b
as
ed
tr
an
sl
at
io
n
m
od
el
s,
w
he
re
th
e
to
pi
c
in
fo
rm
at
io
n
of
sy
nc
hr
on
ou
s
ru
le
s
w
as
di
re
ct
ly
in
-
fe
rr
ed
w
it
h
th
e
he
lp
of
do
cu
m
en
t-
le
ve
l
in
fo
rm
a-
ti
on
.
E
xp
er
im
en
ts
sh
ow
th
at
th
ei
r
ap
pr
oa
ch
no
t
on
ly
ac
hi
ev
ed
be
tt
er
tr
an
sl
at
io
n
pe
rf
or
m
an
ce
bu
t
al
so
pr
ov
id
ed
a
fa
st
er
de
co
di
ng
sp
ee
d
co
m
pa
re
d
w
it
h
pr
ev
io
us
le
xi
co
n-
ba
se
d
m
et
ho
ds
.
A
no
th
er
di
re
ct
io
n
of
ap
pr
oa
ch
es
le
ve
ra
ge
d
to
pi
c
m
od
el
in
g
te
ch
ni
qu
es
fo
r
do
m
ai
n
ad
ap
ta
ti
on
.
T
am
et
al
.
(2
00
7)
us
ed
bi
li
ng
ua
l
L
S
A
to
le
ar
n
la
te
nt
to
pi
c
di
st
ri
bu
ti
on
s
ac
ro
ss
di
ff
er
en
t
la
ng
ua
ge
s
an
d
en
fo
rc
e
on
e-
to
-o
ne
to
pi
c
co
rr
es
po
nd
en
ce
du
ri
ng
m
od
el
tr
ai
ni
ng
.
T
he
y
in
co
rp
or
at
ed
th
e
bi
li
ng
ua
l
to
pi
c
in
fo
rm
at
io
n
in
to
la
ng
ua
ge
m
od
el
ad
ap
ta
ti
on
an
d
le
xi
co
n
tr
an
sl
at
io
n
m
od
el
ad
ap
ta
ti
on
,
ac
hi
ev
-
in
g
si
gn
ifi
ca
nt
im
pr
ov
em
en
ts
in
th
e
la
rg
e-
sc
al
e
ev
al
ua
ti
on
.
(S
u
et
al
.,
20
12
)
in
ve
st
ig
at
ed
th
e
re
la
-
ti
on
sh
ip
be
tw
ee
n
ou
t-
of
-d
om
ai
n
bi
li
ng
ua
ld
at
a
an
d
in
-d
om
ai
n
m
on
ol
in
gu
al
da
ta
vi
a
to
pi
c
m
ap
pi
ng
us
-
Figure 4: An exampl from the NIST 2005 dataset. We ill strate the normalized topic repres ntations of
the source sentence and three ambiguous synchronous rules. Details are explained in Section 4.5.
our method is that it is applicable to both sentence-
level and doc ment-level SMT, since we do not
place any restricti ns on the input. In addition, our
method directly maximizes the similarity between
parallel sentence pairs, which is ideal for SMT de-
coding. Compared to document-level topic mod-
eling which uses the topic of a document for all
sentences within the document (Xiao et al, 2012),
our contributions are:
? We proposed a more general approach to
leveraging topic information for SMT by us-
ing IR methods to get a collection of related
documents, regardless of whether or not doc-
ument boundaries are explicitly given.
? We used neural networks to learn topic repre-
sentations more accurately, with more practi-
cable and scalable modeling techniques.
? We directly optimized bilingual topic simi-
larity in the deep learning framework with
the help of sentence-level parallel data, so
that the learned representation could be easily
used in SMT decoding procedure.
6 Conclusion and Future Work
In this paper, we propose a neural network based
approach to learning bilingual topic representa-
tion for SMT. We enrich contexts of parallel sen-
tence pairs with topic related monolingual data
and obtain a set of documents to represent sen-
tences. These documents are converted to a bag-
of-words input and fed into neural networks. The
learned low-dimensional vector is used to obtain
the topic representations of synchronous rules. In
SMT decoding, appropriate rules a e selected to
best match source texts according to their similar-
ity in the topic space. Experimental results show
that our approach is promising for SMT systems to
learn a better translation model. It is a significant
improvement over the state-of-the-art Hiero sys-
tem, as well as a conventional LDA-based method.
In the future research, we will extend our neural
network methods to address document-level trans-
lation, where topic transition between sentences is
a crucial problem to be solved. Since the transla-
tion of the current sentence is usually influenced
by the topic of previous sentences, we plan to
leverage recurrent neural networks to model this
phenomenon, where the history translation infor-
mation is naturally combined in the model.
Acknowledgments
We are grateful to the anonymous reviewers for
their insightful comments. We also thank Fei
Huang (BBN), Nan Yang, Yajuan Duan, Hong Sun
and Duyu Tang for the helpful discussions. This
work is supported by the National Natural Science
Foundation of China (Granted No. 61272384)
141
References
Yoshua Bengio, Pascal Lamblin, Dan Popovici, and
Hugo Larochelle. 2006. Greedy layer-wise train-
ing of deep networks. In B. Sch?olkopf, J. Platt, and
T. Hoffman, editors, Advances in Neural Informa-
tion Processing Systems 19, pages 153?160. MIT
Press, Cambridge, MA.
Yoshua Bengio. 2009. Learning deep architectures for
ai. Found. Trends Mach. Learn., 2(1):1?127, Jan-
uary.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet alocation. J. Mach. Learn.
Res., 3:993?1022, March.
Marine Carpuat and Dekai Wu. 2005. Word sense dis-
ambiguation vs. statistical machine translation. In
Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics (ACL?05),
pages 387?394, Ann Arbor, Michigan, June. Asso-
ciation for Computational Linguistics.
Marine Carpuat and Dekai Wu. 2007. Context-
dependent phrasal translation lexicons for statistical
machine translation. Proceedings of Machine Trans-
lation Summit XI, pages 73?80.
Boxing Chen, Roland Kuhn, and George Foster. 2013.
Vector space model for adaptation in statistical ma-
chine translation. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1285?
1293, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228.
Ronan Collobert, Jason Weston, L?eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. J. Mach. Learn. Res., 12:2493?2537,
November.
Lei Cui, Xilun Chen, Dongdong Zhang, Shujie Liu,
Mu Li, and Ming Zhou. 2013. Multi-domain adap-
tation for SMT using multi-task learning. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1055?
1065, Seattle, Washington, USA, October. Associa-
tion for Computational Linguistics.
George E. Dahl, Dong Yu, Li Deng, and Alex Acero.
2012. Context-dependent pre-trained deep neural
networks for large-vocabulary speech recognition.
IEEE Transactions on Audio, Speech and Language
Processing, 20(1):30?42, January.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. J. Mach. Learn. Res.,
12:2121?2159, July.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable smoothing for statistical machine
translation. In Proceedings of the 2006 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 53?61, Sydney, Australia, July. As-
sociation for Computational Linguistics.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Deep sparse rectifier networks. In Proceed-
ings of the 14th International Conference on Arti-
ficial Intelligence and Statistics. JMLR W&CP Vol-
ume, volume 15, pages 315?323.
Amit Gruber, Michal Rosen-zvi, and Yair Weiss. 2007.
Hidden topic markov models. In In Proceedings of
Artificial Intelligence and Statistics.
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexical-
ized rule selection. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (Coling 2008), pages 321?328, Manchester, UK,
August. Coling 2008 Organizing Committee.
Geoffrey E. Hinton, Simon Osindero, and Yee-Whye
Teh. 2006. A fast learning algorithm for deep belief
nets. Neural Comput., 18(7):1527?1554, July.
Reinhard Kneser and Hermann Ney. 1995. Im-
proved backing-off for m-gram language modeling.
In Acoustics, Speech, and Signal Processing, 1995.
ICASSP-95., 1995 International Conference on, vol-
ume 1, pages 181?184. IEEE.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388?395, Barcelona, Spain, July. Association
for Computational Linguistics.
Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton.
2012. Imagenet classification with deep convolu-
tional neural networks. In P. Bartlett, F.C.N. Pereira,
C.J.C. Burges, L. Bottou, and K.Q. Weinberger, ed-
itors, Advances in Neural Information Processing
Systems 25, pages 1106?1114.
Honglak Lee, Alexis Battle, Rajat Raina, and An-
drew Y. Ng. 2006. Efficient sparse coding algo-
rithms. In B. Sch?olkopf, J. Platt, and T. Hoffman,
editors, Advances in Neural Information Processing
Systems 19, pages 801?808. MIT Press, Cambridge,
MA.
Qun Liu, Zhongjun He, Yang Liu, and Shouxun Lin.
2008. Maximum entropy based rule selection model
for syntax-based statistical machine translation. In
Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, pages
89?97, Honolulu, Hawaii, October. Association for
Computational Linguistics.
Zhiyuan Liu, Yuzhou Zhang, Edward Y. Chang, and
Maosong Sun. 2011. Plda+: Parallel latent dirichlet
allocation with data placement and pipeline process-
ing. ACM Transactions on Intelligent Systems and
142
Technology, special issue on Large Scale Machine
Learning. Software available at http://code.
google.com/p/plda.
Yuval Marton and Philip Resnik. 2008. Soft syntactic
constraints for hierarchical phrased-based transla-
tion. In Proceedings of ACL-08: HLT, pages 1003?
1011, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Franz Josef Och. 2003. Minimum error rate train-
ing in statistical machine translation. In Proceed-
ings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 160?167, Sap-
poro, Japan, July. Association for Computational
Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311?318, Philadelphia,
Pennsylvania, USA, July. Association for Computa-
tional Linguistics.
David E. Rumelhart, Geoffrey E. Hinton, and Ronald J.
Williams. 1988. Neurocomputing: Foundations
of research. chapter Learning Representations
by Back-propagating Errors, pages 696?699. MIT
Press, Cambridge, MA, USA.
Noah A. Smith and Jason Eisner. 2005. Contrastive
estimation: Training log-linear models on unlabeled
data. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL?05), pages 354?362, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Richard Socher, Cliff C. Lin, Andrew Y. Ng, and
Christopher D. Manning. 2011a. Parsing Natural
Scenes and Natural Language with Recursive Neural
Networks. In Proceedings of the 26th International
Conference on Machine Learning (ICML).
Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011b.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing, pages 151?161, Edinburgh,
Scotland, UK., July. Association for Computational
Linguistics.
Jinsong Su, Hua Wu, Haifeng Wang, Yidong Chen,
Xiaodong Shi, Huailin Dong, and Qun Liu. 2012.
Translation model adaptation for statistical machine
translation with monolingual topic information. In
Proceedings of the 50th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 459?468, Jeju Island, Korea,
July. Association for Computational Linguistics.
Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007.
Bilingual lsa-based adaptation for statistical ma-
chine translation. Machine Translation, 21(4):187?
207, December.
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and
Pierre-Antoine Manzagol. 2008. Extracting and
composing robust features with denoising autoen-
coders. In Proceedings of the 25th International
Conference on Machine Learning, ICML ?08, pages
1096?1103, New York, NY, USA. ACM.
Pascal Vincent, Hugo Larochelle, Isabelle Lajoie,
Yoshua Bengio, and Pierre-Antoine Manzagol.
2010. Stacked denoising autoencoders: Learning
useful representations in a deep network with a local
denoising criterion. J. Mach. Learn. Res., 11:3371?
3408, December.
Xinyan Xiao, Deyi Xiong, Min Zhang, Qun Liu, and
Shouxun Lin. 2012. A topic similarity model for
hierarchical phrase-based translation. In Proceed-
ings of the 50th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 750?758, Jeju Island, Korea, July. As-
sociation for Computational Linguistics.
Deyi Xiong and Min Zhang. 2013. A topic-based co-
herence model for statistical machine translation. In
AAAI.
Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li.
2009. A syntax-driven bracketing model for phrase-
based translation. In Proceedings of the Joint Con-
ference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural
Language Processing of the AFNLP, pages 315?
323, Suntec, Singapore, August. Association for
Computational Linguistics.
Bing Zhao and Eric P. Xing. 2006. Bitam: Bilingual
topic admixture models for word alignment. In Pro-
ceedings of the COLING/ACL 2006 Main Confer-
ence Poster Sessions, pages 969?976, Sydney, Aus-
tralia, July. Association for Computational Linguis-
tics.
Bing Zhao and Eric P. Xing. 2007. Hm-bitam: Bilin-
gual topic exploration, word alignment, and trans-
lation. In J.C. Platt, D. Koller, Y. Singer, and
S. Roweis, editors, Advances in Neural Informa-
tion Processing Systems 20, pages 1689?1696. MIT
Press, Cambridge, MA.
143
