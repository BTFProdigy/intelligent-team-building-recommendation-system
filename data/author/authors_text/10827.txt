Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 69?72,
Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics
Anaphora ? Clause Annotation and Alignment Tool 
 
 
Borislav Rizov 
Department of Computational 
Linguistics, IBL-BAS 
52 Shipchenski Prohod Blvd., bl. 17 
1113 Sofia, Bulgaria 
boby@dcl.bas.bg 
Rositsa Dekova 
Department of Computational 
Linguistics, IBL-BAS 
52 Shipchenski Prohod Blvd., bl. 17 
1113 Sofia, Bulgaria 
rosdek@dcl.bas.bg 
 
  
 
Abstract 
The paper presents Anaphora ? an OS and 
language independent tool for clause 
annotation and alignment, developed at the 
Department of Computational Linguistics, 
Institute for Bulgarian Language, Bulgarian 
Academy of Sciences. The tool supports 
automated sentence splitting and alignment 
and modes for manual monolingual annotation 
and multilingual alignment of sentences and 
clauses. Anaphora has been successfully 
applied for the annotation and the alignment of 
the Bulgarian-English Sentence- and Clause-
Aligned Corpus (Koeva et al. 2012a) and a 
number of other languages including French 
and Spanish. 
1 Introduction 
For years now corpus annotation has played an 
essential part in the development of various NLP 
technologies. Most of the language resources, 
however, do not include clause annotation and 
alignment which are considered quite useful in 
recent research on Machine Translation (MT) 
and parallel text processing (Piperidis et al., 
2000; Sudoh et al., 2010; Ramanathan et al., 
2011).  
Aiming to facilitate and improve the process 
of clause annotation and alignment of 
multilingual texts, we developed Anaphora.  
The tool is OS and language independent and 
supports automated sentence splitting and 
alignment, manual  sentence and clause splitting, 
validation, correction and alignment, selection 
and annotation of conjunctions (including 
compounds (MWE)), and identification of the 
type of relation between pairs of syntactically 
connected clauses.  
2 User Interface and Functionalities 
Anaphora supports two kinds of operating modes: 
a monolingual and a multilingual one. 
The monolingual mode is designed for manual 
editing and annotation of each part of the parallel 
corpus. The window consists of three active 
panes (Fig. 1): Text view (top pane), Sentence 
view (bottom left-hand pane) and Clause view 
and annotation (bottom right-hand pane). 
 
Figure 1. Anaphora ? monolingual mode. 
69
In this mode the user may chose a file for 
verification and post-editing of the automatically 
performed sentence alignment. The individual 
monolingual texts which are part of an aligned 
pair are selected by the file tabs.  
The monolingual mode offers the following 
functionalities:  
? sentence splitting;  
? clause splitting; 
? correction of wrong splitting (merging of 
split sentences/clauses); 
? annotation of conjunctions; 
? selection of compounds; 
? identification of the type of relation 
between pairs of syntactically connected 
clauses. 
The end of a sentence may be changed by 
choosing the last word of the sentence and 
marking it using the End button from the top 
menu. Thus, the selection of the word as a 
sentence end is toggled and if it was marked as 
an End word, it is no longer such and the 
following sentence is automatically merged to 
the current one. If the word has not been already 
marked as an end, it is thus marked as one and 
the sentence is automatically split. 
Clicking on any word of a sentence in the Text 
view pane results in the sentence appearing in the 
Sentence view pane, where clause segmentation 
and choice of conjunction are performed. The 
user defines the boundaries of clauses by 
selecting the words in them. This is achieved by 
marking the particular fragment of the text in the 
Sentence view pane with the mouse and pressing 
the 'space' key. This operation toggles the 
selection. Thus, a repeated use causes deselection. 
Marking a disconnected clause is done by 
marking the block of text containing it and 
unmarking the unnecessary words. When a 
clause is defined, it is listed in the bottom right-
hand pane in a new color following the surface 
order of the sentence. Selection of a clause 
within another clause is also possible. Then the 
inner clause is listed directly after the split clause 
while the order of the split clause in the Clause 
view pane depends on the position of its first 
word in the sentence. 
Once the clauses are defined, the user may 
annotate the conjunction of two clauses, also 
referred to as a marker. The marker may consist 
of one or more words or an empty word. Empty 
words (w="====") are artificial elements 
automatically introduced at the beginning of a 
potential new clause. An empty word may be 
selected as a marker when the conjunction is not 
explicit or the clauses are connected by means of 
a punctuation mark (for simplicity of annotation 
punctuation marks are not identified as 
independent tokens but are attached to the 
preceding token). When a word or a 
compound from one clause is selected in the 
Sentence view pane the user chooses another 
clause from the Clause view pane to create a pair 
of syntactically linked clauses. Then the relation 
for the pair is identified by selecting its type with 
the grey buttons N_N (coordination), N_S 
(subordinated clause following the main clause), 
S_N (subordinated clause preceding the main 
clause), etc.  
The multilingual mode is selected with the 
align tab. In this mode annotators can create, 
validate and correct the alignment of the parallel 
units ? sentences and/or clauses. 
The window (Fig. 2) has two parallel Text 
view panes (on the top) and two parallel List 
view panes (in the bottom). Depending on the 
chosen menu (Clause or Sentence) the bottom 
panes show lists of aligned clauses or sentences.   
 
Figure 2. Anaphora ? multilingual mode. 
70
The multilingual mode uses the output of the 
monolingual sentence and clause splitting and 
supports the following functionalities:  
? automated sentence alignment;  
? manual sentence alignment;  
? manual clause alignment. 
Automated sentence alignment is available as 
a menu command (Auto Sentence Align) in the 
multilingual mode. 
?o switch to manual sentence or clause 
alignment the corresponding menu commands 
are used ? Sentence and Clause. 
In the sentence menu the two bottom panes 
show lists of aligned sentences, each pair in a 
distinct color. The user may correct the 
alignment by choosing one or more sentences in 
each of the bottom panes and pressing the 'space' 
button to create a new alignment bead. 
In the clause menu, when a sentence is 
selected in one of the two Text panes, its clauses 
are listed in the respective bottom pane. The 
corresponding aligned sentence appears in the 
parallel top pane with its clauses listed in the 
bottom. Alignment is performed when the user 
chooses one or more clauses from each of the 
bottom panes and then presses the 'space' button. 
Thus a new clause alignment bead is created. 
3 Applications 
Anaphora was successfully used for the 
annotation and the alignment of the Bulgarian-
English Sentence- and Clause-Aligned Corpus 
(Koeva et al. 2012a) which was created as a 
training and evaluation data set for automatic 
clause alignment in the task of exploring the 
effect of clause reordering on the performance of 
SMT (Koeva et al., 2012b).  
Since its development the tool is continuously 
used for annotation and clause alignment of 
different parts of the Bulgarian-X language 
Parallel Corpus (Koeva et al. 2012c) covering a 
number of languages including French and 
Spanish. 
4 Implementation  
Anaphora was designed as a self-sufficient 
module for annotation and clause alignment 
within the multi-functional platform Chooser 
(Koeva et al. 2008) which supports various NLP 
tasks that involve corpora annotation.  
The tool is a stand-alone single user 
application implemented in Python and it uses 
the standard GUI library tkinter (the Tcl/Tk 
python binding) which makes it highly OS 
independent. 
5 Data Processing and Representation 
5.1 Input Data  
The used format is a flat xml with root 
element text. The text is a list of word elements 
with several attributes like ?w? ? wordform, ?l? ? 
lemma, ?u? ? annotator, ?t? ? timestamp, ?e? ? 
sentence end, etc.  
Special attributes are responsible for marking 
the compounds (MWE) and clauses. The words 
that are members of a compound share a 
common value for the attribute ?p? (parent). 
Similarly, the words in a clause share a common 
value for clause ? ?cl?.  
This format is compatible with the other 
modules of the Chooser platform. Thus, one file 
can be annotated with several different types of 
annotation like POS, semantic annotation, etc.  
The system provides import scripts for two 
formats ? plain text and the output of the 
Bulgarian Language Processing Chain (Koeva 
and Genov, 2011) ? a TSV/CSV family format, 
where the text is tokenized and lemmatized. 
Sentence splitting depends on the format of 
the input text. If it is a plain text, sentence 
splitting is based on the presence of end of 
sentence punctuation (full stop, exclamation 
mark, and question mark) followed by a capital 
letter. When the file is of the TSV/CSV family 
format sentence splitting is part of the Language 
Processing Chain. 
71
5.2 Automated Sentence Alignment  
The automated sentence alignment is 
performed using the Gale-Church aligning 
algorithm (Gale and Church, 1993). 
6 Conclusions and Future Work 
We believe that, based on its design and 
functionalities, Anaphora can be easily used and 
it will perform well for any given pair of 
languages, that is, it is to a great extent language 
independent. The system can also be applied as it 
is for phrase segmentation and word and phrase 
alignment. However, if we want to include 
simultaneous alignment of words, phrases, and 
clauses the system needs to be adopted.  
We work on including additional functionalities 
to facilitate corpora annotation and parallel text 
processing such as anaphora annotation.  
Our future intentions include also publishing it as 
an Open Source code so that it can serve the NLP 
community.  
Acknowledgments 
The present paper was prepared within the 
project Integrating New Practices and 
Knowledge in Undergraduate and Graduate 
Courses in Computational Linguistics 
(BG051PO001-3.3.06-0022) implemented with 
the financial support of the Human Resources 
Development Operational Programme 2007-2013 
co-financed by the European Social Fund of the 
European Union. The authors take full 
responsibility for the content of the present paper 
and under no conditions can the conclusions 
made in it be considered an official position of 
the European Union or the Ministry of Education, 
Youth and Science of the Republic of Bulgaria. 
References  
William A. Gale and Kenneth W. Church. 1993. A 
Program for Aligning Sentences in Bilingual 
Corpora, Computational Linguistics 19(1): 75?102. 
Svetla Koeva and Angel Genov. 2011. Bulgarian 
Language Processing Chain. In: Proceeding to The 
Integration of multilingual resources and tools in 
Web applications Workshop in conjunction with 
GSCL 2011, University of Hamburg. 
Svetla Koeva, Borislav Rizov, Svetlozara Leseva. 
2008. Chooser - A Multi-Task Annotation Tool. In: 
Proceedings of the Sixth International Conference 
on Language Resources and Evaluation (LREC'08), 
Marrakech, ELRA electronic publication, 728-734. 
Svetla Koeva, Borislav Rizov, Ekaterina 
Tarpomanova, Tsvetana Dimitrova, Rositsa 
Dekova, Ivelina Stoyanova, Svetlozara Leseva, 
Hristina Kukova, Angel Genov. 2012a. Bulgarian-
English Sentence- and Clause-Aligned Corpus. In 
Proceedings of the Second Workshop on 
Annotation of Corpora for Research in the 
Humanities (ACHR-2), Lisboa: Colibri, 51-62. 
Svetla Koeva, Borislav Rizov, Ekaterina 
Tarpomanova, Tsvetana Dimitrova, Rositsa 
Dekova, Ivelina Stoyanova, Svetlozara Leseva, 
Hristina Kukova, and Angel Genov. 2012b. 
Application of clause alignment for statistical 
machine translation. In Proceedings of the Sixth 
Workshop on Syntax, Semantics and Structure in 
Statistical Translation (SSST-6), Korea, 2012. 
Svetla Koeva, Ivelina Stoyanova, Rositsa Dekova, 
Borislav Rizov, and Angel Genov. 2012c. 
Bulgarian X-language parallel corpus. In 
Proceedings of the Eighth International 
Conference on Language Resources and 
Evaluation (LREC'12). N. Calzolari et al. (Eds.) 
Istanbul: ELRA, 2480-2486. 
Stelios Piperidis, Harris Papageorgiou, and Sotiris 
Boutsis. 2000. From sentences to words and 
clauses. In J. Veronis, editor, Parallel Text 
Processing, Alignment and Use of Translation 
Corpora, Kluwer Academic Publishers, 117?138. 
Ananthakrishnan Ramanathan, Pushpak 
Bhattacharyya, Karthik Visweswariah, Kushal 
Ladha and Ankur Gandhe. 2011. Clause-based 
reordering constraints to improve statistical 
machine translation. In Proceedings of the 5th 
International Joint Conference on NLP, Thailand, 
November 8-13, 2011, 1351?1355. 
Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, 
Tsutomu Hirao, Masaaki Nagata. 2010. Divide and 
translate: improving long distance reordering in 
statistical machine translation. In Proceedings of 
the Joint 5thWorkshop on SMT and Metrics 
MATR,  418?427. 
72
Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 102?110,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Application of Clause Alignment for Statistical Machine Translation
Svetla Koeva, Borislav Rizov, Ivelina Stoyanova, Svetlozara Leseva, Rositsa Dekova, Angel Genov,
Ekaterina Tarpomanova, Tsvetana Dimitrova and Hristina Kukova
Department of Computational Linguistics
Institute for Bulgarian Language, Bulgarian Academy of Sciences
Sofia 1113, Bulgaria
{svetla,boby,iva,zarka,rosdek,angel,katja,cvetana,hristina}@dcl.bas.bg
Abstract
The paper presents a new resource light flexi-
ble method for clause alignment which com-
bines the Gale-Church algorithm with in-
ternally collected textual information. The
method does not resort to any pre-developed
linguistic resources which makes it very ap-
propriate for resource light clause alignment.
We experiment with a combination of the
method with the original Gale-Church algo-
rithm (1993) applied for clause alignment.
The performance of this flexible method, as it
will be referred to hereafter, is measured over
a specially designed test corpus.
The clause alignment is explored as means
to provide improved training data for the
purposes of Statistical Machine Translation
(SMT). A series of experiments with Moses
demonstrate ways to modify the parallel re-
source and effects on translation quality: (1)
baseline training with a Bulgarian-English
parallel corpus aligned at sentence level; (2)
training based on parallel clause pairs; (3)
training with clause reordering, where clauses
in each source language (SL) sentence are re-
ordered according to order of the clauses in
the target language (TL) sentence. Evaluation
is based on BLEU score and shows small im-
provement when using the clause aligned cor-
pus.
1 Motivation
Evaluation on the performance of MT systems has
shown that a pervasive shortcoming shared by both
the phrase-based and the syntax-based SMT systems
is translating long and (syntactically) complex sen-
tences (Koehn et al, 2003; Li et al, 2007; Sudoh et
al., 2010).
The power of phrase-based SMT lies in local lex-
ical choice and short-distance reordering (Li et al,
2007). Syntax-based SMT is better suited to cope
with long-distance dependencies, however there also
are problems, some of them originated from the lin-
guistic motivation itself ? incorrect parse-trees, or
reordering that might involve blocks that are not
constituents (Li et al, 2007).
An efficient way to overcome the problem of sen-
tence length and complexity is to process the clauses
in a similar way as sentences. This has incited grow-
ing interest towards the alignment and processing of
clauses ? a group of syntactically and semantically
related words expressing predicative relation and
positioned between sentence borders or clause con-
nectors. (It is known that some predicative relations
can be considered complex being saturated with an-
other predicative relation ? but with the above given
definition this case is simplified).
The differences in word order and phrase structure
across languages can be better captured at a clause
rather than at a sentence level, therefore, monolin-
gual and parallel text processing in the scope of the
clauses may significantly improve syntactic parsing,
automatic translation, etc. The sentences can be very
long and complex in structure, may consist of a con-
siderable number of clauses which in turn may vary
with respect to their relative position to each other
in parallel texts both due to linguistic reasons per se
and translators? choices.
The flexible order, length and number of clauses
102
in sentences, along with the different word order and
ways of lexicalisation across languages contribute to
the complexity of clause alignment as compared to
sentence alignment and call for more sophisticated
approaches. These findings have inspired growing
research into clause-to-clause machine translation
involving clause splitting, alignment and word order
restructuring within the clauses (Cowan et al, 2006;
Ramanathan et al, 2011; Sudoh et al, 2010; Goh et
al., 2011).
A fixed clause order in a language (i.e. rela-
tive clauses in Bulgarian, English, French and many
other languages follow the head noun, while in Chi-
nese, Japanese, Turkish, etc. they precede it) may
correspond to a free order in another (i.e. Bulgar-
ian and English adverbial clauses). The hypothesis
is that a SMT model can be improved by inducing
a straightforward clause alignment through reorder-
ing the clauses of the source language text so as to
correspond to the order of the clauses in the target
language text.
2 State-of-the-art
The task of clause alignment is closely related to
that of sentence alignment (Brown et al, 1990; Gale
and Church, 1993; Kay and Roscheisen, 1993) and
phrase alignment (DeNero and Klein, 2008; Koehn
et al, 2003). There are two main approaches ? sta-
tistical and lexical, often employed together to pro-
duce hybrid methods. Machine learning techniques
are applied to extract models from the data and re-
duce the need of predefined linguistic resources.
Boutsis, Piperidis and others (Boutsis and
Piperidis, 1998; Boutsis and Piperidis, 1998;
Piperidis et al, 2000) employ a method combin-
ing statistical techniques and shallow linguistic pro-
cessing applied on a bilingual parallel corpus of
software documentation which is sentence-aligned,
POS-tagged and shallow parsed. The combined task
of clause borders identification uses linguistic in-
formation (POS tagging and shallow parsing) and
clause alignment based on pure statistical analysis.
The reported precision is 85.7%. Kit et al (2004)
propose a method for aligning clauses in Hong Kong
legal texts to English which relies on linguistic in-
formation derived from a glossary of bilingual legal
terms and a large-scale bilingual dictionary. The al-
gorithm selects a minimal optimal set of scores in
the similarity matrix that covers all clauses in both
languages. The authors report 94.60% alignment ac-
curacy of the clauses, corresponding to 88.64% of
the words.
The quality of the parallel resources is of cru-
cial importance to the performance of SMT sys-
tems and substantial research is focused on devel-
oping good parallel corpora of high standard. Most
clause alignment methods are applied on domain
specific corpora, in particular administrative cor-
pora and are not extensively tested and evaluated on
general corpora or on texts of other domains. Al-
though clause segmentation is often performed to-
gether with clause alignment (Papageorgiou, 1997)
the former tends to be more language-specific and
therefore clause alignment is performed and eval-
uated independently. The majority of the avail-
able comparative analyses discuss modifications of
one method rather than the performance of different
methods. Moreover, the performance of resource-
free against resource-rich methods has been poorly
explored. To the best of our knowledge, there is
no purely resource-free method for clause alignment
offered so far.
In recent years, handling machine translation at
the clause level has been found to overcome some of
the limitations of phrase-based SMT. Clause aligned
corpora have been successfully employed in the
training of models for clause-to-clause translation,
reordering and subsequent sentence reconstruction
in SMT ? Cowan et al (2006) for syntax-based
German-to-English SMT, Sudoh et al (2010) for
English-to-Japanese phrase-based SMT, among oth-
ers.
Cowan et al (2006) discuss an approach for
tree-to-tree SMT using Tree Adjoining Grammars.
Clause alignment is performed on a corpus (Eu-
roparl) which is then used in the training of a model
for mapping parse trees in the source language to
parse trees in the target language. The performance
of this syntax-based method is similar to the phrase-
based model of Koehn et al (2003).
Sudoh et al (2010) propose a method for clause-
to-clause translation by means of a standard SMT
method. The clauses may contain non-terminals as
placeholders for embedded clauses. After transla-
tion is performed, the non-terminals are replaced
103
by their clause translations. The model for clause
translation is trained using a clause-aligned bilin-
gual corpus of research paper abstract. The proposed
improvement by using Moses is 1.4% in BLEU
(33.19% to 34.60%), and 1.3% in TER (57.83% to
56.50%) and 2.2% in BLEU (32.39% to 34.55%)
and 3.5% in TER (58.36% to 54.87%) using a hi-
erarchical phrase-based SMT system.
The potential of clause alignment along with
other sub-sentence levels of alignment in extract-
ing matching translation equivalents from transla-
tion archives has been recognised within the EBMT
framework, as well (Piperidis et al, 2000).
3 Bootstrapping clause alignment
The clause alignment is modelled as a bipartite
graph. Each node in the graph corresponds to a
clause in either the source or the target language.
A pair of clauses that are fully or partially trans-
lational equivalents is connected by an edge in the
graph. The connected components of the graph are
beads (the smallest group of aligned clauses). In
these terms, the task of clause alignment is the task
of the identification of the edges in a bipartite graph,
where the nodes are the clauses (Brown et al, 1990).
A bootstrapping method for clause alignment that
does not exploit any pre-developed linguistic re-
sources is elaborated. The method uses length-
balance based alignment algorithm ? i.e. Gale-
Church (Gale and Church, 1993), for the data col-
lecting. The bootstrapping algorithm attains high
precision and relatively good recall. In order to
improve the recall while preserving the precision
the method is combined with the Gale-Church al-
gorithm applied to clause alignment.
The proposed method consists of the following
stages:
1. Initial clause alignment that serves as training
data.
2. Identifying similarities between clauses in dif-
ferent languages.
3. Building the clause alignment.
3.1 The Gale and Church algorithm
Gale and Church (1993) describe a method for align-
ing sentences based on a simple statistical model of
sentence lengths measured in number of characters.
It relies on the fact that longer sentences in one lan-
guage tend to be translated into longer sentences in
the other language, and vice versa. A probabilis-
tic score is assigned to each proposed correspon-
dence of sentences, based on the scaled difference
and the variance of the lengths of the two sentences.
The method is reported to give less than 4% error in
terms of alignment and is probably the most widely
used sentence alignment method.
The extended version of the Gale-Church aligner
from the Natural Language Toolkit1 is applied for
clause alignment. The original Gale-Church method
applies the 1:1, 0:1, 1:0, 1:2, 2:1 and 2:2 bead mod-
els; in the extended version ? the 1:3, 3:1, 2:3, 3:2,
3:3 models are added.
3.2 Clause alignment training data
The clause beads are identified by applying the
Gale-Church algorithm. The aim is to select a set
of aligned beads which are to serve as a training set
for the subsequent stages. Only beads showing high
probability of correctness are used. For any proba-
bility p we could find ? so that for the Gale-Church
measure within [??, ?] the corresponding bead is
correct with probability p.
3.3 Clause similarity
Clause similarity is measured by means of: a) par-
tial word alignment, b) length similarity, and c)
weighted punctuation similarity.
3.3.1 Word alignment
To align words in the scope of parallel clauses,
word-to-word connections (weighted links between
two words based on word similarity) are calculated
using several methods given below:
? Vector space model
A given word is assigned a vector
< x1, x2, ? ? ? , xn >
in an n-dimensional vector space, where each
dimension represents a bead in the preliminary
clause alignment and x i is the number of the
occurrences of the word in the bead. The set of
these vectors is a matrix.
1http://nltk.googlecode.com
104
The vector space word similarity is the cosine
of the angle between the vectors of the words
(Ruge, 1992; Schu?tze, 1992). Two words are
similar if the cosine is above a specified thresh-
old. The observations over the training and
test data show that the translation equivalents
are identified best when the cosine is higher
than 0.7. However, the word-to-word align-
ment reduces some of the errors which increase
in number when lowering the threshold. There-
fore, the threshold is set at 0.4 acquiring a good
balance between the number of the connections
obtained and the error rate.
A second vector space matrix is built using the
first two words in each clause on the assump-
tion that clause-introducing words may express
stronger word-to-word connections.
Some experiments with word similarity asso-
ciation measures e.g. the chi-square measure
(Evert, 2005) failed to show any improvements.
Word forms are treated as instances of one and
the same word if either their actual or nor-
malised forms are equal (Kay and Roscheisen,
1993). The normalised forms cover correspon-
dences between grammatically and semanti-
cally related words in languages with rich in-
flectional and derivational morphology. The
morphology algorithm proposed by Kay and
Roscheisen (1993) is applied for splitting po-
tential suffixes and prefixes and for obtaining
the normalised word forms. The vector space
word-to-word connections are calculated for
both actual and normalised forms and the ob-
tained similarity measures are summed up.
? Levenshtein measure (Levenshtein, 1966)
Church (1993) employs a method that in-
duces sentence alignment by employing cog-
nates (words that are spelled similarly across
languages). Instead the standard Levenshtein
distance (the number of edits required to trans-
form a string A into another string B) is ap-
plied. The non-Latin characters are transliter-
ated into Latin ones. The distance is calculated
within a tolerance different for a different word
length. The distance is then transformed into
similarity by means of the tolerance.
?
1?
levenshtein
tolerance + 1
.
? Punctuation
Similarity is calculated also if two words con-
tain identical prefixes or suffixes which are
punctuation marks or special characters. Punc-
tuation and special characters are not all equal.
Some of them are more robust, e.g. marks
for currency and measurement, or mathemati-
cal symbols ($, , , %, +,<,>, =) or the different
types of brackets. Others (e.g. comma, hyphen,
colon, semi-colon) may be governed by lan-
guage specific rules and may lead to improve-
ment only for those pairs of languages that em-
ploy similar rules.
The word-to-word similarity measure is the
weighted sum of the above measures where the
Levenshtein similarity is multiplied by 3, the
punctuation similarity by 0.4 and the vector
space similarity measure by 1, which is defined
as a base.
The similarity connections are sorted descend-
ingly and sequentially processed. At each itera-
tion only connections between dangling words
are stored. Thus there is only one connec-
tion left for each word resulting in partial word
alignment. The weights of all obtained word-
to-word connections are summed up to pro-
duce the weight of the clause association that is
propagated to the clause similarity calculation
stage.
3.3.2 Length similarity
Zero-weighted similarity connections between
clauses are collected using Gale-Church?s distance
measure. Thus connections are added without in-
creasing the weight of the existing ones.
3.3.3 Weighted punctuation similarity
This similarity is calculated by the following for-
mula
?
Z?PU
min(count(Z ? cl1), count(Z ? cl2)),
105
where PU is the set of the punctuation marks and
special symbols being prefixes and suffixes of words
in the clauses processed.
3.4 Clause alignment with the bootstrapping
method
The bipartite graph is built by filtering the set of the
calculated clause similarity connections. The con-
nected components of this graph form the clause
beads. A conservative fallback strategy is applied
to add the dangling clauses to the most appropri-
ate bead. The filtering process starts by defining a
threshold for grouping (1,2) and every clause simi-
larity connection with weight above it is considered
strong. In a way similar to word alignment, the re-
maining (weak) connections are sorted descendingly
and processed one by one. If the processed connec-
tion relates clauses that are not attached to any bead,
it passes the filter. In other words these two clauses
form a 1:1 bead.
The bootstrapping method evaluated on the test
corpus has precision above 94% and recall of 77%.
To overcome this low recall we combine the Gale-
Church algorithm with the core method.
3.5 Combined clause alignment
The combined method also distinguishes strong and
weak clause connections by means of a threshold
constant. At the beginning the Gale-Church results
in clause alignment are compared with the strong
connections. If they comply with the Gale-Church?s
beads, the weak connections are processed. The
weak connections are added to the final graph if
they do not contradict Gale-Church?s output, i.e.
when they do not connect clauses from two differ-
ent beads.
In case of a strong connection the Gale-Church?s
alignment is discarded, assuming that the seman-
tic and the syntactic similarities between clauses are
more significant than the length.
4 Clause alignment evaluation
4.1 Test corpus
A test corpus was constructed for the purposes
of method evaluation. It consists of 363,402 to-
kens altogether (174,790 for Bulgarian and 188,612
for English) distributed over five thematic domains:
Fiction (21.4%), News (37.1%), Administrative
(20.5%), Science (11.2%) and Subtitles (9.8%). The
purpose of using a general testing corpus with texts
from a variety of domains is to investigate method
performance in a wider range of contexts.
Both Bulgarian and English parts of the corpus
are first automatically segmented and then aligned
at sentence level. The task of sentence detection
in Bulgarian is carried out using a Bulgarian sen-
tence splitter (Koeva and Genov, 2011). For sen-
tence splitting of the English texts a pre-trained
OpenNLP2 model is used. Sentence alignment is
produced using HunAlign3 (Varga et al, 2005), with
the alignment manually verified by human experts.
Clause splitting is considered a highly language
dependent task and separate linguistic models need
to be developed for each language. For the pur-
poses of the present study, Bulgarian sentences are
manually or semiautomatically split into clauses and
for the English texts a pre-trained OpenNLP parser
is used to determine clause boundaries followed by
manual expert verification and post-editing (the task
of automatic clause splitting falls outside the scope
of the present study).
Subsequently, manual clause alignment is per-
formed. Tables 1 and 2 present the number of sen-
tences and clauses, respectively, in Bulgarian and
English with their average length in tokens (LS(t))
and in characters (LS(ch)).
Language
Sentences
number LS(t) LS(ch)
Bulgarian 13,213 13.23 73.04
English 13,896 13.57 69.21
Total 27,109 ? ?
Table 1: Number of sentences and their length.
Different models of clause alignment reflect in-
terlingual symmetry or assymetry, such as: 1:1 for
equivalent clauses in both languages; 0:1 or 1:0 if
a clause in one of the languages is missing in the
other; 1 : N and N : 1 (N > 1) in the cases of dif-
ferent clause segmentation, when clauses contain the
same information; N : M (N,M > 1) in relatively
rare cases when the information is crossed among
2http://opennlp.apache.org/index.html
3http://mokk.bme.hu/resources/hunalign/
106
Language
Clauses
number LS(t) LS(ch)
Bulgarian 24,409 7.20 39.54
English 28,949 6.57 33.22
Total 53,358 ? ?
Table 2: Number of clauses and their length.
clauses. The distribution of the models is given in
Table 3.
Model Frequency % of all
0:1 553 2.53
1:0 412 1.88
1:1 17,708 80.88
1:2 2,055 9.39
1:3 309 1.41
1:4 98 0.45
2:1 588 2.69
2:2 81 0.37
2:3 15 0.07
3:1 31 0.14
3:2 7 0.03
Table 3: Distribution of bead models in the manually
aligned corpus.
4.2 Evaluation
The precision is calculated as the number of true
connections (between clauses in the two languages)
divided by the number of the proposed connections,
while the recall is the proportion of true connections
to all connections in the corpus. The connections in
a bead are the Cartesian product of the clauses in the
first and the second language. The K : 0 and 0 : K
bead models are considered as K : 1 and 1 : K by
adding a fake clause.
The evaluation is performed both over the corpus
as a whole and on each of the domain specific sub-
corpora included in it.
The evaluation of the clause alignment implemen-
tation of the Gale-Church algorithm on the same cor-
pus shows overall precision of 0.902, recall ? 0.891
and F1 measure ? 0.897. Although the original
Gale-Church method performs very well in terms of
both precision and recall, sentence alignment poses
a greater challenge. The explanation for this fact lies
Domain Precision Recall F1
Total 0.910 0.911 0.911
Administrative 0.865 0.857 0.861
Fiction 0.899 0.902 0.901
News 0.933 0.946 0.940
Science 0.874 0.852 0.862
Subtitles 0.934 0.934 0.934
Table 4: Performance of the flexible method.
in the broader scope of variations of clause corre-
spondences as compared to sentences.
The bootstrapping method performs better in the
translations with clause reordering. An example
is the administrative subcorpus where Gale-Church
gives precision/recall ? 81.5%/79.7% compared to
86.6%/85.8% shown by the bootstrapping method.
In the texts with less clause order asymmetries the
results are close.
5 Application of clause alignment in SMT
Typical Moses4 (Koehn et al, 2007) models are built
on a large amount of parallel data aligned at the sen-
tence level. For the purposes of the present study a
specially designed parallel corpus is used. The aim
is to demonstrate the effect of using syntactically en-
hanced parallel data (clause segmentation and align-
ment, reordering of clauses, etc.).
A series of experiments with Moses is designed
to demonstrate the effect of training data modifica-
tion on the performance of the SMT system. The
different training datasets comprise the same sen-
tences but differ in their syntactic representation.
The baseline model is constructed on the basis of
aligned sentence pairs. The first experiment is based
on aligned clauses rather than sentences. The second
experiment demonstrates the effect of reordering of
the clauses within the source language sentences.
The main purpose of the experiments is to demon-
strate possible applications of the clause alignment
method for training an SMT system, enhanced with
linguistic information.
5.1 Training corpus
For the demonstration purposes of the present study
we apply a small corpus of 27,408 aligned sen-
4http://www.statmt.org/moses/
107
tence pairs (comprising 382,950 tokens in Bulgar-
ian and 409,757 tokens in English) which is semi-
automatically split into clauses and automatically
aligned at clause level. The current purposes of the
research do not include the development of a full
SMT model but focus on the demonstration of the
effect of syntactical information on the performance
of the SMT system. Thus, the size of the train-
ing corpus is considered sufficient for demonstration
purposes. The parallel texts are extracted from sev-
eral domains ? Administrative, Fiction, News, Sci-
ence, Subtitles.
5.2 Test corpus
The test corpus compiled for the purposes of evalu-
ation of the SMT performance is independently de-
rived from the Bulgarian-English parallel corpus and
does not overlap with the training corpus. It how-
ever, resembles its structure and contains texts from
the same domains as the training data. Table 5 gives
the number of tokens in the Bulgarian and in the En-
glish part of the test corpus, with percent of tokens
in the Bulgarian texts.
Domain BG ENl % (BG)
Administrative 36,042 35,185 21.10
Fiction 34,518 38,723 20.21
News 64,169 62,848 37.57
Science 18,912 19,856 11.07
Subtitles 17,147 18,951 10.04
Total 170,788 175,563
Table 5: Number of tokens in the test corpus.
5.3 Baseline model
The baseline model corresponds to the traditional
Moses trained models and is constructed from
aligned sentences in Bulgarian and English. The
BLEU score for translation from Bulgarian into En-
glish is 16.99 while for the reverse it is substantially
lower ? 15.23. In the subsequent tests we observe
the results for the Bulgarian-to-English translation
only.
5.4 Clause level trained model
The first experiment aims to demonstrate that train-
ing of the model based on aligned clauses rather than
sentences yields improvement. The assumption is
that alignment at a sub-sentential level would im-
prove word and phrase alignment precision by limit-
ing the scope of occurrence of translational equiva-
lents. On the other hand, however, lower level align-
ment reduces the number of aligned phrases. For
this purpose clauses are the optimal scope for align-
ment as phrases rarely cross clause boundaries.
The results of the clause level training show small
improvement of 0.11 in the BLEU score from 16.99
(baseline) to 17.10 for the Bulgarian-to-English
translation.
5.5 Reordering of clauses
The second experiment relies on reordering of
clauses within aligned sentences. The experiment
aims at showing that reordering improves perfor-
mance of SMT system.
A simple clause reordering task was carried out
within the sentences on the parallel training cor-
pus. Clause reordering involves linear reordering of
clauses in the source language sentences to match
the linear order of corresponding clauses in the tar-
get language sentences.
Reordering applies to cases where asymmetries
are present in the alignment i.e. crossed connections
between clauses, which is expected to vary across
languages and domains. This suggests that the pro-
portion of the corpus affected by reordering also de-
pends on the language and on the domain. Based on
an experiment with a smaller corpus, approximately
7% of the Bulgarian sentences are affected by re-
ordering when adjusted to the English sentences.
The result is BLEU score of 17.12 compared to
16.99 (baseline) which yields an improvement of
0.13.
5.6 Analysis
The results obtained from the above two experi-
ments show a small yet consistent improvement in
the BLEU score. It shows a possibility to im-
prove the results by applying parallel data enhanced
by syntactic information, namely, aligned pairs at
clause level, or sentences with reordered clauses.
The data, however, are not sufficient to draw a
definite conclusion both on whether the improve-
ment is stable and on which of the two methods ?
108
using clause aligned pairs or reordered sentences ?
performs better.
6 Conclusions
The research done in the scope of this paper has
shown that, on the one hand, the Gale-Church al-
gorithm is applicable for clause alignment. The re-
sults achieved by the bootstrapping method, on the
other hand, show that clause alignment may be ap-
propriately improved by means of similarity mea-
surement especially for the domain dependent tasks
? particularly for the domains for which non-linear
order of the translated clauses is typical. Exper-
iments showed that especially for texts exhibiting
alignment asymmetries our method for clause align-
ment outperforms Gale-Church considerably.
We applied automatic clause alignment for build-
ing a Moses training dataset enhanced with syntac-
tic information. Two experiments were performed
? first, involving aligned clause pairs, and the sec-
ond using clause reordering in the source language
assuming that the order of clauses in the target lan-
guage defines relations specific for the particular
language. The experiments suggest that the clause
reordering might improve translation models.
The series of experiments conducted with Moses
showed possible applications of the clause align-
ment method for training an SMT system, enhanced
with linguistic information.
References
Sotiris Boutsis and Stelios Piperidis. 1998. OK with
alignment of sentences. What about clauses? Pro-
ceedings of the Panhellenic Conference on New Infor-
mation Technology (NIT98). pp. 288?297.
Sotiris Boutsis and Stelios Piperidis. 1998. Aligning
clauses in parallel texts. Proceedings of the 3rd Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 1998). pp. 17?26.
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Frederick Jelinek, Robert L.
Mercer and Paul S. Roossin. 1990. A statistical ap-
proach to language translation. Computational Lin-
guistics, 16(2): 79?85.
Kenneth Church. 1993. Charalign: A program for align-
ing parallel texts at the character level. Proceedings of
the 31st Annual Meeting of the Association for Com-
putational Linguistics (ACL 1993). pp. 1?8.
Brooke Cowan, Ivona Kucerova? and Michael Collins.
2006. A Discriminative Model for Tree-to-Tree Trans-
lation. Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP
2006). pp. 232?241.
John DeNero and Dan Klein. 2008. The Complexity of
Phrase Alignment Models. Proceedings of the 46th
Annual Meeting of the Association for Computational
Linguistics (ACL 2008), Short Paper Track.
Stefan Evert. 2005. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis. In-
stitut fur maschinelle Sprachverarbeitung, University
of Stuttgart.
William A. Gale and Kenneth. W. Church. 1993.
A Program for Aligning Sentences in Bilingual
Corpora. Computational Linguistics, 19(1): 75?
102. URL: http://acl.ldc.upenn.edu/J/
J93/J93-1004.pdf.
Chooi-Ling Goh, Takashi Onishi and Eiichiro Sumita.
2011. Rule-based Reordering Constraints for Phrase-
based SMT. Mikel L. Forcada, Heidi Depraetere,
Vincent Vandeghinste (eds.) Proceedings of the 15th
Conference of the European Association for Machine
Translation (EAMT 2011). pp. 113?120.
Mridul Gupta, Sanjika Hewavitharana and Stephan Vo-
gel. 2011. Extending a probabilistic phrase alignment
approach for SMT. Proceedings of the International
Workshop on Spoken Language Translation (IWSLT
2011). pp. 175-182.
Martin Kay and Martin Roscheisen. 1993. Text trans-
lation alignment. Computational Linguistics, 19(1):
121?142.
Chunyu Kit, Jonathan J. Webster, King Kui Sin, Haihua
Pan, Heng Li. 2004. Clause Alignment for Hong
Kong Legal Texts: A Lexical-based Approach. Inter-
national Journal of Corpus Linguistics, 9(1): 29?51.
Philipp Koehn, Franz J. Och and Daniel Marcu. 2003.
Statistical phrase-based translation. Proceedings of
the North American Chapter of the Association for
Computational Linguistics (NAACL 2003). pp. 48?54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. Annual
Meeting of the Association for Computational Linguis-
tics (ACL), demonstration session. Prague, Czech Re-
public, June 2007.
Svetla Koeva, Diana Blagoeva and Siya Kolkovska.
2010. Bulgarian National Corpus Project. Nicoletta
Calzolari, Khalid Choukri, Bente Maegaard, Joseph
Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner,
109
Daniel Tapias (eds.) Proceedings of the 7th conference
on International Language Resources and Evaluation
(LREC 2010). pp. 3678?3684.
Svetla Koeva and Angel Genov. 2011. Bulgarian lan-
guage processing chain. Proceedings of Integration of
multilingual resources and tools in Web applications.
Workshop in conjunction with GSCL 2011, 26 Septem-
ber 2011, University of Hamburg. (to appear)
Vladimir Levenshtein 1966. Binary codes capable of
correcting deletions, insertions, and reversals. Soviet
Physics Doklady, 10. pp. 707?710.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li, Ming
Zhou and Yi Guan. 2007. A probabilistic approach to
syntax-based reordering for statistical machine trans-
lation. Proceedings of the 45rd Annual Meeting of
the Association for Computational Linguistics (ACL
2007). pp. 720?727.
Harris Papageorgiou 1997. Clause recognition in the
framework of alignment. Ruslan Mitkov and Nicolas
Nicolov, N. (eds.) Current Issues in Linguistic Theory,
136: 417?425. John Benjamins B.V.
Stelios Piperidis, Harris Papageorgiou and Sotiris Bout-
sis. 2000. From sentences to words and clauses.
Chapter 6. Jean Veronis and Nancy Ide (eds.) Paral-
lel Text Processing: Alignment and Use of Translation
Corpora. Text, Speech and Language Technology se-
ries, 13: 117?137.
Ananthakrishnan Ramanathan, Pushpak Bhattacharyya,
Karthik Visweswariah, Kushal Ladha and Ankur
Gandhe. 2011. Clause-Based Reordering Constraints
to Improve Statistical Machine Translation. Proceed-
ings of the 5th International Joint Conference on Nat-
ural Language Processing (IJCNLP 2011). pp. 1351?
1355.
Gerda Ruge. 1992. Experiments on linguistically based
term associations. Information Processing & Manage-
ment. 28(3):317-332.
Hinrich Schu?tze. 1992. Context Space. Working Notes
of the AAAI Fall Symposium on Probabilistic Ap-
proaches to Natural Language. pp. 113-120
Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, Tsutomu
Hirao, Masaaki Nagata. 2010. Divide and Trans-
late: Improving Long Distance Reordering in Statis-
tical Machine Translation. Proceedings of the Joint
5th Workshop on Statistical Machine Translation and
MetricsMATR. pp. 418?427.
Daniel Varga, Laszlo Nemeth, Peter Halacsy, Andras Ko-
rnai, Viktor Tron, Viktor Nagy. 2005. Parallel cor-
pora for medium density languages. Proceedings of
the RANLP 2005. pp. 590?596.
110
