Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 12?17,
Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational Linguistics
Evaluating Sentiment Analysis Systems in Russian
Ilia Chetviorkin
Faculty of Computational
Mathematics and Cybernetics
Lomonosov Moscow State University
Moscow, Leninskiye Gory 1, Building 52
ilia2010@yandex.ru
Natalia Loukachevitch
Research Computing Center
Lomonosov Moscow State University
Moscow, Leninskiye Gory 1, Building 4
louk nat@mail.ru
Abstract
In this paper we describe our experience in
conducting the first open sentiment anal-
ysis evaluations in Russian in 2011-2012.
These initiatives took part within Russian
Information Retrieval Seminar (ROMIP),
which is an annual TREC-like competition
in Russian. Several test and train collec-
tions were created for such tasks as senti-
ment classification in blogs and newswire,
opinion retrieval. The paper describes the
state of the art in sentiment analysis in
Russian, collection characteristics, track
tasks and evaluation metrics.
1 Introduction
Sentiment analysis of natural language texts is one
of the fast-developing technologies of natural lan-
guage processing. Many lexical resources and
tools were created for sentiment analysis in En-
glish. But lately a lot of research work was initi-
ated for sentiment analysis in other languages (Mi-
halcea et al, 2007; Abdul-Mageed et al, 2011;
Pe?rez-Rosas et al, 2012).
The development of sentiment analysis in Rus-
sian previously did not attract a lot of attention
at international conferences. Besides, until re-
cently, the interest to sentiment analysis within
Russia was connected only with election cam-
paigns. But now there is a considerable interest
to sentiment analysis within Russia both from the
research community and from the industry.
Therefore during the last years, two workshops
on the evaluation of sentiment analysis systems
were organized within the framework of Russian
Information Retrieval Seminar ROMIP1 . In many
respects ROMIP seminars are similar to other in-
ternational information retrieval events such as
TREC and NTCIR, which have already conducted
1http://romip.ru/en/index.html
different sentiment analysis tracks. Besides, there
are various shared tasks connected to the senti-
ment analysis like (Morante and Blanco, 2012;
Pestian et al, 2012; Wu and Jin, 2010; Amigo? et
al., 2012).
In this paper we partly overview the sentiment
analysis tasks proposed at ROMIP-2011 (Chetv-
iorkin et al, 2012) and ROMIP-2012 (Chetviorkin
and Loukachevich, 2013), the data prepared for
evaluation (and therefore available for other in-
terested researchers), and the results obtained by
participants. In addition we summarize the results
of two initiatives, compare them with the state of
the art in English and describe some interesting is-
sues connected to news-based sentiment analysis.
We justify all our decisions about the conducted
tracks based on the experience of the other re-
searchers, who made the similar initiatives in En-
glish. ROMIP-2011 and ROMIP-2012 are unique
events for Slavic languages and other European
languages different from English.
The paper is structured as follows. In section 2
we review papers on Russian sentiment analysis,
not related to the ROMIP evaluations. In section
3 we consider sentiment analysis evaluation tasks
proposed during ROMIP-2011, 2012 and consider
the main results obtained by participants.
2 Sentiment Analysis in Russian
In Russia studies devoted to sentiment analysis in
Russian before 2011 are not very numerous.
In (Ermakov, 2009) a sentiment analysis sys-
tem extracting opinions about cars from a Russian
blog community (http://avto-ru.livejournal.com/)
is presented. The approach is based on the detailed
description of knowledge about car trade marks,
their details and characteristics, semantic patterns
of sentiment expressions. This paper is the first, to
our knowledge, paper in Russia that reports eval-
uation results of the proposed approach: precision
84%, recall 20% (self-evaluation).
12
In international research Russian sentiment
analysis appears mainly in multilingual experi-
ments.
In (Zagibalov et al, 2010) comparable corpora
of reviews related to the same books in English
and in Russian are described. These corpora al-
lowed authors to study specific ways of sentiment
expression in Russian and English.
In (Steinberger et al, 2011) construction of gen-
eral sentiment vocabularies for several languages
is described. They create two source sentiment
vocabularies: English (2400 entries) and Spanish
(1737 entries). Both lists are translated by Google
translator to the target language. Only the overlap-
ping entries from each translation are taken into
further consideration. The set of target languages
comprises six languages including Russian. The
extracted Russian list of sentiment words con-
tained 966 entries with accuracy of 94.9%.
In one of the recent papers not related
to the ROMIP evaluations (Chetviorkin and
Loukachevitch, 2012), the generation of the Rus-
sian sentiment vocabulary for the generalized do-
main of products and services is described. Au-
thors constructed a new model based on multiple
features for domain-specific sentiment vocabulary
extraction, then applied this model to several do-
mains, and at last combined these domain-specific
vocabularies to generate Russian sentiment vocab-
ulary for products and services ? ProductSentiRus.
Now the extracted list is publicly available2.
3 Sentiment analysis tasks
The tasks of two Russian sentiment analysis eval-
uations ROMIP-2011 and ROMIP-2012 included:
? Sentiment classification of user reviews in
three domains (movies, books, digital cam-
eras) using several different sentiment scales,
? Sentiment classification of news-based opin-
ions, which are fragments of direct or indirect
speech extracted from news articles,
? Query-based retrieval of opinionated blog
posts in three domains (movies, books, dig-
ital cameras).
In ROMIP-2011 sentiment evaluation there
were 12 participants with more than 200 runs. In
ROMIP-2012 17 teams sent more than 150 runs.
2http://www.cir.ru/SentiLexicon/ProductSentiRus.txt
The presentations describing approaches were or-
ganized as a section of International Conference
on Computational Linguistics and Information
Technologies ?Dialog? (www.dialog-21.ru/en/).
3.1 Sentiment classification of reviews
The only task of ROMIP-2011 and one of the tasks
of ROMIP-2012 was sentiment classification of
users reviews in three domains: movies, books and
digital cameras.
The training data for this task included
movie and book collections with 15,718 and
24,159 reviews respectively from Imhonet service
(imhonet.ru) and the digital camera review collec-
tion with 10,370 reviews from Yandex Market ser-
vice (http://market.yandex.ru/). All reviews have
the authors score on the ten-point scale or the five-
point scale.
For testing, another collection of reviews with-
out any authors? scores was created. The testing
collection contained blog posts about the above-
mentioned entities found with Yandex?s Blog
Search Engine (http://blog.yandex.ru). So in this
track we tried to model a real-word task, when
a classifier should be trained on available data,
which can be quite different from the task data.
The participants stressed that our track is more dif-
ficult than training and testing on the similar data,
but agreed that this task setting is more realistic.
For each domain a list of search queries was
manually compiled and for each query a set of
blog posts was extracted. Finally, results obtained
for all queries were merged and sent to the partic-
ipants.
For the evaluation, annotators selected subjec-
tive posts related to three target domains, as-
sessed the polarity of these posts and labeled them
with three scores corresponding to different senti-
ment scales (two-class, three-class and five-class
scales).
The participants systems had to classify the
reviews to two, three or five classes according
to sentiment. The primary measures for evalua-
tion of two and three class tasks were accuracy
and macro-F1 measure. Macro-measures (Man-
ning et al, 2008) were used because the majority
of user reviews in blogs are positive (more than
80%). Macro-averaging means a simple average
over classes. The five-class task was additionally
evaluated with Euclidean distance measure, which
is the quadratic mean between the scores of the al-
13
Domains
2-class 3-class 5-class
F1 Acc. F1 Acc. F1 Acc.
Movies 0.786 0.881 0.592 0.754 0.286 0.602
Books 0.747 0.938 0.577 0.771 0.291 0.622
Cameras 0.929 0.959 0.663 0.841 0.342 0.626
Table 1: Best results of blog review classification in ROMIP-2011
Domains
2-class 3-class 5-class
F1 Acc. F1 Acc. F1 Acc.
Movies 0.707 0.831 0.520 0.694 0.377 0.407
Books 0.715 0.884 0.560 0.752 0.402 0.480
Cameras 0.669 0.961 0.480 0.742 0.336 0.480
Table 2: Best results of blog review classification in ROMIP-2012
gorithm and the assessor scores.
Practically all the best approaches in the review
classification tasks used SVM machine learning
method (Kotelnikov and Klekovkina, 2012; Pak
and Paroubek, 2012; Polyakov et al, 2012). Be-
sides, the best methods usually combined SVM
with other approaches including manual or auto-
matic dictionaries or rule-based systems. The best
achieved results according to macro-F1 measure
and Accuracy within ROMIP 2011 are presented
in Table 1 and within ROMIP 2012 in Table 2.
Observing the results of the open evaluation of
sentiment analysis systems in Russian during two
years we can make some conclusions about the
state of the art performance and specific charac-
teristics of the track.
The average level in 2-class classification task
according to Accuracy is near 90%, near 75% for
3-class classification task and near 50% for 5-class
task. Such results are consistent with the state of
the art performance in English. However these fig-
ures are slightly overestimated due to the skewness
of the testing collections. This fact is the conse-
quence of using blogs as a test set. The majority
of blog opinions about various objects is positive,
but such a collection is a priori unlabeled, which
leads to fair evaluation results.
3.2 Sentiment classification of opinionated
quotations
The next task of ROMIP-2012 concerned senti-
ment classification of short (1-2 sentences on av-
erage) fragments of direct or indirect speech au-
tomatically extracted from news articles (further
quotations). The somewhat similar task was con-
ducted within the NTCIR-6, where one of the main
tasks was extraction of opinion sentences from the
news articles in three languages: English, Chinese
and Japanese (Seki et al, 2007).
The topics of quotations could be quite differ-
ent: from politics and economy to sports and arts.
Therefore this task should be difficult enough for
both knowledge-based and machine-learning ap-
proaches.
Assessors annotated quotations as positive, neu-
tral, negative, or mixed. After the annotation the
quotations with mixed sentiment were removed
from the evaluation. So the participating systems
should classify quotations to three classes. This
task is similar to sentiment classification of po-
litical quotations (Awadallah et al, 2012; Bala-
subramanyan et al, 2012) to pro and contra po-
sitions. In (Awadallah et al, 2012) authors state
that short quotations are difficult for classification
because useful linguistic features tend to be sparse
and the same quotation can have different polari-
ties for different topics. In our case the task was
even more difficult because of unlimited topics
and three-class classification.
In ROMIP-2012 evaluation 4,260 quotations
were prepared for training. For testing more than
120 thousand quotes were sent to participants, but
real evaluation was made on the basis of 5,500
quotations randomly sampled and annotated from
the testing set. An example of the quotation is as
follows: Patriarch Kirill, says feminism is a ?very
dangerous? phenomenon offering an illusion of
freedom to women, who he says should focus on
their families and children.
In this task class distribution was rather bal-
anced in comparison with the review classifica-
tion task: 41% of quotes were negative, 32% of
14
RunID Macro P Macro R Macro F1 Accuracy
xxx-4 0.626 0.616 0.621 0.616
xxx-11 0.606 0.579 0.592 0.571
xxx-15 0.563 0.560 0.562 0.582
Baseline 0.138 0.333 0.195 0.413
Table 3: Best results for the news quotation classification task in ROMIP 2012
RunID Domain P@1 P@5 P@10 NDCG@10
xxx-0 book 0.3 0.32 0.286 0.305
xxx-8 book 0.25 0.31 0.332 0.298
yyy-9 camera 0.402 0.313 0.302 0.305
yyy-1 camera 0.402 0.328 0.325 0.226
zzz-3 film 0.494 0.449 0.438 0.338
zzz-8 film 0. 494 0.448 0.444 0.332
Table 4: Best results in the task of retrieval of opinionated blog posts
quotes were positive and 27% of quotes were neu-
tral. For evaluation again macro-measures and ac-
curacy were applied.
The results of the participants are presented in
Table 3. The baseline results correspond to clas-
sification of quotations according to the major
class. In opposite to the review classification task,
the leaders in the news-based classification were
knowledge-based approaches. It is due to the ab-
sence of a large training collection appropriate for
this task because of the broad scope of quotation
topics.
The authors of the best approach in this task re-
port that their knowledge-based system has a con-
siderable vocabulary including 15 thousand nega-
tive expressions, 7 thousand positive expressions,
around 120 so-called operators (intensifiers and
invertors) and around 200 neutral stop expressions
including sentiment words as their components.
The system has a small number of rules for ag-
gregating scores of sentiment word and operator
sequences (Kuznetsova et al, 2013). The second
and third results in this task were obtained by a
rule-based system with comparably small senti-
ment dictionaries but a rich rule set based on syn-
tactic analysis (Panicheva, 2013).
An interesting conclusion is that the size of sen-
timent dictionaries can be compensated with vari-
ous syntactic rules, which allows handling the va-
riety of situations in expressing sentiment.
The results of this task can be compared with
one of the recent studies on lexicon-based meth-
ods for sentiment analysis in English (Taboada et
al., 2011). The text fragments in the paper and
in ROMIP evaluation are rather equal by style
(news quotes versus opinionated news sentences).
We cannot directly compare the results of analo-
gous systems in Russian and English, because we
worked with 3 class classification problem (pos-
itive, negative, neutral) versus 2 class task in the
paper, but available figures are the following: the
accuracy of sentiment analysis systems in Russian
is near 61.6% in the three-class task versus 71.57%
for the two-class task in English.
3.3 Query-based retrieval of opinionated
blog posts
For several years TREC Blog tracks were con-
nected with opinion finding and processing of blog
data (Ounis et al, 2007; Macdonald et al, 2008;
Ounis et al, 2008; Macdonald et al, 2010; Ou-
nis et al, 2011). During the research cycles within
these initiatives, the following sentiment analysis
tasks were considered:
? Opinion finding (blog post) retrieval task,
? Polarised opinion finding (blog post) retrieval
task.
The query-based retrieval of opinions from
blogs was one of the basic tasks for the TREC
Blog Track. Thus, we also decided to start with the
similar task for Russian language. Here the par-
ticipants had to find all relevant opinionated posts
from the blog collection according to a specific
query. Examples of queries include (translation
from Russian):
15
? movie domain: The Girl with the Dragon Tat-
too; film ?The dictator?;
? book domain: Agatha Cristie ?Ten little nig-
gers?; Dan Brown ?The Code da Vinci?;
? digital camera domain: Canon EOS 1100D
Kit; Canon PowerShot G12.
Only one group participated in this task and
therefore organizers implemented a simple ap-
proach to conduct the track. The approach to the
sentiment post retrieval was based on computa-
tion of weighted sum of three components: TFIDF
similarity of a query to the title of a blog post,
TFIDF of a query to the text of the post and the
share of sentiment words in the post. For com-
putation of the latter component, aforementioned
Russian sentiment list ProductSentiRus (see sec-
tion 2) was used:
Weight = ? ? (
?
w?q
tfidf +
?
w?q
tfidfheader)+
+(1? ?) ? (SentiWeight)
The organizers experimented with different val-
ues of ? = 0.2, 0.4, 0.5, 0.6, 0.8. The best per-
formance was obtained with ? = 0.6 for all sub-
domains of this task. To avoid underestimation of
participant results, the evaluation was made only
on the basis of labeled documents. For this task
we used two measures: P@n and NDGN@n.
Precision@n indicates the number of correct
(relevant) objects in the first n objects in the re-
sult set and NDCG@n measures the usefulness,
or gain, of a document based on its position in
the result list (Manning et al, 2008). The main
measures of the performance in this task were
NDCG@10 and Precision@10 (Table 4).
4 Conclusion
In this paper we reported the state of the art of
Russian sentiment analysis. Our report is based on
the results of two evaluations of sentiment analysis
systems organized in 2011?2012 within the frame-
work of Russian seminar on information retrieval
ROMIP. We proposed user review classification
tasks in a practical setting, when available data
should be used for training a classifier intended for
similar, but another data. Besides, one of the inter-
esting and complicated tasks of ROMIP-2012 was
sentiment classification of opinions extracted from
news articles.
Acknowledgments
This work is partially supported by grant N11-07-
00588-a.
References
Muhammad Abdul-Mageed, Mona Diab, and Mo-
hammed Korayem. 2011. Subjectivity and senti-
ment analysis of modern standard arabic. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, volume 2, pages 587?591.
Enrique Amigo?, Adolfo Corujo, Julio Gonzalo, Edgar
Meij, and Md Rijke. 2012. Overview of re-
plab 2012: Evaluating online reputation manage-
ment systems. In CLEF 2012 Labs and Workshop
Notebook Papers, pages 1?24.
Rawia Awadallah, Maya Ramanath, and Gerhard
Weikum. 2012. Polaricq: polarity classification of
political quotations. In Proceedings of the 21st ACM
international conference on Information and knowl-
edge management, pages 1945?1949.
Ramnath Balasubramanyan, William W Cohen, Doug
Pierce, and David P Redlawsk. 2012. Modeling po-
larizing topics: When do different political commu-
nities respond differently to the same news? In the
International AAAI Conference on Weblogs and So-
cial Media (ICWSM).
Ilia Chetviorkin and Natalia Loukachevich. 2013.
Sentiment analysis track at romip 2012. In Proceed-
ings of International Conference Dialog, volume 2,
pages 40?50.
Ilia Chetviorkin and Natalia Loukachevitch. 2012.
Extraction of russian sentiment lexicon for product
meta-domain. In Proceedings of COLING 2012,
pages 593?610.
Ilia Chetviorkin, P Braslavskiy, and Natalia
Loukachevich. 2012. Sentiment analysis track
at romip 2011. In Proceedings of International
Conference Dialog, volume 2, pages 1?14.
Alexander Ermakov. 2009. Knowledge extraction
from text and its processing: Current state and
prospects. Information technologies, (7):50?55.
Evgeniy Kotelnikov and Marina Klekovkina. 2012.
Sentiment analysis of texts based on machine learn-
ing methods. In Proceedings of International Con-
ference Dialog, volume 2, pages 27?36.
Ekaterina Kuznetsova, Natalia Loukachevitch, and Ilia
Chetviorkin. 2013. Testing rules for sentiment anal-
ysis system. In Proceedings of International Con-
ference Dialog, volume 2, pages 71?80.
Craig Macdonald, Iadh Ounis, and Ian Soboroff. 2008.
Overview of the trec 2007 blog track. In Proceed-
ings of TREC, volume 7.
16
Craig Macdonald, Iadh Ounis, and Ian Soboroff. 2010.
Overview of the trec 2009 blog track. In Proceed-
ings of TREC, volume 9.
Christopher D Manning, Prabhakar Raghavan, and
Hinrich Schu?tze. 2008. Introduction to information
retrieval, volume 1. Cambridge University Press
Cambridge.
Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2007. Learning multilingual subjective language via
cross-lingual projections. In Proceedings of the An-
nual Meeting of the Association of Computational
Linguistics, volume 45, pages 976?983.
Roser Morante and Eduardo Blanco. 2012. * sem 2012
shared task: Resolving the scope and focus of nega-
tion. In Proceedings of the First Joint Conference on
Lexical and Computational Semantics, pages 265?
274.
Iadh Ounis, Maarten de Rijke, Craig Macdonald, Gi-
lad Mishne, and Ian Soboroff. 2007. Overview of
the trec 2006 blog track. In Proceedings of TREC,
volume 6.
Iadh Ounis, Craig Macdonald, and Ian Soboroff. 2008.
Overview of the trec-2008 blog track. Technical re-
port, DTIC Document.
Iadh Ounis, Craig Macdonald, and Ian Soboroff. 2011.
Overview of the trec 2010 blog track. In Proceed-
ings of TREC, volume 10.
Alexander Pak and Patrick Paroubek. 2012. Language
independent approach to sentiment analysis (limsi
participation in romip11. In Proceedings of Interna-
tional Conference Dialog, volume 2, pages 37?50.
Polina Panicheva. 2013. Atex. a rule-based sentiment
analysis system. processing texts in various topics.
In Proceedings of International Conference Dialog,
volume 2, pages 101?113.
Vero?nica Pe?rez-Rosas, Carmen Banea, and Rada Mi-
halcea. 2012. Learning sentiment lexicons in
spanish. In Proceedings of the Eight International
Conference on Language Resources and Evaluation
(LREC?12).
John P Pestian, Pawel Matykiewicz, Michelle Linn-
Gust, Brett South, Ozlem Uzuner, Jan Wiebe, K Bre-
tonnel Cohen, John Hurdle, and Christopher Brew.
2012. Sentiment analysis of suicide notes: A shared
task. Biomedical Informatics Insights, 5(Suppl
1):3?16.
Pavel Polyakov, Maria Kalinina, and Vladimir Pleshko.
2012. Research on applicability of thematic classifi-
cation methods to the problem of book review classi-
fication. In Proceedings of International Conference
Dialog, volume 2, pages 51?59.
Yohei Seki, David Kirk Evans, Lun-Wei Ku, Hsin-Hsi
Chen, Noriko Kando, and Chin-Yew Lin. 2007.
Overview of opinion analysis pilot task at ntcir-6. In
Proceedings of NTCIR-6 Workshop Meeting, pages
265?278.
Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann,
Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova,
Ralf Steinberger, Hristo Tanev, Silvia Va?zquez, and
Vanni Zavarella. 2011. Creating sentiment dictio-
naries via triangulation. Decision Support Systems,
pages 28?36.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional linguistics, 37(2):267?307.
Yunfang Wu and Peng Jin. 2010. Semeval-2010
task 18: Disambiguating sentiment ambiguous ad-
jectives. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 81?85.
Taras Zagibalov, Katerina Belyatskaya, and John Car-
roll. 2010. Comparable english-russian book review
corpora for sentiment analysis. In Computational
Approaches to Subjectivity and Sentiment Analysis,
pages 67?72.
17
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 67?72,
Baltimore, Maryland, USA. June 27, 2014.
c?2014 Association for Computational Linguistics
Two-Step Model for Sentiment Lexicon Extraction from Twitter Streams
Ilia Chetviorkin
Lomonosov Moscow State University
Moscow, Leninskiye Gory 1
ilia.chetviorkin@gmail.com
Natalia Loukachevitch
Lomonosov Moscow State University
Moscow, Leninskiye Gory 1
louk nat@mail.ru
Abstract
In this study we explore a novel technique
for creation of polarity lexicons from the
Twitter streams in Russian and English.
With this aim we make preliminary fil-
tering of subjective tweets using general
domain-independent lexicons in each lan-
guage. Then the subjective tweets are
used for extraction of domain-specific sen-
timent words. Relying on co-occurrence
statistics of extracted words in a large un-
labeled Twitter collections we utilize the
Markov random field framework for the
word polarity classification. To evaluate
the quality of the obtained sentiment lex-
icons they are used for tweet sentiment
classification and outperformed previous
results.
1 Introduction
With growing popularity of microblogging ser-
vices such as Twitter, the amount of subjective in-
formation containing user opinions and sentiments
is increasing dramatically. People tend to express
their opinions about events in the real life and such
opinions contain valuable information for market
research, brand monitoring and political polls.
The task of automatic processing of such in-
formal resources is challenging because people
use a lot of slang, vulgarity and out-of-vocabulary
words to state their opinions about various ob-
jects and situations. In particular, it is difficult
to achieve the high quality of sentiment analy-
sis on such type of short informal texts as tweets
are. Standard domain-independent lexicon-based
methods suffer from low coverage, and for ma-
chine learning methods it is difficult to prepare a
representative collection of labeled data because
topics of discussion are changing rapidly.
Thus, special methods for processing social me-
dia data streams should be developed. We pro-
posed and evaluated our approach for Russian lan-
guage, where only a limited number of natural
language processing tools and resources are avail-
able. Then to demonstrate the robustness of the
method and to compare the results with the other
approaches we used it for English.
The current research can be separated into two
steps. We start with a special supervised model
based on statistical and linguistic features of sen-
timent words, which is trained and evaluated in
the movie domain. Then this model is utilized
for extraction of sentiment words from unlabeled
Twitter datasets, which are preliminary filtered us-
ing the domain-independent lexicons: Product-
SentiRus (Chetviorkin and Loukachevitch, 2012)
for Russian and MPQA (Wilson et al., 2005) for
English.
In the second step an algorithm for polarity clas-
sification of extracted sentiment words is intro-
duced. It is built using the Markov random field
framework and uses only information contained in
text collections.
To evaluate the quality of the created lexicons
extrinsically, we conduct the experiments on the
tweet subjectivity and polarity classification tasks
using various lexicons.
The key advantage of the proposed two-step al-
gorithm is that once trained it can be utilized to
different domains and languages with minor mod-
ifications. To demonstrate the ability of the pro-
posed algorithm to extract sentiment words in var-
ious domains we took significantly different col-
lections for training and testing: movie review col-
lection for training and large collections of tweets
for testing.
2 Related work
There are two major approaches for creation
of a sentiment lexicon in a specific language:
dictionary-based methods and corpus-based meth-
ods.
67
Dictionary-based methods for various lan-
guages have received a lot of attention in the lit-
erature (P?erez-Rosas et al., 2012; Mohammad et
al., 2009; Clematide and Klenner, 2010), but the
main problem of such approaches is that it is diffi-
cult to apply them to processing social media. The
reason is that short informal texts contain a lot of
misspellings and out-of-vocabulary words.
Corpus-based methods are more suitable for
processing social media data. In such approaches
various statistical and linguistic features are used
to discriminate opinion words from all other
words (He et al., 2008; Jijkoun et al., 2010).
Another important group of approaches, which
can be both dictionary-based and corpus-based are
graph-based methods. In (Velikovich et al., 2010)
a new method for constructing a lexical network
was proposed, which aggregates the huge amount
of unlabeled data. Then the graph propagation al-
gorithm was used. Several other researchers uti-
lized the graph or label propagation techniques
for solving the problem of opinion word extrac-
tion (Rao and Ravichandran, 2009; Speriosu et al.,
2011).
In (Takamura et al., 2005) authors describe a
probabilistic model for assigning polarity to each
word in a collection. This model is based on
the Ising spin model of magnetism and is built
upon Markov random field framework, using var-
ious dictionary-based and linguistic features. In
our research, unlike (Takamura et al., 2005) we
use only information contained in a text collection
without any external dictionary resources (due to
the lack of necessary resources for Russian). Our
advantage is that we use only potential domain-
specific sentiment words during the construction
of the network.
A large body of research has been focused on
Twitter sentiment analysis during the previous sev-
eral years (Barbosa and Feng, 2010; Bermingham
and Smeaton, 2010; Bifet and Frank, 2010; Davi-
dov et al., 2010; Kouloumpis et al., 2011; Jiang
et al., 2011; Agarwal et al., 2011; Wang et al.,
2011). In (Chen et al., 2012) authors propose an
optimization framework for extraction of opinion
expressions from tweets. Using extracted lexicons
authors were able to improve the tweet sentiment
classification quality. Our approach is based on
similar assumptions (like consistency relations),
but we do not use any syntactic parsers and dic-
tionary resources. In (Volkova et al., 2013) a new
multilingual bootstrapping technique for building
tweet sentiment lexicons was introduced. This
method is used as a baseline in our work.
3 Data
For the experiments in this paper we use several
collections in two domains: movie review col-
lection in Russian for training and fine-tuning of
the proposed algorithms and Twitter collections
for evaluation and demonstration of robustness in
Russian and English languages.
Movie domain. The movie review dataset col-
lected from the online service imhonet.ru. There
are 28, 773 movie reviews of various genres with
numeric scores specified by their authors (DOM).
Additionally, special collections with low con-
centration of sentiment words are utilized: the
contrast collection consists of 17, 980 movie plots
(DESC) and a collection of two million news doc-
uments (NEWS). Such collections are useful for
filtering out of domain-specific and general neu-
tral words, which are very frequent in news and
object descriptions.
Twitter collections. We use three datasets for
each language: 1M+ of unlabeled tweets (UNL)
for extraction of sentiment lexicons, 2K labeled
tweets for development data (DEV), and 2K la-
beled tweets for evaluation (TEST). DEV dataset
is used to find the best combination of various lex-
icons for processing Twitter data and TEST for
evaluating the quality of constructed lexicons.
The UNL dataset in Russian was collected dur-
ing one day using Twitter API. These tweets con-
tain various topics without any filtering. Only
strict duplicates and retweets were removed from
the dataset. The similar collection for English was
downloaded using the links from (Volkova et al.,
2013).
All tweets in DEV and TEST collections are
manually labeled by subjectivity and polarity us-
ing the Mechanical Turk with five workers (ma-
jority voting). This data was used for development
and evaluation in (Volkova et al., 2013).
4 Method for sentiment word extraction
In this section we introduce an algorithm for
sentiment lexicon extraction, which is inspired
by the method described in (Chetviorkin and
Loukachevitch, 2012), but have more robust fea-
tures, which allow us to apply it to any unlabeled
text collection (e.g. tweets collection). The pro-
68
posed algorithm is applied to text collections in
Russian and English and obtained results are eval-
uated intrinsically for Russian and extrinsically for
both languages.
4.1 An extraction model
Our algorithm is based on several text collec-
tions: collection with the high concentration of
sentiment words (e.g. DOM collection), con-
trast domain-specific collection (e.g. DESC col-
lection), contrast domain-independent collection
(e.g. NEWS collection). Thus, taking into ac-
count statistical distributions of words in such col-
lections we are able to distinguish domain-specific
sentiment words.
We experimented with various features to create
the robust cross-domain feature representation of
sentiment words. As a result the eight most valu-
able features were used in further experiments:
Linguistic features. Adjective binary indica-
tor, noun binary indicator, feature reflecting part-
of-speech ambiguity (for lemma), binary feature
of predefined list of prefixes (e.g. un, im);
Statistical features. Frequency of capitalized
words, frequency of co-occurrence with polarity
shifters (e.g. no, very), TFIDF feature calculated
on the basis of various collection pairs, weirdness
feature (the ratio of relative frequencies of certain
lexical items in special and general collections)
calculated using several pairs of collections.
To train supervised machine learning algo-
rithms all words with frequency greater than three
in the Russian movie review collection (DOM)
were labeled manually by two assessors. If there
was a disagreement about the sentiment of a spe-
cific word, the collective judgment after the dis-
cussion was used as a final ground truth. As a re-
sult of the assessment procedure the list of 4079
sentiment words was obtained.
The best quality of classification using labeled
data was shown by the ensemble of three classi-
fiers: Logistic Regression, LogitBoost and Ran-
dom Forest. The quality according to Precision@n
measure can be found in Table 1. This trained
model was used in further experiments for extrac-
tion of sentiment words both in English and in
Russian.
4.2 Extraction of subjective words from
Twitter data
To verify the robustness of the model on new un-
labeled data it was utilized for sentiment word ex-
Lexicon P@100 P@1000
MovieLex 95.0% 78.3%
TwitterLex 95.0% 79.9%
Table 1: Quality of subjective word extraction in
Russian
traction from multi-topic tweet collection UNL in
each language. To apply this model we prepared
three collections: domain-specific with high con-
centration of sentiment words, domain-specific
with low concentration of sentiment words and
one general collection with low concentration of
sentiment words. As the general collection we
could take the same NEWS collection (see Sec-
tion 3) for Russian and British National Corpus
1
for English.
To prepare domain-specific collections we clas-
sified the UNL collections by subjectivity using
general purpose sentiment lexicons ProductSen-
tiRus and MPQA in accordance with the language.
The subjectivity classifier predicted that a tweet
was subjective if it contained at least one subjec-
tive term from this lexicon. All subjective tweets
constituted a collection with the high concentra-
tion of sentiment words and all the other tweets
constituted the contrast collection.
Finally, using all specially prepared collections
and the trained model (in the movie domain), new
lexicons of twitter-specific sentiment words were
extracted. The quality of extraction in Russian ac-
cording to manual labeling of two assessors can be
found in Table 1. The resulting quality of extracted
Russian lexicon is on the same level as in the ini-
tial movie domain, what confirms the robustness
of the proposed model.
We took 5000 of the most probable sentiment
words from each lexicon for further work.
5 Polarity classification using MRF
In the second part of current research we describe
an algorithm for polarity classification of extracted
sentiment words. The proposed method relies on
several assumptions:
? Each word has the prior sentiment score cal-
culated using the review scores where it ap-
pears (simple averaging);
? Words with similar polarity tend to co-occur
closely to each other;
1
http://www.natcorp.ox.ac.uk/
69
? Negation between sentiment words leads to
the opposite polarity labels.
5.1 Algorithm description
To formalize all these assumptions we construct an
undirected graphical model using extracted sen-
timent word co-occurrence statistics. Each ex-
tracted word is represented by a vertex in a graph
and an edge between two vertexes is established in
case if they co-occur together more than once in
the collection. We drop all the edges where aver-
age distance between words is more than 8 words.
Our model by construction is similar to ap-
proach based on the Ising spin model described
in (Takamura et al., 2005). Ising model is used
to describe ferromagnetism in statistical mechan-
ics. In general, the system is composed of N bi-
nary variables (spins), where each variable x
i
?
{?1,+1}, i = 1, 2, ..., N . The energy function of
the system is the following:
E(x) = ?
?
ij
s
ij
x
i
x
j
?
?
i
h
i
x
i
(1)
where s
ij
represents the efficacy of interaction be-
tween two spins and h
i
stands for external field
added to x
i
. The probability of each system con-
figuration is provided by Boltzmann distribution:
P (X) =
exp
??E(X)
Z
(2)
where Z is a normalizing factor and ? = (T
?1
>
0) is inverse temperature, which is parameter of
the model. We calculate values of P (X) with sev-
eral different values of ? and try to find the locally
polarized state of the network.
To specify the initial polarity of each word, we
assume that each text from the collection has its
sentiment score. This condition is not very strict,
because there are a lot of internet review services
where people assign numerical scores to their re-
views. Using such scores we can calculate the de-
viation from the average score for each word in the
collection:
h(i) = E(c|w
i
)? E(c)
where c is the review score random variable, E(c)
is the expectation of the score in the collection and
E(c|w
i
) is the expectation of the score for reviews
containing word w
i
. Thus we assign the initial
weight of each vertex i in the MRF to be equal
to h(i).
To specify the weight of each edge in the net-
work we made preliminary experiments to detect
the dependency between the probability of the
word pair to have similar polarity and average dis-
tance between them. The result of such experi-
ment for movie reviews can be found on Figure 1.
One can see that if the distance between the words
Figure 1: The dependency between the probability
to have similar polarity and average distance
is above four, then the probability is remain on the
same level which is slightly biased to similar po-
larity. Relying on this insight and taking into ac-
count the frequency of co-occurrence of the words
we used the following edge weights:
s(i, j) = f(w
i
, w
j
)max
(
0.5?
d(w
i
, w
j
)
d(w
i
, w
j
) + 4
, 0
)
where f(w
i
, w
j
) is the co-occurrence frequency
in the collection and d(w
i
, w
j
) is the average dis-
tance between words w
i
and w
j
.
Finally, we revert the sign of this equation in
case of more than half of co-occurrences contains
negation (no, not, but) between opinion words.
In practice we can find approximate solution us-
ing such algorithms as: Loopy Belief Propagation
(BP), Mean Field (MF), Gibbs Sampling (Gibbs).
The performance of the methods was evalu-
ated for a lexical network constructed from the
first 3000 of the most probable extracted sentiment
words in the movie review collection (DOM). We
took from them 822 interconnected words with
strict polarity labeled by two assessors as a gold
standard. Testing was performed by varying ?
from 0.1 to 1.0. The primary measure in this ex-
periment was accuracy. The best results can be
found in Table 2.
The best performance was demonstrated by MF
algorithm and ? = 0.4. This algorithm and pa-
rameter value were used in further experiments on
unlabeled tweet collections.
70
? BP MF Gibbs
0.4 83.8 85.2 83.7
0.5 83.6 84.5 82.0
0.6 85.0 83.1 79.4
Table 2: Dependence between the accuracy of
classification and ?
5.2 Polarity classification of subjective words
from Twitter data
Using the general polarity lexicons we classify all
subjective tweets in large UNL collections into
positive and negative categories. For the polarity
classifier, we predict a tweet to be positive (nega-
tive) if it contains at least one positive (negative)
term from the lexicon taking into account nega-
tion. If a tweet contains both positive and nega-
tive terms, we take the majority label. In case if a
tweet does not contain any word from the lexicon
we predict it to be positive.
These labels (+1 for positive and ?1 for nega-
tive) can be used to compute initial polarity h(i)
for all extracted sentiment words from the UNL
collections. The weights of the links between
words s(i, j) can be also computed using full un-
labeled collections.
Thus, we can utilize the algorithm for polarity
classification of sentiment words extracted from
Twitter. The resulting lexicon for Russian contains
2772 words and 2786 words for English (we take
only words that are connected in the network). To
evaluate the quality of the obtained lexicons the
Russian one was labeled by two assessors. In re-
sult of such markup 1734 words with strict posi-
tive or negative polarity were taken. The accuracy
of the lexicon on the basis of the markup was equal
to 72%, which is 1.5 % better than the simple av-
erage score baseline.
6 Lexicon Evaluations
To evaluate all newly created lexicons they were
utilized in tweet polarity and subjectivity classifi-
cation tasks using the TEST collections. The re-
sults of the classification for both languages can
be found in Table 3 and Table 4.
As one can see, the newly created Twitter-
specific sentiment lexicon results outperform the
result of (Volkova et al., 2013) in subjectivity clas-
sification for Russian but slightly worse than the
result for English. On the other hand the re-
sults of polarity classification are on par or better
Lexicon P R F
subj
Russian
Volkova, 2013 - - 61.0
TwitterLex 60.2 79.3 68.5
English
Volkova, 2013 - - 75.0
TwitterLex 58.8 95.5 73.0
Table 3: Quality of tweet subjectivity classifica-
tion
Lexicon P R F
pol
Russian
Volkova, 2013 - - 73.0
TwitterLex 65.5 82.0 72.8
Combined 65.8 85.5 74.3
English
Volkova, 2013 - - 78.0
TwitterLex 72.1 88.1 79.3
Combined 73.2 89.3 80.4
Table 4: Quality of tweet polarity classification
than the results of (Volkova et al., 2013) lexicons
bootstrapped from domain-independent sentiment
lexicons. Thus, to push the quality of polarity
classification forward we combined the domain-
independent lexicons and our Twitter-specific lex-
icons. We experimented with various word counts
from general lexicons and found the optimal com-
bination on the DEV collection: all words from
TwitterLex and 2000 the most strong sentiment
words from ProductSentiRus in Russian and all
strong sentiment words from MPQA in English.
The lexicon combination outperforms all previous
results by F-measure leading to the conclusion that
proposed method can capture valuable domain-
specific sentiment words.
7 Conclusion
In this paper we proposed a new method for ex-
traction of domain-specific sentiment lexicons and
adopted the Ising model for polarity classifica-
tion of extracted words. This two-stage method
was applied to a large unlabeled Twitter dataset
and the extracted sentiment lexicons performed on
the high level in the tweet sentiment classification
task. Our method can be used in a streaming mode
for augmentation of sentiment lexicons and sup-
porting the high quality of multilingual sentiment
classification.
71
Acknowledgements This work is partially sup-
ported by RFBR grant 14-07-00682.
References
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-
bow, and Rebecca Passonneau. 2011. Sentiment
analysis of twitter data. In Proceedings of the Work-
shop on Languages in Social Media, pages 30?38.
Association for Computational Linguistics.
Luciano Barbosa and Junlan Feng. 2010. Robust sen-
timent detection on twitter from biased and noisy
data. In Proceedings of the 23rd International
Conference on Computational Linguistics: Posters,
pages 36?44. Association for Computational Lin-
guistics.
Adam Bermingham and Alan F Smeaton. 2010. Clas-
sifying sentiment in microblogs: is brevity an advan-
tage? In Proceedings of the 19th ACM international
conference on Information and knowledge manage-
ment, pages 1833?1836. ACM.
Albert Bifet and Eibe Frank. 2010. Sentiment knowl-
edge discovery in twitter streaming data. In Discov-
ery Science, pages 1?15. Springer.
Lu Chen, Wenbo Wang, Meenakshi Nagarajan, Shao-
jun Wang, and Amit P Sheth. 2012. Extracting
diverse sentiment expressions with target-dependent
polarity from twitter. In ICWSM.
Ilia Chetviorkin and Natalia V Loukachevitch. 2012.
Extraction of russian sentiment lexicon for product
meta-domain. In COLING, pages 593?610.
Simon Clematide and Manfred Klenner. 2010. Eval-
uation and extension of a polarity lexicon for ger-
man. In Proceedings of the First Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis, pages 7?13.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics:
Posters, pages 241?249. Association for Computa-
tional Linguistics.
Ben He, Craig Macdonald, Jiyin He, and Iadh Ounis.
2008. An effective statistical approach to blog post
opinion retrieval. In Proceedings of the 17th ACM
conference on Information and knowledge manage-
ment, pages 1063?1072. ACM.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. In ACL, pages 151?160.
Valentin Jijkoun, Maarten de Rijke, and Wouter
Weerkamp. 2010. Generating focused topic-
specific sentiment lexicons. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 585?594. Association for
Computational Linguistics.
Efthymios Kouloumpis, Theresa Wilson, and Johanna
Moore. 2011. Twitter sentiment analysis: The good
the bad and the omg! In ICWSM.
Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009. Generating high-coverage semantic orien-
tation lexicons from overtly marked words and a
thesaurus. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Pro-
cessing: Volume 2, pages 599?608. Association for
Computational Linguistics.
Ver?onica P?erez-Rosas, Carmen Banea, and Rada Mi-
halcea. 2012. Learning sentiment lexicons in span-
ish. In LREC, pages 3077?3081.
Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 675?682. Association for Computational Lin-
guistics.
Michael Speriosu, Nikita Sudan, Sid Upadhyay, and
Jason Baldridge. 2011. Twitter polarity classifica-
tion with label propagation over lexical links and the
follower graph. In Proceedings of the First work-
shop on Unsupervised Learning in NLP, pages 53?
63. Association for Computational Linguistics.
H. Takamura, T. Inui, and M. Okumura. 2005. Ex-
tracting semantic orientations of words using spin
model. In Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics, pages
133?140.
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry
Hannan, and Ryan McDonald. 2010. The viability
of web-derived polarity lexicons. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 777?785. As-
sociation for Computational Linguistics.
Svitlana Volkova, Theresa Wilson, and David
Yarowsky. 2013. Exploring sentiment in social
media: Bootstrapping subjectivity clues from
multilingual twitter streams. In Proceedings
of the 51st Annual Meeting of the Association
for Computational Linguistics (ACL13), pages
505?510.
Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou,
and Ming Zhang. 2011. Topic sentiment analysis
in twitter: a graph-based hashtag sentiment classifi-
cation approach. In Proceedings of the 20th ACM
international conference on Information and knowl-
edge management, pages 1031?1040. ACM.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the con-
ference on human language technology and empiri-
cal methods in natural language processing, pages
347?354. Association for Computational Linguis-
tics.
72
