Event Detection and Summarization in Weblogs with Temporal Collocations 
Chun-Yuan Teng and Hsin-Hsi Chen 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, Taiwan 
{r93019, hhchen}@csie.ntu.edu.tw 
Abstract 
 
This paper deals with the relationship between weblog content and time. With the proposed temporal mutual information, we analyze 
the collocations in time dimension, and the interesting collocations related to special events. The temporal mutual information is 
employed to observe the strength of term-to-term associations over time. An event detection algorithm identifies the collocations that 
may cause an event in a specific timestamp. An event summarization algorithm retrieves a set of collocations which describe an event. 
We compare our approach with the approach without considering the time interval. The experimental results demonstrate that the 
temporal collocations capture the real world semantics and real world events over time. 
 
1. 
2. 
Introduction 
Compared with traditional media such as online news 
and enterprise websites, weblogs have several unique 
characteristics, e.g., containing abundant life experiences 
and public opinions toward different topics, highly 
sensitive to the events occurring in the real world, and 
associated with the personal information of bloggers. 
Some works have been proposed to leverage these 
characteristics, e.g., the study of the relationship between 
the content and bloggers? profiles (Adamic & Glance, 
2005; Burger & Henderson, 2006; Teng & Chen, 2006), 
and content and real events (Glance, Hurst & Tornkiyo, 
2004; Kim, 2005; Thelwall, 2006; Thompson, 2003). 
In this paper, we will use temporal collocation to 
model the term-to-term association over time.  In the past, 
some useful collocation models (Manning & Sch?tze, 
1999) have been proposed such as mean and variance, 
hypothesis test, mutual information, etc. Some works 
analyze the weblogs from the aspect of time like the 
dynamics of weblogs in time and location (Mei, et al, 
2006), the weblog posting behavior (Doran, Griffith & 
Henderson, 2006; Hurst, 2006), the topic extraction (Oka, 
Abe & Kato, 2006), etc. The impacts of events on social 
media are also discussed, e.g., the change of weblogs after 
London attack (Thelwall, 2006), the relationship between 
the warblog and weblogs (Kim, 2005; Thompson, 2003), 
etc. 
This paper is organized as follows. Section 2 defines 
temporal collocation to model the strength of term-to-term 
associations over time.  Section 3 introduces an event 
detection algorithm to detect the events in weblogs, and 
an event summarization algorithm to extract the 
description of an event in a specific time with temporal 
collocations. Section 4 shows and discusses the 
experimental results.  Section 5 concludes the remarks. 
Temporal Collocations 
We derive the temporal collocations from Shannon?s 
mutual information (Manning & Sch?tze, 1999) which is 
defined as follows (Definition 1). 
Definition 1 (Mutual Information) The mutual 
information of two terms x and y is defined as: 
)()(
),(log),(),(
yPxP
yxPyxPyxI =  
where P(x,y) is the co-occurrence probability of x and y, 
and P(x) and P(y) denote the occurrence probability of x 
and y, respectively. 
Following the definition of mutual information, we 
derive the temporal mutual information modeling the 
term-to-term association over time, and the definition is 
given as follows.  
 Definition 2 (Temporal Mutual Information) Given 
a timestamp t and a pair of terms x and y, the temporal 
mutual information of x and y in t is defined as: 
)|()|(
)|,(log)|,()|,(
tyPtxP
tyxPtyxPtyxI =
where P(x,y|t) is the probability of co-occurrence of terms 
x and y in timestamp t, P(x|t) and P(y|t) denote the 
probability of occurrences of x and y in timestamp t, 
respectively. 
To measure the change of mutual information in time 
dimension, we define the change of temporal mutual 
information as follows. 
Definition 3 (Change of Temporal Mutual 
Information) Given time interval [t1, t2], the change of 
temporal mutual information is defined as: 
12
12
21
)|,()|,(),,,(
tt
tyxItyxIttyxC ?
?=  
where C(x,y,t1,t2) is the change of temporal mutual 
information of terms x and y in time interval [t1, t2], I(x,y| 
t1) and I(x,y| t2) are the temporal mutual information in 
time t1 and t2, respectively. 
3. Event Detection 
Event detection aims to identify the collocations 
resulting in events and then retrieve the description of 
events. Figure 1 sketches an example of event detection. 
The weblog is parsed into a set of collocations. All 
collocations are processed and monitored to identify the 
plausible events.  Here, a regular event ?Mother?s day? 
and an irregular event ?Typhoon Chanchu? are detected.  
The event ?Typhoon Chanchu? is described by the words  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: An Example of Event Detection
?Typhoon?, ?Chanchu?, ?2k?, ?Eye?, ?Path? and 
?chinaphillippine?.  
The architecture of an event detection system includes 
a preprocessing phase for parsing the weblogs and 
retrieving the collocations; an event detection phase 
detecting the unusual peak of the change of temporal 
mutual information and identifying the set of collocations 
which may result in an event in a specific time duration; 
and an event summarization phase extracting the 
collocations related to the seed collocations found in a 
specific time duration. 
The most important part in the preprocessing phase is 
collocation extraction. We retrieve the collocations from 
the sentences in blog posts. The candidates are two terms 
within a window size. Due to the size of candidates, we 
have to identify the set of tracking terms for further 
analysis. In this paper, those candidates containing 
stopwords or with low change of temporal mutual 
information are removed. 
In the event detection phase, we detect events by 
using the peak of temporal mutual information in time 
dimension.  However, the regular pattern of temporal 
mutual information may cause problems to our detection. 
Therefore, we remove the regular pattern by seasonal 
index, and then detect the plausible events by measuring 
the unusual peak of temporal mutual information. 
If a topic is suddenly discussed, the relationship 
between the related terms will become higher. Two 
alternatives including change of temporal mutual 
information and relative change of temporal mutual 
information are employed to detect unusual events. Given 
timestamps t1 and t2 with temporal mutual information 
MI1 and MI2, the change of temporal mutual information 
is calculated by (MI2-MI1). The relative change of 
temporal mutual information is calculated by (MI2-
MI1)/MI1. 
For each plausible event, there is a seed collocation, 
e.g., ?Typhoon Chanchu?. In the event description 
retrieval phase, we try to select the collocations with the 
highest mutual information with the word w in a seed 
collocation. They will form a collocation network for the 
event.  Initially, the seed collocation is placed into the 
network.  When a new collocation is added, we compute 
the mutual information of the multiword collocations by 
the following formula, where n is the number of 
collocations in the network up to now. 
?= n iMInInformatioMutualMultiwo  
If the multiword mutual information is lower than a 
threshold, the algorithm stops and returns the words in the 
collocation network as a description of the event.  Figure 
2 sketches an example.  The collocations ?Chanchu?s 
path?, ?Typhoon eye?, and ?Chanchu affects? are added 
into the network in sequence based on their MI. 
We have two alternatives to add the collocations to 
the event description. The first method adds the 
collocations which have the highest mutual information 
as discussed above. In contrast, the second method adds 
the collocations which have the highest product of mutual 
information and change of temporal mutual information. 
 
 
 
 
 
 
Figure 2: An Example of Collocation network 
4. 
4.1. 
Experiments and Discussions 
Temporal Mutual Information versus 
Mutual Information 
In the experiments, we adopt the ICWSM weblog data 
set (Teng & Chen, 2007; ICWSM, 2007). This data set 
collected from May 1, 2006 through May 20, 2006 is 
about 20 GB. Without loss of generality, we use the 
English weblog of 2,734,518 articles for analysis. 
To evaluate the effectiveness of time information, we 
made the experiments based on mutual information 
(Definition 1) and temporal mutual information 
(Definition 2). The former called the incremental 
approach measures the mutual information at each time 
point based on all available temporal information at that 
time. The latter called the interval-based approach 
considers the temporal mutual information in different 
time stamps.  Figures 3 and 4 show the comparisons 
between interval-based approach and incremental 
approach, respectively, in the event of Da Vinci Code.   
We find that ?Tom Hanks? has higher change of 
temporal mutual information compared to ?Da Vinci 
Code?. Compared to the incremental approach in Figure 4, 
the interval-based approach can reflect the exact release 
date of ?Da Vinci Code.? 
 rd
=i 1 4.2. Evaluation of Event Detection 
We consider the events of May 2006 listed in 
wikipedia1 as gold standard. On the one hand, the events 
posted in wikipedia are not always complete, so that we 
adopt recall rate as our evaluation metric.  On the other 
hand, the events specified in wikipedia are not always 
discussed in weblogs.  Thus, we search the contents of 
blog post to verify if the events were touched on in our 
blog corpus. Before evaluation, we remove the events 
listed in wikipedia, but not referenced in the weblogs. 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Interval-based Approach in Da Vinci Code  
 
 
 
 
 
 
 
 
Figure 4: Incremental Approach in Da Vinci Code 
gure 5 sketches the idea of evaluation.  The left side 
of t s figure shows the collocations detected by our event 
dete tion system, and the right side shows the events 
liste  in wikipedia.  After matching these two lists, we 
can find that the first three listed events were correctly 
identified by our system.  Only the event ?Nepal Civil 
War? was listed, but not found. Thus, the recall rate is 
75% in this case. 
 
 
 
 
 
 
 
Figure 5: Evaluation of Event Detection Phase 
As discussed in Section 3, we adopt change of 
temporal mutual information, and relative change of 
temporal mutual information to detect the peak. In Figure 
6, we compare the two methods to detect the events in 
weblogs. The relative change of temporal mutual 
information achieves better performance than the change 
of temporal mutual information. 
                                                     
1 http://en.wikipedia.org/wiki/May_2006 
Table 1 and Table 2 list the top 20 collocations based 
on these two approaches, respectively. The results of the 
first approach show that some collocations are related to 
the feelings such as ?fell left? and time such as ?Saturday 
night?. In contrast, the results of the second approach 
show more interesting collocations related to the news 
events at that time, such as terrorists ?zacarias 
moussaoui? and ?paramod mahajan.? These two persons 
were killed in May 3. Besides, ?Geena Davis? got the 
golden award in May 3. That explains why the 
collocations detected by relative change of temporal 
mutual information are better than those detected by 
change of temporal mutual information. 
-20
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6: Performance of Event Detection Phase 
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
Collocations CMI Collocations CMI 
May 03 9276.08 Current music 1842.67
Illegal immigrants 5833.17 Hate studying 1722.32
Feel left 5411.57 Stephen Colbert 1709.59
Saturday night 4155.29 Thursday night 1678.78
Past weekend 2405.32 Can?t believe 1533.33
White house 2208.89 Feel asleep 1428.18
Red sox 2208.43 Ice cream 1373.23
Album tool 2120.30 Oh god 1369.52
Sunday morning 2006.78 Illegalimmigration 1368.12
16.56
f 
CMI
32.50
31.63
29.09
28.45
28.34
28.13Sunday night 1992.37 Pretty cool 13
Table 1: Top 20 collocations with highest change o
temporal mutual information 
Collocations CMI Collocations 
casinos online 618.36 Diet sodas 
zacarias moussaoui 154.68 Ving rhames 
Tsunami warning 107.93 Stock picks 
Conspirator zacarias 71.62 Happy hump 
Artist formerly 57.04 Wong kan 
Federal  
Jury 
41.78 Sixapartcom 
movabletype Wed 3 39.20 Aaron echolls 27.48
Pramod mahajan 35.41 Phnom penh 25.78
BBC  
Version 
35.21 Livejournal 
sixapartcom 
23.83  Fi
hi
c
dGeena davis 33.64 George yeo 20.34
Table 2: Top 20 collocations with highest relative change 
of mutual information 
4.3. Evaluation of Event Summarization 
As discussed in Section 3, we have two methods to 
include collocations to the event description. Method 1 
employs the highest mutual information, and Method 2 
utilizes the highest product of mutual information and 
change of temporal mutual information. Figure 7 shows 
the performance of Method 1 and Method 2. We can see 
that the performance of Method 2 is better than that of 
Method 1 in most cases. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Overall Performance of Event Summarization 
The results of event summarization by Method 2 are 
shown in Figure 8. Typhoon Chanchu appeared in the 
Pacific Ocean on May 10, 2006, passed through 
Philippine and China and resulted in disasters in these 
areas on May 13 and 18, 2006.  The appearance of the 
typhoon Chanchu cannot be found from the events listed 
in wikipedia on May 10.  However, we can identify the 
appearance of typhoon Chanchu from the description of 
the typhoon appearance such as ?typhoon named? and 
?Typhoon eye.  In addition, the typhoon Chanchu?s path 
can also be inferred from the retrieved collocations such 
as ?Philippine China? and ?near China?. The response of 
bloggers such as ?unexpected typhoon? and ?8 typhoons? 
is also extracted.   
 
 
 
 
 
 
 
 
 
 
Figure 8: Event Summarization for Typhoon Chanchu 
5. Concluding Remarks 
This paper introduces temporal mutual information to 
capture term-term association over time in weblogs. The 
extracted collocation with unusual peak which is in terms 
of relative change of temporal mutual information is 
selected to represent an event.  We collect those 
collocations with the highest product of mutual 
information and change of temporal mutual information 
to summarize the specific event.  The experiments on 
ICWSM weblog data set and evaluation with wikipedia 
event lists at the same period as weblogs demonstrate the 
feasibility of the proposed temporal collocation model 
and event detection algorithms. 
Currently, we do not consider user groups and 
locations. This methodology will be extended to model 
the collocations over time and location, and the 
relationship between the user-preferred usage of 
collocations and the profile of users. 
Acknowledgments 
Research of this paper was partially supported by 
National Science Council, Taiwan (NSC96-2628-E-002-
240-MY3) and Excellent Research Projects of National 
Taiwan University (96R0062-AE00-02). 
References 
Adamic, L.A., Glance, N. (2005). The Political 
Blogosphere and the 2004 U.S. Election: Divided 
They Blog. In: Proceedings of the 3rd International 
Workshop on Link Discovery, pp. 36--43. 
Burger, J.D., Henderson J.C. (2006). An Exploration of 
Observable Features Related to Blogger Age. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
15--20. 
Doran, C., Griffith, J., Henderson, J. (2006). Highlights 
from 12 Months of Blogs. In: Proceedings of AAAI 
2006 Spring Symposium on Computational 
Approaches to Analysing Weblogs, pp. 30--33. 
Glance, N., Hurst, M., Tornkiyo, T. (2004). Blogpulse: 
Automated Trend Discovery for Weblogs. In: 
Proceedings of WWW 2004 Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Hurst, M. (2006). 24 Hours in the Blogosphere. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
73--77. 
ICWSM (2007). http://www.icwsm.org/data.html 
Kim, J.H. (2005). Blog as an Oppositional Medium? A 
Semantic Network Analysis on the Iraq War Blogs. In: 
Internet Research 6.0: Internet Generations. 
 
Manning, C.D., Sch?tze, H. (1999). Foundations of 
Statistical Natural Language Processing, The MIT 
Press, London England. 
Mei, Q., Liu, C., Su, H., Zhai, C. (2006). A Probabilistic 
Approach to Spatiotemporal Theme Pattern Mining on 
Weblogs. In: Proceedings of the 15th International 
Conference on World Wide Web, Edinburgh, Scotland, 
pp. 533--542. 
Oka, M., Abe, H., Kato, K. (2006). Extracting Topics 
from Weblogs Through Frequency Segments. In: 
Proceedings of WWW 2006 Annual Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Teng, C.Y., Chen, H.H. (2006). Detection of Bloggers? 
Interest: Using Textual, Temporal, and Interactive 
Features. In: Proceeding of IEEE/WIC/ACM 
International Conference on Web Intelligence, pp. 
366--369. 
Teng, C.Y., Chen, H.H. (2007). Analyzing Temporal 
Collocations in Weblogs. In: Proceeding of 
International Conference on Weblogs and Social 
Media, 303--304. 
Thelwall, M. (2006). Blogs During the London Attacks: 
Top Information Sources and Topics. In: Proceedings 
of 3rd Annual Workshop on the Weblogging 
Ecosystem: Aggregation, Analysis and Dynamics. 
Thompson, G. (2003). Weblogs, Warblogs, the Public 
Sphere, and Bubbles. Transformations, 7(2). 
Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 1?8
Manchester, August 2008
TuLiPA: Towards a Multi-Formalism Parsing Environment for
Grammar Engineering
Laura Kallmeyer
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
lk@sfs.uni-tuebingen.de
Yannick Parmentier
CNRS - LORIA
Nancy Universite?
F-54506, Vand?uvre, France
parmenti@loria.fr
Timm Lichte
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
timm.lichte@uni-tuebingen.de
Johannes Dellert
SFB 441 - SfS
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
{jdellert,kevang}@sfs.uni-tuebingen.de
Wolfgang Maier
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
wo.maier@uni-tuebingen.de
Kilian Evang
SFB 441 - SfS
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
Abstract
In this paper, we present an open-source
parsing environment (Tu?bingen Linguistic
Parsing Architecture, TuLiPA) which uses
Range Concatenation Grammar (RCG)
as a pivot formalism, thus opening the
way to the parsing of several mildly
context-sensitive formalisms. This en-
vironment currently supports tree-based
grammars (namely Tree-Adjoining Gram-
mars (TAG) and Multi-Component Tree-
Adjoining Grammars with Tree Tuples
(TT-MCTAG)) and allows computation not
only of syntactic structures, but also of the
corresponding semantic representations. It
is used for the development of a tree-based
grammar for German.
1 Introduction
Grammars and lexicons represent important lin-
guistic resources for many NLP applications,
among which one may cite dialog systems, auto-
matic summarization or machine translation. De-
veloping such resources is known to be a complex
task that needs useful tools such as parsers and
generators (Erbach, 1992).
Furthermore, there is a lack of a common frame-
work allowing for multi-formalism grammar engi-
neering. Thus, many formalisms have been pro-
posed to model natural language, each coming
with specific implementations. Having a com-
mon framework would facilitate the comparison
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
between formalisms (e.g., in terms of parsing com-
plexity in practice), and would allow for a better
sharing of resources (e.g., having a common lex-
icon, from which different features would be ex-
tracted depending on the target formalism).
In this context, we present a parsing environ-
ment relying on a general architecture that can
be used for parsing with mildly context-sensitive
(MCS) formalisms1 (Joshi, 1987). Its underly-
ing idea is to use Range Concatenation Grammar
(RCG) as a pivot formalism, for RCG has been
shown to strictly include MCS languages while be-
ing parsable in polynomial time (Boullier, 2000).
Currently, this architecture supports tree-based
grammars (Tree-Adjoining Grammars and Multi-
Component Tree-Adjoining Grammars with Tree
Tuples (Lichte, 2007)). More precisely, tree-
based grammars are first converted into equivalent
RCGs, which are then used for parsing. The result
of RCG parsing is finally interpreted to extract a
derivation structure for the input grammar, as well
as to perform additional processings (e.g., seman-
tic calculus, extraction of dependency views).
The paper is structured as follows. In section 2,
we present the architecture of the TuLiPA parsing
environment and show how the use of RCG as a
pivot formalism makes it easier to design a modu-
lar system that can be extended to support several
dimensions (syntax, semantics) and/or formalisms.
In section 3, we give some desiderata for gram-
mar engineering and present TuLiPA?s current state
1A formalism is said to be mildly context sensitive (MCS)
iff (i) it generates limited cross-serial dependencies, (ii) it is
polynomially parsable, and (iii) the string languages gener-
ated by the formalism have the constant growth property (e.g.,
{a
2
n
|n ? 0} does not have this property). Examples of MCS
formalisms include Tree-Adjoining Grammars, Combinatory
Categorial Grammars and Linear Indexed Grammars.
1
with respect to these. In section 4, we compare
this system with existing approaches for parsing
and more generally for grammar engineering. Fi-
nally, in section 5, we conclude by presenting fu-
ture work.
2 Range Concatenation Grammar as a
pivot formalism
The main idea underlying TuLiPA is to use RCG
as a pivot formalism for RCG has appealing for-
mal properties (e.g., a generative capacity lying be-
yond Linear Context Free Rewriting Systems and
a polynomial parsing complexity) and there ex-
ist efficient algorithms, for RCG parsing (Boullier,
2000) and for grammar transformation into RCG
(Boullier, 1998; Boullier, 1999).
Parsing with TuLiPA is thus a 3-step process:
1. The input tree-based grammar is converted
into an RCG (using the algorithm of
Kallmeyer and Parmentier (2008) when deal-
ing with TT-MCTAG).
2. The resulting RCG is used for parsing the in-
put string using an extension of the parsing
algorithm of Boullier (2000).
3. The RCG derivation structure is interpreted to
extract the derivation and derived trees with
respect to the input grammar.
The use of RCG as a pivot formalism, and thus
of an RCG parser as a core component of the sys-
tem, leads to a modular architecture. In turns, this
makes TuLiPA more easily extensible, either in
terms of functionalities, or in terms of formalisms.
2.1 Adding functionalities to the parsing
environment
As an illustration of TuLiPA?s extensibility, one
may consider two extensions applied to the system
recently.
First, a semantic calculus using the syn-
tax/semantics interface for TAG proposed by Gar-
dent and Kallmeyer (2003) has been added. This
interface associates each tree with flat semantic
formulas. The arguments of these formulas are
unification variables, which are co-indexed with
features labelling the nodes of the syntactic tree.
During classical TAG derivation, trees are com-
bined, triggering unifications of the feature struc-
tures labelling nodes. As a result of these unifica-
tions, the arguments of the semantic formulas are
unified (see Fig. 1).
S
NP?x VP
NP
j
V NP?y NP
m
John loves Mary
name(j,john) love(x,y) name(m,mary)
; love(j,m),name(j,john),name(m,mary)
Figure 1: Semantic calculus in Feature-Based
TAG.
In our system, the semantic support has been in-
tegrated by (i) extending the internal tree objects to
include semantic formulas (the RCG-conversion is
kept unchanged), and (ii) extending the construc-
tion of the derived tree (step 3) so that during the
interpretation of the RCG derivation in terms of
tree combinations, the semantic formulas are car-
ried and updated with respect to the feature unifi-
cations performed.
Secondly, let us consider lexical disambigua-
tion. Because of the high redundancy lying within
lexicalized formalisms such as lexicalized TAG,
it is common to consider tree schemata having a
frontier node marked for anchoring (i.e., lexical-
ization). At parsing time, the tree schemata are
anchored according to the input string. This an-
choring selects a subgrammar supposed to cover
the input string. Unfortunately, this subgrammar
may contain many trees that either do not lead to
a parse or for which we know a priori that they
cannot be combined within the same derivation
(so we should not predict a derivation from one
of these trees to another during parsing). As a re-
sult, the parser could have poor performance be-
cause of the many derivation paths that have to
be explored. Bonfante et al (2004) proposed to
polarize the structures of the grammar, and to ap-
ply an automaton-based filtering of the compatible
structures. The idea is the following. One compute
polarities representing the needs/resources brought
by a given tree (or tree tuple for TT-MCTAG).
A substitution or foot node with category NP re-
flects a need for an NP (written NP-). In the same
way, an NP root node reflects a resource of type
NP (written NP+). Then you build an automaton
whose edges correspond to trees, and states to po-
larities brought by trees along the path. The au-
tomaton is then traversed to extract all paths lead-
ing to a final state with a neutral polarity for each
category and +1 for the axiom (see Fig. 2, the state
2
7 is the only valid state and {proper., trans., det.,
noun.} the only compatible set of trees).
0
John
1 1
eats
2 2
a
3 3
cake
4
0 1
NP+
2
S+
3
S+ NP-
4
S+
5
S+ NP-
6
S+ NP+
7
S+
proper.
intrans.
trans.
det.
det.
noun.
noun.
Figure 2: Polarity-based lexical disambiguation.
In our context, this polarity filtering has been
added before step 1, leaving untouched the core
RCG conversion and parsing steps. The idea is
to compute the sets of compatible trees (or tree
tuples for TT-MCTAG) and to convert these sets
separately. Indeed the RCG has to encode only
valid adjunctions/substitutions. Thanks to this
automaton-based ?clustering? of the compatible
tree (or tree tuples), we avoid predicting incompat-
ible derivations. Note that the time saved by using
a polarity-based filter is not negligible, especially
when parsing long sentences.2
2.2 Adding formalisms to the parsing
environment
Of course, the two extensions introduced in the
previous section may have been added to other
modular architectures as well. The main gain
brought by RCG is the possibility to parse not
only tree-based grammars, but other formalisms
provided they can be encoded into RCG. In our
system, only TAG and TT-MCTAG have been
considered so far. Nonetheless, Boullier (1998)
and S?gaard (2007) have defined transformations
into RCG for other mildly context-sensitive for-
malisms.3
To sum up, the idea would be to keep the core
RCG parser, and to extend TuLiPA with a specific
conversion module for each targeted formalism.
On top of these conversion modules, one should
also provide interpretation modules allowing to de-
code the RCG derivation forest in terms of the in-
put formalism (see Fig. 3).
2An evaluation of the gain brought by this technique when
using Interaction Grammar is given by Bonfante et al (2004).
3These include Multi-Component Tree-Adjoining Gram-
mar, Linear Indexed Grammar, Head Grammar, Coupled
Context Free Grammar, Right Linear Unification Grammar
and Synchronous Unification Grammar.
Figure 3: Towards a multi-formalism parsing envi-
ronment.
An important point remains to be discussed. It
concerns the role of lexicalization with respect to
the formalism used. Indeed, the tree-based gram-
mar formalisms currently supported (TAG and TT-
MCTAG) both share the same lexicalization pro-
cess (i.e., tree anchoring). Thus the lexicon format
is common to these formalisms. As we will see
below, it corresponds to a 2-layer lexicon made of
inflected forms and lemma respectively, the latter
selecting specific grammatical structures. When
parsing other formalisms, it is still unclear whether
one can use the same lexicon format, and if not
what kind of general lexicon management module
should be added to the parser (in particular to deal
with morphology).
3 Towards a complete grammar
engineering environment
So far, we have seen how to use a generic parsing
architecture relying on RCG to parse different for-
malisms. In this section, we adopt a broader view
and enumerate some requirements for a linguistic
resource development environment. We also see
to what extent these requirements are fulfilled (or
partially fulfilled) within the TuLiPA system.
3.1 Grammar engineering with TuLiPA
As advocated by Erbach (1992), grammar en-
gineering needs ?tools for testing the grammar
with respect to consistency, coverage, overgener-
ation and accuracy?. These characteristics may
be taken into account by different interacting soft-
ware. Thus, consistency can be checked by a semi-
automatic grammar production device, such as the
XMG system of Duchier et al (2004). Overgen-
eration is mainly checked by a generator (or by
a parser with adequate test suites), and coverage
and accuracy by a parser. In our case, the TuLiPA
system provides an entry point for using a gram-
mar production system (and a lexicon conversion
3
tool introduced below), while including a parser.
Note that TuLiPA does not include any generator,
nonetheless it uses the same lexicon format as the
GenI surface realizer for TAG4.
TuLiPA?s input grammar is designed using
XMG, which is a metagrammar compiler for tree-
based formalisms. In other terms, the linguist de-
fines a factorized description of the grammar (the
so-called metagrammar) in the XMG language.
Briefly, an XMG metagrammar consists of (i) ele-
mentary tree fragments represented as tree descrip-
tion logic formulas, and (ii) conjunctive and dis-
junctive combinations of these tree fragments to
describe actual TAG tree schemata.5 This meta-
grammar is then compiled by the XMG system to
produce a tree grammar in an XML format. Note
that the resulting grammar contains tree schemata
(i.e., unlexicalized trees). To lexicalize these, the
linguist defines a lexicon mapping words with cor-
responding sets of trees. Following XTAG (2001),
this lexicon is a 2-layer lexicon made of morpho-
logical and lemma specifications. The motivation
of this 2-layer format is (i) to express linguistic
generalizations at the lexicon level, and (ii) to al-
low the parser to only select a subgrammar accord-
ing to a given sentence, thus reducing parsing com-
plexity. TuLiPA comes with a lexicon conversion
tool (namely lexConverter) allowing to write a lex-
icon in a user-friendly text format and to convert it
into XML. An example of an entry of such a lexi-
con is given in Fig. 4.
The morphological specification consists of a
word, the corresponding lemma and morphologi-
cal features. The main pieces of information con-
tained in the lemma specification are the ?ENTRY
field, which refers to the lemma, the ?CAT field
referring to the syntactic category of the anchor
node, the ?SEM field containing some semantic in-
formation allowing for semantic instantiation, the
?FAM field, which contains the name of the tree
family to be anchored, the ?FILTERS field which
consists of a feature structure constraining by uni-
fication the trees of a given family that can be
anchored by the given lemma (used for instance
for non-passivable verbs), the ?EQUATIONS field
allowing for the definition of equations targeting
named nodes of the trees, and the ?COANCHORS
field, which allows for the specification of co-
anchors (such as by in the verb to come by).
4http://trac.loria.fr/?geni
5See (Crabbe?, 2005) for a presentation on how to use the
XMG formalism for describing a core TAG for French.
Morphological specification:
vergisst vergessen [pos=v,num=sg,per=3]
Lemma specification:
?ENTRY: vergessen
?CAT: v
?SEM: BinaryRel[pred=vergessen]
?ACC: 1
?FAM: Vnp2
?FILTERS: []
?EX:
?EQUATIONS:
NParg1 ? cas = nom
NParg2 ? cas = acc
?COANCHORS:
Figure 4: Morphological and lemma specification
of vergisst.
From these XML resources, TuLiPA parses a
string, corresponding either to a sentence or a con-
stituent (noun phrase, prepositional phrase, etc.),
and computes several output pieces of informa-
tion, namely (for TAG and TT-MCTAG): deriva-
tion/derived trees, semantic representations (com-
puted from underspecified representations using
the utool software6, or dependency views of the
derivation trees (using the DTool software7).
3.2 Grammar debugging
The engineering process introduced in the preced-
ing section belongs to a development cycle, where
one first designs a grammar and corresponding
lexicons using XMG, then checks these with the
parser, fixes them, parses again, and so on.
To facilitate grammar debugging, TuLiPA in-
cludes both a verbose and a robust mode allow-
ing respectively to (i) produce a log of the RCG-
conversion, RCG-parsing and RCG-derivation in-
terpretation, and (ii) display mismatching features
leading to incomplete derivations. More precisely,
in robust mode, the parser displays derivations step
by step, highlighting feature unification failures.
TuLiPA?s options can be activated via an intu-
itive Graphical User Interface (see Fig. 5).
6See http://www.coli.uni-saarland.de/
projects/chorus/utool/, with courtesy of Alexander
Koller.
7With courtesy of Marco Kuhlmann.
4
Figure 5: TuLiPA?s Graphical User Interface.
3.3 Towards a functional common interface
Unfortunately, as mentioned above, the linguist
has to move back-and-forth from the gram-
mar/lexicon descriptions to the parser, i.e., each
time the parser reports grammar errors, the linguist
fixes these and then recomputes the XML files and
then parses again. To avoid this tedious task of re-
sources re-compilation, we started developing an
Eclipse8 plug-in for the TuLiPA system. Thus, the
linguist will be able to manage all these resources,
and to call the parser, the metagrammar compiler,
and the lexConverter from a common interface (see
Fig. 6).
Figure 6: TuLiPA?s eclipse plug-in.
The motivation for this plug-in comes from
the observation that designing electronic gram-
mars is a task comparable to designing source
8See http://www.eclipse.org
code. A powerful grammar engineering environ-
ment should thus come with development facili-
ties such as precise debugging information, syntax
highlighting, etc. Using the Eclipse open-source
development platform allows for reusing several
components inherited from the software develop-
ment community, such as plug-ins for version con-
trol, editors coupled with explorers, etc.
Eventually, one point worth considering in the
context of grammar development concerns data en-
coding. To our knowledge, only few environments
provide support for UTF-8 encoding, thus guaran-
tying the coverage of a wide set of charsets and
languages. In TuLiPA, we added an UTF-8 sup-
port (in the lexConverter), thus allowing to design
a TAG for Korean (work in progress).
3.4 Usability of the TuLiPA system
As mentioned above, the TuLiPA system is made
of several interacting components, that one cur-
rently has to install separately. Nonetheless, much
attention has been paid to make this installation
process as easy as possible and compatible with
all major platforms.9
XMG and lexConverter can be installed by com-
piling their sources (using a make command).
TuLiPA is developed in Java and released as an ex-
ecutable jar. No compilation is needed for it, the
only requirement is the Gecode/GecodeJ library10
(available as a binary package for many platforms).
Finally, the TuLiPA eclipse plug-in can be installed
easily from eclipse itself. All these tools are re-
leased under Free software licenses (either GNU
GPL or Eclipse Public License).
This environment is being used (i) at the Univer-
sity of Tu?bingen, in the context of the development
of a TT-MCTAG for German describing both syn-
tax and semantics, and (ii) at LORIA Nancy, in the
development of an XTAG-based metagrammar for
English. The German grammar, called GerTT (for
German Tree Tuples), is released under a LGPL li-
cense for Linguistic Resources11 and is presented
in (Kallmeyer et al, 2008). The test-suite cur-
rently used to check the grammar is hand-crafted.
A more systematic evaluation of the grammar is in
preparation, using the Test Suite for Natural Lan-
guage Processing (Lehmann et al, 1996).
9See http://sourcesup.cru.fr/tulipa.
10See http://www.gecode.org/gecodej.
11See http://infolingu.univ-mlv.
fr/DonneesLinguistiques/
Lexiques-Grammaires/lgpllr.html
5
4 Comparison with existing approaches
4.1 Engineering environments for tree-based
grammar formalisms
To our knowledge, there is currently no available
parsing environment for multi-component TAG.
Existing grammar engineering environments for
TAG include the DyALog system12 described in
Villemonte de la Clergerie (2005). DyALog is a
compiler for a logic programming language using
tabulation and dynamic programming techniques.
This compiler has been used to implement efficient
parsing algorithms for several formalisms, includ-
ing TAG and RCG. Unfortunately, it does not in-
clude any built-in GUI and requires a good know-
ledge of the GNU build tools to compile parsers.
This makes it relatively difficult to use. DyALog?s
main quality lies in its efficiency in terms of pars-
ing time and its capacity to handle very large re-
sources. Unlike TuLiPA, it does not compute se-
mantic representations.
The closest approach to TuLiPA corresponds to
the SemTAG system13, which extends TAG parsers
compiled with DyALog with a semantic calculus
module (Gardent and Parmentier, 2007). Unlike
TuLiPA, this system only supports TAG, and does
not provide any graphical output allowing to easily
check the result of parsing.
Note that, for grammar designers mainly inter-
ested in TAG, SemTAG and TuLiPA can be seen
as complementary tools. Indeed, one may use
TuLiPA to develop the grammar and check spe-
cific syntactic structures thanks to its intuitive pars-
ing environment. Once the grammar is stable, one
may use SemTAG in batch processing to parse
corpuses and build semantic representations using
large grammars. This combination of these 2 sys-
tems is made easier by the fact that both use the
same input formats (a metagrammar in the XMG
language and a text-based lexicon). This approach
is the one being adopted for the development of a
French TAG equipped with semantics.
For Interaction Grammar (Perrier, 2000), there
exists an engineering environment gathering the
XMG metagrammar compiler and an eLEtrOstatic
PARser (LEOPAR).14 This environment is be-
ing used to develop an Interaction Grammar for
French. TuLiPA?s lexical disambiguation module
12See http://dyalog.gforge.inria.fr
13See http://trac.loria.fr/?semconst
14See http://www.loria.fr/equipes/
calligramme/leopar/
reuses techniques introduced by LEOPAR. Unlike
TuLiPA, LEOPAR does not currently support se-
mantic information.
4.2 Engineering environments for other
grammar formalisms
For other formalisms, there exist state-of-the-art
grammar engineering environments that have been
used for many years to design large deep grammars
for several languages.
For Lexical Functional Grammar, one may cite
the Xerox Linguistic Environment (XLE).15 For
Head-driven Phrase Structure Grammar, the main
available systems are the Linguistic Knowledge
Base (LKB)16 and the TRALE system.17 For
Combinatory Categorial Grammar, one may cite
the OpenCCG library18 and the C&C parser.19
These environments have been used to develop
broad-coverage resources equipped with semantics
and include both a generator and a parser. Un-
like TuLiPA, they represent advanced projects, that
have been used for dialog and machine translation
applications. They are mainly tailored for a spe-
cific formalism.20
5 Future work
In this section, we give some prospective views
concerning engineering environments in general,
and TuLiPA in particular. We first distinguish be-
tween 2 main usages of grammar engineering en-
vironments, namely a pedagogical usage and an
application-oriented usage, and finally give some
comments about multi-formalism.
5.1 Pedagogical usage
Developing grammars in a pedagogical context
needs facilities allowing for inspection of the struc-
tures of the grammar, step-by-step parsing (or gen-
eration), along with an intuitive interface. The idea
is to abstract away from technical aspects related to
implementation (intermediate data structures, opti-
mizations, etc.).
15See http://www2.parc.com/isl/groups/
nltt/xle/
16See http://wiki.delph-in.net/moin
17See http://milca.sfs.uni-tuebingen.de/
A4/Course/trale/
18See http://openccg.sourceforge.net/
19See http://svn.ask.it.usyd.edu.au/trac/
candc/wiki
20Nonetheless, Beavers (2002) encoded a CCG in the
LKB?s Type Description Language.
6
The question whether to provide graphical or
text-based editors can be discussed. As advo-
cated by Baldridge et al (2007), a low-level text-
based specification can offer more flexibility and
bring less frustration to the grammar designer, es-
pecially when such a specification can be graph-
ically interpreted. This is the approach chosen
by XMG, where the grammar is defined via an
(advanced or not) editor such as gedit or emacs.
Within TuLiPA, we chose to go further by using
the Eclipse platform. Currently, it allows for dis-
playing a summary of the content of a metagram-
mar or lexicon on a side panel, while editing these
on a middle panel. These two panels are linked
via a jump functionality. The next steps concern
(i) the plugging of a graphical viewer to display
the (meta)grammar structures independently from
a given parse, and (ii) the extension of the eclipse
plug-in so that one can easily consistently modify
entries of the metagrammar or lexicon (especially
when these are split over several files).
5.2 Application-oriented usage
When dealing with applications, one may demand
more from the grammar engineering environment,
especially in terms of efficiency and robustness
(support for larger resources, partial parsing, etc.).
Efficiency needs optimizations in the parsing
engine making it possible to support grammars
containing several thousands of structures. One
interesting question concerns the compilation of a
grammar either off-line or on-line. In DyALog?s
approach, the grammar is compiled off-line into
a logical automaton encoding all possible deriva-
tions. This off-line compilation can take some
minutes with a TAG having 6000 trees, but the re-
sulting parser can parse sentences within a second.
In TuLiPA?s approach, the grammar is compiled
into an RCG on-line. While giving satisfactory re-
sults on reduced resources21 , it may lead to trou-
bles when scaling up. This is especially true for
TAG (the TT-MCTAG formalism is by definition a
factorized formalism compared with TAG). In the
future, it would be useful to look for a way to pre-
compile a TAG into an RCG off-line, thus saving
the conversion time.
Another important feature of grammar engineer-
ing environments consists of its debugging func-
21For a TT-MCTAG counting about 300 sets of trees and an
and-crafted lexicon made of about 300 of words, a 10-word
sentence is parsed (and a semantic representation computed)
within seconds.
tionalities. Among these, one may cite unit and
integration testing. It would be useful to extend
the TuLiPA system to provide a module for gen-
erating test-suites for a given grammar. The idea
would be to record the coverage and analyses of
a grammar at a given time. Once the grammar is
further developed, these snapshots would allow for
regression testing.
5.3 About multi-formalism
We already mentioned that TuLiPA was opening
a way towards multi-formalism by relying on an
RCG core. It is worth noticing that the XMG
system was also designed to be further extensi-
ble. Indeed, a metagrammar in XMG corresponds
to the combination of elementary structures. One
may think of designing a library of such structures,
these would be dependent on the target gram-
mar formalism. The combinations may represent
general linguistic concepts and would be shared
by different grammar implementations, following
ideas presented by Bender et al (2005).
6 Conclusion
In this paper, we have presented a multi-formalism
parsing architecture using RCG as a pivot formal-
ism to parse mildly context-sensitive formalisms
(currently TAG and TT-MCTAG). This system has
been designed to facilitate grammar development
by providing user-friendly interfaces, along with
several functionalities (e.g., dependency extrac-
tion, derivation/derived tree display and semantic
calculus). It is currently used for developing a core
grammar for German.
At the moment, we are working on the extension
of this architecture to include a fully functional
Eclipse plug-in. Other current tasks concern op-
timizations to support large scale parsing and the
extension of the syntactic and semantic coverage
of the German grammar under development.
In a near future, we plan to evaluate the parser
and the German grammar (parsing time, correction
of syntactic and semantic outputs) with respect to
a standard test-suite such as the TSNLP (Lehmann
et al, 1996).
Acknowledgments
This work has been supported by the Deutsche
Forschungsgemeinschaft (DFG) and the Deutscher
Akademischer Austausch Dienst (DAAD, grant
7
A/06/71039). We are grateful to three anonymous
reviewers for valuable comments on this work.
References
Baldridge, Jason, Sudipta Chatterjee, Alexis Palmer,
and Ben Wing. 2007. DotCCG and VisCCG: Wiki
and programming paradigms for improved grammar
engineering with OpenCCG. In King, Tracy Hol-
loway and Emily M. Bender, editors, Proceedings of
the GEAF07 workshop, pages 5?25, Stanford, CA.
CSLI.
Beavers, John. 2002. Documentation: A CCG Imple-
mentation for the LKB. LinGO Working Paper No.
2002-08, CSLI, Stanford University, Stanford, CA.
Bender, Emily, Dan Flickinger, Frederik Fouvry, and
Melanie Siegel. 2005. Shared representation in mul-
tilingual grammar engineering. Research on Lan-
guage & Computation, 3(2):131?138.
Bonfante, Guillaume, Bruno Guillaume, and Guy Per-
rier. 2004. Polarization and abstraction of grammat-
ical formalisms as methods for lexical disambigua-
tion. In Proceedings of the International Conference
on Computational Linguistics (CoLing 2004), pages
303?309, Geneva, Switzerland.
Boullier, Pierre. 1998. Proposal for a natural lan-
guage processing syntactic backbone. Rapport de
Recherche 3342, INRIA.
Boullier, Pierre. 1999. On TAG and Multicomponent
TAG Parsing. Rapport de Recherche 3668, INRIA.
Boullier, Pierre. 2000. Range concatenation gram-
mars. In Proceedings of the International Workshop
on Parsing Technologies (IWPT 2000), pages 53?64,
Trento, Italy.
Crabbe?, Benoit. 2005. Grammatical development with
XMG. In Proceedings of the conference on Logical
Aspects of Computational Linguistics 2005 (LACL
05), pages 84?100, Bordeaux, France.
Duchier, Denys, Joseph Le Roux, and Yannick Parmen-
tier. 2004. The Metagrammar Compiler: An NLP
Application with a Multi-paradigm Architecture. In
Proceedings of the 2nd International Mozart/Oz
Conference (MOZ?2004), pages 175?187, Charleroi,
Belgium.
Erbach, Gregor. 1992. Tools for grammar engineer-
ing. In 3rd Conference on Applied Natural Lan-
guage Processing, pages 243?244, Trento, Italy.
Gardent, Claire and Laura Kallmeyer. 2003. Semantic
Construction in FTAG. In Proceedings of the Con-
ference of the European chapter of the Association
for Computational Linguistics (EACL 2003), pages
123?130, Budapest, Hungary.
Gardent, Claire and Yannick Parmentier. 2007. Sem-
tag: a platform for specifying tree adjoining gram-
mars and performing tag-based semantic construc-
tion. In Proceedings of the International Confer-
ence of the Association for Computational Linguis-
tics (ACL 2007), Companion Volume Proceedings of
the Demo and Poster Sessions, pages 13?16, Prague,
Czech Republic.
Joshi, Aravind K. 1987. An introduction to Tree Ad-
joining Grammars. In Manaster-Ramer, A., editor,
Mathematics of Language, pages 87?114. John Ben-
jamins, Amsterdam.
Kallmeyer, Laura and Yannick Parmentier. 2008. On
the relation between Multicomponent Tree Adjoin-
ing Grammars with Tree Tuples (TT-MCTAG) and
Range Concatenation Grammars (RCG). In Pro-
ceedings of the 2nd International Conference on
Language and Automata Theories and Applications
(LATA 2008), pages 277?288, Tarragona, Spain.
Kallmeyer, Laura, Timm Lichte, Wolfgang Maier, Yan-
nick Parmentier, and Johannes Dellert. 2008. De-
velopping an MCTAG for German with an RCG-
based Parser. In Proceedings of the Language, Re-
source and Evaluation Conference (LREC 2008),
Marrakech, Morocco.
Lehmann, Sabine, Stephan Oepen, Sylvie Regnier-
Prost, Klaus Netter, Veronika Lux, Judith Klein,
Kirsten Falkedal, Frederik Fouvry, Dominique Esti-
val, Eva Dauphin, Herve? Compagnion, Judith Baur,
Lorna Balkan, and Doug Arnold. 1996. TSNLP ?
Test Suites for Natural Language Processing. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (Coling 1996), volume 2, pages
711?716, Copenhagen, Denmark.
Lichte, Timm. 2007. An MCTAG with tuples for co-
herent constructions in German. In Proceedings of
the 12th Conference on Formal Grammar, Dublin,
Ireland.
Perrier, Guy. 2000. Interaction grammars. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (CoLing 2000), pages 600?606,
Saarbruecken, Germany.
S?gaard, Anders. 2007. Complexity, expressivity and
logic of linguistic theories. Ph.D. thesis, University
of Copenhagen, Copenhagen, Denmark.
Villemonte de la Clergerie, ?Eric. 2005. DyALog: a
tabular logic programming based environment for
NLP. In Proceedings of the workshop on Constraint
Satisfaction for Language Processing (CSLP 2005),
pages 18?33, Barcelona, Spain.
XTAG-Research-Group. 2001. A lexicalized tree
adjoining grammar for english. Technical Re-
port IRCS-01-03, IRCS, University of Pennsylva-
nia. Available at http://www.cis.upenn.
edu/?xtag/gramrelease.html.
8
