Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 10?18,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
IBM?s Belief Tracker: Results On Dialog State Tracking Challenge
Datasets
Rudolf Kadlec, Jind
?
rich Libovick?y, Jan Macek, and Jan Kleindienst
IBM Czech Republic
V Parku 4, Prague 4
Czech Republic
{rudolf kadlec, jindrich libovicky, jmacek2, jankle}@cz.ibm.com
Abstract
Accurate dialog state tracking is crucial
for the design of an efficient spoken dialog
system. Until recently, quantitative com-
parison of different state tracking meth-
ods was difficult. However the 2013 Dia-
log State Tracking Challenge (DSTC) in-
troduced a common dataset and metrics
that allow to evaluate the performance of
trackers on a standardized task. In this pa-
per we present our belief tracker based on
the Hidden Information State (HIS) model
with an adjusted user model component.
Further, we report the results of our tracker
on test3 dataset from DSTC. Our tracker
is competitive with trackers submitted to
DSTC, even without training it achieves
the best results in L2 metrics and it per-
forms between second and third place in
accuracy. After adjusting the tracker using
the provided data it outperformed the other
submissions also in accuracy and yet im-
proved in L2. Additionally we present pre-
liminary results on another two datasets,
test1 and test2, used in the DSTC. Strong
performance in L2 metric means that our
tracker produces well calibrated hypothe-
ses probabilities.
1 Introduction
Spoken dialog systems need to keep a represen-
tation of the dialog state and the user goal to
follow an efficient interaction path. The perfor-
mance of state-of-the-art speech recognition sys-
tems varies widely with domain and environment
with word accuracy rates ranging from less than
70% to 98%, which often leads to misinterpreta-
tion of the user?s intention. Dialog state tracking
methods need to cope with such error-prone auto-
matic speech recognition (ASR) and spoken lan-
guage understanding (SLU) outputs. Traditional
dialog systems use hand-crafted rules to select
from the SLU outputs based on their confidence
scores. Recently, several data-driven approaches
to dialog state tracking were developed as a part
of end-to-end spoken dialog systems. However,
specifics of these systems render comparison of
dialog state tracking methods difficult.
The Dialog State Tracking Challenge (DSTC)
(Williams et al., 2013) provides a shared testbed
with datasets and tools for evaluation of dialog
state tracking methods. It abstracts from subsys-
tems of end-to-end spoken dialog systems focus-
ing only on the dialog state estimation and track-
ing. It does so by providing datasets of ASR and
SLU outputs with reference transcriptions together
with annotation on the level of dialog acts.
In this paper we report initial encouraging re-
sults of our generative belief state tracker. We plan
to investigate discriminative approaches in the fu-
ture.
The rest of the paper continues as follows. In
the next section we formally introduce the dia-
log tracking task together with datasets used in
the DSTC. Then in Section 3 we discuss related
work. Section 4 describes the belief update equa-
tions of our tracker. After that we introduce the
design of our whole tracking system, especially
how we trained the system in a supervised setting
on the train dataset and in an unsupervised setting
on the test dataset. In Section 6 we show results
of our trackers, compare them to other DSTC par-
ticipants, and discuss the results in the context of
design choices and task characteristics.
2 DSTC Problem Definition, Datasets
and Metrics
The task of the DSTC can be formally defined
as computing P(g
t
|u
0:t
, a
0:t
). That is, for each
time step t of the dialog compute the proba-
bility distribution over the user?s hidden goal g
given a sequence of SLU hypotheses from the
10
Dataset System # Annotated
train1a A 1013 yes
train1b A 1117 no
train1c A 9502 no
train2 A 643 yes
train3 B 688 yes
test1 A 715 for eval. only
test2 A 750 for eval. only
test3 B 1020 for eval. only
test4 C 438 for eval. only
Table 1: Datasets description. The System col-
umn shows what dialog system was used to col-
lect the dataset. The # column shows the number
of dialogs in the dataset. The last column informs
whether the ground truth annotation was provided
with the dataset.
System Dial. model SLU scores
A open ?? inf, 0?
B fixed ?0, 1?
C open ?0, 1?
Table 2: Main features of the dialog managers
used to collect the datasets. System A and C use
open dialog structure where the user can respond
with any combination of slots on any machine
question. System B uses a fixed dialog structure
where the user can respond only with the concept
the system expects.
beginning of the dialog up to the time t de-
noted as u
0:t
and a sequence of machine ac-
tions a
0:t
. It is assumed that the goal is fixed
through the dialog, unless the user is informed
that the requested goal does not exist. In DSTC
the user?s goal consist of nine slots: route,
from.desc, from.neighborhood, from.monument,
to.desc, to.neighborhood, to.monument, date,
time.
The dialog datasets in the DSTC are partitioned
into five training sets and four test sets. Details
and differences of the datasets are summarized in
Table 1 and 2. The datasets come from dialog sys-
tems deployed by three teams denoted as A, B and
C. All the training datasets were transcribed but
only three of them were annotated on the level of
dialog acts. The SLU confidence scores from sys-
tem B are relatively well calibrated, meaning that
confidences can be directly interpreted as proba-
bilities of observing the SLU hypothesis. Confi-
dence scores from the system A are not well cali-
brated as noted by several DSTC participants (Lee
and Eskenazi, 2013; Kim et al., 2013).
The evaluation protocol is briefly described in
Section 6. Its detailed description can be found in
(Williams et al., 2012), its evaluation in (Williams
et al., 2013).
In 2013, nine teams with 27 trackers partici-
pated in the challenge. The results of the best
trackers will be discussed together with the results
of our tracker later in Section 6.
3 Related Work
This section shortly reviews current approaches to
dialog state tracking. We divide the trackers into
two broad families of generative and discrimina-
tive methods.
3.1 Generative Methods
The HIS model (Young et al., 2010) introduces an
approximative method of solving the belief track-
ing as an inference in a dynamic Bayesian network
with SLU hypotheses and machine actions as ob-
served variables and the estimate of the user?s goal
as a hidden variable. The HIS model was im-
plemented several times (Williams, 2010; Ga?si?c,
2011). Recent criticism of generative methods for
belief tracking brought more attention to the dis-
criminative methods (Williams, 2012b).
In the DSTC only few generative system partic-
ipated. Kim et al. (2013) implemented the HIS
model with additional discriminative rescoring,
Wang and Lemon (2013) introduced a very simple
model based on hand-crafted rules. Both of them
scored between the second and the fourth place in
the challenge.
3.2 Discriminative Methods
As was previously mentioned, the discriminative
methods received more attention recently.
The overall winner of the DSTC (Lee and Es-
kenazi, 2013) used a maximum entropy model,
which they claim to be outperformed by bringing
more structure to the model by using the Condi-
tional Random Fields (Lee, 2013). The same type
of model is used also by Ren et al. (2013). Usage
of Deep Neural Networks was tested by Hender-
son et al. (2013).
?
Zilka et al. (2013) compare a discriminative
maximum entropy model and a generative method
based on approximate inference in a Bayesian net-
11
work, with the discriminative model preforming
better.
4 Model
Our model is an implementation of the HIS
model (Young et al., 2010). In HIS the belief state
is viewed as a probability distribution over all pos-
sible user?s goals. The belief state is represented
by a set of so-called partitions, which are sets of
user?s goals that are indistinguishable based on ac-
tions the system observes. It means the probability
mass assigned to a partition spreads to the user?s
goals in the partition proportionally to their?s prior
probabilities. The belief update is performed in
two steps.
Belief refinement ensures that for each user ac-
tion on the SLU n-best list and each partition all
goals in the partition are either consistent with the
user action or not. This step does not change the
belief state, it only enables the actual belief update
to be computed using the update equation (Eq. 1).
The partitions are organized in a tree structure
for which it holds that a child and a parent partition
are identical in some slots and complementary in
the remaining ones. This is ensured by the belief
refinement procedure. For each observed user ac-
tion and each partition it first checks whether all of
the hypotheses in the partition are either consistent
with the action or not. If they are not, it splits the
partition into two partitions with the parent-child
relationship. The inconsistent hypotheses remain
in the parent partition and the consistent ones are
moved to the child. The belief of the original par-
tition is distributed between the new ones in the
ratio of their priors.
To prevent an exponential increase in the num-
ber of partitions during the dialog, a partition re-
combination strategy can be used that removes the
less probable partition and moves their hypothe-
ses to different partitions. We perform partition
recombination at the end of each turn (Henderson
and Lemon, 2008), during the recombination low
probability partitions are merged with their parents
exactly as suggested by Williams (2010).
For the actual belief update the following stan-
dard update equation is used:
P
t+1
(p) = k ? P
t
(p) ?
?
u?u
P(u|u) ? P(u|p, a) (1)
where k is a normalization constant, P
t
(p) is belief
in partition p after turn t, a is the machine action
taken in turn t, u is a set of observed user actions,
P(u|u) is the score of action u in the SLU n-best
list u. In this definition P
0
(p) is a prior probabil-
ity of partition p; the prior might be either uniform
or estimated from the training data. The list u is
extended with an unobserved action u? whose prob-
ability is:
P(u?|u) = 1?
?
u?u\{u?}
P(u|u). (2)
P(u|p, a) in the update equation is the user
model, i.e. how likely the user is to take an ac-
tion u given that the last machine action was a and
user?s goal is represented by partition p.
In our case:
P(u|p, a) =
?(p, u, a)
?
p
?
? partitions
?(p
?
, u, a) ? size(p
?
)
(3)
where size(p) is the number of possible user?s
goals represented by p and ?(p, u, a) is an indi-
cator function that evaluates to 1 when user?s ac-
tion u is compatible with the goal represented by
p given the last machine?s action was a, otherwise
? evaluates to 0.
? is defined in the following way, for every ob-
served action u ? u \ {u?}:
?(p, u, a) = ?
?
(p, u, a) (4)
where ?
?
is a deterministic function that encodes
the meanings of user and machine actions for a
given partition. The rules expressed by ?
?
are for
example:
?a : ?
?
(p
s=w
, inform(s = v), a) =
{
1 if v = w
0 if v 6= w
and
?
?
(p
s=w
, yes(), conf (s = v)) =
{
1 if v = w
0 if v 6= w
where p
s=w
represents a partition where slot s has
value w, inform(s = v) is user?s action assigning
value v to the slot s and conf (s = v) is machine
action requiring confirmation that slot s has value
v.
For an unobserved action u? we define ? as:
?(p, u?, a) =
?
u?u\{u?}
(1? ?
?
(p, u, a)). (5)
12
This definition assumes that user?s unobserved
action u? uniformly supports each partition not sup-
ported by any of the observed user?s actions u.
?(p, u?, a) evaluates to 1 if none of user?s actions
support given partition, otherwise it evaluates to
0. This can be viewed as an axiom of our system,
alternatively we could assume that u? supports all
partitions, not only those not supported by any ob-
served action.
The key property of the update equations for-
mulated in this way is that the probability of a par-
tition representing a hypothesis that a user?s goal
was not mentioned in any of the SLU lists up to
the time t does not outweigh probability of ob-
served goals even though the prior probability of
unobserved hypothesis is usually orders of mag-
nitude higher than the probability of all observed
hypotheses. However, when two goals are indis-
tinguishable based on the SLU input then the ratio
of their probabilities will be exactly the ratio of
their priors.
Belief update equations are generic and in-
dependent of the internal structure of partitions.
When the tracker has to be adapted to a new dia-
log domain with the fixed goal the application de-
veloper needs to supply only a new definition of
?
?
and partition splitting mechanism adjusted ac-
cording to ?
?
.
4.1 Differences to the Original HIS
The key difference between our HIS implementa-
tion and previous HIS systems is in the formula-
tion of the user model. Previous HIS-based sys-
tems (Young et al., 2010; Ga?si?c, 2011) factorize
the user model as:
P
orig
(u|p, a) = k ? P(T (u)|T (a)) ? M(u, p, a)
where P(T (u)|T (a)) is a dialog act type bigram
model and M is a deterministic item matching
model that is similar to our ?. Based on a descrip-
tion of the item matching model given in (Keizer
et al., 2008; Young et al., 2010; Ga?si?c, 2011) we
deduce that it evaluates to a constant c
+
instead of
1 when the user action is consistent with the parti-
tion and to c
?
instead of 0 otherwise. It holds that
0 ? c
?
 c
+
? 1, e.g. c
?
= 0.1 and c
+
= 0.9.
In our tracker, we omit the dialog act type model
since it is not a mandatory component of the user
model and it can be added later. However, the
most important systematic difference between our
tracker and the original HIS formulation is that in-
stead of using a reduced user model, which would
Par. P
t
P
orig
t+1
P
ours
t+1
p
a
1
/3
1
/3
1
/4
p
b
1
/3
1
/3
1
/4
p
c
1
/3
1
/3
1
/2
Table 3: Comparison of the effects of original HIS
user model and our modified user model. Initially
all partitions are equally likely. After performing
belief update using Eq. 1 the original model out-
puts probabilities in the column P
orig
t+1
, the column
P
orig
t+1
shows results of our user model.
be P
orig
(u|p, a) = ?(p, u, a) in the original HIS,
we use the formulation given in Eq. 3. The origi-
nal HIS does not use a concept of partition?s size
(size(p
?
) in Eq. 3) that we need for the definition
of our user model.
We will illustrate the difference between these
two approaches on a minimalistic abstract exam-
ple. Suppose the belief space consists of three par-
titions p
a
, p
b
and p
c
, each of them having probabil-
ity of
1
/3 and representing one possible user?s goal
(i.e. size(p
?
) = 1). There are two actions on the
SLU list: u
a,b
that is consistent only with p
a
and
p
b
(i.e. ?
?
(p
a
, u
a,b
, ?) = 1), and u
c
that is con-
sistent only with p
c
. Both u
a,b
and u
c
are equally
probable, P(u
a,b
|u) = P(u
c
|u) =
1
/2. Accord-
ing to one intuition p
a
and p
b
should share support
given to them by action u
a,b
, on the other hand p
c
does not share the action u
c
with any other par-
tition. Thus after updating the probability using
Eq. 1 one would expect P
t+1
(p
c
) to be higher than
P
t+1
(p
a
). Now we can compare the output of our
model and the original HIS side by side as shown
in Table 3. The user model as formulated in the
original HIS leads to a new belief state where all
partitions are equally probable. However, accord-
ing to our modified user model partition p
c
is twice
as probable than p
a
or p
b
. This is, we argue, closer
to human intuition.
The update equation for a partition p in this sim-
plistic example is:
P
t+1
(p) = k ? P(p) ?
(
P(u
a,b
|u) ? P(u
a,b
|p, ?)+
P(u
c
|u) ? P(u
c
|p, ?)
)
.
For every partition the original model would
output the same probability:
P
orig
t+1
(p) = k
1
1
3
(
1
2
? c
+
+
1
2
? c
?
)
=
1
3
13
However our model gives the following equa-
tion for both p
a
and p
b
:
P
our
t+1
(p
x
) = k
2
1
3
(
1
2
?
1
1 + 1
+
1
2
?
0
1
)
=
1
4
where x ? {a, b}. The impact of u
a,b
on p
x
is di-
vided by a factor of 2 since it is shared by two par-
titions each representing one possible user goal.
For p
c
we have:
P
our
t+1
(p
c
) = k
2
1
3
(
1
2
?
0
1 + 1
+
1
2
?
1
1
)
=
1
2
.
This is how values in Table 3 were computed.
Another extension of the original HIS is how
we handle the unobserved action. To our knowl-
edge, the original HIS systems (Young et al., 2010;
Ga?si?c, 2011) do not deal with probability of unob-
served action; Williams (2010) presents a differ-
ent way of handling the unobserved action. We
provide unified way how to handle unrecognized
mass on the SLU list. In the original HIS model,
partition p
unobs
not supported by any of the ob-
served actions obtains probability by M evalu-
ating to c
?
on each observed action. In our
model, p
unobs
receives non-zero probability due to
?(p
unobs
, u?, ?) evaluating to 1 (see Eq. 5).
5 Tracker Design and its Variants
The previous section gave detailed description of
the update equations of our HIS based tracker.
This section presents an overall design of differ-
ent implemented tracker variants. We will discuss
how we use the bus route database and how we
perform supervised and unsupervised prior adap-
tation.
5.1 Single Slot Tracking versus Joint
Tracking of Multiple Slots
An advantage of a HIS-based systems is that they
make it possible to track a joint probability distri-
bution over a user?s goal. This advantage is two-
fold. First, it enables usage of a joint prior, either
learned from training data or from the bus sched-
ule database. Second, tracking a joint distribution
makes it possible to use more information from
SLU hypotheses. We will illustrate this on an ex-
ample. Suppose that SLU is able to extract multi-
ple slots from one user?s utterance, in our example
it might be interpreted as:
inform(route=61,to.desc=cmu) 0.5
inform(route=60,to.desc=zoo) 0.4
And the machine explicitly confirms the route:
expl-confirm(route=61)
If the user?s response is interpreted as:
negate() 0.8
affirm() 0.1
Then the system tracking only marginal proba-
bilities over single slots will correctly consider
route 60 as being more probable but user?s nega-
tion will have no effect on marginal distribution of
to.desc. However, a system tracking the joint
distribution will now correctly rank zoo higher
than cmu. The disadvantage of tracking joint hy-
potheses is that it requires more computational re-
sources. A tracker tracking all slots independently
with a uniform prior is denoted as IBM
indep
uniform
, a
tracker tracking joint hypotheses with a uniform
prior as IBM
jointly
uniform
.
5.2 Bus Schedule Database
Along with the dialog dataset DSTC organizers
provided a database with bus schedules for routes
in Pittsburgh area. We tested possibility to use re-
lation between bus routes and bus stops that can be
extracted from the database. First, we normalized
bus stop names as found in the SLU hypotheses
(e.g. by removing prepositions), in this way we
were able to match 98 percent of bus stops found
in the SLU to stops in the database.
An initial analysis of the data revealed that
only around 55% of route , from.desc, to.desc
hypotheses annotated by human annotators as a
ground truth were also found in the database.
This means that either callers were often asking
for non-existing combinations or the database was
mismatched.
Our tracker utilizing the database tracked joint
hypotheses for route , from.desc and to.desc slots
and hypotheses with combinations not found in the
database were penalized. The prior of a joint par-
tition p
r,f,t
, for a route r from destination f to des-
tination t, was computed as:
P(p
r,f,t
) = P
uniform
?DB(r, f, t)
Where DB is
DB(r , f , t) =
{
1 if ?r, f, t? ? database
1
c
otherwise
where parameter c is a penalty constant for hy-
potheses not in the database. The value of c is
estimated by parameter search on the train data.
This tracker will be denoted as IBM
jointly
db
.
14
Test set 3
Schedule 2 Schedule 3
joint
acc.
avg.
acc.
joint
L2
avg.
L2
joint
acc.
avg.
acc.
joint
L2
avg.
L2
Team 6 (Lee and Eskenazi, 2013) .558 .680 .801 .597 .589 .823 .779 .367
Team 8 (unknown authors) .424 .616 .845 .559 .408 .716 .878 .422
Team 9 (Kim et al., 2013) .499 .657 .914 .710 .551 .828 .928 .461
Team 3 (
?
Zilka et al., 2013) .464 .645 .831 .669 .528 .794 .734 .390
1-best baseline .448 .620 .865 .611 .492 .703 .839 .514
IBM
jointly
uniform
.521 .654 .785 .575 .557 .804 .746 .344
IBM
indep
uniform
.521 .654 .786 .576 .558 .806 .746 .343
IBM
jointly
db
.523 .657 .774 .564 .559 .806 .738 .339
IBM
indep
train-to-test
.563 .680 .694 .513 .609 .828 .644 .285
IBM
indep
unsup
.573 .689 .685 .505 .611 .834 .634 .279
Table 4: Results on the DSTC test set 3. Higher accuracy is better, whereas lower L2 score is better.
Numbers in bold highlight performance of the best tracker in the selected metric. The first four rows
show teams that performed the best in at least one of the selected metrics. For each team in each metric
we show performance of the best submitted tracker. This means that numbers in one row do not have to be
from a single tracker. It is an upper bound of the team?s performance. The fifth row shows performance
of a 1-best baseline tracker that always picks the SLU hypothesis with the top confidence. The rest are
different variants of our tracker. Here the bold numbers show where our tracker performed better than the
best tracker submitted to the DSTC. A light gray highlight of a cell denotes the overall best performance
in online setting, a dark gray highlight denotes the best performance while tracking offline.
5.3 Priors Adaptation
We tested two variants of adjusting prior probabili-
ties of user goals. We estimated prior probabilities
as a mixture of the uniform probability and empir-
ical distribution estimated on the training data.
In the first experiment the empirical probabili-
ties were estimated using the annotation that was
available in the training data. We tracked the
slots independently because the empirical joint
distribution would be too sparse to generalize on
the test data. We used one prior distribution to
guide the selection of route hypotheses Pr
route
and one shared distribution for possible destina-
tion names Pr
desc
. This distribution is trained on
data from both from and to destinations thus gain-
ing a more robust estimate compared to using two
separate distributions for from.desc and to.desc.
This tracker will be denoted as IBM
indep
train-to-test
.
In the second experiment we used the test data
without the ground truth labels to estimate the em-
pirical prior. We first ran the tracker with the uni-
form prior on the testing set and we used the out-
put hypotheses as a basis for the empirical distri-
bution. The prior of a hypothesis is proportional
to a sum of all tracker output scores for the hy-
pothesis. This scheme is called unsupervised prior
adaptation by Lee and Eskenazi (2013). Note that
the prior was computed on the test dataset. Thus
this technique is not directly applicable to a realis-
tic setting where the belief tracker has to produce a
belief for each dialog from the test set the first time
it sees it. This tracker will be called IBM
indep
unsup
.
6 Evaluation
We evaluated all our tracker variants on the DSTC
test3 dataset using the protocol designed for the
challenge participants. We also present initial re-
sults of the basic IBM
indep
uniform
and IBM
jointly
uniform
track-
ers for test1 and test2 datasets. Several quanti-
ties were measured in three different schedules,
which defines, which moments of the dialog the
evaluation is performed. Here we report results
for schedule 2 and 3. Schedule 2 takes into ac-
count all turns when the relevant concept appeared
on user?s SLU list or was mentioned by the dialog
system. Schedule 3 evaluates belief at the end of
the dialog, i.e. at the moment when the queried
information is presented to the user.
We report accuracy, which is the ratio of dialogs
where the user goal was correctly estimated, and
15
the L2 score, which is the Euclidean distance of
the vector of the resulting belief from a vector hav-
ing 1 for the correct hypothesis and 0s for the oth-
ers. For both of these the average values over all
tracked slot is reported as well as the value for the
joint hypotheses. The accuracy informs us how of-
ten the correct query to the database will be made.
The L2 score tells us how well-calibrated the re-
sults are, which can be important for disambigua-
tion and for statistical policy optimization.
6.1 Method
We used one thousand partitions as the limit for
the number of tracked hypotheses. For each
tracker ran on the test set 3 we used only the top
five SLU hypotheses.
All parameters for mixing the empirical prior
probability with uniform distribution in trackers
IBM
indep
train-to-test
and IBM
indep
unsup
were estimated us-
ing 3-fold cross validation scheme on the training
data. The best parameter setting on the training
data was then used in evaluation on the test set.
Test set 1
joint
acc.
avg.
acc.
joint
L2
avg.
L2
Team 6 .364 .862 .989 .278
Team 9 .225 .789 1.154 .354
Team 2 .206 .777 1.234 .409
1-best baseline .138 .626 1.220 .530
IBM
jointly
uniform
.332 .813 .992 .282
IBM
indep
uniform
.331 .804 1.010 .304
Table 5: Preliminary results for schedule 3 on the
DSTC test set 1 of our two trackers compared to
three overall well performing teams. For teams 6
and 9 see Table 4, team 2 is (Wang and Lemon,
2013). The legend of the table is the same as in
Table 4.
Even though we concentrated mainly on test-
ing the tracker on dataset 3, we also ran it on the
datasets 1 and 2. For the datasets 1 and 2 we used
the single best SLU hypothesis from the live sys-
tem. Such hypothesis was assigned 99% probabil-
ity and the remaining 1% was left for the unob-
served action. For the datasets 1 and 2 a post hoc
computed SLU hypotheses are available in addi-
tion to the live data. In our experiments, using the
post hoc computed SLU hypotheses with normal-
ized confidence scores yielded worse results for
our tracking systems.
Test set 2
joint
acc.
avg.
acc.
joint
L2
avg.
L2
Team 6 .526 .854 .885 .311
Team 9 .268 .748 1.098 .450
Team 2 .320 .764 1.148 .470
1-best baseline .141 .487 1.185 .648
IBM
jointly
uniform
.431 .789 .846 .316
IBM
indep
uniform
.413 .778 .875 .332
Table 6: Preliminary results for schedule 3 on the
DSTC test set 2. For teams see Tables 4 and 5.
The legend of the table is the same as in Table 4.
6.2 Results
Results of our trackers on the DSTC dataset 3 are
summarized in Table 4. Preliminary results of
the trackers on datasets 1 and 2 whose confidence
scores are not that well calibrated are shown in Ta-
bles 5 and 6. The running time of the trackers
was on average below 0.05 seconds per turn
1
. The
only exception is IBM
jointly
db
that executes plenty of
database queries. Although we did not focus on
the computational performance optimization most
of the trackers are suitable for on-line use.
6.3 Discussion
Quantitative Comparison to DSTC Trackers.
First let us discuss results of our trackers on test 3
(Table 4). Here both basic variants of the tracker
IBM
indep
uniform
and IBM
jointly
uniform
perform almost identi-
cally. This is because test 3 uses fixed dialog flow
as discussed in Section 2, minor differences in per-
formance between IBM
indep
uniform
and IBM
jointly
uniform
are
caused only by numerical issues. The trackers are
around the third place in accuracy. In joint L2 met-
rics they outperform the best tracker in DSTC sub-
mitted by Team 6 (Lee and Eskenazi, 2013).
Tracker utilizing database IBM
jointly
db
does not
show any significant improvement over the same
tracker without database-based prior IBM
jointly
uniform
.
We hypothesize that this is because of the fact that
people frequently asked for non-existing combina-
tions of routes and stops, which were penalized for
not being in the database, as discussed in Sec. 5.2.
Next follow the results of tracker IBM
indep
train-to-test
that learns priors for single slots on training
dataset and uses them while inferring user?s goal
on the test set. In test set 3 priors enhanced
1
On one core of Intel Xeon CPU E3-1230 V2, 3.30GHz,
with memory limitation of 1GB.
16
tracker?s performance in all metrics and the tracker
outperformed all DSTC trackers.
Interesting results were achieved by IBM
indep
unsup
that performed even better than the IBM
indep
train-to-test
.
It uses a prior trained on the test set by running the
tracker with a uniform prior. The tracker was run
for three iterations each time using output of the
previous iteration as a new prior.
After running the experiments with the top 5
SLU hypotheses, we performed an experiment that
investigated influence of n-best list length on the
tracker?s accuracy. We evaluated five system vari-
ants that received 1, 2, 3, 4 and 5 best SLU hy-
potheses. The overall trend was that initially per-
formance increased as more SLU hypotheses were
provided however then performance started de-
creasing. The 3-best variant achieved about 1.5%
increase in joint accuracy compared to the 1-best.
However, when using more than 3 best hypothe-
ses, the performance slightly decreased. For in-
stance, IBM
indep
uniform
using 1-best hypothesis per-
formed comparable to the 5-best configuration.
Similar behavior of generative systems assuming
observation independence has already been ob-
served in different domains (Vail et al., 2007).
Based on these results we deduce two conclu-
sions. First, strong performance of IBM
indep
uniform
1-best system compared to the 1-best baseline sys-
tem suggests that the main added value of our
tracker in this domain is in the aggregation of ob-
servations from multiple time steps, not in track-
ing multiple hypotheses from one turn. Sec-
ond, we attribute the effect of decreasing accu-
racy to the correlation of ASR errors from con-
secutive dialog turns. As noted by Williams
(2012b), correlated ASR errors violate the as-
sumption of observation independence that is as-
sumed by HIS. Extending the user model with
an auto-regressive component, that is with depen-
dence on observations from the previous time step
(i.e. P(u
t
|u
t?1
, p, a)), might help to tackle this
problem in generative models (Wellekens, 1987).
To summarize the results on test set 3, even
without any prior adaptation on the data our
tracker is competitive with the best submissions
to DSTC. After incorporating prior knowledge it
outperforms all submitted trackers.
On test set 1 and test set 2 (see Tables 5 and 6)
the trackers perform second in accuracy. In L2
metrics the trackers are competitive with the best
tracker in DSTC submitted by Team 6 and they
outperform it in one out of four cases. It is inter-
esting that our basic strategy that ignores live SLU
scores performed that strong.
However, on test 1 and test 2, which make it
possible to input multiple slots in one user utter-
ance, IBM
jointly
uniform
outperforms IBM
indep
uniform
, both in
accuracy and L2. We hypothesize that this is be-
cause of effect of tracking joint distributions de-
scribed in Section 5.1.
Qualitative Comparison to DSTC Trackers.
Compared to another HIS-based system (Kim et
al., 2013) participating in the DSTC, our imple-
mentation does not suffer from the problem of as-
signing high probability to the hypothesis that the
user goal was not observed so far. This might be
due to our modified user model. Therefore our im-
plementation does not need a final transformation
of belief scores as reported by Kim et al. (2013).
Additionally, our implementation does not
exhibit the forgetting behavior as experienced
by
?
Zilka et al. (2013). Forgetting is undesirable
given the validity of assumption that the user?s
goal remains fixed in the whole dialog, which is
the case of DSTC bus schedule domains.
7 Conclusion
Although the use of generative trackers was re-
cently criticized by Williams (2012a), our re-
sults show that at least in some metrics (e.g. L2
metrics on dataset 3) a generative tracker can
outperform the best state-of-the-art discriminative
tracker (Lee and Eskenazi, 2013). Even though
we agree that the discriminative approach might be
more promising, it seems that in general there are
conditions where generative models learn faster
than discriminative models (Ng and Jordan, 2001).
Thus it might be beneficial to use a generative
tracker for a newly deployed dialog system with
only a few training dialogs available and switch to
a discriminative model once enough training data
from an already running system is collected. En-
semble trackers incorporating both generative and
discriminative models as used by Lee and Eske-
nazi (2013) might also be an interesting direction
for future research.
Acknowledgment
We would like to thank Ji?r?? Havelka for his valu-
able comments on a draft of this paper. This work
was partially funded by the GetHomeSafe project
(EU 7
th
Framework STREP project No. 288667).
17
References
Milica Ga?si?c. 2011. Statistical Dialogue Modelling.
PhD thesis, University of Cambridge.
James Henderson and Oliver Lemon. 2008. Mixture
Model POMDPs for Efficient Handling of Uncer-
tainty in Dialogue Management. In Proc ACL-HLT,
pages 73?76.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2013. Deep neural network approach for
the dialog state tracking challenge. In Proceedings
of the SIGDIAL 2013 Conference, pages 467?471,
Metz, France, August. Association for Computa-
tional Linguistics.
Simon Keizer, Milica Ga?si?c, Franc?ois Mairesse, Blaise
Thomson, Kai Yu, and Steve Young. 2008. Mod-
elling user behaviour in the his-pomdp dialogue
manager. In Spoken Language Technology Work-
shop, 2008. SLT 2008. IEEE, pages 121?124. IEEE.
Daejoong Kim, Jaedeug Choi Choi, Kee-Eung Kim,
Jungsu Lee, and Jinho Sohn. 2013. Engineering sta-
tistical dialog state trackers: A case study on dstc.
In Proceedings of the SIGDIAL 2013 Conference,
pages 462?466, Metz, France, August. Association
for Computational Linguistics.
Sungjin Lee and Maxine Eskenazi. 2013. Recipe for
building robust spoken dialog state trackers: Dialog
state tracking challenge system description. In Pro-
ceedings of the SIGDIAL 2013 Conference, pages
414?422, Metz, France, August. Association for
Computational Linguistics.
Sungjin Lee. 2013. Structured Discriminative Model
For Dialog State Tracking. In Proceedings of the
SIGDIAL 2013 Conference, pages 442?451, Metz,
France, August. Association for Computational Lin-
guistics.
Andrew Ng and Michael Jordan. 2001. On discrim-
inative vs. generative classifiers: A comparison of
logistic regression and naive bayes. Neural Infor-
mation Processing Systems, pages 841?848.
Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan.
2013. Dialog state tracking using conditional ran-
dom fields. In Proceedings of the SIGDIAL 2013
Conference, pages 457?461, Metz, France, August.
Association for Computational Linguistics.
Douglas L Vail, Manuela M Veloso, and John D Laf-
ferty. 2007. Conditional Random Fields for Activ-
ity Recognition Categories and Subject Descriptors.
In Proceedings of the 6th International Joint Confer-
ence on Autonomous Agents and Multiagent systems
(AAMAS 2007).
Zhuoran Wang and Oliver Lemon. 2013. A sim-
ple and generic belief tracking mechanism for the
dialog state tracking challenge: On the believabil-
ity of observed information. In Proceedings of the
SIGDIAL 2013 Conference, pages 423?432, Metz,
France, August. Association for Computational Lin-
guistics.
Christian Wellekens. 1987. Explicit time correlation
in hidden markov models for speech recognition. In
Acoustics, Speech, and Signal Processing, IEEE In-
ternational Conference on ICASSP?87., volume 12,
pages 384?386. IEEE.
Jason D Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2012. Dialog state tracking
challenge handbook.
Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The Dialog State
Tracking Challenge. In Proceedings of the SIGDIAL
2013 Conference, pages 404?413, Metz, France,
August. Association for Computational Linguistics.
Jason D. Williams. 2010. Incremental partition re-
combination for efficient tracking of multiple dialog
states. In ICASSP, pages 5382?5385.
Jason D. Williams. 2012a. Challenges and Opportuni-
ties for State Tracking in Statistical Spoken Dialog
Systems: Results From Two Public Deployments.
IEEE Journal of Selected Topics in Signal Process-
ing, 6(8):959?970, December.
Jason D Williams. 2012b. A critical analysis of
two statistical spoken dialog systems in public use.
In Spoken Language Technology Workshop (SLT),
2012 IEEE, pages 55?60. IEEE.
Steve Young, Milica Ga?si?c, Simon Keizer, Franc?ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The Hidden Information State model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech & Lan-
guage, 24(2):150?174, April.
Luk?a?s
?
Zilka, David Marek, Mat?ej Korvas, and Filip
Jur?c???cek. 2013. Comparison of bayesian discrim-
inative and generative models for dialogue state
tracking. In Proceedings of the SIGDIAL 2013 Con-
ference, pages 452?456, Metz, France, August. As-
sociation for Computational Linguistics.
18
Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 28?32,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Recipes for building voice search UIs for automotive
Martin Labsky, Ladislav Kunc, Tomas Macek, Jan Kleindienst, Jan Vystrcil
IBM Prague Research and Development Lab
V Parku 2294/4, 148 00 Prague 4
Czech Republic
{martin.labsky, ladislav kunc1, tomas macek,
jankle, jan vystrcil}@cz.ibm.com
Abstract
In this paper we describe a set of tech-
niques we found suitable for building
multi-modal search applications for au-
tomotive environments. As these ap-
plications often search across different
topical domains, such as maps, weather
or Wikipedia, we discuss the problem
of switching focus between different do-
mains. Also, we propose techniques use-
ful for minimizing the response time of the
search system in mobile environment. We
evaluate some of the proposed techniques
by means of usability tests with 10 novice
test subjects who drove a simulated lane
change test on a driving simulator. We re-
port results describing the induced driving
distraction and user acceptance.
1 Introduction
The task of designing mobile search user inter-
faces (UIs) that combine multiple application do-
mains (such as navigation, POI and web search)
is significantly harder than just placing all sin-
gle domain solutions adjacent to one another. We
propose and evaluate a set of UI techniques use-
ful for implementing such systems. The tech-
niques are exemplified using a prototype multi-
modal search assistant tailored for in-car use. The
prototype supports several application domains in-
cluding navigation and POI search, Wikipedia,
weather forecasts and car owner?s manual. Fi-
nally, we report usability evaluation results using
this prototype.
2 Related Work
Two examples of multi-modal search UIs for au-
tomotive are the Toyota Entune
1
and the Honda
1
http://www.toyota.com/entune/
Link
2
. Both infotainment systems integrate a
set of dedicated mobile applications including
a browser, navigation, music services, stocks,
weather or traffic information. Both use a tablet or
a smartphone to run the mobile applications which
brings the advantage of faster upgrades of the in-
car infotainment suite. Home screens of these sys-
tems consist of a matrix of square tiles that corre-
spond to individual applications.
The answers presented to the user should only
contain highly relevant information, e.g. present-
ing only points of interest that are near the cur-
rent location. This is called conversational maxim
of relevance (Paul, 1975). Many other lessons
learned by evaluating in-car infotainment systems
are discussed in (Green, 2013).
In recent years, personal assistant systems like
Siri (Aron, 2011), Google Now! (Google, 2013)
and the Dragon Mobile Assistant (Nuance, 2013)
started to penetrate the automotive environment.
Most of these applications are being enhanced
with driving modes to enable safer usage while
driving. Dragon Mobile Assistant can detect
whether the user is in a moving car and auto-
matically switches to ?Driver Mode? that relies
on speech recognition and text-to-speech feed-
back. Siri recently added spoken presentation
of incoming text messages and voice mail, and
it also allows to dictate responses. Besides the
speech-activated assistant functionality, Google
Now! tries to exploit various context variables
(e.g. location history, user?s calendar, search his-
tory). Context is used for pro-active reminders that
pop-up in the right time and place. Speech recog-
nition of Google Now! has an interesting feature
that tries to act upon incomplete/interim recogni-
tion results; sometimes the first answer is however
not the right one which is later detected and the
answer is replaced when results are refined.
2
http://owners.honda.com/hondalink/
nextgeneration
28
3 UI techniques to support search while
driving
Below we present selected techniques we found
useful while designing and testing prototype
search UIs for automotive.
3.1 Nearly stateless VUI
While driving and interacting with an application
UI, it often happens that the driver must interrupt
interaction with the system due to a sudden in-
crease of cognitive load associated with the pri-
mary task of driving. The interaction is either
postponed or even abandoned. The UI activity
may later be resumed but often the driver will
not remember the context where s/he left off. In
heavily state-based systems such as those based
on hierarchical menus, reconstruction of applica-
tion context in the driver?s mind may be costly and
associated with multiple glances at the display.
In order to minimize the need for memorizing
or reconstructing the application context, we ad-
vocate UIs that are as stateless as possible from
the user?s point of view. In the context of spoken
input, this means the UI should be able to process
all voice input regardless of its state.
This is important so that the driver does not need
to recall the application state before s/he utters a
request. For instance, being able to ask ?Where
can we get a pizza? only after changing screen to
?POI search? can be problematic as the driver (1)
needs to change screens, (2) needs to remember
what the current screen is, and (3) may need to
look at the display to check the screen state. All
of these issues may increase driver distraction (its
haptic, visual and mental components).
3.2 Self-sufficient auditory channel
According to the subjective results of usability
tests described in Section 6 and according to ear-
lier work on automotive dictation (Macek et al.,
2013), many drivers were observed to rely primar-
ily on the audio-out channel to convey information
from the UI while driving and they also preferred
it to looking at a display. A similar observation
was made also for test drivers who listened to and
navigated news articles and short stories (Kunc et
al., 2014).
Two recommendations could be abstracted from
the above user tests. First, the UI should produce
verbose audio output that fully describes what
happens with the system (in cases when the driver
controls the UI while driving). This includes spo-
ken output as well as earcons indicating important
micro-states of the system such as ?listening? or
?processing?. Second, the UI should enable the
user to easily replay what has been said by the
system, e.g. by pressing a button, to offset the se-
rial character of spoken output. These steps should
make it possible for selected applications to run in
a display-less mode while driving or at least mini-
mize the number of gazes at the display.
3.3 Distinguish domain transition types
By observing users accessing functions of mul-
tiple applications through a common UI, we ob-
served several characteristic transition types.
Hierarchical. The user navigates a menu tree,
often guided by GUI hints.
Within domain. Users often perform multiple
interactions within one application, such as per-
forming several Wikipedia queries, refining them
and browsing the retrieved results.
Application switching. Aware of the namings
of the applications supported by the system, users
often switch explicitly to a chosen domain before
uttering a domain-specific command.
Direct task invocation. Especially in case of UIs
having a unifying persona like Siri (Aron, 2011),
users do not view the system as a set of appli-
cations and instead directly request app-specific
functions, regardless of their past interaction.
Subdialog. The user requests functionality out
of the current application domain. The corre-
sponding application is invoked to handle the re-
quest and then the focus returns automatically to
the original domain. Examples include taking a
note or checking the weather forecast while in the
middle of another task.
Undo. A combined ?undo? or ?go back? fea-
ture accessible globally at a key press proved use-
ful during our usability testing to negate any un-
wanted actions accidentally triggered.
Figure 1 shows samples for the above transi-
tion types using an example multi-domain search
assistant further described in Section 4. Similar
lists of transition types ware described previously,
e.g. (Milward et al., 2006). Based on observing
human interactions with our prototype system, we
built a simple probabilistic model to control the
likelihood of the system taking each of the above
transition types, and used it to rescore the results
of the ASR and NLU systems.
29
Figure 1: Transitions in a multi-domain system.
3.4 Early and incremental feedback about
the application state
Mobile search UIs often depend both on local and
remote resources such as ASR and NLU services
and various data providers. In mobile environ-
ments, availability and response times of remote
services may vary significantly. Most mobile UIs
address this problem by responding with a beep
and displaying a ?processing? sign until the fi-
nal answer is rendered. We describe a UI tech-
nique that combines redundant local and remote
resources (ASR and NLU) to quickly come up
with a partial meaningful response that addresses
the user?s request. Chances are that the first re-
sponse based on partial understanding is wrong
and the following prompt must correct it.
Figure 2 shows a template definition for a sys-
tem prompt that starts playing once the system is
confident enough about the user?s intent being a
weather forecast question. The system provides
forecasts for the current location by default but
can switch to other locations if specified by the
user. Supposing the system is equipped with real-
time ASR and NLU that quickly determine the
high-level intent of the user, such as ?weather fore-
cast?, the initial part of the prompt can start play-
ing almost immediately after the user has stopped
speaking. While a prefix of this prompt is play-
ing, more advanced ASR and NLU models de-
liver a finer-grained and more precise interpreta-
tion of the input, including any slot-value pairs
like ?location=London?. Once this final interpre-
tation is known, the playback can be directed via
the shortest path to the identified variable prompt
segments like <location>. Further, the selec-
tion of prompt prefix to be played can be guided
by a current estimate of service delays to mini-
mize chances of potential pauses before speaking
prompt segments whose values are not yet known.
Figure 2: Sample incremental prompt graph. Seg-
ments are annotated with durations in round brack-
ets and min/max times before an unknown slot
value has to be spoken (ms).
4 Voice search assistant prototype
In this section we briefly present a voice search in-
terface that was developed by incrementaly imple-
menting the four UI techniques presented above.
While interim versions of this system were only
evaluated subjectively, formal evaluation results
are presented for the final version in Section 6.
The voice search assistant covers six applica-
tion domains shown in Figure 3. Navigation ser-
vices include spoken route guidance together with
unified destination entry by voice (addresses and
POIs). Some POIs are accompanied by user re-
views that can be read out as part of POI details.
Figure 3: Prototype home screen (apps as tiles).
Further, the user can search various knowledge
sources like Wikipedia, Wolfram Alpha and the
web. The retrieved results are pre-processed and
the first one is played back to the user with the
possibility of navigating the result list.
To simulate asynchronous events, the system
reads out Skype text messages. The driver can also
create location and time based reminders that pop
up during the journey.
Finally, the system supports full-text search
over the car owner?s manual. Relevant text pas-
sages are read out and displayed based on a prob-
lem description or question uttered by the driver.
30
5 Usability testing setup and procedure
A low-fidelity driving simulator setup similar to
the one described in (Curin et al., 2011) was
used to conduct lane change tests using (Mattes,
2003). Tests were conducted with 10 novice sub-
jects and took approximately 1 hour and 20 min-
utes per participant. At the beginning and at the
end of the test, subjects filled in pre-test and post-
test questionnaires. Before the actual test, each
participant practised both driving and using the
prototype for up to 20 minutes. The evaluated
test consisted of four tasks: an initial undistracted
drive (used to adapt a custom LCT ideal path for
each participant), two distracted driving trips in
counter-balanced order, and a final undistracted
drive (used for evaluation). Each of the four drives
was performed at constant speed of 60km/h and
took about 3.5 minutes. During the distracted
driving tasks, the users were instructed verbally
to perform several search tasks using the proto-
type. During task 1, subjects had to set destina-
tion to ?office?, then find a pharmacy along the
route, check the weather forecast and take a note
about the forecast conditions. Task 2 only dif-
fered slightly by having a different destination and
POI, and by the user searching Wikipedia instead
of asking about weather.
6 Usability testing results
Objective distraction was measured using mean
deviation (MDev) and standard deviation
(SDLP ) of the vehicle?s lateral position (Mattes,
2003). Two versions of both statistics were
obtained: overall (computed over the whole trip)
and using lane-keeping segments only. The graph
in Figure 4 shows averaged results for the final
undistracted drive and for the first and second
distracted driving tasks (reflecting the order of the
tasks, not their types). We observe that using the
search UI led to significant distraction during lane
change segments but not during lane keeping.
Also, the distraction results for the first trip show
higher variance which we attribute to the users
still adapting to the driving simulator and to
using the UI. The observed distraction levels are
comparable to our earlier results obtained for a
text dictation UI when used with a GUI display
(Curin et al., 2011).
Several observations came out of the subjec-
tive feedback collected using forms. The users re-
ported extensive use of the auditory channel (both
00,10,20,30,40,50,60,70,80,91
 
 
 
 
 
Und
istra
cted
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Firs
t tas
k    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Sec
ond
 
task
[m]
Ove
rall 
MD
ev
Ove
rall 
SDL
P
Lan
e ke
epin
g M
Dev
Lan
e ke
epin
g SD
LP
Figure 4: Driving distraction while using a multi-
modal search UI.
in and out) only with occasional glimpses at the
scre n (w however observed that objectively they
looked at the display more often than they reported
subjectively). Users also missed some informa-
tion in the voice output channel such as audio indi-
cation of route calculation progress (which could
take several seconds). Reading any text from the
screen was found difficult, and users requested that
playback be improved; see related follow-up study
(Kunc et al., 2014). Interestingly, multiple partic-
ipants requested voice commands that would du-
plicate buttons like ?next? and ?previous?, even in
cases where speech would be less efficient. This
may show a tendency to stick with a single modal-
ity as described by (Suhm et al., 2001). Addi-
tionally, the users requested better synchronization
of navigation announcements like ?take exit 4 in
200 metres? with the output of other applications.
The baseline behaviour utilized in the test was
that high-priority navigation prompts interrupted
the output of other applications. Navigation, POI
search, simple note-taking and constrained search
domains like weather and Wikipedia were found
most useful (in this order). Open web search
and browsing an original car owner?s manual were
considered too distracting to use while driving.
7 Conclusion
We described several recipes for building spoken
search applications for automotive and exempli-
fied them on a prototype search UI. Early us-
ability testing results for the prototype were pre-
sented. Our future work focuses on improving the
introduced techniques and exploring alternative UI
paradigms (Macek et al., 2013).
Acknowledgement
The presented work is part of an IBM and Nuance
joint research project.
31
References
Jacob Aron. 2011. How innovative is apple?s new
voice assistant, siri? New Scientist, 212(2836):24.
J. Curin, M. Labsky, T. Macek, J. Kleindienst,
H. Young, A. Thyme-Gobbel, H. Quast, and
L. Koenig. 2011. Dictating and editing short texts
while driving: distraction and task completion. In
Proceedings of the 3rd International Conference on
Automotive User Interfaces and Interactive Vehicu-
lar Applications.
Google. 2013. Google now assistant. Available at
http://www.google.com/landing/now/.
Paul A Green. 2013. Development and evaluation
of automotive speech interfaces: useful information
from the human factors and the related literature. In-
ternational Journal of Vehicular Technology, 2013.
L. Kunc, M. Labsky, T. Macek, J. Vystrcil, J. Klein-
dienst, T. Kasparova, D. Luksch, and Z. Medenica.
2014. Long text reading in a car. In Proceedings
of the 16th International Conference on Human-
Computer Interaction Conference (HCII).
Tom?a?s Macek, Tereza Ka?sparov?a, Jan Kleindienst,
Ladislav Kunc, Martin Labsk?y, and Jan Vystr?cil.
2013. Mostly passive information delivery in a
car. In Proceedings of the 5th International Confer-
ence on Automotive User Interfaces and Interactive
Vehicular Applications, AutomotiveUI ?13, pages
250?253, New York, NY, USA. ACM.
Stefan Mattes. 2003. The lane-change-task as a tool
for driver distraction evaluation. In Proceedings of
the Annual Spring Conference of the GFA/ISOES,
volume 2003.
David Milward, Gabriel Amores, Nate Blaylock,
Staffan Larsson, Peter Ljunglof, Pilar Manchon, and
Guillermo Perez. 2006. D2.2: Dynamic multimodal
interface reconfiguration. In Talk and Look: Tools
for Ambient Linguistic Knowledge IST-507802 De-
liverable D2.2.
Nuance. 2013. Dragon mobile assistant. Available at
http://www.dragonmobileapps.com.
Grice H Paul. 1975. Logic and conversation. Syntax
and semantics, 3:41?58.
Bernhard Suhm, Brad Myers, and Alex Waibel. 2001.
Multimodal error correction for speech user inter-
faces. ACM Transactions on Computer-Human In-
teraction (TOCHI), 8(1):60?98.
32
Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 53?57,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Mostly Passive Information Delivery ? a Prototype
J. Vystr
?
cil, T. Macek, D. Luksch, M. Labsk?y, L. Kunc, J. Kleindienst, T. Ka
?
sparov
?
a
IBM Prague Research and Development Lab
V Parku 2294/4, 148 00 Prague 4
Czech Republic
{jan vystrcil, tomas macek, david.luksch, martin labsky,
ladislav kunc1, jankle, tereza.kasparova}@cz.ibm.com
Abstract
In this paper we introduce a new UI
paradigm that mimics radio broadcast
along with a prototype called Radio One.
The approach aims to present useful infor-
mation from multiple domains to mobile
users (e.g. drivers on the go or cell phone
users). The information is served in an en-
tertaining manner in a mostly passive style
? without the user having to ask for it? as
in real radio broadcast. The content is gen-
erated on the fly by a machine and inte-
grates a mix of personal (calendar, emails)
and publicly available but customized in-
formation (news, weather, POIs). Most of
the spoken audio output is machine syn-
thesized. The implemented prototype per-
mits passive listening as well as interaction
using voice commands or buttons. Initial
feedback gathered while testing the proto-
type while driving indicates good accep-
tance of the system and relatively low dis-
traction levels.
1 Introduction
The main purpose of this paper is to describe a
prototype of the Radio One concept. Radio One
presents music, news, emails, relevant POI and
other information to the user in a mostly passive
way, similarly to conventional radios. Users can
interract with the system as well using voice com-
mands or buttons. The concept was refined and
initially tested with prerecorded audio-visual sce-
narios using the Wizard-of-Oz (WOZ) technique
(Macek et al., 2013).
Here we describe the early prototype implemen-
tation of the system and summarize initial feed-
back collected during informal testing.
2 Related Work
Applications that produce customized audio
streams can be found in many online music deliv-
ery services including Spotify, Pandora, or iTunes.
While the above services often focus on music
only, other providers (BBC, CNN) publish their
spoken content in the form of podcasts. Spoken
audio used for podcasts is often recorded by pro-
fessional speakers as opposed to the concept pre-
sented here. The Aha radio (Aha, 2014) provides
various thematic streams of information including
music, news, social network updates or Points of
Interest (POI). Content can be selected manually
by switching between channels. Similar strategies
are utilized by Stitcher (Stitcher, 2014) and other
services. The concept presented here attempts in-
sted to preselect the content automatically and on
the fly while preserving the option to request the
content explicitely.
Many in-car infotainment systems adopted the
use of voice control and utilize information di-
rectly from on-line services; e.g. (BMW, 2014)
and (Ford, 2014). All of the abovementioned ap-
plications use mobile data connection to deliver
audio stream (as opposed to text) to the user. This
can lead to large data downloads and potentially to
high bills from mobile network providers.
3 Radio One Concept
Radio One mimics radio broadcast by generating
infotainment content on the fly. Unlike real radios,
Radio One customizes its content to the particular
listener and should even adapt automatically while
the user interacts with it. In addition to the content
typically played by radios, the synthetic content
also includes private information like calendar or
emails. Most of the spoken output is produced by
a text-to-speech system with the exception of pod-
casts.
The presented information stream is sparse with
53
the intervals between spoken segments filled with
music and moderator small-talk. The content
structure is configurable and can be adapted both
automatically, based on observing habits of the
user, or via explicit voice commands or buttons.
The main benefit of dynamically generated con-
tent is that the system can easily include dynamic
personal content and that the infotainment stream
can be efficiently controlled by the user and in-
fluenced by the environment (such as expected
duration of the drive or current road conditions).
From a technical perspective, the connection re-
quirements are much smaller compared to audio
transfers, as Radio One mostly downloads textual
feeds only. Downloading redundant information
can be avoided by knowing what has already been
presented to the particular user. Further, the user
can navigate in the broadcast, either to specific
topics by using voice commands, or just backward
and forward by using buttons. This option should
reduce potential stress related to a driver concen-
trating on a broadcasted topic knowing s/he would
be unable to replay. The radio presents informa-
tion from the covered domains continuously. The
stream of presented information also serves as a
natural way of teaching the user about the sup-
ported domains. By hearing that news are read
as part of the radio stream, the user finds out that
news is one category that can be requested by
voice commands.
4 System Description
Although previous WOZ tests (Macek et al.,
2013) were sufficient to collect the initial user
feedback, their flexibility and fidelity was limited.
The prototype described in this paper is intended
for testing of concepts and for conducting realistic
usability tests in a car. The implemented prototype
is a fully functioning system, although still with a
limited feature set.
4.1 Architecture
The overall architecture of the system is depicted
in Figure 1. The system collects inputs both from
manual controls (steering wheel buttons, rotary
knob) and from ASR (voice commands). Multi-
ple on-line and off-line data sources provide con-
tent. While driving, GPS information about the
car position is used together with an optional cal-
culated route and POI data to plan overall broad-
casting. The core of the Radio One system (see
Figure 1: Radio One big picture.
Figure 2: Radio One architecture.
Figure 2) is the scheduler. The scheduler is re-
sponsible for planning both the type of content
and the time of its presentation. The content as-
sociated with higher expected cognitive load (e.g.
emails or calendar) can be planned for segments
of the journey that have low driving difficulty (e.g.
straight highway). The overall architecture aims
to be highly configurable and context-aware to be
able to produce heterogeneous content based on
differing user preferences and changing state of
the environment.
4.2 Controls
Multiple button configurations are possible, rang-
ing from a ?speech button-only? setup to several
buttons used to provide quick access to frequently
used functions. For in-car setups, the availabil-
ity of buttons is often limited. A configuration of
3 buttons in a row (in addition to speech button)
can be used to let the user navigate back and forth
using the two outer buttons and request more de-
tails or pause/resume the broadcast with a central
button. Both ?per-item? (e.g. single email, song
or news title) and ?per-bundle? navigation (?bun-
dle? being a coherent group of affiliated items, e.g.
emails) can be supported by short and long presses
of the navigation buttons. Other functions would
54
typically be available through voice commands
only, or also through a touch interface where avail-
able (e.g. on a cell phone or in a parked car).
Alternatively to the buttons on the steering
wheel, a rotary knob can be placed on the side of
the driver?s seat (depicted on the left of Figure 3).
Usually, a single knob press initiates speech input,
while turning the knob navigates back and forth in
items. Per-bundle navigation can be triggered ei-
ther by using greater turns or by turning the knob
while pressed.
The voice control subsystem is hybrid with
speech recognition and understanding being done
both remotely and locally. This way, functions
are available even when off-line while benefit-
ing from improved accuracy and coverage of the
server models when on-line. Free-form commands
are understood (e.g. ?email? or ?would you read
my email please?).
4.3 Content and Presentation
Two modes of operation are implemented. The
off-line mode permits testing with locally saved
data or data specifically tailored for various exper-
iments. The on-line mode collects data (e.g. email,
calendar, news) periodically from the network and
presents it at appropriate times.
News are collected periodically from config-
urable network sources and grouped by topic. Two
forms of news presentation are implemented. A
shorter version is used during news summaries.
A longer version can be requested by an explicit
voice request like ?tell me more? or by pressing a
?details? button.
Emails undergo elementary pre-processing to
improve their suitability for being read out loud.
Emails longer than a configured threshold are
shortened at the end of the sentence. Email his-
tories are also skipped. The user can request a full
version of the email using a voice command like
?read the whole message?.
Moderator commentaries are tailored to the
content they accompany. We use a set of hand-
crafted prompt templates for natural language gen-
eration. Prompt templates are grouped according
to the context that triggers them into pools of al-
ternatives, from which prompts are selected ran-
domly while avoiding repetitions. Moderators can
announce upcoming content or refer to content
that just finished playing. Prompt templates often
contain variables referring to various properties of
the neighbouring content (e.g. name of the preced-
ing song or topic of the upcoming news).
Information is presented as a story, typically
with a brief summary-of-the-broadcast at the be-
ginning. This order can be interrupted by sudden
events (e.g. emails arriving, hot breaking news,
POI announcements) with proper moderator com-
ments to indicate what is happening. The infor-
mation is grouped together in bundles of the same
type (e.g. email summaries are not mixed with cal-
endar or news items). Typical in-car presentation
order starts with music to allow the listener to get
concentrated on driving. Then a summary is pro-
vided followed by blocks of music and informa-
tion bundles.
In contrast to our earlier WOZ study, the cur-
rent version of the prototype does not present any
visual information as we focus on the driving sce-
nario. The previous WOZ study indicated that this
information was distracting to the driver and not
much valued by the participants.
Figure 3: Alternative user interface controls
4.4 Implementation
The prototype is implemented in Java. It uses
a local text-to-speech system (TTS). We use the
Nuance Vocalizer premium voices to provide the
best available TTS quality. Current implementa-
tion is primarily in English (moderators and their
comments) although playback of content in other
languages (currently Czech) is supported as well.
Language detection is done automatically (Cy-
bozu Labs, 2014). The system was tested both
on a PC (Windows 7) and on tablets and phones
(Android, Windows 8). Emails are currently re-
trieved using the IMAP protocol so various email
providers can be used. News are currently down-
loaded from the Feedzilla (Feedzilla, 2014) REST
API and from other RSS feeds.
Calendar events are retrieved from the user?s
Google Calendar account. The radio automati-
cally announces individual upcoming events and
55
also plays summaries about the remaining events
of the day (also can be requested by voice).
Like real radios, we use characteristic earcons
and jingles to introduce particular types of infor-
mation (e.g. email, news or calendar) and other
sounds to separate individual information items
from each other (e.g. earcons between emails or
news titles).
For testing purposes we use infra-red remote
control buttons (see right hand part of Figure 3)
mounted to the steering wheel, with key events re-
ceived by a special purpose hardware and passed
to Radio One via Bluetooth.
We use either an AUX cable or a radio FM
transmitter to integrate with the car?s audio sys-
tem. The current prototype implements music
playback, presents news, email, weather reports
and calendar summaries. Initial work was done
on presenting POIs near the current location. An
arbitrary list of MP3 files can be used as a source
of music. Ideally, user?s own collection of music
is used during the tests. ID3 tags of music files are
utilized in the process of generating voice prompts
spoken by moderators as part of their small talk
(e.g. ?This was a song by the Beatles?).
5 Usability testing
Initially, a WOZ experiment was conducted with-
out having the system implemented. Test subjects
drove a low-fidelity driving simulator while lis-
tening to a radio stream broadcasted by the wiz-
ard, who played pre-recorded audio-visual snip-
pets trying to satisfy user?s requests. We described
results of this experiment previously in (Macek
et al., 2013). The main feedback from this ex-
periment was that the users perceived the quality
of synthesized speech sufficiently. The visual in-
formation shown by the wizard contained mostly
static pictures or short texts in large fonts. Most
of the users did not find the screen useful in this
setup. Therefore the current radio prototype is
screen-less. Two groups of users could be iden-
tified. The first one used the system in the same
way as a standard radio, with minimal interaction.
The other group preferred to be ?in control? and
used both buttons and voice commands to ask for
specific content.
Multiple informal tests were conducted by 4 test
drivers in real traffic. More extensive testing is still
in preparation. The feedback collected so far was
positive, indicating that the TTS quality was suf-
ficient. Even with a small number of test drivers
it became apparent that the roles of customization
and automatic adaptation to preferences of a spe-
cific user will be crucial.
Information-heavy content like certain kinds of
news was sometimes considered difficult to lis-
ten to while driving, which was in part due to
all of the test drivers being non-native speakers
of English. Adding jingles to separate the pre-
sented news items from one another improved the
perception of the system significantly. The news
feeds used by the prototype were originally not
intended for audio presentation, which does im-
pact their understandability, but the effect does not
seem to be major. Lighter content like weather
forecasts and calendar announcements were con-
sidered easy to understand.
The test drivers considered it important to be
able to use their personal data (news, email, mu-
sic). This motivated the inclusion of information
sources in languages other than English and the
addition of automatic language identification so as
to select proper TTS voices. The fact that multi-
ple languages were present in the broadcast was
not perceived adversely. One shortcoming of the
tested system was still a low variability of moder-
ators? comments.
6 Conclusion
We presented a work-in-progress demonstration
prototype of a novel method for presenting in-
formation to users on-the-go. A preceding WOZ
study indicated promising user acceptance which
was also confirmed using the described prototype.
When comparing with existing systems, the sys-
tem presented here has much lower requirements
on communication bandwidth, requires less hu-
man work for content authoring and permits a
higher level of personalization. Amount of inter-
activity depends very much on user preferences.
In future work we would like to pay attention
to evaluation of user feedback on more extensive
usability tests. It will be interesting to see to what
extent the user will opt for active interaction with
the system and for the particular interaction tech-
niques.
Acknowledgments
The presented work is part of an IBM and Nuance
joint research project.
56
References
Harman International Aha. 2014. Aha radio web-
site. Retrieved from http://www.aharadio.
com/.
BMW. 2014. Bmw connecteddrive ser-
vices. Retrieved from http://www.bmw.
com/com/en/insights/technology/
connecteddrive/2013/services_apps/
bmw_connecteddrive_services.html.
Inc. Cybozu Labs. 2014. Language detection li-
brary for java. Retrieved from https://code.
google.com/p/language-detection/.
Feedzilla. 2014. Feedzilla - news feed directory. Re-
trieved from http://www.feedzilla.com/.
Ford. 2014. Sync with myford touch. Retrieved
from http://www.ford.com/technology/
sync/.
Tom?a?s Macek, Tereza Ka?sparov?a, Jan Kleindienst,
Ladislav Kunc, Martin Labsk?y, and Jan Vystr?cil.
2013. Mostly passive information delivery in a
car. In Proceedings of the 5th International Confer-
ence on Automotive User Interfaces and Interactive
Vehicular Applications, AutomotiveUI ?13, pages
250?253, New York, NY, USA. ACM.
Inc. Stitcher. 2014. Stitcher website. Retrieved from
http://www.stitcher.com/.
57
