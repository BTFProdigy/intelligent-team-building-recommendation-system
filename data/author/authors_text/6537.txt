Integrated Feasibility Experiment for Bio-Security: IFE-Bio
A TIDES Demonstration
Lynette Hirschman, Kris Concepcion, Laurie Damianos, David Day, John Delmore, Lisa Ferro,
John Griffith, John Henderson, Jeff Kurtz, Inderjeet Mani, Scott Mardis, Tom McEntee, Keith
Miller, Beverly Nunan, Jay Ponte, Florence Reeder, Ben Wellner, George Wilson, Alex Yeh
The MITRE Corporation
Bedford, Massachusetts, USA and
McLean, Virginia, USA
781-271-7789
lynette@mitre.org
ABSTRACT
As part of MITRE?s work under the DARPA TIDES
(Translingual Information Detection, Extraction and
Summarization) program, we are preparing a series of
demonstrations to showcase the TIDES Integrated Feasibility
Experiment on Bio-Security (IFE-Bio).  The current
demonstration illustrates some of the resources that can be made
available to analysts tasked with monitoring infectious disease
outbreaks and other biological threats.
Keywords
Translation, information extraction, summarization, topic
detection and tracking, system integration.
1. INTRODUCTION
The long-term goal of TIDES is to provide delivery of
information on demand in real-time from live on-line sources. For
IFE-Bio, the resources made available to the analyst include e-
mail, news groups, digital library resources, and eventually (in
later versions), topic-specific segments from broadcast news.
Because of the emphasis on global monitoring, there is a need to
process incoming information in multiple languages.  The system
must deliver the appropriate information content in the
appropriate form and in the appropriate language (taken for now
to be English). This means that the IFE-Bio system will have to
deliver news stories, clusters of relevant documents, threaded
discussions, alerts on new events, tables, summaries (particularly
over document collections), answers to questions, graphs and geo-
spatial  temporal displays of information.
The demonstration system for the Human Language Technology
Conference in March 2001 represents an early stage of the full
IFE-Bio system, with an emphasis on end-to-end processing.
Future demonstrations will make use of MITRE?s Catalyst
architecture, providing an efficient, scalable architecture to
facilitate  integration of multiple stages of linguistic processing.
By June 2001, the IFE-Bio system will provide richer linguistic
processing through the integration of modules contributed by
other TIDES participants. By June 2002, the IFE-Bio system will
include additional functionality, such as real-time broadcast news
feeds, new machine translation components, support for question-
answering, cross-language information retrieval, multi-document
summarization, automatic extraction and normalization of
temporal and spatial information, and automated geospatial and
temporal displays.
2. The IFE-Bio System
The current demonstration (March 2001) highlights the basic
functionality required by an analyst, including:
? Capture of sources, including e-mail, digital library
material, news groups, and web-based resources;
? Categorizing of the sources into multiple orthogonal
hierarchies useful to the analyst, e.g., disease, region, news
source, language;
? Processing of the information through various stages,
including ?zoning? of the text to select the relevant portions
for processing; named entity detection, event detection,
extraction of temporal information, summarization, and
translation from Spanish, Portuguese, and Chinese into
English;
? Access to the information through use of any mail and news
group reader, which allows the analyst to organize, save, and
share the information in a familiar, readily accessible
environment;
? Display of the information in alternate forms, including
color-tagged documents, tables, summaries, graphs, and
geospatial, map-based displays.
Figure 1 below shows the overall functionality envisioned
for the IFE-Bio system, including capture, categorizing,
processing, access and display.
Collection capability for the current IFE-Bio system includes
email, news groups, journals, and Web resources. We have a
complete copy of the ProMED mailings (a moderated source
tracking global infectious disease outbreaks), and are routinely
collecting other information sources from the World Health
Organization and CDC.  In addition, we are collecting several
general global news feeds. Current volume is around 2000
messages per day; we estimate capacity for the current system at
around 4500 messages/day. Once we have integrated a filtering
capability, we expect the volume of messages saved in IFE-Bio
should drop significantly, since many of the global news services
report on a wide range of events and not all need to be passed on
to IFE-Bio analysts.  The categorizing of sources is done based on
the message header. The header is synthesized by extracting key
information about disease name, the country, and other relevant
information such as type of victim and source of information, as
well as date of message receipt.
The processing for the current demonstration system uses a
limited subset of the Catalyst architecture capabilities and a
number of in-house linguistic modules. The linguistic modules in
the current demonstration system include tokenization, sentence
segmentation, part-of-speech tagging, named entity detection,
temporal extraction (Mani and Wilson 2000) and source-specific
event detection.  In addition, we have incorporated the
CyberTrans embedded machine translation system which ?wraps?
available machine translation engines to make them available via
an e-mail or Web interface (Reeder 2000). Single document
summarization is performed by the MITRE WebSumm system
(Mani and Bloedorn 1999).
We carefully chose a light-weight interface mechanism for
delivery of the information to the analyst.  By treating the
incoming streams of data as feeds to a news server, the analyst can
inspect and organize the information using a familiar news and e-
mail browser. The analyst can subscribe to areas of interest, flag
important messages, watch specific threads, and create tailored
filters for monitoring outbreaks. The stories are crossed-posted to
multiple relevant news groups, based on the information in the
header, e.g., a story on Ebola in Africa would be cross posted to
the Africa regional newsgroup and to the Ebola disease
newsgroup. Search by subject and date allow the analyst to select
subsets of the messages for further processing, annotation or
sharing.  The news client provides notification of incoming
messages. In later versions, we plan to integrate topic detection
and tracking capabilities, to provide improved filtering and
routing of messages, as well as detection of new topics.  The use
of this simple delivery mechanism provides a familiar
environment with almost no learning curve, and it avoids issues of
platform and operating system dependence.
Finally, the system makes use of several different devices to
display the information appropriately. Figure 2 shows the layout
of the Netscape news browser interface.  It includes the list of
newsgroups that have been subscribed to (on the left), the list of
messages from the chosen newsgroup (on top), and a particular
message with color-coded named entities (including disease terms
displayed in red, so that they are easy to spot in the message).
What is the status of the
current Ebola outbreak?
The epidemic is contained;
as of 12/22/00, there were 
421 cases with 162 deaths
Interaction
CDC
WHO
Medical
literatureEmail:
ProMed
~ 2500
 stories/day
Internl
News
Sources  Capture
Translingual 
Information 
Detection 
Extraction 
Summarization 
U niden tif ied h emor rhagic  f
U niden tif ied h emor rhagic  f
Ebola hemorr hagic  fever  in
Re :  Ebo la hemorrhagi. ..
R e: Ebola hemo rrha gi...
ProMED
A nnotator
Ja ne Analyst
10 /17/00 1 9:37
10 /17/00 2 0:42
10 /18/00 7 :42
High
Norm al
Normal
read
rep lied
ProMED
10 /18/00 1 2:3 4 High un read
Ebola hemorr hagic  fever  in
Sour ce
D ate
Priority Status
10   99
0   105
1   57
0   10
2   34
0   50
1   1
0   25
5   200
0   45
0   0
0   0
0   0
0   0
0   6
0   32
0   3
0   1
High
Norm al
High
High
Ebola hemorrhagic feve r  -  Ugan da
U nf ilte red
O utbr eak
     C holer a
     D engue  Fe ve r
     Eb ola
I nfras tructure?
N atu ral  Di sas. ..
Spi lls
A cc id en ts
W M D Tra ckin. ..
Sus picious Il ln. ..
Sus picious De.. .
Pos sible  Biol o. ..
Pathogen threa ?
- --- --- ---------------------
W orkspa ce
      E bola
      D ra fts
      Re ports
D isease
R e: Ebola hemo rrha gi...
Location
U NK
U NK
Ebola
Ebola
Ebola
Ebola
Rabies
Rabies
U gan da
U gan da
U gan da
K eny a
U gan da
IHT
ProMED
WHO
Jo e Analyst
D ate
10 /14/00 2 3:06
10 /15/00 1 0:50
10 /16/00 2 1:45
10 /17/00 1 9:12
read
read
read
read
un read
Date: 10/16/00
Disease: Ebo la
Descripto r: hem orrh agic fever
Locatio n:          Ugan da
Disease Date:     10/14/00
Ho spital: mission ary hosp ital  in Gulu
New cases:  at least  7
Total  cases: 51
Total  dead:       31
Ebola hemorr hagic  fever  -
Ugand an M ini stry  ide ntif ies Eb ola  virus as t he c ause of  the outbreak.  KA MP ALA :
The  dreade d Eb ola  virus that struck over 300  peopl e i n Kikwit,  in  t he D emocratic
Rep ub lic  of Con go  in  1995, has ki lled 31  people in northe rn Ugan da.  A  U gandan
M ini s tr y of Heal th  sta tement  said l aboratory test s had r eveale d that  the Ebola vi rus
was  t he caus e of the  epidemi c hemorr hagic feve r whi ch has been r agi ng in the  G ulu
dis trict  since Septe mbe r.   Thr ee  of the dea d wer e s tud ent nur ses , who tre ated the first
Eb ola  patients admitt ed to a  Lac or  mis sionary hosp it al in  Gu lu  tow n.  A  task force
he ade d by G ul u dis trict adm ini str ator, Walte r O ch ora , has bee n se t up to co-or dina te
efforts to control the epi demi c.  F ie ld offic ials i n  Gul u tol d the Ka mpala-based Ne w
H ttp: //ti des2000.mi tre.org/
Pr oM ED /10162000/34n390h.ht ml
U gan da
News Repository
CATALYSTEntity Tagging
Event Extraction
Translation
Summarization
Alerting
Change detection
Threading
Cross-language IR
Topic clustering
Figure 1: Overview of the IFE-Bio Demonstration System
Local,
private
workspace
Documents
automatically
categorized
into shared,
tailorable
hierarchy
Sort by disease, location, source, date, etc.
Associated
meta-data:
header,
event,
summary,
named-entity
Figure 2: Screenshot of IFE-Bio Interface Using News Group Reader
Figure 3: Sample Summarization Automatically Generated by WebSumm
There are multiple display modalities available. The message in
Figure 2 contains a short tabular display in the beginning,
identifying disease, region and victim type. Below that is a URL
to a document summary, created by MITRE?s WebSumm system
(see Figure 3 for a sample summary).   If an incoming message is
in a language other than English, then CyberTrans is called to run
code set and language identification modules, and the language is
translated into English for further processing. Figure 4 below
shows a sample translated message; note that there are a number
of untranslated words, but it is still possible to get the gist of the
message.
In addition, we are working on a mechanism to provide
geographic and eventually, temporal display of outbreak
information. Figure 5 shows the stages of processing involved.
Stage 1 shows onamed entity and temporal tagging to identify the
items of interest. These are combined into disease events by
further linguistic processing; the result is shown in the table in
Stage 2. This spreadsheet of events serves as input for a map-
based display, shown in Stage 3. The graph plots number of new
cases and number of cumulative cases over time.  In the map, the
size of the outer dot represents total number of cases to date, and
the inner dot represents new cases.  This allows the analyst to
visualize spread of the disease, as well as the stage of the outbreak
(spreading or subsiding).
3. REFERENCES
[1] Mani, I. and Bloedorn, E. (1999). "Summarizing
Similarities and Among Related Documents".
Information Retrieval 1(1): 35-67.
[2] Mani, I. and Wilson, G. (2000). "Robust Temporal
Processing of News," Proceedings of the 38th Annual
Meeting of the Association for Computational
Linguistics (ACL'2000), 69-76. New Brunswick, New
Jersey. Association for Computational Linguistics.
[3] Reeder, F.  (2000) "At Your Service:  Embedded MT
as a Service",  NAACL Workshop on Embedded MT,
March, 2000.
Figure 4: Translation from Portuguese to English Produced by CyberTrans
1. Annotate entities of interest via XML
Dise a se Source Country City_na m eDa te Ca se s Ne w _ca se s De a d
Ebola PROM ED Uganda G ula 26-O ct-2000 182 17 64
Ebola PROM ED Uganda G ula 5-Nov-2000 280 14 89
Ebola PROM ED Uganda G ulu 13-O ct-2000 42 9 30
Ebola PROM ED Uganda G ulu 15-O ct-2000 51 7 31
Ebola PROM ED Uganda G ulu 16-O ct-2000 63 12 33
Ebola PROM ED Uganda G ulu 17-O ct-2000 73 2 35
Ebola PROM ED Uganda G ulu 18-O ct-2000 94 21 39
Ebola PROM ED Uganda G ulu 19-O ct-2000 111 17 41
2. Assemble entities into events
0
50
100
150
200
250
300
350
400
10/
13/
200
0
10/
20/
200
0
10/
27/
200
0
11/
3/2
000
11/
10/
200
0
11/
17/
200
0
11/
24/
200
0
T IME
Nu
m
be
r C
as
es
Cases
New_cases
Dead
3. Display events...
   Total Cases   New Cases
Figure 5: Steps in Extraction to Support Temporal and Geospatial Displays of Disease Outbreak
Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1145?1152
Manchester, August 2008
A Systematic Comparison of Phrase-Based, Hierarchical and
Syntax-Augmented Statistical MT
Andreas Zollmann
?
and Ashish Venugopal
?
and Franz Och and Jay Ponte
Google Inc.
1600 Amphitheatre Parkway
Mountain View, CA 94303, USA
{zollmann,ashishv}@cs.cmu.edu {och,ponte}@google.com
Abstract
Probabilistic synchronous context-free
grammar (PSCFG) translation models
define weighted transduction rules that
represent translation and reordering oper-
ations via nonterminal symbols. In this
work, we investigate the source of the im-
provements in translation quality reported
when using two PSCFG translation mod-
els (hierarchical and syntax-augmented),
when extending a state-of-the-art phrase-
based baseline that serves as the lexical
support for both PSCFG models. We
isolate the impact on translation quality
for several important design decisions in
each model. We perform this comparison
on three NIST language translation tasks;
Chinese-to-English, Arabic-to-English
and Urdu-to-English, each representing
unique challenges.
1 Introduction
Probabilistic synchronous context-free grammar
(PSCFG) models define weighted transduction
rules that are automatically learned from parallel
training data. As in monolingual parsing, such
rules make use of nonterminal categories to gener-
alize beyond the lexical level. In the example be-
low, the French (source language) words ?ne? and
?pas? are translated into the English (target lan-
guage) word ?not?, performing reordering in the
context of a nonterminal of type ?VB? (verb).
VP ? ne VB pas, do not VB : w
1
?
Work done during internships at Google Inc.
?
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
VB ? veux,want : w
2
.
As with probabilistic context-free grammars, each
rule has a left-hand-side nonterminal (VP and VB
in the two rules above), which constrains the rule?s
usage in further composition, and is assigned a
weight w, estimating the quality of the rule based
on some underlying statistical model. Transla-
tion with a PSCFG is thus a process of compos-
ing such rules to parse the source language while
synchronously generating target language output.
PSCFG approaches such as Chiang (2005) and
Zollmann and Venugopal (2006) typically begin
with a phrase-based model as the foundation for
the PSCFG rules described above. Starting with
bilingual phrase pairs extracted from automatically
aligned parallel text (Och and Ney, 2004; Koehn et
al., 2003), these PSCFG approaches augment each
contiguous (in source and target words) phrase
pair with a left-hand-side symbol (like the VP in
the example above), and perform a generalization
procedure to form rules that include nonterminal
symbols. We can thus view PSCFG methods as
an attempt to generalize beyond the purely lexi-
cal knowledge represented in phrase based mod-
els, allowing reordering decisions to be explicitly
encoded in each rule. It is important to note that
while phrase-based models cannot explicitly repre-
sent context sensitive reordering effects like those
in the example above, in practice, phrase based
models often have the potential to generate the
same target translation output by translating source
phrases out of order, and allowing empty trans-
lations for some source words. Apart from one
or more language models scoring these reorder-
ing alternatives, state-of-the-art phrase-based sys-
tems are also equipped with a lexicalized distortion
model accounting for reordering behavior more di-
rectly. While previous work demonstrates impres-
1145
sive improvements of PSCFG over phrase-based
approaches for large Chinese-to-English data sce-
narios (Chiang, 2005; Chiang, 2007; Marcu et al,
2006; DeNeefe et al, 2007), these phrase-based
baseline systems were constrained to distortion
limits of four (Chiang, 2005) and seven (Chiang,
2007; Marcu et al, 2006; DeNeefe et al, 2007),
respectively, while the PSCFG systems were able
to operate within an implicit reordering window of
10 and higher.
In this work, we evaluate the impact of the ex-
tensions suggested by the PSCFG methods above,
looking to answer the following questions. Do the
relative improvements of PSCFG methods persist
when the phrase- based approach is allowed com-
parable long-distance reordering, and when the n-
gram language model is strong enough to effec-
tively select from these reordered alternatives? Do
these improvements persist across language pairs
that exhibit significantly different reodering effects
and how does resource availablility effect relative
performance? In order to answer these questions
we extend our PSCFG decoder to efficiently han-
dle the high order LMs typically applied in state-
of-the-art phrase based translation systems. We
evaluate the phrase-based system for a range of re-
ordering limits, up to those matching the PSCFG
approaches, isolating the impact of the nontermi-
nal based approach to reordering. Results are pre-
sented in multiple language pairs and data size
scenarios, highlighting the limited impact of the
PSCFG model in certain conditions.
2 Summary of approaches
Given a source language sentence f , statistical ma-
chine translation defines the translation task as se-
lecting the most likely target translation e under a
model P (e|f), i.e.:
?
e(f) = argmax
e
P (e|f) = argmax
e
m
?
i=1
h
i
(e, f)?
i
where the argmax operation denotes a search
through a structured space of translation ouputs
in the target language, h
i
(e, f) are bilingual fea-
tures of e and f and monolingual features of e,
and weights ?
i
are trained discriminitively to max-
imize translation quality (based on automatic met-
rics) on held out data (Och, 2003).
Both phrase-based and PSCFG approaches
make independence assumptions to structure this
search space and thus most features h
i
(e, f) are
designed to be local to each phrase pair or rule.
A notable exception is the n-gram language model
(LM), which evaluates the likelihood of the se-
quential target words output. Phrase-based sys-
tems also typically allow source segments to be
translated out of order, and include distortion mod-
els to evaluate such operations. These features
suggest the efficient dynamic programming al-
gorithms for phrase-based systems described in
Koehn et al (2004).
We now discuss the translation models com-
pared in this work.
2.1 Phrase Based MT
Phrase-based methods identify contiguous bilin-
gual phrase pairs based on automatically gener-
ated word alignments (Och et al, 1999). Phrase
pairs are extracted up to a fixed maximum length,
since very long phrases rarely have a tangible im-
pact during translation (Koehn et al, 2003). Dur-
ing decoding, extracted phrase pairs are reordered
to generate fluent target output. Reordered trans-
lation output is evaluated under a distortion model
and corroborated by one or more n-gram language
models. These models do not have an explicit rep-
resentation of how to reorder phrases. To avoid
search space explosion, most systems place a limit
on the distance that source segments can be moved
within the source sentence. This limit, along with
the phrase length limit (where local reorderings
are implicit in the phrase), determine the scope of
reordering represented in a phrase-based system.
All experiments in this work limit phrase pairs to
have source and target length of at most 12, and
either source length or target length of at most 6
(higher limits did not result in additional improve-
ments). In our experiments phrases are extracted
by the method described in Och and Ney (2004)
and reordering during decoding with the lexical-
ized distortion model from Zens and Ney (2006).
The reordering limit for the phrase based system
(for each language pair) is increased until no addi-
tional improvements result.
2.2 Hierarchical MT
Building upon the success of phrase-based meth-
ods, Chiang (2005) presents a PSCFG model of
translation that uses the bilingual phrase pairs of
phrase-based MT as starting point to learn hierar-
chical rules. For each training sentence pair?s set of
extracted phrase pairs, the set of induced PSCFG
rules can be generated as follows: First, each
1146
phrase pair is assigned a generic X-nonterminal as
left-hand-side, making it an initial rule. We can
now recursively generalize each already obtained
rule (initial or including nonterminals)
N ? f
1
. . . f
m
/e
1
. . . e
n
for which there is an initial rule
M ? f
i
. . . f
u
/e
j
. . . e
v
where 1 ? i < u ? m and 1 ? j < v ? n, to
obtain a new rule
N ? f
i?1
1
X
k
f
m
u+1
/e
j?1
1
X
k
e
n
v+1
where e.g. f
i?1
1
is short-hand for f
1
. . . f
i?1
, and
where k is an index for the nonterminal X that
indicates the one-to-one correspondence between
the new X tokens on the two sides (it is not in
the space of word indices like i, j, u, v,m, n). The
recursive form of this generalization operation al-
lows the generation of rules with multiple nonter-
minal symbols.
Performing translation with PSCFG grammars
amounts to straight-forward generalizations of
chart parsing algorithms for PCFG grammars.
Adaptations to the algorithms in the presence of n-
gram LMs are discussed in (Chiang, 2007; Venu-
gopal et al, 2007; Huang and Chiang, 2007).
Extracting hierarchical rules in this fashion can
generate a large number of rules and could in-
troduce significant challenges for search. Chiang
(2005) places restrictions on the extracted rules
which we adhere to as well. We disallow rules
with more than two nonterminal pairs, rules with
adjacent source-side nonterminals, and limit each
rule?s source side length (i.e., number of source
terminals and nonterminals) to 6. We extract rules
from initial phrases of maximal length 12 (exactly
matching the phrase based system).
1
Higher length
limits or allowing more than two nonterminals per
rule do not yield further improvements for systems
presented here.
During decoding, we allow application of all
rules of the grammar for chart items spanning up
to 15 source words (for sentences up to length 20),
or 12 source words (for longer sentences), respec-
tively. When that limit is reached, only a special
glue rule allowing monotonic concatenation of hy-
potheses is allowed. (The same holds for the Syn-
tax Augmented system.)
1
Chiang (2005) uses source length limit 5 and initial
phrase length limit 10.
2.3 Syntax Augmented MT
Syntax Augmented MT (SAMT) (Zollmann and
Venugopal, 2006) extends Chiang (2005) to in-
clude nonterminal symbols from target language
phrase structure parse trees. Each target sentence
in the training corpus is parsed with a stochas-
tic parser?we use Charniak (2000))?to produce
constituent labels for target spans. Phrases (ex-
tracted from a particular sentence pair) are as-
signed left-hand-side nonterminal symbols based
on the target side parse tree constituent spans.
Phrases whose target side corresponds to a con-
stituent span are assigned that constituent?s label as
their left-hand-side nonterminal. If the target span
of the phrase does not match a constituent in the
parse tree, heuristics are used to assign categories
that correspond to partial rewriting of the tree.
These heuristics first consider concatenation oper-
ations, forming categories such as ?NP+V?, and
then resort to CCG (Steedman, 1999) style ?slash?
categories such as ?NP/NN.? or ?DT\NP?. In the
spirit of isolating the additional benefit of syntactic
categories, the SAMT system used here also gen-
erates a purely hierarchical (single generic nonter-
minal symbol) variant for each syntax-augmented
rule. This allows the decoder to choose between
translation derivations that use syntactic labels and
those that do not. Additional features introduced
in SAMT rules are: a relative frequency estimated
probability of the rule given its left-hand-side non-
terminal, and a binary feature for the the purely
hierachial variants.
3 Large N-Gram LMs for PSCFG
decoding
Brants et al (2007) demonstrate the value of large
high-order LMs within a phrase-based system. Re-
cent results with PSCFG based methods have typ-
ically relied on significantly smaller LMs, as a
result of runtime complexity within the decoder.
In this work, we started with the publicly avail-
able PSCFG decoder described in Venugopal et al
(2007) and extended it to efficiently use distributed
higher-order LMs under the Cube-Pruning decod-
ing method from Chiang (2007). These extensions
allow us to verify that the benefits of PSCFG mod-
els persist in the presence of large, powerful n-
gram LMs.
3.1 Asynchronous N-Gram LMs
As described in Brants et al (2007), using large
distributed LMs requires the decoder to perform
1147
asynchronous LM requests. Scoring n-grams un-
der this distributed LM involves queuing a set
of n-gram probability requests, then distributing
these requests in batches to dedicated LM servers,
and waiting for the resulting probabilities, before
accessing them to score chart items. In order
to reduce the number of such roundtrip requests
in the chart parsing decoding algorithm used for
PSCFGs, we batch all n-gram requests for each
cell.
This single batched request per cell paradigm
requires some adaptation of the Cube-Pruning al-
gorithm. Cube-Pruning is an early pruning tech-
nique used to limit the generation of low quality
chart items during decoding. The algorithm calls
for the generation of N-Best chart items at each
cell (across all rules spanning that cell). The n-
gram LM is used to score each generated item,
driving the N-Best search algorithm of Huang and
Chiang (2005) toward items that score well from
a translation model and language model perspec-
tive. In order to accomodate batched asynchronous
LM requests, we queue n-gram requests for the top
N*K chart items without the n-gram LM where
K=100. We then generate the top N chart items
with the n-gram LM once these probabilties are
available. Chart items attempted to be generated
during Cube-Pruning that would require LM prob-
abilities of n-grams not in the queued set are dis-
carded. While discarding these items could lead
to search errors, in practice they tend to be poorly
performing items that do not affect final translation
quality.
3.2 PSCFG Minimal-State Recombination
To effectively compare PSCFG approaches to
state-of-the-art phrase-based systems, we must be
able to use high order n-gram LMs during PSCFG
decoding, but as shown in Chiang (2007), the
number of chart items generated during decoding
grows exponentially in the the order of the n-gram
LM. Maintaining full n?1 word left and right his-
tories for each chart item (required to correctly se-
lect the argmax derivation when considering a n-
gram LM features) is prohibitive for n > 3.
We note however, that the full n ? 1 left and
right word histories are unneccesary to safely com-
pare two competing chart items. Rather, given
the sparsity of high order n-gram LMs, we only
need to consider those histories that can actually
be found in the n-gram LM. This allows signifi-
cantly more chart items to be recombined during
decoding, without additional search error. The n-
gram LM implementation described in Brants et
al. (2007) indicates when a particular n-gram is
not found in the model, and returns a shortened
n-gram or (?state?) that represents this shortened
condition. We use this state to identify the left and
right chart item histories, thus reducing the number
of equivalence classes per cell.
Following Venugopal et al (2007), we also cal-
culate an estimate for the quality of each chart
item?s left state based on the words represented
within the state (since we cannot know the tar-
get words that might precede this item in the fi-
nal translation). This estimate is only used during
Cube-Pruning to limit the number of chart items
generated.
The extensions above allows us to experiment
with the same order of n-gram LMs used in state-
of-the-art phrase based systems. While experi-
ments in this work include up to 5-gram mod-
els, we have succesfully run these PSCFG systems
with higher order n-gram LM models as well.
4 Experiments
4.1 Chinese-English and Arabic-English
We report experiments on three data configura-
tions. The first configuration (Full) uses all the
data (both bilingual and monolingual) data avail-
able for the NIST 2008 large track translation
task. The parallel training data comprises of 9.1M
sentence pairs (223M Arabic words, 236M En-
glish words) for Arabic-English and 15.4M sen-
tence pairs (295M Chinese Words, 336M English
words) for Chinese-English. This configuration
(for both Chinese-English and Arabic-English) in-
cludes three 5-gram LMs trained on the target side
of the parallel data (549M tokens, 448M 1..5-
grams), the LDC Gigaword corpus (3.7B tokens,
2.9B 1..5-grams) and the Web 1T 5-Gram Cor-
pus (1T tokens, 3.8B 1..5-grams). The second
configuration (TargetLM) uses a single language
model trained only on the target side of the paral-
lel training text to compare approaches with a rela-
tively weaker n-gram LM. The third configuration
is a simulation of a low data scenario (10%TM),
where only 10% of the bilingual training data is
used, with the language model from the TargetLM
configuration. Translation quality is automatically
evaluated by the IBM-BLEU metric (Papineni et
al., 2002) (case-sensitive, using length of the clos-
est reference translation) on the following publicly
1148
Ch.-En. System \%BLEU Dev (MT04) MT02 MT03 MT05 MT06 MT08 TstAvg
FULL
Phraseb. reo=4 37.5 38.0 38.9 36.5 32.2 26.2 34.4
Phraseb. reo=7 40.2 40.3 41.1 38.5 34.6 27.7 36.5
Phraseb. reo=12 41.3* 41.0 41.8 39.4 35.2 27.9 37.0
Hier. 41.6* 40.9 42.5 40.3 36.5 28.7 37.8
SAMT 41.9* 41.0 43.0 40.6 36.5 29.2 38.1
TARGET-LM
Phraseb. reo=4 35.9* 36.0 36.0 33.5 30.2 24.6 32.1
Phraseb. reo=7 38.3* 38.3 38.6 35.8 31.8 25.8 34.1
Phraseb. reo=12 39.0* 38.7 38.9 36.4 33.1 25.9 34.6
Hier. 38.1* 37.8 38.3 36.0 33.5 26.5 34.4
SAMT 39.9* 39.8 40.1 36.6 34.0 26.9 35.5
TARGET-LM, 10%TM
Phraseb. reo=12 36.4* 35.8 35.3 33.5 29.9 22.9 31.5
Hier. 36.4* 36.5 36.3 33.8 31.5 23.9 32.4
SAMT 36.5* 36.1 35.8 33.7 31.2 23.8 32.1
Ar.-En. System \%BLEU Dev (MT04) MT02 MT03 MT05 MT06 MT08 TstAvg
FULL
Phraseb. reo=4 51.7 64.3 54.5 57.8 45.9 44.2 53.3
Phraseb. reo=7 51.7* 64.5 54.3 58.2 45.9 44.0 53.4
Phraseb. reo=9 51.7 64.3 54.4 58.3 45.9 44.0 53.4
Hier. 52.0* 64.4 53.5 57.5 45.5 44.1 53.0
SAMT 52.5* 63.9 54.2 57.5 45.5 44.9 53.2
TARGET-LM
Phraseb. reo=4 49.3 61.3 51.4 53.0 42.6 40.2 49.7
Phraseb. reo=7 49.6* 61.5 51.9 53.2 42.8 40.1 49.9
Phraseb. reo=9 49.6 61.5 52.0 53.4 42.8 40.1 50.0
Hier. 49.1* 60.5 51.0 53.5 42.0 40.0 49.4
SAMT 48.3* 59.5 50.0 51.9 41.0 39.1 48.3
TARGET-LM, 10%TM
Phraseb. reo=7 47.7* 59.4 50.1 51.5 40.5 37.6 47.8
Hier. 46.7* 58.2 48.8 50.6 39.5 37.4 46.9
SAMT 45.9* 57.6 48.7 50.7 40.0 37.3 46.9
Table 1: Results (% case-sensitive IBM-BLEU) for Ch-En and Ar-En NIST-large. Dev. scores with * indicate that the param-
eters of the decoder were MER-tuned for this configuration and also used in the corresponding non-marked configurations.
available NIST test corpora: MT02, MT03, MT05,
MT06, MT08. We used the NIST MT04 corpus
as development set to train the model parameters
?. All of the systems were evaluated based on the
argmax decision rule. For the purposes of stable
comparison across multiple test sets, we addition-
ally report a TstAvg score which is the average of
all test set scores.
2
Table 1 shows results comparing phrase-based,
hierarchical and SAMT systems on the Chinese-
English and Arabic-English large-track NIST 2008
tasks. Our primary goal in Table 1 is to evaluate
the relative impact of the PSCFG methods above
the phrase-based approach, and to verify that these
improvements persist with the use of of large n-
gram LMs. We also show the impact of larger
reordering capability under the phrase-based ap-
proach, providing a fair comparison to the PSCFG
approaches.
2
We prefer this over taking the average over the aggregate
test data to avoid artificially generous BLEU scores due to
length penalty effects resulting from e.g. being too brief in a
hard test set but compensating this by over-generating in an
easy test set.
Chinese-to-English configurations: We see
consistent improvements moving from phrase-
based models to PSCFG models. This trend
holds in both LM configurations (Full and Tar-
getLM) as well as the 10%TM case, with the ex-
ception of the hierarchical system for TargetLM,
which performs slightly worse than the maximum-
reordering phrase-based system.
We vary the reordering limit ?reo? for the
phrase-based Full and TargetLM configurations
and see that Chinese-to-English translation re-
quires significant reordering to generate fluent
translations, as shown by the TstAvg difference be-
tween phrase-based reordering limited to 4 words
(34.4) and 12 words (37.0). Increasing the reorder-
ing limit beyond 12 did not yield further improve-
ment. Relative improvements over the most capa-
ble phrase-based model demonstrate that PSCFG
models are able to model reordering effects more
effectively than our phrase-based approach, even
in the presence of strong n-gram LMs (to aid the
distortion models) and comparable reordering con-
straints.
1149
Our results with hierarchical rules are consis-
tent with those reported in Chiang (2007), where
the hierarchical system uses a reordering limit of
10 (implicit in the maximum length of the initial
phrase pairs used for the construction of the rules,
and the decoder?s maximum source span length,
above which only the glue rule is applied) and is
compared to a phrase-based system with a reorder-
ing limit of 7.
Arabic-to-English configurations: Neither the
hierarchical nor the SAMT system show consis-
tent improvements over the phrase-based baseline,
outperforming the baseline on some test sets, but
underperforming on others. We believe this is due
to the lack of sufficient reordering phenomena be-
tween the two languages, as evident by the mini-
mal TstAvg improvement the phrase-based system
can achieve when increasing the reordering limit
from 4 words (53.3) to 9 words (53.4).
N-Gram LMs: The impact of using addi-
tional language models in configuration Full in-
stead of only a target-side LM (configuration Tar-
getLM) is clear; the phrase-based system improves
the TstAvg score from 34.6 to 37.0 for Chinese-
English and from 50.0 to 53.4 for Arabic-English.
Interestingly, the hierarchical system and SAMT
benefit from the additional LMs to the same extent,
and retain their relative improvement compared to
the phrase-based system for Chinese-English.
Expressiveness: In order to evaluate how much
of the improvement is due to the relatively weaker
expressiveness of the phrase-based model, we tried
to regenerate translations produced by the hierar-
chical system with the phrase-based decoder by
limiting the phrases applied during decoding to
those matching the desired translation (?forced
translation?). By forcing the phrase-based system
to follow decoding hypotheses consistent with a
specific target output, we can determine whether
the phrase-based system could possibly generate
this output. We used the Chinese-to-English NIST
MT06 test (1664 sentences) set for this experi-
ment. Out of the hierarchical system?s translations,
1466 (88%) were generable by the phrase-based
system. The relevant part of a sentence for which
the hierarchical translation was not phrase-based
generable is shown in Figure 1. The reason for the
failure to generate the translation is rather unspec-
tacular: While the hierarchical system is able to
delete the Chinese word meaning ?already? using
the rule spanning [27-28], which it learned by gen-
eralizing a training phrase pair in which ?already?
was not explicitly represented in the target side, the
phrase-based system has to account for this Chi-
nese word either directly or in a phrase combining
the previous word (Chinese for ?epidemic?) or fol-
lowing word (Chinese for ?outbreak?).
Out of the generable forced translations, 1221
(83%) had a higher cost than the phrase-based sys-
tem?s preferred output; in other words, the fact
that the phrase-based system does not prefer these
forced translations is mainly inherent in the model
rather than due to search errors.
These results indicate that a phrase-based sys-
tem with sufficiently powerful reordering features
and LM might be able to narrow the gap to a hier-
archical system.
System \ %BLEU Dev MT08
Phr.b. reo=4 12.8 18.1
Phr.b. reo=7 14.2 19.9
Phr.b. reo=10 14.8* 20.2
Phr.b. reo=12 15.0 20.1
Hier. 16.0* 22.1
SAMT 16.1* 22.6
Table 2: Translation quality (% case-sensitive IBM-BLEU)
for Urdu-English NIST-large. We mark dev. scores with *
to indicate that the parameters of the corresponding decoder
were MER-tuned for this configuration.
4.2 Urdu-English
Table 2 shows results comparing phrase-based,
hierarchical and SAMT system on the Urdu-
English large-track NIST 2008 task. Systems were
trained on the bilingual data provided by the NIST
competition (207K sentence pairs; 2.2M Urdu
words / 2.1M English words) and used a n-gram
LM estimated from the English side of the parallel
data (4M 1..5-grams). We see clear improvements
moving from phrase-based to hierarchy, and addi-
tional improvements from hierarchy to syntax. As
with Chinese-to-English, longer-distance reorder-
ing plays an important role when translating from
Urdu to English (the phrase-based system is able
to improve the test score from 18.1 to 20.2), and
PSCFGs seem to be able to take this reordering
better into account than the phrasal distance-based
and lexical-reordering models.
4.3 Are all rules important?
One might assume that only a few hierarchical
rules, expressing reordering phenomena based on
common words such as prepositions, are sufficient
to obtain the desired gain in translation quality
1150
Figure 1: Example from NIST MT06 for which the hierarchical system?s first best hypothesis was not generable by the phrase-
based system. The hierarchical system?s decoding parse tree contains the translation in its leaves in infix order (shaded). Each
non-leaf node denotes an applied PSCFG rule of the form: [Spanned-source-positions:Left-hand-side->source/target]
Ch.-En. System \%BLEU Dev (MT04) MT02 MT03 MT05 MT06 MT08 TstAvg
Phraseb. 41.3* 41.0 41.8 39.4 35.2 27.9 37.0
Hier. default (mincount=3) 41.6* 40.9 42.5 40.3 36.5 28.7 37.8
Hier. mincount=4 41.4 41.0 42.5 40.4 36.1 28.4 37.7
Hier. mincount=8 41.0 41.0 42.0 40.5 35.7 27.8 37.4
Hier. mincount=16 40.7 40.3 41.5 40.0 35.2 27.8 37.0
Hier. mincount=32 40.4 40.0 41.5 39.5 34.8 27.5 36.6
Hier. mincount=64 39.8 40.0 40.9 39.1 34.6 27.3 36.4
Hier. mincount=128 39.4 39.8 40.3 38.7 34.0 26.6 35.9
Hier. 1NT 40.1* 39.8 41.1 39.1 35.1 28.1 36.6
Urdu-En. System \%BLEU Dev MT08
Phraseb. 15.0* 20.1
Hier. default (mincount=2) 16.0* 22.1
Hier. mincount=4 15.7 22.0
Hier. mincount=8 15.4 21.5
Hier. mincount=16 15.1 21.3
Hier. mincount=32 14.9 20.7
Hier. mincount=64 14.6 20.1
Hier. mincount=128 14.4 19.6
Hier. 1NT 15.3* 20.8
Table 3: Translation quality (% case-sensitive IBM-BLEU) for Chinese-English and Urdu-English NIST-large when restricting
the hierarchical rules. We mark dev. scores with * to indicate that the parameters of the corresponding decoder were MER-tuned
for this configuration.
over a phrase-based system. Limiting the number
of rules used could reduce search errors caused by
spurious ambiguity during decoding. Potentially,
hierarchical rules based on rare phrases may not
be needed, as these phrase pairs can be substituted
into the nonterminal spots of more general and
more frequently encountered hierarchical rules.
As Table 3 shows, this is not the case. In
these experiments for Hier., we retained all non-
hierarchical rules (i.e., phrase pairs) but removed
hierarchical rules below a threshold ?mincount?.
Increasing mincount to 16 (Chinese-English) or 64
(Urdu-English), respectively, already deteriorates
performance to the level of the phrase-based sys-
tem, demonstrating that the highly parameterized
reordering model implicit in using more rules does
result in benefits. This immediate reduction in
translation quality when removing rare rules can
be explained by the following effect. Unlike in
a phrase-based system, where any phrase can po-
tentially be reordered, rules in the PSCFG must
compose to generate sub-translations that can be
reordered. Removing rare rules, even those that
are highly lexicalized and do not perform any re-
ordering (but still include nonterminal symbols),
increases the likelihood that the glue rule is applied
simply concatenating span translations without re-
ordering.
Removing hierarchical rules occurring at most
twice (Chinese-English) or once (Urdu-English),
respectively, did not impact performance, and led
to a significant decrease in rule table size and de-
coding speed.
We also investigate the relative impact of the
1151
rules with two nonterminals, over using rules with
a single nonterminal. Using two nonterminals al-
lows more lexically specific reordering patterns at
the cost of decoding runtime. Configuration ?Hier.
1NT? represents a hierarchical system in which
only rules with at most one nonterminal pair are
extracted instead of two as in Configuration ?Hier.
default?. The resulting test set score drop is more
than one BLEU point for both Chinese-to-English
and Urdu-to-English.
5 Conclusion
In this work we investigated the value of PSCFG
approaches built upon state-of-the-art phrase-
based systems. Our experiments show that PSCFG
approaches can yield substantial benefits for lan-
guage pairs that are sufficiently non-monotonic.
Suprisingly, the gap (or non-gap) between phrase-
based and PSCFG performance for a given lan-
guage pair seems to be consistent across small and
large data scenarios, and for weak and strong lan-
guage models alike. In sufficiently non-monotonic
languages, the relative improvements of phrase-
based systems persist when compared against a
state-of-the art phrase-based system that is capable
of equally long reordering operations modeled by
a lexicalized distortion model and a strong n-gram
language model. We hope that this work addresses
several of the important questions that the research
community has regarding the impact and value of
these PSCFG approaches.
Acknowledgments
We thank Richard Zens and the anonymous re-
viewers for their useful comments and sugges-
tions.
References
Brants, Thorsten, Ashok C. Popat, Peng Xu, Franz J.
Och, and Jeffrey Dean. 2007. Large language mod-
els in machine translation. In Proc. of EMNLP-
CoNLL.
Charniak, Eugene. 2000. A maximum entropy-
inspired parser. In Proc. of HLT/NAACL.
Chiang, David. 2005. A hierarchical phrase-based
model for statistical machine translation. In Proc.
of ACL.
Chiang, David. 2007. Hierarchical phrase based trans-
lation. Computational Linguistics, 33(2):201?228.
DeNeefe, Steve, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What can syntax-based MT learn
from phrase-based MT? In Proc. of EMNLP-
CoNLL.
Huang, Liang and David Chiang. 2005. Better k-best
parsing. In Proc. of IWPT.
Huang, Liang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. In Proc. of ACL.
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of HLT/NAACL.
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
2004. Pharaoh: A beam search decoder for phrase-
base statistical machine translation models. In Proc.
of AMTA.
Marcu, Daniel, Wei Wang, Abdessamad Echihabi,
and Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proc. of EMNLP.
Och, Franz and Hermann Ney. 2004. The alignment
template approach to statistical machine translation.
Computational Linguistics, 30(4):417?449.
Och, Franz Josef, Christoph Tillmann, and Hermann
Ney. 1999. Improved alignment models for statis-
tical machine translation. In Proc. of EMNLP.
Och, Franz Josef. 2003. Minimum error rate training
in statistical machine translation. In Proc. of ACL.
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proc. of ACL.
Steedman, Mark. 1999. Alternative quantifier scope in
CCG. In Proc. of ACL.
Venugopal, Ashish, Andreas Zollmann, and Vogel
Stephan. 2007. An efficient two-pass approach to
synchronous-CFG driven statistical MT. In Proc. of
HLT/NAACL.
Zens, Richard and Hermann Ney. 2006. Discrimina-
tive reordering models for statistical machine trans-
lation. In Proc. of the Workshop on Statistical Ma-
chine Translation, HLT/NAACL.
Zollmann, Andreas and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart pars-
ing. In Proc. of the Workshop on Statistical Machine
Translation, HLT/NAACL.
1152
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1101?1109,
Beijing, August 2010
Large Scale Parallel Document Mining for Machine Translation
Jakob Uszkoreit Jay M. Ponte Ashok C. Popat Moshe Dubiner
Google, Inc.
{uszkoreit,ponte,popat,moshe}@google.com
Abstract
A distributed system is described that re-
liably mines parallel text from large cor-
pora. The approach can be regarded
as cross-language near-duplicate detec-
tion, enabled by an initial, low-quality
batch translation. In contrast to other ap-
proaches which require specialized meta-
data, the system uses only the textual con-
tent of the documents. Results are pre-
sented for a corpus of over two billion web
pages and for a large collection of digi-
tized public-domain books.
1 Introduction
While the World Wide Web provides an abun-
dance of readily available monolingual text, par-
allel data is still a comparatively scarce resource,
yet plays a crucially important role in training sta-
tistical machine translation systems.
We describe an approach to mining document-
aligned parallel text to be used as training data
for a statistical machine translation system. Pre-
vious approaches have focused on rather homo-
geneous corpora and relied on metadata such as
publication dates (Munteanu and Marcu, 2005;
Munteanu and Marcu, 2006; Udupa et al, 2009;
Do et al, 2009; Abdul-Rauf and Schwenk, 2009)
or information about document structure (Resnik
and Smith, 2003; Chen and Nie, 2000). In large
and unstructured collections of documents such as
the Web, however, metadata is often sparse or un-
reliable. Our approach, in contrast, scales com-
putationally to very large and diverse collections
of documents and does not require metadata. It is
based solely on the textual contents of the input
documents.
Casting the problem as one of cross-language
near duplicate detection, we use a baseline ma-
chine translation system to translate all input doc-
uments into a single language. However, the
words and phrases that are most discriminatory
for the purposes of information retrieval and du-
plicate detection are the relatively rare ones, pre-
cisely those that are less likely to be translated
well by the baseline translation system.
Our approach to circumvent this problem and
to avoid the prohibitive quadratic computational
complexity of the naive approach of performing a
comparison of every possible pair of input docu-
ments is similar to previous work in near duplicate
detection (Broder, 2000; Henzinger, 2006; Man-
ber, 1994) and noisy data retrieval (Harding et al,
1997).
We use shingles consisting of word n-grams to
construct relatively rare features from more com-
mon, in-vocabulary words. For each input doc-
ument, we identify a comparatively small set of
candidate pairings with documents sharing at least
a certain number of such features. We then per-
form a more expensive comparison between each
document and all documents in its candidate set
using lower order n-gram features that would typ-
ically be too frequent to be used efficiently in
forming candidate pairings, but provide a higher
coverage of the scored document pairs. Another
important aspect of our approach is that it can be
implemented in a highly parallel way, as we de-
scribe in the following section.
1101
2 System Description
The input is a set of documents from diverse
sources such as web pages and digitized books.
In a first stage, all documents are independently
translated into English using a baseline statistical
machine translation system.
We then extract two different sets of n-grams
from the translated documents: matching n-grams
that are used to construct the candidate sets as well
as scoring n-grams used only in the computation
of a score for a given pair of documents. This
stage generates two indexes: a forward index list-
ing all extracted scoring n-grams, indexed by doc-
Machine translate input data
Extract n-grams
Filter inverted index
by document frequency and 
number of original languages
Generate all pairs of documents 
sharing matching n-grams
Score unique document pairs,
querying the forward Index
Discard non-symmetric pairs
Join with original input data
Evaluate on reference document 
alignments
Fold global, per-scoring n-gram 
information from inverted index 
into forward index
Documents 
in Multiple 
Languages
English 
Translations
Forward Index
Inverted Index
Per-document n-best lists
Figure 1: Architecture of the Parallel Text Mining
System.
ument; and an inverted index referencing all doc-
uments from which we extracted a given match-
ing n-gram, indexed by n-grams. The inverted
index is also used to accumulate global informa-
tion about scoring n-grams, such as their docu-
ment frequency, yet for scoring n-grams we do
not accumulate a posting list of all documents in
which they occur.
In the next step, the system generates all possi-
ble pairs of documents for each matching n-gram
posting list in the inverted index. Since we keep
only those pairs of documents that originated in
different languages, we can discard posting lists
from the inverted index that contain only a single
document, i.e. those of singleton n-grams, or only
documents in a single language.
Crucially, we further discard posting lists for
matching n-grams whose frequency exceeds a
certain threshold. When choosing a sufficiently
large order for the matching n-grams, their long-
tailed distribution causes only a small fraction of
matching n-grams to be filtered out due to fre-
quency, as we show empirically in Section 5. It
is this filtering step that causes the overall runtime
of the system to be linear in the size of the input
data and allows the system to scale to very large
document collections.
In parallel, global information about scoring n-
grams accumulated in the inverted index that is
required for pairwise scoring, such as their doc-
ument frequency, is folded into the forward in-
dex by iterating over all forward index entries, re-
questing the respective per-feature quantities from
the inverted index and storing them with each oc-
currence of a scoring n-gram in an updated for-
ward index.
In the next stage, we compute pairwise scores
for all candidate document pairs, accessing the
forward index entry of each of the two scored doc-
uments to obtain the respective scoring n-grams.
Document pairs with a score below a given thresh-
old are discarded. For each input document, this
results in one n-best list per language. In the last
step we retain only those document pairs where
each document is contained in the n-best list of
the other document for its original language. Fi-
nally we perform a join of our identified transla-
tion pairs with the original text by making another
1102
pass over the original, untranslated input data
where the contents of document pairs with suffi-
ciently high scores are then aggregated and out-
put. Document pairings involving all languages
are identified simultaneously. Each stage of the
system fits well into the MapReduce program-
ming model (Dean and Ghemawat, 2004). The
general architecture is shown in Figure 1.
2.1 Pairwise Scoring
For scoring a pair of documents d and d?, the
forward index is queried for the entries for both
documents. Let Fd = {f1, f2, ...fn} and Fd? =
{f ?1, f ?2, ...f ?n?} be the sets of scoring n-grams in
the forward index entries of d and d?, respectively.
Let idf(f) = log |D|df(f) be the inverse document
frequency of a scoring n-gram f , where |D| is
the number of documents in the input corpus and
df(f) is the number documents from which we
extracted the feature f . Interpreting Fd and Fd? as
incidence vectors in the vector space of n-grams
and replacing each non-zero component f with
idf(f), we compute the score of the document pair
as the inverse document frequency weighted co-
sine similarity of Fd and Fd?
score(d, d?) = Fd ? Fd?||Fd|| ? ||Fd? || (1)
The per-document n-best lists are sorted ac-
cording to this score and document pairs for which
the score is below a threshold are discarded com-
pletely.
We do not use term frequency in the scoring
metric. In preliminary experiments, incorporat-
ing the term frequency to yield basic tf/idf as
well as using other information retrieval ranking
functions incorporating term frequencies such as
BM25 (Robertson et al, 1995) resulted in a degra-
dation of performance compared to the simpler
scoring function described above. We believe this
is due to the fact that, in contrast to the standard
information retrieval setting, the overall length of
our queries is on par with that of the documents in
the collection.
The scoring is completely agnostic regarding
the scoring n-grams? positions in the documents.
Since especially for long documents such as
books this may produce spurious matches, we ap-
ply an additional filter to remove document pairs
for which the relative ordering of the matching
scoring n-grams is very different. Together with
each scoring n-gram we also extract its relative
position in each document and store it in the for-
ward index. When scoring a document pair, we
compute the normalized permutation edit distance
(Cormode et al, 2001) between the two sequences
of overlapping n-grams sorted by their position in
the respective document. If this distance exceeds
a certain threshold, we discard the document pair.
2.2 Computational Complexity
By limiting the frequency of matching n-grams,
the complexity becomes linear. Let the tunable
parameter c be the maximum occurrence count for
matching n-grams to be kept in the inverted in-
dex. Let m be the average number of matching
n-grams extracted from a single document whose
count is below c and D be the set of documents
in the input corpus. Then the system generates up
to |D| ?m ? c candidate pairings. Scoring a given
candidate document pair according to cosine sim-
ilarity involves computing three dot-products be-
tween sparse vectors with one non-zero compo-
nent per scoring n-gram extracted and not filtered
from the respective document. Let s be the av-
erage number of such scoring n-grams per docu-
ment, which is bounded by the average document
length. Then the time complexity of the entire
document alignment is in
O(|D| ?m ? c ? s) (2)
and therefore linear in the number of input doc-
uments in the corpus and the average document
size.
The space complexity is dominated by the size
of the inverted and forward indexes, both of which
are linear in the size of the input corpus.
2.3 Sentence-Level Alignment
Further filtering is performed on a per-sentence
basis during per-document-pair sentence align-
ment of the mined text with a standard dynamic
programming sentence alignment algorithm using
sentence length and multilingual probabilistic dic-
tionaries as features. Afterwards we crudely align
1103
words within each pair of aligned source and tar-
get sentences. This crude alignment is used only
to filter nonparallel sentences. Let S be the set
of source words, T the set of target words and
S ? T the set of ordered pairs. Let the source
sentence contain words S0 ? S and the target
sentence contain words T0 ? T . An alignment
A0 ? S0 ? T0 will be scored by
score(A0) =
?
(s,t)?A0
ln p(s, t)p(s) p(t) (3)
where the joint probabilities p(s, t) and marginal
probabilities p(s), p(t) are taken to be the respec-
tive empirical distributions (without smoothing)
in an existing word aligned corpus. This is greed-
ily maximized and the result is divided by its ap-
proximate expected value
?
(s,t)?S0?T
p(s, t)
p(s) ln
p(s, t)
p(s) p(t) (4)
We discard sentence pairs for which the ratio be-
tween the actual and the expected score is less
than 1/3. We also drop sentence pairs for which
both sides are identical, or a language detector de-
clares them to be in the wrong language.
2.4 Baseline Translation System
To translate the input documents into English we
use phrase-based statistical machine translation
systems based on the log-linear formulation of the
problem (Och and Ney, 2002).
We train the systems on the Europarl Cor-
pus (Koehn, 2002), the DGT Multilingual
Translation Memory (European Commission
Directorate-General for Translation, 2007) and
the United Nations ODS corpus (United Nations,
2006). Minimum error rate training (Macherey
et al, 2008) under the BLEU criterion is used
to optimize the feature function weights on de-
velopment data consisting of the nv-dev2007 and
news-dev2009 data sets provided by the organiz-
ers of the 2007 and 2009 WMT shared translation
tasks1. We use a 4-gram language model trained
on a variety of large monolingual corpora. The
BLEU scores of our baseline translation system
1available at http://statmt.org
on the test sets from various WMT shared trans-
lation tasks are listed in Table 5. An empirical
analysis of the impact of the baseline translation
system quality on the data mining system is given
in Section 6.3.
3 Input Document Collections
We evaluate the parallel text mining system on
two input data sets:
web A collection of 2.5 Billion general pages
crawled from the Web, containing only pages
in Czech, English, French, German, Hungar-
ian and Spanish
books A collection of 1.5 Million public domain
books digitized using an optical character
recognition system. The collection consists
primarily of English, French and fewer Span-
ish volumes
3.1 Reference Sets
We created reference sets of groups of docu-
ments in multiple languages which are true trans-
lations of one another for both the web and the
books data set. Due to the presence of duplicates,
each reference pairing can contain more than a
single alternative translation per language. The
web reference set was constructed by exploiting
the systematic hyperlink structure of the web-site
http://america.gov/, that links pages in
one language to their respective translations into
one or more other languages. The resulting refer-
ence set contains documents in Arabic, Chinese,
English, French, Russian and Spanish, however,
for most English pages there is only one transla-
tion into one of the other languages. Overall, the
reference set contains 6,818 documents and 7,286
translation pairs.
The books reference set contains 30 manually
aligned groups of translations covering a total of
103 volumes in English and French.
4 Evaluation Metrics
The fact that the system outputs pairs of docu-
ments and the presence of duplicate documents in
the corpus motivate the use of modified versions
of precision and recall.
1104
Let C be a set of candidate parallel document
pairs and let R be a possibly incomplete reference
set of groups of parallel documents known to exist
in the corpus. Consider the following two subsets
of C:
? Matching pairs which are in some reference
cluster.
? Touching pairs which are non-matching but
have at least one document in some reference
cluster.
We define
Precision = |CMatching||CMatching|+ |CTouching|
and
Recall = |CMatching||R| (5)
5 Parameter Selection
We conducted a series of small-scale experiments
on only those documents contained in the web ref-
erence data set to empirically determine good set-
tings for the tunable parameters of the text min-
ing system. Among the most important parame-
ters are the orders of the n-grams used for pair-
ing documents as well as scoring them. Aside
from the obvious impact on the quality of the out-
put, these parameters have a very large influence
on the overall computational performance of the
system. The choice of the order of the extracted
matching n-grams is mainly a trade-off between
recall and efficiency. If the order is too large
the system will miss valid pairs; if too small the
the threshold on matching n-gram frequency will
need to be increased.
Figure 2 shows the F1-scores obtained run-
ning only on the documents contained in the web
reference set with different orders of matching
and scoring n-grams. Figure 3 shows the corre-
sponding number of pairwise comparisons made
when using different orders of matching n-grams.
While there is a drop of 0.01 in F1 score between
using 2-grams and 5-grams as matching n-grams,
this drop in quality seems to be well worth the 42-
fold reduction in resulting pairwise comparisons.
0.89
0.9
0.91
0.92
0.93
0.94
0.95
0.96
2 3 4 5
F1
Sc
ore
on
we
bT
est
Da
ta
Se
t
Scoring n-gram Order
2-gram matching
3-gram matching
4-gram matching
5-gram matching
Figure 2: F1 scores on the web reference set for
different scoring and matching n-gram orders.
105
106
107
2 3 4 5
Nu
mb
er
of
Pa
irw
ise
Co
mp
ari
son
s
Matching n-gram Order
Figure 3: Number of pairwise comparisons made
when using matching n-grams of different orders.
The largest portion of the loss in F1 score is in-
curred when increasing the matching n-gram or-
der from 4 to 5, the reduction in pairwise compar-
isons, however, is still more than twofold.
Table 1 shows the precision and recall on the
web reference set when running only on docu-
ments in the reference set using 5-grams as match-
ing n-grams and bigrams for scoring for differ-
ent values of the threshold on the cosine similar-
ity score. In this setting as well as in large-scale
experiments on both complete data sets described
in section 6.1, a threshold of 0.1 yields the highest
F1 score.
1105
score threshold 0.06 0.10 0.12 0.16 0.20
precision 0.92 0.97 0.98 0.99 0.99
recall 0.91 0.91 0.90 0.89 0.83
Table 1: Precision and recall on the web reference
set when running only on documents contained in
the reference set.
6 Evaluation
We run the parallel text mining system on the web
and books data sets using 5-grams for matching
and bigrams for scoring. In both cases we discard
matching n-grams which occurred in more than
50 documents and output only the highest scoring
candidate for each document.
In case of the web data set, we extract every 5-
gram as potential matching feature. For the books
data set, however, we downsample the number
of candidate matching 5-grams by extracting only
those whose integer fingerprints under some hash
function have four specific bits set, thus keeping
on average only 1/16 of the matching n-grams.
Here, we also restrict the total number of match-
ing n-grams extracted from any given document
to 20,000. Scoring bigrams are dropped from
the forward index if their document frequency ex-
ceeds 100,000, at which point their influence on
the pairwise score would be negligible.
Running on the web data set, the system on
average extracts 250 matching 5-grams per doc-
ument, extracting a total of approximately 430
Billion distinct 5-grams. Of those, 78% are
singletons and 21% only occur in a single lan-
guage. Only approximately 0.8% of all match-
ing n-grams are filtered due to having a docu-
ment frequency higher than 50. The forward in-
dex initially contains more than 500 Billion bi-
gram occurrences; after pruning out singletons
and bigrams with a document frequency larger
than 100,000, the number of indexed scoring fea-
ture occurrences is reduced to 40%. During scor-
ing, approximately 50 Billion pairwise compar-
isons are performed.
In total the n-gram extraction, document scor-
ing and subsequent filtering takes less than 24
hours on a cluster of 2,000 state-of-the-art CPUs.
The number of words after sentence-level fil-
tering and alignment that the parallel text mining
baseline books web
Czech 27.5 M 0 271.9 M
French 479.8 M 228.5 M 4,914.3 M
German 54.2 M 0 3,787.6 M
Hungarian 26.9 M 0 198.9 M
Spanish 441.0 M 15.0 M 4,846.8 M
Table 2: The number of words per language in the
baseline training corpora and extracted from the
two different data sets.
system extracted for the different languages from
each dataset are listed in Table 2.
score threshold 0.06 0.10 0.12 0.16 0.20
precision 0.88 0.93 0.95 0.97 0.97
recall 0.68 0.65 0.63 0.52 0.38
Table 3: Precision and recall on the reference set
when running on the complete web data set with
different score thresholds.
score threshold 0.06 0.10 0.12 0.16 0.20
precision 0.95 1.00 1.00 1.00 1.00
recall 0.71 0.71 0.71 0.48 0.38
Table 4: Precision and recall on the reference set
when running on the complete books data set with
different score thresholds.
6.1 Precision and Recall
Tables 3 and 4 show precision and recall on the re-
spective reference sets for the web and the books
input data sets. While the text mining system
maintains a very high precision, recall drops sig-
nificantly compared to running only on the doc-
uments in the reference set. One reason for this
behavior is that the number of n-grams in the test
data set which are sufficiently rare to be used as
queries drops with increasing amounts of input
data and in particular short documents which only
share a small number of matching n-grams any-
way, may happen to only share matching n-grams
with a too high document frequency. Further anal-
ysis shows that another, more significant factor is
the existence of multiple, possibly partial transla-
tions and near-duplicate documents which cause
symmetrization to discard valid document pairs
because each document in the pair is determined
by the document pair score to be more similar to
a different translation of a near-duplicate or sub-
1106
Language Pair Training Data WMT 2007 news commentary WMT 2008 news WMT 2009 news
Czech English baseline 21.59 14.59 16.46web 29.26 (+7.67) 20.16 (+5.57) 23.25 (+6.76)
German English baseline 27.99 20.34 20.03web 32.35 (+4.36) 23.22 (+2.88) 23.35 (+3.32)
Hungarian English baseline - 10.21 11.02web - 12.92 (+2.71) 14.68 (+3.66)
French English
baseline 34.26 22.14 26.39
books 34.73 (+0.47) 22.39 (+0.25) 27.15 (+0.76)
web 36.65 (+2.39) 23.22 (+1.08) 28.34 (+1.95)
Spanish English
baseline 43.67 24.15 26.88
books 44.07 (+0.40) 24.32 (+0.17) 27.16 (+0.28)
web 46.21 (+2.54) 25.52 (+1.37) 28.50 (+1.62)
English Czech baseline 14.78 12.45 11.62web 20.65 (+5.86) 18.70 (+6.25) 16.60 (+4.98)
English German baseline 19.89 14.67 14.31web 23.49 (+3.60) 16.78 (+2.11) 16.96 (+2.65)
English Hungarian baseline - 07.93 08.52web - 10.16 (+2.23) 11.42 (+2.90)
English French
baseline 31.59 22.29 25.14
books 31.92 (+0.33) 22.42 (+0.13) 25.46 (+0.32)
web 34.35 (+2.76) 23.56 (+1.27) 27.05 (+1.91)
English Spanish
baseline 42.05 24.65 25.85
books 42.05 24.79 (+0.14) 26.07 (+0.22)
web 45.21 (+3.16) 26.46 (+1.81) 27.79 (+1.94)
Table 5: BLEU scores of the translation systems trained on the automatically mined parallel corpora
and the baseline training data.
set of the document. This problem seems to affect
news articles in particular where there are often
multiple different translations of large subsets of
the same or slightly changed versions of the arti-
cle.
6.2 Translation Quality
Arabic English NIST 2006 NIST 2008
Baseline (UN ODS) 44.31 42.79
Munteanu and Marcu 45.13 43.86
Present work 44.72 43.64
Chinese English NIST 2006 NIST 2008
Baseline (UN ODS) 25.71 19.79
Munteanu and Marcu 28.11 21.69
Present work 28.08 22.02
Table 6: BLEU scores of the Chinese and Arabic
to English translation systems trained on the base-
line UN ODS corpus and after adding either the
Munteanu and Marcu corpora or the training data
mined using the presented approach.
We trained a phrase-based translation system
on the mined parallel data sets and evaluated it
on translation tasks for the language pairs Czech,
French, German, Hungarian and Spanish to and
from English, measuring translation quality with
the BLEU score (Papineni et al, 2002). The trans-
lation tasks evaluated are the WMT 2007 news
commentary test set as well the WMT 2008 and
2009 news test sets.
The parallel data for this experiment was mined
using the general settings described in the previ-
ous section and a threshold of 0.1 on the pairwise
score. We ensure that the test data is not included
in the training data by filtering out all sentences
from the training data that share more than 30%
of their 6-grams with any sentence from one of
the test corpora.
Table 5 shows the BLEU scores of the differ-
ent translation systems. The consistent and signif-
icant improvements in BLEU score demonstrate
the usefulness of the mined document pairs in
training a translation system.
Even though the presented approach works
on a less granular level than the sentence-level
approach of Munteanu and Marcu (2005), we
compare results on the same input data2 used
by those authors to automatically generate the
2LDC corpora LDC2005T12, LDC2005T14 and
LDC2006T02, the second editions of the Arabic, Chinese
and English Gigaword corpora.
1107
Sampling Rate WMT 2007 news commentary WMT 2008 news WMT 2009 news
degraded Cz?En En?Cz degraded Cz?En En?Cz degraded Cz?En En?Cz
1.0 21.59 29.26 20.65 14.59 20.16 18.70 16.46 23.25 16.60
0.5 20.12 29.16 20.55 13.65 20.16 18.71 15.44 23.16 16.56
0.25 18.59 29.09 20.61 12.79 20.09 18.58 14.35 23.18 16.50
0.125 16.69 29.10 20.39 11.87 20.07 18.48 13.05 23.06 16.53
0.0625 14.72 29.04 20.44 10.87 20.06 18.49 11.62 23.11 16.44
0.0312 12.60 28.75 20.28 09.71 19.97 18.45 10.43 23.04 16.41
Table 7: BLEU scores of the degraded Czech to English baseline systems used for translating Czech
documents from the web data set as well as those of Czech to and from English systems trained on data
mined using translations of varying quality created by sampling from the training data.
Arabic English and Chinese English sentence-
aligned parallel LDC corpora LDC2007T08 and
LDC2007T09. We trained Arabic and Chinese
English baseline systems on the United Nations
ODS corpus (United Nations, 2006); we also use
these to translate the non-English portions of the
input data to English. We then evaluate the effects
of also training on either the LDC2007T08 and
LDC2007T09 corpora or the parallel documents
mined by our approach in addition to the United
Nations ODS corpus on the NIST 2006 and 2008
MT evaluation test sets. The results are presented
in Table 6.
The approach proposed in (Munteanu and
Marcu, 2005) relies critically on the existence
of publication dates in order to be computation-
ally feasible, yet it still scales superlinearly in the
amount of input data. It could therefore not easily
be applied to much larger and less structured input
data collections. While our approach neither uses
metadata nor operates on the sentence level, in all
but one of the tasks, the system trained on the data
mined using our approach performs similarly or
slightly better.
6.3 Impact of Baseline Translation Quality
In order to evaluate the impact of the translation
quality of the baseline system on the quality of
the mined document pairs, we trained artificially
degraded Czech to English translation systems by
sampling from the baseline training data at de-
creasing rates. We translate the Czech subset of
the web document collection into English with
each of the degraded systems and apply the paral-
lel data mining system in the same configuration.
Table 7 shows the BLEU scores of the degraded
baseline systems and those resulting from adding
the different mined data sets to the non-degraded
Czech English and English Czech systems. De-
grading the input data translation quality by up to
8.9% BLEU results in a consistent but only com-
paratively small decrease of less than 0.6% BLEU
in the scores obtained when training on the mined
document pairs. This does not only show that the
impact of variations of the baseline system quality
on the data mining system is limited, but also that
the data mining system will already work with a
rather low quality baseline system.
7 Conclusion
We presented a scalable approach to mining paral-
lel text from collections of billions of documents
with high precision. The system makes few as-
sumptions about the input documents. We demon-
strated that it works well on different types of
data: a large collection of web pages and a col-
lection of digitized books. We further showed that
the produced parallel corpora can significantly im-
prove the quality of a state-of-the-art statistical
machine translation system.
8 Acknowledgments
We thank the anonymous reviewers for their in-
sightful comments.
References
Abdul-Rauf, Sadaf and Holger Schwenk. 2009. On
the use of comparable corpora to improve SMT per-
formance. In EACL, pages 16?23.
Broder, Andrei Z. 2000. Identifying and filtering near-
duplicate documents. In COM ?00: Proceedings of
the 11th Annual Symposium on Combinatorial Pat-
1108
tern Matching, pages 1?10, London, UK. Springer-
Verlag.
Chen, Jiang and Jian-Yun Nie. 2000. Parallel web
text mining for cross-language IR. In In In Proc. of
RIAO, pages 62?77.
Cormode, Graham, S. Muthukrishnan, and
Su?leyman Cenk Sahinalp. 2001. Permutation
editing and matching via embeddings. In ICALP
?01: Proceedings of the 28th International Collo-
quium on Automata, Languages and Programming,,
pages 481?492, London, UK. Springer-Verlag.
Dean, Jeffrey and Sanjay Ghemawat. 2004. MapRe-
duce: Simplified data processing on large clusters.
In Proceedings of the Sixth Symposium on Operat-
ing System Design and Implementation (OSDI-04),
San Francisco, CA, USA.
Do, Thi-Ngoc-Diep, Viet-Bac Le, Brigitte Bigi, Lau-
rent Besacier Eric, and Castelli. 2009. Mining a
comparable text corpus for a Vietnamese - French
statistical machine translation system. In Proceed-
ings of the 4th EACL Workshop on Statistical Ma-
chine Translation, pages 165?172, Athens, Greece,
March.
European Commission Directorate-General for Trans-
lation. 2007. DGT-TM parallel corpus.
http://langtech.jrc.it/DGT-TM.html.
Harding, Stephen M., W. Bruce Croft, and C. Weir.
1997. Probabilistic retrieval of OCR degraded text
using n-grams. In ECDL ?97: Proceedings of
the First European Conference on Research and
Advanced Technology for Digital Libraries, pages
345?359, London, UK. Springer-Verlag.
Henzinger, Monika. 2006. Finding near-duplicate
web pages: a large-scale evaluation of algorithms.
In SIGIR ?06: Proceedings of the 29th annual inter-
national ACM SIGIR conference on Research and
development in information retrieval, pages 284?
291, New York, NY, USA. ACM.
Koehn, Philipp. 2002. Europarl: A multilingual cor-
pus for evaluation of machine translation. Draft.
Macherey, Wolfgang, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum er-
ror rate training for statistical machine translation.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
725?734, Honolulu, Hi, October. Association for
Computational Linguistics.
Manber, Udi. 1994. Finding similar files in a large file
system. In Proceedings of the USENIX Winter 1994
Technical Conferenc.
Munteanu, Dragos Stefan and Daniel Marcu. 2005.
Improving machine translation performance by ex-
ploiting non-parallel corpora. Comput. Linguist.,
31(4):477?504.
Munteanu, Dragos Stefan and Daniel Marcu. 2006.
Extracting parallel sub-sentential fragments from
non-parallel corpora. In ACL.
Och, Franz Josef and Hermann Ney. 2002. Dis-
criminative training and maximum entropy models
for statistical machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 295?302,
Philadelphia, PA, USA.
Papineni, Kishore, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
311?318, Philadelphia, PA, USA.
Resnik, Philip and Noah A. Smith. 2003. The web
as a parallel corpus. Computational Linguistics,
29:349?380.
Robertson, S E, S Walker, S Jones, M M Hancock-
Beaulieu, and M Gatford. 1995. Okapi at TREC?3.
In Proceedings of the Third Text REtrieval Confer-
ence (TREC-3).
Udupa, Raghavendra, K. Saravanan, A. Kumaran, and
Jagadeesh Jagarlamudi. 2009. Mint: A method
for effective and scalable mining of named entity
transliterations from large comparable corpora. In
EACL, pages 799?807.
United Nations. 2006. ODS UN parallel corpus.
http://ods.un.org/.
1109
