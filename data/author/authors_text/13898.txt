Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 172?176,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
UPV-PRHLT English?Spanish system for WMT10
Germa?n Sanchis-Trilles and Jesu?s Andre?s-Ferrer and Guillem Gasco?
Jesu?s Gonza?lez-Rubio and Pascual Mart??nez-Go?mez and Martha-Alicia Rocha
Joan-Andreu Sa?nchez and Francisco Casacuberta
Instituto Tecnolo?gico de Informa?tica
Departamento de Sistemas Informa?ticos y Computacio?n
Universidad Polite?cnica de Valencia
{gsanchis|jandres|fcn}@dsic.upv.es
{ggasco|jegonzalez|pmartinez}@dsic.upv.es
{mrocha|jandreu}@dsic.upv.es
Abstract
In this paper, the system submitted by
the PRHLT group for the Fifth Work-
shop on Statistical Machine Translation of
ACL2010 is presented. On this evalua-
tion campaign, we have worked on the
English?Spanish language pair, putting
special emphasis on two problems derived
from the large amount of data available.
The first one, how to optimize the use of
the monolingual data within the language
model, and the second one, how to make
good use of all the bilingual data provided
without making use of unnecessary com-
putational resources.
1 Introduction
For this year?s translation shared task, the Pat-
tern Recognition and Human Language Technolo-
gies (PRHLT) research group of the Universidad
Polite?cnica de Valencia submitted runs for the
English?Spanish translation task. In this paper, we
report the configuration of such a system, together
with preliminary experiments performed to estab-
lish the final setup.
As in 2009, the central focus of the Shared Task
is on Domain Adaptation, where a system typi-
cally trained using out-of-domain data is adjusted
to translate news commentaries.
For the preliminary experiments, we used only a
small amount of the largest available bilingual cor-
pus, i.e. the United Nations corpus, by including
into our system only those sentences which were
considered similar.
Language model interpolation using a develop-
ment set was explored in this work, together with
a technique to cope with the problem of ?out of
vocabulary words?.
Finally, a reordering constraint using walls and
zones was used in order to improve the perfor-
mance of the submitted system.
In the final evaluation, our system was ranked
fifth, considering only primary runs.
2 Language Model interpolation
Nowadays, it is quite common to have very large
amounts of monolingual data available from sev-
eral different domains. Despite of this fact, in
most of the cases we are only interested in trans-
lating from one specific domain, as is the case in
this year?s shared task, where the provided mono-
lingual training data belonged to European parlia-
mentary proceedings, news related domains, and
the United Nations corpus, which consists of data
crawled from the web.
Although the most obvious thing to do is to con-
catenate all the data available and train a single
language model on the whole data, we also inves-
tigated a ?smarter? use of such data, by training
one language model for each of the available cor-
pora.
3 Similar sentences selection
Currently, it is common to of huge bilingual cor-
pora for SMT. For some common language pairs,
corpora of millions of parallel sentences are avail-
able. In some of the cases big corpora are used
as out-of-domain corpora. For example, in the
case of the shared task, we try to translate a news
text using a small in-domain bilingual news corpus
(News Commentary) and two big out-of-domain
corpora: Europarl and United Nations.
Europarl is a medium size corpus and can be
completely incorporated to the training set. How-
ever, the use of the UN corpus requires a big com-
putational effort. In order to alleviate this prob-
lem, we have chosen only those bilingual sen-
tences from the United Nations that are similar to
the in-domain corpus sentences. As a similarity
measure, we have chosen the alignment score.
Alignment scores have already been used as a
172
filter for noisy corpora (Khadivi and Ney, 2005).
We trained an IBM model 4 using GIZA++ (Och
and Ney, 2003) with the in-domain corpus and
computed the alignment scores over the United
Nations sentences. We assume that the alignment
score is a good measure of similarity.
An important factor in the alignment score is
the length of the sentences, so we clustered the
bilingual sentences in groups with the same sum of
source and target language sentence sizes. In each
of the groups, the higher the alignment score is,
the more similar the sentence is to the in-domain
corpus sentences. Hence, we computed the aver-
age alignment score for each one of the clusters
obtained for the corpus considered in-domain (i.e.
the News-Commentary corpus). This being done,
we assessed the similarity of a given sentence by
computing the probability of such sentence with
respect to the alignment model of the in-domain
corpus, and established the following similarity
levels:
? Level 1: Sentences with an alignment score
equal or higher than the in-domain average.
? Level 2: Sentences with an alignment score
equal or higher than the in-domain average,
minus one standard deviation.
? Level 3: Sentences with an alignment score
equal or higher than the in-domain average,
minus two standard deviations.
Naturally, such similarity levels establish parti-
tions of the out-of-domain corpus. Then, such par-
titions were included into the training set used for
building the SMT system, and re-built the com-
plete system from scratch.
4 Out of Vocabulary Recovery
As stated in the previous section, in order to avoid
a big computational effort, we do not use the
whole United Nations corpus to train the trans-
lation system. Out of vocabulary words are a
common problem for machine translation systems.
When translating the test set, there are test words
that are not in the reduced training set (out of vo-
cabulary words). Some of those out of vocabulary
words are present in the sentences discarded from
the United Nations Corpus. Thus, recovering the
discarded sentences with out of vocabulary words
is needed.
The out of vocabulary words recovery method
is simple: the out of vocabulary words from the
test, when taking into account the reduced training
set, are obtained and then discarded sentences that
contain at least one of them are retrieved. Then,
those sentences are added to the reduced training
set.
Finally, alignments with the resulting training
set were computed and the usual training proce-
dure for phrase-based systems was performed.
5 Walls and zones
In translation, as in other linguistics areas, punc-
tuation marks are essential as they help to un-
derstand the intention of a message and organise
the ideas to avoid ambiguity. They also indicate
pauses, hierarchies and emphasis.
In our system, punctuation marks have been
taken into account during decoding. Traditionally,
in SMT punctuation marks are treated as words
and this has undesirable effects (Koehn and Had-
dow, 2009). For example, commas have a high
probability of occurrence and many possible trans-
lations are generated. Most of them are not consis-
tent across languages. This introduces too much
noise to the phrase tables.
(Koehn and Haddow, 2009) established a
framework to specify reordering constraints with
walls and zones, where commas and end
of sentence are not mixed with various clauses.
Gains between 0.1 and 0.2 of BLEU are reported.
Specifying zones and walls with XML tags
in input sentences allows us to identify structured
fragments that the Moses decoder uses with the
following restrictions:
1. If a <zone> tag is detected, then a block
is identified and must be translated until a
</zone> tag is found. The text between tags
<zone> and </zone> is identified and trans-
lated as a block.
2. If the decoder detects a <wall/> tag, the text
is divided into a prefix and suffix and Moses
must translate all the words of the prefix be-
fore the suffix.
3. If both zones and walls are specified,
then local walls are considered where
the constraint 2 applies only to the area es-
tablished by zones.
173
corpus Language |S| |W | |V |
Europarl v5
Spanish
1272K
28M 154K
English 27M 106K
NC
Spanish
81K
1.8M 54K
English 1.6M 39K
Table 1: Main figures of the Europarl v5 and
News-Commentary (NC) corpora. K/M stands
for thousands/millions. |S| is the number of sen-
tences, |W | the number of running words, and |V |
the vocabulary size. Statistics are reported on the
tokenised and lowercased corpora.
We used quotation marks, parentheses, brackets
and dashes as zone delimiters. Quotation marks
(when appearing once in the sentence), com-
mas, colons, semicolons, exclamation and ques-
tion marks and periods are used as wall delimiters.
The use of zone delimiters do not alter the per-
formance. When using walls, a gain of 0.1
BLEU is obtained in our best model.
6 Experiments
6.1 Experimental setup
For building our SMT systems, the open-source
SMT toolkit Moses (Koehn et al, 2007) was used
in its standard setup. The decoder includes a log-
linear model comprising a phrase-based transla-
tion model, a language model, a lexicalised dis-
tortion model and word and phrase penalties. The
weights of the log-linear interpolation were opti-
mised by means of MERT (Och, 2003). In addi-
tion, a 5-gram LM with Kneser-Ney (Kneser and
Ney, 1995) smoothing and interpolation was built
by means of the SRILM (Stolcke, 2002) toolkit.
For building our baseline system, the News-
Commentary and Europarl v5 (Koehn, 2005) data
were employed, with maximum sentence length
set to 40 in the case of the data used to build the
translation models, and without restriction in the
case of the LM. Statistics of the bilingual data can
be seen in Table 1.
In all the experiments reported, MERT was run
on the 2008 test set, whereas the test set 2009 was
considered as test set as such. In addition, all the
experiments described below were performed in
lowercase and tokenised conditions. For the fi-
nal run, the detokenisation and recasing was per-
formed according to the technique described in the
Workshop baseline description.
corpus |S| |W | |V |
Europarl 1822K 51M 172K
NC 108K 3M 68K
UN 6.2M 214M 411K
News 3.9M 107M 512K
Table 2: Main figures of the Spanish resources
provided: Europarl v5, News-Commentary (NC),
United Nations (UN) and News-shuffled (News).
6.2 Language Model interpolation
The final system submitted to the shared task
included a linear interpolation of four language
models, one for each of the monolingual resources
available for Spanish (see Table 2). The results
can be seen in Table 3. As a first experiment, only
the in-domain corpus, i.e. the News-Commentary
data (NC data) was used for building the LM.
Then, all the available monolingual Spanish data
was included into a single LM, by concatenat-
ing all the data together (pooled). Next, in
interpolated, one LM for each one of the
provided monolingual resources was trained, and
then they were linearly interpolated so as to min-
imise the perplexity of the 2008 test set, and fed
such interpolation to the SMT system. We found
out that weights were distributed quite unevenly,
since the News-shuffled LM received a weight of
0.67, whereas the other three corpora received a
weight of 0.11 each. It must be noted that even
the in-domain LM received a weight of 0.11 (less
than the News-shuffled LM). The reason for this
might be that, although the in-domain LM should
be more appropriate and should receive a higher
weight, the News-shuffled corpus is also news re-
lated (hence not really out-of-domain), but much
larger. For this reason, the result of using only
such LM (News) was also analysed. As expected,
the translation quality dropped slightly. Never-
theless, since the differences are not statistically
significant, we used the News-shuffled LM for in-
ternal development purposes, and the interpolated
LM only whenever an improvement prooved to be
useful.
6.3 Including UN data
We analysed the impact of the selection technique
detailed in Section 3. In this case, the LM used
was the interpolated LM described in the previous
section. The result can be seen in Table 4. As
it can be seen, translation quality as measured by
174
Table 3: Effect of considering different LMs
LM used BLEU
NC data 21.86
pooled 23.53
interpolated 24.97
news 24.79
BLEU improves constantly as the number of sen-
tences selected increases. However, further sen-
tences were not included for computational rea-
sons.
In the same table, we also report the effect of
adding the UN sentences selected by our out-of-
vocabulary technique described in Section 4. In
this context, it should be noted that MERT was
not rerun once such sentences had been selected,
since such sentences are related with the test set,
and not with the development set on which MERT
is run.
Table 4: Effect of including selected sentences
system BLEU
baseline 24.97
+ oovs 25.08
+ Level 1 24.98
+ Level 2 25.07
+ Level 3 25.13
6.4 Final system
Since the News-shuffled, UN and Europarl cor-
pora are large corpora, a new LM interpolation
was estimated by using a 6-gram LM on each one
of these corpora, obtaining a gain of 0.17 BLEU
points by doing so. Further increments in the n-
gram order did not show further improvements.
In addition, preliminary experimentation re-
vealed that the use of walls, as described in
Section 5, also provided slight improvements, al-
though using zones or combining both did not
prove to improve further. Hence, only walls
were included into the final system.
Lastly, the final system submitted to the Work-
shop was the result of combining all the techniques
described above. Such combination yielded a fi-
nal BLEU score of 25.31 on the 2009 test set, and
28.76 BLEU score on the 2010 test set, both in
tokenised and lowercased conditions.
7 Conclusions and future work
In this paper, the SMT system presented by the
UPV-PRHLT team for WMT 2010 has been de-
scribed. Specifically, preliminary results about
how to make use of larger data collections for
translating more focused test sets have been pre-
sented.
In this context, there are still some things which
need a deeper investigation, since the results pre-
sented here give only a small insight about the po-
tential of the similar sentence selection technique
described.
However, a deeper analysis is needed in order
to assess the potential of such technique and other
strategies should be implemented to explore new
kids of reordering constraints.
Acknowledgments
This paper is based upon work supported by
the EC (FEDER/FSE) and the Spanish MICINN
under the MIPRCV ?Consolider Ingenio 2010?
program (CSD2007-00018),iTrans2 (TIN2009-
14511) project, and the FPU scholarship AP2006-
00691. This work was also supported by the Span-
ish MITyC under the erudito.com (TSI-020110-
2009-439) project and by the Generalitat Valen-
ciana under grant Prometeo/2009/014 and schol-
arships BFPI/2007/117 and ACIF/2010/226 and
by the Mexican government under the PROMEP-
DGEST program.
References
Shahram Khadivi and Hermann Ney. 2005. Automatic
filtering of bilingual corpora for statistical machine
translation. In Natural Language Processing and In-
formation Systems, 10th Int. Conf. on Applications
of Natural Language to Information Systems, vol-
ume 3513 of Lecture Notes in Computer Science,
pages 263?274, Alicante, Spain, June. Springer.
R. Kneser and H. Ney. 1995. Improved backing-off
for m-gram language modeling. IEEE International
Conference on Acoustics, Speech and Signal Pro-
cessing, II:181?184, May.
Philipp Koehn and Barry Haddow. 2009. Edinburgh?s
submission to all tracks of the WMT2009 shared
task with reordering and speed improvements to
Moses. In The 4th EACL Workshop on Statistical
Machine Translation, ACL, pages 160?164, Athens,
Greece, March. Springer.
P. Koehn et al 2007. Moses: Open Source Toolkit for
Statistical Machine Translation. In Proceedings of
175
the ACL Demo and Poster Sessions, pages 177?180,
Prague, Czech Republic.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT Summit.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training in
Statistical Machine Translation. In Proceedings of
ACL, pages 160?167, Sapporo, Japan.
A. Stolcke. 2002. SRILM ? an extensible language
modeling toolkit. In Proc. of ICSLP?02, pages 901?
904, September.
176
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 296?300,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
The UPV-PRHLT Combination System for WMT 2010
Jesu?s Gonza?lez-Rubio and Jesu?s Andre?s-Ferrer and Germa?n Sanchis-Trilles
Guillem Gasco? and Pascual Mart??nez-Go?mez and Martha-Alicia Rocha
Joan-Andreu Sa?nchez and Francisco Casacuberta
Instituto Tecnolo?gico de Informa?tica
Departamento de Sistemas Informa?ticos y Computacio?n
Universidad Polite?cnica de Valencia
{jegonzalez|jandres|gsanchis}@dsic.upv.es
{ggasco|pmartinez|mrocha}@dsic.upv.es
{jandreu|fcn}@dsic.upv.es
Abstract
UPV-PRHLT participated in the System
Combination task of the Fifth Workshop
on Statistical Machine Translation (WMT
2010). On each translation direction, all
the submitted systems were combined into
a consensus translation. These consen-
sus translations always improve transla-
tion quality of the best individual system.
1 Introduction
The UPV-PRHLT approach to MT system combi-
nation is based on a refined version of the algo-
rithm described in (Gonza?lez-Rubio and Casacu-
berta, 2010), with additional information to cope
with hypotheses of different quality.
In contrast to most of the previous approaches
to combine the outputs of multiple MT sys-
tems (Bangalore et al, 2001; Jayaraman and
Lavie, 2005; Matusov et al, 2006; Schroeder et
al., 2009), which are variations over the ROVER
voting scheme (Fiscus, 1997), we consider the
problem of computing a consensus translation as
the problem of modelling a set of string patterns
with an adequate prototype. Under this frame-
work, the translation hypotheses of each of the
MT systems are considered as individual patterns
in a set of string patterns. The (generalised) me-
dian string, which is the optimal prototype of a set
of strings (Fu, 1982), is the chosen prototype to
model the set of strings.
2 System Combination Algorithm
The median string of a set is defined as the string
that minimises the sum of distances to the strings
in the set. Therefore, defining a distance between
strings is the primary problem to deal with.
The most common definition of distance be-
tween two strings is the Levenshtein distance,
also known as edit distance (ED). This metric
computes the optimal sequence of edit operations
(insertions, deletions and substitutions of words)
needed to transform one string into the other. The
main problem with the ED is its dependence on the
length of the compared strings. This fact led to the
definition of a new distance whose value is inde-
pendent from the length of the strings compared.
This normalised edit distance (NED) (Vidal et al,
1995) is computed by averaging the number of edit
operations by the length of the edit path. The ex-
perimentation in this work was carried out using
the NED.
2.1 Median String
Given a set E = e1, . . . , en, . . . , eN of translation
hypotheses from N MT systems, let ? be the vo-
cabulary in the target language and ?? be the free
monoid over that vocabulary (E ? ??). The me-
dian string of the set E (noted as M(E)) can be
formally defined as:
M(E) = argmin
e????
N
?
n=1
[
wn ? D(e?, en)
]
, (1)
where D is the distance used to compare two
strings and the value wn, 1 ? n ? N weights
the contribution of the hypothesis n to the sum of
distances, and therefore, it denotes the significance
of hypothesis n in the computation of the median
string. The value wn can be seen as a measure of
the ?quality? of hypothesis n.
Computing the median string is a NP-Hard
problem (de la Higuera and Casacuberta, 2000),
therefore we can only build approximations to the
median string by using several heuristics. In this
work, we follow two different approximations: the
set median string (Fu, 1982) and the approximate
median string (Mart??nez et al, 2000).
296
2.2 Set Median String
The most straightforward approximation to the
median string corresponds to the search of a set
median string. Under this approximation, the
search is constrained to the strings in the given in-
put set. The set median string can be informally
defined as the most ?centred? string in the set. The
set median string of the set E (noted as Ms(E))
is given by:
Ms(E) = argmin
e??E
N
?
n=1
[
wn ? D(e?, en)
]
. (2)
The set median string can be computed in poly-
nomial time (Fu, 1982; Juan and Vidal, 1998).
Unfortunately, in some cases, the set median may
not be a good approximation to the median string.
For example, in the extreme case of a set of two
strings, either achieves the minimum accumulated
distance to the set. However, the set median string
is a useful initialisation in the computation of the
approximate median string.
2.3 Approximate Median String
A good approximation to efficiently compute the
median string is proposed in (Mart??nez et al,
2000). To compute the approximate median string
of the set E, the algorithm starts with an initial
string e which is improved by successive refine-
ments in an iterative process. This iterative pro-
cess is based on the application of different edit
operations over each position of the string e look-
ing for a reduction of the accumulated distance to
the strings in the set. Algorithm 1 describes this
iterative process.
The initial string can be a random string or
a string computed from the set E. Martinez et
al. (2000) proposed two kinds of initial strings: the
set median string of E and a string computed by a
greedy algorithm, both of them obtained similar
results. In this work, we start with the set median
string in the initialisation of the computation of the
approximate median string of the set E. Over this
initial string we apply the iterative procedure de-
scribed in Algorithm 1 until there is no improve-
ment. The final median string may be different
from the original hypotheses.
The computational time cost of Algorithm 1 is
linear with the number of hypotheses in the com-
bination, and usually only a moderate number of
iterations is needed to converge.
For each position i in the string e:
1. Build alternatives:
Substitution: Make x = e. For each word a ? ?:
? Make x? the result string of substituting the ith
word of x by a.
? If the accumulated distance of x? to E is lower
than the accumulated distance from x to E, then
make x = x?.
Deletion: Make y the result string of deleting the ith
word of e.
Insertion: Make z = e. For each word a ? ?:
? Make z? the result of inserting a at position i of
e.
? If the accumulated distance from z? to E is lower
than the accumulated distance from z to E, then
make z = z?.
2. Choose an alternative:
? From the set {e,x,y, z} take the string e? with
less accumulated distance to E. Make e = e?.
Algorithm 1: Iterative process to refine a string
e in order to reduce its accumulated distance to a
given set E.
3 Experiments
Experiments were conducted on all the 8 transla-
tion directions cz?en, en?cz, de?en, en?de,
es?en, en?es, fr?en and en?fr. Some of the
entrants to the shared translation task submit lists
of n-best translations, but, in our experience, if a
large number of systems is available, using n-best
translations does not allow to obtain better consen-
sus translations than using single best translations,
but raises computation time significantly. Conse-
quently, we compute consensus translations only
using the single best translation of each individ-
ual MT system. Table 1 shows the number of sys-
tems submitted and gives an overview of the test
corpus on each translation direction. The number
of running words is the average number of run-
ning words in the test corpora, from where the
consensus translations were computed; the vocab-
ulary is the merged vocabulary of these test cor-
pora. All the experiments were carried out with
the true-cased, detokenised version of the tuning
and test corpora, following the WMT 2010 sub-
mission guidelines.
3.1 Evaluation Criteria
We will present translation quality results in terms
of translation edit rate (TER) (Snover et al, 2006)
and bilingual evaluation understudy (BLEU) (Pa-
297
cz?en en?cz de?en en?de es?en en?es fr?en en?fr
Submitted systems 6 11 16 12 8 10 14 13
Avg. Running words 45K 37K 47K 41K 47K 47K 47K 49K
Distinct words 24K 51K 38K 40K 23K 30K 27K 37K
Table 1: Number of systems submitted and main figures of test corpora on each translation direction. K
stands for thousands of elements.
pineni et al, 2002). TER is computed as the num-
ber of edit operations (insertions, deletions and
substitutions of single words and shifts of word se-
quences) to convert the system hypothesis into the
reference translation. BLEU computes a geomet-
ric mean of the precision of n-grams multiplied by
a factor to penalise short sentences.
3.2 Weighted Sum of Distances
In section 2, we define the median string of a set
as the string which minimises a weighted sum of
distances to the strings in the set (Eq. (1)). The
weights wn in the sum can be tuned. We compute
a weight value for each MT system as a whole, i.e.
all the hypotheses of a given MT system share the
same weight value. We study the performance of
different sets of weight looking for improvements
in the quality of the consensus translations. These
weight values are derived from different automatic
MT evaluation measures:
? BLEU score of each system.
? 1.0 minus TER score of each system.
? Number of times the hypothesis of each sys-
tem is the best TER-scoring translation.
We estimate these scores on the tuning corpora.
A normalisation is performed to transform these
scores into the range [0.0, 1.0]. After the normal-
isation, a weight value of 0.0 is assigned to the
lowest-scoring hypothesis, i.e. the lowest-scoring
hypothesis is not taking into account in the com-
putation of the median string.
3.3 System Combination Results
Our framework to compute consensus translations
allows multiple combinations varying the median
string algorithm or the set of weight values used
in the weighted sum of distances. To assure the
soundness of our submission to the WMT 2010
system combination task, the experiments on the
tuning corpora were carried out in a leaving-one-
out fashion dividing the tuning data into 5 parts
and averaging translation results over these 5 par-
titions. On each of the experiments, 4 of the par-
titions are devoted to obtain the weight values for
the weighted sum of distances while BLEU and
TER scores are calculated on the consensus trans-
lations of the remaining partition.
Table 2 shows, on each translation direction,
the performance of the consensus translations on
the tuning corpora. The consensus translations
were computed with the set median string and the
approximated median string using different sets
of weight values: Uniform, all weights are set
to 1.0, BLEU-based weights, TER-based weights
and oracle-based weights. In addition, we display
the performance of the best of the individual MT
systems for comparison purposes. The number of
MT systems combined for each translation direc-
tion is displayed between parentheses.
On all the translation directions under study, the
consensus translations improved the results of the
best individual systems. E.g. TER improved from
66.0 to 63.3 when translating from German into
English. On average, the set median strings per-
formed better than the best individual system, but
its results were always below the performance of
the approximate median string. The use of weight
values computed from MT quality measures al-
lows to improve the quality of the consensus trans-
lation computed. Specially, oracle-based weight
values that, except for the cz?en task, always per-
form equal or better than the other sets of weight
values. We have observed that no improvements
can be achieved with uniform weight values; it is
necessary to penalise low quality hypotheses.
To compute our primary submission to the
WMT 2010 system combination task we choose
the configurations that obtain consensus transla-
tions with highest BLEU score on the tuning cor-
pora. The approximate median string using oracle-
based scores is the chosen configuration for all
translation directions, except on the cz?en trans-
lation direction for which TER-based weights per-
formed better. As our secondary submission we
298
Single Set median Approximated median
best Uniform Bleu Ter Oracle Uniform Bleu Ter Oracle
cz?en (6) BLEU 17.6 16.5 17.8 18.2 17.6 17.1 18.5 18.5 18.0TER 64.5 68.7 67.6 65.2 64.5 67.0 65.9 65.4 64.4
en?cz (11) BLEU 11.4 10.1 10.9 10.7 11.0 10.1 10.7 10.7 11.0TER 75.3 75.1 74.3 74.2 74.2 73.9 73.4 73.3 73.0
de?en (16) BLEU 19.0 19.0 19.1 19.3 19.7 19.3 19.8 19.9 20.1TER 66.0 65.4 65.2 65.0 64.6 64.4 63.4 63.4 63.3
en?de (12) BLEU 11.9 11.6 11.7 11.7 12.0 11.6 11.8 11.8 12.0TER 74.3 74.1 74.1 74.0 73.7 72.7 72.9 72.7 72.6
es?en (8) BLEU 23.2 23.0 23.3 23.2 23.6 23.1 23.9 23.8 24.2TER 60.2 60.6 59.8 59.8 59.5 60.0 59.2 59.4 59.1
en?es (10) BLEU 23.3 23.0 23.3 23.4 24.0 23.6 23.8 23.8 24.2TER 60.1 60.1 59.9 59.7 59.5 59.0 59.1 58.9 58.6
fr?en (14) BLEU 23.3 22.9 23.2 23.2 23.4 23.4 23.8 23.8 23.9TER 61.1 61.2 60.9 60.9 60.7 60.6 60.0 60.1 59.9
en?fr (13) BLEU 22.7 23.4 23.5 23.6 23.8 23.3 23.6 23.7 23.8TER 62.3 61.0 61.0 60.9 60.6 60.2 60.1 60.0 60.0
Table 2: Consensus translation results (case-sensitive) on the tuning corpora with the set median string
and the approximate median string using different sets of weights: Uniform, BLEU-based, TER-based
and oracle-based. The number of systems being combined for each translation direction is in parentheses.
Best consensus translation scores are in bold.
Best Secondary Primary
BLEU TER BLEU TER BLEU TER
cz?en 18.2 63.9 18.3 66.7 19.0 65.1
en?cz 10.8 75.2 11.3 73.6 11.6 71.9
de?en 18.3 66.6 19.1 65.4 19.6 63.9
en?de 11.6 73.4 11.7 72.9 11.9 71.7
es?en 24.7 59.0 24.9 58.9 25.0 58.2
en?es 24.3 58.4 24.9 57.3 25.3 56.3
fr?en 23.7 59.7 23.6 59.8 23.9 59.4
en?fr 23.3 61.3 23.6 59.9 24.1 58.9
Table 3: Translation scores (case-sensitive) on the
test corpora of our primary and secondary submis-
sions to the WMT 2010 system combination task.
chose the set median string using the same set of
weight values chosen for the primary submission.
We compute MT quality scores on the WMT
2010 test corpora to verify the results on the tuning
data. Table 3 displays, on each translation direc-
tion, the results on the test corpora of our primary
and secondary submissions and of the best indi-
vidual system. These results confirm the results
on the tuning data. On all translation directions,
our submissions perform better than the best indi-
vidual systems as measured by BLEU and TER.
4 Summary
We have studied the performance of two consen-
sus translation algorithms that based in the compu-
tation of two different approximations to the me-
dian string. Our algorithms use a weighted sum of
distances whose weight values can be tuned. We
show that using weight values derived from auto-
matic MT quality measures computed on the tun-
ing corpora allow to improve the performance of
the best individual system on all the translation di-
rections under study.
Acknowledgements
This paper is based upon work supported
by the EC (FEDER/FSE) and the Spanish
MICINN under the MIPRCV ?Consolider In-
genio 2010? program (CSD2007-00018), the
iTransDoc (TIN2006-15694-CO2-01) and iTrans2
(TIN2009-14511) projects and the FPU scholar-
ship AP2006-00691. This work was also sup-
ported by the Spanish MITyC under the eru-
dito.com (TSI-020110-2009-439) project and by
the Generalitat Valenciana under grant Prom-
eteo/2009/014 and scholarships BFPI/2007/117
and ACIF/2010/226 and by the Mexican govern-
ment under the PROMEP-DGEST program.
299
References
S. Bangalore, G. Bodel, and G. Riccardi. 2001. Com-
puting consensus translation from multiple machine
translation systems. In IEEE Workshop on ASRU,
pages 351?354.
C. de la Higuera and F. Casacuberta. 2000. Topology
of strings: Median string is np-complete. Theoreti-
cal Computer Science, 230:39?48.
J. Fiscus. 1997. A post-processing system to yield
reduced word error rates: Recogniser output voting
error reduction (rover).
K.S. Fu. 1982. Syntactic Pattern Recognition and Ap-
plications. Prentice Hall.
J. Gonza?lez-Rubio and F. Casacuberta. 2010. On the
use of median string for multi-source translation.
In Proceedings of 20th International Conference on
Pattern Recognition, Istambul, Turkey, May 27-28.
S. Jayaraman and A. Lavie. 2005. Multi-engine ma-
chine translation guided by explicit word matching.
In Proc. of EAMT, pages 143?152.
A. Juan and E. Vidal. 1998. Fast Median Search in
Metric Spaces. In Proc. of SPR, volume 1451 of
Lecture Notes in Computer Science, pages 905?912.
C. D. Mart??nez, A. Juan, and F. Casacuberta. 2000.
Use of Median String for Classification. In Proc. of
ICPR, volume 2, pages 907?910.
E. Matusov, N. Ueffing, and H-Ney. 2006. Computing
consensus translation from multiple machine trans-
lation systems using enhanced hypotheses align-
ment. In Proc. of EACL, pages 33?40.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proc. of ACL, pages 311?318.
J. Schroeder, T. Cohn, and P. Koehn. 2009. Word lat-
tices for multi-source translation. In Proc. of EACL,
pages 719?727.
M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and
J. Makhoul. 2006. A study of TER with targeted
human annotation. In Proc. of AMTA, pages 223?
231.
E. Vidal, A. Marzal, and P. Aibar. 1995. Fast compu-
tation of normalized edit distances. IEEE Transac-
tions on PAMI, 17(9):899?902.
300
Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 25?33,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
Using Unlabeled Dependency Parsing for Pre-reordering
for Chinese-to-Japanese Statistical Machine Translation
Dan Han1,2 Pascual Mart??nez-Go?mez2,3 Yusuke Miyao1,2
Katsuhito Sudoh4 Masaaki Nagata4
1The Graduate University For Advanced Studies
2National Institute of Informatics, 3The University of Tokyo
4NTT Communication Science Laboratories, NTT Corporation
{handan,pascual,yusuke}@nii.ac.jp
{sudoh.katsuhito,nagata.masaaki}@lab.ntt.co.jp
Abstract
Chinese and Japanese have a different sen-
tence structure. Reordering methods are
effective, but need reliable parsers to ex-
tract the syntactic structure of the source
sentences. However, Chinese has a loose
word order, and Chinese parsers that ex-
tract the phrase structure do not perform
well. We propose a framework where only
POS tags and unlabeled dependency parse
trees are necessary, and linguistic knowl-
edge on structural difference can be en-
coded in the form of reordering rules. We
show significant improvements in transla-
tion quality of sentences from news do-
main, when compared to state-of-the-art
reordering methods.
1 Introduction
Translation between Chinese and Japanese lan-
guages gains interest as their economic and polit-
ical relationship intensifies. Despite their linguis-
tic influences, these languages have different syn-
tactic structures and phrase-based statistical ma-
chine translation (SMT) systems do not perform
well. Current word alignment models (Och and
Ney, 2003) account for local differences in word
order between bilingual sentences, but fail at cap-
turing long distance word alignments. One of
the main problems in the search of the best word
alignment is the combinatorial explosion of word
orders, but linguistically-motivated heuristics can
help to guide the search.
This work explores syntax-informed pre-
reordering for Chinese; that is, we obtain syntactic
structures of Chinese sentences, reorder the words
to resemble the Japanese word order, and then
translate the reordered sentences using a phrase-
based SMT system. However, Chinese parsers
have difficulties in extracting reliable syntactic in-
formation, mainly because Chinese has a loose
word order and few syntactic clues such as inflec-
tion and function words.
On one hand, parsers implementing head-driven
phrase structure grammars infer a detailed con-
stituent structure, and such a rich syntactic struc-
ture can be exploited to design well informed re-
ordering methods. However, inferring abundant
syntactic information often implies introducing er-
rors, and reordering methods that heavily rely on
detailed information are sensitive to those parsing
errors (Han et al, 2012).
On the other hand, dependency parsers are com-
mitted to the simpler task of finding dependency
relations and dependency labels, which can also be
useful to guide reordering (Xu et al, 2009). How-
ever, reordering methods that rely on those depen-
dency labels will also be prone to errors, specially
in the case of Chinese since it has a richer set of
dependency labels when compared to other lan-
guages. Since improving parsers for Chinese is
challenging, we thus aim at reducing the influence
of parsing errors in the reordering procedure.
We present a hybrid approach that boosts the
performance of phrase-based SMT systems by
pre-reordering the source language using unla-
beled parse trees augmented with constituent
information derived from Part-of-Speech tags.
Specifically, we propose a framework to pre-
reorder a Subject-Verb-Object (SVO) language,
in order to improve its translation to a Subject-
Object-Verb (SOV) language, where the only re-
quired syntactic information are POS tags and un-
labeled dependency parse trees. We test the per-
formance of our pre-reordering method and com-
pare it to state-of-the-art reordering methods in the
news domain for Chinese.
In the next section, we describe similar work on
pre-reordering methods for language pairs that in-
25
volve either Chinese or Japanese, and explain how
our method builds upon them. From a linguis-
tic perspective, we describe in section 3 our ob-
servations of reordering issues between Chinese
and Japanese and detail how our framework solves
those issues. In section 4 we assess to what extent
our pre-reordering method succeeds in reordering
words in Chinese sentences to resemble the order
of Japanese sentences, and measure its impact on
translation quality. The last section is dedicated to
discuss our findings and point to future directions.
2 Related Work
Although there are many works on pre-reordering
methods for other languages to English translation
or inverse (Xia and McCord, 2004; Xu et al, 2009;
Habash, 2007; Wang et al, 2007; Li et al, 2007;
Wu et al, 2011), reordering method for Chinese-
to-Japanese translation, which is a representative
of long distance language pairs, has received little
attention.
The most related work to ours is in (Han et al,
2012), in which the authors introduced a refined
reordering approach by importing an existing re-
ordering method for English proposed in (Isozaki
et al, 2010b). These reordering strategies are
based on Head-driven phrase structure grammars
(HPSG) (Pollard and Sag, 1994), in that the re-
ordering decisions are made based on the head of
phrases. Specifically, HPSG parsers (Miyao and
Tsujii, 2008; Yu et al, 2011) are used to extract the
structure of sentences in the form of binary trees,
and head branches are swapped with their depen-
dents according to certain heuristics to resemble
the word order of the target language. However,
those strategies are sensitive to parsing errors, and
the binary structure of their parse trees impose
hard constraints in sentences with loose word or-
der. Moreover, as Han et al (2012) noted, reorder-
ing strategies that are derived from the HPSG the-
ory may not perform well when the head definition
is inconsistent in the language pair under study. A
typical example for the language pair of Chinese
and Japanese that illustrates this phenomenon is
the adverb ?bu4?, which is the dependent of its
verb in Chinese but the head in Japanese.
The work in (Xu et al, 2009) used an English
dependency parser and formulated handcrafted re-
ordering rules with dependency labels, POS tags
and weights as triplets and implemented them re-
cursively into sentences. This design, however,
limited the extensibility of their method. Our ap-
proach follows the idea of using dependency tree
structures and POS tags, but we discard the infor-
mation on dependency labels since we did not find
them informative to guide our reordering strate-
gies in our preliminary experiments, partly due to
Chinese showing less dependencies and a larger
label variability (Chang et al, 2009).
3 Methodology
In Subject-Verb-Object (SVO) languages, objects
usually follow their verbs, while in Subject-
Object-Verb (SOV) languages, objects precede
them. Our objective is to reorder words in Chinese
sentences (SVO) to resemble the word order of
Japanese sentences (SOV). For that purpose, our
method consists in moving verbs to the right-hand
side of their objects. However, it is challenging
to correctly identify the appropriate verbs and ob-
jects that trigger a reordering, and this section will
be dedicated to that end.
More specifically, the first step of our method
consists in identifying the appropriate verb (and
certain words close to it) that need to be moved to
the right-hand side of its object argument. Verbs
(and those accompanying words) will move as a
block, preserving the relative order among them.
We will refer to them as verbal blocks (Vbs). The
second step will consist in identifying the right-
most argument object of the verb under considera-
tion, and moving the verbal block to the right-hand
side of it. Finally, certain invariable grammatical
particles in the original vicinity of the verb will
also be reordered, but their positions will be de-
cided relative to their verb.
In what follows, we describe in detail how to
identify verbal blocks, their objects and the invari-
able grammatical particles that will play a role in
our reordering method. As mentioned earlier, the
only information that will be used to perform this
task will be the POS tags of the words and their
unlabeled dependency structures.
3.1 Identifying verbal blocks (Vbs)
Verbal blocks are composed of a head (Vb-H)
and possibly accompanying dependents (Vb-D).
In the Chinese sentence ?wo3 (I) chi1 le5 (ate) li2
(pear).?1, ?chi1? refers to the English verb ?eat?
1In this paper, we represent a Chinese character by using
Pinyin plus a tone number (there are 5 tones in Chinese). In
the example, ?chi1(eat)? is a verb and ?le5(-ed)? is an aspect
particle that adds preterit tense to the verb.
26
Vb-H VV VE VC VA P
Vb-D AD AS SP MSP CC VV VE VC VA
BEI LB SB
RM-D NN NR NT PN OD CD M FW CC
ETC LC DEV DT JJ SP IJ ON
Oth-DEP LB SB CS
Table 1: Lists of POS tags in Chinese used to iden-
tify blocks of words to reorder (Vb-H, Vb-D, BEI
lists), the POS tags of their dependents (RM-D
lists) which indicate the reordering position, and
invariable grammatical particles (Oth-DEP) that
need to be reordered.
and the aspect particle ?le5? adds a preterit tense
to the verb. The words ?chi1 le5? are an example
of verbal block that should be reordered as a block
without altering its inner word order, i.e. ?wo3
(I) li2 (pear) chi1 le5 (ate).?, which matches the
Japanese SOV order.
Possible heads of verbal blocks (Vb-H) are
verbs (words with POS tags VV, VE, VC and VA),
or prepositions (words with POS tag P). The Vb-H
entry of Table 1 contains the list of POS tags for
heads of verbal blocks. We use prepositions for
Vb-H identification since they behave similarly to
verbs in Chinese and should be moved to the right-
most position in a prepositional phrase to resemble
the Japanese word order. There are three condi-
tions that a word should meet to be considered as
a Vb-H:
i) Its POS tag is in the set of Vb-H in Table 1.
ii) It is a dependency head, which indicates that
it may have an object as a dependent.
iii) It has no dependent whose POS tag is in the
set of BEI in Table 1. BEI particles indicate
that the verb is in passive voice and should
not be reordered since it already resembles
the Japanese order.
Chinese language does not have inflection, con-
jugation, or case markers (Li and Thompson,
1989). For that reason, some adverbs (AD), as-
pect particles (AS) or sentence-final particles (SP)
are used to signal modality, indicate grammati-
cal tense or add aspectual value to verbs. Words
in this category preserve the order when translat-
ing to Japanese, and they will be candidates to be
part of the verbal block (Vb-D) and accompany
the verb when it is reordered. Other words in this
category are coordinating conjunctions (CC) that
connect multiple verbs, and both resultative ?de5?
(DER) and manner ?de5? (DEV). The full list of
POS tags used to identify Vb-Ds can be found in
Table 1. To be a Vb-D, there are three necessary
conditions as well:
i) Its POS tag is in the Vb-D entry in Table 1.
ii) It is a dependent of a word that is already in
the Vb.
iii) It is next to its dependency head or only a
coordination conjunction is in between.
To summarize, to build verbal blocks (Vbs) we
first find the words that meet the three Vb-H con-
ditions. Then, we test the Vb-D conditions on the
words adjacent to the Vb-Hs and extend the verbal
blocks to them if they meet the conditions. This
process is iteratively applied to the adjacent words
of a block until no more words can be added to the
verbal block, possibly nesting other verbal blocks
if necessary.
Figure 1a 2 shows an example of a dependency
tree of a Chinese sentence that will be used to il-
lustrate Vb identification. By observing the POS
tags of the words in the sentence, only the words
?bian1 ji4 (edit)? and ?chu1 ban3 (publish)? have
a POS tag (i.e. VV) in the Vb-H entry of Table 1.
Moreover, both words are dependency heads and
do not have any dependent whose POS tag is in
the BEI entry of Table 1. Thus, ?bian1 ji4 (edit)?
and ?chu1 ban3 (publish)? will be selected as Vb-
Hs and form, by themselves, two separate incipi-
ent Vbs. We arbitrarily start building the Vb from
the word ?chu1 ban3 (publish)?, by analyzing its
adjacent words that are its dependents.
We observe that only ?le5 (-ed)? is adjacent to
?chu1 ban3 (publish)?, it is its dependent, and its
POS tag is in the Vb-D list. Since ?le5 (-ed)?
meets all three conditions stated above, ?le5 (-ed)?
will be included in the Vb originated by ?chu1
ban3 (publish)?. The current Vb thus consists of
the sequence of tokens ?chu1 ban3 (publish)? and
?le5 (-ed)?, and the three conditions for Vb-D are
tested on the adjacent words of this block. Since
the adjacent words (or words separated by a coor-
dinating conjunction) do not meet the conditions,
the block is not further extended. Figure 1b shows
the dependency tree where the Vb block that con-
sists of the words ?chu1 ban3 (publish)? and ?le5
(-ed)? is represented by a rectangular box.
By checking in the same way, there are three
dependents that meet the requirements of being
2For all the dependency parsing trees in this paper, arrows
are pointing from heads to their dependents.
27
..xue2 xiao4 .yi3 jing1 .bian1 ji4 .he2 .chu1 ban3 .le5 .yi1 .ben3 .shu1 ..?? .?? .?? .? .?? .? .? .? .? .?.School .has already .edit (-ed) .and .publish .-ed .a . .book.NN .AD .VV .CC .VV .AS .CD .M .NN .PU
.ROOT.o .o
.o.o .o .o .o .o .o
(a) Original dependency tree
..xue2 xiao4 .yi3 jing1 .bian1 ji4 .he2 .chu1 ban3 .le5 .yi1 .ben3 .shu1 ..?? .?? .?? .? .?? .? .? .? .? .?.School .has already .edit (-ed) .and .publish .-ed .a . .book
.NN .AD .VV .CC .VV .AS .CD .M .NN .PU
.ROOT .o.o .o .o.o
(b) Vbs in rectangular boxes
..xue2 xiao4 .yi3 jing1 .bian1 ji4 .he2 .chu1 ban3 .le5 .yi1 .ben3 .shu1 ..?? .? .? .? .?? .?? .? .?? .? .?.School .a . .book .has already .edit (-ed) .and .publish .-ed
(c) Merged and reordered Vb
Figure 1: An example that shows how to de-
tect and reorder a Verbal block (Vb) in a sen-
tence. In the first two figures 1a and 1b, Chi-
nese Pinyin, Chinese tokens, word-to-word En-
glish translations, and POS tags of each Chinese
token are listed in four lines. In Figure 1c, there
are Chinese Pinyin, reordered Chinese sentence
and its word-to-word English counterpart.
Vb-Ds for ?bian1 ji4 (edit)?: ?yi3 jing1 (has al-
ready)?, ?he2 (and)? and ?chu1 ban4 (publish)?
and hence this Vb consists of three tokens and one
Vb. The outer rectangular box in Figure 1b shows
that the Vb ?bian1 ji4 (edit)? as the Vb-H. Fig-
ure 1c shows an image of how this Vb will be
reordered while the inner orders are kept. Note
that the order of building Vbs from which Vb-Hs,
?chu1 ban3 (publish)? or ?bian1 ji4 (edit)? will not
affect any change of the final result.
3.2 Identifying objects
In the most general form, objects are dependents
of verbal blocks3 that act as their arguments.
While the simplest objects are nouns (N) or pro-
nouns (PN), they can also be comprised of noun
phrases or clauses (Downing and Locke, 2006)
such as nominal groups, finite clauses (e.g. that
clauses, wh-clauses) or non-finite clauses (e.g. -
ing clauses), among others.
For every Vb in a verb phrase, clause, or sen-
tence, we define the right-most object dependent
(RM-D) as the word that:
3Dependents of verbal blocks are dependents of any word
within the verbal block.
..ta1 .chi1 .le5 .wu3 fan4 . .qu4 .xue2 xiao4 ..? .? .? .?? .? .? .?? .?.he .eat .-ed .lunch .(and) .go(to) .school ..PN .VV .AS .NN .PU .VV .NN .PU
.ROOT.o .o .o.o
.o.o .o
? ?? ? ? ? ?? ? ?he lunch eat -ed school go(to)
V ?????? O V ???? OS
O ????? V O ???? VS
English Translation: He ate lunch, and went to school.
Figure 2: An example of a Chinese sentence with
a coordination of verb phrases as predicate. Sub-
ject(S), verbs(V), and objects(O) are displayed for
both verb phrases. Lines between the original Chi-
nese sentence and the reordered Chinese sentence
indicate the reordering trace of Verbal blocks(Vb).
i) its POS tag is in the RM-D entry of Table 1,
ii) its dependency head is inside of the verbal
block, and
iii) is the right-most object among all objects of
the verbal block.
All verbal blocks in the phrase, clause, or sen-
tence will move to the right-hand side of their cor-
respondent RM-Ds recursively. Figure 1b and Fig-
ure 1c show a basic example of object identifica-
tion. The Chinese word corresponding to ?shu1
(book)? is a dependent of a word within the verbal
block and its POS tag is within the RM-D entry
list of Table 1 (i.e. NN). For this reason, ?shu1
(book)? is identified as the right-most dependent
of the verbal block (Vb), and the Vb will move to
the right-hand side of it to resemble the Japanese
word order.
A slightly more complex example can be found
in Figure 2. In this example, there is a coordina-
tion structure of verb phrases, and the dependency
tree shows that the first verb, ?chi1 (eat)?, ap-
pears as the dependency head of the second verb,
?qu4 (go)?. The direct right-most object depen-
dent (RM-D) of the first verb, ?chi1 (eat)?, is the
word ?wu3 fan4 (lunch)?, and the verb ?chi1 (eat)?
will be moved to the right-hand side of its object
dependent.
There are cases, however, where there is no co-
ordination structure of verb phrases but a simi-
lar dependency relation occurs between two verbs.
Figure 3 illustrates one of these cases, where the
main verb ?gu3 li4 (encourage)? has no direct de-
28
..xue2 xiao4 .gu3 li4 .xue2 sheng1 .can1 yu3 .she4 hui4 .shi2 jian4 ..?? .?? .?? .?? .?? .?? .?.school .encourage .student .participate .social .practice.NN .VV .NN .VV .NN .NN .PU
.o .ROOT
.o
.o.o .o .o
?? ?? ?? ?? ?? ?? ?school student social practice participate encourage
S ???? V ?????? O
S ???? V ?????????? O
S ?????? O ??????? V
S ???????????? O ??????????? VEnglish Translation: School encourages student to participate in social practice.
Figure 3: An example of a Chinese sentence in
which an embedded clause appears as the object
of the main verb. Subjects (S), verbs (V), and ob-
jects (O) are displayed for both the sentence and
the clause. Lines between the original Chinese
sentence and the reordered Chinese sentence in-
dicate the reordering trace of Verbal blocks (Vb).
pendent that can be considered as an object since
no direct dependent has a POS tag in the RM-D en-
try of Table 1. Instead, an embedded clause (SVO)
appears as the object argument of the main verb,
and the main verb ?gu3 li4 (encourage)? appears
as the dependency head of the verb ?can1 yu2 (par-
ticipate)?.
In the news domain, reported speech is a fre-
quent example that follows this pattern. In our
method, if the main verb of the sentence (labeled
as ROOT) has dependents but none of them is a
direct object, we move the main verb to the end of
the sentence. As for the embedded clause ?xue2
sheng1 (student) can1 yu2 (participate) she4 hui4
(social) shi2 jian4 (practice)?, the verbal block of
the clause is the word ?can1 yu2 (participate)?
and its object is ?shi2 jian4 (practice)?. Apply-
ing our reordering method, the clause order results
in ?xue2 sheng1 (student) she4 hui4 (social) shi2
jian4 (practice) can1 yu2 (participate)?. The result
is an SOV sentence with an SOV clause, which
resembles the Japanese word order.
3.3 Identifying invariable grammatical
particles
In Chinese, certain invariable grammatical parti-
cles that accompany verbal heads have a different
word order relative to their heads, when compared
to Japanese. Those particles are typically ?bei4?
particle (POS tags LB and SB) and subordinating
conjunctions (POS tag CS). Those particles appear
on the left-hand side of their dependency heads in
Chinese, and they should be moved to the right-
hand side of their dependency heads for them to
resemble the Japanese word order. Reordering in-
variable grammatical particles in our framework
can be summarized as:
i) Find dependents of a verbal head (Vb-H)
whose POS tags are in the Oth-DEP entry of
Table 1.
ii) Move those particles to the right-hand side of
their (possibly reordered) heads.
iii) If there is more than one such particle, move
them keeping the relative order among them.
3.4 Summary of the reordering framework
Based on the definitions above, our dependency
parsing based pre-reordering framework can be
summarized in the following steps:
1. Obtain POS tags and an unlabeled depen-
dency tree of a Chinese sentence.
2. Obtain reordering candidates: Vbs.
3. Obtain the object (RM-D) of each Vb.
4. Reorder each Vb in two exclusive cases by
following the order:
(a) If RM-D exists, reorder Vb to be the
right-hand side of RM-D.
(b) If Vb-H is ROOT and its RM-D does not
exist, reorder Vb to the end of the sen-
tence.
(c) If none of above two conditions is met,
no reordering happens.
5. Reorder grammatical particles (Oth-DEPs) to
the right-hand side of their corresponding
Vbs.
Note that, unlike other works in reordering dis-
tant languages (Isozaki et al, 2010b; Han et al,
2012; Xu et al, 2009), we do not prevent chunks
from crossing punctuations or coordination struc-
tures. Thus, our method allows to achieve an
authentic global reordering in reported speech,
which is an important reordering issue in news do-
mains.
In order to illustrate our method, a more compli-
cated Chinese sentence example is given in Fig-
ure 4, which includes the unlabeled dependency
29
..xin1wen2 .bao2dao3 . .sui2zhe5 .jing1ji4 .de5 .fa1zhan3 . .sheng4dan4jie2 .zhu2jian4 .jin4ru4 .le5 .zhong1guo2 . .cheng2wei2 .shang1jia1 .jia1qiang2 .li4cu4 .mai3qi4 .de5 .yi1 .ge4 .ji2ri4 ..?? .?? .? .?? .?? .? .?? .? .??? .?? .?? .? .?? .? .?? .?? .?? .?? .?? .? .? .? .?? .?.news .report . .with .economic .?s .development . .Christmas .gradually .enter .-ed .China . .become .businesses .strengthen .urge .purchase .?s .one .kind .festival ..NN .VV .PU .P .NN .DEG .NN .PU .NN .AD .VV .AS .NR .PU .VV .NN .VV .VV .NN .DEC .CD .M .NN .PU
.ROOT
.o.o .o .o .o.o.o
.o .o .o .o.o .o
.o
.o
.o .o.o .o .o .o.o.o
?? ? ?? ? ?? ?? ? ??? ?? ?? ?? ? ? ?? ?? ?? ?? ? ? ? ???? ?? ?
???? ?? ?? ?? ??? ?????? ? ??? ?? ? ??? ? ?? ? ? ?? ?? ? ?? ? ?? ? ?????? ???Entire English translation: News reports, with the economic development, Christmas has gradually entered into China, and becomes one of the festivals that businesses use to promote commerce.
Figure 4: Dependency parse tree of a complex Chinese sentence example, and word alignments for
reordered sentence with its Japanese counterpart. The first four lines are Chinese Pinyin, tokens, word-
to-word English translations, and the POS tags of each Chinese token. The fifth line shows the reordered
Chinese sentence while the sixth line is the segmented Japanese translation. The entire English transla-
tion for the sentence is showed in the last line.
parsing tree of the original Chinese sentence, and
the word alignment between reordered Chinese
sentence and its Japanese counterpart, etc.
Based on both POS tags and the unlabeled de-
pendency tree, first step of our method is to obtain
all Vbs. For all heads in the tree, according to the
definition of Vb introduced in Section 3.1, there
are six tokens which will be recognized as the can-
didates of Vb-Hs, that is ?bao4 dao3 (report)?,
?sui2 zhe5 (with)?, ?jin4 ru4 (enter)?, ?cheng2
wei2 (become)?, ?jia1 qiang2 (strengthen)?, and
?li4 cu4 (urge)?. Then, for each of the candidate,
its direct dependents will be checked if they are
Vb-Ds. For instance, for the verb of ?jin4 ru4 (en-
ter)?, its dependents of ?zhu2 jian4 (gradually)?
and ?le5 (-ed)? will be considered as the Vb-Ds.
For the case of ?jia1 qiang2 (strengthen)?, instead
of being a Vb-H, it will be recognized as Vb-D
of the Vb ?li4 cu4 (urge)? since it is one of the
direct dependents of ?li4 cu4 (urge)? with a qual-
ified POS tag for Vb-D. Therefore, there are five
Vbs in total, which are ?bao4 dao3 (report)?, ?sui2
zhe5 (with)?, ?zhu2 jian4 (gradually) jin4 ru4 (en-
ter) le5 (-ed)?, ?cheng2 wei2 (become)?, and ?jia1
qiang2 (strengthen) li4 cu4 (urge)?.
The next step is to identify RM-D for each
Vb, if there is one. By checking all conditions,
four Vbs have their RM-Ds: ?fa1 zhan3 (develop-
ment)? is the RM-D of the Vb ?sui2 zhe5 (with)?;
?zhong1 guo2 (China)? is the RM-D of the Vb
?zhu2 jian4 (gradually) jin4 ru4 (enter) le5 (-ed)?;
?jie2 ri4 (festival)? is the RM-D of the Vb ?cheng2
wei2 (become)?; ?mai3 qi4 (purchase)? is the RM-
D of the Vb ?jia1 qiang2 (strengthen) li4 cu4
(urge)?.
After obtaining all RM-Ds, we find those Vbs
that have RM-Ds and move them to right of their
RM-Ds. As for the case of ?bao4 dao3 (report)?,
since it is the root and does not have any matched
RM-D, it will be moved to the end of the sen-
tence, before any final punctuation. Finally, since
there is no any invariable grammatical particle in
the sentence that need to be reordered, reordering
has been finished. From the alignments between
the reordered Chinese and its Japanese translation
showed in the figure, an almost monotonic word
alignment has been achieved.
For comparison purposes, particle seed words
had been inserted into the reordered sentences in
the same way as the Refined-HFC method, which
is using the information of predicate argument
structure output by Chinese Enju (Yu et al, 2011).
We therefore can not entirely disclaim the use
of the HPSG parser at the present stage in our
method. However, we believe that dependency
parser can provide enough information for insert-
ing particles.
4 Experiments
We conducted experiments to assess how our pro-
posed dependency-based pre-reordering for Chi-
nese (DPC) impacts on translation quality, and
compared it to a baseline phrase-based system
and a Refined-HFC pre-reordering for Chinese to
Japanese translation.
We used two Chinese-Japanese training data
30
News CWMT+News
BLEU RIBES BLEU RIBES
Baseline 39.26 84.83 38.96 85.01
Ref-HFC 39.22 84.88 39.26 84.68
DPC 39.93 85.23 39.94 85.22
Table 3: Evaluation of translation quality of two
test sets when CWMT, News and the combination
of both corpora were used for training.
sets of parallel sentences, namely an in-house-
collected Chinese-Japanese news corpus (News),
and the News corpus augmented with the
CWMT (Zhao et al, 2011) corpus. We extracted
disjoint development and test sets from News cor-
pus, containing 1, 000 and 2, 000 sentences re-
spectively. Table 2 shows the corpora statistics.
We used MeCab 4 (Kudo and Matsumoto, 2000)
and the Stanford Chinese segmenter 5 (Chang et
al., 2008) to segment Japanese and Chinese sen-
tences. POS tags of Chinese sentences were ob-
tained using the Berkeley parser 6 (Petrov et al,
2006), while dependency trees were extracted us-
ing Corbit 7 (Hatori et al, 2011). Following the
work in (Han et al, 2012), we re-implemented
the Refined-HFC using the Chinese Enju to ob-
tain HPSG parsing trees. For comparison purposes
with the work in (Isozaki et al, 2010b), particle
seed words were inserted at a preprocessing stage
for Refined-HFC and our DPC method.
DPC and Refined-HFC pre-reordering strate-
gies were followed in the pipeline by a standard
Moses-based baseline system (Koehn et al, 2007),
using a default distance reordering model and a
lexicalized reordering model ?msd-bidirectional-
fe?. A 5-gram language model was built using
SRILM (Stolcke, 2002) on the target side of the
corresponding training corpus. Word alignments
were extracted using MGIZA++ (Gao and Vogel,
2008) and the parameters of the log-linear combi-
nation were tuned using MERT (Och, 2003).
Table 3 summarizes the results of the Baseline
system (no pre-reordering nor particle word inser-
tion), the Refined-HFC (Ref-HFC) and our DPC
method, using the well-known BLEU score (Pap-
ineni et al, 2002) and a word order sensitive met-
ric named RIBES (Isozaki et al, 2010a).
4http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html
5http://nlp.stanford.edu/software/segmenter.shtml
6http://nlp.cs.berkeley.edu/Software.shtml
7http://triplet.cc/software/corbit
As it can be observed, our DPC method obtains
around 0.7 BLEU points of improvement when
compared to the second best system in both cor-
pora. When measuring the translation quality in
terms of RIBES, our method obtains an improve-
ment of 0.3 and 0.2 points when compared to the
second best system in News and CWMT + News
corpora, respectively. We suspect that corpus di-
versity might be one of the reasons for Refined-
HFC not to show any advantage in this setting.
We tested the significance of BLEU improve-
ment for Refined-HFC and DPC when compared
to the baseline phrase-based system. Refined-HFC
tests obtained p-values 0.355 and 0.135 on News
and CWMT + News corpora, while our proposed
DPC method obtained p-values 0.002 and 0.0,
which indicates significant improvements over the
phrase-based system.
5 Conclusions
In the present paper, we have analyzed the dif-
ferences in word order between Chinese and
Japanese sentences. We captured the regulari-
ties of ordering differences between Chinese and
Japanese sentences, and proposed a framework to
reorder Chinese sentences to resemble the word
order of Japanese.
Our framework consists in three steps. First,
we identify verbal blocks, which consist of Chi-
nese words that will move all together as a block
without altering their relative inner order. Sec-
ond, we identify the right-most object of the verbal
block, and move the verbal block to the right of it.
Finally, we identify invariable grammatical parti-
cles in the original vicinity of the verbal block and
move them relative to their dependency heads.
Our framework only uses the unlabeled depen-
dency structure of sentences and POS tag informa-
tion of words. We compared our system to a base-
line phrase-based SMT system and a refined head-
finalization system. Our method obtained a Chi-
nese word order that is more similar to Japanese
word order, and we showed its positive impact on
translation quality.
6 Discussion and future work
In the literature, there are mainly two types of
parsers that have been used to extract sentence
structure and guide reordering. The first type cor-
responds to parsers that extract phrase structures
(i.e. HPSG parsers). These parsers infer a rich
31
News CWMT+News
Chinese Japanese Chinese Japanese
Training
Sentences 342, 050 621, 610
Running words 7,414,749 9,361,867 9,822,535 12,499,112
Vocabulary 145,133 73,909 214,085 98,333
News Devel.
Sentences 1, 000 ?
Running words 46,042 56,748 ? ?
Out of Vocab. 255 54 ? ?
News Test
Sentences 2, 000 ?
Running words 51,534 65,721 ? ?
Out of Vocab. 529 286 ? ?
Table 2: Basic statistics of our corpora. News Devel. and News Test were used to tune and test the
systems trained with both training corpora. Data statistics were collected after tokenizing and filtering
out sentences longer than 64 tokens.
annotation of the sentence in terms of semantic
structure or phrase heads. Other reordering strate-
gies use a different type of parsers, namely depen-
dency parsers. These parsers extract dependency
information among words in the sentence, often
consisting in the dependency relation between two
words and the type of relation (dependency label).
Reordering strategies that use syntactic infor-
mation have proved successful, but they are likely
to magnify parsing errors if their reordering rules
heavily rely on abundant parse information. This
is aggravated when reordering Chinese sentences,
due to its loose word order and large variety of
possible dependency labels.
In this work, we based our study of ordering
differences between Chinese and Japanese solely
on dependency relations and POS tags. This con-
trasts with the work in (Han et al, 2012) that re-
quires phrase structures, phrase-head information
and POS tags, and the work in (Xu et al, 2009)
that requires dependency relations, dependency la-
bels and POS tags.
In spite of the fact that our method uses less syn-
tactic information, it succeeds at reordering sen-
tences with reported speech even in presence of
punctuation symbols. It is worth saying that re-
ported speech is very common in the news domain,
which might be one of the reasons of the supe-
rior translation quality achieved by our reordering
method. Our method also accounted for ordering
differences in serial verb constructions, comple-
mentizers and adverbial modifiers, which would
have required an increase in the complexity of the
reordering logic in other methods.
To the best of our knowledge, dependency
parsers are more common than HPSG parsers
across languages, and our method can potentially
be applied to translate under-resourced languages
into other languages with a very different sentence
structure, as long as they count with dependency
parsers and reliable POS taggers.
Implementing our method for other languages
would first require a linguistic study on the re-
ordering differences between the two distant lan-
guage pairs. However, some word ordering differ-
ences might be consistent across SVO and SOV
language pairs (such as verbs going before or after
their objects), but other ordering differences may
need special treatment for the language pair under
consideration (i.e. Chinese ?bei? particles).
There are two possible directions to extend the
present work. The first one would be to refine the
current method to reduce its sensitivity to POS tag-
ging or dependency parse errors, and to extend our
linguistic study on ordering differences between
Chinese and Japanese languages. The second di-
rection would be to manually or automatically find
common patterns of ordering differences between
SVO and SOV languages. The objective would be
then to create a one-for-all reordering method that
induces monotonic word alignments between sen-
tences from distant language pairs, and that could
also be easily extended to account for the unique
characteristics of the source language of interest.
Acknowledgments
We would like to thank Dr. Takuya Matsuzaki for
his precious advice on this work and Dr. Jun Ha-
tori for his support on using Corbit.
32
References
Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing Chinese word segmen-
tation for machine translation performance. In Proc.
of the 3rd Workshop on SMT, pages 224?232.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D Manning. 2009. Discriminative re-
ordering with Chinese grammatical relations fea-
tures. In Proc. of the Third Workshop on Syntax and
Structure in Statistical Translation, pages 51?59.
Angela Downing and Philip Locke. 2006. English
grammar: a university course. Routledge.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, pages 49?57.
Nizar Habash. 2007. Syntactic preprocessing for sta-
tistical machine translation. In Proc. of Machine
Translation Summit XI, pages 215?222.
Dan Han, Katsuhito Sudoh, Xianchao Wu, Kevin Duh,
Hajime Tsukada, and Masaaki Nagata. 2012. Head
finalization reordering for Chinese-to-Japanese ma-
chine translation. In Proc. of the Sixth Workshop on
Syntax, Semantics and Structure in Statistical Trans-
lation, pages 57?66.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Ju-
nichi Tsujii. 2011. Incremental joint POS tagging
and dependency parsing in Chinese. In Proc. of
5th International Joint Conference on Natural Lan-
guage Processing, pages 1216?1224.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada. 2010a. Automatic
evaluation of translation quality for distant language
pairs. In Proc. of EMNNLP.
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and
Kevin Duh. 2010b. Head finalization: A simple re-
ordering rule for SOV languages. In Proc. of WMT-
MetricsMATR, pages 244?251.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proc. of ACL ?07, Demonstration Sessions, pages
177?180.
Taku Kudo and Yuji Matsumoto. 2000. Japanese de-
pendency structure analysis based on support vector
machines. In Proc. of the EMNLP/VLC-2000, pages
18?25.
Charles N Li and Sandra Annear Thompson. 1989.
Mandarin Chinese: A functional reference gram-
mar. Univ of California Press.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,
Ming Zhou, and Yi Guan. 2007. A probabilistic ap-
proach to syntax-based reordering for statistical ma-
chine translation. In Proc. of ACL, page 720.
Yusuke Miyao and Jun?ichi Tsujii. 2008. Feature for-
est models for probabilistic HPSG parsing. Compu-
tational Linguistics, 34:35?80.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Comput. Linguist., 29:19?51.
Franz J. Och. 2003. Minimum error rate training
for statistical machine translation. In Proc. of ACL,
pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic
evaluation of machine translation. In Proc. of ACL,
pages 311?318.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proc. of the 21st COL-
ING and the 44th ACL, pages 433?440.
Carl Jesse Pollard and Ivan A. Sag. 1994. Head-
driven phrase structure grammar. The University
of Chicago Press and CSLI Publications.
Andreas Stolcke. 2002. SRILM ? an extensible lan-
guage modeling toolkit. In Proc. of the 7th interna-
tional conference on Spoken Language Processing,
2002, pages 901?904.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statistical
machine translation. In Proc. of the 2007 Joint Con-
ference on EMNLP-CoNLL, pages 737?745.
Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime
Tsukada, and Masaaki Nagata. 2011. Extracting
pre-ordering rules from predicate-argument struc-
tures. In Proc. of 5th International Joint Conference
on Natural Language Processing, pages 29?37.
Fei Xia and Michael McCord. 2004. Improving
a statistical MT system with automatically learned
rewrite patterns. In Proc. of the 20th international
conference on Computational Linguistics.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
SMT for subject-object-verb languages. In Proc. of
HLT: NA-ACL 2009, pages 245?253.
Kun Yu, Yusuke Miyao, Takuya Matsuzaki, Xiangli
Wang, and Junichi Tsujii. 2011. Analysis of the
difficulties in Chinese deep parsing. In Proc. of the
12th International Conference on Parsing Technolo-
gies, pages 48?57.
Hong-Mei Zhao, Ya-Juan Lv, Guo-Sheng Ben, Yun
Huang, and Qun Liu. 2011. Evaluation report
for the 7th China workshop on machine translation
(CWMT2011). The 7th China Workshop on Ma-
chine Translation (CWMT2011).
33
