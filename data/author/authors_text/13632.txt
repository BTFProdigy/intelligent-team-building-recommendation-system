Exploiting Social Q&A Collection in Answering Complex Questions
Youzheng Wu Hisashi Kawai
Spoken Language Communication Group, MASTAR Project
National Institute of Information and Communications Technology
2-2-2 Hikaridai, Keihanna Science City, Kyoto 619-0288, Japan
{youzheng.wu, hisashi.kawai}@nict.go.jp
Abstract
This paper investigates techniques to au-
tomatically construct training data from
social Q&A collections such as Yahoo!
Answer to support a machine learning-
based complex QA system1. We extract
cue expressions for each type of question
from collected training data and build
question-type-specific classifiers to im-
prove complex QA system. Experiments
on 10 types of complex Chinese ques-
tions verify that it is effective to mine
knowledge from social Q&A collections
for answering complex questions, for in-
stance, the F3 improvement of our sys-
tem over the baseline and translation-
based model reaches 7.9% and 5.1%, re-
spectively.
1 Introduction
Research on the topic of QA systems has mainly
concentrated on answering factoid, definitional,
reason and opinion questions. Among the ap-
proaches proposed to answer these questions,
machine learning techniques have been found
more effective in constructing QA components
from scratch. Yet these supervised techniques re-
quire a certain scale of (question, answer), short
for Q&A, pairs as training data. For example,
(Echihabi et al, 2003) and (Sasaki, 2005) con-
structed 90,000 English Q&A pairs and 2,000
Japanese Q&A pairs, respectively for their fac-
toid QA systems. (Cui et al, 2004) constructed
1Complex questions cannot be answered by simply ex-
tracting named entities. In this paper complex questions do
not include definitional questions.
76 term-definition pairs for their definitional QA
systems. (Stoyanov et al, 2005) required a
known subjective vocabulary for their opinion
QA. (Higashinaka and Isozaki, 2008) used 4,849
positive and 521,177 negative examples in their
reason QA system. Among complex QA sys-
tems, many other types of questions have not
been well studied, apart from reason and defi-
nitional questions. Appendix A lists 10 types of
complex Chinese questions and their examples
we discussed in this paper.
According to the related studies on QA, su-
pervised machine-learning technique may be ef-
fective for answering these questions. To em-
ploy the supervised approach, we need to re-
construct training Q&A pairs for each type of
question, though this is an extremely expensive
and labor-intensive task. To deal with the ac-
quisition problem of training Q&A pairs, we in-
vestigate techniques to automatically construct
training data by utilizing social Q&A collections
crawled from the Web, which contains millions
of user-generated Q&A pairs. Many studies
(Surdeanu et al, 2008) (Duan et al, 2008) have
been done on retrieving similar Q&A pairs from
social QA websites as answers to test questions.
Our study, however, regards social Q&A web-
sites as a knowledge repository and aims to mine
knowledge from them for synthesizing answers
to questions from multiple documents. There is
very little literature on this aspect. Our work can
be seen as a kind of query-based summarization
(Dang, 2006) (Harabagiu et al, 2006) (Erkan
and Radev, 2004), and can also be employed to
answer questions that have not been answered in
social Q&A websites.
This paper mainly focuses on the following three
steps: (1) automatically constructing question -
type-specific training Q&A pairs from the so-
cial Q&A collection; (2) extracting cue expres-
sions for each type of question from the col-
lected training data, and (3) building question-
type-specific classifiers to filer out noise sen-
tences before using a state-of-the-art IR formula
to select answers.
We evaluate our system on 10 types of Chi-
nese questions by using the Pourpre evalua-
tion tool (Lin and Demner-Fushman, 2006).
The experimental results show the effectiveness
of our system, for instance, the F3/NR im-
provement of our system over the baseline and
translation-based model reaches 7.9%/11.1%,
and 5.1%/5.6%, respectively.
2 Social Q&A Collection
Recently launched social QA websites such as
Yahoo! Answer2 and Baidu Zhidao3 provide
an interactive platform for users to post ques-
tions and answers. After questions are answered
by users, the best answer can be chosen by the
asker or nominated by the community. The num-
ber of Q&A pairs on such sites has risen dra-
matically. These pairs could collectively form a
source of training data that is required in super-
vised machine-learning-based QA systems.
In this paper we aim to explore such user-
generated Q&A collections to automatically col-
lect Q&A training data. However, social col-
lections have two salient characteristics: tex-
tual mismatch between questions and answers
(i.e., question words are not necessarily used
in answers); and user-generated spam or flip-
pant answers, which are unfavorable factors in
our study. Thus, we only crawl questions and
their best answers to form Q&A pairs, wherein
the best answers are longer than the empiri-
cal threshold. Finally, 60.0 million Q&A pairs
were crawled from Chinese social QA websites.
These pairs will be used as the source of training
data required in our study.
2http://answers.yahoo.com/
3http://zhidao.baidu.com/
3 Our Complex QA System
The typical complex QA system architecture is
a cascade of three modules. The Question Ana-
lyzer analyzes test questions and identifies an-
swer types of questions. The Document Re-
triever & Answer Candidate Extractor retrieves
documents related to questions from the given
collection (Xinhua and Lianhe Zaobao newspa-
pers from 1998-2001 were used in this study) for
consideration, and segments the documents into
sentences as answer candidates. The Answer Ex-
traction module applies state-of-the-art IR for-
mulas (e.g., KL-divergence language model) to
directly estimate similarities between sentences
(1,024 sentences were used in our case) and
questions, and selects the most similar sentences
as the final answers. Given three answer candi-
dates, s1 = ?Solutions to global warming range
from changing a light bulb to engineering giant
reflectors in space ...?, s2 = ?Global warming
will bring bigger storms and hurricanes that will
hold more water ...?, and s3 = ?nuclear power
is the relatively low emission of carbon diox-
ide (CO2), one of the major causes of global
warming,? to the question of ?What are the haz-
ards of global warming??, however, it is hard for
this architecture to select the correct answer, s2,
because the three candidates contain the same
question words ?global warming?.
According to our observation, answers to a
type of question usually contain some type-
of-question dependent cue expressions (?will
bring? in this case). This paper argues that
the above QA system can be improved by us-
ing such question-type-specific cue expressions.
For each test question, we perform the follow-
ing three steps. (1) Collecting question-type-
specific Q&A pairs from the social Q&A collec-
tion which question types are same as the test
question to form positive training data. Sim-
ilarly, negative Q&A pairs are also collected
which question types are different from the
test question. (2) Extracting and weighting
question-type-specific cue expressions from the
collected Q&A pairs. (3) Building a question-
type-specific classifier by employing the cue ex-
pressions and the collected Q&A pairs, which re-
moves noise sentences from answer candidates
before using the Answer Extraction module.
3.1 Collecting Q&A Pairs
We first introduce the notion of the answer type
informer of the question as follows. In a ques-
tion, a short subsequence of tokens (typically 1-
3 words) that are adequate for question classi-
fication is considered an answer-type informer,
e.g., ?hazard? in the question of ?What are the
hazards of global warming?? This paper makes
the following assumption: type of complex ques-
tion is determined by its answer type informer.
For example, the question of ?What are the haz-
ards of global warming?? belongs to hazard-type
question, because its answer type informer is
?hazard?. Therefore, the task of recognizing
question-types is shifted to identifying answer
type informer of question.
In this paper, we regard answer-type informer
recognition as a sequence tagging problem and
adopt conditional random fields (CRFs) because
many work has shown that CRFs have a con-
sistent advantage in sequence tagging. We
manually label 3,262 questions with answer-
type informers to train a CRF, which classi-
fies each question word into a set of tags O =
{IB , II , IO}: IB for a word that begins an in-
former, II for a word that occurs in the mid-
dle of an informer, and IO for a word that
is outside of an informer. In the following
feature templates used in the CRF model, wn
and tn, refer to word and PoS, respectively;
n refers to the relative position from the cur-
rent word n=0. The feature templates in-
clude the following four types: unigrams of
wn and tn, where n=?2,?1, 0, 1, 2; bigrams
of wnwn+1 and tntn+1, where n=?1, 0; tri-
grams of wnwn+1wn+2 and tntn+1tn+2, where
n=?2,?1, 0; and bigrams of OnOn+1, where
n=?1, 0.
The trained CRF model is then employed to
recognize answer-type informers from questions
of social Q&A pairs. Finally, we recognized 103
answer-type informers in which frequencies are
larger than 10,000. Moreover, the numbers of
answer type informers for which frequencies are
larger than 100, 1,000, and 5,000 are 2,714, 807,
and 194, respectively.
Based on answer-type informers of questions
recognized, we can collect training data for each
type of question as follows: (1) Q&A pairs are
grouped together in cases in which the answer-
type informers X of their questions are the same,
and (2) Q&A pairs clustered by informers X
are regarded as the positive training data of
X-type questions. For instance, 10,362 Q&A
pairs grouped via informer X (=?hazard?) are
regarded as positive training data of answering
hazard-type questions. Table 1 lists some ques-
tions, which, together with their best answers,
are employed as the training data of the corre-
sponding type of questions. For each type of
question, we also randomly select some Q&A
pairs that do not contain informers in questions
as negative training data. Preprocessing of the
training data, including word segmentation, PoS
tagging, and named entity (NE) tagging (Wu et
al., 2005), is conducted. We also replace each
NE with its tag type.
Qtype Questions of Q&A pairs
Hazard-
type
What are the hazards of the tro-
jan.psw.misc.kah virus?
What are the hazards of RMB appreciation
on China?s economy?
Hazards of smoke
What are the hazards of contact lenses?
What are the hazards of waste accumula-
tion?
Casualty-
type
What were the casualties on either side from
the U.S.-Iraq war?
What were the casualties of the Sino-French
War?
What were the casualties of the Sichuan
earthquake in 2008?
What were the casualties of highway acci-
dents over the years?
What were the casualties of the Ryukyu Is-
lands tsunami?
Reason-
type
What are the main reasons of China?s water
shortage?
What are the reasons of asthma?
What are the reasons of blurred photos?
What are the reasons of air pollution?
The reasons for the soaring prices!
Table 1: Questions (translated from Chinese) of
social Q&A pairs (words in bold denote answer-
type informers of questions). These questions
and their best answers are regarded as positive
training data for hazard-type question.
3.2 Cue Expressions
We extract lexical and PoS-based n-grams as cue
expressions from the collected training data. To
reduce the dimensionality of the cue expression
space, we first select the top 3,000 lexical un-
igrams using the formula: scorew = tfw ?
log(idfw), where tf(w) denotes the frequency of
word w, and idf(w) represents the inverted doc-
ument frequency of w that indicates its global
importance. Table 2 shows some of the learned
unigrams. The top 300 unigrams are then used as
seeds to learn lexical bigrams and trigrams iter-
atively. Only lexical bigrams and trigrams that
contain seed unigrams with frequencies larger
than the thresholds are retained as lexical fea-
tures. Moreover, we extract PoS-based unigrams
and bigrams as cue expressions.
Further, we assign each extracted feature si a
weight calculated using the equation weightsi =
csi1 /(c
si
1 + c
si
2 ), where, c
si
1 and c
si
2 denote its fre-
quencies in positive and negative training Q&A
pairs, respectively.
Qtype Top Unigrams
Hazard-type ?3/hazard s?/lead to ?/cause
Z?/give rise to ?	/bring about k
//influence?3/damage
Casualty-type ?}/casualty ?}/death I?/hurt
/missing ?
/wrecked j}/die
in battle??/wounded
Table 2: Top unigrams learned from hazard-type
and casualty-type Q&A pairs
3.3 Classifiers
As mentioned above, we use the extracted cue
expressions and the collected Q&A pairs to build
question-type-specific classifiers, which is used
to remove noise sentences from answer candi-
dates. For classifiers, we employ multivariate
classification SVMs (Thorsten Joachims, 2005)
that can directly optimize a large class of perfor-
mance measures like F1-Score, prec@k (preci-
sion of a classifier that predicts exactly k = 100
examples to be positive) and error-rate (percent-
age of errors in predictions). Instead of learn-
ing a univariate rule that predicts the label of a
single example in conventional SVMs (Vapnik,
1998), multivariate SVMs formulate the learn-
ing problem as a multivariate prediction of all
examples in the data set. Considering hypothe-
ses h that map a tuple x of n feature vectors
x = (x1, ...,xn) to a tuple y of n labels y =
(y1, ..., yn), multivariate SVMs learn a classifier
hw(x) = argmaxy??Y {wT?(x, y?)} (1)
by solving the following optimization problem.
minw,??0
1
2?w?
2 +C? (2)
s.t. : ?y? ? Y \y : wT [?(x, y) ? ?(x, y?)]
? ?(y?, y) ? ?
(3)
where, w is a parameter vector, ? is a function
that returns a feature vector describing the match
between (x1, ...,xn) and (y?1, ..., y?n), ? denotes
types of multivariate loss functions, and ? is a
slack variable.
4 Experiments
The NTCIR 2008 test data set (Mitamura et al,
2008) contains 30 complex questions4 we dis-
cussed here. However, a small number of test
questions are included for some question types,
e.g.; it contains only 1 hazard-type, 1 scale-type,
and 3 significance-type questions. To form a
more complete test set, we create another 65 test
questions5 . Therefore, the test data used in this
paper includes 95 complex questions.
For each test question we also provide a list
of weighted nuggets, which are used as the gold
standard answers for evaluation. The evaluation
is conducted by employing Pourpre v1.0c (Lin
and Demner-Fushman, 2006), which uses the
standard scoring methodology for TREC other
questions (Voorhees, 2003), i.e., answer nugget
recall NR, nugget precision NP , and a combi-
nation score F3 of NR and NP . For better un-
derstanding, we evaluate the systems when out-
putting the top N sentences as answers.
4Because definitional, biography, and relationship ques-
tions in the NTCIR 2008 test set are not discussed here.
5The approach of creating test data is same as that in the
NTCIR 2008.
F3 (%) NR (%) NP (%)
N = 1 N = 5 N = 10 N = 1 N = 5 N = 10 N = 1 N = 5 N = 10
Baseline 9.82 18.18 21.95 9.44 19.85 27.64 34.35 25.32 18.96
TransM 9.76 20.47 24.76 9.44 19.85 33.10 31.96 21.73 13.57
Ourslin 10.92 22.61 25.74 10.49 25.95 34.70 34.98 23.40 15.11
Ourserrorrate 12.37 23.10 27.74 12.05 26.98 37.03 33.22 26.48 18.67
Ourspre@k 8.96 22.85 29.85 8.72 25.67 38.78 26.28 28.82 20.45
Table 3: Overall performance for the test data
4.1 Overall Results
Table 3 summarizes the evaluation results for
several N values. The baseline refers to the con-
ventional method introduced in Section 3, which
does not employ question-type-specific classi-
fiers before the Answer Extraction. The baseline
can be expressed by the formula:
sim(q, s) = ?Vq ? Vs??Vq? ? ?Vs?
(4)
where, Vq and Vs are the vectors of the ques-
tion and candidate answer. The TransM de-
notes a translation model for QA (Xue, et al,
2008) (Bernhard et al, 2009), which uses Q&A
pairs as the parallel corpus, with questions to the
?source? language and answers corresponding to
the ?target? language. This model can be ex-
pressed by:
P (q|S) =
?
w?q
((1 ? ?)Pmx(w|S) + ?Pml(w|C))
Pmx(w|S) = (1 ? ?)Pml(w|S)+
?
?
t?S
P (w|t)Pml(t|S)
(5)
where, q is the question, S the sentence, P (w|t)
the probability of translating a sentence term t to
the question term w, which is obtained by using
the GIZA++ toolkit (Och and Ney, 2003). We
use six million Q&A pairs to train IBM model 1
for obtaining word-to-word probability P (w|t).
Ourserrorrate and Ourspre@k denote our models
that are based on classifiers optimizing perfor-
mance measure error-rate and prec@k, respec-
tively. Ourslin, a linear interpolation model, that
combines scores of classifiers and the baseline,
which is similar to (Mori et al, 2008) and can be
expressed by the equation:
sim(q, s)? = sim(q, s) + ? ? ?(s) (6)
where, ?(s) is the score calculated by classi-
fiers (Thorsten Joachims, 2005) and ? denotes
the weight of the score.
This experiment shows that: (1) Question-
type-specific classifiers can greatly outperform
the baseline; for example, the F3 improvements
of Ourserrorrate and Ourspre@k over the base-
line in terms of N=10 are 5.8% and 7.9%,
respectively. (2) Ourserrorrate is better than
Ourspre@k when N < 10. The average num-
bers of sentences retained in Ourserrorrate and
Ourspre@k are 130, and 217, respectively. That
means the precision of the classifier optimiz-
ing errorrate is superior to the classifier optimiz-
ing prec@k, while the recall is relatively infe-
rior. (3) Ourslin is worse than Ourserrorrate and
Ourspre@k, which indicates that using question-
type-specific classifiers by classification is better
than using it by interpolation like (Mori et al,
2008). (4) Our models also outperform TransM,
e.g.; the F3 improvement is 5.1% when N is
set to 10. TransM exploits the social Q&A col-
lection without consideration of question types,
while our models select and exploit the social
Q&A pairs of the same question types. Thereby,
this experiment also indicates that it is better to
exploit social Q&A pairs by type of question.
The performance ranking of these models when
N=10 is: Oursprec@k > Ourserrorrate > Ourslin
> TransM > Baseline.
4.2 Impact of Features
In order to evaluate the contributions of indi-
vidual features to our models, this experiment
is conducted by gradually adding them. Table
4 summarizes the performance of Ourprec@k on
different set of features, L and P represent lex-
ical and PoS-based features, respectively. This
table demonstrates that all the lexical and PoS
features can positively impact Ourprec@k, espe-
cially, the contribution of the PoS-based features
is largest.
Features F3 NR NP
Lunigram 23.44 31.23 17.32
+Lbigram +Ltrigram 25.34 33.15 18.87
+Punigram 28.24 36.27 20.18
+Pbigram 29.85 38.78 20.45
Table 4: Impact of features on Ourprec@k.
4.3 Improvement
As discussed in Section 2, the writing style of
social Q&A collections slightly differs from that
of our complex QA system, which is an unfavor-
able circumstance in utilizing social Q&A col-
lections. For better understanding we randomly
select 100 Q&A training pairs of each type of
question acquired in Section 3, and manually
classify each Q&A pair into NON-NOISE and
NOISE6 categories. Figure 1 reports the percent-
age of NON-NOISE. This figure indicates that
71% of the training pairs of the scale-type ques-
tions are noises, which may lead to a small im-
provement.
0.87
0.79
0.86
0.5 0.51
0.79
0.54 0.58
0.85
0.29
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Figure 1: Percentage of NON-NOISE pairs by
type of questions.
To further improve the performance, we em-
6NOISE means that the Q&A pair is not useful in our
study.
ploy k-fold cross validation to remove noises
from the collected training data in Section 3.1.
Specifically, the collected training data are first
divided into k (= 5) sets. Secondly, k-1 sets are
used to train classifiers that are applied to clas-
sify the Q&A pairs in the remaining set. Finally,
part of the Q&A pairs classified as negative pairs
are removed7. According to Figure 1, we re-
move 20% of the training data from the nega-
tive pairs for the hazard-type, impact-type, and
function-type questions, and 40% of the train-
ing data for significance-type, event-type, and
reason-type questions. Because the sizes of the
training pairs of the other four types of ques-
tions are small, we do not use this approach on
them. Table 5 shows the results of Ourspre@k on
the above six types of questions. The numbers
in brackets indicate absolute improvements over
the system based on the data without removing
noises. N is the number of answer sentences to a
question. The experiment shows that the perfor-
mance is generally improved by removing noise
in the training Q&A pairs using k-fold cross-
validation.
F3 (%) NR (%) NP (%)
N = 1 9.6+2.1 9.3+2.0 30.8+7.4
N = 5 21.6+0.7 24.9+1.2 26.0?1.3
N = 10 28.6+0.9 37.9+1.7 19.2?0.2
Table 5: Performance of Ourspre@k after remov-
ing noises in the training Q&A pairs.
4.4 Subjective evaluation
Pourpre v1.0c evaluation is based on n-gram
overlap between the automatically produced an-
swers and the human generated reference an-
swers. Thus, it is not able to measure concep-
tual equivalent. In subjective evaluation, the an-
swer sentences returned by systems are labeled
by a native Chinese assessor. Figure 2 shows the
distribution of the ranks of the first correct an-
swers for all questions. This figure demonstrates
that the Ourspre@k answers 57 questions which
7We do not remove all negative Q&A pairs to ensure
the coverage of training data because the classifiers have
relatively lower recall, as mentioned in Section 3.3.
first answers are ranked in top 3, which is larger
than that of the baseline, i.e., 49. Moreover,
the Ourspre@k contains only 11.5% of questions
which answers are ranked after top 10, while this
number of the baseline is 20.7%.
26
16
15
6
0
3
2
3 2 4
30
9 10
1
6
8
2
1 2 00
5
10
15
20
25
30
35
1 2 3 4 5 6 7 8 9 10
Ourprec@k
Baseline
Figure 2: Distribution of the ranks of first an-
swers.
5 Related Work
Recently, some pioneering studies on the social
Q&A collection have been conducted. Among
them, much of the research aims to retrieve an-
swers to queried questions from the social Q&A
collection. For example, (Surdeanu et al, 2008)
proposed an answer ranking engine for non-
factoid questions by incorporating textual fea-
tures into a machine learning approach. (Duan
et al, 2008) proposed searching questions se-
mantically equivalent or close to the queried
question for a question recommendation sys-
tem. (Agichtein et al, 2008) investigated tech-
niques of finding high-quality content in the so-
cial Q&A collection, and indicated that 94% of
answers to questions with high quality have high
quality. (Xue, et al, 2008) proposed a retrieval
model that combines a translation-based lan-
guage model for the question part with a query
likelihood approach for the answer part.
Another category of study regards the social
Q&A collection as a kind of knowledge reposi-
tory and aims to mine knowledge from it for gen-
erating answers to questions. To the best of our
knowledge, there is very limited work reported
on this aspect. This paper is similar to (Mori et
al., 2008), but different from it as follows. (1)
(Mori et al, 2008) collects training data for each
test question using 7-grams for which centers are
interrogatives, while this paper collects training
data for each type of question using answer type
informers. (2) About the knowledge learned,
we extract lexical/class-based, PoS-based uni-
grams, bigrams, and trigrams. (Mori et al, 2008)
only extracts lexical bigrams. (3) They incor-
porated knowledge learned by interpolating with
the baseline. However, we utilize the learned
knowledge to train a binary classifier, which can
remove noise sentences before answer selection.
6 Conclusion
This paper investigated a technique for mining
knowledge from social Q&A websites for im-
proving a sentence-based complex QA system.
More specifically, it explored a social Q&A col-
lection to automatically construct training data,
and created question-type-specific classifier for
each type of question to filter out noise sentences
before answer selection.
The experiments on 10 types of complex Chi-
nese questions show that the proposed approach
is effective; e.g., the improvement in F3 reaches
7.9%. In the future, we will endeavor to reduce
NOISE pairs in the training data, and to extract
type-of-question dependent features. Future re-
search tasks also include adapting the QA system
to a topic-based summarization system, which,
for example, summarizes accidents according to
?casualty?, ?reason?, and summarizes events ac-
cording to ?reason?, ?measure,? ?impact?, etc.
Appendix A. Examples of 10 Types of Ques-
tions.
References
Abdessamad Echihabi and Daniel Marcu. 2003. A
Noisy-Channel Approach to Question Answering.
In Proc. of ACL 2003, Japan.
Delphine Bernhard and Iryna Gurevych. 2009. Com-
bining Lexical Semantic Resources with Question
& Answer Archives for Translation-based Answer
Finding. In Proc. of ACL-IJCNLP 2009, Singa-
pore, pp728-736.
Ellen M. Voorhees. 2003 Overview of the TREC
2003 Question Answering Track. In Proc. of
TREC 2003, pp54-68, USA.
Qtype Examples
? 3/Hazard-
type
\E?#F{?34??What
are the hazards of global warming?
*~/Function-
type
?\){*~4??What are the
functions of the United Nations?
k //Impact-
type
??911/G??){k/List
the impact of the 911 attacks on the
United States.
?B/ ???)?WTO{?B
Significance-
type
List the significance of China?s acces-
sion to the WTO.
? ?/Attitude-
type
???)??1?B{??List
the attitudes of other countries toward
the Israeli-Palestinian conflict.
D/Measure-
type
????>\0?fR?
?JD?What measures have
been taken for energy-saving and
emissions-reduction in Japan?
? O/Reason-
type
\E?#F{?O4??What
are the reasons for global warming?
?}/Casualty-
type
??b.8
{?}List the
casualties of the Lockerbie Air Disas-
ter.
/ G/Event-
type
????}Z?Z??g/
GList the events in the Northern
Ireland peace process.
 ?/Scale-
type
??f?-??2F??{
?Give information about the scale
of the Kunming World Horticulture
Exposition.
Eugene Agichtein, Carlos Castillo, Debora Donato.
2008 Finding High-Quality Content in Social Me-
dia. In Proc. of WSDM 2008, California, USA.
Franz J. Och and Hermann Ney. 2003. A system-
atic Comparison of Various Statistical Alignment
Models. In Computational Linguistics, 29(1):19-
51.
Gunes Erkan and Dragomir Radev. 2004. LexRank:
Graph-based Lexical Centrality as Salience in
Text. In Journal of Artificial Intelligence
Research,22:457-479.
Hang Cui, Min Yen Kan, and Tat Seng Chua. 2004.
Unsupervised Learning of Soft Patterns for Defini-
tion Question Answering. In Proc. of WWW 2004.
Hoa Trang Dang. 2006. Overview of DUC 2006. In
Proc. of TREC 2006.
Huizhong Duan, Yunbo Cao, Chin Yew Lin, and
Yong Yu. 2008. Searching Questions by Identify-
ing Question Topic and Question Focus. In Proc.
of ACL 2008, Canada, pp 156-164.
Jimmy Lin and Dina Demner-Fushman. 2006. Will
Pyramids Built of Nuggets Topple Over. In Proc.
of HLT/NAACL2006, pp 383-390.
Mihai Surdeanu, Massimiliano Ciaramita, and Hugo
Zaragoza. 2008. Learning to Rank Answers on
Large Online QA Collections. In Proc. of ACL
2008, Ohio, USA, pp 719-727.
Ryuichiro Higashinaka and Hideki Isozaki. 2008.
Corpus-based Question Answering for why-
Questions. In Proc. of IJCNLP 2008, pp 418-425.
Tatsunori Mori, Takuya Okubo, and Madoka Ish-
ioroshi. 2008. A QA system that can answer any
class of Japanese non-factoid questions and its ap-
plication to CCLQA EN-JA task. In Proc. of NT-
CIR2008, Tokyo, pp 41-48.
Sanda Harabagiu, Finley Lacatusu, Andrew Hickl.
2006. Answering Complex Questions with Ran-
dom Walk Models. In Proc. of the 29th SIGIR, pp
220-227, ACM.
Ves Stoyanov, Claire Cardie, and Janyce Wiebe.
2005. Multi-Perspective Question Answering Us-
ing the OpQA Corpus. In Proc. of HLT/EMNLP
2005, Canada, pp 923-930.
Teruko Mitamura, Eric Nyberg, Hideki Shima,
Tsuneaki Kato, Tatsunori Mori, Chin-Yew Lin,
Ruihua Song, Chuan-Jie Lin, Tetsuya Sakai,
Donghong Ji and Noriko Kando. 2008. Overview
of the NTCIR-7 ACLIA Tasks: Advanced Cross-
Lingual Information Access. In Proc. of NTCIR
2008.
Thorsten Joachims. 2005. A Support Vector Method
for Multivariate Performance Measures. In Proc.
of ICML2005, pp 383-390.
Vladimir Vapnik 1998. Statistical learning theory.
John Wiley.
Xiaobing Xue, Jiwoon Jeon, W.Bruce Croft. 2008.
Retrieval Models for Question and Answer
Archives. In Proc. of SIGIR 2008, pp 475-482.
Yutaka Sasaki. 2005. Question Answering as
Question-biased Term Extraction: A New Ap-
proach toward Multilingual QA. In Proc. of ACL
2005, pp 215-222.
Youzheng Wu, Jun Zhao, Bo Xu, and Hao Yu. 2005.
Chinese Named Entity Recognition Model based
on Multiple Features. In Proc. of HLT/EMNLP
2005, Canada, pp 427-434.
Yuanjie Liu, Shasha Li, Yunbo Cao, Chin-Yew Lin,
Dingyi Han, Yong Yu. 2008. Understanding
and Summarizing Answers in Community-Based
Question Answering Services. In Proc. of COL-
ING 2008, Manchester, pp 497-504.
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 221?224,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Modeling Spoken Decision Making Dialogue
and Optimization of its Dialogue Strategy
Teruhisa Misu, Komei Sugiura, Kiyonori Ohtake,
Chiori Hori, Hideki Kashioka, Hisashi Kawai and Satoshi Nakamura
MASTAR Project, NICT
Kyoto, Japan.
teruhisa.misu@nict.go.jp
Abstract
This paper presents a spoken dialogue frame-
work that helps users in making decisions.
Users often do not have a definite goal or cri-
teria for selecting from a list of alternatives.
Thus the system has to bridge this knowledge
gap and also provide the users with an appro-
priate alternative together with the reason for
this recommendation through dialogue. We
present a dialogue state model for such deci-
sion making dialogue. To evaluate this model,
we implement a trial sightseeing guidance sys-
tem and collect dialogue data. Then, we opti-
mize the dialogue strategy based on the state
model through reinforcement learning with a
natural policy gradient approach using a user
simulator trained on the collected dialogue
corpus.
1 Introduction
In many situations where spoken dialogue interfaces
are used, information access by the user is not a goal in
itself, but a means for decision making (Polifroni and
Walker, 2008). For example, in a restaurant retrieval
system, the user?s goal may not be the extraction of
price information but to make a decision on candidate
restaurants based on the retrieved information.
This work focuses on how to assist a user who is
using the system for his/her decision making, when
he/she does not have enough knowledge about the tar-
get domain. In such a situation, users are often un-
aware of not only what kind of information the sys-
tem can provide but also their own preference or fac-
tors that they should emphasize. The system, too, has
little knowledge about the user, or where his/her inter-
ests lie. Thus, the system has to bridge such gaps by
sensing (potential) preferences of the user and recom-
mend information that the user would be interested in,
considering a trade-off with the length of the dialogue.
We propose a model of dialogue state that consid-
ers the user?s preferences as well as his/her knowledge
about the domain changing through a decision making
dialogue. A user simulator is trained on data collected
with a trial sightseeing system. Next, we optimize
the dialogue strategy of the system via reinforcement
learning (RL) with a natural policy gradient approach.
2 Spoken decision making dialogue
We assume a situation where a user selects from a given
set of alternatives. This is highly likely in real world
situations; for example, the situation wherein a user se-
lects one restaurant from a list of candidates presented
Choose the optimal spot
1. Cherry 
Blossoms
2. Japanese
Garden
3. Easy
Access
Kinkakuji-
Temple
Ryoanji-
Temple
Nanzenji-
Temple
?
?????
Goal
Criteria
Alternatives
(choices)
?????
p1 p2 p3
v11 v12 v13
? ?
Figure 1: Hierarchy structure for sightseeing guidance
dialogue
by a car navigation system. In this work, we deal with
a sightseeing planning task where the user determines
the sightseeing spot to visit, with little prior knowledge
about the target domain. The study of (Ohtake et al,
2009), which investigated human-human dialogue in
such a task, reported that such consulting usually con-
sists of a sequence of information requests from the
user, presentation and elaboration of information about
certain spots by the guide followed by the user?s evalu-
ation. We thus focus on these interactions.
Several studies have featured decision support sys-
tems in the operations research field, and the typical
method that has been employed is the Analytic Hierar-
chy Process (Saaty, 1980) (AHP). In AHP, the problem
is modeled as a hierarchy that consists of the decision
goal, the alternatives for achieving it, and the criteria
for evaluating these alternatives. An example hierarchy
using these criteria is shown in Figure 1.
For the user, the problem of making an optimal de-
cision can be solved by fixing a weight vector P
user
=
(p
1
, p
2
, . . . , p
M
) for criteria and local weight matrix
V
user
= (v
11
, v
12
, . . . , v
1M
, . . . , v
NM
) for alterna-
tives in terms of the criteria. The optimal alternative
is then identified by selecting the spot k with the maxi-
mum priority of
?
M
m=1
p
m
v
km
. In typical AHP meth-
ods, the procedure of fixing these weights is often con-
ducted through pairwise comparisons for all the possi-
ble combinations of criteria and spots in terms of the
criteria, followed by weight tuning based on the re-
sults of these comparisons (Saaty, 1980). However, this
methodology cannot be directly applied to spoken dia-
logue systems. The information about the spot in terms
of the criteria is not known to the users, but is obtained
only via navigating through the system?s information.
In addition, spoken dialogue systems usually handle
several candidates and criteria, making pairwise com-
parison a costly affair.
We thus consider a spoken dialogue framework that
estimates the weights for the user?s preference (po-
tential preferences) as well as the user?s knowledge
221
about the domain through interactions of information
retrieval and navigation.
3 Decision support system with spoken
dialogue interface
The dialogue system we built has two functions: an-
swering users? information requests and recommend-
ing information to them. When the system is requested
to explain about the spots or their determinants, it ex-
plains the sightseeing spots in terms of the requested
determinant. After satisfying the user?s request, the
system then provides information that would be helpful
in making a decision (e.g., instructing what the system
can explain, recommending detailed information of the
current topic that the user might be interested in, etc.).
Note that the latter is optimized via RL (see Section 4).
3.1 Knowledge base
Our back-end DB consists of 15 sightseeing spots as al-
ternatives and 10 determinants described for each spot.
We select determinants that frequently appear in the di-
alogue corpus of (Ohtake et al, 2009) (e.g. cherry blos-
soms, fall foliage). The spots are annotated in terms of
these determinants if they apply to them. The value of
the evaluation e
nm
is ?1? when the spot n applies to the
determinant m and ?0? when it does not.
3.2 System initiative recommendation
The content of the recommendation is determined
based on one of the following six methods:
1. Recommendation of determinants based on the
currently focused spot (Method 1)
This method is structured on the basis of the user?s
current focus on a particular spot. Specifically, the
system selects several determinants related to the
current spot whose evaluation is ?1? and presents
them to the user.
2. Recommendation of spots based on the cur-
rently focused determinant (Method 2)
This method functions on the basis of the focus on
a certain specific determinant.
3. Open prompt (Method 3)
The system does not make a recommendation, and
presents an open prompt.
4. Listing of determinants 1 (Method 4)
This method lists several determinants to the user in
ascending order from the low level user knowledge
K
sys
(that the system estimates). (K
sys
, P
sys
, p
m
and Pr(p
m
= 1) are defined and explained in Sec-
tion 4.2.)
5. Listing of determinants 2 (Method 5)
This method also lists the determinants, but the or-
der is based on the user?s high preference P
sys
(that
the system estimates).
6. Recommendation of user?s possibly preferred
spot (Method 6)
The system recommends a spot as well as the de-
terminants that the users would be interested in
based on the estimated preference P
sys
. The sys-
tem selects one spot k with a maximum value of
?
M
m=1
Pr(p
m
= 1) ? e
k,m
. This idea is based
on collaborative filtering which is often used for
recommender systems (Breese et al, 1998). This
method will be helpful to users if the system suc-
cessfully estimates the user?s preference; however,
it will be irrelevant if the system does not.
We will represent these recommendations
through a dialogue act expression, (ca
sys
{sc
sys
}),
which consists of a communicative act ca
sys
and the semantic content sc
sys
. (For exam-
ple Method1{(Spot
5
), (Det
3
,Det
4
,Det5)},
Method3{NULL,NULL}, etc.)
4 Optimization of dialogue strategy
4.1 Models for simulating a user
We introduce a user model that consists of a tuple of
knowledge vector K
user
, preference vector P
user
, and
local weight matrix V
user
. In this paper, for simplic-
ity, a user?s preference vector or weight for determi-
nants P
user
= (p
1
, p
2
, . . . , p
M
) is assumed to con-
sist of binary parameters. That is, if the user is in-
terested in (or potentially interested in) the determi-
nant m and emphasizes it when making a decision,
the preference p
m
is set to ?1?. Otherwise, it is set
to ?0?. In order to represent a state that the user has
potential preference, we introduce a knowledge param-
eter K
user
= (k
1
, k
2
, . . . , k
M
) that shows if the user
has the perception that the system is able to handle or
he/she is interested in the determinants. k
m
is set to
?1? if the user knows (or is listed by system?s recom-
mendations) that the system can handle determinant m
and ?0? when he/she does not. For example, the state
that the determinant m is the potential preference of a
user (but he/she is unaware of that) is represented by
(k
m
= 0, p
m
= 1). This idea is in contrast to previous
research which assumes some fixed goal observable by
the user from the beginning of the dialogue (Schatz-
mann et al, 2007). A user?s local weight v
nm
for spot
n in terms of determinant m is set to ?1?, when the
system lets the user know that the evaluation of spots is
?1? through recommendation Methods 1, 2 and 6.
We constructed a user simulator that is based on
the statistics calculated through an experiment with the
trial system (Misu et al, 2010) as well as the knowl-
edge and preference of the user. That is, the user?s com-
municative act cat
user
and the semantic content sct
user
for the system?s recommendation at
sys
are generated
based on the following equation:
Pr(cat
user
, sct
user
|cat
sys
, sct
sys
,K
user
,P
user
)
= Pr(cat
user
|cat
sys
)
?Pr(sct
user
|K
user
,P
user
, cat
user
, cat
sys
, sct
sys
)
This means that the user?s communicative act ca
user
is sampled based on the conditional probability of
Pr(cat
user
|cat
sys
) in (Misu et al, 2010). The seman-
tic content sc
user
is selected based on the user?s pref-
erence P
user
under current knowledge about the de-
terminants K
user
. That is, the sc is sampled from the
determinants within the user?s knowledge (k
m
= 1)
based on the probability that the user requests the de-
terminant of his/her preference/non-preference, which
is also calculated from the dialogue data of the trial sys-
tem.
4.2 Dialogue state expression
We defined the state expression of the user in the pre-
vious section. However the problem is that for the
system, the state (P
user
,K
user
,V
user
) is not observ-
able, but is only estimated from the interactions with
the user. Thus, this model is a partially observable
Markov decision process (POMDP) problem. In or-
der to estimate unobservable properties of a POMDP
222
 
Priors of the estimated state:
- Knowledge: K
sys
= (0.22, 0.01, 0.02, 0.18, . . . )
- Preference: P
sys
= (0.37, 0.19, 0.48, 0.38, . . . )
Interactions (observation):
- System recommendation:
a
sys
= Method1{(Spot
5
), (Det
1
, Det
3
, Det4)}
- User query:
a
user
= Accept{(Spot
5
), (Det
3
)}
Posterior of the estimated state:
- Knowledge: K
sys
= (1.00, 0.01, 1.00, 1.00, . . . )
- Preference: P
sys
= (0.26, 0.19, 0.65, 0.22, . . . )
User?s knowledge acquisition:
- Knowledge: K
user
? {k
1
= 1, k
3
= 1, k
4
= 1}
- Local weight: V
user
? {v
51
= 1, v
53
= 1, v
54
=
1}
 
Figure 2: Example of state update
and handle the problem as an MDP, we introduce
the system?s inferential user knowledge vector K
sys
or probability distribution (estimate value) K
sys
=
(Pr(k
1
= 1), P r(k
2
= 1), . . . , P r(k
M
= 1)) and
that of preference P
sys
= (Pr(p
1
= 1), P r(p
2
=
1), . . . , P r(p
M
= 1)).
The dialogue state DSt+1 or estimated user?s dia-
logue state of the step t+1 is assumed to be dependent
only on the previous state DSt, as well as the interac-
tions It = (at
sys
, at
user
).
The estimated user?s state is represented as a prob-
ability distribution and is updated by each interac-
tion. This corresponds to representing the user types
as a probability distribution, whereas the work of (Ko-
matani et al, 2005) classifies users to several discrete
user types. The estimated user?s preference P
sys
is up-
dated when the system observes the interaction It. The
update is conducted based on the following Bayes? the-
orem using the previous state DSt as a prior.
Pr(p
m
= 1|It) =
Pr(I
t
|p
m
=1)Pr(p
m
=1)
Pr(I
t
|p
m
=1)Pr(p
m
=1)+Pr(I
t
|(p
m
=0))Pr(1?Pr(p
m
=1))
Here, Pr(It|p
m
= 1), P r(It|(p
m
= 0) to the right
side was obtained from the dialogue corpus of (Misu et
al., 2010). This posterior is then used as a prior in the
next state update using interaction It+1. An example
of this update is illustrated in Figure 2.
4.3 Reward function
The reward function that we use is based on the num-
ber of agreed attributes between the user preference
and the decided spot. Users are assumed to determine
the spot based on their preference P
user
under their
knowledge K
user
(and local weight for spots V
user
)
at that time, and select the spot k with the maximum
priority of
?
m
k
k
? p
k
? v
km
. The reward R is then
calculated based on the improvement in the number of
agreed attributes between the user?s actual (potential)
preferences and the decided spot k over the expected
agreement by random spot selection.
R =
M
?
m=1
p
m
? e
k,m
?
1
N
N
?
n=1
M
?
m=1
p
m
? e
n,m
For example, if the decided spot satisfies three prefer-
ences and the average agreement of the agreement by
random selection is 1.3, then the reward is 1.7.
4.4 Optimization by reinforcement learning
The problem of system recommendation generation is
optimized through RL. The MDP (S, A, R) is defined
as follows. The state parameter S = (s
1
, s
2
, . . . , s
I
) is
generated by extracting the features of the current dia-
logue state DSt. We use the following 29 features 1.
1. Parameters that indicate the # of interactions from
the beginning of the dialogue. This is approximated by
five parameters using triangular functions. 2. User?s
previous communicative act (1 if at?1
user
= x
i
, other-
wise 0). 3. System?s previous communicative act (1 if
at?1
sys
= y
j
, otherwise 0). 4. Sum of the estimated user
knowledge about determinants (?N
n=1
Pr(k
n
= 1)).
5. Number of presented spot information. 6. Expecta-
tion of the probability that the user emphasizes the de-
terminant in the current state (Pr(k
n
= 1)? Pr(p
n
=
1)) (10 parameters). The action set A consists of the
six recommendation methods shown in subsection 3.2.
Reward R is given by the reward function of subsection
4.3.
A system action a
sys
(ca
sys
) is sampled based on the
following soft-max (Boltzmann) policy.
?(a
sys
= k|S) = Pr(a
sys
= k|S,?)
=
exp(
?
I
i=1
s
i
? ?
ki
)
?
J
j=1
exp(
?
I
i=1
s
i
? ?
ji
)
Here, ? = (?
11
, ?
12
, . . . ?
1I
, . . . , ?
JI
) consists of J (#
actions) ? I (# features) parameters. The parameter
?
ji
works as a weight for the i-th feature of the ac-
tion j and determines the likelihood that the action j
is selected. This ? is the target of optimization by RL.
We adopt the Natural Actor Critic (NAC) (Peters and
Schaal, 2008), which adopts a natural policy gradient
method as the policy optimization method.
4.5 Experiment by dialogue simulation
For each simulated dialogue session, a simulated user
(P
user
,K
user
,V
user
) is sampled. A preference vector
P
user
of the user is generated so that he/she has four
preferences. As a result, four parameters in P
user
are
?1? and the others are ?0?. This vector is fixed through-
out the dialogue episode. This sampling is conducted
based on the rate proportional to the percentage of users
who emphasize it for making decisions (Misu et al,
2010). The user?s knowledge K
user
is also set based
on the statistics of the ?percentage of users who stated
the determinants before system recommendation?. For
each determinant, we sample a random valuable r that
ranges from ?0? to ?1?, and k
m
is set to ?1? if r is
smaller than the percentage. All the parameters of
local weights V
user
are initialized to ?0?, assuming
that users have no prior knowledge about the candi-
date spots. As for system parameters, the estimated
user?s preference P
sys
and knowledge K
sys
are ini-
tialized based on the statistics of our trial system (Misu
et al, 2010).
We assumed that the system does not misunderstand
the user?s action. Users are assumed to continue a di-
alogue session for 20 turns2, and episodes are sampled
using the policy ? at that time and the user simulator
1Note that about half of them are continuous variables and
that the value function cannot be denoted by a lookup table.
2In practice, users may make a decision at any point once
they are satisfied collecting information. And this is the rea-
son why we list the rewards in the early dialogue stage in
223
Table 1: Comparison of reward with baseline methods
Reward (?std)
Policy T = 5 T = 10 T = 15 T = 20
NAC 0.96 (0.53) 1.04 (0.51) 1.12 (0.50) 1.19 (0.48)
B1 0.02 (0.42) 0.13 (0.54) 0.29 (0.59) 0.34 (0.59)
B2 0.46 (0.67) 0.68 (0.65) 0.80 (0.61) 0.92 (0.56)
Table 2: Comparison of reward with discrete dialogue
state expression
Reward (?std)
State T = 5 T = 10 T = 15 T = 20
PDs 0.96 (0.53) 1.04 (0.51) 1.12 (0.50) 1.19 (0.48)
Discrete 0.89 (0.60) 0.97 (0.56) 1.03 (0.54) 1.10 (0.52)
Table 3: Effect of estimated preference and knowledge
Reward (?std)
Policy T = 5 T = 10 T = 15 T = 20
Pref+Know0.96 (0.53) 1.04 (0.51) 1.12 (0.50) 1.19 (0.48)
Pref only 0.94 (0.57) 0.96 (0.55) 1.02 (0.55) 1.09 (0.53)
Know only 0.96 (0.59) 1.00 (0.56) 1.08 (0.53) 1.15 (0.51)
No Pref or
Know
0.93 (0.57) 0.96 (0.55) 1.02 (0.53) 1.08 (0.52)
of subsection 4.1. In each turn, the system is rewarded
using the reward function of subsection 4.3. The pol-
icy (parameter ?) is updated using NAC in every 2,000
dialogues.
4.6 Experimental result
The policy was fixed at about 30,000 dialogue
episodes. We analyzed the learned dialogue policy by
examining the value of weight parameter ?. We com-
pared the parameters of the trained policy between ac-
tions3. The weight of the parameters that represent the
early stage of the dialogue was large in Methods 4 and
5. On the other hand, the weight of the parameters that
represent the latter stage of the dialogue was large in
Methods 2 and 6. This suggests that in the trained pol-
icy, the system first bridges the knowledge gap between
the user, estimates the user?s preference, and then, rec-
ommends specific information that would be useful to
the user.
Next, we compared the trained policy with the fol-
lowing baseline methods.
1. No recommendation (B1)
The system only provides the requested informa-
tion and does not generate any recommendations.
2. Random recommendation (B2)
The system randomly chooses a recommendation
from six methods.
The comparison of the average reward between the
baseline methods is listed in Table 1. Note that the ora-
cle average reward that can be obtained only when the
user knows all knowledge about the knowledge base
(it requires at least 50 turns) was 1.45. The reward by
the strategy optimized by NAC was significantly better
than that of baseline methods (n = 500, p < .01).
We then compared the proposed method with the
case where estimated user?s knowledge and preference
are represented as discrete binary parameters instead of
probability distributions (PDs). That is, the estimated
user?s preference p
m
of determinant m is set to ?1?
when the user requested the determinant, otherwise it
is ?0?. The estimated user?s knowledge k
m
is set to
the following subsections. In our trial system, the dialogue
length was 16.3 turns with a standard deviation of 7.0 turns.
3The parameters can be interpreted as the size of the con-
tribution for selecting the action.
?1? when the system lets the user know the determi-
nant, otherwise it is ?0?. Another dialogue strategy was
trained using this dialogue state expression. This result
is shown in Table 2. The proposed method that rep-
resents the dialogue state as a probability distribution
outperformed (p < .01 (T=15,20)) the method using a
discrete state expression.
We also compared the proposed method with the
case where either one of estimated preference or
knowledge was used as a feature for dialogue state in
order to carefully investigate the effect of these factors.
In the proposed method, expectation of the probabil-
ity that the user emphasizes the determinant (Pr(k
n
=
1) ? Pr(p
n
= 1)) was used as a feature of dialogue
state. We evaluated the performance of the cases where
the estimated knowledge Pr(k
n
= 1) or estimated
preference Pr(p
n
= 1) was used instead of the expec-
tation of the probability that the user emphasizes the
determinant. We also compared with the case where
no preference/knowledge feature was used. This result
is shown in Table 3. We confirmed that significant im-
provement (p < .01 (T=15,20)) was obtained by taking
into account the estimated knowledge of the user.
5 Conclusion
In this paper, we presented a spoken dialogue frame-
work that helps users select an alternative from a list of
alternatives. We proposed a model of dialogue state for
spoken decision making dialogue that considers knowl-
edge as well as preference of the user and the system,
and its dialogue strategy was trained by RL. We con-
firmed that the learned policy achieved a better recom-
mendation strategy over several baseline methods.
Although we dealt with a simple recommendation
strategy with a fixed number of recommendation com-
ponents, there are many possible extensions to this
model. The system is expected to handle a more com-
plex planning of natural language generation. We also
need to consider errors in speech recognition and un-
derstanding when simulating dialogue.
References
J. Breese, D. Heckerman, and C. Kadie. 1998. ?empirical
analysis of predictive algorithms for collaborative filter-
ing?. In ?Proc. the 14th Annual Conference on Uncer-
tainty in Artificial Intelligence?, pages 43?52.
K. Komatani, S. Ueno, T. Kawahara, and H. Okuno. 2005.
User Modeling in Spoken Dialogue Systems to Generate
Flexible Guidance. User Modeling and User-Adapted In-
teraction, 15(1):169?183.
T. Misu, K. Ohtake, C. Hori, H. Kashioka, H. Kawai, and
S. Nakamura. 2010. Construction and Experiment of a
Spoken Consulting Dialogue System. In Proc. IWSDS.
K. Ohtake, T. Misu, C. Hori, H. Kashioka, and S. Nakamura.
2009. Annotating Dialogue Acts to Construct Dialogue
Systems for Consulting. In Proc. The 7th Workshop on
Asian Language Resources, pages 32?39.
J. Peters and S. Schaal. 2008. Natural Actor-Critic. Neuro-
computing, 71(7-9):1180?1190.
J. Polifroni and M. Walker. 2008. Intensional Summaries
as Cooperative Responses in Dialogue: Automation and
Evaluation. In Proc. ACL/HLT, pages 479?487.
T. Saaty. 1980. The Analytic Hierarchy Process: Planning,
Priority Setting, Resource Allocation. Mcgraw-Hill.
J. Schatzmann, B. Thomson, K. Weilhammer, H. Ye, and
S. Young. 2007. Agenda-based User Simulation for
Bootstrapping a POMDP Dialogue System. In Proc.
HLT/NAACL.
224
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 259?265,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Toward Construction of Spoken Dialogue System
that Evokes Users? Spontaneous Backchannels
Teruhisa Misu, Etsuo Mizukami, Yoshinori Shiga, Shinichi Kawamoto?,
Hisashi Kawai and Satoshi Nakamura
National Institute of Information and Communications Technology (NICT), Kyoto, Japan.
teruhisa.misu@nict.go.jp
Abstract
This paper addresses a first step toward a
spoken dialogue system that evokes user?s
spontaneous backchannels. We construct
an HMM-based dialogue-style text-to-speech
(TTS) system that generates human-like cues
that evoke users? backchannels. A spoken
dialogue system for information navigation
was implemented and the TTS was evaluated
in terms of evoked user backchannels. We
conducted user experiments and demonstrated
that the user backchannels evoked by our TTS
are more informative for the system in detect-
ing users? feelings than those by conventional
reading-style TTS.
1 Introduction
One of the most enduring problems in spoken di-
alogue systems research is realizing a natural dia-
logue in a human-human form. One direction re-
searchers have been utilizing spontaneous nonverbal
and paralinguistic information. For example,
This paper focuses on backchannels, one of the
most common forms of para-linguistic information
in human-human dialogue. In particular, we focus
on users? verbal feedback, such as ?uh-huh? (called
Aizuchi in Japanese), and non-verbal feedback in the
form of nods. Such backchannels are very com-
mon phenomena, and considered to be used to fa-
cilitate smooth human-human communications. In
this regard, Maynard (Maynard, 1986) indicated that
such backchannels are listener?s signals to let the
speaker continue speaking (continuer), to indicate
that the listener understands and consents. It was
also hypothesized that humans detect feelings ex-
pressed via backchannels, and the correlation be-
tween backchannel patterns and user interests was
examined (Kawahara et al, 2008). These studies in-
dicate that detection of spontaneous user backchan-
? currently with Japan Advanced Institute of Science and
Technology (JAIST)
nels can benefit spoken dialogue systems by provid-
ing informative cues that reflect the user?s situation.
For instance, if a spoken dialogue system can detect
user?s backchannels, it can facilitate smooth turn-
taking. The system can also detect user?s feelings
and judge if it should continue the current topic or
change it.
Despite these previous studies and decades of
analysis on backchannels, few practical dialogue
systems have made use of them. This is proba-
bly due to the fact that users do not react as spon-
taneously to dialogue systems as they do to other
humans. We presume one of the reasons for this
is the unnatural intonation of synthesized speech.
That is, conventional speech synthesizers do not pro-
vide users with signs to elicit backchannels; an ap-
propriate set of lexical, acoustic and prosodic cues
(or backchannel-inviting cues (A. Gravano and J.
Hirschberg, 2009)), which tends to precede the lis-
tener?s backchannels in human-human communica-
tion. Though recorded human speech can provide
such cues, it is costly to re-record system?s speech
every time system scripts are updated. In this work,
we therefore tackle the challenge of constructing
dialogue-style text-to-speech (TTS) system that in-
spires users to make spontaneous backchannels un-
der the hypothesis of:
People will give more spontaneous backchannels to
a spoken dialogue system that makes more spontaneous
backchannel-inviting cues than a spoken dialogue system
that makes less spontaneous ones.
which is derived from the Media Equation (Reeves
and Nass, 1996).
2 Related Works
A number of studies have aimed at improving
the naturalness of TTS. Though most of these
have focused on means of realizing a clear and
easy-to-listen-to reading-style speech, some at-
tempts have been made at spontaneous conversa-
tional speech. Andersson (Andersson et al, 2010)
and Marge (Marge et al, 2010) focused on lexi-
259
cal phenomena such as lexical filler and acknowl-
edgments in spontaneous speech, and showed that
inserting them improves the naturalness of human-
computer dialogues. In this work, we tackle con-
structing a natural dialogue-style TTS system focus-
ing on prosodic phenomena such as intonation and
phoneme duration.
In the field of conversation analysis, many studies
analyzed backchannels in human-human dialogue
focusing on lexical and non-verbal cues (Koiso et
al., 1998; Ward and Tsukahara, 2000; A. Gravano
and J. Hirschberg, 2009). For instance these cues
were examined in preceding utterances, such as in
part-of-speech tags, length of pause, power contour
pattern, and F
0
contour pattern around the end of
the Inter-Pausal Units (IPUs). (A. Gravano and J.
Hirschberg, 2009) showed that when several of the
above cues occur simultaneously, the likelihood of
occurrence of a backchannel will increase.
Several studies also utilized the above findings
for spoken dialogue systems. Okato (Okato et al,
1996) and Fujie (Fujie et al, 2005) trained models to
predict backchannels, and implemented spoken di-
alogue systems that make backchannels. Our goal
differs in that it is to inspire users to give backchan-
nels.
3 Construction of Spoken Dialogue TTS
3.1 Spoken Dialogue Data collection for TTS
In order to make spontaneous dialogue-style TTS
that can evoke backchannels, we construct a spon-
taneous dialogue-style speech corpus that contains
backchannel-inviting cues, and then train an HMM
acoustic model for synthesis.
We collected our training data by dubbing a script
of our Kyoto Sightseeing Guidance Spoken Dia-
logue Corpus (Misu et al, 2009), a set of itinerary-
planning dialogues in Japanese. In the dialogue
task, the expert guide has made recommendations on
sightseeing spots and restaurants until has decided
on a plan for the day. With the guide?s recommen-
dations, many users give spontaneous backchannels.
We made a set of dialogue scripts from the corpus,
and asked voice actors to act them out.
When preparing the dialogue script for dubbing,
we first removed fillers and backchannels from the
transcripts of the dialogue corpus. We then anno-
tated the guide?s end of the IPUs, where the the
user made backchannels, with #. A sample dialogue
script is shown in Figure 6. We asked two profes-
sional voice actresses to duplicate the spoken dia-
logue of the script, with playing the role of the tour
guide, and the other as the tourist, sitting face-to-
face. During the recording, we asked the tour guide
role to read the scenario with intonation so that the
tourist role would spontaneously make backchan-
nels at the points marked with #. The tourist was
allowed to make backchannels at will at any pause
segments the guide made. We recorded 12 dialogue
sessions in total. The speech data was manually la-
beled, and 239.3 minutes of tour guide utterances,
which are used to train our HMM for the TTS sys-
tem, were collected. The training data is comple-
mented by the ATR 503 phonetically balanced sen-
tence set (Abe et al, 1990), so as to cover deficien-
cies in the phoneme sequence. The sentence set is
collected from news articles, and data consists of
43.1 minutes of reading-style speech.
3.2 Analysis of Collected Speech Data
Before training the HMM, we analyzed the collected
spoken dialogue data to confirm if the recorded di-
alogue speech data contained backchannel-inviting
prosodic cues. We compared prosodic features of
the dialogue speech data with those of the reading-
style speech data (phonetically balanced sentences
that we collected). Following the findings of a pre-
vious study (Koiso et al, 1998), we investigated the
duration, F
0
contour pattern and power contour pat-
tern of the final phoneme of the IPUs1.
In conversation analysis of Japanese, the F
0
con-
tour pattern label of the final phoneme is often used.
While the contour pattern is usually manually la-
beled, we roughly determined the patterns based on
the following procedure. We first normalized the log
F
0
scale using all utterances so that it has zero mean
and one standard deviation (z-score: z = (x??)/?).
We then divided each final phoneme of the IPU into
former and latter parts, and calculated the F
0
slope
of each segment by linear regression. By combina-
tion of following three patterns, we defined nine F
0
contour patterns for the final phonemes of the IPUs.
The pattern of the segment was judged as rise if the
slope was larger than a threshold ?. If the slope was
less than the threshold??, the pattern was judged as
fall. Otherwise, it was judged as flat. Here, ? was
empirically set to 5.0. The power contour patterns
of the IPUs were estimated by a similar procedure.
We analyzed 3,311 IPUs that were not followed
1For this study, we define an IPU as a maximal sequence
of words surrounded by silence longer than 200 ms. This unit
usually coincides with one Japanese phrasal unit.
260
Table 1: Prosodic analysis of final phonemes of IPUs
(dialogue script vs. newsarticle script)
dialogue newsarticle
dur. phoneme [msec] 177.1 (? 83.6) 119.4 (? 31.3)
average (? standard deviation)
F
0
power
pattern dialogue news dialogue news
rise-rise 3.7 % 10.4 % 0.0 % 0.0 %
rise-flat 2.6 % 2.1 % 0.0 % 0.0 %
rise-fall 18.8 % 3.2 % 0.0 % 0.0 %
flat-rise 4.8 % 11.5 % 0.0 % 0.0 %
flat-flat 3.5 % 1.8 % 0.0 % 9.2 %
flat-fall 12.6 % 2.7 % 13.6 % 0.1 %
fall-rise 29.2 % 47.0 % 0.0 % 0.0 %
fall-flat 7.7 % 9.0 % 86.0 % 90.7 %
fall-fall 17.1 % 12.3 % 0.0 % 0.0 %
by a turn-switch in the dialogue-style speech data
and 645 non-sentence-end IPUs in the reading-
style speech data. The prosodic features of final
phonemes of these IPUs are listed in Table 1.
According to a study (Koiso et al, 1998), in which
prosodic features of IPUs followed by a turn-hold
with backchannel, without backchannel and turn-
switch were compared, a long duration in the final
phoneme is a speaker?s typical sign to keep floor.
The same study also reported that the flat-fall and
rise-fall pattern of F
0
and power are more likely
to be followed by a backchannel than a turn-hold
without a backchannel and turn-switch. In our col-
lected speech corpus, there were actually signifi-
cant (p < 0.01) differences in the duration of the
final phoneme between that in the dialogue-style
speech and in reading-style speech. There was
also significant (p < 0.01) difference in the oc-
currence probability of the above two prosodic pat-
terns between dialogue-style speech and reading-
style speech data. These figures indicate that
as a whole the collected dialogue-style data con-
tains more backchannel-inviting cues than collected
reading-style speech data.
We trained HMM for our TTS system Ximera
using the HMM-based Speech Synthesis System
(HTS) (Zen et al, 2007). We adopted mel log spec-
trum approximation (MLSA) filter-based vocod-
ing (SPTK, 2011), a quint-phone-based phoneme
set and five state HMM-based acoustic modeling.
All training data including reading-style speech data
were used for model training.
4 User Experiment
4.1 Dialogue System used for Experiment
To evaluate our TTS system based on users? reac-
tions, a sightseeing guidance spoken dialogue sys-
Figure 1: Screen shot of the dialogue system
tem that assist users in making decision was im-
plemented. The system can explain six sightseeing
spots in Kyoto. The system provides responses to
user requests for explanation about a certain spot.
Each descriptive text on a sightseeing spot consists
of 500 (?1%) characters, 30 phrases. The text is
synthesized using section 3 TTS2. We set the speech
rate of our TTS as nine phoneme per second.
A display is used to present photos of the tar-
get sightseeing spot and an animated 3D desktop
avatar named Hanna. Figure 1 shows the GUI
the user sees. The avatar can express its status
through several motions. For example, when the
user begins speaking, it can express the state of
listening using the listener?s motion, as shown in
the figure. A sample dialogue with the system is
shown in Table 7. A video (with English subtitles)
of an sample dialogue with a user can be seen at
http://mastarpj.nict.go.jp/?xtmisu/video/TTS.wmv.
To compare the effectiveness of our TTS in
evoking users? spontaneous backchannels, we con-
structed a comparison system that adopts a conven-
tional reading-style TTS system. An HMM model
was trained using 10-hour reading-style speech by
another professional female narrator. Other settings,
such as the descriptive text and avatar agent, were
the same as those of the base system.
4.2 Comparison of Prosodic Features of the
Synthesized Speech
Prior to the experiments, we investigated the
prosodic features of the final phoneme of IPUs in
the synthesized explanations on six spots to confirm
if they contain backchannel-inviting cues. The re-
sults are given in Table 2.
Tendencies in the duration of the final phoneme
and prosody pattern distribution of the synthesized
2The descriptive texts are not included in the training data.
261
Table 2: Prosodic analysis of final phonemes of IPUs
(dialogue-style TTS vs. reading-style TTS)
dialogue synth. reading synth.
dur. phoneme [msec] 172.9 (? 29.6) 126.1 (? 19.1)
average (? standard deviation)
F
0
power
pattern dialogue reading dialogue reading
rise-rise 5.4 % 0.0 % 0.0 % 0.0 %
rise-flat 2.0 % 0.0 % 1.7 % 0.0 %
rise-fall 23.5 % 0.0 % 46.3 % 5.3 %
flat-rise 5.0 % 0.0 % 0.0 % 0.0 %
flat-flat 1.7 % 0.0 % 4.0 % 9.2 %
flat-fall 15.8 % 0.0 % 22.8 % 18.1 %
fall-rise 15.8 % 0.0 % 0.7 % 0.0 %
fall-flat 3.4 % 0.0 % 7.0 % 0.0 %
fall-fall 27.5 % 100.0 % 17.4 % 76.5 %
speech by the dialogue-style TTS system were simi-
lar to that of recorded dialogue speech, suggests that
the constructed dialogue-style TTS system can du-
plicate the backchannel-inviting cues of the recorded
original speech. The synthesized dialogue-style
speech also contained much more rise-fall and flat-
fall patterns in F
0
and power than that generated by
the reading-style TTS system. The average dura-
tion of the final phoneme was also longer. Consider-
ing the fact that the speech data was generated from
the same script, this indicates that the synthesized
speech by the dialogue-style TTS system contains
more backchannel-inviting features than that by the
reading-style TTS system.
4.3 Experimental Setup
We evaluated the TTS systems using 30 subjects
who had not previously used spoken dialogue sys-
tems. Subjects were asked to use the dialogue sys-
tem in two settings; dialogue-style TTS system and
reading-style TTS system. The experiment was con-
ducted in a small (about 2 m2) soundproof room
with no one else present.
We instructed the subjects to speak with the avatar
agent Hanna (not with the system). We also told
them that the avatar agent was listening to their
speech at all times using the microphone, and was
observing their reactions using the camera above the
display3. Subjects were given the task of acquiring
information about three candidate sightseeing spots
in Kyoto shown on the display and then selecting
one that they liked. An example dialogue with the
system is shown in Table 7. A video (with English
subtitles) showing a real user dialogue can be seen
at http://mastarpj.nict.go.jp/?xtmisu/video/exp.avi.
3The system did not actually sense the subjects? reactions.
Table 3: Questionnaire items
1. Overall, which speech was better?
2. Which speech had easier-to-understand explanations?
3. For which speech did you feel compelled to give
backchannels?
4. Which speech was more appropriate for this system?
5. Which speech had more human-like explanation?
(a) both
(b) dialogue style
(c) reading style
(d) neither
#5#4
#3#2
#1
Figure 2: Questionnaire results
After the subject selected from candidate spots,
we changed the TTS system settings and instructed
the user to have another dialogue session selecting
one of another three spots. Considering the effects of
the order, the subjects were divided into four groups;
the first group (Group 1) used the system in the order
of ?Spot list A with dialogue-style speech ? Spot
list B with reading-style speech,? the second group
(Group 2) worked in reverse order. Groups 3 and 4
used a system alternating the order of the spot sets.
5 Experimental Results
5.1 Questionnaire Results
After the experiments, subjects were asked to fill in
a questionnaire about the system. Table 3 shows the
questionnaire items. The subjects selected (a) both
are good, (b) dialogue-style speech was better, (c)
reading-style speech was better, or (d) neither were
good. Figure 2 shows the results.
The dialogue-style speech generally earned
higher ratings, but reading-style was slightly higher
in items #2 and #5. This tendency is likely at-
tributable to the fact that the dialogue-style speech
had worse clarity and naturalness than reading-style.
The mean opinion score (MOS), which is often used
to measure clarity and naturalness of TTS, of the
dialogue-style TTS was in fact 2.79, worse than 3.74
for the reading-style.
5.2 Analysis of Frequency of Backchannels
We analyzed the number of backchannels that users
made during the dialogue session. We manually
annotated subjects? verbal feedbacks, such as ?uh-
huh? and nodding of the head using the recorded
video. Out of 30 subjects, 26 gave some form of
262
Table 4: Percentages and average number of users who made backchannels
TTS % users made BCs # average BCs taken
Group 1: (Dialogue? Reading) Dialogue-style 100.0% (50.0%, 100.0%) 30.4 (1.8, 28.6)
(Spot list A? Spot list B) Reading-style 100.0% (50.0%, 87.5%) 26.1 (3.1, 23.0)
Group 2: (Reading? Dialogue) Dialogue-style 75.0% (25.0%, 62.5%) 12.7 (0.5, 12.2)
(Spot list A? Spot list B) Reading-style 75.0% (25.0%, 62.5%) 12.9 (1.3, 11.6)
Group 3: (Dialogue? Reading) Dialogue-style 100.0% (28.6%, 100.0%) 14.0 (0.4, 13.6)
(Spot list B? Spot list A) Reading-style 100.0% (0%, 100.0%) 19.3 (0, 19.3)
Group 4: (Reading? Dialogue) Dialogue-style 87.5% (42.9%, 87.5%) 28.2 (4.7, 23,5)
(Spot list B? Spot list A) Reading-style 100.0% (71.4%, 87.5%) 24.8 (6.5, 18.3)
All: Dialogue-style 86.7% (36.7%, 86.7%) 21.1 (1.7, 19.4)
Reading-style 90.0% (40.0%, 83.3%) 20.6 (2.4, 18.2)
Total backchannel (verbal feedback [Aizuchi], nodding)
backchannel to the system. Table 4 shows the per-
centages and average number of times subjects gave
backchannels. Many users made more backchannels
using the dialogue-style TTS system. Despite the
significant difference in questionnaire item #3, there
were no significant differences in the average num-
ber of users? backchannels.
5.3 Informativeness of Backchannels
We then evaluated the TTS in terms of the informa-
tiveness of evoked backchannels. The spontaneous
prosodic pattern of the backchannels is expected
to suggest positive/negative feelings on regarding
the recommended candidate. One promising use
of backchannels in our application is for detecting
users? feelings about the currently focused on spot,
and choosing to continue the explanation on the cur-
rent topic if the user seems interested, or otherwise
change the topic. We therefore label backchannels
made during the systems explanation of the spot
that the user finally selected as ?positive? and those
made during the explanations of the other two spots
as ?negative? and consider distinguishing between
them. In human-human dialogues, it was confirmed
that when a user responds promptly, the majority of
responses are positive, and more backchannels also
suggest positive responses (Kawahara et al, 2008).
We investigated the informativeness of the
backchannels based on their classification rate, or
whether the system can distinguish positive and neg-
ative backchannels, using 10-fold cross-validation.
That is, the backchannels evoked by the dialogue-
style TTS system were divided into 10 groups and
nine were used for training and the other for classi-
fication tests. We trained decision trees using J4.8
algorithm using timing, frequency, total frequency
throughout the session and type of backchannel (ver-
bal feedback or nod) as the feature set. The classifi-
cation error cost of the positive sample was set to (#
negative samples / # positive samples) considering
the difference in the number of positive and nega-
tive samples. Ten trials were conducted by chang-
ing the test set and the average classification rate
was calculated. The classification rate of backchan-
nels evoked by the system with dialogue-style TTS
was 71.4%, The confusion matrix of the classifi-
cation is shown below. We obtained precisions of
62.8% in the classification of the positive backchan-
nels, and 73.2% in that of the negative backchan-
nels. The rates are significantly higher than chance
rates of 33.5% and 66.5%. This result indicates
the backchannels evoked by the dialogue-style TTS
were informative for the system.
Table 5: Confusion matrix of classification
? classified as positive negative
? label
positive 76 141
negative 45 386
The classification rate of the reading-style TTS
system was calculated in the same way. The av-
erage classification rate of backchannels evoked by
reading-style TTS was a significantly lower 47.4%,
meaning they were not informative at all.
These results suggest that our dialogue-style TTS
system can evoke more spontaneous and informative
backchannels that reflects users? intentions than the
conventional reading-style one. This classification
rate is not completely satisfactory, but we expect that
users? feeling can be detected after observing several
backchannels. We also believe that we can estimate
users? interest more precisely by combining verbal
information of dialogue acts (Misu et al, 2010).
6 Conclusions
This paper presented our first steps toward a spoken
dialogue system that evokes users? spontaneous lis-
tener?s reactions. We constructed a dialogue-style
TTS and confirmed that by generating human-like
backchannel-inviting cues, the system can evoke
user?s spontaneous backchannels, which are infor-
mative for the system.
263
References
A. Gravano and J. Hirschberg. 2009. Backchannel-
inviting cues in task-oriented dialogue. In Proc. In-
terspeech, pages 1019?1022.
M. Abe, Y. Sagisaka, T. Umeda, and H. Kuwabara. 1990.
Speech Database User?s Manual. ATR Technical Re-
port TR-I-0166.
S. Andersson, K. Georgila, D. Traum, and R. Clark
M. Aylett. 2010. Prediction and Realisation of Con-
versational Characteristics by Utilising Spontaneous
Speech for Unit Selection. In Proc. Speech Prosody.
S. Fujie, K. Fukushima, and T. Kobayashi. 2005. Back-
channel feedback generation using linguistic and non-
linguistic information and its application to spoken di-
alogue system. In Proc. Interspeech, pages 889?892.
T. Kawahara, M. Toyokura, T. Misu, and C. Hori. 2008.
Detection of Feeling Through Back-Channels in Spo-
ken Dialogue. In Proc. Interspeech, pages 1696?1696.
H. Koiso, Y. Horiuchi, S. Tutiya, A. Ichikawa, and
Y. Den. 1998. An Analysis of Turn-Taking and
Backchannels based on Prosodic and Syntactic Fea-
tures in Japanese Map Task Dialogue. Language and
Speech, 41(3-4):295?322.
M. Marge, J. Miranda, A. Black, and A. I. Rudnicky.
2010. Towards Improving the Naturalness of Social
Conversations with Dialogue Systems. In Proc. SIG-
DIAL, pages 91?94.
S. Maynard. 1986. On back-channel behavior in
japanese and english casual conversation. Linguistics,
24(6):1079?1108.
T. Misu, K. Ohtake, C. Hori, H. Kashioka, and S. Naka-
mura. 2009. Annotating Communicative Function
and Semantic Content in Dialogue Act for Construc-
tion of Consulting Dialogue Systems. In Proc. Inter-
speech.
Teruhisa Misu, Komei Sugiura, Kiyonori Ohtake, Chiori
Hori, Hideki Kashioka, Hisashi Kawai, and Satoshi
Nakamura. 2010. Dialogue Strategy Optimization
to Assist User?s Decision for Spoken Consulting Di-
alogue Systems. In Proc. IEEE-SLT, pages 342?347.
Y. Okato, K. Kato, M. Yamamoto, and S. Itahashi. 1996.
Insertion of interjectory response based on prosodic
information. In Proc. of IEEE Workshop Interac-
tive Voice Technology for Telecommunication Applica-
tions, pages 85?88.
B. Reeves and C. Nass. 1996. The Media Equation: How
People Treat Computers, Television, and New Media
Like Real People and Places. Cambridge University
Press.
SPTK, 2011. Speech Signal Processing Toolkit (SPTK).
http://sp-tk.sourceforge.net/.
N. Ward and W. Tsukahara. 2000. Prosodic fea-
tures which cue backchannel responses in English and
Japanese. Journal of Pragmatics, 32(8):1177?1207.
H. Zen, T. Nose, J. Yamagishi, S. Sako, T. Masuko, A.W.
Black, and K. Tokuda. 2007. The HMM-based speech
synthesis system version 2.0. In Proc. ISCA SSW6.
A Appendix
264
Table 6: Example dialogue scenario used for recording (translation of Japanese)
Guide And Kyomizu-dera.
Guide Yeah, it is very famous for.
Guide There is this like wooden balcony#, and you can?t see the whole city#, but you can see a
good part of the city from there. And it is a beautiful view.
User It is nice. You have been there?
Guide Yes, many a times.
Guide Unfortunately, in winter it is not very green#, and there are not any flowers.
User So if there is snow will they close the stairs or will they - we are just going to be careful
walking the steps?
Guide You have to be careful going up.
Guide Basically, it?s a slope it?s a slope#, so if it?s very icy - if there is, you know, like black
ice#, you might want to rethink hiking up that slope. But usually it is okay# in the winter.
I mean, Kyomizu-dera and this whole area, like every tourist eventually makes their way
here#, whether they are Japanese or foreign.
Guide So, I am sure the paths should be clear.
Guide Yeah, that is a good spot too.
Table 7: Example dialogue with the system (translation of Japanese)
System Hello, my name is Hanna, a tour guide for sightseeing in Kyoto. Nice to meet you. Please
say ?Okay? when you have decided which spot you would like to know about first.
User Okay.
System Which spot would you like to know about?
User Tell me about Shinnyo-do temple.
System Sure, I?ll explain Shinnyo-do temple.
System Shinnyo-do is a Buddhist Tendai Temple in Sakyo-ku, Kyoto City and the formal name is
Shinsho Gokuraku-ji. You may take the bus directly from Kyoto Station for about thirty
minutes, and the fee is two hundred twenty yen. The admission fee for the temple is five
hundred yen. The temple was established in nine hundred eighty-four A.D., when Amida
Nyorai-zo; a principle image from Mt. Hiei was placed in the Imperial villa of this area.
System Shall I continue?
User Sure.
System The temple is famous, especially for its coloring of autumn leaves; Red Maple stand on both
sides of the stone-paved approach, and it appears as though the temple is placed inside a
maple forest. . . .
. . .
System That?s all about this spot.
System Which spot would you like to know about next?
User Daitoku-ji please.
. . .
265
