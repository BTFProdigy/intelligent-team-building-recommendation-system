GoDiS  - An  Accommodat ing  Dia logue System 
Sta f fan  Larsson ,  Peter  L jung l6 f ,  Rob in  Cooper ,  E l i sabet  Engdah l ,  S t ina  Er i csson  
Depar tment  of linguistics, GSteborg University 
Box 200-295, Humanisten,  SE-405 30 G5teborg,  Sweden 
{s l ,  peb,  cooper ,  engdah l ,  s t inae}01 ing ,  gu. se 
Abst rac t  
This paper accompanies a demo of the GoDiS sys- 
tem. Work on~hi~ system was reported at IJCAI- 
99 (Bohlin et-al.~ 1999). GoDiS is a prototype 
dialogue system for information-seeking dialogue, 
capable of accommodating questions and tasks to 
enable the user to present information in any de- 
sired order, without explicitly naming the dialogue 
task. GoDiS is implemented using the TRINDIKIT 
software package, which enables implementation f 
these behaviours in a compact and natural way. 
1 In t roduct ion  
This paper accompanies a demo of the GoDiS 1 
system reported at IJCAI-99 (Bohlin et al, 
1999). GoDiS is a prototype dialogue system for 
information-seeking dialogue, capable of accommo- 
dating questions and tasks to enable the user to 
present information in any desired order, without 
explicitly naming the dialogue task. GoDiS is im- 
plemented using the TRINDIKIT 2 software package 
developed in the TRINDI project. The TRINDIKIT 
is a toolkit for building and experimenting with dia- 
logue move engines and information states (IS), We 
use the term information state to mean, roughly, 
the information stored internally by an agent, in 
this case a dialogue system. A dialogue move engine 
(DME) updates the information state on the basis 
of observed ialogue moves and selects appropriate 
moves to be performed. 
2 System Descr ip t ion  
The overall structure of the GoDiS system is 
illustrated below: 
1Work on GoDiS has been supported by the TRINDI 
(Task Oriented Instructional Dialogue), EC Project LE4- 
8314, SDS (Swedish Dialogue Systems), NUTEK/HSFR Lan- 
guage Technology Project F1472/1997, and INDI (Infor- 
mation Exchange in Dialogue), Riksbankens Jubileumsfond 
1997-0134, projects. 
2 .x~.n~. ling, gU. se/research/proJ ects/trlndi/ 
Like any dialogue system built using the 
TRINDIKIT, GoDiS consists of a number of mod- 
ules, an information state, and a number of resources 
hooked up to the information state. 
In addition to the control module, which wires 
together the other modules, there are six modules in 
? GoDiS: input, which receives input3from the user; 
interpret, which interprets utterances as dialogue 
moves with some content; generate, which gener- 
ates natural language from dialogue moves; out- 
put, which produces output to the user; update, 
which updates the information state based on in- 
terpreted moves; and select, which selects the next 
move(s) to perform 4. The last two are DME rood- 
ules, which means that they together make up the 
3GoDiS originally accepted written input only, but it is 
currently being hooked up to a speech recogniser toaccept 
spoken input. 
4This is done by updating the part of the information state 
containing the moves to be performed. 
7 
DME in GoDiS. DME modules consist of a set of up- 
date rules and (optionally) an update algorithm gov- 
erning the order in which rules are applied. Update 
rules are rules for updating the information state. 
They consist of a rule name, a precondition list, and 
an effect list. The preconditions are conditions on 
the information state, and the effects are operations 
on the information state. If the preconditions of a 
rule are true for the information state, then the ef- 
fects of that rule can be applied to the information 
state. 
There are three resources in GoDiS: a lexicon, a 
database and a domain resource containing (among 
other things) domain-specific dialogue plans. Cur- 
rently, there are GoDiS resources for a travel agency 
domain andS-the autoroute domain. Also, for each 
of these domains there are lexicons in both English 
and Swedish. 
The question about what should be included in 
the information state is central to any theory of dia- 
logue management. The notion of information state 
we are putting forward here is basically a simplified 
version of the dialogue game board which has been 
proposed by Ginzburg. We are attempting to use as 
simple a version as possible in order to have a more 
or less practical system to experiment with. 
The main division in the information state is be- 
tween information which is private to the agent and 
that which is (assumed to be) shared between the 
dialogue participants. What we mean by shared in- 
formation here is that which has been established 
(i.e. grounded) during the conversation, akin to 
what Lewis in (Lewis, 1979) called the "conversa- 
tional scoreboard". We represent information states 
of a dialogue participant as a record of the type 
shown in figure 1. 
The private part of the information state includes 
a set of beliefs and a dialogue plan, i.e. is a list 
of dialogue actions that the agent wishes to carry 
out. The plan can be changed during the course 
of the conversation. For example, if a travel agent 
discovers that his customer wishes to get information 
about a flight he will adopt a plan to ask her where 
she wants to go, when she wants to go, what price 
class she wants and so on. The agenda, on the other 
hand, contains the short term goals or obligations 
that the agent has, i.e. what the agent is going to do 
next. For example, if the other dialogue participant 
raises a question, then the agent will normally put 
an action on the agenda to respond to the question. 
This action may or may not be in the agent's plan. 
The private part of the IS also includes "tem- 
porary" shared information that saves the previ- 
ously shared information until the latest utterance is
grounded, i.e. confirmed as having been understood 
8 
by the other dialogue participant 5. In this way it 
is easy to retract the "optimistic" assumption that 
the information was understood if it should turn out 
that the other dialogue participant does not under- 
stand or accept it. If the agent pursues a cautious 
rather than an optimistic strategy then information 
will at first only be placed in the "temporary" slot 
until it has been acknowledged by the other dialogue 
participant whereupon it can be moved to the appro- 
priate shared field. 
The (supposedly) shared part of the IS consists 
of three subparts. One is a set of propositions 
which the agent assumes for the sake of the conversa- 
tion and which are established uring the dialogue. 
The second is a stack of questions under discussion 
(QUD). These are questions that have been raised 
and are currently under discussion in the dialogue. 
The third contains information about the latest ut- 
terance (speaker, moves and integration status). 
3 Accommodat ion in GoDiS 
Dialogue participants can address questions that 
have not been explicitly raised in the dialogue. How- 
ever, it is important hat a question be available to 
the agent who is to interpret it because the utter- 
ance may be elliptical. Here is an example from a 
travel agency dialogue6: 
$J: what month do you want to go 
SP: well around 3rd 4th april / some time 
there 
SP: as cheap as possible 
The strategy we adopt for interpreting elliptical 
utterances i to think of them as short answers (in 
the sense of Ginzburg (Ginzburg, 1998)) to questions 
on QUD. A suitable question here is What kind of 
price does P want for the ticket?. This question 
is not under discussion at the point when P says 
"as cheap as possible". But it can be figured out 
since J knows that this is a relevant question. In 
fact it will be a question which J has as an action 
in his plan to raise. On our analysis it is this fact 
which enables A to interpret he ellipsis. He finds 
the matching question on his plan, accommodates 
by placing it on QUD and then continues with the 
integration of the information expressed by as cheap 
as possible as normal. Note that if such a question is 
? not available then the ellipsis cannot be interpreted 
as in the dialogue below. 
A. What  time are you coming to pick up Maria? 
B. Around 6 p.m. As cheap as possible. 
5In discussing rounding we will assume that  there is just 
one other dialogue participant. 
6This dialogue has been collected by the University of 
Lund as part of the SDS project. We quote a translation 
of the transcription done in GSteborg as part of the same 
project. 
IS : 
PRIVATE : 
SHARED : 
PLAN : STACKSET(AcT1ON)  
AGENDA : STACK(ACTION) 
PaL : SET(PRoP) 
I BEL : SET(PRoP) 
QUD : STACK(QUESTION) 
TMP : \[ SPEAKER : 
LU : \[ MOVES : 
BEL : SET(PRoP)  
QUD : STACKSET(QUESTION) 
SPEAKER : PARTICIPANT 
LU : MOVES : 
PARTICIPANT 
ASsoCSET(MOvE,BOoL) 
ASsOCSET(MOvE,BooL) \] \] 
Figure 1: The type of information state we are assuming 
This dialogue is incoherent if what is being dis- 
cussed is when the child Maria is going to be picked 
up from her friend's house (at least under standard 
dialogue plans-that we might have for such a con- 
versation). 
Question accommodation has been implemented 
in GoDiS using a single information state update 
rule accommodateQuest ion,  seen below. When 
interpreting the latest utterance by the other par- 
ticipant, the system makes the assumption that it 
was a reply move with content A. This assump- 
tion requires accommodating some question Q such 
that A is a relevant answer to Q. The check operator 
"answer-to(A, Q)" is true if A is a relevant answer to 
Q given the current information state, according to 
a (domain-dependent) definition of question-answer 
relevance. 
RULE: accommodateQuest ion  
CLASS: accommodate  
val( SHARED.LU.SPEAKER, us r  ) 
in( SHARED.LU.MOVES, answer(A) ) 
not ( lexicon :: yn_answer(A) ) 
PRE: aSSOC( SHARED.LU.MOVES, answer(A), false ) 
in( PRIVATE.PLAN, raise(Q) ) 
domain :: relevant_answer(Q, A)
del( PRIVATE.PLAN, raise(Q) ) 
EFF: push( SHARED.QUD, Q ) 
After an initial exchange for establishing contact 
the first thing that P says to the travel agent in our 
dialogue is "flights to paris". This is again an el- 
lipsis which on our analysis has to be interpreted as 
the answer to a question (two questions, actually) 
in order to be understandable and relevant. As no 
questions have been raised yet in the dialogue (apart 
from whether the participants have each other's at- 
tention) the travel agent cannot find the appropriate 
question on his plan. Furthermore, as this is the first 
indication of what the customer wants, the travel 
agent cannot have a plan with detailed questions. 
We assume that the travel agent has various plan 
types in his domain knowledge determining what 
kind of conversations heis able to have. Each plan 
is associated with a task. E.g. he is able to book 
trips by various modes of travel, he is able to han- 
dle complaints, book hotels, rental cars etc. What 
he needs to do is take the customer's utterance and 
try to match it against questions in his plan types 
in his domain knowledge. When he finds a suitable 
match he will accommodate the corresponding task, 
thereby providing a plan to ask relevant question 
for flights, e.g. when to travel?, what date? etc. 
Once he has accommodated this task and retrieved 
the plan he can proceed as in the previous example. 
That is, he can accommodate the; QUD with the rel- 
evant question and proceed with the interpretation 
of ellipsis in the normal fashion. 
This example is interesting for a couple of reasons. 
It provides us with an example of "recursive" accom- 
modation. The QUD needs to be accommodated, 
but in order to do this the dialogue task needs to be 
accommodated and the plan retrieved. The other 
interesting aspect of this is that accommodating the 
dialogue task in this way actually serves to drive the 
dialogue forward. That is, the mechanism by which 
the agent interprets this ellipsis, gives him a plan for 
a substantial part of the rest of the dialogue. This is 
a way of capturing the intuition that saying flights to 
Paris to a travel agent immediately makes a number 
of questions become relevant. 
Task accommodation a d retrieval of the relevant 
plan has been implemented in GoDiS by two infor- 
mation state update rules. 
4 Sample dialogues 
We will give some examples of CoDiS dialogues in 
the English travel agency domain. One of the fea- 
tures of the TRINDIKIT is that it provides methods 
for inspecting the information state at any stage of 
a dialogue, and also to see which rules are applied. 
Unfortunately, because of space limitations, we are 
not able to include examples of this in this paper; 
however, it is an integral part of our demo. 
The first dialogue shows the typical behaviour of 
dialogue systems for information-seeking: each ques- 
tion is answered in turn, and the user always gives 
exactly the information requested. 
$S> Welcome to the travel agency! 
$U> hello 
9 
$S> What can I do for you? 
$U> I want price information on a trip 
please 
$S> How do you want to travel? 
$U> by plane 
$S> What city do you want to go to? 
SU> gothenburg 
$S> What city do you want to go from? 
SU> london 
$S> Do you want a return ticket? 
$U> yes 
$S> What month do you want to  leave?  
$U> april 
$S> What class did you have in mind? 
$U> as cheap as possible 
$S> It~wil-i cost 50 crowns 
SU> thanks-, bye! 
$S> Thank you for your visit! 
In contrast, the second dialogue (below) shows 
how GoDiS is able to accommodate the task and in- 
tegrate information i  the order that the user gives 
it. 
$S> Welcome to the travel agency! 
$U> flights to paris 
$S> What city do you want to go from? 
$U> gothenburg, in april, as cheap as 
possible 
$S> Do you want a return ticket7 
$U> no 
$S> It will cost 50 crowns 
SU> thanks~ bye! 
$S> Thank you for your visit! 
5 Limitat ions 
GoDiS is a small-scale prototype and as such it suf- 
fers from the familiar drawbacks of many experi- 
mental systems: its lexicons and databases are very 
small, and the domain knowledge is limited. The di- 
alogue plans cover only a small (but important) part 
of the kind of dialogues that can take place in the 
travel agency and autoroute domains. We hope to 
be able to extend both the number of domains and 
the scale of each domain in the future. 
Also, the focus in the development of GoDiS has 
been on the dialogue management, i.e. the dialogue 
move engine and the information state. Less effort 
has been put into the interpretation a d generation 
modules, which currently use (a slightly extended 
version of) keyword spotting and partially canned 
text, respectively. We hope to replace these by plug- 
ging in existing interpretation a d generation tech- 
nology to GoDiS. 
For the tasks that GoDiS currently is able to han- 
dle, full-blown semantics i not needed. We use a 
very limited semantics where propositions are essen- 
tially feature-value pairs. As a consequence, GoDiS 
10 
is e.g. not able to handle dialogue with more than 
one referent; for this, the information state would 
have to be amended with a set of referents, and 
propositions would have to include referent informa- 
tion. This is an area where we hope to improve 
GoDiS in the near future. 
Speech recognition and synthesis i currently be- 
ing added to GoDiS, but at the time of writing only 
written input and output is available. 
6 Contr ibut ions 
Currently, the main contribution of GoDiS is per- 
haps to show how an extended notion of accommo- 
dation can serve to make dialogue systems easier to 
interact with, by letting the user decide how and 
in what order to present information to the system. 
Also, the fact that accommodation can be imple- 
mented simply by adding three update rules indi- 
cates that information state update rules provide a 
natural and compact way of implementing dialogue 
strategies. An important issue for future research 
is the relation of question and task accommodation 
to plan recognition approaches to dialogue (Sidner, 
1985). 
GoDiS also features a simple grounding strategy 
which is nevertheless ufficient in many cases. The 
grounding mechanism is implemented by three up- 
date rules. It is possible to switch resources in mid- 
dialogue, e.g. to change language. Also, GoDiS 
is easily reconfigurable to new information-seeking 
domains. To adapt GoDiS to a new domain, one 
needs to supply a database, a lexicon and domain 
knowledge, including a set of dialogue plans. The 
GoDiS modules or information state don't need to 
be changed in any way. 
In general, as an example of a dialogue system ira- 
plemented using the TRINDIKIT package, GoDiS 
shows how the information state approach is use- 
ful for clarifying and comparing theories of dialogue, 
and for exploring new solutions. 
References 
P. Bohlin, R. Cooper, E. Engdahl, and S. Lars- 
son. 1999. Information states and dialogue move 
engines. In J. Alexandersson, editor, IJCAI-99 
Workshop on Knowledge and Reasoning in Prac- 
tical Dialogue Systems. 
? J. Ginzburg. 1998. Clarifying utterances. In J. Hul- 
stijn and A. Niholt, editors, Proc. of the Twente 
Workshop on the Formal Semantics and Pragmat- 
ics of Dialogues, pages 11-30, Enschede. Univer- 
siteit Twente, Faculteit Informatica. 
D. K. Lewis. 1979. Scorekeeping in a language 
game. Journal of Philosophical Logic, 8:339-359. 
C. L. Sidner. 1985. Plan parsing for intended re- 
sponse recognition in discourse. Computational 
Intelligence, 1 (1) :1-10, February. 
Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 11?17,
Vancouver, October 2005. c?2005 Association for Computational Linguistics
Parsing Linear Context-Free Rewriting Systems
H?kan Burden
Dept. of Linguistics
G?teborg University
cl1hburd@cling.gu.se
Peter Ljungl?f
Dept. of Computing Science
G?teborg University
peb@cs.chalmers.se
Abstract
We describe four different parsing algorithms
for Linear Context-Free Rewriting Systems
(Vijay-Shanker et al, 1987). The algorithms
are described as deduction systems, and possi-
ble optimizations are discussed.
The only parsing algorithms presented for linear context-
free rewriting systems (LCFRS; Vijay-Shanker et al,
1987) and the equivalent formalism multiple context-free
grammar (MCFG; Seki et al, 1991) are extensions of the
CKY algorithm (Younger, 1967), more designed for their
theoretical interest, and not for practical purposes. The
reason for this could be that there are not many imple-
mentations of these grammar formalisms. However, since
a very important subclass of the Grammatical Framework
(Ranta, 2004) is equivalent to LCFRS/MCFG (Ljungl?f,
2004a; Ljungl?f, 2004b), there is a need for practical
parsing algorithms.
In this paper we describe four different parsing algo-
rithms for Linear Context-Free Rewriting Systems. The
algorithms are described as deduction systems, and pos-
sible optimizations are discussed.
1 Introductory definitions
A record is a structure ? = {r1 = a1; . . . ; rn = an},
where all ri are distinct. That this can be seen as a set
of feature-value pairs. This means that we can define a
simple version of record unification ?1 unionsq ?2 as the union
?1??2, provided that there is no r such that ?1.r 6= ?2.r.
We sometimes denote a sequence X1, . . . , Xn by the
more compact ~X . To update the ith record in a list of
records, we write ~?[i := ?]. To substitute a variable
Bk for a record ?k in any data structure ?, we write
?[Bk/?k].
1.1 Decorated Context-Free Grammars
The context-free approximation described in section 4
uses a form of CFG with decorated rules of the form
f : A ? ?, where f is the name of the rule, and ? is a
sequence of terminals and categories subscripted with in-
formation needed for post-processing of the context-free
parse result. In all other respects a decorated CFG can be
seen as a straight-forward CFG.
1.2 Linear Context-Free Rewriting Systems
A linear context-free rewriting system (LCFRS; Vijay-
Shanker et al, 1987) is a linear, non-erasing multiple
context-free grammar (MCFG; Seki et al, 1991). An
MCFG rule is written1
A ? f [B1 . . . B?] := { r1 = ?1; . . . ; rn = ?n }
where A and Bi are categories, f is the name of the rule,
ri are record labels and ?i are sequences of terminals and
argument projections of the form Bi.r. The language
L(A) of a category A is a set of string records, and is
defined recursively as
L(A) = { ?[B1/?1, . . . , B?/??] |
A ? f [B1 . . . B?] := ?,
?1 ? L(B1), . . . , ?? ? L(B?) }
It is the possibility of discontinuous constituents that
makes LCFRS/MCFG more expressive than context-free
grammars. If the grammar only consists of single-label
records, it generates a context-free language.
Example A small example grammar is shown in figure 1,
and generates the language
L(S) = { s shm | s ? (a ? b)
? }
where shm is the homomorphic mapping such that
each a in s is translated to c, and each b is translated
to d. Examples of generated strings are ac, abcd and
bbaddc. However, neither abc nor abcdabcd will be
1We borrow the idea of equating argument categories and
variables from Nakanishi et al (1997) , but instead of tuples we
use the equivalent notion of records for the linearizations.
11
Figure 1: An example grammar describing the language
{ s shm | s ? (a ? b)? }
S ? f [A] := { s = A.p A.q }
A ? g[A1 A2] := { p = A1.p A2.p; q = A1.q A2.q }
A ? ac[ ] := { p = a; q = c }
A ? bd[ ] := { p = b; q = d }
generated. The language is not context-free since
it contains a combination of multiple and crossed
agreement with duplication.
If there is at most one occurrence of each possible pro-
jection Ai.r in a linearization record, the MCFG rule is
linear. If all rules are linear the grammar is linear. A rule
is erasing if there are argument projections that have no
realization in the linearization. A grammar is erasing if
it contains an erasing rule. It is possible to transform an
erasing grammar to non-erasing form (Seki et al, 1991).
Example The example grammar is both linear and non-
erasing. However, given that grammar, the rule
E ? e[A] := { r1 = A.p; r2 = A.p }
is both non-linear (since A.p occurs more than once)
and erasing (since it does not mention A.q).
1.3 Ranges
Given an input string w, a range ? is a pair of indices,
(i, j) where 0 ? i ? j ? |w| (Boullier, 2000). The en-
tire string w = w1 . . . wn spans the range (0, n). The
word wi spans the range (i ? 1, i) and the substring
wi+1, . . . , wj spans the range (i, j). A range with identi-
cal indices, (i, i), is called an empty range and spans the
empty string.
A record containing label-range pairs,
? = { r1 = ?1, . . . , rn = ?n }
is called a range record. Given a range ? = (i, j), the
ceiling of ? returns an empty range for the right index,
d?e = (j, j); and the floor of ? does the same for the
left index b?c = (i, i). Concatenation of two ranges is
non-deterministic,
(i, j) ? (j?, k) = { (i, k) | j = j? }
.
1.3.1 Range restriction
In order to retrieve the ranges of any substring s in a
sentence w = w1 . . . wn we define range restriction of s
with respect to w as ?s?w = { (i, j) | s = wi+1 . . . wj },
i.e. the set of all occurrences of s in w. If w is understood
from the context we simply write ?s?.
Range restriction of a linearization record ? is written
???, which is a set of records, where every terminal token
s is replaced by a range from ?s?. The range restriction of
two terminals next to each other fails if range concatena-
tion fails for the resulting ranges. Any unbound variables
in ? are unaffected by range restriction.
Example Given the string w = abba, range restricting
the terminal a yields
?a?w = { (0, 1), (3, 4) }
Furthermore,
?aA.r a bB.q?w =
{ (0, 1)A.r (0, 2)B.q, (3, 4)A.r (0, 2)B.q }
The other possible solutions fail since they cannot
be range concatenated.
2 Parsing as deduction
The idea with parsing as deduction (Shieber et al, 1995)
is to deduce parse items by inference rules. A parse item
is a representation of a piece of information that the pars-
ing algorithm has acquired. An inference rule is written
?1 . . . ?n
C
?
where ? is the consequence of the antecedents ?1 . . . ?n,
given that the side conditions in C hold.
2.1 Parsing decorated CFG
Decorated CFG can be parsed in a similar way as stan-
dard CFG. For our purposes it suffices to say that the al-
gorithm returns items of the form,
[f : A/? ? B1/?1 . . . Bn/?n ? ]
saying that A spans the range ?, and each daughter Bi
spans ?i.
The standard inference rule combine might look like
this for decorated CFG:
Combine
[f : A/? ? ? ? Bx ?]
[g : B/?? ? . . . ? ]
??? ? ? ? ??
[f : A/? ? ? Bx/??? ? ?]
Note that the subscript x in Bx is the decoration that will
only be used in post-processing.
12
3 The Na?ve algorithm
Seki et al (1991) give an algorithm for MCFG, which can
be seen as an extension of the CKY algorithm (Younger,
1967). The problem with that algorithm is that it has to
find items for all daughters at the same time. We modify
this basic algorithm to be able to find one daughter at the
time.
There are two kinds of items. A passive item [A; ?]
has the meaning that the category A has been found span-
ning the range record ?. An active item for the rule
A ? f [ ~B ~B?] := ? has the form
[A ? f [ ~B ? ~B?]; ?; ~?]
in which the categories to the left of the dot, ~B, have been
found with the linearizations in the list of range records
~?. ? is the result of substituting the projections in ? with
ranges for the categories found in ~B.
3.1 Inference rules
There are three inference rules, Predict, Combine and
Convert.
Predict
A ? f [ ~B] := ?
? ? ???
[A ? f [ ? ~B]; ?; ]
Prediction gives an item for every rule in the gram-
mar, where the range restriction ? is what has been
found from the beginning. The list of daughters is
empty since none of the daughters in ~B have been
found yet.
Combine
[A ? f [ ~B ? Bk ~B?]; ?; ~?]
[Bk; ?k]
?? ? ?[Bk/?k]
[A ? f [ ~B Bk ? ~B?]; ??; ~?, ?k]
An active item looking for Bk and a passive item
that has found Bk can be combined into a new active
item. In the new item we substitute Bk for ?k in
the linearization record. We also add ?k to the new
item?s list of daughters.
Convert
[A ? f [ ~B ? ]; ?; ~?]
? ? ?
[A; ?]
Every fully instantiated active item is converted into
a passive item. Since the linearization record ?
is fully instantiated, it is equivalent to the range
record ?.
Figure 2: The example grammar converted to a decorated
CFG
f : (S.s) ? (A.p) (A.q)
g : (A.p) ? (A.p)1 (A.p)2
g : (A.q) ? (A.q)1 (A.q)2
ac : (A.p) ? a
ac : (A.q) ? b
bd : (A.p) ? c
bd : (A.q) ? d
The subscripted numbers are for distinguishing the two
categories from each other, since they are equivalent.
Here A.q is a context-free category of its own, not a
record projection.
4 The Approximative algorithm
Parsing is performed in two steps in the approximative
algorithm. First we parse the sentence using a context-
free approximation. Then the resulting context-free chart
is recovered to a LCFRS chart.
The LCFRS is converted by creating a decorated
context-free rule for every row in a linearization record.
Thus, the rule
A ? f [ ~B] := { r1 = ?1; . . . ; rn = ?n }
will give n context-free rules f : A.ri ? ?i. The ex-
ample grammar from figure 1 is converted to a decorated
CFG in figure 2.
Parsing is now initiated by a context-free parsing algo-
rithm returning decorated items as in section 2.1. Since
the categories of the decorated grammar are projections
of LCFRS categories, the final items will be of the form
[f : (A.r)/? ? . . . (B.r?)x/?
? . . . ? ]
Since the decorated CFG is over-generating, the re-
turned parse chart is unsound. We therefore need to re-
trieve the items from the decorated CFG parse chart and
check them against the LCFRS to get the discontinuous
constituents and mark them for validity.
The initial parse items are of the form,
[A ? f [ ~B]; r = ?; ~?]
where ~? is extracted from a corresponding decorated item
[f : (A.r)/? ? ?], by partitioning the daughters in ?
such that ?i = { r = ? | (B.r)i/? ? ? }. In other words,
?i will consist of all r = ? such that B.r is subscripted
by i in the decorated item.
Example Given ? = (A.p)2/?? (B.q)1/??? (A.q)2/????,
we get the two range records ?1 = {q = ???} and
?2 = {p = ??; q = ????}.
13
Apart from the initial items, we use three kinds of parse
items. From the initial parse items we first build LCFRS
items, of the form
[A ? f [ ~B]; ? ? ri . . . rn; ~?]
where ri . . . rn is a list of labels, ~? is a list of | ~B| range
records, and ? is a range record for the labels r1 . . . ri?1.
In order to recover the chart we use mark items
[A ? f [ ~B ? ~B?]; ?; ~? ? ~??]
The idea is that ~? has been verified as range records span-
ning the daughters ~B. When all daughters have been ver-
ified, a mark item is converted to a passive item [A; ?].
4.1 Inference rules
There are five inference rules, Pre-Predict, Pre-Combine,
Mark-Predict, Mark-Combine and Convert.
Pre-Predict
A ? f [ ~B] := {r1 = ?1; . . . ; rn = ?n}
~?? = { }, . . . , { }
[A ? f [ ~B]; ? r1 . . . rn; ~??]
Every rule A ? f [ ~B] is predicted as an LCFRS
item. Since the context-free items contain informa-
tion about ?1 . . . ?n, we only need to use the labels
r1, . . . , rn. ~?? is a list of | ~B| empty range records.
Pre-Combine
[R; ? ? r ri . . . rn; ~?]
[R; r = ?; ~??]
~??? ? ~? unionsq ~??
[R; {?; r = ?} ? ri . . . rn; ~???]
If there is an initial parse item for the rule R with la-
bel r, we can combine it with an LCFRS item look-
ing for r, provided the daughters? range records can
be unified.
Mark-Predict
[A ? [ ~B]; ? ? ; ~?]
[A ? [ ? ~B]; ?; ? ~?]
When all record labels have been found, we can start
to check if the items have been derived in a valid way
by marking the daughters? range records for correct-
ness.
Mark-Combine
[A ? f [ ~B ? Bi ~B?]; ?; ~? ? ?i ~??]
[Bi; ?i]
[A ? f [ ~B Bi ? ~B?]; ?; ~??i ? ~??]
Record ?i is correct if there is a correct passive item
for category Bi that has found ?i.
Convert
[A ? f [ ~B ? ]; ?; ~? ? ]
[A; ?]
An item that has marked all daughters as correct is
converted to a passive item.
5 The Active algorithm
The active algorithm parses without using any context-
free approximation. Compared to the Na?ve algorithm
the dot is used to traverse the linearization record of a
rule instead of the categories in the right-hand side.
For this algorithm we use a special kind of range,
??, which denotes simultaneously all empty ranges (i, i).
Range restricting the empty string gives ??? = ??. Con-
catenation is defined as ???? = ???? = ?. Both the ceiling
and the floor of ?? are identities, d??e = b??c = ??.
There are two kinds of items. Passive items [A; ?] say
that we have found category A inside the range record ?.
An active item for the rule
A ? f [ ~B] := {?; r = ??; ?}
is of the form
[A ? f [ ~B]; ?, r = ? ? ?, ?; ~?]
where ? is a range record corresponding to the lineariza-
tion rows in ? and ? has been recognized spanning ?.
We are still looking for the rest of the row, ?, and the re-
maining linearization rows ?. ~? is a list of range records
containing information about the daughters ~B.
5.1 Inference rules
There are five inference rules, Predict, Complete, Scan,
Combine and Convert.
Predict
A ? f [ ~B] := {r = ?; ?}
~?? = { }, . . . , { }
[A ? f [ ~B]; {}, r = ?? ? ?, ?; ~??]
For every rule in the grammar, predict a correspond-
ing item that has found the empty range. ~?? is a list
of | ~B| empty range records since nothing has been
found yet.
Complete
[R; ?, r = ? ? ?, {r? = ?; ?}; ~?]
[R; {?; r = ?}, r? = ?? ? ?,?; ~?]
When an item has found an entire linearization row
we continue with the next row by starting it off with
the empty range.
14
Scan
[R; ?, r = ? ? s?, ?; ~?]
?? ? ? ? ?s?
[R; ?, r = ?? ? ?, ?; ~?]
When the next symbol to read is a terminal, its range
restriction is concatenated with the range for what
the row has found so far.
Combine
[A ? f [ ~B]; ?, r = ? ? Bi.r? ?, ?; ~?]
[Bi; ??]
?? ? ? ? ??.r?
?i ? ??
[A ? f [ ~B]; ?, r = ?? ? ?, ?; ~?[i := ??]]
If the next thing to find is a projection on Bi, and
there is a passive item where Bi is the category,
where ?? is consistent with ?i, we can move the dot
past the projection. ?i is updated with ??, since it
might contain more information about the ith daugh-
ter.
Convert
[A ? f [ ~B]; ?, r = ? ? ?, {}; ~?]
[A; {?; r = ?}]
An active item that has fully recognized all its lin-
earization rows is converted to a passive item.
6 The Incremental algorithm
An incremental algorithm reads one token at the time and
calculates all possible consequences of the token before
the next token is read2. The Active algorithm as described
above is not incremental, since we do not know in which
order the linearization rows of a rule are recognized. To
be able to parse incrementally, we have to treat the lin-
earization records as sets of feature-value pairs, instead
of a sequence.
The items for a rule A ? f [ ~B] := ? have the same
form as in the Active algorithm:
[A ? f [ ~B]; ?, r = ? ? ?, ?; ~?]
However, the order between the linearization rows does
not have to be the same as in ?. Note that in this algo-
rithm we do not use passive items. Also note that since
we always know where in the input we are, we cannot
make use of a distinguished ?-range. Another conse-
quence of knowing the current input position is that there
are fewer possible matches for the Combine rule.
2See e.g. the ACL 2004 workshop ?Incremental Parsing:
Bringing Engineering and Cognition Together?.
6.1 Inference rules
There are four inference rules, Predict, Complete, Scan
and Combine.
Predict
A ? f [ ~B] := {?; r = ?; ?}
0 ? k ? |w|
[A ? f [ ~B]; {}, r = (k, k) ? ?, {?;?}; ~??]
An item is predicted for every linearization row r
and every input position k. ~?? is a list of | ~B| empty
range records.
Complete
[R; ?, r = ? ? ?, {?; r? = ?; ?}; ~?]
d?e ? k ? |w|
[R; {?; r = ?}, r? = (k, k) ? ?, {?;?}; ~?]
Whenever a linearization row r is fully traversed, we
predict an item for every remaining linearization row
r? and every remaining input position k.
Scan
[R; ?, r = ? ? s?, ?; ~?]
?? ? ? ? ?s?
[R; ?, r = ?? ? ?, ?; ~?]
If the next symbol in the linearization row is a termi-
nal, its range restriction is concatenated to the range
for the partially recognized row.
Combine
[R; ?, r = ? ? Bi.r? ?, ?; ~?]
[Bi ? . . . ; ??, r? = ?? ? ?, . . . ; . . .]
??? ? ? ? ??
?i ? {??; r? = ??}
[R; ?, r = ??? ? ?, ?; ~?[i := {??; r? = ??}]]
If the next item is a record projection Bi.r?, and
there is an item for Bi which has found r?, then
move the dot forward. The information in ?i must
be consistent with the information found for the Bi
item, {??; r? = ??}.
7 Discussion
We have presented four different parsing algorithms for
LCFRS/MCFG. The algorithms are described as deduc-
tion systems, and in this final section we discuss some
possible optimizations, and complexity issues.
15
7.1 Different prediction strategies
The Predict rule in the above described algorithms is very
crude, predicting an item for each rule in the grammar
(for the Incremental algorithm even for each input po-
sition). A similar context-free prediction rule is called
bottom-up Earley by Sikkel and Nijholt (1997). Such
crude predictions are only intended for educational pur-
poses, since they lead to lots of uninteresting items, and
waste of computing power. For practical purposes there
are two standard context-free prediction strategies, top-
down and bottom-up (see e.g. Wir?n (1992)) and they can
be adapted to the algorithms presented in this paper.
The main idea is that an item for the rule A ? f [ ~B]
with the linearization row r = ? is only predicted if. . .
(Top-down prediction) . . . there is another item looking
for A.r.
(Bottom-up prediction) . . . there is an passive item that
has found the first symbol in ?.
For a more detailed description of these prediction strate-
gies, see Ljungl?f (2004a).
7.2 Efficiency and complexity of the algorithms
The theoretical time complexity for these algorithms is
not better than what has been presented earlier.3 The
complexity arguments are similar and the reader is re-
ferred to Seki et al (1991).
However, theoretical time complexity does not say
much about practical performance, as is already clear
from context-free parsing, where the theoretical time
complexity has remained the same ever since the first
publications (Kasami, 1965; Younger, 1967). There are
two main ways of improving the efficiency of existing
algorithms, which can be called refinement and filtering
(Sikkel and Nijholt, 1997). First, one wants to be able
to locate existing parse items efficiently, e.g. by indexing
some properties in a hash table. This is often done by
refining the parse items or inference rules, increasing the
number of items or deduction steps. Second, it is desir-
able to reduce the number of parse items, which can be
done by filtering out redundant parts of an algorithm.
The algorithms presented in this paper can all be seen
as refinements and filterings of the basic algorithm of
Seki et al (1991):
The na?ve algorithm is a refinement of the basic algo-
rithm, since single items and deduction steps are de-
composed into several different items and smaller
deduction steps.
3Nakanishi et al (1997) reduce the parsing problem to
boolean matrix multiplication, but this can be considered a
purely theoretical result.
The approximative algorithm is both a refinement and
a filtering of the na?ve algorithm; a refinement since
the inference rules Pre-Predict and Pre-Combine are
added, and a filtering since there will hopefully be
less items for Mark-Predict and Mark-Combine to
take care of.
The active algorithm is a refinement of the na?ve algo-
rithm, since the Combine rule is divided into the
rules Complete, Scan and Combine.
The incremental algorithm is finally a refinement of
the active algorithm, since Predict and Complete
can select from any possible remaining linearization
row, and not just the following.
Furthermore, the different prediction strategies (top-
down and bottom-up), become filterings of the algo-
rithms, since they reduce the number of parse items.
7.3 Implementing and testing the algorithms
The algorithms presented in this paper have been im-
plemented in the programming language Haskell, for in-
clusion in the Grammatical Framework system (Ranta,
2004). These implementations are described by Bur-
den (2005). We have also started to implement a selection
of the algorithms in the programming language Prolog.
Preliminary results suggest that the Active algorithm
with bottom-up prediction is a good candidate for parsing
grammars written in the Grammatical Framework. For
a normal sentence in the English resource grammar the
speedup is about 20 times when compared to context-free
parsing and filtering of the parse trees. In the future we
plan to test the different algorithms more extensively.
Acknowledgments
The authors are supported by the EU project TALK (Talk
and Look, Tools for Ambient Linguistic Knowledge),
IST-507802.
References
Pierre Boullier. 2000. Range concatenation grammars.
In 6th International Workshop on Parsing Technolo-
gies, pages 53?64, Trento, Italy.
H?kan Burden. 2005. Implementations of parsing al-
gorithms for linear multiple context-free grammars.
Master?s thesis, G?teborg University, Gothenburg,
Sweden.
Tadao Kasami. 1965. An efficient recognition and syntax
algorithm for context-free languages. Technical Re-
port AFCLR-65-758, Air Force Cambridge Research
Laboratory, Bedford, MA.
16
Peter Ljungl?f. 2004a. Expressivity and Complexity
of the Grammatical Framework. Ph.D. thesis, G?te-
borg University and Chalmers University of Technol-
ogy, Gothenburg, Sweden.
Peter Ljungl?f. 2004b. Grammatical Framework and
multiple context-free grammars. In 9th Conference on
Formal Grammar, Nancy, France.
Ryuichi Nakanishi, Keita Takada, and Hiroyuki Seki.
1997. An efficient recognition algorithm for multi-
ple context-free languages. In MOL5: 5th Meeting on
the Mathematics of Language, pages 119?123, Saar-
br?cken, Germany.
Aarne Ranta. 2004. Grammatical Framework, a type-
theoretical grammar formalism. Journal of Functional
Programming, 14(2):145?189.
Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free gram-
mars. Theoretical Computer Science, 88:191?229.
Stuart Shieber, Yves Schabes, and Fernando Pereira.
1995. Principles and implementation of deductive
parsing. Journal of Logic Programming, 24(1?2):3?
36.
Klaas Sikkel and Anton Nijholt. 1997. Parsing of
context-free languages. In G. Rozenberg and A. Sa-
lomaa, editors, The Handbook of Formal Languages,
volume II, pages 61?100. Springer-Verlag, Berlin.
K. Vijay-Shanker, David Weir, and Aravind Joshi. 1987.
Characterizing structural descriptions produced by var-
ious grammatical formalisms. In 25th Meeting of the
Association for Computational Linguistics.
Mats Wir?n. 1992. Studies in Incremental Natural-
Language Analysis. Ph.D. thesis, Link?ping Univer-
sity, Link?ping, Sweden.
Daniel H Younger. 1967. Recognition of context-
free languages in time n3. Information and Control,
10(2):189?208.
17
Proceedings of SPEECHGRAM 2007, pages 9?16,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Converting Grammatical Framework to Regulus
Peter Ljungl?f
Department of Linguistics
G?teborg University
Gothenburg, Sweden
peb@ling.gu.se
Abstract
We present an algorithm for converting
Grammatical Framework grammars (Ranta,
2004) into the Regulus unification-based
framework (Rayner et al, 2006). The main
purpose is to take advantage of the Regulus-
to-Nuance compiler for generating opti-
mized speech recognition grammars. But
there is also a theoretical interest in knowing
how similar the two grammar formalisms
are.
Since Grammatical Framework is more ex-
pressive than Regulus, the resulting Regu-
lus grammars can be overgenerating. We
therefore describe a subclass of Grammati-
cal Framework for which the algorithm re-
sults in an equivalent Regulus grammar.
1 Background
In this section we describe the grammar formalism
Grammatical Framework (GF), and discuss its ex-
pressive power and the present options for creat-
ing speech recognition grammars (SRGs). The main
problem is that the size of the grammar can explode
when inflectional parameters are expanded. In this
paper we try to solve this problem by converting to
a formalism for which there is an optimized SRG
compiler. This formalism is Regulus, which is de-
scribed together with its SRG compiler.
The formal details are left out of the descriptions
in this section and can instead be found in section 2.
In section 3 the conversion algorithm is presented in
detail, and in section 4 there is a short discussion.
1.1 Grammatical Framework
Grammatical Framework (Ranta, 2004) is a gram-
mar formalism based on type theory. The main fea-
ture is the separation of abstract and concrete syn-
tax, which makes it very suitable for writing mul-
tilingual grammars. A rich module system also fa-
cilitates grammar writing as an engineering task, by
reusing common grammars.
1.1.1 Separating abstract and concrete syntax
The main idea of GF is the separation of ab-
stract and concrete syntax, a distinction which is
shared with several other grammar formalisms such
as Abstract Categorial Grammars (de Groote, 2001),
Lambda Grammar (Muskens, 2003) and Higher Or-
der Grammar (Pollard, 2004). The abstract part of
a grammar defines a set of abstract syntactic struc-
tures, called abstract terms or trees; and the concrete
part defines a relation between abstract structures
and concrete structures.
GF has a linearization perspective to grammar
writing, where the relation between abstract and
concrete is viewed as a mapping from abstract to
concrete structures, called linearization terms. In
some cases the mapping can be partial or even many-
valued.
Although not exploited in many well-known
grammar formalisms, a clear separation between ab-
stract and concrete syntax gives some advantages.
High-level language descriptions: When describ-
ing the abstract syntax, the grammar writer can
choose not to care about language specific de-
tails, such as inflection and word order.
Multilingual grammars: It is possible to define
different concrete syntaxes for one particular
9
abstract syntax. Multilingual grammars can be
used as a model for interlingua translation, but
also to simplify localization of language tech-
nology applications.
Resource grammars: The abstract syntax of one
grammar can be used as a concrete syntax of
another grammar. This makes it possible to im-
plement grammar resources to be used in sev-
eral different application domains.
These points are currently exploited in the GF Re-
source Grammar Library (Ranta et al, 2006), which
is a multilingual GF grammar with a common ab-
stract syntax for 13 languages. The grammati-
cal coverage is similar to the Core Language En-
gine (Rayner et al, 2000). The main purpose of
the Grammar Library is as a resource for writing
domain-specific grammars.
1.1.2 Abstract syntax
The abstract theory of GF is a version of Martin-
L?f?s (1984) dependent type theory. A grammar
consists of declarations of categories and functions.
Categories can depend on other categories. Func-
tion declarations can bind variables to be used in de-
pendent types, and also take functions as arguments,
thus giving rise to higher-order functions. Since the
abstract syntax also permits function definitions, the
expressive power of GF abstract syntax is Turing-
complete.
In this article we restrict ourselves to an impor-
tant subclass of GF, where there are no dependent
types and no higher-order functions. This subclass
is called context-free GF, and is an instance of Gen-
eralized Context-Free Grammar (Pollard, 1984).
The abstract syntax of a context-free GF grammar
consists of a set of function typings of the form
f : A1 ? ? ? ? ? A? ? A
This typing says that f is a function taking ? argu-
ments with categories A1 . . . A? and returning a cat-
egory A. This is equivalent to a context-free gram-
mar without terminal symbols. Note however, that
the function f would be written A ? A1 . . . A? as
an ordinary context-free rule. I.e., the left-hand side
of a context-free rule corresponds to the result of the
function, which is written to the right. The restric-
tion to a context-free backbone is not severe, since
the concrete syntax is so expressive.
1.1.3 Concrete syntax
Linearizations are written as terms in a typed
functional programming language, which is limited
to ensure decidability in generation and in parsing.
The language has records and finite-domain func-
tions (called tables); and the basic types are termi-
nal lists (called strings) and finite data types (called
parameter types). There are also local definitions,
lambda-abstractions and global function definitions.
The parameters are declared by the grammar; they
can be hierarchical but not recursive, to ensure finite-
ness.
The language of linearization terms is quite com-
plex, but it can be compiled to a normalized form
which is called canonical GF. In this paper we as-
sume that all linearizations are in canonical form.
A canonical concrete GF grammar contains declara-
tions of all parameter types, and linearization defini-
tions for all abstract functions.
1.1.4 Expressive power
The expressive power of context-free GF solely
depends on the possibility of discontinuous con-
stituents. This means that one grammatical phrase
can be split into several parts occurring in different
places in the sentence. Discontinuous constituents
permit a simple and compositional way of treating,
e.g., German compound verbs, where the particle
commonly is moved to the end of the sentence.
Ljungl?f (2004) showed that context-free GF is
equivalent to Multiple Context-Free Grammar (Seki
et al, 1991), which is known to be parseable in time
polynomial in the length of the input string. From a
converted Multiple CFG, each constituent can be ex-
tracted as a context-free rule, which will result in a
possibly overgenerating context-free grammar. This
context-free grammar can be output from the GF
system in several different speech recognition for-
mats, as described by Bringert (2007).
There is a severe problem with the conversion
from GF to Multiple CFG however ? the size of
the resulting grammar tend to explode when the in-
flectional parameters are expanded. Large gram-
mars such as many of the languages in the Resource
10
Grammar Library simply cannot be converted. One
solution would be to optimize the conversion algo-
rithm, e.g., by interleaving parameter expansion and
grammar compaction. Another solution would be
to translate into a grammar formalism which does
not have this size explosion. This is where Regulus
comes in ? if we could translate GF grammars into
Regulus grammars, we could make use of the re-
search already put into the Regulus-to-Nuance com-
piler, and would not have to reinvent the wheel.
1.2 Regulus
Regulus is an open-source toolkit for writing
grammar-based speech recognition systems (Rayner
et al, 2006).1 The central part is the Regulus gram-
mar formalism and a compiler for creating speech
recognition grammars. The toolkit has been en-
hanced with templates for developing e.g., speech
translation systems and dialogue systems. There is
also an English resource grammar, which can be
used for grammar specialization using explanation-
based learning (Rayner et al, 2006, chapters 9?10).
1.2.1 Unification of finite parameters
The Regulus formalism is a context-free gram-
mar, enhanced with unification of finite parameters.
This means that the formalism is equivalent to a
context-free grammar.
Each context-free category (e.g., Noun) has a
number of features (e.g., Number and Gender)
with a finite domain of values (e.g., Sg/Pl and
Masc/Fem/Neutr). The feature values are specified
using a record paired with the grammatical category.
Logical variables can be used for unifying features
of different constituents in the rule. It is possible to
define macros for simplifying common tasks, e.g.,
when implementing a lexicon.
Compared to Grammatical Framework, the Regu-
lus formalism is quite restricted. There is no clear
distinction between abstract and concrete syntax,
and there is no advanced module system in which to
define grammatical resources. Also, Regulus lacks
discontinuous constituents, which reduces the ex-
pressive power considerably.
1More information about Regulus, including download in-
formation, can be found on the project homepage: http:
//www.issco.unige.ch/projects/regulus/
1.2.2 Compiling Regulus to Nuance GSL
Nuance Communications (2003) has developed
a context-free grammar format for speech recogni-
tion, which has become one of the de facto stan-
dards for speech recognition. The grammar format
is called Nuance Grammar Specification Language
(GSL). The format has some special features, such
as semantic tagging and probabilistic grammar rules.
There are also restrictions in the format, most no-
tably that the grammars must not be left-recursive.
The Regulus formalism is designed to be able to
make use of the special features in Nuance GSL, and
the compiler can always create correct GSL gram-
mars without left-recursion.
2 Formal definitions
In this section we give formal definitions of rules and
linearization terms in GF, grammar rules and terms
in Regulus, and the intermediate structures we will
be using.
2.1 GF grammar rules
Since we are only interested in GF grammars with
a context-free backbone, the abstract syntax is a
context-free grammar where each rule has a unique
name. The rules are written as typings in a func-
tional language:
f : A1 ? ? ? ? ? A? ? A
Asmentioned earlier, this declaration corresponds to
the context-free rule A ? A1 . . . A?.
Linearizations are written as function definitions,
f x1 . . . x? = t, where x1 . . . x? are variables that
occur in the linearization term t. An alternative way
of writing this is to name the variables consistently
for each rule, and then the linearization term t it-
self is sufficient as a linearization definition. We
adopt this idea and use the uniform variable names
$1 . . . $? in each linearization. With this approach
we also distinguish the argument variables from the
parameter variables which get bound in tables.
2.2 GF linearization terms and substructures
A parameter type P is just a set of parameter values
{p1, . . . , pn}. Note that all parameter types must
be disjoint, i.e., each parameter should belong to
11
exactly one parameter type. Linearizations are de-
fined by association linearization terms to the ab-
stract functions. Note that the definition of terms is
slightly more general than the definition in GF, since
we want to include reduced terms in the definition.
The relation between the introduced classes are as
follows:
P ? VPar
VStr
}
? V ? T
Terms (t ? T) are defined inductively as follows:
t ::= $n argument
| ?s? string
| t ++ t? concatenation
| p pattern
| {r1 = t1; . . . ; rn = tn} record
| t.r projection
| [p1 ? t1; . . . ; pn ? tn] table
| t1!t2 selection
where n > 0 is a positive integer, p ? P is a pattern,
and r ? R is a record label. The class R of record
labels is just a finite class of atomic values. The ar-
gument reference $n denotes the nth argument of
the linearization function.
Patterns (p ? P) are pairs x@pi of variables, x,
and sets of parameters, pi = {p1 . . . pn}. The pa-
rameters p1 . . . pn all must belong to the same pa-
rameter type P, i.e., pi ? P. The meaning of the
pattern is that x is bound to one of the parameters in
pi. If pi = P we can skip that part and simply write
x. Conversely, if x is not used elsewhere in the term,
we can skip it and simply write pi.
Note that a pattern is a term in itself, but in GF
it will always occur as a single variable x or as a
single parameter p. However, after the conversion
algorithm has transformed tables into records, pat-
terns will become first class terms.
Reduced terms (v ? V) are subterms of ordinary
terms. A reduced term is a term which does not
contain a table or a selection, and where projections
only occur in the form $n.?, where ? ? R? is a se-
quence of labels:
v ::= $n.?
| ?s?
| v ++ v?
| p
| {r1 = v1; . . . ; rn = vn}
Reduced parameter terms (vp ? VPar) are sub-
terms of reduced terms, which correspond to param-
eters:
vp ::= $n.? | p
Reduced string terms (vs ? VStr) are subterms
of reduced terms, which correspond to strings:
vs ::= $n.? | ?s? | vs ++ v
?
s
Note that this is equivalent to a sequence of argu-
ment projections and string constants, which in turn
is equivalent to a right-hand side in a context-free
rule.
2.3 Regulus grammar rules and terms
A Regulus grammar is a unification-based phrase-
structure grammar. It consists of grammar rules,
which in turn is built up using Regulus terms.
Regulus rules are regular context-free grammar
rules, where each category is augmented with a Reg-
ulus term:
A:v ? ?0 A1:v1 ?1 . . . A?:v? ??
where each Ai is a context-free category, each vi is
a Regulus term, and each ?i is a (possibly empty)
sequence of terminal tokens.
Regulus terms are flat records where all values
are patterns (pi = xi@pii):2
vr ::= {r1 = p1; . . . ; rn = pn}
In this sense, Regulus terms are just subterms of re-
duced terms. However, a Regulus term can include
one of the two special labels sem and gsem, cor-
responding to return values and global slot-filling
in Nuance GSL, respectively. They can contain
complex structures, such as deeply nested lists and
records. Using these it is possible to define the syn-
tactical structure of a phrase.
2This is a slight abuse of syntax ? in Regulus the record row
ri = xi@pii is written as two separate rows ri = xi; ri = pii.
12
3 Converting GF to Regulus
In this section we describe an algorithm for convert-
ing any context-free GF rule into a set of Regulus
rules. This conversion is done in three steps:
1. Tables and table selections are removed from
the GF term, resulting in several reduced terms
and sets of constraints.
2. The results are massaged into Regulus terms
for the left-hand side and the right-hand side.
3. Finally, GF abstract syntax is used to create the
final Regulus rules.
In the final step, the abstract syntax is added as a se-
mantic value in the Regulus rules. This makes it pos-
sible to get back the GF abstract syntax tree, when
using Regulus (or Nuance) for parsing the grammar.
Example As a running example we will use a stan-
dard English GF rule for combining transitive verbs
with noun phrases:
vp : TV ? NP ? VP
= {s = [n ? $1.s!n ++ $2.s]}
The idea is that a verb phrase has a parametrical
number (n), which it inherits from the verb. When
the verb phrase is used in a sentence, the number
will depend on the inherent number of the subject.
3.1 Converting tables to unification-based
records
The main difference between GF and Regulus is that
the former has tables and the latter has unification.
The problem when converting from GF to Regulus
is therefore how to get rid of the tables and selec-
tions. We present an algorithm for removing tables
and selections, by replacing them with logical vari-
ables and equality constraints.
The basic idea is to translate each row pi ? ti
in a table into a record {p = pi;v = ti}. The
variables in ti which are bound by pi become log-
ical variables. Thus the original table gives rise to n
different records (if n is the number of table rows),
which in the end becomes n different Regulus terms.
A table selection t!t? then has to be translated into
the value t.v of the table, and a constraint is added
that the selection term t? and the pattern t.p of the
table should be unified.
Step 1: Removing tables and selections
We define a nondeterministic reduction operation
=? . The meaning of t =? v/? is that the term t ?
T is converted to the reduced term v ? V together
with the set of constraints ? ? VPar ? VPar. Each
constraint in ? is of the form vp
.
= v?p, where vp and
v?p are reduced parameter terms.
? Each row pi ? ti in a table is reduced to a
record containing the pattern pi and the reduced
value vi:
ti =? vi/?i
[. . . ; pi ? ti; . . .] =? {p = pi;v = vi}/?i
Note that this rule is nondeterministic ? the ta-
ble is reduced to n different terms, where n is
the number of table rows.
? A table selection t!t? is reduced to the value v.v,
with the added constraint that the pattern v.p
and the selection term v? should unify:
t =? v0/? t? =? v?p/?
?
t!t? =? v / ???(vp
.
= v?p)
vp = prj(v0,p)
v = prj(v0,v)
Note that since t? denotes a parameter, it will be
reduced to a parameter term, v?p ? VPar.
? A record projection t.r is reduced to a projec-
tion v.r:
t =? v/?
t.r =? vr/?
vr = prj(v, r)
? All other term constructors are reduced com-
positionally, i.e., by reducing the internal terms
recursively.
The function prj(v, r) calculates the projection of
r on the simple term v. Since there are only two
reduced term constructors that can correspond to a
record, there are only two cases in the definition:
prj({. . . ; r = vr; . . .}, r) = vr
prj($n.? , r) = $n.?r
13
Example The original linearization term of the ex-
ample contains one table and one selection. The
selection $1.s!n is reduced to $1.sv with the added
constraint $1.sp .= n. And since there is only one
row in the table, the example term is reduced to one
single term vvp with the constraints ?vp:
vvp = {s = {p = n;v = $1.sv ++ $2.s}}
?vp = $1.sp
.
= n
3.2 Building Regulus terms
The reduced term and the constraints from the first
step do not constitute a Regulus grammar rule, but
they have to be massaged into the correct form. This
is done in four small steps below.
Step 2a: Flattening the reduced term
After the conversion t =? v/?, we have a re-
duced term v ? V and a set of constraints ? ?
VPar ? VPar. Now we convert v into a set of con-
straints and add to the constraint store ?:
? For each subterm v? in v denoting a parameter,
add $0.?
.
= v? to ?. The path ? is the sequence
of labels for getting from v to v?, i.e., v? = v.?.
We also create a set of ?proto rules? ? ? R??VStr:
? For each subterm v? in v denoting a string, add
? ? v? to ?. The path ? is the same as above.
Example There is one subterm in vvp denoting a
parameter, so we add $0.sp .= n to ?vp. There is
one subterm in vvp that denotes a string, so we let
?vp contain sv ? $1.sv ++ $2.s.
Step 2b: Simplifying the constraints
Now we have two constraint stores, ? and ?, of
which the latter can be partially evaluated into a sim-
pler form.
1. For each constraint of the form $n1.?1
.
=
$n2.?2, we replace it with two new constraints
$ni.?i
.
= x, where x is a fresh variable.3
2. For each constraint of the form x1@pi1
.
=
x2@pi2 , there are two possibilities:
3Recall that x is just a shorthand for x@pi, where pi is the set
of all parameters.
? If pi1 and pi2 are disjoint, then the con-
straint is contradictive and we remove v,
? and ? from the list of results.
? Otherwise, we replace each occurrence of
xi@pii in v and in ?, by x@pi, where x is a
fresh variable and pi = pi1 ? pi2.
Example We do not have to do anything to ?vp,
since all constraints already are in simplified form.
Step 2c: Building Regulus terms
Now ? only contains constraints of the form
$n.?
.
= p where p = x@pi. We transform these
constraints into the Regulus records T0, T1, . . . , T?
in the following way:
? For each constraint $n.?
.
= p, add the record
row {? = p} to Tn.
Note that the labels in the Regulus terms are se-
quences of GF labels.
Example The constraints in ?vp now give rise to
the Regulus terms:
Tvp,0 = {sp = n}
Tvp,1 = {sp = n}
Tvp,2 = {}
3.3 Building a Regulus grammar
To be able to create Regulus grammar rules from the
Regulus terms T0 . . . T?, we need to look at the ab-
stract syntax in the GF grammar. In this section we
will assume that the typing of the linearization in
question is f : A1 ? ? ? ? ? A? ? A.
Regulus (and Nuance GSL) permits the use of ar-
bitrary nested lists in the special sem feature. We
will use the nested list for representing a GF abstract
syntax tree which then will be returned directly by
Nuance after the parsing has succeeded. This is im-
portant since the arguments to the function can be
permuted in the linearization, which then means that
the arguments in the Regulus rule are permuted as
well.
14
Step 3a: Adding GF abstract syntax to the
Regulus terms
The abstract syntax tree of the original rule is put
as a sem value in the left-hand side term T0:
? Add the row {sem=[f x1 . . . x?]} to T0.
? For each 1 ? i ? ?, add {sem=xi} to Ti.
Note that the x1 . . . x? should be fresh variables, not
used elsewhere in the terms.
Example After adding semantics, the example
terms become:
Tvp,0 = {sp = n; sem = [vp x y]}
Tvp,1 = {sp = n; sem = x}
Tvp,2 = {sem = y}
Step 3b: Building Regulus grammar rules
Finally, we can transform the proto rules in ? into
Regulus grammar rules:
? For each proto rule ?0 ? v1 ++ ? ? ? ++ vm in
?, create a new Regulus rule:
A?0 : T0 ? v
?
1 . . . v
?
m
where the terms in the right-hand side are cal-
culated as follows:
(?s?)? = ?s?
($n.?)? = An ? : Tn
Example From the single proto rule in?vp we cre-
ate the Regulus rule:
VPsv : Tvp,0 ? TVsv : Tvp,1 NPs : Tvp,2
where the terms Tvp,i are described above.
4 Discussion
We have presented an algorithm for converting
GF grammars with a context-free backbone into
unification-based Regulus grammars. The algorithm
is simple and straightforward, which is an indication
that the formalisms are more similar than one might
have guessed beforehand.
4.1 Equivalence of the grammars
The presented algorithm does not necessarily yield
an equivalent grammar. This is a consequence of the
fact that context-free GF is equivalent to Multiple
CFG, and that Multiple CFG is much more expres-
sive than context-free grammars.
However, if the original grammar does not make
use of multiple constituents, the conversion is equiv-
alent. Note that the grammar might very well con-
tain multiple constituents, but if there is no right-
hand side that refers to both constituents simultane-
ously the equivalence is still preserved.
4.2 Complexity issues
As mentioned earlier, each GF function might give
rise to several Regulus rules, so in one sense the re-
sulting grammar is bigger than the original. How-
ever, the actual size in terms of memory usage does
not differ (except maybe linear because of differ-
ences in syntax).
4.2.1 The number of rules
The number of Regulus rules for one single GF
linearization term is equal to:
|?|
?
?
|?|
where |?| is the number of discontinuous con-
stituents, and ? ranges over all tables in the lin-
earization term. This is easy to see, since it is
only tables that are reduced nondeterministically,
and each proto rule in ? gives rise to one Regulus
rule.
4.2.2 The size of the grammar
The total size of the final grammar can be larger
than the original GF grammar. This is because the
Regulus grammar will contain lots of copies of the
same structures, e.g., everything outside of a table
has to be duplicated in for each table row. The the-
oretical limit is the same as above ? the number of
constituents, times the the total product of all table
rows ? but in practice the grammar explosion is not
that extreme.
Since the increase in size is due to copying, the
Regulus grammar can be compacted by the use of
macros (Rayner et al, 2006, section 4.5). This could
15
probably be implemented in the algorithm directly,
but we have not yet investigated this idea.
4.2.3 Time complexity
The time complexity of the algorithm is approxi-
mately equivalent to the size of the resulting Regu-
lus grammar. The first step (in section 3.1), can be
implemented as a single pass through the term and
is therefore linear in the size of the resulting terms.
The post-processing steps (in section 3.2) are also
linear in the size of the terms and constraints. Fi-
nally, the steps for building grammar rules does not
depend on the term size at all. Thus, the time com-
plexity is linear in the size of the final Regulus gram-
mar.
4.3 Using Regulus as a compiler for speech
recognition grammars
By presenting an algorithm for converting GF gram-
mars into Regulus, it is possible to further use the
Regulus-to-Nuance compiler for getting an opti-
mized speech recognition grammar. The advantage
to compiling Nuance grammars directly from GF is
clear: the Regulus project has developed and imple-
mented several optimizations (Rayner et al, 2006,
chapter 8), which would have to be reimplemented
in a direct GF-to-Nuance compiler.
As previously mentioned in section 1.1.4, there is
a speech recognition grammar compiler already im-
plemented in GF (Bringert, 2007), which uses the
equivalence of GF and Multiple CFG. An interest-
ing future investigation would be to compare the two
approaches on realistic grammars.
References
Bj?rn Bringert. 2007. Speech recognition grammar com-
pilation in Grammatical Framework. Submitted to
SpeechGram 2007.
Philippe de Groote. 2001. Towards abstract categorial
grammars. In 39th Meeting of the Association for
Computational Linguistics, Toulouse, France.
Peter Ljungl?f. 2004. Expressivity and Complexity of
the Grammatical Framework. Ph.D. thesis, G?teborg
University and Chalmers University of Technology,
November.
Per Martin-L?f. 1984. Intuitionistic Type Theory. Bib-
liopolis, Napoli.
ReinhardMuskens. 2003. Language, lambdas, and logic.
In Geert-Jan Kruijff and Richard Oehrle, editors, Reo-
surce Sensitivity in Binding and Anaphora, pages 23?
54. Kluwer.
Nuance Communications, Inc., 2003. Nuance Speech
Recognition System 8.5: Grammar Developer?s
Guide, December.
Carl Pollard. 1984. Generalised Phrase Structure Gram-
mars, Head Grammars and Natural Language. Ph.D.
thesis, Stanford University.
Carl Pollard. 2004. Higher-order categorial grammar. In
Michel Moortgat, editor, International Conference on
Categorial Grammars, Montpellier, France.
Aarne Ranta, Ali El-Dada, and Janna Khegai,
2006. The GF Resource Grammar Library.
Can be downloaded from the GF homepage
http://www.cs.chalmers.se/~aarne/GF
Aarne Ranta. 2004. Grammatical Framework, a type-
theoretical grammar formalism. Journal of Functional
Programming, 14(2):145?189.
Manny Rayner, Dave Carter, Pierrette Bouillon, Vassilis
Digalakis, and Mats Wir?n. 2000. The Spoken Lan-
guage Translator. Cambridge University Press.
Manny Rayner, Beth Ann Hockey, and Pierrette Bouil-
lon. 2006. Putting Linguistics into Speech Recogni-
tion: The Regulus Grammar Compiler. CSLI Publica-
tions.
Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free gram-
mars. Theoretical Computer Science, 88:191?229.
16
Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 110?119,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Lekbot: A talking and playing robot for children with disabilities
Peter Ljungl?f
Computer Science and Engineering
University of Gothenburg, Sweden
peter.ljunglof@gu.se
Britt Claesson
Ingrid Mattsson M?ller
DART: Centre for AAC and AT
Queen Silvia Children?s Hospital
Gothenburg, Sweden
{britt.claesson,ingrid.mattsson-muller}@vgregion.se
Stina Ericsson
Cajsa Ottesj?
Philosophy, Linguistics and
Theory of Science
University of Gothenburg, Sweden
{stina.ericsson,cajsa.ottesjo}@gu.se
Alexander Berman
Fredrik Kronlid
Talkamatic AB
Gothenburg, Sweden
{alex,fredrik}@talkamatic.se
Abstract
This paper describes an ongoing project
where we develop and evaluate a setup in-
volving a communication board and a toy
robot, which can communicate with each
other via synthesised speech. The purpose
is to provide children with communicative
disabilities with a toy that is fun and easy
to use together with peers, with and with-
out disabilities. When the child selects
a symbol on the communication board,
the board speaks and the robot responds.
This encourages the child to use language
and learn to cooperate to reach a common
goal. Throughout the project, three chil-
dren with cerebral palsy and their peers
use the robot and provide feedback for fur-
ther development. The multimodal inter-
action with the robot is video recorded and
analysed together with observational data
in activity diaries.
1 Background
The vision of our project is to utilise current
technology in human computer interaction and
dialogue systems to provide young people with
communication disabilities with a fun and ex-
citing toy. Currently there are not many op-
portunities for children with severe disabilities
to play independently and to interact on equal
terms with typically developing children. Our
hope is that the toy will give children, with and
without disabilities, the opportunity to interact
Figure 1: The robot and the communication board
and play with each other. As a side effect this
can also help them develop their communicative
skills.
We are developing a remote-controlled robot
that can be used by children with severe phys-
ical and/or communicative disabilities, such as
cerebral palsy or autism. The child communi-
cates by selecting a symbol on a communication
board, which is translated into an utterance us-
ing a speech synthesiser. The robot responds us-
ing synthesised utterances and physical actions,
that the child in turn can respond to. The com-
munication board acts as an extension of the
child, by giving the child speech as a means of
communication. The robot and its communica-
tion board is shown in Figure 1.
Technically the robot is controlled wirelessly,
110
with no speech recognition. The spoken dialogue
is there for the benefit of the child, and enables
the child to engage in a spoken dialogue, without
having the physical and/or cognitive ability to
do so. Our hope is that this will facilitate the
child?s own language development while having
fun with the radio-controlled robot.
1.1 The Lekbot project
The Lekbot project is a collaboration between
DART,1 Talkamatic AB and the University of
Gothenburg. It is funded by VINNOVA2 and
runs from March 2010 to August 2011.
The project is similar to the TRIK project
(Ljungl?f et al, 2009), which developed a draw-
ing robot that was controlled in the same man-
ner as above. The very limited user study that
was conducted suggested that the product had
great potential. The current project can be seen
as a continuation of TRIK, where we perform a
more full-scale user study, with video recording,
transcription, interaction analyses, etc.
1.2 Dialogue systems and robots
Most existing dialogue systems are meant to be
used by competent language users without phys-
ical, cognitive or communicative disabilities; ei-
ther they are supposed to be spoken to (e.g.,
phone based systems), or one has to be able to
type the utterances (e.g., the interactive agents
that can be found on the web). Dialogue sys-
tems for users with disabilities have so far been
targeted at people with physical disabilities, who
need help in performing daily activities.
Dialogue systems have also been used for sec-
ond language learning; i.e., learning a new lan-
guage for already language competent people.
Two examples are the artificial agent ?Ville: The
Virtual Language Tutor? (Beskow et al, 2004),
and ?SCILL: Spoken Conversational Interface
for Language Learning?, a system for practicing
Mandarin Chinese (Seneff et al, 2004).
However, we are not aware of any examples
where a dialogue system is used for communicat-
1Centre for AAC and AT at the Queen Silvia Chil-
dren?s Hospital
2The Swedish Governmental Agency for Innovation
Systems
ing with people with communication disorders.
With the advent of tablet computers, there
now exist several spoken-language and touch-
screen apps for children?s games and interactive
and linguistic training. In these apps, the in-
teraction is between the child and the tablet,
whereas in Lekbot the child and the tablet act
together as one dialogue participant, interact-
ing with the robot. The Lekbot robot is also a
physical agent, acting in the world, thus adding
another dimension to the interaction.
When it comes to robots, there are a number
of past and present research projects on robots
and children. An early inspiration is the LOGO
robot developed at Massachusetts Institute of
Technology for teaching children to use com-
puters and program simple applications (Papert,
1993). There are several robots focusing on chil-
dren with disabilities (Robins et al, 2008; Sal-
dien et al, 2006; Kozima et al, 2007; Lee et al,
2008; Arent and Wnuk, 2007), and most com-
monly autism. Some of these communicate with
children in different ways. For instance, KAS-
PAR is a child-sized humanoid robot for chil-
dren with autism, and it trains interactional ca-
pabilities through gesture imitation.3 Probo, de-
veloped for hospitalised children, produces non-
sense speech intended to convey different feel-
ings.4 KOALA is a small round ball that in-
teracts with children with autism using lights
and sounds (Arent and Wnuk, 2007). However,
none of these robots and research projects in-
volves natural language communication in any
form between the child and the robot.
2 Project description
Our basic idea is to use a dialogue system
to stimulate play and interaction for children
with severe communicative disabilities. There
are already communication boards connected to
speech synthesis in the form of communication
software on computers. The main values that
this project adds to existing systems are that:
? the child is offered an exciting, creative and
fun activity
3http://kaspar.feis.herts.ac.uk/
4http://probo.vub.ac.be/
111
? the child can play and interact with other
peers on equal terms
? the child can explore language in stimulat-
ing cooperation with the robot and with
other children
By being able to use a symbol-based communi-
cation board the children are given an opportu-
nity to play, interact, explore language, and at
the same time learn to use tools for alternative
and augmentative communication.
2.1 Description of the system
The child has a communication board that can
talk; when the child points at one of the symbols
it is translated to an utterance which the board
expresses via speech synthesis in Swedish. This
is recognised by a robot that moves around in the
room, and performs the commands that the child
expresses through the board. The robot has an
incarnation as a toy animal, currently a bumble-
bee. It has a very basic personality which means
that it can take the initiative, without the child
telling it, refuse actions, or even negotiate with
the child.
The inspiration for the robot comes from robot
toys such as babies, dogs and dinosaurs, but
also from electronic pets such as Tamagotchi and
Talking Tom. The main difference is that our
robot is able to have a dialogue with the child,
to find out what to do, or just to be teasingly
playful.
The Lekbot robot can move forward and back-
ward, and turn right and left. Furthermore it
can perform actions such as laughing, dancing,
yawning, farting and eating. The functionality
is constantly improving during the evaluation, to
keep the children interested in playing with the
robot.
2.2 Needs and potential
The target audience is children with severe
physical, cognitive or communicative disabilities.
These children depend on assistive devices and
persons to be able to interact with other people
and artifacts. The idea is that the robot will be
a fun toy that gives the child an opportunity to
control the artifacts itself, without the help of
other people. Hopefully this will increase the
child?s confidence, and also promote language
development.
2.2.1 The importance of play
Play may be defined by the following terms
(Knutsdotter Olofsson, 1992):
? spontaneous; the child takes the initiative,
not the adults
? not goal-oriented; the game does not have
an explicit purpose
? fun and pleasurable
? repeating; that it can be played many times
as one wants
? voluntary
For children with severe disabilities, playing re-
quires adult help, and it is difficult for the adult
not to control the game, especially if the child
has problems communicating what it wants. Of-
ten play is used as a tool for development train-
ing, and many times play is so scheduled that
it is no longer spontaneous (Brodin and Lind-
strand, 2007). A toy that is always available for
the child to play with whenever it wants, and
on its own terms can help the child to play ?for
real?.
Children learn from each other, and a toy that
is used on equal terms by children, with and
without disabilities, encourages interaction that
otherwise would not have been possible between
children with such diverse backgrounds.
2.2.2 Educational advantages
As discussed in section 3.3 later, the setup
works without the robot and the communication
board actually listening to each others? speech ?
instead, they communicate wirelessly. However,
there is an important educational point in hav-
ing them (apparently) communicate using spo-
ken language. It provides the child with an ex-
perience of participating in a spoken dialogue,
even though the child is not physically able to
speak. For children who are more advanced in
their language development, the robot can offer
112
the opportunity to understand the basic proper-
ties of the dialogue, such as taking turns, asking
and answering questions, the importance of pro-
viding sufficient information, and cooperating to
achieve a shared goal. Another educational ad-
vantage is that the child learns to use tools for
alternative and augmentative communication.
3 Implementation
This section describes some technical aspects of
the implementation of the Lekbot system.
3.1 Components
The final Lekbot setup consists of the following
components:
? a simple LEGO Mindstorms robot which
can turn and move in all directions, can
perform different specialised actions, and
has a ?costume? which makes it look like
a bumble-bee
? a touch-screen computer which functions as
a communication board, and a custom sup-
port frame for the computer
? the dialogue system GoDiS (Larsson, 2002),
using Acapela Multimedia text-to-speech
with Swedish voices
? Bluetooth communication and wireless au-
dio transmission, from the touch-screen
computer to the robot, and two sets of loud-
speakers, for the computer and the robot
If the target user already has his or her ownWin-
dows based communication device, with adapted
accessibility for him or her, this special software
for the robot play can be installed on this device.
Note that it is the communication board com-
puter that controls the robot via the dialogue
system, but the intention is that it should seem
like the robot is autonomous. Every utterance
by the robot is executed by the speech synthe-
siser, and then sent to the robot via radio.
3.2 LEGO Mindstorms
The robot is built using LEGO Mindstorms
NXT,5 a kind of technical lego which can be con-
5http://mindstorms.lego.com/
trolled and programmed via a computer. Apart
from being cheap, this technology makes it easy
to build a prototype and to modify it during the
course of the project.
3.3 Perfect speech recognition
Typically, the most error-prone component of a
spoken dialogue system is speech recognition;
the component responsible for correctly inter-
preting speech. This of course becomes even
more problematic when working with language
learning or communication disorders, since in
these situations it is both more difficult and more
important that the computer correctly hears and
understands the user?s utterances. An advan-
tage of the Lekbot setup is that we will, in a
sense, have ?perfect speech recognition?, since
we are cheating a bit. The robot does not ac-
tually have to listen for the speech generated by
the communication board; since the information
is already electronically encoded, it can instead
be transferred wirelessly. This means that the
robot will never hear ?go forward and then stop?
when the communication board actually says ?go
forward seven steps?.
3.4 The GoDiS dialogue manager
A dialogue system typically consists of several
components: speech recogniser, natural lan-
guage interpreter, dialogue manager, language
generator, speech synthesiser and a short-term
memory for keeping track of the dialogue state.
One can make a distinction between dialogue
systems, which (ideally) are general and reusable
over several domains, and dialogue system appli-
cations, which are specific to a certain domain.
The dialogue manager is the ?intelligence? of the
system, keeping track of what has been said so
far and deciding what should be said next.
The GoDiS dialogue manager (Larsson, 2002)
has been developed at the Department of Philos-
ophy, Linguistics and Theory of Science at the
University of Gothenburg over several years. It
is designed to be easily adaptable to new do-
mains, but nevertheless be able to handle a va-
riety of simpler or more complex dialogues. For
example, GoDiS can either take initiative and
prompt a user for information, or take a back
113
seat and let the experienced user provide infor-
mation in any desired order, without having to
wait for the right question from the system.
From the viewpoint of dialogue systems re-
search, there are some interesting aspects in the
Lekbot setting:
? Constantly changing environment : the sur-
roundings of the robot can change all the
time, and the dialogue system needs to
adapt
? Alternative input modalities: instead of
speech input, we are using a touch screen in-
terface, on which the symbols on the screen
also changes depending on the current dia-
logue state
? Utterance generation: it is important for ev-
eryone, but in particular children with com-
municative disabilities, that information is
presented in a correct way ? with correct
and consequent grammar, lexicon and pro-
nunciation
3.5 Utterance generation
Clear pronunciation is important, and perhaps
even more important when we are dealing with
communicative disabilities. We are experiment-
ing with using different utterance generation
strategies and stressing important words to make
the children understand the robot better. Inter-
estingly, user feedback from children and pre-
schools during the project has also indicated
when default intonation does not work and needs
to be modified.
The Lekbot system uses two different voices,
one for the touch screen, acting as the child?s
voice, and one for the robot. Whereas the touch-
screen voice is a vocalisation of something the
child has already seen on the screen, the utter-
ances of the robot have no visualisations. Hence,
it is particularly important that the robot?s ut-
terances are as clear as possible, and the TTS
voice chosen for the robot is therefore the voice
that was determined to have the best and most
flexible intonation in informal perception tests
at the start of the project.
3.5.1 Contextual intonation
We have incorporated models of information
structure in GoDiS to enable the appropriate
assignment of phonological emphasis (Ericsson,
2005).
Lekbot uses a fairly basic dialogue-move-to-
string mapping for the creation of output utter-
ances, which are then fed to the speech synthe-
siser. Determining the information structure of
an utterance to be generated, involves the deter-
mination of what is informative in the utterance
? the focus ? and what is a reflection of some-
thing already in the context ? the ground (Vall-
duv?, 1992). The system assigns emphasis to all
alternatives, that is, all contrasting elements, in
alternative questions, that are produced by the
robot. Consider the following example:
User : Go forward.
Robot : Do you want me to go forward
a lot or go forward a little?
For the generation of the robot utterance, the
system determines ?go forward a lot? and ?go
forward a little? as alternatives, and assigns em-
phasis to these. Future development of the sys-
tem may involve the inclusion of information
structure also for utterances other than non-
alternative questions, to determine appropriate
intonation assignment more generally.
Unfortunately, we have not yet been able to
use this feature in the actual demonstration sys-
tem, since the Swedish TTS voices do not em-
phasise properly with regard to the markup. In-
stead we have tuned the utterances lexically and
syntactically to make the best possible use of the
default TTS intonation.
4 Evaluation
We are evaluating the Lekbot system during
spring and summer 2011, in parallel with con-
tinued development, in the spirit of eXtreme
Programming (XP). Some major themes in XP
that were deemed particularly interesting in this
project are i) the need to involve the users in
the development process, ii) to work in short it-
erations with frequent releases to get a nearly
constant feedback from users, and iii) to always
114
prioritise the tasks that provide the greatest ben-
efit to users.
4.1 Users
A test group was recruited consisting of three
target children with peers and staff, at three
different pre-schools, was recruited. The target
children, two boys and one girl are in the ages 4?
6 years, two boys and one girl. They have cere-
bral palsy with complex communication needs.
They also have a poor gross motor control, but
are able to use their hands for activating a touch
screen on a computer. They serve as the test
group and as a basis for the specifications of the
further development of the system. During the
course of development the children in the test
group use the system to verify that it works as
intended and help to identify the most important
qualities to develop. The project group works
with one month iterations with a new public re-
lease every second month. Therefore, the users
have in the end used about six releases of the
robot.
Along with the target children, three typically
developed peers, of the same age, or slightly
younger, were recruited at each pre-school. The
three peers were all girls. Hence, there are three
groups of children playing with the robot. At
various occasions other children in the pre-school
group are involved in the robot play.
The children were assessed regarding their re-
ceptive language levels by using Test for Re-
ception of Grammar (TROG) (Bishop et al,
1998). Their communication levels were es-
timated by the project group in cooperation
with the pre-school staff using Communication
Function Classification System (CFCS) for In-
dividuals with Cerebral Palsy (Hidecker et al,
2009). The pre-school staff also completed
Swedish Early Communicative Development In-
ventories (SECDI) forms for each child (Eriks-
son and Berglund, 1999; Berglund and Eriksson,
2000). A pre-school form (F?rskoleformul?r) was
also completed (Granlund and Olsson, 1998). It
consists of questions concerning the child?s en-
gagement in various situations, the pre-school
teacher?s perception of the interaction between
her and the child as well as the interaction be-
tween the child and other children.
With the two youngest target children TROG
testing was not feasible, while the oldest one ap-
peared to have some difficulties in understand-
ing verbs, prepositions and sentences containing
these components, thus a bit lower than his age.
The three peers showed results matching their
age. From here on the target children will be
named Per, Hans and Greta.
The purpose of CFCS is to classify the every
day communication performance of an individ-
ual with cerebral palsy. The levels are ranged
between 1 and 5, where 1 is the highest and 5
the lowest.
? The 6 year old Per shows a level of 3: Ef-
fective sender and effective receiver with fa-
miliar partners.
? The 5 year old Hans is estimated to level
5: Seldom effective sender and effective re-
ceiver with familiar partners, and
? The 4 year old Greta is at level 4: Incon-
sistent sender and/or receiver with familiar
partners.
? All the peers, of course, reach the level of 1.
The CFCS levels will be estimated over again
when the Lekbot testing is finished.
The results of SECDI and the pre-school form
will be presented at a later stage of the Lekbot
project, as they will be redistributed.
4.2 Evaluation tools and methods
The tools used to evaluate the robot play are
three:
? Talking Mats,6 which is an established com-
munication tool that uses a mat with at-
tached symbols as the basis for communi-
cation. It is designed to help people with
communicative and cognitive difficulties to
think about issues discussed with them, and
provide them with a way to effectively ex-
press their opinions. Both the target chil-
dren and their peers were interviewed about
the robot and the interaction, in order to get
6http://www.talkingmats.com
115
feedback for evaluation and for developing
the system.
They were asked questions about the be-
haviour of the robot and answered by
putting symbol cards either at the ?fun? side
of the mat or at the ?boring/not nice? side.
It is also possible to put symbols between
?fun? and ?boring/not nice?. The answers
were then checked and evaluated together
with the children. An example is shown in
Figure 2.
? Video recordings during the robot play were
made by the project group from January
to May 2011, six recordings from each peer
group, in all 18 recordings. The duration
is between 20 and 30 minutes each and
shot with one camera by one of the project
members. Short sequences from the videos
have been transcribed and analysed with
focus on cooperation between the children
and joyfulness. Transcriptions were made
in CLAN7 with detailed descriptions of the
non-verbal actions, signs and gaze. We got
permissions to do the recordings from the
parents of the children.
? Weekly Activity diaries were kept by the
pre-school staff, where they could provide
their reflections about the play sessions.
The diaries included headings regarding
numbers of play occasions, duration of the
play, persons participating, what happened
in the play, functionality of the robot, sug-
gestions for improvement and the children?s
satisfaction with the play perceived by the
staff.
Furthermore, the interaction between the com-
munication board and the robot is logged by the
system, providing valuable information.
Beside these evaluation tools there have also
been discussions with the designated staff at the
current pre-schools.
7http://childes.psy.cmu.edu/clan/
Figure 2: Talking Mats
4.3 Preliminary evaluation results from
the activity diaries
According to the activity diaries, Lekbot was
used 56 times during releases 2?5; just below 10
times each for the early releases, and 20 times
each for releases 4 and 5. There is a great varia-
tion in numbers of performed play sessions and
in completed activity diaries, mainly due to ill-
ness in children or staff, orthopedic surgery in
one child and holidays. In the beginning there
was always the same peer, and only that one,
attending the play sessions. Further on in the
project the staff chose to engage more peers
from the pre-school. That means that sometimes
there was a different peer than originally and
sometimes there was a group of peers interact-
ing in the play. The support person attending
the play sessions was always the same. She also
was the one completing the activity diaries.
4.3.1 Functionality
15 comments were given about the system
working well, where release 5 got the best scores.
Problems with the system were reported 16
times. Comments were given about rebooting
the system, loosing the commands, or problems
with activating them. Dissatisfaction with the
actions of the Lekbot was reported 5 times,
mainly about the delay between activating a
command and the activation of the robot. There
were also reports of improved accessibility of the
system, by finding a mobile piece of furniture
116
for the stand and by changing the angle of the
display.
4.3.2 Interaction
The project group chose not to give strict in-
structions on what to do in the play, just to let
everyone use the Lekbot at suitable level. Thus,
there was a variation in complexity of the com-
ments, as the headings in the activity diaries
gave a structure of open questions. The col-
lected, written comments were categorised in five
groups; Preparations for the Lekbot play, Ex-
plicit support from adult, Target child?s activity
and perception of the play, Peer?s activity and
perception of the play and Shared activity and
perception of the play between target child and
peer(s). The three latter are reported together
release by release.
Preparation for the Lekbot play occurred
mainly for Per?s group, where he and his peers
built different tracks for the robot to follow. Ex-
plicit support by adult is mentioned only for
Per?s group, where the adult chose target point
for the robot and she used the play for educa-
tional matters regarding letter teaching. She
also mediated between the children which im-
proved their cooperation. In the final sessions
Per initiated turn taking after being urged by
the adult.
4.3.3 Activity and perception
Target child?s activity and perception of the
play is mentioned a lot, especially for Per and
Greta. Most frequent among the comments are
those concerning Shared activity and perception
of the play between target child and peer(s).
Release 2: Per initiates turn taking, reacts
to the event followed by the activation of the
command on the display, protests when his peer
choses ?the wrong command?. Together they re-
peatedly perform turn taking and use Per?s dig-
ital communication device in the Lekbot activ-
ity. Hans and his peers make a tunnel and the
children give commands that make the robot go
through it. Greta has high expectations on the
play before the session. Repeatedly she is unwill-
ing to stop the play and she gives oral comments
to the activities of the robot.
Release 3: Per explores the commands and
what happens when using them to answer the
newly implemented supplementary questions.
Around Hans there is turn taking. Several chil-
dren are playing together and the children most
frequently choose the dance command. Greta
is excited and unwilling to stop the play. She
protests when the adult makes the choice for the
robot.
Release 4: Per shows the new commands for
his peer, and the children imitate the robot.
Per and his original peer chose one new peer
each. Interaction between the children takes
place through dancing and hand clapping. Hans
plays with the robot together with adults from
outside the preschool. Greta likes going back-
wards, turning and hitting things with the robot.
She starts telling her peer how to act by us-
ing the commands on the display and her paper
communication chart. Her peer enjoys follow-
ing Greta?s ?instructions? and she likes dancing.
There are repeated turn taking between them
and they enjoy to cooperate getting the robot to
move from one spot to another.
Release 5: Per plays with the new commands,
by himself. He finds strategies for the robot in
finding food. When there are more than two
children in the play, Per chooses to be the one
controlling the display. He cooperates more ?
waits for his turn and shows better understand-
ing for the other?s turn. All children repeatedly
use communication charts and Blissymbolics to
express themselves. They imitate the robot and
they act instead of it when it is out of order.
In Hans?s group there is dancing and looking
for food play. Turn taking takes place and all
children want to participate in the Lekbot play.
Greta decides whose turn it is to control the
robot. Her peer likes the play of finding food.
4.3.4 Satisfaction
Starting in release 3, the level of satisfaction
with the play session was noted in the activity
diary. The staff was asked to estimate how sat-
isfied the target child and the peer were on a
scale from 1 to 5, where 1 is the lowest and 5
the highest. This was done every time at some
117
pre-schools and some times at others. The ten-
dency is that the target children seem to be more
satisfied with the play than their peers from the
start of the play session. This is most protrud-
ing regarding the oldest pair. At release 4 where
Per and his peer interact as a group for the first
time, the scores suddenly are reversed so the Per
is perceived to 3 on the satisfactory scale and the
peer(s) at 5. In release 5 the scores get a more
even variation.
4.4 Video recordings
Most of the interviews with Talking Mats were
video recorded. The full analysis will be done
later in the project. The analysis of the video
recordings of the robot interaction is an ongoing
work were three of the project members partic-
ipate. This part of the work is time consuming
and only minor sequences are transcribed and
analysed so far. Through micro analysis the fine
grained interactional movements and the coop-
eration between the children and the teacher ap-
pears, as well as the joy of playing.
Figure 3 contains a segment from the tran-
scription. The participants are Per, his peer
Selma and his teacher Isa; and the Computer
and the Robot. In the excerpt we can see how
Per asks for Selma?s attention and with the help
of Isa and the communication map tells Selma
to take her turn, which is to make a new com-
mand for the robot to perform. Finally they
both dance to the music.
4.5 Conclusion
All target children have enjoyed the Lekbot play
from the beginning. The more commands and
abilities the robot has received the more appre-
ciated has the play become also by the peers.
Improved play and interaction skills can be ob-
served in varying degrees depending on the level
of each child. The Lekbot has been a nice and
fun artefact for the children to gather round and
it has given both the target children and their
peers experiences of playing with each other.
From Talking Mats interviews performed with
Per and Greta it was revealed that they had no
problems handling the computer display or see-
ing and hearing the display and the robot. Mak-
126 %gaze: Per looks at Selma
127 %move: Selma is standing on her knees, sits down
on her heels, keeps booths hands on her skirt
128 %gaze: Selma looks toward the mirror on the wall
129 %move: Per touches the left hand of Selma, keeps
his arm stretched when Selma moves a bit
131 %gaze: Isa looks at Per?s hand
132 *Selma: ????????
133 %comment : Selma is singing while Per stretches to-
ward her left hand
134 %gesture: Isa draws the pointing map closer
135 %gaze: Per looks down at the map
136 %gaze: Selma looks down at the map
137 *Per : ????????
138 %move: Selma stands up on her knee, departs on a
movement forward
139 *Isa: eh::: (0.3) your turn (0.3) Selma?s turn
140 %gesture: Isa moves her finger back and forth over
the 6th picture on the map
141 %gesture: Isa rests her finger at the picture, then
withdraws it
142 %gesture: Per points at the map
143 %move: Selma moves toward the screen
144 (2.1)
145 %action: Selma makes a fast press at the screen
146 %gaze: Per looks at the screen
147 *Selma: dance: my king ????????
148 %move: Selma moves left with arms swinging, bends
forward, landing on hands and knees
149 %action: Per looks at Selma, smiles
150 *Computer : dance
151 *Selma: mi:ine ?: ?: ?(1.8)?
152 *Robot : okay I gladly dance
153 (1.0)
154 *Robot : plays music 11 sec
155 %comment : both children are dancing, Selma on her
knees and Per sitting down
Figure 3: An example transcription segment, trans-
lated to English
ing the same interview with Hans was not feasi-
ble, though the project group experienced that
he seemed to deal pretty well with the system,
although he needed a little more support than
the two other children, who were able to control
the toy autonomously. More results will be pre-
sented when the video sequences are analysed,
later on in the project.
5 Acknowledgements
We are grateful to 5 anonymous referees for
their valuable comments. The Lekbot project
is financed by Vinnova, and Acapela has kindly
provided us with speech synthesis.
118
References
K. Arent and M. Wnuk. 2007. Remarks on be-
haviours programming of the interactive therapeu-
tic robot Koala based on fuzzy logic techniques.
In First KES International Symposium on Agent
and Multi-Agent Systems: Technologies and Ap-
plications, Wroclaw, Poland.
E. Berglund and M. Eriksson. 2000. Communicative
development in Swedish children 16?28 months
old: The Swedish early communicative develop-
ment inventory ? words and sentences. Scandina-
vian Journal of Psychology, 41(2):133?144.
Jonas Beskow, Olov Engwall, Bj?rn Granstr?m, and
Preben Wik. 2004. Design strategies for a virtual
language tutor. In INTERSPEECH 2004.
Dorothy Bishop, Eva Holmberg, and Eva Lund?lv.
1998. TROG: Test for Reception of Grammar
(Swedish version). SIH L?romedel.
J. Brodin and P. Lindstrand. 2007. Perspektiv p?
IKT och l?rande f?r barn, ungdomar och vuxna
med funktionshinder. Studentlitteratur.
Stina Ericsson. 2005. Information Enriched Con-
stituents in Dialogue. Ph.D. thesis, University of
Gothenburg, Gothenburg, Sweden.
M. Eriksson and E. Berglund. 1999. Swedish early
communicative development inventory ? words
and gestures. First Language, 19(55):55?90.
M. Granlund and C. Olsson. 1998. Familjen och
habiliteringen. Stiftelsen ALA.
M. J. C. Hidecker, N. Paneth, P. Rosenbaum, R. D.
Kent, J. Lillie, and B. Johnson. 2009. Develop-
ment of the Communication Function Classifica-
tion System (CFCS) for individuals with cerebral
palsy. Developmental Medicine and Child Neurol-
ogy, 51(Supplement s2):48.
B. Knutsdotter Olofsson. 1992. I lekens v?rld.
Almqvist och Wiksell.
H. Kozima, C. Nakagawa, and Y. Yasuda. 2007.
Children-robot interaction: a pilot study in autism
therapy. Progress in Brain Research, 164:385?400.
Staffan Larsson. 2002. Issue-based Dialogue Man-
agement. Ph.D. thesis, Department of Linguistics,
University of Gothenburg, Sweden.
C.H. Lee, K. Kim, C. Breazeal, and R.W. Picard.
2008. Shybot: Friend-stranger interaction for chil-
dren living with autism. In CHI2008, Florence,
Italy.
Peter Ljungl?f, Staffan Larsson, Katarina M?hlen-
bock, and Gunilla Thunberg. 2009. TRIK: A talk-
ing and drawing robot for children with commu-
nication disabilities. In Nodalida?09: 17th Nordic
Conference of Computational Linguistics. Short
paper and demonstration.
Seymour Papert. 1993. Mindstorms: Children,
Computers, and Powerful Ideas. Basic Books.
B. Robins, K. Dautenhahn, R. te Boekhorst, and
C.L. Nehaniv. 2008. Behaviour delay and ex-
pressiveness in child-robot interactions: a user
study on interaction kinesics. In HRI?08, 3rd
ACM/IEEE International Conference on Human
Robot Interaction, Amsterdam, Netherlands.
J. Saldien, K. Goris, B. Verrelst, R. Van Ham, and
D. Lefeber. 2006. ANTY: The development of
an intelligent huggable robot for hospitalized chil-
dren. In CLAWAR, 9th International Conference
on Climbing and Walking Robots, Brussels, Bel-
gium.
Stephanie Seneff, Chao Wang, and Julia Zhang.
2004. Spoken conversational interaction for lan-
guage learning. In InSTIL/ICALL 2004 Sympo-
sium on Computer Assisted Learning: NLP and
Speech Technologies in Advanced Language Learn-
ing Systems.
E. Vallduv?. 1992. The Informational Component.
Garland.
119
