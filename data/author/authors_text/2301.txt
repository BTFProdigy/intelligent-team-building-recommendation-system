Proceedings of the TextInfer 2011 Workshop on Textual Entailment, EMNLP 2011, pages 50?58,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Strings over intervals
Tim Fernando
Computer Science Department
Trinity College, Dublin 2
Ireland
Tim.Fernando@tcd.ie
Abstract
Intervals and the events that occur in them
are encoded as strings, elaborating on a con-
ception of events as ?intervals cum descrip-
tion.? Notions of satisfaction in interval
temporal logics are formulated in terms of
strings, and the possibility of computing these
via finite-state machines/transducers is inves-
tigated. This opens up temporal semantics to
finite-state methods, with entailments that are
decidable insofar as these can be reduced to
inclusions between regular languages.
1 Introduction
It is well-known that Kripke models for Linear
Termporal Logic (LTL) can be formulated as strings
(e.g. Emerson, 1990). For the purposes of natu-
ral language semantics, however, it has been argued
since at least (Bennett and Partee, 1972) that inter-
vals should replace points. It is less clear (than in
the case of LTL) how to view models as strings for
intervals drawn (say) from the real line R, as in one
of the more recent interval temporal logics proposed
for English, the system T PL of (Pratt-Hartmann,
2005). But if we follow T PL in restricting our mod-
els to finite sets, we can encode satisfaction of a for-
mula ? in a set L(?) of strings str(A, I) represent-
ing models A and intervals I
(?) A |=I ? ?? str(A, I) ? L(?) .
The present paper shows how to devise encodings
str(A, I) and L(?) that establish (?) in a way that
opens temporal semantics up to finite-state methods
(e.g. Beesley and Karttunen, 2003). Notice that the
entailment from ? to ?? given by
(?A, I) if A |=I ? then A |=I ?
?
is equivalent, under (?), to the inclusion L(?) ?
L(??). This inclusion is decidable provided L(?)
and L(??) are regular languages. (The same cannot
be said for context-free languages.)
1.1 T PL-models and strings
We start with T PL, a model in which is defined,
relative to an infinite set E of event-atoms, to be a
finite set A of pairs ?I, e? of closed, bounded inter-
vals I ? R and event-atoms e ? E. (A closed,
bounded interval in R has the form
[r1, r2]
def
= {r ? R | r1 ? r ? r2}
for some r1, r2 ? R.) The idea is that ?I, e? repre-
sents ?an occurrence of an event of type e over the
interval? I (Pratt-Hartmann, 2005; page 17). That
is, we can think of A as a finite set of events, con-
ceived as ?intervals cum description? (van Benthem,
1983; page 113). Our goal below is to string out this
conception beyond event-atoms, and consider rela-
tions between intervals other than sub-intervalhood
(the focus of T PL). To get some sense for what is
involved, it is useful to pause for examples of the
strings we have in mind.1
1Concrete English examples connected with text infer-
ence can be found in (Pratt-Hartmann, 2005; Pratt-Hartmann,
2005a), the latter of which isolates a fragment T PL? of T PL
related specifically to TimeML (Pustejovsky et al, 2003). The
finite-state encoding below pays off in expanding the coverage
50
?X(?1 ? ? ??n)
def
= (?1 ?X) ? ? ? (?n ?X)
bc(s) def=
?
?
?
bc(?s?) if s = ??s?
?bc(??s?) if s = ???s? and ? 6= ??
s otherwise
Table 1: Two useful functions
Example A Given event-atoms e and e?, let A be
the T PL-model {x1, x2, x3}, where
x1
def
= ?[1, 4], e?
x2
def
= ?[3, 9], e?
x3
def
= ?[9, 100], e?? .
Over the alphabet Pow(A) of subsets of A, let us
represent A by the string
s(A)
def
= x1 x1, x2 x2 x2, x3 x3
of length 5, each box representing a symbol (i.e. a
subset of A) and arranged in chronological order
with time increasing from left to right much like a
film/cartoon strip (Fernando, 2004). Precisely how
s(A) is constructed from A is explained in section
2. Lest we think that a box represents an indivisible
instant of time, we turn quickly to
Example B The 12 months, January to December,
in a year are represented by the string
sy/m
def
= Jan Feb ? ? ? Dec
of length 12, and the 365 days of a (common) year
by the string
sy/m,d
def
= Jan,d1 Jan,d2 ? ? ? Dec,d31
of length 365. These two strings are linked by two
functions on strings: a function ?months that keeps
only the months in a box so that
?months(sy/m,d) = Jan
31
Feb
28
? ? ? Dec
31
and block compression bc, which compresses con-
secutive occurrences of a box into one, mapping
?months(sy/m,d) to
bc( Jan
31
Feb
28
? ? ? Dec
31
) = sy/m .
to examples discussed in (Fernando, 2011a) and papers cited
therein. These matters are given short shrift below (due to space
and time constraints); I hope to make amends at my talk in the
workshop.
(A1) x? x (i.e. ? is reflexive)
(A2) x? x? =? x?? x
(A3) x ? x? =? not x? x?
(A4) x ? x?? x?? ? x??? =? x ? x???
(A5) x ? x? or x? x? or x? ? x
Table 2: Axioms for event structures
That is,
bc(?months(sy/m,d)) = sy/m
where, as made precise in Table 1, ?X ?sees only
X? (equating months with {Jan, Feb, . . . Dec} to
make ?months an instance of ?X ), while bc discards
duplications, in accordance with the view that time
passes only if there is change. Or rather: we observe
time passing only if we observe a change in the con-
tents of a box. The point of this example is that tem-
poral granularity depends on the set X of what are
observable ? i.e., the boxables (we can put inside a
box). That set X might be a T PL-modelA or more
generally the set E of events in an event structure
?E,?,??, as defined in (Kamp and Reyle, 1993).
Example C Given a T PL-model A, let? and ?
be binary relations on A given by
?I, e? ? ?I ?, e??
def
?? I ? I ? 6= ?
?I, e? ? ?I ?, e??
def
?? (?r ? I)(?r? ? I ?) r < r?
for all ?I, e? and ?I ?, e?? ? A. Clearly, the triple
?A,?,?? is an event structure ? i.e., it satisfies
axioms (A1) to (A5) in Table 2. But for finite A, the
temporal structure the real line R confers on A is
reduced considerably by the Russell-Wiener-Kamp
derivation of time from event structures (RWK). In-
deed, for the particular T PL-model A in Exam-
ple A above, RWK yields exactly two temporal
points, constituting the substring x1, x2 x2, x3 of
the string s(A) of length 5. As an RWK-moment
from an event structure ?E,?,?? is required to be
a ?-maximal set of pairwise?-overlapping events,
RWK discards the three boxes x1 , x2 and x3 in
s(A). There is, however, a simple fix from (Fer-
nando, 2011) that reconciles RWK not only with
s(A) but also with block compression bc: enlarge the
set A of events/boxables to include pre- and post-
51
events, turning s(A) into
x1, pre(x2), pre(x3) x1, x2, pre(x3)
x2, post(x1), pre(x3) x2, x3, post(x1)
x3, post(x1), post(x2) .
Note that pre(xi) and post(xi) mark the past and fu-
ture relative to xi, injecting, in the terminology of
(McTaggart, 1908), A-series ingredients for tense
into the B-series relations ? and ? (which is just
?-incomparability). For our present purposes, these
additional ingredients allow us to represent all 13 re-
lations between intervals x and x? in (Allen, 1983)
by event structures over {x, x?, pre(x), post(x?)}, in-
cluding the sub-interval relation x during x? at the
center of (Pratt-Hartmann, 2005),2 which strings out
to
pre(x), x? x, x? post(x), x? .
It will prove useful in our account of T PL-formulas
below to internalize the demarcation of x by pre(x)
and post(x) when forming str(A, I).
1.2 Outline
The remainder of the paper is organized as follows.
Section 2 fills in details left out in our presentation of
examples above, supplying the ingredient str(A, I)
in the equivalence
(?) A |=I ? ?? str(A, I) ? L(?) .
The equivalence itself is not established before sec-
tion 3, where every T PL-formula ? is mapped to a
language L(?) via a translation ?+ of ? to a mi-
nor variant T PL+ of T PL. That variant is de-
signed to smoothen the step in section 4 from T PL
to other interval temporal logics which can be strung
out similarly, and can, under natural assumptions, be
made amenable to finite-state methods.
2Or to be more correct, the version of T PL in (Pratt-
Hartmann, 2005a), as the strict subset relation ? between in-
tervals assumed in the Artificial Intelligence article amounts to
the disjunction of the Allen relations during, starts and finishes.
For concreteness, we work with ? below; only minor changes
are required to switch to during.
2 Strings encoding finite interval models
This section forms the string str(A, I) in three
stages described by the equation
str(A, I)
def
= s(AI)
? .
First, we combine A and I into the restriction AI of
A to pairs ?J, e? such that J is a strict subset of I
AI
def
= {?J, e? ? A | J ? I}
Second, we systematize the construction of the
string s(A) in Example A. And third, we map a
string s to a string s? that internalizes the borders
externally marked by the pre- and post-events de-
scribed in Example C. The map A 7? s(A) is the
business of ?2.1, and s 7? s? of ?2.2. With an eye
to interval temporal logics other than T PL, we will
consider the full set Ivl(R) of (non-empty) intervals
in R
Ivl(R) def= {a ? R | a 6= ? and (?x, y ? a)
[x, y] ? a} ,
and write ]r1, r2[ for the open interval
]r1, r2[
def
= {r ? R | r1 < r < r2}
where we allow r1 = ?? for intervals unbounded
to the left and r2 = +? for intervals unbounded
to the right. The constructs ?? are convenient for
associating endpoints with every interval I , whether
or not I is bounded. For I bounded to the left and
to the right, we refer to real numbers r and r? as I?s
endpoints provided I ? [r, r?] and
[r, r?] ? [r??, r???] for all r?? and r??? such
that I ? [r??, r???] .
We write Endpoints(I) for the (non-empty) set con-
sisting of I?s endpoints (including possibly ??).
2.1 Order, box and compress
Given a finite subsetA ? Ivl(R)?E, we collect all
endpoints of intervals in A in the finite set
Endpoints(A)
def
=
?
?I,e??A
Endpoints(I)
and construct s(A) in three steps.
52
Step 1 Order Endpoints(A) into an increas-
ing sequence
r1 < r2 < ? ? ? < rn.
Step 2 Box the A-events into the sequence
of 2n? 1 intervals
{r1}, ]r1, r2[, {r2}, ]r2, r3[, . . . {rn}
(partitioning the closed interval
[r1, rn]), forming the string
?1?1?2?2 ? ? ??n
(of length 2n? 1) where
?j
def
= {?i, e? ? A | rj ? i}
?j
def
= {?i, e? ? A | ]rj , rj+1[? i} .
Step 3 Block-compress ?1?1?2?2 ? ? ??n
s(A)
def
= bc(?1?1?2?2 ? ? ??n) .
For example, revisiting Example A, where A is
{x1, x2, x3} and
x1
def
= ?[1, 4], e?
x2
def
= ?[3, 9], e?
x3
def
= ?[9, 100], e??
we have from Step 1, the 5 endpoints
~r = 1, 3, 4, 9, 100
and from Step 2, the 9 boxes
x1 x1 x1, x2 x1, x2 x1, x2 x2 x2, x3 x3 x3
that block-compresses in Step 3 to the 5 boxes s(A)
x1 x1, x2 x2 x2, x3 x3 .
Notice that if we turned the closed intervals in x1
and x3 to open intervals ]1, 4[ and ]9, 100[ respec-
tively, then Step 2 gives
x1 x1, x2 x1, x2 x2 x2 x2 x3
which block-compresses to the 6 boxes
x1 x1, x2 x2 x3 .
2.2 Demarcated events
Block compression accounts for part of the Russell-
Wiener-Kamp constuction of moments from an
event structure (RWK). We can neutralize the re-
quirement of ?-maximality on RWK moments by
adding pre(xi), post(xi), turning, for instance, s(A)
for A given by Example A into
x1, pre(x2), pre(x3) x1, x2, pre(x3)
post(x1), x2, pre(x3) post(x1), x2, x3
post(x1), post(x2), x3
(which ?A maps back to s(A)). In general, we say
a string ?1?2 ? ? ??n is A-delimited if for all x ? A
and integers i from 1 to n,
pre(x) ? ?i ?? x ? (
n?
j=i+1
?j)?
i?
j=1
?j
and
post(x) ? ?i ?? x ? (
i?1?
j=1
?j)?
n?
j=i
?j .
Clearly, for every string s ? Pow(A)?, there is a
unique A-delimited string s? such that ?A(s?) = s.
Let s? be that unique string.
Notice that pre(x) and post(x) explicitly mark the
borders of x in s?. For the application at hand to
T PL, it is useful to internalize the borders within x
so that, for instance in Example A, s(A)? becomes
x1, begin-x1 x1, x2, x1-end, begin-x2
x2 x2, x3, x2-end, begin-x3 x3, x3-end
(with pre(xi) shifted to the right as begin-xi and
post(xi) to the left as xi-end). The general idea is
that given a string ?1?2 ? ? ??n ? Pow(A)n and x ?
A that occurs at some ?i, we add begin-x to the first
box in which x appears, and x-end to the last box
in which x appears. Or economizing a bit by pick-
ing out the first component I in a pair ?I, e? ? A, we
form the demarcation (?1?2 ? ? ??n)? of?1?2 ? ? ??n
by adding bgn-I to ?i precisely if
there is some e such that ?I, e? ? ?i and either
i = 1 or ?I, e? 6? ?i?1
53
? ::= mult(e) | ?? | ? ? ?? | ????
? ::= e | ef | el
? ::= ? | ?< | ?>
Table 3: T PL+-formulas ? from extended labels ?
and adding I-end to ?i precisely if
there is some e such that ?I, e? ? ?i and either
i = n or ?I, e? 6? ?i+1 .
Returning to Example A, we have
s(A)? = x1, bgn-I1 x1, x2, I1-end, bgn-I2
x2 x2, x3, I2-end, bgn-I3 x3, I3-end
which is str(A, I) for any interval I such that
[1, 100] ? I .
3 T PL-satisfaction in terms of strings
This section defines the set L(?) of strings for the
equivalence (?)
(?) A |=I ? ?? str(A, I) ? L(?)
by a translation to a language T PL+ that differs
ever so slightly from T PL and its extension T PL+
in (Pratt-Hartmann, 2005). As in T PL and T PL+,
formulas in T PL+ are closed under the modal op-
erator ?e?, for every event-atom e ? E. Essen-
tially, ?e?> says at least one e-transition is possible.
In addition, T PL+ has a formula mult(e) stating
that multiple (at least two) e-transitions are possible.
That is, mult(e) amounts to the T PL+-formula
?e?> ? ?{e}>
where the T PL+-formula {e}? can be rephrased as
?e?? ? ?mult(e)
(and > as the tautology ?(mult(e) ? ?mult(e))).
More formally, T PL+-formulas ? are generated
according to Table 3 without any explicit mention
of the T PL-constructs {?}, {?}< and {?}>. In-
stead, a T PL+-formula ? is translated to a T PL+-
formula ?+ so that (?) holds with L(?) equal to
T (?+), where T (?) is a set of strings (defined
below) characterizing satisfaction in T PL+. The
translation ?+ commutes with the connectives com-
mon to T PL+ and T PL+
e.g., (??)+
def
= ?(?+)
and elsewhere,
>+
def
= ?(mult(e) ? ?mult(e))
({e}?)+
def
= ?e??+ ? ?mult(e)
([e]?)+
def
= ??e???+
({e}<?)+
def
= ?e<??+ ? ?mult(e)
({e}>?)+
def
= ?e>??+ ? ?mult(e)
and as minimal-first and minimal-last subintervals
are unique (Pratt-Hartmann, 2005, page 18),
({eg}<?)+
def
= ?eg<??+ for g ? {f, l}
({eg}>?)+
def
= ?eg>??+ for g ? {f, l} .
3.1 The alphabet ? = ?I,E and its subscripts
The alphabet from which we form strings will de-
pend on a choice I, E of a set I ? Ivl(R) of
real intervals, and a set E of event-atoms. Recall-
ing that the demarcation s(A)? of a string s(A)
contains occurrences of bgn-I and I-end, for each
I ? domain(A), let us associate with I the set
I?
def
= {bgn-I | I ? I} ? {I-end | I ? I}
from which we build the alphabet
?I,E
def
= Pow((I? E) ? I?)
so that a symbol (i.e., element of ?I,E) is a set with
elements of the form ?I, e?, bgn-I and I-end. Notice
that
(?A ? I? E) str(A, I) ? ??I,E
for any real interval I . To simplify notation, we will
often drop the subscripts I and E, restoring them
when we have occasion to vary them. This applies
not only to the alphabet ? = ?I,E but also to the
truth sets T (?) = TI,E(?) below, with I fixed in
the case of (?) to the full set of closed, bounded real
intervals.
54
3.2 The truth sets T (?)
We start with mult(e), the truth set T (mult(e)) for
which consists of strings properly containing at least
two e-events. We first clarify what ?properly con-
tain? means, before turning to ?e-events.? The no-
tion of containment needed combines two ways a
string can be part of another. The first involves delet-
ing some (possibly null) prefix and suffix of a string.
A factor of a string s is a string s? such that s = us?v
for some strings u and v, in which case we write
s fac s?
s fac s?
def
?? (?u, v) s = us?v .
A factor of s is proper if it is distinct from s. That
is, writing s pfac s? to mean s? is a proper factor of
s,
s pfac s? ?? (?u, v) s = us?v
and uv 6= 
where  is the null string. The relation pfac between
strings corresponds roughly to that of proper inclu-
sion ? between intervals.
The second notion of part between strings applies
specifically to strings s and s? of sets: we say s sub-
sumes s?, and write s  s?, if they are of the same
length, and ? holds componentwise between them
?1 ? ? ??n  ?
?
1 ? ? ??
?
m
def
?? n = m and
??i ? ?i for
1 ? i ? n
(Fernando, 2004). Now, writing R;R? for the com-
position of binary relations R and R? in which the
output of R is fed as input to R?
s R;R? s?
def
?? (?s??) sRs?? and s??R?s? ,
we compose fac with  for containment w
w
def
= fac ;  (=  ; fac)
and pfac with  for proper containment A
A
def
= pfac ;  (=  ; pfac) .
Next, for e-events, given I ? I, let
D(e, I)
def
= {s? | s ? ?I, e?
+
}
and summing over intervals I ? I,
DI(e)
def
=
?
I?I
D(e, I) .
Dropping the subscripts on ? and D(e), we put
into T (mult(e)) all strings in ?? properly contain-
ing more than one string in D(e)
s ? T (mult(e))
def
?? (?s1, s2 ? D(e)) s1 6= s2
and s A s1 and s A s2.
Moving on, we interpret negation ? and conjunc-
tion ? classically
T (??)
def
= ?? ? T (?)
T (? ? ??)
def
= T (?) ? T (??)
and writing R?1L for {s ? ?? | (?s? ? L) sRs?},
we set
T (????)
def
= R(?)?1T (?)
which brings us to the question ofR(?).
3.3 The accessibility relationsR(?)
Having defined T (mult(e)), we let R(e) be the re-
striction of proper containment A to D(e)
sR(e) s?
def
?? s A s? and s? ? D(e) .
As for ef and el, some preliminary notation is use-
ful. Given a language L, let us collect strings that
have at most one factor in L in nmf (L) (for non-
multiple f actor)
nmf (L)
def
= {s ? ?? | at most one factor of s
belongs to L}
and let us shorten ?1L to L
s ? L
def
?? (?s? ? L) s s? .
Now,
sR(ef ) s?
def
?? (?u, v) s = us?v
and uv 6= 
and s? ? D(e)
and us? ? nmf (D(e))
55
and similarly,
sR(el) s?
def
?? (?u, v) s = us?v
and uv 6= 
and s? ? D(e)
and s?v ? nmf (D(e)) .
Finally,
sR(?<) s?
def
?? (?s??, s???) s = s?s??s???
and sR(?) s??
sR(?>) s?
def
?? (?s??, s???) s = s???s??s?
and sR(?) s?? .
A routine induction on T PL+-formulas ? estab-
lishes that for I equal to the set I of all closed,
bounded real intervals,
Proposition 1. For all finite A ? I ? E and I ? I,
A |=I ? ?? str(A, I) ? TI,E(?+)
for every T PL+-formula ?.
3.4 T PL-equivalence and I revisited
When do two pairs A, I and A?, I ? of finite subsets
A,A? of I ? E and intervals I, I ? ? I satisfy the
same T PL-formulas? A sufficient condition sug-
gested by Proposition 1 is that str(A, I) is the same
as str(A?, I ?) up to renaming of intervals. More pre-
cisely, recalling that str(A, I) = s(AI)?, let us de-
fine A to be congruent with A?, A ?= A?, if there
is a bijection between the intervals of A and A? that
turns s(A) into s(A?)
A ?= A?
def
?? (?f : domain(A)? domain(A?))
f is a bijection, and
A? = {?f(I), e? | ?I, e? ? A}
and f [s(A)] = s(A?)
where for any string s ? Pow(domain(f)? E)?,
f [s]
def
= s after renaming each
I ? domain(f) to f(I) .
As a corollary to Proposition 1, we have
Proposition 2. For all finite subsets A and A? of
I ? E and all I, I ? ? I, if AI ?= A?I? then for every
T PL+-formula ?,
A |=I ? ?? A
? |=I? ? .
The significance of Proposition 2 is that it spells out
the role the real line R plays in T PL ? nothing
apart from its contribution to the strings s(A). In-
stead of picking out particular intervals over R, it
suffices to work with interval symbols, and to equate
the subscript I on our alphabet ? and truth rela-
tions T (?) to say, the set Z+ of positive integers
1, 2, . . .. But lest we confuse T PLwith Linear Tem-
poral Logic, note that the usual order on Z+ does not
shape the accessibility relations in T PL. We useZ+
here only because it is big enough to include any fi-
nite subset A of I ? E.
Turning to entailments, we can reduce entail-
ments
? |?I,E ?
? def?? (? finite A ? I ? E)(?I ? I)
A |=I ? implies A |=I ?
?
to satisfiability as usual
? |?I,E ?
? ?? TI,E(? ? ??
?) = ? .
The basis of the decidability/complexity results in
(Pratt-Hartmann, 2005) is a lemma (number 3 in
page 20) that, for any T PL+-formula ?, bounds
the size of a minimal model of ?. That is, as far
as the satisfiability of a T PL+-formula ? is con-
cerned, we can reduce the subscript I on T (?) to a
finite set ? or in the aforementioned reformulation,
to a finite segment {1, 2, . . . , n} of Z+. We shall
consider an even more drastic approach in the next
section. For now, notice that the shift from the real
line R towards strings conforms with
The Proposal of (Steedman, 2005)
the so-called temporal semantics of nat-
ural language is not primarily to do with
time at all. Instead, the formal devices we
need are those related to representation of
causality and goal-directed action. [p ix]
The idea is to move away from some absolute (in-
dependently given) notion of time (be they points or
intervals) to the changes and forces that make natu-
ral language temporal.
56
4 The regularity of T PL and beyond
Having reformulated T PL in terms of strings, we
proceed now to investigate the prospects for a finite-
state approach to temporal semantics building on
that reformulation. We start by bringing out the
finite-state character of the connectives in T PL be-
fore considering some extensions.
4.1 T PL+-connectives are regular
It is well-known that the family of regular languages
is closed under complementation and intersection ?
operations interpreting negation and conjunction, re-
spectively. The point of this subsection is to show
that all the T PL+-connectives map regular lan-
guages and regular relations to regular languages
and regular relations. A relation is regular if it is
computed by a finite-state transducer. If I and E are
both finite, then DI,E(e) is a regular language and
A is a regular relation. Writing RL for the relation
{(s, s?) ? R | s? ? L}, note that
R(e) = AD(e)
and that in general, if R and L are regular, then so is
RL.
Moving on, the set of strings with at least two fac-
tors belonging to L is
twice(L)
def
= ??(L?? ? (?+L??)) +
??(L?+ ? L)??
and the set of strings that have a proper factor be-
longing to L is
[L]
def
= ?+L?? + ??L?+ .
It follows that we can capture the set of strings that
properly contain at least two strings in L as
Mult(L)
def
= [twice(L)] .
Note that
T (mult(e)) = Mult(D(e))
and recallingR(ef ) andR(el) use nmf ,
nmf (L) = ?? ? twice(L) .
R(ef ) is minFirst(D(e)) where
s minFirst(L) s?
def
?? (?u, v) s = us?v
and uv 6= 
and s? ? L
and us? ? nmf (L)
andR(el) is minLast(D(e)) where
s minLast(L) s?
def
?? (?u, v) s = us?v
and uv 6= 
and s? ? L
and s?v ? nmf (L).
Finally,R(?<) is init(R(?)) where
s init(R) s?
def
?? (?s??, s???) s = s?s??s???
and s R s??
whileR(?>) is fin(R(?)) where
s fin(R) s?
def
?? (?s??, s???) s = s???s??s?
and s R s?? .
Proposition 3. If L is a regular language and R is a
regular relation, then
(i) Mult(L), R?1L, and nmf (L) are regular lan-
guages
(ii) RL, minFirst(L), minLast(L), init(R) and
fin(R) are regular relations.
4.2 Beyond sub-intervals
As is clear from the relations R(e), T PL makes
do with the sub-interval relation ? and a ?quasi-
guarded? fragment at that (Pratt-Hartmann, 2005,
page 5). To string out the interval temporal logic
HS (Halpern and Shoham, 1991), the key is to com-
bine A and I using some r 6? E to mark I (rather
than forming AI )
Ar[I]
def
= A ? {?I, r?}
and modify str(A, I) to define
strr(A, I)
def
= s(Ar[I])
? .
57
Let us agree that (i) a string ?1 ? ? ??n r-marks I if
?I, r? ?
?n
i=1 ?i, and that (ii) a string is r-marked
if there is a unique I that it r-marks. For every r-
marked string s, we define two strings: let s  r be
the factor of swith bgn-I in its first box and I-end in
its last, where s r-marks I; and let s?r be ??(sr).3
We can devise a finite-state transducer converting r-
marked strings s into s?r, which we can then apply
to evaluate an event-atom e as anHS-formula
s ? Tr(e)
def
?? (?s? ? D(e)) s?r  s
? .
It is also not difficult to build finite-state transducers
for the accessibility relations Rr(B),Rr(E), Rr(B),
and Rr(E), showing that, as in T PL, the connec-
tives inHS map regular languages and regular rela-
tions to regular languages and regular relations. The
question for both T PL andHS is can we start with
regular languages D(e)? As noted towards the end
of section 3, one way is to reduce the set I of inter-
vals to a finite set. We close with an alternative.
4.3 A modest proposal: splitting event-atoms
An alternative to D(e) =
?
I?ID(e, I) is to ask
what it is that makes an e-event an e-event, and en-
code that answer inD(e). In and of itself, an interval
[3,9] cannot make ?[3, 9], e? an e-event, because in
and of itself, ?[3, 9], e? is not an e-event. ?[3, 9], e? is
an e-event only in a model A such that A([3, 9], e).
Putting I aside, let us suppose, for instance, that
e were the event Pat swim a mile. We can repre-
sent the ?internal temporal contour? of e through a
parametrized temporal proposition f(r) with param-
eter r ranging over the reals in the unit interval [0, 1],
and f(r) saying Pat has swum r?(a mile). Let D(e)
be
f(0) f?
+
f(1)
where f? abbreviates the temporal proposition
(?r < 1) f(r) ? Previously ?f(r) .
3? is defined as in ?3.1, and ?X as in ?1.1 above. Were
we to weaken ? to ? in the definition of AI and the semantics
of T PL, then we would have (strr(A, I))?r = str(A, I), and
truth sets Tr(?) and accessibility relationsRr(?) such that
T (?) = {s?r | s ? Tr(?)}
R(?) = {?s?r, s
?
?r? | sRr(?) s
?}
for T PL+-formulas ? and extended labels ?.
Notice that the temporal propositions f(r) and f?
are to be interpreted over points (as in LTL); as il-
lustrated in Example B above, however, these points
can be split by adding boxables. Be that as it may, it
is straightforward to adjust our definition of a model
A and strr(A, I) to accommodate such changes to
D(e). Basing the truth sets T (?) on sets D(e) of e-
denotations independent of a model A (Fernando,
2011a) is in line with the proposal of (Steedman,
2005) mentioned at the end of ?3.4 above.
References
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the Associa-
tion for Computing Machinery 26(11): 832?843.
Kenneth R. Beesley and Lauri Karttunen. 2003. Finite
State Morphology. CSLI, Stanford, CA.
Michael Bennett and Barbara Partee. 1972. Toward the
logic of tense and aspect in English. Indiana Univer-
sity Linguistics Club, Bloomington, IN.
J.F.A.K. van Benthem. 1983. The Logic of Time. Reidel.
E. Allen Emerson. 1990. Temporal and modal logic. In
(J. van Leeuwen, ed.) Handbook of Theoretical Com-
puter Science, volume B. MIT Press, 995?1072.
Tim Fernando. 2004. A finite-state approach to events in
natural langue semantics. J. Logic & Comp 14:79?92.
Tim Fernando. 2011. Constructing situations and time.
J. Philosophical Logic 40(3):371?396.
Tim Fernando. 2011a. Regular relations for temporal
propositions. Natural Language Engineering 17(2):
163?184.
Joseph Y. Halpern and Yoav Shoham. 1991. A Proposi-
tional Modal Logic of Time Intervals. J. Association
for Computing Machinery 38(4): 935?962.
Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer, Dordrecht.
John E. McTaggart. 1908. The Unreality of Time. Mind
17:456?473.
Ian Pratt-Hartmann. 2005. Temporal prepositions and
their logic. Artificial Intelligence 166: 1?36.
Ian Pratt-Hartmann. 2005a. From TimeML to TPL?. In
(G. Katz et al, eds.) Annotating, Extracting and Rea-
soning about Time and Events, Schloss Dagstuhl.
James Pustejovsky, Jose? Castan?o, Robert Ingria, Roser
Saur??, Robert Gaizauskas, Andrea Setzer and Graham
Katz. 2003. TimeML: Robust Specification of Event
and Temporal Expressions in Text. In 5th International
Workshop on Computational Semantics. Tilburg.
Mark Steedman. 2005. The Productions of Time: Tem-
porality and Causality in Linguistic Semantics. Draft,
homepages.inf.ed.ac.uk/steedman/papers.html.
58
Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 80?89,
Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational Linguistics
A Finite-State Temporal Ontology and Event-intervals
Tim Fernando
Computer Science Department
Trinity College Dublin
Ireland
tfernand@tcd.ie
Abstract
A finite-state approach to temporal ontology
for natural language text is described under
which intervals (of the real line) paired with
event descriptions are encoded as strings. The
approach is applied to an interval temporal
logic linked to TimeML, a standard mark-up
language for time and events, for which vari-
ous finite-state mechanisms are proposed.
1 Introduction
A model-theoretic perspective on finite-state meth-
ods is provided by an important theorem due to
Bu?chi, Elgot and Trakhtenbrot (Thomas, 1997).
Given a finite alphabet ?, a system MSO? of
monadic second-order logic is set up with a binary
relation symbol (for successor) and a unary relation
symbol for each symbol in ? so that the formulae of
MSO? define precisely the regular languages over ?
(minus the null string ). Extensions of this theorem
to infinite strings and trees are fundamental to work
on formal verification associated with Model Check-
ing (Clarke et al, 1999). In that work, a well-defined
computational system (of hardware or software) can
be taken for granted, against which to evaluate pre-
cise specifications. The matter is far more delicate,
however, with natural language semantics. It is not
clear what models, if any, are appropriate for natural
language. Nor is it obvious what logical forms natu-
ral language statements translate to. That said, there
is a considerable body of work in linguistic seman-
tics that uses model theory, and no shortage of nat-
ural language text containing information that cries
out for extraction.
A step towards (semi-)automated reasoning about
temporal information is taken in TimeML (Puste-
jovsky et al, 2003), a ?mark-up language for tempo-
ral and event expressions? (www.timeml.org).
The primary aim of the present paper is to show how
finite-state methods can push this step further, by
building strings, regular languages and regular rela-
tions to represent some basic semantic ingredients
proposed for TimeML. An instructive example is
sentence (1), which is assigned in (Pratt-Hartmann,
2005a; ISO, 2007) the logical form (2).
(1) After his talk with Mary, John drove to Boston.
(2) p(e) ? q(e?) ? after(e, e?)
If we read p(e) as ?e is an event of John talking with
Mary? and q(e?) as ?e? is an event of John driving to
Boston? then (2) says ?an event e? of John driving to
Boston comes after an event e of John talking with
Mary .? Evidently, (1) follows from (3) and (4) be-
low (implicitly quantifying the variables e and e? in
(2) existentially).
(3) John talked with Mary from 1pm to 2pm.
(4) John drove to Boston from 2pm to 4pm.
But is (3) not compatible with (5) ? and indeed im-
plied by (5)?
(5) John talked with Mary from 1pm to 4pm.
Could we truthfully assert (1), given (4) and (5)? Or
if not (1), perhaps (6)?
(6) After talking with Mary for an hour, John drove
to Boston.
80
The acceptability of (6) suffers, however, if we are
told (7).
(7) John drove toward Boston from 1pm to 2pm.
Clearly, individuating events, as (2) does, opens
up a can of worms. But since at least (Davidson,
1967), there has been no retreating from events (Par-
sons, 1990; Kamp and Reyle, 1993; Pratt-Hartmann,
2005). Be that as it may, an appeal to events carries
with it an obligation to provide a minimal account
of what holds during these events and perhaps even
a bit beyond. It is for such an account that finite-
state methods are deployed below, viewed through
the lens of the Bu?chi-Elgot-Trakhtenbrot theorem.
That lens gives temporal logic, the formulae of
which ? hereafter called fluents (for brevity) ?
may or may not hold at a string position, conceived
as time and ordered according to succession within
the string. For example, we can introduce a flu-
ent p for ?John talked with Mary? and a fluent q
for ?John drove to Boston? to form the string p q
(of length 2) for ?after John talked with Mary, John
drove to Boston.? The idea is that a string ?1 ? ? ??n
of boxes ?i describes a sequence t1, . . . , tn of n
times, ti coming before ti+1, such that every fluent
in ?i holds at ti.1 To a first approximation, a box ?i
is a snapshot at time ti, making ?1 ? ? ??n a cartoon
or filmstrip. But just what is a time ti: a temporal
point or an interval?
For p q to apply to (3) and (4), it is natural
to regard ti as an interval, setting up an account
of the entailment from (5) to (3) in terms of the
so-called subinterval property of John-talking-with-
Mary (Bennett and Partee, 1972). John-driving-to-
Boston, by contrast, does not have this property, ne-
cessitating the change from to Boston in (4) to to-
ward Boston in (7). We can bring out this fact by
representing individual events as strings, refining,
for instance, our picture q of John?s drive to Boston
by adding a fluent r for ?John in Boston? to form
q q,r . An event of motion is conceptualized as a
finite sequence of snapshots in (Tenny, 1987) and
elsewhere ? a conceptualization resoundingly re-
jected in (Jackendoff, 1996) because
1The alphabet ? from which strings are formed is the family
Pow(X) of subsets of some set X of fluents. A fluent corre-
sponds to a monadic second-order variable in the Bu?chi-Elgot-
Trakhtenbrot theorem.
it misrepresents the essential continuity of
events of motion. For one thing, aside from
the beginning and end points, the choice of a
finite set of subevents is altogether arbitrary.
How many subevents are there, and how is one
to choose them? Notice that to stipulate the
subevents as equally spaced, for instance one
second or 3.5 milliseconds apart, is as arbi-
trary and unmotivated as any other choice.
Another difficulty with a snapshot conceptu-
alization concerns the representation of non-
bounded events (activities) such as John ran
along the river (for hours). A finite sequence
of subevents necessarily has a specified begin-
ning and ending, so it cannot encode the ab-
sence of endpoints. And excluding the speci-
fied endpoints simply exposes other specified
subevents, which thereby become new end-
points. Thus encoding nonbounded events re-
quires major surgery in the semantic represen-
tation. [page 316]
Jackendoff?s objections are overcome below by
finite-state manipulations that may well be called
surgery. Following details supplied in the next sec-
tion,2 strings are formed from a finite set X of flu-
ents that is allowed to vary so that
(i) the continuity desired by Jackendoff arises in
the inverse limit of a system of projections piX
(defined below; Table 1), and
(ii) the temporal span of any finite string may, on
expanding the set X , stretch without bound to
the left (past) and/or to the right (future).
Applying piX , section 2 proceeds to encode a model
A of an interval temporal logic as a string s(A).
Building on that encoding, section 3 develops finite-
state methods for interval temporal logic. Section
4 concludes with proposals (drawing on work of the
earlier sections) for extending the empirical (linguis-
tic) coverage.
2 From event-intervals to strings
Before equating the set X of fluents with a model
interpreting TimeML, let us bring out the intuition
2The present work extends a line of research most recently
reported in (Fernando, 2011, 2011a, 2011b, 2012). That line is
related to (Niemi and Koskenniemi, 2009), from which it dif-
fers in adopting an alphabet Pow(X) that equates sucession in
a string with temporal succession.
81
?X(?1 ? ? ??n) def= (?1 ?X) ? ? ? (?n ?X)
bc(s) def=
?
?
?
bc(?s?) if s = ??s?
?bc(??s?) if s = ???s? and ? 6= ??
s otherwise
unpad(s) def=
{ unpad(s?) if s = s? or s?
s otherwise
Table 1: Behind piX(s) def= unpad(bc(?X(s)))
underlying the function piX through a familiar exam-
ple. We can represent a calendar year by the string
smo def= Jan Feb ? ? ? Dec
of length 12 (with a month in each box), or (adding
one of 31 days d1, d2,. . ., d31) the string
smo,dy def= Jan,d1 Jan,d2 ? ? ?
Jan,d31 Feb,d1 ? ? ? Dec,d31
of length 365 (a box per day in a non-leap year).3
Unlike the points in say, the real line R, a box can
split if we enlarge the set X of fluents we can put in
it, as illustrated by the change from Jan in smo to
Jan,d1 Jan,d2 ? ? ? Jan,d31 in smo,dy. Two func-
tions link the strings smo,dy and smo
(i) a function ?mo that keeps only the months in a
box so that
?mo(smo,dy) = Jan 31 Feb 28 ? ? ? Dec 31
(ii) block compression bc, which compresses con-
secutive occurrences of a box into one, map-
ping ?mo(smo,dy) to
bc( Jan 31 Feb 28 ? ? ? Dec 31) = smo
so that bc(?mo(smo,dy)) = smo. As made precise
in Table 1, ?X ?sees only X? (setting modef= {Jan,
3In (Niemi and Koskenniemi, 2009), smo is represented as
the string
[m Jan ]m [m Feb ]m [m Mar ]m ... [m Dec ]m
of length 36 over 14 symbols (the 12 months plus the 2 brackets
[m and ]m) on which finite-state transducers operate. (See the
previous footnote.)
R ?Allen sR ? Lpi({x, x?}) ?R([a, b], [a?, b?])
x = x? x, x? a = a?, b = b?
x s x? x, x? x? a = a?, b < b?
x si x? x, x? x a = a?, b? < b
x f x? x? x, x? a? < a, b = b?
x fi x? x x, x? a < a?, b = b?
x d x? x? x, x? x? a? < a, b < b?
x di x? x x, x? x a < a?, b? < b
x o x? x x, x? x? a < a? ? b < b?
x oi x? x? x, x? x a? < a ? b? < b
x m x? x x? --
x < x? x x? b < a?
x mi x? x? x --
x > x? x? x b? < a
Table 2: The Allen relations via pi{x,x?}
Feb, . . .Dec} to make ?mo an instance of ?X ), while
bc eliminates stutters, hardwiring the view that time
passes only if there is change (or rather: we observe
time passing only if we observe a change within a
box). As this example shows, temporal granularity
depends on the set X of observables that may go
inside a box. Writing bcX for the composition map-
ping s to bc(?X(s)), we have
bc{Jan}(smo,dy) = bc{Jan}(smo) = Jan
bc{Feb}(smo,dy) = bc{Feb}(smo) = Feb
bc{d3}(smo,dy) = ( d3 )12 .
Now, the function piX is bcX followed by the deletion
unpad of any initial or final empty boxes (Table
1).4 We can then define a fluent x to be an s-interval
if pi{x}(s) is x . Next, let Lpi(X) be the language
piX [
?
x?X pi?1{x} x ] consisting of strings piX(s) for
s ? Pow(X)? such that pi{x}(s) = x for all x ? X .
Note that Lpi({x}) = { x } while for x 6= x?,
Lpi({x, x?}) consists of 13 strings sR, one per inter-
val relation R in (Allen, 1983); see columns 1 and 2
of Table 2
Lpi({x, x?}) = {sR | R ? Allen} .
4Restricted to a finite alphabet, the maps ?X , bc, unpad
and piX are computable by finite-state transducers (Fernando,
2011).
82
For example, in the case of the ?f inish? relation
f?Allen,
s |= x fx? ?? pi{x,x?}(s) = x? x, x?
provided x and x? are s-intervals. The third column
of Table 2 characterizes R ?Allen as conditions ?R
on pairs [a, b] and [a?, b?] of real numbers (in R) de-
noting closed intervals5 ? e.g.,
[a, b] f [a?, b?] ?? a? < a and b = b? .
This brings us to the semantics of TimeML pro-
posed in (Pratt-Hartmann, 2005a). A system T PL
of Temporal Preposition Logic is built from an infi-
nite set E of event-atoms, and interpreted relative to
the family
I def= {[a, b] | a, b ? R and a ? b}
of closed, bounded non-empty intervals in R. A
T PL-model A is defined to be a finite subset of
I ? E. The intuition is that a pair ?I, e? in A repre-
sents ?an occurrence of an event of type e over the
interval? I (Pratt-Hartmann, 2005; page 17), revers-
ing the construal in line (2) above of e as a token.
Identifying occurrences with events, we can think of
A as a finite set of events, conceived as ?intervals
cum description? (van Benthem, 1983; page 113).
Treating events as fluents, we have
Proposition 1. For every T PL-model A, there is a
unique string s(A) ? Lpi(A) such that for all x, x? ?
A with x = ?I, e? and x? = ?I ?, e??,
pi{x,x?}(s(A)) = sR ?? ?R(I, I ?)
for R ?Allen and sR, ?R specified in Table 2.
To construct the string s(A), let Ends(A) be the set
of endpoints of A
Ends(A) def=
?
I?dom(A)
ends(I)
where dom(A) is the domain {I | (?e ? E) ?I, e? ?
A} of A, and ends([a, b]) is the unordered pair
5Over non-empty closed intervals that include points [a, a],
the Allen relations m and mi collapse to o and oi, respectively.
Alternatively, we can realize m and mi by trading closed in-
tervals for open intervals (required to be non-empty); see the
Appendix below.
x1 def= ?[1, 5], e? r1 = 1, r2 = 4
x2 def= ?[4, 9], e? r3 = 5, r4 = 9
x3 def= ?[9, 50], e?? r5 = 50
A def= {x1, x2, x3}
Table 3: Example s(A) = x1 x1, x2 x2 x2, x3 x3
{a, b}. Sorting gives Ends(A) = {r1, r2, . . . , rn}
with r1 < r2 < ? ? ? < rn. Breaking [r1, rn] up into
2n? 1 intervals, let
?i def= {?I, e? ? A | ri ? I} for 1 ? i ? n
and
?i def= {?I, e? ? A | [ri, ri+1] ? I} for 1 ? i < n.
Interleaving and block-compressing give
s(A) def= bc(?1?1 ? ? ??n?1?n?1?n)
(see Table 3 for an example). One may then verify
(by induction on the cardinality of the domain of A)
that s(A) is the unique string in Lpi(A) satisfying
the equivalence in Proposition 1.
But is encoding A as a string s(A) adequate for
T PL-satisfaction? Let us introduce T PL-formulae
through an English example.
(8) During each of John?s drives to Boston, he ate
a donut.
(8) translates in T PL to (9), which is interpreted
relative to a T PL-model A and an interval I ? I
according to (10) and (11), with [e]? abbreviating
??e??? (as usual), > a tautology (in that A |=I >
always) and ? as strict (irreflexive) subset.
(9) [John-drive-to-Boston] ?John-eat-a-donut?>
(10) A |=I ?e?? def?? (?J ? I s.t. A(J, e))
A |=J ?
(11) A |=I ?? def?? not A |=I ?
Clause (10) shows off a crucial feature of T PL:
quantification over intervals is bounded by the do-
main of A; that is, quantification is restricted to in-
tervals that are paired up with an event-atom by the
83
T PL-model (making T PL ?quasi-guarded?; Pratt-
Hartmann, 2005; page 5). This is not to say that the
only intervals I that may appear in formingA |=I ?
are those in the domain of A. Indeed, for [a, b] ? I
and [a?, b?] ? dom(A) such that [a?, b?] ? [a, b],
T PL uses intervals
init([a?, b?], [a, b]) def= [a, a?]
fin([a?, b?], [a, b]) def= [b?, b]
to interpret {e}<? and {e}>? according to (12).
(12) A |=I {e}<? def?? (?!J ? I s.t. A(J, e))
A |=init(J,I) ?
A |=I {e}>? def?? (?!J ? I s.t. A(J, e))
A |=fin(J,I) ?
The bang ! in ?!J in (12) expresses uniqueness,
which means that under the translation of (1) as (13)
below, the interval I of evaluation is required to con-
tain a unique event of John talking with Mary.
(1) After his talk with Mary? ?? ? John drove to Boston? ?? ?.
p q
(13) {p}>?q?>
For a translation of (1) more faithful to
(2) p(e) ? q(e?) ? after(e, e?)
than (13),6 it suffices to drop ! in (12) for ?e?< and
?e?> in place of {e}< and {e}> respectively (Fer-
nando, 2011a), and to revise (13) to ?p?>?q?>. Re-
laxing uniqueness, we can form [p]>?q?> for after
every talk with Mary, John drove to Boston, as well
as ?p?>?p?> for after a talk with Mary, John talked
with Mary again. T PL has further constructs ef
and el for the (minimal) first and (minimal) last e-
events in an interval.
Returning to the suitability of s(A) for T PL, con-
sider the question: when do two pairsA, I andA?, I ?
of T PL-models A,A? and intervals I, I ? ? I sat-
isfy the same T PL-formulae? Some definitions are
in order. A bijection f : A ? B between finite sets
6Caution: e and e? are tokens in (2), but types in T PL.
A and B of real numbers is order-preserving if for
all a, a? ? A,
a < a? ?? f(a) < f(a?)
in which case we write f : A ?= B. Given a T PL-
model A, and a function f : Ends(A) ? R, let Af
be A with all its intervals renamed by f
Af def= {?[f(a), f(b)], e? | ?[a, b], e? ? A} .
Now, we say A is congruent with A? and write A ?=
A? if there is an order-preserving bijection between
Ends(A) and Ends(A?) that renames A to A?
A ?= A? def?? (?f : Ends(A) ?= Ends(A?))
A? = Af .
Finally, we bring I into the picture by defining the
restriction AI of A to I to be the subset
AI def= {?J, e? ? A | J ? I}
of A with intervals strictly contained in I .
Proposition 2. For all finite subsets A and A? of
I ? E and all intervals I, I ? ? I, if AI ?= A?I? then
for every T PL-formula ?,
A |=I ? ?? A? |=I? ? .
Proposition 2 suggests normalizing a T PLmodelA
with endpoints r1 < r2 < ? ? ? < rn to nr(A) with ri
renamed to i
nr(A) def= Af where f def= {?r1, 1?, . . . , ?rn, n?}.
Assigning every T PL-formula ? the truth set
T (?) def= {s(nr(AI)) | A is a T PL-model,
I ? I and A |=I ?}
gives
Proposition 3. For every T PL-formula ?, T PL-
model A, and interval I ? I,
A |=I ? ?? s(nr(AI)) ? T (?) .
To bolster the claim that T (?) encodes T PL-
satisfaction, we may construct T (?) by induction
on ?, mimicking the clauses for T PL-satisfaction,
as in (14).
(14) T (? ? ??) = T (?) ? T (??)
Details are provided in the next section, where we
consider the finite-state character of the clauses, and
may verify Propositions 2 and 3.
84
3 Regularity and relations behind truth
A consequence of Proposition 3 is that the entail-
ment from ? to ?? given by
? |?I,E ?? def?? (? finite A ? I ? E)(?I ? I)
A |=I ? implies A |=I ??
becomes equivalent to the inclusion T (?) ? T (??),
or to the unsatisfiability of ? ? ???
? |?I,E ?? ?? T (? ? ???) = ?
assuming classical interpretations (14) and (15) of
conjunction ? and negation ?.
(15) T (??) = ?+ ? T (?)
Finite-state methods are of interest as regular lan-
guages are closed under intersection and comple-
mentation. (Context-free languages are not; nor is
containment between context-free languages decid-
able.) The alphabet ? in (15) is, however, infinite;
? is the set Fin(J ? E) of finite subsets of J ? E,
where J is the set
J def= {[n,m] ? I | n,m ? Z+}
of intervals in I with endpoints in the set Z+ of
positive integers 1, 2, . . . (containing the domain of
a normalized T PL-model). As with piX , regular-
ity demands restricting ? to a finite subalphabet ?
or better: subalphabets given by the set F of pairs
?I ?, E?? of finite subsets I ? and E? of J and E re-
spectively, for which
? =
?
?I?,E???F
Pow(I ? ? E?) .
The basis of the decidability/complexity results in
(Pratt-Hartmann, 2005) is a lemma (number 3 in
page 20) that, for any T PL-formula ?, bounds the
size of a minimal model of ?. We get a computable
function mapping a T PL-formula ? to a finite sub-
set I? of J just big enough so that if ? is T PL-
satisfiable,
(?A ? Pow(I? ? E?))(?I ? I?) A |=I ?
whereE? is the finite subset ofE occurring in ?. To
minimize notational clutter, we leave out the choice
?I ?, E?? ? F of a finite alphabet below.
Next, keeping intersection and complementation
in (14) and (15) in mind, let us call an opera-
tion regularity-preserving (rp) if its output is regu-
lar whenever all its inputs are regular. To interpret
T PL, we construe operations broadly to allow their
inputs and output to range over relations between
strings (and not just languages), construing a rela-
tion to be regular if it is computable by a finite-state
transducer. For instance, the modal diamond ?e? la-
belled by an event-atom e ? E is interpreted via an
accessibility relation R(e) in the usual Kripke se-
mantics
T (?e??) = R(e)?1T (?)
of ?e?? where R?1L is the set {s ? ?? | (?s? ?
L) sRs?} of strings related by R to a string in L.
The operation that outputs R?1L on inputs R and L
is rp. But what is the accessibility relationR(e)?
Three ingredients go into makingR(e):
(i) a notion of strict containment A between
strings
(ii) the demarcation s? of a string s
(iii) a set D(e) of strings representing full occur-
rences of e.
We take up each in turn, starting withA, which com-
bines two ways a string can be part of another. To
capture strict inclusion ? between intervals, we say
a string s? is a proper factor of a string s, and write
s pfac s?, if s? is s with some prefix u and suffix v
deleted, and uv is non-empty
s pfac s? ?? (?u, v) s = us?v and uv 6= .
(Dropping the requirement uv 6=  gives factors
simpliciter.) The second way a string s? may be part
of s applies specifically to strings of sets. We say s
subsumes s?, and write s s?, if they are of the same
length, and ? holds componentwise between them
?1 ? ? ??n  ??1 ? ? ???m
def?? n = m and
??i ? ?i for 1 ? i ? n.
Now, writing R;R? for the relational composition of
binary relations R and R? in which the output of R
is fed as input to R?
s R;R? s? def?? (?s??) sRs?? and s??R?s? ,
85
we compose pfac with  for strict containment A
A def= pfac ;  (=  ; pfac) .
(It is well-known that relational composition ; is
rp.) Next, the idea behind demarcating a string s
is to mark the beginning and ending of every in-
terval I mentioned in s, with fresh fluents bgn-I
and I-end. The demarcation (?1?2 ? ? ??n)? of
?1?2 ? ? ??n adds bgn-I to ?i precisely if
there is some e such that ?I, e? ? ?i and either
i = 1 or ?I, e? 6? ?i?1
and adds I-end to ?i precisely if
there is some e such that ?I, e? ? ?i and either
i = n or ?I, e? 6? ?i+1.7
For s = s(A) given by the example in Table 3,
s? = x1, bgn-I1 x1, x2, I1-end, bgn-I2
x2 x2, x3, I2-end, bgn-I3 x3, I3-end
We then form the denotation DI?(e) of e relative to
a finite subset I ? of I by demarcating every string in?
I?I? ?I, e?
+ as in (16).
(16) DI?(e) def= ?I?I?{s? | s ? ?I, e?
+}
To simplify notation, we suppress the subscript I ?
on DI?(e). Restricting strict containment A to D(e)
gives
sR?(e) s? def?? s A s? and s? ? D(e)
from which we defineR(e), making adjustments for
demarcation
sR(e) s? def?? s? R?(e) s??.
That is, R(e) is the composition ??;R?(e); ?? where
demarcation ?? is inverted by ??. As T PL?s other
constructs are shown in ?4.1 of (Fernando, 2011a)
to be interpretable by rp operations, we have
7The markers bgn-I and I-end are analogous to the brackets
[g and ]g in (Niemi and Koskenniemi, 2009), an essential differ-
ence being that a grain (type) g supports multiple occurrences
of [g and ]g, in contrast to the (token) interval I .
Proposition 4. All T PL-connectives can be inter-
preted by rp operations.
Beyond T PL, the interval temporal logic HS of
(Halpern and Shoham, 1991) suggests variants of
?e?? with strict containment A in R(e) replaced by
any of Allen?s 13 interval relations R.
(17) A |=I ?e?R? def?? (?J s.t. I R J)
A(J, e) and A |=J ?
To emulate (17), we need to mark the evaluation in-
terval I in A by some r 6? E, setting
Ar[I] def= A ? {?I, r?}
rather than simply forming AI (which will do if we
can always assume the model?s full temporal extent
is marked). A string s = ?1 ? ? ??n r-marks I if
?I, r? ? ?ni=1 ?i. If that interval is unique, we say
s is r-marked, and write I(s) for the interval it r-
marks, and s? for s with the fluent ?I(s), r? deleted
(so that s(Ar[I])? = s(A)). For any of the rela-
tions R ?Allen, we let ?R hold between r-marked
strings that are identical except possibly for the in-
tervals they r-mark, which are related by R
s ?R s? def?? s? = s?? and I(s) R I(s?).
Next, given an event-atom e, we let R(e)R be a bi-
nary relation that holds between r-marked strings re-
lated by ?R, the latter of which picks out a factor
subsuming some string in D(e)
sR(e)R s? def?? s ?R s? and
(?d ? D(e)) s?r  d
where s?r is the factor of s? that begins with bgn-I(s?)
and ends with I(s?)-end. Replacing AI by Ar[I] in
T (?) for
Tr(?) def= {s(nr(Ar[I])) | A is a T PL-model,
I ? I and A |=I ?} ,
(17) corresponds to
Tr(?e?R?) = R(e)?1R Tr(?).
86
4 Conclusion and future work
The key notion behind the analysis above of time in
terms of strings is the map piX , which for X consist-
ing of interval-event pairs ?I, e?, is applied in Propo-
sition 1 to turn a T PL-model A into a string s(A).
As far as T PL-satisfaction A |=I ? is concerned,
we can normalize the endpoints of the intervals to an
initial segment of the positive integers, after restrict-
ing A to intervals contained in the evaluation inter-
val I (Proposition 3). For a finite-state encoding of
T PL-satisfaction, it is useful to demarcate the oth-
erwise homogeneous picture ?I, e? + of ?I, e?, and
to define a notion A of proper containment between
strings. We close with further finite-state enhance-
ments.
Demarcation is linguistically significant, bearing
directly on telicity and the so-called Aristotle-Ryle-
Kenny-Vendler classification (Dowty, 1979), illus-
trated by the contrasts in (18) and (19).
(18) John was driving |? John drove
John was driving to L.A. 6|? John drove to L.A.
(19) John drove for an hour
John drove to L.A. in an hour
The difference at work in (18) and (19) is that John
driving to L.A. has a termination condition, in(John,
L.A.), missing from John driving. Given a fluent
such as in(John, L.A.), we call a language L ?-telic
if for every s ? L, there is an n ? 0 such that
s  ?? n ? (which is to say: a string in L ends
as soon as ? becomes true). L is telic if it is ?-telic,
for some ?. Now, the contrasts in (18) and (19) can
be put down formally to the language for John driv-
ing to L.A. being telic, but not that for John driving
(Fernando, 2008).
The demarcation (via ?) just described does not
rely on some set I ? of intervals I from which flu-
ents bgn-I and I-end are formed (as in s? from sec-
tion 3). There are at least two reasons for attempt-
ing to avoid I ? when demarcating or, for that matter,
building the set D(e) of denotations of e. The first
is that under a definition such as (16), the number
of e-events (i.e., events of type e) is bounded by the
cardinality of I ?.
(16) DI?(e) def= ?I?I?{s? | s ? ?I, e?
+}
The second is that an interval arguably has little to
do with an e-event being an e-event. An interval
[4,9] does not, in and of itself, make ?[4, 9], e? an e-
event; ?[4, 9], e? is an e-event only in a T PL-model
that says it is. An alternative is to express in strings
what holds during an event that makes it an e-event.
Consider the event type e of Pat walking a mile. In-
cremental change in an event of that type can be rep-
resented through a parametrized fluent f(r) with pa-
rameter r ranging over the reals in the unit interval
[0, 1], such that f(r) says Pat has walked r?(a mile).
Let D(e) be
f(0) f?
+
f(1)
where f? abbreviates the fluent
(?r < 1) f(r) ? Previous(?f(r)).
Previous is a temporal operator that constrains
strings ?1 ? ? ??n so that whenever Previous(?) be-
longs to ?i+1, ? belongs to ?i; that is,
Previous(?) ? ?
using an rp binary operator ? on languages that
combines subsumption  with constraints famil-
iar from finite-state morphology (Beesley and Kart-
tunen, 2003).
The borders and interior of ?I, e? aside, there is
the matter of locating an e-string in a larger string
(effected in T PL through strict inclusion ?, the
string-analog of which is proper containment A).
But what larger string? The influential theory of
tense and aspect in (Reichenbach, 1947) places e rel-
ative not only to the speech S but also to a reference
time r, differentiating, for instance, the simple past
e, r S from the present perfect e S,r , as required
by differences in defeasible entailments |?, (20), and
acceptability, (21).
(20) Pat has left Paris |? Pat is not in Paris
Pat left Paris 6|? Pat is not in Paris
(21) Pat left Paris. (?Pat has left Paris.)
But Pat is back in Paris.
The placement of r provides a bound on the iner-
tia applying to the postcondition of Pat?s departure
87
(Fernando, 2008). The extension Ar[I] proposed in
section 3 to the combinationAI (adequate for T PL,
but not HS) explicitly r-marks the evaluation inter-
val I , facilitating an account more intricate than sim-
ply A of e?s occurrence in the larger string. T PL
goes no further than Ramsey in analyzing That Cae-
sar died as an ontological claim that an event of cer-
tain sort exists (Parsons, 1990), leading to the view
of an event as a truthmaker (Davidson, 1967; Mulli-
gan et al, 1984). The idea of an event (in isolation)
as some sort of proof runs into serious difficulties,
however, as soon as tense and aspect are brought
into the picture; complications such as the Imperfec-
tive Paradox (Dowty, 1979), illustrated in (22), raise
tricky questions about what it means for an event to
exist and how to ground it in the world (speaking
loosely) in which the utterance is made.
(22) John was drawing a circle when he ran out of
ink.
But while the burden of proof may be too heavy to
be borne by a single pair ?I, e? of interval I and
event-atom e, the larger picture in which the pair is
embedded can be strung out, and a temporal state-
ment ? interpreted as a binary relation R? between
such strings that goes well beyond A. The inputs to
R? serve as indices, with those in the domain ofR?
supporting the truth of ?
? is true at s def?? (?s?) sR? s?
(Fernando, 2011, 2012). In witnessing truth at par-
ticular inputs, the outputs of R? constitute denota-
tions more informative than truth values, from which
indices can be built bottom-up, in harmony with a
semantic analysis of text from its parts (to which
presumably TimeML is committed). An obvious
question is how far finite-state methods will take us.
Based on the evidence at hand, we have much fur-
ther to go.
Acknowledgments
My thanks to Daniel Isemann for useful, sustained
discussions. The work is supported by EI Grant #
CC-2011-2601B:GRCTC.
References
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the Associa-
tion for Computing Machinery 26(11): 832?843.
James F. Allen and George Ferguson. Actions and events
in interval temporal logic. J. Logic and Computation,
4(5):531?579, 1994.
Kenneth R. Beesley and Lauri Karttunen. 2003. Finite
State Morphology. CSLI, Stanford, CA.
Michael Bennett and Barbara Partee. 1972. Toward the
logic of tense and aspect in English. Indiana University
Linguistics Club, Bloomington, IN.
J.F.A.K. van Benthem. 1983. The Logic of Time. Reidel.
Edmund M. Clarke, Jr., Orna Grumberg and Doron A.
Peled. 1999. Model Checking. MIT Press.
Donald Davidson. 1967. The logical form of action sen-
tences. In The Logic of Decision and Action, pages 81?
95. University of Pittsburgh Press.
David Dowty. 1979. Word Meaning and Montague Gram-
mar. Kluwer.
Tim Fernando. 2008. Branching from inertia worlds. J.
Semantics 25:321?344.
Tim Fernando. 2011. Regular relations for temporal
propositions. Natural Language Engineering 17(2):
163?184.
Tim Fernando. 2011a. Strings over intervals. TextInfer
2011 Workshop on Textual Entailment, pages 50-58,
Edinburgh (ACL Archives).
Tim Fernando. 2011b. Finite-state representations em-
bodying temporal relations. In 9th International Work-
shop FSMNLP 2011, Blois, pages 12?20. A revised,
extended version is in the author?s webpage.
Tim Fernando. 2012. Steedman?s temporality proposal
and finite automata. In Amsterdam Colloquium 2011,
Sprnger LNCS 7218, pages 301-310.
Joseph Y. Halpern and Yoav Shoham. 1991. A Proposi-
tional Modal Logic of Time Intervals. J. Association
for Computing Machinery 38(4): 935?962.
ISO. 2007. ISO Draft International Standard 24617-1 Se-
mantic annotation framework ? Part 1: Time and
events. ISO (Geneva).
Ray Jackendoff. 1996. The proper treatment of mea-
suring out, telicity, and perhaps even quantification
in English. Natural Language and Linguistic Theory
14:305?354.
Hans Kamp and Uwe Reyle. 1993. From Disocurse to
Logic. Kluwer.
Kevin Mulligan, Peter Simons and Barry Smith. 1984.
Truth-makers. Philosophy and Phenomenological Re-
search 44: 287?321.
Jyrki Niemi and Kimmo Koskenniemi. 2009. Repre-
senting and combining calendar information by using
88
finite-state transducers. In 7th International Workshop
FSMNLP 2008, pages 122?33. Amsterdam.
Terry Parsons. 1990. Events in the Semantics of English.
MIT Press.
Ian Pratt-Hartmann. 2005. Temporal prepositions and
their logic. Artificial Intelligence 166: 1?36.
Ian Pratt-Hartmann. 2005a. From TimeML to TPL?. In
Annotating, Extracting and Reasoning about Time and
Events, Schloss Dagstuhl.
James Pustejovsky, Jose? Castan?o, Robert Ingria, Roser
Saur??, Robert Gaizauskas, Andrea Setzer and Graham
Katz. 2003. TimeML: Robust Specification of Event
and Temporal Expressions in Text. In 5th International
Workshop on Computational Semantics, pages 337-
353. Tilburg.
Hans Reichenbach. 1947. Elements of Symbolic Logic.
Macmillan & Co (New York).
Carol Tenny. 1987. Grammaticalizing Aspect and Affect-
edness. PhD dissertation, Department of Linguistics
and Philosophy, MIT.
Wolfgang Thomas. 1997. Languages, automata and logic.
In Handbook of Formal Languages: Beyond Words,
Volume 3, pages 389?455. Springer-Verlag.
Appendix: a case of ?less is more??
Because the set I of intervals from which a T PL-
model A is constructed includes singleton sets
[a, a] = {a} (for all real numbers a), there can never
be events x and x? in A such that x meets (or abuts)
x?, x m x?, according to Table 2 above. It is, how-
ever, easy enough to throw out sets [a, a] from I,
requiring that for [a, b] ? I, a be strictly less than
b. (In doing so, we follow (Allen, 1983) and (Pratt-
Hartmann, 2005a), but stray from (Pratt-Hartmann,
2005).) The result is that the overlap at b between
[a, b] and [b, c] is deeemed un-observable (effec-
tively re-interpreting closed intervals by their interi-
ors, understood to be non-empty). The third column
?R([a, b], [a?, b?]) in Table 2 is modified to a condi-
tion [a, b]R? [a?, b?] that differs on the cases whereR
is one of the four Allen relations o,m,oi,mi, split-
ting the disjunction a? ? b in o with m, and a ? b?
in oi with mi.
R ?Allen sR ? Lpi({e1, e2}) [a, b] R? [a?, b?]
x o x? x x, x? x? a < a? < b < b?
x m x? x x? b = a?
x oi x? x? x, x? x a? < a < b? < b
x mi x? x? x b? = a
All other rows in Table 2 are the same for
[a, b] R? [a?, b?]. The somewhat wasteful encoding
s(A) in Proposition 1 then becomes s?(A) in
Proposition 1?. For every T PL-model A such that
a < b for all [a, b] ? dom(A), there is a unique
string s?(A) ? Lpi(A) such that for all x, x? ? A
with x = ?I, e? and x? = ?I ?, e??, and R ?Allen
pi{x,x?}(s?(A)) = sR ?? I R?I ?.
The encoding s?(A) is formed exactly as s(A) is in
section 2 above from the endpoints r1 < r2 < ? ? ? <
rn of dom(A), except that the ?i?s for the endpoints
ri are dropped (these being un-observable), leaving
us with the ?i?s for [ri, ri+1]
s?(A) def= bc(?1 ? ? ??n?1).
Beyond Proposition 1, the arguments above for
s(A) carry over to s?(A), with the requirement on
a T PL-model A that a < b for all [a, b] ? dom(A).
It is noteworthy that (Pratt-Hartmann, 2005a) makes
no mention that this requirement is a departure from
(Pratt-Hartmann, 2005). Although the restriction
a < b rules out T PL-models with points [a, a] in
their domain, it also opens T PL up to strings in
which events meet ? a trade-off accepted in (Allen
and Ferguson, 1994). To properly accommodate
points alongside larger intervals, we can introduce
a fluent indiv marking out boxes corresponding to
points [a, a] (as opposed to divisible intervals [a, b]
where a < b), and re-define piX to leave boxes with
indiv in them alone. From this perspective, the re-
striction a < b is quite compatible with piX as de-
fined above. But can we justify the notational over-
head in introducing indiv and complicating piX? We
say no more here.
89
Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 30?40,
Sofia, Bulgaria, August 9, 2013. c?2013 Association for Computational Linguistics
Segmenting Temporal Intervals for Tense and Aspect
Tim Fernando
Trinity College Dublin, Ireland
Tim.Fernando@tcd.ie
Abstract
Timelines interpreting interval temporal
logic formulas are segmented into strings
which serve as semantic representations
for tense and aspect. The strings have
bounded but refinable granularity, suit-
able for analyzing (im)perfectivity, dura-
tivity, telicity, and various relations includ-
ing branching.
1 Introduction
A sentence in the simple past, such as (1a), ut-
tered at (speech) time S can be pictured as a time-
line (1b), describing an event E (Ernest explain-
ing) prior to S.
(1) a. Ernest explained.
b. E S (depicting E ? S)
We can view the event E in (1b) as an unbroken
point, wholly to the left of S, E? S. By contrast, in
the timeline (2a) for the progressive (2b), E splits
into three boxes, the middle of which contains also
a reference time R (Reichenbach, 1947).1
(2) a. E E,R E (depicting R @ E)
b. Ernest explaining
The relation of R inside E, R @ E, breaks E
apart, moving us away from conceptualizing E as
a point. Indeed, it has become common practice
in linguistic semantics since (Bennett and Partee,
1972) to evaluate temporal formulas at intervals,
rather than simply points. Interval temporal logics
are, however, notoriously more complex than or-
dinary (pointwise) temporal logics (Halpern and
Shoham, 1991; Marcinkowski and Michaliszyn,
1Boxes are drawn instead of the usual curly braces {, }
around the elements of a set to reinforce a reading of (1b) and
(2a) as comic strips, with time standing still within a box, but
between boxes, progressing from left to right.
2013). That said, for linguistic applications to
tense and aspect, the present paper derives strings
such as (1b) and (2a) from timelines for interval
temporal logic, in effect reducing these timelines
to finite models of ordinary temporal logic. This
reduction rests on certain assumptions that require
explanation and defense.
We begin with temporal formulas, which for the
sake of brevity, we hereafter call fluents. A fluent
such as E, R or S can occur as a whole, as E and
S do in (1b), or as segmented, as E does in (2a).
We formulate the notions of whole and segmented
model-theoretically in section 2, defining a map
? 7? ?? on fluents ? through which the picture
(2a) is sharpened to (3) with E? segmented.
(3) E? E?,R E? (segmented E?, whole R)
The map ? 7? ?? is essentially a universal grinder
(the right half of an adjoint pair with a universal
packager, max)
whole
segmented
?
count
mass
pointing to well-known ?parallels between the
mass-count distinction in nominal systems and
the aspectual classification of verbal expressions?
(Bach, 1986a). The aspectual classification to
which the whole/segmented contrast pertains is
that of perfectives and imperfectives
whole
segmented
?
perfective
imperfective
as opposed to Aktionsart. A variant of the
Aristotle-Ryle-Kenny-Vendler aspectual classes
(Dowty, 1979) which can be reduced to durativ-
ity and telicity (Comrie, 1976; Moens and Steed-
man, 1988; Pulman, 1997) is analyzed in section
3 through strings that arise naturally in the investi-
gation of grinding in section 2.
Some restraint on grinding is called for, as the
simplest strings are the most coarse-grained. Sec-
tion 4 enshrines this restraint as a principle, whilst
30
accommodating refinements as required. The idea
is that strings can be refined by enlarging some
contextually supplied set X of (interesting) flu-
ents: the larger X is, the finer the grain becomes.
An inverse system of string functions piX indexed
by different finite sets X of fluents is constructed,
and applied for an account of relations between
strings as well as branching time. The relations
here go beyond the familiar order ? for tense,
stretching to the progressive and the perfect, from
a variety of perspectives.
2 Segmented versus whole fluents
Fix a set ? of fluents. Fluents in ? are interpreted
relative to a ?-timeline, a triple A = ?T,?, |=?
consisting of a linear order ? on a non-empty set
T of (temporal) points, and a binary relation |=
between intervals I (over ?) and fluents ? ? ?.
An interval is understood here to be a nonempty
subset I of T with no holes ? i.e. t ? I whenever
t1 ? t ? t2 for some pair of points t1, t2 in I .2
I |= ? is pronounced ?? holds at I? or ?I satisfies
?? (in A).
A fluent ? is said to be A-segmented if for all
intervals I and I ? such that I ? I ? is an interval,
? holds at I and at I ? precisely if it does at their
union
I |= ? and I ? |= ? ?? I ? I ? |= ?.
A simple way for a fluent ? to be A-segmented is
by holding at an interval I precisely if it holds at
all points of I
I |= ? ?? (?t ? I) {t} |= ?
in which case we say ? is A-pointed.3 A fluent is
A-singular if at most one interval satisfies it. Gen-
eralizing A-singular fluents, we call a fluent ? A-
whole if for all intervals I and I ? such that I ? I ?
is an interval,
I |= ? and I ? |= ? implies I = I ?.
That is, any number of intervals may satisfy a A-
whole fluent so long as no two form an interval.
A A-whole fluent ? defines a quantized predicate
(Krifka, 1998) insofar as no two distinct intervals
can satisfy ? if one is a subset of the other. But the
2Not much would be lost were we to take an interval I ,
as in (Halpern and Shoham, 1991), to be a pair of points t, t?
with t  t?, or, as in (Allen, 1983), t ? t?.
3For finite T , A-segmented is the same as A-pointed.
ban on pairs of intervals satisfying ? is wider un-
der A-wholeness. For example, over T = {1, 2}, a
fluent holding at exactly {1} and {2} is not whole,
even though {{1}, {2}} is quantized.
A-wholeness shares half of A-segmentedness: a
fluent ? is A-summable if for all intervals I and I ?
in A such that I ? I ? is an interval,
I |= ? and I ? |= ? implies I ? I ? |= ?.
Apart from the restriction that I ? I ? is an interval,
A-summability coincides with additivity in (Bach,
1981), illustrated in (4).
(4) Ed slept from 3 to 5pm, Ed slept from 4 to
6pm |? Ed slept from 3 to 6pm
The other half of A-segmentedness (differentiat-
ing it from A-wholeness) is the subinterval prop-
erty (Bennett and Partee, 1972), enjoyed by states
and activities.
(5) Ed slept from 3 to 6 |? Ed slept from 3 to 5
A fluent ? is A-subinterval-persistent (A-sip) if
for all intervals I and I ? in A,
I ? I ? and I ? |= ? implies I |= ? .
It is useful to associate with any fluent ? a fluent
?? that holds precisely at subintervals of intervals
satisfying ?
I |= ?? ?? (?I
? ? I) I ? |= ? .
We say ? is A-equivalent to ? and write ? ?A ?
if for every interval I ,
I |= ? ?? I |= ?.
Clearly, ? is A-sip iff ? ?A ??. Also, ?? is A-sip
and we can say more if ? is A-whole.
2.1 An adjoint pair
The map ? 7? ?? is one half of a pair for break-
ing down and building up fluents. To describe the
other half, more definitions are helpful. Given a
fluent ? and a relation r between intervals, let us
form the modal fluent ?r?? that holds at an interval
r-related to one satisfying ?
I |= ?r?? ?? (?I ?) I r I ? and I ? |= ?.
Note ?? is just ????. Apart from ?, other useful
examples of relations r between intervals I and I ?
include full precedence ?
I ? I ? ?? (?t ? I)(?t? ? I ?) t ? t?
31
and a relation m called meet in (Allen, 1983) and
abutment in (Hamblin, 1971).
I m I ? ?? I ? I ? and I ? I ? is an interval.
Now, let mi be the inverse of m
I mi I ? ?? I ? m I
and max be a function on fluents that maps a fluent
? to its conjunction with ??mi?? and ??m??
max(?) = ? ? ??mi?? ? ??m??.
Proposition 1.
(a) For all A-whole ?, ?? is A-segmented and
? ?A max(??).
(b) For all A-segmented ?, max(?) is A-whole
and ? ?A (max(?))?.
As to the promised adjunction, let us agree to write
?A for the set of intervals satisfying ?
?A = {I | I |= ?}
(so ? ?A ? iff ?A = ?A) from which we define
two pre-orders on fluents
? ?A ?
? ?? ?A ? ?
?
A
? ?A ?? ?? (?I ? ?A)(?I
? ? ??A) I ? I
?
that apply to A-segmented fluents ? and A-whole
fluents ? respectively, for the equivalence
max(?) ?A ? ?? ? ?A ??
making max left (lower) adjoint to (of) ??.
Next, we turn to linguistic applications and the
correspondences
whole
segmented
?
count
mass
?
perfective
imperfective
.
The notion that imperfectives are mass and perfec-
tives count is argued in (Herweg, 1991), building
on (Galton, 1984; Galton, 1987) for a concept of
pofective event-type very close to that of A-whole
fluent above. Perfectives contrast with imperfec-
tives according to (6).
(6) a. viewed from outside, completed, closed
b. viewed from inside, ongoing, open-ended
Towards formalizing (6), let us say an interval I is
inside an interval I ?, written I @ I ?, if I ? extends
to the left and also to the right of I
I @ I ? ?? (?t? ? I ?) {t?} ? I and
(?t?? ? I ?) I ? {t??}
(called during in (Allen, 1983)). Next, we intro-
duce an A-whole fluent V for viewpoint to picture
a perfective view (6a) of E and an imperfective
view (6b) as (7a) and (7b) respectively.
(7) a. V? E,V? V? (depicting E @ V)
b. E? E?,V E? (depicting V @ E)
The idea now is to spell out what strings such as
(7a) and (7b) mean.
2.2 Segmentations and strings
A segmentation (seg) is a sequence I = I1I2 ? ? ? In
of intervals such that
Ii m Ii+1 for 1 ? i < n
or equivalently,
n?
i=1
Ii is an interval, and Ii ? Ii+1 for 1 ? i < n.
Given a sequence I = I1I2 ? ? ? In of intervals and
an interval I , we write I? I to mean
I is a seg and I =
n?
i=1
Ii,
in which case we say I is a seg(mentation) of
I . We extend satisfaction |= to segs I1 ? ? ? In and
strings ?1 ? ? ??m of finite subsets ?i of ?, requir-
ing that the lengths be the same and that Ii satisfy
every fluent in ?i
I1 ? ? ? In |= ?1 ? ? ??m ?? n = m and
(?? ? ?i) Ii |= ? for 1 ? i ? n.
For example, if E and V are A-singular (or just
A-whole)
(?I) I |= E? E?,V E? ?? (?I |= E)
(?J |= V) J @ I.
Next, I |= s extends from a string s to a set L
of strings, with L holding at I if some string in L
does
I |= L ?? (?s ? L) I |= s.
32
We then define ? to be A-segmentable as L if an
interval I in A satisfies ? iff every, or equivalently,
some seg of I satisfies L
I |= ? ?? (?I? I) I |= L
?? (?I? I) I |= L .
Proposition 2. If ? is A-summable, ?? is A-
segmentable as the infinite language
??
+ = ?? + ?? ?? +
?? ?? ?? + ? ? ?
of strings ??
n, n ? 1. Moreover, the following
five conditions are pairwise equivalent.
(i) ? is A-segmented
(ii) ? is A-segmentable as ??
+
(iii) ? is A-segmentable as ? +
(iv) ? is A-sip and A-summable
(v) ? ?A max(?)?.
As for A-whole fluents, we bound the strings
in ??
+, adding ??mi??? to the initial boxes and
??m??? to the final boxes to form the language
L(?) = ??,??mi???,??m??? +
??,??mi??? ??
?
??,??m??? .
Proposition 3. The following conditions (i)-(iv)
are pairwise equivalent.
(i) ? is A-whole
(ii) ? ?A max(??)
(iii) ? is A-segmentable as L(?)
(iv) I |= ? ?? + ?? ? for no seg I.
3 Durative and/or telic strings
For any integer n > 1, an interval may have a wide
variety of segmentations of length n, Propositions
2 and 3 notwithstanding. Even if
I |= V ? ?A?E,
a seg I1I2 of I need not satisfy
V?, ???E V? + V? V?, ???E
(as E may straddle the line between I1 and I2), and
if E is A-singular, the string
V? E,V? V?
holds in only one out of a possible multitude of
segs of I with length 3. The choice of a seg can
be a delicate matter. A string of sets of fluents ex-
presses such a choice. The present section links
that choice to aspect, stepping from a fluent ? to
a set L of strings of finite sets of fluents, without
requiring that L hold at every seg of every interval
satisfying ?. That is, the account of aspect given
below makes essential use of the string represen-
tations over and above the fluents from which the
strings are formed. Fluents/intervals describe ob-
jective matters of fact; strings/segmentations em-
body, in addition, particular perspectives on these
matters.
A concrete linguistic illustration is provided by
the notion that some events are punctual ? i.e.,
lacking in internal structure. (Comrie, 1976) dis-
cusses the example of cough, noting that ?the
inherent punctuality of cough would restrict the
range of interpretations that can be given to im-
perfective forms of this verb? to an iterative read-
ing (of a series of coughs), as opposed to a single
cough, which he refers to as semelfactive. Comrie
concedes, however, that, in fact, one can imagine
a situation where someone is comment-
ing on a slowed down film which incor-
porates someone?s single cough, as for
instance in an anatomy lecture: here, it
would be quite appropriate for the lec-
turer to comment on the relevant part of
the film and now the subject is cough-
ing, even in referring to a single cough,
since the single act of coughing has now
been extended, and is clearly durative, in
that the relevant film sequence lasts for
a certain period of time. (page 43)
The earlier contention that coughing can only be
read iteratively suggests that the intervals spanned
by single coughs are too small for our ?normal?
segmentations. These segmentations consist of
intervals too big for ?punctual? events, leading
to a representation of a ?-semelfactive as ?A??
rather than say, (8), with a middle box ?? of in-
ternal structure supporting the progressive.
(8) ??,??mi??? ?? ??,??m???
33
The special context provided above by an anatomy
lecture overturns this restriction, making (8) avail-
able after all. The punctual-durative distinction is
evidently not cast in stone. But just what is du-
rative? The simple proposal this section explores
is that what is durative is a string ?1?2 ? ? ??n of
sets ?i of fluents with n ? 3. Between the first
box ?1 and the last box ?n is a string ?2 ? ? ??n?1
representing internal structure that, for n ? 3, is
non-empty.4
Apart from the length n of a string ?1 ? ? ??n,
there is also the matter of what fluents to box in
a string, describing the interior as well as the im-
mediate exterior of the situation the string repre-
sents. (The string in (8) is just an example to flesh
out or otherwise revise.) Of particular relevance
to temporal extent are any fluents chosen to mark
the boundaries of the situation. An example in (9)
is the fluent ? which makes the string ?telic? by
appearing in all its boxes negated, except for the
rightmost box, which it marks.
(9) ??,?? ??,?? ?
Whether or not the intervals described by ?1 and
?n count as part of the situation represented by the
string is independent of (10).
(10) a. ?1 ? ? ??n is durative if it has length n ? 3
b. ?1 ? ? ??n is telic if the negation of some
? in ?n appears in ?i for 1 ? i < n.
While (10a) says ?1 ? ? ??n has internal structure,
(10b) says ?1 ? ? ??n culminates in some fluent
? ? ?n. (10b) is even more representational than
(10a) in that it depends not only on segmenting an
interval but on the choice of fluents we put into
a string describing that segmentation. As Krifka
notes, the telic-atelic distinction lies not ?in the na-
ture of the object described, but in the description
applied to the object? as
one and the same event of running can
be described by running (i.e. by an atelic
4Segmentations of the full linear order T into 2 or 3 inter-
vals are central to the interpretation of event radicals in (Gal-
ton, 1987). A formal occurrence is defined there to be a pair
B,A of intervals such that either AB ? T or AIB ? T
where I is the complement T ? (A ? B). The intuition is
that B is before, and A after the situation with temporal ex-
tent T ? (A ? B). The first box ?1 and last box ?n of a
string ?1 ? ? ??n above (with n ? 3) represent final and initial
subintervals of B and A, respectively (constituting external
structure). The middle bit ?2 ? ? ??n?1 describes a segmen-
tation of T ? (A ? B). Segs generalize formal occurrences,
elaborating on internal as well as external structure.
predicate) or by running a mile (i.e. a
telic, or delimited, predicate)
(Krifka, 1998, page 207).5 Krifka goes on to lo-
cate telicity not in objects but in sets P of objects
meeting the condition in (11a), based on a proper
part relation < on objects induced by a sum oper-
ation ? according to (11b).
(11) a. P is quantized if there are no x, y ? P
such that x < y
b. x < y ?? x 6= y and x? y = y
Under (11), the predicate run a mile is quantized,
whereas the predicate run is not, even though one
and the same run may belong to both predicates.
But what about run to the post office? Surely, the
second half of any run to the post office is also a
run to the post office. A telic string may fail to
be quantized because its left boundary (inception)
has not been specified.
3.1 Subsumption and superposition
Some notation from (Fernando, 2004) will come
in handy in what follows. Given strings s and s? of
sets, we say s subsumes s? and write s s? if they
have the same length and are related component-
wise by inclusion
?1 ? ? ??n  ?
?
1 ? ? ??
?
m ?? n = m and
?i ? ?
?
i for 1 ? i ? n.
For instance,
?,?? ?,?? ?,?? ?  ? ? ? .
We extend subsumption  to languages L existen-
tially (just as we did with |=)
s L ?? (?s? ? L) s s?
so that a string s is durative iff s + and telic
iff s  ??
+
? for some ?. A binary operation
on strings of the same length complementing sub-
sumption  is superposition & obtained by com-
ponentwise union
?1 ? ? ??n & ?
?
1 ? ? ??
?
n = (?1 ? ?
?
1) ? ? ? (?n ? ?
?
n).
5Notice that the condition (10b) for telicity is not met by
(8), but by the string
??,??mi???, ?m??? ??, ?m??? ??,??m???
provided ?m??? is understood to be the negation of ??m???.
An alternative to leaving ? existentially quantified in (10b) is
to specify the fluent ? and work with the notion of ?culimi-
nating in ?.?
34
For instance, ? ? ? & ?? ?? ? =
?,?? ?,?? ?,? and for strings s and s? of
the same length,
s s? ?? s = s & s?
s & s? = least -upper bound of s and s? .
We extend & to sets L and L? of strings (of possi-
bly different lengths) by collecting superpositions
of strings from L and L? of the same length
L & L? = {s & s? | s ? L, s? ? L?
and length(s)=length(s?)}
(a regular language provided L and L? are (Fer-
nando, 2004)). Notice that
{s}&{s?} = {s&s?} if length(s)= length(s?)
and the durative strings in L can be obtained by
superposing L with +
L& + = {s ? L | s +}.
3.2 Application to Aktionsart
Semelfactives, activities (= processes), achieve-
ments (= culminations) and accomplishments (=
culminated processes) are commonly differenti-
ated on the basis of durativity and telicity (Moens
and Steedman, 1988; Pulman, 1997).
(12) a. A semelfactive is non-durative and atelic
b. An activity is durative but atelic
c. An achievement is non-durative but telic
d. An accomplishment is telic and durative
Under the present approach based on strings, (12)
can be sharpened to (13).
(13) a. A ?-semelfactive  ????
b. A ?-activity  ? ? ? + (presupposing
? is A-segmented)
c. A ?-achievement  ?? ?
d. An accomplishment built from a ?-activity
culminating in ?
 ?,?? ?,?? ?,??
+
?
(presupposing ? is A-segmented)
(Bach, 1986a) argues that processes are mass
and events are count, raising the question: how
does the A-segmented/whole opposition sit with
our account (13) of semelfactives, activities,
achievements and accomplishments? Bach?s pro-
cesses are the activities in (13b), represented by
the durative strings in the language ? + that a A-
segmented fluent ? is A-segmentable as. Where
A-whole fluents fit in (13) is, however, not im-
mediately obvious. But as pointed out by (Com-
rie, 1976) for coughs and by (Krifka, 1998) for
(mile-long) runs, there is an element of perspective
(over and above pure, objective facts) that makes
Aktionsart pliable. An achievement may, for in-
stance, be coerced into an accomplishment to in-
terpret the progressive in (14).
(14) The train was arriving when Anna went to or-
der a drink.
A seg II ? satisfying an achievement ?? ?
might, for some segmentation I1I2I3 of I , be re-
fined to the seg I1I2I3I ? satisfying an accomplish-
ment ?,?? ?,?? ?,?? ? with preparatory
process/activity ? ? ? , for some A-segmented
?.
As representations, strings are slippery in a
way that fixed pairs A, I are not; a shorter string
might describe a larger interval than a longer string
does. Strings are not so much finished objects
as makeshift representations subject to refinement.
So should A-whole fluents go into these strings?
The simplest examples of A-whole-fluents are
A-singular fluents (harking back to Davidson?s
events as particulars). Conceptualizing event time
at some level of abstraction as an interval is rea-
son enough to form a fluent picking out that inter-
val. And with an A-singular fluent ? comes the A-
segmented fluent ??, and the fluents ??mi??? and
??m??? from which to form the language L(?)
which ? is A-segmentable as (Proposition 3).
(Dowty, 1979) explores the hypothesis that
the different aspectual properties of the
various kinds of verbs can be explained
by postulating a single homogeneous
class of predicates ? stative predicates
? plus three or four sentential operators
and connectives
(page 71). A simplified event-based reformulation
(15) of the Vendler classes in terms of Dowty?s
operators DO, BECOME and CAUSE is given in
(Rothstein, 2004), page 35.
35
(15) states ?e.P (e)
activities ?e.(DO(P ))(e)
achievements ?e.(BECOME(P ))(e)
accomplishments ?e.?e1, e2.[e = e1 ?S e2
?(DO(P ))(e1) ? Cul(e) = e2]
Dowty?s CAUSE operator is reworked in (15) with
a sum operation ?S producing singular entities,
and a culmination function Cul. The resulting ac-
complishment e is the sum e1?S e2 of its prepara-
tory process (activity) e1 and culmination e2. To
bring (13) in line with (15), we put
DO(P ) ? P P P
+
BECOME(P ) ? ?P P
and require that P be A-segmented. Defining
du(L) = L& +
cu(L,?) = (L& ??
+
) ?
yields
P P P
+
= du( P
+
)
?P P = cu( , P )
and for accomplishments as culiminated activities,
cu(du( ? +), ?) = ?,?? ?,?? ?,??
+
?
= du( ?,?? ) ? .
Left out of (13) are the states in (15), which can
be compared to A-segmented fluents in the present
framework. As noted in (Dowty, 1986), one might
also require that stative fluents be inertial, for
which see (Fernando, 2008).
4 Desegmenting and branching time
Why segment an interval? The two reasons given
above are (1) to get a handle on durativity and
telicity, and (2) to unwind an interval fluent such
as E??A?R to a string E? E?,R E? interpreted
against segmentations (i.e. finite timelines). Nei-
ther reason justifies grinding indefinitely. The
thrust of the present section is to leave segs as
coarse as possible, segmenting only if necessary,
leading to a notion of time that may branch.
4.1 Desegmenting via pi
Quantifying the model A out of the notion of A-
segmentability and weakening the connection be-
tween intervals and segs, let us agree that a lan-
guage L depicts ? if for all models A, L is A-
satisfiable precisely if ? is
(? seg I) I |= L ?? (? interval I) I |= ?.
Trivially, ? depicts ?, but there are more inter-
esting examples. Unwinding the modal operator
?? and conjunction ? in the fluent S ????,
? S + ? S depicts S ? ???.
The language ? S + ? S reduces the infinite
language
?
?
?
S
?
depicting S ???? to two
strings. This reduction illustrates the possibility
that under suitable assumptions on a language L
depicting ?, the strings in L can be simplified in
two ways:
(w1) any initial or final empty boxes can be
stripped off, and
(w2) all repeating blocks ?n (for n ? 1) of a box
? can be compressed to ?.
More precisely, we implement (w1) by a function
unpad defined on strings s by
unpad(s) =
?
?
?
unpad(s?) if s = s? or
else s = s?
s otherwise
so that unpad(s) neither begins nor ends with .
For (w2), all blocks ?n+1 in s are compressed in
bc(s) to ?
bc(s) =
?
???
???
bc(?s?) if s = ??s?
? bc(?s?) if s = ??s? with
? 6= ?
s otherwise
so that if bc(s) = ?1 ? ? ??n then ?i 6= ?i+1 for i
from 1 to n ? 1. We then compose bc with unpad
for pi
pi(s) = unpad(bc(s)).
One can check that
{pi(s) | s ?
?
?
?
S
?
} = ? S + ? S .
36
Clearly, pi(s) is never longer than s, and pi(s) =
pi(pi(s)) for all strings s.
As for the ?suitable assumptions? on L under
which L can be reduced to {pi(s)|s ? L}, it is
helpful to consider the fluent R ? ?@??. Can we
unwind ?@? in R,?@?? ? Assuming ?? is A-
summable for all models A,
?? R,?? ?? depicts R ? ?@??.
Now, let us call a string s = ?1 ? ? ??n of sets ?i
of fluents A-reducible if every fluent appearing in
two consecutive string positions ?i?i+1 in s (for
some 1 ? i < n) is A-summable. (For exam-
ple, ?? R,?? ?? is A-reducible, provided ??
is A-summable.) Let us say a seg I refines a seg
I1 ? ? ? In if for all i from 1 to n, Ii is the union of
some subsequence of I.
Proposition 4. For any A-reducible string s, ev-
ery seg I that satisfies s refines some seg I? that
satisfies pi(s). Consequently, if for all s ? L, s is
A-reducible and pi(s) ? L, then L is A-satisfiable
iff {pi(s)|s ? L} is
(? seg I) I |= L ?? (? seg I) I |= {pi(s) |
s ? L}.
4.2 Relativizing pi to a finite set X of fluents
Next, we fix a notion of bounded granularity
through a finite set X of fluents of interest, which
we can expand to refine granularity or contract to
coarsen granularity. An instructive example for
orientation is the representation of a calendar year
of twelve months as the string
smo = Jan Feb Mar ? ? ? Dec
of length 12, or, were we also interested in days
d1,d2. . .,d31, the string
smo,dy = Jan,d1 Jan,d2 ? ? ? Jan,d31
Feb,d1 ? ? ? Dec,d31
of length 365 (for a non-leap year). Un-
like the points in the real line R, a box
can split, as Jan in smo does (30 times) to
Jan,d1 Jan,d2 ? ? ? Jan,d31 in smo,dy, on in-
troducing days d1, d2,. . ., d31 into the picture.
Reversing direction and generalizing from mo =
{Jan,Feb,. . .Dec} to any set X of fluents, we de-
fine the function ?X on strings (of sets) to compo-
nentwise intersect with X
?X(?1 ? ? ??n) = (?1 ?X) ? ? ? (?n ?X)
throwing out non-X?s from each box (keeping
only the elements of X) so that
?mo(smo,dy) = Jan
31
Feb
28
? ? ? Dec
31
.
Next, we compose ?X and pi for the function piX
mapping a string s of sets to
piX(s) = pi(?X(s)) = unpad(bc(?X(s)))
so that for example,
pimo(smo,dy) = pi( Jan
31
Feb
28
? ? ? Dec
31
)
= smo
and
pi{E?}( E? R,E? E? ) = pi( E? E? E? )
= E? .
In general, a description sX of granularity X can
be refined to one sX? of granularity X ? ? X pro-
vided piX maps sX? to sX . More precisely, given
some large set ? of fluents, let Fin(?) be the set
of finite subsets of ?. A function f with domain
Fin(?) mapping X ? Fin(?) to a string f(X)
over the alphabet 2X is said to be pi-consistent if
whenever X ? X ? ? Fin(?),
f(X) = piX(f(X
?)).
Let us write ILpi(?) for the set of all pi-consistent
functions. ?IL? here stands not for intensional
logic but for inverse limit ? to be precise, the in-
verse limit of the restrictions of piX to (2X
?
)? for
X ? X ? ? Fin(?) (all computable by finite-
state transducers). That said, ILpi(?) is inten-
sional: time branches under the relation ?? be-
tween f, f ? ? ILpi(?) given by
f ?? f
? ?? f 6= f ? and (?X ? Fin(?))
f(X) is a prefix of f ?(X)
(where s is a prefix of s? if s? = ss? for some
possibly empty string s?). The intuition is that a
temporal moment comes with its past, and that
an f ? ILpi(?) encodes the moment that is X-
approximated, for each X ? Fin(?), by the last
37
box in f(X), with past given by the remainder of
f(X) (leading to that box). More precisely, ?? is
tree-like in the sense of (Dowty, 1979).
Proposition 5. ?? is transitive and left linear: for
every f ? IL(?),
(?f1 ?? f)(?f2 ?? f) f1 ?? f2 or
f2 ?? f1 or f1 = f2.
Moreover, no element of ILpi(?) is ??-maximal.
Maximal chains, called histories in (Dowty, 1979),
figure prominently in possible worlds semantics.
While we can pick one out in ILpi(?) to represent
an actual history, it is far from obvious what sig-
nificance maximal ??-chains have in the present
framework, which is closer in spirit to situation
semantics (Bawise and Perry, 1983), updated in
(Cooper, 2005; Ginzburg, 2005).
Tha handbook chapter (Thomason, 1984) opens
with the declaration
Physics should have helped us to re-
alise that a temporal theory of a phe-
nomenon X is, in general, more than a
simple combination of two components:
the statics of X and the ordered set of
temporal instants. The case in which
all functions from times to world-states
are allowed is uninteresting; there are
too many such functions, and the the-
ory has not begun until we have begun
to restrict them. And often the princi-
ples that emerge from the interaction of
time with the phenomena seem new and
surprising.
For a non-empty set W of worlds, and a linearly
ordered set T of time instants, Thomason com-
pares T ? W -frames, not unlike that in (Mon-
tague, 1973), unfavorably to tree-like frames, of
which ?? above is an example, when paired with
a ?-maximal ??-chain. The crudeness of the
cartesian product ? aside, one may ask where T
comes from, as Bach pointedly does in page 69 of
(Bach, 1981), to say nothing of W . The answer
from ILpi(?) involves strings formed from flu-
ents. The projective system (piX)X?Fin(?) gives
for every finite subset X of ?, a choice of X-
approximations in (2X)?, including for X =
{e, e?} with e 6= e?, 13 strings sr corresponding
to the Allen interval relations r between intervals
e and e? (Allen, 1983); see Table 1 (Fernando,
r ?Allen sr ? (2{e,e
?})+
e = e? e, e?
e s e? e, e? e?
e si e? e, e? e
e f e? e? e, e?
e fi e? e e, e?
e d e? e? e, e? e?
e di e? e e, e? e
e o e? e e, e? e?
e oi e? e? e, e? e
e m e? e e?
e < e? e e?
e mi e? e? e
e > e? e? e
Table 1: The Allen relations in (2{e,e
?})+
2012). Under the projections piX , these strings
are most naturally viewed as indices for evalu-
ating an expression ? as an extension or deno-
tation, as prescribed by Carnap-Montague inten-
sions (Fernando, 2011). In (Bach, 1986b), an
event type such as KISSING induces a function
EXT(KISSING) that maps histories to subparts
that are temporal manifestations of KISSING,
treating input histories as indices and output mani-
festations as extensions. Under the current frame-
work, EXT(KISSING) can for any X ? Fin(?),
be given as a binary relation between strings in
(2X)? thatX-approximate indices and extensions.
5 Conclusion
Segmentations arise naturally in the view from
(Klein, 2009) that
The expression of time in natural lan-
guages relates a clause-internal tempo-
ral structure to a clause-external tem-
poral structure. The latter may shrink
to a single interval, for example, the
time at which the sentence is uttered; but
this is just a special case. The clause-
internal temporal structure may also be
very simple ? it may be reduced to a sin-
gle interval without any further differen-
tiation, the ?time of the situation?; but if
this ever happens, it is only a borderline
case. As a rule, the clause-internal struc-
38
ture is much more complex. (page 75)
The simplest case described by the passage is il-
lustrated by the picture (16) of the clause-internal
event (or situation) time E preceding the clause-
external speech (utterance) time S.
(16) E S + E S depicting E????S
Slightly more complicated is the picture (3) of
event time E with R inside it.
(3) E? E?,R E? (segmented E?, whole R)
Whereas E in (16) is unbroken and whole, the
?differentiation? in (3) puts E through a universal
grinder ?? described in section 2, alongside notions
of A-whole and A-segmented fluents, the contrast
between which surfaces in pairs such as (17) and
(18).
(17) Ernest was explaining 6|? Ernest explained
(18) Ernest was laughing |? Ernest laughed
The non-entailment (17) is clear from (19).
(19) Ernest was explaining when he was made to
stop.
To extract a rigorous account of (17) versus (18)
from the assumption that explaining is whole and
laughing is segmented (as fluents) would require
stepping beyond lexical/internal aspect (consid-
ered in sections 2 and 3 above) to grammati-
cal/external aspect, hinted at in (3), as well as
tense. Some details compatible with the present
approach can be found in (Fernando, 2008).6 Suf-
fice it to say that additional temporal parameters
from tense and aspect enlarge the set X of fluents
that, under the inverse limit ILpi(?) in section 4,
refines granularity. While we have taken pains to
show how to interpret a string of subsets of ? in
6An alternative would be to follow along (Galton, 1984;
Galton, 1987). There are likely to be many ways to fill in
the details. In the case of the perfect, for instance, the basic
approach outlined here is, as far as I can tell, neutral between
extended now accounts (Pancheva, 2003) augmented with (7)
(7) a. V? E,V? V? (depicting E @ V)
b. E? E?,V E? (depicting V @ E)
and consequent-state approaches (Moens and Steedman,
1988; Kamp and Reyle, 1993; Pulman, 1997) that might be
augmented with inertia (Dowty, 1986) and forces (Fernando,
2008).
a segmentation (essentially, a finite, ordered par-
tition of an interval from a ?-timeline), no ?-
timeline is used to define ILpi(?), resulting in a
notion of time that branches (away from any single
segmentation or timeline). There is sure to be junk
in ILpi(?) to throw out; but what use tense and
aspect might have for timelines not represented in
ILpi(?), I fail to see (apart from linking tempo-
rality up with other linguistic mechanisms such as
quantification). Work on tense and aspect has led
to extensions of ordinary temporal logic in three
directions.
(20) a. addition of temporal parameters (e.g. R)
b. expansion of points to intervals
c. recognition of events and states
Stringing together finite sets of fluents, we attend
to (20c) in sections 2 and 3 above, and to (20a)
in section 4, putting the distinction (20b) between
points and intervals down to the set X of fluents
under consideration.7
References
James F. Allen. 1983 Maintaining knowledge about
temporal intervals. Communications of the ACM,
26:832?843.
Emmon Bach. 1981. On time, tense and aspect: an
essay in English metaphysics. In Peter Cole, editor,
Radical Pragmatics, pages 63 ? 81. Academic Press.
Emmon Bach. 1986a. The algebra of events. Linguis-
tics and Philosophy, 9:5?16.
Emmon Bach. 1986b. Natural language metaphysics.
In R. Barcan Marcus, G.J.W. Dorn, and P. Weingart-
ner, editors, Logic, Methodology and Philosophy of
Science VII, pages 573 ? 595. Elsevier.
Jon Bawise and John Perry. 1983. Situations and Atti-
tudes. Bradford, MIT Press.
Michael Bennett and Barbara Partee. 1972. Toward the
logic of tense and aspect in English. Indiana Univer-
sity Linguistics Club, Bloomington, IN.
Bernard Comrie. 1976. Aspect. Cambridge University
Press.
Robin Cooper. 2005. Austinian truth, attitudes and
type theory. Research on Language and Computa-
tion, 3(4):333?362.
7Added in haste. The literature on interval temporal logic
is vast, and the present paper has doubtless failed to do it
justice. In particular, (Nishimura, 1980) and (Moszkowski,
1986) deserve to be mentioned properly in this paper, which
I hope to do in a revision.
39
David R. Dowty. 1979. Word Meaning and Montague
Grammar. Reidel, Dordrecht.
David R. Dowty. 1986. The effects of aspectual class
on the temporal structure of discourse: semantics or
pragmatics? Linguistics and Philosophy, 9(1):37?
61.
Tim Fernando. 2004. A finite-state approach to events
in natural language semantics. Journal of Logic and
Computation, 14(1):79?92.
Tim Fernando. 2008. Branching from inertia worlds.
J. Semantics, 25(3):321?344.
Tim Fernando. 2011. Regular relations for tempo-
ral propositions. Natural Language Engineering,
17(2):163?184.
Tim Fernando. 2012. A finite-state temporal ontol-
ogy and event-intervals. Proceedings of the 10th In-
ternational Workshop on Finite State Methods and
Natural Language Processing, pages 80?89, Donos-
tia/San Sebastian (ACL archive).
Antony Galton. 1984. The logic of aspect: an ax-
iomatic approach. Clarendon Press.
Antony Galton. 1987. The logic of occurrence.
In Temporal Logics and Their Applications, pages
169?196. Academic Press.
Jonathan Ginzburg. 2005. Situation semantics: the
ontological balance sheet. Research on Language
and Computation, 3(4):363?389.
Joseph Halpern and Yoav Shoham. 1991. A proposi-
tional modal logic of time intervals. Journal of the
Association for Computing Machinery, 38(4):935?
962.
Charles L. Hamblin. 1971. Instants and intervals,
Studium Generale, 24:127?134.
Michael Herweg. 1991. A critical examination of two
classical approaches to aspect. J. Semantics, 8:363?
402.
Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer.
Wolfgang Klein. 2009. How time is encoded. In W.
Klein and P. Li, editors, The Expression of Time,
pages 39?81. Mouton De Gruyter.
Manfred Krifka. 1998. The origins of telicity. In
S. Rothstein, editor, Events and Grammar, pages
197?235. Kluwer.
Jerzy Marcinkowski and Jakub Michaliszyn. 2013.
The undecidability of the logic of subintervals. Fun-
damenta Informaticae 20:124.
Marc Moens and Mark Steedman. 1988. Temporal on-
tology and temporal reference. Computational Lin-
guistics, 14(2):15?28.
Richard Montague. 1973. The proper treatment of
quantification in ordinary English. In K.J.J. Hin-
tikka, J.M.E. Moravcsik, and P. Suppes, editors, Ap-
proaches to Natural Language, pages 221?42. D.
Reidel, Dordrecht.
Ben Moszkowski. 1986. Executing Temporal Logic
Programs. Cambridge University Press.
Hirokazu Nishimura. 1980. Interval Logics with Ap-
plications to Study of Tense and Aspect in English.
Publ. Research Institute for Mathematical Sciences,
Kyoto University 16:417-459.
Roumyana Pancheva. 2003. The aspectual makeup
of Perfect participles and the interpretations of the
Perfect. In A. Alexiadou and M. Rathert and A. von
Stechow, editors, Perfect Explorations, pages 277?
306. Mouton de Gruyter.
Stephen G. Pulman. 1997. Aspectual shift as type
coercion. Transactions of the Philological Society,
95(2):279?317.
Hans Reichenbach. 1947. Elements of Symbolic Logic.
MacMillan Company, NY.
Susan Rothstein. 2004. Structuring Events: A Study in
the Semantics of Lexical Aspect. Blackwell.
Richmond Thomason. 1984. Combinations of tense
and modality. In D. Gabbay and F. Guenthner, ed-
itors, Handbook of Philosophical Logic, volume II,
pages 135?165. Reidel.
40
Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 63?71,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
Incremental semantic scales by strings
Tim Fernando
Computer Science Department
Trinity College Dublin
Dublin, Ireland
Tim.Fernando@tcd.ie
Abstract
Scales for natural language semantics are
analyzed as moving targets, perpetually
under construction and subject to ad-
justment. Projections, factorizations and
constraints are described on strings of
bounded but refinable granularities, shap-
ing types by the processes that put seman-
tics in flux.
1 Introduction
An important impetus for recent investigations
into type theory for natural language semantics is
the view of ?semantics in flux,? correcting ?the im-
pression? from, for example, Montague 1973 ?of
natural languages as being regimented with mean-
ings determined once and for all? (Cooper 2012,
page 271). The present work concerns scales
for temporal expressions and gradable predicates.
Two questions that loom large from the perspec-
tive of semantics in flux are: how to construct
scales and align them against one another (e.g.
Klein and Rovatsos 2011). The formal study car-
ried out below keeps scales as simple as possi-
ble, whilst allowing for necessary refinements and
adjustments. The basic picture is that a scale is
a moving target finitely approximable as a string
over an alphabet which we can expand to refine
granularity. Reducing a scale to a string comes,
however, at a price; indivisible points must give
way to refinable intervals (embodying underspec-
ification).
Arguments for a semantic reorientation around
intervals (away from points) are hardly new. Best
known within linguistic semantics perhaps are
those in tense and aspect from Bennett and Partee
1972, which seem to have met less resistance than
arguments in the degree literature from Kennedy
2001 and Schwarzschild and Wilkinson 2002 (see
Solt 2013). At the center of the present argument
for intervals is a notion of finite approximabil-
ity, plausibly related to cognition. What objection
might there be to it? The fact that no finite lin-
ear order is dense raises the issue of compatibility
between finite approximability and density ? no
small worry, given the popularity of dense linear
orders for time (e.g. Kamp and Reyle 1993, Pratt-
Hartmann 2005, Klein 2009) as well as measure-
ment (e.g. Fox and Hackl 2006).
Fortunately, finite linear orders can be orga-
nized into a system of approximations converging
at the limit to a dense linear order. The present
work details ways to form such systems and lim-
its, with density reanalyzed as refinability of ar-
bitrary finite approximations. A familiar example
provides some orientation.
Example A (calendar) We can represent a cal-
endar year as the string
s
mo
:= Jan Feb Mar ? ? ? Dec
of length 12, or, were we interested also in days
d1,d2. . .,d31, the string
s
mo,dy
:= Jan,d1 Jan,d2 ? ? ? Jan,d31
Feb,d1 ? ? ? Dec,d31
of length 365 for a non-leap year (Fernando
2011).
1
In contrast to the points in the real line
R, a box can split, as Jan in s
mo
does (30 times)
to
Jan,d1 Jan,d2 ? ? ? Jan,d31
in s
mo,dy
, on introducing days d1, d2,. . ., d31
into the picture. Reversing direction and gener-
alizing from
mo := {Jan,Feb,. . .Dec}
1
We draw boxes (instead of the usual curly braces { and })
around sets-as-symbols, stringing together ?snapshots? much
like a cartoon/film strip.
63
to any set A, we define the function ?
A
on strings
(of sets) to componentwise intersect with A
?
A
(?
1
? ? ??
n
) := (?
1
?A) ? ? ? (?
n
?A)
(throwing out non-A?s from each box) so that
?
mo
(s
mo,dy
) = Jan
31
Feb
28
? ? ? Dec
31
.
Next, the block compression bc(s) of a string s
compresses all repeating blocks ?
n
(for n ? 1)
of a box ? in a string s to ? for
bc(s) :=
?
?
?
?
?
?
?
bc(?s
?
) if s = ??s
?
? bc(?s
?
) if s = ??s
?
with
? 6= ?
s otherwise
so that if bc(s) = ?
1
? ? ??
n
then ?
i
6= ?
i+1
for i
from 1 to n? 1. In particular,
bc( Jan
31
Feb
28
? ? ? Dec
31
) = s
mo
.
Writing bc
A
for the function mapping s to
bc(?
A
(s)), we have
bc
mo
(s
mo,dy
) = s
mo
.
In general, we can refine a string s
A
of granu-
larity A to one s
A
?
of granularity A
?
? A with
bc
A
(s
A
?
) = s
A
. Iterating over a chain
A ? A
?
? A
??
? ? ? ? ,
we can glue together strings s
A
, s
A
?
, s
A
??
, . . . such
that
bc
X
(s
X
?
) = s
X
for X ? {A,A
?
, A
??
, . . .}.
Details in section 2.
We shall refer to the expressions we can put in
a box as fluents (short for temporal propositions),
and assume they are the elements of a set ?. While
the set ? of fluents might be infinite, we restrict the
boxes that we string together to finite sets of flu-
ents. Writing Fin(?) for the set of finite subsets
of ? and 2
X
for the powerset of X (i.e. the set
of X?s subsets), we will organize the strings over
the infinite alphabet Fin(?) around finite alpha-
bets 2
A
, for A ? Fin(?)
Fin(?)
?
=
?
A?Fin(?)
(2
A
)
?
.
In addition to projecting Fin(?) down to 2
A
for
some A ? Fin(?), we can build up, forming
the componentwise unions of strings ?
1
? ? ??
n
and
?
1
? ? ??
n
of the same number n of sets for their su-
perposition
?
1
? ? ??
n
& ?
1
? ? ??
n
:= (?
1
? ?
1
) ? ? ? (?
n
? ?
n
)
and superposing languages L and L
?
over Fin(?)
by superposing strings in L and L
?
of the same
length
L & L
?
:= {s&s
?
| s ? L, s
?
? L
?
and
length(s) = length(s
?
)}
(Fernando 2004). For example,
s
mo,dy
= ?
mo
(s
mo,dy
) & ?
dy
(s
mo,dy
)
where dy := {d1, d2 . . . , d31}. More generally,
writing L
A
for the image of L under ?
A
L
A
:= {?
A
(s) | s ? L},
observe that for L ? (2
B
)
?
and A ? B, L is
included in the superposition of L
A
and L
B?A
L ? L
A
& L
B?A
.
The next step is to identify a language L
?
such that
L = (L
A
& L
B?A
) ? L
?
(1)
other than L
?
= L. For a decomposition (1) of
L into (generic) contextual constraints L
?
separate
from the (specific) components L
A
and L
B?A
,
it will be useful to sharpen L
A
, L
B?A
and &,
factoring in bc and variants of bc (not to mention
?). Measurements ranging from crude compar-
isons (of order) to quantitative judgments (mul-
tiplying unit magnitudes with real numbers) can
be expressed through fluents in ?. We interpret
the fluents relative to suitable strings in Fin(?)
?
,
presented below in category-theoretic terms con-
nected to type theory (e.g. Mac Lane and Moerdijk
1992). Central to this presentation is the notion of
a presheaf on Fin(?) ? a functor from the op-
posite category Fin(?)
op
(a morphism in which
is a pair (B,A) of finite subsets of ? such that
A ? B) to the category Set of sets and functions.
The Fin(?)-indexed family of functions bc
A
(for
A ? Fin(?)) provides an important example that
we generalize in section 2.
An example of linguistic semantic interest to
which block compression bc applies is
64
Example B (continuous change) The pair (a),
(b) below superposes two events, soup cooling and
an hour passing, in different ways (Dowty 1979).
(a) The soup cooled in an hour.
(b) The soup cooled for an hour.
A common intuition is that in an hour requires
an event that culminates, while for an hour re-
quires a homogeneous event. In the case of (a),
the culmination may be that some threshold tem-
perature (supplied by context) was reached, while
in (b), the homogeneity may be the steady drop
in temperature over that hour. We might track
soup cooling by a descending sequence of degrees,
d
1
> d
2
> ? ? ? > d
n
, with d
1
at the beginning
of the hour, and d
n
at the end. But no sample of
finite size n can be complete. To overcome this
limitation, it is helpful to construe the ith box in
a string as a description of an interval I
i
over the
real line R. We call a sequence I
1
? ? ? I
n
of inter-
vals a segmentation if
?
n
i=1
I
i
is an interval and for
1 ? i < n, I
i
< I
i+1
, where < is full precedence
I < I
?
iff (?r ? I)(?r
?
? I
?
) r < r
?
.
Now, assuming an assignment of degrees sDg(r)
to real numbers r representing temporal instants,
the idea is to define satisfaction |= between inter-
vals I and fluents sDg < d according to
I |= sDg < d iff (?r ? I) sDg(r) < d
and similarly for d ? sDg. We then lift |= to
segmentations I
1
? ? ? I
n
and strings ?
1
? ? ??
n
?
Fin(?)
n
of the same length n such that
I
1
? ? ? I
n
|= ?
1
? ? ??
n
iff whenever 1 ? i ? n
and ? ? I
i
, I
i
|= ?
i
and analyze (a) above as (c) below, where d is
the contextually given threshold required by in an
hour, and x is the start of that hour, the end of
which is marked by hour(x).
(c) x, d ? sDg d ? sDg hour(x), sDg < d
All fluents ? in (c) have the stative property
(?) for all intervals I and I
?
whose union I ? I
?
is an interval,
I ? I
?
|= ? iff I |= ? and I
?
|= ?
(Dowty 1979). (?) holds also for the fluents in
the string (d) below for (b), where the subinterval
relation v is inclusion restricted to intervals,
I |= [w]? iff (?I
?
v I) I
?
|= ?
and sDg
?
is the fluent
?x (sDg < x ? Prev(x ? sDg))
saying the degree drops (with I |= Prev(?) iff
I
?
I |= ? for some I
?
< I such that I ? I
?
is
an interval).
(d) x [w]sDg
?
hour(x), [w]sDg
?
(?) is intimately related to block compression bc
(Fernando 2013b), supporting derivations of (c)
and (d) by a modification &
bc
of & defined in ?2.3
below.
Our third example directly concerns computa-
tional processes, which we take up in section 3.
Example C (finite automata) Given a finite al-
phabet A, a (non-deterministic) finite automaton
A over A is a quadruple (Q, ?, F, q
0
) consisting
of a finite set Q of states, a transition relation
? ? Q ? A ? Q, a subset F of Q consisting of
final (accepting) states, and an initial state q
0
? Q.
A accepts a string a
1
? ? ? a
n
? A
?
precisely if there
is a string q
1
? ? ? q
n
? Q
n
such that
q
n
? F and ?(q
i?1
, a
i
, q
i
) for 1 ? i ? n (2)
(where q
0
is A?s designated initial state). The ac-
cepting runs of A are strings of the form
a
1
, q
1
? ? ? a
n
, q
n
? (2
A?Q
)
?
satisfying (2). While we can formulate such runs
as strings over the alphabet A?Q, we opt for the
alphabet 2
A?Q
(formed from A ? Q ? Fin(?))
to link up smoothly with examples where more
than one automata may be running, not all neces-
sarily known nor in perfect harmony with others.
Such examples are arguably of linguistic interest,
the so-called Imperfective Paradox (Dowty 1979)
being a case in point (Fernando 2008). That said,
the attention below is largely on certain category-
theoretic preliminaries for type theory.
2
We adopt the following notational conventions.
Given a function f and a set X , we write
2
Only the most rudimentary category-theoretic notions
are employed; explanations can be found in any number of in-
troductions to category theory available online (and in print).
65
- f  X for f restricted to X ? domain(f)
- image(f) for {f(x) | x ? domain(f)}
- fX for image(f  X)
- f
?1
X for {x ? domain(f) | f(x) ? X}
and if g is a function for which image(f) ?
domain(g),
- f ; g for f composed (left to right) with g
(f ; g)(x) := g(f(x))
for all x ? domain(f).
We say f is a function on X if
domain(f) = X ? image(f)
? i.e., f : X ? X . The kernel of f , ker(f), is
the equivalence relation on domain(f) that holds
between s, s
?
such that f(s) = f(s
?
). Clearly,
ker(f) ? ker(f ; g)
when f ; g is defined.
2 Some presheaves on Fin(?)
Given a function f on Fin(?)
?
and A ? Fin(?),
let us write f
A
for the function ?
A
; f on Fin(?)
?
f
A
(s) := f(?
A
(s))
(recalling ?
A
(?
1
? ? ??
n
) := (?
1
?A) ? ? ? (?
n
?A)
and generalizing bc
A
from Example A). To extract
a presheaf on Fin(?) from the Fin(?)-indexed
family of functions f
A
, certain requirements on f
are helpful. Toward that end, let us agree that
- f preserves a function g with domain
Fin(?)
?
if g = f ; g
- f is idempotent if f preserves itself (i.e., f =
f ; f )
- the vocabulary voc(s) of s ? Fin(?)
?
is the
set of fluents that occur in s
voc(?
1
? ? ??
n
) :=
n
?
i=1
?
i
whence s ? voc(s)
?
.
Note that for idempotent f , image(f) consists of
canonical representatives f(s) of ker(f)?s equiva-
lence classes {s
?
? Fin(?)
?
| f(s
?
) = f(s)}.
2.1 ?-preserving functions
A function f on Fin(?)
?
is ?-preserving if f pre-
serves voc and f
A
, for all A ? Fin(?). Note that
bc is ?-preserving, as is the identity function id on
Fin(?)
?
.
Proposition 1. If f is ?-preserving then f is
idempotent and
f
B
; f
A
= f
A?B
for all A,B ? Fin(?).
Let P
f
be the function with domain
Fin(?) ? {(B,A) ? Fin(?)?Fin(?) |A ? B}
mapping A ? Fin(?) to f(2
A
)
?
P
f
(A) := {f(s) | s ? (2
A
)
?
}
and a Fin(?)
op
-morphism (B,A) to the restric-
tion of f
A
to P
f
(B)
P
f
(B,A) := f
A
 P
f
(B).
Corollary 2. If f is ?-preserving then P
f
is a
presheaf on Fin(?).
Apart from bc, we get a ?-preserving function
by stripping off any initial or final empty boxes
unpad(s) :=
?
?
?
unpad(s
?
) if s = s
?
or
else s = s
?
s otherwise
so that unpad(s) neither begins nor ends with .
Notice that bc; unpad = unpad; bc.
Proposition 3. If f and g are ?-preserving and
f ; g = g; f , then f ; g is ?-preserving.
2.2 The Grothendieck construction
Given a presheaf F on Fin(?), the category
?
F
of elements of F (also known as the Grothendieck
construction for F ) has
- objects (A, s) ? Fin(?) ? F (A) (making
?
X?Fin(?)
F (X) the set of objects in
?
F )
- morphisms (B, s
?
, A, s) from objects (B, s
?
)
to (A, s) when A ? B and F (B,A)(s
?
) = s
(e.g. Mac Lane and Moerdijk 1992). Let pi
f
be the
left projection
pi
f
(A, s) = A
66
from
?
P
f
back to Fin(?). The inverse limit of
P
f
, lim
??
P
f
, is the set of (
?
P
f
)-valued presheaves
p on Fin(?) (i.e. functors p : Fin(?)
op
?
?
P
f
)
that are inverted by pi
f
pi
f
(p(A)) = A for all A ? Fin(?).
That is, p(A) = (A, s
A
) for some s
A
? f(2
A
)
?
such that
(?) s
A
= f
A
(s
B
) whenever A ? B ? Fin(?).
(?) is the essential restriction that lim
??
P
f
adds
to objects {s
X
}
X?Fin(?)
of the dependent type
?
X?Fin(?)
P
f
(X).
2.3 Superposition and non-determinism
Taking the presheaf P
id
induced by the identity
function id on Fin(?)
?
, observe that in
?
P
id
,
there is a product of
(?, ) and ({?}, ? )
but not of
({?}, ) and ({?}, ? ).
The tag A in (A, s) differentiating (?, ) from
({?}, ) cannot be ignored when forming prod-
ucts in
?
P
id
. A necessary and sufficient condition
for (A, s) and (B, s
?
) to have a product is
?
B
(s) = ?
A
(s
?
)
presupposed by the pullback of
(A, s) ? (A ?B, ?
B
(s)) ? (B, s
?
).
By comparison, the superposition s&s
?
exists (as
a string) if and only if
?
?
(s) = ?
?
(s
?
)
for
(voc(s), s) ? (?, ?
?
(s)) ? (voc(s
?
), s
?
)
(or length(s) = length(s
?
) as ?
?
(s) =
length(s)
).
Products in
?
P
id
are superpositions, but superpo-
sitions need not be products.
Next, we step from id to other ?-preserving
functions f such as bc and bc; unpad. A pair
(A, s) and (B, s
?
) of
?
P
f
-objects may fail to
have a product not because there is no
?
P
f
-object
(A ?B, s
??
) such that
(A, s) ? (A ?B, s
??
) ? (B, s
?
)
but too many non-isomorphic choices for such s
??
.
Consider the case of bc; unpad, with (?, ) terminal
in
?
P
bc;unpad
(where  is the null string of length
0). For distinct fluents a and b ? ?, there are 13
strings s ? P
bc;unpad
({a, b}) such that
({a}, a )? ({a, b}, s)? ({b}, b ))
corresponding to the 13 interval relations in Allen
1983 (Fernando 2007).
The explosion of solutions s
??
? P
f
(A ? B) to
the equations
f
A
(s
??
) = s and f
B
(s
??
) = s
?
given
(A, s) ? (A ?B, f
B
(s)) ? (B, s
?
)
(i.e., f
B
(s) = f
A
(s
?
)) is paralleled by the trans-
formation, under f , of a language L to
L
f
:= f
?1
fL
used to turn the superposition L&L
?
of languages
L and L
?
into
L &
f
L
?
:= f(L
f
& L
?
f
).
For f := bc; unpad, the set a &
f
b consists of
the 13 strings mentioned above. (We follow the
usual practice of conflating a string s with the sin-
gleton language {s} whenever convenient.)
Stepping from strings to languages, we lift the
presheaf P
f
to the presheaf Q
f
mapping A ?
Fin(?) to
Q
f
(A) := {fL | L ? (2
A
)
?
}
and a Fin(?)
op
-morphism (B,A) to the function
Q
f
(B,A) := (?L ? Q
f
(B)) f
A
L
sending L ? Q
f
(B) to f
A
L ? Q
f
(A). Then,
for non-identity morphisms between
?
Q
f
-objects
(A,L) and (A,L
?
) where L ? L
?
, we add in-
clusions from (A,L) to (A,L
?
) to the
?
Q
f
-
morphisms for the category C(?, f) with
- objects the same as those in
?
Q
f
, and
- morphisms (B,L
?
, A, L) from objects
(B,L
?
) to (A,L) whenever A ? B and
f
A
L
?
? L.
67
As is the case with
?
Q
f
-morphisms, the sources
(domains) of C(?, f)-morphisms entail their tar-
gets (codomains). To make these entailments pre-
cise, we can identify the space of possible worlds
with the inverse limit of P
f
, and reduce (A,L) to
[[A,L]]
f
:= {p ? lim
??
P
f
|
(?s ? L) p(A) = (A, s)}.
The inclusion
[[B,L
?
]]
f
? [[A,L]]
f
can then be pronounced: (B,L
?
) f -entails (A,L).
Proposition 4. Let f be a ?-preserving function
and (A,L) and (B,L
?
) be
?
Q
f
-objects such that
A ? B. (B,L
?
) f -entails (A,L) iff there is a
C(?, f)-morphism from (B,L
?
) to (A,L).
Relaxing the assumption A ? B, one can also
check that for f ? {bc, unpad, (bc; unpad)}, pull-
backs of
(A,L)? (A ?B, (f
?
L) ? f
?
L
?
)? (B,L
?
)
in C(?, f) are given by
(A,L)? (A ?B,L&
f
L
?
)? (B,L
?
) (3)
although (3) need not hold for L&
f
L
?
to be well-
defined.
3 Constraints and finite automata
We now bring finite automata into the picture, re-
calling from section 1 Example C?s superpositions
a
1
? ? ? a
n
& q
1
? ? ? q
n
(4)
where a
1
? ? ? a
n
is accepted by a finite automaton
A going through the sequence q
1
? ? ? q
n
of (inter-
nal) states. We can assume the tape alphabet A ?
{a
1
, . . . , a
n
} and the state set Q ? {q
1
, . . . , q
n
}
are two disjoint subsets of the set ? of fluents; flu-
ents in A are ?observable? (on a tape), while flu-
ents in Q are ?hidden? (inside a black box). Dis-
joint though they may be,A andQ are tightly cou-
pled byA?s transition table ? ? Q?A?Q (not to
mention the other components of A, its initial and
final states). That coupling can hardly be recreated
by superposition & (or some simple modification
&
f
) without the help of some machinery encoding
?. But first, there is the small matter of formulat-
ing the map a
1
? ? ? a
n
7? a
1
? ? ? a
n
implicit in
(4) above as a natural transformation.
3.1 Bottom ? naturally
If the function ?
A
such that for a
1
? ? ? a
n
? A
?
,
?
A
(a
1
? ? ? a
n
) = a
1
? ? ? a
n
is to be the A-th component of a natural trans-
formation ? : S ? P
id
, we need to specify
the presheaf S on Fin(?). To form a function
S(B,A) : S(B) ? S(A) for A ? B ? Fin(?)
with B
?
? S(B) and A
?
? S(A), it is handy to
introduce a bottom ? for B ?A, adjoining ? to a
finite subset X of ? for X
?
:= X + {?} before
forming the strings in S(X) := X
?
?
. We then set
S(B,A) : B
?
?
? A
?
?
S(B,A)() := 
S(B,A)(?s) :=
{
? S(B,A)(s) if ? ? A
?
? S(B,A)(s) otherwise
(e.g. S({a, b}, {a})(ba?) = ?a?) and let ?
A
:
A
?
?
? (2
A
)
?
map  to itself, and
?
A
(?s) :=
{
?
A
(s) if ? = ?
? ?
A
(s) otherwise
(e.g. ?
{a}
(?a?) = a ).
Proposition 5. ? is a natural transformation
from S to P
id
.
3.2 Another presheaf and category
Turning now to finite automata, we recall a funda-
mental result about languages that are regular (i.e.,
accepted by finite automata),
3
the B?uchi-Elgot-
Trakhtenbrot theorem (e.g. Thomas 1997)
for every finite alphabet A 6= ?, a language
L ? A
+
is regular iff there is a sentence ? of
MSO
A
such that
L = {s ? A
+
| s |=
A
?} .
MSO
A
is Monadic Second Order logic with a
unary relation symbol U
a
for each a ? A, plus a
binary relation symbol S for successors. The pred-
icate |=
A
treats a string a
1
a
2
? ? ? a
n
over A as an
MSO
A
-model with universe {1, 2, . . . , n}, U
a
as
its subset {i | a
i
= a}, and S as
{(1, 2), (2, 3), . . . , (n? 1, n)}
3
Whether or not this sense of regular has an interesting
connection with regular categories (which are, among other
things, finitely complete), I do not know.
68
so that, for instance,
a
1
? ? ? a
n
|=
A
?x?y S(x, y) iff n ? 2 (5)
for all finite A 6= ?. Notice that no a ? A is
required to interpret ?x?y S(x, y), which after all
is an MSO
?
-sentence suited to strings ?
n
? S(?).
Furthermore, for a 6= b and {a, b} ? A,
no string in A
+
satisfies ?x U
a
(x) ? U
b
(x) (6)
which makes it awkward to extend |=
A
to formulas
with free variables (requiring variable assignments
on top of strings in A
+
).
A simple way to accommodate variables is to
include them in A and interpret MSO
A
-formulas
not over A
+
but over (2
A
)
+
, lifting |=
A
from
strings s over A to a predicate |=
A
on strings over
2
A
such that
s |=
A
? iff ?
A
(s) |=
A
? (7)
for every MSO
A
-sentence ? (Fernando 2013a).
For all s ? (2
A
)
+
, we set
s |=
A
S(x, y) iff ?
{x,y}
(s) ?
?
x y
?
(8)
for A ? {x, y}, and
s |=
A
U
a
(x) iff ?
{a,x}
(s) ? E
a
a, x E
a
(9)
forA ? {a, x}, where E
a
:= ( + a )
?
. We must
be careful to incorporate into the clauses defining
s |=
A
? the presupposition that each first-order
variable x free in ? occurs uniquely in s ? i.e.
s |=
A
x = x where
s |=
A
x = y iff ?
{x,y}
(s) ?
?
x, y
?
(10)
for x, y ? A. In particular, we restrict negation
?? to strings |=
A
-satisfying x = x, for each first-
order variable x free in ?. We can then put
s |=
A
?x ? iff (?s
?
) ?
A
(s
?
) = ?
A
(s)
and s
?
|=
A?{x}
?
and similarly for second-order existential quantifi-
cation. The equivalence (5) above then becomes
s |=
A
?x?y S(x, y) iff ?
?
(s) ?
+
(11)
and in place of (6), we have
s |=
A
?x U
a
(x) ? U
b
(x) iff ?
{a,b}
(s) ?
(2
{a,b}
)
?
a, b (2
{a,b}
)
?
(12)
for a, b ? A.
Working back from (7)
s |=
A
? iff ?
A
(s) |=
A
?
to the B?uchi-Elgot-Trakhtenbrot theorem, one can
check that for every finite A and MSO
A
-formula
?, the set
L
A
(?) := {s ? (2
A
)
+
| s |=
A
?}
of strings over 2
A
that |=
A
-satisfy ? is regular, us-
ing the fact that for all A
?
? A, the restriction
of ?
A
?
to (2
A
)
?
is computable by a finite state
transducer. But for A ? ?,
4
?
A
?
 (2
A
)
?
is just
P
id
(A,A
?
). In recognition of the role of these
functions in |=
A
, we effectivize the presheaf Q
id
from ?2.3 as follows. Let R
?
be the presheaf on
Fin(?) mapping
- A ? Fin(?) to the set of languages over the
alphabet 2
A
that are regular
R
?
(A) := {L ? Q
id
(A) | L is regular}
and
- a Fin(?)
op
-morphism (B,A) to the restric-
tion of Q
id
(B,A) to R
?
(B)
R
?
(B,A) := (?L ? R
?
(B)) ?
A
L.
?
R
?
-objects are then pairs (A,L) where A ?
Fin(?) and L is a regular language over the al-
phabet 2
A
, while
?
R
?
-morphisms are quadru-
ples (B,L,A, ?
A
L) from (B,L) to (A, ?
A
L) for
A ? B ? Fin(?). To account for the Boolean op-
erations in MSO (as opposed to the predications
(8)? (10) involving ?
A
), we add inclusions for a
category R(?) with
- the same objects as
?
R
?
- morphisms all of those in C(?, id) be-
tween objects in
?
R
?
? i.e., quadruples
(B,L
?
, A, L) such that A ? B ? Fin(?),
L
?
? (2
B
)
?
is regular, L ? (2
A
)
?
is regular,
and ?
A
L
?
? L.
Let us agree to write
(B,L
?
) ; (A,L)
4
Note an MSO
A
-formula ? is not strictly a fluent in ? but
is formed in part from fluents.
69
to mean (B,L
?
, A, L) is a R(?)-morphism.
Clearly, for s ? (2
A
)
+
, A
?
? A and L ? (2
A
?
)
+
,
?
A
?
(s) ? L iff (A, {s}) ; (A
?
, L).
In particular, for x ? A and s ? (2
A
)
+
,
s |=
A
x = x iff (A, {s}) ; ({x},
?
x
?
)
and similarly for x = x replaced by the differ-
ent MSO
A
-formulas specified in clauses (8)?(12)
above. The MSO
A
-sentence
spec(A) := ?x
?
a?A
(U
a
(x) ?
?
b?A?{a}
?U
b
(x))
associating a unique a ? A with each string po-
sition (presupposed in |=
A
but not in |=
A
) fits the
same pattern
s |=
A
spec(A) iff ?
A
(s) ? { a | a ? A}
+
iff (A ? voc(s), {s}) ;
(A, { a | a ? A}
+
)
iff ?
A
(s) ? ?
A
A
+
.
Let us define a string s ? Fin(?)
+
to be
- A-specified if s |=
A
spec(A)
- A-underspecified if ?
A
(s) ? ?
A
(A
?
+
?A
+
)
- A-overspecified if ?
A
(s) 6? image(?
A
)
so that for a 6= a
?
and A = {a, a
?
}, a a is A-
specified, a is A-underspecified, and a, a
?
a
is A-overspecified. Given a finite automaton A
over A with set Q of states, its set AcRun(A) of
accepting runs (Example C) is both A-specified
and Q-specified, provided A ? Q = ? (and other-
wise risks being A-overspecified). The language
accepted by A is the ?
?1
A
-image of the language
?
A
AcRun(A) that is Q-underspecified, in accor-
dance with the intuition that the states are hidden.
From the regularity of AcRun(A), however, it is
clear that we can make these states visible, with
AcRun(A) as the language accepted by a finite au-
tomaton A
?
(over 2
A?Q
) that may (or may not)
have the same set Q of states.
The maps ?
A
and inclusions ? underlying the
morphisms of R(?) represent the two ways in-
formation may grow from
?
R
?
-objects (A,L)
to (B,L
?
) ? expansively with A ? B and L =
?
A
L
?
, and eliminatively with L
?
? L and A = B.
The same notion of f -entailment defined in ?2.3
through the sets [[A,L]]
f
applies, but we have been
careful here to fix f to id, in view of
Proposition 6. For A ? B ? Fin(?), ? an
MSO
A
-formula and s ? (2
B
)
+
,
s |=
B
? iff ?
A
(s) |=
A
?.
Proposition 6 says that s |=
B
? depends only on
the part ?
A
(s) of s mentioned in ?. It is a par-
ticular instance of the satisfaction condition in in-
stitutions, expressing the invariance of truth under
change of notation (Goguen and Burstall 1992).
Proposition 6 breaks down if we replace ?
A
by
bc
A
or unpad
A
, as can be seen with A = ?, and
? = ?x?y S(x, y), for which recall (11).
3.3 Varying grain and span
Troublesome as they are, the maps bc
A
and
unpad
A
have some use. Just as we can vary tem-
poral grain through bc (Examples A and B in sec-
tion 1), we can vary temporal span through unpad.
For instance, we can combine runs of automataA
1
over A
1
and A
2
over A
2
in
L(A
1
,A
2
) := AcRun(A
1
) &
unpad
AcRun(A
2
)
with the subscript unpad on & relaxing the re-
quirement thatA
1
andA
2
start and finish together
(running in lockstep throughout). For i ? {1, 2},
and Q
i
the state set for A
i
,
AcRun(A
i
) = unpad
A
i
?Q
i
L(A
1
,A
2
)
assuming the sets A
1
, A
2
, Q
1
and Q
2
are pair-
wise disjoint. The disjointness assumption rules
out any communication (or interference) between
A
1
and A
2
. As subsets of one large set ? of
fluents, however, it is perfectly natural for these
sets to intersect (and communicate through a com-
mon vocabulary), and we might express very par-
tial constraints involving them through, for ex-
ample, MSO-formulas. Recalling the definition
L
A
(?) := {s ? (2
A
)
+
| s |=
A
?}, we can rewrite
the satisfaction condition
s |=
B
? iff f
A
(s) |=
A
?
on MSO
A
-formulas ?, A ? B ? Fin(?) and s ?
(2
B
)
+
as
L
B
(?) = {s ? (2
B
)
+
| f
A
(s) ? L
A
(?)}.
This equation lifts any regular language L
A
(?) to
a regular languageL
B
(?), provided f is computed
by a finite-state transducer (as in the case of bc or
unpad). Inverse images under such relations are a
useful addition to the stock of operations constitut-
ing MSO-formulas as well as regular expressions.
70
References
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. C. ACM, 26(11):832?843.
Michael Bennett and Barbara Partee. 1972. Toward the
logic of tense and aspect in English. Technical re-
port, System Development Corporation, Santa Mon-
ica, California. Reprinted in Partee 2008.
Robin Cooper. 2012. Type theory and semantics in flux.
In Handbook of the Philosophy of Science. Volume
14: Philosophy of Linguistics. pages 271?323.
David R. Dowty. 1979. Word Meaning and Montague
Grammar. Reidel, Dordrecht.
Tim Fernando. 2004. A finite-state approach to events
in natural language semantics. J. Logic and Compu-
tation, 14(1):79?92.
Tim Fernando. 2007. Observing events and situations
in time. Linguistics and Philosophy 30(5):527?550.
Tim Fernando. 2008. Branching from inertia worlds. J.
Semantics 25(3):321?344.
Tim Fernando. 2011. Regular relations for temporal
propositions. Natural Language Engineering 17(2):
163?184.
Tim Fernando. 2013a. Finite state methods and descrip-
tion logics Proceedings of the 11th International
Conference on Finite State Methods and Natural
Language Processing, pages 63 ? 71.
Tim Fernando. 2013b. Dowty?s aspect hypothesis seg-
mented. Proceedings of the 19th Amsterdam Collo-
quium, pages 107 ? 114.
Danny Fox and Martin Hackl. 2006. The universal
density of measurement. Linguistics and Philosophy
29(5): 537 ? 586.
Joseph Goguen and Rod Burstall. 1992., Institutions:
Abstract model theory for specification and pro-
gramming, J. ACM, 39(1):95?146.
Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer.
Christopher Kennedy. 2001. Polar opposition and the
ontology of degrees. Linguistics and Philosophy 24.
33 ? 70.
Ewan Klein and Michael Rovatsos. 2011. Temporal
Vagueness, Coordination and Communication In
Vagueness in Communication 2009, LNAI 6517,
pages 108?126.
Wolfgang Klein. 2009. How time is encoded. In W.
Klein and P. Li, editors, The Expression of Time,
pages 39 ? 81, Mouton De Gruyter.
Saunders Mac Lane and Ieke Moerdijk. 1992. Sheaves
in Geometry and Logic: A First Introduction to
Topos Theory. Springer.
Richard Montague. 1973. The proper treatment of
quantification in ordinary English. In Approaches to
Natural Language, pages 221 ? 42. D. Reidel, Dor-
drecht.
Ian Pratt-Hartmann. 2005. Temporal prepositions and
their logic. Artificial Intelligence 166: 1?36.
Roger Schwarzschild and Karina Wilkinson. 2002.
Quantifiers in comparatives: A semantics of de-
gree based on intervals. Natural Language Seman-
tics 10(1):1?41.
Stephanie Solt. 2013. Scales in natural language.
Manuscript.
Wolfgang Thomas. 1997. Languages, automata and
logic. In Handbook of Formal Languages: Beyond
Words, volume 3, pages 389 ? 455. Springer-Verlag.
71
Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 89?96,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Propositions, Questions, and Adjectives: a rich type theoretic approach
Jonathan Ginzburg
CLILLAC-ARP
& Laboratoire d?Excellence (LabEx)?Empirical Foundations of Linguistics
Universit?e Paris-Diderot, Sorbonne Paris-Cit?e
yonatan.ginzburg@univ-paris-diderot.fr
Robin Cooper Tim Fernando
University of Gothenburg Trinity College, Dublin
cooper@ling.gu.se Tim.Fernando@cs.tcd.ie
Abstract
We consider how to develop types cor-
responding to propositions and questions.
Starting with the conception of Proposi-
tions as Types, we consider two empirical
challenges for this doctrine. The first re-
lates to the putative need for a single type
encompassing questions and propositions
in order to deal with Boolean operations.
The second relates to adjectival modifica-
tion of question and propositional entities.
We partly defuse the Boolean challenge
by showing that the data actually argue
against a single type covering questions
and propositions. We show that by ana-
lyzing both propositions and questions as
records within Type Theory with Records
(TTR), we can define Boolean operations
over these distinct semantic types. We ac-
count for the adjectival challenge by em-
bedding the record types defined to deal
with Boolean operations within a theory of
semantic frames formulated within TTR.
1 Introduction
Propositions as types has long been viewed as a
sine qua non of many a type theoretic approach to
semantics (see e.g., the seminal work of (Ranta,
1994)). Although this has lead to a variety of
very elegant formal accounts, one can question its
appropriateness as a type for NL propositions?
the denotata of declaratives and of nouns such as
?claim? and the objects of assertion. One imme-
diate issue concerns semantic selection?how to
specify the semantic types of predicates such as
?believe? and ?assert? so that they will not select
for e.g., the type of biscuits or the type of natural
numbers, given their inappropriateness as objects
of belief or assertion. However, one resolves this
issue, we point to two other significant challenges:
1. Recently there have been a number of pro-
posals that questions and propositions are of a
single ontological category (see (Nelken and
Francez, 2002; Nelken and Shan, 2006)) and
most influentially work in Inquisitive Seman-
tics (IS) (Groenendijk and Roelofsen, 2009).
A significant argument for this is examples
like (1), where propositions and questions
can apparently be combined by boolean con-
nectives.
(1) If Kim is not available, who should
we ask to give the talk?
In Inquisitive Semantics, such data are han-
dled by postulating a common type for ques-
tions and propositions as sets of sets of
worlds. It is not a priori clear how propo-
sitions as types can account for such cases.
2. Adjectives pose a challenge to all existing
theories of questions and propositions, pos-
sible worlds based (e.g., (Karttunen, 1977;
Groenendijk and Stokhof, 1997; Groenendijk
and Roelofsen, 2009), or type theoretic, as in
Type Theory with Records (TTR, (Cooper,
2012; Ginzburg, 2012)). There is nothing
in the semantic entity associated with a po-
lar question as in (2), be it a two cell parti-
tion (as in partition semantics) or a constant
function from records into propositions (as in
Ginzburg 2012) that will allow it to distin-
guish difficult from easy questions. Similarly,
since the denotation of a question is not con-
ceived as an event, this denotation is not ap-
propriate for the adjective quick:
(2) A: I have a quick question: is every
number above 2 the sum of two
primes?
B: That?s a difficult question.
89
And yet, these two distinct classes of adjec-
tives can simultaneously apply to a question
together with ?resolved?, a target of all exist-
ing theories of questions, as in (3), calling for
a unified notion of question:
(3) The quick question you just posed
is difficult and for the moment unre-
solved.
?Difficult? and ?silly? apply to both proposi-
tional and question entities, suggesting the
need for a unified meaning for the adjective
and a means of specifying its selection so
that it can modify both questions and propo-
sitions:
(4) a. silly claim (a claim silly to assert)
b. silly question (a question silly to
ask);
c. difficult claim (a claim difficult to
prove)
In this paper we partly defuse the Boolean
challenge by showing that the data actually ar-
gue against a single type covering questions and
propositions. We show that by analyzing both
propositions and questions as records within TTR,
we can define Boolean operations over these dis-
tinct semantic types. We then propose to deal
with the adjectival challenge by embedding the
types initially defined within a theory of semantic
frames (Fillmore, 1985; Pustejovsky, 1995) for-
mulated within TTR.
2 Questions and Propositions: a unified
semantic type?
Although there has been a recent trend to assume
a commonality of type for questions and propo-
sitions, both Hamblin and Karttunen gave argu-
ments for distinguishing questions as an ontologi-
cal category from propositions?(Hamblin, 1958)
pointing out that interrogatives lack truth values;
to which one can add their incompatibility with a
wider scoping alethic modality:
(5) a. It?s true/false who came yesterday
b. # Necessarily, who will leave tomorrow?
Whereas (Karttunen, 1977) pointed to the exis-
tence of predicates that select interrogatives, but
not for declaratives and vice versa:
(6) a. Bo asked/investigated/wondered/#
believed /# claimed who came yesterday.
b. Bo # asked/# investigated/# wondered/
believed /claimed that Mary came yester-
day.
We argue that although speech acts involving
questions and propositions can be combined by
boolean connectives they are not closed under
boolean operations. Furthermore, we argue that
the propositions and questions qua semantic ob-
jects cannot be combined by boolean operations
at all. This, together with the examples above,
strongly suggests that questions and propositions
are distinct types of semantic objects.
We use embedding under attitude verbs as a test
for propositions and questions as semantic objects.
Here we do not find mixed boolean combinations
of questions and propositions. Thus, for exam-
ple, wonder selects for an embedded question and
believe for an embedded proposition but a mixed
conjunction does not work with either, showing
that it is neither a question nor a proposition:
(7) The manager *wonders/*believes that
several people left and what rooms we
need to clean.
The verb know is compatible with both
interrogative and declarative complements,
though(Vendler, 1972; Ginzburg and Sag, 2000)
argue that such predicates do not take questions or
propositions as genuine arguments (i.e. not purely
referentially), but involve coercions which leads
to a predication of a fact. The well formedness
of these coercion processes require that sentences
involving decl/int conjunctions such as (8) can
only be understood where the verb is distributed
over the two conjuncts: ?knows that John?s smart
and knows what qualifications he has?:
(8) The manager knows that John?s smart and
what qualifications he has.
Compare (9a,b)?in the second mixed case
there is only a reading which entails that it is sur-
prising the conference was held at the usual time
whereas arguably in the first sentence only the
conjunction but not the individual conjuncts need
be surprising.
(9) a. It?s surprising that the conference was
held at the usual time and so few people
registered.
90
b. It?s surprising that the conference was
held at the usual time and how few peo-
ple registered.
Embedded conditional questions are impossible
although, of course, embedded questions contain-
ing conditionals are fine:
(10) *The manager wonders if Hollande left,
whether we need to clean the west wing.
a. The manager wonders whether, if Hol-
lande left, we need to clean the west wing.
Why, then, do apparent mixed boolean com-
binations appear in root sentences? Our answer
is that natural language connectives, in addition
to their function as logical connectives combin-
ing propositions, can be used to combine speech
acts into another single speech act. This, however,
can only be expressed in root sentences and speech
acts are not closed under operations correspond-
ing to boolean connectives. For example in (11a),
where a query follows an assertion is fine whereas
the combination of an assertion with a preceding
query is not, as in (11b):
(11) a. John?s very smart but does he have any
qualifications?
b. *Does John have any qualifications
and/but he?s smart
This is puzzling because a discourse corre-
sponding to a string of the same separate speech
acts works well:
(12) Does John have any qualifications? (no
answer) But he?s smart.
Similarly, while we can apparently conditionalize
a query with a proposition, we cannot conditional-
ize an assertion with a question, nor can we condi-
tionalize a query with a question:
(13) a. If Hollande left, do we need to clean the
west wing? ( ?If Hollande left, I ask you
whether we need to clean the west wing?),
b. *If whether Hollande left/did Hollande
leave, we need to clean the west wing?
c. *If who left, do we need to clean the west
wing?
However we treat these facts, it seems clear that
it would be dangerous to collapse questions and
propositions into the same type of semantic object
and allow general application of semantic boolean
operators. This would seem to force you into a sit-
uation where you have to predict acceptability of
these sentences purely on the basis of a theory of
syntax, although semantically/pragmatically they
would have made perfect sense. It seems to us that
distinguishing between questions and propositions
and combinations of speech acts offers a more ex-
planatory approach.
3 Austinian Types for Propositions and
Questions
3.1 TTR as synthesizing Constructive Type
Theory and Situation Semantics
The system we sketch is formulated in TTR
(Cooper, 2012). TTR is a framework that draws its
inspirations from two quite distinct sources. One
source is Constructive Type Theory, whence the
repertory of type constructors, and in particular
records and record types, and the notion of wit-
nessing conditions. The second source is situa-
tion semantics (Barwise and Perry, 1983; Barwise,
1989) which TTR follows in viewing semantics as
ontology construction. This is what underlies the
emphasis on specifying structures in a model the-
oretic way, introducing structured objects for ex-
plicating properties, propositions, questions etc. It
also takes from situation semantics an emphasis on
partiality as a key feature of information process-
ing. This aspect is exemplified in a key assumption
of TTR?the witnessing relation between records
and record types: the basic relationship between
the two is that a record r is of type RT if each
value in r assigned to a given label l
i
satisfies the
typing constraints imposed by RT on l
i
:
(14) record witnessing
The record:
?
?
?
?
?
?
l
1
= a
1
l
2
= a
2
. . .
l
n
= a
n
?
?
?
?
?
?
is of type:
?
?
?
?
?
?
l
1
: T
1
l
2
: T
2
(l
1
)
. . .
l
n
: T
n
(l
1
, l
2
, . . . , l
n?1
)
?
?
?
?
?
?
91
iff a
1
: T
1
, a
2
: T
2
(a
1
), . . . , a
n
:
T
n
(a
1
, a
2
, . . . , a
n?1
)
This allows for cases where there are fields in
the record with labels not mentioned in the record
type. This is important when e.g., records are used
to model contexts and record types model rules
about context change?we do not want to have to
predict in advance all information that could be
in a context when writing such rules. (15) illus-
trates this: the record (15a) is of the type (15b),
though the former has also a field for FACTS;
(15b) constitutes the preconditions for a greeting,
where FACTS?the contextual presuppositions?
has no role to play.
(15) a.
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
spkr = A
addr = B
utt-time = t1
c1 = p1
Moves =
??
qud =
{}
facts = cg1
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
b.
?
?
?
?
?
?
?
?
?
?
?
?
?
spkr : IND
addr : IND
utt-time : TIME
c1 : addressing(spkr,addr,utt-time)
Moves =
??
: list(LocProp)
qud =
{}
: set(Question)
?
?
?
?
?
?
?
?
?
?
?
?
?
3.2 Propositions
Our starting point is the situation semantics no-
tion of an Austinian proposition (Barwise and
Etchemendy, 1987). (Ginzburg, 2012) introduces
Austinian propositions as records of the form:
(16)
[
sit = s
sit-type = T
]
This gives us a type theoretic object correspond-
ing to a judgement. The type of Austinian proposi-
tions is the record type (17a),where the type Rec-
Type
?
is a basic type which denotes the type of
(non-dependent) record types closed under meet,
join and negation.
1
Truth conditions for Austinian
1
When we say ?the type of record types?, this should be
understood in a relative, not absolute way. That is, this means
the type of record types up to some level of stratification, oth-
erwise foundational problems such as russellian paradoxes
can potentially ensue. See (Cooper, 2012) for discussion and
a more careful development.
propositions are defined in (17b):
(17) a. AustProp =
def
[
sit : Rec
sit-type : RecType
?
]
b. A proposition p =
[
sit = s
0
sit-type = ST
0
]
is true iff
s
0
: ST
0
We introduce negative types by the clause in
(18a). Motivated in part by data concerning nega-
tive perception complements ((Barwise and Perry,
1983; Cooper, 1998), we can characterize wit-
nesses for negative types by (18b).
(18) a. If T is a type then ?T is a type
b. a : ?T iff there is some T
?
such that a : T
?
and T
?
precludes T . We assume the exis-
tence of a binary, irreflexive and symmet-
ric relation of preclusion which satisfies
also the following specification:
T
?
precludes T iff either (i) T = ?T
?
or,
(ii) T, T
?
are non-negative and there is no
a such that a : T and a : T
?
for any mod-
els assigning witnesses to basic types and
p(red)types
(19a) and (19b) follow from these two defini-
tions:
(19) a. a : ??T iff a : T
b. a : T ??T is not necessary (a may not be
of type T and there may not be any type
which precludes T either).
Thus this negation is a hybrid of classical and
intuitionistic negation in that (19a) normally holds
for classical negation but not intuitionistic whereas
(19b), that is failure of the law of the excluded
middle, normally holds for intuitionistic negation
but not classical negation.
The type of negative (positive) Austinian propo-
sitions can be defined as (20a,b), respctively:
(20) a.
[
sit : Rec
sit-type : RecType
??
]
b.
[
sit : Rec
sit-type : RecType
]
92
If p:Prop and p.sit-type is T
1
? T
2
(T
1
? T
2
) we say that p is the conjunction
(disjunction) of
[
sit = p.sit
sit-type = T
1
]
and
[
sit = p.sit
sit-type = T
2
]
.
3.3 Questions
Extensive motivation for the view of questions
as propositional abstracts has been provided in
(Ginzburg, 1995; Ginzburg and Sag, 2000)?TTR
contributes to this by providing an improved no-
tion of simultaneous, restricted abstraction: A (ba-
sic, non-compound) question is a function from
records into propositions. In particular, a polar
question is a 0-ary propositional abstract, which
in TTR makes it a constant function from the uni-
verse of all records into propositions. We pro-
pose a refinement of this view which we believe
maintains the essential insights of the proposi-
tional function approach, motivated in part by the
need to enable conjunction and disjunction to be
defined for questions.
We introduce a notion of Austinian questions
defined as records containing a record and a func-
tion into record types, the latter associated with
the label ?abstr(act)?. The role of wh-words on
this view is to specify the domains of these func-
tions; in the case of polar questions there is no re-
striction, hence the function component of such a
question is a constant function. (21) exemplifies
this for a unary ?who? question and a polar ques-
tion:
(21) a. Who =
[
x
1
: Ind
c1 : person(x
1
)
]
; Whether = Rec;
b. ?Who runs? 7?
?
?
sit =r
1
abstr = ?r:Who(
[
c : run(r.x
1
)
]
)
?
?
;
c. ?Whether Bo runs? 7?
?
?
sit =r
1
abstr = ?r:Whether(
[
c : run(b)
]
)
?
?
We characterize the type AustQuestion within
TTR by means of the parametric type given in
(22); the parametric component of the type char-
acterizes the range of abstracts that build up ques-
tions:
(22) AustQuestion(T) =
def
[
sit : Rec
abstr : (T ? RecType)
]
Given this, we define the following relation be-
tween a situation and a function, which is the ba-
sis for defining key coherence answerhood no-
tions such as resolvedness and aboutness (weak
partial answerhood (Ginzburg and Sag, 2000))
and question dependence (cf. erotetic implica-
tion,(Wi?sniewski, 2001)):
(23) s resolves q, where q is ?r : (T
1
)T
2
, (in
symbols s?q) iff either
(i) for some a : T
1
s : q(a),
or
(ii) a : T
1
implies s : ?q(a)
Austinian questions can be conjoined and dis-
joined though not negated. The definition for
conj/disj-unction, from which it follows that q
1
and (or) q
2
is resolved iff q
1
is resolved and (or)
q
2
is resolved, is as follows:
(24)
[
sit = s
abstr = ?r : T
1
(T
2
)
]
? (?)
[
sit = s
abstr = ?r : T
3
(T
4
)
]
=
?
?
?
?
?
?
?
sit = s
abstr = ?r:
[
left:T
1
right:T
3
]
(q
1
(r.left) ? (?)q
2
(r.right))
?
?
?
?
?
?
?
Following (Cooper and Ginzburg, 2012)) we ar-
gue that ?negative questions? involve questions re-
lating to negative propositions rather than nega-
tions of positive questions. As Cooper and
Ginzburg show, such negative questions are cru-
cially distinct from the corresponding positive
question. Since we have a clear way of distin-
guishing negative and positive propositions, we do
not conflate positive and negative polar questions.
4 Connectives in dialogue
We assume a gameboard dialogue semantics
(Ginzburg, 2012) which keeps track of questions
under discussion (QUD). One of the central con-
versational rules in KoS is QSPEC, a conversa-
tional rule that licenses either speaker to follow
up q, the maximal element in QUD with asser-
tions and queries whose QUD update Depends on
93
q. These in turn become MaxQUD. Consequently,
QSPEC seems to be able to handle the commonest
case of successive questions, as in (25).
(25)
a. Ann: Anyway, talking of over the road,
where is she? Is she home?
Betty: No. She?s in the Cottage.
b. Arthur: How old is she? Forty?
Evelyn: Forty one!
Nonetheless, not all cases of successive ques-
tions do involve a second question which is a sub-
question of the first, as exemplified in (26):
(26) On the substantive front, we now have
preliminary answers to two key ques-
tions: What did the agency do wrong?
And who ordered it to target conservative
groups? Notwithstanding Miller?s resig-
nation, which the President himself an-
nounced on Tuesday evening, the answers
appear to be: not nearly as much as re-
cent headlines suggest; and, nobody in
the Obama Administration. (The New
Yorker, May 16, 2013)
In contrast to cases covered by QSPEC, these
cases are strange if the second question is posed
by the addressee of the first question?one gets the
feeling that the original question was ignored:
(27) A: What did the agency do wrong? B:
Who ordered it to target conservative
groups?
(Ginzburg, 2012) postulates an additional con-
versational rule that allows a speaker to follow up
an initial question with a non-influencing question,
where the initial question remains QUD-maximal.
We believes this basic treatment allows one to ex-
plain how the mixed cases involving conjunctions
of assertions and queries can be captured. and,but
and or can be used as discourse particles which
express a relationship between a speech act and
the one preceding it:
? and can indicate that the following question
is Independent of MaxQUD.
? but indicates that the following question
is not independent, but unexpected given
MaxQUD:
? John?s smart (no response) But what
qualifications does he have?
? John?s smart might be offered as an en-
thymematic argument (Breitholtz, 2011;
Breitholtz and Cooper, 2011) to a con-
clusion, e.g. ?we should hire John?. but
indicates that the answer to the ques-
tion might present an enthymematic ar-
gument against this conclusion.
? or can indicate that q1 addresses the same
ultimate issue as MaxQUD, so retain both
as MaxQUD; sufficient to address one issue
since it will resolve both simultaneously:
(28) a. Would you like coffee and biscuits
or would you like some fruit or a
piece of bread and jam or what do
you fancy?
b. are you gonna stay on another day or
what are you doing?
c. David Foster Wallace is overrated
or which novel by him refutes this
view?
5 Abstract Entities and Adjectives
How to deal with adjectival modification of propo-
sitional and question entities, exemplified in (3,4)
above? The extended notion of question required
can be explicated within Cooper 2012?s theory
of semantic frames, inspired by (Fillmore, 1985;
Pustejovsky, 1995). Neither Ty2 (Groenendijk and
Stokhof, 1997) nor inquisitive semantics in propo-
sitional or first order formulation support the de-
velopment of such an ontology. Cooper formu-
lates a frame as a record type (RT). In (29) we
exemplify a possible frame for question. Here,
the illoc role represents a question?s role in dis-
course, whereas the telic role describes the goal of
the process associated with resolving a question
? finding a resolving answer. The frame repre-
sents a ?default? view of a question, which vari-
ous in effect non-subsective adjectives can modify
(e.g., ?unspoken question? negates the existence
of an associated utterance, while ?open question?
negates the end point of the resolution event).
2
2
Here Resolve maps an austinian proposition and an aus-
tinian question to a predicate type. In a more detailed account
one would add an additional argument for an information
state, given the arguments that this notion is agent?relative
(Ginzburg, 1995) and much subsequent literature.
94
(29) Question =
def
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
T : Type
external : AustQuestion(T),
illoc :
?
?
?
?
u : Event
A : Ind
c2 : Ask(A,external,u)
?
?
?
?
telic :
[
p : AustProp
c1 : Resolve(p,external)
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
A type-driven compositional analysis is for-
mulated with adjectives as record type modifiers
(functions from RTs to RTs) that pick out frame el-
ements of the appropriate type (for a related view
cf. Asher & Luo 2012). For example, difficult
question has the record type in (30):
(30)
?
?
?
?
?
?
?
T : Type
external : AustQuestion
telic :
[
p : AustProp
c1 : difficult(Resolve(p,external))
]
?
?
?
?
?
?
?
Records and record types come with a well-
known notion of subtyping, often construed syn-
tactically (see e.g., (Betarte and Tasistro, 1998)).
However, given our ontological perspective on se-
mantics, we take a semantic perspective on sub-
typing (see e.g. (Frisch et al., 2008) for a detailed
exposition of such an approach.), wherein T < T
?
iff {s|s : T} ? {s|s : T
?
}. Given this, a record of
the type (29) above can be viewed as also having
type:
(31)
[
T : Type
external : AustQuestion(T)
]
This forms the basis of our account of how an
adjective such as difficult applies simultaneously
to question and to path. Difficult is specified as
in (32)? a function from record types subsumed
by the record type given in the domain whose
output involves a modification of the restriction
field of the telic role. This yields (32b) when
combined with question and (32c) when combined
with path:
3
(32) a. f : (RT <
?
?
?
?
?
external : Type
P : Type
telic :
[
c1 : P
]
?
?
?
?
?
)RT[P;difficult(P)]
3
Here difficult maps any type P into the predicate type
difficult(P ). One probably needs to narrow this specifica-
tion somewhat.
b.
?
?
?
?
?
?
?
T : Type
external : AustQuestion(T)
telic :
[
p : AustProp
c1 : difficult(Resolve(p,external))
]
?
?
?
?
?
?
?
c.
?
?
?
?
?
external : PhysTrajectory
telic :
[
a : Ind
c1 : difficult(Cross(a,external))
]
?
?
?
?
?
Turning to propositions, we postulate (33) as a
type for proposition. This allows us, for instance,
to specify the adjective silly as modifying along
the illoc dimension, thereby capturing silly claim
(a claim silly to assert) and silly question (a ques-
tion silly to ask); given the specification of the telic
dimension and our lexical entry for difficult, diffi-
cult claim is correctly predicted to mean ?a claim
difficult to prove?.
(33) Proposition =
def
?
?
?
?
?
?
?
?
?
?
?
?
?
external : AustProp,
illoc :
?
?
?
?
u : Event
A : Ind
c2 : Assert(A,external,u)
?
?
?
?
telic :
[
f : Fact
c1 : Prove(f,external)
]
?
?
?
?
?
?
?
?
?
?
?
?
?
Subject matter adjectives such as political, per-
sonal, moral, philosophical as in (34) lead us to
another intrinsic advantage for rich type theories
such as TTR over possible worlds based type the-
ories, relating to the types AustQuestion/Prop.
(34) a. A: Are you involved with Demi Lovato?
B: That?s a personal question.
b. A: One shouldn?t eat meat. B:
That?s a moral claim.
Subject matter adjectives target the external role
of a question/proposition. This can be explicated
on the basis of the predicate types which consti-
tute the sit-type (abstr type) field in propositions
(questions). Given the coarse granularity of possi-
ble worlds, it to unclear how to do so in ontologies
based on sets of possible worlds.
Acknowledgments
Earlier versions of portions of this work were
presented at the workshop Conference on Logic,
95
Questions and Inquiry (LoQI) in Paris and at a
course on TTR given in June 2013 in Gothen-
burg. We thanks audiences on those occasions, as
well as two anonymous referees for very stimu-
lating comments. This work is supported by the
French Investissements d?Avenir?Labex EFL pro-
gram (ANR-10-LABX-0083).
References
Jon Barwise and John Etchemendy. 1987. The Liar.
Oxford University Press, New York.
Jon Barwise and John Perry. 1983. Situations and At-
titudes. Bradford Books. MIT Press, Cambridge.
Jon Barwise. 1989. The Situation in Logic. CSLI Lec-
ture Notes. CSLI Publications, Stanford.
Gustavo Betarte and Alvaro Tasistro. 1998. Martin-
l?of?s type theory with record types and subtyping.
In G. Sambin and J. Smith, editors, 25 Years of Con-
structive Type Theory. Oxford University Press.
Ellen Breitholtz and Robin Cooper. 2011. En-
thymemes as rhetorical resources. In Ron Artstein,
Mark Core, David DeVault, Kallirroi Georgila, Elsi
Kaiser, and Amanda Stent, editors, SemDial 2011
(Los Angelogue): Proceedings of the 15th Workshop
on the Semantics and Pragmatics of Dialogue.
Ellen Breitholtz. 2011. Enthymemes under Discus-
sion: Towards a micro-rhetorical approach to dia-
logue modelling. In Proceedings of SPR-11 ILCLI
International Workshop on Semantics, Pragmatics,
and Rhetoric Donostia, 9-11 November 2011.
R. Cooper and J. Ginzburg. 2012. Negative inquisi-
tiveness and alternatives-based negation. In Maria
Aloni, Vadim Kimmelman, Floris Roelofsen, Gal-
itW. Sassoon, Katrin Schulz, and Matthijs West-
era, editors, Logic, Language and Meaning, volume
7218 of Lecture Notes in Computer Science, pages
32?41. Springer Berlin Heidelberg.
Robin Cooper. 1998. Austinian propositions,
davidsonian events and perception complements.
In Jonathan Ginzburg, Zurab Khasidashvili,
Jean Jacques Levy, Carl Vogel, and Enric Vallduvi,
editors, The Tbilisi Symposium on Logic, Language,
and Computation: Selected Papers, Foundations of
Logic, Language, and Information, pages 19?34.
CSLI Publications, Stanford.
Robin Cooper. 2012. Type theory and semantics in
flux. In Ruth Kempson, Nicholas Asher, and Tim
Fernando, editors, Handbook of the Philosophy of
Science, volume 14: Philosophy of Linguistics. El-
sevier, Amsterdam.
C.J. Fillmore. 1985. Frames and the semantics of un-
derstanding. Quaderni di semantica, 6(2):222?254.
Alain Frisch, Giuseppe Castagna, and V?eronique Ben-
zaken. 2008. Semantic subtyping: Dealing set-
theoretically with function, union, intersection, and
negation types. Journal of the ACM (JACM),
55(4):19.
Jonathan Ginzburg and Ivan A. Sag. 2000. Interrog-
ative Investigations: the form, meaning and use of
English Interrogatives. Number 123 in CSLI Lec-
ture Notes. CSLI Publications, Stanford: California.
Jonathan Ginzburg. 1995. Resolving questions, i. Lin-
guistics and Philosophy, 18:459?527.
Jonathan Ginzburg. 2012. The Interactive Stance:
Meaning for Conversation. Oxford University
Press, Oxford.
J. Groenendijk and F. Roelofsen. 2009. Inquisitive se-
mantics and pragmatics. In Meaning, Content, and
Argument: Proceedings of the ILCLI International
Workshop on Semantics, Pragmatics, and Rhetoric.
www. illc. uva. nl/inquisitive-semantics.
Jeroen Groenendijk and Martin Stokhof. 1997. Ques-
tions. In Johan van Benthem and Alice ter Meulen,
editors, Handbook of Logic and Linguistics. North
Holland, Amsterdam.
C. L. Hamblin. 1958. Questions. Australian Journal
of Philosophy, 36:159?168.
Lauri Karttunen. 1977. Syntax and semantics of ques-
tions. Linguistics and Philosophy, 1:3?44.
Rani Nelken and Nissim Francez. 2002. Bilattices and
the semantics of natural language questions. Lin-
guistics and Philosophy, 25:37?64.
Rani Nelken and Chung-Chieh Shan. 2006. A modal
interpretation of the logic of interrogation. Journal
of Logic, Language, and Information, 15:251?271.
James Pustejovsky. 1995. The Generative Lexicon.
MIT Press, Cambridge.
Aarne Ranta. 1994. Type Theoretical Grammar. Ox-
ford University Press, Oxford.
Zeno Vendler. 1972. Res Cogitans. Cornell University
Press, Ithaca.
Andrzej Wi?sniewski. 2001. Questions and inferences.
Logique et Analyse, 173:5?43.
96
