Coling 2010: Poster Volume, pages 1006?1013,
Beijing, August 2010
Expressing OWL axioms by English sentences: dubious in theory,
feasible in practice
Richard Power
Department of Computing
Open University
r.power@open.ac.uk
Allan Third
Department of Computing
Open University
a.third@open.ac.uk
Abstract
With OWL (Web Ontology Language) es-
tablished as a standard for encoding on-
tologies on the Semantic Web, interest
has begun to focus on the task of ver-
balising OWL code in controlled English
(or other natural language). Current ap-
proaches to this task assume that axioms
in OWL can be mapped to sentences in
English. We examine three potential prob-
lems with this approach (concerning log-
ical sophistication, information structure,
and size), and show that although these
could in theory lead to insuperable diffi-
culties, in practice they seldom arise, be-
cause ontology developers use OWL in
ways that favour a transparent mapping.
This result is evidenced by an analysis of
patterns from a corpus of over 600,000 ax-
ioms in about 200 ontologies.
1 Introduction
Since the adoption of OWL (Web Ontology Lan-
guage) as a standard in 2004, several research
groups have explored ways of mapping between
OWL and controlled English, with the aim of
presenting ontologies (both for viewing and edit-
ing) in natural language (Schwitter and Tilbrook,
2004; Kaljurand and Fuchs, 2007; Funk et al,
2007; Hart et al, 2008); this task has been called
ontology ?verbalisation? (Smart, 2008). To de-
velop generic methods for ontology verbalisation,
some kind of structural mapping is needed be-
tween the formal and natural languages, and the
assumption generally adopted has been a three-
tier model in which identifiers for atomic terms
(e.g., individuals, classes, properties) map to lexi-
cal entries, single axioms map to sentences, and
groups of related axioms map to higher textual
units such as paragraphs and sections. The pur-
pose of this paper is to look in detail at one level of
this model, the realisation of axioms by sentences,
and to check its feasibility through an analysis of
a large corpus of ontologies.
The input to a verbaliser is a file in one
of the standard formats such as OWL/RDF or
OWL/XML, containing axioms along with sup-
porting statements such as annotations. As ex-
amples of the nature of the input, table 1 shows
three axioms in OWL/XML format; without any
attempt at aggregation or pronominalisation, they
could be realised by the following sentences1:
Horatio Nelson is an admiral.
Horatio Nelson is the victor of the Battle of
Trafalgar.
Every admiral is commander of a fleet.
Without attempting anything like a full descrip-
tion of OWL, it will be useful to look more closely
at the structure of these expressions. Note first that
they are essentially in functor-argument form2. In
the first axiom, for example, there is a functor
called ClassAssertion with two arguments, one
a class and the other an individual; the mean-
ing of the axiom is that the individual belongs
to the class. The second functor (ObjectProp-
ertyAssertion) requires instead three arguments,
1Note that one limitation of OWL is that at present it con-
tains no treatment of time; we therefore have to fall back on
the historical present.
2In fact, there is an alternative format called OWL
Functional Syntax in which, for example, the first ax-
iom would be represented by a predication of the form
ClassAssertion(X,Y).
1006
<ClassAssertion>
<Class IRI="http://www.example.org#admiral"/>
<NamedIndividual IRI="www.example.org#HoratioNelson"/>
</ClassAssertion>
<ObjectPropertyAssertion>
<ObjectProperty IRI="http://www.example.org#victorOf"/>
<NamedIndividual IRI="http://www.example.org#HoratioNelson"/>
<NamedIndividual IRI="http://www.example.org#BattleOfTrafalgar"/>
</ObjectPropertyAssertion>
<SubClassOf>
<Class IRI="http://www.example.org#admiral"/>
<ObjectSomeValuesFrom>
<ObjectProperty IRI="http://www.example.org#commanderOf"/>
<Class IRI="http://www.example.org#fleet"/>
</ObjectSomeValuesFrom>
</SubClassOf>
Table 1: Examples of axioms in OWL/XML
and describes a relation (in OWL these are called
?properties?) holding between two individuals; the
third (SubClassOf) requires two arguments, both
classes, and asserts that the first class is a subclass
of the second.
Turning to the structure of the arguments, there
are two possibilities: either the argument is
atomic, in which case it will be represented by
an identifier (or a literal if it is a data value), or
it is complex, in which case it will be represented
by an OWL functor with arguments of its own.
Most of the arguments in table 1 are atomic, the
sole exception being the second argument of Sub-
ClassOf, which denotes a complex class meaning
?someone that is commander of a fleet?3. In gen-
eral, then, the OWL functors denote logical con-
cepts such as class membership and class inclu-
sion, while atomic terms denote domain-specific
concepts such as Nelson and admiral. A funda-
mental design decision of the Semantic Web is
that logical concepts are standardised, while do-
main concepts are left open: ontology developers
are free to name the class admiral in any way they
please, provided that the identifier takes the form
of an IRI (Internationalized Resource Identifier).
Given this distinction, the obvious strategy to
follow in developing a verbaliser is to divide lin-
guistic resources into two parts: (a) a generic set
3To be more precise we should say ?someone that is com-
mander of one or more fleets?; this kind of trade-off between
elegance and precision often arises in systems that verbalise
formal languages.
of rules for realising logical expressions (based
on standardised OWL functors); (b) a domain-
specific lexicon for realising atomic individuals,
classes and properties. This obviously raises the
problem of how to acquire the specialised lexicons
needed for each ontology. All else failing, these
would have to be crafted by hand, but provided
that we are not too concerned about text quality, a
provisional lexicon can often be derived automat-
ically from internal evidence within the ontology
(i.e., either from identifier names or annotation la-
bels)4.
Assuming that a lexicon for atomic terms can
be obtained (by fair means or foul), there remains
a question of whether we can find sentence pat-
terns which provide understandable realisations
of the logical patterns determined by (possibly
nested) OWL functors. In section 2 we show that
this is not guaranteed, for three reasons. First,
there may be OWL functors that represent logi-
cally sophisticated concepts which cannot be ex-
pressed in non-technical English. Secondly, an
OWL axiom may be hard to verbalise because
it lacks the right kind of information structure
(i.e., because it fails to make a statement about a
recognisable topic such as an individual or atomic
class). Finally, since arguments can be nested in-
definitely, an axiom might contain so much se-
4We have discussed elsewhere whether phrases derived in
this way provide suitable lexicalisations (Power, 2010), but
this topic lies outside the scope of the present paper.
1007
mantic complexity that it cannot be compressed
clearly into a single sentence. We then describe
(section 3) an empirical analysis of axiom pat-
terns from about 200 ontologies, which investi-
gates whether these potential problems are com-
mon in practice. Section 4 discusses the results,
and section 5 concludes.
2 Potential problems in verbalising
axioms
2.1 Logical sophistication
We show in table 2 the 16 most commonly used
OWL functors for expressing axioms, each ac-
companied by a simple English sentence illustrat-
ing what the functor means. As will be seen, the
functors divide into two groups. For those in the
upper segment, it is relatively easy to find En-
glish constructions that realise the logical content
of the axiom ? assuming we have suitable lexi-
calisations of the atomic terms. For those in the
lower segment, finding a good English realisation
is harder, since statements describing properties
are normally found only in the rarified worlds of
mathematics and logic, not in everyday discourse.
Our attempts to verbalise these axioms are accord-
ingly clumsy (e.g., through resorting to variables
like X and Y), and not even entirely precise (e.g.,
the sentence for FunctionalObjectProperty should
really specify ?For any X. . . ?); perhaps the reader
can do better.
Does this mean that our aim of realising OWL
axioms in non-technical English is doomed? We
would argue that this depends on how the axioms
describing properties are used in practice. First,
for any difficult axiom functor, it is important to
consider its frequency. If it turns out that a func-
tor accounts for (say) only one axiom in every
thousand, then it will give rise only to the occa-
sional clumsy sentence, not a text that is clumsy
through and through. Second, it is important to
take account of argument complexity. If a func-
tor is used invariably with atomic terms as argu-
ments, then the sentence expressing it will contain
only one source of complexity ? logical sophisti-
cation; if instead the functor has non-atomic argu-
ments, this additional strain might push it over a
threshold from difficult to incomprehensible. For-
tunately, OWL syntax requires that all property ar-
guments for the difficult functors are atomic ? for
FunctionalObjectProperty, for instance, the argu-
ment cannot be a complex property expression.
For statements about domains and ranges, how-
ever, class arguments can be non-atomic, so here
a complexity issue might arise.
2.2 Information structure
We learn at school that sentences have a sub-
ject (preferably simple) and predicate (relatively
complex), the purpose of the predicate being to
say something about the subject. This rather
simplified idea is developed technically in work
on information structure (Kruijff-Korbayova? and
Steedman, 2003) and centering theory (Walker et
al., 1998). Is there any equivalent to this topic-
comment distinction in OWL? Formally speak-
ing, one would have to answer in the negative.
The two-argument functor SubClassOf, for exam-
ple, can have class expressions of any complex-
ity in either argument position, and there is no
logical reason to claim that it is ?about? one of
these classes rather than the other. This is still
clearer in the case of EquivalentClasses, where
the functor is commutative (so that switching the
arguments leaves the meaning unchanged). Again
there seems to be a difficulty here ? and again
we argue that this difficulty might disappear, or at
least diminish, if we consider how OWL is used
in practice.
Suppose, for instance, that although OWL syn-
tax allows indefinitely complex arguments in ei-
ther position for the SubClassOf functor, in prac-
tice users invariably construct axioms in which the
first argument is an atomic term, with complex
expressions occurring (if at all) only in second-
argument position. This would strongly suggest,
in our view, that developers are assigning a topic-
comment structure to the two arguments, with the
first expressing the topic and the second express-
ing the comment. As we will show later in the
paper, this pattern is found overwhelmingly ? so
much so that in a sample of nearly half a million
SubClassOf axioms, fewer than 1000 instances
(0.2%) were found of non-atomic first arguments.
1008
Functor Example
SubClassOf Every admiral is a sailor
EquivalentClasses An admiral is defined as a person that commands a fleet
DisjointClasses No sailor is a landlubber
ClassAssertion Nelson is an admiral
ObjectPropertyAssertion Nelson is victor of the Battle of Trafalgar
DataPropertyAssertion The Battle of Trafalgar is dated 1805
ObjectPropertyDomain If X commands Y, X must be a person
ObjectPropertyRange If X commands Y, Y must be a fleet
SubObjectPropertyOf If X is a child of Y, X must be related to Y
InverseObjectProperties If X is a child of Y, Y must be a parent of X
TransitiveObjectProperty If X contains Y and Y contains Z, X must contain Z
FunctionalObjectProperty There can be only one Y such that X has as father Y
DataPropertyDomain If X is dated Y, X must be an event
DataPropertyRange If X is dated Y, Y must be an integer
SubDataPropertyOf If X occurs during Y, X must be dated Y
FunctionalDataProperty There can be only one Y such that X is dated Y
Table 2: Meanings of OWL functors
2.3 Semantic complexity
When encoding knowledge in description logic,
developers have considerable freedom in dis-
tributing content among axioms, so that axiom
size is partly a matter of style ? rather like sen-
tence length in composing a text. Development
tools like Prote?ge? (Rector et al, 2004) support
refactoring of axioms, so that for example any ax-
iom of the form CA v CS u CL (e.g., ?Every ad-
miral is a sailor and a leader?) can be split into
two axioms CA v CS and CA v CL (?Every
admiral is a sailor. Every admiral is a leader.?),
or vice-versa5. Indeed, it can be shown that any
set of SubClassOf axioms can be amalgamated
into a single axiom (Horrocks, 1997) of the form
> v M , where > is the class containing all indi-
viduals in the domain, and M is a class to which
any individual respecting the axiom set must be-
long6. Applying this transformation to just two
axioms already yields an amalgam that will per-
plex most readers:
Every admiral is a sailor
Every admiral commands a fleet.
Everything is (a) either a non-admiral or a sailor,
and (b) either a non-admiral or something that
commands a fleet.
There is thus no guarantee that an axiom in OWL
can be verbalised transparently by a single sen-
5The symbols v and u in logical notation correspond to
the OWL functors SubClassOf and ObjectIntersectionOf.
6This all-embracing axiom or ?meta-constraint? is com-
puted by the standard description logic reasoning algorithms
when determining the consistency of a knowledge base.
tence; in theory it could contain as much knowl-
edge as a textbook. As before, we have to appeal
to practice. Do ontology developers distribute
content among knowledge units (axioms) equiv-
alent in size to sentences? If they (almost always)
do, then our approach is worth pursuing; if not,
we have to reconsider.
3 Method
To investigate the issues of usage just described,
we have analysed axiom patterns in a large cor-
pus of ontologies of varying subject-matter and
provenance. The corpus was based on the TONES
Ontology Repository (TONES, 2010), which is
a searchable database of RDF/XML ontologies
from a range of sources. The repository is in-
tended to be useful to developers of tools to work
with ontologies, and as such represents a wide
range of ontology kinds and features. It also clas-
sifies ontologies by ?expressivity? ? the weak-
est description logic necessary to express every
axiom. While the TONES site itself acknowl-
edges that the expressivity categorisation is only
a guideline, it can serve as a rough guide for com-
parison with the pattern frequency analysis carried
out here.
The whole repository was downloaded, com-
prising 214 files each containing between 0 and
100726 logical axioms7. (Note that an OWL
7A few of the ontologies in the TONES repository were
excluded, either because of syntax errors in the original files
(2-3 files), or because they exceeded our processing limits ?
1009
file may contain no logical axioms and still
be non-empty.) To develop quickly a program
that could cope with the larger ontologies with-
out memory problems, we used the Java-based
OWL API (Horridge and Bechhofer, 2010) as
much as possible, in conjunction with standard
Unix text-processing tools (?grep?, ?sed? and
?awk? (Dougherty and Robbins, 1997)) for pattern
recognition8.
Each ontology was converted into OWL Func-
tional Syntax (Motik et al, 2010) and lists were
automatically generated of the identifiers it con-
tains ? classes, named individuals, properties,
and so on. The Unix tools were scripted to re-
place every occurrence of such an identifier with
a string representing its type. This process gen-
erated a new file in which every axiom of the
original ontology had been replaced with a string
representing its logical structure: thus SubClas-
sOf(Admiral, Sailor) and SubClassOf(Sailor, Per-
son) would each have been replaced with Sub-
ClassOf(Class, Class). The number of occur-
rences of each unique pattern was then counted
and the results converted into a set of Prolog
facts for further analysis. Some manual tidying-
up of the data was necessary in order to correct
some complex cases such as quoted string liter-
als which themselves contained (escaped) quoted
strings; however, these cases were so rare that any
remaining errors should not adversely affect out-
put quality.
4 Results
To address the issue of logical sophistication, we
first calculated frequencies for each axiom func-
tor, using two measures: (a) the number of ontolo-
gies in which the functor was used at least once,
and (b) the number of axioms using the functor
overall. The former measure (which we will call
?ontology frequency?) is a useful corrective since
a simple axiom count can be misleading when a
e.g., the Foundational Model of Anatomy (Rosse and Mejino,
2003).
8A pure Java solution was not practical in the time avail-
able since the OWL API was designed to support reasoning
and evaluation of OWL ontologies rather than syntactic anal-
ysis of their axioms. We hope to produce an extension of the
OWL API to support straightforward and portable analysis
of ontologies in the future.
functor is used profusely in a few very large on-
tologies, but rarely elsewhere. The results are pre-
sented in table 3, ordered by ontology frequency
rather than overall axiom frequency9. As can be
seen, the ten functors classified as logically so-
phisticated in table 2 are relatively rare, by both
measures, accounting overall for just 2.2% of the
axioms in the corpus, with none of them having a
frequency reaching even 5 in 1000.
Next, to address information structure, we
looked at the argument patterns for each ax-
iom functor, distinguishing three cases: (a) all
arguments simple (i.e., atomic); (b) all argu-
ments complex (non-atomic); (c) mixed argu-
ments (some atomic, some non-atomic). This
comparison is relevant only for the functors Sub-
ClassOf, EquivalentClasses and DisjointClasses,
for which OWL syntax allows multiple non-
atomic arguments. The results (table 4) show a
clear preference for patterns in which at least one
argument is simple. Thus for SubClassOf, given
the overall frequencies of simple and complex ar-
guments for this functor, the expected frequency
for the combination Complex-Complex would be
12606 (2.7%), whereas the observed frequency
was only 978 (0.2%) (?2 = 16296 with df=2,
p < 0.0001)10. The corresponding result for
EquivalentClasses is even clearer, with not a sin-
gle instance of an axiom in which all arguments
are complex, against an expected frequency of 973
(16.0%) (?2 = 2692 with df=2, p < 0.0001)11.
For DisjointClasses no complex arguments were
obtained, so the only possible combination was
?All Simple?. Overall, 99.8% of axioms for these
three functors contained at least one atomic term,
suggesting that the arguments were interpreted ac-
cording to intuitions of information structure, with
one atomic argument serving as the topic. This
point is reinforced by our next analysis, which
considers detailed argument patterns.
9Note that the total in the first column of table 3 is sim-
ple the number of ontologies in our sample; the sum of the
frequencies in the column is of no interest at all.
10The data for this test, with expected values in brack-
ets, are SS = 297293 (312138), CC = 978 (12606), and SC
= 170541 (144068), where S means ?Simple? and C means
?Complex?.
11The data for this test, with expected values in brackets,
are SS = 1222 (2190), CC = 0 (973), and SC = 4860 (2919),
where again S means ?Simple? and C means ?Complex?.
1010
Functor Ontology Frequency Percent Axiom Frequency Percent
SubClassOf 190 94% 468812 74.0%
EquivalentClasses 94 46% 6082 1.0%
ObjectPropertyRange 92 45% 2275 0.4%
ObjectPropertyDomain 91 45% 2176 0.3%
DisjointClasses 88 43% 94390 14.9%
SubObjectPropertyOf 75 37% 2511 0.4%
InverseObjectProperties 63 31% 1330 0.2%
TransitiveObjectProperty 59 29% 221 0.0%
FunctionalObjectProperty 56 28% 1129 0.2%
DataPropertyRange 52 26% 2067 0.3%
ClassAssertion 49 24% 12798 2.0%
DataPropertyDomain 47 23% 2019 0.3%
FunctionalDataProperty 37 18% 931 0.1%
ObjectPropertyAssertion 22 11% 19524 3.1%
DataPropertyAssertion 14 7% 17488 2.8%
SubDataPropertyOf 6 3% 12 0.0%
TOTAL 203 100% 633791 100%
Table 3: Frequencies for OWL functors
Functor All Simple Percent All Complex Mixed Percent
SubClassOf 297293 63% 978 (0.2%) 170541 37%
EquivalentClasses 1222 20% 0 4860 80%
DisjointClasses 94390 100% 0 0 0%
TOTAL 392905 69% 978 (0.2%) 175401 31%
Table 4: Simple and complex arguments of OWL functors
OWL Pattern Frequency Percent
SubClassOf(Class,Class) 297293 46.9%
SubClassOf(Class,ObjectSomeValuesFrom(ObjectProperty,Class)) 158519 25.0%
DisjointClasses(Class,Class) 94358 14.9%
ObjectPropertyAssertion(ObjectProperty,NamedIndividual,NamedIndividual) 18552 3.0%
DataPropertyAssertion(DataProperty,NamedIndividual,Literal) 17433 2.7%
ClassAssertion(Class,NamedIndividual) 12767 2.0%
SubClassOf(Class,ObjectAllValuesFrom(ObjectProperty,Class)) 4990 0.8%
SubObjectPropertyOf(ObjectProperty,ObjectProperty) 2453 0.4%
EquivalentClasses(Class,ObjectIntersectionOf(Class,ObjectSomeValuesFrom(ObjectProperty,Class))) 2217 0.3%
ObjectPropertyRange(ObjectProperty,Class) 2025 0.3%
ObjectPropertyDomain(ObjectProperty,Class) 1835 0.3%
DataPropertyDomain(DataProperty,Class) 1703 0.3%
SubClassOf(Class,ObjectHasValue(ObjectProperty,NamedIndividual)) 1525 0.2%
SubClassOf(Class,DataHasValue(DataProperty,Literal)) 1473 0.2%
InverseObjectProperties(ObjectProperty,ObjectProperty) 1318 0.2%
DataPropertyRange(DataProperty,Datatype) 1308 0.2%
EquivalentClasses(Class,Class) 1222 0.2%
FunctionalObjectProperty(ObjectProperty) 1121 0.2%
Other pattern. . . 11469 1.8%
TOTAL 633791 100%
Table 5: Frequencies for OWL Functor-Argument patterns
1011
Finally, to address semantic complexity (i.e.,
axiom size), we counted the frequencies of de-
tailed argument patterns, abstracting from atomic
terms as explained in section 3. The results (or-
dered by pattern frequency) are presented in table
5, which reveals several clear trends:
? A small number of patterns covers most of
the axioms in the corpus. Thus the top five
patterns cover 91.9% of the axioms, the top
10 cover 95.8%, and the top 20 cover 97.2%.
? All of the frequent patterns (i.e., the top 20)
can be expressed by a single sentence with-
out problems of semantic complexity arising
from size. The most complex is the Equiv-
alentClasses pattern (number 10 in the list),
but this can be realised comfortably by a sen-
tence following the classical Aristotelian pat-
tern for a definition ? e.g., ?An admiral is
defined as a person that commands a fleet?.
? None of the first ten patterns employs the
axiom functors previously classified as log-
ically sophisticated (bottom half of table 2).
? In the patterns where one argument is sim-
ple and the other is complex (i.e., SubClas-
sOf and EquivalentClasses), the simple ar-
gument invariably comes first, supporting the
intuition that developers conceptualise these
statements in subject-predicate form, with
(simple) topic preceding (possibly complex)
comment.
? Among the frequent patterns, different func-
tors have distinctive argument preferences.
For instance, for SubClassOf most axioms
have atomic arguments, presumably because
it is through this functor that the class hierar-
chy is specified. For EquivalentClasses, in-
stead, the Aristotelean definition pattern is by
far the most frequent, although all-atomic ar-
guments are occasionally employed (0.2% of
axioms) to show that two class terms are syn-
onymous.
5 Conclusion
Our analysis of over 600,000 axioms from 203
ontologies provides empirical support for the as-
sumption that in practice OWL axioms can be
transparently expressed by English sentences. In
principle, as we have seen, OWL syntax grants
users the freedom to construct axioms that would
defeat this assumption entirely, either by concen-
trating too much semantic content into a single ax-
iom, or by filling all argument positions by com-
plex expressions that are unsuited to fulfilling the
role of topic; it also allows logically sophisticated
statements about properties, which would lead to
impossibly clumsy texts if they occurred too of-
ten, or were exacerbated by complex arguments.
In practice, if our sample is typical, none of these
problems seems to arise, and we think it would
be a fair summary of our results to say that on-
tology developers treat OWL axioms by analogy
with sentences, by assigning a clear information
structure (so that one atomic argument is identi-
fied with the topic) and including only an appro-
priate amount of content.
Having identified a relatively small set of com-
mon axiom patterns, it is obviously interesting to
consider how each pattern can best be expressed
in a given natural language. Considering the pat-
tern SubClassOf(Class,Class) for instance (47%
of all axioms), one could weigh the relative mer-
its of ?Every admiral is a sailor?, ?All admirals are
sailors?, ?Admirals are sailors?, ?If X is an admiral,
then X must be a sailor?, and so forth. To address
this issue we are planning a quite different kind of
empirical study on how various sentence patterns
are interpreted by human readers; by highlighting
the logical patterns that occur most often in prac-
tice, the results reported here will help set the pa-
rameters for such an investigation.
Acknowledgments
The research described in this paper was un-
dertaken as part of the SWAT project (Seman-
tic Web Authoring Tool), which is supported by
the UK Engineering and Physical Sciences Re-
search Council (EPSRC) grants G033579/1 (Open
University) and G032459/1 (University of Manch-
ester). We thank the anonymous reviewers and
our colleagues on the SWAT project for their com-
ments.
1012
References
Dougherty, Dale and Arnold Robbins. 1997. sed and
awk. UNIX Power Tools. O?Reilly Media, 2nd edi-
tion.
Funk, Adam, Valentin Tablan, Kalina Bontcheva,
Hamish Cunningham, Brian Davis, and Siegfried
Handschuh. 2007. CLOnE: Controlled Lan-
guage for Ontology Editing. In 6th Interna-
tional and 2nd Asian Semantic Web Conference
(ISWC2007+ASWC2007), pages 141?154, Novem-
ber.
Hart, Glen, Martina Johnson, and Catherine Dolbear.
2008. Rabbit: Developing a control natural lan-
guage for authoring ontologies. In ESWC, pages
348?360.
Horridge, Matthew and Sean Bechhofer. 2010. The
OWL API. http://owlapi.sourceforge.net. Last ac-
cessed: 21st April 2010.
Horrocks, Ian. 1997. Optimising Tableaux Decision
Procedures for Description Logics. Ph.D. thesis,
University of Manchester.
Kaljurand, K. and N. Fuchs. 2007. Verbalizing OWL
in Attempto Controlled English. In Proceedings of
OWL: Experiences and Directions, Innsbruck, Aus-
tria.
Kruijff-Korbayova?, Ivana and Mark Steedman. 2003.
Discourse and information structure. Journal of
Logic, Language and Information, 12(3):249?259.
Motik, Boris, Peter F. Patel-Schneider, and Bijan
Parsia. 2010. OWL 2 web ontology language:
Structural specification and functional-style syn-
tax. http://www.w3.org/TR/owl2-syntax/. 21st
April 2010.
Power, Richard. 2010. Complexity assumptions in on-
tology verbalisation. In 48th Annual Meeting of the
Association for Computational Linguistics.
Rector, Alan, Nick Drummond, Matthew Horridge,
Jeremy Rogers, Holger Knublauch, Robert Stevens,
Hai Wang, and Chris Wroe. 2004. OWL Pizzas:
Practical Experience of Teaching OWL-DL: Com-
mon Errors and Common Patterns. In 14th Interna-
tional Conference on Knowledge Engineering and
Knowledge Management, pages 63?81.
Rosse, Cornelius and Jose? L. V. Mejino. 2003.
A reference ontology for biomedical informatics:
the Foundational Model of Anatomy. Journal of
Biomedical Informatics, 36(6):478?500.
Schwitter, R. and M. Tilbrook. 2004. Controlled
natural language meets the semantic web. In Pro-
ceedings of the Australasian Language Technology
Workshop, pages 55?62, Macquarie University.
Smart, Paul. 2008. Controlled Natural Languages and
the Semantic Web. Technical Report Technical Re-
port ITA/P12/SemWebCNL, School of Electronics
and Computer Science, University of Southampton.
TONES. 2010. The TONES ontology repository.
http://owl.cs.manchester.ac.uk/repository/browser.
Last accessed: 21st April 2010.
Walker, M., A. Joshi, and E. Prince. 1998. Centering
theory in discourse. Clarendon Press, Oxford.
1013
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 67?75,
Utica, May 2012. c?2012 Association for Computational Linguistics
?Hidden semantics?: what can we learn from the names in an ontology??
Allan Third
Computing Department, Open University, UK
a.third@open.ac.uk
Abstract
Despite their flat, semantics-free structure, on-
tology identifiers are often given names or la-
bels corresponding to natural language words
or phrases which are very dense with informa-
tion as to their intended referents. We argue
that by taking advantage of this information
density, NLG systems applied to ontologies
can guide the choice and construction of sen-
tences to express useful ontological informa-
tion, solely through the verbalisations of iden-
tifier names, and that by doing so, they can re-
place the extremely fussy and repetitive texts
produced by ontology verbalisers with shorter
and simpler texts which are clearer and eas-
ier for human readers to understand. We spec-
ify which axioms in an ontology are ?defin-
ing axioms? for linguistically-complex identi-
fiers and analyse a large corpus of OWL on-
tologies to identify common patterns among
all defining axioms. By generating texts from
ontologies, and selectively including or omit-
ting these defining axioms, we show by sur-
veys that human readers are typically capable
of inferring information implicitly encoded in
identifier phrases, and that texts which do not
make such ?obvious? information explicit are
preferred by readers and yet communicate the
same information as the longer texts in which
such information is spelled out explicitly.
1 Introduction
There has been increasing interest in recent years in
the generation of natural language texts from, or us-
?Many thanks to Richard Power and Sandra Williams for
their help and comments. This work was supported by En-
gineering and Physical Sciences Research Council Grant Ref.
G033579/1.
ing, ontologies ((Cregan et al, 2007; Kaljurand and
Fuchs, 2007; Smart, 2008), for example). Such ?ver-
balisations? ? translations of the logic of, for exam-
ple, OWL (W3C Consortium, 2012), into human-
readable natural language ? can be useful for a vari-
ety of purposes, such as communicating the results
of ontology inference, generating custom texts to
suit a particular application domain or assisting non-
ontology-experts in authoring, reviewing and vali-
dating ontologies. This paper takes as its starting
point an observation about ontology structure and
use. The purpose of an ontology (specifically, the
so-called ?T-box?1) is to define the terms of a par-
ticular domain in order to allow automated infer-
ence of the semantics of that domain. Given that
machines are essentially tabulae rasae with regard
to nearly any kind of world knowledge, it is there-
fore necessary to spell out the meanings of most
terms in what (to a human) would be excruciating
detail. In most, if not all, ontology languages, and
certainly in OWL, identifiers ? the ?names? for in-
dividual entities, classes and relations2 ? are atomic
units. That is to say, every identifier is treated by
the machine as simply a flat string, with no internal
structure or semantics. The corresponding natural
language constructions ? noun and verb phrases ?
by contrast have a very rich internal structure which
can communicate very subtle semantic distinctions.
Best practice for human ontology developers recom-
mends that for every entity in an ontology, either its
identifier should be a meaningful simple or complex
term, or it should have a (localised) label which is
a meaningful simple or complex natural language
1?Terminology box?
2?Property? is the OWL terminology for a relation between
two entities
67
term. For example, in the domain of education, a
class intended to represent the real-world class of
junior schools ought to have (in English) an iden-
tifier such as junior school or a label such as
?junior school?. Ontology developers who follow
this best practice (and, according to (Power, 2010),
the vast majority do) produce ontologies in which
the entities are easily recognisable and understood
by human readers who can parse these identifiers, to
infer, for example, that ?junior school? is a subclass
of the class ?school?. As it stands, however, a ma-
chine will not make this inference. In order for the
machine to comprehend the semantics of this exam-
ple, there must additionally be an axiom equivalent
to ?a junior school is a school?.
The motivation for this work is the desire to iden-
tify which kinds of identifier or label are ?obvious?
in this way. That is to say, if we treat an OWL iden-
tifier as if it were in fact a multi-word natural lan-
guage expression, can we infer at least some of its
semantics from its properties as a noun phrase, for
example? This has two overall purposes: given an
existing ontology, definitional axioms for ?obvious?
identifiers can be omitted when verbalising for a hu-
man user, in order to shorten the text and make it
more relevant, and, conversely, during the process of
ontology creation, if a human uses an obvious iden-
tifier, a reasonable guess can be made as to its defi-
nitional axiom(s), and these can be presented to the
user for confirmation, thus saving the user the need
to spend time and energy spelling out the obvious
for the machine?s purposes. This paper addresses
the first of these two purposes. Note that the aim of
this work is not particular to consider how best to re-
alise entity names in a verbalisation, but rather, how
to use the names of entities to guide the choice and
construction of sentences.
This work was undertaken in the context of
the SWAT (Semantic Web Authoring Tool) project,
which is investigating the application of NLG/NLP
to ontology authoring and editing (Williams et
al., 2011),(Williams and Power, 2010),(Power
and Third, 2010),(Stevens et al, 2011), (Power,
2010),(The SWAT Project, 2012).
2 Existing work
Other researchers have attempted to take advantage
of the internal structure of ontology identifiers to in-
fer semantics, but these have exclusively been con-
cerned with the question of checking or improving
an ontology?s coverage of its domain. Examples
include (Wroe et al, 2003; Fernandez-Breis et al,
2010; Egan?a Aranguren et al, 2008). To the best
of our knowledge, our current research is the first to
take advantage of identifier structure to infer seman-
tics in order to improve verbalisation and produce
more human-focused texts.
3 Hypothesis
Informal feedback from existing work indicates that
many readers are dissatisfied with the kinds of text
produced by ontology verbalisers, feeling them to be
somewhat fussy and unnatural. Some of this can no
doubt be put down to the verbalisations themselves
? it is very difficult to find a natural way to express
that one property is the inverse of another without
resorting to mathematical variables ? but, as with
other generation tasks, the problem is not necessar-
ily just how things are said, but also in the selection
of which things to say at all. Our hypothesis takes
two parts:
1. linguistically-complex identifiers/labels are of-
ten defined by ?obvious? axioms in the OWL
ontologies containing them, and
2. ontology verbalisations which omit such ?obvi-
ous? axioms lead to a better reading experience
for users without sacrificing content.
A prerequisite for these is also the claim that
linguistically-complex identifiers are reasonably
common in ontologies. (Power, 2010) demonstrated
very clearly that recommended best-practice is in
fact followed very well in much ontology develop-
ment, and entities do tend to be given meaningful
names.
One caveat is necessary here. We are talking
about what an average human reader might reason-
ably expect to follow from a given use of language.
However, observing that a black horse is a horse,
a grey horse is a horse, a brown horse is a horse,
and so on, does not guarantee the truth of any infer-
ences we might make on encountering a reference
68
to a clothes-horse. There will always be situations
in which ordinary uses of language will need to be
made more precise. An interesting future direction
of this work would be to investigate whether it is
possible to detect exactly when such clarification is
necessary, in the context of ontology verbalisation,
at least.
4 Definitions
Of course, ?complex?, ?obvious?, and so on can be
loaded terms, and it is necessary to make them pre-
cise before continuing.
4.1 Simple and complex identifiers
Identifiers3 may consist of a single natural language
word, in which case we call it simple, or multiple
words, in which case it is complex. The words in a
complex identifier may be separated by spaces (?ju-
nior school?), punctuation (junior school) or
capitalisation (juniorSchool). In any case, it is
trivial to separate these words into a list automati-
cally.
4.2 Content words
In looking for ?defining? axioms, we often need to
ignore words occurring in complex identifiers which
have some grammatical function. For example, if
comparing ?has as father? to other identifiers in the
same ontology, we may ignore ?has? and ?as? and
consider only the content word ?father?. ?Has? oc-
curs far too frequently to be of any use in identifying
axioms relating to the semantics of ?has as father?,
although it is of course relevant to what those se-
mantics actually are in any one of such axioms.
4.3 Constructed identifiers
A complex identifier is constructed if its component
words (or just its content words) are themselves sim-
ple identifiers in the containing ontology. For exam-
ple, if an ontology contains identifiers correspond-
ing to ?French?, ?woman? and ?French woman?,
then ?French woman? is a constructed identifier. We
may wish to relax this definition slightly to consider
constructed identifiers where most of the component
3Henceforth, for brevity, ?identifier? may mean ?OWL iden-
tifier?, if that is human-meaningful, or it may mean ?label?, oth-
erwise.
(content) words are also identifiers, or where com-
ponent words are morphological variants of other
identifiers.
4.4 Defining axioms
The meaning of a constructed identifier can be de-
fined in an ontology by axioms in which all, or most,
of its component or content words occur as, or in,
other identifiers. For example, if there is an iden-
tifier van driver, there is likely to be an axiom
similar to
A van driver drives a van.
So, for a complex identifier I , we take an axiom
A to be a defining axiom if:
? A contains at least two distinct identifiers,
? I occurs in A, and either
? for each identifier J 6= I in A, the content
words in J are a subset of the content words
in I , OR
? the content words in I are a subset of the union
of the content words of at least two other iden-
tifiers in A.
The third condition is relatively straightforward ?
a phrase such as ?white van man? can be defined in
OWL using at most terms corresponding to ?white?,
?van? and ?man?, but not every word in a complex
phrase must appear in its defining axiom. Adjec-
tives often work like this: we accept ?a junior school
is a school? as being a defining axiom of ?junior
school?, but ?junior? only appears in the definien-
dum. It is worth noting here that a defining ax-
iom need not be the whole of the definition of its
definiendum; a complex identifier may have more
than one defining axiom associate with it, in which
case its definition would be the set of all of its defin-
ing axioms.
The fourth condition perhaps seems stranger. The
intention here is to capture defining axioms such as
A French woman is a woman whose nationality is
French
where ?nationality? is not a content word of ?French
woman?, and yet there is an underlying relation-
ship between this ?extra? word/phrase and one of
69
the content words of ?French woman?, namely in
this case that ?French? is a nationality. One goal of
future work might be to look into ways to identify
such underlying relationships from OWL semantics
in order to use them in new contexts.
5 Corpus study
So far, we have given criteria for which identifiers
we consider to be linguistically-complex and for
which axioms we believe serve as definitions for
such identifiers. The immediately obvious question
is whether these criteria are useful. To test this, we
evaluate them against a corpus of 548 OWL ontolo-
gies collected from a variety of sources, include the
Tones repository (TONES, 2012), the Swoogle se-
mantic web search engine (Finin et al, 2004) and
the Ontology Design Patterns corpus (ODP, 2012).
The corpus includes ontologies on a wide range of
topics and featuring a variety of authoring styles.
By using the OWL API (OWL API, 2012), a
Java program was written to scan through the corpus
for identifiers matching the definition of ?complex?
above, and for each such identifier found, look for
defining axioms for it. Of the logical entity types
possible in OWL ? Named Individuals, Classes,
Data- and Object-Properties ? it was decided to omit
Named Individuals from the current study. Much as
with proper nouns in natural language, the names of
individuals typically have less internal structure than
other kinds of entity or relation names, and those
which do have such structure (such as, e.g., ?Lake
Windermere?) are usually very simple. Individuals
are also not really ?defined? as such. One may state
what are deemed to be highly-salient features about
them, such as that Lake Windermere is a lake, but
this is not a definition. Had we included individuals
in this study, it was thought that the large number
of non-defined names would artificially depress the
statistics and give an inaccurate view of the phenom-
ena being studied. Re-running the analysis including
Named Individuals confirmed this hypothesis: less
than 10 ontologies in the whole corpus contained
any defining axioms for named individuals, with the
most common pattern having only 77 occurrences in
the whole corpus ? a negligible frequency. It would
be interesting to look at these cases in more detail,
however, to examine what kinds of individual are de-
fined in this way.
Having identified defining axioms across the cor-
pus, the results were then abstracted, by replacing
the occurrences of content words of each identifier
in an axiom with alphabetic variables, so that
SubClassOf(junior school school)
and
SubClassOf(domestic mammal mammal)
both become
SubClassOf(AB B).
The occurrences of each abstracted axiom pattern
could then be counted and tabulated. Table 1 shows
the most frequent 10 patterns, comprising 43% of all
results. Across the whole corpus, 69% of all identi-
fiers were complex, according to our definition, and
of those, 45% had at least one defining axiom. These
figures indicate that the phenomenon we are investi-
gating is in fact a very common one, and hence that
any improvements to ontology verbalisation based
on taking advantage of identifier semantics are likely
to be significantly useful.
Of all the patterns identified, 64% involve the
SubClassOf axiom type (?A junior school is a
school?). A further 14% involve InverseObjectProp-
erties (?Bill is father of John if and only if John has
father Bill?), and another 14% involve ObjectProp-
ertyDomain or ObjectPropertyRange (?If something
has as segment X, then X is a segment?). Col-
lectively, then, these axiom types cover 92% of all
defining axioms. An informal glance at the results
involving SubClassOf axioms shows that what ap-
pears to be the case in Table 1 is generally true ? the
bulk of the SubClassOf axioms involve some form
of adjective construction.
It should be noted here that the intention was to
use the absolute bare minimum of linguistic knowl-
edge in identifying these axioms ? almost everything
is done by matching substrings ? in order to avoid
influencing the results with our own intuitions about
how we think it ought to look. It is reassuring to see
nonetheless how far it is possible to get without in-
volving linguistic knowledge. Indeed, one of the on-
tologies in the test corpus has identifiers in Italian,
and it was confirmed by a bilingual English/Italian
speaker that the axiom patterns our software identi-
fied for that ontology were just as ?obvious? in Ital-
70
Table 1: 10 most frequent patterns of defining axiom
No. of Pattern Example
occurrences
1430 SubClassOf(AB B ) SubClassOf(representation-activity activity)
1179 SubClassOf(ABC BC ) SubClassOf(Quantified set builder Set builder)
455 InverseObjectProperties(hasA isAof ) InverseObjectProperties(HasInput IsInputOf)
387 SubClassOf(ABCD BCD ) SubClassOf(Continental-Statistical-Water-Area Statistical-Water-Area)
348 SubClassOf(ABCD CD ) SubClassOf(NonWikipediaWebPage WebPage)
240 SubClassOf(ABC AC ) SubClassOf(Process-Resource-Relation Process-Relation)
229 ObjectPropertyRange(hasA A ) ObjectPropertyRange(hasAnnotation Annotation)
192 ObjectPropertyRange(hasAB AB ) ObjectPropertyRange(hasTrustValue TrustValue)
188 InverseObjectProperties(AB ABof ) InverseObjectProperties(situation-place situation-place-of)
179 InverseObjectProperties(Aof hasA ) InverseObjectProperties(contentOf hasContent)
ian as they are in English. There are limitations,
of course. A defining axiom such as ?a pet owner
is a person who owns a pet? would not be picked
up by this software, as ?owner? and ?owns? do not
match each other as strings. To bypass this particular
limitation, the software has been modified to allow
the optional use of a (language-specific) stemming
algorithm before substring matching, so that both
?owner? and ?owns? would be matched as ?own?,
for example. The current work, however, focuses
on the non-stemmed results for reasons of simplic-
ity and time; we intend to carry out further research
using the stemmed results in future.
6 Generation study
6.1 Design
A core part of our claim for these defining axioms
is that their semantics are in some sense ?obvious?.
A human reading a phrase such as ?junior school?
is unlikely to need to be told explicitly that a junior
school is a school. This claim needs to be tested.
Furthermore, it was suggested above that ontology
verbalisations would be improved in quality for hu-
man readers if such ?obvious? sentences were omit-
ted and the semantics implied by the internal struc-
ture of noun and verb phrases were used to improve
verbalisation. Again, it is necessary to test whether
any improvement does occur.
In order to test the first of these claims, a sur-
vey was designed, in which each question would
consist of a (verbalised) identifier phrase, followed
by three sentences containing that identifier phrase.
Respondents were asked to indicate which of those
sentences, if any, they were able to deduce from
the phrase itself, without relying on any domain
knowledge. The questions were based on the top
8 patterns of defining axiom from Table 1, and the
containing ontology of each was verbalised using
the SWAT ontology verbalisation tool ((The SWAT
Project, 2012)). The choice of 8 was motivated by
an intended survey size of 10 to 14 questions allow-
ing for some duplication of patterns in order to vary,
e.g., the order of elements in sentences, and to min-
imise the effects of possible domain knowledge on
behalf of respondents.
Figure 1 shows an example of a question from
the first survey. The prediction was that respondents
would be more likely to select sentences based on a
defining axiom pattern than sentences which are not
based on any such pattern.
The second claim required a more involved test.
It was decided to present respondents with two para-
graphs of text, both verbalised from the same set
of axioms ?about? the same class or property. One
paragraph of each pair contains verbalisations of ev-
ery initial axiom, possibly with common subjects
or objects aggregated between sentences (the ?full?
paragraph). The other omitted the verbalisations
of any defining axioms, and allowed aggregation
of common elements from within identifiers where
that was justified by one of the omitted defining ax-
iom. For example, the already-aggregated (in the
full paragraph) sentence
The following are kinds of atrium cavity: left
atrium cavity, right atrium cavity
was further aggregated to
The following are kinds of atrium cavity: left, right.
because of the defining axioms
A left (right) atrium cavity is an atrium cavity.
This second paragraph is the ?simplified? para-
graph. Both paragraphs were checked in each case
to ensure that the original set of axioms could be
71
Figure 1: Sample question from survey 1
inferred without any external information, provid-
ing an objective guarantee that both carried the same
semantic content even if one only did so implicitly.
Respondents were asked to judge whether each pair
of paragraphs expressed the same information, to ex-
press a preference (or lack of preference) for one
paragraph over the other, and to select those sen-
tences from each paragraph which conveyed infor-
mation which was not conveyed by the other para-
graph. Figure 2 shows an example survey question.
Three hypotheses were tested simultaneously by
this survey. The first was that respondents would
be able to detect when two paragraphs contained
the same information at a probability significantly
greater than chance and the second that respondents
would tend to prefer the simplified paragraphs. The
third hypothesis was that respondents would be un-
likely to label information as being ?missing? from a
paragraph when that information was implicitly ex-
pressed.
Our initial survey design also included pairs of
paragraphs which genuinely did contain different in-
formation, to serve as a control, and so respondents?
ability to judge pairs of paragraphs as carrying the
same information would be compared to their abil-
ity to judge when the presence of different informa-
tion. However, in piloting that design, nearly every
respondent reported such examples as being highly
confusing and distracting. This is perhaps not sur-
prising; the task of telling when two texts express
the same content is not symmetrical with the task
of telling when they express different content. The
latter is considerably easier, by virtue of the fact
that different content will involve different words or
phrases, or noticably different sentence structures.
Because of this, the decision was taken only to test
texts which objectively did contain the same logi-
cal content, and to compare the results to chance.
Each paragraph pair was controlled to minimise the
effects of ordering of information and, where possi-
ble, of length.
To maximise take-up and completion, it was de-
cided to try to keep the length of time taken to com-
plete each survey down to around five minutes. Con-
sequently, survey 1 had 14 of the relatively sim-
ple identifier inference questions and survey 2 had
4 of the more complex paragraph-comparison ques-
tions. Both surveys were published via Survey-
Monkey (Monkey, 2012) and were publicised via
the social networking sites Twitter (Twitter, 2012),
Facebook (Facebook, 2012) and Google+ (Google+,
2012).
6.2 Results and evaluation
The first survey attracted 30 respondents, the second
29. The data collected from the first survey are sum-
marised in Table 2, where S is ?sentence predicted
to be obvious by a defining axiom pattern? and J is
?sentence judged inferrable from the given identi-
fier?. Applying a 2 ? 2 ?2 contingency test results
in ?2 = 342.917, df = 1 and P < 0.0001, indi-
cating an extremely significant association between
the predicted obviousness of a sentence and respon-
dent judgement of that sentence as following from
the given identifier.
It is interesting, however, to note the top row of
Table 2: for sentences which are predicted to hold,
human judges are ambivalent as to whether to judge
it as definitely true or not. One interpretation of this
result is that, while it is very clear that non-defining
axioms can not be inferred from identifier phrases,
people are hesitant to commit to asserting these ax-
ioms in an unfamiliar domain, perhaps for fear of an
unknown exception to the general rule. For example,
72
Figure 2: Sample question from survey 2
while ?a Qualifier Noun is a Noun? is usually a good
rule of thumb, ?a clothes-horse is a horse? is a clear
counterexample. So perhaps the better interpreta-
tion of these results would be to say that, presented
for example with a phrase of the form ?Qualifier
Noun?, a reader would not be surprised if it turned
out that the entity referred to is also a ?Noun?. Ei-
ther way, these statistics suggest that it could well be
safe, when generating texts, to omit defining axioms
and allow readers? default assumptions to apply. A
simple improvement suggests itself. In the situation
where a particular defining axiom pattern would be
predicted, but its negation is in fact present, the said
negation is automatically highly-salient. It is always
likely to be worthwhile verbalising ?a clothes-horse
is not a horse.?
Table 2: Results of the survey on identifier inference.
J not J
S 224 211
not S 44 739
It is also interesting to separate out the results of
this survey by type of axiom. There were three gen-
eral families of defining axiom type tested ? Sub-
ClassOf (?A junior school is a school?), InverseOb-
jectProperties (?Bill is father of John if and only if
John has father Bill?) and ObjectPropertyRange (?If
something has as segment X, then X is a segment?).
Table 3 shows the results broken down by these cat-
egories, where ?SC? is SubClassOf, ?IOP? is In-
verseObjectProperties? and ?OPR? is ObjectProper-
tyRange.
Table 3: Breakdown of identifier inference results by ax-
iom type.
J not J
SC 152 109
IOP 52 64
OPR 20 38
A 3 ? 2 ?2 test results in ?2 = 13.54, df = 2
and P = 0.001148, indicating that the judgement
of a sentence as obvious or not varies to a signif-
icant degree with the type of sentence it is. This
is perhaps to be expected, given that not all axiom-
types can be verbalised by sentences of similar lin-
guistic complexities. In particular, it is very difficult
to see how to verbalise ObjectPropertyRange sen-
tences without appealing to the use of variables such
as X and Y, which tend to lead to rather clunky sen-
tences. Sentences corresponding to SubClassOf ax-
ioms are most likely to be judged as obvious. Fur-
ther work is necessary to determine the reasons for
73
these differences empirically.
Table 4: Results of paragraph comparison survey (I)
Yes No
Same info 74 22
Prefer simplified 61 24
paragraph
Table 4 summarises the results of the ?same
information? and ?preference? questions from the
paragraph-comparison survey, aggregated across
questions. Comparing each of these to a random
distribution of Yes/No answers gives, in turn, ?2 =
15.198, df = 1 and P < 0.0001 (same information)
and ?2 = 8.498, df = 1 and P = 0.0036 (prefer-
ence), indicating an extremely significant likelihood
of judging two paragraphs containing the same in-
formation as in fact doing so, and a significant like-
lihood of preferring the more concise of such para-
graphs.
More interesting are the results shown in Table
5. Here, taken across all paragraph-pairs, E denotes
that the information expressed by a sentence in one
paragraph is explicitly expressed in the other para-
graph, and J denotes the judgement as to whether
each sentence was judged to express information not
also expressed in the other paragraph. These dis-
tributions of observations need to be compared, for
explicit and implicit in turn, to the expected distri-
butions of judgements as to whether the information
is missing or not. For explicit information, the ex-
pected distribution is zero judgements of ?missing?
? where sentences were explicit in both paragraphs,
they were in fact identical in both paragraphs and
so should never have been judged missing ? and 696
judgements of ?not missing?. It scarcely needs a sta-
tistical test to show that the actual observations of
3, and 693, respectively, do not differ significantly
from these expectations. Nonetheless, Fisher?s exact
test (since one of the expected values is 0, ruling out
?2) gives P=0.2495. For implicit information, the
null hypothesis is that implicit information is indis-
tinguishable from absent information, and so the ex-
pected distribution is 290 judgements of ?missing?
and zero judgements of ?not missing?, compared to
observations of 33, and 257, respectively. Apply-
ing Fisher?s exact test gives P less than 0.0001, indi-
cating an extremely significant difference. In other
words, implicit information is readily distinguish-
able from absent information, as predicted.
Table 5: Results of paragraph comparison survey (II)
J not J
E 3 693
not E 33 257
7 Conclusion and further work
Beginning from some observations about identifier
use and semantics in ontologies, we posed two hy-
potheses, that linguistically-complex identifiers are
often defined by ?obvious? axiom patterns in terms
of the content words contained in those identifiers,
and that these ?obvious? axiom patterns could be
omitted from ontology verbalisations in order to pro-
duce clearer texts without significant information
loss. By means of an ontology corpus study, and the
survey evaluation of generated NL texts with human
readers, we have confirmed these hypotheses. As a
result, these generation strategies have already been
incorporated into the SWAT ontology verbaliser and
ontology authoring tool and are already being eval-
uated in use by ontology developers as those tools
progress.
Of course, there are many avenues along which
this work could be taken further. We have barely
scratched the surface when it comes to using under-
lying logical formalisms, and the information ?hid-
den? in identifiers to improve generated text. Further
investigation of the possibilities of language-specific
stemming algorithms in defining-axiom-pattern de-
tection, the interactions between multiple defining
axioms for the same entities to form whole defini-
tions, and exploitation of the logical contents of an
ontology to determine the salience of ?usual? or ?un-
usual? features in order to aid text organisation, all
offer rich opportunities to improve natural-language
generation from ontologies. We look forward to be-
ing able to look further into these areas, and to iden-
tifying which of these phenomena can perhaps be
generalised to other NLG applications by means of
ontologies.
74
References
Anne Cregan, Rolf Schwitter, and Thomas Meyer. 2007.
Sydney owl syntax - towards a controlled natural lan-
guage syntax for owl 1.1. In OWLED.
M. Egan?a Aranguren, C. Wroe, C. Goble, and R. Stevens.
2008. In situ migration of handcrafted ontologies to
reason-able forms. Data & Knowledge Engineering,
66(1):147?162.
Facebook. 2012. Facebook. http://www.facebook.com.
Last checked: 10th February 2012.
J. Fernandez-Breis, L. Iannone, I. Palmisano, A. Rec-
tor, and R. Stevens. 2010. Enriching the gene on-
tology via the dissection of labels using the ontology
pre-processor language. Knowledge Engineering and
Management by the Masses, pages 59?73.
Tim Finin, Yun Peng, R. Scott, Cost Joel, Sachs Anu-
pam Joshi, Pavan Reddivari, Rong Pan, Vishal Doshi,
and Li Ding. 2004. Swoogle: A search and meta-
data engine for the semantic web. In In Proceedings
of the Thirteenth ACM Conference on Information and
Knowledge Management, pages 652?659. ACM Press.
Google+. 2012. Google+. http://plus.google.com,
February. Last checked: 10th February 2012.
Kaarel Kaljurand and Norbert E. Fuchs. 2007. Verbaliz-
ing owl in attempto controlled english. In Proceed-
ings of Third International Workshop on OWL: Ex-
periences and Directions, Innsbruck, Austria (6th?7th
June 2007), volume 258.
Survey Monkey. 2012. Survey monkey.
http://www.surveymonkey.com. Last checked:
10th February 2012.
ODP. 2012. Ontology design patterns.
http://ontologydesignpatterns.org. Last checked:
10th February 2012.
OWL API. 2012. The OWL API.
http://owlapi.sourceforge.net. Last checked: 10th
February 2012.
Richard Power and Allan Third. 2010. Expressing OWL
axioms by English sentences: dubious in theory, fea-
sible in practice. In 23rd International Conference on
Computational Linguistics.
Richard Power. 2010. Complexity assumptions in on-
tology verbalisation. In 48th Annual Meeting of the
Association for Computational Linguistics.
Paul R Smart. 2008. Controlled natural languages and
the semantic web. July.
R. Stevens, J. Malone, S. Williams, R. Power, and
A. Third. 2011. Automating generation of textual
class definitions from owl to english. Journal of
Biomedical Semantics, 2(Suppl 2):S5.
The SWAT Project. 2012. Last checked: 10th February
2012.
TONES. 2012. The TONES ontology repository.
http://owl.cs.manchester.ac.uk/repository/browser.
Last checked: 10th February 2012.
Twitter. 2012. Twitter. http://twitter.com. Last checked:
10th February 2012.
W3C Consortium. 2012. Last checked: 10th February
2012.
Sandra Williams and Richard Power. 2010. Grouping
axioms for more coherent ontology descriptions. In
6th International Natural Language Generation Con-
ference, pages 197?202.
Sandra Williams, Allan Third, and Richard Power. 2011.
Levels of organisation in ontology verbalisation. In
Proceedings of the 13th European Workshop on Natu-
ral Language Generation (forthcoming).
CJ Wroe, R. Stevens, CA Goble, and M. Ashburner.
2003. A methodology to migrate the gene ontology to
a description logic environment using. In Pacific Sym-
posium on Biocomputing, volume 8, pages 624?635.
75
