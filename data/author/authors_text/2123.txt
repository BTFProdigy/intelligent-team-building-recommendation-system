Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 391?399,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
When Harry Met Harri,  and : 
Cross-lingual Name Spelling Normalization 
 
Fei Huang , Ahmad Emami and Imed Zitouni 
IBM T. J. Watson Research Center 
1101 Kitchawan Road 
Yorktown Heights, NY 10598 
{huangfe, emami, izitouni}@us.ibm.com 
 
Abstract 
Foreign name translations typically include 
multiple spelling variants. These variants 
cause data sparseness problems, increase 
Out-of-Vocabulary (OOV) rate, and present 
challenges for machine translation, 
information extraction and other NLP tasks. 
This paper aims to identify name spelling 
variants in the target language using the 
source name as an anchor. Based on word-
to-word translation and transliteration 
probabilities, as well as the string edit 
distance metric, target name translations with 
similar spellings are clustered. With this 
approach tens of thousands of high precision 
name translation spelling variants are 
extracted from sentence-aligned bilingual 
corpora. When these name spelling variants 
are applied to Machine Translation and 
Information Extraction tasks, improvements 
over strong baseline systems are observed in 
both cases. 
1 Introduction 
Foreign names typically have multiple spelling 
variants after translation, as seen in the 
following examples:   
He confirmed that "al-Kharroub 
province is at the top of our 
priorities."  
?for the Socialist Progressive 
Party in upper Shuf and the Al-
Kharrub region,? 
?during his tour of a number of 
villages in the region of Al-
Kharub,? 
?Beirut and its suburbs and 
Iqlim al-Khurub,? 
  
 
 
 
Such name spelling variants also frequently 
appear in other languages, such as (bushi) / 
(bushu) / (buxi) (for Bush) in Chinese, 
and 	 (sbrngfyld) /
	  (sbryngfyld) / 
	 (sbrynjfyld) (for Springfield) in Arabic.  
These spelling variants present challenges for 
many NLP tasks, increasing vocabulary size and 
OOV rate, exacerbating the data sparseness 
problem and reducing the readability of MT 
output when different spelling variants are 
generated for the same name in one document. 
We address this problem by replacing each 
spelling variant with its corresponding canonical 
form. Such text normalization could potentially 
benefit many NLP tasks including information 
retrieval, information extraction, question 
answering, speech recognition and machine 
translation. 
Research on name spelling variants has been 
studied mostly in Information Retrieval research, 
especially in query expansion and cross-lingual 
IR.  Baghat and Hovy (2007) proposed two 
approaches for spelling variants generation, 
based on the letters-to-phonemes mapping and 
Soundex algorithm (Knuth 1973). Raghaven and 
Allan (2005) proposed several techniques to 
group names in ASR output and evaluated their 
effectiveness in spoken document retrieval 
(SDR). Both approaches use a named entity 
extraction system to automatically identify 
names. For multi-lingual name spelling variants, 
Linden (2005) proposed to use a general edit 
distance metric with a weighted FST to find 
technical term translations (which were referred 
to as ?cross-lingual spelling variants?). These 
391
variants are typically translated words with 
similar stems in another language. Toivonen and 
colleagues (2005) proposed a two-step fuzzy 
translation technique to solve similar problems. 
Al-Onaizan and Knight (2002), Huang (2003) 
and Ji and Grishman (2007) investigated the 
general name entity translation problem, 
especially in the context of machine translation. 
This paper aims to identify mono-lingual 
name spelling variants using cross-lingual 
information. Instead of using a named entity 
tagger to identify name spelling variants, we 
treat names in one language as the anchor of 
spelling variants in another language. From 
sentence-aligned bilingual corpora we collect 
word co-occurrence statistics and calculate word 
translation1 probabilities. For each source word, 
we group its target translations into clusters 
according to string edit distances, then calculate 
the transliteration cost between the source word 
and each target translation cluster. Word pairs 
with small transliteration costs are considered as 
name translations, and the target cluster contains 
multiple spelling variants corresponding to the 
source name.  
We apply this approach to extract name 
transliteration spelling variants from bilingual 
corpora. We obtained tens of thousands of high 
precision name translation pairs. We further 
apply these spelling variants to Machine 
Translation (MT) and Information Extraction (IE) 
tasks, and observed statistically significant 
improvement on the IE task, and close to oracle 
improvement on the MT task.  
The rest of the paper is organized as follows. 
In section 2 we describe the technique to 
identify name spelling variants from bilingual 
data. In section 3 and 4 we address their 
application to MT and IE respectively. We 
present our experiment results and detailed 
analysis in section 5. Section 6 concludes this 
paper with future work. 
2 Finding Name Translation Variants 
                                                          
1
 In this paper, the translation cost measures the semantic 
difference between source and target names, which are 
estimated from their co-occurrence statistics. The 
transliteration cost measures their phonetic distance and are 
estimated based on a character transliteration model. 
Starting from sentence-aligned parallel data, we 
run HMM alignment (Vogel et. al. 1996 & Ge 
2004) to obtain a word translation model. For 
each source word this model generates target 
candidate translations as well as their translation 
probabilities. A typical entry is shown in Table 1.  
It can be observed that the Arabic name?s 
translations include several English words with 
similar spellings, all of which are correct 
translations. However, because the lexical 
translation probabilities are distributed among 
these variants, none of them has the highest 
probability. As a result, the incorrect translation, 
iqlim, is assigned the highest probability and 
often selected in MT output. To fix this problem, 
it is desirable to identify and group these target 
spelling variants, convert them into a canonical 
form and merge their translation probabilities.  
 | Alxrwb
iqlim 
[0.22] 
al-kharrub 
[0.16] 
al-kharub 
[0.11] 
overflew 
[0.09] 
junbulat 
[0.05] 
al-khurub 
[0.05] 
hours 
[0.04] 
al-kharroub 
[0.03] 
 
Table 1. English translations of a Romanized Arabic 
name Alxrwb with translation probabilities. 
   For each source word in the word translation 
model, we cluster its target translations based on 
string edit distances using group average 
agglomerative clustering algorithm (Manning 
and Sch?tze, 2000). Initially each target word is 
a single word cluster. We calculate the average 
editing distance between any two clusters, and 
merge them if the distance is smaller than a 
certain threshold. This process repeats until the 
minimum distance between any two clusters is 
above a threshold. In the above example, al-
kharrub, al-kharub, al-khurub and al-kharroub 
are grouped into a single cluster, and each of the 
ungrouped words remains in its single word 
cluster. Note that the source word may not be a 
name while its translations may still have similar 
spellings. An example is the Arabic word   
which is aligned to English words brief, briefing, 
briefed and briefings. To detect whether a source 
word is a name, we calculate the transliteration 
cost between the source word and its target 
translation cluster, which is defined as the 
average transliteration cost between the source 
word and each target word in the cluster. As 
392
many names are translated based on their 
pronunciations, the source and target names 
have similar phonetic features and lower 
transliteration costs. Word pairs whose 
transliteration cost is lower than an empirically 
selected threshold are considered as name 
translations. 
2.1 Name Transliteration Cost 
The transliteration cost measures the phonetic 
similarity between a source word and a target 
word. It is calculated based on the character 
transliteration model, which can be trained from 
bilingual name translation pairs. We segment the 
source and target names into characters, then run 
monotone2 HMM alignment on the source and 
target character pairs. After the training, 
character transliteration probabilities can be 
estimated from the relevant frequencies of 
character alignments. 
Suppose the source word f contains m 
characters, f1, f2, ?, fm,  and the target word e 
contains n characters, e1, e2, ?, en. For j=1, 2,?, 
n, letter  ej is aligned to character jaf according 
to the HMM aligner. Under the assumption that 
character alignments are independent, the word 
transliteration probability is calculated as 
 ?
=
=
n
j
aj jfepfeP
1
)|()|(          (2.1) 
where )|(
jaj fep is the character transliteration 
probability.  Note that in the above configuration 
one target character can be aligned to only one 
source character, and one source character can 
be aligned to multiple target characters.  
An example of the trained A-E character 
transliteration model is shown in Figure 1. The 
Arabic character  is aligned with high 
probabilities to English letters with similar 
pronunciation. Because Arabic words typically 
omit vowels, English vowels are also aligned to 
Arabic characters. Given this model, the 
characters within a Romanized Arabic name and 
its English translation are aligned as shown in 
Figure 1.   
                                                          
2
 As name are typically phonetically translated, the 
character alignment are often monotone. There is no cross-
link in character alignments. 
2.2 Transliteration Unit Selection 
The transliteration units are typically characters. 
The Arabic alphabet includes 32 characters, and 
the English alphbet includes 56 letters 3 . 
However, Chinese has about 4000 frequent 
characters. The imbalance of Chinese and 
English vocabulary sizes results in suboptimal 
transliteration model estimation. Each Chinese 
character also has a pinyin, the Romanized 
representation of its pronunciation. Segmenting 
the Chinese pinyin into sequence of Roman 
letters, we now have comparable vocabulary 
sizes for both Chinese and English. We build a 
pinyin transliteration model using Chinese-
English name translation pairs, and compare its 
performance with a character transliteration 
model in Experiment section 5.1. 

h 
[0.44] 
K 
[0.29] 
k 
[0.21] 
a 
[0.03] 
u 
[0.015] 
i 
[0.004] 
 
Figure 1. Example of the learned A-E character 
transliteration model with probabilities, and its 
application in the alignment between an Romanized 
Arabic name and an English translation. 
3 Application to Machine Translation 
We applied the extracted name translation 
spelling variants to the machine translation task. 
Given the name spelling variants, we updated 
both the translation and the language model, 
adding variants? probabilities to the canonical 
form. 
   Our baseline MT decoder is a phrase-based 
decoder as described in (Al-Onaizan and 
Papineni 2006). Given a source sentence, the 
decoder tries to find the translation hypothesis 
with minimum translation cost, which is defined 
as the log-linear combination of different feature 
functions, such as translation model cost, 
language model cost, distortion cost and 
                                                          
3Uppercase and lowercase letters plus some special 
symbols such as ?_?, ?-?. 
393
sentence length cost. The translation cost 
includes word translation probability and phrase 
translation probability. 
3.1 Updating The Translation Model 
Given target name spelling variants { mttt ,...,, 21  
} for a source name s, here mttt ,...,, 21 are sorted 
based on their lexical translation probabilities, 
).|(...)|()|( 21 stpstpstp m???  
We select 1t  as the canonical spelling, and 
merge other spellings? translation probabilities 
with this one: 
?
=
=
m
j
m stpstp
1
1 ).|()|(  
Other spelling variants get zero probability. 
Table 2 shows the updated word translation 
probabilities for ?|Alxwrb?. Compared 
with Figure 1, the translation probabilities from 
several spelling variants are merged with the 
canonical form, al-kharrub, which now has the 
highest probability in the new model. 

Table 2. English translations of an Arabic name |Alxrwb with the updated word translation 
model. 
 
   The phrase translation table includes source 
phrases, their target phrase translations and the 
frequencies of the bilingual phrase pair 
alignment. The phrase translation probabilities 
are calculated based on their alignment 
frequencies, which are collected from word 
aligned parallel data. To update the phrase 
translation table, for each phrase pair including a 
source name and its spelling variant in the target 
phrase, we replace the target name with its 
canonical spelling. After the mapping, two target 
phrases differing only in target names may end 
up with the identical target phrase, and their 
alignment frequencies are added. Phrase 
translation probabilities are re-estimated with the 
updated frequencies. 
3.2 Updating The Language Model 
The machine translation decoder uses a language 
model as a measure of a well-formedness of the 
output sentence. Since the updated translation 
model can produce only the canonical form of a 
group of spelling variants, the language model 
should be updated in that all m-grams 
( Nm ??1 ) that are spelling variants of each 
other are merged (and their counts added), 
resulting in the canonical form of the m-gram. 
Two m-grams are considered spelling variants of 
each other if they contain words it1 , 
it2 ( ii tt 21 ? ) 
at the same position i in the m-gram, and that it1  
and it2 belong to the same spelling variant group. 
   An easy way to achieve this update is to 
replace every spelling variant in the original 
language model training data with its 
corresponding canonical form, and then build 
the language model again. However, since we do 
not want to replace words that are not names we 
need to have a mechanism for detecting names.  
For simplicity, in our experiments we assumed a 
word is a name if it is capitalized, and we 
replaced spelling variants with their canonical 
forms only for words that start with a capital 
letter.  
4 Applying to Information Extraction 
Information extraction is a crucial step toward 
understanding a text, as it identifies the 
important conceptual objects in a discourse. We 
address here one important and basic task of 
information extraction: mention detection4: we 
call instances of textual references to objects 
mentions, which can be either named (e.g. John 
Smith), nominal (the president) or pronominal 
(e.g. he, she). For instance, in the sentence  
? President John Smith said he has no 
comments.   
there are two mentions: John Smith and he. 
Similar to many classical NLP tasks, we 
formulate the mention detection problem as a 
classification problem, by assigning to each 
token in the text a label, indicating whether it 
starts a specific mention, is inside a specific 
mention, or is outside any mentions. Good 
                                                          
4We adopt here the ACE (NIST 2007) nomenclature. 
 | Alxwrb
al-kharrub 
 [0.35] 
 iqlim 
 [0.22] 
al-kharub 
[0.0] 
overflew 
[0.09] 
junbulat 
[0.05] 
al-khurub 
[0.0] 
hours 
[0.04] 
al-kharroub 
[0.0] 
 
394
performance in many natural language 
processing tasks has been shown to depend 
heavily on integrating many sources of 
information (Florian et al 2007). We select an 
exponential classifier, the Maximum Entropy 
(MaxEnt henceforth) classifier that can integrate 
arbitrary types of information and make a 
classification decision by aggregating all 
information available for a given classification 
(Berger et al 1996). In this paper, the MaxEnt 
model is trained using the sequential conditional 
generalized iterative scaling (SCGIS) technique 
(Goodman, 2002), and it uses a Gaussian prior 
for regularization (Chen and Rosenfeld, 2000). 
   In ACE, there are seven possible mention 
types: person, organization, location, facility, 
geopolitical entity (GPE), weapon, and vehicle. 
Experiments are run on Arabic and English. Our 
baseline system achieved very competitive result 
among systems participating in the ACE 2007 
evaluation. It uses a large range of features, 
including lexical, syntactic, and the output of 
other information extraction models. These 
features were described in (Zitouni and Florian, 
2008 & Florian et al 2007), and are not 
discussed here. In this paper we focus on 
examining the effectiveness of name spelling 
variants in improving mention detection 
systems. We add a new feature that for each 
token xi  to process we fire its canonical form 
(class label) C(xi) ,  representative of name 
spelling variants of xi . This name spelling 
variant feature is also used in conjunction with 
the lexical (e.g., words and morphs in a 3-word 
window, prefixes and suffixes of length up to 4, 
stems in a 4-word window for Arabic) and 
syntactic (POS tags, text chunks) features. 
5 Experiments 
5.1 Evaluating the precision of name 
spelling variants 
We extracted Arabic-English and English-
Arabic name translation variants from sentence-
aligned parallel corpora released by LDC. The 
accuracy of the extracted name translation 
spelling variants are judged by proficient Arabic 
and Chinese speakers. 
   The Arabic-English parallel corpora include 
5.6M sentence pairs, 845K unique Arabic words 
and 403K unique English words. We trained a 
word translation model by running HMM 
alignment on the parallel data, grouped target 
translation with similar spellings and computed 
the average transliteration cost between the 
Arabic word and each English word in the 
translation clusters according to Formula 2.1. 
We sorted the name translation groups according 
to their transliteration costs, and selected 300 
samples at different ranking position for 
evaluation (20 samples at each ranking position). 
The quality of the name translation variants are 
judged as follows: for each candidate name 
translation group }|,...,,{ 21 sttt m , if the source 
word s is a name and all the target spelling 
variants are correct translations, it gets a credit 
of 1. If s is not a name, the credit is 0. If s is a 
name but only part of the target spelling variants 
are correct, it gets partial credit n/m, where n is 
the number of correct target translations. We 
evaluate only the precision of the extracted 
spelling variants 5 . As seen in Figure 2, the 
precision of the top 22K A-E name translations 
is 96.9%. Among them 98.5% of the Arabic 
words are names. The precision gets lower and 
lower when more non-name Arabic words are 
included. On average, each Arabic name has 
2.47 English spelling variants, although there are 
some names with more than 10 spelling variants. 
   Switching the source and target languages, we 
obtained English-Arabic name spelling variants, 
i.e., one English name with multiple Arabic 
spellings. As seen in Figure 3, top 20K E-A 
name pairs are obtained with a precision above 
87.9%, and each English name has 3.3 Arabic 
spellings on average. Table 3 shows some A-E 
and E-A name spelling variants, where Arabic 
words are represented in their Romanized form. 
  We conduct a similar experiment on the 
Chinese-English language pair, extracting 
Chinese-English and English-Chinese name 
spelling variants from 8.7M Chinese-English 
sentence pairs. After word segmentation, the 
Chinese vocabulary size is 1.5M words, and 
English vocabulary size is 1.4M words. With the  
                                                          
5
 Evaluating recall requires one to manually look through 
the space of all possible transliterations (hundreds of 
thousands of entries), which is impractical. 
395
Chinese pinyin transliteration model, we extract 
64K C-E name spelling variants with 93.6% 
precision. Figure 4 also shows the precision 
curve of the Chinese character transliteration 
model. On average the pinyin transliteration 
model has about 6% higher precision than the 
character transliteration model. The pinyin 
transliteration model is particularly better on the 
tail of the curve, extracting more C-E 
transliteration variants. Figure 5 shows the 
precision curve for E-C name spelling variants, 
where 20K name pairs are extracted using letter-
to-character transliteration model, and obtaining 
a precision of 74.3%. 
 Table 4 shows some C-E and E-C name 
spelling variants. We observed errors due to 
word segmentation. For example, the last two 
Chinese words corresponding to ?drenica? have 
additional Chinese characters, meaning ?drenica 
region? and ?drenica river?. Similarly for tenet, 
the last two Chinese words also have 
segmentation errors due to missing or spurious 
characters. Note that in the C-E spelling variants, 
the source word ? ? has 14 spelling 
variants. Judge solely from the spelling, it is 
hard to tell whether they are the same person 
name with different spellings. 
5.2   Experiments on Machine Translation 
We apply the Arabic-English name spelling 
variants on the machine translation task. Our 
baseline system is trained with 5.6M Arabic- 
English sentence pairs, the same training data 
used to extract A-E spelling variants. The 
language model is a modified Kneser-Ney 5-
gram model trained on roughly 3.5 billion words. 
After pruning (using count cutoffs), it contains a 
total of 935 million N-grams. We updated the 
translation models and the language model with 
the name spelling variant class. 
   Table 5 shows a Romanized Arabic sentence, 
the translation output from the baseline system 
and the output from the updated models. In the 
baseline system output, the Arabic name 
?Alxrwb? was incorrectly translated into 
?regional?. This error was fixed in the updated 
model, where both translation and language 
models assign higher probabilities to the correct 
translation ?al-kharroub? after spelling variant 
normalization.  
 
 
	
	
		

























	

















	
	













	











	









	

 
Figure 2. Arabic-English name spelling variants 
precision curve (Precision of evaluation sample at 
different ranking positions. The larger square indicates 
the cutoff point). 
	
	
		

























	

















	
	













	











	









	
ranking
pinyin char
 
Figure 4. Chinese-English name spelling variants 
precision curve. 
	
	
		

























	

















	
	













	











	




 
Figure 3. English-Arabic name spelling variants 
precision curve. 
	
	
		

























	

















	
	













	











	




 
Figure 5. English-Chinese name spelling variants 
precision curve. 
396
Source Alm&tmr AlAwl lAqlym Alxrwb AlErby AlmqAwm 
Reference the first conference of the Arab resistance in Iqlim Kharoub 
Baseline the first conference of the Arab regional resistance 
Updated model first conference of the Al-Kharrub the Arab resistance 
 
Table 5. English translation output with the baseline MT system and the system with updated models 
 
    
 BLEU 
r1n4 TER 
Baseline 0.2714 51.66 
Baseline+ULM+UTM 0.2718 51.46 
Ref. Normalization 0.2724 51.40 
Table 6. MT scores with updated TM and LM 
  We also evaluated the updated MT models on a 
MT test set. The test set includes 70 documents 
selected from GALE 2007 Development set. It 
contains 42 newswire documents and 28 weblog 
and newsgroup documents. There are 669 
sentences with 16.3K Arabic words in the test 
data. MT results are evaluated against one 
reference human translation using BLEU 
(Papineni et. al. 2001) and TER (Snover et. al. 
2006) scores. The results using the baseline 
decoder and the updated models are shown in 
Table 6. Applying the updated language model 
(ULM) and the translation model (UTM) lead to 
a small reduction in TER. After we apply similar 
name spelling normalization on the reference 
translation, we observed some additional 
improvements. Overall, the BLEU score is 
increased by 0.1 BLEU point and TER is 
reduced by 0.26. 
   Although the significance of correct name 
translation can not be fully represented by 
 
Table 3. Arabic-English and English-Arabic name spelling variant examples. Italic words represent different 
persons with similar spelling names. 
 
Lang. Pair Source Name Target Spelling Variants 
Alxmyny khomeini al-khomeini al-khomeni khomeni khomeyni khamenei khameneh'i 
krwby     karroubi karrubi krobi karubi karoubi kroubi 
Arabic-
English 
gbryAl     gabriel gabrielle gabrial ghobrial ghybrial 
cirebon   syrybwn syrbwn syrbn kyrybwn bsyrybwn bsyrwbwn 
mbinda     mbyndA mbndA mbydA AmbyndA AmbAndA mbynydA  
English-
Arabic 
nguyen     njwyn ngwyn ngwyyn ngyyn Angwyn nygwyyn nygwyn wnjwyn njwyyn 
nyjyn bnjwyn wngyyn ngwyAn njyn nykwyn  
 
Table 4. Chinese-English and English-Chinese name spelling variant examples with pinyin for Chinese characters. 
Italic words represent errors due to word segmentation. 
Lang. Pair Source Name  Target Spelling Variants 
	

(yan/duo/wei/ci/ji) 
endovitsky jendovitski yendovitski endovitski 
  
(si/te/fan/ni) 
stefani steffani stephani stefanni stefania 
Chinese-
English 
 
(wei/er/man) 
woermann wellman welman woellmann wohrmann wormann velman 
wollmann wehrmann verman woehrmann wellmann welmann wermann 
tenet (te/ni/te) (te/nei/te) (tai/nei/te) (te/nai/te) 
(te/nai/te) (te/nei/te/yu) (te/nei) 
drenica (de/lei/ni/cha) (de/lei/ni/ka) (te/lei/ni/cha) 
(te/lei/ni/cha) (de/lei/ni/cha/qu) 	
(de/lei/ni/cha/he) 
English-
Chinese 
ahmedabad Training Connectionist Models for the Structured Language Model  
Peng Xu, Ahmad Emami and Frederick Jelinek
Center for Language and Speech Processing
Johns Hopkins University
Baltimore, MD 21218

xp,emami,jelinek  @jhu.edu
Abstract
We investigate the performance of the
Structured Language Model (SLM) in
terms of perplexity (PPL) when its compo-
nents are modeled by connectionist mod-
els. The connectionist models use a dis-
tributed representation of the items in
the history and make much better use of
contexts than currently used interpolated
or back-off models, not only because of
the inherent capability of the connection-
ist model in fighting the data sparseness
problem, but also because of the sub-
linear growth in the model size when the
context length is increased. The connec-
tionist models can be further trained by an
EM procedure, similar to the previously
used procedure for training the SLM. Our
experiments show that the connectionist
models can significantly improve the PPL
over the interpolated and back-off mod-
els on the UPENN Treebank corpora, after
interpolating with a baseline trigram lan-
guage model. The EM training procedure
can improve the connectionist models fur-
ther, by using hidden events obtained by
the SLM parser.
1 Introduction
In many systems dealing with natural speech or lan-
guage such as Automatic Speech Recognition and

This work was supported by the National Science Founda-
tion under grants No.IIS-9982329 and No.IIS-0085940.
Statistical Machine Translation, a language model
is a crucial component for searching in the often
prohibitively large hypothesis space. Most of the
state-of-the-art systems use n-gram language mod-
els, which are simple and effective most of the
time. Many smoothing techniques that improve lan-
guage model probability estimation have been pro-
posed and studied in the n-gram literature (Chen and
Goodman, 1998).
Recent efforts have studied various ways of us-
ing information from a longer context span than that
usually captured by normal n-gram language mod-
els, as well as ways of using syntactical informa-
tion that is not available to the word-based n-gram
models (Chelba and Jelinek, 2000; Charniak, 2001;
Roark, 2001; Uystel et al, 2001). All these language
models are based on stochastic parsing techniques
that build up parse trees for the input word sequence
and condition the generation of words on syntactical
and lexical information available in the parse trees.
Since these language models capture useful hierar-
chical characteristics of language, they can improve
the PPL significantly for various tasks. Although
more improvement can be achieved by enriching the
syntactical dependencies in the structured language
model (SLM) (Xu et al, 2002), a severe data sparse-
ness problem was observed in (Xu et al, 2002) when
the number of conditioning features was increased.
There has been recent promising work in us-
ing distributional representation of words and neu-
ral networks for language modeling (Bengio et al,
2001) and parsing (Henderson, 2003). One great ad-
vantage of this approach is its ability to fight data
sparseness. The model size grows only sub-linearly
with the number of predicting features used. It has
been shown that this method improves significantly
on regular n-gram models in perplexity (Bengio et
al., 2001). The ability of the method to accommo-
date longer contexts is most appealing, since exper-
iments have shown consistent improvements in PPL
when the context of one of the components of the
SLM is increased in length (Emami et al, 2003).
Moreover, because the SLM provides an EM train-
ing procedure for its components, the connectionist
models can also be improved by the EM training.
In this paper, we will study the impact of neural
network modeling on the SLM, when all of its three
components are modeled with this approach. An EM
training procedure will be outlined and applied to
further training of the neural network models.
2 A Probabilistic Neural Network Model
Recently, a relatively new type of language model
has been introduced where words are represented
by points in a multi-dimensional feature space and
the probability of a sequence of words is computed
by means of a neural network. The neural network,
having the feature vectors of the preceding words as
its input, estimates the probability of the next word
(Bengio et al, 2001). The main idea behind this
model is to fight the curse of dimensionality by inter-
polating the seen sequences in the training data. The
generalization this model aims at is to assign to an
unseen word sequence a probability similar to that
of a seen word sequence whose words are similar to
those of the unseen word sequence. The similarity
is defined as being close in the multi-dimensional
space mentioned above.
In brief, this model can be described as follows.
A feature vector is associated with each token in the
input vocabulary, that is, the vocabulary of all the
items that can be used for conditioning. Then the
conditional probability of the next word is expressed
as a function of the input feature vectors by means
of a neural network. This probability is produced
for every possible next word from the output vocab-
ulary. In general, there does not need to be any rela-
tionship between the input and output vocabularies.
The feature vectors and the parameters of the neural
network are learned simultaneously during training.
The input to the neural network are the feature vec-
tors for all the inputs concatenated, and the output
is the conditional probability distribution over the
output vocabulary. The idea here is that the words
which are close to each other (close in the sense of
their role in predicting words to follow) would have
similar (close) feature vectors and since the proba-
bility function is a smooth function of these feature
values, a small change in the features should only
lead to a small change in the probability.
2.1 The Architecture of the Neural Network
Model
The conditional probability function
  
		
	
where

and  are from the
input and output vocabularies 