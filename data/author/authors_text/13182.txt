Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 46?50,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
A Statistical Spoken Dialogue System using Complex User Goals and
Value Directed Compression
Paul A. Crook, Zhuoran Wang, Xingkun Liu and Oliver Lemon
Interaction Lab
School of Mathematical and Computer Sciences (MACS)
Heriot-Watt University, Edinburgh, UK
{p.a.crook, zhuoran.wang, x.liu, o.lemon}@hw.ac.uk
Abstract
This paper presents the first demonstration
of a statistical spoken dialogue system that
uses automatic belief compression to rea-
son over complex user goal sets. Reasoning
over the power set of possible user goals al-
lows complex sets of user goals to be rep-
resented, which leads to more natural dia-
logues. The use of the power set results in a
massive expansion in the number of belief
states maintained by the Partially Observ-
able Markov Decision Process (POMDP)
spoken dialogue manager. A modified form
of Value Directed Compression (VDC) is
applied to the POMDP belief states produc-
ing a near-lossless compression which re-
duces the number of bases required to rep-
resent the belief distribution.
1 Introduction
One of the main problems for a spoken dialogue
system (SDS) is to determine the user?s goal (e.g.
plan suitable meeting times or find a good Indian
restaurant nearby) under uncertainty, and thereby
to compute the optimal next system dialogue ac-
tion (e.g. offer a restaurant, ask for clarification).
Recent research in statistical SDSs has success-
fully addressed aspects of these problems through
the application of Partially Observable Markov
Decision Process (POMDP) approaches (Thom-
son and Young, 2010; Young et al 2010). How-
ever POMDP SDSs are currently limited by the
representation of user goals adopted to make sys-
tems computationally tractable.
Work in dialogue system evaluation, e.g.
Walker et al(2004) and Lemon et al(2006),
shows that real user goals are generally sets of
items, rather than a single item. People like to
explore possible trade offs between the attributes
of items.
Crook and Lemon (2010) identified this as a
central challenge for the field of spoken dialogue
systems, proposing the use of automatic compres-
sion techniques to allow for extended accurate
representations of user goals. This paper presents
a proof of concept of these ideas in the form of a
complete, working spoken dialogue system. The
POMDP dialogue manager (DM) of this demon-
stration system uses a compressed belief space
that was generated using a modified version of the
Value Directed Compression (VDC) algorithm
as originally proposed by Poupart (2005). This
demonstration system extends work presented by
Crook and Lemon (2011) in that it embeds the
compressed complex user goal belief space into a
working system and demonstrates planning (and
acting) in the compressed space.
2 Complex User Goals
The type of SDS task that we focus on is a limited-
domain query-dialogue, also known as a ?slot fill-
ing? task. The spoken dialogue system has knowl-
edge about some set of objects where these ob-
jects have attributes and these attributes can take
several values. An object can thus be described
by a conjunction of attribute-value pairs. A di-
alogue progresses with the system obtaining re-
quirements from the user which are specified in
terms of attribute values. The system should even-
tually present objects (search results) based upon
its understanding of the user?s requirement. The
dialogue ends when the user accepts one of the
domain objects.
Prior work on POMDP SDSs has assumed that
a user has a narrowly constrained goal (as speci-
46
User goal: cheap central Thai or expensive French
S: Hello, how can I help you?
U: I?m looking for a cheap central Thai restaurant.
S: You?re looking for budget, city centre, Thai
restaurants. ?
U: Or an expensive French restaurant anywhere.
S: You?re looking for non-budget French restaurants.
What ?
U: And cheap, city centre, Thai.
S: You?re looking for budget, city centre, Thai
restaurants. What about ?
U: (SIGH) And French.
S: You?re looking for budget, city centre, French
restaurants. What about ?
U: (HANG UP)
Table 1: Example dialogue using simple user goals.
S=System, U=User. ??? indicates the user barged in.
fied in terms of the domain objects) and thus the
role of the DM is one of reducing uncertainty un-
til its belief is strongly focused on a particular do-
main object. This has the unfortunate effect of
forcing users to select one domain object in order
to progress the dialogue, see Table 1. Note that the
example given is problematic not only because the
user wants two different food types but because
they have different requirements associated with
each, i.e. Thai restaurants should be in the centre
and cheap, while any French restaurants should be
expensive1 and can be located anywhere. To our
knowledge such a combination of goals with dif-
ferent attribute values cannot be straightforwardly
handled by comparable state-of-the-art statistical
SDSs which appear in the literature.
Crook and Lemon (2011) suggest that rather
than the DM assuming that the user has a single
narrowly constrained goal in mind, it should as-
sume that they want any possible sub-set of the
complete set of domain objects. Thus, instead
of maintaining the POMDP belief over individual
domain objects, it should be maintained over the
power set of domain objects. As an example see
Table 3 which is the power set for a domain with
three objects that can take two attributes u, v with
associated values u1, u2, u3 and v1 respectively.
The power set representation allows the
demonstration system to straightforwardly handle
previously problematic dialogues. See Table 2.
Of course this approach significantly expands the
1Interpreted as non-budget by the system since its
database only classifies restaurants as budget or non-budget.
User goal: cheap central Thai or expensive French
S: Hello, how can I help you?
U: I?m looking for a cheap central Thai restaurant.
S: You?re looking for budget, city centre, Thai
restaurants. ?
U: Or an expensive French restaurant anywhere.
S: You?re looking for budget, city centre, Thai
restaurants or non-budget French. What about
Chang Thai in Old Town?? Chang Thai?s set lunch
price is ? 7.95 ?
U: What alternatives do you have?
S: What about the Plumed Horse in Leith?? The
Plumed Horse is a Michelin starred French ...
Table 2: Example dialogue using complex user goals.
S=System, U=User. ?Old Town is part of the city cen-
tre. ?Leith is outside the centre.
state space of possible user goals, with the num-
ber of goal sets being equal to 2|domain objects| .
2.1 Automatic Compression
Even considering limited domains, POMDP state
spaces for SDSs grow very quickly. Thus the cur-
rent state-of-the-art in POMDP SDSs uses a vari-
ety of handcrafted compression techniques, such
as making several types of independence assump-
tion as discussed above.
Crook and Lemon (2010) propose replacing
handcrafted compressions with automatic com-
pression techniques. The idea is to use princi-
pled statistical methods for automatically reduc-
ing the dimensionality of belief spaces, but which
preserve useful distributions from the full space,
and thus can more accurately represent real user?s
goals.
2.2 VDC Algorithm
The VDC algorithm (Poupart, 2005) uses Krylov
iteration to compute a reduced state space. It finds
a set of linear basis vectors that can reproduce the
value2 of being in any of the original POMDP
states. Where, if a lossless VDC compression is
possible, the number of basis vectors is less than
the original number of POMDP states.
The intuition here is that if the value of taking
an action in a given state has been preserved then
planning is equally as reliable in the compressed
space as the in full space.
The VDC algorithm requires a fully specified
POMDP, i.e. ?S,A,O, T,?,R? where S is the set
2The sum of discounted future rewards obtained through
following some series of actions.
47
state goal set meaning: user?s goal is
s1 ? (empty set) none of the domain objects
s2 u=u1?v=v1 domain object 1
s3 u=u2?v=v1 domain object 2
s4 u=u3?v=v1 domain object 3
s5 (u=u1?v=v1) ? (u=u2?v=v1) domain objects 1 or 2
s6 (u=u1?v=v1) ? (u=u3?v=v1) domain objects 1 or 3
s7 (u=u2?v=v1) ? (u=u3?v=v1) domain objects 2 or 3
s8 (u=u1?v=v1) ? (u=u2?v=v1) ? (u=u3?v=v1) any of the domain objects
Table 3: Example of complex user goal sets.
of states, A is the set of actions, O is the set of ob-
servations, T conditional transition probabilities,
? conditional observation probabilities, and R is
the reward function. Since it iteratively projects
the rewards associated with each state and action
using the state transition and observation proba-
bilities, the compression found is dependent on
structures and regularities in the POMDP model.
The set of basis vectors found can be used to
project the POMDP reward, transition, and obser-
vation probabilities into the reduced state space
allowing the policy to be learnt and executed in
this state space.
Although the VDC algorithm (Poupart, 2005)
produces compressions that are lossless in terms
of the states? values, the set of basis vectors found
(when viewed as a transformation matrix) can be
ill-conditioned. This results in numerical instabil-
ity and errors in the belief estimation. The com-
pression used in this demonstration was produced
using a modified VDC algorithm that improves
the matrix condition by approximately selecting
the most independent basis vectors, thus improv-
ing numerical stability. It achieves near-lossless
state value compression while allowing belief es-
timation errors to be minimised and traded-off
against the amount of compression. Details of this
algorithm are to appear in a forthcoming publica-
tion.
3 System Description
3.1 Components
Input and output to the demonstration system is
using standard open source and commercial com-
ponents. FreeSWITCH (Minessale II, 2012) pro-
vides a platform for accepting incoming Voice
over IP calls, routing them (using the Media Re-
source Control Protocol (MRCP)) to a Nuance 9.0
Automatic Speech Recogniser (Nuance, 2012).
Output is similarly handled by FreeSWITCH
routing system responses via a CereProc Text-to-
Speech MRCP server (CereProc, 2012) in order
to respond to the user.
The heart of the demonstration system consists
of a State-Estimator server which estimates the
current dialogue state using the compressed state
space previously produced by VDC, a Policy-
Executor server that selects actions based on
the compressed estimated state, and a template
based Natural Language Generator server. These
servers, along with FreeSWITCH, use ZeroC?s
Internet Communications Engine (Ice) middle-
ware (ZeroC, 2012) as a common communica-
tions platform.
3.2 SDS Domain
The demonstration system provides a restaurant
finder system for the city of Edinburgh (Scot-
land, UK). It presents search results from a real
database of over 600 restaurants. The search
results are based on the attributes specified by
the user, currently; location, food type and
budget/non-budget.
3.3 Interface
The demonstration SDS is typically accessed over
the phone network. For debugging and demon-
stration purposes it is possible to visualise the
belief distribution maintained by the DM as dia-
logues progress. The compressed version of the
belief distribution is not a conventional proba-
bility distribution3 and its visualisation is unin-
formative. Instead we take advantage of the re-
versibility of the VDC compression and project
the distribution back onto the full state space. For
an example of the evolution of the belief distribu-
tion during a dialogue see Figure 1.
3The values associated with the basis vectors are not con-
fined to the range [0? 1].
48
#4096
10?7 10?6 10?5 0.0001 0.001
(a) Initial uniform distribution over the power set.
#2048
#2048
10?7 10?6 10?5 0.0001 0.001
(b) Distribution after user responds to greet.
#512
#3584
10?11 10?9 10?7 10?5 0.001
(c) Distribution after second user utterance.
Figure 1: Evolution of the belief distribution for the
example dialogue in Table 2. The horizontal length of
each bar corresponds to the probability of that com-
plex user goal state. Note that the x-axis uses a log-
arithmic scale to allow low probability values to be
seen. The y-axis is the set of complex user goals or-
dered by probability. Lighter shaded (green) bars indi-
cate complex user goal states corresponding to ?cheap,
central Thai? and ?cheap, central Thai or expensive
French anywhere? in figures (b) and (c) respectively.
The count ?#? indicates the number of states in those
groups.
4 Conclusions
We present a demonstration of a statistical SDS
that uses automatic belief compression to reason
over complex user goal sets. Using the power set
of domain objects as the states of the POMDP
DM allows complex sets of user goals to be rep-
resented, which leads to more natural dialogues.
To address the massive expansion in the number
of belief states, a modified form of VDC is used
to generate a compression. It is this compressed
space which is used by the DM for planning and
acting in response to user utterances. This is the
first demonstration of a statistical SDS that uses
automatic belief compression to reason over com-
plex user goal sets.
VDC and other automated compression tech-
niques reduce the human design load by automat-
ing part of the current POMDP SDS design pro-
cess. This reduces the knowledge required when
building such statistical systems and should make
them easier for industry to deploy.
Such compression approaches are not only ap-
plicable to SDSs but should be equally relevant
for multi-modal interaction systems where sev-
eral modalities are being combined in user-goal
or state estimation.
5 Future Work
The current demonstration system is a proof
of concept and is limited to a small number
of attributes and attribute-values. Part of our
ongoing work involves investigation of scaling.
For example, increasing the number of attribute-
values should produce more regularities across
the POMDP space. Does VDC successfully ex-
ploit these?
We are in the process of collecting corpora
for the Edinburgh restaurant domain mentioned
above with the aim that the POMDP observation
and transition statistics can be derived from data.
As part of this work we have launched a long
term, public facing outlet for testing and data col-
lection, see http:\\www.edinburghinfo.
co.uk. It is planned to make future versions of
the demonstration system discussed in this paper
available via this public outlet.
Finally we are investigating the applicability
of other automatic belief (and state) compression
techniques for SDSs, e.g. E-PCA (Roy and Gor-
don, 2002).
49
Acknowledgments
The research leading to these results was funded
by the Engineering and Physical Sciences Re-
search Council, UK (EPSRC) under project no.
EP/G069840/1 and was partially supported by the
EC FP7 projects Spacebook (ref. 270019) and
JAMES (ref. 270435).
References
CereProc. 2012. http://www.cereproc.com/.
Paul A. Crook and Oliver Lemon. 2010. Representing
uncertainty about complex user goals in statistical
dialogue systems. In proceedings of SIGdial.
Paul A. Crook and Oliver Lemon. 2011. Lossless
Value Directed Compression of Complex User Goal
States for Statistical Spoken Dialogue Systems. In
Proceedings of the Twelfth Annual Conference of
the International Speech Communication Associa-
tion (Interspeech).
Oliver Lemon, Kallirroi Georgila, and James Hender-
son. 2006. Evaluating Effectiveness and Portabil-
ity of Reinforcement Learned Dialogue Strategies
with real users: the TALK TownInfo Evaluation. In
IEEE/ACL Spoken Language Technology.
Anthony Minessale II. 2012. FreeSWITCH. http:
//www.freeswitch.org/.
Nuance. 2012. Nuance Recognizer. http://www.
nuance.com.
P. Poupart. 2005. Exploiting Structure to Efficiently
Solve Large Scale Partially Observable Markov De-
cision Processes. Ph.D. thesis, Dept. Computer Sci-
ence, University of Toronto.
N. Roy and G. Gordon. 2002. Exponential Family
PCA for Belief Compression in POMDPs. In NIPS.
B. Thomson and S. Young. 2010. Bayesian update
of dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562?588.
Marilyn Walker, S. Whittaker, A. Stent, P. Maloor,
J. Moore, M. Johnston, and G. Vasireddy. 2004.
User tailored generation in the match multimodal
dialogue system. Cognitive Science, 28:811?840.
S. Young, M. Gas?ic?, S. Keizer, F. Mairesse, B. Thom-
son, and K. Yu. 2010. The Hidden Information
State model: a practical framework for POMDP
based spoken dialogue management. Computer
Speech and Language, 24(2):150?174.
ZeroC. 2012. The Internet Communications Engine
(Ice). http://www.zeroc.com/ice.html.
50
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 209?212,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Representing Uncertainty about Complex User Goals in Statistical
Dialogue Systems
Paul A. Crook
Interaction Lab
Heriot-Watt University
Edinburgh, United Kingdom
p.a.crook@hw.ac.uk
Oliver Lemon
Interaction Lab
Heriot-Watt University
Edinburgh, United Kingdom
o.lemon@hw.ac.uk
Abstract
We point out several problems in scaling-
up statistical approaches to spoken dia-
logue systems to enable them to deal with
complex but natural user goals, such as
disjunctive and negated goals and prefer-
ences. In particular, we explore restric-
tions imposed by current independence as-
sumptions in POMDP dialogue models.
This position paper proposes the use of
Automatic Belief Compression methods to
remedy these problems.
1 Introduction
One of the main problems for a spoken dia-
logue system is to determine the user?s goal (e.g.
plan suitable meeting times or find a good Indian
restaurant nearby) under uncertainty, and thereby
to compute the optimal next system dialogue ac-
tion (e.g. offer a restaurant, ask for clarification).
Recent research in statistical spoken dialogue sys-
tems (SSDS) has successfully addressed aspects of
these problems through the application of Partially
Observable Markov Decision Process (POMDP)
approaches (Thomson and Young, 2010; Young et
al., 2010). However POMDP SSDS are currently
limited by an impoverished representation of user
goals adopted to enable tractable learning.
Current POMDP SSDS state approximations
make it impossible to represent some plausible
user goals, e.g. someone who wants to know about
nearby cheap restaurants and high-quality ones
further away, or wants to schedule a meeting any-
time this week except monday afternoon (also see
Examples in Tables 1?3). This renders dialogue
management sub-optimal and makes it impossi-
ble to deal adequately with the following types of
user utterance: ?I?m looking for French or Ital-
ian food?, or ?Not Italian, unless it?s expensive?.
User utterances with negations and disjunctions of
various sorts are very natural, and exploit the full
power of natural language input. Moreover, work
in dialogue system evaluation, e.g. (Walker et al,
2004; Lemon et al, 2006), shows that real user
goals are generally sets of items with different fea-
tures, rather than a single item. People like to ex-
plore possible trade offs between features of items.
A central challenge for the field of spoken di-
alogue systems is therefore to: develop realistic
large-scale statistical approaches with an accurate,
extended representation of user goals.
In this paper we propose that the independence
assumptions that have guided POMDP SSDS de-
sign to date should be relaxed, user goal sets
should be introduced and that the subsequent ex-
plosion in the size of the state space should be
dealt with by employing Automatic Belief Com-
pression (ABC) techniques.
2 POMDP SSDS
Partially Observable Markov Decision Processes
(POMDPs) are Markov Decision Processes where
the system?s state is only partially observable, i.e.
there is uncertainty as to what the true state is.
The ability to account for uncertainty is crucial for
spoken dialogue systems because their knowledge
about the state is uncertain due to speech recogni-
tion errors and the fact that the user?s goals are not
directly observable. In POMDP models of spo-
ken dialogue (Williams and Young, 2005; Thom-
son and Young, 2010; Young et al, 2010) the dia-
logue policy (what the system should say next) is
based not on a single view of the current state of
the conversation, but on a probability distribution
over all possible states of the conversation. The
optimal POMDP SSDS dialogue act thus automat-
ically takes account of the uncertainty about the
user?s utterances and goals.
All work to date on POMDP SSDS has assumed
(i) that a user has a singular, fully constrained,
fixed goal and (ii) that there is one source of un-
209
User goal: good Italian but not Thai food User Goal: good Italian but not Thai food
POMDP SSDS (Example 1) ABC-SSDS (Example 2)
U1: What restaurants are nearby? U?1: What restaurants are nearby?
S1: There are 3 nearby. What type of food do you
want?
S?1: There are 3 nearby. What type of food do
you want?
U2: Not Italian, unless it?s really good U?2: Not Italian, unless it?s really good
S2: There are 2 Thai restaurants. S?2: Ok. Al Capone?s is highly rated. There are
?The compressed state (i.e. marginal likelihoods in Figure 1)
indicates that Italian food is dis-preferred.?
also 2 Thai restaurants nearby.
U3: No Thanks. Bye. U?3: Great. I?ll try Al Capone?s.
Table 1: State-of-the-art POMDP SSDS vs ABC-SSDS: Example dialogues 1 and 2. U=User, S=System
certainty; errors in speech recognition. The tradi-
tional role of the Dialogue Manager (DM) is there-
fore one of reducing uncertainty until its belief is
strongly focused on a single goal which strictly fits
the user?s stated constraints. Both the policies that
DMs currently follow and the design decisions im-
plemented to make SDSS tasks learnable use these
assumptions (Thomson and Young, 2010; Young
et al, 2010). The resulting systems force users
into selecting a single domain object as their goal
in order to progress the dialogue. The example
POMDP SSDS dialogues, Examples 1 and 3 (Ta-
bles 1 and 2), show the problems inherent in this
approach.
User goal: good Italian or good French food
S1: How can I help you?
U1: What restaurants are nearby?
S2: There are 6, what type of food do you
want?
U2: Err... Italian or French
S3: Do you want Italian or French food?
U3: Uh. either.
S4: Do you want Italian or French food?
U4: Ok , how about French then.
S5: There are 2 good French restaurants
nearby. What price range do you want?
U5: What about Italian?
S6: Did you say Italian?
U6: QUIT
Table 2: POMDP SSDS: Example 3
3 Independence Assumptions
Even considering limited domains, POMDP state
spaces grow very quickly. For example, consider
finding a user?s restaurant preference, which in-
volves getting 4 pieces of information, i.e. food-
type, city-area, price range, quality rating. Given 8
food types, 8 city areas, 3 price ranges and 3 qual-
ity ratings, coupled with 7 user actions and a 34 di-
alogue progress indicator1 then the dialogue state
space contains 8? 8? 3? 3? 7? 34 = 326, 592
states. A POMDP belief space is a probability
distribution over all these dialogue states, i.e. a
326, 592 dimensional real valued (R) space.
In order to render such large belief spaces
tractable, the current state of the art in POMDP
SSDS uses a variety of handcrafted compression
techniques, such as making several types of in-
dependence assumption. For example, by assum-
ing that users are only ever interested in one type
of food or one location, and that their interests
in food type, price range, quality, etc. are inde-
pendent, the 326, 592 real valued state space can
be reduced to a much smaller ?summary space?
(Williams and Young, 2005) consisting of, say,
4 ? R values2. See Figure 1 for a graphical de-
piction of such assumptions3.
As illustrated by Figure 1 the information lost
due to the independence assumptions mean that
these approaches are unable to support conversa-
tions such as that shown in Example 2 (Table 1).
4 Sets of User Goals
Getting rid of independence assumptions allows
the DM to reason and ask questions about the
user?s requirements in a more rational way. It can,
for example distinguish between the user want-
ing ?excellent Italian? or ?any Thai? versus only
?excellent? restaurants ? see Figure 1. However,
the resulting high dimensional real valued state
space can still only represent uncertainly over sin-
gular user goals (limited to single points in the
feature space, e.g. an excellent Italian restaurant).
1Whether each piece of information is obtained, con-
firmed or unknown.
2By considering only the maximum marginal likelihood
for each of the features.
3These apply after utterance U2/U?2 of Example 1.
210
ma
r
g
i
n
a
l
s
 
f
o
r
 
f
o
o
d
 
t
y
p
e
marginals for quality
 
 
 
 
 
 






 
 
 
 
 
 





italian
reasonable good excellent
Independence between
slots assumed
user?sgoal
thai
Figure 1: Assuming independence of features is
equivalent to marginalising across features. Here,
marginalisation incorrectly suppresses belief in
Italian. Thai retains a uniform belief (which ex-
ists across all restaurant types not yet mentioned).
To achieve a substantial gain in the flexibility of
SSDS we need to allow user?s goals that are sets
of points. Maintaining beliefs over ?sets of goals?
allows a POMDP DM to refine its belief in the
user?s requirements (managing speech recognition
errors) without forcing the user to specify a sin-
gular tightly constrained goal. The disadvantage
of this approach is a further expansion of the state
space.
5 Automatic Belief Compression
To allow for expansion of the state space, whilst
keeping its size tractable for policy learning, we
suggest replacing handcraft approaches with Au-
tomatic Belief Compression (ABC) techniques.
We propose to use proven, principled statisti-
cal learning methods for automatically reducing
the dimensionality of belief spaces, but which pre-
serve the useful distributions within the full space.
Two complementary methods that we are cur-
rently investigating are VDC (Poupart, 2005) and
E-PCA (Roy and Gordon, 2002; Roy et al, 2005).
These methods have been applied successfully in a
real-time daily living assistant with over 106 states
(St-Aubin et al, 2000; Hoey and Poupart, 2005;
Poupart et al, 2006) and to robotic navigation by
(Roy and Gordon, 2002; Roy et al, 2005). They:
? reduce the dimensionality of state spaces that
were previously intractable for POMDP solu-
tion methods, and
? automatically compress the representation of
belief space distributions to take advantage of
sparsity between likely distributions.
The tight coupling between some dia-
logue states and actions (e.g. a user?s goal
state travel-from-London and system act
confirm-from-London) has led some researchers
to conclude that compression techniques, such as
state aggregation, are not useful in the dialogue
domain (Williams and Young, 2007). However,
such tight coupling may not exist for all states,
indeed VDC has already been applied to a small
spoken dialogue system problem (Poupart, 2005)
where it was shown that compressions could be
found without losing any information4. Further,
for POMDP approaches the state is not the
dialogue state but the belief distribution over
dialogue states. Incompressibility at the dialogue
state level does not rule out compressibility of
belief distributions. Finally, our introduction
of sets for user goals should provide additional
possibilities for compression.
Our aim in applying ABC methods is to allow
POMDP SSDS to handle the much larger state
spaces that are required to achieve the expressive-
ness which we believe will be a real benefit to
users. We plan to do this for real world tasks, e.g. a
city search over 1000s of entities with an uncom-
pressed belief space of the order of 108 ? R.
6 Target Dialogues
In general, when a user starts a dialogue they
rarely have a singular goal in mind (Walker et al,
2004; Lemon et al, 2006). Their goal is not a fixed
point in the domain but instead can be thought
of as a (possibly disconnected) set of points, for
example either a nearby cheap restaurant or high-
quality one further away. The set represents trade
offs that the particular user is interested in. People
rarely communicate their goals in terms of such
distributions or trade offs, preferring to provide in-
formation in a piecemeal manner and thus incre-
mentally explore the domain.
In Examples 1?4 (Tables 1?3) we contrast the
operation of a current state-of-the-art POMDP
SSDS with our proposed ABC-SSDS system. The
user?s goal in Examples 3 and 4 (Tables 2 and 3)
is to explore what restaurants are nearby, with a
preference for French or Italian. Current POMDP
SSDS approaches assume that any spread of prob-
ability mass in the belief space represents uncer-
tainty which needs to be resolved. This gener-
ates problems for the POMDP SSDS in Example 3
since the user is forced into specifying one food
type at a time, resulting in an unwieldy confirma-
4Compressing a test problem of 433 states to 31 basis
functions, i.e. a summary space of 31 states.
211
User goal: good Italian or good French food
S?1: How can I help you?
U?1: What restaurants are nearby?
S?2: There are 6, what type of food do you
want?
U2?: Err... Italian or French
S?3: Ok, there are 2 good French restaurants
nearby, and one good Italian.
U?4: OK. Which is best quality?
S?3: Mamma Mia?s has the best rating.
U?5: Great. I?ll go there!
Table 3: Proposed ABC-SSDS: Example 4
tion step (S6 of Example 3) where the user is as-
sumed to have changed their mind. In contrast, the
proposed ABC-SSDS system can believe that the
user has requested information on the combined
set of French and Italian restaurants.
In Examples 1 and 2 (both shown in Table 1)
the user?s goal is to explore restaurants nearby, in-
cluding only well-rated Italians. Here the standard
POMDP SSDS is forced by its ?summary space?
(see marginals in Figure 1) to incorrectly represent
the user?s goal after U2 ?Not Italian, unless it?s
really good? by ruling out all Italian restaurants5.
The ABC-SSDS user is able to find the restaurant
of their choice, whereas the POMDP SSDS user?s
choice is artificially restricted, and they quit hav-
ing failed to find a suitable item.
The ABC-SSDS style of dialogue is clearly more
efficient than that of current POMDP SSDS. It
seems likely that users of such a system may also
find the style of the conversation more natural, and
may be more confident that their eventual choices
really meet their goals (Walker et al, 2004).
All of these hypotheses remain to be explored
in our future empirical work.
7 Conclusion
We present several problems for current POMDP
approaches to spoken dialogue systems, concern-
ing the representation of complex, but natural, user
goals. We propose the development of princi-
pled automatic methods for dimensionality reduc-
tion, in place of the ad-hoc assumptions and hand-
crafted compressions currently used.
In parallel we are also exploring: (i) what ap-
proaches are required for updating beliefs over
sets in real time ? in principle a method similar
5There are several ways to try to remedy this, but all have
problems.
to user goal state partitioning (Young et al, 2010)
would appear to be sufficient, (ii) what exploitable
bounds exist on the sets of goals that are commu-
nicable and (iii) to what extent the complexity of
user goal sets can be traded off against the overall
user experience.
Acknowledgments
Thanks to Dr. Jesse Hoey, the SIGdial reviewers
and the Engineering and Physical Sciences Re-
search Council (EPSRC) project EP/G069840/1.
References
J. Hoey and P. Poupart. 2005. Solving POMDPs with
Continuous or Large Discrete Observation Spaces.
In IJCAI.
O. Lemon, K. Georgila, and J. Henderson. 2006. Eval-
uating Effectiveness and Portability of Reinforce-
ment Learned Dialogue Strategies with real users:
the TALK TownInfo Evaluation. In IEEE/ACL Spo-
ken Language Technology.
P. Poupart, N. Vlassis, and J. Hoey. 2006. An An-
alytic Solution to Discrete Bayesian Reinforcement
Learning. In ICML.
P. Poupart. 2005. Exploiting Structure to Efficiently
Solve Large Scale Partially Observable Markov De-
cision Processes. Ph.D. thesis, Dept. Computer Sci-
ence, University of Toronto.
N. Roy and G. Gordon. 2002. Exponential Family
PCA for Belief Compression in POMDPs. In NIPS.
N. Roy, G. Gordon, and S. Thrun. 2005. Finding Ap-
proximate POMDP Solutions Through Belief Com-
pression. Artificial Intelligence Research, 22(1-40).
R. St-Aubin, J. Hoey, and C. Boutilier. 2000. Approx-
imate policy construction using decision diagrams.
In NIPS.
B. Thomson and S. Young. 2010. Bayesian update
of dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562?588.
M. Walker, S. Whittaker, A. Stent, P. Maloor, J. Moore,
M. Johnston, and G. Vasireddy. 2004. User tai-
lored generation in the match multimodal dialogue
system. Cognitive Science, 28:811?840.
J. Williams and S. Young. 2005. Scaling Up POMDPs
for Dialog Management: The ?Summary POMDP?
Method. In Proc. ASRU.
J. Williams and S. Young. 2007. Scaling POMDPs
for spoken dialog management. IEEE Transac-
tions on Audio, Speech, and Language Processing,
15(7):2116 ?2129, Sept.
S. Young, M. Gas?ic?, S. Keizer, F. Mairesse, B. Thom-
son, and K. Yu. 2010. The Hidden Information
State model: a practical framework for POMDP
based spoken dialogue management. Computer
Speech and Language, 24(2):150?174.
212
