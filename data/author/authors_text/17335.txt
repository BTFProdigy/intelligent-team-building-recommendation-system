Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 402?407, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
SINAI: Machine Learning and Emotion of the Crowd for Sentiment
Analysis in Microblogs
E. Mart??nez-Ca?mara
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
emcamara@ujaen.es
A. Montejo-Ra?ez
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
amontejo@ujaen.es
M. T. Mart??n-Valdivia
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
maite@ujaen.es
L. A. Uren?a-Lo?pez
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
laurena@ujaen.es
Abstract
This paper describes the participation of
the SINAI research group in the 2013 edi-
tion of the International Workshop Se-
mEval. The SINAI research group has
submitted two systems, which cover the
two main approaches in the field of sen-
timent analysis: supervised and unsuper-
vised.
1 Introduction
In the last years, the sentiment analysis (SA) re-
search community wants to go one step further,
which consists in studying different texts that
usually can be found in commerce websites or
opinions websites. Currently, the users publish
their opinions through other platforms, being one
of the most important the microblogging plat-
form Twitter1. Thus, the SA research commu-
nity is focused on the study of opinions that users
publish through Twitter. This interest is shown in
several workshops focused on the study of SA in
Twitter:
1. RepLab 2012 at CLEF2 (Amigo? et al,
2012): Competition carried out within the
CLEF conference, where the participants
had to develop a system for measuring the
reputation of commercial brands.
1http://twitter.com
2http://limosine-project.eu/events/
replab2012
2. TASS 2012 at SEPLN3(Villena-Roma?n et
al., 2013): Satellite event of the SEPLN
2012 Conference to foster the research in
the field of SA in social media, specifically
focused on the Spanish language.
In this paper is described the participation of
the SINAI4 research group in the second task of
the 2013 edition of the International Workshop
SemEval (Wilson et al, 2013). We have submit-
ted two systems (constrained and unconstrained).
The constrained system follows a supervised ap-
proach, while the unconstrained system is based
on an unsupervised approach which used two lin-
guistic resources: the Sentiment Analysis Lexi-
con5 (Hu and Liu, 2004) andWeFeelFine6 (Kam-
var and Harris, 2011).
The paper is organized as follows: first we
present a description of the preparing data pro-
cess. Then the constrained system is outlined.
The participation overview finishes with the de-
scription of the unconstrained system.
2 Preparing data
The organizers provided two sets of data, one for
training and another for the development. The
data was concerned by a set of identification
number of tweets with their corresponding po-
larity label. We used the script provided by the
organizers to download the two sets of tweets.
3http://www.daedalus.es/TASS/
4http://sinai.ujaen.es
5http://www.cs.uic.edu/?liub/FBS/
opinion-lexicon-English.rar
6http://wefeelfine.org
402
The python script was no able to download all the
tweets. The training set was composed by 8,633
tweets and the development set by 1,053 tweets.
The data preparation is a step in the workflow
of most data mining tasks. Also, in Natural Lan-
guage Processing is usual the preparation of the
documents or the texts for their further process-
ing. Internet is usually the source of texts for SA
tasks, so the application of a specific processing
to those texts with the aim of extracting their po-
larity is recommended. The texts published in
Twitter have several issues that must be resolved
before processing them:
1. The linguistic style of tweets is usually in-
formal, with a intensive usage of abbrevia-
tions, idioms, and jargon.
2. The users do not care about the correct use
of grammar, which increases the difficulty
of carrying out a linguistic analysis.
3. Because the maximum length of a tweet is
140 characters, the users normally refer to
the same concept with a large variety of
short and irregular forms. This problems is
known as data sparsity, and it is a challenge
for the sentiment-topic task.
4. The lack of context, which makes difficult
to extract the semantics of these sort pieces
of text.
Before applying a cleaning process to the cor-
pus with the aim of overcoming the issues de-
scribed above, we have studied the different
kinds of marks, like emoticons, question and ex-
clamation marks or hashtags in the tweets.
Regarding the issues listed above and the
marks in the tweets, we have carried out a clean-
ing and a normalization process which imply the
following operations:
1. The uppercase characters have been ex-
changed by lowercase characters.
2. Links have been replaced by the token
? ULR ?.
3. Question and exclamation marks have been
switched to the tokens ? QUESTION ? and
? EXCLAMATION ? respectively.
4. Mentions7 have been exchanged by the to-
ken ? MENTION ?.
5. All the HTML tags have been removed.
6. The hashtags8 have been normalized with
the token ? HASHTAG ?.
7. Tokens that express laughing (hahaha,
hehehe...) have been normalized with the
token ? LAUGH ?.
8. Users usually write expressions or abbrevi-
ations for surprise phrases like omg. All
these kind of expressions are replaced by the
token ? SURPRISE ?.
9. Positive emoticons like :), ;) or :, have been
normalized with the token ? HAPPY ?.
10. Negative emoticons like :(, :?( or :-( have
been normalized with the token ? SAD ?.
11. Twitter users usually repeat letters to em-
phasize the idea that they want to express.
Therefore, all the words with a letter re-
peated more than two times have been re-
duced to only two instances. For exam-
ple, the word ?aaaamaaaaaziiiing? in tweet
111733236627025920 is transformed into
?aamaaziing?.
After applying a normalization process to the
training and development sets, we have used for
the constrained system and the unsconstrained
system a dataset of 9,686 tweets.
3 Constrained System
The guidelines of the task define a constrained
system as a system that only can use the train
data provided by the organizers. Due to this re-
striction we decided to follow a supervised ap-
proach. It is required to define a set of parame-
ters when the supervised method is the elected.
The first step is to choose the minimum unit of
information, i.e. what segments of text are con-
sidered as features. Pang et al (2002) assert that
7A twitter mention is a reference to another user which
has the pattern ?@user name?
8A hashtag is the way to refer a topic in Twitter, which
has the pattern ?#topic name?
403
Class Precision Recall F1-score
Positive 0.6983 0.6295 0.6621
Neutral 0.6591 0.8155 0.7290
Negative 0.5592 0.2710 0.3651
Average 0.6652
Table 1: Assessment with TF-IDF weighting scheme
opinions or reviews should be represented with
unigrams, but other work shows bigrams and tri-
grams outperformed the unigrams features (Dave
et al, 2003). Therefore, there is not agreement
in the SA research community about what is the
best choice, unigrams or n-grams. Before several
validations on the training set of the task we de-
cided to use unigrams as feature for the polarity
classification process. Thus, for the supervised
algorithm, we have represented each tweet as a
vector of unigrams.
The next decision was about the application
of a stemmer process and getting rid off the En-
glish stop words. We only have applied stemmer
process to the data because in previous works
(Mart??nez-Ca?mara et al, 2013a) we did not reach
good results removing the stop words in texts
from Twitter. Another topic of discussion in the
SA research community is the weighting scheme.
Pang et al (2002) weighted each unigram fol-
lowing a binary scheme. Also, in the most cited
survey about SA (Pang and Lee, 2008) the au-
thors indicated that the overall sentiment may not
usually be highlighted through repeated use of
the same terms. On the other hand, Mart??nez-
Ca?mara et al (2011) achieved the best results
using TF-IDF as weighting scheme. Due to the
lack of agreement in the SA research community
about the use of a specific weight scheme, we
have carried out several assessments with aim of
deciding the most suitable one for the task. The
machine learning algorithm selected for the eval-
uation was SVM. The results are shown in Tables
1 and 2.
The results achieved with the two weighting
schemes are very similar. Regarding the posi-
tive class, the binary weighting scheme obtains
better results than the TF-IDF one, so the pres-
ence of positive keywords is more useful than
Class Precision Recall F1-score
positive 0.7037 0.6335 0.6668
neutral 0.6506 0.8313 0.7299
negative 0.5890 0.2105 0.3112
Average 0.6654
Table 2: Assessment with a binary weighting scheme
the frequent occurrence of those keywords. For
the neutral class, regarding precision and F1-
score, the TF-IDF scheme outperformed the bi-
nary scheme, but the recall had a higher value
when the terms are weighted binary. The pre-
cision of the classification for the neutral class
is only 1.2% better than the case where TF-IDF
is used, while recall and the F1-score is better
when the weighting of the features is binary. Al-
though the negative class has a similar perfor-
mance to that of the positive one with the two
weighting schemes, we highlighted the high dif-
ference between the other two classes and the
negative. The difference is more evident in the
recall value, while the neutral class has a value
of 0.8313 (binary), the negative one has a value
of 0.2105 (binary). Therefore, due to the fact that
the binary weighting scheme achieved better re-
sults in average, we decided to use it in the final
system.
The last step in the configuration of a su-
pervised approach based on machine learning is
the selection of the algorithm. The algorithm
selected was Support Vector Machine (SVM)
(Cortes and Vapnik, 1995). Our decision is based
on the widely used SVM by the research com-
munity of SA. The first application of SVM for
SA was in (Pang et al, 2002) with good re-
sults. Since the publication of the previous work,
other researchers have used SVM, and some of
them are: (Zhang et al, 2009), (Pang and Lee,
2004) and (Jindal and Liu, 2006). Also, the al-
gorithm SVM has been used to classify the po-
larity over tweets (Go et al, 2009) (Zhang et al,
2011) (Jiang et al, 2011). A broader review of
the research about SA in Twitter can be found in
(Mart??nez-Ca?mara et al, 2013b). Furthermore,
our decision is supported by previous in-house
experimentation.
404
For the experimentation we have used the
framework for data mining RapidMiner9. In
RapidMiner there are several implementations
of SVM, among which we have selected Lib-
SVM10(Chang and Lin, 2011) with built-in de-
fault parametrization.
To sum up, the configuration of the SINAI
constrained system is:
1. Machine learning approach: Supervised
2. Features: Unigrams.
3. Weighted scheme: Binary. If the term is
presence the value is 1, 0 in other case.
4. Stemmer: Yes
5. Stopper: No
6. Algorithm: SVM.
The results reached during the development
period are shown in Table 2
4 Unconstrained System
Our unconstrained system follows a two level
categorization approach, determining whether
the tweet is subjective or not at a first stage, and,
for the subjective classified ones, whether the
tweet is positive or negative. Both classification
phases are fully based on knowledge resources.
A predefined list of affective words is used for
subjectivity detection, and a search process over
the collection of emotions generated from a web
resource is applied for final polarity classifica-
tion. Figure 1 shows a general diagram of the
system.
4.1 Step 1: determining subjectivity
The system based in WeFeelFine only catego-
rizes between positive and negative texts, so a
preliminary classification into subjective and ob-
jective (i.e. neutral) must be performed. To this
end, a lexical approach is followed: those tweets
containing at least one affective term from a list
of predefined ones are considered subjective. If
9http://rapid-i.com/
10http://www.csie.ntu.edu.tw/?cjlin/
libsvm/
Figure 1: Unconstrained system general diagram
affective terms are not found, then the tweet is
directly labeled as neutral. This list is called Sen-
timent Analysis Lexicon (SAL), which is defined
in the work of Bing Liu (Hu and Liu, 2004). The
list has two differentiated groups: a list of posi-
tive terms (agile, enjoy, improving) and another
with negative ones (anger, refusing, unable...).
At this phase, the polarity is not considered, so
both lists are merged into a list of around 6,800
subjectivity terms.
4.2 Step 2: determining polarity
The WeFeelFine project (Kamvar and Harris,
2011) has been used as knowledge base for po-
larity classification following the approach pro-
posed by (Montejo-Ra?ez, 2013). WeFeelFine11
gathers affective texts from several blogs, cre-
ating a huge database of mood-related expres-
sions. Almost two millions ?feelings? are col-
lected and indexed by the system. It is possible
to retrieve related sentences and expressions by
using its API. In this way, we have obtained the
11http://wefeelfine.org
405
top 200 most frequent feelings. For each feeling,
about 1,500 sentences are include in a document
that represents such a feeling. Then, using the
Lucene12 search engine, these documents have
been indexed. In this way, we can use an incom-
ing tweet as query and retrieve a ranked list of
feelings, as shown in Figure 2.
Figure 2: Polarity classification
The ranked list with the top 100 feelings (i.e.
those feelings more related to the tweet) is taken
for computing the final polarity by a summation
of the manually assigned polarity of the feeling
weighted with the score value returned by the en-
gine, as shown in Equation 1.
p(t) = 1
|R|
?
r?R
RSVr ? lr (1)
where
p(t) is the polarity of tweet t
R is the list of retrieved feelings
lr is the polarity label of feeling r
RSVr is the Ranking Status Value of the feel-
ing determined by Lucene.
As we did with the constrained system, we
also assess the unconstrained system before ap-
plying the test data. The results reached during
the evaluation phase are shown in Table 3. It is
remarkable the fact that the precision value of the
unconstrained system is a bit higher than the one
12http://lucene.apache.org/
Class Precision Recall F1-score
positive 0.5004 0.6341 0.5593
neutral 0.6772 0.5416 0.6018
negative 0.3580 0.3456 0.3516
Average 0.5094
Table 3: Assessment of the unconstrained system
reached by the constrained configuration. Thus,
SAL is a good resource for subjective classifi-
cation tasks. The unconstrained system reached
worse results with positive and negative classes,
but it is an expected result because supervised
approaches usually obtain better results than the
unsupervised and knowledge based approaches.
However, the polarity classification has reached
acceptable results, so it encourage us to follow
improving the method based of the use of We-
FeelFine.
Acknowledgments
This work has been partially supported by a grant
from the Fondo Europeo de Desarrollo Regional
(FEDER), TEXT-COOL 2.0 project (TIN2009-
13391-C04-02) and ATTOS project (TIN2012-
38536-C03-0) from the Spanish Government.
Also, this paper is partially funded by the Eu-
ropean Commission under the Seventh (FP7
- 2007-2013) Framework Programme for Re-
search and Technological Development through
the FIRST project (FP7-287607). This publica-
tion reflects the views only of the authors, and
the Commission cannot be held responsible for
any use which may be made of the information
contained therein.
References
Enrique Amigo?, Adolfo Corujo, Julio Gonzalo, Edgar
Meij, and Md Rijke. 2012. Overview of replab
2012: Evaluating online reputation management
systems. In CLEF 2012 Labs and Workshop Note-
book Papers.
Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm:
A library for support vector machines. ACM Trans.
Intell. Syst. Technol., 2(3):27:1?27:27, May.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine Learning, 20:273?297.
406
Kushal Dave, Steve Lawrence, and David M. Pen-
nock. 2003. Mining the peanut gallery: opinion
extraction and semantic classification of product
reviews. In Proceedings of the 12th international
conference on World Wide Web, WWW ?03, pages
519?528, New York, NY, USA. ACM.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervi-
sion. CS224N Project Report, Stanford, pages 1?
12.
Minqing Hu and Bing Liu. 2004. Mining and sum-
marizing customer reviews. In Proceedings of the
tenth ACM SIGKDD international conference on
Knowledge discovery and data mining, KDD ?04,
pages 168?177, New York, NY, USA. ACM.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies
- Volume 1, HLT ?11, pages 151?160, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Nitin Jindal and Bing Liu. 2006. Identifying com-
parative sentences in text documents. In Proceed-
ings of the 29th annual international ACM SIGIR
conference on Research and development in infor-
mation retrieval, SIGIR ?06, pages 244?251, New
York, NY, USA. ACM.
Sepandar D. Kamvar and Jonathan Harris. 2011. We
feel fine and searching the emotional web. In Pro-
ceedings of the fourth ACM international confer-
ence on Web search and data mining, WSDM ?11,
pages 117?126, New York, NY, USA. ACM.
Eugenio Mart??nez-Ca?mara, M. Teresa Mart??n-
Valdivia, Jose? M. Perea-Ortega, and L. Al-
fonso Ure na Lo?pez. 2011. Opinion classification
techniques applied to a spanish corpus. Proce-
samiento de Lenguaje Natural, 47.
Eugenio Mart??nez-Ca?mara, M. Teresa Mart??n-
Valdivia, L. Alfonso Ure na Lo?pez, and Ruslan
Mitkov. 2013a. Detecting sentiment polarity in
spanish tweets. Information Systems Management,
In Press.
Eugenio Mart??nez-Ca?mara, M. Teresa Mart??n-
Valdivia, L. Alfonso Ure na Lo?pez, and Arturo
Montejo-Ra?ez. 2013b. Sentiment analysis
in twitter. Natural Language Engineering,
FirstView:1?28, 2.
Arturo Montejo-Ra?ez. 2013. Wefeelfine as resource
for unsupervised polarity classification. Proce-
samiento del Lenguaje Natural, 50:29?35.
Bo Pang and Lillian Lee. 2004. A sentimental educa-
tion: sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42nd Annual Meeting on Association for Com-
putational Linguistics, ACL ?04, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2):1?135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification us-
ing machine learning techniques. In Proceedings
of the ACL-02 conference on Empirical methods in
natural language processing - Volume 10, EMNLP
?02, pages 79?86, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Julio Villena-Roma?n, Sara Lana-Serrano, Euge-
nio Mart??nez-Ca?mara, and Jose? Carlos Gonza?lez-
Cristo?bal. 2013. Tass - workshop on sentiment
analysis at sepln. Procesamiento del Lenguaje
Natural, 50(0).
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,
Sara Rosenthal, Veselin Stoyanov, and Alan Ritter.
2013. SemEval-2013 task 2: Sentiment analysis in
twitter. In Proceedings of the International Work-
shop on Semantic Evaluation, SemEval ?13, June.
Changli Zhang, Daniel Zeng, Jiexun Li, Fei-Yue
Wang, and Wanli Zuo. 2009. Sentiment analy-
sis of chinese documents: From sentence to docu-
ment level. Journal of the American Society for In-
formation Science and Technology, 60(12):2474?
2487.
Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil,
Meichun Hsu, and Bing Liu. 2011. Combining
lexiconbased and learning-based methods for twit-
ter sentiment analysis. HP Laboratories, Technical
Report HPL-2011-89.
407
Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 87?93,
Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational Linguistics
Bilingual Experiments on an Opinion Comparable Corpus
E. Mart??nez-Ca?mara
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
emcamara@ujaen.es
M. T. Mart??n-Valdivia
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
maite@ujaen.es
M. D. Molina-Gonza?lez
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
mdmolina@ujaen.es
L. A. Uren?a-Lo?pez
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
laurena@ujaen.es
Abstract
Up until now most of the methods published
for polarity classification are applied to En-
glish texts. However, other languages on the
Internet are becoming increasingly important.
This paper presents a set of experiments on
English and Spanish product reviews. Us-
ing a comparable corpus, a supervised method
and two unsupervised methods have been as-
sessed. Furthermore, a list of Spanish opinion
words is presented as a valuable resource.
1 Introduction
Opinion Mining (OM) is defined as the computa-
tional treatment of opinion, sentiment, and subjec-
tivity in text. The OM discipline combines Natural
Language Processing (NLP) with data mining tech-
niques and includes a large number of tasks (Pang
and Lee, 2008). One of the most studied tasks
is polarity classification of reviews. This task fo-
cuses on determining which is the overall sentiment-
orientation (positive or negative) of the opinions
contained within a given document.
Two main appraoches are followed by researches
to tackle the OM task. On the one hand, the Ma-
chine Learning (ML) approach (also known as the
supervised approach) is based on using a collection
of data to train the classifiers (Pang et al, 2002). On
the other hand, (Turney, 2002) proposed an unsuper-
vised method based on the semantic orientation of
the words and phrases in the reviews. Both method-
ologies have their advantages and drawbacks. For
example, the ML approach depends on the avail-
ability of labelled data sets (training data), which
in many cases are impossible or difficult to achieve,
partially due to the novelty of the task. On the
contrary, the unsupervised method requires a large
amount of linguistic resources which generally de-
pend on the language, and often this approach ob-
tains lower recall because it depends on the presence
of the words comprising the lexicon in the document
in order to determine the polarity of opinion.
Although opinions and comments on the Inter-
net are expressed in any language, most of research
in OM is focused on English texts. However, lan-
guages such as Chinese, Spanish or Arabic, are ever
more present on the web. Thus, it is important to
develop resources for these languages. The work
presented herein is mainly motivated by the need
to develop polarity classification systems and re-
sources in languages other than English. We present
an experimental study over the SFU Review Corpus
(Taboada, 2008), a comparable corpus that includes
opinions of several topics in English and in Span-
ish. We have followed this line of work: Firstly,
we have taken as baseline a supervised experiment
using Support Vector Machine (SVM). Then we
have tried different unsupervised strategies. The first
one uses the method presented in (Montejo-Ra?ez et
al., 2012). This approach combines SentiWordNet
scores with a random walk analysis of the concepts
found in the text over the WordNet graph in order to
determine the polarity of a tweet. This method ob-
tained very good results in short texts (tweets) and
so, we want to try it using larger document. Al-
though we have carried out several experiments us-
ing different parameters and modifications, the re-
sults are not as good as we hoped. For this, we have
87
tried a very simple experiment using a list of opin-
ionated words in order to classify the polarity of the
reviews. For English we have used the Bin Liu En-
glish lexicon (BLEL) (Hu and Liu, 2004) and for
Spanish we have automatically translated the BLEL
lexicon into Spanish. In addition, we have also
checked manually and improved the Spanish list.
The paper is organized as follows: Section 2
briefly describes papers that study non-English sen-
timent polarity classification and, specifically work
related to Spanish OM. In Section 3 we explain
the resources used in the unsupervised methods as-
sessed. Section 4 presents the experiments carried
out and discusses the main results obtained. Finally,
we outline conclusions and further work.
2 Related Work
There are some interesting papers that have stud-
ied the problem using non-English collections. De-
necke (2008) worked on German comments col-
lected from Amazon. These reviews were translated
into English using standard machine translation soft-
ware. Then the translated reviews were classified as
positive or negative, using three different classifiers:
LingPipe7, SentiWordNet (Baccianella et al, 2010)
with classification rule, and SentiWordNet with ma-
chine learning. Ghorbel and Jacot (2011) used a cor-
pus with movie reviews in French. They applied a
supervised classification combined with SentiWord-
Net in order to determine the polarity of the reviews.
In (Rushdi-Saleh et al, 2011a) a corpus of movies
reviews in Arabic annotated with polarity was pre-
sented and several supervised experiments were per-
formed. Subsequently, they generated the parallel
EVOCA corpus (English version of OCA) by trans-
lating the OCA corpus automatically into English.
The results showed that they are comparable to other
English experiments, since the loss of precision due
to the translation process is very slight, as can be
seen in (Rushdi-Saleh et al, 2011b).
Regarding Spanish, there are also some interest-
ing studies. Banea et al (2008) showed that au-
tomatic translation is a viable alternative for the
construction of resources and tools for subjectivity
analysis in a new target language. In (Brooke et
al., 2009) several experiments are presented deal-
ing with Spanish and English resources. They con-
clude that although the ML techniques can provide
a good baseline performance, it is necessary to inte-
grate language-specific knowledge and resources in
order to achieve an improvement. Cruz et al (2008)
manually recollected the MuchoCine (MC) corpus
to develop a sentiment polarity classifier based on
the semantic orientation of the phrases and words.
The corpus contains annotated Spanish movie re-
views from the MuchoCine website. The MC cor-
pus was also used in (Mart??nez-Ca?mara et al, 2011)
to carry out several experiments with a supervised
approach applying different ML algorithms. Finally,
(Mart??n-Valdivia et al, 2012) also dealt with the MC
corpus to present an experimental study of super-
vised and unsupervised approaches over a Spanish-
English parallel corpus.
3 Resources for the unsupervised methods
In order to tackle the unsupervised experiments we
have chosen several well-known resources in the
OM research community. In addition, we have also
generated a new Spanish linguistic resource.
Comparable corpora are those consisted of texts
in two or more languages about the same topic, but
they are not the translated version of the texts in the
source language. For the experiments, we chose the
comparable corpus SFU Review Corpus. The SFU
Review Corpus is composed of reviews of prod-
ucts in English and Spanish. The English version
(Taboada and Grieve, 2004) has 400 reviews (200
positive and 200 negative) of commercial products
downloaded in 2004 from the Epinions web which
are divided into eight categories: books, cars, com-
puters, cookware, hotels, movies, music and phones.
Each category includes 25 positive reviews and 25
negative reviews. Recently, the authors of SFU Re-
view Corpus have made available the Spanish ver-
sion of the corpus1. The Spanish reviews are divided
into the same eight categories, and also each cate-
gory has 25 positive and 25 negative reviews.
In the unsupervised experiments we have anal-
ysed the performance of two approaches, the first
one is based on lexicon and the other one in a graph-
based method. We have selected the BLEL lexicon
(Hu and Liu, 2004) to carry out the experiment based
1http://www.sfu.ca/?mtaboada/download/
downloadCorpusSpa.html
88
on lexicon on the English version of the corpus. The
lexicon is composed by 6,787 opinion words that
indicate positive or negative opinions, which 2,005
are positive and 4,782 are negative. With the aim of
following the same approach over the Spanish ver-
sion, firstly we have translated the BLEL lexicon
with the Reverso machine translator, and them we
have checked manually the resultant list. The Span-
ish Opinion Lexicon2 (SOL) is composed by 2,509
positive and 5,627 negative words, thus in total SOL
has 8,136 opinion words. If a review has more or
the same positive words than negative the polarity is
positive, otherwise negative.
The graph-based method is a modular system
which is made up of different components and
technologies. The method was first presented in
(Montejo-Ra?ez et al, 2012) with a good perfor-
mance over a corpus of English tweets. The main
idea of the algorithm is to represent each review as a
vector of polarity scores of the senses in the text and
senses related to the context of the first ones. Be-
sides, the polarity score is weighted with a measure
of importance. Taking a review as input, the work-
flow of the algorithm is the following:
1. Disambiguation: To get the corresponding
sense of the words that are in the text is required
to disambiguate them. Thus, the output of this
first step is one unique synset from WordNet3
(Miller, 1995) for each term. The input of the
algorithm is the set of words with a POS-Tag
allowed in WordNet. The graph nature of the
WordNet structure is the basis for the UKB dis-
ambiguation method proposed by (Agirre and
Soroa, 2009). The UKB disambiguation algo-
rithm apply PageRank (Page et al, 1999) on
the WordNet graph starting from term nodes,
where each term node points to all its possible
senses or synsets. The output of the process is a
ranked list of synsets for each input word, and
the highest rank synset is chosen as candidate
sense.
For the Spanish disambiguation process we
have chosen the Spanish WordNet version
offered by the project Multilingual Central
2http://sinai.ujaen.es/wiki/index.php/
SOL
3We have used the 3.0 release of WordNet.
Repository (MCR) (Gonzalez-Agirre et al,
2012). The Spanish WordNet of MCR has
38,702 synsets while WordNet has 117,659, i.e.
the MCR covers the 32.89% of WordNet.
2. PPV: Once the synsets for the reviews are com-
puted, the following step performs a second run
of PageRank described in (Agirre and Soroa,
2009). Using the Personalized PageRank, a
set of Personalized PageRank Vectors (PPVs)
is obtained. This vector is a list of synsets with
their ranked values. The key of this approach
is to take from this vector additional synsets
not related directly to the set of synsets disam-
biguated in the first step. The result is a longer
list of pair <synset, weight> where the weight
is the rank value obtained by the propagation of
the weights of original synsets across theWord-
Net graph.
3. Polarity: The following step is to calculate the
polarity score. For this purpose it is necessary a
semantic resource to take the polarity score for
each retrieved synset in the two previous steps.
The semantic resource selected is SentiWord-
Net (Baccianella et al, 2010). According to
these values, the three following equations have
been applied to obtain the final polarity value:
p(r) = 1
|r|
?
s?r
1
|s|
?
i?s
(p+i ? p
?
i )wi (1)
p(r) = 1
|r|
?
s?r
1
|s|
?
i?s
f(pi)
f(pi) =
{
p+i if p
+
i > p
?
i
p?i if p
+
i <= p
?
i
(2)
p(r) = 1
|r|
?
s?r
1
|s|
?
i?s
f(pi)
f(pi) =
?
?
?
?
?
?
?
1 if i ? [positive words]
?1 if i ? [negative words]
p+i if p
+
i > p
?
i
p?i if p
+
i <= p
?
i
(3)
where p(r) is the polarity of the review; |r| is
the number of sentences in the review r; s is a
sentence in r, being itself a set of synsets; i is a
synset in s; p+i is the positive polarity of synset
i; p?i is the negative polarity of synset i and wi
is the weight of synset i.
89
4 Experiments and Results
Systems based on supervised approach are the most
successfully in the OM literature. Therefore, we be-
gan the set of experiments applying a machine learn-
ing algorithm to the SFU corpus. Also, we have car-
ried out a set of unsupervised experiments following
a lexicon-based approach and a graph-based algo-
rithm. For all the experiments the evaluation mea-
sures have been: precision, recall, F1 and Accuracy
(Acc.). The validation approach followed for the
supervised approach has been the well-known 10-
cross-validation.
The algorithm chose for the supervised experi-
ments is SVM (Cortes and Vapnik, 1995) because
is one of the most successfully used in OM. Lib-
SVM4 (Chang and Lin, 2011) was the implementa-
tion selected to carry out several experiments using
SVM. We have evaluated unigrams and bigrams as
minimum unit of information. Also, the influence of
stemmer have been assessed. The weight scheme for
representing each unit of information is TF-IDF. The
same configuration has been applied to English and
Spanish version of SFU corpus. Table 1 and Table
2 show the results for English version and Spanish
version respectively.
Precision Recall F1 Acc.
Unigrams 79.07% 78.50% 78.78% 78.50%
Unigrams
& stemmer 79.82% 79.50% 79.66% 79.50%
Bigrams 78.77% 78.25% 78.51% 78.25%
Bigrams
& stemmer 80.64% 80.25% 80.44% 80.25%
Table 1: SVM results for English SFU corpus
Precision Recall F1 Acc.
Unigrams 73.65% 73.25% 73.45% 73.25%
Unigrams
& stemmer 74.10% 73.75% 73.92% 73.75%
Bigrams 74.02% 73.50% 73.76% 73.50%
Bigrams
& stemmer 73.90% 73.50% 73.70% 73.50%
Table 2: SVM results for Spanish SFU corpus
The results show one of the differences between
the works published in SA, the use of unigrams or
4http://www.csie.ntu.edu.tw/?cjlin/
libsvm/
bigrams. In (Pang et al, 2002) is asserted that the
reviews should be represented with unigrams, but
in (Dave et al, 2003) bigrams and trigrams outper-
formed the unigrams features. In our case, regarding
the results reached without using a stemmer, the use
of unigrams as minium unit of information achieves
better result than the use of bigrams when the lan-
guage is English, but bigrams outperform unigrams
when the texts are in Spanish. On the other hand, the
best result both in English and Spanish is reached
when a stemmer algorithm is applied. So, one con-
clusion of the supervised experiments is that the use
of stemmer enhances the polarity classification in re-
views. The following conclusion is that in English
the presence of pair of words separate better the pos-
itive and negative classes, while in Spanish the use
of unigrams is enough to classify the polarity when
a stemmer algorithm is used.
The set of unsupervised experiments begins with
a lexicon-based method. The method consists of find
the presence in the reviews of opinion words which
are included in a lexicon of opinion words. BLEL
has been used for the English reviews, and SOL for
the Spanish reviews. The results are presented in
Table 3.
Precision Recall F1 Acc.
BLEL lexicon 69.56% 64.42% 66.89% 64.75%
SOL 66.91% 61.94% 64.33% 62.25%
Table 3: Lexicon-based approch results
The differences in the results between the En-
glish and Spanish version of SFU Review Corpus
are lower when a lexicon is used instead of a ma-
chine learning algorithm is applied. In a lexicon-
based method is very important the recall value, be-
cause it indicates whether the set of words covers
the vocabulary of the corpus. The recall value is
upper 60% regarding English and Spanish, although
is not an excellent value, is good for the two small
and independent-domain lexicons. In the case of
Spanish the supervised method is only 15.59% bet-
ter regarding Accuracy. The results show that may
be considered the use of a lexicon-based method for
Spanish due to the few computer resources needed.
Moreover, it must be highlighted the performance of
SOL, so it is the first time that this resource is used
to resolve a polarity classification problem.
90
The graph-based method has been described as a
modular and flexible algorithm. Due to its modular
nature we have carried out several experiments:
1. wnet ant+ eq1 [en|es]: As baseline, we have
run the algorithm with the same configuration
as is described in (Montejo-Ra?ez et al, 2012),
i.e. using the equation 1.
2. wnet ant- eq1 [en|es]: We have assessed the
algorithm with a version of WordNet without
the antonym relation.
3. wnet ant+ eq2 [en|es]: The equation to calcu-
late the polarity is 2
4. wnet ant- eq2 [en|es]: The same as
wnet ant+ eq2 [en|es] but the antonym
relation is not considered.
5. wnet ant+ eq3 [en|es]: The same as
wnet ant+ eq2 [en|es] but the equation 3
is used to calculate the polarity.
6. wnet ant- eq3 [en|es]: The same as
wnet ant+ eq3 [en|es] but the antonym
relation is not considered.
Furthermore, one of the key elements of the al-
gorithm is the possibility of setting the number of
related synsets to get from WordNet. In all of the ex-
periments we have evaluated from an expansion of 0
sysnsets to 100 synsets. In Table 4 are the best re-
sults obtained with the English and the Spanish ver-
sion of SFU corpus.
Regarding the results, only for English is evident
that the selection of the right equation to calculate
the polarity score is important. On the other hand,
the initial assumption that the relation of antonym
could complicate the calculation of the final polarity,
and the use of a graph of WordNet without antonym
could enhance the results cannot be demonstrated
because these experiments have reached the same
results as the obtained ones using the graph with
the relation of antonym. The equation 3, which in-
cludes additional information (in this case the BLEL
lexicon) to calculate the final polarity score, out-
performs the original way to get the polarity score
(equation 1). The equation 3 for the English version
of the corpus reaches 5.84% and 8.4% better results
than equation 1 regarding F1 and Accuracy respec-
tively.
The results obtained with the Spanish reviews are
a bit different. In this case, the results are always
improved when the antonym relation is not taking
into account. So the first conclusion is the relation
of antonym is not convenient for the calculation of
the polarity value on Spanish texts. The process of
expansion with related senses has not been relevant
for the final results on the English reviews, but when
the language of the reviews is Spanish the expan-
sion is more decisive. For the wnet ant- eq3 es ex-
periment the best result has been reached consider-
ing 71 related senses, so we can conclude that for
Spanish the context should be considered. Although
the best results is obtained with the configuration
wnet ant+ eq3 es, it must be highlighted the pre-
cision value of 68.03% reached by the configura-
tion wnet ant+ eq2 es. In some OM experiments is
more important the precision of the system than the
recall or other evaluation measures, so for Spanish
reviews should be taken account this configuration
too.
Regarding English and Spanish results, Table 4
shows similar performance, i.e. the graph-based al-
gorithm obtained better results when the antonym is
not considered and the use of a lexicon of opinion
words enhances considerably the results.
The supervised approach clearly outperforms the
two unsupervised approaches. The results obtained
by the two unsupervised approaches are closer. The
lexicon based method has a better performance on
English reviews regarding the four different eval-
uation measures considered. Thus, the lexicon
method not only has better results but also it is sim-
pler, faster and more efficient than the graph-based
method. Nevertheless, the graph-based method on
Spanish reviews outperforms in precision regard-
ing the configuration wnet ant+ eq2 es and in the
other three measures take into account the configu-
ration wnet ant+ eq3 es. However, the graph-based
method is only 1.64% better regarding the precision
value, and 0.54% better regarding F1. Therefore, we
also considered the lexicon-based approach as the
more suitable approach than the graph-based one.
91
Expansion Precision Recall F1 Accuracy
wnet ant+ eq1 en 2 66.86% 57.25% 61.68% 57.25%
wnet ant- eq1 en 2 66.86% 57.25% 61.68% 57.25%
wnet ant+ eq2 en 0 65.27% 55.5% 59.99% 55.50%
wnet ant- eq2 en 0 65.27% 55.5% 59.99% 55.50%
wnet ant+ eq3 en 3 68.83% 62.50% 65.51% 62.50%
wnet ant- eq3 en 3 68.83% 62.50% 65.51% 62.50%
wnet ant+ eq1 es 0 65.42% 54.5% 59.46% 54.5%
wnet ant- eq1 es 19 64.39% 57.75% 60.89% 57.75%
wnet ant+ eq2 es 0 68.03% 52.75% 59.42% 52.75%
wnet ant- eq2 es 70 64.62% 58.00% 61.13% 58.00%
wnet ant+ eq3 es 71 65.91% 63.50% 64.68% 63.05%
wnet ant- eq3 es 71 65.91% 63.50% 64.68% 63.05%
Table 4: Results of the graph-based algorithm
5 Conclusion and future work
In this work, we have presented a set of experiments
with a comparable corpora in English and Spanish.
As it is usual, the supervised experiment has outper-
forms the unsupervised ones. The unsupervised ex-
periments have included the evaluation of two differ-
ent approaches: lexicon-based and graph-based. In
the lexicon-based approach we have presented a new
resource for the Spanish OM research community,
being an important contribution of this paper. The
results reached with SOL are very closed to the ones
obtained with graph-based methods. Although, for
short texts the graph-based method performed well,
for the kind of reviews used in these experiments is
not as good. Due to the fact that for English the
BLEL lexicon has reached better results, for Span-
ish the results of SOL are nearly the same ones ob-
tained by the graph method, and the use of a lexicon
is more efficient, we conclude that the lexicon-based
method is most suitable.
Currently we are improving the SOL lexicon, and
also we are adding domain information to the words
in SOL. Furthermore, one of our main objectives is
the treatment of the negation because we considered
that is essential for OM.
Acknowledgments
This work has been partially supported by a grant
from the Fondo Europeo de Desarrollo Regional
(FEDER), TEXT-COOL 2.0 project (TIN2009-
13391-C04-02) and ATTOS project (TIN2012-
38536-C03-0) from the Spanish Government. Also,
this paper is partially funded by the European
Commission under the Seventh (FP7 - 2007-2013)
Framework Programme for Research and Techno-
logical Development through the FIRST project
(FP7-287607). This publication reflects the views
only of the authors, and the Commission cannot be
held responsible for any use which may be made of
the information contained therein.
References
Eneko Agirre and Aitor Soroa. 2009. Personalizing
pagerank for word sense disambiguation. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics,
EACL ?09, pages 33?41, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Stefano Baccianella, Andrea Esuli, and Fabrizio Se-
bastiani. 2010. Sentiwordnet 3.0: An enhanced
lexical resource for sentiment analysis and opinion
mining. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Bente Maegaard, Joseph Mariani,
Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh Interna-
tional Conference on Language Resources and Evalu-
ation (LREC?10), Valletta, Malta, may. European Lan-
guage Resources Association (ELRA).
Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
Samer Hassan. 2008. Multilingual subjectivity
analysis using machine translation. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, EMNLP ?08, pages 127?135,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Julian Brooke, Milan Tofiloski, and Maite Taboada.
2009. Cross-linguistic sentiment analysis: From en-
glish to spanish. In Proceedings of the International
Conference RANLP-2009, pages 50?54, Borovets,
92
Bulgaria, September. Association for Computational
Linguistics.
Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm:
A library for support vector machines. ACM Trans.
Intell. Syst. Technol., 2(3):27:1?27:27, May.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine Learning, 20:273?297.
Ferm??n L. Cruz, Jose A. Troyano, Fernando Enriquez,
and Javier Ortega. 2008. Clasificacio?n de documen-
tos basada en la opinio?n: experimentos con un cor-
pus de cr??ticas de cine en espan?ol. Procesamiento del
Lenguaje Natural, 41:73?80.
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: opinion extraction
and semantic classification of product reviews. In Pro-
ceedings of the 12th international conference on World
Wide Web, WWW ?03, pages 519?528, New York, NY,
USA. ACM.
Kerstin Denecke. 2008. Using sentiwordnet for multilin-
gual sentiment analysis. In Data Engineering Work-
shop, 2008. ICDEW 2008. IEEE 24th International
Conference on, pages 507?512. IEEE.
Hatem Ghorbel and David Jacot. 2011. Sentiment anal-
ysis of french movie reviews. Advances in Distributed
Agent-Based Retrieval Tools, pages 97?108.
Aitor Gonzalez-Agirre, Egoitz Laparra, and German
Rigau. 2012. Multilingual central repository version
3.0. In Nicoletta Calzolari (Conference Chair), Khalid
Choukri, Thierry Declerck, Mehmet Ug?ur Dog?an,
Bente Maegaard, Joseph Mariani, Jan Odijk, and Ste-
lios Piperidis, editors, Proceedings of the Eight In-
ternational Conference on Language Resources and
Evaluation (LREC?12), Istanbul, Turkey, may. Euro-
pean Language Resources Association (ELRA).
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ?04, pages 168?
177, New York, NY, USA. ACM.
Eugenio Mart??nez-Ca?mara, M. Teresa Mart??n-Valdivia,
and L. Alfonso Uren?a Lo?pez. 2011. Opinion clas-
sification techniques applied to a spanish corpus. In
Proceedings of the 16th international conference on
Natural language processing and information sys-
tems, NLDB?11, pages 169?176, Berlin, Heidelberg.
Springer-Verlag.
M. Teresa Mart??n-Valdivia, Eugenio Mart??nez-Ca?mara,
Jose M. Perea-Ortega, and L. Alfonso Uren?a Lo?pez.
2012. Sentiment polarity detection in spanish reviews
combining supervised and unsupervised approaches.
Expert Systems with Applications. In press.
George A. Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39?41.
Arturo Montejo-Ra?ez, Eugenio Mart??nez-Ca?mara,
M. Teresa Mart??n-Valdivia, and L. Alfonso Uren?a
Lo?pez. 2012. Random walk weighting over senti-
wordnet for sentiment polarity detection on twitter. In
Proceedings of the 3rd Workshop in Computational
Approaches to Subjectivity and Sentiment Analy-
sis, pages 3?10, Jeju, Korea, July. Association for
Computational Linguistics.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The pagerank citation ranking:
Bringing order to the web. Technical Report 1999-
66, Stanford InfoLab, November. Previous number =
SIDL-WP-1999-0120.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1?
135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing - Volume 10, EMNLP ?02, pages
79?86, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Mohammed Rushdi-Saleh, M. Teresa Mart??n-Valdivia,
L. Alfonso Uren?a Lo?pez, and Jose? M. Perea-Ortega.
2011a. OCA: Opinion corpus for Arabic. Journal
of the American Society for Information Science and
Technology, 62(10):2045?2054, October.
Mohammed Rushdi-Saleh, Maria Teresa Martn-Valdivia,
Luis Alfonso Urea-Lpez, and Jos M. Perea-Ortega.
2011b. Bilingual Experiments with an Arabic-English
Corpus for Opinion Mining. In Galia Angelova,
Kalina Bontcheva, Ruslan Mitkov, and Nicolas Ni-
colov, editors, RANLP, pages 740?745. RANLP 2011
Organising Committee.
Maite Taboada and Jack Grieve. 2004. Analyzing ap-
praisal automatically. In Proceedings of AAAI Spring
Symposium on Exploring Attitude and Affect in Text
(AAAI Technical Re# port SS# 04# 07), Stanford Uni-
versity, CA, pp. 158q161. AAAI Press.
Maite Taboada. 2008. Sfu review corpus. http:
//www.sfu.ca/?mtaboada/research/SFU_
Review_Corpus.html.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classifi-
cation of reviews. In Proceedings of the 40th Annual
Meeting on Association for Computational Linguis-
tics, ACL ?02, pages 417?424, Stroudsburg, PA, USA.
Association for Computational Linguistics.
93
