Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 24?25,
Vancouver, October 2005.
A Flexible Conversational Dialog System for MP3 Player
Fuliang Weng
1
 Lawrence Cavedon
2
 Badri Raghunathan
1
 Danilo Mirkovic
2 
Ben Bei
1
Heather Pon-Barry
1
 Harry Bratt
3
 Hua Cheng
2
 Hauke Schmidt
1
 Rohit Mishra
4
 Brian Lathrop
4
Qi Zhang
1
   Tobias Scheideck
1
   Kui Xu
1
    Tess Hand-Bender
1
   Sandra Upson
1
     Stanley Peters
2
Liz Shriberg
3
 Carsten Bergmann
4
Research and Technology Center, Robert Bosch Corp., Palo Alto, California
1
Center for Study of Language and Information, Stanford University, Stanford, California
2
Speech Technology and Research Lab, SRI International, Menlo Park, California
3
Electronics Research Lab, Volkswagen of America, Palo Alto, California
4
{Fuliang.weng,badri.raghunathan,hauke.Schmidt}@rtc.bosch.com
{lcavedon,huac,peters}@csli.Stanford.edu
{harry,ees}@speech.sri.com
{rohit.mishra,carsten.bergmann}@vw.com
1 Abstract
In recent years, an increasing number of new de-
vices have found their way into the cars we drive.
Speech-operated devices in particular provide a
great service to drivers by minimizing distraction,
so that they can keep their hands on the wheel and
their eyes on the road. This presentation will dem-
onstrate our latest development of an in-car dialog
system for an MP3 player designed under a joint
research effort from Bosch RTC, VW ERL, Stan-
ford CSLI, and SRI STAR Lab funded by NIST
ATP [Weng et al2004] with this goal in mind.
This project has developed a number of new tech-
nologies, some of which are already incorporated
in the system.  These include: end-pointing with
prosodic cues, error identification and recovering
strategies, flexible multi-threaded, multi-device
dialog management, and content optimization and
organization strategies. A number of important
language phenomena are also covered in the sys-
tem?s functionality. For instance, one may use
words relying on context, such as ?this,? ?that,? ?it,?
and ?them,? to reference items mentioned in par-
ticular use contexts. Different types of verbal revi-
sion are also permitted by the system, providing a
great convenience to its users. The system supports
multi-threaded dialogs so that users can diverge to
a different topic before the current one is finished
and still come back to the first after the second
topic is done. To lower the cognitive load on the
drivers, the content optimization component orga-
nizes any information given to users based on on-
tological structures, and may also refine users?
queries via various strategies. Domain knowledge
is represented using OWL, a web ontology lan-
guage recommended by W3C, which should
greatly facilitate its portability to new domains.
The spoken dialog system consists of a number of
components (see Fig. 1 for details). Instead of the
hub architecture employed by Communicator pro-
jects [Senef et al 1998], it is developed in Java and
uses a flexible event-based, message-oriented mid-
dleware. This allows for dynamic registration of
new components. Among the component modules
in Figure 1, we use the Nuance speech recognition
engine with class-based ngrams and dynamic
grammars, and the Nuance Vocalizer as the TTS
engine. The Speech Enhancer removes noises and
echo. The Prosody module will provide additional
features to the Natural Language Understanding
(NLU) and Dialogue Manager (DM) modules to
improve their performance.
The NLU module takes a sequence of recognized
words and tags, performs a deep linguistic analysis
with probabilistic models, and produces an XML-
based semantic feature structure representation.
Parallel to the deep analysis, a topic classifier as-
signs top n topics to the utterance, which are used
in the cases where the dialog manager cannot make
24
any sense of the parsed structure. The NLU mod-
ule also supports dynamic updates of the knowl-
edge base.
The CSLI DM module mediates and manages in-
teraction. It uses the dialogue-move approach to
maintain dialogue context, which is then used to
interpret incoming utterances (including fragments
and revisions), resolve NPs, construct salient re-
sponses, track issues, etc. Dialogue states can also
be used to bias SR expectation and improve SR
performance, as has been performed in previous
applications of the DM. Detailed descriptions of
the DM can be found in [Lemon et al2002; Mirk-
ovic & Cavedon 2005].
The Knowledge Manager (KM) controls access to
knowledge base sources (such as domain knowl-
edge and device information) and their updates.
Domain knowledge is structured according to do-
main-dependent ontologies. The current KM
makes use of OWL, a W3C standard, to represent
the ontological relationships between domain enti-
ties. Prot?g? (http://protege.stanford.edu), a do-
main-independent ontology tool, is used to
maintain the ontology offline. In a typical interac-
tion, the DM converts a user?s query into a seman-
tic frame (i.e. a set of semantic constraints) and
sends this to the KM via the content optimizer.
The Content Optimization module acts as an in-
termediary between the dialogue management
module and the knowledge management module
during the query process. It receives semantic
frames from the DM, resolves possible ambigui-
ties, and queries the KM. Depending on the items
in the query result as well as the configurable
properties, the module selects and performs an ap-
propriate optimization strategy.
Early evaluation shows that the system has a
task completion rate of 80% on 11 tasks of MP3
player domain, ranging from playing requests to
music database queries. Porting to a restaurant se-
lection domain is currently under way.
References
Seneff, Stephanie, Ed Hurley, Raymond Lau, Christine Pao,
Philipp Schmid, and Victor Zue, GALAXY-II: A Reference
Architecture for Conversational System Development, In-
ternational Conference on Spoken Language Processing
(ICSLP), Sydney, Australia, December 1998.
Lemon, Oliver, Alex Gruenstein, and Stanley Peters, Collabo-
rative activities and multi-tasking in dialogue systems,
Traitement Automatique des Langues (TAL), 43(2), 2002.
Mirkovic, Danilo, and Lawrence Cavedon, Practical Multi-
Domain, Multi-Device Dialogue Management, Submitted
for publication, April 2005.
Weng, Fuliang, Lawrence Cavedon, Badri Raghunathan, Hua
Cheng, Hauke Schmidt, Danilo Mirkovic, et al, Develop-
ing a conversational dialogue system for cognitively over-
loaded users, International Conference on Spoken
Language Processing (ICSLP), Jeju, Korea, October 2004.
25
NAACL HLT Demonstration Program, pages 23?24,
Rochester, New York, USA, April 2007. c?2007 Association for Computational Linguistics
A Conversational In-car Dialog System
Baoshi Yan1 Fuliang Weng1 Zhe Feng1 Florin Ratiu2 Madhuri Raya1 Yao Meng1
Sebastian Varges2 Matthew Purver2 Annie Lien1 Tobias Scheideck1 Badri Raghunathan1
Feng Lin1 Rohit Mishra4 Brian Lathrop4 Zhaoxia Zhang4 Harry Bratt3 Stanley Peters2
Research and Technology Center, Robert Bosch LLC, Palo Alto, California1
Center for the Study of Language and Information, Stanford University, Stanford, California2
Speech Technology and Research Lab, SRI International, Menlo Park, California3
Electronics Research Lab, Volkswagen of America, Palo Alto, California4
Abstract
In this demonstration we present a con-
versational dialog system for automobile
drivers. The system provides a voice-
based interface to playing music, finding
restaurants, and navigating while driving.
The design of the system as well as the
new technologies developed will be pre-
sented. Our evaluation showed that the
system is promising, achieving high task
completion rate and good user satisfation.
1 Introduction
As a constant stream of electronic gadgets such as
navigation systems and digital music players en-
ters cars, it threatens driving safety by increasing
driver distraction. According to a 2005 report by
the National Highway Traffic Safety Administration
(NHTSA) (NHTSA, 2005), driver distraction and
inattention from all sources contributed to 20-25%
of police reported crashes. It is therefore impor-
tant to design user interfaces to devices that mini-
mize driver distraction, to which voice-based inter-
faces have been a promising approach as they keep
a driver?s hands on the wheel and eyes on the road.
In this demonstration we present a conversational
dialog system, CHAT, that supports music selection,
restaurant selection, and driving navigation (Weng
et al, 2006). The system is a joint research effort
from Bosch RTC, VWERL, Stanford CSLI, and SRI
STAR Lab funded by NIST ATP. It has reached a
promising level, achieving a task completion rate of
98%, 94%, 97% on playing music, finding restau-
rants, and driving navigation respectively.
Specifically, we plan to present a number of fea-
tures in the CHAT system, including end-pointing
with prosodic cues, robust natural language under-
standing, error identification and recovery strate-
gies, content optimization, full-fledged reponse gen-
eration, flexible multi-threaded, multi-device dialog
management, and support for random events, dy-
namic information, and domain switching.
2 System Descriptions
The spoken dialog system consists of a number of
components (see the figure on the next page). In-
stead of the hub architecture employed by Commu-
nicator projects (Seneff et al, 1998), it is devel-
oped in Java and uses flexible event-based, message-
oriented middleware. This allows for dynamic regis-
tration of new components. Among the component
modules in the figure, we use the Nuance speech
recognition engine with class-based n-grams and
dynamic grammars, and the Nuance Vocalizer as the
TTS engine. The Speech Enhancer removes noises
and echo. The Prosody module will provide addi-
tional features to the Natural Language Understand-
ing (NLU) and Dialog Manager (DM) modules to
improve their performance.
The NLU module takes a sequence of recognized
words and tags, performs a deep linguistic analysis
with probabilistic models, and produces an XML-
based semantic feature structure representation. Par-
allel to the deep analysis, a topic classifier assigns
n-best topics to the utterance, which are used in the
cases where the dialog manager cannot make any
sense of the parsed structure. The NLU module also
supports dynamic updates of the knowledge base.
The DM module mediates and manages interac-
23
tion. It uses an information-state-update approach to
maintain dialog context, which is then used to inter-
pret incoming utterances (including fragments and
revisions), resolve NPs, construct salient responses,
track issues, etc. Dialog states can also be used to
bias SR expectation and improve SR performance,
as has been performed in previous applications of
the DM. Detailed descriptions of the DM can be
found in (Lemon et al, 2002) (Mirkovic and Cave-
don, 2005).
The Knowledge Manager (KM) controls access
to knowledge base sources (such as domain knowl-
edge and device information) and their updates. Do-
main knowledge is structured according to domain-
dependent ontologies. The current KMmakes use of
OWL, a W3C standard, to represent the ontological
relationships between domain entities.
The Content Optimization module acts as an in-
termediary between the dialog management module
and the knowledge management module and con-
trols the amount of content and provides recommen-
dations to user. It receives queries in the form of se-
mantic frames from the DM, resolves possible ambi-
guities, and queries the KM. Depending on the items
in the query result as well as configurable properties,
the module selects and performs an appropriate op-
timization strategy (Pon-Barry et al, 2006).
The Response Generation module takes query re-
sults from the KM or Content Optimizer and gener-
ates natural language sentences as system responses
to user utterances. The query results are converted
into natural language sentences via a bottom-up ap-
proach using a production system. An alignment-
based ranking algorithm is used to select the best
generated sentence.
The system supports random events and dy-
namic external information, for example, the system
prompts users for the next turn when they drive close
to an intersection and dialogs can be carried out in
terms of the current dynamic situation. The user can
also switch among the three different applications
easily by explicitly instructing the system which do-
main to operate in.
3 Acknowledgement
This work is partially supported by the NIST Ad-
vanced Technology Program.
References
Oliver Lemon, Alex Gruenstein, and Stanley Peters.
2002. Collaborative activities and multi-tasking in
dialogue systems. In Traitement Automatique des
Langues (TAL), page 43(2).
Danilo Mirkovic and Lawrence Cavedon. 2005. Prac-
tical Plug-and-Play Dialogue Management. In Pro-
ceedings of the 6th Meeting of the Pacific Associa-
tion for Computational Linguistics (PACLING), page
43(2), Tokyo, Japan.
National Highway Traffic Safety Administration
NHTSA. 2005. NHTSA Vehicle Safety Rulemaking
and Supporting Research Priorities: Calendar Years
2005-2009. January.
Heather Pon-Barry, Fuliang Weng, and Sebastian Varges.
2006. Evaluation of content presentation strategies
for an in-car spoken dialogue system. In Proceedings
of the 9th International Conference on Spoken Lan-
guage Processing (Interspeech/ICSLP), pages 1930?
1933, Pittsburgh, PA, September.
Stephanie Seneff, Ed Hurley, Raymond Lau, Chris-
tine Pao, Philipp Schmid, and Victor Zue. 1998.
GALAXY-II: A Reference Architecture for Conversa-
tional System Development. In International Confer-
ence on Spoken Language Processing (ICSLP), page
43(2), Sydney, Australia, December.
Fuliang Weng, Sebastian Varges, Badri Raghunathan,
Florin Ratiu, Heather Pon-Barry, Brian Lathrop,
Qi Zhang, Tobias Scheideck, Harry Bratt, Kui Xu,
Matthew Purver, Rohit Mishra, Annie Lien, Mad-
huri Raya, Stanley Peters, Yao Meng, Jeff Russel,
Lawrence Cavedon, Liz Shriberg, and Hauke Schmidt.
2006. CHAT: A conversational helper for automo-
tive tasks. In Proceedings of the 9th International
Conference on Spoken Language Processing (Inter-
speech/ICSLP), pages 1061?1064, Pittsburgh, PA,
September.
24
