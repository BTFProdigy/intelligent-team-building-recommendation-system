Multilingual Sentence Generation
Takako Aikawa
Maite Melero
Lee Schwartz
Andi Wu
Microsoft Research
One Microsoft Way
Redmond, WA 98008, USA
takakoa@microsoft.com
maitem@microsoft.com
leesc@micorosft.com
andiwu@microsoft.com
Abstract
This paper presents an overview of a
robust, broad-coverage, and
application-independent natural
language generation system. It
demonstrates how the different
language generation components
function within a multilingual
Machine Translation (MT) system,
using the languages that we are
currently working on (English,
Spanish, Japanese, and Chinese).
Section 1 provides a system
description. Section 2 focuses on the
generation components and their core
set of rules. Section 3 describes an
additional layer of generation rules
included to address application-
specific issues. Section 4 provides a
brief description of the evaluation
method and results for the MT system
of which our generation components
are a part.
1 System Description
We present a natural language generation
method in the context of a multi-lingual MT
system. The system that we have been
developing is a hybrid system with rule-based,
example-based, and statistical components.
Analysis and generation are performed with
linguistic parsers and syntactic realization
modules, the rules of which are coded by hand.
Transfer is accomplished using transfer
rules/mappings automatically extracted from
aligned corpora.
The MT process starts with a source sentence
being analyzed by the source-language parser,
which produces as output a syntactic tree. This
tree is input to the Logical Form module, which
produces a deep syntactic representation of the
input sentence, called the LF (Heidorn, G. E.,
2000). The LF uses the same basic set of
relation types for all languages. Figure 1 gives
the syntactic tree and LF for the simple English
sentence, ?I gave the pencils to John?.
Tree
LF
Figure 1
The LF is the final output of the analysis phase
and the input to the transfer phase.
Transfer extracts a set of mappings from the
source-target language MindNet (Richardson,
2000), a translation knowledge database, and
applies these mappings to the LF of the source
sentence to produce a target LF. The translation
MindNet for a language pair is a repository of
aligned LFs and portions of LFs (produced by
analyzing sentence-aligned corpora). An
alignment of two LFs is a set of mappings
between a node or set of nodes (and the relations
between them) in the source LF and a node or
set of nodes (and the relations between them) in
the target LF (Menezes & Richardson, 2001).
In the translation process, the transfer
component searches the alignments in the
MindNet for those that match portions of the LF
of the sentence being translated. Mappings with
larger context are preferred to mappings with
smaller context and higher frequency mappings
are preferred to lower frequency mappings. The
lemmas in any portion of the LF of the input
sentence that do not participate in a mapping are
mapped to a target lemma using a bilingual
dictionary. The target LF fragments from the
transfer mappings and dictionary mappings are
stitched together to produce the target LF
(Menezes & Richardson, 2001). For our
example in Figure 1, the transfer component
produces the following target LFs for Spanish,
Japanese, and Chinese (Figure 2).1
Source sentence: I gave the pencils to John.
Transferred Spanish LF:
Transferred Japanese LF:
Transferred Chinese LF:
Figure 2
The transferred LF is the input to the generation
component, which we will discuss in detail
below.
2 Syntactic Generation Component
The different language generation modules in
our system are syntactic realization components
that take as input an LF characteristic of the
language to be generated and produce a
syntactic tree and surface string for that
language. In this sense, they are functionally
similar to the REALPRO system (Lavoie and
Rambow, 1997).
1 English gloss is provided in Figure 2 for readability
purposes only.
The generation modules are not designed
specifically for MT, but rather are application-
independent. They can take as input an LF
produced by a dialog application, a critiquing
application, a database query application, an MT
application, etc. They only require a
monolingual dictionary for the language being
generated and an input LF that is characteristic
of that language. For each language there is
only one generation component that is used for
all applications, and for MT, it is used for
translation from all languages to that language.
At the beginning of generation, the input LF
is converted into a basic syntactic tree that
conforms to the tree geometry of the NLP
system. The nodes in LF become subtrees of this
tree and the LF relations become
complement/adjunct relationships between the
subtrees. This basic tree can be set up in
different ways. For English, Spanish, and
Chinese, we set it up as strictly head-initial with
all the complements/adjuncts following the
head, resembling the tree of a VSO language.
For Japanese, we set it up as strictly head-final,
with all the complements/adjuncts preceding the
head. Figure 3 gives the basic Spanish
generation tree produced from the Spanish
transferred LF in Figure 2.
Figure 3
The generation rules apply to the basic tree,
transforming it into a target language tree. In the
application of the rules, we traverse the tree in a
top-down, left-to-right, depth-first fashion,
visiting each node and applying the relevant
rules. Each rule can perform one or more of the
following operations:
(1) Assign a syntactic label to the node. For
example, the ?DECL? label will be assigned
to the root node of a declarative sentence.
(2) Modify a node by changing some
information within the node. For example, a
pronoun might be marked as reflexive if it is
found to be co-referential with the subject of
the clause it is in.
(3) Expand a node by introducing new node(s)
into the tree. For example, the ?Definite?
(+Def) feature on a node may become a
determiner phrase attached to the syntactic
subtree for that node.
(4) Delete a node. For example, for a pro-drop
language, a pronominal subject may be
removed from the tree.
(5) Move a node by deleting it from Position A
and inserting it in Position B. For example,
for an SVO language, the subject NP of a
sentence may be moved from a post-verbal
position to a pre-verbal position.
(6) Ensure grammatical agreement between
nodes. For example, if the subject of a
sentence is first person singular, those
number and person features will be assigned
to the main verb.
(7) Insert punctuation and capitalization.
The nodes in the generated tree are linked to
each other by relations such as ?head?, ?parent?
and ?sibling?. The entire tree is thus visible
from any given node via these relations. When
a rule is applied to a node, the decisions made in
that rule can be based not just on features of that
node, but also on features of any other node in
the tree. This basically eliminates the need for
backtracking, which would be necessary only if
there were local ambiguities resulting from the
absence of global information. In this sense, our
approach is similar to that of other large-scale
generators (Tomita and Nyberg, 1988).
The generation rules operate on a single tree.
Rule application is deterministic and thus very
efficient. If necessary, the tree can be traversed
more than once, as is the case in the generation
modules for the languages we are currently
working on. There is a ?feeding? relationship
among the rules. The rules that assign
punctuation and capitalization, for example, do
not apply until all the movement rules have
applied, and movement rules do not apply until
nodetypes and functional roles are assigned.
To improve efficiency and to prevent a rule
from applying at the wrong time or to the wrong
structure, the rules are classified into different
groups according to the passes in which they are
applied. Each traversal of the tree activates a
given group of rules. The order in which the
different groups of rules are applied depends on
the feeding relations.
For the simple example in Figure 2 above,
the Spanish, Chinese, and Japanese generation
components all have an initial pass that assigns
nodetypes and functional roles and a final pass
that inserts punctuation marks.
In addition, the Spanish component, in a first
pass that identifies syntactic functions, deletes
the pronominal subject and inserts a dative clitic
pronoun. It also inserts the definite article and
the personal marker ?a?. In a second pass, it
checks agreement between indirect object and
doubled clitic as well as between subject and
verb, assigning the appropriate person, number,
and gender agreement information to the
terminal nodes.
Reordering operations, such as moving the
clitic in front of the verb, if the verb is finite, or
after, if it is non-finite, come later. The last pass
takes care of euphonic issues, such as
contractions or apocopated adjectives. Figure 4a
shows the resulting tree.
Figure 4a
The Chinese component has a node-
modification pass, which adds the FUNCW
node headed by (le) to indicate past tense. In
this pass the direct object is also turned into a
prepositional phrase introduced by (ba) to
show the definiteness of the NP. Following this
pass, a movement pass moves the subject in
front of the verb.
Figure 4b
The Japanese component has a pass in which
case-markers or modifiers are inserted. In
Figure 4c, the nominative, the accusative, and
the dative case markers are inserted in the
subject, direct object, and indirect object NPs,
respectively. Also, the demonstrative
corresponding to English "that" is inserted at the
beginning of the definite NP (pencil).
Figure 4c
After the grammatical rules apply, the
morphological rules apply to the leaf nodes of
the tree. Since each node in the tree is a feature
matrix and agreement information has already
been assigned by the generation rules,
morphological processing simply turns the
feature matrices into inflected forms. For
instance, in our Spanish example, the verb ?dar?
with the ?past?, ?singular? and ?1st person?
features is spelled out as ?di?. Once all the
words are inflected, the inflected form of each
leaf node is displayed to produce the surface
string. This completes the generation process,
as exemplified for Spanish in Figure 5.
Figure 5
3 Application-Driven Generation
The example used in the previous sections is
quite simple, and not representative of the actual
problems that arise in MT. Applications, such
as MT, that automatically create input for the
generation component for a language will not
always produce ideal LFs for that language, i.e.,
LFs that could have been produced by the
analysis modules for that language.
We have designed the generation
components, therefore, to add a degree of
robustness to our applications. To some extent,
and based only on information about the
language being generated, the generation
components will fix incomplete or inconsistent
LFs and will verify that the structures they
generate comply with the constraints imposed
by the target language.
The core generation rules are designed to be
application-independent and source-language-
independent. Expanding the rule base to cover
all the idiosyncrasies of the input would
contaminate the core rules and result in loss of
generality. In order to maintain the integrity of
the core rules while accommodating imperfect
input, we have opted to add a pre-generation
layer to our generation components.
Pre-generation rules apply before the basic
syntactic tree is built. They can modify the
input LF by adding or removing features,
changing lemmas, or even changing structural
relations. Below we give examples of problems
solved in the pre-generation layers of our
different language generation modules. These
illustrate not just the source-language
independence, but also the application-
independence of the generation modules.
We start with the English generation
component, which was used in experimental
question-answering applications before being
used in MT. Among the pre-generation rules in
this component is one that removes the marker
indicating non-restrictive modification (Nonrest)
from LF nodes that are not in a modification
relationship to another LF node. So, for
example, when the question-answering
application is presented with the query ?When
did Hitler come to power,? the NLP system
analyzes the question, produces an LF for it,
searches its Encarta Mindnet (which contains
the LFs for the sentences in the Encarta
encyclopedia), retrieves the LF fragment in
Figure 6, and sends it to the English generation
component.
Figure 6
The LF that is the input to generation in this
example is a portion of the LF representation of
a complete sentence that includes the phrase
?Hitler, who came to power in 1933.? The part
of that sentence that answers the question is the
nonrestrictive relative clause ?who came to
power in 1933.? Yet, we do not want to
generate the answer as a non-restrictive relative
clause (as indicated by Nonrest in the LF), but
as a declarative sentence. So, rather than pollute
the core generation rules by including checks for
implausible contexts in the rule for generating
nonrestrictive modifiers, a pre-generation rule
simply cleans up the input. The rule is
application-independent (though motivated by a
particular application) and can only serve to
clean up bad input, whatever its source.
An example of a rule motivated by MT, but
useful for other applications, is the pre-
generation rule that changes the quantifier ?less?
to ?fewer?, and vice versa, in the appropriate
situations. When the LF input to the English
generation component specifies ?less? as a
quantifier of a plural count noun such as ?car,?
this rule changes the quantifier to ?fewer?.
Conversely, when an input LF has ?fewer?
specified as a quantifier of a mass noun such as
?luck?, the rule changes it to ?less.? This rule
makes no reference to the source of the input to
generation. This has the advantage that it will
apply in a grammar-checking application as well
as in an MT application (or any other
application). If the input to English generation
were the LF produced for the ungrammatical
sentence ?He has less cars,? the generation
component would produce the correct ?He has
fewer cars,? thereby effectively grammar
checking the sentence. And, if the ultimate
source of the same input LF were the Spanish
sentence ?Juan tiene menos coches, ? the result
would be the same, even if ?menos? which
corresponds to both ?less? and ?fewer? in
English, were not transferred correctly. Another
type of problem that a generation component
might encounter is the absence of necessary
information. The Spanish generation
component, for instance, may receive as input
underspecified nominal relations, such as the
one exemplified in Figure 7, in which a noun
(registro) is modified by another noun
(programa). The relationship between the two
nouns needs to be made explicit, in Spanish, by
means of a preposition when the modifying
noun is not a proper noun. Absent the necessary
information in the incoming LF, a pre-
generation rule introduces the default
preposition ?de? to specify this relationship.
Figure 7
Another example of a pre-generation rule, this
time from Japanese, deals with the unspecified
1st/2nd person pronominal subject for particular
types of predicates. The 1st/2nd person pronoun
( ) is not used as the subject in
sentences that express the speaker?s/the
listener?s desire (unless there is some
focus/contrast on the subject). So, one of the
Japanese pre-generation rules deletes the subject
in the input LF that involves such a predicate.
For instance, below is the input LF, the modified
LF, and the string produced from the English
sentence ?I want to read the book.?
Figure 8
From Chinese, we give an example of a rule that
actually changes the structure of an LF. In our
system, it is possible for the source and target
languages to have different LF representations
for similar structures. In English and other
European languages, for example, the verb ?BE?
is required in sentences like ?He is smart?. In
Chinese, however, no copula is used. Instead,
an adjectival predicate is used. While we might
attempt at the LF level to unify these
representations, we have not yet done so.
Moreover, the LF in our system is not intended
to be an interlingua representation. Differences
between languages and their LFs are tolerated.
Therefore, Chinese uses a pre-generation rule to
transform the be-predicate adjective LF into its
Chinese equivalent as shown in Figure 9, though
we soon expect transfer to automatically do this.
Figure 9
4 Evaluation
The generation components described in the
previous sections are part of an MT system that
has been run on actual Microsoft technical
documentation. The system is frequently
evaluated to provide a measure of progress and
to yield feedback on its design and development.
In evaluating our progress over time and
comparing our system with others, we have
performed several periodic, blind human
evaluations. We focus here on the evaluation of
our Spanish-English and English-Spanish
systems.
For each evaluation, several human raters
judge the same set of 200-250 sentences
randomly extracted from our technical corpora
(150K sentences).2 The raters are not shown the
source language sentence; instead, they are
presented with a human translation, along with
two machine-generated translations. Their task
is to choose between the alternatives, using the
human translation as a reference.
Table 1 summarizes a comparison of the
output of our Spanish-English system with that
of Babelfish (http://world.altavista.com/).
Table 2 does the same for our English-Spanish
system and Lernout & Hauspie?s English-
Spanish system (http://officeupdate.lhsl.com/).
In these tables, a rating of 1 means that raters
uniformly preferred the translation produced by
our system; a rating of 0 means that they did not
uniformly prefer either translation; a rating of -1
means that they uniformly preferred the
translation produced by the alternative system.3
Beside each rating is a confidence measure for
the mean preference at the .99 level (Richardson,
S., et al(2001)).
Spanish-English
Systems
Mean preference
score (7 raters)
Sample
size
Our 4/01 (2001)
MT vs. Babelfish
0.32 ? 0.11
(at .99)
250
sentences
Table 1. Our Spanish-English MT vs. Babelfish
English-Spanish
Systems
Mean preference
score (5 raters)
Sample
size
Our 4/01 (2001)
MT vs. L&H
0.19 ? 0.14
(at 0.99)
250
sentences
Table 2. Our English-Spanish MT vs. Lernout &
Hauspie
2 The human raters used for these evaluations work for an
independent agency and played no development role
building the systems they test.
3 In interpreting our results, it is important to keep in mind
that our MT system has been customized to the test domain,
while the Babelfish and Lernout & Hauspie systems have
not.
5 Conclusion
In this paper we have presented an overview of
the natural language generation component
developed at Microsoft Research and have
demonstrated how this component functions
within a multilingual Machine Translation
system. We have provided motivation for the
generation architecture, which consists of a set
of core rules and a set of application-driven pre-
generation rules, within a wide-coverage, robust,
application-independent, multilingual natural
language processing system. In addition we
have presented evaluation figures for Spanish-
English and English-Spanish, two of the
language pairs of the MT system in which our
generation components are used.
6 References
Heidorn, G. E. (2000): Intelligence Writing
Assistance. In Dale R., Moisl H., and Somers
H. (eds.), A Handbook of Natural Language
Processing: Techniques and Applications for
the Processing of Language as Text. Marcel
Dekker, New York, 1998 (published in
August 2000), pages 181-207.
Jensen, K., Heidorn G., and Richardson S.
(eds.) (1993): Natural Language Processing:
The PLNLP Approach, Boston, Kluwer.
Lavoie, Benoit and Owen Rambow. (1997): A
fast and portable realizer for text generation.
In Proceedings of the Fifth Conference on
Applied Natural-Language Processing
(ANLP-1997), pages 265-268.
Melero, M. and Font-Llitjos, A. (2001):
Construction of a Spanish Generation module
in the framework of a General-Purpose,
Multilingual Natural Language Processing
System. In Proceedings of the VII
International Symposium on Social
Communication, Santiago de Cuba.
Reiter, E. and Dale, R. (2000): Building Natural
Language Generation Systems, Cambridge
University Press.
Richardson, S., et al(2001): Overcoming the
customization bottleneck using example-
based MT, Paper submitted for Data-driven
MT Workshop at ACL 2001, Toulouse,
France.
Richardson, S. (2000): The evolution of an NLP
System. NLP Group Microsoft Research,
Presentation at the LREC?2000 Athens,
Greece.
Tomita, M. and Nyberg E. (1988): The GenKit
and Transformation Kit User?s Guide.
Technical Report CMU-CMT-88-MEMO,
Centre for Machine Translation, Carnegie
Mellon University.
Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT, pages 101?109,
Dublin, Ireland, August 23rd 2014.
EUMSSI: a Platform for Multimodal Analysis and Recommendation
using UIMA
Jens Grivolla
Universitat Pompeu Fabra
Barcelona, Spain
jens.grivolla@upf.edu
Maite Melero
Universitat Pompeu Fabra
Barcelona, Spain
maite.melero@upf.edu
Toni Badia
Universitat Pompeu Fabra
Barcelona, Spain
toni.badia@upf.edu
Cosmin Cabulea
Deutsche Welle
Bonn, Germany
cosmin.cabulea@dw.de
Yannick Est
`
eve
Universit?e du Maine
Le Mans, France
yannick.esteve@
lium.univ-lemans.fr
Eelco Herder
L3S Research Center
Hannover, Germany
herder@l3s.de
Jean-Marc Odobez
IDIAP Research Institute
Martigny, Switzerland
odobez@idiap.ch
Susanne Preu?
Gesellschaft zur F?orderung der
Angewandten Informationsforschung
Saarbr?ucken, Germany
susannep@iai.uni-sb.de
Ra?ul Mar??n
VSN Innovation
and Media Solutions
Alicante, Spain
rmarin@vsn.es
Abstract
The EUMSSI project (Event Understanding through Multimodal Social Stream Interpretation)
aims at developing technologies for aggregating data presented as unstructured information in
sources of very different nature. The multimodal analytics will help organize, classify and clus-
ter cross-media streams, by enriching its associated metadata in an interactive manner, so that
the data resulting from analysing one media helps reinforce the aggregation of information from
other media, in a cross-modal semantic representation framework. Once all the available de-
scriptive information has been collected, an interpretation component will dynamically reason
over the semantic representation in order to derive implicit knowledge. Finally the enriched in-
formation will be fed to a hybrid recommendation system, which will be at the basis of two
well-motivated use-cases. In this paper we give a brief overview of EUMSSI?s main goals and
how we are approaching its implementation using UIMA to integrate and combine various layers
of annotations coming from different sources.
1 Introduction
Nowadays, a multimedia journalist has access to a vast amount of data from a plurality of types of sources
to document a story. In order to put information into context and tell his story from all significant angles,
he needs to go through an enormous amount of records with information of very diverse degrees of
granularity. At the same time, he needs to reduce the noise of irrelevant content. This is extremely
time-consuming, especially when a topic or event is interconnected with multiple entities from different
domains. At a different level, many TV viewers are getting used to navigating with their tablets or iPads
while watching the TV, the tablet effectively functioning as a second screen, often providing background
information on the program or interaction in social networks about what is being watched. Both the
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
101
journalist and the TV viewer would greatly benefit from a system capable of automatically analysing and
interpreting unstructured multimedia data stream and its social background, and, with this understanding,
be able of contextualising the data, and contributing with new, related information.
The FP7-ICT-2013-10 STREP project EUMSSI, which started in December 2013, is developing
methodologies and techniques for identifying and aggregating data presented as unstructured informa-
tion in sources of very different nature (video, image, audio, speech, text and social context), including
both online (e.g., YouTube) and traditional media (e.g. audiovisual repositories), and for dealing with
information of very different degrees of granularity.
This will be accomplished thanks to the integration in a UIMA-based
1
multimodal platform of state-
of-the-art information extraction and analysis techniques from the different fields involved (image, audio,
text and social media analysis). The multimodal interpretation platform, in an optimized process chain,
will analyze a vast amount of multimedia content, aggregate all the resulting information and semanti-
cally enrich it with additional metadata layers. The resulting system will be potentially useful for any
application in need of cross-media data analysis and interpretation, such as intelligent content manage-
ment, recommendation, real time event tracking, content filtering, etc. In particular, the EUMSSI project
will use the semantically enriched information to make personalized content-based recommendation.
2 Multimodal analytics and Semantic Enrichment
For reasoning with and about the multimedia data, the EUMSSI platform needs to recognize entities,
such as actors, places, topics, dates and genres. A core idea is that the process of integrating information
coming from different media sources is carried out in an interactive manner, so that the metadata resulting
from analyzing one media helps reinforce the aggregation of information from other media. For example,
the quality of speech recognition heavily depends on the audio quality and background noise. Existing
text, tags and other metadata will be exploited for disambiguation. Further, OCR on video data, speech
analysis and speaker recognition mutually reinforce one another. The combined and integrated results of
the audio, video and text analysis will significantly enhance the existing metadata, which can be used for
retrieval and recommendation. In addition, the extracted entities and other annotations will be exploited
for identifying specific video fragments in which a particular person speaks, a new topic begins, or an
entity is mentioned. Figure 1 illustrates some of the different layers of analysis that may exist for a video
content item.
Once the entities and concepts have been identified in the different modalities, all the information is ag-
gregated and semantically enriched, using general ontologies or structured knowledge bases. Wikipedia
categories have been successfully exploited with this purpose in different works: e.g. to describe chemi-
cal documents (K?ohncke and Balke, 2010), to identify topics of interest for Twitter users (Michelson and
Macskassy, 2010), and also to improve Web video categorization (Chen et al., 2010). Moreover, (Hahn et
al., 2010) have shown that the structured information gathered from Wikipedia infoboxes can be used to
answer complex questions, like ?Which Rivers flow into the Rhine and are longer than 50 kilometers??
For this purpose, text documents need to be previously annotated using DBpedia Spotlight (Mendes et
al., 2011), which automatically annotates text with links to articles in Wikipedia. The process of se-
mantic enrichment is still largely domain-dependent; therefore, apart from the available general-purpose
knowledge bases and ontologies (DBpedia, FOAF, DublinCore...), the EUMSSI platform needs special-
ized resources for categorizing videos on different dimensions. Linked Data technologies (Heath and
Bizer, 2011) and the Linked Open Data cloud
2
provide access to several of these resources, including
geodata, movie databases and program information.
3 Content-based Recommendation and the Demonstrators
The semantically enriched information is then used by the EUMSSI system to make personalized
content-based recommendation. We propose a novel recommender system that leverages matrix factor-
ization (Koren, 2008) with implicit feedback in order to integrate content-based similarity, usage history
1
Unstructured Information Management Architecture: http://uima.apache.org/
2
http://lod-cloud.net/
102
Figure 1: Video Mining Analysis
(i.e. collaborative filtering), as well as user demographics. This integrated approach reduces the cold-
start problems typical of collaborative filtering, both for new users and for new content. Recommendation
and aggregation of related content in EUMSSI is expected to use varying degrees of personalization, giv-
ing more weight in some cases to the individual user?s interests, based on his viewing history, but being
based primarily on the similarity to the currently shown content in other cases.
On top of the recommender, two demonstrators will be implemented within the EUMSSI project, each
catering to a different use-case: (i) a computer-assisted storytelling tool integrated in the workflow of a
multimedia news editor, empowering the journalist to monitor and gather up-to-date documents related
with his investigation, without the need of reviewing an enormous amount of insufficiently annotated
records; and (ii) a second-screen application for an end-user, able to make relevant suggestions of mul-
timedia content based on what the user is watching, what other people have watched, and what people
are saying about these contents in the social networks. Figure 2 shows how both applications build on a
common base of multimedia analysis and content aggregation/recommendation algorithms.
4 Architecture overview
All new content coming into the system is first normalized to a common metadata schema (based on
schema.org) and stored in a database (MAM/media asset manager, or MongoDB
3
) to make it available
for further processing. Analysis results, as well as the original metadata, are stored in CAS format to
allow integration of different aligned layers of analysis.
The process flow, pictured in Figure 3, can be summarized as follows:
1. new data arrives (or gets imported)
2. preprocessing stage
(a) make content available through unique URI (from central MAM)
(b) create initial CAS with aligned metadata / text content and content URI
3
it will be developed in parallel as an open source MongoDB based solution, as well as integrated into VSN?s proprietary
platform
103
Figure 2: Multimodal platform catering both for the journalist and the end-user?s use-cases
(c) add content to processing queues
3. processing / content analysis
(a) distributed analysis systems query queue when they have processing capacity
(b) retrieve CAS with existing data (or get relevant metadata from wrapper API)
(c) retrieve raw content based on content URI
(d) process
(e) update CAS (possibly through wrapper API)
(f) update queues
i. mark as processed
ii. add to queues for other processes that depend on previous analysis results
4. indexing when processing is complete for a content item (e.g. with Solr)
Note that this architecture design mainly depicts the data analysis part of the EUMSSI system ? the
deployment by Web applications is not visible in the figure. These will be built upon the Solr indexes
created from the CAS.
5 Aligned data representation
Much of the reasoning and cross-modal integration depends on an aligned view of the different annotation
layers, e.g., in order to connect person names detected from OCR with corresponding speakers from the
speaker recognition component, or faces detected by the face recognition.
The Apache UIMA
4
CAS (common analysis structure) representation is a good fit for the needs of the
EUMSSI project as it has a number of interesting characteristics:
? Annotations are stored ?stand-off?, meaning that the original content is not modified in any way by
adding annotations. Rather, the annotations are entirely separate and reference the original content
by offsets
4
http://uima.apache.org/
104
Data Sources
crawlers
DW
feeds
...
extract metadata / 
content
create 
initial CAS
add to / update 
processing queues
video 
analysis
audio 
analysis
text 
analysis
MAM / 
MongoDB
1. get raw content / 
previous CAS
2. process
3. update CAS
Preprocess
Processing
queue 
manager
...
Figure 3: Architecture design
? Annotations can be defined freely by defining a ?type system? that specifies the types of anno-
tations (such as Person, Keyword, Face, etc.) and the corresponding attributes (e.g. dbpediaUrl,
canonicalRepresentation, ...)
? Source content can be included in the CAS (particularly for text content) or referenced as external
content via URIs (e.g. for multimedia content)
? While each CAS represents one ?document? or ?content item?, it can have several Views that rep-
resent different aspects of that item, e.g. the video layer, audio layer, metadata layer, transcribed
text layer, etc., with separate source content (SofA or ?subject of annotation?) and separate sets of
annotations
? CASes can be passed efficiently in-memory between UIMA analysis engines
? CASes can be serialized in a standardised OASIS format
5
for storage and interchange
In the case of the EUMSSI project, the common base for alignment for different annotation layers
referring to multimedia content is timestamps relative to the original content.
Annotations based directly on multimedia content (video and audio) will naturally refer to that content
via timestamps, whereas text analysis modules normally work with character offsets relative to the text
content. It is therefore fundamental that any textual views created from multimedia content (e.g. via ASR
or OCR) refer back to the timestamps in the original content. This will be done by creating annotations,
e.g. tokens, that include the original timestamps as attributes in addition to the character offsets.
As an example, we may have a CAS with an audio view on which we apply automatic speech recogni-
tion (ASR), providing the transcription as a series of tokens/words with a timestamp for each word. The
system then creates a new view in the CAS that has the full plain-text transcription as SofA and a series
of Token annotations with both character offsets relative to the plain-text SofA, and timestamp offsets
relative to the multimedia content.
In this way it is possible to apply standard text analysis modules (that rely on character offsets) on the
textual representation, while maintaining the possibility to later map the resulting annotations back onto
the temporal scale.
Timestamps will be represented in milliseconds in order to avoid floating point values. In this way, all
annotations can be subtypes of the standard UIMA Annotation type
6
, which provides access to a number
5
http://docs.oasis-open.org/uima/v1.0/uima-v1.0.html
6
otherwise annotations would need to derive from the more generic TOP type
105
of utility functions that help find sets of overlapping annotations, retrieve annotations in offset order, etc.
SofA-aware UIMA components are able to work on multiple views, whereas ?normal? analysis en-
gines only see one specific view that is presented to them. This means that e.g. standard text analysis
engines don?t need to be aware that they are being applied to an ASR view or an OCR view; they just
see a regular text document. SofA-aware components, however, can explicitly work on annotations from
different views and can therefore be used to integrate and combine the information coming from different
sources or layers, and create new, integrated views with the output from that integration and reasoning
process.
6 Flow management
UIMA provides a platform for execution of analysis components (Analysis Engines or AEs), as well as
for managing the flow between those components.
CPE or uimaFIT
7
(Ogren and Bethard, 2009) can be used to design and execute pipelines made up of a
sequence of AEs (and potentially some more complex flows), and UIMA-AS
8
(Asynchronous Scaleout)
permits the distribution of the process among various machines or even a cluster (with the help of UIMA
DUCC
9
).
Analysis Engines can either be ?natively? written for UIMA or can be wrappers that translate inputs
and outputs for existing analysis components so they can be integrated in UIMA. All text analysis com-
ponents, as well as the integration and reasoning components, will be available as UIMA AEs and can
therefore be configured and executed directly within the UIMA environment.
There are some components of the EUMSSI platform, however, that do not integrate easily in this
fashion. This is the case of computationally expensive processes that are optimized for batch execution.
A UIMA AE needs to expose a process() method that operates on a single CAS (= document), and is
therefore not compatible with batch processing. This is particularly true for processes that need to be run
on a cluster, with significant startup overhead, such as many video and audio analysis tasks.
It is therefore necessary to have an alternative flow mechanism for offline or batch processes, which
needs to integrate with the processing performed within the UIMA environment.
The main architectural and integration issues revolve around the data flow, rather than the computa-
tion. In fact, the computationally complex and expensive aspects are specific to the individual analysis
components, and should not have an important impact on the design of the overall platform.
As such, the design of the flow management is presented in terms of transformations between data
states, rather than from the procedural point of view. The resulting system should only rely on the
robustness of those data states to ensure the reliability and robustness of the overall system, protecting
against potential problems from server failures or other causes. At any point, the system should be able
to resume its function purely from the state of the persisted data.
To ensure reliability and performance of the data persistence, we expect to use a well-established and
widely used database system such as MongoDB.
Figure 4 shows the general flow of the EUMSSI system, focusing on the data states needed for the
system to function.
In order to avoid synchronization issues, the state of the data processing is stored together with the
data, and the list of pending tasks can be extracted at any point through simple database queries.
For example in order to retrieve the list of content items that have been crawled or received from feeds,
but still need to be converted to the unified EUMSSI schema, it is sufficient to query for items that have
a ?source meta:original? but no ?source meta:eumssi?.
Similarly, the queues for analysis processes can be constructed directly from the ?processing state? of
an item by selecting (for a given queue) all items that have not yet been processed by that queue and that
fulfil all prerequisites (dependencies).
7
https://uima.apache.org/uimafit.html
8
http://uima.apache.org/doc-uimaas-what.html
9
http://uima.apache.org/doc-uimaducc-whatitam.html
106
Figure 4: data flow and transformations
As an illustration, each content item has approximately the following structure:
{
"content_id" : UUID,
"source_meta" : {
"original" : ORIGINAL_SOURCE_METADATA,
"eumssi" : EUMSSI_SOURCE_METADATA
},
"cas" : {
"xmi" : XMI_CAS,
"binary" : BINARY_CAS
},
"processing_state" : {
"queue1" : "done",
"queue2" : "in_process",
...
"queueN" : "pending"
},
"extracted_meta" : METADATA_FROM_CAS
}
where:
107
? UUID is a system-wide unique content id, created when first inserting the content into the system
? ORIGINAL SOURCE METADATA is the metadata as provided from the original content fields
? EUMSSI SOURCE METADATA is the original metadata mapped to the EUMSSI vocabulary /
schema
? XMI CAS is the CAS serialized in XMI format (and possibly compressed)
? BINARY CAS is the CAS serialized in binary format (alternative to XMI CAS)
? METADATA FROM CAS is metadata that is generated by EUMSSI analysis processes, using the
EUMSSI schema
Normally, the CAS will be stored only in one of the available formats, but potentially different serial-
izations could be used. The ?extracted meta? information can be used for analysis results that are used
as inputs to other annotators (such as detected Named Entities as input to speech recognition), to avoid
the overhead of extracting that information from the CAS on demand.
MongoDB allows to stored structured information (corresponding to a JSON structure), so that the
content of fields like ORIGINAL SOURCE METADATA can reflect whatever internal structure the orig-
inal data had.
The final applications are not expected to use the information stored in MongoDB directly, but rather
access Solr indexes created from that information to respond specifically to the types of queries needed
by the applications. Those indexes will typically be created from the CAS when all analysis steps have
been performed.
It is, however, possible to have indexing processes that only depend on a subset of analyses, and thus
make content items (at least partially) accessible to the applications before they have been fully processed
(which may take a relatively long time). The indexing processes can be managed in the same way as any
analysis process, with their own queues that specify the necessary dependencies, and taking the current
state of the CAS as input.
In its simplest form, the processes responsible for the data transitions are fully independent and poll
the database periodically to retrieve pending work. Those processes can then be implemented in any
language that can communicate comfortably with MongoDB. As an efficiency improvement, in order
to reduce the polling load, message queues (such as managed by ActiveMQ
10
) can be used to notify
processes of pending work after performing the preceding steps.
7 Conclusions and future work
In this paper, we have presented the main goals and approaches of the EUMSSI project, which aims
to innovatively integrate state-of-the-art text and A/V analysis technologies, semantic enrichment and
reasoning, social intelligence and collaborative content-based recommendation, in order to build a mul-
timodal, interoperable platform potentially useful for any application in need of automatic cross-media
data analysis and interpretation, such as intelligent content management, personalized recommendation,
real time event tracking, content filtering, etc.
The project is still in an early stage, and many aspects will need to be defined later on. The different
analysis modalities are handled by separate research groups that will each improve the individual types of
analysis in their are of expertise. This paper only reports on the platform that will integrate and combine
the analysis results.
Additionally, possible interactions between modalities will need to be defined as it becomes clearer
what information each analysis can provide or benefit from. We have at this point identified some of the
more obvious interactions, such as doing text analysis on speech recognition output, or adding Named
Entities from surrounding text to the vocabulary known to the ASR system, but many more may become
apparent as the different research groups learn from each other.
10
http://activemq.apache.org/
108
One of the main innovative aspects of the project also lies in the combination of the outputs of different
analysis layers, and the capacity to perform reasoning or inference over this combined view to create a
richer model of the content than can be obtained individually. This is an important research task that
has not started yet, and we hope to report on it in the near future. As such, this article is limited to the
technological foundation that will enable this work by providing a flexible platform with easy access to
all available information layers.
Development of the platform has recently begun and all developments will become publicly available
at https://github.com/EUMSSI/.
Acknowledgements
The work presented in this article is being carried out within the FP7-ICT-2013-10 STREP
project EUMSSI under grant agreement n
?
611057, receiving funding from the European
Union?s Seventh Framework Programme managed by the REA-Research Executive Agency
http://ec.europa.eu/research/rea.
References
Zhineng Chen, Juan Cao, Yicheng Song, Yongdong Zhang, and Jintao Li. 2010. Web video categorization based
on Wikipedia categories and content-duplicated open resources. In Proceedings of the international conference
on Multimedia - MM ?10, page 1107, New York, New York, USA, October. ACM Press.
Rasmus Hahn, Christian Bizer, Christopher Sahnwaldt, Christian Herta, Scott Robinson, Michaela B?urgle, Holger
D?uwiger, and Ulrich Scheel. 2010. Faceted wikipedia search. In Business Information Systems, pages 1?11.
Springer.
Tom Heath and Christian Bizer. 2011. Linked data: Evolving the web into a global data space. Synthesis Lectures
on the Semantic Web: Theory and Technology.
Benjamin K?ohncke and Wolf-Tilo Balke. 2010. Using Wikipedia categories for compact representations of chem-
ical documents. In Proceedings of the 19th ACM international conference on Information and knowledge
management - CIKM ?10, page 1809, New York, New York, USA, October. ACM Press.
Yehuda Koren. 2008. Factorization meets the neighborhood. In Proceeding of the 14th ACM SIGKDD interna-
tional conference on Knowledge discovery and data mining - KDD 08, page 426, New York, New York, USA,
August. ACM Press.
Pablo N. Mendes, Max Jakob, Andr?es Garc??a-Silva, and Christian Bizer. 2011. DBpedia spotlight. In Proceedings
of the 7th International Conference on Semantic Systems - I-Semantics ?11, pages 1?8, New York, New York,
USA, September. ACM Press.
Matthew Michelson and Sofus A. Macskassy. 2010. Discovering users? topics of interest on twitter. In Proceed-
ings of the fourth workshop on Analytics for noisy unstructured text data - AND ?10, page 73, New York, New
York, USA, October. ACM Press.
Philip V. Ogren and Steven J. Bethard. 2009. Building test suites for UIMA components. SETQA-NLP ?09
Proceedings of the Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language
Processing, pages 1?4, June.
109
