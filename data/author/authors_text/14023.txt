Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 815?823,
Beijing, August 2010
Nonparametric Word Segmentation for Machine Translation
ThuyLinh Nguyen Stephan Vogel Noah A. Smith
Language Technologies Institute
Carnegie Mellon University
{thuylinh,vogel,nasmith}@cs.cmu.edu
Abstract
We present an unsupervised word seg-
mentation model for machine translation.
The model uses existing monolingual seg-
mentation techniques and models the joint
distribution over source sentence segmen-
tations and alignments to the target sen-
tence. During inference, the monolin-
gual segmentation model and the bilin-
gual word alignment model are coupled
so that the alignments to the target sen-
tence guide the segmentation of the source
sentence. The experiments show improve-
ments on Arabic-English and Chinese-
English translation tasks.
1 Introduction
In statistical machine translation, the smallest unit
is usually the word, defined as a token delimited
by spaces. Given a parallel corpus of source and
target text, the training procedure first builds a
word alignment, then extracts phrase pairs from
this word alignment. However, in some languages
(e.g., Chinese) there are no spaces between words.
The same problem arises when translating be-
tween two very different languages, such as from
a language with rich morphology like Hungarian
or Arabic to a language with poor morphology
like English or Chinese. A single word in a mor-
phologically rich language is often the composi-
tion of several morphemes, which correspond to
separate words in English.1
1We will use the terms word segmentation, morphologi-
cal analysis, and tokenization more or less interchangeably.
Often some preprocessing is applied involving
word segmentation or morphological analysis of
the source and/or target text. Such preprocess-
ing tokenizes the text into morphemes or words,
which linguists consider the smallest meaning-
bearing units of the language. Take as an ex-
ample the Arabic word ?fktbwha? and its En-
glish translation ?so they wrote it?. The preferred
segmentation of ?fktbwha? would be ?f-ktb-w-ha
(so-wrote-they-it),? which would allow for a one-
to-one mapping between tokens in the two lan-
guages. However, the translation of the phrase in
Hebrew is ?wktbw ath?. Now the best segmen-
tation of the Arabic words would be ?fktbw-ha,?
corresponding to the two Hebrew words. This ex-
ample shows that there may not be one correct
segmentation that can be established in a prepro-
cessing step. Rather, tokenization depends on the
language we want to translate into and needs to
be tied in with the alignment process. In short,
we want to find the tokenization yielding the best
alignment, and thereby the best translation sys-
tem.
We propose an unsupervised tokenization
method for machine translation by formulating a
generative Bayesian model to ?explain? the bilin-
gual training data. Generation of a sentence pair
is described as follows: first a monolingual to-
kenization model generates the source sentence,
then the alignment model generates the target sen-
tence through the alignments with the source sen-
tence. Breaking this generation process into two
steps provides flexibility to incorporate existing
monolingual morphological segmentation mod-
els such as those of Mochihashi et al (2009) or
Creutz and Lagus (2007). Using nonparametric
815
models and the Bayesian framework makes it pos-
sible to incorporate linguistic knowledge as prior
distributions and obtain the posterior distribution
through inference techniques such as MCMC or
variational inference.
As new test source sentences do not have trans-
lations which can help to infer the best segmenta-
tion, we decode the source string according to the
posterior distribution from the inference step.
In summary, our segmentation technique con-
sists of the following steps:
? A joint model of segmented source text and
its target translation.
? Inference of the posterior distribution of the
model given the training data.
? A decoding algorithm for segmenting source
text.
? Experiments in translation using the prepro-
cessed source text.
Our experiments show that the proposed seg-
mentation method leads to improvements on
Arabic-English and Chinese-English translation
tasks.
In the next section we will discuss related work.
Section 3 will describe our model in detail. The
inference will be covered in Section 4, and decod-
ing in Section 5. Experiments and results will be
presented in Section 6.
2 Related Work
The problem of segmentation for machine trans-
lation has been studied extensively in recent lit-
erature. Most of the work used some linguistic
knowledge about the source and the target lan-
guages (Nie?en and Ney, 2004; Goldwater and
McClosky, 2005). Sadat and Habash (2006) ex-
perimented with a wide range of tokenization
schemes for Arabic-English translation. These
experiments further show that even for a single
language pair, different tokenizations are needed
depending on the training corpus size. The ex-
periments are very expensive to conduct and do
not generalize to other language pairs. Recently,
Dyer (2009) created manually crafted lattices for
a subset of source words as references for seg-
mentation when translating into English, and then
learned the segmentation of the source words to
optimize the translation with respect to these ref-
erences. He showed that the parameters of the
model can be applied to similar languages when
translating into English. However, manually cre-
ating these lattices is time-consuming and requires
a bilingual person with some knowledge of the un-
derlying statistical machine translation system.
There have been some attempts to apply un-
supervised methods for tokenization in machine
translation (Chung and Gildea, 2009; Xu et al,
2008). The alignment model of Chung and
Gildea (2009) forces every source word to align
with a target word. Xu et al (2008) mod-
eled the source-to-null alignment as in the source
word to target word model. Their models are
special cases of our proposed model when the
source model2 is a unigram model. Like Xu et
al. (2008), we use Gibbs sampling for inference.
Chung and Gildea (2009) applied efficient dy-
namic programming-based variational inference
algorithms.
We benefit from existing unsupervised mono-
lingual segmentation. The source model uses the
nested Pitman-Yor model as described by Mochi-
hashi et al (2009). When sampling each potential
word boundary, our inference technique is a bilin-
gual extension of what is described by Goldwater
et al (2006) for monolingual segmentation.
Nonparametric models have received attention
in machine translation recently. For example,
DeNero et al (2008) proposed a hierarchical
Dirichlet process model to learn the weights of
phrase pairs to address the degeneration in phrase
extraction. Teh (2006) used a hierarchical Pitman-
Yor process as a smoothing method for language
models.
Recent work on multilingual language learning
successfully used nonparametric models for lan-
guage induction tasks such as grammar induction
(Snyder et al, 2009; Cohen et al, 2010), morpho-
logical segmentation (Goldwater et al, 2006; Sny-
der and Barzilay, 2008), and part-of-speech tag-
ging (Goldwater and Griffiths, 2007; Snyder et al,
2Note that ?source model? here means a model of source
text, not a source model in the noisy channel paradigm.
816
2008).
3 Models
We start with the generative process for a source
sentence and its alignment with a target sentence.
Then we describe individual models employed by
this generation scheme.
3.1 Generative Story
A source sentence is a sequence of word tokens,
and each word is either aligned or not aligned. We
focus only on the segmentation problem and not
reordering source words; therefore, the model will
not generate the order of the target word tokens.
A sentence pair and its alignment are captured by
four components:
? a sequence of words in the source sentence,
? a set of null-aligned source tokens,
? a set of null-aligned target tokens, and
? a set of (source word to target word) align-
ment pairs.
We will start with a high-level story of how the
segmentation of the source sentence and the align-
ment are generated.
1. A source language monolingual segmenta-
tion model generates the source sentence.
2. Generate alignments:
(a) Given the sequence of words of the
source sentence already generated in
step 1, the alignment model marks each
source word as either aligned or un-
aligned. If a source word is aligned, the
model also generates the target word.
(b) Unaligned target words are generated.
The model defines the joint probability of a seg-
mented source language sentence and its align-
ment. During inference, the two parts are cou-
pled, so that the alignment will influence which
segmentation is selected. However, there are sev-
eral advantages in breaking the generation process
into two steps.
First of all, in principle the model can incor-
porate any existing probabilistic monolingual seg-
mentation to generate the source sentence. For
example, the source model can be the nested
Pitman-Yor process as described by Mochihashi et
al. (2009), the minimum description length model
presented by Creutz and Lagus (2007), or some-
thing else. Also the source model can incorporate
linguistic knowledge from a rule-based or statisti-
cal morphological disambiguator.
The model generates the alignment after the
source sentence with word boundaries already
generated. Therefore, the alignment model can
be any existing word alignment model (Brown
et al, 1993; Vogel et al, 1996). Even though
the choices of source model or alignment model
can lead to different inference methods, the model
we propose here is highly extensible. Note that
we assume that the alignment consists of at most
one-to-one mappings between source and target
words, with null alignments possible on both
sides.
Another advantage of a separate source model
lies in the segmentation of an unseen test set. In
section 5 we will show how to apply the source
model distribution learned from training data to
find the best segmentation of an unseen test set.
Notation and Parameters
We will use bold font for a sequence or bags
of words and regular font for an individual word.
A source sentence s is a sequence of |s| words
si:
(
s1, . . . , s|s|
); the translation of sentence s is
the target sentence t of |t| words (t1, . . . , t|t|
).
In sentence s the list of unaligned words is snal
and the list of aligned source words is sal. In
the target sentence t the list of unaligned words
is tnal and the list of target words having one-
to-one alignment with source words sal is tal.
The alignment a of s and t is represented by
{?si, null? | si ? snal} ? {?si, tai? | si ? sal; tai ?
tal} ? {?null, tj? | tj ? tnal} where ai denotes
the index in t of the word aligned to si.
The probability of a sequence or a set is denoted
by P (.), probability at the word level is p (.). For
example, the probability of sentence s is P (s), the
probability of a word s is p (s), the probability
that the target word t aligns to an aligned source
817
word s is p (t |s).
A sentence pair and its alignment are generated
from the following models:
? The source model generates sentence s with
probability P (s).
? The source-to-null alignment model de-
cides independently for each word s
whether it is unaligned with probability
p (null | si) or aligned with probabil-
ity: 1 ? p (null | si). The probability
of this step, for all source words, is:
P (snal, sal | s) = ?si?snal p (null | si) ??
si?sal (1 ? p (null | si)) .
We will also refer to the source-to-null model
as the deletion model, since words in snal are
effectively deleted for the purposes of align-
ment.
? The source-to-target algnment model gen-
erates a bag of target words tal aligned
to the source words sal with probability:
P (tal |sal) = ?si?sal;tai?tal p (tai |si). Notethat we do not need to be concerned with
generating a explicitly, since we do not
model word order on the target side.
? The null-to-target algnment model gen-
erates the list of unaligned target words
tnal given aligned target words tal with
P (tnal |tal) as follows:
? Generate the number of unaligned tar-
get words |tnal| given the number of
aligned target words |tal| with probabil-
ity P (|tnal| | |tal|).
? Generate |tnal| unaligned words t ?
tnal independently, each with probabil-
ity p (t |null).
The resulting null-to-target proba-
bility is therefore: P (tnal | tal) =
P (|tnal| | |tal|)?t?tnal p (t |null) .
We also call the null-to-target model the in-
sertion model.
The above generation process defines the joint
probability of source sentence s and its alignment
a as follows:
P (s, a) = P (s)????
source model
? P (a | s)? ?? ?
alignment model
(1)
P (a | s) = P (tal |sal) ? P (tnal |tal) (2)
?
?
si?snal
p (null | si) ?
?
si?sal
(1 ? p (null | si))
3.2 Source Model
Our generative process provides the flexibility of
incorporating different monolingual models into
the probability distribution of a sentence pair.
In particular we use the existing state-of-the-art
nested Pitman-Yor n-gram language model as de-
scribed by Mochihashi et al (2009). The proba-
bility of s is given by
P (s) = P (|s|)
|s|?
i=1
p (si |si?n, . . . , si?1) (3)
where the n-gram probability is a hierarchical
Pitman-Yor language model using (n ? 1)-gram
as the base distribution.
At the unigram level, the model uses the base
distribution p (s) as the infinite-gram character-
level Pitman-Yor language model.
3.3 Modeling Null-Aligned Source Words
The probability that a source word aligns to null
p (null | s) is defined by a binomial distribution
with Beta prior Beta (?p, ? (1 ? p)), where ?
and p are model parameters. When p ? 0 and
? ? ? the probability p (null | s) converges to 0
forcing each source words align to a target word.
We fixed p = 0.1 and ? = 20 in our experiment.
Xu et al (2008) view the null word as another
target word, hence in their model the probability
that a source word aligns to null can only depend
on itself.
By modeling the source-to-null alignment sep-
arately, our model lets the distribution depend
on the word?s n-gram context as in the source
model. p (null | si?n, . . . , si) stands for the prob-
ability that the word si is not aligned given its con-
text (si?n, . . . , si?1).
The n-gram source-to-null distribution
p (null | si?n, . . . , si) is defined similarly to
818
p (null | si) definition above in which the base
distribution p now becomes the (n ? 1)-gram:
p (null | si?n+1, . . . , si).3
3.4 Source-Target Alignment Model
The probability p (t |s) that a target word t aligns
to a source word s is a Pitman-Yor process:
t | s ? PY (d, ?, p0 (t |s))
here d and ? are the input parameters, and
p0 (t |s) is the base distribution.
Let |s, ?| denote the number of times s is aligned
to any t in the corpus and let |s, t| denote the num-
ber of times s is aligned to t anywhere in the cor-
pus. And let ty(s) denote the number of different
target words t the word s is aligned to anywhere
in the corpus. In the Chinese Restaurant Process
metaphor, there is one restaurant for each source
word s, the s restaurant has ty(s) tables and total
|s, ?| customers; table t has |s, t| customers.
Then, at a given time in the generative process
for the corpus, we can write the probability that t
is generated by the word s as:
? if |s, t| > 0:
p (t |s) =
|s, t| ? d + [? + dty(s)]p0 (t |s)
|s, ?| + ?
? if |s, t| = 0:
p (t |s) = [? + dty(s)]p0 (t |s)|s, ?| + ?
For language pairs with similar character sets
such as English and French, words with similar
surface form are often translations of each other.
The base distribution can be defined based on
the edit distance between two words (Snyder and
Barzilay, 2008).
We are working with diverse language pairs
(Arabic-English and Chinese-English), so we
use the base distribution as the flat distribution
p0 (t |s) = 1T ; T is the number of distinct targetwords in the training set. In our experiment, the
model parameters are ? = 20 and d = .5.
3We also might have conditioned this decision on words
following si, since those have all been generated already at
this stage.
3.5 Modeling Null-Aligned Target Words
The null-aligned target words are modeled condi-
tioned on previously generated target words as:
P (tnal |tal) = P (|tnal| | |tal|)
?
t?tnal
p (t |null)
This model uses two probability distributions:
? the number of unaligned target words:
P (|tnal| | |tal|), and
? the probability that each word in tnal is gen-
erated by null: p (t |null).
We model the number of unaligned target
words similarly to the distribution in the IBM3
word alignment model (Brown et al, 1993).
IBM3 assumes that each aligned target words gen-
erates a null-aligned target word with probabil-
ity p0 and fails to generate a target word with
probability 1 ? p0. So the parameter p0 can
be used to control the number of unaligned tar-
get words. In our experiments, we fix p0 =
.05. Following this assumption, the probability of
|tnal| unaligned target words generated from |tal|
words is: P (|tnal| | |tal|) =
( |tal|
|tnal|
)
p|tnal|0 (1 ?
p0)|tal|?|tnal|.
The probability that a target word t aligns to
null, p (t |null), also has a Pitman-Yor process
prior. The base distribution of the model is similar
to the source-to-target model?s base distribution
which is the flat distribution over target words.
4 Inference
We have defined a probabilistic generative model
to describe how a corpus of alignments and seg-
mentations can be generated jointly. In this sec-
tion we discuss how to obtain the posterior distri-
butions of the missing alignments and segmenta-
tions given the training corpus, using Gibbs sam-
pling.
Suppose we are provided a morphological
disambiguator for the source language such as
MADA morphology tokenization toolkit (Sadat
and Habash, 2006) for Arabic.4 The morpho-
logical disambiguator segments a source word to
4MADA provides several segmentation schemes; among
them the MADA-D3 scheme seeks to separate all mor-
phemes of each word.
819
morphemes of smallest meaning-bearing units of
the source language. Therefore, a target word is
equivalent to one or several morphemes. Given
a morphological disambiguation toolkit, we use
its output to bias our inference by not consider-
ing word boundaries after every character but only
considering potential word boundaries as a subset
of the morpheme boundaries set. In this way, the
inference uses the morphological disambiguation
toolkit to limit its search space.
The inference starts with an initial segmenta-
tion of the source corpus and also its alignment
to the target corpus. The Gibbs sampler consid-
ers one potential word boundary at a time. There
are two hypotheses at any given boundary posi-
tion of a sentence pair (s, t): the merge hypothe-
sis stands for no word boundary and the resulting
source sentence smerge has a word s spanning over
the sample point; the split hypothesis indicates the
resulting source sentence ssplit has a word bound-
ary at the sample point separating two words s1s2.
Similar to Goldwater et al (2006) for monolingual
segmentation, the sampler randomly chooses the
boundary according to the relative probabilities of
the merge hypothesis and the split hypothesis.
The model consists of source and alignment
model variables; given the training corpora size of
a machine translation system, the number of vari-
ables is large. So if the Gibbs sampler samples
both source variables and alignment variables, the
inference requires many iterations until the sam-
pler mixes. Xu et al (2008) fixed this by repeat-
edly applying GIZA++ word alignment after each
sampling iteration through the training corpora.
Our inference technique is not precisely Gibbs
sampling. Rather than sampling the alignment or
attempting to collapse it out (by summing over
all possible alignments when calculating the rel-
ative probabilities of the merge and split hypothe-
ses), we seek the best alignment for each hypoth-
esis. In other words, for each hypothesis, we per-
form a local search for a high-probability align-
ment of the merged word or split words, given
the rest of alignment for the sentence. Up to one
word may be displaced and realigned. This ?local-
best? alignment is used to score the hypothesis,
and after sampling merge or split, we keep that
best alignment.
This inference technique is motivated by run-
time demands, but we do not yet know of a the-
oretical justification for combining random steps
with maximization over some variables. A more
complete analysis is left to future work.
5 Decoding for Unseen Test Sentences
Section 4 described how to get the model?s pos-
terior distribution and the segmentation and align-
ment of the training data under the model. We are
left with the problem of decoding or finding the
segmentation of test sentences where the transla-
tions are not available. This is needed when we
want to translate new sentences. Here, tokeniza-
tion is performed as a preprocessing step, decou-
pled from the subsequent translation steps.
The decoding step uses the model?s posterior
distribution for the training data to segment un-
seen source sentences. Because of the clear sep-
aration of the source model and the alignment
model, the source model distribution learned from
the Gibbs sampling directly represents the distri-
bution over the source language and can therefore
also handle the segmentation of unknown words
in new test sentences. Only the source model is
used in preprocessing.
The best segmentation s? of a string of charac-
ters c = (c1, . . . , c|c|
) according to the n-gram
source model is:
s? = argmax
s from c
p (|s|)
i=|s|?
i=1
p (si |si?n, . . . , si?1)
We use a stochastic finite-state machine for de-
coding. This is possible by composition of the fol-
lowing two finite state machines:
? Acceptor Ac. The string of characters c is
represented as an finite state acceptor ma-
chine where any path through the machine
represents an unweighted segmentation of c.
? Source model weighted finite state trans-
ducer Lc. Knight and Al-Onaizan (1998)
show how to build an n-gram language
model by a weighted finite state machine.
The states of the transducer are (n ? 1)-
gram history, the edges are words from the
language. The arc si coming from state
820
(si?n, . . . , si?1) to state (si?n+1, . . . , si) has
weight p (si |si?n, . . . , si?1).
The best segmentation s? is given as s? =
BestPath(Ac ? Lc).
6 Experiments
This section presents experimental results on
Arabic-English and Chinese-English translation
tasks using the proposed segmentation technique.
6.1 Arabic-English
As a training set we use the BTEC corpus dis-
tributed by the International Workshop on Spo-
ken Language Translation (IWSLT) (Matthias and
Chiori, 2005). The corpus is a collection of
conversation transcripts from the travel domain.
The ?Supplied Data? track consists of nearly 20K
Arabic-English sentence pairs. The development
set consists of 506 sentences from the IWSLT04
evaluation test set and the unseen set consists of
500 sentences from the IWSLT05 evaluation test
set. Both development set and test set have 16 ref-
erences per Arabic sentence.
6.2 Chinese-English
The training set for Chinese-English translation
task is also distributed by the IWSLT evaluation
campaign. It consists of 67K Chinese-English
sentence pairs. The development set and the test
set each have 489 Chinese sentences and each sen-
tence has 7 English references.
6.3 Results
We will report the translation results where the
preprocessing of the source text are our unigram,
bigram, and trigram source models and source-to-
null model.
The MCMC inference algorithm starts with an
initial segmentation of the source text into full
word forms. For Chinese, we use the original
word segmentation as distributed by IWSLT. To
get an initial alignment, we generate the IBM4
Viterbi alignments in both directions using the
GIZA++ toolkit (Och and Ney, 2003) and com-
bine them using the ?grow-diag-final-and? heuris-
tic. The output of combining GIZA++ align-
ment for a sentence pair is a sequence of si-tj
entries where i is an index of the source sen-
tence and j is an index of the target sentence.
As our model allows only one-to-one mappings
between the words in the source and target sen-
tences, we remove si-tj from the sequence if ei-
ther the source word si or target word tj is al-
ready in a previous entry of the combined align-
ment sequence. The resulting alignment is our ini-
tial alignment for the inference.
We also apply the MADA morphology seg-
mentation toolkit (Habash and Rambow, 2005) to
preprocess the Arabic corpus. We use the D3
scheme (each Arabic word is segmented into mor-
phemes in sequence [CONJ+ [PART+ [Al+ BASE
+PRON]]]), mark the morpheme boundaries, and
then combine the morphemes again to have words
in their original full word form. During inference,
we only sample over these morpheme boundaries
as potential word boundaries. In this way, we
limit the search space, allowing only segmenta-
tions consistent with MADA-D3.
The inference samples 150 iterations through
the whole training set and uses the posterior prob-
ability distribution from the last iteration for de-
coding. The decoding process is then applied
to the entire training set as well as to the devel-
opment and test sets to generate a consistent to-
kenization across all three data sets. We used
the OpenFST toolkit (Allauzen et al, 2007) for
finite-state machine implementation and opera-
tions. The output of the decoding is the pre-
processed data for translation. We use the open
source Moses phrase-based MT system (Koehn et
al., 2007) to test the impact of the preprocessing
technique on translation quality.5
6.3.1 Arabic-English Translation Results
We consider the Arabic-English setting. We
use two baselines: original full word form
and MADA-D3 tokenization scheme for Arabic-
English translation. Table 1 compares the trans-
lation results of our segmentation methods with
these baselines. Our segmentation method shows
improvement over the two baselines on both the
development and test sets. According to Sadat
and Habash (2006), the MADA-D3 scheme per-
5The Moses translation alignment is the output of
GIZA++, not from our MCMC inference.
821
Dev. Test
Original 59.21 54.00
MADA-D3 58.28 54.92
Unigram 59.44 56.18
Bigram 58.88 56.18
Trigram 58.76 56.82
Table 1: Arabic-English translation results
(BLEU).
forms best for their Arabic-English translation es-
pecially for small and moderate data sizes. In our
experiments, we see an improvement when using
the MADA-D3 preprocessing over using the orig-
inal Arabic corpus on the unseen test set, but not
on the development set.
The Gibbs sampler only samples on the mor-
phology boundary points of MADA-D3, so the
improvement resulting from our segmentation
technique does not come from removing unknown
words. It is due to a better matching between
the source and target sentences by integrating seg-
mentation and alignment. We therefore expect the
same impact on a larger training data set in future
experiments.
6.3.2 Chinese-English Translation Results
Dev. Test
Whole word 23.75 29.02
Character 23.39 27.74
Unigram 24.90 28.97
Trigram 23.98 28.20
Table 2: Chinese-English translation result in
BLEU score metric.
We next consider the Chinese-English setting.
The translation performance using our word seg-
mentation technique is shown in Table 2. There
are two baselines for Chinese-English translation:
(a) the source text in the full word form distributed
by the IWSLT evaluation and (b) no segmentation
of the source text, which is equivalent to interpret-
ing each Chinese character as a single word.
Taking development and test sets into account,
the best Chinese-English translation system re-
sults from our unigram model. It is significantly
better than other systems on the development set
and performs almost equally well with the IWSLT
segmentation on the test set. Note that the seg-
mentation distributed by IWSLT is a manual seg-
mentation for the translation task.
Chung and Gildea (2009) and Xu et al (2008)
also showed improvement over a simple mono-
lingual segmentation for Chinese-English trans-
lation. Our character-based translation result is
comparable to their monolingual segmentations.
Both trigram and unigram translation results out-
perform the character-based translation.
We also observe that there are no additional
gains for Chinese-English translation when using
a higher n-gram model. Our Gibbs sampler has
the advantage that the samples are guaranteed to
converge eventually to the model?s posterior dis-
tributions, but in each step the modification to the
current hypothesis is small and local. In itera-
tions 100?150, the average number of boundary
changes for the unigram model is 14K boundaries
versus only 1.5K boundary changes for the tri-
gram model. With 150 iterations, the inference
output of trigram model might not yet represent
its posterior distribution. We leave a more de-
tailed investigation of convergence behavior to fu-
ture work.
Conclusion and Future Work
We presented an unsupervised segmentation
method for machine translation and presented
experiments for Arabic-English and Chinese-
English translation tasks. The model can incor-
porate existing monolingual segmentation mod-
els and seeks to learn a segmenter appropriate for
a particular translation task (target language and
dataset).
Acknowledgements
We thank Kevin Gimpel for interesting discus-
sions and technical advice. We also thank the
anonymous reviewers for useful feedback. This
work was supported by DARPA Gale project,
NSF grants 0844507 and 0915187.
822
References
Allauzen, C., M. Riley, J. Schalkwyk, W. Skut, and
M. Mohri. 2007. OpenFst: A General and Efficient
Weighted Finite-State Transducer Library. In Pro-
ceedings of the CIAA 2007, volume 4783 of Lecture
Notes in Computer Science, pages 11?23. Springer.
http://www.openfst.org.
Brown, Peter F., Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Comput. Linguist., 19(2):263?
311.
Chung, T. and D. Gildea. 2009. Unsupervised Tok-
enization for Machine Translation. In Proceedings
of EMNLP 2009, pages 718?726, Singapore, Au-
gust. Association for Computational Linguistics.
Cohen, S. B., D. M. Blei, and N. A. Smith. 2010. Vari-
ational Inference for Adaptor Grammars. In Pro-
ceedings of NAACL-HLT, pages 564?572, June.
Creutz, Mathias and Krista Lagus. 2007. Unsu-
pervised Models for Morpheme Segmentation and
Morphology Learning. ACM Trans. Speech Lang.
Process., 4(1):1?34.
DeNero, J., A. Bouchard-Co?te?, and D. Klein. 2008.
Sampling Alignment Structure under a Bayesian
Translation Model. In Proceedings of EMNLP
2008, pages 314?323, Honolulu, Hawaii, October.
Association for Computational Linguistics.
Dyer, C. 2009. Using a Maximum Entropy model to
build segmentation lattices for MT. In Proceedings
of HLT 2009, pages 406?414, Boulder, Colorado,
June.
Goldwater, S. and T. L. Griffiths. 2007. A Fully
Bayesian Approach to Unsupervised Part-of-Speech
Tagging. In Proceedings of ACL.
Goldwater, S. and D. McClosky. 2005. Improving Sta-
tistical Machine Translation Through Morphologi-
cal Analysis. In Proc. of EMNLP.
Goldwater, S., T. L. Griffiths, and M. Johnson. 2006.
Contextual Dependencies in Unsupervised Word
Segmentation. In Proc. of COLING-ACL.
Habash, N. and O. Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging, and Morpholog-
ical Disambiguation in One Fell Swoop. In Proc. of
ACL.
Knight, K. and Y. Al-Onaizan. 1998. Translation
with Finite-State Devices. In Proceedings of AMTA,
pages 421?437.
Koehn, P., H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Proc.
of ACL (demo session).
Matthias, E. and H. Chiori. 2005. Overview of the
IWSLT 2005 Evaluation Campaign. In Proceedings
of IWSLT.
Mochihashi, D., T. Yamada, and N. Ueda. 2009.
Bayesian Unsupervised Word Segmentation with
Nested Pitman-Yor Language Modeling. In Pro-
ceedings of 47th ACL, pages 100?108, Suntec, Sin-
gapore, August.
Nie?en, S. and H. Ney. 2004. Statistical Machine
Translation with Scarce Resources Using Morpho-
Syntactic Information. Computational Linguistics,
30(2), June.
Och, F. and H. Ney. 2003. A Systematic Comparison
of Various Statistical Alignment Models. Computa-
tional Linguistics, 29(1).
Sadat, F. and N. Habash. 2006. Combination of Ara-
bic Preprocessing Schemes for Statistical Machine
Translation. In Proceedings of the ACL, pages 1?8.
Snyder, B. and R. Barzilay. 2008. Unsupervised Mul-
tilingual Learning for Morphological Segmentation.
In Proceedings of ACL-08: HLT, pages 737?745,
June.
Snyder, B., T. Naseem, J. Eisenstein, and R. Barzilay.
2008. Unsupervised Multilingual Learning for POS
Tagging. In Proceedings of EMNLP.
Snyder, B., T. Naseem, and R. Barzilay. 2009. Unsu-
pervised Multilingual Grammar Induction. In Pro-
ceedings of ACL-09, pages 73?81, August.
Teh, Y. W. 2006. A Hierarchical Bayesian Language
Model Based On Pitman-Yor Processes. In Pro-
ceedings of ACL, pages 985?992, July.
Vogel, S., H. Ney, and C. Tillmann. 1996. HMM-
Based Word Alignment in Statistical Translation. In
Proceedings of COLING, pages 836?841.
Xu, J., J. Gao, K. Toutanova, and H. Ney. 2008.
Bayesian Semi-Supervised Chinese Word Segmen-
tation for Statistical Machine Translation. In
Proceedings of (Coling 2008), pages 1017?1024,
Manchester, UK, August.
823
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1587?1596,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Integrating Phrase-based Reordering Features into a Chart-based
Decoder for Machine Translation
ThuyLinh Nguyen
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
thuylinh@cs.cmu.edu
Stephan Vogel
Qatar Computing Research Institute
Tornado Tower
Doha, Qatar
svogel@qf.org.qa
Abstract
Hiero translation models have two lim-
itations compared to phrase-based mod-
els: 1) Limited hypothesis space; 2) No
lexicalized reordering model. We pro-
pose an extension of Hiero called Phrasal-
Hiero to address Hiero?s second problem.
Phrasal-Hiero still has the same hypoth-
esis space as the original Hiero but in-
corporates a phrase-based distance cost
feature and lexicalized reodering features
into the chart decoder. The work consists
of two parts: 1) for each Hiero transla-
tion derivation, find its corresponding dis-
continuous phrase-based path. 2) Extend
the chart decoder to incorporate features
from the phrase-based path. We achieve
significant improvement over both Hiero
and phrase-based baselines for Arabic-
English, Chinese-English and German-
English translation.
1 Introduction
Phrase-based and tree-based translation model are
the two main streams in state-of-the-art machine
translation. The tree-based translation model, by
using a synchronous context-free grammar for-
malism, can capture longer reordering between
source and target language. Yet, tree-based trans-
lation often underperforms phrase-based transla-
tion in language pairs with short range reordering
such as Arabic-English translation (Zollmann et
al., 2008; Birch et al, 2009).
We follow Koehn et al (2003) for our phrase-
based system and Chiang (2005) for our Hiero sys-
tem. In both systems, the translation of a source
sentence f is the target sentence e? that maximizes
a linear combination of features and weights:
?e?,a?? = argmax
?e,a??H(f)
?
m?M
?mhm (e, f ,a) . (1)
where
? a is a translation path of f . In the phrase-
based system, aph represents a segmentation
of e and f and a correspondance of phrases.
In the Hiero system, atr is a derivation of a
parallel parse tree of f and e, each nontermi-
nal representing a rule in the derivation.
? H (f) is the hypothesis space of the sentence
f . We denote Hph (f) as the phrase-based
hypothesis space of f and Htr (f) as its tree-
based hypothesis space. Galley and Manning
(2010) point out that due to the hard con-
straints of rule combination, the tree-based
system does not have the same excessive hy-
pothesis space as the phrase-based system.
? M is the set of feature indexes used in the
decoder. Many features are shared between
phrase-based and tree-based systems includ-
ing language model, word count, and trans-
lation model features. Phrase-based systems
often use a lexical reordering model in addi-
tion to the distance cost feature.
The biggest difference in a Hiero system and a
phrase-based system is in how the reordering is
modeled. In the Hiero system, the reordering de-
cision is encoded in weighted translation rules, de-
termined by nonterminal mappings. For example,
the rule X ? ne X1 pas ; not X1 : w indicates
the translation of the phrase between ne and pas to
be after the English word not with scorew. During
decoding, the system parses the source sentence
and synchronously generates the target output.
To achieve reordering, the phrase-based sys-
tem translates source phrases out of order. A re-
ordering distance limit is imposed to avoid search
space explosion. Most phrase-based systems are
equipped with a distance reordering cost feature
to tune the system towards the right amount of
reordering, but then also a lexicalized reordering
1587
model to model the direction of adjacent source
phrases reordering as either monotone, swap or
discontinuous.
There are two reasons to explain the shortcom-
ings of the current Hiero system:
1. A limited hypothesis space because the syn-
chronous context-free grammar is not appli-
cable to non-projective dependencies.
2. It does not have the expressive lexicalized re-
ordering model and distance cost features of
the phrase-based system.
When comparing phrase-based and Hiero trans-
lation models, most of previous work on tree-
based translation addresses its limited hypothesis
space problem. Huck et al (2012) add new rules
into the Hiero system, Carreras and Collins (2009)
apply the tree adjoining grammar formalism to al-
low highly flexible reordering. On the other hand,
the Hiero model has the advantage of capturing
long distance and structure reordering. Galley
and Manning (2010) extend phrase-based trans-
lation by allowing gaps within phrases such as
?ne . . . pas, not?, so the decoder still has the dis-
criminative reordering features of phrase-based,
but also uses on average longer phrases. How-
ever, these phrase pairs with gaps do not capture
structure reordering as do Hiero rules with non-
terminal mappings. For example, the rule X ?
ne X1 pas ; not X1 explicitly places the transla-
tion of the phrase between ne and pas behind the
English word not through nonterminal X1. This
is important for language pairs with strict reorder-
ing. In our Chinese-English experiment, the Hiero
system still outperforms the discontinuous phrase-
based system.
We address the second problem of the origi-
nal Hiero decoder by mapping Hiero translation
derivations to corresponding phrase-based paths,
which not only have the same output but also pre-
serve structure distortion of the Hiero translation.
We then include phrase-based features into the Hi-
ero decoder.
A phrase-based translation path is the sequence
of phrase-pairs, whose source sides cover the
source sentence and whose target sides generate
the target sentence from left to right. If we look at
the leaves of a Hiero derivation tree, the lexicals
also form a segmentation of the source and target
sentence, thus also form a discontinuous phrase-
based translation path. As an example, let us look
at the translation of the French sentence je ne parle
pas le franc?aise into English i don?t speak french
in Figure 1. The Hiero decoder translates the sen-
tence using a derivation of three rules:
? r1 = X? parle ; speak.
? r2 = X? ne X1 pas ; don?t X1.
? r3 = X?
Je X1 le Franc?ais ; I X1 french.
From this Hiero derivation, we have a seg-
mentation of the sentence pairs into phrase
pairs according to the word alignments, as
shown on the left side of Figure 1. Or-
dering these phrase pairs according the word
sequence on the target side, shown on the
right side of Figure 1, we have a phrase-
based translation path consisting of four phrase
pairs: (je, i) , (ne . . . pas, not) , (parle, speak) ,
(lefrancaise, french) that has the same output
as the Hiero system. Note that even though the
Hiero decoder uses a composition of three rules,
the corresponding phrase-based path consists of
four phrase pairs. We name this new variant of the
Hiero decoder, which uses phrase-based features,
Phrasal-Hiero.
Our Phrasal-Hiero addresses the shortcomming
of the original Hiero system by incorporating
phrase-based features. Let us revisit machine
translation?s loglinear model combination of fea-
tures in equation 1. We denote ph(a) as the corre-
sponding phrase-based path of a Hiero derivation
a, and MPh\H as the indexes of phrase-based fea-
tures currently not applicable to the Hiero decoder.
Our Phrasal-Hiero decoder seeks to find the trans-
lation, which optimizes:
?e?,a?? = argmax
?e,a??Htr(f)
( ?
m?MH
?mhm (e, f ,a) +
+
?
m??MPh\H
?m?hm? (e, f , ph(a))
)
.
We focus on improving the modelling of re-
ordering within Hiero and include discriminative
reordering features (Tillmann, 2004) and a dis-
tance cost feature, both of which are not modeled
in the original Hiero system. Chiang et al (2008)
added structure distortion features into their de-
coder and showed improvements in their Chinese-
English experiment. To our knowledge, Phrasal-
Hiero is the first system, which directly integrates
phrase-based and Hiero features into one model.
1588
Figure 1: Example of French-English Hiero Translation on the left and its corresponding discontinuous
phrase-based translation on the right.
Rules Alignments Phrase pairs & nonterminals
r1 = X? parle ; speak. 0-0 (parle ; speak)
r2 = X? ne X1 pas ; don?t X1. 0-0 1-1 2-0 (ne . . . pas ; don?t) ; X1
r3 = X? Je X1 le Francais ; I X1 French 0-0 1-1 3-2 (Je ; I) ; X1 ; (le Francais; french)
r4 = X? je X1 le X2 ; i X1 X2 0-0 1-1 3-2 Not Applicable
Table 1: Rules and their sequences of phrase pairs and nonterminals
Previous work has attempted to weaken the con-
text free assumption of the synchronous context
free grammar formalism, for example using syn-
tactic non-terminals (Zollmann and Venugopal,
2006). Our approach can be viewed as applying
soft context constraint to make the probability of
substituting a nonterminal by a subtree depending
on the corresponding phrase-based reordering fea-
tures.
In the next section, we explain the model in de-
tail.
2 Phrasal-Hiero Model
Phrasal-Hiero maps a Hiero derivation into a dis-
continuous phrase-based translation path by the
following two steps:
1. Training: Represent each rule as a sequence
of phrase pairs and nonterminals.
2. Decoding: Use the rules? sequences of
phrase pairs and nonterminals to find the
corresponding phrase-based path of a Hiero
derivation and calculate its feature scores.
2.1 Map Rule to A Sequence of Phrase Pairs
and Nonterminals
We segment the rules? lexical items into phrase
pairs. These phrase pairs will be part of the phrase-
based translation path in the decoding step. The
rules? nonterminals are also preserved in the se-
quence, during the decoding they will be substi-
tuted by other rules? phrase pairs. We now explain
how to map a rule to a sequence of phrase pairs
and nonterminals.
Let r = X ?
s0X1s1 . . . Xksk ; t0X?(1)t1 . . . X?(k)tk be a rule
of k nonterminals, ?(.) defines the sequence of
nonterminals on the target. si or ti , i = 0 . . . k
are phrases between nonterminals, they can be
empty because nonterminals can be at the border
of the rule or two nonterminals are adjacent. For
example the rule X ? ne X1 pas ; not X1
has k = 1, s0 = ne, s1 = pas, t0 = not, t1 is
an empty phrase because the target X1 is at the
rightmost position.
Phrasal-Hiero retains both nonterminals and
lexical alignments of Hiero rules instead of only
nonterminal mappings as in (Chiang, 2005). A
1589
rule?s lexical alignment is the most frequent one
in the training data. We use the lexical alignments
of a rule to decide how source phrases and tar-
get phrases are connected. In the rule r, a source
phrase si is connected to a target phrase ti? if at
least one word in si aligns to a target word in ti? . In
the rule X? Je X1 le Franc?ais ; I X1 french
extract from sentence pair in Figure 1, the phrase
le Franc?ais connects to the phrase french because
the French word Franc?ais aligns with the English
word french even though le is unaligned.
We then group the source phrases and target
phrases into phrase pairs such that only phrases
that are connected to each other are in the same
phrase pair. So phrase pairs still preserve the lexi-
cal dependency of the rule. Phrase pairs and non-
terminals are then ordered according to the target
side of the rule. Table 1 shows an example of rules,
alignments and their sequences of phrase pairs and
nonterminals on the last column.
Figure 2: Alignment of a sentence pair.
There are Hiero rules in which one of its source
phrases or target phrases is not aligned. For exam-
ple in the rule r4 = X ? je X1 le X2 ; i X1 X2
extracted from the sentence pair in Figure 2, the
phrase le is not aligned. In our Arabic-English
experiment, rules without nonaligned phrases ac-
count for only 48.54% of the total rules. We com-
pared the baseline Hiero translation from the full
set of rules and the translation from only rules
without nonaligned phrases. The later translation
is faster and Table 2 1 shows that it outperforms
the translation with the whole set of rules. We
therefore decided to not use rules with nonaligned
phrases in Phrasal-Hiero.
It is important to note that there are different
ways to use all the rules and map rules with un-
aligned phrases into a sequence of phrase pairs.
1The dataset and experiment setting description are in sec-
tion 4.
Test set MT04 MT05 MT09
All rules 48.17 47.85 42.37
Phrasal Hiero 48.52 47.78 42.8
Table 2: Arabic-English pilot experiment. Com-
pare BLEU scores of translation using all ex-
tracted rules (the first row) and translation using
only rules without nonaligned subphrases (the sec-
ond row).
For example, adding these unaligned phrases to
the previous phrase pair i.e. the rule r4 has one dis-
continuous phrase pair (je . . . le, i) or treat these
unaligned phrases as deletion/insertion phrases.
We started the work with Arabic-English transla-
tion and decided not to use rules with nonaligned
phrases in Phrasal-Hiero. In the experiment sec-
tion, we will discuss the impact of removing
rules with nonaligned sub-phrases in our German-
English and Chinese-English experiments.
2.2 Training: Lexicalized Reordering Table
Phrasal-Hiero needs a phrase-based lexicalized re-
ordering table to calculate the features. The lexi-
calized reordering table could be from a discontin-
uous phrase-based system. To guarantee the lexi-
calized reordering table to cover all phrase pairs
of the rule table, we extract phrase-pairs and their
reordering directions during rule extraction.
Let (s, t) be a sentence pair in the training data
and r = X? s0X1s1 . . . Xksk ; t0X1t1 . . . Xktk
be a rule extracted from the sentence. The lex-
ical phrase pair corresponding to the rule r is
ph = (s0 . . . s1 . . . sk, t0 . . . t1 . . . tk), with non-
terminals are replaced by the gaps. Because the
nonterminal could be at the border of the rule, the
lexical phrase pair might have smaller coverage
than the rule. For example, the training sentence
pair in Figure 2 generates the rule r2 = X ?
ne X1 pas ; don?t X1 spanning (1 . . . 3, 1 . . . 2)
but its lexical phrase pair (ne . . . pas, not) only
spans (1 . . . 3, 1 . . . 1).
Also, two different rules can have the same
lexical phrase pairs. In Phrasal-Hiero, each lex-
ical phrase pair is only generated once for a
sentence. Look at the example of the train-
ing sentence pair in Figure 2, the rule X ?
je ; I spanning (0 . . . 1, 0 . . . 1) and the rule X ?
je X1 ; I X1 spanning (0 . . . 3, 0 . . . 2) are both
sharing the same lexical phrase pair (je, i) span-
ning (0 . . . 1, 0 . . . 1). But Phrasal-Hiero only gen-
1590
erates (je, i) once for the sentence. Phrase pairs
are generated together with phrase-based reorder-
ing orientations to build lexicalized reordering ta-
ble.
3 Decoding
Chiang (2007) applied bottom up chart parsing to
parse the source sentence and project on the tar-
get side for the best translation. Each chart cell
[X, i, j, r] indicates a subtree with rule r at the root
covers the translation of the i-th word upto the j-th
word of the source sentence. We extend the chart
parsing, mapping the subtree to the equivalent dis-
continuous phrase-based path and includes phrase-
based features to the log-linear model.
In Phrasal-Hiero, each chart cell [X, i, j, r] also
stores the first phrase pair and the last phrase pair
of the phrase-based translation path covered the i-
th to the j-th word of the source sentence. These
two phrase pairs are the back pointers to calcu-
late reordering features of later larger spans. Be-
cause the distance cost feature and phrase-based
discriminative reordering feature calculation are
both only required the source coverage of two ad-
jacent phrase pairs, we explain here the distance
cost calculation.
We will again use three rules r1, r2, r3 in Ta-
ble 1 and the translation je ne parle pas le franc?ais
into I don?t speak French to present the technique.
Table 3 shows the distance cost calculation.
First, when the rule r has only terminals, the
rule?s sequence of phrase pairs and nonterminals
consists of only a phrase pair. No calculation is
needed, the first phrase pair and the last phrase
pair are the same. The chart cell X1 : 2 . . . 2 in
Table 3 shows the translation with the rule r1 =
X ? parle ; speak. The first phrase pair and the
last phrase pair point to the phrase (parle, speak)
spanning 2 . . . 2 of the source sentence.
When the translation rule?s right hand side has
nonterminals, the nonterminals in the sequence
belong to smaller chart cells that we already found
phrase-based paths and calculated their features
before. The decoder then substitute these paths
into the rule?s sequence of phrase pairs and non-
terminals to form the complete path for the current
span.
We now demonstrate finding the phrase based
path and calculate distance cost of the chart
cell X2 spanning 1 . . . 3. The next phrase pair
of (ne . . . pas, don?t) is the first phrase pair
of the chart cell X1 which is (parle, speak).
The distance cost of these two phrase pairs ac-
cording to discontinuous phrase-based model is
|2? 3? 1| = 2. The distance cost of the
whole chart cell X2 also includes the cost of the
translation path covered by chart cell X1 which
is 0, therefore the distance cost for X2 is 2 +
dist(X1) = 2. We then update the first phrase
pair and the last phrase pair of cell X2. The first
phrase pair of X2 is (ne . . . pas, don?t), the last
phrase pair is also the last phrase pair of cell X1
which is (parle, speak).
Similarly, finding the phrase-based path and
calculate its distortion features in the chart cell
X3 include calculate the feature values for mov-
ing from the phrase pair (je, I) to the first
phrase pair of chart cell X2 and also from last
phrase pair of chart cell X2 to the phrase pair
(le franc?aise, french).
4 Experiment Results
In all experiments we use phrase-orientation lex-
icalized reordering (Galley and Manning, 2008)2
which models monotone, swap, discontinuous
orientations from both reordering with previous
phrase pair and with the next phrase pair. There
are total six features in lexicalized reordering
model.
We will report the impact of integrating phrase-
based features into Hiero systems for three lan-
guage pairs: Arabic-English, Chinese-English and
German-English.
4.1 System Setup
We are using the following three baselines:
? Phrase-based without lexicalized reodering
features. (PB+nolex)
? Phrase-based with lexicalized reordering fea-
tures.(PB+lex)
? Hiero system with all rules extracted from
training data. (Hiero)
We use Moses phrase-based and chart decoder
(Koehn et al, 2007) for the baselines. The score
difference between PB+nolex and PB+lex results
indicates the impact of lexicalized reordering fea-
tures on phrase-based system. In Phrasal-Hiero we
2Galley and Manning (2008) introduce three orientation
models for lexicalized reordering: word-based, phrase-based
and hierarchical orientation model. We apply phrase-based
orientation in all experiment using lexicalized reordering.
1591
Chart Cell Rule?s phrase pairs & NTs Distance First Phrase Pair Last Phrase Pair
X1 : 2 . . . 2 (parle, speak) ? 2 . . . 2 (parle, speak)
X2 : 1 . . . 3 (ne . . . pas, don?t) ; X1 2 + dist (X1) 1 . . . 3 2 . . . 2 (parle, speak)= 2 (ne . . . pas, don?t)
X3 : 0 . . . 5 (Je ; I) ; X2 ; 0 + dist (X2) 0 . . . 0 (je, I) 4 . . . 5(le Franc?ais; french) +1 = 3 (le Franc?ais; french)
Table 3: Phrasal-Hiero Decoding Example: Calculate distance cost feature for the translation in Figure 1.
will compare if these improvements still carry on
into Hiero systems.
The original Hiero system with all rules ex-
tracted from training data (Hiero) is the most rele-
vant baseline. We will evaluate the difference be-
tween this Hiero baseline and our Phrasal-Hiero.
To implement Phrasal-Hiero, we extented
Moses chart decoder (Koehn et al, 2007) to in-
clude distance-based reordering as well as the lex-
icalized phrase orientation reordering model. We
will report the following results for Phrasal-Hiero:
? Hiero translation results on the subset of rules
without unaligned phrases. (we denote this in
the table scores as P.H.)
? Phrasal-Hiero with phrase-based distance
cost feature (P.H.+dist).
? Phrasal-Hiero with phrase-based lexicalized
reordering features(P.H.+lex).
? Phrasal-Hiero with distance cost and lexical-
ized reordering features(P.H.+dist+lex).
4.2 Arabic-English Results
The Arabic-English system was trained from
264K sentence pairs with true case English. The
Arabic is in ATB morphology format. The lan-
guage model is the interpolation of 5-gram lan-
guage models built from news corpora of the NIST
2012 evaluation. We tuned the parameters on
the MT06 NIST test set (1664 sentences) and re-
port the BLEU scores on three unseen test sets:
MT04 (1353 sentences), MT05 (1056 sentences)
and MT09 (1313 sentences). All test sets have four
references per each sentence.
The results are in Table 4. The three
rows in the first block are the baseline scores.
Phrase-based with lexicalized reordering fea-
tures(PB+lex) shows significant improvement on
all test sets over the simple phrase-based system
without lexicalized reordering (PB+nolex). On av-
erage the improvement is 1.07 BLEU score (45.66
MT04 MT05 MT09 Avg.
PB+nolex 47.40 46.83 42.75 45.66
PB+lex 48.62 48.07 43.51 46.73
Hiero 48.17 47.85 42.37 46.13
P.H. 48.52 47.78 42.80 46.37(48.54% rules)
P.H.+dist 48.46 47.92 42.62 46.33
P.H. +lex 48.70 48.59 43.84 47.04
P.H +lex+dist 49.35 49.07 43.40 47.27
Improv. over 0.73 1.00 0.34 0.54PB+lex
Improv. over 0.83 1.29 1.04 0.90P.H.
Improv. over 1.18 1.22 1.47 1.14Hiero
Table 4: Arabic-English true case translation
scores in BLEU metric. The three rows in the first
block are the baseline scores. The next four rows
in the second block are Phrasal-Hiero scores, the
best scores are in boldface. The three rows in the
last block are the Phrasal-Hiero improvements.
versus 46.73). We make the same observation as
Zollmann et al (2008), i.e, that the Hiero baseline
system underperforms compared to the phrase-
based system with lexicalized phrase-based re-
ordering for Arabic-English in all test sets, on av-
erage by about 0.60 BLEU points (46.13 versus
46.73). This is because Arabic language has rel-
ative free reordering, but mostly short distance,
which is better captured by discriminative reorder-
ing features.
The next four rows in the second block of Ta-
ble 4 show Phrasal-Hiero results. The P.H. line is
the result of Hiero experiment on only a subset of
rules without nonaligned phrases. As mentioned
in section 2.1, Phrasal-Hiero only uses 48.54% of
the rules but achieves as good or even better per-
formance (on average 0.24 BLEU points better)
compared to the original Hiero system using the
full set of rules.
We do not benefit from adding only the
1592
distance-based reordering feature (P.H+dist) to the
Arabic-English experiment but get significant im-
provements when adding the six features of the
lexicalized reordering (P.H+lex). Table 4 shows
that the P.H.+lex system gains on average 0.67
BLEU points (47.04 versus 46.37). Even though
the baseline Hiero underperforms phrase-based
system with lexicalized reordering(P.B+lex), the
P.H.+lex system already outperforms P.B+lex in
all test sets (on average 47.04 versus 46.73).
Adding both distance cost and lexicalized re-
ordering features (P.H.+dist+lex) performs the
best. On average P.H.+dist+lex improves 0.90
BLEU points over P.H. without new phrase-based
features and 1.14 BLEU score over the base-
line Hiero system. Note that Hiero rules already
have lexical context in the reordering, but adding
phrase-based lexicalized reordering features to the
system still gives us about as much improvement
as the phrase-based system gets from lexicalized
reordering features, here 1.07 BLEU points. And
our best Phrasal-Hiero significantly improves over
the best phrase-based baseline by 0.54 BLEU
points. This shows that the underperformance of
the Hiero system is due to its lack of lexicalized
reordering features rather than a limited hypothe-
sis space.
4.3 Chinese-English Results
The Chinese-English system was trained on FBIS
corpora of 384K sentence pairs, the English cor-
pus is lower case. The language model is the tri-
gram SRI language model built from Xinhua cor-
pus of 180 millions words. We tuned the parame-
ters on MT06 NIST test set of 1664 sentences and
report the results of MT04, MT05 and MT08 un-
seen test sets. The results are in Table 5.
We also make the same observation as Zoll-
mann et al (2008) on the baselines for Chinese-
English translation. Even though the phrase-
based system benefits from lexicalized reordering,
PB+lex on average outperforms PB+nolex by 1.16
BLEU points (25.87 versus 27.03), it is the Hiero
system that has the best baseline scores across all
test sets, with and average of 27.70 BLEU points.
Phrasal Hiero scores are given in the second
block of Table 5. It uses 84.19% of the total train-
ing rules, but unlike the Arabic-English system,
using a subset of the rules costs Phrasal-Hiero on
all test sets and on average it loses 0.49 BLEU
points (27.21 versus 27.70). Similar to Chiang
MT04 MT05 MT08 Avg.
PB+nolex 29.99 26.4 21.23 25.87
PB+lex 31.03 27.57 22.41 27.03
Hiero 32.49 28.06 22.57 27.70
P.H. 31.83 27.66 22.16 27.21(84.19% rules)
P.H.+dist 32.18 28.25 22.46 27.63
P.H.+lex 32.55 28.51 23.08 28.05
P.H+lex+dist 33.06 28.78 23.23 28.35
Improv. over 2.03 1.21 0.82 1.32PB+lex
Improv. over 1.23 1.12 1.07 1.14P.H.
Improv. over 0.57 0.72 0.66 0.65Hiero
Table 5: Chinese-English lower case translation
scores in BLEU metric.
et al (2008) in their Chinese-English experiment,
we benefit by adding the distance cost feature.
PH.+dist outperforms P.H. on all test sets. We
have better improvements when adding the six fea-
tures of the lexicalized reordering model: P.H.+lex
on average has 28.05 BLEU points, i.e. gains
0.84 over P.H.. The P.H.+lex system is even better
than the best Hiero baseline using the whole set of
rules.
We again get the best translation when adding
both the distance cost feature and the lexicalized
reordering features. The P.H+dist+lex has the best
score across all the test sets and on average gains
1.14 BLEU points over P.H. So adding phrase-
based features to the Hiero system yields nearly
the same improvement as adding lexicalized re-
ordering features to the phrase-based system. This
shows that a strong Chinese-English Hiero system
still benefits from phrase-based features. Further
more, the P.H+dist+lex also outperforms the Hi-
ero baseline using all rules from training data.
4.4 German-English Results
We next consider German-English translation.
The systems were trained on 1.8 million sentence
pairs using the Europarl corpora. The language
model is three-gram SRILM trained from the tar-
get side of the training corpora. We use WMT
2010 (2489 sentences) as development set and
report scores on WMT 2008 (2051 sentences),
WMT 2009 (2525 sentences), WMT 2011 (3003
sentences). All test sets have one reference per
test sentence. The results are in Table 6.
1593
WMT test 08 09 11 Avg.
PB+nolex 17.46 17.38 16.76 17.20
PB+lex 18.16 17.85 17.18 17.73
Hiero 18.20 18.23 17.46 17.96
P.H. 18.24 18.15 17.39 17.92(80.54% rules)
P.H. +dist 18.19 17.97 17.41 17.85
P.H. +lex 18.59 18.46 17.69 18.24
P.H.+lex+dist 18.70 18.53 17.81 18.34
Improv. over 0.54 0.68 0.63 0.61PB+lex
Improv. over 0.46 0.38 0.42 0.42P.H.
Improv. over 0.50 0.30 0.35 0.38Hiero
Table 6: German-English lower case translation
scores in BLEU metric.
The Hiero baseline performs on average 0.26
BLEU points better than the phrase-based sys-
tem with lexicalized reordering features (PB+lex).
The hrasal-Hiero system used 80.54% of the total
training rules, but on average the P.H. system has
the same performance as the Hiero system using
all the rules extracted from training data. Similar
to the Arabic-English experiment, Phrasal-Hiero
does not benefit from adding the distance cost fea-
ture. We do, however, see improvements on all
test sets when adding lexicalized reordering fea-
tures. On average the P.H.+lex results are 0.32
BLEU points higher than the P.H. results. The
best scores are achieved with P.H+lex+dist. The
German-English translations on average gain 0.38
BLEU score by adding both distance cost and dis-
criminative reordering features.
4.5 Impact of segment rules into phrase pairs
Phrasal Hiero is the first system using rules? lexi-
cal alignments. If lexical alignments are not avail-
able, we can not divide the rules? lexicals into
phrase pairs without losing their dependancies. An
alternative approach would be combining all lex-
icals of a rule into one phrase pair. We run an
addition experiment for this approach on Arabic-
English dataset. Table 7 shows the examples rules
and its new sequence of nonterminals and phrase
pairs. The rules r1 and r2 have the same se-
quences as in Table 1. Without segment rules into
phrase pairs, the rule r3 has only one phrase pair:
ph = (Je . . . le Francaise ; I . . . french) and
ph is repeated twice in r3?s sequence of phrase
pairs and nonterminals. The new experiment uses
the complete set of rules so the rule r4 is included.
According to the new sequence of phrase pairs
and nonterminals, during decoding the rule r3 has
discontinous translation directions on both from
phrase pair ph to the nonterminal X1 and from
X1 to ph. But using lexical alignment and divide
the rule into phrase pairs as in section 2.1 , the
sequence preserves the translation order of r3 as
two monotone translations from (je; I) to X1 and
from X1 to (le Francaise ; french).
Avg
Hiero 46.13
Hiero+lex 46.45 ( +0.32)(no lex. alignments)
P.H 46.37
P.H.+lex 47.04 (+0.67)(with lex. alignments)
Table 8: Average of Arabic-English translation
scores in BLEU metric. Compare the improve-
ment of using rules? lexical alignments (2nd
block) and not using rules? lexical alignments (1st
block).
Table 8 compares the two experiments results.
The additional experiment is denoted as Hiero+lex
in the table. The first block shows an improvement
of 0.32 BLEU score when adding discriminated
reordering features on Hiero (using the whole set
of rules and no rule segmentation). The second
block is the impact of adding discriminated re-
ordering features on Phrasal Hiero (using a sub-
set of rules and segment rules into phrase pairs).
Here the improvement of P.H+lex over P.H is 0.67
BLEU score. It shows the benefit of segment rules
into phrase pairs.
4.6 Rules without unaligned phrases
A-E C-E G-E
Hiero 46.13 27.70 17.96
P.H. 46.36 27.21 17.92
%Rules used 48.54% 84.19% 80.54%
P.H.+lex+dist 47.27 28.35 18.34
Table 9: The impact of using only rules without
nonaligned phrases on Phrasal-Hiero results.
Table 9 summarizes the impact of using only
rules without nonaligned phrases on Phrasal-
1594
Rules Phrase pairs & nonterminals
r1 = X? parle ; speak. (parle ; speak)
r2 = X? ne X1 pas ; don?t X1. (ne . . . pas ; don?t) ; X1
r3 = X? Je X1 le Francais ; I X1 French (Je . . . le Francais ; I . . . french) ; X1 ;
(Je . . . le Francais ; I . . . french)
r4 = X? je X1 le X2 ; i X1 X2 (je . . . le ; i) ; X1 ; X2
Table 7: Example of translation rules and their sequences of phrase pairs and nonterminals when lexical
alignments are not available.
Hiero. Using only rules without nonaligned
phrases can get the same performance with trans-
lation with full set of rules for Arabic-English and
German-English experiments but underperforms
for the Chinese-English system. We suggest the
difference might come from the linguistic diver-
gences of source and target languages.
Phrasal Hiero includes all lexical rules (rules
without nonterminal) therefore it still has the same
lexical coverage as the original Hiero system.
In the Arabic-English system, the Arabic is in
ATB format, therefore most English words should
have alignments in the ATB source, rules with
nonaligned phrases could be the results of bad
alignments or non-informative rules, therefore we
could have better performance by using a subset of
rules in Phrasal-Hiero.
As Chinese and English are highly divergent,
we expect many phrases in one language correctly
unaligned in the other language. So leaving out
the rules with nonaligned phrases could degrade
the system. Even though the current Phrasal-Hiero
with extra phrase-based features outperforms the
Hiero baseline, future work for Phrasal-Hiero will
focus on including all rules extracted from training
corpora.
4.7 Discontinuous Phrase-Based
C-E G-E
PB+lex 27.03 17.73
PB+lex+gap 27.11 17.55
Hiero 27.70 17.96
P.H.+lex+dist 28.35 18.34
Table 10: Comparing Phrasal-Hiero with transla-
tion with gap for Chinese-English and German-
English. The numbers are average BLEU scores
of all test sets.
We compare Phrasal-Hiero with a discontinu-
ous phrase-based system introduced by Galley and
Manning (2010) for Chinese-English and German-
English system. Table 10 shows the average re-
sults. We used Phrasal decoder (Cer et al, 2010)
for phrase-based with gaps (PB+lex+gap) results.
While we do not focus on the differences in the
toolkits, our Phrasal-Hiero still outperforms the
phrase-based with gaps experiments.
Conclusion
We have presented a technique to combine phrase-
based features and tree-based features into one
model. Adding a distance cost feature, we only
get better translation for Chinese-English transla-
tion. Phrasal-Hiero benefits from adding discrim-
inative reodering features in all experiment. We
achieved the best result when adding both distance
cost and lexicalized reordering features. Phrasal-
Hiero currently uses only a subset of rules from
training data. A future work on the model can in-
clude complete rule sets together with word inser-
tion/deletion features for nonaligned phrases.
References
A. Birch, P. Blunsom, and M. Osborne. 2009. A
Quantitative Analysis of Reordering Phenomena. In
StatMT ?09: Proceedings of the Fourth Workshop on
Statistical Machine Translation, pages 197?205.
X. Carreras and M. Collins. 2009. Non-Projective
Parsing for Statistical Machine Translation. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 1 -
Volume 1, EMNLP ?09, pages 200?209.
D. Cer, M. Galley, D. Jurafsky, and C. Manning. 2010.
Phrasal: A Statistical Machine Translation Toolkit
for Exploring New Model Features. In Proceedings
of the NAACL HLT 2010 Demonstration Session,
pages 9?12. Association for Computational Linguis-
tics, June.
D. Chiang, Y. Marton, and P. Resnik. 2008. Online
Large-Margin Training of Syntactic and Structural
Translation Features. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
1595
Processing, pages 224?233. Association for Com-
putational Linguistics.
D. Chiang. 2005. A Hierarchical Phrase-Based Model
for Statistical Machine Translation. In Proc. of ACL.
D. Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
M. Galley and C. Manning. 2008. A Simple and Effec-
tive Hierarchical Phrase Reordering Model. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 847?
855, Honolulu, Hawaii, October.
M. Galley and C. D. Manning. 2010. Accurate Non-
Hierarchical Phrase-Based Translation. In Proceed-
ings of NAACL-HLT, pages 966?974.
M. Huck, S. Peitz, M. Freitag, and H. Ney. 2012. Dis-
criminative Reordering Extensions for Hierarchical
Phrase-Based Machine Translation. In EAMT, pages
313?320.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
Phrase-Based Translation. In Proc. of HLT-NAACL,
pages 127?133.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In ACL demon-
stration session.
C. Tillmann. 2004. A Unigram Orientation Model for
Statistical Machine Translation. In Proceedings of
HLT-NAACL: Short Papers, pages 101?104.
A. Zollmann and A. Venugopal. 2006. Syntax Aug-
mented Machine Translation via Chart Parsing. In
Proc. of NAACL 2006 - Workshop on Statistical Ma-
chine Translation.
A. Zollmann, A. Venugopal, F. Och, and J. Ponte.
2008. A Systematic Comparison of Phrase-Based,
Hierarchical and Syntax-Augmented Statistical MT.
In Proceedings of the Conference on Computational
Linguistics (COLING).
1596
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 135?142
Manchester, August 2008
Context-based Arabic Morphological Analysis for Machine Translation
ThuyLinh Nguyen
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213, USA
thuylinh@cs.cmu.edu
Stephan Vogel
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213, USA
vogel@cs.cmu.edu
Abstract
In this paper, we present a novel morphol-
ogy preprocessing technique for Arabic-
English translation. We exploit the Arabic
morphology-English alignment to learn a
model removing nonaligned Arabic mor-
phemes. The model is an instance of
the Conditional Random Field (Lafferty et
al., 2001) model; it deletes a morpheme
based on the morpheme?s context. We
achieved around two BLEU points im-
provement over the original Arabic trans-
lation for both a travel-domain system
trained on 20K sentence pairs and a news
domain system trained on 177K sentence
pairs, and showed a potential improvement
for a large-scale SMT system trained on 5
million sentence pairs.
1 Introduction
Statistical machine translation (SMT) relies heav-
ily on the word alignment model of the source
and the target language. However, there is a
mismatch between a rich morphology language
(e.g Arabic, Czech) and a poor morphology lan-
guage (e.g English). An Arabic source word of-
ten corresponds to several English words. Pre-
vious research has focused on attempting to ap-
ply morphological analysis to machine translation
in order to reduce unknown words of highly in-
flected languages. Nie?en and Ney (2004) rep-
resented a word as a vector of morphemes and
gained improvement over word-based system for
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
German-English translation. Goldwater and Mc-
closky (2005) improved Czech-English translation
by applying different heuristics to increase the
equivalence of Czech and English text.
Specially for Arabic-English translation, Lee
(2004) used the Arabic part of speech and English
parts of speech (POS) alignment probabilities to
retain an Arabic affix, drop it from the corpus or
merge it back to a stem. The resulting system
outperformed the original Arabic system trained
on 3.3 million sentence pairs corpora when using
monotone decoding. However, an improvement
in monotone decoding is no guarantee for an im-
provement over the best baseline achievable with
full word forms. Our experiments showed that an
SMT phrase-based translation using 4 words dis-
tance reordering could gain four BLEU points over
monotone decoding. Sadat and Habash (2006) ex-
plored a wide range of Arabic word-level prepro-
cessing and produced better translation results for
a system trained on 5 million Arabic words.
What all the above methodologies do not pro-
vide is a means to disambiguate morphologi-
cal analysis for machine translation based on the
words? contexts. That is, for an Arabic word anal-
ysis of the form prefix*-stem-suffix* a morpheme
only is either always retained, always dropped off
or always merged to the stem regardless of its
surrounding text. In the example in Figure (1),
the Arabic word ?AlnAfi*h?(?window? in English)
was segmented as ?Al nAfi* ap?. The morpheme
?ap? is removed so that ?Al nAfi*? aligned to ?the
window? of the English sentence. In the sentence
?hl ldyk mqAEd bjwAr AlnAf*h ?? (?do you have
window tables ?? in English) the word ?AlnAfi*h?
is also segmented as ?Al nAfi* ap?. But in this
sentence, morphological preprocessing should re-
move both ?Al? and ?ap? so that only the remain-
135
nu  riyd  u  |||  mA}id  ap  |||  bi  jAnib  |||  Al  nAfi* ap  |||  .
we  want  to  have  a  table  near  the  window  .
nu  riyd  u  mA}id  ap  bi  jAnib  Al  nAfi* .
nryd   mA}dh   bjAnb   AlnAf*h   .
(c)
(a)
(b)
(d)
Figure 1: (a) Romanization of original Arabic sentence, (b) Output of morphological analysis toolkit?
words are separated by ?|||?, (c) English translation and its alignment with full morphological analysis
(d) Morphological analysis after removing unaligned morphemes.
ing morpheme ?nAfi*? aligned to the word ?win-
dow? of the English translation. Thus an appropri-
ate preprocessing technique should be guided by
English translation and bring the word context into
account.
In this paper we describe a context-based mor-
phological analysis for Arabic-English translation
that take full account morphemes alignment to En-
glish text. The preprocessing uses the Arabic mor-
phology disambiguation in (Smith et al, 2005) for
full morphological analysis and learns the remov-
ing morphemes model based on the Viterbi align-
ment of English to full morphological analysis. We
tested the model with two training corpora of 5.2
millions Arabic words(177K sentences) in news
domain and 159K Arabic words (20K sentences)
in travel conversation domain and gain improve-
ment over the original Arabic translation in both
experiments. The system that trained on a sub-
sample corpora of 5 millions sentence pairs cor-
pora also showed one BLEU score improvement
over the original Arabic system on unseen test set.
We will explain our technique in the next section
and briefly review the phrase based SMT model in
section 3. The experiment results will be presented
in section 4.
2 Methodology
We first preprocess the Arabic training corpus and
segment words into morpheme sequences of the
form prefix* stem suffix*. Stems are verbs, adjec-
tives, nouns, pronouns, etc., carrying the content
of the sentence. Prefixes and suffixes are func-
tional morphemes such as gender and case mark-
ers, prepositions, etc. Because case makers do not
exist in English, we remove case marker suffixes
from the morphology output. The output of this
process is a full morphological analysis corpus.
Even after removing case markers, the token count
of the full morphology corpus still doubles the
original Arabic?s word token count and is approx-
imately 1.7 times the number of tokens of the En-
glish corpus. As stated above, using original Ara-
bic for translation introduces more unknown words
in test data and causes multiple English words to
map to one Arabic word. At the morpheme level,
an English word would correspond to a morpheme
in the full morphology corpus but some prefixes
and suffixes in the full morphology corpus may not
be aligned with any English words at all. For ex-
ample, the Arabic article ?Al? (?the? in English)
prefixes to both adjectives and nouns, while En-
glish has only one determiner in a simple noun
phrase. Using the full morphological analysis cor-
pus for translation would introduce redundant mor-
phemes in the source side.
The goal of our morphological analysis method
for machine translation is removing nonaligned
prefixes and suffixes from the full morphology cor-
pus using a data-driven approach. We use the word
alignment output of the full morphology corpus to
the English corpus to delete morphemes in a sen-
tence. If an affix is not aligned to an English word
in the word alignment output, the affix should be
removed from the morphology corpus for better
one-to-one alignment of source and target corpora.
However, given an unseen test sentence, the En-
glish translation of the sentence is not available to
remove affixes based on the word alignment out-
put. We therefore learn a model removing non-
aligned morphemes from the full morphology Ara-
bic training corpus and its alignment to the English
corpus. To obtain consistency between training
corpus and test set, we applied the model to both
Arabic training corpus and test set, obtaining pre-
processed morphology corpora for the translation
task.
In this section, we will explain in detail each
steps of our preprocessing methodology:
136
? Apply word segmentation to the Arabic train-
ing corpus to get the full morphological anal-
ysis corpus.
? Annotate the full morphological analysis cor-
pus based on its word alignment to the En-
glish training corpus. We tag a morpheme as
?Deleted? if it should be removed from the
corpus, and ?Retained? otherwise.
? Learn the morphology tagger model.
? Apply the model to both Arabic training cor-
pus and Arabic test corpus to get prepro-
cessed corpus for translation.
2.1 Arabic Word Segmentation
Smith et al (2005) applies a source-channel model
to the problem of morphology disambiguation.
The source model is a uniform model that de-
fines the set of analyses. For Arabic morphology
disambiguation, the source model uses the list of
un-weighted word analyses generated by BAMA
toolkit (Buckwalter, 2004). The channel model
disambiguates the morphology alternatives. It is a
log-linear combination of features, which capture
the morphemes? context including tri-gram mor-
pheme histories, tri-gram part-of-speech histories
and combinations of the two.
The BAMA toolkit and hence (Smith et al,
2005) do not specify if a morpheme is an affix or
a stem in the output. Given a segmentation of an
original Arabic word, we considered a morpheme
a
i
as a stem if its parts of speech p
i
is either a
noun, pronoun, verb, adjective, question, punctua-
tion, number or abbreviation. A morpheme on the
left of its word?s stem is a prefix and it is a suffix
if otherwise. We removed case marker morphemes
and got the full morphology corpus.
2.2 Annotate Morphemes
To extract the Arabic morphemes that align to
English text, we use English as the source cor-
pus and aligned to Arabic morpheme corpus us-
ing GIZA++ (Och and Ney, 2003) toolkit. The
IBM3 and IBM4 (Brown et al, 1994) word align-
ment models select each word in the source sen-
tence, generate fertility and a list of target words
that connect to it. This generative process would
constrain source words to find alignments in the
target sentence. Using English as source corpus,
the alignment models force English words to gen-
erate their alignments in the Arabic morphemes.
GIZA++ outputs Viterbi alignment for every sen-
tence pair in the training corpus as depicted in (b)
and (c) of Figure (1). In our experiment, only 5%
of English words are not aligned to any Arabic
morpheme in the Viterbi alignment. From Viterbi
English-morpheme alignment output, we annotate
morphemes either to be deleted or retained as fol-
lows:
? Annotate stem morphemes as ?Retained?(R),
in dependant of word alignment output.
? Annotate a prefix or a suffix as ?Retained? (R)
if it is aligned to an English word.
? Annotate a prefix or a suffix as ?Deleted? (D)
if it is not aligned to an English word.
Note that the model does not assume that
GIZA++ outputs accurate word alignments. We
lessen the impact of the GIZA++ errors by only
using the word alignment output of prefix and suf-
fix morphemes.
Furthermore, because the full morphology sen-
tence is longer, each English word could align to a
separate morpheme. Our procedure of annotating
morphemes also constrains morphemes tagged as
?Retained? to be aligned to English words. Thus
if we remove ?Deleted? morphemes from the mor-
phology corpus, the reduced corpus and English
corpus have the property of one-to-one mapping
we prefer for source-target corpora in machine
translation.
2.3 Reduced Morphology Model
The reduced morphology corpus would be the
best choice of morphological analysis for machine
translation. Because it is impossible to tag mor-
phemes of a test sentence without the English ref-
erence based on Viterbi word alignment, we need
to learn a morpheme tagging model. The model
estimates the distributions of tagging sequences
given a morphologically analysed sentence using
the previous step?s annotated training data.
The task of tagging morphemes to be either
?Deleted? or ?Retained? belongs to the set of se-
quence labelling problems. The conditional ran-
dom fields (CRF) (Lafferty et al, 2001) model has
shown great benefits in similar applications of nat-
ural language processing such as part-of-speech
tagging, noun phrase chunking (Sha and Pereira,
2003), morphology disambiguation(Smith et al,
2005). We apply the CRF model to our morpheme
tagging problem.
137
Let A = {(A,T)} be the full morphology train-
ing corpus whereA = a
1
|p
1
a
2
|p
2
. . . a
m
|p
m
is a
morphology Arabic sentence, a
i
is a morpheme in
the sentence and p
i
is its POS;T = t
1
t
2
. . . t
m
is
the tag sequence of A, each t
i
is either ?Deleted?
or ?Retained? . The CRF model estimates param-
eter ?
?
maximizing the conditional probability of
the sequences of tags given the observed data:
?
?
= argmax
?
?
(A,T)?A
(1)
p? ((A,T)) log p
(
T|A, ?
)
where p? ((A,T)) is the empirical distribution of
the sentence (A,T) in the training data, ? are the
model parameters. The model?s log conditional
probability log p
(
T|A, ?
)
is the linear combina-
tion of feature weights:
log p
(
T|A, ?
)
=
?
k
?
k
f
k
((A
q
,T
q
)) (2)
The feature functions {f
k
} are defined on any sub-
set of the sentence A
q
? A and T
q
? T. CRFs
can accommodate many closely related features
of the input. In our morpheme tagging model,
we use morpheme features, part-of-speech features
and combinations of both. The features capture
the local contexts of morphemes. The lexical mor-
pheme features are the combinations of the current
morpheme and up to 2 previous and 2 following
morphemes. The part-of-speech features are the
combinations of the current part of speech and up
to 3 previous part of speeches. The part of speech,
morpheme combination features capture the de-
pendencies of current morphemes and up to its 3
previous parts of speech.
2.4 Preprocessed Data
Given a full morphology sentence A, we use the
morpheme tagging model learnt as described in the
previous section to decode A into the most proba-
ble sequence of tags T? = t
1
t
2
. . . t
m
.
T
?
= argmax
T
Pr
(
T|A, ?
?
)
(3)
If a t
i
is ?Deleted?, the morpheme a
i
is removed
from the morphology sentence A. The same pro-
cedure is applied to both training Arabic corpus
and test corpus to get preprocessed data for transla-
tion. We call a morphology sentence after remov-
ing ?Deleted? tag a reduced morphology sentence.
In our experiments, we used the freely available
CRF++1 toolkit to train and decode with the mor-
pheme tagging model. The CRF model smoothed
the parameters by assigning them Gaussian prior
distributions.
3 Phrase-based SMT System
We used the open source Moses (Koehn, 2007)
phrase-based MT system to test the impact of the
preprocessing technique on translation results. We
kept the default parameter settings of Moses for
translation model generation. The system used the
?grow-diag-final? alignment combination heuris-
tic. The phrase table consisted of phrase pairs up to
seven words long. The system used a tri-gram lan-
guage model built from SRI (Stolcke, 2002) toolkit
with modified Kneser-Ney interpolation smooth-
ing technique (Chen and Goodman, 1996). By de-
fault, the Moses decoder uses 6 tokens distance re-
ordering windows.
4 Experiment Results
In this section we present experiment results using
our Arabic morphology preprocessing technique.
4.1 Data Sets
We tested our morphology technique on a small
data set of 20K sentence pairs and a medium size
data set of 177K sentence pairs.
4.1.1 BTEC Data
As small training data set we used the BTEC
corpus (Takezawa et al, 2002) distributed by
the International Workshop on Spoken Language
Translation (IWSLT) (Eck and Hori, 2005). The
corpus is a collection of conversation transcripts
from the travel domain. Table 1 gives some de-
Arabic EngOri Full Reduced
Sentences 19972
Tokens 159K 258K 183K 183K
Types 17084 8207 8207 7298
Table 1: BTEC corpus statistics
tails for this corpus, which consists of nearly 20K
sentence pairs with lower case on the English side.
There is an imbalance of word types and word to-
kens between original Arabic and English. The
1http://crfpp.sourceforge.net/
138
original Arabic sentences are on average shorter
than the English sentences whereas the Arabic vo-
cabulary is more than twice the size of the English
vocabulary. The word segmentation reduced the
number of word types in the corpus to be closed
to English side but also increased word tokens
quite substantially. By removing nonaligned mor-
phemes, the reduced corpus is well balanced with
the English corpus.
The BTEC experiments used the 2004 IWSLT
Evaluation Test set as development set and 2005
IWSLT Evaluation Test set as unseen test data.
Table 2 gives the details of the two test sets. Both
of them had 16 reference translations per source
sentence. The English side of the training corpus
was used to build the language model. To optimize
the parameters of the decoder, we performed min-
imum error rate training on IWSLT04 optimizing
for the IBM-BLEU metric (Papineni et al, 2002).
4.1.2 Newswire Corpora
We also tested the impact of our morphology
technique on parallel corpus in the news domain.
The corpora were collected from LDC?s full Ara-
bic news translation corpora and a small portion
of UN data. The details of the data are give in
Table 3. The data consists of 177K sentence pairs,
5.2M words on the Arabic and 6M words on the
English side.
Arabic EngOri Full Reduced
Sentences 177035
Tokens 5.2M 9.3M 6.2M 6.2M
Types 155K 47K 47K 68K
Table 3: Newswire corpus statistics
We used two test sets from past NIST evalua-
tions as test data. NIST MT03 was used as devel-
opment set for optimizing parameters with respect
to the IBM-BLEU metric, NIST MT06 was used
as unseen test set. Both test sets have 4 references
per test sentence. Table 4 describes the data statis-
tics of the two test sets. All Newswire translation
experiments used the same language model esti-
mated from 200 million words collected from the
Xinhua section of the GIGA word corpus.
4.2 Translation Results
4.2.1 BTEC
We evaluated the machine translation accord-
ing to the case-insensitive BLEU metric. Table 5
shows the BTEC results when translated with de-
fault Moses setting of distance-based reordering
window size 6. The original Arabic word trans-
lation was the baseline of the evaluation. The
second row contains translation scores using the
full morphology translation. Our new technique of
context-based morphological analysis is shown in
the last row.
IWSLT04 IWSLT05
Ori 58.20 54.50
Full 58.55 55.87
Reduced 60.28 56.03
Table 5: BTEC translations results on IBM-BLEU
metrics(Case insensitive and 6 tokens distance re-
ordering window). The boldface marks scores sig-
nificantly higher than the original Arabic transla-
tion scores.
The full morphology translation performed sim-
ilar to the baseline on the development set but
outperformed the baseline on the unseen test set.
The reduced corpus showed significant improve-
ments over the baseline on the development set
(IWSLT04) and gave an additional small improve-
ment over the full morphology score over the un-
seen data (IWSLT05).
So why did the reduced morphology translation
not outperform more significantly the full mor-
phology translation on unseen set IWSLT05? To
analysis this in more detail, we selected good
full morphology translations and compared them
with the corresponding reduced morphology trans-
lations. Figure 2 shows one of these examples.
Typically, the reduced morphology translations
Figure 2: An example of BTEC translation output.
are shorter than both the references and the full
morphology outputs. Table 2 shows that for the
IWSLT05 test set, the ratio of the average En-
glish reference sentence length and the source sen-
139
IWSLT04 (Dev set) IWSLT05 (Unseen set)
Arabic English Arabic EnglishOri Full Reduced Ori Full Reduced
Sentences 500 8000 506 8096
Words 3261 5243 3732 64896 3253 5155 3713 66286
Avg Sent Length 6.52 10.48 7.46 8.11 6.43 10.19 7.34 8.18
Table 2: BTEC test set statistics
MT03 (Dev set) MT06 (Unseen set)
Arabic English Arabic EnglishOri Full Reduced Ori Full Reduced
Sentences 663 2652 1797 7188
Words 16268 27888 18888 79163 41059 71497 48716 222750
Avg Sent Length 24.53 42.06 28.49 29.85 22.85 39.79 27.1 30.98
Table 4: Newswire test set statistics
tence length is slightly higher than the correspond-
ing ratio for IWSLT04. Using the parameters op-
timised for IWSLT04 to translate IWSLT05 sen-
tences would generate hypotheses slightly shorter
than the IWSLT05 references resulting in brevity
penalties in the BLEU metric. The IWSLT05
brevity penalties for original Arabic, reduced mor-
phology and full morphology are 0.969, 0.978 and
0.988 respectively. Note that the BTEC corpus and
test sets are in the travel conversation domain, the
English reference sentences contain a large num-
ber of high frequency words. The full morpho-
logical analysis with additional prefixes and suf-
fixes outputs longer translations containing high
frequency words resulting in a high n-gram match
and lower BLEU brevity penalty. The reduced
translation method could generate translations that
are comparable but do not have the same effect on
BLEU metrics.
4.2.2 Newswire results
Table 6 presents the translation results for the
Newswire corpus. Even though morphology seg-
mentation reduced the number of unseen words,
the translation results of full morphological anal-
ysis are slightly lower than the original Arabic
scores in both development set MT03 and unseen
test set MT06. This is consistent with the result
achieved in previous literature (Sadat and Habash,
2006). Morphology preprocessing only helps with
small corpora, but the advantage decreases for
larger data sets.
Our context dependent preprocessing technique
MT03 MT06
Ori 45.55 32.09
Full 45.30 31.54
Reduced 47.69 34.13
Table 6: Newswire translation results on IBM-
BLEU metrics(Case insensitive and 6 tokens dis-
tance reordering wondow). The boldface marks
scores significantly higher than the original Arabic
translation?s scores.
shows significant improvements on both develop-
ment and unseen test sets. Moreover, while the ad-
vantage of morphology segmentation diminishes
for the full morphology translation, we achieve an
improvement of more than two BLEU points over
the original Arabic translations in both develop-
ment set and unseen test set.
4.3 Unknown Words Reduction
A clear advantage of using morphology based
translation over original word translation is the
reduction in the number of untranslated words.
Table 7 compares the number of unknown Arabic
tokens for original Arabic translation and reduced
morphology translation. In all the test sets, mor-
phology translations reduced the number of un-
known tokens by more than a factor of two.
4.4 The Impact of Reordering Distance Limit
The reordering window length is determined based
on the movements of the source phrases. On an
average, an original Arabic word has two mor-
140
Reorder Window 0 2 3 4 5 6 7 8 9
IWSLT04
Ori 57.21 57.92 58.01 58.31 58.16 58.20 58.20 58.12 58.01
Full 56.89 57.54 58.62 58.39 58.32 58.55 58.55 58.55 58.57
Reduced 58.36 59.56 60.05 60.70 60.32 60.28 60.46 60.30 60.55
MT03
Ori 41.75 43.84 45.24 45.61 45.40 45.55 45.21 45.22 45.19
Full 41.45 43.12 44.32 44.71 45.30 45.80 45.88 45.82
Reduced 44.08 45.28 46.50 47.40 47.41 47.69 47.59 47.75 47.79
Table 8: The impact of reordering limits on BTEC ?s development set IWSLT04 and Newswire?s devel-
opment set MT03. The translation scores are IBM-BLEU metric
Test Set Ori Reduced
IWSLT04 242 100
IWSLT05 219 97
MT03 1463 553
MT06 3734 1342
Table 7: Unknown tokens count
phemes. The full morphology translation with a
6-word reordering window has the same impact
as a 3-word reordering when translating the orig-
inal Arabic. To fully benefit from word reorder-
ing, the full morphology translation requires a
longer reorder distance limit. However, in current
phrase based translations, reordering models are
not strong enough to guide long distance source-
word movements. This shows an additional advan-
tage of the nonaligned morpheme removal tech-
nique.
We carried out experiments from monotone de-
coding up to 9 word distance reordering limit for
the two development sets IWSLT04 and MT03.
The results are given in Table 8. The BTEC data
set does not benefit from a larger reordering win-
dow. Using only a 2-word reordering window
the score of the original Arabic translations(57.92)
was comparable to the best score (58.31) obtained
by using a 4-word reordering window. On the
other hand, the reordering limit showed a signifi-
cant impact on Newswire data. The MT03 original
Arabic translation using a 4-word re-ordering win-
dow resulted in an improvement of 4 BLEU points
over monotone decoding. Large Arabic corpora
usually contain data from the news domain. The
decoder might not effectively reorder very long
distance morphemes for these data sets. This ex-
plains why machine translation does not benefit
from word-based morphological segmentation for
large data sets which adequately cover the vocabu-
lary of the test set.
4.5 Large Training Corpora Results
We wanted to test the impact of our preprocess-
ing technique on a system trained on 5 million
sentence pairs (128 million Arabic words). Un-
fortunately, the CRF++ toolkit exceeded memory
limits when executed even on a 24GB server. We
created smaller corpora by sub-sampling the large
corpus for the source side of MT03 and MT06
test sets. The sub-sampled corpus have 500K sen-
tence pairs and cover all source phrases of MT03
and MT06 which can be found in the large cor-
pus. In these experiments, we used a lexical re-
ordering model into translation model. The lan-
guage model was the 5-gram SRI language model
built from the whole GIGA word corpus. Table 9
MT03 MT06
5M Ori 56.22 42.17
Sub-sample Ori 54.54 41.59
Sub-sample Full 51.47 40.84
Sub-sample Reduced 54.78 43.20
Table 9: Translation results of large corpora(Case
insensitive, IBM-BLEU metric). The boldface
marks score significantly higher than the original
Arabic translation score.
presents the translation result of original Arabic
system trained on the full 5M sentence pairs cor-
pus and the three systems trained on the 500K sen-
tence pairs sub-sampled corpus. The sub-sampled
full morphology system scores degraded for both
development set and unseen test set. On devel-
opment set, the sub-sampled reduced morphology
system score was slightly better than baseline. On
the unseen test set, it significantly outperformed
both the baseline on sub-sampled training data and
even outperformed the system trained on the entire
141
5M sentence pairs.
5 Conclusion and Future Work
In this paper, we presented a context-dependent
morphology preprocessing technique for Arabic-
English translation. The model significantly out-
performed the original Arabic systems on small
and mid-size corpora and unseen test set on large
training corpora. The model treats morphology
processing task as a sequence labelling problem.
Therefore, other machine learning techniques such
as perceptron (Collins, 2002) could also be applied
for this problem.
The paper also discussed the relation between
the size of the reordering window and morphol-
ogy processing. In future investigations, we plan
to extend the model such that merging morphemes
is included. We also intent to study the impact of
phrase length and phrase extraction heuristics.
Acknowledgement
We thank Noah Smith for useful comments and
suggestions and providing us with the morphol-
ogy disambiguation toolkit. We also thank Sameer
Badaskar for help on editing the paper. We also
thank anonymous reviewers for helpful comments.
The research was supported by the GALE project.
References
Brown, Peter F., Stephen Della Pietra, Vincent J. Della Pietra,
and Robert L. Mercer. 1994. The Mathematic of Statisti-
cal Machine Translation: Parameter Estimation. Compu-
tational Linguistics, 19(2):263?311.
Buckwalter, T. 2004. Arabic Morphological Analyzer ver-
sion 2.0. LDC2004L02.
Chen, Stanley F. and Joshua Goodman. 1996. An Empirical
Study of Smoothing Techniques for Language Modeling.
In Proceedings of the ACL, pages 310?318.
Collins, Michael. 2002. Discriminative Training Methods
for Hidden Markov Models: Theory and Experiments with
Perceptron Algorithms. In Proceedings of EMNLP ?02,
pages 1?8.
Eck, M. and C. Hori. 2005. Overview of the IWSLT 2005
Evaluation Campaign. In Proceedings of IWSLT, pages
11?17.
Goldwater, Sharon and David Mcclosky. 2005. Improv-
ing Statistical MT through Morphological Analysis. In
Proceedings of HLT/EMNLP, pages 676?683, Vancouver,
British Columbia, Canada.
Koehn, et al 2007. Moses: Open Source Toolkit for Sta-
tistical Machine Translation. In Annual Meeting of ACL,
demonstration session.
Lafferty, John, Andrew McCallum, and Fernando Pereira.
2001. Conditional Random Fields: Probabilistic Models
for Segmenting and Labeling Sequence Data. In Proceed-
ings of 18th ICML, pages 282?289.
Lee, Young S. 2004. Morphological Analysis for Statistical
Machine Translation. In HLT-NAACL 2004: Short Papers,
pages 57?60, Boston, Massachusetts, USA.
Nie?en, Sonja and Hermann Ney. 2004. Statistical Ma-
chine Translation with Scarce Resources Using Morpho-
Syntactic Information. Computational Linguistics, 30(2),
June.
Och, Franz Josef and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51.
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. BLEU: a Method for Automatic Evaluation
of Machine Translation. In Proceedings of the 40th ACL,
pages 311?318, Philadelphia.
Sadat, Fatiha and Nizar Habash. 2006. Combination of Ara-
bic Preprocessing Schemes for Statistical Machine Trans-
lation. In Proceedings of the ACL, pages 1?8, Sydney,
Australia. Association for Computational Linguistics.
Sha, Fei and Fernando Pereira. 2003. Shallow Parsing with
Conditional Random Fields. In Proceedings of NAACL
?03, pages 134?141, Morristown, NJ, USA.
Smith, Noah A., David A. Smith, and Roy W. Tromble. 2005.
Context-Based Morphological Disambiguation with Ran-
dom Fields. In Proceedings of HLT/EMNLP, pages 475?
482, Vancouver, British Columbia, Canada, October. As-
sociation for Computational Linguistics.
Stolcke, A. 2002. SRILM ? an Extensible Language Model-
ing Toolkit. In Intl. Conf. on Spoken Language Process-
ing.
Takezawa, Toshiyuki, Eiichiro Sumita, Fumiaki Sugaya, Hi-
rofumi Yamamoto, and Seiichi Yamamoto. 2002. Toward
a Broad-Coverage Bilingual Corpus for Speech Transla-
tion of Travel Conversations in the Real World. In Pro-
ceedings of LREC 2002, pages 147?152.
142
