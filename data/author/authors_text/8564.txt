Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 485?494,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
Improving Interactive Machine Translation via Mouse Actions
Germa?n Sanchis-Trilles and Daniel Ortiz-Mart??nez and Jorge Civera
Instituto Tecnolo?gico de Informa?tica
Universidad Polite?cnica de Valencia
{gsanchis,dortiz,jorcisai}@iti.upv.es
Francisco Casacuberta and Enrique Vidal
Departamento de Sistemas Informa?ticos y Computacio?n
Universidad Polite?cnica de Valencia
{fcn,evidal}@dsic.upv.es
Hieu Hoang
University of Edinburgh
hhoang@sms.ed.ac.uk
Abstract
Although Machine Translation (MT) is a very
active research field which is receiving an in-
creasing amount of attention from the research
community, the results that current MT sys-
tems are capable of producing are still quite
far away from perfection. Because of this,
and in order to build systems that yield correct
translations, human knowledge must be inte-
grated into the translation process, which will
be carried out in our case in an Interactive-
Predictive (IP) framework. In this paper, we
show that considering Mouse Actions as a sig-
nificant information source for the underly-
ing system improves the productivity of the
human translator involved. In addition, we
also show that the initial translations that the
MT system provides can be quickly improved
by an expert by only performing additional
Mouse Actions. In this work, we will be using
word graphs as an efficient interface between
a phrase-based MT system and the IP engine.
1 Introduction
Information technology advances in modern society
have led to the need of more efficient methods of
translation. It is important to remark that current
MT systems are not able to produce ready-to-use
texts (Kay, 1997; Hutchins, 1999; Arnold, 2003).
Indeed, MT systems are usually limited to specific
semantic domains and the translations provided re-
quire human post-editing in order to achieve a cor-
rect high-quality translation.
A way of taking advantage of MT systems is to
combine them with the knowledge of a human trans-
lator, constituting the so-called Computer-Assisted
Translation (CAT) paradigm. CAT offers different
approaches in order to benefit from the synergy be-
tween humans and MT systems.
An important contribution to interactive CAT
technology was carried out around the TransType
(TT) project (Langlais et al, 2002; Foster et al,
2002; Foster, 2002; Och et al, 2003). This project
entailed an interesting focus shift in which interac-
tion directly aimed at the production of the target
text, rather than at the disambiguation of the source
text, as in former interactive systems. The idea
proposed was to embed data driven MT techniques
within the interactive translation environment.
Following these TT ideas, (Barrachina and oth-
ers, 2008) propose the usage of fully-fledged statis-
tical MT (SMT) systems to produce full target sen-
tence hypotheses, or portions thereof, which can be
partially or completely accepted and amended by a
human translator. Each partial correct text segment
is then used by the SMT system as additional infor-
mation to achieve further, hopefully improved sug-
gestions. In this paper, we also focus on the inter-
active and predictive, statistical MT (IMT) approach
to CAT. The IMT paradigm fits well within the In-
teractive Pattern Recognition framework introduced
in (Vidal and others, 2007).
485
SOURCE (x): Para encender la impresora:
REFERENCE (y): To power on the printer:
ITER-0 (p) ( )(s?h) To switch on:
ITER-1
(p) To
(sl) switch on:
(k) power
(s?h) on the printer:
ITER-2
(p) To power on the printer:
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) To power on the printer:
Figure 1: IMT session to translate a Spanish sentence into English. Non-validated hypotheses are displayed in italics,
whereas accepted prefixes are printed in normal font.
Figure 1 illustrates a typical IMT session. Ini-
tially, the user is given an input sentence x to be
translated. The reference y provided is the trans-
lation that the user would like to achieve at the end
of the IMT session. At iteration 0, the user does not
supply any correct text prefix to the system, for this
reason p is shown as empty. Therefore, the IMT sys-
tem has to provide an initial complete translation sh,
as it were a conventional SMT system. At the next
iteration, the user validates a prefix p as correct by
positioning the cursor in a certain position of sh. In
this case, after the words ?To print a?. Implicitly, he
is also marking the rest of the sentence, the suffix sl,
as potentially incorrect. Next, he introduces a new
word k, which is assumed to be different from the
first word sl1 in the suffix sl which was not validated,
k 6= sl1 . This being done, the system suggests a new
suffix hypothesis s?h, subject to s?h1 = k. Again, the
user validates a new prefix, introduces a new word
and so forth. The process continues until the whole
sentence is correct that is validated introducing the
special word ?#?.
As the reader could devise from the IMT session
described above, IMT aims at reducing the effort
and increasing the productivity of translators, while
preserving high-quality translation. For instance, in
Figure 1, only three interactions were necessary in
order to achieve the reference translation.
In this paper, we will show how Mouse Actions
performed by the human expert can be taken advan-
tage of in order to further reduce this effort.
2 Statistical interactive-predictive MT
In this section we will briefly describe the statistical
framework of IMT. IMT can be seen as an evolution
of the SMT framework, which has proved to be an
efficient framework for building state-of-the-art MT
systems with little human effort, whenever adequate
corpora are available (Hutchings and Somers, 1992).
The fundamental equation of the statistical approach
to MT is
y? = argmax
y
Pr(y |x) (1)
= argmax
y
Pr(x |y)Pr(y) (2)
where Pr(x |y) is the translation model modelling
the correlation between source and target sentence
and Pr(y) is the language model representing the
well-formedness of the candidate translation y.
In practise, the direct modelling of the posterior
probability Pr(y|x) has been widely adopted. To
this purpose, different authors (Papineni et al, 1998;
Och and Ney, 2002) propose the use of the so-called
log-linear models, where the decision rule is given
by the expression
y? = argmax
y
M
?
m=1
?mhm(x,y) (3)
where hm(x,y) is a score function representing an
important feature for the translation of x into y, M
is the number of models (or features) and ?m are the
weights of the log-linear combination.
486
One of the most popular instantiations of log-
linear models is that including phrase-based (PB)
models (Zens et al, 2002; Koehn et al, 2003).
Phrase-based models allow to capture contextual in-
formation to learn translations for whole phrases in-
stead of single words. The basic idea of phrase-
based translation is to segment the source sentence
into phrases, then to translate each source phrase
into a target phrase, and finally to reorder the trans-
lated target phrases in order to compose the tar-
get sentence. Phrase-based models were employed
throughout this work.
In log-linear models, the maximisation problem
stated in Eq. 3 is solved by means of the beam search
algorithm1 which was initially introduced in (Low-
erre, 1976) for its application in the field of speech
recognition. The beam search algorithm attempts to
generate partial solutions, called hypotheses, until
a complete sentence is found; these hypotheses are
stored in a stack and ordered by their score. Such a
score is given by the log-linear combination of fea-
ture functions.
However, Eq. 1 needs to be modified according to
the IMT scenario in order to take into account part
of the target sentence that is already translated, that
is p and k
s?h = argmax
sh
Pr(sh|x,p, k) (4)
where the maximisation problem is defined over the
suffix sh. This allows us to rewrite Eq. 4, by decom-
posing the right side appropriately and eliminating
constant terms, achieving the equivalent criterion
s?h = argmax
sh
Pr(p, k, sh|x). (5)
An example of the intuition behind these variables
can be seen in Figure 1.
Note that, since (p k sh) = y, Eq. 5 is very simi-
lar to Eq. 1. The main difference is that the argmax
search is now performed over the set of suffixes sh
that complete (p k) instead of complete sentences
(y in Eq. 1). This implies that we can use the same
models if the search procedures are adequately mod-
ified (Barrachina and others, 2008).
1Also known as stack decoding algorithm.
3 Phrase-based IMT
The phrase-based approach presented above can be
easily adapted for its use in an IMT scenario. The
most important modification is to rely on a word
graph that represents possible translations of the
given source sentence. The use of word graphs
in IMT has been studied in (Barrachina and oth-
ers, 2008) in combination with two different trans-
lation techniques, namely, the Alignment Templates
technique (Och et al, 1999; Och and Ney, 2004),
and the Stochastic Finite State Transducers tech-
nique (Casacuberta and Vidal, 2007).
3.1 Generation of word graphs
A word graph is a weighted directed acyclic graph,
in which each node represents a partial translation
hypothesis and each edge is labelled with a word of
the target sentence and is weighted according to the
scores given by an SMT model (see (Ueffing et al,
2002) for more details). In (Och et al, 2003), the
use of a word graph is proposed as interface between
an alignment-template SMT model and the IMT en-
gine. Analogously, in this work we will be using
a word graph built during the search procedure per-
formed on a PB SMT model.
During the search process performed by the above
mentioned beam search algorithm, it is possible to
create a segment graph. In such a graph, each node
represents a state of the SMT model, and each edge
a weighted transition between states labelled with a
sequence of target words. Whenever a hypothesis is
extended, we add a new edge connecting the state
of that hypothesis with the state of the extended hy-
pothesis. The new edge is labelled with the sequence
of target words that has been incorporated to the ex-
tended hypothesis and is weighted appropriately by
means of the score given by the SMT model.
Once the segment graph is generated, it can be
easily converted into a word graph by the introduc-
tion of artificial states for the words that compose
the target phrases associated to the edges.
3.2 IMT using word graphs
During the process of IMT for a given source sen-
tence, the system makes use of the word graph gen-
erated for that sentence in order to complete the pre-
fixes accepted by the human translator. Specifically,
487
SOURCE (x): Para encender la impresora:
REFERENCE (y): To power on the printer:
ITER-0 (p) ( )(s?h) To switch on:
ITER-1
(p) To
(sl) |switch on:
(s?h) power on the printer:
ITER-2
(p) To power on the printer:
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) To power on the printer:
Figure 2: Example of non-explicit positioning MA which solves an error of a missing word. In this case, the system
produces the correct suffix sh immediately after the user validates a prefix p, implicitly indicating that we wants the
suffix to be changed, without need of any further action. In ITER-1, character | indicates the position where a MA
was performed, sl is the suffix which was rejected by that MA, and s?h is the new suffix that the system suggests after
observing that sl is to be considered incorrect. Character # is a special character introduced by the user to indicate that
the hypothesis is to be accepted.
the system finds the best path in the word graph as-
sociated with a given prefix so that it is able to com-
plete the target sentence, being capable of providing
several completion suggestions for each prefix.
A common problem in IMT arises when the user
sets a prefix which cannot be found in the word
graph, since in such a situation the system is un-
able to find a path through the word graph and pro-
vide an appropriate suffix. The common procedure
to face this problem is to perform a tolerant search
in the word graph. This tolerant search uses the well
known concept of Levenshtein distance in order to
obtain the most similar string for the given prefix
(see (Och et al, 2003) for more details).
4 Enriching user?machine interaction
Although the IMT paradigm has proved to offer in-
teresting benefits to potential users, one aspect that
has not been reconsidered as of yet is the user?
machine interface. Hence, in traditional IMT the
system only received feedback whenever the user
typed in a new word. In this work, we show how
to enrich user?machine interaction by introducing
Mouse Actions (MA) as an additional information
source for the system. By doing so, we will consider
two types of MAs, i.e. non-explicit (or positioning)
MAs and interaction-explicit MAs.
4.1 Non-explicit positioning MAs
Before typing in a new word in order to correct a hy-
pothesis, the user needs to position the cursor in the
place where he wants to type such a word. In this
work, we will assume that this is done by perform-
ing a MA, although the same idea presented can also
be applied when this is done by some other means.
It is important to point out that, by doing so, the user
is already providing some very useful information to
the system: he is validating a prefix up to the posi-
tion where he positioned the cursor, and, in addition,
he is signalling that whatever word is located after
the cursor is to be considered incorrect. Hence, the
system can already capture this fact and provide a
new translation hypothesis, in which the prefix re-
mains unchanged and the suffix is replaced by a new
one in which the first word is different to the first
word of the previous suffix. We are aware that this
does not mean that the new suffix will be correct, but
given that we know that the first word in the previ-
ous suffix was incorrect, the worst thing which can
happen is that the the first word of the new suffix is
incorrect as well. However, if the new suffix hap-
pens to be correct, the user will happily find that he
does not need to correct that word any more.
An example of such behaviour can be seen in
Figure 2. In this example, the SMT system first
provides a translation which the user does not
488
like. Hence, he positions the cursor before word
?postscript?, with the purpose of typing in ?lists?.
By doing so, he is validating the prefix ?To print
a?, and signalling that he wants ?postscript? to be
replaced. Before typing in anything, the system re-
alises that he is going to change the word located
after the cursor, and replaces the suffix by another
one, which is the one the user had in mind in the
first place. Finally, the user only has to accept the
final translation.
We are naming this kind of MA non-explicit be-
cause it does not require any additional action from
the user: he has already performed a MA in order to
position the cursor at the place he wants, and we are
taking advantage of this fact to suggest a new suffix
hypothesis.
Since the user needs to position the cursor before
typing in a new word, it is important to point out
that any improvement achieved by introducing non-
explicit MAs does not require any further effort from
the user, and hence is considered to have no cost.
Hence, we are now considering two different situ-
ations: the first one, the traditional IMT framework,
in which the system needs to find a suffix according
to Eq. 5, and a new one, in which the system needs
to find a suffix in which the first word does not need
to be a given k, but needs to be different to a given
sl1. This constraint can be expressed by the follow-
ing equation:
s?h = argmax
sh:sh1 6=sl1
Pr(p, sh|x, sl) (6)
where sl is the suffix generated in the previous iter-
ation, already discarded by the user, and sl1 is the
first word in sl. k is omitted in this formula because
the user did not type any word at all.
4.2 Interaction-explicit MAs
If the system is efficient and provides suggestions
which are good enough, one could easily picture a
situation in which the expert would ask the system
to replace a given suffix, without typing in any word.
We will be modelling this as another kind of MA,
interaction-explicit MA, since the user needs to in-
dicate explicitly that he wants a given suffix to be
replaced, in contrast to the non-explicit positioning
MA. However, if the underlying MT engine provid-
ing the suffixes is powerful enough, the user would
quickly realise that performing a MA is less costly
that introducing a whole new word, and would take
advantage of this fact by systematically clicking be-
fore introducing any new word. In this case, as
well, we assume that the user clicks before an in-
correct word, hence demanding a new suffix whose
first word is different, but by doing so he is adopting
a more participative and interactive attitude, which
was not demanded in the case of non-explicit posi-
tioning MAs. An example of such an explicit MA
correcting an error can be seen in Figure 3
In this case, however, there is a cost associated to
this kind of MAs, since the user does need to per-
form additional actions, which may or may not be
beneficial. It is very possible that, even after asking
for several new hypothesis, the user will even though
need to introduce the word he had in mind, hence
wasting the additional MAs he had performed.
If we allow the user to perform n MAs before in-
troducing a word, this problem can be formalised in
an analogous way as in the case of non-explicit MAs
as follows:
s?h= argmax
sh:sh1 6=sil1?i?{1..n}
Pr(p, sh|x, s1l , s2l , . . . , snl ) (7)
where sil1 is the first word of the i-th suffix dis-
carded and s1l , s2l , . . . , snl is the set of all n suffixes
discarded.
Note that this kind of MA could also be imple-
mented with some other kind of interface, e.g. by
typing some special key such as F1 or Tab. How-
ever, the experimental results would not differ, and
in our user interface we found it more intuitive to
implement it as a MA.
5 Experimental setup
5.1 System evaluation
Automatic evaluation of results is a difficult problem
in MT. In fact, it has evolved to a research field with
own identity. This is due to the fact that, given an
input sentence, a large amount of correct and differ-
ent output sentences may exist. Hence, there is no
sentence which can be considered ground truth, as is
the case in speech or text recognition. By extension,
this problem is also applicable to IMT.
In this paper, we will be reporting our results as
measured by Word Stroke Ratio (WSR) (Barrachina
489
SOURCE (x): Seleccione el tipo de instalacio?n.
REFERENCE (y): Select the type of installation.
ITER-0 (p) ( )(s?h) Select the installation wizard.
ITER-1
(p) Select the
(sl) |installation wizard.
(s?h) install script.
ITER-2
(p) Select the
(k) type
(s?h) installation wizard.
ITER-3
(p) Select the type
(sl) |installation wizard.
(s?h) of installation.
ITER-4
(p) Select the type of installation.
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) Select the type of installation.
Figure 3: Example of explicit interactive MA which corrects an erroneous suffix. In this case, a non-explicit MA is
performed in ITER-1 with no success. Hence, the user introduces word ?type? in ITER-2, which leaves the cursor
position located immediately after word ?type?. In this situation the user would not need to perform a MA to re-
position the cursor and continue typing in order to further correct the remaining errors. However, since he has learnt
the potential benefit of MAs, he performs an interaction-explicit MA in order to ask for a new suffix hypothesis, which
happens to correct the error.
and others, 2008), which is computed as the quotient
between the number of word-strokes a user would
need to perform in order to achieve the translation
he has in mind and the total number of words in
the sentence. In this context, a word-stroke is in-
terpreted as a single action, in which the user types
a complete word, and is assumed to have constant
cost. Moreover, each word-stroke also takes into ac-
count the cost incurred by the user when reading the
new suffix provided by the system.
In the present work, we decided to use WSR in-
stead of Key Stroke Ratio (KSR), which is used in
other works on IMT such as (Och et al, 2003). The
reason for this is that KSR is clearly an optimistic
measure, since in such a scenario the user is often
overwhelmed by receiving a great amount of trans-
lation options, as much as one per key stroke, and
it is not taken into account the time the user would
need to read all those hypotheses.
In addition, and because we are also introducing
MAs as a new action, we will also present results in
terms of Mouse Action Ratio (MAR), which is the
quotient between the amount of explicit MAs per-
formed and the number of words of the final trans-
lation. Hence, the purpose is to elicit the number of
times the user needed to request a new translation
(i.e. performed a MA), on a per word basis.
Lastly, we will also present results in terms of
uMAR (useful MAR), which indicates the amount
of MAs which were useful, i.e. the MAs that actu-
ally produced a change in the first word of the suffix
and such word was accepted. Formally, uMAR is
defined as follows:
uMAR = MAC ? n ?WSCMAC (8)
where MAC stands for ?Mouse Action Count?,
WSC for ?Word Stroke Count? and n is the max-
imum amount of MAs allowed before the user types
in a word. Note that MAC?n ?WSC is the amount
of MAs that were useful since WSC is the amount
of word-strokes the user performed even though he
had already performed n MAs.
Since we will only use single-reference WSR and
MAR, the results presented here are clearly pes-
simistic. In fact, it is relatively common to have the
underlying SMT system provide a perfectly correct
490
Table 1: Characteristics of Europarl for each of the sub-
corpora. OoV stands for ?Out of Vocabulary? words,
Dev. for Development, K for thousands of elements and
M for millions of elements.
De En Es En Fr En
Tr
ai
n
in
g Sentences 751K 731K 688K
Run. words 15.3M16.1M 15.7M15.2M 15.6M13.8M
Avg. len. 20.3 21.4 21.5 20.8 22.7 20.1
Voc. 195K 66K 103K 64K 80K 62K
D
ev
.
Sentences 2000 2000 2000
Run. words 55K 59K 61K 59K 67K 59K
Avg. len. 27.6 29.3 30.3 29.3 33.6 29.3
OoV 432 125 208 127 144 138
Te
st
Sentences 2000 2000 2000
Run. words 54K 58K 60K 58K 66K 58K
Avg. len. 27.1 29.0 30.2 29.0 33.1 29.3
OoV 377 127 207 125 139 133
translation, which is ?corrected? by the IMT proce-
dure into another equivalent translation, increasing
WSR and MAR significantly by doing so.
5.2 Corpora
Our experiments were carried out on the Eu-
roparl (Koehn, 2005) corpus, which is a corpus
widely used in SMT and that has been used in sev-
eral MT evaluation campaigns. Moreover, we per-
formed our experiments on the partition established
for the Workshop on Statistical Machine Translation
of the NAACL 2006 (Koehn and Monz, 2006). The
Europarl corpus (Koehn, 2005) is built from the pro-
ceedings of the European Parliament. Here, we will
focus on the German?English, Spanish?English and
French?English tasks, since these were the language
pairs selected for the cited workshop. The corpus is
divided into three separate sets: one for training, one
for development, and one for test. The characteris-
tics of the corpus can be seen in Table 1.
5.3 Experimental results
As a first step, we built a SMT system for each of
the language pairs cited in the previous subsection.
This was done by means of the Moses toolkit (Koehn
and others, 2007), which is a complete system for
building Phrase-Based SMT models. This toolkit in-
volves the estimation from the training set of four
different translation models, which are in turn com-
Table 2: WSR improvement when considering non-
explicit MAs. ?rel.? indicates the relative improvement.
All results are given in %.
pair baseline non-explicit rel.
Es?En 63.0?0.9 59.2?0.9 6.0?1.4
En?Es 63.8?0.9 60.5?1.0 5.2?1.6
De?En 71.6?0.8 69.0?0.9 3.6?1.3
En?De 75.9?0.8 73.5?0.9 3.2?1.2
Fr?En 62.9?0.9 59.2?1.0 5.9?1.6
En?Fr 63.4?0.9 60.0?0.9 5.4?1.4
bined in a log-linear fashion by adjusting a weight
for each of them by means of the MERT (Och, 2003)
procedure, optimising the BLEU (Papineni et al,
2002) score obtained on the development partition.
This being done, word graphs were generated
for the IMT system. For this purpose, we used a
multi-stack phrase-based decoder which will be dis-
tributed in the near future together with the Thot
toolkit (Ortiz-Mart??nez et al, 2005). We discarded
the use of the Moses decoder because preliminary
experiments performed with it revealed that the de-
coder by (Ortiz-Mart??nez et al, 2005) performs
clearly better when used to generate word graphs
for use in IMT. In addition, we performed an ex-
perimental comparison in regular SMT with the Eu-
roparl corpus, and found that the performance dif-
ference was negligible. The decoder was set to
only consider monotonic translation, since in real
IMT scenarios considering non-monotonic transla-
tion leads to excessive waiting time for the user.
Finally, the word graphs obtained were used
within the IMT procedure to produce the reference
translation contained in the test set, measuring WSR
and MAR. The results of such a setup can be seen in
Table 2. As a baseline system, we report the tradi-
tional IMT framework, in which no MA is taken into
account. Then, we introduced non-explicit MAs, ob-
taining an average improvement in WSR of about
3.2% (4.9% relative). The table also shows the
confidence intervals at a confidence level of 95%.
These intervals were computed following the boot-
strap technique described in (Koehn, 2004). Since
the confidence intervals do not overlap, it can be
stated that the improvements obtained are statisti-
cally significant.
491
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
Spanish -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
Spanish -> English
WSR
uMAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
German -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
German -> English
WSR
uMAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
French -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
French -> English
WSR
uMAR
Figure 4: WSR improvement when considering one to five maximum MAs. All figures are given in %. The left
column lists WSR improvement versus MAR degradation, and the right column lists WSR improvement versus uMAR.
Confidence intervals at 95% confidence level following (Koehn, 2004).
Once the non-explicit MAs were considered and
introduced into the system, we analysed the effect
of performing up to a maximum of 5 explicit MAs.
Here, we modelled the user in such a way that, in
case a given word is considered incorrect, he will
always ask for another translation hypothesis until
he has asked for as many different suffixes as MAs
considered. The results of this setup can be seen in
Figure 4. This yielded a further average improve-
ment in WSR of about 16% (25% relative improve-
ment) when considering a maximum of 5 explicit
MAs. However, relative improvement in WSR and
492
uMAR increase drop significantly when increasing
the maximum allowed amount of explicit MAs from
1 to 5. For this reason, it is difficult to imagine that
a user would perform more than two or three MAs
before actually typing in a new word. Nevertheless,
just by asking twice for a new suffix before typing
in the word he has in mind, the user might be saving
about 15% of word-strokes.
Although the results in Figure 4 are only
for the translation direction ?foreign??English,
the experiments in the opposite direction (i.e.
English??foreign?) were also performed. How-
ever, the results were very similar to the ones dis-
played here. Because of this, and for clarity pur-
poses, we decided to omit them and only display the
direction ?foreign??English.
6 Conclusions and future work
In this paper, we have considered new input sources
for IMT. By considering Mouse Actions, we have
shown that a significant benefit can be obtained, in
terms of word-stroke reduction, both when consid-
ering only non-explicit MAs and when considering
MAs as a way of offering the user several suffix hy-
potheses. In addition, we have applied these ideas
on a state-of-the-art SMT baseline, such as phrase-
based models. To achieve this, we have first ob-
tained a word graph for each sentence which is to be
translated. Experiments were carried out on a refer-
ence corpus in SMT.
Note that there are other systems (Esteban and
others, 2004) that, for a given prefix, provide n-
best lists of suffixes. However, the functionality of
our system is slightly (but fundamentally) different,
since the suggestions are demanded to be different
in their first word, which implies that the n-best list
is scanned deeper, going directly to those hypothe-
ses that may be of interest to the user. In addition,
this can be done ?on demand?, which implies that
the system?s response is faster and that the user is
not confronted with a large list of hypotheses, which
often results overwhelming.
As future work, we are planning on performing a
human evaluation that assesses the appropriateness
of the improvements described.
Acknowledgements
This work has been partially supported by the Span-
ish MEC under scholarship AP2005-4023 and un-
der grants CONSOLIDER Ingenio-2010 CSD2007-
00018, and by the EC (FEDER) and the Spanish
MEC under grant TIN2006-15694-CO2-01.
References
D. J. Arnold, 2003. Computers and Translation: A trans-
lator?s guide, chapter 8, pages 119?142.
S. Barrachina et al 2008. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, page In press.
F. Casacuberta and E. Vidal. 2007. Learning finite-state
models for machine translation. Machine Learning,
66(1):69?91.
J. Esteban et al 2004. Transtype2 - an innovative
computer-assisted translation system. In The Compan-
ion Volume to the Proc. ACL?04, pages 94?97.
G. Foster, P. Langlais, and G. Lapalme. 2002. User-
friendly text prediction for translators. In Proc. of
EMNLP?02, pages 148?155.
G. Foster. 2002. Text Prediction for Translators. Ph.D.
thesis, Universite? de Montre?al.
J. Hutchings and H. Somers. 1992. An introduction to
machine translation. In Ed. Academic Press.
J. Hutchins. 1999. Retrospect and prospect in computer-
based translation. In Proc. of MT Summit VII, pages
30?44.
M. Kay. 1997. It?s still the proper place. Machine Trans-
lation, 12(1-2):35?38.
P. Koehn and C. Monz, editors. 2006. Proc. of the Work-
shop on SMT.
P. Koehn et al 2007. Moses: Open source toolkit for
statistical machine translation. In Proc. of the ACL?07.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. HLT/NAACL?03,
pages 48?54.
P. Koehn. 2004. Statistical significance tests for machine
translation evaluation. In Proc. of EMNLP?04, pages
388?395, Barcelona, Spain.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In Proc. of the MT Summit X,
pages 79?86.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator?s productivity. Machine Translation,
15(4):77?98.
Bruce T. Lowerre. 1976. The harpy speech recogni-
tion system. Ph.D. thesis, Carnegie Mellon University,
Pittsburgh, PA, USA.
493
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. In Proc. of the ACL?02, pages 295?302.
F.J. Och and H. Ney. 2004. The alignment template ap-
proach to statistical machine translation. Comput. Lin-
guist., 30(4):417?449.
F. Och, C. Tillmann, and H. Ney. 1999. Improved align-
ment models for statistical machine translation. In
Proc. of EMNLP/WVLC?99, pages 20?28.
F.J. Och, R. Zens, and H. Ney. 2003. Efficient search for
interactive statistical machine translation. In Proc. of
EACL?03, pages 387?393.
F.J. Och. 2003. Minimum error rate training for statis-
tical machine translation. In Proc. of ACL?03, pages
160?167.
D. Ortiz-Mart??nez, I. Garc??a-Varea, and F. Casacuberta.
2005. Thot: a toolkit to train phrase-based statisti-
cal translation models. In Proc. of the MT Summit X,
pages 141?148.
K. Papineni, S. Roukos, and T. Ward. 1998. Maximum
likelihood and discriminative training of direct transla-
tion models. In Proc. of ICASSP?98, pages 189?192.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002.
Bleu: A method for automatic evaluation of machine
translation. In Proc. of ACL?02.
N. Ueffing, F. Och, and H. Ney. 2002. Generation of
word graphs in statistical machine translation. In Proc.
of EMNLP?02, pages 156?163.
E. Vidal et al 2007. Interactive pattern recognition. In
Proc. of MLMI?07, pages 60?71.
R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Proc. of KI?02, pages
18?32.
494
c? 2004 Association for Computational Linguistics
Machine Translation with Inferred
Stochastic Finite-State Transducers
Francisco Casacuberta? Enrique Vidal?
Universidad Polite?cnica de Valencia Universidad Polite?cnica de Valencia
Finite-state transducers are models that are being used in different areas of pattern recognition and
computational linguistics. One of these areas is machine translation, in which the approaches that
are based on building models automatically from training examples are becoming more and more
attractive. Finite-state transducers are very adequate for use in constrained tasks in which training
samples of pairs of sentences are available. A technique for inferring finite-state transducers is
proposed in this article. This technique is based on formal relations between finite-state transducers
and rational grammars. Given a training corpus of source-target pairs of sentences, the proposed
approach uses statistical alignment methods to produce a set of conventional strings from which
a stochastic rational grammar (e.g., an n-gram) is inferred. This grammar is finally converted
into a finite-state transducer. The proposed methods are assessed through a series of machine
translation experiments within the framework of the EuTrans project.
1. Introduction
Formal transducers give rise to an important framework in syntactic-pattern recogni-
tion (Fu 1982; Vidal, Casacuberta, and Garc??a 1995) and in language processing (Mohri
1997). Many tasks in automatic speech recognition can be viewed as simple translations
from acoustic sequences to sublexical or lexical sequences (acoustic-phonetic decod-
ing) or from acoustic or lexical sequences to query strings (for database access) or
(robot control) commands (semantic decoding) (Vidal, Casacuberta, and Garc??a 1995;
Vidal 1997; Bangalore and Ricardi 2000a, 2000b; Hazen, Hetherington, and Park 2001;
Mou, Seneff, and Zue 2001; Segarra et al 2001; Seward 2001).
Another similar application is the recognition of continuous hand-written char-
acters (Gonza?lez et al 2000). Yet a more complex application of formal transducers
is language translation, in which input and output can be text, speech, (continuous)
handwritten text, etc. (Mohri 1997; Vidal 1997; Bangalore and Ricardi 2000b, 2001;
Amengual et al 2000).
Rational transductions (Berstel 1979) constitute an important class within the field
of formal translation. These transductions are realized by the so-called finite-state
transducers. Even though other, more powerful transduction models exist, finite-state
transducers generally entail much more affordable computational costs, thereby mak-
ing these simpler models more interesting in practice.
One of the main reasons for the interest in finite-state machines for language
translation comes from the fact that these machines can be learned automatically from
examples (Vidal, Casacuberta, and Garc??a 1995). Nowadays, only a few techniques
exist for inferring finite-state transducers (Vidal, Garc??a, and Segarra 1989; Oncina,
? Departamento de Sistemas Informa?ticos y Computacio?n, Instituto Tecnolo?gico de Informa?tica, 46071
Valencia, Spain. E-mail:{fcn, evidal}@iti.upv.es.
206
Computational Linguistics Volume 30, Number 2
Garc??a, and Vidal 1993; Ma?kinen 1999; Knight and Al-Onaizan 1998; Bangalore and
Ricardi 2000b; Casacuberta 2000; Vilar 2000). Nevertheless, there are many techniques
for inferring regular grammars from finite sets of learning strings which have been
used successfully in a number of fields, including automatic speech recognition (Vi-
dal, Casacuberta, and Garc??a 1995). Some of these techniques are based on results from
formal language theory. In particular, complex regular grammars can be built by infer-
ring simple grammars that recognize local languages (Garc??a, Vidal, and Casacuberta
1987).
Here we explore this idea further and propose methods that use (simple) finite-
state grammar learning techniques, such as n-gram modeling, to infer rational trans-
ducers which prove adequate for language translation.
The organization of the article is as follows. Sections 2 and 3 give the basic defini-
tions of a finite-state transducer and the corresponding stochastic extension, presented
within the statistical framework of language translation. In Section 4, the proposed
method for inferring stochastic finite-state transducers is presented. The experiments
are described in Section 5. Finally, Section 6 is devoted to general discussion and
conclusions.
2. Finite-State Transducers
A finite-state transducer, T , is a tuple ??, ?, Q, q0, F, ??, in which ? is a finite set of
source symbols, ? is a finite set of target symbols (? ? ? = ?), Q is a finite set of
states, q0 is the initial state, F ? Q is a set of final states, and ? ? Q ? ? ? ? ? Q is
a set of transitions.1 A translation form ? of length I in T is defined as a sequence of
transitions:
? = (q?0 , s
?
1 , t?
?
1 , q
?
1 )(q
?
1 , s
?
2 , t?
?
2 , q
?
2 )(q
?
2 , s
?
3 , t?
?
3 , q
?
3 ) . . . (q
?
I?1, s
?
I , t?
?
I , q
?
I ) (1)
where (q?i?1, s
?
i , t?
?
i , q
?
i ) ? ?, q
?
0 = q0, and q
?
I ? F. A pair (s, t) ? ? ?? is a translation
pair if there is a translation form ? of length I in T such that I =|s | and t = t??1 t?
?
2 . . . t?
?
I .
By d(s, t) we will denote the set of translation forms2 in T associated with the pair (s, t).
A rational translation is the set of all translation pairs of some finite-state transducer T .
This definition of a finite-state transducer is similar to the definition of a regular
or finite-state grammar G. The main difference is that in a finite-state grammar, the set
of target symbols ? does not exist, and the transitions are defined on Q ? ? ? Q. A
translation form is the transducer counterpart of a derivation in a finite-state gram-
mar, and the concept of rational translation is reminiscent of the concept of (regular)
language, defined as the set of strings associated with the derivations in the grammar
G.
Rational translations exhibit many properties similar to those shown for regular
languages (Berstel 1979). One of these properties can be stated as follows (Berstel 1979):
Theorem 1
T ? ? ?? is a rational translation if and only if there exist an alphabet ?, a regular language
L ? ?, and two morphisms h? : ? ? ? and h? : ? ? ?, such that T = {(h?(w), h?(w)) |
w ? L}.
1 By ?? and ??, we denote the set of finite-length strings on ? and ?, respectively.
2 To simplify the notation, we will remove the superscript ? from the components of a translation form
if no confusion is induced.
207
Casacuberta and Vidal Translation with Finite-State Transducers
As will be discussed later, this theorem directly suggests the transducer inference
methods proposed in this article.
3. Statistical Translation Using Finite-State Transducers
In the statistical translation framework, the translation of a given source string s in
? is a string t? ? ?, such that3
t? = argmax
t??
Pr(t | s) = argmax
t??
Pr(s, t) (2)
Pr(s, t) can be modeled by the stochastic extension of a finite-state transducer. A
stochastic finite-state transducer, TP, is defined as a tuple ??,?, Q, q0, p, f ?, in which
Q, q0, Q,?, and ? are as in the definition of a finite-state transducer and p and f are
two functions p : Q ? ??? ? Q ? [0, 1] and f : Q ? [0, 1] that satisfy, ?q ? Q,
f (q) +
?
(a,?,q?)?????Q
p(q, a,?, q?) = 1
In this context, T will denote the natural finite-state transducer associated with a
stochastic finite-state transducer TP (characteristic finite-state transducer). The set of
transitions of T is the set of tuples (q, s, t, q?) in TP with probabilities greater than zero,
and the set of final states is the set of states with nonzero final-state probabilities.
The probability of a translation pair (s, t) ? ? ? ? according to TP is the sum
of the probabilities of all the translation forms of (s, t) in T :
PTP(s, t) =
?
??d(s,t)
PTP(?)
where the probability of a translation form ? (as defined in equation (1)) is
PTP(?) =
I
?
i=0
p(qi?1, si, t?i, qi) ? f (qI) (3)
that is, the product of the probabilities of all the transitions involved in ?.
We are interested only in transducers without useless states, that is, those in which
for every state in T , there is a path leading to a final state. If we further assume that
PTP(s, t) is zero when no translation form exists for (s, t) in T , it can be easily verified
that
?
(s,t)????
PTP(s, t) = 1
That is, PTP is a joint distribution on ?
 ? ? which will be called the stochastic
translation defined by TP. 4
Finally, the translation of a source string s ? ? by a stochastic finite-state trans-
ducer TP is
t? = argmax
t??
PTP(s, t) (4)
3 For the sake of simplicity, we will denote Pr(X = x) as Pr(x) and Pr(X = x | Y = y) as Pr(x | y).
4 This concept is similar to the stochastic regular language for a stochastic regular grammar. In that
case, the probability distribution is defined on the set of finite-length strings rather than on the set of
pairs of strings.
208
Computational Linguistics Volume 30, Number 2
A stochastic finite-state transducer has stochastic source and target regular languages
embedded (Pi and Po, respectively.):
Pi(s) =
?
t??
PTP(s, t), Po(t) =
?
s??
PTP(s, t)
In practice, these source or target regular languages are obtained, by dropping the
target or the source symbols, respectively, from each transition of the finite-state trans-
ducer.
The following theorem naturally extends Theorem 1 to the stochastic framework
(Casacuberta, Vidal, and Pico? 2004):
Theorem 2
A distribution PT : ? ? ? ? [0, 1] is a stochastic rational translation if and only if there
exist an alphabet ?, two morphisms h? : ? ? ? and h? : ? ? ?, and a stochastic regular
language PL such that, ?(s, t) ? ? ??,
PT(s, t) =
?
? ? ? :
(h?(?), h?(?)) = (s, t)
PL(?) (5)
3.1 Search with Stochastic Finite-State Transducers
The search for an optimal t? in Equation (4) has proved to be a difficult computational
problem (Casacuberta and de la Higuera 2000). In practice, an approximate solution
can be obtained (Casacuberta 2000) on the basis of the following approximation to the
probability of a translation pair (Viterbi score of a translation):
PTP(s, t) ? VTP(s, t) = max
??d(s,t)
PTP(?) (6)
An approximate translation can now be computed as
t? = argmax
t??
VTP(s, t) = argmax
t??
max
??d(s,t)
PTP(?) (7)
This computation can be carried out efficiently (Casacuberta 1996) by solving the
following recurrence by means of dynamic programming:
max
t???
VTP(s, t) = max
q?Q
(
V(|s|, q) ? f (q)
)
(8)
V(i, q) = max
q??Q,w??
(
V(i ? 1, q?) ? p(q?, si, w, q)
)
if i = 0, q = q0 (9)
V(0, q0) = 1 (10)
Finally, the approximate translation t? is obtained as the concatenation of the target
strings associated with the translation form
?? = (q0, s1, t?1, q1)(q1, s2, t?2, q2) . . . (qI?1, sI?1, t?I, qI),
corresponding to the optimal sequence of states involved in the solution to Equa-
tion (8); that is,
t? = t?1 t?2 . . . t?I
209
Casacuberta and Vidal Translation with Finite-State Transducers
0 1una / a  (1.0)
2camera / double (0.3)
4camera / ?   (0.3)
6
camera / room (0.4)
3doppia / room (1.0)
5doppia / double room (1.0)
7doppia / with two beds (1.0)
Figure 1
Example of Viterbi score-based suboptimal result. The probability PTP of the pair una camera
doppia/a double room is (1.0 ? 0.3 ? 1.0) + (1.0 ? 0.3 ? 1.0) = 0.6. This is greater than the probability
PTP of the pair una camera doppia/a room with two beds, 1.0 ? 0.4 ? 1.0 = 0.4. However, the Viterbi
score VTP for the first pair is 1.0 ? 0.3 ? 1.0 = 0.3, which is lower than the Viterbi score VTP for
the second pair, 1.0 ? 0.4 ? 1.0 = 0.4. Therefore this second pair will be the approximate result
given by equation (7).
The computational cost of the iterative version of this algorithm is O(| s | ? |Q| ? B),
where B is the (average) branching factor of the finite-state transducer.
Figure 1 shows a simple example in which Viterbi score maximization (7) leads to
a suboptimal result.
4. A Method for Inferring Finite-State Transducers
Theorems 1 and 2 establish that any (stochastic) rational translation T can be obtained
as a homomorphic image of certain (stochastic) regular language L over an adequate
alphabet ?. The proofs of these theorems are constructive (Berstel 1979; Casacuberta,
Vidal, and Pico? 2004) and are based on building a (stochastic) finite-state transducer T
for T by applying certain morphisms h? and h? to the symbols of ? that are associated
with the rules of a (stochastic) regular grammar that generates L.
This suggests the following general technique for learning a stochastic finite-state
transducer, given a finite sample A of string pairs (s, t) ? ??? ( a parallel corpus):
1. Each training pair (s, t) from A is transformed into a string z from an
extended alphabet ? (strings of ?-symbols) yielding a sample S of
strings S ? ?.
2. A (stochastic) regular grammar G is inferred from S.
3. The ?-symbols of the grammar rules are transformed back into pairs of
source/target symbols/strings (from ? ??).
This technique, which is very similar to that proposed in Garc??a, Vidal, and Casacu-
berta (1987) for the inference of regular grammars, is illustrated in Figure 2.
The first transformation is modeled by the labeling function L : ? ? ? ? ?,
while the last transformation is carried out by an ?inverse labeling function? ?(?), that
is, one such that ?(L(A)) = A. Following Theorems 1 and 2, ?(?) consists of a couple
of morphisms, h?, h?, such that for a string z ? ?, ?(z) = (h?(z), h?(z)).
Without loss of generality, we assume that the method used in the second step of
the proposed method consists of the inference of n-grams (Ney, Martin, and Wessel
1997) with final states, which are particular cases of stochastic regular grammars. This
simple method automatically derives, from the strings in S, both the structure of G
(i.e., the rules?states and transitions) and the associated probabilities.
Since ? is typically the inverse of L, the morphisms h? and h? needed in the
third step of the proposed approach are determined by the definition of L. So a key
210
Computational Linguistics Volume 30, Number 2
Figure 2
Basic scheme for the inference of finite-state transducers. A is a finite sample of training pairs.
S is the finite sample of strings obtained from A using L. G is a grammar inferred from S such
that S is a subset of the language, L(G), generated by the grammar G. T is a finite-state
transducer whose translation (T(T )) includes the training sample A.
point in this approach is its first step, that is, how to conveniently transform a parallel
corpus into a string corpus. In general, there are many possible transformations, but
if the source?target correspondences are complex, the design of an adequate transfor-
mation can become difficult. As a general rule, the labeling process must capture these
source?target word correspondences and must allow for a simple implementation of
the inverse labeling needed in the third step.
A very preliminary, nonstochastic version of this finite-state transducer inference
technique was presented in Vidal, Garc??a, and Segarra (1989) An important drawback
of that early proposal was that the methods proposed for building the ? sentences
from the training pairs did not adequately cope with the dependencies between the
words of the source sentences and the words of the corresponding target sentences. In
the following section we show how this drawback can be overcome using statistical
alignments (Brown et al 1993).
The resulting methodology is called grammatical inference and alignments for
transducer inference (GIATI).5 A related approach was proposed in Bangalore and
Ricardi (2000b). In that case, the extended symbols were also built according to pre-
viously computed alignments, but the order of target words was not preserved. As a
consequence, that approach requires a postprocess to try to restore the target words
to a proper order.
4.1 Statistical Alignments
The statistical translation models introduced by Brown et al (1993) are based on the
concept of alignment between source and target words (statistical alignment mod-
els). Formally, an alignment of a translation pair (s, t) ? ? ? ? is a function
a : {1, . . . , |t|} ? {0, . . . , | s |}. The particular case a(j) = 0 means that the position j
in t is not aligned with any position in s. All the possible alignments between t and
s are denoted by A(s, t), and the probability of translating a given s into t by an
alignment a is Pr(t, a | s).
Thus, an optimal alignment between s and t can be computed as
a? = argmax
a?A(s,t)
Pr(t, a | s) (11)
5 In previous work, this idea was often called morphic generator transducer inference.
211
Casacuberta and Vidal Translation with Finite-State Transducers
Different approaches for estimating Pr(t, a | s) were proposed in Brown et al (1993).
These approaches are known as models 1 through 5. Adequate software packages are
publicly available for training these statistical models and for obtaining good align-
ments between pairs of sentences (Al-Onaizan et al 1999; Och and Ney 2000). An
example of Spanish-English sentence alignment is given below:
Example 1
? Cua?nto cuesta una habitacio?n individual por semana ?
how (2) much (2) does (3) a (4) single (6) room (5) cost (3) per (7) week (8) ? (9)
Each number within parentheses in the example represents the position in the source
sentence that is aligned with the (position of the) preceding target word. A graphical
representation of this alignment is shown in Figure 3.
4.2 First Step of the GIATI Methodology: Transformation of Training Pairs into
Strings
The first step of the proposed method consists in a labeling process (L) that builds a
string of certain extended symbols from each training string pair and its corresponding
statistical alignment. The main idea is to assign each word from t to the corresponding
word from s given by the alignment a. But sometimes this assignment produces a
violation of the sequential order of the words in t. To illustrate the GIATI methodology
we will use example 2:
Figure 3
Graphical representation of the alignment between a source (Spanish) sentence (? Cua?nto cuesta
una habitacio?n individual por semana ?) and a target (English) sentence (How much does a single
room cost per week ?). Note the correspondence between the Spanish cuesta and the English does
and cost. Note also that the model does not allow for alignments between sets of two or more
source words and one target word.
212
Computational Linguistics Volume 30, Number 2
Example 2
Let A be a training sample composed by the following pairs (Italian/English):
una camera doppia # a double room
una camera # a room
la camera singola # the single room
la camera # the room
Suitable alignments for these pairs are
una camera doppia # a (1) double (3) room (2)
una camera # a (1) room (2)
la camera singola # the (1) single (3) room (2)
la camera # the (1) room (2)
In the first pair of this example, the English word double could be assigned to
the third Italian word (doppia) and the English word room to the second Italian word
(camera). This would imply a ?reordering? of the words double and room, which is not
appropriate in our finite-state framework.
Given s, t, and a (source and target strings and associated alignment, respectively),
the proposed transformation z = L1(s, t) avoids this problem as follows:
| z | = | s |
1 ? i ? | z |
zi =
?
?
?
(si , tj tj+1 . . . tj+l) if ?j : a(j) = i and ?| j? < j : a(j?) > a(j)
and for j?? : j ? j?? ? j + l, a(j??) ? a(j)
(si , ?) otherwise
Each word from t is joined with the corresponding word from s given by the alignment
a if the target word order is not violated. Otherwise, the target word is joined with
the first source word that does not violate the target word order.
The application of L1 to example 2 generates the following strings of extended
symbols:
(una , a) (camera , ?) (doppia , double room)
(una , a) (camera , room)
(la , the) (camera , ?) (singola , single room)
(la , the) (camera , room)
As a more complicated example, the application of this transformation to example 1
generates the following string:
(? , ?) (Cua?nto , how much) (cuesta , does) (una , a) (habitacio?n , ?)
(individual , single room cost) (por , per) (semana , week) (? , ?)
In this case the unaligned token ? has an associated empty target string, and the
target word cost, which is aligned with the source word cuesta, is associated with the
nearby source word individual. This avoids a ?reordering? of the target string and
entails an (apparently) lower degree of nonmonotonicity. This is achieved, however,
at the expense of letting the method generalize from word associations which can be
considered improper from a linguistic point of view (e.g., (cuesta, does), (individual, single
213
Casacuberta and Vidal Translation with Finite-State Transducers
room cost)). While this would certainly be problematic for general language translation,
it proves not to be so harmful when the sentences to be translated come from limited-
domain languages.
Obviously, other transformations are possible. For example, after the application of
the above procedure, successive isolated source words (without any target word) can
be joined to the first extended word which has target word(s) assigned. Let z = L1(s, t)
be a transformed string obtained from the above procedure and let
(sk?1 , tj tj+1 . . . tj+m)(sk , ?) . . . (sk+l?1 , ?)(sk+l , tj+m+1 . . . tj+n)
be a subsequence within z. Then the subsequence
(sk , ?) . . . (sk+l?1 , ?)(sk+l , tj+m+1 . . . tj+n)
is transformed by L2 into
(sk . . . sk+l?1 sk+l , tj+m+1 . . . tj+n)
The application of L2 to example 2 leads to
(una , a) (camera doppia , double room)
(una , a) (camera , room)
(la , the) (camera singola , single room)
(la , the) (camera , room)
Although many other sophisticated transformations can be defined following the
above ideas, only the simple L1 will be used in the experiments reported in this article.
4.3 Second Step of the GIATI Methodology: Inferring a Stochastic Regular Grammar
from a Set of Strings
Many grammatical inference techniques are available to implement the second step
of the proposed procedure. In this work, (smoothed) n-grams are used. These models
have proven quite successful in many areas such as language modeling (Clarkson and
Rosenfeld 1997; Ney, Martin, and Wessel 1997).
Figures 4 and 5 show the (nonsmoothed) bigram models inferred from the sample
obtained using L1 and L2, respectively, in example 2. Note that the generalization
achieved by the first model is greater than that of the second.
The probabilities of the n-grams are computed from the corresponding counts in
the training set of extended strings. The probability of an extended word zj = (si, t?i)
given the sequence of extended words zi?n+1, . . . , zi?1 = (si?n+1, t?i?n+1) . . . (si?1, t?i?1)
0
1(una , a)
4
(la , the)
2
(camera , ?  )
5
(camera , room)
3(doppia , double room)
6
(singola , single room)
(camera , ?  )
(camera , room)
Figure 4
Bigram model inferred from strings obtained by the transformation L1 in example 2.
214
Computational Linguistics Volume 30, Number 2
0
1(una , a)
4
(la , the)
2(camera doppia , double room)
3
(camera , room)
(camera , room)
5
(camera singola , single room)
Figure 5
Bigram model inferred from strings obtained by the transformation L2 in example 2.
is estimated as
pn(zi | zi?n+1 . . . zi?1) =
c(zi?n+1, . . . , zi?1, zi)
c(zi?n+1, . . . , zi?1)
(12)
where c(?) is the number of times that an event occurs in the training set. To deal with
unseen n-grams, the back-off smoothing technique from the CMU Statistical Language
Modeling (SLM) Toolkit (Rosenfeld 1995) has been used.
The (smoothed) n-gram model obtained from the set of extended symbols is repre-
sented as a stochastic finite-state automaton (Llorens, Vilar, and Casacuberta 2002). The
states of the automaton are the observed (n ? 1)-grams. For the n-gram (zi?n+1 . . . zi),
there is a transition from state (zi?n+1 . . . zi?1) to state (zi?n+2 . . . zi) with the associ-
ated extended word zi and a probability pn(zi | zi?n+1 . . . zi?1). The back-off smoothing
method supplied by the SLM Toolkit is represented by the states corresponding to k-
grams (k < n) and by special transitions between k-gram states and (k ? 1)-gram
states (Llorens, Vilar, and Casacuberta 2002). The final-state probability is computed
as the probability of a transition with an end-of-sentence mark.
4.4 Third Step of the GIATI Methodology: Transforming a Stochastic Regular Gram-
mar into a Stochastic Finite-State Transducer
In order to obtain a finite-state transducer from a grammar of L1?transformed symbols,
an ?inverse transformation? ?(?) is used which is based on two simple morphisms:
if (a, b1b2 . . . bk) ? ? with a ? ? and b1, b2, . . . , bk ? ?,
h?((a, b1b2 . . . bk)) = a
h?((a, b1b2 . . . bk)) = b1 b2 . . . bk
It can be verified that this constitutes a true inverse transformation; that is, for every
training pair ?(s, t) ? A
s = h?(L1(s, t)), t = h?(L1(s, t))
If zi is a transition of the inferred regular grammar, where zi = (a, b1b2 . . . bk) ? ?, the
corresponding transition of the resulting finite-state transducer is (q, a, b1b2 ? ? ? bk, q?).
This construction is illustrated in Figures 6 and 7 for the bigrams of Figures 4 and 5,
respectively. Note that in the second case, this construction entails the trivial addition of
a few states which did not exist in the corresponding bigram. As previously discussed,
the first transformation (L1) definitely leads to a greater translation generalization than
the second (L2) (Casacuberta, Vidal, and Pico? 2004). The probabilities associated with
215
Casacuberta and Vidal Translation with Finite-State Transducers
0
1una / a
4
la / the
2camera / ?
5
camera / room
3doppia / double room
6
singola / single room
camera / ?
camera / room
Figure 6
A finite-state transducer built from the n-gram of Figure 4.
0
1una / a
4
la / the
camera  / ?  
3
camera / room
2doppia / double room
camera / room
camera  / ?  
5singola / single room
Figure 7
A finite-state transducer built from the n-gram of Figure 5.
the transitions and the final states of the finite-state transducer are the same as those
of the original stochastic regular grammar.
Since we are using n-grams in the second step, a transition (q, a, b1b2 ? ? ? bk, q?) is in
the finite-state transducer if the states q and q? are (zi?n+1 . . . zi?1), (zi?n+2 . . . zi), respec-
tively, and (a, b1b2 ? ? ? bk) is zi. The probability of the transition is pn(zi | zi?n+1 . . . zi?1).
The transitions associated with back-off are labeled with a special source symbol (not
in the source vocabulary) and with an empty target string. The number of states is
the overall number of k-grams (k < n) that appear in the training set of extended
strings plus one (the unigram state). The number of transitions is the overall num-
ber of k-grams (k ? n) plus the number of states (back-off transitions). The actual
number of these k-grams depends on the degree of nonmonotonicity of the original
bilingual training corpus. If the corpus if completely monotone, this number would be
approximately the same as the number of k-grams in the source or target parts of the
training corpus. If the corpus in not monotone, the vocabulary of expanded strings
becomes large, and the number of k-grams can be much larger than the number of
training source or target k-grams. As a consequence, an interesting property of this
type of transformations is that the source and target languages embedded in the final
finite-state transducer are more constrained than the corresponding n-gram models
obtained from either the source or the target strings, respectively, of the same training
pairs (Casacuberta, Vidal, and Pico? 2004).
While n-grams are deterministic (hence nonambiguous) models, the finite-state
transducers obtained after the third-step inverse transformations (h?, h?) are often
nondeterministic and generally ambiguous; that is, there are source strings which can
be parsed through more than one path. This is in fact a fundamental property, directly
coming from expression (5) of Theorem 2, on which the whole GIATI approach is
essentially based. As a consequence, all the search issues discussed in Section 3.1 do
apply to GIATI-learned transducers.
216
Computational Linguistics Volume 30, Number 2
5. Experimental Results
Different translation tasks of different levels of difficulty were selected to assess the
capabilities of the proposed inference method in the framework of the EuTrans
project (ITI et al 2000): two Spanish-English tasks (EuTrans-0 and EuTrans-I),
an Italian-English task (EuTrans-II) and a Spanish-German task (EuTrans-Ia). The
EuTrans-0 task, with a large semi-automatically generated training corpus, was used
for studying the convergence of transducer learning algorithms for increasingly large
training sets (Amengual et al 2000). In this article it is used to get an estimation of per-
formance limits of the GIATI technique by assuming an unbounded amount of training
data. The EuTrans-I task was similar to EuTrans-0 but with a more realistically sized
training corpus. This corpus was defined as a first benchmark in the EuTrans project,
and therefore results with other techniques are available. The EuTrans-II task, with a
quite small and highly spontaneous natural training set, was a second benchmark of
the project. Finally, EuTrans-Ia was similar to EuTrans-I, but with a higher degree
of nonmonotonicity between corresponding words in input/output sentence pairs.
Tables 1, 4, and 7 show some important features of these corpora. As can be seen in
these tables, the training sets of EuTrans-0, EuTrans-I and EuTrans-Ia contain non-
negligible amounts of repeated sentence pairs. Most of these repetitions correspond
to simple and/or usual sentences such as good morning, thank you, and do you have a
single room for tonight. The repetition rate is quite significant for EuTrans-0, but it was
explicitly reduced in the more realistic benchmark tasks EuTrans-I and EuTrans-Ia.
It is worth noting, however, that no repetitions appear in any of the test sets of these
tasks. While repetitions can be helpful for probability estimation, they are completely
useless for inducing the transducer structure. Moreover, since no repetitions appear
in the test sets, the estimated probabilities will not be as useful as they could be if
test data repetitions exhibited the same patterns as those in the corresponding training
materials.
In all the experiments reported in this article, the approximate optimal translations
(equation (7)) of the source test strings were computed and the word error rate (WER),
the sentence error rate (SER), and the bilingual evaluation understudy (BLEU) metric
for the translations were used as assessment criteria. The WER is the minimum number
of substitution, insertion, and deletion operations needed to convert the word string
hypothesized by the translation system into a given single reference word string (ITI
et al 2000). The SER is the result of a direct comparison between the hypothesized and
reference word strings as a whole. The BLEU metric is based on the n-grams of the
hypothesized translation that occur in the reference translations (Papineni et al2001).
The BLEU metric ranges from 0.0 (worst score) to 1.0 (best score).
5.1 The Spanish-English Translation Tasks
A Spanish-English corpus was semi-automatically generated in the first phase of the
EuTrans project (Vidal 1997). The domain of the corpus involved typical human-to-
human communication situations at a reception desk of a hotel.
A summary of this corpus (EuTrans-0) is given in Table 1 (Amengual et al2000;
Casacuberta et al 2001). From this (large) corpus, a small subset of ten thousand
training sentence pairs (EuTrans-I) was randomly selected in order to approach more
realistic training conditions (see also Table 1). From these data, completely disjoint
training and test sets were defined. It was guaranteed, however, that all the words in
the source test sentences were contained in both training sets (closed vocabulary).
Results for the EuTrans-0 and EuTrans-I corpora are presented in Tables 2 and 3,
respectively. The best results obtained using the proposed technique were 3.1% WER
217
Casacuberta and Vidal Translation with Finite-State Transducers
Table 1
The Spanish-English corpus. There was no overlap between
training and test sentences, and the test set did not contain
out-of-vocabulary words with respect to any of the training sets.
Spanish English
EuTrans-0 Train: Sentence pairs 490,000
Distinct pairs 168,629
Running words 4,655,000 4,802,000
Vocabulary 686 513
EuTrans-I Train: Sentence pairs 10,000
Distinct pairs 6,813
Running words 97,131 99,292
Vocabulary 683 513
Test: Sentences 2,996
Running words 35,023 35,590
EuTrans-0 Bigram test perplexity 6.8 5.8
EuTrans-I Bigram test perplexity 8.6 6.3
Table 2
Results with the standard corpus EuTrans-0. The
underlying regular models were smoothed n-grams for
different values of n.
n-grams States Transitions WER % SER % BLEU
2 4,056 67,235 8.8 50.0 0.86
3 33,619 173,500 4.7 27.2 0.94
4 110,321 364,373 4.2 23.2 0.94
5 147,790 492,840 3.8 20.5 0.95
6 201,319 663,447 3.6 19.0 0.96
7 264,868 857,275 3.4 18.0 0.96
8 331,598 1,050,949 3.3 17.4 0.96
9 391,812 1,218,367 3.3 17.2 0.96
10 438,802 1,345,278 3.2 16.8 0.96
11 471,733 1,432,027 3.1 16.4 0.96
12 492,620 1,485,370 3.1 16.4 0.96
Table 3
Results with the standard corpus EuTrans-I. The
underlying regular models were smoothed n-grams for
different values of n.
n-grams States Transitions WER % SER % BLEU
2 1,696 17,121 9.0 53.7 0.86
3 8,562 36,763 6.7 38.9 0.90
4 21,338 64,856 6.7 37.9 0.91
5 23,879 72,006 6.6 37.1 0.91
6 25,947 77,531 6.6 37.0 0.91
7 27,336 81,076 6.6 37.0 0.91
218
Computational Linguistics Volume 30, Number 2
for EuTrans-0 and 6.6% WER for EuTrans-I. These results were achieved using the
statistical alignments provided by model 5 (Brown et al 1993; Och and Ney 2000) and
smoothed 11-grams and 6-grams, respectively.
These results were obtained using the first type of transformation described in
Section 4.2 (L1). Similar experiments with the second type of transformation (L2) pro-
duced slightly worse results. However, L2 is interesting because many of the extended
symbols obtained in the experiments involve very good relations between some source
word groups and target word groups which could be useful by themselves. Conse-
quently, more research work has to be done with this second type of transformation.
The results on the (benchmark) EuTrans-I corpus can be compared with those
obtained using other approaches. GIATI outperforms other finite-state techniques in
similar experimental conditions (with a best result of 8.3% WER, using another trans-
ducer inference technique called OMEGA [ITI et al 2000]). On the other hand, the
best result achieved by the statistical templates technique (Och and Ney 2000) was
4.4% WER (ITI et al 2000). However, this result cannot be exactly compared with
that achieved by GIATI, because the statistical templates approach used an explicit
(automatic) categorization of the source and the target words, while only the raw
word forms were used in GIATI. Although GIATI is compatible with different forms
of word categorization, the required finite-state expansion is not straightforward, and
some work is still needed in order to actually allow this technique to be taken advan-
tage of.
5.2 The Italian-English Task
The Italian-English translation task of the EuTrans project (ITI et al 2000) consisted
of spoken person-to-person telephone communications in the framework of a hotel
reception desk. A text corpus was collected with the transcriptions of dialogues of this
type, along with the corresponding (human-produced) translations. A summary of the
corpus used in the experiments (EuTrans-II) is given in Table 4. There was a small
overlap of seven pairs between the training set and the test set, but in this case, the
vocabulary was not closed (there were 107 words in the test set that did not exist in
the training-set vocabulary). The processing of words out of the vocabulary was very
simple in this experiment: If the word started with a capital letter, the translation was
the source word; otherwise it was the empty string.
The same translation procedure and evaluation criteria used for EuTrans-0 and
EuTrans-I were used for EuTrans-II. The results are reported in Table 5.
Table 4
The EuTrans-II corpus. There was a small
overlap of seven pairs between the training and
test sets, but 107 source words in the test set were
not in the (training-set-derived) vocabulary.
Italian English
Train: Sentence pairs 3,038
Running words 55,302 64,176
Vocabulary 2,459 1,712
Test: Sentences 300
Running words 6,121 7,243
Bigram test perplexity 31 25
219
Casacuberta and Vidal Translation with Finite-State Transducers
Table 5
Results with the standard EuTrans-II corpus. The
underlying regular models were smoothed
n-grams (Rosenfeld 1995) for different values of n.
n-grams States Transitions WER % SER % BLEU
2 5,909 49,701 27.2 96.7 0.56
3 24,852 97,893 27.3 96.0 0.56
4 54,102 157,073 27.4 96.0 0.56
Table 6
Results with the standard EuTrans-II corpus. The
underlying regular models were smoothed n-grams
(Rosenfeld 1994) for different values of n. The training
set was (automatically) segmented using a priori
knowledge. The statistical alignments were constrained
to be within each parallel segment.
n-grams States Transitions WER % SER % BLEU
2 6,300 52,385 24.9 93.0 0.62
3 26,194 102,941 25.5 93.3 0.61
4 56,856 164,972 25.5 93.3 0.61
This corpus contained many long sentences, most of which were composed of
rather short segments connected by punctuation marks. Typically, these segments can
be monotonically aligned with corresponding target segments using a simple dynamic
programming procedure (prior segmentation) (ITI et al 2000). We explored computing
the statistical alignments within each pair of segments rather than in the entire sen-
tences. Since the segments were shorter than the whole sentences, the alignment prob-
ability distributions were better estimated. In the training phase, extended symbols
were built from these alignments, and the strings of extended symbols corresponding
to the segments of the same original string pair were concatenated. Test sentences
were directly used, without any kind of segmentation.
The translation results using prior segmentation are reported in Table 6. These
results were clearly better than those of the corresponding experiments with nonseg-
mented training data.
The accuracy of GIATI in the EuTrans-II experiments was significantly worse
than that achieved in EuTrans-I, and best performance is obtained with a lower-order
n-gram. One obvious reason for this behavior is that this corpus is far more sponta-
neous than the first one, and consequently, it has a much higher degree of variability.
Moreover, the training data set is about three times smaller than the corresponding
data of EuTrans-I, while the vocabularies are three to four times larger.
The best result achieved with the proposed technique on EuTrans-II was 24.9%
WER, using prior segmentation of the training pairs and a smoothed bigram model.
This result was comparable to the best among all those reported in RWTH Aachen and
ITI (1999). The previously mentioned statistical templates technique achieved 25.1%
WER in this case. In this application, in which categories are not as important as in
EuTrans-I, statistical templates and GIATI achieved similar results.
220
Computational Linguistics Volume 30, Number 2
Table 7
The Spanish-German corpus. There was no overlap
between training and test sets and no
out-of-vocabulary words in the test set.
Spanish German
Train: Sentence pairs 10,000
Distinct pairs 6,636
Running words 96,043 90,099
Vocabulary 6,622 4,890
Test: Sentences 2,862
Running words 33,542 31,103
Bigram test perplexity 8.3 6.6
Table 8
Results with the standard corpus EuTrans-Ia. The
underlying regular models were smoothed n-grams for
different values of n.
n-grams States Transitions WER % SER % BLEU
2 2,441 21,181 16.0 78.1 0.74
3 10,592 43,294 11.3 65.3 0.82
4 24,554 74,412 10.6 62.3 0.83
5 27,748 83,553 10.6 62.5 0.83
6 30,501 91,055 10.6 62.4 0.83
7 32,497 96,303 10.7 62.7 0.83
5.3 The Spanish-German Task
The Spanish-German translation task is similar to EuTrans-I, but here the target
language is German instead of English. It should be noted that Spanish syntax is
significantly more different from that of German than it is from that of English, and
therefore, the corresponding corpus exhibited a higher degree of nonmonotonicity. The
features of this corpus (EuTrans-Ia) are summarized in Table 7. There was no overlap
between training and test sets, and the vocabulary was closed.
The translation results are reported in Table 8. As expected from the higher degree
of nonmonotonicity of the present task, these results were somewhat worse than those
achieved with EuTrans-I. This is consistent with the larger number of states and
transitions of the EuTrans-Ia models: The higher degree of word reordering of these
models is achieved at the expense of a larger number of extended words.
The way GIATI transducers cope with these monotonicity differences can be more
explicitly illustrated by estimating how many target words are produced after some
delay with respect to the source. While directly determining (or even properly defin-
ing) the actual production delay for each individual (test) word is not trivial, an
approximation can be indirectly derived from the number of target words that are
preceded by sequences of ? symbols (from target-empty transitions) in the parsing of
a source test text with a given transducer. This has been done for the EuTrans-I and
EuTrans-Ia test sets with GIATI transducers learned with n = 6. On the average, the
EuTrans-I transducer needed to introduce delays ranging from one to five positions
for approximately 15% of the English target words produced, while the transducer
for EuTrans-Ia had to introduce similar delays for about 20% of the German target
words produced.
221
Casacuberta and Vidal Translation with Finite-State Transducers
5.4 Error Analysis
The errors reported in the previous sections can be attributed to four main factors:
1. Correct translations which differ from the given (single) reference
2. Wrong alignments of training pairs
3. Insufficient or improper generalization of n-gram-based GIATI learning
4. Wrong approximate Viterbi score?based search results
An informal inspection of the target sentences produced by GIATI in all the experi-
ments reveals that the first three factors are responsible for the vast majority of errors.
Table 9 shows typical examples for the results of the EuTrans-I experiment with
6-gram-based GIATI transducers.
The first three examples correspond to correct translations which have been wrong-
ly counted as errors (factor 1). Examples 4 and 5 are probably due to alignment prob-
lems (factor 2). In fact, more than half of the errors reported in the EuTrans-I experi-
ments are due to misuse or misplacement of the English word please. Examples 6?8 can
also be considered minor errors, probably resulting from factors 2 and 3. Examples 9
and 10 are clear undergeneralization errors (factor 3). These errors could have been
easily overcome through an adequate use of bilingual lexical categorization. Examples
11 and 12, finally, are more complex errors that can be attributed to (a combination of)
factors 2, 3, and 4.
6. Conclusions
A method has been proposed in this article for inferring stochastic finite-state trans-
ducers from stochastic regular grammars. This method, GIATI, allowed us to achieve
good results in several language translation tasks with different levels of difficulty. It
works better than other finite-state techniques when the training data are scarce and
achieves similar results with sufficient training data.
The GIATI approach produces transducers which generalize the information pro-
vided by the (aligned) training pairs. Thanks to the use of n-grams as a core learning
procedure, a wide range of generalization degrees can be achieved. It is well-known
that a 1-gram entails a maximum generalization, allowing (extended) words to follow
one another. On the other hand, for sufficiently large m, a (nonsmoothed) m-gram is just
an exact representation of the training strings (of extended words, in our case). Such a
representation can thus be considered a simple ?translation memory? that just contains
the (aligned) training pairs. For any new source sentence, this ?memory? can be eas-
ily and quite efficiently searched through finite-state parsing. For other intermediate
values of n, 1<n<m, GIATI obtains increasing degrees of generalization. As in the
case of language modeling, the generalization degree (n) has to be tuned so as to take
maximum advantage of the available training data. As training pairs become scarce,
more generalization is needed to allow GIATI to adequately accept new test sentences.
This behavior can be clearly observed throughout the results presented in this article.
Another feature of the GIATI approach is the use of smoothed n-grams of extended
words as the basic mechanism for producing smoothed transducers. The combination
of this feature with the intrinsic generalization provided by the n-gram modeling itself
has proved very adequate to deal with the problem of unseen source (sub)strings.
Obviously, the overall quality of the generalizations achieved by GIATI strongly
relies on the quality of the statistical alignments used and on the way word order
is preserved in the source-target strings of each training pair. Taking into account the
222
Computational Linguistics Volume 30, Number 2
Table 9
Examples of typical errors produced by a 6-gram-based GIATI
transducer in the the EuTrans-I task. For each Spanish source sentence,
the corresponding target reference and GIATI translations are shown in
successive lines.
1 ? les importar??a bajarnos nuestras bolsas a recepcio?n ?
would you mind sending our bags down to reception ?
would you mind sending down our bags to reception ?
2 explique la cuenta de la habitacio?n cuatro diecise?is .
explain the bill for room number four one six .
explain the bill for room number four sixteenth .
3 ? cua?nto vale una habitacio?n doble para cinco d??as incluyendo desayuno ?
how much is a double room including breakfast for five days ?
how much is a double room for five days including breakfast ?
4 por favor , deseo una habitacio?n individual para esta semana .
I want a single room for this week , please .
I want a single room for this week .
5 ? le importar??a despertarnos a las cinco ?
would you mind waking us up at five ?
would you mind waking us up at five , please ?
6 ? hay televisio?n , aire acondicionado y caja fuerte en las habitaciones ?
are there a tv , air conditioning and a safe in the rooms ?
is there a tv , air conditioning and a safe in the rooms ?
7 ? tiene habitaciones libres con tele?fono ?
do you have any rooms with a telephone available ?
do you have any rooms with a telephone ?
8 ? querr??a llamar a mi taxi ?
would you call my taxi , please ?
would you call my taxi for me , please ?
9 hemos de marcharnos el veintise?is de marzo por la tarde .
we should leave on March the twenty-sixth in the afternoon .
we should leave on March the twenty-seventh in the afternoon
10 por favor , ? nos podr??a dar usted la llave de la ochocientos ochenta y uno ?
could you give us the key to room number eight eight one , please ?
could you give us the key to room number eight oh eight one , please ?
11 quiero cambiarme de habitacio?n .
I want to change rooms .
I want to move .
12 ? tiene televisio?n nuestra habitacio?n ?
does our room have a tv ?
does our room ?
223
Casacuberta and Vidal Translation with Finite-State Transducers
finite-state nature of GIATI transducers, certain heuristics have been needed in order to
avoid a direct use of too-long-distance alignments (L1 in Section 4.2). This has proved
adequate for language pairs with not too different (syntactic) structure and more so
if the domains are limited. As we relax these restrictions, we might have to relax the
not-too-long-distance assumption correspondingly. In this respect, the bilingual word
reordering ideas of Vilar, Vidal, and Amengual (1996), Vidal (1997), and Bangalore and
Ricardi (2000a) may certainly prove useful in future developments.
Acknowledgments
This work has been partially supported by
the European Union under grants
IT-LTR-OS-30268, IST-2001-32091 and
Spanish project TIC 2000-1599-C02-01. The
authors wish to thank the anonymous
reviewers for their criticisms and
suggestions.
References
Al-Onaizan, Yaser, Jan Curin, Michael Jahr,
Kevin Knight, John Lafferty, Dan
Melamed, Franz-Josef Och, David Purdy,
Noah A. Smith, and David Yarowsky.
1999. Statistical machine translation. Final
Report, JHU Workshop, Johns Hopkins
University, Baltimore.
Amengual, Juan-Carlos, Jose-Miguel Bened??,
Francisco Casacuberta, Asuncio?n Casta
no, Antonio Castellanos, V??ctor Jime?nez,
David Llorens, Andre?s Marzal, Moise?s
Pastor, Federico Prat, Enrique Vidal, and
Juan-Miguel Vilar. 2000. The EUTRANS-I
speech translation system. Machine
Translation Journal, 15(1?2):75?103.
Bangalore, Srinivas and Giuseppe Ricardi.
2000a. Finite-state models for lexical
reordering in spoken language
translation. In Proceedings of the
International Conference on Speech and
Language Processing, Beijing, China,
October.
Bangalore, Srinivas and Giuseppe Ricardi.
2000b. Stochastic finite-state models for
spoken language machine translation. In
Proceedings of the Workshop on Embedded
Machine Translation Systems, North
American Association for Computational
Linguistics, pages 52?59, Seattle, May.
Bangalore, Srinivas and Giuseppe Ricardi.
2001. A finite-state approach to machine
translation. In Proceedings of the Second
Meeting of the North American Chapter of the
Association for Computational Linguistics
2001, Pittsburgh, May.
Berstel, Jean. 1979. Transductions and
context-free languages. B. G. Teubner,
Stuttgart.
Brown, Peter F., Stephen A. Della Pietra,
Vincent J. Della Pietra, and Robert L.
Mercer. 1993. The mathematics of
statistical machine translation: Parameter
estimation. Computational Linguistics,
19(2):263?310.
Casacuberta, Francisco. 1996. Maximum
mutual information and conditional
maximum likelihood estimation of
stochastic regular syntax-directed
translation schemes. In Grammatical
Inference: Learning Syntax from Sentences
(volume 1147 of Lecture Notes on
Computer Science). Springer-Verlag,
Berlin and Heidelberg, pages 282?291.
Casacuberta, Francisco. 2000. Inference of
finite-state transducers by using regular
grammars and morphisms. In Grammatical
Inference: Algorithms and Applications
(volume 1891 of Lecture Notes in
Artificial Intelligence). Springer-Verlag,
Berlin and Heidelberg, pages 1?14.
Casacuberta, Francisco and Colin de la
Higuera. 2000. Computational complexity
of problems on probabilistic grammars
and transducers. In Grammatical Inference:
Algorithms and Applications (volume 1891
of Lecture Notes in Artificial Intelligence).
Springer-Verlag, Berlin and Heidelberg,
pages 15?24.
Casacuberta, Francisco, David Llorens,
Carlos Mart??nez, Sirko Molau, Francisco
Nevado, Hermann Ney, Moisee?s Pastor,
David Pico?, Alberto Sanchis, Enrique
Vidal, and Juan-Miguel Vilar. 2001.
Speech-to-speech translation based on
finite-state transducers. In Proceedings of
the IEEE International Conference on
Acoustic, Speech and Signal Processing,
volume 1. IEEE Press, Piscataway, NJ,
pages 613?616.
Casacuberta, Francisco, Enrique Vidal, and
David Pico?. 2004. Inference of finite-state
transducers from regular languages.
Pattern Recognition, forthcoming.
Clarkson, Philip and Ronald Rosenfeld.
1997. Statistical language modeling using
the CMU-Cambridge toolkit. In
Proceedings of EUROSPEECH, volume 5,
pages 2707?2710, Rhodes, September.
Fu, King-Sun. 1982. Syntactic pattern
recognition and applications. Prentice-Hall,
Englewood Cliffs, NJ.
224
Computational Linguistics Volume 30, Number 2
Garc??a, Pedro, Enrique Vidal, and Francisco
Casacuberta. 1987. Local languages, the
successor method, and a step towards a
general methodology for the inference of
regular grammars. IEEE Transactions on
Pattern Analysis and Machine Intelligence,
9(6):841?845.
Gonza?lez, Jorge, Ismael Salvador, Alejandro
Toselli, Alfons Juan, Enrique Vidal, and
Francisco Casacuberta. 2000. Offline
recognition of syntax-constrained cursive
handwritten text. In Advances in Pattern
Recognition (volume 1876 of Lecture Notes
in Computer Science). Springer-Verlag,
Berlin and Heidelberg, pages 143?153.
Hazen, Timothy, I. Lee Hetherington, and
Alex Park. 2001. FST-based recognition
techniques for multi-lingual and
multi-domain spontaneous speech. In
Proceedings of EUROSPEECH2001, pages
1591?1594, Aalborg, Denmark, September.
ITI, FUB, RWTH Aachen, and ZERES. 2000.
Example-based language translation
systems: Final report. Technical Report
D0.1c, Instituto Tecnolo?gico de
Informa?tica, Fondazione Ugo Bordoni,
Rheinisch Westfa?lische Technische
Hochschule Aachen Lehrstuhl fu?r
Informatik V and Zeres GmbH Bochum.
Information Technology. Long Term
Research Domain. Open scheme.
Knight, Kevin and Yaser Al-Onaizan. 1998.
Translation with finite-state devices. In
Proceedings of the Fourth. AMTA Conference
(volume 1529 of Lecture Notes in
Artificial Intelligence). Springer-Verlag,
Berlin and Heidelberg, pages 421?437.
Llorens, David, Juna-Miguel Vilar, and
Francisco Casacuberta. 2002. Finite state
language models smoothed using
n-grams. International Journal of Pattern
Recognition and Artificial Intelligence,
16(3):275?289.
Ma?kinen, Erkki. 1999. Inferring finite
transducers. Technical Report A-1999-3,
University of Tampere, Tampere, Finland.
Mohri, Mehryar. 1997. Finite-state
transducers in language and speech
processing. Computational Linguistics,
23(2):1?20.
Mou, Xiaolong, Stephanie Seneff, and Victor
Zue. 2001. Context-dependent
probabilistic hierarchical sub-lexical
modelling using finite-state transducers.
In Proceedings of EUROSPEECH2001, pages
451?454, Aalborg, Denmark, September.
Ney, Hermann, Sven Martin, and
Frank Wessel. 1997. Statistical language
modeling using leaving-one-out. In
S. Young and G. Bloothooft, editors,
Corpus-Based Statiscal Methods in Speech and
Language Processing. Kluwer Academic,
Dordrecht, the Netherlands, pages
174?207.
Och, Franz-Josef and Hermann Ney. 2000.
Improved statistical alignment models. In
Proceedings of the 38th Annual Meeting of the
Association for Computational Linguistics,
pages 440?447, Hong Kong, October.
Oncina, Jose?, Pedro Garc??a, and Enrique
Vidal. 1993. Learning subsequential
transducers for pattern recognition
interpretation tasks. IEEE Transactions on
Pattern Analysis and Machine Intelligence,
15(5):448?458.
Papineni, Kishore, Salim Roukos, Todd
Ward, and Wei-Jing Zhu. 2001. Bleu: A
method for automatic evaluation of
machine translation. Technical Report
RC22176(W?1?9-?22), IBM Research
Division, Yorktown Heights, NY,
September.
Rosenfeld, Ronald. 1995. The CMU
statistical language modeling toolkit and
its use in the 1994 ARPA CSR evaluation.
In Proceedings of the ARPA Spoken Language
Technology Workshop, Princeton, NJ.
Morgan Kaufmann, San Mateo, CA.
RWTH Aachen and ITI. 1999. Statistical
modeling techniques and results and
search techniques and results. Technical
Report D3.1a and D3.2a,
Rheinisch Westfa?lische Technis-
che Hochschule
Aachen Lehrstuhl fu?r Informatik VI and
Instituto Tecnolo?gico de Informa?tica.
Information Technology. Long Term
Research Domain. Open scheme.
Segarra, Encarna, Mar??a-Isabel Galiano
Emilio Sanchis, Fernando Garc??a, and
Luis Hurtado. 2001. Extracting semantic
information through automatic learning
techniques. In Proceedings of the Spanish
Symposium on Pattern Recognition and Image
Analysis, pages 177?182, Benicasim, Spain,
May.
Seward, Alexander. 2001. Transducer
optimizations for tight-coupled decoding.
In Proceedings of EUROSPEECH2001, pages
1607?1610, Aalborg, Denmark, September.
Vidal, Enrique. 1997. Finite-state
speech-to-speech translation. In
Proceedings of the International Conference on
Acoustic Speech and Signal Processing,
Munich. IEEE Press, Piscataway, NJ,
pages 111?114.
Vidal, Enrique, Francisco Casacuberta, and
Pedro Garc??a. 1995. Grammatical inference
and automatic speech recognition. In
A. Rubio, editor, New Advances and Trends
in Speech Recognition and Coding (volume
147 of NATO-ASI Series F: Computer and
225
Casacuberta and Vidal Translation with Finite-State Transducers
Systems Sciences). Springer-Verlag, Berlin
and Heidelberg, pages 174?191.
Vidal, Enrique, Pedro Garc??a, and Encarna
Segarra. 1989. Inductive learning of
finite-state transducers for the
interpretation of unidimensional objects.
In R. Mohr, T. Pavlidis, and A. Sanfeliu,
editors, Structural Pattern Analysis. World
Scientific, Singapore, pages 17?35.
Vilar, Juan-Miguel. 2000. Improve the
learning of subsequential transducers by
using alignments and dictionaries. In
Grammatical Inference: Algorithms and
Applications (volume 1891 of Lecture Notes
in Artificial Intelligence). Springer-Verlag,
Berlin and Heidelberg, pages 298?312.
Vilar, Juan-Miguel, Enrique Vidal, and
Juan-Carlos Amengual. 1996. Learning
extended finite state models for language
translation. In Andra?s Kornai, editor,
Proceedings of the Extended Finite State
Models of Language Workshop, pages 92?96,
Budapest, August.
Statistical Approaches to
Computer-Assisted Translation
Sergio Barrachina?
Universitat Jaume I
Oliver Bender??
RWTH Aachen
Francisco Casacuberta?
Universitat Polite`cnica de Vale`ncia
Jorge Civera?
Universitat Polite`cnica de Vale`ncia
Elsa Cubel?
Universitat Polite`cnica de Vale`ncia
Shahram Khadivi??
RWTH Aachen
Antonio Lagarda?
Universitat Polite`cnica de Vale`ncia
Hermann Ney??
RWTH Aachen
Jesu?s Toma?s?
Universitat Polite`cnica de Vale`ncia
Enrique Vidal?
Universitat Polite`cnica de Vale`ncia
Juan-Miguel Vilar?
Universitat Jaume I
Current machine translation (MT) systems are still not perfect. In practice, the output
from these systems needs to be edited to correct errors. A way of increasing the productivity of
the whole translation process (MT plus human work) is to incorporate the human correction
activities within the translation process itself, thereby shifting the MT paradigm to that of
computer-assisted translation. This model entails an iterative process in which the human
translator activity is included in the loop: In each iteration, a prefix of the translation is validated
(accepted or amended) by the human and the system computes its best (or n-best) translation
suffix hypothesis to complete this prefix. A successful framework for MT is the so-called statis-
tical (or pattern recognition) framework. Interestingly, within this framework, the adaptation
of MT systems to the interactive scenario affects mainly the search process, allowing a great
reuse of successful techniques and models. In this article, alignment templates, phrase-based
models, and stochastic finite-state transducers are used to develop computer-assisted translation
systems. These systems were assessed in a European project (TransType2) in two real tasks: The
translation of printer manuals; manuals and the translation of the Bulletin of the European
Union. In each task, the following three pairs of languages were involved (in both translation
directions): English?Spanish, English?German, and English?French.
? Departament d?Enginyeria i Cie`ncies dels Computadors, Universitat Jaume I, 12071 Castello? de la Plana,
Spain.
?? Lehrstuhl fu?r Informatik VI, RWTH Aachen University of Technology, D-52056 Aachen, Germany.
? Institut Tecnolo`gic d?Informa`tica, Departament de Sistemes Informa`tics i Computacio?, Universitat
Polite`cnica de Vale`ncia, 46071 Vale`ncia, Spain.
? Institut Tecnolo`gic d?Informa`tica, Departament de Comunicacions, Universitat Polite`cnica de Vale`ncia,
46071 Vale`ncia, Spain.
? Departament de Llenguatges i Sistemes Informa`tics, Universitat Jaume I, 12071 Castello? de la Plana,
Spain.
Submission received: 1 June 2006; revised submission received: 20 September 2007; accepted for publication:
19 December 2007.
? 2008 Association for Computational Linguistics
Computational Linguistics Volume 35, Number 1
1. Introduction to Computer-Assisted Translation
Research in the field of machine translation (MT) aims to develop computer systems
which are able to translate text or speech without human intervention. However,
present translation technology has not been able to deliver fully automated high-quality
translations. Typical solutions to improving the quality of the translations supplied by
an MT system require manual post-editing. This serial process prevents the MT system
from taking advantage of the knowledge of the human translator, and the human
translator cannot take advantage of the adaptive ability of the MT system.
An alternative way to take advantage of the existing MT technologies is to use
them in collaboration with human translators within a computer-assisted translation
(CAT) or interactive framework (Isabelle and Church 1997). Historically, CAT and MT
have been considered different but close technologies (Kay 1997) and more so for one
of the most popular CAT technologies, namely, translation memories (Bowker 2002;
Somers 2003). Interactivity in CAT has been explored for a long time. Systems have
been designed to interact with human translators in order to solve different types
of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al 1986).
Other interaction strategies have been considered for updating user dictionaries or for
searching through dictionaries (Slocum 1985; Whitelock et al 1986). Specific proposals
can be found in Tomita (1985), Zajac (1988), Yamron et al (1993), and Sen, Zhaoxiong,
and Heyan (1997), among others.
An important contribution to CAT technology, carried out within the TransType
project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster,
and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an
interesting focus shift in which interaction is directly aimed at the production of the
target text, rather than at the disambiguation of the source text, as in earlier interactive
systems. The idea proposed in that work was to embed data-driven MT techniques
within the interactive translation environment. The hope was to combine the best of
both paradigms: CAT, in which the human translator ensures high-quality output, and
MT, in which the machine ensures a significant gain in productivity.
Following these TransType ideas, the innovative embedding proposed here con-
sists in using a complete MT system to produce full target sentence hypotheses, or
portions thereof, which can be accepted or amended by a human translator. Each cor-
rect text segment is then used by the MT system as additional information to achieve
further, hopefully improved, suggestions. More specifically, in each iteration, a prefix
of the target sentence is somehow fixed by the human translator and, in the next itera-
tion, the system predicts a best (or n-best) translation suffix(es)1 to complete this prefix.
We will refer to this process as interactive-predictive machine translation (IPMT).
This approach introduces two important requirements: First, the models have to
provide adequate completions and, second, this has to happen efficiently. Taking these
requirements into account, stochastic finite-state transducers (SFSTs), alignment tem-
plates (ATs), and phrase-based models (PBMs) are compared in this work. In previous
works these models have proven adequate for conventional MT (Vidal 1997; Amengual
et al 2000; Ney et al 2000; Toma?s and Casacuberta 2001; Och and Ney 2003; Casacuberta
and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that
1 The terms prefix and suffix are used here to denote any substring at the beginning and end (respectively)
of a string of characters (including spaces and punctuation), with no implication of morphological
significance as is usually implied by these terms in linguistics.
4
Barrachina et al Statistical Computer-Assisted Translation
existing efficient searching algorithms can be adapted in order to provide completions
(rather than full translations) also in a very efficient way.
The work presented here has been carried out in the TransType2 (TT2) project
(SchlumbergerSema S.A. et al 2001), which is considered as a follow-up to the inter-
active MT concepts introduced in the precursory TransType project cited previously.
We should emphasize the novel contributions of the present work with respect
to TransType. First, we show how fully fledged statistical MT (SMT) systems can be
extended to handle IPMT. In particular, the TT2 systems always produce complete
sentence hypotheses on which the human translator can work. This is an important
difference to previous work, in which the use of basic MT techniques only allowed the
prediction of single tokens (c.f., Section 2.2). Second, using fully fledged SMT systems,
we have performed systematic offline experiments to simulate the specific conditions of
interactive translation and we report and study the results of these experiments. Thirdly,
the IPMT systems presented in this article were successfully used in several field trials
with professional translators (Macklovitch, Nguyen, and Silva 2005; Macklovitch 2006).
We should finally mention that the work developed in TT2 has gone beyond con-
ventional keyboard-and-mouse interaction, leading to the development of advanced
multi-modal interfaces. Speech is the most natural form of human communication and
its use as feedback in the IPMT framework has been explored by Vidal et al (2006).
On the other hand, human translators can be faster dictating the translation text rather
than typing it, thus it has also been investigated how to improve system performance
and usability when the user dictates the translation first and then edits the recognized
text (Khadivi, Zolnay, and Ney 2005; Khadivi, Zens, and Ney 2006).
The rest of the article is structured as follows. The next section introduces the
general setting for SMT and IPMT. In Section 3, AT, PBM, and SFST are briefly surveyed
along with the corresponding learning procedures. In Section 4, general search proce-
dures for the previous models are outlined and a detailed description of the extension
of these procedures to IPMT scenarios is presented. Section 5 is devoted to introducing
the tasks used for the assessment of the proposal presented in the previous sections:
the pairs of languages, corpora, and assessment procedures. The results are reported in
Section 6. A discussion of these results and the conclusions which can be drawn from
this work are presented in the final section.
2. Statistical Framework
The statistical or pattern recognition framework constitutes a very successful frame-
work for MT. As we will see here, this framework also proves adequate for IPMT.
2.1 Statistical Machine Translation
Assuming that we are given a sentence s in a source language, the text-to-text translation
problem can be stated as finding its translation t in a target language. Using statistical
decision theory, the best translation is given by the equation2
t? = argmax
t
Pr(t|s) (1)
2 We follow the common notation of Pr(x) for Pr(X = x) and Pr(x|y) for Pr(X = x|Y = y), for any random
variables X and Y. Similarly, Pr() will be used to denote ?true? probability functions, and p() or q() will
denote model approximations.
5
Computational Linguistics Volume 35, Number 1
Using Bayes?s Theorem, we arrive at
t? = argmax
t
Pr(t) ? Pr(s|t) (2)
This equation is generally interpreted as follows. The best translation must be a correct
sentence in the target language that conveys the meaning of the source sentence. The
probability Pr(t) represents the well-formedness of t and it is generally called the
language model probability (n-gram models are usually adopted [Jelinek 1998]). On
the other hand, Pr(s|t) represents the relationship between the two sentences (the source
and its translation). It should be of a high value if the source is a good translation of
the target and of a low value otherwise. Note that the translation direction is inverted
from what would be normally expected; correspondingly the models built around this
equation are often called inverted translation models (Brown et al 1990, 1993). As we
will see in Section 3, these models are based on the notion of alignment. It is interesting to
note that if we had perfect models, the use of Equation (1) would suffice. Given that we
have only approximations, the use of Equation (2) allows the language model to correct
deficiencies in the translation model.
In practice all of these models (and possibly others) are often combined into a log-
linear model for Pr(t | s) (Och and Ney 2004):
t? = argmax
t
{
N
?
i=1
?i ? log fi(t, s)
}
(3)
where fi(t, s) can be a model for Pr(s|t), a model for Pr(t|s), a target language model
for Pr(t), or any model that represents an important feature for the translation. N is the
number of models (or features) and ?i are the weights of the log-linear combination.
When using SFSTs, a different transformation can be used. These transducers
have an implicit target language model (which can be obtained from the finite-state
transducer by dropping the source symbols of each transition (Vidal et al 2005)). There-
fore, this separation is no longer needed. SFSTs model joint probability distributions;
therefore, Equation (1) has to be rewritten as
t? = argmax
t
Pr(s, t) (4)
This is the approach followed in GIATI (Casacuberta et al 2004a; Casacuberta and Vidal
2004), but other models for the joint probability can be adopted.
If the input is a spoken sentence, instead of a written one, the problem becomes
more complex; we will not deal with this here. The interested reader may consult
Amengual et al (2000), Ney et al (2000), or Casacuberta et al (2004a, 2004b), for
instance.
2.2 Statistical Interactive-Predictive Machine Translation
Unfortunately, current models and therefore the systems which can be built from them
are still far from perfect. This implies that, in order to achieve good, or even acceptable,
translations, manual post-editing is needed. An alternative to this serial approach (first
MT, then manual correction) is given by the IPMT paradigm. Under this paradigm,
translation is considered as an iterative process where human and computer activity
6
Barrachina et al Statistical Computer-Assisted Translation
Figure 1
Typical example of IPMT with keyboard interaction. The aim is to translate the English sentence
Click OK to close the print dialog into Spanish. Each step starts with a previously fixed target
language prefix tp, from which the system suggests a suffix t?s. Then the user accepts a part of this
suffix (a) and types some keystrokes (k), possibly in order to amend the remaining part of ts.
This produces a new prefix, composed by the prefix from the previous iteration and the accepted
and typed text, (a) (k), to be used as tp in the next step. The process ends when the user enters
the special keystroke ?#?. System suggestions are printed in italics and user input in boldface
typewriter font. In the final translation t, text that has been typed by the user is underlined.
are interwoven. This way, the models take into account both the input sentence and the
corrections of the user.
As previously mentioned, this idea was originally proposed in the TransType
project (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000;
Langlais, Lapalme, and Loranger 2002). In that project, the parts proposed by the sys-
tems were produced using a linear combination of a target language model (trigrams)
and a lexicon model (so-called IBM-1 or -2) (Langlais, Lapalme, and Loranger 2002). As
a result, TransType allowed only single-token completions, where a token could be either
a word or a short sequence of words from a predefined set of sequences. This proposal
was extended to complete full target sentences in the TT2 project, as discussed hereafter.
The approach taken in TT2 is exemplified in Figure 1. Initially, the system provides
a possible translation. From this translation, the user marks a prefix as correct and
provides, as a hint, the beginning of the rest of the translation. Depending on the system
or the user preferences, the hint can be the next word or some letters from it (in the
figure, hints are assumed to be words and are referred to as k). Let us use tp for the prefix
validated by the user together with the hint. The system now has to produce (predict)
a suffix ts to complete the translation. The cycle continues with a new validation and
hint from the user until the translation is completed. This justifies our choice of the term
?interactive-predictive machine translation? for this approach.
The crucial step of the process is the production of the suffix. Again, decision theory
tells us to maximize the probability of the suffix given the available information. That
is, the best suffix will be
t?s = argmax
ts
Pr(ts|s, tp) (5)
which can be straightforwardly rewritten as
t?s = argmax
ts
Pr(tp, ts|s) (6)
7
Computational Linguistics Volume 35, Number 1
Note that, because tpts = t, this equation is very similar to Equation (1). The main
difference is that the argmax search now is performed over the set of suffixes ts that
complete tp instead of complete sentences (t in Equation (1)). This implies that we can
use the same models if the search procedures are adequately modified (Och, Zens, and
Ney 2003).
The situation with respect to finite-state models is similar. Now, Equation (5) is
rewritten as
t?s = argmax
ts
Pr(tp, ts, s) (7)
which allows the use of the same models as in Equation (4) as long as the search
procedure is changed appropriately (Cubel et al 2003, 2004; Civera et al 2004a,
2004b).
3. Statistical and Finite-State Models
The models used are presented in the following subsections: Section 3.1 for the condi-
tional distribution Pr(s|t) in Equation (2) and Section 3.2 for the joint distribution Pr(s, t)
in Equation (4).
3.1 Statistical Alignment Models
The translation models which Brown et al (1993) introduced to deal with Pr(s|t) in
Equation (2) are based on the concept of alignment between the components of a pair
(s, t) (thus they are called statistical alignment models). Formally, if the number of
the source words in s is J and the number of target words in t is I, an alignment is a
function a : {1, ..., J} ? {0, ..., I}. The image of j by a will be denoted as aj, in which the
particular case aj = 0 means that the position j in s is not aligned with any position of t.
By introducing the alignment as a hidden variable in Pr(s|t),
Pr(s|t) =
?
a
Pr(s, a|t) (8)
The alignment that maximizes Pr(s, a|t) is shown to be very useful in practice for
training and for searching.
Different approaches have been proposed for modeling Pr(s, a|t) in Equation (8):
Zero-order models such as model 1, model 2, and model 3 (Brown et al 1993) and the first-
order models such as model 4, model 5 (Brown et al 1993), hidden Markov model (Ney
et al 2000), and model 6 (Och and Ney 2003).
In all these models, single words are taken into account. Moreover, in practice the
summation operator is replaced with the maximization operator, which in turn reduces
the contribution of each individual source word in generating a target word. On the
other hand, modeling word sequences rather than single words in both the alignment
and lexicon models cause significant improvement in translation quality (Och and Ney
8
Barrachina et al Statistical Computer-Assisted Translation
2004). In this work, we use two closely related models: ATs (Och and Ney 2004) and
PBMs (Toma?s and Casacuberta 2001; Koehn, Och, and Marcu 2003; Zens and Ney 2004).
Both models are based on bilingual phrases3 (pairs of segments or word sequences)
in which all words within the source-language phrase are aligned only to words of
the target-language phrase and vice versa. Note that at least one word in the source-
language phrase must be aligned to one word of the target-language phrase, that is,
there are no empty phrases similar to the empty word of the word-based models. In
addition, no gaps and no overlaps between phrases are allowed.
We introduce some notation to deal with phrases. As before, s denotes a source-
language sentence; ?s denotes a generic phrase in s, and ?sk the kth phrase in s. sj denotes
the jth source word in s; s
j?
j denotes the contiguous sequence of words in s beginning
at position j and ending at position j? (inclusive); obviously, if s has J words, s
J
1 denotes
the whole sentence s. An analogous notation is used for target words, phrases, and
sequences in target sentence t.
3.1.1 Alignment Templates. The ATs are based on the bilingual phrases but they are
generalized by replacing words with word classes and by storing the alignment in-
formation for each phrase pair. Formally, an AT Z is a triple (S,T,?a), where S and
T are a source class sequence and a target class sequence, respectively, and ?a is an
alignment from the set of positions in S to the set of positions in T.4 Mapping of source
and target words to bilingual word classes is automatically trained using the method
described by Och (1999). The method is actually an unsupervised clustering method
which partitions the source and target vocabularies, so that assigning words to classes
is a deterministic operation. It is also possible to employ parts-of-speech or semantic
categories instead of the unsupervised clustering method used here. More details can
be found in Och (1999) and Och and Ney (2004). However, it should be mentioned
that the whole AT approach (and similar PBM approaches as they are now called) is
independent of the word clustering concept. In particular, for large training corpora,
omitting the word clustering in the AT system does not much affect the translation
accuracy.
To arrive at our translation model, we first perform a segmentation of the source
and target sentences into K ?blocks? dk ? (ik; bk, jk) (ik ? {1, . . . , I} and jk, bk ? {1, . . . , J}
for 1 ? k ? K). For a given sentence pair (sJ1, t
I
1), the kth bilingual segment (?sk,
?tk)
is (s
jk
bk?1+1
, t
ik
ik?1+1
) (Och and Ney 2003). The AT Zk = (Sk,Tk,?ak) associated with the kth
bilingual segment is: Sk the sequence of word classes in ?sk; Tk the sequence of word
classes in ?tk, and ?ak the alignment between positions in a source class sequence S and
positions in a target class sequence T.
For translating a given source sentence s we use the following decision rule as an
approximation to Equation (1):
(I?, t?I?1) = argmax
I,tI1
{
max
K,dK1 ,?a
K
1
log PAT(s
J
1, t
I
1; d
K
1 ,?a
K
1 )
}
(9)
3 Although the term ?phrase? has a more restricted meaning, in this article it refers to a word sequence.
4 Note that the phrases in an AT are sequences of word classes rather than words, which motivates the use
of a different notation.
9
Computational Linguistics Volume 35, Number 1
We use a log-linear model combination:
log PAT(s
J
1, t
I
1; d
K
1 ,?a
K
1 ) =
I
?
i=1
[
?1 + ?2 ? log p(ti|t
i?1
i?2)+ ?3 ? log p(Ti|T
i?1
i?4 )
]
+
K
?
k=1
[ ?4 + ?5 ? log q(bk|jk?1)+ ?6 ? log p(Tk,?ak|Sk)+
ik
?
i=ik?1+1
?7 ? log p(ti|?sk,?ak) ] (10)
with weights ?i, i = 1, ? ? ? , 7. The weights ?1 and ?4 play a special role and are used
to control the number I of words and number K of segments for the target sentence
to be generated, respectively. The log-linear combination uses the following set of
models:
 p(ti|t
i?1
i?2): Word-based trigram language model
 p(Ti|T
i?1
i?4 ): Class-based five-gram language model
 p(Tk,?ak|Sk): AT at class level, model parameters are estimated directly
from frequency counts in a training corpus
 p(ti|?sk,?ak): Single word model based on a statistical dictionary and ?ak. As
in the preceding model, the model parameters are estimated by using
frequency counts
 q(bk|jk?1) = e|bk?jk?1+1|: Re-ordering model using absolute j distance of
the phrases.
As can be observed, all models are implemented as feature functions which depend on
the source and the target language sentences, as well as on the two hidden variables
(?aK1 , b
K
1 ). Other feature functions can be added to this sort of model as needed. For a
more detailed description the reader is referred to Och and Ney (2004).
Learning alignment templates. To learn the probability of applying an AT, p(Z =
(S,T,?a)|?s ), all bilingual phrases that are consistent with the segmentation are extracted
from the training corpus together with the alignment within these phrases. Thus, we
obtain a count N(Z) of how often an AT occurred in the aligned training corpus. Using
the relative frequency
p(Z) = (S,T,?a)|?s) =
N(Z) ? ?(S,C(?s))
N(C(?s))
(11)
we estimate the probability of applying an AT Z to translate the source language phrase
?s, in which ? is Kronecker?s delta function. The class function C maps words onto their
10
Barrachina et al Statistical Computer-Assisted Translation
classes. To reduce the memory requirements, only probabilities for phrases up to a
maximal length are estimated, and phrases with a probability estimate below a certain
threshold are discarded.
The weights ?i in Equation (10) are usually estimated using held-out data with
respect to the automatic evaluation metric employed using the downhill simplex al-
gorithm from Press et al (2002).
3.1.2 Phrase-Based Models. A simple alternative to AT has been introduced in recent
works: The PBM approach (Toma?s and Casacuberta 2001; Marcu and Wong 2002; Zens,
Och, and Ney 2002; Toma?s and Casacuberta 2003; Zens and Ney 2004). These methods
learn the probability that a sequence of contiguous words?the source phrase?(as a
whole unit) in a source sentence is a translation of another sequence of contiguous
words?the target phrase?(as a whole unit) in the target sentence. In this case, the
statistical dictionaries of single word pairs are substituted by statistical dictionaries of
bilingual phrases or bilingual segments. These models are simpler than ATs, because no
alignments are assumed between word positions inside a bilingual segment and word
classes are not used in the definition of a bilingual phrase.
The simplest formulation is for monotone PBMs (Toma?s and Casacuberta 2007),
assuming a uniform distribution of the possible segmentations of the source and of the
target sentences. In this case, the approximation to Equation (1) is:
(I?, t?I?1) = argmax
I,tI1
{
max
K,dK1
log PPBM(s
J
1, t
I
1; d
K
1 )
}
(12)
In our implementation of this approach, we have also adopted a log-linear model
log PPBM(s
J
1, t
I
1; d
K
1 ) =
I
?
i=1
[
?1 + ?2 ? log p(ti|t
i?1
i?2)+ ?3 ? log p(Ti|T
i?1
i?4 )
]
+
K
?
k=1
[
?4 + ?5 ? log p(?tk|?sk)
]
(13)
with weights ?i, i = 1, ? ? ? , 5. The weights ?1 and ?4 play a special role and are used
to control the number I of words and number K of segments for the target sentence
to be generated, respectively. The log-linear combination uses the following set of
models:
 p(ti|t
i?1
i?2): Word-based trigram language model
 p(Ti|T
i?1
i?4 ): Class-based five-gram language model
 p(?tk|?sk): Statistical dictionary of bilingual phrases.
11
Computational Linguistics Volume 35, Number 1
If segment re-ordering is desired (non-monotone models), the probability of phrase-
alignment q can be introduced (a first-order distortion model is assumed):
log PPBM(s
J
1, t
I
1; d
K
1 ) =
I
?
i=1
[
?1 + ?2 ? log p(ti|t
i?1
i?2)+ ?3 ? log p(Ti|T
i?1
i?4 )
]
+
K
?
k=1
[
?4 + ?5 ? log p(?tk|?sk)+ ?6 ? log q(bk|jk?1)
]
(14)
with the additional model q, similar to the one used for AT.
Learning phrase-based alignment models. The parameters of each model and the weights
?i in Equations (13) and (14) have to be estimated. There are different approaches to
estimating the parameters of each model (Toma?s and Casacuberta 2007). Some of these
techniques correspond to a direct learning of the parameters from a sentence-aligned
corpus using a maximum likelihood approach (Toma?s and Casacuberta 2001; Marcu
and Wong 2002). Other techniques are heuristics based on the previous computation
of word alignments in the training corpus (Zens, Och, and Ney 2002; Koehn, Och, and
Marcu 2003). On the other hand, as for AT, the weights ?i in Equation (13) are usually
optimized using held-out data.
3.2 Stochastic Finite-State Transducers
SFSTs constitute an important framework in syntactic pattern recognition and nat-
ural language processing. The simplicity of finite-state models has given rise to some
concerns about their applicability to real tasks. Specifically in the field of language
translation, it is often argued that natural languages are so complex that these simple
models are never able to cope with the required source-target mappings. However, one
should take into account that the complexity of the mapping between the source and
target domains of a transducer is not always directly related to the complexity of the
domains themselves. Instead, a key factor is the degree of monotonicity or sequentiality
between source and target subsequences of these domains (Casacuberta, Vidal, and
Pico? 2005). Finite-state transducers have been shown to be adequate to handle complex
mappings efficiently (Berstel 1979) and SFSTs are closely related to monotone PBMs.
In Equation (4), Pr(s, t) can be modeled by an SFST T, which is defined as a tuple
??,?,Q, q0, p, f ?, where ? is a finite set of source symbols,? is a finite set of target symbols
(? ?? = ?), Q is a finite set of states, q0 is the initial state, p and f are two functions
p : Q ? ??? ? Q ? [0, 1] (for the probabilities of transitions) and f : Q ? [0, 1] (for the
probabilities of final states) that satisfy ?q ? Q:
f (q) +
?
(s,?t,q? )?????Q
p(q, s,?t, q?) = 1 (15)
Given T, a path with J transitions associated with the translation pair (s, t) ?
?? ??? is a sequence of transitions ? = (q0, s1 , t?1, q1) (q1, s2 , t?2, q2) (q2, s3 , t?3, q3) . . .
(qJ?1, sJ , t?J, qJ ), such that s1 s2 . . . sJ = s and t?1 t?2 . . . t?J = t. The probability of a path is
12
Barrachina et al Statistical Computer-Assisted Translation
the product of its transition probabilities, times the final-state probability of the last
state in the path:
PT(?) =
J
?
j=1
p(qj?1, sj , t?j, qj) ? f (qJ ) (16)
The probability of a translation pair (s, t) according to T is then defined as the sum of
the probabilities of all the paths associated with (s, t):
PT(s, t) =
?
?
PT(?) (17)
Learning finite-state transducers. There are different families of techniques to train an
SFST from a parallel corpus of source?target sentences (Casacuberta and Vidal 2007).
One of the techniques that has been adopted in this work is the grammatical inference
and alignments for transducer inference (GIATI) technique. This technique is in the
category of hybrid methods which use statistical techniques to guide the SFST structure
learning and simultaneously train the associated probabilities.
Given a finite sample of string pairs, the inference of SFSTs using the GIATI tech-
nique is performed as follows (Casacuberta and Vidal 2004; Casacuberta, Vidal, and
Pico? 2005): i) Building training strings: Each training pair is transformed into a single
string from an extended alphabet to obtain a new sample of strings. ii) Inferring a
(stochastic) regular grammar. Typically, a smoothed n-gram is inferred from the sample
of strings obtained in the previous step. iii) Transforming the inferred regular grammar
into a transducer: The symbols associated with the grammar rules are converted back
into input/output symbols, thereby transforming the grammar inferred in the previous
step into a transducer. The transformation of a parallel corpus into a string corpus
is performed using statistical alignments. These alignments are obtained using the
GIZA++ software (Och and Ney 2003).
4. Searching
Searching is an important computational problem in SMT. Algorithmic solutions de-
veloped for SMT can be adapted to the IPMT framework. The main general search
procedures for each model in Section 3 are presented in the following subsections,
each followed by a detailed description of the necessary adaptations to the interactive
framework.
4.1 Searching with Alignment Templates
In offline MT, the generation of the best translation for a given source sentence s is
carried out by producing the target sentence in left-to-right order using the model of
Equation (10). At each step of the generation algorithm we maintain a set of active
hypotheses and choose one of them for extension. A word of the target language is
then added to the chosen hypothesis and its costs get updated. This kind of generation
fits nicely into a dynamic programming (DP) framework, as hypotheses which are
indistinguishable by both language and translation models (and that have covered
the same source positions) can be recombined. Because the DP search space grows
13
Computational Linguistics Volume 35, Number 1
Figure 2
Example of a word graph for the source German sentence was hast du gesagt? (English reference
translation: ?what did you say??).
exponentially with the size of the input, standard DP search is prohibitive, and we resort
to a beam-search heuristic.
4.1.1 Adaptation to the Interactive-Predictive Scenario. The most important modification
is to rely on a word graph that represents possible translations of the given source
sentence. This word graph is generated once for each source sentence. During the
process of human?machine interaction the system makes use of this word graph in
order to complete the prefixes accepted by the human translator. In other words, after
the human translator has accepted a prefix string, the system finds the best path in the
word graph associated with this prefix string so that it is able to complete the target
sentence. Using the word graph in such a way, the system is able to interact with the
human translator in a time efficient way. In Och, Zens, and Ney (2003), an efficient
algorithm for interactive generation using word graphs was presented. A word graph
is a weighted directed acyclic graph, in which each node represents a partial translation
hypothesis and each edge is labeled with a word of the target sentence and is weighted
according to the language and translation model scores. In Ueffing, Och, and Ney (2002),
the authors give a more detailed description of word graphs and show how they can be
easily produced as a by-product of the search process. An example of a word graph is
shown in Figure 2.
The computational cost of this approach is much lower, as the whole search for the
translation must be carried out only once, and the generated word graph can be reused
for further completion requests.
For a fixed source sentence, if no pruning is applied in the production of the word
graph, it represents all possible sequences of target words for which the posterior
probability is greater than zero, according to the models used. However, because of
the pruning generally needed to render the problem computationally feasible, the
resulting word graph only represents a subset of the possible translations. Therefore,
it may happen that the user sets prefixes which cannot be found in the word graph. To
circumvent this problem some heuristics need to be implemented.
First, we look for the node with minimum edit distance to the prefix except for
its last (partial) word.5 Then we select the completion path which starts with the last
5 The edit distance concept for finding the prefix string in a word graph could be refined by casting the edit
distance operations into a suitable probabilistic model.
14
Barrachina et al Statistical Computer-Assisted Translation
(partial) word of the prefix and has the best backward score?this is the score associated
with a path going from the node to the final node. Now, because the original word graph
may not be compatible with the new information provided by the prefix, it might be
impossible to find a completion in this word graph due to incompatibility with the
last (partial) word in the prefix. This problem can be solved to a certain degree by
searching for a completion of the last word with the highest probability using only the
language model. This supplementary heuristic to the usual search increases the perfor-
mance of the system, because some of the rejected words in the pruning process can
be recovered.
A desirable feature of an IPMT system is the possibility of producing a list of
alternative target suffixes, instead of only one. This feature can be easily added by
computing the n-best hypotheses. Of course, these n-best hypotheses do not refer to
the whole target sentence, but only to the suffixes. However, the problem is that in
many cases the sentence hypotheses in the n-best list differ in only one or two words.
Therefore, we introduce the additional requirement that the first four words of the n-
best hypotheses must be different.
4.2 Searching with Phrase-Based Models
The generation of the best translation with PBMs is similar to the one described in the
previous section. Each hypothesis is composed of a prefix of the target sentence, a subset
of source positions that are aligned with the positions of the prefix of the target sentence,
and a score. In this case, we adopted an extension of the best-first strategy where the
hypotheses are stored in several sorted lists, depending on which words in the source
sentence have been translated. This strategy is related to the well-known multi-stack-
decoding algorithm (Berger et al 1996; Toma?s and Casacuberta 2004). In each iteration,
the algorithm extends the best hypothesis from each available list.
While target words are always generated from left to right, there are two alter-
natives in the source word extraction: Monotone search, which takes the source words
from left to right, and non-monotone search, which can take source words in any
order.
4.2.1 Adaptation to the Interactive-Predictive Scenario. Only a simple modification of this
search algorithm is necessary: If the new extended hypothesis is not compatible with
the fixed target prefix, tp, then this hypothesis is not considered. This compatibility is
verified at the character level; therefore the user does not need to type the whole target
word at the end of the target prefix.
In the interactive scenario, speed is a critical aspect. In the PBM approach, monotone
search is much faster than non-monotone search in the tasks which are considered in this
work (Toma?s and Casacuberta 2006). However, monotone search presents a problem for
interactive operation: If a user introduces a prefix that cannot be obtained in a monotone
way from the source, the search algorithm is not able to complete this prefix. In order
to solve this problem without losing computational efficiency, we use the following ap-
proach: Non-monotone search is used for target prefixes, whereas completions (suffixes)
are generated using monotone search.
As for AT models, a list of target suffixes can also be produced. This list can be
obtained easily by keeping the n-best hypotheses in each sorted list. To avoid generating
very similar hypotheses in the n-best list, we apply the following procedure: Starting
from the n-best list resulting from the normal search, we first add hypotheses obtained
15
Computational Linguistics Volume 35, Number 1
by translating a single untranslated word from the source, along with hypotheses
consisting of a single high-probability word according to the target language model; we
then re-order the hypotheses, maximizing the diversity at the beginning of the suffixes,
and keep only the n first hypotheses in the re-ordered list.
4.3 Searching with Stochastic Finite-State Transducers
As discussed by Pico? and Casacuberta (2001), the computation of Equation (4) for SFSTs
under a maximum approximation (i.e., using maximization in Equation (17) instead
of the sum) amounts to a conventional Viterbi search. The algorithm finds the most
probable path among those paths in the SFST which are compatible with the source
sentence s. The corresponding translation, t?, is simply obtained by concatenating the
target strings of the edges of this path.
4.3.1 Adaptation to the Interactive-Predictive Scenario. Here, Equation (7) is used wherein
the optimization is performed over the set of target suffixes (completions) rather than
the set of complete target sentences. To solve this maximization problem, an approach
similar to that proposed for AT in Section 4.1 has been adopted.
First, given the source sentence, a word graph is extracted from the SFST. In this
case, the word graph is just (a pruned version of) the Viterbi search trellis obtained when
translating the whole source sentence. The main difference between the word graphs
generated with ATs and SFSTs is how the nodes and edges are defined in each case. On
the one hand, the nodes are defined as partial hypotheses of the search procedure in
the AT approach, whereas the nodes in the case of SFSTs can be directly mapped into
states in the SFST representing a joint (source word/target string) language model. On
the other hand, the scores associated with the edges in the AT approach are computed
from a combination of the language and translation models, whereas in the case of
SFSTs these scores simply come from the joint language model estimated by the GIATI
technique.
Once the word graph has been generated, the search for the most probable com-
pletion as stated in Equation (6) is carried out in two steps, in a similar way to that
explained for the AT approach. In this case, the computation entailed by both the edit-
distance (prefix error-correcting) and the remaining search is significantly accelerated
by visiting the nodes in topological order and by the incorporation of the beam-search
technique (Amengual and Vidal 1998). Moreover, the error-correcting algorithm takes
advantage of the incremental way in which the user prefix is generated, parsing only
the new suffix appended by the user in the last interaction.
It may be the case that a user prefix ends in an incomplete word during the inter-
active translation process. Therefore, it is necessary to start the translation completion
with a word whose prefix matches this unfinished word. The proposed algorithm thus
searches for such a word. First, it considers the target words of the edges leaving
the nodes returned by the error-correcting algorithm. If this initial search fails, then
a matching word is looked up in the word-graph vocabulary. Finally, as a last resort,
the whole transducer vocabulary is taken into consideration to find a matching word;
otherwise this incomplete word is treated as an entire word.
This error-correcting algorithm returns a set of nodes from which the best comple-
tion would be selected according to the best backward score. Moreover, n-best com-
pletions can also be produced. Among many weighted-graph n-best path algorithms
which are available, the recursive enumeration algorithm presented in Jime?nez and
16
Barrachina et al Statistical Computer-Assisted Translation
Marzal (1999) was adopted for its simplicity in calculating best paths on demand and its
smooth integration with the error-correcting algorithm.
5. Experimental Framework
The models and search procedures introduced in the previous sections were assessed
through a series of IPMT experiments with different corpora. These corpora, along with
the corresponding pre- and post-processing and assessment procedures, are presented
in this section.
5.1 Pre- and Post-Processing
Usually, MT models are trained on a pre-processed version of an original corpus. Pre-
processing provides a simpler representation of the training corpus which makes token
or word forms more homogeneous. In this way automatic training of the MT models is
boosted, and the amount of computation decreases.
The pre-processing steps are: tokenization, removing unnecessary case information,
and tagging some special tokens like numerical sequences, e-mail addresses, and URLs
(?categorization?). In translation from a source language to a target language, there are
some words which are translated identically (because they have the same spelling in
both languages). Therefore, we identify them in the corpus and replace them with some
generic tags to help the translation system.
Post-processing takes place after the translation in order to hide the internal repre-
sentation of the text from the user. Thus, the user will only work with an output which
is very similar to human-generated texts. In detail, the post-processing steps are: de-
tokenization, true-casing, and replacing the tags with their corresponding words.
In an IPMT scenario, the pre-/post-processing must run in real-time and should be
reversible as much as possible. In each human?machine interaction, the current prefix
has to be pre-processed for the interactive-predictive engine and then the generated
completion has to be post-processed for the user. It is crucial that the pre-processing of
prefixes is fully compatible with the training corpus.
5.2 Xerox and EU Corpora
Six bilingual corpora were used for two different tasks and three different language
pairs in the framework of the TT2 project (SchlumbergerSema S.A. et al 2001).
The language pairs involved were English?Spanish, English?French, and English?
German (Khadivi and Goutte 2003), and the tasks were Xerox (Xerox printer manuals)
and EU (Bulletin of the European Union).
The three Xerox corpora were obtained from different user manuals for Xerox print-
ers (SchlumbergerSema S.A. et al 2001). The main features of these corpora are shown
in Table 1. Dividing the corpora into training and test sets was performed by randomly
selecting (without replacement) a specified amount of test sentences and leaving the
remaining ones for training. It is worth noting that the manuals were not the same in
each pair of languages. Even though all training and test sets have similar size, this
probably explains why the perplexity varies considerably over the different language
pairs. The vocabulary size was computed using the tokenized and true-case corpus.
The three bilingual EU corpora were extracted from the Bulletin of the European
Union, which exists in all official languages of the European Union (Khadivi and Goutte
17
Computational Linguistics Volume 35, Number 1
Table 1
The Xerox corpora. For all the languages, the training/test full-sentence overlap and the rate of
out-of-vocabulary test-set words were less than 10% and 1%, respectively. Trigram models were
used to compute the test word perplexity. (K and M denote thousands and millions,
respectively.)
English/Spanish English/German English/French
T
ra
in Sent. pairs (K) 56 49 53
Running words (M) 0.7/0.7 0.6/0.5 0.6/0.7
Vocabulary (K) 15/17 14/25 14/16
T
e
st
Sentences (K) 1.1 1.0 1.0
Running words (K) 8/10 12/12 11/12
Running chars. (K) 46/59 63/73 56/65
Perplexity 99/58 57/93 109/70
2003) and is publicly available on the Internet. The corpora used in the experiments
which are described subsequently were again acquired and processed in the framework
of the TT2 project. The main features of these corpora are shown in Table 2. The
vocabulary size and the training and test set partitions were obtained in a similar way
as with the Xerox corpora.
5.3 Assessment
In all the experiments reported in this article, system performance is assessed by
comparing test sentence translations produced by the translation systems with the
corresponding target language references of the test set. Some of the computed assess-
ment figures measure the quality of the translation engines without any system?user
interactivity:
 Word error rate (WER): The minimum number of substitution, insertion,
and deletion operations needed to convert the word strings produced by
the translation system into the corresponding single-reference word
strings. WER is normalized by the overall number of words in the
reference sentences (Och and Ney 2003).
Table 2
The EU corpora. For all the languages, the training/test full-sentence overlap and the rate of
out-of-vocabulary test-set words were less than 3% and 0.2%, respectively. Trigram models were
used to compute the test word perplexity. (K and M denote thousands and millions,
respectively.)
English/Spanish English/German English/French
T
ra
in Sent. pairs (K) 214 223 215
Running words (M) 5.2/5.9 5.7/5.4 5.3/6.0
Vocabulary (K) 84/97 86/153 84/91
T
e
st
Sentences (K) 0.8 0.8 0.8
Running words (K) 20/23 20/19 20/23
Running chars. (K) 119/135 120/134 119/134
Perplexity 58/46 57/87 58/45
18
Barrachina et al Statistical Computer-Assisted Translation
 Bilingual evaluation understudy (BLEU): This is based on the coverage of
n-grams of the hypothesized translation which occur in the reference
translations (Papineni et al 2001).
Other assessment figures are aimed at estimating the effort needed by a human
translator to produce correct translations using the interactive system. To this end, the
target translations which a real user would have in mind are simulated by the given
references. The first translation hypothesis for each given source sentence is compared
with a single reference translation and the longest common character prefix (LCP) is
obtained. The first non-matching character is replaced by the corresponding reference
character and then a new system hypothesis is produced. This process is iterated until
a full match with the reference is obtained.
Each computation of the LCP would correspond to the user looking for the next
error and moving the pointer to the corresponding position of the translation hypothesis.
Each character replacement, on the other hand, would correspond to a keystroke of
the user. If the first non-matching character is the first character of the new system
hypothesis in a given iteration, no LCP computation is needed; that is, no pointer
movement would be made by the user. Bearing this in mind, we define the following
interactive-predictive performance measures:
 Keystroke ratio (KSR): Number of keystrokes divided by the total number
of reference characters.
 Mouse-action ratio (MAR): Number of pointer movements plus one more
count per sentence (aimed at simulating the user action
needed to accept the final translation), divided by the total number of
reference characters.
 Keystroke and mouse-action ratio (KSMR): KSR plus MAR.
Note that KSR estimates only the user?s actions on the keyboard whereas MAR
estimates actions for which the user would typically use the mouse. From a user
point of view the two types of actions are different and require different types of
effort (Macklovitch, Nguyen, and Silva 2005; Macklovitch 2006). In any case, as an
approximation, KSMR accounts for both KSR and MAR, assuming that both actions
require a similar effort.
In the case of SMT systems, it is well known that an automatically computed
quality measure like BLEU correlates quite well with human judgment (Callison-Burch,
Osborne, and Koehn 2006). In the case of IPMT, we should keep in mind that the
main goal of (automatic) assessment is to estimate the effort of the human translator.
Moreover, translation quality is not an issue here, because the (simulated) human
intervention ensures ?perfect? translation results. The important question is whether
the (estimated) productivity of the human translator can really be increased or not by
the IPMT approach. In order to answer this question, the KSR and KSMR measures will
be used in the IPMT experiments to be reported in the next section.
In order to show the statistical significance of the results, all the assessment figures
reported in the next section are accompanied by the corresponding 95% confidence
intervals. These intervals have been computed using bootstrap sampling techniques, as
proposed by Bisani and Ney (2004), Koehn (2004), and Zhang and Vogel (2004).
19
Computational Linguistics Volume 35, Number 1
6. Results
Two types of results are reported for each corpus and for each translation approach.
The first are conventional MT results, obtained as a reference to give an idea of the
?classical? MT difficulty of the selected tasks. The second aim is to assess the interactive
MT (IPMT) approach proposed in this article.
The results are presented in different subsections. The first two subsections present
the MT and IPMT results for the 1-best translation obtained by the different techniques
in the Xerox and EU tasks, respectively. The third subsection presents further IPMT
results for the 5-best translations on a single pair of languages.
Some of these results may differ from results presented in previous works (Cubel
et al 2003; Och, Zens, and Ney 2003; Civera et al 2004a; Cubel et al 2004; Bender
et al 2005). The differences are due to variations in the pre-/post-processing procedures
and/or recent improvements of the search techniques used by the different systems.
6.1 Experiments with the Xerox Corpora
In this section, the translation results obtained using ATs, PBMs, and SFSTs for all six
language pairs of the Xerox corpus are reported. Word-based trigram and class-based
five-gram target-language models were used for the AT models (the parameters of the
log-linear model are tuned so as to minimize WER on a development corpus); word-
based trigram target-language models were used for PBMs and trigrams were used to
infer GIATI SFSTs.
Off-line MT Results. MT results with ATs, PBMs, and SFSTs are presented in Figure 3.
Results obtained using the PBMs are slightly but consistently better that those achieved
using the other models. In general, the different techniques perform similarly for the
various translation directions. However, the English?Spanish language pair is the one
for which the best translations can be produced.
IPMT Results. Performance has been measured in terms of KSRs and MARs (KSR and
MAR are represented as the lower and upper portions of each bar, respectively, and
KSMR is the whole bar length). The results are shown in Figure 4.
Figure 3
Off-line MT results (BLEU and WER) for the Xerox corpus. Segments above the bars show the
95% confidence intervals. En = English; Sp = Spanish; Fr = French; Ge = German.
20
Barrachina et al Statistical Computer-Assisted Translation
Figure 4
IPMT results for the Xerox corpus. In each bar, KSR is represented by the lower portion, MAR by
the upper portion, and KSMR is the whole bar. Segments above the bars show the 95%
confidence intervals. En = English; Sp = Spanish; Fr = French; Ge = German.
According to these results, a human translator assisted by an AT-based or a SFST-
based interactive system would only need an effort equivalent to typing about 20% of
the characters in order to produce the correct translations for the Spanish to English
task; or even less than 20% if a PBM-based system is used.
For the Xerox task, off-line MT performance and IPMT results show similar tenden-
cies. The PBMs show better performance for both the off-line MT and for the IPMT
assessment figures. The AT and SFST models perform more or less equivalently. In
both scenarios, the best results were achieved for the Spanish?English language pair
followed by French?English and German?English.
The computing times needed by all the systems involved in these experiments were
well within the range of the on-line operational requirements. The average initial time
for each source test sentence was very low (less than 50 msec) for PBMs and SFSTs
and adequate for ATs (772 msec). In the case of ATs and SFSTs, this included the time
required for the generation of the initial word-graph of each sentence. Moreover, the
most critical times incurred in the successive IPMT iterations were very low in all
the cases: 18 msec for ATs, 99 msec for PBMs, and 9 msec for SFSTs. Note, however,
that these average times are not exactly comparable because of the differences in the
computer hardware used by each system (2 Ghz AMD, 1.5 Ghz Pentium, and 2.4 Ghz
Pentium for ATs, PBMs, and SFSTs, respectively).
6.2 Experiments with the EU Corpora
The translation results using the AT, PBM, and SFST approaches for all six language
pairs of the EU corpus are reported in this section. As for the Xerox corpora, in the AT
experiments, word-based trigram and class-based five-gram target-language models
were used; in the PBM experiments, word-based trigram and class-based five-gram
target-language models were also used and five-grams were used to infer GIATI SFSTs.
Off-line MT Results. Figure 5 presents the results obtained using ATs, PBMs, and SFSTs.
Generally speaking, the results are comparable to those obtained on the Xerox corpus
with the exception of the English?Spanish language pair, which were better. With these
corpora, the best results were obtained with the ATs and PBMs for all the pairs and the
best translation direction was French-to-English with all the models used.
21
Computational Linguistics Volume 35, Number 1
Figure 5
Off-line MT results (BLEU and WER) for the EU corpus. Segments above the bars show the 95%
confidence intervals. En = English; Sp = Spanish; Fr = French; Ge = German.
IPMT Results. Figure 6 shows the performance of the AT, PBM, and SFST systems in
terms of KSRs and MARs in a similar way as for the Xerox corpora.
As in the MT experiments, the results are comparable to those obtained on the Xerox
corpus, with the exception of the English?Spanish pair. Similarly, as in MT, the best
results were obtained for the French-to-English translation direction.
Although EU is a more open-domain task, the results demonstrate again the poten-
tial benefit of computer-assisted translation systems. Using PBMs, a human translator
would only need an effort equivalent to typing about 20% of the characters in order
to produce the correct translations for French-to-English translation direction, whereas
for ATs and SFSTs the effort would be about 30%. For the other language pairs, the
efforts would be about 20?30% and 35% of the characters for PBMs and ATs/SFSTs,
respectively.
The systemwise correlation between MT and IPMT results on this corpus is not
as clear as in the Xerox case. One possible cause is the much larger size of the EU
corpus compared to the Xerox corpus. In order to run the EU experiments within rea-
sonable time limits, all the systems have required the use of beam search and/or other
Figure 6
IPMT results for the EU corpus. In each bar, KSR is represented by the lower portion, MAR by
the upper portion and KSMR is the whole bar. Segments above the bars show the 95%
confidence intervals. En = English; Sp = Spanish; Fr = French; Ge = German.
22
Barrachina et al Statistical Computer-Assisted Translation
Table 3
IPMT results (%) for the Xerox corpus (English?Spanish) using ATs, PBMs, and SFSTs for the
1-best hypothesis and 5-best hypotheses. 95% confidence intervals are shown.
1-best 5-best
Technique KSR KSMR KSR KSMR
AT 12.9?0.9 23.2?1.3 11.1?0.8 20.3?1.2
PBM 8.9?0.8 16.7?1.2 7.3?0.6 15.4?1.1
SFST 13.0?1.0 21.8?1.4 11.2?1.0 19.2?1.3
suboptimal pruning techniques, although this was largely unnecessary for the Xerox
corpus. Clearly, the pruning effects are different in the off-line (MT) and the on-line
(IPMT) search processes and the differences may lead to wide performance variations
for the AT, PBM, and SFST approaches.
Nevertheless, as can be seen in Bender et al (2005), the degradation in system
performance due to pruning is generally not too substantial and sufficiently accurate
real-time interactive operation could also be achieved in the EU task with the three
systems tested.
6.3 Results with n-Best Hypotheses
Further experiments were carried out to study the usefulness of n-best hypotheses in
the interactive framework. In this scenario, the user can choose one out of n proposed
translation suffixes and then proceed as in the usual IPMT paradigm. As with the
previous experiments, the automated evaluation is based on a selected target sentence
that best matches a prefix of the reference translation in each IPMT iteration (therefore
KSR is minimized).
Here, only IPMT results for the English-to-Spanish translation direction are re-
ported for both Xerox and EU tasks, using a list of the five best translations. These results
are shown in Tables 3 and 4.
In all the cases there is a clear and significant accuracy improvement when moving
from single-best to 5-best translations. This gain in translation quality diminishes in a
log-wise fashion as we increase the number of best translations. From a practical point
of view, the improvements provided by using n-best completions would come at the
cost of the user having to ponder which of these completions is more suitable. In a
real operational environment, this additional user effort may or may not outweigh the
Table 4
IPMT results (%) for the EU corpus (English?Spanish) using ATs, PBMs, and SFSTs for the 1-best
hypothesis and 5-best hypotheses. 95% confidence intervals are shown.
1-best 5-best
Technique KSR KSMR KSR KSMR
AT 20.2?0.9 32.6?1.3 18.5?0.8 29.9?1.2
PBM 16.3?0.7 27.8?1.1 13.2?0.6 25.0?1.1
SFST 21.3?0.9 33.0?1.3 19.3?0.9 29.9?1.3
23
Computational Linguistics Volume 35, Number 1
benefits of the n-best increased accuracy. Consequently, this feature should be offered to
the users as an option.
7. Practical Issues
IPMT results reported in the previous section provide reasonable estimations of potential
savings of human translator effort, assuming that the goal is to obtain high quality
translations. In real work, however, several practical issues not discussed in this article
may significantly affect the actual system usability and overall user productivity.
One of the most obvious issues is that a carefully designed graphical user interface
(GUI) is needed to let the users actually be in command of the translation process, so
that they really feel the system is assisting them rather than the other way around. In
addition, an adequate GUI has to provide adequate means for the users to easily and
intuitively change at will IPMT engine parameters that may have an impact on their
way of working with the system. To name just a few: The maximum length of system
hypotheses, the value of n for n-best suggestions, or the ?interaction step granularity?;
that is, whether the system should react at each user keystroke, or at the end of each
complete typed word, or after a sufficiently long typing pause, and so on.
Clearly, all these important issues are beyond the scope of the present article. But
we can comment that, in the TT2 project, complete prototypes of some of the systems
presented in this article, including the necessary GUI, were actually implemented and
thoroughly evaluated by professional human translators in their working environ-
ment (Macklovitch, Nguyen, and Silva 2005; Macklovitch 2006).
The results of these field tests showed that the actual productivity depended not
only on the individual translators, but also on the given test texts. In cases where these
texts were quite unrelated to the training data, the system did not significantly help
the human translators to increase their productivity. However, when the test texts were
reasonably well related to the training data, high productivity gains were registered?
close to what could be expected according to the KSR/MAR empirical results.
8. Concluding Remarks
The IPMT paradigm proposed in this article allows for a close collaboration between a
human translator and a machine translation system. This paradigm entails an iterative
process where, in each iteration, a data-driven machine translation engine suggests a
completion for the current prefix of a target sentence which a human translator can
accept, modify, or ignore.
This idea was originally proposed in the TransType project (Langlais, Foster, and
Lapalme 2000), where a simple engine was used which only supported single-token
suggestions. Furthering these ideas, in the TransType2 project (SchlumbergerSema S.A.
et al 2001), state-of-the-art statistical machine translation systems have been developed
and integrated in the IPMT framework.
In a laboratory environment, results on two different tasks suggest that the pro-
posed techniques can reduce the typing effort needed to produce a high-quality transla-
tion of a given source text by as much as 80% with respect to the effort needed to simply
type the whole translation. In real conditions, a high productivity gain was achieved in
many cases.
We have studied here IPMT from the point of view of a standalone CAT tool.
Nevertheless, IPMT can of course be easily and conveniently combined with other
popular translator workbench tools. More specifically, IPMT lends itself particularly
24
Barrachina et al Statistical Computer-Assisted Translation
well to addressing the typical lack of generalization capabilities of translation memories.
When used as a CAT tool, translation memories allow the human translator to keep
producing increasingly long segments of correct target text. Clearly, these segments can
be used by an IPMT engine to suggest to the translator possible translations for source
text segments that are not found in the translation memories as exact matches.
Acknowledgments
This work has been partially supported by
the ST Programme of European Union under
grant IST-2001-32091, by the Spanish project
TIC?2003-08681-C02-02, and the Spanish
research programme Consolider
Ingenio-2010 CSD2007-00018. The authors
wish to thank the anonymous reviewers for
their criticisms and suggestions.
References
Amengual, J. C., J. M. Bened??, A. Castan?o,
A. Castellanos, V. M. Jime?nez, D. Llorens,
A. Marzal, M. Pastor, F. Prat, E. Vidal, and
J. M. Vilar. 2000. The EuTrans-I speech
translation system. Machine Translation,
15:75?103.
Amengual, J. C. and E. Vidal. 1998. Efficient
error-correcting Viterbi parsing. IEEE
Transactions on Pattern Analysis and Machine
Intelligence, 20(10):1109?1116.
Bender, O., S. Hasan, D. Vilar, R. Zens, and
H. Ney. 2005. Comparison of generation
strategies for interactive machine
translation. In Proceedings of the 10th
Annual Conference of the European
Association for Machine Translation (EAMT
05), pages 33?40, Budapest.
Berger, A. L., P. F. Brown, S. A. Della Pietra,
V. J. Della Pietra, J. R. Gillett, A. S. Kehler,
and R. L. Mercer. 1996. Language
translation apparatus and method of using
context-based translation models. United
States Patent No. 5510981, April.
Berstel, J. 1979. Transductions and Context-Free
Languages. B. G. Teubner, Stuttgart.
Bisani, M. and H. Ney. 2004. Bootstrap
estimates for confidence intervals in ASR
performance evaluation. In Proceedings of
the International Conference on Acoustic,
Speech and Signal Processing (ICASSP 04),
volume 1, pages 409?412, Montreal.
Bowker, L. 2002. Computer-Aided Translation
Technology: A Practical Introduction,
chapter 5: Translation-memory systems.
Didactics of Translation. University of
Ottawa Press, pages 92?127.
Brown, P. F., J. Cocke, S. A. Della Pietra,
V. J. Della Pietra, F. Jelinek, J. D. Lafferty,
R. L. Mercer, and P. S. Roosin. 1990.
A statistical approach to machine
translation. Computational Linguistics,
16(2):79?85.
Brown, P. F., S. A. Della Pietra, V. J.
Della Pietra, and R. L. Mercer. 1993. The
mathematics of statistical machine
translation: Parameter estimation.
Computational Linguistics, 19(2):263?310.
Callison-Burch, C., M. Osborne, and
P. Koehn. 2006. Re-evaluating the role of
BLEU in machine translation research. In
Proceedings of the 10th Conference of the
European Chapter of the Association for
Computational Linguistics (EACL 06),
pages 249?256, Trento.
Casacuberta, F., H. Ney, F. J. Och, E. Vidal,
J. M. Vilar, S. Barrachina, I. Garc??a-Varea,
D. Llorens, C. Mart??nez, S. Molau,
F. Nevado, M. Pastor, D. Pico?, A. Sanchis,
and C. Tillmann. 2004a. Some approaches
to statistical and finite-state
speech-to-speech translation. Computer
Speech and Language, 18:25?47.
Casacuberta, F. and E. Vidal. 2004. Machine
translation with inferred stochastic
finite-state transducers. Computational
Linguistics, 30(2):205?225.
Casacuberta, F. and E. Vidal. 2007. Learning
finite-state models for machine translation.
Machine Learning, 66(1):69?91.
Casacuberta, F., E. Vidal, and D. Pico?. 2005.
Inference of finite-state transducers from
regular languages. Pattern Recognition,
38:1431?1443.
Casacuberta, F., E. Vidal, A. Sanchis, and
J. M. Vilar. 2004b. Pattern recognition
approaches for speech-to-speech
translation. Cybernetic and Systems: an
International Journal, 35(1):3?17.
Civera, J., J. M. Vilar, E. Cubel, A. L. Lagarda,
S. Barrachina, E. Vidal, F. Casacuberta,
D. Pico?, and J. Gonza?lez. 2004a. From
machine translation to computer assisted
translation using finite-state models. In
Proceedings of the Conference on Empirical
Methods for Natural Language Processing
(EMNLP 04), pages 349?356, Barcelona.
Civera, J., J. M. Vilar, E. Cubel, A. L. Lagarda,
S. Barrachina, F. Casacuberta, E. Vidal,
D. Pico?, and J. Gonza?lez. 2004b. A syntactic
pattern recognition approach to computer
assisted translation. In Advances in
25
Computational Linguistics Volume 35, Number 1
Statistical, Structural and Syntactical Pattern
Recognition, Proceedings of the Joint IAPR
International Workshops on Syntactical and
Structural Pattern Recognition (SSPR 04)
and Statistical Pattern Recognition
(SPR 04)), Lisbon, Portugal, August 18?20,
volume 3138 of Lecture Notes in Computer
Science. Springer-Verlag, Heidelberg,
pages 207?215.
Cubel, E., J. Civera, J. M. Vilar, A. L. Lagarda,
S. Barrachina, E. Vidal, F. Casacuberta,
D. Pico?, J. Gonza?lez, and L. Rodr??guez.
2004. Finite-state models for computer
assisted translation. In Proceedings of the
16th European Conference on Artificial
Intelligence (ECAI 04), pages 586?590,
Valencia.
Cubel, E., J. Gonza?lez, A. Lagarda,
F. Casacuberta, A. Juan, and E. Vidal. 2003.
Adapting finite-state translation to the
TransType2 project. In Proceedings of the
Joint Conference Combining the 8th
International Workshop of the European
Association for Machine Translation and the
4th Controlled Language Applications Workshop
(EAMT-CLAW 03), pages 54?60, Dublin.
Foster, G. 2002. Text Prediction for Translators.
Ph.D. thesis, Universite? de Montre?al,
Canada.
Foster, G., P. Isabelle, and P. Plamondon.
1997. Target-text mediated interactive
machine translation. Machine Translation,
12(1?2):175?194.
Isabelle, P. and K. Church. 1997. Special issue
on new tools for human translators.
Machine Translation, 12(1?2).
Jelinek, F. 1998. Statistical Methods for Speech
Recognition. The MIT Press, Cambridge,
MA.
Jime?nez, V. M. and A. Marzal. 1999.
Computing the k shortest paths: a new
algorithm and an experimental
comparison. In Algorithm Engineering:
Proceedings of the 3rd International
Workshop (WAE 99), London, UK, July 19?21,
volume 1668 of Lecture Notes in Computer
Science. Springer-Verlag, Heidelberg,
pages 15?29.
Kay, M. 1997. The proper place of men and
machines in language translation. Machine
Translation, 12:3?23. [This article first
appeared as a Xerox PARC Working Paper
in 1980].
Khadivi, S. and C. Goutte. 2003. Tools for
corpus alignment and evaluation of the
alignments (deliverable d4.9). Technical
report, TransType2 (IST-2001-32091).
Khadivi, S., R. Zens, and H. Ney. 2006.
Integration of speech to computer-assisted
translation using finite-state automata.
In Proceedings of the 44th Annual Meeting of
the Association for Computational Linguistics
and 21th International Conference on
Computational Linguistics (COLING/ACL
06), pages 467?474, Sydney.
Khadivi, S., A. Zolnay, and H. Ney. 2005.
Automatic text dictation in
computer-assisted translation. In
Proceedings of the European Conference on
Speech Communication and Technology,
(INTERSPEECH 05-EUROSPEECH),
pages 2265?2268, Lisbon.
Koehn, P. 2004. Statistical significance
tests for machine translation evaluation.
In Proceedings of the Conference on
Empirical Methods for Natural Language
Processing (EMNLP 04), pages 388?395,
Barcelona.
Koehn, P., F. J. Och, and D. Marcu. 2003.
Statistical phrase-based translation. In
Proceedings of the 2003 Meeting of the North
American Chapter of the Association for
Computational Linguistics (NAACL 03),
pages 127?133, Edmonton.
Langlais, P., G. Foster, and G. Lapalme. 2000.
TransType: a computer-aided translation
typing system. In Proceedings of the
NAACL/ANLP Workshop on Embedded
Machine Translation Systems, pages 46?52,
Seattle, WA.
Langlais, P., G. Lapalme, and M. Loranger.
2002. Transtype: Development-evaluation
cycles to boost translator?s productivity.
Machine Translation, 15(4):77?98.
Macklovitch, E. 2006. TransType2: The last
word. In Proceedings of the 5th International
Conference on Languages Resources and
Evaluation (LREC 06), pages 167?172,
Genoa.
Macklovitch, E., N. T. Nguyen, and R. Silva.
2005. User evaluation report. Technical
report, TransType2 (IST-2001-32091).
Marcu, D. and W. Wong. 2002. A
phrase-based, joint probability model
for statistical machine translation.
In Proceedings of the Conference on
Empirical Methods for Natural Language
Processing (EMNLP 02), pages 133?139,
Philadelphia, PA.
Ney, H., S. Nie?en, F. Och, H. Sawaf,
C. Tillmann, and S. Vogel. 2000.
Algorithms for statistical translation of
spoken language. IEEE Transactions on
Speech and Audio Processing, 8(1):24?36.
Och, F. J. 1999. An efficient method for
determining bilingual word classes. In
Proceedings of the 9th Conference of the
European Chapter of the Association for
26
Barrachina et al Statistical Computer-Assisted Translation
Computational Linguistics (EACL 99),
pages 71?76, Bergen.
Och, F. J. and H. Ney. 2003. A systematic
comparison of various statistical
alignment models. Computational
Linguistics, 29(1):19?51.
Och, F. J. and H. Ney. 2004. The alignment
template approach to statistical machine
translation. Computational Linguistics,
30(4):417?450.
Och, F. J., R. Zens, and H. Ney. 2003.
Efficient search for interactive statistical
machine translation. In Proceedings of
the 10th Conference of the European Chapter
of the Association for Computational
Linguistics (EACL 03), pages 387?393,
Budapest.
Papineni, K., S. Roukos, T. Ward, and
W. Zhu. 2001. BLEU: a method for
automatic evaluation of machine
translation. Technical Report RC22176,
Thomas J. Watson Research Center.
Pico?, D. and F. Casacuberta. 2001. Some
statistical-estimation methods for
stochastic finite-state transducers. Machine
Learning, 44:121?142.
Press, W. H., S. A. Teukolsky, W. T.
Vetterling, and B. P. Flannery. 2002.
Numerical Recipes in C++: The Art of
Scientific Computing. Cambridge University
Press, Cambridge, UK.
SchlumbergerSema S.A., Intituto Tecnolo?gico
de Informa?tica, Rheinisch Westfa?lische
Technische Hochschule Aachen Lehrstul
fu?r Informatik VI, Recherche Applique?e
en Linguistique Informatique Laboratory
University of Montreal, Celer Soluciones,
Socie?te? Gamma, and Xerox
Research Centre Europe. 2001. TT2.
TransType2?computer-assisted
translation. Project technical annex.
Information Society Technologies (IST)
Programme, IST-2001-32091.
Sen, Z., Ch. Zhaoxiong, and H. Heyan. 1997.
Interactive approach in machine translation
systems. In Proceedings of IEEE International
Conference on Intelligent Processing Systems
(ICIPS 97), pages 1814?1819, Beijing.
Slocum, J. 1985. A survey of machine
translation: Its history, current status and
future prospects. Computational Linguistics,
11(1):1?17.
Somers, H., 2003. Computers and Translation: a
Translator?s Guide, chapter 3: Translation
memory systems. John Benjamins,
Amsterdam, pages 31?48.
Toma?s, J. and F. Casacuberta. 2001.
Monotone statistical translation using
word groups. In Proceedings of the Machine
Translation Summit VIII (MT SUMMIT
VIII), pages 357?361, Santiago de
Compostela.
Toma?s, J. and F. Casacuberta. 2003.
Combining phrase-based and
template-based alignment models in
statistical translation. In Pattern Recognition
and Image Analysis, Proceedings of the First
Iberian Conference (IbPRIA 03), Puerto
de Andratx, Mallorca, Spain, June 4-6,
volume 2652 of Lecture Notes in Computer
Science. Springer-Verlag, Heidelberg,
pages 1020?1031.
Toma?s, J. and F. Casacuberta. 2004. Statistical
machine translation decoding using
target word reordering. In Advances in
Statistical, Structural and Syntactical Pattern
Recognition, Proceedings of the Joint IAPR
International Workshops on Syntactical
and Structural Pattern Recognition
(SSPR 04) and Statistical Pattern Recognition
(SPR 04), Lisbon, Portugal, August 18?20,
volume 3138 of Lecture Notes in Computer
Science. Springer-Verlag, Heidelberg,
pages 734?743.
Toma?s, J. and F. Casacuberta. 2006. Statistical
phrase-based models for interactive
computer-assisted translation. In
Proceedings of the 44th Annual Meeting
of the Association for Computational
Linguistics and 21th International
Conference on Computational Linguistics
(COLING/ACL 06), pages 835?841, Sydney.
Toma?s, J. and F. Casacuberta. 2007. A
pattern recognition approach to
machine translation: Monotone and
non-monotone phrase-based statistical
models. Technical Report DSIC-II/18/07,
Departamento de Sistemas Informa?ticos y
Computacio?n, Universidad Polite?cnica
de Valencia.
Tomita, M. 1985. Feasibility study of
personal/interactive machine translation
systems. In Proceedings of the First
International Conference on Theoretical
and Methodological Issues in Machine
Translation (TMI 85), pages 289?297,
New York, NY.
Ueffing, N., F. J. Och, and H. Ney. 2002.
Generation of word graphs in statistical
machine translation. In Proceedings of
the Conference on Empirical Methods for
Natural Language Processing (EMNLP 02),
pages 156?163, Philadelphia, PA.
Vidal, E. 1997. Finite-state speech-to-speech
translation. In Proceedings of the
International Conference on Acoustic,
Speech and Signal Processing (ICASSP 97),
volume 1, pages 111?114, Munich.
27
Computational Linguistics Volume 35, Number 1
Vidal, E. and F. Casacuberta. 2004. Learning
finite-state models for machine translation.
In Grammatical Inference: Algorithms and
Applications, Proceedings of the 7th
International Coloquium on Grammatical
Inference (ICGI 04), Athens, Greece,
October 11?13, volume 3264 of Lecture
Notes in Artificial Intelligence. Springer,
Heidelberg, pages 16?27.
Vidal, E., F. Casacuberta, L. Rodr??guez,
J. Civera, and C. Mart??nez. 2006.
Computer-assisted translation using
speech recognition. IEEE Transactions
on Speech and Audio Processing,
14(3):941?951.
Vidal, E., F. Thollard, F. Casacuberta
C. de la Higuera, and R. Carrasco. 2005.
Probabilistic finite-state machines?
part II. IEEE Transactions on Pattern
Analysis and Machine Intelligence,
27(7):1025?1039.
Whitelock, P. J., M. McGee Wood, B. J.
Chandler, N. Holden, and H. J. Horsfall.
1986. Strategies for interactive machine
translation: The experience and
implications of the UMIST Japanese
project. In Proceedings of the 11th
International Conference on Computational
Linguistics (COLING 86), pages 329?334,
Bonn.
Yamron, J., J. Baker, P. Bamberg,
H. Chevalier, T. Dietzel, J. Elder,
F. Kampmann, M. Mandel, L. Manganaro,
T. Margolis, and E. Steele. 1993.
LINGSTAT: an interactive, machine-aided
translation system. In Proceedings of the
Workshop on Human Language Technology,
pages 191?195, Princeton, NJ.
Zajac, R. 1988. Interactive translation: A new
approach. In Proceedings of the 12th
International Conference on Computational
Linguistics (COLING 88), pages 785?790,
Budapest.
Zens, R. and H. Ney. 2004. Improvements
in phrase-based statistical machine
translation. In Proceedings of the Human
Language Technology Conference / North
American Chapter of the Association for
Computational Linguistics Annual Meeting
(HLT-NAACL 04), pages 257?264,
Boston, MA.
Zens, R., F. J. Och, and H. Ney. 2002.
Phrase-based statistical machine
translation. In Advances in Artificial
Intelligence. 25th Annual German Conference
on Artificial Intelligence (KI 02), Aachen,
Germany, September 16?22, Proceedings,
volume 2479 of Lecture Notes on Artificial
Intelligence. Springer Verlag, Heidelberg,
pages 18?32.
Zhang, Y. and S. Vogel. 2004. Measuring
confidence intervals for the machine
translation evaluation metrics. In
Proceedings of the Tenth International
Conference on Theoretical and
Methodological Issues in Machine
Translation (TMI 04), pages 294?301,
Baltimore, MD.
28
Architectures for speech-to-speech translation
using finite-state models
Francisco Casacuberta Enrique Vidal
Dpt. de Sistemes Informa`tics i Computacio? &
Institut Tecnolo`gic d?Informa`tica
Universitat Polite`cnica de Vale`ncia
46071 Vale`ncia, SPAIN.
fcn@iti.upv.es, evidal@iti.upv.es
Juan Miguel Vilar
Dpt. de Llenguatges i Sistemes Informa`tics
Universitat Jaume I
Castello?, SPAIN.
jvilar@lsi.uji.es
Abstract
Speech-to-speech translation can be ap-
proached using finite state models and
several ideas borrowed from automatic
speech recognition. The models can be
Hidden Markov Models for the accous-
tic part, language models for the source
language and finite state transducers for
the transfer between the source and target
language. A ?serial architecture? would
use the Hidden Markov and the language
models for recognizing input utterance
and the transducer for finding the transla-
tion. An ?integrated architecture?, on the
other hand, would integrate all the mod-
els in a single network where the search
process takes place. The output of this
search process is the target word sequence
associated to the optimal path. In both
architectures, HMMs can be trained from
a source-language speech corpus, and the
translation model can be learned automat-
ically from a parallel text training cor-
pus. The experiments presented here cor-
respond to speech-input translations from
Spanish to English and from Italian to En-
glish, in applications involving the inter-
action (by telephone) of a customer with
the front-desk of a hotel.
1 Introduction
Present finite-state technology allows us to build
speech-to-speech translation (ST) systems using
ideas very similar to those of automatic speech
recognition (ASR). In ASR the acoustic hidden
Markov models (HMMs) can be integrated into the
language model, which is typically a finite-state
grammar (e.g. a N-gram). In ST the same HMMs
can be integrated in a translation model which con-
sists in a stochastic finite-state transducer (SFST).
Thanks to this integration, the translation process
can be efficiently performed by searching for an
optimal path of states through the integrated net-
work by using well-known optimization procedures
such as (beam-search accelerated) Viterbi search.
This ?integrated architecture? can be compared with
the more conventional ?serial architecture?, where
the HMMs, along with a suitable source language
model, are used as a front-end to recognize a se-
quence of source-language words which is then pro-
cessed by the translation model. A related approach
has been proposed in (Bangalore and Ricardi, 2000;
Bangalore and Ricardi, 2001).
In any case, a pure pattern-recognition approach
can be followed to build the required systems.
Acoustic models can be trained from a suffi-
ciently large source-language speech training set,
in the very same way as in speech recognition.
On the other hand, using adequate learning algo-
rithms (Casacuberta, 2000; Vilar, 2000), the trans-
lation model can also be learned from a sufficiently
large training set consisting of source-target parallel
text.
In this paper, we comment the results obtained us-
ing this approach in EUTRANS, a five-year joint ef-
fort of four European institutions, partially funded
by the European Union.
                                            Association for Computational Linguistics.
                           Algorithms and Systems, Philadelphia, July 2002, pp. 39-44.
                          Proceedings of the Workshop on Speech-to-Speech Translation:
2 Finite-state transducers and speech
translation
The statistical framework allow us to formulate the
speech translation problem as follows: Let x be an
acoustic representation of a given utterance; typi-
cally a sequence of acoustic vectors or ?frames?.
The translation of x into a target-language sentence
can be formulated as the search for a word se-
quence, t?, from the target language such that:
t? = argmax
t
Pr(t|x). (1)
Conceptually, the translation can be viewed as a
two-step process (Ney, 1999; Ney et al, 2000):
x ? s ? t,
where s is a sequence of source-language words
which would match the observed acoustic sequence
x and t is a target-language word sequence associ-
ated with s. Consequently,
Pr(t|x) =
?
s
Pr(t, s|x), (2)
and, with the natural assumption that Pr(x|s, t) does
not depend on the target sentence t,
t? = argmax
t
(
?
s
Pr(s, t) ? Pr(x|s)
)
. (3)
Using a SFST as a model for Pr(s, t) and HMMs
to model Pr(x|s), Eq. 3 is transformed in the opti-
mization problem:
t? = argmax
t
(
?
s
PrT (s, t) ? PrM(x|s)
)
, (4)
where PrT (s, t) is the probability supplied by the
SFST and PrM(x|s) is the density value supplied
by the corresponding HMMs associated to s for the
acoustic sequence x.
2.1 Finite-state transducers
A SFST, T , is a tuple ?Q,?,?, R, q0, F, P ?, where
Q is a finite set of states; q0 is the initial state; ? and
? are finite sets of input symbols (source words) and
output symbols (target words), respectively (??? =
?); R is a set of transitions of the form (q, a, ?, q?)
for q, q? ? Q, a ? ?, ? ? ?? and1 P : R ? IR+
(transition probabilities) and F : Q ? IR+ (final-
state probabilities) are functions such that ?q ? Q:
F (q) +
?
?(a, ?, q?) ? ???? ?Q :
(q, a, ?, q?) ? R
P (q, a, ?, q?) = 1.
Fig. 1 shows a small fragment of a SFST for Spanish
to English translation.
A particular case of finite-state transducers are
known as subsequential transducers (SSTs). These
are finite-state transducers with the restriction of be-
ing deterministic (if (q, a, ?, q), (q, a, ??, q?) ? R,
then ? = ?? and q = q?). SSTs also have output
strings associated to the (final) states. This can fit
well under the above formulation by simply adding
an end-off-sentence marker to each input sentence.
For a pair (s, t) ? ?? ? ??, a translation form,
?, is a sequence of transitions in a SFST T :
? : (q0, s1, ?t1, q1), (q1, s2, ?t2, q2),
. . . , (qI?1, sI , ?tI , qI),
where ?tj denotes a substring of target words (the
empty string for ?tj is also possible), such that
?t1 ?t2 ... ?tI = t and I is the length of the source sen-
tence s. The probability of ? is
PrT (?) = F (qI) ?
I?
i=0
P (qi?1, si, ?ti, qi). (5)
Finally, the probability of the pair (s, t) is
PrT (s, t) =
?
??d(s,t)
PrT (?) (6)
? max
??d(s,t)
PrT (?), (7)
where d(s, t) is the set of all translation forms for
the pair (s, t).
These models have implicit source and target lan-
guage models embedded in their definitions, which
are simply the marginal distributions of PrT . In
practice, the source (target) language model can be
obtained by removing the target (source) words from
each transition of the model.
1By?? and?? we denote the sets of finite-length strings on
? and ?, respectively
0 1una / a  (0.5)la / the (0.5)
2habitaci?n / room (0.1)
4
habitaci?n / room (0.3)
3habitaci?n / ?   (0.6)
doble / with two beds (1)
doble / double room (0.3)
individual / single room (0.7)
Figure 1: Example of SFST. ? denotes the empty string. The source sentence ?una habitacio?n doble? can
be translated to either ?a double room? or ?a room with two beds?. The most probable translation is the
first one with probability of 0.09.
The structural (states and transitions) and the
probabilistic components of a SFST can be learned
automatically from training pairs in a single process
using the MGTI technique (Casacuberta, 2000). Al-
ternatively, the structural component can be learned
using the OMEGA technique (Vilar, 2000), while
the probabilistic component is estimated in a second
step using maximum likelihood or other possible cri-
teria (Pico? and Casacuberta, 2001). One of the main
problems that appear during the learning process is
the modelling of events that have not been seen in
the training set. This problem can be confronted,
in a similar way as in language modelling, by using
smoothing techniques in the estimation process of
the probabilistic components of the SFST (Llorens,
2000). Alternatively, smoothing can be applied in
the process of learning both components (Casacu-
berta, 2000).
2.2 Architectures for speech translation
Using Eq. 7 as a model for Pr(s, t) in Eq. 4,
t? = argmax
t
(
?
s
max
??d(s,t)
PrT (?) ? PrM(x|s)
)
,
(8)
For the computation of PrM(x|s) in Eq. 8, let
b be an arbitrary segmentation of x into I acous-
tic subsequences, each of which associated with a
source word (therefore, I is the number of words in
s). Then:
PrM(x|s) =
?
b
I?
i=1
PrM(x?i|si), (9)
where x?i is the i-th. acoustic segment of b, and each
source word si has an associated HMM that supplies
the density value PrM(x?i|si).
Finally, by substituting Eq. 5 and Eq. 9 into Eq. 8
and approximating sums by maximisations:
t? = argmax
??d(s,t),b
I?
i=1
P (qi?1, si, t?i, qi) ? PrM(x?i|si).
(10)
Solving this maximisation yields (an approximation
to) the most likely target-language sentence t? for the
observed source-language acoustic sequence x.
This computation can be accomplished using the
well known Viterbi algorithm. It searches for an op-
timal sequence of states in an integrated network (in-
tegrated architecture) which is built by substituting
each edge of the SFST by the corresponding HMM
of the source word associated to the edge.
This integration process is illustrated in Fig. 2. A
small SFST is presented in the first panel (a) of this
figure. In panel (b), the source words in each edge
are substituted by the corresponding phonetic tran-
scription. In panel (c) each phoneme is substituted
by the corresponding HMM of the phone. Clearly,
this direct integration approach often results in huge
finite-state networks. Correspondingly, a straight-
forward (dynamic-programming) search for an op-
timal target sentence may require a prohibitively
high computational effort. Fortunately, this compu-
tational cost can be dramatically reduced by means
of standard heuristic acceleration techniques such as
beam search.
An alternative, which sacrifices optimality more
drastically, is to break the search down into two
steps, leading to a so-called ?serial architecture?. In
the first step a conventional source-language speech
decoding system (using just a source-language lan-
guage model) is used to obtain a single (may be mul-
tiple) hypothesis for the sequence of uttered words.
In the second step, this text sequence is translated
into a target-language sentence.
0 1la / the 2maleta / ?
3bolsa / ? 4
azul / blue suitcase
azul / blue bag
a) Original FST.
0 l / ? 1a / the
m / ?
b / ?
a / ?
o / ?
l / ? e / ? t / ? 2t / ?
a / ? a / ? z / ?s / ?
l / ? s / ?
3s / ?
a / ? a / ? z / ?s / ?
u / ?
4
l / blue suitcase
u / ? l / blue bag
b) Lexical expansion.
0 l a 1   the   m
b
a l e
t
t
a
2
 
a 
o l s
s
a
3
 
a 
z
s
u l
4
             blue suitcase           
z
s
u
l
 
      blue bag
c) Phonetic expansion.
Figure 2: Example of the integration process of the lexical knowledge (figure b) and the phonetic knowledge
(figure c) in a FST (figure a). ? denotes the empty string in panels a and b. In panel c, source symbols are
typeset in small fonts, target strings are typeset in large fonts and edges with no symbols denote empty
transitions.
Using Pr(s, t) = Pr(t | s) ? Pr(s) in Eq. 3 and
approximating the sum by the maximum, the opti-
mization problem can be presented as
(t?, s?) = argmax
t,s
(Pr(t|s) ? Pr(s) ? Pr(x|s)) ,
(11)
and the two-step approximation reduces to
s? ? argmax
s
{Pr(s) ? Pr(x|s)} , (12)
t? ? argmax
t
Pr(t|s?) (13)
= argmax
t
Pr(s?, t). (14)
In other words, the search for an optimal target-
language sentence is now approximated as follows:
1. Word decoding of x. A source-language sen-
tence s? is searched for using a source language
model, PrN (s), for Pr(s) and the correspond-
ing HMMs, PrM(x|s), to model Pr(x|s):
s? ? argmax
s
(PrN (s) ? PrM(x|s)) .
2. Translation of s?. A target-language sentence t?
is searched for using a SFST, PrT (s?, t), as a
model of Pr(s?, t)
t? ? argmax
t
PrT (s?, t).
A better alternative for this crude ?two-step? ap-
proach is to use Pr(s, t) = Pr(s | t) ?Pr(t) in Eq. 3.
Now, approximating the sum by the maximum, the
optimization problem can be presented as
(t?, s?) = argmax
t,s
(Pr(s | t) ? Pr(t) ? Pr(x | s)) ,
(15)and now the two-step approximation reduces to
s? ? argmax
s
{Pr(s | t) ? Pr(x | s)} , (16)
t? ? argmax
t
Pr(s? | t) ? Pr(t) (17)
= argmax
t
Pr(s?, t). (18)
The main problem of this approach is the term
t that appears in the first maximisation (Eq. 16).
A possible solution is to follow an iterative proce-
dure where t, that is used for computing s?, is the
one obtained from argmaxt Pr(s?, t) in the previous
iteration (Garc??a-Varea et al, 2000). In this case,
Pr(s | t) can be modelled by a source language
model that depends on a previously computed t?:
PrN ,t?(s). In the first iteration no t? is known, but
PrN ,t?(s) can be approximated by PrN (s). Follow-
ing this idea, the search can be formulated as:
Initialization:
Let PrN ,t(s) be approximated by a source lan-
guage model PrN (s).
while not convergence
1. Word decoding of x. A source-language sen-
tence s? is searched for using a source lan-
guage model that depends on the target sen-
tence, PrN ,t?(s), for Pr(s | t) (t? is the t? com-
puted in the previous iteration) and the corre-
sponding HMMs, PrM(x | s), to model Pr(x |
s):
s? ? argmax
s
(
PrN ,t?(s) ? PrM(x | s)
)
.
2. Translation of s?. A target-language sentence t?
is searched for using a SFST, PrT (s?, t), as a
model of Pr(s?, t)
t? ? argmax
t
PrT (s?, t).
end of while
The first iteration corresponds to the sequential ar-
chitecture proposed above.
While this seems a promising idea, only very
preliminary experiments were carried out (Garc??a-
Varea et al, 2000) and it has not been considered in
the experiments presented in the present paper.
3 Experiments and results
Three sets of speech-to-speech translation proto-
types have been implemented for Spanish to English
and for Italian to English. In all of them, the appli-
cation was the translation of queries, requests and
complaints made by telephone to the front desk of
a hotel. Three tasks of different degree of difficulty
have been considered.
In the first one (EUTRANS-0), Spanish-to-English
translation systems were learned from a big and
well controlled training corpus: about 170k differ-
ent pairs (? 2M running words), with a lexicon of
about 700 words. In the second one (EUTRANS-
I), also from Spanish to English, the systems were
learned from a random subset of 10k pairs (? 100k
running words) from the previous corpus; this was
established as a more realistic training corpus for the
kind of application considered. In the third and most
difficult one, from Italian to English (EUTRANS-II),
the systems were learned from a small training cor-
pus that was obtained from a transcription of a spon-
taneous speech corpus: about 3k pairs (? 60k run-
ning words), with a lexicon of about 2,500 words.
For the serial architecture, the speech decoding
was performed in a conventional way, using the
same acoustic models as with the integrated archi-
tecture and trigrams of the source language models.
For the integrated architecture, the speech decoding
of an utterance is a sub-product of the translation
process (the sequence of source words associated to
the optimal sequence of transitions that produces the
sequence of target words).
The acoustic models of phone units were trained
with the HTK Toolkit (Woodland, 1997). For the
EUTRANS-0 and EUTRANS-I prototypes, a training
speech corpus of 57,000 Spanish running words was
used, while the EUTRANS-II Italian acoustic models
were trained from another corpus of 52,000 running
words
Performance was assessed on the base of 336
Spanish sentences in the case of EUTRANS-0
and EUTRANS-I and 278 Italian sentences in
EUTRANS-II. In all the cases, the test sentences (as
well as the corresponding speakers) were different
from those appearing in the training data.
For the easiest task, EUTRANS-0, (well controlled
and a large training set), the best result was achieved
with an integrated architecture and a SFST obtained
with the OMEGA learning technique. A Transla-
tion Word Error Rate of 7.6% was achieved, while
the corresponding source-language speech decoding
Word Error Rate was 8.4%. Although these figures
may seem strange (and they would certainly be in
the case of a serial architecture), they are in fact con-
sistent with the fact that, in this task (corpus), the tar-
get language exhibits a significantly lower perplex-
ity than the source language.
For the second, less easy task EUTRANS-I, (well
controlled task but a small training set), the best
result was achieved with an integrated architecture
and a SFST obtained with the MGTI learning tech-
nique (10.5% of word error rate corresponding to the
speech decoding and 12.6% of translation word er-
ror rate).
For the most difficult task, EUTRANS-II (spon-
taneous task and a small training set), the best result
was achieved with a serial architecture and a SFST
obtained with the MGTI learning technique (22.1%
of word error rate corresponding to the speech de-
coding and 37.9% of translation word error rate).
4 Conclusions
Several systems have been implemented for speech-
to-speech translation based on SFSTs. Some of them
were implemented for translation from Italian to En-
glish and the others for translation from Spanish to
English. All of them support all kinds of finite-state
translation models and run on low-cost hardware.
They are currently accessible through standard tele-
phone lines with response times close to or better
than real time.
From the results presented, it appears that the in-
tegrated architecture allows for the achievement of
better results than the results achieved with a serial
architecture when enough training data is available
to train the SFST. However, when the training data
is insufficient, the results obtained by the serial ar-
chitecture were better than the results obtained by
the integrated architecture. This effect is possible
because the source language models for the exper-
iments with the serial architecture were smoothed
trigrams. In the case of sufficient training data, the
source language model associated to a SFST learnt
by the MGTI or OMEGA is better than trigrams
(Section 2.1). However, in the other case (not suf-
ficient training data) these source languages were
worse than trigrams. Consequently an important
degradation is produced in the implicit decoding of
the input utterance.
Acknowledgments
The authors would like to thank the researchers that
participated in the EUTRANS project and have de-
veloped the methodologies that are presented in this
paper.
This work has been partially supported by the Eu-
ropean Union under grant IT-LTR-OS-30268, by the
project TT2 in the ?IST, V Framework Programme?,
and Spanish project TIC 2000-1599-C02-01.
References
S. Bangalore and G. Ricardi. 2000. Stochastic finite-
state models for spoken language machine translation.
In Workshop on Embeded Machine Translation Sys-
tems.
S. Bangalore and G. Ricardi. 2001. A finite-state ap-
proach to machine translation. In The Second Meeting
of the North American Chapter of the Association for
Computational Linguistics.
F. Casacuberta. 2000. Inference of finite-state trans-
ducers by using regular grammars and morphisms.
In Grammatical Inference: Algorithms and Applica-
tions, volume 1891 of Lecture Notes in Artificial Intel-
ligence, pages 1?14. Springer-Verlag.
I. Garc??a-Varea, A. Sanchis, and F. Casacuberta. 2000.
A new approach to speech-input statistical translation.
In Proceedings of the International Conference on Pat-
tern Recognition (ICPR2000), volume 2, pages 907?
910, Barcelona, Sept. IAPR, IEEE Press.
D. Llorens. 2000. Suavizado de auto?matas y traduc-
tores finitos estoca?sticos. Ph.D. thesis, Universitat
Polite`cnica de Vale`ncia.
H. Ney, S. Nie?en, F. Och, H. Sawaf, C. Tillmann, and
S. Vogel. 2000. Algorithms for statistical translation
of spoken language. IEEE Transactions on Speech and
Audio Processing, 8(1):24?36.
H. Ney. 1999. Speech translation: Coupling of recogni-
tion and translation. In Proceedins of the IEEE Inter-
national Conference on Acoustic, Speech and Signal
Processing, pages 517?520, Phoenix, AR, March.
D. Pico? and F. Casacuberta. 2001. Some statistical-
estimation methods for stochastic finite-state transduc-
ers. Machine Learning, 44:121?141.
J.M. Vilar. 2000. Improve the learning of subsequen-
tial transducers by using alignments and dictionaries.
In Grammatical Inference: Algorithms and Applica-
tions, volume 1891 of Lenture Notes in Artificial Intel-
ligence, pages 298?312. Springer-Verlag.
S. Young; J. Odell; D. Ollason; V. Valtchev; P. Wood-
land. 1997. The HTK Book (Version 2.1). Cambridge
University Department and Entropic Research Labora-
tories Inc.
From Machine Translation to Computer Assisted Translation using
Finite-State Models
Jorge Civera, Elsa Cubel, Antonio L. Lagarda, David Pico?,
Jorge Gonza?lez, Enrique Vidal, Francisco Casacuberta
Instituto Tecnolo?gico de Informa?tica
Dpto. de Sistemas Informa?ticos y Computacio?n, Universidad Polite?cnica de Valencia
E-46071 Valencia, Spain
jorcisai@iti.upv.es
Juan M. Vilar, Sergio Barrachina
Dpto. de Lenguajes y Sistemas Informa?ticos, Universidad Jaime I,
E-12071 Castello?n de la Plana, Spain
jvilar@lsi.uji.es
Abstract
State-of-the-art machine translation techniques are
still far from producing high quality translations.
This drawback leads us to introduce an alterna-
tive approach to the translation problem that brings
human expertise into the machine translation sce-
nario. In this framework, namely Computer As-
sisted Translation (CAT), human translators inter-
act with a translation system, as an assistance tool,
that dinamically offers, a list of translations that best
completes the part of the sentence already trans-
lated. In this paper, finite state transducers are
presented as a candidate technology in the CAT
paradigm. The appropriateness of this technique
is evaluated on a printer manual corpus and re-
sults from preliminary experiments confirm that hu-
man translators would reduce to less than 25% the
amount of work to be done for the same task.
1 Introduction
State-of-the-art machine translation techniques are
still far from producing high quality translations.
This drawback leads us to introduce an alternative
approach to the translation problem that brings
human expertise into the machine translation sce-
nario. (Langlais et al, 2000) proposed this idea that
can be illustrated as follows. Initially, the human
translator is provided with a possible translation
for the sentence to be translated. Unfortunately in
most of the cases, this translation is not perfect, so
the translator amends it and asks for a translation
of the part of the sentence still to be translated
(completion). This latter interaction is repeated as
many times as needed until the final translation is
achieved.
The scenario described in the previous para-
graph, can be seen as an iterative refinement of
the translations offered by the translation system,
that without possessing the desired quality, help the
translator to increase his/her productivity. Nowa-
days, this lack of translation excellence is a common
characteristic in all machine translation systems.
Therefore, the human-machine synergy represented
by the CAT paradigm seems to be more promising
than fully-automatic translation in the near future.
The CAT paradigm has two important as-
pects: the models need to provide adequate com-
pletions and they have to do so efficiently to per-
form under usability constrains. To fulfill these two
requirements, Stochastic Finite State Transducers
(SFST) have been selected since they have proved
in the past to be able to provide adequate transla-
tions (Vidal, 1997; Knight and Al-Onaizan, 1998;
Amengual et al, 2000; Casacuberta et al, 2001;
Bangalore and Ricardi, 2001). In addition, efficient
parsing algorithms can be easily adapted in order to
provide completions.
The rest of the paper is structured as follows.
The following section introduces the general setting
for machine translation and finite state models. In
section 3, the search procedure for an interactive
translation is presented. Experimental results are
presented in section 4. Finally, some conclusions
and future work are explained in section 5.
2 Machine translation with finite-state
transducers
Given a source sentence   , the goal of MT is to find
a target sentence

t that maximizes:
t   argmax
t

t  s   argmax
t

t 	 s  (1)
The joint distribution  t 	 s  can be modeled
by a Stochastic Finite State Transducer 
 (Pico? and
Casacuberta, 2001):

t   argmax
t

t 	 s  argmax
t

t 	 s  (2)
A Stochastic Finite-State Transducer (SFST)
is a finite-state network whose transitions are la-
beled by three items:
1. a source symbol (a word from the source lan-
guage vocabulary);
2. a target string (a sequence of words from the
target language vocabulary) and
3. a transition probability.
They have been successfully applied into
many translation tasks (Vidal, 1997; Amengual et
al., 2000; Casacuberta et al, 2001). Furthermore,
there exist efficient search algorithms like Viterbi
(Viterbi, 1967) for the best path and the Recur-
sive Enumeration Algorithm (REA) (Jime?nez and
Marzal, 1999) for the  -best paths.
One possible way of inferring SFSTs is the
Grammatical Inference and Alignments for Trans-
ducer Inference (GIATI) technique (the previous
name of this technique was MGTI - Morphic-
Generator Transducer Inference) (Casacuberta et
al., 2004). Given a finite sample of string pairs, it
works in three steps:
1. Building training strings. Each training pair
is transformed into a single string from an ex-
tended alphabet to obtain a new sample of
strings. The ?extended alphabet? contains
words or substrings from source and target sen-
tences coming from training pairs.
2. Inferring a (stochastic) regular grammar.
Typically, smoothed  -gram is inferred from
the sample of strings obtained in the previous
step.
3. Transforming the inferred regular grammar
into a transducer. The symbols associated
to the grammar rules are transformed into
source/target symbols by applying an ade-
quate transformation, thereby transforming the
grammar inferred in the previous step into a
transducer.
The transformation of a parallel corpus into
a corpus of single sentences is performed with the
help of statistical alignments: each word is joined
with its translation in the output sentence, creating
an ?extended word?. This joining is done taking
care not to invert the order of the output words. The
third step is trivial with this arrangement. In our
experiments, the alignments are obtained using the
GIZA software (Och and Ney, 2000; Al-Onaizan et
al., 1999), which implements IBM statistical mod-
els (Brown et al, 1993).
3 Interactive search
The concept of interactive search is closely related
to the CAT paradigm. This paradigm introduces the
new factor t into the general machine translation
equation (Equation 1). t represents a prefix in the
target language obtained as a result of the interac-
tion between the human translator and the machine
translation system.
As a side effect of this reformulation, the op-
timization defined in Equation 3 is performed over
the set of target suffixes rather than the set of com-
plete target sentences. Thence, the goal of CAT in
the finite-state transducer framework is to find a pre-
diction of the best suffix

t  , given a source sentence
s, a prefix of the target sentence t  and a SFST 
 :

t  argmax
t 
Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 199?207,
Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005
A Recursive Statistical Translation Model?
Juan Miguel Vilar
Dpto. de Lenguajes y Sistemas
Informa?ticos
Universitat Jaume I
Castello?n (Spain)
jvilar@lsi.uji.es
Enrique Vidal
Dpto. de Sistemas Informa?ticos
y Computacio?n
Universidad Polite?cnica de Valencia
Instituto Tecnolo?gico de Informa?tica
Valencia (Spain)
evidal@iti.upv.es
Abstract
A new model for statistical translation is
presented. A novel feature of this model
is that the alignments it produces are hier-
archically arranged. The generative pro-
cess begins by splitting the input sen-
tence in two parts. Each of the parts is
translated by a recursive application of
the model and the resulting translation
are then concatenated. If the sentence
is small enough, a simpler model (in our
case IBM?s model 1) is applied.
The training of the model is explained. Fi-
nally, the model is evaluated using the cor-
pora from a large vocabulary shared task.
1 Introduction
Suppose you were to find an English translation for
a Spanish sentence. One possible approach is to as-
sume that every English sentence is a candidate but
that different English sentences have different prob-
abilities of being the correct translation. Then, the
translation task can be divided in two parts: define
an adequate probability distribution that answers to
the question ?given this English sentence, which is
the probability that it is a good translation of that
Spanish sentence??; and use that distribution in or-
der to find the most likely translation of your input
sentence.
?Work partially supported by Bancaixa through the project
?Sistemas Inductivos, Estad??sticos y Estructurales, para la Tra-
duccio?n Automa?tica (Siesta)?.
This approach is referred to as the statistical ap-
proach to machine translation. The usual approach
is to define an statistical model and train its parame-
ters from a training corpus consisting in pairs of sen-
tences that are known to be translation of each other.
Different models have been presented in the litera-
ture, see for instance (Brown et al, 1993; Och and
Ney, 2004; Vidal et al, 1993; Vogel et al, 1996).
Most of them rely on the concept of alignment: a
mapping from words or groups of words in a sen-
tence into words or groups in the other (in the case
of (Vidal et al, 1993) the mapping goes from rules
in a grammar for a language into rules of a grammar
for the other language). This concept of alignment
has been also used for tasks like authomatic vocab-
ulary derivation and corpus alignment (Dagan et al,
1993).
A new statistical model is proposed in this pa-
per, which was initially introduced in (Vilar Torres,
1998). This model is designed so that the align-
ment between two sentences can be seen in an struc-
tured manner: each sentence is divided in two parts
and they are put in correspondence; then each of
those parts is similarly divided and related to its
translation. This way, the alignment can be seen as
a tree structure which aligns progressively smaller
segments of the sentences. This recursive procedure
gives its name to the model: MAR, which comes
from ?Modelo de Alineamiento Recursivo?, which
is Spanish for ?Recursive Alignment Model?.
The rest of the paper is structured as follows: af-
ter a comment on previous works, we introduce the
notation that we will use throughout the paper, then
we briefly explain the model 1 from IBM, next we
199
introduce our model, then we explain the process
of parameter estimation, and how to use the model
to translate new test sentences. Finally, we present
some experiments and results, together with conclu-
sions.
2 Previous works
The initial formulation of the proposed model,
including the training procedures, was presented
in (Vilar Torres, 1998), along with preliminary ex-
periments in a small translation task which provided
encouraging results.
This model shares some similarities with the
stochastic inversion transduction grammars (SITG)
presented by Wu in (Wu, 1997). The main point
in common is the type of possible alignments con-
sidered in both models. Some of the properties
of these alignments are studied in (Zens and Ney,
2003). However, the parametrizations of SITGs and
the MAR are completely different. The generative
process of SITGs produces simultaneously the in-
put and output sentences and the parameters of the
model refer to the rules of the nonterminals. This
provides a symmetry to both input and output sen-
tences. In contrast, our model clearly distinguishes
the input and output sentences and the parameters
are based on observable properties of the strings
(their lengths and the words composing them). On
the other hand, the MAR idea of splitting the sen-
tences until a simple structure is found, also ap-
pears in the Divisive Clustering approach presented
in (Deng et al, 2004). Again, the main difference
lies in the probabilistic modeling of the alignments.
In Divisive Clustering a uniform distribution on the
alignments is assumed while MAR uses a explicit
parametrization.
3 Some notation
In the rest of the paper, we use the following nota-
tion. Sentences are taken as concatenations of sym-
bols (words) and represented using a letter and a
small bar, like in x?. The individual words are de-
signed by the name of the sentence and a subindex
indicating the position, so x? = x1x2 . . . xn. The
length of a sentence is indicated by |x?|. Segments
of a sentence are denoted by x?ji = xi . . . xj . For the
substrings of the form x?|x?|i we use the notation x?.i.
Consistently, x? denotes the input sentence and y?
its translation and both are assumed to have at least
one word. The input and output vocabularies are X
and Y , respectively. Finally, we assume that we are
presentend a set M for training our models. The ele-
ments of this set are pairs (x?, y?) where y? is a possible
translation for x?.
4 IBM?s model 1
IBM?s model 1 is the simplest of a hierarchy of five
statistical models introduced in (Brown et al, 1993).
Each model of the hierarchy can be seen as a refine-
ment of the previous ones. Although model 1, which
we study here, relies on the concept of alignment,
its formulation allows an interpretation of it as a re-
lationship between multisets of words (the order of
the words is irrelevant in the final formula).
A word of warning is in order here. The model we
are going to present has an important difference with
the original: we do not use the empty word. This is
a virtual word which does not belong to the vocabu-
lary of the task and that is added to the beginning of
each sentence in order to allow words in the output
that cannot be justified by the words in the input. We
have decided not to incorporate it because of the use
we are going to make of the model. As we will see,
model 1 is going to be used repeatedly over different
substrings of the input sentence in order to analyze
their contribution to the total translation. This means
that we would have an empty word in each of these
substrings. We have decided to avoid this ?prolifer-
ation? of empty words. Future work may introduce
the concept in a more appropriate way.
The model 1 makes two assumptions. That a
stochastic dictionary can be employed to model the
probability that word y is the translation of word x
and that all the words in the input sentence have the
same weight in producing a word in the output. This
leads to:
pI(y? | x?) =
?(|x?|, |y?|)
|x?||y?|
|y?|?
j=1
|x?|?
i=1
t(yj | xi). (1)
Where t is the stochastic dictionary and ? represents
a table that relates the length of the alignment with
the length of the input sentence (we assume that
there is a finite range of possible lengths). This ex-
plicit relations between the lengths is not present in
200
the original formulation of the model, but we prefer
to include it so that the probabilities are adequately
normalized.
Clearly, this model is not adequate to describe
complex translations in which complicated patterns
and word order changes may appear. Nevertheless,
this model can do a good job to describe the transla-
tion of short segments of texts. For example, it can
be adequate to model the translation of the Spanish
?gracias? into the English ?thank you?.
5 A Recursive Alignment Model
To overcome that limitation of the model we will
take the following approach: if the sentence is com-
plex enough, it will be divided in two and the two
halves will be translated independently and joined
later; if the sentence is simple, the model 1 will be
used.
Let us formalize this intuition for the generative
model. We are given an input sentence x? and the first
decission is whether x? is going to be translated by
IBM?s model 1 or it is complex enough to be trans-
lated by MAR. In the second case, three steps are
taken: a cut point of x? is defined, each of the result-
ing parts are translated, and the corresponding trans-
lations are concatenated. For the translation of the
second step, the same process is recursively applied.
The concatenation of the third step can be done in
a ?direct? way (the translation of the first part and
then the translation of the second) or in an ?inverse?
way (the translation of the second part and then the
translation of the first). The aim of this choice is to
allow for the differences in word order between the
input and ouput languages.
So, we are proposing an alignment model in
which IBM?s model 1 will account for translation
of elementary segments or individual words while
translation of larger and more complex segments or
whole sentences will rely on a hierarchical align-
ment pattern in which model 1 alignments will be
on the lowest level of the hierarchy.
Following this discussion, the model can be for-
mally described through a series of four random ex-
periments:
? The first is the selection of the model. It has
two possible outcomes: IBM and MAR, with
obvious meanings.
? The second is the choice of b, a cut point of x?.
The segment x?b1 will be used to generate one of
the parts of the translation, the segment x?.b+1
will generate the other. It takes values from 1
to |x?| ? 1.
? The third is the decision about the order of the
concatenation. It has two possible outcomes:
D (for direct) and I (for inverse).
? The fourth is the translation of each of the
halves of x?. They take values in Y+.
The translation probability can be approximated
as follows:
pT (y? | x?) = Pr(M = IBM | x?)pI(y? | x?)
+ Pr(M = MAR | x?)pM (y? | x?).
The value of pI(y? | x?) corresponds to IBM?s
model 1 (Equation 1). To derive pM (y? | x?), we ob-
serve that:
pM (y? | x?) =
|x?|?1?
b=1
Pr(b | x?)
?
d?{D,I}
Pr(d | b, x?)
?
y?1?Y+
Pr(y?1 | b, d, x?)
?
y?2?Y+
Pr(y?2 | b, d, x?, y?1) Pr(y? | d, b, x?, y?1, y?2).
Note that the probability that y? is generated from
a pair (y?1, y?2) is 0 if y? 6= y?1y?2 and 1 if y? = y?1y?2, so
the last two lines can be rewritten as:
?
y?1?Y+
Pr(y?1 | b, d, x?)
?
y?2?Y+
Pr(y?2 | b, d, x?, y?1) Pr(y? | b, d, x?, y?1, y?2)
=
?
y?1,y?2?Y
+
y?=y?1y?2
Pr(y?1 | b, d, x?) Pr(y?2 | b, d, x?, y?1)
=
?
y?1 ? pref(y?)? y?
Pr(y?1 | b, d, x?) Pr(y?
?1
1 y? | b, d, x?, y?1)
=
|y?|?1?
c=1
Pr(y?c1 | b, d, x?) Pr(y?
.
c+1 | b, d, x?, y?
c
1),
201
where pref(y?) is the set of prefixes of y?. And finally:
pM (y? | x?) =
|x?|?1?
b=1
Pr(b | x?)
?
d?{D,I}
Pr(d | b, x?)
|y?|?1?
c=1
Pr(y?c1 | b, d, x?) Pr(y?
.
c+1 | b, d, x?, y?
c
1).
(2)
The number of parameters of this model is very
large, so it is necessary to introduce some simplifi-
cations in it. The first one relates to the decision of
the translation model: we assume that it can be done
just on the basis of the length of the input sentence.
That is, we cat set up two tables, MI and MM , so
that
Pr(M = IBM | x?) ? MI(|x?|),
Pr(M = MAR | x?) ? MM (|x?|).
Obviously, for any x? ? X+, we will haveMI(|x?|)+
MM (|x?|) = 1. On the other hand, since it is not
possible to break a one word sentence, we define
MI(1) = 1. This restriction comes in the line men-
tioned before: the translation of longer sentences
will be structured whereas shorter ones can be trans-
lated directly.
In order to decide the cut point, we will assume
that the probability of cutting the input sentence at
a given position b is most influenced by the words
around it: xb and xb+1. We use a table B such that:
Pr(b | x?) ?
B(xb, xb+1)
?|x?|?1
i=1 B(xi, xi+1)
.
This can be interpreted as having a weight for each
pair of words and normalizing these weights in each
sentence in order to obtaing a proper probability dis-
tribution.
Two more tables, DD and DI , are used to store the
probabilities that the alignment be direct or inverse.
As before, we assume that the decission can be made
on the basis of the symbols around the cut point:
Pr(d = D | b, x?) = DD(xb, xb+1),
Pr(d = I | b, x?) = DI(xb, xb+1).
Again, we have DD(xb, xb+1) + DI(xb, xb+1) = 1
for every pair of words (xb, xb+1).
Finally, a probability must be assigned to the
translation of the two halves. Assuming that they are
independent we can apply the model in a recursive
manner:
Pr(y?c1 | b, d, x?) ?
{
pT (y?c1 | x?
b
1) if d = D,
pT (y?c1 | x?
.
b+1) if d = I ,
Pr(y?.c+1 | b, d, x?, y?
c
1) ?
{
pT (y?.c+1 | x?
.
b+1) if d = D,
pT (y?.c+1 | x?
b
1) if d = I .
Finally, we can rewrite (2) as:
pM (y? | x?) =
|x?|?1?
b=1
B(xb, xb+1)
?|x?|?1
i=1 B(xi, xi+1)
?
(
DD(xb, xb+1)
|y?|?1?
c=1
pT (y?
c
1 | x?
b
1)pT (y?
.
c+1 | x?
.
b+1)
+DI(xb, xb+1)
|y?|?1?
c=1
pT (y?
.
c+1 | x?
b
1)pT (y?
c
1 | x?
.
b+1)
)
.
The final form of the complete model is then:
pT (y? | x?) =
MI(|x?|)pI(y? | x?)
+MM (|x?|)
|x?|?1?
b=1
B(xb, xb+1)
?|x?|?1
i=1 B(xi, xi+1)
?
(
DD(xb, xb+1)
|y?|?1?
c=1
pT (y?
c
1 | x?
b
1)pT (y?
.
c+1 | x?
.
b+1)
+DI(xb, xb+1)
|y?|?1?
c=1
pT (y?
.
c+1 | x?
b
1)pT (y?
c
1 | x?
.
b+1)
)
.
(3)
6 Parameter estimation
Once the model is defined, it is necessary to find
a way of estimating its parameters given a training
corpus M. We will use maximun likelihood estima-
tion. In our case, the likelihood of the sample corpus
is:
V =
?
(x?,y?)?M
pT (y? | x?).
202
In order to maximize V , initial values are given
to the parameters and they are reestimated using re-
peatedly Baum-Eagon?s (Baum and Eagon, 1967)
and Gopalakrishnan?s (Gopalakrishnan et al, 1991)
inequalities. Let P be a parameter of the model (ex-
cept for those in B) and let F(P ) be its ?family? (i.e.
the set of parameters such that
?
Q?F(P ) Q = 1).
Then, a new value of P can be computed as follows:
N (P ) =
P
? V
? P
?
Q?F(P )
Q
? V
? Q
=
?
(x?,y?)?M
P
pT (y? | x?)
? pT (y? | x?)
? P
?
Q?F(P )
?
(x?,y?)?M
Q
pT (y? | x?)
? pT (y? | x?)
? Q
=
C(P )
?
Q?F(P )
C(Q)
,
(4)
where
C(P ) =
?
(x?,y?)?M
P
pT (y? | x?)
? pT (y? | x?)
? P
, (5)
are the ?counts? of parameter P . This is correct as
long as V is a polynomial in P . However, we have a
problem for B since V is a rational function of these
parameters. We can solve it by assuming, without
lose of generality, that
?
x1,x2?X B(x1, x2) = 1.
Then Gopalakrishnan?s inequality can be applied
similarly and we get:
N (P ) =
C + C(P )
?
Q?F(P )
C + C(Q)
, (6)
where C is an adequate constant. Now it is easy
to design a reestimation algorithm. The algorithm
gives arbitrary initial values to the parameters (typi-
cally those corresponding to uniform probabilities),
computes the counts of the parameters for the corpus
and, using either (4) or (6), gets new values for the
parameters. This cycle is repeated until a stopping
criterion (in our case a prefixed number of iterations)
is met. This algorithm can be seen in Figure 1
7 Some notes on efficiency
Estimating the parameters as discussed above entails
high computational costs: computing pT (y? | x?) re-
quires O(mn) arithmetic operations involving the
values of pT (y?ji | x?lk) for every possible value of
i, j, k and l, which are O(m2n2). This results in a
global cost of O(m3n3). On the other hand, com-
puting ? pT? P costs as much as computing pT . So it is
interesting to keep the number of computed deriva-
tives low.
7.1 Reduction of the parameters to train
In the experiments we have followed some heuristics
in order not to reestimate certain parameters:
? The values of MI ?and, consequently,
of MM? for lengths higher than a threshold
are assumed to be 0 and therefore there is no
need to estimate them.
? As a consequence, the values of ? for lengths
above the same threshold, need not be reesti-
mated.
? The values of t for pairs of words with counts
under a certain threshold are not reestimated.
Furthermore, during the computation of counts, the
recursion is cut on those substring pairs where the
value of the probability for the translation is very
small.
7.2 Efficient computation of model 1
Other source of optimization is the realization that
for computing pT (y? | x?), it is necessary to com-
pute the value of pI for each possible pair (x?ieib, y?oeob)
(where ib, ie, ob and oe stand for input begin, in-
put end, output begin and output end, respectively).
Fortunately, it is possible to accelerate this compu-
tations. First, define:
I(ib, ie, ob, oe) =
pI(x?ieib, y?
oe
ob)
?(ie? ib + 1, oe? ob + 1)
=
1
(ie? ib + 1)oe?ob+1
oe?
j=ob
ie?
i=ib
t(y?j | x?i).
Now let
S(ib, ie, j) =
ie?
i=ib
t(y?j | x?i).
203
Algorithm Maximum likelihood estimation
give initial values to the parameters;
repeat
initialize the counts to 0;
for each (x?, y?) ? M do
compute pT (y? | x?);
for each parameter P involved in the alignment of (x?, y?) do
CP := CP +
P
pT (y? | x?)
? pT (y? | x?)
? P
;
endfor
endfor
for each parameter P do
reestimate P using (4) or (6);
endfor
until the stopping criterion is met;
End Maximum likelihood estimation
Figure 1: Algorithm for maximum likelihood estimation of the parameters of MAR
This leads to
I(ib, ie, ob, oe) = S(ib, ie, ob),
if ob = oe, and to
I(ib, ie, ob, oe) =
I(ib, ie, ob, oe? 1)S(ib, ie, ob)
(ie? ib + 1)
,
if ob 6= oe.
So we can compute all values of I with the algo-
rithm in Figure 2.
7.3 Splitting the corpora
Another way of reducing the costs of training has
been the use of a heuristic to split long sentences
into smaller parts with a length less than l words.
Suppose we are to split sentences x? and y?. We
begin by aligning each word in y? to a word in x?.
Then, a score and a translation is assigned to each
substring x?ji with a length below l. The translation is
produced by looking for the substring of y? which has
a length below l and which has the largest number
of words aligned to positions between i and j. The
pair so obtained is given a score equal to sum of: (a)
the square of the length of x?ji ; (b) the square of the
number of words in the output aligned to the input;
and (c) minus ten times the sum of the square of the
number of words aligned to a nonempty position out
of x?ji and the number of words outside the segment
chosen that are aligned to x?ji .
After the segments of x? are so scored, the partition
of x? that maximizes the sum of scores is computed
by dynamic programming.
8 Translating the test sentences
The MAR model can be used to obtain adequate
bilingual templates which can be used to translate
new test sentences using an appropriate template-
based translation system. Here we have adopted the
pharaoh program (Koehn, 2004).
8.1 Finding the templates
The parameters of the MAR were trained using the
algorithm above: first ten IBM model 1 iterations
were used for giving initial values to the dictionary
probabilities and then five more iterations for re-
training the dictionary together with the rest of the
parameters.
The alignment of a pair has the form of a tree sim-
ilar to the one in Figure 3 (this is one of the sen-
tences from the Spanish-English part of the training
corpus). Each interior node has two children corre-
sponding to the translation of the two parts in which
the input sentence is divided. The leaves of the tree
correspond to those segments that were translated by
model 1. The templates generated were those de-
fined by the leaves. Further templates were obtained
by interpreting each pair of words in the dictionary
as a template.
204
Algorithm all IBM
for ob := 1 to |y?| do
for oe := ob to |y?| do
for ib := 1 to |x?| do
S := 0;
for ie := ib to |x?| do
S := S + t(yoe | xie);
I(ib, ie, ob, oe) :=
{
S/(ie? ib + 1) if ob = oe,
I(ib, ie, ob, oe? 1)? S/(ie? ib + 1) otherwise;
End all IBM
Figure 2: Efficient computation of different values of IBM?s model 1.
Equipos a presi?n transportables
Transportable pressure equipment
Equipos
equipment
a presi?n transportables
Transportable pressure
a presi?n
pressure
transportables
Transportable
Figure 3: A sample alignment represented as a tree.
Each template was assigned four weights1 in or-
der to use the pharaoh program. For the templates
obtained from the alignments, the first weight was
the probability assigned to it by MAR, the second
weight was the count for the template, i.e., the num-
ber of times that template was found in the corpus,
the third weight was the normalized count, i.e., the
number of times the template appeared in the corpus
divided by the number of times the input part was
present in the corpus, finally, the fourth weight was
a small constant (10?30). The intention of this last
weight was to ease the combination with the tem-
plates from the dictionary. For these, the first three
weights were assigned the same small constant and
the fourth was the probability of the translation of
the pair obtained from the stochastic dictionary. This
weighting schema allowed to separate the influence
of the dictionary in smoothing the templates.
1They should have been probabilities, but in two of the cases
there was no normalization and in one they were even greater
than one!
Table 1: Statistics of the training corpora. The
languages are German (De), English (En), Span-
ish (Es), Finnish (Fi) and French (Fr).
Languages Sentences Words (input/output)
De-En 751 088 15 257 871 / 16 052 702
Es-En 730 740 15 725 136 / 15 222 505
Fi-En 716 960 11 318 863 / 15 493 334
Fr-En 688 031 15 599 184 / 13 808 505
9 Experiments
In order to test the model, we have decided to par-
ticipate in the shared task for this workshop.
9.1 The task
The aim of the task was to translate a set of 2,000
sentences from German, Spanish, Finnish and
French into English. Those sentences were ex-
tracted from the Europarl corpus (Koehn, Unpub-
lished). As training material, four different corpora
were provided, one for each language pair, compris-
ing around 700 000 sentence pairs each. Some de-
tails about these corpora can be seen in Table 1. An
automatic alignment for each corpus was also pro-
vided.
The original sentence pairs were splitted using the
techniques discussed in section 7.3. The total num-
ber of sentences after the split is presented in Ta-
ble 2. Two different alignments were used: (a) the
one provided in the definition of the task and (b)
one obtained using GIZA++ (Och and Ney, 2003)
to train an IBM?s model 4. As it can be seen, the
number of parts is very similar in both cases. The
205
Table 2: Number of training pairs after splitting to
a maximum length of ten. ?Provided? refers to the
alignment provided in the task, ?GIZA++? to those
obtained with GIZA++.
Sentence pairs
Languages Provided GIZA++
De-En 2 351 121 2 282 316
Es-En 2 160 039 2 137 301
Fi-En 2 099 634 2 017 130
Fr-En 2 112 931 2 080 200
Table 3: Number of templates for each language
pair: ?Alignment? shows the number of templates
derived from the alignments; ?dictionary?, those ob-
tained from the dictionary; and ?total? is the sum.
(a) Using the alignments provided with the task.
Lang. Alignment Dictionary Total
De-En 2 660 745 1 840 582 4 501 327
Es-En 2 241 344 1 385 086 3 626 430
Fi-En 2 830 433 2 852 583 5 683 016
Fr-En 2 178 890 1 222 266 3 401 156
(b) Using GIZA++.
Lang. Alignment Dictionary Total
De-En 2 672 079 1 796 887 4 468 966
Es-En 2 220 533 1 350 526 3 571 059
Fi-En 2 823 769 2 769 929 5 593 698
Fr-En 2 140 041 1 181 990 3 322 031
number of pairs after splitting is roughly three times
the original.
Templates were extracted as described in sec-
tion 8.1. The number of templates we obtained can
be seen in Table 3. Again, the influence of the
type of alignment was small. Except for Finnish,
the number of dictionary templates was roughly two
thirds of the templates extracted from the align-
ments.
9.2 Obtaining the translations
Once the templates were obtained, the development
corpora were used to search for adequate values of
Table 4: Best weights for each language pair. The
columns are for the probability given by the model,
the counts of the templates, the normalized counts
and the weight given to the dictionary.
(a) Using the alignments provided with the task.
Languages Model Count Norm Dict
De-En 0.0 3.0 0.0 0.3
Es-En 0.0 2.9 0.0 0.4
Fi-En 0.0 7.0 0.0 0.0
Fr-En 0.0 7.0 1.0 1.0
(b) Using GIZA++.
Languages Model Count Norm Dict
De-En 0.0 3.0 0.0 0.0
Es-En 0.0 2.9 0.0 0.4
Fi-En 0.0 3.0 1.5 0.0
Fr-En 0.0 3.0 1.0 0.4
Table 5: BLEU scores of the translations.
BLEU
Languages Provided GIZA++
De-En 18.08 18.89
Es-En 21.65 21.48
Fi-En 13.31 13.79
Fr-En 21.25 19.86
the weights that pharaoh uses for each template
(these are the weights passed to option weight-t,
the other weights were not changed as an initial ex-
ploration seemed to indicate that they had little im-
pact). As expected, the best weights differed be-
tween language pairs. The values can be seen in
table 4.
It is interesting to note that the probabilities as-
signed by the model to the templates seemed to
be better not taken into account. The most impor-
tant feature was the counts of the templates, which
sometimes were helped by the use of the dictionary,
although that effect was small. Normalization of
counts also had little impact.
206
10 Results and discussion
The results over the test sets can be seen in Table 5.
It can be seen that, except for French, the influence
of the initial alignment is very small. Also, the best
results are obtained for Spanish and French, which
are more similar to English that German or Finnish.
There are still many open questions that deserve
more experimentation. The first is the influence of
the split of the original corpora. Although the simi-
larity of results seem to indicate that it has little in-
fluence, this has to be tested. Two more relevant as-
pects are whether the weighting schema is the best
for the decoder. In particular, it is surprising that the
normalization of counts had so little effect.
Finally, the average number of words per template
is below two, which probably is too low. It is inter-
esting to find alternate ways of obtaining the tem-
plates, for instance using internal nodes up to a given
height or covering portions of the sentences up to a
predefined number of words.
11 Conclusions
A new translation model has been presented. This
model produces translations in a recursive way: the
input sentence is divided in two parts, each is trans-
lated using the same procedure recursively and the
translations are concatenated. The model has been
used for finding the templates in a large vocabulary
translation task. This involved using several heuris-
tics to improve training time, including a method for
splitting the input before training the models. Fi-
nally, the influence of using a stochastic dictionary
together with the templates as a means of smoothing
has been explored.
References
Leonard E. Baum and J. A. Eagon. 1967. An inequal-
ity with applications to statistical estimation for prob-
abilistic functions of Markov processes and to a model
for ecology. Bulletin of the American Mathematical
Society, 73:360?363.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: Parameter esti-
mation. Computational Linguistics, 19(2):263?311,
June.
Ido Dagan, Kenneth W. Church, and William A. Gale.
1993. Robust bilingual word alignment for machine
aided translation. In Proceedings of the Workshop on
Very Large Corpora, Columbus, Ohio (USA). ACL.
Yonggang Deng, Shankar Kumar, and William Byrne.
2004. Bitext chunk alignment for statistical machine
translation. Research Note 50, CLSP Johns Hopkins
University, April.
P. S. Gopalakrishnan, Dimitri Kanevsky, Arthur Na?das,
and David Nahamoo. 1991. An inequality for ra-
tional functions with applications to some statistical
problems. IEEE Transactions on Information Theory,
37(1):107?113, January.
Philipp Koehn. 2004. Pharaoh: A beam search decoder
for phrase-based statistical machine translation mod-
els. In AMTA, pages 115?124.
Philipp Koehn. Unpublished. Europarl: A multilingual
corpus for evaluation of machine translation. Draft.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Franz Joseph Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics, 30(4):417?449, De-
cember.
Enrique Vidal, Roberto Pieraccini, and Esther Levin.
1993. Learning associations between grammars: A
new approach to natural language understanding. In
Proceedings of the EuroSpeech?93, pages 1187?1190,
Berlin (Germany).
Juan Miguel Vilar Torres. 1998. Aprendizaje de Tra-
ductores Subsecuenciales para su empleo en tareas
de dominio restringido. Ph.D. thesis, Departamento
de Sistemas Informa?ticos y Computacio?n, Universidad
Polite?cnica de Valencia, Valencia (Spain). (in Span-
ish).
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the COLING?96, pages 836?
841, Copenhagen (Denmark), August.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Richard Zens and Hermann Ney. 2003. A comparative
study on reordering constraints in statistical machine
translation. In Proceedings of the Annual Meeting of
the Association for Computational Linguistics, pages
144?151, Sapporo (Japan), July. Association for Com-
putational Lingustics.
207
Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007), pages 9?16,
Prague, 28 June 2007. c?2007 Association for Computational Linguistics
Viterbi Based Alignment between Text Images and their Transcripts?
Alejandro H. Toselli, Vero?nica Romero and Enrique Vidal
Institut Tecnolo`gic d?Informa`tica
Universitat Polite`cnica de Vale`ncia
Cam?? de Vera s/n
46071 - Vale`ncia, Spain
[ahector,vromero,evidal]@iti.upv.es
Abstract
An alignment method based on the Viterbi
algorithm is proposed to find mappings be-
tween word images of a given handwrit-
ten document and their respective (ASCII)
words on its transcription. The approach
takes advantage of the underlying segmen-
tation made by Viterbi decoding in hand-
written text recognition based on Hidden
Markov Models (HMMs). Two HMMs
modelling schemes are evaluated: one using
78-HMMs (one HMM per character class)
and other using a unique HMM to model all
the characters and another to model blank
spaces. According to various metrics used
to measure the quality of the alignments, en-
couraging results are obtained.
1 Introduction
Recently, many on-line digital libraries have been
publishing large quantities of digitized ancient hand-
written documents, which allows the general pub-
lic to access this kind of cultural heritage resources.
This is a new, comfortable way of consulting and
querying this material. The Biblioteca Valenciana
Digital (BiValDi)1 is an example of one such digital
library, which provides an interesting collection of
handwritten documents.
?This work has been supported by the EC (FEDER), the
Spanish MEC under grant TIN2006-15694-C02-01, and by the
Conseller??a d?Empresa, Universitat i Cie`ncia - Generalitat Va-
lenciana under contract GV06/252.
1http://bv2.gva.es
Several of these handwritten documents include
both, the handwritten material and its proper tran-
scription (in ASCII format). This fact has moti-
vated the development of methodologies to align
these documents and their transcripts; i.e. to gen-
erate a mapping between each word image on a doc-
ument page with its respective ASCII word on its
transcript. This word by word alignment would al-
low users to easily find the place of a word in the
manuscript when reading the corresponding tran-
script. For example, one could display both the
handwritten page and the transcript and whenever
the mouse is held over a word in the transcript, the
corresponding word in the handwritten image would
be outlined using a box. In a similar way, whenever
the mouse is held over a word in the handwritten im-
age, the corresponding word in the transcript would
be highlighted (see figure 1). This kind of alignment
can help paleography experts to quickly locate im-
age text while reading a transcript, with useful ap-
plications to editing, indexing, etc. In the opposite
direction, the alignment can also be useful for people
trying to read the image text directly, when arriving
to complex or damaged parts of the document.
Creating such alignments is challenging since the
transcript is an ASCII text file while the manuscript
page is an image. Some recent works address this
problem by relying on a previous explicit image-
processing based word pre-segmentation of the page
image, before attempting the transcription align-
ments. For example, in (Kornfield et al, 2004),
the set of previously segmented word images and
their corresponding transcriptions are transformed
into two different times series, which are aligned
9
Figure 1: Screen-shot of the alignment prototype interface displaying an outlined word (using a box) in the
manuscript (left) and the corresponding highlighted word in the transcript (right).
using dynamic time warping (DTW). In this same
direction, (Huang and Srihari, 2006), in addition to
the word pre-segmentation, attempt a (rough) recog-
nition of the word images. The resulting word string
is then aligned with the transcription using dynamic
programming.
The alignment method presented here (hencefor-
ward called Viterbi alignment), relies on the Viterbi
decoding approach to handwritten text recogni-
tion (HTR) based on Hidden Markov Models
(HMMs) (Bazzi et al, 1999; Toselli et al, 2004).
These techniques are based on methods originally
introduced for speech recognition (Jelinek, 1998).
In such HTR systems, the alignment is actually a
byproduct of the proper recognition process, i.e. an
implicit segmentation of each text image line is ob-
tained where each segment successively corresponds
to one recognized word. In our case, word recogni-
tion is not actually needed, as we do already have
the correct transcription. Therefore, to obtain the
segmentations for the given word sequences, the so-
called ?forced-recognition? approach is employed
(see section 2.2). This idea has been previously ex-
plored in (Zimmermann and Bunke, 2002).
Alignments can be computed line by line in cases
where the beginning and end positions of lines are
known or, in a more general case, for whole pages.
We show line-by-line results on a set of 53 pages
from the ?Cristo-Salvador? handwritten document
(see section 5.2). To evaluate the quality of the ob-
tained alignments, two metrics were used which give
information at different alignment levels: one mea-
sures the accuracy of alignment mark placements
and the other measures the amount of erroneous as-
10
0.3
0.7 0.8
0.2
0.9
0.1
0.8
0.2
0.7
0.3
Figure 2: Example of 5-states HMM modeling (feature vectors sequences) of instances of the character ?a?
within the Spanish word ?cuarenta? (forty). The states are shared among all instances of characters of the
same class. The zones modelled by each state show graphically subsequences of feature vectors (see details
in the magnifying-glass view) compounded by stacking the normalized grey level and its both derivatives
features.
signments produced between word images and tran-
scriptions (see section 4).
The remainder of this paper is organized as fol-
lows. First, the alignment framework is introduced
and formalized in section 2. Then, an implemented
prototype is described in section 3. The alignment
evaluation metrics are presented in section 4. The
experiments and results are commented in section 5.
Finally, some conclusions are drawn in section 6.
2 HMM-based HTR and Viterbi alignment
HMM-based handwritten text recognition is briefly
outlined in this section, followed by a more detailed
presentation of the Viterbi alignment approach.
2.1 HMM HTR Basics
The traditional handwritten text recognition problem
can be formulated as the problem of finding a most
likely word sequence w? = ?w1, w2, . . . , wn?, for
a given handwritten sentence (or line) image rep-
resented by a feature vector sequence x = xp1 =
?x1, x2, . . . , xp?, that is:
w? = arg max
w
Pr(w|x)
= arg max
w
Pr(x|w) ? Pr(w) (1)
where Pr(x|w) is usually approximated by
concatenated character Hidden Markov Models
(HMMs) (Jelinek, 1998; Bazzi et al, 1999),
whereas Pr(w) is approximated typically by an
n-gram word language model (Jelinek, 1998).
Thus, each character class is modeled by a con-
tinuous density left-to-right HMM, characterized by
a set of states and a Gaussian mixture per state. The
Gaussian mixture serves as a probabilistic law to
model the emission of feature vectors by each HMM
state. Figure 2 shows an example of how a HMM
models a feature vector sequence corresponding to
11
b0 b3 b4 b5 b6 bn=7
x1
w1 w3 w4 w5 w6 xp
wn=7
b1 b2
w2
Figure 3: Example of segmented text line image along with its resulting deslanted and size-normalized
image. Moreover, the alignment marks (b0 . . . b8) which delimit each of the words (including word-spaces)
over the text image feature vectors sequence x.
character ?a?. The process to obtain feature vector
sequences from text images as well as the training of
HMMs are explained in section 3.
HMMs as well as n-grams models can be rep-
resented by stochastic finite state networks (SFN),
which are integrated into a single global SFN by re-
placing each word character of the n-gram model by
the corresponding HMM. The search involved in the
equation (1) to decode the input feature vectors se-
quence x into the more likely output word sequence
w?, is performed over this global SFN. This search
problem is adequately solved by the Viterbi algo-
rithm (Jelinek, 1998).
2.2 Viterbi Alignment
As a byproduct of the Viterbi solution to (1), the
feature vectors subsequences of x aligned with each
of the recognized words w1, w2, . . . , wn can be ob-
tained. These implicit subsequences can be visual-
ized into the equation (1) as follows:
w? = arg max
w
?
b
Pr(x,b|w) ? Pr(w) (2)
where b is an alignment; that is, an ordered se-
quence of n+1 marks ?b0, b1, . . . , bn?, used to de-
marcate the subsequences belonging to each recog-
nized word. The marks b0 and bn always point out
to the first and last components of x (see figure 3).
Now, approximating the sum in (2) by the domi-
nant term:
w? ? arg max
w
max
b
Pr(x,b|w) ? Pr(w) (3)
where b? is the optimal alignment. In our case,
we are not really interested in proper text recogni-
tion because the transcription is known beforehand.
Let w? be the given transcription. Now, Pr(w) in
equation 3 is zero for all w except w?, for which
Pr(w?) = 1. Therefore,
b? = arg max
b
Pr(x,b|w?) (4)
which can be expanded to,
b? = arg max
b
Pr(x, b1|w?)Pr(x, b2|b1, w?) . . .
. . . P r(x, bn|b1b2 . . . bn?1, w?)
(5)
Assuming independence of each bi mark from
b1b2 . . . bi?1 and assuming that each subsequence
xbibi?1 depends only of w?i, equation (5) can be rewrit-
ten as,
b? = arg max
b
Pr(xb1b0 |w?1) . . . P r(x
bn
bn?1 |w?n) (6)
This simpler Viterbi search problem is known as
?forced recognition?.
3 Overview of the Alignment Prototype
The implementation of the alignment prototype in-
volved four different parts: document image prepro-
cessing, line image feature extraction, HMMs train-
ing and alignment map generation.
12
Document image preprocessing encompasses the
following steps: first, skew correction is carried out
on each document page image; then background
removal and noise reduction is performed by ap-
plying a bi-dimensional median filter (Kavalliera-
tou and Stamatatos, 2006) on the whole page im-
age. Next, a text line extraction process based on
local minimums of the horizontal projection profile
of page image, divides the page into separate line
images (Marti and Bunke, 2001). In addition con-
nected components has been used to solve the situ-
ations where local minimum values are greater than
zero, making impossible to obtain a clear text line
separation. Finally, slant correction and non-linear
size normalization are applied (Toselli et al, 2004;
Romero et al, 2006) on each extracted line image.
An example of extracted text line image is shown
in the top panel of figure 3, along with the result-
ing deslanted and size-normalized image. Note how
non-linear normalization leads to reduced sizes of
ascenders and descenders, as well as to a thiner un-
derline of the word ?ciudadanos?.
As our alignment prototype is based on Hid-
den Markov Models (HMMs), each preprocessed
line image is represented as a sequence of feature
vectors. To do this, the feature extraction mod-
ule applies a grid to divide line image into N ?
M squared cells. In this work, N = 40 is cho-
sen empirically (using the corpus described further
on) and M must satisfy the condition M/N =
original image aspect ratio. From each cell, three
features are calculated: normalized gray level, hor-
izontal gray level derivative and vertical gray level
derivative. The way these three features are deter-
mined is described in (Toselli et al, 2004). Columns
of cells or frames are processed from left to right
and a feature vector is constructed for each frame
by stacking the three features computed in its con-
stituent cells.
Hence, at the end of this process, a sequence of
M 120-dimensional feature vectors (40 normalized
gray-level components, 40 horizontal and 40 vertical
derivatives components) is obtained. An example of
feature vectors sequence, representing an image of
the Spanish word ?cuarenta? (forty) is shown in fig-
ure 2.
As it was explained in section 2.1, characters are
modeled by continuous density left-to-right HMMs
with 6 states and 64 Gaussian mixture components
per state. This topology (number of HMM states and
Gaussian densities per state) was determined by tun-
ing empirically the system on the corpus described
in section 5.1. Once a HMM ?topology? has been
adopted, the model parameters can be easily trained
from images of continuously handwritten text (with-
out any kind of segmentation) accompanied by the
transcription of these images into the correspond-
ing sequence of characters. This training process is
carried out using a well known instance of the EM
algorithm called forward-backward or Baum-Welch
re-estimation (Jelinek, 1998).
The last phase in the alignment process is the gen-
eration of the mapping proper by means of Viterbi
?forced recognition?, as discussed in section 2.2.
4 Alignment Evaluation Metrics
Two kinds of measures have been adopted to evalu-
ate the quality of alignments. On the one hand, the
average value and standard deviation (henceforward
called MEAN-STD) of the absolute differences be-
tween the system-proposed word alignment marks
and their corresponding (correct) references. This
gives us an idea of the geometrical accuracy of the
alignments obtained. On the other hand, the align-
ment error rate (AER), which measures the amount
of erroneous assignments produced between word
images and transcriptions.
Given a reference mark sequence r =
?r0, r1, . . . , rn? along with an associated to-
kens sequence w = ?w1, w2, . . . , wn?, and a
segmentation marks sequence b = ?b0, b1, . . . , bn?
(with r0 =b0 ? rn =bn), we define the MEAN-STD
and AER metrics as follows:
MEAN-STD: The average value and standard devi-
ation of absolute differences between reference and
proposed alignment marks, are given by:
? =
?n?1
i=1 di
n ? 1 ? =
?
?n?1
i=1 (di ? ?)2
n ? 1 (7)
where di = |ri ? bi|.
13
w1 w3 w4 w5 w6 wn=7w2
r0 r3 r4 r5 r6 r7
x1 xp
r1 r2
b7b1 b2 b3 b4 b6b5b0
m7m5m3m1
Figure 4: Example of AER computation. In this case N = 4 (only no word-space are considered:
w1, w3, w5, w7) and w5 is erroneously aligned with the subsequence xb6b5 (m5 /? (b4, b5)). The resulting
AER is 25%.
AER: Defined as:
AER(%) =100N
?
j:wj 6=b
ej
ej =
{
0 bj?1 <mj <bj
1 otherwise
(8)
where b stands for the blank-space token, N < n is
the number of real words (i.e., tokens which are not
b, and mj = (rj?1 + rj)/2.
A good alignment will have a ? value close to 0
and small ?. Thus, MEAN-STD gives us an idea of
how accurate are the automatically computed align-
ment marks. On the other hand, AER assesses align-
ments at a higher level; that is, it measures mis-
matches between word-images and ASCII transcrip-
tions (tokens), excluding word-space tokens. This is
illustrated in figure 4, where the AERwould be 25%.
5 Experiments
In order to test the effectiveness of the presented
alignment approach, different experiments were car-
ried out. The corpus used, as well as the experiments
carried out and the obtained results, are reported in
the following subsections.
5.1 Corpus description
The corpus was compiled from the legacy handwrit-
ing document identified as Cristo-Salvador, which
was kindly provided by the Biblioteca Valenciana
Digital (BIVALDI). It is composed of 53 text page
images, scanned at 300dpi and written by only one
writer. Some of these page images are shown in the
figure 5.
As has been explained in section 3, the page im-
ages have been preprocessed and divided into lines,
resulting in a data-set of 1,172 text line images.
In this phase, around 4% of the automatically ex-
tracted line-separation marks were manually cor-
rected. The transcriptions corresponding to each line
image are also available, containing 10,911 running
words with a vocabulary of 3,408 different words.
To test the quality of the computed alignments, 12
pages were randomly chosen from the whole corpus
pages to be used as references. For these pages the
true locations of alignment marks were set manually.
Table 1 summarized the basic statistics of this cor-
pus and its reference pages.
Number of: References Total Lexicon
pages 12 53 ?
text lines 312 1,172 ?
words 2,955 10,911 3,408
characters 16,893 62,159 78
Table 1: Basic statistics of the database
5.2 Experiments and Results
As mentioned above, experiments were carried out
computing the alignments line-by-line. Two differ-
ent HMM modeling schemes were employed. The
first one models each of the 78 character classes us-
ing a different HMM per class. The second scheme
uses 2 HMMs, one to model all the 77 no-blank
character classes, and the other to model only the
blank ?character? class. The HMM topology was
identical for all HMMs in both schemes: left-to-
right with 6 states and 64 Gaussian mixture com-
14
Figure 5: Examples page images of the corpus ?Cristo-Salvador?, which show backgrounds of big variations
and uneven illumination, spots due to the humidity, marks resulting from the ink that goes through the paper
(called bleed-through), etc.
ponents per state.
As has been explained in section 4, two different
measures have been adopted to evaluate the quality
of the obtained alignments: the MEAN-STD and the
AER. Table 2 shows the different alignment evalu-
ation results obtained for the different schemes of
HMM modeling.
78-HMMs 2-HMMs
AER (%) 7.20 25.98
? (mm) 1.15 2.95
? (mm) 3.90 6.56
Table 2: Alignment evaluation results 78-HMMs
and 2-HMMs.
From the results we can see that using the 78
HMMs scheme the best AER is obtained (7.20%).
Moreover, the relative low values of ? and ? (in mil-
limeters) show that the quality of the obtained align-
ments (marks) is quite acceptable, that is they are
very close to their respective references. This is il-
lustrated on the left histogram of figure 6.
The two typical alignment errors are known as
over-segmentation and under-segmentation respec-
tively. The over-segmentation error is when one
word image is separated into two or more fragments.
The under-segmentation error occurs when two or
more images are grouped together and returned as
one word. Figure 7 shows some of them.
6 Remarks and Conclusions
Given a manuscript and its transcription, we propose
an alignment method to map every word image on
the manuscript with its respective ASCII word on
the transcript. This method takes advantage of the
implicit alignment made by Viterbi decoding used
in text recognition with HMMs.
The results reported in the last section should be
considered preliminary.
Current work is under way to apply this align-
ment approach to the whole pages, which represents
a more general case where the most corpora do not
have transcriptions set at line level.
References
I. Bazzi, R. Schwartz, and J. Makhoul. 1999. An Om-
nifont Open-Vocabulary OCR System for English and
15
02
4
6
8
10
12
0 1 2 3 4 5 6
Fr
eq
ue
nc
y
(%
)
|Segi ? Refi| (mm)
mean
0
1
2
3
4
5
6
0 1 2 3 4 5 6
Fr
eq
ue
nc
y
(%
)
|Segi ? Refi| (mm)
mean
Figure 6: |ri ? bi| distribution histograms for 78-HMMs (left) and 2-HMMs (right) modelling schemes.
Figure 7: Word alignment for 6 lines of a particularly noisy part of the corpus. The four last words on the
second line as well as the last line illustrate some of over-segmentation and under-segmentation error types.
Arabic. IEEE Trans. on PAMI, 21(6):495?504.
Chen Huang and Sargur N. Srihari. 2006. Mapping Tran-
scripts to Handwritten Text. In Suvisoft Ltd., editor,
Tenth International Workshop on Frontiers in Hand-
writing Recognition, pages 15?20, La Baule, France,
October.
F. Jelinek. 1998. Statistical Methods for Speech Recog-
nition. MIT Press.
Ergina Kavallieratou and Efstathios Stamatatos. 2006.
Improving the quality of degraded document images.
In DIAL ?06: Proceedings of the Second International
Conference on Document Image Analysis for Libraries
(DIAL?06), pages 340?349, Washington, DC, USA.
IEEE Computer Society.
E. M. Kornfield, R. Manmatha, and J. Allan. 2004. Text
Alignment with Handwritten Documents. In First In-
ternational Workshop on Document Image Analysis
for Libraries (DIAL), pages 195?209, Palo Alto, CA,
USA, January.
U.-V. Marti and H. Bunke. 2001. Using a Statistical Lan-
guage Model to improve the preformance of an HMM-
Based Cursive Handwriting Recognition System. Int.
Journal of Pattern Recognition and Artificial In telli-
gence, 15(1):65?90.
V. Romero, M. Pastor, A. H. Toselli, and E. Vidal. 2006.
Criteria for handwritten off-line text size normaliza-
tion. In Procc. of The Sixth IASTED international
Conference on Visualization, Imaging, and Image Pro-
cessing (VIIP 06), Palma de Mallorca, Spain, August.
A. H. Toselli, A. Juan, D. Keysers, J. Gonzlez, I. Sal-
vador, H. Ney, E. Vidal, and F. Casacuberta. 2004.
Integrated Handwriting Recognition and Interpretation
using Finite-State Models. Int. Journal of Pattern
Recognition and Artificial Intelligence, 18(4):519?
539, June.
M. Zimmermann and H. Bunke. 2002. Automatic Seg-
mentation of the IAM Off-Line Database for Hand-
written English Text. In ICPR ?02: Proceedings of
the 16 th International Conference on Pattern Recog-
nition (ICPR?02) Volume 4, page 40035, Washington,
DC, USA. IEEE Computer Society.
16
Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 107?111,
Avignon, France, 24 April 2012. c?2012 Association for Computational Linguistics
Natural Language Inspired Approach for Handwritten Text Line
Detection in Legacy Documents?
Vicente Bosch Campos
Inst. Tec. de Informa?tica
Univ. Polite?cnica Valencia
Valencia - Spain
vbosch@iti.upv.es
Alejandro He?ctor Toselli
Inst. Tec. de Informa?tica
Univ. Polite?cnica Valencia
Valencia - Spain
ahector@iti.upv.es
Enrique Vidal
Inst. Tec. de Informa?tica
Univ. Polite?cnica Valencia
Valencia - Spain
evidal@iti.upv.es
Abstract
Document layout analysis is an important
task needed for handwritten text recogni-
tion among other applications. Text lay-
out commonly found in handwritten legacy
documents is in the form of one or more
paragraphs composed of parallel text lines.
An approach for handwritten text line de-
tection is presented which uses machine-
learning techniques and methods widely
used in natural language processing. It is
shown that text line detection can be accu-
rately solved using a formal methodology,
as opposed to most of the proposed heuris-
tic approaches found in the literature. Ex-
perimental results show the impact of us-
ing increasingly constrained ?vertical lay-
out language models? in text line detection
accuracy.
1 Introduction
Handwritten text transcription is becoming an in-
creasingly important task, in order to provide his-
torians and other researchers new ways of index-
ing, consulting and querying the huge amounts of
historic handwritten documents which are being
published in on-line digital libraries.
Transcriptions of such documents are currently
obtained with solutions that range from the use of
systems that aim at fully automatic handwritten
text recognition (Bazzi et al, 1999)
(HTR), to computer assisted transcription
(CATTI), were the users participate interactively
in the proper transcription process (Toselli et al,
2009).
?Work supported under the MIPRCV ?Consolider
Ingenio 2010? program (CSD2007-00018), MITTRAL
(TIN2009-14633-C03-01) and also Univ. Polite?cnica Valen-
cia (PAID-05-11)
The basic input to these systems consists of text
line images. Hence, text line detection and ex-
traction from a given document page image be-
comes a necessary preprocessing step in any kind
of transcription systems. Furthermore the quality
of line segmentation directly influences the final
accuracy achieved by such systems.
Detection of handwritten text lines in an im-
age entails a greater difficulty, in comparison with
printed text lines, due to the inherent properties of
handwritten text: variable inter-line spacing, over-
lapping and touching strokes of adjacent hand-
written lines, etc.
The difficulty is further increased in the case
of ancient documents, due to common problems
appearing in them: presence of smear, significant
background variations and uneven illumination,
spots due to the humidity, and marks resulting
from the ink that goes through the paper (gener-
ally called ?bleed-through?).
Among the most popular state-of-the art meth-
ods involved in handwritten text line detection
we find four main families: based on (ver-
tical) projection profiles (Likforman-Sulem et
al., 2007), on the Hough transform (Likforman-
Sulem et al, 1995), the repulsive-attractive net-
work approach (O?ztop et al, 1999) and finally
the so-called stochastic methods (Vinciarelli et al,
2004), which combine probabilistic models such
as Hidden Markov Models (HMMs) along with
dynamic programming techniques (e.g. Viterbi
algorithm) to derive optimal paths between over-
lapping text lines.
It is worth noting that, most of the mentioned
approaches somewhat involve heuristic adjust-
ments of their parameters, which have to be prop-
erly tuned according to the characteristics of each
107
task in order to obtain adequate results.
In this work, the text line detection problem in
legacy handwritten documents is approached by
using machine-learning techniques and methods
which are widely used in natural language pro-
cessing (NLP).
It is shown that the text line detection problem
can be solved by using a formal methodology, as
opposed to most of the currently proposed heuris-
tic based approaches found in the literature.
2 Statistical Framework for Text Line
Detection
For the work presented in this paper, we assume
that the input image (of a page or selected region)
contains one or more paragraphs of single-column
parallel text with no images or diagram figures.
Additionally, we assume that the input image has
been properly preprocessed so as to ensure that
their text lines are roughly horizontal. These as-
sumptions are reasonable enough for most legacy
handwritten documents.
Similarly to how the statistic framework of
automatic speech recognition (ASR) is estab-
lished, the handwritten text line detection prob-
lem can be also formulated as the problem of
finding the most likely text lines sequence, h? =
?h1, h2, . . . , hn?, for a given handwritten page
image represented by a sequence of observations1
o = ?o1, o2, . . . , om?, that is:
h? = argmax
h
P (h | o) (1)
Using the Bayes? rule we can decompose the
probability P (h | o) into two terms:
h? = argmax
h
P (o | h) ? P (h) (2)
In the jargon of NLP these probabilities rep-
resent the morphological and syntactic knowl-
edge levels, respectively. As it happens in ASR,
P (o | h) is typically approximated by HMMs,
which model vertical page regions, while P (h)
by a ?language model? (LM), which restricts how
those regions are composed in order to form an
actual page. In what follows, a detailed descrip-
tion of this modelling scheme is given.
1Henceforward, in the context of this formal framework,
each time it is mentioned image of page or selected text, we
are implicitly referring to the input feature vector sequence
?o? describing it.
2.1 Modelling
In our line detection approach four different kinds
of vertical regions are defined:
Blank Line-region (BL): Large rectangular re-
gion of blank space usually found at the start
and the end of a page (top and bottom mar-
gins).
Normal text Line-region (NL): Region oc-
cupied by the main body of a normal
handwritten text line.
Inter Line-region (IL): Defined as the region
found within two consecutive normal text
lines, characterized by being crossed by the
ascenders and descenders belonging to the
adjacent text lines.
Non-text Line-region (NT): Stands for every-
thing which does not belong to any of the
other regions.
Figure 1: Examples of the different kind of line-
regions.
We model each of these regions by an HMM
which is trained with instances of such regions.
Basically, each line-region HMM is a stochastic
finite-state device that models the succession of
feature vectors extracted from instances of this
line-region image. In turn, each HMM state
generates feature vectors following an adequate
parametric probabilistic law; typically, a mixture
of Gaussian densities. The adequate number of
states and Gaussians per state may be conditioned
by the available amount of training data.
Once an HMM ?topology? (number of states
and structure) has been adopted, the model pa-
rameters can be easily trained from instances (se-
quences of features vectors) of full images con-
taining a sequence of line-regions (without any
108
kind of segmentation) accompanied by the refer-
ence labels of these images into the correspond-
ing sequence of line-region classes. This training
process is carried out using a well known instance
of the EM algorithm called forward-backward or
Baum-Welch re-estimation (Jelinek, 1998).
The syntactic modelling level is responsible for
the way that the different line regions are com-
posed in order to produce a valid page structure.
For example we can force that NL and NT line
regions must always be followed by IL inter-line
regions: NL+IL and NT+IL. We can also use
the LM to impose restrictions about the mini-
mum or maximum number of line-regions to be
detected. The LM for our text line detection ap-
proach, consists in a stochastic finite state gram-
mar (SFSG) which recognizes valid sequences of
elements (line regions): NL+IL, NT+IL and BL.
Both modelling levels, morphological and syn-
tactical, which are represented by finite-state au-
tomaton, can be integrated into a single global
model on which Eq. (2) is easily solved; that is,
given an input sequence of raw feature vectors,
an output string of recognized sequence of line-
region labels is obtained. In addition the vertical
position of each detected line and and line-region
is obtained as a by-product.
3 System Architecture
Page layoutcorpus
LM ModelOff-line  lineHMMs
HMM Training LM Training
Preprocessing
Feature Extraction
Decoding
Training
Page Images
Cleaned PageImages
Feature Vectors
Type label and Region positioncoordinates
Figure 2: Global scheme of the handwritten text line
detection process.
The flow diagram of Fig. 2 displays the overall
process of the proposed handwritten text line de-
tection approach. It is composed of four different
phases: image preprocessing, feature extraction,
HMMs and LM training and decoding. Next we
will overview the first two phases, preprocessing
and feature extraction, since the rest has already
been covered in the preceding section.
3.1 Preprocessing Phase
Initially performing background removal and
noise reduction is carried out by applying a bi-
dimensional median filter on them. The resulting
image skew is corrected by applying vertical pro-
jection profile and RLSA (Wong and Wahl, 1982),
along with standard techniques to calculate the
skew angle.
3.2 Feature Extraction Phase
As our text line detection approach is based on
HMMs, each preprocessed image must be rep-
resented as a sequence of feature vectors.This is
done by dividing the already preprocessed image
(from left-to-right) into D non-overlapping rect-
angular regions with height equal to the image-
height (see Fig. 3).
In each of these rectangular regions we calcu-
late the vertical grey level histogram. RLSA is
applied to obtain a more emphasized vertical pro-
jection profile. Finally, to eliminate local maxima
on the obtained vertical projection profiles, they
are smoothed with a rolling median filter (Man-
matha and Srimal, 1999) (see Fig. 3) . In this way,
Figure 4: Review of the impact of the RLSA and
rolling media filter on the histogram calculation of a
sample line.
a D-dimensional feature vector is constructed for
each page/block image pixels row, by stacking the
D projection profile values corresponding to that
row. Hence, at the end of this process, a sequence
of L D-dimensional feature vectors is obtained,
where L is the image height.
4 Experimental Setup and Results
In order to study the efficacy of the line detection
approach proposed in this paper, different experi-
ments were carried out. We are mainly interested
in assessing the impact upon final text line detec-
109
1 2 3 4 5
Figure 3: Partial page image visualization of 5 (D = 5) rectangular regions across over 3 handwritten text lines.
For each region, its vertical projection profile is also plotted.
tion accuracy of employing increasingly restric-
tive LMs.
4.1 Corpus Description
Experiments are carried out with corpus compiled
from a XIX century Spanish manuscript identified
as ?Cristo-Salvador? (CS), which was kindly pro-
vided by the Biblioteca Valenciana Digital (Bi-
VaLDi)2. This is a rather small document com-
posed of 53 colour images of text pages, scanned
at 300 dpi and written by a single writer. Some
page images examples are shown in Fig. 5.
Figure 5: Examples of pages images from CS corpus.
In this work we employ the so-called book
partition, which has been defined for this data-
set (Romero et al, 2007). Its test set contains
the last 20 page images were as the training set
is composed of the 33 remaining pages. Table 1
summarizes the relevant information of this parti-
tion.
Table 1: Basic statistics of the Cristo-Salvador corpus
partition.
Number of: Training Test Total
Pages 33 20 53
Normal-text lines (NL) 685 497 1 182
Blank Lines (BL) 73 70 143
Non-text Lines (NT) 16 8 24
Inter Lines (IL) 701 505 1 206
Each page was annotated with a succession of
reference labels (NL, NT, BL and IL) indicating
2http://bv2.gva.es.
the kind of line-regions that composed it. Such
references were generated by executing standard
methods for text line detection based on vertical
projection profiles, which were afterwards manu-
ally labelled, verified, adjusted and/or rectified by
a human operator to ensure correctness.
4.2 Evaluation Measures
We measure the quality of the text line detec-
tion by means of the ?line error rate? (LER)
which is performed by comparing the sequences
of automatically obtained region labels with the
corresponding reference label sequences. The
LER is computed in the same way as the well
known WER, with equal costs assigned to dele-
tions, insertions and substitutions (McCowan et
al., 2004).
4.3 Experiments and Results
A series of experiments were performed on the CS
corpus using a simple hold-out validation as per
the CS ?book? partition. Initially some param-
eters were set up: feature extraction dimension
D, HMM topology (number of states and Gaus-
sians),number of Baum-Welch iterations, and de-
coding grammar scale factor (GSF) and word in-
sertion penalty (WIP). After some informal exper-
imentation, adequate values were found for sev-
eral of them: feature vectors dimension of 2, left-
to-right HMMs with 4 states topology, 32 Gaus-
sian mixtures per state trained by running 3 cycles
of Baum-Welch re-estimation algorithm. The re-
maining parameters, all related with the decoding
process itself, were tuned to obtain the best figures
for each of the two following language models:
the prior and conditional represented by topolog-
ically different SFSGs. The prior model transi-
tion probabilities are estimated from the training
set as the fraction of the number of appearances
of each vertical region label over the whole count
of labels. The conditional model also considers
the previous label in order to perform the estima-
tion. These estimates resemble the uni-gram and
110
bi-gram LMs calculations, except no smoothing
strategy is implemented here.
Additionally, it is defined for each test page a
line-number constrained LM which uses the con-
ditional probabilities to populate the model but
enforces a total number of possible line-regions to
detect as per the number of reference line-region
labels of that test page. Table 2 reports the ob-
tained LER results for each of these LMs.
Table 2: Best detection LER(%) obtained for each
kind of language model: Prior, Conditional and Line-
Number Constrained.
LM WIP GSF LER(%)
Prior -32 8 0.86
Conditional -8 16 0.70
LN-Constrained -128 1 0.34
As can be seen, the more restrictive the LM
is, the better accuracy is achieved. Concerning
the line-number constrained, they are really con-
ceived for its utilization in (parts of) documents
or document collections with homogeneous num-
bers of lines per page.
5 Conclusions
We have presented a new approach for text line
detection by using a statistical framework similar
to that already employed in many topics of NLP.
It avoids the traditional heuristics approaches usu-
ally adopted for this task.
The accuracy of this approach is similar to or
better than that of current state of the art solutions
found in the literature. We find that the detected
baselines provided by our approach are of better
quality (visually closer to the actual line) than cur-
rent heuristic methods as can be seen in 6.
Figure 6: Image shows the difference between our pro-
posed method (upper side of each coloured region )
and the histogram projection method (lower side)
In the future we will extend this approach not
only to detect, but also to classify line-region
types in order to determine for example titles,
short lines, beginning and and end of paragraphs,
etc. Furthermore, it is envisioned that the pro-
posed stochastic framework serves as a corner-
stone to implementing interactive approaches to
line detection similar to those used for handwrit-
ten text transcription used in (Toselli et al, 2009).
References
Issam Bazzi, Richard Schwartz, and John Makhoul.
1999. An omnifont open-vocabulary OCR system
for English and Arabic. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence, 21(6):495?
504.
Frederick Jelinek. 1998. Statistical methods for
speech recognition. MIT Press.
Laurence Likforman-Sulem, Anahid Hanimyan, and
Claudie Faure. 1995. A hough based algorithm
for extracting text lines in handwritten documents.
Document Analysis and Recognition, International
Conference on, 2:774.
Laurence Likforman-Sulem, Abderrazak Zahour, and
Bruno Taconet. 2007. Text line segmentation of
historical documents: a survey. International Jour-
nal on Document Analysis and Recognition, 9:123?
138, April.
Raghavan Manmatha and Nitin Srimal. 1999. Scale
space technique for word segmentation in handwrit-
ten documents. In Proceedings of the Second In-
ternational Conference on Scale-Space Theories in
Computer Vision, SCALE-SPACE ?99, pages 22?
33, London, UK. Springer-Verlag.
Iain A. McCowan, Darren Moore, John Dines, Daniel
Gatica-Perez, Mike Flynn, Pierre Wellner, and
Herve? Bourlard. 2004. On the use of informa-
tion retrieval measures for speech recognition eval-
uation. Idiap-RR Idiap-RR-73-2004, IDIAP, Mar-
tigny, Switzerland, 0.
Vero?nica Romero, Alejandro He?ctor Toselli, Luis
Rodr??guez, and Enrique Vidal. 2007. Com-
puter Assisted Transcription for Ancient Text Im-
ages. In International Conference on Image Anal-
ysis and Recognition (ICIAR 2007), volume 4633
of LNCS, pages 1182?1193. Springer-Verlag, Mon-
treal (Canada), August.
Alejandro He?ctor Toselli, Vero?nica Romero, Moise?s
Pastor, and Enrique Vidal. 2009. Multimodal inter-
active transcription of text images. Pattern Recog-
nition, 43(5):1824?1825.
Alessandro Vinciarelli, Samy Bengio, and Horst
Bunke. 2004. Off-line recognition of uncon-
strained handwritten texts using hmms and statisti-
cal language models. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 26(6):709?720,
june.
Kwan Y. Wong and Friedrich M. Wahl. 1982. Doc-
ument analysis system. IBM Journal of Research
and Development, 26:647?656.
Erhan O?ztop, Adem Y. Mu?layim, Volkan Atalay, and
Fatos Yarman-Vural. 1999. Repulsive attractive
network for baseline extraction on document im-
ages. Signal Processing, 75(1):1 ? 10.
111
