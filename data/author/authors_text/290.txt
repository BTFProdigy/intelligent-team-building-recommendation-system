A word-grammar based morl)hoh)gieal nalyzer 
for agglutinative languages 
Aduriz 1.+, Agirre E., Aldezabal I., Alegria I., Arregi X., Arriohl J. M., Artola X., Gojenola K., 
Marilxalar A., Sarasola K., Urkia M.+ 
l)ept, of Colllptiier 1Aulgtlages and Systems, University of lhe Basqtlo Cotlnlry, 64.9 P. K., 
E-20080 1)onostia, Basque Counh'y 
tUZEI, Aldapeta 20, E-20009 1)onostia, Basque Country 
+Universidad de Barcelona, Grin Vfii de Isis Cortes CalaiallaS, 585, E-08007 Flarcelona 
j ipgogak @ si.elm, es. 
Abst rac l  
Agglutinative languages presenl rich 
morphology and for sonic applications 
they lleed deep analysis at word level. 
Tile work here presenled proposes a 
model for designing a full nlorpho- 
logical analyzer. 
The model integrates lhe two-level 
fornlalisnl alld a ullificalion-I)asod 
fornialisni. In contrast to other works, 
we propose to separate the treatment of 
sequential and non-sequetTtial mou)ho- 
lactic constraints. Sequential constraints 
are applied in lhe seglllenlalion phase, 
and non-seqtlontial OlleS ill the filial 
feature-combination phase. Early appli- 
cation of sequential nlorpholactic 
coilsli'aiills during tile segnloillaiioi/ 
process nlakes feasible :,ill officienl 
iinplenleilialion of tile full morpho- 
logical analyzer. 
The result of lhis research has been tile 
design and imi)len~entation of a full 
nlorphosynlactic analysis procedure for 
each word in unrestricted Basque texts. 
I n t roduct ion  
Morphological analysis of woMs is a basic 
tool for automatic language processing, and 
indispensable when dealing willl highly 
agglutinative languages like Basque (Aduriz el 
al., 98b). In lhis conlext, some applications, 
like spelling corfeclion, do ilOI need illOl'e lhan 
the seglllOlltation of each word inlo its 
different COlllponenl nlorphellles alollg with 
their morphological information, ltowever, 
there are oiher applications such as lemnializa- 
tion, lagging, phrase recognition, and 
delernlinaiion of clause boundaries (Aduriz el 
al., 95), which need an additional global 
morphological i)arsing j of the whole word. 
Such a complete nlorphological analyzer has 
lo consider three main aspects (l~,ilchie et al, 
92; Sproal, 92): 
1 Morl)hographenfics (also called morpho- 
phonology). This ternl covers orthographic 
variations that occur when linking 
I l lOfphellleS. 
2) morpholactics. Specil'ication of which 
nlorphenles can or cannot combine with 
each other lo form wflid words. 
3) Feature-combination. Specification of how 
these lnorphemes can be grouped and how 
their nlorphosyntactic features can be 
comlfined. 
The system here presented adopts, oil the one 
hand, tile lwo-level fornlalisnl to deal with 
morphogralfilemics and sequential morl)ho- 
lactics (Alegria el al., 96) and, on the other 
hand, a unification-based woM-grammar 2 to 
combine the grammatical information defined 
in nlorphemes and to  tackle complex 
nlorphotactics. This design allowed us to 
develop a full coverage analyzer that processes 
efl'iciently unrestricted texts in Basque. 
The remainder of tills paper is organized sis 
follows. After a brief' description of Basque 
nlorphology, section 2 describes tile 
architecture for morphological processing, 
where the morphosynlactic omponent is 
included. Section 3 specifies tile plaenomena 
covered by the analyzer, explains its desigi~ 
criteria, alld presents implementation and 
ewthialion details. Section d compares file 
I This has also been called mo*7)hOSh,ntactic 
parsitlg. When we use lhc \[(fill #11017~\]lOSyltl~/X WC 
will always refer to il~c lficrarchical structure at 
woM level, conlbining morphology and synlax. 
2 '\]'\]lt3 \[IDl'll\] WOl'd-gF(lllllllUl" should not be confused 
with the synlaclic lilcory presented in (Hudson, 84). 
system with previous works. Finally, the paper 
ends with some concluding renmrks. 
1 Brief description of Basque 
morphology 
These are the most important features of 
Basque morphology (Alegria et al, 96): 
? As prepositional functions are realized by 
case suffixes inside word-fornls, Basque 
presents a relatively high power to generate 
inflected word-forms. For instance, froth a 
single noun a minimum of 135 inflected 
forms can be generated. Therefore, the 
number of simple word-forms covered by 
the current 70,000 dictionary entries woukl 
not be less than 10 million. 
? 77 of the inflected forms are simple 
combinations of number, determination, 
and case marks, not capable of further 
inflection, but the other 58 word-forms 
ending in one of the two possible genitives 
(possessive and locative) can be further 
inflected with the 135 morphemes. This 
kind of recursive construction reveals a 
noun ellipsis inside a noun phrase and 
could be theoretically exteuded ad 
infinitum; however, in practice it is not 
usual to fiud more than two levels of this 
kind of recursion in a word-form. Taking 
into account a single level of noun ellipsis, 
the number of word-forum coukl be 
estimated over half a billion. 
? Verbs offer a lot of grammatical 
information. A verb tbrln conveys informa- 
tion about the subject, the two objects, as 
well as the tense and aspect. For example: 
diotsut (Eng.: 1 am telling you something). 
o Word-formation is very productive in 
Basque. It is very usual to create new 
compounds as well as derivatives. 
As a result of this wealth of infornmtion 
contained within word-forms, complex struc- 
tures have to be built to represent complete 
morphological information at word level. 
2 An architecture for the full 
morphological ana lyzer  
The framework we propose for the 
morphological treatment is shown in Figure 1. 
The morphological nalyzer is the fiont-end to 
all present applications for the processing of 
Basque texts. It is composed of two modules: 
the segmentation module and the 
morphosyntactic analyzer. 
conformant .................. ~ U~atabas N TEZ-conf~ 
\[Segmentation module 
____~| HorphograDhemics 
Morphotactics I 
TEI-FS .............. ~ ~ ~ ~  ~ - p ~  
conformant Cegmented TexN 
Morphosyntactic 
analyzer 
Feature- combination 
Morphotactics II 
TEI-FS \] .............. ~ actically 
Lermnatization, linguistic Analysis tagging tools 
Figure 1. Architecture 1"o1" morphological processing. 
The segmentation ,nodule was previously 
implemented in (Alegria et al, 96). This 
system applies two-level morphology 
(Koskenniemi, 83) for the morphological 
description and obtains, for each word, its 
possible segmentations (one or many) into 
component morphemes. The two-level system 
has the following components: 
? A set of 24 morphograf~hemic rules, 
compiled into transducers (Karttunen, 94). 
? A lexicon made up of around 70,000 items, 
grouped into 120 sublexicons and stored in 
a general lexical database (Aduriz et al, 
98a). 
This module has full coverage of free-running 
texts in Basque, giving an average number of 
2.63 different analyses per word. The result is 
the set of possible morphological segmenta- 
tions of a word, where each morpheme is 
associated with its corresponding features in 
the lexicon: part of speech (POS), 
subcategory, declension case, number, 
definiteness, as well as syntactic function and 
some semantic features. Therefore, the output 
of the segmeutation phase is very rich, as 
shown in Figure 2 with the word amarengan 
(Eng.: on the mother). 
grammar 
mother) 
POS noun) 
subc~t common 
:count: +) 
(an imate  +) 
(nleasurable "-) 
aren 
(of life) 
(POS decl-suffix) 
(definite +) 
(number sing) 
(case genitive) 
(synt-f @nouncomp) 
J gan \] 
(o.1 / 
(POS decl-suf fix) I 
(case inossivo) \] 
(synt-f @adverbial)I 
=> 
amarengan 
(o. the mother) 
POS noun) 
subcat common) 
number sing) 
definite +) 
case inessive) 
count +) 
animate +) 
measurable -) 
synt-f @adverbial) 
iq:e, ure 2. Morphosynlactic analysis eof (unureugun (l{ng.: (m 
The architecture is a modular envhoument that 
allows different ypes of output depending on 
the desired level of analysis. The foundation of 
the architecture lies in the fact lhat TEI- 
confommnt SGML has been adopted for the 
comnmnication allloIlg modules (Ide and 
VCFOIIiS, 95). l~'eature shucluleS coded 
accoMing TIU are used to represent linguistic 
information, illcluding tile input mM outl)ut of 
the morplaological analyzer. This reprcscnta- 
tion rambles the use of SGML-aware parsers 
and tools, and Call he easily filtered into 
different formats (Artola et ill., 00). 
3 Word level morl)hosyntactic analysis 
This section Hrst presents the l~henomena lhat 
must be covered by the morphosyntactic 
analyzer, then explains ils design criteria, and 
finally shows implementation and ewfluation 
details. 
3.1 Phenomena covered by the analyzer 
There are several features that emphasized the 
need of morphosyntactic almlysis in order to 
build up word level information: 
I) Multiplicity of values for the same feature 
in successive morphemes. In the analysis 
of Figure 2 there are two different values 
for the POS (noun and declension suffix), 
two for the case (genitive and inessive), 
and two for the syntactic function 
(@nouncomp and @adverbial). Multiple 
values at moq~hemc-level will have to be 
merged to obtain the word level infer 
mation. 
2) Words with phrase structure. Although the 
segmentation is done for isolated words, 
independently of context, in several cases 
3 l?calurc wtlues starling with the "@" character 
correspond to syntactic functions, like @noullcomp 
(norm complement) or @adverbial. 
the mother) 
tile resulting structure is oquiwflent o the 
aualysis of a phrase, as can be seen i, 
Figure 2. 111 this case, although there are 
two different cases (genitive and inessive), 
lhe case of the full word-form is simply 
inessive. 
3) Noun ellipsis inside word-lbrms. A noun 
ellipsis can occur withi, the word 
(oceasi(mally more than once). This 
information must be made explicit in the 
resulting analysis. For example, Figure 3 
shows the analysis of a single word-forln 
like diotsudumtrel&z (Eng.: with what I am 
lelling you). The first line shows its 
segmentation into four morphemes 
(die tsut+en+ 0 +arekin). The feature 
compl ill tile final analysis conveys the 
information for the verb (l um lelliHg you), 
that carries information about pc'rson, 
number and case o1' subject, object and 
indirect object. The feature comp2 
represents an elided noun and its 
declension stfffix (with). 
4) l)erivation and composition are productive 
in Basque. There arc more than 80 deri- 
w/tion morphemes (especially suffixes) 
intensively used in word-fornlatioll. 
3.2 Design of the word-grammar 
The need to impose hierarchical structure upon 
sequences of morphemes and to build complex 
constructions from them forced us to choose a 
unil'ication mechanism. This task is currently 
unsolwlble using finite-state techniques, clue to 
the growth in size of the resulting network 
(Beesley, 98). We have developed a unifica- 
tion based word-grammar, where each rule 
combines information flom different 
mot+lJlemes giving as a result a feature 
structure for each interpretation of a word- 
fol'nl, treating the previously mentioned cases. 
3 
diotsut 
I am tellh,g you) 
POS verb) 
(tense present) 
(pers-ergative is)\[ 
(pets-dative 2s) 
(pers-absol 3s) 
en 
(what) 
(POS relation) 
(subcat subord) 
(relator relative 
(synt-f @rel-clause 
0 
() 
(POS ellipsis) 
arekin 
(wire) 
(POS declension-suffix)) 
(case sociative) 
(number sing) 
(definite +) 
(synt-f @adverbial) 
=> diotsudanarekin (wi~ what lamtel l ingyou) 
(POS verb-noun_ellipsis) 
(case sociative) 
(number sing) 
(definite +) 
(synt-f @adverbial) 
(compl (POS verb) 
(subcat subord) 
(relator relative) 
(synt-f @tel-clause) 
(tense present) 
(pers-ergative is) 
(pets-dative 2s) 
(pers-absol 3s)) 
(comp2 (POS noun) 
(subcat common) 
(number sing) 
(definite+) 
(synt-f @adverbial)) 
Figure 3. Morphosyntactic analysis of diotxudanarekin (Eng.: with what I am tellittg you) 
As a consequence of the rich naorphology of 
Basque we decided to control morphotactic 
phenomena, as much as possible, in the 
morphological segmentation phase. Alterna- 
tively, a model with minimal morphotactic 
treatment (Ritchie et al, 92) would produce 
too many possible analyses after segmentation, 
which should be reiected in a second phase. 
Therefore, we propose to separate sequential 
morphotactics (i.e., which sequences of 
morphemes can or cannot combine with each 
other to form valid words), which will be 
recognized by the two-level system by means 
of continuation classes, and non-sequential 
morphotactics like long-distance dependencies 
that will be controlled by the word-gmnunar. 
The general linguistic principles used to define 
unification equations in the word-grannnar 
rules are the following: 
1) Information risen from the lemma. The 
POS and semantic features are risen flom 
the lemnm. This principle is applied to 
common nouns, adjectives and adverbs. 
The lemma also gives the mnnber in 
proper nouns, pronouns and determiners 
(see Figure 2). 
2) lnfornmtion risen from case suffixes. 
Simple case suffixes provide information 
on declension case, number and syntactic 
function. For example, tile singular 
genitive case is given by the suffix -tell in 
ama+ren (Eng.: of the mother). For 
compound case suffixes the number and 
determination are taken from the first 
suffix and the case from the second one. 
First, both suffixes are joined and after 
that they are attached to the lemma. 
3) Noun ellipsis. When an ellipsis occurs, the 
POS of the whole word-form is expressed 
by a compound, which indicates both the 
presence of the ellipsis (always a noun) 
and the main POS of the word. 
For instance, the resulting POS is 
verb-noun_e l l ips is  when a noun- 
ellipsis occurs after a verb. All the 
information corresponding to both units, 
the explicit lemma and the elided one, is 
stored (see Figure 3). 
4) Subordination morl~hemes. When a 
subordination morpheme is attached to a 
verb, the verb POS and its featm'es are 
risen as well as the subordhmte relation 
and the syntactic fnnction conveyed by the 
naorpheme. 
5) Degree morphemes attached to adjectives, 
past participles and adverbs. The POS and 
diotsudan 
(diotsut + en) 
(POS verb) 
(tense present) 
(relator relative) 
/ \ / 
diotsut 
(POS verb) 
(tense present 
diotsudanarekin 
(diotsut + en -I 0 + arekin) 
(POS verb-noun_ell ipsis) 
(case sociative) 
arekin 
(0 + arekin) 
(POS noun ellipsis) 
(case sociative) 
en 
(pos 
? . . 
o 
(POS e l l ips i s  re la t ion)  
arekin 
(case sociative) 
Figure 4. Parse tree for diotmuhmarekitl (Eng.: with what I am lellittg yott) 
main features arc taken from the lemma 
and the features corresponding to the 
degrees of comparison (comparative, 
supcrhttive) aft taken from the degree 
morphemes. 
6) l)efiwttion. 1)miwttion suffixes select tile 
POS of the base-form to create the deriw> 
tive anti in most cases to change its POS. 
For instance, the suffix -garri (Eng.: -able) 
is applied to verbs and the derived word is 
an adjective. When the derived form is 
obtained by means o1' a prefix, it does not 
change the POS of the base-form. In both 
cases the morphosyntactic rules add a new 
feature representing the structure of tile 
word as a derivative (root and affixes). 
7) Composition. At the moment, we only 
treat the most freqttent kind of 
composition (noun-noun). Since Basque is 
syntactically characterized as a right-head 
hmguage, the main information of the 
compound is taken from the second 
element. 
8) Order of application of the mofphosyn- 
tactic phenomena. When several morpho- 
syntactic phenomena are applied to the 
same leml l la ,  so as to eliminate 
nonsensical readings, the natural order to 
consider them in Basque is the following: 
lemmas, derbation prefixes, deriwltion 
suffixes, composition and inflection (see 
Figure 4). 
9) Morl)hotactic constraints. Elimination of 
illegal sequences of morphemes, such as 
those due to long-distance dependencies, 
which are difficult to restrict by means of 
conti.uation classes. 
The first and second principles are defined lo 
combine information of previously recognized 
mOrl~hemcs, but all the other principles arc 
related to both feature-combination a d non- 
sequential moq~hotactics. 
3.3 Implementation 
We have chosen the PATR formalism 
(Shiebcr, 86) for the definition of the moqflm- 
syntactic rules. There were two main reasons 
for this choice: 
? The formalism is based o.  unification. 
Unification is adequate for the treatment of 
complex phenomena (e.g., agreement of 
conslituents in case, tmmber and definite- 
hess) and complex linguistic structures. 
? Simplicity. The grammar is not linked to a 
linguistic theory, e.g. GPSG in (Ritchie et 
al., 92)? The fact that PATR is simpler than 
more sophisticated formalisms will allow 
that in @e future the grammar could be 
adapted to any of them. 
25 rules have been defined, distributed in the 
following way: 
? 11 rules for the merging of declension 
morphemes and their combination with the 
main categories, 
? 9 rules for the description of verbal 
subordination morphenles, 
? 2 general fulcs for derivation, 
? 1 rule for each of the following 
phenomeml: ellipsis, degree of COlnpavison 
of adjectives (comparative and SUl)erlative) 
and noun composition. 
3.4 Evaluat ion 
As a cousequence of the size of the lexical 
database and tile extensive treatment of 
nlorphosyntax, the resulting analyzer offers 
full coverage when applied to real texts, 
capable of treating unknown words and non- 
standard forms (dialectal wtriants and typical 
errors). 
We performed four experilnents to ewtluate 
tile efficiency of the implemented analyzer 
(see Table 1). A 10,832-word text was 
randomly selected from newspapers. We 
measured tile number of words per second 
analyzed by the morphosyntactic analyzer and 
also by the whole morphological analyzer 
(results taken on a Sun Ultra 10). Ill the first 
experiment all tile word-t'ornls were analyzed 
one-by-one; while ill tile other three experi- 
ments words with more than one occurrence 
were analyzed only once. Ill the last two 
experimeuts a memory with the analysis of tile 
most frequent word-forms (MFW) in Basque 
was used, so that only word-forms not found 
in the MFW were analyzed. 
Test 
description 
All 
word forms 
Diffcrent 
word forms 
MFW 
10,000 words 
(I 5 Mb) 
MFW 
50,000 words 
(75 mb) 
# words/scc 
analyzed Morphosynt. 
words analyzer 
10,832 
3,692 
1,483 
533 
15,13 
44 40 
111 95 
308 270 
words/see 
Full 
morphological 
analyzer 
13,5 
Table 1. Evaluation results. 
Even when our language is agglutinative, and 
its morphological phenomena need more 
computational resources to build complex and 
deep structures, the results prove tile feasibility 
of implementiug efficiently a fifll 
morphological analyzer, although efficiency 
was not the main concern of our 
implementation. The system is currently being 
applied to unrestricted texts in real-time 
applications. 
4 Related work 
(Koskeniemmi, 83) defined the formalism 
named two-level morphology. Its main 
contributiou was the treatment of 
morl)hographemics and morphotactics. The 
formalisnl has been stmcessfully applied to a 
wide wlriety ot' languages. 
(Karttunen, 94) speeds the two-level model 
compiling two-level rules into lexical 
transducers, also increasing the expressiveness 
of the model 
The morphological analyzer created by 
(Ritchie et al, 92) does not adopt finite state 
mechanisms to control morphotactic 
phenomena. Their two-level implementation 
incorporates a straightforward morphotactics, 
reducing tile number of sublexicons to the 
indispensable (prefixes, lemmas and suffixes). 
This approximation would be highly 
inefficient for agglutinative languages, as it 
would create lnany nonsensical interpretatiolas 
that should be rejected by tile unification 
phase. They use the word-grammar for both 
morphotactics and feature-conlbination. 
ill a similar way, (Trost, 90) make a proposal 
to combine two-level morphology and non- 
sequential morphotactics. 
The PC-Kimmo-V2 system (Antworth, 94) 
presents an architecture similar to ours applied 
to English, using a finite-state segmentation 
phase before applying a unification-based 
grammar. 
(Pr6szdky and Kis, 99) describe a morpho- 
syntactic analyzer for Hungarian, an agglu- 
tinative language. The system clots not use the 
two-level model for segmentation, precom- 
piling suffix-sequences to improve efficiency. 
They claim the need of a word-grammar, 
giving a first outline of its design, although 
they do not describe it in detail. 
(Oflazer, 99) presents a different approach for 
the treatment of Turkish, an agglutinative 
language, applying directly a dependency 
parsing scheme to morpheme groups, that is, 
merging morphosyntax and syntax. Although 
we are currently using a similar model to 
Basque, there are several applications that are 
word-based and need full morphological 
parsing of each word-t'orm, like the word- 
oriented Constraint Graminar formalism for 
disambiguation (Karlsson et aI., 95). 
Conc lus ion  
We propose a model for fllll morphological 
analysis iutegrating two different components. 
On tile one hand, the two-level formalism 
deals with morphographenfics and sequential 
morphotactics and, on the other hand, a 
unil\]cation-based word-grammar combines lhe 
granlll-iatical in\['ornlatioli defined in illoi'- 
phelllOS alld also handles COlllplcx illori)ho- 
tactics. 
Early application of sCqtloniial I/lOrl)hotactic 
conslraints dtu-ing the segmentation process 
avoids all excessive laUlllber of nleaningless 
segmentation possibilities before the 
coulputationally lllOlO expensive unification 
process. Unification permits lhe resohition of a 
wide variety of morl)hological phenonlena, 
like ellipsis, thal force the definition of: 
complex and deep structures Io roprosenl the 
output of the analyzer. 
This design allowed us io develop a full 
coverage allalyzor that processes efficiently 
unrestricted loxis in Basque, a strongly 
agglulinafive langttage. 
The anaiyzcl" has bccll integrated ill a gCllOl'al 
franlework for the l)lOCessing of l~asquc, with 
all the linguistic inodulos communicating by 
l l leallS O\[: foattll'C stltlClll l 'eS ill accord  {o the 
principles of ihe Text Encoding Initiative. 
Acknowledgements  
This research was partially supported by the 
Basque Government, the University of the 
\]71aS(lUe Cotlntry {/lid the CICYq' (Cotllisidn 
lntcrministorial de Ciencia y Tecnologfil). 
References 
Aduriz 1., Aldczabal I., Ansa ()., Arlola X., I)faz de 
Ilarraza A., Insau.~li .I.M. (1998a) EI)BL: a 
Mttlli-l~ttrposed Lexica/ Sttl)l)c;rl .lot the 
Treatment of Ba,s'que. Proceedings of the l;irst 
Inlernational Confcncncc on l Auiguagc Resources 
and Ewduation, Granada. 
Aduriz I., Agirre E., Aldczabal 1., Alegria 1., Ansa 
O., Arrcgi X., Arriola J.M., ArtolaX., I)faz de 
lhu'raza A., Ezciza N., Gqicnola K., Maritxahu" 
A., Maritxalar M., Oronoz M., Sarasola K., 
Soroa A., Urizar R., Urkia M. (1998b) A 
Framework .for the Automatic Pmce.vsi#~g (if" 
Basqtte. Proceedings o1 the First Ii~ternational 
Con \[elel i te on Lall.gtlagc Resources turf 
Evaluation, Granada. 
Aduriz I., Alcgria I., Arriohl J.M., Artola X., l)faz 
do Ilarraza A., Ecciza N., Gojcnola K., 
Maritxalar M. (1995) Di\[.ferelt! Issues in the 
Design qf a lemmatizer/Tagger fo Ba,s'qtte. From 
Tcxls to Tags: Issues in Mullilingual Language 
Analysis. ACL SIGI)AT Workshop, l)ublin. 
Alcgria 1., Art(Ha X., Sarasoht K., Urkia M. (1996) 
Automatic moqdzological analysis of Basque. 
IAtcrary and IAnguistic Computing, 11 (4): 193- 
203. Oxford University. 
Aniworlh E. I.. (1994) Morphological Par, ffng with 
a lhl(fication-ba,s'ed Word Grcmmutr. Norlh 
Te, xas Natural l~anguage Processing Workshop, 
Texas. 
Arlola X., Dfaz de \]larraza A., Ezciza N., Oo.icnohi 
K., Marilxahu' A., Soma A. (2000) A proposal 
for the integration of NLP tools using SGML- 
lagged documeHls. Proceedings of ll~e Second 
Cotfforence or1 Language Resources and 
Evaltmfion (IA~,EC 2000). Athens, Greece 2000. 
Bcesl%, K. (1998)AraDic Morphological Analysis 
(m the lnlernet, l'rocccdings of the International 
Conference on Mulii-IAngual Computing (Arabic 
& lhlglish), Cambridge. 
Hudson R. (1990) English Word Grammmar. 
Oxford: Basil Blackwcll. 
ldc N., Vcronis J. K. (1995) Text-Ettcoding hHtia- 
tire, Bac:kgmtmd and Context. Kluwcr Academic 
Publishers. 
Karlsson F., Voulilaincn A., Heikkiht J., Anltila A. 
(1995) Constrai, t Gnmmmr: A lxm,?tmge- 
i#ldcpcndent System Jor Pm:ffng Um'estricled 
Text, Mouton do Gruyicr ed.. 
Kartmnen 1,. (1994) Con,s'tructin~ l,e.vical 
7)'ansdttcers. Proc. of CO13NG'94, 406-411. 
Koskcnniemi, K, (1983) Two-level Mc;qdlo\[ogy: A 
ge,eral Comptttational Model ./br Word-Form 
Recognition and Pmduclioth University of 
Ilclsinki, l)clmrtmcnt of General IAnguisiics. 
l~ublications " 11. 
()flazcr K (1999) l)epetMe/t O' Parsing, with a, 
E.rtended I:inite State Approac\]t. ACL'99, 
Maryland. 
Pr6sz6ky G., Kis B (1999)A Unificati(m-hascd 
Apl~roach to Moqdto-syntactic I'arsitl<~ of 
Agghttinative and Other (Highly) lnjlectional 
Languages. ACtd99, Ma,yhmd. 
Ritchie G., Pulhnan S. G., FJlack A. W., Russcl G. 
J. (1992) Comlmtational Moudu)logy: Practical 
Mechanism,s'.fi)r the l#lglish l,exico,. ACL-MIT 
Series on Natural Language Processing, MIT 
Press. 
Shicbcr S. M. (1986) At/ lntroductiotz to 
Unification-Based Approaches to Grammar. 
CSLI, Slanford. 
Sproat R. (1992) Morphology anU Computcaion. 
ACL-MIT Press series in Natural Language 
Processing. 
Trost It. (1990) The application of two-level 
morldzo/ogy to rzon-concatenative German 
moqgtology. COIANG'90, Hclsinki. 
7 
  Towards a Dependency Parser for Basque 
M. J. Aranzabe, J.M. Arriola and A. Diaz de Ilarraza, 
Ixa Group. (http://ixa.si.ehu.es) 
Department of Computer Languages and Systems 
University of the Basque Country 
P.O. box 649, E-20080 Donostia  
jibarurm@si.ehu.es 
 
 
Abstract 
We present the Dependency Parser, 
called Maxuxta, for the linguistic 
processing of Basque, which can serve 
as a representative of agglutinative 
languages that are also characterized by 
the free order of its constituents. The 
Dependency syntactic model is applied 
to establish the dependency-based 
grammatical relations between the 
components within the clause. Such a 
deep analysis is used to improve the 
output of the shallow parsing where 
syntactic structure ambiguity is not fully 
and explicitly resolved. Previous to the 
completion of the grammar for the 
dependency parsing, the design of the 
Dependency Structure-based Scheme 
had to be accomplished; we concentrated 
on issues that must be resolved by any 
practical system that uses such models. 
This scheme was used both to the 
manual tagging of the corpus and to 
develop the parser. The manually tagged 
corpus has been used to evaluate the 
accuracy of the parser. We have 
evaluated the application of the grammar 
to corpus, measuring the linking of the 
verb with its dependents, with 
satisfactory results. 
1 Introduction 
This article describes the steps given for the 
construction of a dependency syntactic parser 
for Basque (Maxuxta ). Our dependency 
analyser follows the constraint-based approach 
advocated by Karlsson (Karlsson, 1995). It 
takes as input the information obtained in the 
shallow parsing process (Abney, 1997). The 
shallow syntax refers to POS tagging and the 
chunking rules which group sequences of 
categories into structures (chunks) to facilitate 
the dependency analysis. The dependency 
parser is considered as the module involved in 
deep parsing (see Fig. 1). In this approach, 
incomplete syntactic structures are produced 
and, thus, the process goes beyond shallow 
parsing to a deeper language analysis in an 
incremental fashion (Aduriz et al, 2004). This 
allows us to tackle unrestricted text parsing 
through descriptions that are organized in 
ordered modules, depending on the depth level 
of the analysis (see Fig. 1).  
In agglutinative languages like Basque, it is 
difficult to separate morphology from syntax. 
That is why we consider morphosyntactic 
parsing for the first phase of the shallow 
syntactic analyser. 
CG
M
or
ph
os
yn
ta
ct
ic
pa
rs
in
g
Sy
nt
ac
tic
 
ta
gg
in
g
C
hu
nk
er
D
ep
en
de
nc
ie
s
EUSLEM 
Morpheus
Disambiguation using linguistic 
information
Disambiguation using statistical 
information
Shallow syntactic parsing
Named Entities
%
CG
PostpositionsCG
xfst
Noun and verb chainsCG
Tagging of syntactic dependenciesCG
Sh
al
lo
w
 
pa
rs
in
g
D
ee
p 
pa
rs
in
g
Raw data
Analysed text
 
Fig. 1. Syntactic processing for Basque. 
The dependency parser has been performed 
in order to improve the syntactic analysis 
 achieved so far, in the sense that, apart from 
the surface structural properties, we have 
added information about deeper structures by 
expressing the relation between the head and 
the dependent in an explicit manner. 
Additionally, we have adopted solutions to 
overcome problems that have emerged in 
doing this analysis (such as discontinuous 
constituents, subordinate clauses, etc. This 
approach has been used in several projects 
(J?rvinen & Tapanainen, 1998; Oflazer, 2003).  
Before carrying out the definition of the 
grammar for the parser, we established the 
syntactic tagging system in linguistic terms. 
We simultaneously have applied it to build the 
treebank for Basque (Eus3LB1) (Aduriz et al, 
2003) as well as to define the Dependency 
Grammar. The treebank would serve to 
evaluate and improve the dependency parser. 
This will enable us to check how robust our 
grammar is.  
The dependency syntactic tagging system is 
based on the framework presented in Carroll et 
al., (1998, 1999): each sentence in the corpus 
is marked up with a set of grammatical 
relations (GRs), specifying the syntactic 
dependency which holds between each head 
and its dependent(s). However, there are 
certain differences: in our system, arguments 
that are not lexicalised may appear in 
grammatical relations  (for example, the 
phonetically empty pro argument, which 
appears in the so-called pro-drop languages). 
The scheme is superficially similar to a 
syntactic dependency analysis in the style of 
Lin (1998). We annotate syntactically the 
Eus3LB corpus following the dependency-
based formalism. The dependencies we have 
defined constitute a hierarchy (see Fig. 2) that 
describes the theoretically and empirically 
relevant dependency tags employed in the 
analysis of the basic syntactic structures of 
Basque.  
                                                
1This work is part of a general project 
(http://www.dlsi.ua.es/projectes/3lb) which objective is to build 
three linguistically annotated corpora with linguistic annotation 
at syntactic, semantic and pragmatic levels: Cat3LB (for 
Catalan), Cast3LB (for Spanish) (Civit & Mart?, 2002) and 
Eus3LB (for Basque). The Catalan and the Spanish corpora 
include 100.000 words each, and the Basque Corpus 50.000 
words. 
This formalism is also used in the Prague 
Dependency Treebank for Czech (Hajic, 1998) 
and in NEGRA corpora for German (Brants et 
al., 2003) among others.  
 
dependant
structurally case
marked
complements
negation
linking-words
modifiers
auxiliary
others
semantics
non clausal
clausal
clausal
non
clausal
determiner
non clausal
clausal
predicative
finite
non finite
clausal
non
clausal
connector
apposition
graduator
particle
interjec.
ncsubj
nczobj
ncobj
ncmod
finite
non finite
detmod
xcomp_obj
xmod
xcomp_subj
cmod
ccomp_obj
ccomp_subj
ncmod
lot
auxmod
ncpred
non finite xpred
finite
non
finite
aponcmod
apocmod
apoxmod
gradmod
prtmod
itj_out
arg_mod
meta
galdemod
ccomp_zobj
xcomp_zobj
 
Fig. 2. Dependency relations hierarchy. 
Section 2 examines the main features of the 
language involved in the analysis in terms of 
dependency relations. Taking into account 
these features, we will explain the reasons for 
choosing the dependency-based formalism. In 
section 3 we briefly describe the general 
parsing system. Section 4 explains the 
dependency relations, the implementation of 
the dependency rules and a preliminary 
evaluation. Finally, some conclusions and 
objectives for future work are presented. 
 
2 A brief description of Basque in order 
to illustrate the adequacy of the adopted 
formalism 
Basque is an agglutinative language, that is, 
for the formation of words the dictionary entry 
independently takes each of the elements 
necessary for the different functions (syntactic 
case included). More specifically, the affixes 
corresponding to the determinant, number and 
declension case are taken in this order and 
independently of each other. These elements 
appear only after the last element in the noun 
phrase. One of the main characteristics of 
 Basque is its declension system with numerous 
cases, which differentiates it from languages 
spoken in the surrounding countries.  
At sentence level, the verb appears as the 
last element in a neutral order. That is, given 
the language typology proposed by Greenberg, 
Basque is a Subject-Object-Verb (SOV) type 
language (Laka, 1998) or a final head type 
language. However, this corresponds to the 
neutral order, but in real sentences any order of 
the sentence elements (NPs, PPs) around the 
verb is possible, that is, Basque can also be 
considered a language with free order of 
sentence constituents.  
These are the principal features that 
characterize the Basque language and, 
obviously, they have influenced us critically in 
our decision:  
 
1. The dependency-based formalism is the one 
that could best deal with the free word order 
displayed by Basque syntax (Skut et al, 
1997). 
2. We consider that the computational tools 
developed so far in our group facilitate 
either achieving dependency relations or 
transforming from dependency-trees to other 
modes of representation.  
3. From our viewpoint, it is less messy to 
evaluate the relation between the elements 
that compose a sentence rather than the 
relation of elements included in parenthesis. 
4. Dependency-based formalism provides a 
way of expressing semantic relations. 
3 Overview of the Syntactic Processing 
of Basque: from shallow parsing to deep 
parsing  
We face the creation of a robust syntactic 
analyser by implementing it in sequential rule 
layers. In most of the cases, these layers are 
realized in grammars defined by the Constraint 
Grammar formalism (Karlsson et al , 1995; 
Tapanainen & Voutilainen, 1994). Each 
analysis layer uses the output of the previous 
layer as its input and enriches it with further 
information. Rule layers are grouped into 
modules depending on the level of depth of 
their analysis. Modularity helps to maintain 
linguistic data and makes the system easily 
customisable or reusable.  
Figure 1 shows the architecture of the 
system, for more details, see Aduriz et al, 
2004. The shallow parsing of the text begins 
with the morphosyntactic analysis and ends 
delimiting noun and verb chains. Finally, the 
deep analysis phase establishes the 
dependency-based grammatical relations 
between the components within the clause.  
The parsing system is based on finite state 
grammars. The Constraint Grammar (CG) 
formalism has been chosen in most cases 
because, on the one hand, it is suitable for 
treating unrestricted texts and, on the other 
hand, it provides a useful methodology and the 
tools to tackle morphosyntax as well as free 
order phrase components in a direct way.  
A series of grammars are implemented 
within the module of the shallow parsing 
which aim:  
1. To be useful for the disambiguation of 
grammatical categories, removing incorrect 
tags based on the context. 
2. To assign and disambiguate partial syntactic 
functions. 
3. To assign the corresponding tags to delimit 
verb and noun chains. 
3.1 Shallow Syntactic Analyser 
The shallow or partial parsing analyser 
produces minimal and incomplete syntactic 
structures. The output of the shallow parser, as 
stated earlier, is the main base for the 
dependency parser. The shallow syntactic 
analyser includes the following modules: 
1. The morphosyntactic analyser MORFEUS. 
The parsing process starts with the outcome 
of the morphosyntactic analyser MORFEUS 
(Alegria et al, 1996), which was created 
following a two-level morphology 
(Koskenniemi, 1983). It deals with the 
parsing of all the lexical units of a text, both 
simple words and multiword units as a 
Complex Lexical Unit (CLU).  
2. The morphosyntactic disambiguation 
module EUSLEM. From the obtained 
results, grammatical categories and lemmas 
are disambiguated. Once morphosyntactic 
disambiguation has been performed, this  
module assigns a single syntactic function to 
each word.  
 3. The ckunk analysis module ZATIAK. This 
module identifies verb and noun chains 
based on the information about syntactic 
functions provided by each word-form. 
Entity names and postpositional phrases are 
also determined.  
We will focus on the last step of the shallow 
analysis because it contains the more 
appropriate information to make explicit the 
dependency relations. Basically, we use the 
syntactic functions and the chunks that are 
determined in the partial analysis. 
Shallow syntactic functions 
The syntactic functions that are determined 
in the partial analysis are based on those given 
in Aduriz et al, 2000. The syntactic functions 
employed basically follow the same approach 
to syntactic tags found in ENGCG 
(Voutilainen et al, 1992), although some 
decisions and a few changes were necessary. 
There are three types of syntactic functions:  
1. Those that represent the dependencies 
within noun chains (@CM>, @NC> etc.). 
2. Non-dependent or main syntactic functions 
(@SUBJ, @OBJ, etc.). 
3. Syntactic functions of the components of 
verb chains (@-FMAINV, @+FMAINV, 
etc.). 
The distinction of these three groups is 
essential when designing the rules that assign 
the function tags for verb and noun chains 
detection. 
Chunker: verb chain and noun chains 
After the morphological analysis and the 
disambiguation are performed (see Figure 1), 
we have the corpus syntactically analysed 
following the CG syntax. In this syntactic 
representation there are not phrase units. But 
on the basis of this representation, the 
identification of various kinds of phrase units 
such as verb chains and noun chains is 
reasonably straightforward.   
Verb chains  
The identification of verb chains is based on 
both the verb function tags (@+FAUXV, @-
FAUXV, @-FMAINV, @+FMAINV, etc.) and 
some particles (the negative particle, modal 
particles, etc.).  
There are two types of verb chains: 
continuous and dispersed verb chains (the 
latter consisting of three components at most). 
The following function tags have been defined: 
? %VCH: this tag is attached to a verb chain 
consisting of a single element. 
? %INIT_VCH: this tag is attached to the 
initial element of a complex verb chain. 
? %FIN_VCH: this tag is attached to the final 
element of a complex verb chain. 
The tags used to mark-up dispersed verb 
chains are: 
? %INIT_NCVCH: this tag is attached to the 
initial element of a non-continuous verb 
chain. 
? %SEC_NCVCH: this tag is attached to the 
second element of a non-continuous verb 
chain. 
? %FIN_NCVCH: this tag is attached to the 
fina l element of a non-continuous verb 
chain. 
Noun chains 
This module is based on the following 
assumption: any word having a modifier 
function tag has to be linked to some word or 
words with a main syntactic function tag. 
Moreover, a word with a main syntactic 
function tag can, by itself, constitute a phrase 
unit (for instance, noun phrases, adverbials and 
prepositional phrases). Taking into account this 
assumption, we recognise simple and 
coordinated noun chains, for which these three 
function tags have been established:  
? %NCH: this tag is attached to words with 
main syntactic function tags that constitute a 
phrase unit by themselves 
? %INIT_NCH: this tag is attached to the 
initial element of a phrase unit.  
? %FIN_NCH: this tag is attached to the final 
element of a phrase unit.  
Figure 3 shows part of the information 
obtained in the process of parsing the sentence 
Defentsako abokatuak desobedientzia 
zibilerako eskubidea aldarrikatu du epaiketan 
(The defense lawyer has claimed the right to 
civil disobedience in the  trial) with its 
corresponding chains tags.  
Let us know the some syntactic tags used in 
fig. 3: @NC>: noun complement; @CM>: 
modifier of the word carrying case in the noun 
 chain; @-FMAINV: non finite main verb; 
@+FAUXV: finite auxiliary verb and 
@ADVL: adverbial. 
"<Defentsako>" <INIT_CAP>"   defense  
     "defentsa" N @NC>  %INIT_NCH 
"<abokatuak>"  the lawyer  
      "abokatu" N @SUBJ  %FIN_NCH 
"<desobedientzia>"                       disobedience  
   "desobedientzia" N @CM> %INIT_NCH 
"<zibilerako>"                                to civil  
       "zibil" ADJ @<NC 
"<eskubidea>"                                the right  
       "eskubide" N @OBJ %FIN_NCH 
"<aldarrikatu>"                              claimed  
   "aldarrikatu" V @-FMAINV %INIT_VCH 
"<du>"                                            has  
   "*edun" AUXV @+FAUXV %FIN_VCH   
"<epaiketan>"                                 in the trial 
        "epaiketa" N @ADVL  %NCH  
"<$.>" <PUNCT_PUNCT>" 
Fig. 3. Analysis of chains. English translation on the 
right 
3.3 Deep Syntactic Analysis  
The aim of the deep syntactic analysis is to 
make explicit the dependency relations 
between words or chunks. For this reason, we 
have designed a Dependency Grammar based 
on the Constraint Grammar Formalism. 
4 The Dependency Grammar for the 
Parser  
In this section we describe in more detail the 
dependency relations defined (see fig. 2), the 
design of the rules and the results obtained. 
The results obtained in the deep parsing of 
sample sentence will help in providing a better 
understanding of the mentioned parsing 
process. This parsing process takes as basis the 
output of the shallow parser (see fig. 3). The 
rules are implemented by means of the CG-2 
parser (www.conexor.com). 
4.1 The dependency relations 
As Lin (2003) says a dependency 
relationship (Hays, 1964; Hudson, 1984; 
Mel?cuk, 1987; B?mov? et al, 2003) is an 
asymmetric binary relationship between a 
word called head (or governor, parent), and 
another word called modifier (or dependent, 
daughter). Dependency grammars represent 
sentence structures as a set of dependency 
relationships. Normally the dependency 
relationships form a tree that connects all the 
words in a sentence. A word in the sentence 
may have several modifiers, but each word 
may modify at most one word. The root of the 
dependency tree does not modify any word. It 
is also called the head of the sentence. 
For example, figure 4 describes the 
dependency structure of the example sentence. 
We use a list of tuples to represent a 
dependency tree. Each tuple represents one 
relation in the dependency tree. For example, a 
structurally case-marked complement when 
complements are nc (non-clausal, Noun 
Phrases, henceforth NP) has the following 
format: 
case : the case-mark by means of what the 
relation is established among the head and the 
modifier. 
head: the modified word head of 
NP/dependent: the modifier. In this case, the 
head of the NP. 
case-marked element within 
NP/dependent: the component of the 
dependent NP that carries the case. 
subj relationship: the label assigned to the 
dependency relationship. 
The syntactic dependencies between the 
components within the sentence are 
represented by tags starting with ?&?. The 
symbols ?>? and ?<? attached to each 
dependency-tag represent the direction in 
which we find the sentence component whose 
dependant is the target word.  
In the example we can see that the noun 
phrase defentsako abokatuak  ?the defense 
lawyer? depends on the verb aldarrikatu ?to 
claim?, which is on its right side. A post-
process will make this link explicit. 
The dependency tree in fig 4 is represented 
by the following tuples: 
 
Modifier Cat Head Type 
Defentsako 
abokatuak 
desobedientzia 
zibilerako 
eskubidea 
aldarrikatu 
du 
epaiketan 
N 
N 
N 
ADJ 
N 
V 
Aux 
N 
abokatuak  
aldarrikatu  
eskubidea  
desobedientzia 
aldarrikatu 
 
aldarrikatu 
aldarrikatu 
&NCMOD> 
&NCSUBJ> 
&NCMOD> 
&<NCMOD 
&NCOBJ> 
 
&<AUXMOD 
&<NCMOD 
 4.2 The dependency grammar rules  
The grammar consists of 255 rules that have 
been defined and distributed in the following 
way: 
 
complements modifiers 
nc2 cc3 det nc cm4 
others 
62 11 19 124 20 19 
 
These rules were formulated, implemented, 
and tested using a part of the manually 
disambiguated corpus (24.000 words). For the 
moment, part of the rest of the corpus was used 
for testing.  
For more details of the rules, we describe 
some examples that illustrate how dependency 
rules can be written to define different types of 
linguistic relations. 
 
1. Verb-subject dependency 
The following rule defines a verb-subject 
dependency relation between 2 words 
aldarrikatu (claimed) and abokatuak   (lawyer) 
of the sentence in the previous example:  
  
 MAP (&NCSUBJ>) TARGET (NOUN)  
   IF (0 (ERG) + (@SUBJ) +(%FIN_NCH)) 
      (*1(@-FMAINV) + (%INIT_VCH)  
       BARRIER (PUNCT_PUNCT)); 
 
The rule assigned the ncsubj tag to the noun 
abokatuak (lawyer) if the following conditions 
are satisfied: a) the noun is declined in ergative 
case; besides, it has assigned the @SUBJ 
syntactic function and, it is the last word of a 
noun chain; b) it has a non-finite main verb 
everywhere on its right before the punctuation 
mark. 
                                                
2 nc: non-clausal complement or modifier 
3 cc:clausal complement 
4 cm: clausal modifier 
 
2. Subordinate clause dependency 
The following rule defines a complement 
subordinate clause dependency relation 
between a subordinate verb and a main verb. 
We illustrate this rule by means of an example 
in which the word egoten (usually stayed) is 
the verb of the complement subordinate clause 
linked to esan (told): 
 
Example: Lehenago aitona egoten zela ni 
EGOTEN naizen tokian esan dit amonak5. 
 
 MAP(&CCOMP>>)TARGET (V)  
 IF(0(@-FMAINV)+ (%INIT_VCH)) 
(1(@+FAUXV_SUB)+ (%FIN_VCH)); 
 
The rule assigned the CCOMP tag to the 
verb egoten  (usually stayed) if the following 
conditions are satisfied: a) the verb is a non-
finite main verb and, it?s the first word-form of 
a verb chain; b) it has an auxiliary verb on its 
immediate right-side which has assigned the 
complement tag and appears as the last part of 
the verb chain.  
 
3. Infinitive control 
The following rule defines that in the 
sentence Jonek Miren etortzea nahi du. (John 
wants to come Mary), etortzea (infinitive 
subordinate clause with object function, "to 
come") is controled by the main verb nahi  ("to 
want"). Taking into account, that etortzea  is 
the controlled object of nahi, if there is another 
non-infinitive object Miren; then we will 
assign to it the subject dependency relation to 
the infinitive verb ("to come").   
  
                                               
5 My grandmother told me my grandfather 
usually stayed  where I am now 
epaiketan Defentsako abokatuak desobedientzia  zibilerako eskubidea aldarrikatu du 
Fig.4. Dependency tree 
 MAP (&NCSUBJ>) TARGET (NOUN)  
IF (0 (ABS) + (@SUBJ) OR (@OBJ)  + (%NCH))  
    (1(@-FMAINV_SUB_@OBJ) ) (2 VTRANS_ -FV )); 
  
4.3 Evaluation 
The system has been manually tested on a 
corpus of newspaper articles (included in 
Eus3LB), containing 302 sentences (3266 
words).  
We have evaluated the precision (correctly 
selected dependent / number of dependant 
returned) and the recall (correctly selected 
dependent / actual dependent in the sentence) 
of the subject (including coordinated subjects), 
and modifier dependency of verbs. For subject, 
precision and recall were respectively 67% and  
69 %, while the figures for verb modifiers were 
73 % and   95%. 
We have detected two main  reasons for 
explaining these figures: 1) the analysis 
strategy is limited because we cannot make use 
of semantic or contextual information for 
resolving uncertainties at an early level; 2) 
errors in previous steps. These errors can be a) 
due either to an incorrect assignment of POS to 
word-forms or to the syncretism of case marks 
(@SUBJ, @OBJ); b) the presence of non-
known word-forms that increases the number 
of possible analysis. At this moment, the head 
and dependent slot fillers are, in all cases, the 
base forms of single head words, so for 
example, ?multi-component? heads, such as 
names, are reduced to a single word; thus the 
slot filler corresponding to Xabier Arzallus 
would be Arzallus.  
5 Conclusions 
We have presented the application of the 
dependency grammar parser for the processing 
of Basque, which can serve as a representative 
of agglutinative languages with free order of 
constituents.  
We have shown how dependency grammar 
approach provides a good solution for deeper 
syntactic analysis, being at this moment the 
best alternative for morphologically complex 
languages.  
We have also evaluated the application of 
the grammar to corpus, measuring the linking 
of the verb with its dependents, with 
satisfactory results. However, the development 
of a full dependency syntactic analyser is still a 
matter of research.  For instance, all kinds of 
constructions without a clear syntactic head are 
difficult to analyse: ellipses, sentences without 
a verb (e.g., copula -less predicative), and 
coordination. All these aspects have been 
treated in our manually annotated Corpus; our 
efforts now are oriented to deal with them 
automatically. 
 
6 Acnowledgments  
This research is supported by the University 
of the Basque Country (9/UPV00141.226-
14601/2002), the Ministry of Industry of the 
Basque Government (project XUXENG, 
OD02UN52). 
References  
Abney S. P. 1997. Part-of-speech tagging and 
partial parsing. S. Young and G. Bloothooft, 
editors,  Corpus -Based Methods in Language 
and Speech Processing, Kluwer, Dordrecht. 
Aduriz I., Aranzabe M.J., Arriola J.M.,  D?az 
de Ilarraza A., Gojenola K., Oronoz M., Ur?a 
L. 2004. A Cascaded Syntactic Analyser for 
Basque. In Gelbukh, A (ed.) Computational 
Linguistics and Intelligent Text Processing. 
SpringerLNCS 2945.  
Aduriz I., Aranzabe M.J., Arriola J.M., Atutxa 
A., D?az de Ilarraza A., Garmendia A., 
Oronoz M. 2003. Construction of a Basque 
Dependency Treebank. Proceedings of the 
Second Workshop on Treebanks and 
Linguistic Theories "TLT 2003", (J. Nivre 
and E. Hinrichs eds.), V?xj? University 
Press. V ?xj?, Suecia   
Aduriz I., Arriola J.M., Artola X., Diaz de 
Illarraza A., Gojenola K., Maritxalar M. 
2000. Euskararako Murriztapen Gramatika: 
mapaketak, erregela morfosintaktikoak eta 
sintaktikoak. UPV/EHU/LSI/TR 12-2000.  
Alegria I., Artola X., Sarasola K., Urkia M. 
1996. Automatic morphological analysis of 
Basque. Literary & Linguistic Computing 
Vol. 11, No. 4, 193-203. Oxford University 
Press. Oxford. 
 B?mov? , A., Haji?c, J., Hajicov?a, E., 
Hladk?a, B. 2003. The Prague 
DependencyTreebank: A Three level 
Annotation Scenario. In Abeill? (ed.) 
Treebanks Building and Using Parsed 
Corpora, Book Series: TEXT, SPEECH 
AND LANGUAGE TECHNOLOGY : 
Volume 20 Kluwer Academic Publisher, 
Dordrecht. 
Brants T., Skut W. & Uszkoreit H. 2003 
"Syntactic Annotation of a German Newspa-  
per Corpus?. In Abeill? (ed.) Treebanks 
Building and Using Parsed Corpora, Book 
Series: TEXT, SPEECH AND LANGUAGE 
TECHNOLOGY : Volume 20 Kluwer 
Academic Publisher, Dordrecht. 
Carroll J., Briscoe E., Sanfilippo A. 1998. 
Parser evaluation: a survey and a new 
proposal. Proceedings of the 1st 
International Conference on Language 
Resources and Evaluation, 447-454. 
Granada, Spain.  
Carroll J., Minnen G., Briscoe T. 1999. Corpus 
Annotation for Parser Evaluation. 
Proceedings of Workshop on Linguistically 
Interpretated Corpora, EACL?99. Bergen. 
Civit M. & Mart? M. 2002. Design Principles 
for a Spanish Treebank. Proceedings of The 
Treebank and Linguistic Theories 
(TLT2002). Sozopol, Bulgaria. 
Hays, D. 1964. Dependency theory: a 
formalism and some observations. 
Language40, p. 511?525. 
Hajic J. 1998. Building a Syntactically 
Annotated Corpus: The Prague Dependency 
Treebank. In  Issues of Valency and 
Meaning, 106-132. Karolinum, Praha. 
Hudson, R. 1984. Word Grammar. Oxford, 
England: Basil Blackwell PublishersLimited. 
J?rvinen T. and Tapanainen P, 1998. Towards 
an implementable dependency grammar. In 
Proceedings of the Workshop "Processing of 
Dependency-Based Grammars", (eds.) 
Sylvain Kahane and Alain Polgu?re, 
Universit? de Montr?al, Quebec, Canada, 
15th August 1998, pp. 1-10. 
Karlsson F., Voutilainen A., Heikkila J., 
Anttila A. 1995. Constraint Grammar: a 
Language-Independent System for Parsing 
Unrestricted Text. Mouton de Gruyter. 
Koskenniemi K 1983. Two-level Morphology: 
A general Computational Model for Word-
Form Recognition and Production. 
University of Helsinki, Department of 
General Linguistics. Publications 11.  
Laka, I. 1998. A Brief Grammar of Euskara, 
the Basque Language. HTML document. 
http://www.ehu.es/grammar. Office of the 
Vice-Dean for the Basque Language. 
University of the Basque Country. 
Lin D. 1998. A Dependency-based Method for 
Evaluating Broad-Coverage Parsers. Natural 
Language Engineering.  
Lin D. 2003. "Dependency-based evaluation of 
MINIPAR" in Building and Using 
syntactically annotated corpora, Abeill?, A. 
Ed. Kluwer, Dordrecht 
Mel?cuk, I. A. 1987. Dependency syntax: 
theory and practice. Albany: StateUniversity 
of New York Press. 
Oflazer K. 2003. Dependency Parsing with an 
Extended Finite-State Approach. ACL 
Journal of Computational Linguistics, Vol. 
29, n?4. 
Skut W., Krenn B., Brants T., Uszkoreit H. 
1997. An Annotation Scheme for Free Word 
Order Languages. In Proceedings of the 
Fifth Conference on Applied Natural 
Language Processing (ANLP-97). 
Washington, DC, USA. 
Tapanainen P. and Voutilainen A. 1994 
Tagging Accurately-Don?t guess if you know. 
In Proceedings of the 4th Conference on  
Applied Natural Language Processing, 
Washington. 
Voutilainen A., Heikkil? J. and Anttila A. 
1992. Constraint Grammar of English. A 
Performance-Oriented Introduction. 
Publications of Department of General 
Linguistics, University of Helsinki, No. 21, 
Helsinki. 
 
