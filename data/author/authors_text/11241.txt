Annotating information structures in Chinese texts using HowNet 
GAN Kok Wee 
Department of Computer Science, 
Hong Kong University of Science and 
Technology, Clear Water Bay, 
Kowloon, Hong Kong. 
gankw@ cs.nst.hk 
WONG Ping Wai 
Department of Computer Science, 
Hong Kong University of Science and 
Technology, Clear Water Bay, 
Kowloon, Hong Kong. 
wongpw @ cs.ust.hk 
Abstract 
This paper reported our work on 
annotating Chinese texts with 
information structures derived from 
HowNet. An information structure 
consists of two components: HowNet 
definitions and dependency relations. It 
is the unit of representation of the 
meaning of texts. This work is part of a 
multi-sentential approach to Chinese 
text understanding. An overview of 
HowNet and information structure are 
described in this paper. 
1 Introduction 
Corpora are essential resources to any research 
in language ngineering. For Chinese, efforts in 
building large corpora started in the 90s. For 
instance, the PH corpus of 4 million Chinese 
characters with word boundary information was 
released in 1993 (Guo, 1993). The first version 
of the Sinica corpus of two millions words 
marked with word boundaries and parts-of- 
speech was released in 1995 (CKIP, 1995). In 
1996, a small corpus of 5266 distinct words 
(inclusive of punctuation marks) with a total 
occurrence frequency of 51870 was released (Yu 
et al, 1996). This corpus was derived from the 
Singapore Primary School Chinese Language 
Textbooks. It contained information on word 
boundaries, parts-of-speech and also syntactic 
structures. In 2000, two additional bracketed 
corpora have just been announced. The first one, 
the Chinese Penn Treebank, includes 100- 
thousand words (Xia et al, 2000). The second 
one, the Sinica Treebank, which is derived from 
the Sinica corpus, contains 38,725 sentences 
with 1000 of them released to the public 1 (CKIP, 
2000). 
The historical development of Chinese corpus 
construction has shown a consensus in 
incorporating more powerful linguistic 
structures into corpora. As noted by Marcus 
(1997), the more powerful inguistic structures 
will help in improving the accuracy of parsing. 
This is especially true to isolating language such 
as Chinese. However, there is very little work on 
annotating corpora with semantic information. 
To the best of our knowledge, there is only one 
report of this kind. The work by Lua 2 annotated 
340,000 words with semantic lass information 
as defined in a thesaurus of synonyms (Mei, 
1983). With the release of HowNet 3, a bilingual 
general knowledge base, Gan and Tham (1999) 
reported the first corpus of 30,000 words that 
was annotated with the general knowledge 
structure defined in HowNet. This paper 
reported an extension of the work in &an and 
Tham (1999) on the annotation of information 
structures in Chinese texts. In Section 2, an 
overview of HowNet is provided. Information 
structure and an illustration will be given in 
Section 3. 
2 An Overview of HowNet 
HowNet is a bilingual general knowledge-base 
describing relations between concepts and 
relations between the attributes of concepts. The 
latest version covers over 65,000 concepts in 
1 
http://godel.iis.sinica.edu.tw/CKIP/treesl000.htm 
z http://www.cslp.com.nus.edu/sg/cslp/ 
3 http://www.HowNet.com (Dong Zhendong, Dong 
Qiang; HowNet) 
85 
Chinese and close to 75,000 English equivalents. 
The relations include hyponymy, synonymy, 
antonymy, meronymy, attribute-host, material- 
product, converse, dynamic role and concept 
cooccurrence. The philosophy behind the design 
of HowNet is ' i ts ontological view that all 
physical and non-physical matters undergo a 
continual process of motion and change in a 
specific space and time. The motion and change 
are usually reflected by a change in state that in 
turn, is manifested by a change in value of some 
attributes. The top-most level of classification i  
HowNet thus includes: entity, event, attribute 
and attribute value. It is important o point out 
that the classification is derived in a bottom-up 
manner. First, a set of sememes, the most basic 
set of semantic units that are non-decomposable, 
is extracted from about 6,000 Chinese characters. 
This is feasible because ach Chinese character 
is monosyllabic and they are meaning-bearing. 
Similar sememes are grouped. The coverage of 
the set of sememes i tested against polysyllabic 
concepts to identify additional sememes. 
Eventually, a total of over 1,400 sememes are 
found and they are organized hierarchically. 
This is a closed set from which all concepts are 
defined. The bottom-up approach takes 
advantage of the fact that all concepts, either 
current or new, can be expressed using a 
combination of one or more existing Chinese 
characters. It is yet to f'md a new concept hat 
has to resort to the creation of a new Chinese 
character. Therefore, by deriving the set of 
sememes in a bottom-up fashion, it is believed 
that the set of sememes is stable and robust 
enough to describe all kinds of concepts, 
whether current or new. The fact that HowNet 
has verified this thesis over 65,000 concepts is a 
good proof of its robustness. 
2.1 Types of Relation 
The definition of a concept in HowNet expresses 
one or more of the following relations. 
2.1.1 Dynamic Role 
There are a total of 71 dynamic roles defined in 
HowNet. Dynamic role resembles case role in 
case grammar (Fillmore, 1968). However, it 
differs from case role in that it is concerned with 
all probable actants of an event and the roles 
they play in the event. The issue of whether 
these actants can be realized grammatically is
not its concern. For example, 
Concept(l): IJ~g~ (be a vegetarian for 
religious reasons) 
DEF=eatlI~, pat ient=vegetablel~,  
religionl~J~ 
At the syntactic level, "1~"  is an intransitive 
verb. According to case grammar, it has only 
one case role: agent. However, for this word, the 
patient is self-contained in its constituent (i.e. 
"~"  ). HowNet specifies this explicitly and 
indicates the category ('vegetable'4) of 
prototypical concepts which fills up this role. 
Another distinguishing feature of dynamic role 
is its use in defining concepts of 'entity" class. 
Concept(2): ~\[!~ (writing brush) 
DEF=Penlnkl~l~, *writel~ 
Through the use of the "*" pointer, the above 
definition states that the concept being defined 
(~!~)  is the instrument of the event type 
"write'. 
HowNet alo uses dynamic role to specify the 
attributes that a concept contains. For example, 
Concept(3): ~ : ~  (arise suddenly) 
DEF=happenl~Z~ :, manner=suddenly 
The definition of concept (3) specifies that the 
manner of the event is 'sudden'. 
2.L2 Hyponymy Relation 
The 'event' and 'entity' classes in HowNet are 
organized in a hierarchical manner. The parent 
class is a hypernym of its children classes. 
Details of the organization are available from the 
HowNet site and are therefore omitted here. 
2.1.3 Meronymy Relation 
Meronymy relation is expressed through the 
4 We use single-quote and italic to mark sememes 
in HowNet. 
86 
pointer "%" . For example, 
Concept (4): ~ . ~  (CPU) 
DEF=par t l~ ,  %computerl~J~, heartl,~, 
The class of the-concept " t~5~:~"  is 
'part'. It is a part of the class 'computer'. The 
function of the part " t : l~S I~"  is the 
'heart' of the whole 'computer'. 
2.1.4 Material.Product Relation 
Material-product relation is expressed through 
the pointer "?" . For example, 
Concept (5): ~ ,~ (knitting wool) 
DEF=matefialltf~t, ?c lo th ing l~ 
"~,~"  belongs to the class 'material'. It is a 
material for the product 'clothing'. 
2.1.5 Attribute-Host Relation 
Attribute-host relation is expressed by the 
pointer "&" . For example, 
Concept (6): ~--~ (face) 
DEF=attributelJ~, reputat ion l~,  
&humanl),., &organizationl~\]~,~ 
"~:-~:" is an attribute; in particular, it is about 
the attribute 'reputation'. The hosts could be 
'human' as well as 'organization'. 
2.1.6 Concept Co-occurrence Relation 
Some concept typically co-occurs with certain 
concept. For example, 
Concept (7): ~ : ~  (lawless person) 
DEF=humanl)~., fiercely, efimel~l~, 
#policel~, undesiredl~ 
The typical context where the concept "~-~ 
~t~"  is used involves the concept 'police'. 
This type of relation is expressed by the pointer 
3 Information Structures 
Dong (2000) uses the example "~_~l~: .~ 
\ [ \ ]  " (Narcotic drugs smuggling group) to 
illustrate what information structure is. 
Describing the structure of this phrase at the 
syntactic level, such as the analysis of Penn 
Treebank (Xue, 1999: 72-77), only reveals that it 
is a noun phrase with the head of "~.~\[\]" 
modified by a relative clause "~_~.h"  
which involves operator movement. At the 
semantic level of description, we would indicate 
that "~\ [ \ ] "  (group) is the agent of the event 
"~_~.L" (smuggle) and "~"  (Narcotic 
drugs) is the pat/ent of "~_~" (smuggle). 
The informaton structure of this example 
consists of two parts, the dependency relations 
and the HowNet definitions. The descriptions 
are as follows: 
Dependency ~ \[patient\] <--:~_~--\[agent\] ~\ [ \ ]  
relations: 
Definitions: ~:  medicinel~:jqe~J, ?addictivel~ 
~.L :  transportl~l_I~, manner= 
secretly, crimel~l~ 
~\[\]: communityl\[\]~ 
In this example, the descriptions specify that a 
'community" is an agent involved in a 
'transport' event transporting the patient 
"medicine'. Furthermore, the 'transport" event is 
a 'crime' and the manner is 'secret'. The 
'medicine' is a material of 'addictive' products. 
The arrow between two concepts is a 
dependency onnection with the concept pointed 
to by the arrow denoting the dependent and the 
concept at the other end as the governor. The 
name of the dependency relation is enclosed in a 
square bracket and it could appear at either the 
dependent orthe governor side. 
Currently, over 60 types of information structure 
have been defined. The pattern of information 
structure is specified in the following format: 
(sememe) \[DRel\] ~ \[DRel\] (sememe), where 
DRel means the name of a dependency relation. 
For the dependency relation to apply, the 
governor and the dependent must satisfy the 
requirement of the sememes. Table 1 shows a 
87 
subset of the information structures. Information 
structures are derived in a bottom-up fashion 
from analysing the mechanisms used in the 
composition of words. This approach is based on 
the insight that mechanisms used in word 
formation are also applicable to phrase and 
sentence construction i Chinese. For example, 
the type "(l l  ltime) 
levent) " applies to the formation of the 
following units at various levels of linguistic 
structure: 
word 
level: 
phrase 
level: 
sentence 
level: 
"ZF:.~--~I~" (afternoon nap) 
"~\ ] '~- '~W" (summer study) 
" :~  ~ <- ~ ~ ~ ~"  (long-time 
shortage of commodities) 
"1999~ 12 ~ 9 \[\] ~ \ ]  \ [ \ ]  <-'-~ ~3~ 
~"  (leaking occurs on Thursday, 
December 9, 1999) 
In the process of annotating the corpus, the 
coverage of information structure types at the 
phrase and sentence levels was evaluated and 
missing types are added. The new types arise 
mainly due to function words. For example, the 
type "(modalityl ~ ~)  \[modalityl ~ ~ \] <-- 
(~'f~:levent)" is due to the use of function 
words such as "~j~," (must) and "~-~"  
(must). These are words expressing the attitude 
of the speaker of an utterance towards an event. 
3.1 An example 
We annotated a subset of the Sinica corpus 
(version 3.0) of 30,000 words with information 
structures. The corpus includes 103 newspaper 
texts covering the crime domain. The annotation 
has been completed and is currently under 
verification. We expect to release the corpus and 
the annotation guideline at the end of this year. 
An example of our annotation is shown below 
and its information structures are shown in 
Figure 1 at the end of this paper. The difference 
between this work and the work reported in Gan 
and Tham (1999) lies in the addition of the 
dependency relations into the annotation. 
(1) "~-~ ~ ~f~ ~-~-~j 
Tainan county Xinhua police branch 
criminal group junior captain 
Lin Wenzheng yesterday afternoon 
raise gun suicide after, 
"After Lin Wenzbeng, a junior captain 
with the Criminal Investigation Depathuent 
of the Xinhua police branch of Tainan 
county, committed suicide by shooting 
himself yesterday afternoon," 
The hierarchical structure in Figure 1 is another 
way to represent the relation between governor 
and dependent, as illustrated in Figure 2. C1 
immediately dominates C2, indicating that C1 is 
the governor and C2 the dependent. The relation 
between them is either R1 or R2. R1 is located 
at the same level as C 1 and R2 is located at the 
same level as C2. These two possibilities could 
also be represented linearly as shown in (2). 
Conceptcl RelationR2Rl Concept\[c2 
Figure 2: Relations between concepts 
(2) Cl \[RI\] ---~ JR2\[ C2 
R2 between the two concepts C1 and C2 should 
be read as "C2 is the R2 of CI" . For example, 
"T~=" (afternoon) is the .//me of "~"  
(raise). R1 between C1 and C2 should be 
interpreted as "C1 is the RI of C2" . For 
example, the "time" between "~" (after) 
and "~\ ]~"  (suicide) should be interpreted 
as "'~t" is the t/me of "~ I~"  
The HowNet definitions of the concepts in (1) 
are provided in Table 2: 
s A str ing of Chinese characters ending with a 
punctuation nmrk is regarded as a uni t  for 
in format ion structure annotatioIL 
88 
Table 2: An example of HowNet definitions 
Concept Definition 
p lace l J~ ,  cityl~, ProperNamel~\[, 
(ChinaJq W) 
placelJ~l~ 
placel:l~f~, ProperNamel~\[, (Taiwanl 
institutionl~, policel~, branchl3~ 
partl~l~J~:, %inst i tut ion l~,  policel 
aValuel ~ ~ ~f~, importancel ~ ~,  
seeondaryl~2~Z 
humanl),,, #occuputionll~., officiall 
humanl),,, ProperNamel~ 
timell~\[hq, pasti l ,  dayl El 
timeliest, aftemoonl~F: 
li~tl~-~- 
weapon l~,  * f i r ing l~ 
su ic ide l \ [~  
timel\[!.~, futurel~ 
{puncl?~} 
The structures inFigure 1 and Table 2 reveal the 
following information: 
(a) example (1) is about the time after a 
'suicide" event; 
(b) preceding the 'suicide' event is the event 
' raise'; 
(c) the time of the 'raise' event is "1~'I~"1 r 
q=" , the agent is " ;~k3~"  and the 
patient is a "weapon'; 
(d) the 'occupation' of "@~J~"  i s  "1~ 
:\]~" which is an "official' of "secondary' 
importance and ";~hk3~J~" belongs to the 
'institution' "-~-,~-~-~lJ~l:~\[" ; 
(e) the location of the 'institution' "~-~J-~qJ 
~"  is at "~'~g~Jr~J6" 
This kind of representation e ables a computer 
to analyse texts at a deeper level of 
understanding. As an English and Chinese 
bilingual eornmon-sense knowledge system, 
HowNet can contribute much to better text 
understanding and machine translation (Dong 
1999). 
4 Conclusion 
The work reported here constitutes part of our 
efforts to develop a new strategy for Chinese 
text understanding. The strategy was proposed 
by Dong (1999). It starts with tagging each 
concept with the most probable HowNet 
def'mitions. The second step is to determine the 
information structures as described in this paper. 
The last step is to recover the implicit 
information structures from the surface 
information structures based on two additional 
knowledge sources: (i) relations between the 
event ypes as defined in HowNet; and (ii) rules 
governing the interplay of dynamic roles 
between event ypes. For example, the "suicide" 
event in example (1) does not mention its agent 
directly. The means of committing 'suicide' by 
'firing' is also implicit. The recovery of this 
information will be the main issues to be 
resolved at the final stage. In parallel with our 
annotation effort, we are also working on 
developing automatic algorithms for the 
disambiguation of HowNet definitions and the 
identification of information structures. The 
creation of the two additional knowledge bases 
will be our future plan. 
Acknowledgements 
This work was supported by the Hong Kong 
Research Grant Council. We would also like to 
thank Dong Zhendong. Without his advice, this 
work would not be possible. 
References 
CKIP (1995) L~7.~;Sr~'/~-~\[~fT~.~/:~;r.-~'~.~ 
a~, ~.6t~95.02  \[Technical Report no. 95--02, 
the content and illustration of Sinica corpus of 
Academia Sinica\]. lmtitue of Information Science, 
Academia Siniea. 
Dong, Zhendong (1999) Bigger Context and Better 
Understanding - Expectation on Future MT 
Technology. In "Proceedings of Intenational 
Conference on Machine Translation & Computer 
Language Information Processing", 26-28 June 
1999, Beijing, China, pp. 17-25. 
Dong Zhendong (2000) z~r~'~.~#j~.~ \[The 
pattern of Chinese information structure\], ms. 
Fillmore C. J. (1968) The case for case. In 
"Universals in Linguistic Theory", E. Bach, R. 
Harms, eds., New York, Holt, Rinehart and 
Winston. 
89 
Gan, Kok-Wee and Wai-Mun Tham (1999) ~ '~ 
~ ; ~ . ~ m ~ "  \[General Knowledge 
Annotation Based on HowNet\], Computational 
Linguistics and Chinese Language Processing, vol. 
4, 2, pp. 39-86. 
Guo, Jin (1993) PH: A Chinese corpus. 
Communications ofCOLIPS, 3/1, pp. 45-48. 
Marcus, Mitch (1997) Invited speech at the 5th 
Workshop on Very Large Corpora. 
Mei, Jiaju, Yiming Lan, Yunqi Gao, Yongxiang Ying 
(1983) /~-J~n~-J40~ \[A Dictionary of Synonyms\], 
Shanghai Cishu Chnbanshe. 
Xia, Fei, Martha Palmer, Nianwen Xue, Mary Ellen 
Okurowski, John Kovarik, Fu-Dong Chiou, Shizhe 
Huang, Tony Kroch and Mitch Marcus (2000) 
Developing Guidelines and Ensuring Consistency 
for Chinese Text Annotation. In "Proceedings of 
the second International Conference on Language 
Resources and Evaluation" (LREC-2000), Athens, 
Greece. 
Xue, Nianwen, Fei Xia, Shizhe Huang, Anthony 
Kroch (1999) The Bracketing Guidelines for the 
Penn Chinese Treebank (Draft II), 
http://www.upenn.edu/cth/. 
Yu, Shiwen, Qiang Zhou, Wei Zhang, Yunyun Zhang, 
Weidong Zhan, Baobao Chang, Zhifang Sui (1996) 
Word segmented and POS tagged 12 volumes of 
Singapore Chinese primary school text. 
Communications ofCOLIPS, 6(1), pp. 41. 
90 
21 
~l ,n l  
o 
ao  
p~ 
u 
| 
91 
~J 
0 
~o 
0 
.~ 
.11 
q~ 
c~ 
"0  
0 
c~ 
~.) 
Q 
H~ 
Q 
"0  
0 
92 
A Maximum Entropy Approach to HowNet-Based 
Chinese Word Sense Disambiguation 
 
WONG Ping Wai 
Intendi Inc., 
Clear Water Bay, Hong Kong. 
wongpw@intendi.com 
YANG Yongsheng 
Department of Computer Science, 
HKUST, Clear Water Bay, Hong Kong. 
ysyang@cs.ust.hk 
 
Abstract 
This paper presents a maximum entropy 
method for the disambiguation of word 
senses as defined in HowNet. With the 
release of this bilingual (Chinese and 
English) knowledge base in 1999, a corpus 
of 30,000 words was sense tagged and 
released in January 2002. Concepts 
meanings in HowNet are constructed by a 
closed set of sememes, the smallest meaning 
units, which can be treated as semantic tags. 
The maximum entropy model treats 
semantic tags like parts-of-speech tags and 
achieves an overall accuracy of 89.39%, 
outperforming a baseline system, which 
picks the most frequent sense.  
1. Introduction 
A word usually has more than one meaning or 
sense, which are listed in the dictionary. The task 
of Word Sense Disambiguation (WSD) is to make 
the choice between the senses for a particular 
usage of the word in context. There are, however, 
several difficulties to WSD (Yang et al 2000): (i) 
The evaluation of word sense disambiguation 
system is not yet standardized. (ii) The potential 
for WSD varies by task. (iii) Sense-tagged corpora 
are crucial resources for WSD but they are 
difficult to obtain. Efforts in building large 
Chinese corpora started in the 90s, for example, 
the Sinica corpus (CKIP, 1995) and the Chinese 
Penn Tree Bank (Xia et al, 2000). However, these 
two corpora concentrate on the tagging of 
parts-of-speech and syntactic structures, while 
little work has been done on semantic annotation. 
Of the few efforts that were carried out, Lua1 
annotated 340,000 words with semantic classes 
defined in a thesaurus (Mei, 1983). This resource, 
however, was not publicly accessible. With the 
release of HowNet (Dong, 1999; Dong, 2000) in 
                                                   
1
 http://www.cslp.com.nus.edu/sg/cslp/ 
1999, Gan and Tham (1999) manually annotated a 
Chinese corpus of 30,000 words with the senses 
from HowNet. The corpus is a subset of the Sinica 
balanced corpus, and consists of 103 narratives on 
news stories, in which the words have already 
been segmented and tagged with parts-of-speech. 
Gan and Tham (1999) added sense tagging and 
subsequently Gan and Wong (2000) annotated the 
corpus with semantic dependency relations as 
defined in HowNet. The corpus was released to the 
public in January 2002 2 , providing essential 
resources for Chinese word sense disambiguation.  
This paper is organized as follows: Section 2 gives 
an introduction of HowNet. Section 3 describes the 
WSD task and the experiment results. Section 4 
describes the previous work, followed by a 
conclusion in Section 5. 
2. An Introduction to HowNet 
HowNet is a bilingual general knowledge base that 
encodes inter-concept semantic relations and the 
inter-attribute semantic relations. In contrast to 
WordNet (Miller, 1990), HowNet adopts a 
constructive approach of meaning representation 
(Miller, 1993). Basic meaning units called 
sememes, which cannot be decomposed further, 
combine to construct concepts in HowNet. So far, 
there are 65,000 Chinese concepts and 75,000 
English equivalents defined with a set of 1503 
sememes.  
NO.=the record number of the lexical entries 
W_X=concept of the language X 
E_X=example of W_X 
G_X=Part-of-speech of the W_X 
DEF=Definition, which is constructed by sememes and 
pointers 
Figure 1: A sample lexical entry in HowNet. 
 
Figure 1 gives an idea of how word concepts are 
organized in HowNet. ?X? represents some 
                                                   
2
 http://godel.iis.sinica.edu.tw/CKIP/hk/index.html 
language and each language has three specific 
items: W_X, E_X and G_X. The current version of 
HowNet has entries in two languages (Chinese and 
English) with the possibility of extending it to 
other languages. Therefore, W_C, E_C and G_C 
would be entries for the words, the examples and 
the parts-of-speech respectively in Chinese, 
whereas W_E, E_E and G_E are the corresponding 
entries for English.  
NO.=040263 
W_C=
 
 
G_C=N 
E_C= 
W_E=journalist 
G_E=N 
E_E= 
DEF=human|  ,#occupation|  ,*gather|  , 
*compile| 	
 ,#news|   
Figure 2: An example entry in HowNet. 
Figure 2 shows an example word, ?journalist?, as 
entered in HowNet. As mentioned in Miller (1993), 
the definition of a common noun typically consists 
of (i) its immediate superordinate term and (ii) 
some distinguishing features. HowNet represents 
this with pointers3 and the order of the sememes 
in concept definitions. In the example above, the 
sememe appearing in the first position ?human| ? 
is called the categorical attribute. It names the 
hypernym or the superordinate term, which gives a 
general classification of the concept. The sememes 
appearing in other positions: ?occupation|  ?, 
?gather|  ?, ?compile|  ?, ?news|  ? are 
additional attributes, which provide more 
specific, distinguishing features. Two types of 
pointers are used in this concept. The pointer ?#? 
means ?related? and thus ?#occupation| Description of the HKU Chinese Word Segmentation System 
for Sighan Bakeoff 2005 
Guohong Fu 
Department of Linguistics 
The University of Hong Kong
Pokfulam Road, Hong Kong
ghfu@hkucc.hku.hk
Kang-Kwong Luke 
Department of Linguistics 
The University of Hong Kong
Pokfulam Road, Hong Kong
kkluke@hkusua.hku.hk
Percy Ping-Wai WONG  
Department of Linguistics 
The University of Hong Kong
Pokfulam Road, Hong Kong
wongpw@hkusua.hku.hk
Abstract 
In this paper, we describe in brief our 
system for the Second International 
Chinese Word Segmentation Bakeoff 
sponsored by the ACL-SIGHAN. We 
participated in all tracks at the bakeoff. 
The evaluation results show our system 
can achieve an F measure of 0.940-
0.967 for different testing corpora. 
1 Introduction 
Word segmentation is very important for Chi-
nese text processing, which is aiming at recog-
nizing the implicit word boundaries in plain 
Chinese text. Over the past decades, great pro-
gress has been made with Chinese word 
segmentation technology. However, two 
difficulties still face us while developing a 
practical segmentation system for large open 
applications, i.e. the resolution of ambiguous 
segmentation and the identification of unknown 
or out-of-vocabulary (OOV) words. 
In order to resolve the above two problems, 
we developed a purely statistical Chinese word 
segmentation system using a two-stage strategy. 
We participated in eight tracks at the Second 
International Chinese Word Segmentation 
Bakeoff sponsored by the ACL-SIGHAN, and 
tested our system on different testing corpora. 
The scored results show that our system is effec-
tive for most of ambiguous segmentation and 
unknown words in Chinese text. In this paper, 
we make a summary of this work and give some 
analysis on the results. 
The rest of this paper is organized as follows: 
First in Section 2, we describe in brief a two-
stage strategy for Chinese word segmentation. 
Then in Section 3, we give details about the set-
tings or configuration of our system for different 
testing tracks, particularly the training data and 
the dictionaries used in our system. Finally, we 
report the results of our system at this bakeoff in 
Section 4, and give our conclusions on this work 
in Section 5. 
2 Overview of the System 
In practice, our system works in two major steps 
as follows: 
The first step is a process of known word 
segmentation, which aims to segment an input 
sequence of Chinese characters into a sequence 
of known words that are listed in the system dic-
tionary. In our current system, we apply a 
known word bigram model to perform this task 
(Fu and Luke, 2003; Fu and Luke, 2004; Fu and 
Luke, 2005).  
Actually, known word segmentation is a 
process of disambiguation. Given a Chinese 
character string 
ncccC L21= , there are usually 
multiple possible segmentations of known words 
mwwwW L21=  according to the system diction-
ary. The task of known word segmentation is to 
find a proper segmentation 
mwwwW L21? =  that 
maximizes the probability ?
=
?
m
i
ii wwP
1
1 )|( , i.e. 
?
=
?
?=
m
i
ii
WW
wwPCWPW
1
1 )|(maxarg)|(maxarg?  (1) 
The second step is actually a tagging task on 
the sequence of known words acquired in the 
first step, which intends to detect unknown 
165
words or out-of-vocabulary (OOV) words in the 
input. In this process, each known word yielded 
in the first step will be further assigned a proper 
tag that indicates whether the known word is an 
independent segmented word by itself or a be-
ginning/middle/ending component of an OOV 
word  (Fu and Luke, 2004). In order to improve 
our system, part-of-speech information is also 
introduced in some tracks such as the PKU open 
test and the AS open test. Furthermore, a 
lexicalized HMM tagger is developed to per-
form this task (Fu and Luke, 2004).  
Given a sequence of known words 
nwwwW L21= , the lexicalized HMM tagger 
attempt to find an appropriate sequence of tags 
ntttT L21? =  that maximizes the conditional prob-
ability )|( WTP , namely 
  
?
=
???
?
=
n
i
iiiiii
T
T
twtPtwwP
WTPT
1
111 ),|(),|(maxarg
)|(maxarg?
     (2) 
3 Settings for Different Tracks 
Table 1. Training corpora for different tracks 
Table 1 presents the corpora used to train our 
system for different tracks. In the Academia 
Sinica (AS) open test and the Peking University 
(PKU) open test, our system is trained respec-
tively using the Sinica Corpus (3.0) and the PFR 
Corpus. In all other tests, including all closed 
tests, City University of Hong Kong (CityU) 
open test and Microsoft Research (MSR) open 
test, we trained our system using the relevant 
training corpora provided for the bakeoff.  
Track Training Corpus Word 
counts
AS-O The Sinica Corpus 3.0  5,692,150
AS-C AS corpus for Bakeoff 2005 5,449,698
CityU-O CityU corpus for Bakeoff 2005 1,455,629
CityU-C CityU corpus for Bakeoff 2005 1,455,629
MSR-O MSR corpus for Bakeoff 2005 2,368,391
MSR-C MSR corpus for Bakeoff 2005 2,368,391
PKU-O The PFR Corpus  7,286,960
PKU-C PKU corpus for Bakeoff 2005 1,109,947
Table 2 shows all the dictionaries used in our 
system for different tracks.   
In the closed test, the system dictionaries are 
derived automatically from the relevant training 
corpora for this bakeoff by using the following 
three criteria: (1) Each character in the training 
corpus is taken as an independent entry and col-
lected into the relevant system dictionary. (2) A 
standard Chinese word in the training corpus 
will enter to the relevant dictionary if it has four 
or less Chinese characters within it, and at the 
same time, its counts of occurrence in the corpus 
is observed to be larger than a threshold. In our 
current system, the threshold is set to 10 for the 
AS closed test and 5 for other closed tests. (3) 
For non-standard Chinese words such as nu-
meral expressions, English words and punctua-
tions, if they consist of multiple characters, they 
will be not included in the system dictionary. 
As for the open test, some other dictionaries 
are applied. As can be seen from Table 2, the 
CKIP Lexicon and Chinese Grammar is used in 
both AS and CityU open test, and the Gram-
matical Knowledge-base of Contemporary Chi-
nese developed by the Peking University is 
utilized in both PKU and MSR open test.  
   
Track System dictionary # of 
entries
AS-O The CKIP Lexicon and Chinese Grammar 84K
AS-C Automatically extracted from AS 
corpus for Bakeoff 2005 30K
CityU-O
The CKIP Lexicon and Chinese 
Grammar (without part-of-
speech)
84K
CityU-C Automatically extracted from CityU corpus for Bakeoff 2005 22K
MSR-O 
The Grammatical Knowledge-
base of Contemporary Chinese
(without part-of-speech) 
65K
MSR-C Automatically extracted from MSR corpus for Bakeoff 2005 17K
PKU-O The Grammatical Knowledge-base of Contemporary Chinese 65K
PKU-C Automatically extracted from PKU corpus for Bakeoff 2005 17K
Table 2. System dictionaries for different tracks 
It should be noted that part-of-speech infor-
mation is also utilized in the AS open test and 
the PKU open test, because part-of-speech in-
formation proved to be informative in identify-
ing OOV words in Chinese text (Fu and Luke, 
2004). Therefore, the training corpora for the 
two tests are tagged with part-of-speech, and 
entries in the relevant dictionaries are defined 
with their potential part-of-speech categories.   
166
4 The Scored Results 
In Bakeoff 2005, six measures are employed to 
score the performance of a word segmentation 
system, namely recall (R), precision (P), the 
evenly-weighted F-measure (F), out-of-
vocabulary (OOV) rate for the test corpus, recall 
with respect to OOV words (ROOV) or in-
vocabulary words (Riv).  
In order to achieve a consistent evaluation of 
our system in both the closed test and the open 
test, OOV is defined in this paper as the set of 
words in the test corpus but not occurring in 
both the training corpus and the system diction-
ary. Furthermore, the additional two rates, i.e. 
OOV-C and OOV-D are used to denote the out-
of-vocabulary rate with respect to the training 
corpus and the out-of-vocabulary rate with 
respect to the system dictionary, respectively. At 
the same time, the precision with regard to in-
vocabulary words (Piv) and OOV words (POOV) 
are also computed in this paper to give a more 
complete evalution of our system in unknown 
word identification. 
Track OOV-C OOV-D OOV 
AS-O 0.043 0.096 0.039 
AS-C 0.043 0.096 0.043 
CityU-O 0.074 0.140 0.049 
CityU-C 0.074 0.127 0.074 
MSR-O 0.026 0.076 0.023 
MSR-C 0.026 0.087 0.026 
PKU-O 0.038 0.070 0.033 
PKU-C 0.058 0.091 0.058 
Table 3. OOV rates for different tracks 
Track F R P Riv Piv ROOV POOV
AS-O 0.946 0.955 0.938 0.972 0.947 0.532 0.660
AS-C 0.940 0.947 0.934 0.966 0.949 0.523 0.566
CityU-O 0.941 0.944 0.938 0.962 0.956 0.592 0.599
CityU-C 0.939 0.944 0.933 0.969 0.952 0.626 0.677
MSR-O 0.967 0.969 0.966 0.978 0.977 0.586 0.537
MSR-C 0.962 0.962 0.962 0.972 0.977 0.592 0.499
PKU-O 0.962 0.959 0.965 0.963 0.970 0.835 0.816
PKU-C 0.944 0.943 0.944 0.961 0.958 0.656 0.700
Table 4. Scores for different tracks 
The OOV rates and scores of our system are 
summarized respectively in Table 3 and Table 4. 
The results show that our system can achieve a 
F-measure of 0.940-0.967 for different testing 
corpora while the relevant OOV rates are from 
0.023 to 0.074.  
Although our system has achieved a promis-
ing performance, there is still much to be done 
to improve it. Firstly, our system is purely statis-
tics-based, it cannot yield correct segmentations 
for all non-standard words (NSWs) such as nu-
meral expressions and English strings in Chi-
nese text. Secondly, known word segmentation 
and unknown word identification are taken as 
two independent stages in our system. This 
strategy is obviously simple and more easily 
applicable (Fu and Luke, 2003). Although the 
known word bigram model can partly resolve 
this problem, it is not always effective for some 
complicated strings that contains a mixture of 
ambiguities and unknown words, such as ?31
? and the fragment ?? in the sen-
tence ?	
?.   
5 Conclusions 
This paper presents a two-stage statistical word 
segmentation system for Chinese. We partici-
pated in all testing tracks at the second Sighan 
bakeoff. The scored results show that our system 
can achieve a F-measure of 0.940-0.967 as a 
whole for different corpora. This indicates that 
the proposed system is effective for most am-
biguous segmentations and unknown words in 
Chinese test. For future work, we hope to im-
prove our system by incorporating some pattern 
rules to handle complicated ambiguous frag-
ments and non-standard words in Chinese text. 
References 
Guohong Fu, and Kang-Kwong Luke. 2003. A two-
stage statistical word segmentation system for 
Chinese. In: Proceedings of the 2nd SIGHAN 
Workshop on Chinese Language Processing, Sap-
poro, Japan, 156-159. 
Guohong Fu, and Kang-Kwong Luke. 2004. Chinese 
unknown word identification as known word tag-
ging. In: Proceedings of the Third IEEE Interna-
tional Conference on Machine Learning and 
Cybernetics (ICMLC 2004), Shanghai, China, 
2612-2617. 
Guohong Fu, and Kang-Kwong Luke. 2005. Chinese 
unknown word identification using class-based 
LM. Lecture Notes in Computer Science (IJCNLP 
2004), 3248: 704-713. 
167
