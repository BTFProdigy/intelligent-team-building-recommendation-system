Plan-Based Dialogue Management in a Physics Tutor 
Reva Freedman 
Learning Research and Development Center 
University of Pittsburgh 
Pittsburgh, PA 15260 
freedrk+@pitt, edu 
http://www.pitt, edu/~freedrk 
Abstract 
This paper describes an application of APE (the 
Atlas Planning Engine), an integrated planning and 
execution system at the heart of the Atlas dialogue 
management system. APE controls a mixed- 
initiative dialogue between a human user and a 
host system, where turns in the 'conversation' may 
include graphical actions and/or written text. APE 
has full unification and can handle arbitrarily 
nested discourse constructs, making it more 
powerful than dialogue managers based on finite- 
state machines. We illustrate this work by 
describing Atlas-Andes, an intelligent tutoring 
system built using APE with the Andes physics 
tutor as the host. 
1 Introduction 
The purpose of the Atlas project is to enlarge the 
scope of student interaction in an intelligent 
tutoring system (ITS) to include coherent 
conversational sequences, including both written 
text and GUI actions. A key component of Atlas 
is APE, the Atlas Planning Engine, a "just-in- 
time" planner specialized for easy construction 
and quick generation of hierarchically organized 
dialogues. APE is a domain- and task-independent 
system. Although to date we have used APE as a 
dialogue manager for intelligent tutoring systems, 
APE could also be used to manage other types of 
human-computer conversation, such as an advice- 
giving system or an interactive help system. 
Planning is an essential component of a 
dialogue-based ITS. Although there are many 
reasons for using natural anguage in an ITS, as 
soon as the student gives an unexpected response 
to a tutor question, the tutor needs to be able to 
This research was supported by NSF grant number 
9720359 to CIRCLE, the Center for Interdisciplinary 
Research on Constructive Learning Environments atthe 
University of Pittsburgh and Carnegie-Mellon 
University. 
plan in order to achieve its goals as well as 
respond appropriately to the student's tatement. 
Yet classical planning is inappropriate for 
dialogue generation precisely because it assumes 
an unchanging world. A more appropriate 
approach is the "practical reason" approach 
pioneered by Bratman (1987, 1990). According to 
Bratman, human beings maintain plans and prefer 
to follow them, but they are also capable of 
changing the plans on the fly when needed. 
Bratman's approach has been introduced into 
computer science under the name of reactive 
planning (Georgeff and Ingrand 1989, Wilkins et 
al. 1995). 
In this paper we discuss the rationale for the use 
of reactive planning as well as the use of the 
hierarchical task network (HTN) style of plan 
operators. Then we describe APE (the Atlas 
Planning Engine), a dialogue planner we have 
implemented to embody the above concepts. We 
demonstrate he use of APE by showing how we 
have used it to add a dialogue capability to an 
existing ITS, the Andes physics tutor. By showing 
dialogues that Atlas-Andes can generate, we 
demonstrate the advantages of this architecture 
over the finite-state machine approach to dialogue 
management. 
2 Integrated planning and execution for 
dialogue generation 
2.1 'Practical reason' and the BDI model 
For an ITS, planning is required in order to ensure 
a coherent conversation as well as to accomplish 
tutorial goals. But it is impossible to plan a whole 
conversation in advance when the student can 
respond freely at every turn, just as human beings 
cannot plan their daily lives in advance because of 
possible changes in conditions. Classical planning 
algorithms are inappropriate because the tutor 
must be able to change plans based on the 
52 
student's responses. 
For this reason we have adopted the ideas of the 
philosopher Michael Bratman (1987, 1990). 
Bratman uses the term "practical reason" to 
describe his analysis since he is concerned with 
how to reason about practical matters. For human 
beings, planning is required in order to 
accomplish one's goals. Bratman's key insight is 
that human beings tend to follow a plan once they 
have one, although they are capable of dropping 
an intention or changing a partial plan when 
necessary. In other words, human beings do not 
decide what to do from scratch at each turn. 
Bratman and others who have adopted his 
approach use a tripartite mental model that 
includes beliefs, desires and intentions (Bratman, 
Israel and Pollack 1988, Pollack 1992, Georgeff 
et al 1998), hence the name "BDI model." 
Beliefs, which are uninstantiated plans in the 
speaker's head, are reified by the plan library. 
Desires are expressed as the agent's goals. 
Intentions, or plan steps that the agent has 
committed to but not yet acted on, are stored in an 
agenda. Thus the agent's partial plan for 
achieving a goal is a network of intentions. A plan 
can be left in a partially expanded state until it is 
necessary to refine it further. 
2.2 Implementation via reactive planning 
Bratman's approach has been elaborated in a 
computer science context by subsequent 
researchers (Bratman, Israel and Pollack 1988, 
Pollack 1992, Georgeff et al 1998). Reactive 
planning (Georgeff and Ingrand 1989, Wilkins et 
al. 1995), originally known as "integrated 
planning and execution," is one way of 
implementing Bratman's model. Originally 
developed for real-time control of the space 
shuttle, reactive planning has since been used in a 
variety of other domains. For the Atlas project we 
have developed a reactive planner called APE 
(Atlas Planning Engine) which uses these ideas to 
conduct a conversation. After each student 
response, the planner can choose to continue with 
its previous intention or change something in the 
plan to respond better to the student's utterance. 
Like most reactive planners, APE is a 
hierarchical task network (HTN) style planner 
(Yang 1990, Erol, Hendler and Nau 1994). 
Hierarchical decomposition asserts that each goal 
can be achieved via a series of subgoals instead of 
relying on means-end reasoning. Hierarchical 
decomposition is more appropriate to dialogue 
generation for a number of reasons. First, 
decomposition is better suited to the type of large- 
scale dialogue planning required in a real-world 
tutoring system, as it is easier to establish what a 
human speaker will say in a given situation than 
to be able to understand why in sufficient detail 
and generality to do means-end planning. Second, 
Hierarchical decomposition minimizes search 
time. Third, our dialogues are task-oriented and 
have a hierarchical structure (Grosz and Sidner 
1986). In such a case, matching the structure of 
the domain simplifies operator development 
because they can often be derived from transcripts 
of human tutoring sessions. The hierarchy 
information is also useful in determining 
appropriate referring expressions. Fourth, inter- 
leaved planning and execution is important for 
dialogue generation because we cannot predict he 
human user's future utterances. In an HTN-based 
system, it is straightforward to implement 
interleaved planning and execution because one 
only needs to expand the portion of the plan that 
is about to be executed. Finally, the conversation 
is in a certain sense the trace of the plan. In other 
words, we care much more about the actions 
generated by the planner than the states involved, 
whether implicitly or explicitly specified. 
Hierarchical decomposition provides this trace 
naturally. 
3 Background: the Andes physics tutor 
Andes (Gertner, Conati and VanLehn 1998) is an 
intelligent tutoring system in the domain of first- 
year college physics. Andes teaches via coached 
problem solving (VanLehn 1996). In coached 
problem solving, the tutoring system tracks the 
student as the latter attempts to solve a problem. 
If the student gets stuck or deviates too far from a 
correct solution path, the tutoring system provides 
hints and other assistance. 
A sample Andes problem is shown in mid- 
solution in Figure 1. A physics problem is given 
in the upper-left corner with a picture below it. 
Next to the picture the student has begun to 
sketch the vectors involved using the GUI buttons 
along the left-hand edge of the screen. As the 
53 
student draws vectors, Andes and the student 
cooperatively fill in the variable definitions in the 
upper-right corner. Later the student will use the 
space below to write equations connecting the 
variables. 
In this example, the elevator is decelerating, so 
the acceleration vector should face the opposite 
direction from the velocity vector. (If the 
acceleration vector went the same direction as the 
velocity vector, the speed of the elevator would 
increase and it would crash into the ground.) This 
is an important issue in beginning physics; it 
occurs in five Andes problems. 
When such errors occur, Andes turns the 
incorrect item red and provides hints to students 
in the lower-left corner of the screen. A sample of 
these hints, shown in the order a student would 
encounter them, is shown in Fig. 2. But hints are 
an output-only form of natural language; the 
student can't take the initiative or ask a question. 
In addition, there is no way for the system to ask 
the student a question or lead the student through 
a multi-step directed line of reasoning. Thus there 
is no way to use some of the effective rhetorical 
methods used by skilled human tutors, such as 
analogy and reductio ad absurdum. Current 
psychological research suggests that active 
methods, where students have to answer 
questions, will improve the performance of 
tutoring systems. 
4 Structure of the Atlas Planning Engine 
Figure3 shows a sample plan operator. For 
legibility, the key elements have been rendered in 
English instead of in Lisp. The hiercx slot 
provides a way for the planner to be aware of the 
context in which a decomposition is proposed. 
Items in the hiercx slot are instantiated and added 
to the transient database only so long as the 
operator which spawned them is in the agenda. 
To initiate a planning session, the user invokes 
the planner with an initial goal. The system 
searches the operator library to find all operators 
whose goal field matches the next goal on the 
agenda and whose filter conditions and precon- 
An elevator slows to a stop from an initial downward velocity 
of 10.0 m\]s in 2.00 seconds. A passenger in the elevator is 
holding a 3.00 kilogram package by a vertical string. 
What is the tension in the string during the process? 
i ........ ii ....... i i i  
. I ?Y 
~TO e',ev~o, at 10 m/s 
elev~or at a stop 
mass of p~:w'.,I,,~ 
magnitude of the inst~?~taneous Velocity of pack, age ~ {rkne TO v._w 
magnitude of the avelage Acceleratiorl of package ,dudng TO... a._x 
v_v 
a~ 
- - I  
pkg 
Figure I: Screen shot of the Andes physics tutor 
54 
S: (draws acceleration vector in same direction as velocity) 
T: Wrong. 
S: What's wrongwith that? 
T: Think about he direction of the acceleration vector. 
S: Please explain further. 
T: Remember that the direction of acceleration is the direction of the change in velocity. 
S: Please explain further. 
T: The'direction of the acceleration vector is straight up. 
S: (draws acceleration vector correctly) 
Figure 2: Andes hint sequence formatted as dialogue 
ditions are satisfied. Goals are represented in 
first-order logic without quantifiers and matched 
via unification. Since APE is intended especially 
for generation of hierarchically organized task- 
oriented iscourse, each operator has a multi-step 
recipe in the style of Wilkins (1988). When a 
match is found, the matching goal is removed 
from the agenda and is replaced by the steps in 
the recipe. APE has two kinds of primitive 
actions; one ends a turn and the other doesn't. 
From the point of view of discourse generation, 
the most important APE recipe items are those 
allowing the planner to change the agenda when 
necessary. These three types of recipe items make 
APE more powerful than a classical planner. 
? Fact: Evaluate a condition. If false, skip the 
rest of the recipe. Fact is used to allow run-time 
decision making by bypassing the rest of an 
operator when circumstances change during its 
execution. Fact can be used with retry-at to 
implement a loop just as in Prolog. 
? Retry-at. The purpose of retry-at is to allow 
the planner to back up to a choice point and make 
a new decision. It removes goals sequentially 
from the top of the agenda, a full operator at a 
time, until the supplied argument is false. Then it 
restores the parent goal of the last operator 
removed, so that further planning can choose a 
new way to achieve it. Retry-at implements a
Prolog-like choice of alternatives, but it differs 
from backtracking in that the new operator is 
chosen based on conditions that apply when the 
retry operation is executed, rather than on a list of 
possible operators formed when the original 
operator was chosen. For retry-at o be useful, the 
author must provide multiple operators for the 
same goal. Each operator must have a set of 
preconditions enabling it to be chosen at the 
appropriate ime. 
? Prune-replace: The intent of prune-replace is 
(de f -operator  hand le -same-d i rec t ion  
:goal  (...) 
: f i l te r  () 
:p recond (...) 
; We have  asked  a quest ion  about  acce le ra t ion  
; ... and the s tudent  has g iven  an answer  
; ... f rom wh ich  we can deduce  that  s /he  th inks  accel ,  and ve loc i ty  go in 
; the same d i rec t ion  
; and  we have  not  g iven  the exp lanat ion  be low yet  
: rec ipe  (...) 
; Te l l  the s tudent :  "But i f  the acce le ra t ion  went  the same 
d i rec t ion  as the ve loc i ty ,  then the e levator  wou ld  be speed ing  up."  
; Mark  that  we are g iv ing  th is  exp lanat ion  
; Te l l  the s tudent  that  tu tor  is request ing  another  answer  ("Try aga in . " )  
; Ed i t  the agenda (us ing prune-replace) so that  respond ing  to another  
answer  is at the top  of the agenda 
:h ie rcx  ()) 
Figure 3: Sample plan operator 
55 
to allow the planner to remove goals from the 
agenda based on a change in circumstances. It 
removes goals sequentially from the top of the 
agenda, one at a time, until the supplied argument 
becomes false. Then it replaces the removed goals 
with an optional ist of new goals. Prune-replace 
allows a type of decision-making frequently used 
in dialogue generation. When a conversation 
partner does not give the expected response, one 
would often like to remove the next goal from the 
agenda and replace it with one or more 
replacement goals. Prune-replace implements a
generalized version of this concept. 
APE is domain-independent a d communicates 
with a host system via an API. As a partner in a 
dialogue, it needs to obtain information from the 
world as well as produce output turns. 
Preconditions on plan operators can be used to 
access information from external knowledge 
sources. APE contains a recipe item type that can 
be used to execute an external program such as a 
call to a GUI interface. APE also has recipe items 
allowing the user to assert and retract facts in a 
knowledge base. Further details about the APE 
planner can be found in (Freedman, 2000). 
5 Implementation of At las-Andes 
5.1 Architecture of Atlas-Andes 
The first system we have implemented with APE 
is a prototype Atlas-Andes system that replaces 
the hints usually given for an incorrect 
acceleration vector by a choice of generated 
subdialogues. Figure 4 shows the architecture of 
Atlas-Andes; any other system built with APE 
would look similar. Robust natural language 
understanding in Atlas-Andes is provided by 
Ros6's CARMEL system (Ros6 2000); it uses the 
spelling correction algorithm devised by Elmi and 
Evens (1998). 
5.2 Structure of human tutorial dialogues 
In an earlier analysis (Kim, Freedman and Evens 
1998) we showed that a significant portion of 
human-human tutorial dialogues can be modeled 
with the hierarchical structure of task-oriented 
dialogues (Grosz and Sidner 1986). Furthermore, 
a main building block of the discourse hierarchy, 
corresponding to the transaction level in 
Conversation Analysis (Sinclair and Coulthard 
1975), matches the tutoring episode defined by 
VanLehn et al (1998). A tutoring episode 
consists of the turns necessary to help the student 
make one correct entry on the interface. 
NLU 
(CARMEL) Plan Library 
User APE 
< Interface I 
I I 
GUI Transient 
Interpreter Knowledge 
(Andes) Base 
Host 
(Andes) 
Figure 4: Interface between Atlas and host system 
56 
To obtain empirical data for the Atlas-Andes 
plan operators, we analyzed portions of a corpus 
of human tutors helping students olve similar 
physics problems. Two experienced tutors were 
used. Tutor A was a graduate student in computer 
science who had majored in physics; tutor B was 
a professional physics tutor. 
The complete corpus contained solutions to five 
physics problems by 41 students each. We 
analyzed every tutoring episode dealing with the 
acceleration vector during deceleration, totaling 
29 examples divided among 20 students and both 
tutors. The tutors had very different styles. 
Tutor A tended to provide encouragement rather 
than content, making those transcripts less useful 
for deriving an information-based approach. 
Tutor B used an information-based approach, but 
after one wrong answer tended to complete the 
solution as a monologue. Largely following 
tutor B's approach to sequence and content, we 
isolated six ways of teaching the student about 
direction of acceleration. 
5.3 Sample output and evaluation 
Figure 5 shows an example of text that can be 
generated by the Atlas-Andes ystem, showing an 
analogy-based approach to teaching this content. 
The operator library used to generate this text 
could generate a combinatorially arge number of 
versions of this dialogue as well as selected 
examples of other ways of teaching about 
direction of acceleration. 
This operator library used to generate this text 
contained 1l 1 plan operators, divided as follows: 
Tutoring schemata 
Switching between schemata 
API and GUI handling 
Answer handling 
Domain-dep. lex. insertion 
Domain-indep. lex. insertion 
TOTAL 
4 4% 
5 4% 
33 30% 
35 31% 
24 22% 
10 9% 
111 100% 
We are currently working on components hat will 
allow us to increase the number of physics 
concepts covered without a corresponding 
increase in the number of operators. The schema 
switching operators prevent the tutor from 
repeating itself during a physics problem. They 
could be reduced or eliminated by a general 
discourse history component that tutoring schema 
operators could refer to. Domain-dependent 
lexical insertion refers to the choice of lexical 
items such as car and east in the sample dialogue, 
while domain-independent iexical insertion refers 
to items such as OK and exactly. Both categories 
could be eliminated, or at least severely reduced, 
through the use of a text realization package. 
Together that would provide a one-third reduction 
in the number of operators needed. As the set of 
API and GUI handling operators is fixed, that 
would reduce by half the number of application 
operators needed. 
The largest remaining category of operators is 
the answer handlers. These operators handle a 
variety of answers for each of the five questions 
that the system can ask. The answers we 
recognize include categories such as "don't 
know" as well as specific answers (e.g. a direction 
perpendicular to the correct answer) which we 
recognize because the tutor has specific replies 
for them. In order to reduce the number of 
S: (draws acceleration vector in same direction as velocity) 
T: What is the definition of acceleration? 
S: Don't know. 
T: OK, let's try this. If a car was driving along east, which way would you have to push on it 
to make it stop? 
S: West. 
T: Exactly. The opposite direction. So the net force goes the opposite direction, and so does 
the acceleration. Try to draw the acceleration vector again now. 
S: (draws acceleration vector correctly) 
Figure 5: Example of generated ialogue 
57 
operators further, we must investigate more 
general methods of handling student errors. In 
particular, we plan to investigate error-classifying 
predicates that apply to more than one question as 
well as the use of intention-based predicates. 
Since the system only covers one rule of physics, 
albeit in a variety of ways, we plan to make some 
of these efficiency improvements before adding 
new rules of physics and testing it with users. 
Preconditions for the operators in the plan 
library utilize discourse or interaction history, the 
current goal hierarchy, recent information such as 
the tutor's current goal and the student's latest 
response, shared information such as a model of 
objects on the screen, and domain knowledge. As 
an example of the latter, if the student draws an 
acceleration vector which is incorrect but not 
opposite to the velocity vector, a different 
response will be generated. 
5.4 Discussion 
Many previous dialogue-based ITSs have been 
implemented with finite-state machines, either 
simple or augmented. In the most common finite 
state mode\[, each time the human user issues an 
utterance, the processor educes it to one of a 
small number of categories. These categories 
represent the possible transitions between states. 
Thus history can be stored, and context 
considered, only by expanding the number of 
states. This approach puts an arbitrary restriction 
on the amount of context or depth of 
conversational nesting that can be considered. 
More importantly, it misses the significant 
generalization that these types of dialogues are 
hierarchical: larger units contain repeated 
instances of the same smaller units in different 
sequences and instantiated with different values. 
Furthermore, the finite-state machine approach 
does not allow the author to drop one line of 
attack and replace it by another without hard- 
coding every possible transition. 
It is also clear that the dialogue-based approach 
has many benefits over the hint-sequence 
approach. In addition to providing a multi-step 
teaching methods with new content, it can 
respond flexibly to a variety of student answers at 
each step and take context into account when 
generating a reply. 
6 Related work  
Wenger (1987), still the chief textbook on ITSs, 
states that using a global planner to control an ITS 
is too inefficient to try. This is no longer true, if 
indeed it ever was. Vassileva (1995) proposes a 
system based on AND-OR graphs with a separate 
set of rules for reacting to unexpected events. 
Lehuen, Nicolle and Luzzati (1996) present a 
method of dialogue analysis that produces 
schemata very similar to ours. Earlier dialogue- 
based ITSs that use augmented finite-state 
machines or equivalent include CIRCSIM-Tutor 
(Woo et al 1991, Zhouet al 1999) and the 
system described by Woolf (1984). Cook (1998) 
uses levels of finite-state machines. None of these 
systems provides for predicates with variables or 
unification. 
7 Conclusions 
In this paper we described APE, an integrated 
planner and execution system that we have 
implemented as part of the Atlas dialogue 
manager. APE uses HTN-style operators and is 
based on reactive planning concepts. Although 
APE is intended largely for use in domains with 
hierarchical, multi-turn plans, it can be used to 
implement any conversation-based system, where 
turns in the 'conversation' may include graphical 
actions and/or text. We illustrated the use of APE 
with an example from the Atlas-Andes physics 
tutor. We showed that previous models based on 
finite-state machines are insufficient to handle the 
nested subdialogues and abandoned partial 
subdialogues that occur in practical applications. 
We showed how APE generated a sample 
dialogue that earlier systems could not handle. 
Acknowledgments 
We thank Abigail Gertner for her generous 
assistance with the Andes system, and Michael 
Ringenberg for indispensible programming 
support. Carolyn Ros6 built the CARMEL 
natural language understanding component. 
Mohammed EImi and Michael Glass of Illinois 
Institute of Technology provided the spelling 
correction code. We thank Pamela Jordan and the 
referees for their comments. 
B8 
References 
Bratman, M. E. 1987. Intentions, Plans, and Practical 
Reason. Cambridge, MA: Harvard. 
Bratman, M. E. 1990. What is Intention? In P.R. 
Cohen, J. Morgan and M. E. Pollack, Intentions in 
Communication. Cambridge, MA: MIT Press. 
Bratman, M. E., Israel, D. J. and Pollack, M.E. 1988. 
Plans and Resource-Bounded Practical Reasoning. 
Computational Intelligence 4(4): 349-355. 
Cook, J. 1998. Knowledge Mentoring as a Framework 
for Designing Computer-Based Agents for Sup- 
porting Musical Composition Learning. PhD. diss., 
Computing Department, The Open University. 
EImi, M.A. and Evens, M.W. 1998. Spelling 
Correction using Context. In Proceedings of the 17th 
COLING/36th ACL (COLING-ACL '98), Montreal. 
Erol, K., Hendler, J. and Nau, D.S. 1994. HTN 
Planning: Complexity and Expressivity. In 
Proceedings of the Twelfth National Conference on 
Artificial Intelligence (AAAI '94), Seattle. 
Freedman, R. 2000 (to appear). Using a Reactive 
Planner as the Basis for a Dialogue Agent. In 
Proceedings of the Thirteenth Florida Artificial 
Intelligence Research Symposium (FLAIRS'00), 
Orlando. 
Gertner, A.S., Conati, C. and VanLehn, K. 1998. 
Procedural Help in Andes: Generating Hints Using a 
Bayesian Network Student Model. In Proceedings of 
the Fifteenth National Conference on Artificial 
Intelligence (AAAI '98), Madison. 
Georgeff, M. P. and Ingrand, F. F. 1989. Decision- 
Making in an Embedded Reasoning System. In 
Proceedings of the Eleventh International Joint 
Conference on Artificial Intelligence (IJCAI '89), 
Detroit. 
Georgeff, M.P., Pell, B., Pollack, M. E., Tambe, M. 
and Wooldridge, M. 1998. The Belief-Desire- 
Intention Model of Agency. In N. Jenning, J. Muller, 
and M. Wooldridge (Eds.), Intelligent Agents V. 
Springer. 
Grosz, B.J. and Sidner, C.L. 1986. Attention, 
Intentions, and the Structure of Discourse. 
Computational Linguistics 12(3): 175-204. 
Kim, J., Freedman, R. and Evens, M. 1998. 
Responding to Unexpected Student Utterances in 
CIRCSIM-Tutor v. 3: Analysis of Transcripts. In 
Proceedings of the Eleventh Florida Artificial 
Intelligence Research Symposium (FLAIRS '98), 
Sanibel Island. 
Lehuen, J., Nicolle, A. and Luzzati, D. 1996. Un 
mod61e hypoth6tico-exp6rimental dynamique pour la 
gestion des dialogues homme-machine. In Actes du 
dixi6me congr6s de reconnaissance d s formes et 
intelligence artificielle (RFIA '96), Rennes. 
Pollack, M.E. 1992. The Uses of Plans. Artificial 
Intelligence 57(1): 43-69. 
Ros6, C. P. 2000. A Framework for Robust Semantic 
Interpretation. In Proceedings of the First Annual 
Conference of the North American Chapter of the 
Association for Computational Linguistics 
(NAACL '00). 
Sinclair, J. M. and Coulthard, R. M. 1975. Towards an 
Analysis of Discourse: The English Used by 
Teachers and Pupils. London: Oxford University 
Press. 
VanLehn, K. 1996. Conceptual and Meta Learning 
during Coached Problem Solving. In Intelligent 
Tutoring Systems." Third International Conference 
(ITS '96), Montreal. Berlin: Springer. LNCS 1086. 
VanLehn, K., Siler, S., Murray, C. and Baggett, W. 
1998. What Makes a Tutorial Event Effective? In 
Proceedings of the Twenty-first Annual Conference 
of the Cognitive Science Society, Madison. Hillsdale, 
N J: Erlbaum. 
Vassileva, J. 1995. Reactive Instructional Planning to 
Support Interacting Teaching Strategies. In 
Proceedings of the Seventh World Conference on AI 
and Education (AI-ED '95), Washington, D.C. 
Charlottesville, VA: AACE. 
Wenger, E. 1987. Artificial Intelligence and Tutoring 
Systems." Computational nd Cognitive Approaches 
to the Communication of Knowledge. San Mateo, 
CA: Morgan Kaufmann. 
Wilkins, D. 1988. Practical Planning: Extending the 
Classical AI Planning Paradigm. San Mateo, CA: 
Morgan Kaufmann. 
Wilkins, D., Myers, K., Lowrance, J. and Wesley, L. 
1995. Planning and Reacting in Uncertain and 
Dynamic Environments. Journal of Experimental 
and Theoretical Artificial Intelligence 7:121-152. 
Woo, C., Evens, M.W., Michael, J.A. and Rovick, 
A.A. 1991. Dynamic Instructional Planning for an 
Intelligent Physiology Tutoring System. In 
Proceedings of the Fourth Annual 1EEE Computer- 
Based Medical Systems Symposium, Baltimore. 
Woolf, B. 1984. Context-Dependent Planning in a 
Machine Tutor. Ph.D. diss., Dept. of Computer and 
Information Science, University of Massachusetts at 
Amherst. COINS Technical Report 84-21. 
Yang, Q. 1990. Formalizing planning knowledge for 
hierarchical planning. Computational Intelligence 
6(I): 12-24. 
Zhou, Y., Freedman, R., Glass, M., Michael, J.A., 
Rovick, A.A. and Evens, M.W. 1999. Delivering 
Hints in a Dialogue-Based Intelligent Tutoring 
System. In Proceedings of the Sixteenth National 
Conference on Artificial Intelligence (AAAI '99), 
Orlando, FL. 
59 
Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 37?42,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
     
 
 
 
 
 
 
Concrete Assignments for Teaching NLP in an M.S. Program 
 
Reva Freedman 
Department of Computer Science 
Northern Illinois University 
DeKalb, IL 60115 
freedman@cs.niu.edu 
 
 
 
 
 
Abstract 
 
The professionally oriented computer 
science M.S. students at Northern Illinois 
University are intelligent, interested in 
new ideas, and have good programming 
skills and a good math background. 
However, they have no linguistics 
background, find traditional academic 
prose difficult and uninteresting, and have 
had no exposure to research. Given this 
population, the assignments I have found 
most successful in teaching Introduction to 
NLP involve concrete projects where 
students could see for themselves the 
phenomena discussed in class. This paper 
describes three of my most successful 
assignments: duplicating Kernighan et 
al.?s Bayesian approach to spelling 
correction, a study of Greenberg?s 
universals in the student?s native language, 
and a dialogue generation project. For 
each assignment I discuss what the 
students learned and why the assignment 
was successful. 
 
 
 
1 Introduction 
 
Northern Illinois University is a large public 
university (25,000 students) located in the farm-
oriented exurbs of Chicago, about 60 miles west of 
the city. Most of the undergraduate computer 
science majors and about a third of the  M.S. 
students come from the hi-tech corridor west of 
Chicago or small towns near the university. The 
remaining M.S. students are international students, 
currently mostly from India. 
This paper discusses my experiences in two 
semesters of teaching Introduction to NLP and 
three semesters of teaching an NLP unit in an 
Introduction to Artificial Intelligence course. 
Because the students have no background in 
linguistics and are not used to reading the type of 
academic prose found in the textbook (Jurafsky 
and Martin, 2000), the most successful units I have 
taught involved concrete assignments where 
students could see for themselves the phenomena 
discussed in class. Successful assignments also did 
not assume any background in linguistics, even 
such basic notions as part of speech. 
To provide an overview of the field, each year 
the NLP course contains three segments: one on a 
statistical approach to NLP, one on syntax, and 
one on a logic-based approach. The three segments 
are also chosen to include topics from phonology 
and morphology, syntax, and pragmatics. The 
specific content changes from year to year in an 
effort to find topics that both represent current 
issues in the field and capture the students? 
imagination. 
This paper describes three of the most 
successful assignments. For each one, I describe 
the assignment, the topics the students learned, and 
why it was successful. The three assignments are: 
duplicating Kernighan et al?s Bayesian approach 
37
      
to spelling correction, a study of Greenberg?s 
universals in a language other than English 
(usually the student?s native language), and a 
dialogue generation project using my research 
software. 
2 Background 
2.1 Student demographics 
Most of the students taking Introduction to NLP 
are graduate students, although undergraduates are 
eligible if they have had three semesters of C++ 
programming. Graduate students in cognitive 
science-related fields, such as psychology or 
linguistics, are eligible if they have taken one 
semester of programming and are willing to teach 
themselves about trees. I actively recruit non-
computer science students because it makes the 
course more interesting. In addition to providing a 
broader spectrum of interests, they tend to be more 
outgoing. They tend to be more willing to answer 
questions in class, and also to ask questions in 
class, which many of the computer science 
students will not do. 
The preferred career path among the students is 
to obtain a programming job in local industry, 
preferably in a hi-tech area. However, among both 
undergraduates and graduate students, a few 
continue their education. One minority student 
with no previous experience in research became 
interested and is now planning to apply to a PhD 
program. In general, students take the course out 
of a desire to do something different from the 
normal operating systems, networking and 
database courses. An occasional student also takes 
the course because it fits in their schedule or 
because it doesn?t have onerous prerequisites. 
In general, the international students have good 
to near-native competence in spoken English, 
although a few cannot not follow my lectures, and 
some do not have sufficient writing skills for an 
essay exam. All could read my lecture notes 
without difficulty. Both among the international 
students and local students, many do not have 
sufficient experience with formal academic prose 
to understand the textbook (Jurafsky and Martin, 
2000). Students? first languages have included 
Telugu, Hindi/Urdu, Nepali, Chinese (Mandarin), 
and Bulgarian. 
2.2 Student background 
Koedinger (2001), in his research on tutoring 
systems for high school mathematics, gives the 
following as his fundamental principle: ?the 
student is not like me.? In particular, student 
background frequently did not include the 
following items: 
1) Parts of speech 
2) Basic English grammar 
3) Relationships between languages and language 
families 
4) Practical issues, such as the importance of 
transliteration and glossing 
5) Philosophical issues, such as the fact that there 
is no single authoritative grammar of a natural 
language or that one language is not more 
difficult than another in an absolute sense 
However, students were talented at and enjoyed 
programming. Most students also had a good math 
background. Finally, they were enthusiastic about 
learning new things, as long as it involved concrete 
examples that they could work out and a sample 
problem with a solution that they could use as a 
model. 
3 Spelling correction 
3.1 Background 
The goal of the first section of the course was to 
show the students the power of statistical methods 
in NLP. In this section, students were asked to 
duplicate the calculations used in Kernighan et 
al.?s (1990) Bayesian approach to spelling 
correction, as explained in Section 5.5 of the 
textbook. 
Kernighan et al choose as the preferred 
correction the one that maximizes P(t|c)P(c), 
where t is the typo and c is a candidate correction. 
Candidate corrections are generated by assuming 
that errors involve only one letter or the 
transposition of two adjacent letters. To reproduce 
this calculation, students need the confusion 
matrices provided in the original paper, a source of 
unigram and bigram data, and a source for word 
frequencies. 
38
      
3.2 Assignment 
Students are given some misspelled words and 
possible corrections, such as the following 
examples from Kernighan et al 
    misspelled word possible corrections 
    ambitios  ambitious 
       ambitions 
       ambition 
 
For each of these misspelled words, students are 
asked to do the following:  
a)  Use the method described by Kernighan et al, 
or equivalently in section 5.5 of the text, to find 
the probability of each possible correction. 
b)  Use their preferred spell checker (Microsoft 
Word, Unix ispell, etc.) to generate possible 
corrections for the same misspelled words. 
The following questions are asked for each 
misspelled word: 
  Is the most probable correction according to 
Kernighan?s algorithm the same as the one 
suggested by your program? 
  Which additional possible corrections (i.e., non-
single-error corrections or non-single word 
corrections) does your program generate? 
  Which of Kernighan?s possible corrections does 
your program omit? 
Since Kernighan?s original paper omits the 
unigram and bigram count matrices, I provide a 
file with this information. Students are encouraged 
to find a source for word frequencies on the Web. 
As one option, I suggest they use any search 
engine (e.g., Google), after class discussion about 
the approximations involved in this approach. 
Students are also given two summary questions 
to answer: 
  A former student, Mr. I. M. Kluless, says: I 
don?t see the point of using the frequency of 
potential corrections in the corpus (i.e., the prior 
probability) as part of Kernighan?s algorithm. I 
would just use the likelihood of a given error. How 
would you answer Mr. Kluless? (One way to think 
about this question is: what would happen if you 
left it out?) 
  Another former student, Ms. U. R. Useless, says: 
I don?t see the point of using the likelihood of a 
given error as part of Kernighan?s algorithm. I 
would just use the prior probability. How would 
you answer Ms. Useless? 
3.3 Results 
Students enjoyed this assignment because it was 
straightforward and used mathematics they were 
familiar with. They were uniformly surprised to 
discover that spelling correction is generally done 
today using Bayesian concepts rather than by 
dictionary lookup alone. They were also surprised 
to learn that learn that results were largely 
independent of the corpus chosen. Students who 
already knew Bayes? theorem learned about an 
application completely different from the ones 
they had used in other courses. 
The majority of students used my suggestion to 
approximate word frequencies in a corpus by page 
counts in Google. They were surprised to learn 
that in spite of the number of ways in which the 
web differs from an ideal corpus, the volume of 
data available ensures that accurate results are still 
obtained. The better students searched the web for 
corpora they preferred, including the works of 
Shakespeare and an online interface to the British 
National Corpus 
(http://sara.natcorp.ox.ac.uk/lookup.html). 
4 Syntax and language universals 
4.1 Background 
The second section of the course had as its goal to 
teach the students some basic aspects of syntax. I 
started with parts of speech and basic concepts of 
context-free grammars. I then introduced 
unification grammars as a way of obtaining more 
power with fewer rules. 
As a way of showing the syntactic variation 
among languages, I also introduced some of 
Greenberg?s word order universals (Greenberg, 
1966), following the exposition in Baker (2001). 
Although identifying the most probable underlying 
word order (SVO, etc.) of an unknown language 
can involve significant linguistic intuition, I did 
not expect students to achieve that goal. Rather, I 
used Greenberg?s ideas to make students think 
39
      
about the rules they were generating instead of 
generating S --> NP VP by rote. Additionally, the 
use of multiple languages contributed to the 
university?s goal of introducing ideas of 
internationalization and diversity in classes where 
feasible. 
4.2 Assignment 
The students were asked to prepare a 15-minute 
class presentation showing two or three interesting 
phenomena of one of the languages of the world. 
Most students used their native language. 
They were asked to include the following 
information: 
  Where the language fits in Greenberg?s 
classification (SVO, etc.) 
  One or more syntactic phenomena that make 
the language interesting 
  A grammar fragment (a set of CFG rules, 
possibly with unification-based features) 
illustrating one of the chosen phenomena 
They could show several interesting phenomena 
with a short implementation of one, a complex 
phenomenon and a longer fragment of grammar, or 
one interesting phenomenon and multiple ways to 
implement it. 
For each example they used, they were required 
to show the original transliterated into the Roman 
alphabet, a morpheme-level analysis, and a 
translation into English. 
As a template, I gave a presentation using a 
language none of them had been exposed to,  
modern Hebrew. The four sample phenomena I 
presented were: a) there is no indefinite article, 
b) nouns and adjectives must agree in gender and 
number, c) adjectives follow the noun, and d) the 
definite article is attached to every adjective in an 
NP as well as to the noun. 
In addition to providing an example of the scope 
required, the presentation also introduced the 
students to conventions of linguistic presentation, 
including interlinear display of transliteration, 
morpheme analysis, and translation. One slide 
from my presentation is shown below: 
 he- khatul   ha- gadol 
 DET cat-M-S  DET big-M-S 
 ?the big cat? 
 he- khatulim   ha- g?dolim 
 DET cat-M-PL   DET big-M-PL 
 ?the big cats? 
4.3 Results 
This assignment was useful for ensuring that 
students had a basic grasp of many elements of 
syntax covered in Section II of the textbook, 
including parts of speech, context-free grammars, 
and unification grammars. Second, the class 
presentations provided students concrete examples 
of some major syntactic concepts that all 
languages share, as well as some of the 
differences. Finally, this assignment enabled 
students to learn about and present some of the 
core linguistic features of their native language. 
5 Dialogue generation 
5.1 Background 
The third segment of the course had as its goal to 
show how a logic-based approach is useful in 
NLP. Since some of my previous work involves 
implementing dialogue software using a logic-
based approach, dialogue systems was a natural 
choice for this segment. 
Phenomena discussed in lecture included the 
concepts of speech act and discourse intention, the 
relationship between syntactic form and intention, 
direct and indirect speech acts, and a short 
introduction to dialogue act classification. 
As a counterbalance to the more theoretical 
material from Greenberg, this section included 
some information about current commercial uses 
of NLP. Students were asked to read an article 
from the popular press (Mount, 2005) describing 
experiences with currently available commercial 
systems. 
I used my own software, APE (Freedman, 
2000), a domain-independent dialogue plan 
interpreter based on reactive planning concepts. 
APE uses a rule-based macro language 
implemented in Common Lisp. It is a hierarchical 
task network (HTN) style planner, achieving each 
goal via a series of subgoals. APE?s high-level 
planning loop alternates between waiting for user 
input and planning responses. It executes plan 
operators until a primitive, non-decomposable one 
40
      
is obtained. In addition to elicit and inform, plans 
can also include primitives to query and update 
APE?s internal knowledge base, thus giving the 
system a ?mind.? Primitives are added to a buffer 
until a primitive requiring a response from the user 
is received. At that point the operators in the 
buffer are used to build the output text. Goals are 
represented using first-order logic without 
quantifiers, with full unification used for 
matching. 
APE provides two ways to change a plan in 
progress. The author can instruct the system either 
to switch from one method of satisfying a goal to 
another or to add new goals at the top of the 
agenda, possibly replacing existing goals. The 
latter facility is particularly useful in dialogue 
generation, since it allows the system to prompt 
the user after an error. This feature makes APE 
more powerful than the pushdown automaton one 
might use to implement a context-free grammar.  
In addition, APE is obviously more powerful than 
the finite-state machines often used in dialogue 
generation. 
Use of APE allows students to generate realistic 
hierarchically structured conversations with a 
reasonable number of rules. 
5.2 Assignment 
Sample code presented in class involved looking 
up data in a database of presidents? names. The 
sample system prompted the user for input, then 
provided answers, error messages, and re-prompts 
as appropriate. As an illustration of the power of 
the approach, I also demonstrated some of my 
research software, which showed conversations 
embedded in a variety of front-end GUIs. 
For the assignment, students were asked to 
choose their own topic. They were asked to choose 
a problem, then provide a database layout and 
draw a graph showing the possible conversations 
their system could generate. Finally, they were 
asked to implement the code. At the end of the 
semester, students made a five-minute presentation 
to the class showing their application. 
5.3 Results 
Students greatly enjoyed this assignment because 
it involved the activity they enjoyed most, namely 
programming. Even though it was qualitatively 
different from other algorithms they had learned, 
they had no trouble learning the unification 
algorithm, both iterative and recursive versions, 
because they were experienced in learning 
algorithms. For most students in our program, this 
project will be their only experience with a non-
imperative programming language. 
Students were not bothered by the fact that the 
sample software provided included some features 
not discussed in class. In fact, some of the better 
students studied these features and used them in 
their own programs. 
Every student mastered the basics of logic 
programming, including how to choose between 
alternatives, establish a default, implement multi-
step and hierarchical procedures, interact with the 
user, and access an external database. They also 
learned how to use unification along with multiple 
first-order relations to access and update a 
database. The weaker students simply used the 
sample software as a guide, while the stronger 
ones mastered the underlying concepts and wrote 
more creative code. 
Student projects ranged the gamut, including a 
system for running a car dealership, a game 
identifying movie directors, and an interactive 
system providing health information. 
6 Conclusions 
 
Teaching NLP to students for whom this will be 
the only exposure to the topic, and possibly the 
only exposure to a research-oriented topic, can be 
a successful and enjoyable experience for both 
students and teacher. With good organization, 
students can do useful projects even in one 
semester. 
One factor that has increased student 
satisfaction as well as their mastery of the material 
is the use of concrete assignments where students 
can see for themselves concepts described in class. 
Three such assignments I have successfully used 
involve duplicating Kernighan et al?s Bayesian 
approach to spelling correction, a study of 
Greenberg?s universals in the student?s native 
language, and a dialogue generation project using 
my research software. Each of these assignments is 
used in one of the three segments of the course: 
statistical approaches to language, introduction to 
syntax, and logic-based approaches to NLP. 
41
      
Acknowledgments 
 
Michael Glass of Valparaiso University graciously 
supplied the unigram and bigram counts needed to 
implement Kernighan et al?s (1990) spelling 
correction algorithm. 
References 
 
Baker, M. (2001). Atoms of Language: The Mind?s 
Hidden Rules of Grammar. New York: Basic Books. 
Freedman, R. (2000). Using a Reactive Planner as the 
Basis for a Dialogue Agent. In Proceedings of the 
Thirteenth Florida Artificial Intelligence Research 
Symposium (FLAIRS 2000), Orlando. 
Greenberg, J. (1966). Some universals of grammar with 
particular reference to the order of meaningful 
elements. In Universals of language, ed. 
J. Greenberg, pp. 73?113. Cambridge, MA: MIT 
Press. 2nd ed. 
Kernighan, M., Church, K., and Gale, W. (1990). A 
spelling correction program based on a noisy channel 
model. In COLING ?90 (Helsinki), v. 2, pp. 205?211. 
Available online from the ACL archive at 
http://acl.ldc.upenn.edu/C/C90/C90-2036.pdf. 
Koedinger, K. (2001). The Student is Not Like Me. In 
Tenth International Conference on Artificial 
Intelligence in Education (AI-ED 2001). San Antonio, 
TX. Keynote address. Slides available online at 
http://www.itsconference.org/content/seminars.htm. 
Mount, I. (2005). Cranky Consumer: Testing Online 
Service Reps. Wall Street Journal, Feb. 1, 2005. 
 
 
 
42
Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 114?119,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Teaching NLP to Computer Science Majors via Applications and 
Experiments 
 
Reva Freedman 
Department of Computer Science 
Northern Illinois University 
DeKalb, IL 60115 
rfreedman@niu.edu 
 
 
 
 
 
Abstract 
 
Most computer science majors at Northern 
Illinois University, whether at the B.S. or M.S. 
level, are professionally oriented. However, 
some of the best students are willing to try 
something completely different. NLP is a 
challenge for them because most have no 
background in linguistics or artificial 
intelligence, have little experience in reading 
traditional academic prose, and are unused to 
open-ended assignments with gray areas. In 
this paper I describe a syllabus for Introduction 
to NLP that concentrates on applications and 
motivates concepts through student 
experiments. Core materials include an 
introductory linguistics textbook, the Jurafsky 
and Martin textbook, the NLTK book, and a 
Python textbook. 
 
 
 
1 Introduction 
 
Northern Illinois University is a large public 
university (25,000 students) located about 60 miles 
west of Chicago. Most computer science majors 
come from the suburbs and exurbs of Chicago or 
small towns near the university. Their preferred 
career path is generally to obtain a programming 
job in local industry, preferably in a hi-tech area. 
Most students take the Introduction to NLP course 
out of a desire to do something different from their 
required courses. 
In this paper I describe the issues I have found in 
teaching NLP to this population, and the syllabus I 
have developed as a result. Since the students 
enjoy programming and see system development 
as the core issue of computer science, I concentrate 
on applications and their structure. I motivate 
many of the issues involved using data and systems 
from the web and in-class experiments. I explicitly 
teach the linguistics background that they need.  
 
2 Student background 
 
I started from the following assumptions derived 
from several years of teaching Introduction to 
Artificial Intelligence and Introduction to NLP at 
NIU. 
Linguistic background: 
1. Students have never studied linguistics. 
2. Students are not familiar with the common 
syntactic constructions of English taught in 
traditional English grammar, and are often unsure 
about parts of speech. 
3. Students have little experience with languages 
other than English. 
 
Programming: 
4. Students are not familiar with programming 
languages other than conventional imperative 
languages such as C++, Java, and .NET. 
5. Students like to program and to build working 
systems. 
6. Students expect to have programming 
languages explicitly taught in class. 
 
Academic approach: 
7. Students live on the web and are 
uncomfortable having to use offline reference 
materials. 
8. Students are not comfortable with or 
interested in traditional academic prose or research 
papers. 
9. Students are taking the course for fun and to 
do something different. They are unlikely to need 
specific NLP content in their future careers. 
     
114
 10. Students taking NLP are unlikely to have 
time in their program to take another artificial 
intelligence course (although there are exceptions). 
 
3 Course goals 
 
From these presuppositions I have developed the 
following general principles to provide a positive 
experience for both students and teacher: 
1. Teach the linguistic content explicitly, at a 
level suitable for beginners. 
2. Concentrate on applications, using them to 
motivate algorithms. 
3. Concentrate on student involvement at all 
levels: in-class experiments, take-home 
experiments to be discussed in class, and practical 
programming projects. 
4. Concentrate on a few basic principles that are 
repeated in many contexts, such as rule-based vs. 
Bayesian approaches and the role of world 
knowledge in working systems. 
From these presuppositions I have developed a 
syllabus that maintains student interest, provides 
students a basic background in NLP, and also 
provides them with useful skills and knowledge 
that they may not otherwise encounter in their 
program of study. 
The course has three goals: 
1. Give students a general background in the 
issues involved in handling both speech and 
written text, some of the most common 
applications, and some of the most widely used 
algorithms. 
2. Provide students with a productive experience 
in a modern programming language. 
3. Teach students a number of useful concepts 
that they might not otherwise come across in their 
course of study. These topics include: 
?  Bayes? Law 
?  Dynamic programming 
?  Hidden Markov models 
?  Regular expressions and finite-state machines 
?  Context-free grammars 
The following sections of the paper describe the 
most important units of the course, showing how 
they use the principles stated above to contribute to 
these goals. 
4 Introducing NLP 
 
The first goal of the course is to define the NLP 
task and explain why it is harder and less 
determinate than many of the problems they have 
studied in their other courses. 
I start by encouraging students to list all the 
meanings they can for ?I made her duck?, based on 
the five meanings given by Jurafsky and Martin 
(2000, section 1.2). For a view of a system that can 
deal with such issues, I then introduce Figure 1.1 
of Bird, Klein, and Loper (2008, henceforce 
referred to as the NLTK textbook), which shows a 
pipeline architecture for a spoken dialogue system. 
I use this opportunity to discuss each component 
and possible data representations. 
5 Providing linguistic background 
 
I introduce three kinds of background knowledge, 
related to speech, words and sentences, and human 
factors issues. 
5.1 Background for speech processing 
 
To provide essential background for discussing 
speech processing, I introduce the concepts of 
phone and phoneme. I also teach give a brief 
introduction to the IPA so that I can use it in 
examples. I use the following sections from 
Stewart and Vaillette (2001), a textbook for 
introductory linguistics classes: 
File 3.1: International Phonetic Alphabet (IPA) 
File 3.2: English consonants 
File 3.3: English vowels 
File 3.5: English transcription exercises 
File 4.1: Phones vs. phonemes 
These sections were chosen to provide the 
background students need while providing 
maximum opportunities for interaction. Students 
have found this approach more accessible than the 
rather terse treatment in Jurafsky and Martin 
(2000, ch. 4). I do the following activities, familiar 
to teachers of introductory linguistics classes, in 
class: 
?  Putting one?s fingers on the glottis to experience 
the difference between voiced and unvoiced 
     
115
 consonants 
?  Putting one?s hand in front of one?s mouth to 
experience the difference between aspirated and 
unaspirated consonants 
?  Reading IPA transcription in pairs 
I also introduce students to the idea that both 
pronunciation and other areas of human language 
generation are affected by context. For example, 
using Figure 5.7 of Jurafsky and Martin (2000) as 
a guide, I try to generate as many as possible of the 
sixteen most common pronunciations of because 
shown in that figure. 
5.2 Background for text processing 
 
As background for the text processing section, I 
lecture on a few core aspects of syntax and related 
topics that will be needed during the semester. 
These topics include the following: 
?  What is a word? 
?  How many parts of speech are there? 
?  Lexical ambiguity 
?  Syntactic ambiguity, including PP attachment, 
   attachment of gerunds, and coordination 
   ambiguity 
?  Difference between syntactic structure and 
   intention 
5.3 Background in human factors issues 
 
This section includes several topics that experience 
has shown will be needed during the semester. 
The first is the difference between descriptive 
and prescriptive linguistics. I take class polls on 
various sociolinguistic issues, including 
pronunciation, word choice and sentence structure, 
using File 10.10: Language variation from Stewart 
and Vaillette (2001) as a basis. 
I take a poll on the pronunciation of the word 
office, choosing that word since the distribution of 
its first vowel is sensitive both to geography and 
speaker age. The poll gives me an opportunity to 
introduce some of the human factors issues related 
to corpus collection and the issue of statistical 
significance. We also examine some data 
collection tasks found on the Internet, using them 
to discuss experimental design and how it relates to 
the data collected. 
Finally, I begin a discussion on the difference 
between rule-based and statistical systems that will 
recur frequently during the semester. This is a 
good place to discuss the importance of separating 
training data and test data. 
6 Python 
6.1 Basic Python 
 
The next step is to teach basic Python so that there 
will be time for some practice programs before the 
first major programming project. As computer 
science majors, the students tend to find that the 
treatment in the NLTK textbook does not answer 
enough of their technical questions, such as issues 
on argument handling and copying of objects 
vs. references to them. 
I give several lectures on Python, including the 
following topics: 
?  Basic data structures 
?  Basic control structures 
?  Functions and modules 
?  Objects 
?  File handling 
I have found Lutz (2008) to be the most readable 
introductory textbook. I use Chun (2007) as a 
reference for topics not covered by Lutz, such as 
regular expressions and some of the I/O options. 
6.2 Using Python for basic language 
 handling 
 
This unit basically covers the material in chapters 
2, 3, and 6 of the NLTK textbook. The goal is to 
show students how easily some of these problems 
can be handled with an appropriate programming 
language. Many of them are quite uncomfortable 
with the idea of a list not implemented with 
pointers, but in the end they cope well with a 
language that does not have all the baggage of 
C++. 
I give a simple assignment that involves finding 
the most common words in a corpus. A secondary 
purpose of this assignment is to reinforce the 
earlier lecture on the difficulty of defining a word. 
I lard the input text for the assignment with 
problematic cases such as hyphenated multiword 
expressions, e.g., ?the orange-juice based 
confection.? 
     
116
 7 Rule-based dialogue systems using 
 regular expressions 
 
Since later in the course we will be comparing 
rule-based systems to statistics-based systems, this 
is an appropriate time to introduce rule based 
systems. We experiment in class with Eliza, trying 
both to make it work and make it fail. I give out a 
list of versions available on the web, and students 
can easily find more. In class I often use the emacs 
built-in version. 
I then give out copies of the original Eliza paper 
(Weizenbaum, 1966), which contains the original 
script in an appendix. If time permits, I also 
discuss PARRY (Parkison, Colby and Faught, 
1977), which has a much more linguistically 
sophisticated design but there is no simulator 
available for it. 
I introduce regular expressions at this point for 
two reasons. In addition to being required for 
continued use of the NLTK textbook, regular 
expressions are an important idea that is not 
otherwise included in our curriculum. We 
experiment with Rocky Ross? interactive web site 
(Pascoe, 2005) and occasionally with other 
simulators. I also assign a simple homework using 
regular expressions in Python. 
The first major project in the course is to write 
an shallow interactive written dialogue system, i.e., 
an Eliza-type program. Students have the choice of 
choosing a more realistic, limited domain, such as 
a database front-end, or of picking a specific case 
(e.g., a linguistic issue) that they would like Eliza 
to handle. This project is implemented in Python as 
a rule-based system with heavy use of regular 
expressions. Before they write their code, students 
do a five-minute presentation of their domain, 
including a sample conversation. After the projects 
are due, they present their results to the class. 
8 Spelling correction and Bayes? Law 
 
Bayes? Law is another core topic that students are 
generally unfamiliar with, even though statistics is 
required in our program. To provide a contrast to 
rule-based systems, and to introduce this core 
topic, I present Kernighan, Church and Gale?s 
(1990) Bayesian approach to spelling correction, as 
explained by Jurafsky and Martin  (2000, section 
5.5). 
Kernighan et al choose as the preferred 
correction the one that maximizes P(t|c)P(c), where 
t is the typo and c is a candidate correction. In a 
previous paper (Freedman, 2005), I discuss in 
detail an assignment where students choose a 
corpus and replicate Kernighan?s calculations. 
They then compare their results to results from 
their favorite word processor. 
Students are generally surprised at how similar 
the results are from what they originally see as an 
unmotivated calculation. They are always surprised 
to learn that spelling correction is generally not 
done by a lookup process. They are also surprised 
to learn that learn that results were largely 
independent of the corpus chosen. 
I also demonstrate approximating word 
frequencies by page counts in Google, along with a 
discussion of the advantages and disadvantages of 
doing so. In general, students prefer to use one of 
the NLTK corpora or a corpus obtained from the 
web. 
9 Machine translation: rule-based and 
 statistical models 
 
This unit has several purposes. In addition to 
showing students how the same problem can be 
attacked in remarkably different ways, including 
multiple levels of rule-based and statistically-based 
systems, machine translation gives students a look 
at a fielded application that is good enough to be 
viable but sill obviously needs improvement. 
To the extent that information is publicly 
available, I discuss the architecture of one of the 
oldest machine translation systems, Systran 
(Babelfish), and one of the newest, Microsoft Live 
Translator. The latter uses components from 
MindNet, Microsoft?s knowledge representation 
project, which provides another opportunity to 
reinforce the importance of world knowledge in 
artificial intelligence and NLP in particular. It also 
provides an initial opportunity to discuss the 
concept of machine learning as opposed to hand-
crafting rules or databases. 
As the assignment for this unit, students choose 
a short text in a foreign language. They use 
multiple web-based translation systems to translate 
it into English, and analyze the results. In addition 
to the systems mentioned above, the Reverso 
system has done well in these experiments. 
Popular inputs include administrative text (e.g., 
citizenship rules) from a bilingual country and 
     
117
 chapter 1 of Genesis. One student started with a 
French version of the Tolkien poem ?... one ring to 
rule them all...? Although translation of poetry 
obviously poses different issues than technical text, 
a fruitful discussion emerged from the fact that two 
of the systems misparsed one or more of the lines 
of the poem. 
10 POS identification, parsing and 
 author identification 
 
This unit of the course covers key sections of 
chapters 4, 7, 8 and 9 of the NLTK textbook. 
Although one student originally stated that ?I 
really don?t care about parts of speech,? students 
find this material more interesting after seeing how 
many of the machine translation errors are caused 
by parsing errors. Still, I only cover POS 
assignment enough to use it for chunking and 
parsing. 
The application chosen for this unit involves 
author identification. I introduce students to the 
basics of the Federalist Papers controversy. Then I 
discuss the approach of Mosteller and Wallace 
(1984), which depends largely on words used 
much more frequently by one author than the 
other, such as while and whilst. 
I suggest to students that more interesting results 
could perhaps be obtained if data about items such 
as part of speech use and use of specific 
constructions of English were added to the input. 
As an alternative assignment, I give students 
transcripts of tutoring by two different professors 
and invite them to identify the authors of 
additional transcripts from a test set. A secondary 
goal of this assignment is for students to see the 
level of cleanup that live data can require. 
This assignment also shows students the relative 
difficulty level of chunking vs. parsing better than 
any lecture could. This is useful because students 
otherwise tend to find chunking too ad hoc for 
their taste. 
I do teach several approaches to parsing since 
many students will not otherwise see context-free 
grammars in their studies. Having had the 
experiences with machine translation systems helps 
prevent the reaction of a previous class to Earley?s 
algorithm: ?we understand it; it?s just not 
interesting.? I also frame Earley?s algorithm as 
another example of dynamic programming. 
11 Speech understanding 
 
Students generally find speech a much more 
compelling application than written text. In this 
unit I discuss how basic speech processing works. 
This unit provides a nice review of the basics of 
phonology taught at the beginning of the semester. 
It also provides a nice review of Bayes? Law 
because the approach used, based on Jurafsky and 
Martin (2000, ch. 5.7?5.9) uses Bayes? Law in a 
fashion similar to spelling correction. 
The assignment for this unit involves 
experimenting with publicly available speech 
understanding systems to see how well they work. 
The assignment involves comparing two automated 
411 systems, Google?s new system 
(1-800-GOOG411), which was built specifically 
for data collection, and Jingle (1-800-FREE411), 
which is advertising-supported. I also encourage 
students to report on their own experiments with 
bank, airline, and other systems. 
I give at least one anonymous questionnaire 
every semester. Students generally report that the 
level of detail is appropriate. They generally vote 
for more topics as opposed to more depth, and they 
always vote for more programming assignments 
and real systems rather than theory. 
12 Future work 
 
I am considering replacing author identification by 
question answering, both because it is an important 
and practical topic and because I think it would 
provide better motivation for teaching chunking. I 
am also considering keeping author identification 
and adding the use of a machine learning package 
to that unit, since I believe that machine learning is 
rapidly becoming a concept that all students should 
be exposed to before they graduate. 
My long-term goal is to have students build an 
end-to-end system. A short-term goal in service of 
this objective would be to add a unit on text-to-
speech systems. 
13 Conclusions 
 
This paper described a syllabus for teaching NLP 
to computer science majors with no background in 
the topic. Students enjoyed the course more and 
were more apt to participate when the course was 
oriented toward applications such as dialogue 
     
118
 systems, machine translation, spelling correction 
and author identification. Students also learned 
about the architecture of these systems and the 
algorithms underlying them. Students implemented 
versions of some of the smaller applications and 
experimented with web versions of large fielded 
systems such as machine translation systems. 
Acknowledgments 
 
I thank the authors of Jurafsky and Martin (2000) 
and Bird, Klein and Loper (2008), whose extensive 
labor has made it possible to teach this course. I 
would also like to thank the anonymous reviewers 
for their suggestions. 
References 
 
Steven Bird, Ewan Klein, and Edward Loper. (2008). 
Natural Language Processing in Python. Available 
on the web at http://nltk.org/index.php/Book. 
Wesley J. Chun. (2007). Core Python Programming, 
2/e. Upper Saddle River, NJ: Prentice-Hall. 
Reva Freedman. (2005). Concrete Assignments for 
Teaching NLP in an M.S. Program. In Second 
Workshop on Effective Tools and Methodologies for 
Teaching NLP and CL, 43rd Annual Meeting of the 
ACL. 
Daniel Jurafsky and James H. Martin. (2000). Speech 
and Language Processing. Upper Saddle River, NJ: 
Prentice-Hall. 
Mark Lutz. (2008). Learning Python, 3/e. Sebastopol, 
CA: O?Reilly. 
Mark D. Kernighan, Kenneth W. Church, and William 
A. Gale. (1990). A spelling correction program based 
on a noisy channel model. In COLING ?90 
(Helsinki), v. 2, pp. 205?211. 
Frederick and Mosteller and David L. Wallace. (1984). 
Applied Bayesian and Classical Inference: The Case 
of The Federalist Papers. New York: Springer. 
Originally published in 1964 as Inference and 
Disputed Authorship: The Federalist. 
Brad Pascoe (2005). Webworks FSA applet. Available 
at http://www.cs.montana.edu/webworks/projects/ 
theoryportal/models/fsa-exercise/appletCode/ 
fsa_applet.html. 
Roger C. Parkison, Kenneth Mark Colby, and William 
S. Faught. (1977). Conversational Language 
Comprehension Using Integrated Pattern-Matching 
and Parsing. Artificial Intelligence 9: 111?134. 
Thomas W. Stewart, Jr. and Nathan Vaillette. (2001).  
Language Files: Materials for an Introduction to 
Language and Linguistics, 8/e. Columbus: Ohio 
State University Press. 
Joseph Weizenbaum. (1966). Eliza?A Computer 
Program for the Study of Natural Language 
Computation between Man and Machine. 
Communications of the ACM 9(1): 36?45. 
 
     
119
