Proceedings of the Workshop on Statistical Machine Translation, pages 47?54,
New York City, June 2006. c?2006 Association for Computational Linguistics
Searching for alignments in SMT. A novel approach based on an Estimation
of Distribution Algorithm ?
Luis Rodr??guez, Ismael Garc??a-Varea, Jose? A. Ga?mez
Departamento de Sistemas Informa?ticos
Universidad de Castilla-La Mancha
luisr@dsi.uclm.es, ivarea@dsi.uclm.es, jgamez@dsi.uclm.es
Abstract
In statistical machine translation, an align-
ment defines a mapping between the
words in the source and in the target sen-
tence. Alignments are used, on the one
hand, to train the statistical models and, on
the other, during the decoding process to
link the words in the source sentence to the
words in the partial hypotheses generated.
In both cases, the quality of the alignments
is crucial for the success of the translation
process. In this paper, we propose an al-
gorithm based on an Estimation of Dis-
tribution Algorithm for computing align-
ments between two sentences in a paral-
lel corpus. This algorithm has been tested
on different tasks involving different pair
of languages. In the different experiments
presented here for the two word-alignment
shared tasks proposed in the HLT-NAACL
2003 and in the ACL 2005, the EDA-
based algorithm outperforms the best par-
ticipant systems.
1 Introduction
Nowadays, statistical approach to machine trans-
lation constitutes one of the most promising ap-
proaches in this field. The rationale behind this ap-
proximation is to learn a statistical model from a par-
allel corpus. A parallel corpus can be defined as a set
?This work has been supported by the Spanish Projects
JCCM (PBI-05-022) and HERMES 05/06 (Vic. Inv. UCLM)
of sentence pairs, each pair containing a sentence in
a source language and a translation of this sentence
in a target language. Word alignments are neces-
sary to link the words in the source and in the tar-
get sentence. Statistical models for machine trans-
lation heavily depend on the concept of alignment,
specifically, the well known IBM word based mod-
els (Brown et al, 1993). As a result of this, differ-
ent task on aligments in statistical machine transla-
tion have been proposed in the last few years (HLT-
NAACL 2003 (Mihalcea and Pedersen, 2003) and
ACL 2005 (Joel Martin, 2005)).
In this paper, we propose a novel approach to deal
with alignments. Specifically, we address the prob-
lem of searching for the best word alignment be-
tween a source and a target sentence. As there is
no efficient exact method to compute the optimal
alignment (known as Viterbi alignment) in most of
the cases (specifically in the IBM models 3,4 and 5),
in this work we propose the use of a recently ap-
peared meta-heuristic family of algorithms, Estima-
tion of Distribution Algorithms (EDAs). Clearly, by
using a heuristic-based method we cannot guarantee
the achievement of the optimal alignment. Nonethe-
less, we expect that the global search carried out
by our algorithm will produce high quality results
in most cases, since previous experiments with this
technique (Larran?aga and Lozano, 2001) in different
optimization task have demonstrated. In addition to
this, the results presented in section 5 support the
approximation presented here.
This paper is structured as follows. Firstly, Sta-
tistical word alignments are described in section 2.
Estimation of Distribution Algorithms (EDAs) are
47
introduced in section 3. An implementation of the
search for alignments using an EDA is described in
section 4. In section 5, we discuss the experimental
issues and show the different results obtained. Fi-
nally, some conclussions and future work are dis-
cussed in section 6.
2 Word Alignments In Statistical Machine
translation
In statistical machine translation, a word alignment
between two sentences (a source sentence f and a
target sentence e) defines a mapping between the
words f1...fJ in the source sentence and the words
e1..eI in the target sentence. The search for the op-
timal alignment between the source sentence f and
the target sentence e can be stated as:
a? = argmax
a?A
Pr(a|f , e) = argmax
a?A
Pr(f ,a|e) (1)
being A the set of all the possible alignments be-
tween f and e.
The transformation made in Eq. (1) allows us to
address the alignment problem by using the statitisti-
cal approach to machine translation described as fol-
lows. This approach can be stated as: a source lan-
guage string f = fJ1 = f1 . . . fJ is to be translated
into a target language string e = eI1 = e1 . . . eI .
Every target string is regarded as a possible transla-
tion for the source language string with maximum a-
posteriori probability Pr(e|f). According to Bayes?
decision rule, we have to choose the target string
that maximizes the product of both the target lan-
guage model Pr(e) and the string translation model
Pr(f |e). Alignment models to structure the trans-
lation model are introduced in (Brown et al, 1993).
These alignment models are similar to the concept
of Hidden Markov models (HMM) in speech recog-
nition. The alignment mapping is j ? i = aj from
source position j to target position i = aj . In sta-
tistical alignment models, Pr(f ,a|e), the alignment
a is usually introduced as a hidden variable. Never-
theless, in the problem described in this article, the
source and the target sentences are given, and we are
focusing on the optimization of the aligment a.
The translation probability Pr(f ,a|e) can be
rewritten as follows:
Pr(f ,a|e) =
J?
j=1
Pr(fj , aj |f j?11 , aj?11 , eI1)
=
J?
j=1
Pr(aj |f j?11 , aj?11 , eI1)
?Pr(fj |f j?11 , aj1, eI1) (2)
The probability Pr(f ,a|e) can be estimated by
using the word-based IBM statistical alignment
models (Brown et al, 1993). These models, how-
ever, constrain the set of possible alignments so that
each word in the source sentence can be aligned at
most to one word in the target sentence. Of course,
?real? alignments, in most of the cases, do not fol-
low this limitation. Hence, the alignments obtained
from the IBM models have to be extended in some
way to achieve more realistic alignments. This is
usually performed by computing the alignments in
both directions (i.e, first from f to e and then from
e to f ) and then combining them in a suitable way
(this process is known as symmetrization).
3 Estimation of Distribution Algorithms
Estimation of Distribution Algorithms (EDAs)
(Larran?aga and Lozano, 2001) are metaheuristics
which has gained interest during the last five years
due to their high performance when solving com-
binatorial optimization problems. EDAs, as well
as genetics algorithms (Michalewicz, 1996), are
population-based evolutionary algorithms but, in-
stead of using genetic operators are based on the es-
timation/learning and posterior sampling of a prob-
ability distribution, which relates the variables or
genes forming and individual or chromosome. In
this way the dependence/independence relations be-
tween these variables can be explicitly modelled in
the EDAs framework. The operation mode of a
canonical EDA is shown in Figure 1.
As we can see, the algorithm maintains a popu-
lation of m individuals during the search. An in-
dividual is a candidate or potential solution to the
problem being optimized, e.g., in the problem con-
sidered here an individual would be a possible align-
ment. Usually, in combinatorial optimization prob-
lems an individual is represented as a vector of inte-
gers a = ?a1, . . . , aJ?, where each position aj can
48
1. D0 ? Generate the initial population (m individuals)
2. Evaluate the population D0
3. k = 1
4. Repeat
(a) Dtra ? Select s ? m individuals from Dk?1
(b) Estimate/learn a new modelM from Dtra
(c) Daux ? Sample m individuals fromM
(d) Evaluate Daux
(e) Dk ? Select m individuals from Dk?1 ?Daux
(f) k = k + 1
Until stop condition
Figure 1: A canonical EDA
take a set of finite values ?aj = {0, . . . , I}. The first
step in an evolutionary algorithm is to generate the
initial population D0. Although D0 is usually gener-
ated randomly (to ensure diversity), prior knowledge
can be of utility in this step.
Once we have a population our next step is to
evaluate it, that is, we have to measure the goodness
or fitness of each individual with respect to the prob-
lem we are solving. Thus, we use a fitness function
f(a) = Pr(f ,a|e) (see Eq. (3)) to score individu-
als. Evolutionary algorithms in general and EDAs in
particular seek to improve the quality of the individ-
uals in the population during the search. In genetic
algorithms the main idea is to build a new popula-
tion from the current one by copying some individu-
als and constructing new ones from those contained
in the current population. Of course, as we aim to
improve the quality of the population with respect to
fitness, the best/fittest individuals have more chance
to be copied or selected for recombination.
In EDAs, the transition between populations is
quite different. The basic idea is to summarize
the properties of the individuals in the population
by learning a probability distribution that describes
them as much as possible. Since the quality of the
population should be improved in each step, only
the s fittest individuals are selected to be included in
the dataset used to learn the probability distribution
Pr(a1, . . . ,aJ), in this way we try to discover the
common regularities among good individuals. The
next step is to obtain a set of new individuals by
sampling the learnt distribution. These individuals
are scored by using the fitness function and added to
the ones forming the current population. Finally, the
new population is formed by selecting n individuals
from the 2n contained in the current one. A common
practice is to use some kind of fitness-based elitism
during this selection, in order to guarantee that the
best(s) individual(s) is/are retained.
The main problem in the previous description is
related to the estimation/learning of the probability
distribution, since estimating the joint distribution is
intractable in most cases. In the practice, what is
learnt is a probabilistic model that consists in a fac-
torization of the joint distribution. Different levels
of complexity can be considered in that factoriza-
tion, from univariate distributions to n-variate ones
or Bayesian networks (see (Larran?aga and Lozano,
2001, Chapter 3) for a review). In this paper, as
this is the first approximation to the alignment prob-
lem with EDAs and, because of some questions that
will be discussed later, we use the simplest EDA
model: the Univariate Marginal Distribution Algo-
rithm or UMDA (Muhlenbein, 1997). In UMDA
it is assumed that all the variables are marginally
independent, thus, the n-dimensional probability
distribution, Pr(a1, . . . , aJ), is factorized as the
product of J marginal/unidimensional distributions:?J
j=1 Pr(aj). Among the advantages of UMDA
we can cite the following: no structural learning is
needed; parameter learning is fast; small dataset can
be used because only marginal probabilities have to
be estimated; and, the sampling process is easy be-
cause each variable is independently sampled.
4 Design of an EDA to search for
alignments
In this section, an EDA algorithm to align a source
and a target sentences is described.
4.1 Representation
One of the most important issues in the definition
of a search algorithm is to properly represent the
space of solutions to the problem. In the problem
considered here, we are searching for an ?optimal?
alignment between a source sentence f and a target
sentence e. Therefore, the space of solutions can be
stated as the set of possible alignments between both
sentences. Owing to the constraints imposed by the
IBM models (a word in f can be aligned at most to
one word in e), the most natural way to represent a
49
solution to this problem consists in storing each pos-
sible alignment in a vector a = a1...aJ , being J the
length of f. Each position of this vector can take the
value of ?0? to represent a NULL alignment (that is,
a word in the source sentence that is aligned to no
words in the target sentence) or an index represent-
ing any position in the target sentence. An example
of alignment is shown in Figure 4.1.
Please , I would like to book a roomnull
desearia reservar una habitacion .
.e :
Por favorf : ,
( 0     1     2     4     6     7     8     9 )
Figure 2: Example of alignment and its representa-
tion as a vector
4.2 Evaluation function
During the search process, each individual (search
hypothesis) is scored using the fitness function de-
scribed as follows. Let a = a1 ? ? ? aJ be the align-
ment represented by an individual. This alignment a
is evaluated by computing the probability p(f ,a|e).
This probability is computed by using the IBM
model 4 as:
p(f ,a|e) =
?
(?,pi)??f ,a?
p(?, pi|e)
I?
i=1
n(?i|ei)?
I?
i=1
?i?
k=1
t(?ik|ei)?
I?
i=1,?i>0
d=1(pii1 ? c?i |Ec(e?i),Fc(?i1))?
I?
i=1
?i?
k=2
d>1(piik ? pii(k?1)|Fc(?ik))?
(J ? ?0
?0
)
pJ?2?00 p?01 ?
?0?
k=1
t(?0k|e0) (3)
where the factors separated by ? symbols denote
fertility, translation, head permutation, non-head
permutation, null-fertility, and null-translation prob-
abilities1.
This model was trained using the GIZA++ toolkit
(Och and Ney, 2003) on the material available for the
different alignment tasks described in section 5.1
4.3 Search
In this section, some specific details about the search
are given. As was mentioned in section 3, the algo-
rithm starts by generating an initial set of hypothe-
ses (initial population). In this case, a set of ran-
domly generated alignments between the source and
the target sentences are generated. Afterwards, all
the individuals in this population (a fragment of a
real population is shown in figure 3) are scored using
the function defined in Eq.(4.2). At this point, the
actual search starts by applying the scheme shown
in section 3, thereby leading to a gradual improve-
ment in the hypotheses handled by the algorithm in
each step of the search.
This process finishes when some finalization cri-
terium (or criteria) is reached. In our implementa-
tion, the algorithm finishes when it passes a certain
number of generations without improving the qual-
ity of the hypotheses (individuals). Afterwards, the
best individual in the current population is returned
as the final solution.
Regarding the EDA model, as commented before,
our approach rely on the UMDA model due mainly
to the size of the search space defined by the task.
The algorithm has to deal with individuals of length
J , where each position can take (I + 1) possible
values. Thus, in the case of UMDA, the number of
free parameters to be learnt for each position is I
(e.g., in the English-French task avg(J) = 15 and
avg(I) = 17.3). If more complex models were con-
sidered, the size of the probability tables would have
grown exponentially. As an example, in a bivariate
model, each variable (position) is conditioned on an-
other variable and thus the probability tables P (.|.)
to be learnt have I(I + 1) free parameters. In or-
der to properly estimate the probabilty distributions,
the size of the populations has to be increased con-
siderably. As a result, the computational resources
1The symbols in this formula are: J (the length of e), I (the
length of f ), ei (the i-th word in eI1), e0 (the NULL word), ?i
(the fertility of ei), ?ik (the k-th word produced by ei in a), piik
(the position of ?ik in f ), ?i (the position of the first fertile word
to the left of ei in a), c?i (the ceiling of the average of all pi?ik
for ?i, or 0 if ?i is undefined).
50
1 1 5 3 2 0 6 0 (-60.7500)
1 6 5 2 3 0 0 5 (-89.7449)
1 2 2 6 4 0 5 0 (-90.2221)
1 2 3 5 0 3 6 2 (-99.2313)
0 6 0 2 4 6 3 5 (-99.7786)
2 0 0 2 2 0 3 4 (-100.587)
1 0 1 6 3 6 0 5 (-101.335)
Figure 3: Part of one population generated during
the search for the alignments between the English
sentence and then he tells us the correct result !
and the Romanian sentence si ne spune noua rezul-
tatul corect !. These sentences are part of the HLT-
NAACL 2005 shared task. Some individuals and
their scores (fitness) are shown.
required by the algorithm rise dramatically.
Finally, as was described in section 3, some pa-
rameters have to be fixed in the design of an EDA.
On the one hand, the size of each population must
be defined. In this case, this size is proportional to
the length of the sentences to be aligned. Specifi-
cally, the size of the population adopted is equal to
the length of source sentence f multiplied by a factor
of ten.
On the other hand, as we mentioned in section 3
the probability distribution over the individuals is
not estimated from the whole population. In the
present task about 20% of the best individuals in
each population are used for this purpose.
As mentioned above, the fitness function used in
the algorithm just allows for unidirectional align-
ments. Therefore, the search was conducted in
both directions (i.e, from f to e and from e to
f ) combining the final results to achieve bidirec-
tional alignments. To this end, diffferent approaches
(symmetrization methods) were tested. The results
shown in section 5.2 were obtained by applying the
refined method proposed in (Och and Ney, 2000).
5 Experimental Results
Different experiments have been carried out in or-
der to assess the correctness of the search algorithm.
Next, the experimental metodology employed and
the results obtained are described.
5.1 Corpora and evaluation
Three different corpora and four different test sets
have been used. All of them are taken from the
two shared tasks in word alignments developed in
HLT/NAACL 2003 (Mihalcea and Pedersen, 2003)
and ACL 2005 (Joel Martin, 2005). These two tasks
involved four different pair of languages, English-
French, Romanian-English, English-Inuktitut and
English-Hindi. English-French and Romanian-
English pairs have been considered in these exper-
iments (owing to the lack of timeto properly pre-
process the Hindi and the Inuktitut). Next, a brief
description of the corpora used is given.
Regarding the Romanian-English task, the test
data used to evaluate the alignments consisted in
248 sentences for the 2003 evaluation task and 200
for the 2005 evaluation task. In addition to this, a
training corpus, consisting of about 1 million Ro-
manian words and about the same number of En-
glish word has been used. The IBM word-based
alignment models were training on the whole cor-
pus (training + test). On the other hand, a subset
of the Canadian Hansards corpus has been used in
the English-French task. The test corpus consists of
447 English-French sentences. The training corpus
contains about 20 million English words, and about
the same number of French words. In Table 1, the
features of the different corpora used are shown.
To evaluate the quality of the final alignments ob-
tained, different measures have been taken into ac-
count: Precision, Recall, F-measure, and Alignment
Error Rate. Given an alignment A and a reference
alignment G (both A and G can be split into two
subsets AS ,AP and GS , GP , respectively represent-
ing Sure and Probable alignments) Precision (PT ),
Recall (RT ), F-measure (FT ) and Alignment Error
Rate (AER) are computed as (where T is the align-
ment type, and can be set to either S or P ):
PT = |AT
?GT |
|AT |
RT = |AT
?GT |
|GT |
FT = |2PTRT ||PT +RT |
AER = 1? |AS
?GS |+ |AP
?GP |
|AP |+ |GS |
51
Table 1: Features of the corpora used in the different alignment task
En-Fr Ro-En 03 Ro-En 05
Training size 1M 97K 97K
Vocabulary 68K / 86K 48K / 27K 48K / 27K
Running words 20M / 23M 1.9M / 2M 1.9M / 2M
Test size 447 248 200
It is important to emphasize that EDAs are non-
deterministics algorithms. Because of this, the re-
sults presented in section 5.2 are actually the mean
of the results obtained in ten different executions of
the search algorithm.
5.2 Results
In Tables 2, 3 and 4 the results obtained from the
different tasks are presented. The results achieved
by the technique proposed in this paper are com-
pared with the best results presented in the shared
tasks described in (Mihalcea and Pedersen, 2003)
(Joel Martin, 2005). The results obtained by the
GIZA++ hill-climbing algorithm are also presented.
In these tables, the mean and the variance of the re-
sults obtained in ten executions of the search algo-
rithm are shown. According to the small variances
observed in the results we can conclude that the non-
deterministic nature of this approach it is not statis-
tically significant.
According to these results, the proposed EDA-
based search is very competitive with respect to the
best result presented in the two shared task.
In addition to these results, additional experi-
ments were carried out in to evaluate the actual be-
havior of the search algorithm. These experiments
were focused on measuring the quality of the algo-
rithm, distinguishing between the errors produced
by the search process itself and the errors produced
by the model that leads the search (i.e, the errors in-
troduced by the fitness function). To this end, the
next approach was adopted. Firstly, the (bidirec-
tional) reference alignments used in the computation
of the Alignment Error Rate were split into two sets
of unidirectional alignments. Owing to the fact that
there is no exact method to perform this decomposi-
tion, we employed the method described in the fol-
lowing way. For each reference alignment, all the
possible decompositions into unidirectional align-
ments were perfomed, scoring each of them with
the evaluation function F (a) = p(f ,a|e) defined in
section (3), and being selected the best one, aref .
Afterwards, this alignment was compared with the
solution provided by the EDA, aeda . This com-
parison was made for each sentence in the test set,
being measuried the AER for both alignments as
well as the value of the fitness function. At this
point, we can say that a model-error is produced if
F (aeda) > F (aref ). In addition, we can say that a
search-error is produced if F (aeda) < F (aref ). In
table 5, a summary for both kinds of errors for the
English-Romanian 2005 task is shown. In this table
we can also see that these results correlate with the
AER figures.
These experiments show that most of the errors
were not due to the search process itself but to an-
other different factors. From this, we can conclude
that, on the one hand, the model used to lead the
search should be improved and, on the other, dif-
ferent techniques for symmetrization should be ex-
plored.
6 Conclusions and Future Work
In this paper, a new approach, based on the use of an
Estimation of Distribution Algorithm has been pre-
sented. The results obtained with this technique are
very promising even with the simple scheme here
considered.
According to the results presented in the previ-
ous section, the non-deterministic nature of the algo-
rithm has not a real influence in the performance of
this approach. Therefore, the main theoretical draw-
back of evolutionary algorithms have been proven
not to be an important issue for the task we have ad-
dressed here.
Finally, we are now focusing on the influence of
these improved alignments in the statistical models
for machine translation and on the degree of accu-
52
Table 2: Alignment quality (%) for the English-French task with NULL alignments
System Ps Rs Fs Pp Rp Fp AER
EDA 73.82 82.76 78.04 83.91 29.50 43.36 13.61 ?0.03
GIZA++ 73.61 82.56 77.92 79.94 32.96 46.67 15.89
Ralign.EF1 72.54 80.61 76.36 77.56 36.79 49.91 18.50
XRCE.Nolem.EF.3 55.43 93.81 69.68 72.01 36.00 48.00 21.27
Table 3: Alignment quality (%) for the Romanian-English 2003 task with NULL aligments
System Ps Rs Fs Pp Rp Fp AER
EDA 94.22 49.67 65.05 76.66 60.97 67.92 32.08 ?0.05
GIZA++ 95.20 48.54 64.30 79.89 57.82 67.09 32.91
XRCE.Trilex.RE.3 80.97 53.64 64.53 63.64 61.58 62.59 37.41
XRCE.Nolem-56k.RE.2 82.65 54.12 65.41 61.59 61.50 61.54 38.46
Table 4: Alignment quality (%) for the Romanian-English 2005 task
System Ps Rs Fs Pp Rp Fp AER
EDA 95.37 54.90 69.68 80.61 67.83 73.67 26.33 ?0.044
GIZA++ 95.68 53.29 68.45 81.46 65.83 72.81 27.19
ISI.Run5.vocab.grow 87.90 63.08 73.45 87.90 63.08 73.45 26.55
ISI.Run4.simple.intersect 94.29 57.42 71.38 94.29 57.42 71,38 28.62
ISI.Run2.simple.union 70.46 71.31 70.88 70.46 71.31 70.88 29.12
Table 5: Comparison between reference aligments (decomposed into two unidirectional alignments) and
the alignments provided by the EDA. Search errors and model errors for EDA and GIZA++ algorithms are
presented. In addition, the AER for the unidirectional EDA and reference alignments is also shown. These
result are obtained on the Romanian-English 05 task
Romanian-English English-Romanian
EDA search errors (%) 35 (17.5 %) 18 (9 %)
EDA model errors (%) 165 (82.5 %) 182 (91 %)
GIZA++ search errors (%) 87 (43 %) 81 (40 %)
GIZA++ model errors (%) 113 (57 %) 119 (60 %)
AER-EDA 29.67 % 30.66 %
AER-reference 12.77 % 11.03 %
53
racy that could be achieved by means of these alig-
ments. In addition to this, the integration of the
aligment algorithm into the training process of the
statistical translation models is currently being per-
formed.
References
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The mathematics of statisti-
cal machine translation: Parameter estimation. Comp.
Linguistics, 19(2):263?311.
Ted Pedersen Joel Martin, Rada Mihalcea. 2005. Word
alignment for languages with scarce resources. In
Rada Mihalcea and Ted Pedersen, editors, Proceed-
ings of the ACL Workshop on Building and Exploiting
Parallel Texts: Data Driven Machine Translation and
Beyond, pages 1?10, Michigan, USA, June 31. Asso-
ciation for Computational Linguistics.
P. Larran?aga and J.A. Lozano. 2001. Estimation of
Distribution Algorithms. A New Tool for Evolutionary
Computation. Kluwer Academic Publishers.
Z. Michalewicz. 1996. Genetic Algorithms + Data
Structures = Evolution Programs. Springer-Verlag.
Rada Mihalcea and Ted Pedersen. 2003. An evaluation
exercise for word alignment. In Rada Mihalcea and
Ted Pedersen, editors, HLT-NAACL 2003 Workshop:
Building and Using Parallel Texts: Data Driven Ma-
chine Translation and Beyond, pages 1?10, Edmonton,
Alberta, Canada, May 31. Association for Computa-
tional Linguistics.
Heinz Muhlenbein. 1997. The equation for response
to selection and its use for prediction. Evolutionary
Computation, 5(3):303?346.
Franz J. Och and Hermann Ney. 2000. Improved sta-
tistical alignment models. In ACL00, pages 440?447,
Hongkong, China, October.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
54
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 41?45,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
A Computer Assisted Speech Transcription System
Alejandro Revuelta-Mart??nez, Luis Rodr??guez, Ismael Garc??a-Varea
Computer Systems Department
University of Castilla-La Mancha
Albacete, Spain
{Alejandro.Revuelta,Luis.RRuiz,Ismael.Garcia}@uclm.es
Abstract
Current automatic speech transcription sys-
tems can achieve a high accuracy although
they still make mistakes. In some scenar-
ios, high quality transcriptions are needed
and, therefore, fully automatic systems are
not suitable for them. These high accuracy
tasks require a human transcriber. How-
ever, we consider that automatic techniques
could improve the transcriber?s efficiency.
With this idea we present an interactive
speech recognition system integrated with
a word processor in order to assists users
when transcribing speech. This system au-
tomatically recognizes speech while allow-
ing the user to interactively modify the tran-
scription.
1 Introduction
Speech has been the main mean of communica-
tion for thousands of years and, hence, is the most
natural human interaction mode. For this reason,
Automatic Speech Recognition (ASR) has been
one of the major research interests within the Nat-
ural Language Processing (NLP) community.
Although current speech recognition ap-
proaches (which are based on statistical learning
theory (Jelinek, 1998)) are speaker independent
and achieve high accuracy, ASR systems are not
perfect and transcription errors rise drastically
when considering large vocabularies, dealing
with noise environments or spontaneous speech.
In those tasks (as for example, automatic tran-
scription of parliaments proceedings) where
perfect recognition results are required, ASR
can not be fully reliable so far and, a human
transcriber has to check and supervise the
automatically generated transcriptions.
In the last years, cooperative systems, where
a human user and an automatic system work to-
gether, have gain growing attention. Here we
present a system that interactively assists a human
transcriber when using an ASR software. The
proposed tool is fully embedded into a widely
used and open source word processor and it relies
on an ASR system that is proposing suggestions to
the user in the form of practical transcriptions for
the input speech. The user is allowed to introduce
corrections at any moment of the discourse and,
each time an amendment is performed, the sys-
tem will take it into account in order to propose a
new transcription (always preserving the decision
made by the user, as can be seen in Fig. 1). The
rationale behind this idea is to reduce the human
user?s effort and increase efficiency.
Our proposal?s main contribution is that it car-
ries out an interactive ASR process, continually
proposing new transcriptions that take into ac-
count user amendments to increase their useful-
ness. To our knowledge, no current transcription
package provides such an interactive process.
2 Theoretical Background
Computer Assisted Speech Recognition (CAST)
can be addressed by extending the statistical ap-
proach to ASR. Specifically, we have an input
signal to be transcribed x and the user feedback
in the form of a fully correct transcription pre-
fix p (an example of a CAST session is shown
in Fig. 1). From this, the recognition system has
to search for the optimal completion (suffix) s? as:
s? = argmax
s
Pr(s | x,p)
= argmax
s
Pr(x | p, s) ? Pr(s | p) (1)
41
where, as in traditional ASR, we have an acous-
tic model Pr(x | p, s) and a language model
Pr(s | p). The main difference is that, here,
part of the correct transcription is available (pre-
fix) and we can use this information to improve
the suffix recognition. This can be achieved by
properly adapting the language model to account
for the user validated prefix as it is detailed in
(Rodr??guez et al 2007; Toselli et al 2011).
As was commented before, the main goal of
this approach is to improve the efficiency of the
transcription process by saving user keystrokes.
Off-line experiments have shown that this ap-
proach can save about 30% of typing effort when
compared to the traditional approach of off-line
post-editing results from an ASR system.
3 Prototype Description
A fully functional prototype, which implements
the CAST techniques described in section 2, has
been developed. The main goal is to provide a
completely usable tool. To this end, we have im-
plemented a tool that easily allows for organiz-
ing and accessing different transcription projects.
Besides, the prototype has been embedded into a
widely used office suite. This way, the transcribed
document can be properly formatted since all the
features provided by a word processor are avail-
able during the transcription process.
3.1 Implementation Issues
The system has been implemented following a
modular architecture consisting of several compo-
nents:
? User interface. Manages the graphical fea-
tures of the prototype user interface.
? Project management: Allows the user to
define and deal with transcription projects.
These projects are stored in XML files con-
taining parameters such as input files to be
transcribed, output documents, etc.
? System controller. Manages communication
among all the components.
? OpenOffice integration: This subsystem pro-
vides an appropriate integration between the
CAST tool and the OpenOffice1 software
suite. The transcriber has, therefore, full ac-
cess to a word processor functionality.
1www.openoffice.org
? Speech manager: Implements audio play-
back and synchronization with the ASR out-
comes.
? CAST engine: Provides the interactive ASR
suggestion mechanism.
This architecture is oriented to be flexible and
portable so that different scenarios, word proces-
sor software or ASR engines can be adopted with-
out requiring big changes in the current imple-
mentation. Although this initial prototype works
as a standalone application the followed design
should allow for a future ?in the cloud? tool,
where the CAST engine is located in a server and
the user can employ a mobile device to carry out
the transcription process.
With the purpose of providing a real-time sys-
tem response, CAST is actually performed over
a set of word lattices. A lattice, representing a
huge set of hypotheses for the current utterance,
is initially used to parse the user validated prefix
and then to search for the best completion (sug-
gestion).
3.2 System Interface and Usage
The prototype has been designed to be intuitive
for professional speech transcribers and general
users; we expect most users to quickly get used
to the system without any previous experience or
external assistance.
The prototype features and operation mode are
described in the following items:
? The initial screen (Fig. 2) guides the user on
how to address a transcription project. Here,
the transcriber can select one of the three
main tasks that have to be performed to ob-
tain the final result.
? In the project management screen (Fig. 3),
the user can interact with the current projects
or create a new one. A project is a set of
input audio files to be transcribed along with
the partial transcription achieved and some
other related parameters.
? Once the current project has been selected, a
transcription session is started (Fig. 4). Dur-
ing this session, the application looks like a
standard OpenOffice word processor incor-
porating CAST features. Specifically, the
user can perform the following operations:
42
utterance
ITER-0 prefix ( )
ITER-1
suffix (Nine extra soul are planned half beam discovered these years)
validated (Nine)
correction (extrasolar)
prefix (Nine extrasolar)
ITER-2
suffix (planets have been discovered these years)
validated (planets have been discovered)
correction (this)
prefix (Nine extrasolar planets have been discovered this)
FINAL
suffix (year)
validated (#)
prefix (Nine extrasolar planets have been discovered this year)
Figure 1: Example of a CAST session. In each iteration, the system suggests a suffix based on the input utterance
and the previous prefix. After this, the user can validate part of the suggestion and type a correction to generate
a new prefix that can be used in the next iteration. This process is iterated until the full utterance is transcribed.
The user can move between audio segments
by pressing the ?fast forward? and ?rewind?
buttons. Once the a segment to be tran-
scribed has been chosen, the ?play? button
starts the audio replay and transcription. The
system produces the text in synchrony with
the audio so that the user can check in ?real
time? the proposed transcription. As soon as
a mistake is produced, the transcriber can use
the ?pause? button to interrupt the process.
Then, the error is corrected and by pressing
?play? again the process is continued. At
this point, the CAST engine will use the user
amendment to improve the rest of the tran-
scription.
? When all the segments have been tran-
scribed, the final task in the initial screen al-
lows the user to open the OpenOffice?s PDF
export dialog to generate the final document.
A video, showing the prototype operation
mode, can be found on the following website:
www.youtube.com/watch?v=vc6bQCtYVR4.
4 Conclusions and Future Work
In this paper we have presented a CAST system
which has been fully implemented and integrated
into the OpenOffice word processing software.
The implemented techniques have been tested of-
fline and the prototype has been presented to a re-
duced number of real users.
Preliminary results suggest that the system
could be useful for transcribers when high qual-
ity transcriptions are needed. It is expected to
save effort, increase efficiency and allow inexperi-
enced users to take advantage of ASR systems all
along the transcription process. However, these
results should be corroborated by performing a
formal usability evaluation.
Currently, we are in the process of carrying out
a formal usability evaluation with real users that
has been designed following the ISO/IEC 9126-4
(2004) standard according to the efficiency, effec-
tiveness and satisfaction characteristics.
As future work, it will be interesting to consider
concurrent collaborative work at both, project and
transcription levels. Other promising line is to
consider a multimodal user interface in order to
allow users to control the playback and transcrip-
tion features using their own speech. This has
been explored in the literature (Rodr??guez et al
2010) and would allow the system to be used in
devices with constrained interfaces such as mo-
bile phones or tablet PCs.
Acknowledgments
Work supported by the EC (ERDF/ESF) and
the Spanish government under the MIPRCV
?Consolider Ingenio 2010? program (CSD2007-
00018), and the Spanish Junta de Comunidades
de Castilla-La Mancha regional government un-
der projects PBI08-0210-7127 and PPII11-0309-
6935.
43
Figure 2: Main window prototype. The three stages of a transcription project are shown.
Figure 3: Screenshot of the project management window showing a loaded project. A project consists of several
audio segments, each of them is stored in a file so that the user can easily add or remove files when needed. In
this screen the user can choose the current working segments.
Figure 4: Screenshot of a transcription session. This shows the process of transcribing one audio segment. In this
figure, all the text but the last incomplete sentence has already been transcribed and validated. The last partial
sentence, shown in italics, is being produced by the ASR system while the transcriber listen to the audio. As
soon as an error is detected the user momentarily interrupts the process to correct the mistake. Then, the system
will continue transcribing the audio according to the new user feedback (prefix).
44
References
ISO/IEC 9126-4. 2004. Software engineering ?
Product quality ? Part 4: Quality in use metrics.
F. Jelinek. 1998. Statistical Methods for Speech
Recognition. The MIT Press, Cambridge, Mas-
sachusetts, USA.
Luis Rodr??guez, Francisco Casacuberta, and Enrique
Vidal. 2007. Computer assisted transcription of
speech. In Proceedings of the 3rd Iberian confer-
ence on Pattern Recognition and Image Analysis,
Part I, IbPRIA ?07, pages 241?248, Berlin, Heidel-
berg. Springer-Verlag.
Luis Rodr??guez, Ismael Garc??a-Varea, and Enrique Vi-
dal. 2010. Multi-modal computer assisted speech
transcription. In Proceedings of the 12th Interna-
tional Conference on Multimodal Interfaces and the
7th International Workshop on Machine Learning
for Multimodal Interaction, ICMI-MLMI.
A.H. Toselli, E. Vidal, and F. Casacuberta. 2011. Mul-
timodal Interactive Pattern Recognition and Appli-
cations. Springer.
45
