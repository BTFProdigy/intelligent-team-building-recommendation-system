Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1567?1578, Dublin, Ireland, August 23-29 2014.
The Wisdom of Minority: Unsupervised Slot Filling Validation based on
Multi-dimensional Truth-Finding
Dian Yu
1
, Hongzhao Huang
1
, Taylor Cassidy
2,3
, Heng Ji
1
Chi Wang
4
, Shi Zhi
4
, Jiawei Han
4
, Clare Voss
2
, Malik Magdon-Ismail
1
1
Computer Science Department, Rensselaer Polytechnic Institute
2
U.S. Army Research Lab
3
IBM T. J. Watson Research Center
4
Computer Science Department, Univerisity of Illinois at Urbana-Champaign
1
{yud2,huangh9,jih,magdon}@rpi.edu,
2,3
{taylor.cassidy.ctr,clare.r.voss.civ}@mail.mil
4
{chiwang1,shizhi2,hanj}@illinois.edu
Abstract
Information Extraction using multiple information sources and systems is beneficial due to multi-
source/system consolidation and challenging due to the resulting inconsistency and redundancy.
We integrate IE and truth-finding research and present a novel unsupervised multi-dimensional
truth finding framework which incorporates signals from multiple sources, multiple systems and
multiple pieces of evidence by knowledge graph construction through multi-layer deep linguistic
analysis. Experiments on the case study of Slot Filling Validation demonstrate that our approach
can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (finding
90% truths with only one half the cost of a baseline without credibility estimation).
1 Introduction
Traditional Information Extraction (IE) techniques assess the ability to extract information from
individual documents in isolation. However, similar, complementary or conflicting information may
exist in multiple heterogeneous sources. We take the Slot Filling Validation (SFV) task of the NIST Text
Analysis Conference Knowledge Base Population (TAC-KBP) track (Ji et al., 2011) as a case study. The
Slot Filling (SF) task aims at collecting from a large-scale multi-source corpus the values (?slot fillers?)
for certain attributes (?slot types?) of a query entity, which is a person or some type of organization. KBP
2013 has defined 25 slot types for persons (per) (e.g., age, spouse, employing organization) and 16 slot
types for organizations (org) (e.g., founder, headquarters-location, and subsidiaries). Some slot types
take only a single slot filler (e.g., per:birthplace), whereas others take multiple slot fillers (e.g., org:top
employees).
We call a combination of query entity, slot type, and slot filler a claim. Along with each claim, each
system must provide the ID of a source document and one or more detailed context sentences as evidence
which supports the claim. A response (i.e., a claim, evidence pair) is correct if and only if the claim is
true and the evidence supports it.
Given the responses produced by multiple systems from multiple sources in the SF task, the goal of
the SFV task is to determine whether each response is true or false. Though it?s a promising line of
research, it raises two complications: (1) different information sources may generate claims that vary
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1567
in trustability; and (2) a large-scale number of SF systems using different resources and algorithms may
generate erroneous, conflicting, redundant, complementary, ambiguously worded, or inter-dependent
claims from the same set of documents. Table 1 presents responses from four SF systems for the query
entity Ronnie James Dio and the slot type per:city of death. Systems A, B and D return Los Angeles
with different pieces of evidence
1
extracted from different information sources, though the evidence of
System D does not decisively support the claim. System C returns Atlantic City, which is neither true
nor supported by the corresponding evidence.
Such complications call for ?truth finding?: determining the veracity of multiple conflicting claims
from various sources and systems. We propose a novel unsupervised multi-dimensional truth finding
framework to study credibility perceptions in rich and wide contexts. It incorporates signals from
multiple sources and systems, using linguistic indicators derived from knowledge graphs constructed
from multiple evidences using multi-layer deep linguistic analysis. Experiments demonstrate that our
approach can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (find
90% truths with only one half cost of a baseline without credibility estimation).
System Source Slot Filler Evidence
A Agence France-
Presse, News
Los Angeles The statement was confirmed by publicist Maureen O?Connor, who said Dio
died in Los Angeles.
B New York
Times, News
Los Angeles Ronnie James Dio, a singer with the heavy-metal bands Rainbow, Black
Sabbath and Dio, whose semioperatic vocal style and attachment to demonic
imagery made him a mainstay of the genre, died on Sunday in Los Angeles.
C Discussion Fo-
rum
Atlantic City Dio revealed last summer that he was suffering from stomach cancer shortly
after wrapping up a tour in Atlantic City.
D Associated
Press
Worldstream,
News
Los Angeles LOS ANGELES 2010-05-16 20:31:18 UTC Ronnie James Dio, the metal god
who replaced Ozzy Osbourne in Black Sabbath and later piloted the bands
Heaven, Hell and Dio, has died, according to his wife and manager.
Table 1: Conflicting responses across different SF systems and different sources (query entity = Ronnie
James Dio, slot type = per:city of death).
2 Related Work & Our Novel Contributions
Most previous SFV work (e.g., (Tamang and Ji, 2011; Li and Grishman, 2013)) focused on filtering
incorrect claims from multiple systems by simple heuristic rules, weighted voting, or costly supervised
learning to rank algorithms. We are the first to introduce the truth finding concept to this task.
The ?truth finding? problem has been studied in the data mining and database communities (e.g., (Yin
et al., 2008; Dong et al., 2009a; Dong et al., 2009b; Galland et al., 2010; Blanco et al., 2010; Pasternack
and Roth, 2010; Yin and Tan, 2011; Pasternack and Roth, 2011; Vydiswaran et al., 2011; Ge et al.,
2012; Zhao et al., 2012; Wang et al., 2012; Pasternack and Roth, 2013)). Compared with the previous
work, our truth finding problem is defined under a unique setting: each response consists of a claim and
supporting evidence, automatically generated from unstructured natural language texts by a SF system.
The judgement of a response concerns both the truth of the claim and whether the evidence supports
the claim. This has never been modeled before. We mine and exploit rich linguistic knowledge from
multiple lexical, syntactic and semantic levels from evidence sentences for truth finding. In addition,
previous truth finding work assumed most claims are likely to be true. However, most SF systems have
hit a performance ceiling of 35% F-measure, and false responses constitute the majority class (72.02%)
due to the imperfect algorithms as well as the inconsistencies of information sources. Furthermore,
certain truths might only be discovered by a minority of good systems or from a few good sources. For
example, 62% of the true responses are produced only by 1 or 2 of the 18 SF systems.
1
Hereafter, we refer to ?pieces of evidence? with the shorthand ?evidences?. Note that SF systems may include multiple
sentences as ?evidence? within their responses.
1568
r1 
      Response 
<Claim, Evidence> 
t1 
t2 
System 
s1 
r2 
r3 
s2 
Source 
t3 
r4 t4 
s3 
r5 
Figure 1: Heterogeneous networks for MTM.
3 MTM: A Multi-dimensional Truth-Finding Model
MTM Construction
A response is trustworthy if its claim is true and its evidence supports the claim. A trusted
source always supports true claims by giving convincing evidence, and a good system tends to extract
trustworthy responses from trusted sources. We propose a multi-dimensional truth-finding model (MTM)
to incorporate and compute multi-dimensional credibility scores.
Consider a set of responses R = {r
1
, . . . , r
m
} extracted from a set of sources S = {s
1
, . . . , s
n
} and
provided by a set of systems T = {t
1
, . . . , t
l
}. A heterogeneous network is constructed as shown in
Fig. 1. Let weight matrices be W
rs
m?n
= {w
rs
ij
} and W
rt
m?l
= {w
rt
ik
}. A link w
rs
ij
= 1 is generated
between r
i
and s
j
when response r
i
is extracted from source s
j
, and a link w
rt
ik
= 1 is generated between
r
i
and t
k
when response r
i
is provided by system t
k
.
Credibility Initialization
Each source is represented as a combination of publication venue and genre. The credibility scores
of sources S are initialized uniformly as
1
n
, where n is the number of sources. Given the set of systems
T = {t
1
, . . . , t
l
}, we initialize their credibility scores c
0
(t) based on their interactions on the predicted
responses. Suppose each system t
i
generates a set of responses R
t
i
. The similarity between two systems
t
i
and t
j
is defined as similarity(t
i
, t
j
) =
|R
t
i
?R
t
j
|
log (|R
t
i
|)+log (|R
t
j
|)
(Mihalcea, 2004). Then we construct a
weighted undirected graph G = ?T,E?, where T (G) = {t
1
, . . . , t
l
} and E(G) = {?t
i
, t
j
?}, ?t
i
, t
j
? =
similarity(t
i
, t
j
), and apply the TextRank algorithm (Mihalcea, 2004) on G to obtain c
0
(t).
We got negative results by initializing system credibility scores uniformly. We also got negative results
by initializing system credibility scores using system metadata, such as the algorithms and resources the
system used at each step, its previous performance in benchmark tests, and the confidence values it
produced for its responses. We found the quality of an SF system depends on many different resources
instead of any dominant one. For example, an SF system using a better dependency parser does not
necessarily produce more truths. In addition, many systems are actively being improved, rendering
previous benchmark results unreliable. Furthermore, most SF systems still lack reliable confidence
estimation.
The initialization of the credibility scores for responses relies on deep linguistic analysis of the
evidence sentences and the exploitation of semantic clues, which will be described in Section 4.
Credibility Propagation
1569
We explore the following heuristics in MTM.
HEURISTIC 1: A response is more likely to be true if derived from many trustworthy sources. A source
is more likely to be trustworthy if many responses derived from it are true.
HEURISTIC 2: A response is more likely to be true if it is extracted by many trustworthy systems. A
system is more likely to be trustworthy if many responses generated by it are true.
Based on these two heuristics we design the following credibility propagation approach to mutually
reinforce the trustworthiness of linked objects in MTM.
By extension of Co-HITS (Deng et al., 2009), designed for bipartite graphs, we develop a propagation
method to handle heterogeneous networks with three types of objects: source, response and system. Let
the weight matrices beW
rs
(between responses and sources) andW
rt
(between responses and systems),
and their transposes beW
sr
andW
tr
. We can obtain the transition probability that vertex s
i
in S reaches
vertex r
j
in R at the next iteration, which can be formally defined as a normalized weight p
sr
ij
=
w
sr
ij?
k
w
sr
ik
such that
?
r
j
?R
p
sr
ij
= 1. We compute the transition probabilities p
rs
ji
, p
rt
jk
and p
tr
kj
in an analogous
fashion.
Given the initial credibility scores c
0
(r), c
0
(s) and c
0
(t), we aim to obtain the refined credibility scores
c(r), c(s) and c(t) for responses, sources, and systems, respectively. Starting with sources, the update
process considers both the initial score c
0
(s) and the propagation from connected responses, which we
formulated as:
c(s
i
) = (1? ?
rs
)c
0
(s
i
) + ?
rs
?
r
j
?R
p
rs
ji
c(r
j
) (1)
Similarly, the propagation from responses to systems is formulated as:
c(t
k
) = (1? ?
rt
)c
0
(t
k
) + ?
rt
?
r
j
?R
p
rt
jk
c(r
j
) (2)
Each response?s score c(r
j
) is influenced by both linked sources and systems:
c(r
j
) = (1? ?
sr
? ?
tr
)c
0
(r
j
) + ?
sr
?
s
i
?S
p
sr
ij
c(s
i
) + ?
tr
?
t
k
?T
p
tr
kj
c(t
k
) (3)
where ?
rs
, ?
rt
, ?
sr
and ?
tr
? [0, 1]. These parameters control the preference for the propagated over
initial score for every type of random walk link. The larger they are, the more we rely on link structure
2
.
The propagation algorithm converges (10 iterations in our experimental settings) and a similar theoretical
proof to HITS (Peserico and Pretto, 2009) can be constructed. Algorithm 1 summarizes MTM.
4 Response Credibility Initialization
Each evidence along with a claim is expressed as a few natural language sentences that include the query
entity and the slot filler, along with semantic content to support the claim. We analyze the evidence of
each response in order to initialize that response?s credibility score. This is done using heuristic rules
defined in terms of the binary outputs of various linguistic indicators (Section 4.1).
4.1 Linguistic Indicators
We encode linguistic indicators based on deep linguistic knowledge acquisition and use them to
determine whether responses provide supporting clues or carry negative indications (Section 4.3). These
indicators make use of linguistic features on varying levels - surface form, sentential syntax, semantics,
and pragmatics - and are defined in terms of knowledge graphs (Section 4.2). We define a heuristic rule
for each slot type in terms of the binary-valued linguistic indicator outputs to yield a single binary value
(1 or 0) for each response. If a response?s linguistic indicator value is 1, the credibility score of a response
is initialized at 1.0, and 0.5 otherwise.
2
We set ?
rs
= 0.9, ?
sr
= 0.1, ?
rt
= 0.3 and ?
tr
= 0.2, optimized from a development set. See Section 5.1.
1570
Input: A set of responses (R), sources (S) and systems (T ).
Output: Credibility scores (c(r)) for R.
1: Initialize the credibility scores c
0
(s) for S as c
0
(s
i
) =
1
|S|
;
2: Use TextRank to compute initial credibility scores c
0
(t) for T ;
3: Initialize the credibility scores c
0
(r) using linguistic indicators (Section 4);
4: Construct heterogeneous networks across R, S and T ;
5: k ? 0, diff? 10e6;
6: while k < MaxIteration and diff > MinThreshold do
7: Use Eq. (1) to compute c
k+1
(s);
8: Use Eq. (2) to compute c
k+1
(t);
9: Use Eq. (3) to compute c
k+1
(r);
10: Normalize c
k+1
(s), c
k+1
(t), and c
k+1
(r);
11: diff?
?
(|c
k+1
(r)? c
k
(r)|);
12: k ? k + 1
13: end while
Algorithm 1:Multi-dimensional Truth-Finding.
4.2 Knowledge Graph Construction
A semantically rich knowledge graph is constructed that links a query entity, all of its relevant slot
filler nodes, and nodes for other intermediate elements excerpted from evidence sentences. There is one
knowledge graph per sentence.
Fig. 2 shows a subregion of the knowledge graph built from the sentence: ?Mays, 50, died in his sleep
at his Tampa home the morning of June 28.?. It supports 3 claims: [Mays, per: city of death, Tampa],
[Mays, per: date of death, 06/28/2009] and [Mays, per: age, 50].
Formally, a knowledge graph is an annotated graph of entity mentions, phrases and their links. It must
contain one query entity node and one or more slot filler nodes. The annotation of a node includes its
entity type, subtype, mention type, referent entities, and semantic category (though not every node has
each type of annotation). The annotation of a link includes a dependency label and/or a semantic relation
between the two linked nodes.
The knowledge graph is constructed using the following procedure. First, we annotate the evidence
text using dependency parsing (Marneffe et al., 2006) and Information Extraction (entity, relation and
event) (Li et al., 2013; Li and Ji, 2014). Two nodes are linked if they are deemed related by one of the
annotation methods (e.g., [Mays, 50] is labeled with the dependency type amod, and [home, Tampa] is
labeled with the semantic relation located in). The annotation output is often in terms of syntactic heads.
Thus, we extend the boundaries of entity, time, and value mentions (e.g., people?s titles) to include an
entire phrase where possible. We then enrich each node with annotation for entity type, subtype and
mention type. Entity type and subtype refer to the role played by the entity in the world, the latter being
more fine-grained, whereas mention type is syntactic in nature (it may be pronoun, nominal, or proper
name). For example, ?Tampa? in Fig. 2 is annotated as a Geopolitical (entity type) Population-Center
(subtype) Name (mention type) mention. Every time expression node is annotated with its normalized
reference date (e.g., ?June, 28? in Fig. 2 is normalized as ?06/28/2009?).
Second, we perform co-reference resolution, which introduces implicit links between nodes that refer
to the same entity. Thus, an entity mention that is a nominal or pronoun will often be co-referentially
linked to a mention of a proper name. This is important because many queries and slot fillers are
expressed only as nominal mentions or pronouns in evidence sentences, their canonical form appearing
elsewhere in the document.
Finally, we address the fact that a given relation type may be expressed in a variety of ways. For
example, ?the face of ? indicates the membership relation in the following sentence: ?Jennifer Dunn was
the face of the Washington state Republican Party for more than two decades.? We mined a large
1571
Mays 
had 
died 
sleep 
his 
home 
Tampa 
50 
June,28 
amod 
nsubj 
aux 
prep_in 
poss 
prep_at 
prep_of 
nn 
poss 
  located_in 
{PER.Individual, NAM, Billy Mays} 
?Query? 
{NUM } 
?Per:age? 
{Death-Trigger} 
{PER.Individual.PRO, Mays} 
{GPE.Population-Center.NAM, FL-USA} 
? Per:place_of_death? 
{FAC.Building-Grounds.NOM} 
{06/28/2009, TIME-WITHIN}  
? per:date_of_death? 
Figure 2: Knowledge Graph Example.
number of trigger phrases for each slot type by mapping various knowledge bases, including Wikipedia
Infoboxes, Freebase (Bollacker et al., 2008), DBPedia (Auer et al., 2007) and YAGO (Suchanek et
al., 2007), into the Gigaword corpus
3
and Wikipedia articles via distant supervision (Mintz et al.,
2009)
4
. Each intermediate node in the knowledge graph that matches a trigger phrase is then assigned a
corresponding semantic category. For example, ?died? in Fig. 2 is labeled a Death-Trigger.
4.3 Knowledge Graph-Based Verification
We design linguistic indicators in terms of the properties of nodes and paths that are likely to be bear on
the response?s veracity. Formally, a path consists of the list of nodes and links that must be traversed
along a route from a query node to a slot filler node.
Node indicators contribute information about a query entity or slot filler node in isolation, that
may bear on the trustworthiness of the containing evidence sentence. For instance, a slot filler for the
per:date of birth slot type must be a time expression.
Node Indicators
1. Surface: Whether the slot filler includes stop words; whether it is lower cased but appears in news.
These serve as negative indicators.
2. Entity type, subtype and mention type: For example, the slot fillers for ?org:top employees? must be
person names; and fillers for ?org:website? must match the url format. Besides the entity extraction
system, we also exploited the entity attributes mined by the NELL system (Carlson et al., 2010)
from the KBP source corpus.
Each path contains syntactic and/or semantic relational information that may shed light on the manner
in which the query entity and slot filler are related, based on dependency parser output, IE output,
and trigger phrase labeling. Path indicators are used to define properties of the context in which
which query-entity and slot-filler are related in an evidence sentence. For example, whether the path
3
http://catalog.ldc.upenn.edu/LDC2011T07
4
Under the distant supervision assumption, sentences that appear to mention both entities in a binary relation contained in
the knowledge base were assumed to express that relation.
1572
associated with a claim about an organization?s top employee includes a title commonly associated with
decision-making power can be roughly represented using the trigger phrases indicator.
Path Indicators
1. Trigger phrases: Whether the path includes any trigger phrases as described in Section 4.2.
2. Relations and events: Whether the path includes semantic relations or events indicative of the slot
type. For example, a ?Start-Position? event indicates a person becomes a ?member? or ?employee?
of an organization.
3. Path length: Usually the length of the dependency path connecting a query node and a slot filler
node is within a certain range for a given slot type. For example, the path for ?per:title? is usually
no longer than 1. A long dependency path between the query entity and slot filler indicates a lack
of a relationship. In the following evidence sentence, which does not entail the ?per:religion?
relation between ?His? and the religion ?Muslim?, there is a long path (?his-poss-moment-nsubj-
came-advcl-seized-militant-acmod-Muslim?): ?His most noticeable moment in the public eye came
in 1979, when Muslim militants in Iran seized the U.S. Embassy and took the Americans stationed
there hostage.?.
Detecting and making use of interdependencies among various claims is another unique challenge in
SFV. After initial response credibility scores are calculated by combining linguistic indicator values, we
identify responses that have potentially conflicting or potentially supporting slot-filler candidates. For
such responses, their credibility scores are changed in accordance with the binary values returned by the
following indicators.
Interdependent Claims Indicators
1. Conflicting slot fillers: When fillers for two claims with the same query entity and slot type appear
in the same evidence sentence, we apply an additional heuristic rule designed for the slot type in
question. For example, the following evidence sentence indicates that compared to ?Cathleen P.
Black?, ?Susan K. Reed? is more likely to be in a ?org:top employees/members? relation with ?The
Oprah Magazine? due to the latter pair?s shorter dependency path: ?Hearst Magazine?s President
Cathleen P. Black has appointed Susan K. Reed as editor-in-chief of the U.S. edition of The
Oprah Magazine.?. The credibility scores are accordingly changed (or kept at) 0.5 for responses
associated with the former claim, and 1.0 for those associated with the latter.
2. Inter-dependent slot types: Many slot types are inter-dependent, such as ?per:title? and
?per:employee of ?, and various family slots. After determining initial credibility scores for each
response, we check whether evidence exists for any implied claims. For example, given initial
credibility scores of 1.0 for two responses supporting the claims that (1)?David? is ?per:children?
of ?Carolyn Goodman? and (2)?Andrew? is ?per:sibling? of ?David?, we check for any responses
supporting the claim that (3)?Andrew? is ?per:children? of ?Carolyn Goodman?, and set their
credibility scores to 1.0. For example, a response supporting this claim included the evidence
sentence, ?Dr. Carolyn Goodman, her husband, Robert, and their son, David, said goodbye to
David?s brother, Andrew.?.
5 Experimental Results
This section presents the experiment results and analysis of our approach.
5.1 Data
The data set we use is from the TAC-KBP2013 Slot Filling Validation (SFV) task, which consists of the
merged responses returned by 52 runs (regarded as systems in MTM) from 18 teams submitted to the Slot
1573
Methods Precision Recall F-measure Accuracy Mean Average Precision
1.Random 28.64% 50.48% 36.54% 50.54% 34%
2.Voting 42.16% 70.18% 52.68% 62.54% 62%
3.Linguistic Indicators 50.24% 70.69% 58.73% 72.29% 60%
4.SVM (3 + System + Source) 56.59% 48.72% 52.36% 75.86% 56%
5.MTM (3 + System + Source) 53.94% 72.11% 61.72% 81.57% 70%
Table 2: Overall Performance Comparison.
Filling (SF) task. The source collection has 1,000,257 newswire documents, 999,999 web documents
and 99,063 discussion forum posts, which results in 10 different sources (combinations of publication
venues and genres) in our experiment. There are 100 queries: 50 person and 50 organization entities.
After removing redundant responses within each single system run, we use 45,950 unique responses as
the input to truth-finding. Linguistic Data Consortium (LDC) human annotators manually assessed all
of these responses and produced 12,844 unique responses as ground truth. In order to compare with
state-of-the-art supervised learning methods for SFV (Tamang and Ji, 2011; Li and Grishman, 2013), we
trained a SVMs classifier
5
as a counterpart, incorporating the same set of linguistic indicators, sources
and systems as features. We picked 10% (every 10th line) to compose the development set for MTM and
the training set for the SVMs. The rest is used for blind test.
5.2 Overall Performance
Table 2 shows the overall performance of various truth finding methods on judging each response as true
or false. MTM achieves promising results and even outperforms supervised learning approach. Table 3
presents some examples ranked at the top and the bottom based on the credibility scores produced by
MTM.
We can see that majority voting across systems performs much better than random assessment, but its
accuracy is still low. For example, the true claim T5 was extracted by only one system because most
systems mistakenly identified ?Briton Stuart Rose? as a person name. In comparison, MTM obtained
much better accuracy by also incorporating multiple dimensions of source and evidence information.
Method 3 using linguistic indicators alone, already achieved promising results. For example, many
claims are judged as truths through trigger phrases (T1 and T5), event extraction (T2), coreference (T4),
and node type indicators (T3). On the other hand, many claims are correctly judged as false because
their evidence sentences did not include the slot filler (F1, F4, F5) or valid knowledge paths to connect
the query entity and the slot filler (F2, F3). The performance gain (2.99% F-score) from Method 3 to
Method 5 shows the need for incorporating system and source dimensions. For example, most truths are
from news while many false claims are from newsgroups and discussion forum posts (F1, F2, F5).
The SVMs model got very low recall because of the following two reasons: (1) It ignored the inter-
dependency between multiple dimensions; (2) the negative instances are dominant in the training data,
so the model is biased towards labeling responses as false.
5.3 Truth Finding Efficiency
Table 3 shows that some truths (T1) are produced from low-ranked systems whereas some false responses
from high-ranked systems (F1, F2). Note that systems are ranked by their performance in KBP SF task.
In order to find all the truths, human assessors need to go through all the responses returned by multiple
systems. This process was proven very tedious and costly (Ji et al., 2010; Tamang and Ji, 2011).
Our MTM approach can expedite this process by ranking responses based on their credibility scores
and asking human to assess the responses with high credibility first. Traditionally, when human assess
responses, they follow an alphabetical order or system IDs in a ?passive learning? style. This is set as
our baseline. For comparison, we also present the results using only linguistic indicators, using voting
in which the responses which get more votes across systems are assessed first, and the oracle method
assessing all correct responses first. Table 2 shows our model can successfully rank trustworthy responses
at high positions compared with other approaches.
5
We used the LIBSVM toolkit (Chang and Lin, 2011) with Gaussian radial basis function kernel.
1574
Response Ranked by MTM
Source
System
Rank
Claim
Evidence
Query Entity Slot Type Slot Filler
Top
Truths
T1 China
Banking
Regulatory
Commission
org:top
member-
s/employees
Liu
Mingkang
Liu Mingkang, the chairman of
the China Banking Regulatory
Commission
Central
News
Agency
of Taiwan
News
News 15
T2 Galleon
Group
org:founded
by
Raj
Rajaratnam
Galleon Group, founded by bil-
lionaire Raj Rajaratnam
New York
Times
News 9
T3 Mike Penner per:age 52 L.A. Times Sportswriter Mike
Penner, 52, Dies
New York
Times
News 1
T4 China
Banking
Regulatory
Commission
org:alternate
names
CBRC ...China Banking Regulatory Com-
mission said in the notice. The five
banks ... according to CBRC.
Xinhua,
News
News 5
T5 Stuart Rose per:origin Briton Bolland, 50, will replace Briton
Stuart Rose at the start of 2010.
Agence
France-
Presse
News 3
Bottom
False
Claims
F1 American
Association
for the Ad-
vancement of
Science
org:top
members
employees
Freedman erica.html &gt; American Library
Association, President: Maurice
Freedman &lt; http://www.aft.org
&gt; American Federation of
Teachers ...
Google Newsgroup4
F2 Jade Goody per:origin Britain because Jade Goody?s the only
person to ever I love Britain
Discussion Forum 3
F3 Don Hewitt per:spouse Swap ...whether ?Wife Swap? on ABC
or ?Jon &amp; Kate? on TLC
New York
Times
News 7
F4 Council of
Mortgage
Lenders
org:website www.cml.org.ukme purchases in the U.K. jumped
by 16 percent in April, suggesting
the property market slump may
have bottomed out
Associated
Press
World-
stream
News 18
F5 Don Hewitt per:alternate
names
Hewitt M-
chen
US DoMIna THOMPson LACtaTe
haVeD [3866 words]
Google Newsgroup13
Table 3: Top and Bottom Response Examples Ranked by MTM.
Fig. 3 summarizes the results from the above 6 approaches. The common end point of all curves
represents the cost and benefit of assessing all system responses. We can see that the baseline is very
inefficient at finding the truths. If we employ linguistic indicators, the process can be dramatically
expedited. MTM provides further significant gains, with performance close to the Oracle. With only half
the cost of the baseline, MTM can already find 90% truths.
5.4 Enhance Individual SF Systems
Finally, as a by-product, our MTM approach can also be exploited to validate the responses from each
individual SF system based on their credibility scores. For fair comparison with the official KBP
evaluation, we use the same ground-truth in KBP2013 and standard precision, recall and F-measure
metrics as defined in (Ji et al., 2011). To increase the chance of including truths which may be particularly
difficult for a system to find, LDC prepared a manual key which was assessed and included in the final
ground truth. According to the SF evaluation setting, F-measure is computed based on the number of
unique true claims. After removing redundancy across multiple systems, there are 1,468 unique true
claims. The cutoff criteria for determining whether a response is true or not was optimized from the
development set.
Fig. 4 presents the F-measure scores of the best run from each individual SF system. We can see that
our MTM approach consistently improves the performance of almost all SF systems, in an absolute gain
range of [-1.22%, 5.70%]. It promotes state-of-the-art SF performance from 33.51% to 35.70%. Our
MTM approach provides more gains to SF systems which mainly rely on lexical or syntactic patterns
than other systems using distant supervision or logic rules.
1575
1 
0 10000 20000 30000 40000
0
2000
4000
6000
8000
10000
12000
14000
13 2
4
5
#tr
uth
s
 6 Oracle 
 5 MTM
 4 SVM
 3 Linguistic Indicator
 2 Voting
 1 Baseline
#total responses
6
Figure 3: Truth Finding Efficiency.
0 2 4 6 8 10 12 14 16 18 20
0
5
10
15
20
25
30
35
F-m
es
au
re 
(%
)
System
 Before
 After
Figure 4: Impact on Individual SF Systems.
1576
6 Conclusions and Future Work
Truth finding has received attention from both Natural Language Processing (NLP) and Data Mining
communities. NLP work has mostly explored linguistic analysis of the content, while Data Mining
work proposed advanced models in resolving conflict information from multiple sources. They have
relative strengths and weaknesses. In this paper we leverage the strengths of these two distinct,
but complementary research paradigms and propose a novel unsupervised multi-dimensional truth-
finding framework incorporating signals both from multiple sources, multiple systems and multiple
evidences based on knowledge graph construction with multi-layer linguistic analysis. Experiments on
a challenging SFV task demonstrated that this framework can find high-quality truths efficiently. In the
future we will focus on exploring more inter-dependencies among responses such as temporal and causal
relations.
Acknowledgments
This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement
No. W911NF-09-2-0053 (NS-CTA), the U.S. Army Research Office under Cooperative Agreement
No. W911NF-13-1-0193, U.S. National Science Foundation grants IIS-0953149, CNS-0931975,
IIS-1017362, IIS-1320617, IIS-1354329, U.S. DARPA Award No. FA8750-13-2-0041 in the Deep
Exploration and Filtering of Text (DEFT) Program, IBM Faculty Award, Google Research Award,
DTRA, DHS and RPI faculty start-up grant. The views and conclusions contained in this document are
those of the authors and should not be interpreted as representing the official policies, either expressed
or implied, of the U.S. Government. The U.S. Government is authorized to reproduce and distribute
reprints for Government purposes notwithstanding any copyright notation here on.
References
S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, and Z. Ives. 2007. Dbpedia: A nucleus for a web of open data. In
Proc. the 6th International Semantic Web Conference.
L. Blanco, V. Crescenzi, P. Merialdo, and P. Papotti. 2010. Probabilistic models to reconcile complex data
from inaccurate data sources. In Proc. Int. Conf. on Advanced Information Systems Engineering (CAiSE?10),
Hammamet, Tunisia, June.
K. Bollacker, R. Cook, and P. Tufts. 2008. Freebase: A shared database of structured general human knowledge.
In Proc. National Conference on Artificial Intelligence.
A. Carlson, J. Betteridge, B. Kisiel, B. Settles, Estevam R Hruschka Jr, and Tom M Mitchell. 2010. Toward an
architecture for never-ending language learning. In AAAI.
C. Chang and C. Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent
Systems and Technology (TIST), 2(3):27.
H. Deng, M. R. Lyu, and I. King. 2009. A generalized co-hits algorithm and its application to bipartite graphs. In
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD ?09, pages 239?248, New York, NY, USA. ACM.
X. L. Dong, L. Berti-Equille, and D. Srivastavas. 2009a. Integrating conflicting data: The role of source
dependence. In Proc. 2009 Int. Conf. Very Large Data Bases (VLDB?09), Lyon, France, Aug.
X. L. Dong, L. Berti-Equille, and D. Srivastavas. 2009b. Truth discovery and copying detection in a dynamic
world. In Proc. 2009 Int. Conf. Very Large Data Bases (VLDB?09), Lyon, France, Aug.
A. Galland, S. Abiteboul, A. Marian, and P. Senellart. 2010. Corroborating information from disagreeing views.
In Proc. ACM Int. Conf. on Web Search and Data Mining (WSDM?10), New York, NY, Feb.
L. Ge, J. Gao, X. Yu, W. Fan, and A. Zhang. 2012. Estimating local information trustworthiness via multi-
source joint matrix factorization. In Data Mining (ICDM), 2012 IEEE 12th International Conference on, pages
876?881. IEEE.
1577
H. Ji, R. Grishman, H. T. Dang, K. Griffitt, and J. Ellis. 2010. An overview of the tac2010 knowledge base
population track. In Proc. Text Analytics Conf. (TAC?10), Gaithersburg, Maryland, Nov.
H. Ji, R. Grishman, and H.T. Dang. 2011. Overview of the tac 2011 knowledge base population track. In Text
Analysis Conf. (TAC) 2011.
X. Li and R. Grishman. 2013. Confidence estimation for knowledge base population. In Proc. Recent Advances
in Natural Language Processing (RANLP).
Q. Li and H. Ji. 2014. Incremental joint extraction of entity mentions and relations.
Q. Li, H. Ji, and L. Huang. 2013. Joint event extraction via structured prediction with global features.
M. D. Marneffe, B. Maccartney, and C. D. Manning. 2006. Generating typed dependency parses from phrase
structure parses. In LREC, pages 449,454.
R. Mihalcea. 2004. Graph-based ranking algorithms for sentence extraction, applied to text summarization. In
Proc. ACL2004.
M. Mintz, S. Bills, R. Snow, and D. Jurafsky. 2009. Distant supervision for relation extraction without labeled
data. In Proc. ACL2009.
J. Pasternack and D. Roth. 2010. Knowing what to believe (when you already know something). In
Proceedings of the 23rd International Conference on Computational Linguistics, pages 877?885. Association
for Computational Linguistics.
J. Pasternack and D. Roth. 2011. Making better informed trust decisions with generalized fact-finding. In Proc.
2011 Int. Joint Conf. on Artificial Intelligence (IJCAI?11), Barcelona, Spain, July.
J. Pasternack and D. Roth. 2013. Latent credibility analysis. In Proc. WWW 2013.
E. Peserico and L. Pretto. 2009. Score and rank convergence of hits. In Proceedings of the 32nd international
ACM SIGIR conference on Research and development in information retrieval, pages 770?771. ACM.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A Core of Semantic Knowledge. In
16th international World Wide Web conference (WWW 2007), New York, NY, USA. ACM Press.
S. Tamang and H. Ji. 2011. Adding smarter systems instead of human annotators: Re-ranking for slot filling
system combination. In Proc. CIKM2011 Workshop on Search & Mining Entity-Relationship data, Glasgow,
Scotland, UK, Oct.
VG Vydiswaran, C.X. Zhai, and D. Roth. 2011. Content-driven trust propagation framework. In Proceedings
of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 974?982.
ACM.
D. Wang, L. Kaplan, H. Le, and T. Abdelzaher. 2012. On truth discovery in social sensing: A maximum likelihood
estimation approach. In Proc. ACM/IEEE Int. Conf. on Information Processing in Sensor Networks (IPSN?12),
pages 233?244, Beijing, China, April.
X. Yin and W. Tan. 2011. Semi-supervised truth discovery. In Proc. 2011 Int. World Wide Web Conf. (WWW?11),
Hyderabad, India, March.
X. Yin, J. Han, and P. S. Yu. 2008. Truth discovery with multiple conflicting information providers on the Web.
IEEE Trans. Knowledge and Data Engineering, 20:796?808.
B. Zhao, B. I. P. Rubinstein, J. Gemmell, and J. Han. 2012. A Bayesian approach to discovering truth from
conflicting sources for data integration. In Proc. 2012 Int. Conf. Very Large Data Bases (VLDB?12), Istanbul,
Turkey, Aug.
1578
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1083?1093,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Resolving Entity Morphs in Censored Data
Hongzhao Huang1, Zhen Wen2, Dian Yu1, Heng Ji1,
Yizhou Sun3, Jiawei Han4, He Li5
1Computer Science Department and Linguistics Department,
Queens College and Graduate Center, City University of New York, New York, NY, USA
2IBM T. J. Watson Research Center, Hawthorne, NY, USA
3College of Computer and Information Science, Northeastern University, Boston, MA, USA
4Computer Science Department, Univerisity of Illinois at Urbana-Champaign, Urbana, IL, USA
5Admaster Inc., China
{hongzhaohuang1,yudiandoris1,hengjicuny1, liheact5}@gmail.com,
zhenwen@us.ibm.com2, yzsun@ccs.neu.edu3, hanj@illinois.edu4
Abstract
In some societies, internet users have to
create information morphs (e.g. ?Peace
West King? to refer to ?Bo Xilai?) to avoid
active censorship or achieve other com-
munication goals. In this paper we aim
to solve a new problem of resolving en-
tity morphs to their real targets. We ex-
ploit temporal constraints to collect cross-
source comparable corpora relevant to any
given morph query and identify target can-
didates. Then we propose various novel
similarity measurements including surface
features, meta-path based semantic fea-
tures and social correlation features and
combine them in a learning-to-rank frame-
work. Experimental results on Chinese
Sina Weibo data demonstrate that our ap-
proach is promising and significantly out-
performs baseline methods1.
1 Introduction
Language constantly evolves to maximize com-
municative success and expressive power in daily
social interactions. The proliferation of online so-
cial media significantly expedites this evolution,
as new phrases triggered by social events may be
disseminated rapidly in social media. To automati-
cally analyze such fast evolving language in social
media, new computational models are demanded.
In this paper, we focus on one particular lan-
guage evolution that creates new ways to commu-
nicate sensitive subjects because of the existence
of internet information censorship. We call this
1Some of the resources and open source programs devel-
oped in this work are made freely available for research pur-
pose at http://nlp.cs.qc.cuny.edu/Morphing.tar.gz
phenomenon information morph. For example,
when Chinese online users talk about the former
politician ?Bo Xilai?, they use a morph ?Peace
West King? instead, a historical figure four hun-
dreds years ago who governed the same region
as Bo. Morph can be considered as a special
case of alias used for hiding true entities in ma-
licious environment (Hsiung et al, 2005; Pantel,
2006). However, social network plays an impor-
tant role in generating morphs. Usually morphs
are generated by harvesting the collective wisdom
of the crowd to achieve certain communication
goals. Aside from the purpose of avoiding cen-
sorship, other motivations for using morph include
expressing sarcasm/irony, positive/negative senti-
ment or making descriptions more vivid toward
some entities or events. Table 1 presents the wide
range of cases that are used to create the morphs.
We can see that a morph can be either a regular
term with new meaning or a newly created term.
Morph Target Motivation
Peace West King Bo Xilai Sensitive
Blind Man Chen Guangcheng Sensitive
Miracle Brother Wang Yongping Irony
Kim Fat Kim Joing-il Negative
Kimchi Country South Korea Vivid
Table 1: Morph Examples and Motivations.
We believe that successful resolution of morphs
is a crucial step for automated understanding of
the fast evolving social media language, which
is important for social media marketing (Bar-
wise and Meehan, 2010). Another application
is to help common users without enough back-
ground/cultural knowledge to understand internet
language for their daily use. Furthermore, our ap-
proaches can also be applied for satire or other im-
plicit meaning recognition, as well as information
extraction (Bollegala et al, 2011).
1083
However, morph resolution in social media is
challenging due to the following reasons. First,
the sensitive real targets that exist in the same
data source under active censorship are often au-
tomatically filtered. Table 2 presents the distribu-
tions of some examples of morphs and their tar-
gets in English Twitter and Chinese Sina Weibo.
For example, the target ?Chen Guangcheng? only
appears once in Weibo. Thus, the co-occurrence
of a morph and its target is quite low in the vast
amount of information in social media. Second,
most morphs were not created based on pronunci-
ations, spellings or other encryptions of their origi-
nal targets. Instead, they were created according to
semantically related entities in historical and cul-
tural narratives (e.g. ?Peace West King? as morph
of ?Bo Xilai?) and thus very difficult to capture
based on typical lexical features. Third, tweets
from Twitter/Chinese Weibo are short (only up to
140 characters) and noisy, resulting in difficult ex-
traction of rich and accurate evidences due to the
lack of enough contexts.
 Frequency in  Twitter Frequency in  Weibo Morph Target Morph Target Morph Target Hu Ji Hu Jintao 1 3,864 2,611 71 Blind  Man Chen  Guangcheng 18 2,743 20,941 1 Baby Wen Jiabao 2238 2021 26,279 8  
Table 2: Distributions of Morph Examples
To the best of our knowledge, this is the first
work to use NLP and social network analysis tech-
niques to automatically resolve morphed informa-
tion. To address the above challenges, our paper
offers the following novel contributions.
? We detect target candidates by exploiting the
dynamics of the social media to extract tem-
poral distribution of entities, based on the as-
sumption that the popularity of an individ-
ual is correlated between censored and un-
censored text within a certain time window.
? Our approach builds and analyzes heteroge-
neous information networks from multiple
sources, such as Twitter, Sina Weibo and web
documents in formal genre (e.g. news) be-
cause a morph and its target tend to appear in
similar contexts.
? We propose two new similarity measures, as
well as integrating temporal information into
the similarity measures to generate global se-
mantic features.
? We model social user behaviors and use so-
cial correlation to assist in measuring seman-
tic similarities because the users who posted
a morph and its corresponding target tend to
share similar interests and opinions.
Our experiments demonstrate that the pro-
posed approach significantly outperforms tradi-
tional alias detection methods (Hsiung et al,
2005).
2 Approach Overview   Morph Query   Comparable Data Acquisition   
Target Candidate Ranking 
Target
Learning to Rank 
Semantic Features
Semantic Annotation and  Target Candidate Identification
Surface Features Social Features
Censored Data Uncensored Data
Figure 1: Overview of Morph Resolution
Given a morph query m, the goal of morph res-
olution is to find its real target. Figure 1 depicts
the general procedure of our approach. It consists
of two main sub-tasks:
? Target Candidate Identification: For each
m, discover a list of target candidates E =
{e1, e2, ..., eN}. First, relevant comparable
data sets that include m are retrieved. In
this paper we collect comparable censored
data from Weibo and uncensored data from
Twitter and Web documents such as news ar-
ticles. We then apply various annotations
such as word segmentation, part-of-speech
tagging, noun phrase chunking, name tagging
and event extraction to these data sets.
? Target Candidate Ranking: Rank the target
candidates in E. We explore various features
including surface, semantic and social fea-
tures, and incorporate them into a learning to
1084
rank framework. Finally, the top ranked can-
didate is produced as the resolved target.
3 Target Candidate Identification
The general goal of the first step is to identify a list
of target candidates for each morph query from the
comparable corpora including Sina Weibo, Chi-
nese News websites and English Twitter. How-
ever, obviously we cannot consider all of the
named entities in these sources as target candi-
dates due to the sheer volume of information. In
addition, morphs are not limited to named entity
forms. In order to narrow down the scope of tar-
get candidates, we propose a Temporal Distribu-
tion Assumption as follows. The intuition is that
a morph m and its real target e should have sim-
ilar temporal distributions in terms of their occur-
rences. Suppose the data sets are separated into Z
temporal slots (e.g. by day), the assumption can
be stated as:
Let Tm = {tm1, tm2, ..., tmZm} be the set of
temporal slots each morph m occurs, and Te =
{te1, te2, ..., teZe} be the set of slots a target can-
didate e occurs. Then e is considered as a target
candidate of m if and only if, for each tmi ? Tm
(i = 1, 2, ..., Zm), there exist a j ? {1, 2, ..., Ze}
such that tmi ? tej ? ?, where ? is a threshold
value (in this paper we set the threshold to 7 days,
which is optimized from a development set). For
comparison we also attempted topic modeling ap-
proach to detect target candidates, as shown in sec-
tion 5.3.
4 Target Candidate Ranking
Next, we propose a learning-to-rank framework to
rank target candidates based on various levels of
novel features based on surface, semantic and so-
cial analysis.
4.1 Surface Features
We first extract surface features between the
morph and the candidate based on measuring or-
thographic similarity measures which were com-
monly used in entity coreference resolution (e.g.
(Ng, 2010; Hsiung et al, 2005)). The measures
we use include ?string edit distance?, ?normalized
string edit distance? (Wagner and Fischer, 1974)
and ?longest common subsequence? (Hirschberg,
1977).
4.2 Semantic Features
4.2.1 Motivations
Fortunately, although a morph and its target may
have very different orthographic forms, they tend
to be embedded in similar semantic contexts
which involve similar topics and events. Figure 2
presents some example messages under censor-
ship (Weibo) and not under censorship (Twitter
and Chinese Daily). We can see that they include
similar topics, events (e.g., ?fell from power?,
?gang crackdown?, ?sing red songs?), and se-
mantic relations (e.g., family relations with ?Bo
Guagua?). Therefore if we can automatically ex-
tract and exploit these indicative semantic con-
texts, we can narrow down the real targets effec-
tively.
?Pe
ace W
est K
ingfr
om C
hong
qing
fell fr
om p
ower
, still
 nee
d to 
sing 
red s
ongs
?
?T
here
 is no
 diffe
renc
e be
twee
n tha
t 
guy?s
 plag
iarism
 and
 Buh
ou?s
gang
 
crack
down
.
?R
eme
mbe
r tha
t Buh
ousa
id tha
t his 
famil
y wa
s not
 rich 
at th
e pre
ss 
confe
renc
e a f
ew d
ays b
efore
 he 
fell fr
om p
ower
. His 
sonB
o 
Guag
uais 
supp
orted
 by h
is 
scho
larsh
ip.
?B
o Xila
i: ten
 thou
sand
 lette
rs of
 
accu
satio
n ha
ve be
en re
ceive
d du
ring 
Chon
gqing
gang
 crac
kdow
n.
?T
he w
ebpa
ge o
f ?Tia
nzeE
cono
mic 
Stud
y Ins
titute
?own
ed b
y the
 liber
al 
party
 has 
been
 clos
ed. T
his is
 the 
first 
affec
ted w
ebsit
e of 
the li
bera
l par
ty 
after
 Bo X
ilaife
ll from
 pow
er.
?B
o Xila
igave
 an e
xplan
ation
 abo
ut th
e 
sour
ce of
 hiss
on, B
o Gu
agua
?s 
tuitio
n.
?B
o Xila
iled C
hong
qing 
city l
eade
rs 
and 
40 d
istric
t and
 coun
ty pa
rty a
nd 
gove
rnme
nt lea
ders
 to si
ng re
d son
gs.
Weib
o(ce
nsore
d)
Twitt
er an
d Ch
inese
 New
s (un
cens
ored)
Figure 2: Cross-source Comparable Data Example
(each morph and target pair is shown in the same
color)
4.2.2 Information Network Construction
We define an information network as a directed
graph G = (V, E) with an object type mapping
function ? : V ? A and a link type mapping func-
tion ? : E ? R, where each object v ? V belongs
to one particular object type ?(v) ? A, each link
e ? E belongs to a particular relation ?(e) ? R.
If two links belong to the same relation type, then
they share the same starting object type as well as
the same ending object type. An information net-
work is homogeneous if and only if there is only
one type for both objects and links, and an infor-
mation network is heterogeneous when the objects
are from multiple distinct types or there exist more
than one type of links.
In order to construct the information networks
for morphs, we apply the Standford Chinese word
1085
segmenter with Chinese Penn Treebank segmen-
tation standard (Chang et al, 2008) and Stan-
ford part-of-speech tagger (Toutanova et al, 2003)
to process each sentence in the comparable data
sets. Then we apply a hierarchical Hidden Markov
Model (HMM) based Chinese lexical analyzer
ICTCLAS (Zhang et al, 2003) to extract named
entities, noun phrases and events.
We have also attempted using the results from
Dependency Parsing, Relation Extraction and
Event Extraction tools (Ji and Grishman, 2008)
to enrich the link types. Unfortunately the state-
of-the-art techniques for these tasks still perform
poorly on social media in terms of both accuracy
and coverage of important information, these so-
phisticated semantic links all produced negative
impact on the target ranking performance. There-
fore we limited the types of vertices into: Morph
(M), Entity(E), which includes target candidates,
Event (EV), and Non-Entity Noun Phrases (NP);
and used co-occurrence as the edge type. We ex-
tract entities, events, and non-entity noun phrases
that occur in more than one tweet as neighbors.
And for two vertices xi and xj , the weight wij
of their edge is the frequency they co-occur to-
gether within the tweets. A network schema of
such networks is shown in Figure 3. Figure 4
M
E NP
EV
Figure 3: Network Schema of Morph-Related Het-
erogeneous Information Network
presents an example of a heterogeneous informa-
tion network from the motivation examples fol-
lowing the above network schema, which connects
the morphs ?Peace West King?, ?Buhou? and their
corresponding target ?Bo Xilai?.
4.2.3 Meta-Path-Based Semantic Similarity
Measurements
Given the constructed network, a straightforward
solution for finding the target for a morph is to use
link-based similarity search. However, now ob-
jects are linked to different types of neighbors, if
all neighbors are treated as the same, it may cause
information loss problems. For example, the en-
tity ??? (Chongqing)? is a very important aspect
characterizing the politician ????(Bo Xilai)?
Ga
ng 
Cra
ckd
ow
n 
Fel
l Fr
om
 
Pow
er
Ch
ong
qin
g
Sin
g R
ed 
Son
gs
Bu
hou
Pea
ce 
We
st 
Kin
g
Bo
 Xil
ai
Bo
 Gu
agu
a
Ent
ity
Ent
ity
Ent
ity
Eve
nt
Eve
nt
Eve
nt
Mo
rph
Mo
rph
Figure 4: Example of Morph-Related Heteroge-
neous Information Network
since he governed it, and if a morph m which is
also highly correlated with ??? (Chongqing)?, it
is very likely that ?Bo Xilai? is the real target ofm.
Therefore, the semantic features generated from
neighbors such as the entity ??? (Chongqing)?
should be treated differently from other types of
neighbors such as ???(talented people)? .
In this work, we propose to measure the simi-
larity of two nodes over heterogeneous networks
as shown in Figure 3, by distinguishing neighbors
into three types according to the network schema
(i.e. entities, events, non-entity noun phrases). We
then adopt meta-path-based similarity measures
(Sun et al, 2011a; Sun et al, 2011b), which are
defined over heterogeneous networks to extract se-
mantic features. A meta-path is a path defined over
a network, and composed of a sequence of rela-
tions between different object types. For example,
as shown in Figure 3, a morph and its target can-
didate can be connected by three meta-paths, in-
cluding ?M - E - E?, ?M - EV - E?, and ?M - NP
- E?. Intuitively, each meta-path provides a unique
angle to measure how similar two objects are.
For the determined meta-paths, we extract se-
mantic features using the similarity measures pro-
posed in (Sun et al, 2011a; Hsiung et al, 2005).
We denote the neighbor sets of certain type for a
morph m and a target candidate e as ?(m) and
?(e), and a meta-path as P . We now list several
meta-path-based similarity measures below.
Common neighbors (CN). It measures the num-
ber of common neighbors that m and e share as
|?(m) ? ?(e)|.
Path count (PC). It measures the number of path
instances betweenm and e following meta-pathP .
Pairwise random walk (PRW). For a meta-
path P that can be decomposed into two shorter
1086
meta-paths with the same length P = (P1P2),
pairwise random walk measures the probabil-
ity of the pairwise random walk starting from
both m and e and reaching the same mid-
dle object. More formally, it is computed as?
(p1p2)?(P1P2) prob(p1)prob(p?12 ), where p?12 isthe inverse of p2.
Kullback-Leibler distance (KLD). For m and
e, the pairwise random walk probability of their
neighbors can be represented as two probability
vectors, then Kullback-Leibler distance (Hsiung
et al, 2005) can be used to compute sim(m, e).
Beyond the above similarity measures, we also
propose to use cosine-similarity-style normaliza-
tion method to modify common neighbor and pair-
wise random walk measures so that we can ensure
the morph node and the target candidate node are
strongly connected and also have similar popular-
ity. The modified algorithms penalize features in-
volved with the highly popular objects, since they
are more likely to have accidental interactions with
each other.
Normalized common neighbors (NCN). Nor-
malized common neighbors can be measured as
sim(m, e) = |?(m)??(e)|?
|?(m)|
?
|?(e)|
. It refines the simple
counting of common neighbors by avoiding bias
to highly visible or concentrated objects.
Pairwise random walk/cosine (PRW/cosine).
Pairwise random walk measures linkage weights
disproportionately with their visibility to their
neighbors, which may be too strong. Instead, we
propose to use a tamer normalization method as?
(p1p2)?(P1P2) f(p1)f(p?12 ), where.
f(p1) = count(m,x)??
x?? count(m,x)
,
f(p2) = count(e, x)??
x?? count(e, x)
,
and ? is the set of middle objects connecting the
decomposed meta-paths p1 and p?12 , count(y, x)
is the total number of paths between y and the mid-
dle object x, y could be m or e.
The above similarity measures can also be ap-
plied to homogeneous networks that do not differ-
entiate the neighbor types.
4.2.4 Global Semantic Feafure Generation
A morph tends to have higher temporal correlation
with its real target, and share more similar topics
compared to other irrelevant targets. Therefore,
we propose to incorporate temporal information
into similarity measures to generate global seman-
tic features.
Let T = t1 ? t2 ? ... ? tN be a set of temporal
slots (i.e. by day),E be the set of target candidates
for each morphm. Then for each ti ? T , and each
e ? E, the local semantic features simti(m, e)
is extracted based only on the information posted
within ti using one of the similarity measures in-
troduced in Section 4.2.3. Then we propose two
approaches to generate global semantic features.
The first approach is adding the similarity score
between m and e in each temporal slot to attain
the first set of global features:
simglobal sum(m, e) =
?
ti?T
simti(m, e).
The second method first normalizes the similarity
score in each temporal slot ti, them sum the nor-
malized scores to generate the second set of global
features, which can be calculated as
simglobal norm(m, e) =
?
ti?T
normti(m, e).
where normti(m, e) = simti (m,e)?e?E simti (m,e) .
4.2.5 Integrate Cross Source/Cross Genre
Information
Due to internet information censorship or surveil-
lance, users may need to use morphs to post sensi-
tive information. For example, the Chinese Weibo
message ?????,??????? (Already
put in prison, still need to serve Buhou?? include
a morph ?? (Buhou). In contrast, users are less
restricted in some other uncensored social media
such as Twitter. For example, the tweet from Twit-
ter ?...?????????????????...
(...call Bo Xilai?peace west king? or ?buhou?...)?
contains both the morph and the real target ??
? (Bo Xilai). Therefore, we propose to integrate
information from another source (e.g. Twitter) to
help resolution of sensitive morphs in Weibo.
Another difficulty from morph resolution in
micro-blogging is that tweets are only allowed to
contain maximum 140 characters with a lot of
noise and diverse topics. The shortness and di-
versity of tweets may limit the power of content
analysis for semantic feature extraction. However,
formal genres such as web documents are cleaner
and contain richer contexts, thus can provide more
topically related information. In this work, we also
exploit the background web documents from the
1087
embedded URLs in tweets to enrich information
network construction. After applying the same an-
notation techniques as tweets for uncensored data
sets, sentence-level co-occurrence relations are ex-
tracted and integrated into the network as shown in
Figure 3.
4.3 Social Features
It has been shown that there exist correlation be-
tween neighbors in social networks (Anagnos-
topoulos et al, 2008; Wen and Lin, 2010). Be-
cause of such social correlation, close social
neighbors in social media such as Twitter and
Weibo may post similar information, or share sim-
ilar opinion. Therefore, we can utilize social cor-
relation to assist in resolving morphs.
As social correlation can be defined as a func-
tion of social distance between a pair of users, we
use social distance as a proxy to social correla-
tion in our approach. The social distance between
user i and j is defined by considering the degree
of separation in their interaction (e.g. retweet-
ing and mentioning) and the amount of the in-
teraction. Similar definition has been shown ef-
fective in characterizing social distance in social
networks extracted from communication data (Lin
et al, 2012; Wen and Lin, 2010). Specifically,
it is dist(i, j) = ?K?1k=1 1strength(vk,vk+1) , where
v1, ..., vk are the nodes on the shortest path from
user i to user j, and strength(vk, vk+1) measures
the strength of interactions between vk and vk+1
as: strength(i, j) = log(Xij)maxj log(Xij) , where Xij isthe total interactions between user i and j, includ-
ing both retweeting and mentioning (If Xij < 10,
we set strength(i, j) = 0).
We integrate social correlation and temporal in-
formation to define our social features. The in-
tuition is that when a morph is used by an user,
the real target may also in the posts by the user or
his/her close friends within a certain time period.
Let T be the set of temporal slots a morph m oc-
curs, Ut be the set of users whose posts include m
in slot t where t ? T , and Uc be the set of close
friends (i.e., social distance < 0.5) for Ut. The
social features are defined as
s(m, e) =
?
t?T f(e, t, Ut, Uc)
|T | .
where f(e, t, Ut, Uc) is a indicator function which
return 1 if one of the users in Ut or Uc posts tweets
include the target candidate e within 7 days before
t.
4.4 Learning-to-Rank
Similar to (Hsiung et al, 2005; Sun et al, 2011a),
we then model the probability of linkage predic-
tion between a morph m and its target candidate
e as a function incorporating the surface, semantic
and social features. Given a training pair ?m, e?,
we choose the standard logistic regression model
to learn weights for the features defined above.
The learnt model is used to predict the probabil-
ity of linking an unseen morph and its target can-
didate. Based on the descending ranking order of
the probability, we select top k candidates as the
final answers based on the answer size k.
5 Experiments
Next, we present the experiment under various set-
tings shown in Table 3, and the impacts of cross
source and cross genre information.
5.1 Data and Evaluation Metric
We collected 1, 553, 347 tweets from Chinese Sina
Weibo from May 1 to June 30 to construct the
censored data set, and retrieved 66, 559 web doc-
uments from the embedded URLs in tweets as the
initial uncensored data set. Retweets and redun-
dant web documents are filtered to ensure more
reliable frequency counting of co-occurrence rela-
tions. We asked two native Chinese annotators to
analyze the data, and construct a test set consisted
of 107 morph entities (81 persons and 26 loca-
tions) and their real targets as our references. We
verified the references by Web resources includ-
ing the summary of popular morphs in Wikipedia
2. In addition, we used 23 sensitive morphs and
the entities that appear in the tweets as queries and
retrieved 25, 128 Chinese tweets from 10% Twit-
ter feeds within the same time period, as well as
7, 473 web documents from the embedded URLs
and added them into the uncensored data set.
To evaluate the system performance, we use
leave-one-out cross validation by computing ac-
curacy as Acc@k = CkQ , where Ck is the to-tal number of correctly resolved morphs at top
k ranked answers, and Q is the total number of
morph queries. We consider a morph as correctly
resolved at the top k answers if the top k answer
set contains the real target of the morph.
2http://zh.wikipedia.org/wiki/??????????
1088
Feature sets Descriptions
Surf Surface features
HomB Semantic features extracted from homogeneous CN, PC, PRW, and KLD
HomE HomB + semantic features extracted from homogeneous NCN and PRW/cosine
HetB Semantic features extracted from heterogeneous CN, PC, PRW and KLD
HetE HetB + Semantic features extracted from heterogeneous NCN and PRW/cosine
Glob? Global semantic features
Social Social network features
Table 3: Description of feature sets. ? Glob only uses the same set of similarity measures when combined
with other semantic features.
5.2 Resolution Performance
5.2.1 Single Genre Information
We first study the contributions of each set of sur-
face and semantic features, as shown in the first
five rows in Table 4. The poor performance based
on surface features shows that morph resolution
task is very challenging since 70% of morphs are
not orthographically similar to their real targets.
Thus, capturing a morph?s semantic meaning is
crucial. Overall, the results demonstrate the ef-
fectiveness of our proposed methods. Specifi-
cally, comparing ?HomB? and ?HetB?, ?HomE?
and ?HetE?, we can see that the semantic fea-
tures based on heterogeneous networks have ad-
vantages over those based on homogeneous net-
works. This corroborates that different neighbor
sets contribute differently, and such discrepancies
should be captured. And comparisions of ?HomB?
and ?HomE?, ?HetB? and ?HetE?demonstrate the
effectiveness of our two new proposed measures.
To evaluate the importance of each similarity mea-
sures, we delete the semantic features obtained
from each measure in ?HetE? and re-evaluate the
system. We find that NCN is the most effective
measure, while KLD is the least important one.
Further adding the global semantic features signif-
icantly improves the performance. This indicates
that capturing both temporal correlations and se-
mantics of morphing simultaneously are important
for morph resolution.
Table 5 shows that combination of surface and
semantic features further improves the perfor-
mance, showing that they are complementary. For
example, using only surface features, the real tar-
get ?????Steve Jobs?? of the morph ???
? (Qiao Boss)? is not top ranked since some other
candidates such as ??? (George)? are more or-
thographically similar. However, ?Steve Jobs? is
ranked top when combined with semantic features.
Features Surf HomB HomE HetB HetE
Acc@1 0.028 0.201 0.192 0.224 0.252
Acc@5 0.159 0.313 0.369 0.393 0.421
Acc@10 0.243 0.346 0.407 0.439 0.467
Acc@20 0.313 0.411 0.467 0.50 0.523
Features + Glob + Glob + Glob + Glob
Acc@1 0.230 0.285 0.257 0.285
Acc@5 0.402 0.407 0.449 0.458
Acc@10 0.435 0.458 0.50 0.495
Acc@20 0.486 0.523 0.565 0.542
Table 4: The System Performance Based on Each
Single Feature Set.
Features Surf +
HomB
Surf +
HomE
Surf +
HetB
Surf +
HetE
Acc@1 0.234 0.238 0.262 0.276
Acc@5 0.416 0.444 0.481 0.519
Acc@10 0.477 0.505 0.533 0.570
Acc@20 0.519 0.561 0.565 0.598
Features + Glob + Glob + Glob + Glob
Acc@1 0.290 0.341 0.322 0.346
Acc@5 0.505 0.495 0.528 0.533
Acc@10 0.551 0.551 0.579 0.584
Acc@20 0.594 0.603 0.636 0.631
Table 5: The System Performance Based on Com-
binations of Surface and Semantic Features.
5.2.2 Cross Source and Cross Genre
Information
We integrate the cross source information from
Twitter, and the cross genre information from web
documents into Weibo tweets for information net-
work construction, and extract a new set of se-
mantic features. Table 6 shows that further gains
can be achieved. Notice that integrating tweets
from Twitter mainly improves the ranking for top
k where k > 1. This is because Weibo dominates
our dataset, and in Weibo many of these sensi-
tive morphs are mostly used with their traditional
meanings instead of the morph senses. Further
performance improvement is achieved by integrat-
ing information from background formal web doc-
uments which can provide richer context and rela-
tions.
1089
Features Surf +
HomB +
Glob
Surf +
HomE +
Glob
Surf +
HetB +
Glob
Surf +
HetE +
Glob
Acc@1 0.290 0.341 0.322 0.346
Acc@5 0.505 0.495 0.528 0.533
Acc@10 0.551 0.551 0.579 0.584
Acc@20 0.594 0.603 0.636 0.631
Features + Twit-
ter
+ Twit-
ter
+ Twit-
ter
+ Twit-
ter
Acc@1 0.308 0.336 0.336 0.346
Acc@5 0.514 0.519 0.547 0.565
Acc@10 0.579 0.594 0.594 0.636
Acc@20 0.631 0.640 0.668 0.668
Features + Web + Web + Web + Web
Acc@1 0.327 0.360 0.341 0.379
Acc@5 0.528 0.519 0.565 0.575
Acc@10 0.594 0.589 0.622 0.645
Acc@20 0.631 0.650 0.678 0.678
Table 6: The System Performance of Integrating
Cross Source and Cross Genre Information.
5.2.3 Effects of Social Features
Table 7 shows that adding social features can im-
prove the best performance achieved so far. This is
because a group of people with close relationships
may share similar opinion. As an example, two
tweets ?...of course the reputation of Buhou is a
little too high! //@User1: //@User2: Chongqing
event tells us...)? and ?...do not follow Bo Xi-
lai...@User1...) are from two users in the same
social group.One includes a morph ?Buhou? and
the other includes its target ?Bo Xilai?.
Features Surf +
HomB +
Glob +
Twitter
+ Web
Surf +
HomE +
Glob +
Twitter
+ Web
Surf +
HetB +
Glob +
Twitter
+ Web
Surf +
HetE +
Glob +
Twitter
+ Web
Acc@1 0.327 0.360 0.341 0.379
Acc@5 0.528 0.519 0.565 0.575
Acc@10 0.594 0.589 0.622 0.645
Acc@20 0.631 0.650 0.678 0.678
Features + Social + Social + Social + Social
Acc@1 0.336 0.369 0.365 0.379
Acc@5 0.537 0.547 0.589 0.594
Acc@10 0.594 0.601 0.645 0.659
Acc@20 0.645 0.664 0.701 0.701
Table 7: The Effects of Social Features.
5.3 Effects of Candidate Detection
The performance with and without candidate de-
tection step (using all features) is shown in Ta-
ble 8. The gain is small since the combination
of all features in the learning to rank framework
can already well capture the relationship between
a morph and a target candidate. Nevertheless, the
temporal distribution assumption is effective. It
helps to filter out 80% of unrelated targets and
speed up the system 5 times, while retain 98.5%
of the morph candidates that can be detected.
System Acc@1 Acc@5 Acc@10 Acc@20
Without 0.365 0.579 0.645 0.696
With 0.379 0.594 0.659 0.701
Table 8: The Effects of Temporal Constraint
We also attempted using topic modeling ap-
proach to detect target candidates. Due to the large
amount of data, we first split the data set on a daily
basis, then applied Probabilistic Latent Semantic
Analysis (PLSA) (Hofmann, 1999). Named enti-
ties which co-occur at least ? times with a morph
query in the same topic are selected as its target
candidates. As shown in Table9 (K is the num-
ber of predefined topics), PLSA is not quite effec-
tive mainly because traditional topic modeling ap-
proaches do not perform well on short texts from
social media. Therefore, in this paper we choose
a simple method based on temporal distribution to
detect target candidates.
Method All Temporal PLSA( PLSA(
K = 5 K = 5
? = 1) ? = 2)
Acc 0.935 0.921 0.935 0.925
No. 8, 111 1, 964 6, 380 4, 776
Method PLSA( PLSA( PLSA( PLSA(
K = 10 K = 10 K = 20 K = 20
? = 1) ? = 2) ? = 1) ? = 2)
Acc 0.935 0.907 0.888 0.757
No. 5, 117 3, 138 3, 702 1, 664
Table 9: Accuracy of Target Candidate Detection
5.4 Discussions
Compared with the standard alias detection
(?Surf+HomB?) approach (Hsiung et al, 2005),
our proposed approach achieves significantly bet-
ter performance (99.9% confidence level by the
Wilcoxon Matched-Pairs Signed-Ranks Test for
Acc@1). We further explore two types of factors
which may affect the system performance as fol-
lows.
One important aspect affecting the resolution
performance is the morph & non-morph ambigu-
ity. We categorize a morph query as ?Unique? if
the string is mainly used as a morph when it oc-
curs, such as ??? (Bodu)? which is used to re-
fer to ?Bo Xilai?; otherwise as ?Common? (e.g.
??? (Baby)? ,??? (President)? ). Table 10
presents the separate scores for these two cate-
gories. We can see that the morphs in ?Unique?
1090
category have much better resolution performance
than those in ?Common? category.
Category Number Acc@1 Acc@5 Acc@10 Acc@20
Unique 72 0.479 0.715 0.771 0.819
Common 35 0.171 0.343 0.40 0.429
Table 10: Performance of Two Categories
We also investigate the effects of popularity of
morphs on the resolution performance. We split
the queries into 5 bins with equal size based on the
non-descending frequency, and evaluate Acc@1
separately. As shown in Table11, we can see that
the popularity is not highly correlated with the per-
formance.
Rank 0 ?
20%
20% ?
40%
40% ?
60%
60% ?
80%
80% ?
100%
All 0.333 0.476 0.341 0.429 0.318
Unique 0.321 0.679 0.379 0.571 0.483
Common 0.214 0.214 0.071 0.071 0.286
Table 11: Effects of Popularity of Morphs
6 Related Work
To analyze social media behavior under active
censorship, (Bamman et al, 2012) automatically
discovered politically sensitive terms from Chi-
nese tweets based on message deletion analysis.
In contrast, our work goes beyond target idendi-
fication by resolving implicit morphs to their real
targets.
Our work is closely related to alias detec-
tion (Hsiung et al, 2005; Pantel, 2006; Bollegala
et al, 2011; Holzer et al, 2005). We demon-
strated that state-of-the-art alias detection meth-
ods did not perform well on morph resolution. In
this paper we exploit cross-genre information and
social correlation to measure semantic similarity.
(Yang et al, 2011; Huang et al, 2012) also showed
the effectiveness of exploiting information from
formal web documents to enhance tweet summa-
rization and tweet ranking.
Other similar research lines are the TAC-KBP
Entity Linking (EL) (Ji et al, 2010; Ji et al, 2011),
which links a named entity in news and web docu-
ments to an appropriate knowledge base (KB) en-
try, the task of mining name translation pairs from
comparable corpora (Udupa et al, 2009; Ji, 2009;
Fung and Yee, 1998; Rapp, 1999; Shao and Ng,
2004; Hassan et al, 2007) and the link predic-
tion problem (Adamic and Adar, 2001; Liben-
Nowell and Kleinberg, 2003; Sun et al, 2011b;
Hasan et al, 2006; Wang et al, 2007; Sun et al,
2011a). Most of the work focused on unstruc-
tured or structured data with clean and rich re-
lations (e.g. DBLP). In contrast, our work con-
structs heterogeneous information networks from
unstructured, noisy multi-genre text without ex-
plicit entity attributes.
7 Conclusion and Future Work
To the best of our knowledge, this is the first work
of resolving implicit information morphs from the
data under active censorship. Our promising re-
sults can well serve as a benchmark for this new
problem. Both of the Meta-path based and so-
cial correlation based semantic similarity mea-
surements are proven powerful and complemen-
tary.
In this paper we have focused on entity morphs.
In the future we will extend our method to dis-
cover other types of information morphs, such as
events and nominal mentions. In addition, auto-
matic identification of candidate morphs is another
challenging task, especially when the mentions are
ambiguous and can also refer to other real enti-
ties. Our ongoing work includes identifying can-
didate morphs from scratch, as well as discovering
morphs for a given target based on anomaly anal-
ysis and textual coherence modeling.
Acknowledgments
Thanks to the three anonymous reviewers for their
insightful comments. This work was supported
by the U.S. Army Research Laboratory under Co-
operative Agreement No. W911NF- 09-2-0053
(NS-CTA), the U.S. NSF CAREER Award under
Grant IIS-0953149, the U.S. NSF EAGER Award
under Grant No. IIS-1144111, the U.S. DARPA
FA8750-13-2-0041 - Deep Exploration and Filter-
ing of Text (DEFT) Program, the U.S. DARPA un-
der Agreement No. W911NF-12-C-0028, CUNY
Junior Faculty Award, NSF IIS-0905215, CNS-
0931975, CCF-0905014, and MIAS, a DHS-IDS
Center for Multimodal Information Access and
Synthesis at UIUC. The views and conclusions
contained in this document are those of the au-
thors and should not be interpreted as representing
the official policies, either expressed or implied,
of the U.S. Government. The U.S. Government is
authorized to reproduce and distribute reprints for
Government purposes notwithstanding any copy-
right notation here on.
1091
References
Lada A. Adamic and Eytan Adar. 2001. Friends
and neighbors on the web. SOCIAL NETWORKS,
25:211?230.
Aris Anagnostopoulos, Ravi Kumar, and Mohammad
Mahdian. 2008. Influence and correlation in social
networks. In KDD, pages 7?15.
David Bamman, Brendan O?Connor, and Noah A.
Smith. 2012. Censorship and deletion practices in
chinese social media. First Monday, 17(3).
Patrick Barwise and Sea?n Meehan. 2010. The one
thing you must get right when building a brand.
Harvard Business Review, 88(12):80?84.
D. Bollegala, Y. Matsuo, and M. Ishizuka. 2011. Au-
tomatic discovery of personal name aliases from
the web. Knowledge and Data Engineering, IEEE
Transactions on, 23(6):831?844.
Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing chinese word segmen-
tation for machine translation performance. In Pro-
ceedings of the Third Workshop on Statistical Ma-
chine Translation, StatMT ?08, pages 224?232.
Pascale Fung and Lo Yuen Yee. 1998. An ir approach
for translating new words from nonparallel, com-
parable texts. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics - Volume 1, ACL ?98, pages
414?420.
Mohammad Al Hasan, Vineet Chaoji, Saeed Salem,
and Mohammed Zaki. 2006. Link prediction using
supervised learning. In In Proc. of SDM 06 work-
shop on Link Analysis, Counterterrorism and Secu-
rity.
Ahmed Hassan, Haytham Fahmy, and Hany Has-
san. 2007. Improving named entity translation
by exploiting comparable and parallel corpora. In
RANLP.
Daniel S. Hirschberg. 1977. Algorithms for the
longest common subsequence problem. J. ACM,
24(4):664?675.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the 22nd annual inter-
national ACM SIGIR conference on Research and
development in information retrieval, SIGIR ?99,
pages 50?57.
Ralf Holzer, Bradley Malin, and Latanya Sweeney.
2005. Email alias detection using social network
analysis. In Conference on Knowledge Discovery
in Data: Proceedings of the 3 rd international work-
shop on Link discovery, volume 21, pages 52?57.
Paul Hsiung, Andrew Moore, Daniel Neill, and Jeff
Schneider. 2005. Alias detection in link data sets.
In Proceedings of the International Conference on
Intelligence Analysis, May.
Hongzhao Huang, Arkaitz Zubiaga, Heng Ji, Hongbo
Deng, Dong Wang, Hieu Khac Le, Tarek F. Ab-
delzaher, Jiawei Han, Alice Leung, John Hancock,
and Clare R. Voss. 2012. Tweet ranking based on
heterogeneous networks. In COLING, pages 1239?
1256.
Heng Ji and Ralph Grishman. 2008. Refining event ex-
traction through cross-document inference. In Pro-
ceedings of ACL, pages 254?262.
H. Ji, R. Grishman, H.T. Dang, K. Griffitt, and J. El-
lis. 2010. Overview of the tac 2010 knowledge base
population track. In Text Analysis Conference (TAC)
2010.
H. Ji, R. Grishman, and H.T. Dang. 2011. Overview
of the tac 2011 knowledge base population track. In
Text Analysis Conference (TAC) 2011.
Heng Ji. 2009. Mining name translations from com-
parable corpora by creating bilingual information
networks. In Proceedings of the 2nd Workshop
on Building and Using Comparable Corpora: from
Parallel to Non-parallel Corpora, BUCC ?09, pages
34?37.
David Liben-Nowell and Jon Kleinberg. 2003. The
link prediction problem for social networks. In
Proceedings of the twelfth international conference
on Information and knowledge management, CIKM
?03, pages 556?559.
Ching-Yung Lin, Lynn Wu, Zhen Wen, Hanghang
Tong, Vicky Griffiths-Fisher, Lei Shi, and David
Lubensky. 2012. Social network analysis in enter-
prise. Proceedings of the IEEE, 100(9):2759?2776.
Vincent Ng. 2010. Supervised noun phrase corefer-
ence research: the first fifteen years. In Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics, ACL ?10, pages 1396?
1411.
Patrick Pantel. 2006. Alias detection in malicious en-
vironments. In AAAI Fall Symposium on Capturing
and Using Patterns for Evidence Detection, pages
14?20.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th annual meet-
ing of the Association for Computational Linguistics
on Computational Linguistics, ACL ?99, pages 519?
526.
Li Shao and Hwee Tou Ng. 2004. Mining new word
translations from comparable corpora. In Proceed-
ings of the 20th international conference on Compu-
tational Linguistics, COLING ?04.
Yizhou Sun, Rick Barber, Manish Gupta, Charu C. Ag-
garwal, and Han Jiawei. 2011a. Co-author relation-
ship prediction in heterogeneous bibliographic net-
works. In Proceedings of the 2011 International
Conference on Advances in Social Networks Anal-
ysis and Mining, ASONAM ?11, pages 121?128.
1092
Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and
Tianyi Wu. 2011b. Pathsim: Meta path-based top-k
similarity search in heterogeneous information net-
works. PVLDB, 4(11):992?1003.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology
- Volume 1, NAACL ?03, pages 173?180.
Raghavendra Udupa, K. Saravanan, A. Kumaran, and
Jagadeesh Jagarlamudi. 2009. Mint: a method
for effective and scalable mining of named entity
transliterations from large comparable corpora. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Lin-
guistics, EACL ?09, pages 799?807.
Robert A. Wagner and Michael J. Fischer. 1974.
The string-to-string correction problem. J. ACM,
21(1):168?173.
Chao Wang, Venu Satuluri, and Srinivasan
Parthasarathy. 2007. Local probabilistic mod-
els for link prediction. In Proceedings of the 2007
Seventh IEEE International Conference on Data
Mining, ICDM ?07, pages 322?331.
Zhen Wen and Ching-Yung Lin. 2010. On the qual-
ity of inferring interests from social neighbors. In
KDD, pages 373?382.
Zi Yang, Keke Cai, Jie Tang, Li Zhang, Zhong Su, and
Juanzi Li. 2011. Social context summarization. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, SIGIR ?11, pages 255?264.
Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun
Liu. 2003. Hhmm-based chinese lexical analyzer
ictclas. In Proceedings of the second SIGHAN work-
shop on Chinese language processing - Volume 17,
SIGHAN ?03, pages 184?187.
1093
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 380?390,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Collective Tweet Wikification based on Semi-supervised Graph
Regularization
Hongzhao Huang
1
, Yunbo Cao
2
, Xiaojiang Huang
2
, Heng Ji
1
, Chin-Yew Lin
2
1
Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180, USA
2
Microsoft Research Asia, Beijing 100080, P.R.China
{huangh9,jih}@rpi.edu
1
,
{yunbo.cao,xiaojih,cyl}@microsoft.com
2
Abstract
Wikification for tweets aims to automat-
ically identify each concept mention in a
tweet and link it to a concept referent in
a knowledge base (e.g., Wikipedia). Due
to the shortness of a tweet, a collective
inference model incorporating global ev-
idence from multiple mentions and con-
cepts is more appropriate than a non-
collecitve approach which links each men-
tion at a time. In addition, it is chal-
lenging to generate sufficient high quality
labeled data for supervised models with
low cost. To tackle these challenges, we
propose a novel semi-supervised graph
regularization model to incorporate both
local and global evidence from multi-
ple tweets through three fine-grained re-
lations. In order to identify semantically-
related mentions for collective inference,
we detect meta path-based semantic rela-
tions through social networks. Compared
to the state-of-the-art supervised model
trained from 100% labeled data, our pro-
posed approach achieves comparable per-
formance with 31% labeled data and ob-
tains 5% absolute F1 gain with 50% la-
beled data.
1 Introduction
With millions of tweets posted daily, Twitter en-
ables both individuals and organizations to dis-
seminate information, from current affairs to
breaking news in a timely fashion. In this
work, we study the wikification (Disambiguation
to Wikipedia) task (Mihalcea and Csomai, 2007)
for tweets, which aims to automatically identify
each concept mention in a tweet, and link it to a
concept referent in a knowledge base (KB) (e.g.,
Wikipedia). For example, as shown in Figure 1,
Hawks is an identified mention, and its correct ref-
erent concept in Wikipedia is Atlanta Hawks. An
end-to-end wikification system needs to solve two
sub-problems: (i) concept mention detection, (ii)
concept mention disambiguation.
Wikification is a particularly useful task for
short messages such as tweets because it allows
a reader to easily grasp the related topics and en-
riched information from the KB. From a system-
to-system perspective, wikification has demon-
strated its usefulness in a variety of applica-
tions, including coreference resolution (Ratinov
and Roth, 2012) and classification (Vitale et al,
2012).
Sufficient labeled data is crucial for supervised
models. However, manual wikification annota-
tion for short documents is challenging and time-
consuming (Cassidy et al, 2012). The challenges
are: (i) unlinkability, a valid concept may not ex-
ist in the KB. (ii) ambiguity, it is impossible to
determine the correct concept due to the dearth
of information within a single tweet or multiple
correct answer. For instance, it would be diffi-
cult to determine the correct referent concept for
?Gators? in t
1
in Figure 1. Linking ?UCONN?
in t
3
to University of Connecticut may also be ac-
ceptable since Connecticut Huskies is the athletic
team of the university. (iii) prominence, it is chal-
lenging to select a set of linkable mentions that
are important and relevant. It is not tricky to select
?Fans?, ?slump?, and ?Hawks? as linkable men-
tions, but other mentions such as ?stay up? and
?stay positive? are not prominent. Therefore, it
is challenging to create sufficient high quality la-
beled tweets for supervised models and worth con-
sidering semi-supervised learning with the explo-
ration of unlabeled data.
380
    
Stay up Hawk Fans. We are going 
through a slump now, but we have to 
stay positive. Go Hawks!
Congrats to UCONN and Kemba Walker. 
5 wins in 5 days, very impressive...
Just getting to the Arena, we play the 
Bucks tonight. Let's get it!
Fan (person); Mechanical fan
Slump (geology);  Slump (sports)
Atlanta Hawks;  Hawks (film)
University of Connecticut; Connecticut Huskies
Kemba Walker
Arena; Arena (magazine); Arena (TV series)
Bucks County, Pennsylvania; Milwaukee Bucks
Tweets Concept Candidates
Go Gators!!! Florida Gators football; Florida Gators men's basketballt1
t2
t3
t4
Figure 1: An illustration of Wikification Task for Tweets. Concept mentions detected in tweets are
marked as bold, and correctly linked concepts are underlined. The concept candidates are ranked by
their prior popularity which will be explained in section 4.1, and only top 2 ranked concepts are listed.
However, when selecting semi-supervised
learning frameworks, we noticed another unique
challenge that tweets pose to wikification due
to their informal writing style, shortness and
noisiness. The context of a single tweet usually
cannot provide enough information for prominent
mention detection and similarity computing for
disambiguation. Therefore, a collective inference
model over multiple tweets in the semi-supervised
setting is desirable. For instance, the four tweets
in Figure 1 are posted by the same author within
a short time period. If we perform collective
inference over them we can reliably link am-
biguous mentions such as ?Gators?, ?Hawks?,
and ?Bucks? to basketball teams instead of other
concepts such as the county Bucks County.
In order to address these unique challenges
for wikification for the short tweets, we employ
graph-based semi-supervised learning algorithms
(Zhu et al, 2003; Smola and Kondor, 2003; Blum
et al, 2004; Zhou et al, 2004; Talukdar and
Crammer, 2009) for collective inference by ex-
ploiting the manifold (cluster) structure in both
unlabeled and labeled data. These approaches
normally assume label smoothness over a defined
graph, where the nodes represent a set of labeled
and unlabeled instances, and the weighted edges
reflect the closeness of each pair of instances. In
order to construct a semantic-rich graph capturing
the similarity between mentions and concepts for
the model, we introduce three novel fine-grained
relations based on a set of local features, social
networks and meta paths.
The main contributions of this paper are sum-
marized as follows:
? To the best of our knowledge, this is the first
effort to explore graph-based semi-supervised
learning algorithms for the wikification task.
? We propose a novel semi-supervised graph reg-
ularization model performing collective infer-
ence for joint mention detection and disam-
biguation. Our approach takes advantage of
three proposed principles to incorporate both lo-
cal and global evidence from multiple tweets.
? We propose a meta path-based unified frame-
work to detect both explicitly and implicitly rel-
evant mentions.
2 Preliminaries
Concept and Concept Mention We define a con-
cept c as a Wikipedia article (e.g., Atlanta Hawks),
and a concept mentionm as an n-gram from a spe-
cific tweet. Each concept has a set of textual repre-
sentation fields (Meij et al, 2012), including title
(the title of the article), sentence (the first sentence
of the article), paragraph (the first paragraph of
the article), content (the entire content of the arti-
cle), and anchor (the set of all anchor texts with
incoming links to the article).
Wikipedia Lexicon Construction We first
construct an offline lexicon with each entry as
?m, {c
1
, ..., c
k
}?, where {c
1
, ..., c
k
} is the set of
possible referent concepts for the mention m.
Following the previous work (Bunescu, 2006;
Cucerzan, 2007; Hachey et al, 2013), we extract
the possible mentions for a given concept c using
the following resources: the title of c; the aliases
appearing in the introduction and infoboxes of c
(e.g., The Evergreen State is an alias of Wash-
ington state); the titles of pages redirecting to c
(e.g., State of Washington is a redirecting page of
Washington (state)); the titles of the disambigua-
381
tion pages containing c; and all the anchor texts
appearing in at least 5 pages with hyperlinks to c
(e.g., WA is a mention for the concept Washing-
ton (state) in the text ?401 5th Ave N [[Seattle]],
[[Washington (state)?WA]] 98109 USA?. We also
propose three heuristic rules to extract mentions
(i.e., different combinations of the family name
and given name for a person, the headquarters of
an organization, and the city name for a sports
team).
Concept Mention Extraction Based on the
constructed lexicon, we then consider all n-grams
of size? n (n=7 in this paper) as concept mention
candidates if their entries in the lexicon are not
empty. We first segment @usernames and #hash-
tags into regular tokens (e.g., @amandapalmer is
segmented as amanda palmer and #WorldWater-
Day is split as World Water Day) using the ap-
proach proposed by (Wang et al, 2011). Segmen-
tation assists finding concept candidates for these
non-regular mentions.
3 Principles and Approach Overview
    
R elational Graph Construction
Knowledge Base 
(Wikipedia)
Labeled and 
Unlabeled Tweets
Wikipedia Lex icon Construction
Concept Mention and 
Concept Candidate E x traction
Local Compatibility
(local features, 
cosine similarity)
Coreference
(meta path,
mention 
similarity)
Semantic R elatedness
(meta path, concept 
semantic relatedness)
Semi- Supervised Graph R egularization
<Mention, Concept>
Pairs
Figure 2: Approach Overview.
3.1 Principles
A single tweet may not provide enough evidence
to identify prominent mentions and infer their cor-
rect referent concepts due to the lack of contextual
information. To tackle this problem, we propose to
incorporate global evidence from multiple tweets
and performing collective inference for both men-
tion identification and disambiguation. We first in-
troduce the following three principles that our ap-
proach relies on.
Principle 1 (Local compatibility): Two pairs
of ?m, c? with strong local compatibility tend to
have similar labels. Mentions and their correct
referent concepts usually tend to share a set of
characteristics such as string similarity betweenm
and c (e.g., ?Chicago, Chicago? and ?Facebook,
Facebook?). We define the local compatibility to
model such set of characteristics.
Principle 2 (Coreference): Two coreferential
mentions should be linked to the same concept.
For example, if we know ?nc? and ?North Car-
olina? are coreferential, then they should both be
linked to North Carolina.
Principle 3 (Semantic Relatedness): Two
highly semantically-related mentions are more
likely to be linked to two highly semantically-
related concepts. For instance, when ?Sweet 16?
and ?Hawks? often appear together within rel-
evant contexts, they can be reliably linked to
two baseketball-related concepts NCAA Men?s Di-
vision I Basketball Championship and Atlanta
Hawks, respectively.
3.2 Approach Overview
Given a set of tweets ?t
1
, ..., t
|T |
?, our system first
generates a set of candidate concept mentions, and
then extracts a set of candidate concept referents
for each mention based on the Wikipedia lexicon.
Given a pair of mention and its candidate referent
concept ?m, c?, the remaining task of wikification
is to assign either a positive label if m should be
selected as a prominently linkable mention and c
is its correct referent concept, or otherwise a neg-
ative label. The label assignment is obtained by
our semi-supervised graph regularization frame-
work based on a relational graph, which is con-
structed from local compatibility, coreference, and
semantic relatedness relations. The overview of
our approach is as illustrated in Figure 2.
4 Relational Graph Construction
We first construct the relational graphG = ?V,E?,
where V = {v
1
, ..., v
n
} is a set of nodes and E =
{e
1
, ..., e
m
} is a set of edges. Each v
i
= ?m
i
, c
i
?
represents a tuple of mention m
i
and its referent
concept candidate c
i
. An edge is added between
two nodes v
i
and v
j
if there is a proposed rela-
tion based on the three principles described in sec-
tion 3.1.
4.1 Local Compatibility
We first compute local compatibility (Principle 1)
by considering a set of novel local features to cap-
382
ture the importance and relevance of a mention m
to a tweet t, as well as the correctness of its link-
age to a concept c. We have designed a number
of features which are similar to those commonly
used in wikification and entity linking work (Meij
et al, 2012; Guo et al, 2013; Mihalcea and Cso-
mai, 2007).
Mention Features We define the following fea-
tures based on information from mentions.
? IDF
f
(m) = log(
|C|
df(m)
), where |C| is the total
number of concepts in Wikipedia and df(m) is
the total number of concepts in whichm occurs,
and f indicates the field property, including ti-
tle, content, and anchor.
? Keyphraseness(m) =
|C
a
(m)|
df(m)
to measure
how likely m is used as an anchor in Wikipedia,
where C
a
(m) is the set of concepts where m
appears as an anchor.
? LinkProb(m) =
?
c?C
a
(m)
count(m,c)
?
c?C
count(m,c)
, where
count(m, c) indicates the number of occurrence
of m in c.
? SNIL(m) and SNCL(m) to count the number
of concepts that are equal to or contain a sub-n-
gram of m, respectively (Meij et al, 2012).
Concept Features The concept features are
solely based on Wikipedia, including the number
of incoming and outgoing links for c, and the num-
ber of words and characters in c.
Mention + Concept Features This set of fea-
tures considers information from both mentions
and concepts:
? prior popularity prior(m, c) =
count(m,c)?
c
?
count(m,c
?
)
, where count(m, c) mea-
sures the frequency of the anchor links from m
to c in Wikipedia.
? TF
f
(m, c) =
count
f
(m,c)
|f |
to measure the rela-
tive frequency of m in each field representation
f of c, normalized by the length of f . The fields
include title, sentence, paragraph, content and
anchor.
? NCT (m, c), TCN(m, c), and TEN(m, c) to
measure whether m contains the title of c,
whether the title of c contains m, and whether
m equals to the title of c, respectively.
Context Features This set of features include
(i) Context Capitalization features, which indicate
whether the current mention, the token before, and
the token after are capitalized. (ii) tf-idf based fea-
tures, which include the dot product of two word
vectors v
c
and v
t
, and the average tf-idf value of
common items in v
c
and v
t
, where v
c
and v
t
are
the top 100 tf-idf word vectors in c and t.
Local Compatibility Computation For each
node v
i
= ?m
i
, c
i
?, we collect its local features
as a feature vector F
i
= ?f
1
, f
2
, ..., f
d
?. To avoid
features with large numerical values that domi-
nate other features, the value of each feature is
re-scaled using feature standardization approach.
The cosine similarity is then adopted to compute
the local compatibility of two nodes and construct
a k nearest neighbor (kNN) graph, where each
node is connected to its k nearest neighboring
nodes. We compute the weight matrix that rep-
resents the local compatibility relation as:
W
loc
ij
=
{
cosine(F
i
, F
j
) j ? kNN(i)
0 Otherwise
4.2 Meta Path
    
Mention
Hashtag
Tweet User
post - 1
post
contain - 1
contain
contain - 1 contain
Figure 3: Schema of the Twitter network.
In this subsection, we introduce the concept
meta path which will be used to detect corefer-
ence (section 4.3) and semantic relatedness rela-
tions (section 4.4).
A meta-path is a path defined over a network
and composed of a sequence of relations between
different object types (Sun et al, 2011b). In our
experimental setting, we can construct a natu-
ral Twitter network summarized by the network
schema in Figure 3. The network contains four
types of objects: Mention (M), Tweet (T), User
(U), and Hashtag (H). Tweets and mentions are
connected by links ?contain? and ?contained by?
(denoted as ?contain
?1
?); and other linked rela-
tionships can be described similarly.
We then define the following five types of meta
paths to connect two mentions as:
? ?M - T - M?,
? ?M - T - U - T - M?,
? ?M - T - H - T - M?,
? ?M - T - U - T - M - T - H - T - M?,
? ?M - T - H - T - M - T - U - T - M?.
383
Each meta path represents one particular seman-
tic relation. For instance, the first three paths are
basic ones expressing the explicit relations that
two mentions are from the same tweet, posted by
the same user, and share the same #hashtag, re-
spectively. The last two paths are concatenated
ones which are constructed by concatenating the
first three simple paths to express the implicit rela-
tions that two mentions co-occur with a third men-
tion sharing either the same authorship or #hash-
tag. Such complicated paths can be exploited to
detect more semantically-related mentions from
wider contexts. For example, the relational link
between ?narita airport? and ?Japan? would be
missed without using the path ?narita airport - t
1
- u
1
- t
2
- american - t
3
- h
1
- t
4
- Japan? since they
don?t directly share any authorships or #hashtags.
4.3 Coreference
A coreference relation (Principle 2) usually occurs
across multiple tweets due to the highly redundant
information in Twitter. To ensure high precision,
we propose a simple yet effective approach utiliz-
ing the rich social network relations in Twitter.
We consider two mentions m
i
and m
j
corefer-
ential if m
i
and m
j
share the same surface form
or one is an abbreviation of the other, and at least
one meta path exists betweenm
i
andm
j
. Then we
define the weight matrix representing the corefer-
ential relation as:
W
coref
ij
=
?
?
?
1.0 if m
i
and m
j
are coreferential,
and c
i
= c
j
0 Otherwise
4.4 Semantic Relatedness
Ensuring topical coherence (Principle 3) has been
beneficial for wikification on formal texts (e.g.,
News) by linking a set of semantically-related
mentions to a set of semantically-related concepts
simultaneously (Han et al, 2011; Ratinov et al,
2011; Cheng and Roth, 2013). However, the short-
ness of a single tweet means that it may not pro-
vide enough topical clues. Therefore, it is impor-
tant to extend this evidence to capture semantic re-
latedness information from multiple tweets.
We define the semantic relatedness score be-
tween two mentions as SR(m
i
,m
j
) = 1.0 if at
least one meta path exists between m
i
and m
j
,
otherwise SR(m
i
,m
j
) = 0. In order to compute
the semantic relatedness of two concepts c
i
and
c
j
, we adopt the approach proposed by (Milne and
Witten, 2008a):
SR(c
i
, c
j
) = 1?
logmax(|C
i
|, |C
j
|)? log |C
i
? C
j
|
log(|C|)? logmin(|C
i
|, |C
j
|)
,
where |C| is the total number of concepts in
Wikipedia, and C
i
and C
j
are the set of concepts
that have links to c
i
and c
j
, respectively.
Then we compute a weight matrix representing
the semantic relatedness relation as:
W
rel
ij
=
{
SR(N
i
, N
j
) if SR(N
i
, N
j
) ? ?
0 Otherwise
where SR(N
i
, N
j
) = SR(m
i
,m
j
) ? SR(c
i
, c
j
)
and ? = 0.3, which is optimized from a develop-
ment set.
4.5 The Combined Relational Graph
    
hawks, 
 Atlanta Hawks
uconn, 
Connecticut 
Huskies
bucks, 
Milwaukee 
Bucks
kemba walker, 
Kemba Walker
0 .40 4
gators, 
Florida Gators 
men's basketball
now, 
N ow
days, 
D ay
tonight, 
Tonight
0 .9 32
0 .7 6 4
0 .6 6 5
0 .46 7
0 .56 3 0 .538
0 .447
Figure 4: A example of the relational graph con-
structed for the example tweets in Figure 1. Each
node represents a pair of ?m, c?, separated by a
comma. The edge weight is obtained from the lin-
ear combination of the weights of the three pro-
posed relations. Not all mentions are included due
to the space limitations.
Based on the above three weight matricesW
loc
,
W
coref
, and W
rel
, we first obtain their corre-
sponding transition matrices P
loc
, P
coref
, and
P
rel
, respectively. The entry P
ij
of the transition
matrix P for a weight matrix W is computed as
P
ij
=
W
ij?
k
W
ik
such that
?
k
P
ik
= 1. Then we
obtain the combined graph G with weight matrix
W , where W
ij
= ?P
loc
ij
+ ?P
coref
ij
+ ?P
rel
ij
. ?,
?, and ? are three coefficients between 0 and 1
with the constraint that ?+ ? + ? = 1. They con-
trol the contributions of these three relations in our
semi-supervised graph regularization model. We
choose transition matrix to avoid the domination
of one relation over others. An example graph of
G is shown in Figure 4. Compared to the referent
graph which considers each mention or concept
as a node in previous graph-based re-ranking ap-
proaches (Han et al, 2011; Shen et al, 2013), our
384
novel graph representation has two advantages: (i)
It can easily incorporate more features related to
both mentions and concepts. (ii) It is more appro-
priate for our graph-based semi-supervised model
since it is difficult to assign labels to a pair of men-
tion and concept in the referent graph.
5 Semi-supervised Graph Regularization
Given the constructed relational graph with the
weighted matrix W and the label vector Y of all
nodes, we assume the first l nodes are labeled as
Y
l
and the remaining u nodes (u = n? l) are ini-
tialized with labels Y
0
u
. Then our goal is to refine
Y
0
u
and obtain the final label vector Y
u
.
Intuitively, if two nodes are strongly connected,
they tend to hold the same label. We propose a
novel semi-supervised graph regularization frame-
work based on the graph-based semi-supervised
learning algorithm (Zhu et al, 2003):
Q(Y) = ?
n
?
i=l+1
(y
i
?y
0
i
)
2
+
1
2
?
i,j
W
ij
(y
i
?y
j
)
2
.
The first term is a loss function that incorporates
the initial labels of unlabeled examples into the
model. In our method, we adopt prior popular-
ity (section 4.1) to initialize the labels of the un-
labeled examples. The second term is a regular-
izer that smoothes the refined labels over the con-
structed graph. ? is a regularization parameter that
controls the trade-off between initial labels and the
consistency of labels on the graph. The goal of the
proposed framework is to ensure that the refined
labels of unlabeled nodes are consistent with their
strongly connected nodes, as well as not too far
away from their initial labels.
The above optimization problem can be solved
directly since Q(Y) is convex (Zhu et al, 2003;
Zhou et al, 2004). Let I be an identity matrix
and D
W
be a diagonal matrix with entries D
ii
=
?
j
W
ij
. We can split the weighted matrix W into
four blocks as W =
[
W
ll
W
lu
W
ul
W
uu
]
, where W
mn
is
anm?nmatrix. D
w
is split similarly. We assume
that the vector of the labeled examples Y
l
is fixed,
so we only need to infer the refined label vector of
the unlabeled examples Y
u
. In order to minimize
Q(Y), we need to find Y
?
u
such that
?Q
?Y
u
?
?
?
?
Y
u
=Y
?
u
= (D
uu
+ ?I
uu
)Y
u
?W
uu
Y
u
?
W
ul
Y
l
? ?Y
0
u
= 0.
Therefore, a closed form solution can be derived
as Y
?
u
= (D
uu
+ ?I
uu
?W
uu
)
?1
(W
ul
Y
l
+ ?Y
0
u
).
However, for practical application to a large-
scale data set, an iterative solution would be more
efficient to solve the optimization problem. Let
Y
t
u
be the refined labels after the t
th
iteration, the
iterative solution can be derived as:
Y
t+1
u
= (D
uu
+?I
uu
)
?1
(W
uu
Y
t
u
+W
ul
Y
l
+?Y
0
u
).
The iterative solution is more efficient since
(D
uu
+ ?I
uu
) is a diagonal matrix and its inverse
is very easy to compute.
6 Experiments
In this section we compare our approach with
state-of-the-art methods as shown in Table 1.
6.1 Data and Scoring Metric
For our experiments we use a public data set (Meij
et al, 2012) including 502 tweets posted by 28
verified users. The data set was annotated by two
annotators. We randomly sample 102 tweets for
development and the remaining for evaluation. We
use a Wikipedia dump on May 3, 2013 as our
knowledge base, which includes 30 million pages.
For computational efficiency, we also filter some
mention candidates by applying the preprocess-
ing approach proposed in (Ferragina and Scaiella,
2010), and remove all the concepts with prior pop-
ularity less than 2% from an mention?s concept set
for each mention, similar to (Guo et al, 2013).
A mention and concept pair ?m, c? is judged as
correct if and only if m is linkable and c is the
correct referent concept for m. To evaluate the
performance of a wikification system, we use the
standard precision, recall and F1 measures.
6.2 Experimental Results
The overall performance of various approaches
is shown in Table 2. The results of the super-
vised method proposed by (Meij et al, 2012) are
obtained from 5-fold cross validation. For our
semi-supervised setting, we experimentally sam-
ple 200 tweets for training and use the remain-
ing set as unlabeled and testing sets. In our semi-
supervised regularization model, the matrix W
loc
is constructed by a kNN graph (k = 20). The reg-
ularization parameter ? is empirically set to 0.1,
and the coefficients ?, ?, and ? are learnt from the
development set by considering all the combina-
385
Methods Descriptions
TagMe The same approach that is described in (Ferragina and Scaiella, 2010), which aims to annotate short
texts based on prior popularity and semantic relatedness of concepts. It is basically an unsupervised
approach, except that it needs a development set to tune the probability threshold for linkable mentions.
Meij A state-of-the-art system described in (Meij et al, 2012), which is a supervised approach based on the
random forest model. It performs mention detection and disambiguation jointly, and it is trained from
400 labeled tweets.
SSRegu
1
Our proposed model based on Principle 1, using 200 labeled tweets.
SSRegu
12
Our proposed model based on Principle 1 and 2, using 200 labeled tweets.
SSRegu
13
Our proposed model based on Principle 1 and 3, using 200 labeled tweets.
SSRegu
123
Our proposed full model based on Principle 1, 2 and 3, using 200 labeled tweets.
Table 1: Description of Methods.
Methods Precision Recall F1
TagMe 0.329 0.423 0.370
Meij 0.393 0.598 0.475
SSRegu
1
0.538 0.435 0.481
SSRegu
12
0.638 0.438 0.520
SSRegu
13
0.541 0.457 0.495
SSRegu
123
0.650 0.441 0.525
Table 2: Overall Performance.
tions of values from 0 to 1 at 0.1 intervals
1
. In
order to randomize the experiments and make the
comparison fair, we conduct 20 test runs for each
method and report the average scores across the 20
trials.
The relatively low performance of the baseline
system TagMe demonstrates that only relying on
prior popularity and topical information within a
single tweet is not enough for an end-to-end wik-
ification system for the short tweets. As an exam-
ple, it is difficult to obtain topical clues in order
to link the mention ?Clinton? to Hillary Rodham
Clinton by relying on the single tweet ?wolfblitzer-
cnn: Behind the scenes on Clinton?s Mideast trip
#cnn?. Therefore, the system mistakenly links it
to the most popular concept Bill Clinton.
In comparision with the supervised baseline
proposed by (Meij et al, 2012), our model
SSRegu
1
relying on local compatibility already
achieves comparable performance with 50% of
labeled data. This is because that our model
performs collective inference by making use of
the manifold (cluster) structure of both labeled
and unlabeled data, and that the local compat-
ibility relation is detected with high precision
2
(89.4%). For example, the following three pairs
of mentions and concepts ?pelosi, Nancy Pelosi?,
?obama, Barack Obama?, and ?gaddafi, Muam-
1
These three coefficients are slightly different with differ-
ent training data, a sample of them is: ? = 0.4, ? = 0.5, and
? = 0.1
2
Here we define precision as the percentage of links that
holds the same label.
mar Gaddafi? have strong local compatibility with
each other since they share many similar char-
acteristics captured by the local features such as
string similarity between the mention and the con-
cept. Suppose the first pair is labeled, then its pos-
itive label will be propagated to other unlabeled
nodes through the local compatibility relation, and
correctly predict the labels of other nodes.
Incorporating coreferential or semantic related-
ness relation into SSRegu
1
provides further gains,
demonstrating the effectiveness of these two re-
lations. For instance, ?wh? is correctly linked to
White House by incorporating evidence from its
coreferential mention ?white house?. The corefer-
ential relation (Principle 2) is demonstrated to be
more beneficial than the semantic relatedness re-
lation (Principle 3) because the former is detected
with much higher precision (99.7%) than the latter
(65.4%).
Our full model SSRegu
123
achieves significant
improvement over the supervised baseline (5% ab-
solute F1 gain with 95.0% confidence level by
the Wilcoxon Matched-Pairs Signed-Ranks Test),
showing that incorporating global evidence from
multiple tweets with fine-grained relations is ben-
eficial. For instance, the supervised baseline fails
to link ?UCONN? and ?Bucks? in our examples
to Connecticut Huskies and Milwaukee Bucks, re-
spectively. Our full model corrects these two
wrong links by propagating evidence through the
semantic links as shown in Figure 4 to obtain mu-
tual ranking improvement. The best performance
of our full model also illustrates that the three re-
lations complement each other.
We also study the disambiguation performance
for the annotated mentions, as shown in Table 3.
We can easily see that our proposed approach
using 50% labeled data achieves similar perfor-
mance with the state-of-the-art supervised model
with 100% labeled data. When the mentions are
given, the unpervised approach TagMe has already
386
Methods TagMe Meij SSRegu
123
Accuracy 0.710 0.779 0.772
Table 3: Disambiguation Performance.
Methods Precision Recall F1
SSRegu
12
0.644 0.423 0.510
SSRegu
13
0.543 0.441 0.486
SSRegu
123
0.657 0.419 0.512
Table 4: The Performance of Systems Without Us-
ing Concatenated Meta Paths.
achieved reasonable performance. In fact, mention
detection actually is the performance bottleneck of
a tweet wikification system (Guo et al, 2013). Our
system performs better in identifying the promi-
nent mention.
6.3 Effect of Concatenated Meta Paths
In this work, we propose a unified framework uti-
lizing meta path-based semantic relations to ex-
plore richer relevant context. Beyond the basic
meta paths, we introduce concatenated ones by
concatenating the basic ones. The performance of
the system without using the concatenated meta
paths is shown in Table 4. In comparison with
the system based on all defined meta paths, we
can clearly see that the systems using concate-
nated ones outperform those relying on the sim-
ple ones. This is because the concatenated meta
paths can incorporate more relevant information
with implicit relations into the models by increas-
ing 1.6% coreference links and 9.3% semantic re-
latedness links. For example, the mention ?narita
airport? is correctly disambiguated to the concept
?Narita International Airport? with higher confi-
dence since its semantic relatedness relation with
?Japan? is detected with the concatenated meta
path as described in section 4.2.
6.4 Effect of Labeled Data Size
5 0 1 0 0 1 5 0 2 0 0 2 5 0 3 0 0 3 5 0 4 0 00 . 3 00 . 3 50 . 4 00 . 4 5
0 . 5 00 . 5 50 . 6 0F1 L a b e l e d  T w e e t  S i z e S S R e g u 1 2 3 M e i j
Figure 5: The effect of Labeled Tweet Size.
In previous experiments, we experimentally set
the number of labeled tweets to be 200 for over-
all performance comparision with the baselines.
In this subsection, we study the effect of labeled
data size on our full model. We randomly sam-
ple 100 tweets as testing data, and randomly se-
lect 50, 100, 150, 200, 250, and 300 tweets as
labeled data. 20 test runs are conducted and the
average results are reported across the 20 trials,
as shown in Figure 5. We find that as the size
of the labeled data increases, our proposed model
achieves better performance. It is encouraging to
see that our approach, with only 31.3% labeled
tweets (125 out of 400), already achieves a perfor-
mance that is comparable to the state-of-the-art su-
pervised model trained from 100% labeled tweets.
6.5 Parameter Analysis
0 . 1 0 . 5 1 2 5 1 0 2 0 3 0 4 0 5 00 . 3 00 . 3 50 . 4 00 . 4 5
0 . 5 00 . 5 50 . 6 0F1 R e g u l a r i z a t i o n  P a r a m e t e r  ? S S R e g u 1 2 3
Figure 6: The effect of parameter ?.
In previous experiments, we empirically set the
parameter ? = 0.1. ? is the regularization pa-
rameter that controls the trade-off between initial
labels and the consistency of labels on the graph.
When ? increases, the model tends to trust more in
the initial labels. Figure 6 shows the performance
of our models by varying ? from 0.02 to 50. We
can easily see that the system performce is stable
when ? < 0.4. However, when ? ? 0.4, the sys-
tem performance dramatically decreases, showing
that prior popularity is not enough for an end-to-
end wikification system.
7 Related Work
The task of linking concept mentions to a knowl-
edge base has received increased attentions over
the past several years, from the linking of concept
mentions in a single text (Mihalcea and Csomai,
2007; Milne and Witten, 2008b; Milne and Witten,
2008a; Kulkarni et al, 2009; He et al, 2011; Rati-
nov et al, 2011; Cassidy et al, 2012; Cheng and
Roth, 2013), to the linking of a cluster of corefer-
387
ent named entity mentions spread throughout dif-
ferent documents (Entity Linking) (McNamee and
Dang, 2009; Ji et al, 2010; Zhang et al, 2010; Ji et
al., 2011; Zhang et al, 2011; Han and Sun, 2011;
Han et al, 2011; Gottipati and Jiang, 2011; He et
al., 2013; Li et al, 2013; Guo et al, 2013; Shen et
al., 2013; Liu et al, 2013).
A significant portion of recent work considers
the two sub-problems mention detection and men-
tion disambiguation separately and focus on the
latter by first defining candidate concepts for a
deemed mention based on anchor links. Men-
tion disambiguation is then formulated as a rank-
ing problem, either by resolving one mention at
each time (non-collective approaches), or by dis-
ambiguating a set of relevant mentions simulta-
neously (collective approaches). Non-collective
methods usually rely on prior popularity and con-
text similarity with supervised models (Mihalcea
and Csomai, 2007; Milne and Witten, 2008b; Han
and Sun, 2011), while collective approaches fur-
ther leverage the global coherence between con-
cepts normally through supervised or graph-based
re-ranking models (Cucerzan, 2007; Milne and
Witten, 2008b; Han and Zhao, 2009; Kulkarni et
al., 2009; Pennacchiotti and Pantel, 2009; Ferrag-
ina and Scaiella, 2010; Fernandez et al, 2010;
Radford et al, 2010; Cucerzan, 2011; Guo et al,
2011; Han and Sun, 2011; Han et al, 2011; Rati-
nov et al, 2011; Chen and Ji, 2011; Kozareva et
al., 2011; Cassidy et al, 2012; Shen et al, 2013;
Liu et al, 2013). Especially note that when apply-
ing the collective methods to short messages from
social media, evidence from other messages usu-
ally needs to be considered (Cassidy et al, 2012;
Shen et al, 2013; Liu et al, 2013). Our method
is a collective approach with the following novel
advancements: (i) A novel graph representation
with fine-grained relations, (ii) A unified frame-
work based on meta paths to explore richer rele-
vant context, (iii) Joint identification and linking
of mentions under semi-supervised setting.
Two most similar methods to ours were pro-
posed by (Meij et al, 2012; Guo et al, 2013)
by performing joint detection and disambiguation
of mentions. (Meij et al, 2012) studied several
supervised machine learning models, but without
considering any global evidence either from a sin-
gle tweet or other relevant tweets. (Guo et al,
2013) explored second order entity-to-entity rela-
tions but did not incorporate evidence from multi-
ple tweets.
This work is also related to graph-based semi-
supervised learning (Zhu et al, 2003; Smola
and Kondor, 2003; Zhou et al, 2004; Talukdar
and Crammer, 2009), which has been success-
fully applied in many Natural Language Process-
ing tasks (Niu et al, 2005; Chen et al, 2006).
We introduce a novel graph that incorporates three
fine-grained relations. Our work is further re-
lated to meta path-based heterogeneous informa-
tion network analysis (Sun et al, 2011b; Sun et
al., 2011a; Kong et al, 2012; Huang et al, 2013),
which has demonstrated advantages over homoge-
neous information network analysis without dif-
ferentiating object types and relational links.
8 Conclusions
We have introduced a novel semi-supervised graph
regularization framework for wikification to si-
multaneously tackle the unique challenges of an-
notation and information shortage in short tweets.
To the best of our knowledge, this is the first work
to explore the semi-supervised collective inference
model to jointly perform mention detection and
disambiguation. By studying three novel fine-
grained relations, detecting semantically-related
information with semantic meta paths, and ex-
ploiting the data manifolds in both unlabeled and
labeled data for collective inference, our work can
dramatically save annotation cost and achieve bet-
ter performance, thus shed light on the challenging
wikification task for tweets.
Acknowledgments
This work was supported by the U.S. Army Re-
search Laboratory under Cooperative Agreement
No. W911NF-09-2-0053 (NS-CTA), U.S. NSF
CAREER Award under Grant IIS-0953149, U.S.
DARPA Award No. FA8750-13-2-0041 in the
Deep Exploration and Filtering of Text (DEFT)
Program, IBM Faculty Award, Google Research
Award and RPI faculty start-up grant. The views
and conclusions contained in this document are
those of the authors and should not be inter-
preted as representing the official policies, either
expressed or implied, of the U.S. Government.
The U.S. Government is authorized to reproduce
and distribute reprints for Government purposes
notwithstanding any copyright notation here on.
388
References
A. Blum, J. Lafferty, M. Rwebangira, and R. Reddy.
2004. Semi-supervised learning using randomized
mincuts. In Proceedings of the Twenty-first Interna-
tional Conference on Machine Learning, ICML ?04.
Razvan Bunescu. 2006. Using encyclopedic knowl-
edge for named entity disambiguation. In EACL,
pages 9?16.
T. Cassidy, H. Ji, L. Ratinov, A. Zubiaga, and
H. Huang. 2012. Analysis and enhancement of wik-
ification for microblogs with context expansion. In
Proceedings of COLING 2012.
Z. Chen and H. Ji. 2011. Collaborative ranking: A
case study on entity linking. In Proc. EMNLP2011.
J. Chen, D. Ji, C Tan, and Z. Niu. 2006. Rela-
tion extraction using label propagation based semi-
supervised learning. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics.
X. Cheng and D. Roth. 2013. Relational inference
for wikification. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing.
Silviu Cucerzan. 2007. Large-scale named entity dis-
ambiguation based on wikipedia data. In EMNLP-
CoNLL 2007.
S. Cucerzan. 2011. Tac entity linking by performing
full-document entity extraction and disambiguation.
In Proc. TAC 2011 Workshop.
N. Fernandez, J. A. Fisteus, L. Sanchez, and E. Mar-
tin. 2010. Webtlab: A cooccurence-based approach
to kbp 2010 entity-linking task. In Proc. TAC 2010
Workshop.
P. Ferragina and U. Scaiella. 2010. Tagme: on-the-
fly annotation of short text fragments (by wikipedia
entities). In Proceedings of the 19th ACM inter-
national conference on Information and knowledge
management, CIKM ?10.
S. Gottipati and J. Jiang. 2011. Linking entities to a
knowledge base with query expansion. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing.
Y. Guo, W. Che, T. Liu, and S. Li. 2011. A graph-
based method for entity linking. In Proc. IJC-
NLP2011.
S. Guo, M. Chang, and E. Kiciman. 2013. To link
or not to link? a study on end-to-end tweet entity
linking. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies.
B. Hachey, W. Radford, J. Nothman, M. Honnibal, and
J. Curran. 2013. Evaluating entity linking with
wikipedia. Artif. Intell.
X. Han and L. Sun. 2011. A generative entity-mention
model for linking entities with knowledge base. In
Proc. ACL2011.
X. Han and J. Zhao. 2009. Named entity disam-
biguation by leveraging wikipedia semantic knowl-
edge. In Proceedings of the 18th ACM conference
on Information and knowledge management, CIKM
2009.
X. Han, L. Sun, and J. Zhao. 2011. Collective entity
linking in web text: A graph-based method. In Proc.
SIGIR2011.
J. He, M. de Rijke, M. Sevenster, R. van Ommering,
and Y. Qian. 2011. Generating links to background
knowledge: A case study using narrative radiology
reports. In Proceedings of the 20th ACM inter-
national conference on Information and knowledge
management. ACM.
Z. He, S. Liu, Y. Song, M. Li, M. Zhou, and H. Wang.
2013. Efficient collective entity linking with stack-
ing. In Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing.
H. Huang, Z. Wen, D. Yu, H. Ji, Y. Sun, J. Han, and
H. Li. 2013. Resolving entity morphs in censored
data. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers).
H. Ji, R. Grishman, H.T. Dang, K. Griffitt, and J. El-
lis. 2010. Overview of the tac 2010 knowledge base
population track. In Text Analysis Conference (TAC)
2010.
H. Ji, R. Grishman, and H.T. Dang. 2011. Overview
of the tac 2011 knowledge base population track. In
Text Analysis Conference (TAC) 2011.
X. Kong, P. Yu, Y. Ding, and J. Wild. 2012. Meta
path-based collective classification in heterogeneous
information networks. In Proceedings of the 21st
ACM International Conference on Information and
Knowledge Management, CIKM ?12.
Z. Kozareva, K. Voevodski, and S. Teng. 2011. Class
label enhancement via related instances. In Proc.
EMNLP2011.
S. Kulkarni, A. Singh, G. Ramakrishnan, and
S. Chakrabarti. 2009. Collective annotation of
wikipedia entities in web text. In KDD.
Y. Li, C. Wang, F. Han, J. Han, D. Roth, and X. Yan.
2013. Mining evidences for named entity dis-
ambiguation. In Proceedings of the 19th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ?13.
389
X. Liu, Y. Li, H. Wu, M. Zhou, F. Wei, and Y. Lu.
2013. Entity linking for tweets. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers).
P. McNamee and H.T. Dang. 2009. Overview of the
tac 2009 knowledge base population track. In Text
Analysis Conference (TAC) 2009.
E. Meij, W. Weerkamp, and M. de Rijke. 2012.
Adding semantics to microblog posts. In Proceed-
ings of the fifth ACM international conference on
Web search and data mining, WSDM ?12.
R. Mihalcea and A. Csomai. 2007. Wikify!: linking
documents to encyclopedic knowledge. In Proceed-
ings of the sixteenth ACM conference on Conference
on information and knowledge management, CIKM
?07.
D. Milne and I.H. Witten. 2008a. Learning to link
with wikipedia. In An effective, low-cost measure of
semantic relatedness obtained from wikipedia links.
the Wikipedia and AI Workshop of AAAI.
D. Milne and I.H. Witten. 2008b. Learning to link
with wikipedia. In Proceeding of the 17th ACM con-
ference on Information and knowledge management,
pages 509?518. ACM.
Z. Niu, D. Ji, and C. Tan. 2005. Word sense dis-
ambiguation using label propagation based semi-
supervised learning. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL?05).
M. Pennacchiotti and P. Pantel. 2009. Entity extraction
via ensemble semantics. In Proc. EMNLP2009.
W. Radford, B. Hachey, J. Nothman, M. Honnibal, and
J. R. Curran. 2010. Cmcrc at tac10: Document-
level entity linking with graph-based re-ranking. In
Proc. TAC 2010 Workshop.
L. Ratinov and D. Roth. 2012. Learning-based multi-
sieve co-reference resolution with knowledge. In
EMNLP.
L. Ratinov, D. Roth, D. Downey, and M. Anderson.
2011. Local and global algorithms for disambigua-
tion to wikipedia. In Proc. of the Annual Meeting of
the Association of Computational Linguistics (ACL).
W. Shen, J. Wang, P. Luo, and M. Wang. 2013. Link-
ing named entities in tweets with knowledge base
via user interest modeling. In Proceedings of the
19th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD ?13.
A. Smola and R. Kondor. 2003. Kernels and regular-
ization on graphs. COLT.
Y. Sun, R. Barber, M. Gupta, C. Aggarwal, and J. Han.
2011a. Co-author relationship prediction in hetero-
geneous bibliographic networks. In Proceedings of
the 2011 International Conference on Advances in
Social Networks Analysis and Mining, ASONAM
?11.
Y. Sun, J. Han, X. Yan, P. Yu, and T. Wu. 2011b. Path-
sim: Meta path-based top-k similarity search in het-
erogeneous information networks. PVLDB, 4(11).
P. Talukdar and K. Crammer. 2009. New regularized
algorithms for transductive learning. In Proceed-
ings of the European Conference on Machine Learn-
ing and Knowledge Discovery in Databases: Part II,
ECML PKDD ?09.
D. Vitale, P. Ferragina, and U. Scaiella. 2012. Clas-
sification of short texts by deploying topical annota-
tions. In ECIR, pages 376?387.
K. Wang, C. Thrasher, and B. Hsu. 2011. Web scale
nlp: A case study on url word breaking. In Proceed-
ings of the 20th International Conference on World
Wide Web, WWW ?11.
W. Zhang, J. Su, C. Tan, and W. Wang. 2010. En-
tity linking leveraging automatically generated an-
notation. In Proceedings of the 23rd International
Conference on Computational Linguistics (Coling
2010).
W. Zhang, J. Su, and C. L. Tan. 2011. A wikipedia-lda
model for entity linking with batch size changing. In
Proc. IJCNLP2011.
D. Zhou, O. Bousquet, T. Lal, J. Weston, and
B. Sch?olkopf. 2004. Learning with local and global
consistency. In Advances in Neural Information
Processing Systems 16.
X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semi-
supervised learning using gaussian fields and har-
monic functions. In ICML.
390
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 706?711,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Be Appropriate and Funny: Automatic Entity Morph Encoding
Boliang Zhang
1
, Hongzhao Huang
1
, Xiaoman Pan
1
, Heng Ji
1
, Kevin Knight
2
Zhen Wen
3
, Yizhou Sun
4
, Jiawei Han
5
, Bulent Yener
1
1
Computer Science Department, Rensselaer Polytechnic Institute
2
Information Sciences Institute, University of Southern California
3
IBM T. J. Watson Research Center
4
College of Computer and Information Science, Northeastern University
5
Computer Science Department, Univerisity of Illinois at Urbana-Champaign
1
{zhangb8,huangh9,panx2,jih,yener}@rpi.edu,
2
knight@isi.edu
3
zhenwen@us.ibm.com,
4
yzsun@ccs.neu.edu,
5
hanj@illinois.edu
Abstract
Internet users are keen on creating differ-
ent kinds of morphs to avoid censorship,
express strong sentiment or humor. For
example, in Chinese social media, users
often use the entity morph ???? (In-
stant Noodles)? to refer to ???? (Zhou
Yongkang)? because it shares one char-
acter ?? (Kang)? with the well-known
brand of instant noodles ???? (Master
Kang)?. We developed a wide variety of
novel approaches to automatically encode
proper and interesting morphs, which can
effectively pass decoding tests
1
.
1 Introduction
One of the most innovative linguistic forms in so-
cial media is Information Morph (Huang et al,
2013). Morph is a special case of alias to hide the
original objects (e.g., sensitive entities and events)
for different purposes, including avoiding censor-
ship (Bamman et al, 2012; Chen et al, 2013),
expressing strong sentiment, emotion or sarcasm,
and making descriptions more vivid. Morphs are
widely used in Chinese social media. Here is an
example morphs: ?????????????
????. (Because of Gua Dad?s issue, Instant
Noodles faces down with Antenna.)?, where
? ??? (Gua Dad)? refers to ???? (Bo Xilai)?
because it shares one character ?? (Gua)? with
???? (Bo Guagua)? who is the son of ???
? (Bo Xilai)?;
? ???? (Instant Noodles)? refers to ????
(Zhou Yongkang)? because it shares one char-
acter ?? (kang)? with the well-known instant
noodles brand ???? (Master Kang)?;
1
The morphing data set is available for research purposes:
http://nlp.cs.rpi.edu/data/morphencoding.tar.gz
? ??? (Antenna)? refers to ???? (Wen Ji-
abao)? because it shares one character ??
(baby)? with the famous children?s television
series ????? (Teletubbies)?;
In contrast with covert or subliminal chan-
nels studied extensively in cryptography and se-
curity, Morphing provides confidentiality against
a weaker adversary which has to make a real time
or near real time decision whether or not to block
a morph within a time interval t. It will take longer
than the duration t for a morph decoder to decide
which encoding method is used and exactly how it
is used; otherwise adversary can create a codebook
and decode the morphs with a simple look up.
We note that there are other distinct characteristics
of morphs that make them different from crypto-
graphic constructs: (1) Morphing can be consid-
ered as a way of using natural language to com-
municate confidential information without encryp-
tion. Most morphs are encoded based on seman-
tic meaning and background knowledge instead
of lexical changes, so they are closer to Jargon.
(2) There can be multiple morphs for an entity.
(3) The Shannon?s Maxim ?the enemy knows the
system? does not always hold. There is no com-
mon code-book or secret key between the sender
and the receiver of a morph. (4) Social networks
play an important role in creating morphs. One
main purpose of encoding morphs is to dissemi-
nate them widely so they can become part of the
new Internet language. Therefore morphs should
be interesting, fun, intuitive and easy to remem-
ber. (5) Morphs rapidly evolve over time, as some
morphs are discovered and blocked by censorship
and newly created morphs emerge.
We propose a brand new and challenging re-
search problem - can we automatically encode
morphs for any given entity to help users commu-
nicate in an appropriate and fun way?
706
2 Approaches
2.1 Motivation from Human Approaches
Let?s start from taking a close look at human?s
intentions and general methods to create morphs
from a social cognitive perspective. In Table 1
and Table 2, we summarize 548 randomly selected
morphs into different categories. In this paper we
automate the first seven human approaches, with-
out investigating the most challenging Method 8,
which requires deep mining of rich background
and tracking all events involving the entities.
2.2 M1: Phonetic Substitution
Given an entity name e, we obtain its pho-
netic transcription pinyin(e). Similarly, for each
unique term t extracted from Tsinghua Weibo
dataset (Zhang et al, 2013) with one billion
tweets from 1.8 million users from 8/28/2012 to
9/29/2012, we obtain pinyin(t). According to the
Chinese phonetic transcription articulation man-
ner
2
, the pairs (b, p), (d, t), (g,k), (z,c), (zh,ch),
( j,q), (sh,r), (x,h), (l,n), (c,ch), (s,sh) and (z,zh)
are mutually transformable.
If a part of pinyin(e) and pinyin(t) are identi-
cal or their initials are transformable, we substi-
tute the part of e with t to form a new morph.
For example, we can substitute the characters of
??? ?? (Bill Gates) [Bi Er Gai Ci]? with
??? (Nose and ear) [Bi Er]? and ??? (Lid)
[Gai Zi]? to form new morph ??? ?? (Nose
and ear Lid) [Bi Er Gai Zi]?. We rank the candi-
dates based on the following two criteria: (1) If the
morph includes more negative words (based on a
gazetteer including 11,729 negative words derived
from HowNet (Dong and Dong, 1999), it?s more
humorous (Valitutti et al, 2013). (2) If the morph
includes rarer terms with low frequency, it is more
interesting (Petrovic and Matthews, 2013).
2.3 M2: Spelling Decomposition
Chinese characters are ideograms, hieroglyphs
and mostly picture-based. It allows us to natu-
rally construct a virtually infinite range of combi-
nations from a finite set of basic units - radicals (Li
and Zhou, 2007). Some of these radicals them-
selves are also characters. For a given entity name
e = c
1
...c
n
, if any character c
k
can be decomposed
into two radicals c
1
k
and c
2
k
which are both char-
acters or can be converted into characters based
on their pictograms (e.g., the radical ??? can be
2
http://en.wikipedia.org/wiki/Pinyin#Initials and finals
converted into??? (grass) ), we create a morph by
replacing c
k
with c
1
k
c
2
k
in e. Here we use a charac-
ter to radical mapping table that includes 191 rad-
icals (59 of them are characters) and 1328 com-
mon characters. For example, we create a morph
???? (Person Dumb Luo)? for ??? (Paul)?
by decomposing ?? (Pau-)? into ?? (Person)?
and ?? (Dull)?. A natural alternative is to com-
posing two chracter radicals in an entity name to
form a morph. However, very few Chinese names
include two characters with single radicals.
2.4 M3: Nickname Generation
We propose a simple method to create morphs by
duplicating the last character of an entity?s first
name. For example, we create a morph ???
(Mimi)? to refer to ??? (Yang Mi)?.
2.5 M4: Translation and Transliteration
Given an entity e, we search its English translation
EN(e) based on 94,015 name translation pairs (Ji
et al, 2009). Then, if any name component in
EN(e) is a common English word, we search for
its Chinese translation based on a 94,966 word
translation pairs (Zens and Ney, 2004), and use the
Chinese translation to replace the corresponding
characters in e. For example, we create a morph
??? ?? (Larry bird)? for ??? ?? (Larry
Bird)? by replacing the last name ??? (Bird)?
with its Chinese translation ??? (bird)?.
2.6 M5: Semantic Interpretation
For each character c
k
in the first name of a given
entity name e, we search its semantic interpreta-
tion sentence from the Xinhua Chinese character
dictionary including 20,894 entries
3
. If a word
in the sentence contains c
k
, we append the word
with the last name of e to form a new morph. Sim-
ilarly to M1, we prefer positive, negative or rare
words. For example, we create a morph ????
(Bo Mess)? for ???? (Bo Xi Lai)? because the
semantic interpretation sentence for ?? (Lai)? in-
cludes a negative word ??? (Mess)?.
2.7 M6: Historical Figure Mapping
We collect a set of 38 famous historical figures
including politicians, emperors, poets, generals,
ministers and scholars from a website. For a given
entity name e, we rank these candidates by ap-
plying the resolution approach as described in our
previous work (Huang et al, 2013) to measure the
similarity between an entity and a historic figure
3
http://xh.5156edu.com/
707
Category
Frequency
Distribution
Examples
Entity Morph Comment
(1) Avoid censorship 6.56% ??? (Bo Xi-
lai)
B?? (B Secre-
tary)
?B? is the first letter of ?Bo? and ?Secretary? is
the entity?s title.
(2) Express strong
sentiment, sarcasm,
emotion
15.77% ??? (Wang
Yongping)
? ? ? (Miracle
Brother)
Sarcasm on the entity?s public speech: ?It?s a mir-
acle that the girl survived (from the 2011 train col-
lision)?.
(3) Be humorous or
make descriptions
more vivid
25.91% ?? (Yang Mi) ???? (Tender
Beef Pentagon)
The entity?s face shape looks like the shape of fa-
mous KFC food ?Tender Beef Pentagon?.
Mixture 25.32% ? ? ?
(Gaddafi)
???? (Crazy
Duck Colonel)
Sarcasm on Colonel Gaddafi?s violence.
Others 23.44% ??? (Chi-
ang Kai-shek)
??? (Peanut) Joseph Stilwell, a US general in China during
World War II, called Chiang Kai-shek ????
(Peanut)? in his diary because of his stubbornness.
Table 1: Morph Examples Categorized based on Human Intentions
No. Category
Frequency
Distribution
Example
Entity Morph Comment
M1 Phonetic Sub-
stitution
12.77% ? ? ?
(Sarkozy)
??? (Silly Po-
lite)
The entity?s phonetic transcript ?Sa Ke Qi? is
similar to the morph?s ?Sha Ke Qi?.
M2 Spelling De-
composition
0.73% ??? (Hu
Jintao)
?? (Old Moon) The entity?s last name is decomposed into the
morph ??? (Old Moon)??
M3 Nickname Gen-
eration
12.41% ??? (Jiang
Zemin)
?? (Old Jiang) The morph is a conventional name for old people
with last name ?Jiang?.
M4 Translation &
Transliteration
3.28% ?? (Bush) ?? (shrub) The morph is the Chinese translation of ?bush?.
M5 Semantic Inter-
pretation
20.26% ??? (Kim
Il Sung)
??? (Kim Sun) The character ??? in the entity name means ??
? (Sun)?.
M6 Historical Fig-
ure Mapping
3.83% ??? (Bo
Xilai)
??? (Conquer
West King)
The entity shares characteristics and political ex-
periences similar to the morph.
M7 Characteristics
Modeling
20.62% ??? (Kim
Il Sung)
??? (Kim Fat) ??? (Fat)? describes ???? (Kim Il
Sung)??s appearance.
M8
Reputation and
public perception
26.09%
? ? ?
(Obama)
?? (Staring at
the sea)
Barack Obama received a calligraphy ????
? (Staring at sea and listening to surf)? as a
present when he visited China.
??? (Ma
Jingtao)
???? (Roar
Bishop)
In the films Ma Jingtao starred, he always used
exaggerated roaring to express various emotions.
??? (Ma
Yingjiu)
??? (Ma Se-
cession)
The morph derives from Ma Yingjiu?s political
position on cross-strait relations.
Table 2: Morph Examples Categorized based on Human Generation Methods
based on their semantic contexts. For example,
this approach generates a morph ??? (the First
Emperor)? for ???? (Mao Zedong)? who is the
first chairman of P. R. China and ??? (the Sec-
ond Emperor )? for ???? (Deng Xiaoping )?
who succeeded Mao.
2.8 M7: Characteristics Modeling
Finally, we propose a novel approach to auto-
matically generate an entity?s characteristics using
Google word2vec model (Mikolov et al, 2013).
To make the vocabulary model as general as pos-
sible, we use all of the following large corpora
that we have access to: Tsinghua Weibo dataset,
Chinese Gigaword fifth edition
4
which includes
10 million news documents, TAC-KBP 2009-2013
Source Corpora (McNamee and Dang, 2009; Ji et
4
http://catalog.ldc.upenn.edu/LDC2011T13
al., 2010; Ji et al, 2011; Ji and Grishman, 2011)
which include 3 million news and web documents,
and DARPA BOLT program?s discussion forum
corpora with 300k threads. Given an entity e, we
compute the semantic relationship between e and
each word from these corpora. We then rank the
words by: (1) cosine similarity, (2) the same cri-
teria as in section 2.6. Finally we append the top
ranking word to the entity?s last name to obtain
a new morph. Using this method, we are able
to generate many vivid morphs such as ?? ??
(Yao Wizard)? for ??? (Yao Ming)?.
3 Experiments
3.1 Data
We collected 1,553,347 tweets from Chinese Sina
Weibo from May 1 to June 30, 2013. We extracted
708
187 human created morphs based on M1-M7 for
55 person entities. Our approach generated 382
new morphs in total.
3.2 Human Evaluation
We randomly asked 9 Chinese native speakers
who regularly access Chinese social media and are
not involved in this work to conduct evaluation in-
dependently. We designed the following three cri-
teria based on Table 1:
? Perceivability: Who does this morph refer to?
(i) Pretty sure, (ii) Not sure, and (iii) No clues.
? Funniness: How interesting is the morph? (i)
Funny, (ii) Somewhat funny, and (iii) Not funny.
? Appropriateness: Does the morph describe the
target entity appropriately? (i) Make sense, (ii)
Make a little sense, and (iii) Make no sense.
The three choices of each criteria account for
100% (i), 50% (ii) and 0% (iii) satisfaction rate,
respectively. If the assessor correctly predicts the
target entity with the Perceivability measure, (s)he
is asked to continue to answer the Funniness and
Appropriateness questions; otherwise the Funni-
ness and Appropriateness scores are 0. The hu-
man evaluation results are shown in Table 4. The
Fleiss?s kappa coefficient among all the human as-
sessors is 0.147 indicating slight agreement.
From Table 4 we can see that overall the sys-
tem achieves 66% of the human performance
with comparable stability as human. In partic-
ular, Method 4 based on translation and translit-
eration generates much more perceivable morphs
than human because the system may search in a
larger vocabulary. Interestingly, similar encour-
aging results - system outperforms human - have
been observed by previous back-transliteration
work (Knight and Graehl, 1998).
It?s also interesting to see that human assessors
can only comprehend 76% of the human generated
morphs because of the following reasons: (1) the
morph is newly generated or it does not describe
the characteristics of the target entity well; and (2)
the target entity itself is not well known to human
assessors who do not keep close track of news top-
ics. In fact only 64 human generated morphs and
72 system generated morphs are perceivable by all
human assessors.
For Method 2, the human created morphs are
assessed as much more and funny than the sys-
tem generated ones because human creators use
this approach only if: (1). the radicals still reflect
the meaning of the character (e.g., ?? (worry)?
is decomposed into two radicals ??? (heart au-
tumn)? instead of three ????? (grain fire heart)
because people tend to feel sad when the leaves
fall in the autumn), (2). the morph reflects some
characteristics of the entity (e.g., ???? (Jiang
Zemin)? has a morph ????? (Water Engi-
neer Zemin)? because he gave many instructions
on water conservancy construction); or (3). The
morph becomes very vivid and funny (e.g., the
morph ?????? (Muji Yue Yue Bird)? for
???? is assessed as very funny because ??
?(Muji)? looks like a Japanese name, ???(Yue
Yue)? can also refer to a famous chubby woman,
and ??? (bird man)? is a bad word referring to
bad people); or (4). The morph expresses strong
sentiment or sarcasm; or (5) The morph is the
name of another entity (e.g., the morph ???(Gu
Yue)? for ????(Hu Jintao)? is also the name
of a famous actor who often acts as Mao Zedong).
The automatic approach didn?t explore these intel-
ligent constraints and thus produced more boring
morph. Moreover, sometimes human creators fur-
ther exploit traditional Chinese characters, gener-
alize or modify the decomposition results.
Table 3 presents some good (with average score
above 80%) and bad (with average score below
20%) examples.
Good Examples
Entity Morph Method
??? (Osama bin
Laden)
??? (The silly turn-
ing off light)
M1
??? (Chiang Kai-
shek)
???? (Grass Gen-
eral Jie Shi)
M2
???? (Bill Gates) ???? (Bill Gates) M4
Bad Examples
Entity Morph Method
?? (Kobe) ?? (Arm) M1
? ? ? ? ?
(Medvedev)
??? (Mei Virtue) M5
??? (Jeremy Lin) ?? (Lao Tze) M6
Table 3: System Generated Morph Examples
To understand whether users would adopt sys-
tem generated morphs for their social media com-
munication, we also ask the assessors to recite
the morphs that they remember after the survey.
Among all the morphs that they remember cor-
rectly, 20.4% are system generated morphs, which
is encouraging.
3.3 Automatic Evaluation
Another important goal of morph encoding is to
avoid censorship and freely communicate about
709
Human System Human System Human System Human System Human System Human System Human System Human System# of morphs 17 124 4 21 10 54 9 28 64 87 9 18 74 50 187 382Perceivability 75 76 95 86 94 81 61 71 87 59 66 5 77 34 76 67Funniness 78 49 92 43 44 41 70 47 70 35 74 28 79 44 76 46Appropriateness 71 51 89 59 81 43 75 49 76 36 78 18 82 38 79 43Average 75 59 92 57 73 55 69 56 78 43 73 17 79 39 77 52Standard Deviation 12.29 21.81 7.32 11.89 13.2 9.2 17.13 20.3 18.83 17.54 10.01 21.23 15.18 15.99 15.99 18.14
h s2568 58984214.3 29691742 45712641 1153922692 26766901.8 811317052 1278447812 1E+05255.7 329.12568 58984 214.3 2969 1742 4571 2641 11539 22692 26766 901.8 8113 17052 12784
M6 M7 OverallM1 M2 M3 M4 M5
Table 4: Human Evaluation Satisfaction Rate (%)
certain entities. To evaluate how well the new
morphs can pass censorship, we simulate the cen-
sorship using an automatic morph decoder con-
sisted of a morph candidate identification system
based on Support Vector Machines incorporating
anomaly analysis and our morph resolution sys-
tem (Huang et al, 2013). We use each system gen-
erated morph to replace its corresponding human-
created morphs in Weibo tweets and obtain a new
?morphed? data set. The morph decoder is then
applied to it. We define discovery rate as the per-
centage of morphs identified by the decoder, and
the ranking accuracy Acc@k to evaluate the reso-
lution performance. We conduct this decoding ex-
periment on 247 system generated and 151 human
generated perceivable morphs with perceivability
scores > 70% from human evaluation.
Figure 1 shows that in general the decoder
achieves lower discovery rate on system gener-
ated morphs than human generated ones, because
the identification component in the decoder was
trained based on human morph related features.
This result is promising because it demonstrates
that the system generated morphs contain new and
unique characteristics which are unknown to the
decoder. In contrast, from Figure 2 we can see
that system generated morphs can be more easily
resolved into the right target entities than human
generated ones which are more implicit.
0	 ?
20	 ?
40	 ?
60	 ?
80	 ?
100	 ?
M1	 ? M2	 ? M3	 ? M4	 ? M5	 ? M6	 ? M7	 ? ALL	 ?
Human	 ?created	 ?	 ?morph	 ? System	 ?generated	 ?morph	 ?
Figure 1: Discovery Rate (%)
4 Related Work
Some recent work attempted to map between Chi-
nese formal words and informal words (Xia et al,
2005; Xia and Wong, 2006; Xia et al, 2006; Li
Figure 2: Resolution Acc@K Accuracy (%)
and Yarowsky, 2008; Wang et al, 2013; Wang and
Kan, 2013). We incorporated the pronunciation,
lexical and semantic similarity measurements pro-
posed in these approaches. Some of our basic se-
lection criteria are also similar to the constraints
used in previous work on generating humors (Val-
itutti et al, 2013; Petrovic and Matthews, 2013).
5 Conclusions and Future Work
This paper proposed a new problem of encoding
entity morphs and developed a wide variety of
novel automatic approaches. In the future we will
focus on improving the language-independent ap-
proaches based on historical figure mapping and
culture and reputation modeling. In addition, we
plan to extend our approaches to other types of in-
formation including sensitive events, satires and
metaphors so that we can generate fable stories.
We are also interested in tracking morphs over
time to study the evolution of Internet language.
Acknowledgments
This work was supported by U.S. ARL No.
W911NF-09-2-0053, DARPA No. FA8750-13-
2-0041 and No. W911NF-12-C-0028, ARO
No. W911NF-13-1-0193, NSF IIS-0953149,
CNS-0931975, IIS-1017362, IIS-1320617, IIS-
1354329, IBM, Google, DTRA, DHS and RPI.
The views and conclusions in this document are
those of the authors and should not be inter-
preted as representing the official policies, either
expressed or implied, of the U.S. Government.
The U.S. Government is authorized to reproduce
and distribute reprints for Government purposes
notwithstanding any copyright notation here on.
710
References
David Bamman, Brendan O?Connor, and Noah A.
Smith. 2012. Censorship and deletion practices in
Chinese social media. First Monday, 17(3).
Le Chen, Chi Zhang, and Christo Wilson. 2013.
Tweeting under pressure: analyzing trending topics
and evolving word choice on sina weibo. In Pro-
ceedings of the first ACM conference on Online so-
cial networks, pages 89?100.
Zhendong Dong and Qiang Dong. 1999. Hownet. In
http://www.keenage.com.
Hongzhao Huang, Zhen Wen, Dian Yu, Heng Ji,
Yizhou Sun, Jiawei Han, and He Li. 2013. Resolv-
ing entity morphs in censored data. In Proceedings
of the 51st Annual Meeting of the Association for
Computational Linguistics (ACL2013).
Heng Ji and Ralph Grishman. 2011. Knowledge base
population: Successful approaches and challenges.
In Proceedings of the Association for Computational
Linguistics (ACL2011).
Heng Ji, Ralph Grishman, Dayne Freitag, Matthias
Blume, John Wang, Shahram Khadivi, Richard
Zens, and Hermann Ney. 2009. Name extraction
and translation for distillation. Handbook of Natu-
ral Language Processing and Machine Translation:
DARPA Global Autonomous Language Exploitation.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Text Analysis
Conference (TAC) 2010.
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the tac 2011 knowledge base popula-
tion track. In Proc. Text Analysis Conference (TAC)
2011.
Kevin Knight and Jonathan Graehl. 1998. Machine
transliteration. Computational Linguistics, 24(4).
Zhifei Li and David Yarowsky. 2008. Mining and
modeling relations between formal and informal chi-
nese phrases from web corpora. In Proceedings
of Conference on Empirical Methods in Natural
Language Processing (EMNLP2008), pages 1031?
1040.
Jianyu Li and Jie Zhou. 2007. Chinese character struc-
ture analysis based on complex networks. Phys-
ica A: Statistical Mechanics and its Applications,
380:629?638.
Paul McNamee and Hoa Trang Dang. 2009.
Overview of the tac 2009 knowledge base popula-
tion track. In Proceedings of Text Analysis Confer-
ence (TAC2009).
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In C.J.C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K.Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111?3119.
Sasa Petrovic and David Matthews. 2013. Unsuper-
vised joke generation from big data. In Proceed-
ings of the Association for Computational Linguis-
tics (ACL2013).
Alessandro Valitutti, Hannu Toivonen, Antoine
Doucet, and Jukka M. Toivanen. 2013. ?let every-
thing turn well in your wife?: Generation of adult
humor using lexical constraints. In Proceedings
of the Association for Computational Linguistics
(ACL2013).
Aobo Wang and Min-Yen Kan. 2013. Mining informal
language from chinese microtext: Joint word recog-
nition and segmentation. In Proceedings of the As-
sociation for Computational Linguistics (ACL2013).
Aobo Wang, Min-Yen Kan, Daniel Andrade, Takashi
Onishi, and Kai Ishikawa. 2013. Chinese informal
word normalization: an experimental study. In Pro-
ceedings of International Joint Conference on Natu-
ral Language Processing (IJCNLP2013).
Yunqing Xia and Kam-Fai Wong. 2006. Anomaly de-
tecting within dynamic chinese chat text. In Proc.
Workshop On New Text Wikis And Blogs And Other
Dynamic Text Sources.
Yunqing Xia, Kam-Fai Wong, and Wei Gao. 2005. Nil
is not nothing: Recognition of chinese network in-
formal language expressions. In 4th SIGHAN Work-
shop on Chinese Language Processing at IJCNLP,
volume 5.
Yunqing Xia, Kam-Fai Wong, and Wenjie Li. 2006.
A phonetic-based approach to chinese chat text nor-
malization. In Proceedings of COLING-ACL2006,
pages 993?1000.
Richard Zens and Hermann Ney. 2004. Improvements
in phrase-based statistical machine translation. In
Proceedings of HLT-NAACL2004.
Jing Zhang, Biao Liu, Jie Tang, Ting Chen, and Juanzi
Li. 2013. Social influence locality for modeling
retweeting behaviors. In Proceedings of the 23rd
International Joint Conference on Artificial Intelli-
gence (IJCAI?13), pages 2761?2767.
711
Proceedings of the 25th International Conference on Computational Linguistics, pages 74?81,
Dublin, Ireland, August 23-29 2014.
Cross-media Cross-genre Information Ranking Multi-media Information
Networks
Tongtao Zhang
Rensselaer Polytechnic Institute
zhangt13@rpi.edu
Haibo Li
Nuance
lihaibo.c@gmail.com
Hongzhao Huang
R.P.I.
huangh9@rpi.edu
Heng Ji
R.P.I.
jih@rpi.edu
Min-Hsuan Tsai
mtsai2@illinois.edu
Shen-Fu Tsai
University of Illinois at Urbana-Champaign
stsai8@illinois.edu
Thomas Huang
huang@ifp.uiuc.edu
Abstract
Current web technology has brought us a scenario that information about a certain topic is widely dis-
persed in data from different domains and data modalities, such as texts and images from news and social
media. Automatic extraction of the most informative and important multimedia summary (e.g. a ranked
list of inter-connected texts and images) from massive amounts of cross-media and cross-genre data can
significantly save users? time and effort that is consumed in browsing. In this paper, we propose a novel
method to address this new task based on automatically constructed Multi-media Information Networks
(MiNets) by incorporating cross-genre knowledge and inferring implicit similarity across texts and im-
ages. The facts from MiNets are exploited in a novel random walk-based algorithm to iteratively propagate
ranking scores across multiple data modalities. Experimental results demonstrated the effectiveness of our
MiNets-based approach and the power of cross-media cross-genre inference.
1 Introduction
Recent development on web technology ? especially on fast connection and large-scale storage systems ? has
enabled social and news media to fulfill their jobs more efficiently in time and depth. However, such development
also raises some problems such as overwhelming social media information and distracting news media contents.
In emergent scenarios such as facing an incoming disaster (e.g., Hurricane Irene in 2011 or Sandy in 2012), tweets
and news are often repeatedly spread and forwarded in certain circles and contents are often overlapped by each
other. However, browsing these messages and pages is almost unpleasant and inefficient. Therefore, an automatic
summarization on piles of tweets and news is always necessary and welcomed, among which ranking is the most
intuitive way to inform the users about the most informative content.
A passive solution is prompting the users to add more key words when typing the search query as most search
engines do. However, without prior knowledge or due to the word limit, it is never trivial for the users to establish
a satisfied ranking list for topics which attract more public attention. Recent changes on some Google Search have
integrated image search and adopted some heterogenous content analysis, nevertheless, the connection between
image and the keywords are still arbitrarily determined by the users, thus it is still far from optimal.
Active solutions which attempt to summarize information only focused on single data modalities. For example,
Zanzotto et al. (2011) provided a comprehensive comparison about summarization methods for tweets. Zhao et al.
(2011) developed a context-sensitive topical PageRank (Brin and Page, 1998) method to extract topical key phrase
from Twitter as a way to summarize twitter content. As a new prospective, Feng and Lapata (2010) used LDA to
annotate images, but this does not firmly integrate the information across different data types. Huang et al. (2012)
presented a tweet ranking approach but only focused on single data modality (i.e., text).
Other conventional solutions towards analyzing the relationship or links between the instances have long been
proposed and applied, such as PageRank (Brin and Page, 1998)and VisualRank (Jing and Baluja, 2008). The
former is excessively used in heterogeneous networks (i.e., webpages and resources) but they are mainly based on
linkage itself. VisualRank, which is based on PageRank, is a content-based linkage method but is confined with
homogeneous networks.
Above all, our goal is to integrate cross-media inference and create the linkage among the information extracted
from those heterogenous data. Our novel Multi-media Information Networks (MiNets) representation initializes
our idea about a basic ontology of the ranking system.
The main contribution of this work is to fill in the domain gaps across different network genres and bridge them
in a principled method. In this work, we manage to discover the hidden links or structures between the heteroge-
neous networks in different genres. We combine joint inference to resolve information conflicts across multi-genre
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
74
networks. We can also effectively measure, share and transfer complementary information and knowledge across
multi-genre networks using structured correspondence.
The work is presented in sections as follows. We firstly introduce an overview of our system in Section 2.
Detailed approaches in information extraction and constructing meta-information network are then followed in
Section 3. Measurement across the multimedia information are proposed in Section 4 and 5. In Section 6 we
demonstrate the results and performance gain.
2 Approach Overview
Within the context of an event where users generate a vast amount of multi-media messages in forms of tweets and
images, we aim to provide a ranked subset of the most informative ones. Given a set of tweets T = {t
1
, ..., t
n
},
and a set of images P = {p
1
, ..., p
m
} as input, our approach provides ordered lists of the most informative tweets
or images (a.k.a objects) so that the informativeness of an object in position i is higher than or equal to that of an
object in position i + 1. We consider the degree of informativeness of a certain object as the extent to which it
provides valuable information to people who are involved in or tracking the event in question.
During emergent events, there are tight correlations between social media and web documents. Important infor-
mation shared in social media tends to be posted in web documents. Therefore we also integrate information in a
formal genre such as web documents to enhance the ranking quality of tweets and images. It consists of two main
sub-tasks:
? Multimedia Information Network (MiNet) Construction:
Construct MiNet from cross-media and cross-genre information (i.e. tweets, images, sentences of web doc-
uments). Given a set of tweets and images on a specific topic as input, the formal genre web documents and
images from the embedded URLs in those tweets are retrieved. Afterwards, a set of sentences and images are
extracted from the web documents. Then we exploit advanced text Information Extraction and image Concept
Extraction techniques to extract meta-information and construct the meta-information network. Together with
three sets of heterogeneous input data, MiNet is constructed.
? MiNet-Based Information Ranking: Rank the tweets and images. By extending and adapting Tri-
HITS (Huang et al., 2012), we propose EN-Tri-HITs, an random walk-based propagation algorithm which
iteratively propagate ranking scores for sentences, tweets, and images across MiNet to refine the tweet and
image rankings.
3 Meta-information Network
When integrating information from different data modalities, meta-information network plays a pivotal role for
representing interesting concepts and relations between them. We automatically construct the initial informa-
tion networks using our state-of-the-art information extraction and image concept extraction techniques. A meta-
information network is a heterogeneous network including a set of ?information graphs? which is formally defined
as: G = {G
i
: G
i
= (V
i
, E
i
)}, where V
i
is the collection of concept nodes, and E
i
is the collection of edges
linking one concept to the other. An example is depicted in Figure 1. The meta-information network contains
human knowledge pertaining to the target domain that could improve the performance of text process and image
analysis. In this paper, we first construct meta-information networks separately from texts and images, and then
fuse and enrich them through effective cross-media linking methods.
3.1 Information Extraction from Texts
Extracting salient types of facts for a meta-information network is challenging. In this paper we tackle this problem
from two angles to balance the trade-off between quality and granularity/annotation cost. On one hand, to reveal
deep semantics in meta-information network, we focus on achieving high-quality extraction for pre-defined fine-
grained types such as those in NIST Automatic Content Extraction (ACE)
1
. For example, a ?Person/Individual?
node may include attributes such as ?Birth-Place?, and a ?Organization/Employee? node may include attributes
such as ?City-of-Headquarter?. These two nodes may be connected via a ?Employment/End-Position? link.
We apply an Information Extraction (IE) system (Li et al., 2013) to extract entities, relations and events defined
in ACE2005. There are 7 types of entities, 18 types of relations and 33 types of events. This system is based
on a joint framework using structured perceptron with efficient beam-search and incorporating diverse lexical,
syntactic, semantic and ontological features. We convert the IE output into the graph structured representation of
meta-information network by mapping each entity as a node, and link entity nodes by semantic relations or events
they are involved. For example, the relations between entities are naturally mapped to links in the meta-information
network, such as the ?employment? relation between ?Bill Read? and ?Hurricane Center?. In addition, if an event
1
http://www.itl.nist.gov/iad/894.01/tests/ace/
75
flood
Multimedia information Networks
Meta-information Networks
ORG
flooding from Irene killed one person Puerto RicoBill Read Hurricane Center said
Employment
Speaker
Agent Subject
Clause Subject
PlaceAgent
Victim
storm
Wikipedia
Verifiedby wiki Verifiedby wiki Verifiedby wiki
Verified Entity Concepts
Tweets Sentences of web documents Images
Contents Structured information
PER GPEEvent TriggerPredicate Predicate Noun phrase Noun phrase
Example:SRL
IE concept
type
Conceptfrom image Concept from image
Figure 1: An example of meta-information network. Sentence: ?Bill Read, Hurricane Center director, said that
flooding from Irene killed at least one person in Puerto Rico?
argument is an entity, we also add an ?Event Argument? link between the event trigger and the entity, such as the
link between ?Irene? and ?killed?.
On the other hand, in order to enrich the meta-information network, we extract more coarse-grained salient
fact types based on Semantic Role Labeling (SRL) (Pradhan et al., 2008). For example, given the sentence ?In
North Carolina, 10 counties are being evacuated.?, the ?evacuation? event is not included in ACE. However, the
SRL system can successfully detect the predicate (?evacuated?) and its semantic roles (?10 counties? and ?North
Carolina?). These argument heads and predicates are added into the meta-information network as vertices, and
edges are added between each predicate-argument pairs.
We merge entity mentions across tweets and web documents based on a cross-document entity clustering system
described in (Chen and Ji, 2011). Moreover, for the same type of nodes from the SRL system, we also merge them
by string matching across documents.
3.2 Concept Extraction from Images
We also developed a concept modeling approach by extending the similar framework in previous work (Tsai et al.,
2012), Probabilistic Logical Tree (PLT), to extract semantic concepts from images. PLT integrates the logical and
statistical inferences in a unifying framework where the existing primitive concepts are connected into a potentially
unlimited vocabulary of high-level concepts by basic logical operations. In contrast, most existing image concept
extraction algorithms either only learn a flat correlative concept structure, or a simple hierarchical structure without
logical connections.
With an efficient statistical learning algorithm, the complex concepts in upper level of PLT are modeled upon
some logically connected primitive concepts. This statistical learning approach is very flexible, where each concept
in PLT can be modeled from distinctive feature spaces with the most suitable feature descriptors (e.g., visual
features such as color and shape for scenery concepts).
For our case study on ?Hurricane Irene? scenario, we apply this algorithm to extract the hierarchical concept
trees with roots ?flood? or ?storm? from all the images in web documents whose URLs are contained in tweets.
The main problem is the classifications of the concepts such that it may be properly be placed onto an ontology.
In order to enrich the hierarchy, we seek to classify these linkages through the use of the semi-structured and
structured data that exists on Wikipedia. We use pattern matching to extract is-a relations from the first paragraphs
of Wikipedia articles. For example, starting from our initial concept ?Hurricane Irene?, we can find its is-a relation
with ?Tropical Cyclone?, and then climb up one more level to ?Storm? where we can further mine lower concepts
such as ?Tornado? and ?Snow Storm?.
76
4 Multi-media Information Networks
A Multimedia Information Network (MINet) is a structured collection made up of a set of multimedia documents
(e.g., texts and images) and links between these documents. Each link corresponds to a specific relationship
between nodes, such as hyperlinks between web documents or similarity links between tweets. In this paper, we
construct our MINet based on two forms of contents from different domains: tweets, web documents (plain texts)
and images.
4.1 Within-media Linking
4.1.1 Text-Text Similarity
Taking web document for example, we construct the meta-information network G = {G
i
: G
i
= (V
i
, E
i
)} for all
web documents D, in which each web document d
i
? D corresponds to G
i
. Given the meta-information network
G, we compute the weight of each vertex v
j
? V
i
as weight
v
j
=
nf(v
j
,d)
AV E(D)
,
where nf(v
j
, d) is the mention number of node v
j
appearing in a document d and AV E(D) is the average
number of mentions in a document d, which is defined as AV E(D) =
?
d?D
concept mentions in d
|D|
.
Similarly, we define the weight of each link e
k
? E
i
as weight
e
k
=
nf(e
k
,d)
AV E(D)
, where nf(e
k
, d) is the mention
number of the node e
k
in a document d and AV E(D) is the average number of mentions in a document d, which
is defined as AV E(D) =
?
d?D
relation mentions in d
|D|
.
If two edges share the same type and link nodes corresponding to the same tokens, we consider them as two
mentions involved in a relation. Based on the weight of each concept mention and relation mention, we count their
frequencies and transform them into vectors. Finally, we compute cosine similarity between every two vectors.
4.1.2 Image-Image Similarity
We extract Histogram of Oriented Gradients (HOG) features (Dalal and Triggs, 2005) from patches in images and
apply Hierarchical Gaussianization (Zhou et al., 2009) to those HOG feature vectors. We learn a Gaussian mixture
model (GMM) to obtain the statistics of the patches of an image by adapting the distribution of the extracted HOG
features from these image patches and each image is represented by a super-vector. Based on the obtained image
representation, the image-image similarity is simply a cosine similarity between two HG super-vectors.
4.2 Cross-media Linking
In order to obtain cross-media similarity, we propose a method based on transfer learning technique (Qi et al.,
2012). Given a set of m points [p
1
, p
2
, . . . , p
m
] in the source (image) domain P , a set of n points [t
1
, t
2
, . . . , t
n
]
in the target (text) domain T , and a set of N corresponding pairs C = {(p
a
i
, t
b
i
}
N
i=1
in these two domains, we aim
to find a cross-media similarity function:
G(p, t) = `((Up)
T
(V t)) = `(p
T
St)), (1)
where U and V are the linear embedding of P and T , respectively. S = U
T
V is the cross-domain similarity
matrix and `(?) =
1
1+e
??
is the logistic sigmoid function.
The key to S in Equation 1 is to solve the optimization problem blow:
min
S
?
L
s
(S) + ?
?
L
d
(S) + ?
?
?(S), (2)
where
?
L
s
(S) =
?
(x,y)?C
log(1 + exp(?p
T
St)), and
?
?(S) = ?S?
?
is the nuclear norm that is the surrogate of
the matrix rank. Also, we have
?
L
d
(S) =
1
2
?
K
P
(p, p
?
)d
T
(p, p
?
) +
1
2
?
K
T
(t, t
?
)d
P
(t, t
?
),
where K(?, ?) is the similarity matrix among the points in a single domain and d(?, ?) defines the distance between
two points due to the transfer.
Taking one step further, we have
?
L
d
(S) = tr(L
T
Q
T
(S)
T
K
P
Q
P
(S)) + tr(L
X
Q
P
(S)
T
K
T
Q
T
(S)),
where L
P
and L
T
are the Laplacian matrices for K
P
and K
T
, respectively.
To solve the optimization problem (2) with nuclear norm regularization we follow the proximal gradient method
(Toh and Yun, 2010) with the following gradients:
5
?
L
s
(S) = P (J
C
?H)P
T
,5
?
L
d
(S) = P ((K
P
Q
P
L
T
+ L
P
Q
T
K
T
) ?H)P
T
(3)
77
JC
is an m ? n matrix with its (i, j)-th entry 1 if (p
i
, t
j
) ? C, otherwise 0. H is also an m ? n matrix whose
(i, j)-th entry where H
ij
= `
?
(p
T
i
St
j
).
Hence we have
5
?
L(S) = P (G ?H)T
T
, (4)
where G = J
C
+ ?K
P
Q
P
L
T
+ ?L
P
Q
T
K
T
. With the gradient in (4), one can solve the problem (2) using the
proximal gradient method.
5 MiNet-Based Information Ranking: EN-Tri-HITs
5.1 Initializing Ranking Scores
1 Input: A set of tweets (T ), and images (P ) and web documents (W ) on a given topic.
2 Output: Ranking scores (S
t
) for T and (S
p
) for P .
1: Use TextRank to compute initial ranking scores S
0
p
for P ,
S
0
t
for T and S
0
w
for W ;
2: Construct multimedia information networks across P , T
and W ;
3: k ? 0, diff ? 10e6;
4: while k < MaxIteration and diff > MinThreshold do
5: Use Eq. (5) (6) and (7) to compute S
k+1
p
, S
k+1
t
and S
k+1
w
;
6: Normalize S
k+1
p
, S
k+1
t
and S
k+1
w
;
7: diff ? max(
?
(|S
k+1
t
? S
k
t
|),
?
(|S
k+1
p
? S
k
p
|));
8: k ? k + 1
9: end while
Algorithm 1: EN-Tri-HITS: Random walk on multimedia information networks
Graph-based ranking algorithms have been widely used to analyze relations between vertices in graphs. In
this paper, we adapted PageRank (Brin and Page, 1998; Mihalcea and Tarau, 2004; Jing and Baluja, 2008) to
compute initial ranking scores in tweet-only and image-only networks where edges between tweets or images are
determined by their cosine similarity.
The ranking score is computed as follows:
S(V
i
) = (1? d) + d ?
?
V
j
?In(V
i
)
w
ji
?
V
k
?Out(V
j
)
w
jk
S(V
j
),
where V
i
is a vertex with S(V
i
) as its ranking score; In(V
i
) and Out(V
i
) are the incoming edge set and outgoing
edge set of V
i
, respectively; w
ij
is the weight for the edge between two vertices V
i
and V
j
. An edge links two
vertices that represent text units when their cosine similarity of shared content exceeds or equals to a predefined
threshold ?
t
.
5.2 Random Walk on Multimedia Information Networks
We introduce a novel algorithm to incorporate both initial ranking scores and global evidence from multimedia
information networks. It propagates ranking scores across MiNets iteratively. Our algorithm is a natural extension
of Tri-HITS (Huang et al., 2012) based on the mutual reinforcement to boost linked objects.
By extending Tri-HITS, we develop enhanced Tri-HITS (EN-Tri-HITs) to handle multimedia information net-
works with three types of objects: Tweets (T ), sentences of web documents (W ) and images (P ). EN-Tri-HITs
is able to handle more complicated network structure with more links. Given the similarity matrices M
tw
(be-
tween tweets and sentences of web documents), M
wp
(between sentences of web documents and images) andM
tp
(between tweets and images), and initial ranking scores of S
0
(p), S
0
(t) and S
0
(w), we aim to refine the initial
ranking scores and obtain the final ranking scores S(w), S(t) and S(p). Starting from images S(p), the update
process considers both the initial score S
0
(p) and the propagation from connected tweets S(t) and web documents
S(w), which can be expressed as:
?
S
w
(p
j
) =
?
i?W
m
wp
ij
S(w
i
),
?
S
t
(p
j
) =
?
k?T
m
tp
kj
S(t
k
),
S(p
j
) = (1? ?
wp
? ?
tp
)S
0
(p
j
) + ?
wp
?
S
w
(p
j
)
?
j
?
S
w
(p
j
)
+ ?
tp
?
S
t
(p
j
)
?
j
?
S
t
(p
j
)
, (5)
78
Set ID Tweets
Web Doc
Images
(Sentences)
1 1171 41(1272) 183
2 1116 47(1634) 265
3 1184 69(1639) 346
All 3471 157(4545) 794
Table 1: Data Statistics: Numbers of each item in
the dataset.
word word word word
+IE +SRL +IE+SRL
I+W 0.545 0.539 0.521 0.583
I+T 0.422 0.436 0.407 0.489
I+W+T 0.526 0.513 0.492 0.541
Table 2: NDCG@5 of Images. The image ranking
baseline performance is 0.421. I stands for Image;
W Web Documents; T Tweets
where ?
wp
, ?
tp
? [0, 1] (?
wp
+ ?
tp
? 1) are the parameters to balance between initial and propagated ranking
scores. Similar to Tri-HITS, EN-Tri-HITS normalizes the propagated ranking scores
?
S
w
(p
i
) and
?
S
t
(p
i
).
Similarly, we define the propagations from images and web documents to tweets as follows:
?
S
p
(t
k
) =
?
i?P
m
pt
ik
S(p
i
),
?
S
w
(t
k
) =
?
j?W
m
wt
jk
S(w
j
),
S(t
k
) = (1? ?
wt
? ?
pt
)S
0
(t
k
) + ?
wt
?
S
p
(t
k
)
?
k
?
S
p
(t
k
)
+ ?
pt
?
S
w
(t
k
)
?
k
?
S
w
(t
k
)
, (6)
where M
pt
is the transpose of M
tp
, ?
pt
and ?
wt
are parameters to balance between initial and propagated ranking
scores.
Each sentence of web documents S(w
j
) may be influenced by the propagation from both tweets and images:
?
S
t
(w
i
) =
?
k?T
m
tw
ki
S(t
k
),
?
S
p
(w
i
) =
?
i?P
m
pw
ji
S(p
j
),
S(w
i
) = (1? ?
tw
? ?
pw
)S
0
(w
i
) + ?
tw
?
S
t
(w
i
)
?
i
?
S
t
(w
i
)
+ ?
pw
?
S
p
(w
i
)
?
i
?
S
p
(w
i
)
, (7)
where M
pw
is the transpose of M
wp
, ?
tw
and ?
pw
are parameters to balance between initial and propagated
ranking scores.
Algorithm 1 summarizes En-Tri-HITS.
6 Experiments
6.1 Data and Scoring Metric
Currently there are no information ranking related benchmark data sets publicly available, therefore we build our
own data set and network ontology.
We crawled 3471 tweets during a three-hour period and extracted key phrases from these tweets, then we use
the key phrases as image search queries. The image search queries are submitted to Bing Image Search API and
we take the top 10 images for each query. We extract a 512-d GIST feature from each image for meta information
training. For image similarity metrics, we resize images to a maximum of 240 ? 240 and segmented into patches
with three different sizes (16, 25 and 31) by a 6-pixel step size. A 128-d Histogram of Oriented Gradients (HOG)
feature is extracted from each patch and followed by a PCA dimension reduction to 80-d. The size of dimension
of the final feature vector for each image is 42,496.
We create the ground truth based on human assessment of informativeness on a 5-star likert scale, with grade 5
as the most informative and 1 as the least informative. Table 1 presents an overview on our data sets. We conduct
3-fold cross-validation for our experiments.
To evaluate tweet ranking, we use nDCG as our evaluation metric (J?arvelin and Kek?al?ainen, 2002), which
considers both the informativeness and the position of a tweet:
nDCG(?, k) =
1
|?|
|?|
?
i=1
DCG
ik
IDCG
ik
, DCG
ik
=
k
?
j=1
2
rel
ij
? 1
log(1 + j)
,
where ? is the set of documents in the test set, with each document corresponding to an hour of tweets in our case,
rel
ij
is the human-annotated label for the tweet j in the document i, and IDCG
ik
is the DCG score of the ideal
ranking. The average nDCG score for the top k tweets is: Avg@k =
?
k
i=1
nDCG(?, i)/k. To favor diversity of
top ranked tweets, redundant tweets are penalized to lower down the final score.
79
6.2 Impact of Cross-media Inference
Table 2 and Figure 2 present the image ranking results. The results indicate that methods integrating heterogeneous
networks outperform the baseline of image ranking (0.421). When web documents are aligned with images (row
1), the ranking quality improves significantly, proving that web documents can help detect informative images by
adding support from text media of formal genre. However, the text media of informal genre, such as tweets, almost
cannot help improve the ranking performance.
1 2 3 4 5 6 7 8 9 1 00 . 20 . 30 . 40 . 50 . 60 . 7
0 . 80 . 91 . 0NDCG@N N
 I m a g e + T w e e t + W e b  D o c + W e b  D o c & T w e e t
Figure 2: NDCG@n score of Images with Various n
word word word word
+IE +SRL +IE+SRL
T 0.675 0.691 0.697 0.700
T+W 0.766 0.771 0.757 0.809
T+I 0.675 0.691 0.667 0.700
T+W+I 0.722 0.771 0.757 0.809
Table 3: NDCG@5 of Tweets
6.3 Impact of Cross-genre Inference
Methods that integrate heterogeneous networks after filtering, outperform the baseline TextRank, as shown in
Table 3. When tweets are aligned with web documents, the ranking quality improves significantly, proving that
web documents can help infer informative tweets by adding support from a formal genre. The fact that tweets with
low initial ranking scores are aligned with web documents helps promote their ranking positions. For example,
the ranking of the tweet ?Hurricane Irene: City by City Forecasts http://t.co/x1t122A? is improved compared to
TextRank, benefitting from the fact that 10 retrieved web documents are about this topic.
6.4 Remaining Error Analysis
Enhanced Tri-HITS shows encouraging improvements in ranking quality with respect to a state-of-the-art model
such as TextRank. However, there are still some issues to be addressed for further improvements.
(i) Long tweets preferred. We tracked tweets containing the keywords ?Hurricane? and ?Irene?. Using such a
query might also return tweets that are not related to the event being followed. This may occur either because
the terms are ambiguous, or because of spam being injected into trending conversations to make it visible. For
example, the tweet ?Hurricane Kitty: http://t.co/cdIexE3? is an advertisement, which is not topically related to
Irene.
(ii) Deep semantic analysis of the content, especially for images. We rely on distinct terms to refer to the
same concept. More extensive semantic analyses of text can help identify those terms, possibly enhancing the
propagation process. For example, we can explore existing text dictionaries such as WordNet (Miller, 1995) to
mine synonym/hypernym/hyponym relations, and Brown clusters (Brown et al., 1992) to mine other types of
relations in order to enrich the concepts extracted from images.
7 Conclusion and Future Work
In this paper, we propose a comprehensive information ranking approach which facilitates measurement on cross-
media/cross-genre informativeness based on a novel multi-media information network representation MiNet. We
establish links via information extraction method from text and images and verification with Wikipedia. In ad-
dition, we propose similarity measurement on intra-media and cross-media using transfer learning techniques.
We also introduce a novel En-Tri-Hits algorithm to evaluate the ranking scores across MiNet. Experiments have
demonstrated that our cross-media/cross-genre ranking method is able to significantly boost the performance of
multi-media tweet ranking. In the future, we aim to focus on enhancing the quality of concept extraction by
exploiting cross-media inference that goes beyond simple fusion.
Acknowledgement
This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement No. W911NF-
09-2-0053 (NS-CTA), U.S. NSF CAREER Award under Grant IIS-0953149, U.S. DARPA Award No. FA8750-
13-2-0041 in the ?Deep Exploration and Filtering of Text? (DEFT) Program, IBM Faculty award and RPI faculty
start-up grant. The views and conclusions contained in this document are those of the authors and should not
be interpreted as representing the official policies, either expressed or implied, of the U.S. Government. The
80
U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any
copyright notation here on.
References
Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual web search engine. Computer
Networks, 30(1-7):107?117.
Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Class-based
n-gram models of natural language. Computational Linguistics, 18:467?479.
Zheng Chen and Heng Ji. 2011. Collaborative ranking: A case study on entity linking. In Proc. EMNLP2011.
Navneet Dalal and Bill Triggs. 2005. Histograms of oriented gradients for human detection. In In CVPR, pages
886?893.
Yansong Feng and Mirella Lapata. 2010. Topic models for image annotation and text illustration. In Human
Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for
Computational Linguistics, HLT ?10, pages 831?839, Stroudsburg, PA, USA. Association for Computational
Linguistics.
Hongzhao Huang, Arkaitz Zubiaga, Heng Ji, Hongbo Deng, Dong Wang, Hieu Le, Tarek Abdelzaher, Jiawei Han,
Alice Leung, John Hancock, and Clare Voss. 2012. Tweet ranking based on heterogeneous networks. In Proc.
COLING 2012, pages 1239?1256, Mumbai, India. The COLING 2012 Organizing Committee.
Kalervo J?arvelin and Jaana Kek?al?ainen. 2002. Cumulated gain-based evaluation of ir techniques. ACM Trans. Inf.
Syst., 20(4):422?446, October.
Yushi Jing and Shumeet Baluja. 2008. Visualrank: Applying pagerank to large-scale image search. IEEE Trans.
Pattern Anal. Mach. Intell., 30(11):1877?1890.
Qi Li, Heng Ji, and Liang Huang. 2013. Joint event extraction via structured prediction with global features. In
Proc. ACL2013, pages 73?82.
R. Mihalcea and P. Tarau. 2004. Textrank: Bringing order into texts. In Proceedings of EMNLP, volume 4.
Barcelona: ACL.
George A. Miller. 1995. Wordnet: A lexical database for english. COMMUNICATIONS OF THE ACM, 38:39?41.
Sameer Pradhan, Wayne Ward, and James H. Martin. 2008. Towards robust semantic role labeling. In Computa-
tional Linguistics Special Issue on Semantic Role Labeling, volume 34, pages 289?310.
Guo-Jun Qi, Charu C. Aggarwal, and Thomas S. Huang. 2012. Transfer learning of distance metrics by cross-
domain metric sampling across heterogeneous spaces. In SDM, pages 528?539.
Kim-Chuan Toh and Sangwoon Yun. 2010. An accelerated proximal gradient algorithm for nuclear norm regular-
ized linear least squares problems. Pacific Journal of Optimization.
Shen-Fu Tsai, Henry Hao Tang, Feng Tang, and Thomas S. Huang. 2012. Ontological inference framework
with joint ontology construction and learning for image understanding. In IEEE International Conference on
Multimedia and Expo (ICME) 2012.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and Kostas Tsioutsiouliklis. 2011. Linguistic redundancy in
twitter. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ?11,
pages 659?669, Stroudsburg, PA, USA. Association for Computational Linguistics.
Wayne X. Zhao, Jing Jiang, Jing He, Yang Song, Palakorn Achananuparp, Ee P. Lim, and Xiaoming Li. 2011.
Topical keyphrase extraction from Twitter. In Proceedings of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Technologies - Volume 1, HLT ?11, pages 379?388, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Xi Zhou, Na Cui, Zhen Li, Feng Liang, and Thomas S. Huang. 2009. Hierarchical gaussianization for image
classification. In ICCV, pages 1971?1977.
81
