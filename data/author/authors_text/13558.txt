Proceedings of the ACL 2010 Student Research Workshop, pages 13?18,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
WSD as a Distributed Constraint Optimization Problem
Siva Reddy
IIIT Hyderabad
India
gvsreddy@students.iiit.ac.in
Abhilash Inumella
IIIT Hyderabad
India
abhilashi@students.iiit.ac.in
Abstract
This work models Word Sense Disam-
biguation (WSD) problem as a Dis-
tributed Constraint Optimization Problem
(DCOP). To model WSD as a DCOP,
we view information from various knowl-
edge sources as constraints. DCOP al-
gorithms have the remarkable property to
jointly maximize over a wide range of util-
ity functions associated with these con-
straints. We show how utility functions
can be designed for various knowledge
sources. For the purpose of evaluation,
we modelled all words WSD as a simple
DCOP problem. The results are competi-
tive with state-of-art knowledge based sys-
tems.
1 Introduction
Words in a language may carry more than one
sense. The correct sense of a word can be iden-
tified based on the context in which it occurs. In
the sentence, He took all his money from the bank,
bank refers to a financial institution sense instead
of other possibilities like the edge of river sense.
Given a word and its possible senses, as defined
by a dictionary, the problem of Word Sense Dis-
ambiguation (WSD) can be defined as the task of
assigning the most appropriate sense to the word
within a given context.
WSD is one of the oldest problems in com-
putational linguistics which dates back to early
1950?s. A range of knowledge sources have been
found to be useful for WSD. (Agirre and Steven-
son, 2006; Agirre and Mart??nez, 2001; McRoy,
1992; Hirst, 1987) highlight the importance of
various knowledge sources like part of speech,
morphology, collocations, lexical knowledge base
(sense taxonomy, gloss), sub-categorization, se-
mantic word associations, selectional preferences,
semantic roles, domain, topical word associations,
frequency of senses, collocations, domain knowl-
edge. etc. Methods for WSD exploit information
from one or more of these knowledge sources.
Supervised approaches like (Yarowsky and Flo-
rian, 2002; Lee and Ng, 2002; Mart??nez et al,
2002; Stevenson and Wilks, 2001) used collec-
tive information from various knowledge sources
to perform disambiguation. Information from var-
ious knowledge sources is encoded in the form of
a feature vector and models were built by training
on sense-tagged corpora. These approaches pose
WSD as a classification problem. They crucially
rely on hand-tagged sense corpora which is hard
to obtain. Systems that do not need hand-tagging
have also been proposed. Agirre and Martinez
(Agirre and Mart??nez, 2001) evaluated the contri-
bution of each knowledge source separately. How-
ever, this does not combine information from more
than one knowledge source.
In any case, little effort has been made in for-
malizing the way in which information from var-
ious knowledge sources can be collectively used
within a single framework: a framework that al-
lows interaction of evidence from various knowl-
edge sources to arrive at a global optimal solution.
Here we present a way for modelling informa-
tion from various knowledge sources in a multi
agent setting called distributed constraint opti-
mization problem (DCOP). In DCOP, agents have
constraints on their values and each constraint has
a utility associated with it. The agents communi-
cate with each other and choose values such that a
global optimum solution (maximum utility) is at-
tained. We aim to solve WSD by modelling it as a
DCOP.
To the best of our knowledge, ours is the first
attempt to model WSD as a DCOP. In DCOP
framework, information from various knowledge
sources can be used combinedly to perform WSD.
In section 2, we give a brief introduction of
13
DCOP. Section 3 describes modelling WSD as
a DCOP. Utility functions for various knowledge
sources are described in section 4. In section 5,
we conduct a simple experiment by modelling all-
words WSD problem as a DCOP and perform dis-
ambiguation on Senseval-2 (Cotton et al, 2001)
and Senseval-3 (Mihalcea and Edmonds, 2004)
data-set of all-words task. Next follow the sec-
tions on related work, discussion, future work and
conclusion.
2 Distributed Constraint Optimization
Problem (DCOP)
A DCOP (Modi, 2003; Modi et al, 2004) consists
of n variables V = x
1
, x
2
, ...x
n
each assigned
to an agent, where the values of the variables are
taken from finite, discrete domains D
1
, D
2
, ..., D
n
respectively. Only the agent has knowledge and
control over values assigned to variables associ-
ated to it. The goal for the agents is to choose
values for variables such that a given global objec-
tive function is maximized. The objective function
is described as the summation over a set of utility
functions.
DCOP can be formalized as a tuple (A, V, D, C,
F) where
? A = {a
1
, a
2
, . . . a
n
} is a set of n agents,
? V = {x
1
, x
2
, . . . x
n
} is a set of n variables,
each one associated to an agent,
? D = {D
1
, D
2
, . . . D
n
} is a set of finite and
discrete domains each one associated to the
corresponding variable,
? C = {f
k
: D
i
?D
j
? . . . D
m
? ?} is a set of
constraints described by various utility func-
tions f
k
. The utility function f
k
is defined
over a subset of variables V . The domain
of f
k
represent the constraints C
f
k
and f
k
(c)
represents the utility associated with the con-
straint c, where c ? C
f
k
.
? F =
?
k
z
k
? f
k
is the objective function to be
maximized where z
k
is the weight of the cor-
responding utility function f
k
An agent is allowed to communicate only with
its neighbours. Agents communicate with each
other to agree upon a solution which maximizes
the objective function.
3 WSD as a DCOP
Given a sequence of words W= {w
1
, w
2
, . . . w
n
}
with corresponding admissible senses D
w
i
=
{s
1
w
i
, s
2
w
i
. . .}, we model WSD as DCOP as fol-
lows.
3.1 Agents
Each word w
i
is treated as an agent. The agent
(word) has knowledge and control of its values
(senses).
3.2 Variables
Sense of a word varies and it is the one to be deter-
mined. We define the sense of a word as its vari-
able. Each agent w
i
is associated with the variable
s
w
i
. The value assigned to this variable indicates
the sense assigned by the algorithm.
3.3 Domains
Senses of a word are finite in number. The set of
senses D
w
i
, is the domain of the variable s
w
i
.
3.4 Constraints
A constraint specifies a particular configuration of
the agents involved in its definition and has a util-
ity associated with it. For e.g. If c
ij
is a constraint
defined on agents w
i
and w
j
, then c
ij
refers to a
particular instantiation of w
i
and w
j
, say w
i
= s
p
w
i
and w
j
= s
q
w
j
.
A utility function f
k
: C
f
k
? ? denote a set of
constraints C
f
k
= {D
w
i
?D
w
j
. . . D
w
m
}, defined
on the agents w
i
, w
j
. . . w
m
and also the utilities
associated with the constraints. We model infor-
mation from each knowledge source as a utility
function. In section 4, we describe in detail about
this modelling.
3.5 Objective function
As already stated, various knowledge sources are
identified to be useful for WSD. It is desirable to
use information from these sources collectively,
to perform disambiguation. DCOP provides such
framework where an objective function is defined
over all the knowledge sources (f
k
) as below
F =
?
k
z
k
? f
k
where F denotes the total utility associated with
a solution and z
k
is the weight given to a knowl-
edge source i.e. information from various sources
14
can be weighted. (Note: It is desirable to nor-
malize utility functions of different knowledge
sources in order to compare them.)
Every agent (word) choose its value (sense) in a
such a way that the objective function (global solu-
tion) is maximized. This way an agent is assigned
a best value which is the target sense in our case.
4 Modelling information from various
knowledge sources
In this section, we discuss the modelling of infor-
mation from various knowledge sources.
4.1 Part-of-speech (POS)
Consider the word play. It has 47 senses out of
which only 17 senses correspond to noun category.
Based on the POS information of a word w
i
, its
domain D
w
i
is restricted accordingly.
4.2 Morphology
Noun orange has at least two senses, one corre-
sponding to a color and other to a fruit. But plu-
ral form of this word oranges can only be used in
the fruit sense. Depending upon the morphologi-
cal information of a word w
i
, its domain D
w
i
can
be restricted.
4.3 Domain information
In the sports domain, cricket likely refers to a
game than an insect. Such information can be cap-
tured using a unary utility function defined for ev-
ery word. If the sense distributions of a word w
i
are known, a function f : D
w
i
? ? is defined
which return higher utility for the senses favoured
by the domain than to the other senses.
4.4 Sense Relatedness
Sense relatedness between senses of two words
w
i
, w
j
is captured by a function f : D
w
i
?D
w
j
?
? where f returns sense relatedness (utility) be-
tween senses based on sense taxonomy and gloss
overlaps.
4.5 Discourse
Discourse constraints can be modelled using a
n-ary function. For instance, to the extent one
sense per discourse (Gale et al, 1992) holds true,
higher utility can be returned to the solutions
which favour same sense to all the occurrences
of a word in a given discourse. This information
can be modeled as follows: If w
i
, w
j
, . . . w
m
are
the occurrences of a same word, a function f :
D
i
? D
j
? . . . D
m
? ? is defined which returns
higher utility when s
w
i
= s
w
j
= . . . s
w
m
and for
the rest of the combinations it returns lower utility.
4.6 Collocations
Collocations of a word are known to provide
strong evidence for identifying correct sense of the
word. For example: if in a given context bank co-
occur with money, it is likely that bank refers to
financial institution sense rather than the edge of
a river sense. The word cancer has at least two
senses, one corresponding to the astrological sign
and the other a disease. But its derived form can-
cerous can only be used in disease sense. When
the words cancer and cancerous co-occur in a dis-
course, it is likely that the word cancer refers to
disease sense.
Most supervised systems work through colloca-
tions to identify correct sense of a word. If a word
w
i
co-occurs with its collocate v, collocational in-
formation from v can be modeled by using the fol-
lowing function
coll infrm v
w
i
: D
w
i
? ?
where coll infrm v
w
i
returns high utility to
collocationally preferred senses of w
i
than other
senses.
Collocations can also be modeled by assigning
more than one variable to the agents or by adding a
dummy agent which gives collocational informa-
tion but in view of simplicity we do not go into
those details.
Topical word associations, semantic word asso-
ciations, selectional preferences can also be mod-
eled similar to collocations. Complex information
involving more than two entities can be modelled
by using n-ary utility functions.
5 Experiment: DCOP based All Words
WSD
We carried out a simple experiment to test the ef-
fectiveness of DCOP algorithm. We conducted
our experiment in an all words setting and used
only WordNet (Fellbaum, 1998) based relatedness
measures as knowledge source so that results can
be compared with earlier state-of-art knowledge-
based WSD systems like (Agirre and Soroa, 2009;
Sinha and Mihalcea, 2007) which used similar
knowledge sources as ours.
15
Our method performs disambiguation on sen-
tence by sentence basis. A utility function based
on semantic relatedness is defined for every pair
of words falling in a particular window size. Re-
stricting utility functions to a window size reduces
the number of constraints. An objective function is
defined as sum of these restricted utility functions
over the entire sentence and thus allowing infor-
mation flow across all the words. Hence, a DCOP
algorithm which aims to maximize this objective
function leads to a globally optimal solution.
In our experiments, we used the best similarity
measure settings of (Sinha and Mihalcea, 2007)
which is a sum of normalized similarity mea-
sures jcn, lch and lesk. We used used Distributed
Pseudotree Optimization Procedure (DPOP) algo-
rithm (Petcu and Faltings, 2005), which solves
DCOP using linear number of messages among
agents. The implementation provided with the
open source toolkit FRODO1 (Le?aute? et al, 2009)
is used.
5.1 Data
To compare our results, we ran our experiments
on SENSEVAL-2 and SENSEVAL -3 English all-
words data sets.
5.2 Results
Table 1 shows results of our experiments. All
these results are carried out using a window size
of four. Ideally, precision and recall values are ex-
pected to be equal in our setting. But in certain
cases, the tool we used, FRODO, failed to find a
solution with the available memory resources.
Results show that our system performs con-
sistently better than (Sinha and Mihalcea, 2007)
which uses exactly same knowledge sources as
used by us (with an exception of adverbs in
Senseval-2). This shows that DCOP algorithm
perform better than page-rank algorithm used in
their graph based setting. Thus, for knowledge-
based WSD, DCOP framework is a potential al-
ternative to graph based models.
Table 1 also shows the system (Agirre and
Soroa, 2009), which obtained best results for
knowledge based WSD. A direct comparison
between this and our system is not quantita-
tive since they used additional knowledge such
as extended WordNet relations (Mihalcea and
1http://liawww.epfl.ch/frodo/
Moldovan, 2001) and sense disambiguated gloss
present in WordNet3.0.
Senseval-2 All Words data set
noun verb adj adv all
P dcop 67.85 37.37 62.72 56.87 58.63
R dcop 66.44 35.47 61.28 56.65 57.09
F dcop 67.14 36.39 61.99 56.76 57.85
P Sinha07 67.73 36.05 62.21 60.47 58.83
R Sinha07 65.63 32.20 61.42 60.23 56.37
F Sinha07 66.24 34.07 61.81 60.35 57.57
Agirre09 70.40 38.90 58.30 70.1 58.6
MFS 71.2 39.0 61.1 75.4 60.1
Senseval-3 All Words data set
P dcop 62.31 43.48 57.14 100 54.68
R dcop 60.97 42.81 55.17 100 53.51
F dcop 61.63 43.14 56.14 100 54.09
P Sinha07 61.22 45.18 54.79 100 54.86
R Sinha07 60.45 40.57 54.14 100 52.40
F Sinha07 60.83 42.75 54.46 100 53.60
Agirre09 64.1 46.9 62.6 92.9 57.4
MFS 69.3 53.6 63.7 92.9 62.3
Table 1: Evaluation results on Senseval-2 and
Senseval-3 data-set of all words task.
5.3 Performance analysis
We conducted our experiment on a computer with
two 2.94 GHz process and 2 GB memory. Our
algorithm just took 5 minutes 31 seconds on
Senseval-2 data set, and 5 minutes 19 seconds on
Senseval-3 data set. This is a singable reduction
compared to execution time of page rank algo-
rithms employed in both Sinha07 and Agirre09. In
Agirre09, it falls in the range 30 to 180 minutes on
much powerful system with 16 GB memory hav-
ing four 2.66 GHz processors. On our system,
time taken by the page rank algorithm in (Sinha
and Mihalcea, 2007) is 11 minutes when executed
on Senseval-2 data set.
Since DCOP algorithms are truly distributed in
nature the execution times can be further reduced
by running them parallely on multiple processors.
6 Related work
Earlier approaches to WSD which encoded infor-
mation from variety of knowledge sources can be
classified as follows:
? Supervised approaches: Most of the super-
vised systems (Yarowsky and Florian, 2002;
16
Lee and Ng, 2002; Mart??nez et al, 2002;
Stevenson and Wilks, 2001) rely on the sense
tagged data. These are mainly discrimina-
tive or aggregative models which essentially
pose WSD a classification problem. Dis-
criminative models aim to identify the most
informative feature and aggregative models
make their decisions by combining all fea-
tures. They disambiguate word by word and
do not collectively disambiguate whole con-
text and thereby do not capture all the rela-
tionships (e.g sense relatedness) among all
the words. Further, they lack the ability to
directly represent constraints like one sense
per discourse.
? Graph based approaches: These approaches
crucially rely on lexical knowledge base.
Graph-based WSD approaches (Agirre and
Soroa, 2009; Sinha and Mihalcea, 2007) per-
form disambiguation over a graph composed
of senses (nodes) and relations between pairs
of senses (edges). The edge weights encode
information from a lexical knowledge base
but lack an efficient way of modelling in-
formation from other knowledge sources like
collocational information, selectional prefer-
ences, domain information, discourse. Also,
the edges represent binary utility functions
defined over two entities which lacks the abil-
ity to encode ternary, and in general, any N-
ary utility functions.
7 Discussion
This framework provides a convenient way of
integrating information from various knowledge
sources by defining their utility functions. Infor-
mation from different knowledge sources can be
weighed based on the setting at hand. For exam-
ple, in a domain specific WSD setting, sense dis-
tributions play a crucial role. The utility function
corresponding to the sense distributions can be
weighed higher in order to take advantage of do-
main information. Also, different combination of
weights can be tried out for a given setting. Thus
for a given WSD setting, this framework allows us
to find 1) the impact of each knowledge source in-
dividually 2) the best combination of knowledge
sources.
Limitations of DCOP algorithms: Solving
DCOPs is NP-hard. A variety of search algorithms
have therefore been developed to solve DCOPs
(Mailler and Lesser, 2004; Modi et al, 2004;
Petcu and Faltings, 2005) . As the number of
constraints or words increase, the search space in-
creases thereby increasing the time and memory
bounds to solve them. Also DCOP algorithms ex-
hibit a trade-off between memory used and num-
ber of messages communicated between agents.
DPOP (Petcu and Faltings, 2005) use linear num-
ber of messages but requires exponential memory
whereas ADOPT (Modi et al, 2004) exhibits lin-
ear memory complexity but exchange exponential
number of messages. So it is crucial to choose a
suitable algorithm based on the problem at hand.
8 Future Work
In our experiment, we only used relatedness based
utility functions derived from WordNet. Effect of
other knowledge sources remains to be evaluated
individually and in combination. The best possible
combination of weights of knowledge sources is
yet to be engineered. Which DCOP algorithm per-
forms better WSD and when has to be explored.
9 Conclusion
We initiated a new line of investigation into WSD
by modelling it in a distributed constraint opti-
mization framework. We showed that this frame-
work is powerful enough to encode information
from various knowledge sources. Our experimen-
tal results show that a simple DCOP based model
encoding just word similarity constraints performs
comparably with the state-of-the-art knowledge
based WSD systems.
Acknowledgement
We would like to thank Prof. Rajeev Sangal and
Asrar Ahmed for their support in coming up with
this work.
References
Eneko Agirre and David Mart??nez. 2001. Knowledge
sources for word sense disambiguation. In Text,
Speech and Dialogue, 4th International Conference,
TSD 2001, Zelezna Ruda, Czech Republic, Septem-
ber 11-13, 2001, Lecture Notes in Computer Sci-
ence, pages 1?10. Springer.
Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing pagerank for word sense disambiguation. In
EACL ?09: Proceedings of the 12th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 33?41, Morristown, NJ,
USA. Association for Computational Linguistics.
17
Eneko Agirre and Mark Stevenson. 2006. Knowledge
sources for wsd. In Word Sense Disambiguation:
Algorithms and Applications, volume 33 of Text,
Speech and Language Technology, pages 217?252.
Springer, Dordrecht, The Netherlands.
Scott Cotton, Phil Edmonds, Adam Kilgarriff, and
Martha Palmer. 2001. Senseval-2. http://www.
sle.sharp.co.uk/senseval2.
Christiane Fellbaum, editor. 1998. WordNet An Elec-
tronic Lexical Database. The MIT Press, Cam-
bridge, MA ; London, May.
William A. Gale, Kenneth W. Church, and David
Yarowsky. 1992. One sense per discourse. In HLT
?91: Proceedings of the workshop on Speech and
Natural Language, pages 233?237, Morristown, NJ,
USA. Association for Computational Linguistics.
Graeme Hirst. 1987. Semantic interpretation and
the resolution of ambiguity. Cambridge University
Press, New York, NY, USA.
Thomas Le?aute?, Brammert Ottens, and Radoslaw Szy-
manek. 2009. FRODO 2.0: An open-source
framework for distributed constraint optimization.
In Proceedings of the IJCAI?09 Distributed Con-
straint Reasoning Workshop (DCR?09), pages 160?
164, Pasadena, California, USA, July 13. http:
//liawww.epfl.ch/frodo/.
Yoong Keok Lee and Hwee Tou Ng. 2002. An em-
pirical evaluation of knowledge sources and learn-
ing algorithms for word sense disambiguation. In
EMNLP ?02: Proceedings of the ACL-02 conference
on Empirical methods in natural language process-
ing, pages 41?48, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Roger Mailler and Victor Lesser. 2004. Solving
distributed constraint optimization problems using
cooperative mediation. In AAMAS ?04: Proceed-
ings of the Third International Joint Conference on
Autonomous Agents and Multiagent Systems, pages
438?445, Washington, DC, USA. IEEE Computer
Society.
David Mart??nez, Eneko Agirre, and Llu??s Ma`rquez.
2002. Syntactic features for high precision word
sense disambiguation. In COLING.
Susan W. McRoy. 1992. Using multiple knowledge
sources for word sense discrimination. COMPUTA-
TIONAL LINGUISTICS, 18:1?30.
Rada Mihalcea and Phil Edmonds, editors. 2004.
Proceedings Senseval-3 3rd International Workshop
on Evaluating Word Sense Disambiguation Systems.
ACL, Barcelona, Spain.
Rada Mihalcea and Dan I. Moldovan. 2001. ex-
tended wordnet: progress report. In in Proceedings
of NAACL Workshop on WordNet and Other Lexical
Resources, pages 95?100.
Pragnesh Jay Modi, Wei-Min Shen, Milind Tambe, and
Makoto Yokoo. 2004. Adopt: Asynchronous dis-
tributed constraint optimization with quality guaran-
tees. Artificial Intelligence, 161:149?180.
Pragnesh Jay Modi. 2003. Distributed constraint opti-
mization for multiagent systems. PhD Thesis.
Adrian Petcu and Boi Faltings. 2005. A scalable
method for multiagent constraint optimization. In
IJCAI?05: Proceedings of the 19th international
joint conference on Artificial intelligence, pages
266?271, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Ravi Sinha and Rada Mihalcea. 2007. Unsupervised
graph-basedword sense disambiguation using mea-
sures of word semantic similarity. In ICSC ?07: Pro-
ceedings of the International Conference on Seman-
tic Computing, pages 363?369, Washington, DC,
USA. IEEE Computer Society.
Mark Stevenson and Yorick Wilks. 2001. The inter-
action of knowledge sources in word sense disam-
biguation. Comput. Linguist., 27(3):321?349.
David Yarowsky and Radu Florian. 2002. Evaluat-
ing sense disambiguation across diverse parameter
spaces. Natural Language Engineering, 8:2002.
18
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 387?391,
Uppsala, Sweden, 15-16 July 2010.
c
?2010 Association for Computational Linguistics
IIITH: Domain Specific Word Sense Disambiguation
Siva Reddy
IIIT Hyderabad
India
gvsreddy@students.iiit.ac.in
Diana McCarthy
Lexical Computing Ltd.
United Kingdom
diana@dianamccarthy.co.uk
Abhilash Inumella
IIIT Hyderabad
India
abhilashi@students.iiit.ac.in
Mark Stevenson
University of Sheffield
United Kingdom
m.stevenson@dcs.shef.ac.uk
Abstract
We describe two systems that participated
in SemEval-2010 task 17 (All-words Word
Sense Disambiguation on a Specific Do-
main) and were ranked in the third and
fourth positions in the formal evaluation.
Domain adaptation techniques using the
background documents released in the
task were used to assign ranking scores to
the words and their senses. The test data
was disambiguated using the Personalized
PageRank algorithm which was applied
to a graph constructed from the whole of
WordNet in which nodes are initialized
with ranking scores of words and their
senses. In the competition, our systems
achieved comparable accuracy of 53.4 and
52.2, which outperforms the most frequent
sense baseline (50.5).
1 Introduction
The senses in WordNet are ordered according to
their frequency in a manually tagged corpus, Sem-
Cor (Miller et al, 1993). Senses that do not oc-
cur in SemCor are ordered arbitrarily after those
senses of the word that have occurred. It is known
from the results of SENSEVAL2 (Cotton et al,
2001) and SENSEVAL3 (Mihalcea and Edmonds,
2004) that first sense heuristic outperforms many
WSD systems (see McCarthy et al (2007)). The
first sense baseline?s strong performance is due to
the skewed frequency distribution of word senses.
WordNet sense distributions based on SemCor are
clearly useful, however in a given domain these
distributions may not hold true. For example, the
first sense for ?bank? in WordNet refers to ?slop-
ing land beside a body of river? and the second
to ?financial institution?, but in the domain of ?fi-
nance? the ?financial institution? sense would be
expected to be more likely than the ?sloping land
beside a body of river? sense. Unfortunately, it
is not feasible to produce large manually sense-
annotated corpora for every domain of interest.
McCarthy et al (2004) propose a method to pre-
dict sense distributions from raw corpora and use
this as a first sense heuristic for tagging text with
the predominant sense. Rather than assigning pre-
dominant sense in every case, our approach aims
to use these sense distributions collected from do-
main specific corpora as a knowledge source and
combine this with information from the context.
Our approach focuses on the strong influence of
domain for WSD (Buitelaar et al, 2006) and the
benefits of focusing on words salient to the do-
main (Koeling et al, 2005). Words are assigned
a ranking score based on its keyness (salience) in
the given domain. We use these word scores as
another knowledge source.
Graph based methods have been shown to
produce state-of-the-art performance for unsu-
pervised word sense disambiguation (Agirre and
Soroa, 2009; Sinha and Mihalcea, 2007). These
approaches use well-known graph-based tech-
niques to find and exploit the structural properties
of the graph underlying a particular lexical knowl-
edge base (LKB), such as WordNet. These graph-
based algorithms are appealing because they take
into account information drawn from the entire
graph as well as from the given context, making
them superior to other approaches that rely only
on local information individually derived for each
word.
Our approach uses the Personalized PageRank
algorithm (Agirre and Soroa, 2009) over a graph
387
representing WordNet to disambiguate ambigu-
ous words by taking their context into consider-
ation. We also combine domain-specific informa-
tion from the knowledge sources, like sense distri-
bution scores and keyword ranking scores, into the
graph thus personalizing the graph for the given
domain.
In section 2, we describe domain sense ranking.
Domain keyword ranking is described in Section
3. Graph construction and personalized page rank
are described in Section 4. Evaluation results over
the SemEval data are provided in Section 5.
2 Domain Sense Ranking
McCarthy et al (2004) propose a method for
finding predominant senses from raw text. The
method uses a thesaurus acquired from automat-
ically parsed text based on the method described
by Lin (1998). This provides the top k nearest
neighbours for each target word w, along with the
distributional similarity score between the target
word and each neighbour. The senses of a word
w are each assigned a score by summing over the
distributional similarity scores of its neighbours.
These are weighted by a semantic similarity score
(using WordNet Similarity score (Pedersen et al,
2004) between the sense of w and the sense of the
neighbour that maximizes the semantic similarity
score.
More formally, let N
w
= {n
1
, n
2
, . . . n
k
}
be the ordered set of the top k scoring
neighbours of w from the thesaurus with
associated distributional similarity scores
{dss(w, n
1
), dss(w, n
2
), . . . dss(w, n
k
)}. Let
senses(w) be the set of senses of w. For each
sense of w (ws
i
? senses(w)) a ranking score is
obtained by summing over the dss(w, n
j
) of each
neighbour (n
j
? N
w
) multiplied by a weight.
This weight is the WordNet similarity score
(wnss) between the target sense (ws
i
) and the
sense of n
j
(ns
x
? senses(n
j
)) that maximizes
this score, divided by the sum of all such WordNet
similarity scores for senses(w) and n
j
. Each
sense ws
i
? senses(w) is given a sense ranking
score srs(ws
i
) using
srs(ws
i
) =
?
n
j
N
w
dss(w, n
j
)?
wnss(ws
i
, n
j
)
?
ws
i
senses(w)
wnss(ws
i
, n
j
)
where wnss(ws
i
, n
j
) =
max
ns
x
?senses(n
j
)
(wnss(ws
i
, ns
x
))
Since this approach requires only raw text,
sense rankings for a particular domain can be gen-
erated by simply training the algorithm using a
corpus representing that domain. We used the
background documents provided to the partici-
pants in this task as a domain specific corpus. In
general, a domain specific corpus can be obtained
using domain-specific keywords (Kilgarriff et al,
2010). A thesaurus is acquired from automatically
parsed background documents using the Stanford
Parser (Klein and Manning, 2003). We used k = 5
to built the thesaurus. As we increased k we found
the number of non-domain specific words occur-
ring in the thesaurus increased and negatively af-
fected the sense distributions. To counter this, one
of our systems IIITH2 used a slightly modified
ranking score by multiplying the effect of each
neighbour with its domain keyword ranking score.
The modified sense ranking msrs(ws
j
) score of
sense ws
i
is
msrs(ws
i
) =
?
n
j
N
w
dss(w, n
j
)?
wnss(ws
i
, n
j
)
?
ws
i
senses(w)
wnss(ws
i
, n
j
)
?krs(n
j
)
where krs(n
j
) is the keyword ranking score of
the neighbour n
j
in the domain specific corpus. In
the next section we describe the way in which we
compute krs(n
j
).
WordNet::Similarity::lesk (Pedersen et al,
2004) was used to compute word similarity wnss.
IIITH1 and IIITH2 systems differ in the way
senses are ranked. IIITH1 uses srs(ws
j
) whereas
IIITH2 system uses msrs(ws
j
) for computing
sense ranking scores in the given domain.
3 Domain Keyword Ranking
We extracted keywords in the domain by compar-
ing the frequency lists of domain corpora (back-
ground documents) and a very large general cor-
pus, ukWaC (Ferraresi et al, 2008), using the
method described by Rayson and Garside (2000).
For each word in the frequency list of the domain
corpora, words(domain), we calculated the log-
likelihood (LL) statistic as described in Rayson
and Garside (2000). We then normalized LL to
compute keyword ranking score krs(w) of word
w words(domain) using
388
krs(w) =
LL(w)
?
w
i
?words(domain)
LL(w
i
)
The above score represents the keyness of the
word in the given domain. Top ten keywords (in
descending order of krs) in the corpora provided
for this task are species, biodiversity, life, habitat,
natura
1
, EU, forest, conservation, years, amp
2
.
4 Personalized PageRank
Our approach uses the Personalized PageRank al-
gorithm (Agirre and Soroa, 2009) with WordNet
as the lexical knowledge base (LKB) to perform
WSD. WordNet is converted to a graph by repre-
senting each synset as a node (synset node) and the
relationships in WordNet (hypernymy, hyponymy
etc.) as edges between synset nodes. The graph is
initialized by adding a node (word node) for each
context word of the target word (including itself)
thus creating a context dependent graph (person-
alized graph). The popular PageRank (Page et al,
1999) algorithm is employed to analyze this per-
sonalized graph (thus the algorithm is referred as
personalized PageRank algorithm) and the sense
for each disambiguous word is chosen by choos-
ing the synset node which gets the highest weight
after a certain number of iterations of PageRank
algorithm.
We capture domain information in the personal-
ized graph by using sense ranking scores and key-
word ranking scores of the domain to assign initial
weights to the word nodes and their edges (word-
synset edge). This way we personalize the graph
for the given domain.
4.1 Graph Initialization Methods
We experimented with different ways of initial-
izing the graph, described below, which are de-
signed to capture domain specific information.
Personalized Page rank (PPR): In this method,
the graph is initialized by allocating equal prob-
ability mass to all the word nodes in the context
including the target word itself, thus making the
graph context sensitive. This does not include do-
main specific information.
1
In background documents this word occurs in reports de-
scribing Natura 2000 networking programme.
2
This new word ?amp? is created by our programs while
extracting body text from background documents. The
HTML code ?&amp;? which represents the symbol?&? is
converted into this word.
Keyword Ranking scores with PPR (KRS +
PPR): This is same as PPR except that context
words are initialized with krs.
Sense Ranking scores with PPR (SRS + PPR):
Edges connecting words and their synsets are as-
signed weights equal to srs. The initialization of
word nodes is same as in PPR.
KRS + SRS + PPR: Word nodes are initialized
with krs and edges are assigned weights equal to
srs.
In addition to the above methods of unsuper-
vised graph initialization, we also initialized the
graph in a semi-supervised manner. WordNet (ver-
sion 1.7 and above) have a field tag cnt for each
synset (in the file index.sense) which represents
the number of times the synset is tagged in vari-
ous semantic concordance texts. We used this in-
formation, concordance score (cs) of each synset,
with the above methods of graph initialization as
described below.
Concordance scores with PPR (CS + PPR): The
graph initialization is similar to PPR initialization
additionally with concordance score of synsets on
the edges joining words and their synsets.
CS + KRS + PPR: The initialization graph of
KRS + PPR is further initialized by assigning con-
cordance scores to the edges connecting words and
their synsets.
CS + SRS + PPR: Edges connecting words and
their synsets are assigned weights equal to sum of
the concordance scores and sense ranking scores
i.e. cs + srs. The initialization of word nodes is
same as in PPR.
CS + KRS + SRS + PPR: Word nodes are ini-
tialized with krs and edges are assigned weights
equal to cs + srs.
PageRank was applied to all the above graphs to
disambiguate a target word.
4.2 Experimental details of PageRank
Tool: We used UKB tool
3
(Agirre and Soroa,
2009) which provides an implementation of per-
sonalized PageRank. We modified it to incorpo-
rate our methods of graph initialization. The LKB
used in our experiments is WordNet3.0 + Gloss
which is provided in the tool. More details of the
tools used can be found in the Appendix.
Normalizations: Sense ranking scores (srs) and
keyword ranking scores (krs) have diverse ranges.
We found srs generally in the range between 0 to
3
http://ixa2.si.ehu.es/ukb/
389
Precision Recall
Unsupervised Graph Initialization
PPR 37.3 36.8
KRS + PPR 38.1 37.6
SRS + PPR 48.4 47.8
KRS + SRS + PPR 48.0 47.4
Semi-supervised Graph Initialization
CS + PPR 50.2 49.6
CS + KRS + PPR 50.1 49.5
* CS + SRS + PPR 53.4 52.8
CS + KRS + SRS + PPR 53.6 52.9
Others
1
st
sense 50.5 50.5
PSH 49.8 43.2
Table 1: Evaluation results on English test data of SemEval-2010 Task-17. * represents the system which
we submitted to SemEval and is ranked 3rd in public evaluation.
1 and krs in the range 0 to 0.02. Since these scores
are used to assign initial weights in the graph,
these ranges are scaled to fall in a common range
of [0, 100]. Using any other scaling method should
not effect the performance much since PageRank
(and UKB tool) has its own internal mechanisms
to normalize the weights.
5 Evaluation Results
Test data released for this task is disambiguated
using IIITH1 and IIITH2 systems. As described
in Section 2, IIITH1 and IIITH2 systems differ in
the way the sense ranking scores are computed.
Here we project only the results of IIITH1 since
IIITH1 performed slightly better than IIITH2 in all
the above settings. Results of 1
st
sense system pro-
vided by the organizers which assigns first sense
computed from the annotations in hand-labeled
corpora is also presented. Additionally, we also
present the results of Predominant Sense Heuristic
(PSH) which assigns every word w with the sense
ws
j
(ws
j
? senses(w)) which has the highest
value of srs(ws
j
) computed in Section 2 similar
to (McCarthy et al, 2004).
Table 1 presents the evaluation results. We used
TreeTagger
4
to Part of Speech tag the test data.
POS information was used to discard irrelevant
senses. Due to POS tagging errors, our precision
values were not equal to recall values. In the com-
petition, we submitted IIITH1 and IIITH2 systems
with CS + SRS + PPR graph initialization. IIITH1
4
http://www.ims.uni-stuttgart.de/
projekte/corplex/TreeTagger/
and IIIH2 gave performances of 53.4 % and 52.2
% precision respectively. In our later experiments,
we found CS + KRS + SRS + PPR has given the
best performance of 53.6 % precision.
From the results, it can be seen when srs in-
formation is incorporated in the graph, precision
improved by 11.1% compared to PPR in unsuper-
vised graph initialization and by 3.19% compared
to CS + PPR in semi-supervised graph initializa-
tion. Also little improvements are seen when krs
information is added. This shows that domain
specific information like sense ranking scores and
keyword ranking scores play a major role in do-
main specific WSD.
The difference between the results in unsu-
pervised and semi-supervised graph initializations
may be attributed to the additional information the
semi-supervised graph is having i.e. the sense dis-
tribution knowledge of non-domain specific words
(common words).
6 Conclusion
This paper proposes a method for domain specific
WSD. Our method is based on a graph-based al-
gorithm (Personalized Page Rank) which is mod-
ified to include information representing the do-
main (sense ranking and key word ranking scores).
Experiments show that exploiting this domain spe-
cific information within the graph based methods
produces better results than when this information
is used individually.
390
Acknowledgements
The authors are grateful to Ted Pedersen for his
helpful advice on the WordNet Similarity Pack-
age. We also thank Rajeev Sangal for supporting
the authors Siva Reddy and Abhilash Inumella.
References
Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing pagerank for word sense disambiguation. In
EACL ?09: Proceedings of the 12th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 33?41, Morristown, NJ,
USA. Association for Computational Linguistics.
Paul Buitelaar, Bernardo Magnini, Carlo Strapparava,
and Piek Vossen. 2006. Domain-specific wsd. In
Word Sense Disambiguation. Algorithms and Appli-
cations, Editors: Eneko Agirre and Philip Edmonds.
Springer.
Scott Cotton, Phil Edmonds, Adam Kilgarriff, and
Martha Palmer. 2001. Senseval-2. http://www.
sle.sharp.co.uk/senseval2.
A. Ferraresi, E. Zanchetta, M. Baroni, and S. Bernar-
dini. 2008. Introducing and evaluating ukwac,
a very large web-derived corpus of english. In
Proceed-ings of the WAC4 Workshop at LREC 2008,
Marrakesh, Morocco.
Adam Kilgarriff, Siva Reddy, Jan Pomik?alek, and Avi-
nesh PVS. 2010. A corpus factory for many lan-
guages. In LREC 2010, Malta.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In ACL ?03: Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 423?430, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Rob Koeling, Diana McCarthy, and John Carroll.
2005. Domain-specific sense distributions and pre-
dominant sense acquisition. In HLT ?05: Proceed-
ings of the conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing, pages 419?426, Morristown, NJ, USA.
Association for Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and cluster-
ing of similar words. In Proceedings of the 17th
international conference on Computational linguis-
tics, pages 768?774, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding predominant word senses in
untagged text. In ACL ?04: Proceedings of the 42nd
Annual Meeting on Association for Computational
Linguistics, page 279, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised acquisition of pre-
dominant word senses. Computational Linguistics,
33(4):553?590.
Rada Mihalcea and Phil Edmonds, editors. 2004.
Proceedings Senseval-3 3rd International Workshop
on Evaluating Word Sense Disambiguation Systems.
ACL, Barcelona, Spain.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A semantic concordance. In
Proceedings of the ARPA Workshop on Human Lan-
guage Technology, pages 303?308. Morgan Kauf-
man.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical Report
1999-66, Stanford InfoLab, November.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet::similarity: measuring the re-
latedness of concepts. In HLT-NAACL ?04: Demon-
stration Papers at HLT-NAACL 2004 on XX, pages
38?41, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Paul Rayson and Roger Garside. 2000. Comparing
corpora using frequency profiling. In Proceedings
of the workshop on Comparing corpora, pages 1?
6, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Ravi Sinha and Rada Mihalcea. 2007. Unsupervised
graph-basedword sense disambiguation using mea-
sures of word semantic similarity. In ICSC ?07: Pro-
ceedings of the International Conference on Seman-
tic Computing, pages 363?369, Washington, DC,
USA. IEEE Computer Society.
Appendix
Domain Specific Thesaurus, Sense Ranking
Scores and Keyword Ranking Scores are accessi-
ble at
http://web.iiit.ac.in/
?
gvsreddy/
SemEval2010/
Tools Used:
? UKB is used with options ?ppr ?dict weight. Dictio-
nary files which UKB uses are automatically generated
using sense ranking scores srs.
? Background document words are canonicalized using
KSTEM, a morphological analyzer
? The Stanford Parser is used to parse background docu-
ments to build thesaurus
? Test data is part of speech tagged using TreeTagger.
391
Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology (SIGMORPHON2012), pages 10?16,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
Hindi Derivational Morphological Analyzer
Nikhil Kanuparthi
LTRC
IIIT-Hyderabad
India
{nikhil.kvs,abhilashi}
Abhilash Inumella
LTRC
IIIT-Hyderabad
India
@research.iiit.ac.in
Dipti Misra Sharma
LTRC
IIIT-Hyderabad
India
dipti@iiit.ac.in
Abstract
Hindi is an Indian language which is rela-
tively rich in morphology. A few morpholog-
ical analyzers of this language have been de-
veloped. However, they give only inflectional
analysis of the language. In this paper, we
present our Hindi derivational morphological
analyzer. Our algorithm upgrades an existing
inflectional analyzer to a derivational analyzer
and primarily achieves two goals. First, it suc-
cessfully incorporates derivational analysis in
the inflectional analyzer. Second, it also in-
creases the coverage of the inflectional analy-
sis of the existing inflectional analyzer.
1 Introduction
Morphology is the study of processes of word for-
mation and also the linguistic units such as mor-
phemes, affixes in a given language. It consists
of two branches: derivational morphology and in-
flectional morphology. Derivational morphology
is the study of those processes of word formation
where new words are formed from the existing stems
through the addition of morphemes. The meaning of
the resultant new word is different from the original
word and it often belongs to a different syntactic cat-
egory. Example: happiness (noun) = happy (adjec-
tive) + ness. Inflectional morphology is the study of
those processes of word formation where various in-
flectional forms are formed from the existing stems.
Number is an example of inflectional morphology.
Example: cars = car + plural affix ?s?.
The main objective of our work is to develop a
tool which executes the derivational morphological
analysis of Hindi. Morphological analysis is an im-
portant step for any linguistically informed natural
language processing task. Most morphological ana-
lyzers perform only inflectional analysis. However,
derivational analysis is also crucial for better perfor-
mance of several systems. They are used to improve
the efficiency of machine translators (C Gdaniec et
al., 2001). They are also used in search engines
to improve the information extraction (J Vilares et
al., 2001). Since derivational processes can often be
productive in a language, the development of an ef-
fective derivational analyzer will prove beneficial in
several aspects.
We developed a derivational analyzer for Hindi
over an already existing inflectional analyzer devel-
oped at IIIT Hyderabad. In this approach, first, the
derived words in Hindi were studied to obtain the
derivational suffixes of the language. Then the rules
were designed by understanding the properties of the
suffixes. The Hindi Wikipedia was also utilized to
collect the required background data. Finally, an al-
gorithm was developed based on the above findings.
This algorithm has been used to upgrade the inflec-
tional analyzer to a derivational analyzer.
In the sections that follow, we describe the ap-
proach we followed to develop our derivational an-
alyzer and the experiments that we conducted using
our system.
2 Related Work
There is no derivational morphological analyzer for
Hindi to the best of our knowledge. However,
a few inflectional morphological analyzers (IIIT;
Vishal and G. Singh, 2008; Niraj and Robert, 2010)
10
of this language have been developed. There are
derivational analyzers for other Indian languages
like Marathi (Ashwini Vaidya, 2009) and Kannada
(Bhuvaneshwari C Melinamath et al, 2011). The
Marathi morphological analyzer was built using a
Paradigm based approach whereas the Kannada ana-
lyzer was built using an FST based approach. As far
as English is concerned, there are some important
works (Woods, 2000; Hoeppner, 1982) pertaining
to the area of derivational morphological analysis.
However, both of these are lexicon based works.
For our work, we employed a set of suffix replace-
ment rules and a dictionary in our derivational ana-
lyzer, having taken insights from the Porter?s stem-
mer (Porter, 1980) and the K-stemmer (R. Krovetz.
1993). They are amongst the most cited stemmers
in the literature. The primary goal of Porter?s stem-
mer is suffix stripping. So when a word is given as
input, the stemmer strips all the suffixes in the word
to produce a stem. It achieves the task in five steps
applying rules at each step. Given a word as input,
the Krovetz stemmer removes inflectional suffixes
present in the word in three steps. First it converts
the plural form of the word into a singular form,
then it converts past tense to present tense, and fi-
nally removes -ing. As the last step, the stemmer
checks the dictionary for any recoding and returns
the stem. Our algorithm uses the main principles of
both the Porters stemmer and Krovetz stemmer. The
suffix replacement rules of our algorithm resemble
that of the Porters and a segment of the algorithm
is analogous to the dictionary based approach of the
Krovetzs stemmer.
3 Existing Inflectional Hindi
Morphological Analyzers
A derivational morph analyzer can be developed
from an existing morph analyzer instead of build-
ing one from scratch. So three inflectional analyzers
were considered for the purpose. The morphological
analyzer developed by Vishal and Gurpreet stores all
the commonly used word forms for all Hindi root
words in its database. Thus, space is a constraint for
this analyzer but the search time is quite low. The
morph analyzer developed by Niraj and Robert ex-
tracts a set of suffix replacement rules from a corpus
and a dictionary. The rules are applied to an inflected
word to obtain the root word. They show that the
process of developing such rulessets is simple and it
can be applied to develop morphological analyzers
of other Indian languages.
However, our derivational analyzer is an exten-
sion of an existing inflectional morphological ana-
lyzer developed at IIIT Hyderabad (Bharati Akshar
et al 1995). The inflectional analyzer is based on
the paradigm model. It uses the combination of
paradigms and a root word dictionary to provide in-
flectional analysis. Given an inflected Hindi word,
this inflectional analyzer returns its root form and
other grammatical features such as gender, num-
ber, person, etc. For example: if the input word
to the morphological analyzer is bAgabAnoM1 (gar-
deners), the output will be bAgabAna (gardener),
noun, m, pl, etc. Here the word bAgabAna is the
root word of the input word. ?Noun? is the cate-
gory of the input word, ?m? means masculine and
?pl? means that the input word is plural in number.
The analyzer uses a root word dictionary for the
purpose. If a word is present in the root word dic-
tionary, the analyzer handles all the inflections per-
taining to that word. For example: xe (give) is a root
word present in the dictionary of the analyzer. xewA
(gives), xenA (to give), xiyA (gave) and other inflec-
tional forms of the root word xe are handled by the
analyzer. There are 34407 words in the root word
dictionary.
The analyzer handles inflected words using the
paradigm tables. Every entry (word) in the dic-
tionary has values like lexical category, paradigm
class, etc. For example: there is a word pulisavAlA
(policeman) in the dictionary. Its paradigm class
is ladakA. Table 1 shows the paradigm forms of
ladakA. Since the paradigm value of pulisavAlA is
ladakA, its four inflections will be similar to the four
paradigms of ladakA (root paradigm). The four in-
flections of pulisavAlA are pulisavAlA, pulisavAle,
pulisavAle, pulisavAloM. Only the root form (word)
pulisavAlA is present in the dictionary. In this way
every root word present in the dictionary belongs to
a paradigm class and this paradigm class has a struc-
tured paradigm table containing all the inflections of
the main paradigm. This paradigm table is used by
1The Hindi words are in wx-format (san-
skrit.inria.fr/DATA/wx.html) followed by IIIT-Hyderabad.
11
Table 1: Paradigm table of ladakA
Case Singular form Plural form
Direct ladakA (boy) ladake (boys)
Oblique ladake (boy) ladakoM (boys)
the analyzer to reconstruct all the inflections of the
root words belonging to this paradigm class. There-
fore the analyzer can analyze a word only if its root
word is present in the dictionary.
This inflectional morphological analyzer works as
a platform for our derivational morphological ana-
lyzer. So our tool gives derivational analysis of all
the words whose root forms are present in the root
word dictionary. Our tool also tackles certain words
whose root forms are not present in the root word
dictionary of the IIIT morphological analyzer.
4 Approach
We pursued the following five step approach for
building our derivational analyzer.
4.1 Studying Hindi Derivations
To build the derivational morphological analyzer, we
first conducted a study to identify the derivational
suffixes and the related morphological changes. Af-
ter identifying the suffixes, the rules pertaining to
these suffixes were obtained.
First, the nouns present in the Hindi vocabulary
were studied. The study of nouns helped us in iden-
tifying some of the most productive derivational suf-
fixes present in the language. For example, let us
consider the word maxaxagAra (helper). This word
is derived from the word maxaxa (maxaxagAra =
maxaxa (help) + gAra). But gAra cannot be con-
firmed as a suffix because of just one instance. In
order to confirm gAra as a suffix, even other words
ending with gAra must be examined. The more the
number of words we find, the greater is the pro-
ductivity of the suffix. Words like yAxagAra (de-
rived from yAxa) and gunAhagAra (criminal) (de-
rived from gunAha (crime)) prove that gAra is a
derivational suffix. However, every word ending
with gAra need not be a derived word. For exam-
ple: the word aMgAra is not a derived word. There-
fore only relevant words were studied and the suf-
fixes were obtained only from them.
Table 2: Example derivations of some suffixes
Suffix Root Derivation
Ana laganA lagAna
bAna bAga bAgabAna
gAra yAxa yAxagAra
xAra xukAna xukAnaxAra
ika aXikAra aXikArika
I KuSa KuSI
AI acCA acCAI
Table 3: Rules of few suffixes
Suffix First set rules
bAna noun = noun/adj + bAna
gAra noun = noun/adj + gAra
xAra noun = noun/adj + xAra
ika adj = noun - a + ika
The entire process of obtaining the derivational
suffixes was done manually and was a time consum-
ing process. This process was repeated for adjec-
tives as well. Only those suffixes that participate in
the formation of nouns and adjectives were found.
A total of 22 productive derivational suffixes were
procured. Table 2 shows a few suffixes and their
derivations.
4.2 Derivational Rules
After finding the derivational suffixes, two sets of
derivational rules were developed for each suffix.
The first set explains the formation of the derived
words from their root words. Let us consider the
suffix gAra. This suffix generates nouns from nouns
and adjectives. The rule of this suffix explains the
formation of derivations like yAxagAra (yAxagAra
= yAxa (noun) + gAra) and maxaxagAra (maxaxa-
gAra = maxaxa + gAra). The second set consists of
reverse rules of the first set. The reverse rule for the
previous example is noun/adj = noun - suffix. In this
way, rules were developed for all the 22 derivational
suffixes. These rules form a vital component of our
algorithm. Table 3 contains the derivational rules of
a few suffixes.
4.3 Finding Majority Properties
The majority properties (of derived words of a suf-
fix) are the properties which most of the words ex-
12
hibit. Example: let us consider the derived words
of the suffix vAlA. There are 36 derived words of
the vAlA suffix in the root word dictionary. Some
of these words are adjectives but the majority are
nouns. Hence noun is fixed as the category (major-
ity category) for derived words of this class. Simi-
larly the majority paradigm class of these words is
ladakA. The majority properties of derived words
pertaining to all the 22 suffixes were acquired.
The majority properties of a suffix help us in the
derivational analysis of the unknown derived words
of that suffix. For example: consider the word Gar-
avAlA (housekeeper). Let us assume that it is not
present in the root word dictionary. Therefore the
lexical category, paradigm value and other important
features of this word are not known. But let us as-
sume that this word is a genuine derived word of the
suffix vAlA. So the tool must handle this case. The
majority properties of the vAlA suffix are assigned to
this word. So noun and ladakA are fixed as the cat-
egory and paradigm of this word. Thus the genuine
derived words which are unknown to the analyzer
will be analyzed using the majority properties.
The majority properties of derived words were ob-
tained in two main steps. First, a suffix was consid-
ered. Then all the derived words pertaining to that
suffix were acquired. Only genuine derived words
were taken into consideration. Genuine derivations
were found out using the suffix derivational rules.
Example: let us take the word maxaxagAra (ending
with gAra). First, the root word of this word is re-
trieved using the gAra derivational rule. The root
word according to the rule is maxaxa. This word is
present in the dictionary and it also satisfies the cat-
egory condition of the rule. The word maxaxa is a
noun. Hence the word maxaxagAra is accepted as a
derived word. If the word maxaxa is not found in the
dictionary or if its category is not a noun/adjective,
the word maxaxagAra will be rejected. In this way
all the valid derivations of the suffix were acquired.
This process was repeated for other suffixes as well.
In the second step, the majority properties of the de-
rived words were directly retrieved.
Finally, a suffix table was built using the major-
ity properties of the derived words. The suffix table
contains all the suffixes and their inflectional forms.
Table 4 contains few suffixes and their inflectional
forms. For example: the majority paradigm of de-
Table 4: Few suffixes and their forms
Suffix Suffix-forms
Ana Ana
bAna bAna, bAnoM
gAra gAra, gAroM
xAra xAra, xAroM
ika ika
I I
AI AI
anI anI, aniyAz, aniyoM
rived words of vAlA suffix is ladakA. This implies
that the derived words of this suffix end with vAlA,
vAle and vAloM. Thus the possible inflections of a
suffix can be derived from its majority properties.
This information was stored in a table. The majority
properties and the suffix table play an important role
in the analysis of the unknown words. Their usage in
our algorithm will be described in the later sections.
4.4 Using Wikipedia Data for Confirming
Genuineness
If an invalid word is not analyzed by the inflec-
tional analyzer, there is no need for proceeding to
the derivational analysis of that word. Therefore the
genuineness of a word must be tested before going
for the derivational analysis. The Hindi Wikipedia
was chosen as a resource that enables us to test the
genuineness of a word.
A total of 400k words were extracted from the
Hindi Wikipedia. This data contains many words
which do not exist in Hindi vocabulary. So 220k
proper Hindi words were selected (on the basis of
frequency) from the data and a list containing those
220k words was created. A word will be treated as
a genuine word only when it is present in that list.
This assumption is used by our algorithm. The Wiki
data is used as a standard corpus.
4.5 Algorithm for Derivational Analysis
An algorithm was developed to make use of the
existing inflectional morphological analyzer for
derivational analysis. This algorithm enabled us to
bypass the construction of a derivational analyzer
from the scratch. The majority properties of the
derivations, the Wikipedia data and the suffix-table
are also employed by the algorithm for analyzing un-
13
known derivations.
Figure 1: Algorithm
The input to the algorithm is a word. The out-
put is a combination of the inflectional analysis and
the derivational analysis of the input word. For ex-
ample: if the input word is bAgabAnoM (garden-
ers). First, the algorithm gives the inflectional anal-
ysis of the input word. In this case the word bAga-
bAnoM is a noun, plural in number, etc. Then it
gives the information (category, gender) of the root
word (bAga (garden)) from which the input word is
derived (derivational analysis). So a dual analysis of
the input word is provided.
4.6 Examples
The following 4 examples explain the working of
the algorithm in 4 different cases. These examples
are provided to give a clear picture of the complete
algorithm.
a) Example 1
Input word: pulisavAle (Policemen)
In the step-2, the word is analyzed by the IIIT
inflectional analyzer. In the step 3a.1, the word
pulisavAlA (Policeman) is the normal-form of the
input word. The normal-form is ending (vAlA)
with one of our 22 suffixes. The rule of the suffix
is noun = noun/verb + vAlA. So the root word is
pulisa because pulisavAlA = pulisa + vAlA. The
word pulisa should be a noun or a verb in order
to satisfy the rule. All the conditions are met and
the step 3a.5 becomes the vital final step. This
step gives the information that the final root word
pulisa is a masculine noun and the input word is
also a masculine noun and it is plural in number.
Here the information about the final root word and
the input word is again given using the inflectional
morphological analyzer.
b) Example 2
Input word: kirAexAroM (Tenants)
The IIIT inflectional analyzer cannot analyze this
word. The word kirAexAroM is ending with one
of the forms (xAroM) present in the suffix table.
The normal-form of the input word is obtained by
replacing the suffix form in the input word with
the suffix. Hence the normal-form of the input
word kirAexAroM is kirAexAra. In this way, the
normal-form of the input word is acquired without
the inflectional analyzer. The word kirAexAra is
present in Wiki data and it is ending with one of
the 22 suffixes. The rule of the suffix is noun =
noun/adj + xAra. So the root word is kirAe because
kirAexAra = kirAe + xAra.
c) Example 3
Input word: ladake (Boys)
In the step-2, the word is analyzed by the IIIT
inflectional analyzer. The normal form of the word
is ladakA (boy). The normal-form of the word is not
ending with any of our 22 suffixes. So there is no
derivational analysis of this particular case.
d) Example 4
Input word: ppppwA (invalid word)
The IIIT inflectional analyzer cannot analyze this
word. The word ppppwA is ending with one of
the forms (wA) present in the suffix table. But the
14
normal-form (ppppwA) is not present in Wikipedia.
So there is no derivational analysis for this particular
case.
4.7 Expanding Inflectional Analysis
The algorithm for derivational analysis was also
used for expanding the inflectional analysis of the
analyzer. Consider the second example in the pre-
vious section. The word kirAexAroM is analyzed
by the derivational analyzer even though its root
form (kirAexAra) is not present in the root word dic-
tionary. Words like kirAexAra are genuine deriva-
tions and can be added to the root word dictio-
nary. The addition of such kind of words will extend
the inflectional analysis of the analyzer. For exam-
ple. if the word kirAexAra is added, its forms ki-
rAexAroM and kirAexAra will be automatically ana-
lyzed. This is because the word kirAexAra would be
added along with its features/values like category,
paradigm class, etc.
Therefore all the words which fall into the
example-2 category of the previous section can be
added to the dictionary. All such words must be ob-
tained in order to expand our dictionary. For this
purpose, a Wiki data consisting of 220k Wiki words
was extracted from Wikipedia. Out of these 220k
words, 40k words are ending with our 22 suffixes
and their forms. So the derived words which can be
analyzed by our system are part of this sub-dataset.
Out of 40k words, the derivational analyzer analyzed
5579 words. The inflectional analyzer analyzed only
2362 words out of 40000. So the derivational an-
alyzer analyzed 3217 derived words more than the
inflectional analyzer. So these words were added to
the root word dictionary for expanding the inflec-
tional analysis of the analyzer. The algorithm which
was designed to perform derivational analysis also
inflated the inflectional analysis of the analyzer.
5 Experiments and Results
The performance of our derivational analyzer must
be compared with an existing derivational analyzer.
Since there is no such derivational analyzer, we
compared the performance of our tool with the ex-
isting IIIT inflectional analyzer (or the old morpho-
logical analyzer). The two tools must be tested on
a gold-data (data that does not contain any errors).
For example: let us assume that we have a data of
100 words and their morphological analysis. The
analysis of these 100 words does not contain any
errors and it is a gold-data. Now we must get the
analysis of these 100 words from both the deriva-
tional analyzer and the old morphological analyzer.
Then their analyses must be compared against the
gold-data. This is nothing but directly comparing
the outputs of the derivational analyzer and the old
morphological analyzer. This will help in evaluating
the derivational analyzer. This method of evaluation
will also tell the improvement the derivational ana-
lyzer achieved.
Figure 2: Evaluation Methodology for Morph Analyzers
The figure 2 (Amba P Kulkarni, 2010) explains
our evaluation methodology for morphological ana-
lyzers. Let us continue with the example mentioned
in the previous paragraph. First, we find the anal-
ysis of the 100 words by the old morph analyzer.
We compare its output with the gold output/analysis.
Let there be 50 words which belong to Type-1. It
means the gold analysis and morphological analysis
(by old morph) of 50 words is perfectly equal. Let
there be 10 words which belong to Type-6. It means
15
Table 5: Output analysis of old morph analyzer
Type Number of instances % of Type
Type1 2361 47.2
Type2 763 15.2
Type3 419 8.4
Type4 575 11.5
Type5 599 11.9
Type6 288 5.8
Table 6: Output analysis of derivational analyzer
Type Number of instances % of Type
Type1 2600 51.9
Type2 771 15.4
Type3 418 8.4
Type4 576 11.5
Type5 609 12.2
Type6 31 0.6
that the old morphological analyzer could not an-
alyze 10 words but there is gold analysis of those
words. In this way, each type forms an important
part of the evaluation process. Similarly we evalu-
ate the analysis of the 100 words by the derivational
analyzer. Finally we compare the evaluations of the
old morphological analyzer and our derivational an-
alyzer. This is our evaluation methodology.
So a gold-data consisting of the analysis of 5000
words was taken. The linguistic experts of IIIT Hy-
derabad have built this data and it was acquired from
that institution. The 5000 words were tested on both
the derivational analyzer and the inflectional ana-
lyzer.
Both the analyzers were tested on the gold-data
containing 5000 words. The table 6 proves that
the performance of the new derivational analyzer
is better than the old morphological analyzer. The
old analyzer could not provide any output of 288
words (Type-6) whereas that number is only 31 in-
case of the derivational analyzer. As a result of
this improvement, the overall Type-1 (Perfect output
which is completely matching with the gold output)
of derivational analyzer is nearly 5% more than that
of the old morphological analyzer. The data size is
small (only 5000). A testing on a larger gold-data
will show an even better picture of the improvement
that can be achieved by the derivational analyzer.
6 Conclusions
We presented an algorithm which uses an exist-
ing inflectional analyzer for performing derivational
analysis. The algorithm uses the main principles of
both the Porters stemmer and Krovetz stemmer for
achieving the task. The algorithm achieves decent
precision and recall. It also expands the coverage
of the inflectional analyzer. But it must be incorpo-
rated in applications like machine translators which
use derivational analysis for understanding its real
strengths and limitations.
References
Claudia Gdaniec, Esm Manandise, Michael C. McCord.
2001. Derivational morphology to the rescue: how it
can help resolve unfound words in MT, pp.129?131.
Summit VIII: Machine Translation in the Information
Age, Proceedings, Santiago de Compostela, Spain.
Jesus Vilares, David Cabrero and Miguel A. Alonso.
2001. Applying Productive Derivational Morphology
to Term Indexing of Spanish Texts. In Proceedings of
CICLing.
Vishal Goyal, Gurpreet Singh Lehal. 2008. Hindi Mor-
phological Analyzer and Generator, pp. 1156?1159.
IEEE Computer Society Press, California, USA.
Niraj Aswani, Robert Gaizauskas. 2010. Develop-
ing Morphological Analysers for South Asian Lan-
guages: Experimenting with the Hindi and Gujarati
Languages. In Proceedings of LREC.
Ashwini Vaidya. 2009. Using paradigms for certain
morphological phenomena in Marathi. In Proceedings
of ICON.
Bhuvaneshwari C Melinamath, Shubhagini D. 2011. A
robust Morphological analyzer to capture Kannada
noun Morphology, VOL 13. IPCSIT.
William A. Woods. 2000. Aggressive Morphology for
Robust Lexical Coverage. In Proceedings of ANLC.
Wolfgang Hoeppner. 1982. A multilayered approach to
the handling of word formation. In Proceedings of
COLING.
R. Krovetz. 1993. Viewing morphology as an inference
process. In Proceedings of COLING.
M. F. Porter. 1980. An algorithm for suffix stripping.
Originally published in Program, 14 no. 3, pp 130-137.
Bharati Akshar, Vineet Chaitanya, Rajeev Sangal. 1995.
Natural Language Processing: A Paninian Perspec-
tive. Prentice-Hall of India.
Amba P Kulkarni. 2010. A Report on Evaluation of San-
skrit Tools.
16
