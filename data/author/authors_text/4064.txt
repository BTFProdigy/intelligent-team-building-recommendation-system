Integrating Cross-Lingually Relevant News Articles and
Monolingual Web Documents in Bilingual Lexicon Acquisition
Takehito Utsuro? and Kohei Hino? and Mitsuhiro Kida?
Seiichi Nakagawa? and Satoshi Sato?
?Graduate School of Informatics, Kyoto University, Sakyo-ku, Kyoto, 606-8501, Japan
?Department of Information and Computer Sciences, Toyohashi University of Technology
Tenpaku-cho, Toyohashi, 441?8580, Japan
Abstract
In the framework of bilingual lexicon acquisition
from cross-lingually relevant news articles on the
Web, it is relatively harder to reliably estimate bilin-
gual term correspondences for low frequency terms.
Considering such a situation, this paper proposes to
complementarily use much larger monolingual Web
documents collected by search engines, as a resource
for reliably re-estimating bilingual term correspon-
dences. We experimentally show that, using a suf-
ficient number of monolingual Web documents, it
is quite possible to have reliable estimate of bilin-
gual term correspondences for those low frequency
terms.
1 Introduction
Translation knowledge acquisition from paral-
lel/comparative corpora is one of the most im-
portant research topics of corpus-based MT.
This is because it is necessary for an MT sys-
tem to (semi-)automatically increase its trans-
lation knowledge in order for it to be used in
the real world situation. One limitation of
the corpus-based translation knowledge acquisi-
tion approach is that the techniques of transla-
tion knowledge acquisition heavily rely on avail-
ability of parallel/comparative corpora. How-
ever, the sizes as well as the domain of existing
parallel/comparative corpora are limited, while
it is very expensive to manually collect paral-
lel/comparative corpora. Therefore, it is quite
important to overcome this resource scarcity
bottleneck in corpus-based translation knowl-
edge acquisition research.
In order to solve this problem, we proposed
an approach of taking bilingual news articles
on Web news sites as a source for translation
knowledge acquisition (Utsuro et al, 2003). In
the case of Web news sites in Japan, Japanese
as well as English news articles are updated ev-
eryday. Although most of those bilingual news
articles are not parallel even if they are from
the same site, certain portion of those bilingual
news articles share their contents or at least re-
port quite relevant topics. This characteristic
is quite important for the purpose of transla-
tion knowledge acquisition. Utsuro et al (2003)
showed that it is possible to acquire translation
knowledge of domain specific named entities,
event expressions, and collocational expressions
from the collection of bilingual news articles on
Web news sites.
Based on the results of our previous study,
this paper further examines the correlation of
term frequency and the reliability of bilingual
term correspondences estimated from bilingual
news articles. We show that, for high frequency
terms, it is relatively easier to reliably estimate
bilingual term correspondences. However, for
low frequency terms, it is relatively harder to re-
liably estimate bilingual term correspondences.
Low frequency problem of this type often hap-
pens when a sufficient number of bilingual news
articles are not available at hand.
Considering such a situation, this paper then
proposes to complementarily use much larger
monolingual Web documents collected by search
engines, as a resource for reliably re-estimating
bilingual term correspondences. Those col-
lected monolingual Web documents are re-
garded as comparable corpora. Here, a stan-
dard technique of estimating bilingual term cor-
respondences from comparable corpora is em-
ployed. In the evaluation, we show that, using
a sufficient number of monolingual Web docu-
ments, it is relatively easier to have reliable esti-
mate of bilingual term correspondences. As one
of the most remarkable experimental evalua-
tion results, we further show that, for the terms
which appear infrequently in news articles, the
accuracy of re-estimating bilingual term corre-
spondences does actually improve.
Figure 1: Translation Knowledge Acquisition
from Web News Sites: Overview
2 Estimating Bilingual Term
Correspondences from
Cross-Lingually Relevant News
Articles
2.1 Overview
Figure 1 illustrates the overview of our frame-
work of translation knowledge acquisition from
Web news sites. First, pairs of Japanese and
English news articles which report identical con-
tents or at least closely related contents are re-
trieved. In this cross-lingual retrieval process,
translation knowledge such as a bilingual dic-
tionary and an MT software is used for mea-
suring similarity of Japanese and English arti-
cles across languages. Then, by applying pre-
viously studied techniques of translation knowl-
edge acquisition from parallel/comparative cor-
pora, translation knowledge such as bilingual
term correspondences are acquired.
2.2 Cross-Language Retrieval of Rel-
evant News Articles
This section gives the overview of our frame-
work of cross-language retrieval of relevant news
articles from Web news sites (Utsuro et al,
2003). First, from Web news sites, both
Japanese and English news articles within cer-
tain range of dates are retrieved. Let dJ and
dE denote one of the retrieved Japanese and
English articles, respectively. Then, each En-
glish article dE is translated into a Japanese
document dMTJ by some commercial MT soft-
ware1. Each Japanese article dJ as well as the
Japanese translation dMTJ of each English ar-
ticle are next segmented into word sequences,
and word frequency vectors v(dJ ) and v(dMTJ )
are generated. Then, cosine similarities between
v(dJ ) and v(dMTJ ) are calculated
2 and pairs of
articles dJ and dE which satisfy certain criterion
are considered as candidates for cross-lingually
relevant article pairs.
As we describe in section 4.1, on Web news
sites in Japan, the number of articles up-
dated per day is far greater (about 4 times)
in Japanese than in English. Thus, it is
much easier to find cross-lingually relevant ar-
ticles for each English query article than for
each Japanese query article. Considering this
fact, we estimate bilingual term correspon-
dences from the results of cross-lingually re-
trieving relevant Japanese articles with English
query articles. For each English query article
diE and its Japanese translation d
MTi
J , the set
DiJ of Japanese articles that are within certain
range of dates and are with cosine similarities
higher than or equal to a certain lower bound
Ld is constructed:
DiJ =
{
dJ | cos(v(dMTiJ ), v(dJ )) ? Ld
}
(1)
2.3 Estimating Bilingual Term Cor-
respondences with Pseudo-
Parallel Corpus
This section describes the technique we apply to
the task of estimating bilingual term correspon-
dences from cross-lingually relevant news texts.
Here, we regard cross-lingually relevant news
texts as a pseudo-parallel corpus, to which stan-
dard techniques of estimating bilingual term
correspondences from parallel corpora can be
applied3.
1In this query translation process, we compared an
MT software with a bilingual lexicon. CLIR with query
translation by an MT software performed much better
than that by a bilingual lexicon. In the case of news
articles on Web news sites, it is relatively easier to find
articles in the other language which report closely related
contents, with just a few days difference of report dates.
In such a case, exact query translation by an MT soft-
ware is suitable, because exact translation is expected to
easily match the closely related articles in the other lan-
guage. As we mention in section 3.3, this is opposite to
the situation of monolingual Web documents, where it is
much less expected to find closely related documents in
the other language.
2It is also quite possible to employ weights other than
word frequencies such as tf ?idf and similarity measures
other than cosine measure such as dice or Jaccard coef-
ficients.
3We also applied another technique based on con-
textual vector similarities (Utsuro et al, 2003), which
First, we concatenate constituent Japanese
articles of DiJ into one article D
?i
J , and regard
the article pair diE and D
?i
J as a pseudo-parallel
sentence pair. Next, we collect such pseudo-
parallel sentence pairs and construct a pseudo-
parallel corpus PPCEJ of English and Japanese
articles:
PPCEJ =
{
?diE , D
?i
J ? | D
i
J = ?
}
Then, we apply standard techniques of es-
timating bilingual term correspondences from
parallel corpora (Matsumoto and Utsuro, 2000)
to this pseudo-parallel corpus PPCEJ . First,
from a pseudo-parallel sentence pair diE and D
?i
J ,
we extract monolingual (possibly compound4)
term pair tE and tJ :
r?tE , tJ ? s.t. ?diE?dJ , tE in d
i
E , tJ in dJ , (2)
cos(v(dMTiJ ), v(dJ )) ? Ld
Then, based on the contingency table of co-
occurrence document frequencies of tE and tJ
below, we estimate bilingual term correspon-
dences according to the statistical measures
such as the mutual information, the ?2 statistic,
the dice coefficient, and the log-likelihood ratio.
tJ ?tJ
tE df(tE , tJ ) = a df(tE ,?tJ ) = b
?tE df(?tE , tJ) = c df(?tE ,?tJ) = d
We compare the performance of those four
measures, where the ?2 statistic and the log-
likelihood ratio perform best, the dice coefficient
the second best, and the mutual information the
worst. In section 4.3, we show results with the
?2 statistic as the bilingual term correspondence
corrEJ(tE , tJ):
?2(tE , tJ) =
(ad ? bc)2
(a + b)(a + c)(b + d)(c + d)
3 Re-estimating Bilingual Term
Correspondences using
Monolingual Web Documents
3.1 Overview
This section illustrates the overview of the pro-
cess of re-estimating bilingual term correspon-
dences using monolingual Web documents col-
lected by search engines. Figure 2 gives its
rough idea.
has been well studied in the context of bilingual lexicon
acquisition from comparable corpora. In this method,
we regard cross-lingually relevant texts as a compara-
ble corpus, where bilingual term correspondences are es-
timated in terms of contextual similarities across lan-
guages. This technique is less effective than the one we
describe here (Utsuro et al, 2003).
4In the evaluation of this paper, we restrict English
and Japanese terms t
E
and t
J
to be up to five words
long.
Figure 2: Re-estimating Bilingual Term Corre-
spondences using Monolingual Web Documents:
Overview
Suppose that we have an English term, and
that the problem to solve here is to find its
Japanese translation. As we described in the
previous section and in Figure 1, with a cross-
lingually relevant Japanese and English news
articles database, we can have a certain num-
ber of Japanese translation candidates for the
target English term. Here, for high frequency
terms, it is relatively easier to have reliable
ranking of those Japanese translation candi-
dates. However, for low frequency terms, hav-
ing reliable ranking of those Japanese transla-
tion candidates is difficult. Especially, low fre-
quency problem of this type often happens when
we do not have large enough language resources
(in this case, cross-lingually relevant news arti-
cles).
Considering such a situation, re-estimation of
bilingual term correspondences proceeds as fol-
lows, using much larger monolingual Web doc-
uments sets that are easily accessible through
search engines. First, English pages which
contain the target English term are collected
through an English search engine. In the simi-
lar way, for each Japanese term in the Japanese
translation candidates, Japanese pages which
contain the Japanese term are collected through
a Japanese search engine. Then, texts con-
tained in those English and Japanese pages are
extracted and are regarded as comparable cor-
pora. Here, a standard technique of estimat-
ing bilingual term correspondences from com-
parable corpora (e.g., Fung and Yee (1998) and
Rapp (1999)) is employed. Contextual sim-
ilarity between the target English term and
the Japanese translation candidate is measured
across languages, and all the Japanese transla-
tion candidates are re-ranked according to the
contextual similarities.
3.2 Filtering by Hits of Search En-
gines
Before re-estimating bilingual term correspon-
dences using monolingual Web documents, we
assume there exists certain correlation between
hits of the English term tE and the Japanese
term tJ returned by search engines. Depending
on the hits h(tE) of tE , we restrict the hits h(tJ )
of tJ to be within the range of a lower bound
hL and an upper bound hU :
hL < h(tJ ) ? hU
As search engines, we used AltaVista
(http://www. altavista.com/ for En-
glish, and goo (http://www.goo.ne.jp/) for
Japanese. With a development data set con-
sisting of translation pairs of an English term
and a Japanese term, we manually constructed
the following rules for determining the lower
bound hL and the upper bound hU :
1. 0 < h(tE) ? 100
hL = 0, hU = 10, 000 ? h(tE)
2. 100 < h(tE) ? 20, 000
hL = 0.05 ? h(tE), hU = 1, 000, 000
3. 20, 000 < h(tE)
hL = 1, 000, hU = 50 ? h(tE)
In the experimental evaluation of Section 4.4,
the initial set of Japanese translation candi-
dates consists of 50 terms for each English term,
which are then reduced to on the average 24.8
terms with this filtering.
3.3 Re-estimating Bilingual Term
Correspondences based on Con-
textual Similarity
This section describes how to re-estimate bilin-
gual term correspondences using monolingual
Web documents collected by search engines.
For an English term tE and a Japanese term
tJ , let D(tE) and D(tJ) be the sets of docu-
ments returned by search engines with queries
tE and tJ , respectively. Then, for the English
term tE, translated contextual vector cvtrJ (tE)
is constructed as below: each English sen-
tence sE which contains tE is translated into
Japanese sentence strJ , then the term frequency
vectors5 v(strJ ) of Japanese translation s
tr
J are
5In the term frequency vectores, compound terms are
restricted to be up to five words long both for English
and Japanese.
Table 1: Statistics of # of Days, Articles, and
Article Sizes
total total average # average
# of # of of articles article
days articles per day size (bytes)
Eng 935 23064 24.7 3228.9
Jap 941 96688 102.8 837.7
summed up into the translated contextual vec-
tor cvtrJ(tE):
cvtrJ (tE) =
?
?s
E
in D(t
E
) s.t. t
E
in s
E
v(strJ )
The contextual vector cv(tJ ) for the Japanese
term tJ is also constructed by summing up the
term frequency vectors v(sJ) of each Japanese
sentence sJ which contains tJ :
cv(tJ ) =
?
?s
J
in D(t
J
) s.t. t
J
in s
J
v(sJ)
In the translation of English sentences into
Japanese, we evaluated an MT software and a
bilingual lexicon in terms of the performance of
re-estimation of bilingual term correspondences.
Unlike the situation of cross-lingually relevant
news articles mentioned in Section 2.2, trans-
lation by a bilingual lexicon is more effective
for monolingual Web documents. In the case of
monolingual Web documents, it is much less ex-
pected to find closely related documents in the
other language. In such cases, multiple trans-
lation rather than exact translation by an MT
software is suitable. In Section 4.4, we show
evaluation results with translation by a bilin-
gual lexicon6.
Finally, bilingual term correspondence
corrEJ(tE , tJ) is estimated in terms of co-
sine measure cos(cvtrJ (tE), cv(tJ )) between
contextual vectors cvtrJ (tE) and cv(tJ ).
4 Experimental Evaluation
4.1 Japanese-English Relevant News
Articles on Web News Sites
We collected Japanese and English news articles
from a Web news site. Table 1 shows the total
number of collected articles and the range of
dates of those articles represented as the num-
ber of days. Table 1 also shows the number of
articles updated in one day, and the average ar-
ticle size. The number of Japanese articles up-
dated in one day are far greater (about 4 times)
than that of English articles.
6Eijiro Ver.37, 850,000 entries, http://homepage3.
nifty.com/edp/.
Table 2: # of Japanese/English Articles Pairs with Similarity Values above Lower Bounds
Lower Bound Ld of Articles? Sim w/o 0.3 0.4 0.5
Difference of Dates (days) CLIR ? 2
# of English Articles 23064 6073 2392 701
# of Japanese Articles 96688 12367 3444 882
# of English-Japanese Article Pairs ? 16507 3840 918
Next, for several lower bounds Ld of the
similarity between English and Japanese arti-
cles, Table 2 shows the numbers of English and
Japanese articles as well as article pairs which
satisfy the similarity lower bound. Here, the
difference of dates of English and Japanese arti-
cles is within two days, with which it is guaran-
teed that, if exist, closely related articles in the
other language can be discovered (see Utsuro et
al. (2003) for details). Note that it can happen
that one article has similarity values above the
lower bound against more than one articles in
the other language.
According to our previous study (Utsuro et
al., 2003), cross-lingually relevant news arti-
cles are available in the direction of English-
to-Japanese retrieval for more than half of the
retrieval query English articles. Furthermore,
with the similarity lower bound Ld = 0.3, pre-
cision and recall of cross-language retrieval are
around 30% and 60%, respectively. Therefore,
with the similarity lower bound Ld = 0.3, at
least 1,800 (? 6, 073?0.5?0.6) English articles
have relevant Japanese articles in the results of
cross-language retrieval. Based on this analysis,
the next section gives evaluation results with
the similarity lower bound Ld = 0.3.
4.2 English Term List for Evaluation
For the evaluation of this paper, we first man-
ually select target English terms and their
reference Japanese translation, and examine
whether reference bilingual term correspon-
dences can be estimated by the methods pre-
sented in Sections 2 and 3. Target English terms
are selected by the following procedure.
First, from the whole English articles of Ta-
ble 1, any sequence of more than one words
whose frequency is more than or equal to 10 is
enumerated. This enumeration is easily imple-
mented and efficiently computed by employing
the technique of PrefixSpan (Pei et al, 2001).
Here, certain portion of those word sequences
are appropriate as compound terms, while the
rest are some fragments of a compound term,
or concatenation of those fragments. In or-
der to automatically select candidates for cor-
rect compound terms, we parse those word se-
Figure 3: Accuracy of Estimating Bilingual
Term Correspondences with News Articles
quences by Charniak parser7, and collect noun
phrases which consist of adjectives, nouns, and
present/past participles. For each of those word
sequences, the ?2 statistic against Japanese
translation candidates is calculated, then those
word sequences are sorted in descending order of
their ?2 statistic. Finally, among top 3,000 can-
didates for compound terms, 100 English com-
pound terms are randomly selected for the eval-
uation of this paper. Selected 100 terms satisfy
the following condition: those English terms can
be correctly translated neither by the MT soft-
ware used in Section 2.2, nor by the bilingual
lexicon used in Section 3.3.
4.3 Estimating Bilingual Term Cor-
respondences with News Articles
For the 100 English terms selected in the pre-
vious section, Japanese translation candidates
which satisfy the condition of the formula (2) in
Section 2.3 are collected, and are ranked accord-
ing to the ?2 statistic. Figure 3 plots the rate
of reference Japanese translation being within
top n candidates. In the figure, the plot labeled
as ?full? is the result with the whole articles in
Table 1. In this case, the accuracy of the top
ranked Japanese translation candidate is about
40%, and the rate of reference Japanese trans-
lation within top five candidates is about 75%.
7http://www.cs.brown.edu/people/ec/
Table 3: Statistics of Average Document Frequencies and Number of Days
Document Frequencies of target English Term # of Days
Data Set df(tE) df(tE, tJ) Eng Jap
freq=10, 13.6 days 14.9 9.1 13.6 21.9
freq=10, 20 days 14.9 9.1 21.0 78.7
freq=10, 200 days 14.9 9.1 200 581
freq=70, 600 days 37.4 24.9 600 872
full 53.9 35.6 935 941
On the other hand, other plots labeled as
?Freq=x, y days? are the results when the num-
ber of the news articles is reduced, which are
simulations for estimating bilingual term cor-
respondences for low frequency terms. Here,
the label ?Freq=x, y days? indicates that news
articles used for ?2 statistic estimation is re-
stricted to certain portion of the whole news
articles so that the following condition be satis-
fied: i) co-occurrence document frequency of a
target English term and its reference Japanese
translation is fixed to be x,8 ii) the number of
days be greater than or equal to y. For each
news articles data set, Table 3 shows document
frequencies df(tE) of a target English term tE ,
co-occurrence document frequencies df(tE, tJ )
of tE and its reference Japanese translation tJ ,
and the numbers of days for English as well as
Japanese articles. Those numbers are all aver-
aged over the 100 English terms. The number of
days for Japanese articles could be at maximum
five times larger than that for English articles,
because relevant Japanese articles are retrieved
against a query English article from the dates of
differences within two days (details are in Sec-
tions 2.2 and 4.1).
As can be seen from the plots of Figure 3,
the smaller the news articles data set, the lower
the plot is. Especially, in the case of the small-
est news articles data set, it is clear that re-
liable ranking of Japanese translation candi-
dates is difficult. This is because it is not easy
to discriminate the reference Japanese transla-
tion and the other candidates with statistics ob-
tained from such a small news articles data set.
4.4 Re-estimating Bilingual Term
Correspondences with Monolin-
gual Web Documents
For the 100 target English terms evaluated in
the previous section, this section describes the
result of applying the technique presented in
Section 3.3, i.e., re-estimating bilingual term
8When the co-occurrence document frequency of t
E
and t
J
in the whole news articles is less than x, all the
co-occurring dates are included.
Figure 4: Accuracy of Re-estimating Bilingual
Term Correspondences with Monolingual Web
Documents
correspondences with monolingual Web docu-
ments. For each of the 100 target English
terms, bilingual term correspondences are re-
estimated against candidates of Japanese trans-
lation ranked within top 50 according to the
?2 statistic. Here, as a simulation for terms
that are infrequent in news articles, 50 can-
didate terms for Japanese translation are col-
lected from the smallest data set labeled as
?Freq=10, 13.6 days?. As mentioned in Sec-
tion 3.2, those 50 candidates are reduced to on
the average 24.8 terms with the filtering by hits
of search engines. For each of an English term
tE and a Japanese term tJ , 100 monolingual
documents are collected by search engines9 10.
Figure 4 compares the plots of re-estimation
with monolingual Web documents and estima-
tion by news articles (data set ?Freq=10, 13.6
9In the result of our preliminary evaluation, accuracy
of re-estimating bilingual term correspondences did not
improve even if more than 100 documents were used.
10Alternatively, as the monolingual documents from
which contextual vectors are constructed, we evaluated
each of the short passages listed in the summary pages
returned by search engines, instead of the whole docu-
ments of the URLs listed in the summary pages. The
difference of the performance of bilingual term corre-
spondence estimation is little, while the computational
cost can reduced to almost 5%.
days?). It is clear from this result that mono-
lingual Web documents contribute to improving
the accuracy of estimating bilingual term corre-
spondences for low frequency terms.
One of the major reasons for this improve-
ment is that topics of monolingual Web doc-
uments collected through search engines are
much more diverse than those of news articles.
Such diverse topics help discriminate correct
and incorrect Japanese translation candidates.
For example, suppose that the target English
term tE is ?special anti-terrorism law? and its
reference Japanese translation is ???????
????. In the news articles we used for evalua-
tion, most articles in which tE or tJ appear have
?dispatch of Self-Defense Force for reconstruc-
tion of Iraq? as their topics. Here, Japanese
translation candidates other than ??????
????? that are highly ranked according to
the ?2 statistic are: e.g., ????? (dissolution
of the House of Representatives)? and ?????
??? (assistance for reconstruction of Iraq)?,
which frequently appear in the topic of ?dis-
patch of Self-Defense Force for reconstruction
of Iraq?.
On the other hand, in the case of monolin-
gual Web documents collected through search
engines, it can be expected that topics of docu-
ments may vary according to the query terms.
In the case of the example above, the major
topic is ?dispatch of Self-Defense Force for re-
construction of Iraq? for both of reference terms
tE and tJ , while major topics for other Japanese
translation candidates are: ?issues on Japanese
Diet? for ????? (dissolution of the House
of Representatives)? and ?issues on reconstruc-
tion of Iraq, not only in Japan, but all over the
world? for ???????? (assistance for re-
construction of Iraq)?. Those topics of incor-
rect Japanese translation candidates are differ-
ent from that of the target English term tE, and
their contextual vector similarities against the
target English term tE are relatively low com-
pared with the reference Japanese translation
tJ . Consequently, the reference Japanese trans-
lation tJ is re-ranked higher compared with the
ranking based on news articles.
5 Related Works
In large scale experimental evaluation of bilin-
gual term correspondence estimation from com-
parable corpora, it is difficult to estimate bilin-
gual term correspondences against every possi-
ble pair of terms due to its computational com-
plexity. Previous works on bilingual term cor-
respondence estimation from comparable cor-
pora controlled experimental evaluation in var-
ious ways in order to reduce this computational
complexity. For example, Rapp (1999) filtered
out bilingual term pairs with low monolingual
frequencies (those below 100 times), while Fung
and Yee (1998) restricted candidate bilingual
term pairs to be pairs of the most frequent 118
unknown words. Cao and Li (2002) restricted
candidate bilingual compound term pairs by
consulting a seed bilingual lexicon and requir-
ing their constituent words to be translation
of each other across languages. On the other
hand, in the framework of bilingual term corre-
spondences estimation of this paper, the compu-
tational complexity of enumerating translation
candidates can be easily avoided with the help of
cross-language retrieval of relevant news texts.
Furthermore, unlike Cao and Li (2002), bilin-
gual term correspondences for compound terms
are not restricted to compositional translation.
6 Conclusion
In the framework of bilingual lexicon acquisition
from cross-lingually relevant news articles on
the Web, it has been relatively harder to reliably
estimate bilingual term correspondences for low
frequency terms. This paper proposed to com-
plementarily use much larger monolingual Web
documents collected by search engines, as a re-
source for reliably re-estimating bilingual term
correspondences. We showed that, for the terms
which appear infrequently in news articles, the
accuracy of re-estimating bilingual term corre-
spondences actually improved.
References
Y. Cao and H. Li. 2002. Base noun phrase translation
using Web data and the EM algorithm. In Proc. 19th
COLING, pages 127?133.
P. Fung and L. Y. Yee. 1998. An IR approach for trans-
lating new words from nonparallel, comparable texts.
In Proc. 17th COLING and 36th ACL, pages 414?420.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge
acquisition. In R. Dale, H. Moisl, and H. Somers,
editors, Handbook of Natural Language Processing,
chapter 24, pages 563?610. Marcel Dekker Inc.
J. Pei, J. Han, B. Mortazavi-Asl, and H. Pinto. 2001.
Prefixspan: Mining sequential patterns efficiently by
prefix-projected pattern growth. In Proc. Inter. Conf.
Data Mining, pages 215?224.
R. Rapp. 1999. Automatic identification of word trans-
lations from unrelated English and German corpora.
In Proc. 37th ACL, pages 519?526.
T. Utsuro, T. Horiuchi, T. Hamamoto, K. Hino, and
T. Nakayama. 2003. Effect of cross-language IR in
bilingual lexicon acquisition from comparable cor-
pora. In Proc. 10th EACL, pages 355?362.
Effect of Domain-Specific Corpus
in Compositional Translation Estimation for Technical Terms
Masatsugu Tonoike?, Mitsuhiro Kida?,
Takehito Utsuro?
?Graduate School of Informatics,
Kyoto University
Yoshida-Honmachi, Sakyo-ku,
Kyoto 606-8501 Japan
(tonoike,kida,takagi,sasaki,
utsuro)@pine.kuee.kyoto-u.ac.jp
Toshihiro Takagi?, Yasuhiro Sasaki?,
and Satoshi Sato?
?Graduate School of Engineering,
Nagoya University
Furo-cho, Chikusa-ku,
Nagoya 464-8603 JAPAN
ssato@nuee.nagoya-u.ac.jp
Abstract
This paper studies issues on compiling
a bilingual lexicon for technical terms.
In the task of estimating bilingual term
correspondences of technical terms, it
is usually quite difficult to find an exist-
ing corpus for the domain of such tech-
nical terms. In this paper, we take an
approach of collecting a corpus for the
domain of such technical terms from
the Web. As a method of translation
estimation for technical terms, we pro-
pose a compositional translation esti-
mation technique. Through experimen-
tal evaluation, we show that the do-
main/topic specific corpus contributes
to improving the performance of the
compositional translation estimation.
1 Introduction
This paper studies issues on compiling a bilingual
lexicon for technical terms. So far, several tech-
niques of estimating bilingual term correspon-
dences from a parallel/comparable corpus have
been studied (Matsumoto and Utsuro, 2000). For
example, in the case of estimation from compa-
rable corpora, (Fung and Yee, 1998; Rapp, 1999)
proposed standard techniques of estimating bilin-
gual term correspondences from comparable cor-
pora. In their techniques, contextual similarity
between a source language term and its transla-
tion candidate is measured across the languages,
and all the translation candidates are re-ranked ac-
cording to the contextual similarities. However,
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
Figure 1: Compilation of a Domain/Topic Spe-
cific Bilingual Lexicon
there are limited number of parallel/comparable
corpora that are available for the purpose of es-
timating bilingual term correspondences. There-
fore, even if one wants to apply those existing
techniques to the task of estimating bilingual term
correspondences of technical terms, it is usually
quite difficult to find an existing corpus for the
domain of such technical terms.
Considering such a situation, we take an ap-
proach of collecting a corpus for the domain of
such technical terms from the Web. In this ap-
proach, in order to compile a bilingual lexicon
for technical terms, the following two issues have
to be addressed: collecting technical terms to be
listed as the headwords of a bilingual lexicon, and
estimating translation of those technical terms.
Among those two issues, this paper focuses on the
second issue of translation estimation of technical
terms, and proposes a method for translation es-
timation for technical terms using a domain/topic
specific corpus collected from the Web.
More specifically, the overall framework of
114
compiling a bilingual lexicon from the Web can
be illustrated as in Figure 1. Suppose that we have
sample terms of a specific domain/topic, techni-
cal terms to be listed as the headwords of a bilin-
gual lexicon are collected from the Web by the re-
lated term collection method of (Sato and Sasaki,
2003). Those collected technical terms can be di-
vided into three subsets according to the number
of translation candidates they have in an existing
bilingual lexicon, i.e., the subset XUS of terms for
which the number of translations in the existing
bilingual lexicon is one, the subset XMS of terms
for which the number of translations is more than
one, and the subset YS of terms which are not
found in the existing bilingual lexicon. (Hence-
forth, the union XUS ? XMS is denoted as XS .)
The translation estimation task here is to estimate
translations for the terms of XMS and YS . For the
terms of XMS , it is required to select an appro-
priate translation from the translation candidates
found in the existing bilingual lexicon. For ex-
ample, as a translation of the Japanese technical
term ??????, which belongs to the logic cir-
cuit field, the term ?register? should be selected
but not the term ?regista? of the football field. On
the other hand, for the terms of YS , it is required
to generate and validate translation candidates. In
this paper, for the above two tasks, we use a do-
main/topic specific corpus. Each term of XUS has
the only one translation in the existing bilingual
lexicon. The set of the translations of terms of
XUS is denoted as XUT . Then, the domain/topic
specific corpus is collected from the Web using
the terms in the set XUT . A new bilingual lexicon
is compiled from the result of translation estima-
tion for the terms of XMS and YS , as well as the
translation pairs which consist of the terms of XUS
and their translations found in the existing bilin-
gual lexicon.
For each term of XMS , from the translation can-
didates found in the existing bilingual lexicon, we
select the one which appears most frequently in
the domain/topic specific corpus. The experimen-
tal result of this translation selection process is de-
scribed in Section 5.2.
As a method of translation genera-
tion/validation for technical terms, we propose a
compositional translation estimation technique.
Compositional translation estimation of a term
can be done through the process of composi-
tionally generating translation candidates of the
term by concatenating the translation of the
constituents of the term. Here, those translation
candidates are validated using the domain/topic
specific corpus.
In order to assess the applicability of the com-
positional translation estimation technique, we
randomly pick up 667 Japanese and English tech-
nical term translation pairs of 10 domains from
existing technical term bilingual lexicons. We
then manually examine their compositionality,
and find out that 88% of them are actually com-
positional, which is a very encouraging result.
Based on this assessment, this paper proposes a
method of compositional translation estimation
for technical terms, and through experimental
evaluation, shows that the domain/topic specific
corpus contributes to improving the performance
of compositional translation estimation.
2 Collecting a Domain/Topic Specific
Corpus
When collecting a domain/topic specific corpus of
the language T , for each technical term xUT in the
set XUT , we collect the top 100 pages with search
engine queries including xUT . Our search engine
queries are designed so that documents which de-
scribe the technical term xUT is to be ranked high.
For example, an online glossary is one of such
documents. Note that queries in English and those
in Japanese do not correspond. When collect-
ing a Japanese corpus, the search engine ?goo?1
is used. Specific queries used here are phrases
with topic-marking postpositional particles such
as ?xUT ???, ?xUT ????, ?xUT ??, and an ad-
nominal phrase ?xUT ??, and ?xUT ?. When col-
lecting a English corpus, the search engine ?Ya-
hoo!?2 is used. Specific queries used here are ?xUT
AND what?s?, ?xUT AND glossary?, and ?xUT ?.
3 Compositional Translation Estimation
for Technical Terms
3.1 Overview
An example of compositional translation estima-
tion for the Japanese technical term ??????
1http://www.goo.ne.jp/
2http://www.yahoo.com/
115
? application(1)
? practical(0.3)
? applied(1.6)
? action(1)
? activity(1)
? behavior(1)
? analysis(1)
? diagnosis(1)
? assay(0.3)
? behavior analysis(10)
??Compositional generation 
of translation candidate
? applied behavior analysis(17.6)
? application behavior analysis(11)
? applied behavior diagnosis(1)
??Decompose source term into constituents  
??Translate constituents into target language      process
?? ?? ??a
?? ????b
Generated translation candidates
?(1.6?1?1)+(1.6?10)
? application(1)
? practical(0.3)
? applied(1.6)
Figure 2: Compositional Translation Estimation
for the Japanese Technical Term ????????
?? is shown in Figure 2. First, the Japanese tech-
nical term ???????? is decomposed into
its constituents by consulting an existing bilin-
gual lexicon and retrieving Japanese headwords.3
In this case, the result of this decomposition can
be given as in the cases ?a? and ?b? (in Fig-
ure 2). Then, each constituent is translated into
the target language. A confidence score is as-
signed to the translation of each constituent. Fi-
nally, translation candidates are generated by con-
catenating the translation of those constituents
without changing word order. The confidence
score of translation candidates are defined as the
product of the confidence scores of each con-
stituent. Here, when validating those translation
candidates using the domain/topic specific cor-
pus, those which are not observed in the corpus
are not regarded as candidates.
3.2 Compiling Bilingual Constituents
Lexicons
This section describes how to compile bilingual
constituents lexicons from the translation pairs of
the existing bilingual lexicon Eijiro. The under-
lying idea of augmenting the existing bilingual
lexicon with bilingual constituents lexicons is il-
lustrated with the example of Figure 3. Suppose
that the existing bilingual lexicon does not in-
clude the translation pair ?applied :???, while
it includes many compound translation pairs with
the first English word as ?applied? and the first
3Here, as an existing bilingual lexicon, we use Ei-
jiro(http://www.alc.co.jp/) and bilingual constituents lexi-
cons compiled from the translation pairs of Eijiro (details
to be described in the next section).
 
applied mathematics : ?? ??
applied science : ?? ??
applied robot : ?? ????
.
.
. frequency
? ??
applied : ?? : 40
 
Figure 3: Example of Estimating Bilingual Con-
stituents Translation Pair (Prefix)
Table 1: Numbers of Entries and Translation Pairs
in the Lexicons
lexicon # of entries # of translationEnglish Japanese pairs
Eijiro 1,292,117 1,228,750 1,671,230
P
2
232,716 200,633 258,211
B
P
38,353 38,546 112,586
B
S
22,281 20,627 71,429
Eijiro : existing bilingual lexicon
P
2
: entries of Eijiro with two constituents
in both languages
B
P
: bilingual constituents lexicon (prefix)
B
S
: bilingual constituents lexicon (suffix)
Japanese word ????.4 In such a case, we align
those translation pairs and estimate a bilingual
constituent translation pair, which is to be col-
lected into a bilingual constituents lexicon.
More specifically, from the existing bilingual
lexicon, we first collect translation pairs whose
English terms and Japanese terms consist of two
constituents into another lexicon P
2
. We compile
?bilingual constituents lexicon (prefix)? from the
first constituents of the translation pairs in P
2
and
compile ?bilingual constituents lexicon (suffix)?
from their second constituents. The numbers of
entries in each language and those of translation
pairs in those lexicons are shown in Table 1.
In the result of our assessment, only 27% of the
667 translation pairs mentioned in Section 1 can
be compositionally generated using Eijiro, while
the rate increases up to 49% using both Eijiro and
?bilingual constituents lexicons?.5
4Japanese entries are supposed to be segmented into a
sequence of words by the morphological analyzer JUMAN
(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html)
5In our rough estimation, the upper bound of this rate
is about 80%. Improvement from 49% to 80% could be
achieved by extending the bilingual constituents lexicons
and by introducing constituent reordering rules with preposi-
tions into the process of compositional translation candidate
generation.
116
3.3 Score of Translation Pairs in the
Lexicons
This section introduces a confidence score of
translation pairs in the various lexicons presented
in the previous section. Here, we suppose that
the translation pair ?s, t? of terms s and t is used
when estimating translation from the language of
the term s to that of the term t. First, in this pa-
per, we assume that translation pairs follow cer-
tain preference rules and can be ordered as below:
1. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of two or more constituents.
2. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are high.
3. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of exactly one constituent.
4. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are not
high.
As the definition of the confidence score
q(?s, t?) of a translation pair ?s, t?, in this paper,
we use the following:
q(?s, t?) =
?
?
?
?
?
10
(compo(s)?1) (?s, t? in Eijiro)
log
10
fp(?s, t?) (?s, t? in BP )
log
10
fs(?s, t?) (?s, t? in BS)
(1)
where compo(s) denotes the word (in English) or
morpheme (in Japanese) count of s, fp(?s, t?) the
frequency of ?s, t? as the first constituent in P
2
,
and fs(?s, t?) the frequency of ?s, t? as the second
constituent in P
2
.
6
3.4 Score of Translation Candidates
Suppose that a translation candidate yt is gener-
ated from translation pairs ?s
1
, t
1
?, ? ? ? , ?sn, tn?
by concatenating t
1
, ? ? ? , tn as yt = t1 ? ? ? tn.
Here, in this paper, we define the confidence score
of yt as the product of the confidence scores of the
6It is necessary to empirically examine whether this def-
inition of the confidence score is optimal or not. However,
according to our rough qualitative examination, the results
of the confidence scoring seem stable when without a do-
main/topic specific corpus, even with minor tuning by incor-
porating certain parameters into the score.
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
Figure 4: Experimental Evaluation of Translation
Estimation for Technical Terms with/without the
Domain/Topic Specific Corpus (taken from Fig-
ure 1)
constituent translation pairs ?s
1
, t
1
?, ? ? ? , ?sn, tn?.
Q(yt) =
n
?
i=1
q(?si, ti?) (2)
If a translation candidate is generated from
more than one sequence of translation pairs, the
score of the translation candidate is defined as the
sum of the score of each sequence.
4 Translation Candidate Validation
using a Domain/Topic Specific Corpus
It is not clear whether translation candidates
which are generated by the method described in
Section 3 are valid as English or Japanese terms,
and it is not also clear whether they belong to the
domain/topic. So using a domain/topic specific
corpus collected by the method described in Sec-
tion 2, we examine whether the translation candi-
dates are valid as English or Japanese terms and
whether they belong to the domain/topic. In our
validation method, given a ranked list of trans-
lation candidates, each translation candidate is
checked whether it is observed in the corpus, and
one which is not observed in the corpus is re-
moved from the list.
5 Experiments and Evaluation
5.1 Translation Pairs for Evaluation
In our experimental evaluation, within the frame-
work of compiling a bilingual lexicon for tech-
nical terms, we evaluate the translation estima-
tion part which is indicated with bold line in Fig-
117
Table 2: Number of Translation Pairs for Evaluation
dictionaries categories |X
S
| |Y
S
|
S = English S = Japanese
|X
U
S
| |X
M
S
| C(S) |X
U
S
| |X
M
S
| C(S)
Electromagnetics 58 33 36 22 82% 32 26 76%
McGraw-Hill Electrical engineering 52 45 34 18 67% 25 27 64%
Optics 54 31 42 12 65% 22 32 65%
Iwanami Programming language 55 29 37 18 86% 38 17 100%Programming 53 29 29 24 86% 29 24 79%
Dictionary of (Computer) 100 100 91 9 46% 69 31 56%Computer
Anatomical Terms 100 100 91 9 86% 33 67 39%
Dictionary of Disease 100 100 91 9 74% 53 47 51%
250,000 Chemicals and Drugs 100 100 94 6 58% 74 26 51%
medical terms Physical Science and Statistics 100 100 88 12 64% 58 42 55%
Total 772 667 633 139 68% 433 339 57%
McGraw-Hill : Dictionary of Scientific and Technical Terms
Iwanami : Encyclopedic Dictionary of Computer Science
C(S) : for Y
S
, the rate of including correct translations within the collected domain/topic specific corpus
ure 4. In the evaluation of this paper, we sim-
ply skip the evaluation of the process of collecting
technical terms to be listed as the headwords of a
bilingual lexicon. In order to evaluate the transla-
tion estimation part, from ten categories of exist-
ing Japanese-English technical term dictionaries
listed in Table 2, terms are randomly picked up
for each of the set XUS , XMS , and YS . (Here, as
the terms of YS , these which consist of the only
one word or morpheme are excluded.) As de-
scribed in Section 1, the terms of XUT (the set
of the translations for the terms of XUS ) is used
for collecting a domain/topic specific corpus from
the Web. Translation estimation evaluation is to
be done against the set XMS and YS . For each of
the ten categories, Table 2 shows the sizes of XUS ,
XMS and YS , and for YS , the rate of including cor-
rect translation within the collected domain/topic
specific corpus, respectively.
5.2 Translation Selection from Existing
Bilingual Lexicon
For the terms of XMS , the selected translations are
judged by a human. The correct rates are 69%
from English to Japanese on the average and 75%
from Japanese to English on the average.
5.3 Compositional Translation Estimation
for Technical Terms without the
Domain/Topic Specific Corpus
Without the domain specific corpus, the cor-
rect rate of the first ranked translation candidate
is 19% on the average (both from English to
Japanese and from Japanese to English). The
rate of including correct candidate within top 10
is 40% from English to Japanese and 43% from
Japanese to English on the average. The rate of
compositionally generating correct translation us-
ing both Eijiro and the bilingual constituents lex-
icons (n = ?) is about 50% on the average (both
from English to Japanese and from Japanese to
English).
5.4 Compositional Translation Estimation
for Technical Terms with the
Domain/Topic Specific Corpus
With domain specific corpus, on the average, the
correct rate of the first ranked translation candi-
date improved by 8% from English to Japanese
and by 2% from Japanese to English. However,
the rate of including correct candidate within top
10 decreased by 7% from English to Japanese,
and by 14% from Japanese to English. This is be-
cause correct translation does not exist in the cor-
pus for 32% (from English to Japanese) or 43%
(from Japanese to English) of the 667 translation
pairs for evaluation.
For about 35% (from English to Japanese) or
30% (from Japanese to English) of the 667 trans-
lation pairs for evaluation, correct translation does
exist in the corpus and can be generated through
the compositional translation estimation process.
For those 35% or 30% translation pairs, Fig-
ure 5 compares the correct rate of the first ranked
translation pairs between with/without the do-
main/topic specific corpus. The correct rates in-
crease by 34?37% with the domain/topic specific
corpus. This result supports the claim that the do-
118
??
???
???
???
???
???
???
???
???
???
????
???
???
??
??
??
???
?
???
???
???
???
??
???
???
??
??
???
?
??
??
???
??
??
???
??
??
??
??
??
???
??
??
??
??
???
?
??
???
??
??
???
???
?
???
??
??
??
??
???
???
??
???
???
?
??
??
???
???
???
??
?
??
???
??
??
??
??
??
??
??
??
???
???
??
??
??
??
??
??
??
??
???
?
??
??
??
??
??
??
?
??????????????
???????????
(a) English to Japanese
??
???
???
???
???
???
???
???
???
???
????
???
???
??
??
??
???
?
???
???
???
???
??
???
???
??
??
???
?
??
??
???
??
??
???
??
??
??
??
??
???
??
??
??
??
???
?
??
???
??
??
???
???
?
???
??
??
??
??
???
???
??
???
???
?
??
??
???
???
???
??
?
??
???
??
??
??
??
??
??
??
??
???
???
??
??
??
??
??
??
??
??
???
?
??
??
??
??
??
??
?
??????????????
???????????
(b) Japanese to English
Figure 5: Evaluation against the Translation Pairs
whose Correct Translation Exist in the Corpus
and can be Generated Compositionally
main/topic specific corpus is effective in transla-
tion estimation of technical terms.
6 Related Works
As a related work, (Fujii and Ishikawa, 2001)
proposed a technique of compositional estima-
tion of bilingual term correspondences for the
purpose of cross-language information retrieval.
In (Fujii and Ishikawa, 2001), a bilingual con-
stituents lexicon is compiled from the translation
pairs included in an existing bilingual lexicon in
the same way as our proposed method. One of the
major differences of the technique of (Fujii and
Ishikawa, 2001) and the one proposed in this pa-
per is that in (Fujii and Ishikawa, 2001), instead of
the domain/topic specific corpus, they use a cor-
pus of the collection of the technical papers, each
of which is published by one of the 65 Japanese
associations for various technical domains. An-
other important difference is that in (Fujii and
Ishikawa, 2001), they evaluate only the perfor-
mance of cross-language information retrieval but
not that of translation estimation.
(Cao and Li, 2002) proposed a method of com-
positional translation estimation for compounds.
In the proposed method of (Cao and Li, 2002),
translation candidates of a term are composition-
ally generated by concatenating the translation
of the constituents of the term and are re-ranked
by measuring contextual similarity against the
source language term. One of the major differ-
ences of the technique of (Cao and Li, 2002) and
the one proposed in this paper is that in (Cao and
Li, 2002), they do not use the domain/topic spe-
cific corpus.
7 Conclusion
This paper proposed a method of compositional
translation estimation for technical terms using
the domain/topic specific corpus, and through
the experimental evaluation, showed that the do-
main/topic specific corpus contributes to improv-
ing the performance of compositional translation
estimation.
Future works include the followings: first, in
order to improve the proposed method with re-
spect to its coverage, for example, it is desir-
able to extend the bilingual constituents lexicons
and to introduce constituent reordering rules with
prepositions into the process of compositional
translation candidate generation. Second, we are
planning to introduce a mechanism of re-ranking
translation candidates based on the frequencies of
technical terms in the domain/topic specific cor-
pus.
References
Y. Cao and H. Li. 2002. Base noun phrase translation using
Web data and the EM algorithm. In Proc. 19th COLING,
pages 127?133.
Atsushi Fujii and Tetsuya Ishikawa. 2001. Japanese/english
cross-language information retrieval: Exploration of
query translation and transliteration. Computers and the
Humanities, 35(4):389?420.
P. Fung and L. Y. Yee. 1998. An IR approach for translating
new words from nonparallel, comparable texts. In Proc.
17th COLING and 36th ACL, pages 414?420.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge ac-
quisition. In R. Dale, H. Moisl, and H. Somers, editors,
Handbook of Natural Language Processing, chapter 24,
pages 563?610. Marcel Dekker Inc.
R. Rapp. 1999. Automatic identification of word transla-
tions from unrelated English and German corpora. In
Proc. 37th ACL, pages 519?526.
S. Sato and Y. Sasaki. 2003. Automatic collection of related
terms from the web. In Proc. 41st ACL, pages 121?124.
119
A Comparative Study on Compositional Translation Estimation
using a Domain/Topic-Specific Corpus collected from the Web
Masatsugu Tonoike?, Mitsuhiro Kida?, Toshihiro Takagi?, Yasuhiro Sasaki?,
Takehito Utsuro??, Satoshi Sato? ? ?
?Graduate School of Informatics, Kyoto University
Yoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan
??Graduate School of Systems and Information Engineering, University of Tsukuba
1-1-1, Tennodai, Tsukuba, 305-8573, Japan
? ? ?Graduate School of Engineering, Nagoya University
Furo-cho, Chikusa-ku, Nagoya 464-8603, Japan
Abstract
This paper studies issues related to the
compilation of a bilingual lexicon for tech-
nical terms. In the task of estimating bilin-
gual term correspondences of technical
terms, it is usually rather difficult to find
an existing corpus for the domain of such
technical terms. In this paper, we adopt
an approach of collecting a corpus for the
domain of such technical terms from the
Web. As a method of translation esti-
mation for technical terms, we employ a
compositional translation estimation tech-
nique. This paper focuses on quantita-
tively comparing variations of the compo-
nents in the scoring functions of composi-
tional translation estimation. Through ex-
perimental evaluation, we show that the
domain/topic-specific corpus contributes
toward improving the performance of the
compositional translation estimation.
1 Introduction
This paper studies issues related to the compilation
of a bilingual lexicon for technical terms. Thus
far, several techniques of estimating bilingual term
correspondences from a parallel/comparable cor-
pus have been studied (Matsumoto and Utsuro,
2000). For example, in the case of estimation from
comparable corpora, (Fung and Yee, 1998; Rapp,
1999) proposed standard techniques of estimating
bilingual term correspondences from comparable
corpora. In their techniques, contextual similarity
between a source language term and its translation
candidate is measured across the languages, and
all the translation candidates are re-ranked accord-
ing to their contextual similarities. However, there
are limited number of parallel/comparable corpora
that are available for the purpose of estimating
bilingual term correspondences. Therefore, even
if one wants to apply those existing techniques to
the task of estimating bilingual term correspon-
dences of technical terms, it is usually rather dif-
ficult to find an existing corpus for the domain of
such technical terms.
On the other hand, compositional translation es-
timation techniques that use a monolingual corpus
(Fujii and Ishikawa, 2001; Tanaka and Baldwin,
2003) are more practical. It is because collecting a
monolingual corpus is less expensive than collect-
ing a parallel/comparable corpus. Translation can-
didates of a term can be compositionally generated
by concatenating the translation of the constituents
of the term. Here, the generated translation candi-
dates are validated using the domain/topic-specific
corpus.
In order to assess the applicability of the com-
positional translation estimation technique, we
randomly pick up 667 Japanese and English tech-
nical term translation pairs of 10 domains from ex-
isting technical term bilingual lexicons. We then
manually examine their compositionality, and find
out that 88% of them are actually compositional,
which is a very encouraging result.
But still, it is expensive to collect a
domain/topic-specific corpus. Here, we adopt
an approach of using the Web, since documents
of various domains/topics are available on the
Web. When validating translation candidates
using the Web, roughly speaking, there exist the
following two approaches. In the first approach,
translation candidates are validated through
the search engine (Cao and Li, 2002). In the
second approach, a domain/topic-specific corpus
is collected from the Web in advance and fixed
11
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
web
(language T )
web
(language T )
Figure 1: Compilation of a Domain/Topic-
Specific Bilingual Lexicon using the Web
before translation estimation, then generated
translation candidates are validated against the
domain/topic-specific corpus (Tonoike et al,
2005). The first approach is preferable in terms of
coverage, while the second is preferable in terms
of computational efficiency. This paper mainly
focuses on quantitatively comparing the two
approaches in terms of coverage and precision of
compositional translation estimation.
More specifically, in compositional translation
estimation, we decompose the scoring function
of a translation candidate into two components:
bilingual lexicon score and corpus score. In this
paper, we examine variants for those components
and define 9 types of scoring functions in total.
Regarding the above mentioned two approaches
to validating translation candidates using the Web,
the experimental result shows that the second
approach outperforms the first when the correct
translation does exist in the corpus. Furthermore,
we examine the methods that combine two scor-
ing functions based on their agreement. The ex-
perimental result shows that it is quite possible to
achieve precision much higher than those of single
scoring functions.
2 Overall framework
The overall framework of compiling a bilingual
lexicon from the Web is illustrated as in Figure 1.
Suppose that we have sample terms of a specific
domain/topic, then the technical terms that are to
be listed as the headwords of a bilingual lexicon
are collected from the Web by the related term col-
lection method of (Sato and Sasaki, 2003). These
collected technical terms can be divided into three
subsets depending on the number of translation
candidates present in an existing bilingual lexicon,
i.e., the subset XUS of terms for which the number
of translations in the existing bilingual lexicon is
one, the subset XMS of terms for which the number
of translations is more than one, and the subset YS
of terms that are not found in the existing bilingual
lexicon (henceforth, the union XUS ? XMS will be
denoted as XS). Here, the translation estimation
task here is to estimate translations for the terms
of the subsets XMS and YS . A new bilingual lex-
icon is compiled from the result of the translation
estimation for the terms of the subsets XMS and
YS as well as the translation pairs that consist of
the terms of the subset XUS and their translations
found in the existing bilingual lexicon.
For the terms of the subset XMS , it is required
that an appropriate translation is selected from
among the translation candidates found in the ex-
isting bilingual lexicon. For example, as a trans-
lation of the Japanese technical term ?????,?
which belongs to the logic circuit domain, the term
?register? should be selected but not the term ?reg-
ista? of the football domain. On the other hand, for
the terms of YS , it is required that the translation
candidates are generated and validated. In this pa-
per, out of the above two tasks, we focus on the
latter of translation candidate generation and val-
idation using the Web. As we introduced in the
previous section, here we experimentally compare
the two approaches to validating translation candi-
dates. The first approach directly uses the search
engine, while the second uses the domain/topic-
specific corpus, which is collected in advance from
the Web. Here, in the second approach, we use the
term of XUS , which has only one translation in the
existing bilingual lexicon. The set of translations
of the terms of the subset XUS is denoted as XUT .
Then, in the second approach, the domain/topic-
specific corpus is collected from the Web using the
terms of the set XUT .
3 Compositional Translation Estimation
for Technical Terms
3.1 Overview
An example of compositional translation estima-
tion for the Japanese technical term ??????
?? is illustrated in Figure 2. First, the Japanese
technical term ???????? is decomposed
into its constituents by consulting an existing
bilingual lexicon and retrieving Japanese head-
12
? application(1)
? practical(0.3)
? applied(1.6)
? action(1)
? activity(1)
? behavior(1)
? analysis(1)
? diagnosis(1)
? assay(0.3)
? behavior analysis(10)
??Compositional generation 
of translation candidate
? applied behavior analysis(17.6)
? application behavior analysis(11)
? applied behavior diagnosis(1)
??Decompose source term into constituents  
??Translate constituents into target language      process
?? ?? ??a
?? ????b
Generated translation candidates
?(1.6?1?1)+(1.6?10)
? application(1)
? practical(0.3)
? applied(1.6)
Figure 2: Compositional Translation Estimation
for the Japanese Technical Term ????????
words.1 In this case, the result of this decompo-
sition can be given as in the cases ?a? and ?b?
(in Figure 2). Then, each constituent is translated
into the target language. A confidence score is as-
signed to the translation of each constituent. Fi-
nally, translation candidates are generated by con-
catenating the translation of those constituents ac-
cording to word ordering rules considering prepo-
sitional phrase construction.
3.2 Collecting a Domain/Topic-Specific
Corpus
When collecting a domain/topic-specific corpus of
the language T , for each technical term xUT in the
set XUT , we collect the top 100 pages obtained
from search engine queries that include the term
xUT . Our search engine queries are designed such
that documents that describe the technical term xUT
are ranked high. For example, an online glossary
is one such document. When collecting a Japanese
corpus, the search engine ?goo?2 is used. The spe-
cific queries that are used in this search engine
are phrases with topic-marking postpositional par-
ticles such as ?xUT ??,? ?xUT ???,? ?xUT ?,?
and an adnominal phrase ?xUT ?,? and ?xUT .?
3.3 Translation Estimation
3.3.1 Compiling Bilingual Constituents
Lexicons
This section describes how to compile bilingual
constituents lexicons from the translation pairs of
1Here, as an existing bilingual lexicon, we use Ei-
jiro(http://www.alc.co.jp/) and bilingual constituents lexicons
compiled from the translation pairs of Eijiro (details to be de-
scribed in the next section).
2http://www.goo.ne.jp/
 
applied mathematics : ?? ??
applied science : ?? ??
applied robot : ?? ????
.
.
. frequency
? ??
applied : ?? : 40
 
Figure 3: Example of Estimating Bilingual Con-
stituents Translation Pair (Prefix)
the existing bilingual lexicon Eijiro. The under-
lying idea of augmenting the existing bilingual
lexicon with bilingual constituents lexicons is il-
lustrated in Figure 3. Suppose that the existing
bilingual lexicon does not include the translation
pair ?applied : ??,? while it includes many
compound translation pairs with the first English
word ?applied? and the first Japanese word ??
?.?3 In such a case, we align those translation
pairs and estimate a bilingual constituent transla-
tion pair which is to be collected into a bilingual
constituents lexicon.
More specifically, from the existing bilingual
lexicon, we first collect translation pairs whose
English terms and Japanese terms consist of two
constituents into another lexicon P
2
. We com-
pile the ?bilingual constituents lexicon (prefix)?
from the first constituents of the translation pairs
in P
2
and compile the ?bilingual constituents lex-
icon (suffix)? from their second constituents. The
number of entries in each language and those of
the translation pairs in these lexicons are shown in
Table 1.
The result of our assessment reveals that only
48% of the 667 translation pairs mentioned in Sec-
tion 1 can be compositionally generated by using
Eijiro, while the rate increases up to 69% using
both Eijiro and ?bilingual constituents lexicons.?4
3.3.2 Score of Translation Candidates
This section gives the definition of the scores
of a translation candidate in compositional trans-
lation estimation.
First, let ys be a technical term whose transla-
tion is to be estimated. We assume that ys is de-
3Japanese entries are supposed to be segmented into a
sequence of words by the morphological analyzer JUMAN
(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html).
4In our rough estimation, the upper bound of this rate
is approximately 80%. An improvement from 69% to 80%
could be achieved by extending the bilingual constituents lex-
icons.
13
Table 1: Numbers of Entries and Translation Pairs
in the Lexicons
lexicon # of entries # of translationEnglish Japanese pairs
Eijiro 1,292,117 1,228,750 1,671,230
P
2
217,861 186,823 235,979
B
P
37,090 34,048 95,568
B
S
20,315 19,345 62,419
B 48,000 42,796 147,848
Eijiro : existing bilingual lexicon
P
2
: entries of Eijiro with two constituents
in both languages
B
P
: bilingual constituents lexicon (prefix)
B
S
: bilingual constituents lexicon (suffix)
B : bilingual constituents lexicon (merged)
composed into their constituents as below:
ys = s1, s2, ? ? ? , sn (1)
where each si is a single word or a sequence of
words.5 For ys, we denote a generated translation
candidate as yt.
yt = t1, t2, ? ? ? , tn (2)
where each ti is a translation of si. Then the trans-
lation pair ?ys, yt? is represented as follows.
?ys, yt? = ?s1, t1?, ?s2, t2?, ? ? ? , ?sn, tn? (3)
The score of a generated translation candidate is
defined as the product of a bilingual lexicon score
and a corpus score as follows.
Q(ys, yt) = Qdict(ys, yt) ? Qcoprus(yt) (4)
Bilingual lexicon score measures appropriateness
of correspondence of ys and yt. Corpus score
measures appropriateness of the translation candi-
date yt based on the target language corpus. If a
translation candidate is generated from more than
one sequence of translation pairs, the score of the
translation candidate is defined as the sum of the
score of each sequence.
Bilingual Lexicon Score
In this paper, we compare two types of bilin-
gual lexicon scores. Both scores are defined as the
product of scores of translation pairs included in
the lexicons presented in the previous section as
follows.
5Eijiro has both single word entries and compound word
entries.
? Frequency-Length
Qdict(ys, yt) =
n
?
i=1
q(?si, ti?) (5)
The first type of bilingual lexicon scores is re-
ferred to as ?Frequency-Length.? This score is
based on the length of translation pairs and the fre-
quencies of translation pairs in the bilingual con-
stituent lexicons (prefix,suffix) BP , BS in Table 1.
In this paper, we first assume that the translation
pairs follow certain preference rules and that they
can be ordered as below:
1. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of two or more constituents.
2. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are high.
3. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of exactly one constituent.
4. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are not
high.
As the definition of the confidence score
q(?s, t?) of a translation pair ?s, t?, we use the fol-
lowing:
q(?s, t?) =
?
?
?
10
(compo(s)?1) (?s, t? in Eijiro)
log
10
fp(?s, t?) (?s, t? in BP )
log
10
fs(?s, t?) (?s, t? in BS)
(6)
, where compo(s) denotes the word count of s,
fp(?s, t?) represents the frequency of ?s, t? as the
first constituent in P
2
, and fs(?s, t?) represents the
frequency of ?s, t? as the second constituent in P
2
.
? Probability
Qdict(ys, yt) =
n
?
i=1
P (si|ti) (7)
The second type of bilingual lexicon scores is re-
ferred to as ?Probability.? This score is calcu-
lated as the product of the conditional probabili-
ties P (si|ti). P (s|t) is calculated using bilingual
lexicons in Table 1.
P (s|t) =
fprob(?s, t?)
?
s
j
fprob(?sj , t?)
(8)
14
Table 2: 9 Scoring Functions of Translation Candidates and their Components
bilingual lexicon score corpus score corpus
score ID freq-length probability probability frequency occurrence off-line on-line
(search engine)
A prune/final prune/final o
B prune/final prune/final o
C prune/final prune/final o
D prune/final prune o
E prune/final
F prune/final final prune o
G prune/final prune/final o
H prune/final final o
I prune/final final o
fprob(?s, t?) denotes the frequency of the transla-
tion pair ?s, t? in the bilingual lexicons as follows:
fprob(?s, t?) =
{
10 (?s, t? in Eijiro)
fB(?s, t?) (?s, t? in B)
(9)
Note that the frequency of a translation pair in Ei-
jiro is regarded as 106 and fB(?s, t?) denotes the
frequency of the translation pair ?s, t? in the bilin-
gual constituent lexicon B.
Corpus Score
We evaluate three types of corpus scores as fol-
lows.
? Probability: the occurrence probability of yt
estimated by the following bi-gram model
Qcorpus(yt) = P (t1) ?
n
?
i=1
P (ti+1|ti) (10)
? Frequency: the frequency of a translation
candidate in a target language corpus
Qcorpus(yt) = freq(yt) (11)
? Occurrence: whether a translation candidate
occurs in a target language corpus or not
Qcorpus(yt) =
?
?
?
?
?
1 yt occurs in a corpus
0 yt does not occur
in a corpus
(12)
6It is necessary to empirically examine whether or not the
definition of the frequency of a translation pair in Eijiro is
appropriate.
Variation of the total scoring functions
As shown in Table 2, in this paper, we examine
the 9 combinations of the bilingual lexicon scores
and the corpus scores. In the table, ?prune? indi-
cates that the score is used for ranking and pruning
sub-sequences of generated translation candidates
in the course of generating translation candidates
using a dynamic programming algorithm. ?Final?
indicates that the score is used for ranking the fi-
nal outputs of generating translation candidates.
In the column ?corpus?, ?off-line? indicates that
a domain/topic-specific corpus is collected from
the Web in advance and then generated transla-
tion candidates are validated against this corpus.
?On-line? indicates that translation candidates are
directly validated through the search engine.
Roughly speaking, the scoring function ?A? cor-
responds to a variant of the model proposed by
(Fujii and Ishikawa, 2001). The scoring func-
tion ?D? is a variant of the model proposed by
(Tonoike et al, 2005) and ?E? corresponds to the
bilingual lexicon score of the scoring function ?D?.
The scoring function ?I? is intended to evaluate the
approach proposed in (Cao and Li, 2002).
3.3.3 Combining Two Scoring Functions
based on their Agreement
In this section, we examine the method that
combines two scoring functions based on their
agreement. The two scoring functions are selected
out of the 9 functions introduced in the previous
section. In this method, first, confidence of trans-
lation candidates of a technical term are measured
by the two scoring functions. Then, if the first
ranked translation candidates of both scoring func-
tions agree, this method outputs the agreed trans-
lation candidate. The purpose of introducing this
method is to prefer precision to recall.
15
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
domain/topic
specific
corpus
(language T )
validating
translation
candidates
web
(language T )
web
(language T )
Figure 4: Experimental Evaluation of Translation
Estimation for Technical Terms with/without the
Domain/Topic-Specific Corpus (taken from Fig-
ure 1)
4 Experiments and Evaluation
4.1 Translation Pairs for Evaluation
In our experimental evaluation, within the frame-
work of compiling a bilingual lexicon for techni-
cal terms, we evaluate the translation estimation
portion that is indicated by the bold line in Fig-
ure 4. In this paper, we simply omit the evalua-
tion of the process of collecting technical terms to
be listed as the headwords of a bilingual lexicon.
In order to evaluate the translation estimation por-
tion, terms are randomly selected from the 10 cate-
gories of existing Japanese-English technical term
dictionaries listed in Table 3, for each of the sub-
sets XUS and YS (here, the terms of YS that consist
of only one word or morpheme are excluded). As
described in Section 1, the terms of the set XUT (the
set of translations for the terms of the subset XUS )
is used for collecting a domain/topic-specific cor-
pus from the Web. As shown in Table 3, size of the
collected corpora is 48MB on the average. Trans-
lation estimation evaluation is to be conducted for
the subset YS . For each of the 10 categories, Ta-
ble 3 shows the sizes of the subsets XUS and YS ,
and the rate of including correct translation within
the collected domain/topic-specific corpus for YS .
In the following, we show the evaluation results
with the source language S as English and the tar-
get language T as Japanese.
4.2 Evaluation of single scoring functions
This section gives the results of evaluating single
scoring functions A ? I listed in Table 2.
Table 4 shows three types of experimental re-
sults. The column ?the whole set YS? shows the
results against the whole set YS . The column
?generatable? shows the results against the trans-
lation pairs in YS that can be generated through
the compositional translation estimation process.
69% of the terms in ?the whole set YS? belongs
to the set ?generatable?. The column ?gene.-exist?
shows the result against the source terms whose
correct translations do exist in the corpus and that
can be generated through the compositional trans-
lation estimation process. 50% of the terms in ?the
whole set YS? belongs to the set ?gene.-exist?. The
column ?top 1? shows the correct rate of the first
ranked translation candidate. The column ?top 10?
shows the rate of including the correct candidate
within top 10.
First, in order to evaluate the effectiveness of
the approach of validating translation candidates
by using a target language corpus, we compare the
scoring functions ?D? and ?E?. The difference be-
tween them is whether or not they use a corpus
score. The results for the whole set YS show that
using a corpus score, the precision improves from
33.9% to 43.0%. This result supports the effec-
tiveness of the approach of validating translation
candidates using a target language corpus.
As can be seen from these results for the whole
set YS , the correct rate of the scoring function ?I?
that directly uses the web search engine in the cal-
culation of its corpus score is higher than those
of other scoring functions that use the collected
domain/topic-specific corpus. This is because,
for the whole set YS , the rate of including cor-
rect translation within the collected domain/topic-
specific corpus is 72% on the average, which is
not very high. On the other hand, the results of the
column ?gene.-exist? show that if the correct trans-
lation does exist in the corpus, most of the scor-
ing functions other than ?I? can achieve precisions
higher than that of the scoring function ?I?. This
result supports the effectiveness of the approach
of collecting a domain/topic-specific corpus from
the Web in advance and then validating generated
translation candidates against this corpus.
4.3 Evaluation of combining two scoring
functions based on their agreement
The result of evaluating the method that combines
two scoring functions based on their agreement is
shown in Table 5. This result indicates that com-
binations of scoring functions with ?off-line?/?on-
16
Table 3: Number of Translation Pairs for Evaluation (S=English)
dictionaries categories |Y
S
| |X
U
S
| corpus size C(S)
Electromagnetics 33 36 28MB 85%
McGraw-Hill Electrical engineering 45 34 21MB 71%
Optics 31 42 37MB 65%
Iwanami Programming language 29 37 34MB 93%Programming 29 29 33MB 97%
Dictionary of (Computer) 100 91 67MB 51%Computer
Anatomical Terms 100 91 73MB 86%
Dictionary of Disease 100 91 83MB 77%
250,000 Chemicals and Drugs 100 94 54MB 60%
medical terms Physical Science and Statistics 100 88 56MB 68%
Total 667 633 482MB 72%
McGraw-Hill : Dictionary of Scientific and Technical Terms
Iwanami : Encyclopedic Dictionary of Computer Science
C(S) : for Y
S
, the rate of including correct translations within the collected domain/topic-specific corpus
Table 4: Result of Evaluating single Scoring Functions
the whole set Y
S
(667 terms?100%) generatable (458 terms?69%) gene.-exist (333 terms?50%)
ID top 1 top 10 top 1 top 10 top 1 top 10
A 43.8% 52.9% 63.8% 77.1% 82.0% 98.5%
B 42.9% 50.7% 62.4% 73.8% 83.8% 99.4%
C 43.0% 58.0% 62.7% 84.5% 75.1% 94.6%
D 43.0% 47.4% 62.7% 69.0% 85.9% 94.6%
E 33.9% 57.3% 49.3% 83.4% 51.1% 84.1%
F 40.2% 47.4% 58.5% 69.0% 80.2% 94.6%
G 39.1% 46.8% 57.0% 68.1% 78.1% 93.4%
H 43.8% 57.3% 63.8% 83.4% 73.6% 84.1%
I 49.8% 57.3% 72.5% 83.4% 74.8% 84.1%
Table 5: Result of combining two scoring func-
tions based on their agreement
corpus combination precision recall F
?=1
A & I 88.0% 27.6% 0.420
off-line/ D & I 86.0% 29.5% 0.440
on-line F & I 85.1% 29.1% 0.434
H & I 58.7% 37.5% 0.457
A & H 86.0% 30.4% 0.450
F & H 80.6% 33.7% 0.476
off-line/ D & H 80.4% 32.7% 0.465
off-line A & D 79.0% 32.1% 0.456
A & F 74.6% 33.0% 0.457
D & F 68.2% 35.7% 0.469
line? corpus tend to achieve higher precisions than
those with ?off-line?/?off-line? corpus. This result
also shows that it is quite possible to achieve high
precisions even by combining scoring functions
with ?off-line?/?off-line? corpus (the pair ?A? and
?H?). Here, the two scoring functions ?A? and ?H?
are the one with frequency-based scoring func-
tions and that with probability-based scoring func-
tions, and hence, have quite different nature in the
design of their scoring functions.
5 Related Works
As a related work, (Fujii and Ishikawa, 2001) pro-
posed a technique for compositional estimation of
bilingual term correspondences for the purpose of
cross-language information retrieval. One of the
major differences between the technique of (Fu-
jii and Ishikawa, 2001) and the one proposed in
this paper is that in (Fujii and Ishikawa, 2001), in-
stead of a domain/topic-specific corpus, they use a
corpus containing the collection of technical pa-
pers, each of which is published by one of the
65 Japanese associations for various technical do-
mains. Another significant difference is that in
(Fujii and Ishikawa, 2001), they evaluate only the
performance of the cross-language information re-
trieval and not that of translation estimation.
(Cao and Li, 2002) also proposed a method
of compositional translation estimation for com-
pounds. In the method of (Cao and Li, 2002), the
translation candidates of a term are composition-
ally generated by concatenating the translation of
the constituents of the term and are validated di-
rectly through the search engine. In this paper,
we evaluate the approach proposed in (Cao and
Li, 2002) by introducing a total scoring function
17
that is based on validating translation candidates
directly through the search engine.
6 Conclusion
This paper studied issues related to the compila-
tion a bilingual lexicon for technical terms. In
the task of estimating bilingual term correspon-
dences of technical terms, it is usually rather dif-
ficult to find an existing corpus for the domain
of such technical terms. In this paper, we adopt
an approach of collecting a corpus for the do-
main of such technical terms from the Web. As
a method of translation estimation for technical
terms, we employed a compositional translation
estimation technique. This paper focused on quan-
titatively comparing variations of the components
in the scoring functions of compositional transla-
tion estimation. Through experimental evaluation,
we showed that the domain/topic specific corpus
contributes to improving the performance of the
compositional translation estimation.
Future work includes complementally integrat-
ing the proposed framework of compositional
translation estimation using the Web with other
translation estimation techniques. One of them is
that based on collecting partially bilingual texts
through the search engine (Nagata and others,
2001; Huang et al, 2005). Another technique
which seems to be useful is that of transliteration
of names (Knight and Graehl, 1998; Oh and Choi,
2005).
References
Y. Cao and H. Li. 2002. Base noun phrase translation using
Web data and the EM algorithm. In Proc. 19th COLING,
pages 127?133.
A. Fujii and T. Ishikawa. 2001. Japanese/english cross-
language information retrieval: Exploration of query
translation and transliteration. Computers and the Hu-
manities, 35(4):389?420.
P. Fung and L. Y. Yee. 1998. An IR approach for translating
new words from nonparallel, comparable texts. In Proc.
17th COLING and 36th ACL, pages 414?420.
F. Huang, Y. Zhang, and S. Vogel. 2005. Mining key phrase
translations from web corpora. In Proc. HLT/EMNLP,
pages 483?490.
K. Knight and J. Graehl. 1998. Machine transliteration.
Computational Linguistics, 24(4):599?612.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge ac-
quisition. In R. Dale, H. Moisl, and H. Somers, editors,
Handbook of Natural Language Processing, chapter 24,
pages 563?610. Marcel Dekker Inc.
M. Nagata et al 2001. Using the Web as a bilingual dictio-
nary. In Proc. ACL-2001 Workshop on Data-driven Meth-
ods in Machine Translation, pages 95?102.
J. Oh and K. Choi. 2005. Automatic extraction of english-
korean translations for constituents of technical terms. In
Proc. 2nd IJCNLP, pages 450?461.
R. Rapp. 1999. Automatic identification of word translations
from unrelated English and German corpora. In Proc.
37th ACL, pages 519?526.
S. Sato and Y. Sasaki. 2003. Automatic collection of related
terms from the web. In Proc. 41st ACL, pages 121?124.
T. Tanaka and T. Baldwin. 2003. Translation selection for
japanese-english noun-noun compounds. In Proc. Ma-
chine Translation Summit IX, pages 378?85.
M. Tonoike, M. Kida, T. Takagi, Y. Sasaki, T. Utsuro, and
S. Sato. 2005. Effect of domain-specific corpus in com-
positional translation estimation for technical terms. In
Proc. 2nd IJCNLP, Companion Volume, pages 116?121.
18
