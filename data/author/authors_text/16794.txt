Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 72?77,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Using an SVM Ensemble System for Improved Tamil Dependency Parsing
Nathan Green, Loganathan Ramasamy and Zdene?k Z?abokrtsky?
Charles University in Prague
Institute of Formal and Applied Linguistics
Faculty of Mathematics and Physics
Prague, Czech Republic
{green,ramasamy,zabokrtsky}@ufal.mff.cuni.cz
Abstract
Dependency parsing has been shown to im-
prove NLP systems in certain languages and
in many cases helps achieve state of the art re-
sults in NLP applications, in particular appli-
cations for free word order languages. Mor-
phologically rich languages are often short on
training data or require much higher amounts
of training data due to the increased size of
their lexicon. This paper examines a new
approach for addressing morphologically rich
languages with little training data to start.
Using Tamil as our test language, we cre-
ate 9 dependency parse models with a lim-
ited amount of training data. Using these
models we train an SVM classifier using only
the model agreements as features. We use
this SVM classifier on an edge by edge deci-
sion to form an ensemble parse tree. Using
only model agreements as features allows this
method to remain language independent and
applicable to a wide range of morphologically
rich languages.
We show a statistically significant 5.44%
improvement over the average dependency
model and a statistically significant 0.52% im-
provement over the best individual system.
1 Introduction
Dependency parsing has made many advancements
in recent years. A prime reason for the quick ad-
vancement has been the CoNLL shared task compe-
titions, which gave the community a common train-
ing/testing framework along with many open source
systems. These systems have, for certain languages,
achieved high accuracy ranging from on average
from approximately 60% to 80% (Buchholz and
Marsi, 2006). The range of scores are more of-
ten language dependent rather than system depen-
dent, as some languages contain more morpholog-
ical complexities. While some of these languages
are morphologically rich, we would like to addition-
ally address dependency parsing methods that may
help under-resourced languages as well, which often
overlaps with morphologically rich languages. For
this reason, we have chosen to do the experiments
in this paper using the Tamil Treebank (Ramasamy
and Z?abokrtsky?, 2012).
Tamil belongs to Dravidian family of languages
and is mainly spoken in southern India and also in
parts of Sri Lanka, Malaysia and Singapore. Tamil
is agglutinative and has a rich set of morphologi-
cal suffixes. Tamil has nouns and verbs as two ma-
jor word classes, and hundreds of word forms can
be produced by the application of concatenative and
derivational morphology. Tamil?s rich morphology
makes the language free word order except that it is
strictly head final.
When working with small datasets it is often very
difficult to determine which dependency model will
best represent your data. One can try to pick the
model through empirical means on a tuning set but
as the data grows in the future this model may no
longer be the best choice. The change in the best
model may be due to new vocabulary or through a
domain shift. If the wrong single model is chosen
early on when training is cheap, when the model is
applied in semi supervised or self training it could
lead to significantly reduced annotation accuracy.
72
For this reason, we believe ensemble combinations
are an appropriate direction for lesser resourced lan-
guages, often a large portion of morphologically
rich languages. Ensemble methods are robust as
data sizes grow, since the classifier can easily be re-
trained with additional data and the ensemble model
chooses the best model on an edge by edge basis.
This cost is substantially less than retraining multi-
ple dependency models.
2 Related Work
Ensemble learning (Dietterich, 2000) has been used
for a variety of machine learning tasks and recently
has been applied to dependency parsing in various
ways and with different levels of success. (Surdeanu
and Manning, 2010; Haffari et al, 2011) showed
a successful combination of parse trees through a
linear combination of trees with various weight-
ing formulations. Parser combination with depen-
dency trees have been examined in terms of accu-
racy (Sagae and Lavie, 2006; Sagae and Tsujii,
2007; Zeman and Z?abokrtsky?, 2005; S?gaard and
Rish?j, 2010). (Sagae and Lavie, 2006; Green and
Z?abokrtsky?, 2012) differ in part since their method
guarantees a tree while our system can, in some sit-
uations, produce a forest. POS tags were used in
parser combination in (Hall et al, 2007) for combin-
ing a set of Malt Parser models with an SVM clas-
sifier with success, however we believe our work is
novel in its use of an SVM classifier solely on model
agreements. Other methods of parse combinations
have shown to be successful such as using one parser
to generate features for another parser. This was
shown in (Nivre and McDonald, 2008; Martins et
al., 2008), in which Malt Parser was used as a fea-
ture to MST Parser.
Few attempts were reported in the literature on the
development of a treebank for Tamil. Our exper-
iments are based on the openly available treebank
(TamilTB) (Ramasamy and Z?abokrtsky?, 2012). De-
velopment of TamilTB is still in progress and the ini-
tial results for TamilTB appeared in (Ramasamy and
Z?abokrtsky?, 2011). Previous parsing experiments in
Tamil were done using a rule based approach which
utilized morphological tagging and identification of
clause boundaries to parse the sentences. The results
were also reported for Malt Parser and MST parser.
Figure 1: Process Flow for one run of our SVM Ensemble
system. This Process in its entirety was run 100 times for
each of the 8 data set splits.
When the morphological tags were available during
both training and testing, the rule based approach
performed better than Malt and MST parsers. For
other Indian languages, treebank development is ac-
tive mainly for Hindi and Telugu. Dependency pars-
ing results for them are reported in (Husain et al,
2010).
3 Methodology
3.1 Process Flow
When dealing with small data sizes it is often
not enough to show a simple accuracy increase.
This increase can be very reliant on the train-
ing/tuning/testing data splits as well as the sam-
pling of those sets. For this reason our experi-
ments are conducted over 7 training/tuning/testing
data split configurations. For each configuration
we randomly sample without replacement the train-
ing/tuning/testing data and rerun the experiment 100
times. These 700 runs, each on different samples,
allow us to better show the overall effect on the ac-
curacy metric as well as the statistically significant
changes as described in Section 3.5. Figure 1 shows
this process flow for one run of this experiment.
73
3.2 Parsers
A dependency tree is a special case of a depen-
dency graph that spawns from an artificial root, is
connected, follows a single-head constraint and is
acyclic. Because of this we can look at a large his-
tory of work in graph theory to address finding the
best spanning tree for each dependency graph. The
most common form of this type of dependency pars-
ing is Graph-Based parsing also called arc-factored
parsing and deals with the parameterization of the
edge weights. The main drawback of these meth-
ods is that for projective trees, the worst case sce-
nario for most methods is a complexity of O(n3)
(Eisner, 1996). However, for non-projective pars-
ing Chu-Liu-Edmond?s algorithm has a complexity
of O(n2) (McDonald et al, 2005). The most com-
mon tool for doing this is MST parser (McDonald et
al., 2005). For this parser we generate two models,
one projective and one non-projective to use in our
ensemble system.
Transition-based parsing creates a dependency
structure that is parameterized over the transitions.
This is closely related to shift-reduce constituency
parsing algorithms. The benefit of transition-based
parsing is the use greedy algorithms which have a
linear time complexity. However, due to the greedy
algorithms, longer arc parses can cause error propa-
gation across each transition (Ku?bler et al, 2009).
We make use of Malt Parser (Nivre et al, 2007),
which in the CoNLL shared tasks was often tied
with the best performing systems. For this parser
we generate 7 different models using different train-
ing parameters, seen in Table 1, and use them as
input into our ensemble system along with the two
Graph-based models described above. Each parser
has access to gold POS information as supplied by
the TamilTB described in 3.4.
Dependency parsing systems are often optimized
for English or other major languages. This opti-
mization, along with morphological complexities,
lead other languages toward lower accuracy scores
in many cases. The goal here is to show that
while the corpus is not the same in size or scope of
most CoNLL data, a successful dependency parser
can still be trained from the annotated data through
model combination for morphologically rich lan-
guages.
Training Parameter Model Description
nivreeager Nivre arc-eager
nivrestandard Nivre arc-standard
stackproj Stack projective
stackeager Stack eager
stacklazy Stack lazy
planar Planar eager
2planar 2-Planar eager
Table 1: Table of the Malt Parser Parameters used during
training. Each entry represents one of the parsing algo-
rithms used in our experiments. For more information see
http://www.maltparser.org/options.html
3.3 Ensemble SVM System
We train our SVM classifier using only model agree-
ment features. Using our tuning set, for each cor-
rectly predicted dependency edge, we create
(
N
2
)
features where N is the number of parsing models.
We do this for each model which predicted the cor-
rect edge in the tuning data. So for N = 3 the
first feature would be a 1 if model 1 and model 2
agreed, feature 2 would be a 1 if model 1 and model
3 agreed, and so on. This feature set is novel and
widely applicable to many languages since it does
not use any additional linguistic tools.
For each edge in the ensemble graph, we use our
classifier to predict which model should be correct,
by first creating the model agreement feature set
for the current edge of the unknown test data. The
SVM predicts which model should be correct and
this model then decides to which head the current
node is attached. At the end of all the tokens in a
sentence, the graph may not be connected and will
likely have cycles. Using a Perl implementation of
minimum spanning tree, in which each edge has a
uniform weight, we obtain a minimum spanning for-
est, where each subgraph is then connected and cy-
cles are eliminated in order to achieve a well formed
dependency structure. Figure 2 gives a graphical
representation of how the SVM decision and MST
algorithm create a final Ensemble parse tree which
is similar to the construction used in (Hall et al,
2007; Green and Z?abokrtsky?, 2012). Future itera-
tions of this process could use a multi-label SVM
or weighted edges based on the parser?s accuracy on
tuning data.
74
Figure 2: General flow to create an Ensemble parse tree
3.4 Data Sets
Table 2 shows the statistics of the TamilTB Tree-
bank. The last 2 rows indicate how many word types
have unique tags and how many have two tags. Also,
Table 2 illustrates that most of the word types can
be uniquely identified with single morphological tag
and only around 120 word types take more than one
morphological tag.
Description Value
#Sentences 600
#Words 9581
#Word types 3583
#Tagset size 234
#Types with unique tags 3461
#Types with 2 tags 112
Table 2: TamilTB: data statistics
Since this is a relatively small treebank and in or-
der to confirm that our experiments are not heavily
reliant on one particular sample of data we try a va-
riety of data splits. To test the effects of the train-
ing, tuning, and testing data we try 7 different data
splits. The tuning data in the Section 4 use the for-
mat training-tuning-testing. So 70-20-10 means we
used 70% of the TamilTB for training, 20% for tun-
ing the SVM classifier, and 10% for evaluation.
3.5 Evaluation
Made a standard in the CoNLL shared tasks com-
petition, two standard metrics for comparing depen-
dency parsing systems are typically used. Labeled
attachment score (LAS) and unlabeled attachment
score (UAS). UAS studies the structure of a depen-
dency tree and assesses whether the output has the
correct head and dependency arcs. In addition to the
structure score in UAS, LAS also measures the accu-
racy of the dependency labels on each arc (Buchholz
and Marsi, 2006). Since we are mainly concerned
with the structure of the ensemble parse, we report
only UAS scores in this paper.
To test statistical significance we use Wilcoxon
paired signed-rank test. For each data split we have
100 iterations each with different sampling. Each
model is compared against the same samples so a
paired test is appropriate in this case. We report sta-
tistical significance values for p < 0.01 and p <
0.05.
4 Results and Discussion
Data Average % Increase % Increase
Split SVM UAS over Avg over Best
70-20-10 76.50% 5.13% 0.52%
60-20-20 76.36% 5.68% 0.72%
60-30-10 75.42% 5.44% 0.52%
60-10-30 75.66% 4.83% 0.10%
85-5-10 75.33% 3.10% -1.21%
90-5-5 75.42% 3.19% -1.10%
80-10-10 76.44% 4.84% 0.48%
Table 3: Average increases and decreases in UAS score
for different Training-Tuning-Test samples. The average
was calculated over all 9 models while the best was se-
lected for each data split
For each of the data splits, Table 3 shows the per-
cent increase in our SVM system over both the av-
erage of the 9 individual models and over the best
individual model. As the Table 3 shows, our ap-
proach seems to decrease in value along with the de-
crease in tuning data. In both cases when we only
used 5% tuning data we did not get any improve-
ment in our average UAS scores. Examining Table
4, shows that the decrease in the 90-5-5 split is not
statistically significant however the decrease in 85-
5-10 is a statistically significant drop. However, the
increases in all data splits are statistically significant
except for the 60-20-20 data split. It appears that
75
Model 70-20-10 60-20-20 60-30-10 60-10-30 85-5-10 90-5-5 80-10-10
2planar * * * * * * **
mstnonproj * * * * * * **
mstproj * * * * * * **
nivreeager * * * * ** x *
nivrestandard * * ** x * * *
planar * * * * * * **
stackeager * * * x * ** *
stacklazy * * * x * ** *
stackproj ** * * x ** ** **
Table 4: Statistical Significance Table for different Training-Tuning-Test samples. Each experiment was sampled
100 times and Wilcoxon Statistical Significance was calculated for our SVM model?s increase/decrease over each
individual model. ? = p < 0.01 , ? ? p =< 0.05, x = p ? 0.05
the size of the tuning and training data matter more
than the size of the test data given the low variance
in Table 5. Since the TamilTB is relatively small
when compared to other CoNLL treebanks, we ex-
pect that this ratio may shift more when additional
data is supplied since the amount of out of vocab-
ulary, OOV, words will decrease as well. As OOV
words decrease, we expect the use of additional test
data to have less of an effect.
Data Splits SVM Variance
70-20-10 0.0011
60-20-20 0.0005
60-30-10 0.0010
60-10-30 0.0003
85-5-10 0.0010
90-5-5 0.0028
80-10-10 0.0010
Table 5: Variance of the UAS Scores of our Ensemble
SVM System over 100 data splits
The traditional approach of using as much data as
possible for training does not seem to be as effec-
tive as partitioning more data for tuning an SVM.
For instance the highest training percentage we use
is 90% applied to training with 5% for tuning and
testing each. In this case the best individual model
had a UAS of 76.25% and the SVM had a UAS of
75.42%. One might think using 90% of the data
would achieve a higher overall UAS than using less
training data. On the contrary, we achieve a better
UAS score on average using only 60%, 70%, 80%,
and 85% of the data towards training. This addi-
tional data spent for tuning appears to be worth the
cost.
5 Conclusion
We have shown a new SVM based ensemble parser
that uses only dependency model agreement fea-
tures. The ability to use only model agreements al-
lows us to keep this approach language independent
and applicable to a wide range of morphologically
rich languages. We show a statistically significant
5.44% improvement over the average dependency
model and a statistically significant 0.52% improve-
ment over the best individual system.
In the future we would like to examine how our
data splits? results change as more data is added.
This might be a prime use for self training. Since
the tuning data size for the SVM seems most impor-
tant, the UAS may be improved by only adding self
training data to our tuning sets. This would have the
additional benefit of eliminating the need to retrain
the individual parsers, thus saving computation time.
The tuning size may have a reduced effect for larger
treebanks but in our experiments it is critical to the
smaller treebank. Additionally, a full comparison of
various ensemble parsing error distributions will be
needed.
6 Acknowledgments
This research has received funding from the Euro-
pean Commission?s 7th Framework Program (FP7)
under grant agreement n? 238405 (CLARA)
76
References
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of the Tenth Conference on Compu-
tational Natural Language Learning, CoNLL-X ?06,
pages 149?164, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Thomas G. Dietterich. 2000. Ensemble methods in ma-
chine learning. In Proceedings of the First Interna-
tional Workshop on Multiple Classifier Systems, MCS
?00, pages 1?15, London, UK. Springer-Verlag.
Jason Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In Proceed-
ings of the 16th International Conference on Com-
putational Linguistics (COLING-96), pages 340?345,
Copenhagen, August.
Nathan Green and Zdene?k Z?abokrtsky?. 2012. Hybrid
Combination of Constituency and Dependency Trees
into an Ensemble Dependency Parser. In Proceedings
of the Workshop on Innovative Hybrid Approaches to
the Processing of Textual Data, pages 19?26, Avignon,
France, April. Association for Computational Linguis-
tics.
Gholamreza Haffari, Marzieh Razavi, and Anoop Sarkar.
2011. An ensemble model that combines syntactic
and semantic clustering for discriminative dependency
parsing. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 710?714, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Johan Hall, Jens Nilsson, Joakim Nivre, Gu?lsen Eryigit,
Bea?ta Megyesi, Mattias Nilsson, and Markus Saers.
2007. Single Malt or Blended? A Study in Mul-
tilingual Parser Optimization. In Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007,
pages 933?939.
Samar Husain, Prashanth Mannem, Bharat Ram Ambati,
and Phani Gadde. 2010. The icon-2010 tools contest
on indian language dependency parsing. In Proceed-
ings of ICON-2010 Tools Contest on Indian Language
Dependency Parsing, pages 1?8.
Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency parsing. Synthesis lectures on hu-
man language technologies. Morgan & Claypool, US.
Andre? F. T. Martins, Dipanjan Das, Noah A. Smith, and
Eric P. Xing. 2008. Stacking dependency parsers.
In Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ?08,
pages 157?166, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings of
Human Language Technology Conference and Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 523?530, Vancouver, British Columbia,
Canada, October. Association for Computational Lin-
guistics.
Joakim Nivre and Ryan McDonald. 2008. Integrating
graph-based and transition-based dependency parsers.
In Proceedings of ACL-08: HLT, pages 950?958,
Columbus, Ohio, June. Association for Computational
Linguistics.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
Gulsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,
and Erwin Marsi. 2007. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(2):95?135.
Loganathan Ramasamy and Zdene?k Z?abokrtsky?. 2011.
Tamil dependency parsing: results using rule based
and corpus based approaches. In Proceedings of the
12th international conference on Computational lin-
guistics and intelligent text processing - Volume Part I,
CICLing?11, pages 82?95, Berlin, Heidelberg.
Loganathan Ramasamy and Zdene?k Z?abokrtsky?. 2012.
Prague dependency style treebank for Tamil. In Pro-
ceedings of LREC 2012, I?stanbul, Turkey.
Kenji Sagae and Alon Lavie. 2006. Parser combina-
tion by reparsing. In Proceedings of the Human Lan-
guage Technology Conference of the NAACL, Com-
panion Volume: Short Papers, pages 129?132, New
York City, USA, June. Association for Computational
Linguistics.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with LR models and parser
ensembles. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 1044?1050,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Anders S?gaard and Christian Rish?j. 2010. Semi-
supervised dependency parsing using generalized tri-
training. In Proceedings of the 23rd International
Conference on Computational Linguistics (Coling
2010), pages 1065?1073, Beijing, China, August.
Mihai Surdeanu and Christopher D. Manning. 2010. En-
semble models for dependency parsing: cheap and
good? In HLT: The 2010 Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, HLT ?10, pages 649?652,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Daniel Zeman and Zdene?k Z?abokrtsky?. 2005. Improving
parsing accuracy by combining diverse dependency
parsers. In In: Proceedings of the 9th International
Workshop on Parsing Technologies.
77
Proceedings of the First Workshop on Multilingual Modeling, pages 18?24,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
The Study of Effect of Length in Morphological Segmentation of
Agglutinative Languages
Loganathan Ramasamy and Zdene?k Z?abokrtsky?
Institute of Formal and Applied Linguistics
Faculty of Mathematics and Physics, Charles University in Prague
{ramasamy, zabokrtsky}@ufal.mff.cuni.cz
Sowmya Vajjala
Seminar fu?r Sprachwissenschaft
Universita?t Tu?bingen
sowmya@sfs.uni-tuebingen.de
Abstract
Morph length is one of the indicative feature
that helps learning the morphology of lan-
guages, in particular agglutinative languages.
In this paper, we introduce a simple unsu-
pervised model for morphological segmenta-
tion and study how the knowledge of morph
length affect the performance of the seg-
mentation task under the Bayesian frame-
work. The model is based on (Goldwater et
al., 2006) unigram word segmentation model
and assumes a simple prior distribution over
morph length. We experiment this model
on two highly related and agglutinative lan-
guages namely Tamil and Telugu, and com-
pare our results with the state of the art Mor-
fessor system. We show that, knowledge of
morph length has a positive impact and pro-
vides competitive results in terms of overall
performance.
1 Introduction
Most of the NLP tasks require one way or an-
other the handling of morphology. The task be-
comes very crucial when the language in ques-
tion is morphologically rich as is the case in many
Indo-European languages. The application of mor-
phology is evident in applications such as Statis-
tical Machine Translation (SMT) (Lee, 2004), de-
pendency parsing, information retrieval and so on.
Apart from the morphological analysis as in the tra-
ditional linguistic sense, morphological segmenta-
tion is also widely used as an easy alternative to
full fledged morphological analysis. In this paper
we mainly focus on the task of morphological seg-
mentation.
The main task in morphological segmentation is
to segment the given token or wordform into set
of morphs or identifying the location of each mor-
pheme boundary within the token. Morphological
segmentation is most suitable for agglutinative lan-
guages (such as Finnish or Turkish) than fusional
languages (such as Semitic languages).
Though both supervised (Koskenniemi, 1983)
and unsupervised methods (Goldsmith, 2001;
Creutz and Lagus, 2005) are extensively studied for
morphological segmentation, unsupervised tech-
niques have the appeal of application to multilin-
gual data with cost effective manner. Within un-
supervised paradigm, various methods have been
explored. Minimum Description Length (MDL)
(Goldsmith, 2001; Creutz and Lagus, 2005) based
approaches are most popular in which the best seg-
mentation corresponds to the compact represen-
tation of morphology and the resulting lexicon.
(Goldwater et al, 2009; Snyder and Barzilay, 2008)
attempted word segmentation and joint segmenta-
tion of related languages using Bayesian approach.
(Demberg, 2007; Dasgupta and Ng, 2007) applied
various probabilistic measures to discover affixes
of wordforms. (Naradowsky and Goldwater, 2009;
Yarowsky and Wicentowski, 2000) explored ways
to model orthographic rules of wordforms.
In this work, we are mainly going to focus on
Bayesian approach. Bayesian approaches provide
natural way of modeling subjective knowledge as
well as separating problem specific aspects from
general aspects. In the case of agglutinative lan-
18
guages, the number of morphemes in a word as well
as morph length play a major role in morpholog-
ical process. The main rationale for this work is
to study linguistic factors (mainly morph length),
so that language specific priors can be applied over
different languages. This will especially be use-
ful when modeling resource poor languages (RPL)
with little or no data, as well as building resources
for RPL from resource rich languages (RRL).
Towards that objective, our main contribution in
this work is, we introduce a simple unsupervised
segmentation model based on Bayesian approach
and we study the effect of morph length prior for
two agglutinative languages.
2 Previous Work
In this section, we briefly survey earlier works that
utilized the morph length information, then we pro-
vide basis for our unsupervised morphological seg-
mentation model and finally we list some prior
works on morphological analysis/segmentation of
Telugu and Tamil.
Snover (2001) used an exponential like distri-
bution for morph length that decreased over word
length, thus favoring shorter morph lengths. Our
work is directly related to (Creutz, 2003) as it
made use of prior distributions on morph length and
frequency of morphs under maximum a posteriori
(MAP) framework. Gamma distribution was used
as a prior distribution for morph length. The main
difference between (Creutz, 2003) and our work is
that, we are going to experiment different morph
lengths under Bayesian framework.
Naradowsky (2011) introduced an exponential
length penalty to prevent the model from under seg-
mentation results. It also emphasized that avoiding
length penalty seriously affected the model. (Poon
et al , 2009) indirectly specified about the morph
length by restricting the number of morphemes per
word.
In this work, we mainly rely on Goldwater (2009;
2006) which conducted an extensive study on the
application of Bayesian approach to word segmen-
tation in child-directed speech utterances. It in-
cluded both unigram and bigram models (based on
Hierarchical Dirichlet Processes) for word segmen-
tation. Gibbs sampling was used to extract sam-
ples (utterances with word boundaries) from pos-
terior distribution. We apply the unigram model
(Goldwater et al, 2009) to morphological segmen-
tation where the word boundaries in speech utter-
ances correspond to morpheme boundaries in word-
forms.
Before we describe unsupervised morphological
segmentation model, we briefly survey the existing
work on Telugu and Tamil morphological segmen-
tation/analysis.
Rao et al (2011) described in detail, the prepara-
tion of a linguistic database for Telugu morpholog-
ical analysis, compiling 2800 morphological cate-
gories and reported a coverage of 95-97%. They
followed a word and paradigm model, which was
considered to be better suited for agglutinative lan-
guages. The issue of out-of-vocabulary words was
handled better in the rule based approach by (Gana-
pathiraju and Levin, 2006). They describe a rule-
based morphological analyzer TelMore for Telugu
nouns and verbs.
Aksharbharathi et al (2004) describes the devel-
opment of a generic morphological analysis shell
that uses dictionaries along with Finite State Trans-
ducers based feature structures, to perform the mor-
phological analysis of a word. The feature struc-
tures were derived from the standard rules of the
grammar in respective languages. This was tested
with Hindi, Telugu, Tamil and Russian.
Kiranmai et al (2010) describe a supervised
morphological analyzer with support vector ma-
chines.
For Tamil, morphological segmentation is rarely
studied. Most of the work is done for morpholog-
ical analysis of wordforms. Most of the analyz-
ers use rule based approaches. Dhanalakshmi et al
(2009) used sequence labeling approach to morpho-
logical analysis of wordforms.
3 Unsupervised Morphological
Segmentation
Consider a wordform (w) of length n composed of
characters from alphabet LA,
w = c1c2c3...cn
The main objective is to identify the character po-
sitions where morpheme boundaries occur. The
19
model we describe here is similar to the cache
model described in (Goldwater et al, 2006) for
word segmentation. We apply the same model to
identify morpheme boundaries. The model makes
decision at every character position in the wordform
for the entire corpus. The hypothesis probability
that no morpheme boundary at position i in word-
form w is calculated as follows,
P (w?i |h) =
nma + ?P0(ma)
Nm + ?
(1)
ma is a substring or a morph in the wordform
w which contains the character position position i.
nma refers to number of times the morph ma oc-
curs in the history of morph counts Nm. In the case
of having a boundary at position i, we will have
two morphs to consider, one morph (ma) to the left
of position i (including i), and another morph (mb)
starting after i. The probability of having a mor-
pheme boundary at position i is calculated in the
same way as Equation 1, but this time with two
morphs,
P (w+i |h) =
nma + ?P0(ma)
Nm + ?
.
nmb + I(ma == mb) + ?P0(mb)
(Nm + 1) + ?
(2)
I(ma == mb) takes the value 1 if both morphs
are same, otherwise the value is 0. Also note that
the additional 1 (due to previous factor) in the de-
nominator of the second part of the equation. In
both the equations, P0 is a base distribution which
can be utilized to put a bias over certain hypothe-
ses. In our case, the base distribution (P0) mainly
assigns probability distribution over morph length.
Additional linguistic factors can also be modeled
this way. ? is a concentration parameter which can
be used to control P0. Overall, the model (in equa-
tion 1 and 2) uses only unigram morph counts.
Every character position (except the last posi-
tion) in a given word is a potential candidate that
can have a morpheme boundary. To determine
whether they really have morpheme boundary or
not, for every character position i inw, we calculate
hypothesis probabilities b+i (i.e. has a morpheme
boundary) and b?i (has no morpheme boundary).
Having calculated the hypothesis probabilities, we
choose the hypothesis by using a weighted coin flip.
In our problem, we have only two hypotheses: (i) a
morpheme boundary and (ii) no morpheme bound-
ary. If the new hypothesis is different from the char-
acter?s previous status, then appropriate data struc-
tures are updated. This procedure is repeated for
many number of iterations.
3.1 Modeling morpheme length
We encode our beliefs about morph length via
base distribution P0. We chose Poisson distribu-
tion for modeling the length of the morphs. Pois-
son distribution utilizing morph length is defined as
P (l, k) = l
ke?l
k! , where l is an expected length of
the morph and when supplied k, it returns the prob-
ability density of a morph having length k. We de-
fine two base distributions based on morph length
prior,
PA0 (m) = p(l, k)
=
lke?l
k!
(3)
PB0 (m) = p(m)p(l, k)
=
nm
| lm |
lke?l
k!
(4)
p(m) is probability of the morph itself. | lm | -
total number of substrings of length equal to the
length of morph m. Morfessor (Creutz and Lagus,
2005) uses Zipfian distribution for frequencies and
gamma length prior for modeling the length of the
morphs. Setting a particular expected morph length
effectively puts a bias towards that particular morph
length (l). We experiment both our base distribu-
tions over different morph lengths.
3.2 Inferencing
Gibbs sampling (Gilks et al, 1996) uses iterative
procedure to repeatedly draw value of a variable
given the current state of all other variables in the
model. In our case, drawing a value is equal to
determining whether there is a boundary at the
character position, thus obtaining individual mor-
phemes. We iteratively segment the given corpus or
list of words into morphological segments. The in-
tuitive idea is that, when we sample enough number
of times i.e. drawing morphological segments of
words given history of segments of all other words,
20
the sampler converges to the posterior distribution
of the morphological segments of the entire corpus.
The Algorithm 1 gives a general outline of how the
Gibbs sampling procedure is applied to morpholog-
ical segmentation.
Algorithm 1: Basic Sampling Procedure
Data: words, model
Result: Segmented words
begin
RandSeg ?? InitializeSegments(words)
Baseline?? Evaluate(RandSeg)
CurrSeg ?? RandSeg
MorphCounts?? GetCounts(CurrSeg)
for i ? iterations do
for j ? size(words) do
for k ? length(words[j]) do
b?k ?? Calculate(P (words[j]
?
k ))
b+k ?? Calculate(P (words[j]
+
k ))
if HasNoBoundaryAt(k) then
add boundary at k with
probability
b+k
b?k +b
+
k
no change at k with probability
b?k
b?k +b
+
k
if HasBoundaryAt(k) then
remove boundary at k with
probability
b?k
b?k +b
+
k
no change at k with probability
b+k
b?k +b
+
k
UpdateCurrSeg(CurrSeg)
AdjustMorphCounts(MorphCounts)
We use temperature (T) settings (not shown in
the algorithm) to make the sampling procedure con-
verge faster. We use 10 values (from 0.1 to 1.0) for
T and raise the probability values of hypotheses to
( 1T ). Also, we make the collection rate very small,
so that only few and substantially different samples
(or morphological segmentation of the entire cor-
pus) are collected.
4 Experimental Setup
The experiments are carried out for the unigram
segmentation model (unsup-uni) as described in
Section 3 and Morfessor system (Creutz and Lagus,
2005). For both Tamil and Telugu, we perform the
following experiments: (i) baseline (ii) unsup-uni
with base distribution PA0 (unsup-uni-p0-len) (iii)
unsup-uni with base distribution PB0 (unsup-uni-
p0-lex-len) and (iv) with Morfessor. For each sys-
tem, we add some knowledge about morph length
(l) and report the accuracy.
The experiments (ii), (iii) and (iv) use additional
dataset known as extra-data. Extra-data is an unan-
notated/unsegmented data which augments the test
data while training the systems. As test data with
gold segmentation is very small, we feel this step is
necessary to make the evaluation credible. The fol-
lowing subsection describes the datasets in detail.
Baseline system corresponds to random segmen-
tation. We evaluate baseline system for morph
lengths 1 to 10. For each morph length (l) experi-
ment, we change the probability of adding a bound-
ary at each character position to be (1l ) except at
l = 1 where the probability is 0.75.
Unsup-uni-p0-len experiment uses base distribu-
tion PA0 (see Section 3.1). We conduct this experi-
ment in 2 steps: (i) running the Gibbs sampler with
the extra-data and (ii) use the parameters (includ-
ing morph counts) from step (i) and run the Gibbs
sampler on test data. We set the expected morph
length (l) in the base distribution PA0 every time we
run the experiment for different morph length. For
the step (i), the Gibbs sampler is run for 10000 iter-
ations with different concentration parameter (?).
We collect samples every 1000 iterations and we
store the last sample as our model along with other
parameters. For step (ii), we use the model from
step (i) and run the Gibbs sampler on test data. We
collect the final sample as our predicted segmen-
tation of the test data and perform evaluation on
the predicted segmentation. In unsup-uni-p0-lex-
len experiment, we use the base distribution PB0
(see Section 3.1). PB0 includes morpheme proba-
bility apart from the length prior. Experiments for
unsup-uni-p0-lex-len is carried out in the same way
as that of unsup-uni-p0-len.
We use gamma distribution length prior for ex-
periments with Morfessor. We train Morfessor on
extra-data for morph lengths 1 to 10. We change
the expected length in the gamma prior for each
morph length experiment. Then we run the Mor-
fessor on test data with same parameters created
during the training.
We use Precision (P), Recall (R) and F-score (F)
21
Lang. Words Chars Morphs Avg. m.(l)
Tamil 1500 12642 3280 3.85
Telugu 998 10303 1733 5.95
Table 1: Gold segmentation: statistics
for evaluating our predicted segmentation with gold
segmentation. Our evaluation is same as (Creutz
and Linde?n, 2004).
4.1 Data
We use EMILLE corpus (Xiao et al , 2004) for
our experiments. The EMILLE corpus contains
monolingual, parallel and annotated data for var-
ious Indian languages. We randomly selected ar-
ticles from monolingual section of Tamil and Tel-
ugu data. The original data were in utf-8 and
we transliterated the data into latin format. The
transliteration step is an important step as it avoids
confusion in specifying morph length (l). As we
already mentioned earlier, we use two sets (extra-
data and test data) of data for each language. For
training of extra-data, we use 30000 unique words
list for each language. For test data, we make words
list from real sentences thus it can contain multi-
ple occurrences of a same wordform. The Table 1
provides the statistics of the test data for which we
have manually performed gold segmentations. At
present, our gold segmentation does not take into
account multiple possible segmentations.
The Figure 1 shows morph counts distribution
of both Tamil and Telugu (derived from gold seg-
ments) according to their morph lengths. Tamil has
more morphs that are shorter in length than Telugu.
5 Results
The Table 2 shows evaluation results for the exper-
imental setup described in the previous section.
For Tamil, most of the morphs have the length 1-
4. The models unsup-uni-p0-len and unsup-uni-p0-
lex-len perform quite well near to that length range.
For the same range (l = 1 to 4), both the models
together perform better than Morfessor in terms of
F-score. The performance of unsup-uni-p0-len and
unsup-uni-p0-lex-len are constantly decreasing and
start to perform worse than Morfessor after length
5. This is somewhat expected that unsup-uni mod-
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 18
Tamil
morph length (l)
mo
rph c
ount
0
200
400
600
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
Telugu
morph length (l)
mo
rph c
ount
0
100
200
300
Figure 1: Morph counts according to morph length (l)
els are quite sensitive to length priors and may per-
form poorly if we assume morph lengths far from
the true range. Whereas, Morfessor has a consis-
tent performance over the entire length range (l = 1
to 10). This implies that, Morfessor is less sensitive
to length priors even if we drastically change the
expected morph length. Unsup-uni-p0-len gave the
best overall performance (F-score - 48.83%) com-
pared to other models in this task.
Telugu?s common morph length ranges from 2-
8. Except at l = 1 & 2, Morfessor beats both
unsup-uni-p0-len and unsup-uni-p0-lex-len in all
other remaining length ranges. Unsup-uni models
perform quite poorly over different length ranges
when comparing with Tamil for the same range. In
this task, Morfessor?s overall performance (F-score
43.63%) is better than unsup-uni models. Mor-
fessor also performs better near the most frequent
morph length range (5-8).
6 Some Observations on (l)
? The results (Table 2) suggest that unsup-uni
model is quite sensitive to morph length pa-
rameter in the prior distributions.
? For Tamil, unsup-uni model performs well
near to the true morph length range. But the
performance deteriorates when the expected
morph length parameter is too different from
22
Language System P/R/F
Morph length (l)
1 2 3 4 5 6 7 8 9 10
Tamil
baseline
P 15.79 15.86 17.04 17.11 15.33 16.33 15.98 14.75 17.63 16.65
R 73.98 50.08 34.92 26.25 19.64 15.50 13.82 11.47 12.31 10.24
F 26.02 24.09 22.91 20.72 17.22 15.91 14.82 12.91 14.50 12.68
unsup-uni-p0-len
P 63.61 62.17 67.99 69.68 69.22 72.77 72.29 68.70 66.73 64.08
R 39.62 40.01 36.49 33.18 28.82 26.47 24.23 22.10 20.65 20.76
F 48.83 48.69 47.49 44.96 40.7 38.82 36.30 33.45 31.54 31.36
unsup-uni-p0-lex-len
P 46.51 59.48 63.79 63.69 56.10 54.58 50.29 48.18 45.99 50.39
R 41.35 41.07 39.34 38.28 36.04 33.69 34.25 34.08 33.02 28.65
F 43.78 48.59 48.67 47.82 43.88 41.66 40.75 39.92 38.44 36.53
Morfessor
P 48.54 48.32 48.61 49.01 50.24 49.07 49.93 49.21 49.42 48.93
R 41.75 40.18 40.07 40.24 40.46 39.84 40.35 39.84 40.40 39.62
F 44.89 43.87 43.93 44.19 44.82 43.98 44.63 44.03 44.64 43.78
Telugu
baseline
P 07.88 08.05 07.91 07.38 07.70 07.54 07.62 08.52 08.96 07.91
R 75.69 51.59 32.97 23.86 20.00 16.00 13.66 13.38 12.97 10.07
F 14.28 13.93 12.76 11.27 11.12 10.25 09.78 10.41 10.60 10.07
unsup-uni-p0-len
P 36.67 37.29 36.2 39.71 41.87 40.58 41.34 39.15 38.10 33.65
R 53.10 51.17 48.14 38.07 29.1 19.31 16.14 11.45 11.03 9.66
F 43.38 43.14 41.33 38.87 34.34 26.17 23.21 17.72 17.11 15.01
unsup-uni-p0-lex-len
P 22.27 26.55 32.46 35.76 28.29 19.31 19.83 18.3 18.17 17.26
R 66.9 58.34 44.41 35.17 35.31 55.17 42.21 49.79 55.45 52.28
F 33.41 36.5 37.51 35.47 31.41 28.6 26.98 26.76 27.37 25.95
Morfessor
P 29.32 29.59 30.48 30.72 30.88 30.85 31.31 30.34 29.88 30.40
R 70.30 69.48 69.48 69.75 70.17 70.30 71.96 70.99 70.58 71.96
F 41.38 41.50 42.38 42.65 42.89 42.88 43.63 42.51 41.99 42.74
Table 2: Results for Tamil and Telugu
the true frequent morph length range.
? However for Telugu, morph length parameter
did not improve the results at the most frequent
morph length range (5-8).
? Concentration parameter (?) too influences
the effect of base distribution as a whole, but
at present, our study does not take into account
?. For small ? values, the base distribution
will not have much effect.
7 Conclusion
In this paper, we mainly studied the effect of knowl-
edge of morph length that could have on the ac-
curacy of morphological segmentation of aggluti-
native languages. Towards that goal, we intro-
duced a simple unsupervised morphological seg-
mentation model based on Bayesian approach that
utilized prior distribution over morph length. The
results showed that the knowledge of length cer-
tainly has a positive impact on the accuracy. Also,
the model provided competitive results in general
and achieved best overall performance (F-score:
48.83%) for Tamil against Morfessor. As a future
work, it would be interesting to see the model and
priors that handle sandhi changes.
Acknowledgements
The research leading to these results has re-
ceived funding from the European Commission?s
7th Framework Program (FP7) under grant agree-
ment n? 238405 (CLARA). We would like to thank
David Marec?ek for useful suggestions about theory
and implementation of the system. We also would
like to thank anonymous reviewers for their useful
comments.
References
Akshar Bharathi, Rajeev Sangal, Dipti M Sharma and
Radhika Mamidi. 2004. Generic Morphological
Analysis Shell. In Proceedings of LREC 2004.
Benjamin Snyder and Regina Barzilay. 2008. Unsuper-
vised Multilingual Learning for Morphological Seg-
mentation. In Proceedings of the 46th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 737?745. 2008.
David Yarowsky and Richard Wicentowski. Minimally
Supervised Morphological Analysis by Multimodal
Alignment. In Proceedings of the 38th Annual Meet-
ing on Association for Computational Linguistics
(ACL), 2000.
Dhanalakshmi V, AnandKumar M, Rekha RU and Ra-
jendran S. 2009. Morphological Analyzer for Ag-
23
glutinative Languages Using Machine Learning Ap-
proaches. In Advances in Recent Technologies in
Communication and Computing, 2009, ARTCom?09,
2009.
Hoifung Poon, Colin Cherry and Kristina Toutanova.
2009. Unsupervised Morphological Segmentation
with Log-Linear Models. In Proceedings of Hu-
man Language Technologies: The 2009 Annual Con-
ference of the North American Chapter of the ACL
(NAACL-HLT), pages 209?217, Boulder, Colorado,
June 2009.
Jason Naradowsky and Sharon Goldwater. 2009. Im-
proving Morphology Induction by Learning Spelling
Rules. In Proceedings of 21st International Joint
Conference on Artificial Intelligence (IJCAI), 2009.
Jason Naradowsky and Kristina Toutanova. 2011. Un-
supervised Bilingual Morpheme Segmentation and
Alignment with Context-rich Hidden Semi-Markov
Models. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 895?904,
June, 2011.
John Goldsmith. 2001. Unsupervised Learning of the
Morphology of a Natural Language. Computational
Linguistics, 27(2): pages 153?198, 2001.
Kimmo Koskenniemi. 1983. Two-level morphol-
ogy: A general computational model for word-form
recognition and production. Publication 11, Univer-
sity of Helsinki, Department of General Linguistics,
Helsinki. 1983.
Madhavi Ganapathiraju and Lori Levin. 2006. Tel-
More: Morphological Generator for Telugu Nouns
and Verbs. In Proceedings of the Second Interna-
tional Conference on Digital Libraries. 2006.
Mathias Creutz. 2003. Unsupervised Segmentation of
Words Using Prior Distributions of Morph Length
and Frequency. In Proceedings of the 41st Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 280?287, July 2003.
Mathias Creutz and Krista Lagus. 2005. Unsupervised
Morpheme Segmentation and Morphology Induction
from Text Corpora Using Morfessor 1.0. In Publica-
tions in Computer and Information Science, Report
A81, Helsinki University of Technology, 2005.
Mathias Creutz and Krister Linde?n. 2004. Morpheme
Segmentation Gold Standards for Finnish and En-
glish. Publications in Computer and Information Sci-
ence, Report A77, Helsinki University of Technology,
October, 2004.
Matthew G. Snover and Michael R. Brent. 2001. A
Bayesian model for morpheme and paradigm identi-
fication. In Proceedings of the 39th Annual Meeting
on Association for Computational Linguistics (ACL),
pages 490?498, 2001.
Sai Kiranmai G., K. Mallika, M. Anand Kumar, V.
Dhanalakshmi and K. P. Soman. 2010. Morpho-
logical Analyzer for Telugu using support vector ma-
chines. In Proceedings of ICT 2010.
Sajib Dasgupta and Vincent Ng. 2007. High-
Performance, Language-Independent Morphological
Segmentation. In Proceedings of NAACL HLT 2007,
pages 155?163, 2007.
Sharon Goldwater, Thomas L. Griffiths and Mark John-
son. 2006. Contextual dependencies in unsupervised
word segmentation. In In Proceedings of the 21st In-
ternational Conference on Computational Linguistics
and 44th Annual Meeting of the Association for Com-
putational Linguistics (ACL), 2006.
Sharon Goldwater, Thomas L. Griffiths and Mark John-
son. 2009. A Bayesian framework for word segmen-
tation: Exploring the effects of context. Cognition,
112 (1), pp. 21?54, 2009.
Uma Maheshwar Rao G., Amba Kulkarni P. and Christo-
pher Mala. 2011. A Telugu Morphological Analyzer.
International Telugu Internet Conference Proceed-
ings, Milpitas, California, USA, 28th - 30th Septem-
ber, 2011
Vera Demberg. 2007. A Language-Independent Unsu-
pervised Model for Morphological Segmentation. In
Proceedings of the 45th Annual Meeting of the As-
sociation of Computational Linguistics (ACL), pages
920?927, Prague, Czech Republic, June 2007.
Walter R. Gilks, Sylvia Richardson and David Spiegel-
halter. 1996. Markov Chain Monte Carlo in Practice.
Chapman and Hall. 1996.
Xiao Z., McEnery A., Baker P. and Hardie A. 2004.
Developing Asian language corpora: standards and
practice. In Proceedings of the Fourth Workshop on
Asian Language Resources, pp. 1?8, 2004.
Young-Suk Lee. 2004. Morphological Analysis for Sta-
tistical Machine Translation. In Proceedings of the
HLT-NAACL 2004, pp. 57?60, Boston, USA, 2004.
24
