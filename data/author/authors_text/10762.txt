Proceedings of the Workshop on BioNLP, pages 1?9,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Static Relations: a Piece in the Biomedical Information Extraction Puzzle
Sampo Pyysalo? Tomoko Ohta? Jin-Dong Kim? Jun?ichi Tsujii???
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
{smp,okap,jdkim,tsujii}@is.s.u-tokyo.ac.jp
Abstract
We propose a static relation extraction task to
complement biomedical information extrac-
tion approaches. We argue that static re-
lations such as part-whole are implicitly in-
volved in many common extraction settings,
define a task setting making them explicit, and
discuss their integration into previously pro-
posed tasks and extraction methods. We fur-
ther identify a specific static relation extrac-
tion task motivated by the BioNLP?09 shared
task on event extraction, introduce an anno-
tated corpus for the task, and demonstrate the
feasibility of the task by experiments showing
that the defined relations can be reliably ex-
tracted. The task setting and corpus can serve
to support several forms of domain informa-
tion extraction.
1 Introduction
Relation Extraction (RE) is a key task in biomedi-
cal Information Extraction (IE). The automatic de-
tection of relevant types of relations ? for various
definitions of relevant ? between entities has been
one of the primary focus points for significant do-
main research efforts over the past decade, and a
substantial number of biomedical RE methods and
annotated corpora have been published (Zweigen-
baum et al, 2007). Motivated by the needs of biolo-
gists and e.g. database curation efforts, most domain
RE efforts target relations involving biologically rel-
evant changes in the involved entities, commonly to
the complete exclusion of static relations. However,
static relations such as entity membership in a fam-
ily and one entity being a part of another are not only
relevant IE targets in themselves but can also play an
important supporting role in IE systems not primar-
ily targeting them.
In this paper, we investigate the role of static re-
lations in causal RE and event extraction. Here,
we use relation extraction in the MUC and ACE
(Sundheim, 1995; Doddington et al, 2004) sense to
refer to the task of extracting binary relations, or-
dered pairs of entities, where both participating enti-
ties must be specified and their roles (agent, patient,
etc.) are fixed by the relation. By contrast, event ex-
traction is understood to involve events (things that
happen) and representations where the number and
roles of participants may vary more freely. We re-
fer to relations where one one entity causes another
to change as causal relations; typical domain exam-
ples are phosphorylation and activation. Static rela-
tions, by contrast, hold between two entities without
implication of change or causality: examples from
the ACE IE task include Physical.Located and Part-
Whole.Artifact.
2 Task definition
In the following, we argue that static relations are
relevant to much of current biomedical IE work,
present a task setting making these relations explicit,
and discuss applications of static relation annotation
and extraction methods.
2.1 Named entity-driven IE and static relations
Named entities (NEs) provide a simple anchor con-
necting text to entities in the real world and thus a
natural starting point for IE. Named entity recog-
nition (NER) is well studied and several biomed-
1
ical NER systems are available (see e.g. (Wilbur
et al, 2007; Leaman and Gonzalez, 2008)), and
most domain IE approaches are NE-driven: a typi-
cal way to cast the RE task is as deciding for each
pair of co-occurring NEs whether a relevant rela-
tion is stated for them in context. Like the previ-
ous LLL and BioCreative2-PPI relation extraction
tasks (Ne?dellec, 2005; Krallinger et al, 2007), the
BioNLP?09 shared task on event extraction (Kim et
al., 2009) similarly proceeds from NEs, requiring
participants to detect events and determine the roles
given NEs play in them.
Any domain IE approach targeting nontrivial
causal NE relations or events necessarily involves
decisions relating to static relations. Consider, for
example, the decision whether to extract a relation
between NE1 and NE2 in the following cases (affects
should here be understood as a placeholder for any
relevant statement of causal relation):
1) NE1 affects NE2 gene
2) NE1 affects NE2 promoter
3) NE1 affects NE2 mutant
4) NE1 affects NE2 antibody
5) NE1 affects NE2 activator
The decision here depends on the interpretation of
the noun compounds (NCs) NE2 gene, NE2 pro-
moter, etc. Depending on the IE setting, one might,
for example, judge that statements (1)?(3) justify the
extraction of an (NE1, NE2) relation, while (4) and
(5) do not. This question is rarely formalized as
a separate (sub)task in domain studies, and meth-
ods targeting e.g. the LLL, BioCreative2-PPI and
BioNLP?09 shared task relations and events must
learn to resolve this question together with the sep-
arate issue of which words and syntactic structures
express relevant causal relations.
2.2 Task setting
The relation extraction problems represented by ex-
amples (1)?(5) above are closely related to the well-
studied issue of NC semantics. However, the prob-
lem extends past simple binary NCs to include judg-
ments on the relations of arbitrary base NPs (nouns
with premodifiers) to contained NEs,
NE1 affects truncated NE2
NE1 affects NE2/NE3 complexes
NE1 affects NE2-dependent phosphatase
and further to relations of NPs with NEs that are syn-
tactically less immediately attached:
NE1 affects first exon of NE2
NE1 affects an element in the NE2 promoter
NE1 affects members of the immediate-early acti-
vation genes family such as NE2
The problem thus encompasses also more general
relations between nominals.
While these different cases could also be studied
as separate tasks, in the current IE context they can
be seen as presenting a continuum of different syn-
tactic realizations of similar relations that also carry
the same implications for further processing. We
propose to treat them together, formulating the spe-
cific task studied in this paper as follows:
Given: named entity NE and another entity E
with their context in text,
Determine: whether there is a relevant static re-
lation R(NE, E) and its type.
Here, relevant relations are defined as those that jus-
tify an inference of some role for the NE in causal re-
lations/events involving E. Additionally, the level of
granularity chosen for typing is chosen according to
the need to determine the role of the NE in the rela-
tions/events. These choices are intentionally depen-
dent on the IE context: we do not expect to be able
to formulate a universally accepted set of relevance
criteria or relations. Our choice of relation scope
and types here follows the perspective of a currently
highly relevant IE problem, the BioNLP?09 shared
task on event extraction. We aim to recognize a set
of relations sufficient to capture the relevant rela-
tionships of the NEs provided as given information
in the shared task (all of protein/gene/RNA type)
and the terms annotated in the GENIA Event corpus
(Kim et al, 2008) as participants in events.
We note that this task setting excludes the recog-
nition of candidate NEs and other entities. The as-
sumption that they are given is analogous to the
common NE-NE causal relation extraction setting.
Further, requiring their recognition would, in our
view, unnecessarily complicate the task with aspects
of NER and NP chunking, well-studied separate
tasks.
We next sketch a formulation of an causal rela-
tion/event extraction task incorporating static rela-
tions and briefly present one possible way in which
2
static relation extraction could be applied in IE set-
tings not explicitly targeting such relations.
2.3 Applications of static relations
In the following, we assume that NEs are detected in
a prior processing step. Consider, then, the task of
extracting relevant information from the following
sentence:
NE1 is a subunit of the complex that inhibits the
expression of mutant forms of NE2
An example causal relation extraction target here
could be
Inhibit(NE1,NE2)
while an event extraction task might aim to recog-
nize the events
E1:Expression(NE2)
E2:Inhibit(NE1, E1)
An IE system directly targeting either representa-
tion will need to simultaneously address issues re-
lating to the causal statements and static relations.
Static relation annotation makes this explicit (square
brackets are used to mark non-NE entities):
Part-Whole.Component-Object(NE1, [complex])
Variant(NE2, [mutant forms])
This type of static relation detection as prior step to
causal relation or event extraction could be applied
in at least two different ways: primarily augment-
ing the extracted information, or alternatively assist-
ing in the extraction of the information considered
above. Assuming the successful extraction of the
above static relations, the input can be reformulated
as
NE1 is a subunit of the [complex] that inhibits the
expression of [mutant forms] of NE2
Then, under the augmented extraction model, the
causal relation and event extraction targets would be,
respectively,
Inhibit([complex],[mutant forms])
and
E1:Expression([mutant forms])
E2:Inhibit([complex], E1)
Taken together with the static relations, this provides
a more detailed representation of the information
stated in the example sentence. Further, simple rules
would suffice to derive the simplified representations
involving only the NEs, and such rules would have
the further benefit of making explicit which inter-
vening static relations are taken to support the infer-
ence that an NE is involved in a stated causal relation
or event.
Alternatively, under the assisted extraction model,
with the assumption that the static relations are taken
to allow the inference that any relation or event hold-
ing of the other entities holds for the NEs, the input
to the causal relation or event extraction system can
be recast as
NE1 is a subunit of the NE?1 that inhibits the ex-
pression of NE?2 of NE2
where NE?1 and NE?2 should be understood as
aliases for NE1 and NE2, respectively. Now, un-
der the causal relation extraction model, each of
the (NE1,NE2), (NE?1, NE2), (NE1,NE?2), (NE?1,NE?2)
pairs can serve as an example of the desired rela-
tion, both for the purposes of training and actual
extraction (the event extraction case can be treated
analogously). By increasing the number of positive
cases, this application of information on static rela-
tions would be expected to have a positive effect on
the performance of the primary causal relation/event
extraction method.
While these two alternatives are only rough
sketches of possible uses of static relation annota-
tion, we expect either could be developed into a
practical implementation. Further, these examples
by no means exhaust the possibilities of this class
of annotation. As static relation extraction can thus
be seen to have multiple potential benefits for both
causal relation and event extraction, we believe the
efforts to pursue static relations as a separate task
and to develop resources specific to this task are jus-
tified.
3 Relations
Based on an analysis of the shared task data (see
Section 4.1), we recognize the static relations illus-
trated in Table 1. In the following, we briefly discuss
the types and their selection.
3
Name Examples
Variant Bcl-6 gene, IL-1 mRNA, wild-type SHP1, TRADD mutant, human IL-1beta,
[cell-surface isoforms] of CD43, phosphorylated CREB protein
PW.Object-Component IL-6 promoter, GR N-terminal transactivation domain, SAA promoter sequence,
proximal IL-2 promoter-enhancer, [transcriptional enhancers] including IFNB
PW.Component-Object NF-kappa B1/RelA heterodimer, p65 homodimer, p50-p65 complex,
STAT1-containing [DNA-binding complex], [heterodimer] of p50 and p65
PW.Member-Collection CREB/ATF family, p21ras small GTP binding proteins,
[non-heat shock genes] such as IL1B, [cellular genes] including GM-CSF
PW.Place-Area beta-globin locus
Table 1: Relations. In examples, NEs are underlined and square brackets are used to mark the extent of non-NE entities
that do not span the entire example text.
3.1 Selection criteria
Relations could be recognized and split into differ-
ent types at a number of different granularities. Mo-
tivated by practical IE applications, we aimed to de-
fine a static relation extraction subtask that fits natu-
rally into existing IE frameworks and to create an-
notation that supplements existing annotation and
avoids overlap in annotated information. The practi-
cal goals also motivate our aim to recognize a min-
imal set of different relation types that can satisfy
other goals, fewer distinctions implying an easier
task and more reliable extraction.
To decide whether to use a single relation type or
introduce several subtypes to annotate a given set of
cases, we aimed to introduce coherent relation types,
each implying consistent further processing. More
specifically, we required that each relation R(NE,
entity) must uniquely and consistently define the re-
lation and roles of the participants, and that in the
relevant IE context the relation alone is sufficient to
decide how to interpret the role of the NE in other
relations/events. Specific examples are given in the
introduction of the chosen relation types below.
In the following, we follow in part the relation
taxonomy and relation definitions of (Winston et al,
1987). However, we recognize that there is no clear
agreement on how to subdivide these relations and
do not suggest this to be the only appropriate choice.
3.2 Part-whole relations
Part-whole, or meronymic, relations are, not surpris-
ingly, the most common class of static relations in
our data: a single generic Part-Whole relation could
capture more than half of the relevant relations in
the corpus. However, although the relations be-
tween the NE and entity in, for example, [complex]
containing NE and [site] in NE are both types of
Part-Whole (below PW) relations, the roles of par-
ticipants are not consistently defined: in PW(NE,
[site]) the entity is a component of the NE, while
in PW(NE, [complex]) the roles are reversed. We
thus recognize separate PW.Object-Component and
PW.Component-Object relations. By contrast, while
the relation between a NE representing a gene and a
site on that gene is is arguably different from the re-
lation between a protein NE and a site on the protein,
we do not distinguish these relations as the annota-
tion would duplicate information available in as part
of the entity typing in the corpus and would further
imply a static relation extraction task that incorpo-
rates aspects of NE recognition.
Also frequent in the data are relations such as
that between a protein and a protein family it be-
longs to. While many cases are clearly identifiable
as PW.Member-Collection relations, others could al-
ternatively be analysed as Class-Member. As in our
context the relations in e.g. P, a member of the [type
F protein family] and P, a [type F protein] imply
the same processing, we will apply the PW.Member-
Collection label to both, as well as to ad hoc col-
lections such as [cellular genes] such as NE, even
if this requires a somewhat relaxed interpretation of
the relation label. Finally, there are a few cases in
our data (e.g. NE locus) that we view as instances of
the PW.Place-Area relation.
3.3 Variant relations
To avoid unnecessary division of relations that im-
ply in our context similar interpretation and process-
ing, we define a task-specific Variant relation that
4
encompasses a set of possible relation types holding
between an NE and its variants along multiple dif-
ferent axes. One significant class of cases annotated
as Variant includes expressions such as NE gene and
NE protein, under the interpretation that NE refers
to the abstract information that is ?realized? as ei-
ther DNA, RNA or protein form, and the entity to
one of these realizations (for alternative interpreta-
tions, see e.g. (Rosario and Hearst, 2001; Heimonen
et al, 2008)).
The Variant relation is also used to annotate NE-
entity relations where the entity expresses a different
state of the NE, such as a phosphorylated or mutated
state. While each possible post-translational modifi-
cation, for example, could alternatively be assigned
a specific relation type, in the present IE context
these would only increase the difficulty of the task
without increasing the applicability of the resulting
annotation.
3.4 Other/Out annotation
We apply a catch-all category, Other/Out, for anno-
tating candidate (NE, entity) pairs between which
there is no relevant static relation. This label is thus
applied to a number of quite different cases: causal
relations, both implied (e.g. NE receptors, NE re-
sponse element) and explicitly stated (NE binds the
[site]), relations where the entity is considered too
far removed from the NE to support reliable infer-
ence of a role for the NE in causal relations/events
involving the entity (e.g. [antibodies] for NE), and
cases where no relation is stated (e.g. NE and other
[proteins]). The diversity of this generic category
of irrelevant cases is a necessary consequence of the
aim to avoid annotation involving decisions directly
relating to other tasks by creating distinctions be-
tween e.g. causal and no relation.
3.5 Sufficiency of the setting and relation types
We have cast the static relation extraction task as al-
ways involving an NE, which in the present context
is further always of a protein, gene or RNA type.
This restriction considerably simplifies the task con-
ceptually and reduces annotation effort as well as ex-
pected extraction difficulty, as the type of only one
of the entities involved in the relation can vary sig-
nificantly. However, it is not obvious that the restric-
tion allows coherent relations types to be defined. If
the corpus contained frequent cases where the stated
relationship of the NE to the entity involved different
types of relevant relations (e.g. collections of parts
of an NE), it would be necessary to either recog-
nized ?mixed? or combined relations or extend the
task to include general entity-entity relations.
Interestingly, during annotation we encountered
only two cases (less than 0.1% of those annotated)
involving two of the recognized relation types at
once: mutant NE promoter and 5? truncation mu-
tants of the NE promoter1. While this result is likely
affected by a number of complex factors (annota-
tion criteria, NE and entity types, granularity of re-
lations, etc.), we find the outcome ? which was nei-
ther planned for nor forced on the data ? a very en-
couraging sign of the sufficiency of the task setting
for this and related domain IE tasks.
4 Data
We created the data set by building on the annota-
tion of the GENIA Event corpus (Kim et al, 2008),
making use of the rich set of annotations already
contained in the corpus: term annotation for NEs
and other entities (Ohta et al, 2002), annotation of
events between these terms, and treebank structure
closely following the Penn Treebank scheme (Tateisi
et al, 2005).
4.1 Annotation
The existing GENIA annotations served as the basis
of the new annotation. We initially selected as can-
didates entities annotated as participating in events
considered in the BioNLP?09 shared task.
As the term annotation includes nesting of en-
tities, NEs contained within these relevant entities
were used as the starting point for the annotation.
We first performed a preliminary study of the rele-
vant static relations occurring between the entities
and NEs occurring within them to determine the
set of relations to annotate. Next, all unique cases
where a selected entity contained an NE were anno-
tated with the appropriate relation based on the con-
tained text of the entity, with the text of the contained
NE normalized away. For the present study, we ex-
cluded from consideration cases where the annota-
1To resolve these cases, we simply ignored the implied Vari-
ant relation.
5
tion indicated simple aliasing (e.g. [CREB/ATF]), a
relation irrelevant to our purpose and found in the
selected data only due to the annotation specifying
one entity but two NEs in these cases. In this step,
830 unique cases representing a total of 1601 entities
containing NEs were annotated.
The nesting structure of the term annotation does
not, however, capture all relevant static relations:
the term annotation scheme disallows discontinuous
terms and annotation of terms with structure more
complex than base NPs. Thus, the possible relations
of NEs to entities to which they were connected e.g.
by a prepositional phrase cannot be directly derived
from the existing annotation. As an example, the
nesting in [NE region] directly suggest the existence
of a relation, while no such connection appears in
[region] of NE. To annotate relations for entities for
which the term annotation does not identify a can-
didate related NE, it is necessary to form (NE, en-
tity) pairs with co-occurring NEs. Even when the
candidate NEs were restricted to those occurring in
the same sentence, the number of such pairs in the
corpus was over 17,000, beyond the scope of what
could be annotated as part of this effort. Further, as
the great majority of co-occurring (NE, entity) pairs
will have no relevant static relation, we used heuris-
tics to increase the proportion of relevant and near-
miss cases in the annotated data.
We first converted the gold standard annotation of
the GENIA treebank (Tateisi et al, 2005) into a de-
pendency representation using the Stanford parser
tools (de Marneffe et al, 2006) and then deter-
mined the shortest paths in the dependency analy-
ses connecting each relevant entity with each NE.
The (NE, entity) pairs were then ordered according
to the length of these paths, on the assumption that
syntactically more closely related entities are more
likely to have a relevant static relation. Annotation
then proceeded on the ordered list of pairs. Dur-
ing the annotation, we further developed more or-
dering heuristics, such as giving higher ranking to
candidate pairs connected by a path that contains
a subpath known to connect pairs with relevant re-
lations. Such known paths were first derived from
the BioInfer static relation annotation (Pyysalo et al,
2007) and later extracted from previously annotated
cases. In this annotation process, judgments were
performed with reference to the full sentence con-
Annotated instances
Relation cont. nonc. total
PW.Object-Component 394 133 527
PW.Component-Object 299 44 343
Variant 253 20 273
PW.Member-Collection 25 124 149
PW.Place-Area 4 1 5
Other/Out 626 778 1404
total 1601 1100 2701
Table 2: Statistics for annotated data. Number of in-
stances given separately for relations annotated between
entities with contained (cont.) and non-contained (nonc.)
NEs.
text. In total, 1100 cases were annotated in this way.
All stages of the annotation process involved only
lists formatted as simple text files for markup and
custom-written software for processing.
Table 2 contains statistics for the annotated data,
showing separately the number of annotated re-
lations of entities to contained and non-contained
NEs. There are interesting differences in the rela-
tion type distribution between these two categories,
reflecting the different ways in which relations are
typically stated. This difference in distribution sug-
gests that it may be beneficial to give the two cases
different treatment in extraction.
4.2 Representation
For simplicitly of use, we provide the annotated data
in two equivalent representations: a simple inline
XML format and a standoff format. The XML for-
mat closely resembles the representation used for the
SemEval-2007 Semantic Relations between Nomi-
nals task (Girju et al, 2007). Here, each NE-Entity
pair is given its own entry with its sentence con-
text in which only the pair is marked. In the alter-
nate standoff representation, all entities appearing in
each sentence are tagged, and the annotated relations
given separately. These representations are easily
processed and should be usable with little modifica-
tion with many existing relation extraction methods.
We further split the data into training,
development-test and test sets according to the
same division applied in the BioNLP?09 shared
task on event extraction. This division allows the
dataset to be easily integrated into settings using the
shared task data, combining static relation and event
extraction approaches.
6
5 Experiments
The selected task setting and representation form a
natural basis for two alternative classification prob-
lems: a binary classification problem for detecting
the presence of any relevant relation, and a multi-
class classification problem where the correct rela-
tion type must also be determined. In the following,
we describe experiments using the dataset in these
two settings. While we apply a state-of-the-art ma-
chine learning method and a fairly expressive repre-
sentation, the aim of the experiments is only to de-
termine the relative difficulty of the relation extrac-
tion task and to establish a moderately competitive
baseline result for the newly created dataset.
We use a linear Support Vector Machine (SVM)
classifier (Chang and Lin, 2001) with N-gram fea-
tures defined over token sequences delimited by the
beginning and end of the entity and the position of
the NE. The NE is treated as a single token and
its text content blinded from the classifier to avoid
overfitting on specific names. Features are gener-
ated from two sequences of tokens: those inside
the entity and, when the NE is not contained in the
entity, those between the entity and the NE (inclu-
sive of the entity and NE at the sequence bound-
aries). In preliminary experiments on the develop-
ment test set we found no clear benefit from includ-
ing N-gram features extracted from a broader con-
text, supporting an assumption that the problem can
be mostly addressed on the basis of local features.
By contrast, preliminary experiments supported the
use of the simple Porter algorithm (Porter, 1980) for
stemming, the inclusion of uni-, bi- and trigram fea-
tures, and normalization of the feature vectors to unit
length; these were adopted for the final experiment.
The SVM regularization parameter was optimized
using a sparse search with evaluation on the devel-
opment test set.
We first reduced the annotated data into a binary
classification problem with the Other/Out class rep-
resenting negative (irrelevant) and the other rela-
tions positive (relevant) cases. The results for this
experiment were very encouraging, giving both a
high classification accuracy of 86.8% and an F-score
of 84.1%. The test set contains 179 positive and
269 negative cases, giving a majority baseline ac-
curacy of 60.0% and an all-true baseline F-score of
P R F
Relevant 81.2 87.2 84.1
PW.Object-Component 94.2 75.4 83.8
PW.Component-Object 60.0 71.2 65.1
Variant 88.0 57.9 69.8
PW.Member-Collection 54.5 37.5 44.4
Table 3: Classification results with (P)recision, (R)ecall
and (F)-score for the binary Relevant/Irrelevant exper-
iment and classwise results for the relevant classes
(PW.Place-Area excluded for lack of data).
57.1%. The classifier notably and statistically sig-
nificantly (McNemar?s test, p < 0.01) outperforms
these simple baselines. We then performed a sep-
arate multiclass classification experiment, predict-
ing the specific type of the relation, also including
the Other/Out type. In this experiment, accuracy re-
mained relatively high at 81.9%, while per-class pre-
cision and recall results (considering each class in
turn positive and all others negative, see Table 3) in-
dicate some remaining challenges. The results vary
somewhat predictably with the number of exam-
ples per relation type (Table 2): while PW.Object-
Component relations can be predicted at high pre-
cision and fair recall, performance for PW.Member-
Collection relations falls behind expectations for a
local relation extraction problem.
To briefly relate these results to domain causal RE
results, we note that the recently proposed state-of-
the-art method of (Airola et al, 2008) was reported
to achieve F-scores ranging between 56.4?76.8% on
five different causal RE corpora in a binary classi-
fication setting. As our relatively simple method
achieves a notably higher 84.1% F-score at the bi-
nary static RE task, we can conclude that this static
RE task is not as difficult as the causal RE tasks.
This is encouraging for the prospects of static RE in
support of domain causal RE and event extraction.
6 Related work
Relations of types that we have here termed static
have figured prominently in the MUC and ACE se-
ries of events that have largely defined the ?gen-
eral domain? IE research program (Sundheim, 1995;
Doddington et al, 2004). In this line of research,
event-type annotation is used (as the name implies)
to capture events, defined as ?[...] something that
happens [...] [that] can frequently be described as a
7
change of state? (LDC, 2005) and relation-type an-
notation is applied for relevant non-causal relation-
ships. General static relations have been studied ex-
tensively also in broader, non-IE contexts (see e.g.
(Girju et al, 2007)).
In the biomedical domain, static relations have re-
ceived relatively little attention. Domain noun com-
pound semantics, including static relations, have
been considered in studies by (Rosario and Hearst,
2001) and (Nakov et al, 2005), but in IE settings
static relations tend to appear only implicitly, as in
the RelEx causal RE system of (Fundel et al, 2007),
or through the causal relations they imply: for ex-
ample, in the AIMed corpus (Bunescu et al, 2005)
statements such as NE1/NE2 complex are annotated
as a binding relation between the two NEs, not Part-
Whole relations with the broader entity. By contrast,
there has been considerable focus on the extraction
of ?things that happen,? dominantly making use of
relation-type corpus annotation and extraction ap-
proaches: a study of five corpora containing primar-
ily causal relation annotation is found in (Pyysalo et
al., 2008); more complete lists of domain corpora
are maintained by Kevin Cohen2 and Jo?rg Haken-
berg3. For a thorough review of recent work in do-
main RE, we refer to (Zweigenbaum et al, 2007).
BioInfer (Pyysalo et al, 2007), to the best of our
knowledge the first domain corpus to include event-
type annotation, also includes annotation for a set
of static relation types. The design of the BioIn-
fer corpus and relationship type ontology as well as
work applying the corpus in jointly targeting event
extraction and static relation extraction (Heimonen
et al, 2008; Bjo?rne et al, 2008) have considerably
influenced the present study. A key difference in fo-
cus is that BioInfer primarily targets NE-NE rela-
tions, while our concern here has been the relations
of NEs with other, non-NE entities, specifically fo-
cusing on the requirements of the BioNLP?09 shared
task. A class of static relations, connecting Mu-
tants and Fragments with their parent proteins, is
annotated in the recently introduced ITI TXM cor-
pora (Alex et al, 2008). While somewhat limited
in the scope of static relations, this annotation cov-
ers an extensive number of instances, over 20,000,
2http://compbio.uchsc.edu/ccp/corpora/obtaining.shtml
3http://www2.informatik.hu-
berlin.de/?hakenber/links/benchmarks.html
and could likely support the development of high-
reliability methods for the extraction extraction of
these specific static relations. As discussed in detail
in Section 4.1, previously published versions of the
GENIA corpus (Kim et al, 2008) contain NE, term
and event annotation, but no static relations have
been annotated in GENIA prior to this effort.
While previously introduced corpora thus cover
aspects of the annotation required to address the
static relation extraction task considered in this pa-
per, we are not aware of previously published re-
sources that would address this task specifically or
contain annotation supporting the entire task as en-
visioned here.
7 Conclusions and future work
In this paper, we have argued for a position for static
relations in biomedical domain IE, specifically
advancing the subtask of extracting static relations
between named entities and other entities appearing
in their context. We explored this subtask in the
specific IE context of the BioNLP?09 shared task on
event extraction, identifying possible instances of
static relations relevant to the task setting. We then
studied these instances of detail, defining a minimal
set of basic static relations argued to be sufficient
to support the type of IE envisioned in the shared
task. We annotated 2701 instances of candidate
static relations, creating the first domain corpus
of static relations explicitly designed to support
IE, and performed experiments demonstrating that
the static relation extraction task can be performed
accurately, yet retains challenges for future work.
The newly annotated corpus is publicly available at
www-tsujii.is.s.u-tokyo.ac.jp/GENIA
to encourage further research on this task.
Acknowledgments
Discussions with members of the BioInfer group
were central for developing many of the ideas pre-
sented here. We are grateful for the efforts of Maki
Niihori in producing supporting annotation applied
in this work. This work was partially supported
by Grant-in-Aid for Specially Promoted Research
(Ministry of Education, Culture, Sports, Science and
Technology (MEXT), Japan), and Genome Network
Project (MEXT, Japan).
8
References
Antti Airola, Sampo Pyysalo, Jari Bjorne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008.
All-paths graph kernel for protein-protein interaction
extraction with evaluation of cross-corpus learning.
BMC Bioinformatics, 9(Suppl 11):S2.
Bea Alex, Claire Grover, Barry Haddow, Mijail Kabad-
jov, Ewan Klein, Michael Matthews, Stuart Roebuck,
Richard Tobin, and Xinglong Wang. 2008. The ITI
TXM corpora: Tissue expressions and protein-protein
interactions. In Proceedings of LREC?08.
Jari Bjo?rne, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. How complex are complex protein-
protein interactions? In Proceedings SMBM?08.
Razvan C Bunescu, Ruifang Ge, Rohit J. Kate, Ed-
ward M. Marcotte, Raymond J. Mooney, Arun Kumar
Ramani, and Yuk Wah Wong. 2005. Comparative ex-
periments on learning information extractors for pro-
teins and their interactions. Artificial Intelligence in
Medicine, 33(2):139?155.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a
library for support vector machines.
George Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The Automatic Content Extrac-
tion (ACE) program: Tasks, data, and evaluation. In
Proceedings of LREC?04, pages 837?840.
Katrin Fundel, Robert Kuffner, and Ralf Zimmer. 2007.
RelEx?Relation extraction using dependency parse
trees. Bioinformatics, 23(3):365?371.
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
Semeval-2007 task 04: Classification of semantic re-
lations between nominals. In Proceedings of Se-
mEval?07, pages 13?18.
Juho Heimonen, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. Complex-to-pairwise mapping of
biological relationships using a semantic network rep-
resentation. In Proceedings of SMBM?08.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
bionlp?09 shared task on event extraction. In Proceed-
ings of BioNLP?09.
Martin Krallinger, Florian Leitner, and Alfonso Valen-
cia. 2007. Assessment of the second BioCreative PPI
task: Automatic extraction of protein-protein interac-
tions. In Proceedings of BioCreative II, pages 41?54.
LDC. 2005. ACE (automatic content extraction) en-
glish annotation guidelines for events. Technical re-
port, Linguistic Data Consortium.
R. Leaman and G. Gonzalez. 2008. Banner: An exe-
cutable survey of advances in biomedical named entity
recognition. In Proceedings of PSB?08, pages 652?
663.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In Pro-
ceedings of LREC?06, pages 449?454.
Preslav Nakov, Ariel Schwartz, Brian Wolf, and Marti
Hearst. 2005. Scaling up bionlp: Application of a text
annotation architecture to noun compound bracketing.
In Proceedings of BioLINK?05.
Claire Ne?dellec. 2005. Learning language in logic -
genic interaction extraction challenge. In Proceedings
of LLL?05.
Tomoko Ohta, Yuka Tateisi, Hideki Mima, and Jun?ichi
Tsujii. 2002. GENIA corpus: An annotated research
abstract corpus in molecular biology domain. In Pro-
ceedings of the Human Language Technology Confer-
ence (HLT?02), pages 73?77.
M. F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(2):130?137.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Antti Airola, Juho Heimonen, and Jari
Bjo?rne. 2008. Comparative analysis of five protein-
protein interaction corpora. BMC Bioinformatics,
9(Suppl. 3):S6.
Barbara Rosario and Marti Hearst. 2001. Classify-
ing the semantic relations in noun compounds via a
domain-specific lexical hierarchy. In Proceedings of
EMLNP?01, pages 82?90.
Beth M. Sundheim. 1995. Overview of results of the
MUC-6 evaluation. In Proceedings of MUC-6, pages
13?31.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun?ichi Tsujii. 2005. Syntax annotation for the GE-
NIA corpus. In Proceedings of IJCNLP?05, pages
222?227.
John Wilbur, Larry Smith, and Lorrie Tanabe. 2007.
Biocreative 2 gene mention task. In Proceedings of
BioCreative 2, pages 7?16.
Morton E. Winston, Roger Chaffin, and Douglas Her-
rmann. 1987. A taxonomy of part-whole relations.
Cognitive Science, 11.
Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu,
and Kevin B. Cohen. 2007. Frontiers of biomedical
text mining: Current progress. Briefings in Bioinfor-
matics.
9
Proceedings of the Workshop on BioNLP, pages 106?107,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Incorporating GENETAG-style annotation to GENIA corpus
Tomoko Ohta? and Jin-Dong Kim? and Sampo Pyysalo? and Yue Wang? and Jun?ichi Tsujii???
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
{okap,jdkim,smp,wangyue,tsujii}@is.s.u-tokyo.ac.jp
1 Introduction
Proteins and genes are the most important entities in
molecular biology, and their automated recognition
in text is the most widely studied task in biomed-
ical information extraction (IE). Several corpora
containing annotation for these entities have been
introduced, GENIA (Kim et al, 2003; Kim et al,
2008) and GENETAG (Tanabe et al, 2005) being
the most prominent and widely applied. While both
aim to address protein/gene annotation, their an-
notation principles differ notably. One key differ-
ence is that GENETAG annotates the conceptual en-
tity, gene, which is often associated with a function,
while GENIA concentrates on the physical forms of
gene, i.e. protein, DNA and RNA. The difference
has caused serious problems relating to the compat-
ibility and comparability of the annotations. In this
work, we present an extension of GENIA annotation
which integrates GENETAG-style gene annotation.
The new version of the GENIA corpus is the first to
bring together these two types of entity annotation.
2 GGP Annotation
Gene is the basic unit of heredity, which is encoded
in the coding region of DNA. Its physical manifes-
tations as RNA and Protein are often called its prod-
ucts. In our view of these four entity types, gene is
taken as an abstract entity whereas protein, DNA and
RNA are physical entities. While the three physical
entity types are disjoint, the abstract concept, gene,
is defined from a different perspective and is realized
in, not disjoint from, the physical entity types.
The latest public version of GENIA corpus (here-
after ?old corpus?) contains annotations for gene-
Protein DNA RNA GGP
Old Annotation 21,489 8,653 876 N/A
New Annotation 15,452 7,872 863 12,272
Table 1: Statistics on annotation for gene-related entities
related entities, but they are classified into only
physical entity types: Protein, DNA and RNA. The
corpus revisions described in this work are two-fold.
First, annotation for the abstract entity, gene, were
added (Table 1, GGP). To emphasize the character-
istics of the new entity type, which does not dis-
tinguish a gene and its products, we call it GGP
(gene or gene product). Second, the addition of GGP
annotation triggered large-scale removal of Protein,
DNA and RNA annotation instances for cases where
the physical form of the gene was not referred to
(Due to space limitations, we omit RNA from now
on). The time cost involved with this revision was
approximately 500 person-hours.
3 Quality Assessment
To measure the effect of revision, we performed
NER experiments with old and new annotation (Ta-
bles 2 and 3). We split the corpus into disjoint 90%
and 10% parts for use in training and test, respec-
tively. We used the BANNER (Leaman and Gonza-
lez, 2008) NE tagger and created a separate single-
class NER problem for each entity type.
In the old annotation, consistency is moderate
for protein (77.70%), while DNA is problematic
(58.03%). The new GGP annotation has been
achieved in a fairly consistent way (81.44%). How-
ever, the removal of annotation for entities previ-
ously marked as protein or DNA had opposite effects
on the two: better performance for DNA (64.06%),
106
Precision Recall F-score
Protein 80.78 74.84 77.70
DNA 64.90 52.48 58.03
Table 2: NER performance before GGP annotation
Precision Recall F-score
Protein 71.20 56.61 63.08
DNA 69.59 59.35 64.06
GGP 86.86 76.65 81.44
Protein+ 83.22 78.20 80.63
Table 3: NER performance after GGP annotation
Phosphorylation Gene expression
GGP in protein 70% GGP abstract 34%
Protein 25% Protein 24%
GGP abstract 3% GGP in Protein 17%
Peptide 1% GGP in DNA 9%
Table 4: Distribution of theme entity types in GENIA
implying annotation consistency improved with the
removals, but worse for Protein (63.08%).
We find the primary explanation for this effect in
the statistics in Table 1: in the revision, a large num-
ber of protein annotations (6,037) but only a small
number of DNA annotations (780) were replaced
with GGP. To distinguish such GGPs from those em-
bedded in Protein or DNA annotations, we call them
?abstract? GGPs, as they appear in text without in-
formation on their physical form. Nevertheless, in
the old annotation, they had to be annotated as either
protein or DNA, which might have caused inconsis-
tent annotation. However, the statistics show a clear
preference for choosing Protein over DNA. The rad-
ical drop of performance in protein recognition can
then be explained in part as a result of removing this
systematic preference.
Aside from the discussion on whether the pref-
erence is general or specific, we interpret the pref-
erence as a need for ?potential? proteins to be re-
trieved together with ?real? proteins, which was an-
swered by the old protein annotation. To reproduce
this class in the new annotation, we added abstract
GGPs to the Protein annotation and performed an
NER experiment. The result (Table 3, Protein+)
shows a clear improvement over the comparable re-
sult for the old protein annotation.
In conclusion, we argue, the revision of the GE-
NIA annotation, in addition to introducing a new en-
tity class, has led to a significant improvement of
overall consistency.
4 Discussion
Although there are already corpora such as GENE-
TAG with annotation similar to GGPs, we expect
this newly introduced class of annotation to support
existing annotations of GENIA, such as event and
co-reference annotation, opening up new possibili-
ties for application. The quality of entity annota-
tion should be closely related to that of other seman-
tic annotation, e.g. events. For example, the event
type Phosphorylation is about a change on physi-
cal entities, e.g. proteins and peptides, and as such,
it is expected that themes of these events would be
physical entities. On the other hand, the event type
Gene expression is about the manifestation of an ab-
stract entity (gene) as a physical entity (protein) and
would thus be expected to involve both abstract and
physical entities. Statistics from GENIA (Table 4)
show that the theme selection made in event anno-
tation well reflects these characteristics of the two
event types. The observation suggests that there is a
good likelihood that improvement of the entity an-
notation can be further transferred to other semantic
annotation, which is open for future work.
Acknowledgments
This work was partially supported by Grant-in-Aid
for Specially Promoted Research (MEXT, Japan)
and Genome Network Project (MEXT, Japan).
References
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun?ichi
Tsujii. 2003. GENIA corpus - a semantically an-
notated corpus for bio-textmining. Bioinformatics,
19(suppl. 1):i180?i182.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
lterature. BMC Bioinformatics, 9(1):10.
R. Leaman and G. Gonzalez. 2008. Banner: an exe-
cutable survey of advances in biomedical named en-
tity recognition. Pacific Symposium on Biocomputing,
pages 652?663.
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne Mat-
ten, and W John Wilbur. 2005. Genetag: a tagged cor-
pus for gene/protein named entity recognition. BMC
Bioinformatics, 6(Suppl 1):S3.
107
Proceedings of the Workshop on BioNLP: Shared Task, pages 1?9,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Overview of BioNLP?09 Shared Task on Event Extraction
Jin-Dong Kim? Tomoko Ohta? Sampo Pyysalo? Yoshinobu Kano? Jun?ichi Tsujii???
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
{jdkim,okap,smp,kano,tsujii}@is.s.u-tokyo.ac.jp
Abstract
The paper presents the design and implemen-
tation of the BioNLP?09 Shared Task, and
reports the final results with analysis. The
shared task consists of three sub-tasks, each of
which addresses bio-molecular event extrac-
tion at a different level of specificity. The data
was developed based on the GENIA event cor-
pus. The shared task was run over 12 weeks,
drawing initial interest from 42 teams. Of
these teams, 24 submitted final results. The
evaluation results are encouraging, indicating
that state-of-the-art performance is approach-
ing a practically applicable level and revealing
some remaining challenges.
1 Introduction
The history of text mining (TM) shows that shared
tasks based on carefully curated resources, such
as those organized in the MUC (Chinchor, 1998),
TREC (Voorhees, 2007) and ACE (Strassel et al,
2008) events, have significantly contributed to the
progress of their respective fields. This has also been
the case in bio-TM. Examples include the TREC Ge-
nomics track (Hersh et al, 2007), JNLPBA (Kim et
al., 2004), LLL (Ne?dellec, 2005), and BioCreative
(Hirschman et al, 2007). While the first two ad-
dressed bio-IR (information retrieval) and bio-NER
(named entity recognition), respectively, the last two
focused on bio-IE (information extraction), seeking
relations between bio-molecules. With the emer-
gence of NER systems with performance capable of
supporting practical applications, the recent interest
of the bio-TM community is shifting toward IE.
Similarly to LLL and BioCreative, the
BioNLP?09 Shared Task (the BioNLP task, here-
after) also addresses bio-IE, but takes a definitive
step further toward finer-grained IE. While LLL and
BioCreative focus on a rather simple representation
of relations of bio-molecules, i.e. protein-protein
interactions (PPI), the BioNLP task concerns the
detailed behavior of bio-molecules, characterized as
bio-molecular events (bio-events). The difference in
focus is motivated in part by different applications
envisioned as being supported by the IE methods.
For example, BioCreative aims to support curation
of PPI databases such as MINT (Chatr-aryamontri
et al, 2007), for a long time one of the primary tasks
of bioinformatics. The BioNLP task aims to support
the development of more detailed and structured
databases, e.g. pathway (Bader et al, 2006) or Gene
Ontology Annotation (GOA) (Camon et al, 2004)
databases, which are gaining increasing interest
in bioinformatics research in response to recent
advances in molecular biology.
As the first shared task of its type, the BioNLP
task aimed to define a bounded, well-defined bio-
event extraction task, considering both the actual
needs and the state of the art in bio-TM technology
and to pursue it as a community-wide effort. The
key challenge was in finding a good balance between
the utility and the feasibility of the task, which was
also limited by the resources available. Special con-
sideration was given to providing evaluation at di-
verse levels and aspects, so that the results can drive
continuous efforts in relevant directions. The pa-
per discusses the design and implementation of the
BioNLP task, and reports the results with analysis.
1
Type Primary Args. Second. Args.
Gene expression T(P)
Transcription T(P)
Protein catabolism T(P)
Phosphorylation T(P) Site
Localization T(P) AtLoc, ToLoc
Binding T(P)+ Site+
Regulation T(P/Ev), C(P/Ev) Site, CSite
Positive regulation T(P/Ev), C(P/Ev) Site, CSite
Negative regulation T(P/Ev), C(P/Ev) Site, CSite
Table 1: Event types and their arguments. The type of the
filler entity is specified in parenthesis. The filler entity
of the secondary arguments are all of Entity type which
represents any entity but proteins: T=Theme, C=Cause,
P=Protein, Ev=Event.
2 Task setting
To focus efforts on the novel aspects of the event
extraction task, is was assumed that named entity
recognition has already been performed and the task
was begun with a given set of gold protein anno-
tation. This is the only feature of the task setting
that notably detracts from its realism. However,
given that state-of-the-art protein annotation meth-
ods show a practically applicable level of perfor-
mance, i.e. 88% F-score (Wilbur et al, 2007), we
believe the choice is reasonable and has several ad-
vantages, including focus on event extraction and ef-
fective evaluation and analysis.
2.1 Target event types
Table 1 shows the event types addressed in the
BioNLP task. The event types were selected from
the GENIA ontology, with consideration given to
their importance and the number of annotated in-
stances in the GENIA corpus. The selected event
types all concern protein biology, implying that they
take proteins as their theme. The first three types
concern protein metabolism, i.e. protein production
and breakdown. Phosphorylation is a representa-
tive protein modification event, and Localization and
Binding are representative fundamental molecular
events. Regulation (including its sub-types, Posi-
tive and Negative regulation) represents regulatory
events and causal relations. The last five are uni-
versal but frequently occur on proteins. For the bio-
logical interpretation of the event types, readers are
referred to Gene Ontology (GO) and the GENIA on-
tology.
The failure of p65 translocation to the nucleus . . .
T3 (Protein, 40-46)
T2 (Localization, 19-32)
E1 (Type:T2, Theme:T3, ToLoc:T1)
T1 (Entity, 15-18)
M1 (Negation E1)
Figure 1: Example event annotation. The protein an-
notation T3 is given as a starting point. The extraction
of annotation in bold is required for Task 1, T1 and the
ToLoc:T1 argument for Task 2, and M1 for Task 3.
As shown in Table 1, the theme or themes of all
events are considered primary arguments, that is, ar-
guments that are critical to identifying the event. For
regulation events, the entity or event stated as the
cause of the regulation is also regarded as a primary
argument. For some event types, other arguments
detailing of the events are also defined (Secondary
Args. in Table 1).
From a computational point of view, the event
types represent different levels of complexity. When
only primary arguments are considered, the first five
event types require only unary arguments, and the
task can be cast as relation extraction between a
predicate (event trigger) and an argument (Protein).
The Binding type is more complex in requiring the
detection of an arbitrary number of arguments. Reg-
ulation events always take a Theme argument and,
when expressed, also a Cause argument. Note that a
Regulation event may take another event as its theme
or cause, a unique feature of the BioNLP task com-
pared to other event extraction tasks, e.g. ACE.
2.2 Representation
In the BioNLP task, events are expressed using three
different types of entities. Text-bound entities (t-
entities hereafter) are represented as text spans with
associated class information. The t-entities include
event triggers (Localization, Binding, etc), protein
references (Protein) and references to other entities
(Entity). A t-entity is represented by a pair, (entity-
type, text-span), and assigned an id with the pre-
fix ?T?, e.g. T1?T3 in Figure 1. An event is ex-
pressed as an n-tuple of typed t-entities, and has
a id with prefix ?E?, e.g. E1. An event modifi-
cation is expressed by a pair, (predicate-negation-
or-speculation, event-id), and has an id with prefix
?M?, e.g. M1.
2
Item Training Devel. Test
Abstract 800 150 260
Sentence 7,449 1,450 2,447
Word 176,146 33,937 57,367
Event 8,597 / 8,615 1,809 / 1,815 3,182 / 3,193
Table 2: Statistics of the data sets. For events,
Task1/Task2 shown separately as secondary arguments
may introduce additional differentiation of events.
2.3 Subtasks
The BioNLP task targets semantically rich event ex-
traction, involving the extraction of several different
classes of information. To facilitate evaluation on
different aspects of the overall task, the task is di-
vided to three sub-tasks addressing event extraction
at different levels of specificity.
Task 1. Core event detection detection of typed,
text-bound events and assignment of given pro-
teins as their primary arguments.
Task 2. Event enrichment recognition of sec-
ondary arguments that further specify the
events extracted in Task 1.
Task 3. Negation/Speculation detection detection
of negations and speculation statements
concerning extracted events.
Task 1 serves as the backbone of the shared task and
is mandatory for all participants. Task 2 involves the
recognition of Entity type t-entities and assignment
of those as secondary event arguments. Task 3 ad-
dresses the recognition of negated or speculatively
expressed events without specific binding to text. An
example is given in Fig. 1.
3 Data preparation
The BioNLP task data were prepared based on the
GENIA event corpus. The data for the training and
development sets were derived from the publicly
available event corpus (Kim et al, 2008), and the
data for the test set from an unpublished portion of
the corpus. Table 2 shows statistics of the data sets.
For data preparation, in addition to filtering out
irrelevant annotations from the original GENIA cor-
pus, some new types of annotation were added to
make the event annotation more appropriate for the
purposes of the shared task. The following sections
describe the key changes to the corpus.
3.1 Gene-or-gene-product annotation
The named entity (NE) annotation of the GENIA
corpus has been somewhat controversial due to dif-
ferences in annotation principles compared to other
biomedical NE corpora. For instance, the NE an-
notation in the widely applied GENETAG corpus
(Tanabe et al, 2005) does not differentiate proteins
from genes, while GENIA annotation does. Such
differences have caused significant inconsistency in
methods and resources following different annota-
tion schemes. To remove or reduce the inconsis-
tency, GENETAG-style NE annotation, which we
term gene-or-gene-product (GGP) annotation, has
been added to the GENIA corpus, with appropriate
revision of the original annotation. For details, we
refer to (Ohta et al, 2009). The NE annotation used
in the BioNLP task data is based on this annotation.
3.2 Argument revision
The GENIA event annotation was made based on
the GENIA event ontology, which uses a loose typ-
ing system for the arguments of each event class.
For example, in Figure 2(a), it is expressed that
the binding event involves two proteins, TRAF2
and CD40, and that, in the case of CD40, its cy-
toplasmic domain takes part in the binding. With-
out constraints on the type of theme arguments,
the following two annotations are both legitimate:
(Type:Binding, Theme:TRAF2, Theme:CD40)
(Type:Binding, Theme:TRAF2,
Theme:CD40 cytoplasmic domain)
The two can be seen as specifying the same event
at different levels of specificity1. Although both al-
ternatives are reasonable, the need to have consis-
tent training and evaluation data requires a consis-
tent choice to be made for the shared task.
Thus, we fix the types of all non-event
primary arguments to be proteins (specifically
GGPs). For GENIA event annotations involving
themes other than proteins, additional argument
types were introduced, for example, as follows:
1In the GENIA event annotation guidelines, annotators are
instructed to choose the more specific alternative, thus the sec-
ond alternative for the example case in Fig. 2(a).
3
(a)
TRAF2 is a ? which binds to the CD40 cytoplasmic domain
GGP GGP PDR
(b)
HMG-I binds to GATA motifs
GGP DDR
(c)
alpha B2 bound the PEBP2 site within the GM-CSF promoter
GGP GGPDDR DDR
Figure 2: Entity annotation to example sentences
from (a) PMID10080948, (b) PMID7575565, and (c)
PMID7605990 (simplified).
(a)
Ah receptor recognizes the B cell transcription factor, BSAP
(b)
Grf40 binds to linker for activation of T cells (LAT)
(c)
expression of p21(WAF1/CIP1) and p27(KIP1)
(d)
included both p50/p50 and p50/p65 dimers
(e)
IL-4 Stat, also known as Stat6
Figure 3: Equivalent entities in example sentences from
(a) PMID7541987 (simplified), (b) PMID10224278, (c)
PMID10090931, (d) PMID9243743, (e) PMID7635985.
(Type:Binding, Theme1:TRAF2, Theme2:CD40,
Site2:cytoplasmic domain)
Note that the protein, CD40, and its domain, cyto-
plasmic domain, are associated by argument num-
bering. To resolve issues related to the mapping
between proteins and related entities systematically,
we introduced partial static relation annotation for
relations such as Part-Whole, drawing in part on
similar annotation of the BioInfer corpus (Pyysalo
et al, 2007). For details of this part of the revision
process, we refer to (Pyysalo et al, 2009).
Figure 2 shows some challenging cases. In (b),
the site GATA motifs is not identified as an argument
of the binding event, because the protein containing
it is not stated. In (c), among the two sites (PEBP2
site and promoter) of the gene GM-CSF, only the
more specific one, PEBP2, is annotated.
3.3 Equivalent entity references
Alternative names for the same object are fre-
quently introduced in biomedical texts, typically
through apposition. This is illustrated in Figure 3(a),
where the two expressions B cell transcription fac-
tor and BSAP are in apposition and refer to the
same protein. Consequently, in this case the fol-
lowing two annotations represent the same event:
(Type:Binding, Theme:Ah receptor,
Theme:B cell transcription factor)
(Type:Binding, Theme:Ah receptor, Theme:BSAP)
In the GENIA event corpus only one of these is an-
notated, with preference given to shorter names over
longer descriptive ones. Thus of the above exam-
ple events, the latter would be annotated. How-
ever, as both express the same event, in the shared
task evaluation either alternative was accepted as
correct extraction of the event. In order to im-
plement this aspect of the evaluation, expressions
of equivalent entities were annotated as follows:
Eq (B cell transcription factor, BSAP)
The equivalent entity annotation in the revised GE-
NIA corpus covers also cases other than simple ap-
position, illustrated in Figure 3. A frequent case in
biomedical literature involves use of the slash sym-
bol (?/?) to state synonyms. The slash symbol is
ambiguous as it is used also to indicate dimerized
proteins. In the case of p50/p50, the two p50 are
annotated as equivalent because they represent the
same proteins at the same state. Note that although
rare, also explicitly introduced aliases are annotated,
as in Figure 3(e).
4 Evaluation
For the evaluation, the participants were given the
test data with gold annotation only for proteins. The
evaluation was then carried out by comparing the
annotation predicted by each participant to the gold
annotation. For the comparison, equality of anno-
tations is defined as described in Section 4.1. The
evaluation results are reported using the standard
recall/precision/f-score metrics, under different cri-
teria defined through the equalities.
4.1 Equalities and Strict matching
Equality of events is defined as follows:
Event Equality equality holds between any two
events when (1) the event types are the same,
(2) the event triggers are the same, and (3) the
arguments are fully matched.
4
A full matching of arguments between two events
means there is a perfect 1-to-1 mapping between the
two sets of arguments. Equality of individual argu-
ments is defined as follows:
Argument Equality equality holds between any
two arguments when (1) the role types are the
same, and (2-1) both are t-entities and equality
holds between them, or (2-2) both are events
and equality holds between them.
Due to the condition (2-2), event equality is defined
recursively for events referring to events. Equality
of t-entities is defined as follows:
T-entity Equality equality holds between any two
t-entities when (1) the entity types are the same,
and (2) the spans are the same.
Any two text spans (beg1, end1) and (beg2, end2),
are the same iff beg1 = beg2 and end1 = end2.
Note that the event triggers are also t-entities thus
their equality is defined by the t-entity equality.
4.2 Evaluation modes
Various evaluation modes can be defined by varying
equivalence criteria. In the following, we describe
three fundamental variants applied in the evaluation.
Strict matching The strict matching mode requires
exact equality, as defined in section 4.1. As some
of its requirements may be viewed as unnecessarily
precise, practically motivated relaxed variants, de-
scribed in the following, are also applied.
Approximate span matching The approximate
span matching mode is defined by relaxing the
requirement for text span matching for t-entities.
Specifically, a given span is equivalent to a gold
span if it is entirely contained within an extension
of the gold span by one word both to the left and
to the right, that is, beg1 ? ebeg2 and end1 ?
eend2, where (beg1, end1) is the given span and
(ebeg2, eend2) is the extended gold span.
Approximate recursive matching In strict match-
ing, for a regulation event to be correct, the events it
refers to as theme or cause must also be be strictly
correct. The approximate recursive matching mode
is defined by relaxing the requirement for recursive
event matching, so that an event can match even
if the events it refers to are only partially correct.
Event Release date
Announcement Dec 8
Sample data Dec 15
Training data Jan 19 ? 21, Feb 2 (rev1), Feb 10 (rev2)
Devel. data Feb 7
Test data Feb 22 ? Mar 2
Submission Mar 2 ? Mar 9
Table 3: Shared task schedule. The arrows indicate a
change of schedule.
Specifically, for partial matching, only Theme argu-
ments are considered: events can match even if re-
ferred events differ in non-Theme arguments.
5 Schedule
The BioNLP task was held for 12 weeks, from the
sample data release to the final submission. It in-
cluded 5 weeks of system design period with sam-
ple data, 6 weeks of system development period with
training and development data, and a 1 week test pe-
riod. The system development period was originally
planned for 5 weeks but extended by 1 week due to
the delay of the training data release and the revi-
sion. Table 3 shows key dates of the schedule.
6 Supporting Resources
To allow participants to focus development efforts
on novel aspects of event extraction, we prepared
publicly available BioNLP resources readily avail-
able for the shared task. Several fundamental
BioNLP tools were provided through U-Compare
(Kano et al, 2009)2, which included tools for to-
kenization, sentence segmentation, part-of-speech
tagging, chunking and syntactic parsing.
Participants were also provided with the syntactic
analyses created by a selection of parsers. We ap-
plied two mainstream Penn Treebank (PTB) phrase
structure parsers: the Bikel parser3, implementing
Collins? parsing model (Bikel, 2004) and trained
on PTB, and the reranking parser of (Charniak
and Johnson, 2005) with the self-trained biomed-
ical parsing model of (McClosky and Charniak,
2008)4. We also applied the GDep5, native de-
pendency parser trained on the GENIA Treebank
2http://u-compare.org/
3http://www.cis.upenn.edu/?dbikel/software.html
4http://www.cs.brown.edu/?dmcc/biomedical.html
5http://www.cs.cmu.edu/?sagae/parser/gdep/
5
NLP Task
Team Task Org Word Chunking Parsing Trigger Argument Ext. Resources
UTurku 1-- 3C+2BI Porter MC SVM SVM (SVMlight)
JULIELab 1-- 1C+2L+2B OpenNLP OpenNLP GDep Dict+Stat SVM(libSVM) UniProt, Mesh,
Porter ME(Mallet) GOA, UMLS
ConcordU 1-3 3C Stanford Stanford Dict+Stat Rules WordNet, VerbNet,
UMLS
UT+DBCLS 12- 2C Porter MC Dict MLN(thebeast)
CCG
VIBGhent 1-3 2C+1B Porter, Stanford Dict SVM(libSVM)
UTokyo 1-- 3C GTag GDep, Dict ME(liblinear) UIMA
Enju
UNSW 1-- 1C+1B GDep CRF Rules WordNet, MetaMap
UZurich 1-- 3C LingPipe, LTChunk Pro3Gres Dict Rules
Morpha
ASU+HU+BU 123 6C+2BI Porter BioLG, Dict Rules Lucene
Charniak Rules
Cam 1-- 3C Porter RASP Dict Rules
UAntwerp 12- 3C GTag GDep MBL MBL(TiMBL)
Rules
UNIMAN 1-- 4C+2BI Porter GDep Dict, CRF SVM MeSH, GO
GTag Rules
SCAI 1-- 1C Rules
UAveiro 1-- 1C+1L NooJ NooJ Rules BioLexicon
USzeged 1-3 3C+1B GTag Dict, VSM C4.5(WEKA) BioScope
Rules
NICTA 1-3 4C GTag ERG CRF(CRF++) Rules JULIE
CNBMadrid 12- 2C+1B Porter, GTag CBR
GTag Rules
CCP-BTMG 123 7C LingPipe LingPipe OpenDMAP LingPipe, CM Rules GO, SO, MIO,
UIMA
CIPS-ASU 1-- 3C MontyTagger Custom Stanford CRF(ABNER) Rules,
NB(WEKA)
UMich 1-- 2C Stanford MC Dict SVM(SVMlight)
PIKB 1-- 5C+2B MIRA MIRA
KoreaU 1-- 5C GTag GDep Rules, ME ME WSJ
Table 4: Profiles of the participants: GTag=GENIAtagger, MLN=Markov Logic Network, UMLS=UMLS SPE-
CIALIST Lexicon/tools, MC=McClosky-Charniak, GDep=Genia Dependency Parser, Stanford=Stanford Parser,
CBR=Case-Based Reasoning, CM=ConceptMapper.
(Tateisi et al, 2005), and a version of the C&C CCG
deep parser6 adapted to biomedical text (Rimell and
Clark, 2008).
The text of all documents was segmented and to-
kenized using the GENIA Sentence Splitter and the
GENIA Tagger, provided by U-Compare. The same
segmentation was enforced for all parsers, which
were run using default settings. Both the native out-
put of each parser and a representation in the popular
Stanford Dependency (SD) format (de Marneffe et
al., 2006) were provided. The SD representation was
created using the Stanford tools7 to convert from the
PTB scheme, the custom conversion introduced by
(Rimell and Clark, 2008) for the C&C CCG parser,
and a simple format-only conversion for GDep.
7 Results and Discussion
7.1 Participation
In total, 42 teams showed interest in the shared task
and registered for participation, and 24 teams sub-
6http://svn.ask.it.usyd.edu.au/trac/candc/wiki
7http://nlp.stanford.edu/software/lex-parser.shtml
mitted final results. All 24 teams participated in the
obligatory Task 1, six in each of Tasks 2 and 3, and
two teams completed all the three tasks.
Table 4 shows a profile of the 22 final teams,
excepting two who wished to remain anonymous.
A brief examination on the team organization (the
Org column) shows a computer science background
(C) to be most frequent among participants, with
less frequent participation from bioinformaticians
(BI), biologists (B) and liguists (L). This may be
attributed in part to the fact that the event extrac-
tion task required complex computational modeling.
The role of computer scientists may be emphasized
in part due to the fact that the task was novel to most
participants, requiring particular efforts in frame-
work design and implementation and computational
resources. This also suggests there is room for im-
provement from more input from biologists.
7.2 Evaluation results
The final evaluation results of Task 1 are shown in
Table 5. The results on the five event types involv-
6
Team Simple Event Binding Regulation All
UTurku 64.21 / 77.45 / 70.21 40.06 / 49.82 / 44.41 35.63 / 45.87 / 40.11 46.73 / 58.48 / 51.95
JULIELab 59.81 / 79.80 / 68.38 49.57 / 35.25 / 41.20 35.03 / 34.18 / 34.60 45.82 / 47.52 / 46.66
ConcordU 49.75 / 81.44 / 61.76 20.46 / 40.57 / 27.20 27.47 / 49.89 / 35.43 34.98 / 61.59 / 44.62
UT+DBCLS 55.75 / 72.74 / 63.12 23.05 / 48.19 / 31.19 26.32 / 41.81 / 32.30 36.90 / 55.59 / 44.35
VIBGhent 54.48 / 79.31 / 64.59 38.04 / 38.60 / 38.32 17.36 / 31.61 / 22.41 33.41 / 51.55 / 40.54
UTokyo 45.69 / 72.19 / 55.96 34.58 / 50.63 / 41.10 14.22 / 34.26 / 20.09 28.13 / 53.56 / 36.88
UNSW 45.85 / 69.94 / 55.39 23.63 / 37.27 / 28.92 16.58 / 28.27 / 20.90 28.22 / 45.78 / 34.92
UZurich 44.92 / 66.62 / 53.66 30.84 / 37.28 / 33.75 14.82 / 30.21 / 19.89 27.75 / 46.60 / 34.78
ASU+HU+BU 45.09 / 76.80 / 56.82 19.88 / 44.52 / 27.49 05.20 / 33.46 / 09.01 21.62 / 62.21 / 32.09
Cam 39.17 / 76.40 / 51.79 12.68 / 31.88 / 18.14 09.98 / 37.76 / 15.79 21.12 / 56.90 / 30.80
UAntwerp 41.29 / 65.68 / 50.70 12.97 / 31.03 / 18.29 11.07 / 29.85 / 16.15 22.50 / 47.70 / 30.58
UNIMAN 50.00 / 63.21 / 55.83 12.68 / 40.37 / 19.30 04.05 / 16.75 / 06.53 22.06 / 48.61 / 30.35
SCAI 43.74 / 70.73 / 54.05 28.82 / 35.21 / 31.70 12.64 / 16.55 / 14.33 25.96 / 36.26 / 30.26
UAveiro 43.57 / 71.63 / 54.18 13.54 / 34.06 / 19.38 06.29 / 21.05 / 09.69 20.93 / 49.30 / 29.38
Team 24 41.29 / 64.72 / 50.41 22.77 / 35.43 / 27.72 09.38 / 19.23 / 12.61 22.69 / 40.55 / 29.10
USzeged 47.63 / 44.44 / 45.98 15.27 / 25.73 / 19.17 04.17 / 18.21 / 06.79 21.53 / 36.99 / 27.21
NICTA 31.13 / 77.31 / 44.39 16.71 / 29.00 / 21.21 07.80 / 18.12 / 10.91 17.44 / 39.99 / 24.29
CNBMadrid 50.25 / 46.59 / 48.35 33.14 / 20.54 / 25.36 12.22 / 07.99 / 09.67 28.63 / 20.88 / 24.15
CCP-BTMG 28.17 / 87.63 / 42.64 12.68 / 40.00 / 19.26 03.09 / 48.11 / 05.80 13.45 / 71.81 / 22.66
CIPS-ASU 39.68 / 38.60 / 39.13 17.29 / 31.58 / 22.35 11.86 / 08.15 / 09.66 22.78 / 19.03 / 20.74
UMich 52.71 / 25.89 / 34.73 31.70 / 12.61 / 18.05 14.22 / 06.56 / 08.98 30.42 / 14.11 / 19.28
PIKB 26.65 / 75.72 / 39.42 07.20 / 39.68 / 12.20 01.09 / 30.51 / 02.10 11.25 / 66.54 / 19.25
Team 09 27.16 / 43.61 / 33.47 03.17 / 09.82 / 04.79 02.42 / 11.90 / 04.02 11.69 / 31.42 / 17.04
KoreaU 20.56 / 66.39 / 31.40 12.97 / 50.00 / 20.59 00.67 / 37.93 / 01.31 09.40 / 61.65 / 16.31
Table 5: Evaluation results of Task 1 (recall / precision / f-score).
Team All Site for Phospho.(56) AtLoc & ToLoc (65) All Second Args.
UT+DBCLS 35.86 / 54.08 / 43.12 71.43 / 71.43 / 71.43 23.08 / 88.24 / 36.59 32.14 / 72.41 / 44.52
UAntwerp 21.52 / 45.77 / 29.27 00.00 / 00.00 / 00.00 01.54 /100.00 / 03.03 06.63 / 52.00 / 11.76
ASU+HU+BU 19.70 / 56.87 / 29.26 00.00 / 00.00 / 00.00 00.00 / 00.00 / 00.00 00.00 / 00.00 / 00.00
Team 24 22.08 / 38.28 / 28.01 55.36 / 93.94 / 69.66 21.54 / 66.67 / 32.56 30.10 / 76.62 / 43.22
CCP-BTMG 13.25 / 70.97 / 22.33 30.36 /100.00 / 46.58 00.00 / 00.00 / 00.00 08.67 /100.00 / 15.96
CNBMadrid 25.02 / 18.32 / 21.15 85.71 / 57.14 / 68.57 32.31 / 47.73 / 38.53 50.00 / 09.71 / 16.27
Table 6: Evaluation results for Task 2.
ing only a single primary theme argument are shown
in one merged class, ?Simple Event?. The broad per-
formance range (31% ? 70%) indicates even the ex-
traction of simple events is not a trivial task. How-
ever, the top-ranked systems show encouraging per-
formance, achieving or approaching 70% f-score.
The performance ranges for Binding (5% ? 44%)
and Regulation (1% ? 40%) events show their ex-
traction to be clearly more challenging. It is in-
teresting that while most systems show better per-
formance for binding over regulation events, the
systems [ConcordU] and [UT+DBCLS] are better
for regulation, showing somewhat reduced perfor-
mance for Binding events. This is in particular con-
trast to the following two systems, [ViBGhent] and
[UTokyo], which show far better performance for
Binding than Regulation events. As one possible
explanation, we find that the latter two differentiate
binding events by their number of themes, while the
former two give no specific treatment to multi-theme
binding events. Such observations and comparisons
are a clear benefit of a community-wide shared task.
Table 6 shows the evaluation results for the teams
who participated in Task 2. The ?All? column shows
the overall performance of the systems for Task 2,
while the ?All Second Args.? column shows the
performance of finding only the secondary argu-
ments. The evaluation results show considerable
differences between the criteria. For example, the
system [Team 24] shows performance comparable
to the top ranked system in finding secondary argu-
ments, although its overall performance for Task 2
is more limited. Table 6 also shows the three sys-
tems, [UT+DBCLS], [Team 24] and [CNBMadrid],
7
Team Negation Speculation
ConcordU 14.98 / 50.75 / 23.13 16.83 / 50.72 / 25.27
VIBGhent 10.57 / 45.10 / 17.13 08.65 / 15.79 / 11.18
ASU+HU+BU 03.96 / 27.27 / 06.92 06.25 / 28.26 / 10.24
NICTA 05.29 / 34.48 / 09.17 04.81 / 30.30 / 08.30
USzeged 05.29 / 01.94 / 02.84 12.02 / 03.88 / 05.87
CCP-BTMG 01.76 / 05.26 / 02.64 06.73 / 13.33 / 08.95
Table 7: Evaluation results for Task 3.
 0
 10
 20
 30
 40
 50
 60
02/18 02/21 02/24 02/27 03/02 03/05 03/08
daily average
Figure 4: Scatterplot of the evaluation results on the de-
velopment data during the system development period.
show performance at a practical level in particular in
finding specific sites of phosphorylation.
As shown in Table 7, the performance range for
Task 3 is very low although the representation of the
task is as simple as the simple events. We attribute
the reason to the fact that Task 3 is the only task of
which the annotation is not bound to textual clue,
thus no text-bound annotation was provided.
Figure 4 shows a scatter plot of the performance
of the participating systems during the system devel-
opment period. The performance evaluation comes
from the log of the online evaluation system on the
development data. It shows the best performance
and the average performance of the participating
systems were trending upwards up until the dead-
line of final submission, which indicates there is still
much potential for improvement.
7.3 Ensemble
Table 8 shows experimental results of a system en-
semble using the final submissions. For the ex-
periments, the top 3?10 systems were chosen, and
the output of each system treated as a weighted
vote8. Three weighting schemes were used; ?Equal?
weights each vote equally; ?Averaged? weights each
8We used the ?ensemble? function of U-Compare.
Ensemble Equal Averaged Event Type
Top 3 53.19 53.19 54.08
Top 4 54.34 54.34 55.21
Top 5 54.77 55.03 55.10
Top 6 55.13 55.77 55.96
Top 7 54.33 55.45 55.73
Top 10 52.79 54.63 55.18
Table 8: Experimental results of system ensemble.
vote by the overall f-score of the system; ?Event
Type? weights each vote by the f-score of the sys-
tem for the specific event type. The best score,
55.96%, was obtained by the ?Event Type? weight-
ing scheme, showing a 4% unit improvement over
the best individual system. While using the final
scores for weighting uses data that would not be
available in practice, similar weighting could likely
be obtained e.g. using performance on the devel-
opment data. The experiment demonstrates that an
f-score better than 55% can be achieved simply by
combining the strengths of the systems.
8 Conclusion
Meeting with the community-wide participation, the
BioNLP Shared Task was successful in introducing
fine-grained event extraction to the domain. The
evaluation results of the final submissions from the
participants are both promising and encouraging for
the future of this approach to IE. It has been revealed
that state-of-the-art performance in event extraction
is approaching a practically applicable level for sim-
ple events, and also that there are many remain-
ing challenges in the extraction of complex events.
A brief analysis suggests that the submitted data
together with the system descriptions are rich re-
sources for finding directions for improvements. Fi-
nally, the experience of the shared task participants
provides an invaluable basis for cooperation in fac-
ing further challenges.
Acknowledgments
This work was partially supported by Grant-in-Aid
for Specially Promoted Research (MEXT, Japan)
and Genome Network Project (MEXT, Japan).
8
References
Gary D. Bader, Michael P. Cary, and Chris Sander. 2006.
Pathguide: a Pathway Resource List. Nucleic Acids
Research., 34(suppl 1):D504?506.
Daniel M. Bikel. 2004. Intricacies of Collins? Parsing
Model. Computational Linguistics, 30(4):479?511.
Evelyn Camon, Michele Magrane, Daniel Barrell, Vi-
vian Lee, Emily Dimmer, John Maslen, David Binns,
Nicola Harte, Rodrigo Lopez, and Rolf Apweiler.
2004. The Gene Ontology Annotation (GOA)
Database: sharing knowledge in Uniprot with Gene
Ontology. Nucl. Acids Res., 32(suppl 1):D262?266.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL?05), pages 173?180.
Andrew Chatr-aryamontri, Arnaud Ceol, Luisa Montec-
chi Palazzi, Giuliano Nardelli, Maria Victoria Schnei-
der, Luisa Castagnoli, and Gianni Cesareni. 2007.
MINT: the Molecular INTeraction database. Nucleic
Acids Research, 35(suppl 1):D572?574.
Nancy Chinchor. 1998. Overview of MUC-7/MET-2.
In Message Understanding Conference (MUC-7) Pro-
ceedings.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
William Hersh, Aaron Cohen, Ruslenm Lynn, , and
Phoebe Roberts. 2007. TREC 2007 Genomics track
overview. In Proceeding of the Sixteenth Text RE-
trieval Conference.
Lynette Hirschman, Martin Krallinger, and Alfonso Va-
lencia, editors. 2007. Proceedings of the Second
BioCreative Challenge Evaluation Workshop. CNIO
Centro Nacional de Investigaciones Oncolo?gicas.
Yoshinobu Kano, William Baumgartner, Luke McCro-
hon, Sophia Ananiadou, Kevin Cohen, Larry Hunter,
and Jun?ichi Tsujii. 2009. U-Compare: share and
compare text mining tools with UIMA. Bioinformat-
ics. To appear.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier. 2004. Introduction
to the bio-entity recognition task at JNLPBA. In Pro-
ceedings of the International Joint Workshop on Nat-
ural Language Processing in Biomedicine and its Ap-
plications (JNLPBA), pages 70?75.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
lterature. BMC Bioinformatics, 9(1):10.
David McClosky and Eugene Charniak. 2008. Self-
Training for Biomedical Parsing. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics - Human Language Technolo-
gies (ACL-HLT?08), pages 101?104.
Claire Ne?dellec. 2005. Learning Language in Logic -
Genic Interaction Extraction Challenge. In J. Cussens
and C. Ne?dellec, editors, Proceedings of the 4th Learn-
ing Language in Logic Workshop (LLL05), pages 31?
37.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, and
Jun?ichi Tsujii. 2009. Incorporating GENETAG-style
annotation to GENIA corpus. In Proceedings of Nat-
ural Language Processing in Biomedicine (BioNLP)
NAACL 2009 Workshop. To appear.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static Relations: a Piece
in the Biomedical Information Extraction Puzzle.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop. To
appear.
Laura Rimell and Stephen Clark. 2008. Porting a
lexicalized-grammar parser to the biomedical domain.
Journal of Biomedical Informatics, To Appear.
Stephanie Strassel, Mark Przybocki, Kay Peterson, Zhiyi
Song, and Kazuaki Maeda. 2008. Linguistic Re-
sources and Evaluation Techniques for Evaluation of
Cross-Document Automatic Content Extraction. In
Proceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008).
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne Mat-
ten, and John Wilbur. 2005. Genetag: a tagged cor-
pus for gene/protein named entity recognition. BMC
Bioinformatics, 6(Suppl 1):S3.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun?ichi Tsujii. 2005. Syntax Annotation for the GE-
NIA corpus. In Proceedings of the IJCNLP 2005,
Companion volume, pages 222?227.
Ellen Voorhees. 2007. Overview of TREC 2007. In
The Sixteenth Text REtrieval Conference (TREC 2007)
Proceedings.
John Wilbur, Lawrence Smith, and Lorraine Tanabe.
2007. BioCreative 2. Gene Mention Task. In
L. Hirschman, M. Krallinger, and A. Valencia, editors,
Proceedings of Second BioCreative Challenge Evalu-
ation Workshop, pages 7?16.
9
Analysis of Link Grammar on Biomedical Dependency Corpus
Targeted at Protein-Protein Interactions
Sampo Pyysalo, Filip Ginter, Tapio Pahikkala,
Jorma Boberg, Jouni Ja?rvinen, Tapio Salakoski
Turku Centre for Computer Science (TUCS)
and Dept. of computer science, University of Turku
Lemminka?isenkatu 14A
20520 Turku, Finland,
first name.last name@it.utu.fi
Jeppe Koivula
MediCel Ltd.,
Haartmaninkatu 8
00290 Helsinki, Finland,
jeppe.koivula@medicel.com
Abstract
In this paper, we present an evaluation of the
Link Grammar parser on a corpus consisting
of sentences describing protein-protein interac-
tions. We introduce the notion of an interac-
tion subgraph, which is the subgraph of a de-
pendency graph expressing a protein-protein in-
teraction. We measure the performance of the
parser for recovery of dependencies, fully correct
linkages and interaction subgraphs. We analyze
the causes of parser failure and report specific
causes of error, and identify potential modifica-
tions to the grammar to address the identified
issues. We also report and discuss the effect of
an extension to the dictionary of the parser.
1 Introduction
The challenges of processing the vast amounts of
biomedical publications available in databases
such as MEDLINE have recently attracted a
considerable interest in the Natural Language
Processing (NLP) research community. The
task of information extraction, commonly tar-
geting entity relationships, such as protein-
protein interactions, is an often studied prob-
lem to which various NLP methods have been
applied, ranging from keyword-based methods
(see, e.g., Ginter et al (2004)) to full syntactic
analysis as employed, for example, by Craven
and Kumlien (1999), Temkin and Gilder (2003)
and Daraselia et al (2004).
In this paper, we focus on the syntactic anal-
ysis component of an information extraction
system targeted to find protein-protein inter-
actions from the dependency output produced
by the Link Grammar1 (LG) parser of Sleator
and Temperley (1991). Two recent papers study
LG in the context of biomedical NLP. The work
by Szolovits (2003) proposes a fully automated
method to extend the dictionary of the LG
1http://www.link.cs.cmu.edu/link/
parser with the UMLS Specialist2 lexicon, and
Ding et al (2003) perform a basic evaluation
of LG performance on biomedical text. As both
papers suggest, LG will require modifications in
order to provide a correct analysis of grammat-
ical phenomena that are rare in general English
text, but common in biomedical language. Im-
plementing such modifications is a major effort
that requires a careful analysis of the perfor-
mance of the LG parser to identify the most
common causes of parsing failures and to target
modification efforts.
While Szolovits (2003) does not attempt to
evaluate parser performance at all and Ding
et al (2003) provide only an informal evalua-
tion on manually simplified sentences, we focus
on a more formal evaluation of the LG parser.
For the purpose of this study and also for sub-
sequent research of biomedical information ex-
traction with the LG parser, we have developed
a hand-annotated corpus consisting of unmod-
ified sentences from publications. We use this
corpus to evaluate the performance of the LG
parser and to identify problems and potential
improvements to the grammar and parser.
2 Link Grammar and parser
The Link Grammar and its parser represent an
implementation of a dependency-based compu-
tational grammar. The result of LG analysis for
a sentence is a labeled undirected simple graph,
whose nodes represent the words of the sentence
and whose edges and their labels express the
grammatical relationships between the words.
In LG terminology, the graph is called a link-
age, and its edges are called links. The linkage
must be planar (i.e., links must not cross) when
drawn above the words of the sentence, and the
labels of the links must satisfy the linking con-
straints specified for each word in the grammar.
A connected linkage is termed complete.
2http://www.nlm.nih.gov/research/umls/
15
findings suggest that PIP2 binds to proteins such as profilin
Figure 1: Annotation example. The interaction of two proteins, PIP2 and profilin, is stated by
the words binds to. The links joining these words form the interaction subgraph (drawn with solid
lines).
Due to the structural ambiguity of natural
language, several linkages can typically be con-
structed for an input sentence. In such cases,
the LG parser enumerates all linkages allowed
by the grammar. A post-processing step is then
employed to enforce a number of additional con-
straints. The number of linkages for some sen-
tences can be very high, making post-processing
and storage prohibitively expensive. This prob-
lem is addressed in the LG parser by defining
kmax, the maximal number of linkages to be
post-processed. If the parsing algorithm pro-
duces more than kmax linkages, the output is
reduced to kmax linkages by random sampling.
The linkages are then ordered from best to worst
using heuristic goodness criteria.
In order to be usable in practice, a parser is
typically required to provide a partial analysis
of a sentence for which it cannot construct a full
analysis. If the LG parser cannot construct a
complete linkage for a sentence, the connected-
ness requirement is relaxed so that some words
do not belong to the linkage at all. The LG
parser is also time-limited. If the full set of
linkages cannot be constructed in a given time
tmax, the parser enters a panic mode, in which it
performs an efficient but considerably restricted
parse, resulting in reduced performance. The
parameters tmax and kmax set the trade-off be-
tween the qualitative performance and the re-
source efficiency of the parser.
3 Corpus annotation and interaction
subgraphs
To compile a corpus of sentences describing
protein-protein interactions, we first selected
pairs of proteins that are known to interact
from the Database of Interacting Proteins3. We
entered these pairs as search terms into the
PubMed retrieval system. We then split the
publication abstracts returned by the searches
into sentences and included titles. These were
again searched for the protein pairs. This gave
us a set of 1927 sentences that contain the
3http://dip.doe-mbi.ucla.edu/
names of at least two proteins that are known
to interact. A domain expert annotated these
sentences for protein names and for words stat-
ing their interactions. Of these sentences, 1114
described at least one protein-protein interac-
tion.
Thereafter, we performed a dependency anal-
ysis and produced annotation of dependencies.
To minimize the amount of mistakes, each sen-
tence was independently annotated by two an-
notators and differences were then resolved by
discussion. The assigned dependency structure
was produced according to the LG linkage con-
ventions. Link types were not included in the
annotation, and no cycles were introduced in
the dependency graphs. All ambiguities where
the LG parser is capable of at least enumerat-
ing all alternatives (such as prepositional phrase
attachment) were enforced in the annotation.
A random sample consisting of 300 sentences,
including 28 publication titles, has so far been
fully annotated, giving 7098 word-to-word de-
pendencies. This set of sentences is the corpus
we refer to in the following sections.
An information extraction system targeted
at protein-protein interactions and their types
needs to identify three constituents that express
an interaction in a sentence: the proteins in-
volved and the word or phrase that states their
interaction and suggests the type of this inter-
action. To extract this information from a LG
linkage, the links connecting these items must
be recovered correctly by the parser. The fol-
lowing definition formalizes this notion.
Definition 1 (Interaction subgraph) The
interaction subgraph for an interaction between
two proteins A and B in a linkage L is the
minimal connected subgraph of L that contains
A, B, and the word or phrase that states their
interaction.
The recovery of a connected component con-
taining the protein names and the interaction
word is not sufficient: by the definition of a
complete linkage, such a component is always
present. Consequently, the exact set of links
16
that forms the interaction subgraph must be re-
covered.
For each interaction stated in a sentence,
the corpus annotation specifies the proteins in-
volved and the interaction word. The interac-
tion subgraph for each interaction can thus be
extracted automatically from the corpus. Be-
cause the corpus does not contain cyclic depen-
dencies, the interaction subgraphs are unique.
366 interaction subgraphs were identified from
the corpus, one for each described interaction.
The interaction subgraphs can be partially over-
lapping, because a single link can be part of
more than one interaction subgraph. Figure 1
shows an example of an annotated text frag-
ment.
4 Evaluation criteria
We evaluated the performance of the LG parser
according to the following three quantitative cri-
teria:
? Number of dependencies recovered
? Number of fully correct linkages
? Number of interaction subgraphs recovered
The number of recovered dependencies gives an
estimate of the probability that a dependency
will be correctly identified by the LG parser
(this criterion is also employed by, e.g., Collins
et al (1999)). The number of fully correct link-
ages, i.e. linkages where all annotated depen-
dencies are recovered, measures the fraction of
sentences that are parsed without error. How-
ever, a fully correct linkage is not necessary to
extract protein-protein interactions from a sen-
tence; to estimate how many interactions can
potentially be recovered, we measure the num-
ber of interaction subgraphs for which all de-
pendencies were recovered.
For each criterion, we measure the perfor-
mance for the first linkage returned by the
parser. However, the first linkage as ordered
by the heuristics of the LG parser was often not
the best (according to the criteria above) of the
linkages returned by the parser. To separate
the effect of the heuristics from overall LG per-
formance, we identify separately for each of the
three criteria the best linkage among the link-
ages returned by the parser, and we also report
performance for the best linkages.
We further divide the parsed sentences into
three categories: (1) sentences for which the
time tmax for producing a normal parse was ex-
hausted and the parser entered panic mode, (2)
sentences where linkages were sampled because
more than kmax linkages were produced, and
(3) stable sentences for which neither of these
occurred. A full analysis of all linkages that
the grammar allows is only possible for stable
sentences. For sentences in the other two cat-
egories, random effects may affect the results:
sentences for which more than kmax linkages are
produced are subject to randomness in sam-
pling, and sentences where the parser enters
panic mode were always subject to subsequent
sampling in our experiments.
5 Evaluation
To evaluate the ability of the LG parser to pro-
duce correct linkages, we increased the number
of stable sentences by setting the tmax param-
eter to 10 minutes and the kmax parameter to
10000 instead of using the defaults tmax = 30
seconds and kmax = 1000. When parsing the
corpus using these parameters, 28 sentences fell
into the panic category, 61 into the sampled
category, and 211 were stable. The measured
parser performance for the corpus is presented
in Table 1.
While the fraction of sentences that have a
fully correct linkage as the first linkage is quite
low (approximately 7%), for 28% of sentences
the parser is capable of producing a fully cor-
rect linkage. Performance was especially poor
for the publication titles in the corpus. Because
titles are typically fragments not containing a
verb, and LG is designed to model full clauses,
the parser failed to produce a fully correct link-
age for any of the titles.
The performance for recovered interaction
subgraphs is more encouraging, as 25% of the
subgraphs were recovered in the first linkage and
more than half in the best linkage. Yet many in-
teraction subgraphs remain unrecovered by the
parser: the results suggest an upper limit of
approximately 60% to the fraction of protein-
protein interactions that can be recovered from
any linkage produced by the unmodified LG.
In the following sections we further analyze the
reasons why the parser fails to recover all de-
pendencies.
5.1 Panics
No fully correct linkages and very few interac-
tion subgraphs were found in the panic mode.
This effect may be partly due to the complex-
ity of the sentences for which the parser en-
17
Category
Criterion Linkage Stable Sampled Panic Overall
Dependency First linkage 3242 (80.0%) 1376 (74.3%) 569 (52.3%) 5187 (73.1%)
Best linkage 3601 (86.6%) 1576 (85.0%) 620 (57.0%) 5797 (81.7%)
Total 4157 1853 1088 7098
Fully correct First linkage 22 (10.4%) 0 (0.0%) 0 (0.0%) 22 (7.3%)
Best linkage 79 (37.4%) 6 (9.8%) 0 (0.0%) 85 (28.3%)
Total 211 61 28 300
Interaction First linkage 75 (30.5%) 16 (20.2%) 0 (0.0%) 91 (24.9%)
subgraph Best linkage 156 (63.4%) 49 (62.0%) 4 (9.8%) 209 (57.1%)
Total 246 79 41 366
Table 1: Parser performance. The fraction of fulfilled criteria is shown by category (the criteria and
categories are explained in Section 4). The total rows give the number of criteria for each category,
and the overall column gives combined results for all categories.
tered panic mode. The effect of panics can
be better estimated by forcing the parser to
bypass standard parsing and to directly apply
panic options. For the 272 sentences where the
parser did not enter the panic mode, 77% of
dependencies were recovered in the first link-
age. When these sentences were parsed in forced
panic mode, 67% of dependencies were recov-
ered, suggesting that on average parses in panic
mode recover approximately 10% fewer depen-
dencies than in standard parsing mode. Simi-
larly, the number of fully correct first linkages
decreased from 22 to 6 and the number of inter-
action subgraphs recovered in the first linkage
from 91 to 65. These numbers indicate that
panics are a significant cause of error.
Experiments indicate than on a 1GHz ma-
chine approximately 40% of sentences can be
fully parsed in under a second, 80% in under 10
seconds and 90% within 10 minutes; yet approx-
imately 5% of sentences take more than an hour
to fully parse. With tmax set to 10 minutes, the
total parsing time was 165 minutes.
Long parsing times are caused by ambiguous
sentences for which the parser creates thousands
or even millions of alternative linkages. In ad-
dition to simply increasing the time limit, the
fraction of sentences where the parser enters the
panic mode could therefore be reduced by re-
ducing the ambiguity of the sentences, for ex-
ample, by extending the dictionary of the parser
(see Section 7).
5.2 Heuristics
When several linkages are produced for a sen-
tence, the LG parser applies heuristics to or-
der the sentences so that linkages that are more
likely to be correct are presented first. The
heuristics are based on examination and intu-
itions on general English, and may not be opti-
mal for biomedical text. Note in Table 1 that
both for recovered full linkages and interaction
subgraphs, the number of items that were recov-
ered in the best linkage is more than twice the
number recovered in the first linkage, suggesting
that a better ordering heuristic could dramat-
ically improve the performance of the parser.
Such improvements could perhaps be achieved
by tuning the heuristics to the domain or by
adopting a probabilistic ordering model.
6 Failure analysis
A significant fraction of dependencies were not
recovered in any linkage, even in sentences
where resources were not exhausted. In order to
identify reasons for the parser failing to recover
the correct dependencies, we analyze sentences
for which it is certain that the grammar cannot
produce a fully correct linkage. We thus ana-
lyzed the 132 stable sentences for which some
dependencies were not recovered.
For each sentence, we attempt to identify the
reason for the failure of the parser. For each
identified reason, we manually edit the sentence
to remove the source of failure. We repeat this
procedure until the parser is capable of pro-
ducing a correct parse for the sentence. Note
that this implies that also the interaction sub-
graphs in the sentence are correctly recovered,
and therefore the reasons for failures to recover
interaction subgraphs are a subset of the iden-
tified issues. The results of the analysis are
18
Reason for failure Cases
Unknown grammatical structure 72 (34.4%)
Dictionary issue 54 (25.8%)
Unknown word handling 35 (16.7%)
Sentence fragment 27 (12.9%)
Ungrammatical sentence 17 (8.1%)
Other 4 (1.9%)
Table 2: Results of failure analysis
summarized in Table 2. In many of the sen-
tences, more than one reason for parser failure
was found; in total 209 issues were identified in
the 132 sentences. The results are described in
more detail in the following sections.
6.1 Fragments and ungrammatical
sentences
As some of the analyzed sentences were taken
from publication titles, not all of them were
full clauses. To identify further problems when
parsing fragments not containing a verb, the
phrase ?is explained? and required determiners
were added to these fragments, a technique used
also by Ding et al (2003). The completed frag-
ments were then analyzed for potential further
problems.
A number of other ungrammatical sentences
were also encountered. The most common
problem was the omission of determiners, but
some other issues such as missing possessive
markers and errors in agreement (e.g., ?expres-
sions. . . has?) were also encountered.
Ungrammatical sentences pose interesting
challenges for parsing. Because many authors
are not native English speakers, a greater toler-
ance for grammatical mistakes should allow the
parser to identify the intended parse for more
sentences. Similarly, the ability to parse publi-
cation titles would extend the applicability of
the parser; in some cases it may be possible
to extract information concerning the key find-
ings of a publication from the title. However,
while relaxing completeness and correctness re-
quirements, such as mandatory determiners and
subject-predicate agreement, would allow the
parser to create a complete linkage for more sen-
tences, it would also be expected to lead to in-
creased ambiguity for all sentences, and subse-
quent difficulties in identifying the correct link-
age. If the ability to parse titles is considered
important, a potential solution not incurring
this cost would be to develop a separate version
of the grammar for parsing titles.
capping protein and actin genes
capping protein and actin genes
Figure 2: Multiple modifier coordination prob-
lem. Above: correct linkage disallowed by the
LG parser. Below: solution by chaining modi-
fiers.
6.2 Unknown grammatical structures
The method of the LG implementation for pars-
ing coordinations was found to be a frequent
cause of failures. A specific coordination prob-
lem occurs with multiple noun-modifiers: the
parser assumes that coordinated constituents
can be connected to the rest of the sentence
through exactly one word, and the grammar at-
taches all noun-modifiers to the head. Biomed-
ical texts frequently contain phrases that cause
these requirements to conflict: for example, in
the phrase ?capping protein and actin genes?
(where ?capping protein genes? and ?actin
genes? is the intended parse), the parser allows
only one of the words ?capping? and ?protein?
to connect to the word ?genes?, and is thus un-
able to produce the correct linkage (for illustra-
tion, see Figure 2(a)).
This multiple modifier coordination issue
could be addressed by modifying the grammar
to chain modifiers (Figure 2(b)). This alterna-
tive model is adopted by another major depen-
dency grammar, the EngCG-based Connexor
Machinese. The problem could also be ad-
dressed by altering the coordination handling
system in the parser.
Other identified grammatical structures not
known to the parser were number postmodifiers
to nouns (e.g., ?serine 38?), specifiers in paren-
theses (e.g., ?profilin mutant (H119E)?), coor-
dination with the phrase ?but not?, and various
unknown uses of colons and quotes. Single in-
stances of several distinct unknown grammati-
cal structures were also noted (e.g., ?5 to 10?,
?as expected from?, ?most concentrated in?).
Most of these issues can be addressed by local
modifications to the grammar.
6.3 Unknown word handling
The LG parser assigns unknown words to cate-
gories based on morphological or other surface
clues when possible. For remaining unknown
19
words, parses are attempted by assigning the
words to the generic noun, verb and adjective
types in all possible combinations.
Some problems with the unknown word pro-
cessing method were encountered during analy-
sis; for example, the assumption that unknown
capitalized words are proper nouns often caused
failures, especially in sentences beginning with
an unknown word. Similarly, the assumption
that words containing a hyphen behave as ad-
jectives was violated by a number of unknown
verbs (e.g., ?cross-links?).
Another problem that was noted occurred
with lowercase unknown words that should be
treated as proper nouns: because LG does not
allow unknown lowercase words to act as proper
nouns, the parser assigns incorrect structure to
a number of phrases containing words such as
?actin?. Improving unknown word handling re-
quires some modifications to the LG parser.
6.4 Dictionary issues
Cases where the LG dictionary contains a word,
but not in the sense in which it appears in a
sentence, almost always lead to errors. For ex-
ample, the LG dictionary does not contain the
word ?assembly? in the sense ?construction?,
causing the parser to erroneously require a de-
terminer for ?protein assembly?4. A related
frequent problem occurred with proper names
headed by a common noun, where the parser ex-
pects a determiner for such names (e.g., ?myosin
heavy chain?), and fails when one is not present.
These issues are mostly straightforward to ad-
dress in the grammar, but difficult to identify
automatically.
6.5 Biomedical entity names
Many of the causes for parser failure discussed
above are related to the presence of biomed-
ical entity names. While the causes for fail-
ures relating to names can be addressed in the
grammar, the existence of biomedical named en-
tity (NE) recognition systems (for a recent sur-
vey, see, e.g., Bunescu et al (2004)) suggests
an alternative solution: NEs could be identified
in preprocessing, and treated as single (proper
noun) tokens during the parse. During failure
analysis, 59 cases (28% of all cases) were noted
where this procedure would have eliminated the
error, assuming that no errors are made in NE
430 distinct problematic word definitions were iden-
tified, including ?breakdown?, ?composed?, ?factor?,
?half?, ?independent?, ?localized?, ?parallel?, ?pro-
moter?, ?segment?, ?upstream? and ?via?.
recognition. However, the performance of cur-
rent NE recognition systems is not perfect, and
it is not clear what the effect of adopting such
a method would be on parser performance.
7 Dictionary extension
Szolovits (2003) describes an automatic method
for mapping lexical information from one lexi-
con to another, and applies this method to aug-
ment the LG dictionary with terms from the ex-
tensive UMLS Specialist lexicon. The extension
introduces more than 125,000 new words into
the LG dictionary, more than tripling its size.
We evaluated the effect of this dictionary exten-
sion on LG parser performance using the criteria
described above. The fraction of distinct tokens
in the corpus found in the parser dictionary in-
creased from 52% to 72% with the dictionary
extension, representing a significant reduction
in uncertainty. This decrease was coupled with
a 32% reduction in total parsing time.
Because the LG parser is unable to produce
any linkage for sentences where it cannot iden-
tify a verb (even incorrectly), extending the dic-
tionary significantly reduced the ability of LG
to extract dependencies in titles, where the frac-
tion of recovered dependencies fell from the al-
ready low value of 67% to 55%.
For the sentences excluding titles, the benefits
of the dictionary extension were most significant
for sentences that were in the panic category
when using the unextended LG dictionary; 12
of these 28 sentences could be parsed without
panic with the dictionary extension. In the first
linkage of these sentences, the fraction of re-
covered dependencies increased by 8%, and the
fraction of recovered interaction subgraphs in-
creased from zero to 15% with the dictionary
extension.
The overall effect of the dictionary extension
was positive but modest, with no more than
2.5% improvement for either the first or best
linkages for any criterion, despite the threefold
increase in dictionary size. This result agrees
with the failure analysis: most problems can-
not be removed by extending the dictionary and
must instead be addressed by modifications of
the grammar or parser.
8 Conclusion
We have presented an analysis of Link Gram-
mar performance using a custom dependency
corpus targeted at protein-protein interactions.
We introduced the concept of the interaction
20
subgraph and reported parser performance for
three criteria: recovery of dependencies, in-
teraction subgraphs and fully correct linkages.
While LG was able to recover 73% of dependen-
cies in the first linkage, only 7% of sentences had
a fully correct first linkage. However, fully cor-
rect linkages are not required for information ex-
traction, and we found that 25% of interaction
subgraphs were recovered in the first linkage.
Resource exhaustion was found to be a signif-
icant cause of poor performance. Furthermore,
an evaluation of performance in the case when
optimal heuristics for ordering linkages are ap-
plied indicated that the fraction of recovered in-
teraction subgraphs could be more than doubled
(to 57%) by optimal heuristics.
To further analyze the cases where the parser
cannot produce a correct linkage, we carefully
examined the sentences and were able to iden-
tify five problem types. For each identified
case, we discussed potential modifications for
addressing the problems. We also considered
the possibility of using a named entity recogni-
tion system to improve parser performance and
found that 28% of LG failures would be avoided
by a flawless named entity recognition system.
We evaluated the effect of the dictionary ex-
tension proposed by Szolovits (2003), and found
that while it significantly reduced ambiguity
and improved performance for the most ambigu-
ous sentences, overall improvement was only
2.5%. This indicates that extending the dic-
tionary is not sufficient to address the perfor-
mance problems and that modifications to the
grammar and parser are necessary.
The quantitative analysis of LG performance
confirms that, in its current state, LG is not well
suited to the IE task discussed. However, in the
failure analysis we have identified a number of
specific issues and problematic areas for LG in
parsing biomedical publications, and suggested
improvements for adapting the parser to this
domain. The examination and implementation
of these improvements is a natural follow-up of
this study. Our initial experiments suggest that
it is indeed possible to implement general so-
lutions to many of the discussed problems, and
such modifications would be expected to lead to
improved applicability of LG to the biomedical
domain.
9 Acknowledgments
This work has been supported by Tekes, the
Finnish National Technology Agency.
References
Razvan Bunescu, Ruifang Ge, Rohit J. Kate,
Edward M. Marcotte, Raymond J. Mooney,
Arun Kumar Ramani, and Yuk Wah Wong. 2004
(to appear). Comparative experiments on learn-
ing information extractors for proteins and their
interactions. Artificial Intelligence in Medicine.
Special Issue on Summarization and Information
Extraction from Medical Documents.
Michael Collins, Jan Hajic, Lance Ramshaw, and
Christoph Tillmann. 1999. A statistical parser
for Czech. In 37th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 505?
512. Association for Computational Linguistics,
Somerset, New Jersey.
Mark Craven and Johan Kumlien. 1999. Construct-
ing biological knowledge bases by extracting in-
formation from text sources. In T. Lengauer,
R. Schneider, P. Bork, D. Brutlag, J. Glasgow,
H HW Mewes, and Zimmer R., editors, Proceed-
ings of the 7th International Conference on Intel-
ligent Systems in Molecular Biology, pages 77?86.
AAAI Press, Menlo Park, CA.
Nikolai Daraselia, Anton Yuryev, Sergei Egorov,
Svetalana Novichkova, Alexander Nikitin, and
Ilya Mazo. 2004. Extracting human protein in-
teractions from MEDLINE using a full-sentence
parser. Bioinformatics, 20(5):604?611.
Jing Ding, Daniel Berleant, Jun Xu, and Andy W.
Fulmer. 2003. Extracting biochemical interac-
tions from medline using a link grammar parser.
In B. Werner, editor, Proceedings of the 15th
IEEE International Conference on Tools with Ar-
tificial Intelligence, pages 467?471. IEEE Com-
puter Society, Los Alamitos, CA.
Filip Ginter, Tapio Pahikkala, Sampo Pyysalo,
Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2004. Extracting protein-protein inter-
action sentences by applying rough set data anal-
ysis. In S. Tsumoto, R. Slowinski, J. Komorowski,
and J.W. Grzymala-Busse, editors, Lecture Notes
in Computer Science 3066. Springer, Heidelberg.
Daniel D. Sleator and Davy Temperley. 1991. Pars-
ing english with a link grammar. Technical Re-
port CMU-CS-91-196, Department of Computer
Science, Carnegie Mellon University, Pittsburgh,
PA.
Peter Szolovits. 2003. Adding a medical lexicon to
an english parser. In Mark Musen, editor, Pro-
ceedings of the 2003 AMIA Annual Symposium,
pages 639?643. American Medical Informatics As-
sociation, Bethesda, MD.
Joshua M. Temkin and Mark R. Gilder. 2003. Ex-
traction of protein interaction information from
unstructured text using a context-free grammar.
Bioinformatics, 19(16):2046?2053.
21
BioNLP 2007: Biological, translational, and clinical language processing, pages 25?32,
Prague, June 2007. c?2007 Association for Computational Linguistics
On the unification of syntactic annotations under the Stanford
dependency scheme: A case study on BioInfer and GENIA
Sampo Pyysalo, Filip Ginter, Katri Haverinen,
Juho Heimonen, Tapio Salakoski
Department of Information Technology
University of Turku,
Joukahaisenkatu 3-5
20014 Turku, Finland
first.last@utu.fi
Veronika Laippala
Department of French Studies
University of Turku,
Henrikinkatu 2
20014 Turku, Finland
veronika.laippala@utu.fi
Abstract
Several incompatible syntactic annotation
schemes are currently used by parsers and
corpora in biomedical information extrac-
tion. The recently introduced Stanford de-
pendency scheme has been suggested to be
a suitable unifying syntax formalism. In this
paper, we present a step towards such uni-
fication by creating a conversion from the
Link Grammar to the Stanford scheme. Fur-
ther, we create a version of the BioInfer cor-
pus with syntactic annotation in this scheme.
We present an application-oriented evalua-
tion of the transformation and assess the
suitability of the scheme and our conversion
to the unification of the syntactic annotations
of BioInfer and the GENIA Treebank.
We find that a highly reliable conversion is
both feasible to create and practical, increas-
ing the applicability of both the parser and
the corpus to information extraction.
1 Introduction
One of the main challenges in biomedical infor-
mation extraction (IE) targeting entity relationships
such as protein-protein interactions arises from the
complexity and variability of the natural language
statements used to express such relationships. To
address this complexity, many biomedical IE sys-
tems (Alphonse et al, 2004; Rinaldi et al, 2004;
Fundel et al, 2007) and annotated corpora (Kim et
al., 2003; Aubin, 2005; Pyysalo et al, 2007) incor-
porate full syntactic analysis. However, there are
significant differences between the syntactic anno-
tation schemes employed. This leads to difficulties
in sharing data between corpora and establishing the
relative performance of parsers as well as to a lack
of interchangeability of one parser for another in IE
systems, among other issues.
Syntax formalisms are broadly divided into con-
stituency and dependency. Constituency schemes
are dominant in many fields and are unified under
the established Penn Treebank (PTB) scheme (Bies
et al, 1995). However, dependency schemes have
been suggested to be preferable in IE, as they repre-
sent the semantic structure of the sentences more di-
rectly (see, e.g., de Marneffe et al (2006)). Further,
Lin (1998) argues for dependency-based evaluation
of both dependency and constituency parsers since
it allows evaluation metrics that are more relevant
to semantic interpretation as well as intuitively more
meaningful. Even though there is clearly a need for a
unifying scheme for dependency comparable to that
of PTB for constituency, no widely adopted standard
currently exists.
In this paper, we present a step towards unify-
ing the diverse syntax schemes in use in IE sys-
tems and corpora such as the GENIA Treebank1 and
the recently introduced BioInfer corpus (Pyysalo et
al., 2007). Clegg and Shepherd (2007) have re-
cently proposed to use the Stanford dependency
scheme (de Marneffe et al, 2006) as a common,
application-oriented syntax representation. To as-
sess this choice, we develop a set of conversion
rules for transforming the Link Grammar (LG) de-
pendency scheme (Sleator and Temperley, 1993) to
1http://www-tsujii.is.s.u-tokyo.ac.jp/ ?genia
25
the Stanford scheme and then create a version of
the BioInfer corpus in the Stanford scheme by ap-
plying the conversion rules and manually correcting
the errors. By making the BioInfer corpus available
in the Stanford scheme, we also increase the value
of the corpus for biomedical IE. The transforma-
tion has the further benefit of allowing Link Gram-
mar output to be normalized into a more application-
oriented form. Finally, to assess the practical value
of the conversion method and of the BioInfer syntac-
tic annotation in the Stanford scheme, we compare
the Charniak-Lease constituency parser2 (Charniak
and Lease, 2005) and BioLG,3 an adaptation of LG
(Pyysalo et al, 2006), on the newly unified dataset
combining the constituency-annotated GENIA Tree-
bank with the dependency-annotated BioInfer cor-
pus.
The transformation rules and software as well as
the Stanford annotation of the BioInfer corpus, the
main practical results of this work, are freely avail-
able at http://www.it.utu.fi/BioInfer.
2 Motivation
To support the development of IE systems, it is im-
portant for a corpus to provide three key types of
annotation capturing the named entities, their rela-
tionships and the syntax. To our knowledge, there
are only two corpora in the biomedical domain that
currently provide these three annotation types simul-
taneously, BioInfer and LLL (Aubin, 2005). In ad-
dition, GENIA, the de facto standard domain corpus
for named entity recognition and syntactic analysis,
is in the process of adding a relationship annota-
tion. The corpora have different strengths; BioInfer
provides a detailed relationship annotation, while
GENIA has a broader coverage of named entities
and a larger treebank. Unifying the syntactic anno-
tations of these two corpora allows these strengths
to be combined.
The BioInfer syntactic annotation follows the LG
dependency scheme, addressing the recent interest
in LG in the biomedical NLP community (Ding et
al., 2003; Alphonse et al, 2004; Aubin et al, 2005).
However, the LG scheme has been criticized for be-
ing oriented more towards structural than semantic
2http://nlp.stanford.edu/software/,
version 1.5.1
3http://www.it.utu.fi/BioLG, version 1.2.0
relations and having excessively detailed link types
whose functional meaning and value for semantic
analysis is questionable (Schneider, 1998; de Marn-
effe et al, 2006). Our experience with LG leads us
to largely agree with these criticisms.
De Marneffe et al (2006) have recently intro-
duced a transformation from PTB to the Stanford
scheme. Clegg and Shepherd (2007) have ap-
plied this transformation to perform a dependency-
based comparison of several statistical constituency
parsers on the GENIA Treebank and have argued for
the adoption of the Stanford scheme in biomedical
IE. Moreover, the IE system of Fundel et al (2007),
which employs the Stanford scheme, was shown to
notably outperform previously applied systems on
the LLL challenge dataset, finding an F-score of
72% against a previous best of 54%. This further
demonstrates the suitability of the Stanford scheme
to IE applications.
3 Dependency schemes
In this section, we present the Stanford and LG
dependency schemes and discuss their relative
strengths.
3.1 Stanford dependency scheme
A parse in the Stanford scheme (SF) is a directed
graph where the nodes correspond to the words and
the edges correspond to pairwise syntactic depen-
dencies between the words. The scheme defines
a hierarchy of 48 grammatical relations, or depen-
dency types. The most generic relation, dependent,
can be specialized as auxiliary, argument, or modi-
fier, which again have several subtypes (de Marneffe
et al, 2006).
The Stanford conversion transforms phrase struc-
ture parses into the Stanford scheme. First, the se-
mantic head of each constituent is identified using
head rules similar to those of Collins (1999) and un-
typed dependencies are then extracted and labeled
with the most specific grammatical relations possi-
ble using Tregex rules (Levy and Andrew, 2006).
The system additionally provides a set of collaps-
ing rules, suggested to be beneficial for IE appli-
cations (de Marneffe et al, 2006; Clegg and Shep-
herd, 2007). These rules collapse some dependen-
cies by incorporating certain parts of speech (mostly
26
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
A/ANPv Cs
Mp
Ss
A/AN PvDsuE
Js
MVsCC
Spx
CC
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
cc>
conj>
<nsubjpass
<auxpass
<advmod
advcl>
<mark
<det prep>
<nsubjpass
pobj>
<nmod
<nmod <auxpass
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
conj_and>
<nsubjpass
<nsubjpass
<auxpass
<advmod
advcl>
<mark
<det
prep_of>
<nsubjpass
<nmod
<nmod <auxpass
Figure 1: A sentence from the BioInfer corpus with its LG linkage (top), the Stanford parse (middle), and
the collapsed Stanford parse (bottom). The < and > symbols denote the direction of dependencies.
during incubation , actin suffered degradation
Jp
CO
Ss Os
actin suffered degradation during incubation
Jp
MVp
Ss Os
actin suffered degradation during incubation
JpMpSs Os
Figure 2: Variation in the link type connecting a
preposition: CO to the main noun in topicalized
prepositional phrases, MVp when modifying a verb,
and Mp when modifying a noun.
conjunctions and prepositions) in grammatical rela-
tions. This is realized by combining two relations
and denominating the resulting dependency with a
type based on the word to which the original two
relations were linked (see Figure 1).
In the LG-SF conversion, we target the uncol-
lapsed Stanford scheme, as the collapsing rules have
already been developed and reported by de Marn-
effe et al; reimplementing the collapsing would be
an unnecessary duplication of efforts. Also, the col-
lapsed relations can be easily created based on the
uncollapsed ones, whereas reversing the conversion
would be more complicated.
3.2 LG dependency scheme
Link Grammar (Sleator and Temperley, 1993) is
closely related to dependency formalisms. It is
based on the notion of typed links connecting words.
While links are not explicitly directional, the roles
of the words can be inferred from their left-to-right
order and the link type. An LG parse, termed link-
age, consists of a set of links that connect the words
so that no two links cross or connect the same two
words. When discussing LG, we will use the terms
dependency and link interchangeably.
Compared to the 48 dependency types of the Stan-
ford scheme, the LG English grammar defines over
100 main link types which are further divided into
400 subtypes. The unusually high number of dis-
tinct types is one of the properties of the LG English
grammar that complicate the application of LG in
information extraction. Consider, for instance, the
case of prepositional phrase attachment illustrated in
Figure 2, where all the alternative attachment struc-
tures receive different types. Arguably, this distinc-
tion is unimportant to current IE systems and there-
fore should be normalized. This normalization is in-
herent in the Stanford scheme, where the preposition
always attaches using a prep dependency.
In contrast to such unnecessarily detailed distinc-
tions, in certain cases LG types fail to make seman-
tically important distinctions. For instance, the CO
link type is used to mark almost all clause openers,
not distinguishing between, for example, adverbial
and prepositional openers.
4 Our contributions
In this section, we describe the LG-SF conversion
as well as SF BioInfer, the BioInfer corpus syntactic
27
annotation in the Stanford scheme. These are the
two primary contributions of this study.
4.1 LG-SF conversion
The LG-SF conversion transforms the undirected
LG links into directed dependencies that follow the
Stanford scheme. The transformation is based on
handwritten rules, each rule consisting of a pattern
that is matched in the LG linkage and generating a
single dependency in the Stanford parse. Since the
conversion rules only refer to the LG linkage, they
do not influence each other and are applied inde-
pendently in an arbitrary order. The pattern of each
rule is expressed as a set of positive or negative con-
straints on the presence of LG links. The constraints
typically restrict the link types and may also refer to
the lexical level, restricting only to links connecting
certain word forms. Since LG does not define link
directionality, the patterns refer to the left-to-right
order of tokens and the rules must explicitly specify
the directionality of the generated SF dependencies.
As an example, let us consider the rule
[X Pv? Y]? Y auxpass? X. The pattern matches two
tokens connected with an LG link of type Pv and
generates the corresponding directed auxpass de-
pendency. This rule applies twice in the linkage
in Figure 1. It is an example of a rare case of a
one-to-one correspondence between an LG and an
SF type. Many-to-many correspondences are much
more common: in these cases, rules specify multiple
restrictions and multiple rules are needed to gener-
ate all instances of a particular dependency type. As
a further example, we present the three rules below,
which together generate all left-to-right prep depen-
dencies. An exclamation mark in front of a restric-
tion denotes a negative restriction, i.e., the link must
not exist in order for the rule to apply. The link types
are specified as regular expressions.
[A Mp|MX[a-z]x? B]![B Cs? C]![A RS? D]? A prep? B
[A OF|MVx? B]![A RS? C]? A prep? B
[A MVp? B]![A RS? C]![C MVl? A]? A prep? B
The first of the above three rules generates the prep
dependency in the parse in Figure 1, with A=isoform
and B=of. The variables C and D are not bound to
any tokens in this sentence, as they only occur in
negative restrictions.
actin , profilin and cofilin
CC
CC CC
Figure 3: Example of a structure where the relative
order of the first two tokens cannot be resolved by
the rules.
To resolve coordination structures, it is crucial to
recognize the leftmost coordinated element, i.e. the
head of the coordination structure in the SF scheme.
However, the conversion rule patterns are unable to
capture general constraints on the relative order of
the tokens. For instance, in the linkage in Figure 3, it
is not possible to devise a pattern only matching one
of the tokens actin and profilin, while not matching
the other. Therefore, we perform a pre-processing
step to resolve the coordination structures prior to
the application of the conversion rules. After the
pre-processing, the conversion is performed with the
lp2lp software (Alphonse et al, 2004), previously
used to transform LG into the LLL competition for-
mat (Aubin, 2005).
In the development of the LG-SF conversion and
SF BioInfer, we make the following minor modifi-
cations to the Stanford scheme. The scheme dis-
tinguishes nominal and adjectival pre-modifiers of
nouns, a distinction that is not preserved in the
BioInfer corpus. Therefore, we merge the nom-
inal and adjectival pre-modifier grammatical rela-
tions into a single relation, nmod. For the same rea-
son, we do not distinguish between apposition and
abbreviation, and only use the appos dependency
type. Finally, we do not annotate punctuation.
Schneider (1998) has previously proposed a strat-
egy for identifying the head word for each LG link,
imposing directionality and thus obtaining a depen-
dency graph. Given the idiosyncrasies of the LG
linkage structures, this type of transformation into
dependency would clearly not have many of the nor-
malizing benefits of the LG-SF transformation.
4.2 SF BioInfer
For creating the BioInfer corpus syntactic annota-
tion in the Stanford scheme, the starting point of
the annotation process was the existing manual an-
notation of the corpus in the LG scheme to which
we applied the LG-SF conversion described in Sec-
tion 4.1. The resulting SF parses were then manu-
28
ally corrected by four annotators. In the manual cor-
rection phase, each sentence was double-annotated,
that is, two annotators corrected the converted out-
put independently. All disagreements were resolved
jointly by all annotators.
To estimate the annotation quality and the sta-
bility of the SF scheme, we determined annotator
agreement as precision and recall measured against
the final annotation. The average annotation preci-
sion and recall were 97.5% and 97.4%, respectively.
This high agreement rate suggests that the task was
well-defined and the annotation scheme is stable.
The BioInfer corpus consists of 1100 sentences
and, on average, the annotation consumed approxi-
mately 10 minutes per sentence in total.
5 Evaluation
In this section, we first evaluate the LG-SF conver-
sion. We then present an evaluation of the Charniak-
Lease constituency parser and the BioLG depen-
dency parser on BioInfer and GENIA.
5.1 Evaluation of the conversion rules
In the evaluation of the conversion rules against the
gold standard SF BioInfer annotation, we find a pre-
cision of 98.0% and a recall of 96.2%. Currently,
the LG-SF conversion consists of 114 rules, each
of which specifies, on average, 4.4 restrictions. Al-
together the rules currently generate 32 SF depen-
dency types, thus averaging 3.5 rules per SF type.
Only 9 of the SF types are generated by a single
rule, while the remaining require several rules. We
estimate that the current ruleset required about 100
hours to develop.
In Figure 4, we show the cumulative precision and
recall of the rules when added in the descending or-
der of their recall. Remarkably, we find that a recall
of 80% is reached with just 13 conversion rules, 90%
with 28 rules, and 95% with 56 rules. These fig-
ures demonstrate that while the SF and LG schemes
are substantially different, a high-recall conversion
can be obtained with approximately fifty carefully
crafted rules. Additionally, while precision is con-
sistently high, the highest-recall rules also have the
highest precision. This may be related to the fact
that the most common SF dependency types have a
straightforward correspondence in LG types.
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 0  20  40  60  80  100
Number of conversion rules
Recall
Precision
Figure 4: Cumulative precision and recall of the con-
version rules.
A common source of errors in the LG-SF conver-
sion are the Link Grammar idiomatic expressions,
which are analyzed as a chain of ID links (0.7% of
all links in the BioInfer corpus) and connected to
the linkage always through their last word. Some
examples of LG idiomatic expressions include each
other, no one, come of age, gotten rid of, for good,
and the like. These expressions are often problem-
atic in the SF conversion as well. We did not at-
tempt any wide-coverage systematic resolution of
the idiomatic expressions and, apart from the most
common cases such as in vitro, we preserve the LG
structure of connecting these expressions through
their last word. We note, however, that the list of
idiomatic LG expressions is closed and therefore a
case-by-case resolution leading to a full coverage is
possible, although not necessarily practical.
Similar to the LG idiomatic expressions are the
SF dep dependencies, generated when none of the
SF rules assigns a more specific type. In most cases,
dep is a result of a lack of coverage of the SF con-
version rules typically occurring in rare or idiomatic
expressions. We assume that many of the dep depen-
dencies will be resolved in the future, given that the
SF conversion and the SF dependency scheme itself
are presented by the authors as a work in progress.
Therefore, we do not attempt to replicate most of
the SF dep dependencies with the LG-SF conversion
rules; much of the effort would be obsoleted by the
progress of the SF conversion. The dep dependen-
cies account for 23% of the total 3.8% of dependen-
cies not recovered by the LG-SF conversion.
29
Charniak-Lease BioLG
corpus Prec. Rec. F Prec. Rec. F
GENIA 81.2 81.3 81.3 76.9 72.4 74.6
BioInfer 78.4 79.9 79.4 79.6 76.1 77.8
Table 1: Parser performance. Precision, recall and
F-measure for the two parsers on the two corpora.
5.2 Evaluated parsers and corpora
The Charniak-Lease parser is a statisti-
cal constituency parser developed by Char-
niak and Lease (2005). It is an adaptation of the
Charniak parser (Charniak, 1999) to the biomedical
domain. For example, it uses a POS-tagger trained
on the GENIA corpus, although the parser itself has
been trained on the Penn Treebank. The Charniak-
Lease parser is of particular interest, because in a
recent comparison performed by Clegg and Shep-
herd (2007) on the GENIA Treebank, it was the
best performing of several state-of-the-art statistical
constituency parsers.
The LG parser is a rule-based dependency parser
with a broad coverage grammar of newspaper-type
English. It has no probabilistic component and does
not perform pruning of ambiguous alternatives dur-
ing parsing. Instead, the parser generates all parses
accepted by the grammar. Simple heuristics are ap-
plied to rank the alternative parses.
Here, we evaluate a recently introduced adap-
tation of LG to the biomedical domain, BioLG
(Pyysalo et al, 2006), incorporating the GENIA
POS tagger (Tsuruoka et al, 2005) as well as a num-
ber of modifications to lexical processing and the
grammar.
To facilitate the comparison of results with those
of Clegg and Shepherd, we use their modified subset
of GENIA Treebank.4 As 600 of the 1100 BioInfer
sentences have previously been used in the develop-
ment of the BioLG parser, we only use the remaining
500 blind sentences of BioInfer in the evaluation.
5.3 Parser performance
To evaluate the performance of the parsers, we de-
termined the precision, recall and F-measure by
comparing the parser output against the corpus gold
4http://chomsky-ext.cryst.bbk.ac.uk/
andrew/downloads.html
BioLG
scheme Prec. Rec. F
LG 78.2 77.2 77.7
SF 79.6 76.1 77.8
Table 2: BioLG performance on the BioInfer corpus
with and without the LG-SF conversion.
standard dependencies. The matching criterion re-
quired that the correct words are connected and
that the direction and type of the dependency are
correct. The dependency-based evaluation results
for the Charniak-Lease and BioLG parsers on the
GENIA and BioInfer corpora are shown in Table 1.
We note that Clegg and Shepherd (2007) report
77% F-score performance of Charniak-Lease on the
GENIA corpus, using the collapsed variant of the SF
scheme. We replicated their experiment using the
uncollapsed variant and found an F-score of 80%.
Therefore, most of the approximately 4% difference
compared to our finding reported in Table 1 is due
to this difference in the use of collapsing, with our
modifications to the SF scheme having a lesser ef-
fect. The decrease in measured performance caused
by the collapsing is, however, mostly an artifact
caused by merging several dependencies into one; a
single mistake of the parser can have a larger effect
on the performance measurement.
We find that while the performance of the
Charniak-Lease parser is approximately 2 percent-
age units better on GENIA than on BioInfer, for
BioLG we find the opposite effect, with performance
approximately 3 percentage units better on BioInfer.
Thus, both parsers perform better on the corpora
closer to their native scheme. We estimate that this
total 5 percentage unit divergence represents an up-
per limit to the evaluation bias introduced by the two
sets of conversion rules. We discuss the possible
causes for this divergence in Section 5.4.
To determine whether the differences between the
two parsers on the two corpora were statistically
significant, we used the Wilcoxon signed-ranks test
for F-score performance using the Bonferroni cor-
rection for multiple comparisons (N = 2), follow-
ing the recent recommendation of Dems?ar (2006).
We find that the Charniak-Lease parser outperforms
BioLG statistically significantly on both the GENIA
corpus (p ? 0.01) and on the BioInfer corpus
30
  Z   protein  but  not  c-myb  protein 
<nmod <dep
cc>
<nmod
conj>
  Z   protein  but  not  c-myb  protein 
<nmod dep>
cc>
<nmod
conj>
Figure 5: Example of divergence on the interpreta-
tion of the Stanford scheme. Above: GENIA and
Stanford conversion interpretation. Below: BioInfer
and LG-SF rules interpretation.
(p < 0.01). Thus, the relative performance of the
parsers can, in this case, be established even in the
presence of opposing conversion biases on the two
corpora.
In Table 2, we present an evaluation of the BioLG
parser with and without the LG-SF conversion,
specifically evaluating the effect of the conversion
presented in this study. Here we find a substantially
more stable performance, including even an increase
in precision. This further validates the quality of the
conversion rules.
Finally, we note that the processing time required
to perform the conversions is insignificant compared
to the time consumed by the parsers.
5.4 Discussion
Evaluating BioLG on GENIA and the Charniak-
Lease parser on BioInfer includes multiple sources
of divergence. In addition to parser errors, differ-
ences can be created by the LG-SF conversion and
the Stanford conversion. Moreover, in examining
the outputs we identified that a further source of
divergence is due to differing interpretations of the
Stanford scheme. One such difference is illustrated
in Figure 5. Here the BioLG parser with the LG-
SF conversion produces an analysis that differs from
the result of converting the GENIA Treebank analy-
sis by the Stanford conversion. This is due to the
Stanford conversion producing an apparently flawed
analysis that is not replicated by the LG-SF con-
version. In certain cases of this type, the lack of a
detailed definition of the SF scheme prevents from
distinguishing between conversion errors and inten-
tional analyses. This will necessarily lead to differ-
ing interpretations, complicating precise evaluation.
6 Conclusions
We have presented a step towards unifying syntactic
annotations under the Stanford dependency scheme
and assessed the feasibility of this unification by
developing and evaluating a conversion from Link
Grammar to the Stanford scheme. We find that a
highly reliable transformation can be created, giv-
ing a precision and recall of 98.0% and 96.2%, re-
spectively, when compared against our manually an-
notated gold standard version of the BioInfer cor-
pus. We also find that the performance of the BioLG
parser is not adversely affected by the conversion.
Given the clear benefits that the Stanford scheme
has for domain analysis, the conversion increases the
overall suitability of the parser to IE applications.
Based on these results, we conclude that converting
to the Stanford scheme is both feasible and practical.
Further, we have developed a version of the
BioInfer corpus annotated with the Stanford scheme,
thereby increasing the usability of the corpus. We
applied the LG-SF conversion to the original LG
BioInfer annotation and manually corrected the er-
rors. The high annotator agreement of above 97%
precision and recall confirms the stability of the SF
scheme.
We have also demonstrated that the unification
permits direct parser comparison that was previously
impossible. However, we found that there is a cer-
tain accumulation of errors caused by the conver-
sion, particularly in a case when two distinct rule
sets are applied. In our case, we estimate this error
to be on the order of several percentage units, never-
theless, we were able to establish the relative perfor-
mance of the parses with a strong statistical signif-
icance. These results demonstrate the utility of the
Stanford scheme as a unifying representation of syn-
tax. We note that an authoritative definition of the
Stanford scheme would further increase its value.
Acknowledgments
We would like to thank Erick Alphonse, Sophie
Aubin and Adeline Nazarenko for providing us with
the lp2lp software and the LLL conversion rules. We
would also like to thank Andrew Brian Clegg and
Adrian Shepherd for making available the data and
evaluation tools used in their parser evaluation. This
work was supported by the Academy of Finland.
31
References
Erick Alphonse, Sophie Aubin, Philippe Bessie`res, Gilles
Bisson, Thierry Hamon, Sandrine Laguarigue, Ade-
line Nazarenko, Alain-Pierre Manine, Claire Ne?dellec,
Mohamed Ould Abdel Vetah, Thierry Poibeau, and
Davy Weissenbacher. 2004. Event-Based Information
Extraction for the biomedical domain: the Caderige
project. In N. Collier, P. Ruch, and A. Nazarenko, ed-
itors, COLING NLPBA/BioNLP Workshop, pages 43?
49, Geneva, Switzerland.
Sophie Aubin, Adeline Nazarenko, and Claire Ne?dellec.
2005. Adapting a general parser to a sublanguage. In
G. Angelova, K. Bontcheva, R. Mitkov, N. Nicolov,
and N. Nikolov, editors, Proceedings of the Interna-
tional Conference on Recent Advances in Natural Lan-
guage Processing (RANLP 05), Borovets, Bulgaria,
pages 89?93. Incoma, Bulgaria.
Sophie Aubin. 2005. LLL challenge - syntactic analysis
guidelines. Technical report, LIPN, Universite? Paris
Nord, Villetaneuse.
Ann Bies, Mark Ferguson, Karen Katz, and Robert Mac-
Intyre. 1995. Bracketing guidelines for treebank ii
style. Technical report, Penn Treebank Project, Uni-
versity of Pennsylvania.
Eugene Charniak and Matthew Lease. 2005. Parsing
biomedical literature. In R. Dale, K. F. Wong, J. Su,
and O. Y. Kwong, editors, Proceedings of the Sec-
ond International Joint Conference on Natural Lan-
gage Processing, Jeju Island, Korea, pages 58?69.
Eugene Charniak. 1999. A maximum-entropy-inspired
parser. Technical report, Brown University.
Andrew Brian Clegg and Adrian Shepherd. 2007.
Benchmarking natural-language parsers for biological
applications using dependency graphs. BMC Bioinfor-
matics, 8(1):24.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
N. Calzolari, K. Choukri, A. Gangemi, B. Maegaard,
J. Mariani, J. Odijk, and D. Tapias, editors, Proceed-
ings of the 5th International Conference on Language
Resources and Evaluation (LREC 2006), pages 449?
454.
Janez Dems?ar. 2006. Statistical comparisons of clas-
sifiers over multiple data sets. Journal of Machine
Learning Research, 7:1?30.
Jing Ding, Daniel Berleant, Jun Xu, and Andy W. Fulmer.
2003. Extracting biochemical interactions from med-
line using a link grammar parser. In B. Werner, editor,
Proceedings of the 15th IEEE International Confer-
ence on Tools with Artificial Intelligence, pages 467?
471. IEEE Computer Society, Los Alamitos, CA.
Katrin Fundel, Robert Kuffner, and Ralf Zimmer. 2007.
RelEx?Relation extraction using dependency parse
trees. Bioinformatics, 23(3):365?371.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun?ichi
Tsujii. 2003. GENIA corpus?a semantically an-
notated corpus for bio-textmining. Bioinformatics,
19:i180?182.
Roger Levy and Galen Andrew. 2006. Tregex and Tsur-
geon: tools for querying and manipulating tree data
structures. In N. Calzolari, K. Choukri, A. Gangemi,
B. Maegaard, J. Mariani, J. Odijk, and D. Tapias, ed-
itors, Proceedings of the 5th International Conference
on Language Resources and Evaluation (LREC 2006),
pages 2231?2234.
Dekang Lin. 1998. A dependency-based method for
evaluating broad-coverage parsers. Natural Language
Engineering, 4(2):97?114.
Sampo Pyysalo, Tapio Salakoski, Sophie Aubin, and
Adeline Nazarenko. 2006. Lexical adaptation of link
grammar to the biomedical sublanguage: a compara-
tive evaluation of three approaches. BMC Bioinfor-
matics, 7(Suppl 3).
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Fabio Rinaldi, Gerold Schneider, Kaarel Kaljurand,
James Dowdall, Andreas Persidis, and Ourania Kon-
stanti. 2004. Mining relations in the genia corpus. In
Proceedings of the Workshop W9 on Data Mining and
Text Mining for Bioinformatics (ECML/PKDD?04),
pages 61?68, Pisa, Italy.
Gerold Schneider. 1998. A linguistic comparison of
constituency, dependency and link grammar. Master?s
thesis, University of Zu?rich.
Daniel D. Sleator and Davy Temperley. 1993. Parsing
English with a Link Grammar. In Third International
Workshop on Parsing Technologies.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,
Tomoko Ohta, John McNaught, Sophia Ananiadou,
and Jun?ichi Tsujii. 2005. Developing a robust part-
of-speech tagger for biomedical text. In P. Bozanis and
E. N. Houstis, editors, 10th Panhellenic Conference on
Informatics, volume 3746, pages 382?392.
32
BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 1?9,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
A Graph Kernel for Protein-Protein Interaction Extraction
Antti Airola, Sampo Pyysalo, Jari Bjo?rne, Tapio Pahikkala, Filip Ginter and Tapio Salakoski
Turku Centre for Computer Science
and Department of IT, University of Turku
Joukahaisenkatu 3-5
20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
In this paper, we propose a graph kernel
based approach for the automated extraction
of protein-protein interactions (PPI) from sci-
entific literature. In contrast to earlier ap-
proaches to PPI extraction, the introduced all-
dependency-paths kernel has the capability
to consider full, general dependency graphs.
We evaluate the proposed method across five
publicly available PPI corpora providing the
most comprehensive evaluation done for a ma-
chine learning based PPI-extraction system.
Our method is shown to achieve state-of-the-
art performance with respect to comparable
evaluations, achieving 56.4 F-score and 84.8
AUC on the AImed corpus. Further, we iden-
tify several pitfalls that can make evaluations
of PPI-extraction systems incomparable, or
even invalid. These include incorrect cross-
validation strategies and problems related to
comparing F-score results achieved on differ-
ent evaluation resources.
1 Introduction
Automated protein-protein interaction (PPI) extrac-
tion from scientific literature is a task of significant
interest in the BioNLP field. The most commonly
addressed problem has been the extraction of binary
interactions, where the system identifies which pro-
tein pairs in a sentence have a biologically relevant
relationship between them. Proposed solutions in-
clude both hand-crafted rule-based systems and ma-
chine learning approaches (see e.g. (Bunescu et al,
2005)). A wide range of results have been reported
for the systems, but as we will show, differences in
evaluation resources, metrics and strategies make di-
rect comparison of these numbers problematic. Fur-
ther, the results gained from the BioCreative II eval-
uation, where the best performing system achieved
a 29% F-score (Hunter et al, 2008), suggest that the
problem of extracting binary protein protein interac-
tions is far from solved.
The public availability of large annotated PPI-
corpora such as AImed (Bunescu et al, 2005),
BioInfer (Pyysalo et al, 2007a) and GENIA (Kim
et al, 2008), provides an opportunity for building
PPI extraction systems automatically using machine
learning. A major challenge is how to supply the
learner with the contextual and syntactic informa-
tion needed to distinguish between interactions and
non-interactions. To address the ambiguity and vari-
ability of the natural language expressions used to
state PPI, several recent studies have focused on
the development, adaptation and application of NLP
tools for the biomedical domain. Many high-quality
domain-specific tools are now freely available, in-
cluding full parsers such as that introduced by Char-
niak and Lease (2005). Additionally, a number
of conversions from phrase structure parses to de-
pendency structures that make the relationships be-
tween words more directly accessible have been in-
troduced. These include conversions into represen-
tations such as the Stanford dependency scheme (de
Marneffe et al, 2006) that are explicitly designed for
information extraction purposes. However, special-
ized feature representations and kernels are required
to make learning from such structures possible.
Approaches such as subsequence kernels
(Bunescu and Mooney, 2006), tree kernels (Zelenko
1
interaction of P1 and P2
prep_of> conj_and>prep_of>
P1 is a P2 binding protein
<nn<nn
<det<cop
<nsubj
P1 fails to bind P2
<nsubj <aux dobj>xcomp>
<xsubj
Figure 1: Stanford dependency parses (?collapsed? rep-
resentation) where the shortest path, shown in bold, ex-
cludes important words.
et al, 2003) and shortest path kernels (Bunescu
and Mooney, 2005) have been proposed and suc-
cessfully used for relation extraction. However,
these methods lack the expressive power to consider
representations derived from general, possibly
cyclic, dependency graph structures, such as those
generated by the Stanford tools. The subsequence
kernel approach does not consider parses at all, and
the shortest path approach is limited to representing
only a single path in the full dependency graph,
which excludes relevant words even in many simple
cases (Figure 1). Tree kernels can represent more
complex structures, but are still restricted to tree
representations.
Lately, in the framework of kernel-based machine
learning methods there has been an increased in-
terest in designing kernel functions for graph data.
Building on the work of Ga?rtner et al (2003),
graph representations tailored for the task of depen-
dency parse ranking were proposed by Pahikkala et
al. (2006b). Though the proposed representations
are not directly applicable to the task of PPI extrac-
tion, they offer insight in how to learn from depen-
dency graphs. We develop a graph kernel approach
for PPI extraction based on these ideas.
We next define a graph representation suitable for
describing potential interactions and introduce a ker-
nel which makes efficient learning from a general,
unrestricted graph representation possible. Then we
provide a short description of the sparse regular-
ized least squares (sparse RLS) kernel-based ma-
chine learning method we use for PPI-extraction.
Further, we rigorously assess our method on five
publicly available PPI corpora, providing the first
broad cross-corpus evaluation with a machine learn-
ing approach to PPI extraction. Finally, we discuss
the effects that different evaluation strategies, choice
of corpus and applied metrics have on measured per-
formance, and conclude.
2 Method
We next present our graph representation, formalize
the notion of graph kernels, and present our learning
method of choice, the sparse RLS.
2.1 Graph encoding of sentence structure
As in most recent work on machine learning for PPI
extraction, we cast the task as learning a decision
function that determines for each unordered candi-
date pair of protein names occurring together in a
sentence whether the two proteins interact. In the
following, we first define the graph representation
used to represent an interaction candidate pair. We
then proceed to derive the kernel used to measure
the similarities of these graphs.
We assume that the input of our learning method
is a dependency parse of a sentence where a pair of
protein names is marked as the candidate interac-
tion for which an extraction decision must be made.
Based on this, we form a weighted, directed graph
that consists of two unconnected subgraphs. One
represents the dependency structure of the sentence,
and the other the linear order of the words (see Fig-
ure 2).
The first subgraph is built from the dependency
analysis. One vertex and an associated set of labels
is created in the graph for each token and for each
dependency. The vertices that represent tokens have
as labels the text and part-of-speech (POS) of the
token. To ensure generalization of the learned ex-
traction model, the labels of vertices that correspond
to protein names are replaced with PROT1, PROT2
or PROT, where PROT1 and PROT2 are the pair of
interest. The vertices that represent dependencies
are labeled with the type of the dependency. The
edges in the subgraph are defined so that each de-
pendency vertex is connected by an incoming edge
from the vertex representing its governor token, and
by an outgoing edge to the vertex representing its de-
2
Figure 2: Graph representation generated from an example sentence. The candidate interaction pair is marked as
PROT1 and PROT2, the third protein is marked as PROT. The shortest path between the proteins is shown in bold. In
the dependency based subgraph all nodes in a shortest path are specialized using a post-tag (IP). In the linear order
subgraph possible tags are (B)efore, (M)iddle, and (A)fter. For the other two candidate pairs in the sentence, graphs
with the same structure but different weights and labels would be generated.
pendent token. The graph thus represents the entire
sentence structure.
It is widely acknowledged that the words between
the candidate entities or connecting them in a syn-
tactic representation are particularly likely to carry
information regarding their relationship; (Bunescu
and Mooney, 2005) formalize this intuition for de-
pendency graphs as the shortest path hypothesis. We
apply this insight in two ways in the graph repre-
sentation: the labels of the nodes on the shortest
undirected paths connecting PROT1 and PROT2 are
differentiated from the labels outside the paths us-
ing a special tag. Further, the edges are assigned
weights; after limited preliminary experiments, we
chose a simple weighting scheme where all edges
on the shortest paths receive a weight of 0.9 and
other edges receive a weight of 0.3. The represen-
tation thus allows us to emphasize the shortest path
without completely disregarding potentially relevant
words outside of the path.
The second subgraph is built from the linear struc-
ture of the sentence. For each token, a second ver-
tex is created and the labels for the vertices are de-
rived from the texts, POS-tags and named entity tag-
ging as above. The labels of each word are special-
ized to denote whether the word appears before, in-
between, or after the protein pair of interest. Each
word node is connected by an edge to its succeed-
ing word, as determined by sentence order the of the
words. Each edge is given the weight 0.9.
2.2 The all-dependency-paths graph kernel
We next formalize the graph representation and
present the all-dependency-paths kernel. This ker-
nel can be considered as a practical instantiation of
the theoretical graph kernel framework introduced
by Ga?rtner et al (2003). Let V be the set of ver-
tices in the graph and L be the set of possible labels
vertices can have. We represent the graph with an
adjacency matrix A ? R|V |?|V |, whose rows and
columns are indexed by the vertices, and [A]i,j con-
tains the weight of the edge connecting vi ? V and
vj ? V if such an edge exists, and zero otherwise.
Further, we represent the labels as a label allocation
matrix L ? R|L|?|V | so that Li,j = 1 if the j-th
vertex has the i-th label and Li,j = 0 otherwise. Be-
cause only a very small fraction of all the possible
labels are ever assigned to any single node, this ma-
trix is extremely sparse.
It is well known that when an adjacency matrix is
multiplied with itself, each element [A2]i,j contains
the summed weight of paths from vertex vi to vertex
vj through one intervening vertex, that is, paths of
length two. Similarly, for any length n, the summed
weights from vi to vj can be determined by calculat-
ing [An]i,j .
Since we are interested not only in paths of one
specific length, it is natural to combine the effect of
paths of different lengths by summing the powers
of the adjacency matrices. We calculate the infinite
sum of the weights of all possible paths connecting
3
the vertices using the Neumann Series, defined as
(I ?A)?1 = I + A + A2 + ... =
??
k=0
Ak
if |A| < 1 where |A| is the spectral radius of A
(Meyer, 2000). From this sum we can form a new
adjacency matrix
W = (I ?A)?1 ? I .
The final adjacency matrix contains the summed
weights of all possible paths connecting the ver-
tices. The identity matrix is subtracted to remove
the paths of length zero, which would correspond to
self-loops.
Next, we present the graph kernel that utilizes the
graph representation defined previously. We define
an instance G representing a candidate interaction
as G = LWLT, where L and W are the label al-
location matrix and the final adjacency matrix cor-
responding to the graph representation of the candi-
date interaction.
Following Ga?rtner et al (2003) the graph kernel
is defined as
k(G?, G??) =
|L|?
i=1
|L|?
j=1
G?i,jG
??
i,j ,
where G? and G?? are two instances formed as de-
fined previously. The features can be thought as
combinations of labels from connected pairs of ver-
tices, with a value that represents the strength of
their connection. In practical implementations, the
full G matrices, which consist mostly of zeroes, are
never explicitly formed. Rather, only the non-zero
elements are stored in memory and used when cal-
culating the kernels.
2.3 Scalable learning with Sparse RLS
RLS is a state-of-the-art kernel-based machine
learning method which has been shown to have
comparable performance to support vector machines
(Rifkin et al, 2003). We choose the sparse version
of the algorithm, also known as subset of regressors,
as it allows us to scale up the method to very large
training set sizes. Sparse RLS also has the property
that it is possible to perform cross-validation and
regularization parameter selection so that their time
complexities are negligible compared to the training
complexity. These efficient methods are analogous
to the ones proposed by Pahikkala et al (2006a) for
the basic RLS regression.
We now briefly present the basic sparse RLS al-
gorithm. Let m denote the training set size and
M = {1, . . . ,m} an index set in which the indices
refer to the examples in the training set. Instead of
allowing functions that can be expressed as a linear
combination over the whole training set, as in the
case of basic RLS regression, we only allow func-
tions of the following restricted type:
f(?) =
?
i?B
aik(?, xi), (1)
where k is the kernel function, xi are training data
points, ai ? R are weights, and the set indexing the
basis vectors B ? M is selected in advance. The co-
efficients ai that determine (1) are obtained by min-
imizing
m?
i=1
(yi ?
?
j?B
ajk(xi, xj))
2 + ?
?
i,j?B
aiajk(xi, xj),
where the first term is the squared loss function, the
second term is the regularizer, and ? ? R+ is a reg-
ularization parameter. Note that all the training in-
stances are used for determining the coefficient vec-
tor. The minimizer is obtained by solving the corre-
sponding system of linear equations, which can be
performed in O(m|B|2) time.
We set the maximum number of basis vectors to
4000 in all experiments in this study. The subset
is selected randomly when the training set size ex-
ceeds this number. Other methods for the selection
of the basis vectors were considered by Rifkin et
al. (2003), who however reported that the random
selection worked as well as the more sophisticated
approaches.
3 Experimental evaluation
We next describe the evaluation resources and met-
rics used, provide a comprehensive evaluation of our
method across five PPI corpora, and compare our re-
sults to earlier work. Further, we discuss the chal-
lenges inherent in providing a valid method evalua-
tion and propose solutions.
4
Statistics Graph Kernel Co-occ.
Corpus #POS. #NEG. P R F ?F AUC ?AUC P F
AIMed 1000 4834 0.529 0.618 0.564 0.050 0.848 0.023 0.178 0.301
BioInfer 1370 8924 0.477 0.599 0.529 0.053 0.849 0.065 0.135 0.237
HPRD50 163 270 0.643 0.658 0.634 0.114 0.797 0.063 0.389 0.554
IEPA 335 482 0.696 0.827 0.751 0.070 0.851 0.051 0.408 0.576
LLL 164 166 0.725 0.872 0.768 0.178 0.834 0.122 0.559 0.703
Table 1: Counts of positive and negative examples in the corpora and (P)recision, (R)ecall (F)-score and AUC for the
graph kernel, with standard deviations provided for F and AUC.
3.1 Corpora and evaluation criteria
We evaluate our method using five publicly avail-
able corpora that contain PPI interaction annotation:
AImed (Bunescu et al, 2005), BioInfer (Pyysalo et
al., 2007a), HPRD50 (Fundel et al, 2007), IEPA
(Ding et al, 2002) and LLL (Ne?dellec, 2005). All
the corpora were processed to a common format us-
ing transformations1 that we have introduced ear-
lier (Pyysalo et al, 2008). We parse these cor-
pora with the Charniak-Lease parser (Charniak and
Lease, 2005), which has been found to perform best
among a number of parsers tested in recent domain
evaluations (Clegg and Shepherd, 2007; Pyysalo et
al., 2007b). The Charniak-Lease phrase structure
parses are transformed into the collapsed Stanford
dependency scheme using the Stanford tools (de
Marneffe et al, 2006). We cast the PPI extraction
task as binary classification, where protein pairs that
are stated to interact are positive examples and other
co-occuring pairs negative. Thus, from each sen-
tence,
(n
2
)
examples are generated, where n is the
number of occurrences of protein names in the sen-
tence. Finally, we form the graph representation de-
scribed earlier for each candidate interaction.
We evaluate the method with 10-fold document-
level cross-validation on all of the corpora. This
guarantees the maximal use of the available data,
and also allows comparison to relevant earlier work.
In particular, on the AImed corpus we apply the ex-
act same 10-fold split that was used by Bunescu et
al. (2006) and Giuliano et al (2006). Performance
is measured according to the following criteria: in-
teractions are considered untyped, undirected pair-
wise relations between specific protein mentions,
that is, if the same protein name occurs multiple
1Available at http://mars.cs.utu.fi/PPICorpora.
times in a sentence, the correct interactions must be
extracted for each occurrence. Further, we do not
consider self-interactions as candidates and remove
them from the corpora prior to evaluation.
The majority of PPI extraction system evaluations
use the balanced F-score measure for quantifying the
performance of the systems. This metric is defined
as F = 2prp+r , where p is precision and r recall. Like-
wise, we provide F-score, precision, and recall val-
ues in our evaluation. It should be noted that F-score
is very sensitive to the underlying positive/negative
pair distribution of the corpus ? a property whose
impact on evaluation is discussed in detail below. As
an alternative to F-score, we also evaluate the per-
formance of our system using the area under the re-
ceiver operating characteristics curve (AUC) mea-
sure (Hanley and McNeil, 1982). AUC has the im-
portant property that it is invariant to the class dis-
tribution of the used dataset. Due to this and other
beneficial properties for comparative evaluation, the
usage of AUC for performance evaluation has been
recently advocated in the machine learning commu-
nity (see e.g. (Bradley, 1997)). Formally, AUC can
be defined as
AUC =
?m+
i=1
?m?
j=1H(xi ? yi)
m+m?
,
where m+ and m? are the numbers of positive
and negative examples, respectively, and x1,...,xm+
are the outputs of the system for the positive, and
y1,...,ym? for the negative examples, and
H(r) =
?
?
?
1, if r > 0
0.5, if r = 0
0, otherwise.
The measure corresponds to the probability that
given a randomly chosen positive and negative ex-
5
ample, the system will be able to correctly disin-
guish which one is which.
3.2 Performance across corpora
The performance of our method on the five corpora
for the various metrics is presented in Table 1. For
reference, we show also the performance of the co-
occurrence (or all-true) baseline, which simply as-
signs each candidate into the interaction class. The
recall of the co-occurrence method is trivially 100%,
and in terms of AUC it has a score of 0.5, the ran-
dom baseline. All the numbers in Table 1 are aver-
ages taken over the ten folds. One should note that
because of the non-linearity of the F-score measure,
the average precision and recall will not produce ex-
actly the average F.
The results hold several interesting findings. First,
we briefly observe that on the AImed corpus, which
has recently been applied in numerous evaluations
(S?tre et al, 2008) and can be seen as an emerging
de facto standard for PPI extraction method evalua-
tion, the method achieves an F-score performance of
56.4%. As we argue in more detail below, this level
of performance is comparable to the state-of-the-art
in machine learning based PPI extraction. For the
other large corpus, BioInfer, F-score performance is
slightly lower.
Second, we observe that the F-score performance
of the method varies strikingly between the differ-
ent corpora, with results on IEPA and LLL approx-
imately 20 percentage units higher than on AImed
and BioInfer, despite the larger size of the latter two.
In our previous work we have observed similar re-
sults with a rule-based extraction method (Pyysalo et
al., 2008). As the first broad cross-corpus evaluation
using a state-of-the-art machine learning method for
PPI extraction, our results support and extend the
key finding that F-score performance results mea-
sured on different corpora cannot, in general, be
meaningfully compared.
The co-occurrence baseline numbers indicate one
reason for the high F-score variance between the
corpora. The F-score metric is not invariant to the
distribution of positive and negative examples: for
example, halving the number of negative test exam-
ples is expected to approximately halve the number
of false positives at a given recall point. Thus, the
greater the fraction of true interactions in a corpus
is, the easier it is to reach high performance in terms
of F-score. This is reflected in co-occurrence re-
sults, which range from 24% to 70% depending on
the class distribution of the corpus.
This is a critical weakness of the F-score metric in
cross-corpus comparisons as, for example, the frac-
tion of true interactions out of all candidates is 50%
on the LLL corpus but only 17% on AImed. By
contrast to the large differences in performance mea-
sured using F-score, we find that for the distribution-
invariant AUC measure the performance for all of
the AImed, BioInfer, IEPA, and LLL corpora falls in
the narrow range of 83-85%. In terms of AUC, per-
formance on the HPRD50 corpus is an outlier, being
approximately three percentage units lower than for
any other corpus. Nevertheless, the results provide a
strong argument in favor of applying the AUC met-
ric instead of, or in addition to, F-score. AUC is also
more stable in terms of variance.
Finally, we note that the similar performance in
terms of AUC for corpora with as widely differing
sizes as LLL and BioInfer indicates that past a rel-
atively modest number of examples, increasing cor-
pus size has a surprisingly small effect on the perfor-
mance of the method. A similar finding can be seen,
for example, in the relatively flat learning curve of
Giuliano et al (2006). While the issue requires fur-
ther investigation, these results suggest that there
may be more value in investing effort in develop-
ing better learning methods as opposed to larger cor-
pora.
3.3 Performance compared to other methods
We next discuss the performance of our method
compared to other methods introduced in the liter-
ature and the challenges of meaningful comparison,
where we identify three major issues.
First, as indicated by the results above, differ-
ences in the makeup of different corpora render
cross-corpus comparisons in terms of F-score es-
sentially meaningless. As F-score is typically the
only metric for which results are reported in the PPI
extraction literature, we are limited to comparing
against results on single corpora. We consider the
AImed and BioInfer evaluations to be the most rele-
vant ones, as these corpora are sufficiently large for
training and reliably testing machine learning meth-
ods. As the present study is, to the best of our knowl-
6
P R F
(Giuliano et al, 2006) 60.9% 57.2% 59.0%
All-dependency-paths graph kernel 52.9% 61.8% 56.4%
(Bunescu and Mooney, 2006) 65.0% 46.4% 54.2%
(S?tre et al, 2008) 64.3% 44.1% 52.0%
(Mitsumori et al, 2006) 54.2% 42.6% 47.7%
(Yakushiji et al, 2005) 33.7% 33.1% 33.4%
Table 2: (P)recision, (R)ecall and (F)-score results for methods evaluated on AImed with the correct cross-validation
methodology.
edge, the first to report machine learning method
performance on BioInfer, we will focus on AImed
in the following comparison.
Second, the cross-validation strategy used in eval-
uation has a large impact on measured performance.
In earlier system evaluations, two major strategies
for defining the splits used in cross-validation can
be observed. The approach used by Bunescu and
Mooney (2006), which we consider the correct one,
is to split the data into folds on level of docu-
ments. This guarantees that all pairs generated from
the same document are always either in the train-
ing set or in the test set. Another approach is to
pool all the generated pairs together, and then ran-
domly split them to folds. To illustrate the signifi-
cance of this choice, consider two interaction candi-
dates extracted from the same sentence, e.g. from
a statement of the form ?P1 and P2 [. . . ] P3?,
where ?[. . . ]? is any statement of interaction or non-
interaction. Due to the near-identity of contexts, a
machine learning method will easily learn to predict
that the label of the pair (P1, P2) should match that
of (P1, P3). However, such ?learning? will clearly
not generalize. This approach must thus be consid-
ered invalid, because allowing pairs generated from
same sentences to appear in different folds leads to
an information leak between the training and test
sets. S?tre et al (2008) observed that adopting the
latter cross-validation strategy on AImed could lead
up to 18 F-score percentage unit overestimation of
performance. For this reason, we will not consider
results listed in the ?False 10-fold cross-validation?
table (2b) of S?tre et al (2008).
With these restrictions in place, we now turn to
comparison with relevant results reported in related
research, summarized in Table 2. We note that
Bunescu and Mooney (2006) only applied evalua-
tion criteria where it is enough to extract only one
occurrence of each mention of an interaction from
each abstract, while the other results shown were
evaluated using the same criteria as applied here.
The former approach can produce higher perfor-
mance: the evaluation of Giuliano et al (2006) in-
cludes both alternatives, and their method achieves
an F-score of 63.9% under the former criterion,
which they term One Answer per Relation in a
given Document (OARD). Our method outperforms
most studies using similar evaluation methodology,
with the exception being the approach of Giuliano
et al (2006). This result is somewhat surprising,
as the method proposed by Giuliano does not ap-
ply any form of parsing but relies instead only on
the sequential order of the words. This brings us
to our third point regarding comparability of meth-
ods. As pointed out by S?tre et al (2008), the
AImed corpus allows remarkably different ?inter-
pretations? regarding the number of interacting and
non-interacting pairs. For example, where we have
identified 1000 interacting and 4834 non-interacting
protein pairs in AImed, in the data used by Giuliano
there are eight more interacting and 200 fewer non-
interacting pairs. The corpus can also be prepro-
cessed in a number of ways. In particular we noticed
that whereas protein names are always blinded in our
data, in the data used by Giuliano protein names are
sometimes partly left visible. As Giuliano has gen-
erously made his method implementation available2,
we were able to test the performance of his system
on the data we used in our experiments. This re-
sulted in an F-score of 52.4%.
Finally, there remains an issue of parameter se-
lection. For sparse RLS the values of the regular-
2Available at http://tcc.itc.it/research/
textec/tools-resources/jsre.html.
7
ization parameter ? and the decision threshold sep-
arating the positive and negative classes must be
chosen, which can be problematic when no sepa-
rate data for choosing them is available. Choos-
ing from several parameter values the ones that give
best results in testing, or picking the best point
from a precision/recall curve when evaluating in
terms of F-score, will lead to an overoptimistic eval-
uation of performance. This issue has often not
been addressed in earlier evaluations that do cross-
validation on a whole corpus. We choose the pa-
rameters by doing further leave-one-document-out
cross-validation within each round of 10-fold-cross-
validation, on the nine folds that constitute the train-
ing set.
As a conclusion, we observe the results achieved
with the all-dependency-paths kernel to be state-of-
the-art level. However, differences in evaluation
strategies and the large variance exhibited in the re-
sults make it impossible to state which of the sys-
tems considered can be expected in general to per-
form best. We encourage future PPI-system evalua-
tions to report AUC and F-score results over mul-
tiple corpora, following clearly defined evaluation
strategies, to bring further clarity to this issue.
4 Conclusions and future work
In this paper we have proposed a graph kernel
approach to extracting protein-protein interactions,
which captures the information in unrestricted de-
pendency graphs to a format that kernel based learn-
ing algorithms can process. The method combines
syntactic analysis with a representation of the lin-
ear order of the sentence, and considers all possi-
ble paths connecting any two vertices in the result-
ing graph. We demonstrate state-of-the art perfor-
mance for the approach. All software developed in
the course of this study is made publicly available at
http://mars.cs.utu.fi/PPICorpora.
We identify a number of issues which make re-
sults achieved with different evaluation strategies
and resources incomparable, or even incorrect. In
our experimental design we consider the problems
related to differences across corpora, the effects dif-
ferent cross-validation strategies have, and how pa-
rameter selection can be done. Our recommendation
is to provide evaluations over different corpora, to
use document-level cross-validation and to always
selected parameters on the training set.
We draw attention to the behaviour of the F-score
metric over corpora with differing pair distributions.
The higher the relative frequency of interacting pairs
is, the higher the performance can be expected to
be. This is noticed both for the graph kernel method
and for the naive co-occurrence baseline. Indeed,
the strategy of just stating that all pairs interact leads
to as high result as 70% F-score on one of the cor-
pora. We consider AUC as an alternative measure
that does not exhibit such behaviour, as it is invari-
ant to the distribution of pairs. The AUC metric is
much more stable across all the corpora, and never
gives better results than random for approaches such
as the naive co-occurrence.
Though we only consider binary interactions in
this work, the graph representations have the prop-
erty that they could be used to represent more com-
plex structures than pairs. The availability of cor-
pora that annotate complex interactions, such as the
full BioInfer and GENIA, makes training a PPI ex-
traction system for extracting complex interactions
an important avenue of future research. However,
how to avoid the combinatorial explosion following
from considering triplets, quartets etc. remains an
open question. Also, the performance of the cur-
rent approaches may need to be yet improved before
extending them to recognize complex interactions.
Acknowledgements
We would like to thank Razvan Bunescu, Claudio
Giuliano and Rune S?tre for their generous assis-
tance in providing us with data, software and infor-
mation about their work on PPI extraction. Further,
we thank CSC, the Finnish IT center for science,
for providing us extensive computational resources.
This work has been supported by the Academy of
Finland and the Finnish Funding Agency for Tech-
nology and Innovation, Tekes.
References
Andrew P. Bradley. 1997. The use of the area under
the ROC curve in the evaluation of machine learning
algorithms. Pattern Recognition, 30(7):1145?1159.
Razvan Bunescu and Raymond Mooney. 2005. A short-
est path dependency kernel for relation extraction. In
Proceedings of HLT/EMNLP?05, pages 724?731.
8
Razvan Bunescu and Raymond Mooney. 2006. Subse-
quence kernels for relation extraction. In Proceedings
of NIPS?05, pages 171?178. MIT Press.
Razvan C. Bunescu, Ruifang Ge, Rohit J. Kate, Ed-
ward M. Marcotte, Raymond J. Mooney, Arun Ku-
mar Ramani, and Yuk Wah Wong. 2005. Compar-
ative experiments on learning information extractors
for proteins and their interactions. Artif Intell Med,
33(2):139?155.
Eugene Charniak and Matthew Lease. 2005. Parsing
biomedical literature. In Proceedings of IJCNLP?05,
pages 58?69.
Andrew Brian Clegg and Adrian Shepherd. 2007.
Benchmarking natural-language parsers for biological
applications using dependency graphs. BMC Bioinfor-
matics, 8(1):24.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In Pro-
ceedings of LREC?06, pages 449?454.
J. Ding, D. Berleant, D. Nettleton, and E. Wurtele. 2002.
Mining MEDLINE: abstracts, sentences, or phrases?
In Proceedings of PSB?02, pages 326?337.
Katrin Fundel, Robert Kuffner, and Ralf Zimmer. 2007.
RelEx?Relation extraction using dependency parse
trees. Bioinformatics, 23(3):365?371.
Thomas Ga?rtner, Peter A. Flach, and Stefan Wrobel.
2003. On graph kernels: Hardness results and efficient
alternatives. In COLT?03, pages 129?143. Springer.
Claudio Giuliano, Alberto Lavelli, and Lorenza Romano.
2006. Exploiting shallow linguistic information for re-
lation extraction from biomedical literature. In Pro-
ceedings of EACL?06.
James A. Hanley and B. J. McNeil. 1982. The meaning
and use of the area under a receiver operating charac-
teristic (roc) curve. Radiology, 143(1):29?36.
Lawrence Hunter, Zhiyong Lu, James Firby, William A.
Baumgartner, Helen L Johnson, Philip V. Ogren, and
K. Bretonnel Cohen. 2008. OpenDMAP: An open-
source, ontology-driven concept analysis engine, with
applications to capturing knowledge regarding protein
transport, protein interactions and cell-specific gene
expression. BMC Bioinformatics, 9(78).
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Carl D. Meyer. 2000. Matrix analysis and applied linear
algebra. Society for Industrial and Applied Mathe-
matics.
Tomohiro Mitsumori, Masaki Murata, Yasushi Fukuda,
Kouichi Doi, and Hirohumi Doi. 2006. Extracting
protein-protein interaction information from biomed-
ical text with svm. IEICE - Trans. Inf. Syst., E89-
D(8):2464?2466.
Claire Ne?dellec. 2005. Learning language in logic -
genic interaction extraction challenge. In Proceedings
of LLL?05.
Tapio Pahikkala, Jorma Boberg, and Tapio Salakoski.
2006a. Fast n-fold cross-validation for regularized
least-squares. In Proceedings of SCAI?06, pages 83?
90.
Tapio Pahikkala, Evgeni Tsivtsivadze, Jorma Boberg, and
Tapio Salakoski. 2006b. Graph kernels versus graph
representations: a case study in parse ranking. In Pro-
ceedings of the ECML/PKDD?06 workshop on Mining
and Learning with Graphs.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007a. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Filip Ginter, Veronika Laippala, Ka-
tri Haverinen, Juho Heimonen, and Tapio Salakoski.
2007b. On the unification of syntactic annotations un-
der the stanford dependency scheme: A case study on
BioInfer and GENIA. In Proceedings of BioNLP?07,
pages 25?32.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari
Bjo?rne, Filip Ginter, and Tapio Salakoski. 2008.
Comparative analysis of five protein-protein interac-
tion corpora. BMC Bioinformatics, special issue,
9(Suppl 3):S6.
Ryan Rifkin, Gene Yeo, and Tomaso Poggio, 2003. Reg-
ularized Least-squares Classification, volume 190 of
NATO Science Series III: Computer and System Sci-
ences, chapter 7, pages 131?154. IOS Press.
Rune S?tre, Kenji Sagae, and Jun?ichi Tsujii. 2008. Syn-
tactic features for protein-protein interaction extrac-
tion. In Proceedings of LBM?07, volume 319, pages
6.1?6.14.
Akane Yakushiji, Yusuke Miyao, Yuka Tateisi, and
Jun?ichi Tsujii. 2005. Biomedical information ex-
traction with predicate-argument structure patterns. In
Proceedings of SMBM?05, pages 60?69.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation
extraction. J. Mach. Learn. Res., 3:1083?1106.
9
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 779?787,
Beijing, August 2010
Evaluating Dependency Representation for Event Extraction
Makoto Miwa1 Sampo Pyysalo1 Tadayoshi Hara1 Jun?ichi Tsujii1,2,3
1Department of Computer Science, the University of Tokyo
2School of Computer Science, University of Manchester
3National Center for Text Mining
{mmiwa,smp,harasan,tsujii}@is.s.u-tokyo.ac.jp
Abstract
The detailed analyses of sentence struc-
ture provided by parsers have been applied
to address several information extraction
tasks. In a recent bio-molecular event ex-
traction task, state-of-the-art performance
was achieved by systems building specif-
ically on dependency representations of
parser output. While intrinsic evalua-
tions have shown significant advances in
both general and domain-specific pars-
ing, the question of how these translate
into practical advantage is seldom con-
sidered. In this paper, we analyze how
event extraction performance is affected
by parser and dependency representation,
further considering the relation between
intrinsic evaluation and performance at
the extraction task. We find that good
intrinsic evaluation results do not always
imply good extraction performance, and
that the types and structures of differ-
ent dependency representations have spe-
cific advantages and disadvantages for the
event extraction task.
1 Introduction
Advanced syntactic parsing methods have been
shown to effective for many information extrac-
tion tasks. The BioNLP 2009 Shared Task, a re-
cent bio-molecular event extraction task, is one
such task: analysis showed that the application of
a parser correlated with high rank in the task (Kim
et al, 2009). The automatic extraction of bio-
molecular events from text is important for a num-
ber of advanced domain applications such as path-
way construction, and event extraction thus a key
task in Biomedical Natural Language Processing
(BioNLP).
Methods building feature representations and
extraction rules around dependency representa-
tions of sentence syntax have been successfully
applied to a number of tasks in BioNLP. Several
parsers and representations have been applied in
high-performing methods both in domain studies
in general and in the BioNLP?09 shared task in
particular, but no direct comparison of parsers or
representations has been performed. Likewise,
a number of evaluation of parser outputs against
gold standard corpora have been performed in the
domain, but the broader implications of the results
of such intrinsic evaluations are rarely considered.
The BioNLP?09 shared task involved documents
contained also in the GENIA treebank (Tateisi et
al., 2005), creating an opportunity for direct study
of intrinsic and task-oriented evaluation results.
As the treebank can be converted into various de-
pendency formats using existing format conver-
sion methods, evaluation can further be extended
to cover the effects of different representations.
In this this paper, we consider three types of de-
pendency representation and six parsers, evaluat-
ing their performance from two different aspects:
dependency-based intrinsic evaluation, and effec-
tiveness for bio-molecular event extraction with a
state-of-the-art event extraction system. Compar-
ison of intrinsic and task-oriented evaluation re-
779
	








	
 


 
	

 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 102?107,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
BRAT: a Web-based Tool for NLP-Assisted Text Annotation
Pontus Stenetorp1? Sampo Pyysalo2,3? Goran Topic?1
Tomoko Ohta1,2,3 Sophia Ananiadou2,3 and Jun?ichi Tsujii4
1Department of Computer Science, The University of Tokyo, Tokyo, Japan
2School of Computer Science, University of Manchester, Manchester, UK
3National Centre for Text Mining, University of Manchester, Manchester, UK
4Microsoft Research Asia, Beijing, People?s Republic of China
{pontus,smp,goran,okap}@is.s.u-tokyo.ac.jp
sophia.ananiadou@manchester.ac.uk
jtsujii@microsoft.com
Abstract
We introduce the brat rapid annotation tool
(BRAT), an intuitive web-based tool for text
annotation supported by Natural Language
Processing (NLP) technology. BRAT has
been developed for rich structured annota-
tion for a variety of NLP tasks and aims
to support manual curation efforts and in-
crease annotator productivity using NLP
techniques. We discuss several case stud-
ies of real-world annotation projects using
pre-release versions of BRAT and present
an evaluation of annotation assisted by se-
mantic class disambiguation on a multi-
category entity mention annotation task,
showing a 15% decrease in total annota-
tion time. BRAT is available under an open-
source license from: http://brat.nlplab.org
1 Introduction
Manually-curated gold standard annotations are
a prerequisite for the evaluation and training of
state-of-the-art tools for most Natural Language
Processing (NLP) tasks. However, annotation is
also one of the most time-consuming and finan-
cially costly components of many NLP research
efforts, and can place heavy demands on human
annotators for maintaining annotation quality and
consistency. Yet, modern annotation tools are
generally technically oriented and many offer lit-
tle support to users beyond the minimum required
functionality. We believe that intuitive and user-
friendly interfaces as well as the judicious appli-
cation of NLP technology to support, not sup-
plant, human judgements can help maintain the
quality of annotations, make annotation more ac-
cessible to non-technical users such as subject
?These authors contributed equally to this work
Figure 1: Visualisation examples. Top: named en-
tity recognition, middle: dependency syntax, bot-
tom: verb frames.
domain experts, and improve annotation produc-
tivity, thus reducing both the human and finan-
cial cost of annotation. The tool presented in
this work, BRAT, represents our attempt to realise
these possibilities.
2 Features
2.1 High-quality Annotation Visualisation
BRAT is based on our previously released open-
source STAV text annotation visualiser (Stene-
torp et al 2011b), which was designed to help
users gain an understanding of complex annota-
tions involving a large number of different se-
mantic types, dense, partially overlapping text an-
notations, and non-projective sets of connections
between annotations. Both tools share a vector
graphics-based visualisation component, which
provide scalable detail and rendering. BRAT in-
tegrates PDF and EPS image format export func-
tionality to support use in e.g. figures in publica-
tions (Figure 1).
102
Figure 2: Screenshot of the main BRAT user-interface, showing a connection being made between the
annotations for ?moving? and ?Citibank?.
2.2 Intuitive Annotation Interface
We extended the capabilities of STAV by imple-
menting support for annotation editing. This was
done by adding functionality for recognising stan-
dard user interface gestures familiar from text ed-
itors, presentation software, and many other tools.
In BRAT, a span of text is marked for annotation
simply by selecting it with the mouse by ?drag-
ging? or by double-clicking on a word. Similarly,
annotations are linked by clicking with the mouse
on one annotation and dragging a connection to
the other (Figure 2).
BRAT is browser-based and built entirely using
standard web technologies. It thus offers a fa-
miliar environment to annotators, and it is pos-
sible to start using BRAT simply by pointing a
standards-compliant modern browser to an instal-
lation. There is thus no need to install or dis-
tribute any additional annotation software or to
use browser plug-ins. The use of web standards
also makes it possible for BRAT to uniquely iden-
tify any annotation using Uniform Resource Iden-
tifiers (URIs), which enables linking to individual
annotations for discussions in e-mail, documents
and on web pages, facilitating easy communica-
tion regarding annotations.
2.3 Versatile Annotation Support
BRAT is fully configurable and can be set up to
support most text annotation tasks. The most ba-
sic annotation primitive identifies a text span and
assigns it a type (or tag or label), marking for e.g.
POS-tagged tokens, chunks or entity mentions
(Figure 1 top). These base annotations can be
connected by binary relations ? either directed or
undirected ? which can be configured for e.g. sim-
ple relation extraction, or verb frame annotation
(Figure 1 middle and bottom). n-ary associations
of annotations are also supported, allowing the an-
notation of event structures such as those targeted
in the MUC (Sundheim, 1996), ACE (Doddington
et al 2004), and BioNLP (Kim et al 2011) In-
formation Extraction (IE) tasks (Figure 2). Addi-
tional aspects of annotations can be marked using
attributes, binary or multi-valued flags that can
be added to other annotations. Finally, annotators
can attach free-form text notes to any annotation.
In addition to information extraction tasks,
these annotation primitives allow BRAT to be
configured for use in various other tasks, such
as chunking (Abney, 1991), Semantic Role La-
beling (Gildea and Jurafsky, 2002; Carreras
and Ma`rquez, 2005), and dependency annotation
(Nivre, 2003) (See Figure 1 for examples). Fur-
ther, both the BRAT client and server implement
full support for the Unicode standard, which al-
low the tool to support the annotation of text us-
ing e.g. Chinese or Devana?gar?? characters. BRAT
is distributed with examples from over 20 cor-
pora for a variety of tasks, involving texts in seven
different languages and including examples from
corpora such as those introduced for the CoNLL
shared tasks on language-independent named en-
tity recognition (Tjong Kim Sang and De Meul-
der, 2003) and multilingual dependency parsing
(Buchholz and Marsi, 2006).
BRAT also implements a fully configurable sys-
tem for checking detailed constraints on anno-
tation semantics, for example specifying that a
TRANSFER event must take exactly one of each
of GIVER, RECIPIENT and BENEFICIARY argu-
ments, each of which must have one of the types
PERSON, ORGANIZATION or GEO-POLITICAL
ENTITY, as well as a MONEY argument of type
103
Figure 3: Incomplete TRANSFER event indicated
to the annotator
MONEY, and may optionally take a PLACE argu-
ment of type LOCATION (LDC, 2005). Constraint
checking is fully integrated into the annotation in-
terface and feedback is immediate, with clear vi-
sual effects marking incomplete or erroneous an-
notations (Figure 3).
2.4 NLP Technology Integration
BRAT supports two standard approaches for inte-
grating the results of fully automatic annotation
tools into an annotation workflow: bulk anno-
tation imports can be performed by format con-
version tools distributed with BRAT for many
standard formats (such as in-line and column-
formatted BIO), and tools that provide standard
web service interfaces can be configured to be in-
voked from the user interface.
However, human judgements cannot be re-
placed or based on a completely automatic analy-
sis without some risk of introducing bias and re-
ducing annotation quality. To address this issue,
we have been studying ways to augment the an-
notation process with input from statistical and
machine learning methods to support the annota-
tion process while still involving human annotator
judgement for each annotation.
As a specific realisation based on this approach,
we have integrated a recently introduced ma-
chine learning-based semantic class disambigua-
tion system capable of offering multiple outputs
with probability estimates that was shown to be
able to reduce ambiguity on average by over 75%
while retaining the correct class in on average
99% of cases over six corpora (Stenetorp et al
2011a). Section 4 presents an evaluation of the
contribution of this component to annotator pro-
ductivity.
2.5 Corpus Search Functionality
BRAT implements a comprehensive set of search
functions, allowing users to search document col-
Figure 4: The BRAT search dialog
lections for text span annotations, relations, event
structures, or simply text, with a rich set of search
options definable using a simple point-and-click
interface (Figure 4). Additionally, search results
can optionally be displayed using keyword-in-
context concordancing and sorted for browsing
using any aspect of the matched annotation (e.g.
type, text, or context).
3 Implementation
BRAT is implemented using a client-server ar-
chitecture with communication over HTTP using
JavaScript Object Notation (JSON). The server is
a RESTful web service (Fielding, 2000) and the
tool can easily be extended or adapted to switch
out the server or client. The client user interface is
implemented using XHTML and Scalable Vector
Graphics (SVG), with interactivity implemented
using JavaScript with the jQuery library. The
client communicates with the server using Asyn-
chronous JavaScript and XML (AJAX), which
permits asynchronous messaging.
BRAT uses a stateless server back-end imple-
mented in Python and supports both the Common
Gateway Interface (CGI) and FastCGI protocols,
the latter allowing response times far below the
100 ms boundary for a ?smooth? user experience
without noticeable delay (Card et al 1983). For
server side annotation storage BRAT uses an easy-
to-process file-based stand-off format that can be
converted from or into other formats; there is no
need to perform database import or export to in-
terface with the data storage. The BRAT server in-
104
Figure 5: Example annotation from the BioNLP Shared Task 2011 Epigenetics and Post-translational
Modifications event extraction task.
stallation requires only a CGI-capable web server
and the set-up supports any number of annotators
who access the server using their browsers, on any
operating system, without separate installation.
Client-server communication is managed so
that all user edit operations are immediately sent
to the server, which consolidates them with the
stored data. There is no separate ?save? operation
and thus a minimal risk of data loss, and as the
authoritative version of all annotations is always
maintained by the server, there is no chance of
conflicting annotations being made which would
need to be merged to produce an authoritative ver-
sion. The BRAT client-server architecture also
makes real-time collaboration possible: multiple
annotators can work on a single document simul-
taneously, seeing each others edits as they appear
in a document.
4 Case Studies
4.1 Annotation Projects
BRAT has been used throughout its development
during 2011 in the annotation of six different cor-
pora by four research groups in efforts that have
in total involved the creation of well-over 50,000
annotations in thousands of documents compris-
ing hundreds of thousands of words.
These projects include structured event an-
notation for the domain of cancer biology,
Japanese verb frame annotation, and gene-
mutation-phenotype relation annotation. One
prominent effort making use of BRAT is the
BioNLP Shared Task 2011,1 in which the tool was
used in the annotation of the EPI and ID main
task corpora (Pyysalo et al 2012). These two
information extraction tasks involved the annota-
tion of entities, relations and events in the epige-
netics and infectious diseases subdomains of biol-
ogy. Figure 5 shows an illustration of shared task
annotations.
Many other annotation efforts using BRAT are
still ongoing. We refer the reader to the BRAT
1http://2011.bionlp-st.org
Mode Total Type Selection
Normal 45:28 13:49
Rapid 39:24 (-6:04) 09:35 (-4:14)
Table 1: Total annotation time, portion spent se-
lecting annotation type, and absolute improve-
ment for rapid mode.
website2 for further details on current and past an-
notation projects using BRAT.
4.2 Automatic Annotation Support
To estimate the contribution of the semantic class
disambiguation component to annotation produc-
tivity, we performed a small-scale experiment in-
volving an entity and process mention tagging
task. The annotation targets were of 54 dis-
tinct mention types (19 physical entity and 35
event/process types) marked using the simple
typed-span representation. To reduce confound-
ing effects from annotator productivity differ-
ences and learning during the task, annotation was
performed by a single experienced annotator with
a Ph.D. in biology in a closely related area who
was previously familiar with the annotation task.
The experiment was performed on publication
abstracts from the biomolecular science subdo-
main of glucose metabolism in cancer. The texts
were drawn from a pool of 1,750 initial candi-
dates using stratified sampling to select pairs of
10-document sets with similar overall statistical
properties.3 Four pairs of 10 documents (80 in to-
tal) were annotated in the experiment, with 10 in
each pair annotated with automatic support and 10
without, in alternating sequence to prevent learn-
ing effects from favouring either approach.
The results of this experiment are summarized
in Table 1 and Figure 6. In total 1,546 annotations
were created in normal mode and 1,541 annota-
2http://brat.nlplab.org
3Document word count and expected annotation count,
were estimated from the output of NERsuite, a freely avail-
able CRF-based NER tagger: http://nersuite.nlplab.org
105
0500
1000
1500
2000
2500
3000
Normal Mode Rapid Mode
Tim
e(
se
co
nd
s)
Figure 6: Allocation of annotation time. GREEN
signifies time spent on selecting annotation type
and BLUE the remaining annotation time.
tions in rapid mode; the sets are thus highly com-
parable. We observe a 15.4% reduction in total
annotation time, and, as expected, this is almost
exclusively due to a reduction in the time the an-
notator spent selecting the type to assign to each
span, which is reduced by 30.7%; annotation time
is otherwise stable across the annotation modes
(Figure 6). The reduction in the time spent in se-
lecting the span is explained by the limiting of the
number of candidate types exposed to the annota-
tor, which were decreased from the original 54 to
an average of 2.88 by the semantic class disam-
biguation component (Stenetorp et al 2011a).
Although further research is needed to establish
the benefits of this approach in various annotation
tasks, we view the results of this initial experi-
ment as promising regarding the potential of our
approach to using machine learning to support an-
notation efforts.
5 Related Work and Conclusions
We have introduced BRAT, an intuitive and user-
friendly web-based annotation tool that aims to
enhance annotator productivity by closely inte-
grating NLP technology into the annotation pro-
cess. BRAT has been and is being used for several
ongoing annotation efforts at a number of aca-
demic institutions and has so far been used for
the creation of well-over 50,000 annotations. We
presented an experiment demonstrating that inte-
grated machine learning technology can reduce
the time for type selection by over 30% and over-
all annotation time by 15% for a multi-type entity
mention annotation task.
The design and implementation of BRAT was
informed by experience from several annotation
tasks and research efforts spanning more than
a decade. A variety of previously introduced
annotation tools and approaches also served to
guide our design decisions, including the fast an-
notation mode of Knowtator (Ogren, 2006), the
search capabilities of the XConc tool (Kim et al
2008), and the design of web-based systems such
as MyMiner (Salgado et al 2010), and GATE
Teamware (Cunningham et al 2011). Using ma-
chine learning to accelerate annotation by sup-
porting human judgements is well documented in
the literature for tasks such as entity annotation
(Tsuruoka et al 2008) and translation (Mart??nez-
Go?mez et al 2011), efforts which served as in-
spiration for our own approach.
BRAT, along with conversion tools and exten-
sive documentation, is freely available under the
open-source MIT license from its homepage at
http://brat.nlplab.org
Acknowledgements
The authors would like to thank early adopters of
BRAT who have provided us with extensive feed-
back and feature suggestions. This work was sup-
ported by Grant-in-Aid for Specially Promoted
Research (MEXT, Japan), the UK Biotechnology
and Biological Sciences Research Council (BB-
SRC) under project Automated Biological Event
Extraction from the Literature for Drug Discov-
ery (reference number: BB/G013160/1), and the
Royal Swedish Academy of Sciences.
106
References
Steven Abney. 1991. Parsing by chunks. Principle-
based parsing, 44:257?278.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of the Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
pages 149?164.
Stuart K. Card, Thomas P. Moran, and Allen Newell.
1983. The psychology of human-computer interac-
tion. Lawrence Erlbaum Associates, Hillsdale, New
Jersey.
Xavier Carreras and Llu??s Ma`rquez. 2005. Introduc-
tion to the CoNLL-2005 shared task: Semantic Role
Labeling. In Proceedings of the 9th Conference on
Natural Language Learning, pages 152?164. Asso-
ciation for Computational Linguistics.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, Valentin Tablan, Niraj Aswani, Ian
Roberts, Genevieve Gorrell, Adam Funk, Angus
Roberts, Danica Damljanovic, Thomas Heitz,
Mark A. Greenwood, Horacio Saggion, Johann
Petrak, Yaoyong Li, and Wim Peters. 2011. Text
Processing with GATE (Version 6).
George Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The Automatic Content Extrac-
tion (ACE) program: Tasks, data, and evaluation. In
Proceedings of the 4th International Conference on
Language Resources and Evaluation, pages 837?
840.
Roy Fielding. 2000. REpresentational State Trans-
fer (REST). Architectural Styles and the Design
of Network-based Software Architectures. Univer-
sity of California, Irvine, page 120.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245?288.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008. Corpus annotation for mining biomedi-
cal events from literature. BMC Bioinformatics,
9(1):10.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011.
Overview of BioNLP Shared Task 2011. In Pro-
ceedings of BioNLP Shared Task 2011 Workshop,
pages 1?6, Portland, Oregon, USA, June. Associa-
tion for Computational Linguistics.
LDC. 2005. ACE (Automatic Content Extraction) En-
glish Annotation Guidelines for Events. Technical
report, Linguistic Data Consortium.
Pascual Mart??nez-Go?mez, Germa?n Sanchis-Trilles,
and Francisco Casacuberta. 2011. Online learn-
ing via dynamic reranking for computer assisted
translation. In Alexander Gelbukh, editor, Compu-
tational Linguistics and Intelligent Text Processing,
volume 6609 of Lecture Notes in Computer Science,
pages 93?105. Springer Berlin / Heidelberg.
Joakim Nivre. 2003. An Efficient Algorithm for Pro-
jective Dependency Parsing. In Proceedings of the
8th International Workshop on Parsing Technolo-
gies, pages 149?160.
Philip V. Ogren. 2006. Knowtator: A prote?ge? plug-in
for annotated corpus construction. In Proceedings
of the Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, Companion Volume:
Demonstrations, pages 273?275, New York City,
USA, June. Association for Computational Linguis-
tics.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Junichi Tsujii, and Sophia Ananiadou. 2012.
Overview of the ID, EPI and REL tasks of BioNLP
Shared Task 2011. BMC Bioinformatics, 13(suppl.
8):S2.
David Salgado, Martin Krallinger, Marc Depaule,
Elodie Drula, and Ashish V Tendulkar. 2010.
Myminer system description. In Proceedings of the
Third BioCreative Challenge Evaluation Workshop
2010, pages 157?158.
Pontus Stenetorp, Sampo Pyysalo, Sophia Ananiadou,
and Jun?ichi Tsujii. 2011a. Almost total recall: Se-
mantic category disambiguation using large lexical
resources and approximate string matching. In Pro-
ceedings of the Fourth International Symposium on
Languages in Biology and Medicine.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo,
Tomoko Ohta, Jin-Dong Kim, and Jun?ichi Tsujii.
2011b. BioNLP Shared Task 2011: Supporting Re-
sources. In Proceedings of BioNLP Shared Task
2011 Workshop, pages 112?120, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
Beth M. Sundheim. 1996. Overview of results of
the MUC-6 evaluation. In Proceedings of the Sixth
Message Understanding Conference, pages 423?
442. Association for Computational Linguistics.
Erik F. Tjong Kim Sang and Fien De Meulder.
2003. Introduction to the CoNLL-2003 shared
task: Language-independent named entity recogni-
tion. In Proceedings of the Seventh Conference on
Natural Language Learning at HLT-NAACL 2003,
pages 142?147.
Yoshimasa Tsuruoka, Jun?ichi Tsujii, and Sophia Ana-
niadou. 2008. Accelerating the annotation of
sparse named entities by dynamic sentence selec-
tion. BMC Bioinformatics, 9(Suppl 11):S8.
107
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 19?27,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Event Extraction for Post-Translational Modifications
Tomoko Ohta? Sampo Pyysalo? Makoto Miwa? Jin-Dong Kim? Jun?ichi Tsujii???
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
{okap,smp,mmiwa,jdkim,tsujii}@is.s.u-tokyo.ac.jp
Abstract
We consider the task of automatically
extracting post-translational modification
events from biomedical scientific publica-
tions. Building on the success of event
extraction for phosphorylation events in
the BioNLP?09 shared task, we extend the
event annotation approach to four major
new post-transitional modification event
types. We present a new targeted corpus of
157 PubMed abstracts annotated for over
1000 proteins and 400 post-translational
modification events identifying the modi-
fied proteins and sites. Experiments with
a state-of-the-art event extraction system
show that the events can be extracted with
52% precision and 36% recall (42% F-
score), suggesting remaining challenges
in the extraction of the events. The an-
notated corpus is freely available in the
BioNLP?09 shared task format at the GE-
NIA project homepage.1
1 Introduction
Post-translational-modifications (PTM), amino
acid modifications of proteins after translation, are
one of the posterior processes of protein biosyn-
thesis for many proteins, and they are critical
for determining protein function such as its ac-
tivity state, localization, turnover and interac-
tions with other biomolecules (Mann and Jensen,
2003). Since PTM alter the properties of a pro-
tein by attaching one or more biochemical func-
tional groups to amino acids, understanding of
the mechanism and effects of PTM are a major
goal in the recent molecular biology, biomedicine
and pharmacology fields. In particular, epige-
netic (?outside conventional genetics?) regulation
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA
of gene expression has a crucial role in these fields
and PTM-like modifications of biomolecules are a
burning issue. For instance, tissue specific or con-
text dependent expression of many proteins is now
known to be controlled by specific PTM of his-
tone proteins, such as Methylation and Acetylation
(Jaenisch and Bird, 2003). This Methylation and
Acetylation of specific amino acid residues in his-
tone proteins are strongly implicated in unwinding
the nucleosomes and exposing genes to transcrip-
tion, replication and DNA repairing machinery.
The recent BioNLP?09 Shared Task on Event
Extraction (Kim et al, 2009a) (below, BioNLP
shared task) represented the first community-wide
step toward the extraction of fine-grained event
representations of information from biomolecular
domain publications (Ananiadou et al, 2010). The
nine event types targeted in the task included one
PTM type, Phosphorylation, whose extraction in-
volved identifying the modified protein and, when
stated, the specific phosphorylated site. The re-
sults of the shared task showed this PTM event to
be single most reliably extracted event type in the
data, with the best-performing system for the event
type achieving 91% precision and 76% recall
(83% F-score) in the extraction of phosphorylation
events (Buyko et al, 2009). The results suggest
both that the event representation is well applica-
ble to PTM and that current extraction methods are
capable of reliable PTM extraction. Most of the
proposed state-of-the-art methods for event extrac-
tion are further largely machine-learning based.
This suggest that the coverage of many existing
methods could be straightforwardly extended to
new event types and domains by extending the
scope of available PTM annotations and retrain-
ing the methods on newly annotated data. In this
study, we take such an annotation-based approach
to extend the extraction capabilities of state of the
art event extraction methods for PTM.
19
Term Count
Phosphorylation 172875 50.90%
Methylation 49780 14.66%
Glycosylation 36407 10.72%
Hydroxylation 20141 5.93%
Acetylation 18726 5.51%
Esterification 7836 2.31%
Ubiquitination 6747 1.99%
ADP-ribosylation 5259 1.55%
Biotinylation 4369 1.29%
Sulfation 3722 1.10%
. . .
TOTAL 339646 100%
Table 1: PTM mentions in PubMed. The number
of citations returned by the PubMed search engine
for each PTM term shown together with the frac-
tion of the total returned for all searches. Searches
were performed with the terms as shown, allow-
ing MeSH term expansion and other optimizations
provided by the Entrez search.
2 Corpus Annotation
We next discuss the selection of the annotated
PTM types and source texts and present the rep-
resentation and criteria used in annotation.
2.1 Event Types
A central challenge in the automatic extraction
of PTMs following the relatively data-intensive
BioNLP shared task model is the sheer number
of different modifications: the number of known
PTM types is as high as 300 and constantly grow-
ing (Witze et al, 2007). Clearly, the creation of
a manually annotated resource with even mod-
est coverage of statements of each of the types
would be a formidable undertaking. We next
present an analysis of PTM statement occurrences
in PubMed as the first step toward resolving this
challenge.
We estimated the frequency of mentions of
prominent PTM types by combining MeSH
ontology2 PTM terms with terms occurring
in the post-translational protein
modification branch of the Gene Ontology
(The Gene Ontology Consortium, 2000). After
removing variants (e.g. polyamination for amina-
tion or dephosphorylation for phosphorylation)
and two cases judged likely to occur frequently
2http://www.nlm.nih.gov/mesh/meshhome.
html
in non-PTM contexts (hydration and oxidation),
we searched PubMed for the remaining 31 PTM
types. The results for the most frequent types
are shown in Table 1. We find a power-law
- like distribution with phosphorylation alone
accounting for over 50% of the total, and the top
6 types together for over 90%. By contrast, the
bottom ten types together represent less than a
percent of total occurrences.
This result implies that fair coverage of individ-
ual PTM event mentions can be achieved without
considering even dozens of different PTM event
types, let alne hundreds. Thus, as a step toward
extending the coverage of event extraction systems
for PTM, we chose to focus limited resources on
annotating a small selection of types so that a num-
ber of annotations sufficient for supervised learn-
ing and stable evaluation can be provided. To
maximize the utility of the created annotation, the
types were selected based on their frequency of oc-
currence.
2.2 Text Selection
Biomedical domain corpora are frequently anno-
tated from selections of texts chosen as a sample
of publications in a particular subdomain of inter-
est. While several areas in present-day molecu-
lar biology are likely to provide ample source data
for PTM statements, a sample of articles from any
subdomain is unlikely to provide a well-balanced
distribution of event types: for example, the most
frequent PTM event type annotated in the GENIA
event corpus occurs more than 10 times as often
as the second most frequent (Kim et al, 2008).
Further, avoiding explicit subdomain restrictions
is not alone sufficient to assure a balanced distri-
bution of event types: in the BioInfer corpus, for
which sentences were selected on the basis of their
containing mentions of protein pairs known to in-
teract, the most frequent PTM type is again anno-
tated nearly four times as often as the second most
frequent (Pyysalo et al, 2007).
To focus annotation efforts on texts relevant to
PTM and to guarantee that the annotation results
in relatively balanced numbers of PTM events of
each targeted type, we decided to annotate a tar-
geted set of source texts instead of a random sam-
ple of texts for a particular subdomain. This type
of targeted annotation involves a risk of introduc-
ing bias: a badly performed selection could pro-
duce a corpus that is not representative of the
20
PTM type AB FT
Acetylation 103 128
Glycosylation 226 336
Methylation 72 69
Phosphorylation 186 76
Hydroxylation 71 133
Table 2: Number of abstracts (AB) and full-text ar-
ticles (FT) tagged in PIR as containing PTM state-
ments.
statements expressing PTMs in text and thus poor
material for either meaningful evaluation or for
training methods with good generalization perfor-
mance.3 To avoid such bias, we decided to base
our selection of the source texts on an indepen-
dently annotated PTM resource with biological (as
opposed to textual) criteria for inclusion. Owing
in part to the recent interest in PTMs, there are
currently a wealth of resources providing different
levels of annotation for PTMs.
Here, we have chosen to base initial annotation
on corpora provided by the Protein Information
Resource4 (PIR) (Wu et al, 2003). These corpora
contain annotation for spans with evidence for five
different PTM types (Table 2), corresponding to
the five PTMs found above to occur in PubMed
with the highest frequency. A key feature setting
this resource apart from others we are aware of is
that it provides text-bound annotations identifying
the statement by which a PTM record was made in
the context of the full publication abstracts. While
this annotation is less specific and detailed than
the full BioNLP shared task markup, it could both
serve as an initial seed for annotation and assure
that the annotation agrees with relevant database
curation criteria. The PIR corpora have also been
applied in previous PTM extraction studies (e.g.
(Hu et al, 2005; Narayanaswamy et al, 2005)).
We judged that the annotated Phosphorylation
events in the BioNLP shared task data provide
sufficient coverage for the extraction of this PTM
type, and chose to focus on producing annota-
tion for the four other PTM types in the PIR data.
As the high extraction performance for phospho-
rylation events in the BioNLP shared task was
3One could easily gather PTM-rich texts by performing
protein name tagging and searching for known patterns such
as ?[PROTEIN] methylates [PROTEIN]?, but a corpus cre-
ated in this way would not necessarily provide significant
novelty over the original search patterns.
4http://pir.georgetown.edu
Protein Site PTM Count
collagen lysine Hydroxylate 44
myelin arginine Methylate 17
M protein N-terminal Glycosylate 2
EF-Tu lysine Methylate 1
Actobindin NH2 terminus Acetylate 0
Table 3: Example queried triples and match counts
from Medie.
achieved with annotated training data containing
215 PTM events, in view of the available resources
we set as an initial goal the annotation of 100
events of each of the four PTM types. To assure
that the annotated resource can be made publicly
available, we chose to use only the part of the PIR
annotations that identified sections of PubMed ab-
stracts, excluding full-text references and non-
PubMed abstracts. Together with the elimination
of duplicates and entries judged to fall outside of
the event annotation criteria (see Section 2.4), this
reduced the number of source texts below our tar-
get, necessitating a further selection strategy.
For further annotation, we aimed to select ab-
stracts that contain specific PTM statements iden-
tifying both the name of a modified protein and the
modified site. As for the initial selection, we fur-
ther wished to avoid limiting the search by search-
ing for any specific PTM expressions. To imple-
ment this selection, we used the Medie system5
(Ohta et al, 2006; Miyao et al, 2006) to search
PubMed for sentences where a specific protein and
a known modified site were found together in a
sentence occurring in an abstract annotated with a
specific MeSH term. The (protein name, modified
site, MeSH term) triples were extracted from PIR
records, substituting the appropriate MeSH term
for each PTM type. Some examples with the num-
ber of matching documents are shown in Table 3.
As most queries returned either no documents or a
small number of hits, we gave priority to responses
to queries that returned a small number of docu-
ments to avoid biasing the corpus toward proteins
whose modifications are frequently discussed.
We note that while the PIR annotations typically
identified focused text spans considerably shorter
than a single sentence and sentence-level search
was used in the Medie-based search to increase the
likelihood of identifying relevant statements, after
selection all annotation was performed to full ab-
stracts.
5http://www-tsujii.is.s.u-tokyo.ac.jp/
medie/
21
Event type Count
Protein modification 38
Phosphorylation 546
Dephosphorylation 28
Acetylation 7
Deacetylation 1
Ubiquitination 6
Deubiquitination 0
Table 4: GENIA PTM-related event types and
number of events in the GENIA event corpus.
Type names are simplified: the full form of e.g.
the Phosphorylation type in the GENIA event on-
tology is Protein amino acid phosphorylation.
Event type Arguments Count
Protein modification Theme 31
Phosphorylation Theme 261
Phosphorylation Theme, Site 230
Phosphorylation Site 20
Phosphorylation Theme, Cause 14
Dephosphorylation Theme 16
Table 5: GENIA PTM-related event arguments.
Only argument combinations appearing more than
10 times in the corpus shown.
2.3 Representation
The employed event representation can capture
the association of varying numbers of participants
in different roles. To apply an event extraction
approach to PTM, we must first define the tar-
geted representation, specifying the event types,
the mandatory and optional arguments, and the ar-
gument types ? the roles that the participants play
in the events. In the following, we discuss alterna-
tives and present the representation applied in this
work.
The GENIA Event ontology, applied in the
annotation of the GENIA Event corpus (Kim
et al, 2008) that served as the basis of the
BioNLP shared task data, defines a general Pro-
tein modification event type and six more specific
modification subtypes, shown in Table 4. While
the existing Acetylation type could thus be applied
together with the generic Protein modification
type to capture all the annotated PTMs, we be-
lieve that identification of the specific PTM type
is not only important to users of extracted PTM
events but also a relatively modest additional bur-
den for automatic extraction, owing to the unam-
biguous nature of typical expressions used to state
Figure 1: Alternative representations for PTM
statements including a catalyst in GENIA Event
corpus. PTM events can be annotated with a di-
rect Cause argument (top, PMID 9374467) or us-
ing an additional Regulation event (middle, PMID
10074432). The latter annotation can be applied
also in cases where there is no expression directly
?triggering? the secondary event (bottom, PMID
7613138).
PTMs in text. We thus chose to introduce three
additional specific modification types, Glycosyla-
tion, Hydroxylation and Methylation for use in the
annotation.
The GENIA Event corpus annotation allows
PTM events to take Theme, Site and Cause argu-
ments specifying the event participants, where the
Theme identifies the entity undergoing the mod-
ification, Site the specific region being modified,
and Cause an entity or event leading to the modi-
fication. Table 5 shows frequent argument combi-
nations appearing in the annotated data. We note
that while Theme is specified in the great majority
of events and Site in almost half, Cause is anno-
tated for less than 5% of the events. However, the
relative sparsity of Cause arguments in modifica-
tion events does not imply that e.g. catalysts of the
events are stated only very rarely, but instead re-
flects also the use of an alternative representation
for capturing such statements without a Cause ar-
gument for the PTM event. The GENIA event an-
notation specifies a Regulation event (with Posi-
tive regulation and Negative regulation subtypes),
used to annotate not only regulation in the biolog-
ical sense but also statements of general causality
between events: Regulation events are used gen-
erally to connect entities or events stated to other
events that they are stated to cause. Thus, PTM
22
events with a stated cause (e.g. a catalyst) can be
alternatively represented with a Cause argument
on the PTM event or using a separate Regulation
event (Figure 1). The interpretation of these event
structures is identical, and from an annotation per-
spective there are advantages to both. However,
for the purpose of automatic extraction it is impor-
tant to establish a consistent representation, and
thus only one should be used.
In this work, we follow the latter representation,
disallowing Cause arguments for annotated PTM
events and applying separate Regulation events
to capture e.g. catalyst associations. This choice
has the benefits of providing an uniform repre-
sentation for catalysis and inhibition (one involv-
ing a Positive regulation and the other a Nega-
tive regulation event), reducing the sparseness of
specific event structures in the data, and matching
the representation chosen in the BioNLP shared
task, thus maintaining compatibility with exist-
ing event extraction methods. Finally, we note
that while we initially expected that glycosylation
statements might frequently identify specific at-
tached side chains, necessitating the introduction
of an additional argument type to accurately cap-
ture all the stated information regarding Glycosy-
lation events, the data contained too few examples
for either training material or to justify the mod-
ification of the event model. We adopt the con-
straints applied in the BioNLP shared task regard-
ing the entity types allowed as specific arguments.
Thus, the representation we apply here annotated
PTM events with specific types, taking as Theme
argument a gene/gene product type entity and as
Site argument a physical (non-event) entity that
does not need to be assigned a specific type.
2.4 Annotation criteria
To create PTM annotation compatible with the
event extraction systems introduced for the
BioNLP shared task, we created annotation fol-
lowing the GENIA Event corpus annotation cri-
teria (Kim et al, 2008), as adapted for the shared
task. The criteria specify that annotation should be
applied to statements that involve the occurrence
of a change in the state of an entity ? even if stated
as having occurred in the past, or only hypotheti-
cally ? but not in cases merely discussing the state
or properties of entities, even if these can serve as
the basis for inference that a specific change has
occurred. We found that many of the spans an-
notated in PIR as evidence for PTM did not ful-
fill the criteria for event annotation. The most fre-
quent class consisted of cases where the only evi-
dence for a PTM was in the form of a sequence of
residues, for example
Characterization [. . . ] gave the follow-
ing sequence, Gly-Cys-Hyp-D-Trp-Glu-
Pro-Trp-Cys-NH2 where Hyp = 4-trans-
hydroxyproline. (PMID 8910408)
Here, the occurrence of hydroxyproline in the se-
quence implies that the protein has been hydrox-
ylated, but as the hydroxylation event is only im-
plied by the protein state, no event is annotated.
Candidates drawn from PIR but not fulfilling
the criteria were excluded from annotation. While
this implies that the general class of event extrac-
tion approaches considered here will not recover
all statements providing evidence of PTM to bi-
ologists (per the PIR criteria), several factors mit-
igate this limitation of their utility. First, while
PTMs implied by sequence only are relatively fre-
quent in PIR, its selection criteria give emphasis
to publications initially reporting the existence of a
PTM, and further publications discussing the PTM
are not expected to state it as sequence only. Thus,
it should be possible to extract the correspond-
ing PTMs from later sources. Similarly, one of
the promises of event extraction approaches is the
potential to extract associations of multiple enti-
ties and extract causal chains connecting events
with others (e.g. E catalyzes the hydroxylation of
P, leading to . . . ), and the data indicates that the
sequence-only statements typically provide little
information on the biological context of the modi-
fication beyond identifying the entity and site. As
such non-contextual PTM information is already
available in multiple databases, this class of state-
ments may not be of primary interest for event ex-
traction.
2.5 Annotation results
The new PTM annotation covers 157 PubMed
abstracts. Following the model of the BioNLP
shared task, all mentions of specific gene or gene
product names in the abstracts were annotated, ap-
plying the annotation criteria of (Ohta et al, 2009).
This new named entity annotation covers 1031
gene/gene product mentions, thus averaging more
than six mentions per annotated abstract. In to-
tal, 422 events of which 405 are of the novel PTM
23
Event type Count
Glycosylation 122
Hydroxylation 103
Methylation 90
Acetylation 90
Positive reg. 12
Phosphorylation 3
Protein modification 2
TOTAL 422
Table 6: Statistics of the introduced event annota-
tion.
Arguments Count
Theme, Site 363
Theme 36
Site 6
Table 7: Statistics for the arguments of the anno-
tated PTM events.
types were annotated, matching the initial annota-
tion target in number and giving a well-balanced
distribution of the specific PTM types (Table 6).
Reflecting the selection of the source texts, the
argument structures of the annotated PTM events
(Table 7) show a different distribution from those
annotated in the GENIA event corpus (Table 5):
whereas less than half of the GENIA event corpus
PTM events include a Site argument, almost 90%
of the PTM events in the new data include a Site.
PTM events identifying both the modified protein
and the specific modified site are expected to be
of more practical interest. However, we note that
the greater number of multi-argument events is ex-
pected to make the dataset more challenging as an
extraction target.
3 Evaluation
To estimate the capacity of the newly annotated
resource to support the extraction of the targeted
PTM events and the performance of current event
extraction methods at open-domain PTM extrac-
tion, we performed a set of experiments using an
event extraction method competitive with the state
of the art, as established in the BioNLP shared task
on event extraction (Kim et al, 2009a; Bjo?rne et
al., 2009).
3.1 Methods
We adopted the recently introduced event extrac-
tion system of Miwa et al (2010). The system
applies a pipeline architecture consisting of three
supervised classification-based modules: a trig-
ger detector, an event edge detector, and an event
detector. In evaluation on the BioNLP shared
task test data, the system extracted phosphory-
lation events at 75.7% precision and 85.2% re-
call (80.1% F-score) for Task 1, and 75.7% preci-
sion and 83.3% recall (79.3% F-score) for Task 2,
showing performance comparable to the best re-
sults reported in the literature for this event class
(Buyko et al, 2009). We assume three precondi-
tions for the PTM extraction: proteins are given,
all PTMs have Sites, and all arguments in a PTM
co-occur in sentence scope. The first of these is
per the BioNLP shared task setup, the second fixed
based the corpus statistics, and the third a property
intrinsic to the extraction method, which builds on
analysis of sentence structure.6 In the experiments
reported here, only the four novel PTM event types
with Sites in the corpus are regarded as a target for
the extraction.
The system extracted PTMs as follows: the
trigger detector detected the entities (triggers and
sites) of the PTMs, the event edge detector de-
tected the edges in the PTMs, and the event de-
tector detected the PTMs. The evaluation setting
was the same as the evaluation in (Miwa et al,
2010) except for the threshold. The thresholds in
the three modules were tuned with the develop-
ment data set.
Performance evaluation is performed using the
BioNLP shared task primary evaluation criteria,
termed the ?Approximate Span Matching? crite-
rion. This criterion relaxes the requirements of
strict matching in accepting extracted event trig-
gers and entities as correct if their span is inside
the region of the corresponding region in the gold
standard annotation.
3.2 Data Preparation
The corpus data was split into training and test sets
on the document level with a sampling strategy
that aimed to preserve a roughly 3:1 ratio of oc-
currences of each event type between training and
test data. The test data was held out during sys-
tem development and parameter selection and only
applied in a single final experiment. The event ex-
traction system was trained using the 112 abstracts
of the training set, further using 24 of the abstracts
6We note that in the BioNLP shared task data, all argu-
ments were contained within single sentences for 95% of
events.
24
Figure 2: Performance of PTM extraction on the
development data set.
Event type Prec Rec F
Acetylation 69.6% 36.7% 48.1%
Methylation 50.0% 34.2% 40.6%
Glycosylation 36.7% 42.5% 39.4%
Hydroxylation 57.1% 29.3% 38.7%
Overall 52.1% 35.7% 42.4%
Table 8: Event extraction results on the test set.
as a development test set.
3.3 Results
We first performed parameter selection, setting the
machine learning method parameter by estimating
performance on the development data set. Figure 2
shows the performance of PTM extraction on the
development data set with different values of pa-
rameter. The threshold value corresponding to the
best performance (0.3) was then applied for an ex-
periment on the held-out test set.
Performance on the test set was evaluated as
52% precision and 36% recall (42% F-score),
matching estimates on the development data. A
breakdown by event type (Table 8) shows that
Acetylation is most reliably extracted with extrac-
tion for the other three PTM types showing sim-
ilar F-scores despite some variance in the preci-
sion/recall balance. We note that while these re-
sults fall notably below the best result reported
for Phosphorylation events in the BioNLP shared
task, they are comparable to the best results re-
ported in the task for Regulation and Binding
events (Kim et al, 2009a), suggesting that the
dataset alows the extraction of the novel PTM
events with Theme and Site arguments at levels
comparable to multi-argument shared task events.
Figure 3: Learning curve of PTM extraction on the
development data set.
Further, a learning curve (Figure 3) plotted on
the development data suggests roughly linearly
increasing performance over most of the curve.
While the increase appears to be leveling off to
an extent when using all of the available data, the
learning curve indicates that performance can be
further improved by increasing the size of the an-
notated dataset.
4 Discussion
Post-translational modifications have been a fo-
cus of interest in the biomedical text mining com-
munity, and a number of resources and systems
targeting PTM have been proposed. The GE-
NIES and GeneWays systems (Friedman et al,
2001; Rzhetsky et al, 2004) targeted PTM events
such as phosphorylation and dephosphorylation
under the more general createbond and breakbond
types. Hu et al (2005) introduce the RLIMS-P
rule-based system for mining the substrates and
sites for phosphorylation, which is extended with
the capacity to extract intra-clausal statements by
Narayanaswamy et al (2005). Saric et al (2006)
present an extension of their rule-based STRING-
IE system for extracting regulatory networks to
capture phosphorylation and dephosphorylation
events. Lee et al (2008) present E3Miner, a tool
for automatically extracting information related to
ubiquitination, and Kim et al (2009b) present a
preliminary study adapting the E3Miner approach
to the mining of acetylation events.
It should be noted that while studies target-
ing single specific PTM types report better re-
sults than found in the initial evaluation presented
here (in many cases dramatically so), different
25
extraction targets and evaluation criteria compli-
cate direct comparison. Perhaps more importantly,
our aim here is to extend the capabilities of gen-
eral event extraction systems targeting multiple
types of structured events. Pursuing this broader
goal necessarily involves some compromise in the
ability to focus on the extraction of individual
event types, and it is expected that highly focused
systems will provide better performance than re-
trained general systems.
The approach to PTM extraction adopted here
relies extensively on the availability of annotated
resources, the creation of which requires consider-
able effort and expertise in understanding the tar-
get domain as well as the annotation methodology
and tools. The annotation created in this study,
performed largely on the basis of partial existing
annotations drawn from PIR data, involved an es-
timated three weeks of full-time effort from an ex-
perienced annotator. As experiments further in-
dicated that a larger corpus may be necessary for
reliable annotation, we can estimate that extending
the approach to sufficient coverage of each of hun-
dreds of PTM types without a partial initial anno-
tation would easily require several person-years of
annotation efforts. We thus see a clear need for the
development of unsupervised or semisupervised
methods for PTM extraction to extend the cover-
age of event extraction systems to the full scale of
different PTM types. Nevertheless, even if reliable
methods for PTM extraction that entirely avoid the
need for annotated training data become available,
a manually curated reference standard will still be
necessary for reliable estimation of their perfor-
mance. To efficiently support the development of
event extraction systems capable of capturing the
full variety of PTM events, it may be beneficial to
reverse the approach taken here: instead of anno-
tating hundreds of examples of a small number of
PTM types, annotate a small number of each of
hundreds of PTM types, thus providing both seed
data for semisupervised approaches as well as ref-
erence data for the evaluation of broad-coverage
PTM event extraction systems.
5 Conclusions and Future Work
We have presented an event extraction approach
to automatic PTM recognition, building on the
model introduced in the BioNLP shared task on
event extraction. By annotating a targeted cor-
pus for four prominent PTM types not considered
in the BioNLP shared task data, we have created
a resource that can be straightforwardly used to
extend the capability of event extraction systems
for PTM extraction. We estimated that while sys-
tems trained on the original shared task dataset
could not recognize more than 50% of PTM men-
tions due to their types, the introduced annotation
increases this theoretical upper bound to nearly
90%. An initial experiment on the newly intro-
duced dataset using a state-of-the-art method indi-
cated that straightforward adoption of the dataset
as training data to extend coverage of PTM events
without specific adaptations of the method is feasi-
ble, although the measured performance indicates
remaining challenges for reliable extraction. Fur-
ther, while the experiments were performed on a
dataset selected to avoid bias toward e.g. a partic-
ular subdomain or specific forms of event expres-
sions, it remains an open question how extraction
performance generalizes to biomedical literature
beyond the selected sample. As experiments in-
dicated clear remaining potential for the improve-
ment of extraction performance from more train-
ing data, the extension of the annotated dataset is
a natural direction for future work. We considered
also the possiblity of extending annotation to cover
small numbers of each of a large variety of PTM
types, which would place focus on the challenges
of event extraction with little or no training data
for specific event types.
The annotated corpus covering over 1000 gene
and gene product entities and over 400 events is
freely available in the widely adopted BioNLP
shared task format at the GENIA project home-
page.7
Acknowledgments
We would like to thank Goran Topic for automat-
ing Medie queries to identify target abstracts.
This work was partially supported by Grant-in-
Aid for Specially Promoted Research (MEXT,
Japan) and Japan-Slovenia Research Cooperative
Program (JSPS, Japan and MHEST, Slovenia).
References
Sophia Ananiadou, Sampo Pyysalo, Junichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology. (to appear).
7http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA
26
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 10?18, Boulder, Colorado, June. Association
for Computational Linguistics.
Ekaterina Buyko, Erik Faessler, Joachim Wermter, and
Udo Hahn. 2009. Event extraction from trimmed
dependency graphs. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 19?27, Boulder, Colorado, June. Association
for Computational Linguistics.
Carol Friedman, Pauline Kra, Hong Yu, Michael
Krauthammer, and Andrey Rzhetsky. 2001. GE-
NIES: A natural-language processing system for the
extraction of molecular pathways from journal arti-
cles. Bioinformatics, 17(Suppl. 1):S74?S82.
Z. Z. Hu, M. Narayanaswamy, K. E. Ravikumar,
K. Vijay-Shanker, and C. H. Wu. 2005. Literature
mining and database annotation of protein phospho-
rylation using a rule-based system. Bioinformatics,
21(11):2759?2765.
Rudolf Jaenisch and Adrian Bird. 2003. Epigenetic
regulation of gene expression: how the genome in-
tegrates intrinsic and environmental signals. Nature
Genetics, 33:245?254.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008. Corpus annotation for mining biomedical
events from lterature. BMC Bioinformatics, 9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009a. Overview
of bionlp?09 shared task on event extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Youngrae Kim, Hodong Lee, and Gwan-Su Yi. 2009b.
Literature mining for protein acetylation. In Pro-
ceedings of LBM?09.
Hodong Lee, Gwan-Su Yi, and Jong C. Park. 2008.
E3Miner: a text mining tool for ubiquitin-protein
ligases. Nucl. Acids Res., 36(suppl.2):W416?422.
Matthias Mann and Ole N. Jensen. 2003. Proteomic
analysis of post-translational modifications. Nature
Biotechnology, 21:255?261.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and
Jun?ichi Tsujii. 2010. Event extraction with com-
plex event classification using rich features. Jour-
nal of Bioinformatics and Computational Biology
(JBCB), 8(1):131?146, February.
Yusuke Miyao, Tomoko Ohta, Katsuya Masuda, Yoshi-
masa Tsuruoka, Kazuhiro Yoshida, Takashi Ni-
nomiya, and Jun?ichi Tsujii. 2006. Semantic Re-
trieval for the Accurate Identification of Relational
Concepts in Massive Textbases. In Proceedings of
COLING-ACL 2006, pages 1017?1024.
M. Narayanaswamy, K. E. Ravikumar, and K. Vijay-
Shanker. 2005. Beyond the clause: extraction
of phosphorylation information from medline ab-
stracts. Bioinformatics, 21(suppl.1):i319?327.
Tomoko Ohta, Yusuke Miyao, Takashi Ninomiya,
Yoshimasa Tsuruoka, Akane Yakushiji, Katsuya
Masuda, Jumpei Takeuchi, Kazuhiro Yoshida, Ta-
dayoshi Hara, Jin-Dong Kim, Yuka Tateisi, and
Jun?ichi Tsujii. 2006. An Intelligent Search Engine
and GUI-based Efficient MEDLINE Search Tool
Based on Deep Syntactic Parsing. In Proceedings
of the COLING/ACL 2006 Interactive Presentation
Sessions, pages 17?20.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, and
Jun?ichi Tsujii. 2009. Incorporating GENETAG-
style annotation to GENIA corpus. In Proceedings
of Natural Language Processing in Biomedicine
(BioNLP) NAACL 2009 Workshop, pages 106?107,
Boulder, Colorado. Association for Computational
Linguistics.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for infor-
mation extraction in the biomedical domain. BMC
Bioinformatics, 8(50).
Andrey Rzhetsky, Ivan Iossifov, Tomohiro Koike,
Michael Krauthammer, Pauline Kra, Mitzi Mor-
ris, Hong Yu, Pablo Ariel Duboue?, Wubin Weng,
W. John Wilbur, Vasileios Hatzivassiloglou, and
Carol Friedman. 2004. GeneWays: A system for
extracting, analyzing, visualizing, and integrating
molecular pathway data. Journal of Biomedical In-
formatics, 37(1):43?53.
Jasmin Saric, Lars Juhl Jensen, Rossitza Ouzounova,
Isabel Rojas, and Peer Bork. 2006. Extraction
of regulatory gene/protein networks from Medline.
Bioinformatics, 22(6):645?650.
The Gene Ontology Consortium. 2000. Gene ontol-
ogy: tool for the unification of biology. Nature Ge-
netics, 25:25?29.
Eric S Witze, William M Old, Katheryn A Resing,
and Natalie G Ahn. 2007. Mapping protein post-
translational modifications with mass spectrometry.
Nature Methods, 4:798?806.
Cathy H. Wu, Lai-Su L. Yeh, Hongzhan Huang, Leslie
Arminski, Jorge Castro-Alvear, Yongxing Chen,
Zhangzhi Hu, Panagiotis Kourtesis, Robert S. Led-
ley, Baris E. Suzek, C.R. Vinayaka, Jian Zhang, and
Winona C. Barker. 2003. The Protein Information
Resource. Nucl. Acids Res., 31(1):345?347.
27
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 28?36,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Scaling up Biomedical Event Extraction to the Entire PubMed
Jari Bjo?rne?, ,1,2 Filip Ginter,?,1 Sampo Pyysalo,?,3 Jun?ichi Tsujii,3,4 Tapio Salakoski1,2
1Department of Information Technology, University of Turku, Turku, Finland
2Turku Centre for Computer Science (TUCS), Turku, Finland
3Department of Computer Science, University of Tokyo, Tokyo, Japan
4National Centre for Text Mining, University of Manchester, Manchester, UK
jari.bjorne@utu.fi,ginter@cs.utu.fi,smp@is.s.u-tokyo.ac.jp
tsujii@is.s.u-tokyo.ac.jp,tapio.salakoski@it.utu.fi
Abstract
We present the first full-scale event extrac-
tion experiment covering the titles and ab-
stracts of all PubMed citations. Extraction
is performed using a pipeline composed
of state-of-the-art methods: the BANNER
named entity recognizer, the McClosky-
Charniak domain-adapted parser, and the
Turku Event Extraction System. We an-
alyze the statistical properties of the re-
sulting dataset and present evaluations of
the core event extraction as well as nega-
tion and speculation detection components
of the system. Further, we study in de-
tail the set of extracted events relevant
to the apoptosis pathway to gain insight
into the biological relevance of the result.
The dataset, consisting of 19.2 million oc-
currences of 4.5 million unique events,
is freely available for use in research at
http://bionlp.utu.fi/.
1 Introduction
There has recently been substantial interest in
event models in biomedical information extraction
(IE). The expressive event representation captures
extracted knowledge as structured, recursively
nested, typed associations of arbitrarily many par-
ticipants in specific roles. The BioNLP?09 Shared
Task on Event Extraction (Kim et al, 2009), the
first large scale evaluation of biomedical event
extraction systems, drew the participation of 24
groups and established a standard event represen-
tation scheme and datasets. The training and test
data of the Shared Task comprised 13,623 manu-
ally annotated events in 1,210 PubMed citation ab-
stracts, and on this data the top performing system
of Bjo?rne et al (2009; 2010b) achieved an overall
F-score of 51.95% (Kim et al, 2009).
?Equal contribution by first three authors.
The issue of the scalability and generalization
ability of the introduced event extraction systems
beyond the domain of the GENIA corpus on which
the Shared Task was based has remained largely
an open question. In a prior study, we have es-
tablished on a 1% random sample of PubMed ti-
tles and abstracts that the event extraction system
of Bjo?rne et al is able to scale up to PubMed-
wide extraction without prohibitive computational
time requirements, however, the actual extraction
from the entire PubMed was left as a future work
(Bjo?rne et al, 2010a). Thus, the top-ranking event
extraction systems in the Shared Task have, in fact,
not been used so far for actual mass-scale event ex-
traction beyond the carefully controlled setting of
the Shared Task itself. Further, since an automated
named entity recognition step was not part of the
Shared Task, the interaction of the event extrac-
tion systems with gene/protein name recognizers
remains largely unexplored as well.
In this study, we address some of these ques-
tions by performing a mass-scale event extraction
experiment using the best performing system1 of
the Shared Task (Bjo?rne et al, 2009; Bjo?rne et al,
2010b), and applying it to the entire set of titles
and abstracts of the nearly 18 million citations in
the 2009 distribution of PubMed. The extraction
result, containing 19.2 million event occurrences,
is the largest dataset of its type by several orders
of magnitude and arguably represents the state-of-
the-art in automatic event extraction with respect
to both accuracy and size.
To support emerging community efforts in tasks
that build on event extraction output, such as event
network refinement, hypothesis generation, path-
way extraction, and others, we make the entire
resulting dataset freely available for research pur-
poses. This allows researchers interested in ques-
tions involving text mining, rather than initial in-
1Available at http://bionlp.utu.fi/
28
Event type Example
Gene expression 5-LOX is expressed in leukocytes
Transcription promoter associated with IL-4 gene
transcription
Localization phosphorylation and nuclear translo-
cation of STAT6
Protein catabolism I kappa B-alpha proteolysis by
phosphorylation.
Phosphorylation BCL-2 was phosphorylated at the
G(2)/M phase
Binding Bcl-w forms complexes with Bax and
Bak
Regulation c-Met expression is regulated by Mitf
Positive regulation IL-12 induced STAT4 binding
Negative regulation DN-Rac suppressed NFAT activation
Table 1: Targeted event types with brief example
statements expressing an event of each type. In the
examples, the word or words marked as triggering
the presence of the event are shown in italics and
event participants underlined. The event types are
grouped by event participants, with the first five
types taking one theme, binding events taking mul-
tiple themes and the regulation types theme and
cause participants. Adapted from (Bjo?rne et al,
2009).
formation extraction, to make use of the many fa-
vorable statistical properties of the massive dataset
without having to execute the laborious and time-
consuming event extraction pipeline.
In the following, we describe the Shared Task
event representation applied throughout this study,
the event extraction pipeline itself, and a first set
of analyzes of multiple aspects of the resulting
dataset.
2 Event extraction
The event extraction pipeline follows the model of
the BioNLP?09 Shared Task in its representation
of extracted information. The primary extraction
targets are gene or gene product-related entities
and nine fundamental biomolecular event types in-
volving these entities (see Table 1 for illustration).
Several aspects of the event representation, as
defined in the context of the Shared Task, differ-
entiate the event extraction task from the body of
domain IE studies targeting e.g. protein?protein
interactions and gene?disease relations, including
previous domain shared tasks (Ne?dellec, 2005;
Krallinger et al, 2008). Events can have an ar-
bitrary number of participants with specified roles
(e.g. theme or cause), making it possible to cap-
ture n-ary associations and statements where some
participants occur in varying roles or are only oc-
Regulation
NNP NN VB NNP CC .conj_and>
<nn dobj><nsubj NNP
ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
event detectionC
B
A
dobj>
named entity recognition
ProteinSTAT3 phosphorylation involve ProteinVav and ProteinRac-1 .
STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) mayNNP
appos> <auxMD
Ser(727) may
Ser(727) mayEntity
<Theme<Site <Theme
Regulation
ProteinSTAT3 Phosphorylationphosphorylation involve ProteinVav and ProteinRac-1 .
Cause>
Cause><Theme
speculation and negation detectionD
Ser(727) mayEntity
<Theme<Site <Theme
RegulationSpec
Spec
STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) may
parsing
Figure 1: Event extraction. A multi-stage sys-
tem produces an event graph for each sentence.
Named entities are detected (A) using BANNER.
Independently of named entity detection, sen-
tences are parsed (B) to produce a dependency
parse. Event detection (C) uses the named entities
and the parse in predicting the trigger nodes and
argument edges that form the events. Finally, po-
larity and certainty (D) are predicted for the gen-
erated events. Adapted from (Bjo?rne et al, 2009).
casionally mentioned. A further important prop-
erty is that event participants can be other events,
resulting in expressive, recursively nested struc-
tures. Finally, events are given GENIA Event on-
tology types drawn from the community-standard
Gene Ontology (The Gene Ontology Consortium,
2000), giving each event well-defined semantics.
2.1 Event Extraction Pipeline
The event extraction pipeline applied in this work
consists of three main processing steps: named en-
tity recognition, syntactic parsing, and event ex-
traction. The process is illustrated in Figure 1.
For named entity recognition, we use the BAN-
NER system of Leaman and Gonzales (2008),
which in its current release achieves results close
to the best published on the standard GENETAG
dataset and was reported to have the best perfor-
mance in a recent study comparing publicly avail-
able taggers (Kabiljo et al, 2009). Titles and ab-
stracts of all 17.8M citations in the 2009 distribu-
tion of PubMed are processed through the BAN-
NER system.
Titles and abstracts of PubMed citations in
which at least one named entity was identified, and
29
which therefore contain a possible target for event
extraction, are subsequently split into sentences
using a maximum-entropy based sentence splitter
trained on the GENIA corpus (Kazama and Tsujii,
2003) with limited rule-based post-processing for
some common errors.
All sentences containing at least one named
entity are then parsed with the domain-adapted
McClosky-Charniak parser (McClosky and Char-
niak, 2008; McClosky, 2009), which has achieved
the currently best published performance on the
GENIA Treebank (Tateisi et al, 2005). The con-
stituency parse trees are then transformed to the
collapsed-ccprocessed variant of the Stanford De-
pendency scheme using the conversion tool2 intro-
duced by de Marneffe et al (2006).
Finally, events are extracted using the Turku
Event Extraction System of Bjo?rne et al which
achieved the best performance in the BioNLP?09
Shared Task and remains fully competitive with
even the most recent advances (Miwa et al, 2010).
We use a recent publicly available revision of the
event extraction system that performs also extrac-
tion of Shared Task subtask 2 and 3 information,
providing additional event arguments relevant to
event sites and localization (site, atLoc, and toLoc
role types in the Shared Task) as well as informa-
tion on event polarity and certainty (Bjo?rne et al,
2010b).
2.2 Extraction result and computational
requirements
Named entity recognition using the BANNER sys-
tem required in total roughly 1,800 CPU-hours
and resulted in 36,454,930 named entities identi-
fied in 5,394,350 distinct PubMed citations.
Parsing all 20,037,896 sentences with at least
one named entity using the McClosky-Charniak
parser and transforming the resulting constituency
trees into dependency analyzes using the Stanford
conversion tool required about 5,000 CPU-hours,
thus averaging 0.9 sec per sentence. Even though
various stability and scalability related problems
were met during the parsing process, we were able
to successfully parse 20,020,266 (99.91%) of all
sentences.
Finally, the event extraction step required ap-
proximately 1,500 CPU-hours and resulted in
19,180,827 event instances. In total, the entire cor-
2http://www-nlp.stanford.edu/
downloads/lex-parser.shtml
pus of PubMed titles and abstracts was thus pro-
cessed in roughly 8,300 CPU-hours, or, 346 CPU-
days, the most time-consuming step by far being
the syntactic parsing.
We note that, even though the components used
in the pipeline are largely well-documented and
mature, a number of technical issues directly re-
lated to, or at least magnified by, the untypi-
cally large dataset were met at every point of the
pipeline. Executing the pipeline was thus far from
a trivial undertaking. Due to the computational re-
quirements of the pipeline, cluster computing sys-
tems were employed at every stage of the process.
2.3 Evaluation
We have previously evaluated the Turku Event
Extraction System on a random 1% sample of
PubMed citations, estimating a precision of 64%
for event types and arguments pertaining to sub-
task 1 of the Shared Task (Bjo?rne et al, 2010a),
which compares favorably to the 58% precision
the system achieves on the Shared Task dataset it-
self (Bjo?rne et al, 2009).
To determine precision on subtasks 2 and 3
on PubMed citations, we manually evaluate 100
events with site and location arguments (sub-
task 2) and 100 each of events predicted to be
speculated or negated (subtask 3).
Subtask 2 site and location arguments are
mostly external to the events they pertain to and
therefore were evaluated independently of their
parent event. Their precision is 53% (53/100),
comparable to the 58% precision established on
the BioNLP?09 Shared Task development set, us-
ing the same parent-independent criterion.
To estimate the precision of the negation detec-
tion (subtask 3), we randomly select 100 events
predicted to be negated. Of these, 9 were incor-
rect as events to such an extent that the correct-
ness of the predicted negation could not be judged
and, among the remaining 91 events, the negation
was correctly predicted in 82% of the cases. Sim-
ilarly, to estimate the precision of speculation de-
tection, we randomly select 100 events predicted
to be speculated, of which 20 could not be judged
for correctness of speculation. Among the remain-
ing 80, 88% were correctly predicted as specula-
tive events. The negations were mostly signalled
by explicit statements such as is not regulated, and
speculation by statements, such as was studied,
that defined the events as experimental questions.
30
For comparison, on the BioNLP?09 Shared Task
development set, for correctly predicted events,
precision for negation examples was 83% (with
recall of 53%) and for speculation examples 77%
(with recall of 51%).
In the rest of this paper, we turn our attention to
the extraction result.
3 Term-NE mapping
As the event types are drawn from the Gene On-
tology and the original data on which the system
is trained has been annotated with reference to the
GO definitions, the events targeted by the extrac-
tion system have well-defined biological interpre-
tations. The meaning of complete event struc-
tures depends also on the participating entities,
which are in the primary event extraction task con-
strained to be of gene/gene product (GGP) types,
as annotated in the GENIA GGP corpus (Ohta et
al., 2009a). The simple and uniform nature of
these entities makes the interpretation of complete
events straightforward.
However, the semantics of the entities au-
tomatically tagged in this work are somewhat
more openly defined. The BANNER system was
trained on the GENETAG corpus, annotated for
?gene/protein entities? without differentiating be-
tween different entity types and marking entities
under a broad definition that not only includes
genes and gene products but also related entities
such as gene promoters and protein complexes,
only requiring that the tagged entities be specific
(Tanabe et al, 2005). The annotation criteria of
the entities used to train the BANNER system as
well as the event extraction system also differ in
the extent of the marked spans, with GENIA GGP
marking the minimal name and GENETAG allow-
ing also the inclusion of head nouns when a name
occurs in modifier position. Thus, for example, the
latter may annotate the spans p53 gene, p53 pro-
tein, p53 promoter and p53 mutations in contexts
where the former would in each case mark only
the substring p53.
One promising future direction for the present
effort is to refine the automatically extracted data
into an event network connected to specific entries
in gene/protein databases such as Entrez Gene and
UniProt. To achieve this goal, the resolution of
the tagged entities can be seen to involve two re-
lated but separate challenges. First, identifying
the specific database entries that are referred to
Relation Examples
Equivalent GGP gene, wild-type GGP
Class-Subclass human GGP, HIV-1 GGP
Object-Variant
GGP-Isoform GGP isoform
GGP-Mutant dominant-negative GGP
GGP-Recombinant GGP expression plasmid
GGP-Precursor GGP precursor, pro-GGP
Component-Object
GGP-Amino acid GGP-Ile 729
GGP-AA motif GGP NH2-terminal
GGP-Reg. element GGP proximal promoter
GGP-Flanking region GGP 5? upstream sequence
Object-Component
GGP-Protein Complex GGP homodimers
Place-Area
GGP-Locus GGP loci
Member-Collection
GGP-Group GGP family members
Table 2: Gene/gene product NE-term relation
types with examples. Top-level relations in the re-
lation type hierarchy shown in bold, specific NE
names in examples replaced with GGP. Intermedi-
ate levels in the hierarchy and a number of minor
relations omitted. Relation types judged to allow
remapping (see text) underlined.
by the genes/proteins named in the tagged enti-
ties, and second, mapping from the events involv-
ing automatically extracted terms to ones involv-
ing the associated genes/proteins. The first chal-
lenge, gene/protein name normalization, is a well-
studied task in biomedical NLP for which a num-
ber of systems with promising performance have
been proposed (Morgan and Hirschman, 2007).
The second we believe to be novel. In the follow-
ing, we propose a method for resolving this task.
We base the decision on how to map events ref-
erencing broadly defined terms to ones referencing
associated gene/protein names in part on a recently
introduced dataset of ?static relations? (Pyysalo et
al., 2009) between named entities and terms (Ohta
et al, 2009b). This dataset was created based on
approximately 10,000 cases where GGP NEs, as
annotated in the GENIA GGP corpus (Ohta et al,
2009a), were embedded in terms, as annotated in
the GENIA term corpus (Ohta et al, 2002). For
each such case, the relation between the NE and
the term was annotated using a set of introduced
relation types whose granularity was defined with
reference to MeSH terms (see Table 2, Ohta et al,
2009b). From this data, we extracted prefix and
suffix strings that, when affixed to a GGP name,
produced a term with a predictable relation (within
the dataset) to the GGP. Thus, for example, the
31
term GGP
p53 protein p53
p53 gene p53
human serum albumin serum albumin
wild-type p53 p53
c-fos mRNA c-fos
endothelial NO synthase NO synthase
MHC cl. II molecules MHC cl. II
human insulin insulin
HIV-1 rev.transcriptase rev.transcriptase
hepatic lipase lipase
p24 antigen p24
tr. factor NF-kappaB NF-kappaB
MHC molecules MHC
PKC isoforms PKC
HLA alleles HLA
RET proto-oncogene RET
ras oncogene ras
SV40 DNA SV40
EGFR tyrosine kinase EGFR
Table 3: Examples of frequently applied map-
pings. Most frequent term for each mapping is
shown. Some mention strings are abbreviated for
space.
Mentions Types
Total 36454930 4747770
Mapped 2212357 (6.07%) 547920 (11.54%)
Prefix 430737 (1.18%) 129536 (2.73%)
Suffix 1838646 (5.04%) 445531 (9.38%)
Table 4: Statistics for applied term-GGP map-
pings. Tagged mentions and types (unique men-
tions) shown separately. Overall total given for
reference, for mappings overall for any mapping
shown and further broken down into prefix-string
and suffix-string based.
prefix string ?wild-type? was associated with the
Equivalent relation type and the suffix string ?ac-
tivation sequence? with the GGP-Regulatory ele-
ment type. After filtering out candidates shorter
than 3 characters as unreliable (based on prelim-
inary experiments), this procedure produced a set
of 68 prefix and 291 suffix strings.
To make use of the data for predicting relations
between GGP names and the terms formed by af-
fixing a prefix or suffix string, it is necessary to
first identify name-term pairs. Candidates can be
generated simply by determining the prefix/suffix
strings occurring in each automatically tagged en-
tity and assuming that what remains after remov-
ing the prefixes and suffixes is a GGP name. How-
ever, this naive strategy often fails: while remov-
ing ?protein? from ?p53 protein? correctly identi-
fies ?p53? as the equivalent GGP name, for ?cap-
sid protein? the result, ?capsid? refers not to a
GGP but to the shell of a virus ? ?protein? is prop-
erly part of the protein name. To resolve this is-
sue, we drew on the statistics of the automatically
tagged entities, assuming that if a prefix/suffix
string is not a fixed part of a name, the name will
appear tagged also without that string. As the tag-
ging covers the entire PubMed, this is likely to
hold for all but the very rarest GGP names. To
compensate for spurious hits introduced by tag-
ging errors, we specifically required that to accept
a candidate prefix/suffix string-name pair, the can-
didate name should occur more frequently without
the prefix/suffix than with it. As the dataset is very
large, this simple heuristic often gives the right de-
cision with secure margins: for example, ?p53?
was tagged 117,835 times but ?p53 protein? only
11,677, while ?capsid? was (erroneously) tagged
7 times and ?capsid protein? tagged 1939 times.
A final element of the method is the definition
of a mapping to events referencing GGP NEs from
the given events referencing terms, the NEs con-
tained in the terms, and the NE-term relations. In
this work, we apply independently for each term a
simple mapping based only on the relation types,
deciding for each type whether replacing refer-
ence to a term with reference to a GGP holding
the given relation to the term preserves event se-
mantics (to an acceptable approximation) or not.
For the Equivalent relation this holds by defini-
tion. We additionally judged all Class-Subclass
and Component-Object relations to allow remap-
ping (accepting e.g. P1 binds part of P2 ? P1
binds P2) as well as selected Object-Variant rela-
tions (see Table 2). For cases judged not to allow
remapping, we simply left the event unmodified.
Examples of frequently applied term-GGP map-
pings are shown in Table 3, and Table 4 shows
the statistics of the applied mappings. We find
that suffix-based mappings apply much more fre-
quently than prefix-based, perhaps reflecting also
the properties of the source dataset. Overall, the
number of unique tagged types is reduced by over
10% by this procedure. It should be noted that the
applicability of the method could likely be consid-
erably extended by further annotation of NE-term
relations in the dataset of Ohta et al (2009b): the
current data is all drawn from the GENIA corpus,
drawn from the subdomain of transcription factors
in human blood cells, and its coverage of PubMed
is thus far from exhaustive.
32
4 Event recurrence
Given a dataset of events extracted from the en-
tire PubMed, we can study whether, and to what
extent, events are re-stated in multiple PubMed ci-
tations. This analysis may shed some light ? nat-
urally within the constraints of an automatically
extracted dataset rather than gold-standard anno-
tation ? on the often (informally) discussed hy-
pothesis that a high-precision, low recall system
might be a preferred choice for large-scale extrac-
tion as the lower recall would be compensated by
the redundancy of event statements in PubMed.
In order to establish event recurrence statistics,
that is, the number of times a given event is re-
peated in the corpus, we perform a limited normal-
ization of tagged entities consisting of the Term-
NE mapping presented in Section 3 followed
by lowercasing and removal of non-alphanumeric
characters. Two named entities are then consid-
ered equal if their normalized string representa-
tions are equal. For instance, the two names IL-
2 gene and IL2 would share the same normalized
form il2 and would thus be considered equal.
For the purpose of recurrence statistics, two
events are considered equal if their types are equal,
and all their Theme and Cause arguments, which
can be other events, are recursively equal as well.
A canonical order of arguments is used in the com-
parison, thus e.g. the following events are consid-
ered equal:
regulation(Cause:A, Theme:binding(Theme:B, Theme:C))
regulation(Theme:binding(Theme:C, Theme:B), Cause:A)
In total, the system extracted 19,180,827 instances
of 4,501,883 unique events. On average, an
event is thus stated 4.2 times. The distribution
is, however, far from uniform and exhibits the
?long tail? typical of natural language phenom-
ena, with 3,484,550 (77%) of events being single-
ton occurrences. On the other hand, the most fre-
quent event, localization(Theme:insulin), occurs
as many as 59,821 times. The histogram of the
number of unique events with respect to their oc-
currence count is shown in Figure 2.
The total event count consists mostly of sim-
ple one-argument events. The arguably more
interesting category of events that involve at
least two different named entities constitutes
2,064,278 instances (11% of the 19.2M total)
of 1,565,881 unique events (35% of the 4.5M
total). Among these complex events, recur-
 10
 100
1K
10K
100K
1M
 1  10  100 1K 10KUn
iqu
e e
ven
ts w
ith 
giv
en 
occ
urre
nce
 co
unt
Event occurrence count
Figure 2: Number of unique events (y-axis) with a
given occurrence count (x-axis).
R P N L B E T C H
R 561 173 128 42 63 83 30 16 17
P 173 1227 192 58 99 143 39 20 23
N 128 192 668 46 73 98 31 17 18
L 42 58 46 147 57 75 25 15 15
B 63 99 73 57 1023 134 35 20 21
E 83 143 98 75 134 705 49 22 24
T 30 39 31 25 35 49 79 11 11
C 16 20 17 15 20 22 11 39 7
H 17 23 18 15 21 24 11 7 49
Table 5: Event type confusion matrix. Each el-
ement contains the number of unique events, in
thousands, that are equal except for their type.
The matrix is symmetric and its diagonal sums to
4,5M, the total number of extracted unique events.
The event types are (R)egulation, (P)ositive
regulation, (N)egative regulation, (L)ocalization,
(B)inding, gene (E)xpression, (T)ranscription,
protein (C)atabolism, and p(H)osphorylation.
rence is thus considerably lower, an event be-
ing stated on average 1.3 times. The most
frequent complex event, with 699 occurrences,
is positive-regulation(Cause:GnRG,Theme:local-
ization(Theme:LH)), reflecting the well-known
fact that GnRG causes the release of LH, a hor-
mone important in human reproduction.
To gain an additional broad overview of the
characteristics of the extracted events, we com-
pute an event type confusion matrix, shown in Ta-
ble 5. In this matrix, we record for each pair of
event types T1 and T2 the number of unique events
of type T1 for which an event of type T2 can be
found such that, apart for the type difference, the
events are otherwise equal. While e.g. a posi-
tive regulation-negative regulation pair is at least
unusual, in general these event pairs do not sug-
gest extraction errors: for instance the existence
33
of the event expression(Theme:A) does not in any
way prevent the existence of the event localiza-
tion(Theme:A), and regulation subsumes positive-
regulation. Nevertheless, Table 5 shows a clear
preference for a single type for the events.
5 Case Study: The apoptosis pathway
In this section, we will complement the preceding
broad statistical overview of the extracted events
with a detailed study of a specific pathway, the
apoptosis pathway, determining how well the ex-
tracted events cover its interactions (Figure 3).
To create an event network, the events must be
linked through their protein arguments. In addi-
tion to the limited named entity normalization in-
troduced in Section 4, we make use of a list of syn-
onyms for each protein name in the apoptosis path-
way, obtained manually from protein databases,
such as UniProt. Events whose protein arguments
correspond to any of these known synonyms are
then used for reconstructing the pathway.
The apoptosis pathway consists of several over-
lapping signaling routes and can be defined on
different levels of detail. To have a single, ac-
curate and reasonably high-level definition, we
based our pathway on a concisely presentable sub-
set of the KEGG human apoptosis pathway (entry
hsa04210) (Kanehisa and Goto, 2000). As seen
in Figure 3, the extracted dataset contains events
between most interaction partners in the pathway.
The constructed pathway also shows that the ex-
tracted events are not necessarily interactions in
the physical sense. Many ?higher level? events
are extracted as well. For example, the extracel-
lular signaling molecule TNF? can trigger path-
ways leading to the activation of Nf-?B. Although
the two proteins are not likely to interact directly,
it can be said that TNF? upregulates NF-?B, an
event actually extracted by the system. Such state-
ments of indirect interaction co-exist with state-
ments of actual, physical interactions in the event
data.
6 Conclusions
In this paper, we have presented the result of pro-
cessing the entire, unabridged set of PubMed titles
and abstracts with a state-of-the-art event extrac-
tion pipeline as a new resource for text mining in
the biomedical domain. The extraction result ar-
guably represents the best event extraction output
achievable with currently available tools.
The primary contribution of this work is the set
of over 19M extracted event instances of 4.5M
unique events. Of these, 2.1M instances of 1.6M
unique events involve at least two different named
entities. These form an event network several
orders of magnitude larger than those previously
available. The data is intended to support re-
search in biological hypothesis generation, path-
way extraction, and similar higher-level text min-
ing tasks. With the network readily available in an
easy-to-process format under an open license, re-
searchers can focus on the core tasks of text min-
ing without the need to perform the tedious and
computationally very intensive task of event ex-
traction with a complex IE pipeline.
In addition to the extracted events, we make
readily available the output of the BANNER sys-
tem on the entire set of PubMed titles and abstracts
as well as the parser output of the McClosky-
Charniak domain-adapted parser (McClosky and
Charniak, 2008; McClosky, 2009) further trans-
formed to the Stanford Dependency representa-
tion using the tools of de Marneffe et al (2006)
for nearly all (99.91%) sentences with at least one
named entity identified. We expect this data to be
of use for the development and application of sys-
tems for event extraction and other BioNLP tasks,
many of which currently make extensive use of
dependency syntactic analysis. The generation of
this data having been far from a trivial technical
undertaking, its availability as-is can be expected
to save substantial duplication of efforts in further
research.
A manual analysis of extracted events relevant
to the apoptosis pathway demonstrates that the
event data can be used to construct detailed bio-
logical interaction networks with reasonable accu-
racy. However, accurate entity normalization, in
particular taking into account synonymous names,
seems to be a necessary prerequisite and remains
among the most important future work directions.
In the current study, we take first steps in this di-
rection in the form of a term-NE mapping method
in event context. The next step will be the applica-
tion of a state-of-the-art named entity normaliza-
tion system to obtain biological database identities
for a number of the named entities in the extracted
event network, opening possibilities for combin-
ing the data in the network with other biological
information. A further practical problem to ad-
dress will be that of visualizing the network and
34
ev
n
nv
v
v v
n e t
n n v
v nv
v
vn
n
n
n
n
n
n
n n
n
n
n
n n
n
nn
 
n
d
n
e
n
c
v
n
v
t
n
nvnv
n
n
n
v
t
en
ct
nncv
n
n
n e n v
n
n
vnd
n
 
n
v
n t
n
vv
v
n
v
t
n
t
e t
e n v
e
t
n
v
v
n
v
v
nv
n
n v
v
n v
n
c
n
n
v
n v
nn
c
v
nn
vn
v
v
n
v
v
n
e v
vn
IL-1 TNF? TRAIL Fas-L
IL-1R TNF-R1 TRAIL-R Fas
FADDTRADDRIP1MyD88IRAK
NIK
IKK
I?B? NF-?B
CASP10CASP8
FLIP
CASP3CASP7
dioamayorgsrdapuaporrlpaop
ugugpp
TRAF2
IAP
doiiraii
Figure 3: Extracted apoptosis event network. Events shown in the figure are selected on their
prominence in the data or correspondence to known apoptosis interactions. Events corresponding
to KEGG apoptosis pathway interaction partners are highlighted with a light grey background. The
event types are (P)ositive regulation, (N)egative regulation, (R)egulation, gene (E)xpression, (B)inding,
p(H)osphorylation, (L)ocalization and protein (C)atabolism.
presenting the information in a biologically mean-
ingful manner.
The introduced dataset is freely available for
research purposes at http://bionlp.utu.
fi/.
Acknowledgments
This work was supported by the Academy of
Finland and by Grant-in-Aid for Specially Pro-
moted Research (MEXT, Japan). Computational
resources were provided by CSC ? IT Center for
Science, Ltd., a joint computing center for Finnish
academia and industry. We thank Robert Leaman
for advance access and assistance with the newest
release of BANNER.
35
References
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 10?18, Boulder, Colorado. Association for
Computational Linguistics.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-
jii, and Tapio Salakoski. 2010a. Complex event ex-
traction at PubMed scale. In Proceedings of the 18th
Annual International Conference on Intelligent Sys-
tems for Molecular Biology (ISMB 2010). In press.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2010b. Ex-
tracting contextualized complex biological events
with rich graph-based feature sets. Computational
Intelligence. In press.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In
Proceedings of LREC-06, pages 449?454.
Renata Kabiljo, Andrew Clegg, and Adrian Shepherd.
2009. A realistic assessment of methods for extract-
ing gene/protein interactions from free text. BMC
Bioinformatics, 10(1):233.
M. Kanehisa and S. Goto. 2000. KEGG: kyoto ency-
clopedia of genes and genomes. Nucleic Acids Res.,
28:27?30, Jan.
Jun?ichi Kazama and Jun?ichi Tsujii. 2003. Evalua-
tion and extension of maximum entropy models with
inequality constraints. In Proceedings of the 2003
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 137?144.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9, Boulder, Col-
orado. ACL.
Martin Krallinger, Florian Leitner, Carlos Rodriguez-
Penagos, and Alfonso Valencia. 2008. Overview of
the protein-protein interaction annotation extraction
task of BioCreative II. Genome Biology, 9(Suppl
2):S4.
R. Leaman and G. Gonzalez. 2008. BANNER: an exe-
cutable survey of advances in biomedical named en-
tity recognition. Pacific Symposium on Biocomput-
ing, pages 652?663.
David McClosky and Eugene Charniak. 2008. Self-
Training for Biomedical Parsing. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics - Human Language Technolo-
gies (ACL-HLT?08), pages 101?104.
David McClosky. 2009. Any Domain Parsing: Au-
tomatic Domain Adaptation for Natural Language
Parsing. Ph.D. thesis, Department of Computer Sci-
ence, Brown University.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and
Jun?ichi Tsujii. 2010. Event Extraction With Com-
plex Event Classification Using Rich Features. J
Bioinform Comput Biol, 8:131?146.
Alexander A. Morgan and Lynette Hirschman. 2007.
Overview of BioCreative II gene normalization. In
Proceedings of BioCreative II, pages 101?103.
Claire Ne?dellec. 2005. Learning Language in
Logic - Genic Interaction Extraction Challenge. In
J. Cussens and C. Ne?dellec, editors, Proceedings
of the 4th Learning Language in Logic Workshop
(LLL05), pages 31?37.
Tomoko Ohta, Yuka Tateisi, Hideki Mima, and Jun?ichi
Tsujii. 2002. GENIA corpus: An annotated re-
search abstract corpus in molecular biology domain.
In Proceedings of the Human Language Technology
Conference (HLT?02), pages 73?77.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009a. Incorporating
genetag-style annotation to genia corpus. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 106?
107, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Tomoko Ohta, Sampo Pyysalo, Kim Jin-Dong, and
Jun?ichi Tsujii. 2009b. A re-evaluation of biomedi-
cal named entity - term relations. In Proceedings of
LBM?09.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 1?9,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Lorraine Tanabe, Natalie Xie, Lynne H Thom, Wayne
Matten, and W John Wilbur. 2005. GENETAG: A
tagged corpus for gene/protein named entity recog-
nition. BMC Bioinformatics, 6(Suppl. 1):S3.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun?ichi Tsujii. 2005. Syntax Annotation for the
GENIA corpus. In Proceedings of the IJCNLP
2005, Companion volume, pages 222?227.
The Gene Ontology Consortium. 2000. Gene ontol-
ogy: tool for the unification of biology. Nature ge-
netics, 25:25?29.
36
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 37?45,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
A Comparative Study of Syntactic Parsers for Event Extraction
Makoto Miwa1 Sampo Pyysalo1 Tadayoshi Hara1 Jun?ichi Tsujii1,2,3
1Department of Computer Science, the University of Tokyo, Japan
Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan.
2School of Computer Science, University of Manchester, UK
3National Center for Text Mining, UK
{mmiwa,smp,harasan,tsujii}@is.s.u-tokyo.ac.jp
Abstract
The extraction of bio-molecular events
from text is an important task for a number
of domain applications such as pathway
construction. Several syntactic parsers
have been used in Biomedical Natural
Language Processing (BioNLP) applica-
tions, and the BioNLP 2009 Shared Task
results suggest that incorporation of syn-
tactic analysis is important to achieving
state-of-the-art performance. Direct com-
parison of parsers is complicated by to dif-
ferences in the such as the division be-
tween phrase structure- and dependency-
based analyses and the variety of output
formats, structures and representations ap-
plied. In this paper, we present a task-
oriented comparison of five parsers, mea-
suring their contribution to bio-molecular
event extraction using a state-of-the-art
event extraction system. The results show
that the parsers with domain models using
dependency formats provide very similar
performance, and that an ensemble of dif-
ferent parsers in different formats can im-
prove the event extraction system.
1 Introduction
Bio-molecular events are useful for modeling and
understanding biological systems, and their au-
tomatic extraction from text is one of the key
tasks in Biomedical Natural Language Process-
ing (BioNLP). In the BioNLP 2009 Shared Task
on event extraction, participants constructed event
extraction systems using a variety of different
parsers, and the results indicated that the use of
a parser was correlated with high ranking in the
task (Kim et al, 2009). By contrast, the results
did not indicate a clear preference for a particular
parser, and there has so far been no direct compar-
ison of different parsers for event extraction.
While the outputs of parsers applying the same
out format can be compared using a gold standard
corpus, it is difficult to perform meaningful com-
parison of parsers applying different frameworks.
Additionally, it is still an open question to what ex-
tent high performance on a gold standard treebank
correlates with usefulness at practical tasks. Task-
based comparisons of parsers provide not only a
way to asses parsers across frameworks but also a
necessary measure of their practical applicability.
In this paper, five different parsers are com-
pared on the bio-molecular event extraction task
defined in the BioNLP 2009 Shared Task using a
state-of-the-art event extraction system. The data
sets share abstracts with GENIA treebank, and the
treebank is used as an evaluation standard. The
outputs of the parsers are converted into two de-
pendency formats with the help of existing conver-
sion methods, and the outputs are compared in the
two dependency formats. The evaluation results
show that different syntactic parsers with domain
models in the same dependency format achieve
closely similar performance, and that an ensemble
of different syntactic parsers in different formats
can improve the performance of an event extrac-
tion system.
2 Bio-molecular Event Extraction with
Several Syntactic Parsers
This paper focuses on the comparison of several
syntactic parsers on a bio-molecular event extrac-
tion task with a state-of-the-art event extraction
system. This section explains the details of the
comparison. Section 2.1 presents the event ex-
37
traction task setting, following that of the BioNLP
2009 Shared Task. Section 2.2 then summa-
rizes the five syntactic parsers and three formats
adopted for the comparison. Section 2.3 described
how the state-of-the-art event extraction system of
Miwa et al (2010) is modified and used for the
comparison.
2.1 Bio-molecular Event Extraction
The bio-molecular event extraction task consid-
ered in this study is that defined in the BioNLP
2009 Shared Task (Kim et al, 2009)1. The shared
task provided common and consistent task defi-
nitions, data sets for training and evaluation, and
evaluation criteria. The shared task consists of
three subtasks: core event extraction (Task 1),
augmenting events with secondary arguments
(Task 2), and the recognition of speculation and
negation of the events (Task 3) (Kim et al, 2009).
In this paper we consider Task 1 and Task 2. The
shared task defined nine event types, which can be
divided into five simple events (Gene expression,
Transcription, Protein catabolism, Phosphoryla-
tion, and Localization) that take one core argu-
ment, a multi-participant binding event (Bind-
ing), and three regulation events (Regulation, Pos-
itive regulation, and Negative regulation) that can
take other events as arguments.
In the two tasks considered, events are repre-
sented with a textual trigger, type, and arguments,
where the trigger is a span of text that states the
event in text. In Task 1 the event arguments that
need to be extracted are restricted to the core ar-
guments Theme and Cause, and secondary argu-
ments (locations and sites) need to be attached in
Task 2.
2.2 Parsers and Formats
Five parsers and three formats are adopted for
the evaluation. The parsers are GDep (Sagae and
Tsujii, 2007)2, the Bikel parser (Bikel) (Bikel,
2004)3, the Charniak-Johnson reranking parser,
using David McClosky?s self-trained biomedi-
cal parsing model (MC) (McClosky, 2009)4, the
C&C CCG parser, adapted to biomedical text
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA/SharedTask/
2http://www.cs.cmu.edu/?sagae/parser/
gdep/
3http://www.cis.upenn.edu/?dbikel/
software.html
4http://www.cs.brown.edu/?dmcc/
biomedical.html
	 
     Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 132?140,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Towards Event Extraction from Full Texts on Infectious Diseases
Sampo Pyysalo? Tomoko Ohta? Han-Cheol Cho? Dan Sullivan?
Chunhong Mao? Bruno Sobral? Jun?ichi Tsujii??? Sophia Ananiadou??
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Virginia Bioinformatics Institute, Virginia Tech, Blacksburg, Virginia, USA
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
{smp,okap,priancho,tsujii}@is.s.u-tokyo.ac.jp
{dsulliva,cmao,sobral}@vbi.vt.edu
Sophia.Ananiadou@manchester.ac.uk
Abstract
Event extraction approaches based on ex-
pressive structured representations of ex-
tracted information have been a significant
focus of research in recent biomedical nat-
ural language processing studies. How-
ever, event extraction efforts have so far
been limited to publication abstracts, with
most studies further considering only the
specific transcription factor-related subdo-
main of molecular biology of the GENIA
corpus. To establish the broader relevance
of the event extraction approach and pro-
posed methods, it is necessary to expand
on these constraints. In this study, we pro-
pose an adaptation of the event extraction
approach to a subdomain related to infec-
tious diseases and present analysis and ini-
tial experiments on the feasibility of event
extraction from domain full text publica-
tions.
1 Introduction
For most of the previous decade, biomedical In-
formation Extraction (IE) efforts have focused pri-
marily on tasks that allow extracted information
to be represented as simple pairs of related enti-
ties. This representation is applicable to many IE
targets of interest, such as gene-disease associa-
tions (Chun et al, 2006) and protein-protein inter-
actions (Ne?dellec, 2005; Krallinger et al, 2007).
However, it has limited applicability to advanced
applications such as semantic search, Gene On-
tology term annotation, and pathway extraction,
tasks for which and relatively few resources or sys-
tems (e.g. (Rzhetsky et al, 2004)) have been intro-
duced. A number of recent studies have proposed
more expressive representations of extracted in-
formation, introducing resources supporting ad-
vanced IE approaches (Pyysalo et al, 2007; Kim
et al, 2008; Thompson et al, 2009; Ananiadou
et al, 2010a). A significant step in the develop-
ment of domain IE methods capable of extract-
ing this class of representations was taken in the
BioNLP?09 shared task on event extraction, where
24 teams participated in an IE task setting requir-
ing the extraction of structured representations of
multi-participant biological events of several types
(Kim et al, 2009).
While the introduction of structured event ex-
traction resources and methods has notably ad-
vanced the state of the art in biomedical IE rep-
resentations, the focus of event extraction studies
carries other limitations frequently encountered in
domain IE efforts. Specifically, resources anno-
tated for biomedical events contain exclusively
texts from publication abstracts, typically further
drawn from small subdomains of molecular biol-
ogy. These choices constrain not only the types of
texts but also the types of events considered, re-
stricting the applicability of event extraction. This
paper presents results from one ongoing effort to
extend an event extraction approach over these
boundaries, toward event extraction from full text
documents in the domain of infectious diseases.
In this study, we consider the subdomain related
to Type IV secretion systems as a model subdo-
main of interest within the broad infectious dis-
eases domain. Type IV secretion systems (T4SS)
are mechanisms for transferring DNA and pro-
teins across cellular boundaries. T4SS are found
in a broad range of Bacteria and in some Ar-
chaea. These translocation systems enable gene
transfer across cellular membranes thus contribut-
ing to the spread of antibiotic resistance and viru-
132
Figure 1: Event representation example. Inhibition of binding caused by phosphorylation is represented
using three events. The shaded text background identifies the text bindings of the events and entities.
lence genes making them an especially important
mechanism in infectious disease research (Juhas et
al., 2008). Type IV secretion systems are found in
plant pathogens, such as Agrobacterium tumefa-
ciens, the cause of crown gall disease as well as in
animal pathogens, such as Helicobacter pylori, a
cause of severe gastric disease. The study of T4SS
has been hampered by the lack of consistent termi-
nology to describe genes and proteins associated
with the translocation mechanism thus motivating
the use of natural language processing techniques
to enhance information retrieval and information
extraction from relevant literature.
2 Event Extraction for the T4SS Domain
This section presents the application of an event
extraction approach to the T4SS domain.
2.1 Event Extraction
We base our information extraction approach on
the model introduced in the BioNLP?09 shared
task on event extraction. Central to this approach
is the event representation, which can capture
the association of multiple participants in varying
roles and numbers and treats events as primary ob-
jects of annotation, thus allowing events to be par-
ticipants in other events. Further, both entities and
events are text-bound, i.e. anchored to specific ex-
pressions in text (Figure 1).
The BioNLP?09 shared task defined nine event
types and five argument types (roles): Theme spec-
ifies the core participant(s) that an event affects,
Cause the cause of the the event, Site a specific
domain or region on a participant involved in the
event, and ToLoc and AtLoc locations associated
with localization events (Table 1). Theme and
Cause arguments may refer to either events or
gene/gene product entities, and other arguments
refer to other physical entities. The Theme ar-
gument is always mandatory, while others can be
omitted when a relevant participant is not stated.
The event types were originally defined to cap-
ture statements of biologically relevant changes in
Event type Args Example
Gene expression T 5-LOX is coexpressed
Transcription T IL-4 transcription
Protein catabolism T IkB-A proteolysis
Localization T,L translocation of STAT6
Phosphorylation T,S NF90 was phosphorylated
Binding T+,S+ Nmi interacts with STAT
Regulation T,C,S IL-4 gene control
Positive regulation T,C,S IL-12 induced binding
Negative regulation T,C,S suppressed dimerization
Table 1: Event types targeted in the BioNLP?09
shared task and their arguments, with minimal
examples of each event type. Arguments ab-
breviate for (T)heme, (C)ause, (S)ite and L for
ToLoc/AtLoc, with ?+? identifying arguments
than can occur multiple times. The expression
marked as triggering the event shown in italics.
the state of entities in a target subdomain involv-
ing transcription factors in human blood cells. In
adapting the approach to new domains, some ex-
tension of the event types is expected to be nec-
essary. By contrast, the argument types and the
general design of the representation are intended
to be general, and to maintain compatibility with
existing systems we aim to avoid modifying these.
2.2 T4SS Domain
A corpus of full-text publications relating to the
T4SS subdomain of the infectious diseases do-
main annotated for biological entities and terms of
interest to domain experts was recently introduced
by (Ananiadou et al, 2010b). In the present study,
we use this corpus as a reference standard defin-
ing domain information needs. In the following
we briefly describe the corpus annotation and the
view it provides of the domain.
The T4SS corpus annotation covers four classes
of tagged entities and terms: Bacteria, Cellular
components, Biological Processes, and Molecular
functions. The latter three correspond to the three
Gene Ontology (GO) (Ashburner et al, 2000) top-
level sub-ontologies, and terms of these types were
annotated with reference to both GO and relevance
to the interests of domain experts, with guidelines
133
Bacterium
A. tumefaciens 32.7%
H. pylori 20.0%
L. pneumophila 16.3%
E. coli 12.3%
B. pertussis 3.0%
Cell component
T4SS 5.2%
Ti plasmid 5.1%
outer membrane 4.2%
membrane 3.5%
genome 3.4%
Biological process
virulence 14.1%
conjugation 7.9%
localization 6.1%
nuclear import 5.8%
transfer 5.1%
Molecular function
nucleotide-binding 20.3%
ATPase activity 17.3%
NTP-binding 14.7%
ATP-binding 12.2%
DNA-binding 9.1%
Table 2: Most frequently tagged terms (after normalization) and their relative frequencies of all tagged
entities of each of the four types annotated in the T4SS corpus.
Type Annotations
Bacteria 529
Cellular component 2237
Biological process 1873
Molecular function 197
Table 3: Statistics for the existing T4SS corpus
annotation.
requiring that marked terms be both found in GO
and associated with T4SS. These constraints as-
sure that the corpus is relevant to the informa-
tion needs of biologists working in the domain and
that it can be used as a reference for the study of
automatic GO annotation. In the work introduc-
ing the corpus, the task of automatic GO anno-
tation was studied as facilitating improved infor-
mation access, such as advanced search function-
ality: GO annotation can allow for search by se-
mantic classes or co-occurrences of terms of speci-
fied classes. The event approach considered in this
study further extends on these opportunities in in-
troducing a model allowing e.g. search by specific
associations of the concepts of interest.
The previously created annotation of the T4SS
corpus covers 27 full text publications totaling
15143 pseudo-sentences (text sentences plus table
rows, references, etc.) and 244942 tokens.1 A to-
tal of nearly 5000 entities and terms are annotated
in these documents; Table 2 shows the most fre-
quently tagged terms of each type after basic nor-
malization of different surface forms, and Table 3
gives the per-class statistics. Domain characteris-
tics are clearly identifiable in the first three tagged
types, showing disease-related bacteria, their ma-
jor cellular components, and processes related to
movement, reproduction and infection. The last
term type is dominated by somewhat more generic
binding-type molecular functions.
In addition to the four annotated types it was
1While the document count is modest compared to that
of abstract-based corpora, we estimate that in terms of the
amount of text (tokens) the corpus corresponds to over 1000
abstracts, comparable in size to e.g. the GENIA event corpus
(Kim et al, 2008).
recognized during the original T4SS corpus anno-
tation that genes and gene products are centrally
important for domain information needs, but their
annotation was deferred to focus on novel cate-
gories. As part of the present study, we introduce
annotation for gene/gene product (GGP) mentions
(Section 3.2), and in the following discussion of
applying an event extraction approach to the do-
main the availability of this class annotation as an
additional category is assumed.
2.3 Adaptation of the Event Model
The event model involves two primary categories
of representation: physical entities such as genes
and proteins are elementary (non-structured) and
their mentions annotated as typed spans of text,2
and events and processes (?things that happen?)
are represented using the structured event repre-
sentation described in Section 2.1. This division
applies straightforwardly to the T4SS annotations,
suggesting an approach where bacteria and cell
components retain their simple tagged-term repre-
sentation and the biological processes and molec-
ular functions are given an event representation.
In the following, we first analyze correspondences
between the latter two classes and BioNLP?09
shared task events, and then proceed to study the
event arguments and their roles as steps toward a
complete event model for the domain.
Molecular functions, the smallest class tagged
in the T4SS corpus, are highly uniform: almost
75% involve binding, immediately suggesting rep-
resentation using the Binding class of events de-
fined in the applied event extraction model. The
remaining functions are ATPase activity, together
with its exact GO synonyms (e.g. ATP hydrolase
activity) accounting for 19% of the terms, the gen-
eral type hydrolysis (4.5%), and a small number
of rare other functions. While these have no cor-
respondence with previously defined event types,
2Normalization identifying e.g. the Uniprot entry corre-
sponding to a protein mention may also be necessary, but here
excluded from consideration an independent issue.
134
Class Category Freq
Location
Transfer 27.6%
Localization 15.6%
Import/export 14.5%
Virulence 14.1%
High-level Assembly 8.7%
process Conjugation 8.3%
Secretion 8.1%
(Other) 1.8%
Table 4: Categorization of T4SS corpus biologi-
cal processes and relative frequency of mentions
of each category of the total tagged.
their low overall occurrence counts make them of
secondary interest as extraction targets.
The biological processes are considerably more
diverse. To identify general categories, we per-
formed a manual analysis of the 217 unique nor-
malized terms annotated in the corpus as biologi-
cal processes (Table 4). We find that the majority
of the instances (58%) relate to location or move-
ment. As related types of statements are anno-
tated as Localization events in the applied model,
we propose to apply this event type and differen-
tiate between the specific subtypes on the basis of
the event arguments. A further 39% are of cate-
gories that can be viewed as high-level processes.
These are distinct from the events considered in
the BioNLP?09 shared task in involving coarser-
grained events and larger-scale participants than
the GGP entities considered in the task: for ex-
ample, conjugation occurs between bacteria, and
virulence may involve a human host.
To analyze the role types and arguments char-
acteristic of domain events, we annotated a small
sample of tagged mentions for the most fre-
quent types in the broad classification discussed
above: Binding for Molecular function, Transfer
for Location-related, and Virulence for High-level
process. The statistics of the annotated 65 events
are shown in Tables 5, 6 and 7. For Binding, we
find that while an estimated 90% of events in-
volve a GGP argument, the other participant of
the binding is in all cases non-GGP, most fre-
quently of Nucleotide type (e.g. NTP/ATP). While
only GGP Binding arguments were considered in
the shared task events, the argument structures are
typical of multi-participant binding and this class
of expressions are in scope of the original GE-
NIA Event corpus annotation (Kim et al, 2008).
Event annotations could thus potentially be de-
rived from existing data. Localization event
arguments show substantially greater variety and
Freq Arguments
78% Theme: GGP, Theme: Nucleotide
5.5% Theme: GGP, Theme: DNA
5.5% Theme: GGP, Theme: Sugar
5.5% Theme: Protein family, Theme: DNA
5.5% Theme: Protein, Theme: Nucleotide
Table 5: Binding event arguments.
Freq Arguments
16% Theme: DNA, From/To: Organism
16% Theme: DNA
16% Theme: Cell component
12% Theme: DNA, To: Organism
8% Theme: Protein family, From/To: Organism
4% Theme: GGP
4% Theme: GGP, To: Organism
4% Theme: GGP, From: Organism
4% Theme: Protein family, From: Organism
4% Theme: Protein family
4% Theme: Organism, To: Cell component
4% Theme: DNA From: Organism, To: Cell component
4% (no arguments)
Table 6: Localization (Transfer) event arguments.
Freq Arguments
64% Cause: GGP
16% Theme:Organism, Cause: GGP
8% Cause: Organism
8% (no arguments)
4% Cause: Protein family
Table 7: Process (Virulence) arguments.
some highly domain-specific argument combina-
tions, largely focusing on DNA and Cell compo-
nent (e.g. phagosome) transfer, frequently involv-
ing transfer between different organisms. While
the participants are almost exclusively of types
that do not appear in Localization events in exist-
ing annotations, the argument structures are stan-
dard and in our judgment reasonably capture the
analyzed statements, supporting the applicability
of the general approach. Finally, the argument
analysis shown in Table 7 supports the previous
tentative observation that the high-level biologi-
cal processes are notably different from previously
considered event types: for over 80% of these pro-
cesses no overtly stated Theme could be identified.
We take this to indicate that the themes ? the core
participants that the processes concern ? are ob-
vious in the discourse context and their overt ex-
pression would be redundant. (For example, in
the context virulence obviously involves a host and
conjugation involves bacteria.) By contrast, in the
corpus the entities contributing to these processes
are focused: a participant we have here analyzed
as Cause is stated in over 90% of cases. This
135
Sentences Tokens
Abstracts 150 3789
Full texts 448 13375
Total 598 17164
Table 8: Statistics for the selected subcorpus.
novel pattern of event arguments suggests that the
event model should be augmented to capture this
category of high-level biological processes. Here,
we propose an event representation for these pro-
cesses that removes the requirement for a Theme
and substitutes instead a mandatory Cause as the
core argument. In the event annotation and exper-
iments, we focus on this newly proposed class.
3 Annotation
This section describes the new annotation intro-
duced for the T4SS corpus.
3.1 Text Selection
The creation of exhaustive manual annotation for
the full T4SS corpus represents a considerable an-
notation effort. Due to resource limitations, for
this study we did not attempt full-scope annota-
tion but instead selected a representative subset of
the corpus texts. We aimed to select texts that pro-
vide good coverage of the text variety in the T4SS
corpus and can be freely redistributed for use in re-
search. We first selected for annotation all corpus
documents with at least a freely available PubMed
abstract, excluding 3 documents. As the corpus
only included a single freely redistributable Open
Access paper, we extended full text selection to
manuscripts freely available as XML/HTML (i.e.
not only PDF) via PubMed Central. While these
documents cannot be redistributed in full, their
text can be reliably combined with standoff anno-
tations to recreate the annotated corpus.
In selected full-text documents, to focus anno-
tation efforts on sections most likely to contain re-
liable new information accessible to natural lan-
guage processing methods, we further selected the
publication body text, excluding figures and tables
and their captions, and removed Methods and Dis-
cussion sections. We then removed artifacts such
as page numbers and running heads and cleaned
remaining errors from PDF conversion of the orig-
inal documents. This selection produced a subcor-
pus of four full-text documents and 19 abstracts.
The statistics for this corpus are shown in Table 8.
GGP GGP/sentence
Abstracts 124 0.82
Full texts 394 0.88
Total 518 0.87
Table 9: Statistics for the GGP annotation.
3.2 Gene/Gene Product Annotation
As gene and gene product entities are central to
domain information needs and the core entities of
the applied event extraction approach, we first in-
troduced annotation for this entity class. We cre-
ated manual GGP annotation following the an-
notation guidelines of the GENIA GGP Corpus
(Ohta et al, 2009). As this corpus was the source
of the gene/protein entity annotation provided as
the basis of the BioNLP shared task on event ex-
traction, adopting its annotation criteria assures
compatibility with recently introduced event ex-
traction methods. Briefly, the guidelines spec-
ify tagging for minimal continuous spans of spe-
cific gene/gene product names, without differen-
tiating between DNA/RNA/protein. A ?specific
name? is understood to be a a name that allows
a domain expert to identify the entry in a rele-
vant database (Entrez gene/Uniprot) that the name
refers to. Only GGP names are tagged, excluding
descriptive references and the names of related en-
tities such as complexes, families and domains.
The annotation was created on the basis of an
initial tagging created by augmenting the output
of the BANNER tagger (Leaman and Gonzalez,
2008) by dictionary- and regular expression-based
tagging. This initial high-recall markup was then
corrected by a human annotator. To confirm that
the annotator had correctly identified subdomain
GGPs and to check against possible error intro-
duced through the machine-assisted tagging, we
performed a further verification of the annotation
on approx. 50% of the corpus sentences: we com-
bined the machine- and human-tagged annotations
as candidates, removed identifying information,
and asked two domain experts to identify the cor-
rect GGPs. The two sets of independently pro-
duced judgments showed very high agreement:
holding one set of judgments as the reference stan-
dard, the other would achieve an f-score of 97%
under the criteria presented in Section 4.2. We
note as one contributing factor to the high agree-
ment that the domain has stable and systematically
applied GGP naming criteria. The statistics of the
full GGP annotation are shown in Table 9.
136
Events Event/sentence
Abstracts 15 0.1
Full texts 5 0.01
Additional 80 2.2
Total 100 0.16
Table 10: Statistics for the event annotation.
3.3 Event Annotation
Motivated by the analysis described in Section 2.3,
we chose to focus on the novel category of asso-
ciations of GGP entities in high-level processes.
Specifically, we chose to study biological pro-
cesses related to virulence, as these are the most
frequent case in the corpus and prototypical of the
domain. We adopted the GENIA Event corpus an-
notation guidelines (Kim et al, 2008), marking as-
sociations between specific GGPs and biological
processes discussed in the text even when these
are stated speculatively or their existence explic-
itly denied. As the analysis indicated this category
of processes to typically involve a single stated
participant in a fixed role, annotations were ini-
tially recorded as (GGP, process) pairs and later
converted into an event representation.
During annotation, the number of annotated
GGP associations with the targeted class of pro-
cesses in the T4SS subcorpus was found to be too
low to provide material for both training and test-
ing a supervised learning-based event extraction
approach. To extend the source data, we searched
PubMed for cases where a known T4SS-related
protein co-occurred with an expression known to
relate to the targeted process class (e.g. virulence,
virulent, avirulent, non-virulent) and annotated a
further set of sentences from the search results for
both GGPs and their process associations. As the
properties of these additional examples could not
be assured to correspond to those of the targeted
domain texts, we used these annotations only as
development and training data, performing evalu-
ation on cases drawn from the T4SS subcorpus.
As the annotation target was novel, we per-
formed two independent sets of judgments for all
annotated cases, jointly resolving disagreements.
Although initial agreement was low, for a final set
of judgments we measured high agreement, corre-
sponding to 93% f-score when holding one set of
judgments as the gold standard. The statistics of
the annotation are shown in Table 10. Annotations
are sparse in the T4SS subcorpus and, as expected,
very dense in the targeted additional data.
4 Experiments
4.1 Methods
For GGP tagging experiments, we applied a state-
of-the-art tagger with default settings as reference
and a custom tagger for adaptation experiments.
As the reference tagger, we applied a recent re-
lease of BANNER (Leaman and Gonzalez, 2008)
trained on the GENETAG corpus (Tanabe et al,
2005). The corpus is tagged for gene and protein-
related entities and its texts drawn from a broad
selection of PubMed abstracts. The current revi-
sion of the tagger3 achieves an f-score of 86.4%
on the corpus, competitive with the best result re-
ported in the BioCreative II evaluation (Wilbur et
al., 2007), 87.2%. The custom tagger4 follows the
design of BANNER in both the choice of Con-
ditional Random Fields (Lafferty et al, 2001) as
the applied learning method and the basic feature
design, but as a key extension can further adopt
features from external dictionaries as both positive
and negative indicators of tagged entities. Tagging
experiments were performed using a document-
level 50/50 split of the GGP-annotated subcorpus.
For event extraction, we applied an adapta-
tion of the approach of the top-ranking system in
the BioNLP?09 shared task (Bjo?rne et al, 2009):
all sentences in the input text were parsed with
the McClosky-Charniak (2008) parser and the re-
sulting phrase structure analyses then converted
into the Stanford Dependency representation us-
ing conversion included in the Stanford NLP tools
(de Marneffe et al, 2006). Trigger recognition
was performed with a simple regular expression-
based tagger covering standard surface form vari-
ation. Edge detection was performed using a su-
pervised machine learning approach, applying the
LibSVM (Chang and Lin, 2001) Support Vector
Machine implementation with a linear kernel and
the feature representation of Bjo?rne et al (2009),
building largely around the shortest dependency
path connecting a detected trigger with a candi-
date participant. The SVM regularization parame-
ter was selected by a sparse search of the parame-
ter space with evaluation using cross-validation on
the training set. As the class of events targeted for
extraction in this study are of a highly restricted
type, each taking only of a single mandatory Cause
argument, the construction of events from detected
3http://banner.sourceforge.net
4http://www-tsujii.is.s.u-tokyo.ac.jp/
NERsuite/
137
Precision Recall F-score
Abstracts 68.1% 89.5% 77.3%
Full texts 56.9% 80.7% 66.7%
Total 59.4% 82.8% 69.2%
Table 11: Initial GGP tagging results.
triggers and edges could be implemented as a sim-
ple deterministic rule.
4.2 Evaluation Criteria
For evaluating the performance of the taggers we
apply a relaxed matching criterion that accepts a
match between an automatically tagged and a gold
standard entity if the two overlap at least in part.
This relaxation is adopted to focus on true tagging
errors. The GENETAG entity span guidelines dif-
fer from the GENIA GGP guidelines adopted here
in allowing the inclusion of e.g. head nouns when
names appear in modifier position, while the an-
notation guidelines applied here require marking
only the minimal name.5 When applying strict
matching criteria, a substantial number of errors
may trace back to minor boundary differences
(Wang et al, 2009), which we consider of sec-
ondary interest to spurious or missing tags. Over-
all results are microaverages, that is, precision, re-
call and f-score are calculated from the sum of true
positive etc. counts over individual documents.
For event extraction, we applied the BioNLP?09
shared task event extraction criteria (Kim et al,
2009) with one key change: to make it possible
to evaluate the extraction of the high-level pro-
cess participants, we removed the requirement that
all events must define a Theme as their core argu-
ment.
4.3 Gene/Gene Product Tagging
The initial GGP tagging results using BANNER
are shown in Table 11. We find that even for the
relaxed overlap matching criterion, the f-score is
nearly 10% points lower than reported on GENE-
TAG in the evaluation on abstracts. For full texts,
performance is lower yet by a further 10% points.
In both cases, the primary problem is the poor
precision of the tagger, indicating that many non-
GGPs are spuriously tagged.
To determine common sources of error, we per-
formed a manual analysis of 100 randomly se-
lected falsely tagged strings (Table 12). We find
5GENETAG annotations include e.g. human ets-1 protein,
whereas the guidelines applied here would require marking
only ets-1.
Category Freq Examples
GGP family or group 34% VirB, tmRNA genes
Figure/table 26% Fig. 1B, Table 1
Cell component 10% T4SS, ER vacuole
Species/strain 9% E. coli, A348deltaB4.5
Misc. 9% step D, Protocol S1
GGP domain or region 4% Pfam domain
(Other) 8% TrIP, LGT
Table 12: Common sources of false positives in
GGP tagging.
Precision Recall F-score
Abstracts 90.5% 95.7% 93.1%
Full texts 90.0% 93.2% 91.6%
Total 90.1% 93.8% 91.9%
Table 13: GGP tagging results with domain adap-
tation.
that the most frequent category consists of cases
that are arguably correct by GENETAG annota-
tion criteria, which allow named protein families
of groups to be tagged. A similar argument can
be made for domains or regions. Perhaps not sur-
prisingly, a large number of false positives relate
to features common in full texts but missing from
the abstracts on which the tagger was trained, such
as figure and table references. Finally, systematic
errors are made for entities belonging to other cat-
egories such as named cell components or species.
To address these issues, we applied a domain-
adapted custom tagger that largely replicates the
features of BANNER, further integrating infor-
mation from the UMLS Metathesaurus,6 which
provides a large dictionary containing terms cov-
ering 135 different semantic classes, and a cus-
tom dictionary of 1081 domain GGP names, com-
piled by (Ananiadou et al, 2010b). The non-GGP
UMLS Metathesaurus terms provided negative in-
dicators for reducing spurious taggings, and the
custom dictionary positive indicators. Finally, we
augmented the GENETAG training data with 10
copies7 of the training half of the T4SS GGP cor-
pus as in-domain training data.
Table 13 shows the results with the domain-
adapted tagger. We find dramatically improved
performance for both abstracts and full texts,
showing results competitive with the state of the
art performance on GENETAG (Wilbur et al,
2007). Thus, while the performance of an un-
adapted tagger falls short of both results reported
6http://www.nlm.nih.gov/research/umls/
7As the GENETAG corpus is considerably larger than the
T4SS GGP corpus, replication was used to assure that suffi-
cient weight is given to the in-domain data in training.
138
Precision Recall F-score
Co-occurrence 65% 100% 78%
Machine learning 81% 85% 83%
Table 14: Event extraction results.
on GENETAG and levels necessary for practi-
cal application, adaptation addressing common
sources of error through the adoption of general
and custom dictionaries and the use of a small
set of in-domain training data was successful in
addressing these issues. The performance of the
adapted tagger is notably high given the modest
size of the in-domain data, perhaps again reflect-
ing the consistent GGP naming conventions of the
subdomain.
4.4 Event Extraction
We performed an event extraction experiment fol-
lowing the training and test split described in Sec-
tion 3.3. Table 14 shows the results of the ap-
plied machine learning-based method contrasted
with a co-occurrence baseline replacing the edge
detection with a rule that extracts a Cause edge for
all trigger-GGP combinations co-occurring within
sentence scope. This approach achieves 100% re-
call as the test data was found to only contain
events where the arguments are stated in the same
sentence as the trigger.
The results show that the machine learning ap-
proach achieves very high performance, matching
the best results reported for any single event type
in the BioNLP?09 shared task (Kim et al, 2009).
The very high co-occurrence baseline result sug-
gests that the high performance largely reflects the
relative simplicity of the task. With respect to
the baseline result, the machine-learning approach
achieves a 21% relative reduction in error.
While this experiment is limited in both scope
and scale, it suggests that the event extraction ap-
proach can be beneficially applied to detect do-
main events represented by novel argument struc-
tures. As a demonstration of feasibility the result
is encouraging for both the applicability of event
extraction to this specific new domain and for the
adaptability of the approach to new domains in
general.
5 Discussion and Conclusions
We have presented a study of the adaptation of an
event extraction approach to the T4SS subdomain
as a step toward the introduction of event extrac-
tion to the broader infectious diseases domain. We
applied a previously introduced corpus of subdo-
main full texts annotated for mentions of bacte-
ria and terms from the three top-level Gene On-
tology subontologies as a reference defining do-
main information needs to study how these can
be met through the application of events defined
in the BioNLP?09 Shared Task on event extrac-
tion. Analysis indicated that with minor revision
of the arguments, the Binding and Localization
event types could account for the majority of both
biological processes and molecular functions of
interest. We further identified a category of ?high-
level? biological processes such as the virulence
process typical of the subdomain, which necessi-
tated extension of the considered event extraction
model.
Based on argument analysis, we proposed a rep-
resentation for high-level processes in the event
model that substitutes Cause for Theme as the
core argument. We further produced annotation
allowing an experiment on the extraction of the
dominant category of virulence processes with
gene/gene product (GGP) causes, annotating 518
GGP mentions and 100 associations between these
and the processes. Experiments indicated that with
annotated in-domain resources both the GGP enti-
ties and their associations with processes could be
extracted with high reliability.
In future work we will extend the model and
annotation proposed in this paper to the broader
infectious diseases domain, introducing annotated
resources and extraction methods for advanced in-
formation access. All annotated resources intro-
duced in this study are available from the GENIA
project homepage.8
Acknowledgments
This work was partially supported by Grant-in-Aid
for Specially Promoted Research (MEXT, Japan),
the National Institutes of Health, grant number
HHSN272200900040C, and the Joint Information
Systems Committee (JISC, UK).
References
Sophia Ananiadou, Sampo Pyysalo, Junichi Tsujii, and
Douglas B. Kell. 2010a. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology. (to appear).
8http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA/
139
Sophia Ananiadou, Dan Sullivan, Gina-Anne Levow,
Joseph Gillespie, Chunhong Mao, Sampo Pyysalo,
Jun?ichi Tsujii, and Bruno Sobral. 2010b. Named
entity recognition for bacterial type IV secretion sys-
tems. (manuscript in review).
M Ashburner, CA Ball, JA Blake, D Botstein, H But-
ler, JM Cherry, AP Davis, K Dolinski, SS Dwight,
JT Eppig, MA Harris, DP Hill, L Issel-Tarver,
A Kasarskis, S Lewis, JC Matese, JE Richardson,
M Ringwald, GM Rubin, and G Sherlock. 2000.
Gene ontology: tool for the unification of biology.
Nature genetics, 25:25?29.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 10?18, Boulder, Colorado, June. Association
for Computational Linguistics.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a library for support vector machines.
Software available at http://www.csie.ntu.
edu.tw/?cjlin/libsvm.
Hong-Woo Chun, Yoshimasa Tsuruoka, Jin-Dong
Kim, Rie Shiba, Naoki Nagata, Teruyoshi Hishiki,
and Jun?ichi Tsujii. 2006. Extraction of gene-
disease relations from medline using domain dic-
tionaries and machine learning. In Proceedings of
the Pacific Symposium on Biocomputing (PSB?06),
pages 4?15.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
Mario Juhas, Derrick W. Crook, and Derek W. Hood.
2008. Type IV secretion systems: tools of bacterial
horizontal gene transfer and virulence. Cellular mi-
crobiology, 10(12):2377?2386.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008. Corpus annotation for mining biomedical
events from lterature. BMC Bioinformatics, 9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing
in Biomedicine (BioNLP) NAACL 2009 Workshop,
pages 1?9.
Martin Krallinger, Florian Leitner, and Alfonso Valen-
cia. 2007. Assessment of the Second BioCreative
PPI task: Automatic Extraction of Protein-Protein
Interactions. In L. Hirschman, M. Krallinger, and
A. Valencia, editors, Proceedings of Second BioCre-
ative Challenge Evaluation Workshop, pages 29?39.
John D. Lafferty, Andrew McCallum, and Fernando
C . N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In ICML ?01: Proceedings of the
18th International Conference on Machine Learn-
ing, pages 282?289.
R. Leaman and G. Gonzalez. 2008. Banner: an ex-
ecutable survey of advances in biomedical named
entity recognition. Pacific Symposium on Biocom-
puting, pages 652?663.
David McClosky and Eugene Charniak. 2008. Self-
Training for Biomedical Parsing. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics - Human Language Technolo-
gies (ACL-HLT?08), pages 101?104.
Claire Ne?dellec. 2005. Learning Language in
Logic - Genic Interaction Extraction Challenge. In
J. Cussens and C. Ne?dellec, editors, Proceedings
of the 4th Learning Language in Logic Workshop
(LLL05), pages 31?37.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, and
Jun?ichi Tsujii. 2009. Incorporating GENETAG-
style annotation to GENIA corpus. In Proceedings
of Natural Language Processing in Biomedicine
(BioNLP) NAACL 2009 Workshop, pages 106?107,
Boulder, Colorado. Association for Computational
Linguistics.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for infor-
mation extraction in the biomedical domain. BMC
Bioinformatics, 8(50).
Andrey Rzhetsky, Ivan Iossifov, Tomohiro Koike,
Michael Krauthammer, Pauline Kra, Mitzi Mor-
ris, Hong Yu, Pablo Ariel Duboue?, Wubin Weng,
W. John Wilbur, Vasileios Hatzivassiloglou, and
Carol Friedman. 2004. GeneWays: A system for
extracting, analyzing, visualizing, and integrating
molecular pathway data. Journal of Biomedical In-
formatics, 37(1):43?53.
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne
Matten, and John Wilbur. 2005. Genetag: a tagged
corpus for gene/protein named entity recognition.
BMC Bioinformatics, 6(Suppl 1):S3.
Paul Thompson, Syed Iqbal, John McNaught, and
Sophia Ananiadou. 2009. Construction of an anno-
tated corpus to support biomedical information ex-
traction. BMC Bioinformatics, 10(1):349.
Yue Wang, Jin-Dong Kim, Rune Saetre, Sampo
Pyysalo, and Jun?ichi Tsujii. 2009. Investigat-
ing heterogeneous protein annotations toward cross-
corpora utilization. BMC Bioinformatics, 10(1):403.
John Wilbur, Lawrence Smith, and Lorraine Tanabe.
2007. BioCreative 2. Gene Mention Task. In
L. Hirschman, M. Krallinger, and A. Valencia, ed-
itors, Proceedings of Second BioCreative Challenge
Evaluation Workshop, pages 7?16.
140
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 144?152,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Integration of Static Relations to Enhance Event Extraction from Text
Sofie Van Landeghem1,2, Sampo Pyysalo3, Tomoko Ohta3, Yves Van de Peer1,2
1. Dept. of Plant Systems Biology, VIB, Gent, Belgium
2. Dept. of Plant Biotechnology and Genetics, Ghent University, Gent, Belgium
3. Department of Computer Science, University of Tokyo, Tokyo, Japan
yves.vandepeer@psb.vib-ugent.be
Abstract
As research on biomedical text mining is
shifting focus from simple binary relations
to more expressive event representations,
extraction performance drops due to the
increase in complexity. Recently intro-
duced data sets specifically targeting static
relations between named entities and do-
main terms have been suggested to enable
a better representation of the biological
processes underlying annotated events and
opportunities for addressing their com-
plexity. In this paper, we present the first
study of integrating these static relations
with event data with the aim of enhanc-
ing event extraction performance. While
obtaining promising results, we will argue
that an event extraction framework will
benefit most from this new data when tak-
ing intrinsic differences between various
event types into account.
1 Introduction
Recently, biomedical text mining tools have
evolved from extracting simple binary relations
between genes or proteins to a more expressive
event representation (Kim et al, 2009). Further-
more, new data sets have been developed target-
ing relations between genes and gene products
(GGPs) and a broader category of entities, cov-
ering terms that can not be annotated as named
entities (NEs) but that are still highly relevant
for biomedical information extraction (Ohta et al,
2009b). In contrast to relations involving change
or causality, the annotation for this data covers re-
lations such as part-of, here termed ?static rela-
tions? (SR) (Pyysalo et al, 2009).
Tissue-specific expression of interleukin-3
expression event GGP
is mediated via cis-acting elements located 
regulation event               term part-of GGP 
within 315 base pairs of the transcription start.
term part-of GGP
Figure 1: A sentence from PMID:8662845, show-
ing how the event data set (single line) and the SR
data set (double line) offer complementary infor-
mation, enabling a more precise model of the bio-
logical reality.
As an example, Figure 1 depicts a sentence con-
taining complementary annotations from the event
data set and the SR data. The event annotation
indicates an expression event involving the GGP
?interleukin-3?. Furthermore, regulation of this
expression event is stated by the trigger word ?me-
diated?. In addition, the SR annotation marks two
terms that refer to parts of the GGP, namely ?cis-
acting elements? and ?transcription starts?. These
two terms provide more detailed information on
the regulation event. Thus, by combining the two
types of annotation, a text mining algorithm will
be able to provide a more detailed representation
of the extracted information. This would be in par-
ticular beneficial in practical applications such as
abstract summarization or integration of the pre-
dictions into complex regulatory pathways.
In addition to providing enhanced represen-
tation of biological processes, the SR data set
also offers interesting opportunities to improve on
event extraction. As an example, consider the sen-
tence presented in Figure 2, in which ?c-Rel? and
?p50? are both annotated as being subunits of the
144
We show here that c-Rel binds to
GGP_1   binding event
kappa B sites as heterodimers with p50.
GGP_1 subunit-of Term GGP_2
GGP_2 subunit-of Term
Figure 2: A sentence from PMID:1372388, show-
ing how SR data (double line) can provide strong
clues for the extraction of biomolecular events
(double line) from text.
term ?heterodimers?. The SR data thus provides
strong clues for the extraction of a Binding event
involving both c-Rel and p50.
During the last few years, event extraction
has gained much interest in the field of nat-
ural language processing (NLP) of biomedical
text (Pyysalo et al, 2007; Kim et al, 2008; Kim
et al, 2009). However, owing to the more com-
plex nature of this task setting, performance rates
are lower than for the extraction of simple bi-
nary relations. The currently best performing
framework for event extraction obtains 53.29% F-
score (Miwa et al, 2010), which is considerably
lower than the performance reported for extrac-
tion of protein-protein interaction relations, rang-
ing between 65% and 87% depending on the data
set used for evaluation (Miwa et al, 2009).
In this paper, we will study how data on static
relations can be applied to improve event extrac-
tion performance. First, we describe the various
data sets (Section 2) and the text mining frame-
work that was applied (Section 3). The main con-
tributions of this paper are presented in Section 4,
in which we study how static relation information
can be integrated into an event extraction frame-
work to enhance extraction performance. Finally,
Section 5 presents the main conclusions of this
work.
2 Data
In this section, we provide an overview of the two
main data sets used in this work: event annotation
(Section 2.1) and static relation annotation (Sec-
tion 2.2).
2.1 Event Data
The BioNLP?09 Shared Task data, derived from
the GENIA Event corpus (Kim et al, 2008), de-
Event type Args Train Devel Test
Gene expression T 1738 356 722
Transcription T 576 82 137
Protein catabolism T 110 21 14
Localization T 265 53 174
Phosphorylation T 169 47 139
Binding T+ 887 249 349
Regulation T, C 961 173 292
Positive regulation T, C 2847 618 987
Negative regulation T, C 1062 196 379
TOTAL - 8615 1795 3193
Table 1: BioNLP ST events, primary argument
types and data statistics. Arguments abbreviate for
(T)heme and (C)ause, with + marking arguments
that can occur multiple times for an event. We re-
fer to the task definition for details.
fines nine types of biomolecular events and is di-
vided into three data sets: training data, develop-
ment data and final test data, covering 800, 150
and 260 PubMed abstracts respectively. The event
types and their statistics in the three data sets are
shown in Table 1.
In the shared task setting, participants were pro-
vided with the gold annotations for Gene/Gene
Product (GGP) named entities, and for all three
data sets the texts of the abstracts and the gold
GGP annotations are publicly available. However,
while full gold event annotation is available for the
training and development data sets, the shared task
organizers have chosen not to release the gold an-
notation for the test data set. Instead, access to
overall results for system predictions is provided
through an online interface. This setup, adopted in
part following a similar design by the organizers of
the LLL challenge (Ne?dellec, 2005), is argued to
reduce the possibility of overfitting to the test data
and assure that evaluations are performed identi-
cally, thus maintaining comparability of results.
For the current study, involving detailed analy-
sis of the interrelationships of two classes of anno-
tations, the lack of access to the gold annotations
of the test set rules this data set out as a poten-
tial target of study. Consequently, we exclude the
blind test data set from consideration and use the
development set as a test set.
To simplify the analysis, we further focus our
efforts in this study on simple events involving
only the given GGPs as participants. In the full
shared task, events of the three Regulation types
may take events as arguments, resulting in re-
cursive event structures. These event types were
found to be the most difficult to extract in the
145
SR type Examples
term variant-of GGP [RFX5 fusion protein], [Tax mutants], [I kappa B gamma isoforms]
term part-of GGP [murine B29 promoter], [c-fos regulatory region], [transactivation domain] of Stat6,
the nearby [J element] of the human DPA gene,
the [consensus NF-kappa B binding site] of the E-selectin gene
GGP member-of term The [Epstein-Barr virus oncoprotein] latent infection membrane protein 1,
[Ikaros family members], PU.1 is a transcription factor belonging to the [Ets-family]
GGP subunit-of term the [NF-kappa B complex] contains both RelA and p50,
Human TAFII 105 is a cell type-specific [TFIID] subunit, [c-Rel/p65 heterodimers]
Table 2: Training examples of some of the SR types, including both noun phrase relations as well as
relations between nominals. GGPs are underlined and terms are delimited by square brackets.
shared task evaluation (Kim et al, 2009). Fur-
thermore, their inclusion introduces a number of
complications for evaluation as well as analysis,
as failure to extract a referenced event implies fail-
ure to extract events in which they appear as argu-
ments. We note that even with the limitations of
considering only the smallest of the three data sets
and excluding Regulation events from considera-
tion, the ST data still contains over 800 develop-
ment test events for use in the analysis.
2.2 Static Relation Data
The data on relations is drawn from two recently
introduced data sets. Both data sets cover specifi-
cally static relations where one of the participants
is a GGP and the other a non-GGP term. The
GGPs are drawn from the data introduced in (Ohta
et al, 2009a) and the terms from the GENIA cor-
pus term annotation (Kim et al, 2003), excluding
GGPs. The first data set, introduced in (Pyysalo et
al., 2009), covers static relations involving GENIA
corpus terms that are annotated as participants
in the events targeted in the BioNLP?09 shared
task. The second data set, introduced in (Ohta et
al., 2009b), contains annotation for relations hold-
ing between terms and GGPs embedded in those
terms. In this study, we will use the non-embedded
relations from the former data set, referring to this
data as RBN for ?Relations Between Nominals?
in recognition of the similarity of the task setting
represented by this data set and the task of learn-
ing semantic relations between nominals, as stud-
ied e.g. in SemEval (Girju et al, 2007; Hendrickx
et al, 2009). We use all of the latter data set,
below referred to as NPR for ?Noun Phrase Re-
lations?. The NPR data set extends on the em-
bedded part of the data introduced by (Pyysalo
et al, 2009), increasing the coverage of terms in-
cluded and the granularity of the annotated event
types. While RBN only differentiates between a
domain-specific Variant relation and four different
part-whole relations, in NPR these are refined into
more than 20 different types.
To apply these data sets together in a single
framework, it was necessary to resolve the differ-
ences in the annotated relation types. First, as the
finer-grained NPR types are organized in a hier-
archy that includes the four part-whole relations
of the RBN categorization as intermediate types
(see Fig. 1 in Ohta et al (2009b)), we collapsed
the subtypes of each into these supertypes. While
this removes some potentially useful distinctions,
many of the finer-grained types are arguably un-
necessarily detailed for the purposes of the event
extraction task which, for example, makes no dis-
tinctions between events involving different gene
components. Furthermore, the NPR annotations
also define an Object-Variant class with multiple
subtypes, but as these were judged too diverse to
process uniformly, we did not collapse these sub-
types as was done for part-whole relations. Rather,
we divided them into ?near? and ?far? variants by
a rough ?functional distance? to the related GGP,
as suggested by Ohta et al (2009b). The relations
GGP-Modified Protein, GGP-Isoform and GGP-
Mutant were accepted into the ?near? set, expected
to provide positive features for inclusion in events,
and the remaining subtypes into the ?far? set, ex-
pected to provide negative indicators.
In addition to the primary annotation covering
static relations, the RBN annotation only recog-
nizes a mixed ?other relation/out? category, used
to annotate both GGP-term pairs for which the
stated relation is not one of the targeted types (e.g.
a causal relation) and pairs for which no relation is
stated. Due to the heterogeneity of this category,
146
it is difficult to make use of these annotations, and
we have chosen not to consider them in this work.
By contrast, the NPR annotation also subdi-
vides the ?other relation? category into five spe-
cific types, providing an opportunity to also use
the part of the data not strictly involving static re-
lations. We judged the classes labeled Functional,
Experimental Method and Diagnosis and Ther-
apeutics to involve terms where contained GGP
names are unlikely to be participants in stated
events and thus provide features that could serve as
potentially useful negative indicators for event ex-
traction. As an example, the Functional category
consists of GGP-term pairs such as GGP inhibitor
and GGP antibody, where the term references an
entity separate from the GGP, identified through
a functional or causal relation to the GGP. As
such terms occur in contexts similar to ones stat-
ing events involving the GGP, explicit marking of
these cases could improve precision. Consider, for
example, GGP1 binds GGP2, GGP1 binds GGP2
promoter, GGP1 binds GGP2 inhibitor and GGP1
binds GGP2 antagonist: a binding event involving
GGP1 and GGP2 should be extracted for the first
two statements but not the latter two.
Table 2 lists some interesting examples of static
relation grouped by type, including both noun
phrase relations as well as relations between nom-
inals. The consolidated data combining the two
static relations - related data sets are available at
the GENIA project webpage.1
3 Methods
The text mining tool used for all analyses in this
paper is based on the event extraction frame-
work of Van Landeghem et al (2009), which
was designed specifically for participation in the
BioNLP?09 Shared Task. In this framework, trig-
gers are discovered in text by using automati-
cally curated dictionaries. Subsequently, candi-
date events are formed by combining these triggers
with an appropriate number of GGPs co-occurring
in the same sentence. For each distinct event type,
a classifier is then built using all training examples
for that specific type. Final predictions are merged
for all types, forming a complex interaction graph
for each article in the test set.
To distinguish between positive instances and
negatives, the framework extracts rich feature vec-
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA
binds
c-Rel
nsu
bj
heterodimer
p50
prep_as
pr e
p_
wi t
h
we
show
nsubj
here
advmod
complm
that
cc
om
p
sites
Bkappa
nn nn
pre
p_
to
Figure 3: Dependency graph for the sentence ?We
show here that c-Rel binds to kappa B sites as het-
erodimers with p50?. Words of the sentence form
the nodes of the graph, while edges denote their
syntactic dependencies.
tors by analyzing lexical and syntactic information
from the training data. Subsequently, a support
vector machine (SVM) is built with these training
patterns. The patterns include trigrams, bag-of-
word features, vertex walks and information about
the event trigger. As part of the current study dis-
cusses the extension and generalization of these
feature patterns (Section 4.4), we will briefly dis-
cuss the various types in this section.
To derive syntactic patterns, dependency pars-
ing is applied using the Stanford parser (Klein and
Manning, 2003; De Marneffe et al, 2006). Specif-
ically, for each candidate event, the smallest sub-
graph is built including the relevant nodes for the
trigger and the GGP names. Each edge in this sub-
graph then gives rise to a pattern including the in-
formation from the connecting nodes (or vertices)
in combination with the syntactic relation speci-
fied by the edge. Trigger words and GGP names
are blinded by replacing their text with the strings
protx and trigger (respectively), resulting in highly
general features.
Figure 3 depicts an exemplary dependency
graph. For the Binding event between c-Rel and
p50, the following vertex walks would be ex-
tracted: ?trigger nsubj protx?, ?trigger prep-as het-
erodimer? and ?heterodimer prep-with protx?.
147
Events Training Dev. test
Pos. SR data 1190 32% 227 28%
Neg. SR data 841 22% 207 26%
All SR data 1635 44% 350 43%
Table 3: Number of events that can be linked to at
least one static relation, including explicitly anno-
tated ?near miss? negative annotations, also show-
ing percentage of all gold-standard events.
Furthermore, lexical information is provided by
bag-of-word (BOW) features and trigrams. BOW
features incorporate all words occurring as nodes
in the dependency sub-graph. They include highly
informative words such as ?promoter?. Trigrams
are formed by combining three consecutive words
in the sub-sentence delimited by the trigger and
GGP offsets in text. They are capable of captur-
ing common phrases such as ?physical association
with?.
Finally, the lexical tokens of the event trigger
are highly relevant to determine the plausibility of
the event being a correct one. For example, ?se-
cretion? points to a Localization event, but more
general words often lead to false candidate events,
such as ?present?. The part of speech tags of the
trigger words are also included as separate fea-
tures.
During feature generation, all lexical patterns
are stemmed using the Porter stemming algo-
rithm (Porter, 1980), creating even more general
features and reducing sparseness of the feature
vectors.
4 Experiments
This section describes a thorough study on how
data on static relations can be integrated into an
event extraction framework. First, we will analyze
the amount of useful complementary annotations
across both data sets (Section 4.1). Next, we de-
scribe the generation and evaluation of new candi-
date events using terms involved in static relations,
in an effort to boost recall of the event predictions
(Section 4.2). To additionally improve on preci-
sion, we have implemented a false positive filter
exploiting SR annotations of GGPs involved in re-
lations judged to serve as negative indicators, such
as ?GGP inhibitor? (Section 4.3). Finally, Section
4.4 details experiments on the creation of more ex-
tensive features for event extraction by including
static relation data.
Predicted Percentage
instances of data set
Gene expression 63 17.70%
Transcription 34 41.46%
Protein catabolism 4 19.05%
Phosphorylation 20 42.55%
Localization 4 7.55%
Binding 73 29.44%
All events 198 24.54%
Table 4: Maximal recall performance of event in-
stances involving at least one non-NE term as ar-
gument. These terms are functioning as aliases for
the GGPs they are positively associated with.
4.1 Analysis of complementary data across
the two data sets
To assess the usability of the SR data set for event
extraction, we first analyze the amount of comple-
mentary annotations across the two data sets. On
the document level, the static relations data con-
tains some annotation for 87.6% of all training set
articles and for 94.67% of the development test
set, including both positive static relations as well
as explicitly negated ones. Most articles from the
event data set thus involve terms at least poten-
tially involved in static relations.
Analyzing the overlap in more detail, we de-
termined the number of events that could benefit
from adding SR data by counting the number of
events for which at least one GGP is also involved
in a static relation (either a positive or a negative
one). Table 3 shows the results of this evalua-
tion. In the training data, 1635 events involve at
least one GGP with SR annotation, which is 44%
of all events in the gold-standard annotation. For
the development test set, the number is 350 out of
the 808 gold standard events, i.e. 43% of events.
These development set events in particular will be
the subject of this study.
4.2 Terms as aliases for related GGPs
Our first application of static relations in an event
extraction framework involves the use of non-NE
terms appearing in the SR data set as aliases for the
GGPs they are positively associated with. In the
event extraction framework, new candidate events
can thus be formed by treating the terms as GGPs,
and mapping them back to the real GGPs after
classification. This procedure is motivated by the
definition of the various SR types and the under-
lying biological processes. For example, if a com-
plex is known to activate the expression of a cer-
148
Recall Precision F-score
Gene expression 11.24% 81.63% 19.75%
Transcription 20.73% 89.47% 33.66%
Protein catabolism 19.05% 100.00% 32.00%
Phosphorylation 36.17% 100.00% 53.12%
Localization 3.77% 25.00% 6.56%
Binding 12.50% 45.59% 19.62%
All events 13.75% 67.27% 22.84%
Table 5: Performance of event instances involv-
ing at least one non-NE term as argument. These
terms are functioning as aliases for the GGPs they
are positively associated with.
tain target GGP, then the various subunits of this
complex can be annotated as participants in that
event.
Obviously, this approach has some intrinsic lim-
itations as not all GGPs occurring as arguments
in events have a corresponding term that could be
used as alias. However, from Table 3 it is clear
that it should still be possible to extract 227 gold
standard cases. To test the limitation, we have
used the event extraction framework detailed in
Section 3, removing the SVM classifier from the
pipeline and simply labeling all candidate events
as positive predictions. The result indicates that
the framework is capable of retrieving 198 of the
227 gold standard cases (Table 4). The 29 missing
events are due to trigger words not appearing (fre-
quently) in the training set and thus missing from
the dictionary, preventing the event to be formed
as a candidate in the framework.
Our results thus show that nearly 25% of all
events are potentially retrievable by using non-NE
terms as aliases for GGPs. However, the analy-
sis also indicates that in this approach, some event
types are much easier to extract than others. For
example, less than 8% of Localization events can
be found with this setup, while maximal recall for
Phosphorylation events is over 40%. These re-
sults reflect the intrinsic differences between event
types and the ways in which they are typically ex-
pressed, and suggest that it should be beneficial
for event extraction to take these differences into
account when incorporating static relations.
Having established an upper bound for recall, a
subsequent experiment involves treating the newly
created instances as normal candidate events. For
classification, we use an SVM trained on regular
candidate events involving GGPs, as this ensures
sufficient training material.
Both lexical and syntactic patterns are expected
Baseline Merged
predictions predictions
Gene expression 77.01% 77.56%
Transcription 63.41% 64.24%
Protein catabolism 86.36% 86.36%
Phosphorylation 70.10% 76.47%
Localization 80.00% 76.77%
Binding 38.69% 40.52%
All events 64.71% 65.33%
All events (precision) 69.11% 67.19%
All events (recall) 60.84% 63.57%
Table 6: Performance of the event extraction
framework. First column: using only normal
events involving GGPs (?baseline?). Second col-
umn: merging the new predictions (Table 5) with
the first ones. All performance rates indicate F-
score, except for the last two rows.
to be similar for events involving either non-NE
terms or GGPs. To test this hypothesis, we have
run the event-extraction pipeline for these new in-
stances. Evaluation is performed with the stan-
dard evaluation script provided by the BioNLP?09
Shared Task organizers, which measures the per-
centage of true events amongst all predictions
(precision), the percentage of gold-standard events
recovered (recall) and the harmonic mean of these
two metrics (F-score). The results are detailed in
Table 5. While we have already established that
recall is subject to severe limitations (Table 4), we
note in particular the high precision rates of the
predictions. In particular, four out of six event
types achieve a precision rate higher than 80%.
To allow for a meaningful comparison, these re-
sults should be put into perspective by merging the
new predictions with the predictions of a baseline
extractor and comparing against this baseline (Ta-
ble 6). This analysis reveals interesting results:
while overall performance increases slightly from
64.71% to 65.33% F-score, this trend is not com-
mon to all event types. For instance, prediction of
Localization drops 3.23% points F-score. Consid-
ering the maximum recall results, this is not en-
tirely surprising and confirms the hypothesis that
the prediction of Localization events will not ben-
efit from static relation data in this approach.
However, we do observe a considerable increase
in performance for Phosphorylation (6.37% points
F-score) events and some increase for Binding
events (1.83% points F-score). This performance
boost is mainly caused by an increase in recall
(10.64% and 4.43% points, respectively). When
considering all protein events, recall is increased
149
from 60.84% to 63.57% (Table 6, last row). These
results clearly indicate that the inclusion of static
relations can improve recall while retaining and
even slightly improving general performance.
4.3 Using static relations to filter false
positive events
To further improve event extraction performance,
we have designed a false-positive (FP) filter using
specific categories of relations serving as negative
indicators for event extraction. In particular, we
have used the ?far variants? and Functional rela-
tion annotations, as described in Section 2.2. For
each such relation, we add the GGP involved to
the FP filter, as the GGP should not participate in
any event. Thus, for example, the GGP in ?GGP
antibodies? would be filtered as the GGP is con-
sidered too far removed from the containing term
to be a participant in any event in the context.
In the development test set, this strategy has au-
tomatically identified 24 relevant GGP mentions
that should not be annotated as being involved in
any event. Even though this number is relatively
small, we aim at designing a high specificity FP
filter while relying on the SVM classifier to solve
more ambiguous cases.
Applying the FP filter to the baseline result de-
tailed in Table 6, we find that 3 events are dis-
carded from the set of predictions. All three in-
stances represented false positives; two of them
were Binding events and one a Gene expression
event. Overall precision and F-score increased by
0.30% points and 0.13% points, respectively.
4.4 Extended feature representation
incorporating information on static
relations
The last type of experiment aims to boost both
precision and recall by substantially extending the
feature generation module for event extraction us-
ing the newly introduced SR data. Table 3 shows
that such an enhanced feature representation could
influence 1190 events in the training data (1635
events including negative annotations) and 227
events in the development test data (350 including
negative), covering a significant part of the data
set.
Building further on the feature generation mod-
ule described in Section 3, we have added a range
of new features to the feature vectors while also
providing enhanced generalization of existing fea-
tures. Generalization is crucial for the text mining
framework as it enables the extraction of relations
from new contexts and forms of statements.
First, for each term involved in a static rela-
tion with a GGP, the string of the term is included
as a separate feature. This generates relation-
associated features such as ?tyrosine?, which is
strongly correlated with Phosphorylation events.
For terms spanning multiple tokens, we addition-
ally include each token as a separate feature, cap-
turing commonly used words such as ?promoter?
or ?receptor?. Each distinct feature is linked to its
specific relation type, such as Part-of or Member-
collection (Section 2.2). To make use of annota-
tion for ?near-miss? negative cases, we generate
features also for these relations, marking each fea-
ture to identify whether it was derived from a pos-
itive or negative annotation.
Additionally, we introduced a new feature type
expressing whether or not the trigger of the event
is equal to a term related to one or more GGPs in-
volved in the event. As an example, suppose the
candidate event is triggered by the word ?homod-
imer?. If the GGP involved is annotated as being a
subunit of this homodimer, this provides a strong
clue for a positive event. Similarly, the explicit
negation of the existence of any static relation in-
dicates a negative event.
Apart from these new features, we have also in-
vestigated the use of static relations to create more
general lexical patterns. In particular, we have ad-
justed the lexical information in the feature vector
by blinding terms involved in relevant relations,
depending on the specific type of relation. For
each such term, the whole term string is replaced
by one word, expressing the type of the static re-
lation and whether the relation is positive or neg-
ative. This results in more general patterns such
as ?inhibit prep-to partx? (vertex walk) or ?activ
in nonpartx? (trigram). In Figure 3, ?heterodimer?
would be blinded as ?complexx? as both c-Rel and
p50 are members of this complex.
Initial experiments with the extended feature
representation showed that an increase in perfor-
mance could be obtained on the development test
set, achieving 61.34% recall, 69.58% precision
and 65.20% F-score. However, it also became
clear that not all event types benefit from the new
features. Surprisingly, Binding is one such exam-
ple. We hypothesize that this is mainly due to the
intrinsic complexity of Binding events, requiring
an even more advanced feature representation.
150
Baseline New
predictions predictions
Gene expression 77.01% 78.06%
Transcription 63.41% 63.80%
Protein catabolism 86.36% 86.36%
Phosphorylation 70.10% 76.29%
Localization 80.00% 84.21%
Binding 38.69% 38.34%
All events 64.71% 65.73%
All events (precision) 69.11% 69.99%
All events (recall) 60.84% 61.96%
Table 7: Performance of the event extraction
framework. First column: using the baseline fea-
ture representation. Second column: using the
extended feature representation. All performance
rates indicate F-score, except for the last two rows.
To take the inherent differences between vari-
ous event types into account, we selected the opti-
mal set of features for each type. In a new experi-
ment, the feature generation step thus depends on
the event type under consideration. Table 7 details
the results of this optimization: an overall F-score
of 65.73% is achieved. Similar to the experiments
in Section 4.2, the F-score for the prediction of
Phosphorylation events increases by 6.19% points.
Additionally, in this experiment we obtain an in-
crease of 4.21% points in F-score for Localization
events, even though we were unable to improve
on them when using terms as aliases for additional
candidate events (Section 4.2). Additional exper-
iments suggested the reason to be that while the
Localization event type in general does not ben-
efit from positive static relations, negative static
relations seem to provide strong clues to the SVM
classifier.
5 Conclusion
We have presented the first study on the appli-
cability of static relations for event prediction
in biomedical texts. While data on static rela-
tions can offer a more detailed representation of
biomolecular events, it can also help to boost
the performance of event prediction. We have
performed three sets of experiments to investi-
gate these opportunities. First, we have designed
new candidate events by treating non-NE terms
as aliases for the GGPs they are associated with.
By augmenting the normal event predictions with
predictions for these new candidates, we have es-
tablished a considerable increase in recall. Next,
we have implemented a false positive filter to im-
prove precision, by exploiting annotation for re-
lations judged to imply only distant associations
of the GGP and the enclosing term. Finally, the
last type of experiment involves integrating com-
plementary data on static relations to obtain more
informative feature vectors for candidate events.
Results show that both recall and precision can be
increased slightly by this last, more complex con-
figuration.
During the experiments, it has become clear that
there are important differences between the data
sets of distinct event types. For example, we have
found that Phosphorylation events benefit the most
from added static relations data, while Localiza-
tion events can be enhanced using only features
of negative static relation annotations. For some
event types, such as Protein catabolism, the cur-
rent techniques for integration of static relations
do not generate a performance boost. However,
our findings pave the way for experiments involv-
ing more detailed representations, taking the in-
trinsic properties of the various event types into
account and combining the various ways of inte-
grating the new information. We regard these op-
portunities as promising future work.
Finally, having established the potential added
value offered by data on static relations in an event
extraction framework, additional future work will
focus on the automatic extraction of the static re-
lations. Similar relations have been considered in
numerous recent studies, and while challenges to
reliable prediction remain, several methods with
promising performance have been proposed (Girju
et al, 2007; Hendrickx et al, 2009). By inte-
grating predictions from both static relations and
events instead of using gold standard relation an-
notations, we will be able to study the effect of
the relation information on new data, including the
shared task test set. Such experiments are key to
establishing the practical value of static relations
for biomolecular event extraction.
Acknowledgments
SVL would like to thank the Research Founda-
tion Flanders (FWO) for funding her research.
The work of SP and TO was partially supported
by Grant-in-Aid for Specially Promoted Research
(MEXT, Japan).
References
M. De Marneffe, B. Maccartney, and C. Manning.
2006. Generating typed dependency parses from
151
phrase structure parses. In Proceedings of LREC-
06, pages 449?454.
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
Semeval-2007 task 04: Classification of semantic
relations between nominals. In Proceedings of the
Fourth International Workshop on Semantic Evalu-
ations (SemEval-2007), pages 13?18, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid O? Se?aghdha, Sebastian
Pado?, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2009. Semeval-2010 task
8: Multi-way classification of semantic relations
between pairs of nominals. In Proceedings of
the Workshop on Semantic Evaluations: Recent
Achievements and Future Directions (SEW-2009),
pages 94?99, Boulder, Colorado, June. Association
for Computational Linguistics.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and
Jun?ichi Tsujii. 2003. GENIA corpus - a seman-
tically annotated corpus for bio-textmining. Bioin-
formatics, 19(suppl. 1):i180?i182.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008. Corpus annotation for mining biomedi-
cal events from literature. BMC Bioinformatics,
9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
bionlp?09 shared task on event extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting of the Association for Com-
putational Linguistics, pages 423?430, Sapporo,
Japan, July. Association for Computational Linguis-
tics.
Makoto Miwa, Rune Saetre, Yusuke Miyao, and
Jun?ichi Tsujii. 2009. A rich feature vector for
protein-protein interaction extraction from multiple
corpora. In EMNLP ?09: Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 121?130, Morristown, NJ,
USA. Association for Computational Linguistics.
Makoto Miwa, Rune Saetre, Jin-Dong D. Kim, and
Jun?ichi Tsujii. 2010. Event extraction with com-
plex event classification using rich features. Jour-
nal of bioinformatics and computational biology,
8(1):131?146, February.
Claire Ne?dellec. 2005. Learning language in logic -
genic interaction extraction challenge. In Proceed-
ings of the Learning Language in Logic Workshop
(LLL?05).
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009a. Incorporating
genetag-style annotation to genia corpus. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 106?
107, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Tomoko Ohta, Sampo Pyysalo, Kim Jin-Dong, and
Jun?ichi Tsujii. 2009b. A re-evaluation of biomedi-
cal named entity - term relations. In Proceedings of
LBM?09.
M. F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130?137.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. Bioinfer: a corpus for information
extraction in the biomedical domain. BMC bioinfor-
matics, 8(1):50+.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 1?9,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Sofie Van Landeghem, Yvan Saeys, Bernard De Baets,
and Yves Van de Peer. 2009. Analyzing text in
search of bio-molecular events: a high-precision ma-
chine learning framework. In BioNLP ?09: Pro-
ceedings of the Workshop on BioNLP, pages 128?
136, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
152
Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 105?113,
Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational Linguistics
From Pathways to Biomolecular Events: Opportunities and Challenges
Tomoko Ohta? Sampo Pyysalo? Jun?ichi Tsujii?
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Microsoft Research Asia, Beijing, China
{okap,smp}@is.s.u-tokyo.ac.jp, jtsujii@microsoft.com
Abstract
The construction of pathways is a major fo-
cus of present-day biology. Typical pathways
involve large numbers of entities of various
types whose associations are represented as
reactions involving arbitrary numbers of reac-
tants, outputs and modifiers. Until recently,
few information extraction approaches were
capable of resolving the level of detail in text
required to support the annotation of such
pathway representations. We argue that event
representations of the type popularized by the
BioNLP Shared Task are potentially applica-
ble for pathway annotation support. As a step
toward realizing this possibility, we study the
mapping from a formal pathway representa-
tion to the event representation in order to
identify remaining challenges in event extrac-
tion for pathway annotation support. Follow-
ing initial analysis, we present a detailed study
of protein association and dissociation reac-
tions, proposing a new event class and repre-
sentation for the latter and, as a step toward
its automatic extraction, introduce a manu-
ally annotated resource incorporating the type
among a total of nearly 1300 annotated event
instances. As a further practical contribu-
tion, we introduce the first pathway-to-event
conversion software for SBML/CellDesigner
pathways and discuss the opportunities arising
from the ability to convert the substantial ex-
isting pathway resources to events.
1 Introduction
For most of the previous decade of biomedical in-
formation extraction (IE), efforts have focused on
foundational tasks such as named entity detection
and their database normalization (Krallinger et al,
2008) and simple IE targets, most commonly bi-
nary entity relations representing associations such
as protein-protein interactions (Pyysalo et al, 2008;
Tikk et al, 2010). In recent years, an increasing
number of resources and methods pursuing more de-
tailed representations of extracted information are
becoming available (Pyysalo et al, 2007; Kim et al,
2008; Thompson et al, 2009; Bjo?rne et al, 2010).
The main thrust of this move toward structured, fine-
grained information extraction falls under the head-
ing of event extraction (Ananiadou et al, 2010), an
approach popularized and represented in particular
by the BioNLP Shared Task (BioNLP ST) (Kim et
al., 2009a; Kim et al, 2011).
While a detailed representation of extracted in-
formation on biomolecular events has several po-
tential applications ranging from semantic search to
database curation support (Ananiadou et al, 2010),
the number of practical applications making use of
this technology has arguably so far been rather lim-
ited. In this study, we pursue in particular the op-
portunities that event extraction holds for pathway
annotation support,1 arguing that the match between
1Throughout this paper, we call the projected task pathway
annotation support. There is no established task with this label,
and we do not envision this to be a specific single task. Rather,
we intend the term to refer to a set of tasks where information
extraction/text mining methods are applied in some role to con-
tribute directly to pathway curation, including, for example, the
identification of specific texts in the literature relevant to anno-
tated reactions, the automatic suggestion of further entities or
reactions to add to a pathway, or even the fully automatic gen-
eration of entire pathways from scratch.
105
representations that biologists employ to capture re-
actions between biomolecules in pathways and the
event representation of the BioNLP ST task makes
pathway-oriented applications a potential ?killer ap-
plication? for event extraction technology.
The fit between these representations is not ac-
cidental ? the design of the BioNLP ST event rep-
resentation has been informed by that of popular
pathway models ? nor is it novel to suggest to sup-
port pathway extraction through information meth-
ods in general (see e.g. (Rzhetsky et al, 2004))
or through event extraction specifically (Oda et al,
2008). However, our study differs from previous
efforts in two key aspects. First, instead of being
driven by information extraction and defining a rep-
resentation fitting its results, we specifically adopt
the perspective and model of a widely applied stan-
dard database representation and proceed from the
pathway to events in text. Second, while previous
work on event extraction for pathway annotation has
been exploratory in nature or has otherwise had lim-
ited practical impact, we introduce and release a
first software implementation of a conversion from
a standard pathway format to the event format, thus
making a large amount of pathway data available for
use in event extraction and taking a concrete step
toward reliable, routine mappings between the two
representations.
2 Representations and Resources
Before proceeding to consider the mapping between
the two, we first briefly introduce the pathway and
event representations in focus in this study and the
applied pathway resources.
2.1 Pathways
The biomolecular curation community has created
and made available an enormous amount of path-
way resources: for example, as of April 2011, the
Pathguide pathway resource list2 includes references
to 325 pathway-related resources ? many of which
are themselves pathway databases containing hun-
dreds of individual models. These resources in-
volve a formidable variety of different, largely inde-
pendently developed formats and representations of
which only few pairs have tools supporting mutual
2http://www.pathguide.org/
conversion. To address the challenges of interoper-
ability that this diversity implies, a number of stan-
dardization efforts for pathway representations have
been introduced.
In this work, we consider two widely adopted
pathway representation formats: Systems Biol-
ogy Markup Language (SBML)3 (Hucka et al,
2003) and Biological Pathway Exchange (BioPAX)4
(Demir et al, 2010). SBML is an XML-based
machine-readable data exchange format that sup-
ports a formal mathematical representation of chem-
ical reactions (including e.g. kinetic parameters),
allowing biochemical simulation. BioPAX is an
RDF/OWL-based standard language to represent
bio-molecular and cellular networks designed to en-
able data integration, exchange, visualization and
analysis. Despite significantly different choices in
storage format, the represented information content
of the two is broadly compatible. In the follow-
ing, we refer to established correspondences and
mappings when relating the two (see e.g. (Mi and
Thomas, 2009)).
As an interchange format aimed to support a large
variety of specific representations, the SBML stan-
dard itself does not define a fixed set of types of
physical entities or biochemical reactions. However,
the standard defines an extension mechanism allow-
ing additional information, including such types, to
be defined. As specific, fixed types with established
semantics are a requirement for practical conversion
between the different representations, we thus rely
in this work not only on SBML core, but also a min-
imal set of the extensions introduced by the popu-
lar CellDesigner pathway modeling tool (Funahashi
et al, 2008). In the following, we assume through-
out the availability of CellDesigner extensions when
discussing SBML features.
For pathway data, in this study we use the full
set of pathways contained in the Panther and Payao
pathway repositories in SBML form. Panther (Pro-
tein ANalysis THrough Evolutionary Relationships)
is a gene function-based classification system that
hosts a large collection of pathways. The Panther
repository consists of 165 pathways, including 153
signaling and 12 metabolic pathways. All pathways
3http://sbml.org
4http://www.biopax.org
106
Figure 1: Illustration of the event representation.
were drawn on CellDesigner by manual curation
and thus include CellDesigner SBML extensions
(Mi and Thomas, 2009). Payao is a community-
based SBML model tagging platform (Matsuoka et
al., 2010) that allows a community to share models,
tag and add comments, and search relevant literature
(Kemper et al, 2010). Currently, 28 models are reg-
istered in Payao. As in Panther, all Payao pathways
include CellDesigner extensions.
2.2 Event Representation
The application of event representations in biomed-
ical IE is a relatively recent development, follow-
ing the introduction of corpus resources annotating
structured, n-ary associations of entities with de-
tailed types (Pyysalo et al, 2007; Kim et al, 2008;
Thompson et al, 2009)) and popularized in particu-
lar by the BioNLP Shared Task (BioNLP ST) events
(Kim et al, 2009b; Kim et al, 2011). In this pa-
per, we use event in the BioNLP ST sense, to refer
specifically to the representation where each event
is assigned a type from a fixed ontology, bound to a
specific expression in text stating its occurrence (the
trigger or text binding), and associated with an ar-
bitrary number of participants (similarly text-bound
entities or other events), for which the roles in which
they are involved in the event are defined from a
fixed small inventory of event argument types (e.g.
Theme, Cause, Site). These concepts are illustrated
in Figure 1.
3 Analysis of Pathway-Event Mapping
We next present an analysis of the relationship be-
tween the two representations, considering features
required from IE systems for efficient support of
pathway annotation support.
We assume throughout that the target on the path-
way side is restricted to the broad, central biologi-
cal content of pathways, excluding information only
related to e.g. simulation support or pathway visual-
ization/layout.
Figure 2: Illustration of a generalized pathway reaction.
3.1 Top-level concepts
Both SBML and BioPAX involve two (largely com-
parable) top-level concepts that form the core of the
representation: entity (species/physical entity) and
reaction (interaction). In the following we focus pri-
marily on entities and reactions, deferring consider-
ation of detailed concepts such as modification state
and compartment localization to Section 3.3.
The concept of a reaction in the considered path-
way representations centrally involves three sets of
entities: reactants, products, and modifiers. As the
names suggest, the reaction produces the set of prod-
uct entities from the reactant entities and is affected
by the modifiers. Figure 2 shows an illustration of a
generalized reaction. Pathway reactions find a rea-
sonably good analogy in events in the event repre-
sentation. While the event representation does not
differentiate ?reactants? from ?products? in these
terms, the roles assigned to event participants al-
low comparable interpretation. There is no single
concept in the event representation directly compa-
rable to reaction modifiers. However, the semantics
of specific modification types (see Section 3.3) cor-
respond broadly to those of regulation in the event
representation, suggesting that modification be rep-
resented using a separate event of the appropriate
type with the modifying entities participating in the
Cause role (Kim et al, 2008). Figure 3 illustrates the
event structure proposed to correspond to the reac-
tion of Figure 2, with the added assumptions that the
reaction and modification types (unspecified in Fig-
ure 2) are Association (BioPAX:ComplexAssembly)
and Modulation (BioPAX:Control).
107
Figure 3: Illustration of a generalized event structure with four entities and two events (REGULATION and BINDING).
Note that the text is only present as filler to satisfy the requirement that events are bound to specific expressions in
text. The Product role is not a standard role in event representation but newly proposed in this study.
Pathway Event
CellDesigner BioPAX ST?09 ST?11 GENIA
Protein Protein Protein Protein Protein
RNA RNA Protein Protein RNA
AntiSenseRNA RNA Protein Protein RNA
Gene DNA Protein Protein DNA
Simple molecule Small molecule - Chemical Inorganic compound
Ion Small molecule - Chemical Inorganic compound
Drug PhysicalEntity - Chemical Inorganic compound
Hetero/homodimer Complex - - Protein complex
Table 1: Entity type comparison between pathways and events.
The mapping of top-level concepts that we con-
sider thus unifies physical entities in pathways with
the entities of the BioNLP ST representation, and
pathway reaction with event.5
To be able to efficiently support (some aspect of)
pathway annotation through IE, the applied extrac-
tion model should be able, for both entities and reac-
tions, to 1) recognize mentions of all relevant types
of entity/reaction and 2) differentiate between en-
tity/reaction types at the same or finer granularity as
the pathway representation. For example, an IE sys-
tem that does not detect mentions of protein com-
plexes cannot efficiently support aspects of pathway
annotation that involve this type; a system that de-
tects proteins and complexes with no distinction be-
tween the two will be similarly limited. In the fol-
lowing, we consider entity and reaction types sep-
arately to determine to what extent these require-
ments are filled by presently available resources for
event extraction, in particular the GENIA corpus
(Kim et al, 2008) and the BioNLP ST 2009 (Kim
et al, 2009b) and 2011 corpora.
5Pathways and IE/text mining use many of the same terms
with (sometimes subtly) different meanings. We use largely IE
terminology, using e.g. entity instead of species (SBML) and
entity type instead of physical entity class (BioPAX) / species
type (SBML) For the pathway associations, we have adopted
reaction (SBML term) in favor of interaction (BioPAX). With
event, we refer to the BioNLP ST sense of the word; we make
no use of the SBML ?event? concept.
3.2 Entities
Table 1 shows a comparison of the primary entity
types between SBML/CellDesigner, BioPAX, and
the event representations. There is significant dif-
ference in the resolution of gene and gene product
types between the pathway representations and that
applied in ST?09 and ST?11: while both pathway
representations and the GENIA corpus differenti-
ate the DNA, RNA and protein forms, the STs fold
the three types into a single one, PROTEIN.6 The
CHEMICAL type defined in ST?11 (ID task) overlaps
largely with BioPAX SMALL MOLECULE, a type
that SBML/CellDesigner further splits into two spe-
cific types, and further partly covers the definition of
the SBML/CellDesigner type Drug. The same holds
(with somewhat less specificity) for GENIA INOR-
GANIC COMPOUND. Finally, although annotated in
GENIA, the category of protein complexes has no
correspondence among the entities considered in the
BioNLP ST representation.
Thus, information extraction systems applying
the core BioNLP ST entity types will entirely lack
coverage for protein complexes and will not be able
6While the term PROTEIN appears to suggest that the class
consists only of protein forms, these entities are in fact anno-
tated in the BioNLP ST data according to the GENIA gene/gene
product guidelines (Ohta et al, 2009) and thus include also
DNA and RNA forms. The type could arguably more accurately
be named GENE OR GENE PRODUCT.
108
Pathway Event
CellDesigner BioPAX ST?09 ST?11 GENIA
State transition BiochemicalReaction (see Table 3)
Truncation BiochemicalReaction Catabolism Catabolism Catabolism
Transcription BiochemicalReaction Transcription Transcription Transcription
Translation BiochemicalReaction - - Translation
Association ComplexAssembly Binding Binding Binding
Dissociation ComplexAssembly - - -
Transport Transport w/reaction Localization Localization Localization
Degradation Degradation Catabolism Catabolism Catabolism
Catalysis Catalysis Positive regulation Positive regulation Positive regulation
Physical stimulation Control Positive regulation Positive regulation Positive regulation
Modulation Control Regulation Regulation Regulation
Trigger Control Positive regulation Positive regulation Positive regulation
Inhibition Control Negative regulation Negative regulation Negative regulation
Table 2: Reaction type comparison between pathways and events.
to fully resolve the detailed type of gene and gene
product types applied in the pathway representa-
tions. While these distinctions exist in the full GE-
NIA corpus, it has not been frequently applied in
event extraction in its complete form and is un-
likely to be adopted over the widely applied ST
resources. Finally, none of the event representa-
tions differentiate the pathway small molecule/drug
types. We discuss the implications of these ambigu-
ities in detail below. By contrast, we note that both
SBML/CellDesigner and BioPAX entity types cover
the scope of the major BioNLP ST types and have
comparable or finer granularity in each case.
3.3 Reactions
Table 2 shows a comparison between the reaction
types of the two considered pathway representations
and those of the BioNLP ST event representation.
The full semantics of the generic reaction type State
transition (BioPAX: BiochemicalReaction) cannot
be resolved from the type alone; we defer discussion
of this type.
Contrary to the event types, we find that for re-
action types even the least comprehensive BioNLP
ST?09 event representation has high coverage of the
pathway reaction types as well as a largely compa-
rable level of granularity in its types. While neither
of the BioNLP ST models defines a TRANSLATION
type, the adoption of the GENIA representation ?
matching that for TRANSCRIPTION ? for this simple
and relatively rare event type would likely be rela-
tively straightforward. A more substantial omission
in all of the event representations is the lack of a
Dissociation event type. As dissociation is the ?re-
verse? reaction of (protein) BINDING and central to
many pathways, its omission from the event model
is both surprising as well as potentially limiting for
applications of event extraction to pathway annota-
tion support.
The detailed resolution of pathway reactions pro-
vided by the event types has implications on the
impact of the ambiguity noted between the sin-
gle type covering genes and gene products in the
event representation as opposed to the distinct
DNA/RNA/protein types applied in the pathways.
Arguably, for many practical cases the specific type
of an entity of the broad gene/gene product type is
unambiguously resolved by the events it participates
in: for example, any gene/gene product that is mod-
ified through phosphorylation (or similar reaction)
is necessarily a protein.7 Similarly, only proteins
will be involved in e.g. localization between nucleus
and cytoplasm. On a more detailed level, BIND-
ING events resolves their arguments in part through
their Site argument: binding to a promoter implies
DNA, while binding to a C-terminus implies pro-
tein. Thus, we can (with some reservation) forward
the argument that it is not necessary to disambiguate
all gene/gene product mentions on the entity level
for pathway annotation support, and that success-
ful event extraction will provide disambiguation in
cases where the distinction matters.
7DNA methylation notwithstanding; the BioNLP ST?11 EPI
task demonstrated that protein and DNA methylation can be dis-
ambiguated on the event type level without entity type distinc-
tions.
109
Pathway Event
SBML/CellDesigner ST?09 ST?11 GENIA
in:Compartment1 ? in:Compartment2 Localization Localization Localization
residue:state:? ? residue:state:Phosphorylated Phosphorylation Phosphorylation Phosphorylation
residue:state:Phosphorylated ? residue:state:? - Dephosphorylation Dephosphorylation
residue:state:? ? residue:state:Methylated - Methylation Methylation
residue:state:Methylated ? residue:state:? - Demethylation Demethylation
residue:state:? ? residue:state:Ubiquitinated - Ubiquitination Ubiquitination
residue:state:Ubiquitinated ? residue:state:? - Deubiquitination Deubiquitination
species:state:inactive ? species:state:active Positive regulation Positive regulation Positive regulation
species:state:active ? species:state:inactive Negative regulation Negative regulation Negative regulation
Table 3: Interpretation and comparison of state transitions.
Finally, the pathway representations de-
fine generic reaction types (State transi-
tion/BiochemicalReaction) that do not alone
have specific interpretations. To resolve the event
involved in these reactions it is necessary to com-
pare the state of the reactants against that of the
matching products. Table 3 shows how specific state
transitions map to event types (this detailed compar-
ison was performed only for SBML/CellDesigner
pathways). We find here a good correspondence for
transitions affecting a single aspect of entity state.
While generic pathway transitions can change any
number of such aspects, we suggest that decomposi-
tion into events where one event corresponds to one
point change in state is a reasonable approximation
of the biological interpretation: for example, a reac-
tion changing one residue state into Methylated and
another into Phosphorylated would map into two
events, METHYLATION and PHOSPHORYLATION.
In summary of the preceding comparison of the
core pathway and event representations, we found
that in addition to additional ambiguity in e.g. gene
and gene product types, the popular BioNLP ST rep-
resentations lack a protein complex type and further
that none of the considered event models define a
(protein) dissociation event. To address these latter
omissions, we present in the following section a case
study of dissociation reactions as a step toward their
automatic extraction. We further noted that pathway
types cover the event types well and have similar or
higher granularity in nearly all instances. This sug-
gests to us that mapping from the pathway repre-
sentation to events is more straightforward than vice
versa. To follow up on these opportunities, we intro-
duce such a mapping in Section 5, in following the
correspondences outlined above.
4 Protein Association and Dissociation
In the analysis presented above, we noted a major re-
action type defined in both considered pathway rep-
resentations that had no equivalent in the event rep-
resentation: dissociation. In this section, we present
a study of this reaction type and its expression as
statements in text through the creation of event-style
annotation for dissociation statements.
4.1 Target data
Among the large set of pathways available, we chose
to focus on the Payao mTOR pathway (Caron et al,
2010) because it is a large, recently introduced path-
way with high-quality annotations that involves nu-
merous dissociation reactions. The Payao pathways
are further annotated with detailed literature refer-
ences, providing a PubMed citation for nearly each
entity and reaction in the pathway. To acquire texts
for event annotation, we followed the references in
the pathway annotation and retrieved the full set of
PubMed abstracts associated with the pathway, over
400 in total. We then annotated 60 of these abstracts
that were either marked as relevant to dissociation
events in the pathway or were found to include dis-
sociation statements in manual analysis. These ab-
stracts were not included in any previously anno-
tated domain corpus. Further, as we aimed specifi-
cally to be able to identify event structures for which
no previous annotations exist, we could not rely on
(initial) automatic annotation.
4.2 Annotation guidelines
We performed exhaustive manual entity and event
annotation in the event representation for the se-
lected 60 abstracts. For entity annotation, we ini-
110
tially considered adopting the gene/gene product an-
notation guidelines (Ohta et al, 2009) applied in
the BioNLP ST 2009 as well as in the majority
of the 2011 tasks. However, the requirement of
these guidelines to mark only specific gene/protein
names would exclude a substantial number of the
entities marked in the pathway, as many refer to
gene/protein families or groups instead of specific
individual genes or proteins. We thus chose to adopt
the pathway annotation itself for defining the scope
of our entity annotation: we generated a listing of all
the names appearing in the target pathway and an-
notated their mentions, extrapolating from this rich
set of examples to guide us in decisions on how to
annotate references to entities not appearing in the
pathway. For event annotation, we adapted the GE-
NIA event corpus annotation guidelines (Kim et al,
2008), further developing a specific representation
and guidelines for annotating dissociation events
based on an early iteration of exploratory annotation.
Annotation was performed by a single biology
PhD with extensive experience in event annotation
(TO). While we could thus not directly assess inter-
annotator consistency, we note that our recent com-
parable efforts have been evaluated by comparing
independently created annotations at approximately
90% F-score for entity annotations and approxi-
mately 80% F-score for event annotations (BioNLP
Shared Task primary evaluation criteria) (Pyysalo et
al., 2011; Ohta et al, 2011).
4.3 Representing Association and Dissociation
Based on our analysis of 107 protein dissociation
statements annotated in the corpus and a correspond-
ing study of the ?reverse?, statements of protein as-
sociation in the corpus, we propose the following
extensions for the BioNLP ST event representation.
First, the introduction of the event type DISSOCIA-
TION, taking as its primary argument a single Theme
identifying a participating entity of the type COM-
PLEX. Second, we propose the new role type Prod-
uct, in the annotation of DISSOCIATION events an
optional (secondary) argument identifying the PRO-
TEIN entities that are released in the dissociation
event. This argument should be annotated (or ex-
tracted) only when explicitly stated in text. Third,
for symmetry in the representation, more detail in
extracted information, and to have a representation
Figure 4: Examples annotated with the proposed event
representation for DISSOCIATION and BINDING events
with the proposed Product role marking formed complex.
Item Count
Abstract 60
Word 11960
Protein 1483
Complex 201
Event 1284
Table 4: Annotation statistics.
more compatible with the pathway representation
for protein associations, we propose to extend the
representation for BINDING, adding Product as an
optional argument identifying a COMPLEX partici-
pant in BINDING events marking statements of com-
plex formation stating the complex. The extended
event representations are illustrated in Figure 4.
4.4 Annotation statistics
Table 4 presents the statistics of the created annota-
tion. While covering a relatively modest number of
abstracts, the annotation density is very high, relat-
ing perhaps in part to the fact that many of the ref-
erenced documents are reviews condensing a wealth
of information into the abstract.
5 Pathway-to-event conversion
As an additional practical contribution and out-
come of our analysis of the mapping from the path-
way representation to the event representation, we
created software implementing this mapping from
SBML with CellDesigner extensions to the event
representation. This conversion otherwise follows
111
the conventions of the event model, but lacks spe-
cific text bindings for the mentioned entities and
event expressions (triggers). To maximize the appli-
cability of the conversion, we chose to forgo e.g. the
CellDesigner plugin architecture and to instead cre-
ate an entirely standalone software based on python
and libxml2. We tested this conversion on the 165
Panther and 28 Payao pathways to assure its robust-
ness.
Conversion from pathways into the event repre-
sentation opens up a number of opportunities, such
as the ability to directly query large-scale event
repositories (e.g. (Bjo?rne et al, 2010)) for specific
pathway reactions. For pathways where reactions
are marked with literature references, conversion
further allows event annotations relevant to specific
documents to be created automatically, sparing man-
ual annotation costs. While such event annotations
will not be bound to specific text expressions, they
could be used through the application of techniques
such as distant supervision (Mintz et al, 2009). As a
first attempt, the conversion introduced in this work
is limited in a number of ways, but we hope it can
serve as a starting point for both wider adoption
of pathway resources for event extraction and fur-
ther research into accurate conversions between the
two. The conversion software, SBML-to-event,
is freely available for research purposes.
6 Discussion and Conclusions
Over the last decade, the bio-community has in-
vested enormous efforts in the construction of de-
tailed models of the function of a large variety of bi-
ological systems in the form of pathways. These ef-
forts toward building systemic understanding of the
functioning of organisms remain a central focus of
present-day biology, and their support through infor-
mation extraction and text mining perhaps the great-
est potential contribution that the biomedical natural
language processing community could make toward
the broader bio-community.
We have argued that while recent developments
in BioNLP are highly promising for approaching
practical support of pathway annotation through in-
formation extraction, the BioNLP community has
not yet made the most of the substantial resources
in the form of existing pathways and that pursu-
ing mapping from pathways to the event represen-
tation might be both more realistic and more fruit-
ful than the other way around. As a first step in
what we hope will lead to broadened understand-
ing of the different perspectives, communication be-
tween the communities, and better uses resources,
we have introduced a fully automatic mapping from
SBML/CellDesigner pathways into the BioNLP ST-
style event representation. As a first effort this map-
ping has many limitations and imperfections that we
hope the BioNLP community will take as a chal-
lenge to do better.
Noting in analysis that dissociation reactions are
not covered in previously proposed event represen-
tations, we also presented a detailed case study fo-
cusing on statements describing protein association
and dissociation reactions in PubMed abstracts rel-
evant to the mTOR pathway. Based on exploratory
annotation, we proposed a novel event class DIS-
SOCIATION, thus taking a step toward covering this
arguably most significant omission in the event rep-
resentation.
The pathway-bound event annotations created
in this study, exhaustive annotation of all rel-
evant entities and events in 60 abstracts, con-
sist in total of annotation identifying nearly
1500 protein and 200 complex mentions and
over 1200 events involving these entities in text.
These annotations are freely available for use
in research at http://www-tsujii.is.s.
u-tokyo.ac.jp/GENIA.
Acknowledgments
We would like to thank Hiroaki Kitano, Yukiko Mat-
suoka and Samik Ghosh of the Systems Biology In-
stitute for their generosity in providing their time
and expertise in helping us understand the CellDe-
signer and SBML pathway representations. This
work was partially supported by Grant-in-Aid for
Specially Promoted Research (MEXT, Japan).
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
112
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,
and Tapio Salakoski. 2010. Complex event extraction
at PubMed scale. Bioinformatics, 26(12):i382?390.
E. Caron, S. Ghosh, Y. Matsuoka, D. Ashton-Beaucage,
M. Therrien, S. Lemieux, C. Perreault, P.P. Roux, and
H. Kitano. 2010. A comprehensive map of the mTOR
signaling network. Molecular Systems Biology, 6(1).
E. Demir, M.P. Cary, S. Paley, K. Fukuda, C. Lemer,
I. Vastrik, G. Wu, P. D?Eustachio, C. Schaefer, J. Lu-
ciano, et al 2010. The BioPAX community stan-
dard for pathway data sharing. Nature biotechnology,
28(9):935?942.
A. Funahashi, Y. Matsuoka, A. Jouraku, M. Morohashi,
N. Kikuchi, and H. Kitano. 2008. CellDesigner 3.5:
a versatile modeling tool for biochemical networks.
Proceedings of the IEEE, 96(8):1254?1265.
M. Hucka, A. Finney, H. M. Sauro, H. Bolouri, J. C.
Doyle, and H Kitano et al 2003. The systems biol-
ogy markup language (SBML): a medium for repre-
sentation and exchange of biochemical network mod-
els. Bioinformatics, 19(4):524?531.
B. Kemper, T. Matsuzaki, Y. Matsuoka, Y. Tsuruoka,
H. Kitano, S. Ananiadou, and J. Tsujii. 2010. Path-
Text: a text mining integrator for biological pathway
visualizations. Bioinformatics, 26(12):i374.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009a. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of BioNLP 2009 Shared Task.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009b. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011.
Overview of BioNLP Shared Task 2011. In Proceed-
ings of BioNLP 2011.
M. Krallinger, A. Morgan, L. Smith, F. Leitner, L. Tan-
abe, J. Wilbur, L. Hirschman, and A. Valencia.
2008. Evaluation of text-mining systems for biology:
overview of the Second BioCreative community chal-
lenge. Genome biology, 9(Suppl 2):S1.
Y. Matsuoka, S. Ghosh, N. Kikuchi, and H. Kitano. 2010.
Payao: a community platform for SBML pathway
model curation. Bioinformatics, 26(10):1381.
H. Mi and P. Thomas. 2009. PANTHER pathway: an
ontology-based pathway database coupled with data
analysis tools. Methods Mol. Biol, 563:123?140.
Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-
sky. 2009. Distant supervision for relation extraction
without labeled data. In Proceedings of ACL?09, pages
1003?1011.
Kanae Oda, Jin-Dong Kim, Tomoko Ohta, Daisuke
Okanohara, Takuya Matsuzaki, Yuka Tateisi, and
Jun?ichi Tsujii. 2008. New challenges for text min-
ing: Mapping between text and manually curated path-
ways. BMC Bioinformatics, 9(Suppl 3):S5.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009. Incorporating
GENETAG-style annotation to GENIA corpus. In
Proceedings of BioNLP?09, pages 106?107.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of BioNLP 2011.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Antti Airola, Juho Heimonen, and Jari
Bjo?rne. 2008. Comparative analysis of five protein-
protein interaction corpora. BMC Bioinformatics,
9(Suppl. 3):S6.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of BioNLP
2011.
Andrey Rzhetsky, Ivan Iossifov, Tomohiro Koike,
Michael Krauthammer, Pauline Kra, Mitzi Morris,
Hong Yu, Pablo Ariel Duboue?, Wubin Weng, W. John
Wilbur, Vasileios Hatzivassiloglou, and Carol Fried-
man. 2004. GeneWays: A system for extracting, ana-
lyzing, visualizing, and integrating molecular pathway
data. Journal of Biomedical Informatics, 37(1):43?53.
Paul Thompson, Syed Iqbal, John McNaught, and Sophia
Ananiadou. 2009. Construction of an annotated
corpus to support biomedical information extraction.
BMC Bioinformatics, 10(1):349.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg
Hakenberg, and Ulf Leser. 2010. A comprehen-
sive benchmark of kernel methods to extract protein-
protein interactions from literature. PLoS Comput
Biol, 6(7):e1000837, 07.
113
Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 114?123,
Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational Linguistics
Towards Exhaustive Protein Modification Event Extraction
Sampo Pyysalo? Tomoko Ohta? Makoto Miwa? Jun?ichi Tsujii?
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Microsoft Research Asia, Beijing, China
{smp,okap,mmiwa}@is.s.u-tokyo.ac.jp, jtsujii@microsoft.com
Abstract
Protein modifications, in particular post-
translational modifications, have a central role
in bringing about the full repertoire of pro-
tein functions, and the identification of spe-
cific protein modifications is important for
understanding biological systems. This task
presents a number of opportunities for the au-
tomatic support of manual curation efforts.
However, the sheer number of different types
of protein modifications is a daunting chal-
lenge for automatic extraction that has so far
not been met in full, with most studies focus-
ing on single modifications or a few prominent
ones. In this work, aim to meet this challenge:
we analyse protein modification types through
ontologies, databases, and literature and intro-
duce a corpus of 360 abstracts manually anno-
tated in the BioNLP Shared Task event repre-
sentation for over 4500 mentions of proteins
and 1000 statements of modification events of
nearly 40 different types. We argue that to-
gether with existing resources, this corpus pro-
vides sufficient coverage of modification types
to make effectively exhaustive extraction of
protein modifications from text feasible.
1 Introduction
In the decade following the sequencing of the hu-
man genome, the critical role of protein modifica-
tions in establishing the full set of protein functions
from forms transcribed from the fixed DNA is in-
creasingly appreciated, reflected in the rise of pro-
teomics as an extension and complement to genetics
in efforts to understand gene and protein functions.
The mapping of the space of modifications of spe-
cific proteins is a formidable undertaking: the num-
ber of known types of post-translational modifica-
tions (PTMs) is as high as 300 (Witze et al, 2007)
with new types identified regularly (e.g. (Brennan
and Barford, 2009)), and the number of specific
molecular variants of proteins in cells may be several
orders of magnitude larger than that encoded in the
genome; up to millions for humans (Walsh, 2006).
Automatic extraction of protein modifications from
the massive literature on the topic could contribute
significantly to addressing these challenges.
Biomedical information extraction (IE) has ad-
vanced substantially in recent years, shifting from
the detection of simple binary associations such
as protein-protein interactions toward resources and
methods for the extraction of multiple types of struc-
tured associations of varying numbers participants in
specific roles. These IE approaches are frequently
termed event extraction (Ananiadou et al, 2010).
While protein modifications have been considered
in numerous IE studies in the domain (e.g. (Fried-
man et al, 2001; Rzhetsky et al, 2004; Hu et al,
2005; Narayanaswamy et al, 2005; Saric et al,
2006; Yuan et al, 2006; Lee et al, 2008; Ohta et
al., 2010), event extraction efforts have brought in-
creased focus also on the extraction of protein modi-
fications: in the BioNLP Shared Task series that has
popularized event extraction, the 2009 shared task
(Kim et al, 2009) involved the extraction of nine
event types including one PTM, and in the 2011
follow-up event (Kim et al, 2011) the Epigenet-
ics and Post-translational modifications (EPI) task
(Ohta et al, 2011) targeted six PTM types, their re-
114
verse reactions, and statements regarding their catal-
ysis. The results of these tasks were promising, sug-
gesting that the single PTM type could be extracted
at over 80% F-score (Buyko et al, 2009) and the
core arguments of the larger set at nearly 70% F-
score (Bjo?rne and Salakoski, 2011).
The increasing availability of systems capable of
detailed IE for protein modifications, their high per-
formance also for multiple modifications types, and
demonstrations of the scalability of the technology
to the full scale of the literature (Bjo?rne et al, 2010)
are highly encouraging for automatic extraction of
protein modifications. However, previous efforts
have been restricted by the relatively narrow scope
of targeted modification types. In the present study,
we seek to address the task in full by identifying
all modifications of substantial biological signifi-
cance and creating an annotated resource with effec-
tively complete type-level coverage. We addition-
ally present preliminary extraction results to assess
the difficulty of exhaustive modification extraction.
2 Event representation
To be able to benefit from the substantial number of
existing resources and systems for event extraction,
we apply the event representation of the BioNLP
Shared Task (ST) for annotating protein modifica-
tions. Specifically, we directly extend the approach
of the BioNLP ST 2011 EPI task (Ohta et al, 2011).
In brief, in the applied representation, each event
is marked as being expressed by a specific span of
text (the event trigger) and assigned a type from a
fixed ontology defining event types. Events can take
a conceptually open-ended number of participants,
each of which is similarly bound to a specific tex-
tual expression and marked as participating in the
event in a specific role. In this work, we apply three
roles: Theme identifies the entity or event that is af-
fected by the event (e.g. the protein that is modified),
Cause its cause, and Site specifies a specific part on
the Theme participant that is affected, i.e. the mod-
ification site or region. Further, events are primary
objects of annotation and can thus in turn be par-
ticipants in other events as well as being marked as
e.g. explicitly negated (?is not phosphorylated?) or
stated speculatively (?may be phosphorylated?). An
event annotation example is shown in Figure 1.
Figure 1: Illustration of the event representation. An
event of type ADP-RIBOSYLATION (expressed through
the text ?ADP-ribosylation?) with a PROTEIN (?P2X7?)
participant in the Theme role is in turn the Theme of a
CATALYSIS event with another PROTEIN (?ART2?) as its
Cause.
3 Protein Modifications
We next present our selection of protein modifica-
tion types relevant to event annotation and an ex-
tended analysis of their relative prominence.
3.1 Protein Modifications in Ontologies
For mapping and structuring the space of protein
modification concepts, we primarily build on the
community-standard Gene Ontology (GO) (Ash-
burner et al, 2000). GO has substantial represen-
tation of protein modifications: the sub-ontology
rooted at protein modification process
(GO:0006464) in the GO biological process ontol-
ogy contains 805 terms1 (including both leaf and in-
ternal nodes). This set of terms is the starting point
for our selection of modifications types to target.
First, many specific GO terms can be excluded
due to the different approach to semantic representa-
tion taken in event annotation: while GO terms rep-
resent detailed concepts without explicit structure
(see e.g. (Ogren et al, 2004)), the event representa-
tion is structured, allowing more general terms to be
applied while capturing the same information. For
example, many GO modification terms have child
nodes that identify the target (substrate) of modifica-
tion, e.g. protein phosphorylation has the
child actin phosphorylation. In the event
representation, the target of modification is cap-
tured through the Theme argument. Similarly, GO
terms may identify the site or region of modifica-
tion, which becomes a Site argument in the event
representation (see Figure 2). To avoid redundancy,
we exclude GO terms that differ from a more gen-
eral included term only in specifying a substrate or
modification site. We similarly exclude terms that
specify a catalyst or refer to regulation of modifi-
1GO structure and statistics from data retrieved Dec. 2010.
115
Figure 2: Comparison of hypothetical text-bound GO an-
notation with specific terms (top) and event annotation
with general GO terms (bottom).
cation, as these are captured using separate events
in the applied representation, as illustrated in Fig-
ure 1. For an analogous reason, we do not separately
include type-level distinctions for ?magnitude?
variants of terms (e.g. monoubiquitination,
polyubiquitination) as these can be system-
atically modeled as aspects that can mark any event
(cf. the low/neutral/high Manner of Nawaz et al
(2010)).
Second, a number of the GO terms identify reac-
tions that are in scope of previously defined (non-
modification) event types in existing resources. To
avoid introducing redundant or conflicting annota-
tion with e.g. the GENIA Event corpus (Kim et al,
2008) or BioNLP ST resources, we excluded terms
that involve predominantly (or exclusively) non-
covalent binding (included in the scope of the event
type BINDING) and terms involving the removal of
or binding between the amino acids of a protein, in-
cluding protein maturation by peptide bond cleav-
age (annotated ? arguably somewhat inaccurately ?
as PROTEIN CATABOLISM in GENIA/BioNLP ST
data). By contrast, we do differentiate between re-
actions involving the addition of chemical groups or
small proteins and those involving their removal, in-
cluding e.g. PALMITOYLATION and DEPALMITOY-
LATION as distinct types. To preserve the ontology
structure, we further include also internal nodes ap-
pearing in GO for the purposes of structuring the
ontology (e.g. small protein conjugation
or removal), although we only apply more spe-
cific leaf nodes in event annotation.
This selection, aiming to identify the maximal
subset of the protein modification branch of the GO
ontology relevant to event annotation, resulted in
the inclusion of 74 terms, approximately 9% of the
branch total. Table 1 shows the relevant part of
the GO protein modification subontology
term structure, showing each term only once2 and
excluding very rare terms for space. (A detailed de-
scription of other information in the table is given in
the following sections.)
In addition to GO, we consider protein modifica-
tions in the MeSH ontology,3 used to index PubMed
citations with concepts relevant to them. Further, for
resolving cases not appearing in GO, we refer to the
Uniprot controlled vocabulary of posttranslational
modifications4 and the Proteomics Standards Ini-
tiative Protein Modification Ontology5 (PSI-MOD)
(Montecchi-Palazzi et al, 2008).
3.2 Protein Modifications in Databases
A substantial number of databases tracking pro-
tein modifications from a variety of perspectives ex-
ist, and new ones are introduced regularly. The
databases range from the specific (e.g. (Gupta et al,
1999; Diella et al, 2004; Zhang et al, 2010)) to the
broad in scope (Lee et al, 2005; Li et al, 2009). In-
formation on protein modifications is also found in
general protein knowledge resources such as Swiss-
Prot (Boeckmann et al, 2003) and PIR (Wu et al,
2003). The relative number of entries relevant to
each protein modification in such resources is one
possible proxy for the biological significance of the
various modifications. We apply two such estimates
in this work.
One of the primary applications of GO is the use
of the ontology terms to annotate gene products,
identifying their functions. These annotations, pro-
vided by a variety of groups in different efforts (e.g.
(Camon et al, 2004)), are readily available in GO
and used in various GO tools as a reflection of the
prominence of each of the ontology concepts. As
GO is a community standard with wide participa-
tion and a primary source in this work, we give these
annotation numbers priority in introducing an addi-
tional filter: we exclude from detailed analysis any
term that has no gene product association annota-
tions, taking this as an indication that the modifica-
2GO allows multiple inheritance, and e.g. protein
palmitoylation occurs under both protein
lipidation and protein acylation reflecting
the biological definition.
3http://www.nlm.nih.gov/mesh/meshhome.
html
4http://www.uniprot.org/docs/ptmlist
5http://www.psidev.info/MOD
116
G
PA
Sy
sP
TM
Pu
bM
ed
G
EN
IA
O
ht
a?
10
EP
I
Th
is
st
ud
y
Term GO ID
phosphorylation GO:0006468 8246 24705 93584 546 3 130 85
small protein conj./removal GO:0070647
small protein conjugation GO:0032446
ubiquitination GO:0016567 1724 439 4842 6 - 340 52
sumoylation GO:0016925 121 260 886 - - - 101
neddylation GO:0045116 66 2 100 - - - 52
ufmylation GO:0071569 33 - 1 - - - -
urmylation GO:0032447 16 - 7 - - - -
pupylation GO:0070490 11 - 15 - - - -
small protein removal GO:0070646
deubiquitination GO:0016579 360 - 206 0 - 17 2
deneddylation GO:0000338 45 - 39 - - - 8
desumoylation GO:0016926 20 - 45 - - - 3
dephosphorylation GO:0006470 1479 121 8339 28 - 3 1
glycosylation GO:0006486 1145 2982 12619 - 122 347 62
acylation GO:0043543 1 - 1728 - - - 71
acetylation GO:0006473 522 2000 4423 7 90 337 17
palmitoylation GO:0018345 49 198 1009 - - - 187
myristoylation GO:0018377 27 150 895 - - - 34
octanoylation GO:0018190 4 - 11 - - - -
palmitoleylation GO:0045234 3 - 0 - - - -
alkylation GO:0008213 0
methylation GO:0006479 552 499 9749 - 90 374 18
lipidation GO:0006497 34 51 258 - - - 16
prenylation GO:0018342 64 111 822 - - - 71
farnesylation GO:0018343 19 - 118 - - - 48
geranylgeranylation GO:0018344 26 - 79 - - - 30
deacylation GO:0035601 1 - 331 - - - 1
deacetylation GO:0006476 320 6 1056 1 - 50 4
depalmitoylation GO:0002084 9 - 81 - - - 9
ADP-ribosylation GO:0006471 261 9 3113 - - - 52
cofactor linkage GO:0018065
lipoylation GO:0009249 53 - 49 - - - 14
FAD linkage GO:0018293 46 - 6 - - - -
pyridoxal-5-phosphate linkage GO:0018352 6 - 0 - - - -
dealkylation GO:0008214 0
demethylation GO:0006482 116 - 1465 - - 13 1
deglycosylation GO:0006517 22 1 1204 - - 27 0
ISG15-protein conjugation GO:0032020 20 - 3 - - - -
arginylation GO:0016598 20 - 46 - - - -
hydroxylation GO:0018126 20 226 2948 - 103 139 3
sulfation GO:0006477 18 132 960 - - - 37
carboxylation GO:0018214 17 7 595 - - - 34
nucleotidylation GO:0018175 0
adenylylation GO:0018117 16 - 116 - - - -
uridylylation GO:0018177 1 - 105 - - - -
polyglycylation GO:0018094 17 - 14 - - - -
de-ADP-ribosylation GO:0051725 16 - 7 - - - 5
nitrosylation GO:0017014 14 - 670 - - - -
glutathionylation GO:0010731 11 - 279 - - - -
biotinylation GO:0009305 8 - 1247 - - - 4
deglutathionylation GO:0080058 3 - 42 - - - -
delipidation GO:0051697 3 - 303 - - - -
oxidation GO:0018158 3 475 23413 - - - 21
phosphopantetheinylation GO:0018215 3 - 26 - - - -
tyrosinylation GO:0018322 2 - 2 - - - -
deamination GO:0018277 1 - 840 - - - -
esterification GO:0018350 1 - 1180 - - - -
glucuronidation GO:0018411 1 - 705 - - - -
polyamination GO:0018184 1 - 13 - - - -
Table 1: Protein modifications and protein modification resources. GO terms shown abbreviated, mostly by removing
?protein? (e.g. ?acylation? instead of ?protein acylation?). Terms with 0 GPA not shown except when required for
structure. Columns: GPA: number of Gene Product Associations for each term in GO (not including counts of more
specific child nodes), SysPTM: number of SysPTM modification entries (excluding sites), PubMed: PubMed query
matches (see Section 3.3), GENIA: GENIA corpus (Kim et al, 2008), Ohta?10: corpus introduced in Ohta et al
(2010), EPI: BioNLP ST?11 EPI task corpus (Ohta et al, 2011) (excluding test set).
117
tion is not presently established as having high bio-
logical significance.6
In addition to the GO associations, we include
an estimate based on dedicated protein modification
databases. We chose to use the integrated SysPTM
resource (Li et al, 2009), which incorporates data
from five databases, four webservers, and manual
extraction from the literature. In its initial release,
SysPTM included information on ?nearly 50 modifi-
cation types? on over 30,000 proteins. The columns
labeled GPA and SysPTM in Table 1 show the num-
ber of gene product associations for each selected
type in GO and entries per type in SysPTM, respec-
tively.
3.3 Protein Modifications in domain literature
As a final estimate of the relative prominence of the
various protein modification types, we estimated the
relative frequency with which they are discussed in
the literature through simple PubMed search, query-
ing the Entrez system for each modification in its
basic nominalized form (e.g. phosphorylation) in a
protein-related article. Specifically, for each modifi-
cation string MOD we searched Entrez for
?MOD?[TIAB] AND ?protein?[TIAB]
The modifier [TIAB] specifies to search the title and
abstract. The literal string ?protein? is included to
improve the estimate by removing references that
involve the modification of non-proteins or related
concepts that happen to share the term.7 While this
query is far from a perfect estimate of the actual
number of protein modifications, we expect it to be
a useful as a rough indicator of their relative fre-
quencies and more straightforward to assess than
more involved statistical analyses (e.g. (Pyysalo et
al., 2010)). The results for these queries are given in
the PubMed column of Table 1.
6We are also aware that GO coverage of protein modifica-
tions is not perfect: for example, citrullination, eliminylation,
sialylation, as well as a number of reverse reactions for addi-
tion reactions in the ontology (e.g. demyristoylation) are not
included at the time of this writing. As for terms with no gene
product associations, we accept these omissions as indicating
that these modifications are not biologically prominent.
7For example, search for only dehydration ? a modification
with zero GPA in GO ? matches nearly 10 times as many doc-
uments as search including protein, implying that most of the
hits for the former query likely do not concern protein modi-
fication by dehydration. By contrast, the majority of hits for
phosphorylation match also phosphorylation AND protein.
3.4 Protein Modifications in Event Resources
The rightmost four columns of Table 1 present the
number of annotations for each modification type
in previously introduced event-annotated resources
following the BioNLP ST representation as well as
those annotated in the present study. While modi-
fication annotations are found also in other corpora
(e.g. (Wu et al, 2003; Pyysalo et al, 2007)), we
only include here resources readily compatible with
the BioNLP ST representation.
Separating for the moment from consideration the
question of what level of practical extraction per-
formance can be supported by these event annota-
tions, we can now provide an estimate of the up-
per bound on the coverage of relevant modifica-
tion statements for each of the three proxies (GO
GPA, SysPTM DB entries, PubMed query hits) sim-
ply by dividing the sum of instances of modifica-
tions for which annotations exist by the total. Thus,
for example, there are 8246 GPA annotations for
Phosphorylation and a total of 15597 GPA an-
notations, so the BioNLP ST?09 data (containing
only PHOSPHORYLATION events) could by the GPA
estimate cover 8246/15597, or approximately 53%
of individual modifications.8
For the total coverage of the set of types for which
event annotation is available given the corpus in-
troduced in this study, the coverage estimates are:
GO GPA: 98.2%, SysPTM 99.6%, PubMed 97.5%.
Thus, we estimate that correct extraction of the in-
cluded types would, depending on whether one takes
a gene association, database entry, or literature men-
tion point of view, cover between 97.5% to 99.6%
of protein modification instances ? a level of cov-
erage we suggest is effectively exhaustive for most
practical purposes. We next briefly describe our an-
notation effort before discarding the assumption that
correct extraction is possible and measuring actual
extraction performance.
4 Annotation
This section presents the entity and event annotation
approach, document selection, and the statistics of
the created annotation.
8The remarkably high coverage for a single type reflects the
Zipfian distribution of the modification types; see e.g. Ohta et
al. (2010).
118
4.1 Entity and Event Annotation
To maximize compatibility with existing event-
annotated resources, we chose to follow the gen-
eral representation and annotation guidelines ap-
plied in the annotation of GENIA/BioNLP ST re-
sources, specifically the BioNLP ST 2011 EPI task
corpus. Correspondingly, we followed the GE-
NIA gene/gene product (Ohta et al, 2009) annota-
tion guidelines for marking protein mentions, ex-
tended the GENIA event corpus guidelines (Kim et
al., 2008) for the annotation of protein modification
events, and marked CATALYSIS events following the
EPI task representation. For compatibility, we also
marked event negation and speculation as in these
resources. We followed the GO definitions for in-
dividual modification types, and in the rare cases
where a modification discussed in text had no ex-
isting GO definition, we extrapolated from the way
in which protein modifications are generally defined
in GO, consulting other domain ontologies and re-
sources (Section 3.1) as necessary.
4.2 Document Selection
As the distribution of protein modifications in
PubMed is extremely skewed, random sampling
would recover almost solely instances of major
types such as phosphorylation. As we are inter-
ested also in the extraction of very rare modifica-
tions, we applied a document selection strategy tar-
geted at individual modification types. We applied
one of two primary strategies depending on whether
each targeted modification type had a correspond-
ing MeSH term or not. If a MeSH term specific
to the modification exists, we queried PubMed for
the MeSH term, thus avoiding searches for spe-
cific forms of expression that might bias the search.
In cases where no specific MeSH term existed,
we searched the text of documents marked with
the generic MeSH term protein processing,
post-translational for mentions of likely
forms of expression for the modification.9 Fi-
nally, in a few isolated instances we applied cus-
tom text-based PubMed searches with broader cov-
9Specifically, we applied a regular expression incorporating
the basic form of modification expression and allowing variance
through relevant affixes and inflections derived from an initial
set of annotations for documents for which MeSH terms were
defined.
Item Count
Abstract 360
Word 76806
Protein 4698
Event type 37
Event instance 1142
Table 2: Annotation statistics.
erage. Then, as many of the modifications are not
limited to protein substrates, to select documents re-
lating specifically to protein modification we pro-
ceeded to tagged a large random sample of selected
documents with the BANNER named entity tagger
(Leaman and Gonzalez, 2008) trained on the GENE-
TAG corpus (Tanabe et al, 2005) and removed doc-
uments with fewer than five automatically tagged
gene/protein-related entities. The remaining docu-
ments were then randomly sampled for annotation.10
4.3 Corpus Statistics
We initially aimed to annotate balanced numbers of
modification types in order of their estimated promi-
nence, with particular focus on previously untar-
geted reaction types involving the addition of chem-
ical groups or small proteins. However, it became
apparent in the annotation process that the extreme
rarity of some of the modifications as well as the
tendency for more frequent modifications to be dis-
cussed in texts mentioning rare ones made this im-
possible. Thus, while preserving the goal of es-
tablishing broadly balanced numbers of major new
modifications, we allowed the number of rare reac-
tions to remain modest.
Table 2 summarizes the statistics of the final cor-
pus, and the rightmost column of Table 1 shows
per-type counts. We note that as reactions involv-
ing the removal of chemical groups or small pro-
teins were not separately targeted, only few events
of such types were annotated. We did not sepa-
rately measure inter-annotator agreement for this ef-
fort, but note that this work is an extension of the
EPI corpus annotation, for which comparison of in-
dependently created event annotations indicated an
F-score of 82% for the full task and 89% for the core
targets (see Section 5.1) (Ohta et al, 2011).
10This strategy, including MeSH-based search, was applied
also in the BioNLP Shared Task 2011 EPI task document selec-
tion.
119
5 Experiments
To assess actual extraction performance, we per-
formed experiments using a state-of-the art event ex-
traction system.
5.1 Experimental Setup
We first split the corpus into a training/development
portion and a held out set for testing, placing half of
the abstracts into each set. The split was stratified
by event type to assure that relatively even numbers
of each event type were present in both sets. All
development was performed using cross-validation
on the visible portion of the data, and a single final
experiment was performed on the test dataset.
To assure that our results are comparable with
those published in recent event extraction stud-
ies, we adopted the standard evaluation crite-
ria of the BioNLP Shared Task. The evalua-
tion is event instance-based and uses the standard
precision/recall/F1-score metrics. We modified the
shared task evaluation software to support the newly
defined event types and ran experiments with the
standard approximate span matching and partial re-
cursive matching criteria (see (Kim et al, 2009)).
We further follow the EPI task evaluation in re-
porting results separately for the extraction of only
Theme and Cause arguments (core task) and for the
full argument set.
5.2 Event extraction method
We applied the EventMine event extraction system
(Miwa et al, 2010a; Miwa et al, 2010b), an SVM-
based pipeline system using an architecture similar
to that of the best-performing system in the BioNLP
ST?09 (Bjo?rne et al, 2009); we refer to the studies
of Miwa et al for detailed description of the base
system. For analysing sentence structure, we applied
the mogura 2.4.1 (Matsuzaki and Miyao, 2007) and
GDep beta2 (Sagae and Tsujii, 2007) parsers.
For the present study, we modified the base Event-
Mine system as follows. First, to improve efficiency
and generalizability, instead of using all words as
trigger candidates as in the base system, we filtered
candidates using a dictionary extracted from train-
ing data and expanded by using the UMLS specialist
lexicon (Bodenreider, 2004) and the ?hypernyms?
and ?similar to? relations in WordNet (Fellbaum,
1998). Second, to allow generalization across ar-
gument types, we added support for solving a single
classification problem for event argument detection
instead of solving multiple classification problems
separated by argument types. Finally, to facilitate
the use of other event resources for extraction, we
added functionality to incorporate models trained by
other corpora as reference models, using predictions
from these models as features in classification.
5.3 Experimental results
We first performed a set of experiments to determine
whether models can beneficially generalize across
different modification event types. The EventMine
pipeline has separate classification stages for event
trigger detection, event-argument detection, and the
extraction of complete event structures. Each of
these stages involves a separate set of features and
output labels, some of which derive directly from
the involved event types: for example, in deter-
mining whether a specific entity is the Theme of
an event triggered by the string ?phosphorylation?,
the system by default uses the predicted event type
(PHOSPHORYLATION) among its features. It is pos-
sible to force the model to generalize across event
types by replacing specific types with placehold-
ers, for example replacing PHOSPHORYLATION,
METHYLATION, etc. with MODIFICATION.
In preliminary experiments on the development
set, we experimented with a number of such gener-
alizations. Results indicated that while some gen-
eralization was essential for achieving good ex-
traction performance, most implementation variants
produced broadly comparable results. We chose the
following generalizations for the final test: in the
trigger detection model, no generalization was per-
formed (allowing specific types to be extracted), for
argument detection, all instances of event types were
replaced with a generic type (EVENT), and for event
structure prediction, all instances of specific modi-
fication event types (but not CATALYSIS) were re-
placed with a generic type (MODIFICATION). Re-
sults comparing the initial, ungeneralized model to
the generalized one are shown in the top two rows
of Table 3. The results indicate that generalization is
clearly beneficial: attempting to learn each of the
event types in isolation leaves F-score results ap-
proximately 4-5% points lower than when general-
120
Core Full
Initial 39.40 / 46.36 / 42.60 31.39 / 38.88 / 34.74
Generalized 39.02 / 61.18 / 47.65 31.07 / 51.89 / 38.87
+Model 41.28 / 61.28 / 49.33 33.66 / 53.06 / 41.19
+Ann 38.46 / 66.99 / 48.87 32.36 / 59.17 / 41.84
+Model +Ann 41.84 / 66.17 / 51.26 33.98 / 56.00 / 42.30
Test data 45.69 / 62.35 / 52.74 38.03 / 54.57 / 44.82
Table 3: Experimental results.
izing across types. A learning curve for the gen-
eralized model is shown in Figure 3. While there
is some indication of decreasing slope toward use
of the full dataset, the curve suggests performance
could be further improved through additional anno-
tation efforts.
In a second set of experiments, we investigated
the compatibility of the newly introduced annota-
tions with existing event resources by incorporat-
ing their annotations either directly as training data
(+Ann) or indirectly through features from predic-
tions from a model trained on existing resources
(+Model), as well as their combination. We per-
formed experiments with the BioNLP Shared Task
2011 EPI task corpus11 and the generalized setting.
The results of these experiments are given in the
middle rows of Table 3. We find substantial bene-
fit from either form of existing resource integration
alone, and, interestingly, an indication that the ben-
efits of the two approaches can be combined. This
result indicates that the newly introduced corpus is
compatible with the EPI corpus, a major previously
introduced resource for protein modification event
extraction. Evaluation on the test data (bottom row
of Table 3) confirmed that development data results
were not overfit and generalized well to previously
unseen data.
6 Discussion and Conclusions
We have presented an effort to directly address the
challenges involved in the exhaustive extraction of
protein modifications in text. We analysed the Gene
Ontology protein modification process
subontology from the perspective of event extraction
for information extraction, arguing that due largely
to the structured nature of the event representation,
11When combining EPI annotations directly as additional
training abstracts, we filtered out abstracts including possible
?missing? annotations for modification types not annotated in
EPI data using a simple regular expression.
Figure 3: Learning curve.
74 of the 805 ontology terms suffice to capture the
general modification types included. Through an
analysis of the relative prominence of protein modi-
fications in ontology annotations, domain databases,
and literature, we then filtered and prioritized these
types, estimating that correct extraction of the most
prominent half of these types would give 97.5%-
99.6% coverage of protein modifications, a level that
is effectively exhaustive for practical purposes.
To support modification event extraction and to
estimate actual extraction performance, we then
proceeded to manually annotate a corpus of 360
PubMed abstracts selected for relevance to the se-
lected modification types. The resulting corpus an-
notation marks over 4500 proteins and over 1000 in-
stances of modification events and more than triples
the number of specific protein modification types for
which text-bound event annotations are available.
Experiments using a state-of-the-art event extraction
system showed that a machine learning method can
beneficially generalize features across different pro-
tein modification event types and that incorporation
of BioNLP Shared Task EPI corpus annotations can
improve performance, demonstrating the compati-
bility of the created resource with existing event cor-
pora. Using the best settings on the test data, we
found that the core extraction task can be performed
at 53% F-score.
The corpus created in this study is freely available
for use in research from http://www-tsujii.
is.s.u-tokyo.ac.jp/GENIA.
Acknowledgments
We would like to thank Yo Shidahara and Yoshihiro
Okuda of NalaPro Technologies for their efforts in
creating the corpus annotation. This work was sup-
ported by Grant-in-Aid for Specially Promoted Re-
search (MEXT, Japan).
121
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
M Ashburner, CA Ball, JA Blake, D Botstein, H Butler,
JM Cherry, AP Davis, K Dolinski, SS Dwight, JT Ep-
pig, MA Harris, DP Hill, L Issel-Tarver, A Kasarskis,
S Lewis, JC Matese, JE Richardson, M Ringwald,
GM Rubin, and G Sherlock. 2000. Gene ontology:
tool for the unification of biology. Nature genetics,
25:25?29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing biomedical event extraction. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In Proceedings of BioNLP?09 Shared
Task, pages 10?18.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-
jii, and Tapio Salakoski. 2010. Scaling up biomed-
ical event extraction to the entire pubmed. In Pro-
ceedings of the 2010 Workshop on Biomedical Natural
Language Processing, pages 28?36.
Olivier Bodenreider. 2004. The Unified Medical Lan-
guage System (UMLS): integrating biomedical ter-
minology. Nucleic Acids Research, 32(Database
issue):D267?70.
B. Boeckmann, A. Bairoch, R. Apweiler, M.C. Blat-
ter, A. Estreicher, E. Gasteiger, M.J. Martin, K. Mi-
choud, C. O?Donovan, I. Phan, et al 2003. The
SWISS-PROT protein knowledgebase and its supple-
ment TrEMBL in 2003. Nucleic acids research,
31(1):365.
D.F. Brennan and D. Barford. 2009. Eliminylation:
a post-translational modification catalyzed by phos-
phothreonine lyases. Trends in biochemical sciences,
34(3):108?114.
Ekaterina Buyko, Erik Faessler, Joachim Wermter, and
Udo Hahn. 2009. Event extraction from trimmed de-
pendency graphs. In Proceedings of the BioNLP?09
Shared Task, pages 19?27, Boulder, Colorado, June.
Association for Computational Linguistics.
Evelyn Camon, Michele Magrane, Daniel Barrell, Vi-
vian Lee, Emily Dimmer, John Maslen, David Binns,
Nicola Harte, Rodrigo Lopez, and Rolf Apweiler.
2004. The Gene Ontology Annotation (GOA)
Database: sharing knowledge in Uniprot with Gene
Ontology. Nucl. Acids Res., 32(suppl 1):D262?266.
Francesca Diella, Scott Cameron, Christine Gemund,
Rune Linding, Allegra Via, Bernhard Kuster, Thomas
Sicheritz-Ponten, Nikolaj Blom, and Toby Gibson.
2004. Phospho.elm: A database of experimentally
verified phosphorylation sites in eukaryotic proteins.
BMC Bioinformatics, 5(1):79.
C. Fellbaum. 1998. Wordnet: an electronic lexical
database. In International Conference on Computa-
tional Linguistics.
Carol Friedman, Pauline Kra, Hong Yu, Michael
Krauthammer, and Andrey Rzhetsky. 2001. GE-
NIES: A natural-language processing system for the
extraction of molecular pathways from journal articles.
Bioinformatics, 17(Suppl. 1):S74?S82.
Ramneek Gupta, Hanne Birch, Kristoffer Rapacki, Sren
Brunak, and Jan E. Hansen. 1999. O-glycbase version
4.0: a revised database of o-glycosylated proteins. Nu-
cleic Acids Research, 27(1):370?372.
Z. Z. Hu, M. Narayanaswamy, K. E. Ravikumar,
K. Vijay-Shanker, and C. H. Wu. 2005. Literature
mining and database annotation of protein phospho-
rylation using a rule-based system. Bioinformatics,
21(11):2759?2765.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
lterature. BMC Bioinformatics, 9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011. Overview of bionlp
shared task 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: An executable survey of advances in biomedical
named entity recognition. In Proceedings of PSB?08,
pages 652?663.
Tzong-Yi Lee, Hsien-Da Huang, Jui-Hung Hung, Hsi-
Yuan Huang, Yuh-Shyong Yang, and Tzu-Hao Wang.
2005. dbPTM: an information repository of protein
post-translational modification. Nucleic Acids Re-
search, 34(suppl 1):D622?D627.
Hodong Lee, Gwan-Su Yi, and Jong C. Park. 2008.
E3Miner: a text mining tool for ubiquitin-protein lig-
ases. Nucl. Acids Res., 36(suppl.2):W416?422.
Hong Li, Xiaobin Xing, Guohui Ding, Qingrun Li, Chuan
Wang, Lu Xie, Rong Zeng, and Yixue Li. 2009.
Sysptm: A systematic resource for proteomic research
on post-translational modifications. Molecular & Cel-
lular Proteomics, 8(8):1839?1849.
Takuya Matsuzaki and Yusuke Miyao. 2007. Efficient
HPSG parsing with supertagging and CFG-filtering.
In In Proceedings of IJCAI-07, pages 1671?1676.
122
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and
Jun?ichi Tsujii. 2010a. Evaluating dependency rep-
resentations for event extraction. In Proceedings of
Coling?10, pages 779?787.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and Jun?ichi
Tsujii. 2010b. Event extraction with complex event
classification using rich features. Journal of Bioinfor-
matics and Computational Biology (JBCB), 8(1):131?
146.
Luisa Montecchi-Palazzi, Ron Beavis, Pierre-Alain Binz,
Robert Chalkley, John Cottrell, David Creasy, Jim
Shofstahl, Sean Seymour, and John Garavelli. 2008.
The PSI-MOD community standard for representation
of protein modification data. Nature Biotechnology,
26:864?866.
M. Narayanaswamy, K. E. Ravikumar, and K. Vijay-
Shanker. 2005. Beyond the clause: extraction of
phosphorylation information from medline abstracts.
Bioinformatics, 21(suppl.1):i319?327.
R. Nawaz, P. Thompson, J. McNaught, and S. Ananiadou.
2010. Meta-Knowledge Annotation of Bio-Events.
Proceedings of LREC 2010, pages 2498?2507.
P.V. Ogren, K.B. Cohen, G.K. Acquaah-Mensah, J. Eber-
lein, and L. Hunter. 2004. The compositional struc-
ture of Gene Ontology terms. In Pacific Symposium
on Biocomputing, page 214.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009. Incorporating
GENETAG-style annotation to GENIA corpus. In
Proceedings of BioNLP?09, pages 106?107.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, Jin-Dong
Kim, and Jun?ichi Tsujii. 2010. Event extraction
for post-translational modifications. In Proceedings of
BioNLP?10, pages 19?27.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii. 2010.
An analysis of gene/protein associations at pubmed
scale. In Proceedings of the fourth International Sym-
posium for Semantic Mining in Biomedicine (SMBM
2010).
Andrey Rzhetsky, Ivan Iossifov, Tomohiro Koike,
Michael Krauthammer, Pauline Kra, Mitzi Morris,
Hong Yu, Pablo Ariel Duboue?, Wubin Weng, W. John
Wilbur, Vasileios Hatzivassiloglou, and Carol Fried-
man. 2004. GeneWays: A system for extracting, ana-
lyzing, visualizing, and integrating molecular pathway
data. Journal of Biomedical Informatics, 37(1):43?53.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with LR models and parser
ensembles. In Proceedings of EMNLP-CoNLL?07,
pages 1044?1050.
Jasmin Saric, Lars Juhl Jensen, Rossitza Ouzounova, Is-
abel Rojas, and Peer Bork. 2006. Extraction of regu-
latory gene/protein networks from Medline. Bioinfor-
matics, 22(6):645?650.
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne Mat-
ten, and John Wilbur. 2005. Genetag: a tagged cor-
pus for gene/protein named entity recognition. BMC
Bioinformatics, 6(Suppl 1):S3.
Christopher Walsh. 2006. Posttranslational modification
of proteins: expanding nature?s inventory. Roberts &
Company Publishers.
Eric S Witze, William M Old, Katheryn A Resing,
and Natalie G Ahn. 2007. Mapping protein post-
translational modifications with mass spectrometry.
Nature Methods, 4:798?806.
Cathy H. Wu, Lai-Su L. Yeh, Hongzhan Huang, Leslie
Arminski, Jorge Castro-Alvear, Yongxing Chen,
Zhangzhi Hu, Panagiotis Kourtesis, Robert S. Led-
ley, Baris E. Suzek, C.R. Vinayaka, Jian Zhang, and
Winona C. Barker. 2003. The Protein Information
Resource. Nucl. Acids Res., 31(1):345?347.
X. Yuan, ZZ Hu, HT Wu, M. Torii, M. Narayanaswamy,
KE Ravikumar, K. Vijay-Shanker, and CH Wu. 2006.
An online literature mining tool for protein phospho-
rylation. Bioinformatics, 22(13):1668.
Yan Zhang, Jie Lv, Hongbo Liu, Jiang Zhu, Jianzhong Su,
Qiong Wu, Yunfeng Qi, Fang Wang, and Xia Li. 2010.
Hhmd: the human histone modification database. Nu-
cleic Acids Research, 38(suppl 1):D149?D154.
123
Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 136?145,
Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational Linguistics
SimSem: Fast Approximate String Matching in Relation to Semantic
Category Disambiguation
Pontus Stenetorp?? Sampo Pyysalo? and Jun?ichi Tsujii?
? Tsujii Laboratory, Department of Computer Science, The University of Tokyo, Tokyo, Japan
? Aizawa Laboratory, Department of Computer Science, The University of Tokyo, Tokyo, Japan
? Microsoft Research Asia, Beijing, People?s Republic of China
{pontus,smp}@is.s.u-tokyo.ac.jp
jtsujii@microsoft.com
Abstract
In this study we investigate the merits of
fast approximate string matching to address
challenges relating to spelling variants and to
utilise large-scale lexical resources for seman-
tic class disambiguation. We integrate string
matching results into machine learning-based
disambiguation through the use of a novel set
of features that represent the distance of a
given textual span to the closest match in each
of a collection of lexical resources. We col-
lect lexical resources for a multitude of se-
mantic categories from a variety of biomedi-
cal domain sources. The combined resources,
containing more than twenty million lexical
items, are queried using a recently proposed
fast and efficient approximate string match-
ing algorithm that allows us to query large
resources without severely impacting system
performance. We evaluate our results on six
corpora representing a variety of disambigua-
tion tasks. While the integration of approxi-
mate string matching features is shown to sub-
stantially improve performance on one corpus,
results are modest or negative for others. We
suggest possible explanations and future re-
search directions. Our lexical resources and
implementation are made freely available for
research purposes at: http://github.com/ninjin/
simsem
1 Introduction
The use of dictionaries for boosting performance has
become commonplace for Named Entity Recogni-
tion (NER) systems (Torii et al, 2009; Ratinov and
Roth, 2009). In particular, dictionaries can give an
initial improvement when little or no training data
is available. However, no dictionary is perfect, and
all resources lack certain spelling variants and lag
behind current vocabulary usage and thus are un-
able to cover the intended domain in full. Further,
due to varying dictionary curation and corpus anno-
tation guidelines, the definition of what constitutes
a semantic category is highly unlikely to precisely
match for any two specific resources (Wang et al,
2009). Ideally, for applying a lexical resource to an
entity recognition or disambiguation task to serve as
a definition of a semantic category there would be
a precise match between the definitions of the lexi-
cal resource and target domain, but this is seldom or
never the case.
Most previous work studying the use of dictionary
resources in entity mention-related tasks has focused
on single-class NER, in particular this is true for
BioNLP where it has mainly concerned the detec-
tion of proteins. These efforts include Tsuruoka and
Tsujii (2003), utilising dictionaries for protein de-
tection by considering each dictionary entry using a
novel distance measure, and Sasaki et al (2008), ap-
plying dictionaries to restrain the contexts in which
proteins appear in text. In this work, we do not
consider entity mention detection, but instead focus
solely on the related task of disambiguating the se-
mantic category for a given continuous sequence of
characters (a textual span), doing so we side-step the
issue of boundary detection in favour of focusing on
novel aspects of semantic category disambiguation.
Also, we are yet to see a high-performing multi-class
biomedical NER system, this motivates our desire to
include multiple semantic categories.
136
2 Methods
In this section we introduce our approach and the
structure of our system.
2.1 SimSem
Many large-scale language resources are available
for the biomedical domain, including collections
of domain-specific lexical items (Ashburner et al,
2000; Bodenreider, 2004; Rebholz-Schuhmann et
al., 2010). These resources present obvious opportu-
nities for semantic class disambiguation. However,
in order to apply them efficiently, one must be able
to query the resources taking into consideration both
lexical variations in dictionary entries compared to
real-world usage and the speed of look-ups.
We can argue that each resource offers a differ-
ent view of what constitutes a particular semantic
category. While these views will not fully overlap
between resources even for the same semantic cate-
gory, we can expect a certain degree of agreement.
When learning to disambiguate between semantic
categories, a machine learning algorithm could be
expected to learn to identify a specific semantic cat-
egory from the similarity between textual spans an-
notated for the category and entries in a related lex-
ical resource. For example, if we observe the text
?Carbonic anhydrase IV? marked as PROTEIN and
have an entry for ?Carbonic anhydrase 4? in a lexical
resource, a machine learning method can learn to as-
sociate the resource with the PROTEIN category (at
specific similarity thresholds) despite syntactic dif-
ferences.
In this study, we aim to construct such a system
and to demonstrate that it outperforms strict string
matching approaches. We refer to our system as
SimSem, as in ?Similarity? and ?Semantic?.
2.2 SimString
SimString1 is a software library utilising the CP-
Merge algorithm (Okazaki and Tsujii, 2010) to en-
able fast approximate string matching. The software
makes it possible to find matches in a collection with
over ten million entries using cosine similarity and
a similarity threshold of 0.7 in approximately 1 mil-
lisecond with modest modern hardware. This makes
it useful for querying a large collection of strings to
1http://www.chokkan.org/software/simstring/
find entries which may differ from the query string
only superficially and may still be members of the
same semantic category.
As an example, if we construct a SimString
database using an American English wordlist2 and
query it using the cosine measure and a threshold of
0.7. For the query ?reviewer? SimString would re-
turn the following eight entries: review, viewer, pre-
view, reviewer, unreviewed, televiewer, and review-
eress. We can observe that most of the retrieved en-
tries share some semantic similarity with the query.
2.3 Machine Learning
For the machine learning component of our system
we use the L2-regularised logistic regression im-
plementation of the LIBLINEAR3 software library
(Fan et al, 2008). We do not normalise our feature
vectors and optimise our models? penalty parameter
using k-fold cross-validation on the training data. In
order to give a fair representation of the performance
of other systems, we use a rich set of features that are
widely applied for NER (See Table 1).
Our novel SimString features are generated as fol-
lows. We query each SimString database using the
cosine measure with a sliding similarity threshold,
starting at 1.0 and ending at 0.7, lowering the thresh-
old by 0.1 per query. If a query is matched, we gen-
erate a feature unique for that database and thresh-
old, we also generate the same feature for each step
from the current threshold to the cut-off of 0.7 (a
match at e.g. 0.9 similarity also implies matches at
0.8 and 0.7).
The cut-off is motivated by the fact that very
low thresholds introduces a large degree of noise.
For example, for our American English wordlist
the query ?rejection? using threshold 0.1 and the
cosine measure will return 13,455 results, among
them ?questionableness? which only have a single
sequence ?ion? in common.
It is worthwhile to note that during our prelimi-
nary experiments we failed to establish a consistent
benefit from contextual features across our develop-
ment sets. Thus, contextual features are not included
in our feature set and instead our study focuses only
2/usr/share/dict/web2 under FreeBSD 8.1-RELEASE, based
on Webster?s Second International dictionary from 1934
3We used version 1.7 of LIBLINEAR for our experiments
137
Feature Type Input Value(s)
Text Text Flu Flu
Lower-cased Text DNA dna
Prefixes: sizes 3 to 5 Text bull bul, . . .
Suffixes: sizes 3 to 5 Text bull ull, . . .
Stem (Porter, 1993) Text performing perform
Is a pair of digits Bool 42 True
Is four digits Bool 4711 True
Letters and digits Bool C4 True
Digits and hyphens Bool 9-12 True
Digits and slashes Bool 1/2 True
Digits and colons Bool 3,1 True
Digits and dots Bool 3.14 True
Upper-case and dots Bool M.C. True
Initial upper-case Bool Pigeon True
Only upper-case Bool PMID True
Only lower-case Bool pure True
Only digits Bool 131072 True
Only non-alpha-num Bool #*$! True
Contains upper-case Bool gAwn True
Contains lower-case Bool After True
Contains digits Bool B52 True
Contains non-alpha-num Bool B52;s True
Date regular expression4 Bool 1989-01-30 True
Pattern Text 1B-zz 0A-aa
Collapsed Pattern Text 1B-zz 0A-a
Table 1: Basic features used for classification
the features that are generated solely from the tex-
tual span which has been annotated with a semantic
category (span-internal features) and the comparison
of approximate and strict string matching.
3 Resources
This section introduces and discusses the prepro-
cessing and statistics of the lexical and corpus re-
sources used in our experiments.
3.1 Lexical Resources
To generate a multitude of SimString databases cov-
ering a wide array of semantic categories we employ
several freely available lexical resources (Table 2).
The choice of lexical resources was initially made
with the aim to cover commonly annotated domain
semantic categories: the CHEBI and CHEMICAL
subsets of JOCHEM for chemicals, LINNAEUS for
species, Entrez Gene and SHI for proteins. We then
4A simple regular expression matching dates:
?(19|20)\d\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$
from http://www.regular-expressions.info/dates.html
expanded the selection based on error analysis to in-
crease our coverage of a wider array of semantic cat-
egories present in our development data.
We used the GO version from March 2011, ex-
tracting all non-obsolete terms from the ontology
and separating them into the three GO subontolo-
gies: biological process (BP), cellular component
(CC) and molecular function (MF). We then created
an additional three resources by extracting all exact
synonyms for each entry. Lastly, we expanded these
six resources into twelve resources by applying the
GO term variant generation technique described by
Beisswanger et al (2008).
UMLS, a collection of various resources, contain
135 semantic categories (e.g. Body Location or Re-
gion and Inorganic Chemical) which we use to cre-
ate a database for each category.
For Entrez Gene we extracted all entries for the
following types: gene locus, protein name, protein
description, nomenclature symbol and nomenclature
fullname, creating a SimString database for each.
This leaves some parts of Entrez Gene unutilised,
but we deemed these categories to be sufficient for
our experiments.
The Turku Event Corpus is a resource created by
applying an automated event extraction system on
the full release of PubMed from 2009. As a pre-
condition for the event extraction system to operate,
protein name recognition is necessary; for this cor-
pus, NER has been performed by the corpus curators
using the BANNER (Leaman and Gonzalez, 2008)
NER system trained on GENETAG (Tanabe et al,
2005). We created a database (PROT) containing
all protein annotations, extracted all event triggers
(TRIG) and created a database for each of the event
types covered by the event extraction system.
For the AZDC corpus, we extracted each anno-
tated textual span since the corpus covers only a sin-
gle semantic category. Similarly, the LINNAEUS
dictionary was converted into a single database since
it covers the single category ?species?.
Table 3 contains the statistics per dictionary re-
source and the number of SimString databases cre-
ated for each resource. Due to space requirements
we leave out the full details for GO BP, GO CC,
GO MF, UMLS, Entrez Gene and TURKU TRIG,
and instead give the total entries for all the databases
generated from these resources.
138
Name Abbreviation Semantic Categories Publication
Gene Ontology GO Multiple Ashburner et al (2000)
Protein Information Resource PIR Proteins Wu et al (2003)
Unified Medical Language System UMLS Multiple Bodenreider (2004)
Entrez Gene ? Proteins Maglott et al (2005)
Automatically generated dictionary SHI Proteins Shi and Campagne (2005)
Jochem JOCHEM Multiple Hettne et al (2009)
Turku Event Corpus TURKU Proteins and biomolecular events Bjo?rne et al (2010)
Arizona Disease Corpus AZDC Diseases Chowdhury and Lavelli (2010)
LINNAEUS Dictionary LINNAEUS Species Gerner et al (2010)
Webster?s International Dictionary WID Multiple ?
Table 2: Lexical resources gathered for our experiments
Resource Unique Entries Databases
GO BP 67,411 4
GO CC 5,993 4
GO MF 55,595 4
PIR 691,577 1
UMLS 5,902,707 135
Entrez Gene 3,602,757 5
SHI 61,676 1
CHEBI 187,993 1
CHEMICAL 1,527,751 1
TURKU PROT 4,745,825 1
TURKU TRIG 130,139 10
AZDC 1,195 1
LINNAEUS 3,119,005 1
WID 235,802 1
Total: 20, 335, 426 170
Table 3: Statistics per dictionary resource
3.2 Corpora
To evaluate our approach we need a variety of cor-
pora annotated with multiple semantic categories.
For this purpose we selected the six corpora listed
in Table 4.
The majority of our corpora are available in the
common stand-off style format introduced for the
BioNLP 2009 Shared Task (BioNLP?09 ST) (Kim
et al, 2009). The remaining two, NLPBA and
CALBC CII, were converted into the BioNLP?09 ST
format so that we could process all resources in the
same manner for our experimental set-up.
In addition to physical entity annotations, the
GREC, EPI, ID and GENIA corpora incorporate
event trigger annotations (e.g. Gene Regulatory
Event (GRE) for GREC). These trigger expressions
carry with them a specific semantic type (e.g. ?in-
teract? can carry the semantic type BINDING for
GENIA), allowing us to enrich the data sets with
additional semantic categories by including these
types in our dataset as distinct semantic categories.
This gave us the following increase in semantic cat-
egories: GREC one, EPI 15, ID ten, GENIA nine.
The original GREC corpus contains an exception-
ally wide array of semantic categories. While this
is desirable for evaluating the performance of our
approach under different task settings, the sparsity
of the data is a considerable problem; the majority
of categories do not permit stable evaluation as they
have only a handful of annotations each. To alleviate
this problem we used the five ontologies defined in
the GREC annotation guidelines5, collapsing the an-
notations into five semantic super categories to cre-
ate a resource we refer to as Super GREC. This pre-
processing conforms with how the categories were
used when annotating the GREC corpus (Thompson
et al, 2009). This resource contains sufficient anno-
tations for each semantic category to enable evalua-
tion on a category-by-category basis. Also, for the
purpose of our experiments we removed all ?SPAN?
type annotations since they themselves carry no se-
mantic information (cf. GREC annotation guide-
lines).
CALBC CII contains 75,000 documents, which
is more than enough for our experiments. In order
to maintain balance in size between the resources in
our experiments, we sampled a random 5,000 docu-
ments and used these as our CALBC CII dataset.
5http://www.nactem.ac.uk/download.php?target=GREC/
Event annotation guidelines.pdf
139
Name Abbreviation Publication
BioNLP/NLPBA 2004 Shared Task Corpus NLPBA Kim et al (2004)
Gene Regulation Event Corpus GREC Thompson et al (2009)
Collaborative Annotation of a Large Biomedical Corpus CALBC CII Rebholz-Schuhmann et al (2010)
Epigenetics and Post-Translational Modifications EPI Ohta et al (2011)
Infectious Diseases Corpus ID Pyysalo et al (2011)
Genia Event Corpus GENIA Kim et al (2011)
Table 4: Corpora used for evaluation
3.3 Corpus Statistics
In this section we present statistics for each of our
datasets. For resources with a limited number of se-
mantic categories we use pie charts to illustrate their
distribution (Figure 1). For the other corpora we use
tables to illustrate this. Tables for the corpora for
which pie charts are given has been left out due to
space requirements.
The NLPBA corpus (Figure 1a) with 59,601 to-
kens annotated, covers five semantic categories, with
a clear majority of protein annotations. While
NLPBA contains several semantic categories, they
are closely related, which is expected to pose chal-
lenges for disambiguation. This holds in particular
for proteins, DNA and RNA, which commonly share
names.
Our collapsed version of GREC, Super GREC
(see Figure 1b), contains 6,777 annotated tokens and
covers a total of six semantic categories: Regulatory
Event (GRE), nucleic acids, proteins, processes, liv-
ing system and experimental. GREC is an interest-
ing resource in that its classes are relatively distinct
and four of them are evenly distributed.
CALBC CII is balanced among its annotated cat-
egories, as illustrated in Figure 1c. The 6,433 to-
kens annotated are of the types: proteins and genes
(PRGE), species (SPE), disorders (DISO) and chem-
icals and drugs (CHED). We note that we have in-
troduced lexical resources covering each of these
classes (Section 3.1).
For the BioNLP?11 ST resources EPI (Table 5),
GENIA (Figure 1d and contains 27,246 annotated
tokens) and ID (Table 6), we observe a very skewed
distribution due to our decision to include event
types as distinct classes; The dominating class for
all the datasets are proteins. For several of these
categories, learning accurate disambiguation is ex-
Type Ratio Annotations
Acetylation 2.3% 294
Catalysis 1.4% 186
DNA demethylation 0.1% 18
DNA methylation 2.3% 301
Deacetylation 0.3% 43
Deglycosylation 0.2% 26
Dehydroxylation 0.0% 1
Demethylation 0.1% 12
Dephosphorylation 0.0% 3
Deubiquitination 0.1% 13
Entity 6.6% 853
Glycosylation 2.3% 295
Hydroxylation 0.9% 116
Methylation 2.5% 319
Phosphorylation 0.9% 112
Protein 77.7% 10,094
Ubiquitination 2.3% 297
Total: 12,983
Table 5: Semantic categories in EPI
pected to be very challenging if not impossible due
to sparsity: For example, Dehydroxylation in EPI
has a single annotation.
ID is of particular interest since it contains a con-
siderable amount of annotations for more than one
physical entity category, including in addition to
protein also organism and a minor amount of chem-
ical annotations.
4 Experiments
In this section we introduce our experimental set-up
and discuss the outcome of our experiments.
4.1 Experimental Set-up
To ensure that our results are not biased by over-
fitting on a specific set of data, all data sets were
separated into training, development and test sets.
140
(a) NLPBA
(b) Super GREC
(c) CALBC CII
(d) GENIA
Figure 1: Semantic category distributions
NLPBA defines only a training and test set, GREC
and CALBC CII are provided as resources and lack
any given division, and for the BioNLP?11 ST data
the test sets are not distributed. Thus, we combined
all the available data for each dataset and separated
the documents into fixed sets with the following ra-
tios: 1/2 training, 1/4 development and 1/4 test.
Type Ratio Annotations
Binding 1.0% 102
Chemical 6.8% 725
Entity 0.4% 43
Gene expression 3.3% 347
Localization 0.3% 36
Negative regulation 1.6% 165
Organism 25.5% 2,699
Phosphorylation 0.5% 54
Positive regulation 2.5% 270
Process 8.0% 843
Protein 43.1% 4,567
Protein catabolism 0.0% 5
Regulation 1.8% 188
Regulon-operon 1.1% 121
Transcription 0.4% 47
Two-component-system 3.7% 387
Total: 10,599
Table 6: Semantic categories in ID
We use a total of six classifiers for our experi-
ments. First, a naive baseline (Naive): a majority
class voter with a memory based on the exact text
of the textual span. The remaining five are ma-
chine learning classifiers trained using five differ-
ent feature sets: gazetteer features constituting strict
string matching towards our SimString databases
(Gazetteer), SimString features generated from our
SimString databases (SimString), the span internal
features listed in Table 1 (Internal), the span inter-
nal and gazetteer features (Internal-Gazetteer) and
the span internal and SimString features (Internal-
SimString).
We evaluate performance using simple instance-
level accuracy (correct classifications / all classifica-
tions). Results are represented as learning curves for
each data set.
4.2 Results
From our experiments we find that ? not surpris-
ingly ? the performance of the Naive, Gazetteer and
SimString classifiers alone is comparatively weak.
Their performance is illustrated in Figure 2. We can
briefly summarize the results for these methods by
noting that the SimString classifier outperforms the
Gazetteer by a large margin for every dataset.6 From
6Due to space restrictions we do not include further analysis
or charts.
141
Figure 2: SimString, Gazetteer and Naive for ID
Figure 3: Learning curve for NLPBA
here onwards we focus on the performance of the In-
ternal classifier in combination with Gazetteer and
SimString features.
For NLPBA (Figure 3), GENIA (Figure 4) and ID
(Figure 5) our experiments show no clear systematic
benefit from either SimString or Gazetteer features.
For Super GREC (Figure 6) and EPI (Figure 7)
classifiers with Gazetteer and SimString features
consistently outperform the Internal classifier, and
the SimString classifier further shows some benefit
over Gazetteer for EPI.
The only dataset for which we see a clear benefit
from SimString features over Gazetteer and Internal
is for CALBC CII (Figure 8).
5 Discussion and Conclusions
While we expected to see clear benefits from both
using Gazetteers and SimString features, our exper-
Figure 4: Learning curve for GENIA
Figure 5: Learning curve for ID
iments returned negative results for the majority of
the corpora. For NLPBA, GENIA and ID we are
aware that most of the instances are either proteins
or belong to event trigger classes for which we may
not have had adequate lexical resources for disam-
biguation. By contrast, for Super GREC there are
several distinct classes for which we expected lex-
ical resources to have fair coverage for SimString
and Gazetteer features. While an advantage over In-
ternal was observed for Super GREC, SimString fea-
tures showed no benefit over Gazetteer features. The
methods exhibited the expected result on only one of
the six corpora, CALBC CII, where there is a clear
advantage for Gazetteer over Internal and a further
clear advantage for SimString over Gazetteer.
Disappointingly, we did not succeed in establish-
ing a clear improvement for more than one of the six
corpora. Although we have not been successful in
142
Figure 6: Learning curve for Super GREC
Figure 7: Learning curve for EPI
proving our initial hypothesis we argue that our re-
sults calls for further study due to several concerns
raised by the results remaining unanswered. It may
be that our notion of distance to lexical resource en-
tries is too naive. A possible future direction would
be to compare the query string to retrieved results us-
ing a method similar to that of Tsuruoka and Tsujii
(2003). This would enable us to retain the advantage
of fast approximate string matching, thus being able
to utilise larger lexical resources than if we were to
calculate sophisticated alignments for each lexical
entry.
Study of the confusion matrices revealed that
some event categories such as negative regulation,
positive regulation and regulation for ID are com-
monly confused by the classifiers. Adding addi-
tional resources or contextual features may alleviate
these problems.
Figure 8: Learning curve for CALBC CII
To conclude, we have found a limited advantage
but failed to establish a clear, systematic benefit
from approximate string matching for semantic class
disambiguation. However, we have demonstrated
that approximate string matching can be used to gen-
erate novel features for classifiers and allow for the
utilisation of large scale lexical resources in new and
potentially interesting ways. It is our hope that by
making our findings, resources and implementation
available we can help the BioNLP community to
reach a deeper understanding of how best to incor-
porate our proposed features for semantic category
disambiguation and related tasks.
Our system and collection of resources are freely
available for research purposes at http://github.com/
ninjin/simsem
Acknowledgements
The authors would like to thank Dietrich Rebholz-
Schuhmann and the CALBC organisers for allowing
us the use of their data. and Jari Bjo?rne for answer-
ing questions regarding the Turku Event Corpus. We
would also like to thank the anonymous reviewers
and Luke McCrohon for their insightful and exten-
sive feedback, which has considerably helped us to
improve this work. Lastly the first author would
like to thank Makoto Miwa and Jun Hatori for their
timely and helpful advice on machine learning meth-
ods.
This work was supported by the Swedish Royal
Academy of Sciences and by Grant-in-Aid for Spe-
cially Promoted Research (MEXT, Japan).
143
References
M. Ashburner, C.A. Ball, J.A. Blake, D. Botstein, H. But-
ler, J.M. Cherry, A.P. Davis, K. Dolinski, S.S. Dwight,
J.T. Eppig, et al 2000. Gene ontology: tool for the
unification of biology. The Gene Ontology Consor-
tium. Nature genetics, 25(1):25.
E. Beisswanger, M. Poprat, and U. Hahn. 2008. Lexical
Properties of OBO Ontology Class Names and Syn-
onyms. In 3rd International Symposium on Semantic
Mining in Biomedicine.
J. Bjo?rne, F. Ginter, S. Pyysalo, J. Tsujii, and
T. Salakoski. 2010. Scaling up biomedical event ex-
traction to the entire PubMed. In Proceedings of the
2010 Workshop on Biomedical Natural Language Pro-
cessing, pages 28?36. Association for Computational
Linguistics.
O Bodenreider. 2004. The unified medical language sys-
tem (umls): integrating biomedical terminology. Nu-
cleic Acids Research, 32:D267?D270.
M.F.M. Chowdhury and A. Lavelli. 2010. Disease Men-
tion Recognition with Specific Features. ACL 2010,
page 83.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A li-
brary for large linear classification. Journal of Ma-
chine Learning Research, 9:1871?1874.
M. Gerner, G. Nenadic, and C.M. Bergman. 2010.
LINNAEUS: A species name identification system for
biomedical literature. BMC bioinformatics, 11(1):85.
K.M. Hettne, R.H. Stierum, M.J. Schuemie, P.J.M. Hen-
driksen, B.J.A. Schijvenaars, E.M. Mulligen, J. Klein-
jans, and J.A. Kors. 2009. A dictionary to identify
small molecules and drugs in free text. Bioinformat-
ics, 25(22):2983.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier. 2004. Introduction
to the bio-entity recognition task at JNLPBA. In Pro-
ceedings of the International Joint Workshop on Nat-
ural Language Processing in Biomedicine and its Ap-
plications (JNLPBA), pages 70?75.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Yue Wang, Toshihasi Takagi, and Aki-
nori Yonezawa. 2011. Overview of genia event
task in bionlp shared task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
R. Leaman and G. Gonzalez. 2008. BANNER: an exe-
cutable survey of advances in biomedical named entity
recognition. In Pacific Symposium on Biocomputing,
volume 13, pages 652?663. Citeseer.
D. Maglott, J. Ostell, K.D. Pruitt, and T. Tatusova. 2005.
Entrez Gene: gene-centered information at NCBI. Nu-
cleic Acids Research, 33(suppl 1):D54.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
Naoaki Okazaki and Jun?ichi Tsujii. 2010. Simple and
efficient algorithm for approximate dictionary match-
ing. In Proceedings of the 23rd International Con-
ference on Computational Linguistics (Coling 2010),
pages 851?859, Beijing, China, August.
M.F. Porter. 1993. An algorithm for suffix stripping.
Program: electronic library and information systems,
14(3):130?137.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
L. Ratinov and D. Roth. 2009. Design challenges and
misconceptions in named entity recognition. In Pro-
ceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning, pages 147?155.
Association for Computational Linguistics.
D. Rebholz-Schuhmann, A.J.J. Yepes, E.M. Van Mul-
ligen, N. Kang, J. Kors, D. Milward, P. Corbett,
E. Buyko, E. Beisswanger, and U. Hahn. 2010.
CALBC silver standard corpus. Journal of bioinfor-
matics and computational biology, 8(1):163?179.
Y. Sasaki, Y. Tsuruoka, J. McNaught, and S. Ananiadou.
2008. How to make the most of NE dictionaries in
statistical NER. BMC bioinformatics, 9(Suppl 11):S5.
L. Shi and F. Campagne. 2005. Building a protein name
dictionary from full text: a machine learning term ex-
traction approach. BMC bioinformatics, 6(1):88.
L. Tanabe, N. Xie, L. Thom, W. Matten, and W.J.
Wilbur. 2005. GENETAG: a tagged corpus for
gene/protein named entity recognition. BMC bioinfor-
matics, 6(Suppl 1):S3.
P. Thompson, S.A. Iqbal, J. McNaught, and S. Anani-
adou. 2009. Construction of an annotated corpus
to support biomedical information extraction. BMC
bioinformatics, 10(1):349.
144
M. Torii, Z. Hu, C.H. Wu, and H. Liu. 2009. BioTagger-
GM: a gene/protein name recognition system. Jour-
nal of the American Medical Informatics Association,
16(2):247.
Y. Tsuruoka and J. Tsujii. 2003. Boosting precision and
recall of dictionary-based protein name recognition.
In Proceedings of the ACL 2003 workshop on Natural
language processing in biomedicine-Volume 13, pages
41?48. Association for Computational Linguistics.
Yue Wang, Jin-Dong Kim, Rune Saetre, Sampo Pyysalo,
and Jun?ichi Tsujii. 2009. Investigating heteroge-
neous protein annotations toward cross-corpora uti-
lization. BMC Bioinformatics, 10(1):403.
C.H. Wu, L.S.L. Yeh, H. Huang, L. Arminski, J. Castro-
Alvear, Y. Chen, Z. Hu, P. Kourtesis, R.S. Ledley, B.E.
Suzek, et al 2003. The protein information resource.
Nucleic Acids Research, 31(1):345.
145
Proceedings of BioNLP Shared Task 2011 Workshop, pages 1?6,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Overview of BioNLP Shared Task 2011
Jin-Dong Kim
Database Center for Life Science
2-11-16 Yayoi, Bunkyo-ku, Tokyo
jdkim@dbcls.rois.ac.jp
Sampo Pyysalo
University of Tokyo
7-3-1 Hongo, Bunkyo-ku, Tokyo
smp@is.s.u-tokyo.ac.jp
Tomoko Ohta
University of Tokyo
7-3-1 Hongo, Bunkyo-ku, Tokyo
okap@is.s.u-tokyo.ac.jp
Robert Bossy
National Institute for Agricultural Research
78352 Jouy en Josas, Cedex
Robert.Bossy@jouy.inra.fr
Ngan Nguyen
University of Tokyo
7-3-1 Hongo, Bunkyo-ku, Tokyo
nltngan@is.s.u-tokyo.ac.jp
Jun?ichi Tsujii
Microsoft Research Asia
5 Dan Ling Street, Haiian District, Beijing
jtsujii@microsoft.com
Abstract
The BioNLP Shared Task 2011, an informa-
tion extraction task held over 6 months up to
March 2011, met with community-wide par-
ticipation, receiving 46 final submissions from
24 teams. Five main tasks and three support-
ing tasks were arranged, and their results show
advances in the state of the art in fine-grained
biomedical domain information extraction and
demonstrate that extraction methods success-
fully generalize in various aspects.
1 Introduction
The BioNLP Shared Task (BioNLP-ST, hereafter)
series represents a community-wide move toward
fine-grained information extraction (IE), in particu-
lar biomolecular event extraction (Kim et al, 2009;
Ananiadou et al, 2010). The series is complemen-
tary to BioCreative (Hirschman et al, 2007); while
BioCreative emphasizes the short-term applicability
of introduced IE methods for tasks such as database
curation, BioNLP-ST places more emphasis on the
measurability of the state-of-the-art and traceabil-
ity of challenges in extraction through an approach
more closely tied to text.
These goals were pursued in the first event,
BioNLP-ST 2009 (Kim et al, 2009), through high
quality benchmark data provided for system devel-
opment and detailed evaluation performed to iden-
tify remaining problems hindering extraction perfor-
mance. Also, as the complexity of the task was high
and system development time limited, we encour-
aged focus on fine-grained IE by providing gold an-
notation for named entities as well as various sup-
porting resources. BioNLP-ST 2009 attracted wide
attention, with 24 teams submitting final results. The
task setup and data since have served as the basis
for numerous studies (Miwa et al, 2010b; Poon and
Vanderwende, 2010; Vlachos, 2010; Miwa et al,
2010a; Bjo?rne et al, 2010).
As the second event of the series, BioNLP-ST
2011 preserves the general design and goals of the
previous event, but adds a new focus on variabil-
ity to address a limitation of BioNLP-ST 2009: the
benchmark data sets were based on the Genia corpus
(Kim et al, 2008), restricting the community-wide
effort to resources developed by a single group for
a small subdomain of molecular biology. BioNLP-
ST 2011 is organized as a joint effort of several
groups preparing various tasks and resources, in
which variability is pursued in three primary direc-
tions: text types, event types, and subject domains.
Consequently, generalization of fine grained bio-IE
in these directions is emphasized as the main theme
of the second event.
This paper summarizes the entire BioNLP-ST
2011, covering the relationships between tasks and
similar broad issues. Each task is presented in detail
in separate overview papers and extraction systems
in papers by participants.
1
2 Main tasks
BioNLP-ST 2011 includes four main tracks (with
five tasks) representing fine-grained bio-IE.
2.1 Genia task (GE)
The GE task (Kim et al, 2011) preserves the task
definition of BioNLP-ST 2009, arranged based on
the Genia corpus (Kim et al, 2008). The data repre-
sents a focused domain of molecular biology: tran-
scription factors in human blood cells. The purpose
of the GE task is two-fold: to measure the progress
of the community since the last event, and to eval-
uate generalization of the technology to full papers.
For the second purpose, the provided data is com-
posed of two collections: the abstract collection,
identical to the BioNLP-ST 2009 data, and the new
full paper collection. Progress on the task is mea-
sured through the unchanged task definition and the
abstract collection, while generalization to full pa-
pers is measured on the full paper collection. In this
way, the GE task is intended to connect the entire
event to the previous one.
2.2 Epigenetics and post-translational
modification task (EPI)
The EPI task (Ohta et al, 2011) focuses on IE for
protein and DNA modifications, with particular em-
phasis on events of epigenetics interest. While the
basic task setup and entity definitions follow those of
the GE task, EPI extends on the extraction targets by
defining 14 new event types relevant to task topics,
including major protein modification types and their
reverse reactions. For capturing the ways in which
different entities participate in these events, the task
extends the GE argument roles with two new roles
specific to the domain, Sidechain and Contextgene.
The task design and setup are oriented toward the
needs of pathway extraction and curation for domain
databases (Wu et al, 2003; Ongenaert et al, 2008)
and are informed by previous studies on extraction
of the target events (Ohta et al, 2010b; Ohta et al,
2010c).
2.3 Infectious diseases task (ID)
The ID task (Pyysalo et al, 2011a) concerns the ex-
traction of events relevant to biomolecular mecha-
nisms of infectious diseases from full-text publica-
tions. The task follows the basic design of BioNLP-
ST 2009, and the ID entities and extraction targets
are a superset of the GE ones. The task extends
considerably on core entities, adding to PROTEIN
four new entity types, including CHEMICAL and
ORGANISM. The events extend on the GE defini-
tions in allowing arguments of the new entity types
as well as in introducing a new event category for
high-level biological processes. The task was im-
plemented in collaboration with domain experts and
informed by prior studies on domain information ex-
traction requirements (Pyysalo et al, 2010; Anani-
adou et al, 2011), including the support of systems
such as PATRIC (http://patricbrc.org).
2.4 Bacteria track
The bacteria track consists of two tasks, BB and BI.
2.4.1 Bacteria biotope task (BB)
The aim of the BB task (Bossy et al, 2011) is to ex-
tract the habitats of bacteria mentioned in textbook-
level texts written for non-experts. The texts are
Web pages about the state of the art knowledge about
bacterial species. BB targets general relations, Lo-
calization and PartOf , and is challenging in that
texts contain more coreferences than usual, habitat
references are not necessarily named entities, and,
unlike in other BioNLP-ST 2011 tasks, all entities
need to be recognized by participants. BB is the first
task to target phenotypic information and, as habi-
tats are yet to be normalized by the field community,
presents an opportunity for the BioNLP community
to contribute to the standardization effort.
2.4.2 Bacteria interaction task (BI)
The BI task (Jourde et al, 2011) is devoted to the ex-
traction of bacterial molecular interactions and reg-
ulations from publication abstracts. Mainly focused
on gene transcriptional regulation in Bacillus sub-
tilis, the BI corpus is provided to participants with
rich semantic annotation derived from a recently
proposed ontology (Manine et al, 2009) defining
ten entity types such as gene, protein and deriva-
tives as well as DNA sites/motifs. Their interactions
are described through ten relation types. The BI
corpus consists of the sentences of the LLL corpus
(Ne?dellec, 2005), provided with manually checked
linguistic annotations.
2
Task Text Focus #
GE abstracts, full papers domain (HT) 9
EPI abstracts event types 15
ID full papers domain (TCS) 10
BB web pages domain (BB) 2
BI abstracts domain (BS) 10
Table 1: Characteristics of BioNLP-ST 2011 main tasks.
?#?: number of event/relation types targeted. Domains:
HT = human transcription factors in blood cells, TCS
= two-component systems, BB = bacteria biology, BS =
Bacillus subtilis
2.5 Characteristics of main tasks
The main tasks are characterized in Table 1. From
the text type perspective, BioNLP-ST 2011 gener-
alizes from abstracts in 2009 to full papers (GE and
ID) and web pages (BB). It also includes data collec-
tions for a variety of specific subject domains (GE,
ID, BB an BI) and a task (EPI) whose scope is not
defined through a domain but rather event types. In
terms of the target event types, ID targets a superset
of GE events and EPI extends on the representation
for PHOSPHORYLATION events of GE. The two bac-
teria track tasks represent an independent perspec-
tive relatively far from other tasks in terms of their
target information.
3 Supporting tasks
BioNLP-ST 2011 includes three supporting tasks
designed to assist in primary the extraction tasks.
Other supporting resources made available to par-
ticipants are presented in (Stenetorp et al, 2011).
3.1 Protein coreference task (CO)
The CO task (Nguyen et al, 2011) concerns the
recognition of coreferences to protein references. It
is motivated from a finding from BioNLP-ST 2009
result analysis: coreference structures in biomedical
text hinder the extraction results of fine-grained IE
systems. While finding connections between event
triggers and protein references is a major part of
event extraction, it becomes much harder if one is
replaced with a coreferencing expression. The CO
task seeks to address this problem. The data sets for
the task were produced based on MedCO annotation
(Su et al, 2008) and other Genia resources (Tateisi
et al, 2005; Kim et al, 2008).
Event Date Note
Sample Data 31 Aug. 2010
Support. Tasks
Train. Data 27 Sep. 2010 7 weeks for development
Test Data 15 Nov. 2010 4 days for submission
Submission 19 Nov. 2010
Evaluation 22 Nov. 2010
Main Tasks
Train. Data 1 Dec. 2010 3 months for development
Test Data 1 Mar. 2011 9 days for submission
Submission 10 Mar. 2011 extended from 8 Mar.
Evaluation 11 Mar. 2011 extended from 10 Mar.
Table 2: Schedule of BioNLP-ST 2011
3.2 Entity relations task (REL)
The REL task (Pyysalo et al, 2011b) involves the
recognition of two binary part-of relations between
entities: PROTEIN-COMPONENT and SUBUNIT-
COMPLEX. The task is motivated by specific chal-
lenges: the identification of the components of pro-
teins in text is relevant e.g. to the recognition of
Site arguments (cf. GE, EPI and ID tasks), and re-
lations between proteins and their complexes rele-
vant to any task involving them. REL setup is in-
formed by recent semantic relation tasks (Hendrickx
et al, 2010). The task data, consisting of new anno-
tations for GE data, extends a previously introduced
resource (Pyysalo et al, 2009; Ohta et al, 2010a).
3.3 Gene renaming task (REN)
The REN task (Jourde et al, 2011) objective is to ex-
tract renaming pairs of Bacillus subtilis gene/protein
names from PubMed abstracts, motivated by dis-
crepancies between nomenclature databases that in-
terfere with search and complicate normalization.
REN relations partially overlap several concepts:
explicit renaming mentions, synonymy, and renam-
ing deduced from biological proof. While the task
is related to synonymy relation extraction (Yu and
Agichtein, 2003), it has a novel definition of renam-
ing, one name permanently replacing the other.
4 Schedule
Table 2 shows the task schedule, split into two
phases to allow the use of supporting task results in
addressing the main tasks. In recognition of their
higher complexity, a longer development period was
arranged for the main tasks (3 months vs 7 weeks).
3
Team GE EPI ID BB BI CO REL REN
UTurku 1 1 1 1 1 1 1 1
ConcordU 1 1 1 1 1 1
UMass 1 1 1
Stanford 1 1 1
FAUST 1 1 1
MSR-NLP 1 1
CCP-BTMG 1 1
Others 8 0 2 2 0 4 2 1
SUM 15 7 7 3 1 6 4 3
Table 3: Final submissions to BioNLP-ST 2011 tasks.
5 Participation
BioNLP-ST 2011 received 46 submissions from 24
teams (Table 3). While seven teams participated in
multiple tasks, only one team, UTurku, submitted fi-
nal results to all the tasks. The remaining 17 teams
participated in only single tasks. Disappointingly,
only two teams (UTurku, and ConcordU) performed
both supporting and main tasks, and neither used
supporting task analyses for the main tasks.
6 Results
Detailed evaluation results and analyses are pre-
sented in individual task papers, but interesting ob-
servations can be obtained also by comparisons over
the tasks. Table 4 summarizes best results for vari-
ous criteria (Note that the results shown for e.g. GEa,
GEf and GEp may be from different teams).
The community has made a significant improve-
ment in the repeated GE task, with an over 10%
reduction in error from ?09 to GEa. Three teams
achieved better results than M10, the best previously
reported individual result on the ?09 data. This in-
dicates a beneficial role from focused efforts like
BioNLP-ST. The GEf and ID results show that
generalization to full papers is feasible, with very
modest loss in performance compared to abstracts
(GEa). The results for PHOSPHORYLATION events
in GE and EPI are comparable (GEp vs EPIp), with
the small drop for the EPI result, suggesting that
the removal of the GE domain specificity does not
compromise extraction performance. EPIc results
indicate some challenges in generalization to simi-
lar event types, and EPIf suggest substantial further
challenges in additional argument extraction. The
complexity of ID is comparable to GE, also reflected
to their final results, which further indicate success-
Task Evaluation Results
BioNLP-ST 2009 (?09) 46.73 / 58.48 / 51.95
Miwa et al (2010b) (M10) 48.62 / 58.96 / 53.29
LLL 2005 (LLL) 53.00 / 55.60 / 54.30
GE abstracts (GEa) 50.00 / 67.53 / 57.46
GE full texts (GEf) 47.84 / 59.76 / 53.14
GE PHOSPHORYLATION (GEp) 79.26 / 86.99 / 82.95
GE LOCALIZATION (GEl) 37.88 / 77.42 / 50.87
EPI full task (EPIf) 52.69 / 53.98 / 53.33
EPI core task (EPIc) 68.51 / 69.20 / 68.86
EPI PHOSPHORYLATION (EPIp) 86.15 / 74.67 / 80.00
ID full task (IDf) 48.03 / 65.97 / 55.59
ID core task (IDc) 50.62 / 66.06 / 57.32
BB 45.00 / 45.00 / 45.00
BB PartOf (BBp) 32.00 / 83.00 / 46.00
BI 71.00 / 85.00 / 77.00
CO 22.18 / 73.26 / 34.05
REL 50.10 / 68.00 / 57.70
REN 79.60 / 95.90 / 87.00
Table 4: Best results for various (sub)tasks (recall / preci-
sion / f-score (%)). GEl: task 2 without trigger detection.
ful generalization to a new subject domain as well
as to new argument (entity) types. The BB task is
in part comparable to GEl and involves a represen-
tation similar to REL, with lower results likely in
part because BB requires entity recognition. The BI
task is comparable to LLL Challenge, though BI in-
volves more entity and event types. The BI result
is 20 points above the LLL best result, indicating a
substantial progress of the community in five years.
7 Discussion and Conclusions
Meeting with wide participation from the commu-
nity, BioNLP-ST 2011 produced a wealth of valu-
able resources for the advancement of fine-grained
IE in biology and biomedicine, and demonstrated
that event extraction methods can successfully gen-
eralize to new text types, event types, and domains.
However, the goal to observe the capacity of sup-
porting tasks to assist the main tasks was not met.
The entire shared task period was very long, more
than 6 months, and the complexity of the task was
high, which could be an excessive burden for partic-
ipants, limiting the application of novel resources.
There have been ongoing efforts since BioNLP-ST
2009 to develop IE systems based on the task re-
sources, and we hope to see continued efforts also
following BioNLP-ST 2011, especially exploring
the use of supporting task resources for main tasks.
4
References
Sophia Ananiadou, Sampo Pyysalo, Junichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology.
Sophia Ananiadou, Dan Sullivan, William Black, Gina-
Anne Levow, Joseph J. Gillespie, Chunhong Mao,
Sampo Pyysalo, BalaKrishna Kolluru, Junichi Tsujii,
and Bruno Sobral. 2011. Named entity recognition
for bacterial type IV secretion systems. PLoS ONE,
6(3):e14780.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,
and Tapio Salakoski. 2010. Complex event extraction
at PubMed scale. Bioinformatics, 26(12):i382?390.
Robert Bossy, Julien Jourde, Philippe Bessie`res, Marteen
van de Guchte, and Claire Ne?dellec. 2011. BioNLP
Shared Task 2011 - Bacteria Biotope. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav
Nakov, Diarmuid ?O. Se?aghdha, Sebastian Pado?, Marco
Pennacchiotti, Lorenza Romano, and Stan Szpakow-
icz. 2010. Semeval-2010 task 8: Multi-way classi-
fication of semantic relations between pairs of nom-
inals. In Proceedings of the 5th International Work-
shop on Semantic Evaluation, SemEval ?10, pages 33?
38, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Lynette Hirschman, Martin Krallinger, and Alfonso Va-
lencia, editors. 2007. Proceedings of the Second
BioCreative Challenge Evaluation Workshop. CNIO
Centro Nacional de Investigaciones Oncolo?gicas.
Julien Jourde, Alain-Pierre Manine, Philippe Veber,
Kare?n Fort, Robert Bossy, Erick Alphonse, and
Philippe Bessie`res. 2011. BioNLP Shared Task 2011
- Bacteria Gene Interactions and Renaming. In Pro-
ceedings of the BioNLP 2011 Workshop Companion
Volume for Shared Task, Portland, Oregon, June. As-
sociation for Computational Linguistics.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
lterature. BMC Bioinformatics, 9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011. Overview of the Genia Event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
A.P. Manine, E. Alphonse, and Bessie`res P. 2009. Learn-
ing ontological rules to extract multiple relations of
genic interactions from text. International Journal of
Medical Informatics, 78(12):e31?38.
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and
Jun?ichi Tsujii. 2010a. A comparative study of syn-
tactic parsers for event extraction. In Proceedings of
BioNLP?10, pages 37?45.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and Jun?ichi
Tsujii. 2010b. Event extraction with complex event
classification using rich features. Journal of Bioinfor-
matics and Computational Biology (JBCB), 8(1):131?
146, February.
Ne?dellec. 2005. Learning Language in Logic ? Genic
Interaction Extraction Challenge. In Proceedings of
4th Learning Language in Logic Workshop (LLL?05),
pages 31?37.
Ngan Nguyen, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
Overview of the Protein Coreference task in BioNLP
Shared Task 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Tomoko Ohta, Sampo Pyysalo, Jin-Dong Kim, and
Jun?ichi Tsujii. 2010a. A re-evaluation of biomedical
named entity-term relations. Journal of Bioinformat-
ics and Computational Biology (JBCB), 8(5):917?928.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, Jin-Dong
Kim, and Jun?ichi Tsujii. 2010b. Event extraction
for post-translational modifications. In Proceedings of
BioNLP?10, pages 19?27.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and
Jun?ichi Tsujii. 2010c. Event extraction for dna
methylation. In Proceedings of SMBM?10.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
Mate? Ongenaert, Leander Van Neste, Tim De Meyer,
Gerben Menschaert, Sofie Bekaert, and Wim
Van Criekinge. 2008. PubMeth: a cancer methylation
database combining text-mining and expert annota-
tion. Nucleic Acids Research, 36(suppl 1):D842?846.
Hoifung Poon and Lucy Vanderwende. 2010. Joint infer-
ence for knowledge extraction from biomedical litera-
ture. In Proceedings of NAACL-HLT?10, pages 813?
821.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static Relations: a Piece
5
in the Biomedical Information Extraction Puzzle.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9, Boulder, Colorado. Association for Computa-
tional Linguistics.
Sampo Pyysalo, Tomoko Ohta, Han-Cheol Cho, Dan Sul-
livan, Chunhong Mao, Bruno Sobral, Jun?ichi Tsujii,
and Sophia Ananiadou. 2010. Towards event extrac-
tion from full texts on infectious diseases. In Proceed-
ings of BioNLP?10, pages 132?140.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011a.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii.
2011b. Overview of the Entity Relations (REL) sup-
porting task of BioNLP Shared Task 2011. In Pro-
ceedings of the BioNLP 2011 Workshop Companion
Volume for Shared Task, Portland, Oregon, June. As-
sociation for Computational Linguistics.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
Jian Su, Xiaofeng Yang, Huaqing Hong, Yuka Tateisi,
and Jun?ichi Tsujii. 2008. Coreference Resolution in
Biomedical Texts: a Machine Learning Approach. In
Ontologies and Text Mining for Life Sciences?08.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun?ichi Tsujii. 2005. Syntax Annotation for the GE-
NIA corpus. In Proceedings of the IJCNLP 2005,
Companion volume, pages 222?227.
Andreas Vlachos. 2010. Two strong baselines for the
bionlp 2009 event extraction task. In Proceedings of
BioNLP?10, pages 1?9.
Cathy H. Wu, Lai-Su L. Yeh, Hongzhan Huang, Leslie
Arminski, Jorge Castro-Alvear, Yongxing Chen,
Zhangzhi Hu, Panagiotis Kourtesis, Robert S. Led-
ley, Baris E. Suzek, C.R. Vinayaka, Jian Zhang, and
Winona C. Barker. 2003. The Protein Information
Resource. Nucleic Acids Research, 31(1):345?347.
H. Yu and E. Agichtein. 2003. Extracting synony-
mous gene and protein terms from biological litera-
ture. Bioinformatics, 19(suppl 1):i340.
6
Proceedings of BioNLP Shared Task 2011 Workshop, pages 16?25,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Overview of the Epigenetics and Post-translational Modifications (EPI) task
of BioNLP Shared Task 2011
Tomoko Ohta? Sampo Pyysalo? Jun?ichi Tsujii?
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Microsoft Research Asia, Beijing, China
{okap,smp}@is.s.u-tokyo.ac.jp, jtsujii@microsoft.com
Abstract
This paper presents the preparation, resources,
results and analysis of the Epigenetics and
Post-translational Modifications (EPI) task, a
main task of the BioNLP Shared Task 2011.
The task concerns the extraction of detailed
representations of 14 protein and DNA modifi-
cation events, the catalysis of these reactions,
and the identification of instances of negated
or speculatively stated event instances. Seven
teams submitted final results to the EPI task in
the shared task, with the highest-performing
system achieving 53% F-score in the full task
and 69% F-score in the extraction of a simpli-
fied set of core event arguments.
1 Introduction
The Epigenetics and Post-translational Modifica-
tions (EPI) task is a shared task on event extrac-
tion from biomedical domain scientific publications,
first introduced as a main task in the BioNLP Shared
Task 2011 (Kim et al, 2011a).
The EPI task focuses on events relating to epige-
netic change, including DNA methylation and hi-
stone methylation and acetylation (see e.g. (Hol-
liday, 1987; Jaenisch and Bird, 2003)), as well
as other common protein post-translational modi-
fications (PTMs) (Witze et al, 2007). PTMs are
chemical modifications of the amino acid residues
of proteins, and DNA methylation a parallel mod-
ification of the nucleotides on DNA. While these
modifications are chemically simple reactions and
can thus be straightforwardly represented in full de-
tail, they have a crucial role in the regulation of
gene expression and protein function: the modifi-
cations can alter the conformation of DNA or pro-
teins and thus control their ability to associate with
other molecules, making PTMs key steps in protein
biosynthesis for introducing the full range of protein
functions. For instance, protein phosphorylation ?
the attachment of phosphate ? is a common mecha-
nism for activating or inactivating enzymes by alter-
ing the conformation of protein active sites (Stock
et al, 1989; Barford et al, 1998), and protein ubiq-
uitination ? the post-translational attachment of the
small protein ubiquitin ? is the first step of a major
mechanism for the destruction (breakdown) of many
proteins (Glickman and Ciechanover, 2002).
Many of the PTMs targeted in the EPI task in-
volve modification of histone, a core protein that
forms an octameric complex that has a crucial role in
packaging chromosomal DNA. The level of methy-
lation and acetylation of histones controls the tight-
ness of the chromatin structure, and only ?unwound?
chromatin exposes the gene packed around the hi-
stone core to the transcriptional machinery. Since
histone modification is of substantial current inter-
est in epigenetics, we designed aspects of the EPI
task to capture the full detail in which histone mod-
ification events are stated in text. Finally, the DNA
methylation of gene regulatory elements controls the
expression of the gene by altering the affinity with
which DNA-binding proteins (including transcrip-
tion factors) bind, and highly methylated genes are
not transcribed at all (Riggs, 1975; Holliday and
Pugh, 1975). DNA methylation can thus ?switch
off? genes, ?removing? them from the genome in a
way that is reversible through DNA demethylation.
16
Figure 1: Three views of protein methylation. a)
chemical formula b) event representation c) modification
database entry.
The BioNLP?09 Shared Task on Event Extrac-
tion (Kim et al, 2009), the first task in the present
shared task series, involved the extraction of nine
event types including one PTM type, PHOSPHORY-
LATION. The results of the shared task showed this
PTM event to be the single most reliably extracted
event type in the task, with the best-performing
system for the type achieving 91% precision and
76% recall (83% F-score) in its extraction (Buyko
et al, 2009). The results suggest both that the
event representation is well applicable to PTM ex-
traction and that current extraction methods are ca-
pable of reliable PTM extraction. The EPI task
follows up on these opportunities, introducing spe-
cific, strongly biologically motivated extraction tar-
gets that are expected to be both feasible for high-
accuracy event extraction, relevant to the needs of
present-day molecular biology, and closely appli-
cable to biomolecular database curation needs (see
Figure 1) (Ohta et al, 2010a).
2 Task Setting
The EPI task is an event extraction task in the sense
popularized by a number of recent domain resources
and challenges (e.g. (Pyysalo et al, 2007; Kim et al,
2008; Thompson et al, 2009; Kim et al, 2009; Ana-
niadou et al, 2010)). In broad outline, the task fo-
cuses on the extraction of information on statements
regarding change in the state or properties of (physi-
cal) entities, modeled using an event representation.
Figure 2: Illustration of the event representation. An
event of type METHYLATION (expressed through the text
?methylation?) with two participants of the types PRO-
TEIN (?histone H3?) and ENTITY (?Lys9?), participating
in the event in Theme and Site roles, respectively.
In this representation, events are typed n-ary asso-
ciations of participants (entities or other events) in
specific roles. Events are bound to specific expres-
sions in text (the event trigger or text binding) and
are primary objects of annotation, allowing them to
be marked in turn e.g. as negated or as participants
in other events. Figure 2 illustrates these concepts.
In its specific formulation, EPI broadly follows
the definition of the BioNLP?09 shared task on event
extraction. Basic modification events are defined
similarly to the PHOSPHORYLATION event type tar-
geted in the ?09 and the 2011 GE and ID tasks (Kim
et al, 2011b; Pyysalo et al, 2011b), with the full
task extending previously defined arguments with
two additional ones, Sidechain and Contextgene.
2.1 Entities
The EPI task follows the general policy of the
BioNLP Shared Task in isolating the basic task of
named entity recognition from the event extraction
task by providing task participants with manually
annotated gene and gene product entities as a start-
ing point for extraction. The entity types follow the
BioNLP?09 Shared Task scheme, where genes and
their products are simply marked as PROTEIN.1
In addition to the given PROTEIN entities, some
events involve other entities, such as the modifica-
tion Site. These entities are not given and must thus
be identified by systems targeting the full task (see
Section 4). In part to reduce the demands of this
entity recognition component of the task, these ad-
ditional entities are not given specific types but are
generically marked as ENTITY.
1While most of the modifications targeted in the task involve
proteins, this naming is somewhat inaccurate for the Themes of
DNA METHYLATION and DNA DEMETHYLATION events and
for Contextgene arguments, which refer to genes. Despite this
inaccuracy, we chose to follow this naming scheme for consis-
tency with other tasks.
17
Type Core arguments Additional arguments
HYDROXYLATION Theme(PROTEIN) Site(ENTITY)
PHOSPHORYLATION Theme(PROTEIN) Site(ENTITY)
UBIQUITINATION Theme(PROTEIN) Site(ENTITY)
DNA METHYLATION Theme(PROTEIN) Site(ENTITY)
GLYCOSYLATION Theme(PROTEIN) Site(ENTITY), Sidechain(ENTITY)
ACETYLATION Theme(PROTEIN) Site(ENTITY), Contextgene(PROTEIN)
METHYLATION Theme(PROTEIN) Site(ENTITY), Contextgene(PROTEIN)
CATALYSIS Theme(Event), Cause(PROTEIN)
Table 1: Event types and their arguments. The type of entity allowed as argument is specified in parenthesis. For each
event type except CATALYSIS, the reverse reaction (e.g. DEACETYLATION for ACETYLATION) is also defined, with
identical arguments. The total number of event types in the task is thus 15.
2.2 Relations
The EPI task does not define any explicit relation
extraction targets. However, the task annotation in-
volves one relation type, EQUIV. This is a binary,
symmetric, transitive relation between entities that
defines two entities to be equivalent (Hoehndorf et
al., 2010). The relation is used in the gold annota-
tion to mark local aliases such as the full and abbre-
viated forms of a protein name as referring to the
same real-world entity. While the ?09 task only rec-
ognized equivalent PROTEIN entities, EPI extends
on the scope of EQUIV annotations in allowing enti-
ties of any type to be marked equivalent. In evalua-
tion, references to any of a set of equivalent entities
are treated identically.
2.3 Events
While the EPI task entity definition closely follows
that of the previous shared task, the task introduces
considerable novelty in the targeted events, adding a
total of 14 novel event types and two new participant
roles. Table 1 summarizes the targeted event types
and their arguments.
As in the BioNLP?09 shared task, Theme argu-
ments identify the entity that the event is about, such
as the protein that is acetylated in an acetylation
event. A Theme is always mandatory for all EPI task
events. Site arguments identify the modification site
on the Theme entity, such as a specific residue on a
modified protein or a specific region on a methylated
gene. The Sidechain argument, specific to GLYCO-
SYLATION and DEGLYCOSYLATION among the tar-
geted events, identifies the moiety attached or re-
moved in the event (in glycosylation, the sugar).2 Fi-
nally, the Contextgene argument, specific to ACETY-
LATION and METHYLATION events and their re-
verse reactions, identifies the gene whose expression
is controlled by these modifications. This argument
applies specifically for histone protein modification:
the modification of the histones that form the nu-
cleosomes that structure DNA are key to the epige-
netic control of gene expression. The Site, Sidechain
and Contextgene arguments are not mandatory, and
should only be extracted when explicitly stated.
For CATALYSIS events, representing the cataly-
sis of protein or DNA modification by another pro-
tein, both Theme and Cause are mandatory. While
CATALYSIS is a new event type, it is related to
the ?09 POSITIVE REGULATION type by a class-
subclass relation: any CATALYSIS event is a POS-
ITIVE REGULATION event in the ?09 task terms (but
not vice versa).
2.4 Event modifications
In addition to events, the EPI task defines two
event modification extraction targets: NEGATION
and SPECULATION. Both are represented as simple
binary ?flags? that apply to events, marking them as
being explicitly negated (e.g. H2A is not methylated)
or stated in a speculative context (e.g. H2A may be
methylated). Events may be both negated and spec-
ulated.
2Note that while arguments similar to Sidechain could be
defined for other event types also, their extraction would pro-
vide no additional information: the attached molecule is always
acetyl in acetylation, methyl in methylation, etc.
18
3 Data
The primary EPI task data were annotated specifi-
cally for the BioNLP Shared Task 2011 and are not
based on any previously released resource. Before
starting this annotation effort, we performed two
preparatory studies using in part previously released
related datasets: in (Ohta et al, 2010a) we consid-
ered the extraction of four protein post-translational
modifications event types with reference to annota-
tions originally created for the Protein Information
Resource3 (PIR) (Wu et al, 2003), and in (Ohta et
al., 2010b) we studied the annotation and extraction
of DNA methylation events with reference to anno-
tations created for the PubMeth4 (Ongenaert et al,
2008) database. The corpus text selection and anno-
tation scheme were then defined following the un-
derstanding formed in these studies.
3.1 Document selection
The texts for the EPI task corpus were drawn from
PubMed abstracts. In selecting the primary cor-
pus texts, we aimed to gather a representative sam-
ple of all PubMed documents relevant to selected
modification events, avoiding bias toward, for ex-
ample, specific genes/proteins, species, forms of
event expression, or subdomains. We primarily tar-
geted DNA methylation and the ?prominent PTM
types? identified in (Ohta et al, 2010a). We de-
fined the following document selection protocol: for
each of the targeted event types, 1) Select a ran-
dom sample of PubMed abstracts annotated with the
MeSH term corresponding to the target event (e.g.
Acetylation) 2) Automatically tag protein/gene
entities in the selected abstracts, removing ones
where fewer than a specific cutoff are found 3) Per-
form manual filtering removing documents not rele-
vant to the targeted topic (optional).
MeSH is a controlled vocabulary of over 25,000
terms that is used to manually annotate each docu-
ment in PubMed. By performing initial document
retrieval using MeSH terms it is possible to se-
lect relevant documents without bias toward specific
expressions in text. While search for documents
tagged with e.g. the Acetylation MeSH term is
sufficient to select documents relevant to the modi-
3http://pir.georgetown.edu
4http://www.pubmeth.org/
fication, not all such documents necessarily concern
specifically protein modification, necessitating a fil-
tering step. Following preliminary experiments, we
chose to apply the BANNER named entity tagger
(Leaman and Gonzalez, 2008) trained on the GENE-
TAG corpus (Tanabe et al, 2005) and to filter docu-
ments where fewer than five entities were identified.
Finally, for some modification types this protocol se-
lected also a substantial number of non-relevant doc-
uments. In these cases a manual filtering step was
performed prior to full annotation to avoid marking
large numbers of non-relevant abstracts.
This primary corpus text selection protocol does
not explicitly target reverse reactions such as
deacetylation, and the total number of these events
in the resulting corpus was low for many types. To
be able to measure the extraction performance for
these types, we defined a secondary selection pro-
tocol that augmented the primary protocol with a
regular expression-based filter removing documents
that did not (likely) contain mentions of reverse re-
actions. This protocol was used to select a secondary
set of test abstracts enriched in mentions of reverse
reactions. Performance on this secondary test set
was also evaluated, but is not part of the primary task
evaluation. Due to space considerations, we only
present the primary test set results in this paper, re-
ferring to the shared task website for the secondary
results.
3.2 Annotation
Annotation was performed manually. The
gene/protein entities automatically detected in
the document selection step were provided to
annotators for reference for creating PROTEIN
annotations, but all entity annotations were checked
and revised to conform to the specific guidelines for
the task.5 For the annotation of PROTEIN entities,
we adopted the GENIA gene/gene product (GGP)
annotation guidelines (Ohta et al, 2009), adding
one specific exception: while the primary guidelines
require that only specific individual gene or gene
product names are annotated, we allowed also the
annotation of mentions of groups of histones or
5This revision was substantial: only approximately 65% of
final PROTEIN annotations exactly match an automatically pre-
dicted one due to differences in annotation criteria (Wang et al,
2009).
19
the entire histone protein family to capture histone
modification events also in cases where only the
group is mentioned.
All event annotations were created from scratch
without automatic support to avoid bias toward spe-
cific automatic extraction methods or approaches.
The event annotation follows the GENIA event cor-
pus annotation guidelines (Kim et al, 2008) as they
apply to protein modifications, with CATALYSIS be-
ing annotated following the criteria for the POSI-
TIVE REGULATION event type with the additional
constraints that the Cause of the event is a gene or
gene product entity and the form of regulation is
catalysis of a modification reaction.
The manual annotation was performed by three
experienced annotators with a molecular biology
background, with one chief annotator with extensive
experience in domain event annotation organizing
and supervising the annotator training and the over-
all process. After completion of primary annotation,
we performed a final check targeting simple human
errors using an automatic extraction system.6 This
correction process resulted in the revision of approx-
imately 2% of the event annotations. To evaluate the
consistency of the annotation, we performed inde-
pendent event annotation (taking PROTEIN annota-
tions as given) for a random sample of 10% of the
corpus documents. Comparison of the two manually
created sets of event annotations under the primary
task evaluation criteria gave an F-score of 82% for
the full task and 89% for the core task.7 We found
that CATALYSIS events were particularly challeng-
ing, showing just 65% agreement for the core task.
Table 2 shows the statistics of the primary task
data. We note that while the corpus is broadly com-
parable in size to the BioNLP?09 shared task dataset
(Kim et al, 2009) in terms of the number of ab-
stracts and annotated entities, the number of anno-
tated events in the EPI corpus is approximately 20%
of that in the ?09 dataset, reflecting the more focused
event types.
6High-confidence system predictions differing from gold
annotations were provided to a human annotator, not used di-
rectly to change corpus data. To further reduce the risk of bias,
we only informed the annotator of the entities involved, not of
the predicted event structure.
7Due to symmetry of precision/recall and the applied crite-
ria, this score was not affected by the choice of which set of
annotations to consider as ?gold? for the comparison.
Item Training Devel Test
Abstract 600 200 400
Word 127,312 43,497 82,819
Protein 7,595 2,499 5,096
Event 1,852 601 1,261
Modification 173 79 117
Table 2: Statistics of the EPI corpus. Test set statistics
shown only for the primary test data.
4 Evaluation
Evaluation is instance- and event-oriented and based
on the standard precision/recall/F-score8 metrics.
The primary evaluation criteria are the same as in the
BioNLP?09 shared task, incorporating the ?approx-
imate span matching? and ?approximate recursive
matching? variants to strict matching. In brief, un-
der these criteria text-bound annotations (event trig-
gers and entities) in a submission are considered to
match a corresponding gold annotation if their span
is contained within the (mildly extended) span of
the gold annotation, and events that refer to other
events as arguments are considered to match if the
Theme arguments of the recursively referred events
match, that is, non-Theme arguments are ignored in
recursively referred events. For a detailed descrip-
tion of these evaluation criteria, we refer to (Kim et
al., 2009).
In addition to the primary evaluation criteria, we
introduced a new relaxed evaluation criterion we
term single partial penalty. Under the primary cri-
teria, when a predicted event matches a gold event
in some of its arguments but lacks one or more ar-
guments of the gold event, the submission is ar-
guably given a double penalty: the predicted event
is counted as a false positive (FP), and the gold
event is counted as a false negative (FN). Under the
single partial penalty evaluation criterion, predicted
events that match a gold event in all their arguments
are not counted as FP, although the corresponding
gold event still counts as FN (the ?single penalty?).
Analogously, gold events that partially match a pre-
dicted event are not counted as FN, although the cor-
responding predicted event with ?extra? arguments
counts as FP. This criterion can give a more nuanced
view of performance for partially correctly predicted
events.
8Specifically F1. F is used for short throughout.
20
NLP Events Other resources
Rank Team Org word parse trigger arg group modif. corpora other
1 UTurku 1BI Porter McCCJ + SD SVM SVM SVM SVM - hedge words
2 FAUST 3NLP
CoreNLP,
SnowBall
McCCJ + SD (UMass+Stanford as features) - - word clusters
3 MSR-NLP
1SDE,
3NLP
Porter,
custom
McCCJ + SD,
Enju
SVM SVM SVM - -
triggers, word
clusters
4 UMass 1NLP
CoreNLP,
SnowBall
McCCJ + SD Joint, dual decomposition - - -
5 Stanford 3NLP custom McCCJ + SD MaxEnt Joint, MSTParser - - word clusters
6 CCP-BTMG 3BI
Porter,
WN-lemma
Stanford + SD Graph extraction & matching - - -
7 ConcordU 2NLP - McCCJ + SD Dict Rules Rules Rules -
triggers and
hedge words
Table 3: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Lan-
guage Processing researcher, SDE=Software Development Engineer, CoreNLP=Stanford CoreNLP, Porter=Porter
stemmer, Snowball=Snowball stemmer, WN-lemma=WordNet lemmatization, McCCJ=McClosky-Charniak-Johnson
parser, Charniak=Charniak parser, SD=Stanford Dependency conversion, Dict=Dictionary
The full EPI task involves many partially indepen-
dent challenges, incorporating what were treated in
the BioNLP?09 shared task as separate subtasks: the
identification of additional non-Theme event partic-
ipants (Task 2 in ?09) and the detection of negated
and speculated events (Task 3 in ?09). The EPI task
does not include explicit subtasks. However, we
specifies minimal core extraction targets in addition
to the full task targets. Results are reported sepa-
rately for core targets and full task, allowing partic-
ipants to choose to only extract core targets. The
full task results are considered the primary evalua-
tion for the task e.g. for the purposes of determining
the ranking of participating systems.
5 Results
5.1 Participation
Table 3 summarizes the participating groups and the
features of their extraction systems. We note that,
similarly to the ?09 task, machine learning-based
systems remain dominant overall, although there is
considerable divergence in the specific methods ap-
plied. In addition to domain mainstays such as sup-
port vector machines and maximum entropy mod-
els, we find increased application of joint models
(Riedel et al, 2011; McClosky et al, 2011; Riedel
and McCallum, 2011) as opposed to pure pipeline
systems (Bjo?rne and Salakoski, 2011; Quirk et al,
2011) . Remarkably, the application of full pars-
ing together with dependency-based representations
of syntactic analyses is adopted by all participants,
with the parser of Charniak and Johnson (2005) with
the biomedical domain model of McClosky (2009)
is applied in all but one system (Liu et al, 2011) and
the Stanford Dependency representation (de Marn-
effe et al, 2006) in all. These choices may be mo-
tivated in part by the success of systems using the
tools in the previous shared task and the availability
of the analyses as supporting resources (Stenetorp et
al., 2011).
Despite the availability of PTM and DNA methy-
lation resources other than those specifically intro-
duced for the task and the PHOSPHORYLATION an-
notations in the GE task (Kim et al, 2011b), no par-
ticipant chose to apply other corpora for training.
With the exception of externally acquired unlabeled
data such as PubMed-derived word clusters applied
by three groups, the task results thus reflect a closed
task setting in which only the given data is used for
training.
5.2 Evaluation results
Table 4 presents a the primary results by event type,
and Table 5 summarizes these results. We note
that only two teams, UTurku (Bjo?rne and Salakoski,
2011) and ConcordU (Kilicoglu and Bergler, 2011),
predicted event modifications, and only UTurku pre-
dicted additional (non-core) event arguments (data
not shown). The other five systems thus addressed
21
MSR-
NLP
CCP-
BTMG
Con-
cordUUTurku FAUST UMass Stanford Size
HYDROXYLATION 42.25 10.26 10.20 12.80 9.45 12.84 6.32 139
DEHYDROXYLATION - - - - - - - 1
PHOSPHORYLATION 67.12 51.61 50.00 49.18 40.98 47.06 44.44 130
DEPHOSPHORYLATION 0.00 0.00 0.00 0.00 0.00 50.00 0.00 3
UBIQUITINATION 75.34 72.95 67.88 72.94 67.44 70.87 69.97 340
DEUBIQUITINATION 54.55 40.00 0.00 31.58 0.00 42.11 14.29 17
DNA METHYLATION 60.21 31.21 34.54 23.82 31.02 15.65 8.22 416
DNA DEMETHYLATION 26.67 0.00 0.00 0.00 0.00 0.00 0.00 21
Simple event total 63.05 45.17 44.97 43.01 40.96 40.62 37.84 1067
GLYCOSYLATION 49.43 41.10 38.87 40.00 37.22 25.62 25.94 347
DEGLYCOSYLATION 40.00 35.29 0.00 38.10 30.00 35.29 26.67 27
ACETYLATION 57.22 40.00 41.42 40.25 35.12 37.50 38.19 337
DEACETYLATION 54.90 28.00 31.82 29.17 21.74 24.56 27.27 50
METHYLATION 57.67 24.82 19.57 23.67 18.54 16.99 15.50 374
DEMETHYLATION 35.71 0.00 0.00 0.00 0.00 0.00 0.00 13
Non-simple event total 54.36 33.86 31.85 33.07 29.28 25.06 25.10 1148
CATALYSIS 7.06 6.58 7.75 5.00 2.84 7.58 1.74 238
Subtotal 55.02 36.93 36.17 35.30 32.85 30.58 28.92 2453
NEGATION 18.60 0.00 0.00 0.00 0.00 0.00 26.51 149
SPECULATION 37.65 0.00 0.00 0.00 0.00 0.00 6.82 103
Modification total 28.07 0.00 0.00 0.00 0.00 0.00 16.37 252
Total 53.33 35.03 34.27 33.52 31.22 28.97 27.88 2705
Addition total 59.33 40.27 39.05 38.65 36.03 32.75 31.50 2038
Removal total 44.29 22.41 15.73 22.76 14.41 23.53 17.48 132
Table 4: Primary evaluation F-scores by event type. The ?size? column gives the number of annotations of each type
in the given data (training+development). Best result for each type shown in bold. For DEHYDROXYLATION, no
examples were present in the test data and none were predicted by any participant.
Team recall prec. F-score
UTurku 52.69 53.98 53.33
FAUST 28.88 44.51 35.03
MSR-NLP 27.79 44.69 34.27
UMass 28.08 41.55 33.52
Stanford 26.56 37.85 31.22
CCP-BTMG 23.44 37.93 28.97
ConcordU 20.83 42.14 27.88
Table 5: Primary evaluation results
only the core task. For the full task, this differ-
ence in approach is reflected in the substantial per-
formance advantage for the UTurku system, which
exhibits highest performance overall as well as for
most individual event types.
Extraction performance for simple events tak-
ing only Theme and Site arguments is consistently
higher than for other event types, with absolute F-
score differences of over 10% points for many sys-
tems. Similar notable performance differences are
seen between the addition events, for which am-
ple training data was available, and the removal
types for which data was limited. This effect is
particularly noticeable for DEPHOSPHORYLATION,
DNA DEMETHYLATION and DEMETHYLATION,
for which the clear majority of systems failed to pre-
dict any correct events. Extraction performance for
CATALYSIS events is very low despite a relatively
large set of training examples, indicating that the
extraction of nested event structures remains very
challenging. This low performance may also be re-
lated to the fact that CATALYSIS events are often
triggered by the same word as the catalysed mod-
ification (e.g. Figure 1b), requiring the assignment
of multiple event labels to a single word in typical
system architectures.
Table 6 summarizes the full task results with the
addition of the single partial penalty criterion. The
F-scores for the seven participants under this crite-
22
Team recall prec. F-score ?
UTurku 54.79 58.42 56.55 3.22
FAUST 28.88 72.05 41.24 6.21
MSR-NLP 27.79 66.72 39.24 4.97
UMass 28.08 63.28 38.90 5.38
Stanford 26.56 56.83 36.20 4.98
CCP-BTMG 23.44 50.79 32.08 3.11
ConcordU 20.83 60.55 30.99 3.11
Table 6: Full task evaluation results for primary criteria
and with single partial penalty. The ? column gives F-
score difference to the primary results.
rion are on average over 4% points higher than un-
der the primary criteria, with the most substantial
increases seen for high-ranking participants only ad-
dressing the core task: for example, the precision
of the FAUST system (Riedel et al, 2011) is nearly
30% higher under the relaxed criterion. These re-
sults provide new perspective deserving further de-
tailed study into the question of what are the most
meaningful criteria for event extraction system eval-
uation.
Table 7 summarizes the core task results. While
all systems show notably higher performance than
for the full task, high-ranking participants focusing
on the core task gain most dramatically, with the
FAUST system core task F-score essentially match-
ing that of the top system (UTurku). For the core
task, all participants achieve F-scores over 50% ?
a result achieved by only a single system in the ?09
task ? and the top four participants average over 65%
F-score. These results confirm that current event
extraction technology is well applicable to the core
PTM extraction task even when the number of tar-
geted event types is relatively high and may be ready
to address the challenges of exhaustive PTM extrac-
tion (Pyysalo et al, 2011a). The best core tasks re-
sults, approaching 70% F-score, are particularly en-
couraging as the level of performance is comparable
to or better than state-of-the-art results for many ref-
erence resources for protein-protein interaction ex-
traction (see e.g. Tikk et al (2010))) using the simple
untyped entity pair representation, a standard task
that has been extensively studied in the domain.
6 Discussion and Conclusions
This paper has presented the preparation, resources,
results and analysis of the BioNLP Shared Task
Team recall prec. F-score ?1 ?2
UTurku 68.51 69.20 68.86 15.53 12.31
FAUST 59.88 80.25 68.59 33.56 27.35
MSR-NLP 55.70 77.60 64.85 30.58 25.61
UMass 57.04 73.30 64.15 30.63 25.25
Stanford 56.87 70.22 62.84 31.62 26.64
ConcordU 40.28 76.71 52.83 24.95 21.84
CCP-BTMG 45.06 63.37 52.67 23.70 20.59
Table 7: Core task evaluation results. The ?1 column
gives F-score difference to primary full task results, ?2
to full task results with single partial penalty.
2011 Epigenetics and Post-translational modifica-
tions (EPI) main task. The results demonstrate that
the core extraction target of identifying statements
of 14 different modification types with the modified
gene or gene product can be reliably addressed by
current event extraction methods, with two systems
approaching 70% F-score at this task. Nevertheless,
challenges remain in detecting statements regarding
the catalysis of these events as well as in resolving
the full detail of such modification events, a task at-
tempted by only one participant and at which perfor-
mance remains at somewhat above 50% in F-score.
Detailed evaluation showed that the highly com-
petitive participating systems differ substantially in
their relative strengths, indicating potential for fur-
ther development at protein and DNA modification
event detection. The task results are available in
full detail from the shared task webpage, http:
//sites.google.com/site/bionlpst/.
In the future, we will follow the example of the
BioNLP?09 shared task in making the data and re-
sources of the EPI task open to all interested par-
ties to encourage further study of event extraction
for epigenetics and post-translational modification
events, to facilitate system comparison on a well-
defined standard task, and to support the develop-
ment of further applications of event extraction tech-
nology in this important area of biomolecular sci-
ence.
Acknowledgments
We would like to thank Yoshiro Okuda and Yo Shi-
dahara of NalaPro Technologies for their efforts in
producing the EPI task annotation. This work was
supported by Grant-in-Aid for Specially Promoted
Research (MEXT, Japan).
23
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
D. Barford, A.K. Das, and M.P. Egloff. 1998. The struc-
ture and mechanism of protein phosphatases: insights
into catalysis and regulation. Annual review of bio-
physics and biomolecular structure, 27(1):133?164.
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing biomedical event extraction. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Ekaterina Buyko, Erik Faessler, Joachim Wermter, and
Udo Hahn. 2009. Event extraction from trimmed de-
pendency graphs. In Proceedings of BioNLP Shared
Task 2009, pages 19?27.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of ACL?05, pages 173?
180.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
M.H. Glickman and A. Ciechanover. 2002. The
ubiquitin-proteasome proteolytic pathway: destruction
for the sake of construction. Physiological reviews,
82(2):373.
R. Hoehndorf, A.C.N. Ngomo, S. Pyysalo, T. Ohta,
A. Oellrich, and D. Rebholz-Schuhmann. 2010.
Applying ontology design patterns to the imple-
mentation of relations in GENIA. In Proceedings
of the Fourth Symposium on Semantic Mining in
Biomedicine SMBM 2010.
Robin Holliday and JE Pugh. 1975. Dna modification
mechanisms and gene activity during development.
Science, 187:226?232.
Robin Holliday. 1987. The inheritance of epigenetic de-
fects. Science, 238:163?170.
Rudolf Jaenisch and Adrian Bird. 2003. Epigenetic reg-
ulation of gene expression: how the genome integrates
intrinsic and environmental signals. Nature Genetics,
33:245?254.
Halil Kilicoglu and Sabine Bergler. 2011. Adapting a
general semantic interpretation approach to biological
event extraction. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011a. Overview
of BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011b. Overview of the Genia Event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
R. Leaman and G. Gonzalez. 2008. Banner: an exe-
cutable survey of advances in biomedical named entity
recognition. Proceedings of the Pacific Symposium on
Biocomputing (PSB?08), pages 652?663.
Haibin Liu, Ravikumar Komandur, and Karin Verspoor.
2011. From graphs to events: A subgraph matching
approach for information extraction from biomedical
text. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
David McClosky, Mihai Surdeanu, and Christopher Man-
ning. 2011. Event extraction as dependency parsing
for bionlp 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
David McClosky. 2009. Any Domain Parsing: Auto-
matic Domain Adaptation for Natural Language Pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009. Incorporating
GENETAG-style annotation to GENIA corpus. In
Proceedings of BioNLP?09, pages 106?107.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, Jin-Dong
Kim, and Jun?ichi Tsujii. 2010a. Event extraction
for post-translational modifications. In Proceedings of
BioNLP?10, pages 19?27.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and
Jun?ichi Tsujii. 2010b. Event extraction for dna
methylation. In Proceedings of SMBM?10.
Mate? Ongenaert, Leander Van Neste, Tim De Meyer,
Gerben Menschaert, Sofie Bekaert, and Wim
24
Van Criekinge. 2008. PubMeth: a cancer methy-
lation database combining text-mining and expert
annotation. Nucl. Acids Res., 36(suppl 1):D842?846.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, and
Jun?ichi Tsujii. 2011a. Towards exhaustive protein
modification event extraction. In Proceedings of the
BioNLP 2011 Workshop, Portland, Oregon, June. As-
sociation for Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011b.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Chris Quirk, Pallavi Choudhury, Michael Gamon, and
Lucy Vanderwende. 2011. Msr-nlp entry in bionlp
shared task 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Sebastian Riedel and Andrew McCallum. 2011. Ro-
bust biomedical event extraction with dual decompo-
sition and minimal domain adaptation. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Sebastian Riedel, David McClosky, Mihai Surdeanu, An-
drew McCallum, and Chris Manning. 2011. Model
combination for event extraction in bionlp 2011. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
A.D. Riggs. 1975. X inactivation, differentiation, and
dna methylation. Cytogenetic and Genome Research,
14:9?25.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
JB Stock, AJ Ninfa, and AM Stock. 1989. Protein
phosphorylation and regulation of adaptive responses
in bacteria. Microbiology and Molecular Biology Re-
views, 53(4):450.
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne Mat-
ten, and John Wilbur. 2005. Genetag: a tagged cor-
pus for gene/protein named entity recognition. BMC
Bioinformatics, 6(Suppl 1):S3.
Paul Thompson, Syed Iqbal, John McNaught, and Sophia
Ananiadou. 2009. Construction of an annotated
corpus to support biomedical information extraction.
BMC Bioinformatics, 10(1):349.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg
Hakenberg, and Ulf Leser. 2010. A comprehen-
sive benchmark of kernel methods to extract protein-
protein interactions from literature. PLoS Comput
Biol, 6(7):e1000837, 07.
Yue Wang, Jin-Dong Kim, Rune S?tre, Sampo Pyysalo,
and Jun?ichi Tsujii. 2009. Investigating heteroge-
neous protein annotations toward cross-corpora uti-
lization. BMC Bioinformatics, 10(403), Dec. ISSN:
1471-2105.
Eric S Witze, William M Old, Katheryn A Resing,
and Natalie G Ahn. 2007. Mapping protein post-
translational modifications with mass spectrometry.
Nature Methods, 4:798?806.
Cathy H. Wu, Lai-Su L. Yeh, Hongzhan Huang, Leslie
Arminski, Jorge Castro-Alvear, Yongxing Chen,
Zhangzhi Hu, Panagiotis Kourtesis, Robert S. Led-
ley, Baris E. Suzek, C.R. Vinayaka, Jian Zhang, and
Winona C. Barker. 2003. The Protein Information
Resource. Nucl. Acids Res., 31(1):345?347.
25
Proceedings of BioNLP Shared Task 2011 Workshop, pages 26?35,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011
Sampo Pyysalo? Tomoko Ohta? Rafal Rak?? Dan Sullivan? Chunhong Mao?
Chunxia Wang? Bruno Sobral? Jun?ichi Tsujii? Sophia Ananiadou??
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Virginia Bioinformatics Institute, Virginia Tech, Blacksburg, Virginia, USA
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
?Microsoft Research Asia, Beijing, China
{smp,okap}@is.s.u-tokyo.ac.jp jtsujii@microsoft.com
{dsulliva,cmao,cwang,sobral}@vbi.vt.edu
{rafal.rak,sophia.ananiadou}@manchester.ac.uk
Abstract
This paper presents the preparation, resources,
results and analysis of the Infectious Diseases
(ID) information extraction task, a main task
of the BioNLP Shared Task 2011. The ID
task represents an application and extension
of the BioNLP?09 shared task event extrac-
tion approach to full papers on infectious dis-
eases. Seven teams submitted final results to
the task, with the highest-performing system
achieving 56% F-score in the full task, com-
parable to state-of-the-art performance in the
established BioNLP?09 task. The results in-
dicate that event extraction methods general-
ize well to new domains and full-text publi-
cations and are applicable to the extraction of
events relevant to the molecular mechanisms
of infectious diseases.
1 Introduction
The Infectious Diseases (ID) task of the BioNLP
Shared Task 2011 (Kim et al, 2011a) is an infor-
mation extraction task focusing on the biomolecu-
lar mechanisms of infectious diseases. The primary
target of the task is event extraction (Ananiadou et
al., 2010), broadly following the task setup of the
BioNLP?09 Shared Task (BioNLP ST?09) (Kim et
al., 2009).
The task concentrates on the specific domain of
two-component systems (TCSs, or two-component
regulatory systems), a mechanism widely used by
bacteria to sense and respond to the environment
(Thomason and Kay, 2000). Typical TCSs con-
sist of two proteins, a membrane-associated sensor
kinase and a cytoplasmic response regulator. The
sensor kinase monitors changes in the environment
while the response regulator mediates an adaptive
response, usually through differential expression of
target genes (Mascher et al, 2006). TCSs have many
functions, but those of particular interest for infec-
tious disease researchers include virulence, response
to antibiotics, quorum sensing, and bacterial cell at-
tachment (Krell et al, 2010). Not all TCS functions
are well known: in some cases, TCSs are involved
in metabolic processes that are difficult to precisely
characterize (Wang et al, 2010). TCSs are of in-
terest also as drugs designed to disrupt TCSs may
reduce the virulence of bacteria without killing it,
thus avoiding the potential selective pressure of an-
tibiotics lethal to some pathogenic bacteria (Gotoh
et al, 2010). Information extraction techniques may
support better understanding of these fundamental
systems by identifying and structuring the molecu-
lar processes underlying two component signaling.
The ID task seeks to address these opportuni-
ties by adapting the BioNLP ST?09 event extraction
model to domain scientific publications. This model
was originally introduced to represent biomolecu-
lar events relating to transcription factors in human
blood cells, and its adaptation to a domain that cen-
trally concerns both bacteria and their hosts involves
a variety of novel aspects, such as events concerning
whole organisms, the chemical environment of bac-
teria, prokaryote-specific concepts (e.g. regulons as
elements of gene expression), as well as the effects
of biomolecules on larger-scale processes involving
hosts such as virulence.
26
2 Task Setting
The ID task broadly follows the task definition and
event types of the BioNLP ST?09, extending it with
new entity categories, correspondingly broadening
the scope of events, and introducing a new class of
events, high-level biological processes.
2.1 Entities
The ID task defines five core types of entities:
genes/gene products, two-component systems, reg-
ulons/operons, chemicals, and organisms. Follow-
ing the general policy of the BioNLP Shared Task,
the recognition of the core entities is not part of
the ID task. As named entity recognition (NER)
is considered in other prominent domain evaluations
(Krallinger et al, 2008), we have chosen to isolate
aspects of extraction performance relating to NER
from the main task of interest, event extraction, by
providing participants with human-created gold an-
notations for core entities. These annotations are
briefly presented in the following.
Mentions of names of genes and their products
(RNA and proteins) are annotated with a single
type, without differentiating between subtypes, fol-
lowing the guidelines of the GENIA GGP corpus
(Ohta et al, 2009). This type is named PRO-
TEIN to maintain consistency with related tasks
(e.g. BioNLP ST?09), despite slight inaccuracy
for cases specifically referencing RNA or DNA
forms. Two-component systems, consisting of two
proteins, frequently have names derived from the
names of the proteins involved (e.g. PhoP-PhoR
or SsrA/SsrB). Mentions of TCSs are annotated as
TWO-COMPONENT-SYSTEM, nesting PROTEIN an-
notations if present. Regulons and operons are col-
lections of genes whose expression is jointly regu-
lated. Like the names of TCSs, their names may de-
rive from the names of the involved genes and pro-
teins, and are annotated as embedding PROTEIN an-
notations when they do. The annotation does not
differentiate between the two, marking both with a
single type REGULON-OPERON.
In addition to these three classes relating to genes
and proteins, the core entity annotation recognizes
the classes CHEMICAL and ORGANISM. All men-
tions of formal and informal names of atoms, inor-
ganic compounds, carbohydrates and lipids as well
as organic compounds other than amino acid and nu-
cleic acid compounds (i.e. gene/protein-related com-
pounds) are annotated as CHEMICAL. Mentions of
names of families, genera, species and strains as
well as non-name references with comparable speci-
ficity are annotated as ORGANISM.
Finally, the non-specific type ENTITY1 is defined
for marking entities that specify additional details of
events such as the binding site in a BINDING event or
the location an entity moves to in a LOCALIZATION
event. Unlike the core entities, annotations of the
generic ENTITY type are not provided for test data
and must be detected by participants addressing the
full task.
2.2 Relations
The ID task involves one relation, EQUIV, defin-
ing entities (of any of the core types) to be equiv-
alent. This relation is used to annotate abbreviations
and local aliases and it is not a target of extraction,
but provided for reference and applied in evaluation,
where references to any of a set of equivalent entities
are treated identically.
2.3 Events
The primary extraction targets of the ID task are the
event types summarized in Table 1. These are a su-
perset of those targeted in the BioNLP ST?09 and its
repeat, the 2011 GE task (Kim et al, 2011b). This
design makes it possible to study aspects of domain
adaptation by having the same extraction targets in
two subdomains of biomedicine, that of transcrip-
tion factors in human blood cells (GE) and infectious
diseases. The events in the ID task extend on those
of GE in the inclusion of additional entity types
as participants in previously considered event types
and the introduction of a new type, PROCESS. We
next briefly discuss the semantics of these events,
defined (as in GE) with reference to the community-
standard Gene Ontology (Ashburner et al, 2000).
We refer to (Kim et al, 2008; Kim et al, 2009) for
the ST?09/GE definitions.
1In terms of the GENIA ontology, ENTITY is used to mark
e.g. PROTEIN DOMAIN OR REGION references. Specific types
were applied in manual annotation, but these were replaced
with the generic ENTITY in part to maintain consistency with
BioNLP ST?09 data and to reduce the NER-related demands
on participating systems by not requiring the assignment of de-
tailed types.
27
Type Core arguments Additional arguments
GENE EXPRESSION Theme(PROTEIN or REGULON-OPERON)
TRANSCRIPTION Theme(PROTEIN or REGULON-OPERON)
PROTEIN CATABOLISM Theme(PROTEIN)
PHOSPHORYLATION Theme(PROTEIN) Site(ENTITY)
LOCALIZATION Theme(Core entity) AtLoc(ENTITY), ToLoc(ENTITY)
BINDING Theme(Core entity)+ Site(ENTITY)+
PROCESS Participant(Core entity)?
REGULATION Theme(Core entity / Event), Cause(Core entity / Event)? Site(ENTITY), CSite(ENTITY)
POSITIVE REGULATION Theme(Core entity / Event), Cause(Core entity / Event)? Site(ENTITY), CSite(ENTITY)
NEGATIVE REGULATION Theme(Core entity / Event), Cause(Core entity / Event)? Site(ENTITY), CSite(ENTITY)
Table 1: Event types and their arguments. The type of entity allowed as argument is specified in parenthesis. ?Core en-
tity? is any of PROTEIN, TWO-COMPONENT-SYSTEM, REGULON-OPERON, CHEMICAL, or ORGANISM. Arguments
that can be filled multiple times marked with ?+?, non-mandatory core arguments with ??? (all additional arguments
are non-mandatory).
The definitions of the first four types in Table 1
are otherwise unchanged from the ST?09 definitions
except that GENE EXPRESSION and TRANSCRIP-
TION extend on the former definition in recogniz-
ing REGULON-OPERON as an alternative unit of ex-
pression. LOCALIZATION, taking only PROTEIN
type arguments in the ST?09 definition, is allowed
to take any core entity argument. This expanded
definition remains consistent with the scope of the
corresponding GO term (GO:0051179). BINDING
is similarly extended, giving it a scope largely con-
sistent with GO:0005488 (binding) but also encom-
passing GO:0007155 (cell adhesion) (e.g. a bac-
terium binding another) and protein-organism bind-
ing. The three regulation types (REGULATION,
POSITIVE REGULATION, and NEGATIVE REGULA-
TION) likewise allow the new core entity types as
arguments, but their definitions are otherwise un-
changed from those in ST?09, that is, the GENIA on-
tology definitions. As in these resources, regulation
types are used not only for the biological sense but
also to capture statements of general causality (Kim
et al, 2008). As in ST?09, all events of types dis-
cussed above require a Theme argument: only events
involving an explicitly stated theme (of an appropri-
ate type) should be extracted. All other arguments
are optional.
The PROCESS type, new to ID, is used to annotate
high-level processes such as virulence, infection and
resistance that involve infectious organisms. This
type differs from the others in that it has no manda-
tory arguments: the targeted processes should be ex-
tracted even if they have no explicitly stated partici-
pants, reflecting that they are of interest even without
the further specification. When stated, the involved
participants are captured using the generic role type
Participant. Figure 1 shows an illustration of some
of the the ID task extraction targets.
We term the first five event types in Table 1 taking
exactly one Theme argument as their core argument
simple events. In analysis we further differentiate
non-regulation events (the first seven) and regulation
(the last three), which is known to represent partic-
ular challenges for extraction in involving events as
arguments, thus creating nested event structures.
2.4 Event modifications
The ID task defines two event modification ex-
traction targets, NEGATION and SPECULATION.
These modifications mark events as being explic-
itly negated (e.g. virB is not expressed) or stated in
a speculative context (e.g. virB may be expressed).
Both may apply simultaneously. The modification
definitions are identical to the ST?09 ones, includ-
ing the representation in which modifications (un-
like events) are not assigned text bindings.
3 Data
The ID task data were newly annotated for the
BioNLP Shared Task and are not based on any previ-
ously released resource. Annotation was performed
by two teams, one in Tsujii laboratory (University
of Tokyo) and one in Virginia Bioinformatics Insti-
tute (Virginia Tech). The entity and event annotation
28
Figure 1: Example event annotation. The association of a TCS with an organism is captured through an event structure
involving a PROCESS (?virulence?) and POSITIVE REGULATION. Regulation types are used to capture also statements
of general causality such as ?is essential for? here. (Simplified from PMC ID 2358977)
Journal # Published
PLoS Pathogens 9 2006?2010
PLoS One 7 2008?2010
BMC Genomics 3 2008?2010
PLoS Genetics 2 2007?2010
Open Microbiology J. 2 2008?2010
BMC Microbiology 2 2008?2009
Other 5 2007?2008
Table 2: Corpus composition. Journals in which selected
articles were published with number of articles (#) and
publication years.
design was guided by previous studies on NER and
event extraction in a closely related domain (Pyysalo
et al, 2010; Ananiadou et al, 2011).
3.1 Document selection
The training and test data were drawn from the pri-
mary text content of recent full-text PMC open ac-
cess documents selected by infectious diseases do-
main experts (Virginia Tech team) as representative
publications on two-component regulatory systems.
Table 2 presents some characteristics of the corpus
composition. To focus efforts on natural language
text likely to express novel information, we excluded
tables, figures and their captions, as well as methods
sections, acknowledgments, authors? contributions,
and similar meta-content.
3.2 Annotation
Annotation was performed in two primary stages,
one for marking core entities and the other for events
and secondary entities. As a preliminary processing
step, initial sentence segmentation was performed
with the GENIA Sentence Splitter2. Segmentation
errors were corrected during core entity annotation.
Core entity annotation was performed from the
basis of an automatic annotation created using se-
lected existing taggers for the target entities. The
2http://www-tsujii.is.s.u-tokyo.ac.jp/
?y-matsu/geniass/
Entity type prec. rec. F
PROTEIN 54.64 39.64 45.95
CHEMICAL 32.24 19.05 23.95
ORGANISM 90.38 47.70 62.44
TWO-COMPONENT-SYSTEM 87.69 47.24 61.40
Table 3: Automatic core entity tagging performance.
following tools and settings were adopted, with pa-
rameters tuned on initial annotation for two docu-
ments:
PROTEIN: NeMine (Sasaki et al, 2008) trained on
the JNLPBA data (Kim et al, 2004) with threshold
0.05, filtered to only GENE and PROTEIN types.
ORGANISM: Linnaeus (Gerner et al, 2010) with
?variant matching? for species names variants.
CHEMICAL: OSCAR3 (Corbett and Murray-Rust,
2006) with confidence 90%.
TWO-COMPONENT-SYSTEM: Custom regular ex-
pressions.
Initial automatic tagging was not applied for en-
tities of the REGULON-OPERON type or the generic
ENTITY type (for additional event arguments). All
automatically generated annotations were at least
confirmed through manual inspection, and the ma-
jority of the automatic annotations were revised in
manual annotation. Table 3 summarizes the tag-
ging performance of the automatic tools as measured
against the final human-annotated training and de-
velopment datasets.3
Annotation for the task extraction targets ? events
and event modifications ? was created entirely man-
ually without automatic annotation support to avoid
any possible bias toward specific extraction meth-
ods or approaches. The Tsujii laboratory team orga-
3It should be noted that these results are low in part due to
differences in annotation criteria (see e.g. (Wang et al, 2009))
and to data tagged using the ID task annotation guidelines not
being applied for training; training on the newly annotated data
is expected to allow notably more accurate tagging.
29
Item Train Devel Test Total
Articles 15 5 10 30
Sentences 2,484 709 1,925 5118
Words 74,439 21,225 57,489 153,153
Core entities 6,525 1,976 4,239 12,740
Events 2,088 691 1,371 4150
Modifications 95 45 74 214
Table 4: Statistics of the ID corpus.
nized the annotation effort, with a coordinating an-
notator with extensive experience in event annota-
tion (TO) leading annotator training and annotation
scheme development. Detailed annotation guide-
lines (Pyysalo et al, 2011) extending on the GE-
NIA annotation guidelines were developed jointly
with all annotators and refined throughout the an-
notation effort. Based on measurements of inter-
annotator consistency between annotations indepen-
dently created by the two teams, made throughout
annotator training and primary annotation (exclud-
ing final corpus cleanup), we estimate the consis-
tency of the final entity annotation to be no lower
than 90% F-score and that of the event annotation to
be no lower than 75% F-score for the primary eval-
uation criteria (see Section 4).
3.3 Datasets and statistics
Initial annotation was produced for the selected sec-
tions (see Section 3.1) in 33 full-text articles, of
which 30 were selected for the final dataset as repre-
sentative of the extraction targets. These documents
were split into training, development and test sets of
15, 5 and 10 documents, respectively. Participants
were provided with all training and development set
annotations and test set core entity annotations. The
overall statistics of the datasets are given in Table 4.
As the corpus consists of full-text articles, it con-
tains a somewhat limited number of articles, but in
other terms it is of broadly comparable size to the
largest of the BioNLP ST corpora: the corpus word
count, for example, corresponds to that of a cor-
pus of approximately 800 PubMed abstracts, and the
core entity count is comparable to that in the ST?09
data. However, for reasons that may relate in part to
the domain, the event count is approximately a third
of that for the ST?09 data. In addition to having less
training data, the entity/event ratio is thus consider-
ably higher (i.e. there are more candidates for each
true target), suggesting that the ID data could be ex-
pected to provide a more challenging extraction task.
4 Evaluation
The performance of participating systems was
evaluated in terms of events using the standard
precision/recall/F-score metrics. For the primary
evaluation, we adopted the standard criteria defined
in the BioNLP?09 shared task. In brief, for deter-
mining whether a reference annotation and a pre-
dicted annotation match, these criteria relax exact
matching for event triggers and arguments in two
ways: matching of text-bound annotation (event
triggers and ENTITY type entities) allows limited
boundary variation, and only core arguments need to
match in nested event arguments for events to match.
For details of the matching criteria, please refer to
Kim et al (2009).
The primary evaluation for the task requires the
extraction of all event arguments (both core and ad-
ditional; see Table 1) as well as event modifications
(NEGATION and SPECULATION). This is termed
the full task. We additionally report extraction re-
sults for evaluation where both the gold standard ref-
erence data and the submission events are reduced
to only core arguments, event modifications are re-
moved, and resulting duplicate events removed. We
term this the core task. In terms of the subtask divi-
sion applied in the BioNLP?09 Shared Task and the
GE task of 2011, the core task is analogous to sub-
task 1 and the full task analogous to the combination
of subtasks 1?3.
5 Results
5.1 Participation
Final results to the task were successfully submitted
by seven participants. Table 5 summarizes the in-
formation provided by the participating teams. We
note that full parsing is applied in all systems, with
the specific choice of the parser of Charniak and
Johnson (2005) with the biomedical domain model
of McClosky (2009) and conversion into the Stan-
ford Dependency representation (de Marneffe et al,
2006) being adopted by five participants. Further,
five of the seven systems are predominantly machine
learning-based. These can be seen as extensions of
trends that were noted in analysis of the BioNLP
30
NLP Events Other resources
Rank Team Org Word Parse Trig. Arg. Group. Modif. Corpora Other
1 FAUST 3NLP
CoreNLP,
SnowBall
McCCJ + SD (UMass+Stanford as features) GE word clusters
2 UMass 1NLP
CoreNLP,
SnowBall
McCCJ + SD Joint, dual dec.+MIRA 1-best - GE -
3 Stanford 3NLP CoreNLP McCCJ + SD MaxEnt Joint, MSTParser - GE word clusters
4 ConcordU 2NLP - McCCJ + SD dict rules rules rules -
triggers and
hedge words
5 UTurku 1BI Porter McCCJ + SD SVM SVM SVM SVM - hedge words
6 PNNL
1CS, 1NLP,
2BI
Porter Stanford SVM SVM rules - GE UMLS, triggers
7 PredX 1CS, 1NLP LGP LGP dict rules rules - - UMLS, triggers
Table 5: Participants and summary of system descriptions. Abbreviations: Trig./Arg./Group./Modif.=event trigger
detection/argument detection/argument grouping/modification detection, BI=Bioinformatician, NLP=Natural Lan-
guage Processing researcher, CS=Computer scientist, CoreNLP=Stanford CoreNLP, Porter=Porter stemmer, Snow-
ball=Snowball stemmer McCCJ=McClosky-Charniak-Johnson parser, LGP=Link Grammar Parser, SD=Stanford De-
pendency conversion, UMLS=UMLS resources (e.g. lexicon, metamap)
ST?09 participation. In system design choices, we
note an indication of increased use of joint models
as opposed to pure pipeline designs, with the three
highest-ranking systems involving a joint model.
Several participants compiled dictionaries of
event trigger words and two dictionaries of hedge
words from the data. Four teams, including the three
top-ranking, used the GE task corpus as supplemen-
tary material, indicating that the GE annotations are
largely compatible with ID ones (see detailed results
below). This is encouraging for future applications
of the event extraction approach: as manual annota-
tion requires considerable effort and time, the ability
to use existing annotations is important for the feasi-
bility of adaptation of the approach to new domains.
While several participants made use of support-
ing syntactic analyses provided by the organizers
(Stenetorp et al, 2011), none applied the analyses
for supporting tasks, such as coreference or entity
relation extraction results ? at least in cases due to
time constraints (Kilicoglu and Bergler, 2011).
5.2 Evaluation results
Table 6 presents the primary results by event type,
and Table 7 summarizes these results. The full
task requires the extraction of additional arguments
and event modifications and involves multiple novel
challenges from previously addressed domain tasks
including a new subdomain, full-text documents,
several new entity types and a new event category.
Team recall prec. F-score
FAUST 48.03 65.97 55.59
UMass 46.92 62.02 53.42
Stanford 46.30 55.86 50.63
ConcordU 49.00 40.27 44.21
UTurku 37.85 48.62 42.57
PNNL 27.75 52.36 36.27
PredX 22.56 35.18 27.49
Table 7: Primary evaluation results.
Nevertheless, extraction performance for the top
systems is comparable to the state-of-the-art results
for the established BioNLP ST?09 task (Miwa et al,
2010) as well as its repetition as the 2011 GE task
(Kim et al, 2011b), where the highest overall result
for the primary evaluation criteria was also 56% F-
score for the FAUST system (Riedel et al, 2011).
This result is encouraging regarding the ability of
the extraction approach and methods to generalize
to new domains as well as their applicability specifi-
cally to texts on the molecular mechanisms of infec-
tious diseases.
We note that there is substantial variation in the
relative performance of systems for different en-
tity types. For example, Stanford (McClosky et
al., 2011) has relatively low performance for simple
events but achieves the highest result for PROCESS,
while UTurku (Bjo?rne and Salakoski, 2011) results
show roughly the reverse. This suggests further po-
tential for improvement from system combinations.
31
FAUST UMass Stanford ConcordU UTurku PNNL PredX Size
GENE EXPRESSION 70.68 66.43 54.00 56.57 64.88 53.33 0.00 512
TRANSCRIPTION 69.66 68.24 60.00 70.89 57.14 0.00 53.85 77
PROTEIN CATABOLISM 75.00 72.73 20.00 66.67 33.33 11.76 0.00 33
PHOSPHORYLATION 64.00 66.67 40.00 54.55 60.61 64.29 40.00 69
LOCALIZATION 33.33 14.29 31.58 20.00 66.67 20.69 0.00 49
Simple event total 68.47 63.55 52.72 56.78 62.67 43.87 18.18 740
BINDING 31.30 34.62 23.44 40.00 22.22 20.00 28.28 156
PROCESS 65.69 62.26 73.57 67.17 41.57 51.04 53.27 901
Non-regulation total 63.78 60.68 63.59 62.43 46.39 47.34 43.65 1797
REGULATION 35.44 30.49 17.67 19.43 22.96 0.00 2.16 267
POSITIVE REGULATION 47.50 49.49 34.78 23.41 41.28 24.60 21.02 455
NEGATIVE REGULATION 58.86 60.45 44.44 47.96 52.11 25.70 9.49 260
Regulation total 47.07 46.65 33.02 28.87 39.49 18.45 9.71 982
Subtotal 57.28 55.03 52.09 46.60 43.33 37.53 28.38 2779
NEGATION 0.00 0.00 0.00 22.92 32.91 0.00 0.00 96
SPECULATION 0.00 0.00 0.00 3.23 15.00 0.00 0.00 44
Modification total 0.00 0.00 0.00 11.82 26.89 0.00 0.00 140
Total 55.59 53.42 50.63 44.21 42.57 36.27 27.49 2919
Table 6: Primary evaluation F-scores by event type. The ?size? column gives the number of annotations of each type
in the given data (training+development). Best result for each type shown in bold.
The best performance for simple events and for
PROCESS approaches or exceeds 70% F-score, ar-
guably approaching a sufficient level for user-facing
applications of the extraction technology. By con-
trast, BINDING and regulation events, found chal-
lenging in ST?09 and GE, remain problematic also
in the ID task, with best overall performance below
50% F-score. Only two teams, UTurku and Con-
cordU (Kilicoglu and Bergler, 2011), attempted to
extract event modifications, with somewhat limited
performance. The difficulty of correct extraction of
event modifications is related in part to the recursive
nature of the problem (similarly as for nested reg-
ulation events): to extract a modification correctly,
the modified event must also be extracted correctly.
Further, only UTurku predicted any instances of sec-
ondary arguments. Thus, teams other than UTurku
and ConcordU addressed only the core task extrac-
tion targets. With the exception of ConcordU, all
systems clearly favor precision over recall (Table 7),
in many cases having over 15% point higher preci-
sion than recall. This a a somewhat unexpected in-
version, as the ConcordU system is one of the two
rule-based in the task, an approach typically associ-
ated with high precision.
The five top-ranking systems participated also in
the GE task (Kim et al, 2011b), which involves a
subset of the ID extraction targets. This allows ad-
ditional perspective into the relative performance of
the systems. While there is a 13% point spread in
overall results for the top five systems here, in GE
all these systems achieved F-scores ranging between
50?56%. The results for FAUST, UMass and Stan-
ford were similar in both tasks, while the ConcordU
result was 6% points higher for GE and the UTurku
result over 10% points higher for GE, ranking third
after FAUST and UMass. These results suggest that
while the FAUST and UMass systems in particular
have some systematic (e.g. architectural) advantage
at both tasks, much of the performance difference
observed here between the top three systems and
those of ConcordU and UTurku is due to strengths
or weaknesses specific to ID. Possible weaknesses
may relate to the treatment of multiple core entity
types (vs. only PROTEIN in GE) or challenges re-
lated to nested entity annotations (not appearing in
GE). A possible ID-specific strength of the three
top-ranking systems is the use of GE data for train-
ing: Riedel and McCallum (2011) report an esti-
mated 7% point improvement and McClosky et al
(2011) a 3% point improvement from use of this
data; McGrath et al (2011) estimate a 1% point im-
provement from direct corpus combination. The in-
tegration strategies applied in training these systems
32
Team recall prec. F-score ?
FAUST 50.62 66.06 57.32 1.73
UMass 49.45 62.11 55.06 1.64
Stanford 48.87 56.03 52.20 1.57
ConcordU 50.77 43.25 46.71 2.50
UTurku 38.79 49.35 43.44 0.87
PNNL 29.36 52.62 37.69 1.42
PredX 23.67 35.18 28.30 0.81
Table 8: Core task evaluation results. The ? column
gives the F-score difference to the corresponding full task
(primary) result.
could potentially be applied also with other systems,
an experiment that could further clarify the relative
strengths of the various systems. The top-ranking
five systems all participated also in the EPI task
(Ohta et al, 2011), for which UTurku ranked first
with FAUST having comparable performance for the
core task. While this supports the conclusion that
ID performance differences do not reflect a simple
universal ranking of the systems, due to many sub-
stantial differences between the ID and EPI setups it
is not straightforward to identify specific reasons for
relative differences to performance at EPI.
Table 8 summarizes the core task results. There
are only modest and largely consistent differences to
the corresponding full task results, reflecting in part
the relative sparseness of additional arguments: in
the training data, for example, only approximately
3% of instances of event types that can potentially
take additional arguments had at least one additional
argument. While event modifications represent a
further 4% of full task extraction targets not required
for the core task, the overall low extraction perfor-
mance for additional arguments and modifications
limits the practical effect of these annotation cate-
gories on the performance difference between sys-
tems addressing only the core targets and those ad-
dressing the full task.
6 Discussion and Conclusions
We have presented the preparation, resources, re-
sults and analysis of the Infectious Diseases (ID)
task of the BioNLP Shared Task 2011. A corpus
of 30 full-text publications on the two-component
systems subdomain of infectious diseases was cre-
ated for the task in a collaboration of event annota-
tion and domain experts, adapting and extending the
BioNLP?09 Shared Task (ST?09) event representa-
tion to the domain.
Seven teams submitted final results to the ID task.
Despite the novel challenges of full papers, four new
entity types, extension of event scopes and the intro-
duction of a new event category for high-level pro-
cesses, the highest results for the full ID task were
comparable to the state-of-the-art performance on
the established ST?09 data, showing that the event
extraction approach and present systems generalize
well and demonstrating the feasibility of event ex-
traction for the infectious diseases domain. Analy-
sis of results suggested further opportunities for im-
proving extraction performance by combining the
strengths of various systems and the use of other
event resources.
The task design takes into account the needs
of supporting practical applications, and its results
and findings will be adopted in future development
of the Pathosystems Resource Integration Center4
(PATRIC). Specifically, PATRIC will combine do-
main named entity recognition and event extraction
to mine the virulence factor literature and integrate
the results with literature search and retrieval ser-
vices, protein feature analysis, and systems such as
Disease View.5 Present and future advances at the
ID event extraction task can thus assist biologists in
efforts of substantial public health interest.
The ID task will be continued as an open
shared task challenge with data, supporting re-
sources, and evaluation tools freely available from
the shared task site, http://sites.google.
com/site/bionlpst/.
Acknowledgments
This work was supported by Grant-in-Aid for Spe-
cially Promoted Research (MEXT, Japan). This
project has been funded in whole or in part with Fed-
eral funds from the National Institute of Allergy and
Infectious Diseases, National Institutes of Health,
Department of Health and Human Services, under
Contract No. HHSN272200900040C, awarded to
BWS Sobral.
4http://patricbrc.org
5See for example http://patricbrc.org/portal/
portal/patric/DiseaseOverview?cType=
taxon&cId=77643
33
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
Sophia Ananiadou, Dan Sullivan, William Black, Gina-
Anne Levow, Joseph J. Gillespie, Chunhong Mao,
Sampo Pyysalo, BalaKrishna Kolluru, Junichi Tsujii,
and Bruno Sobral. 2011. Named entity recognition
for bacterial type IV secretion systems. PLoS ONE,
6(3):e14780.
M Ashburner, CA Ball, JA Blake, D Botstein, H Butler,
JM Cherry, AP Davis, K Dolinski, SS Dwight, JT Ep-
pig, MA Harris, DP Hill, L Issel-Tarver, A Kasarskis,
S Lewis, JC Matese, JE Richardson, M Ringwald,
GM Rubin, and G Sherlock. 2000. Gene ontology:
tool for the unification of biology. Nature genetics,
25:25?29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing biomedical event extraction. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL?05), pages 173?180.
Peter Corbett and Peter Murray-Rust. 2006. High-
throughput identification of chemistry in life science
texts. Computational Life Sciences II, pages 107?118.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
Martin Gerner, Goran Nenadic, and Casey M. Bergman.
2010. LINNAEUS: a species name identification sys-
tem for biomedical literature. BMC bioinformatics,
11(1):85+, February.
Yasuhiro Gotoh, Yoko Eguchi, Takafumi Watanabe, Sho
Okamoto, Akihiro Doi, and Ryutaro Utsumi. 2010.
Two-component signal transduction as potential drug
targets in pathogenic bacteria. Current Opinion in Mi-
crobiology, 13(2):232?239. Cell regulation.
Halil Kilicoglu and Sabine Bergler. 2011. Adapting a
general semantic interpretation approach to biological
event extraction. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier, editors. 2004. Intro-
duction to the bio-entity recognition task at JNLPBA,
Geneva, Switzerland.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
lterature. BMC Bioinformatics, 9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011a. Overview
of BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011b. Overview of the Genia Event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
M. Krallinger, A. Morgan, L. Smith, F. Leitner, L. Tan-
abe, J. Wilbur, L. Hirschman, and A. Valencia.
2008. Evaluation of text-mining systems for biology:
overview of the Second BioCreative community chal-
lenge. Genome biology, 9(Suppl 2):S1.
Tino Krell, Jess Lacal, Andreas Busch, Hortencia Silva-
Jimnez, Mara-Eugenia Guazzaroni, and Juan Luis
Ramos. 2010. Bacterial sensor kinases: Diversity in
the recognition of environmental signals. Annual Re-
view of Microbiology, 64(1):539?559.
Thorsten Mascher, John D. Helmann, and Gottfried Un-
den. 2006. Stimulus perception in bacterial signal-
transducing histidine kinases. Microbiol. Mol. Biol.
Rev., 70(4):910?938.
David McClosky, Mihai Surdeanu, and Christopher Man-
ning. 2011. Event extraction as dependency parsing
for bionlp 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
David McClosky. 2009. Any Domain Parsing: Auto-
matic Domain Adaptation for Natural Language Pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Liam McGrath, Kelly Domico, Courtney Corley, and
Bobbie-Jo Webb-Robertson. 2011. Complex biologi-
cal event extraction from full text using signatures of
linguistic and semantic features. In Proceedings of
34
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and
Jun?ichi Tsujii. 2010. Evaluating dependency repre-
sentation for event extraction. In Proceedings of COL-
ING?10, pages 779?787.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009. Incorporating
GENETAG-style annotation to GENIA corpus. In
Proceedings of BioNLP?09, pages 106?107.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, Han-Cheol Cho, Dan Sul-
livan, Chunhong Mao, Bruno Sobral, Jun?ichi Tsujii,
and Sophia Ananiadou. 2010. Towards event extrac-
tion from full texts on infectious diseases. In Proceed-
ings of BioNLP?10, pages 132?140.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sulli-
van, Chunhong Mao, Chunxia Wang, Bruno Sobral,
Jun?ichi Tsujii, and Sophia Ananiadou. 2011. An-
notation guidelines for infectious diseases event cor-
pus. Technical report, Tsujii Laboratory, University of
Tokyo. To appear.
Sebastian Riedel and Andrew McCallum. 2011. Ro-
bust biomedical event extraction with dual decompo-
sition and minimal domain adaptation. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Sebastian Riedel, David McClosky, Mihai Surdeanu, An-
drew McCallum, and Chris Manning. 2011. Model
combination for event extraction in bionlp 2011. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
Yutaka Sasaki, Yoshimasa Tsuruoka, John McNaught,
and Sophia Ananiadou. 2008. How to make the most
of NE dictionaries in statistical NER. BMC bioinfor-
matics, 9 Suppl 11.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
Peter Thomason and Rob Kay. 2000. Eukaryotic sig-
nal transduction via histidine-aspartate phosphorelay.
J Cell Sci, 113(18):3141?3150.
Yue Wang, Jin-Dong Kim, Rune S?tre, Sampo Pyysalo,
and Jun?ichi Tsujii. 2009. Investigating heteroge-
neous protein annotations toward cross-corpora uti-
lization. BMC Bioinformatics, 10(403).
Chunxia Wang, Jocelyn Kemp, Isabel O. Da Fonseca,
Raymie C. Equi, Xiaoyan Sheng, Trevor C. Charles,
and Bruno W. S. Sobral. 2010. Sinorhizobium
meliloti 1021 loss-of-function deletion mutation in
chvi and its phenotypic characteristics. Molecular
Plant-Microbe Interactions, 23(2):153?160.
35
Proceedings of BioNLP Shared Task 2011 Workshop, pages 83?88,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Overview of the Entity Relations (REL) supporting task of
BioNLP Shared Task 2011
Sampo Pyysalo? Tomoko Ohta? Jun?ichi Tsujii?
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Microsoft Research Asia, Beijing, China
{smp,okap}@is.s.u-tokyo.ac.jp, jtsujii@microsoft.com
Abstract
This paper presents the Entity Relations
(REL) task, a supporting task of the BioNLP
Shared Task 2011. The task concerns the ex-
traction of two types of part-of relations be-
tween a gene/protein and an associated en-
tity. Four teams submitted final results for the
REL task, with the highest-performing system
achieving 57.7% F-score. While experiments
suggest use of the data can help improve event
extraction performance, the task data has so
far received only limited use in support of
event extraction. The REL task continues as
an open challenge, with all resources available
from the shared task website.
1 Introduction
The BioNLP Shared Task 2011 (BioNLP ST?11)
(Kim et al, 2011a), the follow-up event to the
BioNLP?09 Shared Task (Kim et al, 2009), was
organized from August 2010 (sample data release)
to March 2011. The shared task was divided into
two stages, with supporting tasks carried out be-
fore the main tasks. The motivation for this task
setup drew in part from analysis of the results of the
previous shared task, which suggested that events
that involve coreference or entity relations repre-
sent particular challenges for extraction. To help ad-
dress these challenges and encourage modular ex-
traction approaches, increased sharing of successful
solutions, and an efficient division of labor, the two
were separated into independent supporting tasks on
Coreference (CO) (Nguyen et al, 2011) and Entity
Relations in BioNLP ST?11. This paper presents the
Entity Relations (REL) supporting task.
2 Task Setting
In the design of the REL task, we followed the gen-
eral policy of the shared task in assuming named
entity recognition (NER) as a given starting point:
participants were provided with manually annotated
gold standard annotations identifying gene/protein
names in all of the training, development, and final
test data. By limiting effects due to NER perfor-
mance, the task remains more specifically focused
on the key challenge studied.
Following the results and analysis from previous
studies (Pyysalo et al, 2009; Ohta et al, 2010), we
chose to limit the task specifically to relations in-
volving a gene/protein named entity (NE) and one
other entity. Fixing one entity involved in each re-
lation to an NE helps assure that the relations are
?anchored? to real-world entities, and the specific
choice of the gene/protein NE class further pro-
vides a category with several existing systems and
substantial ongoing efforts addressing the identifica-
tion of those referents through named entity recog-
nition and normalization (Leaman and Gonzalez,
2008; Hakenberg et al, 2008; Krallinger et al, 2008;
Morgan et al, 2008; Wermter et al, 2009). The
recognition of biologically relevant associations of
gene/protein NEs is a key focus of the main event
extraction tasks of the shared task. By contrast, in
the REL task setting, only one participant in each
binary relation is a gene/protein NE, while the other
can be either a non-name reference such as promoter
or the name of an entity not of the gene/protein type
(e.g. a complex).1 Motivated in part by the relatively
limited number of existing methods for the detec-
1Pronominal references are excluded from annotation scope.
83
Figure 1: Simple REL annotation example showing a
PROTEIN-COMPONENT (PR-CO) relation between ?hi-
stone H3? and ?lysine 9?. An associated METHYLATION
event and its arguments (shaded, not part of the REL task
targets) shown for context.
tion of such entity references, their detection is in-
cluded in the task: participants must recognize these
secondary entities in addition to extracting the rela-
tions they participate in. To limit the demands of this
NER-type task, these entities are not assigned spe-
cific types but rather the generic type ENTITY, and
exact matching of their boundaries is not required
(see Section 4).
The general task setting encompasses a rich set
of potential relation extraction targets. For the task,
we aimed to select relations that minimize overlap
between the targets of other tasks while maintain-
ing relevance as a supporting goal. As the main
tasks primarily target events (?things that happen?)
involving change in entities, we chose to focus in
the REL task on what we have previously termed
?static relations? (Pyysalo et al, 2009), that is, rela-
tions such as part-of that hold between entities with-
out necessary implication of causality or change. A
previous study by Van Landeghem et al (2010) in-
dicated that this class of relations may benefit event
extraction. We based our choice of specific target
relation on previous studies of entity relations do-
main texts (Pyysalo et al, 2009; Ohta et al, 2010),
which indicated that part-whole relations are by far
the most frequent class of relevant relations for the
task setting and proposed a classification of these
relations for biomedical entities. We further found
that ? in terms of the taxonomy of Winston et al
(1987) ? object-component and collection-member
relations account for the the great majority of part-
of relations relevant to the domain. For REL, we
chose to omit collection-member relations in part to
minimize overlap with the targets of the coreference
task. Instead, we focused on two specific types of
object-component relations, that holding between a
gene or protein and its part (domain, regions, pro-
moters, amino acids, etc.) and that between a protein
Item Training Devel Test
Abstract 800 150 260
Word 176,146 33,827 57,256
Protein 9,297 2,080 3,589
Relation 1,857 480 497
PROTEIN-COMPONENT 1,302 314 334
SUBUNIT-COMPLEX 555 166 163
Table 1: REL dataset statistics.
and a complex that it is a subunit of. Following the
biological motivation and the general practice in the
shared task to term genes and gene products PRO-
TEIN for simplicity, we named these two relations
PROTEIN-COMPONENT and SUBUNIT-COMPLEX.
Figure 1 shows an illustration of a simple relation
with an associated event (not part of REL). Events
with Site arguments such as that shown in the figure
are targeted in the GE, EPI, and ID tasks (Kim et al,
2011b; Ohta et al, 2011; Pyysalo et al, 2011) that
REL is intended to support.
3 Data
The task dataset consists of new annotations for
the GENIA corpus (Kim et al, 2008), building on
the existing biomedical term annotation (Ohta et
al., 2002), the gene and gene product name annota-
tion (Ohta et al, 2009) and the syntactic annotation
(Tateisi et al, 2005) of the corpus. The general fea-
tures of the annotation are presented by Pyysalo et
al. (2009), describing a previous release of a subset
of the data. The REL task annotation effort extended
the coverage of the previously released annotation to
all relations of the targeted types stated within sen-
tence scope in the GENIA corpus.
For compatibility with the BioNLP ST?09 and its
repeat as the GE task in 2011 (Kim et al, 2011b),
the REL task training/development/test set division
of the GENIA corpus abstracts matches that of the
BioNLP ST?09 data. The statistics of the corpus are
presented in Table 1. We note that both in terms of
training examples and the data available in the given
development set, the number of examples of the
PROTEIN-COMPONENT relation is more than twice
that for SUBUNIT-COMPLEX. Thus, at least for
methods based on machine learning, we might gen-
erally expect to find higher extraction performance
for the former relation.
84
NLP Extraction Other resources
Rank Team Org Word Parse Entities Relations Corpora Other
1 UTurku 1BI Porter McCCJ + SD SVM SVM - -
2 VIBGhent 1NLP, 1ML, 1BI Porter McCCJ + SD SVM SVM GENIA, PubMed word similarities
3 ConcordU 2NLP - McCCJ + SD Dict Rules - -
3 HCMUS 6L OpenNLP OpenNLP Dict Rules - -
Table 2: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural
Language Processing researcher, ML=Machine Learning researcher, L=Linguist, Porter=Porter stemmer,
McCCJ=McClosky-Charniak-Johnson parser, SD=Stanford Dependency conversion, Dict=Dictionary
UTurku VIBGhent ConcordU HCMUS
PROTEIN-COMPONENT 50.90 / 68.57 / 58.43 47.31 / 36.53 / 41.23 23.35 / 52.05 / 32.24 20.96 / 21.63 / 21.29
SUBUNIT-COMPLEX 48.47 / 66.95 / 56.23 47.85 / 38.12 / 42.43 26.38 / 39.81 / 31.73 4.91 / 66.67 / 9.14
Total 50.10 / 68.04 / 57.71 47.48 / 37.04 / 41.62 24.35 / 46.85 / 32.04 15.69 / 23.26 / 18.74
Table 3: Primary evaluation results for the REL task. Results given as recall / precision / F-score.
4 Evaluation
The evaluation of the REL task is relation-based and
uses the standard precision/recall/F1-score metrics.
Similarly to the BioNLP?09 ST and most of the 2011
main tasks, the REL task relaxes the equality criteria
for matching text-bound annotations: for a submis-
sion entity to match an entity in the gold reference
annotation, it is sufficient that the span of the sub-
mitted entity (i.e. its start and end positions in text)
is entirely contained within the span of the gold an-
notation. This corresponds largely to the approxi-
mate span matching criterion of the 2009 task (Kim
et al, 2009), although the REL criterion is slightly
stricter in not involving testing against an extension
of the gold entity span. Relation matching is exact:
for a submitted relation to match a gold one, both its
type and the related entities must match.
5 Results
5.1 Participation
Table 2 summarizes the participating groups and ap-
proaches. We find a remarkable number of sim-
ilarities between the approaches of the systems,
with all four utilizing full parsing and a depen-
dency representation of the syntactic analysis, and
the three highest-ranking further specifically the
phrase structure parser of Charniak and Johnson
(2005) with the biomedical domain model of Mc-
Closky (2009), converted into Stanford Dependency
form using the Stanford tools (de Marneffe et al,
2006). These specific choices may perhaps be influ-
enced by the success of systems building on them
in the 2009 shared task (e.g. Bjo?rne et al (2009)).
While UTurku (Bjo?rne and Salakoski, 2011) and
VIBGhent (Van Landeghem et al, 2011) further
agree in the choice of Support Vector Machines for
the recognition of entities and the extraction of rela-
tions, ConcordU (Kilicoglu and Bergler, 2011) and
HCMUS (Le Minh et al, 2011) pursue approaches
building on dictionary- and rule-based extraction.
Only the VIBGhent system makes use of resources
external to those provided for the task, extracting
specific semantic entity types from the GENIA cor-
pus as well as inducing word similarities from a
large unannotated corpus of PubMed abstracts.
5.2 Evaluation results
Table 3 shows the results of the REL task. We find
that the four systems diverge substantially in terms
of overall performance, with all pairs of systems
of neighboring ranks showing differences approach-
ing or exceeding 10% points in F-score. While
three of the systems notably favor precision over re-
call, VIBGhent shows a decided preference for re-
call, suggesting a different approach from UTurku in
design details despite the substantial similarities in
overall system architecture. The highest-performing
85
system, UTurku, shows an F-score in the general
range of state-of-the-art results in the main event
extraction task, which could be taken as an indica-
tion that the reliability of REL task analyses created
with presently available methods may not be high
enough for direct use as a building block for the
main tasks. However, the emphasis of the UTurku
system on precision is encouraging for such ap-
plications: nearly 70% of the entity-relation pairs
that the system predicts are correct. The two top-
ranking systems show similar precision and recall
results for the two relation types. The submission of
HCMUS shows a decided advantage for PROTEIN-
COMPONENT relation extraction as tentatively pre-
dicted from the relative numbers of training exam-
ples (Section 3 and Table 1), but their rule-based
approach suggests training data size is likely not
the decisive factor. While the limited amount of
data available prevents strong conclusions from be-
ing drawn, overall the lack of correlation between
training data size and extraction performance sug-
gests that performance may not be primarily limited
by the size of the available training data.
6 Discussion
The REL task was explicitly cast in a support role
for the main event extraction tasks, and REL par-
ticipants were encouraged to make their predictions
of the task extraction targets for the various main
task datasets available to main task participants. The
UTurku team responded to this call for supporting
analyses, running their top-ranking REL task sys-
tem on all main task datasets and making its output
available as a supporting resource (Stenetorp et al,
2011). In the main tasks, we are so far aware of
one application of this data: the BMI@ASU team
(Emadzadeh et al, 2011) applied the UTurku REL
predictions as part of their GE task system for re-
solving the Site arguments in events such as BIND-
ING and PHOSPHORYLATION (see Figure 1). While
more extensive use of the data would have been de-
sirable, we find this application of the REL analyses
very appropriate to our general design for the role of
the supporting and main tasks and hope to see other
groups pursue similar possibilities in future work.
7 Conclusions
We have presented the preparation, resources, re-
sults and analysis of the Entity Relations (REL) task,
a supporting task of the BioNLP Shared Task 2011
involving the recognition of two specific types of
part-of relations between genes/proteins and associ-
ated entities. The task was run in a separate early
stage in the overall shared task schedule to allow
participants to make use of methods and analyses for
the task as part of their main task submissions.
Of four teams submitting finals results, the
highest-performing system, UTurku, achieved a pre-
cision of 68% at 50% recall (58% F-score), a
promising level of performance given the relative
novelty of the specific extraction targets and the
short development period. Nevertheless, challenges
remain for achieving a level of reliability that would
allow event extraction systems to confidently build
on REL analyses to address the main information
extraction tasks. The REL task submissions, repre-
senting four independent perspectives into the task,
are a valuable resource for further study of both the
original task data as well as the relative strengths and
weaknesses of the participating systems. In future
work, we will analyse this data in detail to better
understand the challenges of the task and effective
approached for addressing them.
The UTurku team responded to a call for sup-
porting analyses by providing predictions from their
REL system for all BioNLP Shared Task main task
datasets. These analyses were adopted by at least
one main task participant as part of their system,
and we expect that this resource will continue to
serve to facilitate the study of the position of part-
of relations in domain event extraction. The REL
task will continue as an open shared challenge, with
all task data, evaluation software, and analysis tools
available to all interested parties from http://
sites.google.com/site/bionlpst/.
Acknowledgments
We would like to thank the UTurku team for their
generosity with their time and tools in providing
REL task analyses for all the BioNLP Shared Task
2011 main task datasets. This work was supported
by Grant-in-Aid for Specially Promoted Research
(MEXT, Japan).
86
References
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing biomedical event extraction. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In Proceedings of the BioNLP 2009 Work-
shop Companion Volume for Shared Task, pages 10?
18, Boulder, Colorado, June. Association for Compu-
tational Linguistics.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL?05), pages 173?180.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
Ehsan Emadzadeh, Azadeh Nikfarjam, and Graciela
Gonzalez. 2011. Double layered learning for bio-
logical event extraction from text. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
J. Hakenberg, C. Plake, R. Leaman, M. Schroeder,
and G. Gonzalez. 2008. Inter-species normaliza-
tion of gene mentions with GNAT. Bioinformatics,
24(16):i126.
Halil Kilicoglu and Sabine Bergler. 2011. Adapting a
general semantic interpretation approach to biological
event extraction. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011a. Overview
of BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011b. Overview of the Genia Event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
M. Krallinger, A. Morgan, L. Smith, F. Leitner, L. Tan-
abe, J. Wilbur, L. Hirschman, and A. Valencia.
2008. Evaluation of text-mining systems for biology:
overview of the Second BioCreative community chal-
lenge. Genome biology, 9(Suppl 2):S1.
Quang Le Minh, Son Nguyen Truong, and Quoc Ho Bao.
2011. A pattern approach for biomedical event anno-
tation. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
R. Leaman and G. Gonzalez. 2008. Banner: an exe-
cutable survey of advances in biomedical named en-
tity recognition. Pacific Symposium on Biocomputing,
pages 652?663.
David McClosky. 2009. Any Domain Parsing: Auto-
matic Domain Adaptation for Natural Language Pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
A.A. Morgan, Z. Lu, X. Wang, A.M. Cohen, J. Fluck,
P. Ruch, A. Divoli, K. Fundel, R. Leaman, J. Haken-
berg, et al 2008. Overview of BioCreative II gene
normalization. Genome biology, 9(Suppl 2):S3.
Ngan Nguyen, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
Overview of the Protein Coreference task in BioNLP
Shared Task 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Tomoko Ohta, Yuka Tateisi, Hideki Mima, and Jun?ichi
Tsujii. 2002. GENIA corpus: An annotated research
abstract corpus in molecular biology domain. In Pro-
ceedings of the Human Language Technology Confer-
ence (HLT?02), pages 73?77.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009. Incorporating
GENETAG-style annotation to GENIA corpus. In
Proceedings of BioNLP?09, pages 106?107.
Tomoko Ohta, Sampo Pyysalo, Jin-Dong Kim, and
Jun?ichi Tsujii. 2010. A re-evaluation of biomedical
named entity-term relations. Journal of Bioinformat-
ics and Computational Biology (JBCB), 8(5):917?928.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
87
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static Relations: a Piece
in the Biomedical Information Extraction Puzzle.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9, Boulder, Colorado. Association for Computa-
tional Linguistics.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun?ichi Tsujii. 2005. Syntax annotation for the GE-
NIA corpus. In Proceedings of IJCNLP?05, pages
222?227.
Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,
and Yves Van de Peer. 2010. Integration of static re-
lations to enhance event extraction from text. In Pro-
ceedings of the 2010 Workshop on Biomedical Natural
Language Processing, pages 144?152.
Sofie Van Landeghem, Thomas Abeel, Bernard De Baets,
and Yves Van de Peer. 2011. Detecting entity rela-
tions as a supporting task for bio-molecular event ex-
traction. In Proceedings of the BioNLP 2011 Work-
shop Companion Volume for Shared Task, Portland,
Oregon, June. Association for Computational Linguis-
tics.
J. Wermter, K. Tomanek, and U. Hahn. 2009. High-
performance gene name normalization with GeNo.
Bioinformatics, 25(6):815.
Morton E. Winston, Roger Chaffin, and Douglas Her-
rmann. 1987. A taxonomy of part-whole relations.
Cognitive Science, 11.
88
Proceedings of BioNLP Shared Task 2011 Workshop, pages 112?120,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
BioNLP Shared Task 2011: Supporting Resources
Pontus Stenetorp: Goran Topic? Sampo Pyysalo
Tomoko Ohta Jin-Dong Kim; and Jun?ichi Tsujii$
Tsujii Laboratory, Department of Computer Science, University of Tokyo, Tokyo, Japan
:Aizawa Laboratory, Department of Computer Science, University of Tokyo, Tokyo, Japan
; Database Center for Life Science,
Research Organization of Information and Systems, Tokyo, Japan
$Microsoft Research Asia, Beijing, People?s Republic of China
{pontus,goran,smp,okap}@is.s.u-tokyo.ac.jp
jdkim@dbcls.rois.ac.jp
jtsujii@microsoft.com
Abstract
This paper describes the supporting resources
provided for the BioNLP Shared Task 2011.
These resources were constructed with the
goal to alleviate some of the burden of sys-
tem development from the participants and al-
low them to focus on the novel aspects of con-
structing their event extraction systems. With
the availability of these resources we also seek
to enable the evaluation of the applicability of
specific tools and representations towards im-
proving the performance of event extraction
systems. Additionally we supplied evaluation
software and services and constructed a vi-
sualisation tool, stav, which visualises event
extraction results and annotations. These re-
sources helped the participants make sure that
their final submissions and research efforts
were on track during the development stages
and evaluate their progress throughout the du-
ration of the shared task. The visualisation
software was also employed to show the dif-
ferences between the gold annotations and
those of the submitted results, allowing the
participants to better understand the perfor-
mance of their system. The resources, evalu-
ation tools and visualisation tool are provided
freely for research purposes and can be found
at http://sites.google.com/site/bionlpst/
1 Introduction
For the BioNLP?09 Shared Task (Kim et al, 2009),
the first in the ongoing series, the organisers pro-
vided the participants with automatically generated
syntactic analyses for the sentences from the anno-
tated data. For evaluation purposes, tools were made
publicly available as both distributed software and
online services. These resources were well received.
A majority of the participants made use of one or
more of the syntactic analyses, which have remained
available after the shared task ended and have been
employed in at least two independent efforts study-
ing the contribution of different tools and forms of
syntactic representation to the domain of informa-
tion extraction (Miwa et al, 2010; Buyko and Hahn,
2010). The evaluation software for the BioNLP?09
Shared Task has also been widely adopted in subse-
quent studies (Miwa et al, 2010; Poon and Vander-
wende, 2010; Bjo?rne et al, 2010).
The reception and research contribution from pro-
viding these resources encouraged us to continue
providing similar resources for the BioNLP Shared
Task 2011 (Kim et al, 2011a). Along with the
parses we also encouraged the participants and ex-
ternal groups to process the data with any NLP (Nat-
ural Language Processing) tools of their choice and
make the results available to the participants.
We provided continuous verification and evalua-
tion of the participating systems using a suite of in-
house evaluation tools. Lastly, we provided a tool
for visualising the annotated data to enable the par-
ticipants to better grasp the results of their experi-
ments and to help gain a deeper understanding of
the underlying concepts and the annotated data. This
paper presents these supporting resources.
2 Data
This section introduces the data resources provided
by the organisers, participants and external groups
for the shared task.
112
Task Provider Tool
CO University of Utah Reconcile
CO University of Zu?rich UZCRS
CO University of Turku TEES
REL University of Turku TEES
Table 1: Supporting task analyses provided, TEES
is the Turku Event Extraction System and UZCRS
is the University of Zu?rich Coreference Resolution
System
2.1 Supporting task analyses
The shared task included three Supporting Tasks:
Coreference (CO) (Nguyen et al, 2011), Entity re-
lations (REL) (Pyysalo et al, 2011b) and Gene re-
naming (REN) (Jourde et al, 2011). In the shared
task schedule, the supporting tasks were carried out
before the main tasks (Kim et al, 2011b; Pyysalo
et al, 2011a; Ohta et al, 2011; Bossy et al, 2011)
in order to allow participants to make use of analy-
ses from the systems participating in the Supporting
Tasks for their main task event extraction systems.
Error analysis of BioNLP?09 shared task sub-
missions indicated that coreference was the most
frequent feature of events that could not be cor-
rectly extracted by any participating system. Fur-
ther, events involving statements of non-trivial rela-
tions between participating entities were a frequent
cause of extraction errors. Thus, the CO and REL
tasks were explicitly designed to support parts of
the main event extraction tasks where it had been
suggested that they could improve the system per-
formance.
Table 1 shows the supporting task analyses pro-
vided to the participants. For the main tasks, we
are currently aware of one group (Emadzadeh et al,
2011) that made use of the REL task analyses in their
system. However, while a number of systems in-
volved coreference resolution in some form, we are
not aware of any teams using the CO task analyses
specifically, perhaps due in part to the tight sched-
ule and the somewhat limited results of the CO task.
These data will remain available to allow future re-
search into the benefits of these resources for event
extraction.
2.2 Syntactic analyses
For syntactic analyses we provided parses for all
the task data in various formats from a wide range
of parsers (see Table 2). With the exception of
the Pro3Gres1 parser (Schneider et al, 2007), the
parsers were set up and run by the task organisers.
The emphasis was put on availability for research
purposes and variety of parsing models and frame-
works to allow evaluation of their applicability for
different tasks.
In part following up on the results of Miwa et al
(2010) and Buyko and Hahn (2010) regarding the
impact on performance of event extraction systems
depending on the dependency parse representation,
we aimed to provide several dependency parse for-
mats. Stanford Dependencies (SD) and Collapsed
Stanford Dependencies (SDC), as described by de
Marneffe et al (2006), were generated by convert-
ing Penn Treebank (PTB)-style (Marcus et al, 1993)
output using the Stanford CoreNLP Tools2 into the
two dependency formats. We also provided Confer-
ence on Computational Natural Language Learning
style dependency parses (CoNLL-X) (Buchholz and
Marsi, 2006) which were also converted from PTB-
style output, but for this we used the conversion
tool3 from Johansson and Nugues (2007). While
this conversion tool was not designed with convert-
ing the output from statistical parsers in mind (but
rather to convert between treebanks), it has previ-
ously been applied successfully for this task (Miyao
et al, 2008; Miwa et al, 2010).
The text from all documents provided were split
into sentences using the Genia Sentence Splitter4
(S?tre et al, 2007) and then postprocessed using a
set of heuristics to correct frequently occurring er-
rors. The sentences were then tokenised using a to-
kenisation script created by the organisers intended
to replicate the tokenisation of the Genia Tree Bank
(GTB) (Tateisi et al, 2005). This tokenised and
sentence-split data was then used as input for all
parsers.
We used two deep parsers that provide phrase
structure analysis enriched with deep sentence struc-
1https://files.ifi.uzh.ch/cl/gschneid/parser/
2http://nlp.stanford.edu/software/corenlp.shtml
3http://nlp.cs.lth.se/software/treebank converter/
4http://www-tsujii.is.s.u-tokyo.ac.jp/y-matsu/geniass/
113
Name Format(s) Model Availability BioNLP?09
Berkeley PTB, SD, SDC, CoNLL-X News Binary, Source No
C&C CCG, SD Biomedical Binary, Source Yes
Enju HPSG, PTB, SD, SDC, CoNLL-X Biomedical Binary No
GDep CoNLL-X Biomedical Binary, Source Yes
McCCJ PTB, SD, SDC, CoNLL-X Biomedical Source Yes
Pro3Gres Pro3Gres Combination ? No
Stanford PTB, SD, SDC, CoNLL-X Combination Binary, Source Yes
Table 2: Parsers, the formats for which their output was provided and which type of model that was used. The
availability column signifies public availability (without making an explicit request) for research purposes
tures, for example predicate-argument structure for
Head-Driven Phrase Structure Grammar (HPSG).
First we used the C&C Combinatory Categorial
Grammar (CCG) parser5 (C&C) by Clark and Cur-
ran (2004) using the biomedical model described in
Rimell and Clark (2009) which was trained on GTB.
Unlike all other parsers for which we supplied SD
and SDC dependency parses, the C&C output was
converted from its native format using a separate
conversion script provided by the C&C authors. Re-
grettably we were unable to provide CoNLL-X for-
mat output for this parser due to the lack of PTB-
style output. The other deep parser used was the
HPSG parser Enju6 by Miyao and Tsujii (2008), also
trained on GTB.
We also applied the frequently adopted Stanford
Parser7 (Klein and Manning, 2003) using a mixed
model which includes data from the biomedical do-
main, and the Charniak Johnson re-ranking parser8
(Charniak and Johnson, 2005) using the self-trained
biomedical model from McClosky (2009) (McCCJ).
For the BioNLP?09 shared task it was observed
that the Bikel parser9 (Bikel, 2004), which used a
non-biomedical model and can be argued that it uses
the somewhat dated Collins? parsing model (Collins,
1996), did not contribute towards event extraction
performance as strongly as other parses supplied for
the same data. We therefore wanted to supply a
parser that can compete with the ones above in a do-
main which is different from the biomedical domain
to see whether conclusions could be drawn as to the
5http://svn.ask.it.usyd.edu.au/trac/candc/
6http://www-tsujii.is.s.u-tokyo.ac.jp/enju/
7http://nlp.stanford.edu/software/lex-parser.shtml
8ftp://ftp.cs.brown.edu/pub/nlparser/
9http://www.cis.upenn.edu/dbikel/software.html
importance of using a biomedical model. For this
we used the Berkeley parser10 (Petrov et al, 2006).
Lastly we used a native dependency parser, the GE-
NIA Dependency parser (GDep) by Sagae and Tsujii
(2007).
At least one team (Choudhury et al, 2011) per-
formed experiments on some of the provided lexi-
cal analyses and among the 14 submissions for the
EPI and ID tasks, 13 submissions utilised tools for
which resources were provided by the organisers of
the shared task. We intend to follow up on whether
or not the majority of the teams ran the tools them-
selves or used the provided analyses.
2.3 Other analyses
The call for analyses was open to all interested par-
ties and all forms of analysis. In addition to the Sup-
porting Task analyses (CO and REL) and syntactic
analyses provided by various groups, the University
of Antwerp CLiPS center (Morante et al, 2010) re-
sponded to the call providing negation/speculation
analyses in the BioScope corpus format (Szarvas et
al., 2008).
Although this resource was not utilised by the par-
ticipants for the main task, possibly due to a lack of
time, it is our hope that by keeping the data available
it can lead to further development of the participat-
ing systems and analysis of BioScope and BioNLP
ST-style hedging annotations.
3 Tools
This section presents the tools produced by the or-
ganisers for the purpose of the shared task.
10http://code.google.com/p/berkeleyparser/
114
1 10411007-E1 Regulation <Exp>regulate[26-34] <Theme>TNF-alpha[79-88] ?
?<Excerpt>[regulate] an enhancer activity in the third intron of [TNF-alpha]
2 10411007-E2 Gene_expression <Exp>activity[282-290] <Theme>TNF-alpha[252-261] ?
?<Excerpt>[TNF-alpha] gene displayed weak [activity]
3 10411007-E3 +Regulation <Exp>when[291-295] <Theme>E2 <Excerpt>[when]
Figure 1: Text output from the BioNLP?09 Shared Event Viewer with line numbering and newline markings
Figure 2: An illustration of collective (sentence 1)
and distributive reading (sentence 2). ?Theme? is
abbreviated as ?Th? and ?Protein? as ?Pro? when
there is a lack of space
3.1 Visualisation
The annotation data in the format specified by the
shared task is not intended to be human-readable ?
yet researchers need to be able to visualise the data
in order to understand the results of their experi-
ments. However, there is a scarcity of tools that can
be used for this purpose. There are three available
for event annotations in the BioNLP ST format that
we are aware of.
One is the BioNLP?09 Shared Task Event
Viewer11, a simple text-based annotation viewer: it
aggregates data from the annotations, and outputs it
in a format (Figure 1) that is meant to be further pro-
cessed by a utility such as grep.
Another is What?s Wrong with My NLP12, which
visualises relation annotations (see Figure 3a) ? but
is unable to display some of the information con-
tained in the Shared Task data. Notably, the distribu-
tive and collective readings of an event are not dis-
tinguished (Figure 2). It also displays all annotations
on a single line, which makes reading and analysing
longer sentences, let alne whole documents, some-
what difficult.
The last one is U-Compare13 (Kano et al, 2009),
11http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/SharedTask/
downloads.shtml
12http://code.google.com/p/whatswrong/
13http://u-compare.org/bionlp2009.html
which is a comprehensive suite of tools designed for
managing NLP workflows, integrating many avail-
able services. However, the annotation visualisation
component, illustrated in Figure 3b, is not optimised
for displaying complex event structures. Each anno-
tation is marked by underlining its text segment us-
ing a different colour per annotation type, and a role
in an event is represented by a similarly coloured arc
between the related underlined text segments. The
implementation leaves some things to be desired:
there is no detailed information added in the display
unless the user explicitly requests it, and then it is
displayed in a separate panel, away from the text it
annotates. The text spacing makes no allowance for
the annotations, with opaque lines crossing over it,
with the effect of making both the annotations and
the text hard to read if the annotations are above a
certain degree of complexity.
As a result of the difficulties of these existing
tools, in order to extract a piece of annotated text
and rework it into a graph that could be embedded
into a publication, users usually read off the annota-
tions, then create a graph from scratch using vector
drawing or image editing software.
To address these issues, we created a visualisa-
tion tool named stav (stav Text Annotation Visual-
izer), that can read the data formatted according to
the Shared Task specification and aims to present it
to the user in a form that can be grasped at a glance.
Events and entities are annotated immediately above
the text, and the roles within an event by labelled
arcs between them (Figure 3c). In a very complex
graph, users can highlight the object or association
of interest to follow it even more easily. Special fea-
tures of annotations, such as negation or speculation,
are shown by unique visual cues, and more in-depth,
technical information that is usually not required can
be requested by floating the mouse cursor over the
annotation (as seen in Figure 5).
We took care to minimise arc crossovers, and to
115
(a) Visualisation using What?s Wrong with My NLP
(b) Visualisation using U-Compare
(c) Visualisation using stav
Figure 3: Different visualisations of complex textual annotations of Dickensheets et al (1999)
116
Figure 4: A screenshot of the stav file-browser
keep them away from the text itself, in order to main-
tain text readability. The text is spaced to accommo-
date the annotations between the rows. While this
does end up using more screen real-estate, it keeps
the text legible, and annotations adjacent to the text.
The text is broken up into lines, and each sentence
is also forced into a new line, and given a numer-
ical identifier. The effect of this is that the text is
laid out vertically, like an article would be, but with
large spacing to accomodate the annotations. The
arcs are similarly continued on successive lines, and
can easily be traced ? even in case of them spanning
multiple lines, by the use of mouseover highlight-
ing. To preserve the distributionality information of
the annotation, any event annotations are duplicated
for each event, as demonstrated in the example in
Figure 2.
stav is not limited to the Shared Task datasets with
appropriate configuration settings, it could also vi-
sualise other kinds of relational annotations such as:
frame structures (Fillmore, 1976) and dependency
parses (de Marneffe et al, 2006).
To achieve our objectives above, we use the Dy-
namic Scalable Vector Graphics (SVG) functional-
ity (i.e. SVG manipulated by JavaScript) provided
by most modern browsers to render the WYSIWYG
(What You See Is What You Get) representation of
the annotated document. An added benefit from
this technique is that the installation process, if any,
is very simple: although not all browsers are cur-
rently supported, the two that we specifically tested
against are Safari14 and Google Chrome15; the for-
mer comes preinstalled with the Mac OS X oper-
ating system, while the latter can be installed even
by relatively non-technical users. The design is kept
modular using a dispatcher pattern, in order to al-
low the inclusion of the visualiser tool into other
JavaScript-based projects. The client-server archi-
tecture also allows centralisation of data, so that ev-
ery user can inspect an uploaded dataset without the
hassle of downloading and importing into a desktop
application, simply by opening an URL which can
uniquely identify a document, or even a single an-
notation. A screenshot of the stav file browser can
be seen in Figure 4.
3.2 Evaluation Tools
The tasks of BioNLP-ST 2011 exhibit very high
complexity, including multiple non-trivial subprob-
lems that are partially, but not entirely, independent
of each other. With such tasks, the evaluation of par-
ticipating systems itself becomes a major challenge.
Clearly defined evaluation criteria and their precise
implementation is critical not only for the compari-
son of submissions, but also to help participants fol-
low the status of their development and to identify
the specific strengths and weaknesses of their ap-
proach.
A further challenge arising from the complexity
of the tasks is the need to process the relatively in-
tricate format in which annotations are represented,
which in turn carries a risk of errors in submissions.
To reduce the risk of submissions being rejected or
the evaluation showing poor results due to format-
ting errors, tools for checking the validity of the file
format and annotation semantics are indispensable.
For these reasons, we placed emphasis in the or-
ganisation of the BioNLP-ST?11 on making tools for
format checking, validation and evaluation available
to the participants already during the early stages of
system development. The tools were made avail-
able in two ways: as downloads, and as online ser-
vices. With downloaded tools, participants can per-
form format checking and evaluation at any time
without online access, allowing more efficient op-
timisation processes. Each task in BioNLP-ST also
14http://www.apple.com/safari
15http://www.google.com/chrome
117
Figure 5: An example of a false negative illustrated by the evaluation tools in co-ordination with stav
maintained an online evaluation tool for the develop-
ment set during the development period. The online
evaluation is intended to provide an identical inter-
face and criteria for submitted data as the final on-
line submission system, allowing participants to be
better prepared for the final submission. With on-
line evaluation, the organisers could also monitor
submissions to ensure that there were no problems
in, for example, the evaluation software implemen-
tations.
The system logs of online evaluation systems
show that the majority of the participants submit-
ted at least one package with formatting errors, con-
firming the importance of tools for format checking.
Further, most of the participants made use of the on-
line development set evaluation at least once before
their final submission.
To enhance the evaluation tools we drew upon the
stav visualiser to provide a view of the submitted re-
sults. This was done by comparing the submitted
results and the gold data to produce a visualisation
where errors are highlighted, as illustrated in Fig-
ure 5. This experimental feature was available for
the EPI and ID tasks and we believe that by doing so
it enables participants to better understand the per-
formance of their system and work on remedies for
current shortcomings.
4 Discussion and Conclusions
Among the teams participating in the EPI and ID
tasks, a great majority utilised tools for which re-
sources were made available by the organisers. We
hope that the continued availability of the parses will
encourage further investigation into the applicability
of these and similar tools and representations.
As for the analysis of the supporting analyses pro-
vided by external groups and the participants, we are
so far aware of only limited use of these resources
among the participants, but the resources will re-
main available and we are looking forward to see
future work using them.
To enable reproducibility of our resources, we
provide a publicly accessible repository containing
the automated procedure and our processing scripts
used to produce the released data. This repository
also contains detailed instructions on the options and
versions used for each parser and, if the software li-
cense permits it, includes the source code or binary
that was used to produce the processed data. For the
cases where the license restricts redistribution, in-
structions and links are provided on how to obtain
the same version that was used. We propose that us-
ing a multitude of parses and formats can benefit not
just the task of event extraction but other NLP tasks
as well.
We have also made our evaluation tools and visu-
alisation tool stav available along with instructions
on how to run it and use it in coordination with the
shared task resources. The responses from the par-
ticipants in relation to the visualisation tool were
very positive, and we see this as encouragement to
advance the application of visualisation as a way to
better reach a wider understanding and unification
of the concept of events for biomedical event extrac-
tion.
All of the resources described in this paper are
available at http://sites.google.com/site/bionlpst/.
118
Acknowledgements
We would like to thank Jari Bjo?rne of the Uni-
versity of Turku BioNLP group; Gerold Schneider,
Fabio Rinaldi, Simon Clematide and Don Tuggener
of the Univerity of Zurich Computational Linguis-
tics group; Roser Morante of University of Antwerp
CLiPS center; and Youngjun Kim of the Univer-
sity of Utah Natural Language Processing Research
Group for their generosity with their time and exper-
tise in providing us with supporting analyses.
This work was supported by Grant-in-Aid for
Specially Promoted Research (MEXT, Japan) and
the Royal Swedish Academy of Sciences.
References
Daniel M. Bikel. 2004. Intricacies of Collins? Parsing
Model. Computational Linguistics, 30(4):479?511.
J. Bjo?rne, F. Ginter, S. Pyysalo, J. Tsujii, and
T. Salakoski. 2010. Complex event extraction at
PubMed scale. Bioinformatics, 26(12):i382.
Robert Bossy, Julien Jourde, Philippe Bessie`res, Marteen
van de Guchte, and Claire Ne?dellec. 2011. BioNLP
Shared Task 2011 - Bacteria Biotope. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proceed-
ings of the Tenth Conference on Computational Nat-
ural Language Learning, pages 149?164. Association
for Computational Linguistics.
E. Buyko and U. Hahn. 2010. Evaluating the impact
of alternative dependency graph encodings on solv-
ing event extraction tasks. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 982?992. Association for
Computational Linguistics.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL?05), pages 173?180.
Pallavi Choudhury, Michael Gamon, Chris Quirk, and
Lucy Vanderwende. 2011. MSR-NLP entry in
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
S. Clark and J.R. Curran. 2004. Parsing the WSJ us-
ing CCG and log-linear models. In Proceedings of
the 42nd Annual Meeting on Association for Compu-
tational Linguistics, page 103. Association for Com-
putational Linguistics.
Michael John Collins. 1996. A new statistical parser
based on bigram lexical dependencies. In Proceed-
ings of the 34th Annual Meeting of the Association
for Computational Linguistics, pages 184?191, Santa
Cruz, California, USA, June. Association for Compu-
tational Linguistics.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
H.L. Dickensheets, C. Venkataraman, U. Schindler, and
R.P. Donnelly. 1999. Interferons inhibit activation of
STAT6 by interleukin 4 in human monocytes by in-
ducing SOCS-1 gene expression. Proceedings of the
National Academy of Sciences of the United States of
America, 96(19):10800.
Ehsan Emadzadeh, Azadeh Nikfarjam, and Graciela
Gonzalez. 2011. A generalizable and efficient ma-
chine learning approach for biological event extraction
from text. In Proceedings of the BioNLP 2011 Work-
shop Companion Volume for Shared Task, Portland,
Oregon, June. Association for Computational Linguis-
tics.
Charles J. Fillmore. 1976. Frame semantics and the na-
ture of language. Annals of the New York Academy of
Sciences, 280(1):20?32.
R. Johansson and P. Nugues. 2007. Extended
constituent-to-dependency conversion for English. In
Proc. of the 16th Nordic Conference on Computational
Linguistics (NODALIDA).
Julien Jourde, Alain-Pierre Manine, Philippe Veber,
Kare?n Fort, Robert Bossy, Erick Alphonse, and
Philippe Bessie`res. 2011. BioNLP Shared Task 2011
- Bacteria Gene Interactions and Renaming. In Pro-
ceedings of the BioNLP 2011 Workshop Companion
Volume for Shared Task, Portland, Oregon, June. As-
sociation for Computational Linguistics.
Yoshinobu Kano, William Baumgartner, Luke McCro-
hon, Sophia Ananiadou, Kevin Cohen, Larry Hunter,
and Jun?ichi Tsujii. 2009. U-Compare: share and
compare text mining tools with UIMA. Bioinformat-
ics, 25(15):1997?1998, May.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
119
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011a. Overview
of BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011b. Overview of the Genia Event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
D. Klein and C.D. Manning. 2003. Fast exact infer-
ence with a factored model for natural language pars-
ing. Advances in neural information processing sys-
tems, pages 3?10.
M.P Marcus, B. Santorini, and M.A Marcinkiewicz.
1993. Building a large annotated corpus of English:
The Penn Tree Bank. Computational Linguistics,
pages 313?318.
D. McClosky. 2009. Any Domain Parsing: Automatic
Domain Adaptation for Natural Language Parsing.
Ph.D. thesis, Ph. D. thesis, Department of Computer
Science, Brown University.
M. Miwa, S. Pyysalo, T. Hara, and J. Tsujii. 2010. Eval-
uating Dependency Representation for Event Extrac-
tion. In In the 23rd International Conference on Com-
putational Linguistics (COLING 2010), pages 779?
787.
Y. Miyao and J. Tsujii. 2008. Feature forest models for
probabilistic HPSG parsing. Computational Linguis-
tics, 34(1):35?80.
Yusuke Miyao, Rune S?tre, Kenji Sagae, Takuya Mat-
suzaki, and Jun?ichi Tsujii. 2008. Task-oriented eval-
uation of syntactic parsers and their representations. In
Proceedings of ACL-08: HLT, pages 46?54, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
R. Morante, V. Van Asch, and W. Daelemans. 2010.
Memory-based resolution of in-sentence scopes of
hedge cues. CoNLL-2010: Shared Task, page 40.
Ngan Nguyen, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
Overview of the Protein Coreference task in BioNLP
Shared Task 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006.
Learning accurate, compact, and interpretable tree an-
notation. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, pages 433?440. Association for Computa-
tional Linguistics.
H. Poon and L. Vanderwende. 2010. Joint inference
for knowledge extraction from biomedical literature.
In Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 813?
821. Association for Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011a.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii.
2011b. Overview of the Entity Relations (REL) sup-
porting task of BioNLP Shared Task 2011. In Pro-
ceedings of the BioNLP 2011 Workshop Companion
Volume for Shared Task, Portland, Oregon, June. As-
sociation for Computational Linguistics.
Laura Rimell and Stephen Clark. 2009. Porting a
lexicalized-grammar parser to the biomedical domain.
Journal of Biomedical Informatics, 42(5):852 ? 865.
Biomedical Natural Language Processing.
R. S?tre, K. Yoshida, A. Yakushiji, Y. Miyao, Y. Matsub-
yashi, and T. Ohta. 2007. AKANE system: protein-
protein interaction pairs in BioCreAtIvE2 challenge,
PPI-IPS subtask. In Proceedings of the Second
BioCreative Challenge Workshop, pages 209?212.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with LR models and parser
ensembles. In Proceedings of the CoNLL 2007 Shared
Task.
G. Schneider, M. Hess, and P. Merlo. 2007. Hybrid
long-distance functional dependency parsing. Unpub-
lished PhD thesis, Institute of Computational Linguis-
tics, University of Zurich.
G. Szarvas, V. Vincze, R. Farkas, and J. Csirik. 2008.
The BioScope corpus: annotation for negation, uncer-
tainty and their scope in biomedical texts. In Proceed-
ings of the Workshop on Current Trends in Biomedical
Natural Language Processing, pages 38?45. Associa-
tion for Computational Linguistics.
Y. Tateisi, A. Yakushiji, T. Ohta, and J. Tsujii. 2005.
Syntax Annotation for the GENIA corpus. In Proceed-
ings of the IJCNLP, pages 222?227.
120
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 82?90,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
PubMed-Scale Event Extraction for Post-Translational Modifications,
Epigenetics and Protein Structural Relations
Jari Bjo?rne 1,2, Sofie Van Landeghem 3,4, Sampo Pyysalo 5, Tomoko Ohta 5,
Filip Ginter 2, Yves Van de Peer 3,4, Sophia Ananiadou 5 and Tapio Salakoski 1,2
1Turku Centre for Computer Science (TUCS), Joukahaisenkatu 3-5B, 20520 Turku, Finland
2Department of Information Technology, 20014 University of Turku, Finland
3Department of Plant Systems Biology, VIB, Technologiepark 927, 9052 Gent, Belgium
4Department of Plant Biotechnology and Bioinformatics, Ghent University, Gent, Belgium
5National Centre for Text Mining and University of Manchester,
Manchester Interdisciplinary Biocentre,131 Princess Street, Manchester, UK
Abstract
Recent efforts in biomolecular event extrac-
tion have mainly focused on core event types
involving genes and proteins, such as gene
expression, protein-protein interactions, and
protein catabolism. The BioNLP?11 Shared
Task extended the event extraction approach
to sub-protein events and relations in the Epi-
genetics and Post-translational Modifications
(EPI) and Protein Relations (REL) tasks. In
this study, we apply the Turku Event Ex-
traction System, the best-performing system
for these tasks, to all PubMed abstracts and
all available PMC full-text articles, extract-
ing 1.4M EPI events and 2.2M REL relations
from 21M abstracts and 372K articles. We
introduce several entity normalization algo-
rithms for genes, proteins, protein complexes
and protein components, aiming to uniquely
identify these biological entities. This nor-
malization effort allows direct mapping of
the extracted events and relations with post-
translational modifications from UniProt, epi-
genetics from PubMeth, functional domains
from InterPro and macromolecular structures
from PDB. The extraction of such detailed
protein information provides a unique text
mining dataset, offering the opportunity to fur-
ther deepen the information provided by ex-
isting PubMed-scale event extraction efforts.
The methods and data introduced in this study
are freely available from bionlp.utu.fi.
1 Introduction
Biomedical domain information extraction has in re-
cent years seen a shift from focus on the extraction
of simple pairwise relations (Pyysalo et al, 2008;
Tikk et al, 2010) towards the extraction of events,
represented as structured associations of arbitrary
numbers of participants in specific roles (Ananiadou
et al, 2010). Domain event extraction has been pop-
ularized in particular by the BioNLP Shared Task
(ST) challenges in 2009 and 2011 (Kim et al, 2009;
Kim et al, 2011). While the BioNLP ST?09 em-
phasized protein interactions and regulatory rela-
tionships, the expressive event formalism can also
be applied to the extraction of statements regarding
the properties of individual proteins. Accordingly,
the EPI (Epigenetics and Post-Translational Modi-
fications) subchallenge of the BioNLP ST?11 pro-
vided corpora and competitive evaluations for the
detection of epigenetics and post-translational mod-
ification (PTM) events, while the REL (Entity Re-
lations) subchallenge covers structural and complex
membership relations of proteins (Ohta et al, 2011b;
Pyysalo et al, 2011). The complex memberships
and domains define the physical nature of an indi-
vidual protein, which is closely linked to its func-
tion and biological activity. Post-translational mod-
ifications alter and regulate this activity via struc-
tural or chemical changes induced by the covalent
attachment of small molecules to the protein. In
epigenetic regulation, gene expression is controlled
by the chemical modification of DNA and the his-
tone proteins supporting chromosomal DNA. All of
these aspects are important for defining the biologi-
cal role of a protein, and thus the EPI and REL tasks
enable the development of text mining systems that
can extract a more complete picture of the biomolec-
ular reactions and relations than previously possible
(cf. Table 1). Furthermore, previous work has shown
promising results for improving event extraction by
82
integration of ?static? entity relations (Pyysalo et al,
2009), in particular for the previously only available
PTM event, phosphorylation (Van Landeghem et al,
2010).
Information on protein modifications is avail-
able in general-purpose protein databases such as
UniProt, and there are also a number of dedicated
database resources covering such protein modifica-
tions (Wu and others, 2003; Lee et al, 2006; Li et
al., 2009). While the automatic extraction of PTMs
from text has also been considered in a number of
earlier studies, these have primarily involved single
PTM reactions extracted with special-purpose meth-
ods (Hu et al, 2005; Yuan et al, 2006; Lee et al,
2008). The EPI task and associated work (Ohta et
al., 2010) were the first to target numerous PTM re-
actions in a general framework using retrainable ex-
traction methods. The automatic detection of mod-
ification statements using keyword matching-based
methods has been applied also in support of DNA
methylation DB curation (Ongenaert et al, 2008;
Fang et al, 2011). However, as for PTM, the EPI
task and its preparatory efforts (Ohta et al, 2011a)
were the first to consider DNA methylation using the
general event extraction approach. To the best of our
knowledge, the present study is the first to extend the
event extraction approach to PTM and DNA methy-
lation event extraction to the scale of the entire avail-
able literature.
The Turku Event Extraction System (TEES), first
introduced for the BioNLP ST?09 (Bjo?rne et al,
2009), was updated and generalized for participa-
tion in the BioNLP ST?11, in which it had the best
performance on both the EPI and REL challenges
(Bjo?rne and Salakoski, 2011). With an F-score of
53.33% for the EPI and 57.7% for the REL task, it
performed over 16 pp better than the next best sys-
tems, making it well suited for our study. We apply
this system to the extraction of EPI events and REL
relations from all PubMed abstracts and all PMC
open access articles, using a pipeline of open source
text mining tools introduced in Bjo?rne et al (2010).
We further process the result using a recently
created bibliome-scale gene normalization dataset1.
This normalization effort connects protein and gene
mentions in text to their database IDs, a prerequi-
1Data currently under review.
site for effective use of text mining results for most
bioinformatics applications. In addition to protein
names, the EPI and REL challenges refer to the
protein substructures, modifications and complexes,
which we also need to normalize in order to deter-
mine the biological context of these events. In this
work, we develop a number of rule-based algorithms
for the normalization of such non-protein entities.
With both proteins and other entities normalized,
we can align the set of events extracted from the
literature with biological databases containing an-
notations on protein features, such as UniProt. We
can determine how many known and unknown fea-
tures we have extracted from text, and what percent-
age of various protein feature annotations our text
mining results cover. This association naturally also
works in the other direction, as we can take a gene or
protein and find yet unannotated post-translational
modifications, domains, or other features from sci-
entific articles, a promising use case for supporting
biomedical database curation.
2 Methods
2.1 PMC preprocessing
PMC full texts are distributed in an XML format that
TEES cannot use directly for event extraction. We
convert this XML into a flat ASCII text format with
a pipeline built on top of BioNLP ST?11 supporting
resource tools (Stenetorp et al, 2011). This process-
ing resolves embedded LATEX expressions, separates
blocks of text content (titles, sections, etc.) from
others, maps non-ASCII characters to corresponding
ASCII sequences, and normalizes whitespace. Re-
solving non-ASCII characters avoids increased error
rates from NLP tools trained on ASCII-only data.
2.2 Event Extraction
We use the Turku Event Extraction System for ex-
tracting both REL relations and EPI events. TEES is
a modular event extraction pipeline, that has recently
been extended for all the subtasks of the BioNLP?11
ST, including EPI and REL (Bjo?rne and Salakoski,
2011). TEES performs all supported tasks using
a shared graph scheme, which can represent both
events and relations (Figure 1 D). The system also
provides confidence scores enabling selection of the
most likely correct predictions. Before event extrac-
83
Event/relation type Example
Hydroxylation HIF-alpha proline hydroxylation
Phosphorylation (D) siRNA-mediated ATM depletion blocks p53 Serine-15 phosphorylation.
Ubiquitination K5 ubiquitinates BMPR-II on a Membrane-proximal Lysine
DNA methylation RUNX3 is frequently inactivated by P2 methylation in solid tumors.
Glycosylation Also, two asparagine residues in alpha-hCG were glycosylated.
Acetylation This interaction was regulated by Tat acetylation at lysine 50.
Methylation Methylation of lysine 37 of histone H2B is conserved.
Catalysis GRK2 catalyzed modest phosphorylation of BAC1.
Protein-Component Three enhancer elements are located in the 40 kb intron of the GDEP gene.
Subunit-Complex The most common form is a heterodimer composed of the p65/p50 subunits.
Table 1: Sentences with examples of the eight EPI event and two REL relation types, with highlighted triggers, and
protein and site arguments. Relations have no trigger and Catalysis takes as an argument another event.
Protein
Serine
Phosphorylation
of
Catalysis
is
Protein
mediated by CKI .
Cause>
REL detectionD
C
B
parsing
phosphorylation T-bet
Entity
<Theme
<Site
E
named entity recognition and normalization BANNER + GenNorm
McCJ-parser + Stanford Conversion
TEES
sentence splitting GENIA Sentence Splitter
PubMed Article Data
conversion to ST format and database import
A
Theme>
Serine of is mediated by CKI .phosphorylation T-betProteinEntity
<Protein-Component
Serine of is mediated by CKI .phosphorylation T-betNN VBN NN .NNNN VBZIN IN
<nn prep_of>
<nsubjpass
<auxpass agent>
Serine of is mediated by CKI .phosphorylation T-betProtein Protein
57765 27373
Serine of is mediated by CKI .phosphorylation T-bet
EPI detection
REL EPI
Figure 1: Event and relation extraction. Article text is
split into sentences (A), where gene/protein entities are
detected and normalized to their Entrez Gene IDs (B).
Each sentence with at least one entity is then parsed
(C). EPI events and REL relations are extracted from
the parsed sentences (D) and following conversion to
the BioNLP ST format are imported into a database (E).
(Adapted from Bjo?rne and Salakoski (2011)).
tion, protein/gene names are detected and sentences
are parsed. TEES handles all these preprocessing
steps via a pipeline of tool wrappers for the GE-
NIA Sentence Splitter (Kazama and Tsujii, 2003),
the BANNER named entity recognizer (Leaman and
Gonzalez, 2008), the McClosky-Charniak-Johnson
(McCCJ) parser (Charniak and Johnson, 2005; Mc-
Closky, 2010) and the Stanford tools (de Marneffe
et al, 2006). For a detailed description of TEES
we refer to Bjo?rne and Salakoski (2011) and for the
computational requirements of PubMed-scale event
extraction to Bjo?rne et al (2010).
2.3 Entity normalization
The extraction of events and relations as described in
the previous sections is purely text-based and does
not rely on any domain information from external
resources. This ensures generalizability of the meth-
ods to new articles possibly describing novel inter-
actions. However, practical use cases often require
integration of text mining results with external re-
sources. To enable such an integration, it is crucial to
link the retrieved information to known gene/protein
identifiers. In this section, we describe how we link
text mining data to biomolecular databases by pro-
viding integration with Entrez Gene, UniProt, Inter-
Pro and the Protein Data Bank.
2.3.1 Protein annotations
A crucial step for integrating statements in do-
main text with data records is gene name normaliza-
tion As part of a recent PubMed-scale effort,2 gene
2Data currently under review.
84
normalizations were produced by the GenNorm sys-
tem (Wei and Kao, 2011), assigning unique Entrez
Gene identifiers (Sayers and others, 2010) to am-
biguous gene/protein symbols. The GenNorm sys-
tem represents the state-of-the-art in gene normal-
ization, having achieved first rank by several evalua-
tion criteria in the BioCreative III Challenge (Lu and
others, 2011).
For practical applications, the Entrez Gene iden-
tifiers have been mapped to UniProt (The UniProt
Consortium, 2011) through conversion tables pro-
vided by the NCBI. As Entrez Gene and UniProt
are two of the most authoritative resources for gene
and protein identification, these annotations ensure
straightforward integration with other databases.
2.3.2 Complex annotations
The REL task Subunit-Complex relations all in-
volve exactly one protein complex and one of its
subunits, but the same complex may be involved in
many different Subunit-Complex relations (Pyysalo
et al, 2011). A key challenge for making use
of these relations thus involves retrieving a unique
identification of the correct complex. To identify
protein complexes, we use the Protein Data Bank
(PDB), an archive of structural data of biological
macromolecules (Berman et al, 2000). This re-
source currently contains more than 80,000 3-D
structures, and each polymer of a structure is anno-
tated with its respective UniProt ID.
To assign a unique PDB ID to an entity involved
in one or more Subunit-Complex relations, there
is usually no other lexical context than the protein
names in the sentence, e.g. ?the Rad9-Hus1-Rad1
complex?. Consequently, we rely on the normal-
ized protein names (Section 2.3.1) to retrieve a list
of plausible complexes, using data downloaded from
UniProt to link proteins to PDB entries. Ambiguity
is resolved by selecting the complex with the high-
est number of normalized proteins and giving pref-
erence to so-called representative chains. A list of
representative chains is available at the PDB web-
site, and they are determined by clustering similar
protein chains3 and taking the most confident ones
based on resolution quality.
Each assignment of a PDB identifier is annotated
with a confidence value between 0 and 1, express-
3Requiring at least 40% sequence similarity.
ing the percentage of proteins in the complex that
could be retrieved and normalized in text. For ex-
ample, even if one out of three UniProt identifiers is
wrongly assigned for a mention, the correct complex
might still be assigned with 0.66 confidence.
2.3.3 Domain annotations
Protein-Component relations define a relation be-
tween a gene/protein and one of its components,
such as a gene promoter or a protein domain. To
identify at least a substantial subset of these di-
verse relations, we have integrated domain knowl-
edge extracted from InterPro. InterPro is a rich re-
source on protein families, domains and functional
sites, integrating data from databases like PROSITE,
PANTHER, Pfam, ProDom, SMART and TIGR-
FAMs (Hunter and others, 2012). Over 23,000 dis-
tinct InterPro entries were retrieved, linking to more
than 16.5 million protein identifiers.
To assign an InterPro ID to an entity involved in
one or more Protein-Component relations, a set of
candidates is generated by inspecting the InterPro
associations of each of the proteins annotated with
that domain in text. For each such candidate, the
description of the InterPro entry is matched against
the lexical context around the entity by comparing
the number of overlapping tokens, excluding gen-
eral words, such as domain, and prepositions. The
amount of overlap is normalized against the length
of the InterPro description and expressed as a per-
centage, creating confidence values between 0 and 1.
Additionally, a simple pattern matching algorithm
recognizes statements expressing an amino acid in-
terval, e.g. ?aristaless domain (aa 527-542)?. When
such expressions are found, the intervals as anno-
tated in InterPro are matched against the retrieved
interval from text, and the confidence values express
the amount of overlap between the two intervals.
2.3.4 PTM site normalization
Six of the eight4 EPI event types refer to
post-translational modification of proteins. These
events are Hydroxylation, Phosphorylation, Ubiq-
uitination, Glycosylation, Acetylation and (Protein)
Methylation. To evaluate the events predicted
4As we are interested in PTM sites, we make no distinc-
tion between ?additive? PTMs such as Acetylation and their ?re-
verse? reactions such as Deacetylation.
85
from text, we compare these to annotated post-
translational modifications in UniProt. UniProt is
one of the largest manually curated databases for
protein knowledge, and contains annotations corre-
sponding to each of the EPI PTM event types.
We use the reviewed and manually annotated
UniProtKB/Swiss-Prot dataset (release 2012 02) in
XML format. We take for each protein all feature
elements of types modified residue, cross-link and
glycosylation site. Each of these feature elements
defines the site of the modification, either a single
amino acid, or a sequence of amino acids. We select
only annotations based on experimental findings,
that is, features that do not have a non-experimental
status (potential, probable or by similarity) to avoid
e.g. features only inferred from the sequence.
The modified residue feature type covers the event
types Hydroxylation, Phosphorylation, Acetylation
and Methylation. We determine the class of the mod-
ification with the UniProt controlled vocabulary of
post-translational modifications5. The description
attribute is the ID attribute of an entry in the vocabu-
lary, through which we can determine the more gen-
eral keyword (KW) for that description, if defined.
These keywords can then be connected to the corre-
sponding event types in the case of Hydroxylation,
Phosphorylation, Acetylation and Methylation. For
Ubiquitination events, we look for the presence of
the string ?ubiquitin? in the description attribute of
cross-link features. Finally, features corresponding
to Glycosylation events are determined by their fea-
ture element having the type glycosylation site.
The result of this selection process is a list of in-
dividual modification features, which contain a type
corresponding to one of the EPI PTM event types,
the UniProt ID of the protein, and the position and
amino acid(s) of the modification site. This data can
be compared with extracted events, using their type,
normalized protein arguments and modification site
arguments. However, we also need to normalize the
modification site arguments.
PTM sites are defined with a modification type
and the numbered target amino acid residue. In EPI
events, these residues are defined in the site argu-
ment target entities. To convert these into a form
that can be aligned with UniProt, we apply a set
5http://www.uniprot.org/docs/ptmlist/
Event Type Extracted PMC (%)
Hydroxylation 14,555 34.17
Phosphorylation 726,757 44.00
Ubiquitination 74,027 70.46
DNA methylation 140,531 52.27
Glycosylation 154,523 42.31
Acetylation 114,585 69.40
Methylation 122,015 74.86
Catalysis 45,763 67.86
Total EPI 1,392,756 51.53
Protein-Component 1,613,170 52.59
Subunit-Complex 537,577 51.18
Total REL 2,150,747 52.23
Table 2: Total number of EPI events and REL relations
extracted from PubMed abstracts and PMC full-text arti-
cles, with the fractions extracted from PMC.
of rules that try to determine whether a site is an
amino acid. We start from the main site token, and
check whether it is of the form AA#, where AA is an
amino acid name, or a one or three letter code, and
# an optional site number, which can also be in a to-
ken following the amino acid. For cases where the
site entity is the word ?residue? or ?residues?, we
look for the amino acid definition in the preceding
and following tokens. All strings are canonicalized
with removal of punctuation, hyphens and parenthe-
sis before applying the rules. In total, of the 177,994
events with a site argument, 75,131 could be nor-
malized to an amino acid, and 60,622 of these to a
specific residue number.
3 Results
The source for extraction in this work is the set of 21
million PubMed abstracts and 372 thousand PMC
open-access full-text articles. From this dataset,
1.4M EPI events and 2.2M REL relations were ex-
tracted (Table 2). For both tasks, about half of the
results were extracted from PMC, confirming that
full-text articles are an important source of infor-
mation for these extraction targets. The total num-
bers of events and relations are considerably lower
than e.g. the 21.3M events extracted for the GENIA
task from PubMed abstracts (Bjo?rne et al, 2010;
Van Landeghem et al, 2012), likely relating to the
comparatively low frequency with which EPI and
REL extraction targets are discussed with respect to
the basic GENIA biomolecular reactions.
86
Event type UniProt Events Match Coverage Events (site) Match Coverage
Hydroxylation 1,587 14,555 1,526 19 4,298 130 5
Phosphorylation 57,059 726,757 286,978 4,795 86,974 9,732 748
Ubiquitination 792 74,027 4,994 143 10,562 54 20
Glycosylation 6,708 154,523 18,592 897 22,846 68 31
Acetylation 6,522 114,585 15,470 764 25,689 158 30
Methylation 1,135 122,015 2,178 113 27,625 36 10
Total 73,803 1,206,462 329,738 6,731 177,994 10,178 844
Table 3: PTM events. PTMs that are not marked with non-experimental qualifiers are taken from UniProt. The
Events column lists the total number of predicted events, and the Events (site) the number of events that also have a
predicted site-argument. For these groups, Match is the number of events that matches a known PTM from UniProt,
and Coverage the number of UniProt PTMs for which at least one match exists. For Events matching takes into account
the PTM type and protein id, for Events (site) also the amino acid and position of the modified residue.
Event type AA UP # Highest confidence event Article ID
Phosphorylation S9 ? 2 p53 isolated from ML1, HCT116 and RKO cells, after short
term genotoxic stress, were phosphorylated on Ser 6, Ser 9
PMC:2777442
Acetylation S15 4 phosphorylated (Ser15), acetylated p53(Lys382) PMC:2557062
Methylation S15 1 phosphorylation of p53 at serine 15 and acetylation PM:10749144
Phosphorylation S15 ? 238 Chk2, as well as p53 Ser(15) phosphorylation and its PM:16731759
Phosphorylation T18 ? 12 p53 stabilization and its phosphorylation in Thr18 PMC:3046209
Phosphorylation S20 ? 45 that phosphorylation of p53 at Ser20 leads to PMC:3050855
Phosphorylation S33 ? 14 phosphorylation of p53 at serine 33 may be part of PMC:35361
Phosphorylation S37 ? 20 serine 33 of p53 in vitro when serine 37 is already PMC:35361
Phosphorylation S46 ? 55 phosphorylation of p53, especially at Serine 46 by PMC:2634840
Phosphorylation T55 ? 7 that phosphorylation of p53 at Thr55 inhibits its PMC:3050855
Phosphorylation S99 ? 0
Phosphorylation S183 ? 0
Phosphorylation S269 ? 0
Phosphorylation T284 ? 0
Ubiquitination K291 ? 0
Acetylation K292 ? 0
Ubiquitination K292 ? 0
Acetylation K305 ? 0
Phosphorylation S313 ? 1 hyperphosphorylation of p53, particularly of Ser313 PM:8649812
Phosphorylation S314 ? 0
Phosphorylation S315 ? 6 to require phosphorylation of p53 at serine 315 (35) PMC:2532731
Methylation K370 ? 6 by methylating lysine 370 of p53 PMC:1636665
Acetylation K372 1 for lysine 372 and 383 acetylated p53 (Upstate, PMC:1315280
Methylation K372 ? 5 methylation of p53 by the KMT7(SET7/9) methyltransferase
enzyme on Lys372
PMC:2794343
Acetylation K373 ? 16 p53 and acetylated p53 (lysine-373 and lysine-382) PMC:1208859
Methylation K373 ? 4 EHMT1-mediated p53 methylation at K373 PM:20588255
Acetylation K381 ? 0
Acetylation K382 ? 82 p53 acetylation at lysine 382 was found not PM:17898049
Methylation K382 ? 6 SET8 specifically monomethylates p53 at lysine 382 PM:17707234
Methylation K386 ? 1 that sumoylation of p53 at K386 blocks subsequent PM:19339993
Phosphorylation S392 ? 35 and phosphorylation of p53 at S392 PM:17237827
Table 4: Extracted and known PTM sites of p53. The type and site of the modification are in the first two columns.
UP indicates whether the PTM is present in the UniProt annotation for p53. Column # shows the number of extracted
events, followed by the event with the highest confidence score and the PubMed abstract or PMC full-text article it has
been extracted from.
87
3.1 Extracted PTMs compared to UniProt
The EPI PTM events were compared to annotated
PTMs from UniProt (Table 3). The majority of ex-
tracted PTM events (85%) have only a protein ar-
gument, and no information about the modification
site, so these can only be compared by the protein
id and PTM type. For the subset of proteins that
also have a site, which can be normalized to an
amino acid position, we can make a detailed com-
parison with UniProt. Finding a match for these
normalized amino acids is more difficult, and for
both categories, only a small fraction of proteins
from UniProt is covered. In part this may be due
to the limitations of the gene name normalization, as
finding the exact species-specific protein ID remains
a challenging task (Lu and others, 2011). How-
ever, even if the overall coverage is limited, well-
known protein modifications can be assigned to spe-
cific residues, as we show in the next section.
3.2 Extracted PTMs for a single protein
For an in-depth example of PTM modifications, we
study the protein p53, a central tumor suppressor
protein that is the subject of many studies. p53 is
also among the proteins with the most UniProt PTM
sites for which EPI events were predicted, making it
a good example for a case study (see Table 4).
We take from UniProt all known p53 PTMs corre-
sponding to our EPI event types and list the number
of predicted events for them (see Table 4). When
the number of predicted events is high, the most
confident prediction is usually a correctly extracted,
clear statement about the PTM. All events for PTMs
known in UniProt are correct except for the type
of K386. For events not in UniProt, the two S15
ones are false positives, and K372 acetylation, while
correctly extracted, is most likely a typo in the arti-
cle. For the PTMs for which no event was extracted,
we checked the reference article from UniProt an-
notation. K291, K292 ubiquitination, and K305 are
from abstracts, and thus missed events. S183, S269
and T284 are from a non-open access PMC article,
while S99, K292 acetylation, K305, S314 and K381
are from Excel or PDF format supplementary tables,
sources outside our extraction input.
In total, we have extracted 561 PTM events re-
lated to p53, 554 of which correspond to a PTM an-
Item PubMeth Extracted Recall
PMID+UPID 2776 1698 61.2%
UPID 392 363 92.6%
PMID 1163 1120 96.3%
Table 5: Evaluation of DNA methylation event extraction
recall against PubMeth.
notated in UniProt. Of the 28 EPI-relevant PTMs on
p53, 17 have at least one predicted event. The high-
est confidence events are about equally often from
abstracts as from full texts.
3.3 DNA methylation analysis
Two recently introduced databases, PubMeth (On-
genaert et al, 2008) and MeInfoText (Fang et al,
2011) provide manually curated information on
DNA methylation, primarily as it relates to cancer.
To evaluate the coverage of DNA methylation event
extraction, we focus here on PubMeth, as the full
content of this database could be directly used. Each
PubMeth DB record provides the primary name of
the methylated gene and the PMID of the publica-
tion supporting the curation of the record. We used
these two pieces of information to evaluate the recall
6 of DNA methylation event extraction.
We mapped PubMeth entries to UniProt iden-
tifiers (UPIDs), and extracted all unique (PMID,
UPID) pairs from both PubMeth and the automat-
ically extracted DNA methylation/demethylation
events. The results of comparison of these sets of
ID pairs are given in Table 5. We find that for over
60% of PubMeth entries, the system is able to re-
cover the specific (document, gene) pair. This result
is broadly in line with the recall of the system as
evaluated in the BioNLP ST. However, if the match-
ing constraint is relaxed, asking either 1) can the sys-
tem extract the methylation of each gene in PubMeth
somewhere in the literature or, inversely, 2) can the
system detect some DNA methylation event in each
document included in PubMeth as evidence, recall
is over 90%. In particular, the evaluation indicates
that the system shows very high recall for identify-
ing documents discussing DNA methylation.
6As PubMeth does not aim for exhaustive coverage, preci-
sion cannot be directly estimated in this way. For example, Pub-
Meth covers fewer than 2,000 documents and DNA methylation
events were extracted from over 20,000, but due to differences
in scope, this does not suggest precision is below 10%.
88
REL Type Extracted Match (p) Match (e)
Prot-Cmp 1613.1K 561.8K 150.7K
SU-Cmplx 537.6K 226.5K 99.6K
Table 6: Numbers of extracted entity relations, with the
protein (p) or both protein and entity (e) identified.
3.4 REL statistics
Table 6 presents the amount of extracted entity re-
lations and the coverage of the normalization algo-
rithms assigning protein, domain and complex iden-
tifiers. From a total of 537.6K Subunit-Complex re-
lations, 226.5K (42%) involve a protein that could be
unambiguously identified (Section 2.3.1). From this
subset, 99.6K relations (44%) could be assigned to a
PDB complex identifier (Section 2.3.2), accounting
for 3800 representative 3D protein structures.
The Protein-Component relations are much more
frequent in the data (1.6M relations) and here 35%
of the relations (561.8K) involve a normalized pro-
tein mention. The assignment of InterPro domains
to these Protein-Component relations (Section 2.3.3)
further covers 150.7K relations in this subset (27%),
identifying 5500 distinct functional domains. The
vast majority of these annotations (99%) are pro-
duced by matching the lexical context against the
InterPro descriptions, and only a few cases (200)
matched against the amino-acid pattern.
4 Conclusions
We have combined state-of-the-art methods for
gene/protein name normalization together with the
best available methods for event-based extraction
of protein post-translational modifications, reactions
relating to the epigenetic control of gene expres-
sion, and part-of relations between genes/proteins,
their components, and complexes. These methods
were jointly applied to the entire available litera-
ture, both PubMed abstracts and PMC full-text doc-
uments, creating a text mining dataset unique in both
scope and breadth of analysis. We further performed
a comprehensive analysis of the results of this au-
tomatic extraction process against major biological
database resources covering various aspects of the
extracted information. This analysis indicated that
text mining results for protein complexes, substruc-
tures and epigenetic DNA methylation provides al-
ready quite extensive coverage of relevant proteins.
For post-translational modifications, we note that
coverage still needs to be improved, but conclude
that the extracted events already provide a valuable
link to PTM related literature. In future work we
hope to further extend the event types extracted by
our PubMed-scale approach. The extraction meth-
ods as well as all data introduced in this study are
freely available from bionlp.utu.fi.
Acknowledgments
We thank the Academy of Finland, the Research
Foundation Flanders (FWO) and the UK BBSRC
(reference number: BB/G013160/1) for funding,
and CSC ? IT Center for Science Ltd for compu-
tational resources.
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
Helen M. Berman, John Westbrook, Zukang Feng,
Gary Gilliland, T. N. Bhat, Helge Weissig, Ilya N.
Shindyalov, and Philip E. Bourne. 2000. The protein
data bank. Nucleic Acids Research, 28(1):235?242.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 183?191.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In Proceedings of the BioNLP 2009 Work-
shop, pages 10?18.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,
and Tapio Salakoski. 2010. Scaling up biomedical
event extraction to the entire PubMed. In Proceedings
of the BioNLP 2010 Workshop, pages 28?36.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of
ACL, pages 173?180.
Y.C. Fang, P.T. Lai, H.J. Dai, and W.L. Hsu. 2011. Me-
infotext 2.0: gene methylation and cancer relation ex-
traction from biomedical literature. BMC bioinformat-
ics, 12(1):471.
Z. Z. Hu, M. Narayanaswamy, K. E. Ravikumar,
K. Vijay-Shanker, and C. H. Wu. 2005. Literature
mining and database annotation of protein phospho-
rylation using a rule-based system. Bioinformatics,
21(11):2759?2765.
89
Sarah Hunter et al 2012. Interpro in 2011: new devel-
opments in the family and domain prediction database.
Nucleic Acids Research, 40(D1):D306?D312.
Jun?ichi Kazama and Jun?ichi Tsujii. 2003. Evaluation
and extension of maximum entropy models with in-
equality constraints. In Proceedings of EMNLP 2003,
pages 137?144.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of BioNLP 2009, pages 1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011.
Overview of BioNLP Shared Task 2011. In Proceed-
ings of the BioNLP Shared Task 2011, pages 1?6.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedical
named entity recognition. Pacific Symposium on Bio-
computing, pages 652?663.
Tzong-Yi Lee, Hsien-Da Huang, Jui-Hung Hung, Hsi-
Yuan Huang, Yuh-Shyong Yang, and Tzu-Hao Wang.
2006. dbPTM: an information repository of pro-
tein post-translational modification. Nucleic acids re-
search, 34(suppl 1):D622?D627.
Hodong Lee, Gwan-Su Yi, and Jong C. Park. 2008.
E3Miner: a text mining tool for ubiquitin-protein lig-
ases. Nucl. Acids Res., 36(suppl.2):W416?422.
Hong Li, Xiaobin Xing, Guohui Ding, Qingrun Li, Chuan
Wang, Lu Xie, Rong Zeng, and Yixue Li. 2009.
SysPTM: A Systematic Resource for Proteomic Re-
search on Post-translational Modifications. Molecular
& Cellular Proteomics, 8(8):1839?1849.
Zhiyong Lu et al 2011. The gene normalization task
in BioCreative III. BMC Bioinformatics, 12(Suppl
8):S2+.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed depen-
dency parses from phrase structure parses. In Proceed-
ings of LREC-06, pages 449?454.
David McClosky. 2010. Any domain parsing: auto-
matic domain adaptation for natural language pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, Jin-Dong
Kim, and Jun?ichi Tsujii. 2010. Event extraction
for post-translational modifications. In Proceedings of
BioNLP?10, pages 19?27.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and
Jun?ichi Tsujii. 2011a. Event extraction for
DNA methylation. Journal of Biomedical Semantics,
2(Suppl 5):S2.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011b. Overview of the epigenetics and post-
translational modifications (EPI) task of BioNLP
Shared Task 2011. In Proceedings of BioNLP Shared
Task 2011 Workshop, pages 16?25.
Mate? Ongenaert, Leander Van Neste, Tim De Meyer,
Gerben Menschaert, Sofie Bekaert, and Wim
Van Criekinge. 2008. PubMeth: a cancer methy-
lation database combining text-mining and expert
annotation. Nucl. Acids Res., 36(suppl 1):D842?846.
Sampo Pyysalo, Antti Airola, Juho Heimonen, and Jari
Bjo?rne. 2008. Comparative analysis of five protein-
protein interaction corpora. BMC Bioinformatics,
9(Suppl. 3):S6.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Proceed-
ings of the BioNLP 2009 Workshop, pages 1?9.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii. 2011.
Overview of the entity relations (REL) supporting task
of BioNLP Shared Task 2011. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 83?88.
Eric W. Sayers et al 2010. Database resources of the na-
tional center for biotechnology information. Nucleic
Acids Research, 38(suppl 1):D5?D16.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
Bionlp shared task 2011: Supporting resources. In
Proceedings of BioNLP Shared Task 2011 Workshop,
pages 112?120.
The UniProt Consortium. 2011. Ongoing and future de-
velopments at the universal protein resource. Nucleic
Acids Research, 39(suppl 1):D214?D219.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg
Hakenberg, and Ulf Leser. 2010. A comprehen-
sive benchmark of kernel methods to extract protein-
protein interactions from literature. PLoS Comput
Biol, 6(7):e1000837, 07.
Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,
and Yves Van de Peer. 2010. Integration of static re-
lations to enhance event extraction from text. In Pro-
ceedings of BioNLP?10, pages 144?152.
Sofie Van Landeghem, Kai Hakala, Samuel Ro?nnqvist,
Tapio Salakoski, Yves Van de Peer, and Filip Ginter.
2012. Exploring biomolecular literature with EVEX:
Connecting genes through events, homology and indi-
rect associations. Advances in Bioinformatics.
Chih-Hsuan Wei and Hung-Yu Kao. 2011. Cross-species
gene normalization by species inference. BMC bioin-
formatics, 12(Suppl 8):S5.
Cathy H. Wu et al 2003. The Protein Information Re-
source. Nucl. Acids Res., 31(1):345?347.
X. Yuan, ZZ Hu, HT Wu, M. Torii, M. Narayanaswamy,
KE Ravikumar, K. Vijay-Shanker, and CH Wu. 2006.
An online literature mining tool for protein phospho-
rylation. Bioinformatics, 22(13):1668.
90
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 100?108,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
New Resources and Perspectives for Biomedical Event Extraction
Sampo Pyysalo1, Pontus Stenetorp2, Tomoko Ohta1, Jin-Dong Kim3 and Sophia Ananiadou1
1National Centre for Text Mining and University of Manchester,
Manchester Interdisciplinary Biocentre, 131 Princess Street, Manchester, UK
2Tokyo University, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan
3Database Center for Life Science, 2-11-16 Yayoi, Bunkyo-ku, Tokyo, Japan
Abstract
Event extraction is a major focus of re-
cent work in biomedical information extrac-
tion. Despite substantial advances, many chal-
lenges still remain for reliable automatic ex-
traction of events from text. We introduce a
new biomedical event extraction resource con-
sisting of analyses automatically created by
systems participating in the recent BioNLP
Shared Task (ST) 2011. In providing for the
first time the outputs of a broad set of state-of-
the-art event extraction systems, this resource
opens many new opportunities for studying
aspects of event extraction, from the identifi-
cation of common errors to the study of ef-
fective approaches to combining the strengths
of systems. We demonstrate these opportuni-
ties through a multi-system analysis on three
BioNLP ST 2011 main tasks, focusing on
events that none of the systems can success-
fully extract. We further argue for new per-
spectives to the performance evaluation of do-
main event extraction systems, considering a
document-level, ?off-the-page? representation
and evaluation to complement the mention-
level evaluations pursued in most recent work.
1 Introduction
Biomedical information extraction efforts are in-
creasingly focusing on event extraction using struc-
tured representations that allow associations of arbi-
trary numbers of participants in specific roles (e.g.
Theme, Cause) to be captured (Ananiadou et al,
2010). Domain event extraction has been advanced
in particular by the BioNLP Shared Task (ST) events
(Kim et al, 2011a; Kim et al, 2011b), which have
introduced common task settings, datasets, and eval-
uation criteria for event extraction. Participants in
these shared tasks have introduced dozens of sys-
tems for event extraction, and the resulting methods
have been applied to automatically analyse the entire
available domain literature (Bjo?rne et al, 2010) and
applied in support of applications such as semantic
literature search (Ohta et al, 2010; Van Landeghem
et al, 2011b) and pathway curation support (Kemper
et al, 2010).
It is possible to assess recent advances in event ex-
traction through results for a task considered both in
the BioNLP ST 2009 and 2011. By the primary eval-
uation criteria, the highest performance achieved in
the 2009 task was 51.95% F-score, and a 57.46% F-
score was reached in the comparable 2011 task (Kim
et al, 2011b). These results demonstrate significant
advances in event extraction methods, but also indi-
cate that the task continues to hold substantial chal-
lenges. This has led to a call from task participants
for further analysis of the data and results, accompa-
nied by a proposal to release analyses from individ-
ual systems to facilitate such analysis (Quirk et al,
2011).
In this study, we explore new perspectives into the
analyses and performance of event extraction meth-
ods. We build primarily on a new resource compiled
with the support of the majority of groups participat-
ing in the BioNLP ST 2011, consisting of analyses
from systems for the three main tasks sharing the
text-bound event representation. We demonstrate
the use of this resource through an evaluation fo-
cusing on events that cannot be extracted even by
the union of combined systems, identifying partic-
ular remaining challenges for event extraction. We
further propose and evaluate an alternate, document-
level perspective to event extraction, demonstrat-
ing that when only unique events are considered for
100
Figure 1: Example event annotations. The ?crossed-out? event type identifies an event marked as negated. Event
illustrations created using the STAV visualization tool (Stenetorp et al, 2011).
each document, the measured performance and even
ranking of systems participating in the shared task is
notably altered.
2 Background
In this work, we focus on the definition of the
event extraction task first introduced in the BioNLP
Shared Task 2009.1 The task targets the extrac-
tion of events, represented as n-ary associations of
participants (entities or other events), each marked
as playing a specific role such as Theme or Cause
in the event. Each event is assigned a type such
as BINDING or PHOSPHORYLATION from a fixed,
task-specific set. Events are further typically associ-
ated with specific trigger expressions that state their
occurrence in text. As physical entities such as pro-
teins are also identified in the setting with specific
spans referring to the real-world entities in text, the
overall task is ?text-bound? in the sense of requiring
not only the extraction of targeted statements from
text, but also the identification of specific regions of
text expressing each piece of extracted information.
Events can further be marked with modifiers iden-
tifying additional features such as being explicitly
negated or stated in a speculative context. Figure 1
shows an illustration of event annotations.
This BioNLP ST 2009 formulation of the event
extraction task was followed also in three 2011 main
tasks: the GE (Kim et al, 2011c), ID (Pyysalo et al,
2011a) and EPI (Ohta et al, 2011) tasks. A vari-
ant of this representation that omits event triggers
was applied in the BioNLP ST 2011 bacteria track
(Bossy et al, 2011), and simpler, binary relation-
type representations were applied in three support-
ing tasks (Nguyen et al, 2011; Pyysalo et al, 2011b;
Jourde et al, 2011). Due to the challenges of con-
sistent evaluation and processing for tasks involv-
1While far from the only formulation proposed in the litera-
ture, this specific task setting is the most frequently considered
and arguably a de facto standard for domain event extraction.
ing different representations, we focus in this work
specifically on the three 2011 main tasks sharing a
uniform representation: GE, ID and EPI.
3 New Resources for Event Extraction
In this section, we present the new collection of au-
tomatically created event analyses and demonstrate
one use of the data through an evaluation of events
that no system could successfully extract.
3.1 Data Compilation
Following the BioNLP ST 2011, the MSR-NLP
group called for the release of outputs from various
participating systems (Quirk et al, 2011) and made
analyses of their system available.2 Despite the ob-
vious benefits of the availability of these resources,
we are not aware of other groups following this ex-
ample prior to the time of this publication.
To create the combined resource, we approached
each group that participated in the three targeted
BioNLP ST 2011 main tasks to ask for their support
to the creation of a dataset including analyses from
their event extraction systems. This suggestion met
with the support of all but a few groups that were
approached.3 The groups providing analyses from
their systems into this merged resource are summa-
rized in Table 1, with references to descriptions of
the systems used to create the included analyses. We
compiled for each participant and each task both the
final test set submission and a comparable submis-
sion for the separate development set.
As the gold annotations for the test set are only
available for evaluation through an online interface
(in order to avoid overfitting and assure the compa-
rability of results), it is important to provide also de-
velopment set analyses to permit direct comparison
2http://research.microsoft.com/bionlp/
3We have yet to hear back from a few groups, but none has
yet explicitly denied the release of their data. Should any re-
maining group accept the release of their data, we will release a
new, extended version of the resource.
101
Task System
Team GE EPI ID BB BI CO REL REN description
UTurku 1 1 1 1 1 1 1 1 Bjo?rne and Salakoski (2011)
ConcordU 1 1 1 1 1 1 Kilicoglu and Bergler (2011)
UMass 1 1 1 Riedel and McCallum (2011)
Stanford 1 1 1 McClosky et al (2011)
FAUST 1 1 1 Riedel et al (2011)
MSR-NLP 1 1 Quirk et al (2011)
CCP-BTMG 1 1 Liu et al (2011)
BMI@ASU 1 Emadzadeh et al (2011)
TM-SCS 1 Bui and Sloot (2011)
UWMadison 1 Vlachos and Craven (2011)
HCMUS 1 1 Le Minh et al (2011)
PredX 1 -
VIBGhent 1 Van Landeghem et al (2011a)
Table 1: BioNLP ST 2011 participants contributing to the combined resource.
Events
Task Gold FN Recall
GE (task 1) 3250 1006 69.05%
EPI (CORE task) 601 129 78.54%
ID (CORE task) 691 183 73.52%
Table 2: Recall for the union of analyses from systems
included in the combined dataset.
against gold annotations. The inclusion of both de-
velopment and test set annotations also allows e.g.
the study of system combination approaches where
the combination parameters are estimated on devel-
opment data for final testing on the test set (Kim et
al., 2011a).
3.2 Evaluation
We demonstrate the use of the newly compiled
dataset through a manual evaluation of GE, EPI and
ID main task development set gold standard events
that are not extracted by any of the systems for
which analyses were available.4 We perform eval-
uation on the GE subtask 1 and the EPI and ID
task CORE subtasks, as all participating systems ad-
dressed the extraction targets of these subtasks.
We first evaluated each of the analyses against the
development set of the respective task using the of-
ficial shared task evaluation software, using options
for the evaluation tools to list the sets of true posi-
tive (TP), false positive (FP) and false negative (FN)
4The final collection includes analyses from the systems of
two groups that agreed to the release of their data after the com-
pletion of this analysis, but we expect the results to largely hold
also for the final collection.
events. We then selected for each of the three tasks
the set of events that were included in the FN list
for all systems. This gives the results for the re-
call of the union of all systems shown in Table 2.
The recall of the system union is approximately 30%
points higher than that of any individual GE system
(Kim et al, 2011c) and 25% points higher for EPI
and ID (Ohta et al, 2011; Pyysalo et al, 2011a),
suggesting potential remaining benefits from system
combination. Nevertheless, a substantial fraction of
the total set of gold events remains inaccessible also
to this system union.
We then selected a random set of 100 events from
each of the three sets of events that were not re-
covered by any system (i.e. 300 events in total) and
performed a manual evaluation to identify frequent
properties of these events that could contribute to
extraction failures. In brief, we first performed a
brief manual evaluation to identify common charac-
teristics of these events, and then evaluated the 300
events individually to identify the set of these char-
acteristics that apply to each event.
The results of the evaluation for common cases
are shown in Table 3. We find that the most fre-
quent property of the unrecoverable events is that
they involve implicit arguments (Gerber and Chai,
2010), a difficult challenge that has not been ex-
tensively considered in domain event extraction. A
closely related issue are events involving arguments
in a sentence different from that containing the trig-
ger (?cross-sentence?), connected either implicitly
or through explicit coreference (?coreference?). Al-
102
Type GE EPI ID Total
Implicit argument 18 33 15 66
Cross-sentence 14 40 4 58
Weak trigger 28 14 11 53
Coreference 12 20 18 50
Static Relation 6 28 6 40
Error in gold 17 4 9 30
Ambiguous type 2 9 11 22
Shared trigger 2 12 1 15
Table 3: Manual evaluation results for features of events
that could not be recovered by any system.
though coreference was considered as as separate
task in BioNLP ST 2011 (Nguyen et al, 2011), it is
clear that it involves many remaining challenges for
event extraction systems. Similarly, events where
explicit arguments are connected to other arguments
through ?static? relations such as part-of (e.g. ?A
binds the X domain of B?) represent a known chal-
lenge (Pyysalo et al, 2011b). These results sug-
gest that further advances in event extraction perfor-
mance could be gained by the integration of systems
for the analysis of coreference and static relations,
approaches for which some success has already been
demonstrated in recent efforts (Van Landeghem et
al., 2010; Yoshikawa et al, 2011; Miwa et al, 2012).
?Weak? trigger expressions that must be inter-
preted in context to determine whether they express
an event, as well as a related class of events whose
type must be disambiguated with reference to con-
text (?ambiguous type?) are comparatively frequent
in the three tasks, while EPI in particular involves
many cases where a trigger is shared between mul-
tiple events ? an issue for approaches that assume
each token can be assigned at most a single class.
Finally, we noted a number of cases that we judged
to be errors in the gold annotation; the number
is broadly in line with the reported inter-annotator
agreement for the data (see e.g. Ohta et al (2011)).
While there is an unavoidable subjective com-
ponent to evaluations such as this, we note that a
similar evaluation performed following the BioNLP
Shared Task 2009 using test set data reached broadly
comparable results (Kim et al, 2011a). The newly
compiled dataset represents the first opportunity for
those without direct access to the test set data and
submissions to directly assess the task results, as
demonstrated here. We hope that this resource will
encourage further exploration of both the data, the
system analyses and remaining challenges in event
extraction.
4 New Perspectives to Event Extraction
As discussed in Section 2, the BioNLP ST event ex-
traction task is ?text-bound?: each entity and event
annotation is associated with a specific span of text.
Contrasted to the alternative approach where anno-
tations are document-level only, this approach has
a number of important benefits, such as allowing
machine learning methods for event extraction to
be directly trained on fully and specifically anno-
tated data without the need to apply frequently error-
prone heuristics (Mintz et al, 2009) or develop ma-
chine learning methods addressing the mapping be-
tween text expressions and document-level annota-
tions (Riedel et al, 2010). Many of the most suc-
cessful event extraction approaches involve direct
training of machine learning methods using the text-
bound annotations (Riedel and McCallum, 2011;
Bjo?rne and Salakoski, 2011; McClosky et al, 2011).
However, while the availability of text-bound anno-
tations in data provided to task participants is clearly
a benefit, there are drawbacks to the choice of ex-
clusive focus on text-bound annotations in system
output, including issues relating to evaluation and
the applicability of methods to the task. In the fol-
lowing section, we discuss some of these issues and
propose alternatives to representation and evaluation
addressing them.
4.1 Evaluation
The evaluation of the BioNLP ST is instance-based
and text-bound: each event in gold annotation and
each event extracted by a system is considered in-
dependently, separating different mentions of the
?same? real-world event. This is the most detailed
(sensitive) evaluation setting permitted by the data,
and from a technical perspective a reasonable choice
for ranking systems performing the task.
However, from a practical perspective, this eval-
uation setting arguably places excessively strict de-
mands on systems, and may result in poor correla-
tion between measured performance and the practi-
cal value of systems. Our motivating observations
are that specific real-world events tend to be men-
103
tioned multiple times in a single publication ? espe-
cially the events that are of particular importance in
the study ? and that there are few practical applica-
tions for which it is necessary to find each such re-
peated mention. For example, in literature search for
e.g. pathway or database curation support, one typi-
cal information need is to identify biomolecular re-
actions involving a specific protein. Event extraction
can support such needs either by summarizing all
events involving the protein that could be extracted
from the literature (Van Landeghem et al, 2011b), or
by retrieving documents (perhaps showing relevant
text snippets) containing such events (Ohta et al,
2010). For the former to meet the information need,
it may be sufficient that each different event is ex-
tracted once from the entire literature; for the latter,
once from each relevant document. For uses such
as these, there is no obvious need for, or, indeed,
no very obvious benefit from the ability of extrac-
tion systems to separately enumerate every mention
of every event in every publication. It is easy to en-
vision other practical use cases where instance-level
extraction performance is at best secondary and, we
argue, difficult to identify ones where it is of critical
importance.
For applications such as these, the important
question is the reliability of the system at identify-
ing events either on the level of documents or on the
level of (a relevant subset of) the literature, rather
than on the level of individual mentions. For a more
complete and realistic picture of the practical value
of event extraction methods, measures other than
instance-level should thus also be considered.
4.2 Task setting
While applications can benefit from the ability of
IE systems to identify a specific span of text sup-
porting extracted information,5 the requirement of
the BioNLP ST setting that the output of event ex-
traction systems must identify specific text spans for
each entity and event makes it complex or impossi-
ble to address the task using a number of IE methods
that might otherwise represent feasible approaches
to event extraction.
5For example, for curation support tasks, this allows the hu-
man curator to easily check the correctness of extracted infor-
mation and helps to select ?evidence sentences?, as included in
many databases.
For example, Patwardhan and Riloff (2007) and
Chambers and Jurafsky (2011) consider an IE ap-
proach where the extraction targets are MUC-4 style
document-level templates (Sundheim, 1991), the
former a supervised system and the latter fully un-
supervised. These methods and many like them for
tasks such as ACE (Doddington et al, 2004) work
on the document level, and can thus not be readily
applied or evaluated against the existing annotations
for the BioNLP shared tasks. Enabling the appli-
cation of such approaches to the BioNLP ST could
bring valuable new perspectives to event extraction.
4.3 Alternative evaluation
We propose a new mode of evaluation that otherwise
follows the primary BioNLP ST evaluation criteria,
but incorporates the following two exceptions:
1. remove the requirement to match trigger spans
2. only require entity texts, not spans, to match
The first alternative criterion has also been previ-
ously considered in the GE task evaluation (Kim et
al., 2011c); the latter has, to the best of our knowl-
edge, not been previously considered in domain
event extraction. We additionally propose to con-
sider only the minimal set of events that are unique
on the document level (under the evaluation criteria),
thus eliminating effects from repeated mentions of a
single event on evaluated performance. We created
tools implementing this mode of evaluation with ref-
erence to the BioNLP ST 2011 evaluation tools.
While this type of evaluation has, to the best of
our knowledge, not been previously applied specif-
ically in biomedical event extraction, it is closely
related (though not identical) to evaluation criteria
applied in MUC, ACE, and the in-domain PPI re-
lation extraction tasks in BioCreative (Krallinger et
al., 2008).
4.4 Alternative representation
A true conversion to a document-level, ?off the
page? representation would require manual anno-
tation efforts to identify the real-world entities and
events referred to in text (Doddington et al, 2004).
However, it is possible to reasonably approximate
such a representation through an automatic heuristic
conversion.
104
BioNLP Shared Task
T1 Protein 0 5 CIITA
T2 Protein 21 28 TAFII32
T3 Binding 6 15 interacts
E1 Binding:T3 Theme:T1 Theme2:T2
T4 Protein 54 61 TAFII32
T5 Protein 66 71 CIITA
T6 Binding 33 45 interactions
E2 Binding:T6 Theme:T4 Theme2:T5
Document level
T1 Protein CIITA
T2 Protein TAFII32 
E1 Binding Theme:T1 Theme2:T2
CIITA interacts with TAFII32 ... interactions between TAFII32 and CIITA are
Pro Binding Protein Binding Protein ProTh Th2 Theme
Theme2
...
Figure 2: Illustration of BioNLP Shared Task annotation format and the proposed document-level (?off-the-page?)
format.
We first introduce a non-textbound annotation for-
mat that normalizes over differences in e.g. argu-
ment order and eliminates duplicate events. The for-
mat largely follows that of the shared task but re-
moves any dependencies and references to text off-
sets (see Figure 2). The conversion process into this
representation involves a number of steps. First, we
merge duplicate pairs of surface strings and types,
as different mentions of the same entity in different
parts of the text are no longer distinguishable in the
representation. In the original format, equivalence
relations (Kim et al, 2011a) are annotated only for
specific mentions. When ?raising? the annotations
to the document level, equivalence relations are rein-
terpreted to cover the full document by extending
the equivalence to all mentions that share the surface
form and type with members of existing equivalence
classes. Finally, we implemented an event equiv-
alence comparison to remove duplicate annotations
from each document. The result of the conversion
to this alternate representation is thus an ?off-the-
page? summary of the unique set of events in the
document.
This data can then be used for training and com-
parison of methods analogously to the original anno-
tations, but without the requirement that all analyses
include text-bound annotations.
4.5 Experimental Results
We next present an evaluation using the alternative
document-level event representation and evaluation,
comparing its results to those for the primary shared
task evaluation criteria. As comparatively few of the
Primary criteria New criteria
Group Rec. Prec. F Rec. Prec. F
FAUST 49.41 64.75 56.04 53.10 67.56 59.46
UMass 48.49 64.08 55.20 52.55 66.57 58.74
UTurku 49.56 57.65 53.30 54.23 60.11 57.02
MSR-NLP 48.64 54.71 51.50 53.55 58.24 55.80
ConcordU 43.55 59.58 50.32 47.42 60.85 53.30
UWMadison 42.56 61.21 50.21 46.09 62.50 53.06
Stanford 42.36 61.08 50.03 46.48 63.22 53.57
BMI@ASU 36.91 56.63 44.69 41.15 61.44 49.29
CCP-BTMG 31.57 58.99 41.13 34.82 66.89 45.80
TM-SCS 32.73 45.84 38.19 38.02 50.87 43.51
HCMUS 10.12 27.17 14.75 14.50 40.05 21.29
Table 4: Comparison of BioNLP ST 2011 GE task 1 re-
sults.
shared task participants attempted subtasks 2 and 3
for GE or the FULL task setting for EPI and ID, we
consider only GE subtask 1 and the EPI and ID task
CORE extraction targets in these experiments. We
refer to the task overviews for the details of the sub-
tasks and the primary evaluation criteria (Kim et al,
2011c; Pyysalo et al, 2011a; Ohta et al, 2011).
Tables 4, 5 and 6 present the results for the
GE, EPI and ID tasks, respectively. For GE, we
see consistently higher F-scores for the new crite-
ria, in most cases reflecting primarily an increase
in recall, but also involving increases in precision.
The F-score differences range between 3-4% for
most high-ranking systems, with more substantial
increases for lower-ranking systems. Notable in-
creases in precision are seen for some systems (e.g.
HCMUS), indicating that the systems comparatively
frequently extract correct information, but associ-
ated with the wrong spans of text.
105
Primary criteria New criteria
Group Rec. Prec. F Rec. Prec. F
UTurku 68.51 69.20 68.86 74.20 69.14 71.58
FAUST 59.88 80.25 68.59 67.04 76.82 71.60
MSR-NLP 55.70 77.60 64.85 59.24 77.66 67.21
UMass 57.04 73.30 64.15 65.76 69.65 67.65
Stanford 56.87 70.22 62.84 62.74 67.12 64.86
CCP-BTMG 45.06 63.37 52.67 54.62 63.17 58.58
ConcordU 40.28 76.71 52.83 48.41 76.57 59.32
Table 5: Comparison of BioNLP ST 2011 EPI CORE
task results.
For EPI (Table 5), we find comparable differences
in F-score to those for GE, but there is a signifi-
cant difference in the precision-recall balance: the
majority of systems show over 5% points higher re-
call under the new criteria, but many show substan-
tial losses in precision, while for GE precision was
also systematically increased. This effect was not
unexpected: we judge this to reflect primarily the
increased number of opportunities to extract each
unique event (higher recall) combined with the com-
paratively higher effect from errors from the reduc-
tion in the total number of unique correct extraction
targets (lower precision). It is not clear from our
analysis why a comparable effect was not seen for
GE. Interestingly, most systems show a better pre-
cision/recall balance under the new criteria than the
old, despite not optimizing for these criteria.
For ID (Table 6), we find a different effect also on
F-score, with all but one system showing reduced
performance under the new criteria, with some very
clear drops in performance; the only system to ben-
efit is UTurku. Analysis suggests that this effect
traces primarily to a notable reduction in the number
of simple PROCESS events that take no arguments6
when considering unique events on the document
level instead of each event mention independently.7
Conversely, the Stanford system, which showed the
highest instance-level performance in the extraction
of PROCESS type events (see Pyysalo et al (2011a)),
shows a clear loss in precision.
6The ID task annotation criteria call for mentions of some
high-level biological processes such as ?infection? to be anno-
tated as PROCESS even if no explicit participants are mentioned
(Pyysalo et al, 2011a).
7It is interesting to note that there was an error in the
UTurku system implementation causing it to fail to output any
events without arguments (Jari Bjo?rne, personal communica-
tion), likely contributing to the effect seen here.
Primary criteria New criteria
Group Rec. Prec. F Rec. Prec. F
FAUST 50.84 66.35 57.57 50.11 65.33 56.72
UMass 49.67 62.39 55.31 49.34 60.98 54.55
Stanford 49.16 56.37 52.52 42.00 50.80 45.98
ConcordU 50.91 43.37 46.84 43.42 37.18 40.06
UTurku 39.23 49.91 43.93 48.03 51.84 49.86
PredX 23.67 35.18 28.30 20.94 30.69 24.90
Table 6: Comparison of BioNLP ST 2011 ID CORE task
results.
The clear differences in performance and the
many cases in which the system rankings under the
two criteria differ demonstrate that the new evalua-
tion criteria can have a decisive effect in which ap-
proaches to event extraction appear preferred. While
there may be cases for which the original shared task
criteria are preferred, there is at the very minimum
a reasonable argument to be made that the emphasis
these criteria place on the extraction of each instance
of simple events is unlikely to reflect the needs of
many practical applications of event extraction.
While these experimental results demonstrate that
the new evaluation criteria emphasize substantially
different aspects of the performance of the systems
than the original criteria, they cannot per se serve
as an argument in favor of one set of criteria over
another. We hope that these results and the accom-
panying tools will encourage increased study and
discussion of evaluation criteria for event extraction
and more careful consideration of the needs of spe-
cific applications of the technology.
5 Discussion and Conclusions
We have presented a new resource combining analy-
ses from the systems participating in the GE, ID and
EPI main tasks of the BioNLP Shared Task 2011,
compiled with the collaboration of groups partic-
ipating in these tasks. We demonstrated one use
of the resource through an evaluation of develop-
ment set events that none of the participating sys-
tems could recover, finding that events involving
implicit arguments, coreference and participants in
more than once sentence continue to represent chal-
lenges to the event extraction systems that partici-
pated in these tasks.
We further argued in favor of new perspectives to
the evaluation of domain event extraction systems,
106
emphasizing in particular the need for document-
level, ?off-the-page? representations and evaluation
to complement the text-bound, instance-level eval-
uation criteria that have so far been applied in the
shared task evaluation. We proposed a variant of
the shared task standoff representation for support-
ing such evaluation, and introduced evaluation tools
implementing the proposed criteria. An evaluation
supported by the introduced resources demonstrated
that the new criteria can in cases provide substan-
tially different results and rankings of the systems,
confirming that the proposed evaluation can serve
as an informative complementary perspective into
event extraction performance.
In future work, we hope to further extend the cov-
erage of the provided system outputs as well as their
analysis to cover all participants of all tasks in the
BioNLP Shared Task 2011. We also aim to use the
compiled resource in further study of appropriate
criteria for the evaluation of event extraction meth-
ods and deeper analysis of the remaining challenges
in event extraction.
To encourage further study of all aspects of event
extraction, all resources and tools introduced in this
study are provided freely to the community from
http://2011.bionlp-st.org.
Acknowledgments
We wish to thank the members of all groups con-
tributing to the combined resource, and in particular
the members of the MSR-NLP group for providing
both the initial suggestion for its creation as well as
the first publicly released analyses from their sys-
tem. We would also like to thank the anonymous
reviewers for their many insightful comments.
This work was funded in part by UK Biotechnol-
ogy and Biological Sciences Research Council (BB-
SRC) under project Automated Biological Event Ex-
traction from the Literature for Drug Discovery (ref-
erence number: BB/G013160/1), by the Ministry of
Education, Culture, Sports, Science and Technology
of Japan under the Integrated Database Project and
by the Swedish Royal Academy of Sciences.
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,
and Tapio Salakoski. 2010. Complex event extraction
at PubMed scale. Bioinformatics, 26(12):i382?390.
Robert Bossy, Julien Jourde, Philippe Bessie`res, Maarten
van de Guchte, and Claire Ne?dellec. 2011. BioNLP
Shared Task 2011 - Bacteria Biotope. In Proceedings
of BioNLP Shared Task 2011 Workshop, pages 56?64.
Quoc-Chinh Bui and Peter. M.A. Sloot. 2011. Extract-
ing biological events from text using simple syntactic
patterns. In Proceedings of BioNLP Shared Task 2011
Workshop, pages 143?146.
Nathanael Chambers and Dan Jurafsky. 2011. Template-
based information extraction without the templates. In
Proceedings of the ACL-HLT 2011, pages 976?986.
George Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The automatic content extraction
(ACE) program?tasks, data, and evaluation. In Pro-
ceedings of LREC, volume 4, pages 837?840.
Ehsan Emadzadeh, Azadeh Nikfarjam, and Graciela
Gonzalez. 2011. Double layered learning for bio-
logical event extraction from text. In Proceedings of
BioNLP Shared Task 2011 Workshop, pages 153?154.
Matthew Gerber and Joyce Chai. 2010. Beyond nom-
bank: A study of implicit arguments for nominal predi-
cates. In Proceedings of ACL 2010, pages 1583?1592.
Julien Jourde, Alain-Pierre Manine, Philippe Veber,
Kare?n Fort, Robert Bossy, Erick Alphonse, and
Philippe Bessie`res. 2011. BioNLP Shared Task
2011 ? Bacteria gene interactions and renaming. In
Proceedings of BioNLP Shared Task 2011 Workshop,
pages 65?73.
Brian Kemper, Takuya Matsuzaki, Yukiko Matsuoka,
Yoshimasa Tsuruoka, Hiroaki Kitano, Sophia Anani-
adou, and Jun?ichi Tsujii. 2010. PathText: a text min-
ing integrator for biological pathway visualizations.
Bioinformatics, 26(12):i374?i381.
Halil Kilicoglu and Sabine Bergler. 2011. Adapting a
general semantic interpretation approach to biologi-
cal event extraction. In Proceedings of the BioNLP
Shared Task 2011 Workshop.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2011a. Extracting
bio-molecular events from literature - the BioNLP?09
shared task. Computational Intelligence, 27(4):513?
540.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011b.
107
Overview of BioNLP Shared Task 2011. In Proceed-
ings of BioNLP Shared Task, pages 1?6.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Akinori
Yonezawa. 2011c. Overview of the Genia Event task
in BioNLP Shared Task 2011. In Proceedings of the
BioNLP Shared Task 2011 Workshop.
Martin Krallinger, Florian Leitner, Carlos Rodriguez-
Penagos, Alfonso Valencia, et al 2008. Overview
of the protein-protein interaction annotation extrac-
tion task of BioCreative II. Genome Biology, 9(Suppl
2):S4.
Quang Le Minh, Son Nguyen Truong, and Quoc Ho Bao.
2011. A pattern approach for biomedical event anno-
tation. In Proceedings of BioNLP Shared Task 2011
Workshop, pages 149?150.
Haibin Liu, Ravikumar Komandur, and Karin Verspoor.
2011. From graphs to events: A subgraph matching
approach for information extraction from biomedical
text. In Proceedings of the BioNLP Shared Task 2011
Workshop.
David McClosky, Mihai Surdeanu, and Christopher Man-
ning. 2011. Event extraction as dependency parsing.
In Proceedings of ACL-HLT 2011, pages 1626?1635.
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extraction
without labeled data. In Proceedings of ACL-IJCNLP
2009, pages 1003?1011.
Makoto Miwa, Paul Thompson, and Sophia Ananiadou.
2012. Boosting automatic event extraction from the
literature using domain adaptation and coreference
resolution. Bioinformatics.
Ngan Nguyen, Jin-Dong Kim, and Jun?ichi Tsujii.
2011. Overview of BioNLP 2011 Protein Coreference
Shared Task. In Proceedings of BioNLP Shared Task
2011 Workshop, pages 74?82.
Tomoko Ohta, Takuya Matsuzaki, Naoaki Okazaki,
Makoto Miwa, Rune S?tre, Sampo Pyysalo, and
Jun?ichi Tsujii. 2010. Medie and info-pubmed: 2010
update. BMC Bioinformatics, 11(Suppl 5):P7.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP Shared Task 2011
Workshop.
Siddharth Patwardhan and Ellen Riloff. 2007. Effec-
tive information extraction with semantic affinity pat-
terns and relevant regions. In Proceedings of EMNLP-
CoNLL 2007, pages 717?727.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011a.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of the
BioNLP Shared Task 2011 Workshop.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii.
2011b. Overview of the entity relations (REL) sup-
porting task of BioNLP Shared Task 2011. In Pro-
ceedings of BioNLP Shared Task 2011 Workshop,
pages 83?88.
Chris Quirk, Pallavi Choudhury, Michael Gamon, and
Lucy Vanderwende. 2011. MSR-NLP entry in
BioNLP Shared Task 2011. In Proceedings of BioNLP
Shared Task 2011 Workshop, pages 155?163.
Sebastian Riedel and Andrew McCallum. 2011. Fast and
robust joint models for biomedical event extraction. In
Proceedings of EMNLP 2011, pages 1?12.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions without
labeled text. Machine Learning and Knowledge Dis-
covery in Databases, pages 148?163.
Sebastian Riedel, David McClosky, Mihai Surdeanu, An-
drew McCallum, and Chris Manning. 2011. Model
combination for event extraction in BioNLP 2011. In
Proceedings of the BioNLP Shared Task 2011 Work-
shop.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP Shared Task 2011 Work-
shop.
Beth M. Sundheim. 1991. Third message understanding
evaluation and conference (MUC-3): Phase 1 status
report. In Proceedings of the Speech and Natural Lan-
guage Workshop, pages 301?305.
Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,
and Yves Van de Peer. 2010. Integration of static re-
lations to enhance event extraction from text. In Pro-
ceedings of BioNLP 2010, pages 144?152.
Sofie Van Landeghem, Thomas Abeel, Bernard De Baets,
and Yves Van de Peer. 2011a. Detecting entity rela-
tions as a supporting task for bio-molecular event ex-
traction. In Proceedings of BioNLP Shared Task 2011
Workshop, pages 147?148.
Sofie Van Landeghem, Filip Ginter, Yves Van de Peer,
and Tapio Salakoski. 2011b. Evex: a pubmed-scale
resource for homology-based generalization of text
mining predictions. In Proceedings of BioNLP 2011
Workshop, pages 28?37.
Andreas Vlachos and Mark Craven. 2011. Biomedical
event extraction from abstracts and full papers using
search-based structured prediction. In Proceedings of
BioNLP Shared Task 2011 Workshop, pages 36?40.
Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hi-
rao, Masayuki Asahara, and Yuji Matsumoto. 2011.
Coreference based event-argument relation extraction
on biomedical text. Journal of Biomedical Semantics,
2(Suppl 5):S6.
108
Proceedings of the ACL-2012 Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM-2012),
pages 47?56, Jeju, Republic of Korea, 13 July 2012. c?2012 Association for Computational Linguistics
Bridging the Gap Between Scope-based and Event-based
Negation/Speculation Annotations: A Bridge Not Too Far
Pontus Stenetorp1 Sampo Pyysalo2,3 Tomoko Ohta2,3
Sophia Ananiadou2,3 and Jun?ichi Tsujii2,3,4
1Department of Computer Science, University of Tokyo, Tokyo, Japan
2School of Computer Science, University of Manchester, Manchester, United Kingdom
3National Centre for Text Mining, University of Manchester, Manchester, United Kingdom
4Microsoft Research Asia, Beijing, People?s Republic of China
{pontus,smp,okap}@is.s.u-tokyo.ac.jp
sophia.ananiadou@manchester.ac.uk
jtsujii@microsoft.com
Abstract
We study two approaches to the marking of
extra-propositional aspects of statements in
text: the task-independent cue-and-scope rep-
resentation considered in the CoNLL-2010
Shared Task, and the tagged-event representa-
tion applied in several recent event extraction
tasks. Building on shared task resources and
the analyses from state-of-the-art systems rep-
resenting the two broad lines of research, we
identify specific points of mismatch between
the two perspectives and propose ways of ad-
dressing them. We demonstrate the feasibility
of our approach by constructing a method that
uses cue-and-scope analyses together with a
small set of features motivated by data anal-
ysis to predict event negation and speculation.
Evaluation on BioNLP Shared Task 2011 data
indicates the method to outperform the nega-
tion/speculation components of state-of-the-
art event extraction systems.
The system and resources introduced in this
work are publicly available for research pur-
poses at: https://github.com/ninjin/eepura
1 Introduction
Understanding extra-propositional aspects of texts
is key to deeper understanding of statements con-
tained in natural language texts. Extra-propositional
aspects such as the polarity of key statements have
long been acknowledged to be critical for user-
facing applications such as information retrieval
(Friedman et al, 1994; Hersh, 1996). In recogni-
tion of this need, a number of recent information
extraction (IE) resources involving structured repre-
sentations of text statements have explicitly included
some marking of certainty and polarity (LDC, 2005;
Kim et al, 2009; Saur and Pustejovsky, 2009; Kim
et al, 2011a; Thompson et al, 2011).
Although extra-propositional aspects are recog-
nised as important, there is no clear consensus on
how to address their annotation and extraction from
text. Some comparatively early efforts focused on
the detection of negation cue phrases associated with
specific (previously detected) terms through regu-
lar expression-based rules (Chapman et al, 2001).
A number of later efforts identified the scope of
negation cues with phrases in constituency analy-
ses in sentence structure (Huang and Lowe, 2007).
Drawing in part on this work, the BioScope corpus
(Vincze et al, 2008) applied a representation where
both cues and their associated scopes are marked as
contiguous spans of text (Figure 1 bottom). This ap-
proach was also applied in the CoNLL-2010 Shared
Task (Farkas et al, 2010), in which 13 participat-
ing groups proposed approaches for Task 2, which
required the identification of uncertainty cues and
their associated scopes in text. In the following,
we will term this task-independent, linguistically-
motivated approach as the cue-and-scope represen-
tation (please see Vincze et al (2008) for details re-
garding the representation).
For IE efforts, more task-oriented representations
are commonly applied. In an effort to formalise
and drive research for extracting structured repre-
sentations of statements regarding molecular biol-
ogy, the ongoing series of BioNLP shared tasks
have addressed biomedical Event Extraction (EE)
(Kim et al, 2009; Kim et al, 2011a). The extra-
propositional targets of negation and speculation
47
Figure 1: Example illustrating cue-and-scope and
event-based negation marking. ?Crossing-out?
marks events as negated. PRO, TH and NEG are ab-
breviations for PROTEIN, THEME and NEGATION,
respectively.
of extracted events were already included in the
first task in the series, using a representation where
events can be assigned ?flags? to mark them as being
negated, speculated, or both (Figure 1 upper). Due
to space limitations we refer the reader to Kim et al
(2009) for a detailed explanation of the representa-
tion; similar representations have been applied also
in previous event extraction tasks (LDC, 2005).
There are a number of ways in which task-
oriented, event-based approaches could benefit from
the existing linguistically-oriented cue-and-scope
methods for identifying extra-propositional aspects
of text statements. However, there has been sur-
prisingly little work exploring the combination of
the approaches, and comparatively few methods ad-
dressing the latter task in detail. Only three out
of the 24 participants in the BioNLP Shared Task
2009 submitted results for the non-mandatory nega-
tion/speculation task, and although negation and
speculation were also considered in three main tasks
for the 2011 follow-up event (Kim et al, 2011a),
the trend continued, with only two participants ad-
dressing the negation/speculation aspects of the task.
We are aware of only two studies exploring the rela-
tionship between the cue-and-scope and event-based
representations: in a manual analysis of scope over-
lap with tagged events, Vincze et al (2011) identi-
fied a number of issues and mismatches in annota-
tion scope and criteria, which may explain in part
the lack of methods combining these two lines of
research. Kilicoglu and Bergler (2010) approached
the problem from the opposite direction and used an
existing EE system to extract cue-and-scope annota-
tions in the CoNLL-2010 Shared Task.
In this work, we take a high-level perspective,
seeking to bridge the linguistically oriented frame-
work and the more application-oriented event frame-
work to overcome the mismatches demonstrated
by Vincze et al (2011). Specifically, we aim to
determine how cue-and-scope recognition systems
can be used to produce a state-of-the-art nega-
tion/speculation detection system for the EE task.
2 Resources
Several existing resources can support the investiga-
tion of the relationship between the linguistically-
oriented and task-oriented perspectives on nega-
tion/speculation detection. In this study, we make
use of the following resources.
First, we study the three BioNLP 2011 Shared
Task corpora that include annotation for negation
and speculation: the GE, EPI and ID main task cor-
pora (Table 1). Second, we make use of support-
ing analyses provided for these corpora in response
to a call sent by the BioNLP Shared Task organis-
ers to the developers of third-party systems (Stene-
torp et al, 2011). Specifically, we use the output
of the BiographTA NeSp Scope Labeler (here re-
ferred to as CLiPS-NESP) (Morante and Daelemans,
2009; Morante et al, 2010) provided by the Univer-
sity of Antwerp CLiPS center. This system provides
cue-and-scope analyses for negation and speculation
and was demonstrated to have state-of-the-art per-
formance at the relevant CoNLL-2010 Shared Task.
Finally, we make use of the event analyses created
by systems that participated in the BioNLP Shared
Task, made available to the research community for
the majority of the shared task submissions (Pyysalo
et al, 2012). These analyses represent the state-
of-the-art in event extraction and their capability to
detect event structures as well as marking them for
negation and speculation.
The above three resources present us with many
opportunities to relate scope-based annotations to
three highly relevant event-based corpora containing
negation/speculation annotations.
3 Manual Analysis
To gain deeper insight into the data and the chal-
lenges in combining the cue-and-scope and event-
oriented perspectives, we performed a manual anal-
ysis of the corpus annotations using the manually
48
Name Negated Events Speculated Events Negated Spans Speculated Spans Publication
EPI 103 (5.6%) 70 (3.8%) 561 1,032 Ohta et al (2011)
GE 759 (7.4%) 623 (6.0%) 1,308 1,968 Kim et al (2011b)
ID 69 (3.3%) 26 (1.2%) 415 817 Pyysalo et al (2011)
Table 1: Corpora used for our experiments along with annotation statistics for their respective training sets.
The parenthesised values are the relative proportion of negated/speculated event annotations.
Occ. (Ratio) EPI ID
Covered 26 (15.03%) 52 (56.52%)
Not-covered 135 (78.03%) 38 (41.30%)
Error-in-gold 12 (6.94%) 2 (2.18%)
Morphological 48 (27.75%) 11 (11.96%)
Hypothesis 44 (25.43%) 15 (16.30%)
Ellipsis 5 (2.89%) 0 (0.00%)
Argument-only 2 (1.16%) 10 (10.87%)
Table 2: Results from the Manual Data Analysis of
the EPI and ID test sets.
created BioNLP Shared Task training data event an-
notations, and the automatic annotations created for
this data by the CLiPS-NESP system. The test
data was held out and was not directly examined
at any point of our study. We performed the anal-
ysis specifically on the EPI and ID corpora, as the
GE corpus training set texts overlap with the train-
ing data for the CLiPS-NESP system (BioScope cor-
pus), and results on this data would thus not reflect
the performance of the system on unseen data, and
a comparison of the GE and BioScope gold anno-
tations was previously performed by Vincze et al
(2011).
The analysis was performed by an experienced
annotator with a doctoral degree in a related field
in biology, who individually examined each of the
events marked as negated and speculated in the
EPI and ID training corpora. For the analysis,
the CLiPS-NESP system output was super-imposed
onto the BioNLP Shared Task event annotations.
The annotator was asked to assign three primary
flags for each event that was marked as negated or
speculated: Covered if the event trigger was covered
by span(s) of the correct type with a correct cue in
the cue-and-span analysis, Not-covered if not Cov-
ered, and Error-in-gold if the negation/speculation
flag on the event annotation was itself incorrect. We
also identified a number of additional properties that
initial analysis suggested to frequently characterise
instances where the coverage of the cue-and-scope
system is lacking: Morphological was assigned if
the negation/speculation of an event could be in-
ferred only from the morphology of the word ex-
pressing the event, rather than from cue words in its
context (e.g. unphosphorylated, non-glycosylated);
Hypothesis for cases where speculation is marked
for events stated as hyphotheses1 under consider-
ation, e.g. ?We analysed the methylation status of
MGMT?; Ellipsis for cases where the modified ex-
pression is elided (e.g. ?A was phosphorylated but B
was not?); and Argument-only if the CLiPS-NESP
output had marked the argument of an event as
negated rather than the event trigger (we use argu-
ment in the sense it is used in the BioNLP Shared
Tasks, for example, in Figure 1 upper, the two argu-
ments of the event are ?fMimR? and ?fimA?).
The results of the analysis are summarised in Ta-
ble 2. We find that that the system shows a clear dif-
ference in coverage depending on the dataset. For
the ID dataset, a majority of the annotations are cov-
ered by the appropriate spans, while only a small mi-
nority are covered for EPI. Instead, the EPI dataset
contains a significant portion of events where extra-
propositional aspects can only be distinguished by
the morphology of the word expressing the event
(all Morphological cases were negation) as well as
events marked as speculated due to being expressed
as hypotheses under study.
The analysis thus identified specific ways in
which the applicability of negation-detection sys-
tems using a span-and-scope representation could be
improved for some tasks.
1While it is arguable whether such cases represent specula-
tion (Vincze et al, 2008), separation from affirmatively made
claims is clearly motivated for many applications.
49
Event-based
Scope-based
Negation/speculationdetection
Eventextraction
Oursystem
Figure 2: An illustration of our approach.
4 Methods
We next introduce the methods we apply for as-
signing negation and speculation flags to extracted
events.
4.1 Approach
To focus on the extra-propositional aspects of event
extraction, we only consider the assignment of the
negation and speculation flags, not the extraction of
the event structures that these mark. To our knowl-
edge, no previous work studying this subtask in iso-
lation from event extraction exists. Thus, in order to
be able to relate the performance of the methods we
consider to the performance of previously proposed
approaches, it is necessary to base the negation and
speculation detection on an event extraction analy-
sis. For this reason, we construct our methods us-
ing system outputs for systems participating in the
BioNLP Shared Task 2011, in effect creating a nega-
tion/speculation processing stage for a pipeline sys-
tem where the previous stage is the completion of
event analysis without negation/speculation detec-
tion (Figure 2).
Our methods thus take extracted events as input
and attempt to enrich the output with negation and
speculation annotations. This enables us to produce
a general system with the potential to be applied
together with any existing event extraction system.
Additionally, this allows us to directly compare our
system output with that of the negation/speculation
components of previously proposed monolithic sys-
tems by removing the existing negation and spec-
ulation output from submissions including this and
recreating these annotations using our methods.
4.2 Rule-based Methods
The most straightforward way of carrying over in-
formation from scope-based to event-based annota-
tions is to consider any event structure for which the
word or words stating the event (i.e. the event trig-
ger) is within the scope of a negation or speculation
be negated or speculated (respectively). We imple-
mented this simple heuristic as our initial rule-based
method.
One relatively common category of cases where
this heuristic fails that was identified in analysis re-
lates to events that take other events as arguments.
Consider, for example, the case illustrated in Fig-
ure 3. The speculation span is correctly identified as
covering the statement ?FimR modulates mfa1 ex-
pression?, and the event expressed through ?mod-
ulates? is identified as speculated. However, the
nested event, the expression of mfa1, is not spec-
ulated. To cover this case, we implemented what
we refer to as the root-heuristic, which prevents the
propagation of negation/speculation marking from
scopes to events that are the arguments of another
event contained in the same scope. The second rule-
based method we consider incorporates this addi-
tional heuristic.
Preliminary development set experiments indi-
cated that while the root-heuristic could improve
precision, the performance of the rule-based meth-
ods remained poor, in particular on the EPI dataset.
The results of the manual analysis (Section 3) sug-
gested this to trace in particular to two main issues,
namely differences between annotation criteria be-
tween BioScope and the shared task data (as noted
also by Vincze et al (2011)) and events which are
negated not by external cues but by morphological
alternations of the event trigger, such as ?unphos-
phorylated? expressing the absence of phosphory-
lation. As it would have been difficult to system-
atically incorporate both morphology and context
into the rule-based method without compromising
the generality of the approach, we opted to move to a
machine learning framework for further method de-
velopment. This allows us to continue to make use
of the existing cue-and-scope annotations while ex-
ploring the effects of other aspects of the text and
maintaining generality through retraining.
4.3 Machine Learning-based Methods
In developing a machine learning-based approach to
the negation/speculation task, we aimed to identify
and evaluate a minimal set of features directly mo-
50
Feature Example Value(s)
Heuristic ROOT/NON-ROOT
Heuristic-Cue possibility
Heuristic-Span One, possibility, . . .
Trigger-Text non-phosphorylated
Trigger-Prefixes no, non, non-, . . .
Trigger-Preceding-Context is, that, . . .
Trigger-Proceeding-Context mfa1, expression, . . .
Table 3: Machine learning features. The fea-
tures are categorised into three groups: features
based on cue-and-scope based heuristics (top), non-
contextual features derived from the event trigger
(middle), and features derived from the context of
the event trigger (bottom). These three feature sets
are abbreviated as E, M and C, respectively.
Figure 3: Example of a speculation span containing
two events, of which only one is speculated (marked
by a dashed border).
tivated by the analysis of the data and to use the
cue-and-scope analyses as much as possible. In par-
ticular, we wanted to avoid features requiring com-
putationally expensive analyses such as full pars-
ing or replicating the type of analyses performed by
the CLiPS-NESP system, focusing rather on specific
points where its output does not meet the needs of
the event-based approach.
We introduced features representing the heuristics
described in Section 4.2, marking each case as be-
ing either a root or non-root event in its scope (if
any). Drawing further on the cue-and-scope analy-
sis, we included as features the cue word and bag-of-
words features for all tokens in the scope (using sim-
ple white-space tokenisation). To address the issues
identified in manual analysis, we introduced features
for the event trigger text as well as character-based
prefixes of lengths 2 to 7 of the, intended primarily
to capture morphological negation.
All features presented above are derived only
from those parts of the sentence already marked ei-
ther by the event extraction or the cue-and-scope
system. However, due to the differences in anno-
tation guidelines for speculation annotations, we ex-
pect that the scope-based system will fail to mark
a significant portion of the speculation annotations.
To allow the system to learn to detect these, we in-
troduce a minimal set of contextual features, limited
to a bag-of-words representation of the three words
preceding and following the event trigger.
5 Experiments
We perform two sets of experiments, the first to eval-
uate our approach on gold annotations to give a fair
upper-limit to how well our negation/speculation de-
tection system could perform under ideal settings,
and the second to enrich the output of an event ex-
traction system with negation and speculation an-
notations, to evaluate real-world performance and
to allow direct comparison of our methods with
those incorporated in monolithic event extraction
and negation/speculation detection systems.
5.1 Corpora
For our experiments we used the GE, EPI and ID
corpora of the BioNLP Shared Task 2011 (Table 1).
We note that while the GE training set texts overlap
with the BioScope corpus used to train the CLiPS-
NESP system, the GE test set does not, and thus test
set results are not expected to be overfit.
We noted when performing development set
experiments that training machine learning-based
methods on the negation/speculation annotations of
the event-annotated corpora was problematic due to
the sparseness of these flags in the annotation. To
address this issue, we merge the training data of the
three corpora in all experiments with machine learn-
ing methods.
5.2 Baseline methods
We use the event analyses created by the UTurku
(Bjo?rne and Salakoski, 2011) and UConcordia (Kil-
icoglu and Bergler, 2011) systems for the BioNLP
2011, the only systems that included negation and
speculation analyses. To investigate the impact on a
system that did not include a negation/speculation
component, we further consider analyses created
51
Negation (R/P/F) EPI GE ID
H 29.23/31.67/30.40 53.92/52.84/53.38 44.00/31.88/36.97
HR 27.69/32.73/30.00 53.24/71.89/61.18 44.00/37.93/40.74
M 47.69/20.00/28.18 43.00/25.25/31.82 46.00/26.74/33.82
ME 60.00/66.10/62.90 58.36/70.08/63.69 54.00/69.23/60.67
MC 40.00/74.29/52.00 58.36/76.34/66.15 52.00/61.90/56.52
MCE 58.46/73.08/64.96 61.77/83.03/70.84 58.00/70.73/63.74
Table 4: Results for Negation for our two heuristics and the four combinations of machine learning features.
Speculation (R/P/F) EPI GE ID
H 13.46/6.48/8.75 33.77/18.12/23.58 54.17/6.50/11.61
HR 11.54/5.66/7.59 32.79/29.45/31.03 54.17/7.98/13.90
M 1.92/0.62/0.93 25.65/10.84/15.24 45.83/10.58/17.19
ME 3.85/12.50/5.88 22.08/42.24/29.00 29.17/28.00/28.57
MC 51.92/52.94/52.43 27.27/50.30/35.37 37.50/31.03/33.96
MCE 48.08/51.02/49.50 31.82/53.85/40.00 33.33/42.11/37.21
Table 5: Results for Speculation for our two heuristics and the four combinations of ML features.
by the FAUST system, which achieved the high-
est performance at two of the three tasks consid-
ered (Riedel et al, 2011). The UTurku system is
a pipeline ML-based EE system, while the UCon-
cordia system is strictly rule-based. FAUST is an
ML-based model combination system incorporating
information from the parser-based Stanford system
(McClosky et al, 2011) and the jointly-modelled
UMass system (Riedel and McCallum, 2011).
We also performed preliminary experiments for
the other released submissions to the BioNLP 2011
Shared Task, but due to space limitations focus only
on the three above-mentioned systems.
5.3 Evaluation criteria
We use the primary evaluation criteria of the
BioNLP 2011 Shared Task (Kim et al, 2011a) to
assure comparability, reporting all results using the
standard precision, recall and their harmonic mean
(F-score).
5.4 Methods
We apply the rule-based simple heuristic method
and its root extension (Section 4.2) as well as Sup-
port Vector Machines (SVM) trained with the fea-
tures introduced in Section 4.3. For the SVM, we
separately evaluate models based on all permuta-
tions of the feature sets introduced in Table 3. In the
results tables we abbreviate the feature set names as
done in Table 3 and use H for the heuristic method
and R for its root extension. As our machine learn-
ing component we use LIBLINEAR (Fan et al,
2008) with a L2-regularised L2-loss SVM model.
We optimise the SVM regularisation parameter C
using 10-fold cross-validation on the training data.
We use the training, development and test set par-
tition provided by the shared task organisers. In line
with standard ML methodology the test set was held
out during development and was only used when
carrying out the final experiments prior to submit-
ting the manuscript.
6 Results and Discussion
Our initial experiments, building on gold event data
(Tables 4 and 5), support our manual analysis, show-
ing nearly uniform performance improvement with
additional features. First, we find that the root-
heuristic gives an improvement over the original
heuristic in four out of six cases. To justify our us-
age of the cue-and-scope based heuristic feature (E)
we find that adding it as a feature improves on the M
feature set and the MC feature set, showing that even
given context, the cue-and-scope perspective is still
useful. The only anomaly is for speculation on the
EPI dataset, where adding this heuristic feature ac-
tually hampers performance, possibly relating to the
52
Negation (R/P/F) EPI GE ID
UConcordia 16.92/61.11/26.51 18.43/43.44/25.88 22.00/23.91/22.92
UConcordia* 20.00/70.59/31.17 20.14/42.96/27.42 28.00/31.58/29.68
UTurku 12.31/38.10/18.60 22.87/48.85/31.15 26.00/44.83/32.91
UTurku* 43.08/48.28/45.53 21.16/38.56/27.33 26.00/41.94/32.10
FAUST* 29.23/59.38/39.18 21.50/41.18/28.25 28.00/46.67/35.00
Table 6: Results of the Negation enrichment experiment.
Speculation (R/P/F) EPI GE ID
UConcordia 5.77/8.33/6.82 21.10/38.46/27.25 8.33/2.00/3.23
UConcordia* 1.92/4.55/2.70 12.99/29.20/17.98 8.33/2.22/3.51
UTurku 30.77/48.48/37.65 17.86/32.54/23.06 12.50/18.75/15.00
UTurku* 46.15/47.06/46.60 11.04/26.56/15.60 8.33/3.33/4.76
FAUST* 36.54/48.72/41.76 10.39/26.50/14.93 12.50/12.50/12.50
Table 7: Results of the Speculation enrichment experiment.
(R/P/F) EPI ID
UConcordia 20.83/42.14/27.88 49.00/40.27/44.21
UConcordia* 20.83/42.94/28.05 49.20/41.78/45.19
UTurku 52.69/53.98/53.33 37.85/48.62/42.57
UTurku* 54.72/53.86/54.29 37.79/47.76/42.19
FAUST 28.88/44.51/35.03 48.03/65.97/55.59
FAUST* 31.64/45.17/37.21 49.20/64.66/55.88
Table 8: Overall scores for the EPI and ID data sets.
sparseness of useful annotations due to the differing
annotation guidelines, as noted in manual analysis.
The numbers from these initial experiments serve as
an upper bound when we proceed to our enrichment
experiments, as they do not suffer from the possibil-
ity of producing false positives negation/speculation
annotations for false positive event structures.
In addition to the above in preliminary experi-
ments we also considered two features inspired by
findings made by Vincze et al (2011). A distance-
based feature, measuring the distance in tokens be-
tween the cue-word and the event trigger, and also
trigger suffixes to capture some cases of morpholog-
ical speculation (?induced? vs. ?inducible?). How-
ever, we failed to establish any consistent benefits
from these features and only for the EPI dataset did
the suffix features improve performance.
For the enrichment evaluation, adding nega-
F EPI GE ID
UConcordia 57.43 60.68 67.28
UTurku 81.31 66.27 55.84
FAUST 74.91 66.14 67.13
Table 9: Estimated F-score upper-bound for an ora-
cle system precision assigning negation/speculation
annotations to events predicted by an up-stream EE
system.
tion/speculation flags to the output of event extrac-
tion systems (Tables 6 and 7), our results are some-
what more modest. For negation we see an improve-
ment in four out of six cases, and for speculation in
two out of six. Despite the fact that a major limi-
tation to our approach are the false positive events
that are propagated from the original EE system, we
manage to improve the global score for all data sets
where a global score is provided by the organisers
(Table 8). We improve a full point in F-score for
UTurku on EPI, but only sub-percentage for Faust
on ID, the latter most likely since ID contains fewer
negation and speculation annotations and the global
scores are microaverages over all annotations.
As a final analysis we estimate the upper-bound
in F-score performance for all three EE systems
(Table 9). We do so by assuming that the recall
for events marked by negation and speculation is
53
equal to that of the overall recall of the up-stream
EE system and that negation/speculation annotations
assigned by an oracle. What we can see is that
there is still room for improvement, both for our
enrichment approach and for the EE system?s inter-
nal negation/speculation components, although re-
call of the EE output is a limiting factor we can
expect further efforts towards improving the extra-
propositional aspects of the system to yield perfor-
mance improvements.
7 Conclusions and Future Work
In this study, we have considered two broad lines
of research on extra-propositional aspects of key
statements in text, one using the task-independent,
linguistically-motivated cue-and-scope representa-
tion applied in the recent CoNLL-2010 Shared Task,
and the other using the task-oriented flagged-event
representation applied e.g. in the ACE and BioNLP
Shared Task evaluations. We presented a detailed
manual analysis exploring points of disagreement
and evaluated in detail rule-based and machine
learning-based methods joining state-of-the-art sys-
tems representing the two approaches.
Our manual analysis identified a number of phe-
nomena that limit the applicability of existing cue-
and-scope based systems to the event extraction
task, such as negation expressed through morpho-
logical change of words expressing events (e.g. un-
phosphorylated). To address these issues, we pro-
posed a combination of heuristics and simple lexical
features, carefully selected to address differences in
perspective between the cue-and-scope and event-
based frameworks and aiming to complement cue-
and-scope analyses for creating task-oriented out-
puts.
To test our approach, we created a method suit-
able for use as a component of an event extraction
pipeline that incorporates information from a previ-
ously proposed state-of-the-art cue-and-scope based
negation/speculation detection system and a mini-
mal set of features in an SVM-based system that was
shown to enhance and in several cases improve upon
the output of existing EE systems. Experiments on
the BioNLP Shared Task 2011 EPI and ID datasets
demonstrated that the combined approach could im-
prove the results of the best-performing systems at
the original task in 5 out of 6 cases, outperforming
the highest results reported for any system for these
two tasks.
There exist several potential targets for future
work on improving our introduced system and
to join cue-and-scope and event-based approaches.
Since none of the existing EE corpora was con-
structed with the aim to solely cover negation and
speculation annotations and taking into account our
finding that merging datasets to compensate for data
sparseness is beneficial, it might be worth consid-
ering other possible corpora or resources and how
they can be used for training our machine learning
system.
Also, it would be worthwhile to attempt to com-
bine an existing EE system capable of detect-
ing negation/speculation with our proposed method.
Combining the two could yield an ensemble, im-
proving upon an already strong system by bridging
the differences in perspectives and tapping into the
potential benefits of both approaches.
The system and all resources introduced in this
work are publicly available for research purposes at:
https://github.com/ninjin/eepura
Acknowledgements
The authors would like to thank the anonymous re-
viewers for their many insightful comments and sug-
gestions for improvements.
This work was funded in part by UK Biotechnol-
ogy and Biological Sciences Research Council (BB-
SRC) under project Automated Biological Event Ex-
traction from the Literature for Drug Discovery (ref-
erence number: BB/G013160/1), by the Ministry of
Education, Culture, Sports, Science and Technology
of Japan under the Integrated Database Project and
by the Swedish Royal Academy of Sciences.
References
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing Biomedical Event Extraction. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, pages 183?191.
Wendy W. Chapman, Will Bridewell, Paul Hanbury, Gre-
gory F. Cooper, and Bruce G. Buchanan. 2001. A
simple algorithm for identifying negated findings and
diseases in discharge summaries. Journal of biomedi-
cal informatics, 34(5):301?310.
54
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A Li-
brary for Large Linear Classification. Journal of Ma-
chine Learning Research, 9:1871?1874.
Richa?rd Farkas, Veronika Vincze, Gyo?rgy Mo?ra, Ja?nos
Csirik, and Gyo?rgy Szarvas. 2010. The CoNLL-2010
Shared Task: Learning to Detect Hedges and their
Scope in Natural Language Text. In Proceedings of
the Fourteenth Conference on Computational Natural
Language Learning, pages 1?12.
Carol Friedman, Philip O. Alderson, John H.M. Austin,
James J. Cimino, and Stephen B. Johnson. 1994. A
general natural-language text processor for clinical ra-
diology. Journal of the American Medical Informatics
Association, 1(2):161?174.
William R. Hersh. 1996. Information retrieval: a health
care perspective. Springer.
Yuang Huang and Henry J. Lowe. 2007. A novel hybrid
approach to automated negation detection in clinical
radiology reports. Journal of the American Medical
Informatics Association, 14(3):304?311.
Halil Kilicoglu and Sabine Bergler. 2010. A High-
Precision Approach to Detecting Hedges and their
Scopes. In Proceedings of the Fourteenth Conference
on Computational Natural Language Learning, pages
70?77.
Halil Kilicoglu and Sabine Bergler. 2011. Adapting a
General Semantic Interpretation Approach to Biolog-
ical Event Extraction. In Proceedings of the BioNLP
2011 Workshop Companion Volume for Shared Task,
pages 173?182.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 Shared Task on Event Extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011a.
Overview of BioNLP Shared Task 2011. In Proceed-
ings of the BioNLP 2011 Workshop Companion Vol-
ume for Shared Task, pages 1?6.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011b. Overview of Genia Event
Task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, pages 7?15.
LDC. 2005. ACE (Automatic Content Extraction) En-
glish Annotation Guidelines for Events. Technical re-
port, Linguistic Data Consortium.
David McClosky, Mihai Surdeanu, and Christopher Man-
ning. 2011. Event Extraction as Dependency Parsing
for BioNLP 2011. In Proceedings of BioNLP 2011,
pages 41?45.
Roser Morante and Walter Daelemans. 2009. Learn-
ing the scope of hedge cues in biomedical texts. In
Proceedings of the Workshop on Current Trends in
Biomedical Natural Language Processing, pages 28?
36.
Roser Morante, Vincent Van Asch, and Walter Daele-
mans. 2010. Memory-based resolution of in-sentence
scopes of hedge cues. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning ? Shared Task, CoNLL 2010: Shared
Task, pages 40?47.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, pages 16?25.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2011.
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, pages 26?35.
Sampo Pyysalo, Pontus Stenetorp, Tomoka Ohta, Jin-
Dong Kim, and Sophia Ananiadou. 2012. New Re-
sources and Perspectives for Biomedical Event Extrac-
tion. In Proceedings of BioNLP 2012 Workshop. to
appear.
Sebastian Riedel and Andrew McCallum. 2011. Robust
Biomedical Event Extraction with Dual Decomposi-
tion and Minimal Domain Adaptation. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, pages 46?50.
Sebastian Riedel, David McClosky, Mihai Surdeanu, An-
drew McCallum, and Christopher D. Manning. 2011.
Model Combination for Event Extraction in BioNLP
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, pages 51?55.
Roser Saur and James Pustejovsky. 2009. Fact-
Bank: a corpus annotated with event factuality.
Language Resources and Evaluation, 43:227?268.
10.1007/s10579-009-9089-9.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, pages 112?120.
Paul Thompson, Raheel Nawaz, John McNaught, and
Sophia Ananiadou. 2011. Enriching a biomedical
event corpus with meta-knowledge annotation. BMC
Bioinformatics, 12(1):393.
Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gy-
orgy Mora, and Janos Csirik. 2008. The Bio-
55
Scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9(Suppl 11):S9.
Veronika Vincze, Gyorgy Szarvas, Gyorgy Mora,
Tomoko Ohta, and Richard Farkas. 2011. Linguis-
tic scope-based and biological event-based specula-
tion and negation annotations in the BioScope and Ge-
nia Event corpora. Journal of Biomedical Semantics,
2(Suppl 5):S8.
56
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 27?36,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Open-domain Anatomical Entity Mention Detection
Tomoko Ohta 1 Sampo Pyysalo 1 Jun?ichi Tsujii 2 Sophia Ananiadou 1
1National Centre for Text Mining and University of Manchester,
Manchester Interdisciplinary Biocentre, 131 Princess Street, Manchester, UK
2Microsoft Research Asia, Beijing, China
okap.tiffany@gmail.com, sampo.pyysalo@gmail.com
jtsujii@microsoft.com, sophia.ananiadou@manchester.ac.uk
Abstract
Anatomical entities such as kidney, muscle
and blood are central to much of biomedical
scientific discourse, and the detection of men-
tions of anatomical entities is thus necessary
for the automatic analysis of the structure of
domain texts. Although a number of resources
and methods addressing aspects of the task
have been introduced, there have so far been
no annotated corpora for training and evaluat-
ing systems for broad-coverage, open-domain
anatomical entity mention detection. We in-
troduce the AnEM corpus, a domain- and
species-independent resource manually anno-
tated for anatomical entity mentions using a
fine-grained classification system. The cor-
pus texts are selected randomly from citation
abstracts and full-text papers with the aim of
making the corpus representative of the en-
tire available biomedical scientific literature.
We demonstrate the use of the corpus through
an evaluation of the broad-coverage MetaMap
tagger and a CRF-based system trained on the
corpus data, considering also a combination
of these two methods. The combined sys-
tem demonstrates a promising level of per-
formance, approaching 80% F-score for men-
tion detection for a relaxed matching criterion.
The corpus and other introduced resources are
available under open licences from http://
www.nactem.ac.uk/anatomy/.
1 Introduction
Entity mention detection is a prerequisite for most
efforts to systematically analyse and represent the
structure of scientific discourse. In the life sciences,
a comprehensive analysis must include entities at
multiple levels of biological organization, from the
molecular to the organism level. The detection of
references to anatomical entities such as ?kidney?
and ?blood? is thus required for the automatic struc-
tured analysis of biomedical scientific text.
Although a wealth of lexical and ontological re-
sources covering anatomical entities are available
(Rosse and Mejino, 2003; Smith et al, 2007; Boden-
reider, 2004; Haendel et al, 2009), such resources
do not alone confer the ability to reliably detect
mentions of anatomical entities in natural language
(Gerner et al, 2010a; Travillian et al, 2011; Pyysalo
et al, 2012b). To support the development and eval-
uation of reliable anatomical entity mention detec-
tion methods, corpus resources annotated specifi-
cally for the task are necessary.
In this study, we aim to create a reference standard
for evaluating methods for anatomical entity men-
tion detection and for training machine learning-
based methods for the task. We seek to select
a set of texts that are representative of the rele-
vant scientific literature, i.e. open-domain in the
sense of avoiding bias toward, for example, specific
species, levels of biological organization (e.g. sub-
cellular or gross anatomy), parts of documents (e.g.
abstracts), or subdomains of life science. In sup-
port of our annotation, we draw on a granularity-
based, species-independent upper-level ontology of
anatomy as well as relevant species-specific onto-
logical resources.
The overall aim of our efforts is to create methods
and resources for comprehensive event-based anal-
ysis (Ananiadou et al, 2010) of biomedical scien-
tific discourse involving anatomy-level entities and
processes. In aiming to establish a stable basis
for anatomical entity mention detection, the present
study is an important step toward this goal.
27
Label Ontology classes Examples
A
na
to
m
ic
al
en
ti
ty
A
na
to
m
ic
al
st
ru
ct
ur
e ORGANISM SUBDIVISION organism subdivision CARO head, limb
ANATOMICAL SYSTEM anatomical system CARO vascular system
ORGAN compound organ CARO liver, heart
MULTI-TISSUE STRUCTURE multi-tissue structure CARO artery
TISSUE portion of tissue CARO epithelium
CELL cell CARO epithelial cell
DEVELOPING ANATOMICAL STRUCTURE developing anatomical structure UBERON embryo
CELLULAR COMPONENT cellular component GO mitochondrion
ORGANISM SUBSTANCE portion of organism substance CARO blood
IMMATERIAL ANATOMICAL ENTITY immaterial anatomical entity CARO lumen
PATHOLOGICAL FORMATION - carcinoma
Table 1: Annotations targets with applied label, corresponding ontology classes, and common examples.
2 Corpus Annotation
2.1 Ontological Basis
Following our previous efforts on anatomical en-
tity classification (Pyysalo et al, 2012b), we base
our definition of annotated mention scope, the sub-
division of anatomical entities into classes, and
the class labels applied in our annotation primar-
ily on the Common Anatomy Reference Ontology
(CARO) (Haendel et al, 2008). CARO is a small,
species-independent ontology of anatomical entities
based on the upper-level structure of the Founda-
tional Model of Anatomy (FMA) ontology of hu-
man anatomy (Rosse and Mejino, 2003; Rosse and
Mejino, 2008). CARO has been proposed as a stan-
dard for unifying the upper-level structure of the
various existing species-specific ontologies and is
adopted by many of the over 40 ontologies involv-
ing the anatomy domain in the Open Biomedical
Ontologies (OBO) foundry1 (Smith et al, 2007).
CARO adheres to disjoint classes and single inher-
itance, and divides anatomical structures primarily
by granularity (Kumar et al, 2004), a systematic no-
tion familiar to those working in the life sciences.
Although we draw primarily on CARO, we fol-
low the well-established cellular component subon-
tology of the Gene Ontology (GO) (Ashburner et
al., 2000) in grouping sub-cellular structures under
a single upper-level category. For developing struc-
tures that resist granularity-based categorization due
to occupying different levels at different stages of
development, we adopt a separate DEVELOPING
ANATOMICAL STRUCTURE category, as done also
in e.g. Uberon (Haendel et al, 2009).
1http://obofoundry.org/
2.2 Annotation Scope
We diverge from the scope of anatomy ontologies in
two important aspects in our annotation.
First, ontologies of anatomy commonly incorpo-
rate everything from molecules to whole organisms
within their scope. However, in entity mention de-
tection, many molecular level anatomical entities
fall within the scope of the established gene/protein
mention detection tasks (e.g. (Kim et al, 2004; Tan-
abe et al, 2005)), and whole organism mentions
similarly largely within what is covered by existing
methods and resources for organism mention detec-
tion (Gerner et al, 2010b; Naderi et al, 2011). To
avoid overlap with established tasks and to focus on
the novel aspects of anatomical entity mention de-
tection, we exclude biological macromolecules and
mentions of organism names from the scope of our
annotation, as argued in (Pyysalo et al, 2012b).
Second, these ontologies typically represent
canonical anatomy, an idealized state that is rarely
(if ever) encountered in reality (Bada and Hunter,
2011). As our annotation is intended to cover ref-
erences to real-world anatomy, we explicitly include
in the scope of our annotation also healthy as well as
pathological variants of canonical anatomy. We in-
clude also entities derived from these anatomical en-
tities through (planned) processing such as surgical
or laboratory procedures, even when these processed
entities are no longer properly part of the original
organism. Finally, we annotate pathological forma-
tions such as scars and carcinomas that are part of
individual organisms but have no correspondence in
canonical anatomy (Smith et al, 2005).
Table 1 presents the class labels applied in the an-
notation with the corresponding ontology classes.
28
In contrast, the 3 cases of metastatic cancer of the GB had no blood flow signal in the wall of the GB
Pathological form Organ OSubst MTS OrganPart-ofPart-of
Figure 1: Example sentence with annotation. OSUBST and MTS abbreviate for ORGANISM SUBSTANCE and MULTI-
TISSUE STRUCTURE, respectively.
2.3 Representation
The primary corpus annotation marks mentions of
anatomical entities as contiguous spans of characters
in text, each of which is assigned a type (Figure 1).
As the CARO-based categorization has comprehen-
sive coverage and disjoint classes, each annotation
can be assigned exactly one type (class label).
In addition to identifying and typing anatomical
entity mentions, we further apply binary attributes
(?flags?) marking the following characteristics of
each mention:
DEVELOPING developing variant of anatomical
entity, e.g. fetal liver
PATHOLOGICAL pathological variant of anatomi-
cal entity, e.g. carcinoma cell
PLANT anatomical entity that is part of a plant
(member of the Viridiplantae kingdom), e.g.
roots, leaf
PROCESSED variant of anatomical entity that has
undergone planned processing, e.g. tissue spec-
imen
Any combination of attributes can apply to a single
mention. These attributes allow the identification of
subsets of annotations that may be out of scope for
some efforts (e.g. pathological or processed entities)
and facilitate the analysis of mention detection sys-
tem performance by identifying particular problem-
atic categories.
2.4 Annotation Criteria
In very brief summary, we annotate spans of text that
refer to anatomical entities as defined above. Men-
tions that involve only metaphorical senses of such
entities (?on the other hand?) or artificial analogues
(?artificial heart?) are not annotated.
The primary targets of our annotation are anatom-
ical entity names (e.g. ?lymphocyte?) and nominal
mentions of anatomical entities (e.g. ?muscle tis-
sue?). Both names and nominal mentions are anno-
tated similarly, without distinction. We exclude pro-
nouns (it, that) from annotation even when they un-
cytoplasm of phagocytic microglia
Organism substance CellPart-of
thyroid and eye muscle membranes
Tissue TissueFrag
Figure 2: Part-of relation marking entity mention span-
ning a prepositional phrase (above) and Frag relation
marking coordination with ellipsis (below).
ambiguously refer to an anatomical entity; we con-
sider the identification and resolution of such men-
tions part of the distinct coreference resolution task
(see e.g. Pradhan et al (2011)).
In addition to names and nominal mentions, we
mark adjectives that have an unambiguous sense
of relating to a specific anatomical entity. Thus,
for example, both ?kidney? and ?renal? (relating to
the kidneys) are annotated as ORGAN in expres-
sions such as ?kidney failure? and ?renal failure?.
The choice to annotate adjectival references is mo-
tivated by the expected needs of applications mak-
ing use of automatically detected anatomical entity
mentions. For example, for semantic search target-
ing documents relating to organ failure, a document
discussing ?renal failure? is obviously relevant and
should be recovered.
Syntactically, annotations mainly cover base
noun phrases without determiners, i.e. nouns with
premodifiers relevant to identifying the specific
anatomical entity referred to. We exclude noun
phrase postmodifiers such as prepositional phrases
from the span of single annotations, but apply a
separate level of annotation for part-of relations
that allow such alternate spans to be recovered
when they identify an anatomical entity (Figure 2
top). Similarly, we decompose coordinated ref-
erences to anatomical entities involving ellipsis to
non-overlapping spans, but mark the cases using a
frag(ment) relation type (Figure 2 bottom). (Due to
space considerations, we omit detailed discussion of
these relation annotations.) Together with the prop-
erties described in Section 2.3, these constraints as-
sure that any single token is assigned at most one
class label and allow the annotation to be repre-
29
Matching criterion
Task Strict Left boundary Right boundary
Mention detection (single class) 89.2%/ 82.0%/ 85.4% 93.0%/ 85.5%/ 89.1% 94.6%/ 86.9%/ 90.6%
Detection and classification (multi-class) 85.6%/ 78.7%/ 82.0% 87.0%/ 80.0%/ 83.3% 90.2%/ 82.9%/ 86.4%
Table 2: Inter-annotator agreement results (precision / recall / F-score).
sented in the standard BIO format and to be straight-
forwardly applied with many existing entity mention
taggers.
By contrast to previously introduced domain re-
sources for e.g. molecular entity and organism men-
tion detection (Tanabe et al, 2005; Gerner et al,
2010b), we do not incorporate any specificity con-
straints in our annotation criteria. That is, non-
specific expressions such as ?tissue? and ?organ? are
marked identically to specific ones such as ?epithe-
lium? and ?heart?. This choice seeks to assure the
generality of the task and methods for addressing it.
2.5 Text Selection
Texts for the corpus were drawn from two sources:
the PubMed2 database of publication abstracts, and
the PubMed Central3 (PMC) Open Access subset
of full-text publications. PubMed, containing more
than 20 million citations, has a very broad coverage
of domain scientific texts but is limited to publica-
tion abstracts, while PMC has lower coverage but
does provide over 400,000 full-text documents un-
der open licenses. By sampling both sources, we
seek to assure the corpus is relevant to IE efforts re-
gardless of their choice of texts.
To avoid bias toward e.g. subdomains of biol-
ogy or specific species, we selected texts from both
sources by random sampling. For PubMed, we sim-
ply selected a random set of citations and extracted
their abstract and title texts. For PMC, we initially
extracted all non-overlapping section texts (PMC
XML <sec> elements) as well as caption texts
(<caption> elements), and then selected a ran-
dom set of extracts. This selection seeks to maxi-
mize the diversity of the texts in the full-text sec-
tion of the corpus, and the selection of extracts larger
than isolated sentences aims to allow the corpus to
be used to study methods making use of broader
context, e.g. by incorporating constraints such as
one sense per discourse (Gale et al, 1992).
2http://pubmed.com
3http://www.ncbi.nlm.nih.gov/pmc/
We selected a total of 500 documents using this
protocol, half from PubMed and half from PMC
document extracts. (Descriptive statistics of the ab-
stracts and full-text extracts subcorpora are given
later in Table 3.)
2.6 Annotation Process
Primary annotation was created by a PhD biologist
with extensive experience in domain information ex-
traction and text annotation (TO). The use of any rel-
evant resources, such as the full article being anno-
tated or species-specific anatomy ontologies in the
OBO foundry, was encouraged for resolving unclear
or ambiguous cases during annotation. Initial anno-
tation was produced entirely manually. To further
assure the quality of the annotation, a series of au-
tomatic tests was performed and used as the basis
of a further manual round of revision.4 Annotation
guidelines were initially created based on those cre-
ated by our previous domain-specific effort (Pyysalo
et al, 2012a) and revised throughout the annotation
effort to document specific decisions made during
annotation. The annotations were created using the
BRAT annotation tool (Stenetorp et al, 2012).
To evaluate the annotation consistency, we per-
formed an inter-annotator agreement (IAA) exper-
iment. After brief training with annotation guide-
lines provided by the primary annotator, a random
10% of the corpus was independently annotated by
a PhD computer scientist with experience in domain
text annotation and anatomy ontologies (SP). IAA
was evaluated using the same criteria as applied in
experiments (see Section 3.4), holding the primary
annotation as gold. The results are shown in Table 2.
We find very good agreement both for mention de-
tection (ignoring classification) as well as for the full
task, indicating that the task is well defined and the
annotation consistency high.
4No automatically suggested annotations were incorporated
into the corpus without manual verification.
30
3 Methods
We next present the methods applied in our anatomi-
cal entity mention detection experiments. We aim to
evaluate the capacity of the newly annotated corpus
to support reliable mention detection and to estab-
lish initial baseline results for the newly introduced
resource, and thus focus only on relatively straight-
forward applications of existing methods.
3.1 MetaMap
MetaMap5 (Aronson, 2001) is a tool capable of
detecting mentions of concepts from the exten-
sive UMLS Metathesaurus (Bodenreider, 2004)
in text. The metathesaurus and MetaMap have
broad coverage of concepts relevant to biology
and medicine and provide a categorization of
concepts into 133 semantic types, ranging from
Amino Acid to Health Care Activity to
Vertebrate, many directly relevant to anatomi-
cal entities. MetaMap is a key component of the
process used by the National Library of Medicine
(NLM) to index publications in the PubMed
database and has been applied in numerous other in-
formation extraction and information retrieval tasks
(Aronson and Lang, 2010).
In initial experiments, we applied MetaMap to
training set documents to identify the subset of the
133 semantic classes relevant to anatomy, select-
ing 14 classes (including e.g. Cell, Tissue and
Body Substance) for final experiments.6 Dur-
ing testing, we used command-line arguments to re-
strict output to the selected semantic classes. The
core tagging functionality of MetaMap is rule-based,
and it does not support training on tagged data
for concept mention detection. With the exception
of the semantic class selection, the evaluation of
MetaMap reflects an ?off-the-shelf? application of
the general-purpose tool.
3.2 CRF tagging
Conditional Random Fields (CRF) (Lafferty et al,
2001) are graphical models that are frequently ap-
5http://metamap.nlm.nih.gov/
6In brief, we tagged the training data with MetaMap, ex-
tracted the subset of semantic classes giving more than 5%
precision against the gold annotations, and manually analysed
these to select this subset. The selected classes are detailed in
supplementary material available on the project webpage.
plied to sequence labeling tasks, and CRFs form
the basis of state-of-the-art methods for many en-
tity mention tagging tasks. We performed experi-
ments using the NERsuite entity mention recogni-
tion toolkit, based on the CRFsuite implementation
of CRFs (Okazaki, 2007). NERsuite provides an
extensive set of features applied in entity mention
detection, allowing the tool to achieve performance
competitive with state-of-the-art methods for many
biomedical domain tasks through retraining with-
out task-specific adaptation7. Retraining the tool for
new tasks is also straightforward, allowing applica-
tion to new tasks with modest effort.
We set the L2 regularization parameter of the
learning method using held-out evaluation with
training set data, picking out of a set of values 2n
(n ? Z) the one giving best performance.8 Other
learning method parameters were left at default val-
ues.
3.3 System combination
As a third system, we apply a straightforward com-
bination of the MetaMap and CRF tagging systems,
where we initially tag the data using MetaMap and
then incorporate the classes assigned by MetaMap
as features for training and testing with NERsuite
(stacking). More specifically, we create a BIO-
tagged version of MetaMap output segmented to
match NERsuite tokenization, and assign each token
the BIO tag based on the MetaMap semantic type
code (e.g. B-cell) as a feature.
Excepting for the addition of these MetaMap-
derived features, NERsuite is applied as described
above (Section 3.2).
3.4 Experimental setting
We split the corpus data into two primary parts: a
training set consisting of 60% of the documents and
a test set of the remaining 40%. The data splits
were performed independently for the two subcor-
pora (abstracts and full-text extracts), using strati-
fied sampling to assure broadly comparable statisti-
cal properties between the sets. The test set was held
out during development and only applied for the fi-
nal experiments.
7http://nersuite.nlplab.org/
8Specifically, C2 = 2?5 was selected.
31
Dataset
Source Item Train Test Total
Abst.
Document 150 100 250
Word 28,960 18,199 47,159
Entity 1,182 764 1,946
FTE
Document 150 100 250
Word 26,306 17,955 44,261
Entity 697 492 1,189
Total
Document 300 200 500
Word 55,266 36,154 91,420
Entity 1,879 1,256 3,135
Table 3: Overall corpus statistics. Statistics given sepa-
rately for the abstracts (abst.) and full-text extracts (FTE)
subcorpora as well as for the total.
We perform experiments in two settings: a single-
class setting where the task is restricted to the detec-
tion of anatomical entity mentions without classifi-
cation, and a multi-class setting where the correct
class label must further be assigned to each detected
mention. As MetaMap uses UMLS semantic classes
that do not fully align with the applied CARO-based
classes, MetaMap is only applied in the single-class
setting.
For evaluation, we adopted the protocol, crite-
ria and metrics of the established BioNLP/JNLPBA
shared task 2004 (Kim et al, 2004). To assure com-
patibility, we created our evaluation tool on the ba-
sis of the shared task evaluation script. The eval-
uation is thus based on entity-wise (microaverage)
precision/recall/F-score metrics, and tagging perfor-
mance is separately evaluated under strict match, left
boundary match and right boundary match criteria.
In the former setting, a predicted entity must exactly
match the extent of a gold standard entity, while in
the latter two settings, it is enough that the left/right
boundary matches.
3.5 Format
The annotation is distributed in the standard column-
based BIO format applied for e.g. CoNLL 2003
(Tjong Kim Sang and De Meulder, 2003) and
JNLPBA (Kim et al, 2004) data, among other es-
tablished datasets.
4 Results
4.1 Corpus statistics
Table 3 presents the overall corpus statistics. We
note that the abstracts and full-text extracts (FTE)
Type Count
CELL 776
MULTI-TISSUE STRUCTURE 639
ORGAN 381
PATHOLOGICAL FORMATION 368
ORGANISM SUBSTANCE 291
CELLULAR COMPONENT 199
TISSUE 169
ORGANISM SUBDIVISION 162
IMMATERIAL ANATOMICAL ENTITY 60
ANATOMICAL SYSTEM 51
DEVELOPING ANATOMICAL STRUCTURE 39
Table 4: Annotation statistics by type.
subcorpora are of comparable size in terms of their
word counts, but the number of annotations is 1.6
times higher in the abstracts subcorpus (1.5 cor-
recting for number of words). This difference in
anatomical entity mention density between abstracts
and full texts parallels the findings of Cohen et al
(2010) on the relative density of gene, drug and dis-
ease mentions. We further note that the estimated
density of anatomical entity mentions in abstracts
(approx. 41 per 1000 words) and full texts (27 per
1000) are broadly comparable to the gene mention
density estimates of Cohen et al (61 and 47 for ab-
stracts and full texts, respectively).
Table 4 presents a breakdown by annotation type.
There are large differences in the number of anno-
tations by type, with the majority class CELL out-
numbering the rarest type 20-fold. While the total
number of annotated examples is likely to be suf-
ficient for training machine learning-based taggers
and most of the classes contain a respectable num-
ber of examples, the statistics suggest that the least
frequently annotated types may represent challenges
for learning.
4.2 Entity Mention Detection
Table 5 presents the experimental results for anatom-
ical entity mention detection (single-class). In terms
of F-score, we find the same ranking of the three
methods for all three criteria, with the CRF-based
tagger outperforming the rule-based MetaMap, and
the combination method outperforming its compo-
nents. Although it is not surprising that a dedicated
machine learning-based system is capable of outper-
forming a general-purpose, largely rule-based sys-
tem, this result does reflect positively on both the
32
Matching criterion
Method Strict Left boundary Right boundary
MetaMap 50.78% / 64.49% / 56.82% 54.67% / 69.43% / 61.17% 58.18% / 73.89% / 65.10%
NERsuite 77.98% / 52.15% / 62.50% 81.43% / 54.46% / 65.27% 90.00% / 60.19% / 72.14%
MetaMap + NERsuite 82.09% / 62.42% / 70.92% 84.61% / 64.33% / 73.09% 90.68% / 68.95% / 78.34%
Table 5: Overall single-class anatomical entity mention detection results (precision / recall / F-score).
Matching criterion
Method Strict Left boundary Right boundary
NERsuite 72.07% / 42.12% / 53.17% 72.75% / 42.52% / 53.67% 85.69% / 50.08% / 63.22%
MetaMap + NERsuite 75.41% / 51.75% / 61.38% 76.45% / 52.47% / 62.23% 83.99% / 57.64% / 68.37%
Table 6: Overall anatomical entity mention detection and classification results (precision / recall / F-score).
consistency of the annotation as well as the suffi-
ciency of the size of the newly introduced corpus.
In this application, we find that MetaMap tends to
favor recall over precision ? perhaps reflecting its
focus on IR applications (Aronson and Lang, 2010)
? while the trained machine learning-based models
are clearly biased in favor of high precision.
As expected on the basis of the results of previous
evaluations using similar experimental setups (Kim
et al, 2004), results are notably better under the re-
laxed matching criteria. In particular, requiring only
the right boundaries of annotations to match yields
F-scores nearly 10% points higher than under strict
matching. Recalling that the annotations primar-
ily mark base noun phrases, this suggests that the
systems comparatively frequently identify the head
word of an anatomical entity mention correctly but
differ from gold annotation regarding the choice of
premodifiers included in the span of the annotation.
As limited variation in premodifier selection is ar-
guably acceptable for many applications and relaxed
matching criteria are frequently applied in domain
tagging tasks (Kim et al, 2004; Wilbur et al, 2007),
we propose to consider performance under the re-
laxed right boundary match criterion as the primary
result for evaluation using the new corpus.
Table 6 presents the results for anatomical entity
mention detection and classification using the 11-
class categorization used in annotation.9 While per-
formance in terms of F-score is approximately 10%
points lower than for the single-class task, this drop
is comparatively modest given the large number of
9Note that evaluation using MetaMap only is not possible as
its semantic classes differ from those used in the annotation.
distinct classes, indicating that the number of an-
notations of most individual classes is sufficient for
learning.
While these initial results are not as high as for
established entity mention detection tasks in the do-
main (Wilbur et al, 2007; Rebholz-Schuhmann et
al., 2011), we consider the level of performance
quite good given the many new challenges relat-
ing to the task. Further, as the mention detection
methods were also applied with only modest specific
adaptation to the task, we believe there remain many
opportunities for further development of methods
for the task.
4.3 Discussion
Many commonly targeted mention types in both
the ?general? and the biological domain are fre-
quently characterized by obvious surface features:
the names of people and locations are capitalized in
many languages, as are genera in scientific species?
names, and many gene and chemical names have
comparable features distinguishing them from com-
mon nouns (consider e.g. p53, IgE, c-myc, Ca2+,
H2SO4). By contrast, many typical anatomical en-
tity mentions are common noun compounds lacking
obvious distinguishing surface features. This fact
likely contributes to the comparatively low perfor-
mance of the CRF-based tagger when applied with-
out support from lexical resources.
A further challenge that arises comparatively fre-
quently in anatomical entity mention detection is
ambiguity between entity mentions and other words
sharing the same surface form. For example, while
Barack Obama, Sweden, p53 and H2SO4 can be
33
safely identified as mentions of a person, country,
gene, and chemical without reference to context,
face should not be marked as an anatomical entity
mention in face the facts, nor should Airways in
British Airways. Thus, approaches relying on simple
matching against lexical resources will not suffice
for accurate anatomical entity mention detection.
Our evaluation results demonstrated a clear ad-
vantage to combining detection based on lexical re-
sources with machine learning-based tagging, an ap-
proach we believe will be key to the further develop-
ment of reliable anatomical entity mention tagging
that we will seek to explore in detail in future work.
To facilitate analysis of the performance of the meth-
ods, we provide the predictions of each method in
supplementary data on the project homepage.
5 Related work
A number of domain corpora such as GENIA (Ohta
et al, 2002), BioInfer (Pyysalo et al, 2007), and the
recently introduced CellFinder corpus (Neves et al,
2012) include annotation for at least some classes
of anatomical entities. However, such corpora typ-
ically cover only specific subdomains of the litera-
ture, such as transcription factors in human blood
cells (GENIA), protein-protein interactions (BioIn-
fer), or stem cells (CellFinder). To the best of our
knowledge, this is the first effort introducing a cor-
pus annotated for anatomical entity mentions that
specifically aims to be representative of the entire
available literature. We note that there is a well-
established precedent to this goal: sentences for
the de facto standard corpus for gene/protein name
recognition, GENETAG (Tanabe et al, 2005), were
similarly selected from PubMed abstracts without
domain restrictions.
The BioNLP/JNLPBA shared task 2004 (Kim et
al., 2004) targeted the detection of mentions of five
types of biological entities, including two that would
fall within in the scope of our CELL annotation
(?Cell type? and ?Cell line?). Other than this com-
paratively early shared task, collaborative domain
efforts such as BioCreative (Krallinger et al, 2008)
and CALBC (Rebholz-Schuhmann et al, 2011) have
not targeted anatomical entity mentions.
Some recent studies have considered the use of
ontological resources for the detection of anatomi-
cal entity mentions in natural language expressions.
In previous work (Pyysalo et al, 2012b), we studied
the classification of isolated noun phrases extracted
from PubMed to identify anatomy terms. Travillian
et al (2011) considered two lexical matching appli-
cations to detect anatomical entities from two OBO
resources in user-provided terms. However, these
efforts have not involved the annotation or detection
of mentions in context, which we view as critical for
real-world entity mention detection method devel-
opment and evaluation.
6 Conclusions
We have introduced a manually annotated corpus for
open-domain anatomical entity mention detection,
consisting of 500 documents (over 90,000 words)
drawn from publication abstracts and full texts. The
primary corpus annotation consists of the identifi-
cation of over 3,000 references to both healthy and
pathological anatomical entities, marked using a de-
tailed 11-class categorization based on established
biomedical domain ontologies. We demonstrated
the use of the new corpus through a comparative
evaluation of MetaMap, a general semantic class
tagger; NERsuite, a CRF-based machine learning
system; and a stacked combination of the two, find-
ing that under a relaxed matching criterion, the com-
bination approaches 80% F-score at mention detec-
tion and 70% F-score at mention detection and clas-
sification. This level of performance is encourag-
ing for a first application and suggests that reliable
open-domain anatomical entity mention detection is
not an unrealistic target.
We hope that the introduced corpus can serve as a
reference standard for the further development and
evaluation of methods for anatomical entity men-
tion detection. This corpus, the introduced evalua-
tion tools, and other resources created in this study
are made available under open licences from http:
//www.nactem.ac.uk/anatomy/.
Acknowledgments
This work was funded by UK Biotechnology and Bi-
ological Sciences Research Council (BBSRC) under
project Automated Biological Event Extraction from
the Literature for Drug Discovery (reference num-
ber: BB/G013160/1).
34
References
S. Ananiadou, S. Pyysalo, J. Tsujii, and D.B. Kell. 2010.
Event extraction for systems biology by text mining
the literature. Trends in Biotechnology, 28(7):381?
390.
A.R. Aronson and F.M. Lang. 2010. An overview of
MetaMap: historical perspective and recent advances.
Journal of the American Medical Informatics Associa-
tion, 17(3):229?236.
A.R. Aronson. 2001. Effective mapping of biomedical
text to the UMLS Metathesaurus: the MetaMap pro-
gram. In Proceedings of AMIA, pages 17?21.
M Ashburner, CA Ball, JA Blake, D Botstein, H Butler,
JM Cherry, AP Davis, K Dolinski, SS Dwight, JT Ep-
pig, MA Harris, DP Hill, L Issel-Tarver, A Kasarskis,
S Lewis, JC Matese, JE Richardson, M Ringwald,
GM Rubin, and G Sherlock. 2000. Gene ontology:
tool for the unification of biology. Nature genetics,
25:25?29.
M. Bada and L. Hunter. 2011. Desiderata for ontologies
to be used in semantic annotation of biomedical docu-
ments. Journal of Biomedical Informatics, 44(1):94?
101.
O. Bodenreider. 2004. The unified medical language
system (UMLS): integrating biomedical terminology.
Nucleic acids research, 32(suppl 1):D267?D270.
K.B. Cohen, H. Johnson, K. Verspoor, C. Roeder, and
L. Hunter. 2010. The structural and content aspects of
abstracts versus bodies of full text journal articles are
different. BMC bioinformatics, 11(1):492.
W.A. Gale, K.W. Church, and D. Yarowsky. 1992. One
sense per discourse. In Proceedings of the workshop
on Speech and Natural Language, pages 233?237.
M. Gerner, G. Nenadic, and C.M. Bergman. 2010a. An
exploration of mining gene expression mentions and
their anatomical locations from biomedical text. In
BioNLP?10, pages 72?80.
M. Gerner, G. Nenadic, and C.M. Bergman. 2010b.
LINNAEUS: a species name identification system
for biomedical literature. BMC bioinformatics,
11(1):85+.
M.A. Haendel, F. Neuhaus, D. Osumi-Sutherland, P.M.
Mabee, J.L.V. Mejino, C.J. Mungall, and B. Smith.
2008. CARO?the common anatomy reference ontol-
ogy. Anatomy Ontologies for Bioinformatics, pages
327?349.
M.A. Haendel, G.G. Gkoutos, S.E. Lewis, and
C. Mungall. 2009. Uberon: towards a comprehensive
multi-species anatomy ontology. Nature precedings.
J-D. Kim, T. Ohta, Y. Tsuruoka, Y. Tateisi, and N. Collier.
2004. Introduction to the bio-entity recognition task at
JNLPBA. In Proceedings JNLPBA?04.
M. Krallinger, A. Morgan, L. Smith, F. Leitner, L. Tan-
abe, J. Wilbur, L. Hirschman, and A. Valencia.
2008. Evaluation of text-mining systems for biology:
overview of the Second BioCreative community chal-
lenge. Genome biology, 9(Suppl 2):S1.
A. Kumar, B. Smith, and D.D. Novotny. 2004. Biomed-
ical informatics and granularity. Comparative and
functional genomics, 5(6-7):501?508.
J.D. Lafferty, A. McCallum, and F.C.N. Pereira. 2001.
Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Proceed-
ings of ICML, pages 282?289.
N. Naderi, T. Kappler, C.J.O. Baker, and R. Witte.
2011. OrganismTagger: Detection, normalization, and
grounding of organism entities in biomedical docu-
ments. Bioinformatics.
M. Neves, A. Damaschun, A. Kurtz, and U. Leser. 2012.
Annotating and evaluating text for stem cell research.
In Third Workshop on Building and Evaluation Re-
sources for Biomedical Text Mining (BioTxtM 2012).
(to appear).
T Ohta, Y Tateisi, H Mima, and J Tsujii. 2002. GE-
NIA corpus: an annotated research abstract corpus in
molecular biology domain. Proceedings of the Human
Language Technology Conference (HLT 2002), pages
73?77.
N. Okazaki. 2007. CRFsuite: a fast imple-
mentation of conditional random fields (CRFs).
http://www.chokkan.org/software/crfsuite/.
S. Pradhan, L. Ramshaw, M. Marcus, M. Palmer,
R. Weischedel, and N. Xue. 2011. CoNLL-2011
shared task: Modeling unrestricted coreference in
ontonotes. In Proceedings of the Fifteenth Confer-
ence on Computational Natural Language Learning:
Shared Task, pages 1?27.
S. Pyysalo, F. Ginter, J. Heimonen, J. Bjo?rne, J. Boberg,
J. Ja?rvinen, and T. Salakoski. 2007. BioInfer: A cor-
pus for information extraction in the biomedical do-
main. BMC Bioinformatics, 8(50).
S. Pyysalo, T. Ohta, M. Miwa, H-C. Cho, J. Tsujii, and
S. Ananiadou. 2012a. Event extraction across mul-
tiple levels of biological organization. (manuscript in
review).
S. Pyysalo, T. Ohta, J. Tsujii, and S. Ananiadou. 2012b.
Learning to classify anatomical entities using open
biomedical ontologies. Journal of Biomedical Seman-
tics. (to appear).
D. Rebholz-Schuhmann, A. Yepes, C. Li, S. Kafkas,
I. Lewin, N. Kang, P. Corbett, D. Milward, E. Buyko,
E. Beisswanger, K. Hornbostel, A. Kouznetsov,
R. Witte, J. Laurila, C. Baker, C. Kuo, S. Clematide,
F. Rinaldi, R. Farkas, G. Mora, K. Hara, L.I. Fur-
long, M. Rautschka, M. Neves, A. Pascual-Montano,
35
Q. Wei, N. Collier, M. Chowdhury, A. Lavelli,
R. Berlanga, R. Morante, V. Van Asch, W. Daelemans,
J. Marina, E. van Mulligen, J. Kors, and U. Hahn.
2011. Assessment of NER solutions against the first
and second calbc silver standard corpus. Journal of
Biomedical Semantics, 2(Suppl 5):S11.
C. Rosse and J.L.V. Mejino. 2003. A reference on-
tology for biomedical informatics: the foundational
model of anatomy. Journal of Biomedical Informat-
ics, 36(6):478?500.
C. Rosse and J.L.V. Mejino. 2008. The foundational
model of anatomy ontology. Anatomy Ontologies for
Bioinformatics, pages 59?117.
B. Smith, A. Kumar, W. Ceusters, and C. Rosse. 2005.
On carcinomas and other pathological entities. Com-
parative and functional genomics, 6(7-8):379?387.
B. Smith, M. Ashburner, C. Rosse, J. Bard, W. Bug,
W. Ceusters, L. J Goldberg, K. Eilbeck, A. Ireland,
C.J. Mungall, N. Leontis, P. Rocca-Serra, A. Rut-
tenberg, S-A Sansone, R.H. Scheuermann, N. Shah,
P.L. Whetzel, and S. Lewis. 2007. The OBO
Foundry: coordinated evolution of ontologies to sup-
port biomedical data integration. Nature biotechnol-
ogy, 25(11):1251?1255.
P. Stenetorp, S. Pyysalo, G. Topic?, T. Ohta, S. Ananiadou,
and J. Tsujii. 2012. brat: a web-based tool for NLP-
assisted text annotation. In Proceedings of the EACL
2012 Demonstrations, pages 102?107.
L. Tanabe, N. Xie, L. Thom, W. Matten, and W.J.
Wilbur. 2005. GENETAG: a tagged corpus for
gene/protein named entity recognition. BMC bioinfor-
matics, 6(Suppl 1):S3.
E.F. Tjong Kim Sang and F. De Meulder. 2003. Intro-
duction to the CoNLL-2003 shared task: Language-
independent named entity recognition. In Proceedings
of the seventh conference on Natural language learn-
ing at HLT-NAACL 2003, pages 142?147.
R. Travillian, T. Adamusiak, T. Burdett, M. Gruenberger,
J. Hancock, A-M. Mallon, J. Malone, P. Schofield, and
H. Parkinson. 2011. Anatomy ontologies and poten-
tial users: bridging the gap. Journal of Biomedical
Semantics, 2(Suppl 4):S3.
J. Wilbur, L. Smith, and L. Tanabe. 2007. BioCre-
ative 2 Gene Mention Task. In Proceedings of Second
BioCreative Challenge Evaluation Workshop, pages
7?16.
36
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 1?7,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Overview of BioNLP Shared Task 2013 
 Claire N?dellec MIG INRA UR1077  F-78352 Jouy-en-Josas cedex claire.nedellec@jouy.inra.fr  
Robert Bossy MIG INRA UR1077  F-78352 Jouy-en-Josas cedex robert.bossy@jouy.inra.fr   Jin-Dong Kim Database Center for Life Science  2-11-16 Yayoi, Bunkyo-ku, Tokyo  jdkim@dbcls.rois.ac.jp  
Jung-jae Kim Nanyang Technological University Singapore  jungjae.kim@ntu.edu.sg  Tomoko Ohta National Centre for Text Mining and School of Computer Science University of Manchester tomoko.ohta@manchester.ac.uk  
Sampo Pyysalo National Centre for Text Mining and School of Computer Science University of Manchester sampo.pyysalo@gmail.com    Pierre Zweigenbaum LIMSI-CNRS F-91403 Orsay  pz@limsi.fr 
 
    Abstract The BioNLP Shared Task 2013 is the third edition of the BioNLP Shared Task series that is a community-wide effort to address fine-grained, structural information extraction from biomedical literature. The BioNLP Shared Task 2013 was held from January to April 2013. Six main tasks were proposed. 38 final submissions were received, from 22 teams. The results show advances in the state of the art and demonstrate that extraction methods can be successfully generalized in various aspects. 1 Introduction The BioNLP Shared Task (BioNLP-ST hereafter) series is a community-wide effort toward fine-grained biomolecular event extraction, from scientific documents. BioNLP-ST 2013 follows the general outline and goals of the previous tasks, namely BioNLP-ST?09 (Kim  et al, 2009) and BioNLP-ST?11 (Kim et al, 
2011). BioNLP-ST aims to provide a common framework for the comparative evaluation of information extraction (IE) methods in the biomedical domain. It shares this common goal with other tasks, namely BioCreative (Critical Assessment of Information Extraction in Biology) (Arighi  et al, 2011), DDIExtraction (Extraction of Drug-Drug Interactions from biomedical texts) (Segura-Bedmar et al, 2011) and i2b2 (Informatics for Integrating Biology and the Bedside) Shared-Tasks (Sun et al, 2013).  The biological questions addressed by the BioNLP-ST series belong to the molecular biology domain and its related fields. With the three editions, the series gathers several groups that prepared various tasks and resources, which represent diverse themes in biology. As the two previous editions, this one measures the progress accomplished by the community on complex text-bound event extraction. Compared to the other initiatives, the BioNLP-ST series proposes a linguistically motivated approach to event representation that enables the evaluation of the participating methods in a unifying computer science framework. Each edition has attracted an 
1
increasing number of teams with 22 teams submitting 38 final results this year. The task setup and the data serve as a basis for numerous further studies, released event extraction systems, and published datasets.  The first event in 2009 triggered active research in the community on a specific fine-grained IE task called Genia event extraction  task. Expanding on this, the second BioNLP-ST was organized under the theme Generalization, where the participants introduced numerous systems that could be straightforwardly applied to different tasks. This time, the BioNLP-ST goes a step further and pursues the grand theme of Knowledge base construction. There were five tasks in 2011, and this year there are 6.  - [GE] Genia Event Extraction for NFkB knowledge base  - [CG] Cancer Genetics  - [PC] Pathway Curation  - [GRO] Corpus Annotation with Gene Regulation Ontology  - [GRN] Gene Regulation Network in Bacteria  - [BB] Bacteria Biotopes  The grand theme of Knowledge base construction is addressed in various ways: semantic web (GE, GRO), pathway (PC), molecular mechanism of cancer (CG), regulation network (GRN) and ontology population (GRO, BB).  In the biology domain, BioNLP-ST 2013 covers many new hot topics that reflect the evolving needs of biologists. BioNLP-ST 2013 broadens the scope of the text-mining application domains in biology by introducing new issues on cancer genetics and pathway curation. It also builds on the well-known previous datasets GENIA, LLL/BI and BB to propose tasks closer to the actual needs of biological data integration.  As in previous events, manually annotated data are provided to the participants for training, development and evaluation of the information extraction methods. According to their relevance for biological studies, the annotations are either bound to specific expressions in the text or represented as structured knowledge. Linguistic processing support was provided to the participants in the form of analyses of the dataset texts produced by state-of-the art tools. This paper summarizes the BioNLP-ST 2013 organization, the task characteristics and their relationships. It gives synthetic figures on the participants and discusses the participating system advances. 
2 Tasks The BioNLP-ST?13 includes six tasks from four groups: DBCLS, NaCTeM, NTU and INRA. As opposed to the last edition, all tasks were main extraction tasks. There were no supporting tasks designed to assist the extraction tasks. All tasks share the same event-based representation and file format, which is similar to the previous editions. This makes it easier to reuse the systems across tasks. Five kinds of annotation types are defined: ? T: text-bound annotation (entity/event trigger) ? Equiv: entity aliases ? E: event ? M: event modification ? R: relation ? N: normalization (external reference) The normalization type has been introduced this year to represent the references to external resources such as dictionaries for GRN or ontologies for GRO and BB. The annotations are stand-off: the texts of the documents are kept separate from the annotations that refer to specific spans of texts through character offsets. More detail and examples can be found on the BioNLP-ST?13 web site. 2.1     Genia Event Extraction (GE) Originally the design and implementation of the GE task was based on the Genia event corpus (Kim et al, 2008) that represents domain knowledge of NF?B proteins. It was first organized as the sole task of the initial 2009 edition of BioNLP-ST (Kim et al, 2009). While in 2009 the data sets consisted only of Medline abstracts, in its second edition in 2011 (Kim et al, 2011b), it was extended to include full text articles to measure the generalization of the technology to full text papers. For its third edition this year, the GE task is organized with the goal of making it a more ?real? task useful for knowledge base construction. The first design choice is to construct the data sets with recent full papers only, so that the extracted pieces of information could represent up-to-date knowledge of the domain. Second, the co-reference annotations are integrated into the event annotations, to encourage the use of these co-reference features in the solution of the event extraction. 
2
2.2     Cancer Genetics (CG) The CG task concerns the extraction of events relevant to cancer, covering molecular foundations, cellular, tissue, and organ-level effects, and organism-level outcomes. In addition to the domain, the task is novel in particular in extending event extraction to upper levels of biological organization. The CG task involves the extraction of 40 event types involving 18 types of entities, defined with respect to community-standard ontologies (Pyysalo et al, 2011a; Ohta et al, 2012). The newly introduced CG task corpus, prepared as an extension of a previously introduced corpus of 250 abstracts (Pyysalo et al, 2012), consists of 600 PubMed abstracts annotated for over 17,000 events. 2.3     Pathway Curation (PC) The PC task focuses on the automatic extraction of biomolecular reactions from text with the aim of supporting the development, evaluation and maintenance of biomolecular pathway models. The PC task setting and its document selection protocol account for both signaling and metabolic pathways. The 23 event types, including chemical modifications (Pyysalo et al, 2011b), are defined primarily with respect to the Systems Biology Ontology (SBO) (Ohta et al, 2011b; Ohta et al, 2011c), involving 4 SBO entity types. The PC task corpus was newly annotated for the task and consists of 525 PubMed abstracts, chosen for the relevance to specific pathway reactions selected from SBML models registered in BioModels and PANTHER DB repositories (Mi and Thomas, 2009). The corpus was manually annotated for over 12,000 events on top of close to 16,000 entities.  2.4     Gene Regulation Ontology (GRO) The GRO task aims to populate the Gene Regulation Ontology (GRO) (Beisswanger et al, 2008) with events and relations identified from text. The large size and the complex semantic representation of the underlying ontology are the main challenges of the task. Those issues, to a greater extent, should be addressed to support full-fledged semantic search over the biomedical literature, which is the ultimate goal of this work.   The corpus consists of 300 MEDLINE abstracts, prepared as an extension of (Kim et al, 2011c). The analysis of the inter-annotator agreement between the two annotators shows 
Kappa values of 43%-56%, which might indicate the difficulty of the task.  2.5     Gene Regulation Network in Bacteria           (GRN) The Gene Regulation Network task consists of the extraction of the regulatory network of a set of genes involved in the sporulation phenomenon of the model organism Bacillus subtilis. Participant system predictions are evaluated with respect to the target regulation network, rather than the text-bound relations. The aim is to assess the IE methods with regards to the needs of systems biology and predictive biology studies. The GRN corpus is a set of sentences from PubMed abstracts that extends the BioNLP-ST 2011 BI (Jourde et al, 2011) and LLL (Nedellec, 2005) corpora. The additional sentences cover a wider range of publication dates and complement the regulation network of the sporulation phenomenon. It has been thoroughly annotated with different levels of biological abstraction: entities, biochemical events, genic interactions and the corresponding regulation network. The network prediction submissions have been evaluated against the reference network using an original metric, the Slot Error Rate (Makhoul et al, 1999) that is more adapted to graph comparison than the usual Recall, Precision and F-score measures.  2.6     Bacteria Biotopes (BB) The Bacteria Biotope (BB) task concerns the extraction of locations in which bacteria live and the categorization of these habitats with concepts from OntoBiotope,1 a large ontology of 1,700 concepts and 2,000 synonyms. The association between bacteria and their habitats is essential information for environmental biology studies, metagenomics and phylogeny. In the previous edition of the BB task, participants had to recognize bacteria and habitat entities, to categorize habitat entities among eight broad types and to extract localization relations between bacteria and their habitats (Bossy et al, 2011). The BioNLP-ST 2013 edition has been split into 3 sub-tasks in order to better assess the performance of the predictive systems for each step. The novelty of this task is mainly the more comprehensive and fine-grained categorization. It addresses the critical problem of habitat normalization necessary for the                                                            1 http://bibliome.jouy.inra.fr/MEM-OntoBiotope 
3
automatic exploitation of bacteria-habitat databases.  2.7     Task characteristics Task features are given in Table 1. Three different types of text were considered: the abstracts of scientific papers taken from PubMed (CG, PC, GRO and GRN), full-text scientific papers (GE) and scientific web pages (BB).   Task Documents # types # events GE 34 Full papers  2 13 CG 600 Abstracts 18 40 PC 525 Abstracts 4 23 GRO 300 Abstracts 174  126 GRN 201 Abstracts 6 12 BB 124 Web pages 563 2 Table 1. Characteristics of the BioNLP-ST 2013 tasks. The number of relations or events targeted greatly varies with the tasks as shown in column 3. The high number of types and events reflect the increasing complexity of the biological knowledge to be extracted. The grand theme of Knowledge base construction in this edition has been translated into rich knowledge representations with the goal of integrating textual data with data from sources other than text. These figures illustrate the shared ambition of the organizers to promote fine-grained information extraction together with an increasing biological plausibility. Beyond gene and protein interactions, they include many complex biological phenomena and environmental factors. 3 BioNLP-ST?13 organization  BioNLP-ST?13 was split in three main periods. During thirteen weeks from mid-January to the first week of April, the participants prepared their systems with the training data. Supporting resources were delivered to participants during this period. Supporting resources were provided by the organizers and by three external providers after a public call for contribution. They range from tokenizers to entity detection tools, mostly focusing on syntactic parsing (Enju (Miyao and Tsujii, 2008), Stanford (Klein and Manning, 2002), McCCJ (Charniak and Johnson, 2005)). The test data were made available for 10 days before the participants had to submit their final results using on-line services. The evaluation results were 
communicated shortly after and published on the ST site. The descriptions of the tasks and representative sample data have been available since October 2012 so that the participants could become acquainted with the task goals and data formats in advance. Table 2 shows the task schedule.  Date Event 23 Oct. 2012 Release of sample data sets 17 Jan 2013 Release of the training data sets 06 Apr. 2013 Release of the test data sets 16 Apr. 2013 Result submission 17 Apr. 2013 Notification of the evaluation results Table 2: Schedule of BioNLP-ST 2013. The BioNLP-ST?13 web site and a dedicated mailing-list have kept the participant informed about the whole process.  4 Participation  GE 1-2-3 CG PC GRO GRN BB 1 - 2-3 EVEX ? ? ?    ?    TEES-2.1 ? ? ? ? ? ? ?  ? ? BioSEM ?          NCBI ?          DlutNLP ?          HDS 4NLP ?          NICTA  ?  ?        USheff ?          UZH  ?          HCMUS ?          NaCTeM     ? ?      NCBI     ?       RelAgent     ?       UET-NII     ?       ISI    ?       OSEE      ?     U. of Ljubljana       ?    K.U. Leuven       ?    IRISA-TexMex       ? ? ?  Boun        ? ?  LIPN        ?   LIMSI        ? ? ? Table 3: Participating teams per task. BioNLP-ST 2013 received 38 submissions from 22 teams (Table 3). One third, or seven teams, participated in multiple tasks. Only one team, UTurku, submitted final results with TEES-2.1 to 
4
all the tasks except one ? entity categorization. This broad participation resulted from the growing capability of the systems to be applied to various tasks without manual tuning. The remaining 15 teams participated in one single task. 5 Results  Table 4 summarizes the best results and the participating systems for each task and sub-task. They are all measured using F-scores, except when it is not relevant, in which case SER is used instead. It is noticeable that the TEES-2.1 system that participated in 9 of the 10 tasks and sub-tasks achieved the best result in 6 cases. Most of the participating systems applied a combination of machine learning algorithms and linguistic features, mainly syntactic parses, with some noticeable exceptions.   Tasks Evaluation results  GE Core event extraction TEES-2.1, EVEX, BioSEM:  0.51 GE 2 Event enrichment TEES2.1:  0.32 GE 3 Negation/Speculation TEES-2.1, EVEX:   0.25 CG TEES-2.1:  0.55 PC NaCTeM:  0.53 
GRO TEES-2.1: 0.22 (events),   0.63 (relations) 
GRN U. of Ljubljana:   0.73 (SER) BB 1 Entity detection and categorization IRISA: 0.46 (SER) BB 2 Relation extraction IRISA:  0.40 BB 3 Full event extraction TEES-2.1:  0.14 Table 4. Best results and team per task  (F-score, except when SER). Twelve teams submitted final results to the GE task. The performance of highly ranked systems shows that the event extraction technology is applicable to the most recent full papers without drop of performance. Six teams submitted final results to the CG task. The highest-performing systems achieved 
results comparable to those for established molecular level extraction tasks (Kim et al, 2011). The results indicate that event extraction methods generalize well to higher levels of biological organization and are applicable to the construction of knowledge bases on cancer. Two teams successfully completed the PC task, and the highest F-score reached 52.8%, indicating that event extraction is a promising approach to support pathway curation efforts. The GRN task attracted five participants. The best SER score was 0,73 (the higher, the worse), which shows their capability of designing regulatory network, but handling modalities remains an issue. Five teams participated to the 3 BB subtasks with 10 final submissions. Not surprisingly, the systems achieved better results in relation extraction than habitat categorization, which remains a major challenge in IE. One team participated in the GRO task, and their results were compared with those of a preliminary system prepared by the task organizers. An analysis of the evaluation results leads us to study issues such as the need to consider the ontology structure and the need for semantic analysis, which are not seriously dealt with by current approaches to event extraction. 6 Organization of the workshop The BioNLP Shared Task 2013 (BioNLP-ST) workshop was organized as part of the ACL BioNLP 2013 workshop. After submission of their system results, participants were invited to submit a paper on their systems to the workshop.  Task organizers were also invited to present overviews of each task, with analyses of the participant system features and results. The workshop was held in August 2013 in Sofia (Bulgaria). It included overview presentations on tasks, as well as oral and poster presentations by Shared Task participants.  7 Discussion and Conclusion This year, the tasks has significantly gained in complexity to face the increasing need for Systems Biology knowledge from various textual sources. The high level of participation and the quality of the results show that the maturity of the field is such that it can meet this challenge. The innovative and various solutions applied this year will without doubt be extended in the future. As for previous editions of BioNLP-ST, all tasks maintain an online evaluation service that is 
5
publicly available. This on-going challenge will contribute to the assessment of the evolving information extraction field in the biomedical domain. References  Auhors. 2013. Title. In Proceedings of the BioNLP 2013 Workshop Companion Volume for Shared Task, Sofia, Bulgaria. Association for Computational Linguistics. Arighi, C., Lu, Z., Krallinger, M., Cohen, K., Wilbur, W., Valencia, A., Hirschman, L. and Wu, C. 2011. Overview of the BioCreative III Workshop. BMC Bioinformatics, 12, S1. E Beisswanger, V Lee, JJ Kim, D Rebholz-Schuhmann, A Splendiani, O Dameron, S Schulz, U Hahn. Gene Regulation Ontology (GRO): Design principles and use cases. Studies in Health Technology and Informatics, 136:9-14, 2008. BioNLP-ST?13 web site: https://2013.bionlp-st.org Robert Bossy, Julien Jourde, Philippe Bessi?res, Maarten van de Guchte, Claire N?dellec. 2011. BioNLP shared Tasks 2011 - Bacteria Biotope. In Proceedings of BioNLP 2011 Workshop, pages 65-73. Association for Computational Linguistics, Portland, USA, 2011. Eugene Charniak and Mark Johnson. 2005. Coarse-to-fine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 173?180. Association for Computational Linguistics. Julien Jourde, Alain-Pierre Manine, Philippe Veber, Karen Fort, Robert Bossy, Erick Alphonse, Philippe Bessi?res. 2011. BioNLP Shared Task 2011 - Bacteria Gene Interactions and Renaming. In Proceedings of BioNLP 2011 Workshop, pages 65-73. Association for Computational Linguistics, Portland. Jin-Dong Kim, Tomoko Ohta and Jun'ichi Tsujii, 2008, Corpus annotation for mining biomedical events from literature, BMC Bioinformatics, 9(1): 10. Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu Kano and Jun'ichi Tsujii. 2009. Overview of BioNLP'09 Shared Task on Event Extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 1-9. Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert Bossy, Ngan Nguyen and Jun?ichi Tsujii. 2011. Overview of BioNLP Shared Task 2011. In Proceedings of BioNLP 2011 Workshop, pages 1-6. Association for Computational Linguistics. 
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Akinori Yonezawa. 2011b. Overview of the Genia Event task in BioNLP Shared Task 2011. In Proceedings of the BioNLP 2011 Workshop Companion Volume for Shared Task, Portland, Oregon, June. Association for Computational Linguistics. Jung-Jae Kim, Xu Han and Watson Wei Khong Chua. 2011c. Annotation of biomedical text with Gene Regulation Ontology: Towards Semantic Web for biomedical literature. Proceedings of LBM 2011, pp. 63-70. Dan Klein and Christopher D Manning. 2002. Fast ex act inference with a factored model for natural language parsing. Advances in neural information processing systems, 15(2003):3?10. John Makhoul, Francis Kubala, Richard Schwartz and Ralph Weischedel. 1999.  Performance measures for information extraction. In Proceedings of DARPA Broadcast News Workshop, Herndon, VA, February. Yusuke Miyao and Jun?ichi Tsujii. 2008. Feature forest models for probabilistic HPSG parsing. Computational Linguistics, 34(1):35?80. Huaiyu Mi and Paul Thomas. 2009. PANTHER path- way: an ontology-based pathway database coupled with data analysis tools. In Protein Networks and Pathway Analysis, pages 123?140. Springer. Claire N?dellec. 2005. Learning Language in Logic - Genic Interaction Extraction Challenge. In Proceedings of the Learning Language in Logic (LLL05) workshop joint to ICML'05. Cussens J. and Nedellec C. (eds). Bonn, August. Tomoko Ohta, Sampo Pyysalo, Sophia Ananiadou, and Jun'ichi Tsujii. 2011b. Pathway curation support as an information extraction task. Proceedings of LBM 2011. Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011c. From pathways to biomolecular events: opportunities and challenges. In Proceedings of BioNLP 2011 Workshop, pages 105?113. Association for Computational Linguistics. Tomoko Ohta, Sampo Pyysalo, Jun?ichi Tsujii, and Sophia Ananiadou. 2012. Open-domain anatomical entity mention detection. In Proceedings of DSSD 2012, pages 27?36. Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, Han-Cheol Cho, Jun?ichi Tsujii, and Sophia Ananiadou. 2012. Event extraction across multiple levels of biological organization. Bioinformatics, 28(18):i575-i581. Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, and Jun'ichi Tsujii. 2011b. Towards exhaustive event extraction for protein modifications. In Proceedings of the BioNLP 2011 Workshop, 
6
pp.114-123, Association for Computational Linguistics. Sampo Pyysalo, Tomoko Ohta, Jun'ichi Tsujii and Sophia Ananiadou. 2011a. Anatomical Entity Recognition with Open Biomedical Ontologies. In proceedings of LBM 2011. Isabel Segura-Bedmar, Paloma Martinez, and Daniel Sanchez-Cisneros. 2011. The 1st DDIExtraction-2011 challenge task: Extraction of Drug-Drug Interactions from biomedical texts. In Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction 2011, SEPLN 2011 satellite workshop. Huelva, Spain, September 7. Weiyi Sun, Anna Rumshisky, Ozlem Uzuner. 2013. Evaluating temporal relations in clinical text: 2012 i2b2 Challenge. J Am Med Inform Assoc.
7
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 58?66,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Overview of the Cancer Genetics (CG) task of BioNLP Shared Task 2013
Sampo Pyysalo Tomoko Ohta Sophia Ananiadou
National Centre for Text Mining and School of Computer Science, University of Manchester
sampo.pyysalo@gmail.com, tomoko.ohta@manchester.ac.uk,
sophia.ananiadou@manchester.ac.uk
Abstract
We present the design, preparation, results
and analysis of the Cancer Genetics (CG)
event extraction task, a main task of the
BioNLP Shared Task (ST) 2013. The CG
task is an information extraction task tar-
geting the recognition of events in text,
represented as structured n-ary associa-
tions of given physical entities. In addition
to addressing the cancer domain, the CG
task is differentiated from previous event
extraction tasks in the BioNLP ST series
in addressing a wide range of pathological
processes and multiple levels of biological
organization, ranging from the molecular
through the cellular and organ levels up to
whole organisms. Final test set submis-
sions were accepted from six teams. The
highest-performing system achieved an F-
score of 55.4%. This level of performance
is broadly comparable with the state of
the art for established molecular-level ex-
traction tasks, demonstrating that event ex-
traction resources and methods generalize
well to higher levels of biological orga-
nization and are applicable to the analy-
sis of scientific texts on cancer. The CG
task continues as an open challenge to
all interested parties, with tools and re-
sources available from http://2013.
bionlp-st.org/.
1 Introduction
Despite decades of focused research efforts, can-
cer remains one of the leading causes of death
worldwide. It is now well understood that cancer
is a broad class of diseases with a complex genetic
basis, involving changes in multiple molecular
pathways (Hanahan and Weinberg, 2000; Haber
et al, 2011). The scientific literature on cancer is
enormous, and our understanding of cancer is de-
veloping rapidly: a query of the PubMed literature
database for cancer returns 2.7 million scien-
tific article citations, with 140,000 citations from
2012. To build and maintain comprehensive, up-
to-date knowledge bases on cancer genetics, auto-
matic support for managing the literature is thus
required.
The BioNLP Shared Task (ST) series has been
instrumental in encouraging the development of
methods and resources for the automatic extrac-
tion of bio-processes from text, but efforts within
this framework have been almost exclusively fo-
cused on normal physiological processes and on
molecular-level entities and events (Kim et al,
2011a; Kim et al, 2011b). To be relevant to can-
cer biology, event extraction technology must be
generalized to be able to address also pathologi-
cal processes as well as physical entities and pro-
cesses at higher levels of biological organization,
including e.g. mutation, cell proliferation, apop-
tosis, blood vessel development, and metastasis.
The CG task aims to advance the development of
such event extraction methods and the capacity for
automatic analysis of texts on cancer biology.
The CG task introduces a novel corpus cover-
ing multiple subdomains of cancer biology, based
in part on a previously introduced angiogenesis
subdomain resource (Pyysalo et al, 2012a). To
extend event extraction to upper levels of biolog-
ical organization and pathological processes, the
task defines a set of 18 entity and 40 event types
based on domain ontologies such as the Com-
mon Anatomy Reference Ontology and Gene On-
tology, more than doubling the number of entity
and event types from those considered in previous
BioNLP ST extraction tasks.
This paper presents the design of the CG task,
introduces the groups and systems taking part in
the task, and presents evaluation results and anal-
ysis.
58
Gene or gene product Gene expression Positive regulation CarcinogenesisTheme ThemeCause
treatment with L-NAME inhibited growth of adenocarcinoma
Planned process Simple chemical Negative regulation Growth CancerThemeInstrument Theme
Cause
Figure 1: Examples of CG task entities and event structures. Visualizations generated using the BRAT
tool (Stenetorp et al, 2012).
2 Task definition
The CG task goal is the automatic extraction of
events (Ananiadou et al, 2010) from text. The
applied representation and task setting extend on
those first established in the BioNLP ST 2009
(Kim et al, 2011a). Each event has a type such as
GROWTH or METASTASIS and is associated with
a specific span of characters expressing the event,
termed the event trigger. Events can take any num-
ber of arguments, each of which is identified as
participating in the event in a specific role (e.g.
Theme or Cause). Event arguments may be either
(physical) entities or other events, allowing com-
plex event structures that capture e.g. one event
causing or preventing another. Finally, events may
be marked by flags identifying extra-propositional
aspects such as occurrence in a speculative or neg-
ative context. Examples of CG task extraction tar-
gets are shown in Figure 1.
The following sections present the categories
of annotation and the specific annotated types in-
volved in the CG task: entities, relations, events,
and event modifications. To focus efforts on novel
challenges, the CG task follows the general con-
vention of the BioNLP ST series of only requiring
participants to extract events and their modifica-
tions. For other categories of annotation, correct
(gold standard) annotations are provided also for
test data.
2.1 Entities
The entity types defined in the CG task are shown
in Table 1. The molecular level entity types largely
match the scope of types such as PROTEIN and
CHEMICAL included in previous ST tasks (Kim et
al., 2012; Pyysalo et al, 2012b). However, the CG
types are more fine grained, and the types PRO-
TEIN DOMAIN OR REGION and DNA DOMAIN OR
REGION are used in favor of the non-specific type
ENTITY, applied in a number of previous tasks
for additional event arguments (see Section 2.3).
The definitions of the anatomical entity types are
Type
ORGANISM
Anatomical entity
ORGANISM SUBDIVISION
ANATOMICAL SYSTEM
ORGAN
MULTI-TISSUE STRUCTURE
TISSUE
DEVELOPING ANATOMICAL STRUCTURE
CELL
CELLULAR COMPONENT
ORGANISM SUBSTANCE
IMMATERIAL ANATOMICAL ENTITY
PATHOLOGICAL FORMATION
CANCER
Molecular entity
GENE OR GENE PRODUCT
PROTEIN DOMAIN OR REGION
DNA DOMAIN OR REGION
SIMPLE CHEMICAL
AMINO ACID
Table 1: Entity types. Indentation corresponds to
is-a structure. Labels in gray identify groupings
defined for organization only, not annotated types.
progression of chronic myeloid leukemia (CML)
Development Cancer CancerEquivTheme
Figure 2: Example Equiv relation.
drawn primarily from the Common Anatomy Ref-
erence Ontology (Haendel et al, 2008), a small,
species-independent upper-level ontology based
on the Foundational Model of Anatomy (Rosse
and Mejino Jr, 2003). We refer to Ohta et al
(2012) for more detailed discussion of the anatom-
ical entity type definitions.
2.2 Relations
The CG task does not target the extraction of
any standalone relations. However, following the
model of past BioNLP ST tasks, the CG corpus is
annotated by Equiv (equivalence) relations, sym-
metric, transitive relations that identify two entity
mentions as referring to the same entity (Figure 2).
These relations primarily mark local aliases and
are applied only in evaluation. When determining
whether a predicted event matches a gold event,
59
Type Core arguments Additional arguments
Anatomical
DEVELOPMENT Theme (Anatomy)
BLOOD VESSEL DEVELOPMENT Theme?(Anatomy) AtLoc?
GROWTH Theme (Anatomy)
DEATH Theme (Anatomy)
CELL DEATH Theme?(CELL)
BREAKDOWN Theme (Anatomy)
CELL PROLIFERATION Theme (CELL)
CELL DIVISION Theme (CELL)
CELL DIFFERENTIATION Theme (CELL) AtLoc?
REMODELING Theme (TISSUE)
REPRODUCTION Theme (ORGANISM)
Pathological
MUTATION Theme (GGP) AtLoc?, Site?
CARCINOGENESIS Theme?(Anatomy) AtLoc?
CELL TRANSFORMATION Theme (CELL) AtLoc?
METASTASIS Theme?(Anatomy) ToLoc
INFECTION Theme?(Anatomy), Participant?(ORGANISM)
Molecular
METABOLISM Theme (Molecule)
SYNTHESIS Theme (SIMPLE CHEMICAL)
CATABOLISM Theme (Molecule)
AMINO ACID CATABOLISM Theme?(Molecule)
GLYCOLYSIS Theme?(Molecule)
GENE EXPRESSION Theme+(GGP)
TRANSCRIPTION Theme (GGP)
TRANSLATION Theme (GGP)
PROTEIN PROCESSING Theme (GGP)
PHOSPHORYLATION Theme (Molecule) Site?
(other chemical modifications defined similarly to PHOSPHORYLATION)
PATHWAY Participant (Molecule)
General
BINDING Theme+(Molecule) Site?
DISSOCIATION Theme (Molecule) Site?
LOCALIZATION Theme+(Molecule) AtLoc?, FromLoc?, ToLoc?
REGULATION Theme (Any), Cause?(Any)
POSITIVE REGULATION Theme (Any), Cause?(Any)
NEGATIVE REGULATION Theme (Any), Cause?(Any)
PLANNED PROCESS Theme*(Any), Instrument*(Entity)
Table 2: Event types and their arguments. Nesting corresponds to ontological structure (is-a/part-of ).
The affixes ?, *, and + denote zero or one, zero or more, and one or more, respectively. GGP abbreviates
for GENE OR GENE PRODUCT. For brevity, additional argument types are not shown in table: Loc
arguments take an anatomical entity type, and Site PROTEIN/DNA DOMAIN OR REGION.
differences in references to equivalent entities are
ignored, so that e.g. an event referring to CML
as its Theme instead of chronic myeloid leukemia
would be considered to match the event shown in
Figure 2.
2.3 Events
Table 2 summarizes the event types defined in the
CG task. As in most previous BioNLP ST task
settings, the event types are defined primarily with
reference to the Gene Ontology (GO) (Ashburner
et al, 2000). However, GO explicitly excludes
from its scope pathological processes, which are
critically important to the CG task. To capture
pathological processes, we systematically expand
the scope GO-based event types to include also
analogous processes involving pathological enti-
ties. For example, statements such as ?cancer
growth? are annotated with GROWTH events by
analogy to processes such as ?organ growth?. Sec-
ond, we introduce a number of event types ex-
plicitly accounting for pathological processes with
no analogous normal physiological process, such
as METASTASIS. Finally, many important effects
are discussed in the literature through statements
involving experimenter action such as transfect
and treat (Figure 1). To capture such state-
ments, we introduce the general PLANNED PRO-
CESS type, defined with reference to the Ontol-
ogy for Biomedical Investigations (Brinkman et
al., 2010).
The event argument roles largely match those
60
Domain Documents Query terms
Carcinogenesis 150 cell transformation, neoplastic AND (proteins OR genes)
Metastasis 100 neoplasm metastasis AND (proteins OR genes)
Apoptosis 50 apoptosis AND (proteins OR genes)
Glucose metabolism 50 (glucose/metabolism OR glycolysis) AND neoplasms
Table 3: Queries for document selection. All query terms were restricted to MeSH Term matches only
(e.g. "apoptosis"[MeSH Terms])
established in previous BioNLP ST tasks (Kim et
al., 2012; Pyysalo et al, 2012b): Theme identifies
the arguments undergoing the primary effects of
the event, Cause those that are responsible for its
occurrence, and Participant those whose precise
role is not stated. Site is used to identify specific
parts of Theme entities affected (e.g. phosphory-
lated residues) and the Loc roles entities where the
event takes place (AtLoc) and start and end points
of movement (FromLoc and ToLoc).
2.4 Event modifications
The CG task follows many previous BioNLP ST
tasks in including the event modification types
NEGATION and SPECULATION in its extraction
targets. These modifications apply to events,
marking them as explicitly negated and specula-
tively stated, respectively (Kim et al, 2011a).
2.5 Evaluation
The CG task evaluation follows the criteria orig-
inally defined in the BioNLP ST?09, requiring
events extracted by systems to otherwise match
gold standard events exactly, but allowing trigger
spans to differ from gold spans by single words
(approximate span matching) and not requiring
matching of additional arguments (see Table 2) for
events referred from other events (approximate re-
cursive matching). These criteria are discussed in
detail by Kim et al (2011a).
3 Corpus
3.1 Document selection
The corpus texts are the titles and abstracts of pub-
lications from the PubMed literature database, se-
lected on the basis of relevance to cancer genet-
ics, specifically with respect to major subdomains
relating to established hallmarks of cancer (Hana-
han and Weinberg, 2000). Of the 600 documents
forming the CG task corpus, 250 were previously
released as part of the MLEE corpus (Pyysalo
et al, 2012a) involving the angiogenesis subdo-
main. The remaining 350 were selected by iter-
Item Train Devel Test Total
Documents 300 100 200 600
Words 66 082 21 732 42 064 129 878
Entities 11 034 3 665 6 984 21 683
Relations 466 176 275 917
Events 8 803 2 915 5 530 17 248
Modifications 670 214 442 1 326
Table 4: Corpus statistics
atively formulating PubMed queries consisting of
MeSH terms relevant to subdomains such as apop-
tosis and metastasis (Table 3). Following initial
query formulation, random sets of abstracts were
selected from each domain and manually exam-
ined to select a final set of documents that specifi-
cally discuss both the target process and its molec-
ular foundations.
3.2 Annotation process
The corpus annotation was created using the BRAT
annotation tool (Stenetorp et al, 2012) by a single
PhD biologist with extensive experience in event
annotation (Tomoko Ohta). For the entity anno-
tation, we created preliminary annotation using
the following automatic named entity and entity
mention taggers: BANNER (Leaman and Gonza-
lez, 2008) trained on the GENETAG corpus (Tan-
abe et al, 2005) for GENE OR GENE PRODUCT
entities, Oscar4 (Jessop et al, 2011) for SIMPLE
CHEMICAL and AMINO ACID entities, NERsuite1
trained on the AnEM corpus (Ohta et al, 2012)
for anatomical entities, and LINNAEUS (Gerner
et al, 2010) for ORGANISM mentions. Process-
ing was performed on a custom pipeline originally
developed for the BioNLP ST?11 (Stenetorp et al,
2011). Following preliminary automatic annota-
tion, all entity annotations were manually revised
to create the final entity annotation.
By contrast to entity annotation, no automatic
preprocessing was applied for event annotation to
avoid any possibility of bias introduced by ini-
tial application of automatic methods. The event
annotation extended the guidelines and manual
1http://nersuite.nlplab.org
61
Team Institution Members
TEES-2.1 University of Turku 1 BI (Bjo?rne and Salakoski, 2013)
NaCTeM National Centre for Text Mining 1 NLP (Miwa and Ananiadou, 2013)
NCBI National Center for Biotechnology Information 3 BI (Liu et al, 2013)
RelAgent RelAgent Private Ltd. 1 LI, 1 CS (Ramanan and Nathan, 2013)
UET-NII
University of Engineering and Technology, Vietnam
6 CS (Tran et al, 2013)
and National Institute of Informatics, Japan
ISI Indian Statistical Institute 2 ML, 2 NLP -
Table 5: Participating teams and references to system descriptions. Abbreviations: BI=Bioinformatician,
NLP=Natural Language Processing researcher, CS=Computer Scientist, LI=Linguist, ML=Machine
Learning researcher.
NLP methods Events Resources
Team Lexical Syntactic Trigger Arg Group Modif. Corpora Other
TEES-2.1 Porter McCCJ + SD SVM SVM SVM SVM GE hedge words
NaCTeM Snowball Enju, GDep SVM SVM SVM SVM - triggers
NCBI MedPost, BLem McCCJ + SD Joint, subgraph matching - GE, EPI -
RelAgent Brill fnTBL, custom rules rules rules rules - -
UET-NII Porter Enju SVM MaxEnt Earley - - triggers
ISI CoreNLP CoreNLP NERsuite Joint, MaltParser - - -
Table 6: Summary of system architectures. Abbreviations: CoreNLP=Stanford CoreNLP, Porter=Porter
stemmer, BLem=BioLemmatizer, Snowball=Snowball stemmer, McCCJ=McClosky-Charniak-Johnson
parser, Charniak=Charniak parser, SD=Stanford Dependency conversion
annotation process introduced by Pyysalo et al
(2012a). Following the initial annotation, a num-
ber of revision passes were made to further im-
prove the consistency of the annotation using a va-
riety of automatically supported methods.2
3.3 Corpus statistics
Table 4 summarizes the corpus statistics for the
training, development and test sets, representing
50%, 17%, and 33% of the documents, respec-
tively. The CG task corpus is the largest of the
BioNLP ST 2013 corpora by most measures, in-
cluding the number of annotated events.
4 Participation
Final results to the CG task were successfully sub-
mitted by six teams, from six different academic
groups and one company, representing a broad
range of expertise ranging from biology to ma-
chine learning, natural language processing, and
linguistics (Table 5).
The characteristics of the participating systems
are summarized in Table 6. There is an interesting
spread of extraction approaches, with two systems
applying SVM-based pipeline architectures shown
2There was no opportunity to train a second annotator in
order to evaluate IAA specifically for the new CG corpus an-
notation. However, based on our previous evaluation using
the same protocol (Pyysalo et al, 2012a), we expect the con-
sistency of the final annotation to fall in the 70-80% F-score
range (primary task evaluation criteria).
successful in previous BioNLP ST events, one
applying a joint pattern matching approach, one
a rule-based approach, and two systems parsing-
based approaches to event extraction. Together,
these systems represent all broad classes of ap-
proaches applied to event extraction in previous
BioNLP ST events. Three of the six systems ad-
dressed also the event modification (negation and
speculation) extraction aspects of the task.
Although all systems perform syntactic analy-
sis of input texts, there is a fair amount of vari-
ety in the applied parsers, which include the parser
of Charniak and Johnson (2005) with the biomed-
ical domain model of McClosky (2009) and the
Stanford Dependency conversion (de Marneffe
et al, 2006) ? the choice in many systems in
BioNLP ST?11 ? as well as Enju (Miyao and Tsu-
jii, 2008), GDep (Sagae and Tsujii, 2007), Stan-
ford CoreNLP3, and a custom parser by RelAgent
(Ramanan and Nathan, 2013). Simple stemming
algorithms such as that of Porter (1980) remain
popular for word-level processing, with just the
NCBI system using a dedicated biomedical do-
main lemmatizer (Liu et al, 2012).
The task setting explicitly allows the use of any
external resources, including other corpora, and
previously released event resources contain sig-
nificant numbers of annotations that are relevant
3http://nlp.stanford.edu/software/
corenlp.shtml
62
Team recall prec. F-score
TEES-2.1 48.76 64.17 55.41
NaCTeM 48.83 55.82 52.09
NCBI 38.28 58.84 46.38
RelAgent 41.73 49.58 45.32
UET-NII 19.66 62.73 29.94
ISI 16.44 47.83 24.47
Table 7: Primary evaluation results
to the molecular level events annotated in the CG
task. Nevertheless, only the TEES and NCBI
teams made use of corpora other than the task
data, both using the GE corpus (Kim et al, 2012)
and NCBI using also the EPI corpus (Pyysalo et
al., 2012b). In addition to corpora annotated for
events, lexical resources derived from such cor-
pora, containing trigger and hedge expressions,
were applied by three teams.
We refer to the descriptions presented by each
of the participating teams (see Table 5) for further
detail on the systems and their implementations.
5 Results
The primary evaluation results are summarized in
Table 7. The highest performance is achieved by
the established machine learning-based TEES sys-
tem, with an F-score of 55%. Previous versions
of the same system achieved the highest perfor-
mance in the BioNLP ST?09 (52% F-score) and
in four out of eight tasks in BioNLP ST?11 (53%
F-score for the comparable GE task) (Bjo?rne and
Salakoski, 2011). The performance of the system
ranked second, EventMine (Miwa et al, 2012),
is likewise broadly comparable to the results for
the same system on the GE task considered in
BioNLP ST?09 and ?11. The NCBI submis-
sion also extends a system that participated in the
ST?11 GE task, then achieving a somewhat lower
F-score of 41.13% (Liu et al, 2011). By con-
trast, the RelAgent, UET-NII and ISI submissions
involve systems that were not previously applied
in BioNLP ST events. Thus, in each case where
system performance for previously proposed event
extraction tasks is known, the results indicate that
the systems generalize to CG task extraction tar-
gets without loss in performance.
These parallels with results for previously intro-
duced tasks involving molecular-level events are
interesting, in particular considering that the CG
task involves more than twice the number of en-
tity and event types included in previously con-
sidered BioNLP ST tasks. The results suggest
not only that event extraction methods generalize
well to higher levels of biological organization,
but also that overall performance is not primar-
ily limited by the number of targeted types. It is
also notable that the complexity of the task set-
ting does not exclude rule-based systems such as
that of RelAgent, which scores within 10% points
of the highest-ranking system. While the parser-
based systems of UET-NII and ISI perform be-
low others here, it should be noted that related ap-
proaches have achieved competitive performance
in previous BioNLP ST tasks (McClosky et al,
2011), suggesting that further development could
lead to improvements for systems based on these
architectures. As is characteristic for event extrac-
tion systems in general, all systems show notably
higher precision than recall, with the performance
of the UET-NII and ISI systems in particular pri-
marily limited by low recall.
The F-score results are shown separately for
each event type in Table 8. As suggested by the
overall results, the novel categories of events in-
volving anatomical and pathological entities are
not particularly challenging for most systems,
with results roughly mirroring performance for
molecular level events; the best results by event
category are 77% F-score for anatomical, 68%
for pathological, and 73% for molecular. Of
the newly introduced CG event categories, only
planned processes involving intentional human in-
tervention appear to represent difficulties, with the
best-performing system for PLANNED PROCESS
reaching only 41% F-score. Two previously es-
tablished categories of events remain challenging:
general events ? best 53% F-score ? including
BINDING (often taking multiple arguments) and
LOCALIZATION (frequent additional arguments),
and regulation category events, which often form
complex event structures by involving events as ar-
guments. Event modifications, addressed by three
of the six participating teams, show comparatively
low levels of extraction performance, with a best
result of 40% F-score for NEGATION and 30%
for SPECULATION. However, as in previous tasks
(Kim et al, 2011a), this is in part due to the com-
pound nature of the problem: for an event modifi-
cation attribute to be extracted correctly, the event
that it attaches to must also be correct.
Further details on system performance and anal-
yses are available on the shared task home page.
63
Event TEES-2.1 NaCTeM NCBI RelAgent UET-NII ISI
DEVELOPMENT 71.43 64.77 67.33 66.31 61.72 53.66
BLOOD VESSEL DEVELOPM 85.28 78.82 81.92 79.60 21.49 13.56
GROWTH 75.97 59.85 66.67 76.92 70.87 65.52
DEATH 81.74 73.17 74.07 64.71 77.78 63.16
CELL DEATH 73.30 75.18 78.05 66.98 25.17 7.35
CELL PROLIFERATION 80.00 78.33 72.73 64.39 71.43 57.40
CELL DIVISION 0.00 0.00 0.00 0.00 0.00 0.00
CELL DIFFERENTIATION 56.34 48.48 48.98 54.55 59.26 24.14
REMODELING 30.00 22.22 21.05 40.00 20.00 23.53
REPRODUCTION 100.00 100.00 100.00 100.00 100.00 100.00
Anatomical total 77.20 71.31 73.68 70.82 50.04 38.86
MUTATION 38.00 41.05 25.11 27.36 27.91 9.52
CARCINOGENESIS 77.94 72.18 67.14 64.12 35.96 24.72
CELL TRANSFORMATION 81.56 82.54 71.13 67.07 57.14 32.39
BREAKDOWN 76.74 70.13 76.54 42.42 58.67 50.70
METASTASIS 70.91 51.05 52.69 47.79 56.41 26.20
INFECTION 69.57 76.92 69.23 33.33 11.76 0.00
Pathological total 67.51 59.78 54.19 48.14 46.90 25.17
METABOLISM 83.87 70.27 74.29 80.00 68.75 71.43
SYNTHESIS 78.26 71.11 78.26 53.57 64.71 48.65
CATABOLISM 63.64 36.36 38.10 23.08 20.00 36.36
GLYCOLYSIS 0.00 100.00 95.45 97.78 0.00 0.00
AMINO ACID CATABOLISM 0.00 66.67 66.67 66.67 0.00 0.00
GENE EXPRESSION 78.21 79.96 73.69 69.45 58.01 53.28
TRANSCRIPTION 37.33 42.86 51.55 28.12 32.00 20.93
TRANSLATION 40.00 22.22 0.00 0.00 0.00 0.00
PROTEIN PROCESSING 100.00 100.00 100.00 0.00 100.00 100.00
ACETYLATION 100.00 100.00 66.67 100.00 66.67 66.67
GLYCOSYLATION 100.00 100.00 100.00 100.00 100.00 100.00
PHOSPHORYLATION 63.33 70.37 53.12 64.15 58.33 50.00
UBIQUITINATION 100.00 100.00 0.00 100.00 0.00 100.00
DEPHOSPHORYLATION 0.00 80.00 100.00 100.00 0.00 0.00
DNA METHYLATION 66.67 66.67 30.30 42.11 32.43 33.33
DNA DEMETHYLATION 0.00 0.00 0.00 0.00 0.00 0.00
PATHWAY 71.30 59.07 51.14 34.29 18.31 35.64
Molecular total 72.60 72.77 67.33 60.72 49.35 46.70
BINDING 45.35 43.93 37.89 32.69 33.94 11.92
DISSOCIATION 0.00 0.00 0.00 0.00 0.00 0.00
LOCALIZATION 54.83 57.20 47.58 45.22 44.94 35.94
General total 52.20 53.08 44.70 40.89 41.76 29.59
REGULATION 32.66 28.73 14.19 26.48 5.51 4.57
POSITIVE REGULATION 45.89 44.18 34.70 38.40 13.00 12.33
NEGATIVE REGULATION 47.79 43.17 33.20 40.47 10.30 12.16
Regulation total 43.08 39.79 29.21 35.58 10.30 10.29
PLANNED PROCESS 39.43 40.51 34.28 28.57 22.74 21.22
Sub-total 56.75 53.50 48.56 46.37 31.72 25.90
NEGATION 40.00 29.55 0.00 34.64 0.00 0.00
SPECULATION 27.14 30.35 0.00 25.90 0.00 0.00
Modification total 34.66 29.95 0.00 30.88 0.00 0.00
Total 55.41 52.09 46.38 45.32 29.94 24.47
Table 8: Primary evaluation F-scores by event type
6 Discussion and conclusions
We have presented the Cancer Genetics (CG) task,
an information extraction task introduced as a
main task of the BioNLP Shared Task (ST) 2013.
The task is motivated by the needs of maintain-
ing up-to-date knowledge bases of the enormous
and fast-growing literature on cancer genetics, and
extends previously proposed BioNLP ST tasks in
several aspects, including the inclusion of enti-
ties and events at levels of biological organiza-
tion above the molecular and the explicit inclusion
of pathological and planned processes among ex-
traction targets. To address these extraction goals,
we introduced a new corpus covering various sub-
domains of cancer genetics, annotated for 18 en-
tity and 40 event types and marking over 17,000
manually annotated events in 600 publication ab-
stracts.
Final submissions to the CG task were received
from six groups, who applied a variety of ap-
proaches including machine learning-based clas-
64
sifier pipelines, parsing-based approaches, and
pattern- and rule-based systems. The best-
performing system achieved an F-score of 55.4%,
a level of performance comparable to the state of
the art in established molecular level event extrac-
tion tasks. The results indicate that event extrac-
tion methods generalize well across the novel as-
pects introduced in the CG task and that event ex-
traction is applicable to the automatic processing
of the cancer literature.
Following convention in the BioNLP Shared
Task series, the Cancer Genetics task will con-
tinue as an open challenge available to all inter-
ested participants. The CG task corpus, supporting
resources and evaluation tools are available from
http://2013.bionlp-st.org/.
Acknowledgments
We wish to thank the BioNLP ST 2013 CG task
participants and supporting resource providers for
their invaluable contributions to making this task a
success. This work was supported by the Biotech-
nology and Biological Sciences Research Council
(BBSRC) [BB/G53025X/1].
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii,
and Douglas B. Kell. 2010. Event extraction
for systems biology by text mining the literature.
Trends in Biotechnology, 28(7):381?390.
Michael Ashburner, Catherine A Ball, Judith A Blake,
David Botstein, et al 2000. Gene ontology: tool
for the unification of biology. Nature genetics,
25(1):25?29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing biomedical event extraction. In Proceedings of
BioNLP?11, pages 183?191.
Jari Bjo?rne and Tapio Salakoski. 2013. TEES 2.1: Au-
tomated annotation scheme learning in the bioNLP
2013 shared task. In Proceedings of BioNLP Shared
Task 2013.
Ryan R Brinkman, Me?lanie Courtot, Dirk Derom, Jen-
nifer M Fostel, et al 2010. Modeling biomedical
experimental processes with OBI. J Biomed Seman-
tics, 1(Suppl 1):S7.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of ACL?05, pages 173?
180.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of LREC, volume 6, pages 449?454.
Martin Gerner, Goran Nenadic, and Casey M Bergman.
2010. Linnaeus: a species name identification sys-
tem for biomedical literature. BMC bioinformatics,
11(1):85.
Daniel A Haber, Nathanael S Gray, and Jose Baselga.
2011. The evolving war on cancer. Cell, 145(1):19?
24.
Melissa A Haendel, Fabian Neuhaus, David Osumi-
Sutherland, Paula M Mabee, Jos LV Mejino Jr,
Chris J Mungall, and Barry Smith. 2008. CARO?
the common anatomy reference ontology. pages
327?349.
Douglas Hanahan and Robert A Weinberg. 2000. The
hallmarks of cancer. Cell, 100(1):57?70.
David M Jessop, Sam E Adams, Egon L Willigha-
gen, Lezan Hawizy, and Peter Murray-Rust. 2011.
Oscar4: a flexible architecture for chemical text-
mining. Journal of Cheminformatics, 3(1):1?12.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2011a. Ex-
tracting bio-molecular events from literature - the
BioNLP?09 shared task. Computational Intelli-
gence, 27(4):513?540.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011b. Overview
of BioNLP Shared Task 2011. In Proceedings of
BioNLP?11.
Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsu-
jii, Toshihisa Takagi, and Akinori Yonezawa. 2012.
The genia event and protein coreference tasks of
the bionlp shared task 2011. BMC bioinformatics,
13(Suppl 11):S1.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedi-
cal named entity recognition. Proceedings of the Pa-
cific Symposium on Biocomputing (PSB?08), pages
652?663.
Haibin Liu, Ravikumar Komandur, and Karin Ver-
spoor. 2011. From graphs to events: A subgraph
matching approach for information extraction from
biomedical text. In Proceedings of BioNLP?11,
pages 164?172.
Haibin Liu, Tom Christiansen, William A Baumgart-
ner Jr, Karin Verspoor, et al 2012. Biolemmatizer:
a lemmatization tool for morphological processing
of biomedical text. Journal of biomedical seman-
tics, 3(3).
Haibin Liu, Karin Verspoor, Donald Comeau, Andrew
MacKinlay, and W John Wilbur. 2013. General-
izing an approximate subgraph matching-based sys-
tem to extract events in molecular biology and can-
cer genetics. In Proceedings of BioNLP Shared Task
2013 Workshop.
65
David McClosky, Mihai Surdeanu, and Christopher D
Manning. 2011. Event extraction as depen-
dency parsing for bionlp 2011. In Proceedings
BioNLP?11, pages 41?45.
David McClosky. 2009. Any Domain Parsing: Au-
tomatic Domain Adaptation for Natural Language
Parsing. Ph.D. thesis, Department of Computer Sci-
ence, Brown University.
Makoto Miwa and Sophia Ananiadou. 2013. NaCTeM
EventMine for bioNLP 2013 CG and PC tasks. In
Proceedings of BioNLP Shared Task 2013 Work-
shop.
Makoto Miwa, Paul Thompson, and Sophia Ana-
niadou. 2012. Boosting automatic event ex-
traction from the literature using domain adapta-
tion and coreference resolution. Bioinformatics,
28(13):1759?1765.
Yusuke Miyao and Jun?ichi Tsujii. 2008. Feature for-
est models for probabilistic hpsg parsing. Computa-
tional Linguistics, 34(1):35?80.
Tomoko Ohta, Sampo Pyysalo, Jun?ichi Tsujii, and
Sophia Ananiadou. 2012. Open-domain anatomical
entity mention detection. In Proceedings of DSSD
2012, pages 27?36.
Martin F Porter. 1980. An algorithm for suffix strip-
ping. Program: electronic library and information
systems, 14(3):130?137.
Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, Han-
Cheol Cho, Jun?ichi Tsujii, and Sophia Ananiadou.
2012a. Event extraction across multiple levels of bi-
ological organization. Bioinformatics, 28(18):i575?
i581.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun?ichi Tsujii, and Sophia Ananiadou. 2012b.
Overview of the ID, EPI and REL tasks of BioNLP
Shared Task 2011. BMC bioinformatics, 13(Suppl
11):S2.
SV Ramanan and P. Senthil Nathan. 2013. Perfor-
mance and limitations of the linguistically motivated
cocoa/peaberry system in a broad biological domain.
In Proceedings of BioNLP Shared Task 2013 Work-
shop.
Cornelius Rosse and Jose? LV Mejino Jr. 2003. A refer-
ence ontology for biomedical informatics: the foun-
dational model of anatomy. Journal of biomedical
informatics, 36(6):478?500.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency
parsing and domain adaptation with lr models and
parser ensembles. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages
1044?1050.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo,
Tomoko Ohta, Jin-Dong Kim, and Jun?ichi Tsujii.
2011. BioNLP Shared Task 2011: Supporting Re-
sources. In Proceedings of BioNLP?11.
Pontus Stenetorp, Sampo Pyysalo, Goran Topic?,
Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-
jii. 2012. Brat: a web-based tool for nlp-assisted
text annotation. In Proceedings of EACL 2012,
pages 102?107.
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne
Matten, and John Wilbur. 2005. GENETAG: a
tagged corpus for gene/protein named entity recog-
nition. BMC Bioinformatics, 6(Suppl 1):S3.
Mai-Vu Tran, Nigel Collier, Hoang-Quynh Le, Van-
Thuy Phi, and Thanh-Binh Pham. 2013. Adapting
a probabilistic earley parser for event decomposi-
tion in biomedical texts. In Proceedings of BioNLP
Shared Task 2013 Workshop.
66
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 67?75,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013
Tomoko Ohta 1, Sampo Pyysalo 1, Rafal Rak 1, Andrew Rowley1, Hong-Woo Chun2,
Sung-Jae Jung 2,3, Chang-Hoo Jeong 2 Sung-Pil Choi 2,3, Jun?ichi Tsujii 4,Sophia Ananiadou 1
1National Centre for Text Mining and School of Computer Science, University of Manchester
2Software Research Center, Korea Institute of Science and Technology Information (KISTI)
3Department of Applied Information Science, University of Science and Technology (UST)
4Microsoft Research Asia, Beijing, China
Abstract
We present the Pathway Curation (PC)
task, a main event extraction task of
the BioNLP shared task (ST) 2013.
The PC task concerns the automatic ex-
traction of biomolecular reactions from
text. The task setting, representation
and semantics are defined with respect
to pathway model standards and ontolo-
gies (SBML, BioPAX, SBO) and docu-
ments selected by relevance to specific
model reactions. Two BioNLP ST 2013
participants successfully completed the
PC task. The highest achieved F-
score, 52.8%, indicates that event extrac-
tion is a promising approach to support-
ing pathway curation efforts. The PC
task continues as an open challenge with
data, resources and tools available from
http://2013.bionlp-st.org/
1 Introduction
Following developments in molecular biology, bi-
ological phenomena are increasingly understood
on the molecular level, as the products of complex
systems of molecular reactions. Pathway mod-
els formalizing biomolecules and their reactions
in machine readable representations are a key way
of sharing and communicating human understand-
ing of these phenomena and of developing com-
putational models of biological systems (Kitano,
2002). Many pathway models integrate knowl-
edge from hundreds or thousands of scientific pub-
lications, and their curation requires substantial
manual effort. To support this effort, we have de-
veloped PathText (Kemper et al, 2010) which pro-
vides a seamless environment integrating a path-
way visualizer, text mining systems and annota-
tion tools. Furthermore, automatic processing of
the domain literature could thus potentially play
pyruvate kinase catalyzes the conversion of PEP to pyruvate.
GGP +Regulation Conversion Chem ChemicalThemeCause Theme Product
Figure 1: Event representation for a conversion re-
action.
an important role in the support of pathway cura-
tion.
Information extraction targeting biomolecular
reactions has been a major focus of efforts in
biomedical natural language processing, with sev-
eral tasks, resources, and tools addressing in par-
ticular protein-protein interactions (Krallinger et
al., 2007; Pyysalo et al, 2008; Tikk et al, 2010).
However, most such efforts have employed sim-
ple representations, such as entity pairs, that are
not sufficient for capturing molecular reactions to
the level of detail required to support the curation
of pathway models. Additionally, previous efforts
have not directly involved the semantics (e.g. re-
action type definitions) of such models. Perhaps
in part due to these reasons, natural language pro-
cessing and information extraction methods have
not been widely embraced by biomedical pathway
curation communities (Ohta et al, 2011c; Ohta et
al., 2011a).
We believe that the extraction of structured
event representations (Figure 1) pursued in the
BioNLP Shared Tasks offers many opportuni-
ties to make significant contributions to support
the development, evaluation and maintenance of
biomolecular pathways. The Pathway Curation
(PC) task, a main task of the BioNLP Shared Task
2013, is proposed as a step toward realizing these
opportunities. The PC task aims to evaluate the ap-
plicability of event extraction systems to pathway
curation and to encourage the further development
of methods for related tasks. The design of the
task aims to address current issues in information
extraction for pathway curation by explicitly bas-
ing its representation and extraction targets on ma-
67
GTP GDP
GAPs
re1
re1 Protein Molecule MoleculeReactantModifier ProductConversion GAPs catalyze the hydrolysis of GTP to GDP.GGP +Reg Conversion Chem Chem
Cause ThemeTheme Product
(a) CONVERSION
p38 gamma Pp38 gamma
MKK6
re1
re1
MKK6 phosphorylates p38 gamma.Protein Protein
Protein
Modifier Reactant
Product
Phosphorylation MKK6 phosphorylates p38 gamma.GGP Phosphorylation GGP
Cause Theme
(b) PHOSPHORYLATION
NF-kappaB
p65
p50
p65
p50re1
p65 binds to p50.
GGP Bind GGPTheme Theme2
p65-p50 complex formation.
Complex BindingProduct
p65 and p50 form p65-p50 complex.
Protein Protein NC binding ComplexReactant2 Product
Reactant
(c) BINDING
Figure 2: Illustration of pathway reaction (left), matching representation as an idealized text-bound event
structure (middle) and applied event representation for statements actually appearing in text (right).
jor standards developed in the biomolecular path-
way curation community, such as SBML (Hucka
et al, 2003) and BioPAX (Mi et al, 2011), and
ontologies such as the Systems Biology Ontology1
(SBO) (Courtot et al, 2011). Further, The corpus
texts are selected on the basis of relevance to a se-
lection of pathway models from PANTHER Path-
way DB2 (Mi and Thomas, 2009) and BioMod-
els3 (Li et al, 2010) repositories. The PC task set-
ting and its document selection protocol aim to ac-
count for both signalling and metabolic pathways,
the latter of which has received comparatively lit-
tle attention in recent domain IE efforts (Li et al,
2013).
2 Task setting
The PC task is formulated as an event extraction
task (Ananiadou et al, 2010) following the general
representation and task setting first introduced in
the BioNLP ST 2009 (Kim et al, 2011). The pri-
mary aim is the extraction of event structures, or
events, each of which can involve any number of
physical entities or other events in specific roles.
The event representation is sufficiently expres-
sive to allow the definition of event structures that
closely parallel the definition of reactions in path-
way representations such as SBML and BioPAX.
These pathway representations differentiate be-
tween three primary groups of reaction partici-
pants: reactants (?inputs?), products (?outputs?),
and modifiers, where the specific roles of modi-
fiers can be further identified to differentiate e.g.
1http://www.ebi.ac.uk/sbo/main/
2http://www.pantherdb.org/pathway/
3http://www.ebi.ac.uk/biomodels-main/
reaction catalysts from inhibitors. Correspond-
ingly, the PC task applies the Theme role defined
in previous BioNLP ST tasks to capture reactants,
introduces a new Product role for products, and
applies the previously defined Cause role and reg-
ulatory events to capture modifiers (Figure 2; see
also Section 2.3).
It is important to note that while the event repre-
sentation allows a one-to-one mapping to reactions
in principle, an annotation scheme cannot guar-
antee that actual statements in text map to fully
specified reactions: in free-form text, authors fre-
quently omit mention of some entities taking part
in reactions, perhaps most typically to avoid re-
dundancies such as in ?p38? is phosphorylated
into phospho-p38?? (Figure 2b). Representations
extracted from explicit statements in text will thus
in some cases omit aspects of the corresponding
complete reactions in pathway models.
Systems addressing the PC task are expected to
extract events of specific types given 1) free-form
text and 2) gold standard annotation for mentions
of physical entities in that text. The task annota-
tions also include equivalence relations and event
modifications, a secondary extraction target. The
annotation types are detailed below.
2.1 Entities
The entity annotation marks mentions of physical
entities using start and end offsets in text (contigu-
ous span) and a type selected from a fixed set. The
following four entity types are marked in the PC
task: SIMPLE CHEMICAL, annotated with refer-
ence to the Chemical Entities of Biological Inter-
est (ChEBI) resource (Degtyarenko et al, 2008);
68
Entity type Scope Reference Ontology ID
SIMPLE CHEMICAL simple, non-repetitive chemical entities ChEBI SBO:0000247
GENE OR GENE PRODUCT genes, RNA and proteins gene/protein DBs SBO:0000246
COMPLEX entities of non-covalently linked components complex DBs SBO:0000253
CELLULAR COMPONENT parts of cell and extracellular environment GO-CC SBO:0000290
Table 1: Entity types, definitions, and reference resources.
Event type Core arguments Additional arguments Ontology ID
CONVERSION Theme:Molecule, Product:Molecule SBO:0000182
PHOSPHORYLATION Theme:Molecule, Cause:Molecule Site:SIMPLE CHEMICAL SBO:0000216
DEPHOSPHORYLATION Theme:Molecule, Cause:Molecule Site:SIMPLE CHEMICAL SBO:0000330
(Other modifications, such as ACETYLATION, defined similarly.)
LOCALIZATION Theme:Molecule At/From/ToLoc:CELL. COMP. GO:0051179
TRANSPORT Theme:Molecule From/ToLoc:CELL. COMP. SBO:0000185
GENE EXPRESSION Theme:GENE OR GENE PRODUCT GO:0010467
TRANSCRIPTION Theme:GENE OR GENE PRODUCT SBO:0000183
TRANSLATION Theme:GENE OR GENE PRODUCT SBO:0000184
DEGRADATION Theme:Molecule SBO:0000179
BINDING Theme:Molecule, Product:COMPLEX SBO:0000177
DISSOCIATION Theme:COMPLEX, Product:Molecule SBO:0000180
REGULATION Theme:ANY, Cause:ANY GO:0065007
POSITIVE REGULATION Theme:ANY, Cause:ANY
GO:0048518,
GO:0044093
ACTIVATION Theme:Molecule, Cause:ANY SBO:0000412
NEGATIVE REGULATION Theme:ANY, Cause:ANY
GO:0048519,
GO:0044092
INACTIVATION Theme:Molecule, Cause:ANY SBO:0000412
PATHWAY Participant:Molecule SBO:0000375
Table 2: Event types and arguments. ?Molecule? refers to an entity annotation of any of the types
SIMPLE CHEMICAL, GENE OR GENE PRODUCT, or COMPLEX, and ?ANY? refers to an annotation of
any type, either entity or event. The indentation corresponds to ontological relationships between the
event types: for example, PHOSPHORYLATION is-a CONVERSION and TRANSCRIPTION part-of
GENE EXPRESSION.
GENE OR GENE PRODUCT, annotated with refer-
ence to gene and protein databases such as UniProt
(Consortium, 2011), Entrez Gene (Maglott et al,
2005) and PFam (Finn et al, 2010); COMPLEX,
annotated with reference to database resources
covering complexes; and CELLULAR COMPO-
NENT, annotated following the scope of the Gene
Ontology cellular component subontology
(Ashburner et al, 2000) (Table 1). For discussion
of the relation between these types and the repre-
sentations applied in pathway models, we refer to
Ohta et al (2011c).
In terms of mention types in text, the annotation
for SIMPLE CHEMICAL, GENE OR GENE PROD-
UCT and COMPLEX covers entity name mentions
only, while the annotation for CELLULAR COM-
PONENT covers entity name mentions, nominal
mentions, and adjectival references (e.g. ?mito-
chondrial?).
2.2 Relations
The PC task defines one relation type, Equiv
(equivalence), which can hold between entity
mitogen-activated protein kinase (MAPK, also known as ERK)
Gene or gene product GGP GGPEquivEquiv
Figure 3: Example Equiv annotation.
mentions of the same type and specifies that they
refer to the same real-world entity (Figure 3).
These relations are only applied to determine if
two events match during evaluation, where entities
connected by an Equiv relation are considered in-
terchangeable. Gold standard Equiv relations are
applied also for test data, and systems participat-
ing in the task are not expected to extract these
relations.
2.3 Events
The event annotation marks references to reac-
tions, processes and comparable associations in
scope of the annotation using the event represen-
tation. For the definition and scope of the event
annotation, we rely primarily on the Systems Biol-
ogy Ontology (SBO), drawing some general types
not in scope of this ontology from the Gene Ontol-
ogy (GO). Table 2 presents the event types anno-
69
Pathway Repository ID Publication
mTOR BioModels MODEL1012220002 (Caron et al, 2010)
mTORC1 upstream regulators BioModels MODEL1012220003 (Caron et al, 2010)
TLR BioModels MODEL2463683119 (Oda and Kitano, 2006)
Yeast Cell Cycle BioModels MODEL1011020000 (Kaizu et al, 2010)
Rb BioModels MODEL4132046015 (Calzone et al, 2008)
EGFR BioModels MODEL2463576061 (Oda et al, 2005)
Human Metabolic Network BioModels MODEL6399676120 (Duarte et al, 2007)
NF-kappaB pathway - - (Oda et al, 2008)
p38 MAPK PANTHER DB P05918 -
p53 PANTHER DB P00059 -
p53 feedback loop pathway PANTHER DB P04392 -
Wnt signaling pathway PANTHER DB P00057 -
Table 3: Pathway models used to select documents for the task, with pathway repository model identifiers
and publications presenting each model (when applicable).
tated in the PC task and their arguments. We refer
again to Ohta et al (2011c) for detailed discussion
of the relation between these types and other rep-
resentations applied in pathway models.
The role in which each event argument (entity
or other event) participates in an event is specified
as one of the following:
Theme entity/event that undergoes the effects of
the event. For example, the entity that is tran-
scribed in a TRANSCRIPTION event or transported
in a TRANSPORT event.
Cause entity/event that is causally active in the
event. Marks, for example, ?P1? in ?P1 inhibits P2
expression?.
AtLoc,FromLoc,ToLoc : location in which the
Theme entity of a LOCALIZATION event is local-
ized (At) in LOCALIZATION events not involving
movement or is transported (or moves) from/to
(From/To) in LOCALIZATION and TRANSPORT
events involving movement.
Site site on the Theme entity that is modified in
the event. Can be specified for modification events
such as PHOSPHORYLATION.
Participant general role type identifying an en-
tity that participates in some underspecified way in
a high-level process. Only applied for the PATH-
WAY type.
2.4 Event modifications
In addition to events, the PC task defines a sec-
ondary extraction target, event modifications. Two
modification types are defined: NEGATION and
SPECULATION. Both are binary flags that mod-
ify events, the former marking an event as be-
ing explicitly stated as not occurring (e.g. ?P is
not phosphorylated?) and the latter as being stated
in a speculative context (?P may be phosphory-
lated.?). Both are defined in terms of annotation
scope and semantics identically as in the BioNLP
ST?09 (Kim et al, 2009).
2.5 Evaluation
The PC task evaluation applies the standard evalu-
ation criteria established in the BioNLP ST 2009.
These criteria relax exact matching between gold
and predicted events in two aspects: approximate
trigger boundary matching, and approximate re-
cursive event matching. The former allows pre-
dicted event triggers to differ from gold triggers
by one word, and the latter requires recursively re-
ferred events to only match in their core arguments
(see Table 2). We refer to Kim et al (2011) for a
detailed definition of these criteria.
3 Corpus
This section presents the PC task corpus and its
annotation process.
3.1 Document selection
To assure that the documents annotated for the PC
task corpus are relevant to pathway reactions, we
applied two complementary approaches, both se-
lecting documents on the basis of relevance to a
specific pathway reaction. First, we selected from
the BioModels repository those pathway models
with the largest numbers of manually created an-
notations referencing a specific PubMed document
identifier. For each of these models, we extracted
literature references, selected a random subset,
downloaded the documents, and manually filtered
to select abstracts that explicitly discuss relevant
molecular reactions. Second, as only a small sub-
set of models include explicit references to the
70
literature providing evidence for specific pathway
reactions, we applied an alternative strategy where
reactions from a selection of PANTHER DB mod-
els were entered into the PathText system (Kem-
per et al, 2010),4 which is capable of suggest-
ing documents relevant to given reactions based
on an SBML model. We then selected a random
set of reactions to query the system, and manually
evaluated the highest-ranking documents to iden-
tify those whose abstracts explicitly discuss the se-
lected reaction. We refer to Miwa et al (2013a)
for a detailed description of this approach. Table 3
presents the pathway models on which the docu-
ment selection was based.
3.2 Annotation process
The base entity annotation for the PC corpus was
created automatically using state-of-the-art entity
mention taggers for each of the targeted entity
types. For SIMPLE CHEMICAL tagging, the OS-
CAR4 system (Jessop et al, 2011) trained on
the chemical named entity recognition corpus of
Corbett and Copestake (2008) was applied. For
GENE OR GENE PRODUCT mention detection, the
NERsuite5 system trained on the BioCreative 2
Gene Mention task (Wilbur et al, 2007) corpus
was used. NERsuite was also applied for CEL-
LULAR COMPONENT mention detection, for this
task trained on the Anatomical Entity Mention
(AnEM) corpus (Ohta et al, 2012). Finally, COM-
PLEX annotations were created using a combi-
nation of a dictionary and heuristics making use
of the GENE OR GENE PRODUCT annotation (for
mentions such as ?cyclin E/CDK2 complex?). To
support the curation process, these tools were in-
tegrated into the NaCTeM text-analysis workflow
system Argo (Rak et al, 2012).
Based on the evaluations of each of these tools
in the studies presenting them, we expected initial
automatic tagging performance to be in the range
80-90% in both precision and recall. Following
initial automatic annotation, the entity mention an-
notation was manually revised to improve quality
and consistency. As the entity annotation is not
itself a target of extraction in the shared task, we
did not separately evaluate the consistency of the
revised entity mention annotation.
To assure that the quality and consistency of
the event annotation are as high as possible, ini-
4http://nactem.ac.uk/pathtext/
5http://nersuite.nlplab.org/
Item Train Devel Test Total
Documents 260 90 175 525
Words 53811 18579 35966 108356
Entities 7855 2734 5312 15901
Events 5992 2129 4004 12125
Modifications 317 80 174 571
Table 4: PC corpus statistics
tial event annotation was created entirely man-
ually, without automatic support. This annota-
tion effort was carried out using the BRAT anno-
tation tool (Stenetorp et al, 2012) by a group of
biologists in collaboration between NaCTeM and
KISTI. Following initial annotator training and re-
finement of guidelines based on the event type def-
initions provided by the reference ontologies, the
primary event annotation was created by three bi-
ologists. To evaluate and maintain annotation con-
sistency, a random 20% of documents were an-
notated redundantly by all annotators, and these
overlapping annotations were periodically evalu-
ated and differences in annotation were discussed
between the annotators and annotation coordina-
tors. Following initial annotation, a round of semi-
automatic consistency checks were applied using
BRAT. Evaluation of the redundantly annotated
documents using the primary task evaluation cri-
teria gave an inter-annotator agreement of 61.0%
in F-score. For the final corpus, the redundantly
annotated documents were evaluated separately by
an annotation coordinator to select the best of each
set.6
The overall statistics of the corpus are summa-
rized in Table 4. We note that the among the
previous BioNLP ST corpora, only the GENIA
(GE) task corpus has a larger number of annotated
events than the PC corpus.
4 Results
4.1 Participation
Two groups submitted final results to the PC
task, one from the National Centre for Text Min-
ing (NaCTeM) and one from the University of
Turku BioNLP group (TEES-2.1) (Table 5). Both
participants applied their well-established, state-
of-the-art event extraction systems, EventMine7
(Miwa et al, 2012) (NaCTeM) and the Turku
6This selection implies that the consistency of the event
annotation of the final corpus is expected to exceed the 61%
F-score of the IAA experiment. Consistency after selection
was not separately evaluated.
7http://nactem.ac.uk/EventMine/
71
NLP Events Other resources
Rank Team Org Word Parse Trig. Arg. Group. Modif. Corpora Other
1 NaCTeM 1NLP Snowball Enju, GDep SVM SVM SVM SVM (see text) triggers
2 TEES-2.1 1BI Porter McCCJ + SD SVM SVM SVM SVM GE hedge words
Table 5: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician,
NLP=Natural Language Processing researcher, McCCJ=McClosky-Charniak-Johnson parser, Char-
niak=Charniak parser, SD=Stanford Dependency conversion, GE=GE task corpus.
Team recall prec. F-score
NaCTeM 52.23 53.48 52.84
TEES-2.1 47.15 55.78 51.10
Table 6: Primary evaluation results
Event Extraction System8 (Bjo?rne et al, 2011)
(TEES). The two systems share the same over-
all architecture, a one-best pipeline with SVM-
based stages for event trigger detection, trigger-
argument relation detection, argument grouping
into event structures, and modification prediction.
The feature representations of both systems draw
on substructures of dependency-like representa-
tions of sentence syntax, derived from full parses
of input sentences. TEES applies the Charniak
and Johnson (2005) parser with the McClosky
(2009) biomedical model, converting the phrase-
structure parses into dependencies using the Stan-
ford tools (de Marneffe et al, 2006). By contrast,
EventMine uses a combination of the predicate-
argument structure analyses created by the deep
parser Enju (Miyao and Tsujii, 2008) and the out-
put of the the GDep best-first shift-reduce depen-
dency parser (Sagae and Tsujii, 2007). All three
parsers have models trained in part on the biomed-
ical domain GENIA treebank (Tateisi et al, 2005).
Interestingly, both systems make use of the GE
task data, but the application of EventMine ex-
tends on this considerably by applying a stacked
model (Miwa et al, 2013b) with predictions also
from models trained on the BioNLP ST 2011 EPI
and ID tasks (Pyysalo et al, 2012) as well as from
four corpora introduced outside of the shared tasks
by Thompson et al (2011), Pyysalo et al (2011),
Ohta et al (2011b) and Ohta et al (2011c).
4.2 Evaluation results
Table 6 summarizes the primary evaluation results.
The two systems demonstrate broadly similar per-
formance in terms of F-scores, with NaCTeM
achieving an 1.7% point higher overall result.
8http://jbjorne.github.io/TEES/
However, the systems show quite different per-
formance in terms of the precision/recall balance:
while the NaCTeM system has little difference
between precision and recall, TEES-2.1 shows a
clear preference for precision, with 8.6% lower re-
call than precision.
Results are shown separately for each event type
in Table 7. The results largely mirror the over-
all performance, with the NaCTeM system show-
ing better performance for 13 out of the 21 event
types present in the test data and more balanced
precision and recall than TEES-2.1, which em-
phasizes precision over recall for almost all event
types. Although the results do not include evalu-
ation of EventMine with a reduced set of stacked
models in training, the modest difference in per-
formance suggests that comprehensive use of pre-
viously released event resources in EventMine did
not confer a decisive advantage, perhaps in part
due to differences in the event definitions between
the PC task and previous resources.
Overall, the two systems appear quite similar
not only in architecture but also performance, with
the clearest systematic difference observed being
the different emphases on precision vs. recall. As
both systems are based on machine learning meth-
ods with real-valued outputs, it would be relatively
straightforward to use prediction confidences to
analyse performance over the entire precision-
recall curve instead of a single fixed point. Such
analysis could provide further insight into the rel-
ative strengths and weaknesses of these two sys-
tems.
5 Discussion
Although participation in this initial run of the PC
task was somewhat limited, the two participating
systems have been applied to a large variety of
event extraction tasks over the last years and have
shown consistently competitive performance with
the state of the art (Bjo?rne and Salakoski, 2011;
Miwa et al, 2012). It is thus reasonable to as-
sume that the higher performance achieved by the
72
NaCTeM TEES-2.1
Event recall prec. F-score recall prec. F-score
CONVERSION 34.33 35.48 34.90 35.82 42.86 39.02
PHOSPHORYLATION 62.46 55.94 59.02 53.40 66.00 59.03
DEPHOSPHORYLATION 45.00 56.25 50.00 35.00 77.78 48.28
ACETYLATION 69.57 72.73 71.11 82.61 76.00 79.17
DEACETYLATION 33.33 33.33 33.33 0.00 0.00 0.00
METHYLATION 42.86 60.00 50.00 57.14 80.00 66.67
DEMETHYLATION 100.00 100.00 100.00 100.00 100.00 100.00
UBIQUITINATION 52.94 64.29 58.06 58.82 76.92 66.67
DEUBIQUITINATION 100.00 100.00 100.00 100.00 100.00 100.00
LOCALIZATION 42.25 61.22 50.00 43.66 54.39 48.44
TRANSPORT 65.52 61.29 63.33 56.55 59.85 58.16
GENE EXPRESSION 90.65 83.15 86.74 84.55 79.39 81.89
TRANSCRIPTION 71.15 82.22 76.29 57.69 73.17 64.52
TRANSLATION 0.00 0.00 0.00 50.00 100.00 66.67
Simple-total 66.42 64.80 65.60 60.40 67.87 63.92
DEGRADATION 78.57 89.19 83.54 78.57 78.57 78.57
ACTIVATION 78.54 70.96 74.56 72.06 72.06 72.06
INACTIVATION 44.62 55.77 49.57 38.46 45.45 41.67
BINDING 64.96 47.30 54.74 53.96 53.96 53.96
DISSOCIATION 38.46 46.88 42.25 35.90 45.16 40.00
PATHWAY 84.91 75.50 79.93 70.94 75.50 73.15
General-total 69.07 62.69 65.72 61.16 65.74 63.37
REGULATION 33.33 33.97 33.65 29.73 39.51 33.93
POSITIVE REGULATION 35.49 42.81 38.81 34.51 45.45 39.23
NEGATIVE REGULATION 45.75 50.64 48.07 41.02 47.37 43.97
Regulation-total 37.73 42.79 40.10 35.17 44.76 39.39
Sub-total 53.47 53.96 53.72 48.23 56.22 51.92
NEGATION 24.52 35.87 29.13 25.16 41.30 31.27
SPECULATION 15.79 22.22 18.46 0.00 0.00 0.00
Modification-total 23.56 34.65 28.05 22.41 40.00 28.73
Total 52.23 53.48 52.84 47.15 55.78 51.10
Table 7: Primary evaluation results by event type.
task participants, a balanced F-score of 52.8%, is
a good estimate of the performance level that can
be attained for this task by present event extraction
technology.
The results achieved by the two systems are
broadly comparable to the best results achieved by
any system in similar previously introduced event
extraction tasks (Kim et al, 2012; Pyysalo et al,
2012). Given the novelty of the task domain and
reference resource and the broad selection of doc-
uments, we find the results highly encouraging re-
garding the applicability of event extraction tech-
nology to supporting the development, evaluation,
and maintenance of pathway models.
6 Conclusions
This paper presented the Pathway Curation (PC)
task, a main event extraction task of the BioNLP
ST 2013. The task was organized in collaboration
between groups with an interest in pathway cura-
tion with the aim of evaluating and advancing the
state of the art in event extraction toward methods
for developing, evaluating and maintaining formal
pathway models in representations such as SBML
and BioPAX. We introduced an event extraction
task setting with reference to pathway model stan-
dards and the Systems Biology Ontology, selected
a set of 525 publication abstracts relevant to spe-
cific model reactions, and created fully manual
73
event annotation marking over 12,000 event struc-
tures in the corpus.
Two participants in the BioNLP ST 2013 sub-
mitted final predictions to the PC task, applying
established, state-of-the-art event extraction sys-
tems, EventMine and the Turku Event Extrac-
tion System. Both systems achieved F-scores
over 50%, with the EventMine system achiev-
ing the best overall result of 52.8%. This level
of performance is broadly comparable with re-
sults achieved in comparable previously proposed
tasks, indicating that current event extraction tech-
nology is applicable to the projected pathway cu-
ration support tasks.
To allow the further development and evalua-
tion of event extraction methods for the task, the
PC task continues as an open challenge to all inter-
ested participants, with the annotated corpus data,
supporting resources, and evaluation tools avail-
able under open licenses from the task homepage,
http://2013.bionlp-st.org/
Acknowledgments
We would like to thank Yonghwa Jo, Hyeyeon
Choi, Jeong-Ik Lee and Ssang-Goo Cho of
Konkuk University for their contribution to the de-
velopment of the relevance judgment annotation
criteria. We also wish to thank Hyun Uk Kim,
Jinki Kim and Kyusang Hwang of KAIST for
their efforts in producing the PC task annotation.
This work is a part of joint research of KISTI and
NaCTeM, and partially supported by the Biotech-
nology and Biological Sciences Research Council
(BBSRC) [BB/G53025X/1].
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and Dou-
glas B. Kell. 2010. Event extraction for systems biology
by text mining the literature. Trends in Biotechnology,
28(7):381?390.
Michael Ashburner, Catherine A. Ball, Judith A. Blake,
David Botstein, Heather Butler, J. Michael Cherry, Al-
lan P. Davis, Kara Dolinski, et al 2000. Gene ontology:
tool for the unification of biology. Nature genetics, 25:25?
29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 183?191.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola, Tapio
Pahikkala, and Tapio Salakoski. 2011. Extracting contex-
tualized complex biological events with rich graph-based
feature sets. Computational Intelligence, 27(4):541?557.
Laurence Calzone, Ame?lie Gelay, Andrei Zinovyev, Franc?ois
Radvanyl, and Emmanuel Barillot. 2008. A comprehen-
sive modular map of molecular interactions in rb/e2f path-
way. Molecular systems biology, 4(1).
Etienne Caron, Samik Ghosh, Yukiko Matsuoka, Dariel
Ashton-Beaucage, Marc Therrien, Se?bastien Lemieux,
Claude Perreault, Philippe P Roux, and Hiroaki Kitano.
2010. A comprehensive map of the mtor signaling net-
work. Molecular systems biology, 6(1).
Eugene Charniak and Mark Johnson. 2005. Coarse-to-Fine
n-Best Parsing and MaxEnt Discriminative Reranking. In
Proceedings of ACL?05, pages 173?180.
The UniProt Consortium. 2011. Ongoing and future devel-
opments at the universal protein resource. Nucleic Acids
Research, 39(suppl 1):D214?D219.
Peter Corbett and Ann Copestake. 2008. Cascaded classifiers
for confidence-based chemical named entity recognition.
BMC Bioinformatics, 9(Suppl 11):S4.
Me?lanie Courtot, Nick Juty, Christian Knu?pfer, Dagmar Wal-
temath, Anna Zhukova, Andreas Dra?ger, Michel Dumon-
tier, Andrew Finney, Martin Golebiewski, Janna Hastings,
et al 2011. Controlled vocabularies and semantics in sys-
tems biology. Molecular systems biology, 7(1).
Marie-Catherine de Marneffe, Bill MacCartney, and Christo-
pher D Manning. 2006. Generating typed dependency
parses from phrase structure parses. In Proceedings of
LREC, volume 6, pages 449?454.
Kirill Degtyarenko, Paula De Matos, Marcus Ennis, Janna
Hastings, Martin Zbinden, Alan Mcnaught, Rafael
Alca?ntara, Michael Darsow, Mickae?l Guedj, and Michael
Ashburner. 2008. Chebi: a database and ontology for
chemical entities of biological interest. Nucleic acids re-
search, 36(suppl 1):D344?D350.
Natalie C Duarte, Scott A Becker, Neema Jamshidi, Ines
Thiele, Monica L Mo, Thuy D Vo, Rohith Srivas, and
Bernhard ? Palsson. 2007. Global reconstruction of
the human metabolic network based on genomic and bib-
liomic data. Proceedings of the National Academy of Sci-
ences, 104(6):1777?1782.
Robert D. Finn, Jaina Mistry, John Tate, Penny Coggill, An-
dreas Heger, Joanne E. Pollington, O. Luke Gavin, Prasad
Gunasekaran, et al 2010. The Pfam protein families
database. Nucleic Acids Research, 38(suppl 1):D211?
D222.
Michael Hucka, Andrew Finney, Herbert M Sauro, Hamid
Bolouri, John C Doyle, Hiroaki Kitano, Adam P Arkin,
Benjamin J Bornstein, et al 2003. The systems biology
markup language (SBML): a medium for representation
and exchange of biochemical network models. Bioinfor-
matics, 19(4):524?531.
David M. Jessop, Sam Adams, Egon L. Willighagen, Lezan
Hawizy, and Peter Murray-Rust. 2011. Oscar4: a flexible
architecture for chemical text-mining. Journal of chemin-
formatics, 3(1):1?12.
Kazunari Kaizu, Samik Ghosh, Yukiko Matsuoka, Hisao
Moriya, Yuki Shimizu-Yoshida, and Hiroaki Kitano.
2010. A comprehensive molecular interaction map of the
budding yeast cell cycle. Molecular systems biology, 6(1).
Brian Kemper, Takuya Matsuzaki, Yukiko Matsuoka, Yoshi-
masa Tsuruoka, Hiroaki Kitano, Sophia Ananiadou, and
Jun?ichi Tsujii. 2010. Pathtext: a text mining integra-
tor for biological pathway visualizations. Bioinformatics,
26(12):i374?i381.
74
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Jun?ichi Tsujii. 2009. Overview of BioNLP?09
Shared Task on Event Extraction. In Proceedings of
BioNLP?09.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Junichi Tsujii. 2011. Extracting bio-molecular
events from literature ? the bionlp?09 shared task. Com-
putational Intelligence, 27(4):513?540.
Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsujii,
Toshihisa Takagi, and Akinori Yonezawa. 2012. The
genia event and protein coreference tasks of the bionlp
shared task 2011. BMC bioinformatics, 13(Suppl 11):S1.
Hiroaki Kitano. 2002. Systems biology: a brief overview.
Science, 295(5560):1662?1664.
Martin Krallinger, Florian Leitner, and Alfonso Valencia.
2007. Assessment of the Second BioCreative PPI task:
Automatic Extraction of Protein-Protein Interactions. In
L. Hirschman, M. Krallinger, and A. Valencia, editors,
Proceedings of BioCreative II, pages 29?39.
Chen Li, Marco Donizelli, Nicolas Rodriguez, Harish
Dharuri, Lukas Endler, Vijayalakshmi Chelliah, Lu Li,
Enuo He, et al 2010. BioModels Database: An enhanced,
curated and annotated resource for published quantitative
kinetic models. BMC Systems Biology, 4:92.
Chen Li, Maria Liakata, and Dietrich Rebholz-Schuhmann.
2013. Biological network extraction from scientific litera-
ture: state of the art and challenges. Briefings in bioinfor-
matics.
Donna Maglott, Jim Ostell, Kim D. Pruitt, and Tatiana
Tatusova. 2005. Entrez gene: gene-centered information
at ncbi. Nucleic Acids Research, 33(suppl 1):D54.
David McClosky. 2009. Any Domain Parsing: Automatic
Domain Adaptation for Natural Language Parsing. Ph.D.
thesis, Brown University.
Huaiyu Mi and Paul Thomas. 2009. PANTHER pathway: an
ontology-based pathway database coupled with data anal-
ysis tools. In Protein Networks and Pathway Analysis,
pages 123?140. Springer.
Huaiyu Mi, Anushya Muruganujan, Emek Demir, Yukiko
Matsuoka, Akira Funahashi, Hiroaki Kitano, and Paul D
Thomas. 2011. Biopax support in celldesigner. Bioinfor-
matics, 27(24):3437?3438.
Makoto Miwa, Paul Thompson, and Sophia Ananiadou.
2012. Boosting automatic event extraction from the liter-
ature using domain adaptation and coreference resolution.
Bioinformatics, 28(13):1759?1765.
Makoto Miwa, Tomoko Ohta, Rafal Rak, Andrew Rowley,
Douglas B. Kell, Sampo Pyysalo, and Sophia Ananiadou.
2013a. A method for integrating and ranking the evidence
for biochemical pathways by mining reactions from text.
Bioinformatics. in press.
Makoto Miwa, Sampo Pyysalo, Tomoko Ohta, and Sophia
Ananiadou. 2013b. Wide coverage biomedical event
extraction using multiple partially overlapping corpora.
BMC bioinformatics, 14(1):175.
Yusuke Miyao and Jun?ichi Tsujii. 2008. Feature forest mod-
els for probabilistic HPSG parsing. Computational Lin-
guistics, 34(1):35?80.
Kanae Oda and Hiroaki Kitano. 2006. A comprehensive
map of the toll-like receptor signaling network. Molecular
Systems Biology, 2(1).
Kanae Oda, Yukiko Matsuoka, Akira Funahashi, and Hiroaki
Kitano. 2005. A comprehensive pathway map of epider-
mal growth factor receptor signaling. Molecular systems
biology, 1(1).
Kanae Oda, Jin-Dong Kim, Tomoko Ohta, Daisuke
Okanohara, Takuya Matsuzaki, Yuka Tateisi, and Jun?ichi
Tsujii. 2008. New challenges for text mining: mapping
between text and manually curated pathways. BMC bioin-
formatics, 9(Suppl 3):S5.
Tomoko Ohta, Sampo Pyysalo, Sophia Ananiadou, and Ju-
nichi Tsujii. 2011a. Pathway curation support as an infor-
mation extraction task. Proceedings of LBM?11.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and Jun?ichi
Tsujii. 2011b. Event extraction for dna methylation.
Journal of Biomedical Semantics, 2(Suppl 5):S2.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011c.
From pathways to biomolecular events: opportunities and
challenges. In Proceedings of BioNLP?11, pages 105?
113.
Tomoko Ohta, Sampo Pyysalo, Jun?ichi Tsujii, and Sophia
Ananiadou. 2012. Open-domain anatomical entity men-
tion detection. In Proceedings of DSSD?12, pages 27?36.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari Bjo?rne,
Filip Ginter, and Tapio Salakoski. 2008. Comparative
analysis of five protein-protein interaction corpora. BMC
Bioinformatics, 9(Suppl 3):S6.
Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, and Jun?ichi
Tsujii. 2011. Towards exhaustive event extraction for pro-
tein modifications. In Proceedings of BioNLP?11, pages
114?123.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sullivan,
Chunhong Mao, Chunxia Wang, Bruno Sobral, Jun?ichi
Tsujii, and Sophia Ananiadou. 2012. Overview of the id,
epi and rel tasks of bionlp shared task 2011. BMC bioin-
formatics, 13(Suppl 11):S2.
Rafal Rak, Andrew Rowley, William Black, and Sophia Ana-
niadou. 2012. Argo: an integrative, interactive, text
mining-based workbench supporting curation. Database:
The Journal of Biological Databases and Curation, 2012.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency parsing
and domain adaptation with lr models and parser ensem-
bles. In Proceedings of the CoNLL Shared Task Session of
EMNLP-CoNLL 2007, pages 1044?1050.
Pontus Stenetorp, Sampo Pyysalo, Goran Topic?, Tomoko
Ohta, Sophia Ananiadou, and Jun?ichi Tsujii. 2012. Brat:
a web-based tool for nlp-assisted text annotation. In Pro-
ceedings of EACL?12, pages 102?107.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Junichi
Tsujii. 2005. Syntax annotation for the genia corpus. In
Proceedings of IJCNLP, volume 5, pages 222?227.
Paul Thompson, Raheel Nawaz, John McNaught, and Sophia
Ananiadou. 2011. Enriching a biomedical event corpus
with meta-knowledge annotation. BMC Bioinformatics,
12(1):393.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg Haken-
berg, and Ulf Leser. 2010. A comprehensive benchmark
of kernel methods to extract protein-protein interactions
from literature. PLoS Comput Biol, 6(7):e1000837, 07.
John Wilbur, Lawrence Smith, and Lorraine Tanabe. 2007.
BioCreative 2. Gene Mention Task. In L. Hirschman,
M. Krallinger, and A. Valencia, editors, Proceedings of
BioCreative II, pages 7?16.
75
