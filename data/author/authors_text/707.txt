The effects of analys ing cohes ion  on document  summar isat ion  
Bran imi r  K. Boguraev  and  Mary  S. Nef f  
IBM ZJ. Watson Research Centel, P.O. Box 704, Yorktown Heights, NY  10598, USA 
bkb,nef f@watson ,  ibm. com 
Abstract 
We argue that in general, the analysis of lexical co- 
hesion factors in a document can drive a summarizer, 
as well as enable other content characterization tasks. 
More narrowly, this paper focuses on how one particular 
cohesion factol~simple l xical repetition--can enhance 
an existing sentence xtraction summarizer, by enabling 
strategies for overcoming some particularly jarring end- 
user effects in the summaries, typically due to coher- 
ence degradation, readability deterioration, and topical 
under-representation. Lexical repetition is instrumental 
to, among other things, the topical make-up of a text, and 
in our framework a lexical repetition-based model of dis- 
course segmentation, capable of detecting topic shifts, is 
integrated with a linguistically-aware summarizer utiliz- 
ing notions of salience and dynamically-adjustable sum- 
mary size. We show that even by leveraging lexical rep- 
etition alone, summaries are of comparable, and under 
certain conditions bette~, quality than the ones delivered 
by a state-of-the-art summarizer. This is encouraging for 
a broad research platform focusing on the recognition 
and use of cohesive devices in text for a range of content 
characterisation a d document management tasks. 
1 Introduction 
This paper add resses aparticular class of problems inher- 
ent to summaries derived by sentence xtraction, namely 
the related issues of coherence degradation, readability de- 
terioration, and topical under-representation. Fundamen- 
tally, these problems arise from unconstrained deletion 
of arbitrary amount of source material between two sen- 
tences which end up adjacent in the summary; this has 
unpredictable effects on the amount of potentially essen- 
tial information which may be lost in that deletion. Ex- 
amples like 'dangling' anaphors (with lost antecedents) 
have been cited often enougk and strategies like includ- 
ing the immediately preceding sentence in the summary 
lmve some effect. While intuitively plausible, these are 
still simple strategies, prone to misfiring; moreover, other 
effects like the reversal of a cote premise in an argument, 
or the introduction, and subsequent elaboration, of a new 
topic, are not easily handled by similar heuristics. 
We seek to leverage a mechanism for assessing the de- 
gree of cohesion between individual sentences in the source 
document, as well as having a notion of how these map 
onto the underlying themes in the document. Informally, 
cohesion--and lexical cohesion in particular--is manifest 
in the ways in which the words, or word patterns, of a 
sentence connect hat sentence to certain of its predeces- 
sors and successors. The intuition is that identifying, and 
preserving, some of these connections in the summary 
would improve its coherence. 
1.1 Lexical  cohesion and summarization 
Documents are coherent because of the continuity of 
their discourse. A number of rhetorical devices help 
achieve cohesion between related document fragments. 
Analysing such devices--or at the very least being sen- 
sitive to their manifestation and interplay---can bring a 
moderately refined degree of discourse awareness into 
the summarization process. In the absence of deep text 
understanding, this boils down to making extensive use 
of a formalized notion of lexical cohesion. 
Linguists have studied extensively how various cohe- 
sive devices operate, and interact, in order to account for 
certain properties of the overall organization ofa text dis- 
course. For (Halliday and Hasan, 1976), the organization 
of text derives from a variety of relationships (cohesive 
ties) among discourse ntities. More recently, (Wintel; 
1979) has focused on the devices that enforce lexical re- 
lationships and connect a discourse fragment with other 
discourse fragments. The underlying theme here is that 
cohesion can be best explained in terms of how repetition 
is manifested across pairs of sentences. Repetition car- 
ries informational va lue- -  it provides a reference point 
for interpreting what has changed, and thus, what is at 
the focus of attention of the discourse--and thus clearly 
goes well beyond the simple notion that discourse frag- 
ments with shared content will also share vocabulary. As 
(Phillips, 1985) points out, the lexical inventory of a text 
is tightly organized in terms of collocation; this makes 
it possible to get a handle on the overall organization of 
text, in general, and on the identification of topic introduc- 
tion and topic closure, in particular. 
A variety of linguistic devices act as vehicles for rep- 
etition: viewed at the level of interplay between words 
and phrases in the text, these include lexical repetition, tex- 
tual substitution and the use of a range of lexical relations, 
co-re~',rence and ellipsis, paraphrasing, colqunetion, and so 
forth. Analysing these would enable the identification of 
strong cohesive ties pulling together a chain of sentences 
which focus on (aspects of) the same discourse ntity or 
event; this would require carrying out, for instance, in- 
depth co-reference and ellipsis resolution, as well as lexi- 
cal relation determination. 
At the other end of the spectrum, just a lexical chaining 
procedure (like the one described in (Morris and I-1irst, 
1.991)) could be used to determine the degree of cohe- 
sion between adjacent pairs of sentences. Indeed, this has 
been the basis for an operational definition of linear dis- 
course segmentation, where segments in a document are 
defined to be contiguous blocks of text, roughly 'about 
the same thing', with segment boundaries indicative of 
topic shifts. 
The research reported here is just one aspect of a larger 
study into the recognition and use of cohesive devices 
for content characterisation tasks. It presupposes fine- 
grained methods for the identification of cohesive ties 
76 
between (sentence) units in a text; describing the com- 
putational basis for developing such methods is outside 
of the scope of this paper (howeveb see (Kennedy and 
Boguraev, 1996), (Fellbaum, 1999), (Kelleb 1994)), as is 
the complete framework for lexical cohesion analysis we 
have developed. Instead, in focusing on the effects of lex- 
ical cohesion on summarization, we limit ourselves here 
on the phenomenon of simple lexical repetition; it turns 
out that even this can be beneficially applied to enhanc- 
ing summarizatkm quality. 
Recent work (Barzilay and Elhadad, 1999) makes ex- 
plicit this intuition. "Lexical chains" are constructed by 
grouping together items related by repetition and cer- 
tain lexical relations derived via the WOI',DNET lexical 
database (Fellbaum, 1999). A sequence of items in a chain 
highlights a discussion focused on topic related to (an) 
ite, m(s) in the chain; a metric for scoring chains picks top- 
ically prominent ones; these are then taken as the basis of 
sentence xtractkm heuristics. A positive result of that 
work is that in an intrinsic evaluation against human- 
constructed summaries, the system outperformed at least 
one commercial summarizer. This highlights the poten- 
tial of a purely lexical chains-based appnmch; still, Barzi- 
lay and Elhadad remain frustrated by the high degree of 
polysemy in WORDNET (not to mention its limited cov- 
erage with respect o more specialized omains); fortu- 
nately, this does not concern us here. 
1.2 Discourse segmentation and summarization 
Unlike Barzilay and Elhadad, we start with a sentence- 
based summarizeb and are specifically seeking to im- 
prove upon what is already (by some measure; see 
Section 4.1 below) a good performance, judged in a 
discipline-wide evaluation initiative (Mani et al, 1999). 
This places certain constraints on how lexical cohesion 
analysis results, and in particular the identification of 
topically coherent segments, can be incorporated in the 
existing strategies and nmchanisms h~r sentence selec- 
tion, already deployed by the summarizer. Making cer- 
tain that a summary incorporates sentences from each 
segment intuitively seeks to ensure uniform representa- 
tion of all sub-stories ina document; he notion here is to 
avoid having inordinately large gaps between adjacent 
summary sentences, which would tend to lose essential 
inhmnation. Moreove,, a mechanism which would pick 
the sentence(s) in a segment most representative its main 
topic, would also carry over into the summary 'traces' of 
all the main topics in the original document. 
This is more than just an intuition. In the process of 
developing, and training, our base summarizer (see Sec- 
tion 2.2 below), an analysis was carried out to determine 
the causes of a certain class of failure. It turns out that 
30.7% of the failures could be prevented by a heuris- 
tic sensitive to the logical structure of documents, which 
would enforce that each (topical) section gets represented 
in the summary. Additional 15.2% of failures could also 
be avoided if the summarizer was capable of detecting 
sub-stories within a single section, leading/trailing oise 
(see below), and so forth. Thus ahnost half of the errors 
(in a certain summarization regime, at least) could have 
been avoided by using a segmentation component. 
This exemplifies how a document-wide analysis of a 
single lexical cohesion factor (simple repetition) can im- 
prove upon an existing sentence selection strategy-~eveu 
if such a strategy has been devised without prior knowl- 
edge of additional enhancements to come. The specific 
approaches to being sensitive to foci of attention within 
a segment, and topic shifts between segments, may vary; 
as we discuss this below (see Section 3.1), these will de- 
pend on other environment settings for the summarizer. 
Still, in the right operational environment even very sim- 
ple heuristics--take the first sentence from each segment, 
for instance--have r markably noticeable impact. 
We thus argue that a lexical repetition-based model of 
linear segmentation ffers effective schemes for deriving 
sentence-based summaries with certain discourse prop- 
erties, enhancing their quality. 
What follows is organized in three main sections. We 
outline some linguistic functions of the summarizel, and 
give details of the summarization a d segmentation com- 
ponents. We focus specifically on how higher level con- 
tent analysis uses lower level shallow linguistic process- 
ing, both to obtain a richer model of the document do- 
main, and to leverage cohesion analysis for sub-story 
identification. Next we discuss some strategies for op- 
timal ttse of discourse segments and topic shifts for sum- 
marization. We sketch our evaluation testbed environ- 
ment, and present experimental results comparing the 
t)erformance of sunnnarization alone to segmentation- 
enhanced summarizatkm. We conclude with an assess- 
ment of the overall utility of 'cheap' approximations to 
lexical cohesion measures, pecifically from the point of 
view of enhancing a fully operational summarizer. 
2 Techno logy  base 
As an integral component of an infrastructure for docu- 
ment analysis with a number of intercoimccted and mu- 
tually enabling linguistic filters, the summarization sys- 
teln discussed here makes use of'shallow' linguistic func- 
tions. The infrastructure is designed from the ground up 
to perform a variety of linguistic feature xtraction func- 
tions, ranging fl'om single pass tokenisation, lexical took- 
up and morphological analysis, to coinplex aggrega- 
tion of representative (salient) phrasal units across multi- 
doculnent collections. Given such a document processing 
environment, the design of our summarizer is based on 
sentence selection mechanisms utlilizing salience ranking 
of phrasal traits in individual documents, when viewed 
against a background of the distribution of phrasal vo- 
cabulary across a large multi-document collectkm. 
2.1 Linguistic filters 
In essence, we have a robust ext analysis ystem for iden- 
tification of proper nanms and technical terms, since these 
are most likely to carry the bulk of the semantic load 
in a document. Howeveb in addition to simple iden- 
tification of certain phrasal types, capabilities also ex- 
ist for identifying their variants (contractions, abbrevia- 
tions, colloquial uses, etc.) in individual documents in 
a multi-document collection. A collection vocabulary of 
canonical forms and variants, with statistical information 
about their distribution behaviom; are used in the sum- 
marizer's alience calculation. Salience, in turn, is a ma- 
jor component of the sentence-level score that selects the 
sentences for extraction (see 2.2 below). 
As a frequency-based system, our summarizer is ide- 
ally positioned to exploit linguistic analysis, filtering, and 
77 
normalization functions. Morphological processing al- 
lows us to link multiple variants of the same word, by 
normalizing to lemma forms. Proper name identification 
is enhanced with context disambiguation, amed entity 
typing, and variant normalisation; asa result he system's 
frequency analysis is more precise, and less sensitive to 
noise; ultimately, this leads to more robust salience cal- 
culation. Normalisation of different variants of the same 
concept o a canonical form is further facilitated by pro- 
cesses of abbreviations unscrambling, resolution of def- 
inite noun phrase anaphora, and aggregation across the 
entire document collection. The set of potentially salient 
phrases is enriched by the identification and extraction 
of technical terms; this enables the recognition of certain 
multi-word concepts mentioned in the document, with 
discourse properties indicative of high topicality value, 
which is also directly relevant to salience determination. 
Each document in a collection is analyzed individually. 
All 'content' (non-stop) words, as well as all phrasal units 
identified by the linguistic filters, are deemed to be vo- 
cabulary items, indexed via their canonical forms. With 
a view to future extensions of the base summarization 
function (see Section 5), these retain complete contextual 
information about the variants they have been encoun-- 
tered in, as well as the local context of each occurrence. 
The vocabulary items are counted and aggregated across 
documents to form the collection w)cabulary. In addition 
to all the canonical forms and variants, the collection vo- 
cabulary contains the composite frequency of each canoni- 
cal form, and its information quotient, a statistical measure 
of the distribution of a vocabulary item in the collection. 
Aggregating together similar items from different docu- 
ments (cross-document co-reference) is far from straight- 
forward for multi-word items; howeveb being able to 
carry out a process of cross-document coreference r solu- 
tion is clearly a further enabling capability for obtaining 
more precise collection statistics. A pronominal anaphora 
resolution function further contributes to the quality of 
the collection statistics. 
In addition to the domain vocabulary, the summarizer 
also has access to document structure information. A hi- 
erarchical representation f the document separates con- 
tent and layout metadata, and makes the latter explicit 
in a document structure tree. Encoded are data includ- 
ing: appearance and layout ags; document title; abstract, 
and other front matter; (sub-)section, etc. headings; para- 
graphs, themselves composed of sentences; 'floating' ob- 
jects like tables, figures, captions; side-bars and other text 
extraneous to the main document narrative; etc. Doc- 
ument structure is constructed by 'shadowing' markup 
parsing, as markup tags are used to construct he doc- 
ument structure tree; for documents without markup, 
structure determination is carried out on the basis of page 
layout cues. The document structure records additional 
discourse-level annotations, uch as cue phrases mark- 
ing rhetorical relations, quoted speech, and so forth. All 
of these elements both contribute directly to the summa- 
rizer's set of heuristics, as well as inform the discourse 
segmentation process. 
2.2 Sa l ience-dr iven  summar izat ion  
With its set of linguistic filters, our frequency-based sum- 
marizer can exploit linguistic dimensions beyond single 
word analysis; this is not unlike the approach of (Aone 
et al, 1997). Due to the sophistication and integration of 
the filters (see Section 2.1), we are able to exploit a richer 
source of domain knowledge than most other frequency- 
based systems. 
Frequency alone is poor indicator of salience, even 
when ignoring stop words. Unlike early frequency-based 
techniques for sentence selection, we utilize the more 
indicative inverse document frequency measure, adapted 
from information retrieval, in which the relative fre- 
quency of an item in a document is compared with its rel- 
ative frequency in a background collection. The trade-off, 
however, for more precise term salience is the summa- 
rizer's dependence on background collection statistics; 
we return to this issue below. 
Sentence selection is driven by the notion of salience; 
the summary is constructed by extracting the most salient 
sentences in the full document. The salience score of a 
sentence is derived partly from the salience of vocabu- 
lary items in the document and partly from its position 
in the document structure (e.g. section-initial, paragraph- 
internal, and so forth) and the salience of the surround- 
ing sentences. The calculation of inverse document fre- 
quency for a w)cabulary item t compares its relative fre- 
quency in the document with its relative frequency in the 
collection. We define the item's salience score to be this 
inverse document frequency measure (in the formula be- 
low, No'oft and Nlgo,., refer to, respectively, to the number 
of items in the collection, and document). 
Salience(t) = log2((N~:ott/fre~q(i,)c~oll)/(NDo~/J'rexl(t)D,,~:)) 
Salient items are items occurring more than once in the 
document, whose salience score is above an experimen- 
tally determined cutoff, or items appearing in a strategic 
position in the document structure (e.g. title, headings, 
etc.; see Section 2.1). All others are assigned zero salience. 
The score for a sentence is made up of two components. 
The salience component is the sum of the salience scores 
of the items in the sentence. The structure component 
reflects the sentence's proximity to the beginning of the 
paragraph, and its paragraph's proximity to the begin- 
ning and/or  end of the document. Structure score is sec- 
ondary to salience score; sentences with no salient items 
get no structure score. 
A set of heuristics address some of the coherence- 
related problems discussed earlier (see 1). For example, 
under certain conditions, a sentence might be selected for 
inclusion in the summary, even if it has low, or even zero, 
score: sentences immediately preceding higher scoring 
ones in a paragraph may get promoted by virtue of an 
'agglomeration rule'. Agglomeration is an inexpensive 
way of preventing dangling anaphors without having 
to resolve them. Another problem for sentence-based 
summarizers, that of thematic under-representation ( r, 
loosely speaking, coverage; see 1), is addressed by an 
'empty section' rule, which is of particular interest for this 
paper. Longer documents with multiple sections, or news 
digests containing several stories, may be unevenly rep- 
resented in a sentence-extracted summary. The 'empty 
section' rule aims to ensure that each section is repre- 
sented in the summary by forcing inclusion of its high- 
est scoring sentences, ob if all sentence scores are zero, its 
first sentence. 
As a general purpose summarize~, ours makes ex- 
tensive use of small scale linguistic information (term 
phrasal patterns) and large scale statistical information 
78 
(term distribution patterns). With the exception of tile 
heuristic rules outlined earlier in this section, tile summa- 
rizer is operating without any focused analysis of cohe- 
sion factors in tile input text. I lence the departure point 
for this work, as already discussed (in Section 1): can the 
summarizer's performance be improved, if we take into 
account lexical cohesion in the source? 
We address this question by making the summarizer 
aware of certain discourse-level f atures of the document, 
and in particular, by leveraging tile topic shifts in it; to 
this end, the infrastructure has been augmented with a 
function for linear discourse segmentation. 
2.3 Linear discourse segmentation 
Segmentation is a document analysis function which di- 
rectly exploits one of tile core text cohesion factors, pat- 
terras of h'xicaI repetition (see Section 1.1), for" identifying 
some baseline data concerning tile distribution of topics 
in a text. In particulal, discourse segmentation is driven 
by tile determination f points in the narrative where per- 
ceptible discontinuities in the text cohesion are detected. 
Such discontinuities are indicative of topic shifts, t%llow- 
ing the original idea of lexical chains (Morris and l lirst, 
1991), subsequently developed specifically for the pur- 
poses of segmentation f expository text (Hearst, 1994), 
we have adapted an algorithm for discourse segmenta- 
tion to our document processing environment. In par- 
ticulab while remaining sensitive to tile distribution of 
"terms" across tile docunlent, and calculating similarity 
between adjacent ext blocks by a cosine measure, our 
procedure differs from that in (Hearst, 1994) in several 
ways. 
We only take into account content words (as opposed 
to all terms yielded by a tnkenizatkm step). These are 
normalized to lemma forms. "Termhood" is addition- 
ally refined to take into account multi-word sequences 
(pcnper names, technical terms, and so forth, as discussed 
in Section 2.1 above), as well as a notion of co-reference, 
where different name variants get "aggregated" into the 
same canonical form. The cohesioi~ calculation (tll\]C- 
tion is biased towards different ypes of possible break 
points: thus certain cue phrases ("llowever", "On lhe olher 
ham/") unambiguously signal a topic shift; document 
structure lements--such as sentence beginnings, para- 
graph openers, and section heads--are exploited for their 
'pre-disposition' to act as likely segment boundaries; and 
so forth (see Section 2.1). The function is also adjusted to 
reduce the noise from block comparisons where the block 
bnundary--and thus a potential topic shift--falls at un- 
natural break points (such as tile middle of  a sentence). 
By making segmentation a other component within 
our  document processing environment, we are able to 
use, transparently, the results of processes such as lexical 
mM morl;hohNical lookup, docmnent structure identification, 
and cue I#trase detection. Likewise, segmentation results 
are naturally incorporated in an annotation superstruc- 
ture which records the various levels of document anal- 
ysis: discourse segments are just another type of a 'span' 
(annotation) over: a number of sentences, logically akin to 
a paragraph (Bird and Liberman, 1999). 
Apart from the adjustments and modifications out- 
lined above, we use essentially tearst's formnla for com- 
puting lexical similarity between adjacent blocks of text 
bl and b2 (t denotes a discourse lement term identified 
as such by prior processing, ranging over tim text span 
of the currently analyzed block; Wt,l,N is the normalized 
frequency of occurrence of the term in block b~\,): 
sim(bl,b2) :~ > tWl,btwt,b~ 
Unlike most applications ofsegmentatkm to date, which 
are concerned with the identification of segment bound- 
aries, we are primarily interested ira Ieveraging the con- 
tent of the segments, to the extent hat it is indicative 
of the focus of attention, and (indirectl3; at least) points 
at tile topical shifts to be utilized for surnmary genera- 
tion. We use tile segmentation results (together with the 
name and term identificatkm and salience calculation de- 
livered by other functions) in order to ensure that all the 
base data for inferring the topic stamps, and topic shifts, 
ix available to the user. 
3 Segmentation-assisted summaries 
What is tile relationsldp between segmentation a d sum- 
marizatkm: is segmentation a strictly "under the covers" 
function for tile summarizer, or might segmentation re- 
suits be of any interest, and use, to tile end nser? We 
fOCLIS ()l 1. SOIlle strategies for incorporating segmentation 
results in tile summary generation process. 1tmvever, un- 
like (Kan et al, 11998) (whose work also seeks to lever- 
age linear segmentation forthe explicit purposes of docu- 
ment summarization), we further take tile view that with 
an appropriate interface metaphor where the user has 
an overview of the relationships between a sunnnary sen- 
tence, the key salient phrases within it, and its enclosing 
discourse segment--a sequence of visually demarkated 
segments can impart a lot of information directly leading 
to in-depth perception of the summary, as it relates to the 
full docun~ent (Boguraev and Neff, 2000). 
3.1 Strategies for utilizing segments 
(_~ol'ln'llOll intuitions uggest a number of strategies for 
leveraging the results of linear discourse segmentation 
for enhancing stunmavizaLion. As topic shift points in 
tile text are 'published' into the document structure (see 
Section 2.3), by defining a segment as an additional type 
of document span (akin to sentence, paragraph, section, 
and so forth), the summarizer t ansparently, and imme- 
diately, becomes aware of the segmentation results. We 
also make arrangements for a mechanism whereby cer- 
tain strategies for incorporating segmentation results into 
the SUlnnlarization process were easy to cast in summa- 
rizer terms. 
Thus, for instance, a heuristic requMng that each seg- 
ment is represented in the summary can be naturally ex- 
pressed by treating segments as sections, and strictly en- 
forcing the 'empty section' rule (see 2.2). The selection 
of a segment-initial sentence for tile summary can be era- 
forced simply by boosting the salience score for that sen- 
tence above a known threshold. A decision to drop an 
anecdotal (or otherwise peripheral; see below) segment 
from consideration i  summary generation would be re- 
alised by setting, as a last step prior to sumlnary genera- 
tion, the sentence salience scores for all sentences in the 
segment to zeros. 
3.2 Other benefits of segmentation 
Such strategies are discussed in mnre detail atch as they 
naturally belong with their evaluation, llere we highlight 
79 
a few observations concerning the overall benefits that 
segmentation brings to summarization. Thus, in addition 
to facilitating sentence-based summaries with certain dis- 
course and rhetorical properties, it turns out that under 
certain conditions the summarizer can operate very ef- 
fectively without a need for background corpus statistics. 
This is a better solution than the highly genre-sensitive 
approach of supplying a 'generic' background collection, 
against which summaries could be generated even for 
documents which are not a priori part of the collection. 
Note that the derivation of a background collection and 
statistics for it might be impractical for a variety of rea- 
sons: lack of access to a sufficiently large and represen- 
tative data sample; no time for processing; sparse stor- 
age resources; and so forth. Clearly, being able to oper- 
ate without such statistics i an operational bonus for the 
summarizer. 
Another use for segmentation is for optimising the use 
of source input, as well as possibly maximising its re-use. 
Occasionally, the document contains 'noise'--possibly in 
the form of anecdotal leads, closing remarks tangential to the 
main points of the story, side-bars, and so forth--which 
are inappropriate sources for summary sentences. Lin- 
ear segmentation sensitive to topic shifts and document 
structure would identify such source fragments and re- 
move them from consideration by the summarizer. Con- 
versely, in certain news reporting enres a whole docu- 
ment fragment (typically towards the beginning or the 
end of the document) functions as a summary of the 
story: we would like to be able to use this fragment; 
clearly identifying it as a segment would help. 
We also use segmentation to handle long documents 
more effectively. While the collection-based salience 
determination works reasonably well for the average- 
length news story, it has some disadvantages. For 
longer documents, with requisite longer summaries, the 
notion of salience degenerates, and the summary be- 
comes just an incoherent collection of sentences. (Even 
if paragraphs, rather than sentences, are used to com- 
pose the summary--see .g. (Mitra et al, 1997)--the same 
problems of coherence degradation and topical under- 
representation, remain.) We use segmentation to iden- 
tify contiguous ub-stories in long documents, which are 
then individually passed on to the summarizer; the re- 
sults of sub-story summaries are 'glued' together. 
4 Evaluat ion 
For evaluating the effect of various strategies upon sum- 
marizer output quality, we used as baseline an evalua- 
tion corpus of full-length articles and their 'digests', from 
The New York Times. There are advantages, and disadvan- 
tages, to this approach. Setting aside whether task-based 
evaluation is appropriate for testing strictly the effect of 
one technology on another (see Section 4.1 below), such 
a decision ties us to a particular set of data. On the pos- 
itive side, this offers a realistic baseline against which to 
compare strategies and heuristics; on the negative side, if 
a certain type of data is missing from the evaluation cor- 
pus, there is little hard evidence for judging the effects of 
strategies and heuristics on such data. 
The remainder of this section describes our evalua- 
tion environment, and then looks at the results for small- 
to-average size documents (the collection comprises just 
over 800 texts, less than half of which are over 10K, 
and virtually none are over 20K; the byte count includes 
HTML markup tags; in terms of number of sentences per 
document, very few of these longer documents are over 
100 sentences long). 
4.1 Summar izat ion  eva luat iontes tbed  
Evaluating summarization results is not trivial, at least 
because there is no such thing as the best, or correct, 
summary--especial ly when the summary is constructed 
as an extract. The purposes of such extracts vary; so do 
human extractors. Sentence xtraction systems may be 
evaluated by comparing the extract with sentences e- 
lected by human subjects (Edmundson, 1969). This is 
a (superficial) objective measure that clearly ignores the 
possibility of multiple right answers. Another objective 
measure compares summaries with pre-existing abstracts 
using a suitable method for mapping a sentence in the 
abstract o its counterpart in the document. Subjective 
measures, even though still less satisfying, can also be de- 
vised: for instance, summary acceptability has been pro- 
posed as one such measure. Other evaluation protocols 
share the primary feature of being task-based, even though 
details may vary. Thus performance may be measured 
by comparing browsing and search time as summary ab- 
stracts and fulMength originals are being used (Miike et 
al., 1994); other measures look at recall and precision in 
document retrieval (Brandow et al, 1995); or recall, pre- 
cision, and time required in document categorization (i.e. 
assessing whether a document has been correctly judged 
to be relevant or not, on the basis of its summary alone) 
(Mani et al, 1999). 
We built an environment for baseline summarizer eval- 
uation, as part of its development/training cycle. This 
was also used in analyzing the impact of discourse seg- 
mentation on the summarizer's performance. A back- 
ground collection vocabulary statistics was derived from 
analyzing 2334 New York Times news stories. Sentences 
in digests for 808 stories and feature articles were auto- 
matically matched with their corresponding sentences in 
the full-length documents. Digests range in length from 
1 to 4 sentences. Since we were particularly interested 
in longer stories, as well as stories in which the first sen- 
tence in the document did not appear in the digest, their 
representation in the test set, 38%, is larger than their dis- 
tribution in the newspaper. 
Since digests are inherently short, this evaluation strat- 
egy is somewhat limited in its capability of fully assess- 
ing segmentation effects on summarization of long doc- 
uments. Nonetheless, a number of comparative analyses 
can be carried out against his baseline collection, which 
are indicative of the interplay of the various control op- 
tions, environment settings, and linguistic filters used. 
One parameter, in particular, isquite instrumental in tun- 
ing the summarizer's performance, to a large extent be- 
cause it is directly related to length of the original docu- 
ment: size of thesummary, expressed either as number of 
sentences, or as percentage of the full length of the origi- 
nal. In addition to a clear intuition (namely that the size 
of the summary ought to be related to the size of the orig- 
inal), varying the length of the summary offers both the 
ability to measure the summarizer's performance against 
baseline summaries (i.e. our collection of digests), and the 
potential of dynamically adjusting the derived summary 
size to optimally represent the full document content, de- 
80 
pending on the size of that document. 
Our experiments vary tile granularity of summary 
size. In principle, the performance of a system which 
does absolute sentence ranking, and systematically picks 
the N 'best' sentences for tlle summary, should not de- 
pend on the summary size. In our case, the additional 
heuristics for improving the coherence, readability, and 
representativeness of tile summary (see Section 2.2) in- 
troduce variations in overall summary quality, depend- 
ing on the compaction factor applied to the original doc- 
ument size. A representative spectrum for tlle test corpus 
we use is given by data points at: diqest size (i.e. sum- 
mary exactly the size, expressed as number of sentences, 
of tile digest); 4 sentem:es; I0% of the size of the full length 
document; and 20% of the document. Not surprisingly 
(for a salience-based system), the sumnlarization ftmc- 
tion alone, without discourse segmentation, benefits from 
larger summary size. Although tlle recall rate is higher 
still for longer summaries, it is not a measure of the over- 
all quality of tile summary because of tile inherently short 
length of tile digest. 
4.2 Segmentat ion effects on summar izat ion 
Our experiments compare the base summarization pro- 
cedure, which calculates object salience with respect o a 
background ocument collection (Section 2.2), with en- 
hanced procedures incorporating different strategies us- 
ing the notions of discourse segments and topic shifts. 
These elaborate tile intuitions underlying our ap- 
proach to leveraging lexical cohesion effects (see Sec- 
tion 1.2). The experiments fall in either of two categories. 
In an environment where a background collection, and 
statistics, cannot be assumed, a summarization proce- 
dure was defined to take selected (typically initial) sen- 
tences from each segment; this appeals to the intuition 
that segment-initial sentences would be good topic in- 
dicators for their respective segments, qhe other cate- 
gory of experiment focused on enriching the base sum- 
marization procedure with a sentence selection mecha- 
nism which is informed by segment botmdary identifica- 
tion and topic shift detection. 
In combining different sentence selection mechanisms, 
several variables need adjustment to account for relative 
contributions of the different document analysis meth- 
ods, especially where summaries can be specified to be 
of different lengths. Given the additional sentence selec- 
tion factors interacting with abso\]ute sentence ranking, 
we again set the granularity of summary size at three dis- 
crete steps, mirroring the evaluation of the original sum- 
marizer: summaries can be requested to be precisely 4
sentences long, or to reflect source compaction factor of 
10% or 20% (Sectkm 4.1). 
We experimented with two broad strategies for incor- 
porating topical informatkm into the sunnnary. One ap- 
proach aimed to bring 'topic openers' into the summars; 
by adding segment-initial sentences to those already se- 
lected via salience calculation. The other was to exert 
finer control over the number of sentences elected via 
salience, and 'pad' the summary to its requested size with 
sentences selected from segments by invoking the 'empty 
segment' (aka 'empty sectkm', see 2.2) rule. Special pro- 
visions accounted for the fact that segmentatkm would 
naturally always select he document-initial sentence. 
It turns out that the differences between a range of re- 
alisations of the above two strategies are not statistically 
significant over our test corpus; we thus use the label 
"SUM+SEG" to denote a 'composite' strategy and to rep- 
resent he whole family of variations. In contrast, "SUM" 
refers to the base smnmarization component, and "SEG" 
represents summarization by segmentation alone. Table 1 
below shows the recall rates for the three major summa- 
rization regimes defined by different summary granular- 
ities. Since segmentation effects are clearly very differ- 
ent across different sizes of source document, our experi- 
ments were additionally conducted at sampling the doc- 
ument collection at different sizes of the originals: the 
corpus was split into four sections, grouping together 
documents less than 7.5K characters long, 7.5-\]0K, 10- 
19K, and over 19K; for brevity, the table encapsulates a 
'composite' result (denoted by the label "All documents"). 
\[\[ 4 sents 10% 20?/,, 
All documents 
SEG 54.74 54.74 56.09 
SUM 46.85 49.71 66.47 
SUM+SEG 56.52 56.30 58.37 
All documents with > 1 digest sentence 
SEG 45.13 45.13 46.78 
SUM 36.34 39.84 58.66 
SUM+SEG 41.64 46.75 51.65 
All documents whose 1st sentence not in target digest 
SliG 31.12 32.73 33.99 
SUM 29.93 39.96 61.71 
SUM+SEG 32.53 41.45 47.96 
qhble 1: Sumn~ary data for segmentation effects 
lb  get a better sense for tile effects of different strategy 
mixes, we also show results for tile same summarization 
regimes, on subsets of the test corpus. "All documents with 
> I di,?esl senh'm:t'" represents documents whose digests 
are longer than a single sentence; "All documetHs whose 
1st sent is not in target d~qest" extracts a document set for 
which a baseline strategy automatically picking a repre- 
sentative sentence for inclusion in the summary would be 
inappropriate. These subset selection criteria explain the 
deterioration of overall results; howeveb what is more 
interesting to observe in the table is the relative perfor- 
mance of tile three summarization regimes. 
Overall, leveraging some of the segmentation a alysis 
is positively beneficial to summarization; the effects are 
particularly strong where short summaries are required. 
In addition, summarization driven by segmentation data 
alone shows recall rates comparable to, and in certain sit- 
uatkms even higher than, tlle baseline: this suggests that 
such a procedure is certainly usable in situations where 
background collection-based salience calculation is im- 
possible, or impractical. 
Finally, we emphasise a note of particular interest here: 
the complete set of data from these experiments makes it 
possible, for any given document, to select dynamically 
tile summarization strategy appropriate to its size, in or- 
der to get an optimal summary for it, in any given infor- 
mation compaction regime. 
5 Conclusion 
Starting from a class of problems inherent o summariza- 
tion by sentence xtraction, we have proposed a strat- 
81 
egy for alleviating some of the particularly jarring end- 
user effects in the summaries, which are due to coher- 
ence degradation, readability deterioration, and topical 
under-representation. Our approach is to aim for more 
cohesive summaries, by leveraging the lexical cohesion 
factors in the source document exts. As an initial ex- 
periment, we have looked at one particular facto1; lcxical 
repetition, and have developed a framework for integrab 
ing a discourse segmentation component capable of de- 
tecting shifts in topic, with a linguistically-aware summa- 
rizer which utilizes notions of salience and dynamically- 
adjustable size of the resulting summaries. By analyz- 
ing cohesion indicators in the discourse, segmentation 
identifies points in the narrative where sub-stories alter- 
nate; the summarization function uses the resulting set 
of discourse segments to derive more complete, informa- 
tive and faithful summaries than ones extracted solely on 
the basis of sentence salience (calculated with respect o 
a background ocument collection). 
A comparative evaluation of summarization with, and 
without, segmentation analysis shows that under cer- 
tain conditions, segmentation-enhanced summarization 
is better than the base segmentation technology: Some 
of these conditions can be expressed as a function of 
the original document length, and the document-to- 
summary ratio; thus, of particular interest is the fact that 
optimal strategy for combining the two technologies can 
be selected 'on the fly', depending on the type of input to 
be summarized. 
Furthemore, having access to a segmentation compo- 
nent makes it possible to alleviate a serious shortcom- 
ing of summarizers like ours, which crucially depend 
on the statistics of a background collection: in situa- 
tions where background collection-based salience calcu- 
latkm is impossible, or impractical, it is realistic to de- 
liver summaries--of  comparable quality, yet consider- 
ably cheaper to generate--derived by access to discourse 
segmentation i formation alone. 
The research reported here is part of a larger effort fo- 
cused on leveraging elements of the discourse structure 
for a variety of content characterisation tasks. Overall, 
we aim to build an infrastructure for recognizing and us- 
ing a broad range of cohesive devices in text. Document 
summarization is just one application in the larger space 
of document content management; our long term goal is 
to develop a framework where summarization and other 
applications would be enabled by a rich substrate of lin- 
guistic analysis of lexical cohesion. 
References 
Chinatsu Aone, Mary Ellen Okurowski, James Gorlinsky, 
and Bjornar Larsen. 1997. A scalable summarization 
system using robust NLP. In Intelligent Scalable Text 
Summarizathm, Proceedings ofWorkshop Sponsored by the 
Assochltion fi," Computational Linguistics, pages 66-73. 
Regina Barzilay and Michael Elhadad. 1999. Using lex- 
ical chains for text summarization. In Inderjeet Mani 
and Mark T. Maybury, editors, Advances in automatic 
text summarization, pages 111-121. MIT Press, Cam- 
bridge, MA. 
Steven Bird and Mark Liberman. :1999. Annotation 
graphs as a framework for multidimensional linguis- 
tic data analysis. In Proceedings ofa Workshop, "TowaMs 
Standards and Tools fin" Discourse Tagging", 37th Ammal 
Meeting of the AssochTtion for Computational Linguistics, 
pages 1-10, Baltimore, MD. 
Branimir Boguraev and Mary Neff. 2000. Lexical co- 
hesion, discourse segmentation and document sum- 
marization. In Proceedings ofRIAO-2000, Content-Based 
Multimedia Infi~rmation Access, Paris, France. 
R. Brandow, K. Mitze, and L. Rau. 1995. Automatic on- 
densation of electronic publications by sentence selec- 
tion. Informathm Processing & Management, 31(5). 
H.P. Edmundson. 1969. New methods in automatic ab- 
stracting. Journal of the ACM, 16(2):264-285. 
Christiana Fellbaum, editor. 1999. WORDNET: all elec- 
tronic lexical database and some of its applications. M1T 
Press, Cambridge, MA. 
M.A.K. Hall iday and R. Hasan. 1976. Cohesion i  English. 
Longman, London. 
Marti Hearst. 1994. Multi-paragraph segmentation f ex- 
pository text. In 32nd Ammal Meeting of the Association 
fi~r Computational Linguistics, Las Cruces, New Mexico. 
Min-Yen Kan, Judith L. Klavans, and Kathleen R. McK- 
eown. 1998. Linear segmentation and segment signif- 
icance, in Eugene Charniak, editob Proceedings ofthe 
Sixth Workshop on Very Large Corpora, pages 197-205, 
Montreal, Canada, August. Sponsored by ACL and 
ACI 's  SIGDAT. 
Andrew Keller. 1994. Common topics and coherent situ- 
ations: interpreting ellipsis in the context of discourse 
inference. In Proceedinqs ofthe 32nd Annual Meeting ~ 
the Association for Comlmtational Linguistics, pages 50- 
57, Las Cruces, NM. 
Christopher Kennedy and Branimir Bogurae\: 1996. 
Anaphora for everyone: Pronominal anaphora reso- 
lution without a parser. In Proceedings ofCOLING-96 
(161h International Conference on Computathmal Linguis- 
tics), Copenhagen, DK. 
lnderjeet Mani, Therese Firmin, and Beth Sundheim. 
1999. The TIPSTER SUMMAC text summarization eval- 
uation. In Proceedings ofthe Ninth CoJ~rence of the Euro- 
wan Chapter of the ACL, pages 77-85, Bergen, Norway, 
June. Association for Computational Linguistics. 
Seije Miike, Etsuo ltho, Kenji Ono, and Kazuo Sumita. 
1994. A full text retrieval system with a dynamic ab- 
stract generation function. In Proceedings ofthe 17th An- 
m~al International ACM SIGIR Conference on Research and 
Development i  Information Retrieval, pages 152-161. 
Mandar Mitra, Amit Singhal, and Chris Buckley. :1997. 
Automatic text summarisation by paragraph extrac- 
tion. In Inderjeet Mani and Mark T. Maybury, editors, 
Proceedings ~a Worksh W on Intelligent Scalable text Sum- 
marization, pages 39-46, Madrid, Spain. Sponsored by 
the Association for Computational Linguistics. 
Jane Morris and Graeme Hirst. 1991. Lexical cohesion 
computed by thesaural relations as an indicator of the 
structure of text. Computational Linguistics, 17:21-48. 
M. Phillips. 1985. Aspects of text structure: an investigation 
of the lexical organization oftext. North Holland, Ams- 
terdam. 
E.O. Winter 1979. Replacement as a fundamental func- 
tion of the sentence in context. Forum Linguistieum, 
4(2):95-133. 
82 
 
		Introduction to the Special Issue on 
Computational Anaphora Resolution 
Ruslan Mitkov* 
University of Wolverhampton 
Shalom Lappin* 
King's College, London 
Branimir Boguraev* 
IBM T. J. Watson Research Center 
Anaphora accounts for cohesion in texts and is a phenomenon under active study 
in formal and computational linguistics alike. The correct interpretation of anaphora 
is vital for natural anguage processing (NLP). For example, anaphora resolution is 
a key task in natural anguage interfaces, machine translation, text summarization, 
information extraction, question answering, and a number of other NLP applications. 
After considerable initial research, followed by years of relative silence in the early 
1980s, anaphora resolution has attracted the attention of many researchers in the last 10 
years and a great deal of successful work on the topic has been carried out. Discourse- 
oriented theories and formalisms uch as Discourse Representation Theory and Cen- 
tering Theory inspired new research on the computational treatment of anaphora. The 
drive toward corpus-based robust NLP solutions further stimulated interest in alterna- 
tive and/or data-enriched approaches. Last, but not least, application-driven research 
in areas uch as automatic abstracting and information extraction i dependently high- 
lighted the importance of anaphora nd coreference r solution, boosting research in 
this area. 
Much of the earlier work in anaphora resolution heavily exploited omain and lin- 
guistic knowledge (Sidner 1979; Carter 1987; Rich and LuperFoy 1988; Carbonell and 
Brown 1988), which was difficult both to represent and to process, and which required 
considerable human input. However, the pressing need for the development of robust 
and inexpensive solutions to meet the demands of practical NLP systems encouraged 
many researchers tomove away from extensive domain and linguistic knowledge and 
to embark instead upon knowledge-poor anaphora resolution strategies. A number of 
proposals in the 1990s deliberately imited the extent o which they relied on domain 
and/or linguistic knowledge and reported promising results in knowledge-poor per- 
ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 
1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; 
Mitkov 1996, 1998b). 
The drive toward knowledge-poor and robust approaches was further motivated 
by the emergence of cheaper and more reliable corpus-based NLP tools such as part- 
of-speech taggers and shallow parsers, alongside the increasing availability of corpora 
and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw 
and annotated with coreferential links, provided a strong impetus to anaphora resolu- 
* School of Humanities, Language and Social Sciences, Stafford Street, Wolverhampton WV1 1SB, UK. 
E-maih r.mitkov@wlv.ac.uk 
t 30 Saw Mill River Road, Hawthorne, NY 10532, USA. E-mail: bkb@watson.ibm.com 
~: Department of Computer Science, King's College, The Strand, London WC2R 2LS, UK. 
E-mail: lappin@dcs.kcl.ac.uk 
@ 2001 Association for Computational Linguistics 
Computational Linguistics Volume 27, Number 4 
tion with regard to both training and evaluation. Corpora (especially when annotated) 
are an invaluable source not only for empirical research but also for automated learning 
(e.g., machine learning) methods aiming to develop new rules and approaches; they 
also provide an important resource for evaluation of the implemented approaches. 
From simple co-occurrence rules (Dagan and Itai 1990) through training decision trees 
to identify anaphor-antecedent pairs (Aone and Bennett 1995) to genetic algorithms to 
optimize the resolution factors (Or~san, Evans, and Mitkov 2000), the successful per- 
formance of more and more modern approaches was made possible by the availability 
of suitable corpora. 
While the shift toward knowledge-poor strategies and the use of corpora repre- 
sented the main trends of anaphora resolution in the 1990s, there are other signifi- 
cant highlights in recent anaphora resolution research. The inclusion of the corefer- 
ence task in the Sixth and Seventh Message Understanding Conferences (MUC-6 and 
MUC-7) gave a considerable impetus to the development of coreference resolution 
algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas 
and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century 
saw a number of anaphora resolution projects for languages other than English such as 
French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background 
of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- 
lution has gained considerable momentum in recent years (Aone and McKee 1993; 
Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov 
and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). 
Other milestones of recent research include the deployment of probabilistic and ma- 
chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- 
niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either 
in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn 
and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology 
in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state 
of the art in anaphora resolution, see Mitkov (forthcoming). 
The papers published in this issue reflect he major trends in anaphora resolution 
in recent years. Some of them describe approaches that do not exploit full syntactic 
knowledge (as in the case of Palomar et al's and Stuckardt's work) or that employ 
machine learning techniques (Soon, Ng, and Lira); others present centering-based pro- 
noun resolution (Tetreault) or discuss theoretical centering issues (Kibble). Almost all 
of the papers feature extensive valuation (including comparative valuation as in 
the case of Tetreault's and Palomar et al's work) or discuss general evaluation issues 
(Byron as well as Stuckardt). 
Palomar et al's paper describes an approach that works from the output of a 
partial parser and handles third person personal, demonstrative, reflexive, and zero 
pronouns, featuring among other things syntactic onditions on Spanish NP-pronoun 
noncoreference and an enhanced set of resolution preferences. The authors also im- 
plement several known methods and compare their performance with that of their 
own algorithm. An indirect conclusion from this work is that an algorithm requires 
semantic knowledge in order to hope for a success rate higher than 75%. 
Soon, Ng, and Lira describe a C5-based learning approach to coreference resolu- 
tion of noun phrases in unrestricted text. The approach learns from a small, annotated 
corpus and tackles pronouns, proper names, and definite descriptions. The coreference 
resolution module is part of a larger coreference resolution system that also includes 
sentence segmentation, tokenization, morphological analysis, part-of-speech tagging, 
noun phrase identification, named entity recognition, and semantic lass determina- 
tion (via WordNet). The evaluation is carried out on the MUC-6 and MUC-7 test 
474 
Mitkov, Boguraev, and Lappin Anaphora Resolution: Introduction 
corpora. The paper reports on experiments aimed at quantifying the contribution of 
each resolution factor and features error analysis. 
Stuckardt's work presents an anaphor esolution algorithm for systems where only 
partial syntactic information is available. Stuckardt applies Government and Bind- 
ing Theory principles A, B, and C to the task of coreference resolution on partially 
parsed texts. He also argues that evaluation of anaphora resolution systems hould 
take into account several factors beyond simple accuracy of resolution. In particular, 
both developer-oriented (e.g., related to the selection of optimal resolution factors) 
and application-oriented (e.g., related to the requirement of the application, as in the 
case of information extraction, where a proper name antecedent is needed) evaluation 
metrics should be considered. 
Tetreault's contribution features comparative valuation involving the author's 
own centering-based pronoun resolution algorithm called the Left-Right Centering 
algorithm (LRC) as well as three other pronoun resolution methods: Hobbs's naive 
algorithm (Hobbs 1978), BFP (Brennan, Friedman, and Pollard 1987), and Strube's S- 
list approach (Strube 1998). The LRC is an alternative to the original BFP algorithm in 
that it processes utterances incrementally. It works by first searching for an antecedent 
in the current sentence; if none can be found, it continues the search on the Cf-list of 
the previous and the other preceding utterances in a left-to-right fashion. 
In her squib, Byron maintains that additional kinds of information should be 
included in an evaluation in order to make the performance of algorithms on pronoun 
resolution more transparent. In particular, she suggests that the pronoun coverage be 
explicitly reported and proposes that the evaluation details be presented in a concise 
and compact tabular format called standard isclosure. Byron also proposes ameasure, 
the resolution rate, which is computed as the number of pronouns resolved correctly 
divided by the number of (only) referential pronouns. 
Finally, in his squib Kibble discusses a reformulation of the centering transitions 
(Continue, Retain, and Shift), which specify the center movement across sentences. 
Instead of defining a total preference ordering, Kibble argues that a partial ordering 
emerges from the interaction among cohesion (maintaining the same center), salience 
(realizing the center as subject), and cheapness (realizing the anticipated center of a 
following utterance as subject). 
The last years have seen considerable advances in the field of anaphora resolution, 
but a number of outstanding issues either remain unsolved or need more attention 
and, as a consequence, represent major challenges to the further development of the 
field (Mitkov 2001a). A fundamental question that needs further investigation is how 
far the performance of anaphora resolution algorithms can go and what the limitations 
of knowledge-poor methods are. In particular, more research should be carried out on 
the factors influencing the performance of these algorithms. One of the impediments 
to the evaluation or fuller utilization of machine learning techniques is the lack of 
widely available corpora annotated for anaphoric or coreferential links. More work 
toward the proposal of consistent and comprehensive evaluation is necessary; so too 
is work in multilingual contexts. Some of these challenges have been addressed in the 
papers published in this issue, but ongoing research will continue to address them in 
the near future. 
References 
Abra~os, Jose and Jos6 Lopes. 1994. 
Extending DRT with a focusing 
mechanism for pronominal anaphora nd 
ellipsis resolution. In Proceedings ofthe 15th 
International Conference on Computational 
Linguistics (COLING'94), pages 1128-1132, 
Kyoto, Japan. 
Aone, Chinatsu and Scott Bennett. 1995. 
Evaluating automated and manual 
475 
Computational Linguistics Volume 27, Number 4 
acquisition of anaphora resolution 
strategies. In Proceedings ofthe 33rd Annual 
Meeting of the Association for Computational 
Linguistics (ACU95), pages 122-129, Las 
Cruces, NM. 
Aone, Chinatsu and Douglas McKee. 1993. 
A language-independent anaphora 
resolution system for understanding 
multilingual texts. In Proceedings ofthe 31st 
Annual Meeting of the Association for 
Computational Linguistics (ACU93), 
pages 156-163, Columbus, OH. 
Azzam, Saliha, Kevin Humphreys, and 
Robert Gaizauskas. 1998. Coreference 
resolution in a multilingual information 
extraction. In Proceedings ofa Workshop on 
Linguistic Coreference, Granada, Spain. 
Baldwin, Breck. 1997. CogNIAC: High 
precision coreference with limited 
knowledge and linguistic resources. In 
Proceedings ofthe ACU97/EACU97 
Workshop on Operational Factors in Practical, 
Robust Anaphora Resolution for Unrestricted 
Texts, pages 38-45, Madrid, Spain. 
Baldwin, Breck, Jeff Reynar, Mike Collins, 
Jason Eisner, Adwait Ratnaparki, Joseph 
Rosenzweig, Anoop Sarkar, and Srivinas 
Bangalore. 1995. Description of the 
University of Pennsylvania system used 
for MUC-6. In Proceedings ofthe Sixth 
Message Understanding Conference 
(MUC-6), pages 177-191, Columbia, MD. 
Brennan, Susan, Marilyn Friedman, and 
Carl Pollard. 1987. A centering approach 
to pronouns. In Proceedings ofthe 25th 
Annual Meeting of the Association for 
Computational Linguistics (ACU87), 
pages 155-162, Stanford, CA. 
Carbonell, Jaime and Ralf Brown. 1988. 
Anaphora resolution: A multi-strategy 
approach. In Proceedings ofthe 12th 
International Conference on Computational 
Linguistics (COLING'88), volume 1, 
pages 96-101, Budapest, 
Hungary. 
Cardie, Claire and Kiri Wagstaff. 1999. 
Noun phrase coreference asclustering. In 
Proceedings ofthe 1999 Joint SIGDAT 
Conference on Empirical Methods in Natural 
Language Processing and Very Large Corpora, 
pages 82-89, College Park, MD. 
Carter, David M. 1987. Interpreting Anaphors 
in Natural Language Texts. Ellis Horwood, 
Chichester, UK. 
Dagan, Ido and Alon Itai. 1990. Automatic 
processing of large corpora for the 
resolution of anaphora references. In
Proceedings ofthe 13th International 
Conference on Computational Linguistics 
(COLING'90), volume 3, pages 1-3, 
Helsinki, Finland. 
Dagan, Ido and Alon Itai. 1991. A statistical 
filter for resolving pronoun references. In
Yishai A. Feldman and Alfred Bruckstein, 
editors, Artifi'cial Intelligence and Computer 
Vision. Elsevier Science Publishers B.V. 
(North-Holland), Amsterdam, pages 
125-135. 
Gaizauskas, Robert and Kevin Humphreys. 
1996. Quantitative evaluation of 
coreference algorithms in an information 
extraction system. Presented at Discourse 
Anaphora nd Anaphor Resolution 
Colloquium (DAARC-1), Lancaster, UK. 
Reprinted in Simon Botley and Tony 
McEnery, editors, Corpus-Based and 
Computational Approaches to Discourse 
Anaphora. John Benjamins, Amsterdam, 
2000, pages 143-167. 
Ge, Niyu, John Hale, and Eugene Charniak. 
1998. A statistical approach to anaphora 
resolution. In Proceedings ofthe Sixth 
Workshop on Very Large Corpora, 
pages 161-170, Montreal, Canada. 
Hahn, Udo and Michael Strube. 1997. 
Centering-in-the-large: Computing 
referential discourse segments. In 
Proceedings ofthe 35th Annual Meeting of the 
Association for Computational Linguistics 
(ACU97/EACU97), pages 104-111, 
Madrid, Spain. 
Harabagiu, Sanda and Steven Maiorano. 
2000. Multilingual coreference r solution. 
In Proceedings ofConference on Applied 
Natural Language Processing~North American 
Chapter of the Association for Computational 
Linguistics (ANLP-NAACL2000), pages 
142-149, Seattle, WA. 
Hobbs, Jerry. 1978. Resolving pronoun 
references. Lingua, 44:311-338. 
Kameyama, Megumi. 1997. Recognizing 
referential links: An information 
extraction perspective. In Proceedings ofthe 
ACU97/EACL'97 Workshop on Operational 
Factors in Practical, Robust Anaphora 
Resolution for Unrestricted Texts, 
pages 46-53, Madrid, Spain. 
Kehler, Andrew. 1997. Probabilistic 
coreference in information extraction. In 
Proceedings ofthe 2nd Conference on 
Empirical Methods in Natural Language 
Processing (EMNLP-2), pages 163-173, 
Providence, RI. 
Kennedy, Christopher and Branimir 
Boguraev. 1996. Anaphora for everyone: 
Pronominal anaphora resolution without 
a parser. In Proceedings ofthe 16th 
International Conference on Computational 
Linguistics (COLING'96), pages 113-118, 
Copenhagen, Denmark. 
Lappin, Shalom and Herbert Leass. 1994. 
An algorithm for pronominal anaphora 
476 
Mitkov, Boguraev, and Lappin Anaphora Resolution: Introduction 
resolution. Computational Linguistics, 
20(4):535-561. 
Mitkov, Ruslan. 1996. Pronoun resolution: 
The practical alternative. Presented at the 
Discourse Anaphora nd Anaphor 
Resolution Colloquium (DAARC-1), 
Lancaster, UK. Reprinted in Simon Botley 
and Tony McEnery, editors, Corpus-Based 
and Computational Approaches to Discourse 
Anaphora. John Benjamins, Amsterdam, 
2000, 189-212. 
Mitkov, Ruslan. 1998a. Evaluating anaphora 
resolution approaches. In Proceedings ofthe 
Discourse Anaphora nd Anaphora Resolution 
Colloquium (DAARC-2), Lancaster, UK. 
Mitkov, Ruslan. 1998b. Robust pronoun 
resolution with limited knowledge. In 
Proceedings ofthe 36th Annual Meeting of the 
Association for Computational Linguistics and 
the 17th International Conference on 
Computational Linguistics 
(COLING'98/ACU98), pages 869-875, 
Montreal, Canada. 
Mitkov, Ruslan. 1999. Multilingual anaphora 
resolution. Machine Translation, 
14(3-4):281-299. 
Mitkov, Ruslan. 2001a. Outstanding issues 
in anaphora resolution. In Alexander 
Gelbukh, editor, Computational Linguistics 
and Intelligent Text Processing. Springer, 
Berlin, pages 110-125. 
Mitkov, Ruslan. 2001b. Towards a more 
consistent and comprehensive evaluation 
of anaphora resolution algorithms and 
systems. Applied Artificial Intelligence: An 
International Journal, 15:253-276. 
Mitkov, Ruslan. Forthcoming. Anaphora 
Resolution. Longman, Harlow, UK. 
Mitkov, Ruslan, Lamia Belguith, and 
Malgorzata Stys. 1998. Multilingual robust 
anaphora resolution. In Proceedings ofthe 
Third International Conference on Empirical 
Methods in Natural Language Processing 
(EMNLP-3), pages 7-16, Granada, Spain. 
Mitkov, Ruslan and Malgorzata Stys. 1997. 
Robust reference resolution with limited 
knowledge: High precision genre-specific 
approach for English and Polish. In 
Proceedings ofthe International Conference on 
Recent Advances in Natural Language 
Processing (RANLP'97), pages 74-81, 
Tzigov Chark, Bulgaria. 
Mitkov, Ruslan and Catalina Barbu. 2000. 
Improving pronoun resolution in two 
languages by means of bilingual corpora. 
In Proceedings ofthe Discourse, Anaphora nd 
Reference Resolution Conference (DAARC 
2000), pages 133-137, Lancaster, UK. 
Nasukawa, Tetsuya. 1994. Robust method of 
pronoun resolution using full-text 
information. In Proceedings ofthe 15th 
International Conference on Computational 
Linguistics (COLING'94), pages 1157-1163, 
Kyoto, Japan. 
Or~san, Constantin, Richard Evans, and 
Ruslan Mitkov. 2000. Enhancing 
preference-based anaphora resolution 
with genetic algorithms. In Proceedings of
NLP-2000, pages 185-195, Patras, Greece. 
Rich, Elaine and Susann LuperFoy. 1988. An 
architecture for anaphora resolution. In 
Proceedings ofthe Second Conference on 
Applied Natural Language Processing 
(ANLP-2), pages 18-24, Austin, TX. 
Sidner, Candace. 1979. Toward a 
computational theory of definite anaphora 
comprehension in English. Technical 
Report AI-TR-537, MIT, Cambridge, MA. 
Strube, Michael. 1998. Never look back: An 
alternative to centering. In Proceedings of
the 36th Annual Meeting of the Association for 
Computational Linguistics and the 17th 
International Conference on Computational 
Linguistics (COLING'98/ACL'98), 
pages 1251-1257, Montreal, Canada. 
Strube, Michael and Udo Hahn. 1996. 
Functional centering. In Proceedings ofthe 
34th Annual Meeting of the Association for 
Computational Linguistics (ACL'96), 
pages 270-277, Santa Cruz, CA. 
Tetreault, Joel. 1999. Analysis of 
syntax-based pronoun resolution 
methods. In Proceedings ofthe 37th Annual 
Meeting of the Association for Computational 
Linguistics (ACL'99), pages 602-605, 
College Park, MD. 
Williams, Sandra, Mark Harvey, and Keith 
Preston. 1996. Rule-based reference 
resolution for unrestricted text using 
part-of-speech tagging and noun phrase 
parsing. In Proceedings ofthe Discourse 
Anaphora nd Anaphora Resolution 
Colloquium (DAARC-1), pages 441-456, 
Lancaster, UK. 
477 

Multi-document Summarization by Visualizing Topical Content 
Rie Kubota Ando 
Department of Computer Science, Cornell University, Ithaca, NY 14853-7501 
kubotar@cs, cornell, edu 
Branimir K. Boguraev, Roy J. Byrd, Mary  S. Neff  
IBM T.J. Watson Research Center, 30 Saw Mill River Road, Hawthorne, NY 10532 
{bkb, byrd, neff}@watson.ibm.com 
Abstract  
This paper describes a framework for multi- 
document summarization which combines three 
premises: coherent themes can be identified reli- 
ably; highly representative themes, running across 
subsets of the document collection, can function as 
multi-document summary surrogates; and effective 
end-use of such themes hould be facilitated by a vi- 
sualization environment which clarifies the relation- 
ship between themes and documents. We present al- 
gorithms that formalize our framework, describe an 
implementation, and demonstrate a prototype sys- 
tem and interface. 
1 Introduction: multi-document 
summarization as an enabling 
technology for IR  
The rapid growth of electronic documents has 
created a great demand for a navigation tool to 
traverse a large corpus. Information retrieval 
(IR) technologies allow us to access the docu- 
ments presumably matching our interests. How- 
ever, a traditional hit list-based architecture, which 
returns linearly organized single document sum- 
maries, no longer suffices, given the size of a typ- 
ical hit list (e.g. submitting the query "summa- 
rization workshop" to a search engine Altavista 
(h t tp  : / /a l tav is ta .  corn) gave us more than 
ten million hits). 
To allow a more comprehensive and screen space- 
efficient presentation of query results, we propose 
in this paper a technology for summarizing collec- 
tions of multiple documents. In our work, we fo- 
cus on identifying themes, representative of a docu- 
ment, and possibly running across documents. Even 
if we are unable to 'embody' atheme in coherently 
generated prose, we start with the assumption that a 
mapping exists between a theme and a tightly con- 
nected (and therefore intuitively interpretable) set 
of coherent linguistic objects, which would act as 
a 'prompting' device when presented to the user in 
an appropriate context. As will become clear in the 
rest of the paper, we refer to such themes astopics. 
Our view of multi-document summarization 
combines three premises: coherent opics can be 
identified reliably; highly representative topics, run- 
ning across ubsets of the document collection, can 
function as multi-document summary surrogates; 
and effective nd-use of such topics hould be facil- 
itated by a visualization environment which clarifies 
the relationship between topics and documents. The 
work specifically addresses the following consider- 
ations. 
? Multiple general topics We regard the ability 
to respond to multiple topics in a document collec- 
tion - -  in contrast o a prevailing trend in multi- 
document summarization, seeking to present he 
single, possibly pre-determined, topic (see below) 
to be crucial to applications such as summariza- 
tion of query results. In this work we choose not 
to narrow the topic detection process by the given 
query, since in IR it is a well-known concern that 
user-sPecified queries do not necessarily convey the 
user's real interests thoroughly. Thus, we need to 
deal with multiple general topics. 
? Textual and graphical presentation Since 
our multi-document summaries will, by definition, 
incorporate multiple topics, the question arises of 
optimal representation f the relationships among 
the topics, the linguistic objects comprising each 
topic, and the documents associated with (possibly 
more than one) topic. In particular, for IR, we 
want to show the relationships between topics and 
documents o that a user can access documents 
in the context of the topics. A topic by itself 
can clearly be represented largely by a set of text 
objects. However, we need also to present arbitrary 
number of such topics as part of the same summary. 
We believe that, for adequate representation of 
79 
the resulting many-to-many relationships (which 
is crucial for the end-user fully understanding the 
summary), additional graphical components are 
needed in the interface. 
To our knowledge, the existing studies of multi- 
document summarization do not place emphasis on 
these considerations. Radev and McKeown (1998) 
have shown a methodology for 'briefing' news 
articles reporting the same event. Barzilay et al 
(1999) have proposed a method for summarizing 
"news articles presenting different descriptions o f  
the same event". These studies focus on a single 
topic in a document collection. Mani and Bloedom 
(1999) have addressed summarizing of similarities, 
and differences among related documents with 
respect o a specified query or profile. In their 
study, several presentation strategies are suggested. 
Although they mention a graphical strategy, such 
as plotting documents haring more terms closer 
together, no implementation is reported. 
There are a number of different studies that ad- 
dress graphical presentation of multi-document (or 
document corpus visualization) - The VIBE Sys- 
tem (Olsen et al, 1993; Korfhage and Olsen, 1995), 
Galaxy (Rennison, 1994), SPIRE Themescapes 
(Wise et al, 1995), LyberWodd (Hemmje et al, 
1994), and applications of self-organizing map uti- 
lizing neural network technique (Kohonen, 1997; 
Lin, 1993; Lagus et al, 1996). In general, these 
studies consider documents as objects in a model 
space (document space, typically high-dimensional) 
? and provide 2-D or 3-D representation f this docu- 
ment space. Their focus is on detecting and present- 
ing structural relationships among documents in a 
corpus. 
" From our viewpoint, these two fields of research 
address two different perspectives on the multi- 
document analysis problem: multi-document sum- 
marization efforts largely deliver their results in tex- 
tual form, while document corpus visualization re- 
search, which focuses on means for graphical rep- 
resentation of a document space, does not perform 
any Summarization work. While we believe that 
both textual and graphical representations are essen- 
tial in the context of IR, the technologies from the 
two fields, in general, cannot be easily combined 
because of methodological differences ( uch as dif- 
ferences in modeling 1he document set, calculating 
similarity measures, and choosing linguistic objects 
in terms of which a summary would be constructed). 
Motivated by these observations, we propose one 
uniform framework that provides both textual and 
graphical representations of a document collection. 
In this framework, topics underlying a document 
collection are identified, and described by means of 
linguistic objects in the collection. Relationships, 
typically many-to-many, among documents and top- 
ics are graphically presented, together with the topic 
descriptions, by means of a graphical user interface 
specifically designed for this purpose. We focus on 
relatively small document collections (e.g. 100 or 
so top-ranked ocuments), observing that in a real- 
istic environment users will not look much beyond 
such a cut-off point. Our approach maps linguistic 
oSjects onto a multi-dimensional space (called se- 
mantic space). As we will see below, the mapping 
is defined in a way that allows for topics with cer- 
tain properties to be derived and for linguistic ob- 
jects at any granularity to be compared as semantic 
concepts. 
The rest of this paper is organized as follows. The 
next section describes the multi-dimensional space 
for the document collection. Section 3 demonstrates 
our prototype system and illustrates the interplay 
between textual and graphical aspects of the multi- 
document summary. Section 4 highlights the im- 
plementation f the prototype system. We will con- 
clude in Section 5. 
2 Mapping a document collection into 
semantic space 
Semantic space is derived on the basis of analyz- 
ing relationships among linguistic objects - -  such 
as terms, sentences, and documents - - in the entire 
collection. A term can be simply a 'content word', 
in the traditional IR sense, or it can also be con- 
strued as a phrasal unit, further epresentative of a 
concept in the document domain. In our implemen- 
tation, we do, in fact, take that broader definition 
of terms, to incorporate all types of non-stoplexi- 
cal items as well as phrasal units such as named en- 
tities, technical terminology, and other multi-word 
constructions (see Section 4 below). 
.We map linguistic objects (such as terms, sen- 
tences, and documents) to vectors in a multi- 
dimensional space. We construct this space so that 
the vectors for the objects behaving statistically 
similarly (and therefore presumed to be semanti- 
cally similar) point in similar directions. The vec- 
tors are called document vectors, sentence vectors, 
and term vectors, according to the original inguistic 
80 
I 
i 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
i 
i 
I 
I 
i 
i 
I 
i 
I 
i 
! 
I 
! 
I 
objects they are derived from; however, all vectors 
hold the same status in the sense that they repre- 
sent some concepts. In this work, we call this multi- 
dimensional space semantic space (Ando, 2000) to 
distinguish it from a traditional vector space (Salton 
and McGill, 1983). In essence, in our semantic 
space, the terms related to each other are mapped 
to the vectors having similar directions, while a tra- 
ditional vector space model treats all terms as inde- 
pendent from each other. 
Our motivation for using semantic space is at 
least twofold. First, we believe that we need the 
high representational power of a multi-dimensional 
space since natural anguage objects are intrinsi- 
cally complicated, as Deerwester et al (1990) ar- 
gued. Secondly, our definition of semantic space 
allows us to measure similarities among concepts 
and linguistic units at any granularity. Single-word 
terms, multi-word terms, sentences, .and topics- all 
can be equally treated as objects representing some 
concept(s) when they are mapped to vectors in this 
space. From the viewpoint of a summarization task, 
this is an advantage over a traditional vector space 
in which terms are assumed to be independent of 
one another. 
To detect opics underlying the document collec- 
tion, we create aset of vectors in the semantic space 
so that every document vector is represented by (or 
close to) at least one vector (called topic vector). 
.In other words, we provide viewpoints in the se- 
imantic space so that every document can be viewed 
: somewhat closely from some viewpoint. Given such 
. vector epresentations for topics, we can quantita- 
tively measure the degree of associations between 
? topics and linguistic objects by using a standard co- 
sine similarity measure between topic vectors and 
linguistic object vectors. The linguistic objects with 
the.strongest association would represent the topic 
most appropriately. 
The algorithm we use for semantic space con- 
struction (see Figure 5 in Section 4) is closely re- 
lated to singular value decomposition (SVD) used in 
Latent Semantic Indexing (LSI) (Deerwester tal., 
1990). As in SVD, this algorithm finds statistical re- 
lationships between documents and terms by com- 
puting eigenvectors, and it performs dimensional re- 
duction that results in a better statistical modeling. 
The advantages of the semantic space we described 
above are shared with similar approaches ( uch as 
SVD-based and Riemarmian SVD-based (Jiang and 
Berry, 1998)). The algorithm we adopt, however, 
differs from others in that it achieves a high preci- 
sion of similarity measurement among all the doc- 
uments by capturing information more evenly from 
every document while, with other approaches, the 
documents whose statistical behaviors are different 
from the others tend to be less well represented. 
This algorithm fits well in our framework since we 
want to find topics by referring the similarities of 
all pairs of documents ( hown later), and also we 
want to assume all the documents are equal. Full 
details of the semantic space construction algorithm 
may be found in (Ando, 2000), including evaluation 
results compared with SVD. 
3 ,Visual presentation of a semantic space: 
combining text and graphics 
In this section, to illustrate how we combine tex- 
tual and graphical presentation, we demonstrate a 
summary that our prototype system created from 
50 documents (TREC documents relevant to 'non- 
proliferation treaty'). 
The document set is presented in one full screen 
in relation to the underlying topics. The prototype 
system detected six i topics in this document set (see 
Figure 1). For each topic, three types of information 
are presented: a list of terms (topic terms), a list of 
sentences (topic sentences), and a visual represen- 
tation of relevance of each document to the topic 
(document map). 
Below we highlight some essential features of the 
interface. 
Topic terms and topic sentences: The topic pre- 
sented at the upper right comer of Figure I has 
the topic terms "Iraq", "Iraqi", "Kuwait", "Saddam 
Hussein", "embargo", invasion", "disarm", and so 
on. (The frame is scrollable, thus accommodating 
all topic terms.) A topic typically will be addressed 
by more than one sentence, presented in a closely 
associated scrollable frame. The first topic sentence 
for this topic is "israel's Air Force bombed Iraq's 
Osirak ...". Together, the Sets of topic terms and sen- 
tences describe the topic, i.e. one 'thread' discussed 
in possibly several documents. 
Document proxy - a "'dot" represents a docu- 
ment: In a document map, a dot image represents 
each document (i.e. document proxy). A dot before 
a topic sentence isalso a document proxy represent- 
ing the document containing that sentence. 
i The number of topics detected epends on the document 
set and the parameter setting adjusting the granularity. 
81 
Document  map Top ic  te rms Top ic  sentences  
~ ~ +  + \]\]\]+ V ,  ,++~.++ , .................... 
.~.aW., ~e~o pn, nut!era', nuclear wean on..~ssi!e.  So~.e~..~. .  ~ ........ ~ ~aq.. I ra~!~..K~t, . .S addam Huss e i~. .emb~p, .~y~. .~:  
.They exchanged ratiSeafion protocols for ~-  
the Interme<~ate-P..m~e Nucle~ Forces -i.~ 
~r e aty 01q1~ o e.~mhm~e m  <~m~-range |L~.o~ 1 
nuclear n~e, ,  which was ~ned ~t the !ii' '4m .~:  ,3o o 
W ~ n  smm~it last December and ~ .... | " 
ratified by the Senate last Friday and by the :~:,~:. 
Soviet asmnbly ofpresidants 17 hours ~'~' 
~ ~id. cartUicatlon, carfiC'v. John Kelly..suspension. Stenhen 
~.-~ 
-T,eonard Spector. Im expert on the spread +~ 
o+..++.+,.+.+++, o+ evidence leaves little doubt" that Pakistan is . 
indeed developing nuclear anna+ i~ 4 m ~g | 
,The continumgreview of Pakistan's nucleas " ~, + 
prog~ is pm of such concern. ~e~ s,~d, :~:,.. " 
citing a U.S. law, the Pressler amendmant, :~t 
.headwater  nu?learreactOr. Norway, ~ase \ ] ,  Svfitzerlan d ~'~d~a, ton, . . . .~ . ' l~nspo~al  
? Norway does not allow the export of 
heavy water to countries that have not : I  J 
s~ned the international nuclear i 
oo non-prol~'era~on agseement, includ~ns~cKa. ~ : @s g gg 
? Heavy water, or deuler/mu o~de. i. . . .  d ~ ~! 
as a coolaat in some nucle~ reactors, but ~t +' 
ca:) also be used to produce platonhnn for __.~ 
use in nuckas ~m'm. .:~:I~, 
? Israel's Air Force bombed Iraq's Ofirak 
nuclear reactor in 1981 while Iraq was at 
war with Iran, ~ me facility was being 
8go. ,  . g\] ~1~ used to develop aton~c weapons. 
? Some analysts in I.~rael. wl~ch closely 
tracks \]raq's arm5 progrmn, he~mse :~ .i 
, Baghdad could be two to five year~ away 
South Afi3ca. Mrir an. mspec~on, L'~tarnat/ona\] Atonue Ene~ .a~encv. 
? In the past. South Africa has refizsed to ~ 
the 1969~uclearl'~on-ProSferationTreaty i~ 
a~d to submit an its rmcle ar fac/lities to i~ 
o~ I| * "I mlb inspectlonby~eVienna-basedlateraatlonal 
Atomic Ener~ Asency. ~+ \]: 
-Under the Treaty on ill= Non-Pro~fuation ~ ,, 
of Nuclear Weapons. which has been s/~ned i~ '+~ 
? ! ~rtalaon ~ m  eo~ensate ,  reprocess nuclear fuel l~ant ~ | 
1 ~ DIMEIqS'IOH 2
"=41, 
-A federal appeals cotu't in Washington, ~ 
ca~-~ the plant "one of  the most remmicabk t white elephants" in the nation's 1'~tory. t~d in l:ebruary that plant owner AlSed-(3eneral l~'uclenr Services is not entitled to compensation, +" i
? The plant was deraed a 5cense ;,, 1977 ~'.i I 
when former Prcfident Y:mmy Carter .... 
Figure 1: Example of the final output. 
Document maps - topic-document relevance 
shown by document proxy placement and color gra- 
dation: In a document map, the horizontal place- 
ment of each dot represents the degree of relevance 
of the corresponding document o the topic. Docu- 
ments closer to the direction of the arrow are more 
r~levant o the topic. The color intensity of the 
dot also represents the degree of relevance. For 
instance, in the document map at the upper right 
comer of Figure 1, we see that there are six doc- 
uments closely related to this 'Iraq-topic'. These 
flx dots are placed on the right (the direction of the 
? arrow), and their colors are more intense than the 
other document proxies. We see one more docu- 
ment to the left to the six documents, also with a 
relatively strong connection to this topic. Two doc- 
uments, represented by dots almost at the center of 
the map, are only somewhat related to this topic. 
The rest of the documents, having dots that are al- 
most transparent and placed on the left, are not very 
related to this topic. Thus, users can tell, at a glance, 
how many documents are related to each topic and 
how strongly they are related. Note that each doc- 
ument map contains proxies for all the documents. 
Unlike a typical clustering approach, we do not di- 
vide documents into groups. Clusters of documents, 
if any, are naturally observed in the document map. 
A document map is a projection of document vec- 
tors onto a topic vector. The semantic space allows 
us to detect and straightforwardly present he struc- 
tural relationships among the documents. 
Highlighting of document proxies - the rela- 
tionships between a document and multiple topics: 
When a mouse rolls over a dot, the title Of the doc- 
ument appears, and the color of the dots repreSent- 
ing the same document in all the document maps 
changes. (from blue to red) (see Figure 2). This 
color change facilitates understanding the relation- 
ships between a document and multiple topics. 
A hot-link from a document proxy to full text:. 
82 
I 
,I 
I 
l 
i 
I 
I 
I 
i 
i 
I 
i 
I 
i 
I 
i 
i 
I 
I 
I 
I 
I 
I 
I 
I 
i 
! 
! 
! 
I 
I 
I 
i 
I 
i 
I 
I 
I 
When a mouse comes up, and all the proxies for the document a r e ~  
*They exchanged ratification protocols for 
the Intermed~e-Range lquclear Forces 
treaty ~ to e~minate med~n-racge 
nuclear missiles, w~ch was signed at the 
Washington sunm~ last December ~md 
ratified by the Senate last Friday a~d by the 
Soviet ass~nbly ofpresldents 17 hours 
i| .Israel's Ak Force bombed Iraq's Os~rak 
i\] nuclear reactor in 1981 while Iraqwas et 
i| war with Iran, daimi~ the faci~ty was being 
..... ~ i~ l  ~.. . . . .  ' .~ ' ~ " .  ~ ~  ?~;e ly  B~ Cha~e~ ~ m elm to ~ l~le~x De~ces tol~q\[ 
il B~hdad codd be two to five ye~'s away 
.Leonard Spectar, ~m e:cpe~ on the spread 
of nuclear weapons, has stud ~available 
evidence l aves little dox~bt" that ~akistan is
indeed eveloping m~le~ arms. 
? The continuing review of Pakistan's n~clear 
prosrazn ispart of such concern, Kegy said. 
ching a U.S. law. the Presslar amendment, 
,.~Torway does not allow the export of 
heavy water to counhies that have not 
~ned the international nuclear 
non-proliferation agreeme~, including Indi& 
? Heavy water, or deuterium o:~de, is used 
as a coolant in some nuclear reactors, but it 
can ako be nsed to prodUCe p luto~n f~r 
use in nuclear ~ms. 
4- :  
t 
? In the past, South Afiica has refused to sign 
the 1969 lq'uclear l~'on-Proliferation Treaty 
and to subn'~t all its nuclem" fac ies  tO i~ 
inspection by the Vienna-based International ~ 
Atomic Ex~gy Agency. r,~*: 
? Under the Treaty on the Non-Proliferation ~ 
of Nuclear We~ons.  which has been ~cd '~ 
i| oA t'ed~al appeals court in Wastan~on. 
i| c~the  p~ "one of the most ,~ le  
i| white elephants" m the ~on's  history, ruled 
? ? ~ i| i~Februa~plaut?wn~'tnd/ied"C~meral 
i| N=~ar s .~e,  '.,,) ~d to 
i| compensattm~ 
\] ,The plant was denied a fleece in 1977 
_ .  == . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  r \ ]  when former ~'esideutYunmyCm'ter 
Figure 2: When a mouse rolls over a dot: 
When a dot is clicked, the full text of the corre- 
sponding document is displayed in a separate win- 
dow. This allows us to browse documents in the 
context of  document-topic relationships. 
Highlighting a topic sentence in the full text: 
When the clicked dot is associated with a topic sen- 
tence, the full text is displayed in a separate window, 
with the topic sentence highlighted. This highlight- 
ing helps the user to understand the context of  the 
sentence quickly, and thus further facilitates focus- 
ing on the information of particular interest. 
Topic sentences: Finally, we illustrate some of 
the~topic sentences extracted by our system below. 
For each topic, the two sentences related to the 
topic most closely are shown. 
' l raq-topic ' :  
? Israel's Air Force bombed Iraq "s Osirak nuclear eac- 
tor in 1981 while Iraq was at war with lran, claiming 
the facility was being used to develop atomic weapons. 
? Some analysts in Israel, which closely tracks Iraq's 
arms program, believe Baghdad could be two to five 
years away from producing its own atomic warheads for 
missiles or nuclear bombs to be dropped from jets. 
'Pakistan-topic ' :  
? Leonard Spector, an expert on the spread of  nuclear 
weapons, has said "available evidence leaves little 
doubt" that Pakistan is indeed eveloping nuclear arms. 
? The continuing review of Pakistan "s nuclear program 
is part of such concern, Kelly said, citing a U.S. law, 
the Pressler amendment, requiring the president to 
certify annually that Pakistan does not possess anuclear 
weapon. 
' South Afr ica-topic ' :  
? In the past, South Africa has refused to sign the 1969 
Nuclear Non-Proliferation Treaty and to submit all its 
nuclear facih'ties to inspection by the Henna-based 
lnternational Atomic Energy Agency. 
? Under the Treaty on the Non-Proliferation of Nuclear 
83 
-"-?-'+?-"-- P l ....... I i cread?n i I ...... l 
_~ map '~1  ,+++me+ fl 1 " i :~.,t,o. i P'?P" II 
'\] creation 1 \[ . . . . . . . . .  2 
I 
I 
I 
I 
I 
I 
/ 
Figure 3: Overview of the process. 
A block arrow indicates the input to the process, and rectangles with double-line border are the output. Rectangles 
with dashed line border are sub-processes. Other ectangles represent data. 
Weapons, which has been signed by 137 governments 
since its preparation in 1969, countries without such 
weapons open their nuclear facilities to inspection by 
experts from the International Atomic Energy Agency, a 
U.N. agency based in Henna. 
Both for 'lraq-' and "Pakistan-topic', the two 
topic sentences address two different aspects of the 
similar "doubt" or "concern". For 'South Africa- 
topic', the second topic sentence gives background 
knowledge of the specific fact described in the 
first topic sentence. We find it interesting that, 
despite the fact that the two topic sentences are 
extracted from different documents, they appear to 
be consecutive s quences from a uniform source. 
In essence, the design seeks to facilitate quick ap- 
preciation of the contents of a document space by 
supporting browsing through adocument collection 
With easily switching between different views: topic 
highlights (terms), topical sentences, full document 
text, and inter-document relationships. At present, 
there is no attempt to handle redundancy between 
topic sentences. 
4 Implementation 
In this section, we describe the implementation f 
our prototype system. The overall process flow of 
this system is shown in Figure 3. Our description 
omits the process Of creating raphical presentation 
that is straightforwardly understood from Section 
3. The system takes, as its input, the text of a given 
set of documents. Throughout this section, we use 
the three small 'documents' hown below as an 
illustrative xample. The data flow from these three 
documents othe final output is shown in Figure 4. 
Document # 1: 
Mary Jones has a little lamb. The lamb is her good buddy. 
Document #2: 
Mary Jones is a veterinarian for ABC University. 
ABC University has many lambs. 
Document #3: 
Mike Smith is a programmer for XYZ Corporation. 
4.1 Term extraction 
First, we extract all terms contained in the docu- 
ments, using an infrastructure for document pro- 
cessing and analysis, comprising a number of in- 
terconnected, and mutually enabling, linguistic fil- 
ters; which operates without any reference to a pre- 
defined domain. The whole infrastructure (here- 
after eferred to as  TEXTRACT)  is designed from the 
ground up to perform avariety of linguistic feature 
extraction functions, ranging from straightforward, 
single pass, tokenization, lexical ook-up and mor- 
phological analysis, to complex aggregation f rep- 
resentative (salient) phrasal units across large multi- 
document collections (Boguraev and Neff, 2000). 
TEXTRACT combines functions for linguistic analy- 
sis, filtering, and normalization; these focus on mor- 
phological processing, named entity identification, 
technical terminology extraction, and other multi- 
word phrasal analysis; and are further enhanced by 
cross-document aggregation, resulting in some nor- 
I 
i 
a 
i 
i 
I 
i 
i 
i 
i 
I 
I 
84 I 
document ext 
# 1 : Mary Jones has a little lamb. ( s l )  
The lamb is her good buddy. (s2) 
#2: Mary Jones is a veterinarian for ABC University. (s3) 
ABC University has many lambs. (s4) 
#3: Mike Smith is a programmer for XYZ corporation. (sS) 
term.document vectors 
#1 #2 
Mary Jones I ! 
little I 0 
? 
conversion matriz 
(Wansposed) 
0.45 0 0 
0.22 0 0.35 
Terms 
"Mary Jones", "little", "lamb", "good 
buddy", "veterinarian", "ABC University", 
"Mike Smith", "programmer", 
"XYZ Corporation" 
I 1  
term-sentence vectors 
sl s2 s3 
Ma W Jones I 0 1 
little I 0 0 
lamb 1 1 0 
.94 s 
0 
0 
I lamb 2 1 0.67 0 0.38 
I good buddy I 0 0.22 0 0.35 good buddy I 0 0 
veterinarian 0 i 0.22 0 -0.35 veterinarian 0 0 I 0 
ABC Univ. 0 2 0.45 0 -0.71 ABC Univ. 0 0 I 1 
Mike Smith 0 0 0 0.58 0 Mike Smith 0 0 0 0 
programmer 0 0 0 0.58 0 programmer 0 0 0 0 
I XYZ corp. 0 0 0 0.58 0 XYZ corp. 0 0 0 0 
! - -  topic vectors term vectors sentence vectors 
terlTI Vectors are ?cum ? Jt 01 #2 \[ #1 #2 column vectors 
0.84 0.84 #03.53 I 0 of the conversion 
0 0 -0.53 0 1 matrix. 
0.53 0.53 0 0 0 
t J l  
term-topic relevance 
little 
lamb 
veterinarian 
ABC Univ. 
Mike Smith 
? sl s2 s3 s4 s5 \[ 
1.34 0.89 1.12 1.12 0 
I 0 01 0 1.74 0.70 0.70 .06 -0.36 0 
document-topic relevance 
e.g. (doc 01, topic #1) 
= \[0.84,0,0.53\] \[i, 0, 0\] T
= 0.84"1+0"0+0.53"0 = 0.84 
OUtpUt lamb, Mary Jones, ABC University 
? Mary Jones has a little 
lamb. 
? Mary Jones is a 
veterinarian for ABC 
University. 
? ABC University has 
many lambs. 
sentence.to )ic relevance 
topic #1 topic #2 
sl 1.34 0 
s2 0.89 0 
s3 1.12 0 
s4 1.12 0 
s5 0 1.74 
e.g. (#1-l,topic #1) 
= \[ 1.34,0, 0.70\] \[1, 0, 0\] T
= 1.34"1+0"0+0.70"0 = 1.34 
Mike Smith, programmer, XYZ corporation 
J 
? Mike Smith b a 
programmer for XYZ 
corporation. 
Figure 4: Example of data flow. 
85  
Procedure ConstructSemanticSpace 
Input: term-document vectors dr, ..., dn 
Output: conversion matrix C 
D = \[dl...dn\]/* Term-document matrix */ 
R = D/* Initialize aresidual matrix with the term-document matrix */ 
For i = 1 to k 
R, = \[It1 Iqrx---Ir,,Iqr,~\]/* Scale each of R's column vectors by a power of its own length */ 
c /=  the eigenvector fR ,  R,  T with the largest eigenvalue 
R = R - \[(eiTrt)el...(ciTrn)ei\]/* Eliminate the direction of el from R's column vectors */ 
End for 
C = \[el...ek\] r / *  Conversion matrix */ 
Figure 5: Semantic space creation. Scaling factor q ahd the dimensionality k are experimentally determined. 
malization to canonical forms, and simple types of 
co-reference r solution. 
For the example mini-documents above, after e- 
moval of common stop words, the terms remaining 
as linguistic objects for the algorithm to operate on 
are listed at top of Figure 4. 
4.2 Vector creation 
We construct the semantic space from term- 
document relationships by a procedure 2 shown in 
Figure 5. In the semantic space, each of vec- 
tor elements represents a linear combination of 
terms. The conversion matrix returned by the 
semantic space creation procedure keeps the in- 
formation of these linear combinations. For in- 
stance, the conversion matrix for our example 
(see Figure 4) shows that the first element of a 
vector in the semantic space is associated with 
0.45,"Mary Jones"+0.22*"iittle"+0.67*"lamb"+0.22,. 
"good buddy"+0.22,"veterinarian"+0.45,"ABC Uni- 
versity". 
To map the documents o the vectors in the se- 
mantic space, we create the term-document vectors 
each of whose elements represents he degree of rel- 
evance of each term to the document. Our imple- 
? mentation uses term frequency as the degree of rel- 
evance. We create document vectors of the seman- 
tic space by multiplying term-document vectors and 
the conversion matrix. Sentences and terms can also 
be mapped to the vectors in the same way by treat- 
ing them as "small documents". 
2We do not describe the details of this procedure in this pa- 
per. See Section 2. 
4.3 Identifying topics 
Ultimately, our multi-document summaries rely 
crucially on identifying topics representing all the 
documents in the set. This is done by creating topic 
vectors o that each document vector is close to (i.e. 
represented by) at least one topic vector. We imple- 
ment this topic vector creation process as follows. 
First, we create a document graph from the docu- 
ment vectors. In the document graph, each node 
represents a document vector, and two nodes have 
an edge between them if and only if the similar- 
ity between the two document vectors is above a 
threshold. Next, we detect he connected compo- 
nents in the document graph, and we create the topic 
vectors from each connected component by apply- 
ing the procedure 'DetectTopic' (Figure 6) recur- 
sively. 
'DetectTopie' works as follows. The unit eigen- 
vector of a covariance matrix of the document vec- 
tors in a set ,.q is computed as v. It is a representa- 
tive direction of  the document vectors in S. I f  the 
similarity between v and any document vector in 
S is below a threshold, then S is divided into two 
sets $1 and ,-q2 (as in Figure 7), and the procedure 
is called for $1 and $2 recursively. Otherwise, v is 
returned as a topic vector. The granularity of topic 
detection can be adjusted by the setting of threshold 
parameters. 
Note that such a topic vector creation procedure 
essentially detects "cluster centroids" of document 
vectors (not sentence vectors), although grouping 
documents into clusters is not our purpose. This 
indicates that general vector-based clustering tech- 
nologies could be integrated into our framework if  
86 
I 
I 
I 
II 
i 
! 
I 
I 
Ii 
I 
I 
I 
I 
!i 
i 
i 
I 
I 
I 
I 
I 
i 
I 
i 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
it brings further improvement. 
4.4 Associations between topics and linguistic 
objects 
The associations between topics and linguistic ob- 
jects (documents, entences, and terms) are. mea- 
sured by computing the cosine (similarity measure- 
ment) between the topic vectors and linguistic ob- 
ject vectors. The degree of association between top- 
ics and documents i  used to create document maps. 
The terms and sentences with the strongest associa- 
tions are chosen to be the topic terms and the topic 
sentences, respectively. 
As a result, for our example we get the output 
shown at the bottom of Figure 4. 
4.5 Computational complexity 
Let m be the number of different erms in the doc- 
ument set (typically around 5000), and let n be the 
number of documents (typically 50 to 100) 3. Given 
that ra 3> n, the semantic space is constructed in
O(mn 2) time. The topic vectors are created in 
O(n 3) time by using a separator t ee for the compu- 
tation of all-pairs minimum cut 4, assuming that the 
document vector set is divided evenly 5. Let k be the 
dimensionality of the semantic space, and let h be 
the number of detected topics. Note that k and h are 
at most n, but are generally much smaller than n in 
practice. Regarding the number of terms contained 
in one sentence as a constant, opic sentences are ex- 
t:racted in O(skh) time where s is the total number 
of sentences in the document set. Topic terms are 
extracted in O(mkh) time. We note that the proto- 
type system runs efficiently enough for an interac- 
tive system. 
"5 Conclusion and further  work  
? This paper proposes a framework for multiple doc- 
umet~t summarization that leverages graphical el- 
ements to present a summary as a 'constellation' 
of topical highlights, tn this framework, we detect 
topics underlying a given documont collection, and 
we describe the topics by extracting related terms 
and sentences from the document text. Relation- 
ships~among topics and documents are graphically 
presented using gradation of color and placement 
of image objects. We illustrate interactions with 
3In this work, we focus on relatively small document col- 
lections; ee Section I.
4See (Ahuja et al, 1993) for all-pairs rain cut problem. 
~Note that Step 3 in the document vector division procedure 
(Figure 7) seeks for this. 
87 
Procedure DetectTopic(S) 
Input: a set of document vectors S 
Output: topic vectors 
v = the unit eigenvector fa covariance matrix of 
document vectors in S 
Loop for each document vector d in S 
if similarity between d and v is below a threshold 
then begin 
divide S into $I and $2 
Call DetectTopic(St) 
Call DetectTopic(S2) ., 
Exit the procedure 
End if 
, End loop 
Return v as a topic vector 
Figure 6: Topic vector creation. 
our prototype system, and describe its implemen- 
tation. We re-emphasize that the framework pre- 
sented here derives its strength in equal part from 
two components: the results of topical analysis of 
the document collection are displayed by means 
of a multi-perspective graphical interface specifi- 
cally designed to highlight his analysis. Within 
such a philosophy for multi-document summariza- 
tion, sub-components of the analysis technology can 
be modularly swapped in and replaced, without con- 
tradicting the overall approach. 
The algorithms and subsystems comprising the 
document collection analysis component have been 
implemented and are fully operational. The paper 
described one possible interface, focusing on certain 
visual metaphors for highlighting collection topics. 
As this is work in progress, we plan to experiment 
with alternative presentation metaphors. We plan 
to carry out user studies, to evaluate the interface 
in general, and to determine optimal features, best 
suited to representing our linguistic object analysis 
and supporting navigation through query results. 
Other future work will focus on determining the 
effects of analyzing linguistic objects to different 
level of granularity on the overall results. Questions 
to consider here, for instance, would he: what is 
the optimal definition of a term for this application; 
does it make sense to include larger phrasal units 
in the semantic space; or do operations over sen- 
tences, such as sentence merging or reduction, offer 
alternative ways of visualizing topical content. 
It is therefore worthwhile investigating whether 
combining automatic summarization with 
intelligent multimedia presentation techniques 
can make the briefing generation amenable to 
full automation. In other words, the author 
should be able to use a computer program to 
generate an initial briefing, which she can then 
edit and revise as needed. The briefing can then 
be presented by the author if desired, or else 
directly by the computer (particularly useful if 
the briefing is being sent to someone lse). The 
starting point for this process would be a high- 
level outline of the briefing on the part of the 
author. The outline would include references to 
particular information sources that had to be 
summarized in particular ways. If a program 
were able to take such outlines and generate 
briefings which didn't require extensive post- 
editing to massage into a state deemed 
acceptable for the task at hand, the program 
could be regarded as a worthwhile time saving 
tool. 
2 Approach 
Our work forms part of a larger DARPA-funded 
project aimed at improving analysis and 
decision-making in crisis situations by providing 
tools that allow analysts to collaborate to 
develop structured arguments in support of 
particular conclusions and to help predict likely 
future scenarios. These arguments, along with 
background evidence, are packaged together as 
briefings to high-level decision-makers. In 
leveraging automatic methods along the lines 
suggested above to generate briefings, our 
approach needs to allow the analyst to take on as 
~uch of the briefing authoring as she wants to 
(e.g., it may take time for her to adapt o or trust 
the machine, or she may want the machine to 
present just part of the briefing). The analyst's 
organisation usually will instantiate one of 
several templates dictating the high=level 
structure of a briefing; for example, a briefing 
may always have to begin with an executive 
summary. The summarization methods also need 
to be relatively domain-independent, given that 
the subject matter of crises are somewhat 
unpredictable; an analyst in a crisis situation is 
likely to be inundated with large numbers of 
crisis-related news and intelligence r ports from 
many different sources. This means that we 
cannot require that a domain knowledge base be 
available to help the briefing generation process. 
Given these task requirements, we have adopted 
an approach that is flexible about 
accommodating different degrees of author 
involvement, that is relatively neutral about the 
rhetorical theory underlying the briefing 
structure (since a template may be provided by 
others), and that is domain-independent. I  our 
approach, the author creates the briefing outline, 
which is then fleshed out further by the system 
based on information in the outline. The system 
fills out some content by invoking specified 
s taBunarizers; it also makes decisions, when 
needed, about output media type; it introduces 
narrative lements to improve the coherence of 
the briefing; and finally, it assembles the final 
presentation, making decisions about spatial 
layout in the process. 
A briefing is represented asa tree. The structure 
of the tree represents he rhetorical structure of 
the briefing. Each node has a label, which offers 
a brief textual description of the node. Each leaf 
node has an associated goal, which, when 
realized, provides content for that node. There 
are two kinds of goals: content-level goals and 
narrative-level goals. Content-level goals are 
also of two kinds: retrieve goals, which retrieve 
existing media objects of a particular type (text, 
audio, image, audio, video) satisfying some 
description, and create goals, which create new 
media objects of these types using programs 
(called summarization filters). Narrative-level 
goals introduce descriptions of content at other 
nodes: they include captions and running text for 
media objects, and segues, which are rhetorical 
moves describing a transition to a node. 
Ordering relations reflecting temporal and 
spatial ayout are defined on nodes in the tree. 
Two coarse-grained relations, seq for 
precedence, and par for simultaneity, are used to 
specify a temporal ordering on the nodes in the 
tree. As an example, temporal constraints for a 
(tiny) tree of 9 nodes may be expressed as: 
<ordering> <seq> 
<par>7</par> 
<par>8</par> 
<par>3</par> 
<par>4 5</par> 
<par>6</par> 
90 
I 
I 
i 
i 
I 
I 
i 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
i 
I 
I 
I 
I 
I 
| 
<par> l 9</par> 
<par>2</par> 
</seq> </ordering> 
The tree representation, along with the temporal 
constraints, can be rendered in text as XML; we 
refer to the XML representation as a script. 
? 
~\] Tern#ate 
Script \[ 
7Validator I 
~und~c,~ 
\[ 
I 
SMIL J Presentation \[ 
User Brief'mg 
Interface G en~ator 
/ 
Figure 1: System Architecture 
The overall architecture of our system is shown 
in Figure I. The user creates the briefing outline 
in the form of a script, by using a GUI. The 
briefing generator takes the script as input. The 
Script Validator applies an XML parser to the 
script, to check for syntactic orrectness. It then 
builds a.tree representation for the script, which 
represents the briefing outline, with temporal 
constraints attached to the leaves of the tree. 
Next, a Content Creator takes the input tree and 
expands it by introducing narrative-level goals 
including segues to content nodes, and running 
text and captions describing media objects at 
content nodes. Running text and short captions 
are generated from meta-information associated 
with media objects, by using shallow text 
generation methods (canned text). The end result 
of content selection (which has an XML 
representation called a ground scrip0 is that the 
complete tree has been fully specified, with all 
91 
the create and retrieve goals fully specified, 
with all the output media types decided. The 
Content Creator is thus responsible for both 
content selection and creation, in terms of tree 
structure and node content. 
Then, a Content Executor executes all the create 
and retrieve goals. This is a very simple step, 
resulting in the generation of all the media 
objects in the presentation, except for the audio 
files for speech to be synthesized. Thus, this step 
. results in realization of the content at the leaves 
of the tree. 
F ine ly ,  the Presentation Generator takes the 
tree which is output from Content Execution, 
along with its temporal ordering constraints, and 
generates the spatial ayout of the presentation. 
If no spatial ayout constraints are specified (the 
default is to not specify these), the system 
allocates pace using a simple method based on 
the temporal layout for nodes which have spatial 
manifestations. Speech synthesis is also carried 
out here. Once the tree is augmented with spatial 
layout constraints, it is translated by the 
Presentation Generator into SMIL 2 
(Synchronized Multimedia Integration 
Language) (SMIL 99), a W3C-developed 
extension of HTML that can be played by 
standard multimedia players (such as Real 3 and 
Grins 4. This step thus presents the realized 
content, synthesizing it into a multimedia 
presentation laid out spatially and temporally. 
This particular architecture, driven by the above 
project requirements, does not use planning as 
an overall problem-solving strategy, as planning 
requires domain knowledge. It therefore differs 
from traditional intelligent multimedia 
presentation planners, e.g., (Wahlster et al 93). 
Nevertheless, the system does make a number of 
intelligent decisions in organizing and 
coordinating presentation decisions. These are 
discussed next, aRer which we turn to the main 
point of the paper, namely the leveraging of 
summarization in automatic briefing generation. 
2 http://www.w3.org/AudioVideol 
3 www.real.com 
4 www.oratrix.com 
3 Intelligent Multimedia Presentation 
Generation 
The author of a briefing may choose to flesh out 
as little of the tree as desired, with the caveat 
that the temporal ordering relations for non- 
narrative nodes need to be provided by her. 
When a media object is generated at a node by a 
create goal, the running text and captions are 
generated by the system. The motivation for this 
is obvious: when a summarization filter (which 
is a program under our control) is generating a
media object, we can often provide sufficient 
meta-information about hat object o generate a 
short caption and some running text. By default, 
all segues and spatial layout relations are also 
specified by the system, so the author does not 
have to know about these unless she wants to. 
Finally, the decision as to when to produce 
audio, when not specified by the author, is left to 
the system. 
When summarization filters are used (for create 
goals), the media type of the output is specified 
as a parameter to the filter. This media type may 
be converted to some other type by the system, 
e.g., text to speech conversion using Festival 
(Taylor et al 98). By default, all narrative nodes 
attempt to realize their goals as a speech media 
type, using roles based on text length and 
truncatability to less than 250 bytes to decide 
when to use text-to-speech. The truncation 
algorithm is based on dropping syntactic 
constituents, using a method similar to (Mani et 
al. 99). Captions are always realized, in addition, 
as text (i.e., they have a text realization and a 
possible audio realization). 
Spatial layout is decided in the Presentation 
Generator, after all the individual media objects 
are created along with their temporal constraints 
by the Content Executor. The layout algorithm 
walks through the temporal ordering in 
sequence, allocating a segment o each set of 
objects that is designated to occur 
simultaneously (grouped by par in the temporal 
constraints). Each segment can have up to 4 
frames, in each of which a media object is 
displayed (thus, no more than 4 media objects 
can be displayed at the same time). Since media 
objects declared to be simultaneous (using par) 
in the temporal constraints will go together in a 
separate segment, the temporal constraints 
determine what elements are grouped together in 
a segment. The layout within a segment handles 
two special cases. Captions are placed directly 
underneath their associated media object. 
Running text, when realized as text, is placed 
beside the media object being described, so that 
they are paired together visually. Thus, 
coherence of a segment is influenced mainly by 
the temporal constraints (which have been 
fleshed out by the Content Creator to include 
narrative nodes), with further handling of special 
cases. Of course, an individual summarization 
filter may choose to coordinate component 
multimedia objects in particular ways in the 
course of generating a composite multimedia 
object. 
Details such as duration and onset of particular 
frames are specified in the translation to SMIL. 
Duration is determined by the number of frames 
present in a segment, unless there is an audio 
media object in the segment (this media object 
may have a spatial representation, e.g., as an 
audio icon, or it may not). If an audio media 
object occurs in a frame, the duration of all 
media objects in that frame is equal to the length 
of all the audio files in the segment. If there is 
no audio present in a segment, he duration is tx 
seconds (tx has a default value of 5) times the 
number of frames created. 
4 Summarization Filters 
As mentioned above, create goals are satisfied 
by summarization filters, which create new 
media objects ummarizing information sources. 
These programs are called summarization filters 
because in the course of condensing information, 
they take input information and turn it into some 
more abstract and useful representation, filtering 
out unimportant information. Such filters 
provide a novel way of carrying out content 
selection and creation for automated 
presentation generation. 
Our approach relies on component-based 
software composition, i.e., assembly of software 
units that have contractually specified interfaces 
that can be independently deployed and reused. 
The idea of assembling complex language 
processing programs out of simpler ones is 
92 
I 
I 
I 
I 
l 
I 
I 
I 
I 
I 
hardly new; however, by employing current 
industry standards to specify the interaction 
between the components, we simultaneously 
increase the robustness of the system, ensure the 
reusability of individual components and create 
a more fully plug-and-play capability. Among 
the core technology standards that support his 
plug-and-play component assembly capability 
are (a) Java interfaces, used to specify functions 
that all summarization components must 
implement in order to be used in the system, (b) 
the JavaBeans standard, which allows the 
parameters and methods of individual 
components o be inspected by the system and 
revealed to the users (c) the XML markup 
standard, which we have adopted as an inter- 
component communication language. Using 
these technologies, legacy or third-party 
summarizers are incorporated into the system by 
"wrapping" them so as to meet the interface 
specification of the system. These technologies 
also make possible a graphical environment to
assemble and configure complex summarization 
filters from individual summarization 
components. 
Among the most important wins over the 
traditional "piping" approach to filter assembly 
is the ability to impose build-time restrictions on 
the component assembly, disallowing "illegal" 
compositions, e.g. component X cannot provide 
input to component Y unless X's output type 
corresponds to Y's input type. Build-time 
restrictions uch as these play a clear role in 
increasing the overall robustness of the run-time 
summarization system. Another build-time win 
lies in the ability of JavaBeans to be serialized, 
i.e., written to disk in such a way as to preserve 
the state of its parameters settings, ensuring that 
every component in the system can be 
configured and run at different times 
independently of whether the component 
provides aparameter file facility. 
Establishing the standard functions required of a 
summarization filter is challenging on several 
fronts. One class of functions required by the 
interface is necessary tohandle the technicalities 
of exchanging information between otherwise 
discrete components. This set includes 
functions for discovering a component's input 
and output types, for handling messages, 
exceptions, and events passed between 
components and for interpreting XML based on 
one or more system-wide document type 
definitions (DTDs). The other, more interesting 
set of functions gets to the core of 
summarization functionality. Selecting these 
functions involves identifying parameters likely 
to be broadly applicable across most or all 
summarizers and finding ways to group them 
and/or to generalize them. This is desirable in 
order to reduce the burden on the end user of 
understanding the subtle differences between the 
. various settings in the summarizers available to 
her. 
An example of the difficulty inherent in this 
endeavor is provided by the compression 
(summary length divided by source length) vs. 
reduction (l's complement of compression) vs. 
target length paradigm. Different summarizers 
will implement one or more of these. The 
wrapper maps from the high-level interface 
function, where the application/user can specify 
either compression ortarget length, but not both, 
to the individual summarizer's representation. 
Thus, a user doesn't need to know which 
representation(s) a particular summarizer uses 
for reduction/compression. 
A vanilla summarization Bean includes the 
following functionality, which every summarizer 
must be able to provide methods for: 
source: documents to be summarized 
(this can be a single document, or a 
collection) 
reduction-rate: either summary 
size/source size, or target length 
audience: user-focused or generic 
(user-focused requires the specification 
of a bag of terms, which can be of 
different types) 
output-type: specific data formats 
(specified by DTDs) 
The above are parameters which we expect all 
summarizers to support. More specialized 
summarizer beans can be constructed to reflect 
groupings of summarizers. Among other 
parameters are output-fluency, which specifies 
whether a textual summary is to be made up of 
passages (sentences, paras, blocks), named 
entities, lists of words, phrases, or topics, etc. 
Given that definitions of summarization in more 
93 
theoretical terms have not been entirely 
satisfactory (Mani 2000), it is worth noting that 
the above vanilla Bean provides an operational 
definition of what a summarizer is. 
text, and segues. The captions and running text, 
when not provided by the filters, are provided by 
the script input. In the case of retrieve goals, the 
objects may not have any meta-information, i  
which case a default caption and running-text is
generated. Clearly, a system's explanatory 
narrative will be enhanced by the availability of 
rich meta-information. 
The segues are provided by the system. For 
example, an item with a label "A biography of 
bin Laden" could result in a generated segue 
"Here is a biography of bin Laden". The 
Content Creator, when providing content for 
narrative nodes, uses a variety of different 
canned text patterns. For the above example, the 
pattern would be "Here is @6.1abel", where 6 is 
the number of a non-narrative node, with label 
being its label. 
Figure 2: Summarization Filter 
Composition 
In addition to its practical utility in the ability to 
assimilate, combine and reuse components in 
different combinations, and to do so within a 
GUI, this approach is interesting because it 
allows powerful summarization functions to be 
created by composing together simpler tools. 
(Note that this is different from automatically 
finding the best combination, which our system 
does not address). For example, Figure 2 
illustrates a complex filter created by using a 
GUI to compose together a named entity 
extractor, a date extractor, a component which 
discovers significant associations between the 
two and writes the result to a table, and a 
visualizer which plots the results as a graph. The 
resulting summarizer takes in a large collection 
of documents, and produces as a summary a 
graph (a jpeg) of salient named entity mentions 
over time. Each of its components can be easily 
reused within the filter composition system to 
build other summarizers. 
5 Narrative Summarization 
Peru Action Brief 
1 Preamble 
2 Situation Assessment 
2.1 Chronology of Events 
2.1.2 Late st document summary 
cre ate ("uu mmarize -ge n eric 
-compression. l/peru/p32") 
2.2 Biographies 
2.2.1 Biography of Victor Polay 
2.2.1.1 Picture of @2.2.2.p~rson 
relrieveCD :h'awdata\polay.jpg') 
2.2.1.2 Biography of@~2.2.2.p~mon 
create("~ummarize-bio-lwng~ 350 
-~pan multi -pwruon 
~2.2.2.per~n -out table 
3 Coda 
"Th/s briefing has assessed a~ec/~ of the 
situation in Peru. Overall, t\]~ crisis 
appears to be worsening." 
Figure 3: Input Script 
As mentioned above, the system can construct a
narrative to accompany the briefing. Narrative 
nodes are generated to cover captions, running 
94 
Peru Action Brief 
1 Preamble 
audio = "ln this briefing,/will go over 
the ~2.1abeL This n i l  cover 
~2.1.1abel and @2. 3.1.laber" 
2 Situation Assessment 
2.1 "An overview of the @2.2.1abeF 
(Maa-2.2) 
2.2 Chronology of Events 
2.2.1 audio = "Here is the @2.2.2.1abeF 
(Meta-2. 2. 2) 
2.2.2 text = "Latest document summary" 
audio = text = 
ere ate ("summarize -gen eric 
-compression .1/peru/p32") 
2.3 Biographies 
2.3.1 audio = 
"A profile of @2. 3. 2.person" 
(Mete-2.3.2) 
2.3.2 Biography of Victor Polay 
2.3.2.1 audio = text = 
"A file photo of 
@2.3.2.person7 
(Meta-2.3,2.2) 
2.3.2.2 Picture of @2:3.2.person 
image = 
retrie ve("D Arawdata~polay.jpg") 
2.3.2.3 audio = text = 
"Profile of @2. 3.2.\]~rson" 
(Meta-2.3.2.3) 
2.3.2.4 Biography of@2.3.2.person 
audio = text = 
create ("summarize -bio -length 350 
-~'pan multi -person 
@2.2.2.person -out table 
~em/* ") 
3 Coda 
audio = "This briefing has a~sessed 
as-pect$ of the situation in Peru. Overall, 
the crisis appears to be worsening." 
<seq> 
</seq> 
<par> l</par> 
<par>2.2.1 2.2.2</par> 
?par>2.3. l </par> 
<par>2.3.2. l 2.3.2.2 
2.3.2.3 2.3.2.4</par> 
<par>3</par> 
Figure 4: Ground Script 
All segue nodes are by default generated 
automatically by the system, based on node 
labels. We always introduce a segue node at the 
beginning of the presentation (called a preamble 
node), which provides a segue covering the 
"crown" of the tree, i.e., all nodes upto a 
particular depth d from the root (d=-2) are 
marked with segue nodes. A segue node is also 
produced at the end (called a coda). (Both 
preamble and segue can of course be specified 
by the author if desired). 
For introducing intervening segue nodes, we use 
the following algorithm based on the distance 
between odes and the height in the tree. We 
traverse the non-narrative l aves of the tree in 
their temporal order, evaluating each pair of 
adjacent nodes A and B where A precedes B 
temporally. A segue is introduced between 
nodes A and B if either (a) the maximum of the 
2 distances from A and B to their least common 
ancestor is greater than 3 nodes or (19) the sum of 
the 2 distances from A and B to the least 
common ancestor is greater than 4 nodes. This is 
less intrusive than introducing segues at random 
or between every pair of successive nodes, and 
appears to perform better than introducing a 
segue at each depth of the tree. 
6 An Example 
We currently have a working version of the 
system with a variety of different single and 
multi-document summarization filters. Figure 3 
shows an input script created by an author (the 
scripts in Figure 3 and 4 are schematic 
representations of the scripts, rather than the raw 
XML). The script includes two create goals, one 
with a single-document generic summarization 
filter, the other with a multi-document user- 
focused summarization filter. Figure 4 shows the 
ground script which was created automatically 
by the Content Creator component. Note the 
addition of media type specifications, the 
introduction of narrative nodes, and the 
extemion of the temporal constraints. The final 
presentation generated is shown in Figure 5. 
Here we show screen dumps of the six SMIL 
segments produced, with the audio if any for 
each segment indicated in this paper next to an 
audio icon. 
95 
7 Status 
The summarization filters have incorporated 
several summarizers, including some that have 
been evaluated in the DARPA SUMMAC 
conference (Mani et al 99-1). These carry out 
both single-document and multi-document 
summarization, and include a preliminary 
biographical summarizer we have developed. 
The running text for the biography table in the 
second-last segment of Figure 5 is produced 
from meta-information i the table XML 
generated by the biographical summarizer. The 
production method for running text uses canned 
text which should work for any input table 
conforming to that DTD. 
The summarization filters are b.eing tested as 
part of a DARPA situated test with end-users. 
The briefing generator itself has been used 
internally to generate numerous briefings, and 
has been demonstrated as part of the DARPA 
system. We also expect ,to carry out an 
evaluation to assess the extent to which the 
automation described here provides efficiency 
gains in briefing production. 
8 Related Work 
There is a fair amount of work on automatic 
authoring of multimedia presentations, e.g., 
(Wahlster et al 93), (Dalai et al 96), (Mittal et 
al. 95), (Andre and Rist 97) 5. These efforts 
differ from ours in two ways: first, unlike us, 
they are not open-domain; and, second, they 
don't use summarization components. While 
..such efforts are extremely sophisticated 
compared to us in multimedia presentation 
planning and fine-grained coordination and 
synchronization capabilities, many of the 
components used in those efforts are clearly 
applicable to our work. For example, (Andre and 
Rist 96) include methods for leveraging lifelike 
characters in this process; these characters can 
be leveraged in our work as well, to help 
personify the computer narrator. In addition, our 
captions, which are very short, rely on canned 
text based on node labels in the initial script, or 
based on shallow meta-information generated by 
the summarization filter (in XML) along with 
the created media object. (Mittal et al 95) 
describe avariety of strategies for generation of 
longer, more explanatory captions, some of 
which may be exploited in our work by 
deepening the level of meta-information, at least 
for summarization components developed by us. 
In our ability to leverage automatic 
summarization, our work should be clearly 
distinguished from work which attempts to 
format a summary (from an XML 
representation) into something akin to a 
Powerpoint briefing, e.g., (Nagao and Hasida 
98). Our work, by contrast, is focused on using 
summarization i generating briefings from an 
abstract outline. 
9 Conclusion 
We have described methods for leveraging 
automatic summarization in the automatic 
generation of multimedia briefings. This work 
has taken, an open-domain approach, in order to 
meet the requirements of the DARPA 
application we are involved with. We believe 
there is a stronger role that NL generation can 
play in the narrative aspects of our briefings, 
which currently rely for the most part on canned 
text. Our future work on description merging in 
biographical summaries, and on introducing 
referring expressions into the narrative nodes, 
would in effect ake advantage of more powerful 
generation methods, without sacrificing open- 
domain capabilities. This may require much 
richer recta-information specifications than the 
ones we currently use. 
Finally, we have begun the design of the Script 
Creator GUI (the only component in Figure 1 
remaining to be built). This will allow the author 
to create scripts for the briefing generator 
(instead of editing templates by hand), by laying 
out icons for media objects in temporal order. A 
user will be able to select a "standard" briefing 
template from a menu, and then view it in a 
briefing/template structure ditor. The user can 
then provide content by adding annotations to 
any node in the briefing template. The user will 
have a choice of saving the edit version in 
template form, or in SMIL or possibly Microsoft 
Powerpoint format. 
96 
t~ 
, , ,  - -  ~ 
Peru Act ion Br ie f  !! 
? hectare  Summary  | 
o Hypotheds  .| 
Opt ions  ~ 
* S lmadon A . . . . . .  . ~ 
o Chrono loT~/o f  ~'~ve~ts 
o :mop-~Jd~ ii ? SmKtm-ed  Arguments  
? A l tensadve  V iews  i 
? Deds ions  
In this briefing I will go over the situation 
assessment. This will cover an overview of the 
chronology of events and a profile of Victor 
Polay. 
Next, a biography of Victor Polay. 
Here is an overview of the chronology of 
events. 
1: c~l  - PetuvLem rebe ls  te leane  2 hos~eages - Dec. lS th  
3: KbOUC ZOO hostages  remained l l~Lde  ~he home OZ Japanese 
labassaclo:c ~Ol:lhlstt JLOkl, where  TUpOC Az~ru rebe ls  mete 
c~m~ndlng  ~he re lease  ~tmn pc lson  o? e~ouc  400 o f  ~he l r  
co l  leagues .  
q 
o Here is the latest document summary. 
Victor Polay, also known as Comandante 
Rolando, is the Tupac Amaru founder, a
Peruvianguerrilla commander, a former ebel 
leader, and the Tupac Amaru rebels' top leader. 
He studied in both France and Spain. His wife is 
Rosa Polay and his mother is Otilia Campos de 
Polay. His associates include Alan Garcia. 
o This briefing has assessed aspects of the 
situation in Peru. Overall, the crisis appears to 
be worsening. 
Figure 5: Presentation 
97  
References 
Andre, E. and Rist, T. (1997) Towards a New 
Generation of Hypermedia Systems: Extending 
Automated Presentation Design for Hypermedia. 
L. Dybkjaer, ed., Proceedings of the Third Spoken 
Dialogue and Discourse Workshop, Topics in 
Natural Interactive Systems 1. The Maersk Mc- 
Kinney Moiler Institute for Production 
Technology, Odense University, Denmark, pp. 10- 
27. 
Dalal, M., Feiner, S., McKeown, K., Pan, S., Zhou, 
M., Hollerer, T., Shaw, J., Feng, Y., and Framer, J. 
(1996) Negotiation for Automated Generation of 
Temporal MultimediaPresentations. Proceedings 
of ACM Multimedia '96. 
Mani, 1., Gates, B., and Bioedorn, E. (1999) 
Improving Summaries by Revising Them. 
Proceedings of the 37 ~ Annual Meeting of the 
Association for Computational Linguistics, College 
Park, MD, pp. 558-565. 
Mani, I., Firmin, T., House, D., Klein, G., Sundheim, 
B., and Hirschman, L. (1999) The TIPSTER 
SUMMAC Text Summarization Evaluation. 
Proceedings of EACL'99, Bergen, Norway, pp. 77- 
85. 
Mani, 1. (2000)Automatic Text Summarization. John 
Benjamins Publishing Company. To appear. 
Mittal, V., Roth, S., Moore, J., Mattis, J., and 
Carenini, G. (1995) Generating Explanatory 
Captions for Information Graphics. Proceedings of 
the International Joint Conference on Artificial 
Intelligence (IJCAr95), pp. 1276-1283. 
Nagao, K. and K. Hasida, K. (1998)Automatic Text 
Summarization Based on the Global Document 
Annotation. Proceedings of COLING'98, Montreal, 
pp. 917-921. 
Power, R. and Scott, D. (1998) Multilingual 
.. Authoring using Feedback Texts. Proceedings of 
COL1NG'98, Montreal, pp. 1053-1059. 
Taylor, P., Black, A., and Caley, R. (1998) The 
architecture of the Festival Speech Synthesis 
System. Proceedings of the Third ESCA Workshop 
on Speech Synthesis, Jenolan Caves, Australia, pp. 
147-151. 
Wahlster, W., Andre, E., Finkler, W., Profitlich, H.- 
J., and Rist, T. (1993) Plan-Based Integration of 
Natural Language and Graphics Generation. AI 
Journal, 63. 
98 
The Talent System: TEXTRACT Architecture and Data Model 
Mary S. Neff 
IBM Thomas J. Watson 
Research Center 
P.O. Box 704 
Yorktown Heights, NY 
10598 
MaryNeff@us.ibm.com 
Roy J. Byrd 
IBM Thomas J. Watson 
Research Center 
P.O. Box 704 
Yorktown Heights, NY 10598
 
byrd@watson.ibm.com 
Branimir K. Boguraev 
IBM Thomas J. Watson 
Research Center 
P.O. Box 704 
Yorktown Heights, NY 
10598 
bkb@watson.ibm.com 
 
 
Abstract 
We present the architecture and data model for 
TEXTRACT, a document analysis framework for 
text analysis components.  The framework and 
components have been deployed in research 
and industrial environments for text analysis 
and text mining tasks. 
1 
                                                          
Introduction 
In response to a need for a common infrastructure and 
basic services for a number of different, but coordi-
nated, text analysis activities with a common set of re-
quirements, the Talent (Text Analysis and Language 
ENgineering Tools) project at IBM Research developed 
the first TEXTRACT system in 1993.  It featured a com-
mon C API and a tripartite data model, consisting of 
linked list annotations and two hash table extensible 
vectors for a lexical cache and a document vocabulary.  
The experience of productizing this system as part of 
IBM?s well-known commercial product Intelligent 
Miner for Text (IM4T1) in 1997, as well as new research 
requirements, motivated the migration of the analysis 
components to a C++ framework, a more modular archi-
tecture modeled upon IBM?s Software Solutions (SWS) 
Text Analysis Framework (TAF).  
The current version of TEXTRACT that we outline 
here is significantly different from the one in IM4T; 
however, it still retains the tripartite model of the central 
data store. 
In this paper, we first give an overview of the 
TEXTRACT architecture.  Section 3 outlines different 
operational environments in which the architecture can 
be deployed.  In Section 4, we describe the tripartite 
2 
1 http://www-3.ibm.com/software/data/iminer/fortext/ 
data model.  In Section 5, we illustrate some fundamen-
tals of plugin design, by focusing on Talent?s Finite 
State Transducer component and its interaction with the 
architecture and data model.  Section 6 reviews related 
work.  Finally, we conclude and chart  future directions.  
 
The TEXTRACT Architecture: Overview 
TEXTRACT is a robust document analysis framework, 
whose design has been motivated by the requirements of 
an operational system capable of efficient processing of 
thousands of documents/gigabytes of data.  It has been 
engineered for flexible configuration in implementing a 
broad range of document analysis and linguistic proc-
essing tasks.  The common architecture features it 
shares with TAF include: 
? interchangeable document parsers allow the ?in-
gestion? of source documents in more than one 
format (specifically, XML, HTML, ASCII, as 
well as a range of proprietary ones);  
? a document model provides an abstraction layer 
between the character-based document stream 
and annotation-based document components, 
both structurally derived (such as paragraphs and 
sections) and linguistically discovered (such as 
named entities, terms, or phrases); 
? linguistic analysis functionalities are provided 
via tightly coupled individual plugin compo-
nents; these share the annotation repository, lexi-
cal cache, and vocabulary and communicate with 
each other by posting results to, and reading 
prior analyses from, them; 
? plugins share a common interface, and are dis-
patched by a plugin manager according to de-
clared dependencies among plugins; a resource 
manager controls shared resources such as lexi-
cons, glossaries, or gazetteers; and at a higher 
level of abstraction, an engine maintains the 
document processing cycle; 
? the system and individual plugins are softly con-
figurable,  completely from the outside;  
? the architecture allows for processing of a stream 
of documents; furthermore, by means of collec-
tion-level plugins and applications, cross-
document analysis and statistics can be derived 
for entire document collections. 
 
 TEXTRACT is industrial strength (IBM, 1997), Unicode-
ready, and language-independent (currently, analysis 
functionalities are implemented primarily for English).  
It is a cross-platform implementation, written in C++.    
TEXTRACT is ?populated? by a number of plugins, 
providing functionalities for: 
? tokenization; 
? document structure analysis, from tags and white 
space; 
? lexicon interface, complete with efficient look-
up and full morphology;  
? importation of lexical and vocabulary analyses 
from a non-TEXTRACT process via XML markup; 
? analysis of out-of-vocabulary words (Park, 
2002); 
? abbreviation finding and expansion (Park and 
Byrd, 2001); 
? named entity identification and classification 
(person names, organizations, places, and so 
forth) (Ravin and Wacholder, 1997); 
? technical term identification, in technical prose 
(Justeson and Katz, 1995); 
? vocabulary determination and glossary extrac-
tion, in specialized domains (Park et al, 2002);  
? vocabulary aggregation, with reduction to ca-
nonical form, within and across documents; 
? part-of-speech tagging (with different taggers) 
for determining syntactic categories in context;  
? shallow syntactic parsing, for identifying phrasal 
and clausal constructs and semantic relations 
(Boguraev, 2000); 
? salience calculations, both of inter- and intra-
document salience; 
? analysis of topic shifts within a document (Bogu-
raev and Neff, 2000a); 
? document clustering, cluster organization, and 
cluster labeling; 
? single document summarization, configurable to 
deploy different algorithmic schemes (sentence 
extraction, topical highlights, lexical cohesion) 
(Boguraev and Neff, 2000a, 2000b); 
? multi-document summarization, using iterative 
residual rescaling (Ando et al, 2000); 
? pattern matching, deploying finite state technol-
ogy specially designed to operate over document 
content abstractions (as opposed to a character 
stream alone). 
 
The list above is not exhaustive, but indicative of the 
kinds of text mining TEXTRACT is being utilized for; we 
anticipate new technologies being continually added to 
the inventory of plugins.  As will become clear later in 
the paper, the architecture of this system openly caters 
for third-party plugin writers.   
 
Figure 1: TEXTRACT Architecture 
Specific TEXTRACT configurations may deploy cus-
tom subsets of available plugin components, in order to 
effect certain processing; such configurations typically 
implement an application for a specific content analysis 
/ text mining task.  From an application's point of view, 
TEXTRACT plugins deposit analysis results in the shared 
repository; the application itself ?reads? these via a well 
defined interface.  Document application examples to 
date include document summarization, a customer 
claims analysis system (Nasukawa and Nagano, 2001), 
and so forth. 
      
Collection applications have a document analysis 
component, which may also write to the shared reposi-
tory.  These include named relation extraction (Byrd 
and Ravin, 1999), custom dictionary building (Park, et 
al., 2001), indexing for question answering (Prager et 
al., 2000), cross-document coreference (Ravin and Kazi, 
1999), and statistical collection analysis for document 
summarization or lexical navigation (Cooper and Byrd, 
1997).  
Figure 2: TEXTRACT?s GUI 
 
For packaging in applications, Textract has, in addi-
tion to native APIs, a C API layer for exporting the con-
tents of the data store to external components in C++ or 
Java. 
 
3 Different Operational Environments 
 For the purposes of interactive (re-)configuration of 
TEXTRACT?s processing chain, rapid application proto-
typing, and incremental plugin functionality develop-
ment, the system?s underlying infrastructure capabilities 
are available to a graphical interface.  This allows cont-
trol over individual plugins; in particular, it exploits the 
configuration object to dynamically reconfigure speci-
fied plugins on demand.  By exposing access to the 
common analysis substrate and the document object, 
and by exploiting a mechanism for declaring, and inter-
preting, dependencies among individual plugins, the 
interface further offers functionality similar to that of 
GATE (Cunningham, 2002). Such functionality is facili-
tated by suitable annotation repository methods, includ-
ing a provision for ?rolling back? the repository to an 
earlier state, without a complete system reInit(). 
4 The TEXTRACT Data Model 
The plugins and applications communicate via the anno-
tations, vocabulary, and the lexical cache.  The collec-
tion object owns the lexical cache; the document object 
contains the other two subsystems: the annotation re-
pository, and the document vocabulary.  Shared read-
only resources are managed by the resource manager. 
Annotations:  Annotations contain, minimally, the 
character locations of the beginning and ending position 
of the annotated text within the base document, along 
with the type of the annotation.  Types are organized 
into families: lexical, syntactic, document structure, 
discourse, and markup.  The markup family provides 
access to the text buffer, generally only used by the to-
kenizer.  The annotation repository owns the type sys-
tem and pre-populates it at startup time.  Annotation 
features vary according to the type; for example, posi-
tion in a hierarchy of vocabulary categories (e.g. Person, 
Org) is a feature of lexical annotations.  New types and 
features (but not new families) can be added dynami-
cally by any system component.  The annotation reposi-
tory has a container of annotations ordered on start 
location (ascending), end location (descending), priority 
of type family (descending), priority within type family 
(descending), and type name (ascending).  The general 
effect of the family and type priority order is to reflect 
nesting level in cases where there are multiple annota-
tions at different levels with the same span.  With this 
priority, an annotation iterator will always return an NP 
In addition, the GUI is configurable as a development 
environment for finite state (FS) grammar writing and 
debugging, offering native grammar editing and compi-
lation, contextualized visualization of FS matching, and 
in-process inspection of the annotation repository at 
arbitrary level of granularity.  Figure 2 is broadly in-
dicative of some of the functional components exposed: 
in particular, it exemplifies a working context for a 
grammar writer, which includes an interface for setting 
operational parameters, a grammar editor/compiler, and 
multiple viewers for the results of the pattern match, 
mediated via the annotation repository, and making use 
of different presentation perspectives (e.g. a parse tree 
for structural analysis, concordance for pattern match-
ing, and so forth.) 
(noun phrase) annotation before a covered word annota-
tion, no matter how many words are in the NP. 
Iterators over annotations can move forward and 
backward with  respect to this general order.  Iterators 
can be filtered by set of annotation families, types or a 
specified text location.  A particular type of filtered it-
erator is the subiterator, an iterator that covers the span 
of a given annotation (leaving out the given annotation).  
Iterators can be specified to be ?ambiguous? or ?unam-
biguous.?  Ambiguous scans return all the annotations 
encountered; unambiguous scans return only a single 
annotation covering each position in the document, the 
choice being made according to the sort order above.  
Unambiguous scans within family are most useful for 
retrieving just the highest order of analysis.   All the 
different kinds of filters can be specified in any combi-
nation. 
Lexical Cache:  One of the features on a word an-
notation is a reference to an entry in the lexical cache.  
The cache contains one entry for each unique token in 
the text that contains at least one alphabetic character.  
Initially designed to improve performance of lexical 
lookup, the cache has become a central location for au-
thority information about tokens, whatever the source: 
lexicon, stop word list, gazetteer, tagger model etc.  The 
default lifetime of the lexical cache is the collection; 
however, performance can be traded for memory by a 
periodic cache refresh.    
The lexical lookup (lexalyzer) plugin populates the 
lexical cache with tokens, their lemma forms, and mor-
pho-syntactic features.  Morpho-syntactic features are 
encoded in an interchange format which mediates 
among notations of different granularities (of syntactic 
feature distinctions or morphological ambiguity), used 
by dictionaries (we use the IBM LanguageWare dic-
tionaries, available for over 30 languages), tag sets, and 
finite state grammar symbols.  In principle, different 
plugins running together can use different tag sets by 
defining appropriate tagset mapping tables via a con-
figuration file.  Similarly, a different grammar morpho-
syntactic symbol set can also be externally defined.   As 
with annotations, an arbitrary number of additional fea-
tures can be specified, on the fly, for tokens and/or 
lemma forms.  For example, an indexer for domain ter-
minology cross references different spellings, as well as 
misspellings, of the same thing.  The API to the lexical 
cache also provides an automatic pass-through to the 
dictionary API, so that any plugin can look up a string 
that is not in the text and have it placed in the cache. 
Vocabulary: Vocabulary annotations (names, do-
main terms, abbreviations) have a reference to an entry 
in the vocabulary.  The canonical forms, variants, and 
categories in the vocabulary can be plugin-discovered 
(Nominator), or plugin-recovered (matched from an 
authority resource, such as a glossary).  Collection sali-
ence statistics (e.g. tfxidf), needed, for example, by the 
summarizer application, are populated from a resource 
derived from an earlier collection run.  As with the an-
notations and lexical entries, a plugin may define new 
features on the fly. 
Resource Manager:  The Resource Manager, im-
plemented as a C++ singleton object so as to be avail-
able to any component anywhere, manages the files and 
API?s of an eclectic collection of shared read-only re-
sources: a names authority data base (gazetteer), prefix 
and suffix lists, stop word lists, the IBM LanguageWare 
dictionaries with their many functions (lemmatization, 
morphological lookup, synonyms, spelling verification, 
and spelling correction), and, for use in the research 
environment, WordNet (Fellbaum, 1998).  The API 
wrappers for the resources are deliberately not uniform, 
to allow rapid absorption and reuse of components.   For 
performance, the results of lookup in these resources are 
cached as features in the lexical cache or vocabulary.  
 
5 
5.1 
TEXTRACT Plugins 
TEXTRACT plugins and applications need only to con-
form to the API of the plugin manager, which cycles 
through the plugin vector with methods for: con-
struct(), initialize(), processDocument(), 
and endDocument(). Collection applications and 
plugins look nearly the same to the plugin manager; 
they have, additionally, startCollection() and 
endCollection() methods. The complete API also 
includes the interfaces to the annotation repository, lexi-
cal cache, and vocabulary.   
Plugin Example: TEXTRACT?s Finite State 
Transducer 
Numerous NLP applications today deploy finite state 
(FS) processing techniques?for, among other things, 
efficiency of processing, perspicuity of representation, 
rapid prototyping, and grammar reusability (see, for 
instance, Karttunen et al, 1996; Kornai, 1999).  TEX-
TRACT's FS transducer plugin (henceforth TFST), en-
capsulates FS matching and transduction capabilities 
and makes these available for independent development 
of grammar-based linguistic filters and processors. 
In a pipelined architecture, and in an environment 
designed to facilitate and promote reusability, there are 
some questions about the underlying data stream over 
which the FS machinery operates, as well as about the 
mechanisms for making the infrastructure compo-
nents?in particular the annotation repository and 
shared resources?available to the grammar writer.  
Given that the document character buffer logically ?dis-
appears? from a plugin?s point of view, FS operations 
now have to be defined over annotations and their prop-
erties.  This necessitates the design of a notation, in 
which grammars can be written with reference to 
TEXTRACT?s underlying data model, and which still 
have access to the full complement of methods for ma-
nipulating annotations. 
In the extreme, what is required is an environment 
for FS calculus over typed feature structures (see Becker 
et al, 2002), with pattern-action rules where patterns 
would be specified over type configurations, and actions 
would manipulate annotation types in the annotation 
repository.  Manipulation of annotations from FS speci-
fications is also done in other annotation-based text 
processing architectures (see, for instance, the JAPE 
system; Cunningham et al 2000).  However, this is 
typically achieved, as JAPE does, by allowing for code 
fragments on the right-hand side of the rules. 
Both assumptions?that a grammar writer would be 
familiar with the complete type system employed by all 
?upstream? (and possibly third party) plugins, and that a 
grammar writer would be knowledgeable enough to 
deploy raw API's to the annotation repository and re-
source manager?go against the grain of TEXTRACT?s 
design philosophy. 
Consequently, we make use of an abstraction layer 
between an annotation representation (as it is imple-
mented) and a set of annotation property specifications 
which define individual plugin capabilities and granu-
larity of analysis.  We also have developed a notation 
for FS operations, which appeals to the system-wide set 
of annotation families, with their property attributes, as 
well as encapsulates operations over annotations?such 
as create new ones, remove existing ones, modify and/or 
add properties, and so forth?as primitive operations.  
Note that the abstraction hides from the grammar writer 
system-wide design decisions, which separate the anno-
tation repository, the lexicon, and the vocabulary (see 
Section 3 above): thus, for instance, access to lexical 
resources with morpho-syntactic information, or, in-
deed, to external repositories like gazetteers or lexical 
databases, appears to the grammar writer as querying an 
annotation with morpho-syntactic properties and attrib-
ute values; similarly, a rule can post a new vocabulary 
item using notational devices identical to those for post-
ing annotations. 
The freedom to define, and post, new annotation 
types ?on the fly? places certain requirements on the 
FST subsystem.  In particular, it is necessary to infer 
how new annotations and their attributes fit into an al-
ready instantiated data model.  The FST plugin there-
fore incorporates logic in its reInit() method which 
scans an FST file (itself generated by an FST compiler 
typically running in the background), and determines?
by deferring to a symbol compiler?what new annota-
tion types and attribute features need to be dynamically 
configured and incrementally added to the model. 
An annotation-based regime of FS matching needs a 
mechanism for picking a particular path through the 
input annotation lattice, over which a rule should be 
applied: thus, for instance, some grammars would in-
spect raw tokens, others would abstract over vocabulary 
items (some of which would cover multiple tokens), yet 
others might traffic in constituent phrasal units (with an 
additional constrain over phrase type) or/and document 
structure elements (such as section titles, sentences, and 
so forth).   
For grammars which examine uniform annotation 
types, it is relatively straightforward to infer, and con-
struct (for the run-time FS interpreter), an iterator over 
such a type (in this example, sentences).  However, ex-
pressive and powerful FS grammars may be written 
which inspect, at different?or even the same?point of 
the analysis annotations of different types.  In this case 
it is essential that the appropriate iterators get con-
structed, and composed, so that a felicitous annotation 
stream gets submitted to the run-time for inspection; 
TEXTRACT deploys a special dual-level iterator designed 
expressly for this purpose. 
Additional features of the TFST subsystem allow for 
seamless integration of character-based regular expres-
sion matching, morpho-syntactic abstraction from the 
underlying lexicon representation and part-of-speech 
tagset, composition of complex attribute specification 
from simple feature tests, and the ability to constrain 
rule application within the boundaries of specified anno-
tation types only.  This allows for the easy specification, 
via the grammar rules, of a variety of matching regimes 
which can transparently query upstream annotators of 
which only the externally published capabilities are 
known. 
A number of applications utilizing TFST include a 
shallow parser (Boguraev, 2000), a front end to a glos-
sary identification tool (Park et al, 2002), a parser for 
temporal expressions, a named entity recognition de-
vice, and a tool for extracting hypernym relations. 
 
 
6 Related Work 
The Talent system, and TEXTRACT in particular, belongs 
to a family of language engineering systems which in-
cludes GATE (University of Sheffield), Alembic 
(MITRE Corporation), ATLAS (University of Pennsyl-
vania), among others.  Talent is perhaps closest in spirit 
to GATE.  In Cunningham, et al (1997), GATE is de-
scribed as ?a software infrastructure on top of which 
heterogeneous NLP processing modules may be evalu-
ated and refined individually or may be combined into 
larger application systems.?  Thus, both Talent and 
GATE address the needs of researchers and developers, 
on the one hand, and of application builders, on the 
other.   
The GATE system architecture comprises three 
components: The GATE Document Manager (GDM), 
The Collection of Reusable Objects for Language Engi-
neering (CREOLE), and the GATE Graphical Interface 
(GGI).  GDM, which corresponds to TEXTRACT?s 
driver, engine, and plugin manager, is responsible for 
managing the storage and transmission (via APIs) of the 
annotations created and manipulated by the NLP proc-
essing modules in CREOLE.  In TEXTRACT?s terms, the 
GDM is responsible for the data model kept in the docu-
ment and collection objects.  Second, CREOLE is the 
GATE component model and corresponds to the set of 
TEXTRACT plugins.  Cunningham, et al (1997) em-
phasize that CREOLE modules, which can encapsulate 
both algorithmic and data resources, are mainly created 
by wrapping preexisting code to meet the GDM APIs.  
In contrast, TEXTRACT plugins are typically written ex-
pressly in order that they may directly manipulate the 
analyses in the TEXTRACT data model.  According to 
Cunningham, et al (2001), available CREOLE modules 
include: tokenizer, lemmatizer, gazetteer and name 
lookup, sentence splitter, POS tagger, and a grammar 
application module, called JAPE, which corresponds to 
TEXTRACT?s TFST. Finally, GATE?s third component, 
GGI, is the graphical tool which supports configuration 
and invocation of GDM and CREOLE for accomplish-
ing analysis tasks.  This component is closest to 
TEXTRACT?s graphical user interface. As discussed ear-
lier, the GUI is used primarily as a tool for grammar 
development and AR inspection during grammar writ-
ing.  Most application uses of TEXTRACT are accom-
plished with the programming APIs and configuration 
tools, rather than with the graphical tool.   
Most language engineering systems in the 
TEXTRACT family have been motivated by a particular 
set of applications: semi-automated, mixed-initiative 
annotation of linguistic material for corpus construction 
and interchange, and for NLP system creation and 
evaluation, particularly in machine-learning contexts.  
As a result, such systems generally highlight graphical 
user interfaces, for visualizing and manipulating annota-
tions, and file formats, for exporting annotations to 
other systems.  Alembic (MITRE, 1997) and ATLAS 
(Bird, et al, 2000) belong to this group.  Alembic, built 
for participation in the MUC conferences and adhering 
to the TIPSTER API (Grishman, 1996), incorporates 
automated annotators (?plugins?) for word/sentence 
tokenization, part-of-speech tagging, person/ organiza-
tion/ location/ date recognition, and coreference analy-
sis. It also provides a phrase rule interpreter similar to 
TFST.  Alembic incorporates ATLAS?s ?annotation 
graphs? as its logical representation for annotations.  
Annotation graphs reside in ?annotation sets,? which are 
closest in spirit to TEXTRACT?s annotation repository, 
although they don't apparently provide APIs for fine-
grained manipulation of, and filtered iterations over, the 
stored annotations.  Rather, ATLAS exports physical 
representations of annotation sets as XML files or rela-
tional data bases containing stand-off annotations, 
which may then be processed by external applications.    
Other systems in this genre are Anvil (Vintar and 
Kipp (2001), LT-XML (Brew, et al, 2000), MATE 
(McKelvie, et al, 2000), and Transcriber (Barras, et al, 
(2001).  Like ATLAS, some of these were originally 
built for processing speech corpora and have been ex-
tended for handling text.  With the exception of GATE, 
all of these systems are devoted mainly to semi-
automated corpus annotation and to evaluation of lan-
guage technology, rather than to the construction of 
industrial NLP systems, which is TEXTRACT?s focus.  
As a result, TEXTRACT uses a homogeneous implemen-
tation style for its annotation and application plugins, 
with a tight coupling to the underlying shared analysis 
data model.  This is in contrast to the more loosely-
coupled heterogeneous plugin and application model 
used by the other systems. 
 
7 Conclusion 
In this paper, we have described an industrial infra-
structure for composing and deploying natural language 
processing components that has evolved in response to 
both research and product requirements.  It has been 
widely used, in research projects and product-level ap-
plications.  
A goal of the Talent project has been to create tech-
nology that is well-suited for building robust text analy-
sis systems.  With its simple plugin interface (see 
Section 5), its rich declarative data model, and the flexi-
ble APIs to it (Section 4), TEXTRACT has achieved that 
goal by providing a flexible framework for system 
builders. The system is habitable (external processes 
can be ?wrapped? as plugins, thus becoming available as 
stages in the processing pipeline), and open (completely 
new plugins can be written?by anyone?to a simple 
API, as long as their interfaces to the annotation reposi-
tory, the lexical cache, and the vocabulary (Section 4), 
follow the published set of specifications. 
Openness is further enhanced by encouraging the 
use of TFST, which directly supports the development, 
and subsequent deployment, of grammar-based plugins 
in a congenial style.  Overall, TEXTRACT?s design char-
acteristics prompted the adoption of most of the archi-
tecture by a new framework for management and 
processing of unstructured information at IBM Research 
(see below).  
Performance is not generally an inherent property of 
an architecture, but rather of implementations of that 
architecture.  Also, the performance of different con-
figurations of the system would be dependent on the 
number, type, and algorithmic design and implementa-
tion of plugins deployed for any given configuration.  
Thus it is hard to quantify TEXTRACT?s performance. 
The most recent implementation of the architecture is in 
C++ and makes extensive use of algorithms, container 
classes and iterators from the C++ Standard Template 
Library for manipulating the data objects in the data 
model; its performance therefore benefits from state-of-
the-art implementations of the STL.  As an informal 
indication of achievable throughput, an earlier product 
implementation of the tokenization base services and 
annotation subsystem, in the context of an information 
retrieval indexer, was able to process documents at the 
rate of over 2 gigabytes-per-hour on a mid-range Unix 
workstation. 
Allowing TEXTRACT?s plugins to introduce ? dy-
namically ? new annotation types and properties is an 
important part of an open system.  However, a limita-
tion of the current design is the fixed organization of 
annotations into families (see Section 4).  This makes it 
hard to accommodate new plugins which need to appeal 
to information which is either not naturally encodable in 
the family space TEXTRACT pre-defines, or requires a 
richer substrate of (possibly mutually dependent) feature 
sets.   
In a move towards a fully declarative representation 
of linguistic information, where an annotation maxi-
mally shares an underlying set of linguistic properties, a 
rational re-design of TEXTRACT (Ferrucci and Lally, 
2003) is adopting a hierarchical system of feature-based 
annotation types; it has been demonstrated that even 
systems supporting strict single inheritance only are 
powerful enough for a variety of linguistic processing 
applications (Shieber, 1986), largely through their well-
understood mathematical properties (Carpenter, 1992). 
Some of this migration is naturally supported by the 
initial TEXTRACT data model design.  Other architec-
tural components will require re-tooling; in particular, 
the FST subsystem will need further extensions for the 
definition of FS algebra over true typed feature struc-
tures (see, for instance, Brawer, 1998; Wunsch, 2003).  
We will return to this issue in a following paper.  
8 Acknowledgements 
We acknowledge the contributions of our colleagues, 
current and former, in the design and implementation of 
the Talent system and plugins:  Rie Ando, Jim Cooper, 
Aaron Kershenbaum, Youngja Park, John Prager, Yael 
Ravin, Misook Choi, Herb Chong, and Zunaid Kazi. 
 
 
References 
Ando, Rie K., Branimir K. Boguraev, Roy J. Byrd and 
Mary S. Neff.  2000.  Multi-document summarization 
by visualizing topical content.  Advanced Summari-
zation Workshop, NAACL/ANLP-2000, Seattle, 
WA, April 2000. 
Barras, Claude, Edouard Geoffrois, Zhibiao Wu, and 
Mark Liberman. 2001. Transcriber: development and 
use of a tool for assisted speech corpora production.  
In Speech Communication (33):5-22. 
Becker, Marcus, Witold Dro?d?y?ski, Hans-Ulrich 
Krieger, Jakub Poskorski, Ulrich Sch?fer, Feiyu Xu.  
2002. SProUT?Shallow processing with unification 
and typed feature structures.  Proceedings of the In-
ternational Conference on Natural Language Proc-
essing (ICON 2002), Mumbai, India. 
Bird, Steven, David Day, John Garofolo, John Hender-
son, Christohe Laprun, and Mark Liberman. 2000. 
ATLAS: A Flexible and extensible architecture for 
linguistic annotation.  In Proceedings of the Second 
International Conference on Language Resources 
and Evaluation: 1699-1706. 
Brew, Chris, David McKelvie, Richard Tobin, Henry 
Thompson, and Andrei Mikheev. 2000.  The XML 
Library LT XML version 1.2 ? User Documentation 
and Reference Guide," available at http:// 
www.ltg.ed.ac.uk/corpora/xmldoc/release
/book1.htm. 
Boguraev, Branimir K. 2000.  Towards finite-state 
analysis of lexical cohesion", In Proceedings of the 
3rd International Conference on Finite-State Meth-
ods for NLP, INTEX-3, Liege, Belgium. 
Boguraev, Branimir K. and Mary S. Neff. 2000a.  Dis-
course segmentation in aid of document summariza-
tion.  In Proceedings of the 33rd Hawaii International 
Conference on System Sciences, Maui, HI, January 
2000. 
Boguraev, Branimir K. and Mary S. Neff. 2000b.  Lexi-
cal cohesion, discourse segmentation, and document 
summarization.  In RIAO-2000, Paris, April 2000. 
Brawer, Sascha. 1998. Patti: Compiling Unification-
Based Finite-State Automata into Machine Instruc-
tions for a Superscalar Pipelined RISC Processor, 
MA Thesis, University of the Saarland, Saarbr?cken, 
Germany. 
Byrd, Roy and Yael Ravin. 1999.  Identifying and ex-
tracting relations in text.  Presented at the NLDB?99 
Conference, Klagenfurt, Austria. 
Carpenter, Robert. 1992.  The Logic of Typed Feature 
Structures.  Cambridge University Press, Cambridge, 
England. 
Cooper, James and Roy J. Byrd. 1997.  Lexical naviga-
tion ? visually prompted query expansion and re-
finement.  In DIGILIB 97. 
Cunningham, Hamish, Diana Maynard and Valentin 
Tablan. 2000.  JAPE: A Java Annotation Patterns 
Engine.  Research memo CS ? 00 ? 10, Institute for 
Language, Speech and Hearing (ILASH), and De-
partment of Computer Science, University of Shef-
field, UK. 
Cunningham, Hamish, Diana Maynard, Valentin Tab-
lan, Cristian Ursu, and Kalina Bontcheva. 2001 De-
veloping Language Processing Components with 
GATE.  GATE v2.0 User Guide, University of Shef-
field. 
Cunningham, Hamish, Diana Maynard, Kalina 
Bontcheva, Valentin Tablan. 2002.  GATE: A 
framework and graphical development environment 
for robust NLP tools and applications. Proceedings 
of the 40th Anniversary Meeting of the Association 
for Computational Linguistics (ACL'02). Philadel-
phia. 
Cunningham, Hamish, K. Humphreys, R. Gaizauskas, 
and Yorick Wilks. 1997. Software infrastructure for 
natural language processing," in Proceedings of the 
Fifth Conference on Applied Natural Language 
Processing (ANLP-97). 
Grishman, Ralph. 1996.  TIPSTER Architecture Design 
Document Version 2.2  Technical Report, DARPA. 
Fellbaum, Christiane. 1998.  WordNet, An Electronic 
Lexical Database.  MIT Press. 
Ferrucci, David and Adam Lally. 2003.  Accelerating 
corporate research in the development, application, 
and deployment of human language technologies. 
NAACL Workshop on Software Engineering and 
Architecture of Language Technology Systems, Ed-
monton, Canada. 
IBM Corp, Intelligent Miner for Text Product Overview,  
1997. http://www3.ibm.com/software/data/ 
iminer/fortext/.  
Justeson, John S. and Slava Katz. 1995.  Technical ter-
minology: some linguistic properties and an algo-
rithm for identification in text.  Natural Language 
Engineering, 1(1):9-27. 
Karttunen, Lauri, Jean-Pierre Chanod, Gregory Grefen-
stette and Anne Schiller. 1996.  Regular expressions 
for language engineering. Natural Language Engi-
neering, 4(1), pp.305-328. 
Kornai, Andras. 1999.  Extended Finite State Models of 
Language, Cambridge University Press, Cambridge, 
UK. 
McKelvie, David, Amy Isard, Andreas Mengel, Morten 
Baun M?ller, Michael Grosse, Marion Klein. 2000. 
The MATE Workbench - an annotation tool for XML 
coded speech corpora.  In Speech Communication.  
MITRE Corporation. 1997. Alembic Workbench Users 
Guide. available at http://www.mitre.org/ 
technology/alembic-workbench/. 
Nasukawa, Tetsuya and T. Nagano.  2001.  Text analy-
sis and knowledge mining system.  In IBM Systems 
Journal (40:4): 967-984. 
Park, Youngja. 2002.  Identification of probable real 
words: an entropy-based approach. In Proceedings of 
ACL Workshop on Unsupervised Lexical Acquisition: 
pp 1-8.   
Park, Youngja and Roy J. Byrd.  2001.  Hybrid text 
mining for finding terms and their abbreviations, In 
EMNLP-2001. 
Park, Youngja, Roy J. Byrd and Branimir K. Boguraev. 
2002.  Automatic glossary extraction: beyond termi-
nology identification.  In Proceedings of the 19th In-
ternational Conference on Computational  
Linguistics  (COLING): 772-778. 
Prager, John, Eric Brown, Anni Coden, and Dragomir 
Radev.  2000.  Question-answering by predictive an-
notation.  In Proceedings of SIGIR 2000: 184-191, 
Athens, Greece. 
Ravin, Yael and Zunaid Kazi. 1999. Is Hillary Rodham 
Clinton the president?  Disambiguating names across 
documents.  In Proceedings of the ACL ?99 Work-
shop on Coreference and its Applications, June 1999. 
Ravin, Yael and Nina Wacholder. 1997.  Extracting 
names from natural-language text.  IBM Research 
Report 20338. 
Shieber, Stuart. 1986. An Introduction to Unification-
Based Approaches to Grammar, CSLI Lecture Notes, 
Vol. 4, Stanford University, California. 
Vintar, Spela and Michael Kipp. 2001. Multi-track an- 
notation of terminology using Anvil. 
Wunsch, Holger.  2003.  Annotation Grammars and 
Their Compilation into Annotation Transducers.  MA 
Thesis, University of T?bingen, Germany. 
 
