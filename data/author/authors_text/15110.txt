Elaborating a Knowledge Base for Deep Lexical Semantics
Niloofar Montazeri and Jerry R. Hobbs
Information Sciences Institute
University of Southern California
Marina del Rey, California
Abstract
We describe the methodology for constructing axioms defining event-related words, anchored
in core theories of change of state and causality. We first derive from WordNet senses a smaller
set of abstract, general ?supersenses?. We encode axioms for these, and we test them on textual
entailment pairs. We look at two specific examples in detail to illustrate both the power of the
method and the holes in the knowledge base that it exposes. Then we address the problem of holes
more systematically, asking, for example, what kinds of ?pairwise interactions? are possible for core
theory predicates like change and cause.1
1 Introduction
From the sentence
Russia is blocking oil from entering Ukraine.
we would like to be able to conclude
Oil can not be delivered to Ukraine.
But doing this requires fairly complex inference, because the words ?block?, ?enter?, ?can?, ?not? and
?deliver? carve up the world in different ways. Our approach is to define words such as these by means
of axioms that link with underlying core theories2 explicating such very basic concepts as change of
state and causality. Given the logical form of sentences like these two, we apply these axioms to express
the meaning of the sentences in more fundamental predicates, and do a certain amount of defeasible
reasoning in the core theories to determine that the second follows from the first.
More generally, we are engaged in an enterprise we call ?deep lexical semantics? (Hobbs, 2008), in
which we develop various core theories of fundamental commonsense phenomena and define English
word senses by means of axioms using predicates explicated in these theories. Among the core theories
are cognition, microsociology, and the structure of events. The last of these is the focus of this paper. We
use textual entailment pairs like the above to test out subsets of related axioms. This process enforces a
1This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) Machine Reading
Program under Air Force Research Laboratory (AFRL) prime contract no. FA8750-09-C-0172, and in part by the Office of
Naval Research under contract no. N00014-09-1-1029.. Any opinions, findings, and conclusion or recommendations expressed
in this material are those of the author(s) and do not necessarily reflect the view of the DARPA, AFRL, ONR, or the US
government.
2http://www.isi.edu/ hobbs/csk.html.
195
uniformity in the way axioms are constructed, and also exposes missing inferences in the core theories.
The latter is a major issue in this paper.
In Section 2 we describe three aspects of the framework we are working in?the logical form we
use, abductive interpretation and defeasibility, and the core theories of change of state and causality. In
Section 3 we describe the methodology we use for constructing axioms, deriving from WordNet senses
a smaller set of abstract, general ?supersenses?, encoding axioms for these, and testing them on textual
entailment pairs. In Section 4 we look at two specific examples to illustrate both the power of the method
and the holes in the knowledge base that it exposes. In Section 5 we address the problem of holes more
systematically, specifically asking, for example, what kinds of ?pairwise interactions? are possible for
core theory predicates like change and cause.
2 Framework
We use a logical notation in which states and events (eventualities) are reified. Specifically, if the ex-
pression (p x) says that p is true of x, then (p? e x) says that e is the eventuality of p being true
of x. Eventuality e may exist in the real world (Rexist), in which case (p x) holds, or it may only
exist in some modal context, in which case that is expressed simply as another property of the possible
individual e. (In this paper we use a subset of Common Logic3 for the syntax of our notation.)
The logical form of a sentence is a flat conjunction of existentially quantified postive literals, with
about one literal per morpheme. (For example, logical words like ?not? and ?or? are treated as expressing
predications about possible eventualities.) We have developed software4 to translate Penn TreeBank-style
trees (as well as other syntactic formalisms) into this notation. The underlying core theories are expressed
as axioms in this notation (Hobbs, 1985).
The interpretation of a text is taken to be the lowest-cost abductive proof of the logical form of
the text, given the knowledge base. That is, to interpret a text we prove the logical form, allowing for
assumptions at cost, and pick the lowest-cost proof. Factors involved in computing costs include, besides
the number of assumptions, the salience of axioms, the plausibility of axioms expressing defeasible
knowledge, and consiliance or the degree to which the pervasive implicit redundancy of natural language
texts is exploited. We have demonstrated that many interpretation problems are solved as a by-product
of finding the lowest-cost proof. This method has been implemented in an abductive theorem-prover
called Mini-Tacitus5 that has been used in a number of applications (Hobbs et al, 1993; Mulkar et al,
2007), and is used in the textual entailment problems described here. We are also working toward a
probabilistic semantics for the cost of proofs (Blythe et al, 2011). Abductive interpretation accounts for
script-like understanding of text?a script predicate provides the most economical interpretation (Hobbs
et al, 1993)?but also enables interpretation of novel texts.
Most commonsense knowledge is defeasible, i.e., it can be defeated. This is represented in our
framework by having a unique ?et cetera? proposition in the antecedent of Horn clauses that cannot be
proved but can be assumed at a cost corresponding to the likeliehood that the conclusion is true. For
example, the axiom
(forall (x) (if (and (bird x)(etc-i x))(fly x)))
would say that if x is a bird and other unspecified conditions hold, (etc-i), then x flies. No other
axioms enable proving (etc-i x), but it can be assumed, and hence participate in the lowest cost
3http://common-logic.org/.
4http://www.rutumulkar.com/download/NL-Pipeline/NL-Pipeline.php.
5http://rutumulkar.com/download/TACITUS/tacitus.php.
196
proof. The index i is unique to this axiom. In this paper rather than invent new indices for each axiom, we
will use the abbreviation (etc) to indicate the defeasibility of the rule. (This approach to defeasibility
is similar to circumscription (McCarthy, 1980).)
We have articulated a number of core theories6. The two most relevant to this paper are the theory
of change of state and the theory of causality. The predication (change? e e1 e2) says that e is
a change of state whose initial state is e1 and whose final state is e2. The chief properties of change
are that there is some entity whose state is undergoing change, that change is defeasibly transitive,
that e1 and e2 cannot be the same unless there has been an intermediate state that is different, and that
change is consistent with the before relation from our core theory of time. Since many lexical items
focus only on the initial or the final state of a change, we introduce for convenience the predications
(changeFrom? e e1) and (changeTo? e e2), defined in terms of change.
The chief distinction in our core theory of causality is between the notions of causalComplex and
cause. A causal complex includes all the states and events that have to happen or hold in order for the
effect to happen. A cause is that contextually relevant element of the causal complex that is somehow
central to the effect, whether because it is an action the agent performs, because it is not normally true,
or for some other reason. Most of our knowledge about causality is expressed in terms of the predicate
cause, rather than in terms of causal complexes, because we rarely if ever know the complete causal
complex. Typically planning, explanation, and the interpretation of texts (though not diagnosis) involves
reasoning about cause. Among the principal properties of cause are that it is defeasibly transitive,
that events defeasibly have causes, and that cause is consistent with before.
We also have a core theory of time, and the times of states and events can be represented as temporal
properties of the reified eventualities. The theory of time has an essential function in axioms for words
explicitly referencing time, such as ?schedule? and ?delay?. But for most of the words we are explicating
in this effort, we base our approach to the dynamic aspects of the world on the cognitively more basic
theory of change of state. For example, the word ?enter? is axiomatized as a change of state from being
outside to being inside, and the fact that being outside comes before being inside follows from the axiom
relating the predicates change and before.
We find that reifying states and events as eventualities and treating them as first-class individuals is
preferable to employing the event calculus (Gruninger and Menzel, 2010; Mueller, 2006) which makes a
sharp distinction between the two, because language makes no distinction in where they can appear and
we can give them a uniform treatment.
3 Methodology
Our methodology consists of three steps.
1. Analyzing the structure of a word?s WordNet senses.
2. Writing axioms for the most general senses
3. Testing the axioms on textual entailment pairs.
Our focus in this paper is on words involving the concepts of change of state and causality, or event
words, such as ?block?, ?delay?, ?deliver?, ?destroy?, ?enter?, ?escape?, ?give?, ?hit?, ?manage?, and
?provide?. For each word, we analyze the structure of its WordNet senses. Typically, there will be pairs
that differ only in, for example, constraints on their arguments or in that one is inchoative and the other
6http://www.isi.edu/ hobbs/csk.html.
197
causative. This analysis generally leads to a radial structure indicating how one sense leads by incre-
ments, logically and perhaps chronologically, to another word sense (Lakoff, 1987). The analysis also
leads us to posit ?supersenses? that cover two or more WordNet senses. (Frequently, these supersenses
correspond to senses in FrameNet (Baker et al, 2003) or VerbNet (Kipper et al, 2006), which tend to be
coarser grained; sometimes the desired senses are in WordNet itself.)
For example, for the verb ?enter?, three WordNet senses involve a change into a state:
V2: become a participant
V4: play a part in
V9: set out on an enterprise
Call this supersense S1. Two other senses add a causal role to this:
V5: make a record of
V8: put or introduce into something
Two more senses specialize supersense S1 by restricting the target state to be in a physical location:
V1: come or go into
V6: come on stage
One other sense specializes S1 by restricting the target state to be membership in a group.
V3: register formally as a participant or member
Knowing this radial structure of the senses helps enforce uniformity in the construction of the axioms. If
the senses are close, their axioms should be almost the same.
We are currently only constructing axioms for the most general or abstract senses or supersenses.
In this way, although we are missing some of the implications of the more specialized senses, we are
capturing the most basic topological structure in the meanings of the words. Moreover, the specialized
senses usually tap into some specialized domain that needs to be axiomatized before the axioms for these
senses can be written.
In constructing the axioms in the event domain, we are very much informed by the long tradition of
work on lexical decomposition in linguistics (e.g., Gruber, 1965; Jackendoff, 1972). Our work differs
from this in that our decompositions are done as logical inferences and not as tree transformations as in
the earliest linguistic work, they are not obligatory but only inferences that may or may not be part of the
lowest-cost abductive proof, and the ?primitives? into which we decompose the words are explicated in
theories that enable reasoning about the concepts.
Figure 1 shows the radial structure of the senses for the word ?enter?, together with the axioms that
characterize each sense. A link between two word senses means an incremental change in the axiom for
one gives the axiom for the other. For example, the axiom for enter-S2 says that if x1 enters x2 in
x3, then x1 causes a change to the eventuality i1 in which x2 is in x3; and the expanded axiom for
enter-S1.1 states that if x1 enters x2, then there is a change to a state e1 in which x1 is in x2. So
enter-S2 and enter-S1.1 are closely related and thus linked together.
Abstraction is a special incremental change where one sense S1.1 specializes another sense S1 ei-
ther by adding more predicates to or specializing some of the predicates in S1?s axiom. We represent
abstractions via arrows pointing from the subsenses to the supersenses. In Figure 1, enter-S1.1 and
enter-S1.2 both specialize enter-S1. The predicate enter-S1.1 adds an extra predicate de-
scribing e1 as an in eventuality and enter-S1.2 specializes e1 to membership in x2, where x2 is a
group.
198
Figure 1: Senses of and axioms for the verb ?enter?
The supersenses capture the basic topology of the senses they subsume. The extra information that
the subsenses convey are typically the types and properties of the arguments, such as being a place or a
process, or qualities of the causing event, such as being sudden or forceful.
For each set of inferentially related words we construct textual entailment pairs, where the hypothesis
(H) intuitively follows from text (T), and use these for testing and evaluation. The person writing the
axioms does not know what the pairs are, and the person constructing the pairs does not know what the
axioms look like.
The ideal test then is whether given a knowledge base K consisting of all the axioms, H cannot be
proven from K alone, but H can be proven from the union of K and the best intepretation of T. This is
often too stringent a condition, since H may contain irrelevant material that doesn?t follow from T, so an
alternative is to determine whether the lowest cost abductive proof of H given K plus T is substantially
lower than the lowest cost abductive proof of H given K alone, where ?substantially lower? is defined by
a threshold that can be trained (Ovchinnikova et al, 2011).
4 Two Examples
Here we work through two examples to illustrate how textual entailment problems are handled in our
framework. In these examples, given a text T and a hypothesis H, we ask if H can be proven from T,
perhaps with a small number of low-cost assumptions.
Because the examples we deal with involve a great deal of embedding, we need to use the primed
predicates, keeping the eventuality arguments explicit.
We also assume in these examples that lexical disambiguation has been done correctly. With more
context, lexical disambiguation should fall out of the best interpretation, but it is unreasonable to ex-
pect that in these short examples. In practice we run the examples both with disambiguated and with
nondisambiguated predicates.
In these examples we do not show the costs, although they are used by our system.
The first example is the pair
T: Russia is blocking oil from entering Ukraine.
H: Oil cannot be delivered to Ukraine.
199
The relevant part of the logical form of the text is
(and (block-V3? b1 x1 e1)(enter-S2? e1 o1 u1))
That is, there is a blocking event b1 in which Russia x1 blocks eventuality e1 from occurring, and e1 is
the eventuality of oil o1 entering Ukraine u1. The -V3 on block indicates that it is the third WordNet
sense of the verb ?block? and the -S2 suffix on enter indicates that it is the second supersense of
?enter?.
The relevant part of the logical form of the hypothesis is
(and (not? n2 c2) (can-S1? c2 x2 d2) (deliver-S2? d2 x2 o2 u2))
That is, n2 is the eventuality that c2 is not the case, where c2 is some x2?s being able to do d2, where
d2 is x2?s delivering oil o2 to Ukraine u2. Note that we don?t know yet that the oil and Ukraine in the
two sentences are coreferential.
The axiom relating the third verb sense of ?block? to the underlying core theories is
AX4: (forall (c1 x1 e1)
(if (block-V3? c1 x1 e1)
(exist (n1 p1)
(and (cause? c1 x1 n1)(not? n1 p1)(possible? p1 e1)))))
This rule says that for x1 to block some eventuality e1 is for x1 to cause e1 not to be possible. (In this
example, for expositional simplicity, we have allowed the eventuality c1 of blocking be the same as the
eventuality of causing, where properly they should be closely related but not identical.)
The other axioms needed in this example are
AX1: (forall (c1 e1)
(if (and (possible? c1 e1)(etc))
(exist (x1)(can-S1? c1 x1 e1))))
AX2: (forall (d1 x1 c1 r1 x2 x3)
(if (and (cause? d1 x1 c1)(changeTo? c1 r1)(rel? r1 x2 x3)
(deliver-S2? d1 x1 x2 x3))))
AX3: (forall (c1 x1 x2)
(if (enter-S2? c1 x1 x2)
(exist (i1)(and changeTo? c1 i1)(in? i1 x1 x2))))
AX1 says that defeasibly, if an eventuality e1 is possible, then someone can do it. AX2 says that if x1
causes a change to a situation r1 in which x2 in in some relation to x3, then in a very general sense
(S2), x1 has delivered x2 to x3. AX3 says that if c1 is the eventuality of x1 entering x2, then c1 is
the change into a state i1 in which x1 is in x2.
Starting with the logical form of H as the initial interpretation and applying axioms AX1 and AX2,
we get interpretation H1:
H1: (and (not? n2 c2) (possible? c2 d2) (cause? d2 x2 c1)
(changeTo? c1 r1)(rel? r1 o2 u2))
At this point we are stuck in our effort to back-chain to T. An axiom is missing, namely, one that says
that ?in? is a relation between two entities.
AX5: (forall (r x1 x2) (if (in? r1 x1 x2)(rel? r1 x1 x2)))
Using AX5, we can back-chain from H1 and derive interpretation H2:
H2: (and (not? n2 c2)(possible? c2 d2)(cause? d2 x2 c1)
(changeTo? c1 r1)(in? r1 o2 u2))
We can then further back-chain with AX3 to interpretation H3:
200
H3: (and (not? n2 c2)(possible? c2 d2)(cause? d2 x2 c1)
(enter-S2? c1 o2 u2))
Again, we need a missing axiom, AX6, to get closer to the logical form of T:
AX6: (forall (p e1)
(if (and (possible? p,e1)(etc))
(exist (c x1) (and (possible? p c)(cause? c x1 e1)))))
That is, if something is possible, it is possible for something to cause it. Using this axiom, we can derive
H4: (and (not? n2 c2)(possible? c2 c1)(enter-S2? c1 o2 u2))
The final missing axiom, AX7, says that if x1 causes eventuality c2 not to occur, then c2 doesn?t occur.
AX7: (forall (n x1 n1 c2)
(if (and (cause? n x1 n1)(not? n1 c2))( not? n c2)))
Using this we derive interpretation H5.
H5: (and (cause? n2 x3 n)(not? n c2)(possible? c2 c1)(enter-S2? c1 o2 u2))
We can now apply the rule for ?block?, identifying b1 and n2, x1 and x3, e1 and c1, o1 and o2, and
u1 and u2, yielding H6 and establishing the entailment relation between H and T.
H6: (and (block-V3? n2 x3 c1)(enter-S2? c1 o2 u2))
Our second example is the text-hypothesis pair
T: The plane managed to escape the attack.
H: The plane was not captured.
The relevant parts of the logical forms of T and H are as follows:
T: (and (manage-V1? m1 p1 e1)(escape-S1? e1 p1 a1))
H: (and (not? n2 c2)(capture-S1? c2 x2 p2))
The axioms relating these words to the core theories are as follows:
AX1: (forall (cp c x2 n chf a y1 x3 y0 x2)
(if (and (changeTo? cp c)(cause? c x2 n)(not? n chf)
(changeFrom? chf a)(at? a y1 x3)(arg? y0 x2))
(capture? cp y0 y1)))
AX2: (forall (es x0 x1)
(if (escape? es x0 x1)
(exist (ch a)
(and (cause? es x0 ch)(changeFrom? ch a)(at? a x0 x1)))))
AX3: (forall (m y0 e1)
(if (manage? m y0 e1) (Rexist (m e1))))
201
The first says that a change to a situation in which x2 is causing y1 not to change location is a capturing
by some y0 of y1. The second says that escaping implies causing a change from being at a location.
The third says that if you manage to do e1, then e1 occurs.
Using these axioms, we would like to establish the entailment relation from T to H. However, in
order for this reasoning to go through, we need several more axioms?saying that if an eventuality does
not hold, there has been no change to that eventuality, and nothing has caused it to occur; that double
negation cancels out; and that if something is caused, it occurs.
It may seem at first blush that any new text-hypothesis pair will reveal new axioms that must be
encoded, and that therefore it is hopeless ever to achieve completeness in the theories. But a closer
examination reveals that the missing axioms all involve relations among the most fundamental predicates,
like cause, change, not, and possible. These are axioms that should be a part of the core theories
of change and causality. They are not a random collection of facts, any one of which may turn out to
be necessary for any given example. Rather we can investigate the possibilities systematically. That
investigation is what we describe in the following section.
5 Relations among Fundamental Predicates
For completeness in the core theories, we need to look at pairs of fundamental predicates and ask what re-
lations hold between them, what their composition yields, and for each such axiom whether it is defeasi-
ble or indefeasible. The predicates we consider are possible, Rexist, not, cause, changeFrom,
and changeTo.
The first type of axiom formulates the relationship between two predicates. For example, the rule
relating cause and Rexist is
(forall (x e) (if (cause x e)(Rexist e)))
That is, if something is caused, then it actually occurs. Other rules of this type are as follows:
(forall (x e) (if (Rexist e)(possible e)))
(forall (e) (if (and (Rexist e)(etc))(exist (x)(cause x e))))
(forall (e2)
(if (changeTo e2)
(exist (e1)(and (changeFrom e1)(not? e1 e2)))))
(forall (e1)
(if (changeFrom e1)
(exist (e2)(and (changeTo e2)(not? e2 e1)))))
(forall (e) (if (changeTo e)(Rexist e)))
(forall (e) (if (changeFrom e)(not e)))
(forall (e) (if (and (Rexist e)(etc))(changeTo e)))
That is, if something occurs, it is possible and, defeasibly, something causes it. If there is a change to
some state obtaining, then there is a change from its not obtaining, and vice versa. If there is a change
to something, then it obtains, and if there is a change from something, then it no longer obtains. If some
state obtains, then defeasibly there was a change from something else to that state obtaining.
The second type of axiom involves the composition of predicates, and gives us rules of the form
202
(forall (e1 e2 x) (if (and (p? e1 e2)(q? e2 x)) (r? e1 x)))
That is, when p is applied to q, what relation r do we get?
Figure 2 shows the axioms encoding these compositions. The rows correspond to the (p? e1
e2)?s and the columns correspond to the (q? e2 x)?s, and the cell contains the consequents (r? e1
x). If the rule is defeasible, the cell indicates that by adding (etc) to the antecedent. The consequents
in italics are derivable from other rules.
Figure 2: Axioms expressing compositions of fundamental predicates
For example, in the possible-possible cell, the rule says that if it is possible that something
is possible, then it is possible. To take a more complex example, the changeFrom-cause cell says
that if there is a change from some entity causing (or maintaining) a state, then defeasibly there will be a
change from that state. So if a glass is released, it will fall.
We have also looked at axioms whose pattern is the converse of those in Figure 2. For example, if
something does not hold, then it was not caused. Many of the axioms used in the examples are of this
sort.
6 Conclusion
If we are ever to have sophisticated natural language understanding, our systems will have to be able to
draw inferences like the ones illustrated here, and therefore they will need axioms of this complexity or
something equivalent. Because of their complexity, we cannot expect to be able to acquire the axioms
automatically by statistical methods. But that does not mean the situation is bleak. We have shown in
this paper that there is a systematic methodology for developing axioms characterizing the meanings of
words in a way that enforces uniformity and for elaborating the core theories these axioms are anchored
in. Doing this for several thousand of the most common words in English would produce a huge gain in
the inferential power of our systems, as illustrated by the textual entailment examples in this paper, and
would be an enterprise no greater in scope than the manual construction of other widely used resources
such as WordNet and FrameNet.
203
References
[1] Baker, C., Fillmore, C., Cronin, B.: The Structure of the Framenet Database, International Journal of Lexi-
cography, Volume 16.3: (2003) 281-296.
[2] J. Blythe, J. Hobbs, P. Domingos, R. Kate, and R. Mooney, 2011. ?Implementing Weighted Abduction in
Markov Logic?, Proceedings of the 9th International Conference on Computational Semantics, Oxford,
United Kingdom.
[3] Gruber, Jeffrey C., 1965. Studies in Lexical Relations, unpublished Ph.D. dissertation, Massachusetts Institute
of Technology, Cambridge, Massachusetts.
[4] Gruninger, Michael, and Christopher Menzel, 2010. ?The Process Specification Language (PSL) Theory and
Applications?, AI Magazine, Vol 24, No 3.
[5] Hobbs, Jerry R. 1985. ?Ontological Promiscuity.? Proceedings, 23rd Annual Meeting of the Association for
Computational Linguistics, pp. 61-69. Chicago, Illinois, July 1985.
[6] Hobbs, Jerry R., 2008. ?Deep Lexical Semantics?, Proceedings, 9th International Conference on Intelligent
Text Processing and Computational Linguistics (CICLing-2008), Haifa, Israel, February 2008.
[7] Hobbs, Jerry R., Mark Stickel, Douglas Appelt, and Paul Martin, 1993. ?Interpretation as Abduction?, Arti-
ficial Intelligence, Vol. 63, Nos. 1-2, pp. 69-142.
[8] Jackendoff, Ray S. 1972. Semantic interpretation in generative grammar. Cambridge, MA: The MIT Press.
[9] Kipper, Karin, Anna Korhonen, Neville Ryant, and Martha Palmer (2006) Extensive Classifications of En-
glish verbs. Proceedings, 12th EURALEX International Congress. Turin, Italy. September, 2006.
[10] Lakoff, George, 1987. Women, Fire, and Dangerous Things: What Categories Reveal About the Mind, Uni-
versity of Chicago Press, Chicago.
[11] McCarthy, John, 1980. ?Circumscription: A Form of Nonmonotonic Reasoning?, Artificial Intelligence, 13:
27-39.
[12] Mueller, Erik T., 2006. Commonsense Reasoning, Morgan Kaufmann Publishers, Inc., San Mateo, California.
[13] R. Mulkar, J.R. Hobbs, and E. Hovy, 2007. ?Learning from Reading Syntactically Complex Biology Texts?,
Proceedings of the AAAI Spring Symposium Commonsense?07. Stanford University, CA, 2007.
[14] E. Ovchinnikova, N. Montazeri, T. Alexandrov, J. Hobbs, M. McCord, and R. Mulkar-Mehta, 2011. ?Abduc-
tive Reasoning with a Large Knowledge Base for Discourse Processing?, Proceedings of the 9th International
Conference on Computational Semantics, Oxford, United Kingdom.
204
Abductive Reasoning with a Large Knowledge Base
for Discourse Processing
Ekaterina Ovchinnikova
University of Osnabru?ck
eovchinn@uos.de
Niloofar Montazeri
USC ISI
niloofar@isi.edu
Theodore Alexandrov
University of Bremen
theodore@uni-bremen.de
Jerry R. Hobbs
USC ISI
hobbs@isi.edu
Michael C. McCord
IBM Research
mcmccord@us.ibm.com
Rutu Mulkar-Mehta
USC ISI
me@rutumulkar.com
Abstract
This paper presents a discourse processing framework based on weighted abduction. We elabo-
rate on ideas described in Hobbs et al (1993) and implement the abductive inference procedure in a
system called Mini-TACITUS. Particular attention is paid to constructing a large and reliable knowl-
edge base for supporting inferences. For this purpose we exploit such lexical-semantic resources as
WordNet and FrameNet. We test the proposed procedure and the obtained knowledge base on the
Recognizing Textual Entailment task using the data sets from the RTE-2 challenge for evaluation. In
addition, we provide an evaluation of the semantic role labeling produced by the system taking the
Frame-Annotated Corpus for Textual Entailment as a gold standard.
1 Introduction
In this paper, we elaborate on a semantic processing framework based on a mode of inference called
abduction, or inference to the best explanation. In logics, abduction is a kind of inference which arrives
at an explanatory hypothesis given an observation. Hobbs et al (1993) describe how abductive reasoning
can be applied to the discourse processing problem viewing the process of interpreting sentences in
discourse as the process of providing the best explanation of why the sentence would be true. In this
framework, interpreting a sentence means 1) proving its logical form, 2) merging redundancies where
possible, and 3) making assumptions where necessary. As the reader will see later in this paper, abductive
reasoning as a discourse processing technique helps to solve many pragmatic problems such as reference
resolution, the interpretation of noun compounds, the resolution of some kinds of syntactic, and semantic
ambiguity as a by-product. We adopt this approach. Specifically, we use a system we have built called
Mini-TACITUS1 (Mulkar et al, 2007) that provides the expressivity of logical inference but also allows
probabilistic, fuzzy, or defeasible inference and includes measures of the ?goodness? of abductive proofs
and hence of interpretations of texts and other situations.
The success of a discourse processing system based on inferences heavily depends on a knowledge
base. The main contribution of this paper is in showing how a large and reliable knowledge base can be
obtained by exploiting existing lexical semantic resources and can be successfully applied to reasoning
tasks on a large scale. In particular, we experiment with axioms extracted from WordNet, see Fellbaum
(1998), and FrameNet, see Ruppenhofer et al (2006). In axiomatizing FrameNet we rely on the study
described in Ovchinnikova et al (2010).
We evaluate our inference system and the obtained knowledge base in recognizing textual entailment
(RTE). As the reader will see in the following sections, inferences carried out by Mini-TACITUS are
fairly general and not tuned for a particular application. We decided to test our approach on RTE because
this is a well-defined task that captures major semantic inference needs across many natural language
1http://www.rutumulkar.com/download/TACITUS/tacitus.php
225
processing applications, such as question answering, information retrieval, information extraction, and
document summarization. For evaluation, we have chosen the RTE-2 data set (Bar-Haim et al, 2006),
because besides providing text-hypothesis pairs and a gold standard this data set has been annotated with
FrameNet frame and role labels (Burchardt and Pennacchiotti, 2008) which gives us the possibility of
evaluating our frame and role labeling based on the axioms extracted from FrameNet.
2 NL Pipeline and Abductive Reasoning
Our natural language pipeline produces interpretations of texts given the appropriate knowledge base. A
text is first input to the English Slot Grammar (ESG) parser (McCord, 1990, 2010). For each segment,
the parse produced by ESG is a dependency tree that shows both surface and deep structure. The deep
structure is exhibited via a word sense predication for each node, with logical arguments. These logical
predications form a good start on a logical form (LF) for the whole segment. An add-on to ESG converts
the parse tree into a LF in the style of Hobbs (1985). The LF is a conjunction of predications, which have
generalized entity arguments that can be used for showing relationships among the predications. These
LFs are used by the downstream components.
The interpretation of the text is carried out by an inference system called Mini-TACITUS using
weighted abduction as described in detail in Hobbs et al (1993). Mini-TACITUS tries to prove the logical
form of the text, allowing assumptions where necessary. Where the system is able to prove parts of the
LF, it is anchoring it in what is already known from the overall discourse or from a knowledge base.
Where assumptions are necessary, it is gaining new information. Obviously, there are many possible
proofs in this procedure. A cost function on proofs enables the system to chose the ?best? (the cheapest)
interpretation. The key factors involved in assigning a cost are the following: 1) proofs with fewer
assumptions are favored, 2) short proofs are favored over long ones, 3) plausible axioms are favored over
less plausible axioms, and 4) proofs are favored that exploit the inherent implicit redundancy in text.
Let us illustrate the procedure with a simple example. Suppose that we want to construct the best
interpretation of the sentence John composed a sonata. As a by-product, the procedure will disambiguate
between two readings of compose, namely between the ?form? reading instantiated for example in the
sentence Three representatives composed a committee, and the ?create art? meaning instantiated in the
given sentence. After being processed by the parser, the sentence will be assigned the following logical
form where the numbers (20) after every proposition correspond to the default costs of these proposi-
tions.2 The total cost of this logical form is equal to 60.
John(x1):20 & compose(e1,x1,x2):20 & sonata(x2):20
Suppose our knowledge base contains the following axioms:
1) form(e0,x1,x2):90 ? compose(e0,x1,x2)
2) create art(e0,x1,x2):50 & art piece(x2):40 ? compose(e0,x1,x2)
3) art piece(x1):90 ? sonata(x1)
Unlike deductive axioms, abductive axioms should be read ?right to left?. Thus, the propositions on
the right hand side (compose, sonata) correspond to an input, whereas the left hand side propositions
will be assumed given the input. The number assigned to each proposition on the left hand side shows
what percentage of the total input cost the assumption of this proposition will cost.3 For example, if the
proposition compose costs 20 then the assumption of form will cost 18.
Two interpretations can be constructed for the given logical form. The first one is the result of the
application of axioms 1 and 3. Note that the costs of the backchained propositions (compose, sonata) are
2The actual value of the default costs of the input propositions does not matter, because, as the reader will see in this section,
the axiom weights which affect the costs of the resulting interpretations are given as percentages of the input proposition costs.
The only heuristic we use here concerns setting all costs of the input propositions to be equal (all propositions cost 20 in the
discussed example). This heuristic needs a further investigation to be approved or modified.
3The axiom weights in the given example are arbitrary.
226
set to 0, because their costs are now carried by the newly introduces assumptions (form, art piece). The
total cost of the first interpretation I1 is equal to 56.
I1: John(x1):20 & compose(e1,x1,x2):0 & sonata(x2):0 & form(e1,x1,x2):18 & art piece(x2):18
The second interpretation is constructed in two steps. First, axioms 2 and 3 are applied as follows.
I21: John(x1):20 & compose(e1,x1,x2):0 & sonata(x2):0 &
create art(e1,x1,x2):10 & art piece(x2):8 & art piece(x2):18
The total cost of I21 is equal to 56. This interpretation is redundant, because it contains the propo-
sition art piece twice. The procedure will merge propositions with the same predicate, setting the cor-
responding arguments of these propositions to be equal and assigning the minimum of the costs to the
result of merging. The idea behind such mergings is that if an assumption has already been made then
there is no need to make it again. The final form of the second interpretation I22 with the cost of 38
is as follows. The ?create art? meaning of compose has been brought forward because of the implicit
redundancy in the sentence which facilitated the disambiguation.
I22: John(x1):20 & compose(e1,x1,x2):0 & sonata(x2):0 & create art(e1,x1,x2):10 &
art piece(x2):8
Thus, on each reasoning step the procedure 1) applies axioms to propositions with non-zero costs
and 2) merges propositions with the same predicate, assigning the lowest cost to the result of merging.
Reasoning terminates when no more axioms can be applied.4 The procedure favors the cheapest inter-
pretations. Among them, the shortest proofs are favored, i.e. if two interpretations have the same cost
then the one which has been constructed with fewer axiom application steps is considered to be ?better?.
It is easy to see that changing weights of axioms can crucially influence the reasoning process. Axiom
weights can help to propagate more frequent and reliable inferences and to distinguish between ?real?
abduction and deduction. For example, an axiom backchaining from dog to animal should in the general
case have a weight below 100, because it is cheap to assume that there is an animal if there is a dog; it is
a reliable deduction. On the contrary, assuming dog given animal should have a weight above 100.
In order to avoid undesirable mergings, we introduce non-merge constraints. For example, in the
sentence John reads a book and Bill reads a book the two read propositions should not be merged
because they refer to different actions. This is ensured by the following non-merge constraint: if not all
arguments of two propositions (which are not nouns) with the same predicate can be merged, then these
propositions cannot be merged. The constraint implies that in the sentence above two read propositions
cannot be merged, because John being the first argument of the first read cannot be merged with Bill.5
This constraint is a heuristic; it corresponds to the intuition that it is unlikely that the same noun refers to
different objects in a short discourse, while for other parts of speech it is possible. An additional corpus
study is needed in order to prove or disprove it.
The described procedure provides solutions to a whole range of natural language pragmatics prob-
lems, such as resolving ambiguity, discovering implicit relations in nouns compounds, prepositional
phrases, or discourse structure. Moreover, this account of interpretation solves the problem of where to
stop drawing inferences, which could easily be unlimited in number; an inference is appropriate if it is
part of the lowest-cost proof of the logical form.
Adapting Mini-TACITUS to a Large-Scale Knowledge Base
Mini-TACITUS (Mulkar et al, 2007) began as a simple backchaining theorem-prover intended to be a
more transparent version of the original TACITUS system, which was based on Stickel?s PTTP system
(Stickel, 1988). Originally, Mini-TACITUS was not designed for treating large amounts of data. A clear
and clean reasoning procedure rather than efficiency was in the focus of its developers. In order to make
the system work with the large-scale knowledge base, we had to perform several optimization steps and
add a couple of new features.
4In practice, we use the depth parameter d and do not allow an inference chain with more that d steps.
5Recall that only propositions with the same predicate can be merged, therefore John and Bill cannot be merged.
227
For avoiding the reasoning complexity problem, we have introduced two parameters. The time pa-
rameter t is used to restrict the processing time. After the processing time exceeds t the reasoning
terminates and the best interpretation so far is output. The time parameter ensures that an interpretation
will be always returned by the procedure even if reasoning could not be completed in a reasonable time.
The depth parameter d restricts the depth of the inference chain. Suppose that a proposition p occurring
in the input has been backchained and a proposition p? has been introduced as a result. Then, p? will be
backchained and so on. The number of such iterations cannot exceed d. The depth parameter reduces
the number of reasoning steps.
Since Mini-TACITUS processing time increases exponentially with the input size (sentence length
and number of axioms), making such a large set of axioms work was an additional issue. For speeding
up reasoning it was necessary to reduce both the number of the input propositions and the number of
axioms. In order to reduce the number of axioms, a two-step reduction of the axiom set is performed.
First, only the axioms which could be evoked by the input propositions or as a result of backchaining
from the input are selected for each reasoning task. Second, the axioms which could never lead to any
merging are filtered out. Concerning the input propositions, those which could never be merged with the
others (even after backchaining) are excluded from the reasoning process.
3 Knowledge Base
As described in the previous section, the Mini-TACITUS inferences are based on a knowledge base (KB)
consisting of a set of axioms. In order to obtain a reliable KBwith a sufficient coverage we have exploited
existing lexical-semantic resources.
First, we have extracted axioms from WordNet (Fellbaum, 1998), version 3.0, which has already
proved itself to be useful in knowledge-intensive NLP applications. The central entity in WordNet is
called a synset. Synsets correspond to word senses, so that every lexeme can participate in several
synsets. For every word sense, WordNet indicates the frequency of this particular word sense in the
WordNet annotated corpora. We have used the lexeme-synset mapping for generating axioms, with the
corresponding frequencies of word senses converted into the axiom weights. For example, in the axioms
below, the verb compose is mapped to its sense 2 in WordNet which participates in synset-X.
compose-2(e1,x1,x2):80 ? compose(e1,x1,x2)
synset-X(e0,e1):100 ? compose-2(e1,x1,x2)
Moreover, we have converted the following WordNet relations defined on synsets into axioms: hy-
pernymy, instantiation, entailment, similarity, meronymy. Hypernymy and instantiation relations pre-
suppose that the related synsets refer to the same entity (the first axiom below), whereas other types of
relations relate synsets referring to different entities (the second axiom below). All axioms based on
WordNet relations have the weights equal to 100.
synset-1(e0,e1):100 ? synset-2(e0,e1)
synset-1(e0,e1):100 ? synset-2(e2,e3)
WordNet alo provides morphosemantic relations which relate verbs and nouns, e.g., buy-buyer.
WordNet distinguishes between 14 types of such relations.We use relation types in order to define the
direction of the entailment and map the arguments. For example, the ?agent? relation (buy-buyer) stands
for a bi-directional entailment such that the noun is the first (agentive) argument of the verb:
buy-1(e0,x1,x2):100 ? buyer-1(x1)
buyer-1(x1):100 ? buy-1(e0,x1,x2)
Additionally, we have exploited the WordNet synset definitions. In WordNet the definitions are given
in natural language form. We have used the extended WordNet resource6 which provides logical forms
for the definition in WordNet version 2.0. We have adapted logical forms from extended WordNet to our
6http://xwn.hlt.utdallas.edu/
228
representation format and converted them into axioms; for example the following axiom represents the
meaning of the synset containing such lexemes as horseback. These axioms have the total weight of 100.
on(e2,e1,x2):25 & back(e3,x2):25 & of (e4,x2,x1):25 & horse(e5,x1):25 ? synset-X(e0,x0)
The second resource which we have used as a source of axioms is FrameNet, release 1.5, see Rup-
penhofer et al (2006). FrameNet has a shorter history in NLP applications thanWordNet, but lately more
and more researchers have been demonstrating its potential to improve the quality of question answering
(Shen and Lapata, 2007) and recognizing textual entailment (Burchardt et al, 2009). The lexical mean-
ing of predicates in FrameNet is represented in terms of frames which describe prototypical situations
spoken about in natural language. Every frame contains a set of roles corresponding to the participants of
the described situation. Predicates with similar semantics are assigned to the same frame; e.g. both give
and hand over refer to the GIVING frame. For most of the lexical elements FrameNet provides syntactic
patterns showing the surface realization of these lexical elements and their arguments. Syntactic patterns
also contain information about their frequency in the FrameNet annotated corpora. We have used the
patterns and the frequencies for deriving axioms such as for example the following.
GIVING(e1,x1,x2,x3):70 & DONOR(e1,x1):0 & RECIPIENT(e1,x2):0 & THEME(e1,x3):0 ?
give(e1,x1,x3) & to(e2,e1,x2)
HIRING(e1,x1,x3):90 & EMPLOYER(e1,x1) & EMPLOYEE(e1,x3) ?
give(e1,x1,x2,x3):10 & job(x2)
The first pattern above corresponds to the phrases like John gave a book to Mary and the second ?
less frequent ? to phrases like John gave Mary a job. It is interesting to note that application of such
axioms provides a solution to the problem of semantic role labeling as a by-product. As in the statis-
tical approaches, more frequent patterns will be favored. Moreover, patterns helping to detect implicit
redundancy will be brought forward.
FrameNet alo introduces semantic relations defined on frames such as inheritance, causation or
precedence; for example the GIVING and GETTING frames are connected with the causation relation.
Roles of the connected frames are also linked, e.g. DONOR in GIVING is linked with SOURCE in GETTING.
Frame relations have no formal semantics in FrameNet. In order to generate corresponding axioms, we
have used the previous work on axiomatizing frame relations and extracting new relations from corpora
(Ovchinnikova et al, 2010). Weights of the axioms derived from frame relations depend on corpus-based
similarity of the lexical items assigned to the corresponding frames. An example of an axiomatized
relation is given below.7
GIVING(e0,x1,x2,x3):120 & DONOR(e0,x1):0 & RECIPIENT(e0,x2):0 & THEME(e0,x3):0 &
causes(e0,e1):0 ? GETTING(e1,x2,x3,x1) & SOURCE(e1,x1) & RECIPIENT(e1,x2) & THEME(e1,x3)
Both WordNet and FrameNet are manually created resources which ensures a relatively high quality
of the resulting axioms as well as the possibility of exploiting the linguistic information provided for
structuring the axioms. Although manual creation of resources is a very time-consuming task, WordNet
and FrameNet, being long-term projects, have an extensive coverage of English vocabulary. The cover-
age of WordNet is currently larger than that of FrameNet (155 000 vs. 12 000 lexemes). However, the
fact that FrameNet introduces complex argument structures (roles) for frames and provides mappings of
these structures makes FrameNet especially valuable for reasoning.
The complete list of axioms we have extracted from these resources is given in table 1.
4 Recognizing Textual Entailment
As the reader can see from the previous sections, the discourse processing procedure we have presented
is fairly general and not tuned for any particular type of inferences. We have evaluated the procedure and
7The ?causes? predicate is supposed to be linked to an underlying causation theory, see for example
http://www.isi.edu/?hobbs/bgt-cause.text. However, in the described experimental settings we have left the abstract theories
out and evaluated only the axioms extracted from the lexical-semantic resources.
229
Table 1: Statistics for extracted axioms
Axiom type Source Numb. of axioms
Lexeme-synset mappings WN 3.0 422,000
Lexeme-synset mappings WN 2.0 406,000
Synset relations WN 3.0 141,000
Derivational relations WN 3.0 (annotated) 35,000
Synset definitions WN 2.0 (parsed, annotated) 120,500
Lexeme-frame mappings FN 1.5 50,000
Frame relations FN 1.5 + corpora 6,000
the KB derived from WordNet and FrameNet on the Recognizing Textual Entailment (RTE) task, which
is a generic task that seems to capture major semantic inference needs across many natural language
processing applications. In this task, the system is given a text and a hypothesis and must decide whether
the hypothesis is entailed by the text plus commonsense knowledge.
Our approach is to interpret both the text and the hypothesis using Mini-TACITUS, and then see
whether adding information derived from the text to the knowledge base will reduce the cost of the best
abductive proof of the hypothesis as compared to using the original knowledge base only. If the cost
reduction exceeds a threshold determined from a training set, then we predict entailment.
A simple example would be the text John gave a book to Mary and the hypothesis Mary got a book.
Our pipeline constructs the following logical forms for these two sentences.
T: John(x1):20 & give(e1,x1,x2):20 & book(x3):20 & to(e2,e1,x3):20 & Mary(x3):20
H: Mary(x1):20 & get(e1,x1,x2):20 & book(x2):20
These logical forms constitute the Mini-TACITUS input. Mini-TACITUS applies the axioms from
the knowledge base to the input logical forms in order to reduce the overall cost of the interpretations.
Suppose that we have three FrameNet axioms in our knowledge base. The first one maps give to to the
GIVING frame, the second one maps get to GETTING and the third one relates GIVING and GETTING with
the causation relation. The first two axioms have the weights of 90 and the third 120. As a result of the
application of the axioms the following best interpretations will be constructed for T and H.
I(T): John(x1):20 & give(e1,x1,x2):0 & book(x3):20 & to(e2,e1,x3):0 & Mary(x3):20 &
GIVING(e0,x1,x2,x3):18
I(H): Mary(x1):20 & get(e1,x1,x2):0 & book(x2):20 & GETTING(e0,x1,x2):18
The total cost of the best interpretation for H is equal to 58. Now the best interpretation of T will
be added to H with the zero costs (as if T has been totally proven) and we will try to prove H once
again. First of all, merging of the propositions with the same names will result in reducing costs of the
propositions Mary and book to 0, because they occur in T:
I(T+H): John(x1):0 & give(e1,x1,x2):0 & book(x3):0 & to(e2,e1,x3):0 & Mary(x3):0 &
GIVING(e0,x1,x2,x3):0 & get(e1,x1,x2):0 & GETTING(e0,x1,x2):18
The only proposition left to be proved is GETTING. Using the GETTING-GIVING relation as described
in the previous section, this proposition can be backchained on to GIVING which will merge with GIVING
coming from the T sentence. H appears to be proven completely with respect to T; the total cost of its
best interpretation given T is equal to 0. Thus, using knowledge from T helped to reduce the cost of the
best interpretation of H from 58 to 0.
The approach presented does not have any special account for logical connectors such as if, not, or
etc. Given a text If A then B and a hypothesis A and B our procedure will most likely predict entailment.
At the moment our RTE procedure mainly accounts for the informational content of texts, being able to
detect the ?aboutness? overlap of T and H. In our framework, a fuller treatment of the logical structure
230
of the natural language would presuppose a more complicated strategy of merging redundancies.
5 Evaluation Results
We have evaluated our procedure on the RTE-2 dataset 8, see Bar-Haim et al (2006) . The RTE-2
dataset contains the development and the test set, both including 800 text-hypothesis pairs. Each dataset
consists of four subsets, which correspond to typical success and failure settings in different applications:
information extraction (IE), information retrieval (IR), question answering (QA), and summarization
(SUM). In total, 200 pairs were collected for each application in each dataset.
As a baseline we have processed the datasets with an empty knowledge base. Then we have done 2
runs, first, using axioms extracted fromWordNet 3.0 plus FrameNet, and, second, using axioms extracted
from the WordNet 2.0 definitions. In both runs the depth parameter was set to 3. The development
set was used to train the threshold as described in the previous section.9 Table 2 contains results of
our experiments.10 Accuracy was calculated as the percentage of pairs correctly judged. The results
suggest that the proposed method seems to be promising as compared to the other systems evaluated
on the same task. Our best run gives 63% accuracy. Two systems participating the RTE-2 Challenge
had 73% and 75% accuracy, two systems achieved 62% and 63%, while most of the systems achieved
55%-61%, cf. Bar-Haim et al (2006). For our best run (WN 3.0 + FN), we present the accuracy data
for each application separately (table 2). The distribution of the performance of Mini-TACITUS on the
four datasets corresponds to the average performance of systems participating in RTE-2 as reported by
Garoufi (2007). The most challenging task in RTE-2 appeared to be IE. QA and IR follow, and finally,
SUM was titled the ?easiest? task, with a performance significantly higher than that of any other task.11
It is worth noting that the performance of Mini-TACITUS increases with the increasing time of pro-
cessing. This is not surprising. We use the time parameter t for restricting the processing time. The
smaller t is, the fewer chances Mini-TACITUS has for applying all relevant axioms. The experiments
carried out suggest that optimizing the system computationally could lead to producing significantly bet-
ter results. Tracing the reasoning process, we found out that given a long sentence and a short processing
time Mini-TACITUS had time to construct only a few interpretations, and the real best interpretation was
not always among them.
The lower performance of the system using the KB based on axioms extracted from extended Word-
Net can be easily explained. At the moment we define non-merge constraints (see section 2) for the input
propositions only. The axioms extracted from the synset definitions introduce a lot of new lexemes into
the logical form, since these axioms define words with the help of other words rather than abstract con-
cepts. These new lexemes, especially those which are frequent in English, result in undesired mergings
(e.g., mergings of frequent prepositions), since no non-merge constraints are defined for them. In order
to fix this problem, we will need to implement dynamic non-merge constraints which will be added on
the fly if a new lexeme is introduced during reasoning. The WN 3.0 + FN axiom set does not fall into
this problem, because these axioms operate on frames and synsets rather than on lexemes.
In addition, for the run using axioms derived from FrameNet, we have evaluated how well we do
in assigning frames and frame roles. For Mini-TACITUS, semantic role labeling is a by-product of
constructing the best interpretation. But since this task is considered to be important as such in the NLP
community, we provide an additional evaluation for it. As a gold standard we have used the Frame-
Annotated Corpus for Textual Entailment, FATE, see Burchardt and Pennacchiotti (2008). This corpus
provides frame and semantic role label annotations for the RTE-2 challenge test set.12 It is important to
8http://pascallin.ecs.soton.ac.uk/Challenges/RTE2/
9Interpretation costs were normalized to the number of propositions in the input.
10?Time? stands for the value of the time parameter ? processing time per sentence, in minutes; ?Numb. of ax.? stands for
the average number of axioms per sentence.
11In order to get a better understanding of which parts of our KB are useful for computing entailment and for which types of
entailment, in future, we are planning to use the detailed annotation of the RTE-2 dataset describing the source of the entailment
which was produced by Garoufi (2007). We would like to thank one of our reviewers for giving us this idea.
12FATE was annotated with the FrameNet 1.3 labels, while we have been using 1.5 version for extracting axioms. However,
231
Table 2: Evaluation results for the RTE-2 test set
KB Accuracy Time
Numb. of ax.
T H
No KB 57% 1 0 0
WN 3.0 + FN 62% 20 533 237
WN 3.0 + FN 63% 30 533 237
Ext. WN 2.0 60% 20 3700 1720
Ext. WN 2.0 61% 30 3700 1720
Task Accuracy
SUM 75%
IR 64%
QA 62%
IE 50%
Table 3: Evaluation of frames/roles labeling towards FATE
System
Frame match
Recall
Role match
Precision Recall
Shalmaneser 0.55 0.54 0.37
Shalmaneser + Detour 0.85 0.52 0.36
Mini-TACITUS 0.65 0.55 0.30
note that FATE annotates only those frames which are relevant for computing entailment. Since Mini-
TACITUS makes all possible frame assignments for a sentence, we provide only the recall measure for
the frame match and leave the precision out.
The FATE corpus was also used as a gold standard for evaluating the Shalmaneser system (Erk and
Pado, 2006) which is a state-of-the-art system for assigning FrameNet frames and roles. In table 2 we
replicate results for Shalmaneser alone and Shalmaneser boosted with the WordNet Detour to FrameNet
(Burchardt et al, 2005). The WN-FN Detour extended the frame labels assigned by Shalmaneser with
the labels related via the FrameNet hierarchy or by the WordNet inheritance relation, cf. Burchardt et al
(2009). In frame matching, the number of frame labels in the gold standard annotation that can also be
found in the system annotation (recall) was counted. Role matching was evaluated only on the frames
that are correctly annotated by the system. The number of role labels in the gold standard annotation
that can also be found in the system annotation (recall) as well as the number of role labels found by
the system which also occur in the gold standard (precision) were counted.13 Table 3 shows that given
FrameNet axioms, the performance of Mini-TACITUS on semantic role labeling is compatible with those
of the system specially designed to solve this task.
6 Conclusion and Future Work
This paper presents a discourse processing framework underlying the abductive reasoner called Mini-
TACITUS. We have shown that interpreting texts using weighted abduction helps solve pragmatic prob-
lems in discourse processing as a by-product. In this paper, particular attention was paid to the construc-
tion of a large and reliable knowledge base populated with axioms extracted from such lexical-semantic
resources as WordNet and FrameNet. The reasoning procedure as well as the knowledge base were eval-
uated in the Recognizing Textual Entailment task. The data for evaluation were taken from the RTE-2
Challenge. First, we have evaluated the accuracy of the entailment prediction. Second, we have eval-
in the new FN version the number of frames and roles increases and there is no message about removed frames in the General
Release Notes R1.5, see http://framenet.icsi.berkeley.edu. Therefore we suppose that most of the frames and roles used for the
FATE annotation are still present in FN 1.5.
13We do not compare filler matching, because the FATE syntactic annotation follows different standards as the one produced
by the ESG parser, which makes aligning fillers non-trivial.
232
uated frame and role labeling using the Frame-Annotated Corpora for Textual Entailment as the gold
standard. In both tasks our system showed performance compatible with those of the state-of-the art
systems. Since the inference procedure and the axiom set are general and not tuned for a particular task,
we consider the results of our experiments to be promising concerning possible manifold applications of
Mini-TACITUS.
The experiments we have carried out have shown that there is still a lot of space for improving the
procedure. First, for successful application of Mini-TACITUS on a large scale the system needs to be
computationally optimized. In its current state, Mini-TACITUS requires too much time for producing
satisfactory results. As our experiments suggest (cf. table 2), speeding up reasoning may lead to signif-
icant improvements in the system performance. Since Mini-TACITUS was not originally designed for
large-scale processing, its implementation is in many aspects not effective enough. We hope to improve
it by changing the data structure and re-implementing some of the main algorithms.
Second, in the future we plan to elaborate our treatment of natural language expressions standing for
logical connectors such as implication if, negation not, disjunction or and others. Quantifiers such as
all, each, some also require a special treatment. This advance is needed in order to achieve more precise
entailment inferences, which are at the moment based in our approach on the core information content
(?aboutness?) of texts. Concerning the heuristic non-merge constraints preventing undesired mergings
as well as the heuristic for assigning default costs (see section 2), in the future we would like to perform
a corpus study for evaluating and possibly changing these heuristics.
Another future direction concerns the enlargement of the knowledge base. Hand-crafted lexical-
semantic resources such as WordNet and FrameNet provide both an extensive lexical coverage and a
high-value semantic labeling. However, such resources still lack certain features essential for captur-
ing some of the knowledge required for linguistic inferences. First of all, manually created resources
are static; updating them with new information is a slow and time-consuming process. By contrast,
commonsense knowledge and the lexicon undergo daily updates. In order to accommodate dynamic
knowledge, we plan to make use of the distributional similarities of words in a large Web-corpus such
as for example Wikipedia. Many researchers working on RTE have already been using word similarity
for computing similarity between texts and hypotheses, e.g., Mehdad et al (2010). In our approach, we
plan to incorporate word similarities into the reasoning procedure making them affect proposition costs
so that propositions implied by the context (similar to other words in the context) will become cheaper
to prove. This extension might give us a performance improvement in RTE, because it will help to relate
those propositions from H for which there are no appropriate axioms in the KB to propositions in T.
Lexical-semantic resources as knowledge sources for reasoning have another shortcoming: They
imply too little structure. WordNet and FrameNet enable some argument mappings of related synsets or
frames, but they cannot provide a more detailed concept axiomatization. We are engaged in two types of
efforts to obtain more structured knowledge. The first effort is the manual encoding of abstract theories
explicating concepts that pervade natural language discourse, such as causality, change of state, and
scales, and the manual encoding of axioms linking lexical items to these theories. A selection of the core
theories can be found at http://www.isi.edu/ hobbs/csk.html. The second effort concerns making use of
the existing ontologies. The recent progress of the Semantic Web technologies has stimulated extensive
development of the domain-specific ontologies as well as development of inference machines specially
designed to reason with these ontologies.14 In practice, domain-specific ontologies usually represent
detailed and structured knowledge about particular domains (e.g. geography, medicine etc.). We intend
to make Mini-TACITUS able to use this knowledge through querying an externally stored ontology with
the help of an existing reasoner. This extension will give us a possibility to access elaborated domain-
specific knowledge which might be crucial for interpretation of domain-specific texts.
We believe that implementation of the mentioned improvements and extensions will make Mini-
TACITUS a powerful reasoning system equipped with enough knowledge to solve manifold NLP tasks on
a large scale. In our view, the experiments with the axioms extracted from the lexical-semantic resources
presented in this paper show the potential of weighted abduction for natural language reasoning and open
14www.w3.org/2001/sw/,http://www.cs.man.ac.uk/ sattler/reasoners.html
233
new ways for its application.
References
Bar-Haim, R., I. Dagan, B. Dolan, L. Ferro, D. Giampiccolo, B. Magnini, and I. Szpektor (2006). The
second PASCAL recognising textual entailment challenge. In Proc. of the Second PASCAL Challenges
Workshop on Recognising Textual Entailment.
Burchardt, A., K. Erk, and A. Frank (2005). A WordNet Detour to FrameNet. In Sprachtechnologie,
mobile Kommunikation und linguistische Resourcen, Volume 8.
Burchardt, A. and M. Pennacchiotti (2008). FATE: a FrameNet-Annotated Corpus for Textual Entail-
ment. In Proc. of LREC?08.
Burchardt, A., M. Pennacchiotti, S. Thater, and M. Pinkal (2009). Assessing the impact of frame seman-
tics on textual entailment. Natural Language Engineering 15(4), 527?550.
Erk, K. and S. Pado (2006). Shalmaneser - a flexible toolbox for semantic role assignment. In Proc. of
LREC?06, Genoa, Italy.
Fellbaum, C. (Ed.) (1998). WordNet: An Electronic Lexical Database (First ed.). MIT Press.
Garoufi, K. (2007). Towards a better understanding of applied textual entailment: Annotation and eval-
uation of the rte-2 dataset. Master?s thesis, Saarland University.
Hobbs, J. R. (1985). Ontological promiscuity. In Proceedings, 23rd Annual Meeting of the Association
for Computational Linguistics, Chicago, Illinois, pp. 61?69.
Hobbs, J. R., M. Stickel, and P. Martin (1993). Interpretation as abduction. Artificial Intelligence 63,
69?142.
McCord, M. C. (1990). Slot grammar: A system for simpler construction of practical natural language
grammars. In Natural Language and Logic: International Scientific Symposium, Lecture Notes in
Computer Science, pp. 118?145. Springer Verlag.
McCord, M. C. (2010). Using Slot Grammar. Technical report, IBM T. J. Watson Research Center. RC
23978Revised.
Mehdad, Y., A. Moschitti, and F. M. Zanzotto (2010). Syntactic/semantic structures for textual entailment
recognition. In Proc. of HLT ?10: The 2010 Annual Conference of the North American Chapter of the
Association for Computational Linguistics, pp. 1020?1028.
Mulkar, R., J. R. Hobbs, and E. Hovy (2007). Learning from Reading Syntactically Complex Biol-
ogy Texts. In Proc.of the 8th International Symposium on Logical Formalizations of Commonsense
Reasoning. Palo Alto.
Ovchinnikova, E., L. Vieu, A. Oltramari, S. Borgo, and T. Alexandrov (2010). Data-Driven and Onto-
logical Analysis of FrameNet for Natural Language Reasoning. In Proc. of LREC?10, Valletta, Malta.
Ruppenhofer, J., M. Ellsworth, M. Petruck, C. Johnson, and J. Scheffczyk (2006). FrameNet II: Extended
Theory and Practice. International Computer Science Institute.
Shen, D. and M. Lapata (2007). Using Semantic Roles to Improve Question Answering. In Proc. of
EMNLP-CoNLL, pp. 12?21.
Stickel, M. E. (1988). A prolog technology theorem prover: Implementation by an extended prolog
compiler. Journal of Automated Reasoning 4(4), 353?380.
234
Proceedings of the Second Workshop on Metaphor in NLP, pages 33?41,
Baltimore, MD, USA, 26 June 2014.
c
?2014 Association for Computational Linguistics
Abductive Inference for Interpretation of Metaphors
Ekaterina Ovchinnikova*, Ross Israel*, Suzanne Wertheim
+
,
Vladimir Zaytsev*, Niloofar Montazeri*, Jerry Hobbs*
* USC ISI, 4676 Admiralty Way, CA 90292, USA
{katya,israel,vzaytsev,niloofar,hobbs}@isi.edu
+
Worthwhile Research & Consulting, 430 1/2 N Genesee Av., Los Angeles, CA 90036, USA
worthwhileresearch@gmail.com
Abstract
This paper presents a metaphor interpre-
tation pipeline based on abductive infer-
ence. In this framework following (Hobbs,
1992) metaphor interpretation is modelled
as a part of the general discourse pro-
cessing problem, such that the overall dis-
course coherence is supported. We present
an experimental evaluation of the pro-
posed approach using linguistic data in
English and Russian.
1 Introduction
In this paper, we elaborate on a semantic pro-
cessing framework based on a mode of inference
called abduction, or inference to the best expla-
nation. In logic, abduction is a kind of inference
which arrives at an explanatory hypothesis given
an observation. (Hobbs et al., 1993) describe how
abduction can be applied to the discourse process-
ing problem, viewing the process of interpreting
sentences in discourse as the process of providing
the best explanation of why the sentence would be
true. (Hobbs et al., 1993) show that abductive rea-
soning as a discourse processing technique helps
to solve many pragmatic problems such as refer-
ence resolution, the interpretation of noun com-
pounds, detection of discourse relations, etc. as a
by-product. (Hobbs, 1992) explains how abduc-
tion can be applied to interpretation of metaphors.
The term conceptual metaphor (CM) refers
to the understanding of one concept or concep-
tual domain in terms of the properties of another
(Lakoff and Johnson, 1980; Lakoff, 1987). For ex-
ample, development can be understood as move-
ment (e.g., the economy moves forward, the en-
gine of the economy). In other words, a concep-
tual metaphor consists in mapping a target con-
ceptual domain (e.g., economy) to a source do-
main (e.g., vehicle) by comparing their properties
(e.g., an economy develops like a vehicle moves).
In text, conceptual metaphors are represented by
linguistic metaphors (LMs), i.e. natural language
phrases expressing the implied comparison of two
domains.
We present a metaphor interpretation approach
based on abduction. We developed an end-to-
end metaphor interpretation system that takes text
potentially containing linguistic metaphors as in-
put, detects linguistic metaphors, maps them to
conceptual metaphors, and interprets conceptual
metaphors in terms of both logical predicates and
natural language expressions. Currently, the sys-
tem can process linguistic metaphors mapping
predefined target and source domains.
We perform an experimental evaluation
of the proposed approach using linguistic
data in two languages: English and Rus-
sian. We select target concepts and generate
potential sources for them as described at
github.com/MetaphorExtractionTools/mokujin.
For top-ranked sources, we automatically find cor-
responding linguistic metaphors. These linguistic
metaphors are each then validated by three expert
linguists. For the validated linguistic metaphors,
we generate natural language interpretations,
which are also validated by three experts.
2 Related Work
Automatic interpretation of linguistic metaphors is
performed using two principal approaches: 1) de-
riving literal paraphrases for metaphorical expres-
sions from corpora (Shutova, 2010; Shutova et
al., 2012) and 2) reasoning with manually coded
knowledge (Hobbs, 1992; Narayanan, 1999; Barn-
den and Lee, 2002; Agerri et al., 2007; Veale and
Hao, 2008).
(Shutova, 2010; Shutova et al., 2012) present
methods for deriving paraphrases for linguis-
tic metaphors from corpora. For example, the
metaphorical expression "a carelessly leaked re-
33
port" is paraphrased as "a carelessly disclosed re-
port". This approach currently focuses on single-
word metaphors expressed by verbs only and does
not explain the target?source mapping.
The KARMA (Narayanan, 1999) and the ATT-
Meta (Barnden and Lee, 2002; Agerri et al., 2007)
systems perform reasoning with manually coded
world knowledge and operate mainly in the source
domain. The ATT-Meta system takes logical ex-
pressions that are representations of a small dis-
course fragment as input; i.e., it does not work
with natural language. KARMA focuses on dy-
namics and motion in space. For example, the
metaphorical expression the government is stum-
bling in its efforts is interpreted in terms of motion
in space: stumbling leads to falling, while falling
is a conventional metaphor for failing.
(Veale and Hao, 2008) suggest to derive
common-sense knowledge from WordNet and cor-
pora in order to obtain concept properties that can
be used for metaphor interpretation. Simple in-
ference operations, i.e. insertions, deletions and
substitution, allow the system to establish links be-
tween target and source concepts.
(Hobbs, 1992) understands metaphor interpre-
tation as a part of the general discourse processing
problem. According to Hobbs, a metaphorical ex-
pression should be interpreted in context. For ex-
ample, John is an elephant can be best interpreted
as "John is clumsy" in the context Mary is grace-
ful, but John is an elephant. In order to obtain
context-dependent interpretations, (Hobbs, 1992)
uses abductive inference linking parts of the dis-
course and ensuring discourse coherence.
3 Metaphor Interpretation System
Our abduction-based metaphor interpretation sys-
tem is shown in Fig. 1. Text fragments possibly
containing linguistic metaphors are given as in-
put to the pipeline. The text fragments are parsed
and converted into logical forms (section 3.1).
The logical forms are input to the abductive rea-
soner (section 3.2) that is informed by a knowl-
edge base (section 4). The processing component
labelled "CM extractor & scorer" extracts con-
ceptual metaphors from the logical abductive in-
terpretations and outputs scored CMs and Target-
Source mappings (section 3.3). The Target-Source
mappings are then translated into natural language
expressions by the NL generator module (sec-
tion 3.4).
3.1 Logical Form Generation
A logical form (LF) is a conjunction of propo-
sitions which have argument links showing rela-
tionships among phrase constituents. We use logi-
cal representations of natural language texts as de-
scribed in (Hobbs, 1985). In order to obtain LFs
we convert dependency parses into logical repre-
sentations in two steps: 1) assign arguments to
each lemma, 2) apply rules to dependencies in or-
der to link arguments.
Consider the dependency structure for the sen-
tence, John decided to leave: [PRED decide
[SUBJ John] [OBJ leave]]. First, we
generate unlinked predicates for this structure:
John(e
1
, x
1
)?decide(e
2
, x
2
, x
3
)?leave(e
3
, x
4
).
Then, based on the dependency labels, we link
argument x
1
with x
2
, x
3
with e
3
, and x
1
with
x
4
to obtain the following LF: John(e
1
, x
1
) ?
decide(e
2
, x
1
, e
3
) ? leave(e
3
, x
1
).
LFs are preferable to dependency structures in
this case because they generalize over syntax and
link arguments using long-distance dependencies.
Furthermore, we need logical representations in
order to apply abductive inference.
In order to produce logical forms for English,
we use the Boxer semantic parser (Bos et al.,
2004). As one of the possible formats, Boxer
outputs logical forms of sentences in the style of
(Hobbs, 1985). For Russian, we use the Malt de-
pendency parser (Nivre et al., 2006). We devel-
oped a converter turning Malt dependencies into
logical forms in the style of (Hobbs, 1985).
1
3.2 Abductive Inference
In order to detect conceptual metaphors and in-
fer explicit mappings between target and source
domains, we employ a mode of inference called
weighted abduction (Hobbs et al., 1993). This
framework is appealing because it is a realization
of the observation that we understand new mate-
rial by linking it with what we already know.
Abduction is inference to the best explanation.
Formally, logical abduction is defined as follows:
Given: Background knowledge B, observations
O, where both B and O are sets of first-order log-
ical formulas,
Find: A hypothesis H such that H ?B |= O,H ?
B 6|=?, where H is a set of first-order logical for-
mulas.
1
The converter is freely available at
https://github.com/eovchinn/Metaphor-ADP.
34
Figure 1: Abduction-based metaphor interpretation system.
Typically, there exist several hypotheses H ex-
plaining O. To rank hypotheses according to plau-
sibility and select the best hypothesis, we use
the framework of weighted abduction (Hobbs et
al., 1993). Frequently, the best interpretation re-
sults from identifying two entities with each other,
so that their common properties only need to be
proved or assumed once. Weighted abduction fa-
vors those interpretations that link parts of obser-
vations together and supports discourse coherence,
which is crucial for discourse interpretation.
According to (Hobbs, 1985), metaphor interpre-
tation can be modelled as abductive inference re-
vealing conceptual overlap between the target and
the source domain. Consider the abductive inter-
pretation produced for the sentence We intend to
cure poverty, Fig. 2. In the top line of the figure,
we have the LF (cf. Sec. 3.1), where we can see
that a person (x
1
) is the agent for the verbs intend
(e
1
) and cure (e
2
) and that poverty (x
2
) is the ob-
ject of cure. In the first box in the next row, we
see that cure invokes the source concepts of DIS-
EASE, CURE, and DOCTOR, where DISEASE is
the object of CURE, and DOCTOR is the subject.
In the same row, we see that poverty invokes the
POVERTY concept in the target domain. Impor-
tantly, POVERTY and DISEASE share the same
argument (x
2
), which refers to poverty.
The next row contains two boxes with ellipses,
representing long chains of common-sense infer-
ences in the source and target domains of DIS-
EASE and POVERTY, respectively. For DIS-
EASE we know that linguistic tokens such as ill-
ness, sick, disease, etc. cause the afflicted to expe-
rience loss of health, loss of energy, and a general
lack of productivity. For POVERTY, we know that
tokens such as poor, broke, poverty mean that the
experiencer of poverty lacks money to buy things,
take care of basic needs, or have access to trans-
portation. The end result of both of these frame-
works is that the affected individuals (or commu-
nities) cannot function at a normal level, with re-
spect to unaffected peers. We can use this common
meaning of causing the individual to not function
to link the target to the source.
The next three rows provide the mapping
from the meaning of the source (CURE, DOC-
TOR, DISEASE) concepts to the target concept
(POVERTY). As explained above, we can con-
sider DISEASE as a CAUSING-AGENT that can
CAUSE NOT FUNCTION; POVERTY can be ex-
plained the same way, at a certain level of abstrac-
tion. Essentially, the interpretation of poverty in
this sentence is that it causes some entity not to
function, which is what a DISEASE does as well.
For CURE, we see that cure can CAUSE NOT EX-
IST, while looking for a CAUSING-AGENT (per-
son) and an EXISTING DISEASE (poverty).
In our system, we use the implementation of
weighted abduction based on Integer Linear Pro-
gramming (ILP) (Inoue and Inui, 2012), which
makes the inference scalable.
3.3 CM Extractor and Scorer
The abductive reasoning system produces an inter-
pretation that contains mappings of lexical items
into Target and Source domains. Any Target-
Source pair detected in a text fragment constitutes
a potential CM. For some text fragments, the sys-
tem identifies multiple CMs. We score Target-
Source pairs according to the length of the depen-
dency path linking them in the predicate-argument
structure. Consider the following text fragment:
opponents argue that any state attempting to force
an out-of-state business to do its dirty work of tax
collection violates another state?s right to regulate
its own corporate residents and their commerce
35
Figure 2: Abductive interpretation for the sentence We intend to cure poverty.
Suppose our target domain is TAXATION, trig-
gered by tax collection in the sentence above. In
our corpus, we find realizations of the CM TAXA-
TION is an ENEMY (fight against taxes). The lex-
eme opponent triggers the STRUGGLE/ENEMY
domain. However, the sentence does not trigger
the CM TAXATION is an ENEMY. Instead, it in-
stantiates the CM TAXATION is DIRT (dirty work
of tax collection). The length of the dependency
path between dirty and tax is equal to 2, whereas
the path between opponent and tax is equal to
9. Therefore, our procedure ranks TAXATION is
DIRT higher, which corresponds to the intuition
that target and source words should constitute a
syntactic phrase in order to trigger a CM.
3.4 NL Representation of Metaphor
Interpretation
The output of the abduction engine is similar to
the logical forms provided in Fig. 2. In order to
make the output more reader friendly, we produce
a natural language representation of the metaphor
interpretation using templates for each CM. For
example, the text their rivers of money mean they
can offer far more than a single vote would invoke
the WEALTH is WATER CM, and the abduction
engine would output: LARGE-AMOUNT[river],
THING-LARGE-AMOUNT[money]. We then
take this information and use it as input for the
NL generation module to produce: "river" implies
that there is a large amount of "money".
4 Knowledge Base
In order to process metaphors with abduction, we
need a knowledge base that encodes the informa-
tion about the source domain, the target domain,
and the relationships between sources and targets.
We develop two distinct sets of axioms: lexical ax-
ioms that encode lexical items triggering domains,
and mapping axioms that encode knowledge used
to link source and target domains. We will discuss
the details of each axiom type next.
4.1 Lexical Axioms
Every content word or phrase that can be expected
to trigger a source or target domain is included as a
lexical axiom in the knowledge base. For example,
the STRUGGLE domain contains words like war,
fight, combat, conquer, weapon, etc. An example
of how a lexical axiom encodes the system logic is
given in (1). On the left side, we have the linguistic
token, fight, along with its part-of-speech, vb, and
the argument structure for verbs where e
0
is the
eventuality (see (Hobbs, 1985)) of the action of
fighting, x is the subject of the verb, and y is the
object. On the right side, STRUGGLE is linked to
the action of fighting, the subject is marked as the
AGENT, and the object is marked as the ENEMY.
(1) fight-vb(e
0
, x, y) ? STRUGGLE(e
0
)?
AGENT (x, e
0
) ? ENEMY (y, e
0
)
The lexicon is not limited to single-token en-
tries; phrases can be included as single entries; For
example, the ABYSS domain has phrases such as
climb out of as a single entry. Encoding phrases
often proves useful, as function words can often
help to distinguish one domain from others. In
this case, climbing out of something usually de-
notes an abyss, whereas climbing up or on usually
does not. The lexical axioms also include the POS
36
for each word. Thus a word like fight can be en-
tered as both a noun and a verb. In cases where a
single lexical axiom could be applied to multiple
domains, one can create multiple entries for the
axiom with different domains and assign weights
so that a certain domain is preferred over others.
Initial lexical axioms for each domain were de-
veloped based on intuition about each domain.
We then utilize ConceptNet (Havasi et al., 2007)
as a source for semi-automatically extracting a
large-scale lexicon. ConceptNet is a multilingual
semantic network that establishes links between
words and phrases. We query ConceptNet for
our initial lexical axioms to return a list of related
words and expressions.
4.2 Mapping Axioms
Mapping axioms provide the underlying meanings
for metaphors and link source and target domains.
All of these axioms are written by hand based
on common-sense world knowledge about each
target-source pair. For each CM, we consider a
set of LMs that are realizations of this CM in an
effort to capture inferences that are common for
all of the LMs. We consider the linguistic contexts
of the LMs and overlapping properties of the tar-
get and source domains derived from corpora as
described in section 5.1.
We will outline the process of axiomatizing the
STRUGGLE domain here. We know that a verb
like fight includes concepts for the struggle it-
self, an agent, and an enemy. In the context of
a STRUGGLE, an enemy can be viewed as some
entity a that attempts to, or actually does, inhibit
the functioning of some entity b, often through ac-
tual physical means, but also psychologically, eco-
nomically, etc. The struggle, or fight, itself then,
is an attempt by a to rid itself of b so that a can en-
sure normal functionality. So, given a phrase like
poverty is our enemy, the intended meaning is that
poverty is hindering the functionality of some en-
tity (an individual, a community, a country, etc.)
and is seen as a problem that must be fought,
i.e. eliminated. In a phrase like the war against
poverty, war refers to an effort to stop the exis-
tence of poverty. These inferences are supported
by the overlapping property propositions extracted
from English Gigaword as described in Sec. 5.1,
e.g., scourge of X, country fights X, country pulls
of X, suffer from X, fight against X.
To extend the example in (1), consider (2).
Here, we encode a STRUGGLE action, e.g. fight,
as CAUSE NOT EXIST, the AGENT of the
fight as CAUSING-AGENT, and the ENEMY as
EXISTING-THING. Then, for a verb phrase like
we fight poverty, we is the AGENT that engages in
causing poverty, the ENEMY, to not exist.
(2) STRUGGLE(e
0
) ? AGENT (x, e
0
) ?
ENEMY (y, 2
0
)?CAUSE(e
0
)?CAUSED(n, e
0
)?
NOT (n, ex) ? EXIST (ex) ? CAUSING ?
AGENT (x, e
0
) ? EXISTING? THING(y, ex)
We use 75 mapping axioms to cover the valid
LMs discussed in Sec. 5.2. Some interesting
trends emerge when examining the core meanings
of the LMs. Following (Hobbs, 2005), we found
that over 65% of the valid LMs in this study could
be explained in terms of causality. The next most
prevalent aspect that these metaphors touch upon
is that of functionality (nearly 35%), with some of
these overlapping with the causality aspect where
the meaning has to do with X causing Y to function
or not function.
Many of the CMs covered in this study have
fairly transparent interpretations based on these
ideas of causality and functionality, such as
POVERTY is DISEASE, where the main under-
lying meaning is that a disease causes the suf-
ferer not to function properly. However, for some
CMs, the interpretation can be more difficult to
pin down. For example, the interpretation of
WEALTH is a GAME is quite opaque. Given a
sentence such as, Wealth is a game and you better
start playing the game, there are no obvious con-
nections to concepts such as causality or function-
ality. Instead, game raises such ideas as competi-
tion, winning, and losing. In the literal context of a
game, the competition itself, who the competitors
are, and what it means to win or lose are usually
clearly defined, but this is not so when speaking
metaphorically about wealth. To derive a meaning
of game that can apply to wealth, we must look
at a higher level of abstraction and define game as
the instantiation of a positive or negative outcome,
i.e. to win is to achieve a positive outcome, or
gain wealth. In the same sentence play implies that
some voluntary action must be taken to achieve a
positive outcome.
For some metaphors, a simple transfer of the
source properties to the target does not result in
a coherent interpretation at all. Given, for exam-
ple, the CM POVERTY is a PRICE, one LM from
this study is, poverty is the price of peace. In this
case, the meaning has to do with some notion of
37
an exchange, where a negative consequence must
be accepted in order to achieve a desired outcome.
However, the metaphorical meaning of price dif-
fers from the literal meaning of the word. In literal
contexts, price refers to an amount of money or
goods with inherent value that must be given to ac-
quire something; the buyer has a supply of money
or goods that they willingly exchange for their
desired item. In the metaphorical sense, though,
there often is no buyer, and there is certainly not
an inherent value that can be assigned to poverty,
nor can one use a supply of it to acquire peace.
Another issue concerns cultural differences.
While writing the axioms to deal with English and
Russian source-target pairs we noticed that a ma-
jority of the axioms applied equally well to both
languages. However, there are some subtle dif-
ferences of aspect that impact the interpretation
of similar CMs across the two languages. Look-
ing again at the WEALTH is a GAME metaphor,
the Russian interpretation involves some nuance
of a lack of importance about the subject that
does not seem to be present in English when us-
ing words like game and play. Note that there
may be some notion of carelessness for English
(see Sec. 5.3), but for Russian, the notion of being
carefree, which is not the same as careless, about
wealth has a strong prevalence.
5 Experimental Validation
5.1 Source Generation
Following from the definition of metaphor, the tar-
get and the source domain share certain proper-
ties. In natural language, concepts and properties
are represented by words and phrases. There is
a long-standing tradition for considering compu-
tational models derived from word co-occurrence
statistics as being capable of producing reason-
able property-based descriptions of concepts (Ba-
roni and Lenci, 2008). We use proposition stores
to derive salient properties of concepts that can be
potentially compared in a metaphor.
A proposition store is a collection of proposi-
tions such that each proposition is assigned its fre-
quency in a corpus. Propositions are tuples of
words that have a determined pattern of syntactic
relations among them (Clark and Harrison, 2009;
Pe?as and Hovy, 2010; Tsao and Wible, 2013).
For example, the following propositions can be ex-
tracted from the sentence John decided to go to
school:
(NV John decide)
(NV John go)
(NVPN John go to school)
...
We generated proposition stores from parsed
English Gigaword (Parker et al., 2011) and Rus-
sian ruWac (Sharoff and Nivre, 2011). Given the
proposition stores, we generate potential sources
for a seed target lexeme l in three steps:
1. Find all propositions P
l
containing l.
2. Find all potential source lexemes S such that
for each s ? S there are propositions p, p
?
in the proposition store such that l occurs at
position i in p and s occurs at position i in p
?
.
The set of propositions containing l and s at
the same positions is denoted by P
l,s
.
3. Weight potential sources s ? S using the fol-
lowing equation:
weight
l
(s) =
?
p?P
l,s
weight
l
(t), (1)
The source generation procedure and
its validations are described in detail at
github.com/MetaphorExtractionTools/mokujin.
2
In the experiment described below, we gener-
ated potential sources for the target domains of
POVERTY and WEALTH.
5.2 Linguistic Metaphors Extraction and
Validation
For each potential CM, we look for supporting
LMs in corpora. A a large number of LMs sup-
porting a particular CM suggests that this CM
might be cognitively plausible. We use a simple
method for finding LMs. If a target lexeme and
a source lexeme are connected by a dependency
relation in a sentence, then we assume that this
dependency structure contains a LM. For exam-
ple, in the phrases medicine against poverty and
chronic poverty, the target word (poverty) is re-
lated via dependency arc with the source words
(medicine, chronic). LMs were extracted from En-
glish Gigaword (Parker et al., 2011) and Russian
ruWac (Sharoff and Nivre, 2011).
For the generated CMs, we select seed lexemes
for target and source domains. We expand the
2
The tools for generating proposition stores
and the obtained resources are freely available at
https://ovchinnikova.me/proj/metaphor.html.
38
sets of these target and source lexemes with se-
mantically related lexemes using English and Rus-
sian ConceptNet (Speer and Havasi, 2013) and top
ranked patterns from the proposition stores. For
example, the expansion of the lexeme disease re-
sults in the following set of lexemes: {disease,
symptom, syndrome, illness, unwellness, sickness,
sick, medicine, treatment, treat, cure, doctor, ... }
For each language, we select 20 top-ranked
sources per target. Then we randomly select at
most 10 sentences per each target-source pair.
These sentences are validated by 3 linguist experts
each. For each sentence, the experts are asked if
it contains a metaphor comparing an indicated tar-
get domain with an indicated source domain. The
inter-annotator agreement on the validation task is
defined as the percentage of judgements on which
the three experts agree. Agreement is 81% for En-
glish and 80% for Russian.
Tables 1 and 2 show 10 potential sources per
target with the best agreement. Column ALL pro-
vides the number of sentences per a proposed CM
such that all experts agreed that the sentence con-
tains a metaphor. Column TWO provides the num-
ber of sentences such that any two experts agreed
on, and Column ONE shows the number of sen-
tences such that a single expert thought it con-
tained a metaphor.
target source ALL TWO ONE
w
e
a
l
t
h
blood 10 10 10
water 9 10 10
drug 9 10 10
food 9 9 10
body 9 9 10
power 8 9 10
game 8 9 9
security 7 9 10
resource 7 7 9
disease 7 8 9
p
o
v
e
r
t
y
war 10 10 10
abyss 10 10 10
violence 9 9 10
price 8 9 9
location 7 8 8
disease 7 7 7
crime 4 5 6
crop 3 7 9
terrorism 3 3 5
cost 2 3 7
Table 1: Validation of English linguistic
metaphors found for potential sources.
5.3 Metaphor Interpretation Validation
Metaphor interpretations were generated for posi-
tively validated linguistic metaphors, as described
?
?
?
?
?
?
?
?
?
(
w
e
a
l
t
h
)
??????? (energy) 10 10 10
???? (water) 10 10 10
??????? (freedom) 10 10 10
?????? (power) 9 10 10
??? (god) 9 10 10
????? (blood) 9 10 10
???? (way) 9 10 10
???? (game) 8 10 10
????? (glory) 4 5 5
????? (ware) 3 8 10
?
?
?
?
?
?
?
?
(
p
o
v
e
r
t
y
)
???????? (abyss) 10 10 10
???? (enemy) 9 10 10
??????? (disease) 9 9 9
?????? (power) 8 10 10
???? (body) 6 6 6
???? (pain) 5 10 10
???????? (despair) 5 10 10
???? (price) 4 4 4
?????? (death) 3 5 6
????? (fear) 3 9 10
Table 2: Validation of Russian linguistic
metaphors found for potential sources.
in Sec. 3.4. Each interpretation was validated by
three expert linguists. We calculated strict and
relaxed agreement for the validated data. Strict
agreement is calculated over three categories: cor-
rect (C), partially correct (P), and incorrect (I). Re-
laxed agreement is calculated over two categories:
C/P and I. Partially correct means that the valida-
tor felt that something was missing from the inter-
pretation, but that what was there was not wrong.
Table 3 presents the validation results for both lan-
guages. As can be seen in the table, strict agree-
ment (AgrS) is 62% and 52% and strict system
accuracy (AccS ALL) is 62% and 50% for En-
glish and Russian, respectively. Relaxed agree-
ment (AgrR) results is 93% and 83%, and relaxed
accuracy (AccR ALL) is 91% and 78%.
Validators often marked things as only partially
correct if they felt that the interpretation was lack-
ing some aspect that was critical to the meaning of
the metaphor. A common feeling amongst the val-
idators, for example, is that the interpretation for
people who are terrorized by poverty should in-
clude some mention of "fear" as a crucial aspect
of the metaphor, as the interpretation provided
states only that "terrorize" implies that "poverty"
is causing "people" not to function. However, the
end result of "fear" itself is often that the experi-
encer cannot function, as in paralyzed by fear.
Tables 4 and 5 contain interpretation system ac-
curacy results by CM. We calculated the percent-
age of LMs evoking this CM that were validated
as C vs. I (strict) or P/C vs. I (relaxed) by all three
39
AgrS AgrR AccS ALL AccS TWO AccS ONE AccR ALL AccR TWO AccR ONE
English 0.62 0.93 0.62 0.84 0.98 0.91 0.97 0.99
Russian 0.52 0.83 0.50 0.76 0.96 0.78 0.93 0.99
Table 3: Validation results for metaphor interpretation for English and Russian.
(ALL), or just two (TWO) validators. In most of
the cases, the system performs well on "simple"
CMs related to the concepts of causation and func-
tioning (e.g., WEALTH is POWER), cf. section 4,
whereas its accuracy is lower for richer metaphors
(e.g., WEALTH is a GAME).
target source
ALL TWO
S R S R
w
e
a
l
t
h
blood 0.8 1 1 1
water 1 1 1 1
drug 0.44 0.78 0.89 0.89
food 0.89 1 1 1
body 0.67 0.78 0.78 0.78
power 1 1 1 1
game 0.63 1 1 1
security 0.14 0.88 0.71 1
resource 1 1 1 1
disease 0 1 1 1
p
o
v
e
r
t
y
war 0.9 0.9 1 1
abyss 0 0.5 0.4 1
violence 0 1 0.11 1
price 0.88 0.88 0.88 1
location 1 1 1 1
disease 0.43 0.86 0.86 0.86
crime 0.75 1 1 1
crop 1 1 1 1
terrorism 0 1 0.33 1
cost 1 1 1 1
Table 4: Accuracy of English interpretations for
each CM.
The data used in the described experiments, sys-
tem output, and expert validations are available
at http://ovchinnikova.me/suppl/AbductionSystem-
Metaphor-Validation.7z.
6 Conclusion and Future Work
The developed abduction-based metaphor
interpretation pipeline is available at
https://github.com/eovchinn/Metaphor-ADP
as a free open-source project. This pipeline
produces favorable results, with metaphor in-
terpretations that are rated as at least partially
correct, for over 90% of all valid metaphors it is
given for English, and close to 80% for Russian.
Granted, the current research is performed using a
small, controlled set of metaphors, so these results
could prove difficult to reproduce on a large scale
where any metaphor is possible. Still, the high
accuracies achieved on both languages indicate
T source
ALL TWO
S R S R
?
?
?
?
?
?
?
?
?
(
w
e
a
l
t
h
)
??????? (energy) 0.4 0.8 0.9 1
???? (water) 0 0.9 0.6 0.9
??????? (freedom) 1 1 1 1
?????? (power) 1 1 1 1
??? (god) 0.67 1 0.89 1
????? (blood) 1 1 1 1
???? (way) 0.78 0.78 0.89 0.89
???? (game) 0.1 0.2 0.2 0.3
????? (glory) 0 0.75 0.75 1
????? (ware) 0 0 0 1
?
?
?
?
?
?
?
?
(
p
o
v
e
r
t
y
)
???????? (abyss) 0.7 1 1 1
???? (enemy) 0.56 1 1 1
??????? (disease) 0.33 0.89 0.67 1
?????? (power) 0.5 0.5 1 1
???? (body) 0.17 0.17 0.17 0.83
???? (pain) 1 1 1 1
???????? (despair) 0.6 0.6 1 1
???? (price) 0.75 0.75 1 1
?????? (death) 0 0 0.33 1
????? (fear) 0 1 0.67 1
Table 5: Accuracy of Russian interpretations for
each CM.
that the approach is sound and there is potential
for future work.
The current axiomatization methodology is
based mainly on manually writing mapping ax-
ioms based on the axiom author?s intuition. Ob-
viously, this approach is subject to scrutiny re-
garding the appropriateness of the metaphors and
faces scalability issues. Thus, developing new au-
tomatic methods to construct the domain knowl-
edge bases is a main area for future consideration.
The mapping axioms present a significant chal-
lenge as far producing reliable output automati-
cally. One area for consideration is the afore-
mentioned prevalence of certain underlying mean-
ings such as causality and functionality. Gather-
ing enough examples of these by hand could lead
to generalizations in argument structure that could
then be applied to metaphorical phrases in cor-
pora to extract new metaphors with similar mean-
ings. Crowd-sourcing is another option that could
be applied to both axiom writing tasks in order to
develop a large-scale knowledge base in consid-
erably less time and at a lower cost than having
experts build the knowledge base manually.
40
References
R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Walling-
ton. 2007. Metaphor, inference and domain-
independent mappings. In Proc. of RANLP?07,
pages 17?23.
J. A. Barnden and M. G. Lee. 2002. An artificial intel-
ligence approach to metaphor understanding. Theo-
ria et Historia Scientiarum, 6(1):399?412.
M. Baroni and A. Lenci. 2008. Concepts and proper-
ties in word spaces. Italian Journal of Linguistics,
20(1):55?88.
J. Bos, S. Clark, M. Steedman, J. R. Curran, and
J. Hockenmaier. 2004. Wide-coverage semantic
representations from a ccg parser. In Proc. of COL-
ING?04, pages 1240?1246.
P. Clark and P. Harrison. 2009. Large-scale extrac-
tion and use of knowledge from text. In Proc. of the
5th international conference on Knowledge capture,
pages 153?160. ACM.
Catherine Havasi, Robert Speer, and Jason Alonso.
2007. Conceptnet 3: a flexible, multilingual se-
mantic network for common sense knowledge. In
Recent Advances in Natural Language Processing,
Borovets, Bulgaria, September.
J. R. Hobbs, M. Stickel, P. Martin, and D. Edwards.
1993. Interpretation as abduction. Artificial Intelli-
gence, 63:69?142.
J. R. Hobbs. 1985. Ontological promiscuity. In Proc.
of ACL, pages 61?69, Chicago, Illinois.
J. R. Hobbs. 1992. Metaphor and abduction. In
A. Ortony, J. Slack, and O. Stock, editors, Com-
munication from an Artificial Intelligence Perspec-
tive: Theoretical and Applied Issues, pages 35?58.
Springer, Berlin, Heidelberg.
Jerry R. Hobbs. 2005. Toward a useful concept of
causality for lexical semantics. Journal of Seman-
tics, 22(2):181?209.
N. Inoue and K. Inui. 2012. Large-scale cost-based
abduction in full-fledged first-order predicate logic
with cutting plane inference. In Proc. of JELIA,
pages 281?293.
G. Lakoff and M. Johnson. 1980. Metaphors we Live
by. University of Chicago Press.
G. Lakoff. 1987. Women, fire, and dangerous things:
what categories reveal about the mind. University
of Chicago Press.
S. Narayanan. 1999. Moving right along: A computa-
tional model of metaphoric reasoning about events.
In Proc. of AAAI/IAAI, pages 121?127.
J. Nivre, J. Hall, and J. Nilsson. 2006. Maltparser:
A data-driven parser-generator for dependency pars-
ing. In Proc. of LREC?06, volume 6, pages 2216?
2219.
R. Parker, D. Graff, J. Kong, K. Chen, and K. Maeda.
2011. English gigaword fifth edition. LDC.
A. Pe?as and E. H. Hovy. 2010. Filling knowledge
gaps in text for machine reading. In Proc. of COL-
ING?10, pages 979?987.
S. Sharoff and J. Nivre. 2011. The proper place of
men and machines in language technology: Process-
ing Russian without any linguistic knowledge. In
Proc. Dialogue 2011, Russian Conference on Com-
putational Linguistics.
E. Shutova, T. Van de Cruys, and A. Korhonen. 2012.
Unsupervised metaphor paraphrasing using a vector
space model. In COLING (Posters), pages 1121?
1130.
E. Shutova. 2010. Automatic metaphor interpretation
as a paraphrasing task. In Proc. of NAACL?10.
R. Speer and C. Havasi. 2013. Conceptnet 5: A large
semantic network for relational knowledge. In The
People?s Web Meets NLP, pages 161?176. Springer.
N. Tsao and D. Wible. 2013. Word similarity us-
ing constructions as contextual features. In Proc.
JSSP?13, pages 51?59.
T. Veale and Y. Hao. 2008. A fluid knowledge repre-
sentation for understanding and generating creative
metaphors. In Proc. of COLING?08, pages 945?952.
ACL.
41
