Balto-Slavonic Natural Language Processing 2007, June 29, 2007, pages 59?66,
Prague, June 2007. c?2007 Association for Computational Linguistics
Multi-word Term Extraction for Bulgarian
Svetla Koeva
Department of Computational Linguistics ? IBL
Bulgarian Academy of Sciences
52 Shipchenski prohod Blv. Sofia 1113, Bulgaria
svetla@ibl.bas.bg
Abstract
The goal of this paper is to compile a 
method for multi-word term extraction,
taking into account both the linguistic 
properties of Bulgarian terms and their 
statistical rates. The method relies on the 
extraction of term candidates matching 
given syntactic patterns followed by statis-
tical (by means of Log-likelihood ratio) 
and linguistically (by means of inflec-
tional clustering) based filtering aimed at 
improving the coverage and the precision 
of multi-word term extraction. 
1 Introduction
The goal of this paper is to compile a method for 
multi-word term extraction, taking into account
both the linguistic properties of Bulgarian terms 
and their statistical rates. Term extraction exploits
well-established techniques that seem difficult to 
improve significantly. As in many other areas of 
computational linguistics, term extraction has been
approached generally with three different strategies 
? linguistic techniques, statistical techniques and a 
combination of both (Bourigault et al, 2001; Jac-
quemin & Bourigault, 2000). The linguistically 
based techniques exploit the morpho-syntactic 
structure of terms that usually differ from one lan-
guage to another (for example in Bulgarian and in 
English the most frequent syntactic structure repre-
senting terms is the noun phrase, but the two lan-
guages significantly differ in their constituent 
structure and agreement properties). The automatic 
extraction of term morpho-syntactic patterns, being 
in most cases language-dependent, requires spe-
cific language processing ? Part-of-speech (POS) 
tagging, lemmatization, syntactic parsing, etc. The 
statistical techniques, on the other hand, rely on the 
different statistical features of terms compared to 
other words in the text and are usually based on the 
detection of words and expressions with a fre-
quency value higher than a given limit. Some of 
the statistical approaches focus on the association 
measures between the components of the multi-
word terms. Hybrid approaches, combining lin-
guistic and statistical techniques, are also applied, 
mainly in two manners: statistical proceeding is 
used to filter the term candidates obtained through 
linguistic techniques, and, vice versa, some lin-
guistic filters are exploited after statistical process-
ing, in order to extract the statistically significant 
word combinations that match some given syntac-
tic patterns.
The method for automatic multi-word term ex-
traction, presented in this paper, also relies both on 
linguistic knowledge and on statistical processing. 
The research aims are to:
? Apply syntactic patterns of Bulgarian 
terms directed to multi-word term extraction;
? Use well-known statistical methods (asso-
ciation measures) to eliminate some of the irrele-
vant multi-word terms;
? Further limit the number of invalid terms 
by clustering term candidates around their lem-
mas; 
? Test the performance of such a method
over the manually annotated corpus.
59
Most of the current methods for automatic term 
extraction are developed for English, and thus they 
are not appropriate for direct adaptation to Bulgar-
ian, due to the morpho-syntactic differences be-
tween the two languages. Bulgarian is a language 
with a rich inflectional system. That is to say, a 
noun lemma can appear in six forms if it is mascu-
line and in four forms if it is feminine or neuter. 
Besides, noun phrase structure and agreement
properties in Bulgarian differ in some aspects from 
other languages such as English, Therefore, a lan-
guage-specific approach is needed if we want to 
utilise the morpho-syntactical information for term 
extraction. To the best of our knowledge there is 
no report of an extensive work directed towards
Bulgarian term extraction.
The structure of our paper outlines the three 
steps involved in our approach. In the following 
section we present a short linguistic analysis of 
Bulgarian terms. In the third section, we describe 
the identification of the candidate terms. The 
fourth section explains how we applied a list of 
terms to the filters. We then evaluate our results on 
a corpus that was set up by manual annotation. Fi-
nally, we discuss some peculiarities of the pre-
sented study and propose future works to be done.
2 Linguistic analysis of Bulgarian terms
2.1. Compilation of a term annotated corpus
We share the views that larger corpora not only
give statistically more reliable counts, but also re-
veal phenomena that are completely lacking in 
smaller samples. The Acquis Communautaire 
(AC) 1 ? the European Union legislation, which 
consists of approximately eight thousand docu-
ments containing approximately 40 million words 
(to be more specific, its Bulgarian subpart) ? is 
targeted as the most appropriate resource for our 
research: because of its size, and because of the 
number of languages included in it. (The proposed 
method can be further transformed and/or evalu-
ated to deal with the rest of the languages repre-
sented in the parallel corpus.) 
The AC contains documents from several do-
mains, which are divided into chapters: Agricul-
ture, Fisheries, Transport Policy, Taxation, 
Economic and Monetary Union, Statistics, Social 
                                                
1 There has been some experience of exploiting the AC as a 
multilingual corpus (Steinberger at al., 2006).
Policy and Employment, Energy, Industrial Policy, 
Education and Training, Telecommunication and 
Information Technologies, Culture and Audio-
visual Policy, etc. This annotated subpart of the 
Bulgarian AC is developed as a test corpus and 
contains 10,521 words from randomly selected text 
samples representing the domains of Agriculture 
(AGR), Energy (ENR) and Education and Training 
(EDC). 
Some criteria for the manual annotation of Bul-
garian terms were defined, the notion of term 
among others. As with most linguistic concepts, a
term is defined in various ways. For example, as ?a 
word or expression that has a precise meaning in 
some uses or is peculiar to a science, art, profes-
sion? (Webster, 2002), or as ?a word or expression 
used for some particular thing?2, or generally as 
words or phrases that denote specific concepts in a 
given subject domain. For the purposes of this in-
vestigation we defined a term as
An open class word or expression that is peculiar 
to a specific domain of human activities and occurs 
with a determinate (in some limits) frequency in 
that domain.
The annotation of terms in the Bulgarian AC 
subpart is also based on both the maximum and 
minimum length term selection. That is, in the case 
of a multi-word term which constituents are also 
terms, the longest term (as well as all shorter
terms) is selected. It should be pointed out, how-
ever, that the term annotated corpus is still small 
enough to be representative of the word frequency
and is a sample of translated texts that might mani-
fest different tendencies for a term?s distribution 
from those in the original texts.
2.2. Single-word terms vs. multi-word terms
The general impression is that the most of the pa-
pers dealing with automatic term extraction (espe-
cially the statistically based ones) are focused on 
multi-word terms. This can be explained by the 
fact that for English a bigger percentage of multi-
word terms comparing to single-word terms is re-
ported. To show the tendency for the correlation 
between single-word and multi-word terms in Bul-
garian texts, the manually annotated subpart of the 
Bulgarian AC has been studied. We found out (Ta-
ble 1.) that the proportion of single-word terms 
                                                
2 http://wordnet.princeton.edu
60
varies from about 2.5% to 3% depending on the 
subject domain.
The results show that the use of single-word 
terms in Bulgarian technical documents is also not 
very frequent and the tendency is that multi-word 
terms are preferred to single-word ones. Following 
these observations, first we will concentrate on the 
extraction of the Bulgarian multi-word terms.
Domain AGR ENR EDC Total
#Words 4423 3002 3096 10521
#Terms (T) 344 297 254 895
#Multi-word T 266 165 171 602
#Single-word T 111 89 93 293
% Terms 7,77 9,89 8,2 8,5
% Single-word T 2,5 2,96 3 2,78
Table 1. Distribution of single-word terms
2.3 Syntactic structures of Bulgarian terms
The starting point for the linguistically motivated 
part of the automatic term extraction is to describe 
the syntactic structure of Bulgarian terms. There 
are several Bulgarian terminological dictionaries 
published and some terminological databases 
available on the internet ? all recourses are taken 
into consideration in the analysis without providing 
exact calculations. The collection of Bulgarian 
terms, obtained by the annotated subpart of the 
Bulgarian AC, is used as a source for the determi-
nation of the most frequent syntactic structures of 
Bulgarian terms. 
It is claimed that NPs constitute about 80-99 % 
of whole terms in an English text, with the varying 
percentage depending on the text types (Arppe, 
1995). The same statement is roughly true for Bul-
garian; although there are some adjectives and 
verbs that can be regarded as terms in a certain 
domain (only three verbs and one adjective are de-
tected in the annotated corpus). In this study we 
have concentrated on the NPs? term extraction,
which comprises the focus of interest in several 
studies (Jacquemin, 2001; Justeson & Katz, 1995;
Voutanen, 1993).
In order to obtain the statistics, the annotated part 
of Bulgarian AC is pre-processing. This allows the 
consequences of the categories constituting Bul-
garian terms to be extracted and their frequency to 
be calculated. As a result, 16 different sequences of 
categories are obtained, among them 5 with a rate 
higher than 11 %. In the next examples the most 
frequent syntactic patterns of the Bulgarian multi-
word terms are listed following their frequency 
rate:
? AN ? riboloven sezon (fishing season), 
iglolistno darvo (conifer), zemedelski ceni (firm 
prices), termalna energiya (thermal energy), kli-
matichna instalaciya (air-conditioning);
? NpN ? obogatyavane na gorivo (fuel en-
richment), podobryavane na pochvata (soil im-
provement), prava na deteto (children's rights), 
svoboda na pechata (freedom of the press);
? NpAN ? opazvane na okolnata sreda
(environmental protection), nomenklatura na 
zemedelskite produkti (agricultural product no-
menclature), izpolzvane na slanchevata energiya
(solar energy end-use applications), sredstva za 
masova informaciya (media);
? AAN ? semeyno zemedelsko stopanstwo
(family farming), evropeyska parichna sistema
(European Monetary System), inteligentna 
transportna sistema (intelligent transport sys-
tem), magniten informacionen nositel (magnetic 
medium);
? ANpN ? elektronen transfer na fondove
(electronic funds transfer), optichesko raz-
poznavane na simvoli (Optical Character Recog-
nition), pravna uredba na telekomunikaciite
(regulation of telecommunications), izbiratelno 
razprostranenie na informaciya (selective dis-
semination of information).
Among the five types, the AN structure was 
the most frequent one, although the exact percent-
age still remains to be calculated over the bigger 
corpus. 
The main differences observed concerning these 
five Bulgarian structures and their English equiva-
lents are the regular agreement between the adjec-
tival modifier and the head noun in Bulgarian and 
the prepositional phrase in Bulgarian instead the
noun modifier in English. The adjective-noun 
agreement in Bulgarian noun phrases is partially
exploited in the presented piece of work, but it 
might be extensively considered in further im-
provements of the method. 
In the case of NpN, NpAN and ANpN structures,
we found out that most of the terms corresponding 
to these patterns are built up with the Bulgarian 
61
preposition na (of). This may be explained by the 
fact that these PPs usually correspond to the Eng-
lish NPs with a noun modifier denoting more spe-
cific concepts. The possible strings of categories 
that might constitute the Bulgarian terms are ex-
ploited due to the fact that Bulgarian terms usually 
do not allow other constituents among their parts.
2.4 Term variations
Some authors have pointed out the discrepancy
between term representation in dictionaries, and 
the term forms used in real texts (Daille, 2003). It 
is well known that the same concept can be formu-
lated in different ways and the automatic term ex-
traction should be able to recognize and link those 
different linguistic forms or expressions. Different 
kinds of term variants are distinguished in the lit-
erature: orthographic variants (capitalization), in-
flectional variants (word forms), morpho-syntactic 
variants (derivation), syntactic variants (word or-
der differences) and semantic variants (syno-
nyms).
In this study only the orthographic and inflec-
tional variants are taken into consideration. It 
should be pointed out that compared to lemmas 
the multi-word terms have their own inflective 
rules. The POS of the head word determines the 
clustering of the term into grammatical classes,
such as noun, adjective, and so on, which define 
the possible slots in the paradigm. 
The significant grammatical categories inherent 
to the lemma of the head word (such as gender for 
nouns), the number and POS of the remaining 
constituents and the options for inserting some 
words (such as particles) in the multi-word term 
structure all show the grouping of multi-word 
terms? grammatical subclasses and define which 
slots of the paradigm are realized in the language.
And finally, the formation of word forms of each 
component of a multi-word term and the type of 
agreement dependencies between components 
show the classification of multi-word terms into 
grammatical types that describe the real word 
paradigm belonging to a particular term (Koeva, 
2005).
For instance, the Bulgarian term klimatichna in-
stalaciya (air-conditioning) is a noun phrase; the 
members of the paradigm are determined by the 
head feminine noun. The inflection type is deter-
mined by the inflectional alternations of each 
member (the adjective and the noun):
klimatichna instalaciya ? singular, indefinite
klimatichnata instalaciya ? singular, definite
klimatichni instalaciii ? plural, indefinite
klimatichnite instalaciii ? plural, definite
There are agreement dependencies between 
adjective and head noun and no other words? in-
tervention or word order changes are allowed.
3 Automatic term extraction
3.1 Pre-processing of the Bulgarian AC
It is common practice to extract candidate terms 
using a part-of-speech (POS) tagger and an 
automaton (a program extracting word sequences
corresponding to predefined POS patterns). The 
part-of-speech tagging is the process of automati-
cally identifying the words in a text as correspond-
ing to a particular part of speech. The part-of-
speech tagger used in this study is developed utiliz-
ing a large manually annotated corpus consisting 
of 197,000 tokens (150,000 words) randomly ex-
tracted from the Bulgarian Brawn corpus 
(1,000,000 words) (Koeva et al, 2006). The tagger 
has been developed as a modified version of the 
Brill tagger (Brill, 1994). The Brill tagger was 
trained for Bulgarian using a part of the tagged 
corpus. We applied a rule-based approach leading 
to 98.3% precision. A sophisticated tokenizer that
recognizes sentence boundaries and categorizes 
tokens as words, abbreviations, punctuation, nu-
merical expressions, hours, dates and URLs has 
been built as a part of the tagger. For each word in 
the text the initial (most probable) part of speech 
among the ambiguity set is assigned from a large 
inflectional dictionary (Koeva, 1998). 
The words that are not recognized by the dic-
tionary are handled by the guesser analyzing the 
suffixes of the unrecognized words and assigning 
the initial part of speech among the ambiguity set. 
The part-of-speech ambiguity ratio calculated over 
the annotated corpus is 1.51 tags per word, which 
means that on average every second word is am-
biguous. For solving the ambiguity, 144 contextual 
rules are implemented, utilizing the part of speech 
and dictionary information on the context, Some 
additional techniques for the optimizations are im-
plemented ? the application of dictionaries of ab-
breviations, proper nouns, grammatically unambi-
guous words, etc. After POS tagging the text re-
62
mains unchanged and the additional information is 
added in an xml format.
Lemmatization is the process of automatic de-
termining the lemma for a given word. Since the 
lemmatization involves fixing the part of speech of 
a word, it requires the running of a tagger. Lemma-
tization is closely related to stemming. The differ-
ence is that a stemmer operates on a single word 
without explicit knowledge of its identity as a part 
of speech, its lemma or its inflectional properties. 
For Bulgarian a large inflectional dictionary is 
used both for lemmatization and stemming. 
The tag sets differ both in how the words are di-
vided into categories, and in how their categories 
are defined. For the purposes of this investigation 
the grammatical information characterizing the 
forms is also assigned to nouns and adjectives, be-
cause the adjective-noun agreement is exploited.  
3.2 Extraction of term candidates
Following the frequency analysis of the constituent 
structure of the Bulgarian multi-word terms, the 
targeted syntactic patterns will be recognized by 
the following regular expression:
[(A+N(pA*N)?)(NpA*N)]
The strings of categories bellow will be matched;
those with more than two adjectives are either rare, 
or not observed in the language:
AN, AAN, NpN, NpAN, ANpN, ANpAN, 
NpAAN, ANpAAN, AANpAAN, ?
The regular expression does not match the single 
Ns as well as the NPs with low frequently ? only 
the five syntactic patterns with the highest fre-
quency rate are targeted for the term extraction. 
Moreover, the agreement features of the Bulgarian 
NP structures are exploited considering the unifica-
tion of grammatical features between the preceding 
adjective and the immediate following adjective or 
noun. Based on patterns? matching, the term can-
didates corresponding to the above regular expres-
sions are extracted:
? AN ? osnovno obrazovanie (basic educa-
tion),
? AAN ? novi obrazovatelni metodi (new 
educational methods), evropeyska audiovi-
zualna zona (European audiovisual area), 
? NpN ? ezik za programirane 
(programming language), 
? NpAN ? planirane na uchebnata godina
(planning of the school year), elekronna 
obrabotka na danni (electronic data 
processing), potrebitel na ingormacionna 
tehnologiya (information technology user), etc. 
On the other hand, the following phrases (which 
are annotated as terms) are not recognized: 
? NpVpN ? aparat za vazproizwodstvo na 
zvuk (sound reproduction equipment), 
? AcAN ? poshtenski i telekomunikacionni 
uslugi (postal and telecommunications ser-
vices),
? NpNpNN ? sistema za upravlenie na 
baza danni (database management system), etc. 
A deficiency of the approach based on the syntac-
tic patterns is also the fact that any NP that 
matches the patterns will be selected as a term 
candidate, as is shown in the following examples:
? AN ? novi metodi (new methods), 
ogranicheno dvizhenie (limited circulation), 
? NpN ? analiz na informaciya (informa-
tion analysis), broy na uchenicite (number of 
pupils), etc. 
Some of the noun phrases are wrongly extracted, 
although in this case this is concerned with a com-
positional building of structures that cannot be 
considered as that of multi-word terms. Some term 
candidates with a preposition cannot be treated 
even as phrases, because their parts belong to dif-
ferent sentence constituents. The identification of
the sub-phrases that are themselves also terms
should also be taken into account. In the following 
example, sistema za upravlenie na baza ot danni
(database management system), the phrases sis-
tema za uprawlenie (management system), uprav-
lenie na baza ot danni (database management) and 
baza ot danni (database) are also terms.
Domain AGR ENG EDC Total
#Words 4,423 3,002 3,096 10,521
#Term candidates 901 778 712 2,391
Table 2. Number of term candidates
The number of extracted term candidates de-
pends on the structure of the sentences that occur 
in the selected domains. Table 2 shows the ex-
tracted term candidates from a Bulgarian AC sub-
63
part representing texts from the Agriculture, En-
ergy and Education domains.
4 Filtering of term candidates
As a filtering mechanism we adopted the calculat-
ing of the associativity between words, which is 
often used to identify word collocations, and the 
term clustering according to the inflexional para-
digms.
4.1 Statistical filtering
The frequency-based techniques applied to term 
filtering assign a numerical value to sets of words 
to rank term candidates and exclude those term 
candidates below a certain threshold. The state-
ment that the more frequently a lexical unit appears 
in a given document the more likely it is that this 
unit has a terminological function can be applied to 
certain genres of texts. Alone, frequency is not a 
robust metric for assessing the terminological 
property of a candidate. 
In our case, we want to measure the cohesion of 
a multi-word candidate term by verifying if its 
words occur together as a coincidence or not. As-
sociation measures are often used to rate the corre-
lation of word pairs (Daille, 1995; Daille et al, 
1998).
B !B
A Nii Nij N1p
!A Nji Njj N2p
Np1 Np2 Npp
Table 3. The contingency table
These measures can be derived from the contin-
gency table (Table 3.) of the word pair (A,B) con-
taining the observed frequencies of (A,B), as fol-
lows:
Nii  = the joint frequency of word A and word B;
Nij = the frequency word A occurs and word B
does not;
Nji = the frequency word B occurs and word A
does not;
Njj = the frequency word A and word B do not oc-
cur;
Npp = the total number of ngrams;
Np1, Np2, N1p, N2p are the marginal counts.
The lexical association measures are formulas 
that relate the observed frequencies to the expected 
frequency (Mij = (Np1 * N1p) / Npp) under the 
assumption that A and B are independent. For the 
current work, the Log-likelihood coefficient has 
been employed (Dunning, 1993), as it is reported 
to perform well among other scoring methods
(Daille, 1995). 
Log-likelihood = 2 * ? ( Nij * log( Nij / Mij) )
This calculation over the text serves as an impor-
tant technique in identifying term candidates. The 
larger the value of Log-likelihood is, the stronger 
is the association between the two pairs of the 
string; consequently the string is the most probable 
candidate. Statistic filtering is applied only to those 
term candidates extracted by the linguistic compo-
nent. For the calculation, the Ngram Statistics 
Package (NSP), programs that aids in analyzing 
ngrams, is executed (Banerjee & Pedersen, 2003). 
The NSP takes text files (in our case Cyrillic letters 
are transliterated into Latin) as input and generates 
a list of bigrams along with their frequencies as 
outputs. Over the list of bigrams obtained, the Log-
likelihood is run to compute a ratio for each ngram. 
The bigrams are targeted because some of the term 
candidates initially extracted are long ones contain-
ing sub-phrases that are likely to function as term 
candidates. In order to avoid potential term candi-
dates being included in other longer phrases, the 
term candidates are split and the constituting bi-
grams are generated.
As a result of statistical filtering, the initially se-
lected term candidates are assigned different values 
according to their word association. The Log-
likelihood coefficient computed for each bigram is 
used to decide whether or not there is enough evi-
dence to reject or accept a bigram - there is a clear
opposition between small and big values. Below 
the first five ranked candidates are listed.
1. evropeyskata obshtnost (European community) 
2. atomna energiya (nuclear energy) 
3. detska gradina (kindergarten) 
4. Darzhaven vestnik (government newspaper)
5. obrazovatelna sistema (educational system) 
4.2 Linguistic filtering
The linguistic filtering aims at linking the different 
variations of the same basic term. The list of the 
automatically extracted terms was reviewed by 
64
means of lemmatization in order to refine it and to 
increase the score of some terms. Until this stage 
the different word forms of a term were calculated 
separately. Bulgarian is a highly inflected language 
? the forms of the head noun can vary from one to 
seven depending of the gender, number and refer-
ences to a person. The sequences of lemmas be-
longing to the term candidates are processed and 
the frequency values are recalculated according to 
the grouping of terms in one inflectional cluster 
with respect to the common canonical form. 
Through this technique morphologically-related 
occurrences, such as iglolistno darvo (a conifer), 
iglolistnoto darvo (the conifer), iglolistni darveta
(conifers) and iglolistnite darveta (the conifers) are 
treated as one term.
5 Evaluation
The presented method of identifying Bulgarian 
multi-word terms was applied on the manually an-
notated corpus. First the texts were pre-processed 
by means of POS tagging and lemmatization, then 
the target syntactic patterns were extracted, and the 
rates of the related bigrams were calculated by 
means of Log-likelihood association, and finally 
additional reordering of term candidates was per-
formed by means of inflectional clustering. As a 
result, 430 (from 539) correctly extracted multi-
word terms are obtained ? the precision of 79.96% 
is registered.
6 Conclusions and future work
We have presented a method aimed at extracting 
Bulgarian multi-word terms, which relies on the 
extraction of syntactic patterns from text and on 
the statistical and linguistically based filtering
aimed at improving the coverage and the precision 
of multi-word collocation extraction. We have ap-
plied Log-likelihood ratio statistical filtering to the 
extracted multi-word terms. All extracted term 
candidates are grammatically correct, due to the 
syntactically based pattern matching. Further de-
velopments of the method include:
? Statistical determination of single-word 
terms;
? Coverage of long-distance occurrence and 
rare syntactic structures of multi-word terms;
? Analyzing the embedded terms.
? Using 'stop lists' of open and closed class 
words that are hardly to be found in the multi-
word terms. 
Some other experiments will be made using
other well-known techniques of association meas-
ure. For the evaluation purposes the test corpus 
will be extended. A bigger homogeneous corpus 
would undoubtedly result in an increase in terms 
with more representative frequencies, and, there-
fore, in an improvement in statistical estimation of 
terms. The results can be exploited in the multilin-
gual term extraction, due to the fact that the AC 
represents the biggest multilingual parallel corpus.
References
A. Aprre 1995. Term Extraction from Unrestricted Text:
10th Nordic Conference of Computational Linguistics 
(NoDaLiDa), Helsinki. 
S. Banerjee and T. Pedersen 2003. The Design, Imple-
mentation, and Use of the Ngram Statistics Package, 
Proceedings of the Fourth International Conference 
on Intelligent Text Processing and Computational 
Linguistics, Mexico City.
D. Bourigault, C. Jacquemin, and M.-C. L'Homme 
2001. Recent Advances in Computational Terminol-
ogy, volume 2 of Natural Language Processing, John 
Benjamins.
E. Brill 1994. Some Advances In Rule-Based Part of 
Speech Tagging AAAI, Seattle, Washington
B. Daille 1995. Combined approach for terminology 
extraction: lexical statistics and linguistic filtering. 
Technical paper. UCREL, Lancaster University. 
B. Daille 2003. Conceptual structuring through term 
variations, Proceedings of the ACL Workshop on Mul-
tiword Expressions: Analysis, Acquisition and Treat-
ment.
B. Daille, E. Gaussier, and J.-M. Lange 1998. An 
Evaluation of Statistical Scores for Word Association, 
in J. Ginzburg, Z. Khasidashvili, C. Vogel, J.-J. Levy, 
and E. Vallduvi (eds), The Tbilisi Symposium on
Logic, Language and Computation: Selected Papers, 
CSLI Publications, p. 177-188. 
T. Dunning 1993. Accurate methods for thestatistics of 
surprise and coincidence,. Computational Linguistics, 
19(1):61?74.
65
C. Jacquemin 2001. Spotting and Discovering Terms 
through Natural Language Processing. MIT Press.
C. Jacquemin and D. Bouricault 2000. Chapter 19 Term 
Extraction and Automatic Indexing, Handbook of 
Computational Linguistics (R. Mitkov (ed.)), Oxford 
University Press, Oxford.
J. S. Justeson and S. M. Katz 1995. Technical Termi-
nology: Some Linguistic Properties and an Algorithm 
for Identification in Text, Natural Language Engi-
neering. 1(1):9-27.
S. Koeva 1998. Bulgarian Grammatical dictionary. Or-
ganization of the language data, Bulgarian language, 
vol. 6: 49-58.
S. Koeva 2005. Inflection Morphology of Bulgarian 
Multiword Expressions, Computer Applications in 
Slavic Studies ? Proceedings of Azbuki@net, Interna-
tional Conference and Workshop, Sofia, 201-216.
S. Koeva, S. Leseva, I. Stoyanova, E. Tarpomanova, 
and M. Todorova 2006. Bulgarian Tagged Corpora, 
Proceedings of the Fifth International Conference 
Formal Approaches to South Slavic and Balkan Lan-
guages, Sofia, 78-86.
R. Steinberger,  B. Pouliquen, A. Widiger, C. Ignat, T. 
Erjavec, D. Tufi?, and D. Varga 2006. The JRC-
Acquis: A multilingual aligned parallel corpus with 
20+ languages, Proceedings of the 5th International 
Conference on Language Resources and Evaluation
(LREC'2006), Genoa.
A. Voutilainen. 1993. NPtool. A detector of English 
noun phrases, Proceedings of the Workshop on Very 
Large Corpora, Columbus, Ohio.
66
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 6?10,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
 
 
Harnessing NLP Techniques in the Processes of  
Multilingual Content Management 
 
 
Anelia Belogay Diman Karagyozov 
Tetracom IS Ltd. Tetracom IS Ltd. 
anelia@tetracom.com diman@tetracom.com 
Svetla Koeva Cristina Vertan 
Institute for Bulgarian Language Universitaet Hamburg 
svetla@dcl.bass.bg cristina.vertan@uni-hamburg.de 
Adam Przepi?rkowski Polivios Raxis 
Instytut Podstaw Informatyki Polskiej 
Akademii Nauk 
Atlantis Consulting SA 
adamp@ipipan.waw.pl raxis@atlantisresearch.gr 
Dan Cristea  
Universitatea Alexandru Ioan Cuza  
dcristea@info.uaic.ro  
 
 
Abstract 
The emergence of the WWW as the main 
source of distributing content opened the 
floodgates of information. The sheer 
volume and diversity of this content 
necessitate an approach that will reinvent 
the way it is analysed. The quantitative 
route to processing information which 
relies on content management tools 
provides structural analysis. The 
challenge we address is to evolve from 
the process of streamlining data to a level 
of understanding that assigns value to 
content. 
We present an open-source multilingual 
platform ATALS that incorporates 
human language technologies in the 
process of multilingual web content 
management. It complements a content 
management software-as-a-service 
component i-Publisher, used for creating, 
running and managing dynamic content-
driven websites with a linguistic 
platform. The platform enriches the 
content of these websites with revealing 
details and reduces the manual work of 
classification editors by automatically 
categorising content. The platform 
ASSET supports six European languages. 
We expect ASSET to serve as a basis for 
future development of deep analysis tools 
capable of generating abstractive 
summaries and training models for 
decision making systems. 
Introduction 
The advent of the Web revolutionized the way in 
which content is manipulated and delivered. As a 
result, digital content in various languages has 
become widely available on the Internet and its 
sheer volume and language diversity have 
presented an opportunity for embracing new 
methods and tools for content creation and 
distribution. Although significant improvements 
have been made in the field of web content 
management lately, there is still a growing 
demand for online content services that 
incorporate language-based technology. 
Existing software solutions and services such 
as Google Docs, Slingshot and Amazon 
implement some of the linguistic mechanisms 
addressed in the platform. The most used open-
source multilingual web content management 
6
  
systems (Joomla, Joom!Fish, TYPO3, Drupal)1 
offer low level of multilingual content 
management,   providing abilities for building 
multilingual sites. However, the available 
services are narrowly focused on meeting the 
needs of very specific target groups, thus leaving 
unmet the rising demand for a comprehensive 
solution for multilingual content management 
addressing the issues posed by the growing 
family of languages spoken within the EU. 
We are going to demonstrate the open-source 
content management platform ATLAS and as 
proof of concept, a multilingual library i-
librarian, driven by the platform. The 
demonstration aims to prove that people reading 
websites powered by ATLAS can easily find 
documents, kept in order via the automatic 
classification, find context-sensitive content, find 
similar documents in a massive multilingual data 
collection, and get short summaries in different 
languages that help the users to discern essential 
information with unparalleled clarity. 
The ?Technologies behind the system? chapter 
describes the implementation and the integration 
approach of the core linguistic processing 
framework and its key sub-components ? the 
categorisation, summarisation and machine-
translation engines. The chapter ?i-Librarian ? a 
case study? outlines the functionalities of an 
intelligent web application built with our system 
and the benefits of using it. The chapter 
?Evaluation? briefly discusses the user 
evaluation of the new system. The last chapter 
?Conclusion and Future Work? summarises the 
main achievements of the system and suggests 
improvements and extensions. 
Technologies behind the system 
The linguistic framework ASSET employs 
diverse natural language processing (NLP) tools 
technologically and linguistically in a platform, 
based on UIMA 2 . The UIMA pluggable 
component architecture and software framework 
are designed to analyse content and to structure 
it. The ATLAS core annotation schema, as a 
uniform representation model, normalizes and 
harmonizes the heterogeneous nature of the NLP 
tools3. 
                                                          
1 http://www.joomla.org/, http://www.joomfish.net/, 
http://typo3.org/, http://drupal.org/ 
2 http://uima.apache.org/ 
3 The system exploits heterogeneous NLP tools, for 
the supported natural languages, implemented in Java, 
C++ and Perl. Examples are: 
The processing of text in the system is split 
into three sequentially executed tasks. 
Firstly, the text is extracted from the input 
source (text or binary documents) in the ?pre-
processing? phase.  
Secondly, the text is annotated by several NLP 
tools, chained in a sequence in the ?processing? 
phase. The language processing tools are 
integrated in a language processing chain (LPC), 
so that the output of a given NLP tool is used as 
an input for the next tool in the chain. The 
baseline LPC for each of the supported languages 
includes a sentence and paragraph splitter, 
tokenizer, part of speech tagger, lemmatizer, 
word sense disambiguation, noun phrase chunker 
and named entity extractor (Cristea and Pistiol, 
2008). The annotations produced by each LPC 
along with additional statistical methods are 
subsequently used for detection of keywords and 
concepts, generation of summary of text, multi-
label text categorisation and machine translation.  
Finally, the annotations are stored in a fusion 
data store, comprising of relational database and 
high-performance Lucene4 indexes. 
The architecture of the language processing 
framework is depicted in Figure 1. 
 
 
 
Figure 1. Architecture and communication channels in 
our language processing framework. 
 
The system architecture, shown in Figure 2, is 
based on asynchronous message processing 
                                                                                        
OpenNLP (http://incubator.apache.org/opennlp/), 
RASP (http://ilexir.co.uk/applications/rasp/), 
Morfeusz (http://sgjp.pl/morfeusz/),  Panterra 
(http://code.google.com/p/pantera-tagger/), ParsEst 
(http://dcl.bas.bg/), TnT Tagger (http://www.coli.uni-
saarland.de/~thorsten/tnt/). 
4 http://lucene.apache.org/ 
7
  
patterns (Hohpe and Woolf, 2004) and thus 
allows the processing framework to be easily 
scaled horizontally. 
 
 
 
Figure 2. Top-level architecture of our CMS and its 
major components. 
Text Categorisation 
We implemented a language independent text 
categorisation tool, which works for user-defined 
and controlled classification hierarchies. The 
NLP framework converts the texts to a series of 
natural numbers, prior sending the texts to the 
categorisation engine. This conversion allows 
high level compression of the feature space. The 
categorisation engine employs different 
algorithms, such as Na?ve Bayesian, relative 
entropy, Class-Feature Centroid (CFC) (Guan et. 
al., 2009), and SVM. New algorithms can be 
easily integrated because of the chosen OSGi-
based architecture (OSGi Alliance, 2009). A 
tailored voting system for multi-label multi-class 
tasks consolidates the results of each of the 
categorisation algorithms. 
Summarisation (prototype phase) 
The chosen implementation approach for 
coherent text summarisation combines the well-
known LexRank algorithm (Erkan and Radev, 
2004) and semantic graphs and word-sense 
disambiguation techniques (Plaza and Diaz, 
2011). Furthermore, we have automatically built 
thesauri for the top-level domains in order to 
produce domain-focused extractive summaries. 
Finally, we apply clause-boundaries splitting in 
order to truncate the irrelevant or subordinating 
clauses in the sentences in the summary.  
Machine Translation (prototype phase) 
The machine translation (MT) sub-component 
implements the hybrid MT paradigm, combining 
an example-based (EBMT) component and a 
Moses-based statistical approach (SMT). Firstly, 
the input is processed by the example-based MT 
engine and if the whole or important chunks of it 
are found in the translation database, then the 
translation equivalents are used and if necessary 
combined (Gavrila, 2011). In all other cases the 
input is processed by the categorisation sub-
component in order to select the top-level 
domain and respectively, the most appropriate 
SMT domain- and POS-translation model 
(Niehues and Waibel, 2010). 
The translation engine in the system, based on 
MT Server Land (Federmann and Eisele, 2010),  
is able to accommodate and use different third 
party translation engines, such as the Google, 
Bing, Lusy or Yahoo translators. 
Case Study: Multilingual Library  
i-Librarian5  is a free online library that assists 
authors, students, young researchers, scholars, 
librarians and executives to easily create, 
organise and publish various types of documents 
in English, Bulgarian, German, Greek, Polish 
and Romanian. Currently, a sample of the 
publicly available library contains over 20 000 
books in English. 
On uploading a new document to i-Librarian, 
the system automatically provides the user with 
an extraction of the most relevant information 
(concepts and named entities, keywords). Later 
on, the retrieved information is used to generate 
suggestions for classification in the library 
catalogue, containing 86 categories, as well as a 
list of similar documents. Finally, the system 
compiles a summary and translates it in all 
supported languages. Among the supported 
formats are Microsoft Office documents, PDF, 
OpenOffice documents, books in various 
electronic formats, HTML pages and XML 
documents. Users have exclusive rights to 
manage content in the library at their discretion.   
The current version of the system supports 
English and Bulgarian. In early 2012 the Polish, 
Greek, German and Romanian languages will be 
in use. 
                                                          
5 i-Librarian web site is available at http://www.i-
librarian.eu/. One can access the i-Librarian demo content 
using ?demo@i-librarian.eu? for username and ?sandbox? 
for password. 
8
  
Evaluation 
The technical quality and performance of the 
system is being evaluated as well as its appraisal 
by prospective users. The technical evaluation 
uses indicators that assess the following key 
technical elements: 
? overall quality and performance 
attributes (MTBF6, uptime, response 
time); 
? performance of specific functional 
elements (content management, machine 
translation, cross-lingual content 
retrieval, summarisation, text 
categorisation).  
The user evaluation assesses the level of 
satisfaction with the system. We measure non 
functional elements such as: 
? User friendliness and satisfaction, clarity 
in responses and ease of use; 
? Adequacy and completeness of the 
provided data and functionality; 
? Impact on certain user activities and the 
degree of fulfilment of common tasks. 
We have planned for three rounds of user 
evaluation; all users are encouraged to try online 
the system, freely, or by following the provided 
base-line scenarios and accompanying exercises. 
The main instrument for collecting user feedback 
is an online interactive electronic questionnaire7. 
The second round of user evaluation is 
scheduled for Feb-March 2012, while the first 
round took place in Q1 2011, with the 
participation of 33 users. The overall user 
impression was positive and the Mean value of 
each indicator (in a 5-point Likert scale) was 
measured on AVERAGE or ABOVE 
AVERAGE.  
 
 
Figure 3. User evaluation ? UI friendliness and ease 
of use. 
                                                          
6 Mean Time Between Failures 
7 The electronic questionnaire is available at 
http://ue.atlasproject.eu 
 
Figure 4. User evaluation ? user satisfaction with the 
available functionalities in the system. 
 
 
Figure 5. User evaluation ? users productivity 
incensement. 
Acknowledgments 
ATLAS (Applied Technology for Language-
Aided CMS) is a European project funded under 
the CIP ICT Policy Support Programme, Grant 
Agreement 250467. 
Conclusion and Future Work 
The abundance of knowledge allows us to widen 
the application of NLP tools, developed in a 
research environment. The tailor made voting 
system maximizes the use of the different 
categorisation algorithms. The novel summary 
approach adopts state of the art techniques and 
the automatic translation is provided by a cutting 
edge hybrid machine translation system. 
The content management platform and the 
linguistic framework will be released as open-
source software. The language processing chains 
for Greek, Romanian, Polish and German will be 
fully implemented by the end of 2011. The 
summarisation engine and machine translation 
tools will be fully integrated in mid 2012. 
We expect this platform to serve as a basis for 
future development of tools that directly support 
decision making and situation awareness. We 
will use categorical and statistical analysis in 
order to recognise events and patterns, to detect 
opinions and predictions while processing 
The user interface is friendly and 
easy to use 
Excellent
28%
Good 
35%
Average
28%
Below 
Average
9%
Poor
Below Average
Average
Good 
Excellent
I am satisfied with the functionalities 
Below 
Average
3%
Average
38%
Excellent
31%
Good 
28%
Poor
Below
Average
Average
Good 
Excellent
The system increases y ur 
productivity 
Excellent
13%
Below 
Averag
9%
Average
31%
Good 
47%
Poor
Below
Average
Average
Good 
Excellent
9
  
extremely large volumes of disparate data 
resources. 
Demonstration websites 
The multilingual content management platform is 
available for testing at http://i-
publisher.atlasproject.eu/atlas/i-publisher/demo . 
One can access the CMS demo content using 
?demo? for username and ?sandbox2? for 
password. 
The multilingual library web site is available 
at http://www.i-librarian.eu/. One can access the 
i-Librarian demo content using ?demo@i-
librarian.eu? for username and ?sandbox? for 
password. 
References  
Dan Cristea and Ionut C. Pistol, 2008. Managing 
Language Resources and Tools using a Hierarchy 
of Annotation Schemas. In the proceedings of 
workshop 'Sustainability of Language Resources 
and Tools for Natural Language Processing', 
LREC, 2008 
Gregor Hohpe and Bobby Woolf. 2004. Enterprise 
Integration Patterns: Designing, Building, and 
Deploying Messaging Solutions. Addison-Wesley 
Professional. 
Hu Guan, Jingyu Zhou and Minyi Guo. A Class-
Feature-Centroid Classifier for Text 
Categorization. 2009. WWW 2009 Madrid, Track: 
Data Mining / Session: Learning, p201-210. 
OSGi Alliance. 2009. OSGi Service Platform, Core 
Specification, Release 4, Version 4.2. 
Gunes Erkan and Dragomir R. Radev. 2004. 
LexRank: Graph-based Centrality as Salience in 
Text Summarization. Journal of Artificial 
Intelligence Research 22 (2004), p457?479. 
Laura Plaza and Alberto Diaz. 2011. Using Semantic 
Graphs and Word Sense Disambiguation 
Techniques to Improve Text Summarization. 
Procesamiento del Lenguaje Natural, Revista n? 47 
septiembre de 2011 (SEPLN 2011), pp 97-105. 
Monica Gavrila. 2011. Constrained Recombination in 
an Example-based Machine Translation System, In 
the Proceedings of the EAMT-2011: the 15th 
Annual Conference of the European Association 
for Machine Translation, 30-31 May 2011, Leuven, 
Belgium, p. 193-200 
 Jan Niehues and Alex Waibel. 2010. Domain 
adaptation in statistical machine translation using 
factored translation models. EAMT 2010: 
Proceedings of the 14th Annual conference of the 
European Association for Machine Translation, 27-
28 May 2010, Saint-Rapha?l, France. 
Christian Federmann and Andreas Eisele. 2010. MT 
Server Land: An Open-Source MT Architecture. 
The Prague Bulletin of Mathematical Linguistics. 
NUMBER 94, 2010, p57?66 
10
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 72?76,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
ATLAS - Human Language Technologies integrated within a 
Multilingual Web Content Management System
Svetla Koeva
Department of Computational Linguistics, Institute for Bulgarian
Bulgarian Academy of Sciences
svetla@dcl.bas.bg
Abstract
The main purpose of the project ATLAS 
(Applied Technology for Language-Aided 
CMS) is to facilitate multilingual web content 
development and management. Its main 
innovation is the integration of language 
technologies wi th in a web content 
management sys tem. The language 
processing framework, integrated with web 
content management,  provides automatic 
annotation of important words, phrases and 
named entities, suggestions for categorisation 
o f documen t s , au toma t i c summary 
generation, and machine translation of 
summaries of documents. A machine 
translation approach, as well as methods for 
obtaining and constructing training data for 
machine translation are under development. 
1 Introduction
The main purpose of the European project 
ATLAS (Applied Technology for Language-
Aided CMS)
1  
is to facilitate multilingual web 
content development and management. Its main 
innovation is the integration of language 
technologies within a web content management 
system. ATLAS combines a language processing 
framework with a content  management 
component  (i-Publisher)
2
 used for creating, 
running and managing dynamic content-driven 
websites. Examples of such sites are i-Librarian,
3
 
a free online library of digital documents that 
may be personalised according to the user?s 
needs and requirements; and EUDocLib,
4
 a free 
online library of European legal documents. The 
language processing framework of these 
websites provides automatic annotation of 
important  words, phrases and named entities, 
suggestions for categorisation of documents, 
automatic summary generation, and machine 
translation of a summary of a document 
(Karagyozov et al 2012). Six European Union 
languages ? Bulgarian, German, Greek, English, 
Polish, and Romanian are supported.
2. Brief overview of existing content 
management systems
The most frequently used open-source 
multilingual web content  management  systems 
(WordPress, Joomla, Joom!Fish, TYPO3, 
Drupal)
5
 offer a relatively low level of 
multilingual content management. None of the 
platforms supports multiple languages in their 
1
 http://www.atlasproject.eu
2
 http://i-publisher.atlasproject.eu/
3
 http://www.i-librarian.eu/
4
 http://eudoclib.atlasproject.eu/
5
 http://wordpress.com/, http://www.joomla.org/, http://www.joomfish.net/, http://typo3.org/, http://drupal.org/
72
native states. Instead, they rely on plugins to 
handle this: WordPress uses the WordPress 
Multilingual Plugin, Drupal needs a module 
called Locale, and Joomla needs a module called 
Joomfish. There are modules, like those provided 
by ICanLocalize
6
, than can facilitate selection 
within Drupal and WordPress of the material to 
be translated, but  the actual translation is done by 
human translators. To the best  of our knowledge, 
none of the existing content  management 
systems exploits language technologies to 
provide more sophisticated text content 
management. This is proved by the data 
published at  the CMS Critic
7
 - an online media 
providing news, reviews, articles and interviews 
for about 60 content  management  systems. 
Taking into account that  the online data are in 
many cases multilingual and documents stored in 
a content management  system are usually related 
by means of sharing similar topics or domains it 
can be claimed that  the web content management 
systems need the power of modern language 
technologies. In comparison ATLAS offers the 
advantage of integration of natural language 
processing in the multi l ingual content 
management.
3 Selection of ?core? words
ATLAS suggests ?core? words (plus phrases and 
named entities), i.e., the most  essential words 
that capture the main topic of a given document. 
Currently the selection of core words is carried 
out in a two-stage process: identification of 
candidates and ranking. For the identification 
stage a language processing chain is applied that 
consists of the following tools: sentence splitter, 
tokenizer, PoS tagger, lemmatizer, word sense 
disambiguator (assigns a unique sense to a 
word), NP extractor (marks up noun phrases in 
the text) and NE extractor (marks up named 
entities in the text). After this stage, the target 
core words are ranked according to their 
importance scores, which are estimated by 
features such as frequency, linguistic correlation, 
phrase length, etc., combined by heuristics to 
obtain the final ranking strategy. The core words 
are displayed in several groups: named entities 
(locations, names, etc.) - both single words and 
phrases, and noun phrases - terms, multiword 
expressions or noun phrases with a hight 
frequency. For example among the ?core? noun 
phrases extracted from Cocoa Fundamentals 
Guide
8
 are the following phrases: Object-
Oriented Programming, Objective-C language, 
Cocoa application, Cocoa program, etc. Even 
though the language processing chains that  are 
applied differ from language to language, this 
approach offers a common ground for language 
processing and its results can be comfortably 
used by advanced language components such as 
document c lass i f i ca t ion , c lause-based 
summarisation, and statistical machine 
translation. Content  navigation (such as lists of 
similar documents) based on interlinked text 
annotations is also provided.
4 Automatic categorisation
Automatic document  classification (assigning a 
document to one or more domains or categories 
from a set of labels) is of great importance to a 
modern multilingual web content management 
system. ATLAS provides automatic multi-label 
categorisation of documents into one or more 
predefined categories. This starts with a training 
phase, in which a statistical model is created 
based on a set of features from already labelled 
documents. There are currently four classifiers, 
two of which exploit  the Na?ve Bayesian 
algorithm, the two others Relative entropy and 
Class-featured centroid, respectively. In the 
classifying phase, the model is used to assign one 
or more labels to unlabelled documents. The 
results from the different classifiers are 
combined and the final classification result  is 
determined by a majority voting system. The 
automatic text  categorisation is at  the present 
stage able to handle documents in Bulgarian and 
English. For example, the Cocoa Fundamentals 
Guide is automatically categorised under the 
domain Computer science, and unter the Topics 
Computer science, Graphics and Design, 
Database Management, and Programming.
5 Text summarization
Two different  strategies for obtaining summaries 
are used in ATLAS. The strategy for short  texts is 
based on identification of the discourse structure 
and produces a summary that  can be classified as 
a type of excerpt, thus it is possible to indicate 
the length of the summary as a percentage of the 
original text. Summarisation of short texts in 
ATLAS draws on the whole language processing 
chain and also adds a couple of other modules to 
6
 http://www.icanlocalize.com/
7
 http://www.cmscritic.com/
8
 https://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaFundamentals.pdf
73
the chain: clause splitting, anaphora resolution, 
discourse parsing and summarization. The 
method used for short texts (Cristea et al 2005) 
exploits cohesion and coherence properties of the 
text to build intermediate structures. Currently, 
the short  text summarisation modules are 
implemented for English and Romanian.
The strategy for long texts assembles a template 
summary based on extraction of relevant 
information specific to different genres and is for 
the time being still under development.
6	
 Machine translation
For i-Publisher, machine translation serves as a 
translation aid for publishing multilingual 
content. The ability to display content in multiple 
languages is combined with a computer-aided 
localization of the templates. Text  for a 
localization is submitted to the translation engine 
and the output is subject to human post- 
processing.
For i-Librarian and EuDocLib, and for any 
website developed with i-Publisher, the machine 
translation engine provides a translation of the 
document summary provided earlier in the chain. 
This will give the user rough clues about 
documents in different languages, and a basis to 
decide whether they are to be stored.
6.1 Obtaining training corpora
The development  of a translation engine is 
particularly challenging, as the translation should 
be able to be used in different domains and 
within different text  genres. In addition, most of 
the language pairs in question belong to the less 
resourced group for which bilingual training and 
test material is available in limited amounts 
(Gavrila and Vertan 2011). For instance, parallel 
corpora incorporating Bulgarian are relatively 
small and usually domain-specific, with mostly 
literary or administrative texts. ATLAS? 
administrative subcorpus contains texts from EU 
legislation created between the years 1958 and 
2011, available as an online repositories, i.e., the 
EuroParl Corpus (Koehn 2005); the JRC-Acquis 
(Steinberger 2006), and includes all the 
accessible texts in the target languages. The 
scientific / administrative subcorpus consists of 
administrative texts published by the European 
Medicines Evaluation Agency (EMEA) in the 
years between 1978 and 2009. It  is part of the 
OPUS collection (Tiedemann 2009). The mass 
media subcorpus contains news reports as well as 
some other journalistic texts published in nine 
Balkan languages and English from October 
2002 until the present day on the East  Europe 
information website
9
. The fiction subcorpus was 
compiled manually by harvesting freely available 
texts on the Internet, scanning, and from 
donations by authors. So far, it consists of texts 
in Bulgarian, English, and German. The 
subcorpus of informal texts consists of subtitles 
of films: feature films, documentaries, and 
animations, all part of the OPUS collection 
(Tiedemann 2009). Automatic collection of 
corpora is preferred to manual, and for that 
purpose a set  of simple crawlers was designed. 
They are modified for each source to ensure 
efficiency. Figure 1 presents some statistical data 
for the Bulgarian-English parallel corpus, the 
largest in the collection (the vertical axis shows 
the number of words, while the horizontal - the 
domain distribution).
Figure 1 Bulgarian-English parallel corpus
Two basic methods are used to enlarge the 
existing parallel corpora. In the first, the 
available training data for statistical machine 
translation are extended by means of generating 
paraphrases (e.g. compound nouns are 
paraphrased into (semi-) equivalent  phrases with 
a preposition, and vice versa). The paraphrases 
can be classified as morphological (where the 
difference is between the forms of the phrase 
constituents), lexical (based on semantic 
similarity between constituents) and phrasal 
(based on syntactic transformations). Paraphrase 
generation methods that operate both on a single 
monolingual corpus or on parallel corpus are 
discussed by Madnani and Dorr 2010. For 
instance, one of the methods for paraphrase 
generation from a monolingual corpus considers 
as paraphrases all words and phrases that are 
distributionally similar, that is, occurring with the 
0
10000000
20000000
30000000
40000000
Administrative Science Massmedia Fiction Informal
Bulgarian English
9
 http://setimes.com/
74
same sets of anchors (Pa?ca and Dienes 2005). 
An approach using phrase-based alignment 
techniques shows how paraphrases in one 
language can be identified using a phrase in a 
second language as a pivot (Bannard and 
Callison-Burch 2005).
The second method performs automatic 
generation of parallel corpora (Xu and Sun 2011) 
by means of automatic translation. This method 
can be applied for language pairs for which 
parallel corpora are still limited in quantity. If, 
say, a Bulgarian-English parallel corpus exists, a 
Bulgarian Polish parallel corpus can be 
constructed by means of automatic translation 
from English to Polish. To control the quality of 
the automatically generated data, multiple 
translation systems can be used, and the 
compatibility of the translated outputs can be 
calculated. Thus, both methods can fill gaps in 
the available data, the first  method by extending 
existing parallel corpora and the second by 
automatic construction of parallel corpora.
6.2 Accepted approach
Given that the ATLAS platform deals with 
languages from different  language families and 
that the engine should support  several domains, 
an interlingua approach is not suitable. Building 
transfer systems for all language pairs is also 
time-consuming and does not make the platform 
easily portable to other languages. When all 
requirements and limitations are taken into 
account, corpus-based machine translation 
paradigms are the best option that can be 
considered (Karagyozov et al 2012). For the 
ATLAS translation engine it  was decided to use a 
hybrid architecture combining example-based 
and statistical machine translation at  the word- 
based level (i.e., no syntactic trees will be used). 
The ATLAS translation engine interacts with 
other modules of the system. For example, the 
document categorisation module assigns one or 
more domains to each document, and if no 
specific trained translation model for the 
respective domain exists, the user gets a warning 
that the translation may be inadequate with 
respect to lexical coverage. Each input item to 
the translation engine is then processed by the 
example-based machine translation component.
If the input as a whole or important chunks of it 
are found in the translation database, the 
translation equivalents are used and, if necessary, 
combined (Gavrila 2011). In all other cases the 
input  is sent further to the Moses-based machine 
translation component which uses a part-of- 
speech and domain-factored model (Niehues and 
Waibel 2010).
Like the architecture of the categorization 
engine, the translation system in ATLAS is able 
to accommodate and use different  third-party 
translations engines, such as those of Google, 
Bing, and Yahoo.
The ATLAS machine translation module is still 
under development. Some experiments in 
translation between English, German, and 
Romanian have been performed in order to 
define: what  parameter settings are suitable for 
language pairs with a rich morphology, what 
tuning steps lead to significant  improvements, 
wheather the PoS-factored models improve 
significantly the quality of results (Karagyozov 
et al 2012).
7? Conclusion
To conclude, ATLAS enables users to create, 
organise and publish various types of 
multilingual documents. ATLAS reduces the 
manual work by using automatic classification of 
documents and helps users to decide about a 
document by providing summaries of documents 
and their translations. Moreover, the user can 
easily find the most  relevant texts within large 
document collections and get  a brief overview of 
the i r content . A modern web content 
management systems should help users come to 
grips with the growing complexity of today?s 
multilingual websites. ATLAS answers to this 
task.
Acknowledgments
ATLAS (Applied Technology for Language-
Aided CMS) is a European project  funded under 
the CIP ICT  Policy Support  Programme, Grant 
Agreement 250467.
References 
Bannard and Callison-Burch 2005: Bannard, Colin 
and Chris Callison-Burch. Paraphrasing with 
bilingual parallel corpora. In Proceedings of 
ACL, pages 597?604, Ann Arbor, MI. 
Cristea et al 2005: Cristea,  D.,  Postolache, O., Pistol, 
I. (2005). Summarisation through Discourse 
Structure. Computational Linguistics and 
Intelligent Text Processing, 6th International 
Conference CICLing 2005 (pp.  632-644). Mexico 
City, Mexico: Springer LNSC, vol. 3406.
Gavrila 2011: Gavrila, M. Constrained recombination 
in an example-based machine translation system. 
In M. L. Vincent Vondeghinste (Ed.), 15th 
Annual Conference of the European Association 
for Machine Translation, Leuven, Belgium, pp. 
193-200.
75
Gavrila and Vertan 2011: Gavrila Monica and 
Cristina Vertan. Training data in statistical 
machine translation ? the more, the better? In 
Proceedings of the RANLP-2011 Conference, 
September 2011, Hissar, Bulgaria, pp. 551-556.
Karagyozov et al 2012: Diman Karagiozov, Anelia 
Belogay, Dan Cristea, Svetla Koeva,  Maciej 
Ogrodniczuk, Polivios Raxis, Emil Stoyanov and 
Cristina Vertan. i-Librarian ? Free online library 
for European citizens, In Infotheca, Belgrade, to 
appear.
Koehn 2005: Koehn, Ph.  Europarl: A Parallel Corpus 
for Statistical Machine Translation, Proceedings 
of MT Summit, pp. 79?86.
Madnani and Dorr 2010: Nitin Madnani and Bonnie 
Dorr. 2010. Generat- ing phrasal and sentential 
paraphrases: A survey of data-driven methods. 
Computational Linguistics, 36(3), pp. 341?388.
Niehues and Waibel 2010: Niehues Jan and Alex 
Waibel,  Domain Adaptation in Statistical 
Machine Translation using Factored Translation 
Models, Proceedings of EAMT 2010 Saint-
Raphael.
Pa?ca and Dienes 2005: Pa?ca, Marius and P?ter 
Dienes. 2005. Aligning needles in a haystack: 
Paraphrase acquisition across the Web. In 
Proceedings of IJCNLP, Jeju Island, pp. 119-130.
Steinberger et al 2006: Steinberger, R., Pouliquen, 
B., Widiger, A., Ignat,  C., Erjavec, T., Tufi?,  D., 
Varga, D. (2006). The JRC-Acquis: A 
multilingual aligned parallel corpus with 20+ 
languages. Proceedings of LREC 2006. Genoa, 
Italy.
Tiedemann 2009: Tiedemann, J. News from OPUS - 
A Collection of Multilingual Parallel Corpora 
with Tools and Interfaces. In: N. Nicolov, K. 
Bontcheva, G. Angelova, R. Mitkov (eds.) 
Recent Advances in Natural Language 
Processing (vol . V) , John Benjamins, 
Amsterdam/Philadelphia, pp. 237?248.
Xu and Sun 2011: Jia Xu and Weiwei Sun. 
Genera t ing v i r tua l para l le l corpus : A 
compatibility centric method. In Proceedings of 
the Machine Translation Summit XIII.
76
Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 102?110,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Application of Clause Alignment for Statistical Machine Translation
Svetla Koeva, Borislav Rizov, Ivelina Stoyanova, Svetlozara Leseva, Rositsa Dekova, Angel Genov,
Ekaterina Tarpomanova, Tsvetana Dimitrova and Hristina Kukova
Department of Computational Linguistics
Institute for Bulgarian Language, Bulgarian Academy of Sciences
Sofia 1113, Bulgaria
{svetla,boby,iva,zarka,rosdek,angel,katja,cvetana,hristina}@dcl.bas.bg
Abstract
The paper presents a new resource light flexi-
ble method for clause alignment which com-
bines the Gale-Church algorithm with in-
ternally collected textual information. The
method does not resort to any pre-developed
linguistic resources which makes it very ap-
propriate for resource light clause alignment.
We experiment with a combination of the
method with the original Gale-Church algo-
rithm (1993) applied for clause alignment.
The performance of this flexible method, as it
will be referred to hereafter, is measured over
a specially designed test corpus.
The clause alignment is explored as means
to provide improved training data for the
purposes of Statistical Machine Translation
(SMT). A series of experiments with Moses
demonstrate ways to modify the parallel re-
source and effects on translation quality: (1)
baseline training with a Bulgarian-English
parallel corpus aligned at sentence level; (2)
training based on parallel clause pairs; (3)
training with clause reordering, where clauses
in each source language (SL) sentence are re-
ordered according to order of the clauses in
the target language (TL) sentence. Evaluation
is based on BLEU score and shows small im-
provement when using the clause aligned cor-
pus.
1 Motivation
Evaluation on the performance of MT systems has
shown that a pervasive shortcoming shared by both
the phrase-based and the syntax-based SMT systems
is translating long and (syntactically) complex sen-
tences (Koehn et al, 2003; Li et al, 2007; Sudoh et
al., 2010).
The power of phrase-based SMT lies in local lex-
ical choice and short-distance reordering (Li et al,
2007). Syntax-based SMT is better suited to cope
with long-distance dependencies, however there also
are problems, some of them originated from the lin-
guistic motivation itself ? incorrect parse-trees, or
reordering that might involve blocks that are not
constituents (Li et al, 2007).
An efficient way to overcome the problem of sen-
tence length and complexity is to process the clauses
in a similar way as sentences. This has incited grow-
ing interest towards the alignment and processing of
clauses ? a group of syntactically and semantically
related words expressing predicative relation and
positioned between sentence borders or clause con-
nectors. (It is known that some predicative relations
can be considered complex being saturated with an-
other predicative relation ? but with the above given
definition this case is simplified).
The differences in word order and phrase structure
across languages can be better captured at a clause
rather than at a sentence level, therefore, monolin-
gual and parallel text processing in the scope of the
clauses may significantly improve syntactic parsing,
automatic translation, etc. The sentences can be very
long and complex in structure, may consist of a con-
siderable number of clauses which in turn may vary
with respect to their relative position to each other
in parallel texts both due to linguistic reasons per se
and translators? choices.
The flexible order, length and number of clauses
102
in sentences, along with the different word order and
ways of lexicalisation across languages contribute to
the complexity of clause alignment as compared to
sentence alignment and call for more sophisticated
approaches. These findings have inspired growing
research into clause-to-clause machine translation
involving clause splitting, alignment and word order
restructuring within the clauses (Cowan et al, 2006;
Ramanathan et al, 2011; Sudoh et al, 2010; Goh et
al., 2011).
A fixed clause order in a language (i.e. rela-
tive clauses in Bulgarian, English, French and many
other languages follow the head noun, while in Chi-
nese, Japanese, Turkish, etc. they precede it) may
correspond to a free order in another (i.e. Bulgar-
ian and English adverbial clauses). The hypothesis
is that a SMT model can be improved by inducing
a straightforward clause alignment through reorder-
ing the clauses of the source language text so as to
correspond to the order of the clauses in the target
language text.
2 State-of-the-art
The task of clause alignment is closely related to
that of sentence alignment (Brown et al, 1990; Gale
and Church, 1993; Kay and Roscheisen, 1993) and
phrase alignment (DeNero and Klein, 2008; Koehn
et al, 2003). There are two main approaches ? sta-
tistical and lexical, often employed together to pro-
duce hybrid methods. Machine learning techniques
are applied to extract models from the data and re-
duce the need of predefined linguistic resources.
Boutsis, Piperidis and others (Boutsis and
Piperidis, 1998; Boutsis and Piperidis, 1998;
Piperidis et al, 2000) employ a method combin-
ing statistical techniques and shallow linguistic pro-
cessing applied on a bilingual parallel corpus of
software documentation which is sentence-aligned,
POS-tagged and shallow parsed. The combined task
of clause borders identification uses linguistic in-
formation (POS tagging and shallow parsing) and
clause alignment based on pure statistical analysis.
The reported precision is 85.7%. Kit et al (2004)
propose a method for aligning clauses in Hong Kong
legal texts to English which relies on linguistic in-
formation derived from a glossary of bilingual legal
terms and a large-scale bilingual dictionary. The al-
gorithm selects a minimal optimal set of scores in
the similarity matrix that covers all clauses in both
languages. The authors report 94.60% alignment ac-
curacy of the clauses, corresponding to 88.64% of
the words.
The quality of the parallel resources is of cru-
cial importance to the performance of SMT sys-
tems and substantial research is focused on devel-
oping good parallel corpora of high standard. Most
clause alignment methods are applied on domain
specific corpora, in particular administrative cor-
pora and are not extensively tested and evaluated on
general corpora or on texts of other domains. Al-
though clause segmentation is often performed to-
gether with clause alignment (Papageorgiou, 1997)
the former tends to be more language-specific and
therefore clause alignment is performed and eval-
uated independently. The majority of the avail-
able comparative analyses discuss modifications of
one method rather than the performance of different
methods. Moreover, the performance of resource-
free against resource-rich methods has been poorly
explored. To the best of our knowledge, there is
no purely resource-free method for clause alignment
offered so far.
In recent years, handling machine translation at
the clause level has been found to overcome some of
the limitations of phrase-based SMT. Clause aligned
corpora have been successfully employed in the
training of models for clause-to-clause translation,
reordering and subsequent sentence reconstruction
in SMT ? Cowan et al (2006) for syntax-based
German-to-English SMT, Sudoh et al (2010) for
English-to-Japanese phrase-based SMT, among oth-
ers.
Cowan et al (2006) discuss an approach for
tree-to-tree SMT using Tree Adjoining Grammars.
Clause alignment is performed on a corpus (Eu-
roparl) which is then used in the training of a model
for mapping parse trees in the source language to
parse trees in the target language. The performance
of this syntax-based method is similar to the phrase-
based model of Koehn et al (2003).
Sudoh et al (2010) propose a method for clause-
to-clause translation by means of a standard SMT
method. The clauses may contain non-terminals as
placeholders for embedded clauses. After transla-
tion is performed, the non-terminals are replaced
103
by their clause translations. The model for clause
translation is trained using a clause-aligned bilin-
gual corpus of research paper abstract. The proposed
improvement by using Moses is 1.4% in BLEU
(33.19% to 34.60%), and 1.3% in TER (57.83% to
56.50%) and 2.2% in BLEU (32.39% to 34.55%)
and 3.5% in TER (58.36% to 54.87%) using a hi-
erarchical phrase-based SMT system.
The potential of clause alignment along with
other sub-sentence levels of alignment in extract-
ing matching translation equivalents from transla-
tion archives has been recognised within the EBMT
framework, as well (Piperidis et al, 2000).
3 Bootstrapping clause alignment
The clause alignment is modelled as a bipartite
graph. Each node in the graph corresponds to a
clause in either the source or the target language.
A pair of clauses that are fully or partially trans-
lational equivalents is connected by an edge in the
graph. The connected components of the graph are
beads (the smallest group of aligned clauses). In
these terms, the task of clause alignment is the task
of the identification of the edges in a bipartite graph,
where the nodes are the clauses (Brown et al, 1990).
A bootstrapping method for clause alignment that
does not exploit any pre-developed linguistic re-
sources is elaborated. The method uses length-
balance based alignment algorithm ? i.e. Gale-
Church (Gale and Church, 1993), for the data col-
lecting. The bootstrapping algorithm attains high
precision and relatively good recall. In order to
improve the recall while preserving the precision
the method is combined with the Gale-Church al-
gorithm applied to clause alignment.
The proposed method consists of the following
stages:
1. Initial clause alignment that serves as training
data.
2. Identifying similarities between clauses in dif-
ferent languages.
3. Building the clause alignment.
3.1 The Gale and Church algorithm
Gale and Church (1993) describe a method for align-
ing sentences based on a simple statistical model of
sentence lengths measured in number of characters.
It relies on the fact that longer sentences in one lan-
guage tend to be translated into longer sentences in
the other language, and vice versa. A probabilis-
tic score is assigned to each proposed correspon-
dence of sentences, based on the scaled difference
and the variance of the lengths of the two sentences.
The method is reported to give less than 4% error in
terms of alignment and is probably the most widely
used sentence alignment method.
The extended version of the Gale-Church aligner
from the Natural Language Toolkit1 is applied for
clause alignment. The original Gale-Church method
applies the 1:1, 0:1, 1:0, 1:2, 2:1 and 2:2 bead mod-
els; in the extended version ? the 1:3, 3:1, 2:3, 3:2,
3:3 models are added.
3.2 Clause alignment training data
The clause beads are identified by applying the
Gale-Church algorithm. The aim is to select a set
of aligned beads which are to serve as a training set
for the subsequent stages. Only beads showing high
probability of correctness are used. For any proba-
bility p we could find ? so that for the Gale-Church
measure within [??, ?] the corresponding bead is
correct with probability p.
3.3 Clause similarity
Clause similarity is measured by means of: a) par-
tial word alignment, b) length similarity, and c)
weighted punctuation similarity.
3.3.1 Word alignment
To align words in the scope of parallel clauses,
word-to-word connections (weighted links between
two words based on word similarity) are calculated
using several methods given below:
? Vector space model
A given word is assigned a vector
< x1, x2, ? ? ? , xn >
in an n-dimensional vector space, where each
dimension represents a bead in the preliminary
clause alignment and x i is the number of the
occurrences of the word in the bead. The set of
these vectors is a matrix.
1http://nltk.googlecode.com
104
The vector space word similarity is the cosine
of the angle between the vectors of the words
(Ruge, 1992; Schu?tze, 1992). Two words are
similar if the cosine is above a specified thresh-
old. The observations over the training and
test data show that the translation equivalents
are identified best when the cosine is higher
than 0.7. However, the word-to-word align-
ment reduces some of the errors which increase
in number when lowering the threshold. There-
fore, the threshold is set at 0.4 acquiring a good
balance between the number of the connections
obtained and the error rate.
A second vector space matrix is built using the
first two words in each clause on the assump-
tion that clause-introducing words may express
stronger word-to-word connections.
Some experiments with word similarity asso-
ciation measures e.g. the chi-square measure
(Evert, 2005) failed to show any improvements.
Word forms are treated as instances of one and
the same word if either their actual or nor-
malised forms are equal (Kay and Roscheisen,
1993). The normalised forms cover correspon-
dences between grammatically and semanti-
cally related words in languages with rich in-
flectional and derivational morphology. The
morphology algorithm proposed by Kay and
Roscheisen (1993) is applied for splitting po-
tential suffixes and prefixes and for obtaining
the normalised word forms. The vector space
word-to-word connections are calculated for
both actual and normalised forms and the ob-
tained similarity measures are summed up.
? Levenshtein measure (Levenshtein, 1966)
Church (1993) employs a method that in-
duces sentence alignment by employing cog-
nates (words that are spelled similarly across
languages). Instead the standard Levenshtein
distance (the number of edits required to trans-
form a string A into another string B) is ap-
plied. The non-Latin characters are transliter-
ated into Latin ones. The distance is calculated
within a tolerance different for a different word
length. The distance is then transformed into
similarity by means of the tolerance.
?
1?
levenshtein
tolerance + 1
.
? Punctuation
Similarity is calculated also if two words con-
tain identical prefixes or suffixes which are
punctuation marks or special characters. Punc-
tuation and special characters are not all equal.
Some of them are more robust, e.g. marks
for currency and measurement, or mathemati-
cal symbols ($, , , %, +,<,>, =) or the different
types of brackets. Others (e.g. comma, hyphen,
colon, semi-colon) may be governed by lan-
guage specific rules and may lead to improve-
ment only for those pairs of languages that em-
ploy similar rules.
The word-to-word similarity measure is the
weighted sum of the above measures where the
Levenshtein similarity is multiplied by 3, the
punctuation similarity by 0.4 and the vector
space similarity measure by 1, which is defined
as a base.
The similarity connections are sorted descend-
ingly and sequentially processed. At each itera-
tion only connections between dangling words
are stored. Thus there is only one connec-
tion left for each word resulting in partial word
alignment. The weights of all obtained word-
to-word connections are summed up to pro-
duce the weight of the clause association that is
propagated to the clause similarity calculation
stage.
3.3.2 Length similarity
Zero-weighted similarity connections between
clauses are collected using Gale-Church?s distance
measure. Thus connections are added without in-
creasing the weight of the existing ones.
3.3.3 Weighted punctuation similarity
This similarity is calculated by the following for-
mula
?
Z?PU
min(count(Z ? cl1), count(Z ? cl2)),
105
where PU is the set of the punctuation marks and
special symbols being prefixes and suffixes of words
in the clauses processed.
3.4 Clause alignment with the bootstrapping
method
The bipartite graph is built by filtering the set of the
calculated clause similarity connections. The con-
nected components of this graph form the clause
beads. A conservative fallback strategy is applied
to add the dangling clauses to the most appropri-
ate bead. The filtering process starts by defining a
threshold for grouping (1,2) and every clause simi-
larity connection with weight above it is considered
strong. In a way similar to word alignment, the re-
maining (weak) connections are sorted descendingly
and processed one by one. If the processed connec-
tion relates clauses that are not attached to any bead,
it passes the filter. In other words these two clauses
form a 1:1 bead.
The bootstrapping method evaluated on the test
corpus has precision above 94% and recall of 77%.
To overcome this low recall we combine the Gale-
Church algorithm with the core method.
3.5 Combined clause alignment
The combined method also distinguishes strong and
weak clause connections by means of a threshold
constant. At the beginning the Gale-Church results
in clause alignment are compared with the strong
connections. If they comply with the Gale-Church?s
beads, the weak connections are processed. The
weak connections are added to the final graph if
they do not contradict Gale-Church?s output, i.e.
when they do not connect clauses from two differ-
ent beads.
In case of a strong connection the Gale-Church?s
alignment is discarded, assuming that the seman-
tic and the syntactic similarities between clauses are
more significant than the length.
4 Clause alignment evaluation
4.1 Test corpus
A test corpus was constructed for the purposes
of method evaluation. It consists of 363,402 to-
kens altogether (174,790 for Bulgarian and 188,612
for English) distributed over five thematic domains:
Fiction (21.4%), News (37.1%), Administrative
(20.5%), Science (11.2%) and Subtitles (9.8%). The
purpose of using a general testing corpus with texts
from a variety of domains is to investigate method
performance in a wider range of contexts.
Both Bulgarian and English parts of the corpus
are first automatically segmented and then aligned
at sentence level. The task of sentence detection
in Bulgarian is carried out using a Bulgarian sen-
tence splitter (Koeva and Genov, 2011). For sen-
tence splitting of the English texts a pre-trained
OpenNLP2 model is used. Sentence alignment is
produced using HunAlign3 (Varga et al, 2005), with
the alignment manually verified by human experts.
Clause splitting is considered a highly language
dependent task and separate linguistic models need
to be developed for each language. For the pur-
poses of the present study, Bulgarian sentences are
manually or semiautomatically split into clauses and
for the English texts a pre-trained OpenNLP parser
is used to determine clause boundaries followed by
manual expert verification and post-editing (the task
of automatic clause splitting falls outside the scope
of the present study).
Subsequently, manual clause alignment is per-
formed. Tables 1 and 2 present the number of sen-
tences and clauses, respectively, in Bulgarian and
English with their average length in tokens (LS(t))
and in characters (LS(ch)).
Language
Sentences
number LS(t) LS(ch)
Bulgarian 13,213 13.23 73.04
English 13,896 13.57 69.21
Total 27,109 ? ?
Table 1: Number of sentences and their length.
Different models of clause alignment reflect in-
terlingual symmetry or assymetry, such as: 1:1 for
equivalent clauses in both languages; 0:1 or 1:0 if
a clause in one of the languages is missing in the
other; 1 : N and N : 1 (N > 1) in the cases of dif-
ferent clause segmentation, when clauses contain the
same information; N : M (N,M > 1) in relatively
rare cases when the information is crossed among
2http://opennlp.apache.org/index.html
3http://mokk.bme.hu/resources/hunalign/
106
Language
Clauses
number LS(t) LS(ch)
Bulgarian 24,409 7.20 39.54
English 28,949 6.57 33.22
Total 53,358 ? ?
Table 2: Number of clauses and their length.
clauses. The distribution of the models is given in
Table 3.
Model Frequency % of all
0:1 553 2.53
1:0 412 1.88
1:1 17,708 80.88
1:2 2,055 9.39
1:3 309 1.41
1:4 98 0.45
2:1 588 2.69
2:2 81 0.37
2:3 15 0.07
3:1 31 0.14
3:2 7 0.03
Table 3: Distribution of bead models in the manually
aligned corpus.
4.2 Evaluation
The precision is calculated as the number of true
connections (between clauses in the two languages)
divided by the number of the proposed connections,
while the recall is the proportion of true connections
to all connections in the corpus. The connections in
a bead are the Cartesian product of the clauses in the
first and the second language. The K : 0 and 0 : K
bead models are considered as K : 1 and 1 : K by
adding a fake clause.
The evaluation is performed both over the corpus
as a whole and on each of the domain specific sub-
corpora included in it.
The evaluation of the clause alignment implemen-
tation of the Gale-Church algorithm on the same cor-
pus shows overall precision of 0.902, recall ? 0.891
and F1 measure ? 0.897. Although the original
Gale-Church method performs very well in terms of
both precision and recall, sentence alignment poses
a greater challenge. The explanation for this fact lies
Domain Precision Recall F1
Total 0.910 0.911 0.911
Administrative 0.865 0.857 0.861
Fiction 0.899 0.902 0.901
News 0.933 0.946 0.940
Science 0.874 0.852 0.862
Subtitles 0.934 0.934 0.934
Table 4: Performance of the flexible method.
in the broader scope of variations of clause corre-
spondences as compared to sentences.
The bootstrapping method performs better in the
translations with clause reordering. An example
is the administrative subcorpus where Gale-Church
gives precision/recall ? 81.5%/79.7% compared to
86.6%/85.8% shown by the bootstrapping method.
In the texts with less clause order asymmetries the
results are close.
5 Application of clause alignment in SMT
Typical Moses4 (Koehn et al, 2007) models are built
on a large amount of parallel data aligned at the sen-
tence level. For the purposes of the present study a
specially designed parallel corpus is used. The aim
is to demonstrate the effect of using syntactically en-
hanced parallel data (clause segmentation and align-
ment, reordering of clauses, etc.).
A series of experiments with Moses is designed
to demonstrate the effect of training data modifica-
tion on the performance of the SMT system. The
different training datasets comprise the same sen-
tences but differ in their syntactic representation.
The baseline model is constructed on the basis of
aligned sentence pairs. The first experiment is based
on aligned clauses rather than sentences. The second
experiment demonstrates the effect of reordering of
the clauses within the source language sentences.
The main purpose of the experiments is to demon-
strate possible applications of the clause alignment
method for training an SMT system, enhanced with
linguistic information.
5.1 Training corpus
For the demonstration purposes of the present study
we apply a small corpus of 27,408 aligned sen-
4http://www.statmt.org/moses/
107
tence pairs (comprising 382,950 tokens in Bulgar-
ian and 409,757 tokens in English) which is semi-
automatically split into clauses and automatically
aligned at clause level. The current purposes of the
research do not include the development of a full
SMT model but focus on the demonstration of the
effect of syntactical information on the performance
of the SMT system. Thus, the size of the train-
ing corpus is considered sufficient for demonstration
purposes. The parallel texts are extracted from sev-
eral domains ? Administrative, Fiction, News, Sci-
ence, Subtitles.
5.2 Test corpus
The test corpus compiled for the purposes of evalu-
ation of the SMT performance is independently de-
rived from the Bulgarian-English parallel corpus and
does not overlap with the training corpus. It how-
ever, resembles its structure and contains texts from
the same domains as the training data. Table 5 gives
the number of tokens in the Bulgarian and in the En-
glish part of the test corpus, with percent of tokens
in the Bulgarian texts.
Domain BG ENl % (BG)
Administrative 36,042 35,185 21.10
Fiction 34,518 38,723 20.21
News 64,169 62,848 37.57
Science 18,912 19,856 11.07
Subtitles 17,147 18,951 10.04
Total 170,788 175,563
Table 5: Number of tokens in the test corpus.
5.3 Baseline model
The baseline model corresponds to the traditional
Moses trained models and is constructed from
aligned sentences in Bulgarian and English. The
BLEU score for translation from Bulgarian into En-
glish is 16.99 while for the reverse it is substantially
lower ? 15.23. In the subsequent tests we observe
the results for the Bulgarian-to-English translation
only.
5.4 Clause level trained model
The first experiment aims to demonstrate that train-
ing of the model based on aligned clauses rather than
sentences yields improvement. The assumption is
that alignment at a sub-sentential level would im-
prove word and phrase alignment precision by limit-
ing the scope of occurrence of translational equiva-
lents. On the other hand, however, lower level align-
ment reduces the number of aligned phrases. For
this purpose clauses are the optimal scope for align-
ment as phrases rarely cross clause boundaries.
The results of the clause level training show small
improvement of 0.11 in the BLEU score from 16.99
(baseline) to 17.10 for the Bulgarian-to-English
translation.
5.5 Reordering of clauses
The second experiment relies on reordering of
clauses within aligned sentences. The experiment
aims at showing that reordering improves perfor-
mance of SMT system.
A simple clause reordering task was carried out
within the sentences on the parallel training cor-
pus. Clause reordering involves linear reordering of
clauses in the source language sentences to match
the linear order of corresponding clauses in the tar-
get language sentences.
Reordering applies to cases where asymmetries
are present in the alignment i.e. crossed connections
between clauses, which is expected to vary across
languages and domains. This suggests that the pro-
portion of the corpus affected by reordering also de-
pends on the language and on the domain. Based on
an experiment with a smaller corpus, approximately
7% of the Bulgarian sentences are affected by re-
ordering when adjusted to the English sentences.
The result is BLEU score of 17.12 compared to
16.99 (baseline) which yields an improvement of
0.13.
5.6 Analysis
The results obtained from the above two experi-
ments show a small yet consistent improvement in
the BLEU score. It shows a possibility to im-
prove the results by applying parallel data enhanced
by syntactic information, namely, aligned pairs at
clause level, or sentences with reordered clauses.
The data, however, are not sufficient to draw a
definite conclusion both on whether the improve-
ment is stable and on which of the two methods ?
108
using clause aligned pairs or reordered sentences ?
performs better.
6 Conclusions
The research done in the scope of this paper has
shown that, on the one hand, the Gale-Church al-
gorithm is applicable for clause alignment. The re-
sults achieved by the bootstrapping method, on the
other hand, show that clause alignment may be ap-
propriately improved by means of similarity mea-
surement especially for the domain dependent tasks
? particularly for the domains for which non-linear
order of the translated clauses is typical. Exper-
iments showed that especially for texts exhibiting
alignment asymmetries our method for clause align-
ment outperforms Gale-Church considerably.
We applied automatic clause alignment for build-
ing a Moses training dataset enhanced with syntac-
tic information. Two experiments were performed
? first, involving aligned clause pairs, and the sec-
ond using clause reordering in the source language
assuming that the order of clauses in the target lan-
guage defines relations specific for the particular
language. The experiments suggest that the clause
reordering might improve translation models.
The series of experiments conducted with Moses
showed possible applications of the clause align-
ment method for training an SMT system, enhanced
with linguistic information.
References
Sotiris Boutsis and Stelios Piperidis. 1998. OK with
alignment of sentences. What about clauses? Pro-
ceedings of the Panhellenic Conference on New Infor-
mation Technology (NIT98). pp. 288?297.
Sotiris Boutsis and Stelios Piperidis. 1998. Aligning
clauses in parallel texts. Proceedings of the 3rd Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 1998). pp. 17?26.
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Frederick Jelinek, Robert L.
Mercer and Paul S. Roossin. 1990. A statistical ap-
proach to language translation. Computational Lin-
guistics, 16(2): 79?85.
Kenneth Church. 1993. Charalign: A program for align-
ing parallel texts at the character level. Proceedings of
the 31st Annual Meeting of the Association for Com-
putational Linguistics (ACL 1993). pp. 1?8.
Brooke Cowan, Ivona Kucerova? and Michael Collins.
2006. A Discriminative Model for Tree-to-Tree Trans-
lation. Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP
2006). pp. 232?241.
John DeNero and Dan Klein. 2008. The Complexity of
Phrase Alignment Models. Proceedings of the 46th
Annual Meeting of the Association for Computational
Linguistics (ACL 2008), Short Paper Track.
Stefan Evert. 2005. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis. In-
stitut fur maschinelle Sprachverarbeitung, University
of Stuttgart.
William A. Gale and Kenneth. W. Church. 1993.
A Program for Aligning Sentences in Bilingual
Corpora. Computational Linguistics, 19(1): 75?
102. URL: http://acl.ldc.upenn.edu/J/
J93/J93-1004.pdf.
Chooi-Ling Goh, Takashi Onishi and Eiichiro Sumita.
2011. Rule-based Reordering Constraints for Phrase-
based SMT. Mikel L. Forcada, Heidi Depraetere,
Vincent Vandeghinste (eds.) Proceedings of the 15th
Conference of the European Association for Machine
Translation (EAMT 2011). pp. 113?120.
Mridul Gupta, Sanjika Hewavitharana and Stephan Vo-
gel. 2011. Extending a probabilistic phrase alignment
approach for SMT. Proceedings of the International
Workshop on Spoken Language Translation (IWSLT
2011). pp. 175-182.
Martin Kay and Martin Roscheisen. 1993. Text trans-
lation alignment. Computational Linguistics, 19(1):
121?142.
Chunyu Kit, Jonathan J. Webster, King Kui Sin, Haihua
Pan, Heng Li. 2004. Clause Alignment for Hong
Kong Legal Texts: A Lexical-based Approach. Inter-
national Journal of Corpus Linguistics, 9(1): 29?51.
Philipp Koehn, Franz J. Och and Daniel Marcu. 2003.
Statistical phrase-based translation. Proceedings of
the North American Chapter of the Association for
Computational Linguistics (NAACL 2003). pp. 48?54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. Annual
Meeting of the Association for Computational Linguis-
tics (ACL), demonstration session. Prague, Czech Re-
public, June 2007.
Svetla Koeva, Diana Blagoeva and Siya Kolkovska.
2010. Bulgarian National Corpus Project. Nicoletta
Calzolari, Khalid Choukri, Bente Maegaard, Joseph
Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner,
109
Daniel Tapias (eds.) Proceedings of the 7th conference
on International Language Resources and Evaluation
(LREC 2010). pp. 3678?3684.
Svetla Koeva and Angel Genov. 2011. Bulgarian lan-
guage processing chain. Proceedings of Integration of
multilingual resources and tools in Web applications.
Workshop in conjunction with GSCL 2011, 26 Septem-
ber 2011, University of Hamburg. (to appear)
Vladimir Levenshtein 1966. Binary codes capable of
correcting deletions, insertions, and reversals. Soviet
Physics Doklady, 10. pp. 707?710.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li, Ming
Zhou and Yi Guan. 2007. A probabilistic approach to
syntax-based reordering for statistical machine trans-
lation. Proceedings of the 45rd Annual Meeting of
the Association for Computational Linguistics (ACL
2007). pp. 720?727.
Harris Papageorgiou 1997. Clause recognition in the
framework of alignment. Ruslan Mitkov and Nicolas
Nicolov, N. (eds.) Current Issues in Linguistic Theory,
136: 417?425. John Benjamins B.V.
Stelios Piperidis, Harris Papageorgiou and Sotiris Bout-
sis. 2000. From sentences to words and clauses.
Chapter 6. Jean Veronis and Nancy Ide (eds.) Paral-
lel Text Processing: Alignment and Use of Translation
Corpora. Text, Speech and Language Technology se-
ries, 13: 117?137.
Ananthakrishnan Ramanathan, Pushpak Bhattacharyya,
Karthik Visweswariah, Kushal Ladha and Ankur
Gandhe. 2011. Clause-Based Reordering Constraints
to Improve Statistical Machine Translation. Proceed-
ings of the 5th International Joint Conference on Nat-
ural Language Processing (IJCNLP 2011). pp. 1351?
1355.
Gerda Ruge. 1992. Experiments on linguistically based
term associations. Information Processing & Manage-
ment. 28(3):317-332.
Hinrich Schu?tze. 1992. Context Space. Working Notes
of the AAAI Fall Symposium on Probabilistic Ap-
proaches to Natural Language. pp. 113-120
Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, Tsutomu
Hirao, Masaaki Nagata. 2010. Divide and Trans-
late: Improving Long Distance Reordering in Statis-
tical Machine Translation. Proceedings of the Joint
5th Workshop on Statistical Machine Translation and
MetricsMATR. pp. 418?427.
Daniel Varga, Laszlo Nemeth, Peter Halacsy, Andras Ko-
rnai, Viktor Tron, Viktor Nagy. 2005. Parallel cor-
pora for medium density languages. Proceedings of
the RANLP 2005. pp. 590?596.
110
Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 119?128,
Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational Linguistics
Wordnet-Based Cross-Language Identification of Semantic Relations
Ivelina Stoyanova Svetla Koeva Svetlozara Leseva
Department of Computational Linguistics, IBL, BAS, Sofia, Bulgaria
{iva,svetla,zarka}@dcl.bas.bg
Abstract
We propose a method for cross-language
identification of semantic relations based
on word similarity measurement and mor-
phosemantic relations in WordNet. We
transfer these relations to pairs of deriva-
tionally unrelated words and train a model
for automatic classification of new in-
stances of (morpho)semantic relations in
context based on the existing ones and
the general semantic classes of collocated
verb and noun senses. Our experiments
are based on Bulgarian-English parallel
and comparable texts but the method is to
a great extent language-independent and
particularly suited to less-resourced lan-
guages, since it does not need parsed or se-
mantically annotated data. The application
of the method leads to an increase in the
number of discovered semantic relations
by 58.35% and performs relatively consis-
tently, with a small decrease in precision
between the baseline (based on morphose-
mantic relations identified in wordnet) ?
0.774, and the extended method (based on
the data obtained through machine learn-
ing) ? 0.721.
1 Introduction
Natural language semantics has begun to receive
due attention as many areas of natural language
processing have recognized the need for address-
ing both the syntactic structure and the semantic
representation of sentence constituents. Modelling
conceptual and syntactic relationships such as se-
mantic roles, semantic and syntactic frames, or
semantic and syntactic dependencies is known as
semantic role labeling ? SRL (Gildea and Juraf-
sky, 2002), (shallow) semantic parsing (Pradhan et
al., 2004), semantic role tagging (Xue and Palmer,
2004), extraction of predicate-argument structures
(Moschitti and Bejan, 2004), automatic extraction
of semantic relations (Swier and Stevenson, 2005),
among others.
We propose a method for automatic semantic
labeling based on the morphosemantic relations
in Princeton WordNet (PWN). A morphoseman-
tic relation associates a verb synset Sv and a noun
synset Sn if there is a derivational relation between
a literal Lv in Sv and a literal Ln in Sn. Mor-
phosemantic relations inherit the semantics of the
derivation. Consider, for instance, the morphose-
mantic relations agent, instrument, location, and
vehicle, which link a verb to its agent (adminis-
trate ? administrator), instrument (collide ? col-
lider), location (settle ? settlement), vehicle (bomb
? bomber).
We apply word and clause similarity measure-
ment to parallel and comparable texts in order to
perform partial word sense disambiguation and to
identify candidates for labeling with semantic in-
formation. We enhance the WordNet morphose-
mantic relations with semantic generalizations de-
rived from the general semantic word classes of
the synsets and use this knowledge to learn and
assign different types of semantic information:
? semantic relations associated with the noun col-
locates of a particular verb sense;
? general semantic noun classes that are eligible
to collocate with a particular verb sense.
We apply this method to English and Bulgarian
using PWN and the Bulgarian WordNet (BulNet).
An advantage of the proposed approach is that it is
able to assign semantic labels to unstructured text.
The paper is organised as follows. We out-
line the background against which we approach
the identification of semantic relations in Section
2 where we present in brief groundbreaking and
influential recent work in semantic role labeling
(SRL). In Section 3 we discuss the linguistic mo-
tivation for the proposed approach. In Section 4
119
we describe the method for wordnet-based iden-
tification of semantic information and its imple-
mentation. Section 5 presents assessment of the
results, followed by conclusions and an outline of
directions for future research in Section 6.
2 Related Work
Many applications treat the assignment of seman-
tic roles, semantic frames, and dependencies as
a classification problem that involves the training
of models on (large) manually annotated corpora,
such as FrameNet text annotation (Ruppenhofer et
al., 2010), the Prague Dependency Treebank (Ha-
jic, 1998), or PropBank (Palmer et al, 2005), and
the subsequent assignment of semantic labels to
appropriate sentence constituents.
A number of models have been developed us-
ing the FrameNet corpus. Undoubtedly the most
influential one has been Gildea and Jurafsky?s
machine learning method (Gildea and Jurafsky,
2002), which is based on the training of a SRL
classifier on a set of lexical, morpho-syntactic,
syntactic and word order features extracted from
the parsed FrameNet corpus in conjunction with
knowledge of the predicates, prior probabilities of
various combinations of semantic roles, etc.
PropBank spurred a lot of research in SRL
(Pradhan et al, 2004; Pradhan et al, 2008;
Toutanova et al, 2008; Surdeanu et al, 2003; Xue
and Palmer, 2004), to mention but a few. For in-
stance, Pradhan et al (2004) and Pradhan et al
(2008) propose SRL algorithms that augment pre-
viously developed systems, such as Gildea and Ju-
rafsky?s (2002) by replacing earlier classifiers with
SVMs. Xue and Palmer (2004) train a Maximum
Entropy classifier on the PropBank using linguis-
tic features that can be directly extracted from syn-
tactic parse trees and achieve results comparable to
the best performing system at the time (Pradhan et
al., 2004).
Semantic role labeling based on (large) anno-
tated corpora need to deal with a number of issues,
such as the situation specificity of semantic roles,
the manual selection of annotated examples, vari-
ability in the sets of roles used across the compu-
tational resources, among others (Marquez et al,
2008). Pradhan et al (2008) have also shown that
the transfer of such models to other domains leads
to substantial degradation in the results.
Some researchers employ other resources as an
alternative. Swier and Stevenson (2005) describe
an unsupervised SRL system that combines infor-
mation from a verb lexicon ? VerbNet with a sim-
ple probability model. Shi and Mihalcea (2005)
propose the integration of VerbNet, WordNet and
FrameNet into a knowledge base and use it in the
building of a semantic parser. The system iden-
tifies the FrameNet frame best corresponding to
a parsed sentence either as a direct match, or via
VerbNet and/or WordNet relations.
Despite these alternatives the dominant trend
has remained the corpus-based SRL, with un-
supervised approaches gaining popularity as a
way of overcoming the deficiencies of supervised
methods (Lang and Lapata, 2011a; Lang and Lap-
ata, 2011b), among others. Syntactic analysis has
been considered a prerequisite in SRL, with full
parsing winning over partial parsing, as demon-
strated by the results in the CoNLL-2004 (Carreras
and Marquez, 2004) and the CoNLL-2005 (Car-
reras and Marquez, 2005) shared tasks. Syntac-
tic analysis and SRL have been dealt with within
two general frameworks. In the ?pipeline? ap-
proach the systems first perform syntactic pars-
ing followed by SRL, while In the joint parsing
approach syntactic and semantic parsing are per-
formed together. Joint parsing of syntactic and
semantic dependencies has been the focus of the
CoNLL-2008 (Surdeanu et al, 2008) and CoNLL-
2009 (Hajic? et al, 2009) shared tasks.
To sum up, a classical SRL system takes a
parsed input and assigns semantic roles on the
basis of: i) a language model learnt from a pre-
annotated semantically labeled corpus; ii) a frame
lexicon; or iii) a combination of different re-
sources. In the systems using annotated corpora
the syntactically parsed sentences are usually se-
mantically annotated using classifiers trained on
the corpus on the basis of linguistic features de-
rived from the parses. In the case of lexicon-based
systems semantic roles are directly or indirectly
assigned from the lexicon.
3 Motivation
Morphosemantic relations in WordNet denote re-
lations between (synset members) that are similar
in meaning and where one word is derived from
the other by means of a morphological affix (Fell-
baum et al, 2009). The authors also note that most
of the morphosemantic relations connect words
from different classes and go on to demonstrate
that part of the noun-verb relations correspond to
120
semantic roles. In fact, many of the noun-verb
morphosemantic links in WordNet designate typi-
cal relations between a participant and a predicate,
such as agent, instrument, material, location, un-
dergoer, destination, etc.
For instance the verb literal send (cause to be
directed or transmitted to another place) is re-
lated to the noun sender (someone who transmits
a message) through the morphosemantic relation
agent and to the noun sendee (the intended recip-
ient of a message) through destination; train (ed-
ucate for a future role or function) is connected to
trainer (one who trains other persons or animals)
through agent and to trainee (someone who is be-
ing trained) through undergoer. The noun mem-
bers of these morphosemantic relations can func-
tion as arguments of the particular verbs and bear
the respective semantic roles, i.e. agent for sender
and trainer, destination for sendee, and undergoer
for trainee.
Further, we assume that if a noun and a verb
enter into the same morphosemantic relation in-
dividually, they are licensed for it and therefore,
when they collocate, they enter into this relation
if there is no other appropriate noun candidate for
the same relation. As an example, consider the
sentence: The author used the method of cost-
effectiveness analysis. The verb use is linked to
user through the morphosemantic relation agent.
The noun author is connected with the verb author
(be the author of) by means of the same relation.
By virtue of the above assumption we assign the
relation agent between use and author in this par-
ticular sentence. In such a way the morphoseman-
tic relation identified between the derivationally
related verb and noun may be inherited by syn-
onyms, direct hypernyms, hyponyms, sister terms,
etc. Thus, given a morphosemantic relation and
words in the context that participate in such a re-
lation independently of each other, we are able to
discover certain types of semantic relations.
4 Method for Cross-Language Learning
of Semantic Relations
The goal of the study is to identify semantic rela-
tions between a verb and collocated nouns1 within
similar clauses in Bulgarian and English (often
but not necessarily translational equivalents) and
to assign a semantic matrix to the verb based on
1Collocated here means that nouns are found within the
same clause as the verb.
Bulgarian English
Administrative
Politics 28,148 27,609
Economy 25,800 28,436
Health 26,912 30,721
Ecology 27,886 36,227
News
Politics 25,016 25,010
Economy 25,010 25,127
Culture 25,319 25,355
Military 25,283 25,328
Fiction
Adventure 25,053 29,241
Humour 30,003 26,992
Love 32,631 25,459
Fantasy 30,200 32,393
TOTAL 327,261 337,898
Table 1: Distribution of texts (in terms of num-
ber of words) in the Bulgarian-English compara-
ble corpus applied in the study
collocational evidence and the WordNet hierarchy.
The method is developed and tested on a
Bulgarian-English comparable corpus (Table 1)
which is an excerpt from the Bulgarian National
Corpus (Koeva et al, 2012).
4.1 WordNet Enhancement with
Morphosemantic Relations
The interest in morphosemantic relations has been
motivated by the fact that they overlap to a great
extent across wordnets (Bilgin et al, 2004) and
thus improve the internal connectivity of the in-
dividual wordnets, as well as by the fact that the
derivational subnets reflect certain cognitive struc-
tures in natural languages (Pala and Hlavackova,
2007). n approach to wordnet development based
on enrichment with morphosemantic relations has
been adopted for English (Fellbaum et al, 2009),
as well as for a number of other languages ? Turk-
ish (Bilgin et al, 2004), Czech (Pala and Hlavack-
ova, 2007), Bulgarian (Koeva et al, 2008), Serbian
(Koeva, 2008), Polish (Piasecki et al, 2009), Ro-
manian (Barbu Mititelu, 2012), to mention a few.
Provided there is a mapping algorithm between
two or more wordnets, such as the cross-language
relation of equivalence between synsets (Vossen,
2004), a morphosemantic relation between a pair
of synsets in a given language can be mapped
to the corresponding synsets in a different lan-
121
guage, even if the latter language does not exhibit
a derivational relation between members of these
particular synsets.
We automatically expand BulNet with mor-
phosemantic relations in the following two ways:
(1) Morphosemantic relations are mapped from
the morphosemantic database distributed with the
PWN2 to the corresponding Bulgarian synsets.
The morphosemantic relations currently encoded
in Princeton WordNet 3.0.3 have relatively limited
coverage ? 14,876 verb-noun synset pairs, which
involve 7,960 verb synsets and 9,704 noun synsets.
The automatic transfer of morphosemantic links to
BulNet resulted in the association of 5,002 verb-
noun pairs involving 3,584 verb synsets and 4,938
noun synsets.
For example, the PWN synset hammer:2 (beat
with or as if with a hammer) is related to the noun
synset hammer:4 (a hand tool with a heavy rigid
head and a handle; used to deliver an impulsive
force by striking) through the morphosemantic re-
lation instrument. We map this relation to the
corresponding pair in BulNet ? the verb synset
chukam:1; kova:1 and the noun synset chuk:1. In
the particular case a derivational relation exists in
Bulgarian, as well, between chuk and chukam.
(2) In general, the task of detection and clas-
sification of the identified relations includes au-
tomatic generation of derivational pairs based on
knowledge of language-specific derivational pat-
terns followed by filtering of the results through
automatic and/or manual validation. Specific
methods are described in more detail in the re-
search cited at the beginning of this subsection, as
well as in more recent proposals, such as the ma-
chine learning approach to generation and classifi-
cation of derivational pairs made by Piasecki et al
(2012b) and Piasecki et al (2012a), respectively.
We identify new pairs of verb-noun literals in
BulNet that are potentially derivationally (and thus
morphosemantically) related by means of a set of
rules that describe the verb-noun and noun-verb
derivational patterns in Bulgarian (we focus on
patterns affecting the end of the word, thus ig-
noring prefixation) and assign the respective mor-
phosemantic relations to the synsets that include
the related pairs.
2http://wordnetcode.princeton.edu/
standoff-files/morphosemantic-links.xls
3http://wordnet.princeton.edu/wordnet/
download/standoff/
We identified 89 derivational noun endings
(morphophonemic variants of suffixes) and 183
derivational patterns (verb ending to noun ending
correspondences), and associated them with the
morphosemantic relation they indicate. Only 39
of the selected derivational endings were found to
be unambiguous. Moreover, many of them proved
to be highly ambiguous, denoting up to 10 of the
14 morphosemantic relations. In order to disam-
biguate at least partially the possible morphose-
mantic relations associated with a particular suf-
fix, we filtered those meanings with the general
semantic classes derived from the PWN lexicog-
rapher files. The PWN synsets are organized in
45 lexicographer files based on syntactic category
and general semantic word classes (26 for nouns
and 15 for verbs)4.
For instance, the Bulgarian noun suffix -
nik is associated with the following relations
agent, instrument, location, undergoer, and event.
By virtue of the fact that the synsets denot-
ing locations are found in the lexicographer file
noun.location, the synset denoting agents
? in noun.person, and the instruments ? in
noun.artifact, we were able to disambiguate
the suffix at least partially.
Initially, 57,211 new derivational relations were
found in BulNet. These relations were eval-
uated automatically on the basis of the mor-
phosemantic relations transferred from PWN.
Each triple <verb.label, noun.label,
relation>5 was assigned a probability based
on the frequency of occurrence in the set of
morphosemantic relations transferred from PWN.
Those relations with a probability below 1% were
filtered out. As a result 34,677 morphosemantic
relations between a noun literal and a verb lit-
eral were assigned among 7,456 unique noun-verb
synset pairs, which involved 2,537 verb synsets
and 1,708 noun synsets.
For example the noun synset kovach:1 (corre-
sponding to blacksmith:1) is derivationally related
with the verb literal kova:1 through the suffix -ach,
which is associated either with an agent or with an
instrument relation depending on the semantics of
the noun ? a person or an inanimate object. In this
case the meaning of the suffix is disambiguated
4http://wordnet.princeton.edu/wordnet/
man/lexnames.5WN.html
5The verb.label and noun.label are descriptive
labels of the wordnet synsets which are listed in the respective
lexicographer files.
122
by virtue of the fact that kovach:1 is found in the
noun.person lexicographer file. We link the
literals kova:1 and kovach:1 via a derivational re-
lation suffix and assign the synsets the morphose-
mantic relation agent.
4.2 Preprocessing and Clause Splitting
The preprocessing of the Bulgarian-English cor-
pus used in the study includes sentence-splitting,
tokenization, POS-tagging and lemmatization, us-
ing the Bulgarian Language Processing Chain6
(Koeva and Genov, 2011) for the Bulgarian part
and Stanford CoreNLP7 for the English part.
The clause serves as the minimal context for
the realization of verb semantics, and hence ?
the scope within which we carry out the cross-
linguistic analysis and the assignment of relations.
Clause splitting is applied using a general method
based on POS tagging, lists of clause delimiters
(clause linking words, multiword expressions, and
punctuation) and a set of language-specific rules.
We define the clause as a sequence of words be-
tween two potential clause delimiters where ex-
actly one predicate (a simple or a complex verb
form, which may be a lexical verb, an auxiliary,
a copula, or a combination of a lexical verb or
a copula with one or more auxiliaries) occurs.
We identify the predicates in each sentence us-
ing language-specific rules for Bulgarian and En-
glish. Each clause is labeled by a clause opening
and a clause end. The clause splitting algorithm
marks subordinating and coordinating clause link-
ing words and phrases and punctuation clause de-
limiters. If no clause boundary has been identified
between two predicates, a clause boundary is in-
serted before the second one. The nested clauses
are detected, as well.
4.3 Word-to-Word and Text-to-Text
Semantic Similarity
WordNet has inspired the elaboration of metrics
for word similarity and relatedness that quantify
the degree to which words (concepts) are related
using properties of the WordNet structure. The
so-called path-length based measures rely on the
length of the path between two nodes (synsets),
possibly normalized. For instance, the Leacock-
Chodorow metric (Leacock and Chodorow, 1998)
finds the shortest path between two concepts and
6http://dcl.bas.bg/services/
7http://nlp.stanford.edu/software/
corenlp.shtml
scales the path length by the overall depth D of the
WordNet taxonomy, while Wu-Palmer (Wu and
Palmer, 1994) calculates the depth of the concepts
and their least common subsumer in the WordNet
taxonomy.
Information content based metrics augment the
path information with corpus statistics. Resnik
(1995) measures the similarity of two concepts by
calculating the information content (IC) of their
least common subsumer (LCS). Jiang-Conrath
(Jiang and Conrath, 1997) and Lin (Lin, 1998)
combine the information content of the LCS with
the information content of the individual concepts.
Several relatedness metrics have also been pro-
posed, such as Hirst-St-Onge (Hirst and St-Onge,
1998), which measures semantic relatedness based
on the path length and its nature (the changes of di-
rection in the path), and the algorithms proposed
by Banerjee and Pederson (2002) and Patwardhan
et al (2003), which rely on information obtained
from the synsets glosses.
A number of researchers have addressed WSD
based on cross-lingual semantic similarity mea-
surement, such as the application of monolingual
WSD graph-based algorithms to multilingual co-
occurrence graphs based on WordNet (Silberer
and Ponzetto, 2010), or of multilingual WSD al-
gorithms based on multilingual knowledge from
BabelNet (Navigli and Ponzetto, 2012).
For the purposes of the extraction of seman-
tic relations we are interested in corresponding
pairs of clauses in Bulgarian and English satisfy-
ing the following conditions: (a) the verbs in the
clauses are similar (with respect to a certain simi-
larity measure and threshold); and (b) the clauses
are similar in meaning (with respect to a certain
similarity measure and threshold). Similar pairs
of verbs and nouns are identified on the basis of
the Wu-Palmer word-to-word similarity measure
(Wu and Palmer, 1994). Clause similarity is com-
puted by means of the text similarity measurement
proposed by Mihalcea et al (2006).
Measuring semantic similarity cross-
linguistically enables us to filter some of the
senses of a particular word in one language since
potential semantic similarity of words within
similar clauses strongly suggests that these words
are semantically related ? translation equivalents,
close synonyms, hypernyms, or hyponyms.
In the application of the method described in
Section 4.4, we assign semantic relations to the el-
123
ements of similar clauses in a comparable, not nec-
essarily parallel, Bulgarian-English corpus. More-
over, we identify semantically similar rather than
parallel clauses, which enables us to experiment
with a greater number and diversity of contexts for
the identification of semantic relations.
4.4 Method outline
We select corresponding (comparable) pairs of
texts from the corpus ? T1 in Bulgarian and T2 in
English on the basis of their detailed metadata de-
scription (Koeva et al, 2012), including parame-
ters such as style, domain and genre. For each pair
of corresponding texts T1 and T2 we apply the fol-
lowing algorithm:
Step 1. We identify semantically similar pairs
of verbs and consider similarity between their re-
spective clauses ? v1 ? cl1 and v2 ? cl2, where
cl1 ? T1 and cl2 ? T2 and cl1 are also seman-
tically similar (cf. Section 4.3 for word-to-word
and clause-to-clause similarity).
Step 2. We identify semantically similar pairs
of collocated nouns in the bi-clause (cl1, cl2) in
the same way as for verbs.
Step 3. We assign morphosemantic relations
to the verb and its collocated nouns using the en-
hanced set of relations (cf. Section 4.1) and map
all matching candidates (v1, n1, rel) in cl1(v1)
and (v2, n2, rel) in cl(v2).
Step 4. Since co-occurrence of members of a
single instance of a morphosemantic relation are
relatively rare, we transfer the morphosemantic re-
lations to non-derivationally related words, pro-
vided a noun and a verb participate in the same
type of morphosemantic relation independently of
each other. In Example 1 the noun director en-
ters into a morphosemantic relation (agent) with
the verb direct, while the verb send enters inde-
pendently into the same type of relation with the
noun sender. Since both director and send are li-
censed for agent, we assign the relation.
Example 1.
Croatian director Zrinko Ogresta sent an invita-
tion for the international film festival.
send, 01437254-v, verb.contact
{to cause or order to be taken directed or transmit-
ted to another place}
director, 10015215-n, noun.person
VERB send: agent, NOUN director: agent inv
Step 5. We hierarchize the candidates for a
particular morphosemantic relation and select the
most probable one based on the general semantic
word classes (verb.label and noun.label)
and the relations they participate in. Where two or
more morphosemantic relations are assigned be-
tween a pair of words, priority is given to the re-
lation which is most compatible with the general
semantic class of the noun in the relation.
Some relations, such as event, are very general
and therefore are not considered even if their prob-
ability is higher, provided a more meaningful rela-
tion is available. Moreover, we incorporate some
syntactic and word-order dependencies. For in-
stance, a noun which is a complement of a prepo-
sitional phrase and is thus found in the following
configurations: p(A)N (with any number of ad-
jectives preceding the noun) is not licensed for the
morphosemantic relation agent if the verb is ac-
tive.
Step 6. Based on the general semantic class of
the noun and/or the verb, some additional poten-
tial relations are added to the respective synsets in
the model (Example 2). For example, a noun be-
longing to the class noun.location can poten-
tially enter into a location relation with the verb,
although the respective noun synset might not en-
ter into this morphosemantic relation.
Example 2. Newly added relations
verb.label role
contact agent
motion location
noun.label role
person agent inv
location location inv
attribute property inv
Step 7. We extend the number of relations by
learning from previous occurrences. Learning is
performed on the News subcorpus (see Table 1),
and further experiments extend the information ac-
quired in the learning phase with data from the en-
tire corpus.
Given a verb is licensed to enter into a particu-
lar morphosemantic relation, we assign this rela-
tion to a co-occurring verb-noun pair, even if the
noun in this pair does not enter into this type of re-
lation, provided other nouns belonging to the same
general semantic class have been observed to co-
occur with this verb. This assumption is general-
ized over all the members of the verb synset and
the noun synset to which the respective verb and
noun belong.
124
Example 3 shows how learning is applied:
based on the occurrences of verbs from the
same synset (ID: 00974367-v, announce:2; de-
clare:2) in a morphosemantic relation of type
agent with nouns belonging to the semantic class
noun.group (in 60.4% of the cases), we asso-
ciate the verb announce with the noun Ministry
(noun.group) through the agent relation de-
spite the fact that Ministry is not linked to any verb
through a morphosemantic relation.
Example 3.
Learned:
Verb ID relation noun.label freq
00974367-v by-means-of noun.artifact 5
00974367-v by-means-of noun.act 14
00974367-v agent noun.person 9
00974367-v agent noun.group 16
The Ministry of Defense announced on Wednesday
its new plans.
announce, 00974367-v, verb.communication
{make known, make an announcement}
Ministry, 08114004-n, noun.group
VERB announce: agent
NOUN Ministry: agent inv
At a next stage of generalization we consider
only the general semantic classes of a verb and a
noun which are candidates to enter in a morphose-
mantic relation. This step relies on the assumption
that verbs from the same semantic class (e.g. per-
ception verbs) show preference to similar semantic
patterns. The learned information is in a general-
ized form, as presented in Example 4.
Example 4. A sample of semantic compatibil-
ity information learned from the News subcorpus.
verb.label relation noun.label freq
verb.perception undergoer noun.person 15
verb.perception undergoer noun.group 3
verb.perception state noun.state 12
verb.perception by-means-of noun.state 12
verb.perception by-means-of noun.act 6
verb.perception uses noun.group 3
verb.perception agent noun.person 3
4.5 Implementation
We implement the word-to-word similarities with
the ws4j package for Java8, which is based on the
original Perl package Wordnet::Similarity
(Pedersen et al, 2007).
We use the Princeton WordNet 3.0 and access it
through Java libraries such as JAWS9 and JWI10.
8https://code.google.com/p/ws4j/
9http://lyle.smu.edu/?tspell/jaws/
10http://projects.csail.mit.edu/jwi/
api/
We also employ a list of morphosemantic relations
available for WordNet 3.0. The access to BulNet
is modeled roughly on PWN. The corresponding
synsets in the two wordnets are linked by means
of synset IDs.
5 Results and Evaluation
Evaluation was performed with respect to the cov-
erage of the morphosemantic relations, the preci-
sion of the assigned relations, and the informa-
tiveness of the extracted semantic patterns. Test-
ing was carried out on the News subcorpus (Ta-
ble 1) totaling 100,628 tokens distributed in four
subdomains: Politics, Economy, Culture, and Mil-
itary. The corpus comprises 3,362 sentences and
7,535 clauses for Bulgarian and 3,678 sentences
and 8,624 clauses for English.
Method # clauses # relations
1 Baseline 0 920 1, 183
2 Baseline 951 1, 246
3 Learned and
transferred to
synsets
1, 032 1, 353
4 Learned and
transferred to
semantic classes
1, 395 1, 973
Table 2: Coverage of relations in the News subcor-
pus using the baseline method (2) and the extended
method (4)
Table 2 presents: (1) the number of mor-
phosemantic relations covered by the baseline 0
method, i.e. applying only the Princeton WordNet
morphosemantic relations; (2) the number of mor-
phosemantic relations after adding those specific
to Bulgarian; and (3, 4) the number of morphose-
mantic relations learnt with the method described
in Step 7 (Section 4.4). The results show that the
extended method leads to an increase in coverage
by 58.35% (compare the extended method (4) with
the baseline (2)).
To assess the precision of the automatic relation
assignment, we performed evaluation on five rela-
tions: agent, undergoer, location, result, and state
(Table 3). The overall precision based on these
relations is 0.774 for the baseline and 0.721 for
the extended method, which shows that the per-
formance of the method is relatively consistent.
We also obtained two types of generalizations
based on WordNet and confirmed by the corpus
125
Relation Precision
(baseline)
Precision
(extended
method)
Agent 0.963 0.950
Undergoer 0.575 0.577
Location 0.857 0.750
Result 0.303 0.316
State 0.750 0.667
Table 3: Precision of the results for five seman-
tic relations ? baseline (Princeton and Bulgarian
morphosemantic relations) and extended method
(transfer of morphosemantic relations to pairs of
nouns and verbs one of which does not participate
in morphosemantic relations)
data that can be used for further classification. The
first one represents the combinatorial properties
of general semantic verb classes with particular
(morpho)semantic relations. For example a verb
of communication is more likely linked to an
agent rather than to a result (Example 5).
Example 5. Frequency of relations in WordNet
and the entire corpus.
verb.label relation fr wn fr cor
verb.com agent 744 555
verb.com undergoer 306 362
verb.com by-means-of 244 560
verb.com result 192 283
Moreover, the nouns that are eligible to collo-
cate as agents with a communication verb belong
to a limited set of classes ? noun.person or
noun.group (Example 6).
Example 6. Frequency of relations in WordNet
and the entire corpus.
verb.label relation noun label fr wn fr cor
verb.com agent noun.person 473 333
verb.com agent noun.group 271 220
The second generalization refers to the prob-
ability of the association of a given verb sense
with a particular set of semantic relations and the
general noun classes eligible for these relations.
For instance, the communication verb order
(Example 7) in the sense of give instructions
to or direct somebody to do something with
authority connects with the highest probability
with an undergoer (noun.person) and an
agent (noun.person).
Example 7. Relations of the verb order in
WordNet and the entire corpus.
verb.label relation noun label fr wn fr cor
verb.com undergoer noun.person 33 8
verb.com agent noun.person 12 6
verb.com by-means-of noun.phen 9 7
6 Conclusions and Future Work
In this paper we have explored the applicability
of the morphosemantic relations in WordNet for
cross-language identification of semantic and in
some cases syntactic dependencies between col-
located verbs and nouns. As morphosemantic re-
lations are valid cross-linguistically, the method is
applicable for any language or a pair of languages.
The limitations of the proposed method lie in
the insufficient connectivity of the nodes (synsets
and literals). We have described an approach to
automatic wordnet enhancement, which has re-
sulted in a substantial increase in the number
of morphosemantic relations. Another inherent
weakness is that some of the relations are very
general or vaguely defined. We have addressed
this problem by considering relations jointly with
the general semantic classes associated with the
synsets in WordNet.
The method has the advantage of using lim-
ited linguistic annotation. It does not require text
alignment, syntactic parsing or word-sense disam-
biguation. The cross-linguistic similarity partially
disambiguates the target words, so that the senses
for which the clauses are not similar are discarded;
the semantic restrictions imposed by the general
semantic classes and their compatibility also con-
tribute to semantic disambiguation. The method
is thus to a large extent language-independent and
well suited to less-resourced languages.
In order to improve the performance and over-
come the limitations of the method, we plan to
explore deeper into the possibilities of predicting
the roles of the verb participants from their gen-
eral semantic class and the semantic compatibility
of verb and noun classes, as well as from the com-
patibility of the different types of morphosemantic
relations with the general semantic classes.
Another line of research to pursue in the future
is the application of the proposed method and its
subtasks to other NLP tasks, such as clause split-
ting, alignment based on wordnet relations, ex-
traction of patterns from comparable corpora, and
augmentation and enhancement of training data
for MT.
126
References
Satanjeev Banerjee and Ted Pedersen. 2002. An
adapted lesk algorithm for word sense disambigua-
tion using wordnet. Lecture Notes In Computer Sci-
ence, 2276:136?145.
Verginica Barbu Mititelu. 2012. Adding Morpho-
Semantic Relations to the Romanian Wordnet. In
Proceedings of the Eight International Conference
on Language Resources and Evaluation (LREC?12),
pages 2596?2601.
Orhan Bilgin, O?zlem Cetinoug?lu, , and Kemal Oflazer.
2004. Morphosemantic Relations In and Across
Wordnets ? A Study Based on Turkish. In P. So-
jka, K. Pala, P. Smrz, C. Fellbaum, and P. Vossen,
editors, Proceedings of the Global Wordnet Confer-
ence, pages 60?66.
Xavier Carreras and Lluis Marquez. 2004. Intro-
duction to the CoNLL-2004 Shared Task: Semantic
Role Labeling. In Proceedings of CoNLL-2004.
Xavier Carreras and Lluis Marquez. 2005. Intro-
duction to the CoNLL-2005 Shared Task: Semantic
Role Labeling. In Proceedings of CoNLL-2005.
Christine Fellbaum, Anne Osherson, and Peter E.
Clark. 2009. Putting Semantics into Word-
Net?s ?Morphosemantic? Links. In Z. Vetulani and
H. Uszkoreit, editors, Proceedings of the Third Lan-
guage and Technology Conference, Poznan, Poland.
Reprinted in: Responding to Information Society
Challenges: New Advances in Human Language
Technologies, volume 5603 of Springer Lecture
Notes in Informatics, pages 350?358.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245?288, September.
Jan Hajic. 1998. Building a syntactically annotated
corpus: The prague dependency treebank. Issues of
Valency and Meaning, pages 106?132.
Jan Hajic?, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antnia Mart??, Llu??s
Ma?rquez, Adam Meyers, Joakim Nivre, Sebastian
Pado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 Shared Task: Syntactic and Semantic Depen-
dencies in Multiple Languages. In Proceedings of
the Thirteenth Conference on Computational Nat-
ural Language Learning (CoNLL 2009): Shared
Task, pages 1?18.
Graeme Hirst and David St-Onge. 1998. Lexical
chains as representations of context for the detec-
tion and correction of malapropisms. In Christiane
Fellbaum, editor, WordNet: An electronic lexical
database, page 305332. MIT Press.
Jay J. Jiang and David W. Conrath. 1997. Seman-
tic similarity based on corpus statistics and lexical
taxonomy. In Proceedings on International Con-
ference on Research in Computational Linguistics,
page 1933.
S. Koeva and A. Genov. 2011. Bulgarian language
processing chain. In Proceedings of Integration of
multilingual resources and tools in Web applica-
tions. Workshop in conjunction with GSCL 2011,
University of Hamburg.
Svetla Koeva, Cvetana Krstev, and Dusko Vitas. 2008.
Morpho-semantic relations in wordnet - a case study
for two slavic langages. In Proceedings of the
Fourth Global WordNet Conference, pages 239?254.
Svetla Koeva, Ivelina Stoyanova, Svetlozara Leseva,
Tsvetana Dimitrova, Rositsa Dekova, and Ekaterina
Tarpomanova. 2012. The Bulgarian National Cor-
pus: Theory and Practice in Corpus Design. Journal
of Language Modelling, 0(1):65?110.
Svetla Koeva. 2008. Derivational and morphosemantic
relations in bulgarian wordnet. Intelligent Informa-
tion Systems, XVI:359?369.
Joel Lang and Mirella Lapata. 2011a. Unsupervised
Semantic Role Induction via Split-Merge Cluster-
ing. In Proceedings of ACL 2011, pages 1117?1126.
Joel Lang and Mirella Lapata. 2011b. Unsupervised
Semantic Role Induction with Graph Partitioning.
In Proceedings of EMNLP 2011, pages 1320?1331.
Claudia Leacock and Michael Chodorow. 1998. Com-
bining local context and WordNet similarity for
word sense identification. In C. Fellbaum, edi-
tor, WordNet: An electronic lexical database, pages
265?283. MIT Press.
Dekang Lin. 1998. An information-theoretic defini-
tion of similarity. In Proceedings of the Interna-
tional Conference on Machine Learning.
Lluis Marquez, Xavier Carreras, Kenneth C.
Litkowski, and Suzanne Stevenson. 2008. Se-
mantic role labeling: An introduction to the special
issue. Computational Linguistics, 34(2):145?159.
Rada Mihalcea, Courtney Corley, and Carlo Strappa-
rava. 2006. Corpus-based and Knowledge-based
Measures of Text Semantic Similarity. In Proceed-
ings of the American Association for Artificial Intel-
ligence (AAAI 2006), Boston.
Alessandro Moschitti and Cosmin Adrian Bejan. 2004.
A semantic kernel for predicate argument classica-
tion. In In Proceedings of CONLL 2004, pages 17?
24.
Roberto Navigli and Simone Paolo Ponzetto. 2012.
Joining Forces Pays Off: Multilingual Joint Word
Sense Disambiguation. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natu-
ral Language Learning, Jeju Island, Korea, pages
1399?1410.
127
K. Pala and D. Hlavackova. 2007. Derivational rela-
tions in Czech Wordnet. In Proceedings of the Work-
shop on Balto-Slavonic Natural Language Process-
ing, pages 75?81.
Martha Palmer, Paul Kingsbury, and Daniel Gildea.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71?106.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted
Pedersen. 2003. Using measures of semantic re-
latedness for word sense disambiguation. In Pro-
ceedings of the Fourth International Conference on
Intelligent Text Processing and Computational Lin-
guistics, pages 241?257.
Ted Pedersen, Serguei Pakhomov, Siddharth Patward-
han, and Christopher G. Chute. 2007. Measures of
semantic similarity and relatedness in the biomed-
ical domain. Journal of Biomedical Informatics,
40(3):288?299.
Maciej Piasecki, Stanisaw Szpakowicz, and Bartosz
Broda. 2009. A wordnet from the ground up. In
Wroclaw: Oficyna Wydawnicza Politechniki Wro-
clawskiej.
Maciej Piasecki, Radoslaw Ramocki, and Pawel
Minda. 2012a. Corpus-based semantic filtering in
discovering derivational relations. In AIMSA, pages
14?22.
Maciej Piasecki, Radosaw Ramocki, and Marek
Maziarz. 2012b. Automated Generation of Deriva-
tive Relations in the Wordnet Expansion Perspec-
tive. In Proceedings of the 6th Global Wordnet Con-
ference, Matsue, Japan, January.
Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James
Martin, and Daniel Jurafsky. 2004. Shallow Seman-
tic Parsing Using Support Vector Machines. In Pro-
ceedings of NAACL-HLT 2004.
Sameer Pradhan, Wayne Ward, and James Martin.
2008. Towards Robust Semantic Role Labeling.
Computational Linguistics, (34):289?310.
Philip Resnik. 1995. Using information content to
evaluate semantic similarity in a taxonomy. In Pro-
ceedings of the 14th International Joint Conference
on Artificial Intelligence, pages 448?453.
Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.
Petruck, Christopher R. Johnson, and Jan Scheczyk.
2010. Framenet ii: Extended theory and practice.
Web Publication. http://framenet.icsi.
berkeley.edu.
Lei Shi and Rada Mihalcea. 2005. Putting Pieces To-
gether: Combining FrameNet, VerbNet and Word-
Net for Robust Semantic Parsing. In A. Gelbukh,
editor, CICLing 2005, LNCS 3406, page 100111.
Carina Silberer and Simone Paolo Ponzetto. 2010.
UHD: Cross-lingual Word Sense Disambiguation
using multilingual co-occurrence graphs. In Pro-
ceedings of the 5th International Workshop on Se-
mantic Evaluations (SemEval-2010), pages 134?
137.
Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using predicate-argument
structures for information extraction. In Proceed-
ings of ACL-2003, pages 8?15.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu??s Ma?rquez, and Joakim Nivre. 2008. The
CoNLL-2008 Shared Task on Joint Parsing of Syn-
tactic and Semantic Dependencies. In CoNLL 2008:
Proceedings of the Twelfth Conference on Natural
Language Learning, pages 159?177.
Robert Swier and Suzanne Stevenson. 2005. Exploit-
ing a Verb Lexicon in Automatic Semantic Role
Labelling. In In Proceedings of Human Language
Technology Conference and Conference on Empiri-
cal Methods in Natural Language Processing 2005,
pages 883?890.
Kristina Toutanova, Aria Haghighi, and Christopher
Manning. 2008. A global joint model for seman-
tic role labeling. Computational Linguistics.
Piek Vossen. 2004. EuroWordNet: A Multilingual
Database of Autonomous and Language-Specific
Wordnets Connected via an Inter-Lingual Index.
International Journal of Lexicography, 17(1):161?
173, June.
Zhibiao Wu and Martha Palmer. 1994. Verb seman-
tics and lexical selection. In Proceedings of the
32nd Annual Meeting of the Association for Com-
putational Linguistics, pages 133?138.
Nianwen Xue and Martha Palmer. 2004. Calibrating
features for semantic role labeling. In Dekang Lin
and Dekai Wu, editors, Proceedings of EMNLP04,
Barcelona, Spain, July.
128
Proceedings of the 2nd Workshop on Predicting and Improving Text Readability for Target Reader Populations, pages 39?48,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Text Modification for Bulgarian Sign Language Users
Slavina Lozanova? Ivelina Stoyanova? Svetlozara Leseva?
slavinal@abv.bg iva@dcl.bas.bg zarka@dcl.bas.bg
Svetla Koeva? Boian Savtchev?
svetla@dcl.bas.bg bsavtchev@gmail.com
? AssistNet, Sofia, Bulgaria
? Department of Computational Linguistics, IBL, BAS, Sofia, Bulgaria
? Cambridge Language Assessment Centre BG015, Sofia, Bulgaria
Abstract
The paper discusses the main issues re-
garding the reading skills and compre-
hension proficiency in written Bulgarian
of people with communication difficulties,
and deaf people, in particular. We consider
several key components of text compre-
hension which pose a challenge for deaf
readers and propose a rule-based system
for automatic modification of Bulgarian
texts intended to facilitate comprehension
by deaf people, to assist education, etc. In
order to demonstrate the benefits of such a
system and to evaluate its performance, we
have carried out a study among a group of
deaf people who use Bulgarian Sign Lan-
guage (BulSL) as their primary language
(primary BulSL users), which compares
the comprehensibility of original texts and
their modified versions. The results shows
a considerable improvement in readability
when using modified texts, but at the same
time demonstrates that the level of com-
prehension is still low, and that a complex
set of modifications will have to be imple-
mented to attain satisfactory results.
1 Introduction
The individual development of deaf people de-
pends on a complex of factors, which include the
cause and the degree of hearing loss, the age of
hearing loss onset, educational background, lan-
guage and communication methods, cultural iden-
tification, disability preconceptions. Hearing loss
leads to a limited spoken language input, delays
in language acquisition and communication dif-
ficulties. Deaf children and adults demonstrate
lower reading achievements than hearing people
regardless of the degree of hearing loss, and the
use (or lack) of high-performing hearing amplifi-
cation devices (Paul, 1998; Conrad, 1979; Mussel-
man, 2000; Traxler, 2000; Vermeulen AM, 2007),
which shows that reading skills are influenced
by complex social, linguistic and communication-
related factors rather than by the sensory disability
alone.
The paper explores reading comprehension of
Deaf people1 who use Bulgarian Sign Language
(BulSL) as their primary language. Various re-
search studies both in Bulgaria and abroad have
shown that hearing-impaired BulSL users have
poorer reading skills than their hearing peers. Var-
ious methods for text modification have been ex-
plored to the end of obtaining texts that corre-
spond to the proficiency of the readers. Most of
the modification methodologies have been focused
on simplifying the original texts and decreasing
their complexity (Inui et al, 2003). Our approach,
however, focuses not on simplification, but on the
adaptation of the structure of the original texts to
the linguistic properties of BulSL.
The paper is organized as follows. Section 2
discusses the reading skills of BulSL users, paying
attention to children?s and adult education in Bul-
garia focused on the acquisition of Bulgarian and
the relationship between BulSL and verbal Bulgar-
ian. After outlining the main principles which un-
derlie text adaptation aimed at fostering text com-
prehensibility in the target population, we present
a rule-based method for automatic modification of
Bulgarian written texts. The method applies a set
of linguistic transformations and produces modi-
fied versions of the texts, which are better suited
to the needs of BulSL users (Section 3). Section
4 describes an experiment devised to explore the
reading comprehension of BulSL users of original
and modified texts. Section 5 draws conclusions
1Capitalized ?Deaf? is used to denote the community of
deaf people who use Sign Language as their primary lan-
guage. The term emphasizes the socio-cultural model of
Deafness rather than the medical view of hearing impairment.
39
and outlines some directions for future work.
2 Reading Skills of Hearing-Impaired
People
2.1 Education
Previous research has shown that deaf students lag
behind their hearing peers in reading comprehen-
sion, because they experience difficulties with vo-
cabulary (Paul, 1996), syntax (Kelly, 1996), and
the use of prior knowledge and metacognition
(Trezek et al, 2010). In addition, reading com-
prehension difficulties are often linked to lack of
general knowledge due to inadequate education
and limited access to information (Lewis and Jack-
son, 2001). Two independently performed studies
(Albertini and Mayer, 2011; Parault and William,
2010) have found out that deaf college students?
reading skills are below those of six-graders2.
MacAnally et al (1999) support the hypothe-
sis that using less complicated and more accessi-
ble reading materials, consisting of language con-
structions close or similar to sign language struc-
ture can facilitate reading comprehension and mo-
tivate deaf people to read. In support of this claim
Berent (2004) points out that deaf students would
read more smoothly if the subject, verb, and object
are in a simple SVO (subject-verb-object) word
order. These studies provide evidence in favour
of text adaptation that reflects features of the sign
language and the development of modified teach-
ing materials.
Bulgarian education for the deaf is based en-
tirely on the oral approach and no systematic effort
has been invested into exploring total communi-
cation and bilingual approaches (Lozanova, 2002;
Saeva, 2010). Even in the specialized schools
for the deaf, where sign language communication
occurs naturally, BulSL has not been integrated
into the school curriculum. Besides, the linguis-
tic analysis of BulSL has been limited to mere
descriptions and presentation of signs: Bulgar-
ian Sign Language dictionaries (1966, 1996); Sign
Language Dictionary in Civil Education (Stoy-
anova et al, 2003); Specialized Multimedia BulSL
dictionary3 (2005).
In order to improve education and the reading
and communication skills of deaf people, a com-
prehensive study of BulSL is necessary, that will
211-12-year-olds.
3http://www.signlanguage-bg.com
provide the basis for developing advanced meth-
ods for automatic text modification directed to im-
proving text readability for deaf BulSL users.
2.2 Sign Language and Verbal Language
Research has shown that Deaf children of Deaf
parents (DCDP) with sign language as their pri-
mary mode of communication outperform their
deaf peers of hearing parents (DCHP) on differ-
ent academic tests, including reading tests (May-
berry, 2000). Several studies have found a positive
correlation between the advanced American Sign
Language (ASL) skills of deaf students and their
higher reading skills (Hoffmeister, 2000; Padden
and Ramsey, 2000). Evidence is not conclusive as
to how sign languages relate to verbal languages
and what influence they have on the acquisition
of general communication skills and knowledge
about the world.
The extensive research on sign languages in the
last fifty years worldwide has shown that they are
independent linguistic systems which differ from
verbal languages (Stokoe, 1960; Stokoe, 1972;
Sutton-Spence and Woll, 2003). Being an inde-
pendent language, a sign language affects the way
in which its users conceptualize the world, accord-
ing to the principle of linguistic relativity, first for-
mulated by Sapir and Whorf (Lee, 1996). Due
to the fact that sign languages are very different
from verbal ones, many Deaf people attain a cer-
tain level of proficiency in a verbal language at the
state of interlanguage4 (Selinker, 1972) but that
level is not sufficient to ensure successful social
integration.
2.3 Readability of Written Texts for Native
Users of Sign Language
Readability is measured mainly on the basis of vo-
cabulary and sentence complexity, including word
length and sentence length: the higher the letter,
syllable and word count of linguistic units, the
greater the demand on the reader. Some syntactic
structures also affect readability ? negative and in-
terrogative constructions, passive voice, complex
sentences with various relations between the main
clause and the subordinates, long distance depen-
dencies, etc. Besides, readability improves if the
information in a text is well-organized and effec-
4The term ?interlanguage? denotes the intermediate state
in second language acquisition characterized by insufficient
understanding and grammatical and lexical errors in language
production.
40
tively presented so that its local and global dis-
course structure is obvious to the reader (Swann,
1992).
Text modification is often understood as simpli-
fication of text structure but this may result in an
inadequately low level of complexity and loss of
relevant information. Moreover, using a limited
vocabulary, avoiding certain syntactic structures,
such as complex sentences, is detrimental to the
communication and learning skills.
The efforts towards providing equal access to
information for Deaf people lack clear principles
and uniformity. Firstly, there is no system of cri-
teria for evaluation of text complexity in terms of
vocabulary, syntactic structure, stylistics and prag-
matics. Further, no standard framework and re-
quirements for text modification have been estab-
lished, which limits its applications.
3 Text Modification of Bulgarian
Language modification for improved readability is
not a new task and its positive and negative aspects
have been extensively discussed (BATOD, 2006).
One of the most important arguments against text
modification is that it requires a lot of resources in
terms of human effort and time. An appealing al-
ternative is to employ NLP methods that will facil-
itate the implementation of automatic modification
for improved readability of written texts aimed at
the BulSL community.
3.1 General Principles of Text Modification
Several studies have observed different aspects of
text modification: splitting chosen sentences with
existing tools (Petersen and Ostendorf, 2007),
?translating? from complex to simplified sentences
with statistical machine translation methods (Spe-
cia, 2010), developing text simplification systems
(Candido et al, 2009), etc. (Siddharthan, 2011)
compares a rule-based and a general purpose gen-
erator approaches to text adaptation. Recently the
availability of the Simple English Wikipedia has
provided the opportunity to use purely data-driven
approaches (Zhu et al, 2010). The main oper-
ation types both in statistical and in rule-based
approaches are: change, delete, insert, and split
(Bott and Saggion, 2011).
Although text modification is a highly language
dependent task, it observes certain general princi-
ples:
? Modified text should be identical or very
close in meaning to the original.
? Modified text should be grammatically cor-
rect and structurally authentic by preserving
as much as possible of the original textual and
syntactic structure.
? In general, modified text should be character-
ized by less syntactic complexity compared
with the original text. However, the purpose
of the modification is not to simplify the text
but rather to make the information in it more
accessible and understandable by represent-
ing it in relatively short information chunks
with simple syntax without ellipses.
? It should be possible to extend the range
of modifications and include other compo-
nents which contribute to readability or intro-
duce other functionalities that facilitate read-
ing comprehension, such as visual represen-
tations.
3.2 Stages of Text Modification
At present we apply a limited number of modifica-
tions: clause splitting, simplification of syntactic
structure of complex sentences, anaphora resolu-
tion, subject recovery, clause reordering and inser-
tion of additional phrases.
3.2.1 Preprocessing
The preprocessing stage includes annotation with
the minimum of grammatical information nec-
essary for the application of the modification
rules. The texts are sentence-split, tokenized,
POS-tagged and lemmatized using the Bulgarian
Language Processing Chain5 (Koeva and Genov,
2011). Subsequently, clause splitting is applied
using a general method based on POS tagging,
lists of clause delimiters ? clause linking words
and multiword expressions and punctuation, and a
set of language specific rules.
We define a clause as a sequence of words be-
tween two clause delimiters where exactly one fi-
nite verb occurs. A finite verb is either: (a) a sin-
gle finite verb, e.g. yade (eats); (b) or a finite verb
phrase formed by an auxiliary and a full verb, e.g.
shteshe da yade (would eat); or (c) a finite copu-
lar verb phrase with a non-verbal subject comple-
ment, e.g. byaha veseli (were merry).
We identify finite verbs by means of a set of
rules applied within a window, currently set up to
5http://dcl.bas.bg/services/
41
two words to the left or to the right:
Rule P1. A single finite verb is recognized by the
POS tagger. (Some smoothing rules are applied to
detect the verb forms actually used in the context
? e.g. forms with reflexive and negative particles).
Rule P2. If auxiliaries and a lexical verb form
occur within the established window, they form a
single finite verb phrase. (This rule subsumes a
number of more specific rules that govern the for-
mation of analytical forms of lexical verbs by at-
taching auxiliary verbs and particles.)
Rule P3. If an auxiliary (or a copular verb) but not
a lexical verb form occurs within the established
window, the auxiliary or copula itself is a single
finite verb.
Rule P4. If a modal and/or a phase verb and a lex-
ical verb form occur within the established win-
dow, they form a single finite verb phrase.
Rule P5. If a modal (and/or a phase) verb but
not a lexical verb form occurs within the estab-
lished window, the modal verb itself is a single fi-
nite verb.
A clause is labeled by a clause opening (CO)
at the beginning and a clause closing (CC) at the
end. We assume that at least one clause boundary
? an opening and/or a close ? occurs between any
pair of successive finite verbs in a sentence. Each
CO is paired with a CC, even if it might not be
expressed by an overt element.
We distinguish two types of COs with respect to
the type of clause they introduce: coordinate and
subordinate. Most of the coordinating conjunc-
tions in Bulgarian are ambiguous since they can
link not only clauses, but also words and phrases.
On the contrary, most of the subordinating con-
junctions, to the exception of several subordina-
tors which are homonymous with prepositions,
particles or adverbs, are unambiguous.
Clause closing delimiters are sentence end,
closing comma, colon, semicolon, dash.
The following set of clause splitting rules are
applied (C1-C9):
Rule C1. The beginning of a sentence is a coordi-
nate CO.
Rule C2. A subordinating clause linking word or
phrase denotes a subordinate CO.
Rule C3. If a subordinate CO is on the top of the
stack, we look to the right for a punctuation clause
delimiter (e.g. comma) which functions as a CC
element.
Rule C4. If a subordinate CO is on the top of the
stack, and the CC is not identified yet, we look
for a coordinating clause linking word or phrase
which marks a coordinate CO.
Rule C5. If a coordinate CO is on the top of
the stack, we look for another coordinating clause
linking word or phrase which marks a coordinate
CO.
Rule C6. If a coordinate CO is on the top of
the stack and no coordinate CO is found, we look
for a punctuation clause delimiter (e.g. a comma)
which functions as a CC element.
Rule C7. If no clause boundary has been identi-
fied between two finite verbs, we insert a clause
boundary before the second finite verb.
Rule C8. All COs from the stack should have a
corresponding CC.
Rule C9. The part of the sentence to the right of
the last finite verb until the end of the sentence
should contain the CCs for all COs still in the
stack.
3.2.2 Empty subject recovery
The detection, resolution, and assignment of func-
tion tags to empty sentence constituents have be-
come subject of interest in relation to parsing
(Johnson, 2002; Ryan Gabbard and Marcus, 2004;
Dienes and Dubey, 2003), in machine translation,
information extraction, automatic summarization
(Mitkov, 1999), etc. The inventory of empty cate-
gories includes null pronouns, traces of extracted
syntactic constituents, empty relative pronouns,
etc. So far, we have limited our work to subject
recovery.
A common feature of many, if not all, sign lan-
guages (BulSL among others) is that each sentence
requires an overt subject. Moreover, each subject
is indexed by the signer by pointing to the denoted
person or thing if it is present in the signing area,
or by setting up a point in space as a reference
to that person or thing, if it is outside the sign-
ing area, and referring to that point whenever the
respective person or object is mentioned. In or-
der to avoid ambiguity, different referents are as-
signed different spatial points. Deaf people find
it difficult to deal with complex references in writ-
ten texts where additional disambiguating markers
are rarely available. Being a pro(noun)-drop lan-
guage, Bulgarian allows the omission of the sub-
ject when it is grammatically inferable from the
context.
So far the following rules for subject recovery
have been defined and implemented:
42
Rule SR1. In case the verb is in the first or sec-
ond person singular or plural and the clause lacks a
nominative personal pronoun that agrees with the
finite verb, a personal pronoun with the respective
agreement features is inserted in the text.
Rule SR2. In case the verb is in the third person
singular or plural and the clause lacks a noun or
a noun phrase that a) precedes the verb; and b)
agrees with the verb in person, number and gen-
der, the closest noun (a head in a noun phrase) in
the preceding clause that satisfies the agreement
features of the verb is inserted in the text. (The
precision of the rule for singular verbs is low.)
3.2.3 Anaphora Resolution
With respect to text modification regarding
anaphora resolution, we focus on a limited types
of pronominal anaphors ? personal, relative and
possessive pronouns.
Bulgarian personal pronouns agree in gender
and number with their antecedent. Possessive pro-
nouns express a relation between a possessor and
a possessed item, and agree both with their an-
tecedent (through the root morpheme) and with the
head noun (through the number and gender fea-
tures of the inflection). For instance in the sen-
tence Vidyah direktora v negovata kola (I saw the
director in his car), the possessive pronoun negov
indicates that the possessor is masculine or neuter
singular and the inflection -a ? that the possessed
is feminine gender, singular. The agreement with
the possessor is a relevant feature to text modifica-
tion. Some relative pronouns koyto (which) (type
one) agree with their antecedent in gender and
number while others (type two) ? chiyto (whose)
agree with the noun they modify and not with their
antecedent.
We have formulated the following rules for
anaphora resolution:
Rule AR1. The antecedent of a personal or a pos-
sessive pronoun is the closest noun (the head in the
noun phrase) within a given window to the left of
the pronoun which satisfies the agreement features
of the pronoun.
Rule AR2. The antecedent of a relative pronoun
is the nearest noun (the head in the noun phrase)
in the preceding clause that satisfies the agreement
features of the pronoun.
The following rules for modification of
anaphora can be used:
Rule R1. The third personal pronoun is replaced
with the identified antecedent.
Rule R2. The possessive pronoun is replaced with
a prepositional phrase formed by the preposition
na (of ) and the identified antecedent.
Rule R3. A relative pronoun of type one is
replaced with the identified antecedent.
Rule R4. The relative pronoun chiyto (whose)
is replaced with a prepositional phrase formed
by the preposition na (of) and the identified
antecedent.
Rule R5. The relative pronoun kakavto (such
that) is replaced by a noun phrase formed by
a demonstrative pronoun and the identified
antecedent takava chanta (that bag).
3.2.4 Simplification of Complex Sentences
Complex sentences are one of the main issues
for deaf readers because in BulSL, as well as in
other sign languages, they are expressed as sep-
arate signed statements and the relation between
them is explicit.
(Van Valin and LaPolla, 1997) observe that the
elements in complex sentences (and other con-
structions) are linked with a different degree of
semantic and syntactic tightness, which is re-
flected in the Interclausal Relations Hierarchy.
The clauses in a sentence have different degree of
independence, which determines whether they can
be moved within the sentence or whether they can
form an individual sentence.
Temporally related events in BulSL most often
are represented in a chronological order, and the
relation between them is expressed by separate
signs or constructions (Example 1).
Example 1.
Zabavlyavayte se, dokato nauchavate i novi
neshta.
Have fun while you learn new things.
Signed sentence:
Vie se zabavlyavate. Ednovremenno nauchavate
novi neshta /ednovremenno/.
You have fun. Simultaneously, you learn new
things /simultaneously/.
(the sign ?simultaneously? can be repeated at the
end of the sentence again)
Chambers et al (2007) and Tatu and Srikanth
(2008) identify event attributes and event-event
features which are used to describe temporal re-
lations between events. Attributes include tense,
grammatical aspect, modality, polarity, event
43
class. Further, the event-event features include the
following: before, includes, begins, ends, simul-
taneously, and their respective inverses (Cham-
bers et al, 2007), as well as sameActor (bi-
nary feature indicating that the events share the
same semantic role Agent), eventCoref (binary at-
tribute capturing co-reference information), one-
Sent (true when both events are within the same
sentence), relToDocDate (defining the temporal
relation of each event to the document date) (Tatu
and Srikanth, 2008).
(Pustejovsky et al, 2003) also introduce tempo-
ral functions to capture expressions such as three
years ago, and use temporal prepositions (for,
during) and temporal connectives (before, while).
Three types of links are considered: TLINK (tem-
poral link between an event and a moment or pe-
riod of time); SLINK (subordination link between
two events); and ALINK (aspectual link between
aspectual types).
The structure of the complex sentences is sim-
plified by clause reordering that explicitly reflects
the chronological order of the described events.
The preposition or postposition of clauses with
temporal links if, before, after, etc. may not match
the actual causal order. In such cases the order of
clauses is simply reversed based on rules of the
type:
Temporal link sled kato /when, after/
Construction CL1 temporal link CL2
Modification(s) CL2. Sled tova /then/ CL1.
3.2.5 Post-editing
Post editing aims at providing grammatically cor-
rect and semantically complete modified text.
Clause reordering might lead to inappropriate use
of verb tenses. Coping a subject from the previous
sentence might require a transformation from an
indefinite to a definite noun phrase. Thus, several
checks for grammaticality and text cohesion are
performed and relevant changes to verb forms and
noun definiteness are made. Specific expressions
are introduced to highlight temporal, causative,
conditional and other relations and to serve as con-
nectives.
Example 2 shows a fully modified text.
Example 2.
Original:
Vaz osnova na doklada ot razsledvaneto, sled kato
litseto e bilo uvedomeno za vsichki dokazatelstva
i sled kato e bilo izslushano, organat e izdal
razreshenie.
Based on the report from the investigation,
after the person has been notified about all
evidence and after /he/ has been heard, the
authorities have issued a permit.
Modified:
Litseto e bilo uvedomeno za vsichki dokazatelstva.
Litseto e bilo izslushano.
Sled tova vaz osnova na doklada ot razsledvaneto,
organat mozhe da dade razreshenie.
The person has been notified about all evi-
dence.
The person has been heard.
After that based on the report from the investiga-
tion, the authorities may issue a permit.
3.3 Evaluation of System Performance
The evaluation of performance is based on the
Bulgarian part of the Bulgarian-English Clause-
Aligned Corpus (Koeva et al, 2012) which
amounts to 176,397 tokens and includes several
categories: administrative texts, fiction, news. The
overall evaluation of the system performance is as-
sessed in terms of the evaluation of all subtasks
(Section 3.2) as presented in Table 1. The evalu-
ation of finite verbs and anaphora recognition, as
well as subject identification is performed manu-
ally on a random excerpt of the corpus. Clause
splitting is evaluated on the basis of the manual
annotation of the corpus. We assess the precision
and recall in terms of full recognition and partial
recognition. In the first case the entire verb phrase,
clause, anaphora, or dropped subject is recognized
correctly, while in the latter ? only a part of the
respective linguistic item is identified. We ac-
count for partial recognition since it is often suf-
ficient to produce correct overall results, e.g. par-
tial verb phrase recognition in most cases yields
correct clause splitting.
4 Experiments and Evaluation of
Readability of Modified Texts
4.1 Outline of the Experiment
4.1.1 Aims and Objectives
The objective of the experiment was to conduct a
pilot testing of original and modified texts in order
44
Task Precision Recall F1
Finite verb phrases
(full)
0.914 0.909 0.912
Finite verb phrases
(partial)
0.980 0.975 0.977
Clauses borders 0.806 0.827 0.817
Clauses (begin-
ning)
0.908 0.931 0.919
Anaphora (full) 0.558 0.558 0.558
Anaphora (partial) 0.615 0.615 0.615
Subject (full) 0.590 0.441 0.504
Subject (partial) 0.772 0.548 0.671
Table 1: Evaluation of different stages of text
modification
to determine and confirm the need of text modi-
fication for deaf people whose primary language
is BulSL and the verbal language is acquired as a
second language.
The rationale was to identify and distinguish be-
tween levels of comprehension of original and au-
tomatically modified texts.
4.1.2 Respondents? Profile
The participants were selected regardless of their
degree and onset of hearing loss. The experiment
targeted the following group of people:
? Socially active adults (18+);
? BulSL users;
? People with developed reading skills.
4.2 Pilot Test Design Methodology and
Implementation
4.2.1 Text Selection
We decided to use original and modified versions
of journalistic (e.g. news items) and administra-
tive (e.g. legal) texts. The guiding principle was
to select texts that are similar in terms of length,
complexity, and difficulty.
The selected news refer to topics of general in-
terest such as politics in neighbouring countries,
culture, etc. The administrative texts represent
real-life scenarios, rather than abstract or rare le-
gal issues. In general, selected texts do not include
domain-specific terms and professional jargon.
Regarding text modification the main objective
was to preserve the meaning of the original text in
compliance with the principles of textual and fac-
tual accuracy and integrity, and appropriate com-
plexity. The result from the automatic modifica-
tions has been manually checked and post-edited
to ensure grammaticality.
4.2.2 Methodology
The testing is conducted either online via tests in
e-form (predominantly), or using paper-based ver-
sions. Respondents are given texts of each type,
i.e. two original and two modified texts. Each
text is associated with two tasks, which have to be
completed correctly after the reading. The tasks
seek to check the level of understanding of the
main idea, details, purpose, implication, temporal
relations (the sequence of events), and the ability
to follow the text development.
? Task-type 1: Sequence questions. The re-
spondents have to arrange text elements (sen-
tences and clauses) listed in a random se-
quence into a chronological order. The task
covers temporal, causative, conditional, and
other relations, and its goal is to test reading
comprehension which involves temporal and
logical relations and inferences.
? Task-type 2: Multiple response questions
(MRQ) for testing general reading com-
prehension. MRQ are similar to Multiple
choice questions (MCQs) in that they provide
a predefined set of options, but MRQ allow
any number and combinations of options.
Text Type Version #
sen-
tences
#
clauses
#
tem-
poral
shifts
1 News Original 2 6 2
2 News Modified 5 6 0
3 Admin Original 1 4 2
4 Admin Modified 4 4 0
Table 2: Structure of the test
4.2.3 Structure of the Test
The test consists of four different texts, each of
them with two subtasks ? for checking the com-
prehension of temporal relations and the logical
structure of the events in the text (type 1), and gen-
eral comprehension (type 2).
The number of sentences, clauses and temporal
shifts for each text is presented in Table 2.
45
4.3 Analysis of Results
19 deaf adults proficient in BulSL have taken part
in the pilot test study. The results are presented in
Table 3 and on Figure 1.
Task Type Version correct all %
1.1 News Original 5 19 26.32
2.1 News Modified 9 19 47.37
3.1 Admin Original 6 19 31.58
4.1 Admin Modified 10 19 52.63
1.2 News Original 7 19 36.84
2.2 News Modified 9 19 47.37
3.2 Admin Original 7 19 36.84
4.2 Admin Modified 10 19 52.63
Table 3: Results of chronological order sub-
tasks (1.1-4.1) and general comprehension sub-
tasks (1.2-4.2)
We recognize the fact that the small number
of respondents does not provide sufficient data
to draw conclusions regarding the improvement
of readability when using modified texts. How-
ever, the results show a significant improvement
(t = 2.0066 with p = 0.0485 < 0.05) in the over-
all comprehension (chronological order and gen-
eral understanding) when using the modified texts
in comparison with the original texts.
Figure 1: Results in % of correct answers for orig-
inal and modified texts
Still, the improvement in readability after the
text modification is very low and not sufficient to
provide reliable communication strategies and ac-
cess to information. Further work will be aimed at
more precise methodology for testing the reading
skills of deaf people.
5 Conclusions
As the pilot test suggests, the limited number of
modifications is not sufficient to compensate for
the problems which deaf people experience with
reading. A wider range of text modifications are
necessary in order to cover the problematic areas
of verbal language competence. Other issues in-
clude the use of personal and possessive pronouns,
in particular clitics, which are often dropped, the
correct use of auxiliary verbs and analytical verb
forms. Additional problems such as adjective and
noun agreement, subject and verb agreement, etc.
need to be addressed specifically, since these have
a very different realization in sign languages (e.g.,
subject and verb are related spatially).
It should be emphasized that there has not been
any systematic effort for studying BulSL so far.
The detailed exploration of the linguistic proper-
ties of BulSL in relation to Bulgarian can give a
deeper understanding about the problems in the
acquisition of Bulgarian and in particular, the
reading difficulties experienced by deaf readers.
Directions for future work include:
? To explore the relationship between reading
comprehension and social, educational and
other factors;
? To explore the dependence between reading
skills and proficiency in BulSL;
? To analyze problems in relation to vocabulary
with relation to reading;
? To build a detailed methodology for testing
of reading comprehension;
? To explore further the potential of text modi-
fication with respect to BulSL in relation to
the comparative analyses of the features of
BulSL and verbal Bulgarian language.
References
J. Albertini and C. Mayer. 2011. Using miscue analy-
sis to assess comprehension in deaf college readers.
Journal of Deaf Studies and Deaf Education, 16:35?
46.
BATOD. 2006. Training materials for language modi-
fication.
Gerald Berent. 2004. Deaf students? command of En-
glish relative clauses (Paper presented at the annual
convention of Teachers of English to Speakers of
Other Languages).
46
Stefan Bott and Horacio Saggion. 2011. Spanish text
simplification: An exploratory study. In XXVII Con-
greso de la Sociedad Espaola para el Procesamiento
del Lenguaje Natural (SEPLN 2011), Huevla, Spain.
Arnaldo Candido, Erick Maziero, Caroline Gasperin,
Thiago A. S. Pardo, Lucia Specia, and Sandra
Aluisio. 2009. Supporting the adaptation of texts
for poor literacy readers: a text simplification ed-
itor for Brazilian Portuguese. In Proceedings of
the Fourth Workshop on Innovative Use of NLP for
Building Educational Applications, pages 34?42.
Nathanael Chambers, Shan Wang, and Dan Juraf-
sky. 2007. Classifying temporal relations between
events. In Proceedings of the ACL 2007 Demo and
Poster Sessions, Prague, June 2007, pages 173?176.
R. Conrad. 1979. The deaf schoolchild. London:
Harper and Row.
Peter Dienes and Amit Dubey. 2003. Deep syntac-
tic processing by combining shallow methods. In
Proceedings of the 41st Annual Meeting of the Asso-
ciation for Computational Linguistics, volume 1.
R. J. Hoffmeister. 2000. A piece of the puzzle: ASL
and reading comprehension in deaf children. In
C. Chamberlain, J. P. Morford, and R. I. Mayberry,
editors, Language acquisition by eye, pages 143?
163. Mahwah, NJ: Earlbaum.
Kentaro Inui, Atsushi Fujita, Tetsuro Takahashi, Ryu
Iida, and Tomoya Iwakura. 2003. Text simplifi-
cation for reading assistance: A project note. In
PARAPHRASE ?03 Proceedings of the second in-
ternational workshop on Paraphrasing, volume 16,
pages 9?16. Association for Computational Linguis-
tics Stroudsburg, PA, USA.
Mark Johnson. 2002. A simple pattern-matching al-
gorithm for recovering empty nodes and their an-
tecedents. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguis-
tics.
L. Kelly. 1996. The interaction of syntactic compe-
tence and vocabulary during reading by deaf stu-
dents. Journal of Deaf Studies and Deaf Education,
1(1):75?90.
S. Koeva and A. Genov. 2011. Bulgarian language
processing chain. In Proceedings of Integration of
multilingual resources and tools in Web applica-
tions. Workshop in conjunction with GSCL 2011,
University of Hamburg.
Svetla Koeva, Borislav Rizov, Ekaterina Tarpomanova,
Tsvetana Dimitrova, Rositsa Dekova, Ivelina Stoy-
anova, Svetlozara Leseva, Hristina Kukova, and An-
gel Genov. 2012. Bulgarian-english sentence- and
clause-aligned corpus. In Proceedings of the Second
Workshop on Annotation of Corpora for Research
in the Humanities (ACRH-2), Lisbon, 29 November
2012, pages 51?62. Lisboa: Colibri.
Penny Lee. 1996. The Logic and Development of
the Linguistic Relativity Principle. The Whorf The-
ory Complex: A Critical Reconstruction. John Ben-
jamins Publishing.
Margaret Jelinek Lewis and Dorothy Jackson. 2001.
Television literacy: Comprehension of program con-
tent using closed-captions for the deaf. Journal of
Deaf Studies and Deaf Education, 6(1):43?53.
Slavina Lozanova. 2002. Predpostavki za razvitie
na bilingvizma kato metod za obuchenie na detsa s
uvreden sluh. Spetsialna pedagogika.
R. I. Mayberry. 2000. Cognitive development of
deaf children: The interface of language and percep-
tion in cognitive neuroscience. In Child Neuropsy-
chology, Volume 7 of handbook of neuropsychology,
pages 71?107. Amesterdam: Elsvier.
P. McAnally, S. Rose, and S. Quigley. 1999. Reading
practices with deaf learners. Austin, TX: Pro-Ed.
Ruslan Mitkov. 1999. Anaphora resolution: the
state of the art; working paper, (based on the col-
ing?98/acl?98 tutorial on anaphora resolution).
Carol Musselman. 2000. How do children who can?t
hear learn to read an alphabetic script? a review of
the literature on reading and deafness. Journal of
Deaf Studies and Deaf Education, 5:9?31.
C. Padden and C Ramsey. 2000. American Sign
Language and reading ability in deaf children. In
C. Chamberlain, J. P. Morford, and R. I. Mayberry,
editors, Language acquisition by eye, pages 165?
189. Mahwah, NJ: Earlbaum.
S. J. Parault and H. William. 2010. Reading motiva-
tion, reading comprehension and reading amount in
deaf and hearing adults. Journal of Deaf Studies and
Deaf Education, 15:120?135.
Peter Paul. 1996. Reading vocabulary knowledge and
deafness. Journal of Deaf Studies and Deaf Educa-
tion, 1(1):3?15.
Peter Paul. 1998. Literacy and deafness: The develop-
ment of reading, writing and literate thought. Need-
ham, MA: Allyn & Bacon.
Sarah Petersen and Mari Ostendorf. 2007. Natural
language processing tools for reading level assess-
ment and text simplification for bilingual education.
University of Washington Seattle, WA.
James Pustejovsky, Jose? Casta no, Robert Ingria, Roser
Saur??, Robert Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir Radev. 2003. TimeML: Robust
Specification of Event and Temporal Expressions in
Text. Technical report, AAAI.
Seth Kulick Ryan Gabbard and Mitchell Marcus. 2004.
Using linguistic principles to recover empty cate-
gories. In Proceedings of the 42nd Annual Meeting
on Association For Computational Linguistics, page
184191.
47
S. Saeva. 2010. Gluhota i Bilingvizam. Aeropres BG.
L. Selinker. 1972. Interlanguage. International Re-
view of Applied Linguistics, 10:209?231.
Advaith Siddharthan. 2011. Text simplification using
typed dependencies: A comparison of the robustness
of different generation strategies. In Proceedings of
the 13th European Workshop on Natural Language
Generation (ENLG) , pages 211, September.
L. Specia. 2010. Translating from complex to simpli-
fied sentences. In 9th International Conference on
Computational Processing of the Portuguese Lan-
guage (Propor-2010), Porto Alegre, Brazil, vol-
ume 6001 of Lecture Notes in Artificial Intelligence,
pages 30?39. Springer.
William Stokoe. 1960. Sign language structure: An
outline of the visual communication systems of the
american deaf. Studies in linguistics: Occasional
papers, 8.
William Stokoe. 1972. Semiotics and Human Sign
Languages. NICI, Printers, Ghent.
Ivelina Stoyanova, Tanya Dimitrova, and Viktorija Tra-
jkovska. 2003. A handbook in civil education with a
sign language dictionary. In Social and Educational
Training for Hearing Impaired youths: A Handbook
in Civil Education with a Sign Language Dictionary.
Petar Beron, Sofia. (in Bulgarian).
Rachel Sutton-Spence and Bencie Woll. 2003. The
Linguistics of British Sign Language: An Introduc-
tion. Cambridge University Press, 3rd edition.
W. Swann. 1992. Learning for All: Classroom Diver-
sity. Milton Keynes: The Open University.
Marta Tatu and Munirathnam Srikanth. 2008. Experi-
ments with reasoning for temporal relations between
events. In COLING ?08 Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics, volume 1, pages 857?864.
C. B. Traxler. 2000. The stanford achievement test, 9th
edition: National norming and performance stan-
dards for deaf and hard-of-hearing students. Journal
of Deaf Studies and Deaf Education, 5:337348.
Beverly Trezek, Ye Wang, and Peter Paul. 2010. Read-
ing and deafness: Theory, research and practice.
Clifton Park, NY: Cengage Learning.
Robert Van Valin and Randy LaPolla. 1997. Syntax:
Structure, Meaning, and Function. Cambridge Uni-
versity Press.
Schreuder R Knoors H Snik A. Vermeulen AM, van
Bon W. 2007. Reading comprehension of deaf chil-
dren with cochlear implants. Journal of Deaf Stud-
ies and Deaf Education, 12(3):283?302.
Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.
2010. A monolingual tree-based translation model
for sentence simplification. In Proceedings of The
23rd International Conference on Computational
Linguistics, Beijing, China, pages 1353?1361.
48
