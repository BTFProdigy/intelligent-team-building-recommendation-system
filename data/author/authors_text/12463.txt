Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ? AfLaT 2009, pages 17?24,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Information Structure in African Languages: Corpora and Tools 
Christian Chiarcos*, Ines Fiedler**, Mira Grubic*, Andreas Haida**, Katharina 
Hartmann**, Julia Ritz*, Anne Schwarz**, Amir Zeldes**, Malte Zimmermann* 
 
* Universit?t Potsdam 
Potsdam, Germany 
{chiarcos|grubic| 
julia|malte}@ 
ling.uni-potsdam.de 
** Humboldt-Universit?t zu Berlin 
Berlin, Germany 
{ines.fiedler|andreas.haida| 
k.hartmann|anne.schwarz| 
amir.zeldes}@rz.hu-berlin.de 
 
Abstract 
In this paper, we describe tools and resources 
for the study of African languages developed 
at the Collaborative Research Centre ?Infor-
mation Structure?. These include deeply anno-
tated data collections of 25 subsaharan 
languages that are described together with 
their annotation scheme, and further, the cor-
pus tool ANNIS that provides a unified access 
to a broad variety of annotations created with a 
range of different tools. With the application 
of ANNIS to several African data collections, 
we illustrate its suitability for the purpose of 
language documentation, distributed access 
and the creation of data archives. 
1 Information Structure 
The Collaborative Research Centre (CRC) 
"Information structure: the linguistic means for 
structuring utterances, sentences and texts" 
brings together scientists from different fields of 
linguistics and neighbouring disciplines from the 
University of Potsdam and the Humboldt-
University Berlin. Our research comprises the 
use and advancement of corpus technologies for 
complex linguistic annotations, such as the 
annotation of information structure (IS). We 
define IS as the structuring of linguistic 
information in order to optimize information 
transfer within discourse: information needs to 
be prepared ("packaged") in different ways 
depending on the goals a speaker pursues within 
discourse.  
Fundamental concepts of IS include the 
concepts `topic?, `focus?, `background? and 
`information status?. Broadly speaking, the topic 
is the entity a specific sentence is construed 
about, focus represents the new or newsworthy 
information a sentence conveys, background is 
that part of the sentence that is familiar to the 
hearer, and information status refers to different 
degrees of familiarity of an entity.  
Languages differ wrt. the means of realization 
of IS, due to language-specific properties (e.g., 
lexical tone). This makes a typological 
comparison of traditionally less-studied 
languages to existing theories, mostly on 
European languages, very promising. Particular 
emphasis is laid on the study of focus, its 
functions and manifestations in different 
subsaharan languages, as well as the 
differentiation between different types of focus, 
i.e., term focus (focus on arguments/adjuncts), 
predicate focus (focus on verb/verb 
phrase/TAM/truth value), and sentence focus 
(focus on the whole utterance). 
We describe corpora of 25 subsaharan 
languages created for this purpose, together with 
ANNIS, the technical infrastructure developed to 
support linguists in their work with these data 
collections. ANNIS is specifically designed to 
support corpora with rich and deep annotation, as 
IS manifests itself on practically all levels of 
linguistic description. It provides user-friendly 
means of querying and visualizations for 
different kinds of linguistic annotations, 
including flat, layer-based annotations as used 
for linguistic glosses, but also hierarchical 
annotations as used for syntax annotation. 
2 Research Activities at the CRC 
Within the Collaborative Research Centre, there 
are several projects eliciting data in large 
amounts and great diversity. These data, 
originating from different languages, different 
modes (written and spoken language) and 
specific research questions characterize the 
specification of the linguistic database ANNIS. 
2.1 Linguistic Data Base 
The project ?Linguistic database for information 
structure: Annotation and Retrieval?, further 
17
database project, coordinates annotation 
activities in the CRC, provides service to projects 
in the creation and maintenance of data 
collections, and conducts theoretical research on 
multi-level annotations. Its primary goals, 
however, are the development and investigation 
of techniques to process, to integrate and to 
exploit deeply annotated corpora with multiple 
kinds of annotations. One concrete outcome of 
these efforts is the linguistic data base ANNIS 
described further below. For the specific 
facilities of ANNIS, its application to several 
corpora of African languages and its use as a 
general-purpose tool for the publication, 
visualization and querying of linguistic data, see 
Sect. 5. 
 
2.2 Gur and Kwa Languages 
 
Gur and Kwa languages, two genetically related 
West African language groups, are in the focus of 
the project ?Interaction of information structure 
and grammar in Gur and Kwa languages?, 
henceforth Gur-Kwa project. In a first research 
stage, the precise means of expression of the 
pragmatic category focus were explored as well 
as their functions in Gur and Kwa languages. For 
this purpose, a number of data collections for 
several languages were created (Sect. 3.1). 
Findings obtained with this data led to different 
subquestions which are of special interest from a 
cross-linguistic and a theoretical point of view.  
These concern (i) the analysis of syntactically 
marked focus constructions with features of 
narrative sentences (Schwarz & Fiedler 2007), 
(ii) the study of verb-centered focus (i.e., focus 
on verb/TAM/truth value), for which there are 
special means of realization in Gur and Kwa 
(Schwarz, forthcoming), (iii) the identification of 
systematic focus-topic-overlap, i.e., coincidence 
of focus and topic in sentence-initial nominal 
constituents (Fiedler, forthcoming). The project's 
findings on IS are evaluated typologically on 19 
selected languages. The questions raised by the 
project serve the superordinate goal to expand 
our knowledge of linguistically relevant 
information structural categories in the less-
studied Gur and Kwa languages as well as the 
interaction between IS, grammar and language 
type. 
2.3 Chadic Languages 
The project ?Information Structure in the Chadic 
Languages?, henceforth Chadic project, 
investigates focus phenomena in Chadic 
languages.  The Chadic languages are a branch of 
the Afro-Asiatic language family mainly spoken 
in northern Nigeria, Niger, and Chad. As tone 
languages, the Chadic languages represent an 
interesting subject for research into focus 
because here, intonational/tonal marking ? a 
commonly used means for marking focus in 
European languages ? is in potential conflict 
with lexical tone, and so, Chadic languages 
resort to alternative means for marking focus.  
The languages investigated in the Chadic 
project include the western Chadic languages 
Hausa, Tangale, and Guruntum and the central 
Chadic languages Bura, South Marghi, and Tera. 
The main research goals of the Chadic project 
are a deeper understanding of the following 
asymmetries: (i) subject focus is obligatorily 
marked, but marking of object focus is optional; 
(ii) in Tangale and Hausa there are sentences that 
are ambiguous between an object-focus 
interpretation and a predicate-focus 
interpretation, but in intonation languages like 
English and German, object focus and predicate 
focus are always marked differently from each 
other; (iii) in Hausa, Bole, and Guruntum there is 
only a tendency to distinguish different types of 
focus (new-information focus vs. contrastive 
focus), but in European languages like 
Hungarian and Finnish, this differentiation is 
obligatory. 
2.4 Focus from a Cross-linguistic 
Perspective 
The project "Focus realization, focus 
interpretation, and focus use from a cross-
linguistic perspective", further focus project, 
investigates the correspondence between the 
realization, interpretation and use of with an 
emphasis on focus in African and south-east 
Asian languages. It is structured into three fields 
of research: (i) the relation between differences 
in realization and differences in semantic 
meaning or pragmatic function, (ii) realization, 
interpretation and use of predicate focus, and (iii) 
association with focus.  
The relation between differences in realization 
and semantic/pragmatic differences (i) 
particularly pertains the semantic interpretation 
of focus: For Hungarian and Finnish, a 
differentiation between two semantic types of 
foci corresponding to two different types of 
focus realization was suggested, and we 
investigate whether the languages studied here 
have a similar distinction between two (or more) 
semantic focus types, whether this may differ 
18
from language to language, and whether 
differences in focus realization correspond to 
semantic or pragmatic differences.  
The investigation of realization, interpretation 
and use of predicate focus (ii) involves the 
questions why different forms of predicate focus 
are often realized in the same way, why they are 
often not obligatorily marked, and why they are 
often marked differently from term focus. 
Association with focus (iii) means that the 
interpretation of the sentence is influenced by the 
focusing of a particular constituent, marked by a 
focus-sensitive expression (e.g., particles like 
`only?, or quantificational adverbials like 
`always?), while usually, focus does not have an 
impact on the truth value of a sentence. The 
project investigates which focus-sensitive 
expressions there are in the languages studied, 
what kinds of constituents they associate with, 
how this association works, and whether it works 
differently for focus particles and 
quantificational adverbials. 
3 Collections of African Language Data 
at the CRC 
3.1 Gur and Kwa Corpora 
The Gur and Kwa corpora currently comprise  
data from 19 languages.  
Due to the scarceness of information available 
on IS in the Gur and Kwa languages, data had to 
be elicited, most of which was done during field 
research, mainly in West Africa, and some in 
Germany with the help of native speakers of the 
respective languages. The typologically diverse 
languages in which we elicited data by ourselves 
are: Baatonum, Buli, Byali, Dagbani, Ditammari, 
Gurene, Konkomba, Konni, Nateni, Waama, 
Yom (Gur languages) and Aja, Akan, Efutu, Ewe, 
Fon, Foodo, Lelemi, Anii (Kwa languages). 
The elicitation of the data based mainly on the 
questionnaire on information structure, 
developed by our research group (QUIS, see 
Section 4.2). This ensured that  comparable data 
for the typological comparison were obtained. 
Moreover, language-specific additional tasks and 
questionnaires tailored to a more detailed 
analysis or language-specific traits were 
developed. 
As the coding of IS varies across different 
types of texts, different text types were included 
in the corpus, such as (semi-)spontaneous 
speech, translations, mono- and dialogues. Most 
of the languages do not have a long literacy 
tradition, so that the corpus data mainly 
represents oral communication. 
In all, the carefully collected heterogeneous 
data provide a corpus that gives a comprehensive 
picture of IS, and in particular the focus systems, 
in these languages.  
3.2 Hausar Baka Corpus 
In the Chadic project, data from 6 Chadic 
languages are considered. 
One of the larger data sets annotated in the 
Chadic project is drawn from Hausar Baka 
(Randell, Bature & Schuh 1998), a collection of 
videotaped Hausa dialogues recording natural 
interaction in various cultural milieus, involving 
over fifty individuals of different age and gender. 
The annotated data set consists of approximately 
1500 sentences.  
The corpus was annotated according to the 
guidelines for Linguistic Information Structure 
Annotation (LISA, see Section 4.2). The Chadic 
languages show various forms of syntactic 
displacement, and in order to account for this, an 
additional annotation level was added: 
constituents are marked as ex-situ=?+?  if 
they occur displaced from their canonical, 
unmarked position. 
An evaluation of the focus type and the 
displacement status reveals tendencies in the 
morphosyntactic realization of different focus 
types, see Sect. 5.2. 
3.3 Hausa Internet Corpus 
Besides these data collections that are currently 
available in the CRC and in ANNIS, further 
resources are continuously created. As such, a 
corpus of written Hausa is created in cooperation 
with another NLP project of the CRC.   
The corpora previously mentioned mostly 
comprise elicited sentences from little-
documented languages with rather small 
language communities. Hausa, in contrast, is 
spoken by more than 24 million native speakers, 
with large amounts of Hausa material (some of it 
parallel to material in other, more-studied 
languages) available on the internet. This makes 
Hausa a promising language for the creation of 
resources that enable a quantitative study of 
information structure.  
The Hausa internet corpus is designed to cover 
different kinds of written language, including 
news articles from international radio stations 
(e.g., http://www.dw-world.de), religious texts, 
literary prose but also material similar to 
spontaneous spoken language (e.g., in chat logs). 
19
Parallel sections of the corpus comprise 
excerpts from the novel Ruwan Bagaja by 
Abubakar Imam, Bible and Qur?an sections, and 
the Declaration of Human Rights. As will be 
described in Section 4.3, these parallel sections 
open the possibility of semiautomatic 
morphosyntactic annotation, providing a unique 
source for the study of information structure in 
Hausa. Sect. 5.2 gives an example for 
bootstrapping  ex-situ constituents in 
ANNIS only on the basis of  morphosyntactic 
annotation. 
4 Data Elicitation and Annotation 
4.1 Elicitation with QUIS 
The questionnaire on information structure 
(Skopeteas et al, 2006) provides a tool for the 
collection of natural linguistic data, both spoken 
and written, and, secondly, for the elaboration of 
grammars of IS in genetically diverse languages. 
Focus information, for instance, is typically 
elicited by embedding an utterance in a question 
context. To avoid the influence of a mediator 
(working) language, the main body of QUIS is 
built on the basis of pictures and short movies 
representing a nearly culture- and language-
neutral context. Besides highly controlled 
experimental settings, less controlled settings 
serve the purpose of eliciting longer, cohesive, 
natural texts for studying categories such as 
focus and topic in a near-natural environment. 
4.2 Transcription and Manual Annotation 
In the CRC, the annotation scheme LISA has 
been developed with special respect to 
applicability across typologically different 
languages (Dipper et al, 2007). It comprises 
guidelines for the annotation of phonology, 
morphology, syntax, semantics and IS.  
The data mentioned above is, in the case of 
speech, transcribed according to IPA 
conventions, otherwise written according to 
orthographic conventions, and annotated with 
glosses and IS, a translation of each sentence into 
English or French, (optionally) additional notes, 
references to QUIS experiments, and references 
to audio files and metadata. 
4.3 (Semi-)automatic Annotation 
As to the automization of annotation, we pursue 
two strategies: (i) the training of classifiers on 
annotated data, and (ii) the projection of 
annotations on texts in a source language to 
parallel texts in a target language. 
Machine Learning. ANNIS allows to export 
query matches and all their annotated features to 
the table format ARFF which serves as input to 
the data mining tool WEKA (Witten & Frank, 
2005), where instances can be clustered, or used 
to train classifiers for any annotation level. 
Projection. Based on (paragraph-, sentence- 
or verse-) aligned sections in the Hausa internet 
corpus, we are about to project annotations from 
linguistically annotated English texts to Hausa, 
in a first step parts of speech and possibly  
nominal chunks. On the projected annotation, we 
will train a tagger/chunker to annotate the 
remaining, non-parallel sections of the Hausa 
internet corpus. Existing manual annotations 
(e.g. of the Hausar Baka corpus) will then serve 
as a gold standard for evaluation purposes. 
Concerning projection techniques, we expect 
to face a number of problems: (i) the question 
how to assign part of speech tags to categories 
existing only in the target language (e.g., the 
person-aspect complex in Hausa that binds 
together information about both the verb (aspect) 
and its (pronominal subject) argument),  (ii) 
issues of orthography: the official orthography 
Hausa (Boko) is systematically underspecified 
wrt. linguistically relevant distinctions. Neither 
vowel length nor different qualities of certain 
consonants (r) are represented, and also, there is 
no marking of tones (see Examples 1 and 2, fully 
specified word forms in brackets). To distinguish 
such homographs, however, is essential to the 
appropriate interpretation and linguistic analysis 
of  utterances.  
(1) ciki ? 1. [c?k?i, noun] 
stomach, 2. [c?k?, prep.] 
inside 
(2) dace ? 1. [d?ac?e, noun] 
coincidence, 2. [d?ac?e, verb] 
be appropriate 
 
We expect that in these cases, statistical 
techniques using context features may help to 
predict correct vowelization and tonal patterns. 
5 ANNIS ? the Linguistic Database of 
Information Structure Annotation 
5.1 Conception and Architecture 
ANNIS (ANNotation of Information Structure) 
is a web-based corpus interface built to query 
and visualize multilevel corpora. It allows the 
user to formulate queries on arbitrary, possibly 
nested annotation levels, which may be 
20
conflictingly overlapping or discontinuous. The 
types of annotations handled by ANNIS include, 
among others, flat, layer-based annotations (e.g., 
for glossing) and hierarchical trees (e.g., syntax). 
Source data. As an architecture designed to 
facilitate diverse and integrative research on IS, 
ANNIS can import formats from a broad variety 
of tools from NLP and manual annotation, the 
latter including EXMARaLDA (Schmidt, 2004), 
annotate (Brants and Plaehn, 2000), Synpathy 
(www.lat-mpi.eu/tools/synpathy/), MMAX2 
(M?ller and Strube, 2006), RSTTool (O'Donnell, 
2000), PALinkA (Orasan, 2003), Toolbox 
(Busemann & Busemann, 2008) etc. These tools 
allow researchers to annotate data for syntax, 
semantics, morphology, prosody, phonetics, 
referentiality, lexis and much more, as their 
research questions require. 
All annotated data are merged together via a 
general interchange format PAULA (Dipper 
2005, Dipper & G?tze 2005), a highly expressive 
standoff XML format that specifically allows 
further annotation levels to be added at a later 
time without disrupting the structure of existing 
annotations. PAULA, then, is the native format 
of ANNIS. 
Backend. The ANNIS server uses a relational 
database that offers many advantages including 
full Unicode support and regular expression 
searches. Extensive search functionalities are 
supported, allowing complex relations between 
individual word forms and annotations, such as 
all forms of overlapping, contained or adjacent 
annotation spans, dominance axes (children, 
ancestors etc., as well as common parent, left- or 
right-most child and more), etc. 
Search. In the user interface, queries can be 
formulated using the ANNIS Query Language 
(AQL). It is based on the definition of nodes to 
be searched for and the relationships between 
these nodes (see below for some examples). A 
graphical query builder is also included in the 
web interface to make access as easy as possible. 
Visualization. The web interface, realized as a 
window-based AJAX application written in Java, 
provides visualization facilities for search results. 
Available visualizations include token-based 
annotations, layered annotations, tree-like 
annotations (directed acyclic graphs), and a 
discourse view of entire texts for, e.g., 
coreference annotation. Multimodal data is 
represented using an embedded media player.  
Special features. By allowing queries on 
multiple, conflicting annotation levels 
simultaneously, the system supports the study of 
interdependencies between a potentially limitless 
variety of annotation levels.  
At the same time, ANNIS allows us to 
integrate and to search through heterogeneous 
resources by means of a unified interface, a 
powerful query language and a intuitive 
graphical query editor and is therefore 
particularly well-suited for the purpose of 
language documentation. In particular, ANNIS 
can serve as a tool for the publication of data 
collections via internet. A fine-grained user 
management allows granting privileged users 
access to specific data collections, to make a 
corpus available to the public, or to seal (but 
preserve) a resource, e.g., until legal issues 
(copyright) are settled. This also makes 
publishing linguistic data collections possible 
without giving them away. 
Moreover, ANNIS supports deep links to 
corpora and corpus queries. This means that 
queries and query results referred to in, e.g., a 
scientific paper, can be reproduced and quoted 
by means of (complex) links (see following 
example). 
5.2 Using ANNIS. An Example Query 
As an illustration for the application of ANNIS to 
the data collections presented above, consider a 
research question previously discussed in the 
study of object focus in Hausa. 
In Hausa, object focus can be realized in two 
ways: either ex-situ or in-situ (Section 3.2). It 
was found that these realizations do not differ in 
their semantic type (Green & Jaggar 2003, 
Hartmann & Zimmermann 2007): instead, the 
marked form signals that the focused constituent 
(or the whole speech act) is unexpected for the 
hearer (Zimmermann 2008). These assumptions 
are consistent with findings for other African 
languages (Fiedler et al 2006).  
In order to verify such claims on corpora with 
morphosyntactic and syntactic annotation for the 
example of Hausa, a corpus query can be 
designed on the basis of the Hausar Baka corpus 
that comprises not only annotations for 
grammatical functions and information-structural 
categories, but also an annotation of ex-situ 
elements. 
 
21
So, in (3), we look for ex-situ constituents 
(variable #1) in declarative sentences in the 
Hausa Bakar corpus, i.e., sentences that are not 
translated as questions (variable #2) such that 
#1 is included in #2 (#1 _i_ #2). 
(3) EX-SITU=?+? & 
TRANSLATION=?.*[^?]? &     #1 
_i_ #2 
Considering the first 25 matches for this query 
on Hausar Baka, 16 examples reveal to be 
relevant (excluding interrogative pronouns and 
elliptical utterances). All of these are directly 
preceded by a period (sentence-initial) or a 
comma (preceded by ee ?yes?, interjections or 
exclamations), with one exception, preceded by a 
sentence initial negation marker. 
Only seven examples are morphologically 
marked by focus particles (nee, cee), focus-
sensitive adverbs (kaw?i ?only?) or quantifiers 
(koomee ?every?). In nine cases, a personal 
pronoun follows the ex-situ constituent, followed 
by the verb. Together, these constraints describe 
all examples retrieved, and as a generalization, 
we can now postulate a number of patterns that 
only make use of morphosyntactic and syntactic 
annotation (token tok, morphological 
segmentation MORPH, parts of speech CLASS, 
nominal chunks CHUNK) with two examples 
given below: 
 
 (4) tok=/[,.!?]/ & 
CHUNK=?NC? & MORPH=/[cn]ee/ & 
#1 . #2 & #2 . #3 
 (5) tok=/[,.!?]/ & 
CHUNK=?NC? & CLASS=/PRON.*/ & 
CLASS=/V/ & #1 . #2 &   #2 . 
#3 & #3 . #4 
 
In (4), we search for a nominal chunk 
following a punctuation sign and preceding a 
focus particle (cee or nee), in (5), we search for a 
nominal chunk preceding a sequence of 
pronoun/aspect marker and  verb.  
One example matching template (5) from the 
Hausar Baka corpus is given in Fig. 1. 
While AQL can be used in this way to help 
linguists understand the grammatical realization 
of certain phenomena, and the grammatical 
context they occur in, patterns like (5) above are 
probably not too readable to an interested user. 
This deficit, however, is compensated by the 
graphical query builder that allows users to 
create AQL queries in a more intuitive way, cf. 
Fig. 2. 
Of course, these patterns are not exhaustive 
and overgenerate. However, they can be directly 
evaluated against the manual ex-situ annotation 
in the Hausar Baka corpus and further refined.  
So, the manual annotation of ex-situ 
constituents in the Hausar Baka corpus provides 
templates for the semi-automatic detection of ex-
situ constituents in a morphosyntactically 
annotated corpus of Hausa: The patterns generate 
a set of candidate examples from which a human 
annotator can then choose real ex-situ 
constituents. Indeed, for a better understanding 
of ex-situ object focus, a study with a larger 
database of more natural language would be of 
great advantage, and this pattern-based approach 
represents a way to create such a database of ex-
situ constructions in Hausa. 
Finally, it would also help find instances of 
predicate focus. When a V(P) constituent is 
focused in Hausa, it is nominalized, and fronted 
like a focused nominal constituent (Hartmann & 
Zimmermann 2007). 
5.3 Related Corpus Tools 
Some annotation tools come with search 
facilities, e.g. Toolbox (Busemann & Busemann, 
2008), a system for annotating, managing and 
 
Figure 2: ANNIS Query Builder, cf. example (5). 
 
Figure 1: ANNIS partitur view, Hausar Baka corpus. 
22
analyzing language data, mainly geared to 
lexicographic use, and ELAN (Hellwig et al, 
2008), an annotation tool for audio and video 
data.  
In contrast, ANNIS is not intended to provide 
annotation functionality. The main reason behind 
this is that both Toolbox and ELAN are problem-
specific annotation tools with limited capabilities 
for application to different phenomena than they 
were designed for. Toolbox provides an intuitive 
annotation environment and search facilities for 
flat, word-oriented annotations; ELAN, on the 
other hand, for annotations that stand in a 
temporal relation to each other. 
These tools ? as well as the other annotation 
tools used within the CRC ? are tailored to a 
particular type of annotation, neither of them 
being capable of sufficiently representing the 
data from all other tools. Annotation on different 
levels, however, is crucial for the investigation of 
information structural phenomena. In order to fill 
in this gap, ANNIS was designed primarily with 
the focus on visualization and querying of multi-
layer annotations. In particular, ANNIS allows to 
integrate annotations originating from different 
tools (e.g., syntax annotation created with 
Synpathy, coreference annotation created with 
MMAX2, and flat, time-aligned annotations 
created with ELAN) that nevertheless refer to the 
same primary data. In this respect, ANNIS, 
together with the data format PAULA and the 
libraries created for the work with both, is best 
compared to general annotation frameworks such 
as ATLAS, NITE and LAF.  
Taking the NITE XML Toolkit as a 
representative example for this kind of 
frameworks, it provides an abstract data model, 
XML-based formats for data storage and 
metadata, a query language, and a library with 
JAVA routines for data storage and manipulation, 
querying and visualization. Additionally, a set of 
command line tools and simple interfaces for 
corpus querying and browsing are provided, 
which illustrates how the libraries can be used to 
create one's own, project-specific corpus 
interfaces and tools.  
Similarly to ANNIS, NXT supports time-
aligned, hierarchical and pointer-based 
annotation, conflicting hierarchies and the 
embedding of multi-modal primary data. The 
data storage format is based on the bundling of 
multiple XML files similar to the standoff 
concept employed in LAF and PAULA.  
One fundamental difference between NXT and 
ANNIS, however, is to be seen in the primary 
clientele it targets: The NITE XML Toolkit is 
aimed at the developer and allows to build more 
specialized displays, interfaces, and analyses as 
required by their respective end users when 
working with highly structured data annotated on 
multiple levels.  
As compared to this, ANNIS is directly 
targeted at the end user, that is, a linguist trying 
to explore and to work with a particular set of 
corpora. Therefore, an important aspect of the 
ANNIS implementation is the integration with a 
data base and convenient means for visualization 
and querying.  
6 Conclusion 
In this paper, we described the Africanist projects 
of the CRC ?Information Structure? at the 
University of Potsdam and the Humboldt 
University of Berlin/Germany, together with 
their data collections from currently 25 
subsaharan languages. Also, we have presented 
the linguistic database ANNIS that can be used to 
publish, access, query and visualize these data 
collections. As one specific example of our work, 
we have described the design and ongoing 
construction of a corpus of written Hausa, the 
Hausa internet corpus, sketched the relevant NLP 
techniques for (semi)automatic morphosyntactic 
annotation, and the application of the ANNIS 
Query Language to filter out ex-situ constituents 
and their contexts, which are relevant with regard 
to our goal, a better understanding of focus and 
information structure in Hausa and other African 
languages. 
References  
T. Brants, O. Plaehn. 2000. Interactive Corpus 
Annotation. In: Proc. of LREC 2000, Athens, 
Greece. 
A. Busemann, K. Busemann. 2008. Toolbox 
Self-Training. Technical Report (Version 1.5.4 
Oct 2008)  http://www.sil.org/ 
J. Carletta, S. Evert, U. Heid, J. Kilgour, J. 
Robertson, H. Voormann. 2003. The NITE 
XML Toolkit: Flexible Annotation for Multi-
modal Language Data. Behavior Research 
Methods, Instruments, and Computers 35(3), 
353-363. 
J. Carletta, S. Evert, U. Heid, J. Kilgour. 2005. 
The NITE XML Toolkit: data model and 
query. Language Resources and Evaluation 
Journal, 313-334. 
23
S. Dipper. 2005. XML-based Stand-off 
Representation and Exploitation of Multi-
Level Linguistic Annotation. In: Proc. of 
Berliner XML Tage 2005 (BXML 2005), 
Berlin, Germany, 39-50. 
S. Dipper, M. G?tze. 2005. Accessing 
Heterogeneous Linguistic Data - Generic 
XML-based Representation and Flexible 
Visualization. In Proc. of the 2nd Language & 
Technology Conference: Human Language 
Technologies as a Challenge for Computer 
Science and Linguistics. Poznan, Poland, 206-
210. 
S. Dipper, M. G?tze, S. Skopeteas (eds.). 2007. 
Information structure in cross-linguistic 
corpora: Annotation guidelines for phonology, 
morphology, syntax, semantics and 
information structure. Interdisciplinary 
Studies on Information Structure 7,  147-187. 
Potsdam: University of Potsdam. 
I. Fiedler. forthcoming. Contrastive topic 
marking in Gbe. In Proc. of the 18th 
International Conference on Linguistics, 
Seoul, Korea, 21. - 26. July 2008. 
I. Fiedler, K. Hartmann, B. Reineke, A. Schwarz, 
M. Zimmermann.. forthcoming. Subject Focus 
in West African Languages. In M. 
Zimmermann, C. F?ry (eds.), Information 
Structure. Theoretical, Typological, and 
Experimental Perspectives. Oxford: Oxford 
University Press. . 
M. Green, P. Jaggar. 2003. Ex-situ and in-situ 
focus in Hausa: syntax, semantics and 
discourse. In J. Lecarme et al (eds.), Research 
in Afroasiatic Grammar 2 (Current Issues in 
Linguistic Theory). Amsterdam: John 
Benjamins. 187-213. 
K. Hartmann, M. Zimmermann. 2004. Nominal 
and Verbal Focus in the Chadic Languages. In 
F. Perrill et al (eds.), Proc. of the Chicago 
Linguistics Society. 87-101. 
K. Hartmann, M. Zimmermann. 2007. In Place - 
Out of Place? Focus in Hausa. In K. Schwabe, 
S. Winkler (eds.), On Information Structure, 
Meaning and Form: Generalizing Across 
Languages. Benjamins, Amsterdam: 365-403. 
B. Hellwig, D. Van Uytvanck, M. Hulsbosch. 
2008. ELAN ? Linguistic Annotator. Technical 
Report (as of 2008-07-31). http://www.lat-
mpi.eu/tools/elan/ 
?. Kiss.  1998. Identificational Focus Versus 
Information Focus. Language 74: 245-273. 
M. Krifka. 1992. A compositional semantics for 
multiple focus constructions, in Jacobs, J: 
Informationsstruktur und Grammatik, 
Opladen, Westdeutscher Verlag, 17-53. 
C. M?ller, M. Strube. 2006. Multi-Level 
Annotation of Linguistic Data with MMAX2. 
In: S. Braun et al (eds.), Corpus Technology 
and Language Pedagogy. New Resources, 
New Tools, New Methods. Frankfurt: Peter 
Lang, 197?214. 
M. O?Donnell. 2000. RSTTool 2.4 ? A Markup 
Tool for Rhetorical Structure Theory. In: Proc. 
of the International Natural Language 
Generation Conference (INLG'2000), 13-16 
June 2000, Mitzpe Ramon, Israel, 253?256. 
C. Orasan. 2003. Palinka: A Highly 
Customisable Tool for Discourse Annotation. 
In: Proc. of the 4th SIGdial Workshop on 
Discourse and Dialogue, Sapporo, Japan. 
R. Randell, A. Bature, R. Schuh. 1998. Hausar 
Baka.   http://www.humnet.ucla.edu/humnet/ 
aflang/hausarbaka/ 
T. Schmidt. 2004. Transcribing and Annotating 
Spoken Language with Exmaralda. In: Proc. 
of the LREC-Workshop on XML Based Richly 
Annotated Corpora, Lisbon 2004. Paris: 
ELRA. 
A. Schwarz. Verb and Predication Focus Markers 
in Gur. forthcoming. In I. Fiedler, A. Schwarz 
(eds.), Information structure in African 
languages (Typological Studies in Language),  
307-333. Amsterdam, Philadelphia: John 
Benjamins. 
A. Schwarz, I. Fiedler. 2007. Narrative focus 
strategies in Gur and Kwa. In E. Aboh et al 
(eds.): Focus strategies in Niger-Congo and 
Afroasiatic ? On the interaction of focus and 
grammar in some African languages, 267-286. 
Berlin: Mouton de Gruyter. 
S. Skopeteas, I. Fiedler, S. Hellmuth, A. 
Schwarz, R. Stoel, G. Fanselow, C. F?ry, M. 
Krifka. 2006. Questionnaire on information 
structure (QUIS). Interdisciplinary Studies on 
Information Structure 4.  Potsdam: University 
of Potsdam. 
I. H. Witten, E. Frank, Data mining: Practical 
machine learning tools and techniques, 2nd 
edn, Morgan Kaufman, San Francisco, 2005. 
M. Zimmermann. 2008. Contrastive Focus and 
Emphasis. In Acta Linguistica Hungarica 55: 
347-360.  
24
Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 47?54,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Quantifying Constructional Productivity with Unseen Slot Members 
 
Amir Zeldes 
Institut f?r deutsche Sprache und Linguistik 
Humboldt-Universit?t zu Berlin 
Unter den Linden 6, 10099 Berlin, Germany 
amir.zeldes@rz.hu-berlin.de 
 
Abstract 
This paper is concerned with the possibility of 
quantifying and comparing the productivity of 
similar yet distinct syntactic constructions, 
predicting the likelihood of encountering un-
seen lexemes in their unfilled slots. Two ex-
amples are explored: variants of comparative 
correlative constructions (CCs, e.g. the faster 
the better), which are potentially very produc-
tive but in practice lexically restricted; and 
ambiguously attached prepositional phrases 
with the preposition with, which can host both 
large and restricted inventories of arguments 
under different conditions. It will be shown 
that different slots in different constructions 
are not equally likely to be occupied produc-
tively by unseen lexemes, and suggested that 
in some cases this can help disambiguate the 
underlying syntactic and semantic structure. 
1 Introduction 
Some syntactic constructions1 are more productive 
than others. Innovative coinages like the CC: The 
bubblier the Mac-ier (i.e. the more bubbly a pro-
gram looks, the more it feels at home on a Macin-
tosh computer) are possible, but arguably more 
surprising and marked than: I have a bubblier op-
erating system with a Mac-ier look in their respec-
tive construction, despite the same novel lexemes. 
The aim of this paper is to measure differences in 
the productivity of slots in such partially-filled 
constructions and also to find out if this productiv-
ity can be used to disambiguate constructions.  
                                                          
                                                          
1 I use the term ?construction? in a construction grammar sense 
following Goldberg (1995, 2006) to mean mentally stored 
hierarchically organized form-meaning pairs with empty, par-
tially-filled or fully specified lexical material. In this sense, 
both comparative adjectives and the pattern The [COMP] the 
[COMP] are constructions, and the productivity of such pat-
terns is the quantity being examined here. 
As one of the defining properties of language, 
productivity has received much attention in debates 
about the nature of derivational processes, the 
structure of the mental lexicon and the interpreta-
tion of key terms such as compositionality, gram-
maticality judgments or well-formedness. However 
in computational linguistics it is probably fair to 
say that it can be regarded most of all as a problem. 
Familiar items present in training data can be listed 
in lexical resources, the probabilities of their dif-
ferent realizations can be estimated from corpus 
frequency distributions etc. Thus using lexical in-
formation (statistically extracted or handcrafted 
resources) is the most successful strategy in resolv-
ing syntactic ambiguities such as PP-attachment 
(Hindle and Rooth, 1993; Ratnaparkhi, 1998; Stet-
ina and Nagao, 1997; Pantel and Lin, 2000; Kawa-
hara and Kurohashi, 2005), basing decisions on 
previous cases with identical lexemes or additional 
information about those lexemes. Yet because of 
productivity, even very large training data will 
never cover examples for all inputs being analyzed. 
In morphological theory (and corresponding 
computational linguistic practice), the situation has 
been somewhat different: a much larger part of the 
word formations encountered in data can be listed 
in a lexicon, with neologisms being the exception, 
whereas in syntax most sentences are novel, with 
recurring combinations being the exception.2 The 
focus in morphology has therefore often been on 
which word formation processes are productive 
and to what extent, with the computational coun-
terpart being whether or not corresponding rules 
should be built into a morphological analyzer. Syn-
tacticians, conversely, may ask which apparently 
regular constructions are actually lexicalized or 
have at least partly non-compositional properties 
(e.g. collocations, see Choueka, 1988, Evert, 2005, 
2 Compounding represents an exception to this generalization, 
standing, at least for some languages, between syntax and 
word formation and often generating an unusually large 
amount of items unlisted in lexica (cf. Bauer, 2001:36-7). 
47
2009; multiword expressions, Sag et al, 2002; 
lexical bundles, Salem, 1987, Altenberg and Eeg-
Olofsson, 1990, Biber et al, 1999, 2004). 
In morphology, the realization that productivity 
is a matter of degree, rather than a binary trait of 
word formation processes (see e.g. Bauer, 
2001:125-162), has lead to the exploration of quan-
titative measures to assess and compare different 
aspects of the fertility of various patterns (esp. the 
work of Baayen, 2001, 2009). Yet syntactic appli-
cations of these measures have only very recently 
been proposed, dealing with one slot of a pattern 
much like the stem operated on by a morphological 
process (cf. Bar?dal, 2006; Kiss, 2007).  
In this paper I will examine the application of 
measures based on Baayen?s work on morphology 
to different variants of syntactic constructions with 
more or less variable slots. The goal will be to 
show that different constructions have inherently 
different productivity rates, i.e. they are more or 
less liable to produce new members in their free 
slots. If this view is accepted, it may have conse-
quences both theoretically (novelty in certain posi-
tions will be more surprising or marked) and 
practically, e.g. for parsing ambiguous structures 
with novel arguments, since one parse may imply a 
construction more apt to novelty than another.  
The remainder of this article is structured as fol-
lows: the next section introduces concepts underly-
ing morphological productivity and related corpus-
based measures following Baayen (2009). The fol-
lowing two sections adapt and apply these meas-
ures to different types of CCs (such as the faster 
the better) and NP/VP-attached PPs, respectively, 
using the BNC3 as a database. The final section 
discusses the results of these studies and their im-
plications for the study of syntactic productivity. 
2 Morphological Productivity Measures 
Productivity has probably received more attention 
as a topic in morphology than in syntax, if for no 
other reason than that novel words are compara-
tively rare and draw attention, whereas novel 
phrases or sentences are ubiquitous. The exact 
definition of a novel word or ?neologism? is how-
ever less than straightforward. For the present pur-
pose we may use Bauer?s (2001:97-98) working 
definition as a starting point: 
                                                          
3 The British National Corpus (http://www.natcorp.ox.ac.uk/), 
with over 100 million tokens of British English. 
[Productivity] is a feature of morphological proc-
esses which allow for new coinages, [?] coining 
must be repetitive in the speech community [?] 
Various factors appear to aid productivity: type 
frequency of appropriate bases, phonological and 
semantic transparency, naturalness, etc., but these 
are aids to productivity, not productivity itself. 
 
For Bauer, productivity is defined for a morpho-
logical process, which is ideally frequently and 
consistently found and coins ideally transparent 
novel forms. The word ?coining? in this context 
implies that speakers use the process to construct 
the transparent novel forms in question, which in 
turn means the process has a regular output. Yet 
novelty, transparency and regularity are difficult to 
judge intuitively, and the definitions of ?new? vs. 
?existing? words cannot be judged reliably for any 
one speaker, nor with any adequacy for a speaker 
community (cf. Bauer, 2001:34-35).  
This problem has led researchers to turn to cor-
pus data as a sort of ?objective? model of language 
experience, in which the output of a process can be 
searched for, categorized and tagged for evalua-
tion. Baayen (e.g. 2001, 2009) proposes three cor-
pus-based measures for the productivity of word 
formation processes. The first measure, which he 
terms extent of use, is written V(C,N) and is simply 
the proportion of types produced by a process C in 
a corpus of size N, e.g. the count of different nouns 
in -ness out of all the types in N. According to this 
measure, -ness would have a much higher realized 
productivity than the -th in warmth since it is found 
in many more words. However, this measure indis-
criminately deals with all existing material ? all 
words that have already been generated ? and 
hence it cannot assess how likely it is that novel 
words will be created using a certain process. 
Baayen?s other two measures address different 
aspects of this problem and rely on the use of ha-
pax legomena, words appearing only once in a cor-
pus. The intuitive idea behind looking at such 
words is that productively created items are one-
off unique occurrences, and therefore they must 
form a subset of the hapax legomena in a corpus. 
Baayen uses V(1,C,N), the number of types from 
category C occurring once in a corpus of N words 
and V(1,N), the number of all types occurring once 
in a corpus of N words. The second measure, 
termed hapax-conditioned degree of productivity is 
said to measure expanding productivity, the rate at 
48
which a process is currently creating neologisms. It 
is computed as V(1,C,N)/V(1,N), the proportion of 
hapax legomena from the examined category C 
within the hapax legomena from all categories in 
the corpus. Intuitively, if the amount of hapax le-
gomena could be replaced by ?true? neologisms 
only, this would be the relative contribution of a 
process to productivity in the corpus, which could 
then be compared between different processes4. 
The third measure, category-conditioned degree 
of productivity measures the potential productivity 
of a process, meaning how likely it is to produce 
new members, or how saturated a process is. This 
measure is the proportion of hapax legomena from 
category C divided by N(C), the total token count 
from this category:  V(1,C,N)/N(C). It intuitively 
represents the probability of the next item from 
category C, found in further corpus data of the 
same type, to be a hapax legomenon.  
Baayen?s measures (hence p1, p2 and p3 respec-
tively) are appealing since they are rigorously de-
fined, easily extractable from a corpus (provided 
the process can be identified reliably in the data) 
and offer an essential reduction of the corpus wide 
behavior of a process to a number between 1 and 0, 
that is, an item producing no hapax legomena 
would score 0 on p2 and p3, and an item with 
100% hapax legomena would score 1 on p3, even 
if it is overall rather insignificant for productivity 
in the corpus as a whole (as reflected in a low 
score for p2). The measure p3 is the most impor-
tant one in the present context, since it allows us to 
reason conversely that, given that an item is novel 
and could belong to one of two processes, it is 
more likely to have come from whichever process 
is more productive, i.e. has a higher p3 score. 
Indeed the assumptions made in these measures 
do not necessarily fit syntactic productivity at a 
first glance: that the process in question has a 
clearly defined form (e.g. a suffix such as -ness) 
that it accommodates one variable slot (the stem, 
e.g. good- in goodness), and that each different 
stem forms a distinct type. Applying these meas-
ures to syntactic constructions requires conceptual 
                                                          
                                                          
4 This statement must be restricted somewhat: in items show-
ing multiple processes, e.g. bullishness, the processes associ-
ated with the suffixes -ish and -ness are not statistically 
independent, creating a difficulty in using such cases for the 
comparison of these two processes (see Baayen, 2009). In 
syntax the extent of this problem is unclear, since even occur-
rences of NPs and VPs are not independent of each other. 
and mathematical adaptation, which will be dis-
cussed in the next section using the example of 
comparative correlative constructions. 
3 Measuring Productivity in CCs 
Comparative correlatives are a complex yet typo-
logically well attested form of codependent clauses 
expressing a corresponding monotonous positive 
or negative change in degree between two proper-
ties (see den Dikken, 2005 for a cross-linguistic 
overview). For example, in the faster we go, the 
sooner we?ll get there, speed is monotonously cor-
related with time of arrival. A main reason for syn-
tactic interest in this type of sentence is a proposed 
?mismatch? (see McCawley, 1988, Culicover and 
Jackendoff, 1999) between its syntax, which ap-
pears to include two identically constructed para-
tactic clauses, and its semantics, which imply 
possible hypotaxis of the first clause as a sort of 
?conditional? (if and in so much as we go fast?).  
Two other noteworthy features of this construc-
tion in use (the following examples are from the 
BNC) are the frequent lack of a verb (the larger 
the leaf the better quality the tea) and even of a 
subject noun (the sooner the better) 5 and a ten-
dency for the (at least partial) lexicalization of cer-
tain items. The verbless variant often houses these, 
e.g. the more the merrier, but also with verbs, e.g. 
the bigger they come the harder they fall. A con-
text-free grammar might describe a simplified 
variant of such clauses in the following terms: 
 
Scc > the COMP (NP (VP)) 
S > Scc Scc   
 
where Scc is one of the comparative correlative 
clauses, COMP represents either English compara-
tive allomorph (in -er like bigger or analytic with 
more or less in more/less important), and NP and 
VP are optional subjects and corresponding predi-
cates for each clause.6  
However like many CFG rules, these rules may 
be too general, since it is clearly the case that not 
5 The latter form has been analyzed as a case of ellipsis of the 
copula be (Culicover and Jackendoff, 1999:554; similarly for 
German: Zifonun et al, 1997:2338). It is my position that this 
is not the case, as the bare construction has distinct semantic 
properties as well as different productive behavior, see below. 
6 These rules should be understood as agnostic with respect to 
the parataxis/hypotaxis question mentioned above. The paren-
theses mean NP may appear without VP but not vice versa. 
49
all comparatives, nouns and verbs fit in this con-
struction, if only because of semantic limitations, 
i.e. they must be plausibly capable of forming a 
pair of monotonously correlated properties. Corpus 
data shows that comparatives in CC clauses select 
quite different lexemes than comparatives at large, 
that the first and second slots (hence cc1 and cc2) 
have different preferences, and that the presence or 
absence of a VP and possibly a subject NP also 
interact with these choices. Table 1 shows com-
paratives in the BNC sorted by frequency in gen-
eral, along with their frequencies in cc1 and cc2. 
Some frequent comparatives do not or hardly ap-
pear in CCs given their frequency7 while others 
prefer a certain slot exclusively (e.g. more likely in 
cc2) or substantially (e.g. higher in cc1). Columns 
?1 and ?2 show bare comparatives (no subject or 
verb) in cc1 or 2 and the next two columns show 
subsets of bare cc1 or 2 given that the other clause 
is also bare. The last columns show CCs with only 
NPs and no verb, either in one clause or both. In 
bare CCs we find that better selects cc2 exclu-
sively, in fact making up some 88% of cc2s in this 
construction (the COMP the better) in the BNC. 
  
  
                                                          
                                                          
7 Occurrences of items which cannot serve attributively, such 
as more with no adjective and sooner, have been excluded, 
since they are not comparable to the other items. Most occur-
rences of the most frequent item, further, should arguably be 
excluded too, since it is mostly used as a lexicalized adverb 
and not a canonical comparative. However comparative usage 
is also well-attested, e.g.: he was going much further than that. 
A look at the list of lexemes typical to cc1 vs. 
cc2 shows that cc1 tends to express a dependent 
variable with spatiotemporal semantics (higher, 
older, longer), whereas cc2 typically shows an in-
dependent evaluative (better, more likely), though 
many common lexemes appear in both.8 
Although the results imply varying degrees of 
preference and lexicalization in different construc-
tions, they do not yet tell us whether or not, or bet-
ter how likely, we can expect to see new lexemes 
in each slot. This can be assessed using Baayen?s 
measures, by treating each construction as a mor-
phological process and the comparative slot as the 
lexical base forming the type (see Kiss, 2007 for a 
similar procedure).9 The results in Table 2 show 
that all constructions are productive to some ex-
tent, though clearly some yield fewer new types.  
 
 p1 and p2 show that CCs are responsible for 
very little of the productive potential of compara-
tives in the corpus. This is not only a function of 
the relative rarity of CCs: if we look at their rate of 
vocabulary growth (Figure 1), general compara-
tives gather new types more rapidly than CCs even 
for the same sample size10. Using a Finite Zipf 
Mandelbrot Model (FZM, Evert, 2004), we can 
extrapolate from the observed data to predict the 
gap will grow with sample size. 
 toks types hpx p1 p2 p3 
266703 5988 2616 0.00772 0.00651 0.0098
8 I thank Livio Gaeta and an anonymous reviewer for com-
menting on this point. 
9 In fact, one could also address the productivity of the con-
struction as a whole by regarding each argument tuple as a 
type, e.g. <more ergonomic, better> could be a hapax legome-
non despite better appearing quite often. Since each slot mul-
tiplies the chances a construction has to be unique, the nth root 
of the value of the measure would have to be taken in order to 
maintain comparability, thus the square root of pk for 2 slots, the cube root for 3 slots and so on. Another option, if one is 
interested in the chance that any particular slot will be unique, 
is to take the average of pk for all slots. However for the pre-sent purpose the individual score of each slot is more relevant. 
10 The comparative curve is taken from 2000 occurrences 
evenly distributed across the sections of the BNC, to corre-
spond topically to the CCs, which cover the whole corpus. 
word comp cc1 cc2 ?1 ?2 
?1 
(?2) 
(?1) 
?2 n1 n2
n1
(n2)
(n1)
n2 
further 21371                    
better 20727 15 143  89  51 9 22 5 15
higher 15434 97 39 4 2 3  84 23 44 21
greater 13883 82 171 1 1    75 92 35 80
lower 10983 20 27  2    18 12 7 12
older 8714 24 1 1  1  3  1  
?          
longer 3820 45 15 3 1 3  11 3 9 3
bigger 3469 43 13 4 1 3  30 8 15 8
more 
likely 3449  28          2  1
?            
more 
wholistic 1                    
zanier 1 1          1      
Table 1. Comparative frequencies independently and 
in cc1/cc2, with or without nominal subjects/verbs in 
one or both clauses. 
comp 
802 208 140 0.00026 0.00034 0.1745cc1 
802 181 126 0.00023 0.00031 0.1571cc2 
58 45 37 5.80E-05 9.22E-05 0.6379bare1 
58 7 5 9.03E-06 1.24E-05 0.0862bare2 
Table 2. Productivity scores for comparatives, cc-
clauses in general and specifically for bare CCs 
50
  
However, p3 shows the surprising result that 
CCs have more potential productivity than com-
paratives in general, with the bare cc1 slot leading, 
both general CC slots somewhat behind, and the 
bare cc2 last. This means our data does not begin 
to approach covering this category ? the next CC is 
much likelier to be novel, given the data we?ve 
seen so far. 
With this established, the question arises 
whether a CFG rule like the one above should take 
account of the likelihood of each slot to contain 
novel vs. familiar members. For instance, if a 
PCFG parser correctly identifies a novel compara-
tive and the input matches the rule, should it be 
more skeptical of an unseen bare cc1 than an un-
seen bare cc2 (keeping in mind that the latter have 
so far been better in 88% of cases)? To illustrate 
this, we may consider the output of a PCFG parser 
(in this case the Stanford Parser, Klein and Man-
ning, 2003) for an ambiguous example. 
Since CCs are rather rare, PCFGs will tend to 
prefer most other parses of a sentence, if these are 
available. Where no other reading is available we 
may get the expected two clause structure, as in the 
example in Figure 2.11  
 
                                                          
11 The X nodes conform to the Penn Treebank II Bracketing 
Guidelines for CCs (Bies et al, 1995:178).  
 The Stanford Parser fares quite well in cases 
like these, since the pronoun (it, I) can hardly be 
modified by the comparative (*[NP the closer it] or 
*[NP the more worried I]), and similarly for NPs 
with articles (*[NP the closer the time]). Yet article-
less NPs and bare CCs cause problems, as in the 
tree in Figure 3. 
 Figure 2. Stanford Parser tree for: The closer it gets, 
the more worried I become. 
Figure 1. Vocabulary growth curves and FZM ex-
trapolations for comparatives in cc1, cc2 and at large 
in the BNC.  
 
 
Figure 3. Stanford Parser tree for: The less cloudy, 
the better views can be seen to the south. 
 
Here The less cloudy and the better views form one 
NP, separate from the VP complex. Such a reading 
is not entirely impossible: the sentence could mean 
?less cloudy, better views? appositively. However 
despite the overall greater frequency of appositions 
and the fact that less cloudy has probably not been 
observed in cc1 in training data, the pattern of a 
novel form for cc1 and better in cc2 is actually 
consistent with a novel CC. With these ideas in 
mind, the next section examines the potential of 
productivity to disambiguate a much more preva-
lent phenomenon, namely PP attachment. 
4 PP Attachment and Productivity 
The problem of attaching prepositional phrases as 
sister nodes of VP or as adjuncts to its object nouns 
51
is a classic case of syntactic ambiguity that causes 
trouble for parsers (see Hindle and Rooth, 1993; 
Manning and Sch?tze, 1999:278-287; Atterer and 
Sch?tze, 2007), e.g. the difference between I ate a 
fish with a fork and I ate a fish with bones12, i.e. 
denoting the instrument or an attribute of the fish. 
There are also two further common readings of the 
preposition with in this context, namely attached 
either high or low in the VP in a comitative sense: 
I ate a fish with Mary and I ate a fish with potatoes 
respectively, though most approaches do not dis-
tinguish these, rather aiming at getting the attach-
ment site right. 
Already in early work on PP attachment (Hindle 
and Rooth, 1993) it was realized that the lexical 
identity of the verb, its object, the preposition and 
in later approaches also the prepositional object 
noun (Ratnaparkhi et al, 1994) are useful for pre-
dicting the attachment site, casting the task as a 
classification of tuples <v, n1, p, n2> into the 
classes V (VP attachment) and N (NP attachment). 
Classifiers are commonly either supervised, with 
disambiguated training data, or more recently un-
supervised (Ratnaparkhi, 1998) using data from 
unambiguous cases where no n1 or v appears. 
Other approaches supplement this information with 
hand-built or automatically acquired lexical re-
sources and collocation databases to determine the 
relationship between the lexemes, or, for lexemes 
unattested in the tuples, for semantically similar 
ones (Stetina and Nagao, 1997; Pantel and Lin, 
2000). 
Although the state of the art in lexically based 
systems actually approaches human performance, 
they lose their power when confronted with unfa-
miliar items. For example, what is the likeliest at-
tachment for the following BNC example: I can 
always eat dim-sum with my dybbuk? It is safe to 
assume that the (originally Hebrew) loan-word 
dybbuk ?(demonic) possession? does not appear in 
most training datasets, though dim-sum is attested 
more than once as an object of eat in the BNC. 
Crucially, the triple (eat, dim-sum, with) alone 
cannot reliably resolve the attachment site (con-
sider soy-sauce vs. chopsticks as n2). It is thus 
worth examining how likely a novel item is in the 
                                                          
                                                          12 Though in some cases the distinction is not so tenable, e.g. 
we have not signed a settlement agreement with them (Man-
ning and Sch?tze, 1999:286), where with them can arguably be 
attached low or high. Incidentally, the ?fish? examples are 
actually attested in the BNC in a linguistic context. 
relevant slot of each reading?s construction. The 
rest of this section therefore examines productivity 
scores for the slots in eat NP with NP and their 
correlation with different readings as an example. 
Since these cases cannot be identified automati-
cally in an unparsed text with any reliability, and 
since there is not enough hand-parsed data contain-
ing these constructions, a conservative proximity 
assumption was made (cf. Ratnaparkhi, 1998) and 
all occurrences of eat and related forms within ten 
words of with and with no intervening punctuation 
in the BNC were evaluated and tagged manually 
for this study. This also allowed for head-noun and 
anaphor resolution to identify the referent of a slot 
in the case of pronominal realization; thus all slot 
types in the data including pronouns are evaluated 
in terms of a single head noun.  
Results show that out of 131 hits, the largest 
group of PPs (59 tokens) were object noun modifi-
ers, almost all comitatives13, justifying the preva-
lent heuristic to prefer low attachment. However 
verbal instrumentals and high comitatives (25 and 
23 respectively) come at a very close second. The 
remaining 24 cases were adverbial modifications 
(e.g. with enthusiasm). Looking at hapax legomena 
in the respective slots we can calculate the meas-
ures in Table 3. 
 
 The scores show that the verbal instrumental read-
ing is the least likely to exhibit a novel head at the 
n2 slot, which is semantically plausible ? the reper-
toire of eating instruments is rather conventional-
ized and slow to expand. The comitative reading is 
very likely to innovate in n2, but much less so in 
n1, fitting e.g. the ?dim-sum with dybbuk?-
scenario. This fits the fact that one may eat to-
gether with many distinct persons etc., but when 
 n1 slot n2 slot total 
 hapax p3 hapax p3 tokens 
n 39 0.661 45 0.7627 59 
v adv 15 0.625 21 0.875 24 
v com 8 0.3478 20 0.8696 23 
v inst 15 0.6 4 0.16 25 
Table 3. p3 for the first and second head 
noun in nominal and three types of verbal PP 
attachment for eat n with n in the BNC. 
13 Only 4 hits were truely non-comitative noun modifiers, e.g. 
<eat, anything, with, preservatives>, where a comitative read-
ing is clearly not intended. Since the group was so small, all 
noun modifiers have been treated here together. 
52
these are specified, the exact nature of the meal or 
food is often left unspecified14. The adverbial read-
ing is likely to innovate in both slots, since many 
ways or circumstances of eating can be specified 
and these hardly restrict the choice of object for 
eat. Interestingly, the choice of object maintains a 
very stable productivity in all but the high comita-
tive construction. n2 innovation in nominal modi-
fiers is actually lower than for adverbials and 
comitatives, meaning low attachment may not be 
the preferred choice for unknown nouns. 
While these results imply what some reasonable 
expectations may be to find a novel member of 
each slot in each reading, they do not take the iden-
tity of the lexemes into account. In order to com-
bine the general information about the slot with 
knowledge of a known slot member, we may si-
multaneously attempt to score the productivity of 
the construction?s components, namely the noun or 
verb in question, for PP modifiers. This raises the 
problem of what exactly should be counted. One 
may argue that high-attached comitatives and ad-
verbials should be counted separately, since they 
are almost always optional regardless of the verb 
(one can equally well eat or do anything else with 
someone in some way), unlike instrumentals which 
may be more closely linked to the verb. On the 
other hand, the exact constructional sense of such 
PPs is colored by the verb, e.g. eating a meal with 
someone has a rather particular meaning (as op-
posed to coincidentally performing the act of eat-
ing alongside another eater). If the decision is only 
between high and low attachment, then grouping 
all variants together may be sensible in any case.  
Depending on the argument and verb, it is pos-
sible to make fine distinctions, provided enough 
cases are found. For dim-sum, for example, no 
cases of NP modifying with (novel or otherwise) 
are found, making the (correct) high comitative 
reading likely. By contrast, for the head noun fish, 
which is a common object of eat, 37 hits with with-
PPs are found in the BNC, forming 32 preposi-
tional object noun types of which 28 are hapax le-
gomena in this slot. All high readings of with-PPs 
with eat (including intransitive eat) form 92 to-
kens, 68 noun types and 44 hapax legomena. Thus 
fish + PP scores p3=0.756 while eat + PP scores 
                                                          
                                                          
14 In fact the non-food specific nouns breakfast, lunch, dinner, 
dish and meal cover 16 of the high comitative n1 tokens, al-
most 70%. 
0.478, corresponding to less productivity. This 
means novel prepositional objects are substantially 
less probable for the high attachment given that the 
direct object is fish. 
5 Conclusion 
The above results show that similar yet distinct 
constructions, which vary slightly in either con-
stituent structure (high vs. low attachment), seman-
tics (comitative or instrumental PPs), number of 
arguments (more and less bare CCs) or position 
(cc1 vs. cc2),  show very different lexical behavior, 
exhibiting more or less variety in different slots 
and differing proportions of hapax legomena. The 
inference which should become apparent from the 
sharp contrasts in slot scores (especially in p3) 
given the size of the data, is that these differences 
are not coincidental but are indicative of inherently 
different productivity rates for each slot in each 
construction. These properties need not be attrib-
uted to system internal, linguistic reasons alone, 
but may also very well reflect world knowledge 
and pragmatic considerations.15 However, from a 
construction grammar point of view, the entrench-
ment of these constructions in speakers and there-
fore in data is inextricably connected with 
interaction in the world, thus making syntactic 
productivity a plausible and relevant quantity both 
theoretically and potentially for NLP practice. 
It remains to be seen whether or not productiv-
ity scores can help automatically disambiguate 
structures with unseen arguments (e.g. PP attach-
ment with unencountered n2), or even distinguish 
semantic classes such as comitatives, instrumentals 
etc. for novel nouns, for which a classification into 
helpful semantic categories (animate, human and 
so forth) is not available. A large-scale evaluation 
of this question will depend on how easily and re-
liably productivity scores can be extracted auto-
matically from data for the relevant constructions.  
References  
Bengt Altenberg and Mats Eeg-Olofsson. 1990. Phrase-
ology in Spoken English. In: Jan Aarts and Willem 
Meijs, editors, Theory and Practice in Corpus Lin-
guistics. Rodopi, Amsterdam: 1-26. 
15 In this context it is worth mentioning that similar ongoing 
examinations of German CCs reveal different lexical prefer-
ences, implying that some of this behavior is language de-
pendent and to some extent language internally lexicalized. 
53
Michaela Atterer and Hinrich Sch?tze. 2007. Preposi-
tional Phrase Attachment without Oracles. Computa-
tional Linguistics, 33(4): 469-476. 
R. Harald Baayen. 2001. Word Frequency Distributions. 
(Text, Speech and Language Technologies 18.) Klu-
wer Academic Publishers, Dordrecht / Boston / Lon-
don. 
R. Harald Baayen. 2009. Corpus Linguistics in Mor-
phology: Morphological Productivity. In: Anke 
L?deling and Merja Kyt?, editors, Corpus Linguis-
tics. An International Handbook, vol. 2. Mouton de 
Gruyter, Berlin: 899-919. 
J?hanna Bar?dal. 2006. Predicting the Productivity of 
Argument Structure Constructions. In: The 32nd An-
nual Meeting of the Berkeley Linguistics Society. 
Berkeley Linguistics Society, Berkeley. Available at: 
http://ling.uib.no/barddal/BLS-32.barddal.pdf.  
Laurie Bauer. 2001. Morphological Productivity. (Cam-
bridge Studies in Linguistics 95.) Cambridge Univer-
sity Press, Cambridge, UK. 
Ann Bies, Mark Ferguson, Karen Katz and Robert Mac-
Intyre. 1995. Bracketing Guidelines for Treebank II 
Style Penn Treebank Project. Technical report, Uni-
versity of Pennsylvania. 
Douglas Biber, Susan Conrad and Viviana Cortes. 2004. 
If you look at?: Lexical Bundles in University 
Teaching and Textbooks. Applied Linguistics, 25(3): 
371-405. 
Douglas Biber, Stig Johansson, Geoffrey Leech, Susan 
Conrad and Edward Finegan. 1999. The Longman 
Grammar of Spoken and Written English. Longman, 
London. 
Yaacov Choueka. 1988. Looking for Needles in a Hay-
stack. In: Proceedings of RIAO ?88. Cambridge, MA, 
609-623. 
Peter W. Culicover and Ray Jackendoff. 1999. The 
View from the Periphery: The English Comparative 
Correlative. Linguistic Inquiry 30(4): 543-571. 
Marcel den Dikken. 2005. Comparative Correlatives 
Comparatively. Linguistic Inquiry, 36(4): 497-532. 
Stefan Evert. 2004. A simple LNRE model for random 
character sequences. In: Proceedings of JADT 2004: 
411-422. 
Stefan Evert. 2005. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. PhD disserta-
tion, University of Stuttgart. 
Stefan Evert. 2009. Corpora and Collocations. In: Anke 
L?deling and Merja Kyt?, editors, Corpus Linguis-
tics. An International Handbook, vol. 2. Mouton de 
Gruyter, Berlin: 1212-1248. 
Adele E. Goldberg. 1995. Constructions: A Construc-
tion Grammar Approach to Argument Structure. 
University of Chicago Press, Chicago and London. 
Adele E. Goldberg. 2006. Constructions at Work: The 
Nature of Generalization in Language. Oxford Uni-
versity Press, Oxford, UK. 
Donald Hindle and Mats Rooth. 1993. Structural Ambi-
guity and Lexical Relations. Computational Linguis-
tics, 19(1): 103-130. 
Daisuke Kawahara and Sadao Kurohashi. 2005. PP-
Attachment Disambiguation Boosted by a Gigantic 
Volume of Unambiguous Examples. In: Proceedings 
of the 2nd International Joint Conference on Natural 
Language Processing (IJCNLP-05): 188-198. 
Tibor Kiss. 2007. Produktivit?t und Idiomatizit?t von 
Pr?position-Substantiv-Sequenzen. Zeitschrift f?r 
Sprachwissenschaft, 26(2): 317-345. 
Dan Klein and Christopher D. Manning. 2003. Accurate 
Unlexicalized Parsing. In: Proceedings of the 41st 
Meeting of the Association for Computational Lin-
guistics: 423-430. 
Christopher D. Manning and Hinrich Sch?tze. 1999. 
Foundations of Statistical Natural Language Proc-
essing. MIT Press, Cambridge, MA. 
James D. McCawley. 1988. The Comparative Condi-
tional in English, German and Chinese. In: Proceed-
ings of the Fourteenth Annual Meeting of the 
Merkeley Linguistics Society. Berkeley Linguistics 
Society, Berkeley: 176-187. 
Patrick Pantel and Dekang Lin. 2000. An Unsupervised 
Approach to Prepositional Phrase Attachment using 
Contextually Similar Words. In: Proceedings of the 
38th Annual Meeting of the Association for Computa-
tional Linguistics: 101-108. 
Adwait Ratnaparkhi. 1998. Statistical Models for Unsu-
pervised Prepositional Phrase Attachment. In: Pro-
ceedings of COLING-ACL98, Montreal Canada: 
1079-1085 
Adwait Ratnaparkhi, Jeff Reynar and Salim Roukos. 
1994. A Maximum Entropy Model for Prepositional 
Phrase Attachment. In: Proceedings of the ARPA 
Human Language Technology Workshop. Plainsboro, 
NJ: 250-255. 
Ivan Sag, Timothy Baldwin, Francis Bond, Ann 
Copestake and Dan Flickinger. 2002. Multiword Ex-
pressions: A Pain in the Neck for NLP. In: Proceed-
ings of the Third International Conference on 
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002). Mexico City, Mexico: 1-
15. 
Andr? Salem. 1987. Pratique des segments r?p?t?s. 
Institut National de la Langue Fran?aise, Paris.  
Jiri Stetina and Makoto Nagao. 1997. Corpus Based PP 
Attachment Ambiguity Resolution with a Semantic 
Dictionary. In: Jou Zhao and Kenneth Church, edi-
tors, Proceedings of the Fifth Workshop on Very 
Large Corpora. Beijing and Hong Kong: 66-80. 
Gisela Zifonun, Ludger Hoffmann and Bruno Strecker, 
editors. 1997. Grammatik der deutschen Sprache, Bd. 
3. (Schriften des Instituts f?r deutsche Sprache 7.) De 
Gruyter, Berlin / New York. 
54
