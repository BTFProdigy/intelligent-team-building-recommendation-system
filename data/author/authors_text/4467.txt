Topic Identification In Natural Language Dialogues Using
Neural Networks
Krista Lagus and Jukka Kuusisto
Neural Networks Research Centre, Helsinki University of Technology
P.O.Box 9800, FIN-02015 HUT, Finland
krista.lagus@hut.fi
Abstract
In human?computer interaction sys-
tems using natural language, the
recognition of the topic from user?s
utterances is an important task. We
examine two different perspectives
to the problem of topic analysis
needed for carrying out a success-
ful dialogue. First, we apply self-
organized document maps for mod-
eling the broader subject of dis-
course based on the occurrence of
content words in the dialogue con-
text. On a Finnish corpus of 57
dialogues the method is shown to
work well for recognizing subjects of
longer dialogue segments, whereas
for individual utterances the sub-
ject recognition history should per-
haps be taken into account. Sec-
ond, we attempt to identify topically
relevant words in the utterances
and thus locate the old information
(?topic words?) and new information
(?focus words?). For this we define a
probabilistic model and compare dif-
ferent methods for model parameter
estimation on a corpus of 189 dia-
logues. Moreover, the utilization of
information regarding the position
of the word in the utterance is found
to improve the results.
1 Introduction
The analysis of the topic of a sentence or a
document is an important task for many nat-
ural language applications. For example, in
interactive dialogue systems that attempt to
carry out and answer requests made by cus-
tomers, the response strategy employed may
depend on the topic of the request (Jokinen et
al., 2002). In large vocabulary speech recog-
nition knowledge of the topic can, in general,
be utilized for adjusting the language model
used (see, e.g., (Iyer and Ostendorf, 1999)).
We describe two approaches to analyzing
the topical information, namely the use of
topically ordered document maps for analyz-
ing the overall topic of dialogue segments, and
identification of topic and focus words in an
utterance for sentence-level analysis and iden-
tification of topically relevant specific infor-
mation in short contexts.
1.1 Document map as a topically
ordered semantic space
The Self-Organizing Map (Kohonen, 1982;
Kohonen, 1995) is an unsupervised neural
network method suitable for ordering and vi-
sualization of complex data sets. It has been
shown that very large document collections
can be meaningfully organized onto maps that
are topically ordered: documents with similar
content are found near each other on the map
(Lin, 1992; Honkela et al, 1996; Lin, 1997;
Kohonen et al, 2000).
The document map can be considered to
form an ordered representation of possible
topics, i.e., a topical semantic space. Each
set of map coordinates specifies a point in the
semantic space, and additionally, corresponds
to a subset of the corpus, forming a kind of
associative topical-semantic memory.
Document maps have been found useful in
text mining and in improving information re-
      Philadelphia, July 2002, pp. 95-102.  Association for Computational Linguistics.
                  Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
trieval (Lagus, 2000). Recent experiments in-
dicate that the document maps ordered using
the SOM algorithm can be useful in focusing
the language model to the current active vo-
cabulary (Kurimo and Lagus, 2002).
In this article we examine the usefulness
of document maps for analyzing the topics of
transcripts of natural spoken dialogues. The
topic identification from both individual ut-
terances and longer segments is studied.
1.2 Conceptual analysis of individual
utterances
Within a single utterance or sentence the
speaker may provide several details that spec-
ify the request further or provide additional
information that specifies something said ear-
lier. Automatic extraction of the relevant
words and the concepts they relate to may be
useful, e.g., for a system filling out the fields
of a database query intended to answer the
user?s request.
If a small set of relevant semantic concepts
can be defined, and if the sentence structures
allowed are strictly limited, the semantic con-
cept identification problem can be solved, at
least to some degree, by manually designed
rule-based systems (Jokinen et al, 2002).
However, if the goal is the analysis of free-
form dialogues, one cannot count on hearing
full sentences. It is therefore important to try
to formulate the task as a learning problem
into which adaptive, statistical methods can
be applied.
The major challenge in adaptive language
modeling is the complexity of the learning
problem, caused by large vocabularies and
large amount of variation in sentence struc-
tures, compared to the amount of learning
data available. For English there already exist
various tagged and analyzed corpora. In con-
trast, for many smaller languages no tagged
corpora generally exist. Yet the methods that
are developed for English cannot as such be
applied for many other languages, such as
Finnish.
In the analysis of natural language di-
alogues, theories of information structure
(Sgall et al, 1986; Halliday, 1985) concern the
semantic concepts and their structural prop-
erties within an utterance. Such concepts in-
clude the attitudes, prior knowledge, beliefs
and intentions of the speaker, as well as con-
cepts identifying information that is shared
between the speakers. The terms ?topic? and
?focus? may be defined as follows: ?topic? is
the general subject of which the user is talk-
ing about, and ?focus? refers to the specific
additional information that the user now in-
troduces about the topic. An alternative way
of describing these terms is that ?topic? con-
stitutes of the old information shared by both
dialogue participants and ?focus? contains the
new information which is communicated re-
garding the topic.
A traditional way of finding the old and
new information is the ?question test? (see
(Vilkuna, 1989) about using it for Finnish).
For any declarative sentence, a question is
composed so that the sentence would be a nat-
ural answer to that question. Then the items
of the sentence that are repeated in the ques-
tion belong to the topic and the new items to
the focus.
A usual approach for topic?focus identi-
fication is to use parsed data. The sen-
tence, or it?s semantic or syntactic-semantic
representation, is divided into two segments,
usually at the location of the main verb,
and the words or semantical concepts in
the first segment are regarded as ?topic?
words/concepts and those in the second as ?fo-
cus? words/concepts. For example in (Meteer
and Iyer, 1996), the division point is placed
before the first strong verb, or, in the absence
of such a verb, behind the last weak verb of
the sentence. Similar division is also the start-
ing point for the algorithm for topic?focus
identification introduced in (Hajic?ova? et al,
1995). The initial division is then modified
according to the verb?s position and meaning,
the subject?s definiteness or indefiniteness and
the number, type and order of the other sen-
tence constituents.
In language modeling for speech recogni-
tion improvements in perplexity and word er-
ror rate have been observed on English cor-
pora when using language models trained sep-
arately for the topic and the focus part of the
sentence (Meteer and Iyer, 1996; Ma et al,
1998). Identification of these concepts is likely
to be important also for sentence comprehen-
sion and dialogue strategy selection.
In this article we examine the application of
a number of statistical approaches for identifi-
cation of these concepts. In particular, we ap-
ply the notions of topic and focus in informa-
tion structure (Sgall et al, 1986) to tagging a
set of natural dialogues in Finnish. We then
try several approaches for learning to identify
the occurrences of these concepts from new
data based on the statistical properties of the
old instances.
2 Experiments on recognizing the
dialogue topic of a dialogue turn
The ordered document map can be utilized
in the analysis of dialogue topics as follows:
encode a dialogue turn, i.e., an utterance u
(or an utterance combined with its recent his-
tory) as a document vector. Locate the best-
matching map unit, or several such units. Uti-
lize the identities of the best units as a seman-
tic representation of the topic of the u. In ef-
fect, this is a latent semantic representation
of the topical content of the utterance. Eval-
uation of such a latent representation directly
amounts to asking whether the dialogue man-
ager can benefit from the representation, and
must therefore be carried out by the dialogue
manager. This direct evaluation has not yet
been done.
Instead, we have utilized the following ap-
proach for evaluating the ordering of the maps
and the generalization to new, unseen dia-
logues: An intermediate set of named seman-
tic concepts has been defined in an attempt
to approximate what is considered to be inter-
esting for the dialogue manager. The latent
semantic representation of the map is then la-
beled or calibrated to reflect these named con-
cepts. In effect, each dialogue segment is cat-
egorized to a prior topical category. The or-
ganized map is labeled using part of the data
(?training data?), and the remaining part is
used to evaluate the map (?test data?)1.
1Note that even in this case the map is ordered in
Furthermore, a statistical model for docu-
ment classification can be defined on top of
the map. The probability model used for
topic estimation is
P (Ai|S) = P (XN |S)P (Ai|XN ), (1)
where Ai is the topic category, S denotes the
text transcription of the spoken sentence and
XN is the set of N best map vectors used for
the classification. We approximate the proba-
bility P (XN |S) to be equal for each map vec-
tor inXN . We assume thatXN conveys all in-
formation about S. The terms P (Ai|XN ) are
calculated as the relative frequencies of the
topics of the document vectors in the train-
ing data that were mapped to the nodes that
correspond to XN .
2.1 Corpus: transcripts of 57 spoken
dialogues
The data used in the experiments were
Finnish dialogues, recorded from the cus-
tomer service phone line of Helsinki City
Transport. The dialogues, provided by the
Interact project (Jokinen et al, 2002), had
been transcribed into text by a person listen-
ing to the tapes.
The transcribed data is extremely collo-
quial. Both the customers and the customer
service personnel use a lot of expletive words,
such as ?nii? (?so?, ?yea?) and ?tota? (?hum?,
?er?, ?like?), often the words appear in re-
duced or otherwise non-standard forms. The
word order does not always follow grammat-
ical rules and quite frequently there is con-
siderable overlap between the dialogue turns.
For example, the utterance of speaker A may
be interjected by a confirmation from speaker
B. This had currently been transcribed as
three separate utterances: A1 B A2.
2.2 Tagging and segmentation of
dialogues
The data set was split into training and test
data so that the first 33 dialogues were used
for organization and calibration of the map
an unsupervised manner, although it is applied for the
classification of new instances based on old ones.
Table 1: Proportions of customer utterances
in each topic category in the data sets.
Training data Test data
Beginnings 0.08 0.11
Endings 0.12 0.14
Timetables 0.49 0.59
Tickets 0.16 0.11
OOD 0.15 0.06
and the 24 dialogues collected later for test-
ing.
A small number of broad topic categories
were selected so that they comprehensively
encompass the subjects of discussion occur-
ring in the data. The categories were ?timeta-
bles?, ?beginnings?, ?tickets?, ?endings?, and
?out of domain?.
The dialogues were then manually tagged
and segmented, so that each continuous dia-
logue segment of several utterances that be-
longed to one general topic category formed
a single document. This resulted in a total of
196 segments, 115 and 81 in training and test
sets, respectively. Each segment contained
data from both the customer and the assis-
tant.
Of particular interest is the analysis of the
topics of individual customer utterances. The
data was therefore split further into utter-
ances, resulting in 450 and 189 customer ut-
terances in the training and test set, respec-
tively. The relative frequencies of utterances
belonging to each topic category for both
training and test data are shown in Table 1.
Each individual utterance was labeled with
the topic category of the segment it belonged
to.
2.3 Creation of the document map
The documents, whether segments or utter-
ances, were encoded as vectors using the
methods described in detail in (Kohonen et
al., 2000). In short, the encoding was as fol-
lows. Stopwords (function words etc.) and
words that appeared fewer than 2 times in the
training data were removed. The remaining
words were weighted using their entropy over
document classes. The documents were en-
coded using the vector space model by Salton
(Salton et al, 1975) with word weights. Fur-
thermore, sparse random projection of was
applied to reduce the dimensionality of the
document vectors from the original 1738 to
500 (for details of the method, see, e.g., (Ko-
honen et al, 2000)).
In organizing the map each longer dia-
logue segment was considered as a document.
The use of longer segments is likely to make
the organization of the map more robust.
The inclusion of the utterances by the assis-
tant is particularly important given the small
amount of data?all information must be uti-
lized. The document vectors were then orga-
nized on a SOM of 6? 4 = 24 units.
2.4 Experiments and results
We carried out three tests where the length
of dialogue segments was varied. In each
case, different values of N were tried. In
the first case, longer dialogue segments in the
training data were used to estimate the term
P (Ai|XN ) whereas recognition accuracy was
calculated on customer utterances only. Next,
individual customer utterances were used also
in estimating the model term. The best recog-
nition accuracy in both cases were obtained
using the value N = 3, namely 60.3% for
the first case and 65.1% for the second case.
In the third case we used the longer dia-
logue segments both for estimating the model
and for evaluation, to examine the effect of
longer context on the recognition accuracy.
The recognition accuracy was now 87.7%, i.e.,
clearly better for the longer dialogue segments
than for the utterances.
It seems that many utterances taken out of
context are too short or nondescript to pro-
vide reliable cues regarding the topical cat-
egory. An example of such an utterance is
?Onks sinne mita?a? muuta?? (lit. ?Is to there
anything else??, the intended meaning prob-
ably being ?Does any other bus go there??).
In this case it is the surrounding dialogue (or
perhaps the Finnish morpheme corresponding
to ?to?) that would identify the correct cate-
gory, namely ?timetables?.
Moreover, results on comparing a docu-
ment map to Independent Component Analy-
sis on the same corpus are reported in (Bing-
ham et al, 2002). The slightly higher per-
centages in that paper are due to evaluating
longer segments and to reporting the results
on the whole data set instead of a separate
test set.
3 Identification of old and new
information in utterances
We define this task as the identification of
?topic words? and ?focus words? from utter-
ances of natural Finnish dialogues. There
are thus no restrictions regarding the vocabu-
lary or the grammar. By observing previous,
marked instances of these concepts we try to
recognize the instances in new dialogues. It
should be noted that this task definition dif-
fers somewhat from those discussed in Sec-
tion 1.2 in that we do not construct any con-
ceptual representation of the utterances, nor
do we segment them into a ?topic? part and
a ?focus? part. This choice is due to utiliz-
ing natural utterances in which the sentence
borders do not always coincide with the turn-
taking of the speakers?a turn may consist of
several sentences or a partial one (when inter-
rupted by a comment from the other speaker).
In other words, we try to identify the central
words that communicate the topic and focus
in an utterance. We assume that they can ap-
pear in any part of the sentence and between
them there may be other words that are not
relevant to the topic or focus. Whether these
central words form a single topic or focus or
several such concepts is left open.
3.1 Corpus and tagging
The corpus used includes the same data as
in section 2 with additional 133 dialogues
collected from the same source. Basically
each dialogue turn was treated as an utter-
ance, with the exception that long turns were
segmented into sentence-like segments, which
were then considered to be utterances2. Ut-
terances consisting of only one word were re-
2Non-textual cues such as silences within turns
could not be considered for segmenting because they
were not marked in the data.
moved from the data. The training data con-
tained 11464 words in 1704 utterances. Of the
words 17 % were tagged as topic, and 28 % as
focus. The test data consisted of 11750 words
in 1415 utterances, with 14 % tagged as topic
and 25 % as focus.
In tagging the topic and focus words in
the corpus, the following definitions were em-
ployed: In interrogative clauses focus consists
of those words that form the exact entity that
is being asked and all the other words that de-
fine the subject are tagged as belonging to the
topic. In declarative sentences that function
as answers words that form the core of the
answer are tagged as ?focus?, and other words
that merely provide context for the specific
answer are tagged as ?topic?. In other declar-
ative sentences ?topics? are words that define
the subject matter and ?focus? is applied to
words that communicate what is being said
about the topic. Regardless, the tagging task
was in many cases quite difficult, and the re-
sulting choice of tags often debatable.
As is charasteristic of spoken language, the
data contained a noticeable percentage (35 %)
of elliptic utterances, which didn?t contain
any topic words. Multiple topic constructs,
on the other hand, were quite rare: more than
one topic concept occurred in only 1 % of the
utterances. The pronouns were quite evenly
distributed with regard to position in the ut-
terances: 32 % were in medial and 36 % in
final position3.
3.2 The probabilistic model
The probability of a word belonging to the
class topic, focus or other is modeled as
P (Ti|W,S) =
P (Ti|W )P (Ti|S)
P (Ti)
, (2)
where W denotes the word, S its position in
an utterance, and Ti ? {topic, focus, other}
stands for the class. The model thus assumes
that being a topic or a focus word is depen-
dent on the properties of that particular word
as well as its position in the utterance. Due
3We interpreted ?medial? to mean the middle third
of the sentence, and ?final? to be the last third of the
sentence.
to computational reasons we made the sim-
plifying assumption that these two effects are
independent, i.e., P (W,S) = P (W )P (S).
Maximum likelihood estimates are used for
the terms P (Ti|W ) for already seen words.
Moreover, for unseen words we use the aver-
age of the models of words seen only rarely
(once or twice) in the training data.
For the term P (Ti|S) that describes the ef-
fect of the position of a word we use a softmax
model, namely
P (Ti|Sj) =
eqi(xj)
?
i e
qi(xj)
, (3)
where the index j identifies the word and xj
is the position of the word j. The functions
qi are defined as simple linear functions
qi(xj) = aixj + bi (4)
The parameters ai and bi are estimated from
the training data. For the class T3 (other),
these parameters are set to a constant value
of zero.
3.2.1 ML estimation
When evaluating the rest of the model pa-
rameters we use two methods, first Maximum
Likelihood estimation and then Bayesian vari-
ational analysis.
In ML estimation the cost function is the
log likelihood of the training data D given
the model M , i.e,
lnP (D|M) = ln
?
w
P (Ti|Sw) (5)
=
?
w?T1
q1 +
?
w?T2
q2 +
?
w
(? ln(1 + eq1 + eq2)). (6)
The logarithmic term is approximated by a
Taylor series of first degree and the parame-
ters can then be solved as usual, by setting the
partial derivatives of lnP (D|M) to zero with
regard to each parameter. The parameters bi
can be solved analytically and the parameters
ai are solved using Newton iteration.
3.2.2 Bayesian estimation
The ML estimation is known to be prone
to overlearning the properties of the train-
ing data. In contrast, in the Bayesian ap-
proach, also the model cost is included in the
cost function and can be used to avoid over-
learning. For comparison, we thus tried also
the Bayesian approach utilizing the software
and methodology introduced in (Valpola et
al., 2001). The method is based on variational
analysis and uses ensemble learning for esti-
mating the model parameters. The method-
ology and the software allows for the opti-
mization of the model structure with roughly
linear computational complexity without the
risk of over-fitting the model. However, in
these experiments the model structure was
not optimized.
3.2.3 Disregarding position
information
Furthermore, to study the importance of
the position information, we calculated the
probabilities using only ML estimates for
P (T |W ), i.e., disregarding the position of the
word.
3.2.4 Tf?idf
As a comparison, we applied the tf?idf
weighting scheme, which is commonly used
in information retrieval for weighting content
words. This method does not benefit from the
labeling of the training data. For this reason,
it does not differentiate between ?topic? and
?focus? words.
3.3 Experiments and results
The following experiment was performed us-
ing each described method: For each utter-
ance in the test data, n words were tagged
as topic, and likewise for the focus category.
Further, n was varied from 1 to 8 to produce
the results depicted in Figure 1.
As can be seen, the Bayesian variational
analysis and the maximum likelihood estima-
tion produce nearly identical performances.
This is perhaps due to the use of very smooth
model family, namely first-order polynomials,
for taking into account the effect of the posi-
tion of the word. For this reason, overlearn-
0 0.5 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Recall
Prec
ision
Topics
ML          Bayes       No pos. inf.Idf         Random      
0 0.5 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Recall
Prec
ision
Focuses
Figure 1: The precision?recall curves for
topic?focus estimation. (ML = maximum
likelihood, Bayes = Bayesian variational anal-
ysis, No pos. inf. = without position informa-
tion, Idf = tf?idf weighting, Random = the
average precision with random selection.)
ing is not problem even for the ML estima-
tion. However, since the nearly identical re-
sults were obtained using two completely dif-
ferent implementations of quite similar meth-
ods, this can be considered as a validation
experiment on either implementation and op-
timization method. In total, it seems that the
full statistical model designed works rather
well especially in focus identification.
When compared to the full model, disre-
garding position information altoghether re-
sults in inferior performance. The difference
is statistically significant (p ? 0.05) in focus
identification for all values of n and in topic
identification for small values of n. More-
over, the performance of the tf?idf scheme
is clearly inferior in either task. However, it
seems that the tf?idf definition of word im-
portance corresponds more closely with the
definition of ?focus? than that of ?topic?.
4 Discussion and conclusions
We examined two different viewpoints for the
topic identification problem in natural lan-
guage understanding. In experiments utiliz-
ing document maps it was found that longer
dialogue segments are reliably modeled, but
especially for short segments the history of
the utterance must be consulted. A perhaps
more interesting idea would be to also look at
morphological features, such as cases, and in-
clude them in the encoding of the utterances.
We plan to study this possibility in further
work.
In the second viewpoint, individual utter-
ances were analyzed to automatically iden-
tify ?topics? (what the user is talking about)
and ?focuses? (what is being said about the
topic). Each word in an utterance was labeled
as ?topic?, ?focus? or ?other?.
A statistical model that utilized the iden-
tity of the word and its position in the ut-
terance was found to be rather successful, es-
pecially for identification of words belonging
to the ?focus? category. Without the position
information significantly lower performance
was observed, which indicates that position
information is indeed relevant for the iden-
tification. In this case, the Bayesian mod-
eling paradigm and the maximum likelihood
estimation produced nearly identical perfor-
mance. However, this is not the case in gen-
eral, when less smooth model families and op-
timization of model structure are applied. In
the future we plan to examine other kinds of
model structures for this task, perhaps inte-
grating new types of information sources re-
garding the words, as well. For example, it
would be interesting to see whether the ad-
dition of prosodic information would provide
additional cues to improved solving of this
task.
5 Acknowledgements
We thank Harri Valpola for his valuable ad-
vice concerning the estimation of the topic-
focus identification model and for the possi-
bility to apply the Bayesian software package
developed by his group.
This work is part of the collaborative ?Inter-
act? project on natural language interaction in
Finnish.
References
Ella Bingham, Jukka Kuusisto, and Krista Lagus.
2002. Ica and som in text document analy-
sis. In The 25th ACM SIGIR Conference on
Research and Development in Information Re-
trieval,August 11-15, 2002, Tampere, Finland.
Submitted.
Eva Hajic?ova?, Petr Sgall, and Hana Skoumalova?.
1995. An automatic procedure for topic?
focus identification. Computational Linguis-
tics, 21(1):81?94.
M. A. Halliday. 1985. Introduction to Functional
Grammar. Oxford University Press, Oxford,
UK.
Timo Honkela, Samuel Kaski, Krista Lagus, and
Teuvo Kohonen. 1996. Newsgroup exploration
with WEBSOM method and browsing inter-
face. Technical Report A32, Helsinki University
of Technology, Laboratory of Computer and In-
formation Science, Espoo, Finland.
R.M. Iyer and M. Ostendorf. 1999. Modelling
long distance dependencies in language: Topic
mixtures versus dynamic cache model. IEEE
Trans. Speech and Audio Processing, 7.
Kristiina Jokinen, Antti Kerminen, Mauri
Kaipainen, Tommi Jauhiainen, Markku Tu-
runen, Jaakko Hakulinen, Jukka Kuusisto, and
Krista Lagus. 2002. Adaptive dialogue systems
? interaction with interact. In 3rd SIGdial
Workshop on Discourse and Dialogue, July 11
and 12, 2002. To appear.
Teuvo Kohonen, Samuel Kaski, Krista Lagus,
Jarkko Salojrvi, Vesa Paatero, and Antti
Saarela. 2000. Organization of a massive
document collection. IEEE Transactions on
Neural Networks, Special Issue on Neural Net-
works for Data Mining and Knowledge Discov-
ery, 11(3):574?585.
Teuvo Kohonen. 1982. Analysis of a simple
self-organizing process. Biological Cybernetics,
44(2):135?140.
Teuvo Kohonen. 1995. Self-Organizing Maps.
3rd, extended edition, 2001. Springer, Berlin.
Mikko Kurimo and Krista Lagus. 2002. An
efficiently focusing large vocabulary language
model. In International Conference on Arti-
ficial Neural Networks, ICANN?02. To appear.
Krista Lagus. 2000. Text mining with the WEB-
SOM. Acta Polytechnica Scandinavica, Mathe-
matics and Computing Series No. 110, 54 pp.
December. D.Sc(Tech) Thesis, Helsinki Univer-
sity of Technology, Finland.
Xia Lin. 1992. Visualization for the document
space. In Proceedings of Visualization ?92,
pages 274?81, Los Alamitos, CA, USA. Cen-
ter for Comput. Legal Res., Pace Univ., White
Plains, NY, USA, IEEE Comput. Soc. Press.
Xia Lin. 1997. Map displays for information re-
trieval. Journal of the American Society for
Information Science, 48:40?54.
Kristine Ma, George Zavaliagkos, and Marie
Meteer. 1998. Sub-sentence discourse models
for conversational speech recognition. In Pro-
ceedings of the 1998 IEEE International Con-
ference on Acoustics, Speech and Signal Pro-
cessing, vol. 2, Seattle, Washington, USA.
Marie Meteer and Rukmini Iyer. 1996. Model-
ing conversational speech for speech recogni-
tion. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Process-
ing, Philadelphia, PA, USA.
G. Salton, A. Wong, and C. S. Yang. 1975. A vec-
tor space model for automatic indexing. Com-
munications of the ACM, 18(11):613?620.
Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.
1986. The Meaning of the Sentence in Its Se-
mantic and Pragmatic Aspects. D. Reidel Pub-
lishing Company, Dordrecht, Holland.
Harri Valpola, Tapani Raiko, and Juha Karhunen.
2001. Building blocks for hierarchical latent
variable models. In In Proceedings of the 3rd
International Conference on Independent Com-
ponent Analysis and Blind Signal Separation,
San Diego, California, USA.
Maria Vilkuna. 1989. Free Word Order in
Finnish. Its Syntax and discourse functions.
Suomalaisen Kirjallisuuden Seura, Helsinki.
Adaptive Dialogue Systems - Interaction with Interact
Kristiina Jokinen and Antti Kerminen and Mauri Kaipainen
Media Lab, University of Art and Design Helsinki
Ha?meentie 135 C, FIN-00560 Helsinki, Finland
{kjokinen|akermine|mkaipain}@uiah.fi
Tommi Jauhiainen and Graham Wilcock
Department of General Linguistics, University of Helsinki
FIN-00014 University of Helsinki, Finland
{tsjauhia|gwilcock}@ling.helsinki.fi
Markku Turunen and Jaakko Hakulinen
TAUCHI Unit, University of Tampere
FIN-33014 University of Tampere, Finland
{mturunen|jh}@cs.uta.fi
Jukka Kuusisto and Krista Lagus
Neural Networks Research Centre, Helsinki University of Technology
P.O.9800 FIN-02015 HUT, Finland
{krista|jkuusist}@james.hut.fi
Abstract
Technological development has made
computer interaction more common
and also commercially feasible, and
the number of interactive systems has
grown rapidly. At the same time, the
systems should be able to adapt to var-
ious situations and various users, so as
to provide the most efficient and help-
ful mode of interaction. The aim of
the Interact project is to explore nat-
ural human-computer interaction and
to develop dialogue models which will
allow users to interact with the com-
puter in a natural and robust way. The
paper describes the innovative goals of
the project and presents ways that the
Interact system supports adaptivity on
different system design and interaction
management levels.
1 Introduction
The need for flexible interaction is apparent not
only in everyday computer use, but also in vari-
ous situations and services where interactive sys-
tems can diminish routine work on the part of
the service provider, and also cater for the users
with fast and tailored access to digital infor-
mation (call centers, help systems, interactive
banking and booking facilities, routing systems,
information retrieval, etc.).
The innovative goal of the Finnish Interact
project is to enable natural language interac-
tion in a wider range of situations than has been
possible so far, and in situations where its use
has not been functional or robust enough. This
means that the systems should support rich in-
teraction and also be able to learn and adapt
their functionality to the changing situation. It
also implies that the needs of special groups will
be taken into account when designing more nat-
ural interactive systems. Within the current sys-
tem, such scenarios can e.g. include an intelli-
gent bus-stop which allows spoken and text in-
teraction concerning city transportation, with a
sign language help facility.
The project addresses especially the problem
of adaptivity: the users are situated in mo-
bile environments in which their needs, activities
and abilities vary. To allow the users to express
their wishes in a way characteristic to them and
       Philadelphia, July 2002, pp. 64-73.  Association for Computational Linguistics.
                  Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
the situation, interaction with the system should
take place in a robust and efficient manner, en-
abling rich and flexible communication. Natu-
ral language is thus the preferred mode of in-
teraction, compared to graphical interfaces for
example. Adaptivity also appears in the tech-
niques and methods used in the modelling of
the interaction and the system?s processing ca-
pabilities. An important aspect in this respect
is to combine machine learning techniques with
rule-based natural language processing, to in-
vestigate limitations and advantages of the two
approaches for language technology.
In this paper we focus on adaptivity which
manifests itself in various system properties:
? agent-based architecture
? natural language capability
? self-organising topic recognition
? conversational ability.
The paper is organized as follows. We first
introduce the dialogue system architecture. We
then explain how the modules function and
address the specific design decisions that con-
tribute to the system?s adaptivity. We conclude
by discussing the system?s capabilities and pro-
viding pointers for future work.
2 Agent-based architecture
To allow system development with reusable
modules, flexible application building and easy
combination of different techniques, the frame-
work must itself be designed specifically to sup-
port adaptivity. We argue in favour of a sys-
tem architecture using highly specialized agents,
and use the Jaspis adaptive speech application
framework (Turunen and Hakulinen, 2000; Tu-
runen and Hakulinen, 2001a). Compared to e.g.
Galaxy (Seneff et al, 1998), the system supports
more flexible component communication. The
system is depicted in Figure 1.
2.1 Information Storage
The Jaspis architecture contains several features
which support adaptive applications. First of
all, the information about the system state is
kept in a shared knowledge base called Informa-
tion Storage. This blackboard-type information
storage can be accessed by each system compo-
nent via the Information Manager, which allows
them to utilize all the information that the sys-
tem contains, such as dialogue history and user
profiles, directly. Since the important informa-
tion is kept in a shared place, system compo-
nents can be stateless, and the system can switch
between them dynamically. Information Stor-
age thus facilitates the system?s adaptation to
different internal situations, and it also enables
the most suitable component to be chosen to
handle each situation.
2.2 Flexible Component Management
The system is organized into modules which
contain three kinds of components: managers,
agents and evaluators. Each module contains
one manager which co-ordinates component in-
teraction inside the module. The present archi-
tecture implements e.g. the Input/Output Man-
ager, the Dialogue Manager and the Presenta-
tion Manager, and they have different priorities
which allow them to react to the interaction flow
differently. The basic principle is that whenever
a manager stops processing, all managers can
react to the situation, and based on their prior-
ities, one of them is selected. There is also the
Interaction Manager which coordinates applica-
tions on the most general level.
The number and type of modules that can be
connected to the system is not limited. The In-
teraction Manager handles all the connections
between modules and the system can be dis-
tributed for multiple computers. In Interact
we have built a demonstration application on
bus-timetable information which runs on several
platforms using different operating systems and
programming languages. This makes the system
highly modular and allows experiments with dif-
ferent approaches from multiple disciplines.
2.3 Interaction Agents and Evaluators
Inside the modules, there are several agents
which handle various interaction situations such
as speech output presentations and dialogue de-
cisions. These interaction agents can be very
Figure 1: The system architecture.
specialized, e.g. they deal only with speech
recognition errors or outputs related to greet-
ings. They can also be used to model differ-
ent interaction strategies for the same task, e.g.
different dialogue agents can implement alterna-
tive dialogue strategies and control techniques.
Using specialized agents it is possible to con-
struct modular, reusable and extendable inter-
action components that are easy to implement
and maintain. For example, different error han-
dling methods can be included to the system by
constructing new agents which handle errors us-
ing alternative approaches. Similarly, we can
support multilingual outputs by constructing
presentation agents that incorporate language
specific features for each language, while imple-
menting general interaction techniques, such as
error correction methods, to take care of error
situations in speech applications in general (Tu-
runen and Hakulinen, 2001b).
The agents have different capabilities and the
appropriate agent to handle a particular situa-
tion at hand is selected dynamically based on
the context. The choice is done using evalua-
tors which determine applicability of the agents
to various interaction situations. Each evaluator
gives a score for every agent, using a scale be-
tween [0,1]. Zero means that an agent is not
suitable for the situation, one means that an
agent is perfectly suitable for the situation, val-
ues between zero and one indicate the level of
suitability. Scaling functions can be used to em-
phasize certain evaluators over the others The
scores are then multiplied, and the final score, a
suitability factor, is given for every agent. Since
scores are multiplied, an agent which receives
zero from one evaluator is useless for that situ-
ation. It is possible to use different approaches
in the evaluation of the agents, and for instance,
the dialogue evaluators are based on reinforce-
ment learning.
Simple examples of evaluators are for instance
presentation evaluators that select presentation
agents to generate suitable implicit or explicit
confirmations based on the dialogue history and
the system?s knowledge of the user. Another ex-
ample concerns dialogue strategies: the evalua-
tors may give better scores for system-initiative
agents if the dialogue is not proceeding well with
the user-initiative dialogue style, or the evalua-
tors may prefer presentation agents which give
more detailed and helpful information, if the
users seem to have problems in communicating
with the application.
Different evaluators evaluate different aspects
of interaction, and this makes the evaluation
process highly adaptive itself: there is no single
evaluator which makes the final decision. In-
stead, the choice of the appropriate interaction
agent is a combination of different evaluations.
Evaluators have access to all information in the
Information Storage, for example dialogue his-
tory and other contextual information, and it is
also possible to use different approaches in the
evaluation of the agents (such as rule-based and
statistical approaches). Evaluators are the key
concept when considering the whole system and
its adaptation to various interaction situations.
2.4 Distributed Input and Output
The input/output subsystem is also distributed
which makes it possible to use several input and
output devices for the same purposes. For ex-
ample, we can use several speech recognition
engines, each of which with different capabili-
ties, to adapt the system to the user?s way of
talking. The system architecture contains vir-
tual devices which abstract the actual devices,
such as speech recognizers and speech synthesiz-
ers. From the application developers viewpoint
this makes it easy to experiment with different
modalities, since special agents are used to add
and interpret modality specific features. It is
also used for multilingual inputs and outputs,
although the Interact project focuses on Finnish
speech applications.
3 Natural Language Capabilities
The use of Finnish as an interaction language
brings special problems for the system?s nat-
ural language understanding component. The
extreme multiplicity of word forms prevents the
use of all-including dictionaries. For instance,
a Finnish noun can theoretically have around
2200, and a verb around 12000 different forms
(Karlsson, 1983). In spoken language these
numbers are further increased as all the differ-
ent ways to pronounce any given word come into
consideration (Jauhiainen, 2001). Our dialogue
system is designed to understand both written
and spoken input.
3.1 Written and spoken input
The different word forms are analyzed using
Fintwol, the two-level morphological analyzer
for Finnish (Koskenniemi, 1983). The forms are
currently input to the syntactic parser CPARSE
(Carlson, 2001). However, the flexible sys-
tem architecture also allows us to experiment
with different morphosyntactic analyzers, such
as TextMorfo (Kielikone Oy 1999) and Conexor
FDG (Conexor Oy 1997-2000), and we plan
to run them in parallel as separate competing
agents to test and compare their applicability
as well as the Jaspis architecture in the given
task.
We use the Lingsoft Speech Recognizer for the
spoken language input. The current state of the
Finnish speech recognizer forces us to limit the
user?s spoken input to rather restricted vocab-
ulary and utterance structure, compared to the
unlimited written input. The system uses full
word lists which include all the morphological
forms that are to be recognized, and a strict
context-free grammar which dictates all the pos-
sible utterance structures. We are currently ex-
ploring possibilities for a HMM-based language
model, with the conditional probabilities deter-
mined by a trigram backoff model.
3.2 Language analysis
The task of the parsing component is to map
the speaker utterances into task-relevant do-
main concepts which are to be processed by
the dialogue manager. The number of domain
concepts concerning the demonstration system?s
application domain, bus-timetables, is rather
small and contains e.g. bus, departure-time
and arrival-location. However, semantically
equivalent utterances can of course vary in the
lexical elements they contain, and in written and
especially in spoken Finnish the word order in
almost any given sentence can also be changed
without major changes on the semantic level un-
derstood by the system (the difference lies in the
information structure of the utterance). For in-
stance, the request How does one get to Malmi?
can be realised as given in Table 1.
There are two ways to approach the problem:
on one hand we can concentrate on finding the
keywords and their relevant word forms, on the
other hand we can use more specialized syntac-
tic analyzers. At the moment we use CPARSE
as the syntactic analyzer for text-based input.
The grammar has been adjusted for the demon-
Kuinka pa?a?see bussilla Malmille?
Miten pa?a?see Malmille bussilla?
Kuinka Malmille pa?a?see bussilla?
Malmille miten pa?a?see bussilla?
Milla? bussilla pa?a?se Malmille?
Malmille olisin bussia kysellyt.
Pa?a?seeko? bussilla Malmille?
Table 1: Some alternative utterances for Kuinka
pa?a?see Malmille bussilla? ?How does-one-get to-
Malmi by bus?
stration system so that it especially looks for
phrases relevant to the task at hand. For in-
stance, if we can correctly identify the inflected
word form Malmille from the input string, we
can be quite certain of the user wishing to know
something about getting to Malmi.
The current speech input does not go through
any special morpho-syntactic analysis because
of the strict context-free grammar used by the
speech recognizer. The dictionary used by the
recognizer is tagged with the needed morpholog-
ical information and the context-free rules are
tagged with the needed syntactic information.
3.3 Language generation
The language generation function is located in
the system?s Presentation Manager module. Un-
like language analysis, for which different ex-
isting Finnish morphosyntactic analyzers can
be used, there are no readily available general-
purpose Finnish language generators. We are
therefore developing specific generation compo-
nents for this project. The flexible system ar-
chitecture allows us to experiment with different
generators.
Unfortunately the existing Finnish syntactic
analyzers have been designed from the outset as
?parsing grammars?, which are difficult or im-
possible to use for generation. However, the two-
level morphology model (Koskenniemi, 1983) is
in principle bi-directional, and we are work-
ing towards its use in morphological generation.
Fortunately there is also an existing Finnish
speech synthesis project (Vainio, 2001), which
we can use together with the language genera-
tors.
Some of our language generation components
use the XML-based generation framework de-
scribed by Wilcock (2001), which has the ad-
vantage of integrating well with the XML-based
system architecture. The generator starts from
an agenda which is created by the dialogue man-
ager, and is available in the system?s Informa-
tion Storage in XML format. The agenda con-
tains a list of semantic concepts which the dia-
logue manager has tagged as Topic or NewInfo.
From the agenda the generator creates a re-
sponse plan, which passes through the genera-
tion pipeline stages for lexicalization, aggrega-
tion, referring expressions, syntactic and mor-
phological realization. At all stages the response
specification is XML-based, including the final
speech markup language which is passed to the
speech synthesizer.
The system architecture allows multiple gen-
erators to be used. In addition to the XML-
based pipeline components we have some pre-
generated outputs, such as greetings at the start
and end of the dialogue or meta-acts such as
wait-requests and thanking. We are also ex-
ploiting the agent-based architecture to increase
the system?s adaptivity in response generation,
using the level of communicative confidence as
described by Jokinen and Wilcock (2001).
4 Recognition of Discussion Topic
One of the important aspects of the system?s
adaptivity is that it can recognize the correct
topic that the user wants to talk about. By
?topic? we refer to the general subject matter
that a dialogue is about, such as ?bus timetables?
and ?bus tickets?, realized by particular words in
the utterances. In this sense, individual doc-
uments or short conversations may be seen to
have one or a small number of topics, one at a
time.
4.1 Topically ordered semantic space
Collections of short documents, such as news-
paper articles, scientific abstracts and the like,
can be automatically organized onto document
maps utilizing the Self-Organizing Map algo-
rithm (Kohonen, 1995). The document map
methodology has been developed in the WEB-
SOM project (Kohonen et al, 2000), where the
largest map organized consisted of nearly 7 mil-
lion patent abstracts.
We have applied the method to dialogue topic
recognition by carring out experiments on 57
Finnish dialogues, recorded from the customer
service phone line of Helsinki City Transport
and transcribed manually into text. The dia-
logues are first split into topically coherent seg-
ments (utterances or longer segments), and then
organized on a document map. On the ordered
map, each dialogue segment is found in a spe-
cific map location, and topically similar dialogue
segments are found near it. The document map
thus forms a kind of topically ordered semantic
space. A new dialogue segment, either an utter-
ance or a longer history, can likewise be auto-
matically positioned on the map. The coordi-
nates of the best-matching map unit may then
be considered as a latent topical representation
for the dialogue segment.
Furthermore, the map units can be labeled us-
ing named topic classes such as ?timetables? and
?tickets?. One can then estimate the probability
of a named topic class for a new dialogue seg-
ment by construing a probability model defined
on top of the map. A detailed description of the
experiments as well as results can be found in
(Lagus and Kuusisto, 2002).
4.2 Topic recognition module
The topical semantic representation, i.e. the
map coordinates, can be used as input for the
dialogue manager, as one of the values of the
current dialogue state. The system architecture
thus integrates a special topic recognition mod-
ule that outputs the utterance topic in the In-
formation Storage. For a given text segment,
say, the recognition result from the speech rec-
ognizer, the module returns the coordinates of
the best-matching dialogue map unit as well as
the most probable prior topic category (if prior
categorization was used in labeling the map).
5 Dialogue Management
The main task of the dialogue manager com-
ponent is to decide on the appropriate way to
react to the user input. The reasoning includes
recognition of communicative intentions behind
the user?s utterances as well as planning of the
system?s next action, whether this is information
retrieval from a database or a question to clarify
an insufficiently specified request. Natural inter-
action with the user also means that the system
should not produce relevant responses only in
terms of correct database facts but also in terms
of rational and cooperative reactions. The sys-
tem could learn suitable interaction strategies
from its interaction with the user, showing adap-
tation to various user habits and situations.
5.1 Constructive Dialogue Model
A uniform basis for dialogue management can
be found in the communicative principles re-
lated to human rational and coordinated inter-
action (Allwood et al, 2000; Jokinen, 1996).
The speakers are engaged in a particular activ-
ity, they have a certain role in that activity, and
their actions are constrained by communicative
obligations. They act by exchanging new in-
formation and constructing a shared context in
which to resolve the underlying task satisfacto-
rily.
The model consists of a set of dialogue states,
defined with the help of dialogue acts, obser-
vations of the context, and reinforcement val-
ues. Each action results in a new dialogue
state. The dialogue act, Dact, describes the act
that the speaker performs by a particular utter-
ance, while the topic Top and new information
NewInfo denote the semantic content of the ut-
terance and are related to the task domain. To-
gether these three create a useful first approx-
imation of the utterance meaning by abstract-
ing over possible linguistic realisations. Unfilled
task goals TGoals keep track of the activity re-
lated information still necessary to fulfil the un-
derlying task (a kind of plan), and the speaker
information is needed to link the state to pos-
sible speaker characteristics. The expectations,
Expect are related to communicative obligations,
and used to constrain possible interpretations of
the next act. Consequently, the system?s inter-
nal states can be reduced to a combination of
these categories, all of which form an indepen-
dent source of information for the system to de-
cide on the next move.
5.2 Dialogue agents and evaluators
A dialogue state and all agents that contribute
to a dialogue state are shown in Figure 2. The
Dialogue Model is used to classify the current
utterance into one of the dialogue act categories
(Jokinen et al, 2001), and to predict the next
dialogue acts (Expect). The Topic Model rec-
ognizes the domain, or discussion topic, of the
user input as described above.
Figure 2: Dialogue states for user?s utter-
ance and system action, together with dialogue
agents involved in producing various informa-
tion.
All domains out of the system?s capabili-
ties are handled with the help of a special
OutOfDomain-agent which informs the user of
the relevant tasks and possible topics directly.
This allows the system to deal with error sit-
uations, such as irrelevant user utterances, ef-
ficiently and flexibly without invoking the Dia-
logue Manager to evaluate appropriate dialogue
strategies. The information about error situ-
ations and the selected system action is still
available for dialogue and task goal management
through the shared Information Storage.
The utterance Topic and New Information
(Topic, NewInfo) of the relevant user utter-
ances are given by the parsing unit, and sup-
plemented with discourse knowledge by ellipsis
and anaphora resolution agents (which are In-
put Agents). Task related goals are produced by
Task Agents, located in a separate Task Man-
ager module. They also access the backend
database, the public transportation timetables
of Helsinki.
The Dialogue Manager (DM) consists of
agents corresponding to possible system actions
(Figure 3). There are also some agents for inter-
nal system interaction, illustrated in the figure
with a stack of agents labeled with Agent1. One
agent is selected at a time, and the architecture
permits us to experiment with various compet-
ing agents for the same subtask: the evaluators
are responsible for choosing the one that best
fits in the particular situation.
Figure 3: The Dialogue Manager component.
Two types of evaluators are responsible for
choosing the agent in DM, and thus implement-
ing the dialogue strategy. The QEstimate eval-
uator chooses the agent that has proven to be
most rewarding so far, according to a Q-learning
(Watkins and Dayan, 1992) algorithm with on-
line -greedy policy (Sutton and Barto, 1998).
That agent is used in the normal case and the
decision is based on the dialogue state presented
in Figure 2. The underlying structure of the
QEstimate evaluator is illustrated in Figure 4.
The evaluator is based on a table of real val-
ues, indexed by dialogue states, and updated af-
ter each dialogue. The agent with the highest
Figure 4: The QEstimate evaluator.
value for the current dialogue state gets selected.
Adaptivity of the dialogue management comes
from the reinforcement learning algorithm of
this evaluator.
On the other hand, if one of the error evalu-
ators (labeled with Error1..N) detects that an
error has occurred, the QEstimate evaluator is
overridden and a predetermined agent is selected
to handle the error situation (Figure 5). In these
cases, only the the correct agent is given a non-
zero value, forcing the dialogue manager to se-
lect that agent. Examples of such errors include
situations when the user utterance is not recog-
nized by the speech recognizer, its topic is irrele-
vant to the current domain, or its interpretation
is inconsistent with the dialogue context.
Figure 5: An error evaluator.
Because all possible system actions are
reusable agents, we can easily implement a dif-
ferent dialogue management strategy by adding
evaluators, or replacing the current QEstimate
evaluator. We are developing another strategy
based on recurrent self-organizing maps, that
learns to map dialogue states to correct actions
by fuzzy clustering, minimizing the amount of
human labor in designing the dialogue strategy.
6 Demo System and Future Work
The project deals with both speech and text
communication, interfacing with the user by
telephone and web-applications. An initial in-
tegrated system with basic functionality and in-
teraction capabilities concerning bus timetable
inquiries has been built. Sample interactions are
given in Figures 6 and 7. Various other appli-
cation types such as intelligent question-answer
systems, automatic call-centers, and other ser-
vices that would benefit from flexible natural
interaction can also be envisaged.
The current system is the first prototype and
intended to provide useful basis for further ex-
perimentation and system development. The
planned activities include further investigations
of the limitations and advantages of various ap-
proaches for language technology, as well as us-
ability studies concerning real users and users
with special needs.
(1) UT: mmilla?s bussilla ma? pa?a?sen malamille
?with which bus do I get to Malami?
UR: milla? bussilla pa?a?sen malmille
?with which bus do I get to Malmi?
SU: mista? olittekaan la?hdo?ssa? malmille
?where do you want to leave for Malmi?
UT: no hakaniemesta?
?well from Hakaniemi?
UR: hakaniemesta?
?from Hakaniemi?
SU: bussi 70 la?htee sielta? malmille
?bus 70 leaves from there to Malmi?
UT: selva? kiitos hei
?ok thank you bye?
UR: bussi kiitos hei
?bus thank you bye?
SU: kiitos hei
?thank you bye?
Figure 6: Sample dialogue with low recognition
score for the destination Malmille ?to Malmi?
(UT = Utterance as actually made by the user,
UR = Utterance as recognized by the system,
SU = System utterance).
(2) UT: koskas mennee seuraava pussi arapi-
asta malmille
?when will the next bus go from Arapia to
Malmi?
UR: koska menee seuraava bussi arabiasta
malmille
?when will the next bus go from Arabia to
Malmi?
SU: kello 14 30
?at 14:30?
UT: minka? numeroinen se on
?which number is it?
UR: mina? nelonen selva?
?I four okay?
SU: olen pahoillani osaan vastata vain
bussiaikatauluja koskeviin kysymyksiin
?sorry I can reply only to questions con-
cerning bus timetables?
UT: aha no joo jaa kiitos hei
?I see ok thank you bye?
UR: onko aijaa kiitos hei
?is I see thank you bye?
SU: kiitos hei
?thank you bye?
Figure 7: Sample dialogue with misrecognition
of user utterance minka? numeroinen se on
(UT = Utterance as actually made by the user,
UR = Utterance as recognized by the system,
SU = System utterance).
7 Acknowledgements
The research is carried out in the context of the
USIX Interact project, a collaboration project
between four Finnish universities, and funded
by the National Technology Agency, the leading
IT companies ICL Invia oyj, Sonera oyj, Ling-
soft oy, and Gurusoft oy, as well as the Finnish
Association for the Deaf and the Arla Institute.
References
J. Allwood, D. Traum, and K. Jokinen. 2000. Coop-
eration, dialogue and ethics. International Jour-
nal of Human-Computer Studies, 53:871?914.
L. Carlson. 2001. CPARSE manual. http://www
.ling.helsinki.fi/ lcarlson/cparse09en.html.
T. Jauhiainen. 2001. Using existing written lan-
guage analyzers in understanding natural spoken
Finnish. In Proceedings of Nodalida ?01, Uppsala.
K. Jokinen and G. Wilcock. 2001. Confidence-based
adaptivity in response generation for a spoken di-
alogue system. In Proceedings of the 2nd SIGdial
Workshop on Discourse and Dialogue, pages 80?
89, Aarhus.
K. Jokinen, T. Hurtig, K. Hynna?, K. Kanto,
M. Kaipainen, and A. Kerminen. 2001. Self-
organizing dialogue management. In Proceedings
of the 2nd Workshop on Natural Language Pro-
cessing and Neural Networks, pages 77?84, Tokyo.
K. Jokinen. 1996. Goal formulation based on com-
municative principles. In Proceedings of the 16th
COLING, pages 598?603.
F. Karlsson. 1983. Suomen kielen a?a?nne- ja muoto-
rakenne. WSOY, Juva.
T. Kohonen, S. Kaski, K. Lagus, J. Saloja?rvi,
V. Paatero, and A. Saarela. 2000. Organization
of a massive document collection. IEEE Transac-
tions on Neural Networks, Special Issue on Neural
Networks for Data Mining and Knowledge Discov-
ery, 11(3):574?585, May.
T. Kohonen. 1995. Self-Organizing Maps. Springer,
Berlin.
K. Koskenniemi. 1983. Two-level morphology: a
general computational model for word-form recog-
nition and production. University of Helsinki,
Helsinki.
K. Lagus and J. Kuusisto. 2002. Topic identifica-
tion in natural language dialogues using neural
networks. In Proceedings of the 3rd SIGdial Work-
shop on Discourse and Dialogue, Philadelphia.
S. Seneff, E. Hurley, R. Lau, C. Pao, P. Schmid, and
V. Zue. 1998. Galaxy-II: A reference architecture
for conversational system development. In Pro-
ceedings of ICSLP-98, Sydney.
R. Sutton and A. Barto. 1998. Reinforcement Learn-
ing: An Introduction. MIT Press, Cambridge,
Massachusetts.
M. Turunen and J. Hakulinen. 2000. Jaspis - a
framework for multilingual adaptive speech appli-
cations. In Proceedings of the 6th International
Conference on Spoken Language Processing, Bei-
jing.
M. Turunen and J. Hakulinen. 2001a. Agent-based
adaptive interaction and dialogue management ar-
chitecture for speech applications. In Text, Speech
and Dialogue. Proceedings of the Fourth Interna-
tional Conference (TSD-2001), pages 357?364.
M. Turunen and J. Hakulinen. 2001b. Agent-based
error handling in spoken dialogue systems. In Pro-
ceedings of Eurospeech 2001, pages 2189?2192.
M. Vainio. 2001. Artificial Neural Network Based
Prosody Models for Finnish Text-to-Speech Syn-
thesis. Ph.D. thesis, University of Helsinki.
C. Watkins and P. Dayan. 1992. Technical note:
Q-learning. Machine Learning, 8:279?292.
G. Wilcock. 2001. Pipelines, templates and transfor-
mations: XML for natural language generation. In
Proceedings of the 1st NLP and XML Workshop,
pages 1?8, Tokyo.
