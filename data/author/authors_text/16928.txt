Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 530?540, Dublin, Ireland, August 23-29 2014.
Jointly or Separately: Which is Better for
Parsing Heterogeneous Dependencies?
Meishan Zhang
?
, Wanxiang Che
?
, Yanqiu Shao
?
, Ting Liu
??
?
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{mszhang, car, tliu}@ir.hit.edu.cn
?
Beijing Language and Culture University
yqshao163@163.com
Abstract
For languages such as English, several constituent-to-dependency conversion schemes are pro-
posed to construct corpora for dependency parsing. It is hard to determine which scheme is
better because they reflect different views of dependency analysis. We usually obtain dependen-
cy parsers of different schemes by training with the specific corpus separately. It neglects the
correlations between these schemes, which can potentially benefit the parsers. In this paper, we
study how these correlations influence final dependency parsing performances, by proposing a
joint model which can make full use of the correlations between heterogeneous dependencies,
and finally we can answer the following question: parsing heterogeneous dependencies jointly
or separately, which is better? We conduct experiments with two different schemes on the Penn
Treebank and the Chinese Penn Treebank respectively, arriving at the same conclusion that joint-
ly parsing heterogeneous dependencies can give improved performances for both schemes over
the individual models.
1 Introduction
Dependency parsing has been intensively studied in recent years (McDonald et al., 2005; Nivre, 2008;
Zhang and Clark, 2008; Huang et al., 2009; Koo and Collins, 2010; Zhang and Nivre, 2011; Sartorio et
al., 2013; Choi and McCallum, 2013; Martins et al., 2013). Widely-used corpus for training a dependen-
cy parser is usually constructed according to a specific constituent-to-dependency conversion scheme.
Several conversion schemes for certain languages have been available. For example, the English lan-
guage has at least four schemes based on the Penn Treebank (PTB), including the Yamada scheme (Ya-
mada and Matsumoto, 2003), the CoNLL 2007 scheme (Nilsson et al., 2007), the Stanford scheme
(de Marneffe and Manning, 2008) and the LTH scheme (Johansson and Nugues, 2007). There are dif-
ferent conversion schemes for the Chinese Penn Treebank (CTB) as well, including the Zhang scheme
(Zhang and Clark, 2008) and the Stanford scheme (de Marneffe and Manning, 2008). It is hard to
judge which scheme is more superior, because each scheme reflects a specific view of dependency analy-
sis, and also there is another fact that different natural language processing (NLP) applications can prefer
different conversion schemes (Elming et al., 2013).
Traditionally, we get dependency parsers of different schemes by training with the specific corpus
separately. The method neglects the correlations between these schemes, which can potentially help
different dependency parsers. On the one hand, there are many consistent dependencies across heteroge-
neous dependency trees. Some dependency structures remain constant in different conversion schemes.
Taking the Yamada and the Stanford schemes as an example, overall 70.27% of the dependencies are
identical (ignoring the dependency labels), according to our experimental analysis. We show a concrete
example for the two heterogeneous dependency trees in Figure 1, where six of the twelve dependencies
are consistent in the two dependency trees (shown by the solid arcs).
On the other hand, differences between heterogeneous dependencies can possibly boost the ev-
idences of the consistent dependencies. For example in Figure 1, the dependencies ?do
VC
xthink?
?
Corresponding author.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
530
We do n?t think at this point anything need to be said
SUB
ROOT
VMOD
VC
VMOD NMOD
PMOD
SUB
VMOD
VMOD
VMOD
VC
nsubj
aux
neg
root
prep det
pobj
nsubj
ccomp
aux
auxpass
xcomp
Figure 1: An example to show the differences and similarities of two dependency schemes. The above
dependency tree is based on the Yamada scheme, while the below dependency tree is based on the
Stanford scheme. The solid arcs show the consistent dependencies between the two dependency
trees, while the dashed arcs show the differences between the two trees.
and ?We
nsubj
x think? from the two trees can both be potential evidences to support the dependency
?thinkyat?. Another example, the label ?PMOD? from the Yamada scheme and the label ?pobj? from
the Stanford scheme on a same dependency ?atypoint? can make it more reliable than one alone.
In this paper, we investigate the influences of the correlations between different dependency schemes
on parsing performances. We propose a joint model to parse heterogeneous dependencies from two
schemes simultaneously, so that the correlations can be fully used by their interactions in a single model.
Joint models have been widely studied to enhance multiple tasks in NLP community, including joint
word segmentation and POS-tagging (Jiang et al., 2008; Kruengkrai et al., 2009; Zhang and Clark,
2010), joint POS-tagging and dependency parsing (Li et al., 2011; Hatori et al., 2011), and the joint word
segmentation, POS-tagging and dependency parsing (Hatori et al., 2012). These models are proposed
over pipelined tasks. We apply the joint model into parallel tasks, and parse heterogeneous dependencies
together. To our knowledge, we are the first work to investigate joint models on parallel tasks.
We exploit a transition-based framework with global learning and beam-search decoding to imple-
ment the joint model (Zhang and Clark, 2011). The joint model is extended from a state-of-the-art
transition-based dependency parsing model. We conduct experiments on PTB with the Yamada and the
Stanford schemes, and also on CTB 5.1 with the Zhang and the Stanford schemes. The results
show that our joint model gives improved performances over the individual baseline models for both
schemes on both English and Chinese languages, demonstrating positive effects of the correlations be-
tween the two schemes. We make the source code freely available at http://sourceforge.net/
projects/zpar/,version0.7.
2 Baseline
Traditionally, the dependency parsers of different schemes are trained with their corpus separately, using
a state-of-the-art dependency parsing algorithm (Zhang and Clark, 2008; Huang et al., 2009; Koo and
Collins, 2010; Zhang and McDonald, 2012; Choi and McCallum, 2013). In this work, we exploit a
transition-based arc-standard dependency parsing model combined with global learning and beam-search
decoding as the baseline. which is initially proposed by Huang et al. (2009). In the following, we give a
detailed description of the model.
In a typical transition-based system for dependency parsing, we define a transition state, which consists
of a stack to save partial-parsed trees and a queue to save unprocessed words. The parsing is performed
incrementally via a set of transition actions. The transition actions are used to change contents of the
stack and the queue in a transition state. Initially, a start state has an empty stack and all words of a
sentence in its queue. Then transition actions are applied to the start state, and change states step by step.
Finally, we arrive at an end state with only one parsed tree on the stack and no words in the queue. We
score each state by its features generated from the historical actions.
531
S1
? ? ?
? ? ?
S
0
? ? ?
S
AR(l)
AL(l)
P
R
Q
0
Q
1
? ? ?
Q
SH
(a) Arc-standard dependency parsing model for a single dependency tree
S
a
1
? ? ?
? ? ?
S
a
0
? ? ?
S
a
AR
a
(l)
AL
a
(l)
P
R
a
Q
a
0
Q
a
1
? ? ?
Q
a
SH
a
S
b
1
? ? ?
? ? ?
S
b
0
? ? ?
S
b
AR
b
(l)
AL
b
(l)
P
R
b
Q
b
0
Q
b
1
? ? ?
Q
b
SH
b
G
u
i
d
e
d
a
G
u
i
d
e
d
b
(b) The joint model based on arc-standard dependency parsing for two dependency trees
Figure 2: Illustrations for the baseline dependency parsing model and our proposed joint model.
In the baseline arc-standard transition system, we define four kinds of actions, as shown in Figure 2(a).
They are shift (SH), arc-left with dependency label l (AL(l)), arc-right with dependency label l (AR(l))
and pop-root (PR), respectively. The shift action shifts the first element Q
0
of the queue onto the stack;
the action arc-left with dependency label l builds a left arc between the top element S
0
and the second
top element S
1
on the stack, with the dependency label being specified by l; the action arc-right with
dependency label l builds a right arc between the top element S
0
and the second top element S
1
on the
stack, with the dependency label being specified by l; and the pop-root action defines the root node of a
dependency tree when there is only one element on the stack and no element in the queue.
During decoding, each state may have several actions. We employ a fixed beam to reduce the search
space. The low-score states are pruned from the beam when it is full. The feature templates in our
baseline are shown by Table 1, referring to baseline feature templates. We learn the feature weights by
the averaged percepron algorithm with early-update (Collins and Roark, 2004; Zhang and Clark, 2011).
3 The Proposed Joint Model
The aforementioned baseline model can only handle a single dependency tree. In order to parse multiple
dependency trees for a sentence, we usually use individual dependency parsers. This method is not
able to exploit the correlations across different dependency schemes. The joint model to parse multiple
dependency trees with a single model is an elegant way to exploit these correlations fully. Inspired by
this, we make a novel extension to the baseline arc-standard transition system, arriving at a joint model
to parse two heterogeneous dependency trees for a sentence simultaneously.
In the new transition system, we double the original transition state of one stack and one queue into
two stacks and two queues, as shown by Figure 2(b). We use stacks S
a
and S
b
and queues Q
a
and Q
b
to save partial-parsed dependency trees and unprocessed words for two schemes a and b, respectively.
Similarly, the transition actions are doubled as well. We have eight transition actions, where four of them
are aimed for scheme a, and the other four are aimed for scheme b. The concrete action definitions are
similar to the original actions, except an additional constraint that actions should be operated over the
corresponding stack and queue of scheme a or b.
We assume that the actions to build a specific tree of scheme a are A
a
1
A
a
2
? ? ?A
a
n
, and the actions to
532
Baseline feature templates
Unigram features
S
0
w S
0
t S
0
wt S
1
w S
1
t S
1
wt N
0
w N
0
t N
0
wt N
1
w N
1
t N
1
wt
Bigram features
S
0
w?S
1
w S
0
w?S
1
t S
0
t?S
1
w S
0
t?S
1
t S
0
w?N
0
w S
0
w?N
0
t S
0
t?N
0
w S
0
t?N
0
t
Second-order features
S
0l
w S
0r
w S
0l
t S
0r
t S
0l
l S
0r
l S
1l
w S
1r
w S
1l
t S
1r
t S
1l
l S
1r
l
S
0l2
w S
0r2
w S
0l2
t S
0r2
t S
0l2
l2 S
0r2
l2 S
1l2
w S
1r2
w S
1l2
t S
1r2
t S
1l2
l2 S
1r2
l2
Third-order features
S
0
t?S
0l
t?S
0l2
t S
0
t?S
0r
t?S
0r2
t S
1
t?S
1l
t?S
1l2
t S
1
t?S
1r
t?S
1r2
t
S
0
t?S
1
t?S
0l
t S
0
t?S
1
t?S
0l2
t S
0
t?S
1
t?S
0r
t S
0
t?S
1
t?S
0r2
t
S
0
t?S
1
t?S
1l
t S
0
t?S
1
t?S
1l2
t S
0
t?S
1
t?S
1r
t S
0
t?S
1
t?S
1r2
t
Valancy features
S
0
wv
l
S
0
tv
l
S
0
wv
r
S
0
tv
r
S
1
wv
l
S
1
tv
l
S
1
wv
r
S
1
tv
r
Label set features
S
0
ws
r
S
0
ts
r
S
0
ws
l
S
0
ts
l
S
1
ws
l
S
1
ts
l
Proposed new feature templates for the joint model
Guided head features
S
0
w?h
guide
S
0
t?h
guide
S
0
wt?h
guide
S
1
w?h
guide
S
1
t?h
guide
h
guide
Guided label features
S
0
w?S
0
l
guide
S
0
t?S
0
l
guide
S
0
wt?S
0
l
guide
S
1
w?S
0
l
guide
S
1
t?S
0
l
guide
S
0
l
guide
S
0
w?S
1
l
guide
S
0
t?S
1
l
guide
S
0
wt?S
1
l
guide
S
1
w?S
1
l
guide
S
1
t?S
1
l
guide
S
1
l
guide
Table 1: Feature templates for the baseline and joint models, where w denotes the word; t denotes the
POS tag; v
l
and v
r
denote the left and right valencies; l denotes the dependency label; s
l
and s
r
denotes
the label sets of the left and right children; the subscripts l and r denote the left-most and the right-most
children, respectively; the subscripts l2 and r2 denote the second left-most and the second right-most
children, respectively; h
guide
denotes the head direction of the top two elements on the processing stack
in the other tree; l
guide
denotes the label of the same word in the other tree.
build a specific tree of scheme b for the same sentence are A
b
1
A
b
2
? ? ?A
b
n
. We use ST
a
0
ST
a
1
? ? ? ST
a
n
and
ST
b
0
ST
b
1
? ? ? ST
b
n
to denote the historical states for the two action sequences, respectively. A sequence of
actions should consist of A
a
1
A
a
2
? ? ?A
a
n
and A
b
1
A
b
2
? ? ?A
b
n
in a joint model. However, one question that
needs to be answered is that, for a joint state (ST
a
i
,ST
b
j
), which action should be chosen as the next step
to merge the two action sequences into one sequence, A
a
i+1
or A
b
j+1
? To resolve the problem, we employ
a parameter t to limit the next action in the joint model. When t is above zero, an action for scheme b
can be applied only if the last action of scheme a is t steps in advance. For example, the action sequence
is A
a
1
A
b
1
A
a
2
A
b
2
? ? ?A
a
n
A
b
n
when t = 1. t can be negative as well, denoting the reverse constraints.
In the joint model, we extract features separately for the two dependency schemes. When the next
action is aimed for scheme a, we will extract features from S
a
and Q
a
, according to baseline feature
templates in Table 1. In order to make use of the correlations between the two dependency parsing trees,
we introduce several new feature templates, shown in Table 1 referring to proposed new feature templates
for the joint model. The new features are based on two kinds of atomic features: the guided head h
guide
and the guided dependency label l
guide
. Assuming that the currently processing scheme is a, when the
top two elements (S
a
0
and S
a
1
) have both found their heads in Guided
b
(the partial-parsed trees of scheme
b), we can fire the atomic feature h
guide
, which denotes the arc direction between S
0
and S
1
in Guide
b
(S
x
0
S
1
, S
y
0
S
1
or other). When S
a
0
or S
a
1
has its dependency label in Guided
b
, we can fire the atomic
feature l
guide
, which denotes the dependency label of S
a
0
or S
a
1
in Guided
b
. Similarly we can extract the
h
guide
and l
guide
from Guide
a
when we are processing scheme b. When t is infinite, we always have
533
the two atomic features, because the other tree is already parsed. Thus the proposed new features can be
the most effective when t = ? and t = ??. In other conditions, the other tree may not be ready for
the new feature extracting. Similar to the baseline model, we use the beam-search decoding strategy to
reduce the search space, and use the averaged perceptron with early-update to learn the feature weights.
We are especially interested in two cases of the joint models when t is infinite (t =? and t = ??),
where the tree of one specified scheme is always processed after the other tree is finished, because the
new features can be most effectively exploited according to the above analysis. We assume that the first
and second processing schemes are s
1
and s
2
respectively, to facilitate the below descriptions. We can see
that the joint model behaves similarly to a pipeline reranking model, in optimizing scheme s
1
?s parsing
performances. First we get K-best (K equals the beam size of the joint model) candidates for scheme s
1
,
and then employ additional evidences from scheme s
2
?s result, to rerank the K-best candidates, obtaining
a better result. The joint model also behaves similarly to a pipeline feature-based stacking model (Li et
al., 2012), in optimizing scheme s
2
?s parsing performances. After acquiring the best result of scheme
s
1
, we can use it to generate guided features to parse dependencies of scheme s
2
. Thus additional
information from scheme s
1
can be imported into the parsing model of scheme s
2
. Different with the
pipeline reranking and the feature-based stacking models, we employ a single model to achieve the two
goals, making the interactions between the two schemes be better performed.
4 Experiments
4.1 Experimental Settings
In order to evaluate the baseline and joint models, we conduct experiments on English and Chinese da-
ta. For English, we obtain heterogeneous dependencies by the Yamada and the Stanford schemes,
respectively. We transform the bracket constituent trees of English sentences into the Yamada dependen-
cies with the Penn2Malt tool,
1
and into the Stanford dependencies with the Stanford parser version
3.3.1.
2
Following the standard splitting of PTB, we use sections 2-21 as the training data set, section 22 as
the development data set, and section 23 as the final test data set. For Chinese, we obtain heterogeneous
dependencies by the Zhang and the Stanford schemes, respectively. The Zhang dependencies are
obtained by the Penn2Malt tool using the head rules from Zhang and Clark (2008), while the Stanford
dependencies are obtained by the Stanford parser version 3.3.1 similar to English.
We use predicted POS tags in all the experiments. We utilize a linear-CRF POS tagger to obtain
automatic POS tags for English and Chinese datasets.
3
We use a beam size of 64 to train dependency
parsing models. We train the joint models with the Yamada or Zhang dependencies being handled
on stack S
a
and queue Q
a
, and the Stanford dependencies being handled on stack S
b
and queue Q
b
,
referring to Section 3. We follow the standard measures of dependency parsing to evaluate the baseline
and joint models, including unlabeled attachment score (UAS), labeled attachment score (LAS) and
complete match (CM). We ignore the punctuation words for all these measures.
4.2 Development Results
4.2.1 Baseline
Table 2 at the subtable ?Baseline? shows the baseline results on the development data set. The perfor-
mances of the Yamada scheme are better than those of the Stanford scheme. The UAS and LAS of
the Yamada scheme are 92.83 and 91.73 respectively, while they are 92.85 and 90.49 for the Stanford
scheme respectively. The results demonstrate that parsing the Stanford dependencies is more difficult
than parsing the Yamada dependencies because of the lower performances of the Stanford scheme.
1
http://stp.lingfil.uu.se/
?
nivre/research/Penn2Malt.html.
2
The tool is available on http://nlp.stanford.edu/software/lex-parser.shtml. We use three options to
perform the conversion: ?-basic? and ?-keepPunct?, respectively.
3
The tagging accuracies are 97.30% on the English test dataset and 93.68% on the Chinese test dataset. We thank Hao
Zhang for sharing the data used in Martins et al. (2013) and Zhang et al. (2013a).
534
Model
Yamada Stanford
UAS LAS CM UAS LAS CM
Baseline 92.83 91.73 47.35 92.85 90.49 50.06
The joint models,
where the Yamada dependencies are processed with priority
t = 1 92.65 91.55 46.35 93.11 90.75 50.24
t = 2 92.65 91.57 46.71 93.15 90.77 50.59
t = 3 92.82 91.74 47.12 93.19 90.82 50.76
t = 4 92.89 91.78 47.35 93.27 90.93 51.29
t =? 93.04 92.01 48.65 93.52 91.15 52.59
The joint models,
where the Stanford dependencies are processed with priority
t = ?1 92.62 91.54 46.71 93.10 90.70 50.76
t = ?2 92.50 91.41 46.18 93.06 90.74 51.12
t = ?3 92.57 91.42 47.00 93.10 90.68 51.35
t = ?4 92.74 91.60 47.41 93.15 90.72 51.29
t = ?? 93.04 91.95 47.88 93.19 90.91 50.71
Table 2: The main results on the development data set of the baseline and proposed joint models.
4.2.2 Parameter Tuning
The proposed joint model has one parameter t to adjust. The parameter t is used to control the decoding in
a joint model, determining which kind of dependencies should be processed at the next step. In our joint
model, if t is larger than zero, scheme a (the Yamada scheme) should be handled t steps in advance,
while when t is smaller than zero, scheme b (the Stanford scheme) should be handled in advance.
When the value of t is infinite, the dependency tree of one scheme is handled until the dependency tree
of the other scheme is finished for a sentence.
As shown by Table 2, we have two major findings. First, the joint models are slightly better when t is
above zero, by decoding with the Yamada scheme in advance. The phenomenon demonstrates that the
decoding sequence is important in the joint parsing models. Second, no matter when t is above or below
zero, the performances arrive at the peak when t is infinite. One benefit of the joint models is that we
can use the correlations between different dependency trees, through the new features proposed by us.
The new features can be the most effective when t is infinite according to the analysis Section 3. Thus
this finding indicates that the new features are crucial in the joint models, since the ineffective utilization
would decrease the model performances a lot. Actually, when the absolute value of t is small, the features
can sometimes be fired and in some other times are not able to be fired, making the training insufficient
and also inconsistent for certain word-pair dependencies when their distances can differ (when t = 1 for
example, the joint model can fire the new features only if the dependency distance equals 1). This would
make the final model deficient, and can even hurt performances of the Yamada scheme.
According to the results on the development data set, we use the t = ? for the final joint model,
which first finishes the Yamada tree and then the Stanford tree for each sentence. Our final model
achieves increases of 0.21 on UAS and 0.28 on LAS for the Yamada scheme, and increases 0.67 on
UAS and 0.66 on LAS for the Stanford scheme.
4.2.3 Feature Ablation
In order to test the effectiveness of the proposed new features, we conduct a feature ablation experiment.
Table 3 shows the results, where the mark ?/wo? denotes the model without the new features proposed
by us. For the Yamada scheme, losses of 0.15 on UAS and 0.21 on LAS are shown without the new
features. While for Stanford scheme, larger decreases are shown by 0.57 on UAS and 0.58 on LAS,
respectively. The results demonstrate the new features are effective in the joint model.
535
Model
Yamada Stanford
UAS LAS CM UAS LAS CM
Our joint model 93.04 92.01 48.65 93.52 91.15 52.59
Our joint model/wo 92.89 91.80 48.25 92.95 90.57 50.62
? -0.15 -0.21 -0.40 -0.57 -0.58 -1.97
Table 3: Feature ablation results.
Model
Yamada Stanford
UAS LAS CM UAS LAS CM
Baseline 92.71 91.67 47.48 92.72 90.61 47.76
Our joint model 92.89 91.86 48.39 93.30
?
91.19
?
50.37
Zhang and Nivre (2011) 92.9 91.8 48.0 ? ? ?
Rush and Petrov (2012) ? ? ? 92.7
?
? ?
Martins et al. (2013) 93.07 ? ? 92.82
?
? ?
Zhang et al. (2013a) 93.50 92.41 ? 93.64
?
91.28
?
?
Zhang and McDonald (2014) 93.57 92.48 ? 93.71
?
/93.01
??
91.37
?
/90.64
??
?
Kong and Smith (2014) ? ? ? 92.20
??
89.67
??
?
Table 4: The final results on the test data set, where the results with mark
?
demonstrates that the p-value
is below 10
?3
using t-test. Our Stanford dependencies are slightly different with previous works, where
the results with mark
?
show the numbers for the Stanford dependencies from Stanford parser version
2.0.5 and the results with mark
??
show the numbers for the Stanford dependencies from Stanford parser
version 3.3.0.
4.3 Final Results
Table 4 shows our final results on the English test dataset. The final joint model achieves better per-
formances than the baseline models for both the Yamada and the Stanford schemes, by increases
of 0.18 on UAS and 0.19 on LAS for the Yamada scheme, and increases of 0.58 on UAS and 0.58
on LAS for the Stanford scheme. The results demonstrate that the interactions between the two de-
pendency schemes are useful, and the joint model is superior to separately trained models in handling
heterogeneous dependencies.
We compare our results with some representative previous work of dependency parsing as well. Zhang
and Nivre (2011) is a feature-rich transition-based dependency parser using the arc-eager transition sys-
tem. Rush and Petrov (2012), Zhang et al. (2013a) and Zhang and McDonald (2014) are state-of-the-art
graph-based dependency parsers. Martins et al. (2013) and Kong and Smith (2014) report their results
with the full TurboParser. TurboParser is also a graph-based dependency parser but its decoding algo-
rithm has major differences with the general MST-style decoding.
4.4 Analysis
To better understand the joint model, we conduct analysis work on the Chinese development dataset.
First, we make a comparison to see whether the consistent dependencies give larger increases by the
joint model. As mentioned before, the consistent dependencies can be supported by different evidences
from heterogeneous dependencies. We compute the proportion of the consistent dependencies (ignoring
the dependency labels) between the Yamada and the Stanford dependencies, finding that 70.27% of
the overall dependencies are consistent. Table 5 shows the comparison results. The joint model shows
improvements for the consistent dependencies. However, it does not always show positive effectiveness
for the inconsistent dependencies. The results support our initial motivation that consistent dependencies
can benefit much in joint models .
We also make a comparison between the baseline and joint models with respect to dependency dis-
tance. We use the F-measure value to evaluate the performances. The dependency distances are normal-
536
Yamada Stanford
Consistent Inconsistent Consistent Inconsistent
UAS LAS UAS LAS UAS LAS UAS LAS
Baseline 93.43 92.39 91.44 90.17 93.74 91.35 90.75 88.47
Our joint model 93.81 92.85 91.21 90.02 94.58 92.15 91.01 88.78
? +0.38 +0.46 -0.23 -0.15 +0.84 +0.80 +0.36 +0.31
Table 5: Performances of the baseline and joint models by whether the dependencies are consistent
across the Yamada and the Stanford schemes, where the bold numbers denote the larger increases by
comparisons of consistent and inconsistent dependencies for each scheme.
1 2 3 4 5 6 7
75
80
85
90
95
F
-
m
e
a
s
u
r
e
(
%
)
Baseline Joint
(a) Yamada
1 2 3 4 5 6 7
65
75
85
95
F
-
m
e
a
s
u
r
e
(
%
)
Baseline Joint
(b) Stanford
Figure 3: F-measures of the two heterogeneous dependencies with respect to dependency distance.
ized to a max value of 7. Figure 3 shows the comparison results. We find that the joint model can achieve
consistent better performances for the dependencies of different dependency distance, demonstrating the
robustness of the joint model in improving parsing performances. The joint model performs slightly
better for long-distance dependencies, which is more obvious for the Stanford scheme.
4.5 Parsing Heterogeneous Chinese Dependencies
Table 6 shows our final results on the Chinese test data set. For Chinese, the joint model achieves better
performances with Stanford dependencies being parsed first. The final joint model achieves better
performances than the baseline models for both the Zhang and the Stanford schemes, by increases
of 1.13 on UAS and 0.99 on LAS for the Zhang scheme, and increases of 0.30 on UAS and 0.36 on
LAS for the Stanford scheme. The results also demonstrate similar conclusions with the experiments
on English dataset.
5 Related Work
Our work is mainly inspired by the work of joint models. There are a number of successful studies
on joint modeling pipelined tasks where one task is a prerequisite step of another task, for example,
the joint model of word segmentation and POS-tagging (Jiang et al., 2008; Kruengkrai et al., 2009;
Zhang and Clark, 2010), the joint model of POS-tagging and parsing (Li et al., 2011; Hatori et al., 2011;
Bohnet and Nivre, 2012), the joint model of word segmentation, POS-tagging and parsing (Hatori et
Model
Zhang Stanford
UAS LAS CM UAS LAS CM
Baseline 79.07 76.08 27.96 80.33 75.29 31.14
Our joint model 80.20
?
77.07
?
30.10 80.63 75.65 31.20
Table 6: The final results on the test data set, where the results with mark
?
demonstrates that the p-value
is below 10
?3
using t-test.
537
al., 2012; Zhang et al., 2013b; Zhang et al., 2014), and the joint model of morphological and syntactic
analysis tasks (Bohnet et al., 2013). In our work, we propose a joint model on parallel tasks, to parse two
heterogeneous dependency trees simultaneously.
There has been a line of work on exploiting multiple treebanks with heterogeneous dependencies to
enhance dependency parsing. Li et al. (2012) proposed a feature-based stacking model to enhance a
specific target dependency parser with the help of another treebank. Zhou and Zhao (2013) presented
a joint inference framework to combine the parsing results based on two different treebanks. All these
work are case studies of annotation adaptation from different sources, which have been done for Chinese
word segmentation and POS-tagging as well (Jiang et al., 2009; Sun and Wan, 2012). In contrast to their
work, we study the heterogeneous annotations derived from the same source. We use a unified model to
parsing heterogeneous dependencies together.
Our joint parsing model exploits a transition-based framework with global learning and beam-search
decoding (Zhang and Clark, 2011), extended from a arc-standard transition-based parsing model (Huang
et al., 2009). The transition-based framework is easily adapted to a number of joint models, including
joint word segmentation and POS-tagging (Zhang and Clark, 2010), the joint POS-tagging and parsing
(Hatori et al., 2012; Bohnet and Nivre, 2012), and also joint word segmentation, POS-tagging and parsing
(Hatori et al., 2012; Zhang et al., 2013b; Zhang et al., 2014).
6 Conclusions
We studied the effectiveness of the correlations between different constituent-to-dependency schemes
for dependency parsing, by exploiting these information with a joint model to parse two heterogeneous
dependency trees simultaneously. We make a novel extension to a transition-based arc-standard depen-
dency parsing algorithm for the joint model. We evaluate our baseline and joint models on both English
and Chinese datasets, based on the Yamada/Zhang and the Stanford dependency schemes. Final
results demonstrate that the joint model which handles two heterogeneous dependencies can give im-
proved performances for dependencies of both schemes. The source code for the joint model is publicly
available at http://sourceforge.net/projects/zpar/,version0.7.
Acknowledgments
We thank Yue Zhang and the anonymous reviewers for their constructive comments, and grateful-
ly acknowledge the support of the National Basic Research Program (973 Program) of China via
Grant 2014CB340503, the National Natural Science Foundation of China (NSFC) via Grant 61133012,
61170144 and 61370164.
References
Bernd Bohnet and Joakim Nivre. 2012. A transition-based system for joint part-of-speech tagging and labeled
non-projective dependency parsing. In Proceedings of the EMNLP-CONLL, pages 1455?1465, Jeju Island,
Korea, July.
Bernd Bohnet, Joakim Nivre, Igor Boguslavsky, Rich?ard Farkas Filip Ginter, and Jan Hajic. 2013. Joint morpho-
logical and syntactic analysis for richly inflected languages. TACL, 1.
Jinho D. Choi and Andrew McCallum. 2013. Transition-based dependency parsing with selectional branching. In
Proceedings of ACL, pages 1052?1062, August.
Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of the
ACL, pages 111?118, Barcelona, Spain, July.
Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representa-
tion. In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,
pages 1?8, Manchester, UK, August.
Jakob Elming, Anders Johannsen, Sigrid Klerke, Emanuele Lapponi, Hector Martinez Alonso, and Anders
S?gaard. 2013. Down-stream effects of tree-to-dependency conversions. In Proceedings of the NAACL, pages
617?626, Atlanta, Georgia, June.
538
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii. 2011. Incremental joint POS tagging and
dependency parsing in Chinese. In Proceedings of 5th IJCNLP, pages 1216?1224, Chiang Mai, Thailand,
November.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii. 2012. Incremental joint approach to word
segmentation, POS tagging, and dependency parsing in Chinese. In Proceedings of the 50th ACL, pages 1045?
1053, Jeju Island, Korea, July.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In
Proceedings of the EMNLP, pages 1222?1231.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?u. 2008. A cascaded linear model for joint Chinese word
segmentation and part-of-speech tagging. In Proceedings of ACL-08, pages 897?904, Columbus, Ohio, June.
Wenbin Jiang, Liang Huang, and Qun Liu. 2009. Automatic adaptation of annotation standards: Chinese word
segmentation and POS tagging: a case study. In Proceedings of the ACL-IJCNLP, pages 522?530.
Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for english. In
Proceedings of NODALIDA 2007, Tartu, Estonia.
Lingpeng Kong and Noah A Smith. 2014. An empirical comparison of parsing methods for stanford dependencies.
arXiv preprint arXiv:1404.4314.
Terry Koo and Michael Collins. 2010. Efficient third-order dependency parsers. In Proceedings of the 48th Annual
Meeting of the ACL, pages 1?11.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichi Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi Isahara.
2009. An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging. In
Proceedings of the ACL-IJCNLP, pages 513?521, Suntec, Singapore, August.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang Chen, and Haizhou Li. 2011. Joint models for
Chinese POS tagging and dependency parsing. In Proceedings of the EMNLP, pages 1180?1191, Edinburgh,
Scotland, UK., July.
Zhenghua Li, Ting Liu, and Wanxiang Che. 2012. Exploiting multiple treebanks for parsing with quasi-
synchronous grammars. In Proceedings of the 50th ACL, pages 675?684, Jeju Island, Korea, July.
Andre Martins, Miguel Almeida, and Noah A. Smith. 2013. Turning on the turbo: Fast third-order non-projective
turbo parsers. In Proceedings of the 51st ACL, pages 617?622, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency
parsers. In Proceedings of ACL, number June, pages 91?98, Morristown, NJ, USA.
Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In
Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL, pages 915?932.
Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics,
34(4):513?553.
Alexander M Rush and Slav Petrov. 2012. Vine pruning for efficient multi-pass dependency parsing. In Proceed-
ings of the NAACL, pages 498?507.
Francesco Sartorio, Giorgio Satta, and Joakim Nivre. 2013. A transition-based dependency parser using a dynamic
parsing strategy. In Proceedings of the 51st ACL, pages 135?144, Sofia, Bulgaria, August.
Weiwei Sun and Xiaojun Wan. 2012. Reducing approximation and estimation errors for Chinese lexical processing
with heterogeneous annotations. In Proceedings of the 50th ACL, pages 232?241, Jeju Island, Korea, July.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In
Proceedings of IWPT, volume 3.
Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings of EMNLP, pages 562?571, Honolulu, Hawaii, October.
Yue Zhang and Stephen Clark. 2010. A fast decoder for joint word segmentation and POS-tagging using a single
discriminative model. In Proceedings of the EMNLP, pages 843?852, Cambridge, MA, October.
539
Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search.
Computational Linguistics, 37(1):105?151.
Hao Zhang and Ryan McDonald. 2012. Generalized higher-order dependency parsing with cube pruning. In
Proceedings of the EMNLP, pages 320?331.
Hao Zhang and Ryan McDonald. 2014. Enforcing structural diversity in cube-pruned dependency parsing. In
Proceedings of ACL. Association for Computational Linguistics.
Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Pro-
ceedings of the 49th ACL, pages 188?193, Portland, Oregon, USA, June.
Hao Zhang, Liang Huang, Kai Zhao, and Ryan McDonald. 2013a. Online learning for inexact hypergraph search.
In Proceedings of the EMNLP, pages 908?913, Seattle, Washington, USA, October. Association for Computa-
tional Linguistics.
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu. 2013b. Chinese parsing exploiting characters. In
Proceedings of the 51st ACL, pages 125?134, Sofia, Bulgaria, August.
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu. 2014. Character-level Chinese Dependency Parsing.
In Proceedings of the 52st ACL.
Guangyou Zhou and Jun Zhao. 2013. Joint inference for heterogeneous dependency parsing. In Proceedings of
the 51st ACL, pages 104?109, Sofia, Bulgaria, August.
540
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 378?384,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
SemEval-2012 Task 5: Chinese Semantic Dependency Parsing
Wanxiang Che?, Meishan Zhang?, Yanqiu Shao?, Ting Liu?
?Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{car, mszhang, tliu}@ir.hit.edu.cn
?Beijing City University, China
yqshao@bcu.edu.cn
Abstract
The paper presents the SemEval-2012 Shared
Task 5: Chinese Semantic Dependency Pars-
ing. The goal of this task is to identify the de-
pendency structure of Chinese sentences from
the semantic view. We firstly introduce the
motivation of providing Chinese semantic de-
pendency parsing task, and then describe the
task in detail including data preparation, data
format, task evaluation, and so on. Over ten
thousand sentences were labeled for partici-
pants to train and evaluate their systems. At
last, we briefly describe the submitted systems
and analyze these results.
1 Introduction
Semantic analysis is a long-term goal of Natural
Language Processing, and as such, has been re-
searched for several decades. A number of tasks
for encoding semantic information have been devel-
oped over the years, such as entity type recognition
and word sense disambiguation. Recently, sentence-
level semantics ? in particular, semantic role label-
ing ? has received increasing attention. However,
some problems concerning the semantic representa-
tion method used in semantic role labeling continue
to exist (Xue and Palmer, 2005).
1. Semantic role labeling only considers
predicate-argument relations and ignores
the semantic relations between a noun and its
modifier.
2. The meaning of semantic roles is related to spe-
cial predicates. Therefore, there are infinite se-
mantic roles to be learned, as the number of
predicates is not fixed. Although the Prop-
Bank (Xue and Palmer, 2003) normalizes these
semantic roles into certain symbols, such as
Arg0-Arg5, the same symbol can have different
semantic meanings when paired with different
predicates, and thus cannot be learned well.
Semantic dependency parsing is therefore pro-
posed to solve the two problems above for Chinese.
Firstly, the proposed method analyzes all the words?
semantic roles in a sentence and specifies the con-
crete semantic relation of each word pair. After-
ward, this work analyzes and summarizes all the
possible semantic roles, obtaining over 100 of them,
and then uses these semantic roles to specify the se-
mantic relation for each word pair.
Dependency parsing (Ku?bler et al, 2009) is based
on dependency grammar. It has several advantages,
such as concise formalization, easy comprehension,
high efficiency, and so on. Dependency parsing
has been studied intensively in recent decades, with
most related work focusing on syntactic structure.
Many research papers on Chinese linguistics demon-
strate the remarkable difference between semantics
and syntax (Jin, 2001; Zhou and Zhang, 2003).
Chinese is a meaning-combined language with very
flexible syntax, and semantics are more stable than
syntax. The word is the basic unit of semantics,
and the structure and meaning of a sentence consists
mainly of a series of semantic dependencies between
individual words (Li et al, 2003). Thus, a reason-
able endeavor is to exploit dependency parsing for
semantic analysis of Chinese languages. Figure 1
shows an example of Chinese semantic dependency
parsing.
378
??International ??Monetary ??Fund ??organization ??turn down ?for ??global ??economy ??increasing ?of ??prediction
d-genetived-restrictive d-restrictive agent prep-dependd-genetive d-domain aux-depend
d-restrictivecontent
root
Figure 1: An example of Chinese Semantic Dependency Parsing.
Figure 1 shows that Chinese semantic dependency
parsing looks very similar to traditional syntax-
dominated dependency parsing. Below is a compar-
ison between the two tasks, dealing with three main
points:
1. Semantic relations are more fine-grained than
syntactic ones: the syntactic subject can either
be the agent or experiencer, and the syntactic
object can be the content, patient, possession,
and so on. On the whole, the number of seman-
tic relations is at least twice that of syntactic
relations.
2. Semantic dependency parsing builds the depen-
dency structure of a sentence in terms of se-
mantics, and the word pairs of a dependency
should have a direct semantic relation. This
criterion determines many sizeable differences
between semantics and syntax, especially in
phrases formed by ?XP+DEG?, ?XP+DEV?
and prepositional phrases. For example, in ??
? ? ??? (beautiful country), the head of
???? (beautiful) is ???? (country) in se-
mantic dependency parsing, whereas the head
is ??? (de) in syntax dependency parsing.
3. Semantic relations are independent of position.
For example, in ??? ? ??? (the air is
contaminated) and ??? ? ??? (contami-
nate the air), the patient ???? (the air) can be
before or behind a predicate ???? (contami-
nate).
The rest of the paper is organized as follows. Sec-
tion 2 gives a short overview of data annotation.
Section 3 focuses on the task description. Section
4 describes the participant systems. Section 5 com-
pares and analyzes the results. Finally, Section 6
concludes the paper.
2 Data Annotation
2.1 Corpus Section
10,068 sentences were selected from the Penn Chi-
nese Treebank 6.01 (Xue et al, 2005) (1-121, 1001-
1078, 1100-1151) as the raw corpus from which to
create the Chinese Semantic Dependency Parsing
corpus. These sentences were chosen for the anno-
tation for three reasons. First, gold syntactic depen-
dency structures can be of great help in semantic de-
pendency annotation, as syntactic dependency arcs
are often consistent with semantic ones. Second, the
semantic role labels in PropBank2 can be very use-
ful in the present annotation work. Third, the gold
word segmentation and Part-Of-Speech can be used
as the annotation input in this work.
2.2 Semantic Relations
The semantic relations in the prepared Chinese se-
mantic dependency parsing corpus came mostly
from HowNet3 (Dong and Dong, 2006), a fa-
mous Chinese semantic thesaurus. We also referred
to other sources. Aside from the relations from
HowNet, we defined two kinds of new relations: re-
verse relations and indirect relations. When a verb
modifies a noun, the relation between them is a re-
verse relation, and r-XXX is used to indicate this
kind of relation. For instance, in ???????
?? (the little boy who is playing basketball), the se-
mantic relation between the head word ???? (boy)
1http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalog\\Id=LDC2007T36
2http://verbs.colorado.edu/chinese/cpb/
3http://www.keenage.com/
379
and ??? (playing) is the r-agent. When a verbal
noun is the head word, the relation between it and
the modifier is the indirect relation j-XXX. For in-
stance, in ?????? (business management), the
head word is ???? (management) and the modifier
is ???? (business), their relation is j-patient.
Finally, we defined 84 single-level semantic re-
lations. The number of multi-level semantic rela-
tions that actually appear in the labeled corpus in
this work is 39.
Table 1 summarizes all of the semantic relations
used for annotation.
2.3 Annotation Flow
Our corpus annotation flow can be divided into the
following steps.
1. Conversion of the sentences? constituent struc-
tures into dependency structures according to
a set of rules similar with those used by the
syntactic community to find the head of a
phrase (Collins, 1999).
2. Labeling of the semantic relations for each de-
pendency relation according to another set of
rules using the functional tags in the Penn Chi-
nese Treebank and the semantic roles in the
Chinese PropBank.
3. Six human annotators are asked to check and
adjust the structure and semantic relation errors
introduced in Step 2.
The first two steps were performed automatically
using rules. A high accuracy may be achieved with
dependency structures when semantic labels are not
considered. However, accuracy declines remarkably
when the semantic label is considered. Unlabeled
Attachment Score (UAS) and Labeled Attachment
Score (LAS) can be used to evaluate the perfor-
mance of the automatic conversion. Table 2 gives
the detailed results.
UAS LAS
Conversion Result 90.53 57.38
Table 2: Accuracy after conversion from gold ProbBank.
3 Task Description
3.1 Corpus Statistics
We annotated 10,068 sentences from the Penn Chi-
nese TreeBank for Semantic Dependency Parsing,
and these sentences were divided into training, de-
velopment, and test sections. Table 3 gives the de-
tailed statistical information of the three sections.
Data Set CTB files # sent. # words.
1-10; 36-65;81-121; 8301
Training 1001-1078; 250311
1100-1119;
1126-1140
Devel 66-80; 1120-1125 534 15329
Test 11-35; 1141-1151 1233 34311
Total 1-121; 1001-1078 10068 299951
1100-1151
Table 3: Statistics of training, development and test data.
3.2 Data Format
The data format is identical to that of a syntactic de-
pendency parsing shared task. All the sentences are
in one text file, with each sentence separated by a
blank line. Each sentence consists of one or more to-
kens, and each token is represented on one line con-
sisting of 10 fields. Buchholz and Marsi (2006) pro-
vide more detailed information on the format. Fields
are separated from each other by a tab. Only five of
the 10 fields are used: token id, form, pos tagger,
head, and deprel. Head denotes the semantic depen-
dency of each word, and deprel denotes the corre-
sponding semantic relations of the dependency. In
the data, the lemma column is filled with the form
and the cpostag column with the postag. Figure 2
shows an example.
3.3 Evaluation Method
LAS, which is a method widely used in syntactic
dependency parsing, is used to evaluate the perfor-
mance of the semantic dependency parsing system.
LAS is the proportion of ?scoring? tokens assigned
to both the correct head and correct semantic depen-
dency relation. Punctuation is disregarded during
the evaluation process. UAS is another important
indicator, as it reflects the accuracy of the semantic
dependency structure.
380
Main Semantic Roles
Subject Roles agent, experiencer, causer, possessor, existent, whole, relevant
Object Roles isa, content, possession, patient, OfPart, beneficiary, contrast,
partner, basis, cause, cost, scope, concerning
Auxiliary Semantic Roles
Time Roles duration, TimeFin, TimeIni, time, TimeAdv
Location and State Roles LocationFin, LocationIni, LocationThru, StateFin, state,
StateIni, direction, distance, location
Others Verb Modifiers accompaniment, succeeding, frequency, instrument, material,
means, angle, times, sequence, sequence-p, negation, degree,
modal, emphasis, manner, aspect, comment
Attribute Roles
Direct modifiers d-genetive, d-category, d-member, d-domain, d-quantity-p, d-
quantity, d-deno-p, d-deno, d-host, d-TimePhrase, d-LocPhrase,
d-InstPhrase, d-attribute, d-restrictive, d-material, d-content, d-
sequence, d-sequence-p, qp-mod
Verb Phrase r-{Main Semantic Roles}, eg: r-agent, r-patient, r-possessor
Verb Ellipsis c-{Main Semantic Roles}, eg: c-agent, c-content, c-patient
Noun as Predication j-{Main Semantic Roles}, eg: j-agent, j-patient, j-target
Syntactic Roles and Others
Syntactic Roles s-cause, s-concession, s-condition, s-coordinate, s-or, s-
progression, s-besides, s-succession, s-purpose, s-measure, s-
abandonment, s-preference, s-summary, s-recount, s-concerning,
s-result
Others aux-depend, prep-depend, PU, ROOT
Table 1: Semantic Relations defined for Chinese Semantic Dependency Parsing.
ID FORM LEMMA CPOS PPOS FEAT HEAD REL PHEAD PREL
1 ??? ??? NR NR 2 agent
2 ? ? VV VV 0 ROOT
3 ?? ?? NR NR 4 d-genetive
4 ?? ?? NN NN 7 s-coordinate
5 ? ? CC CC 7 aux-depend
6 ?? ?? NR NR 7 d-genetive
7 ?? ?? NN NN 2 content
Figure 2: Data format of the Chinese Semantic Dependency Parsing corpus.
381
4 Participating Systems
Nine organizations were registered to participate in
the Chinese Semantic Dependency Parsing task. Fi-
nally, nine systems were received from five different
participating teams. These systems are as follows:
1. Zhou Qiaoli-1, Zhou Qiaoli-2, Zhou Qiaoli-3
These three systems propose a divide-and-
conquer strategy for semantic dependency
parsing. The Semantic Role (SR) phrases are
identified (Cai et al, 2011) and then replaced
by their head or the SR of the head. The orig-
inal sentence is thus divided into two types of
parts that can be parsed separately. The first
type is SR phrase parsing, and the second in-
volves the replacement of SR phrases with ei-
ther their head or the SR of the head. Finally,
the paper takes a graph-based parser (Li et al,
2011) as the semantic dependency parser for all
parts. These three systems differ in their phrase
identification strategies.
2. NJU-Parser-1, NJU-Parser-2
The NJU-Parser is based on the state-of-the-
art MSTParser (McDonald, 2006). NJU-Parser
applies three methods to enhance semantic de-
pendency parsing. First, sentences are split
into sub-sentences using commas and semi-
colons: (a) sentences are split using only com-
mas and semicolons, as in the primary sys-
tem, and (b) classifiers are used to determine
whether a comma or semicolon should be used
to split the sentence. Second, the last character
in a Chinese word is extracted as the lemma,
since it usually contains the main sense or se-
mantic class. Third, the multilevel-label is in-
troduced into the semantic relation, for exam-
ple, the r-{Main Semantic Roles}, with NJU-
Parser exploiting special strategies to handle it.
However, this third method does not show pos-
itive performance.
3. Zhijun Wu-1
This system extends the second-order of the
MSTParser by adding third-order features, and
then applying this model to Chinese semantic
dependency parsing. In contrast to Koo and
Collins (2010) this system does not implement
the third-order model using dynamic program-
ming, as it requires O(n4) time. It first first ob-
tained the K-best results of second-order mod-
els and then added the third-order features into
the results.
4. ICT-1
The ICT semantic dependency parser employs
a system-combining strategy to obtain the de-
pendency structure and then uses the classifier
from Le Zhang?s Maximum Entropy Model-
ing Toolkit4 to predict the semantic relation for
each dependency. The system-combining strat-
egy involves three steps:
? Parsing each sentence using Nivre?s arc
standard, Nivre?s arc eager (Nivre and
Nilsson, 2005; Nivre, 2008), and Liang?s
dynamic algorithm (Huang and Sagae,
2010);
? Combining parses given by the three
parsers into a weighted directed graph;
? Using the Chu-Liu-Edmonds algorithm to
search for the final parse for each sen-
tence.
5. Giuseppe Attardi-SVM-1-R, Giuseppe Attardi-
SVM-1-rev
We didn?t receive the system description of
these two systems.
5 Results & Analysis
LAS is the main evaluation metric in Chinese Se-
mantic Dependency Parsing, whereas UAS is the
secondary metric. Table 4 shows the results for these
two indicators in all participating systems.
As shown in Table 4, the Zhou Qiaoli-3 system
achieved the best results with LAS of 61.84. The
LAS values of top systems are very closely. We per-
formed significance tests5 for top six results. Table
5 shows the results , from which we can see that
the performances of top five results are comparative
(p > 0.1) and the rank sixth system is significantly
(p < 10?5) worse than top five results.
4http://homepages.inf.ed.ac.uk/s0450736/
maxenttoolkit.html
5http://www.cis.upenn.edu/?dbikel/
download/compare.pl
382
NJU-Parser-2 NJU-Parser-1 Zhijun Wu-1 Zhou Qiaoli-1 Zhou Qiaoli-2
Zhou Qiaoli-3 ? ? ? ? >
NJU-Parser-2 ? ? ? ? >
NJU-Parser-1 ? ? ? ? >
Zhijun Wu-1 ? ? ? ? >
Zhou Qiaoli-1 ? ? ? ? >
Table 5: Significance tests of the top five systems. ? denotes that the two systems are comparable (p > 0.1), and >
means the system of this row is significantly (p < 10?5) better than the system of this column.
System LAS UAS
Zhou Qiaoli-3 61.84 80.60
NJU-Parser-2 61.64 80.29
NJU-Parser-1 61.63 80.35
Zhijun Wu-1 61.58 80.64
Zhou Qiaoli-1 61.15 80.41
Zhou Qiaoli-2 57.55 78.55
ICT-1 56.31 73.20
Giuseppe Attardi-SVM-1-R 44.46 60.83
Giuseppe Attardi-SVM-1-rev 21.86 40.47
Average 54.22 72.82
Table 4: Results of the submitted systems.
The average LAS for all systems was 54.22.
Chinese Semantic Dependency Parsing performed
much more poorly than Chinese Syntactic Depen-
dency Parsing due to the increased complexity
brought about by the greater number of semantic re-
lations compared with syntactic relations, as well as
greater difficulty in classifying semantic relations.
In general, all the systems employed the tradi-
tional syntax-dominated dependency parsing frame-
works. Some new methods were proposed for
this task. Zhou Qiaoli?s systems first identified
the semantic role phrase in a sentence, and then
employed graph-based dependency parsing to ana-
lyze the semantic structure of the sentence. NJU-
Parser first split the sentence into sub-sentences,
then trained and parsed the sentence based on these
sub-sentences; this was shown to perform well. In
addition, ensemble models were also proposed to
solve the task using ICT systems.
6 Conclusion
We described the Chinese Semantic Dependency
Parsing task for SemEval-2012, which is designed to
parse the semantic structures of Chinese sentences.
Nine results were submitted by five organizations,
with the best result garnering an LAS score of 61.84,
which is far below the performance of Chinese Syn-
tax. This demonstrates that further research on the
structure of Chinese Semantics is needed.
In the future, we will check and improve the anno-
tation standards while building a large, high-quality
corpus for further Chinese semantic research.
Acknowledgments
We thank the anonymous reviewers for their help-
ful comments. This work was supported by Na-
tional Natural Science Foundation of China (NSFC)
via grant 61133012 and 61170144, and the Na-
tional ?863? Leading Technology Research Project
via grant 2012AA011102.
References
Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared
task on multilingual dependency parsing. In Proceed-
ings of the Tenth Conference on Computational Nat-
ural Language Learning (CoNLL-X), pages 149?164,
New York City, June. Association for Computational
Linguistics.
Dongfeng Cai, Ling Zhang, Qiaoli Zhou, and Yue Zhao.
2011. A collocation based approach for prepositional
phrase identification. IEEE NLPKE.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Pennsyl-
vania University.
Zhendong Dong and Qiang Dong. 2006. Hownet And the
Computation of Meaning. World Scientific Publishing
Co., Inc., River Edge, NJ, USA.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In Pro-
ceedings of the 48th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 1077?1086,
383
Uppsala, Sweden, July. Association for Computational
Linguistics.
Guangjin Jin. 2001. Theory of modern Chinese verb se-
mantic computation. Beijing University Press.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the 48th
Annual Meeting of the ACL, number July, pages 1?11.
Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. In Synthesis Lectures on
Human Language Technologies.
Mingqin Li, Juanzi Li, Zhendong Dong, Zuoying Wang,
and Dajin Lu. 2003. Building a large chinese corpus
annotated with semantic dependency. In Proceedings
of the second SIGHAN workshop on Chinese language
processing - Volume 17, SIGHAN ?03, pages 84?91,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
chinese pos tagging and dependency parsing. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1180?
1191, Edinburgh, Scotland, UK., July. Association for
Computational Linguistics.
Ryan McDonald. 2006. Discriminative learning and
spanning tree algorithms for dependency parsing.
Ph.D. thesis, University of Pennsylvania.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective
dependency parsing. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL).
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34(4):513?553.
Nianwen Xue and Martha Palmer. 2003. Annotating
the propositions in the penn chinese treebank. In Pro-
ceedings of the Second SIGHAN Workshop on Chinese
Language Processing.
Nianwen Xue and Martha Palmer. 2005. Automatic se-
mantic role labeling for chinese verbs. In Proceedings
of the 19th International Joint Conference on Artificial
Intelligence.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Guoguang Zhou and Linlin Zhang. 2003. The theory
and method of modern Chinese grammar. Guangdong
Higher Education Press.
384
