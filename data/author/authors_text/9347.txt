Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 229?232,
Suntec, Singapore, 4 August 2009.
c
?2009 ACL and AFNLP
Optimizing Word Alignment Combination For Phrase Table Training
Yonggang Deng and Bowen Zhou
IBM T.J. Watson Research Center
Yorktown Heights, NY 10598, USA
{ydeng,zhou}@us.ibm.com
Abstract
Combining word alignments trained in
two translation directions has mostly re-
lied on heuristics that are not directly
motivated by intended applications. We
propose a novel method that performs
combination as an optimization process.
Our algorithm explicitly maximizes the ef-
fectiveness function with greedy search
for phrase table training or synchronized
grammar extraction. Experimental results
show that the proposed method leads to
significantly better translation quality than
existing methods. Analysis suggests that
this simple approach is able to maintain
accuracy while maximizing coverage.
1 Introduction
Word alignment is the process of identifying
word-to-word links between parallel sentences. It
is a fundamental and often a necessary step before
linguistic knowledge acquisitions, such as train-
ing a phrase translation table in phrasal machine
translation (MT) system (Koehn et al, 2003), or
extracting hierarchial phrase rules or synchronized
grammars in syntax-based translation framework.
Most word alignment models distinguish trans-
lation direction in deriving word alignment matrix.
Given a parallel sentence, word alignments in two
directions are established first, and then they are
combined as knowledge source for phrase train-
ing or rule extraction. This process is also called
symmetrization. It is a common practice in most
state of the art MT systems. Widely used align-
ment models, such as IBM Model serial (Brown
et al, 1993) and HMM , all assume one-to-many
alignments. Since many-to-many links are com-
monly observed in natural language, symmetriza-
tion is able to make up for this modeling limita-
tion. On the other hand, combining two direc-
tional alignments practically can lead to improved
performance. Symmetrization can also be real-
ized during alignment model training (Liang et al,
2006; Zens et al, 2004).
Given two sets of word alignments trained in
two translation directions, two extreme combina-
tion are intersection and union. While intersec-
tion achieves high precision with low recall, union
is the opposite. A right balance of these two ex-
treme cases would offer a good coverage with rea-
sonable accuracy. So starting from intersection,
gradually adding elements in the union by heuris-
tics is typically used. Koehn et al (2003) grow
the set of word links by appending neighboring
points, while Och and Hey (2003) try to avoid both
horizontal and vertical neighbors. These heuristic-
based combination methods are not driven explic-
itly by the intended application of the resulting
output. Ayan (2005) exploits many advanced ma-
chine learning techniques for general word align-
ment combination problem. However, human
annotation is required for supervised training in
those techniques.
We propose a new combination method. Like
heuristics, we aim to find a balance between in-
tersection and union. But unlike heuristics, com-
bination is carried out as an optimization process
driven by an effectiveness function. We evaluate
the impact of each alignment pair w.r.t. the target
application, say phrase table training, and gradu-
ally add or remove the word link that currently
can maximize the predicted benefit measured by
the effectiveness function. More specifically, we
consider the goal of word alignment combination
is for phrase table training, and we directly moti-
vate word alignment combination as a process of
maximizing the number of phrase translations that
can be extracted within a sentence pair.
2 Combination As Optimization Process
Given a parallel sentence (e = e
I
1
, f = f
J
1
), a
word link is represented by a pair of indices (i, j),
229
which means that Foreign word f
j
is aligned with
English word e
i
. The direction of word alignments
is ignored. Since the goal of word alignment com-
bination is for phrase table training, we first for-
mally define a phrase translation. Provided with
a set of static word alignments A, a phrase pair
(e
i
2
i
1
, f
j
2
j
1
) is considered translation of each other if
and only if there exists at least one word link be-
tween them and no cross phrase boundary links ex-
ist in A, i.e., for all (i, j) ? A, i ? [i
1
, i
2
] iff j ?
[j
1
, j
2
]. Notice that by this definition, it does not
matter whether boundary words of the phrase pairs
should be aligned or not. Let PP
n
(A) denote the
set of phrase pairs that can be extracted with A
where up to n boundary words are allowed to be
not-aligned, i.e., aligned to empty word NULL. As
can be imagined, increasing n would improve re-
call of phrase table but likely to hurt precision. For
word alignment combination, we focus on the set
with high accuracy where n = 0.
Let A
1
, A
2
denote two sets of word alignments
to be combined for the given sentence pair. For
instance, A
1
could be word alignments from En-
glish to foreign while A
2
the other direction. On
different setup, A
1
could be Model-4 alignments,
while A
2
is from HMM. In the first combination
method we presented in Algorithm 1, we start with
intersection A
I
. A
c
is the candidate link set to be
evaluated and appended to the combined set A. Its
initial value is the difference between union and
intersection. We assume that there is an effective-
ness function g(?) which quantitatively measures
the ?goodness? of a alignment set for the intended
application. A higher number indicates a better
alignment set. We use the function g to drive the
process. Each time, we identify the best word link
(
?
i,
?
j) in the candidate set that can maximize the
function g and append it to the current set A. This
process is repeated until the candidate set is empty
or adding any link in the set would lead to degra-
dation. Finally (line 15 to 21), we pickup word
links in the candidate set to align those uncov-
ered words. This is applied to maximize cover-
age, which is similar as the ?final? in (Koehn et al,
2003). Again, we use the function g(?) to rank the
word links in A
c
and sequentially append them to
A depending on current word coverage.
The algorithm clearly is a greedy search pro-
cedure that maximizes the function g. Since we
plan to take the combined word alignments for
phrase translation training, a natural choice for
g is the number of phrase pairs that can be ex-
tracted with the given alignment set. We choose
g(A) = |PP
0
(A)|, where we only count phrase
pairs that all boundary words are aligned. The
reason of putting a tight constraint is to maintain
phrase table accuracy while improving the cover-
age. By keeping track of the span of currently
aligned words, we can have efficient implemen-
tation of the function g.
Algorithm 1 Combination ofA
1
andA
2
as an Optimized
Expanding Process
1: A
I
= A
1
?A
2
, A
U
= A
1
?A
2
2: A = A
I
, A
c
= A
U
?A
I
3: total = g(A)
4: while A
c
6= ? do
5: curMax = max
(i,j)?A
c
g(A ? {(i, j)})
6: if curMax ? total then
7: (
?
i,
?
j) = argmax
(i,j)?A
c
g(A ? {(i, j)})
8: A = A ? {(
?
i,
?
j)}
9: A
c
= A
c
? {(
?
i,
?
j)}
10: total = curMax
11: else {adding any link will make it worse}
12: break
13: end if
14: end while
15: while A
c
6= ? do
16: (
?
i,
?
j) = argmax
(i,j)?A
c
g(A ? {(i, j)})
17: if e
?
i
is not aligned or f
?
j
is not aligned then
18: A = A ? {(
?
i,
?
j)}
19: end if
20: A
c
= A
c
? {(
?
i,
?
j)}
21: end while
22: return A
Alternatively, the optimization can go in oppo-
site direction. We start with the union A = A
U
,
and gradually remove the worse word link (
?
i,
?
j) =
argmax
(i,j)?A
c
g(A ? {(i, j)}) that could max-
imize the effectiveness function. Similarly, this
shrinking process is repeated until either candidate
set is empty or removing any link in the candidate
set would reduce the value of function g.
Other choice of ?goodness? function g is pos-
sible. For instance, one could consider syntactic
constraints, or weight phrase pairs differently ac-
cording to their global co-occurrence. The basic
idea is to implement the combination as an itera-
tive customized optimization process that is driven
by the application.
3 Experimental Results
We test the proposed new idea on Persian Farsi to
English translation. The task is to translate spoken
Farsi into English. We decode reference transcrip-
tion so recognition is not an issue. The training
230
data was provided by the DARPA TransTac pro-
gram. It consists of around 110K sentence pairs
with 850K English words in the military force
protection domain. We train IBM Model-4 using
GIZA++ toolkit (Och and Ney, 2003) in two trans-
lation directions and perform different word align-
ment combination. The resulting alignment set is
used to train a phrase translation table, where Farsi
phrases are limited to up to 6 words.
The quality of resulting phrase translation table
is measured by translation results. Our decoder
is a phrase-based multi-stack implementation of
the log-linear model similar to Pharaoh (Koehn et
al., 2003). Like other log-linear model based de-
coders, active features in our translation engine in-
clude translation models in two directions, lexicon
weights in two directions, language model, lexi-
calized reordering models, sentence length penalty
and other heuristics. These feature weights are
tuned on the dev set to achieve optimal transla-
tion performance evaluated by automatic metric.
The language model is a statistical 4-gram model
estimated with Modified Kneser-Ney smoothing
(Chen and Goodman, 1996) using only English
sentences in the parallel training data.
3.1 Phrase Table Comparison
We first study the impact of different word align-
ment combination methods on phrase translation
table, and compare our approaches to heuristic
based methods. The same English to Farsi and
Farsi to English Model-4 word alignments are
used, but we try different combination methods
and analysis the final alignment set and the result-
ing phase translation table. Table 1 presents some
statistics. Each row corresponds to a particular
combination. The first two are intersection (I) and
union (U). The next two methods are heuristic (H)
in (Och and Ney, 2003) and grow-diagonal (GD)
proposed in (Koehn et al, 2003). Our proposed
methods are presented in the following two rows:
one is optimization as an expanding process (OE),
the other is optimization as an shrinking process
(OS). In the last four rows, we add ?final? opera-
tion (line 15 to 21 in Algorithm 1).
For each method, we calculate the output align-
ment set size as a percentage of the union (the
2nd column) and resulting phrase table (PP
n
(A))
size (in thousand) with different constrain on the
maximum number of unaligned boundary words
n = 0, 1, 2 (the next 3 columns). As we can
see, the intersection has less than half of all word
links in the pool. This implies the underlying word
alignment quality leaves much room for improve-
ments, mainly due to data sparseness. Not sur-
prisingly, when relaxing unaligned boundary word
number from 0 to 2, the phrase table size increases
more than 7 times. This is the result of very low
recall of word alignments, consequently the esti-
mated phrase table PP
2
(A) has very low accu-
racy. Union suffers from the opposite problem:
many incorrect word links prevent good phrase
pairs from being extracted.
The two heuristic methods and our proposed
optimization approaches achieve somewhat a bal-
ance between I and U. By comparing size of
PP
0
(A) (3rd column), optimization methods are
able to identify much more phrase pairs with sim-
ilar size of alignment set. This confirms that the
new method is indeed moving to the desired di-
rection of extracting as many accurate (all bound-
ary words should be aligned) phrase pairs as pos-
sible. We still notice that ratio of |PP
2
(A)| and
|PP
0
(A)| (the last column) is high. We suspect
that the ratio of this two phrase table size might
somewhat be indicative of the phrase table accu-
racy, which is hard to estimate without manual an-
notation though.
Method
|A|
|A
U
|
|PP
0
| |PP
1
| |PP
2
|
|PP
2
|
|PP
0
|
I 45% 424 2047 3658 8.63
U 100% 354 555 578 1.63
H 78% 538 1225 1519 2.82
GD 82% 499 1081 1484 2.97
OS 84% 592 1110 1210 2.04
OE 78% 659 1359 1615 2.45
HF 95% 427 670 697 1.63
GDF 97% 412 647 673 1.63
OSF 89% 484 752 781 1.61
OEF 89% 476 739 768 1.61
Table 1: Statistics of word alignment set and the
resulting phrase table size (number of entries in
thousand (K)) with different combination methods
3.2 Translation Results
The ultimate goal of word alignment combination
is for building translation system. The quality of
resulting phrase tables is measured by automatic
translation metric. We have one dev set (1430 sen-
tences with 11483 running words), test set 1 (1390
sentences with 10334 running words) and test set
2 (417 sentences with 4239 running words). The
dev set and test set 1 are part of all available Farsi-
231
English parallel corpus. They are holdout from
training data as tuning and testing. The test set 2
is the standard NIST offline evaluation set, where
4 references are available for each sentence. The
dev and test set 1 are much closer to the training
set than the standard test set 2. We tune all fea-
ture weights automatically (Och, 2003) to maxi-
mize the BLEU (Papineni et al, 2002) score on
the dev set.
Table 2 shows BLEU score of different com-
bination methods on all three sets. Union per-
forms much worse on the dev and test1 than inter-
section, while intersection achieved the same per-
formance on test2 as union but with more than 6
times of phrase table size. Grow-diagonal (GD)
has more than 1 bleu point on test2 than intersec-
tion but with less than half of phrase table size.
The proposed new method OE is consistently bet-
ter than both heuristic methods GD and H, with
more than 1 point on dev/teset1 and 0.7 point on
test2. Comparing the last group to the middle one,
we can see the effect of the ?final? operation on
all four methods. Tabel 1 shows that after apply-
ing the final operation, phrase table size is cut into
half. When evaluated with automatic translation
metric, all four methods generally perform much
worse on dev and test1 that are close to training
data, but better on NIST standard test2. We ob-
serve half BLEU point improvement for optimiza-
tion method but marginal gain for heuristic-based
approaches. This suggest that the phrase table ac-
curacy get improved with the final operation. Op-
timization method directly tries to maximize the
number of phrase pairs that can be extracted. We
observe that it (OEF) is able to find more than
14% more phrase pairs than heuristic methods and
achieve 1 BLEU point gain than the best heuristic
method (GDF).
Method dev test1 test2
I 0.396 0.308 0.348
U 0.341 0.294 0.348
H 0.400 0.314 0.341
GD 0.391 0.314 0.360
OS 0.383 0.316 0.356
OE 0.410 0.329 0.367
HF 0.361 0.297 0.343
GDF 0.361 0.301 0.362
OSF 0.372 0.305 0.361
OEF 0.370 0.306 0.372
Table 2: Translation results (BLEU score) with
phrase tables trained with different word align-
ment combination methods
4 Conclusions
We presented a simple yet effective method for
word alignment symmetrization and combination
in general. The problem is formulated as an opti-
mization with greedy search driven by an effec-
tiveness function, which can be customized di-
rectly to maximum benefit for intended applica-
tions such as phrase table training or synchronized
grammar extraction in machine translation. Ex-
perimental results demonstrated consistent better
BLEU scores than the best heuristic method. The
optimization process can better maintain accuracy
while improving coverage.
The algorithm is generic and leaves much space
for variations. For instance, designing a better ef-
fectiveness function g, or considering a soft link
with some probability rather than binary 0/1 con-
nection would potentially be opportunities for fur-
ther improvement. On the other hand, the search
space of current algorithm is limited by the pool
of candidate set, it is possible to suggest new links
while driven by the target function.
Acknowledgments We thank the DARPA
TransTac program for funding and the anonymous
reviewers for their constructive suggestions.
References
N. F. Ayan. 2005. Combining Linguistic andMachine Learn-
ing Techniques for Word Alignment Improvement. Ph.D.
thesis, University of Maryland, College Park, November.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.
1993. The mathematics of machine translation: Parameter
estimation. Computational Linguistics, 19:263?312.
S. F. Chen and J. Goodman. 1996. An empirical study of
smoothing techniques for language modeling. In Proc. of
ACL, pages 310?318.
P. Koehn, F. Och, and D. Marcu. 2003. Statistical phrase-
based translation. In Proc. of HLT-NAACL, pages 48?54.
P. Liang, B. Taskar, and D. Klein. 2006. Alignment by agree-
ment. In Proc. of HLT-NAACL, pages 104?111.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational Lin-
guistics, 29(1):19?51.
F. J. Och. 2003. Minimum error rate training in statistical
machine translation. In Proc. of ACL, pages 160?167.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. Bleu:
a method for automatic evaluation of machine translation.
In Proc. of ACL, pages 311?318.
R. Zens, E. Matusov, and H. Ney. 2004. Improved word
alignment using a symmetric lexicon model. In Proc. of
COLING, pages 36?42.
232
IBM MASTOR SYSTEM: Multilingual Automatic Speech-to-speech Translator * 
 
Yuqing Gao, Liang Gu, Bowen Zhou, Ruhi Sarikaya, Mohamed Afify, Hong-Kwang Kuo, 
Wei-zhong Zhu, Yonggang Deng, Charles Prosser, Wei Zhang and Laurent Besacier 
IBM T. J. Watson Research Center, Yorktown Heights, NY 10598 
 
ABSTRACT 
In this paper, we describe the IBM MASTOR, a speech-to-speech 
translation system that can translate spontaneous free-form 
speech in real-time on both laptop and hand-held PDAs. Chal-
lenges include speech recognition and machine translation in 
adverse environments, lack of training data and linguistic re-
sources for under-studied languages, and the need to rapidly de-
velop capabilities for new languages. Another challenge is de-
signing algorithms and building models in a scalable manner to 
perform well even on memory and CPU deficient hand-held com-
puters. We describe our approaches, experience, and success in 
building working free-form S2S systems that can handle two 
language pairs (including a low-resource language). 
 
1. INTRODUCTION 
Automatic speech-to-speech (S2S) translation breaks down com-
munication barriers between people who do not share a common 
language and hence enable instant oral cross-lingual communica-
tion for many critical applications such as emergency medical 
care. The development of an accurate, efficient and robust S2S 
translation system poses a lot of challenges. This is especially 
true for colloquial speech and resource deficient languages. 
The IBM MASTOR speech-to-speech translation system has been 
developed for the DARPA CAST and Transtac programs whose 
mission is to develop technologies that enable rapid deployment 
of real-time S2S translation of low-resource languages on port-
able devices. It originated from the IBM MARS S2S system 
handling the air travel reservation domain described in [1], which 
was later significantly improved in all components, including 
ASR, MT and TTS, and later evolved into the MASTOR multi-
lingual S2S system that covers much broader domains such as 
medical treatment and force protection [2,3]. More recently, we 
have further broadened our experience and efforts to very rapidly 
develop systems for under-studied languages, such as regional 
dialects of Arabic. The intent of this program is to provide lan-
guage support to military, medical and humanitarian personnel 
during operations in foreign territories, by deciphering possibly 
critical language communications with a two-way real-time 
speech-to-speech translation system designed for specific tasks 
such as medical triage and force protection.  
The initial data collection effort for the project has shown that the 
domain of force protection and medical triage is, though limited, 
rather broad. In fact, the definition of domain coverage is tough 
when the speech from responding foreign language speakers are 
concerned, as their responses are less constrained and may in-
clude out-of-domain words and concepts. Moreover, flexible 
casual or colloquial speaking style inevitably appears in the hu-
man-to-human conversational communications. Therefore, the 
project is a great challenge that calls for major research efforts. 
Among all the challenges for speech recognition and translation 
for under-studied languages, there are two main issues: 1) Lack of 
appropriate amount of speech data that represent the domain of 
interest and the oral language spoken by the target speakers, re-
sulting in difficulties in accurate estimation of statistical models 
for speech recognition and translation. 2) Lack of linguistic 
knowledge realization in spelling standards, transcriptions, lexi-
cons and dictionaries, or annotated corpora. Therefore, various 
different approaches have to be explored.  
Another critical challenge is to embed complicated algorithms 
and programs into small devices for mobile users. A hand-held 
computing device may have a CPU of 256MHz and 64MB mem-
ory; to fit the programs, as well as the models and data files into 
this memory and operate the system in real-time are tremendous 
challenges [4]. 
In this paper, we will describe the overall framework of the 
MASTOR system and our approaches for each major component, 
i.e., speech recognition and translation. Various statistical ap-
proaches [5,6,7,8] are explored and used to solve different techni-
cal challenges. We will show how we addressed the challenges 
that arise when building automatic speech recognition (ASR) and 
machine translation (MT) for colloquial Arabic on both the laptop 
and handheld PDA platforms. 
 
2. SYSTEM OVERVIEW 
The general framework of our speech translation system is illus-
trated in Figure 1. The general framework of our MASTOR sys-
tem has components of ASR, MT and TTS. The cascaded ap-
proach allows us to deploy the power of the existing advanced 
speech and language processing techniques, while concentrating 
on the unique problems in speech-to-speech translation. Figure 2 
illustrates the MASTOR GUI (Graphic User Interface) on laptop 
and PDA, respectively. 
Acoustic models for English and Mandarin baseline are devel-
oped for large-vocabulary continuous speech and trained on over 
200 hours of speech collected from about 2000 speakers for each 
language. However, the Arabic dialect speech recognizer was 
only trained using about 50 hours of dialectal speech.  The train-
ing data for Arabic consists of about 200K short utterances. Large 
efforts were invested in initial cleaning and normalization of the 
training data because of large number of irregular dialectal words 
and variations in spellings. We experimented with three ap-
proaches for pronunciation and acoustic modeling: i.e. grapheme, 
phonetic, and context-sensitive grapheme as will be described in 
ASR TTS 
Statistical NLU/NLG 
based MT 
Figure 1 IBM MASTOR Speech-to-Speech Translation System 
Statistical MT using 
WFST/SIPL  
* Thanks to DARPA for funding 
section 3.A. We found that using context-sensitive pronunciation 
rules reduces the WER of the grapheme based acoustic model by 
about 3% (from 36.7% to 35.8%). Based on these results, we 
decided to use context-sensitive grapheme models in our system.  
The Arabic language model (LM) is an interpolated model con-
sisting of a trigram LM, a class-based LM and a morphologically 
processed LM, all trained from a corpus of a few hundred thou-
sand words. We also built a compact language model for the 
hand-held system, where singletons are eliminated and bigram 
and trigram counts are pruned with increased thresholds. The LM 
footprint size is 10MB. 
There are two approaches for translation. The concept based ap-
proach uses natural language understanding (NLU) and natural 
language generation models trained from an annotated corpus. 
Another approach is the phrase-based finite state transducer 
which is trained using an un-annotated parallel corpus. 
A trainable, phrase-splicing and variable substitution TTS system 
is adopted to synthesize speech from translated sentences, which 
has a special ability to generate speech of mixed languages seam-
lessly [9]. In addition, a small footprint TTS is developed for the 
handheld devices using embedded concatenative TTS technolo-
gies.[10] 
Next, we will describe our approaches in automatic speech recog-
nition and machine translation in greater detail. 
 
3. AUTOMATIC SPEECH RECOGNITION 
A. Acoustic Models 
Acoustic models and the pronunciation dictionary greatly influ-
ence the ASR performance. In particular, creating an accurate 
pronunciation dictionary poses a major challenge when changing 
the language. Deriving pronunciations for resource rich languages 
like English or Mandarin is relatively straight forward using ex-
isting dictionaries or letter to sound models. In certain languages 
such as Arabic and Hebrew, the written form does not typically 
contain short vowels which a native speaker can infer from con-
text. Deriving automatic phonetic transcription for speech corpora 
is thus difficult. This problem is even more apparent when con-
sidering colloquial Arabic, mainly due to the large number of 
irregular dialectal words. 
One approach to overcome the absence of short vowels is to use 
grapheme based acoustic models. This leads to straightforward 
construction of pronunciation lexicons and hence facilitates 
model training and decoding. However, the same grapheme may 
lead to different phonetic sounds depending on its context. This 
results in less accurate acoustic models. For this reason we ex-
perimented with two other different approaches. The first is a full 
phonetic approach which uses short vowels, and the second uses 
context-sensitive graphemes for the letter "A" (Alif) where two 
different phonemes are used for "A" depending on its position in 
the word. 
Using phoneme based pronunciations would require vowelization 
of every word. To perform vowelization, we used a mix of dic-
tionary search and a statistical approach. The word is first 
searched in an existing vowelized dictionary, and if not found it is 
passed to the statistical vowelizer [11].  Due to the difficulties in 
accurately vowelizing dialectal words, our experiments have not 
shown any improvements using phoneme based ASR compared 
to grapheme based.  
Speech recognition for both the laptop and hand-held systems is 
based on the IBM ViaVoice engine. This highly robust and effi-
cient framework uses rank based acoustic scores [12] which are 
derived from tree-clustered context dependent Gaussian models. 
These acoustic scores together with n-gram LM probabilities are 
incorporated into a stack based search algorithm to yield the most 
probable word sequence given the input speech. 
The English acoustic models use an alphabet of 52 phones. Each 
phone is modeled with a 3-state left-to-right hidden Markov 
model (HMM). The system has approximately 3,500 context-
dependent states modeled using 42K Gaussian distributions and 
trained using 40 dimensional features. The context-dependent 
states are generated using a decision-tree classifier. The collo-
quial Arabic acoustic models use about 30 phones that essentially 
correspond to graphemes in the Arabic alphabet. The colloquial 
Arabic HMM structure is the same as that of the English model. 
The Arabic acoustic models are also built using 40 dimensional 
features. The compact model for the PDA has about 2K leaves 
and 28K Gaussian distributions.  The laptop version has over 3K 
leaves and 60K Gaussians. All acoustic models are trained using 
discriminative training [13]. 
B. Language Modeling   
Language modeling (LM) of the probability of various word se-
quences is crucial for high-performance ASR of free-style open-
 
   
 
 
Figure 2  IBM MASTOR system in Windows XP and Win-
dows CE 
ended coversational systems. Our approaches to build statistical 
tri-gram LMs fall into three categories: 1) obtaining additional 
training material automatically; 2) interpolating domain-specific 
LMs with other LMs; 3) improving distribution estimation ro-
bustness and accuracy with limited in-domain resources. Auto-
matic data collection and expansion is the most straight-forward 
way to achieve efficient LM, especially when little in-domain 
data is available. For resource-rich languages such as English and 
Chinese, we retrieve additional data from the World Wide Web 
(WWW) to enhance our limited domain specific data, which 
shows significant improvement [6]. 
In Arabic, words can take prefixes and suffixes to generate new 
words which are semantically related to the root form of the word 
(stem). As a result, the vocabulary size in Arabic can become 
very large even for specific domains. To alleviate this problem, 
we built a language model on morphologically tokenized data by 
applying morphological analysis and hence splitting some of the 
words into prefix+stem+suffix, prefix+stem or stem+suffix forms. 
We refer the reader to [14] to learn more about the morphological 
tokenization algorithm. Morphological analysis reduced the vo-
cabulary size by about 30% without sacrificing the coverage. 
More specifically, in our MASTOR system, the English language 
model has two components that are linearly interpolated. The first 
one is built using in-domain data. The second component acts as a 
background model and is built using a very large generic text 
inventory that is domain independent. The language model counts 
are also pruned to control the size of this background model. The 
colloquial Arabic language model for our laptop system is com-
posed of three components that are linearly interpolated. The first 
one is the basic word tri-gram model. The second one is a class 
based language model with 13 classes that covers names for Eng-
lish and Arabic, numbers, months, days, etc. The third one is the 
morphological language model described above. 
4. SPEECH TRANSLATION 
A. NLU/NLG-based Speech Translation 
One of the translation algorithms we proposed and applied in 
MASTOR is the statistical translation method based on natural 
language understanding (NLU) and natural language generation 
(NLG). Statistical machine translation methods translate a sen-
tence W in the source language into a sentence A in the target 
language by using a statistical model that estimates the probabil-
ity of A given W, i.e. ( )WAp . Conventionally, ( )WAp  is opti-
mized on a set of pairs of sentences that are translations of one 
another. To alleviate this data sparseness problem and, hence, 
enhance both the accuracy and robustness of estimating ( )WAp , 
we proposed a statistical concept-based machine translation para-
digm that predicts A with not only W but also the underlying con-
cepts embedded in W and/or A. As a result, the optimal sentence 
A is picked by first understanding the meaning of the source sen-
tence W.  
Let C denote the concepts in the source language and S denote the 
concepts in the target language, our proposed statistical concept-
based algorithm should select a word sequence A? as 
( ) ( ) ( ) ( )
??
?
??
?
== ? WCpWCSpWCSApWApA
CSAA
,,,maxargmaxarg?
,
 , 
where the conditional probabilities ( )WCp , ( )WCSp ,  and 
( )WCSAp ,,  are estimated by the Natural Language Understand-
ing (NLU), Natural Concept Generation (NCG) and Natural 
Word Generation (NWG) procedures, respectively. The probabil-
ity distributions are estimated and optimized upon a pre-annotated 
bilingual corpus. In our MASTOR system, ( )WCp  is estimated 
by a decision-tree based statistical semantic parser, and 
( )WCSp ,  and ( )WCSAp ,,  are estimated by maximizing the 
conditional entropy as depicted in [2] and [7], respectively. 
We are currently developing a new translation method that unifies 
statistical phrase-based translation models and the above 
NLU/NLG based approach. We will discuss this work in future 
publications. 
 
B. Fast and Memory Efficient Machine Translation Using SIPL 
Another translation method we proposed in MASTOR is based on 
the Weighted Finite-State Transducer (WFST). In particular, we 
developed a novel phrase-based translation framework using 
WFSTs that achieves both memory efficiency and fast speed, 
which is suitable for real time speech-to-speech translation on 
scalable computational platforms. In the proposed framework [15] 
which we refer to as Statistical Integrated Phrase Lattices (SIPLs), 
we statically construct a single optimized WFST encoding the 
entire translation model. In addition, we introduce a Viterbi de-
coder that can combine the translation model and language model 
FSTs with the input lattice efficiently, resulting in translation 
speeds of up to thousands of words per second on a PC and hun-
dred words per second on a PDA device. This WFST-based ap-
proach is well-suited to devices with limited computation and 
memory. We achieve this efficiency by using methods that allow 
us to perform more composition and graph optimization offline 
(such as, the determinization of the phrase segmentation trans-
ducer P) than in previous work, and by utilizing a specialized 
decoder involving multilayer search.  
During the offline training, we separate the entire translation lat-
tice H into two pieces: the language model L and the translation 
model M: 
( )( )( )WTPDetMinMinM =  
where   is the composition operator, Min  denotes the 
minimization operation, and Det  denotes the determinization 
operation; T is the phrase translation transducer, and W is the 
phrase-to-word transducer. Due to the determinizability of P, M 
can be computed offline using a moderate amount of memory. 
The translation problem can be framed as finding the best path in 
the full search lattice given an input sentence/automaton I. To 
address the problem of efficiently computing LMI  , we have 
developed a multilayer search algorithm. 
Specifically, we have one layer for each of the input FSM's: I, L, 
and M. At each layer, the search process is performed via a state 
traversal procedure starting from the start state 0s

, and consum-
ing an input word in each step in a left-to-right manner.  
We represent each state s in the search space using the following 
7-tuple: Is , Ms , Ls , Mc , Lc , h
 
, prevs , where Is , Ms , and 
Ls record the current state in each input FSM; Mc and Lc  record 
the accumulated cost in L and M in the best path up to this point; 
h
 
 records the target word sequence labeling the best path up to 
this point; and prevs  records the best previous state. 
To reduce the search space, two active search states are merged 
whenever they have identical Is , Ms , and Ls values; the re-
maining state components are inherited from the state with lower 
cost.  In addition, two pruning methods, histogram pruning and 
threshold or beam pruning, are used to achieve the desired bal-
ance between translation accuracy and speed. 
To provide the decoder for the PDA devices as well that lacks a 
floating-point processor, the search algorithm is implemented 
using fixed-point arithmetic. 
 
 
5. CONCLUSION 
We described the framework of the IBM MASTOR system, the 
various technologies used in building major components for lan-
guages with different levels of data resources. The technologies 
have shown successes in building real-time S2S systems on both 
laptop and small computation resource platforms for two lan-
guage pairs, English-Mandarin Chinese, and English-Arabic dia-
lect. In the latter case, we also developed approaches which lead 
to very rapid (in the matter of 3-4 months) development of sys-
tems using very limited language and domain resources. We are 
working on improving spontaneous speech recognition accuracy 
and more naturally integrating two translation approaches.  
 
6. ACKNOWLEDGEMENT 
The authors sincerely thank Drs. Yoshinori Tahara, Fu-hua Liu, 
Yongxing Li, Etienne Marcheret, Raimo Bakis, Ellen Eide, Burn 
Lewis, Tony Lee, Ossama Emam, and Lubos Ures for their help 
and contributions to the MASTOR S2S system. 
 
7. REFERENCES 
[1] Y. Gao et al ?MARS: A Statistical Semantic Parsing and Generation 
Based Multilingual Automatic tRanslation System,? Machine Trans-
lation, vol. 17, pp.185-212, 2004. 
[2] L. Gu et al ?Improving Statistical Natural Concept Generation in 
Interlingua-based Speech-to-Speech Translation,? in Proc. Eu-
rospeech?2003, pp.2769-2772. 
[3] F.-H. Liu, ?Robustness in Speech-to-Speech Translation,? in Proc. 
Eurospeech?2003, pp.2797-2800. 
[4] B. Zhou et al ?Two-way speech-to-speech translation on handheld 
devices,? in Proc. ICSLP'04, South Korea, Oct, 2004. 
[5] H. Erdogan et al ?Using Semantic Analysis to Improve Speech 
Recognition Performance,? Computer Speech and Language, vol.19, 
pp.321-343, 2005. 
[6] R. Sarikaya, et al  ?Rapid Language Model Development Using 
External Resources for New Spoken Dialog Domains,? in Proc. 
ICASSP'05, Philadelphia, PA, Mar, 2005. 
[7] L. Gu et al ?Concept-based Speech-to-Speech Translation using 
Maximum Entropy Models for Statistical Natural Concept Genera-
tion,? IEEE Trans. Speech and Audio Processing, vol.14, no.2, 
pp.377-392, March, 2006. 
[8] B. Zhou et al ?Constrained phrase-based translation using weighted 
finite-state transducers,? in Proc. ICASSP'05, Philadelphia, Mar, 
2005. 
[9] E. Eide et al ?Recent Improvements to the IBM Trainable Speech 
Synthesis System,? in Proc.  ICASSP, Hong Kong, China, 2003. 
[10] Dan Chazan et al ?Reducing the Footprint of the IBM Trainable 
Speech Synthesis System,? in ICSLP-2002, pp.2381-2384  
[11] R. Sarikaya et al ?Maximum Entropy Based Vowelization of Ara-
bic,? Interspeech2006 (submitted for publication). 
[12] L.R. Bahl, et al ?Robust methods for using context-dependent fea-
tures and models in a continuous speech recognizer,? in Proc. 
ICASSP, 1994 
[13] D. Povey & P.C. Woodland, ?Minimum Phone Error and I-
Smoothing for Improved Discriminative Training,? In Proc. ICASSP, 
Orlando, 2002. 
[14] M. Afify et.al, ?On the Use of Morphological Analysis for Dialectal 
Arabic Speech Recognition,? Interspeech 2006 (submitted for publi-
cation). 
[15] B. Zhou, S. Chen, and Y. Gao, ?Fast Machine Translation Using 
Statistical Integrated Phrase Lattices,? submitted to COL-
ING/ACL'2006. 
 
 
Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 19?27,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Prior Derivation Models For Formally Syntax-based Translation Using
Linguistically Syntactic Parsing and Tree Kernels
Bowen Zhou
IBM T. J. Watson Research Center
Yorktown Heights, NY
zhou@us.ibm.com
Bing Xiang
IBM T. J. Watson Research Center
Yorktown Heights, NY
bxiang@us.ibm.com
Xiaodan Zhu
Dept. of Computer Science
University of Toronto
xzhu@cs.toronto.edu
Yuqing Gao
IBM T. J. Watson Research Center
Yorktown Heights, NY
yuqing@us.ibm.com
Abstract
This paper presents an improved formally
syntax-based SMT model, which is enriched
by linguistically syntactic knowledge obtained
from statistical constituent parsers. We pro-
pose a linguistically-motivated prior deriva-
tion model to score hypothesis derivations on
top of the baseline model during the trans-
lation decoding. Moreover, we devise a
fast training algorithm to achieve such im-
proved models based on tree kernel meth-
ods. Experiments on an English-to-Chinese
task demonstrate that our proposed models
outperformed the baseline formally syntax-
based models, while both of them achieved
significant improvements over a state-of-the-
art phrase-based SMT system.
1 Introduction
In recent years, syntax-based translation models
(Chiang, 2007; Galley et al, 2004; Liu et al, 2006)
have shown promising progress in improving trans-
lation quality. There are two major elements ac-
counting for such an improvement: namely the in-
corporation of phrasal translation structures adopted
from widely applied phrase-based models (Och
and Ney, 2004) to handle local fluency, and the
engagement of synchronous context-free grammars
(SCFG), which enhances the generative capacity of
the underlying model that is limited by finite-state
machinery.
Approaches to syntax-based translation models
using SCFG can be further categorized into two
classes, based on their dependency on annotated cor-
pus. Following Chiang (Chiang, 2007), we note the
following distinction between these two classes:
? Linguistically syntax-based: models that utilize
structures defined over linguistic theory and
annotations (e.g., Penn Treebank), and SCFG
rules are derived from parallel corpus that is
guided by explicitly parsing on at least one side
of the parallel corpus. Examples among others
are (Yamada and Knight, 2001) and (Galley et
al., 2004).
? Formally syntax-based: models are based on
hierarchical structures of natural language but
synchronous grammars are automatically ex-
tracted from parallel corpus without any usage
of linguistic knowledge or annotations. Exam-
ples include Wu?s (Wu, 1997) ITG and Chi-
ang?s hierarchical models (Chiang, 2007).
While these two often resemble in appearance,
from practical viewpoints, there are some distinc-
tions in training and decoding procedures differen-
tiating formally syntax-based models from linguis-
tically syntax-based models. First, the former has
no dependency on available linguistic theory and
annotations for targeting language pairs, and thus
the training and rule extraction are more efficient.
Secondly, the decoding complexity of the former is
lower 1, especially when integrating a n-gram based
1The complexity is dominated by synchronous parsing and
boundary words keeping. Thus binary SCFG employed in for-
mally syntax-based systems help to maintain efficient CKY de-
coding. Recent work by (Zhang et al, 2006) shows a practi-
cally efficient approach that binarizes linguistically SCFG rules
when possible.
19
language model, which is a key element to ensure
translation output quality.
On the other hand, available linguistic theory
and annotations could provide invaluable benefits in
grammar induction and scoring, as shown by recent
progress on such models (Galley et al, 2006). In
contrast, formally syntax-based grammars often lack
explicit linguistic constraints.
In this paper, we propose a scheme to enrich for-
mally syntax-based models with linguistically syn-
tactic knowledge. In other words, we maintain our
grammar to be based on formal syntax on surface,
but incorporate linguistic knowledge into our mod-
els to leverage syntax theory and annotations.
Our goal is two-fold. First, how to score SCFG
rules whose general abstraction forms are unseen in
the training data is an important question to answer.
In hierarchical models, Chiang (Chiang, 2007) uti-
lizes heuristics where certain assumptions are made
on rule distributions to obtain relative frequency
counts. We intend to explore if additional linguisti-
cally parsing information would be beneficial to im-
prove the scoring of formally syntactic SCFG gram-
mars. Secondly, we note that SCFG-based models
often come with an excessive memory consumption
as its rule size is an order of magnitude larger com-
pared to phrase-based models, which challenges its
practical deployment for online real-time translation
tasks. Furthermore, formal syntax rules are often re-
dundant as they are automatically extracted without
linguistic supervision. Therefore, we are motivated
to study approaches to further score and rank formal
syntax rules based on syntax-inspired methods, and
eventually to prune unnecessary rules without loss
of performance in general.
In our study, we propose a linguistically-
motivated method to train prior derivation models
for formally syntax-based translation. In this frame-
work, prior derivation models can be viewed as a
smoothing of rule translation models, addressing
the weakness of the baseline model estimation that
relies on relative counts obtained from heuristics.
First, we apply automatic parsers to obtain syntax
annotations on the English side of the parallel cor-
pus. Next, we extract tree fragments associated with
phrase pairs, and measure similarity between such
tree fragments using kernel methods (Collins and
Duffy, 2002; Moschitti, 2006). Finally, we score
and rank rules based on their minimal cluster sim-
ilarity of their nonterminals, which is used to com-
pute the prior distribution of hypothesis derivations
during decoding for improved translation.
The remainder of the paper is organized as fol-
lows. We start with a brief review of some related
work in Sec. 2. In Sec. 3, we describe our formally
syntax-based models and decoder implementation,
that is established as our baseline system. Sec. 4
presents the approach to score formal SCFG rules
using kernel methods. Experimental results are pro-
vided in Sec. 5. Finally, Sec. 6 summarized our con-
tributions with discussions and future work.
2 Related Work
Syntax-based translation models engaged with
SCFG have been actively investigated in the liter-
ature (Wu, 1997; Yamada and Knight, 2001; Gildea,
2003; Galley et al, 2004; Satta and Peserico, 2005).
Recent work by (Chiang, 2007; Galley et al,
2006) shows promising improvements compared to
phrase-based models for large-scale tasks. How-
ever, few previous work directly applied linguisti-
cally syntactic information into a formally syntax-
based models, which is explored in this paper.
Kernel methods leverage the fact that the only op-
eration in a procedure is the evaluation of inner dot
products between pairs of observations, where the
inner product is thus replaced with a Mercer kernel
that provides an efficient way to carry out computa-
tion when original feature dimension is large or even
infinite. Collins and Duffy (Collins and Duffy, 2002)
suggested to employ convolution kernels to measure
similarity between two trees in terms of their sub-
structures, and more recently, Moschitti (Moschitti,
2006) described in details a fast implementation of
tree kernels. To our knowledge, this paper is one of
the few efforts of applying kernel methods for im-
proved translation.
3 Formally Syntax-based Models
An SCFG is a synchronous rewriting system gen-
erating source and target side string pairs simulta-
neously based on context-free grammar. Each syn-
chronous production (i.e., rule) rewrites a nonter-
minal into a pair of strings, ? and ?, with both
terminals and nonterminals in both languages, sub-
20
ject to the constraint that there is a one-to-one cor-
respondence between nonterminal occurrences on
the source and target side. In particular, formally
syntax-based models explore hierarchical structures
of natural language and utilize only a unified nonter-
minal symbol X in the grammar,
X ? ??, ?,??, (1)
where ? is the one-to-one correspondence between
X?s in ? and ?, which is indicated by under-
scripted co-indices on both sides. For example,
some English-to-Chinese production rules can be
represented as follows:
X ? ?X1enjoy readingX2, (2)
X1xihuan(enjoy) yuedu(reading)X2?
X ? ?X1enjoy readingX2,
X1xihuan(enjoy)X2yuedu(reading)?
The set of rules, denoted as R, are automatically ex-
tracted from sentence-aligned parallel corpus (Chi-
ang, 2007). First, bidirectional word-level align-
ment is carried out on the parallel corpus running
GIZA++ (Och and Ney, 2000). Based on the result-
ing Viterbi alignments Ae2f and Af2e, the union,
AU = Ae2f ? Af2e, is taken as the symmetrizedword-level alignment. Next, bilingual phrase pairs
consistent with word alignments are extracted from
AU (Och and Ney, 2004). Specifically, any pairof consecutive sequences of words below a maxi-
mum length M is considered to be a phrase pair
if its component words are aligned only within the
phrase pair and not to any words outside. The re-
sulting bilingual phrase pair inventory is denoted as
BP . Each phrase pair PP ? BP is represented as
a production rule X ? ?f ji , elk?, which we refer toas phrasal rules. The SCFG rule set encloses all
phrase pairs, i.e., BP ? R. Next, we loop through
each phrase pair PP and generalize the sub-phrase
pair contained in PP, denoted as SPe and SPf sub-ject to SP = (SPf , SPe) ? BP , with co-indexednonterminal symbols. We thereby obtain a new rule.
We limit the number of nonterminals in each rule
no more than two, thus ensuring the rank of SCFG is
two. To reduce rule size and spurious ambiguity, we
apply constraints described in (Chiang, 2007). In
addition, we require that the sub-phrases being ab-
stracted by correspondent nonterminals have to be
aligned together in the original phrase pair, which
significantly reduces the number of rules. We will
hereafter refer to rules with nonterminal symbols as
abstract rules to distinguish them from phrasal rules.
Finally, an implicit glue rule is embedded with de-
coder to allow for translations that can be achieved
by sequentially linking sub-translations generated
chunk-by-chunk:
X ? ?X1X2, X1X2?. (3)
That is, X is also our sentence start symbol.
During such a rule extraction procedure, we note
that there is a many-to-many mapping between
phrase pairs (contiguous word sequences without
nonterminals) and derived rules (a mixed combina-
tion of word and nonterminal sequences). In other
words, one original phrase pair can induce a num-
ber of different rules, and the same rule can also be
derived from a number of different phrase pairs.
3.1 Models
All rules in R are paired with statistical parame-
ters (i.e., weighted SCFG), which combines with
other features to form our models using a log-linear
framework. Translation using SCFG for an input
sentence f is casted as to find the optimal derivation
on source and target side (as the grammar is syn-
chronous, the derivations on source and target sides
are identical). By ?optimal?, it indicates that the
derivation D maximizes following log-linear mod-
els over all possible derivations:
P (D) ? PLM (e)?LM?
?
i
?
X?<?,?>?D ?i(X ?< ?, ? >)?i , (4)
where the set of ?i(X ?< ?, ? >) are featuresdefined over given production rule, and PLM (e) isthe language model score on hypothesized output,
the ?i is the feature weight.Our baseline model follows Chiang?s hierarchical
model (Chiang, 2007) in conjunction with additional
features:
? conditional probabilities in both directions:
P (?|?) and P (?|?);
? lexical weights (Koehn et al, 2003) in both di-
rections: Pw(?|?) and Pw(?|?);
21
? word counts |e|;
? rule counts |D|;
? target n-gram language model PLM (e);
? glue rule penalty to learn preference of non-
terminal rewriting over serial combination
through Eq. 3;
Moreover, we propose an additional feature, namely
the abstraction penalty, to account for the accumu-
lated number of nonterminals applied in D:
? abstraction penalty exp(?Na), where Na =
?
X?<?,?>?D n(?)
where n(?) is the number of nonterminals in ?. This
feature aims to learn the preference among phrasal
rules, and abstract rules with one or two nontermi-
nals. This makes our syntax-based model includes a
total of nine features.
The training procedure described in (Chiang,
2007) employs heuristics to hypothesize a distri-
bution of possible rules. A count one is assigned
to every phrase pair occurrence, which is equally
distributed among rules that are derived from this
phrase pair. Hypothesizing this distribution as our
observations on rule occurrence, relative-frequency
estimation is used to obtain P (?|?) and P (?|?).
We note that, however, these parameters are of-
ten poorly estimated due to the usage of inaccurate
heuristics, which is the major problem that we alle-
viate in Sec. 4.
3.2 Decoder
The objective of our syntax-based decoder is to
search for the optimal derivation tree D from a for-
est of trees that can represent the input sentence. The
target side is mapped accordingly at each nontermi-
nal node in the tree, and a traverse of these nodes
obtains the target translation. Fig. 1 shows an ex-
ample for chart parsing that produces the translation
from the best parse.
Our decoder implements a modified CKY parser
in C++ with integrated n-gram language model scor-
ing. During search, chart cells are filled in a bottom-
up fashion until a tree rooted from nonterminal is
generated that covers the entire input sentence. The
dynamic programming item we bookkeep is denoted
Figure 1: A chart parsing-based decoding on SCFG pro-
duces translation from the best parse: f1f2f3f4f5 ?
e5e6e3e4e1e2.
as [X, i, j; eb], indicating a sub-tree rooted with Xthat has covered input from position i to j generat-
ing target translation with boundary words eb. Tospeed up the decoding, a pruning scheme similar to
the cube pruning (Chiang, 2007) is performed dur-
ing search.
4 Prior Derivation Models
As mentioned above, decoding searches for the op-
timal tree on source side to cover the input sentence
with respect to given models, as shown in Eq. 4.
Among these feature functions, ?i measures howlikely the source and hypothesized target sub-trees
rooted from same X are paired together through
symmetric conditional probabilities (e.g., P (?|?)
and P (?|?)), and the target language model mea-
sures the fluency on target string. It should be noted
that, however, the baseline models do not discrim-
inate between different parses on source side when
the target side is unknown.
Therefore, if we could obtain some prior distribu-
tions for the source side derivations, we can rewrite
Eq. 4 as:
P (D) ? PLM (e)?LM ?
?
X?<?,?>?D
(?i ?i(X ?< ?, ? >)?i)L(X ?< ?, ? >)?L ,(5)
where L(?) is a feature function defined over a pro-
duction but only depending on one side of the rules
22
and asterisk denotes arbitrary symbol sequences on
the other side consistent with our grammars 2. The
production of L(?) over all rules observed in a
derivation D measures the prior distribution of D.
In the baseline model, as a special case, we can see
that L(?) is a constant function.
The motivation is straightforward since some
derivations should be preferred over others. One
may make an analogy between our prior derivation
distributions to non-uniform source side segmenta-
tion models in phrase-based systems. However, it
should be noted that prior derivation models influ-
ence not only on phrase choices as what segmenta-
tion models do, but also on ordering options due to
the nonterminal usage in syntax-based models.
In principle, some quantitative schemes are
needed to evaluate the monolingual derivation prior
probability. Our scheme links the source side deriva-
tion prior probability with the expected ambiguity
on target side generation when mapping the source
side to target side given the derivation. That is, a
given source side derivation is favored if it intro-
duces less ambiguity on target generation compared
to others.
Let us revisit the rules in Eq. 2. We notice that
the same source side maps into different target or-
ders depending on the syntactic role (e.g., NP or PP)
of X2 in the rule. Furthermore, the following areexample rules trained from real data (see Sec. 5):
X ? ?X1passX2, X1gei (give)X2? (6)
X ? ?X1passX2, X1jingguo (traverse)X2? (7)
X ? ?X1passX2, X1piao (ticket)X2? (8)
Above three rules cover pretty well for different us-
ages of pass in English and its correspondence in
Chinese. Typically, applying the rule to inputs such
as ?my pass expired? obtains reasonable translations
with baseline models. However, it will fail on inputs
like ?my pass to the zoo? as none of th rules provides
a correct translation of X1X2piao (ticket) when X2is a prepositional phrase.
Such linguistic phenomena, among others, indi-
cates that the higher variation of syntax structures
2In general, we can plug in either L(X ?< ?, ? >) or
L(X ?< ?, ? >) here. For illustration purposes, we assume
that the model is on the source side.
the nonterminal embodies, the more translation op-
tions on target side needed to account for various
syntactic roles on source side. This suggests that
our prior derivation models should prefer nonter-
minals that cover more syntactically homogeneous
constituents. Such a model is thus proposed in
Sec. 4.1.
The prior derivation model can also be viewed
as a smoothing on rule translation probabilities esti-
mated using heuristics, as we mentioned in Sec. 3.1.
When there are more translation options, we deem
that there are more ambiguity for this rule. In cases
where some dominating translation option is overes-
timated from hypothesized distributions, all transla-
tion options of this rule are discounted as they are
less favored by prior derivation models.
4.1 Model Syntactic Variations
Each abstract rule is generalized from a set of origi-
nal relevant phrase pairs by grouping an appropriate
set of sub-phrases into a nonterminal symbol, with
each sub-phrase linked to a tree list. Therefore, the
joined tree lists form a forest for this nonterminal
symbol in the rule. For every abstract rule, we de-
fine the rule forest to be the set of tree fragments of
all sub-phrases abstracted within this rule.
We parse the English side of parallel corpus to ob-
tain a syntactic tree for each English sentence. For
each phrase extracted from this sentence, we de-
fine the tree fragment for this phrase as the mini-
mal set of internal tree whose leaves span exactly
over this phrase. As a common practice, we pre-
serve all phrase pairs in BP including those who
are not consistent with parser sub-trees. Therefore,
there will be many phrases that cross over syntactic
sub-trees, which subsequently produced tree frag-
ments lacking a root. We label those as ?incom-
plete? tree fragments, and introduce a parent node of
?INC? on top of them to form a single-rooted sub-
tree. For example, Fig. 2 shows the tree fragments
for phrases of ?reading books? and ?enjoy reading?,
where the latter is an ?incomplete? tree fragment.
Moreover, for sentences failed on parsing, we la-
bel all phrases extracted from those sentences with a
root of ?EMPTY?.
Subset trees of tree fragments are defined as any
sub-graph that contains more than one nodes, with
the restriction that entire rule productions must be
23
(a) S


HH
H
NP
PRP
I
VP


HH
H
VBP
enjoy
NP
 HHNN
reading
NNS
books
(b) NP
 HHNN
reading
NNS
books
(c) INC
 HHVBP
enjoy
NN
reading
Figure 2: Syntax parsing tree (a) and tree fragments for
phrases ?reading books? (b) and ?enjoy reading? (c).
NP
 HHNN
reading
NNS
books
NP
 HHNN
reading
NNS
NP
 HHNN NNS
books
NP
 HHNN NNS
NN
reading
NNS
books
Figure 3: Subset trees of the NP covering ?reading
books?.
included (Collins and Duffy, 2002). Fig. 3 enumer-
ates a list of subset trees for fragment (b) in Fig. 2.
To measure syntactic homogeneity, we define the
fragment similarity K(T1, T2) as the number ofcommon subset trees between two tree fragments T1and T2. Conceptually, if we enumerate all possiblesubset trees 1, . . . ,M , we can represent each tree
fragment T as a vector h(T ) = (c1, . . . , cM ) witheach element as the count of occurrences of each
subset tree in T . Thus, the similarity can be ex-
pressed by the inner products of these two vectors.
Note that M will be a huge number for our problem,
and thus we need kernel methods presented below to
make computation tractable.
4.2 Kernel Methods
Collins and Duffy (Collins and Duffy, 2002) intro-
duced a method employing convolution kernels to
measure similarity between two trees in terms of
their sub-structures. If we define an indicator func-
tion Ii(n) to be 1 if subset tree i is rooted at node nand 0 otherwise, we have:
K(T1, T2) =
?
n1?N1
?
n2?N2
C(n1, n2) (9)
where C(n1, n2) = ?i Ii(n1)Ii(n2) and N1, N2are the set of nodes in the tree fragment T1 and T2respectively. It is noted that C(n1, n2) can be com-puted recursively (Collins and Duffy, 2002):
1. C(n1, n2) = 0 if the productions at n1 and n2are different;
2. C(n1, n2) = 1 if the productions at n1 and n2are the same and both are pre-terminals;
3. Otherwise,
C(n1, n2) = ?
nc(n1)
?
j=1
(1 + C(chjn1 , ch
j
n2)) (10)
where chjn1 is the jth child of node n1, nc(n1) isthe number of children at n1 and 0 < ? ? 1 is adecay factor to discount the effects of deeper tree
structures.
In principle, the computational complexity of
Eq. 10 is O(|N1| ? |N2|). However, as noted by(Collins and Duffy, 2002), the worst case is quite un-
common to natural language syntactic trees. More
recently, Moschitti (Moschitti, 2006) introduced in
details a fast implementation of tree kernels, where a
node pair set is first constructed for those associated
with same production rules. Our work follows Mos-
chitti?s implementation, which runs in linear time on
average. We compute the normalized similarity as
K ?(T1, T2) = K(T1,T2)?K(T1,T1)?
?
K(T2,T2)
to ensure simi-
larity is normalized between 0 and 1.
4.3 Prior Derivation Cost
First we define the purity of a nonterminal forest
(with respect to a given rule) Pur(X) as the aver-
age similarity of all tree fragments in the cluster:
Pur(X) = 2N(N ? 1)
?
j
?
i<j
K ?(Ti, Tj), (11)
where N is number of tree fragments in the forest of
X . We now can define the derivation cost L(X ?<
24
?, ? >) for a rule production as:
L(X ?< ?, ? >) =
? log(( min
X1,X2??
(Pur(X1), Pur(X2)))k), (12)
where k ? 1 is the degree of smoothness. Note that
the prior derivation cost is set as L(?) = 0 by defini-
tion for phrasal rules.
Eq. 11 is quadratic complexity with N , however,
we note that rules with a large N will typically score
poorly on prior derivation models, and thus we can
avoid the computation for those by assigning them
a large cost. With the fast kernel computation, the
training procedure involved with the prior derivation
models for the task presented in Sec. 5 is about 5
times slower on a single machine, compared with
the training of the baseline system. However, we
note that our training procedure can be computed in
parallel, and therefore the training speed is not a bot-
tleneck when multiple CPUs are available.
5 Experiments
We perform our experiments on an English-to-
Chinese translation task in travel domain. Our train-
ing set contains 482017 parallel sentences (with
4.4M words on the English side), which are col-
lected from transcription and human translation of
conversations. The vocabulary size is 37K for En-
glish and 44K for Chinese after segmentation.
Our evaluation data is a held out data set of 2755
sentences pairs. We extracted every one out of two
sentence pairs into the dev-set, and left the remain-
der as the test-set. We thereby obtained a dev-set of
1378 sentence pairs, and a test-set with 1377 sen-
tence pairs. In both cases, there are about 15K run-
ning words on English side. All Chinese sentences
in training, dev and test sets are all automatically
segmented into words. Minimum-error-rate training
(Och, 2003) are conducted on dev-set to optimize
feature weights maximizing the BLEU score up to 4-
grams, and the obtained feature weights are blindly
applied on the test-set. To compare performances
excluding tokenization effects, all BLEU scores are
optimized (on dev-set) and reported (on test-set) at
Chinese character-level.
From training data, we extracted an initial phrase
pair set with 3.7M entries for phrases up to 8 words
on Chinese side. We trained a 4-gram language
model for Chinese at word level, which is shared by
all translation systems reported in this paper, using
the Chinese side of the parallel corpus that contains
around 2M segmented words.
We compare the proposed models with two base-
lines: a state-of-the-art phrase-based system and a
formal syntax-based system as described in Sec. 3.
The phrase-based system employs the 3.7M phrase
pairs to build the translation model, and it con-
tains a total set of 8 features, most of which are
identical to our baseline formal syntax-based model.
The difference only lies on that the glue and ab-
straction penalty are not applicable for phrase-based
system. Instead, a lexicalized reordering model is
trained from the word-aligned parallel corpus for
the phrase-based system. More details about our
multiple-graph based phrasal SMT can be found in
(Zhou et al, 2006; Zhou et al, 2008). For the base-
line syntax-based system, we generated a total of
15M rules and used 9 features.
We chose the Stanford parser (Klein and Man-
ning, 2002) as the English parser in our experiments
due to its high accuracy and relatively faster speed.
It was trained on the Wall Street Journal section of
the Penn Treebank. During the parsing, the input
English sentences were tokenized first, in a style
consistent with the data in the Penn Treebank.
We sent 482017 English sentences to the parser.
There were 1221 long sentences failed, less than
0.3% of the whole set. After the word alignment
and phrase extraction on the parallel corpus, we ob-
tained 2.2M unique English phrases. Among them
there are about 34K phrases having an empty tree
in their corresponding tree lists, due to the failure
in parsing. The number of unique tree fragments
for English phrases is 2.5M. Out of them there are
750K marked as incomplete. As mentioned previ-
ously, each rule covers a set of phrases, with each
phrase linked to a tree list. The total number of rules
with unique English side is around 8M.
The distribution of the number of rules over the
number of corresponding trees is shown in Table 1.
We observe that the majority of rules in our model
has less than 150 tree fragments. Therefore, consid-
ering the quadratic complexity in Eq. 11, we pun-
ish the rules with more than 150 unique tree frag-
ments with some floor cluster purity to speed up
25
Table 1: Distribution of rules over trees
Number of trees Number of rules
(0, 10] 3636766
(10, 20] 1556806
(20, 30] 989848
(30, 40] 916606
(40, 50] 488469
(50, 60] 270484
(60, 70] 198438
(70, 80] 86921
(80, 90] 58280
(90, 100] 29147
(100, 150] 437231
> 150 81060
the training. Not surprisingly, the rules with a large
number of tree fragments are typically those with
few stop words as terminals. For instance, the rule
X ?< X1aX2, ? > comes with more than 100Ktrees for the X1.
Table 2: English-to-Chinese BLEU score result on test-
set (character-based)
Models BLEU(4-gram)
Phrase-based 42.11
Formally Syntax-based 43.75
Formally Syntax-based
with prior derivation 44.51
Translation results are presented in Table 2
with character-based BLEU scores using 2 refer-
ences. Our baseline formally syntax-based mod-
els achieved the BLEU score of 43.75, an abso-
lute improvement of 1.6 point improvement over
phrase-based models. The improvement is statisti-
cally significant with p < 0.01 using the sign-test
described by (Collins et al, 2005). Applying the
prior derivation model into the syntax-based system,
BLEU score is further improved to 44.51, obtained
an another absolute improvement of 0.8 point, which
is also significantly better than our baseline syntax-
based models (p < 0.05).
6 Discussion and Summary
We introduced a prior derivation model to enhance
formally syntax-based SCFG for translation. Our
approach links a prior rule distribution with the syn-
tactic variations of abstracted sub-phrases, which
is modeled by distance measuring of linguistically
syntax parsing tree fragments using kernel meth-
ods. The proposed model has improved translation
performance over both phrase-based and formally
syntax-based models. Moreover, such a prior dis-
tribution can also be used to rank and prune SCFG
rules to reduce memory usage for online translation
systems based on syntax-based models.
Although the experiments in this paper are con-
ducted for prior derivation models on source side
in an English-to-Chinese task, we are interested in
applying this to foreign-to-English models as well.
As what we pointed out in Sec. 4, target side prior
derivation model fits with our framework as well.
7 Acknowledgement
The authors would like to thank Stanley F. Chen and
the anonymous reviewers for their helpful comments
on this paper.
References
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Comput. Linguist., 33(2):201?228.
Michael Collins and Nigel Duffy. 2002. Convolution
kernels for natural language. In Advances in Neural
Information Processing Systems 14.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proc. of ACL, pages 531?540.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In Proc.
of HLT/NAACL-04, Boston, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proc. of
ACL, pages 961?968.
Daniel Gildea. 2003. Loosely tree-based alignment for
machine translation. In Proc. of ACL, pages 80?87.
Dan Klein and Christopher D. Manning. 2002. Fast exact
inference with a factored model for natural language
parsing. In NIPS, pages 3?10.
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proc.
NAACL/HLT.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proc. of ACL, pages 609?616.
26
Alessandro Moschitti. 2006. Making tree kernels practi-
cal for natural language learning. In Proc. of EACL.
F. J. Och and H. Ney. 2000. Improved statistical align-
ment models. In Proc. of ACL, pages 440?447, Hong
Kong, China, October.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Comput. Linguist., 30(4):417?449.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. of ACL, pages
160?167.
Giorgio Satta and Enoch Peserico. 2005. Some computa-
tional complexity results for synchronous context-free
grammars. In Proc. of HLT/EMNLP, pages 803?810.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Comput. Linguist., 23(3):377?403.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proc. of ACL, pages
523?530.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. of HLT/NAACL, pages 256?263.
Bowen Zhou, Stan F. Chen, and Yuqing Gao. 2006. Fol-
som: A fast and memory-efficient phrase-based ap-
proach to statistical machine translation. In IEEE/ACL
Workshop on Spoken Language Technology.
Bowen Zhou, Rong Zhang, and Yuqing Gao. 2008. Lex-
icalized reordering in multiple-graph based statistical
machine translation. In Proc. ICASSP.
27
Coling 2010: Poster Volume, pages 180?188,
Beijing, August 2010
Two Methods for Extending Hierarchical Rules from the Bilingual Chart
Parsing
Martin ?Cmejrek and Bowen Zhou
IBM T. J. Watson Research Center
{martin.cmejrek, zhou}@us.ibm.com
Abstract
This paper studies two methods for train-
ing hierarchical MT rules independently
of word alignments. Bilingual chart pars-
ing and EM algorithm are used to train bi-
text correspondences. The first method,
rule arithmetic, constructs new rules as
combinations of existing and reliable rules
used in the bilingual chart, significantly
improving the translation accuracy on the
German-English and Farsi-English trans-
lation task. The second method is pro-
posed to construct additional rules directly
from the chart using inside and outside
probabilities to determine the span of the
rule and its non-terminals. The paper also
presents evidence that the rule arithmetic
can recover from alignment errors, and
that it can learn rules that are difficult to
learn from bilingual alignments.
1 Introduction
Hierarchical phrase-based systems for machine
translation usually share the same pattern for ob-
taining rules: using heuristic approaches to ex-
tract phrase and rule pairs from word alignments.
Although these approaches are very successful
in handling local linguistic phenomena, handling
longer distance reorderings can be more difficult.
To avoid the combinatorial explosion, various re-
strictions, such as limitations of the phrase length
or non-terminal span are used, that sometimes pre-
vent from extracting good rules. Another reason
is the deterministic nature of those heuristics that
does not easily recover from errors in the word
alignment.
In this work, we learn rules for hierarchical
phrase based MT systems directly from the par-
allel data, independently of bilingual word align-
ments.
Let us have an example of a German-English
sentence pair from the Europarl corpus (Koehn,
2005).
(1) GER: die herausforderung besteht darin
diese systeme zu den besten der welt zu
machen
ENG: the challenge is to make the system
the very best
The two pairs of corresponding sequences diese
systeme ... der welt?the system ... best and zu
machen?to make are swapped. We believe that
the following rule could handle long distance re-
orderings, still with a reasonably low number of
terminals, for example:
(2) X ? ?besteht darin X1 zu X2, is to X2X1?,
There are 127 sentence pairs out of 300K of the
training data that contain this pattern, but this rule
was not learned using the conventional approach
(Chiang, 2007). There are three potential risks:
(1) alignment errors (the first zu aligned to to, or
der welt (of the world) aligned to null); (2) maxi-
mum phrase length for extracting rules lower than
11 words; (3) requirement of non-terminals span-
ning at least 2 words.
The rule arithmetic (Cmejrek et al, 2009) con-
structs the new rule (2) as a combination of good
rule usages:
(3) X ? ?besteht darin, is ?
X ? ?X1 zu X2, to X2X1?
180
The approach consists of bilingual chart parsing
(BCP) of the training data, combining rules found
in the chart using a rule arithmetic to propose new
rules, and using EM to estimate rule probabilities.
In this paper, we study the behavior of the
rule arithmetic on two different language pairs:
German-English and Farsi-English. We also pro-
pose an additional method for constructing new
rules directly from the bilingual chart, and com-
pare it with the rule arithmetic.
The paper is structured as follows: In Sec. 1, we
explain our main motivation, summarize previous
work, and briefly introduce the formalism of hi-
erarchical phrase-based translation. In Sec. 2, we
describe the bilingual chart parsing and the EM
algorithm. The rule arithmetic is introduced in
Sec. 3. The new method for proposing new rules
directly from the chart is described in Sec. 4. The
experimental setup is described in Sec. 5. Results
are thoroughly discussed in Sec. 6. Finally, we
conclude in Sec. 7.
1.1 Related work
Many previous works use the EM algorithm to
estimate probabilities of translation rules: Wu
(1997) uses EM to directly estimate joint word
alignment probabilities of Inversion Transduction
Grammar (ITG). Marcu and Wong (2002) use
EM to estimate joint phrasal translation model
(JPTM). Birch et al (2006) reduce its com-
plexity by using only concepts that match the
high-confidence GIZA++ alignments. Similarly,
Cherry and Lin (2007) use ITG for pruning. May
and Knight (2007) use EM algorithm to train tree-
to-string rule probabilities, and use the Viterbi
derivations to re-align the training data. Huang
and Zhou (2009) use EM to estimate conditional
rule probabilities P (?|?) and P (?|?) for Syn-
chronous Context-free Grammar. Others try to
overcome the deterministic nature of using bilin-
gual alignments for rule extraction by sampling
techniques (Blunsom et al, 2009; DeNero et al,
2008). Galley et al (2006) define minimal
rules for tree-to-string translation, merge them
into composed rules (similarly to the rule arith-
metic), and train weights by EM. While in their
method, word alignments are used to define all
rules, rule arithmetic proposes new rules indepen-
dently of word alignments. Similarly, Liu and
Gildea (2009) identify matching long sequences
(?big templates?) using word alignments and ?lib-
erate? matching small subtrees based on chart
probabilities. Our method of proposing rules di-
rectly from the chart does not use word alignment
at all.
1.2 Formally syntax-based models
Our baseline model follows the Chiang?s hierar-
chical model (Chiang, 2007; Chiang, 2005; Zhou
et al, 2008) based on Synchronous Context-free
Grammar (SCFG). The rules have form
X ? ??, ?,??, (4)
where X is the only non-terminal in the gram-
mar, ? and ? are source and target strings with
terminals and up to two non-terminals, ? is the
correspondence between the non-terminals. Cor-
responding non-terminals have to be expanded at
the same time.
2 Bilingual chart parsing and EM
algorithm
In this section, we briefly overview the algorithm
for bilingual chart parsing and EM estimation of
SCFG rule features.
Let e = eM1 and f = fN1 of source and tar-
get sentences. For each sentence pair e, f , the ?E?
step of the EM algorithm will use the bilingual
chart parser to enumerate all possible derivations
?, compute inside probabilities ?ijkl(X) and out-
side probabilities ?ijkl(X), and finally calculate
expected counts c(r) how many times each rule r
produced the corpus C .
The inside probabilities can be defined recur-
sively and computed dynamically during the chart
parsing:
?ijkl =
?
??tijkl
P (?.r)
?
(i?j?k?l?)??.bp
?i?j?k?l? , (5)
where tijkl represents the chart cell spanning
(eji , f lk), and the data structure ? stores the rule
?.r. If r has non-terminals, then ?.bp stores back-
pointers ?.bp1 and ?.bp2 to the cells representing
their derivations.
181
The outside probabilities can be computed re-
cursively by iterating the chart in top-down order-
ing. We start from the root cell ?1,M,1,N := 1 and
propagate the probability mass as
??.bp1+ = P (?.r)?ijkl (6)
for rules with one non-terminal, and
??.bp1 + = P (?.r)?ijkl??.bp2 , (7)
??.bp2 + = P (?.r)?ijkl??.bp1 , (8)
for rules with two non-terminals. The top-down
ordering ensures that each ?ijkl accumulates up-
dates from all cells higher in the chart before its
own outside probability is used.
The contributions to the rule expected counts
are computed as
c(?.r)+ = P (?.r)?ijkl
??.n
i=1 ??.bpi
?1,M,1,N
. (9)
Finally, rule probabilities P (r) are obtained by
normalizing expected counts in the ?M? step.
To improve the grammar coverage, the rule-
set is extended by the following rules providing
?backoff? parses and scoring for the SCFG rules:
(10) ?X1,X1f?, ?X1, fX1?, ?X1e,X1?,
?eX1,X1?,
(11) ?X1X2,X2X1?.
Rules (10) enable insertions and deletions, while
rule (11) allows for aligning swapped constituents
in addition to the standard glue rule.
3 Proposing new rules with rule
arithmetic
The main idea of this work is to propose new rules
independently of the bilingual word alignments.
We parse each sentence pair using the baseline
ruleset extended by the new rule types (10) and
(11). Then we select the most promising rule us-
ages and combine each two of them using the
rule arithmetic to propose new rules. We put the
new rules into a temporary pool, and parse and
compute probabilities and expected counts again,
this time we use rules from the baseline and from
the temporary pool. Finally, we dump expected
counts for proposed rules, and empty the tempo-
rary pool. This way we can try to propose many
rules for each sentence pair, and to filter them later
using accumulated expected counts from the EM.
The term most promising is purposefully vague
? to cover all possible approaches to filtering rule
usages. In our implementation, we are limited by
space and time, and we have to prune the number
of rules that we can combine. We use expected
counts as the main scoring criterion. When com-
puting the contributions to expected counts from
particular rule usages as described by (9), we re-
member the n-best contributors, and use them as
candidates after the expected counts for the given
sentence pair have been estimated.
The rule arithmetic combines existing rules us-
ing addition operation to create new rules. The
idea is shown in Example 12.
(12) Addition
?5, 13, 5, 11, 13, 13? ?4, 10, 6, 10, 5, 5? X ? ?X1 zu X2, to X2 X1?
?5, 11, 6, 11, 0, 0? ?6, 10, 7, 10, 0, 0? X ? ?diese X1, the X1?
1: ... 4 5 6 ... 11 12 13 3 4 5 6 7 ... 10
2: ... 0 -1 -1 ... -1 zu -2 0 to -2 -1 -1 ... -1
3: ... 0 diese -3 ... -3 0 0 0 0 0 the -3 ... -3
4: ... 0 diese -3 ... -3 zu -2 0 to -2 the -3 ... -3
5: ?5, 13, 6, 11, 13, 13? ?4, 10, 7, 10, 5, 5? X ? ?diese X1 zu X2, to X2 the X1?
First, create span projections for both source
and target sides of both rules. Use symbol 0 for
all unspanned positions, copy terminal symbols as
they are, and use symbols -1, -2, -3, and -4 to tran-
scribe X1 and X2 from the first rule, and X1 and
X2 from the second rule. Repeat the non-terminal
symbol on all spanned positions. In Example 12
line 1 shows the positions in the sentence, lines 2
and 3 show the rule span projections of the two
rules.
Second, merge source span projections (line 4),
record mappings of non-terminal symbols. We re-
quire that merged projections are continuous. We
allow substituting non-terminal symbols by termi-
nals, but we require that the whole span of the
non-terminal is fully replaced. In other words,
shortenings of non-terminal spans are not allowed.
Third, collect new rule. The merged rule us-
ages (lines 5) are generalized into rules, so that
they are not limited to the particular span for
which they were originally proposed.
The rule arithmetic can combine all types of
rules ? phrase pairs, abstract rules, glues, swaps,
insertions and deletions. However, we require that
182
at least one of the rules is either a phrase pair or
an abstract rule.
4 Proposing directly from chart
One of the issues observed while proposing new
rules with the rule arithmetic is the selection of the
best candidates. The number of all candidates that
can be combined depends on the length of the sen-
tence pair and on the number of competing pars-
ing hypotheses. Using a fixed size of the n-best
can constitute a risk of selecting bad candidates
from shorter sentences. On the other hand, the
spans of the best candidates extracted from long
sentences can be far from each other, so that most
combinations are not valid rules (e.g., the combi-
nation of two discontinuous phrasal rules is not
defined).
In our new approach we propose new rules di-
rectly from the bilingual chart, relying on the in-
side and outside probabilities computed after the
parsing of the sentence pair. The method has two
steps. In the first step we identify best matching
parallel sequences; in the second step we propose
?holes? for non-terminals.
4.1 Identifying best matching sequences
To identify the best matching sequences, we score
all sequences (eji , f lk) by a scoring function:
scoreijkl =
?ijkl?ijkl
?1,M,1,N
Lex(i, j, k, l), (13)
where the lexical score is defined as:
Lex(i, j, k, l) =
N?
j?=1
M?
i?=0
t(fj?|ei?)?ijkli?j? (14)
The t is the lexical probability from the word-to-
word translation table, and ?ijkli?j? is defined as
?ins if i? ? ?i, j? and j? ? ?k, l?, and as ?out if
i? /? ?i, j? and j? /? ?k, l?, and as 0 elsewhere.
The purpose of this function is to score only the
pairs of words that are both either from within the
sequence or from outside the sequence. Usually
0 ? ?out ? ?ins to put more weight on words
within the parallel sequence.
The scoring function is a combination of ex-
pected counts contribution of a sequence (eji , f lk)
estimated from the chart with the IBM Model 1
lexical score.
Since only the sequences spanned by filled
chart cells can have non-zero expected counts,
we can select the n-best matching sequences rela-
tively efficiently.
4.2 Proposing non-terminal positions
Similar approach can be used to propose best po-
sitions for non-terminals. We score every com-
bination of non-terminal positions. The expected
counts can be estimated using Eq. 9. Since we are
proposing new rules, the probability P (r) used in
that equation is not defined. Again, we can use
Model 1 score instead, and use the following scor-
ing function:
sijkl(bp1, bp2) = (15)
Lex(i,j,k,l,bp1,bp2)?ijkl?bp1?bp2
?1,M,1,N ,
Lex(i, j, k, l, bp1 , bp2) is defined as in Eq. 14.
This time using 0 ? ?out ? ?NT1 = ?NT2 ?
?term, restricting the IBM Model 1 to score only
word pairs that both belong either to the terminals
of the proposed rule, or to the sequences spanned
by the same non-terminal, or outside of the rule
span. The scoring function for rules with one non-
terminal is just a special case of 15.
Again, the candidates can be scored efficiently,
taking into account only those combinations of
non-terminal spans that correspond to filled cells
in the chart.
The proposed method is again independent of
bilingual alignment, but at the same time utilizes
the information obtained from the bilingual chart
parsing.
5 Experiments
We carried out experiments on two language pairs,
German-English and Farsi-English.
The German-English data is a subset (297k
sentence pairs) of the Europarl (Koehn, 2005) cor-
pus. Since we are focused on speech-to-speech
translation, the punctuation was removed, and the
text was lowercased. The dev set and test set con-
tain each 1k sentence pairs with one reference.
The word alignments were trained by GIZA++
toolkit (Och and Ney, 2000). Phrase pairs were
183
extracted using grow-diag-final (Koehn et al,
2007). The baseline ruleset was obtained as
in (Chiang, 2007). The maximum phrase length
for rule extraction was set to 10, the minimum re-
quired non-terminal span was 2.
Additional rules for insertion, deletion, and
swap were added to improve the parsability of the
data, and to help EM training and rule arithmetic.
However, these rules are not used by the decoder,
since they would degrade the performance.
New rules were proposed after the first iteration
of EM1, either by rule arithmetic or directly from
the chart.
Only non-terminal rules proposed by the rule
arithmetic from at least two different sentence
pairs and ranked (by expected counts c(r)) in the
top 100k were used. Figure 4 presents a sample of
the new rules.
New rules were also proposed directly from the
chart, using the approach in Sec. 4. 5% of best
matching parallel sequences, and 5 best scoring
rules were selected from each parallel sequence.
Non-terminal rules from the 200k-best rank were
added to the model. Figure 5 presents a sample of
the new rules.
Finally, one more iteration of EM was used to
adjust the probabilities of the new and baseline
rules. These probabilities were used as features
in the decoding.
The performance of rule arithmetic was also
verified on Farsi-English translation. The train-
ing corpus contains conversational spoken data
from the DARPA TransTac program extended
by movie subtitles and online dictionaries down-
loaded from the web (297k sentence pairs). The
punctuation was removed, and the text was low-
ercased. The dev set is 1,420 sentence pairs held
out from the training data, with one reference. The
test set provided by NIST contains 470 sentences
with 4 references. The sentences are about 30%
longer and more difficult.
The training pipeline was the same as for the
German-English experiments. 122k new non-
terminal rules were proposed using the rule arith-
metic.
1Since our initial experiments did not show any signifi-
cant gain from proposing rules after additional (lengthy) it-
erations of EM.
The feature weights were tuned on the dev
set for each translation model separately. The
translation quality was measured automatically by
BLEU score (Papineni et al, 2001).
6 Discussion of results
The BLEU score results are shown in the Ta-
ble 3. The cumulative gain of rule arithmetic and
EM (RA + EM-i0) is 1 BLEU point for German-
English translation and 2 BLEU points for Farsi-
English. The cumulative gain of rules proposed
from the chart (DC + EM-i0) is 0.2 BLEU points
for German-English. For comparison of effects of
various components of our method, we also show
scores after the first five iterations of EM (EM-i0?
EM-i4) without adding any new rules, just using
EM-trained probabilities as feature weights, and
also scores for new rules added into the baseline
without adjusting their costs by EM (RA).
The qualities of proposed rules are discussed in
this section.
6.1 German-English rules from rule
arithmetic
The Figure 4 presents a sample of new rules pro-
posed during this experiment. The table is di-
vided into three parts, presenting rules from the
top, middle, and bottom of the 100K list. The
quality of the rules is high even in the middle part
of the table, the tail part is worse.
We were surprised by seeing short rules consist-
ing of frequent words. For example ?um X1, in
order X1?. When looking into word-level align-
ments, we realized that these rules following the
pattern 16 prevent the baseline approach from ex-
tracting the rule.
(16)
GER: um Obj zu V
ENG: in order to V Obj
Similarly many other rules match the pattern of
beginning of a subordinated clause, such as that is
why, or insertions, such as of course, which both
have to be strictly followed by VSO construction
in German, in contrast to the SVO word order in
English.
We also studied the cases of rule arithmetic cor-
recting for systematic word alignment errors. For
184
example the new rule ?X1 zu koennen, to X1? was
learned from the sentence
(17)
um die in kyoto vereinbarten senkungen beibehalten zu koennen
in order to maintain the reductions agreed in kyoto
The English translation often uses a different
modality, thus the modal verb koennen is always
aligned with null. Since unaligned words are usu-
ally not allowed at the edges of sub-phrases gener-
alized into non-terminals (Chiang, 2007), this rule
cannot be learned by the baseline.
We observe that many new proposed rules cor-
respond to patterns with a non-terminal spanning
one word. For example ?um X1 zu X2, to X2
X1? corresponds to the same pattern 16, where X2
spans one verb. The line baseline min1 in the Ta-
ble 3 shows 0.3 BLEU improvement of a model
trained without the minimum non-terminal span
requirement. However, this improvement comes
at a cost of more than four times increased model
size, as shown in Table 2. We observe that us-
ing the minimum span requirement while learning
from bitext alignments combined with rule arith-
metic that can learn the most reliable rules span-
ning one word yields better performance in speed,
memory, and precision.
We can also study the new rules quantitatively.
We want to know how the rules proposed by the
rule arithmetic are used in decoding. We traced
the translation of the 1,000 test set sentences to
mark the rules that were used to generate the best
scoring hypotheses.
The stats are presented in the Table 1. The
chance that a new rules will be used in the test set
decoding (0.86%) is more than 7 times higher than
that of all rules (0.12%). Encouraging evidence is
that while the rule arithmetic rules constitute only
1.87% of total rules, they present 9.17% of rules
used in the decoding.
The Figure 1 lists the most frequently used new
rules in the decoding. We can see many rules
with 2 non-terminals that model complex verb
forms (?wird X1 haben,will have X1?), reorder-
ing in clauses (?um X1 zu gewaehrleisten, to en-
sure X1?), or reordering of verbs from the second
position in German to SVO in English (?heute X1
wir X2, today we X1 X2?).
RA Ger. DC Ger. RA Farsi
Sentences translated 1,000 1,000 417
|ALL| (all rules) 5.359,751 5.459,751 8.532,691
|NEW| (new rules) 100,000 200,000 121,784
|NEW|
|ALL| 1.87% 3.66% 1.43%
|hits ALL| 10,122 7,256 2,521
|glue| 2,910 271 267
|hits ALL unique| 6.303 6,433 2,058
|hits ALL unique|
|ALL| 0.12% 0.12% 0.02
|hits NEW| 928 1,541 125
|hits NEW unique| 858 1,504 110
|hits NEW unique|
|NEW| 0.86% 0.75 % 0.09
|hits NEW|
|hits ALL| 9.17% 21.23% 4.96%
|terminals from NEW| 4,385 7,825 407
|terminals from NEW|
|hits NEW| 4,73 5.08 3.26
Table 1: Rule hits for 1,000 test set.
Model #phrases #rules
Ger-Eng baseline 8.5M 5.3M
Ger-Eng baseline min1 8.5M 23.M
Table 2: Model sizes.
We also studied the correlation between the
rank of the proposed rules (ranked by expected
counts) and the hit rate during the decoding. The
Figure 2 measures the hit rate for each of 1,000
best ranking rules, and should be read as follows:
the rules ranking 0 to 999 were used 70 times, the
hit rate decreases as the rank grows so that there
were no hits for rules ranking 90k and more. The
rank is a good indicator of the usefulness of new
rules.
We hypothesize that the new rules are capable
of combining partial solutions to form hypothe-
ses with better word order, or better complex verb
forms so that these hypotheses are better scored
and are parts of the winning solutions more often.
6.2 German-English rules proposed directly
from the chart
We also studied why the rules proposed directly
from the bilingual chart yield smaller improve-
ment than the rule arithmetic. The number of new
rules used in the decoding (1,541) is even higher
than that of the rule arithmetic, and it constitutes
21.23% of all cases. The two experiments were
185
#hits Ger Eng
5 X1 stellt X2 dar X1 is X2
3 X1 sowohl X2 als auch X1 both X2 and
3 X1 ist es X2 it is X2 X1
3 X1 die X2 ist X1 which is X2
2 wird X1 haben will have X1
2 wir X1 damit X2 we X1 so that X2
2 was X1 hat X2 what X1 has X2
2 was X1 betrifft so as regards X1
2 und X1 muessen wir X2 and X1 we must X2
2 um X1 zu gewaehrleisten to ensure X1
2 um X1 zu X2 to X2 X1
2 sowohl X1 als auch both X1 and
2 sie X1 auch X2 they also X1 X2
2 in erster linie X1 X1 in the first instance
2 in X1 an in X1
2 ich X1 meine i X1
2 heute X1 wir X2 today we X1 X2
2 herr praesident X1 und herren mr president X1 and gentlemen
2 gleich X1 X1 a moment
2 es muss X1 werden it must be X1
Figure 1: Examples of the most frequently hit
rules during the decoding.
tuned separately, so that they used different glue
rule weights. That is why we observe the differ-
ence in the number of glues (and the number of
total rules) in the Table 1. We do not observe any
significant correlation between the rank of the rule
and the hit rate. The Figure 3 shows that the first
10k-ranked rules are hit several times, and then
the hit rate stays flat.
We offer an explanation based on our observa-
tions of rules used for the decoding. The rules
proposed directly from the chart contain a big por-
tion of content words. These rules do not capture
any important differences between the structures
of the two languages that could not be handled
by phrasal rules as well. For example, the rule
?die neuen vorschriften sollen X1,the new rules
are X1? is correct, but a combination of a baseline
phrasal rule and glue will produce the same result.
We also see many rules with non-terminals
spanning one word. For example, the sequence
(18) die europaeische kommission?the
european commission
will produce the rule
(19) ?die X1 kommission, the X1 commission?.
Although the sequence and the rule are high
scored by 13 and 15, we intuitively feel that gen-
Figure 2: Usage of new rules (RA).
Figure 3: Usage of new rules (DC).
eralizing the word european is not very helpful in
this context.
The rule arithmetic could propose the rule 19 as
(20) ?die X1, the X1? + ?kommission,
commission?,
but since the candidates for combination are se-
lected as rules with the highest expected counts
(Sec. 3), the rules 20 will most likely loose to the
phrase pair 18 and will not be selected.
To conclude our comparison, we observe that
both methods produce reliable rules that are of-
ten reused in decoding. Nevertheless, since the
rule arithmetic combines the most successful rules
from each parallel parse, the resulting rules enable
structural transformations that could not be han-
dled by baseline rules.
186
German-English Farsi-English
Model dev set test set dev set test set
baseline 23.9 25.4 41.1 38.2
RA + EM-i0 24.8 26.4 41.8 40.2
DC + EM-i0 24.6 25.6
EM-i0 24.4 26.1 40.8 39.1
EM-i1 24.4 25.8 41.3 38.5
EM-i2 24.4 25.9 41.4 38.2
EM-i3 24.4 26.0 41.3 39.3
EM-i4 24.4 26.0 41.6 39.6
RA 24.4 26.1 40.7 38.4
baseline min1 24.0 25.7
Table 3: BLEU scores
6.3 Farsi-English rules from the rule
arithmetic
Although we have only limited resources to quali-
tatively analyze the Farsi-English experiments, we
noticed that there are two major groups of new
rules.
The first group corresponds to the fact that Farsi
does not have definite article and allows pro-drop.
We observe many new rules that could not be
learned from word alignments, since some defi-
nite articles or pronouns in English were aligned
to null (and unaligned words are not allowed at the
edges of phrases). However, if the chart contains
an insertion (of the determiner or pronoun) with a
high expected count, the rule arithmetic may pro-
pose new rule by combining it with other rules.
The second group contains rules that help word
reordering. We observe rules moving verbs from
the S PP O V in Farsi into SVO in English as well
as rules reordering wh-clauses.
Most of the rules traced during the test set de-
coding belong to the second group. Figure 1
shows that the number of new rules hit during
the decoding is smaller compared to the German-
English experiments. On the other hand, the rules
have smaller number of terminals so that we as-
sume that the positive effect of these rules comes
from the reordering of non-terminals.
um X1 in order X1
natuerlich X1 of course X1
deshalb X1 this is why X1
X1 zu koennen to X1
X1 ist it is X1
nach der tagesordnung folgt die X1 the next item is the X1
herr X1 herr kommissar X2 mr X1 commissioner X2
die X1 der X2 X1 the X2
im gegenteil X1 on the contrary X1
nach der tagesordnung folgt X1 the next item is X1
X1 die X2 the X1 the X2
die X1 die the X1
ausserdem X1 in addition X1
daher X1 that is why X1
wir X1 nicht X2 we X1 not X2
die X1 der X2 the X2 X1
deshalb X1 for this reason X1
um X1 zu X2 to X2 X1
X1 nicht X2 werden X1 not be X2
Figure 4: Sample rules (RA).
ausserdem X1 wir we X1 also
die X1 des kommissars the commissioner ?s X1
den X1 ratsvorsitz the X1 presidency
ich hoffe dass X1 i would hope that X1
X1 ist zu X2 geworden X1 has become X2
die X1 des vereinigten koenigreichs the uk X1
X1 maij weggen X2 X1 maij weggen X2
X1 wir auf X2 sind X1 we are on X2
ich frage mich X1 i wonder X1
Figure 5: Sample rules (DC).
7 Conclusion
In this work, we studied two new methods for
learning hierarchical MT rules: the rule arith-
metic and proposing directly from the parse for-
est. We discussed systematic patterns where the
rule arithmetic outperforms alignment-based ap-
proaches and verified its significant improvement
on two different language pairs (German-English
and Farsi-English). We also hypothesized why the
second method ? proposing rules directly from the
chart ? improves the baseline less than the rule
arithmetic.
Acknowledgment
This work is partially supported by the DARPA
TRANSTAC program under the contract num-
ber NBCH2030007. Any opinions, findings, and
conclusions or recommendations expressed in this
material are those of the authors and do not nec-
essarily reflect the views of DARPA.
187
References
Birch, Alexandra, Chris Callison-Burch, Miles Os-
borne, and Philipp Koehn. 2006. Constraining the
phrase-based, joint probability statistical translation
model. In Proceedings on WSMT?06, pages 154?
157.
Blunsom, Phil, Trevor Cohn, Chris Dyer, and Miles
Osborne. 2009. A gibbs sampler for phrasal syn-
chronous grammar induction. In ACL ?09, pages
782?790.
Cherry, Colin. 2007. Inversion transduction grammar
for joint phrasal translation modeling. In NAACL-
HLT?07/SSST?07.
Chiang, David. 2005. A hierarchical phrase-
based model for statistical machine translation. In
ACL?05, pages 263?270.
Chiang, David. 2007. Hierarchical phrase-based
translation. Comput. Linguist., 33(2):201?228.
Cmejrek, Martin, Bowen Zhou, and Bing Xiang. 2009.
Enriching SCFG rules directly from efficient bilin-
gual chart parsing. In IWSLT?09, pages 136?143.
DeNero, John, Alexandre Bouchard-Co?te?, and Dan
Klein. 2008. Sampling alignment structure under
a bayesian translation model. In EMNLP ?08, pages
314?323.
Galley, Michel, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proc.
of ACL, pages 961?968.
Huang, Songfang and Bowen Zhou. 2009. An EM
algorithm for SCFG in formal syntax-based transla-
tion. In Proc. IEEE ICASSP?09, pages 4813?4816.
Koehn, Philipp, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In ACL.
Koehn, Philipp. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings
of MT Summit.
Liu, Ding and Daniel Gildea. 2009. Bayesian learning
of phrasal tree-to-string templates. In EMNLP ?09,
pages 1308?1317.
Marcu, Daniel and W Wong. 2002. A phrase-based,
joint probability model for statistical machine trans-
lation. In Proceedings of EMNLP?02.
May, Jonathan and Kevin Knight. 2007. Syntactic re-
alignment models for machine translation. In Pro-
ceedings of EMNLP-CoNLL?07, pages 360?368.
Och, F. J. and H. Ney. 2000. Improved statistical
alignment models. In Proc. of ACL, pages 440?447,
Hong Kong, China, October.
Papineni, K., S. Roukos, T. Ward, and W. Zhu. 2001.
Bleu: a method for automatic evaluation of machine
translation. Technical Report RC22176, IBM T. J.
Watson Research Center.
Wu, Dekai. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Zhou, Bowen, Bing Xiang, Xiaodan Zhu, and Yuqing
Gao. 2008. Prior derivation models for formally
syntax-based translation using linguistically syntac-
tic parsing and tree kernels. In Proceedings of the
ACL?08: HLT SSST-2, pages 19?27.
188
Coling 2010: Poster Volume, pages 828?836,
Beijing, August 2010
A Power Mean Based Algorithm for Combining Multiple
Alignment Tables
Sameer Maskey, Steven J. Rennie, Bowen Zhou
IBM T.J. Watson Research Center
{smaskey, sjrennie, zhou}@us.ibm.com
Abstract
Most existing techniques for combining
multiple alignment tables can combine
only two alignment tables at a time, and
are based on heuristics (Och and Ney,
2003), (Koehn et al, 2003). In this pa-
per, we propose a novel mathematical for-
mulation for combining an arbitrary num-
ber of alignment tables using their power
mean. The method frames the combi-
nation task as an optimization problem,
and finds the optimal alignment lying be-
tween the intersection and union of multi-
ple alignment tables by optimizing the pa-
rameter p: the affinely extended real num-
ber defining the order of the power mean
function. The combination approach pro-
duces better alignment tables in terms of
both F-measure and BLEU scores.
1 Introduction
Machine Translation (MT) systems are trained on
bi-text parallel corpora. One of the first steps
involved in training a MT system is obtaining
alignments between words of source and target
languages. This is typically done using some
form of Expectation Maximization (EM) algo-
rithm (Brown et al, 1993), (Och and Ney, 2003),
(Vogel et al, 1996). These unsupervised algo-
rithms provide alignment links between english
words ei and the foreign words fj for a given e?f
sentence pair. The alignment pairs are then used
to extract phrases tables (Koehn et al, 2003), hi-
erarchical rules (Chiang, 2005), or tree-to-string
mappings (Yamada and Knight, 2001). Thus, the
accuracy of these alignment links has a significant
impact in overall MT accuracy.
One of the commonly used techniques to im-
prove the alignment accuracy is combining align-
ment tables obtained for source to target (e2f ) and
target to source (f2e) directions (Och and Ney,
2003). This combining technique involves obtain-
ing two sets of alignment tables A1 and A2 for the
same sentence pair e ? f , and producing a new
set based on union A? = A1 ? A2 or intersec-
tion A? = A1 ?A2 or some optimal combination
Ao such that it is subset of A1 ? A2 but a super-
set of A1 ? A2. How to find this optimal Ao is a
key question. A? has high precision but low re-
call producing fewer alignments and A? has high
recall but low precision.
2 Related Work
Most existing methods for alignment combina-
tion (symmetrization) rely on heuristics to iden-
tify reliable links (Och and Ney, 2003), (Koehn
et al, 2003). The method proposed in (Och and
Ney, 2003), for example, interpolates the intersec-
tion and union of two asymmetric alignment ta-
bles by adding links that are adjacent to intersec-
tion links, and connect at least one previously un-
aligned word. Another example is the method in
(Koehn et al, 2003), which adds links to the inter-
section of two alignment tables that are the diago-
nal neighbors of existing links, optionally requir-
ing that any added links connect two previously
unaligned words.
Other methods try to combine the tables dur-
ing alignment training. In (Liang et al, 2006),
asymmetric models are jointly trained to maxi-
mize the similarity of their alignments, by opti-
828
mizing an EM-like objective function based on
agreement heuristics. In (Ayan et al, 2004), the
authors present a technique for combining align-
ments based on various linguistic resources such
as parts of speech, dependency parses, or bilingual
dictionaries, and use machine learning techniques
to do alignment combination. One of the main dis-
advantages of (Ayan et al, 2004)?s method, how-
ever, is that the algorithm is a supervised learning
method, and so requires human-annotated data.
Recently, (Xiang et al, 2010) proposed a method
that can handle multiple alignments with soft links
which are defined by confidence scores of align-
ment links. (Matusov et al, 2004) on the other
hand, frame symmetrization as finding a set with
minimal cost using use a graph based algorithm
where costs are associated with local alignment
probabilities.
In summary, most existing alignment combina-
tion methods try to find an optimal alignment set
Ao that lies between A? and A? using heuristics.
The main problems with methods based on heuris-
tics are:
1. they may not generalize well across language
pairs
2. they typically do not have any parameters to
optimize
3. most methods can combine only 2 align-
ments at a time
4. most approaches are ad-hoc and are not
mathematically well defined
In this paper we address these issues by propos-
ing a novel mathematical formulation for com-
bining an arbitrary number of alignment tables.
The method frames the combination task as an op-
timization problem, and finds the optimal align-
ment lying between the intersection and union of
multiple alignment tables by optimizing the pa-
rameter p of the power mean function.
3 Alignment combination using the
power mean
Given an english-foreign sentence pair (eI1, fJ1 )
the alignment problem is to determine the pres-
ence of absence of alignment links aij between
the words ei and fj , where i ? I and j ? J . In
this paper we will use the convention that when
aij = 1, words ei and fj are linked, otherwise
aij = 0. Let us define the alignment tables we ob-
tain for two translation directions as A1 and A2,
respectively. The union of these two alignment
tables A? contain all of the links in A1 and A2,
and the intersection A? contain only the common
links. Definitions 1 and 2 below define A? and
A? more formally. Our goal is to find an align-
ment set Ao such that |A?| ? |Ao| ? |A?| that
maximizes some objective function. We now de-
scribe the power mean (PM) and show how the
PM can represent both the union and intersection
of alignment tables using the same formula.
The power mean:
The power mean is defined by equation 1 below,
where p is a real number in (??,?) and an is a
positive real number.
Sp(a1, a2, ..., an) = (
1
n
n?
k=1
apk)
1
p (1)
The power mean, also known as the generalized
mean, has several interesting properties that are
relevant to our alignment combination problem.
In particular, the power mean is equivalent to the
geometric mean G when p? 0 as shown in equa-
tion 2 below:
G(a1, a2, ..., an) = (
n?
i=1
ai)
1
n
= lim
p?0
( 1n
n?
k=1
apk)
1
p (2)
The power mean, furthermore, is equivalent to the
maximum function M when p??:
M(a1, a2, ..., an) = max(a1, a2, ..., an)
= lim
p??(
1
n
n?
k=1
apk)
1
p (3)
Importantly, the PM Sp is a non-decreasing
function of p. This means that Sp is lower
bounded by G and upper-bounded by M for p ?
[0, ?]:
G < Sp < M, 0 < p <?. (4)
829
Figure 1: The power-mean is a principled way to interpolate between the extremes of union and inter-
section when combining multiple alignment tables.
They key insight underpinning our mathematical
formulation of the alignment combination prob-
lem is that the geometric mean of multiple align-
ment tables is equivalent to their intersection,
while the maximum of multiple alignment tables
is equivalent to their union.
Let Aq be an alignment with elements aqij such
that aqij = 1 if words ei and fj are linked, and
aqij = 0 otherwise. The union and intersection of
a set of n alignment tables can then be formally
defined as follows:
Definition 1: The union of alignments
A1, A2, ..., An is a set A? with a?ij = 1 if aqij = 1
for any q ? {1, 2, ..., n}.
Definition 2: The intersection of alignments
A1, A2, ..., An is a set A? with a?ij = 1 if aqij = 1
for all q ? {1, 2, ..., n}.
Figure 1 depicts a simple example of the align-
ment combination problem for the common case
of alignment symmetrization. Two alignments ta-
bles, Ae?f and Af?e (one-to-many alignments),
need to be combined. The result of taking
the union A? and intersection A? of the ta-
bles is shown. A? can be computed by taking
the element-wise maximum of Ae?f and Af?e,
which in turn is equal to the power mean Ap of
the elements of these tables in the limit as p??.
The intersection of the two tables, A?, can simi-
larly be computed by taking the geometric mean
of the elements of Ae?f and Af?e, which is
equal to the power mean Ap of the elements of
these tables in the limit as p? 0. For p ? (0,?),
equation 4 implies that Ap has elements with val-
ues between A? and A?. We now provide formal
proofs for these results when combining an arbi-
trary number of alignment tables.
3.1 The intersection of alignment tables
A1..An is equivalent to their
element-wise geometric mean
G(A1, A2, ..., An), as defined in (2).
Proof : Let A? be the intersection of all Aq
where q ? {1, 2, .., n}. As per our definition of
intersection ? between alignment tables, A? con-
tains links where aqij = 1 ? q.
Let Ag be the set that contains the elements
830
of G(A1, A2, ..., An). Then agij is the geo-
metric mean of the elements aqij where q ?
{1, 2, .., n}, as defined in equation 2, that is, agij =
(?nq=1 agij)
1
n . This product is equal to 1 iff aqij =
1 ? q and zero otherwise, since aqij ? {0, 1} ? q.
Hence Ag = A?. Q.E.D.
3.2 The union of alignment tables A1..An is
equivalent to their element-wise
maximum M(A1, A2, ..., An), as defined
in (3).
Proof : Let A? be the union of all Aq for q ?
{1, 2, .., n}. As per our definition of the union be-
tween alignments A? has links where aqij = 1 for
some q.
Let Am be the set that contain the elements of
M(A1, A2, ..., An). Let amij be the maximum of
the elements aqij where q ? {1, 2, .., n}, as defined
in equation (3). The max function is equal to 1
iff aqij = 1 for some q and zero otherwise, since
aqij ? {0, 1} ? q. Hence Am = A?. Q.E.D.
3.3 The element-wise power mean
Sp(A1, A2, ..., An) of alignment tables
A1..An has entries that are
lower-bounded by the intersection of
these tables, and upper-bounded by their
union for p ? [0, ?].
Proof : We have already shown that the union
and intersection of a set of alignment tables are
equivalent to the maximum and geometric mean
of these tables, respectively. Therefore given that
the result in equation 4 is true (we will not prove it
here), the relation holds. In this sense, the power
mean can be used to interpolate between the in-
tersection and union of multiple alignment tables.
Q.E.D.
4 Data
We evaluate the proposed method using an
English-Pashto translation task, as defined by the
DARPA TransTac program. The training data for
this task consists of slightly more than 100K par-
allel sentences. The Transtac task was designed to
evaluate speech-to-speech translation systems, so
all training sentences are conversational in nature.
The sentence length of these utterances varies
greatly, ranging from a single word to more than
Method F-measure
I 0.5979
H 0.6891
GDF 0.6712
PM 0.6984
PMn 0.7276
U 0.6589
Table 1: F-measure Based on Various Alignment
Combination Methods
50 words. 2026 sentences were randomly sampled
from this training data to prepare held out devel-
opment set. The held out Transtac test set consists
of 1019 parallel sentences.
5 Experiments and Discussion
We have shown in the previous sections that union
and intersection of alignments can be mathemat-
ically formulated using the power mean. Since
both combination operations can be represented
with the same mathematical expression, we can
search the combination space ?between? the in-
tersection and union of alignment tables by op-
timizing p w.r.t. any chosen objective function.
In these experiments, we define the optimal align-
ment as the one that maximizes the objective func-
tion f({aijt}, {a?ijt}, p), where f is standard F-
measure, {a?ijt} is the set of all estimated align-
ment entries on some dataset, {aijt} is the set of
all corresponding human-annotated alignment en-
tries, and p is the order of the power mean func-
tion. Instead of attempting to optimize the F-
measure using heuristics, we can now optimize it
by finding the appropriate power order p using any
suitable numerical optimization algorithm. In our
experiments we used the general simplex algo-
rithm of amoeba search (Nelder and Mead, 1965),
which attempts to find the optimal set of parame-
ters by evolving a simplex of evaluated points in
the direction that the F-measure is increasing.
In order to test our alignment combination for-
mulation empirically we performed experiments
on English-Pashto language with data described in
Section 4. We first trained two sets of alignments,
the e2f and f2e directions, based on GIZA++
(Och and Ney, 2003) algorithm. We then com-
bined these alignments by performing intersec-
831
tion (I) and union (U). We obtained F-measure of
0.5979 for intersection (I), 0.6589 for union (U).
For intersection the F-measure is lower presum-
ably because many alignments are not shared by
the input alignment tables so the number of links
is under-estimated. We then also re-produced the
two commonly used combination heuristic meth-
ods that are based on growing the alignment di-
agonally (GDF) (Koehn et al, 2003), and adding
links based on refined heuristics (H) (Och and
Ney, 2003), respectively. We obtained F-measure
of 0.6891 for H, and 0.6712 for GDF as shown in
Table 1.
We then used our power mean formulation for
combination to maximize the F-measure function
with the aforementioned simplex algorithm for
tuning the power parameter p, where F-measure
is computed with respect to the hand aligned de-
velopment data, which contains 150 sentences.
This hand aligned development set is different
than the development set for training MT models.
While doing so we also optimized table weights
Wq ? (0, 1),
?
q Wq = 1, which were applied to
the alignment tables before combining them using
the PM. The Wq allow the algorithm to weight the
two directions differently. We found that the F-
measure function had many local minima so the
simplex algorithm was initialized at several val-
ues of p and {Wq} to find the globally optimal
F-measure.
After obtaining power mean outputs for the
alignment entries, they need to be converted
into binary valued alignment links, that is,
Sp(a1ij , a2ij , ...anij) needs to be converted into a bi-
nary table. There are many ways to do this con-
version such as simple thresholding or keeping
best N% of the links. In our experiments we used
the following simple selection method, which ap-
pears to perform better than thresholding. First we
sorted links by PM value and then added the links
from the top of the sorted list such that ei and fj
are linked if ei?1 and ei+1 are connected to fj , or
fj?1 and fj+1 is linked to ei, or both ei and fj are
not connected. After tuning power mean parame-
ter and the alignment weights the best parameter
gave an F-measure of 0.6984 which is higher than
commonly used GDF by 2.272% and H by 0.93%
absolute respectively. We observe in Figure 2 that
even though PM has higher F-measure compared
with GDF it has significantly fewer number of
alignment links suggesting that PM has improved
precision on the finding the alignment links. The
presented PM based alignment combination can
be tuned to optimize any chosen objective, so it is
not surprising that we can improve upon previous
results based on heuristics.
One of the main advantages of the combining
alignment tables using the PM is that our state-
ments are valid for any number of input tables,
whereas most heuristic approaches can only pro-
cess two alignment tables at a time. The presented
power mean algorithm, in contrast, can be used
to combine any number of alignments in a sin-
gle step, which, importantly, makes it possible to
jointly optimize all of the parameters of the com-
bination process.
In the second set of experiments the PM ap-
proach, which we call PMn, is applied simultane-
ously to more than two alignments. We obtained
four more sets of alignments from the Berke-
ley aligner (BA) (Liang et al, 2006), the HMM
aligner (HA) (Vogel et al, 1996), the alignment
based on partial words (PA), and alignment based
on dependency based reordering (DA) (Xu et al,
2009). Alignment I was obtained by using Berke-
ley aligner as an off-the-shelf alignment tool. We
built the HMM aligner based on (Vogel et al,
1996) and use the HMM aligner for producing
Alignment II. Producing different sets of align-
ments using different algorithms could be useful
because some alignments that are pruned by one
algorithm may be kept by another giving us a big-
ger pool of possible links to chose from.
We produced Alignment III based on partial
words. Pashto is morphologically rich language
with many prefixes and suffixes. In lack of a mor-
phological segmenter it has been suggested that
keeping only first ?n? characters of a word can ef-
fectively reduce the vocabulary size and may pro-
duce better alignments. (Chiang et al, 2009) used
partial words for alignment training in English and
Urdu. We trained such alignments using using
GIZA++ on parallel data with partial words for
Pashto sentences.
The fourth type of alignment we produced,
Alignment IV, was motivated by the (Xu et al,
832
Figure 2: Number of Alignments Links for Dif-
ferent Combination Types
2009). (Xu et al, 2009) showed that transla-
tion between subject-verb-object (English) and
subject-object-verb (Pashto) languages can be im-
proved by reordering the source side of the par-
allel data. They obtained dependency tree of the
source side and used high level human gener-
ated rules to reorder source side using precedence-
based movement of dependency subtrees. The
rules were particularly useful in reordering of
verbs that moved to the end of the sentence. Mak-
ing the ordering of source and target side more
similar may produce better alignments for lan-
guage pairs which differ in verb ordering, as many
alignment algorithms penalize or fail to consider
alignments that link words that differ greatly in
sentence position. A Pashto language expert was
hired to produce similar precedence-based rules
for the English-Pashto language pair. Using the
rules and algorithm described in (Xu et al, 2009)
we reordered all of the source side and used
GIZA++ to align the sentences.
The four additional alignment sets just de-
scribed, including our baseline alignment, Align-
ment V, were combined using the presented PMn
combination algorithm, where n signifies the
number of tables being combined. As seen on
Table 1, we obtained an F-measure of 0.7276
which is 12.97% absolute better than intersection
and 6.87% better than union. Furthermore PMn,
which in these experiments utilizes 5 alignments,
is better than PM by 2.92% absolute. This is an
encouraging result because this not only shows
that we are finding better alignments than inter-
section and union, but also that combining more
than two alignments is useful. We note that PMn
performed 3.85% absolute better than H (Och and
Ney, 2003), and 5.64% better than GDF heuris-
tics.
In the above experiments the parameters of
the power mean combination method were tuned
on development data to optimize alignment F-
measure, and the performance of several align-
ment combination techniques were compared in
terms of F-measure. However, it is not clear how
correlated alignment F-measures are with BLEU
scores, as explained in (Fraser and Marcu, 2007).
While there is no mathematical problem with
optimizing the parameters of the presented PM-
based combination algorithm w.r.t. BLEU scores,
computationally it is not practical to do so because
each iteration would require a complete training
phase. To further evaluate the quality of the align-
ments methods being compared in this paper, we
built several MT models based on them and com-
pared the resulting BLEU scores.
E2F Dev Test
I 0.1064 0.0941
H 0.1028 0.0894
GDF 0.1256 0.1091
PM 0.1214 0.1094
PMn 0.1378 0.1209
U 0.1062 0.0897
Table 2: E2F BLEU: PM Alignment Combination
Based MT Model Comparision
We built a standard phrase-based translation
system (Koehn et al, 2003) that utilizes a stack-
based decoder based on an A? search. Based on
the combined alignments, we extracted phrase ta-
bles with a maximum phrase length of 6 for En-
glish and 8 for Pashto, respectively. We then
trained the lexicalized reordering model that pro-
duced distortion costs based on the number of
words that are skipped on the target side, in
a manner similar to (Al-Onaizan and Papineni,
2006). Our training sentences are a compilation
of sentences from various domains collected by
DARPA, and hence we were able to build interpo-
lated language model which weights the domains
differently. We built an interpolated LM for both
833
English and Pashto, but for English we had signif-
icantly more monolingual sentences (1.4 million
in total) compared to slightly more than 100K sen-
tences for Pashto. We tuned our MT model using
minimum error rate (Och, 2003) training.
F2E Dev Test
I 0.1145 0.1101
H 0.1262 0.1193
GDF 0.1115 0.1204
PM 0.1201 0.1155
PMn 0.1198 0.1196
U 0.1111 0.1155
Table 3: F2E BLEU : PM Alignment Combina-
tion Based MT Model Comparision
We built five different MT models based on
Intersection (I), Union (U), (Koehn et al, 2003)
Grow Diagonal Final (GDF), (Och and Ney, 2003)
H refined heuristics and Power Mean (PMn) align-
ment sets where n = 5. We obtained BLEU (Pa-
pineni et al, 2002) scores for E2F direction as
shown in Table 2. As expected MT model based
on I alignment has the low BLEU score of 0.1064
on the dev set and 0.0941 on the test set on E2F
direction. Intersection, though, has higher preci-
sion, but throws away many alignments, so the
overall number of alignments is too small to pro-
duce a good phrase translation table. Similarly
the U alignment also has low scores (0.1062 and
0.0897) on the dev and test sets, respectively. The
best scores for E2F direction for both dev and test
set is obtained using the model based on PMn al-
gorithm. We obtained BLEU scores of 0.1378 on
the dev set and 0.1209 on the test set which is bet-
ter than all heuristic based methods. It is better
by 1.22 absolute BLEU score on the dev set and
1.18 on a test compared to commonly used GDF
(Koehn et al, 2003) heuristics. The above BLEU
scores were all computed based on 1 reference.
Note that for the e2f direction PM, which com-
bines only 2 alignments, is not worse than any of
the heuristic based methods. Also note that the
difference in the BLEU score of PM and PMn is
quite large, which indicates that combining more
than two alignments using the power mean leads
to substantial gains in performance.
Although we saw significant gains on E2F di-
Type PT Size (100K)
I 182.17
H 30.73
GDF 27.65
PM 60.87
PMn 25.67
U 24.54
Table 4: E2F Phrase Table Size
rection we did not see similar gains on F2E di-
rection unfortunately. Matching our expectation
Intersection (I) produced the worse results with
BLEU scores of 0.1145 and 0.1101 on the dev
and test set respectively, as shown in Table 3. Our
PMn algorithm obtained BLEU score of 0.1198
on the dev set and 0.1196 on test set which is
better by 0.83 absolute in dev set over GDF. On
the test set though performance between PMn and
GDF is only slightly different with 0.1196 for
PMn and 0.1204 for GDF. The standard deviation
on test set BLEU scores for F2E direction is only
0.0042 which is one third of the standard devia-
tion in E2F direction at 0.013 signifying that the
alignment seems to make less difference in F2E
direction for our models. One possible explana-
tion for such results is that the Pashto LM for the
E2F direction is trained on a small set of sen-
tences available from training corpus while En-
glish LM for F2E direction was trained on 1.4 mil-
lion sentences. Therefore the English LM, which
is trained on significantly more data, is probably
more robust to translation model errors.
Type PT Size (100K)
I 139.98
H 56.76
GDF 22.96
PM 47.50
PMn 21.24
U 20.33
Table 5: F2E Phrase Table Size
Note that different alignments lead to differ-
ent phrase table (PT) sizes (Figure 2). The inter-
section (I) method has the least number of align-
ment links, and tends to produce the largest phrase
tables, because there are less restrictions on the
834
phrases to be extracted. The Union (U) method,
on the other hand, tends to produce the least num-
ber of phrases, because the phrase extraction al-
gorithm has more constraints to satisfy. We ob-
serve that PT produced by intersection is signifi-
cantly larger than others as seen in Tables 4 and
5. The PT size produced by PMn as shown in
Table 4 is between I and U and is significantly
smaller than the other heuristic based methods. It
is 7.1% smaller than GDF heuristic based phrase
table. Similarly in F2E direction as well (Table
5) we see the similar trend where PMn PT size
is smaller than GDF by 4.2%. The decrease in
phrase table size and increase in BLEU scores for
most of the dev and test sets show that our PM
based combined alignments are helping to pro-
duce better MT models.
6 Conclusion and Future Work
We have presented a mathematical formulation for
combining alignment tables based on their power
mean. The presented framework allows us to find
the optimal alignment between intersection and
union by finding the best power mean parameter
between 0 and ?, which correspond to intersec-
tion and union operations, respectively. We eval-
uated the proposed method empirically by com-
puting BLEU scores in English-Pashto transla-
tion task and also by computing an F-measure
with respect to human alignments. We showed
that the approach is more effective than intersec-
tion, union, the heuristics of (Och and Ney, 2003),
and the grow diagonal final (GDF) algorithm of
(Koehn et al, 2003). We also showed that our al-
gorithm is not limited to two tables, which makes
it possible to jointly optimize the combination of
multiple alignment tables to further increase per-
formance.
In future work we would like to address two
particular issues. First, in this work we converted
power mean outputs to binary alignment links by
simple selection process. We are currently investi-
gating ways to integrate the binary constraint into
the PM-based optimization algorithm. Second,
we do not have to limit ourselves to alignments ta-
bles that are binary. PM based algorithm can com-
bine alignments that are not binary, which makes
it easier to integrate other sources of information
such as posterior probability of word translation
into the alignment combination framework.
7 Acknowledgment
This work is partially supported by the DARPA
TRANSTAC program under the contract number
of NBCH2030007. Any opinions, findings, and
conclusions or recommendations expressed in this
material are those of the authors and do not nec-
essarily reflect the views of DARPA.
References
Al-Onaizan, Yaser and Kishore Papineni. 2006. Dis-
tortion models for statistical machine translation. In
Proceedings of ACL.
Ayan, Necip, Bonnie J. Dorr, , and Nizar Habash.
2004. Multi-align: Combining linguistic and statis-
tical techniques to improve alignments for adaptable
mt. In Proceedings of the 6th Conference of the As-
sociation for Machine Translation in the Americas.
Brown, P., V. Della Pietra, S. Della Pietra, and R. Mer-
cer. 1993. The mathematics of statistical machine
translation: parameter estimation. Computational
Linguistics, 19(2):263?311.
Chiang, David, Kevin Knight, and Samad Echihabi.
2009. In Presentation at NIST MT 2009 Workshop,
August.
Chiang, David. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of ACL.
Fraser, Alexander and Daniel Marcu. 2007. Measur-
ing word alignment quality for statistical machine
translation. Comput. Linguist., 33(3):293?303.
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT/NAACL.
Liang, Percy, Ben Taskar, and Dan Klein. 2006.
Alignment by agreement. In Proceedings of ACL.
Matusov, Evgeny, Richard Zens, and Hermann Ney.
2004. Symmetric word alignments for statistical
machine translation. In Proceedings of COLING,
page 219, Morristown, NJ, USA.
Nelder, JA and R Mead. 1965. A simplex method for
function minimization. The Computer Journal 7:
308-313.
Och, F. J. and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19?51.
835
Och, Franz J. 2003. Minimum error rate training in
statistical machine. In Proceedings of ACL.
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei
jing Zhu. 2002. Bleu: A method for automatic eval-
uation of machine translation. In In Proceedings of
ACL, pages 311?318.
Vogel, Stephan, Hermann Ney, and Christoph Till-
mann. 1996. Hmm-based word alignment in statis-
tical translation. In COLING 96: The 16th Int. Conf.
on Computational Linguistics, pages 836?841.
Xiang, Bing, Yonggang Deng, and Bowen Zhou. 2010.
Diversify and combine: Improving word alignment
for machine translation on low-resource languages.
In Proceedings of ACL.
Xu, Peng, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
smt for subject-object-verb languages. In NAACL,
pages 245?253, Morristown, NJ, USA.
Yamada, Kenji and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings
of ACL, pages 523?530, Toulouse, France, July.
ACL.
836
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 138?147,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Soft Syntactic Constraints for Hierarchical Phrase-based Translation
Using Latent Syntactic Distributions
Zhongqiang Huang
Institute for Advanced Computer Studies
University of Maryland
College Park, MD 20742
zqhuang@umiacs.umd.edu
Martin C?mejrek and Bowen Zhou
IBM T. J. Watson Research Center
Yorktown Heights, NY 10598
{martin.cmejrek,zhou}@us.ibm.com
Abstract
In this paper, we present a novel approach
to enhance hierarchical phrase-based machine
translation systems with linguistically moti-
vated syntactic features. Rather than directly
using treebank categories as in previous stud-
ies, we learn a set of linguistically-guided la-
tent syntactic categories automatically from a
source-side parsed, word-aligned parallel cor-
pus, based on the hierarchical structure among
phrase pairs as well as the syntactic structure
of the source side. In our model, each X non-
terminal in a SCFG rule is decorated with a
real-valued feature vector computed based on
its distribution of latent syntactic categories.
These feature vectors are utilized at decod-
ing time to measure the similarity between the
syntactic analysis of the source side and the
syntax of the SCFG rules that are applied to
derive translations. Our approach maintains
the advantages of hierarchical phrase-based
translation systems while at the same time nat-
urally incorporates soft syntactic constraints.
1 Introduction
In recent years, syntax-based translation mod-
els (Chiang, 2007; Galley et al, 2004; Liu et
al., 2006) have shown promising progress in im-
proving translation quality, thanks to the incorpora-
tion of phrasal translation adopted from the widely
used phrase-based models (Och and Ney, 2004) to
handle local fluency and the engagement of syn-
chronous context-free grammars (SCFG) to handle
non-local phrase reordering. Approaches to syntax-
based translation models can be largely categorized
into two classes based on their dependency on anno-
tated corpus (Chiang, 2007). Linguistically syntax-
based models (e.g., (Yamada and Knight, 2001; Gal-
ley et al, 2004; Liu et al, 2006)) utilize structures
defined over linguistic theory and annotations (e.g.,
Penn Treebank) and guide the derivation of SCFG
rules with explicit parsing on at least one side of
the parallel corpus. Formally syntax-based mod-
els (e.g., (Wu, 1997; Chiang, 2007)) extract syn-
chronous grammars from parallel corpora based on
the hierarchical structure of natural language pairs
without any explicit linguistic knowledge or anno-
tations. In this work, we focus on the hierarchi-
cal phrase-based models of Chiang (2007), which
is formally syntax-based, and always refer the term
SCFG, from now on, to the grammars of this model
class.
On the one hand, hierarchical phrase-based mod-
els do not suffer from errors in syntactic constraints
that are unavoidable in linguistically syntax-based
models. Despite the complete lack of linguistic
guidance, the performance of hierarchical phrase-
based models is competitive when compared to lin-
guistically syntax-based models. As shown in (Mi
and Huang, 2008), hierarchical phrase-based models
significantly outperform tree-to-string models (Liu
et al, 2006; Huang et al, 2006), even when at-
tempts are made to alleviate parsing errors using
either forest-based decoding (Mi et al, 2008) or
forest-based rule extraction (Mi and Huang, 2008).
On the other hand, when properly used, syntac-
tic constraints can provide invaluable benefits to im-
prove translation quality. The tree-to-string mod-
els of Mi and Huang (2008) can actually signif-
138
icantly outperform hierarchical phrase-based mod-
els when using forest-based rule extraction together
with forest-based decoding. Chiang (2010) also ob-
tained significant improvement over his hierarchi-
cal baseline by using syntactic parse trees on both
source and target sides to induce fuzzy (not exact)
tree-to-tree rules and by also allowing syntactically
mismatched substitutions.
In this paper, we augment rules in hierarchical
phrase-based translation systems with novel syntac-
tic features. Unlike previous studies (e.g., (Zoll-
mann and Venugopal, 2006)) that directly use ex-
plicit treebank categories such as NP, NP/PP (NP
missing PP from the right) to annotate phrase pairs,
we induce a set of latent categories to capture the
syntactic dependencies inherent in the hierarchical
structure of phrase pairs, and derive a real-valued
feature vector for each X nonterminal of a SCFG
rule based on the distribution of the latent cate-
gories. Moreover, we convert the equality test of
two sequences of syntactic categories, which are ei-
ther identical or different, into the computation of
a similarity score between their corresponding fea-
ture vectors. In our model, two symbolically dif-
ferent sequences of syntactic categories could have
a high similarity score in the feature vector repre-
sentation if they are syntactically similar, and a low
score otherwise. In decoding, these feature vectors
are utilized to measure the similarity between the
syntactic analysis of the source side and the syntax
of the SCFG rules that are applied to derive trans-
lations. Our approach maintains the advantages of
hierarchical phrase-based translation systems while
at the same time naturally incorporates soft syntactic
constraints. To the best of our knowledge, this is the
first work that applies real-valued syntactic feature
vectors to machine translation.
The rest of the paper is organized as follows.
Section 2 briefly reviews hierarchical phrase-based
translation models. Section 3 presents an overview
of our approach, followed by Section 4 describing
the hierarchical structure of aligned phrase pairs and
Section 5 describing how to induce latent syntactic
categories. Experimental results are reported in Sec-
tion 6, followed by discussions in Section 7. Sec-
tion 8 concludes this paper.
2 Hierarchical Phrase-Based Translation
An SCFG is a synchronous rewriting system gener-
ating source and target side string pairs simultane-
ously based on a context-free grammar. Each syn-
chronous production (i.e., rule) rewrites a nonter-
minal into a pair of strings, ? and ?, where ? (or
?) contains terminal and nonterminal symbols from
the source (or target) language and there is a one-to-
one correspondence between the nonterminal sym-
bols on both sides. In particular, the hierarchical
model (Chiang, 2007) studied in this paper explores
hierarchical structures of natural language and uti-
lize only a unified nonterminal symbol X in the
grammar,
X ? ??, ?,??
where ? is the one-to-one correspondence between
X?s in ? and ?, and it can be indicated by un-
derscripted co-indexes. Two example English-to-
Chinese translation rules are represented as follows:
X ? ?give the pen to me,????? (1)
X ? ?giveX1 to me, X1??? (2)
The SCFG rules of hierarchical phrase-based
models are extracted automatically from corpora of
word-aligned parallel sentence pairs (Brown et al,
1993; Och and Ney, 2000). An aligned sentence pair
is a tuple (E,F,A), where E = e1 ? ? ? en can be in-
terpreted as an English sentence of length n, F =
f1 ? ? ? fm its translation of length m in a foreign lan-
guage, andA a set of links between words of the two
sentences. Figure 1 (a) shows an example of aligned
English-to-Chinese sentence pair. Widely adopted
in phrase-based models (Och and Ney, 2004), a pair
of consecutive sequences of words from E and F is
a phrase pair if all words are aligned only within the
sequences and not to any word outside. We call a se-
quence of words a phrase if it corresponds to either
side of a phrase pair, and a non-phrase otherwise.
Note that the boundary words of a phrase pair may
not be aligned to any other word. We call the phrase
pairs with all boundary words aligned tight phrase
pairs (Zhang et al, 2008). A tight phrase pair is the
minimal phrase pair among all that share the same
set of alignment links. Figure 1 (b) highlights the
tight phrase pairs in the example sentence pair.
139
65
4
3
2
1
1
2 3 4 5
(a) (b)
Figure 1: An example of word-aligned sentence pair (a)
with tight phrase pairs marked in a matrix representation
(b).
The extraction of SCFG rules proceeds as fol-
lows. In the first step, all phrase pairs below a max-
imum length are extracted as phrasal rules. In the
second step, abstract rules are extracted from tight
phrase pairs that contain other tight phrase pairs by
replacing the sub phrase pairs with co-indexed X-
nonterminals. Chiang (2007) also introduced several
requirements (e.g., there are at most two nontermi-
nals at the right hand side of a rule) to safeguard
the quality of the abstract rules as well as keeping
decoding efficient. In our example above, rule (2)
can be extracted from rule (1) with the following sub
phrase pair:
X ? ?the pen,???
The use of a unified X nonterminal makes hier-
archical phrase-based models flexible at capturing
non-local reordering of phrases. However, such flex-
ibility also comes at the cost that it is not able to
differentiate between different syntactic usages of
phrases. Suppose rule X ? ?I am readingX1, ? ? ? ?
is extracted from a phrase pair with I am reading a
book on the source side whereX1 is abstracted from
the noun phrase pair . If this rule is used to translate
I am reading the brochure of a book fair, it would
be better to apply it over the entire string than over
sub-strings such as I ... the brochure of. This is be-
cause the nonterminal X1 in the rule was abstracted
from a noun phrase on the source side of the training
data and would thus be better (more informative) to
be applied to phrases of the same type. Hierarchi-
cal phrase-based models are not able to distinguish
syntactic differences like this.
Zollmann and Venugopal (2006) attempted to ad-
dress this problem by annotating phrase pairs with
treebank categories based on automatic parse trees.
They introduced an extended set of categories (e.g.,
NP+V for she went and DT\NP for great wall, an
noun phrase with a missing determiner on the left)
to annotate phrase pairs that do not align with syn-
tactic constituents. Their hard syntactic constraint
requires that the nonterminals should match exactly
to rewrite with a rule, which could rule out poten-
tially correct derivations due to errors in the syn-
tactic parses as well as to data sparsity. For exam-
ple, NP cannot be instantiated with phrase pairs of
type DT+NN, in spite of their syntactic similarity.
Venugopal et al (2009) addressed this problem by
directly introducing soft syntactic preferences into
SCFG rules using preference grammars, but they
had to face the computational challenges of large
preference vectors. Chiang (2010) also avoided hard
constraints and took a soft alternative that directly
models the cost of mismatched rule substitutions.
This, however, would require a large number of pa-
rameters to be tuned on a generally small-sized held-
out set, and it could thus suffer from over-tuning.
3 Approach Overview
In this work, we take a different approach to intro-
duce linguistic syntax to hierarchical phrase-based
translation systems and impose soft syntactic con-
straints between derivation rules and the syntactic
parse of the sentence to be translated. For each
phrase pair extracted from a sentence pair of a
source-side parsed parallel corpus, we abstract its
syntax by the sequence of highest root categories,
which we call a tag sequence, that exactly1 domi-
nates the syntactic tree fragments of the source-side
phrase. Figure 3 (b) shows the source-side parse tree
of a sentence pair. The tag sequence for ?the pen?
is simply ?NP? because it is a noun phrase, while
phrase ?give the pen? is dominated by a verb fol-
lowed by a noun phrase, and thus its tag sequence is
?VBP NP?.
Let TS = {ts1, ? ? ? , tsm} be the set of all tag se-
quences extracted from a parallel corpus. The syntax
of each X nonterminal2 in a SCFG rule can be then
1In case of a non-tight phrase pair, we only abstract and
compare the syntax of the largest tight part.
2There are three X nonterminals (one on the left and two on
the right) for binary abstract rules, two for unary abstract rules,
and one for phrasal rules.
140
Tag Sequence Probability
NP 0.40
DT NN 0.35
DT NN NN 0.25
Table 1: The distribution of tag sequences forX1 inX ?
?I am reading X1, ? ? ? ?.
characterized by the distribution of tag sequences
~PX(TS) = (pX(ts1), ? ? ? , pX(tsm)), based on the
phrase pairs it is abstracted from. Table 1 shows
an example distribution of tag sequences for X1 in
X ? ?I am reading X1, ? ? ? ?.
Instead of directly using tag sequences, as we
discussed their disadvantages above, we represent
each of them by a real-valued feature vector. Sup-
pose we have a collection of n latent syntactic cate-
gories C = {c1, ? ? ? , cn}. For each tag sequence ts,
we compute its distribution of latent syntactic cate-
gories ~Pts(C) = (pts(c1), ? ? ? , pts(cn)). For exam-
ple, ~P?NP VP?(C) = {0.5, 0.2, 0.3} means that the la-
tent syntactic categories c1, c2, and c3 are distributed
as p(c1) = 0.5, p(c2) = 0.2, and p(c3) = 0.3 for tag
sequence ?NP VP?. We further convert the distribu-
tion to a normalized feature vector ~F (ts) to repre-
sent tag sequence ts:
~F (ts) = (f1(ts), ? ? ? , fn(ts))
=
(pts(c1), ? ? ? , pts(cn))
?(pts(c1), ? ? ? , pts(cn))?
The advantage of using real-valued feature vec-
tors is that the degree of similarity between two tag
sequences ts and ts? in the space of the latent syn-
tactic categories C can be simply computed as a dot-
product3 of their feature vectors:
~F (ts) ? ~F (ts?) =
?
1?i?n
fi(ts)fi(ts
?)
which computes a syntactic similarity score in the
range of 0 (totally syntactically different) to 1 (com-
pletely syntactically identical).
Similarly, we can represent the syntax of each X
nonterminal in a rule with a feature vector ~F (X),
computed as the sum of the feature vectors of tag
3Other measures such as KL-divergence in the probability
space are also feasible.
sequences weighted by the distribution of tag se-
quences of the nonterminal X:
~F (X) =
?
ts?TS
pX(ts)~F (ts)
Now we can impose soft syntactic constraints us-
ing these feature vectors when a SCFG rule is used
to translate a parsed source sentence. Given that aX
nonterminal in the rule is applied to a span with tag
sequence4 ts as determined by a syntactic parser, we
can compute the following syntax similarity feature:
SynSim(X, ts) = ? log(~F (ts) ? ~F (X))
Except that it is computed on the fly, this feature
can be used in the same way as the regular features
in hierarchical translation systems to determine the
best translation, and its feature weight can be tuned
in the same way together with the other features on
a held-out data set.
In our approach, the set of latent syntactic cate-
gories is automatically induced from a source-side
parsed, word-aligned parallel corpus based on the
hierarchical structure among phrase pairs along with
the syntactic parse of the source side. In what fol-
lows, we will explain the two critical aspects of
our approach, i.e., how to identify the hierarchi-
cal structures among all phrase pairs in a sentence
pair, and how to induce the latent syntactic cate-
gories from the hierarchy to syntactically explain the
phrase pairs.
4 Alignment-based Hierarchy
The aforementioned abstract rule extraction algo-
rithm of Chiang (2007) is based on the property that
a tight phrase pair can contain other tight phrase
pairs. Given two non-disjoint tight phrase pairs that
share at least one common alignment link, there are
only two relationships: either one completely in-
cludes another or they do not include one another
but have a non-empty overlap, which we call a non-
trivial overlap. In the second case, the intersection,
differences, and union of the two phrase pairs are
4A normalized uniform feature vector is used for tag se-
quences (of parsed test sentences) that are not seen on the train-
ing corpus.
141
Figure 2: A decomposition tree of tight phrase pairs with
all tight phrase pairs listed on the right. As highlighted,
the two non-maximal phrase pairs are generated by con-
secutive sibling nodes.
also tight phrase pairs (see Figure 1 (b) for exam-
ple), and the two phrase pairs, as well as their inter-
section and differences, are all sub phrase pairs of
their union.
Zhang et al (2008) exploited this property to con-
struct a hierarchical decomposition tree (Bui-Xuan
et al, 2005) of phrase pairs from a sentence pair to
extract all phrase pairs in linear time. In this pa-
per, we focus on learning the syntactic dependencies
along the hierarchy of phrase pairs. Our hierarchy
construction follows Heber and Stoye (2001).
Let P be the set of tight phrase pairs extracted
from a sentence pair. We call a sequentially-ordered
list5 L = (p1, ? ? ? , pk) of unique phrase pairs pi ? P
a chain if every two successive phrase pairs in L
have a non-trivial overlap. A chain is maximal if
it can not be extended to its left or right with other
phrase pairs. Note that any sub-sequence of phrase
pairs in a chain generates a tight phrase pair. In par-
ticular, chain L generates a tight phrase pair ?(L)
that corresponds exactly to the union of the align-
ment links in p ? L. We call the phrase pairs
generated by maximal chains maximal phrase pairs
and call the other phrase pairs non-maximal. Non-
maximal phrase pairs always overlap non-trivially
with some other phrase pairs while maximal phrase
pairs do not, and it can be shown that any non-
maximal phrase pair can be generated by a sequence
of maximal phrase pairs. Note that the largest tight
phrase pair that includes all alignment links in A is
also a maximal phrase pair.
5The phrase pairs can be sequentially ordered first by the
boundary positions of the source-side phrase and then by the
boundary positions of the target-side phrase.
give
the pen to me .
X B B B X X
X
X
X
PP
VBP
DT NN TO PRP .
NP
VP
S
give
the pen to me .
(a) (b)
X
X
B B B X X
X
X
X
X
X
X
B B B X X
X
X
X
X
VBP
X
X
B B B X X
X
X
X
X
DT
NN TO PRP
.
NP PP
CR
VP
S
I(!)
O(!)
X
X
B B B X X
X
X
X
X
VBP DT
NN TO PRP
.
S
CR
NP PP
CR
O(!)
I(!)
(c) (d)
Figure 3: (a) decomposition tree for the English side of
the example sentence pair with all phrases underlined, (b)
automatic parse tree of the English side, (c) two example
binarized decomposition trees with syntactic emissions
in depicted in (d), where the two dotted curves give an
example I(?) and O(?) that separate the forest into two
parts.
Lemma 1 Given two different maximal phrase
pairs p1 and p2, exactly one of the following alter-
natives is true: p1 and p2 are disjoint, p1 is a sub
phrase pair of p2, or p2 is a sub phrase pair of p1.
A direct outcome of Lemma 1 is that there is an
unique decomposition tree T = (N,E) covering all
of the tight phrase pairs of a sentence pair, where N
is the set of maximal phrase pairs and E is the set of
edges that connect between pairs of maximal phrase
pairs if one is a sub phrase pair of another. All of the
tight phrase pairs of a sentence pair can be extracted
directly from the nodes of the decomposition tree
(these phrase pairs are maximal), or generated by se-
quences of consecutive sibling nodes6 (these phrase
pairs are non-maximal). Figure 2 shows the decom-
position tree as well as all of the tight phrase pairs
that can be extracted from the example sentence pair
in Figure 1.
We focus on the source side of the decomposition
tree, and expand it to include all of the non-phrase
6Unaligned words may be added.
142
single words within the scope of the decomposition
tree as frontiers and attach each as a child of the low-
est node that contains the word. We then abstract the
trees nodes with two symbol, X for phrases, and B
for non-phrases, and call the result the decomposi-
tion tree of the source side phrases. Figure 3 (a) de-
picts such tree for the English side of our example
sentence pair. We further recursively binarize7 the
decomposition tree into a binarized decomposition
forest such that all phrases are directly represented
as nodes in the forest. Figure 3 (c) shows two of the
many binarized decomposition trees in the forest.
The binarized decomposition forest compactly
encodes the hierarchical structure among phrases
and non-phrases. However, the coarse abstraction
of phrases with X and non-phrases with B provides
little information on the constraints of the hierarchy.
In order to bring in syntactic constraints, we anno-
tate the nodes in the decomposition forest with syn-
tactic observations based on the automatic syntactic
parse tree of the source side. If a node aligns with
a constituent in the parse tree, we add the syntactic
category (e.g., NP) of the constituent as an emitted
observation of the node, otherwise, it crosses con-
stituent boundaries and we add a designated crossing
category CR as its observation. We call the resulting
forest a syntactic decomposition forest. Figure 3 (d)
shows two syntactic decomposition trees of the for-
est based on the parse tree in Figure 3 (b). We will
next describe how to learn finer-grained X and B
categories based on the hierarchical syntactic con-
straints.
5 Inducing Latent Syntactic Categories
If we designate a unique symbol S as the new root
of the syntactic decomposition forests introduced
in the previous section, it can be shown that these
forests can be generated by a probabilistic context-
free grammar G = (V,?, S,R, ?), where
? V = {S,X,B} is the set of nonterminals,
? ? is the set of terminals comprising treebank
categories plus the CR tag (the crossing cate-
gory),
7The intermediate binarization nodes are also labeled as ei-
ther X or B based on whether they exactly cover a phrase or
not.
? S ? V is the unique start symbol,
? R is the union of the set of production rules
each rewriting a nonterminal to a sequence of
nonterminals and the set of emission rules each
generating a terminal from a nonterminal,
? and ? assigns a probability score to each rule
r ? R.
Such a grammar can be derived from the set of
syntactic decomposition forests extracted from a
source-side parsed parallel corpus, with rule prob-
ability scores estimated as the relative frequencies
of the production and emission rules.
The X and B nonterminals in the grammar are
coarse representations of phrase and non-phrases
and do not carry any syntactic information at all.
In order to introduce syntax to these nonterminals,
we incrementally split8 them into a set of latent
categories {X1, ? ? ? , Xn} for X and another set
{B1, ? ? ? , Bn} for B, and then learn a set of rule
probabilities9 ? on the latent categories so that the
likelihood of the training forests are maximized. The
motivation is to let the latent categories learn differ-
ent preferences of (emitted) syntactic categories as
well as structural dependencies along the hierarchy
so that they can carry syntactic information. We call
them latent syntactic categories. The learned Xi?s
represent syntactically-induced finer-grained cate-
gories of phrases and are used as the set of latent
syntactic categories C described in Section 3. In re-
lated research, Matsuzaki et al (2005) and Petrov et
al. (2006) introduced latent variables to learn finer-
grained distinctions of treebank categories for pars-
ing, and Huang et al (2009) used a similar approach
to learn finer-grained part-of-speech tags for tag-
ging. Our method is in spirit similar to these ap-
proaches.
Optimization of grammar parameters to maximize
the likelihood of training forests can be achieved
8We incrementally split each nonterminal to 2, 4, 8, and fi-
nally 16 categories, with each splitting followed by several EM
iterations to tune model parameters. We consider 16 an appro-
priate number for latent categories, not too small to differentiate
between different syntactic usages and not too large for the extra
computational and storage costs.
9Each binary production rule is now associated with a 3-
dimensional matrix of probabilities, and each emission rule as-
sociated with a 1-dimensional array of probabilities.
143
by a variant of Expectation-Maximization (EM) al-
gorithm. Recall that our decomposition forests are
fully binarized (except the root). In the hypergraph
representation (Huang and Chiang, 2005), the hy-
peredges of our forests all have the same format10
?(V,W ), U?, meaning that node U expands to nodes
V and W with production rule U ? VW . Given
a forest F with root node R, we denote e(U) the
emitted syntactic category at node U and LR(U) (or
PL(W ), or PR(V ))11 the set of node pairs (V,W )
(or (U, V ), or (U,W )) such that ?(V,W ), U? is a hy-
peredge of the forest. Now consider node U , which
is either S, X , or B, in the forest. Let Ux be the
latent syntactic category12 of node U . We define
I(Ux) the part of the forest (includes e(U) but not
Ux) inside U , and O(Ux) the other part of the forest
(includes Ux but not e(U)) outside U , as illustrated
in Figure 3 (d). The inside-outside probabilities are
defined as:
PIN(Ux) = P (I(Ux)|Ux)
POUT(Ux) = P (O(Ux)|S)
which can be computed recursively as:
PIN(Ux) =
?
(V,W )?LR(U)
?
y,z
?(Ux ? e(U))
??(Ux ? VyWz)
?PIN(Vy)PIN(Wz)
POUT(Ux) =
?
(V,W )?PL(U)
?
y,z
?(Vy ? e(V ))
??(Vy ?WzUx)
?POUT(Vy)PIN(Wz)
+
?
(V,W )?PR(U)
?
y,z
?(Vy ? e(V ))
??(Vy ? UxWz)
?POUT(Vy)PIN(Wz)
In the E-step, the posterior probability of the oc-
currence of production rule13 Ux ? VyWz is com-
puted as:
P (Ux ? VyWz|F ) =
?(Ux ? e(U))
??(Ux ? VyWz)
?POUT(Ux)PIN(Vy)PIN(Ww)
PIN(R)
10The hyperedge corresponding to the root node has a differ-
ent format because it is unary, but it can be handled similarly.
When clear from context, we use the same variable to present
both a node and its label.
11LR stands for the left and right children, PL for the parent
and left children, and PR for the parent and right children.
12We never split the start symbol S, and denote S0 = S.
13The emission rules can be handled similarly.
In the M-step, the expected counts of rule Ux ?
VyWz for all latent categories Vy and Wz are accu-
mulated together and then normalized to obtain an
update of the probability estimation:
?(Ux ? VyWz) =
#(Ux ? VyWz)
?
(V ?,W ?)
?
y,z
#(Ux ? VyWz)
Recall that each node U labeled asX in a forest is
associated with a phrase whose syntax is abstracted
by a tag sequence. Once a grammar is learned, for
each such node with a corresponding tag sequence
ts in forest F , we compute the posterior probability
that the latent category of node U being Xi as:
P (Xi|ts) =
POUT(Ui)PIN(Ui)
PIN(R)
This contributes P (Xi|ts) evidence that tag se-
quence ts belongs to a Xi category. When all
of the evidences are computed and accumulated in
#(Xi, ts), they can then be normalized to obtain the
probability that the latent category of ts is Xi:
pts(Xi) =
#(Xi, ts)
?
i #(Xi, ts)
As described in Section 3, the distributions of latent
categories are used to compute the syntactic feature
vectors for the SCFG rules.
6 Experiments
We conduct experiments on two tasks, English-to-
German and English-to-Chinese, both aimed for
speech-to-speech translation. The training data for
the English-to-German task is a filtered subset of the
Europarl corpus (Koehn, 2005), containing ?300k
parallel bitext with ?4.5M tokens on each side. The
dev and test sets both contain 1k sentences with one
reference for each. The training data for the English-
to-Chinese task is collected from transcription and
human translation of conversations in travel domain.
It consists of ?500k parallel bitext with ?3M to-
kens14 on each side. Both dev and test sets contain
?1.3k sentences, each with two references. Both
14The Chinese sentences are automatically segmented into
words. However, BLEU scores are computed at character level
for tuning and evaluation.
144
corpora are also preprocessed with punctuation re-
moved and words down-cased to make them suitable
for speech translation.
The baseline system is our implementation of the
hierarchical phrase-based model of Chiang (2007),
and it includes basic features such as rule and
lexicalized rule translation probabilities, language
model scores, rule counts, etc. We use 4-gram lan-
guage models in both tasks, and conduct minimum-
error-rate training (Och, 2003) to optimize feature
weights on the dev set. Our baseline hierarchical
model has 8.3M and 9.7M rules for the English-to-
German and English-to-Chinese tasks, respectively.
The English side of the parallel data is
parsed by our implementation of the Berkeley
parser (Huang and Harper, 2009) trained on the
combination of Broadcast News treebank from
Ontonotes (Weischedel et al, 2008) and a speechi-
fied version of the WSJ treebank (Marcus et al,
1999) to achieve higher parsing accuracy (Huang et
al., 2010). Our approach introduces a new syntactic
feature and its feature weight is tuned in the same
way together with the features in the baseline model.
In this study, we induce 16 latent categories for both
X and B nonterminals.
Our approach identifies ?180k unique tag se-
quences for the English side of phrase pairs in both
tasks. As shown by the examples in Table 2, the syn-
tactic feature vector representation is able to identify
similar and dissimilar tag sequences. For instance,
it determines that the sequence of ?DT JJ NN? is
syntactically very similar to ?DT ADJP NN? while
very dissimilar to ?NN CD VP?. Notice that our la-
tent categories are learned automatically to maxi-
mize the likelihood of the training forests extracted
based on alignment and are not explicitly instructed
to discriminate between syntactically different tag
sequences. Our approach is not guaranteed to al-
ways assign similar feature vectors to syntactically
similar tag sequences. However, as the experimental
results show below, the latent categories are able to
capture some similarities among tag sequences that
are beneficial for translation.
Table 3 and 4 report the experimental results
on the English-to-German and English-to-Chinese
tasks, respectively. The addition of the syntax fea-
ture achieves a statistically significant improvement
(p ? 0.01) of 0.6 in BLEU on the test set of the
Baseline +Syntax ?
Dev 16.26 17.06 0.80
Test 16.41 17.01 0.60
Table 3: BLEU scores of the English-to-German task
(one reference).
Baseline +Syntax ?
Dev 46.47 47.39 0.92
Test 45.45 45.86 0.41
Table 4: BLEU scores of the English-to-Chinese task
(two references).
English-to-German task. This improvement is sub-
stantial given that only one reference is used for each
test sentence. On the English-to-Chinese task, the
syntax feature achieves a smaller improvement of
0.41 BLEU on the test set. One potential explanation
for the smaller improvement is that the sentences on
the English-to-Chinese task are much shorter, with
an average of only 6 words per sentence, compared
to 15 words in the English-to-German task. The
hypothesis space of translating a longer sentence is
much larger than that of a shorter sentence. There-
fore, there is more potential gain from using syn-
tax features to rule out unlikely derivations of longer
sentences, while phrasal rules might be adequate for
shorter sentences, leaving less room for syntax to
help as in the case of the English-to-Chinese task.
7 Discussions
The incorporation of the syntactic feature into the
hierarchical phrase-based translation system also
brings in additional memory load and computational
cost. In the worst case, our approach requires stor-
ing one feature vector for each tag sequence and one
feature vector for each nonterminal of a SCFG rule,
with the latter taking the majority of the extra mem-
ory storage. We observed that about 90% of the
X nonterminals in the rules only have one tag se-
quence, and thus the required memory space can be
significantly reduced by only storing a pointer to the
feature vector of the tag sequence for these nonter-
minals. Our approach also requires computing one
dot-product of two feature vectors for each nonter-
minal when a SCFG rule is applied to a source span.
145
Very similar Not so similar Very dissimilar
~F (ts) ? ~F (ts?) > 0.9 0.4 ? ~F (ts) ? ~F (ts?) ? 0.6 ~F (ts) ? ~F (ts?) < 0.1
DT JJ NN
DT NN DT JJ JJ NML NN PP NP NN
DT JJ JJ NN DT JJ CC INTJ VB NN CD VP
DT ADJP NN DT NN NN JJ RB NP IN CD
VP
VB VP PP JJ NN JJ NN TO VP
VB RB VB PP VB NN NN VB JJ WHNP DT NN
VB DT DT NN VB RB IN JJ IN INTJ NP
ADJP
JJ ADJP JJ JJ CC ADJP IN NP JJ
PDT JJ ADJP VB JJ JJ AUX RB ADJP
RB JJ ADVP WHNP JJ ADJP VP
Table 2: Examples of similar and dissimilar tag sequences.
This cost can be reduced, however, by caching the
dot-products of the tag sequences that are frequently
accessed.
There are other successful investigations to
impose soft syntactic constraints to hierarchical
phrase-based models by either introducing syntax-
based rule features such as the prior derivation
model of Zhou et al (2008) or by imposing con-
straints on translation spans at decoding time, e.g.,
(Marton and Resnik, 2008; Xiong et al, 2009;
Xiong et al, 2010). These approaches are all or-
thogonal to ours and it is expected that they can be
combined with our approach to achieve greater im-
provement.
This work is an initial effort to investigate latent
syntactic categories to enhance hierarchical phrase-
based translation models, and there are many direc-
tions to continue this line of research. First, while
the current approach imposes soft syntactic con-
straints between the parse structure of the source
sentence and the SCFG rules used to derive the
translation, the real-valued syntactic feature vectors
can also be used to impose soft constraints between
SCFG rules when rule rewrite occurs. In this case,
target side parse trees could also be used alone or to-
gether with the source side parse trees to induce the
latent syntactic categories. Second, instead of using
single parse trees during both training and decod-
ing, our approach is likely to benefit from exploring
parse forests as in (Mi and Huang, 2008). Third,
in addition to the treebank categories obtained by
syntactic parsing, lexical cues directly available in
sentence pairs could also to explored to guide the
learning of latent categories. Last but not the least,
it would be interesting to investigate discriminative
training approaches to learn latent categories that di-
rectly optimize on translation quality.
8 Conclusion
We have presented a novel approach to enhance
hierarchical phrase-based machine translation sys-
tems with real-valued linguistically motivated fea-
ture vectors. Our approach maintains the advan-
tages of hierarchical phrase-based translation sys-
tems while at the same time naturally incorpo-
rates soft syntactic constraints. Experimental results
showed that this approach improves the baseline hi-
erarchical phrase-based translation models on both
English-to-German and English-to-Chinese tasks.
We will continue this line of research and exploit
better ways to learn syntax and apply syntactic con-
straints to machine translation.
Acknowledgements
This work was done when the first author was visit-
ing IBM T. J. Watson Research Center as a research
intern. We would like to thank Mary Harper for
lots of insightful discussions and suggestions and the
anonymous reviewers for the helpful comments.
References
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
146
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics.
Binh Minh Bui-Xuan, Michel Habib, and Christophe
Paul. 2005. Revisiting T. Uno and M. Yagiura?s al-
gorithm. In ISAAC.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics.
David Chiang. 2010. Learning to translate with source
and target syntax. In ACL.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2004. What?s in a translation rule. In
HLT/NAACL.
Steffen Heber and Jens Stoye. 2001. Finding all common
intervals of k permutations. In CPM.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In International Workshop on Parsing Tech-
nology.
Zhongqiang Huang and Mary Harper. 2009. Self-
training PCFG grammars with latent annotations
across languages. In EMNLP.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
A syntax-directed translator with extended domain of
locality. In CHSLP.
Zhongqiang Huang, Vladimir Eidelman, and Mary
Harper. 2009. Improving a simple bigram hmm part-
of-speech tagger by latent annotation and self-training.
In NAACL.
Zhongqiang Huang, Mary Harper, and Slav Petrov. 2010.
Self-training with products of latent variable. In
EMNLP.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In ACL.
Mitchell P. Marcus, Beatrice Santorini, Mary Ann
Marcinkiewicz, and Ann Taylor, 1999. Treebank-3.
Linguistic Data Consortium, Philadelphia.
Yuval Marton and Philip Resnik. 2008. Soft syntactic
constraints for hierarchical phrased-based translation.
In ACL.
Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.
2005. Probabilistic CFG with latent annotations. In
ACL.
Haitao Mi and Liang Huang. 2008. Forest-based transla-
tion rule extraction. In EMNLP.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In ACL.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In ACL.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In ACL.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In ACL.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference grammars: soft-
ening syntactic constraints to improve statistical ma-
chine translation. In NAACL.
Ralph Weischedel, Sameer Pradhan, Lance Ramshaw,
Martha Palmer, Nianwen Xue, Mitchell Marcus, Ann
Taylor, Craig Greenberg, Eduard Hovy, Robert Belvin,
and Ann Houston, 2008. OntoNotes Release 2.0. Lin-
guistic Data Consortium, Philadelphia.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics.
Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li. 2009.
A syntax-driven bracketing model for phrase-based
translation. In ACL-IJCNLP.
Deyi Xiong, Min Zhang, and Haizhou Li. 2010. Learn-
ing translation boundaries for phrase-based decoding.
In NAACL-HLT.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In ACL.
Hao Zhang, Daniel Gildea, and David Chiang. 2008. Ex-
tracting synchronous grammar rules from word-level
alignments in linear time. In COLING.
Bowen Zhou, Bing Xiang, Xiaodan Zhu, and Yuqing
Gao. 2008. Prior derivation models for formally
syntax-based translation using linguistically syntactic
parsing and tree kernels. In SSST.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
augmented machine translation via chart parsing. In
StatMT.
147
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 501?512,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Anchor Graph:
Global Reordering Contexts for Statistical Machine Translation
Hendra Setiawan ?
IBM Research
1101 Kitchawan Road
NY 10598, USA
Bowen Zhou
IBM Research
1101 Kitchawan Road
NY 10598, USA
Bing Xiang ?
Thomson Reuters
3 Times Square
NY 10036, USA
Abstract
Reordering poses one of the greatest chal-
lenges in Statistical Machine Translation re-
search as the key contextual information may
well be beyond the confine of translation units.
We present the ?Anchor Graph? (AG) model
where we use a graph structure to model
global contextual information that is crucial
for reordering. The key ingredient of our AG
model is the edges that capture the relation-
ship between the reordering around a set of
selected translation units, which we refer to as
anchors. As the edges link anchors that may
span multiple translation units at decoding
time, our AG model effectively encodes global
contextual information that is previously ab-
sent. We integrate our proposed model into a
state-of-the-art translation system and demon-
strate the efficacy of our proposal in a large-
scale Chinese-to-English translation task.
1 Introduction
Reordering remains one of the greatest challenges
in Statistical Machine Translation (SMT) research as
the key contextual information may span across mul-
tiple translation units.1 Unfortunately, previous ap-
proaches fall short in capturing such cross-unit con-
textual information that could be critical in reorder-
ing. For example, state-of-the-art translation mod-
els, such as Hiero (Chiang, 2005) or Moses (Koehn
et al, 2007), are good at capturing local reordering
within the confine of a translation unit, but their for-
mulation is approximately a simple unigram model
? This work was done when the authors were with IBM.
1We define translation units as phrases in phrase-based SMT
or as translation rules in syntax-based SMT.
over derivation (a sequence of the application of
translation units) with some aid from target language
models. Moving to a higher order formulation (say
to a bigram model) is highly impractical for several
reasons: 1) it has to deal with a severe sparsity issue
as the size of the unigram model is already huge;
and 2) it has to deal with a spurious ambiguity issue
which allows multiple derivations of a sentence pair
to have radically different model scores.
In this paper, we develop ?Anchor Graph? (AG)
where we use a graph structure to capture global
contexts that are crucial for translation. To circum-
vent the sparsity issue, we design our model to rely
only on contexts from a set of selected translation
units, particularly those that appear frequently with
important reordering patterns. We refer to the units
in this special set as anchors where they act as ver-
tices in the graph. To address the spurious ambigu-
ity issue, we insist on computing the model score for
every anchors in the derivation, including those that
appear inside larger translation units, as such our AG
model gives the same score to the derivations that
share the same reordering pattern.
In AG model, the actual reordering is modeled
by the edges, or more specifically, by the edges? la-
bels where different reordering around the anchors
would correspond to a different label. As detailed
later, we consider two distinct set of labels, namely
dominance and precedence, reflecting the two domi-
nant views about reordering in literature, i.e. the first
one that views reordering as a linear operation over
a sequence and the second one that views reordering
as a recursive operation over nodes in a tree struc-
ture The former is prevalent in phrase-based con-
text, while the latter in hierarchical phrase-based and
501
syntax-based context. More concretely, the domi-
nance looks at the anchors? relative positions in the
translated sentence, while the precedence looks at
the anchors? relative positions in a latent structure,
induced via a novel synchronous grammar: Anchor-
centric, Lexicalized Synchronous Grammar.
From these two sets of labels, we develop two
probabilistic models, namely the dominance and the
orientation models. As the edges of AG link pairs
of anchors that may appear in multiple translation
units, our AG models are able to capture high or-
der contextual information that is previously absent.
Furthermore, the parameters of these models are es-
timated in an unsupervised manner without linguis-
tic supervision. More importantly, our experimental
results demonstrate the efficacy of our proposed AG-
based models, which we integrate into a state-of-the-
art syntax-based translation system, in a large scale
Chinese-to-English translation task. We would like
to emphasize that although we use a syntax-based
translation system in our experiments, in principle,
our approach is applicable to other translation mod-
els as it is agnostic to the translation units.
2 Anchor Graph Model
Formally, an AG consists of {A,L} where A is a
set of vertices that correspond to anchors, while L
is a set of labeled edges that link a pair of anchors.
In principle, our AG model is part of a transla-
tion model that focuses on the reordering within the
source sentence F and its translation E. Thus, we
start by first introducing A into a translation model
(either word-based, phrase-based or syntax-based
model) followed by L. Given an F , A is essentially
a subset of non-overlapping (word or phrase) units
that make up F . As the information related to A is
not observed, we introduce A as a latent variable.
Let P (E,? |F ) be a translation model where ?
corresponds to the alignments between units in F
and E. 2 We introduce A into a translation model,
2Alignment (?) represents an existing latent variable. De-
pending on the translation units, it can be defined at different
level, i.e. word, phrase or hierarchical phrase. As during trans-
lation, we are interested in the anchors that appear inside larger
translation units, we set ? at word level, which information can
be induced for (hierarchical) phrase units by either keeping the
word alignment from the training data inside the units or infer-
ring it via lexical translation probability. We use the former.
as follow:
P (E,? |F ) =
?
?A?
P (E,?,A?|F ) (1)
P (E,?,A?|F ) = P (E,? |A?, F )P (A?) (2)
As there can be many possible subsets of F and
summing over all possibleA is intractable, we make
the following approximation for P (A?) such that we
only need to consider one particular A?: P (A?) =
?(A? = A?) which returns 1 only for A?, otherwise
0. The exact definition of the heuristic will be de-
scribed in Section 7, but in short, we equateA? with
units that appear frequently with important reorder-
ing patterns in training data.
Given an A?, we then introduce the edges of AG
(L) into the equation as follow:
P (E,? |A?, F ) = P (E,?,L|A?, F ) (3)
Note that L is also a latent variable but its values are
derived deterministically from (F,E,?) and A?,
thus no extra summation is present in Eq. 3.
Then, we further simplify Eq. 3 by factorizing it
with respect to each individual edges, as follow:
P (E,?,L|A?, F ) ?
?
?am,an?A?
m<n
P (Lm,n|am, an) (4)
where Lm,n ? L corresponds to the label of an edge
that links am and an.
In principle, Lm,n can take any arbitrary value.
For addressing the reordering challenge, it should
ideally correspond to some aspect of the reordering
around am and an, for example, how the reorder-
ing around am affects the reordering around an. As
mentioned earlier, we choose to associate Lm,n with
the dominance and the precedence relations between
am and an, where the former looks at the relative po-
sitions of the two anchors when they are projected
into a latent tree structure, while the latter looks at
their relative positions when they are projected into
the target sentence. We illustrate the two in Fig. 1.
Furthermore, we assume that dominance and
precedence are independent and develop one model
for each, resulting in the dominance and the orien-
tation models, which we describe in Section 3 and 4
respectively. To make the model more compact, we
502
introduce an additional parameterO that restricts the
maximum order of AG as follows:
?
O?
o=1
|A?|+o?1?
i=0
Po(Li?o,i|ai?o, ai) (5)
Thus, we only consider edges that link two anchors
that are at most O? 1 anchors apart. For O = 1, the
AG model only considers relations between neigh-
boring anchors. Following the standard practice in
the n-gram language modeling, we append O num-
ber of pseudo anchors at the beginning and at the end
of F , which represent the sentence delimiter mark-
ers. We do so in a monotone order.
Figure 1: The illustration of the dominance and the prece-
dence relations. The former looks at the anchors? pro-
jection on a derivation structure. The latter looks at the
anchors? projection on the translated sentence.
3 Dominance Model
This section describes our dominance model where
we equate Lm,n in Eq. 4 with dom(am, an) that ex-
presses to the dominance relation between am and
an in a latent tree structure. Due to reordering, an-
chors can only appear in specific nodes. We first
describe a novel formalism of Anchor-centric, Lexi-
calized Synchronous Grammar (AL-SG), used to in-
duce the tree structure and then discuss the proba-
bilistic formulation of the model. Just to be clear,
we introduce AL-SG mainly to facilitate the compu-
tation of dom(am, an). The actual translation model
at decoding time remains either phrase-based, hier-
archical phrase-based or syntax-based model.
3.1 Anchor-centric, Lexicalized Synchronous
Grammar
Given (F,E,?) and A, Anchor-centric, Lexical-
ized Synchronous Grammar (AL-SG) produces a
tree structure where the nodes are decorated with
anchors-related information. As the name alludes,
the core of AL-SG is anchor-centric constituents
(ACC), which corresponds to nodes, composed from
merging anchors with by either their left, their right
neighboring constituents or both.
More concretely, first of all, we consider a span
on the source sentence F to be a constituent if it is
consistent with the alignment (?). Second of all, we
can construct a larger constituent by merging smaller
constituents given that the larger constituent is also
consistent with the alignment. These two constraints
are similar to the heuristic applied to extract hierar-
chical phrases (Chiang, 2005).
Then, specific to AL-SG, we consider an anchor a
to lexicalize a constituent c, if: a) we can compose c
from at most three smaller constituents: cL, a and cR
where a is the anchor while cL,cR are the (possibly
empty) constituents immediately to the left and to
the right of a; and b) we can create smaller anchors-
centric constituents from concatenating a with cL
and a with cR. If a can lexicalize c, then the node
associated with c would be marked with a. In com-
puting dom(am, an), we look at the constituents that
cover both anchors and check whether the anchors
can lexicalized any of such constituents.
Now, we will describe AL-SG in a formal way.
For simplicity, we use a simple grammar, called In-
version Transduction Grammar (ITG) (Wu, 1997),
although in practice, we handle a more powerful
synchronous grammar. Hence, we proceed to de-
scribe Anchor-centric, Lexicalized ITG (AL-ITG).
An AL-ITG is a quadruple {?,A,V,R} where:
? ? = {(f/e)} is a set of terminal symbols,
which represents all possible units defined over
(F,E,?) where each pair corresponds to a link
in ?. We define ? at the most fine-grained
level (i.e. word-level), as we insist on comput-
ing model score for each anchors even if they
appear inside larger units.
? A ? ? is a set of anchors, which is a subset of
the terminal symbols.
? V = {{P,X, Y } ? {A, ?}} is a set of (possi-
bly lexicalized) nonterminal symbols. P rep-
resents the terminal symbols (?); while X and
Y correspond to the spans that are created from
merging two adjacent constituents. On the tar-
503
Figure 2: An illustration of an aligned Chinese-English sentence pair with one possible AL-ITG derivation obtained
by applying the grammar in a left-to-right fashion. Circles represent alignment points. Black circle represents the
anchor; boxes represent the anchor?s neighbors. In the derivation tree, the anchors are represented by their position
and in bold. For succinctness, we omit the preterminal rules in the tree.
get side, for X , the order of the two children
follows the source order, while for Y , the or-
der follows the inverse. Nonterminal symbols
can be lexicalized with zero or more than one
anchor. We represent a lexicalized constituent
as a nonterminal symbol followed by a bracket
which contains the lexicalizing anchors, e.g.
P (H) where H is the anchors lexicalizing P .
? R is a set of production rules which can be clas-
sified into the following categories:
? Preterminal rules. We propagate the sym-
bol if it corresponds to an anchor.
P (H = f/e)? f/e, if f/e ? A?
P (H = ?)? f/e, otherwise
? Monotone production rules, which reorder
the children in monotone order, denoted
by square brackets (?[?,?]?).
X(H1 ?H2)? [P (H1)P (H2)]
X(H1 ?H2)? [X(H1)P (H2)]
X(H1 ?H2)? [X(H1)X(H2)]
X(H1)? [X(H1)Y (H2)]
X(H2)? [Y (H1)P (H2)]
X(H2)? [Y (H1)X(H2)]
X(?)? [Y (H1)Y (H2)]
? Inverse production rules, which reorder
the children in the inverse order, denoted
by angle brackets (???,???).
Y (H1 ?H2)? ?P (H1)P (H2)?
Y (H1 ?H2)? ?Y (H1)P (H2)?
Y (H1 ?H2)? ?Y (H1)Y (H2)?
Y (H1)? ?Y (H1)X(H2)?
Y (H2)? ?X(H1)P (H2)?
Y (H2)? ?X(H1)Y (H2)?
Y (?)? ?X(H1)X(H2)?
Like ITG, AL-ITG only permits two kind of re-
ordering operations, namely monotone and inverse.
To accommodate the lexicalization, we first assign
a unique nonterminal symbol for each, i.e. X for
monotone reordering and Y for inverse reordering.
Then, we lexicalize Xs and Y s with anchors as long
as they satisfy the constraint that the child shares the
same label as the parent. This constraint guarantees
that the constituents are valid ACCs. It also enables
the anchors to lexicalize long constituents, although
the terminal symbols are defined at word-level.
Fig. 2 illustrates an example Chinese-to-English
translation with a AL-ITG derivation when the
grammar is applied in a left-to-right fashion. Admit-
tedly, AL-ITG (or more generally AL-SG) is suscep-
tible to spurious ambiguity as it produces multiple
derivation trees for a given (F,E,?). Fortunately,
the value of dom(am, an) is identical for all deriva-
tions, since the computation of dom(am, an) relies
504
only on whether am and an can lexicalize at least
one constituent that covers both anchors. Hence,
we only need to look at one derivation to compute
dom(am, an). Generalizing AL-ITG to a more pow-
erful formalism is trivial; we just need to forbid the
propagation for non-binarizeable production rules.
3.2 Probabilistic Model
We read-off the dominance relations dom(am, an)
from D obtained from the application of AL-SG to
(F,E,?). As lexicalization is a bottom-up process,
for reading-off dom(am, an), it is sufficient to look
at the lowest common ancestor (LCA) of both an-
chors; if the anchors cannot lexicalize the LCA, they
won?t be able to lexicalize the constituents larger
than LCA. To be more concrete, let?s consider theD
in Fig. 2. In that D, the LCA of am = yu3/with10
and an = de7/that7 is Y5(7). Then, we check the
anchors that can lexicalize the LCA. Let V (H) be
the LCA, then dom(am, an) ?
(LH) , if am ? H ? an 6? H
(RH) , if am 6? H ? an ? H
(BL) , if am ? H ? an ? H
(BD) , if am 6? H ? an 6? H
The value refers to cases where am and an can
lexicalize V (H) and it is useful to model spans
that share a simple, uniform reordering, i.e. all-
monotone or all-inverse, while the value refers to
the cases where am and an cannot lexicalize V (H)
and it is useful to model spans that involve in a com-
plex reordering. Meanwhile, the and refer to cases
where only one anchor can lexicalize V (H), i.e. am
and an respectively. These values are useful for
modeling cases where the surroundings of the two
anchors exhibit different kind of reordering pattern.
With such definition, the edge labels L in Fig. 2
are indicated in Table 1. Note that in Table 1, we
don?t specify the relations involving pseudo anchors,
although they are crucial.
The final probabilistic formulation of the domi-
nance model is as follows:
?
O?
o=1
|A|+o?1?
i=0
Pdomo(dom(ai?o, ai)|ai?o, ai) (6)
As shown, we allocate a separate model Pdomo for
each separate order (o) where each Pdomo will con-
HHH
HHn
m
1 2 3 4 5
1 = (shi2/is2) - - - - -
2 = (yu3/with10) LH - - - -
3 = (you5/have8) LH BD - - -
4 = (de7/that7) LH RH RH - -
5 = (zhi10/of4) LH RH RH BL -
Table 1: The dominance relations between pairs of an-
chors according to the derivation in Fig. 2.
tribute as one additional feature in the log-linear
model of the translation model. In allocating a sep-
arate model for each o, we conjecture that different
pair of anchors contributes differently depending on
how far the two anchors are.
4 Orientation Model
In this section, we introduce the orientation model
(ori) where we equate Lm,n with the precedence re-
lations between a pair of anchors. Instead of directly
modeling the precedence between the two anchors,
we approximate it by modeling the precedence of
each anchor with its neighboring constituents. For-
mally, we approximate P (Lm,n|am, an) as
PoriR(ori(am,MR(am))|am)?
PoriL(ori(an,ML(an))|an) (7)
where MR(am) is the largest constituent to the right
of the first anchor am, ML(an) the largest con-
stituent to the left of the second anchor an, and ori()
a function that maps the anchor and the neighboring
constituent to a particular orientation.
Plugging Eq. 7 into Eq. 5 results in the following
approximation of P (?|A):
C.
|A|?1?
i=0
{PoriL(ori(ai,ML(ai))|ai)?
PoriR(ori(ai,MR(ai))|ai)}
O (8)
where C is a constant term related to the pseudo an-
chors and O is the maximum order of the AG. In
practice, we can safely ignore both C and O as they
are constant for a given AG. As shown, the orienta-
tion model is simplified into a model that looks at the
reordering of the anchors? neighboring constituents.
The exact definition of ML and MR will be
discussed in Section 5. Their orientation, i.e.
505
oriL(CL, a) and oriR(CR, a) respectively, may take
one of the following four values: (MA), (RA), (MG)
and (RG). The first clause (monotone, reverse) in-
dicates whether the target order follows the source
order; the second (adjacent, gap) indicates whether
the anchor and its neighboring constituent are adja-
cent or separated by an intervening when projected.
5 Parameter Estimation
For each (F,E,?), the training starts with the iden-
tification of the regions in the source sentences as
anchors (A). For our Chinese-English experiments,
we use a simple heuristic that equates anchors (A?)
with constituents whose corresponding word class
belongs to function words-related classes, bearing
a close resemblance to (Setiawan et al, 2007). In
total, we consider 21 part-of-speech tags; some of
which are as follows: VC (copula), DEG, DEG,
DER, DEV (de-related), PU (punctuation), AD (ad-
jectives) and P (prepositions).
5.1 Extracting Events from (F,E,?)
The parameter estimation first involves extracting
two statistics from (F,E,?), namely dom(am, an)
for the dominance model as well as ori(a,ML(a))
and ori(a,MR(a)) for the orientation model. In-
stead of developing a separate algorithm for each,
we describe a unified way to extract these statistics
via the largest neighboring constituents of the an-
chors, i.e. ML(a) and MR(a). This approach en-
ables the dominance model to share the same resid-
ual state information as the orientation model.3
Let am be an anchor and MR(am) be its largest
neighboring constituent to the right. Let an be
an anchor to the left of am and ML(an) be an?s
largest neighboring constituent to the left. Ac-
cording to AL-SG, we say that am dominates an
if ori(am,MR(am)) ? {MA,RA} and an ?
MR(am). By the same token, we say that an dom-
inates am if ori(an,ML(an)) ? {MA,RA} and
am ? ML(an). The constraints on the orientation
reflect the fact that in AL-SG, anchors can only be
propagated through monotone or inverse production
rules, which correspond to the MA and RA respec-
tively. The fact that we are looking at the largest
3The analogy in an n-gram language model is the first n?1
words of the hypothesis that have incomplete history.
neighboring constituents guarantees that if the other
anchor is outside that constituent, then that other an-
chor is never dominated.
More formally, given an aligned sentence pair
? = (F,E,?), let ?(?) be all possible con-
stituents that can be extracted from ?:4
{(f j2j1/e
i2
i1) :?(j, i) ??: ((j1? j? j2) ? (ii? i? i2))
?(?(j1? j? j2) ? ?(ii? i? i2))
Then, let the anchors A be a subset of ?(?).
Given A ? ?(?), let a = (f j2j1/e
i2
i1) ? A be a par-
ticular anchor. And, let CL(a) ? ?(?) be a?s left
neighbors and let CR(a) ? ?(?) be a?s right neigh-
bors, iff:
?CL = (f
j4
j3/e
i4
i3) ? CL(a) : j4 + 1 = j1
?CR = (f
j6
j5/e
i6
i5) ? CR(a) : j2 + 1 = j5
Then, let ML(a) ? CL(a) and MR(a) ? CR(a) be
the largest left and right neighbors according to:
ML(a) = arg max
(f
j4
j3
/e
i4
i3
)?CL(a)
(j4 ? j3)
MR(a) = arg max
(f
j6
j5
/e
i6
i5
)?CR(a)
(j6 ? j5)
Let ML = (f
j4
j3/e
i4
i3) and MR = (f
j6
j5/e
i6
i5).
We then proceed to extract oriL(a,ML(a)) and
oriR(a,MR(a)) respectively as follows:
? MA, if (i4 +1) = i1 for oriL or if (i2 +1) = i5
for oriR
? RA, if (i2 + 1) = i3 for oriL or if (i6 + 1) = i1
for oriR
? MG, if (i4 +1) < i1 for oriL or if (i2 +1) < i5
for oriR
? RG, if (i2 + 1) < i3 for oriL or if (i6 + 1) < i1
for oriR.
Then, we proceed to extract dom(am, an). Given
two anchors am, an where m < n, we define the
4We represent a constituent as a source and target phrase
pair (f j2j1/e
i2
i1
) where the subscript and the superscript indicate
the starting and the ending indices as such f j2j1 denotes a source
phrase that spans from j1 to j2.
506
dominance relation between am and an viaMR(am)
and ML(an). Let am = (f
j2
j1/e
i2
i1), MR(am) =
(f j4j3/e
i4
i3), an = (f
j6
j5/e
i6
i5) and ML(an) = (f
j8
j7/e
i8
i7).
Then, ldom(am, an) is true only if (j4 ? j6)
and oriR(am,MR(am)) ? {MA,RA}. Simi-
larly, rdom(am, an) is true only if (j7 ? j1) and
oriL(an,ML(an)) ? {MA,RA}.
Hence, dom(am, an) is as follows:
? LH, if ldom(am, an) ? ?rdom(am, an)
? RH, if ?ldom(am, an) ? rdom(am, an)
? BL, if ldom(am, an) ? rdom(am, an)
? BD, if ?ldom(am, an) ? ?rdom(am, an)
5.2 Parameterization and Training
After extracting events, we are now ready to train
the models. To estimate them, we train a discrimi-
native classifier for each model and use the normal-
ized posteriors at decoding time as additional feature
scores in SMT?s log-linear framework.
At a high level, we use a rich set of binary fea-
tures ranging from lexical to part-of-speech (POS)
and to syntactic features. Additionally, we augment
the feature set with compound features, e.g. a con-
junction of the source word of the left anchor and the
source word of the right anchor. Although they in-
crease the number of features significantly, we found
that they are empirically beneficial.
Suppose a = (f j2j1 /e
i2
i1), ML(a) = (f
j4
j3 /e
i4
i3) and
MR(a) = (f
j6
j5 /e
i6
i5), then based on the context?s
location, the elementary features employed in our
classifiers can be categorized into:
? anchor-related: (the actual word of f j2j1 ),
(part-of-speech (POS) tag of ), (?s parent in the
parse tree), (ei2i1?s actual target word).
? surrounding: (the previous word / f j1?1j1?1 ), (the
next word / f j2+1j2+1 ), (?s POS tag), (?s POS tag),
(?s parent), (?s parent).
? non-local: (the previous anchor?s source word)
, (the next anchor?s source word), (?s POS tag),
(?s POS tag).
There is a separate set of elementary features for am
and an and we come up with manual combination to
construct compound features.
In training the models, we manually come up with
around 30-50 types of features, which consists of a
combination of elementary and compound features.
Due to space constraints, we will describe the ac-
tual features that we use and the classification per-
formance of our models elsewhere. In total, we
generate around one hundred millions binary fea-
tures from our training data that contains six million
sentence pairs. To reduce the number of features,
we employ the L1-regularization in training to en-
force sparse solutions, using the off-the-shelf LIB-
LINEAR toolkit (Fan et al, 2008). After training,
the number of features in our classifiers decreases to
below 1 million features for each classifier.
6 Decoding
As mentioned earlier, we wish to avoid the spuri-
ous ambiguity issue where different derivations have
radically different scores although they lead to the
same reordering. This section describes our decod-
ing algorithm that avoids spurious ambiguity issue
by incrementally constructing MLs and MRs thus
allowing the computation of the models over partial
hypotheses.
In our experiments, we integrate our dominance
model as well as our orientation model into a syntax-
based SMT system that uses SCFG formalism. In-
tegrating the models into syntax-based SMT sys-
tems is non-trivial, especially since the anchors of-
ten reside within translation rules and the model
doesn?t always decompose naturally with the hy-
pothesis structure. To facilitate that, we need to
first induce the necessary alignment for all transla-
tion units in the hypothesis.
To describe the algorithm, let us consider a cheat-
ing exercise where we have to translate the Chinese
sentence in Fig. 2 with the following set of hierar-
chical phrases:
Xa??Aozhou
1shi2X1,Australia
1 is2X1?
Xb??yu
3 Beihan4X1, X1with
3 North4 Korea?
Xc??you
5bangjiao6, have5dipl.6 rels.?
Xd??X1 de
7shaoshu8 guojia9 zhi10 yi11,
one11of10the few8 countries9 that7X1?
As a case in point, let us consider D = Xa ? Xb
? Xd ? Xc, which will lead to the correct English
507
Target string (w/ source index) Symbol(s) read Op. Stack(s)
(1) Xc have
5 dipl.6 rels. [5][6] S,S,R Xc:[5-6]
(2) Xd one11 of
10 few8 countries9 [11][10] S,S,R [10-11]
that7 Xc
(3) [8][9] S,S,R,R [8-11]
(4) [7] S [8-11][7]
(5) Xc:[5,6] S Xd:[8-11][7][5,6]
(6) Xb Xd with
3 North4 Korea Xd:[8-11][7][5,6] S [8-11][7][5,6]
(7) [3][4] S,S,R,R Xb:[8-11][7][3-6]
(8) Xa Australia
1 is2 Xb [1][2] S,S,R [1-2]
(9) Xb:[8-11][7][3,6] S,A Xa:[1-2][8-11][7][3,6]
Table 2: The application of the shift-reduce parsing algorithm, which corresponds to the following derivation D =
Xa ? Xb ? Xd ? Xc. Anchor is in bold. In column Op., S, R and A refer to shift, reduce and accept operation
respectively.
translation as in Fig. 2. Note that the translation
rules contain internal word alignment, which we as-
sume to have been previously inferred.
The algorithm bears a close resemblance to the
shift-reduce algorithm found in phrase-based decod-
ing (Galley and Manning, 2008; Feng et al, 2010;
Cherry et al, 2012). A stack is used to accumulate
(partial) information about a, ML and MR for each
a ? A in the derivation. This algorithm takes an in-
put stream and applies either the shift or the reduce
operations starting from the beginning until the end
of the stream. The shift operation advances the input
stream by one symbol and push the symbol into the
stack; while the reduce operation applies some rule
to the top-most elements of the stack. The algorithm
terminates at the end of the input stream where the
resulting stack will be propagated to the parent for
the later stage of decoding. In our case, the input
stream is the target string of the rule and the symbol
is the corresponding source index of the elements of
the target string. The reduction rule looks at two in-
dices and merge them if they are adjacent (i.e. has
no intervening phrase). We forbid the application
of the reduction rule to anchors. Table 2 shows the
execution trace of the algorithm for the derivation
described earlier. For conciseness, we assume that
there is only one anchor and that is de7/that7.
As shown, the algorithm starts with an empty
stack. It then projects the source index to the corre-
sponding target word and then enumerates the target
string in a left to right fashion. If it finds a target
word with a source index, it applies the shift oper-
ation, pushing the index to the stack. Unless the
symbol corresponds to an anchor, it tries to apply
the reduce operation. Line (4) indicates the special
treatment to the anchor. If the symbol being read
is a nonterminal, then we push the entire stack that
corresponds to that nonterminal. For example, when
the algorithm reads Xd at line (6), it pushes the en-
tire stack from line (5).
As MLs and MRs are being incremen-
tally constructed, we can immediately com-
pute Pdomo(dom(am, an)|am, an) as soon
as a partial derivation covers both am
and an. For example, we can compute
Pdom1(dom(you5/have8, de7/that7) = ),
Pdom1(dom(de7/that7, zhi10/of4) = ) and
Pdom2(dom(you5/have8, zhi10/of4) = ) at
partial hypothesis Xd ? Xc which corresponds to a
constituent spanning from 5-11.
7 Experiments
Our baseline systems is a state-of-the-art string-to-
dependency system (Shen et al, 2008). The sys-
tem is trained on 10 million parallel sentences that
are available to the Phase 1 of the DARPA BOLT
Chinese-English MT task. The training corpora in-
clude a mixed genre of newswire, weblog, broad-
cast news, broadcast conversation, discussion fo-
rums and comes from various sources such as LDC,
HK Law, HK Hansard and UN data.
In total, our baseline model employs more than
50 features, including from our proposed dominance
and orientation models. In addition to the standard
508
Model
newswire weblog newswire+weblog
BLEU TER Comb BLEU TER Comb BLEU TER Comb
(a) (b) (c) (d) (e) (f) (g) (h) (i)
(1) S2D 37.63 53.17 7.77 27.60 57.19 14.77 33.39 54.97 10.79
(2) +dom1 38.12 52.31 7.10 27.56 56.58 14.51 33.64 54.24 10.30
(3) +dom2 38.31 52.28 6.99 27.66 56.57 14.45 33.78 54.20 10.21
(4) +dom3 38.31 52.52 7.10 28.24 56.56 14.16 34.02 54.33 10.15
(5) +dom4 38.54 52.22 6.84 28.38 56.55 14.08 34.20 54.16 9.98
(6) +dom5 38.17 52.57 7.20 28.67 56.27 13.80 34.16 54.27 10.05
(7) +dom6 38.17 52.52 7.18 28.64 56.22 13.79 34.10 54.18 10.04
(8) +ori 38.52 52.43 6.96 28.26 56.54 14.14 34.15 54.27 10.06
(9) +ori+dom1 38.87 52.05 6.59 28.01 56.48 14.23 34.26 54.03 9.89
(10) +ori+dom2 38.96 51.87 6.45 27.98 56.23 14.12 34.29 53.82 9.77
(11) +ori+dom3 39.19 51.77 6.29 28.19 56.15 13.98 34.52 53.73 9.61
(12) +ori+dom4 39.34 51.77 6.21 28.41 56.17 13.88 34.60 53.69 9.54
(13) +ori+dom5 39.31 51.67 6.18 28.62 56.09 13.74 34.76 53.65 9.45
Table 3: The NIST MT08 results on newswire (nw), weblog (wb) and combined genres. S2D is the baseline string-
to-dependency system (line 1). Lines 2-7 shows the results of the dominance model with O = 1 ? 6. Line 8 shows
result on adding ori to the baseline. Lines 9-13 shows the results of the orientation complemented with the dominance
model with varying O. The best BLEU, TER and Comb on each genre of the first set are in italic while those of the
second set are in bold. For BLEU, higher scores are better, while for TER and Comb, lower scores are better.
features such as translation probabilities, we incor-
porate features that are found useful for developing
a state-of-the-art baseline, such as the provenance
features (Chiang et al, 2011). We use a 6-gram
language model, which was trained on 10 billion
English words from multiple corpora, including the
English side of our parallel corpus plus other cor-
pora such as Gigaword (LDC2011T07) and Google
News. We also train a class-based language model
(Chen, 2009) on two million English sentences se-
lected from the parallel corpus. As for our string-to-
dependency system, we train 3-gram models for left
and right dependencies and unigram for head using
the target side of the parallel corpus. To train our
models, we select a set of 5 million sentence pairs.
For the tuning and development sets, we set
aside 1275 and 1239 sentences selected from
LDC2010E30 corpus. We tune the feature weights
with PRO (Hopkins and May, 2011) to minimize
(TER-BLEU)/2 metric. As for the blind test set,
we report the performance on the NIST MT08 eval-
uation set, which consists of 691 sentences from
newswire and 666 sentences from weblog. We pick
the weights that produce the highest development set
scores to decode the test set.
We perform two sets of experiments. The first set
looks at the contribution of the dominance model
with varying values of o. The second one looks at
the combination of the dominance model and the
orientation model. Table 3 summarizes the experi-
mental results on NIST MT08 sets, categorized by
genres. We report the results on newswire genre in
columns a-c, those on weblog genre in column d-f,
and those on mixed genre in column g-i. The perfor-
mance of our baseline string-to-dependency syntax-
based SMT is shown in the first line.
Lines 2-7 in Table 3 show the results of our first
set of experiments, starting from the result of dom1,
which looks at only at pairs of adjacent anchors, to
the result of dom6, which looks at pairs of anchors
that are at most 5 anchors away. As shown in line
2, our dominance model provides a nice improve-
ment of around 0.5 point over the baseline even if it
only looks at restricted context. Increasing the or-
der of our dominance model provides an additional
gain. However, the gain is more pronounced in the
weblog genre (up to around 1 BLEU point) than in
the newswire genre. We conjecture that this may be
the artifact of our tune set, which comes from the
weblog genre. We stop at dom6 because we observe
509
that the weight of the feature score that corresponds
to the maximum order (o = 6) has a negative sign,
which often indicates a high correlation between the
new features and existing ones.
Lines 8-13 in Table 3 shows the results of our sec-
ond set of experiments. Line 8 shows the result of
adding the orientation model (ori) to the baseline
system. As shown, integrating ori shows a signifi-
cant gain. On top of which, we then integrate dom1
to dom5. We see a very encouraging result as adding
the dominance model increases the performance fur-
ther, consistently over different value of o. This sug-
gests that the dominance model is complementary
to the orientation model. Our best result provides
more than 1 BP improvement and 1 TER reduction
consistently over different genres. We see this result
as confirming our intuition that the global contextual
information provided by our AG model can signifi-
cantly improve the performance of SMT even in a
state-of-the-art system.
8 Related Work
Our work intersects with existing work in many dif-
ferent respects. In this section, we mainly focus on
work related to introducing higher-order contextual
information to reordering model.
In providing global contextual information, our
work is related to a large amount of literature. To
name a few, Zens and Ney (2006) improves the lexi-
calized reordering model of Tillman (2004) by in-
corporating part-of-speech information. Chang et
al. (2009) incorporates contexts from syntactic parse
tree. Bach et al (2009) exploits the dependency in-
formation and Xiong et al (2012) uses the predicate-
argument structure.
Vaswani et al (2011) introduces rule markov
models for a forest-to-string model in which the
number of possible derivations is restricted. More
recently, Durrani et al (2013) and Zhang et al
(2013) cast reordering process as a Markov process.
Similar to these models, our proposed model also
provide context dependencies to the application of
translation rules, however, as they focus on mini-
mal translation units (MTU) where we focus on a
selected set of translation units. (Banchs et al, 2005)
introduces a bigram model for monotone phrase-
based system, but their definition of translation units
is suitable only for language pairs with limited re-
ordering, such as translating Spanish to English.
In equating anchors with the function word class,
our work is closely related to the function word-
centered model of Setiawan et al (2007), especially
the orientation model. Our dominance model is
closely related to the reordering model of Setiawan
et al (2009), except that they only look at pair of ad-
jacent anchors, forming a chain structure instead of
a graph like in our dominance model. Furthermore,
we provide a discriminative treatment to the model
to include a richer set of features including syntac-
tic features. This work can be seen as modeling the
identity of the neighboring of the anchors, similar to
(Setiawan et al, 2013). However, instead of looking
at the words at the borders, we look at whether the
neighboring constituents contain other anchors.
9 Conclusion
We propose the ?Anchor Graph? (AG) model to en-
code global contextual information. A selected set
of translation units, which we call anchors, serves
as the vertices of AG. And as the edges, we model
two types of relations, namely the dominance and
the precedence relations, where the former looks at
the positions of the anchors in the derivation struc-
ture, while the latter looks at the positions of the
anchors in the surface structure, resulting into two
probabilistic models over edge labels. As the mod-
els look at the pairs of anchors that go beyond multi-
ple translation units, our AG model provides global
contextual information.
Our AG model embodies (admittedly crudely)
some basic principles of sentence organization,
namely categorization (in categorizing units into an-
chors and non-anchors), linear order (in modeling
the precedence of anchors) and constituency struc-
ture (in modeling the dominance between anchors).
We are encouraged by the facts that we learn these
principles in an unsupervised way and that we can
achieve a significant improvement over a strong
baseline in a large-scale Chinese-to-English trans-
lation task. In the future, we hope to continue this
line of research, perhaps by learning to identify an-
chors automatically from training data or by using
our models to induce derivations directly from un-
aligned sentence pair.
510
Acknowledgements
We would like to acknowledge the support of
DARPA under Grant HR0011-12-C-0015 for fund-
ing part of this work. The views, opinions, and/or
findings contained in this article/presentation are
those of the author/presenter and should not be inter-
preted as representing the official views or policies,
either expressed or implied, of the DARPA.
References
Nguyen Bach, Qin Gao, and Stephan Vogel. 2009.
Source-side dependency tree reordering models with
subtree movements and constraints. In Proceedings of
the Twelfth Machine Translation Summit (MTSummit-
XII), Ottawa, Canada, August. International Associa-
tion for Machine Translation.
Rafael E. Banchs, Josep M. Crego, Adria` de Gispert, Pa-
trik Lambert, and Jose? B. Marin?o. 2005. Statisti-
cal machine translation of Euparl data by using bilin-
gual n-grams. In Proceedings of the ACL Workshop
on Building and Using Parallel Texts, pages 133?136,
Ann Arbor, Michigan, June. Association for Compu-
tational Linguistics.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D. Manning. 2009. Discriminative re-
ordering with Chinese grammatical relations features.
In Proceedings of the Third Workshop on Syntax and
Structure in Statistical Translation (SSST-3) at NAACL
HLT 2009, pages 51?59, Boulder, Colorado, June. As-
sociation for Computational Linguistics.
Stanley Chen. 2009. Shrinking exponential language
models. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 468?476, Boulder, Colorado,
June. Association for Computational Linguistics.
Colin Cherry, Robert C. Moore, and Chris Quirk. 2012.
On hierarchical re-ordering and permutation parsing
for phrase-based decoding. In Proceedings of the
Seventh Workshop on Statistical Machine Translation,
pages 200?209, Montre?al, Canada, June. Association
for Computational Linguistics.
David Chiang, Steve DeNeefe, and Michael Pust. 2011.
Two easy improvements to lexical weighting. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies, pages 455?460, Portland, Oregon, USA,
June. Association for Computational Linguistics.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL?05), pages 263?270, Ann
Arbor, Michigan, June. Association for Computational
Linguistics.
Nadir Durrani, Alexander Fraser, and Helmut Schmid.
2013. Model with minimal translation units, but de-
code with phrases. In Proceedings of the 2013 Con-
ference of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies, pages 1?11, Atlanta, Georgia, June. As-
sociation for Computational Linguistics.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A li-
brary for large linear classification. Journal of Ma-
chine Learning Research, 9:1871?1874.
Yang Feng, Haitao Mi, Yang Liu, and Qun Liu. 2010. An
efficient shift-reduce decoding algorithm for phrased-
based machine translation. In Coling 2010: Posters,
pages 285?293, Beijing, China, August. Coling 2010
Organizing Committee.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing,
pages 848?856, Honolulu, Hawaii, October. Associa-
tion for Computational Linguistics.
Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proceedings of the 2011 Conference on Empir-
ical Methods in Natural Language Processing, pages
1352?1362, Edinburgh, Scotland, UK., July. Associa-
tion for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation, June.
Hendra Setiawan, Min-Yen Kan, and Haizhou Li. 2007.
Ordering phrases with function words. In Proceed-
ings of the 45th Annual Meeting of the Association
of Computational Linguistics, pages 712?719, Prague,
Czech Republic, June. Association for Computational
Linguistics.
Hendra Setiawan, Min Yen Kan, Haizhou Li, and Philip
Resnik. 2009. Topological ordering of function words
in hierarchical phrase-based translation. In Proceed-
ings of the Joint Conference of the 47th Annual Meet-
ing of the ACL and the 4th International Joint Confer-
ence on Natural Language Processing of the AFNLP,
pages 324?332, Suntec, Singapore, August. Associa-
tion for Computational Linguistics.
Hendra Setiawan, Bowen Zhou, Bing Xiang, and Libin
Shen. 2013. Two-neighbor orientation model with
cross-boundary global contexts. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
511
1264?1274, Sofia, Bulgaria, August. Association for
Computational Linguistics.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings of ACL-08: HLT, pages 577?585, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
Christoph Tillman. 2004. A unigram orientation model
for statistical machine translation. In HLT-NAACL
2004: Short Papers, pages 101?104, Boston, Mas-
sachusetts, USA, May 2 - May 7. Association for
Computational Linguistics.
Ashish Vaswani, Haitao Mi, Liang Huang, and David
Chiang. 2011. Rule markov models for fast tree-to-
string translation. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies, pages 856?864,
Portland, Oregon, USA, June. Association for Compu-
tational Linguistics.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?404, Sep.
Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Model-
ing the translation of predicate-argument structure for
smt. In Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics (Volume 1:
Long Papers), pages 902?911, Jeju Island, Korea, July.
Association for Computational Linguistics.
Richard Zens and Hermann Ney. 2006. Discrimina-
tive reordering models for statistical machine trans-
lation. In Human Language Technology Conference
of the North American Chapter of the Association for
Computational Linguistics (HLT-NAACL): Proceed-
ings of the Workshop on Statistical Machine Transla-
tion, pages 55?63, New York City, NY, June. Associa-
tion for Computational Linguistics.
Hui Zhang, Kristina Toutanova, Chris Quirk, and Jian-
feng Gao. 2013. Beyond left-to-right: Multiple de-
composition structures for smt. In Proceedings of the
2013 Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 12?21, Atlanta, Geor-
gia, June. Association for Computational Linguistics.
512
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 545?555,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Flexible and Efficient Hypergraph Interactions for Joint Hierarchical and
Forest-to-String Decoding?
Martin C?mejrek??
?IBM Prague Research Lab
V Parku 2294/4
Prague, Czech Republic, 148 00
martin.cmejrek@us.ibm.com
Haitao Mi? and Bowen Zhou?
?IBM T. J. Watson Research Center
1101 Kitchawan Rd
Yorktown Heights, NY 10598
{hmi,zhou}@us.ibm.com
Abstract
Machine translation benefits from system
combination. We propose flexible interaction
of hypergraphs as a novel technique combin-
ing different translation models within one de-
coder. We introduce features controlling the
interactions between the two systems and ex-
plore three interaction schemes of hiero and
forest-to-string models?specification, gener-
alization, and interchange. The experiments
are carried out on large training data with
strong baselines utilizing rich sets of dense
and sparse features. All three schemes signif-
icantly improve results of any single system
on four testsets. We find that specification?a
more constrained scheme that almost entirely
uses forest-to-string rules, but optionally uses
hiero rules for shorter spans?comes out as
the strongest, yielding improvement up to 0.9
(Ter-Bleu)/2 points. We also provide a de-
tailed experimental and qualitative analysis of
the results.
1 Introduction
Recent years have witnessed the success of var-
ious statistical machine translation (SMT) mod-
els using different levels of linguistic knowledge?
phrase (Koehn et al, 2003), hiero (Chiang, 2005),
and syntax-based (Liu et al, 2006; Galley et al,
2006). System combination became a promising
way of building up synergy from different SMT sys-
tems and their specific merits.
Numerous efforts that have been proposed in this
field recently can be broadly divided into two cat-
?M. C? and H. M. contributed equally to this work.
egories: Offline system combination (Rosti et al,
2007; He et al, 2008; Watanabe and Sumita, 2011;
Denero et al, 2010) aims at producing consensus
translations from the outputs of multiple individ-
ual systems. Those outputs usually contain k-best
lists of translations, which only explore a small por-
tion of the entire search space of each system. This
issue is well addressed in joint decoding (Liu et
al., 2009), or online system combination, showing
comparable improvements to the offline combina-
tion methods. Rather than finding consensus trans-
lations from the outputs of individual systems, joint
decoding works with different grammars at the de-
coding time. Although limited to individual systems
sharing the same search paradigm (e.g. left-to-right
or bottom-up), joint decoding offers many poten-
tial advatages: search through a larger space, bet-
ter efficiency, features designed once for all subsys-
tems, potential cross-system features, online sharing
of partial hypotheses, and many others.
Different approaches have different strengths in
general?hiero rules are believed to provide reliable
lexical coverage, while tree-to-string rules are good
at non-local reorderings. Different contexts present
different challenges?noun phrases usually follow
the adjacency principle, while verb phrases require
more challenging reorderings. In this work, we study
different schemes of interaction between translation
models, reflecting their specific strengths at differ-
ent (syntactic) contexts. We make five new contribu-
tions:
First, we propose a framework for joint decod-
ing by means of flexible combination of trans-
lation hypergraphs, allowing for detailed con-
545
trol of interactions between the different sys-
tems using soft constraints (Section 3).
Second, we study three interaction schemes?
special cases of joint decoding: generalization,
specification, and interchange (Section 3.3).
Third, instead of using a tree-to-string system,
we use a much stronger forest-to-string sys-
temwith fuzzy match of nonterminal categories
(Section 2.1).
Fourth, we train strong systems on a large-
scale data set, and test all methods on four test
sets. Experimental results (Section 6) show that
our new approach brings improvement of up to
0.9 points in terms of (Ter ? Bleu)/2 over the
best single system.
Fifth, we conduct a comprehensive experimen-
tal analysis, and find that joint decoding actu-
ally prefers tree-to-string rules in both shorter
and longer spans. (Section 6.3).
The paper is organized as follows: We briefly re-
view the individual models in Section 2, describe
the method of joint decoding using three alternative
interaction schemes in Section 3, describe the fea-
tures controlling the interactions and fuzzy match in
Section 4, review the related work in Section 5, and
finally, describe our experiments and give detailed
discussion of the results in Section 6.
2 Individual Models
Our individual models are two state-of-the-art sys-
tems: a hiero model (Chiang, 2005), and a forest-to-
string model (Mi et al, 2008; Mi and Huang, 2008).
We will use the following example from Chinese
to English to explain both individual and joint de-
coding algorithms throughout this paper.
SS ta?olu`nSSSSSSSS hu`iSSSSS ze?nmeya`ng
discussion/NN SSS will/VV how/VV
S discuss/VV SS meeting/NN
There are several possible meanings based on the
different POS tagging sequences:
1: NN VV VV: How is the discussion going?
2: VV NN VV: Discuss about the meeting.
3: NN NN VV: How was the discussion meeting?
4: VV VV VV: Discuss what will happen.
id rule
r1 VV(ta?olu`n) ? discuss
r2 NP(ta?olu`n) ? the discussion
r3 NP(hu`i) ? the meeting
r4 VP(ze?nmeya`ng) ? how
r?4 VP(ze?nmeya`ng) ? about
r5 IP(x1:NP x2:VP) ? x2 x1
r6 IP(x1:VV x2:IP) ? x1 x2
r7 IP(x1:NP VP(VV(hu`i) x2:VP)) ? x2 is x1 going
r11 X(x1:X ze?nmeya`ng) ? how was x1
r12 X(ze?nmeya`ng) ? what
r13 X(ta?olu`n hu`i) ? the discussion meeting
r14 X(hu`i x1:X) ? x1 will happen
r15 S(x1:S x2:X) ? x1 x2
Table 1: Translation rules. Tree-to-string (r1?r7), hiero
(r11?r14), vanilla glue (r15).
IP
x1:NP VP
VV
hu`i
x2:VP
? x2 is x1 going
Figure 1: Tree-to-string rule r7.
Table 1 shows translation rules that can generate
all four translations. We will use those rules in the
following sections.
2.1 Forest-to-string
Forest-to-string translation (Mi et al, 2008) is a lin-
guistic syntax-based system, which significantly im-
proves the translation quality of the tree-to-string
model (Liu et al, 2006; Huang et al, 2006) by using
a packed parse forest as the input instead of a single
parse tree.
Figure 1 shows a tree-to-string translation
rule (Huang et al, 2006), which is a tuple
?lhs(r), rhs(r), ?(r)?, where lhs(r) is the source-side
tree fragment, whose internal nodes are labeled by
nonterminal symbols (like NP and VP), and whose
frontier nodes are labeled by source-language words
(like ?hu`i?) or variables from a set X = {x1, x2, . . .};
rhs(r) is the target-side string expressed in target-
language words (like ?going?) and variables; and
?(r) is a mapping from X to nonterminals. Each
546
(a)
IP0, 3
VV0, 1
ta?olu`n
NP0, 1
IP1, 3
NP1, 2
hu`i
VV1, 2
VP1, 3
VP2, 3
ze?nmeya`ng
Rt
? (b)
IP0, 3
X0, 2
VV0, 1
ta?olu`n
NP0, 1
IP1, 3
NP1, 2
hu`i
VV1, 2
X1, 3 VP1, 3
VP2, 3
ze?nmeya`ng
X0, 3
e5
e6
e7
? Rh ?
(b?)
IP0, 3
X0, 2
VV0, 1
ta?olu`n
NP0, 1
IP1, 3
NP1, 2
hu`i
VV1, 2
X1, 3 VP1, 3
VP2, 3
ze?nmeya`ng
X2, 3
X0, 3
e11
e14
? (c)
IP0, 3
X0, 2
VV0, 1
ta?olu`n
NP0, 1
IP1, 3
NP1, 2
hu`i
VV1, 2
X1, 3 VP1, 3
VP2, 3
ze?nmeya`ng
X2, 3
X0, 3
Figure 2: Parse and translation hypergraphs. (a) The parse forest of the example sentence. Solid hyperedges denote
the 1-best parse. (b) The corresponding translation forest F t after applying the tree-to-string translation rule set Rt.
Target lexical content is not shown. Each translation hyperedge (e.g. e7) has the same index as the corresponding rule
(r7). Gray nodes (e.g. VP1,3) became inaccessible due to the insufficient rule coverage. (b?) The translation forest Fh
after applying the hierarchical rule set Rh to the input sentence. (c) The combined translation forest Hm obtained by
superimposing b and b?. The nodes within each solid box share the same span. See Figure 3 for an example of the
internal structure of a box. The forest-to-string system can produce the translation 1 (dashed derivation: r2, r4 and r7)
and 2 (solid derivation: r1, r3, r?4, r5, and r6). Hierarchical rules generate the translation 3 (r11 and r13). The translation
4 is available by using joint decoding at X1, 3 ? IP1, 3 with the derivation: r1, r6, r12, and r14.
variable xi ? X occurs exactly once in lhs(r) and
exactly once in rhs(r). Take the rule r7 in Figure 1
for example, we have:
lhs(r7) = IP(x1:NP VP(VV(hu`i) x2:VP)),
rhs(r7) = x2 is x1 going,
?(r7) = {x1 7? NP, x2 7? VP}.
Typically, a forest-to-string system performs
translation in two steps (shown in Figure 2): pars-
ing and decoding. In the parsing step, we convert the
source language input into a parse forest (a). In the
decoding step, we first convert the parse forest into a
translation forest Ft in (b) by using the fast pattern-
matching technique (Zhang et al, 2009). For exam-
ple, we pattern-match the rule r7 rooted at IP0, 3, in
such a way that x1 spans NP0, 1 and x2 spans VP2, 3,
and add a translation hyperedge e7 in (b). Then the
decoder searches for the best derivation on the trans-
lation forest and outputs the target string.
2.2 Hiero
Hiero (hierarchical phrase-based) model (Chiang,
2005) acquires rules of synchronous context-free
grammars (SCFGs) from word-aligned parallel data,
and uses plain sequences of words as the input, with-
out any syntactic information.
547
FN
IP?1, 3
IP1, 3
BBBBSN
X?1, 3
X1, 3
EEEE
scheme interaction edges in supernode
Generalization
IP?1, 3 X?1, 3
IP1, 3 X1, 3
Specification
IP?1, 3 X?1, 3
IP1, 3 X1, 3
Interchange
IP?1, 3 X?1, 3
IP1, 3 X1, 3
Figure 3: Three interaction schemes for joint decoding.
Details of the interaction supernode for span (1, 3) shown
in Figure 2 (c). Soft constraints control the transitions.
SCFG can be formalized as a set of tuples
?lhs(r), rhs(r), ?(r)?, where lhs(r) is the source-side
one-level CFG, whose root is X or S, and whose
frontier nodes are labeled by source-language words
(like ?hu`i?) or variables from a set X = {x1, x2, . . .};
rhs(r) is the target-side string expressed in target-
language words (like ?going?) and variables; and
?(r) is a mapping from X to nonterminals. Table 1
shows examples of hiero rules r11?r15.
Although different on source side, hiero decod-
ing can be formalized equally as forest-to-string de-
coding: First, pattern-match the input sentence into
a translation forest Fh. For example, since the rule
r11 matches ?ze?nmeya`ng? such that x1 spans the first
two words, add a hyperedge e11 in Figure 2 (b?).
Then search for the best derivation over the trans-
lation forest.
3 Joint Decoding
The goal of joint decoding is to let different MT
models collaborate within the framework of a single
decoder. This can be done by combining translation
hypergraphs of the different models at the decod-
ing time, so that online sharing of partial hypotheses
overcomes weaknesses and boosts strengths of the
systems combined.
As both forest-to-string and hiero produce trans-
lation forests that share the same hypergraph struc-
ture, we first formalize the hypergraph, then we in-
troduce an algorithm to combine different hyper-
graphs, and finally we describe three joint decoding
schemes over the merged hypergraph.
3.1 Hypergraphs
More formally, a hypergraph H is a pair ?V, E?,
where V is the set of nodes, and E the set of hyper-
edges. For a given sentence w1:l = w1 . . .wl, each
node v ? V is in the form of Y i, j, where Y is a
nonterminal in the context-free grammar1 and i, j,
0 ? i < j ? l, are string positions in the sentence
w1:l, which denote the recognition of nonterminal
Y spanning the substring from positions i through j
(that is, wi+1 . . .w j). Each hyperedge e ? E is a tuple
?tails(e), head(e), target(e)?, where head(e) ? V is
the consequent node in the deductive step, tails(e) ?
V? is the list of antecedent nodes, and target(e) is
a list of rhs(r) for rules r such that each rule r has
the same lhs(r) pattern-matched at the node head(e).
For example, the hyperedge e7 in Figure 2 (b) is
e7 = ?(NP0, 1,VP2, 3), IP0, 3, (x2 is x1 going)?,
where we can infer the mapping to be
{x1 7? NP0, 1, x2 7? VP2, 3 }.
We also denote BS(v) to be the set of incoming
hyperedges of node v, which represent the different
ways of deriving v. For example, BS(IP0, 3) is a set
of e7 and e6.
There is also a distinguished root node TOP in
each hypergraph, denoting the goal item in transla-
tion, which is simply TOP0, l.
3.2 Combining Hypergraphs
We enable interaction between translation hyper-
graphs, such as hiero Fh = ?Vh, Eh? and forest-to-
string Ft = ?V t, Et?, on nodes covering the same
span (e.g. IP1, 3 and X1, 3 in Figure 2 (c) grouped in
a box). We call such groups interaction supernodes
and show a detailed example of a supernode for span
(1, 3) in Figure 3.
The combination runs in four steps:
1In this paper, nonterminal labels X and S denote hiero
derivations, other labels are tree-to-string labels.
548
1. For each node v = Y i, j, v ? Vh ? V t, we create
a new interaction node v? = Y ?i, j with empty
BS (v?). For example, we create two nodes,
IP?1, 3 and X?1, 3, at the top of Figure 3.
2. For each hyperedge e ? BS(v), v ? V t ? Vh,
we replace each v in tails(e) with v?. For exam-
ple, e7 becomes ?(NP?0, 1,VP?2, 3), IP0, 3, (x2 is
x1 going)?.
3. All the nodes and hyperedges form the merged
hypergraph Fm, such as in Figure 2 (c).
4. Insert interaction hyperedges connecting nodes
within each interaction supernode to make Fm
connected again.
In the following subsection we present details of in-
teractions and introduce three alternative schemes.
3.3 Three Schemes of Joint Decoding
Interaction hyperedges within each supernode allow
the decoder either to stay within the same system
(e.g. in hiero using X1, 3 ? X?1, 3 in Figure 3), or to
switch to the other (e.g. to forest-to-string using X1, 3
? IP?1, 3).
For example, translation 4 can be produced as
follows: The source string ?ze?nmeya`ng? is trans-
lated by the phrase rule r12. The hiero hyperedge
e14 combines it with the translation of ?hu`i?, reach-
ing the hiero node X1, 3. Using the interaction edge
X1, 3 ? IP?1, 3 will switch into the tree-to-string
model, so that the translation can be completed with
the tree-to-string edge e6 that connects it with a par-
tial tree-to string translation of ?ta?olu`n? done by r1.
In order to achieve more precise control over the
interaction between tree-to-string and hiero deriva-
tions, we propose the following three basic inter-
action schemes: generalization, specification, in-
terchange. The schemes control the interaction be-
tween hiero and tree-to-string models by means of
soft constraints. Some schemes may even restrict
certain types of transitions. The schemes are de-
picted in Figure 3 and their details are discussed in
the following three subsections.
3.3.1 Specification
The specification decoding scheme reflects the in-
tuition of using hiero rules to translate shorter spans
and tree-to-string rules to reorder higher-level sen-
tence structures. In other words, the scheme allows
one-way switching from the hiero general nontermi-
nal into the more specific nonterminal of a tree-to-
string rule. Transitions in reverse directions are not
allowed. This is achieved by inserting specification
interaction hyperedges e leading from hiero nodes
Xi, j or Si, j into all tree-to-string interaction nodes
Y?i, j within the same supernode.
3.3.2 Generalization
In some translation domains, hiero outperforms
tree-to-string systems, as was shown in experiments
in Section 6. While local hiero or tree-to-string re-
orderings perform well, long distance reorderings
proposed by tree-to-string may be too risky (e.g. due
to parsing errors), so that monotone concatenation
of long sequences2 is the more reliable strategy. The
generalization decoding scheme, complementary to
the specification, is motivated by the idea of incorpo-
rating reliable tree-to-string translations for some se-
quences into a strong hiero translation system. This
is achieved by inserting generalization interaction
hyperedges e leading from tree-to-string nodes Yi, j
nodes into general hiero interaction nodes X?i, j and
S?i, j within the same supernode.
3.3.3 Interchange
The interchange decoding scheme is a union of
the two previous approaches. Any derivation can
freely combine hiero and tree-to-string productions.
Both specification and generalization interaction
hyperedges are inserted leading from all hiero and
tree-to-string nodes Xi, j, Si, j, and Yi, j into all inter-
action nodes X?i, j, S?i, j, and Y?i, j.
3.4 Fuzzy match
The translation rule set cannot usually cover all
hyperedges in the parse forest, thus some nodes
become inaccessible in the translation forest (e.g.
VP1, 3 in Figure 2). However, in the parse forest, as
opposed to a 1-best tree, we can find other nodes
spanning the same sequence wi: j (e.g. node IP1, 3).
In order to re-enable inaccessible nodes and to in-
crease the variability of the translation forest, we
allow reaching them from the other tree-to-string
2Monotone glue is the only possibility for very long spans
exceeding the hiero maxParse treshold.
549
nodes within the same interaction node. This can
be achieved by adding fuzzy hyperedges between
every tree-to-string state Y i, j and a differently la-
beled tree-to-string interaction state Z?i, j. For exam-
ple, in the span (0,1), we have a fuzzy hyperedge
VV0, 1 ? NP?0, 1.
While interaction hyperedges combine different
translation models, fuzzy hyperedges combine dif-
ferent derivations within the same (tree-to-string)
model.
4 Interaction Features
Our baseline systems use the log-linear framework
to estimate the probability P(D) of a derivation D
from features ?i and their weights ?i as P(D) ?
exp
(?
i ?i?i
)
. Similarly as Chiang et al (2009), our
systems use tens of dense (e.g. language models,
translation probabilities) and thousands of sparse
(e.g. lexical, fertility) features.
The features related to the joint decoding experi-
ments are the costs for specification, generalization,
interchange, and the fuzzy match. Let Lt be the set
of the labels used by the source language parser and
Lh = {S,X} be the labels used by hiero.
The generalization feature
?Y?Z = |{e; e ? D,?i, j tails(e) = {Yi, j} (1)
?head(e) = Z?i, j}|
is the total number of generalization hyperedges in
D going from tree-to-string states Y ? Lt to hiero
states Z? ? Lh.
The specification feature
?Z?Y = |{e; e ? D,?i, j tails(e) = {Zi, j} (2)
?head(e) = Y?i, j}|
is the total number of specification hyperedges in D
going from hiero states Z ? Lh to tree-to-string states
Y ? ? Lt.
The interchange feature is implemented by en-
abling the generalization and specification features
at the same time for both tuning and testing.
The fuzzy match feature
?U?W = |{e; e ? D,?i, j tails(e) = {Ui, j} (3)
?head(e) = W?i, j}|
is the total number of fuzzy match hyperedges in D
going from tree-to-tree statesU ? Lt to tree-to-string
states W? ? Lt. 3
We use MIRA to obtain weights for the new fea-
tures by tuning on the development set. The num-
ber of new parameters to tune can be estimated as
|Lh| ? |Lt| for generalization and specification, and
2 ? |Lh| ? |Lt| for interchange. For the fuzzy match
of tree-to-string nonterminals we have |Lt| ? |Lt| pa-
rameters organized as a sparse matrix, since we only
consider combinations on nonterminal labels that
cooccur in the data.4
5 Related Work
From the previous explorations of online translation
model combination, we see the work of Liu et al
(2009) proposing an unconstrained combination of
hiero and tree-to-string models as a special configu-
ration of our framework, and we also replicate it.
Denero et al (2010) combine translation mod-
els even with different search paradigms. Their ap-
proach is different, since their component systems
do not interact at decoding time, instead, each of
them provides its weighted translation forest first,
the forests are then combined to infer a new com-
bination model.
6 Experiment
In this section we describe the setup, present results,
and analyze the experiments. Finally, we propose fu-
ture directions of research.
3Here we allow U = W, which can be viewed in such a way
that exact match is a special case of fuzzy match.
4We also carried out an alternative experiment with only
three fuzzy match features estimated from the training data
parse forest by Na??ve Bayes by observing all spans in the train-
ing data, accumulating counts Cs(U) and Cs(U,W) of nonter-
minals (or pairs of nonterminals) heading the same span s. The
first two features (one for each direction) are based on condi-
tional probabilities:
?(U |W) = ? log
(
?
s?spans Cs (U,W)
?
s?spans Cs(W)
)
. (4)
The third feature is based on joint probability:
?(U,W) = ? log
(
?
s?spans Cs(U,W)
?
s?spans,A,B?Lt Cs(A, B)
)
. (5)
The average performance drops by 0.1 (Ter-Bleu)/2 points,
compared to the interchange eperiment.
550
System
GALE-web P1R6-web MT08 news MT08 web Avg.
Bleu (T-B)/2 Bleu (T-B)/2 Bleu (T-B)/2 Bleu (T-B)/2 (T-B)/2
Single
T2S 32.6 11.6 16.9 23.5 37.7 7.8 28.1 14.5 14.4
Hiero 33.7 10.2 17.0 23.1 39.2 6.3 28.8 13.7 13.3
F2S 34.0 10.3 17.3 23.2 39.6 6.3 29.2 13.6 13.4
Joint
Liu:09 34.1 9.7 17.0 23.0 38.8 6.7 29.0 13.2 13.2
Gen. 34.4 9.7 17.8 22.6 40.0 6.1 29.6 13.1 12.9
Spe. 35.1 9.4 18.1 22.2 40.2 5.8 29.6 12.9 12.6
Int. 34.9 9.4 17.9 22.3 40.0 6.2 29.6 12.9 12.7
Table 2: All results of single and joint decoding systems.
6.1 Setup
The training corpus consists of 16 million sen-
tence pairs available within the DARPA BOLT
Chinese-English task. The corpus includes a mix
of newswire, broadcast news, webblog and comes
from various sources such as LDC, HK Law, HK
Hansard and UN data. The Chinese text is seg-
mented with a segmenter trained on CTB data using
conditional random fields (CRF). Language models
are trained on the English side of the parallel cor-
pus, and on monolingual corpora, such as Gigaword
(LDC2011T07) and Google News, altogether com-
prising around 10 billion words.
We use a modified version of the Berkeley parser
(Petrov and Klein, 2007) to obtain a parse forest
for each training sentence, then we prune it with
the marginal probability-based inside-outside algo-
rithm to contain only 3n CFG nodes, where n is the
sentence length. Finally, we apply the forest-based
GHKM algorithm (Mi and Huang, 2008; Galley et
al., 2004) to extract tree-to-string translation rules
from forest-string pairs.
In the decoding step, we prune the input hyper-
graphs to 10n nodes before we use fast pattern-
matching (Zhang et al, 2009) to convert the parse
forest into the translation forest.
We tune on 1275 sentences, each with 4 refer-
ences, from the LDC2010E30 corpus, initially re-
leased under the DARPA GALE program.
All MT experiments are optimized with
MIRA (Crammer et al, 2006) to maximize
(Ter-Bleu)/2.
We test on four different test sets: GALE-web test
set from LDC2010E30 corpus (1239 sentences, 4
references), P1R6-web test set from LDC2012E124
corpus (1124 sentences, 1 reference), NIST MT08
newswire portion (691 sentences, 4 references), and
NIST MT08 web portion (666 sentences, 4 refer-
ences).
6.2 Results
Table 2 shows all results of single and joint decoding
systems. The Bleu score of the single hiero baseline
is 39.2 on MT08-news, showing that it is a strong
system. The single F2S baseline achieves compara-
ble scores on all four test sets.
Then, for reference, we present results of joint Hi-
ero and T2S decoding, which is, to our knowledge, a
strong and competitive reimplementaion of the work
described by Liu et al (2009). Finally, we present re-
sults of joint decoding of hiero and F2S in three in-
teraction schemes: generalization, specification, and
interchange.
All three combination schemes significantly im-
prove results of any single system on all four test-
sets. On average and measured in (Ter-Bleu)/2,
our systems improve the best single system by 0.4
(generalization), 0.7 (specification), and 0.6 (inter-
change).
The specification comes out as the strongest inter-
action scheme, beating the second interchange on 2
testsets by 0.1 and 0.4 (Ter-Bleu)/2 points and on 3
testsets by 0.2 Bleu points.
6.3 Discussion of Results
Interpretations of model behavior with thousands of
parameters that may possibly overlap and interfere
should be always attempted with caution. In this sec-
tion we highlight some interesting observations, ac-
551
Specification Generalization Interchange
X ? ? ? ? X X ? ? ? ? X
VP
IP
VV
NR
ADVP
QP
CC
DVP
NP
P
...
CS
CP
AD
VRD
PU
ADJP
DNP
PP
PRN
DP
0.069
0.059
0.053
0.032
0.025
0.023
0.017
0.017
0.017
0.012
...
-0.005
-0.007
-0.011
-0.012
-0.028
-0.028
-0.045
-0.064
-0.069
-0.092
QP
PP
NN
DP
NR
DNP
NP
LC
DEC
DEG
...
VV
PRN
PN
BA
VP
VRD
JJ
VC
DFL
PU
0.057
0.054
0.048
0.044
0.034
0.032
0.030
0.025
0.023
0.023
...
-0.010
-0.011
-0.013
-0.015
-0.015
-0.028
-0.035
-0.037
-0.054
-0.073
VV
VP
NN
QP
ADVP
LCP
NP
P
IP
NR
...
VSB
PN
PU
M
VRD
DNP
ADJP
PP
DP
PRN
0.062
0.044
0.034
0.025
0.022
0.021
0.018
0.017
0.016
0.016
...
-0.004
-0.004
-0.004
-0.007
-0.014
-0.023
-0.039
-0.058
-0.070
-0.080
NN
PP
CP
LCP
DEG
DP
DEC
QP
LC
NP
...
FLR
DVP
BA
JJ
AS
VRD
ADVP
PN
DFL
PU
0.048
0.041
0.035
0.035
0.031
0.028
0.027
0.027
0.021
0.019
...
-0.006
-0.009
-0.010
-0.011
-0.014
-0.017
-0.021
-0.033
-0.038
-0.103
Table 3: Examples of specification, generalization, and interchange weights. POS tags in italics.
 0
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
 11
 12
 13
 14
 15
 16
 17
 18
AD
VP CL
P
AD
JP
FL
R
D
FL D
P
VC
P
VS
B
VR
D
VC
D QP NP DV
P
D
N
P
LC
P PP VP CP
PR
N IP
FR
AG
Av
er
ag
e 
sp
an
 le
ng
th
Figure 4: Average span length for selected syntactic la-
bels on GALE-web test set.
companying them with our subjective judgements
and speculations.
Table 3 shows the specification and generalization
features tuned for the three combination schemes,
then sorted by their weights ?X?Y or ?Y?X . Features
shown at the top of the table are very expensive (the
#Interactions Generalization Inter. gen.
F2S ? glue 5557 4202
F2S ? hiero 695 1178
total gen. 6252 5380
Specification Inter. spec.
phrase ? F2S 2763 2235
glue ? F2S 946 841
hiero ? F2S 683 839
total spec. 4392 3915
Table 5: Rule interactions on GALE-web test set.
system tries to avoid them), while inexpensive fea-
tures are at the bottom (the system is encouraged to
use them).
The most expensive interactions for the specifi-
cation belong to constituents (IP, VP) that usually
occur higher in a syntactic tree (see Figure 4 for av-
erage span lengths of selected syntactic labels), and
often require non-local reorderings. This indicates
that the decoder is discouraged from switching from
hiero into F2S derivation at these higher-level spans.
552
rule type Generalization Specification Interchange
F2S 18,807 58% 19,399 70% 18,400 61%
Hiero 3,730 12% 2,330 8% 3,133 10%
Glue 7,367 23% 571 2% 4,714 16%
Phrase 2,274 7% 5,484 20% 3,868 13%
total 32,178 27,784 30,115
Table 4: Rule counts on GALE-web test set.
10^0
10^1
10^2
10^3
10^4
 0  5  10  15  20  25  30  35  40  45  50  55  60  65  70
N
um
be
r o
f r
ul
es
Span length
Generalization
F2S
Hiero
Glue
Phrase
10^0
10^1
10^2
10^3
10^4
 0  5  10  15  20  25  30  35  40  45  50  55  60  65  70
N
um
be
r o
f r
ul
es
Span length
Specification
F2S
Hiero
Glue
Phrase
10^0
10^1
10^2
10^3
10^4
 0  5  10  15  20  25  30  35  40  45  50  55  60  65  70
N
um
be
r o
f r
ul
es
Span length
Interchange
F2S
Hiero
Glue
Phrase
Figure 5: Rule distributions on GALE-web test set.
The third most expensive feature belongs to a
part-of-speech tag?the preterminal VV. We may
hypothesize that it shows the importance of lexical
information for the precision of reordering typically
carried out within (parent) VP nodes, and/or the im-
portance of POS information for succesful disam-
biguation of word senses in translation. Ideally, the
system can use a VP rule with a lexicalized VV. Less
preferably, the VV part has to be translated by an-
other T2S rule (losing the lexical constraint). In the
worst case, the system has to use a hiero hypothe-
sis to translate the VV part (losing the syntactic con-
straint), risking imprecise translation, since the hiero
rule is not constrained to senses corresponding to the
source POS VV. Again, the high penalty discourages
from using the hiero derivation in this context.
On the other hand, the bottom of the table shows
labels that encourage using hiero?DP, PP, DNP,
ADJP, etc.?shorter phrases that tend to be monotone
and less ambiguous.
Similar interpretations seem plausible when ex-
amining the generalization experiment. Expensive
features related to preterminals (NR, NN, CD) may
suggest two alternative principles: First, using F2S
rules for thes POS categories and then switching to
hiero is discouraged, since these contexts are more
reliably handled by hiero due to better lexical cover-
age and common adjacency in nominal categories.
Second, since there is only one attempt to switch
from F2S derivation to hiero, letting F2S complete
even larger spans (and maybe switching to hiero
later) is favorable.
The tail of generalization feature weights is more
difficult to interpret. The discount on VP encourages
decoder to use F2S for entire verb phrases before
switching to hiero, on the other hand, other verb-
related preterminals occupy the tail as well, hurrying
into early switching from F2S to hiero.
553
Finally, the feature weights tuned for the in-
terchange experiment are divided into two sub-
columns. Both generalization and specification
weights show similar trends as in the previous two
interaction schemes, although blurred (VP and IP
descending from the absolute top). Since transitions
in both ways are allowed, the search space is big-
ger and the system may behave differently. It is even
possible for a path in the hypergraph to zigzag be-
tween F2S and hiero nodes to collect interaction dis-
counts, ?diluting? the syntactic homogeneity of the
hypothesis.
Figure 5 and Tables 4 and 5 show rule distribu-
tions, total rule counts, and numbers of interactions
of different types for the three interaction schemes
on the GALE-web test set. The scope of phrase rules
is limited to 6 words. The scope of hiero rules is lim-
ited to 20 words by the commonly used maxParse
parameter, leaving longer spans to the glue rule.
The trends of F2S and glue rules show the most
obvious difference. In the generalization, F2S rules
translate spans of up to 50 words. Glue rules pre-
vail on spans longer then 7 words. The specification
is reversed, pushing the longest scope of hiero and
glue rules down to 40 words, completing the longest
sentences entirely with F2S. The interchange comes
out as a mixture of the previous two trends.
All three schemes prefer using F2S rules at
shorter spans, to the contrary of our original assump-
tion of phrasal and hiero rules being stronger on lo-
cal contexts in general. Here we may refer again
to the specification feature weights for preterminals
VV, NR, CC and P in Table 3 and to our previously
stated hypothesis about the importance of preserving
lexical and syntactic context.
Hiero rules usage on longer spans drops fastest
for specification, slowest for generalization, and in
between for interchange.
It is also interesting to notice the trends on very
short spans (2?4 words) shown by rule distributions
and reflected in numbers of interaction types. While
specification often transitions from a single phrase
rule directly into F2S, the interchange has relatively
higher counts of hiero rules, another sign of the hiero
and F2S interaction.
Synthesizing from several sources of indications
is difficult, however, we arrive at the conclusion that
joint decoding of hiero and F2S significantly im-
proves the performance. While the single systems
show similar performance, their roles are not bal-
anced in joint decoding. It seems that the role of hi-
ero consists in enabling F2S in most contexts.
We have focused on three special cases of inter-
action. We see a great potential in further studies
of other schemes, allowing more flexible interaction
than simple specification, but still more constrained
than the interchange. It seems also promising to re-
fine the interaction modeling with features taking
into account more information than a single syntac-
tic label, and to explore additional ways of parame-
ter estimation.
7 Conclusion
We have proposed flexible interaction of hyper-
graphs as a novel technique combining hiero
and forest-to-string translation models within one
decoder. We have explored three basic interac-
tion schemes?specification, generalization, and
interchange?and described soft constraints control-
ling the interactions. We have carried out experi-
ments on large training data and with strong base-
lines. Of the three schemes, the specification shows
the highest gains, achieving improvements from 0.5
to 0.9 (Ter-Bleu)/2 points over the best single sys-
tem. We have conducted a detailed analysis of each
system output based on different indications of inter-
actions, discussed possible interpretations of results,
and finally offered our conclusion and proposed fu-
ture lines of research.
Acknowledgments
We thank Jir??? Havelka for proofreading and help-
ful suggestions. We would like to acknowledge the
support of DARPA under Grant HR0011-12-C-0015
for funding part of this work. The views, opinions,
and/or findings contained in this article/presentation
are those of the author/presenter and should not be
interpreted as representing the official views or poli-
cies, either expressed or implied, of the DARPA.
References
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 new features for statistical machine translation.
In Proceedings of HLT-NAACL, pages 218?226.
554
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL, pages 263?270, Ann Arbor, Michigan, June.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. Journal of Machine Learning
Research, 7:551?585.
John Denero, Shankar Kumar, Ciprian Chelba, and Franz
Och. 2010. Model combination for machine transla-
tion. In In Proceedings NAACL-HLT, pages 975?983.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In Pro-
ceedings of HLT-NAACL, pages 273?280.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proceed-
ings of COLING-ACL, pages 961?968, Sydney, Aus-
tralia, July.
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick Nguyen,
and Robert Moore. 2008. Indirect-HMM-based hy-
pothesis alignment for combining outputs from ma-
chine translation systems. In Proceedings of EMNLP,
pages 98?107, October.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of AMTA, pages
66?73.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of NAACL, pages 127?133.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proceedings of COLING-ACL, pages 609?
616.
Yang Liu, Haitao Mi, Yang Feng, and Qun Liu. 2009.
Joint decoding with multiple translation models. In
Proceedings of ACL-IJCNLP, pages 576?584, August.
Haitao Mi and Liang Huang. 2008. Forest-based transla-
tion rule extraction. In Proceedings of EMNLP, pages
206?214.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of ACL: HLT, pages
192?199.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of HLT-
NAACL, pages 404?411.
Antti-Veikko Rosti, Spyros Matsoukas, and Richard
Schwartz. 2007. Improved word-level system com-
bination for machine translation. In Proceedings of
ACL, pages 312?319, Prague, Czech Republic, June.
Taro Watanabe and Eiichiro Sumita. 2011. Machine
translation system combination by confusion forest. In
Proceedings of ACL 2011, pages 1249?1257.
Hui Zhang, Min Zhang, Haizhou Li, and Chew Lim
Tan. 2009. Fast translation rule matching for syntax-
based statistical machine translation. In Proceedings
of EMNLP, pages 1037?1045, Singapore, August.
555
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 839?844,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
What is Hidden among Translation Rules
Libin Shen
Persado
50 West 17th Street
New York, NY 10011
libin.shen@persado.com
Bowen Zhou
IBM T. J. Watson Research Center
1101 Kitchawan Road
Yorktown Heights, NY 10598
zhou@us.ibm.com
Abstract
Most of the machine translation systems rely
on a large set of translation rules. These rules
are treated as discrete and independent events.
In this short paper, we propose a novel method
to model rules as observed generation output
of a compact hidden model, which leads to
better generalization capability. We present a
preliminary generative model to test this idea.
Experimental results show about one point im-
provement on TER-BLEU over a strong base-
line in Chinese-to-English translation.
1 Introduction
Most of the modern Statistical Machine Transla-
tion (SMT) systems, for example (Koehn et al,
2003; Och and Ney, 2004; Chiang, 2005; Marcu et
al., 2006; Shen et al, 2008), employ a large rule
set that may contain tens of millions of translation
rules or even more. In these systems, each transla-
tion rule has about 20 dense features, which repre-
sent key statistics collected from the training data,
such as word translation probability, phrase transla-
tion probability etc. Except for these common fea-
tures, there is no connection among the translation
rules. The translation rules are treated as indepen-
dent events.
The use of sparse features as in (Arun and Koehn,
2007; Watanabe et al, 2007; Chiang et al, 2009) to
some extent mitigated this problem. In their work,
there are as many as 10,000 features defined on the
appearance of certain frequent words and Part of
Speech (POS) tags in rules. They provide signifi-
cant improvement in automatic evaluation metrics.
However, these sparse features fire quite randomly
and infrequently on each rule. Thus, there is still
plenty of space to better model translation rules.
In this paper, we will explore the relationship
among translation rules. We no longer view rules
as discrete or unrelated events. Instead, we view
rules, which are observed from training data, as ran-
dom variables generated by a hidden model. This
generative process itself is also hidden. All possible
generative processes can be represented with factor-
ized structures such as weighted hypergraphs and fi-
nite state machines. This approach leads to a com-
pact model that has better generalization capability
and allows translation rules not explicitly observed
in training date.
This paper reports work-in-progress to exploit
hidden relations among rules. Preliminary experi-
ments show about one point improvement on TER-
BLEU over a strong baseline in Chinese-to-English
translation.
2 Hidden Models
Let G = {(r, f)} be a grammar observed from paral-
lel training data, where f is the frequency of a bilin-
gual translation rule r.
Let M be a hidden model that generates every
translation rule r. For example, M could be mod-
eled with a weighted hypergraph or finite state ma-
chine. For the sake of convenience, in this section
we assumeM is a meta-grammar M = {m}, where
each m represents a meta-rule. For each translation
r, there exists a hypergraph Hr that represents all
possible derivations Dr = {d} that can generate rule
r. Here, each derivation d is a hyperpath using meta-
rules Md, where Md ? M. Thus, we can use hy-
pergraph Hr to characterize r. Translation rules in G
839
can share nodes and meta-rules in their hypergraphs,
so that M is more compact model than G.
In the rest of this section, we will introduce three
methods to quantify Hr as features of rule r. It
should be noted that there are more ways to exploit
the compact model of M than these three.
2.1 Type 1 : A Generative Model
Let ? be the parameters of a statistical model
Pr(m; ?) for meta-rules m in meta-grammar M es-
timated from the observed translation grammar G.
The probability of a translation rule r can be calcu-
lated as follows.
Pr(r; ?) ? Pr(Hr; ?)
=
?
d?Dr
Pr(d; ?) (1)
By assuming separability,
Pr(d; ?) =
?
m?Md
Pr(m; ?) (2)
we can further decompose rule probability Pr(r; ?)
as below.
Pr(r; ?) =
?
d?Dr
?
m?Md
Pr(m; ?) (3)
In practice, Pr(r; ?) in (3) can be calculated
through bottom-up dynamic programming on hyper-
graph Hr. Hypergraphs of different rules can share
nodes and meta-rules. This reveals the underlying
relationship among translation rules.
As a by-product of this generative model, we use
the log-likelihood of a translation rule, log Pr(r; ?),
as a new dense feature. We call it Type 1 in experi-
ments.
2.2 Type 2 : Meta-Rules as Sparse Features
As given in (3), likelihood of a translation rule is
a function over Pr(m; ?), in which ? is estimated
from the training data with a generative model. Pre-
vious work in (Chiang et al, 2009) showed the ad-
vantage of using a discriminative model to optimize
individual weights for these factors towards a better
automatic score.
Following this practice, we treat each meta-rule
m as a sparse feature. Feature value f(m) = 1 if
and only if m is used in hypergraph Hr. Otherwise,
its default value is 0. We call these features Type
2 in experiments. The Type 2 system contains the
log-likelihood feature in Type 1.
2.3 Type 3 : Posterior as Feature Values
A natural question on the binary sparse features de-
fined above is why all the active features have the
same value of 1. We use these meta-rules to repre-
sent a translation rule in feature space. Intuitively,
for meta-rules with closer connection to the trans-
lation rules, we hope to use relatively larger feature
values to increase their effect.
We formalize this intuition with the posterior
probability that a meta-rule m is used to generate
r, as below.
f(m) ? Pr(m|r; ?) (4)
= Pr(m, r; ?)Pr(r; ?)
=
?
d?Dr ,m?Md Pr(d; ?)
Pr(r; ?)
The posterior in (4) could be too sharp. Follow-
ing the common practice, we smooth the posterior
features with a scaling factor ?.
f(m) ? Pr(m|r)?
We use Type 3(?) to represent the posterior model
with a scaling factor of ? in experiments. The Type
3 systems also contain the log-likelihood feature in
Type 1.
2.4 Parameter Estimation
Now we explain how to obtain parameter ?. With
proper definition of the underlying model M, we
can estimate ? with the traditional EM algorithm or
Bayesian methods.
In the next section, we will present an example
of the hidden model. We will employ the EM algo-
rithm to estimate the parameters in ?. Here, trans-
lation rules and their frequencies in G are observed
data, and derivation d for each rule r is hidden. At
the Expectation step, we search all derivations d in
Dr of each rule r and calculate their probabilities
according to equation (2). At the Maximization step,
we re-estimate ? on all derivations in proportion to
their posterior probability.
840
3 Case Study
In Section 2, we explored the use of meta-grammars
as the underlying model M and developed three
methods to define features. Similar techniques can
be applied to finite state machines and other underly-
ing models. Now, we introduce a POS-based under-
lying model to illustrate the generic model proposed
in Section 2. We will show experimental results in
Section 4.
3.1 Meta-rules on POS tags
Let r ? G be a translation rule composed of a pair of
source and target word strings (Fw, Ew). Let Fp and
Ep be the POS tags for the source and target sides
respectively. For the sake of simplicity as the first
attempt, we treat non-terminal as a special word X
with POS tag X.
Suppose we have a Chinese-to-English translation
rule as below.
yuehan qu zhijiage ? john leaves for chicago
We call
NR VV NR ? NNP VBZ IN NNP (5)
a translation rule in POS tags.
We will propose an underlying model M to gen-
erate translation rules in POS tags instead of trans-
lation rules themselves. For the rest of this section,
we take translation rules in POS tags as the target of
our generative model. We define meta-rules on pairs
of POS tag strings, e.g. NR VV ? NNP VBZ .
We can decompose the probability of translation
rule in (5) into a product on meta-rule probabilities
via various derivations, such as
? Pr(NR VV , NNP VBZ ) ?
Pr(NR, IN NNP), and
? Pr(NR, NNP) ? Pr(VV , VBZ IN ) ?
Pr(NR, NNP).
3.2 The Underlying Model and Features
Now, we introduce a generative model M for trans-
lation rules in POS tags. We still use the example in
(5) as shown in Figure 1, where the top box repre-
sents the source side and the bottom box represents
the target side. Dotted lines represent word align-
ments on three pairs of words.
Figure 1: An example
We first generate the number of source tokens of
a translation rule with a uniform distribution for up
to, for example, 7 tokens.
Then we split the source side into chunks with
a binomial distribution with a Bernoulli variable at
the gap between each two continuous words, which
splits the two words into two chunks with a proba-
bility of p. For example, the probability of obtaining
two chunks NR VV and NR is (1 ? p)p, as shown in
Figure 1.
Suppose we split the target side into two parts,
NNP VBZ and IN NNP, which respects the word
alignments. It generates two meta-rules NR VV ?
NNP VBZ and NR ? IN NNP, as shown in Figure 1.
The probability for the first meta-rule is
Pr(|E| = 2 | |F | = 2) ?
Pr(NR VV ,NNP VBZ | |F | = 2, |E| = 2),
where |F | represents the number of source tokens,
and |E| the number of target tokens. Similarly, the
probability of the second one is as follows.
Pr(|E| = 2 | |F | = 1) ?
Pr(NR, IN NNP | |F | = 1, |E| = 2).
To sum up, the probability of a derivation d for a
translation rule r : F ? E is
Pr(d) ? Pr?1(|F |)
? Pr?2(Fs)
?
?
m?Md
Pr?3(|Em| | |Fm|)
?
?
m?Md
Pr?4(m | |Fm|, |Em|) (6)
where Fm and Em are source and target sides of a
meta-rule m used in derivation d, and Fs is a split-
ting of the source side. As for the distributions, we
841
have
?1 ? Uniform
?2 ? Binomial
?3 ? Categorical
?4 ? Categorical
where ?1 and ?2 have pre-selected hyperparameters,
and ?3 and ?4 are estimated with the EM algorithm.
As for sparse features, we will obtain 7 meta-rule
features as below.
? NR ? NNP
? VV ? VBZ
? VV ? VBZ IN
? NR VV ? NNP VBZ
? NR VV ? NNP VBZ IN
? VV NR ? VBZ IN NNP
? NR VV NR ? NNP VBZ IN NNP
All of them respect the word alignment, which
means that
? there is no alignment that aligns one word in a
meta-rule with the other out of the same meta-
rule, and
? there is at least one alignment within a meta-
rule.
3.3 Implementation Details
Even though the size of all possible meta-rules is
much smaller than the space of translation rules,
it is still too large to work with existing optimiza-
tion methods for sparse features in MT, i.e. MIRA
(Chiang et al, 2009) or L-BFGS (Matsoukas et al,
2009). In practice, we have to limit the feature space
to around 20,000 dimensions.
For this purpose, we first use a frequency based
method to filter meta-rule features. Specifically,
we first divide all the meta-rules into 100 bins,
(|F |, |E|), where |F | is the number of words on the
source side, and |E| the target side, 0 < |F |, |E| ?
10. For each bin, we keep the same top k-percentile
of the meta-rules such that we obtain a total of
20,000 meta-rules as features.
System BLEU% TER% T-B
Baseline 30.35 55.32 24.97
Type 1 30.74 55.48 24.74
Type 2 31.07 55.07 24.00
Type 3 (1) 30.93 55.34 24.41
Type 3 (0.1) 31.05 55.02 23.97
Type 3 (0.01) 31.09 54.96 23.87
Table 1: scores on test-1
A shortcoming of this filtering method is that all
these features are positive indicators, while low-
frequency negative indicators are discarded. In order
to keep the features of various level of frequency, we
define class features with a 3-tuple C(|F |, |E|, q),
where |F | and |E| are numbers of source and target
words as defined above, and q is the integer part of
the log2 value of the feature frequency in the training
data.
In this way, each meta-rule feature can be mapped
to one of these classes. The value of a class feature
equals the sum of the meta-rule features that mapped
into this class. We have about 2,000 class features
defined in this way. They are applied on both Type
2 and Type 3 features.
4 Experiments
We carry out our experiments on web genre of
Chinese-to-English translation. The training set
contains about 10 million parallel sentences avail-
able to Phase 1 of the DARPA BOLT MT task. The
tune set contains 1275 sentences. Each has four ref-
erences. There are two test sets. Test-1 is from a
similar source of the tune set, and it contains 1239
sentences. Test-2 is the web part of the MT08 eval-
uation data.
Our baseline system is a home-made Hiero (Chi-
ang, 2005) style system. The baseline rule set con-
tains about 17 million rules. It contains about 40
dense features, including a 6-gram LM.
The sparse feature optimization algorithm is sim-
ilar to the MIRA recipe described in (Chiang et al,
2009). We optimize on TER-BLEU (Snover et al,
2006; Papineni et al, 2001).
The BLEU, TER and T-B scores on the two tests
are shown in Tables 1 and 2. It should be noted that,
even though our metric of tuning is T-B, the baseline
842
System BLEU% TER% T-B
Baseline 25.80 56.96 31.16
Type 1 26.18 57.09 30.91
Type 2 26.63 56.64 30.01
Type 3 (1) 26.30 57.00 30.70
Type 3 (0.1) 26.34 56.73 30.39
Type 3 (0.01) 26.50 56.73 30.23
Table 2: scores on test-2 (MT08-WB)
system already provides a very competitive BLEU
score on MT08-WB as compared the best system in
the evaluation1, thanks to comprehensive features in
the baseline system and more data in training.
All the three types of systems provide consis-
tent improvement on both test sets in terms of T-B,
our optimization metric. Type 1 gives marginal im-
provement of 0.2. This shows the limitation of the
generative feature. When we use meta-rules as bi-
nary sparse features in Type 2, we obtain about one
point improvement on T-B on both sets. This shows
the advantage of tuning individual meta-rule weights
over a generative model. Type 3 (0.01) and Type 2
are at the same level. Proper smoothing is important
to Type 3.
5 Discussion
In the case study of Section 3, we use POS-based
rules as hidden states. However, it should be noted
that the hidden structures surely do not have to be
POS tags. For example, an alternative could be
unsupervised NT splitting similar to (Huang et al,
2010).
The meta-grammar based approach was also mo-
tivated by the insight acquired on mono-lingual lin-
guistic grammar generation, especially in the TAG
related research (Xia, 2001; Prolo, 2002). Meta-
grammar was viewed as an effective way to remove
redundancy in grammars.
The link between Tree Adjoining Grammar
(TAG) (Joshi et al, 1975; Joshi and Schabes, 1997)
and MT was first introduced in (Shieber and Sch-
abes, 1990), a pioneer work in tree-to-tree transla-
tion. (DeNeefe and Knight, 2009) re-visited the use
of adjoining operation in the context of Statistical
MT, and reported encouraging results. On the other
1http://www.itl.nist.gov/iad/mig/tests/mt/2008/
hand, (Dras, 1999) showed how a meta-level gram-
mar could help in modeling parallel operations in
(Shieber and Schabes, 1990). Our work is another
effort of statistical modeling of well-recognized lin-
guistic insight in NLP and MT.
6 Conclusions and Future Work
In this paper, we introduced a novel method to model
translation rules as observed generation output of a
compact hidden model. As a case study to capital-
ize this model, we presented three methods to en-
rich rule modeling with features defined on a hid-
den model. Preliminary experiments verified gain of
one point on TER-BLEU over a strong baseline in
Chinese-to-English translation.
As for future work, we plan to extend this work in
the following aspects.
? To try other prior distributions to generate the
number of source tokens.
? Unsupervised and semi-supervised learning of
hidden models.
? To incorporate rich models into the generative
process, e.g. reordering, non-terminals, struc-
tural information and lexical models.
? To improve the posterior model with better pa-
rameter estimation, e.g. Bayesian methods.
? To replace the exhaustive translation rule set
with a compact meta grammar that can create
and parameterize new translation rules dynam-
ically, which is the ultimate goal of this line of
work.
Acknowledgments
We would like thank the anonymous reviewers for
their valuable comments. Haitao Mi and Martin
Cmejrek kindly helped on data preparation.
This work was done when the first author was
at IBM. The work was supported by DARPA un-
der Grant HR0011-12-C-0015 for funding part of
this work. The views, opinions, and/or findings con-
tained in this article/presentation are those of the au-
thor/presenter and should not be interpreted as repre-
senting the ofcial views or policies, either expressed
or implied, of the DARPA.
843
References
Abhishek Arun and Philipp Koehn. 2007. Online
learning methods for discriminative training of phrase
based statistical machine translation. In Proceedings
of MT Summit XI.
D. Chiang, K. Knight, and W. Wang. 2009. 11,001
new features for statistical machine translation. In
Proceedings of the 2009 Human Language Technol-
ogy Conference of the North American Chapter of the
Association for Computational Linguistics.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 263?270, Ann Ar-
bor, MI.
Steve DeNeefe and Kevin Knight. 2009. Synchronous
tree adjoining machine translation. In Proceedings of
the 2009 Conference of Empirical Methods in Natural
Language Processing, pages 727?736, Singapore.
Mark Dras. 1999. A meta-level grammar: redefining
synchronous tag for translation and paraphrase. In
Proceedings of the 37th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL).
Zhongqiang Huang, Martin Cmejrek, and Bowen Zhou.
2010. Soft syntactic constraints for hierarchical
phrase-based translation using latent syntactic distri-
butions. In Proceedings of the 2010 Conference of
Empirical Methods in Natural Language Processing.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
adjoining grammars. In G. Rozenberg and A. Salo-
maa, editors, Handbook of Formal Languages, vol-
ume 3, pages 69?124. Springer-Verlag.
Aravind K. Joshi, Leon S. Levy, and Masako Takahashi.
1975. Tree adjunct grammars. Journal of Computer
and System Sciences, 10(1):136?163.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase based translation. In Proceedings
of the 2003 Human Language Technology Conference
of the North American Chapter of the Association for
Computational Linguistics, pages 48?54, Edmonton,
Canada.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical machine
translation with syntactified target language phrases.
In Proceedings of the 2006 Conference of Empirical
Methods in Natural Language Processing, pages 44?
52, Sydney, Australia.
Spyros Matsoukas, Antti-Veikko Rosti, and Bing Zhang.
2009. Discriminative corpus weight estimation for
machine translation. In Proceedings of the 2009 Con-
ference of Empirical Methods in Natural Language
Processing.
Franz J. Och and Hermann Ney. 2004. The alignment
template approach to statistical machine translation.
Computational Linguistics, 30(4).
Kishore Papineni, Salim Roukos, and Todd Ward. 2001.
Bleu: a method for automatic evaluation of machine
translation. IBM Research Report, RC22176.
Carlos Prolo. 2002. Generating the xtag english gram-
mar using metarules. In Proceedings of the 19th in-
ternational conference on Computational linguistics
(COLING).
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings of the 46th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL).
Stuart Shieber and Yves Schabes. 1990. Synchronous
tree adjoining grammars. In Proceedings of COLING
?90: The 13th Int. Conf. on Computational Linguistics,
pages 253?258, Helsinki, Finland.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of Association for Machine Translation
in the Americas, pages 223?231, Cambridge, MA.
T. Watanabe, J. Suzuki, H. Tsukuda, and H. Isozaki.
2007. Online large-margin training for statistical ma-
chine translation. In Proceedings of the 2007 Confer-
ence of Empirical Methods in Natural Language Pro-
cessing.
F. Xia. 2001. Automatic Grammar Generation From
Two Different Perspectives. Ph.D. thesis, University
of Pennsylvania.
844
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 851?856,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
A Corpus Level MIRA Tuning Strategy for Machine Translation
Ming Tan, Tian Xia, Shaojun Wang
Wright State University
3640 Colonel Glenn Hwy,
Dayton, OH 45435 USA
{tan.6, xia.7, shaojun.wang}
@wright.edu
Bowen Zhou
IBM T.J. Watson Research Center
1101 Kitchawan Rd,
Yorktown Heights, NY 10598 USA
zhou@us.ibm.com
Abstract
MIRA based tuning methods have been
widely used in statistical machine translation
(SMT) system with a large number of fea-
tures. Since the corpus-level BLEU is not de-
composable, these MIRA approaches usually
define a variety of heuristic-driven sentence-
level BLEUs in their model losses. Instead,
we present a new MIRA method, which em-
ploys an exact corpus-level BLEU to com-
pute the model loss. Our method is simpler in
implementation. Experiments on Chinese-to-
English translation show its effectiveness over
two state-of-the-art MIRA implementations.
1 Introduction
Margin infused relaxed algorithm (MIRA) has been
widely adopted for the parameter optimization in
SMT with a large feature size (Watanabe et al, 2007;
Chiang et al, 2008; Chiang et al, 2009; Chiang,
2012; Eidelman, 2012; Cherry and Foster, 2012).
Since BLEU is defined on the corpus, and not de-
composed into sentences, most MIRA approaches
consider a variety of sentence-level BLEUs for the
model losses, many of which are heuristic-driven
(Watanabe et al, 2007; Chiang et al, 2008; Chi-
ang et al, 2009; Chiang, 2012; Cherry and Foster,
2012). The sentence-level BLEU appearing in the
objective is generally based on a pseudo-document,
which may not precisely reflect the corpus-level
BLEU. We believe that this mismatch could poten-
tially harm the performance. To avoid the sentence
BLEU, the work in (Haddow et al, 2011) proposed
to process sentences in small batches. The authors
adopted a Gibbs sampling (Arun et al, 2009) tech-
nique to search the hope and fear hypotheses, and
they did not compare with MIRA. Watanabe (2012)
also tuned the parameters with small batches of sen-
tences and optimized a hinge loss not explicitly re-
lated to BLEU using stochastic gradient descent.
Both approaches introduced additional complexities
over baseline MIRA approaches.
In contrast, we propose a remarkably simple but
efficient batch MIRA approach which exploits the
exact corpus-level BLEU to compute model losses.
We search for a hope and a fear hypotheses for the
corpus with a straightforward approach and mini-
mize the structured hinge loss defined on them. The
experiments show that our method consistently out-
performs two state-of-the-art MIRAs in Chinese-to-
English translation tasks with a moderate margin.
2 Margin Infused Relaxed Algorithm
We optimize the model parameters based on N-best
lists. Our development (dev) set is a set of triples
{(fi, ei , ri)}Mi=1, where fi is a source-language sen-
tence, corresponded by a list of target-language hy-
potheses ei = {eij}
N(fi)
j=1 , with a number of refer-
ences ri. h(e ij ) is a feature vector. Generally, most
decoders return a top-1 candidate as the transla-
tion result, such that e?i(w) = arg maxj w ? h(eij ),
where w are the model parameters. In this paper, we
aim at optimizing the BLEU score (Papineni et al,
2002).
MIRA is an instance of online learning which as-
sumes an overlap of the decoding procedure and the
parameter optimization procedure. For example in
(Crammer et al, 2006; Chiang et al, 2008), MIRA
851
is performed after an input sentence are decoded,
and the next sentence is decoded with the updated
parameters. The objective for each sentence i is,
min
w
1
2
||w ?w?||2 + C ? li(w) (1)
li(w) = max
eij
{b(e?i )? b(eij)
?w ? [h(e?i )? h(eij )]} (2)
where e?i ? ei is a hope candidate, w
? is the pa-
rameter vector from the last sentence. Since MIRA
defines its objective only based on the current sen-
tence, b(?) is a sentence-level BLEU.
Most MIRA algorithms need a deliberate defini-
tion of b(?), since BLEU cannot be decomposed into
sentences. The types of the sentence BLEU calcula-
tion includes: (a) a smoothed version of BLEU for
eij (Liang et al, 2006), (b) fit eij into a pseudo-
document considering the history (Chiang et al,
2008; Chiang, 2012), (c) use eij to replace the corre-
sponding hypothesis in the oracles (Watanabe et al,
2007). The sentence-level BLEU sometimes per-
plexes the algorithms and results in a mismatch with
the corpus-level BLEU.
3 Corpus-level MIRA
3.1 Algorithm
We propose a batch tuning strategy, corpus-level
MIRA (c-MIRA), in which an objective is not built
upon a hinge loss of a single sentence, but upon that
of the entire corpus.
The online MIRAs are difficult to parallelize.
Therefore, similar to the batch MIRA in (Cherry and
Foster, 2012), we conduct the batch tuning by re-
peating the following steps: (a) Decode source sen-
tences (in parallel) and obtain {ei}Mi=1, (b) Merge
{ei}Mi=1 with the one from the previous iteration, (c)
Invoke Algorithm 1.
We define E = (eE,1 , eE,2 , ..., eE,M ) as a corpus
hypothesis, with H (E) =
1
M
M?
i=1
h(eE,i). eE,i is the
hypothesis of the source sentence fi covered by E .
E is corresponded to a corpus-level BLEU, which
we ultimately want to optimize. Following MIRA
formulated in (Crammer et al, 2006; Chiang et al,
2008), c-MIRA repeatedly optimizes,
min
w
1
2
||w ?w?||2 + C ? lcorpus(w) (3)
lcorpus(w) = max
E
{B(E?)? B(E)
?w ? [H(E?)?H(E)]} (4)
where B(?) is a corpus-level BLEU. E? is a hope
hypothesis. E ? L, where L is the hypothesis space
of the entire corpus, and |L| = |e1| ? ? ? |eM|.
Algorithm 1 Corpus-Level MIRA
Require: {(fi, ei , ri)}Mi=1, w0, C
1: for t = 1 ? ? ?T do
2: E? = {} ,E ? = {} . Initialize the hope and fear
3: for i = 1 ? ? ?M do
4: eE?,i = arg max
eij
[wt?1 ? h(eij) + b?(eij )]
5: eE?,i = arg max
eij
[wt?1 ? h(eij)? b?(eij )]
6: E? ? E? + {eE?,i} . Build the hope
7: E ? ? E ? + {eE?,i} . Build the fear
8: end for
9: 4B = B(E?)? B(E ?) . the BLEU difference
10: 4H = H(E ?)?H(E?) . the feature difference
11: ? = min
[
C, 4B+wt?1?4H||4H||2
]
12: wt = wt?1 ? ? ? 4H
13: w?t =
1
t+ 1
t?
t=0
wt
14: end for
15: return w?t with the optimal BLEU on the dev set.
c-MIRA can be regarded as a standard MIRA,
in which there is only one single triple (F ,L,R),
where F and R are the source and reference of
the corpus respectively. Eq. 3 is equivalent to a
quadratic programming with |L| constraints. Cram-
mer et al (2006) show that a single constraint with
one hope E? and one fear E ? admits a closed-form
update and performs well. We denote one execution
of the outer loop as an epoch. The hope and fear
are updated in each epoch. Similar to (Chiang et al,
2008), the hope and fear hypotheses are defined as
following,
E? = max
E
[w ?H(E) + B(E)] (5)
E ? = max
E
[w ?H(E)? B(E)] (6)
Eq. 5 and 6 find the hypotheses with the best and
worse BLEU that the decoder can easily achieve. It
is unnecessary to search the entire space of L for
precise solution E?and E ?, because MIRA only at-
852
tempts to separate the hope from the fear by a mar-
gin proportional to their BLEU differentials (Cherry
and Foster, 2012). We just construct E?and E ? re-
spectively by,
eE?,i = max
ei,j
[w ? h(ei,j) + b?(ei,j)]
eE ?,i = max
ei,j
[w ? h(ei,j)? b?(ei,j)]
where b? is simply a BLEU with add one smoothing
(Lin and Och, 2004). A smoothed BLEU is good
enough to pick up a ?satisfying? pair of hope and
fear. However, the updating step (Line 11) uses the
corpus-level BLEU.
3.2 Justification
c-MIRA treats a corpus as one sentence for decod-
ing, while conventional decoders process sentences
one by one. We show the optimal solutions from the
two methods are equivalent theoretically.
We follow the notations in (Och and Ney,
2002). We search a hypothesis on corpus E =
{e1 ,k1 , e2 ,k2 , ..., eM ,kM } with the highest probabil-
ity given the source corpus F = {f1, f2, ..., fM},
E = arg max
E
logP (E|F)
= arg max
E
(
w ?
M?
i=1
h(ei,ki )?
M?
i=1
log(Zi)
)
(7)
= {arg max
ei,ki
w ? h(ei,ki )}
M
i=1 (8)
where Zi =
?N(fi)
j=1 exp(w ? h(ei ,j )), which is a
constant with respective to E . Eq. 7 shows that
the feature vector of E is determined by the sum of
each candidate?s feature vectors. Also, the model
score can be decomposed into each sentence in Eq.
8, which shows that decoding all sentences together
equals to decoding one by one.
We also show that if the metric is decomposable,
the loss in c-MIRA is actually the sum of the hinge
loss li(w) in structural SVM (Tsochantaridis et al,
2004; Cherry and Foster, 2012). We assume B(eij)
to be the metric of a sentence hypothesis, then the
loss of c-MIRA in Eq. 4 is,
lcorpus(w) ? max
E?
M?
i=1
[B(ei,kE? )?B(ei,kE? )
?w?h(ei,kE? ) + w ? h(ei,kE? )]
=
M?
i=1
max
eij
[B(ei,kE? )?B(eij)
?w?h(ei,kE? ) + w ? h(eij)] =
M?
i=1
li(w)
Instead of adopting a cutting-plane algorithm
(Tsochantaridis et al, 2004), we optimize the same
loss with a MIRA pattern in a simpler way. How-
ever, since BLEU is not decomposable, the struc-
tural SVM (Cherry and Foster, 2012) uses an inter-
polated sentence BLEU (Liang et al, 2006). Al-
though Algorithm 1 has an outlook similar to the
batch-MIRA algorithm in (Cherry and Foster, 2012),
their loss definitions differ fundamentally. Batch
MIRA basically uses a sentence-level loss, and they
also follow the sentence-by-sentence tuning pattern.
In the future work, we will compare structural SVM
and c-MIRA under decomposable metrics like WER
or SSER (Och and Ney, 2002).
4 Experiments and Analysis
We first evaluate c-MIRA in a iterative batch tuning
procedure in a Chinese-to-English machine transla-
tion system with 228 features. Second, we show c-
MIRA is also effective in the re-ranking task with
more than 50,000 features.
In both experiments, we compare c-MIRA and
three baselines: (1) MERT (Och, 2003), (2) Chiang
et al?s MIRA (MIRA1) in (Chiang et al, 2008). (3)
batch-MIRA (MIRA2) in (Cherry and Foster, 2012).
Here, we roughly choose C with the best BLEU on
dev set, from {0.1, 0.01, 0.001, 0.0001, 0.00001}.
We convert Chiang et al?s MIRA to the batch mode
described in section 3.1. So the only difference be-
tween MIRA1 and MIRA2 is: MIRA1 obtains mul-
tiple constraints before optimization, while MIRA2
only uses one constraint. We implement MERT
and MIRA1, and directly use MIRA2 from Moses
(Koehn et al, 2007). We conduct experiments in a
server of 8-cores with 2.5GHz Opteron. We set the
maximum number of epochs as we generally do not
observe an obvious increase on the dev set BLEU.
853
MERT MIRA1 MIRA2 c-MIRA
C 0.0001 0.001 0.0001
8 dev 34.80 34.70 34.73 34.70
feat. 04 31.92 31.81 31.73 31.83
05 28.85 28.94 28.71 28.92
C 0.001 0.001 0.001
all dev 34.61 35.24 35.14 35.56
feat. 04 31.76 32.25 32.04 32.57+
05 28.85 29.43 29.37 29.41
06news 30.91 31.43 31.24 31.82+
06others 27.43 28.01 28.13 28.45
08news 25.62 26.11 26.03 26.40
08others 16.22 16.66 16.46 17.10+
Table 1: BLEUs (%) on the dev and test sets with 8 dense
features only and all features. The significant symbols (+
at 0.05 level) are compared with MIRA2
The epoch size for MIRA1 and MIRA2 is 40, while
the one for c-MIRA is 400. c-MIRA runs more
epochs, because we update the parameters by much
fewer times. However, we can implement Line 3?8
in Algorithm 1 in multi-thread (we use eight threads
in the following experiments), which makes our al-
gorithm much faster. Also, we increase the epoch
sizes of MIRA1 and MIRA2 to 400, and find there
is no improvement on their performance.
4.1 Iterative Batch Training
In this experiment, we conduct the batch tuning pro-
cedure shown in section 3. We align the FBIS data
including about 230K sentence pairs with GIZA++
for extracting grammar, and train a 4-gram language
model on the Xinhua portion of Gigaword corpus. A
hierarchical phrase-based model (Chiang, 2007) is
tuned on NIST MT 2002, which has 878 sentences,
and tested on MT 2004, 2005, 2006, and 2008. All
features used here, besides eight basic ones in (Chi-
ang, 2007), consists of an extra 220 group features.
We design such feature templates to group gram-
mar by the length of source side and target side,
(feat type, a ? src side ? b, c ? tgt side ? d) ,
where feat type denotes any of relative frequency,
reversed relative frequency, lexical probability and
reversed lexical probability, and [a, b], [c, d] enumer-
ate all possible subranges of [1, 10], as the maximum
MERT MIRA1 MIRA2 c-MIRA
R. T. 25.8min 16.0min 7.3min 7.8min
Table 2: Running time.
length on each side of a hierarchical grammar is lim-
ited to 10. There are 4? 55 extra group features. We
also set the size of N-best list per sentence before
merge as 200.
All methods use 30 decoding iterations. We se-
lect the iteration with the best BLEU of the dev set
for testing. We present the BLEU scores in Table 1
on two feature settings: (1) 8 basic features only, and
(2) all 228 features. In the first case, due to the small
feature size, MERT can get a better BLEU of the
dev set, and all MIRA algorithms fails to generally
beat MERT on the test set. However, as the feature
size increase to 228, MERT degrades on the dev-set
BLEU, and also become worse on test sets, while
MIRA algorithms improve on the dev set expect-
edly. MIRA1 performs better than MIRA2, proba-
bly because of more constraints. c-MIRA can mod-
erately improve BLEU by 0.2?0.4 from MIRA1
and 0.2?0.6 from MIRA2. This might indicate that
a loss defined on corpus is more accurate than the
one defined on sentence. Table 2 lists the running
time. Only MIRA2 is fairly faster than c-MIRA be-
cause of more epochs in c-MIRA.
4.2 Re-ranking Experiments
The baseline system is a state-of-the-art hierarchi-
cal phrase-based system, and trained on six million
parallel sentences corpora available to the DARPA
BOLT Chinese-English task. This system includes
51 dense features (including translation probabili-
ties, provenance features, etc.) and about 50k sparse
features (mostly lexical and fertility-based). The
language model is a six-gram model trained on a
10 billion words monolingual corpus, including the
English side of our parallel corpora plus other cor-
pora such as Gigaword (LDC2011T07) and Google
News. We use 1275 sentences for tuning and 1239
sentences for testing from the LDC2010E30 corpus
respectively. There are four reference translations
for each input sentence in both tuning and testing
datasets.
We use a N-best list which is an intermediate out-
854
MIRA1 MIRA2 c-MIRA
dense dev 31.90 31.78 32.00
only test 30.89 30.89 31.07
dense dev 32.29 32.20 32.49
+sparse test 31.12 31.00 31.39
Table 3: BLEUs (%) on re-ranking experiments.
MIRA1 MIRA2 c-MIRA
about 1,966,720 35,120 400
Table 4: Times of updating model parameters.
put of the baseline system optimized on TER-BLEU
instead of BLEU. Before the re-ranking task, the ini-
tial BLEUs of the top-1 hypotheses on the tuning
and testing set are 31.45 and 30.56. The average
numbers of hypotheses per sentence are about 200
and 500, respectively for the tuning and testing sets.
Again, we use the best epoch on the tuning set for
testing. The BLEUs on dev and test sets are reported
in Table 3. We observe that the effectiveness of c-
MIRA is not harmed as the feature size is scaled up.
4.3 Analysis
To examine the simple search for hopes and fears
(Line 3?8 in Alg. 1), we use two hope/fear building
strategies to get E? and E ? : (1) simply connect each
e?i and e
?
i in Line 4?5 of Algorithm 1, (2) conduct a
slow beam search among the N-best lists of all for-
eign sentences from e1 to eM and use Eq. 5 and
6 to prune the stack. The stack size is 10. We ob-
serve that there is no significant difference between
the two strategies on the BLEU of the dev set. But
the second strategy is about 10 times slower.
We also consider more constraints in Eq. 3. By
beam search, we obtain one corpus-level oracle and
29 other hypotheses similar to (Chiang et al, 2008),
and optimize with SMO (Platt, 1998). Unfortu-
nately, experiments show that more constraints lead
to an overfitting and no improved performance.
As shown in Table 4, in one execution, our
method updates the parameters by only 400 times;
MIRA2 updates by 40 ? 878 = 35120 times; and
MIRA1 updates much more (about 1,966,720 times)
due to the SMO procedure. We are surprised to find
c-MIRA gets a higher training BLEU with such few
parameter updates. This probably suggests that there
is a gap between sentence-level BLEU and corpus-
level BLEU, so standard MIRAs need to update the
parameters more often.
Regarding simplicity, MIRA1 uses a strongly-
heuristic definition of a sentence BLEU, and
MIRA2 needs a pseudo-document with a decay rate
of ? = 0.9. In comparison, c-MIRA avoids both
the sentence level BLEU and the pseudo-document,
thus needs fewer variables.
5 Conclusion
We present a simple and effective MIRA batch tun-
ing algorithm without the heuristic-driven calcula-
tion of sentence-level BLEU, due to the indecom-
posability of a corpus-level BLEU. Our optimiza-
tion objective is directly defined on the corpus-level
hypotheses. This work simplifies the tuning pro-
cess, and avoid the mismatch between the sentence-
level BLEU and the corpus-level BLEU. This strat-
egy can be potentially applied to other optimiza-
tion paradigms, such as the structural SVM (Cherry
and Foster, 2012), SGD and AROW (Chiang, 2012),
and other forms of samples, such as forests (Chiang,
2012) and lattice (Cherry and Foster, 2012).
6 Acknowledgments
The key idea and a part of the experimental work
of this paper were developed in collaboration with
the IBM researcher when the first author was an in-
tern at IBM T.J. Watson Research Center. This re-
search is partially supported by Air Force Office of
Scientific Research under grant FA9550-10-1-0335,
the National Science Foundation under grant IIS RI-
small 1218863 and a Google research award.
References
A. Arun, C. Dyer, B. Haddow, P. Blunsom, A. Lopez,
and P. Koehn. 2009. Monte Carlo inference and maxi-
mization for phrase-based translation. In Proceedings
of the Thirteenth Conference on Computational Natu-
ral Language Learning (CoNLL), 102-110.
C. Cherry and G. Foster. 2012. Batch tuning strategies
for statistical machine translation. Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (NAACL-HLT), 427-436.
855
D. Chiang. 2012. Hope and fear for discriminative train-
ing of statistical translation models. Journal of Ma-
chine Learning Research (JMLR), 1159-1187.
D. Chiang, K. Knight, and W. Wang. 2009. 11,001 new
features for statistical machine translation. Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies (NAACL-HLT), 218-226.
D. Chiang, Y. Marton, and P. Resnik. 2008. Online large-
margin training of syntactic and structural translation
features. In Proc. of Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), 224-
233.
D. Chiang. 2007. Hierarchical phrase-based translation.
Computational Linguistics, 33(2):201-228.
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive al-
gorithms. Journal of Machine Learning Research
(JMLR), 7:551-585.
V. Eidelman. 2012. Optimization strategies for online
large-margin learning in machine translation. Pro-
ceedings of the Seventh Workshop on Statistical Ma-
chine Translation, 480-489.
B. Haddow, A. Arun, and P. Koehn. 2011. SampleRank
training for phrase-based machine translation. Pro-
ceedings of the Sixth Workshop on Statistical Machine
Translation. Association for Computational Linguis-
tics, 261-271.
P. Koehn, H. Hoang, A. Birch, C. Burch, M. Federico, N.
Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C.
Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. Proceedings of the Annual Meeting of
the Association for Computational Linguistics (ACL),
177-180.
P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar.
2006. An end-to-end discriminative approach to ma-
chine translation. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the Association for Com-
putational Linguistics, 761-768.
C. Lin and F. Och. 2004. Orange: a method for evaluat-
ing automatic evaluation metrics for machine transla-
tion. In Proc. of International Conference on Compu-
tational Linguistics (COLING), No. 501.
F. Och. 2003. Minimum error rate training in statistical
machine translation. Proceedings of the 41st Annual
Meeting on Association for Computational Linguistics
(ACL), 160-167.
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics (ACL),
295-302.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. Proceedings of the 40th annual meeting on
association for computational linguistics. Association
for Computational Linguistics (ACL), 311-318.
J. Platt. 1998. Sequetial minimal optimization: A fast al-
gorithm for training support vector machines. In Tech-
nical Report MST-TR-98-14. Microsoft Research.
I. Tsochantaridis, T. Hofman, T. Joachims, and Y. Altun.
2004. Support vector machine learning for interde-
pendent and structured output spaces. International
Conference on Machine Learning (ICML), 823-830.
T. Watanabe. 2012. Optimized online rank learning for
machine translation. Proceedings of Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (NAACL-HLT), 253-262.
T. Watanabe, J. Suzuki, H. Tsukada, and H. Isozaki.
2007. Online large-margin training for statistical ma-
chine translation. Proceedings of Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), 764-773.
856
Proceedings of NAACL-HLT 2013, pages 335?341,
Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational Linguistics
Discriminative Training of 150 Million Translation Parameters
and Its Application to Pruning
Hendra Setiawan and Bowen Zhou
IBM T.J. Watson Research Center
Yorktown Heights, NY 10598, USA
{hendras, zhou}@us.ibm.com
Abstract
Until recently, the application of discrimina-
tive training to log linear-based statistical ma-
chine translation has been limited to tuning
the weights of a limited number of features or
training features with a limited number of pa-
rameters. In this paper, we propose to scale
up discriminative training of (He and Deng,
2012) to train features with 150 million pa-
rameters, which is one order of magnitude
higher than previously published effort, and
to apply discriminative training to redistribute
probability mass that is lost due to model
pruning. The experimental results confirm the
effectiveness of our proposals on NIST MT06
set over a strong baseline.
1 Introduction
State-of-the-art statistical machine translation sys-
tems based on a log-linear framework are parame-
terized by {?,?}, where the feature weights ? are
discriminatively trained (Och and Ney, 2002; Chi-
ang et al, 2008b; Simianer et al, 2012) by directly
optimizing them against a translation-oriented met-
ric such as BLEU. The feature parameters ? can
be roughly divided into two categories: dense fea-
ture that measures the plausibility of each translation
rule from a particular aspect, e.g., the rule transla-
tion probabilities p(f |e) and p(e|f); and sparse fea-
ture that fires when certain phenomena is observed,
e.g., when a frequent word pair co-occured in a rule.
In contrast to ?, feature parameters in ? are usually
modeled by generative models for dense features, or
by indicator functions for sparse ones. It is therefore
desirable to train the dense features for each rule in a
discriminative fashion to maximize some translation
criterion. The maximum expected BLEU training of
(He and Deng, 2012) is a recent effort towards this
direction, and in this paper, we extend their work
to a scaled-up task of discriminative training of the
features of a strong hierarchical phrase-based model
and confirm its effectiveness empirically.
In this work, we further consider the application
of discriminative training to pruned model. Various
pruning techniques (Johnson et al, 2007; Zens et al,
2012; Eck et al, 2007; Lee et al, 2012; Tomeh et al,
2011) have been proposed recently to filter transla-
tion rules. One common consequence of pruning is
that the probability distribution of many surviving
rules become deficient, i.e.
?
f p(f |e) < 1. In prac-
tice, others have chosen either to leave the pruned
rules as it-is, or simply to re-normalize the proba-
bility mass by distributing the pruned mass to sur-
viving rules proportionally. We argue that both ap-
proaches are suboptimal, and propose a more prin-
cipled method to re-distribute the probability mass,
i.e. using discriminative training with some trans-
lation criterion. Our experimental results demon-
strate that at various pruning levels, our approach
improves performance consistently. Particularly at
the level of 50% of rules being pruned, the discrimi-
natively trained models performs better than the un-
pruned baseline grammar. This shows that discrim-
inative training makes it possible to achieve smaller
models that perform comparably or even better than
the baseline model.
Our contributions in this paper are two-folded:
First of all, we scale up the maximum expected
BLEU training proposed in (He and Deng, 2012) in
a number of ways including using 1) a hierarchical
phrase-based model, 2) a richer feature set, and 3) a
larger training set with a much larger parameter set,
resulting in more than 150 million parameters in the
model being updated, which is one order magnitude
higher than the phrase-based model reported in (He
and Deng, 2012). We are able to show a reasonable
335
improvement over this strong baseline. Secondly,
we combine discriminative training with pruning
techniques to reestimate parameters of pruned gram-
mar. Our approach is shown to alleviate the loss due
to pruning, and sometimes can even outperform the
baseline unpruned grammar.
2 Discriminative Training of ?
Given the entire training data {Fn, En}Nn=1, and cur-
rent parameterization {?,?}, we decode the source
side of training data Fn to produce hypothesis
{E?n}Nn=1. Our goal is to update ? towards ?
? that
maximizes the expected BLEU scores of the entire
training data given the current ?:
U(?)=
?
?E?1...E?N
P??(E?1..E?N |F1..FN )B(E?1..E?N ) (1)
where B(E?1...E?N ) is the BLEU score of the con-
catenated hypothesis of the entire training data, fol-
lowing (He and Deng, 2012).
Eq. 1 summarizes over all possible combina-
tions of E?1...E?N , which is intractable. Hence we
make two simplifying approximations as follows.
First, let the k-best hypotheses of the n-th sen-
tence, E?n =
{
E?1n, ..., E?
K
n
}
, approximate all its
possible translation. In other words, we assume
that
?K
k=1 P? (E?
k
n|Fn) = 1, ?n. Second, let the
sum of sentence-level BLEU approximate the cor-
pus BLEU. We note that corpus BLEU is not strictly
decomposable (Chiang et al, 2008a), however, as
the training data?s size N gets big as in our case, we
expect them to become more positively correlated.
Under these assumptions and the fact that each
sentence is decoded independently, Eq. 1 can be al-
gebraically simplified into:
U(?) =
N?
n=1
K?
k=1
P?(E?
k
n|Fn)B(E?
k
n) (2)
where P?(E?kn|Fn)=P??(E?
k
n|Fn)/
?
?k P??(E?
k
n|Fn).
We detail the process in the Appendix.
To further simplify the problem and relate it with
model pruning, we consider to update a subset of
? ? ? while keeping other parameterization of ?
unchanged, where ? = {?ij = p(ej |fi)} denotes our
parameter set that satisfies
?
j ?ij = 1 and ?ij ? 0.
In experiments, we also consider {?ji = p(fi|ej)}.
To alleviate overfitting, we introduce KL-distance
based reguralization as in (He and Deng, 2012). We
thus arrive at the following objective function:
O(?) = log(U(?))? ? ?KL(?||?0)/N (3)
where ? controls the regularization term?s contribu-
tion, and ?0 represents a prior parameter set, e.g.,
from the conventional maximum likelihood training.
The optimization algorithm is based on the Ex-
tended Baum Welch (EBW) (Gopalakrishnan et al,
1991) as derived by (He and Deng, 2012). The final
update rule is as follow:
??ij =
?
n
?
k ?(n, k, i, j) + U(?)??
0
ij/?+Di?ij
?
n
?
k
?
j ?(n, k, i, j) + U(?)?/?+Di
(4)
where ??ij is the updated parameter, ?(n, k, i, j) =
P?(E?kn|Fn){B(E?
k
n) ? Un(?)}
?
l 1(fn,k,l =
fi, en,k,l = ej); Un(?) =
?K
k=1 P?(E?
k
n|Fn)B(E?
k
n);
Di =
?
n,k,j max(0,??(n, k, i, j)) and ? is the
current feature?s weight.
3 DT is Beneficial for Pruning
Pruning is often a key part in deploying large-scale
SMT systems for many reasons, such as for reduc-
ing runtime memory footprint and for efficiency.
Many pruning techniques have been proposed to as-
sess translation rules and filter rules out if they are
less plausible than others. While different pruning
techniques may use different criterion, they all as-
sume that pruning does not affect the feature func-
tion values of the surviving rules. This assumption
may be suboptimal for some feature functions that
have probabilistic sense since pruning will remove
a portion of the probability mass that is previously
assigned to the pruned rules. To be concrete, for the
rule translation probabilities ?ij under consideration,
the constraint
?
j ?ij = 1 will not hold for all source
rules i after pruning. Previous works typically left
the probability mass as it-is, or simply renormalize
the pruned mass, i.e. ??ij = ?ij/
?
j ?ij .
We argue that applying the DT techniques to a
pruned grammar, as described in Sec. 2, provides
a more principled method to redistribute the mass,
i.e. by quantizing how each rule contributes to the
expected BLEU score in comparison to other com-
peting rules. To empirically verify this, we consider
336
the significance test based pruning (Johnson et al,
2007), though our general idea can be appllied to
any pruning techniques. For our experiments, we
use the significance pruning tool that is available as
part of Moses decoder package (Koehn et al, 2007).
4 Experiments
Our experiments are designed to serve two goals:
1) to show the performance of discriminative train-
ing of feature parameters ? in a large-scale task;
and 2) to show the effectiveness of DT when ap-
plied to pruned grammar. Our baseline system is a
state-of-the-art hierarchical phrase-based system as
described in (Zhou et al, 2008), trained on six mil-
lion parallel sentences corpora that are available to
the DARPA BOLT Chinese-English task. The train-
ing corpora includes a mixed genre of news wire,
broadcast news, web-blog and comes from various
sources such as LDC, HK Hansard and UN data.
In total, there are 50 dense features in our trans-
lation system. In addition to the standard features
which include the rule translation probabilities, we
incorporate features that are found useful for devel-
oping a state-of-the-art baseline, e.g. provenance-
based lexical features (Chiang et al, 2011). We use
a large 6-gram language model, which we train on a
10 billion words monolingual corpus, including the
English side of our parallel corpora plus other cor-
pora such as Gigaword (LDC2011T07) and Google
News. To prevent possible over-fitting, we only kept
the rules that have at most three terminal words (plus
up to two nonterminals) on the source side, resulting
in a grammar with 167 million rules.
Our discriminative training procedure includes
updating both ? and ?, and we follow (He and Deng,
2012) to optimize them in an alternate manner. That
is, when we optimize ? via EBW, we keep ? fixed
and when we optimize ?, we keep ? fixed. We use
PRO (Hopkins and May, 2011) to tune ?.
For discriminative training of ?, we use a subset
of 550 thousands of parallel sentences selected from
the entire training data, mainly to allow for faster ex-
perimental cycle; they mainly come from news and
web-blog domains. For each sentence of this subset,
we generate 500-best of unique hypotheses using the
baseline model. The 1-best and the oracle BLEU
scores for this subset are 40.19 and 47.06 respec-
tively. Following (He and Deng, 2012), we focus on
discriminative training of p(f |e) and p(e|f), which
in practice affects around 150 million of parameters;
hence the title.
For the tuning and development sets, we set
aside 1275 and 1239 sentences respectively from
LDC2010E30 corpus. The tune set is used by PRO
for tuning ? while the dev set is used to decide the
best DT model. As for the blind test set, we re-
port the performance on the NIST MT06 evaluation
set, which consists of 1644 sentences from news and
web-blog domains. Our baseline system?s perfor-
mance on MT06 is 39.91 which is among the best
number ever published so far in the community.
Table 1 compares the key components of our
baseline system with that of (He and Deng, 2012).
As shown, we are working with a stronger system
than (He and Deng, 2012), especially in terms of the
number of parameters under consideration |?|.
He&Deng(2012) This paper
Model phrase-based hierarchical
n-gram lm 3-gram 6-gram
# features 10 50
Max terminal 4 3
|?| 9.2 M 150M
# training data 750K 6M
N for DT 750K 550K
max K-best 100 500
Table 1: Our system compares to He&Deng?s (2012).
4.1 DT of 150 Million Parameters
To ensure the correctness of our implementation,
we show in Fig 2, the first five EBW updates with
? = 0.10. As shown, the utility function log(U(?))
increases monotonically but is countered by the KL
term, resulting in a smaller but consistent increase
of the objective function O(?). This monotonically-
increasing trend of the objective function confirms
the correctness of our implementation since EBW
algorithm is a bound-based technique that ensures
growth transformations between updates.
We then explore the optimal setting for ? which
controls the contribution of the regularization term.
Specifically, we perform grid search, exploring val-
ues of ? from 0.1 to 0.75. For each ? , we run several
iterations of discriminative training where each it-
eration involves one simultaneous update of p(f |e)
337
and p(e|f) according to Eq. 4, followed by one up-
date of ? via PRO (as in (He and Deng, 2012)). In
total, we run 10 such iterations for each ? .
tau=0.01N tau=0.05N tau=0.10N tau=0.25N tau=0.50N tau=0.75N tau=0.100 32.22 32.22 32.22 32.22 32.22 32.22 0 32.221 32.33 32.24 32.39 32.42 32.5 32.34 1 32.392 32.39 32.34 32.63 32.45 32.41 32.33 2 32.633 32.37 32.29 32.54 32.32 32.24 32.45 3 32.544 32.35 32.18 32.41 32.45 32.41 32.38 4 32.415 32.38 32.21 32.45 32.62 32.31 32.08 5 32.456 32.26 32.27 32.68 32.45 32.26 32.28 6 32.687 32.17 32.15 32.45 32.54 32.37 32.15 7 32.458 31.93 32.26 32.29 32.56 32.25 32.31 8 32.299 32.1 32.36 32.25 32.33 32.23 32.54 9 32.2510 32.1 32.29 32.2 32.42 32.29 32.31 10 32.232.39 32.36 32.68 32.62 32.5 32.5433.090.01 0.05 0.1 0.25 0.5 0.750.01 (2) 0.05 (9) 0.10 (6) 0.25 (5) 0.50 (1) 0.75 (9)32.39 32.36 32.68 32.62 32.5 32.5432.22 32.22 32.22 32.22 32.22 32.22
32.2$
32.3$
32.4$
32.5$
32.6$
32.7$
32.8$
0$ 1$ 2$ 3$ 4$ 5$ 6$ 7$
tau=0.10$
32.39$ 32.36$
32.68$ 32.62$
32.5$ 32.54$
32.22$32.2$32.25$
32.3$32.35$
32.4$32.45$
32.5$32.55$
32.6$32.65$
32.7$
0.01$(2)$ 0.05$(9)$ 0.10$(6)$ 0.25$(5)$ 0.50$(1)$ 0.75$(9)$
DT$baseline$
? = 0.01N
Figure 1: The dev set?s BLEU score (y-axis) on different
setting of ? (x-axis). The grey line indicates the baseline
performance on dev set. The number in bracket on the x-
axis indicates the iteration at which the score is obtained.
Across different ? , we find that the first iteration
provides most of the gain while the subsequent iter-
ations provide additional, smaller gain with occas-
sional performance degradation; thus the translation
performance is not always monotonically increasing
over iteration. We report the best score of each ? in
Fig. 1 and at which iteration that score is produced.
As shown in Fig. 1, all settings of ? improve over the
baseline and ? = 0.10 gives the highest gain of 0.45
BLEU score. This improvement is in the same ball-
park as in (He and Deng, 2012) though on a scaled-
up task. We next decode the MT06 using the best
model (i.e. ? = 0.10 at 6-th iteration) observed on
the dev set, and obtained 40.33 BLEU with an im-
provement of around 0.4 BLEU point. We see this
result as confirming the effectiveness of discrimi-
native training but on a larger-scale task, adding to
what was reported by (He and Deng, 2012).
4.2 DT for Significance Pruning
Next, we show the contribution of discriminative
training for model pruning. To do so, we prune the
translation grammar so that its size becomes 50%,
25%, 10% of the original grammar. Respectively,
we delete rules whose significance value below 15,
50 and 500. Table 2 compares the statistics of the
pruned grammars and the unpruned one. In particu-
lar, columns 4 and 5 show the total averaged prob-
ability mass of the remaining rules. This statistics
provides some indication of how deficient the fea-
Figure 2: Objective function (O(??)), the regularization
term (KL(??)) and the unregularized objective function
(log(U(??))) for five EBW updates of updating p(ej |fi)
tures are after pruning. As shown, the total averaged
probability mass after pruning is below 100% and
even lower for the more aggressive pruning.
To show that the deficiency is suboptimal, we con-
siders two baseline systems: models with/without
mass renormalization. We tune a new ? for each
model and use the new ? to decode the dev and test
sets. The results are shown in columns 6 and 9 of
Table 2 where we show the results for the unnor-
malized model in the brackets following the results
for the re-normalized model. The results show that
pruning degrades the performances and that naively
re-normalizing the model provides no significant
changes in performance. Subsequently, we will fo-
cus on the normalized models as the baseline as they
represents the starting points of our EBW iteration.
Next, we run discriminative training that would
reassign the probability mass to the surviving rules.
First, we normalize p(f |e) and p(e|f), so that they
satisfy the sum to one constraint required by the al-
gorithm. Then, we run discriminative training on
these pruned grammars using ? = 0.10 (i.e. the
setting that gives the best performance for the un-
pruned grammar as discussed in Section 4.1). We
report the results in columns 7 and 9 for the dev and
test sets respectively, as well as the gain over the
baseline system in columns 8 and 10.
As shown in Table 2, DT provides a nice im-
provement over the baseline model of no mass re-
assignment. For all pruning levels, DT can compen-
sate the loss associated with pruning. In particular,
at 50% level of pruning, there is a loss about 0.4
338
size |f | |e| p(?|e) p(?|f) dev-set test-set (MT06)
(%) (M) (M) baseline (un) DT (iter) gain baseline (un) DT gain
100 59 50 1.00 1.00 32.22(32.08) 32.68 (6) +0.44 39.91 (39.71) 40.33 +0.42
50 38 35 0.92 0.94 31.84 (32.02) 32.31 (6) +0.57 39.61(39.72) 40.08 +0.47
25 14 14 0.87 0.91 31.39 (31.43) 31.68 (2) +0.29 39.23 (39.17) 39.43 +0.20
10 4 3 0.77 0.84 27.27 (27.10) 27.82 (2) +0.55 36.01 (36.04) 36.43 +0.42
Table 2: The statistics of grammars pruned at various level (column 1), including the number of unique source and
target phrases (columns 2 & 3), total probability mass of the remaining rules for p(f |e) and p(e|f) (columns 4 & 5),
the performance of the pruned model before and after discriminative training as well as the gain on the dev and the
test sets (columns 6 to 11). The iteration at which DT gives the best dev set is indicated by the number enclosed by
bracket in column 7. The baseline performance is in italics, followed by a number in the bracket which refers to the
performance of using unnormalized model. The above-the-baseline performances are in bold.
BLEU point after pruning. With the DT on pruned
model, all pruning losses are reclaimed and the new
pruned model is even better than the unpruned orig-
inal model. This empirical result shows that leaving
probability mass unassigned after pruning is sub-
optimal and that discriminative training provides a
principled way to redistribute the mass.
5 Conclusion
In this paper, we first extend the maximum expected
BLEU training of (He and Deng, 2012) to train
two features of a state-of-the-art hierarchical phrase-
based system, namely: p(f |e) and p(e|f). Com-
pared to (He and Deng, 2012), we apply the algo-
rithm to a strong baseline that is trained on a big-
ger parallel corpora and comes with a richer feature
set. The number of parameters under consideration
amounts to 150 million. Our experiments show that
discriminative training these two features (out of 50)
gives around 0.40 BLEU point improvement, which
is consistent with the conclusion of (He and Deng,
2012) but in a much larger-scale system.
Furthermore, we apply the algorithm to redis-
tribute the probability mass of p(f |e) and p(e|f) that
is commonly lost due to conventional model prun-
ing. Previous techniques either leave the probability
mass as it is or distribute it proportionally among the
surviving rules. We show that our proposal of us-
ing discriminative training to redistribute the mass
empirically performs better, demonstrating the ef-
fectiveness of our proposal.
Appendix
We describe the process to simplify Eq. 1 to Eq. 2,
which is omitted in (He and Deng, 2012). For con-
ciseness, we drop the conditions and write P (E?i|Fi)
as P (E?i). We write Eq. 1 again below as Eq. 5 .
?
?E?1...E?N
N?
i=1
P (E?i|Fi) ?
N?
i=1
B(E?i) (5)
We first focus on the first sentence E1/F1 and ex-
pand the related terms from the equation as follow:
?
?E?1
?
?E?2...E?N
P (E?1)
N?
i=2
P (E?i).
[
B(E?1)+
N?
i=2
B(E?i)
]
Expanding the inner summation, we arrive at:
?
?E?1
P (E?1)B(E?1)
?
?E?2...E?N
N?
i=2
P (E?i) +
?
?E?1
P (E?1)
?
?E?2...E?N
N?
i=2
P (E?i)
N?
i=2
B(E?i)
Due to the that
?K
k=1 P? (E?
K
n |Fn) = 1, we can
equate
?
?E?2...E?N
?N
i=2 P (E?i) and
?
?E?1
P (E?1) to
1. Thus, we arrive at:
?
?E?1
P (E?1)B(E?1) +
?
?E?2...E?N
N?
i=2
P (E?i)
N?
i=2
B(E?i)
Notice that the second term has the same form
as Eq. 5 except that the starting index starts from
the second sentence. The same process can be per-
formed and at the end, thus we can arrive at Eq. 2.
339
Acknowledgments
We thank Xiadong He for helpful discussions. We
would like to acknowledge the support of DARPA
under Grant HR0011-12-C-0015 for funding part of
this work. The views, opinions, and/or findings con-
tained in this article/presentation are those of the au-
thor/presenter and should not be interpreted as rep-
resenting the official views or policies, either ex-
pressed or implied, of the DARPA.
References
David Chiang, Steve DeNeefe, Yee Seng Chan, and
Hwee Tou Ng. 2008a. Decomposability of transla-
tion metrics for improved evaluation and efficient al-
gorithms. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing,
pages 610?619, Honolulu, Hawaii, October. Associa-
tion for Computational Linguistics.
David Chiang, Yuval Marton, and Philip Resnik. 2008b.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the 2008
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 224?233, Honolulu, Hawaii,
October. Association for Computational Linguistics.
David Chiang, Steve DeNeefe, and Michael Pust. 2011.
Two easy improvements to lexical weighting. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies, pages 455?460, Portland, Oregon, USA,
June. Association for Computational Linguistics.
Matthias Eck, Stephan Vogel, and Alex Waibel. 2007.
Translation model pruning via usage statistics for sta-
tistical machine translation. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Companion Volume, Short Papers,
pages 21?24, Rochester, New York, April. Association
for Computational Linguistics.
P. S. Gopalakrishnan, Dimitri Kanevsky, Arthur Na?das,
and David Nahamoo. 1991. An inequality for ratio-
nal functions with applications to some statistical esti-
mation problems. IEEE Transactions on Information
Theory, 37(1):107?113.
Xiaodong He and Li Deng. 2012. Maximum expected
bleu training of phrase and lexicon translation mod-
els. In Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics (Volume 1:
Long Papers), pages 292?301, Jeju Island, Korea, July.
Association for Computational Linguistics.
Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proceedings of the 2011 Conference on Empir-
ical Methods in Natural Language Processing, pages
1352?1362, Edinburgh, Scotland, UK., July. Associa-
tion for Computational Linguistics.
Howard Johnson, Joel Martin, George Foster, and Roland
Kuhn. 2007. Improving translation quality by dis-
carding most of the phrasetable. In Proceedings of the
2007 Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL), pages 967?
975, Prague, Czech Republic, June. Association for
Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages 177?
180, Prague, Czech Republic, June. Association for
Computational Linguistics.
Seung-Wook Lee, Dongdong Zhang, Mu Li, Ming Zhou,
and Hae-Chang Rim. 2012. Translation model size
reduction for hierarchical phrase-based statistical ma-
chine translation. In Proceedings of the 50th Annual
Meeting of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 291?295, Jeju Is-
land, Korea, July. Association for Computational Lin-
guistics.
Franz Josef Och and Hermann Ney. 2002. Discrimi-
native training and maximum entropy models for sta-
tistical machine translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 295?302, Philadelphia, Pennsylva-
nia, USA, July. Association for Computational Lin-
guistics.
Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012.
Joint feature selection in distributed stochastic learn-
ing for large-scale discriminative training in smt. In
Proceedings of the 50th Annual Meeting of the Associ-
ation for Computational Linguistics (Volume 1: Long
Papers), pages 11?21, Jeju Island, Korea, July. Asso-
ciation for Computational Linguistics.
N. Tomeh, M. Turchi, G. Wisniewski, A. Allauzen, and
F. Yvon. 2011. How good are your phrases? assess-
ing phrase quality with single class classification. In
Proceedings of the International Workshop on Spoken
Language Translation, pages 261?268.
Richard Zens, Daisy Stanton, and Peng Xu. 2012. A
systematic comparison of phrase table pruning tech-
niques. In Proceedings of the 2012 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
340
pages 972?983, Jeju Island, Korea, July. Association
for Computational Linguistics.
Bowen Zhou, Bing Xiang, Xiaodan Zhu, and Yuqing
Gao. 2008. Prior derivation models for formally
syntax-based translation using linguistically syntactic
parsing and tree kernels. In Proceedings of the ACL-
08: HLT Second Workshop on Syntax and Structure in
Statistical Translation (SSST-2), pages 19?27, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
341
Proceedings of the ACL 2010 Conference Short Papers, pages 22?26,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Diversify and Combine: Improving Word Alignment for Machine
Translation on Low-Resource Languages
Bing Xiang, Yonggang Deng, and Bowen Zhou
IBM T. J. Watson Research Center
Yorktown Heights, NY 10598
{bxiang,ydeng,zhou}@us.ibm.com
Abstract
We present a novel method to improve
word alignment quality and eventually the
translation performance by producing and
combining complementary word align-
ments for low-resource languages. Instead
of focusing on the improvement of a single
set of word alignments, we generate mul-
tiple sets of diversified alignments based
on different motivations, such as linguis-
tic knowledge, morphology and heuris-
tics. We demonstrate this approach on an
English-to-Pashto translation task by com-
bining the alignments obtained from syn-
tactic reordering, stemming, and partial
words. The combined alignment outper-
forms the baseline alignment, with signif-
icantly higher F-scores and better transla-
tion performance.
1 Introduction
Word alignment usually serves as the starting
point and foundation for a statistical machine
translation (SMT) system. It has received a signif-
icant amount of research over the years, notably in
(Brown et al, 1993; Ittycheriah and Roukos, 2005;
Fraser and Marcu, 2007; Hermjakob, 2009). They
all focused on the improvement of word alignment
models. In this work, we leverage existing align-
ers and generate multiple sets of word alignments
based on complementary information, then com-
bine them to get the final alignment for phrase
training. The resource required for this approach
is little, compared to what is needed to build a rea-
sonable discriminative alignment model, for ex-
ample. This makes the approach especially ap-
pealing for SMT on low-resource languages.
Most of the research on alignment combination
in the past has focused on how to combine the
alignments from two different directions, source-
to-target and target-to-source. Usually people start
from the intersection of two sets of alignments,
and gradually add links in the union based on
certain heuristics, as in (Koehn et al, 2003), to
achieve a better balance compared to using either
intersection (high precision) or union (high recall).
In (Ayan and Dorr, 2006) a maximum entropy ap-
proach was proposed to combine multiple align-
ments based on a set of linguistic and alignment
features. A different approach was presented in
(Deng and Zhou, 2009), which again concentrated
on the combination of two sets of alignments, but
with a different criterion. It tries to maximize the
number of phrases that can be extracted in the
combined alignments. A greedy search method
was utilized and it achieved higher translation per-
formance than the baseline.
More recently, an alignment selection approach
was proposed in (Huang, 2009), which com-
putes confidence scores for each link and prunes
the links from multiple sets of alignments using
a hand-picked threshold. The alignments used
in that work were generated from different align-
ers (HMM, block model, and maximum entropy
model). In this work, we use soft voting with
weighted confidence scores, where the weights
can be tuned with a specific objective function.
There is no need for a pre-determined threshold
as used in (Huang, 2009). Also, we utilize var-
ious knowledge sources to enrich the alignments
instead of using different aligners. Our strategy is
to diversify and then combine in order to catch any
complementary information captured in the word
alignments for low-resource languages.
The rest of the paper is organized as follows.
22
We present three different sets of alignments in
Section 2 for an English-to-Pashto MT task. In
Section 3, we propose the alignment combination
algorithm. The experimental results are reported
in Section 4. We conclude the paper in Section 5.
2 Diversified Word Alignments
We take an English-to-Pashto MT task as an exam-
ple and create three sets of additional alignments
on top of the baseline alignment.
2.1 Syntactic Reordering
Pashto is a subject-object-verb (SOV) language,
which puts verbs after objects. People have pro-
posed different syntactic rules to pre-reorder SOV
languages, either based on a constituent parse tree
(Dra?bek and Yarowsky, 2004; Wang et al, 2007)
or dependency parse tree (Xu et al, 2009). In
this work, we apply syntactic reordering for verb
phrases (VP) based on the English constituent
parse. The VP-based reordering rule we apply in
the work is:
? V P (V B?, ?) ? V P (?, V B?)
where V B? represents V B, V BD, V BG, V BN ,
V BP and V BZ .
In Figure 1, we show the reference alignment
between an English sentence and the correspond-
ing Pashto translation, where E is the original En-
glish sentence, P is the Pashto sentence (in ro-
manized text), and E? is the English sentence after
reordering. As we can see, after the VP-based re-
ordering, the alignment between the two sentences
becomes monotone, which makes it easier for the
aligner to get the alignment correct. During the
reordering of English sentences, we store the in-
dex changes for the English words. After getting
the alignment trained on the reordered English and
original Pashto sentence pairs, we map the English
words back to the original order, along with the
learned alignment links. In this way, the align-
ment is ready to be combined with the baseline
alignment and any other alternatives.
2.2 Stemming
Pashto is one of the morphologically rich lan-
guages. In addition to the linguistic knowledge ap-
plied in the syntactic reordering described above,
we also utilize morphological analysis by applying
stemming on both the English and Pashto sides.
For English, we use Porter stemming (Porter,
                          
                                        S                                                                                                 
 
 
                          S           CC            S 
  
            NP              VP            NP              VP 
 
            PRP  VBP        NP                  VBP        NP        ADVP 
 
                      PRP$         NNS                     PRP       RB 
 
      E:    they  are   your employees and you   know    them      well 
 
 
      P:  hQvy  stAsO   kArvAl   dy    Av  tAsO   hQvy    smh      pOZnB  
 
 
      E?: they  your  employees  are   and  you   them    well      know 
Figure 1: Alignment before/after VP-based re-
ordering.
1980), a widely applied algorithm to remove the
common morphological and inflexional endings
from words in English. For Pashto, we utilize
a morphological decompostion algorithm that has
been shown to be effective for Arabic speech
recognition (Xiang et al, 2006). We start from a
fixed set of affixes with 8 prefixes and 21 suffixes.
The prefixes and suffixes are stripped off from
the Pashto words under the two constraints:(1)
Longest matched affixes first; (2) Remaining stem
must be at least two characters long.
2.3 Partial Word
For low-resource languages, we usually suffer
from the data sparsity issue. Recently, a simple
method was presented in (Chiang et al, 2009),
which keeps partial English and Urdu words in the
training data for alignment training. This is similar
to the stemming method, but is more heuristics-
based, and does not rely on a set of available af-
fixes. With the same motivation, we keep the first
4 characters of each English and Pashto word to
generate one more alternative for the word align-
ment.
3 Confidence-Based Alignment
Combination
Now we describe the algorithm to combine mul-
tiple sets of word alignments based on weighted
confidence scores. Suppose aijk is an alignment
link in the i-th set of alignments between the j-th
source word and k-th target word in sentence pair
(S,T ). Similar to (Huang, 2009), we define the
confidence of aijk as
c(aijk|S, T ) =
?
qs2t(aijk|S, T )qt2s(aijk|T, S),
(1)
23
where the source-to-target link posterior probabil-
ity
qs2t(aijk|S, T ) =
pi(tk|sj)
?K
k?=1 pi(tk? |sj)
, (2)
and the target-to-source link posterior probability
qt2s(aijk|T, S) is defined similarly. pi(tk|sj) is
the lexical translation probability between source
word sj and target word tk in the i-th set of align-
ments.
Our alignment combination algorithm is as fol-
lows.
1. Each candidate link ajk gets soft votes from
N sets of alignments via weighted confidence
scores:
v(ajk|S, T ) =
N
?
i=1
wi ? c(aijk|S, T ), (3)
where the weight wi for each set of alignment
can be optimized under various criteria. In
this work, we tune it on a hand-aligned de-
velopment set to maximize the alignment F-
score.
2. All candidates are sorted by soft votes in de-
scending order and evaluated sequentially. A
candidate link ajk is included if one of the
following is true:
? Neither sj nor tk is aligned so far;
? sj is not aligned and its left or right
neighboring word is aligned to tk so far;
? tk is not aligned and its left or right
neighboring word is aligned to sj so far.
3. Repeat scanning all candidate links until no
more links can be added.
In this way, those alignment links with higher
confidence scores have higher priority to be in-
cluded in the combined alignment.
4 Experiments
4.1 Baseline
Our training data contains around 70K English-
Pashto sentence pairs released under the DARPA
TRANSTAC project, with about 900K words on
the English side. The baseline is a phrase-based
MT system similar to (Koehn et al, 2003). We
use GIZA++ (Och and Ney, 2000) to generate
the baseline alignment for each direction and then
apply grow-diagonal-final (gdf). The decoding
weights are optimized with minimum error rate
training (MERT) (Och, 2003) to maximize BLEU
scores (Papineni et al, 2002). There are 2028 sen-
tences in the tuning set and 1019 sentences in the
test set, both with one reference. We use another
150 sentence pairs as a heldout hand-aligned set
to measure the word alignment quality. The three
sets of alignments described in Section 2 are gen-
erated on the same training data separately with
GIZA++ and enhanced by gdf as for the baseline
alignment. The English parse tree used for the
syntactic reordering was produced by a maximum
entropy based parser (Ratnaparkhi, 1997).
4.2 Improvement in Word Alignment
In Table 1 we show the precision, recall and F-
score of each set of word alignments for the 150-
sentence set. Using partial word provides the high-
est F-score among all individual alignments. The
F-score is 5% higher than for the baseline align-
ment. The VP-based reordering itself does not im-
prove the F-score, which could be due to the parse
errors on the conversational training data. We ex-
periment with three options (c0, c1, c2) when com-
bining the baseline and reordering-based align-
ments. In c0, the weights wi and confidence scores
c(aijk|S, T ) in Eq. (3) are all set to 1. In c1,
we set confidence scores to 1, while tuning the
weights with hill climbing to maximize the F-
score on a hand-aligned tuning set. In c2, we com-
pute the confidence scores as in Eq. (1) and tune
the weights as in c1. The numbers in Table 1 show
the effectiveness of having both weights and con-
fidence scores during the combination.
Similarly, we combine the baseline with each
of the other sets of alignments using c2. They
all result in significantly higher F-scores. We
also generate alignments on VP-reordered partial
words (X in Table 1) and compared B + X and
B + V + P . The better results with B + V + P
show the benefit of keeping the alignments as di-
versified as possible before the combination. Fi-
nally, we compare the proposed alignment combi-
nation c2 with the heuristics-based method (gdf),
where the latter starts from the intersection of all 4
sets of alignments and then applies grow-diagonal-
final (Koehn et al, 2003) based on the links in
the union. The proposed combination approach on
B + V + S + P results in close to 7% higher F-
scores than the baseline and also 2% higher than
24
gdf. We also notice that its higher F-score is
mainly due to the higher precision, which should
result from the consideration of confidence scores.
Alignment Comb P R F
Baseline 0.6923 0.6414 0.6659
V 0.6934 0.6388 0.6650
S 0.7376 0.6495 0.6907
P 0.7665 0.6643 0.7118
X 0.7615 0.6641 0.7095
B+V c0 0.7639 0.6312 0.6913
B+V c1 0.7645 0.6373 0.6951
B+V c2 0.7895 0.6505 0.7133
B+S c2 0.7942 0.6553 0.7181
B+P c2 0.8006 0.6612 0.7242
B+X c2 0.7827 0.6670 0.7202
B+V+P c2 0.7912 0.6755 0.7288
B+V+S+P gdf 0.7238 0.7042 0.7138
B+V+S+P c2 0.7906 0.6852 0.7342
Table 1: Alignment precision, recall and F-score
(B: baseline; V: VP-based reordering; S: stem-
ming; P: partial word; X: VP-reordered partial
word).
4.3 Improvement in MT Performance
In Table 2, we show the corresponding BLEU
scores on the test set for the systems built on each
set of word alignment in Table 1. Similar to the
observation from Table 1, c2 outperforms c0 and
c1, and B + V + S + P with c2 outperforms
B + V + S + P with gdf. We also ran one ex-
periment in which we concatenated all 4 sets of
alignments into one big set (shown as cat). Over-
all, the BLEU score with confidence-based com-
bination was increased by 1 point compared to the
baseline, 0.6 compared to gdf, and 0.7 compared
to cat. All results are statistically significant with
p < 0.05 using the sign-test described in (Collins
et al, 2005).
5 Conclusions
In this work, we have presented a word alignment
combination method that improves both the align-
ment quality and the translation performance. We
generated multiple sets of diversified alignments
based on linguistics, morphology, and heuris-
tics, and demonstrated the effectiveness of com-
bination on the English-to-Pashto translation task.
We showed that the combined alignment signif-
icantly outperforms the baseline alignment with
Alignment Comb Links Phrase BLEU
Baseline 963K 565K 12.67
V 965K 624K 12.82
S 915K 692K 13.04
P 906K 716K 13.30
X 911K 689K 13.00
B+V c0 870K 890K 13.20
B+V c1 865K 899K 13.32
B+V c2 874K 879K 13.60
B+S c2 864K 948K 13.41
B+P c2 863K 942K 13.40
B+X c2 871K 905K 13.37
B+V+P c2 880K 914K 13.60
B+V+S+P cat 3749K 1258K 13.01
B+V+S+P gdf 1021K 653K 13.14
B+V+S+P c2 907K 771K 13.73
Table 2: Improvement in BLEU scores (B: base-
line; V: VP-based reordering; S: stemming; P: par-
tial word; X: VP-reordered partial word).
both higher F-score and higher BLEU score. The
combination approach itself is not limited to any
specific alignment. It provides a general frame-
work that can take advantage of as many align-
ments as possible, which could differ in prepro-
cessing, alignment modeling, or any other aspect.
Acknowledgments
This work was supported by the DARPA
TRANSTAC program. We would like to thank
Upendra Chaudhari, Sameer Maskey and Xiao-
qiang Luo for providing useful resources and the
anonymous reviewers for their constructive com-
ments.
References
Necip Fazil Ayan and Bonnie J. Dorr. 2006. A max-
imum entropy approach to combining word align-
ments. In Proc. HLT/NAACL, June.
Peter Brown, Vincent Della Pietra, Stephen Della
Pietra, and Robert Mercer. 1993. The mathematics
of statistical machine translation: parameter estima-
tion. Computational Linguistics, 19(2):263?311.
David Chiang, Kevin Knight, Samad Echihabi, et al
2009. Isi/language weaver nist 2009 systems. In
Presentation at NIST MT 2009 Workshop, August.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proc. of ACL, pages 531?540.
25
Yonggang Deng and Bowen Zhou. 2009. Optimizing
word alignment combination for phrase table train-
ing. In Proc. ACL, pages 229?232, August.
Elliott Franco Dra?bek and David Yarowsky. 2004. Im-
proving bitext word alignments via syntax-based re-
ordering of english. In Proc. ACL.
Alexander Fraser and Daniel Marcu. 2007. Getting the
structure right for word alignment: Leaf. In Proc. of
EMNLP, pages 51?60, June.
Ulf Hermjakob. 2009. Improved word alignment with
statistics and linguistic heuristics. In Proc. EMNLP,
pages 229?237, August.
Fei Huang. 2009. Confidence measure for word align-
ment. In Proc. ACL, pages 932?940, August.
Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for arabic-english ma-
chine translation. In Proc. of HLT/EMNLP, pages
89?96, October.
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proc.
NAACL/HLT.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proc. of ACL, pages
440?447, Hong Kong, China, October.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proc. of ACL,
pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proc. of ACL, pages
311?318.
Martin Porter. 1980. An algorithm for suffix stripping.
In Program, volume 14, pages 130?137.
Adwait Ratnaparkhi. 1997. A linear observed time sta-
tistical parser based on maximum entropy models.
In Proc. of EMNLP, pages 1?10.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statistical
machine translation. In Proc. EMNLP, pages 737?
745.
Bing Xiang, Kham Nguyen, Long Nguyen, Richard
Schwartz, and John Makhoul. 2006. Morphological
decomposition for arabic broadcast news transcrip-
tion. In Proc. ICASSP.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
smt for subject-object-verb languages. In Proc.
NAACL/HLT, pages 245?253, June.
26
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822?831,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Enlisting the Ghost: Modeling Empty Categories for Machine Translation
Bing Xiang
IBM T. J. Watson Research Center
1101 Kitchawan Rd
Yorktown Heights, NY 10598
bxiang@us.ibm.com
Xiaoqiang Luo *
Google Inc.
111 8th Ave
New York, NY 10011
xql@google.com
Bowen Zhou
IBM T. J. Watson Research Center
1101 Kitchawan Rd
Yorktown Heights, NY 10598
zhou@us.ibm.com
Abstract
Empty categories (EC) are artificial ele-
ments in Penn Treebanks motivated by the
government-binding (GB) theory to ex-
plain certain language phenomena such as
pro-drop. ECs are ubiquitous in languages
like Chinese, but they are tacitly ignored
in most machine translation (MT) work
because of their elusive nature. In this
paper we present a comprehensive treat-
ment of ECs by first recovering them with
a structured MaxEnt model with a rich
set of syntactic and lexical features, and
then incorporating the predicted ECs into
a Chinese-to-English machine translation
task through multiple approaches, includ-
ing the extraction of EC-specific sparse
features. We show that the recovered
empty categories not only improve the
word alignment quality, but also lead to
significant improvements in a large-scale
state-of-the-art syntactic MT system.
1 Introduction
One of the key challenges in statistical machine
translation (SMT) is to effectively model inher-
ent differences between the source and the target
language. Take the Chinese-English SMT as an
example: it is non-trivial to produce correct pro-
nouns on the target side when the source-side pro-
noun is missing. In addition, the pro-drop prob-
lem can also degrade the word alignment qual-
ity in the training data. A sentence pair observed
in the real data is shown in Figure 1 along with
the word alignment obtained from an automatic
word aligner, where the English subject pronoun
* This work was done when the author was with IBM.
?that? is missing on the Chinese side. Conse-
quently, ?that? is incorrectly aligned to the second
to the last Chinese word ?De?, due to their high
co-occurrence frequency in the training data. If
the dropped pronoun were recovered, ?that? would
have been aligned with the dropped-pro (cf. Fig-
ure 3), which is a much more sensible alignment.
Figure 1: Example of incorrect word alignment
due to missing pronouns on the Chinese side.
In order to account for certain language phe-
nomena such as pro-drop and wh-movement, a set
of special tokens, called empty categories (EC),
are used in Penn Treebanks (Marcus et al, 1993;
Bies and Maamouri, 2003; Xue et al, 2005). Since
empty categories do not exist in the surface form
of a language, they are often deemed elusive and
recovering ECs is even figuratively called ?chas-
ing the ghost? (Yang and Xue, 2010).
In this work we demonstrate that, with the avail-
ability of large-scale EC annotations, it is feasi-
ble to predict and recover ECs with high accu-
racy. More importantly, with various approaches
of modeling the recovered ECs in SMT, we are
able to achieve significant improvements1.
The contributions of this paper include the fol-
lowing:
? Propose a novel structured approach to EC
prediction, including the exact word-level lo-
1Hence ?Enlisting the ghost? in the title of this paper.
822
cation and EC labels. Our results are sig-
nificantly higher in accuracy than that of the
state-of-the-art;
? Measure the effect of ECs on automatic word
alignment for machine translation after inte-
grating recovered ECs into the MT data;
? Design EC-specific features for phrases and
syntactic tree-to-string rules in translation
grammar;
? Show significant improvement on top of the
state-of-the-art large-scale hierarchical and
syntactic machine translation systems.
The rest of the paper is organized as follows. In
Section 2, we present a structured approach to EC
prediction. In Section 3, we describe the integra-
tion of Chinese ECs in MT. The experimental re-
sults for both EC prediction and SMT are reported
in Section 4. A survey on the related work is con-
ducted in Section 5, and Section 6 summarizes the
work and introduces some future work.
2 Chinese Empty Category Prediction
The empty categories in the Chinese Treebank
(CTB) include trace markers for A?- and A-
movement, dropped pronoun, big PRO etc. A
complete list of categories used in CTB is shown
in Table 1 along with their intended usages. Read-
ers are referred to the documentation (Xue et al,
2005) of CTB for detailed discussions about the
characterization of empty categories.
EC Meaning
*T* trace of A?-movement
* trace of A-movement
*PRO* big PRO in control structures
*pro* pro-drop
*OP* operator in relative clauses
*RNR* for right node raising
Table 1: List of empty categories in the CTB.
In this section, we tackle the problem of recov-
ering Chinese ECs. The problem has been studied
before in the literature. For instance, Yang and
Xue (2010) attempted to predict the existence of
an EC before a word; Luo and Zhao (2011) pre-
dicted ECs on parse trees, but the position infor-
mation of some ECs is partially lost in their repre-
sentation. Furthermore, Luo and Zhao (2011) con-
ducted experiments on gold parse trees only. In
our opinion, recovering ECs from machine parse
trees is more meaningful since that is what one
would encounter when developing a downstream
application such as machine translation. In this
paper, we aim to have a more comprehensive treat-
ment of the problem: all EC types along with
their locations are predicted, and we will report the
results on both human parse trees and machine-
generated parse trees.
2.1 Representation of Empty Categories
Our effort of recovering ECs is a two-step process:
first, at training time, ECs in the Chinese Treebank
are moved and preserved in the portion of the tree
structures pertaining to surface words only. Origi-
nal ECs and their subtrees are then deleted without
loss of information; second, a model is trained on
transformed trees to predict and recover ECs.
Empty categories heavily depend on syntac-
tic tree structure. For this reason, we choose to
project them onto a parse tree node. To facili-
tate presentation, we first distinguish a solid vs.
an empty non-terminal node. A non-terminal node
is solid if and only if it contains at least one child
node that spans one or more surface words (as op-
posed to an EC); accordingly, an empty node is a
non-terminal node that spans only ECs. In the left
half of Figure 2, the NP node that is the immediate
child of IP has only one child node spanning an
EC ? (-NONE- *pro*), and is thus an empty
node; while all other non-terminal nodes have at
least one surface word as their child and are thus
all solid nodes.
We decide to attach an EC to its lowest solid
ancestor node. That is, the EC is moved up to the
first solid node in the syntactic tree. After ECs
are attached, all empty nodes and ECs are deleted
from the tree. In order to uniquely recover ECs,
we also need to encode the position information.
To this end, the relative child index of an EC is
affixed to the EC tag. Take the NP node spanning
the *pro* in Figure 2 as an example, the *pro*
is moved to the lowest solid ancestor, IP node,
and its position is encoded by @1 since the deleted
NP is the second child of the IP node (we use 0-
based indices). With this transformation, we are
able to recover not only the position of an EC, but
its type as well. A special tag NULL is attached
to non-terminal nodes without EC. Since an EC is
introduced to express the structure of a sentence,
it is a good practice to associate it with the syn-
823
Figure 2: Example of tree transformation on training data to encode an empty category and its position
information.
tactic tree, as opposed to simply attaching it to a
neighboring word, as was done in (Yang and Xue,
2010). We believe this is one of the reasons why
our model has better accuracy than that of (Yang
and Xue, 2010) (cf. Table 7).
In summary, a projected tag consists of an EC
type (such as *pro*) and the EC?s position in-
formation. The problem of predicting ECs is then
cast into predicting an EC tag at each non-terminal
node. Notice that the input to such a predictor is
a syntactic tree without ECs, e.g., the parse tree
on the right hand of Figure 2 without the EC tag
*pro*@1 is such an example.
2.2 A Structured Empty Category Model
We propose a structured MaxEnt model for pre-
dicting ECs. Specially, given a syntactic tree, T ,
whose ECs have been projected onto solid nodes
with the procedure described in Section 2.1, we
traverse it in post-order (i.e., child nodes are vis-
ited recursively first before the current node is vis-
ited). Let T = t1t2 ? ? ? tn be the sequence of
nodes produced by the post-order traversal, and
ei(i = 1, 2, ? ? ? , n) be the EC tag associated with
ti. The probabilistic model is then:
P (en1 |T ) =
n?
i=1
P (ei|T, ei?11 )
=
n?
i=1
exp
(?
k ?kfk(ei?11 , T, ei)
)
Z(ei?11 , T )
(1)
Eq. (1) is the familiar log linear (or MaxEnt)
model, where fk(ei?11 , T, ei) is the feature func-
tion and
Z(ei?11 , T ) =
?
e?E exp
(?
k ?kfk(ei?11 , T, e)
)
is the normalization factor. E is the set of ECs to be
predicted. In the CTB 7.0 processed by the proce-
dure in Section 2.1, the set consists of 32 EC tags
plus a special NULL symbol, obtained by modulat-
ing the list of ECs in Table 1 with their positions
(e.g., *pro*@1 in Figure 2).
Once the model is chosen, the next step is to de-
cide a set of features {fk(ei?11 , T, ei)} to be used
in the model. One advantage of having the rep-
resentation in Section 2.1 is that it is very easy to
compute features from tree structures. Indeed, all
features used in our system are computed from the
syntactic trees, including lexical features.
There are 3 categories of features used in the
model: (1) tree label features; (2) lexical features;
(3) EC features, and we list them in Table 2. In
the feature description column, all node positions
(e.g., ?left?, ?right?) are relative to the current
node being predicted.
Feature 1 to 10 are computed directly from
parse trees, and are straightforward. We include
up to 2 siblings when computing feature 9 and 10.
Feature 11 to 17 are lexical features. Note that we
use words at the edge of the current node: fea-
ture 11 and 12 are words at the internal boundary
of the current node, while feature 13 and 14 are
the immediately neighboring word external to the
current node. Feature 15 and 17 are from head
word information of the current node and the par-
ent node. Feature 18 and 19 are computed from
predicted ECs in the past ? that?s why the model
in Eq. (1) conditions on ei?11 .
Besides the features presented in Table 2, we
also use conjunction features between the current
node label with the parent node label; the cur-
rent node label with features computed from child
nodes; the current node label with features from
left and sibling nodes; the current node label with
lexical features.
824
No. Tree Label Features
1 current node label
2 parent node label
3 grand-parent node label
4 left-most child label or POS tag
5 right-most child label or POS tag
6 label or POS tag of the head child
7 the number of child nodes
8 one level CFG rule
9 left-sibling label or POS tag
10 right-sibling label or POS tag
Lexical Features
11 left-most word under the current node
12 right-most word under the current node
13 word immediately left to the span of the
current node
14 word immediately right to the span of the
current node
15 head word of the current node
16 head word of the parent node
17 is the current node head child of its parent?
EC Features
18 predicted EC of the left sibling
19 the set of predicted ECs of child nodes
Table 2: List of features.
3 Integrating Empty Categories in
Machine Translation
In this section, we explore multiple approaches of
utilizing recovered ECs in machine translation.
3.1 Explicit Recovery of ECs in MT
We conducted some initial error analysis on our
MT system output and found that most of the er-
rors that are related to ECs are due to the missing
*pro* and *PRO*. This is also consistent with
the findings in (Chung and Gildea, 2010). One of
the other frequent ECs, *OP*, appears in the Chi-
nese relative clauses, which usually have a Chi-
nese word ?De? aligned to the target side ?that?
or ?which?. And the trace, *T*, exists in both
Chinese and English sides. For MT we want to fo-
cus on the places where there exist mismatches be-
tween the source and target languages. A straight-
forward way of utilizing the recovered *pro* and
*PRO* is to pre-process the MT training and test
data by inserting ECs into the original source text
(i.e. Chinese in this case). As mentioned in the
previous section, the output of our EC predictor
is a new parse tree with the labels and positions
encoded in the tags. Based on the positional in-
formation in the tags, we can move the predicted
ECs down to the surface level and insert them be-
tween original source words. The same prediction
and ?pull-down? procedure can be conducted con-
sistently cross the MT training and test data.
3.2 Grammar Extraction on Augmented
Data
With the pre-processed MT training corpus, an un-
supervised word aligner, such as GIZA++, can be
used to generate automatic word alignment, as the
first step of a system training pipeline. The ef-
fect of inserting ECs is two-fold: first, it can im-
pact the automatic word alignment since now it al-
lows the target-side words, especially the function
words, to align to the inserted ECs and fix some
errors in the original word alignment; second, new
phrases and rules can be extracted from the pre-
processed training data. For example, for a hier-
archical MT system, some phrase pairs and Hiero
(Chiang, 2005) rules can be extracted with recov-
ered *pro* and *PRO* at the Chinese side.
In this work we also take advantages of the aug-
mented Chinese parse trees (with ECs projected
to the surface) and extract tree-to-string grammar
(Liu et al, 2006) for a tree-to-string MT system.
Due to the recovered ECs in the source parse
trees, the tree-to-string grammar extracted from
such trees can be more discriminative, with an in-
creased capability of distinguishing different con-
text. An example of an augmented Chinese parse
tree aligned to an English string is shown in Figure
3, in which the incorrect alignment in Figure 1 is
fixed. A few examples of the extracted Hiero rules
and tree-to-string rules are also listed, which we
would not have been able to extract from the orig-
inal incorrect word alignment when the *pro*
was missing.
3.3 Soft Recovery: EC-Specific Sparse
Features
Recovered ECs are often good indicators of what
hypothesis should be chosen during decoding. In
addition to the augmented syntax-based grammar,
we propose sparse features as a soft constraint to
boost the performance. For each phrase pair, Hi-
ero rule or tree-to-string rule in the MT system,
a binary feature fk fires if there exists a *pro*
on the source side and it aligns to one of its most
frequently aligned target words found in the train-
ing corpus. We also fire another feature if *pro*
825
Figure 3: Fixed word alignment and examples of
extracted Hiero rules and tree-to-string rules.
aligns to any other target words so the model can
choose to penalize them based on a tuning set.
Similar features can fire for *PRO*. The feature
weights can be tuned on a tuning set in a log-linear
model along with other usual features/costs, in-
cluding language model scores, bi-direction trans-
lation probabilities, etc. The motivation for such
sparse features is to reward those phrase pairs
and rules that have highly confident lexical pairs
specifically related to ECs, and penalize those who
don?t have such lexical pairs.
Table 3 listed some of the most frequent English
words aligned to *pro* or *PRO* in a Chinese-
English parallel corpus with 2M sentence pairs.
Their co-occurrence counts and the lexical trans-
lation probabilities are also shown in the table. In
total we use 15 sparse features for frequent lexical
pairs, including 13 for *pro* and 2 for *PRO*,
and two more features for any other target words
that align to *pro* or *PRO*.
Source Target Counts P (t|s)
*pro* the 93100 0.11
*pro* to 86965 0.10
*pro* it 45423 0.05
*pro* in 36129 0.04
*pro* we 24509 0.03
*pro* which 17259 0.02
*PRO* to 195464 0.32
*PRO* for 31200 0.05
Table 3: Example of frequent word pairs used for
sparse features.
4 Experimental Results
4.1 Empty Category Prediction
We use Chinese Treebank (CTB) v7.0 to train and
test the EC prediction model. We partition the
data into training, development and test sets. The
training set includes 32925 sentences from CTB
files 0001-0325, 0400-0454, 0500-0542, 0600-
0840, 0590-0596, 1001-1120, 2000-3000, cctv,
cnn, msnbc, and phoenix 00-06. The development
set has 3033 sentences, from files 0549-0554,
0900-0931, 1136-1151, 3076-3145, and phoenix
10-11. The test set contains 3297 sentences, from
files 0543-0548, 0841-0885, 1121-1135, 3001-
3075, and phoenix 07-09.
To measure the accuracy of EC prediction, we
project the predicted tags from the upper level
nodes in the parse trees down to the surface level
based on the position information encoded in the
tags. The position index for each inserted EC,
counted at the surface level, is attached for scor-
ing purpose. The same operation is applied on
both the reference and the system output trees.
Such projection is necessary, especially when the
two trees differ in structure (e.g. gold trees vs.
machine-generated trees). We compute the pre-
cision, recall and F1 scores for each EC on the
test set, and collect their counts in the reference
and system output. The results are shown in Ta-
ble 4, where the LDC gold parse trees are used to
extract syntactic features for the model. The first
row in the table shows the accuracy for the places
where no EC should be inserted. The predictor
achieves 99.5% F1 score for this category, with
limited number of missing or false positives. The
F1 scores for majority of the ECs are above 70%,
except for ?*?, which is relatively rare in the data.
For the two categories that are interesting to MT,
*pro* and *PRO*, the predictor achieves 74.3%
and 81.5% in F1 scores, respectively.
The results reported above are based on the
LDC gold parse trees. To apply the EC predic-
tion to NLP applications, such as MT, it is impos-
sible to always rely on the gold trees due to its
limited availability. We parse our test set with a
maximum entropy based statistical parser (Ratna-
parkhi, 1997) first. The parser accuracy is around
84% on the test set. Then we extract features based
on the system-generated parse trees, and decode
with the previously trained model. The results are
shown in Table 5. Compared to those in Table 4,
the F1 scores dropped by different degrees for dif-
826
Tag Ref Sys P R F1
NULL 75159 75508 99.3 99.7 99.5
*pro* 1692 1442 80.8 68.9 74.3
*PRO* 1410 1282 85.6 77.8 81.5
*T* 1851 1845 82.8 82.5 82.7
*OP* 1721 1853 90.9 97.9 94.2
*RNR* 51 39 87.2 66.7 75.6
* 156 96 63.5 39.1 48.4
Table 4: Prediction accuracy with gold parse trees,
where NULL represents the cases where no ECs
should be produced.
ferent types. Such performance drop is expected
since the system relies heavily on syntactic struc-
ture, and parsing errors create an inherent mis-
matching condition between the training and test-
ing time. The smallest drop among all types is on
NULL, at about 1.6%. The largest drop occurs for
*OP*, at 27.1%, largely due to the parsing errors
on the CP nodes. The F1 scores for *pro* and
*PRO* when using system-generated parse trees
are between 50% to 60%.
Tag Precision Recall F1
NULL 97.6 98.2 97.9
*pro* 51.1 50.1 50.6
*PRO* 66.4 50.5 57.3
*T* 68.2 59.9 63.8
*OP* 66.8 67.3 67.1
*RNR* 70.0 54.9 61.5
* 60.9 35.9 45.2
Table 5: Prediction accuracy with system-
generated parse trees.
To show the effect of ECs other than *pro*
and *PRO*, we remove all ECs in the training data
except *pro* and *PRO*. So the model only
predicts NULL, *pro* or *PRO*. The results on
the test set are listed in Table 6. There is 0.8% and
0.5% increase on NULL and *pro*, respectively.
The F1 score for *PRO* drops by 0.2% slightly.
As mentioned earlier, for MT we focus on re-
covering *pro* and *PRO* only. The model
generating the results in Table 6 is the one we ap-
plied in our MT experiments reported later.
In order to compare to the state-of-the-art mod-
els to see where our model stands, we switch our
training, development and test data to those used
in the work of (Yang and Xue, 2010) and (Cai et
Tag Precision Recall F1
NULL 98.5 98.9 98.7
*pro* 51.0 51.1 51.1
*PRO* 66.0 50.4 57.1
Table 6: Prediction accuracy with system-
generated parse trees, modeling *pro* and
*PRO* only.
al., 2011), for the purpose of a direct comparison.
The training set includes CTB files 0081 through
0900. The development set includes files 0041 to
0080, and the test set contains files 0001-0040 and
0901-0931. We merge all empty categories into
a single type in the training data before training
our EC prediction model. To compare the perfor-
mance on system-generated parse trees, we also
train a Berkeley parser on the same training data
and parse the test set. The prediction accuracy
for such single type on the test set with gold or
system-generated parse trees is shown in Table 7,
compared to the numbers reported in (Yang and
Xue, 2010) and (Cai et al, 2011). The model we
proposed achieves 6% higher F1 score than that in
(Yang and Xue, 2010) and 2.6% higher than that in
(Cai et al, 2011), which is significant. This shows
the effectiveness of our structured approach.
Model T P R F1
(Yang and Xue, 2010) G 95.9 83.0 89.0
Structured (this work) G 96.5 93.6 95.0
(Yang and Xue, 2010) S 80.3 52.1 63.2
(Cai et al, 2011) S 74.0 61.3 67.0
Structured (this work) S 74.9 65.1 69.6
Table 7: Comparison with the previous results, us-
ing the same training and test data. T: parse trees.
G: gold parse trees. S: system-generated parse
trees. P: precision. R: recall.
4.2 MT Results
In the Chinese-to-English MT experiments, we
test two state-of-the-art MT systems. One is an re-
implementation of Hiero (Chiang, 2005), and the
other is a hybrid syntax-based tree-to-string sys-
tem (Zhao and Al-onaizan, 2008), where normal
phrase pairs and Hiero rules are used as a backoff
for tree-to-string rules.
The MT training data includes 2 million sen-
tence pairs from the parallel corpora released by
827
LDC over the years, with the data from United
Nations and Hong Kong excluded 2. The Chi-
nese text is segmented with a segmenter trained
on the CTB data using conditional random field
(CRF), followed by the longest-substring match
segmentation in a second pass. Our language
model (LM) training data consists of about 10 bil-
lion English words, which includes Gigaword and
other newswire and web data released by LDC,
as well as the English side of the parallel train-
ing corpus. We train a 6-gram LM with modi-
fied Kneser-Ney smoothing (Chen and Goodman,
1998). Our tuning set for MT contains 1275 sen-
tences from LDC2010E30. We test our system
on the NIST MT08 Newswire (691 sentences)
and Weblog (666 sentences) sets. Both tuning
and test sets have 4 sets of references for each
sentence. The MT systems are optimized with
pairwise ranking optimization (Hopkins and May,
2011) to maximize BLEU (Papineni et al, 2002).
We first predict *pro* and *PRO* with our
annotation model for all Chinese sentences in the
parallel training data, with *pro* and *PRO* in-
serted between the original Chinese words. Then
we run GIZA++ (Och and Ney, 2000) to generate
the word alignment for each direction and apply
grow-diagonal-final (Koehn et al, 2003), same as
in the baseline. We want to measure the impact on
the word alignment, which is an important step for
the system building. We append a 300-sentence
set, which we have human hand alignment avail-
able as reference, to the 2M training sentence pairs
before running GIZA++. The alignment accuracy
measured on this alignment test set, with or with-
out *pro* and *PRO* inserted before running
GIZA++, is shown in Table 8. To make a fair
comparison with the baseline alignment, any tar-
get words aligned to ECs are deemed as unaligned
during scoring. We observe 1.2% improvement on
function word related links, and almost the same
accuracy on content words. This is understand-
able since *pro* and *PRO* are mostly aligned
to the function words at the target side. The pre-
cision and recall for function words are shown in
Table 9. We can see higher accuracy in both pre-
cision and recall when ECs (*pro* and *PRO*)
are recovered in the Chinese side. Especially, the
precision is improved by 2% absolute.
2The training corpora include LDC2003E07,
LDC2003E08, LDC2005T10, LDC2006E26, LDC2006G05,
LDC2007E103, LDC2008G05, LDC2009G01, and
LDC2009G02.
System Function Content All
Baseline 51.7 69.7 65.4
+EC 52.9 69.6 65.7
Table 8: Word alignment F1 scores with or without
*pro* and *PRO*.
System Precision Recall F1
Baseline 54.1 49.5 51.7
+EC 56.0 50.1 52.9
Table 9: Word alignment accuracy for function
words only.
Next we extract phrase pairs, Hiero rules and
tree-to-string rules from the original word align-
ment and the improved word alignment, and tune
all the feature weights on the tuning set. The
weights include those for usual costs and also the
sparse features proposed in this work specifically
for ECs. We test all the systems on the MT08
Newswire and Weblog sets.
The BLEU scores from different systems are
shown in Table 10 and Table 11, respectively. We
measure the incremental effect of prediction (in-
serting *pro* and *PRO*) and sparse features.
Pre-processing of the data with ECs inserted im-
proves the BLEU scores by about 0.6 for newswire
and 0.2 to 0.3 for the weblog data, compared to
each baseline separately. On top of that, adding
sparse features helps by another 0.3 on newswire
and 0.2 to 0.4 on weblog. Overall, the Hiero
and tree-to-string systems are improved by about 1
point for newswire and 0.4 to 0.7 for weblog. The
smaller gain on the weblog data could be due to
the more difficult data to parse, which affects the
accuracy of EC prediction. All the results in Table
10 and 11 marked with ?*? are statistically signif-
icant with p < 0.05 using the sign test described
in (Collins et al, 2005), compared to the baseline
results in each table. Two MT examples are given
in Table 12, which show the effectiveness of the
recovered ECs in MT.
System MT08-nw MT08-wb
Hiero 33.99 25.40
+prediction 34.62* 25.63
+prediction+sparse 34.95* 25.80*
Table 10: BLEU scores in the Hiero system.
828
System MT08-nw MT08-wb
T2S+Hiero 34.53 25.80
+prediction 35.17* 26.08
+prediction+sparse 35.51* 26.53*
Table 11: BLEU scores in the tree-to-string system
with Hiero rules as backoff.
5 Related Work
Empty categories have been studied in recent
years for several languages, mostly in the con-
text of reference resolution and syntactic process-
ing for English, such as in (Johnson, 2002; Di-
enes and Dubey, 2003; Gabbard et al, 2006).
More recently, EC recovery for Chinese started
emerging in literature. In (Guo et al, 2007),
non-local dependencies are migrated from En-
glish to Chinese for generating proper predicate-
argument-modifier structures from surface context
free phrase structure trees. In (Zhao and Ng,
2007), a decision tree learning algorithm is pre-
sented to identify and resolve Chinese anaphoric
zero pronouns. and achieves a performance com-
parable to a heuristic rule-based approach. Similar
to the work in (Dienes and Dubey, 2003), empty
detection is formulated as a tagging problem in
(Yang and Xue, 2010), where each word in the
sentence receives a tag indicating whether there is
an EC before it. A maximum entropy model is
utilized to predict the tags, but different types of
ECs are not distinguished. In (Cai et al, 2011),
a language-independent method was proposed to
integrate the recovery of empty elements into syn-
tactic parsing. As shown in the previous section,
our model outperforms the model in (Yang and
Xue, 2010) and (Cai et al, 2011) significantly us-
ing the same training and test data. (Luo and Zhao,
2011) also tries to predict the existence of an EC
in Chinese sentences, but the ECs in the middle of
a tree constituent are lumped into a single position
and are not uniquely recoverable.
There exists only a handful of previous work on
applying ECs explicitly to machine translation so
far. One of them is the work reported in (Chung
and Gildea, 2010), where three approaches are
compared, based on either pattern matching, CRF,
or parsing. However, there is no comparison be-
tween using gold trees and automatic trees. There
also exist a few major differences on the MT
part between our work and theirs. First, in ad-
dition to the pre-processing of training data and
inserting recovered empty categories, we imple-
ment sparse features to further boost the perfor-
mance, and tune the feature weights directly to-
wards maximizing the machine translation met-
ric. Second, there is no discussion on the quality
of word alignment in (Chung and Gildea, 2010),
while we show the alignment improvement on a
hand-aligned set. Last, they use a phase-based
system trained on only 60K sentences, while we
conduct experiments on more advanced Hiero and
tree-to-string systems, trained on 2M sentences in
a much larger corpus. We directly take advantage
of the augmented parse trees in the tree-to-string
grammar, which could have larger impact on the
MT system performance.
6 Conclusions and Future Work
In this paper, we presented a novel structured ap-
proach to EC prediction, which utilizes a max-
imum entropy model with various syntactic fea-
tures and shows significantly higher accuracy than
the state-of-the-art approaches. We also applied
the predicted ECs to a large-scale Chinese-to-
English machine translation task and achieved sig-
nificant improvement over two strong MT base-
829
lines, i.e. a hierarchical phase-based system and
a tree-to-string syntax-based system. More work
remain to be done next to further take advantages
of ECs. For example, the recovered ECs can be
encoded in a forest as the input to the MT decoder
and allow the decoder to pick the best MT output
based on various features in addition to the sparse
features we proposed in this work. Many promis-
ing approaches can be explored in the future.
Acknowledgments
We would like to acknowledge the support
of DARPA under Grant HR0011-12-C-0015 for
funding part of this work. The views, opin-
ions, and/or findings contained in this arti-
cle/presentation are those of the author/presenter
and should not be interpreted as representing the
official views or policies, either expressed or im-
plied, of the Defense Advanced Research Projects
Agency or the Department of Defense.
References
Ann Bies and Mohamed Maamouri. 2003.
Penn Arabic treebank guidelines. In
http://www.ircs.upenn.edu/arabic/Jan03release/
guidelines-TB-1-28-03.pdf.
Shu Cai, David Chiang, and Yoav Goldberg. 2011.
Language-independent parsing with empty ele-
ments. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics:short papers, pages 212?216.
Stanley F. Chen and Joshua Goodman. 1998. An em-
pirical study of smoothing techniques for language
modeling. In Technical Report TR-10-98, Computer
Science Group, Harvard University.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263?270,
Ann Arbor, Michigan, June.
Tagyoung Chung and Daniel Gildea. 2010. Effects
of empty categories on machine translation. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, pages 636?
645.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Lin-
guistics, pages 531?540.
Peter Dienes and Amit Dubey. 2003. Deep syntactic
processing by combining shallow methods. In Pro-
ceedings of the 41st Annual Meeting of the Associa-
tion for Computational Linguistics.
Ryan Gabbard, Seth Kulick, and Mitchell Marcus.
2006. Fully parsing the penn treebank. In Pro-
ceedings of the Human Language Technology Con-
ference of the North American Chapter of the ACL.
Yuqing Guo, Haifeng Wang, and Josef van Genabith.
2007. Recovering non-local dependencies for Chi-
nese. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL).
Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1352?1362.
Mark Johnson. 2002. A simple pattern-matching al-
gorithm for recovering empty nodes and their an-
tecedents. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguis-
tics.
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT-NAACL, pages 48?54.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 609?616.
Xiaoqiang Luo and Bing Zhao. 2011. A statistical
tree annotator and its applications. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 1230?1238.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: The Penn Treebank. In Compu-
tational Linguistics, volume 19(2), pages 313?330.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association for Com-
putational Linguistics, pages 440?447, Hong Kong,
China, October.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311?318, Philadelphia,
PA.
Adwait Ratnaparkhi. 1997. A linear observed time sta-
tistical parser based on maximum entropy models.
In Proceedings of Second Conference on Empirical
830
Methods in Natural Language Processing, pages 1?
10.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. The Penn Chinese Treebank: Phrase
structure annotation of a large corpus. In Natural
Language Engineering, volume 11(2), pages 207?
238.
Yaqin Yang and Nianwen Xue. 2010. Chasing the
ghost: Recovering empty categories in the Chi-
nese Treebank. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics,
pages 1382?1390, Beijing, China, August.
Bing Zhao and Yaser Al-onaizan. 2008. Generaliz-
ing local and non-local word-reordering patterns for
syntax-based machine translation. In Proceedings of
the 2008 Conference on Empirical Methods in Nat-
ural Language Processing, pages 572?581.
Shanheng Zhao and Hwee Tou Ng. 2007. Identifica-
tion and resolution of Chinese zero pronouns: A ma-
chine learning approach. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL).
831
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1264?1274,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Two-Neighbor Orientation Model with Cross-Boundary Global Contexts
Hendra Setiawan, Bowen Zhou, Bing Xiang and Libin Shen
IBM T.J.Watson Research Center
1101 Kitchawan Road
Yorktown Heights, NY 10598, USA
{hendras,zhou,bxiang,lshen}@us.ibm.com
Abstract
Long distance reordering remains one of
the greatest challenges in statistical ma-
chine translation research as the key con-
textual information may well be beyond
the confine of translation units. In this
paper, we propose Two-Neighbor Orien-
tation (TNO) model that jointly models
the orientation decisions between anchors
and two neighboring multi-unit chunks
which may cross phrase or rule bound-
aries. We explicitly model the longest
span of such chunks, referred to as Max-
imal Orientation Span, to serve as a
global parameter that constrains under-
lying local decisions. We integrate our
proposed model into a state-of-the-art
string-to-dependency translation system
and demonstrate the efficacy of our pro-
posal in a large-scale Chinese-to-English
translation task. On NIST MT08 set, our
most advanced model brings around +2.0
BLEU and -1.0 TER improvement.
1 Introduction
Long distance reordering remains one of the great-
est challenges in Statistical Machine Translation
(SMT) research. The challenge stems from the
fact that an accurate reordering hinges upon the
model?s ability to make many local and global
reordering decisions accurately. Often, such
reordering decisions require contexts that span
across multiple translation units.1 Unfortunately,
previous approaches fall short in capturing such
cross-unit contextual information that could be
1We define translation units as phrases in phrase-based
SMT, and as translation rules in syntax-based SMT.
critical in reordering. Specifically, the popular dis-
tortion or lexicalized reordering models in phrase-
based SMT focus only on making good local pre-
diction (i.e. predicting the orientation of imme-
diate neighboring translation units), while transla-
tion rules in syntax-based SMT come with a strong
context-free assumption, which model only the re-
ordering within the confine of the rules. In this
paper, we argue that reordering modeling would
greatly benefit from richer cross-boundary contex-
tual information
We introduce a reordering model that incorpo-
rates such contextual information, named the Two-
Neighbor Orientation (TNO) model. We first iden-
tify anchors as regions in the source sentences
around which ambiguous reordering patterns fre-
quently occur and chunks as regions that are con-
sistent with word alignment which may span mul-
tiple translation units at decoding time. Most no-
tably, anchors and chunks in our model may not
necessarily respect the boundaries of translation
units. Then, we jointly model the orientations of
chunks that immediately precede and follow the
anchors (hence, the name ?two-neighbor?) along
with the maximal span of these chunks, to which
we refer as Maximal Orientation Span (MOS).
As we will elaborate further in next sections,
our models provide a stronger mechanism to make
more accurate global reordering decisions for the
following reasons. First of all, we consider the
orientation decisions on both sides of the anchors
simultaneously, in contrast to existing works that
only consider one-sided decisions. In this way, we
hope to upgrade the unigram formulation of exist-
ing reordering models to a higher order formula-
tion. Second of all, we capture the reordering of
chunks that may cross translation units and may
be composed of multiple units, in contrast to ex-
1264
isting works that focus on the reordering between
individual translation units. In effect, MOS acts as
a global reordering parameter that guides or con-
strains the underlying local reordering decisions.
To show the effectiveness of our model, we
integrate our TNO model into a state-of-the-
art syntax-based SMT system, which uses syn-
chronous context-free grammar (SCFG) rules to
jointly model reordering and lexical translation.
The introduction of nonterminals in the SCFG
rules provides some degree of generalization.
However as mentioned earlier, the context-free
assumption ingrained in the syntax-based for-
malism often limits the model?s ability to in-
fluence global reordering decision that involves
cross-boundary contexts. In integrating TNO, we
hope to strengthen syntax-based system?s ability
to make more accurate global reordering deci-
sions.
Our other contribution in this paper is a prac-
tical method for integrating the TNO model into
syntax-based translations. The integration is non-
trivial since the decoding of syntax-based SMT
proceeds in a bottom-up fashion, while our model
is more natural for top-down parsing, thus the
model?s full context sometimes is often available
only at the latest stage of decoding. We implement
an efficient shift-reduce algorithm that facilitates
the accumulation of partial context in a bottom-up
fashion, allowing our model to influence the trans-
lation process even in the absence of full context.
We show the efficacy of our proposal in a large-
scale Chinese-to-English translation task where
the introduction of our TNO model provides a
significant gain over a state-of-the-art string-to-
dependency SMT system (Shen et al, 2008) that
we enhance with additional state-of-the-art fea-
tures. Even though the experimental results car-
ried out in this paper employ SCFG-based SMT
systems, we would like to point out that our mod-
els is applicable to other systems including phrase-
based SMT systems.
The rest of the paper is organized as follows.
In Section 2, we introduce the formulation of our
TNO model. In Section 3, we introduce and moti-
vate the concept of Maximal Orientation Span. In
Section 4, we introduce four variants of the TNO
model with different model complexities. In Sec-
tion 5, we describe the training procedure to esti-
mate the parameters of our models. In Section 6,
we describe our shift-reduce algorithm which inte-
grates our proposed TNO model into syntax-based
SMT. In Section 7, we describe our experiments
and present our results. We wrap up with related
work in Section 8 and conclusion in Section 9.
2 Two-Neighbor Orientation Model
Given an aligned sentence pair ? = (F,E,?), let
?(?) be all possible chunks that can be extracted
from ? according to: 2
{(f j2j1/e
i2
i1) :?j1? j? j2,?i : (j, i)??, ii? i? i2 ?
?i1? i? i2,?j : (j, i)??, ji? j?j2}
Our Two-Neighbor Orientation model (TNO)
designatesA ? ?(?) as anchors and jointly mod-
els the orientation of chunks that appear immedi-
ately to the left and to the right of the anchors as
well as the identities of these chunks. We define
anchors as chunks, around which ambiguous re-
ordering patterns frequently occur. Anchors can
be learnt automatically from the training data or
identified from the linguistic analysis of the source
sentence. In our experiments, we use a simple
heuristics based on part-of-speech tags which will
be described in Section 7.
More concretely, given A ? ?(?), let a =
(f j2j1/e
i2
i1) ? A be a particular anchor. Then, let
CL(a) ? ?(?) be a?s left neighbors and let
CR(a) ? ?(?) be a?s right neighbors, iff:
?CL = (f j4j3/e
i4
i3) ? CL(a) : j4 + 1 = j1 (1)
?CR = (f j6j5/e
i6
i5) ? CR(a) : j2 + 1 = j5 (2)
Given CL(a) and CR(a), let CL = (f j4j3/ei4i3) and
CR = (f j6j5/e
i6
i5) be a particular pair of left and right
neighbors of a = (f j2j1/ei2i1). Then, the orientationof CL and CR are OL(CL, a) and OR(CR, a) re-
spectively and each may take one of the following
four orientation values (similar to (Nagata et al,
2006)):
? Monotone Adjacent (MA), if (i4 + 1) = i1
for OL and if (i2 + 1) = i5 for OR
? Reverse Adjacent (RA), if (i2 + 1) = i3 for
OL and if (i6 + 1) = i1 for OR
? Monotone Gap (MG), if (i4 + 1) < i1 for
OL and if (i2 + 1) < i5 for OR
2We represent a chunk as a source and target phrase pair
(f j2j1/ei2i1 ) where the subscript and the superscript indicate the
starting and the ending indices as such f j2j1 denotes a sourcephrase that spans from j1 to j2.
1265
Figure 1: An aligned Chinese-English sentence pair. Circles
represent alignment points. Black circle represents the an-
chor; boxes represent the anchor?s neighbors.
? Reverse Gap (RG), if (i2 + 1) < i3 for OL
and if (i6 + 1) < i1 for OR. (1)
The first clause (monotone, reverse) indicates
whether the target order of the chunks follows the
source order; the second (adjacent, gap) indicates
whether the chunks are adjacent or separated by an
intervening phrase when projected.
To be more concrete, let us consider an aligned
sentence pair in Fig. 1, which is adapted from
(Chiang, 2005). Suppose there is only one anchor,
i.e. a = (f77 /e77) which corresponds to the word
de(that). By applying Eqs. 1 and 2, we can infer
that a has three left neighbors and four right neigh-
bors, i.e. CL(a) = (f66 /e99), (f65 /e98), (f63 /e118 ) and
CR(a) = (f88 /e55), (f98 /e65), (f108 /e64), (f118 /e63)
respectively. Then, by applying Eq.
1, we can compute the orientation val-
ues of each of these neighbors, which
are OL(CL(a), a) = RG,RA,RA and
OR(CR(a), a) = RG,RA,RA,RA. As shown,
most of the neighbors have Reverse Adjacent
(RA) orientation except for the smallest left and
right neighbors (i.e. (f66 /e99) and (f88 /e55)) which
have Reverse Gap (RG) orientation.
Given the anchors together with its neighboring
chunks and their orientations, the Two-Neighbor
Orientation model takes the following form:
?
a?A
?
CL?CL(a),
CR?CR(a)
PTNO(CL, OL, CR, OR|a; ?) (2)
For conciseness, references that are clear from
context, such the reference to CL and a in
OL(CL, a), are dropped.
3 Maximal Orientation Span
As shown in Eq. 2, the TNO model has to enu-
merate all possible pairing of CL ? CL(a) and
CR ? CR(a). To make the TNO model more
tractable, we simplify the TNO model to consider
only the largest left and right neighbors, referred
to as the Maximal Orientation Span/MOS (M ).
More formally, given a = (f j2j1/ei2i1), the left andthe right MOS of a are:
ML(a) = arg max
(fj4j3 /e
i4
i3 )?CL(a)
(j4 ? j3)
MR(a) = arg max
(fj6j5 /e
i6
i5 )?CR(a)
(j6 ? j5)
Coming back to our example, the left and right
MOS of the anchor are ML(a) = (f63 /e118 ) and
MR(a) = (f118 /e63). In Fig. 1, they are denoted as
the largest boxes delineated by solid lines.
As such, we reformulate Eq. 2 into:
?
a?A
?
CL?CL(a),
CR?CR(a)
PTNO(ML, OL,MR, OR|a; ?).?CL==ML?
CR==MR
(3)
where ? returns 1 if (CL == ML ?CR == MR),
otherwise 0.
Beyond simplifying the computation, the key
benefit of modeling MOS is that it serves as a
global parameter that can guide or constrain un-
derlying local reorderings. As a case in point, let
us consider a cheating exercise where we have to
translate the Chinese sentence in Fig. 1 with the
following set of hierarchical phrases3:
Xa??Aozhou1shi2X1,Australia1 is2X1?
Xb??yu3 Beihan4X1, X1with3 North4 Korea?
Xc??you5bangjiao6, have5dipl.6 rels.?
Xd??X1de7shaoshu8 guojia9 zhi10 yi11,
one11of10the few8 countries9 that7X1?
This set of hierarchical phrases represents a trans-
lation model that has resolved all local ambiguities
(i.e. local reordering and lexical mappings) except
for the spans of the hierarchical phrases. With this
example, we want to show that accurate local de-
cisions (rather obviously) don?t always lead to ac-
curate global reordering and to demonstrate that
explicit MOS modeling can play a crucial role to
address this issue. To do so, we will again focus
on the same anchor de (that).
3We use hierarchical phrase-based translation system as a
case in point, but the merit is generalizable to other systems.
1266
d? ?X1de7shaoshu8 guojia9 zhi10 yi11?, ?one11of10the few8 countries9 that7X1?
a? ??Aozhou1shi2X1?de7shaoshu8 guojia9 zhi10 yi11?,
?one11of10the few8 countries9 that7?Australia1 is2X1??
b? ??Aozhou1shi2 ?yu3 Beihan4X1??de7shaoshu8 guojia9 zhi10 yi11?,
?one11of10the few8 countries9 that7?Australia1 is2?X1with3 North4 Korea???
c? ?d ?aAozhou1shi2 ?byu3 Beihan4 ?cyou5bangjiao6?c?b?ade7shaoshu8 guojia9 zhi10 yi11 ?d ,
?one11of10the few8 countries9 that7?Australia1 is2??have5dipl.6 rels.?with3 North4 Korea???
Table 1: Derivation of Xd ?Xa ?Xb ?Xc that leads to an incorrect translation.
a? ?Aozhou1shi2X1?, ?Australia1 is2X1?
b? ?Aozhou1shi2?yu3Beihan4X1??, ?Australia1 is2?X1with3 North4 Korea??
d? ?Aozhou1shi2?yu3Beihan4?X1de7shaoshu8 guojia9 zhi10 yi11???,
?Australia1 is2??one11of10the few8 countries9 that7X1?with3 North4 Korea??
c? ?aAozhou1shi2?byu3Beihan4 ?d ?cyou5bangjiao6?cde7shaoshu8 guojia9 zhi10 yi11 ?d ?b?a,
Australia1 is2??one11of10the few8 countries9 that7?have5dipl.6??with3 North4 Korea??
Table 2: Derivation of Xa ?Xb ?Xd ?Xc that leads to the correct translation.
As the rule?s identifier, we attach an alphabet
letter to each rule?s left hand side, as such the an-
chor de (that) appears in rule Xd. We also attach
the word indices as the superscript of the source
words and project the indices to the target words
aligned, as such ?have5? suggests that the word
?have? is aligned to the 5-th source word, i.e. you.
Note that to facilitate the projection, the rules must
come with internal word alignment in practice.
Now the indices on the target words in the rules
are different from those in Fig. 1. We will also
extensively use indices in this sense in the sub-
sequent section about decoding. In such a sense,
ML(a) = (f63 /e63) and MR(a) = (f118 /e118 ).
Given the rule set, there are three possible
derivations, i.e. Xd ?Xa ?Xb ?Xc,Xa ?Xb ?
Xd ?Xc, and Xa ?Xd ?Xb ?Xc, where ? in-
dicates that the first operand dominates the second
operand in the derivation tree. The application of
the rules would show that the first derivation will
produce an incorrect reordering while the last two
will produce the correct ones. Here, we would like
to point out that even in this simple example where
all local decisions are made accurate, this ambigu-
ity occurs and it would occur even more so in the
real translation task where local decisions may be
highly inaccurate.
Next, we will show that the MOS-related in-
formation can help to resolve this ambiguity, by
focusing more closely on the first and the second
derivations, which are detailed in Tables 1 and 2.
Particularly, we want to show that the MOS gen-
erated by the incorrect derivation does not match
the MOS learnt from Fig. 1. As shown, at the
end of the derivation, we have all the informa-
tion needed to compute the MOS (i.e. ?) which is
equivalent to that available at training time, i.e. the
source sentence, the complete translation and the
word alignment. Running the same MOS extrac-
tion procedure on both derivations would produce
the right MOS that agrees with the right MOS pre-
viously learnt from Fig. 1, i.e. (f118 /e118 ). How-
ever, that?s not the case for left MOS, which we
underline in Tables 1 and 2. As shown, the incor-
rect derivation produces a left MOS that spans six
words, i.e. (f61 /e61), while the correct derivation
produces a left MOS that spans four words, i.e.
(f63 /e63). Clearly, the MOS of the incorrect deriva-
tion doesn?t agree with the MOS we learnt from
Fig. 1, unlike the MOS of the correct translation.
This suggests that explicit MOS modeling would
provide a mechanism for resolving crucial global
reordering ambiguities that are beyond the ability
of local models.
Additionally, this illustration also shows a case
where MOS acts as a cross-boundary context
which effectively relaxes the context-free assump-
tion of hierarchical phrase-based formalism. In
Tables 1 and 2?s full derivations, we indicate rule
boundaries explicitly by indexing the angle brack-
ets, e.g. ?a indicates the beginning of rule Xa in
the derivation. As the anchor appears in Xd, we
1267
highlight its boundaries in box frames. de (that)?s
MOS respects rule boundaries if and only if all
the words come entirely from Xd?s antecedent or
?d and ?d appears outside of MOS; otherwise it
crosses the rule boundaries. As clearly shown in
Table 2, the left MOS of the correct derivation (un-
derlined) crosses the rule boundary (of Xd) since
?d appears within the MOS.
Going back to the formulation, focusing on
modeling MOS would simplify the formulation of
TNO model from Eq. 2 into:
?
a?A
PTNO(ML, OL,MR, OR|a; ?) (4)
which doesn?t require enumerating of all possible
pairs of CL and CR.
4 Model Decomposition and Variants
To make the model more tractable, we decompose
PTNO in Eq. 4 into the following four factors:
P (MR|a)? P (OR|MR, a)? P (ML|OR,MR, a)
? P (OL|ML, OR,MR, a). Subsequently, we will
refer to them as PMR , POR , PML and POL respec-
tively. Each of these factors will act as an addi-
tional feature in the log-linear framework of our
SMT system. The above decomposition follows
a generative story that starts from generating the
right neighbor first. There are other equally credi-
ble alternatives, but based on empirical results, we
settle with the above.
Next, we present four different variants of the
model (not to be confused with the four factors
above). Each variant has a different probabilistic
conditioning of the factors. We start by making
strong independence assumptions in Model 1 and
then relax them as we progress to Model 4. The
description of the models is as follow:
? Model 1. We assume PML and PMR to be
equal to 1 and POR ? P (OR|a; ?) to be in-
dependent of MR and POL ? P (OL|a; ?) to
be in independent of ML,MR and OR.
? Model 2. On top of Model 1, we
make POL dependent on POR , thus
POL?P (OL|OR, a; ?).
? Model 3. On top of Model 2, we make POR
dependent on MR and POL on MR and ML,
thus POR ? P (OR|MR, a; ?) and POL ?
P (OL|ML, OR,MR; a,?) .
? Model 4. On top of Model 3, we model PMR
and PML as multinomial distributions esti-
mated from training data.
Model 1 represents a model that focuses on
making accurate one-sided decisions, independent
of the decision on the other side. Model 2 is
designed to address the deficiency of Model 1
since Model 1 may assign non-zero probability to
improbable assignment of orientation values, e.g.
Monotone Adjacent for the left neighbor and Re-
verse Adjacent for the right neighbor. Model 2
does so by conditioning POL on OR. In Model 3,
we start incorporating MOS-related information in
predicting OL and OR. In Model 4, we explicitly
model the MOS of each anchor.
5 Training
The TNO model training consists of two differ-
ent training regimes: 1) discriminative for train-
ing POL ,POR ; and 2) generative for training PML ,
PMR . Before describing the specifics, we start by
describing the procedure to extract anchors and
their corresponding MOS from training data, from
which we collect statistics and extract features to
train the model.
For each aligned sentence pair (F,E,?) in the
training data, the training starts with the iden-
tification of the regions in the source sentences
as anchors (A). For our Chinese-English experi-
ments, we use a simple heuristic that equates as
anchors, single-word chunks whose corresponding
word class belongs to closed-word classes, bear-
ing a close resemblance to (Setiawan et al, 2007).
In total, we consider 21 part-of-speech tags; some
of which are as follow: VC (copula), DEG, DEG,
DER, DEV (de-related), PU (punctuation), AD
(adjectives) and P (prepositions).
Next we generate all possible chunks ?(?)
as previously described in Sec. 3. We then de-
fine a functionMinC(?, j1, j2) which returns the
shortest chunk that can span from j1 to j2. If
(f j2j1 /e
i2
i1) ? ?, then MinC returns (f j2j1 /ei2i1).The algorithm to extract MOS takes ? and an
anchor a = (f j2j1 /ei2i1) as input; and outputs thechunk that qualifies as MOS or none. Alg. 1
provides the algorithm to extract the right MOS;
the algorithm to extract the left MOS is identical
to Alg. 1, except that it scans for chunks to the
left of the anchor. In Alg. 1, there are two in-
termediate parameters si and ei which represent
the active search range and should initially be set
to j2 + 1 and |F | respectively. Once we obtain
a,ML(a) andMR(a), we computeOL(ML(a), a)
and OR(MR(a), a) and are ready for training.
1268
To estimate POL and POR , we train discrimi-
native classifiers that predict the orientation val-
ues and use the normalized posteriors at decoding
time as additional feature scores in SMT?s log lin-
ear framework. We train the classifiers on a rich
set of binary features ranging from lexical to part-
of-speech (POS) and to syntactic features.
Algorithm 1: Function MREx
input : a = (f j2j1 /ei2i1), si, ei: int; ?: chunks
output: (f j4j3 /ei4i3) : chunk or ?
(f j4j3 /e
i4
i3) = MinC(?, j2 + 1, ei)
if (j3 == j2 + 1 ? j4 == ei) then
? f j4j3 /e
i4
i3
else
if (j2 + 1 == ei) then
? ?
else
if (ei-2 ? si) then
?MREx(a, si, ei? 1,?)
else
m = d(si+ei)/2e
(f j4j3 /e
i4
i4) = MinC(?, j2 + 1,m)
if (j3 == j2 + 1) then
c = MREx(a,m, ei? 1,?)
if (c == ?) then
? f j4j3 /e
i4
i3
else
? c
end
else
?MREx(a, si,m? 1,?)
end
end
end
end
Suppose a = (f j2j1 /ei2i1), ML(a) = (f j4j3 /ei4i3)
and ML(a) = (f j6j5 /ei6i5), then based on the con-text?s location, the elementary features employed
in our classifiers can be categorized into:
1. anchor-related: slex (the actual word of
f j2j1 ), spos (part-of-speech (POS) tag of
slex), sparent (spos?s parent in the parse
tree), tlex (ei2i1?s actual target word)..
2. surrounding: lslex (the previous word /
f j1?1j1?1 ), rslex (the next word / f j2+1j2+1 ), lspos(lslex?s POS tag), rspos (rslex?s POS
tag), lsparent (lslex?s parent), rsparent
(rslex?s parent).
3. non-local: lanchorslex (the previous
anchor?s word) , ranchorslex (the next an-
chor?s word), lanchorspos (lanchorslex?s
POS tag), ranchorspos (ranchorslex?s
POS tag).
4. MOS-related: mosl int slex (the actual
word of f j3j3 ), mosl ext slex (the actual word
of f j3j3 ), mosl int spos (mosl int slex?sPOS tag), mosl ext spos (mosl ext spos?s
POS tag), mosr int slex (the actual word of
f j3j3 ), mosr ext slex (the actual word of f j3j3 ),
mosr int spos (mosr int slex?s POS tag),
mosr ext spos (mosr ext spos?s POS tag).
For Model 1, we train one classifier each for
POR and POL . For Model 2-4, we train four clas-
sifiers for POL for each value of OR. We use only
the MOS features for Model 3 and 4. Addition-
ally, we augment the feature set with compound
features, e.g. conjunction of the lexical of the an-
chor and the lexical of the left and the right an-
chors. Although they increase the number of fea-
tures significantly, we found that these compound
features are empirically beneficial.
We come up with > 50 types of features, which
consist of a combination of elementary and com-
pound features. In total, we generate hundreds of
millions of such features from the training data.
To keep the number features to a manageable size,
we employ the L1-regularization in training to en-
force sparse solutions, using the off-the-shelf LIB-
LINEAR toolkit (Fan et al, 2008). After training,
the number of features in our classifiers decreases
to below 5 million features for each classifier.
We train PML and PMR via the relative fre-
quency principle. To avoid the sparsity issue, we
represent ML as (mosl int spos,mosl ext spos)
and MR as (mosr int spos,mosr ext spos). We
condition PML and PMR only on spos and the ori-
entation, estimating them as follow:
P (ML|spos, OL) =
N(ML, spos, OL)
N(spos, OL)
P (MR|spos, OR) =
N(MR, spos, OR)
N(spos, OR)
where N returns the count of the events in the
training data.
1269
Target string (w/ source index) Symbol(s) read Op. Stack(s)
(1) Xc have5 dipl.6 rels. [5][6] S,S,R Xc:[5-6]
(2) Xd one11 of10 few8 countries9 [11][10] S,S,R [10-11]
that7 Xc
(3) [8][9] S,S,R,R [8-11]
(4) [7] S [8-11][7]
(5) Xc:[5,6] S Xd:[8-11][7][5,6]
(6) Xb Xd with3 North4 Korea Xd:[8-11][7][5,6] S [8-11][7][5,6]
(7) [3][4] S,S,R,R Xb:[8-11][7][3-6]
(8) Xa Australia1 is2 Xb [1][2] S,S,R [1-2]
(9) Xb:[8-11][7][3,6] S,A Xa:[1-2][8-11][7][3,6]
Table 3: The application of the shift-reduce parsing algorithm, which corresponds to Table 2?s derivation.
6 Decoding
Integrating the TNO Model into syntax-based
SMT systems is non-trivial, especially with the
MOS modeling. The method described in Sec. 3
assumes ? = (F,E,?), thus it is only applicable
at training or at the last stage of decoding. Since
many reordering decisions may have been made
at the earlier stages, the late application of TNO
model would limit the utility of the model. In this
section, we describe an algorithm that facilitates
the incremental construction of MOS and the com-
putation of TNO model on partial derivations.
The algorithm bears a close resemblance to the
shift-reduce algorithm where a stack is used to ac-
cumulate (partial) information about a, ML and
MR for each a ? A in the derivation. This al-
gorithm takes an input stream and applies either
the shift or the reduce operations starting from the
beginning until the end of the stream. The shift op-
eration advances the input stream by one symbol
and push the symbol into the stack; while the re-
duce operation applies some reduction rule to the
topmost elements of the stack. The algorithm ter-
minates at the end of the input stream where the
resulting stack will be propagated to the parent for
the later stage of decoding. In our case, the in-
put stream is the target string of the rule and the
symbol is the corresponding source index of the
elements of the target string. The reduction rule
looks at two indices and merge them if they are
adjacent (i.e. has no intervening phrase). We for-
bid the application of the reduction rule to anchors.
Table 3 shows the execution trace of the algorithm
for the derivation described in Table 2.
As shown, the algorithm starts with an empty
stack. It then projects the source index to the cor-
responding target word and then enumerates the
target string in a left to right fashion. If it finds
a target word with a source index, it applies the
shift operation, pushing the index to the stack. Un-
less the symbol corresponds to an anchor, it tries
to apply the reduce operation. Line (4) indicates
the special treatment to the anchor. If the symbol
read is a nonterminal, then we push the entire stack
that corresponds to that nonterminal. For example,
when the algorithm reads Xd at line (6), it pushes
the entire stack from line (5).
This algorithm facilitates the incremental con-
struction of MOS which may cross rule bound-
aries. For example, at the end of the application of
Xd at line (5), the current left MOS is [5-6]. How-
ever, the algorithm grows it to [3-6] after the appli-
cation of ruleXb at line (7). Furthermore, it allows
us to compute the models from partial hypothesis.
For example, at line (5), we can compute POL by
considering [5,6] as ML to be updated with [3,6]
in line (7). This way, we expect our TNO model
would play a bigger role at decoding time.
Specific to SCFG-based translation, the values
of OL and OR are identical in the partial or in
the full derivations. For example, the orientation
values of de (that)?s left neighbor is always RA.
This statement holds, even though at the end of
Section 2, we stated that de (that)?s left neigh-
bor may have other orientation values, i.e. RG
for CL(a) = (f66 /e99). The formal proof is omit-
ted, but the intuition comes from the fact that the
derivations for SCFG-based translation are sub-
set of ?(?) and that (f66 /e99) will never become
ML forMinC(CL(a), a) respectively (chunk that
spans a and CL). Consequently, for Model 1 and
Model 2, we can obtain the model score earlier in
the decoding process.
1270
7 Experiments
Our baseline systems is a state-of-the-art string-
to-dependency system (Shen et al, 2008). The
system is trained on 10 million parallel sentences
that are available to the Phase 1 of the DARPA
BOLT Chinese-English MT task. The training cor-
pora include a mixed genre of newswire, weblog,
broadcast news, broadcast conversation, discus-
sion forums and comes from various sources such
as LDC, HK Law, HK Hansard and UN data.
In total, our baseline model employs about
40 features, including four from our proposed
Two-Neighbor Orientation model. In addition to
the standard features including the rule transla-
tion probabilities, we incorporate features that are
found useful for developing a state-of-the-art base-
line, such as the provenance features (Chiang et
al., 2011). We use a large 6-gram language model,
which was trained on 10 billion English words
from multiple corpora, including the English side
of our parallel corpus plus other corpora such as
Gigaword (LDC2011T07) and Google News. We
also train a class-based language model (Chen,
2009) on two million English sentences selected
from the parallel corpus. As the backbone of
our string-to-dependency system, we train 3-gram
models for left and right dependencies and un-
igram for head using the target side of the bi-
lingual training data. To train our Two-Neighbor
Orientation model, we select a subset of 5 million
aligned sentence pairs.
For the tuning and development sets, we set
aside 1275 and 1239 sentences selected from
LDC2010E30 corpus. We tune the decoding
weights with PRO (Hopkins and May, 2011) to
maximize BLEU-TER. As for the blind test set,
we report the performance on the NIST MT08
evaluation set, which consists of 691 sentences
from newswire and 666 sentences from weblog.
We pick the weights that produce the highest de-
velopment set scores to decode the test set.
Table 4 summarizes the experimental results on
NIST MT08 newswire and weblog. In column 2,
we report the classification accuracy on a subset of
training data. Note that these numbers are for ref-
erence only and not directly comparable with each
other since the features used in these classifiers
include several gold standard information, such
as the anchors? target words, the anchors? MOS-
related features (Model 3 & 4) and the orientation
of the right MOS (Model 2-4); all of which have
Acc MT08 nw MT08 wbBLEU TER BLEU TER
S2D - 36.77 53.28 26.34 57.41
M1 72.5 37.60 52.70 27.59 56.33
M2 77.4 37.86 52.68 27.74 56.11
M3 84.5 38.02 52.42 28.22 55.82
M4 84.5 38.55 52.41 28.44 56.45
Table 4: The NIST MT08 results on newswire (nw) and we-
blog (wb) genres. S2D is the baseline string-to-dependency
system (line 1), on top of which Two-Neighbor Orientation
Model 1 to 4 are employed (line 2-5). The best TER and
BLEU results on each genre are in bold. For BLEU, higher
scores are better, while for TER, lower scores are better.
to be predicted at decoding time.
In columns 2 and 4, we report the BLEU scores,
while in columns 3 and 5, we report the TER
scores. The performance of our baseline string-
to-dependency syntax-based SMT is shown in the
first line, followed by the performance of our Two-
Neighbor Orientation model starting from Model
1 to Model 4. As shown, the empirical results
confirm our intuition that SMT can greatly benefit
from reordering model that incorporate cross-unit
contextual information.
Model 1 provides most of the gain across the
two genres of around +0.9 to +1.2 BLEU and -0.5
to -1.1 TER. Model 2 which conditions POL on
OR provides an additional +0.2 BLEU improve-
ment on BLEU score consistently across the two
genres. As shown in line 4, we see a stronger
improvement in the inclusion of MOS-related in-
formation as features in Model 3. In newswire,
Model 3 gives an additional +0.4 BLEU and -0.2
TER, while in weblog, it gives a stronger improve-
ment of an additional +0.5 BLEU and -0.3 TER.
The inclusion of explicit MOS modeling in Model
4 gives a significant BLEU score improvement of
+0.5 but no TER improvement in newswire. In
weblog, Model 4 gives a mixed results of +0.2
BLEU score improvement and a hit of +0.6 TER.
We conjecture that the weblog text has a more am-
biguous orientation span that are more challenging
to learn. In total, our TNO model gives an encour-
aging result. Our most advanced model gives sig-
nificant improvement of +1.8 BLEU/-0.8 TER in
newswire domain and +2.1 BLEU/-1.0 TER over
a strong string-to-dependency syntax-based SMT
enhanced with additional state-of-the-art features.
1271
8 Related Work
Our work intersects with existing work in many
different respects. In this section, we mainly focus
on work related to the probabilistic conditioning
of our TNO model and the MOS modeling.
Our TNO model is closely related to the Uni-
gram Orientation Model (UOM) (Tillman, 2004),
which is the de facto reordering model of phrase-
based SMT (Koehn et al, 2007). UOM views
reordering as a process of generating (b, o) in a
left-to-right fashion, where b is the current phrase
pair and o is the orientation of b with the pre-
viously generated phrase pair b?. UOM makes
strong independence assumptions and formulates
the model as P (o|b). Tillmann and Zhang (2007)
proposed a Bigram Orientation Model (BOM) to
include both phrase pairs (b and b?) into the model.
Their original intent is to model P (o, b|o?, b?), but
perhaps due to sparsity concerns, they settle with
P (o|b, b?), dropping the conditioning on the pre-
vious orientation o?. Subsequent improvements
use the P (o|b, b?) formula, for example, for in-
corporating various linguistics feature like part-of-
speech (Zens and Ney, 2006), syntactic (Chang et
al., 2009), dependency information (Bach et al,
2009) and predicate-argument structure (Xiong et
al., 2012). Our TNO model is more faithful to the
BOM?s original formulation.
Our MOS concept is also closely related to hi-
erarchical reordering model (Galley and Manning,
2008) in phrase-based decoding, which computes
o of b with respect to a multi-block unit that may
go beyond b?. They mainly use it to avoid overes-
timating ?discontiguous? orientation but fall short
in modeling the multi-block unit, perhaps due to
data sparsity issue. Our MOS is also closely re-
lated to the efforts of modeling the span of hi-
erarchical phrases in formally syntax-based SMT.
Early works reward/penalize spans that respect the
syntactic parse constituents of an input sentence
(Chiang, 2005), and (Marton and Resnik, 2008).
(Xiong et al, 2009) learn the boundaries from
parsed and aligned training data, while (Xiong et
al., 2010) learn the boundaries from aligned train-
ing data alone. Recent work couples span mod-
eling tightly with reordering decisions, either by
adding an additional feature for each hierarchical
phrase (Chiang et al, 2008; Shen et al, 2009) or
by refining the nonterminal label (Venugopal et
al., 2009; Huang et al, 2010; Zollmann and Vo-
gel, 2011). Common to this work is that the spans
modeled may not correspond to MOS, which may
be suboptimal as discussed in Sec. 3.
In equating anchors with the function word
class, our work, particularly Model 1, is closely
related to the function word-centered model of Se-
tiawan et al (2007) and Setiawan et al (2009).
However, we provide a discriminative treatment
to the model to include a richer set of features in-
cluding the MOS modeling. Our work in incorpo-
rating global context also intersects with existing
work in Preordering Model (PM), e.g. (Niehues
and Kolss, 2009; Costa-jussa` and Fonollosa, 2006;
Genzel, 2010; Visweswariah et al, 2011; Tromble
and Eisner, 2009). The goal of PM is to reorder the
input sentence F into F ? whose order is closer to
the target language order, whereas the goal of our
model is to directly reorder F into the target lan-
guage order. The crucial difference is that we have
to integrate our model into SMT decoder, which is
highly non-trivial.
9 Conclusion
We presented a novel approach to address a kind
of long-distance reordering that requires global
cross-boundary contextual information. Our ap-
proach, which we formulate as a Two-Neighbor
Orientation model, includes the joint modeling of
two orientation decisions and the modeling of the
maximal span of the reordered chunks through the
concept of Maximal Orientation Span. We de-
scribe four versions of the model and implement
an algorithm to integrate our proposed model into
a syntax-based SMT system. Empirical results
confirm our intuition that incorporating cross-
boundaries contextual information improves trans-
lation quality. In a large scale Chinese-to-English
translation task, we achieve a significant improve-
ment over a strong baseline. In the future, we hope
to continue this line of research, perhaps by learn-
ing to identify anchors automatically from training
data, incorporating a richer set of linguistics fea-
tures such as dependency structure and strength-
ening the modeling of Maximal Orientation Span.
Acknowledgements
We would like to acknowledge the support of DARPA un-
der Grant HR0011-12-C-0015 for funding part of this work.
The views, opinions, and/or findings contained in this arti-
cle/presentation are those of the author/ presenter and should
not be interpreted as representing the official views or poli-
cies, either expressed or implied, of the DARPA.
1272
References
Nguyen Bach, Qin Gao, and Stephan Vogel. 2009.
Source-side dependency tree reordering models with
subtree movements and constraints. In Proceed-
ings of the Twelfth Machine Translation Summit
(MTSummit-XII), Ottawa, Canada, August. Interna-
tional Association for Machine Translation.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D. Manning. 2009. Discriminative
reordering with Chinese grammatical relations fea-
tures. In Proceedings of the Third Workshop on Syn-
tax and Structure in Statistical Translation (SSST-3)
at NAACL HLT 2009, pages 51?59, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Stanley Chen. 2009. Shrinking exponential language
models. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 468?476, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the
2008 Conference on Empirical Methods in Natu-
ral Language Processing, pages 224?233, Honolulu,
Hawaii, October.
David Chiang, Steve DeNeefe, and Michael Pust.
2011. Two easy improvements to lexical weighting.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies, pages 455?460, Portland,
Oregon, USA, June. Association for Computational
Linguistics.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics (ACL?05), pages
263?270, Ann Arbor, Michigan, June. Association
for Computational Linguistics.
Marta R. Costa-jussa` and Jose? A. R. Fonollosa. 2006.
Statistical machine reordering. In Proceedings of
the 2006 Conference on Empirical Methods in Nat-
ural Language Processing, pages 70?76, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A library for large linear classification. Journal of
Machine Learning Research, 9:1871?1874.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 848?856, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Dmitriy Genzel. 2010. Automatically learning source-
side reordering rules for large scale machine trans-
lation. In Proceedings of the 23rd International
Conference on Computational Linguistics (Coling
2010), pages 376?384, Beijing, China, August. Col-
ing 2010 Organizing Committee.
Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1352?1362, Edinburgh, Scotland, UK.,
July. Association for Computational Linguistics.
Zhongqiang Huang, Martin Cmejrek, and Bowen
Zhou. 2010. Soft syntactic constraints for hierar-
chical phrase-based translation using latent syntac-
tic distributions. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Language
Processing, pages 138?147, Cambridge, MA, Octo-
ber. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion, June.
Yuval Marton and Philip Resnik. 2008. Soft syntac-
tic constraints for hierarchical phrased-based trans-
lation. In Proceedings of The 46th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1003?
1011, Columbus, Ohio, June.
Masaaki Nagata, Kuniko Saito, Kazuhide Yamamoto,
and Kazuteru Ohashi. 2006. A clustered global
phrase reordering model for statistical machine
translation. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Compu-
tational Linguistics, pages 713?720, Sydney, Aus-
tralia, July. Association for Computational Linguis-
tics.
Jan Niehues and Muntsin Kolss. 2009. A POS-based
model for long-range reorderings in SMT. In Pro-
ceedings of the Fourth Workshop on Statistical Ma-
chine Translation, pages 206?214, Athens, Greece,
March. Association for Computational Linguistics.
Hendra Setiawan, Min-Yen Kan, and Haizhou Li.
2007. Ordering phrases with function words. In
Proceedings of the 45th Annual Meeting of the As-
sociation of Computational Linguistics, pages 712?
719, Prague, Czech Republic, June. Association for
Computational Linguistics.
Hendra Setiawan, Min Yen Kan, Haizhou Li, and Philip
Resnik. 2009. Topological ordering of function
words in hierarchical phrase-based translation. In
Proceedings of the Joint Conference of the 47th An-
nual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing
1273
of the AFNLP, pages 324?332, Suntec, Singapore,
August. Association for Computational Linguistics.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008.
A new string-to-dependency machine translation al-
gorithm with a target dependency language model.
In Proceedings of ACL-08: HLT, pages 577?585,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.
Libin Shen, Jinxi Xu, Bing Zhang, Spyros Matsoukas,
and Ralph Weischedel. 2009. Effective use of lin-
guistic and contextual information for statistical ma-
chine translation. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing, pages 72?80, Singapore, August. Asso-
ciation for Computational Linguistics.
Christoph Tillman. 2004. A unigram orienta-
tion model for statistical machine translation. In
HLT-NAACL 2004: Short Papers, pages 101?104,
Boston, Massachusetts, USA, May 2 - May 7. Asso-
ciation for Computational Linguistics.
Christoph Tillmann and Tong Zhang. 2007. A
block bigram prediction model for statistical ma-
chine translation. ACM Transactions on Speech and
Language Processing (TSLP), 4(3).
Roy Tromble and Jason Eisner. 2009. Learning linear
ordering problems for better translation. In Proceed-
ings of the 2009 Conference on Empirical Methods
in Natural Language Processing, pages 1007?1016,
Singapore, August. Association for Computational
Linguistics.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference grammars:
Softening syntactic constraints to improve statisti-
cal machine translation. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 236?244,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Karthik Visweswariah, Rajakrishnan Rajkumar, Ankur
Gandhe, Ananthakrishnan Ramanathan, and Jiri
Navratil. 2011. A word reordering model for im-
proved machine translation. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing, pages 486?496, Edinburgh,
Scotland, UK., July. Association for Computational
Linguistics.
Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li.
2009. A syntax-driven bracketing model for phrase-
based translation. In Proceedings of the Joint Con-
ference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural
Language Processing of the AFNLP, pages 315?
323, Suntec, Singapore, August. Association for
Computational Linguistics.
Deyi Xiong, Min Zhang, and Haizhou Li. 2010.
Learning translation boundaries for phrase-based
decoding. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 136?144, Los Angeles, California,
June. Association for Computational Linguistics.
Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Mod-
eling the translation of predicate-argument structure
for smt. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 902?911, Jeju
Island, Korea, July. Association for Computational
Linguistics.
Richard Zens and Hermann Ney. 2006. Discrimina-
tive reordering models for statistical machine trans-
lation. In Human Language Technology Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics (HLT-NAACL):
Proceedings of the Workshop on Statistical Machine
Translation, pages 55?63, New York City, NY, June.
Association for Computational Linguistics.
Andreas Zollmann and Stephan Vogel. 2011. A word-
class approach to labeling pscfg rules for machine
translation. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1?11,
Portland, Oregon, USA, June. Association for Com-
putational Linguistics.
1274
