Proceedings of the 6th Workshop on Building and Using Comparable Corpora, pages 43?51,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
A modular open-source focused crawler for mining monolingual and
bilingual corpora from the web
Vassilis Papavassiliou
Institute for Language and Speech Processing
Athena Research and Innovation Center
Athens, Greece
{vpapa, prokopis}@ilsp.gr
Prokopis Prokopidis Gregor Thurmair
Linguatec
Gottfried-Keller-Str. 12, 81245
Munich, Germany
g.thurmair@linguatec.de
Abstract
This paper discusses a modular and open-
source focused crawler (ILSP-FC) for the
automatic acquisition of domain-specific
monolingual and bilingual corpora from
the Web. Besides describing the main
modules integrated in the crawler (dealing
with page fetching, normalization, clean-
ing, text classification, de-duplication and
document pair detection), we evaluate sev-
eral of the system functionalities in an ex-
periment for the acquisition of pairs of par-
allel documents in German and Italian for
the "Health & Safety at work" domain.
1 Introduction and motivation
There is a growing literature on using the Web for
constructing various types of text collections, in-
cluding monolingual, comparable, parallel and/or
domain-specific corpora. Such resources can
be used by linguists studying language use and
change (Kilgarriff and Grefenstette, 2003), and at
the same time they can be exploited in applied re-
search fields like machine translation and multi-
lingual information extraction. Moreover, these
collections of raw data can be automatically an-
notated and used to produce, by means of induc-
tion tools, a second order or synthesized deriva-
tives: rich lexica (with morphological, syntactic
and lexico-semantic information), large bilingual
dictionaries (word andmultiword based) and trans-
fer grammars.
To this end, several tools (i.e. web crawlers,
HTMLparsers, language identifiers, HTML clean-
ers, etc.) have been developed and combined in
order to produce corpora useful for specific tasks.
However, to the best of our knowledge, most of
the available systems either omit some processing
tasks or require access to the results of a search en-
gine. For instance, the BootCaT toolkit (Baroni et
al., 2006), a well-known suite of Perl scripts for
bootstrapping specialized language corpora from
the web, uses the Bing search engine and allows
up to 5,000 queries per month.
In this paper, we present ILSP-FC, a modular
system that includes components and methods for
all the tasks required to acquire domain-specific
corpora from the Web. The system is available as
an open-source Java project1 and due to its modu-
lar architecture, each of its components can be eas-
ily substituted by alternatives with the same func-
tionalities. Depending on user-defined configura-
tion, the crawler employs processing workflows
for the creation of either monolingual or bilingual
collections. For users wishing to try the system be-
fore downloading it, two web services2 allow them
to experiment with different configuration settings
for the construction of monolingual and bilingual
domain-specific corpora.
The organization of the rest of the paper is as fol-
lows. In Section 2, we refer to recent related work.
In Section 3, we describe in detail the workflow
of the proposed system. A solution for bootstrap-
ping the focused crawler input is presented in Sec-
tion 4. Then, an experiment on acquiring parallel
documents in German and Italian for the "Health
& Safety at work" domain (H&S) is described in
Section 5, which also includes evaluation results
on a set of criteria including parallelness and do-
main specificity. We conclude and mention future
work in Section 6.
2 Related work
Web crawling for building domain-specific mono-
lingual and/or parallel data involves several tasks
(e.g. link ranking, cleaning, text classification,
near-duplicates removal) that remain open issues.
Even though there are several proposed methods
1http://nlp.ilsp.gr/redmine/projects/
ilsp-fc
2http://nlp.ilsp.gr/ws/
43
for each of these tasks, in this section we refer only
to a few indicative approaches.
Olston and Najork (2010) outline the funda-
mental challenges and describe the state-of-the-art
models and solutions for web crawling. A gen-
eral framework to fairly evaluate focused crawling
algorithms under a number of performance met-
rics is proposed by Srinivasan et al (2005). A
short overview of cleaning methods is presented in
Spousta et al (2008) and the comparison of such
methods is discussed in Baroni et al (2008). Sev-
eral algorithms (Qi and Davison, 2009) exploit the
main content and the HTML tags of a web page
in order to classify a page as relevant to a targeted
domain or not. Methods for the detection and re-
moval of near-duplicates (i.e. acquired web pages
that have almost the same content) are reviewed
and compared in Theobald et al (2008).
Efficient focused web crawlers can be built
by adapting existing open-source frameworks like
Heritrix3, Nutch4 and Bixo5. For instance, Com-
bine6 is an open-source focused crawler that is
based on a combination of a general web crawler
and a text classifier. Other approaches make use
of search engines APIs to identify in-domain web
pages (Hong et al, 2010) or multilingual web sites
(Resnik and Smith, 2003). Starting from these
pages, Almeida and Sim?es (2010) try to detect
which links point to translations, while Shi et al
(2006) harvest multilingual web sites and extract
parallel content from them. Bitextor (Espl?-Gomis
and Forcada, 2010) combines language identifica-
tion with shallow features that represent HTML
structures to mine parallel pages.
Besides structure similarity, systems like PT-
Miner (Nie et al, 1999) and WeBiText (D?silets
et al, 2008) filtered fetched web pages by keep-
ing only those containing languagemarkers in their
URLs. Chen et al (2004) proposed the Parallel
Text Identification System, which incorporated a
content analysis module using a predefined bilin-
gual wordlist. Similarly, Zhang et al (2006) and
Utiyama et al (2009) adopted the use of aligners
in order to estimate the content similarity of candi-
date parallel web pages or mixed languages pages.
Barbosa et al (2012) proposed the use of bilin-
gual dictionaries and generated translations (e.g.
byGoogle Translate andMicrosoft Bing) to extract
3http://crawler.archive.org/
4http://nutch.apache.org
5http://openbixo.org/
6http://combine.it.lth.se/
parallel content from multilingual sites.
3 System architecture
In this section, we describe the main modules inte-
grated in ILSP-FC. In general, the crawler initial-
izes its frontier (i.e. the list of pages to be visited)
from a seed URL list provided by the user (or con-
structed semi-automatically, see Section 4), clas-
sifies fetched pages as relevant to the targeted do-
main, extracts links from fetched web pages and
adds them to the list of pages to be visited.
Focused crawler
page fetching
normalization
cleaning
language
identification
text classification
link extraction
exporting
deduplication
seed
URL list
domain
definition
in-domain
pages
detection of
parallel documents
document pairs
Figure 1: System architecture
In order to ensure modularity and scalability, the
crawler is built using Bixo, an open source web
mining toolkit that allows easy configuration of
workflows and runs on top of the Hadoop7 frame-
work for distributed data processing.
3.1 Page Fetcher
The first module concerns page fetching. A
multithreaded crawling implementation has been
adopted in order to ensure concurrent visiting of
multiple hosts. Users can configure several set-
tings that determine the fetching process, includ-
ing number of concurrent harvesters and filtering
out specific document types. The crawler always
respects standard robots.txt files, while politeness
can also be affected with the use of settings re-
garding time intervals for revisiting URLs from the
same website, maximum number of URLs from a
specific host per iteration, maximum number of at-
tempts to fetch a web page etc.
7http://hadoop.apache.org
44
3.2 Normalizer
The normalizer module uses the Apache Tika
toolkit 8 to parse the structure of each fetched web
page and extract its metadata. Extracted metadata
are exported at a later stage (see Subsection 3.7)
if the web document is considered relevant to the
domain. The text encoding of the web page is also
detected based on the HTTP Content-Encoding
header and the charset part of the Content-Type
header, and if needed, the content is converted into
UTF-8. Besides default conversion, special care is
taken for normalization of specific characters like
no break space, narrow no-break space, three-per-
em space, etc.
3.3 Cleaner
Apart from its textual content, a typical web page
also contains boilerplate, i.e. "noisy" elements like
navigation headers, advertisements, disclaimers,
etc., which are of only limited or no use for the pro-
duction of good-quality language resources. For
removing boileplate, we use a modified version of
Boilerpipe 9 (Kohlsch?tter et al 2010) that also
extracts structural information like title, heading
and list item. At this stage, text is also segmented
in paragraphs on the basis of specific HTML tags
like<p>, <br> and<li>. Paragraphs judged to be
boilerplate and/or detected as titles, etc. are prop-
erly annotated (see Subsection 3.7).
3.4 Language Identifier
The next processing module deals with language
identification. We use the Cybozu10 language
identification library that considers n-grams as fea-
tures and exploits a Naive Bayes classifier for lan-
guage identification. If a web page is not in the
targeted language, its only further use is in extrac-
tion of new links. Even though the main content of
a web page is in the targeted language, it is likely
that the web page includes a few paragraphs that
are not in this language.Thus, the language iden-
tifier is also applied on each paragraph and marks
them properly (see Subsection 3.7).
3.5 Text Classifier
The aim of this module is to identify if a page
that is normalized and in the targeted language
contains data relevant to the targeted domain. To
8http://tika.apache.org
9http://code.google.com/p/boilerpipe/
10http://code.google.com/p/language-detection/
this end, the content of the page is compared
to a user-provided domain definition. Following
the string-matching method adopted by the Com-
bine web crawler, the definition consists of term
triplets (<relevance weight, (multi-word) term,
subdomain>) that describe a domain and, option-
ally, subcategories of this domain. Language-
dependent stemmers from the Lucene11 project
are used to stem user-provided terms and docu-
ment content. Based on the number of terms? oc-
currences, their location in the web page and the
weights of found terms, a page relevance score p
is calculated as follows:
p =
N
?
i=1
4
?
j=1
nij ? wti ? wlj ,
whereN is the amount of terms in the domain def-
inition, wti is the weight of term i, wlj is the weight
of location j and nij denotes the number of occur-
rences of term i in location j. The four discrete
locations in a web page are title, metadata, key-
words, and plain text, with respective weights of
10, 4, 2, and 1.
Moreover, the amount of unique domain terms
found in the main content of the page,m, is calcu-
lated. Then, the values p andm are compared with
two predefined thresholds (t1 and t2) and if both
values are higher than the thresholds, the web page
is categorized as relevant to the domain and stored.
It is worth mentioning that the user can affect the
strictness of the classifier by setting the values of
both thresholds in the crawler's configuration file.
3.6 Link Extractor
Even when a web page is not stored (because it
was deemed irrelevant to the domain, or not in
the targeted language), its links are extracted and
added to the list of links scheduled to be visited.
Since the crawling strategy is a critical issue for
a focused crawler, the links should be ranked and
the most promising links (i.e. links that point to
"in-domain" web pages or candidate translations)
should be followed first. To this end, a score sl is
calculated for each link l as follows:
sl = c+ p/L+
N
?
i=1
ni ? wi
where L is the amount of links originating from
the source page, N is the amount of terms in the
domain definition, ni denotes the number of occur-
rences of the i-th term in the link's surrounding text
and wi is the weight of the i-th term. By using this
11http://lucene.apache.org/
45
formulation, the score link is mainly influenced by
the "domainess" of its surrounding text.
The parameter c is only added in case the
crawler is used for building bilingual collections.
It gets a high positive value if the link under con-
sideration originates from a web page in L1 and
"points" to a web page that is probably in L2.
This is the case when, for example, L2 is Ger-
man and the anchor text contains strings like "de",
"Deutsch", etc. The insertion of this parameter
forces the crawler to visit candidate translations
before following other links.
3.7 Exporter
The Exporter module generates an XML file for
each stored web document. Each file contains
metadata (e.g. language, domain, URL, etc.)
about the corresponding document inside a header
element. Moreover, a <body> element contains
the content of the document segmented in para-
graphs. Apart from normalized text, each para-
graph element <p> is enriched with attributes pro-
viding more information about the process out-
come. Specifically, <p> elements in the XML
files may contain the following attributes: i)
crawlinfo with possible values boilerplate, mean-
ing that the paragraph has been considered boil-
erplate (see Subsection 3.3), or ooi-lang, meaning
that the paragraph is not in the targeted language;
ii) typewith possible values: title, heading and lis-
titem; and iii) topicwith a string value including all
terms from the domain definition detected in this
paragraph.
3.8 De-duplicator
Ignoring the fact12 that the web contains many
near-duplicate documents could have a negative
effect in creating a representative corpus. Thus,
the crawler includes a de-duplicator module that
represents each document as a list containing the
MD5 hashes of the main content's paragraphs, i.e.
paragraphs without the crawlinfo attribute. Each
document list is checked against all other docu-
ment lists, and for each candidate pair, the inter-
section of the lists is calculated. If the ratio of
the intersection cardinality to the cardinality of the
shortest list is more than 0.8, the documents are
considered near-duplicates and the shortest is dis-
carded.
12Baroni et al (2009) reported that during building of the
Wacky corpora, the amount of collected documents was re-
duced by more than 50% after de-duplication.
3.9 Pair Detector
After in-domain pages are downloaded, the Pair
Detector module uses two complementary meth-
ods to identify pairs of pages that could be con-
sidered parallel. The first method is based on co-
occurrences, in two documents, of images with the
same filename, while the second takes into account
structural similarity.
In order to explain the workflow of the pair de-
tection module, we will use the multilingual web-
site http://www.suva.ch as a running exam-
ple. Crawling this website using the processes de-
scribed in previous subsections provides a pool of
707 HTML files (and their exported XML counter-
parts) that are found relevant to the H&S domain
and in the targeted DE and IT languages (376 and
331 files, respectively).
Each XML file is parsed and the following
features are extracted: i) the document lan-
guage; ii) the depth of the original source page,
(e.g. for http://domain.org/d1/d2/d3/
page.html, depth is 4); iii) the amount of para-
graphs; iv) the length (in terms of tokens) of the
clean text; and v) the fingerprint of the main con-
tent, which is a sequence of integers that represent
the structural information of the page, in a way
similar to the approach described by Espl?-Gomis
and Forcada (2010). For instance, the fingerprint
of the extract in Figure 2 is [-2, 28, 145, -4, 9, -3,
48, -5, 740] with boilerplate paragraphs ignored; -
2, -3 and -4 denote that the type attributes of corre-
sponding<p> elements have title, heading and lis-
titem values, respectively; -5 denotes the existence
of the topic attribute in the last <p>; and positive
integers are paragraph lengths in characters.
The language feature is used to filter out pairs of
files that are in the same language. Pages that have
a depth difference above 1 are also filtered out, on
the assumption that it is very likely that translations
are found at the same or neighbouring depths of the
web site tree.
Next, we extract the filenames of the images
from HTML source and each document is repre-
sented as a list of image filenames. Since it is very
likely that some images appear inmanyweb pages,
we count the occurrence frequency of each image
and discard relatively frequent images (i.e. Face-
book and Twitter icons, logos etc.) from the lists.
In order to classify images into "critical" or
"common" (see Figure 3) we need to calcu-
late a threshold. In principle, one should ex-
46
<p type="title">Strategia degli investimenti</p> <!-- -2, 28-->
<p >I ricavi degli investimenti sono un elemento essenziale per finanziare le
rendite e mantenere il potere d'acquisto dei beneficiari delle rendite.</p>
<!--145-->
<p type="listitem">Document:</p> <!-- -4, 9 -->
<p crawlinfo="boilerplate" type="listitem">Factsheet "La strategia d'investimento
della Suva in sintesi" (Il link viene aperto in una nuova finestra) </p> <!--
ignored -->
<p type="heading">Perch? la Suva effettua investimenti finanziari?</p> <!-- -3,
48-->
<p topic="prevenzione degli infortuni;infortunio sul lavoro">Nonostante i molti
sforzi compiuti nella prevenzione degli infortuni sul lavoro e nel tempo libero
ogni anno accadono oltre 2500 infortuni con conseguenze invalidanti o mortali.
In questi casi si versa una rendita per invalidit? agli infortunati oppure una
rendita per orfani o vedovile ai superstiti. Nello stesso anno in cui
attribuisce una rendita, la Suva provvede ad accantonare i mezzi necessari a
pagare le rendite future. La maggior parte del patrimonio investito dalla Suva ?
rappresentato proprio da questi mezzi, ossia dal capitale di copertura delle
rendite. La restante parte del patrimonio ? costituta da accantonamenti per
prestazioni assicurative a breve termine come le spese di cura, le indennit?
giornaliere e le riserve.</p> <!-- -5, 740-->
Figure 2: An extract of an XML file for an Italian web page relevant to the H&S domain.
Figure 3: Critical (dashed) and common (dotted) images in a multilingual (EN/DE) site.
pect that low/high frequencies correspond to "crit-
ical"/"common" images. We employ a non-
parametric approach for estimating the probabil-
ity density function (Alpaydin, 2010) of the image
frequencies using the following formula:
p?(x) = 1Mh
M
?
t=1
K(x?xth )
where the random variable x defines the positions
(i.e. images frequencies) at which the p?(x) will be
estimated, M is the amount of images, xt denotes
the values of data samples in the region of width
h around the variable x, and K(?) is the normal
kernel that defines the influence of values xt in the
estimation of p?(x). The optimal value for h, the
optimal bandwidth of the kernel smoothing win-
dow, was calculated as described in Bowman and
Azzalini (1997).
Figure 4 illustrates the normalized histogram of
image frequencies in the example collection and
the estimated probability density function. One
can identify a main lobe in the low values, which
corresponds to "critical" images. Thus, the thresh-
old is chosen to be equal to the minimum just af-
ter this lobe. The underlining assumption is that if
a web page in L1 contains image(s) then the web
page with its translation in L2 will contain more or
less the same images. In case this assumption is not
valid for a multilingual site (i.e. there are only im-
ages that appear in all pages, e.g. template icons),
probably all images will be included. To eliminate
this, we discard images that exist in more than 10%
of the total HTML files.
Following this step, each document is exam-
ined against all others and two documents are con-
sidered parallel if a) the ratio of their paragraph
amounts (the ratio of their lengths in terms of para-
47
0 2 4 6 8 10 12 14 16 180
0.1
0.2
0.3
0.4
0.5
log2(frequency)
den
sity
Figure 4: The normalized histogram and the esti-
mated pdf of the image frequencies.
graphs), b) the ratio of their clean text lengths (in
terms of tokens), and c) the Jaccard similarity co-
efficient of their image lists, are higher than em-
pirically predefined thresholds.
More pairs are detected by examining structure
similarity. Since the XML files contain informa-
tion about structure, content (i.e. titles, headings,
list items) and domain specificity (i.e. paragraphs
with the topic attribute), we use these files instead
of examining the similarity of the HTML source.
A 3-dimensional feature vector is constructed for
each candidate pair of parallel documents. The
first element in this vector is the ratio of their fin-
gerprint lengths, the second is the ratio of their
sizes in paragraphs, and the third is the ratio of the
edit distance of the fingerprints of the two docu-
ments to the maximum fingerprint length. Clas-
sification of a pair as parallel is achieved using a
soft-margin polynomial Support Vector Machine
trained with the positive and negative examples
collected during our previous work (Pecina et al,
2012). Note that the dataset included only candi-
date pairs that met the criteria regarding the ratio
of paragraphs amounts and the ratio of text lengths,
mentioned above. As a result, negative instances
(i.e. pairs of documents that have similar structure
but are not real pairs) did not heavily outnumber
positive ones and thus the training was not imbal-
anced (Akbani et al, 2004).
4 Bootstrapping the input of the focused
crawler
In the work presented in previous sections, we as-
sumed that users had access to already existing
lists of seed terms and URLs for the initializa-
tion of the frontier and the classifier. But what if
manually compiled resources for a particular do-
main/language(s) combination (e.g. ES/FR termi-
nology for endocrinology or lists of EN/DE web
sites related to floriculture) are impossible or diffi-
cult to find? Can we bootstrap such resources and
provide them to users for post-editing? In this sec-
tion, we present ongoing work towards this goal
using the category graph and the external links of
multilingual editions of Wikipedia.
We initialize the bootstrapping process by
searching for a term defining the domain of in-
terest (e.g. "ballet", "automotive accessories") in
the category graph of the EN wikipedia. If a cat-
egory is found, we recursively collect all pages in
this category and its subcategories for a predefined
depth. For each page we extract its title and we
consider it a term that can participate in a list of
domain-related seed terms. We use a set of pattern
matching rules that exclude certain titles like those
of disambiguation and redirect pages. Other rules
exclude titles that refer to lists of related pages or
titles that use upper case or title case and are proba-
bly abbreviations and named entities, respectively.
Obviously, in a different setting where, for exam-
ple, a user is interested in discovering named enti-
ties related to a domain, these titles should be han-
dled differently.
The next step involves utilizing the links from
each EN page to articles in wikipedias written in
other languages. Based on which languages we are
interested in, we again consider each title a seed
term in language LANG, this time also storing the
information that the term is also a LANG transla-
tion of the EN term.
During traversing the EN category graph and
visiting corresponding articles in other languages,
we also populate a list of seed URLs for the fo-
cused crawler, by keeping record of all links to
URLs outside wikipedia.org. At this stage,
we have all necessary resources to initiate mono-
lingual focused crawls in each language we are in-
terested in.
An optional last stage targets the automatic dis-
covery of sites with multilingual content where
parallel documents can be extracted from. During
this stage, we visit each of the external links we
collected and detect the language of the web page
this link points to. From this web page, we extract
its links and examine whether the anchor text of
each link matches a set of patterns indicating that
48
this link points to a translation (in a way similar to
the process described in Subsection 3.6). If trans-
lation links are found, we store the site as a candi-
date for bilingual focused crawling. Also, since it
is common that links to multilingual editions of a
web site are not present in all of its pages, we re-
peat the same process for the home page of the site.
Notice that it is a task for the FC to detect whether
these sites (or one of their sections) also contain
parallel documents in the targeted domain.
In a first set of experiments following this ap-
proach, we used September 2012 snapshots13 for
English, French, German, Greek, Portuguese and
Spanish wikipedias (EN, FR, DE, EL, PT and ES,
respectively). Although we leave detailed eval-
uation of created resources for future work, we
present as example output a list of terms related to
"Flowers" in Table 1. Notice that, since the num-
ber of articles of multilingual wikipedias varies
considerably, the term list extracted for languages
like EL is, as expected, smaller compared, for ex-
ample, to the 547 and 293 terms collected for EN
and ES, respectively. Finally, using the URLs ex-
tracted from the articles on the "Flowers" domain,
Table 2 contains a sample of web sites detected for
containing relevant multilingual content.
5 Evaluation Results
In order to assess the quality of the resources that
ILSP-FC can produce, we evaluated it in a task of
acquiring pairs of parallel documents in German
and Italian for the "Health & Safety at work" (Ar-
beitsschutz/Sicurezza sul lavoro) domain. We as-
sume that this task is relatively difficult, i.e. that
the number of documents in this domain and pair of
languages is relatively small in the web. Overall,
our system delivered 807 document pairs for H&S,
containing 1.40 and 1.21 million tokens for IT and
DE, respectively. Numbers refer to tokens in the
main content of the acquired web pages, i.e. to to-
kens in paragraphs without the attribute crawlinfo
(see Subsection 3.7).
A sample of the acquired corpora were evalu-
ated against a set of criteria discussed in the fol-
lowing subsections. We randomly selected 103
document pairs for manual inspection. The sample
size was calculated according to a 95% confidence
level and an at most 10% confidence interval.
13We use the JavaWikipedia Library (Zesch et al, 2008) to
convert each snapshot into a database that allows structured
access to several aspects of categories, articles, sections etc.
5.1 Parallelness
The number of the correctly identified parallel doc-
ument pairs was obviously critical in this particular
evaluation setting. We focused on the precision of
the pair detector module, since it is not feasible to
count how many pairs were missed. In the subset
examined, 94 and 4 document pairs were judged as
parallel and not parallel, respectively. The other
5 pairs were considered borderline cases, where
more than 20% of the sentences in one document
were translated in the other. Since about 95% of
the crawled data are of good or sufficiently good
quality, this shows that they are usable for further
processing, e.g. for sentence alignment.
5.2 Domain specificity
We next evaluated how many documents in the se-
lected data fit the targeted domain in both the IT
and the DE partitions. The overall precision was
about 77%, with 79 IT documents and 80DE docu-
ments found relevant to the narrow domain chosen
for evaluation.
Reported results on text-to-topic classification
sometimes score higher; however they neglect a
critical factor of influence, namely the distance be-
tween training and prediction datasets. In the "real
world", scores between 75% and 85% are realistic
to assume. It should be mentioned that the preci-
sion of the topic classifier strongly depends on the
quality of the seed terms: by inspecting results,
modifying the seed term list and re-crawling, re-
sults could easily be improved further.
5.3 Language identification
Since the language identifier is applied on every
paragraph of the main content of each web page,
we examined how many of the paragraphs have
been marked correctly. Overall, 5223 and 4814
paragraphs of IT and DE documents were checked
and only 13 and 65wrong assignments were found,
respectively.
Most errors (about 80%) were found in a sin-
gle document with a lot of tokens denoting chem-
ical substances that seem to confuse the language
identifier. When excluding this document, figures
rise to 99,67% and 99,95% for the DE and IT par-
titions, respectively. The rest of the errors mainly
occurred in paragraphs containing sentences in dif-
ferent languages.
49
EN: 547 DE: 255 EL: 22 ES: 293 FR: 286 IT: 143 PT: 164
Gardenia Gardenien ???????? Gardenia Gard?nia Gardenia Gardenia
Calendula Ringelblumen ?????????? Calendula Calendula Calendula Calendula
Lilium Lilien ????? Lilium Lys Lilium L?rio
Peony Pfingstrosen ??????? Paeoniaceae Pivoine Paeonia Paeoniaceae
Tulip Tulpen ??????? Tulipa Tulipe Tulipa Tulipa
Flower Bl?te ????? Flor Fleur Fiore Flor
Crocus Krokusse ?????? Crocus Crocus Crocus Crocus
Anemone Windr?schen ??????? Anemone An?mone Anemone Anemone
Table 1: Sample seed terms for the "Flowers" domain in 7 languages, collected automatically frommulti-
lingual editions ofWikipedia. The header of the table refers to the total terms collected for each language.
Wikipedia article Seed URL WebSite Langs
EN: Omphalodes_verna http://goo.gl/msyIc http://www.luontoportti.com de,en,es,fr
ES: Tropaeolum http://goo.gl/Ec5uK http://www.chileflora.com de,en,es
EN: Erythronium americanum http://goo.gl/nEP2L http://wildaboutgardening.org en,fr
DE: Nickendes_Leimkraut http://goo.gl/nuHNe http://www.wildblumen.at de,en,pt
DE: Titanenwurz http://goo.gl/rLl9W http://www.wilhelma.de de,en
Table 2: Automatically detected web sites with multilingual content related to the "Flowers" domain.
Column 1 presents the original LANG.wikipedia.org article from which the (shortened for readability
purposes) seed URLs in column 2 were extracted. The seed URLs led to the 3rd column web sites, in
which content in the languages of the 4th column was found.
5.4 Boilerplate removal
For this evaluation aspect, we evaluated howmany
"good" paragraphs were judged to be boilerplate,
and how many "bad" paragraphs were missed. We
examined 23178 and 23176 paragraphs of IT and
DE documents and found 2326 and 2591 errors
with an overall error rate around 10%. It should
be noted that different strategies for boilerplate re-
moval can be followed. One "classical" option is to
remove everything that does not belong to the text,
i.e. headers, advertisements etc. that "frame" real
content. Another option is to attempt to remove
everything which is irrelevant for MT sentence
alignment; this goes beyond the first approach as it
also removes short textual chunks, copyright dis-
claimers, etc. Most of the errors reported herewere
mainly due to this difference; i.e. they were para-
graphs that were deemed not usable for MT align-
ment.
6 Conclusions and future work
In this paper we described and evaluated ILSP-FC,
a system for mining domain-specific monolingual
and bilingual corpora from the web. The system
is available as open-source and is modular in the
sense that each of its components can be easily sub-
stituted with similar software performing the same
functionalities. The crawler can also be tested via
web services that allow the user to perform exper-
iments without the need to install it.
We have already used the crawler in producing
monolingual and parallel corpora and other deriva-
tive resources. Evaluation has shown that the sys-
tem can be used effectively in collecting resources
of high quality, provided that the user can initial-
ize it with lists of seed terms and URLs that can be
easily found on the web. For domains for which
no similar lists are available, we presented ongo-
ing work for bootstrapping them frommultilingual
editions of Wikipedia. Future work includes eval-
uation and improvement of the bootstrapping com-
ponent, more sophisticated methods for text clas-
sification, and grouping of collected data based on
genre.
Acknowledgments
Work by the first two authors was partially funded
by the European Union QTLaunchPad (FP7,
Grant 296347) and Abu-MaTran (FP7-People-
IAPP, Grant 324414) projects. An initial version
of this work was produced during the EU Panacea
project (FP7-ICT, Grant 248064).
50
References
Rehan Akbani, Stephen Kwek, and Nathalie Japkow-
icz. 2004. Applying support vector machines to
imbalanced datasets. In In Proceedings of the 15th
European Conference onMachine Learning (ECML,
pages 39--50.
Jos? Jo?o Almeida and Alberto Sim?es. 2010. Auto-
matic parallel corpora and bilingual terminology ex-
traction from parallel websites. In 3rd Workshop on
Building and Using Comparable Corpora .
Ethem Alpaydin. 2010. Introduction to Machine
Learning. The MIT Press, 2nd edition.
Luciano Barbosa, Vivek Kumar Rangarajan Sridhar,
Mahsa Yarmohammadi, and Srinivas Bangalore.
2012. Harvesting parallel text in multiple languages
with limited supervision. In COLING, pages 201--
214.
Marco Baroni, Adam Kilgarriff, Jan Pomik?lek, and
Pavel Rychl?. 2006. WebBootCaT: Instant Domain-
Specific Corpora to Support Human Translators.
In Proceedings of the 11th Annual Conference of
EAMT, pages 47--252, Norway.
Marco Baroni, Francis Chantree, Adam Kilgarriff, and
Serge Sharoff. 2008. Cleaneval: a competition for
cleaning web pages. In LREC'08.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. TheWaCkyWideWeb: a
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209--226.
Adrian W. Bowman and Adelchi Azzalini. 1997.
Applied smoothing techniques for data analysis:
the kernel approach with S-Plus illustrations, vol-
ume 18. Oxford University Press.
Jisong Chen, Rowena Chau, and Chung-Hsing Yeh.
2004. Discovering parallel text from theWorldWide
Web. In Proceedings of ACSW Frontiers '04, vol-
ume 32, pages 157--161, Darlinghurst, Australia.
Alain D?silets, Benoit Farley, Marta Stojanovic, and
Genevi?ve Patenaude. 2008. WeBiText: Building
Large Heterogeneous Translation Memories from
Parallel Web Content. In Proceedings of Translat-
ing and the Computer (30), London, UK.
Miquel Espl?-Gomis and Mikel L. Forcada. 2010.
Combining Content-Based and URL-Based Heuris-
tics to Harvest Aligned Bitexts from Multilingual
Sites with Bitextor. The Prague Bulletin of Math-
emathical Lingustics, 93:77--86.
Gumwon Hong, Chi-Ho Li, Ming Zhou, and Hae-
Chang Rim. 2010. An empirical study on web min-
ing of parallel data. In Proceedings of the 23rd COL-
ING, pages 474--482.
Adam Kilgarriff and Gregory Grefenstette. 2003. In-
troduction to the special issue on the web as corpus.
Computational Linguistics, 29(3):333--348.
Jian-Yun Nie, Michel Simard, Pierre Isabelle, and
Richard Durand. 1999. Cross-language information
retrieval based on parallel texts and automatic min-
ing of parallel texts from the Web. In Proceedings
of the 22nd annual international ACM SIGIR con-
ference on research and development in information
retrieval, pages 74--81, New York.
Christopher Olston and Marc Najork. 2010. Web
crawling. Found. Trends Inf. Retr., 4(3):175--246.
Pavel Pecina, Antonio Toral, Vassilis Papavassiliou,
Prokopis Prokopidis, and Josef van Genabith. 2012.
Domain adaptation of statistical machine translation
using web-crawled resources: a case study. In Pro-
ceedings of the 16th Annual Conference of EAMT,
pages 145--152, Trento, Italy.
Xiaoguang Qi and Brian D. Davison. 2009. Web page
classification: Features and algorithms. ACM Com-
puting Surveys, 41:11--31.
Philip Resnik and Noah A. Smith. 2003. The Web as a
parallel corpus. Computational Linguistics, 29:349-
-380.
Lei Shi, Cheng Niu, Ming Zhou, and Jianfeng Gao.
2006. A dom tree alignment model for mining paral-
lel data from the web. In COLING/ACL-2006, pages
489--496.
Miroslav Spousta, Michal Marek, and Pavel Pecina.
2008. Victor: the Web-Page Cleaning Tool. In Pro-
ceedings of the 4th Web as Corpus Workshop - Can
we beat Google?, pages 12--17, Marrakech.
Padmini Srinivasan, Filippo Menczer, and Gautam
Pant. 2005. A General Evaluation Framework for
Topical Crawlers. Information Retrieval, 8:417--
447.
Martin Theobald, Jonathan Siddharth, and Andreas
Paepcke. 2008. Spotsigs: robust and efficient near
duplicate detection in large web collections. In Pro-
ceedings of the 31st annual international ACM SI-
GIR conference on research and development in in-
formation retrieval, pages 563--570.
Masao Utiyama, Daisuke Kawahara, Keiji Yasuda, and
Eiichiro Sumita. 2009. Mining parallel texts from
mixed-language web pages. InMT Summit.
Torsten Zesch, Christof M?ller, and Iryna Gurevych.
2008. Extracting lexical semantic knowledge from
wikipedia and wiktionary. In Proceedings of the 6th
International Conference on Language Resources
and Evaluation, Marrakech.
Ying Zhang, Ke Wu, Jianfeng Gao, and Phil Vines.
2006. Automatic Acquisition of Chinese-English
Parallel Corpus from the Web. In Proceedings of
the 28th European Conference on Information Re-
trieval, pages 420--431.
51
First Joint Workshop on Statistical Parsing of Morphologically Rich Languages
and Syntactic Analysis of Non-Canonical Languages, pages 90?96 Dublin, Ireland, August 23-29 2014.
Experiments for Dependency Parsing of Greek
Prokopis Prokopidis
Institute for Language
and Speech Processing
Athena Research Center
Athens, Greece
prokopis@ilsp.gr
Haris Papageorgiou
Institute for Language
and Speech Processing
Athena Research Center
Athens, Greece
xaris@ilsp.gr
Abstract
This paper describes experiments for statistical dependency parsing using two different parsers
trained on a recently extended dependency treebank for Greek, a language with a moderately rich
morphology. We show how scores obtained by the two parsers are influenced by morphology and
dependency types as well as sentence and arc length. The best LAS obtained in these experiments
was 80.16 on a test set with manually validated POS tags and lemmas.
1 Introduction
This work describes experiments for statistical dependency parsing using a recently extended dependency
treebank for Greek, a language with a moderately rich morphology. Relatively small training resources
like the one we use here can set severe sparsity obstacles for languages with flexible word order and
a relatively rich morphology like Greek. This work presents ongoing efforts for evaluating ways of
improving this situation. The rest of this paper is structured as follows: We describe the treebank and
the tools for preprocessing it in section 2. After mentioning some relevant work, we present in section 4
different settings for experiments involving manually validated and automatically pre-processed data for
morphology and lemmas. In section 5we include a comparison of the output of twowell-known statistical
parsers in reference to a set of criteria. Section 6 describes work on using sentences from relatively large
auto-parsed resources as additional training data.
2 Treebank
We use the Greek Dependency Treebank (Prokopidis et al., 2005) for all experiments. GDT includes
texts from open-content sources and from corpora collected in the framework of research projects aiming
at multilingual, multimedia information extraction. A first version of the GDT (GDT-2007) contained
70223 tokens and 2902 sentences, and it was used in the CoNLL 2007 Shared Task on Dependency Pars-
ing (Nivre et al., 2007a). A recently extended version of the resource (henceforth GDT-2014) amounts
to 130753 tokens (including punctuation) and 5668 sentences. The current version of the resource con-
tains 21827 unique types, 11005 lemmas and 10348 hapax legomena (excluding dates, digits and proper
names). The average sentence length is 23.07 tokens. GDT consists of 249 whole documents and can thus
be used for the annotation of other, possibly inter-sentential, relations like coreference. Each document
has 22.76 sentences on average.
The dependency-based annotation scheme used for the syntactic layer of the GDT is based on an adap-
tation of the guidelines for the Prague Dependency Treebank (B?hmov? et al., 2003), and allows for
intuitive representations of long-distance dependencies and non-configurational structures common in
languages with flexible word order. Most trees are headed by a word that bears the Pred relation to an
artificial root node. Other tokens depending on this root node include sentence-final punctuation marks
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
90
.
.... .??????????? .???????? .????? .??????? .???????? .??? .??????? ....
.... .VbMn .NoCm .AsPpPa .PnRe .VbMn .CjSb .VbMn ....
.... .examining .folders .in .which .they-think .that .it-exists ....
Adv
Atr
AuxC Obj
AuxP
Adv
Figure 1: An analysis for a sentence fragment with a non-projective arc
and coordinating conjunctions. Coordinating conjunctions and apposition markers head participating to-
kens in relevant constructions. Table 1 contains some of the most common dependency relations used in
the treebank, while Figure 1 presents a sentence fragment that contains a non-projective arc connecting
the verb of a complement clause and its extraposed argument. In GDT-2014, 12.86% of the trees include
at least one non-projective arc.
The relatively free word order of Greek can be inferred when examining typical head-dependent struc-
tures in the resource. Although nouns are almost always preceded by determiners and adjectives, the
situation is different for arguments of verbs. Of the 5414 explicit subjects in GDT, 31% occur to the
right of their parent. The situation is more straightforward for non-pronominal objects, of which only
4% occur to the left of their head. Of those subjects and objects appearing in ?non-canonical? positions,
21% and 31%, respectively, are of neuter gender. This fact can pose problems to parsing, since the case
of nominative and accusative neuter homographs is particularly difficult to disambiguate, especially due
to the fact that articles and adjectives often preceding them (e.g. ??/the ???????/red ??????/book) are also
invariant for these two case values.
Dep. Rel Description Dep. Rel. Description
Pred Main sentence predicate Adv Adverbial dependent
Subj Subject Atr Attribute
Obj Direct object Coord A node governing coordination
AuxC Subord. conjunction node AuxP Prepositional node
Table 1: Common dependency relations in the Greek Dependency Treebank
Apart from the addition of new material, another difference from previous versions is that GDT-2014
sentences have been manually validated for POS, morphosyntactic features and lemmas. The tagset used
contains 584 combinations of basic POS tags (Table 2) and features that capture the rich morphology
of the Greek language. As an example, the full tag AjBaMaSgNm for a word like ?????????/turbulent
denotes an adjective of basic degree, masculine gender, singular number and nominative case. The three
last features are also used for nouns, articles, pronouns, and passive participles. Verb tags include features
for tense and aspect, while articles are distinguished for definiteness.
Manual annotation at these levels allows to examine how the parser?s accuracy is affected in realistic,
automatic pre-processing scenarios. In these settings, POS tagging is conducted with a tagger (Papa-
georgiou et al., 2000) trained on a manually annotated corpus of Greek texts amounting to 455K tokens.
During automatic processing, the tagger assigns to each token the most frequent tag in a lexicon compiled
from the training corpus. A list of suffixes guides initial tagging of unknown words. When all tokens
have been assigned a tag, a set of about 800 contextual rules learned during training, is applied to correct
initial decisions. The tagger?s accuracy reaches 97.49 when only basic POS is considered. When all
features (including, for example, gender and case for nouns, and aspect and tense for verbs) are taken
into account, the tagger?s accuracy drops to 92.54. As an indication of the relatively rich morphology of
Greek, the tags/word ratio in the tagger?s lexicon is 1.82. Tags for a word typically differ in only one or
two features like case and gender for adjectives. However, distinct basic parts of speech (e.g. Vb/No) is
also a possibility.
Following POS tagging, a lemmatizer retrieves lemmas from a lexicon containing 66K lemmas, which
91
in their expanded form extend the lexicon to approximately 2M different entries. When a token under
examination is associated in the lexicon with two or more lemmas, the lemmatizer uses information from
the POS tags to disambiguate. For example, the token+POS input ?????????/VbMn guides the lemma-
tizer to retrieve the lemma ??????? (examine), while the lemma ??????? (examination) is returned for
?????????/NoCm.
POS Description POS Description
Ad Adverb AsPpPa Prep. + Article combination
AjBa Adjective (basic degree) CjCo Coordinating conjunction
AsPpSp Preposition CjSb Subordinating conjunction
AtDf Definite article NoCm Common noun
AtId Indefinite article PnPo Possessive pronoun
VbMn Finite verb PnRe Relative pronoun
Table 2: Fine grained POS tags in GDT
3 Relevant work
Nakagawa (2007) was the best system in parsing the GDT in the CoNLL 2007 shared task, showing a
76.31 Labeled Attachment Score. Nakagawa?s two-stage parser first constructed unlabeled dependency
structures using sentence and token features, and then labeled the arcs using SVMs. The second best
score for Greek was Hall et al. (2007), who scored 74.65 LAS using an ensemble system combining the
output of six different Maltparser configurations. In recent work discussing the cube-pruned dependency
parsing framework, Zhang and McDonald (2014) report a 78.45 LAS on the CoNLL dataset.
4 Experiments
In this section, we report on experiments using statistical parsers trained on automatically preprocessed
and manually validated versions of GDT-2014. In all experiments we report the Labeled and Unlabeled
Attachment Scores (LAS and UAS) and the Label Accuracy (LACC), with punctuation tokens counting
as scoring tokens. We split the data of GDT-2014 in 90% and 10% training and test sets (5,101/567
sentences; 117,581/13,172 tokens). In this partitioning scheme, unknown tokens and lemmas when pars-
ing the test set are 27% and 16%, respectively. We performed experiments with the transition-based
Maltparser (Nivre et al., 2007b) and the graph-based Mateparser (Bohnet, 2010). For Maltparser, a 5-
fold cross validation on the training set using MaltOptimizer (Ballesteros and Nivre, 2012) resulted in
the selection of the non-projective stacklazy parsing algorithm as the one yielding an average best 78.96
LAS. Table 3 provides an abbreviated overview of the selected feature model, which is dominated by the
top and first three elements in the parser?s stack and its lookahead list. For Mateparser we used default
settings.
Table 4 summarizes the results of our experiments. We observe a better 79.74 LAS with Mateparser
with a larger difference in UAS than in LACC (2.37 vs 1.26). This may suggest that the two parsers
agree on the labels they assign but differ more in discovering node heads. Not surprisingly, testing in
a more realistic scenario of using automatic PoS, features and lemmas produces more errors (Figure 2).
Maltparser shows a relatively smaller decrease in accuracy (-3.05 vs -3.45) in this context. In the next
two experiments with Mateparser, we see that in automatic pre-processing scenarios, the tagger clearly
contributes more to error increase (-3.34) compared to the lemmatizer (-0.06).
We also trained Mateparser in the MPL setting with POS tagsets of varying granularity, by remov-
ing features that were intuitively deemed to increase sparsity without contributing to parsing accuracy.
More specifically, we experimented with several combinations of removing for aspect and tense of verbs,
gender of nominal elements, definiteness of articles and degree of adjectives. A best LAS of 80.16 (cf.
the two final columns of Table 4) was observed after removing features for degree and definiteness.
Finally, and in order to examine how the expansion of the treebank has affected performance, we also
92
Tokens Form Lem PoS Feats Dep Tokens Form Lem PoS Feats Dep
st[0] + + + + rd(st[0]) + +
st[1] + + + + rd(st[1]) +
st[2] + + hd(st[0]) +
inp[0] + lh[0] + + +
ld(st[0]) + + lh[1] + + +
ld(st[1]) + lh[2] +
Table 3: Automatically selected Maltparser features. Stack/Input (st/inp) tokens refer to tokens that
are/have been in the stack of partially parsed tokens. Lookahead (lh) tokens are tokens that have not
been in the stack. Features ld/rd/hd refer to the leftmost/rightmost dependents and and the head. We do
not show features resulting from merging two or three features (e.g. merge3(PoS(lh[0]) + PoS(lh[1]) +
PoS(lh[2])) )
.
.??????? .??? .?? .???????????? .????????? .???? .?? .????????
.VbMn .CjSb .PtFu .VbMn .Aj .PnDm .AtDf .NoCm
.assume-1stPers .that .Future .confirm-3rdPers .orally .this .the .commitment
Pred
AuxC AuxV
Obj
Atr
Atr
Det
Obj
Figure 2: An example of a preprocessing error misguiding the parser: the wrong adjectival tag for the
adverb ????????? leads the parser in recognizing it as an attribute to a noun.
trained Mateparser in the MPL scenario using a training set equal in size to the 2.7K sentences of the
CoNLL-2007 data. The results observed were 78.39 LAS and 84.77 UAS.
MPL APL APML MPAL APL-AUTO MFR1 MFR2
Malt Mate Malt Mate Mate Malt Mate Mate
LAS 77.50 79.74 74.45 76.29 76.40 79.68 75.13 76.81 80.05 80.16
UAS 83.46 85.83 81.35 83.57 83.69 85.77 81.98 83.94 86.02 86.29
LACC 86.68 87.94 84.29 85.67 85.72 87.91 84.92 85.90 88.03 88.13
Table 4: Results from parsing GDT with Malt and Mate parsers: MPL refers to training and testing on
manually validated POS, morphological features and lemmas; APL is evaluation on automatic POS, fea-
tures and lemmas; APML is evaluation on automatic morphology and gold lemmas; MPAL on gold mor-
phology and automatic lemmas. APL-AUTO is APL with training data including automatically parsed
sentences. MFR1 is MPL after removing features for tense, aspect, degree and definiteness. MFR2 is
MPL after removing features for degree and definiteness.
5 Error analysis
In this section we first provide a comparative analysis of errors by the two parsers on the 567 sentences
test set. We use the set of length and linguistic factors proposed in the comparison between the Malt
and MST parsers in McDonald and Nivre (2007). For example, in Figure 3, we plot sentence length in
bins of size 10 and show, as expected, that the accuracy of both parsers decreases when analyzing longer
sentences. Maltparser shows a higher accuracy for sentences of size up to 10, possibly because when
parsing shorter sentences, early mistakes when making greedy decisions based on local features do not
have a chance to lead to large error propagation. We omit details on UAS, where a similar pattern is
observed. Figure 4 shows that Mateparser achieves better harmonic means of precision and recall, when
longer dependencies are examined. This is again consistent with the fact that Maltparser favors shorter
93
0.70
0.75
0.80
0.85
0.90
10 20 30 40 50Sentence Length
LAS
Parser
malt
mate
Figure 3: LAS relative to sentence length.
0.4
0.6
0.8
5 10 15 20Dependency Length
F?sc
ore
Parser
malt
mate
Figure 4: Dependency arc F-score relative to depen-
dency length.
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Adj Adv Conj Noun Prep Pron VerbPart of Speech
LAS
Parser
Malt
Mate
Figure 5: LAS for different POS tags.
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Adv Apos Coord ExD IObj Obj Pnom Pred Pred_Co Sb Sb_Ap Sb_CoDeprel
F?s
core
Parser
Malt
Mate
Figure 6: F-score for different relations.
arcs when making decisions based on local features only. We have seen that both parsers exhibit low
F1-scores (Malt: 0.36; Mate: 0.30) in detecting non-projective heads.
In Figure 5 we see that Mate?s LAS is better for all basic parts of speech. The difference is more
evident for verbs, which are typically involved in longer dependencies. Finally, it is clear from Figure
6 that certain relations are particularly difficult for both parsers. For example, indirect object (IObj)
dependents are low scoring nodes: this is because they are often attached to the correct head but are
mislabeled as adverbial dependents (Adv) or plain objects (Obj). Dependents labeled as ellipsis (ExD) or
heading appositional (Apos) constructions are also more error-prone. The same applies to nodes involved
in coordinate structures as subjects headed by coordinative conjuctions (Sb_Co). The latter show an
almost 0.3 drop in F1-score in comparison to simple subjects (Sb).
In the APL setting, errors by both parsers often involve some type of interaction between the rela-
tively free order of Greek sentences and the case feature of nominal homographs. For example, in the
case of the sentence ???????????/different ????????/figures ??????/provide ?????/three ????????/official
?????/sources ???/on ???/the ???????/unemployment (Three official sources provide different figures on
unemployment), the two nominal arguments of the verb and all of their modifiers are ambiguous as far as
case (Nominative/Accusative) is concerned. Both nominal arguments also agree with the verb in number.
These facts, in combination with the OVS order of this and similar fragments present serious challenges
to both the tagger and the parsers. In contrast, the case of the noun ???????/unemployment is easier for the
tagger to disambiguate based on the preposition+article combination preceding it. However, attaching
the whole subtree headed by the preposition is also problematic: it is part of a non-projective construction
that would probably be disallowed in languages with a more strict order.
94
6 Use of autoparsed data
Following recent efforts in exploiting automatically processed data in training (Chen et al., 2012) and in
accelerating treebank creation (Lynn et al., 2012), we conducted an experiment in extending the training
set with similar material. We used a corpus of 66 million tokens, obtained by crawling (Papavassiliou et
al., 2013) the 2009-2012 online archive of a Greek daily newspaper. We used models induced in theMPL
experiment to parse all documents in the data pool with both parsers. We then appended to the original
training set 30K randomly selected parsed sentences of 10 to 30 tokens length, for which identical trees
were generated by both parsers. After retraining both parsers and testing on the APL test set, we observed
(columns 8 and 9 of table 4) absolute LAS improvements of 0.68 and 0.52 for Maltparser andMateparser.
7 Conclusions and future work
We described a set of experiments for dependency parsing of Greek using Maltparser and Mateparser,
two well known representatives of the transition and graph-based families of parsers. Mateparser has
exhibited the best accuracy on the test partition of a recently expanded version of the Greek Dependency
Treebank, with Maltparser yielding higher scores on shorter sentences. After appending auto-parsed data
to a training set manually validated for POS and lemmas, we observed small accuracy improvements that
show room for improvement.
Scores obtained by training on datasets of different sizes in Section 4 probably indicate that apart from
adding only documents or document fragments to the treebank, we should also consider selecting specific
sentences for annotation, after measuring their informativeness and representativeness. In ongoing work,
we are investigating ways of selecting sentences for manual annotation based on how much two or more
parsers disagree, in combination with criteria like number of coordination/subordination elements and/or
number of OOV words. For this purpose, we will also experiment with more members of the two parser
families.
Our best LAS scores were obtained after mapping certain morphological features to default values.
Since these tagset mappings may not be the most efficient ones, we plan to investigate automatic tech-
niques for selecting optimal feature combinations.
Another line of research will be investigating semi-automatically mapping to different annotation
schemes like the one proposed in McDonald et al. (2013). Finally, we plan to examine, as an additional
source for resource expansion and domain adaptation, sentences from automatic dialogue transcriptions
and/or product reviews.
Acknowledgments
Work by the first author was supported by the European Union Abu-MaTran project (FP7-People-IAPP,
Grant 324414). Work by the second author was supported by the POLYTROPON project (KRIPIS-
GSRT, MIS: 448306). We would like to thank the three anonymous reviewers and our colleague Vassilis
Papavassiliou for their comments.
References
Miguel Ballesteros and Joakim Nivre. 2012. MaltOptimizer: An Optimization Tool for MaltParser. In EACL,
pages 58?62.
Alena B?hmov?, Jan Haji?, Eva Haji?ov?, and Barbora Hladk?, 2003. Treebanks: Building and Using Parsed
Corpora, chapter The Prague Dependency Treebank: A Three-Level Annotation Scenario. Kluwer.
Bernd Bohnet. 2010. Very High Accuracy and Fast Dependency Parsing is Not a Contradiction. In Proceedings
of the 23rd International Conference on Computational Linguistics, COLING ?10, pages 89?97. Association for
Computational Linguistics.
Wenliang Chen, Jun?ichi Kazama, Kiyotaka Uchimoto, and Kentaro Torisawa. 2012. Exploiting subtrees in auto-
parsed data to improve dependency parsing. Computational Intelligence, pages 426?451.
95
Johan Hall, Jens Nilsson, Joakim Nivre, G?lsen Eryigit, Be?ta Megyesi, Mattias Nilsson, and Markus Saers. 2007.
Single Malt or Blended? A Study in Multilingual Parser Optimization. In Proceedings of the CoNLL Shared
Task Session of EMNLP-CoNLL 2007, pages 933?939.
Teresa Lynn, Jennifer Foster, Mark Dras, and Elaine Dhonnchadha. 2012. Active Learning and the Irish Treebank.
In Australasian Language Technology Workshop, December.
Ryan McDonald and Joakim Nivre. 2007. Characterizing the Errors of Data-Driven Dependency Parsing Mod-
els. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-CoNLL), pages 122?131.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev,
Keith Hall, Slav Petrov, Hao Zhang, Oscar T?ckstr?m, Claudia Bedini, N?ria Bertomeu Castell?, and Jungmee
Lee. 2013. Universal Dependency Annotation for Multilingual Parsing. In Proceedings of the 51st Annual
Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 92?97, Sofia, Bul-
garia.
Tetsuji Nakagawa. 2007. Multilingual Dependency Parsing Using Global Features. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages 952?956.
Joakim Nivre, Johan Hall, Sandra K?bler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007a. The CoNLL 2007 Shared Task on Dependency Parsing. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 915?932.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G?lsen Erygit, Sandra K?bler, Svetoslav Marinov, and
Erwin Marsi. 2007b. MaltParser: A language-independent system for data-driven dependency parsing. Natural
Language Engineering, 13:95?135, 6.
Harris Papageorgiou, Prokopis Prokopidis, Voula Giouli, and Stelios Piperidis. 2000. A Unified POS Tagging
Architecture and its Application to Greek. In Proceedings of the 2nd Language Resources and Evaluation
Conference, pages 1455?1462, Athens, June. European Language Resources Association.
Vassilis Papavassiliou, Prokopis Prokopidis, and Gregor Thurmair. 2013. A modular open-source focused crawler
for mining monolingual and bilingual corpora from the web. In Proceedings of the Sixth Workshop on Building
and Using Comparable Corpora, pages 43?51, Sofia, Bulgaria, August. Association for Computational Linguis-
tics.
Prokopis Prokopidis, Elina Desypri, Maria Koutsombogera, Haris Papageorgiou, and Stelios Piperidis. 2005.
Theoretical and practical issues in the construction of a Greek Dependency Treebank. In Proceedings of the
Fourth Workshop on Treebanks and Linguistic Theories, Barcelona, Spain, December.
Hao Zhang and Ryan McDonald. 2014. Enforcing Structural Diversity in Cube-pruned Dependency Parsing. In
ACL.
96
