Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 72?75,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Combining a Two-step Conditional Random Field Model and a Joint
Source Channel Model for Machine Transliteration
Dong Yang, Paul Dixon, Yi-Cheng Pan, Tasuku Oonishi
Masanobu Nakamura and Sadaoki Furui
Department of Computer Science
Tokyo Institute of Techonology
{raymond,dixonp,thomas,oonishi,masa,furui}@furui.cs.titech.ac.jp
Abstract
This paper describes our system for
?NEWS 2009 Machine Transliteration
Shared Task? (NEWS 2009). We only par-
ticipated in the standard run, which is a
direct orthographical mapping (DOP) be-
tween two languages without using any
intermediate phonemic mapping. We
propose a new two-step conditional ran-
dom field (CRF) model for DOP machine
transliteration, in which the first CRF seg-
ments a source word into chunks and the
second CRF maps the chunks to a word
in the target language. The two-step CRF
model obtains a slightly lower top-1 ac-
curacy when compared to a state-of-the-
art n-gram joint source-channel model.
The combination of the CRF model with
the joint source-channel leads to improve-
ments in all the tasks. The official re-
sult of our system in the NEWS 2009
shared task confirms the effectiveness of
our system; where we achieved 0.627 top-
1 accuracy for Japanese transliterated to
Japanese Kanji(JJ), 0.713 for English-to-
Chinese(E2C) and 0.510 for English-to-
Japanese Katakana(E2J) .
1 Introduction
With the increasing demand for machine transla-
tion, the out-of-vocabulary (OOV) problem caused
by named entities is becoming more serious.
The translation of named entities from an alpha-
betic language (like English, French and Spanish)
to a non-alphabetic language (like Chinese and
Japanese) is usually performed through transliter-
ation, which tries to preserve the pronunciation in
the source language.
For example, in Japanese, foreign words im-
ported from other languages are usually written
H a r r i n g t o n ? ? ? ? ? English-to-Japanese
T i m o t h y ??? English-to-Chinese
Source Name       Target Name          Note
ti mo   xi                     Chinese Romanized writing
ha  ri n   to  n Japanese Romanized writing
Figure 1: Transliteration examples
in a special syllabary called Katakana; in Chi-
nese, foreign words accepted to Chinese are al-
ways written by Chinese characters; examples are
given in Figure 1.
An intuitive transliteration method is to first
convert a source word into phonemes, then find the
corresponding phonemes in the target language,
and finally convert to the target language?s writ-
ing system (Knight and Graehl, 1998; Oh et al,
2006). One major limitation of this method is that
the named entities are usually OOVs with diverse
origins and this makes the grapheme-to-phoneme
conversion very difficult.
DOP is gaining more attention in the transliter-
ation research community which is also the stan-
dard evaluation of NEWS 2009.
The source channel and joint source-channel
models (Li et al, 2004) have been proposed for
DOP, which try to model P (T |S) and P (T, S) re-
spectively, where T and S denotes the words in
the target and source languages. (Ekbal et al,
2006) modified the joint source-channel model to
incorporate different context information into the
model for the Indian languages. Here we propose
a two-step CRF model for transliteration, and the
idea is to make use of the discriminative ability of
CRF. For example, in E2C transliteration, the first
step is to segment an English name into alphabet
chunks and after this step the number of Chinese
characters is decided. The second step is to per-
form a context-dependent mapping from each En-
glish chunk into one Chinese character. Figure 1
shows that this method is applicable to many other
72
transliteration tasks including E2C and E2J.
Our CRF method and the n-gram joint source-
channel model use different information in pre-
dicting the corresponding Chinese characters and
therefore in combination better results are ex-
pected. We interpolate the two models linearly
and use this as our final system for NEWS 2009.
The rest of the paper is organized as follows: Sec-
tion 2 introduces our system in detail including the
alignment and decoding modules, Section 3 ex-
plains our experiments and finally Section 4 de-
scribes conclusions and future work.
2 System Description
Our system starts from a joint source channel
alignment to train the CRF segmenter. The CRF
is used to re-segment and align the training data,
and from this alignment we create a Weighted Fi-
nite State Transducer (WFST) based n-gram joint
source-channel decoder and a CRF E2C converter.
The following subsections explain the structure of
our system shown in Figure 2.
N-gram joint source-channel Alignment
CRF segmenter
N-gram WFST decoder CRF E2C converter
Each pair in the training corpus
New Alignment
N-gram WFST decoder
CRF E2C converter
Linear combination
Each source name in the test corpus
CRF segmenter
Tr
ai
ni
ng
Te
st
in
g
Output
Figure 2: System structure
2.1 Theoretical background
2.1.1 Joint source channel model
The source channel model represents the condi-
tional probability of target names given a source
name P (T |S). The joint source channel model
calculates how the source words and target names
are generated simultaneously (Li et al, 2004):
P (S, T ) = P (s1, s2, ..., sk, t1, t2, ..., tk)
= P (< s, t >1, < s, t >2, ..., < s, t >k)
=
K?
k=1
P (< s, t >k | < s, t >k?11 ) (1)
where, S = (s1, s2, ..., sk) and T =
(t1, t2, ..., tk).
2.1.2 CRF
A CRF (Lafferty et al, 2001) is an undirected
graphical model which assigns a probability to a
label sequence L = l1l2 . . . lT , given an input se-
quence C = c1c2 . . . cT ,
P (L|C) = 1
Z(C)
exp(
T?
t=1
?
k
?kfk(lt, lt?1, C, t))
(2)
For the kth feature, fk denotes the feature function
and ?k is the parameter which controls the weight-
ing. Z(C) is a normalization term that ensure the
distribution sums to one. CRF training is usually
performed through the L-BFGS algorithm (Wal-
lach, 2002) and decoding is performed by Viterbi
algorithm (Viterbi, 1967). In this paper, we use an
open source toolkit ?crf++?1.
2.2 N-gram joint source-channel alignment
To calculate the probability in Equation 1, the
training corpus needs to be aligned first. We use
the Expectation-Maximization(EM) algorithm to
optimize the alignment A between the source S
and target T pairs, that is:
A? = arg max
A
P (S, T,A) (3)
The procedure is summarized as follows:
1. Initialize a random alignment
2. E-step: update n-gram probability
3. M-step: apply the n-gram model to realign
each entry in corpus
4. Go to step 2 until the alignment converges
2.3 CRF alignment & segmentation
The performance of EM algorithm is often af-
fected by the initialization. Fortunately, we can
correct mis-alignments by using the discriminative
ability of the CRF. The alignment problem is con-
verted into a tagging problem that doesn?t require
the use of the target words at all. Figure 3 is an
example of a segmentation and alignment, where
the labels B and N indicate whether the character
is in the starting position of the chunk or not.
In the CRF method the feature function de-
scribes a co-occurrence relation, and it is formally
1crfpp.sourceforge.net
73
T i m o t h y ???
T/B i/N m/B o/N t/B h/N y/N
Ti/? mo/? thy/?
Figure 3: An example of the CRF segmenter for-
mat and E2C converter
defined as fk(lt, lt?1, C, t) (Eq. 2). fk is usually a
binary function, and takes the value 1 when both
observation ct and transition lt?1 ? lt are ob-
served. In our segmentation tool, we use the fol-
lowing features
? 1. Unigram features: C?2, C?1, C0, C1, C2
? 2. Bigram features:C?1C0, C0C1
Here, C0 is the current character, C?1 and C1 de-
note the previous and next characters and C?2 and
C2 are the characters two positions to the left and
right of C0.
In the alignment process, we use the CRF seg-
menter to split each English word into chunks.
Sometimes a problem occurs in which the num-
ber of chunks in the segmented output will not be
equal to the number of Chinese characters. In such
cases our solution is to choose from the n-best list
the top scoring segmentation which contains the
correct number of chunks.
In the testing process, we use the segmenter in
the similar way, but only take top-1 output seg-
mented English chunks for use in the following
CRF E2C conversion.
2.4 CRF E2C converter
Similar to the CRF segmenter, the CRF E2C con-
verter has the format shown in Figure 3. For this
CRF, we use the following features:
? 1. Unigram features: C?1, C0, C1
? 2. Bigram features:C?1C0, C0C1
where C represents the English chunks and the
subscript notation is the same as the CRF seg-
menter.
2.5 N-gram WFST decoder for joint source
channel model
Our decoding approach makes use of WFSTs to
represent the models and simplify the develop-
ment by utilizing standard operations such as com-
position and shortest path algorithms.
After the alignments are generated, the first
step is to build a corpus to train the translit-
eration WFST. Each aligned word is converted
to a sequence of transliteration alignment pairs
?s, t?1 , ?s, t?2 , ... ?s, t?k, where each s can be a
chunk of one or more characters and t is assumed
to be a single character. Each of the pairs is
treated as a word and the entire set of alignments is
used to train an n-gram language model. In these
evaluations we used the MITLM toolkit (Hsu and
Glass, 2008) to build a trigram model with modi-
fied Kneser-Ney smoothing.
We then use the procedure described in (Caseiro
et al, 2002) and convert the n-gram to a weighted
acceptor representation where each input label be-
longs to the set of transliteration alignment pairs.
Next the pairs labels are broken down into the in-
put and output parts and the acceptor is converted
to a transducer M . To allow transliteration from a
sequence of individual characters, a second WFST
T is constructed. T has a single state and for each
s a path is added to allow a mapping from the
string of individual characters.
To perform the actual transliteration, the input
word is converted to an acceptor I which has one
arc for each of the characters in the word. I is
then combined with T and M according to O =
I ?T ?M where ? denotes the composition opera-
tor. The n?best paths are extracted from O by pro-
jecting the output, removing the epsilon labels and
applying the n-shortest paths algorithm with de-
terminization from the OpenFst Toolkit(Allauzen
et al, 2007).
2.6 Linear combination
We notice that there is a significant difference be-
tween the correct answers of the n-gram WFST
and CRF decoders. The reason may be due to
the different information utilized in the two de-
coding methods. Since their performance levels
are similar, the overall performance is expected
to be improved by the combination. From the
CRF we compute the probability PCRF (T |S) and
from the list of scores output from the n-gram de-
coder we calculate the conditional probability of
Pn?gram(T |S). These are used in our combina-
tion method according to:
P (T |S) = ?PCRF (T |S)+(1??)Pn?gram(T |S)
(4)
where ? denotes the interpolation weight (0.3 in
this paper).
74
3 Experiments
We use the training and development sets of
NEWS 2009 data in our experiments as detailed
in Table 12. There are several measure metrics in
the shared task and due to limited space in this pa-
per we provide the results for top-1 accuracy.
Task Training data size Test data size
E2C 31961 2896
E2J 23808 1509
Table 1: Corpus introduction
n-gram+CRF
Task Alignment interpolation
WFST CRF
E2C 70.3 67.3 71.5
E2J 44.9 44.8 46.7
Table 2: Top-1 accuracies(%)
The results are listed in Table 2. For E2C
task the top-1 accuracy of the joint source-channel
model is 70.3% and 67.3% for the two-step CRF
model. After combining the two results together
the top-1 accuracy increases to 71.5% correspond-
ing to a 1.2% absolute improvement over the state-
of-the-art joint source-channel model. Similarly,
we get 1.8% absolute improvement for E2J task.
4 Conclusions and future work
In this paper we have presented our new hybrid
method for machine transliteration which com-
bines a new two-step CRF model with a state-of-
the-art joint source-channel model. In compari-
son to the joint source-channel model the combi-
nation approach achieved 1.2% and 1.8% absolute
improvements for E2C and E2J task respectively.
In the first step of the CRF method we only
use the top-1 segmentation, which may propagate
transliteration errors to the following step. In fu-
ture work we would like to optimize the 2-step
CRF jointly. Currently, we are also investigating
minimum classification error (MCE) discriminant
training as a method to further improve the joint
source channel model.
2For the JJ task the submitted results
are only based on the joint source
channel model. Unfortunately, we were
unable to submit a combination result
because the training time for the CRF
was too long.
Acknowledgments
The corpora used in this paper are from ?NEWS
2009 Machine Transliteration Shared Task? (Li et
al., 2004; CJK, website)
References
Kevin Knight and Jonathan Graehl. 1998. Machine
Transliteration, 1998 Association for Computa-
tional Linguistics.
Li Haizhou, Zhang Min and Su Jian. 2004. A joint
source-channel model for machine transliteration,
2004 Proceedings of the 42nd Annual Meeting on
Association for Computational Linguistics.
Asif Ekbal, Sudip Kumar Naskar and Sivaji Bandy-
opadhyay. 2006. A modified joint source-channel
model for transliteration, Proceedings of the COL-
ING/ACL, pages 191-198.
Jong-Hoon Oh, Key-Sun Choi and Hitoshi Isahara.
2006. A comparison of different machine transliter-
ation models , Journal of Artificial Intelligence Re-
search, 27, pages 119-151.
John Lafferty, Andrew McCallum, and Fernando
Pereira 2001. Conditional Random Fields: Prob-
abilistic Models for Segmenting and Labeling Se-
quence Data., Proceedings of International Confer-
ence on Machine Learning, 2001, pages 282-289.
Hanna Wallach 2002. Efficient Training of Condi-
tional Random Fields. M. Thesis, University of Ed-
inburgh, 2002.
Andrew J. Viterbi 1967. Error Bounds for Convolu-
tional Codes and an Asymptotically Optimum De-
coding Algorithm. IEEE Transactions on Informa-
tion Theory, Volume IT-13, 1967,pages 260-269.
Bo-June Hsu and James Glass 2008. Iterative Lan-
guage Model Estimation: Efficient Data Structure
& Algorithms. Proceedings Interspeech, pages 841-
844.
Diamantino Caseiro, Isabel Trancosoo, Luis Oliveira
and Ceu Viana 2002. Grapheme-to-phone using
finite state transducers. Proceedings 2002 IEEE
Workshop on Speech Synthesis.
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-
jciech Skut and Mehryar Mohri 2002. OpenFst: A
General and Efficient Weighted Finite-State Trans-
ducer Library. Proceedings of the Ninth Interna-
tional Conference on Implementation and Applica-
tion of Automata, (CIAA 2007), pages 11-23.
http://www.cjk.org
75
Proceedings of the ACL 2010 Conference Short Papers, pages 275?280,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Jointly optimizing a two-step conditional random field model for machine
transliteration and its fast decoding algorithm
Dong Yang, Paul Dixon and Sadaoki Furui
Department of Computer Science
Tokyo Institute of Technology
Tokyo 152-8552 Japan
{raymond,dixonp,furui}@furui.cs.titech.ac.jp
Abstract
This paper presents a joint optimization
method of a two-step conditional random
field (CRF) model for machine transliter-
ation and a fast decoding algorithm for
the proposed method. Our method lies in
the category of direct orthographical map-
ping (DOM) between two languages with-
out using any intermediate phonemic map-
ping. In the two-step CRF model, the first
CRF segments an input word into chunks
and the second one converts each chunk
into one unit in the target language. In this
paper, we propose a method to jointly op-
timize the two-step CRFs and also a fast
algorithm to realize it. Our experiments
show that the proposed method outper-
forms the well-known joint source channel
model (JSCM) and our proposed fast al-
gorithm decreases the decoding time sig-
nificantly. Furthermore, combination of
the proposed method and the JSCM gives
further improvement, which outperforms
state-of-the-art results in terms of top-1 ac-
curacy.
1 Introduction
There are more than 6000 languages in the world
and 10 languages of them have more than 100 mil-
lion native speakers. With the information revolu-
tion and globalization, systems that support mul-
tiple language processing and spoken language
translation become urgent demands. The transla-
tion of named entities from alphabetic to syllabary
language is usually performed through translitera-
tion, which tries to preserve the pronunciation in
the original language.
For example, in Chinese, foreign words are
written with Chinese characters; in Japanese, for-
eign words are usually written with special char-
G o o g l e ?? ? ? English-to-Japanese
G o o g l e ?? English-to-Chinese
Source Name       Target Name          Note
gu ge Chinese Romanized writing         
guu gu ru Japanese Romanized writing
Figure 1: Transliteration examples
acters called Katakana; examples are given in Fig-
ure 1.
An intuitive transliteration method (Knight and
Graehl, 1998; Oh et al, 2006) is to firstly convert
a source word into phonemes, then find the corre-
sponding phonemes in the target language, and fi-
nally convert them to the target language?s written
system. There are two reasons why this method
does not work well: first, the named entities have
diverse origins and this makes the grapheme-to-
phoneme conversion very difficult; second, the
transliteration is usually not only determined by
the pronunciation, but also affected by how they
are written in the original language.
Direct orthographical mapping (DOM), which
performs the transliteration between two lan-
guages directly without using any intermediate
phonemic mapping, is recently gaining more at-
tention in the transliteration research community,
and it is also the ?Standard Run? of the ?NEWS
2009 Machine Transliteration Shared Task? (Li et
al., 2009). In this paper, we try to make our system
satisfy the standard evaluation condition, which
requires that the system uses the provided parallel
corpus (without pronunciation) only, and cannot
use any other bilingual or monolingual resources.
The source channel and joint source channel
models (JSCMs) (Li et al, 2004) have been pro-
posed for DOM, which try to model P (T |S) and
P (T, S) respectively, where T and S denote the
words in the target and source languages. Ekbal
et al (2006) modified the JSCM to incorporate
different context information into the model for
275
Indian languages. In the ?NEWS 2009 Machine
Transliteration Shared Task?, a new two-step CRF
model for transliteration task has been proposed
(Yang et al, 2009), in which the first step is to
segment a word in the source language into char-
acter chunks and the second step is to perform a
context-dependent mapping from each chunk into
one written unit in the target language.
In this paper, we propose to jointly optimize a
two-step CRF model. We also propose a fast de-
coding algorithm to speed up the joint search. The
rest of this paper is organized as follows: Sec-
tion 2 explains the two-step CRF method, fol-
lowed by Section 3 which describes our joint opti-
mization method and its fast decoding algorithm;
Section 4 introduces a rapid implementation of a
JSCM system in the weighted finite state trans-
ducer (WFST) framework; and the last section
reports the experimental results and conclusions.
Although our method is language independent, we
use an English-to-Chinese transliteration task in
all the explanations and experiments.
2 Two-step CRF method
2.1 CRF introduction
A chain-CRF (Lafferty et al, 2001) is an undi-
rected graphical model which assigns a probability
to a label sequence L = l1l2 . . . lT , given an input
sequence C = c1c2 . . . cT . CRF training is usually
performed through the L-BFGS algorithm (Wal-
lach, 2002) and decoding is performed by the
Viterbi algorithm. We formalize machine translit-
eration as a CRF tagging problem, as shown in
Figure 2.
T i m o t h y ???
T/B i/N m/B o/N t/B h/N y/N
Ti/? mo/? thy/?
Figure 2: An pictorial description of a CRF seg-
menter and a CRF converter
2.2 CRF segmenter
In the CRF, a feature function describes a co-
occurrence relation, and it is usually a binary func-
tion, taking the value 1 when both an observa-
tion and a label transition are observed. Yang et
al. (2009) used the following features in the seg-
mentation tool:
? Single unit features: C?2, C?1, C0, C1, C2
? Combination features: C?1C0, C0C1
Here, C0 is the current character, C?1 and C1 de-
note the previous and next characters, and C?2 and
C2 are the characters located two positions to the
left and right of C0.
One limitation of their work is that only top-1
segmentation is output to the following CRF con-
verter.
2.3 CRF converter
Similar to the CRF segmenter, the CRF converter
has the format shown in Figure 2.
For this CRF, Yang et al (2009) used the fol-
lowing features:
? Single unit features: CK?1, CK0, CK1
? Combination features: CK?1CK0,
CK0CK1
where CK represents the source language chunk,
and the subscript notation is the same as the CRF
segmenter.
3 Joint optimization and its fast decoding
algorithm
3.1 Joint optimization
We denote a word in the source language by S, a
segmentation of S by A, and a word in the target
langauge by T . Our goal is to find the best word T?
in the target language which maximizes the prob-
ability P (T |S).
Yang et al (2009) used only the best segmen-
tation in the first CRF and the best output in the
second CRF, which is equivalent to
A? = arg max
A
P (A|S)
T? = arg max
T
P (T |S, A?), (1)
where P (A|S) and P (T |S,A) represent two
CRFs respectively. This method considers the seg-
mentation and the conversion as two independent
steps. A major limitation is that, if the segmenta-
tion from the first step is wrong, the error propa-
gates to the second step, and the error is very dif-
ficult to recover.
In this paper, we propose a new method to
jointly optimize the two-step CRF, which can be
276
written as:
T? = arg max
T
P (T |S)
= arg max
T
?
A
P (T,A|S)
= arg max
T
?
A
P (A|S)P (T |S,A)
(2)
The joint optimization considers all the segmen-
tation possibilities and sums the probability over
all the alternative segmentations which generate
the same output. It considers the segmentation and
conversion in a unified framework and is robust to
segmentation errors.
3.2 N-best approximation
In the process of finding the best output using
Equation 2, a dynamic programming algorithm for
joint decoding of the segmentation and conversion
is possible, but the implementation becomes very
complicated. Another direction is to divide the de-
coding into two steps of segmentation and conver-
sion, which is this paper?s method. However, exact
inference by listing all possible candidates explic-
itly and summing over all possible segmentations
is intractable, because of the exponential computa-
tion complexity with the source word?s increasing
length.
In the segmentation step, the number of possible
segmentations is 2N , where N is the length of the
source word and 2 is the size of the tagging set. In
the conversion step, the number of possible candi-
dates is MN ? , where N ? is the number of chunks
from the 1st step and M is the size of the tagging
set. M is usually large, e.g., about 400 in Chinese
and 50 in Japanese, and it is impossible to list all
the candidates.
Our analysis shows that beyond the 10th candi-
date, almost all the probabilities of the candidates
in both steps drop below 0.01. Therefore we de-
cided to generate top-10 results for both steps to
approximate the Equation 2.
3.3 Fast decoding algorithm
As introduced in the previous subsection, in the
whole decoding process we have to perform n-best
CRF decoding in the segmentation step and 10 n-
best CRF decoding in the second CRF. Is it really
necessary to perform the second CRF for all the
segmentations? The answer is ?No? for candidates
with low probabilities. Here we propose a no-loss
fast decoding algorithm for deciding when to stop
performing the second CRF decoding.
Suppose we have a list of segmentation candi-
dates which are generated by the 1st CRF, ranked
by probabilities P (A|S) in descending order A :
A1, A2, ..., AN and we are performing the 2nd
CRF decoding starting from A1. Up to Ak,
we get a list of candidates T : T1, T2, ..., TL,
ranked by probabilities in descending order. If
we can guarantee that, even performing the 2nd
CRF decoding for all the remaining segmentations
Ak+1, Ak+2, ..., AN , the top 1 candidate does not
change, then we can stop decoding.
We can show that the following formula is the
stop condition:
Pk(T1|S) ? Pk(T2|S) > 1 ?
k
?
j=1
P (Aj |S). (3)
The meaning of this formula is that the prob-
ability of all the remaining candidates is smaller
than the probability difference between the best
and the second best candidates; on the other hand,
even if all the remaining probabilities are added to
the second best candidate, it still cannot overturn
the top candidate. The mathematical proof is pro-
vided in Appendix A.
The stop condition here has no approximation
nor pre-defined assumption, and it is a no-loss fast
decoding algorithm.
4 Rapid development of a JSCM system
The JSCM represents how the source words and
target names are generated simultaneously (Li et
al., 2004):
P (S, T ) = P (s1, s2, ..., sk, t1, t2, ..., tk)
= P (< s, t >1, < s, t >2, ..., < s, t >k)
=
K
?
k=1
P (< s, t >k | < s, t >k?11 ) (4)
where S = (s1, s2, ..., sk) is a word in the source
langauge and T = (t1, t2, ..., tk) is a word in the
target language.
The training parallel data without alignment is
first aligned by a Viterbi version EM algorithm (Li
et al, 2004).
The decoding problem in JSCM can be written
as:
T? = arg max
T
P (S, T ). (5)
277
After the alignments are generated, we use the
MITLM toolkit (Hsu and Glass, 2008) to build a
trigram model with modified Kneser-Ney smooth-
ing. We then convert the n-gram to a WFST
M (Sproat et al, 2000; Caseiro et al, 2002). To al-
low transliteration from a sequence of characters,
a second WFST T is constructed. The input word
is converted to an acceptor I , and it is then com-
bined with T and M according to O = I ? T ?M
where ? denotes the composition operator. The
n?best paths are extracted by projecting the out-
put, removing the epsilon labels and applying the
n-shortest paths algorithm with determinization in
the OpenFst Toolkit (Allauzen et al, 2007).
5 Experiments
We use several metrics from (Li et al, 2009) to
measure the performance of our system.
1. Top-1 ACC: word accuracy of the top-1 can-
didate
2. Mean F-score: fuzziness in the top-1 candi-
date, how close the top-1 candidate is to the refer-
ence
3. MRR: mean reciprocal rank, 1/MRR tells ap-
proximately the average rank of the correct result
5.1 Comparison with the baseline and JSCM
We use the training, development and test sets of
NEWS 2009 data for English-to-Chinese in our
experiments as detailed in Table 1. This is a paral-
lel corpus without alignment.
Training data Development data Test data
31961 2896 2896
Table 1: Corpus size (number of word pairs)
We compare the proposed decoding method
with the baseline which uses only the best candi-
dates in both CRF steps, and also with the well
known JSCM. As we can see in Table 2, the pro-
posed method improves the baseline top-1 ACC
from 0.670 to 0.708, and it works as well as, or
even better than the well known JSCM in all the
three measurements.
Our experiments also show that the decoding
time can be reduced significantly via using our fast
decoding algorithm. As we have explained, with-
out fast decoding, we need 11 CRF n-best decod-
ing for each word; the number can be reduced to
3.53 (1 ?the first CRF?+2.53 ?the second CRF?)
via the fast decoding algorithm.
We should notice that the decoding time is sig-
nificantly shorter than the training time. While
testing takes minutes on a normal PC, the train-
ing of the CRF converter takes up to 13 hours on
an 8-core (8*3G Hz) server.
Measure Top-1 Mean MRR
ACC F-score
Baseline 0.670 0.869 0.750
Joint optimization 0.708 0.885 0.789
JSCM 0.706 0.882 0.789
Table 2: Comparison of the proposed decoding
method with the previous method and the JSCM
5.2 Further improvement
We tried to combine the two-step CRF model and
the JSCM. From the two-step CRF model we get
the conditional probability PCRF (T |S) and from
the JSCM we get the joint probability P (S, T ).
The conditional probability of PJSCM(T |S) can
be calculuated as follows:
PJSCM (T |S) =
P (T, S)
P (S) =
P (T, S)
?
T P (T, S)
. (6)
They are used in our combination method as:
P (T |S) = ?PCRF (T |S) + (1 ? ?)PJSCM (T |S)
(7)
where ? denotes the interpolation weight (? is set
by development data in this paper).
As we can see in Table 3, the linear combination
of two sytems further improves the top-1 ACC to
0.720, and it has outperformed the best reported
?Standard Run? (Li et al, 2009) result 0.717. (The
reported best ?Standard Run? result 0.731 used
target language phoneme information, which re-
quires a monolingual dictionary; as a result it is
not a standard run.)
Measure Top-1 Mean MRR
ACC F-score
Baseline+JSCM 0.713 0.883 0.794
Joint optimization
+ JSCM 0.720 0.888 0.797
state-of-the-art 0.717 0.890 0.785
(Li et al, 2009)
Table 3: Model combination results
6 Conclusions and future work
In this paper we have presented our new joint
optimization method for a two-step CRF model
and its fast decoding algorithm. The proposed
278
method improved the system significantly and out-
performed the JSCM. Combining the proposed
method with JSCM, the performance was further
improved.
In future work we are planning to combine our
system with multilingual systems. Also we want
to make use of acoustic information in machine
transliteration. We are currently investigating dis-
criminative training as a method to further im-
prove the JSCM. Another issue of our two-step
CRF method is that the training complexity in-
creases quadratically according to the size of the
label set, and how to reduce the training time needs
more research.
Appendix A. Proof of Equation 3
The CRF segmentation provides a list of segmen-
tations: A : A1, A2, ..., AN , with conditional
probabilities P (A1|S), P (A2|S), ..., P (AN |S).
N
?
j=1
P (Aj |S) = 1.
The CRF conversion, given a segmenta-
tion Ai, provides a list of transliteration out-
put T1, T2, ..., TM , with conditional probabilities
P (T1|S,Ai), P (T2|S,Ai), ..., P (TM |S,Ai).
In our fast decoding algorithm, we start per-
forming the CRF conversion from A1, then A2,
and then A3, etc. Up to Ak, we get a list of can-
didates T : T1, T2, ..., TL, ranked by probabili-
ties Pk(T |S) in descending order. The probability
Pk(Tl|S)(l = 1, 2, ..., L) is accumulated probabil-
ity of P (Tl|S) over A1, A2, ..., Ak , calculated by:
Pk(Tl|S) =
k
?
j=1
P (Aj |S)P (Tl|S,Aj)
If we continue performing the CRF conversion
to cover all N (N ? k) segmentations, eventually
we will get:
P (Tl|S) =
N
?
j=1
P (Aj |S)P (Tl|S,Aj)
?
k
?
j=1
P (Aj |S)P (Tl|S,Aj)
= Pk(Tl|S) (8)
If Equation 3 holds, then for ?i 6= 1,
Pk(T1|S) > Pk(T2|S) + (1 ?
k
?
j=1
P (Aj |S))
? Pk(Ti|S) + (1 ?
k
?
j=1
P (Aj |S))
= Pk(Ti|S) +
N
?
j=k+1
P (Aj |S)
? Pk(Ti|S)
+
N
?
j=k+1
P (Aj |S)P (Ti|S,Aj)
= P (Ti|S) (9)
Therefore, P (T1|S) > P (Ti|S)(i 6= 1), and T1
maximizes the probability P (T |S).
279
References
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-
jciech Skut and Mehryar Mohri 2007. OpenFst: A
General and Efficient Weighted Finite-State Trans-
ducer Library. Proceedings of the Ninth Interna-
tional Conference on Implementation and Applica-
tion of Automata, (CIAA), pages 11-23.
Diamantino Caseiro, Isabel Trancosoo, Luis Oliveira
and Ceu Viana 2002. Grapheme-to-phone using fi-
nite state transducers. Proceedings IEEE Workshop
on Speech Synthesis.
Asif Ekbal, Sudip Kumar Naskar and Sivaji Bandy-
opadhyay. 2006. A modified joint source-channel
model for transliteration, Proceedings of the COL-
ING/ACL, pages 191-198.
Bo-June Hsu and James Glass 2008. Iterative Lan-
guage Model Estimation: Efficient Data Structure
& Algorithms. Proceedings Interspeech, pages 841-
844.
Kevin Knight and Jonathan Graehl. 1998. Machine
Transliteration, Association for Computational Lin-
guistics.
John Lafferty, Andrew McCallum, and Fernando
Pereira 2001. Conditional Random Fields: Prob-
abilistic Models for Segmenting and Labeling Se-
quence Data., Proceedings of International Confer-
ence on Machine Learning, pages 282-289.
Haizhou Li, Min Zhang and Jian Su. 2004. A joint
source-channel model for machine transliteration,
Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics.
Haizhou Li, A. Kumaran, Vladimir Pervouchine and
Min Zhang 2009. Report of NEWS 2009 Ma-
chine Transliteration Shared Task, Proceedings of
the 2009 Named Entities Workshop: Shared Task on
Transliteration (NEWS 2009), pages 1-18
Jong-Hoon Oh, Key-Sun Choi and Hitoshi Isahara.
2006. A comparison of different machine transliter-
ation models , Journal of Artificial Intelligence Re-
search, 27, pages 119-151.
Richard Sproat 2000. Corpus-Based Methods and
Hand-Built Methods. Proceedings of International
Conference on Spoken Language Processing, pages
426-428.
Andrew J. Viterbi 1967. Error Bounds for Convolu-
tional Codes and an Asymptotically Optimum De-
coding Algorithm. IEEE Transactions on Informa-
tion Theory, Volume IT-13, pages 260-269.
Hanna Wallach 2002. Efficient Training of Condi-
tional Random Fields. M. Thesis, University of Ed-
inburgh.
Dong Yang, Paul Dixon, Yi-Cheng Pan, Tasuku Oon-
ishi, Masanobu Nakamura and Sadaoki Furui 2009.
Combining a Two-step Conditional Random Field
Model and a Joint Source Channel Model for Ma-
chine Transliteration, Proceedings of the 2009
Named Entities Workshop: Shared Task on Translit-
eration (NEWS 2009), pages 72-75
280
Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 1?9,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Dialect Translation:
Integrating Bayesian Co-segmentation Models with Pivot-based SMT
Michael Paul and Andrew Finch and Paul R. Dixon and Eiichiro Sumita
National Institute of Information and Communications Technology
MASTAR Project
Kyoto, Japan
michael.paul@nict.go.jp
Abstract
Recent research on multilingual statistical ma-
chine translation (SMT) focuses on the usage
of pivot languages in order to overcome re-
source limitations for certain language pairs.
This paper proposes a new method to translate
a dialect language into a foreign language by
integrating transliteration approaches based
on Bayesian co-segmentation (BCS) models
with pivot-based SMT approaches. The ad-
vantages of the proposed method with respect
to standard SMT approaches are three fold:
(1) it uses a standard language as the pivot lan-
guage and acquires knowledge about the re-
lation between dialects and the standard lan-
guage automatically, (2) it reduces the transla-
tion task complexity by using monotone de-
coding techniques, (3) it reduces the num-
ber of features in the log-linear model that
have to be estimated from bilingual data. Ex-
perimental results translating four Japanese
dialects (Kumamoto, Kyoto, Okinawa, Os-
aka) into four Indo-European languages (En-
glish, German, Russian, Hindi) and two Asian
languages (Chinese, Korean) revealed that
the proposed method improves the translation
quality of dialect translation tasks and outper-
forms standard pivot translation approaches
concatenating SMT engines for the majority
of the investigated language pairs.
1 Introduction
The translation quality of SMT approaches heavily
depends on the amount and coverage of the bilin-
gual language resources available to train the statis-
tical models. There are several data collection ini-
tiatives1 amassing and distributing large amounts of
textual data. For frequently used language pairs like
French-English, large-sized text data sets are read-
ily available. However, for less frequently used lan-
guage pairs, only a limited amount of bilingual re-
sources are available, if any at all.
In order to overcome language resource limi-
tations, recent research on multilingual SMT fo-
cuses on the use of pivot languages (de Gispert and
Marino, 2006; Utiyama and Isahara, 2007; Wu and
Wang, 2007; Bertoldi et al, 2008; Koehn et al,
2009). Instead of a direct translation between two
languages where only a limited amount of bilingual
resources is available, the pivot translation approach
makes use of a third language that is more appropri-
ate due to the availability of more bilingual corpora
and/or its relatedness to the source/target language.
In most of the previous research, English has been
the pivot language of choice due to the richness of
available language resources. However, recent re-
search on pivot translation has shown that the usage
of non-English pivot languages can improve trans-
lation quality of certain language pairs, especially
when translating from or into Asian languages (Paul
et al, 2009).
This paper focuses on the translation of dialects,
i.e., a variety of a language that is characteristic of
a particular group of the language?s speakers, into
a foreign language. A standard dialect (or stan-
dard language) is a dialect that is recognized as
the ?correct? spoken and written form of the lan-
guage. Dialects typically differ in terms of mor-
phology, vocabulary and pronunciation. Various
1LDC: http://www.ldc.upenn.edu, ELRA: http://www.elra.info
1
methods have been proposed to measure relatedness
between dialects using phonetic distance measures
(Nerbonne and Heeringa, 1997), string distance al-
gorithms (Heeringa et al, 2006; Scherrer, 2007), or
statistical models (Chitturi and Hansen, 2008).
Concerning data-driven natural language process-
ing (NLP) applications like machine translation
(MT), however, linguistic resources and tools usu-
ally are available for the standard language, but not
for dialects. In order to create dialect language re-
sources, previous research utilized explicit knowl-
edge about the relation between the standard lan-
guage and the dialect using rule-based and statistical
models (Habash et al, 2005; Sawaf, 2010). In addi-
tion, applying the linguistic tools for the standard
language to dialect resources is often insufficient.
For example, the task of word segmentation, i.e.,
the identification of word boundaries in continuous
text, is one of the fundamental preprocessing steps
of MT applications. In contrast to Indo-European
languages like English, many Asian languages like
Japanese do not use a whitespace character to sep-
arate meaningful word units. However, the applica-
tion of a linguistically motivated standard language
word segmentation tool to a dialect corpus results
in a poor segmentation quality due to morphological
differences in verbs and adjectives, thus resulting in
a lower translation quality for SMT systems that ac-
quire the translation knowledge automatically from
a parallel text corpus (Paul et al, 2011).
This paper differs from previous research in the
following aspects:
? it reduces the data sparseness problem of di-
rect translation approaches by translating a
resource-limited dialect language into a foreign
language by using the resource-rich standard
language as the pivot language.
? it is language independent and acquires knowl-
edge about the relation between the standard
language and the dialect automatically.
? it avoids segmentation mismatches between the
input and the translation model by mapping the
characterized dialect language, i.e., each char-
acter is treated as a single token, to the word
segmentation of the standard language using a
Bayesian co-segmentation model.
? it reduces the translation task complexity by us-
ing monotone decoding techniques.
? it reduces the number of features in the log-
linear model that have to be estimated from
bilingual data.
The details of the proposed dialect translation
method are described in Section 2. Experiments
were carried out for the translation of four Japanese
dialects (Kumamoto, Kyoto, Okinawa, Osaka) into
four Indo-European languages (English, German,
Russian, Hindi) and two Asian languages (Chinese,
Korean). The utilized language resources and the
outline of the experiments are summarized in Sec-
tion 3. The results reveal that the integration of
Bayesian co-segmentation models with pivot-based
SMT improves the translation quality of dialect to
foreign language translation tasks and that the pro-
posed system outperforms standard pivot translation
approaches concatenating SMT engines that trans-
late the dialect into the standard language and the
standard language MT output into the foreign lan-
guage for the majority of the investigated language
pairs.
2 Dialect Translation
Spoken language translation technologies attempt to
bridge the language barriers between people with
different native languages who each want to engage
in conversation by using their mother-tongue. For
standard languages, multilingual speech translation
services like the VoiceTra2 system for travel conver-
sations are readily available. However, such tech-
nologies are not capable of dealing with dialect lan-
guages due to the lack of language resources and the
high development costs of building speech transla-
tion components for a large number of dialect varia-
tions.
In order to reduce such problems, the dialect
translation method proposed in this paper integrates
two different methods of transducing a given dialect
input sentence into a foreign language. In the first
step, the close relationship between the local and
standard language is exploited to directly map char-
acter sequences in the dialect input to word seg-
ments in the standard language using a Bayesian co-
2http://mastar.jp/translation/voicetra-en.html
2
segmentation approach, details of which are given in
Section 2.1. The proposed transliteration method is
described in Section 2.2. The advantages of the pro-
posed Bayesian co-segmentation approach are two
fold: it reduces the translation complexity and it
avoids segmentation inconsistencies between the in-
put and the translation models. In the second step,
a state-of-the-art phrase-based SMT system trained
on a large amount of bilingual data is applied to ob-
tain high-quality foreign language translations as de-
scribed in Section 2.3.
2.1 Bayesian Co-segmentation
The method for mapping the dialect sentences into
the standard language word segments is a direct
character-to-character mapping between the lan-
guages. This process is known as translitera-
tion. Many transliteration methods have previously
been proposed, including methods based on string-
similarity measures between character sequences
(Noeman and Madkour, 2010) or generation-based
models (Lee and Chang, 2003; Tsuji and Kageura,
2006; Jiampojamarn et al, 2010).
In this paper, we use a generative Bayesian model
similar to the one from (DeNero et al, 2008) which
offers several benefits over standard transliteration
techniques: (1) the technique has the ability to train
models whilst avoiding over-fitting the data, (2)
compact models that have only a small number of
well-chosen parameters are constructed, (3) the un-
derlying generative transliteration model is based on
the joint source-channel model (Li et al, 2004), and
(4) the model is symmetric with respect to source
and target language. Intuitively, the model has two
basic components: a model for generating an out-
come that has already been generated at least once
before, and a second model that assigns a probabil-
ity to an outcome that has not yet been produced.
Ideally, to encourage the re-use of model parame-
ters, the probability of generating a novel bilingual
sequence pair should be considerably lower then the
probability of generating a previously observed se-
quence pair. The probability distribution over these
bilingual sequence pairs (including an infinite num-
ber of unseen pairs) can be learned directly from un-
labeled data by Bayesian inference of the hidden co-
segmentation of the corpus.
The co-segmentation process is driven by a
Dirichlet process, which is a stochastic process de-
fined over a set S (in our case, the set of all pos-
sible bilingual sequence pairs) whose sample path
is a probability distribution on S. The underlying
stochastic process for the generation of a corpus
composed of bilingual phrase pairs (sk,tk) can be
written in the following form:
G|?,G0 ? DP (?,G0)
(sk, tk)|G ? G (1)
G is a discrete probability distribution over all
the bilingual sequence pairs according to a Dirichlet
process prior with a base measure G0 and concen-
tration parameter ?. The concentration parameter
? > 0 controls the variance of G; intuitively, the
larger ? is, the more similar G0 will be to G.
For the base measure that controls the genera-
tion of novel sequence pairs, we use a joint spelling
model that assigns probability to new sequence pairs
according to the following joint distribution:
G0((s, t)) = p(|s|)p(s||s|)? p(|t|)p(t||t|)
= ?
|s|
s
|s|! e
??sv?|s|s ?
?|t|t
|t|! e
??tv?|t|t (2)
where |s| and |t| are the length in characters of
the source and target sides of the bilingual sequence
pair; vs and vt are the vocabulary sizes of the source
and target languages respectively; and ?s and ?t are
the expected lengths3 of the source and target.
According to this model, source and target se-
quences are generated independently: in each case
the sequence length is chosen from a Poisson dis-
tribution, and then the sequence itself is generated
given the length. Note that this model is able to
assign a probability to arbitrary bilingual sequence
pairs of any length in the source and target sequence,
but favors shorter sequences in both.
The generative model is given in Equation 3. The
equation assigns a probability to the kth bilingual
sequence pair (sk, tk) in a derivation of the corpus,
given all of the other sequence pairs in the history so
far (s?k, t?k). Here ?k is read as: ?up to but not
including k?.
p((sk, tk))|(s?k, t?k))
= N((sk, tk)) + ?G0((sk, tk))N + ? (3)
3Following (Xu et al, 2008), we assign the parameters ?s,
?t and ?, the values 2, 2 and 0.3 respectively.
3
Input: Random initial corpus segmentation
Output: Unsupervised co-segmentation of the corpus
according to the model
foreach iter=1 to NumIterations do
foreach bilingual word-pair w ? randperm(W) do
foreach co-segmentation ?i of w do
Compute probability p(?i|h)
where h is the set of data (excluding w) and
its hidden co-segmentation
end
Sample a co-segmentation ?i from the
distribution p(?i|h)
Update counts
end
end
Algorithm 1: Blocked Gibbs Sampling
In this equation, N is the total number of bilingual
sequence pairs generated so far and N((sk, tk)) is
the number of times the sequence pair (sk, tk) has
occurred in the history. G0 and ? are the base mea-
sure and concentration parameter as before.
We used a blocked version of a Gibbs sampler
for training, which is similar to that of (Mochihashi
et al, 2009). We extended their forward filtering
/ backward sampling (FFBS) dynamic programing
algorithm in order to deal with bilingual segmenta-
tions (see Algorithm 1). We found our sampler con-
verged rapidly without annealing. The number of
iterations was set by hand after observing the con-
vergence behavior of the algorithm in pilot experi-
ments. We used a value of 75 iterations through the
corpus in all experiments reported in this paper. For
more details on the Bayesian co-segmentation pro-
cess, please refer to (Finch and Sumita, 2010).
2.2 Dialect to Standard Language
Transduction
A Bayesian segmentation model is utilized to trans-
form unseen dialect sentences into the word seg-
mentation of the standard language by using the
joint-source channel framework proposed by (Li et
al., 2004). The joint-source channel model, also
called the n-gram transliteration model, is a joint
probability model that captures information on how
the source and target sentences can be generated
simultaneously using transliteration pairs, i.e., the
most likely sequence of source characters and tar-
get words according to a joint language model built
from the co-segmentation from the Bayesian model.
Suppose that we have a dialect sentence ? =
l1l2 . . . lL and a standard language sentence ? =
s1s2 . . . sS where li are dialect characters, sj are
word tokens of the standard language, and there
exists an alignment ? =< l1 . . . lq, s1 >, . . . , <
lr . . . lL, sS >, 1 ? q < r ? L of K translitera-
tion units. Then, an n-gram transliteration model is
defined as the transliteration probability of a translit-
eration pair < l, s >k depending on its immediate n
preceding transliteration pairs:
P (?, ?, ?) =
K
?
k=1
P (< l, s >k|< l, s >k?1k?n+1) (4)
For the experiments reported in this paper, we im-
plemented the joint-source channel model approach
as a weighted finite state transducer (FST) using
the OpenFst toolkit (Allauzen et al, 2007). The
FST takes the sequence of dialect characters as its
input and outputs the co-segmented bilingual seg-
ments from which the standard language segments
are extracted.
2.3 Pivot-based SMT
Recent research on speech translation focuses on
corpus-based approaches, and in particular on statis-
tical machine translation (SMT), which is a machine
translation paradigm where translations are gener-
ated on the basis of statistical models whose param-
eters are derived from the analysis of bilingual text
corpora. SMT formulates the problem of translat-
ing a source language sentence src into a target lan-
guage sentence trg as a maximization problem of
the conditional probability:
argmaxtrg p(src|trg) ? p(trg) (5)
where p(src|trg) is called a translation model
(TM ) and represents the generation probability
from trg into src, and p(trg) is called a language
model (LM ) and represents the likelihood of the tar-
get language (Brown et al, 1993). During the trans-
lation process (decoding), a score based on the sta-
tistical model probabilities is assigned to each trans-
lation hypothesis and the one that gives the highest
probability is selected as the best translation.
The translation quality of SMT approaches heav-
ily depends on the amount and coverage of the bilin-
gual language resources available to train the statis-
tical models. In the context of dialect translation,
4
where only few bilingual language resources (if any
at all) are available for the dialect and the foreign
language, only a relatively low translation quality
can be obtained. In order to obtain better transla-
tions, we apply a pivot translation approach. Pivot
translation is the translation from a source language
(SRC) to a target language (TRG) through an inter-
mediate pivot (or bridging) language (PVT). In this
paper, we select the standard language as the pivot
language.
Within the SMT framework, various coupling
strategies like cascading, phrase-table composition,
or pseudo-corpus generation have been proposed.
For the experiments reported in this paper, we uti-
lized the cascading approach because it is compu-
tational less expensive, but still performs compara-
bly well compared to the other pivot translation ap-
proaches. In the first step, the dialect input is tran-
scribed into the standard language as described in
Section 2.1. Next, the obtained standard language
MT output is translated into the target language us-
ing SMT models trained on the much larger lan-
guage resources.
3 Experiments
The effects of integrating Bayesian co-segmentation
models with pivot-based SMT are investigated using
the Basic Travel Expressions Corpus (BTEC), which
is a collection of sentences that bilingual travel ex-
perts consider useful for people traveling abroad
(Kikui et al, 2006). For the dialect translation ex-
periments, we selected Japanese (ja), a language that
does not naturally separate word units, and the di-
alects from the Kumamoto (jaku), Kyoto (jaky), Ok-
inawa (jaok), and Osaka (jaos) areas. All dialects
share the same Japanese writing system that com-
bines logographic Chinese characters and two syl-
labic scripts, i.e., hiragana (used for native Japanese
words) and katakana (used for foreign loanwords
or onomatopoeia). For the target language, we in-
vestigated four Indo-European languages, i.e., En-
glish (en), German (de), Russian (ru), and Hindi
(hi) and two Asian languages, i.e., Chinese (zh)
and Korean (ko). The corpus statistics are summa-
rized in Table 1, where Voc specifies the vocabulary
size and Len the average sentence length of the re-
spective data sets. These languages differ largely
Table 1: Language Resources
Language Voc Len Order Unit Infl
Japanese ja 17,168 8.5 SOV none moderate
English en 15,390 7.5 SVO word moderate
German de 25,716 7.1 SVO word high
Russian ru 36,199 6.4 SVO word high
Hindi hi 33,629 7.8 SOV word high
Chinese zh 13,343 6.8 SVO none light
Korean ko 17,246 8.1 SOV phrase moderate
in word order (Order: subject-object-verb (SOV),
subject-verb-object (SVO)), segmentation unit (Unit:
phrase, word, none), and degree of inflection (Infl:
high, moderate, light). Concerning word segmenta-
tion, the corpora were preprocessed using language-
specific word segmentation tools that are widely-
accepted within the MT community for languages
that do not use white spaces to separate word/phrase
tokens, i.e., CHASEN4 for Japanese and ICTCLAS5
for Chinese. For all other languages, simple to-
kenization tools were applied. All data sets were
case-sensitive with punctuation marks preserved.
The language resources were randomly split into
three subsets for the evaluation of translation quality
(eval, 1k sentences), the tuning of the SMT model
weights (dev, 1k sentences) and the training of the
statistical models (train, 160k sentences). For the
dialect languages, a subset of 20k sentences was
used for the training of translation models for all
of the resource-limited language pairs. In order to
avoid word segmentation errors from the standard
language segmentation tool beeing applied to dialect
resources, these models are trained on bitext, where
the local dialect source sentence is characterized and
the target language is segmented using language-
specific segmentation tools.
For the training of the SMT models, standard word
alignment (Och and Ney, 2003) and language mod-
eling (Stolcke, 2002) tools were used. Minimum
error rate training (MERT) was used to tune the de-
coder?s parameters on the dev set using the technique
proposed in (Och and Ney, 2003). For the trans-
lation, an inhouse multi-stack phrase-based decoder
was used. For the evaluation of translation quality,
we applied the standard automatic evaluation metric
4http://chasen-legacy.sourceforge.jp
5http://www.nlp.org.cn
5
Table 2: SMT-based Direct Translation Quality
BLEU (%)
SRC ja jaku jaky jaok jaos
TRG (160k) (20k) (20k)
en 56.51 32.84 32.27 31.81 30.99 31.97
de 51.73 26.24 25.06 25.71 24.37 25.18
ru 50.34 23.67 23.12 23.19 22.30 22.07
hi 49.99 21.10 20.46 20.40 19.72 20.96
zh 48.59 33.80 32.72 33.15 32.66 32.96
ko 64.52 53.31 52.93 51.24 49.40 51.57
BLEU, which calculates the geometric mean of n-
gram precision by the system output with respect to
reference translations with the addition of a brevity
penalty to punish short sentences. Scores range be-
tween 0 (worst) and 1 (best) (Papineni et al, 2002).
For the experiments reported here, single translation
references were used.
3.1 Direct Translation
Table 2 summarizes the translation performance of
the SMT engines used to directly translate the source
language dialects into the foreign language. For
the large training data condition (160k), the high-
est BLEU scores are obtained for the translation of
Japanese into Korean followed by English, German,
Russian, and Hindi with Chinese seeming to be the
most difficult translation task out of the investigated
target languages. For the standard language (ja), the
translation quality for the small data condition (20k)
that corresponds to the language resources used for
the translation of the dialect languages is also given.
For the Asian target languages, gains of 11%?14%
BLEU points are obtained when increasing the train-
ing data size from 20k to 160k. However, an even
larger increase (24%?27% BLEU points) in trans-
lation quality can be seen for all Indo-European tar-
get languages. Therefore, larger gains are to be
expected when the pivot translation framework is
applied to the translation of dialect languages into
Indo-European languages compared to Asian target
languages. Comparing the evaluation results for the
small training data condition, the highest scores are
achieved for the standard language for all target lan-
guages, indicating the difficulty in translating the di-
alects. Moreover, the Kumamoto dialect seems to be
the easiest task, followed by the Kyoto dialect and
the Osaka dialect. The lowest BLEU scores were
Table 3: SMT-based Pivot Translation Quality
BLEU (%)
SRC jaku jaky jaok jaos
TRG (SMTSRC?ja+SMTja?TRG)
en 52.10 50.66 45.54 49.50
de 47.51 46.33 39.42 44.82
ru 44.59 43.83 38.25 42.87
hi 45.89 44.01 36.87 42.95
zh 45.14 44.26 40.96 44.20
ko 60.76 59.67 55.59 58.62
obtained for the translation of the Okinawa dialect.
3.2 SMT-based Pivot Translation
The SMT engines of Table 2 are then utilized within
the framework of the SMT-based pivot translation
by (1) translating the dialect input into the stan-
dard language using the SMT engines trained on the
20k data sets and (2) translating the standard lan-
guage MT output into the foreign language using
the SMT engines trained on the 160k data sets. The
translation quality of the SMT-based pivot transla-
tion experiments are summarized in Table 3. Large
gains of 6.2%?25.4% BLEU points compared to
the direct translation results are obtained for all in-
vestigated language pairs, showing the effectiveness
of pivot translation approaches for resource-limited
language pairs. The largest gains are obtained for
jaku, followed by jaos, jaky, and jaok. Therefore, the
easier the translation task, the larger the improve-
ments of the pivot translation approach.
3.3 Bayesian Co-segmentation Model
The proposed method differs from the standard pivot
translation approach in that a joint-source channel
transducer trained from a Bayesian co-segmentation
of the training corpus is used to transliterate the di-
alect input into the standard language, as described
in Section 2.2. This process generates the co-
segmented bilingual segments simultaneously in a
monotone way, i.e., the order of consecutive seg-
ments on the source side as well as on the target side
are the same. Similarly, the decoding process of the
SMT approaches can also be carried out monotoni-
cally. In order to investigate the effect of word order
differences for the given dialect to standard language
transduction task, Table 4 compares the transla-
tion performance of SMT approaches with (reorder-
6
Table 4: Dialect to Standard Language Transduction
BLEU (%)
SRC jaku jaky jaok jaos
Engine (decoding) (SRC?ja)
BCS (monotone) 91.55 86.74 80.36 85.04
SMT (monotone) 88.39 84.87 74.27 82.86
(reordering) 88.39 84.73 74.26 82.66
ing) and without (monotone) distortion models to
the monotone Bayesian co-segmentation approach
(BCS). Only minor differences between SMT decod-
ing with and without reordering are obtained. This
shows that the grammatical structure of the dialect
sentences and the standard language sentences are
very similar, thus justifying the usage of monotone
decoding strategies for the given task. The compari-
son of the SMT-based and the BCS-based transduc-
tion of the dialect sentences into the standard lan-
guage shows that the Bayesian co-segmentation ap-
proach outperforms the SMT approach significantly,
gaining 1.9% / 2.2% / 3.2% / 6.1% BLEU points for
jaky / jaos / jaku / jaok, respectively.
3.4 BCS-based Pivot Translation
The translation quality of the proposed method,
i.e. the integration of the Bayesian co-segmentation
models into the pivot translation framework, are
given in Table 5. The overall gains of the proposed
method compared to (a) the direct translation ap-
proach (see Table 2) and (b) the SMT-based pivot
translation approach (see Table 3) are summarized in
Table 6. The results show that the BCS-based pivot
translation approach also largely outperforms the
direct translation approach, gaining 5.9%?25.3%
BLEU points. Comparing the two pivot translation
approaches, the proposed BCS-based pivot transla-
tion method gains up to 0.8% BLEU points over
the concatenation of SMT engines for the Indo-
European target languages, but is not able to im-
prove the translation quality for translating into Ko-
rean and Chinese. Interestingly, the SMT-based
pivot translation approach seems to be better for lan-
guage pairs where only small relative gains from the
pivot translation approach are achieved when trans-
lating the dialect into a foreign language. For exam-
ple, Korean is a language closely related to Japanese
and the SMT models from the small data condition
already seem to cover enough information to suc-
Table 5: BCS-based Pivot Translation Quality
BLEU (%)
SRC jaku jaky jaok jaos
TRG (BCSSRC?ja+SMTja?TRG)
en 52.42 50.68 45.58 50.22
de 47.52 46.74 39.93 45.60
ru 45.29 44.08 38.39 43.53
hi 45.72 44.71 37.60 43.56
zh 45.15 43.92 40.15 44.06
ko 60.26 59.14 55.33 58.13
Table 6: Gains of BCS-based Pivot Translation
BLEU (%)
SRC jaku jaky jaok jaos
TRG on SMT-based Pivot (Direct) Translation
en +0.32 +0.02 +0.04 +0.72
(+20.15) (+18.87) (+14.59) (+18.25)
de +0.01 +0.41 +0.51 +0.78
(+22.46) (+21.03) (+15.56) (+20.50)
ru +0.70 +0.25 +0.14 +0.66
(+22.17) (+20.89) (+16.09) (+21.46)
hi -0.17 +0.70 +0.73 +0.61
(+25.26) (+24.31) (+17.88) (+22.60)
zh +0.01 -0.34 -0.81 -0.14
(+12.43) (+10.77) (+7.49) (+11.10)
ko -0.50 -0.53 -0.26 -0.49
(+7.33) (+7.90) (+5.93) (+6.56)
cessfully translate the dialect languages into Korean.
In the case of Chinese, the translation quality for
even the large data condition SMT engines is rela-
tively low. Therefore, improving the quality of the
standard language input might have only a small im-
pact on the overall pivot translation performance, if
any at all. On the other hand, the proposed method
can be successfully applied for the translation of lan-
guage pairs where structural differences have a large
impact on the translation quality. In such a transla-
tion task, the more accurate transduction of the di-
alect structure into the standard language can affect
the overall translation performance positively.
4 Conclusion
In this paper, we proposed a new dialect transla-
tion method for resource-limited dialect languages
within the framework of pivot translation. In the first
step, a Bayesian co-segmentation model is learned
to transduce character sequences in the dialect sen-
tences into the word segmentation of the standard
7
language. Next, an FST-based joint-source channel
model is applied to unseen dialect input sentences to
monotonically generate co-segmented bilingual seg-
ments from which the standard language segments
are extracted. The obtained pivot sentence is then
translated into the foreign language using a state-of-
the-art phrase-based SMT engine trained on a large
corpus.
Experiments were carried out for the translation
of four Japanese dialects into four Indo-European
as well as into two Asian languages. The re-
sults revealed that the Bayesian co-segmentation
method largely improves the quality of the stan-
dard language sentence generated from a dialect in-
put compared to SMT-based translation approaches.
Although significant improvements of up to 0.8%
in BLEU points are achieved for certain target
languages, such as all of the investigated Indo-
European languages, it is difficult to transfer the
gains obtained by the Bayesian co-segmentation
model to the outcomes for the pivot translation
method.
Further research will have to investigate features
like language relatedness, structural differences,
and translation model complexity to identify indica-
tors of translation quality that could enable the selec-
tion of BCS-based vs. SMT-based pivot translation
approaches for specific language pairs to improve
the overall system performance further.
In addition we would like to investigate the ef-
fects of using the proposed method for translating
foreign languages into dialect languages. As the
Bayesian co-segmentation model is symmetric with
respect to source and target language, we plan to
reuse the models learned for the experiments pre-
sented in this paper and hope to obtain new insights
into the robustness of the Bayesian co-segmentation
method when dealing with noisy data sets like ma-
chine translation outputs.
Acknowledgments
This work is partly supported by the Grant-in-Aid
for Scientific Research (C) Number 19500137.
References
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-
jciech Skut, and Mehryar Mohri. 2007. Open-
Fst: A General and Efficient Weighted Finite-State
Transducer Library. In Proc. of the 9th Interna-
tional Conference on Implementation and Application
of Automata, (CIAA 2007), volume 4783 of Lecture
Notes in Computer Science, pages 11?23. Springer.
http://www.openfst.org.
Nicola Bertoldi, Madalina Barbaiani, Marcello Federico,
and Roldano Cattoni. 2008. Phrase-Based statistical
machine translation with Pivot Languages. In Proc. of
the 5th International Workshop on Spoken Language
Translation (IWSLT), pages 143?149, Hawaii, USA.
Peter Brown, Stephen Della Pietra, Vincent Della Pietra,
and Robert Mercer. 1993. The mathematics of statis-
tical machine translation: Parameter estimation. Com-
putational Linguistics, 19(2):263?311.
Ragul Chitturi and John Hansen. 2008. Dialect Clas-
sification for online podcasts fusing Acoustic and
Language-based Structural and Semantic Information.
In Proc. of the 46th Annual Meeting of the Associa-
tion for Computational Linguistics - Human Language
Technologies (ACL-HLT), Companion Volume, pages
21?24, Columbus, USA.
Adria de Gispert and Jose B. Marino. 2006. Catalan-
English statistical machine translation without paral-
lel corpus: bridging through Spanish. In Proc. of 5th
International Conference on Language Resources and
Evaluation (LREC), pages 65?68, Genoa, Italy.
John DeNero, Alex Bouchard-Co?te?, and Dan Klein.
2008. Sampling Alignment Structure under a
Bayesian Translation Model. In Proc. of Conference
on Empirical Methods on Natural Language Process-
ing (EMNLP), Hawaii, USA.
Andrew Finch and Eiichiro Sumita. 2010. A Bayesian
Model of Bilingual Segmentation for Transliteration.
In Proc. of the 7th International Workshop on Spoken
Language Translation (IWSLT), pages 259?266, Paris,
France.
Nizar Habash, Owen Rambow, and George Kiraz. 2005.
Morphological Analysis and Generation for Arabic
Dialects. In Proc. of the ACL Workshop on Computa-
tional Approaches to Semitic Languages, pages 17?24,
Ann Arbor, USA.
Wilbert Heeringa, Peter Kleiweg, Charlotte Gosskens,
and John Nerbonne. 2006. Evaluation of String Dis-
tance Algorithms for Dialectology. In Proc. of the
Workshop on Linguistic Distances, pages 51?62, Syd-
ney, Australia.
Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma,
Aditya Bhargava, Qing Dou, Mi-Young Kim, and
Grzegorz Kondrak. 2010. Transliteration Generation
and Mining with Limited Training Resources. In Proc.
of the 2010 Named Entities Workshop (NEWS), pages
39?47, Uppsala, Sweden.
8
Genichiro Kikui, Seiichi Yamamoto, Toshiyuki
Takezawa, and Eiichiro Sumita. 2006. Compar-
ative study on corpora for speech translation. IEEE
Transactions on Audio, Speech and Language,
14(5):1674?1682.
Philipp Koehn, Alexandra Birch, and Ralf Steinberger.
2009. 462 Machine Translation Systems for Europe.
In Proc. of the MT Summit XII, Ottawa, Canada.
Chun-Jen Lee and Jason S. Chang. 2003. Acqui-
sition of English-Chinese transliterated word pairs
from parallel-aligned texts using a statistical machine
transliteration model. In Proc. of the HLT-NAACL
2003 Workshop on Building and using parallel texts,
Volume 3, pages 96?103, Edmonton, Canada.
Haizhou Li, Min Zhang, and Jian Su. 2004. A joint
source-channel model for machine transliteration. In
Proc. of the 42nd ACL, pages 159?166, Barcelona,
Spain.
Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda.
2009. Bayesian unsupervised word segmentation with
nested Pitman-Yor language modeling. In Proc of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP (ACL-
IJCNLP), pages 100?108, Suntec, Singapore.
John Nerbonne and Wilbert Heeringa. 1997. Measur-
ing Dialect Distance Phonetically. In Proc. of the ACL
Special Interest Group in Computational Phonology,
pages 11?18, Madrid, Spain.
Sara Noeman and Amgad Madkour. 2010. Language
Independent Transliteration Mining System Using Fi-
nite State Automata Framework. In Proc. of the 2010
Named Entities Workshop (NEWS), pages 57?61, Up-
psala, Sweden.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proc. of the 40th An-
nual Meeting on Association for Computational Lin-
guistics (ACL), pages 311?318, Philadelphia, USA.
Michael Paul, Hirofumi Yamamoto, Eiichiro Sumita, and
Satoshi Nakamura. 2009. On the Importance of Pivot
Language Selection for Statistical Machine Transla-
tion. In Proc. of the North American Chapter of the
Association for Computational Linguistics - Human
Language Technologies (NAACL HLT), pages 221?
224, Boulder, USA.
Michael Paul, Andrew Finch, and Eiichiro Sumita.
2011. Word Segmentation for Dialect Translation.
LNCS Lectures Note in Computer Science, Springer,
6609:55?67.
Hassan Sawaf. 2010. Arabic Dialect Handling in Hybrid
Machine Translation. In Proc. of the 9th Conference of
the Association for Machine Translation in the Ameri-
cas (AMTA), Denver, USA.
Yves Scherrer. 2007. Adaptive String Distance Mea-
sures for Bilingual Dialect Lexicon Induction. In Proc.
of the ACL Student Research Workshop, pages 55?60,
Prague, Czech Republic.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proc. of the International Con-
ference on Spoken Language Processing (ICSLP), Vol-
ume 2, pages 901?904, Denver, USA.
Keita Tsuji and Kyo Kageura. 2006. Automatic gen-
eration of JapaneseEnglish bilingual thesauri based
on bilingual corpora. J. Am. Soc. Inf. Sci. Technol.,
57:891?906.
Masao Utiyama and Hitoshi Isahara. 2007. A Compari-
son of Pivot Methods for Phrase-Based Statistical Ma-
chine Translation. In Proc. of Human Language Tech-
nologies (HLT), pages 484?491, New York, USA.
Hua Wu and Haifeng Wang. 2007. Pivot Language Ap-
proach for Phrase-Based Statistical Machine Transla-
tion. In Proc. of the 45th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
856?863, Prague, Czech Republic.
Jia Xu, Jianfeng Gao, Kristina Toutanova, and Hermann
Ney. 2008. Bayesian semi-supervised Chinese word
segmentation for Statistical Machine Translation. In
Proc. of the 22nd International Conference on Com-
putational Linguistics (COLING), pages 1017?1024,
Manchester, United Kingdom.
9
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 47?51,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
5HVFRULQJ D 3KUDVHEDVHG 0DFKLQH 7UDQVOLWHUDWLRQ 6\VWHP ZLWK 5HFXUUHQW
1HXUDO 1HWZRUN /DQJXDJH 0RGHOV
$QGUHZ )LQFK
1,&7
 +LNDULGDL
.HLKDQQD 6FLHQFH &LW\
 -$3$1
M/`2rX7BM+?!MB+iX;QXDT
3DXO 'L[RQ
1,&7
 +LNDULGDL
.HLKDQQD 6FLHQFH &LW\
 -$3$1
TmHX/BtQM!MB+iX;QXDT
(LLFKLUR 6XPLWD
1,&7
 +LNDULGDL
.HLKDQQD 6FLHQFH &LW\
 -$3$1
2BB+?B`QXbmKBi!MB+iX;QXDT
$EVWUDFW
7KH V\VWHP HQWHUHG LQWR WKLV \HDU?V VKDUHG
WUDQVOLWHUDWLRQ HYDOXDWLRQ LV LPSOHPHQWHG
ZLWKLQ D SKUDVHEDVHG VWDWLVWLFDO PDFKLQH
WUDQVOLWHUDWLRQ 607 IUDPHZRUN 7KH V\VWHP
LV EDVHG RQ D MRLQW VRXUFHFKDQQHO PRGHO LQ
FRPELQDWLRQ ZLWK D WDUJHW ODQJXDJH PRGHO DQG
PRGHOV WR FRQWURO WKH OHQJWK RI WKH VHTXHQFHV
JHQHUDWHG 7KH MRLQW VRXUFHFKDQQHO PRGHO
ZDV WUDLQHG XVLQJ D PDQ\WRPDQ\ %D\HVLDQ
ELOLQJXDO DOLJQPHQW 7KH IRFXV RI WKLV \HDU?V
V\VWHP LV RQ LQSXW UHSUHVHQWDWLRQ ,Q RUGHU DW
WHPSW WR PLWLJDWH GDWD VSDUVHQHVV LVVXHV LQ WKH
MRLQW VRXUFHFKDQQHO PRGHO ZH DXJPHQWHG WKH
V\VWHP ZLWK UHFXUUHQW QHXUDO QHWZRUN 511
PRGHOV WKDW FDQ OHDUQ WR SURMHFW WKH JUDSKHPH
VHW RQWR D VPDOOHU KLGGHQ UHSUHVHQWDWLRQ :H
SHUIRUPHG H[SHULPHQWV RQ GHYHORSPHQW GDWD
WR HYDOXDWH WKH HIIHFWLYHQHVV RI RXU DSSURDFK
2XU UHVXOWV VKRZ WKDW XVLQJ DQ 511 ODQJXDJH
PRGHO FDQ LPSURYH SHUIRUPDQFH IRU ODQJXDJH
SDLUV ZLWK ODUJH JUDSKHPH VHWV RQ WKH WDUJHW
VLGH
 ,QWURGXFWLRQ
2XU V\VWHP IRU WKH 1(:6 VKDUHG HYDOXDWLRQ RQ
WUDQVOLWHUDWLRQ JHQHUDWLRQ LV EDVHG RQ WKH V\VWHP HQ
WHUHG LQWR ODVW \HDUV HYDOXDWLRQ )LQFK HW DO 
6RPH PLQRU LPSURYHPHQWV KDYH EHHQ PDGH WR VRPH
RI WKH FRPSRQHQWV EXW WKH PDMRU GLIIHUHQFH LV WKH
DGGLWLRQ RI D UHVFRULQJ VWHS ZLWK WKUHH UHVFRULQJ
PRGHOV DQ 511 WDUJHW ODQJXDJH PRGHO DQ 511
MRLQW VRXUFHFKDQQHO PRGHO DQG DPD[LPXP HQWURS\
PRGHO WKLV PRGHO ZDV SDUW RI ODVW \HDU?V V\VWHP
EXW KDV EHHQ PRYHG IURP WKH GHFRGLQJ VWHS LQWR WKH
UHVFRULQJ VWHS IRU HIILFLHQF\ ,Q DOO RXU H[SHUL
PHQWV ZH KDYH WDNHQ D VWULFWO\ ODQJXDJH LQGHSHQ
GHQW DSSURDFK (DFK RI WKH ODQJXDJH SDLUV ZHUH SUR
FHVVHG DXWRPDWLFDOO\ IURP WKH JUDSKHPLF UHSUHVHQWD
WLRQ VXSSOLHG IRU WKH VKDUHG WDVNV ZLWK QR ODQJXDJH
VSHFLILF WUHDWPHQW IRU DQ\ RI WKH ODQJXDJH SDLUV
5HFHQW UHVHDUFK UHVXOWV RQ WKH DSSOLFDWLRQ RI UH
FXUUHQW QHXUDO QHWZRUN PRGHOV WR ODQJXDJH PRGHO
LQJ KDYH VKRZQ WKDW YHU\ SURPLVLQJ UHGXFWLRQV LQ
WH[W GDWD SHUSOH[LW\ UHODWLYH WR WUDGLWLRQDO QJUDP ODQ
JXDJHPRGHO DSSURDFKHV DUH SRVVLEOH 0LNRORY HW DO
 0LNRORY HW DO  7KH 511 DSSURDFK
GLIIHUV IURP WKH VWDQGDUG QJUDP DSSURDFK LQ WKDW
511V DUH DEOH WR VPRRWK E\ SURMHFWLQJ WKH JUDSKHPH
VHW RQWR D VHW RI KLGGHQ XQLWV D SURFHVV WKDW HI
IHFWLYHO\ FOXVWHUV VLPLODU JUDSKHPHV )XUWKHUPRUH
511V KDYH EHHQ UHSRUWHG WR EH HIIHFWLYH ZKHUH GDWD
UHVRXUFHV DUH OLPLWHG .RPEULQN HW DO 
7KHVH FKDUDFWHULVWLFV PRWLYDWH XV WR LQYHVWLJDWH
WKH HIIHFW RI DSSO\LQJ WKLV DSSURDFK LQ PRGHOLQJ DW
WKH JUDSKHPH RU JUDSKHPH VHTXHQFH SDLU OHYHO
SDUWLFXODUO\ DV WZR RI WKH PRVW LPSRUWDQW PRGHOV LQ
RXU V\VWHP DUH ERWK ODQJXDJH PRGHOV 7KH PDLQ
GUDZEDFN RI 511 EDVHG PRGHOV WKHLU H[FHSWLRQDOO\
KLJK WUDLQLQJ FRPSXWDWLRQDO FRPSOH[LW\ 0LNRORY HW
DO  LV QRW DQ REVWDFOH IRU WUDLQLQJ PRGHOV IRU
WKLV VKDUHG WDVN WKRXJK LW PD\ EH DQ LVVXH LI ODUJH
DPRXQWV RI PRQROLQJXDO GDWD DUH XVHG WR EXLOG WKH
ODQJXDJH PRGHOV :H UXQ H[SHULPHQWV XVLQJ WKLV
WHFKQLTXH WR LQYHVWLJDWH LWV HIIHFW RQ ERWK FRUSXV SHU
SOH[LW\ DQG HQGWRHQG V\VWHP SHUIRUPDQFH VLQFH
LW LV QRW QHFHVVDULO\ WKH FDVH WKDW JDLQV LQ ODQJXDJH
PRGHO SHUSOH[LW\ UHVXOW LQ EHWWHU V\VWHPV &KHQ HW DO

7KURXJKRXW WKLV SDSHU ZH ZLOO UHIHU WR JUDSKHPHV
JUDSKHPH VHTXHQFHV DQG JUDSKHPH VHTXHQFH SDLUV
%\ JUDSKHPH ZH PHDQ D VLQJOH XQLFRGH FKDUDFWHU
IRU H[DPSOH ?D? LQ (QJOLVK ??? LQ -DSDQHVH RU ???
LQ &KLQHVH *UDSKHPH VHTXHQFHV DUH DUELWUDU\ VH
TXHQFHV RI WKHVH JUDSKHPHV DQG JUDSKHPH VHTXHQFH
SDLUV DUH WXSOHV RI JUDSKHPH VHTXHQFHV HDFK HOH
PHQW LQ WKH WXSOH EHLQJ D JUDSKHPH VHTXHQFH LQ D
JLYHQ ODQJXDJH IRU H[DPSOH ?KHOOR??????
47
 6\VWHP 'HVFULSWLRQ
 %LOLQJXDO %D\HVLDQ *UDSKHPH $OLJQPHQW
7R WUDLQ WKH MRLQWVRXUFHFKDQQHO PRGHOV LQ RXU
V\VWHP ZH SHUIRUP D PDQ\WRPDQ\ JUDSKHPHWR
JUDSKHPH DOLJQPHQW 7R GLVFRYHU WKLV DOLJQPHQW
ZH XVH WKH %D\HVLDQ QRQSDUDPHWULF WHFKQLTXH GH
VFULEHG LQ )LQFK DQG 6XPLWD  ZKLFK LV D UHO
DWLYH RI WKH WHFKQLTXH SURSRVHG E\ +XDQJ HW DO
 %D\HVLDQ WHFKQLTXHV W\SLFDOO\ EXLOG FRPSDFW
PRGHOV ZLWK IHZ SDUDPHWHUV WKDW GR QRW RYHUILW WKH
GDWD DQG KDYH EHHQ VKRZQ WR EH HIIHFWLYH IRU WUDQVOLW
HUDWLRQ )LQFK DQG 6XPLWD  )LQFK HW DO 
 3KUDVHEDVHG 607 0RGHOV
7KH GHFRGLQJ ZDV SHUIRUPHG XVLQJ D VSHFLDOO\ PRGL
ILHG YHUVLRQ RI WKH 2&7$9,$1 GHFRGHU )LQFK HW DO
