Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1515?1520,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Single-Document Summarization as a Tree Knapsack Problem
Tsutomu Hirao? Yasuhisa Yoshida? Masaaki Nishino? Norihito Yasuda? Masaaki Nagata?
?NTT Communication Science Laboratories, NTT Corporation
2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan
{hirao.tsutomu,yoshida.y,nishino.masaaki,
nagata.masaaki}@lab.ntt.co.jp
? Japan Science and Technology Agency
North 14 West 9, Sapporo, Hokkaido, 060-0814, Japan
yasuda@erato.ist.hokudai.ac.jp
Abstract
Recent studies on extractive text summariza-
tion formulate it as a combinatorial optimiza-
tion problem such as a Knapsack Problem, a
Maximum Coverage Problem or a Budgeted
Median Problem. These methods successfully
improved summarization quality, but they did
not consider the rhetorical relations between
the textual units of a source document. Thus,
summaries generated by these methods may
lack logical coherence. This paper proposes a
single document summarization method based
on the trimming of a discourse tree. This is
a two-fold process. First, we propose rules
for transforming a rhetorical structure theory-
based discourse tree into a dependency-based
discourse tree, which allows us to take a tree-
trimming approach to summarization. Sec-
ond, we formulate the problem of trimming
a dependency-based discourse tree as a Tree
Knapsack Problem, then solve it with integer
linear programming (ILP). Evaluation results
showed that our method improved ROUGE
scores.
1 Introduction
State-of-the-art extractive text summarization meth-
ods regard a document (or a document set) as a set
of textual units (e.g. sentences, clauses, phrases)
and formulate summarization as a combinatorial op-
timization problem, i.e. selecting a subset of the set
of textual units that maximizes an objective with-
out violating a length constraint. For example, Mc-
Donald (2007) formulated text summarization as a
Knapsack Problem, where he selects a set of textual
units that maximize the sum of significance scores
of each unit. Filatova et al (2004) proposed a
summarization method based on a Maximum Cov-
erage Problem, in which they select a set of textual
units that maximizes the weighted sum of the con-
ceptual units (e.g. unigrams) contained in the set.
Although, their greedy solution is only an approxi-
mation, Takamura et al (2009a) extended it to ob-
tain the exact solution. More recently, Takamura et
al. (2009b) regarded summarization as a Budgeted
Median Problem and obtain exact solutions with in-
teger linear programming.
These methods successfully improved ROUGE
(Lin, 2004) scores, but they still have one critical
shortcoming. Since these methods are based on sub-
set selection, the summaries they generate cannot
preserve the rhetorical structure of the textual units
of a source document. Thus, the resulting summary
may lack coherence and may not include significant
textual units from a source document.
One powerful and potential way to overcome the
problem is to include discourse tree constraints in
the summarization procedure. Marcu (1998) re-
garded a document as a Rhetorical Structure The-
ory (RST) (William Charles, Mann and Sandra An-
near, Thompson, 1988)-based discourse tree (RST-
DT) and selected textual units according to a prefer-
ence ranking derived from the tree structure to make
a summary. Daume? et al (2002) proposed a docu-
ment compression method that directly models the
probability of a summary given an RST-DT by us-
ing a noisy-channel model. These methods generate
well-organized summaries, however, since they do
not formulate summarizations as combinatorial op-
1515
Root?
N? S?
N? S? N? S?
S? N? N? S? S? N? S? N?
N? N?
N? S?
Elaboration?
Elaboration?
Background?
Elaboration?
Elaboration?
Contrast? Contrast?
Evidence?
Example?
Concession? Antithesis?
Figure 1: Example RST-DT from (Marcu, 1998).
timization problems, the optimality of the generated
summaries is not guaranteed.
In this paper, we propose a single document sum-
marization method based on the trimming of a dis-
course tree based on the Tree Knapsack Problem. If
a discourse tree explicitly represents parent-child re-
lationships between textual units, we can apply the
well-known tree-trimming approach to a discourse
tree and reap the benefit of combinatorial optimiza-
tion methods. In other words, to apply the tree-
trimming approach, we need a tree whose all nodes
represent textual units. Unfortunately, the RST-DT
does not allow it, because textual units in the RST-
DT are located only on leaf nodes and parent-child
relationship between textual units are represented
implicitly at higher positions in a tree. Therefore, we
first propose rules that transform an RST-DT into a
dependency-based discourse tree (DEP-DT) that ex-
plicitly defines the parent-child relationships. Sec-
ond, we treat it as a rooted subtree selection, in other
words, a Tree Knapsack Problem and formulate the
problem as an ILP.
2 From RST-DT to DEP-DT
2.1 RST-DT
According to RST, a document is represented as an
RST-DT whose terminal nodes correspond to ele-
mentary discourse units (EDU)s1 and whose non-
terminal nodes indicate the role of the contiguous
1EDUs roughly correspond to clauses.
Root?
N? S?
N? S? N? S?
S? N? N? S? S? N? S? N?
N? N?
N? S?
0	
1	
2	
4	 6	 7	
5	
3	
8	
10	
9	
11	
12	
13	
14	 15	 18	
16	
17	
Figure 2: Heads of non-terminal nodes.
EDUs namely, ?nucleus (N)? or ?satellite (S)?. A nu-
cleus is more important than a satellite in terms of
the writer?s purpose. That is, a satellite is a child of
a nucleus in the RST-DT. Some discourse relations
such as ?Elaboration?, ?Contrast? and ?Evidence? be-
tween a nucleus and a satellite or two nuclei are de-
fined. Figure 1 shows an example of an RST-DT.
2.2 DEP-DT
An RST-DT is not suitable for tree trimming because
it does not always explicitly define parent-child re-
lationships between textual units. For example, if
we consider how to trim the RST-DT in Figure 1,
when we drop e8, we have to drop e7 because of the
parent-child relationship defined between e7 and e8,
i.e. e7 is a satellite (child) of the nucleus (parent)
e8. On the other hand, we cannot judge whether we
have to drop e9 or e10 because the parent-child rela-
tionships are not explicitly defined between e8 and
e9, e8 and e10. This view motivates us to produce a
discourse tree that explicitly defines parent-child re-
lationships and whose root node represents the most
important EDU in a source document. If we can ob-
tain such a tree, it is easy to formulate summariza-
tion as a Tree Knapsack Problem.
To construct a discourse tree that represents
the parent-child relationships between EDUs, we
propose rules for transforming an RST-DT to a
dependency-based discourse tree (DEP-DT). The
procedure is defined as follows:
1. For each non-terminal node excluding the par-
1516
Depth=1
Depth=2
Depth=3
Depth=4
Figure 3: The DEP-DT obtained from the RST-DT in Fig-
ure 1.
ent of an EDU in the RST-DT, we define a
?head?. Here, a ?head? of a non-terminal node
is the leftmost descendant EDUwhose parent is
N. In Figure 2, ?H? indicates the ?head? of each
node.
2. For each EDU whose parent is N, we pick the
nearest S with a ?head? from the EDU?s ances-
tors and we add the EDU to the DEP-DT as a
child of the head of the S?s parent. If there is no
nearest S, the EDU is the root of the DEP-DT.
For example, in Figure 2, the nearest S to e3
that has a head is node 5 and the head of node
5?s parent is e2. Thus, e3 is a child of e2.
3. For each EDU whose parent is S, we pick the
nearest non-terminal with a ?head? from the an-
cestors and we add the EDU to the DEP-DT as
a child of the head of the non-terminal node.
For example, the nearest non-terminal node of
e9 that has a head is node 16 and the head of
node 16 is e10. Thus, e9 is a child of e10.
Figure 3 shows the DEP-DT obtained from the
RST-DT in Figure 1. The DEP-DT expresses the
parent-child relationship between the EDUs. There-
fore, we have to drop e7, e9 and e10 when we drop
e8. Note that, by applying the rules, discourse rela-
tions defined between non-terminals of an RST-DT
are eliminated. However, we believe that these re-
lations are no needed for the summarization that we
are attempting to realize.
3 Tree Knapsack Model for
Single-Document Summarization
3.1 Formalization
We denote T as a set of all possible rooted subtrees
obtained from a DEP-DT. F (t) is the significance
score for a rooted subtree t ? T and L is the maxi-
mum number of words allowed in a summary. The
optimal subtree t? is defined as follows:
t? = argmax
t?T
F (t) (1)
s.t. Length(t) ? L. (2)
Here, we define F (t) as
F (t) =
?
e?E(t)
W(e)
Depth(e)
. (3)
E(t) is the set of EDUs contained in t, Depth(e)
is the depth of an EDU e within the DEP-DT. For
example, Depth(e2) = 1, Depth(e6) = 4 for the
DEP-DT of Figure 3. W(e) is defined as follows:
W(e) =
?
w?W (e)
tf(w,D). (4)
W (e) is the set of words contained in e and
tf(w,D) is the term frequency of word w in a docu-
ment D.
3.2 ILP Formulation
We formulate the optimization problem in the pre-
vious section as a Tree Knapsack Problem, which is
a kind of Precedence-Constrained Knapsack Prob-
lem (Samphaiboon and Yamada, 2000) and we can
obtain the optimal rooted subtree by solving the fol-
lowing ILP problem2:
maximize
x
N
?
i=1
W(ei)
Depth(ei)
xi (5)
s.t.
N
?
i=1
?ixi ? L (6)
?i : xparent(i) ? xi (7)
?i : xi ? {0, 1}, (8)
2A similar approach has been applied to sentence compres-
sion (Filippova and Strube, 2008).
1517
ROUGE-1 ROUGE-2
F R F R
TKP(G) .310H,K,L .321G,H,K,L .108 .112H
TKP(H) .281H .284H .092 .093
Marcu(G) .291H .272H .101 .093
Marcu(H) .236 .219 .073 .068
MCP .279 .295H .073 .077
KP .251 .266H .071 .075
LEAD .255 .240 .092 .086
Table 1: ROUGE scores of the RST discourse treebank
dataset. In the table, G,H,K,L indicate a method sta-
tistically significant against Marcu(G), Marcu(H), KP,
LEAD, respectively.
where x is an N -dimensional binary vector that
represents the summary, i.e. xi=1 denotes that the i-
th EDU is included in the summary. N is the number
of EDUs in a document, ?i is the length (the number
of words) of the i-th EDU, and parent(i) indicates
the ID of the parent of the i-th EDU in the DEP-DT.
Constraint (6) ensures that the length of a summary
is less than limit L. Constraint (7) ensures that a
summary is a rooted subtree of the DEP-DT. Thus,
xparent(i) is always 1 when the i-th EDU is included
in the summary.
In general, the Tree Knapsack Problem is NP-
hard, but fortunately we can obtain the optimal solu-
tion in a feasible time by using ILP solvers for doc-
uments of practical tree size. In addition, bottom-
up DP (Lukes, 1974) and depth-first DP algorithms
(Cho and Shaw, 1997) are known to find the optimal
solution efficiently.
4 Experimental Evaluation
4.1 Settings
We conducted an experimental evaluation on the test
collection for single document summarization eval-
uation contained in the RST Discourse Treebank
(RST-DTB)(Carlson et al, 2001) distributed by the
Linguistic Data Consortium (LDC)3. The RST-DTB
Corpus includes 385 Wall Street Journal articles
with RST annotation, and 30 of these documents
also have one human-made reference summary. The
average length of the reference summaries corre-
sponds to about 10 % of the words in the source
3http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2002T07
document.
We compared our method (TKP) with Marcu?s
method (Marcu) (Marcu, 1998), a simple knapsack
model (KP), a maximum coverage model (MCP)
and a lead method (LEAD). MCP is known to be a
state-of-the-art method for multiple document sum-
marization and we believe that MCP also performs
well in terms of single document summarization.
LEAD is also a widely used summarizer that simply
takes the first K textual units of the document. Al-
though this is a simple heuristic rule, it is known as
a state-of-the-art summarizer (Nenkova and McKe-
own, 2011).
For our method, we examined two types of
DEP-DT. One was obtained from the gold RST-
DT. The other was obtained from the RST-DT pro-
duced by a state-of-the-art RST parser, HILDA (du-
Verle and Prendinger, 2009; Hernault et al, 2010).
For Marcu?s method, we examined both the gold
RST-DT and HILDA?s RST-DT. We re-implemented
HILDA and re-trained it on the RST-DT Corpus ex-
cluding the 30 documents used in the evaluation.
The F-score of the parser was around 0.5. For KP,
we exclude constraint (7) from the ILP formulation
of TKP and set the depth of all EDUs in equations
(3) and (5) at 1. For MCP, we use tf (equation (4))
as the word weight.
We evaluated the summarization systems with
ROUGE version 1.5.5 4. Performance metrics were
the recall (R) and F-score (F) of ROUGE-1,2.
4.2 Results and Discussion
Table 1 shows the evaluation results. In the ta-
ble, TKP(G) and TKP(H) denote methods with the
DEP-DT obtained from the gold RST-DT and from
HILDA, respectively. Marcu(G) and Marcu(H) de-
note Marcu?s method described in (Marcu, 1998)
with gold RST-DT and with HILDA, respectively.
We performed a multiple comparison test for the dif-
ferences among ROUGE scores, we calculated the p-
values between systems with the Wilcoxon signed-
rank test (Wilcoxon, 1945) and used the False Dis-
covery Rate (FDR) (Benjamini and Hochberg, 1995)
to calculate adjusted p-values, in order to limit false
positive rate to 5%.
From the table, TKP(G) and Marcu(G) achieved
4Options used: -n 2 -s -m -x
1518
Reference:
The Fuji apple may one day replace the Red Delicious as the number one U.S. apple. Since the Red Delicious has been
over-planted and prices have dropped to new lows, the apple industry seems ready for change. Along with growers, supermarkets
are also trying different varieties of apples. Although the Fuji is smaller and not as perfectly shaped as the Red Delicious, it is
much sweeter, less mealy and has a longer shelf life.
TKP(G):
We?ll still have mom and apple pie. A Japanese apple called the Fuji. Some fruit visionaries say the Fuji could someday tumble
the Red Delicious from the top of America?s apple heap. It has a long shelf life. Now, even more radical changes seem afoot. The
Delicious hegemony won?t end anytime soon. New apple trees grow slowly. But the apple industry is ripe for change. There?s a
Fuji apple cult.
Marcu(G):
We?ll still have mom and apple pie. On second thought, make that just mom. The Fuji could someday tumble the Red Delicious
from the top of America?s apple heap. Now, even more radical changes seem afoot. The Delicious hegemony won?t end anytime
soon. More than twice as many Red Delicious apples are grown as the Golden variety, America?s No. 2 apple. But the apple
industry is ripe for change.
MCP:
Called the Fuji. It has a long shelf life. New apple trees grow slowly. Its roots are patriotic. I?m going to have to get another job
this year. Scowls. They still buy apples mainly for big, red good looks. Japanese researchers have bred dozens of strains of Fujis.
Mr. Auvil, the Washington grower, says. Stores sell in summer. The ? big boss ? at a supermarket chain even rejected his Red
Delicious recently. Many growers employ.
LEAD:
Soichiro Honda?s picture now hangs with Henry Ford?s in the U.S. Automotive Hall of Fame, and the game-show ? Jeopardy ? is
soon to be Sony-owned. But no matter how much Japan gets under our skin, we?ll still have mom and apple pie. On second
thought, make that just mom. A Japanese apple called the Fuji is cropping up in orchards the way Hondas did on U.S. roads.
Figure 4: Summaries obtained from wsj 1128.
better results than MCP, KP and LEAD, although
some of the comparisons are not significant. In par-
ticular, TKP(G) achieved the highest ROUGE scores
on all measures. On ROUGE-1 Recall, TKP(G) sig-
nificantly outperformed Marcu(G), Marcu(H), KP
and LEAD. These results support the effectiveness
of our method that utilizes the discourse structure.
Comparing TKP(H) with Marcu(H), the former
achieved higher scores with statistical significance
on ROUGE-1. In addition, Marcu(H) was outper-
formed by MCP, KP and LEAD. The results confirm
the effectiveness of our summarization model and
trimming proposal for DEP-DT. Moreover, the dif-
ference between TKP(G) and TKP(H) was smaller
than that between Marcu(G) and Marcu(H). This
implies that our method is more robust against dis-
course parser error than Marcu?s method.
Figure 4 shows the example summaries gener-
ated by TKP(G), Marcu(G), MCP and LEAD, re-
spectively for an article, wsj 1128. Since TKP(G)
and Marcu(G) utilize a discourse tree, the summary
generated by TKP(G) is similar to that generated by
Marcu(G) but it is different from those generated by
MCP and LEAD.
5 Conclusion
This paper proposed rules for transforming an RST-
DT to a DEP-DT to obtain the parent-child relation-
ships between EDUs. We treated a single document
summarization method as a Tree Knapsack Problem,
i.e. the summarizer selects the best rooted subtree
from a DEP-DT. To demonstrate the effectiveness of
our method, we conducted an experimental evalua-
tion using 30 documents selected from the RST Dis-
course Treebank Corpus. The results showed that
our method achieved the highest ROUGE-1,2 scores.
References
Yoav Benjamini and Yosef Hochberg. 1995. Control-
ling the false discovery rate: A practical and powerful
approach to multiple testing. Journal of the Royal Sta-
tistical Society, Series B (Methodological), 57(1):289?
300.
Lynn Carlson, Daniel Marcu, andMary Ellen Okurowski.
2001. Building a discourse-tagged corpus in the
framework of rhetorical structure theory. In Proc. of
the SIGDIAL01, pages 1?10.
Geon Cho and Dong X Shaw. 1997. A depth-first
dynamic programming algorithm for the tree knap-
1519
sack problem. INFORMS Journal on Computing,
9(4):431?438.
Hal Daume? III and Daniel Marcu. 2002. A noisy-channel
model for document compression. In Proc. of the 40th
ACL, pages 449?456.
David duVerle and Helmut Prendinger. 2009. A novel
discourse parser based on support vector machine clas-
sification. In Proc. of the Joint Conference of the 47th
ACL and 4th IJCNLP, pages 665?673.
Elena Filatova and Vasileios Hatzivassiloglou. 2004.
A formal model for information selection in multi-
sentence extraction. In Proc. of the 20th COLING,
pages 397?403.
Katja Filippova and Michael Strube. 2008. Dependency
tree based sentence compression. In Proc. of the 5th
International Natural Language Generation Confer-
ence (INLG), pages 25?32.
Hugo Hernault, Helmut Prendinger, David A duVerle,
and Mitsuru Ishizuka. 2010. HILDA: A discourse
parser using support vector machine classification. Di-
alogue and Discourse, 1(3):1?33.
Chin-Yew Lin. 2004. ROUGE: A Package for Automatic
Evaluation of Summaries. In Proc. of Workshop on
Text Summarization Branches Out, pages 74?81.
J. A. Lukes. 1974. Efficient algorithm for the partition-
ing of trees. IBM Journal of Research and Develop-
ment, 18(3):217?224.
Daniel Marcu. 1998. Improving summarization through
rhetorical parsing tuning. In Proc. of the 6th Workshop
on Very Large Corpora, pages 206?215.
Ryan McDonald. 2007. A study of global inference al-
gorithms in multi-document summarization. In Proc.
of the 29th ECIR, pages 557?564.
Ani Nenkova and Kathaleen McKeown. 2011. Auto-
matic summarization. Foundations and Trends in In-
formation Retrieval, 5(2-3):103?233.
Natthawut Samphaiboon and Takeo Yamada. 2000.
Heuristic and exact algorithms for the precedence-
constrained knapsack problem. Journal of Optimiza-
tion Theory and Applications, 105(3):659?676.
Hiroya Takamura and Manabu Okumura. 2009a. Text
summarization model based on maximum coverage
problem and its variant. In Proc. of the 12th EACL,
pages 781?789.
Hiroya Takamura and Manabu Okumura. 2009b. Text
summarization model based on the budgeted median
problem. In Proceedings of the 18th CIKM.
Frank Wilcoxon. 1945. Individual comparisons by rank-
ing methods. Biometrics Bulletin, 1(6):80?83.
William Charles, Mann and Sandra Annear, Thompson.
1988. Rhetorical Structure Theory: Toward a func-
tional theory of text organization. Text, 8(3):243?281.
1520
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1834?1839,
October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Dependency-based Discourse Parser for Single-Document Summarization
Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and Masaaki Nagata
NTT Communication Science Laboratories, NTT Corporation
2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan
{yoshida.y,suzuki.jun,hirao.tsutomu,nagata.masaaki}@lab.ntt.co.jp
Abstract
The current state-of-the-art single-
document summarization method gen-
erates a summary by solving a Tree
Knapsack Problem (TKP), which is the
problem of finding the optimal rooted sub-
tree of the dependency-based discourse
tree (DEP-DT) of a document. We can
obtain a gold DEP-DT by transforming a
gold Rhetorical Structure Theory-based
discourse tree (RST-DT). However, there
is still a large difference between the
ROUGE scores of a system with a gold
DEP-DT and a system with a DEP-DT
obtained from an automatically parsed
RST-DT. To improve the ROUGE score,
we propose a novel discourse parser
that directly generates the DEP-DT. The
evaluation results showed that the TKP
with our parser outperformed that with
the state-of-the-art RST-DT parser, and
achieved almost equivalent ROUGE
scores to the TKP with the gold DEP-DT.
1 Introduction
Discourse structures of documents are believed
to be highly beneficial for generating informa-
tive and coherent summaries. Several discourse-
based summarization methods have been devel-
oped, such as (Marcu, 1998; Daum?e III and
Marcu, 2002; Hirao et al., 2013; Kikuchi et al.,
2014). Moreover, the current best ROUGE score
for the summarization benchmark data of the RST-
discourse Treebank (Carlson et al., 2002) has been
provided by (Hirao et al., 2013), whose method
also utilizes discourse trees. Thus, the discourse-
based summarization approach is one promising
way to obtain high-quality summaries.
One possible weakness of discourse-based sum-
marization techniques is that they rely greatly on
the accuracy of the discourse parser they use.
For example, the above discourse-based summa-
rization methods utilize discourse trees based on
the Rhetorical Structure Theory (RST) (Mann and
Thompson, 1988) for their discourse information.
Unfortunately, the current state-of-the-art RST
parser, as described in (Hernault et al., 2010),
is insufficient as an off-the-shelf discourse parser.
In fact, there is empirical evidence that the qual-
ity (i.e., ROUGE score) of summaries from auto-
parsed discourse trees is significantly degraded
compared with those generated from gold dis-
course trees (Marcu, 1998; Hirao et al., 2013).
From this background, the goal of this paper
is to develop an appropriate discourse parser for
discourse-based summarization. We first focus on
one of the best discourse-based single document
summarization methods as proposed in (Hirao et
al., 2013). Their method formulates a single doc-
ument summarization problem as a Tree Knap-
sack Problem (TKP) over a dependency-based dis-
course tree (DEP-DT). In their method, DEP-DTs
are automatically transformed from (auto-parsed)
RST-discourse trees (RST-DTs) by heuristic rules.
Instead, we develop a DEP-DT parser, that di-
rectly provides DEP-DTs for their state-of-the-art
discourse-based summarization method. We show
that summaries generated by our parser improve
the ROUGE scores to almost the same level as
those generated by gold DEP-DTs. We also inves-
tigate the way in which the parsing accuracy helps
to improve the ROUGE scores.
2 Single-Document Summarization as a
Tree Knapsack Problem
Hirao et al. (2013) formulated single-document
summarization as a TKP that is run on the DEP-
DT. They obtained a summary by trimming the
DEP-DT, i.e. the summary is a rooted subtree of
the DEP-DT.
Suppose that we have N EDUs in a document,
1834
Root!
N! S!
N! S! N! S!
S! N! N! S! S! N! S! N!
N! N!
N! S!
Elaboration!
Background!
Elaboration!
Elaboration!
Contrast! Contrast!
Evidence!
Example!
Concession! Antithesis!
(a)
Background Elabora.on
Elabora.on
Elabora.on Elabora.on
Concession Example
Evidence
An.thesis
(b)
Background Elabora.on Elabora.on
Elabora.on Elabora.on Concession Example
Evidence An.thesis
(c)
Figure 1: Examples of RST-DT and DEP-DT. e
1
, ? ? ? , e
10
are EDUs. (a) Example of an RST-DT from
(Marcu, 1998). n
1
, ? ? ? , n
19
are the non-terminal nodes. (b) Example of the DEP-DT obtained from the
incorrect RST-DT that is made by swapping the Nucleus-Satellite relationship of the node n
2
and the
node n
3
. (c) The correct DEP-DT obtained from the RST-DT in (a).
and the i-th EDU e
i
has l
i
words. L is the maxi-
mum number of words allowed in a summary. In
the TKP, if we select e
i
, we need to select its par-
ent EDU in the DEP-DT. We denote parent(i) as
the index of the parent of e
i
in the DEP-DT. x is
an N -dimensional binary vector that represents a
summary, i.e. x
i
= 1 denotes that e
i
is included in
the summary. The TKP is defined as the following
ILP problem:
maximize
x
?
N
i=1
F (e
i
)x
i
s.t.
?
N
i=1
l
i
x
i
? L
?i : x
parent(i)
? x
i
?i : x
i
? {0, 1},
where F (e
i
) is the score of e
i
. We define F (e
i
) as
follows:
F (e
i
) =
?
w?W (e
i
)
tf(w,D)
Depth(e
i
)
,
where W (e
i
) is the set of words contained in e
i
.
tf(w,D) is the term frequency of word w in a doc-
ument D. Depth(e
i
) is the depth of e
i
in the DEP-
DT.
3 Tree Knapsack Problem with
Dependency-based Discourse Parser
3.1 Motivation
In (Hirao et al., 2013), they automatically ob-
tain the DEP-DT by transforming from the parsed
RST-DT. We simply followed their method for ob-
taining the DEP-DTs
1
. The transformation algo-
rithm can be found in detail in (Hirao et al., 2013).
Figure 1(a) shows an example of the RST-DT. Ac-
cording to RST, a document is represented as a tree
whose terminal nodes correspond to elementary
discourse units (EDUs) and whose non-terminal
nodes indicate the role of the contiguous EDUs,
namely, ?nucleus (N)? or ?satellite (S)?. Since a nu-
cleus is more important than a satellite in terms of
the writer?s purpose, a satellite is always a child of
a nucleus in the RST-DT. Some discourse relations
between a nucleus and a satellite or two nuclei are
defined.
Since the TKP of (Hirao et al., 2013) employs
a DEP-DT obtained from an automatically parsed
RST-DT, their method strongly relies on the ac-
curacy of the RST parser. For example, in Fig-
ure 1(a), if the RST-DT parser incorrectly sets
the node n
2
as Satellite and the node n
3
as Nu-
cleus, we obtain an incorrect DEP-DT in Figure
1(b) because the transformation algorithm uses
the Nucleus-Satellite relationships in the RST-DT.
The dependency relationships in Figure 1(b) are
quite different from that of the correct DEP-DT in
Figure 1(c). In this example, the parser failed to
determine the most salient EDU e
2
, that is the root
EDU of the gold DEP-DT. Thus, the summary ex-
tracted from this DEP-DT will have a low ROUGE
score.
The results motivated us to design a new dis-
course parser fully trained on the DEP-DTs and
1
Li et al. also defined a similar transformation algorithm
(Li et al., 2014). In this paper, we follow the transformation
algorithm defined in (Hirao et al., 2013).
1835
Discourse)Dependency)Parser
Document Summary
Discourse)Dependency)Parser
Tree)Knapsack)Problem
Parser)Training)Phase
Summariza;on)Phase
e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#
Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#
Background# e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#
Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#
Background# e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#
Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#
Background#
DEP=DTs
e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#
Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#
Background#DEP=DT
Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ SS$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$
RST=DTs
Transforma;on)Algorithm
(a)
e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#
Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#
Background#
RST$Parser
Document Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$ SummaryRST$Parser
Transforma3on$Algorithm Tree$Knapsack$Problem
Parser$Training$Phase
Summariza3on$Phase
Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ SS$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$
Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$
Example$Concession$ An7thesis$
RST>DTs
RST>DT DEP>DT
(b)
Figure 2: (a) Overview of our proposed method. In the parser training phase, the parser is trained on
the DEP-DTs, and in the summarization phase, the document is directly parsed into the DEP-DT. (b)
Overview of (Hirao et al., 2013). In the parser training phase, the parser is trained on RST-DTs, and
in the summarization phase, the document is parsed into the RST-DT, and then transformed into the
DEP-DT.
that could directly generate the DEP-DT. Figure
2(a) shows an overview of the TKP combined with
our DEP-DT parser. In the parser training phase,
we transform RST-DTs into DEP-DTs, and di-
rectly train our parser with the DEP-DTs. In the
summarization phase, our method parses a raw
document directly into a DEP-DT, and generates
a summary with the TKP.
3.2 Description of Discourse Dependency
Parser
Our parser is based on the first-order Maximum
Spanning Tree (MST) algorithm (McDonald et al.,
2005b). Our parser extracts the features from the
EDU e
i
and the EDU e
j
. We use almost the fea-
tures as those shown in (Hernault et al., 2010).
Lexical N-gram features use the beginning (or
end) lexical N-grams (N ? {1, 2, 3}) in e
i
and
e
j
. We also include POS tags for the beginning
(or end) lexical N-grams (N ? {1, 2, 3}) in e
i
and
e
j
. Organizational features include the distance
between e
i
and e
j
. They also include the num-
ber of tokens, and features for identifying whether
or not e
i
and e
j
belong to the same sentence (or
paragraph). Soricut et al. (2003) introduced dom-
inance set features. They include syntactic labels
and the lexical heads of head and attachment nodes
along with their dominance relationship. We can-
not use the strong compositionality features and
rhetorical structure features described in (Her-
nault et al., 2010) because we have to know the
subtree structures in advance when using these
features.
To train the parser, we choose the Margin In-
fused Relaxed Algorithm (MIRA) (McDonald et
al., 2005a; Crammer et al., 2006). We denote
s(w,y) = w
T
f
y
as a score function given a
weight vector w and a DEP-DT y. L(y,y
?
) is
a loss function, and we define it as the number of
EDUs that have an incorrect parent EDU in a pre-
dicted DEP-DT y
?
= arg max
y
s(w,y). Then, we
solve the following optimization problem:
min
w
||w ?w
(t)
||
s.t. s(w,y) ? s(w,y
?
) ? L(y,y
?
),
(1)
where w
(t)
is a weight vector in the t-th iteration.
3.3 Redesign of Loss Function for Tree
Knapsack Problem
When we make a summary by solving a TKP, we
do not necessarily need a DEP-DT where all of the
parent-child relationships are correct. This is be-
cause we rarely select the EDUs around the leaves
in the DEP-DT. On the other hand, the parent-
child relationships around the root EDU in the
DEP-DT are important because we often select the
EDUs around the root EDU. Incorporating these
intuitions enables us to develop a DEP-DT parser
optimized for the TKP. To incorporate this infor-
mation, we define the following loss function:
L
Depth
(y,y
?
) =
?
(i,r,j)?y
[1 ? I(y
?
, i, j)]
Depth(e
i
)
, (2)
where I(y
?
, i, j) is an indicator function that
equals 1 if EDU e
j
is the parent of EDU e
i
in the
1836
DEP-DT y
?
and 0 otherwise. In Section 4, we re-
port results with the original loss function L(?, ?)
and with the modified loss function L
Depth
(?, ?).
4 Experimental Evaluation
4.1 Corpus
We used the RST-DT corpus (Carlson et al., 2002)
for our experimental evaluations. The corpus con-
sists of 385 Wall Street Journal articles with RST
annotation, and 30 of these documents also have
one human-made reference summary. We used
these 30 documents as the test documents for the
summarization evaluation, and used the remaining
355 RST annotated documents as the training data
for the parser. Note that we did not use the 30 test
documents for the summarization evaluation when
we trained the parser.
4.2 Summarization Evaluation
We compared the following three systems that dif-
fer in the way they obtain the DEP-DT.
TKP-GOLD Used a DEP-DT converted from a
gold RST-DT.
TKP-DIS-DEP Used a DEP-DT automatically
parsed by our discourse dependency-based
parser (DIS-DEP). Figure 2(a) shows an
overview of this system.
TKP-DIS-DEP-LOSS Used a DEP-DT automat-
ically parsed by our discourse dependency-
based parser (DIS-DEP). Figure 2(a) shows
an overview of this system. It is trained with
the loss function defined in equation (2).
TKP-HILDA Used a DEP-DT obtained by trans-
forming a RST-DT parsed by HILDA, a state-
of-the-art RST-DT parser (Hernault et al.,
2010). Figure 2(b) shows an overview of this
system.
Hirao et al. (2013) proved that TKP-HILDA
outperformed other methods including Marcu?s
method (Marcu, 1998), a simple knapsack model,
a maximum coverage model and LEAD method
that simply takes the first L tokens (L = summary
length). Thus, we only employed TKP-HILDA as
our baseline.
We follow the evaluation conditions described
in (Hirao et al., 2013). The number of tokens in
each summary is determined by the number in the
ROUGE-1 ROUGE-2
TKP-GOLD 0.321 0.112
TKP-DIS-DEP 0.319 0.109
TKP-DIS-DEP-LOSS 0.323 0.121
TKP-HILDA 0.284 0.093
Table 1: ROUGE Recall scores
human-annotated reference summary. The aver-
age length of the reference summaries corresponds
to about 10% of the words in the source document.
This is also the commonly used evaluation con-
dition for single-document summarization evalu-
ation on the RST-DT corpus. We employed the
recall of ROUGE-1, 2 as the evaluation measures.
Table 1 shows ROUGE scores on the RST-DT
corpus. We can see TKP-DIS-DEP and TKP-
DIS-DEP-LOSS outperformed TKP-HILDA, and
achieved almost the same ROUGE scores as TKP-
GOLD. Wilcoxon?s signed rank test in terms
of ROUGE rejected the null hypothesis, ?there
is a difference between TKP-HILDA and TKP-
DIS-DEP (or TKP-DIS-DEP-LOSS)? (Wilcoxon,
1945). This would be because test documents are
relatively small.
We analyzed the differences between the pro-
posed systems (TKP-DIS-DEP and TKP-DIS-
DEP-LOSS) and TKP-HILDA. First, we evaluated
the overlaps between the EDUs in summaries gen-
erated by the system and the EDUs in summaries
generated by TKP-GOLD. To see the overlaps, we
calculated the average F-value using Recall and
Precision defined as follows: Recall = |S
s
?
S
g
|/|S
g
|, Precision = |S
s
? S
g
|/|S
s
|, where S
s
is a set of EDUs in a summary generated by a sys-
tem, and S
g
a set of EDUs in a summary generated
by TKP-GOLD. The first line in Table 2 shows the
results. TKP-DIS-DEP and TKP-DIS-DEP-LOSS
outperformed TKP-HILDA as regards the aver-
age F-values. The result revealed that TKP-DIS-
DEP and TKP-DIS-DEP-LOSS have more EDUs
in common with TKP-GOLD than TKP-HILDA.
This result is evidence that TKP-DIS-DEP and
TKP-DIS-DEP-LOSS outperformed TKP-HILDA
in terms of ROUGE score.
Second, we evaluated the root accuracy (RA),
the rate at which a parser can find the root of DEP-
DTs. Since the root of a gold DEP-DT is the most
salient EDU in a document, it should be included
in the summary. The second line in Table 2 shows
that our methods succeeded in extracting the root
1837
TKP-DIS-DEP TKP-DIS-DEP-LOSS TKP-HILDA
Avg F-value 0.532
?
0.532
?
0.415
RA 0.933
?
0.933
?
0.733
Avg DAS 0.847
?
0.843
?
0.596
?: significantly better than TKP-HILDA (p < .05)
Table 2: Average F-value, Root Accuracy (RA), and average Dependency Accuracy in Summary (DAS).
Wilcoxon?s signed rank test in terms of average F-value, RA and DAS accepted the null hypothesis.
TKP-GOLD:
Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results. Elcotel, a telecommunications company, had net
income of $272,000, or five cents a share, in its year-earlier second quarter. The lower results, Mr. Pierce said. Elcotel will
also benefit from moving into other areas. Elcotel has also developed an automatic call processor. Automatic call processors
will provide that system for virtually any telephone, Mr. Pierce said, not just phones.
TKP-DIS-DEP, TKP-DIS-DEP-LOSS:
Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results. Elcotel, a telecommunications company, had net
income of $272,000, or five cents a share, in its year-earlier second quarter. George Pierce, chairman and chief executive officer,
said in an interview. Although Mr. Pierce expects that line of business to strengthen in the next year. Elcotel will also benefit
from moving into other areas. Elcotel has also developed an automatic call processor.
TKP-HILDA:
Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results. That several new products will lead to a ?much
stronger? performance in its second half. George Pierce, chairman and chief executive officer, said in an interview. Mr.
Pierce said Elcotel should realize a minimum of $10 of recurring net earnings for each machine each month. Elcotel has also
developed an automatic call processor. Automatic call processors will provide that system for virtually any telephone.
Figure 3: Summaries of wsj 2317. The sentences shown in bold-face are the root EDUs in each DEP-DT
of the summary.
of DEP-DT with high accuracy.
Third, to evaluate the coherency of the gener-
ated summaries, we compared the average Depen-
dency Accuracy in Summary (DAS), which is de-
fined as follows:
DAS(S) =
1
|S|
?
e?S
?(e),
?(e) =
{
1 (if parent(e) ? S)
0 (otherwise),
where S is a set of EDUs contained in the sum-
mary and parent(e) returns the parent EDU of e
in the gold DEP-DT. DAS(S) measures the rate of
the correct parent-child relationships in S. When
DAS equals 1, the summary is a rooted subtree of
the gold DEP-DT. The third line in Table 2 shows
the results. The results demonstrate that the sum-
maries generated by TKP-DIS-DEP or TKP-DIS-
DEP-LOSS tend to preserve the upper level depen-
dency relationships between the EDUs within the
gold DEP-DT.
Figure 3 shows summaries of wsj 2317 gener-
ated by the three systems. The EDUs correspond-
ing to the root of the DEP-DT are used in each
system shown in boldface. We can see that the
root EDU in the gold DEP-DT is found in the
summaries generated by TKP-DIS-DEP and TKP-
DIS-DEP-LOSS, but not in the summary gener-
ated by TKP-HILDA.
5 Conclusion
In this paper, we proposed a novel dependency-
based discourse parser for single-document sum-
marization. The parser enables us to obtain the
DEP-DT without transforming the RST-DT. The
evaluation results showed that the TKP with our
parser outperformed that with the state-of-the-art
RST-DT parser, and achieved almost equivalent
ROUGE scores to the TKP with the gold DEP-DT.
References
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2002. Rst discourse treebank,
ldc2002t07.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. The Journal of Ma-
chine Learning Research, 7:551?585.
1838
Hal Daum?e III and Daniel Marcu. 2002. A noisy-
channel model for document compression. In Pro-
ceedings of the 40th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL), pages 449
? 456, Philadelphia, PA, July 6 ? 12.
Hugo Hernault, Helmut Prendinger, Mitsuru Ishizuka,
et al. 2010. Hilda: a discourse parser using support
vector machine classification. Dialogue and Dis-
course, 1(3).
Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,
Norihito Yasuda, and Masaaki Nagata. 2013.
Single-document summarization as a tree knapsack
problem. In Proceedings of the 2013 Conference on
EMNLP, pages 1515?1520.
Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Man-
abu Okumura, and Masaaki Nagata. 2014. Single
document summarization based on nested tree struc-
ture. In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 315?320, Baltimore,
Maryland, June. Association for Computational Lin-
guistics.
Sujian Li, Liang Wang, Ziqiang Cao, and Wenjie Li.
2014. Text-level discourse dependency parsing. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 25?35, Baltimore, Maryland,
June. Association for Computational Linguistics.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243?281.
Daniel Marcu. 1998. Improving summarization
through rhetorical parsing tuning. In Proc. of The
6th Workshop on VLC, pages 206?215.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005a. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd An-
nual Meeting on Association for Computational Lin-
guistics, ACL ?05, pages 91?98, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005b. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceed-
ings of Human Language Technology Conference
and Conference on Empirical Methods in Natural
Language Processing, pages 523?530, Vancouver,
British Columbia, Canada, October. Association for
Computational Linguistics.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical infor-
mation. In Proceedings of the 2003 Human Lan-
guage Technology Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics.
Frank Wilcoxon. 1945. Individual Comparisons by
Ranking Methods. Biometrics Bulletin, 1(6):80?83,
December.
1839
