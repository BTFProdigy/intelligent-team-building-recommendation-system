Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 46?52,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Automated Identification of Synonyms in Biomedical  
Acronym Sense Inventories  
?
Genevieve B. Melton SungRim Moon 
Institute for Health Informatics & Dept of Surgery Institute for Health Informatics 
University of Minnesota University of Minnesota 
Minneapolis, MN 55455 USA Minneapolis, MN 55455 USA 
gmelton@umn.edu moonx086@umn.edu 
  
Bridget McInnes  Serguei Pakhomov 
College of Pharmacy College of Pharmacy 
University of Minnesota University of Minnesota 
Minneapolis, MN 55455 USA Minneapolis, MN 55455 USA 
bthomson@umn.edu  pakh0002@umn.edu 
?
  
Abstract 
Acronyms are increasingly prevalent in bio-
medical text, and the task of acronym disam-
biguation is fundamentally important for 
biomedical natural language processing sys-
tems. Several groups have generated sense in-
ventories of acronym long form expansions 
from the biomedical literature. Long form 
sense inventories, however, may contain con-
ceptually redundant expansions that negative-
ly affect their quality. Our approach to 
improving sense inventories consists of map-
ping long form expansions to concepts in the 
Unified Medical Language System (UMLS) 
with subsequent application of a semantic si-
milarity algorithm based upon conceptual 
overlap. We evaluated this approach on a ref-
erence standard developed for ten acronyms. 
A total of 119 of 155 (78%) long forms 
mapped to concepts in the UMLS. Our ap-
proach identified synonymous long forms 
with a sensitivity of 70.2% and a positive pre-
dictive value of 96.3%. Although further re-
finements are needed, this study demonstrates 
the potential value of using automated tech-
niques to merge synonymous biomedical 
acronym long forms to improve the quality of 
biomedical acronym sense inventories. 
1 Introduction 
Acronyms and abbreviations are increasingly used 
in biomedical text. This is in large part due to the 
expansive growth of the biomedical literature esti-
mated to be close to one million articles annually 
(Stead et al 2005). Ambiguous acronyms represent 
a challenge to both human readers and compute-
rized processing systems for resolving the 
acronym?s meaning within a particular context. For 
any given acronym, there are often multiple possi-
ble long form expansions. Techniques to determine 
the context-specific meaning or sense of an ambi-
guous acronym are fundamentally important for 
biomedical natural language processing and can 
assist with important tasks such as information re-
trieval and information extraction (Friedman 
2000). 
Acronym ambiguity resolution represents a spe-
cial case of word sense disambiguation (WSD) 
with unique challenges. In particular, there are in-
creasing numbers of new acronyms (i.e., short 
forms) as well as increasing numbers of new 
senses (i.e., long forms) for existing acronyms 
within biomedical text. Acronyms in biomedicine 
also range from those that are common, to those 
that are infrequent which appear to be created in an 
ad hoc fashion resulting essentially in neologisms 
distinct to small sets of biomedical discourse.  
Sense inventories are important tools that can 
assist in the task of disambiguation of acronyms 
and abbreviations. The relative formal nature of 
biomedical literature discourse lends itself well to 
building these inventories because long forms are 
typically contained within the text itself, providing 
a ?definition? on its first mention in an article, next 
to a parenthetical expression containing the short 
form or vice versa (Schwartz and Hearst 2003). In 
contrast, clinical documents are less structured and 
46
typically lack expanded long forms for acronyms 
and abbreviations, leaving sense inventories based 
on documents in the clinical domain not as well 
developed as the sense inventories developed from 
the biomedical literature (Pakhomov et al 2005).  
Compilation of sense inventories for acronyms 
in clinical documents typically relies on vocabula-
ries contained in the Unified Medical Language 
System (UMLS) as well as other resources such as 
ADAM (Zhou et al 2006). However, with the ad-
vantage of using rich and diverse resources like 
ADAM and the UMLS comes the challenge of 
having to identify and merge synonymous long 
form expansions which can occur for a given short 
form. Having synonymous long forms in a sense 
inventory for a given acronym poses a problem for 
automated acronym disambiguation because the 
sense inventory dictates that the disambiguation 
algorithm must be able to distinguish between se-
mantically equivalent senses. This is an important 
problem to address because effective identification 
of synonymous long forms allows for a clean sense 
inventory, and it creates the ability for long form 
expansions to be combined while preserving the 
variety of expression occurring in natural lan-
guage. By automating the merging of synonymous 
expansions and building a high quality sense in-
ventory, the task of acronym disambiguation will 
be improved resulting in better biomedical NLP 
system performance.  
Our approach to reducing multiple synonymous 
variants of the same long form for a set of ten bio-
medical acronyms is based on mapping sense in-
ventories for biomedical acronyms to the UMLS 
and using a semantic similarity algorithm based on 
conceptual overlap. This study is an exploratory 
evaluation of this approach on a manually created 
reference standard.  
2 Background  
2.1 Similarity measures in biomedicine 
The area of semantic similarity in biomedicine 
is a major area within biomedical NLP and know-
ledge representation research. Semantic similarity 
aids NLP systems, improves the performance of 
information retrieval tasks, and helps to reveal im-
portant latent relationships between biomedical 
concepts. Several investigators have studied con-
ceptual similarity and have used relationships in 
controlled biomedical terminologies, empiric sta-
tistical data from biomedical text, and other know-
ledge sources (Lee et al 2008; Caviedes and 
Cimino 2004). However, most of these techniques 
focus on generating measures between a single pair 
of concepts and do not deal directly with the task 
of comparing two groups of concepts.  
Patient similarity represents an important ana-
logous problem that deals with sets of concepts. 
The approach used by Melton et al (2006) was to 
represent each patient case as a set of nodes within 
a controlled biomedical terminology (SNOMED 
CT). The investigators then applied several meas-
ures to ascertain similarity between patient cases. 
These measures ranged from techniques indepen-
dent of the controlled terminology (i.e. set overlap 
or Hamming distance) to methods heavily reliant 
upon the controlled terminology based upon path 
traversal between pair of nodes using defined rela-
tionships (either IS-A relationships or other seman-
tic relationships) within the terminology.  
2.2 Lesk algorithm for measuring similarity 
using sets of definitional words 
A variety of techniques have been used for the 
general problem of WSD that range from highly 
labor intensive that depend upon human data tag-
ging (i.e. supervised learning) to unsupervised ap-
proaches that are completely automated and rely 
upon non-human sources of information, such as 
context and other semantic features of the sur-
rounding text or definitional data.  
The Lesk algorithm (Lesk 1986) is one example 
of an unsupervised method that uses dictionary 
information to perform WSD. This algorithm uses 
the observation that words co-occurring in a sen-
tence refer to the same topic and that dictionary 
definition words will have topically related senses, 
as well. The classic form of this algorithm returns a 
measure of word overlap. Lesk depends upon find-
ing common words between dictionary definitions. 
One shortcoming of Lesk, however, it that it can 
perform worse for words with terse, few word de-
finitions.  
As a modification of Lesk, researchers have 
proposed using WordNet (Felbaum 1998) to en-
hance its performance. WordNet has additional 
semantic information that can aid in the task of 
disambiguation, such as relationships between the 
term of interest and other terms. Banerjee and Pe-
47
dersen (2002) demonstrated that modifications to 
Lesk improved performance significantly with the 
addition of semantic relationship information. 
2.3 Biomedical literature sense inventories 
A number of acronym and abbreviation sense in-
ventories have been developed from the biomedi-
cal literature using a variety of approaches. Chang 
et al (2002) developed the Stanford biomedical 
abbreviation server1 using titles and abstracts from 
MEDLINE, lexical heuristic rules, and supervised 
logistic regression to align text and extract short 
form/long form pairs that matched well with 
acronym short form letters. Similarly, Adar (2004) 
developed the Simple and Robust Abbreviation 
Dictionary (SaRAD)2. This inventory, in addition 
to providing the abbreviation and definition, also 
clusters long forms using an N-gram approach 
along with classification rules to disambiguate de-
finitions. This resource, while analogous with re-
spect to its goal of merging and aligning long form 
expansions, is not freely available. Adar measured 
a normalized similarity between N-gram sets and 
then clustered long forms to create a clustered 
sense inventory resource. 
One of the most comprehensive biomedical 
acronym and abbreviation databases is ADAM 
(Zhou et al 2006) an open source database3 that 
we used for this study. Once identified, short 
form/long form pairs were filtered statistically with 
a rule of length ratio and an empirically-based cut-
off value.  This sense inventory is based on  
MEDLINE titles and abstracts from 2006 and con-
sists of over 59 thousand abbreviation/long form 
pairs. The authors report high precision with 
ADAM (97%) and up to 33% novel abbreviations 
not contained within the UMLS or Stanford Ab-
breviation dictionary.  
2.4 MetaMap resource for automated map-
ping to the UMLS 
An important resource for mapping words and 
phrases to the UMLS Metathesaurus is MetaMap. 
This resource was developed at the National Li-
brary of Medicine (Aronson 2001) to map text of 
biomedical abstracts to the UMLS. MetaMap uses 
                                                          
1 http://abbreviation.stanford.edu 
2 http://www.hpl.hp.com/shl/projects/abbrev.html 
3 http://arrowsmith.psych.uic.edu 
a knowledge intensive approach that relies upon 
computational linguistic, statistical, and symbol-
ic/lexical techniques. While MetaMap was initially 
developed to help with indexing of biomedical lite-
rature, it has been applied and expanded success-
fully to a number of diverse applications including 
clinical text.  
With each mapping, an evaluation function 
based upon centrality, variation, coverage, and co-
hesiveness generates a score for a given mapping 
from 0 to 1000 (strongest match). A cut-off score 
of 900 or greater is considered to represent a good 
conceptual match for MetaMap and was used in 
this study as the threshold to select valid mappings. 
3  Methods  
Ten randomly selected acronyms with between 10 
to 20 long forms were selected from the ADAM 
resource database for this pilot study.  
3.1 Long form mappings to UMLS 
Each acronym long-form was mapped to the 
UMLS with MetaMap using two settings. First, 
MetaMap was run with its default setting on each 
long form expansion. Second, MetaMap was run in 
its ?browse mode? (options ?-zogm?) which allows 
for term processing, overmatches, concept gaps, 
and ignores word order. 
Processing each long form with MetaMap then 
resulted in a set of Concept Unique Identifiers 
(CUIs) representing the long form. Each CUI with 
a score over 900 was included in the overall set of 
CUIs for a particular long form expansion. For a 
given pair of long form expansions the two sets of 
CUIs that each long form mapped to were com-
pared for concept overlap, in an analogous fashion 
to the Lesk algorithm. The overlap between con-
cept sets was calculated between each pair of long 
form expansions and expressed as a ratio: 
 
 ????????????? ????????? ???????????????? ?????????? ????????????? .   
 
For this study, an overlap of 50% or greater was 
considered to indicate a potential synonymous pair. 
Now let us assume that we have two concept 
sets: The first one is {A, B} and the second one is 
{A, B, C}, with each CUI having a score over 900. 
In this example, the overlap of concepts for the 
first concept set between it and the other is 100%, 
and for the second that is 66.7%. Because overlaps 
48
are greater than 50%, they are a potential syn-
onymous pair, and the overlap ratio is calculated as 
?????
????? ?
?
? = 1 (100%). 
3.2 Expert-derived reference standard 
Two physicians were asked to judge the similarity 
between each pair combination of long forms ex-
pansions on a continuous scale for our initial refer-
ence standard. Physicians were instructed to rate 
pairs of long forms for conceptual similarity. Long 
forms were presented on a large LCD touch-screen 
display (Hewlett-Packard TouchSmart 22? desk-
top) along with a continuous scale for the physi-
cians to rate long form pairs as dissimilar (far left 
screen) or highly similar (far right screen). The 
rating was measured on a scale from 1 to 1500 pix-
els representing the maximum width of the touch 
sensitive area of the display (along the x-
coordinate). Inter-rater agreement was assessed 
using Pearson correlation.  
Expert scores were then averaged and plotted 
on a histogram to visualize expert ratings. We sub-
sequently used a univariate clustering approach 
based on the R implementation of the Partitioning 
Around Medoids (PAM) method to estimate a cut-
off point between similar and dissimilar terms 
based on the vector of the average responses by the 
two physicians. The responses were clustered into 
two and three clusters based on an informal obser-
vation of the distribution of responses on the histo-
gram showing evidence of at least a bimodal and 
possibly a trimodal distribution.  
As a quality measure, a third physician manual-
ly reviewed the mean similarity ratings of the first 
two physicians to assess whether their similarity 
judgments represented the degree of synonymy 
between long form expansions necessary to war-
rant merging the long form expansions. This re-
view was done using a binary scale (0=not 
synonymous, 1=synonymous). 
3.3 Evaluation of automated methods  
Long form pair determinations based on the map-
pings to the UMLS were compared to our refer-
ence standard as described in Section 3.2. We 
calculated overall results of all long form pair 
comparisons and on all long form pairs that 
mapped to the UMLS with MetaMap. Performance 
is reported as sensitivity, specificity, and positive 
predictive value.  
4 Results 
A total of 10 random acronyms were used in this 
study. All long forms for these 10 acronyms were 
from the sense inventory ADAM (Zhou et al, 
2006). This resulted in a total of 155 long form 
expansions (median 16.5 per acronym, range 11-
19) (Table 1).  
Acronym N of LF  
expansions 
LF expansions 
mapped by MetaMap 
Total 155 119 (78%) 
ALT 13 9 (70%) 
CK 14 9 (64%) 
CSF 11 7 (74%) 
CTA 19 14 (74%) 
MN 19 17 (89%) 
NG 17 15 (88%) 
PCR 17 8 (47%) 
PET 17 15 (88%) 
RV 16 14 (88%) 
TTP 12 11(92%) 
Table 1. Number of acronym long forms in 
ADAM and mapping to the UMLS 
4.1 Long form mappings to UMLS 
The default mode of MetaMap resulted in 119 
(78%) long forms with mappings to the UMLS 
with MetaMap (Table 1). Use of MetaMap?s 
browse mode did not increase the total number of 
mapped long forms but did change some of the 
mapped concepts returned by MetaMap (not de-
picted).  
 
Acronym N pairs Pearson r 
Total 1125 0.78* 
ALT 78 0.79* 
CK 91 0.77* 
CSF 55 0.80* 
CTA 136 0.92* 
MN 171 0.69* 
NG 136 0.68* 
PCR 136 0.89* 
PET 136 0.78* 
RV 120 0.67* 
TTP 66 0.76* 
Table 2. Pearson correlation coefficient for ratings over-
all and for individual acronyms. *p<0.0001 
 
49
 
Figure 1. Two-way and three-way clustering solution of 
expert ratings of long form pairs. 
4.2 Expert-derived reference standard  
For the 1125 total comparison pairs, two raters as-
sessed similarity between long form pairs on a con-
tinuous scale. The overall mean correlation 
between the two raters was 0.78 (standard devia-
tion 0.08). Pearson correlation coefficients for each 
acronym are depicted in Table 2. 
 
Two-way and three-way clustering demonstrat-
ed an empirically determined ?cutoff? of 525 pix-
els from the left of the screen. This separation 
point between clusters (designated as ?low cutoff?) 
was evident on both the two-way and three-way 
clustering approaches using the PAM method to 
estimate a cut-off point between similar and dissi-
milar terms based on the vector of the average res-
ponses by the two physicians (Figure 1). Intuitively 
this low cutoff includes manual ratings indicative 
of moderate to low similarity (as 525 pixels along 
a 1500 pixel-wide scale is approximately one-third 
of the way from the left ?dissimilar? edge of the 
touch-sensitive screen). To isolate terms that were 
rated as highly similar, we also created an arbitrary 
?high cutoff? of 1200 pixels. 
 
 
Figure 2. Examples of terms originally rated as highly 
similar but not synonymous by the curating physician. 
 
Expert curation of the ratings by the third phy-
sician demonstrated that conceptual similarity rat-
ings were sometimes not equivalent to synonymy 
that would warrant the collapse of long form pairs. 
Of 1125 total pairs of long forms, 70 (6%) origi-
CTA: 
   ?CT hepatic arteriography?     ?CT angiography? 
MN:    
   ?median nerve?         ?motor neuron?  
RV:    
    ?rabies virus?           ?rotavirus? 
    ?right ventricular free wall?    ?right ventricle?                 
TTP:  
    ?thiamine triphosphate?          ?thymidine triphosphate? 
Default Mode: MetaMap Browse Mode: MetaMap 
All LF Mapped LF only All LF Mapped LF only 
High Cutoff 
Sensitivity  21.6% 39.6% 23.8% 43.8% 
Specificity  98.1% 96.8% 99.4% 99.0% 
PPV  48.7% 48.7% 77.8% 77.8% 
NPV  93.6% 95.5% 93.9% 95.9% 
Expert Curation 
Sensitivity  34.3% 64.9% 37.1% 70.2% 
Specificity  98.6% 97.7% 99.9% 99.8% 
PPV 61.5% 61.5% 96.3% 96.3% 
NPV  95.8% 98.0% 96.0% 98.3% 
 
Table 3. Performance of automated techniques for merging biomedical long form senses  
for all long forms and for long forms that mapped to the UMLS only.  
PPV, positive predictive value; NPV, negative predictive value. 
50
nally classified as similar were re-classified as 
conceptually different by the third physician. Sev-
eral examples of long form pairs that were origi-
nally rated as highly similar but were judged as not 
synonymous are contained in Figure 2. 
4.3 Evaluation of automated methods 
The performance of our algorithm is shown in Ta-
ble 3 using MetaMap in the default mode and 
browse mode and then applying our reference 
standard using the ?low cutoff?, ?high cutoff?, and 
expert curation (Table 3). Performance is reported 
for all 155 long forms (All LF) and for the subset 
of 119 long forms that mapped to the UMLS 
(Mapped LF only).  Compared to the ?low cutoff? 
reference standard, the ?high cutoff? and expert 
curation were positively associated with more con-
sistent performance. The browse mode identified 
fewer potential terms to merge and had higher ac-
curacy than the default MetaMap mode.   
5 Conclusions  
The results of this pilot study are promising and 
demonstrate high positive predictive value and 
moderate sensitivity for our algorithm, which indi-
cates to us that this technique with some additional 
modifications has value. We found that mapping 
long form expansions to a controlled terminology 
to not be straightforward. Although approximately 
80% of long forms mapped, another 20% were not 
converted to UMLS concepts. Because each long 
form resulted in multiple paired comparisons, a 
20% loss of mappings resulted globally in a 40% 
loss in overall system performance. While long 
form expansions were entered into MetaMap using 
a partially normalized representation of the long 
form, it is possible that additional normalization 
will improve our mapping. 
An important observation from our expert-
derived reference standard was that terms judged 
by physicians as semantically highly similar may 
not necessarily be synonymous (Figure 2). While 
semantic similarity is analogous, there may be 
some fundamentally different cognitive determina-
tions between similarity and synonymy for human 
raters.  
The current technique that we present compares 
sets of mapped concepts in an analogous fashion to 
the Lesk algorithm and other measures of similari-
ty between groups of concepts previously reported. 
This study did not utilize features of the controlled 
terminology nor statistical information about the 
text to help improve performance. Despite the lack 
of additional refinement to the presented tech-
niques, we found a flat overlap measure to be 
moderately effective in our evaluation. 
6 Future Work 
There are several lines of investigation that we will 
pursue as an extension of this study. The most ob-
vious would be to use semantic similarity measures 
between pairs of concepts that capitalize upon fea-
tures and relationships in the controlled terminolo-
gy. We can also expand upon the type of similarity 
measures for the overall long form comparison 
which requires a measure of similarity between 
groups of concepts. In addition, an empiric weight-
ing scheme based on statistical information of 
common senses may be helpful for concept map-
pings to place more or less emphasis on important 
or less important concepts. We plan to determine 
the impact of automatically reduced sense invento-
ries on the evaluation of WSD algorithms used for 
medical acronym disambiguation.   
Finally, we would like to utilize this work to 
help improve the contents of a sense inventory that 
we are currently developing for acronyms and ab-
breviations. This sense inventory is primarily 
based on clinical documents but incorporates in-
formation from a number of diverse sources in-
cluding ADAM, the UMLS, and a standard 
medical dictionary with abbreviations and acro-
nyms.  
Acknowledgments 
This work was supported by the University of 
Minnesota Institute for Health Informatics and De-
partment of Surgery and by the National Library of 
Medicine (#R01 LM009623-01). We would like to 
thank Fairview Health Services for ongoing sup-
port of this research. 
References  
Eytan Adar (2004) SaRAD: A simple and robust ab-
breviation dictionary. Bioinformatics 20:527?33. 
Alan R Aronson (2001) Effective mapping of biomedi-
cal text to the UMLS Metathesaurus: the MetaMap 
program. Proc AMIA Symp. 2001:17-21. 
51
Satanjeev Banerjee, Ted Pedersen. 2002. An Adapted 
Lesk Algorithm for Word Sense Disambiguation Us-
ing WordNet, Proceedings of the Third International 
Conference on Computational Linguistics and Intel-
ligent Text Processing, p.136-145, February 17-23. 
Jorge E. Caviedes JE, James J Cimino. (2004) Towards 
the development of a conceptual distance metric for 
the UMLS. J Biomed Inform. Apr;37(2):77?85. 
Jeffrey T Chang, Hinrich Schutze, Russ B Altman 
(2001) Creating an online dictionary of abbreviations 
from Medline. J Am Med Inform Assoc 9:612?20. 
Christiane Fellbaum, editor. 1998. WordNet: An elec-
tronic lexical database. MIT Press. 
Carol Friedman. 2000. A broad-coverage natural lan-
guage processing system. Proc AMIA Symp., 270?
274. 
Wei-Nchih Lee, Nigam Shah, Karanjot Sundlass, Mark 
Musen (2008) Comparison of Ontology-based Se-
mantic-Similarity Measures. AMIA Annu Symp 
Proc. 2008. 384?388. 
Michael E. Lesk. 1986. Automatic sense disambiguation 
using machine readable dictionaries: How to tell a 
pine cone from a ice cream cone. In Proceedings of 
SIGDOC ?86. 
Genevieve B. Melton, Simon Parsons, Frances P. Mor-
rison, Adam S. Rothschild, Marianthi Markatou, 
George Hripcsak. 2006. Inter-patient distance metrics 
using SNOMED CT defining relationships, Journal 
of Biomedical Informatics, 39(6), 697-705.  
Serguei Pakhomov, Ted Pedersen, Christopher G. 
Chute. 2005. Abbreviation and Acronym Disambigu-
ation in Clinical Discourse. American Medical In-
formatics Association Annual Symposium, 589-593. 
Ariel S Schwartz and Marti A. Hearst. 2003. A Simple 
Algorithm for Identifying Abbreviation Definitions 
in Biomedical Text. Pacific Symposium on Biocom-
puting p451-462. 
William W Stead, Brian J Kelly, Robert M Kolodner. 
2005. Achievable steps toward building a National 
Health Information infrastructure in the United 
States. J. Am. Med. Inform. Assoc., 12, 113?120. 
Wei Zhou, Vetle I Torvik, Neil R Smalheiser (2006) 
ADAM: Another database of abbreviations in Med-
line. Bioinformatics 22:2813? 8. 
52
Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 145?153,
Portland, Oregon, USA, 23?24 June 2011. c?2011 Association for Computational Linguistics
Using Second-order Vectors in a
Knowledge-based Method for Acronym Disambiguation
Bridget T. McInnes?
College of Pharmacy
University of Minnesota
Minneapolis, MN 55455
Ted Pedersen
Department of Computer Science
University of Minnesota
Duluth, MN 55812
Ying Liu
College of Pharmacy
University of Minnesota
Minneapolis, MN 55455
Serguei V. Pakhomov
College of Pharmacy
University of Minnesota
Minneapolis, MN 55455
Genevieve B. Melton
Institute for Health Informatics
University of Minnesota
Minneapolis, MN 55455
Abstract
In this paper, we introduce a knowledge-based
method to disambiguate biomedical acronyms
using second-order co-occurrence vectors. We
create these vectors using information about a
long-form obtained from the Unified Medical
Language System and Medline. We evaluate
this method on a dataset of 18 acronyms found
in biomedical text. Our method achieves an
overall accuracy of 89%. The results show
that using second-order features provide a dis-
tinct representation of the long-form and po-
tentially enhances automated disambiguation.
1 Introduction
Word Sense Disambiguation (WSD) is the task
of automatically identifying the appropriate sense of
a word with multiple senses. For example, the word
culture could refer to anthropological culture
(e.g., the culture of the Mayan civilization), or a
laboratory culture (e.g., cell culture).
Acronym disambiguation is the task of automat-
ically identifying the contextually appropriate long-
form of an ambiguous acronym. For example, the
acronym MS could refer to the disease Multiple Scle-
rosis, the drug Morphine Sulfate, or the state Missis-
sippi, among others. Acronym disambiguation can
be viewed as a special case of WSD, although, un-
like terms, acronyms tend to be complete phrases
or expressions, therefore collocation features are
not as easily identified. For example, the feature
rate when disambiguating the term interest, as in
?Contact author : bthomson@umn.edu.
interest rate, may not be available. Acronyms also
tend to be noun phrases, therefore syntactic features
do not provide relevant information for the purposes
of disambiguation.
Identifying the correct long-form of an acronym
is important not only for the retrieval of information
but the understanding of the information by the re-
cipient. In general English, Park and Byrd (2001)
note that acronym disambiguation is not widely
studied because acronyms are not as prevalent in lit-
erature and newspaper articles as they are in specific
domains such as government, law, and biomedicine.
In the biomedical sublanguage domain, acronym
disambiguation is an extensively studied problem.
Pakhomov (2002) note acronyms in biomedical lit-
erature tend to be used much more frequently than in
news media or general English literature, and tend
to be highly ambiguous. For example, the Uni-
fied Medical Language System (UMLS), which in-
cludes one of the largest terminology resources in
the biomedical domain, contains 11 possible long-
forms of the acronym MS in addition to the four
examples used above. Liu et al (2001) show that
33% of acronyms are ambiguous in the UMLS. In a
subsequent study, Liu et al (2002a) found that 80%
of all acronyms found in Medline, a large repository
of abstracts from biomedical journals, are ambigu-
ous. Wren and Garner (2002) found that there exist
174,000 unique acronyms in the Medline abstracts
in which 36% of them are ambiguous. The authors
also estimated that the number of unique acronyms
is increasing at a rate of 11,000 per year.
Supervised and semi-supervised methods have
been used successfully for acronym disambiguation
145
but are limited in scope due to the need for sufficient
training data. Liu et al (2004) state that an acronym
could have approximately 16 possible long-forms in
Medline but could not obtain a sufficient number of
instances for each of the acronym-long-form pairs
for their experiments. Stevenson et al (2009) cite
a similar problem indicating that acronym disam-
biguation methods that do not require training data,
regardless if it is created manually or automatically,
are needed.
In this paper, we introduce a novel knowledge-
based method to disambiguate acronyms using
second-order co-occurrence vectors. This method
does not rely on training data, and therefore, is not
limited to disambiguating only commonly occurring
possible long-forms. These vectors are created us-
ing the first-order features obtained from the UMLS
about the acronym?s long-forms and second-order
features obtained from Medline. We show that us-
ing second-order features provide a distinct repre-
sentation of the long-form for the purposes of dis-
ambiguation and obtains a significantly higher dis-
ambiguation accuracy than using first order features.
2 Unified Medical Language System
The Unified Medical Language System (UMLS) is
a data warehouse that stores a number of distinct
biomedical and clinical resources. One such re-
source, used in this work, is the Metathesaurus.
The Metathesaurus contains biomedical and clin-
ical concepts from over 100 disparate terminol-
ogy sources that have been semi-automatically in-
tegrated into a single resource containing a wide
range of biomedical and clinical information. For
example, it contains the Systematized Nomencla-
ture of Medicine?Clinical Terms (SNOMED CT),
which is a comprehensive clinical terminology cre-
ated for the electronic exchange of clinical health
information, the Foundational Model of Anatomy
(FMA), which is an ontology of anatomical concepts
created specifically for biomedical and clinical re-
search, and MEDLINEPLUS, which is a terminol-
ogy source containing health related concepts cre-
ated specifically for consumers of health services.
The concepts in these sources can overlap. For
example, the concept Autonomic nerve exists in both
SNOMED CT and FMA. The Metathesaurus assigns
the synonymous concepts from the various sources
a Concept Unique Identifiers (CUIs). Thus both
the Autonomic nerve concepts in SNOMED CT and
FMA are assigned the same CUI (C0206250). This
allows multiple sources in the Metathesaurus to be
treated as a single resource.
Some sources in the Metathesaurus contain ad-
ditional information about the concept such as a
concept?s synonyms, its definition and its related
concepts. There are two main types of relations
in the Metathesaurus that we use: the parent/child
and broader/narrower relations. A parent/child re-
lation is a hierarchical relation between two con-
cepts that has been explicitly defined in one of the
sources. For example, the concept Splanchnic nerve
has an is-a relation with the concept Autonomic
nerve in FMA. This relation is carried forward to
the CUI level creating a parent/child relations be-
tween the CUIs C0037991 (Splanchnic nerve) and
C0206250 (Autonomic nerve) in the Metathesaurus.
A broader/narrower relation is a hierarchical relation
that does not explicitly come from a source but is
created by the UMLS editors. We use the entire
UMLS including the RB/RN and PAR/CHD rela-
tions in this work.
3 Medline
Medline (Medical Literature Analysis and Retrieval
System Online) is a bibliographic database contain-
ing over 18.5 million citations to journal articles
in the biomedical domain which is maintained by
the National Library of Medicine (NLM). The 2010
Medline Baseline, used in this study, encompasses
approximately 5,200 journals starting from 1948 and
is 73 Gigabytes; containing 2,612,767 unique uni-
grams and 55,286,187 unique bigrams. The majority
of the publications are scholarly journals but a small
number of newspapers, and magazines are included.
4 Acronym Disambiguation
Existing acronym disambiguation methods can be
classified into two categories: form-based and
context-based methods. Form-based methods, such
as the methods proposed by Taghva and Gilbreth
(1999), Pustejovsky et al (2001), Schwartz and
Hearst (2003) and Nadeau and Turney (2005), dis-
ambiguate the acronym by comparing its letters di-
146
rectly to the initial letters in the possible long-forms
and, therefore, would have difficulties in distin-
guishing between acronyms with similar long-forms
(e.g., RA referring to Refractory anemia or Rheuma-
toid arthritis).
In contrast, context-based methods disambiguate
between acronyms based on the context in which the
acronym is used with the assumption that the context
surrounding the acronym would be different for each
of the possible long-forms. In the remainder of this
section, we discuss these types of methods in more
detail.
4.1 Context-based Acronym Disambiguation
Methods
Liu et al (2001) and Liu et al (2002b) introduce
a semi-supervised method in which training and
test data are automatically created by extracting ab-
stracts from Medline that contain the acronym?s
long-forms. The authors use collocations and a bag-
of-words approach to train a Naive Bayes algorithm
and report an accuracy of 97%. This method be-
gins to treat acronym disambiguation as more of a
WSD problem by looking at the context in which
the acronym exists to determine its long-form, rather
than the long-form itself. In a subsequent study, Liu
et al (2004) explore using additional features and
machine learning algorithms and report an accuracy
of 99% using the Naive Bayes.
Joshi (2006) expands on Liu, et als work. They
evaluate additional machine learning algorithms us-
ing unigrams, bigrams and trigrams as features.
They found that given their feature set, SVMs ob-
tain the highest accuracy (97%).
Stevenson et al (2009) re-recreate this dataset us-
ing the method described in Liu et al (2001) to auto-
matically create training data for their method which
uses a mixture of linguistics features (e.g., colloca-
tions, unigrams, bigrams and trigrams) in combina-
tion with the biomedical features CUIs and Medi-
cal Subject Headings, which are terms manually as-
signed to Medline abstracts for indexing purposes.
The authors evaluate the Naive Bayes, SVM and
Vector Space Model (VSM) described by Agirre and
Martinez (2004), and report that VSM obtained the
highest accuracy (99%).
Pakhomov (2002) also developed a semi-
supervised method in which training data was
automatically created by first identifying the long-
form found in the text of clinical reports, replacing
the long-form with the acronym to use as training
data. A maximum entropy model trained and tested
on a corpus of 10,000 clinical notes achieved an
accuracy of 89%. In a subsequent study, Pakhomov
et al (2005) evaluate obtaining training data from
three sources: Medline, clinical records and the
world wide web finding using a combination of
instances from clinical records and the web obtained
the highest accuracy.
Joshi et al (2006) compare using the Naive
Bayes, Decision trees and SVM on ambiguous
acronyms found in clinical reports. The authors
use the part-of-speech, the unigrams and the bi-
grams of the context surrounding the acronym as
features. They evaluate their method on 7,738
manually disambiguated instances of 15 ambiguous
acronyms obtaining an accuracy of over 90% for
each acronym.
5 Word Sense Disambiguation
Many knowledge-based WSD methods have been
developed to disambiguate terms which are closely
related to the work presented in this paper. Lesk
(1986) proposes a definition overlap method in
which the appropriate sense of an ambiguous term
was determined based on the overlap between its
definition in a machine readable dictionary (MRD).
Ide and Ve?ronis (1998) note that this work provided
a basis for most future MRD disambiguation meth-
ods; including the one presented in this paper.
Banerjee and Pedersen (2002) use the Lesk?s
overlap method to determine the relatedness be-
tween two concepts (synsets) in WordNet. They ex-
tend the method to not only include the definition
(gloss) of the two synsets in the overlap but also the
glosses of related synsets.
Wilks et al (1990) expand upon Lesk?s method by
calculating the number of times the words in the def-
inition co-occur with the ambiguous words. In their
method, a vector is created using the co-occurrence
information for the ambiguous word and each of its
possible senses. The similarity is then calculated be-
tween the ambiguous word?s vector and each of the
sense vectors. The sense whose vector is most simi-
lar is assigned to the ambiguous word.
147
0
.3
0 0 0 0 0 0disphosphoric
glucose
fructose
phosphoric
esters
changed
effect
0 0 0 0 0
glycolyte
en
zym
es
co
m
bined
decreases
intensity
acid
0
m
etabolites
FEATURES
0 0 0 0 .2 0acid 0 0 0 .1 0 0
0 0 0 0 .5 0 0esters 0 0 0 0 0 0
0 .1 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0
fructose
0 0 0 0 0 0
0 0 0 0 0 0 0
diphosphate
0 0 0 0 0 0isomer
0 0 0 0 0 0 0prevalent 0 0 0 0 0 0
0 .1 0 .3 .5 .2 02nd order vector forFructose Diphosphate 0 0 0 .1 0 0
Ex
te
nd
ed
 D
ef
in
iti
on

fo
r F
ru
ct
os
e 
Di
ph
os
ph
at
e
Figure 1: 2nd Order Vector for Fructose Diphosphate (FDP)
Patwardhan and Pedersen (2006) introduce a vec-
tor measure to determine the relatedness between
pairs of concepts. In this measure, a second order
co-occurrence vector is created for each concept us-
ing the words in each of the concepts definition and
calculating the cosine between the two vectors. This
method has been used in the task of WSD by calcu-
lating the relatedness between each possible sense
of the ambiguous word and its surrounding context.
The context whose sum is the most similar is as-
signed to the ambiguous word.
Second-order co-occurrence vectors were first in-
troduced by Schu?tze (1992) for the task of word
sense discrimination and later extended by Puran-
dare and Pedersen (2004). As noted by Pedersen
(2010), disambiguation requires a sense-inventory
in which the long-forms are known ahead of time,
where as in discrimination this information is not
known a priori.
6 Method
In our method, a second-order co-occurrence vec-
tor is created for each possible long-form of the
acronym, and the acronym itself. The appropriate
long-form of the acronym is then determined by
computing a cosine between the vector represent-
ing the ambiguous acronym and each of the vectors
representing the long-forms. The long-form whose
vector has the smallest angle between it and the
acronym vector is chosen as the most likely long-
form of the acronym.
To create a second-order vector for a long-form,
we first obtain a textual description of the long-form
in the UMLS, which we refer to as the extended defi-
nition. Each long-form, from our evaluation set, was
mapped to a concept in the UMLS, therefore, we use
the long-form?s definition plus the definition of its
parent/children and narrow/broader relations and the
terms in the long-form.
We include the definition of the related concepts
because not all concepts in the UMLS have a defini-
tion. In our evaluation dataset, not a single acronym
has a definition for each possible long-form. On
average, each extended definition contains approx-
imately 453 words. A short example of the extended
definition for the acronym FDP when referring to
148
fructose diphosphate is: ? Diphosphoric acid esters
of fructose. The fructose diphosphate isomer is most
prevalent. fructose diphosphate.?
After the extended definition is obtained, we cre-
ate the second-order vector by first creating a word
by word co-occurrence matrix in which the rows
represent the content words in the long-forms, ex-
tended definition, and the columns represent words
that co-occur in Medline abstracts with the words in
the definition. Each cell in this matrix contains the
Log Likelihood Ratio (Dunning (1993)) of the word
found in the row and the word in the column. Sec-
ond, each word in the long-forms, extended defini-
tion is replaced by its corresponding vector, as given
in the co-occurrence matrix. The centroid of these
vectors constitutes the second order co-occurrence
vector used to represent the long-form.
For example, given the example corpus contain-
ing two instances: 1) The metabolites, glucose fruc-
tose and their phosphoric acid esters are changed
due to the effect of glycolytic enzymes, and 2)
The phosphoric acid combined with metabolites de-
creases the intensity. Figure 1 shows how the
second-order co-occurrence vector is created for the
long-form fructose diphosphate using the extended
definition and features from our given corpus above.
The second-order co-occurrence vector for the
ambiguous acronym is created in a similar fashion,
only rather than using words in the extended defini-
tion, we use the words surrounding the acronym in
the instance.
Vector methods are subject to noise introduced by
features that do not distinguish between the differ-
ent long-forms of the acronym. To reduce this type
of noise, we select the features to use in the second
order co-occurrence vectors based on the following
criteria: 1) second order feature cannot be a stop-
word, and 2) second order feature must occur at least
twice in the feature extraction dataset and not occur
more than 150 times. We also experiment with the
location of the second-order feature with respect to
the first-order feature by varying the window size of
zero, four, six and ten words to the right and the left
of the first-order feature. The experiments in this
paper were conducted using CuiTools v0.15. 1
Our method is different from other context-based
1http://cuitools.sourceforge.net
acronym disambiguation methods discussed in the
related work because it does not require annotated
training data for each acronym that needs to be dis-
ambiguated. Our method differs from the method
proposed by Wilks et al (1990) in two fundamen-
tal aspects: 1) using the extended definition of
the possible long-forms of an acronym, and 2) using
second-order vectors to represent the instance con-
taining the acronym and each of the acronym?s pos-
sible long-forms.
7 Data
7.1 Acronym Dataset
We evaluated our method on the ?Abbrev? dataset 2
made available by Stevenson et al (2009). The
acronyms and long-forms in the data were initially
presented by Liu et al (2001). Stevenson et al
(2009) automatically re-created this dataset by iden-
tifying the acronyms and long-forms in Medline ab-
stracts and replacing the long-form in the abstract
with its acronym. Each abstract contains approxi-
mately 216 words. The dataset consists of three sub-
sets containing 100 instances, 200 instances and 300
instances of the ambiguous acronym referred to as
Abbrev.100, Abbrev.200, Abbrev.300, respectively.
The acronyms long-forms were manually mapped to
concepts in the UMLS by Stevenson, et al
A sufficient number of instances were not found
for each of the 21 ambiguous acronyms by Steven-
son et al (2009). For example, ?ASP? only con-
tained 71 instances and therefore not included in any
of the subsets. ?ANA? and ?FDP? only contained
just over 100 instances and therefore, are only in-
cluded in the Abbrev.100 subset. ?ACE?, ?ASP?
and ?CSF? were also excluded because several of
the acronyms? long-forms did not occur frequently
enough in Medline to create a balanced dataset.
We evaluate our method on the same subsets that
Stevenson et al (2009) used to evaluate their super-
vised method. The average number of long-forms
per acronym is 2.6 and the average majority sense
across all subsets is 70%.
7.2 Feature Extraction Dataset
We use abstracts from Medline, containing ambigu-
ous acronym or long-form, to create the second-
2http://nlp.shef.ac.uk/BioWSD/downloads/corpora
149
order co-occurrence vectors for our method as de-
scribed in Section 6. Table 1 shows the number of
Medline abstracts extracted for the acronyms.
Acronyms # Abstracts Acronym # Abstracts
ANA 3,267 APC 11,192
BPD 3,260 BSA 10,500
CAT 44,703 CML 8,777
CMV 13,733 DIP 2,912
EMG 16,779 FDP 1,677
LAM 1,572 MAC 6,528
MCP 2,826 PCA 11,044
PCP 5,996 PEG 10,416
PVC 2,780 RSV 5,091
Table 1: Feature Extraction Data for Acronyms
8 Results
Table 2 compares the majority sense baseline and the
first-order baseline with the results obtained using
our method on the Acronym Datasets (Abbrev.100,
Abbrev.200 and Abbrev.300) using a window size
of zero, four, six and ten. Differences between the
means of disambiguation accuracy produced by var-
ious approaches were tested for statistical signifi-
cance using the pair-wise Student?s t-tests with the
significance threshold set to 0.01.
Window Abbrev
Size 100 200 300
Maj. Sense Baseline 0.70 0.70 0.70
1-order Baseline 0.57 0.61 0.61
Our Method
0 0.83 0.83 0.81
4 0.86 0.87 0.86
6 0.88 0.90 0.89
10 0.88 0.90 0.89
Table 2: Overall Disambiguation Results
The majority sense baseline is often used to evalu-
ate supervised learning algorithms and indicates the
accuracy that would be achieved by assigning the
most frequent sense (long-form) to every instance.
The results in Table 2 demonstrate that our method is
significantly more accurate than the majority sense
baseline (p ? 0.01).
We compare the results using second-order vec-
tors to first-order vectors. Table 2 shows that ac-
curacy of the second-order results is significantly
higher than the first-order results (p ? 0.01).
The results in Table 2 also show that, as the win-
dow size grows from zero to six, the accuracy of the
system increases and plateaus at a window size of
ten. There is no statistically significant difference
between using a window size of six and ten but there
is a significant difference between a window size of
zero and six, as well as four and six (p ? 0.01).
Acronym # Long Abbrev Abbrev Abbrev
forms 100 200 300
ANA 3 0.84
APC 3 0.88 0.87 0.87
BPD 3 0.96 0.95 0.95
BSA 2 0.95 0.93 0.92
CAT 2 0.88 0.87 0.87
CML 2 0.81 0.84 0.83
CMV 2 0.98 0.98 0.98
DIP 2 0.98 0.98
EMG 2 0.88 0.89 0.88
FDP 4 0.65
LAM 2 0.86 0.87 0.88
MAC 4 0.94 0.95 0.95
MCP 4 0.73 0.67 0.68
PCA 4 0.78 0.79 0.79
PCP 2 0.97 0.96 0.96
PEG 2 0.89 0.89 0.88
PVC 2 0.95 0.95
RSV 2 0.97 0.98 0.98
Table 3: Individual Results using a Window Size of 6.
9 Error Analysis
Table 3 shows the results obtained by our method for
the individual acronyms using a window size of six,
and the number of possible long-forms per acronym.
Of the 18 acronyms, three obtain an accuracy below
80 percent: FDP, MCP and PCA.
FPD has four possible long-forms: Fructose
Diphosphate (E1), Formycin Diphosphate (E2), Fib-
rinogen Degradation Product (E3) and Flexor Dig-
itorum Profundus (E4). The confusion matrix in
Table 4 shows that the method was unable to dis-
tinguish between the two long-forms, E1 and E2,
which are both diphosphates, nor E2 and E3.
Long-Form E1 E2 E3 E4
E1: Fructose Diphosphate
E2: Formycin Diphosphate 5 2 11 19
E3: Fibrinogen Degradation Product 4
E4: Flexor Digitorum Profundus 59
Table 4: FDP Confusion Matrix
MCP also has four possible long-forms: Multicat-
alytic Protease (E1), Metoclopramide (E2), Mono-
cyte Chemoattractant Protein (E3) and Membrane
150
Cofactor Protein (E4). The confusion matrix in Ta-
ble 5 shows that the method was not able to distin-
guish between E3 and E4, which are both proteins,
and E1, which is a protease (an enzyme that breaks
down a protein).
Long-Form E1 E2 E3 E4
E1: Multicatalytic Protease 1 5 6 1
E2: Metoclopramide 15
E3: Monocyte Chemoattractant Protein 1 3 44 11
E4: Membrane Cofactor Protein 13
Table 5: MCP Confusion Matrix
PCA has four possible long-forms: Passive Cu-
taneous Anaphylaxis (E1), Patient Controlled Anal-
gesia (E2), Principal Component Analysis (E3), and
Posterior Cerebral Artery (E4). The confusion ma-
trix in Table 6 shows that the method was not able
to distinguish between E2 and E3. Analyzing the
extended definitions of the concepts showed that E2
includes the definition to the concept Pain Manage-
ment. The words in this definition overlap with
many of the words used in E3s extended definition.
Long-Form E1 E2 E3 E4
E1:Passive Cutaneous Anaphylaxis 18 6 1
E2:Patient Controlled Analgesia 5 15
E3:Principal Component Analysis 48
E4:Posterior Cerebral Artery 7
Table 6: PCA Confusion Matrix
10 Comparison with Previous Work
Of the previously developed methods, Liu et al
(2004) and Stevenson et al (2009) evaluated their
semi-supervised methods on the same dataset as we
used for the current study. A direct comparison
can not be made between our method and Liu et al
(2004) because we do not have an exact duplication
of the dataset that they use. Their results are com-
parable to Stevenson et al (2009) with both report-
ing results in the high 90s. Our results are directly
comparable to Stevenson et al (2009) who report
an overall accuracy of 98%, 98% and 99% on the
Abbrev.100, Abbrev.200 and Abbrev.300 datasets
respectively. This is approximately 10 percentage
points higher than our results.
The advantage of the methods proposed by
Stevenson et al (2009) and Liu et al (2004) is that
they are semi-supervised which have been shown to
obtain higher accuracies than methods that do not
use statistical machine learning algorithms. The dis-
advantage is that sufficient training data are required
for each possible acronym-long-form pair. Liu et
al. (2004) state that an acronym could have approxi-
mately 16 possible long-forms in Medline but a suf-
ficient number of instances for each of the acronym-
long-form pairs were not found in Medline and,
therefore, evaluated their method on 15 out of the
original 34 acronyms. Stevenson et al (2009) cite
a similar problem in re-creating this dataset. This
shows the limitation to these methods is that a suffi-
cient number of training examples can not be ob-
tained for each acronym that needs to be disam-
biguated. The method proposed in the paper does
not have this limitation and can be used to disam-
biguate any acronym in Medline.
11 Discussion
In this paper, we presented a novel method to disam-
biguate acronyms in biomedical text using second-
order features extracted from the UMLS and Med-
line. The results show that using second-order fea-
tures provide a distinct representation of the long-
form that is useful for disambiguation.
We believe that this is because biomedical text
contains technical terminology that has a rich source
of co-occurrence information associated with them
due to their compositionality. Using second-order
information works reasonably well because when
the terms in the extended definition are broken up
into their individual words, information is not being
lost. For example, the term Patient Controlled Anal-
gesia can be understood by taking the union of the
meanings of the three terms and coming up with an
appropriate definition of the term (patient has con-
trol over their analgesia).
We evaluated various window sizes to extract the
second-order co-occurrence information from, and
found using locally occurring words obtains a higher
accuracy. This is consistent with the finding reported
by Choueka and Lusignan (1985) who conducted an
experiment to determine what size window is needed
for humans to determine the appropriate sense of an
ambiguous word.
The amount of data used to extract the second-
151
order features for each ambiguous acronym varied
depending on its occurrence in Medline. Table 1 in
Section 7.2 shows the number of abstracts in Med-
line used for each acronym. We compared the accu-
racy obtained by our method using a window size of
six on the Abbrev.100 dataset with the number of ab-
stracts in the feature extraction data. We found that
the accuracy was not correlated with the amount of
data used (r = 0.07). This confirms that it is not the
quantity but the content of the contextual informa-
tion that determines the accuracy of disambiguation.
We compared using second-order features and
first-order features showing that the second-order re-
sults obtained a significantly higher accuracy. We
believe that this is because the definitions of the pos-
sible concepts are too sparse to provide enough in-
formation to distinguish between them. This find-
ing coincides to that of Purandare and Pedersen
(2004) and Pedersen (2010) who found that with
large amounts of data, first-order vectors perform
better than second-order vectors, but second-order
vectors are a good option when large amounts of
data are not available.
The results of the error analysis indicate that
for some acronyms using the extended definition
does not provide sufficient information to make
finer grained distinctions between the long-forms.
This result also indicates that, although many long-
forms of acronyms can be considered coarse-grained
senses, this is not always the case. For example, the
analysis of MCP showed that two of its possible
long-forms are proteins which are difficult to differ-
entiate from given the context.
The results of the error analysis also show that
indicative collocation features for acronyms are not
easily identified because acronyms tend to be com-
plete phrases. For example, two of the possible
long-forms of DF are Fructose Diphosphate and
Formycin Diphosphate.
Two main limitations of this work must be men-
tioned to facilitate the interpretation of the results.
The first is the small number of acronyms and the
small number of long-forms per acronym in the
dataset; however, the acronyms in this dataset are
representative of the kinds of acronyms one would
expect to see in biomedical text. The second limita-
tion is that the dataset contains only those acronyms
whose long-forms were found in Medline abstracts.
The main goal of this paper was to determine if the
context found in the long-forms, extended definition
was distinct enough to distinguish between them us-
ing second-order vectors. For this purpose, we feel
that the dataset was sufficient although a more ex-
tensive dataset may be needed in the future for im-
proved coverage.
12 Future Work
In the future, we plan to explore three different
avenues. The first avenue is to look at obtaining
contextual descriptions of the possible long-forms
from resources other than the UMLS such as the
MetaMapped Medline baseline and WordNet. The
second avenue is limiting the features that are used
in the instance vectors. The first-order features in
the instance vector contain the words from the entire
abstract. As previously mentioned, vector methods
are subject to noise, therefore, in the future we plan
to explore using only those words that are co-located
next to the ambiguous acronym. The third avenue is
expanding the vector to allow for terms. Currently,
we use word vectors, in the future, we plan to extend
the method to use terms, as identified by the UMLS,
as features rather than single words.
We also plan to test our approach in the clinical
domain. We believe that acronym disambiguation
may be more difficult in this domain due to the in-
crease amount of long-forms as seen in the datasets
used by Joshi et al (2006) and Pakhomov (2002).
13 Conclusions
Our study constitutes a significant step forward in
the area of automatic acronym ambiguity resolu-
tion, as it will enable the incorporation of scalable
acronym disambiguation into NLP systems used for
indexing and retrieval of documents in specialized
domains such as medicine. The advantage of our
method over previous methods is that it does not re-
quire manually annotated training for each acronym
to be disambiguated while still obtaining an overall
accuracy of 89%.
Acknowledgments
This work was supported by the National Insti-
tute of Health, National Library of Medicine Grant
#R01LM009623-01.
152
References
E. Agirre and D. Martinez. 2004. The Basque Country
University system: English and Basque tasks. In Pro-
ceedings of the 3rd ACL workshop on the Evaluation
of Systems for the Semantic Analysis of Text (SENSE-
VAL), pages 44?48.
S. Banerjee and T. Pedersen. 2002. An adapted lesk al-
gorithm for word sense disambiguation using Word-
Net. In Proceedings of the 3rd International Confer-
ence on Intelligent Text Processing and Computational
Linguistics, pages 136?145.
Y. Choueka and S. Lusignan. 1985. Disambiguation
by short contexts. Computers and the Humanities,
19(3):147?157.
T. Dunning. 1993. Accurate methods for the statistics of
surprise and coincidence. Computational Linguistics,
19(1):61?74.
N. Ide and J. Ve?ronis. 1998. Introduction to the special
issue on word sense disambiguation: the state of the
art. Computational Linguistics, 24(1):2?40.
M. Joshi, S. Pakhomov, T. Pedersen, and C.G. Chute.
2006. A comparative study of supervised learning as
applied to acronym expansion in clinical reports. In
Proceedings of the Annual Symposium of AMIA, pages
399?403.
M. Joshi. 2006. Kernel Methods for Word Sense Disam-
biguation and Abbreviation Expansion. Master?s the-
sis, University of Minnesota.
M. Lesk. 1986. Automatic sense disambiguation using
machine readable dictionaries: how to tell a pine cone
from an ice cream cone. Proceedings of the 5th Annual
International Conference on Systems Documentation,
pages 24?26.
H. Liu, YA. Lussier, and C. Friedman. 2001. Disam-
biguating ambiguous biomedical terms in biomedical
narrative text: an unsupervised method. Journal of
Biomedical Informatics, 34(4):249?261.
H. Liu, A.R. Aronson, and C. Friedman. 2002a. A study
of abbreviations in MEDLINE abstracts. In Proceed-
ings of the Annual Symposium of AMIA, pages 464?
468.
H. Liu, S.B. Johnson, and C. Friedman. 2002b. Au-
tomatic resolution of ambiguous terms based on ma-
chine learning and conceptual relations in the UMLS.
JAMIA, 9(6):621?636.
H. Liu, V. Teller, and C. Friedman. 2004. A multi-
aspect comparison study of supervised word sense dis-
ambiguation. JAMIA, 11(4):320?331.
D. Nadeau and P. Turney. 2005. A supervised learning
approach to acronym identification. In Proceedings
of the 18th Canadian Conference on Artificial Intelli-
gence, pages 319?329.
S. Pakhomov, T. Pedersen, and C.G. Chute. 2005. Ab-
breviation and acronym disambiguation in clinical dis-
course. In Proceedings of the Annual Symposium of
AMIA, pages 589?593.
S. Pakhomov. 2002. Semi-supervised maximum en-
tropy based approach to acronym and abbreviation
normalization in medical texts. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, pages 160?167.
Y. Park and R.J. Byrd. 2001. Hybrid text mining for find-
ing abbreviations and their definitions. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 126?133.
S. Patwardhan and T. Pedersen. 2006. Using WordNet-
based context vectors to estimate the semantic related-
ness of concepts. In Proceedings of the EACL 2006
Workshop Making Sense of Sense - Bringing Com-
putational Linguistics and Psycholinguistics Together,
pages 1?8.
T. Pedersen. 2010. The effect of different context repre-
sentations on word sense discrimination in biomedical
texts. In Proceedings of the 1st ACM International IHI
Symposium, pages 56?65.
A. Purandare and T. Pedersen. 2004. Word sense dis-
crimination by clustering contexts in vector and sim-
ilarity spaces. In Proceedings of the Conference on
Computational Natural Language Learning (CoNLL),
pages 41?48.
J. Pustejovsky, J. Castano, B. Cochran, M. Kotecki,
M. Morrell, and A. Rumshisky. 2001. Extraction and
disambiguation of acronym-meaning pairs in medline.
Unpublished manuscript.
H. Schu?tze. 1992. Dimensions of meaning. In Proceed-
ings of the 1992 ACM/IEEE Conference on Supercom-
puting, pages 787?796.
A.S. Schwartz and M.A. Hearst. 2003. A simple
algorithm for identifying abbreviation definitions in
biomedical text. In Proceedings of the Pacific Sym-
posium on Biocomputing (PSB), pages 451?462.
M. Stevenson, Y. Guo, A. Al Amri, and R. Gaizauskas.
2009. Disambiguation of biomedical abbreviations.
In Proceedings of the ACL BioNLP Workshop, pages
71?79.
K. Taghva and J. Gilbreth. 1999. Recognizing acronyms
and their definitions. ISRI UNLV, 1:191?198.
Y. Wilks, D. Fass, C.M. Guo, J.E. McDonald, T. Plate,
and B.M. Slator. 1990. Providing machine tractable
dictionary tools. Machine Translation, 5(2):99?154.
J.D. Wren and H.R. Garner. 2002. Heuristics for iden-
tification of acronym-definition patterns within text:
towards an automated construction of comprehensive
acronym-definition dictionaries. Methods of Informa-
tion in Medicine, 41(5):426?434.
153
