Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 19?28,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
Hierarchical Alignment Decomposition Labels for Hiero Grammar Rules
Gideon Maillette de Buy Wenniger
Institute for Logic,
Language and Computation
University of Amsterdam
Science Park 904, 1098 XH Amsterdam
The Netherlands
gemdbw AT gmail.com
Khalil Sima?an
Institute for Logic,
Language and Computation
University of Amsterdam
Science Park 904, 1098 XH Amsterdam
The Netherlands
k.simaan AT uva.nl
Abstract
Selecting a set of nonterminals for the syn-
chronous CFGs underlying the hierarchical
phrase-based models is usually done on the
basis of a monolingual resource (like a syntac-
tic parser). However, a standard bilingual re-
source like word alignments is itself rich with
reordering patterns that, if clustered some-
how, might provide labels of different (pos-
sibly complementary) nature to monolingual
labels. In this paper we explore a first ver-
sion of this idea based on a hierarchical de-
composition of word alignments into recursive
tree representations. We identify five clus-
ters of alignment patterns in which the chil-
dren of a node in a decomposition tree are
found and employ these five as nonterminal la-
bels for the Hiero productions. Although this
is our first non-optimized instantiation of the
idea, our experiments show competitive per-
formance with the Hiero baseline, exemplify-
ing certain merits of this novel approach.
1 Introduction
The Hiero model (Chiang, 2007; Chiang, 2005)
formulates phrase-based translation in terms of a
synchronous context-free grammar (SCFG) limited
to the inversion transduction grammar (ITG) (Wu,
1997) family. While the original Hiero approach
works with a single nonterminal label (X) (besides
the start nonterminal S ), more recent work is dedi-
cated to devising methods for extracting more elab-
orate labels for the phrase-pairs and their abstrac-
tions into SCFG productions, e.g., (Zollmann and
Venugopal, 2006; Li et al, 2012; Almaghout et al,
2011). All labeling approaches exploit monolin-
gual parsers of some kind, e.g., syntactic, seman-
tic or sense-oriented. The rationale behind mono-
lingual labeling is often to make the probability dis-
tributions over alternative synchronous derivations
of the Hiero model more sensitive to linguistically
justified monolingual phrase context. For example,
syntactic target-language labels in many approaches
are aimed at improved target language modeling
(fluency, cf. Hassan et al (2007); Zollmann and
Venugopal (2006)), whereas source-language labels
provide suitable context for reordering (see Mylon-
akis and Sima?an (2011)). It is usually believed
that the monolingual labels tend to stand for clus-
ters of phrase pairs that are expected to be inter-
substitutable, either syntactically or semantically
(see Marton et al (2012) for an illuminating discus-
sion).
While we believe that monolingual labeling
strategies are sound, in this paper we explore the
complementary idea that the nonterminal labels
could also signify bilingual properties of the phrase
pair, particularly its characteristic word alignment
patterns. Intuitively, an SCFG with nonterminal la-
bels standing for alignment patterns should put more
preference on synchronous derivations that mimic
the word alignment patterns found in the training
corpus, and thus, possibly allow for better reorder-
ing. It is important to stress the fact that these word
alignment patterns are complementary to the mono-
lingual linguistic patterns and it is conceivable that
the two can be combined effectively, but this remains
beyond the scope of this article.
The question addressed in this paper is how to se-
lect word alignment patterns and cluster them into
bilingual nonterminal labels? In this paper we ex-
plore a first instantiation of this idea starting out
from the following simplifying assumptions:
19
? The labels come from the word alignments
only,
? The labels are coarse-grained, pre-defined clus-
ters and not optimized for performance,
? The labels extend the binary set of ITG oper-
ators (monotone and inverted) into five such
labels in order to cover non-binarizable align-
ment patterns.
Our labels are based on our own tree decomposi-
tions of word alignments (Sima?an and Maillette de
Buy Wenniger, 2011), akin to Normalized Decom-
position Trees (NDTs) (Zhang et al, 2008). In this
first attempt we explore a set of five nonterminal la-
bels that characterize alignment patterns found di-
rectly under nodes in the NDT projected for every
word alignment in the parallel corpus during train-
ing. There is a range of work that exploits the mono-
tone and inverted orientations of binary ITG within
hierarchical phrase-based models, either as feature
functions of lexicalized Hiero productions (Chiang,
2007; Zollmann and Venugopal, 2006), or as labels
on non-lexicalized ITG productions, e.g., (Mylon-
akis and Sima?an, 2011). As far as we are aware,
this is the first attempt at exploring a larger set of
such word alignment derived labels in hierarchical
SMT. Therefore, we expect that there are many vari-
ants that could improve substantially on our strong
set of assumptions.
2 Hierarchical SMT models
Hierarchical SMT usually works with weighted in-
stantiations of Synchronous Context-Free Gram-
mars (SCFGs) (Aho and Ullman, 1969). SCFGs
are defined over a finite set of nonterminals (start
included), a finite set of terminals and a finite set
of synchronous productions. A synchronous pro-
duction in an SCFG consists of two context-free
productions (source and target) containing the same
number of nonterminals on the right-hand side, with
a bijective (1-to-1 and onto) function between the
source and target nonterminals. Like the standard
Hiero model (Chiang, 2007), we constrain our work
to SCFGs which involve at most two nonterminals
in every lexicalized production.
Given an SCFG G, a source sentence s is trans-
lated into a target sentence t by synchronous deriva-
tions d, each is a finite sequence of well-formed
substitutions of synchronous productions from G,
see (Chiang, 2006). Standardly, for complexity rea-
sons, most models used make the assumption that
the probability P(t | s) can be optimized through as
single best derivation as follows:
arg max
t
P(t | s) = arg max
t
?
d?G
P(t,d | s) (1)
? arg max
d?G
P(t,d | s) (2)
This approximation can be notoriously problematic
for labelled Hiero models because the labels tend
to lead to many more derivations than in the orig-
inal model, thereby aggravating the effects of this
assumption. This problem is relevant for our work
and approaches to deal with it are Minimum Bayes-
Risk decoding (Kumar and Byrne, 2004; Tromble et
al., 2008), Variational Decoding (Li et al, 2009) and
soft labeling (Venugopal et al, 2009; Marton et al,
2012; Chiang, 2010).
Given a derivation d, most existing phrase-
based models approximate the derivation probabil-
ity through a linear interpolation of a finite set of
feature functions (?(d)) of the derivation d, mostly
working with local feature functions ?i of individ-
ual productions, the target side yield string t of d
(target language model features) and other heuristic
features discussed in the experimental section:
arg max
d?G
P(t,d | s) ? arg max
d?G
|?(d)|?
i=1
?i ? ?i (3)
Where ?i is the weight of feature ?i optimized over
a held-out parallel corpus by some direct error-
minimization procedure like MERT (Och, 2003).
3 Baseline: Hiero Grammars (single label)
Hiero Grammars (Chiang, 2005; Chiang, 2007) are
a particular form of SCFGs that generalize phrase-
based translation models to hierarchical phrase-
based Translation models. They allow only up to
two (pairs of) nonterminals on the right-hand-side of
rules. Hierarchical rules are formed from fully lex-
icalized base rules (i.e. phrase pairs) by replacing a
sub-span of the phrase pair that corresponds itself to
a valid phrase pair with variable X called ?gap?. Two
20
gaps may be maximally introduced in this way1, la-
beled as X1 and X2 respectively for distinction. The
types of permissible Hiero rules are:
X ? ??, ?? (4a)
X ? ?? X1 ?, ? X1 ?? (4b)
X ? ?? X1 ? X2 ? , ? X1 ? X2 ? ? (4c)
X ? ?? X1 ? X2 ? , ? X2 ? X1 ? ? (4d)
Here ?, ?, ?, ?, ?, ? are terminal sequences, pos-
sibly empty. Equation 4a corresponds to a normal
phrase pair, 4b to a rule with one gap and 4c and 4d
to the monotone- and inverting rules respectively.
An important extra constraint used in the original
Hiero model is that rules must have at least one pair
of aligned words, so that translation decisions are al-
ways based on some lexical evidence. Furthermore
the sum of terminals and nonterminals on the source
side may not be greater than five, and nonterminals
are not allowed to be adjacent on the source side.
4 Alignment Labeled Grammars
Labeling the Hiero grammar productions makes
rules with gaps more restricted about what broad
categories of rules are allowed to substitute for the
gaps. In the best case this prevents overgeneraliza-
tion, and makes the translation distributions more
accurate. In the worst case, however, it can also lead
to too restrictive rules, as well as sparse translation
distributions. Despite these inherent risks, a number
of approaches based on syntactically inspired labels
has succeeded to improve the state of the art by
using monolingual labels, e.g., (Zollmann and
Venugopal, 2006; Zollmann, 2011; Almaghout et
al., 2011; Chiang, 2010; Li et al, 2012).
Unlabeled Hiero derivations can be seen as recur-
sive compositions of phrase pairs. A single transla-
tion may be generated by different derivations (see
equation 1), each standing for a choice of com-
position rules over a choice of a segmentation of
the source-target sentence pair into a bag of phrase
pairs. However, a synchronous derivation also in-
duces an alignment between the different segments
1The motivation for this restriction to two gaps is mainly a
practical computational one, as it can be shown that translation
complexity grows exponentially with the number of gaps.
that it composes together. Our goal here is to la-
bel the Hiero rules in order to exploit aspects of the
alignment that a synchronous derivation induces.
We exploit the idea that phrase pairs can be ef-
ficiently grouped into maximally decomposed trees
(normalized decomposition trees ? NDTs) (Zhang
et al, 2008). In an NDT every phrase pair is re-
cursively decomposed at every level into the mini-
mum number of its phrase constituents, so that the
resulting structure is maximal in that it contains the
largest number of nodes. In Figure 1 left we show
an example alignment and in Figure 1 right its as-
sociated NDT. The NDT shows pairs of source and
target spans of (sub-) phrase pairs, governed at dif-
ferent levels of the tree by their parent node. In
our example the root node splits into three phrase
pairs, but these three phrase pairs together do not
manage to cover the entire phrase pair of the par-
ent because of the discontinuous translation struc-
ture ?owe, sind ... schuldig?. Consequently, a par-
tially lexicalized structure with three children corre-
sponding to phrase pairs and lexical items covering
the words left by these phrase pairs is required.
During grammar extraction we determine an
Alignment Label for every left-hand-side and gap of
every rule we extract. This is done by looking at the
NDT that decomposes their corresponding phrase
pairs, and determining the complexity of the rela-
tion with their direct children in this tree. Complex-
ity cases are ordered by preference, where the more
simple label corresponding to the choice of maximal
decomposition is preferred. We distinguish the fol-
lowing five cases, ordered by increasing complexity:
1. Monotonic: If the alignment can be split into
two monotonically ordered parts.
2. Inverted: If the alignment can be split into two
inverted parts.
3. Permutation: If the alignment can be factored
as a permutation of more than 3 parts.2
4. Complex: If the alignment cannot be factored
as a permutation of parts, but the phrase does
contain at least one smaller phrase pair (i.e., it
is composite).
5. Atomic: If the alignment does not allow the ex-
istence of smaller (child) phrase pairs.
2Permutations of just 3 parts never occur in a NDT, as they
can always be further decomposed as a sequence of two binary
nodes.
21
1
we
2
owe
3
this
4
to
5
our
6
citizens
das
1
sind
2
wir
3
unsern
4
burgern
5
schuldig
6
([1, 6], [1, 6])
([5, 6], [4, 5])
([6, 6], [5, 5])([5, 5], [4, 4])
([3, 3], [1, 1])([1, 1], [3, 3])
Figure 1: Example of complex word alignment, taken from Europarl data English-German (left) and its associated
Normalized Decomposition Tree (Zhang et al, 2008) (right).
We show examples of each of these cases in Figure
2. Furthermore, in Figure 3 we show an example
of an alignment labeled Hiero rule based on one of
these alignment examples.
Our kind of labels has a completely different fla-
vor from monolingual labels in that they cannot be
seen as identifying linguistically meaningful clus-
ters of phrase pairs. These labels are mere latent
bilingual clusters and the translation model must
marginalize over them (equation 1) or use Minimum
Bayes-Risk decoding.
4.1 Features : Relations over labels
In this section we describe the features we use in
our experiments. To be unambiguous we first need
to introduce some terminology. Let r be a transla-
tion rule. We use p? to denote probabilities estimated
using simple relative frequency estimation from the
word aligned sentence pairs of the training corpus.
Then src(r) is the source side of the rule, includ-
ing the source side of the left-hand-side label. Simi-
larly tgt(r) is the target side of the rule, including the
target side of the left-hand-side label. Furthermore
un(src(r)) is the source side without any nontermi-
nal labels, and analogous for un(tgt(r)).
4.1.1 Basic Features
We use the following phrase probability features:
? p?(tgt(r)|src(r)): Phrase probability target side
given source side
? p?(src(r)|tgt(r)): Phrase probability source side
given target side
We reinforce those by the following phrase prob-
ability smoothing features:
? p?(tgt(r)|un(src(r)))
? p?(un(src(r))|tgt(r))
? p?(un(tgt(r))|src(r))
? p?(src(r)|un(tgt(r)))
? p?(un(tgt(r))|un(src(r)))
? p?(un(src(r))|un(tgt(r)))
We also add the following features:
? p?w(tgt(r)|src(r)), p?w(src(r)|tgt(r)): Lexical
weights based on terminal symbols as for
phrase-based and hierarchical phrase-based
MT.
? p?(r|lhs(r)) : Generative probability of a rule
given its left-hand-side label
We use the following set of basic binary features,
with 1 values by default, and a value exp(1) if the
corresponding condition holds:
? ?Glue(r): exp(1) if rule is a glue rule
? ?lex(r): exp(1) if rule has only terminals on
right-hand side
? ?abs(r): exp(1) if rule has only nonterminals on
right-hand side
? ?st w tt(r): exp(1) if rule has terminals on the
source side but not on the target side
? ?tt w st(r): exp(1) if rule has terminals on the
target side but not on the source side
? ?mono(r): exp(1) if rule has no inverted pair of
nonterminals
Furthermore we use the :
? ?ra(r): Phrase penalty, exp(1) for all rules.
? exp(?wp(r)): Word penalty, exponent of the
number of terminals on the target side
? ?rare(r): exp( 1#(?r??C ?rr? ) ) : Rarity penalty, with
#(
?
r??C ?rr?) being the count of rule r in the cor-
pus.
4.1.2 Binary Reordering Features
Besides the basic features we want to use extra
sets of binary features that are specially designed
to directly learn the desirability of certain broad
classes of reordering patterns, beyond the way this
is already implicitly learned for particular lexical-
ized rules by the introduction of reordering labels.3
These features can be seen as generalizations of the
most simple feature that penalizes/rewards mono-
3We did some initial experiments with such features in
Joshua, but haven?t managed yet to get them working in Moses
with MBR. Since these experiments are inconclusive without
MBR we leave them out here.
22
this is an important matter
das ist ein wichtige angelegenheit
1
1
2
2
Monotone
we all agree on this
das sehen wir alle
1
1
2
2
Inversion
i want to stress two points
auf zwei punkte mo?chte ich hinweisen
1
1
2
2
3
3
4
4
Permutation
we owe this to our citizens
das sind wir unsern burgern schuldig
1
1
2
2
3
3
Complex
it would be possible
kann mann
1
1
Atomic
Figure 2: Different types of Alignment Labels
tone order ?mono(r) from our basic feature set. The
new features we want to introduce ?fire? for a spe-
cific combination of reordering labels on the left
hand side and one or both gaps, plus optionally the
information whether the rule itself invert its gaps and
whether or not it is abstract.
5 Experiments
We evaluate our method on one language pair using
German as source and English as target. The data is
derived from parliament proceedings sourced from
the Europarl corpus (Koehn, 2005), with WMT-07
development and test data. We used a maximum
sentence length of 40 for filtering. We employ ei-
ther 200K or (approximately) 1000K sentence pairs
for training, 1K for development and 2K for test-
ing (single reference per source sentence). Both the
baseline and our method decode with a 3-gram lan-
guage model smoothed with modified Knesser-Ney
discounting (Chen and Goodman, 1998), trained on
the target side of the full original training set (ap-
proximately 1000K sentences).
We compare against state-of-the-art hierarchi-
cal translation (Chiang, 2005) baselines, based on
the Joshua (Ganitkevitch et al, 2012) and Moses
(Hoang et al, 2007) translation systems with default
decoding settings. We use our own grammar extrac-
we owe this to our citizens
das sind wir unsern burgern schuldig
X Complex
X Atomic1
X Atomic1
X Monotone2
X Monotone2
X Complex
Figure 3: Example of a labeled Hiero rule
X Complex? ?we owe X Atomic1 to X Monotone2 ,
X Atomic1 sind wir X Monotone2 schuldig ?
extracted from the Complex example in Figure 2 by re-
placing the phrase pairs ?this, das? and ?our citizens , un-
sern burgern? with (labeled) variables.
tor for the generation of all grammars, including the
baseline Hiero grammars. This enables us to use the
same features (as far as applicable given the gram-
mar formalism) and assure true comparability of the
grammars under comparison.
5.1 Training and Decoding Details
In this section we discuss the choices and settings
we used in our experiments. Our initial experiments
4We later discovered we needed to add the flag ??return-
best-dev? in Moses to actually get the weights from the best
development run, our initial experiments had not used this. This
explains the somewhat unfortunate drop in performance in our
Analysis Experiments.
23
Decoding
Type
System
Name 200K
Lattice
MBR
Hiero 26.44
Hiero-RL 26.72
Viterbi Hiero 26.23Hiero-RL-PPL 26.16
Table 1: Initial Results. Lowercase BLEU results for
German-English trained on 200K sentence pairs.4
Top rows display results for our experiments using Moses
(Hoang et al, 2007) with Lattice Minimum Bayes-Risk
Decoding5 (Tromble et al, 2008) in combination with
Batch Mira (Cherry and Foster, 2012) for tuning. Below
are results for experiments with Joshua (Ganitkevitch et
al., 2012) using Viterbi decoding (i.e. no MBR) and PRO
(Hopkins and May, 2011) for tuning.
were done on Joshua (Ganitkevitch et al, 2012),
using the Viterbi best derivation. The second set
of experiments was done on Moses (Hoang et al,
2007) using Lattice Minimum Bayes-Risk Decod-
ing5 (Tromble et al, 2008) to sum over derivations.
5.1.1 General Settings
To train our system we use the following settings.
We use the standard Hiero grammar extraction
constraints (Chiang, 2007) but for our reordering
labeled grammars we use them with some modifi-
cations. In particular, while for basic Hiero only
phrase pairs with source spans up to 10 are allowed,
and abstract rules are forbidden, we allow extraction
of fully abstract rules, without length constraints.
Furthermore we allow their application without
length constraints during decoding. Following
common practice, we use simple relative frequency
estimation to estimate the phrase probabilities,
lexical probabilities and generative rule probability
respectively.6
5After submission we were told by Moses support that in
fact neither normal Minimum Bayes-Risk (MBR) nor Lattice
MBR are operational in Moses Chart.
6Personal correspondence with Andreas Zollmann further
reinforced the authors appreciation of the importance of this
feature introduced in (Zollmann and Venugopal, 2006; Zoll-
mann, 2011). Strangely enough this feature seems to be un-
available in the standard Moses (Hoang et al, 2007) and Joshua
(Ganitkevitch et al, 2012) grammar extractors, that also imple-
ment SAMT grammar extraction
5.1.2 Specific choices and settings Joshua
Viterbi experiments
Based on experiments reported in (Mylonakis and
Sima?an, 2011; Mylonakis, 2012) we opted to not
label the (fully lexicalized) phrase pairs, but instead
label them with a generic PhrasePair label and use
a set of switch rules from all other labels to the
PhrasePair label to enable transition between Hiero
rules and phrase pairs.
We train our systems using PRO (Hopkins and
May, 2011) implemented in Joshua by Ganitkevitch
et al (2012). We use the standard tuning, where all
features are treated as dense features.We allow up to
30 tuning iterations. We further follow the PRO set-
tings introduced in (Ganitkevitch et al, 2012) but
use 0.5 for the coefficient ? that interpolates the
weights learned at the current with those from the
previous iteration. We use the final learned weights
for decoding with the log-linear model and report
Lowercase BLEU scores for the tuned test set.
5.1.3 Specific choices and settings Moses
Lattice MBR experiments
As mentioned before we use Moses (Hoang et
al., 2007) for our second experiment, in combina-
tion with Lattice Minimum Bayes-Risk Decoding5
(Tromble et al, 2008). Furthermore we use Batch
Mira (Cherry and Foster, 2012) for tuning with max-
imum 10 tuning iterations of the 200K training set,
and 30 for the 1000K training set.7
For our Moses experiments we mainly worked
with a uniform labeling policy, labeling phrase pairs
in the same way with alignment labels as normal
rules. This is motivated by the fact that since we are
using Minimum Bayes-Risk decoding, the risks of
sparsity from labeling are much reduced. And label-
ing everything does have the advantage that reorder-
7We are mostly interested in the relative performance of our
system in comparison to the baseline for the same settings. Nev-
ertheless, it might be that the labeled systems, which have more
smoothing features, are relatively suffering more from too lit-
tle tuning iterations than the baseline which does not have these
extra features and thus may be easier to tune. This was one of
the reasons to increase the number of tuning iterations from 10
to 30 in our later experiments on 1000K. Usage of Minimum
Bayes-Risk decoding or not is crucial as we have explained be-
fore in section 1. The main reason we opted for Batch Mira over
PRO is that it is more commonly used in Moses systems, and in
any case at least superior to MERT (Och, 2003) in most cases.
24
ing information can be fully propagated in deriva-
tions starting from the lowest (phrase) level. We also
ran experiments with the generic phrase pair label-
ing, since there were reasons to believe this could
decrease sparsity and potentially lead to better re-
sults.8
5.2 Initial Results
We report Lowercase BLEU scores for experi-
ments with and without Lattice Minimum Bayes-
Risk (MBR) decoding (Tromble et al, 2008). Ta-
ble 1 bottom shows the results of our first experi-
ments with Joshua, using the Viterbi derivation and
no MBR decoding to sum over derivations. We
display scores for the Hiero baseline (Hiero) and
the (partially) alignment labeled system (Hiero-AL-
PPL) which uses alignment labels for Hiero rules
and PhrasePair to label all phrase pairs. Scores are
around 26.25 BLEU for both systems, with only
marginal differences. In summary our labeled sys-
tems are at best comparable to the Hiero baseline.
Table 1 top shows the results of our second ex-
periments with Moses and Lattice MBR5. Here
our (fully) alignment labeled system (Hiero-AL)
achieves a score of 26.72 BLEU, in comparison to
26.44 BLEU for the Hiero baseline (Hiero). A small
improvement of 0.28 BLEU point.
5.3 Advanced experiments
We now report Lowercase BLEU scores for more
detailed analysis experiments with and without Lat-
tice Minimum Bayes-Risk5 (MBR) decoding, where
we varied other training and decoding parameters in
the Moses environment. Particularly, in this set of
experiments we choose the best tuning parameter
settings over 30 Batch Mira iterations (as opposed
to the weights returned by default ? used in the pre-
vious experiments). We also explore varieties in tun-
ing with a decoder that works with Viterbi/MBR,
and final testing with Viterbi/MBR.
In Table 2, the top rows show the results of our ex-
periments using MBR decoding. We display scores
8We discovered that the Moses chart decoder does not allow
fully abstract unary rules in the current implementation, which
makes direct usage of unary (switch) rules not possible. Switch
rules and other unaries can still be emulated though, by adapt-
ing the grammar, using multiple copies of rules with different
labels. This blows up the grammar a bit, but at least works in
practice.
Decoding
Type
System
Name 200K 1000K
Lattice
MBR
Hiero 27.19 28.39
Hiero-AL 26.61 28.32
Hiero-AL-PPL 26.89 28.41
Viterbi Hiero 26.80 28.57Hiero-AL 28.36
Table 2: Analysis Results. Lowercase BLEU results for
German-English trained on 200K and 1000K sentence
pairs using Moses (Hoang et al, 2007) in combination
with Batch Mira (Cherry and Foster, 2012) for tuning.
Top rows display results for our experiments with Lattice
Minimum Bayes-Risk Decoding5 (Tromble et al, 2008).
Below are results for experiments using Viterbi decoding
(i.e. no MBR) for tuning. Results on 200K were run with
10 tuning iterations, results on 1000K with 30 tuning it-
erations.
for the Hiero baseline (Hiero) and the fully/partially
alignment labeled systems Hiero-AL and Hiero-AL-
PPL. In the preceding set of experiments MBR de-
coding clearly showed improved performance over
Viterbi, particularly for our labelled system.
On the small training set of 200K we observe
that the Hiero baseline achieves 27.19 BLEU and
thus beats the labeled systems Hiero-AL with 26.61
BLEU and 26.89 BLEU by a good margin. On the
bigger dataset of 1000K and with more tuning iter-
ations (3), all systems perform better. When using
Lattice MBR Hiero achieving 28.39 BLEU, Hiero-
AL 28.32 BLEU and finally Hiero-AL-PPL achieves
28.41. These are insignificant differences in perfor-
mance between the labelled and unlabeled systems.
Table 1 bottom also shows the results of our
second set of experiments with Viterbi decoding.
Here, the baseline Hiero system for 200K training
set achieves a score of 26.80 BLEU on the small
training set. We also conducted another set of
experiments on the larger training set of 1000K, this
time with Viterbi decoding. The Hiero baseline with
Viterbi scores 28.57 BLEU while Hiero-AL scores
28.36 BLEU under the same conditions.
It is puzzling that Hiero Viterbi (for 1000k) per-
forms better than the same system with MBR decod-
ing systems. But after submission we were told by
Moses support that neither normal MBR nor Lattice
MBR are operational in Moses Chart. This means
that in fact the effect of MBR on our labels remains
still undecided, and more work is still needed in this
direction. The small decrease in performance for the
25
labelled system relative to Hiero (in Viterbi) is possi-
bly the result of the labelled system being more brit-
tle and harder to tune than the Hiero system. This
hypothesis needs further exploration.
While a whole set of experimental questions re-
mains open, we think that based on this preliminary
but nevertheless considerable set of experiments, it
seems that our labels do not always improve perfor-
mance compared with the Hiero baseline. It is possi-
ble that these labels, under a more advanced imple-
mentation via soft constraints (as opposed to hard la-
beling), could provide the empirical evidence to our
theoretical choices. A further concern regarding the
labels is that our current choice (5 labels) is heuristic
and not optimized for the training data. It remains to
be seen in the future if proper learning of these labels
as latent variables optimized for the training data or
the use of soft constraints can shed more light on the
use of alignment labels in hierarchical SMT.
5.4 Analysis
While we did not have time to do a deep compara-
tive analysis of the properties of the grammars, a few
things can be said based on the results. First of all
we have seen that alignment labels do not always im-
prove over the Hiero baseline. In earlier experiments
we observed some improvement when the labelled
grammar was used in combination with Minimum
Bayes-Risk Decoding but not without it. In later ex-
periments with different tuning settings (Mira), the
improvements evaporated and in fact, the Viterbi Hi-
ero baseline turned out, surprisingly, the best of all
systems.
Our use of MBR is theoretically justified by the
importance of aggregating over the derivations of the
output translations when labeling Hiero variables:
statistically speaking, if the labels split the occur-
rences of the phrase pairs, they will lead to multiple
derivations per Hiero derivation with fractions of the
scores. This is in line with earlier work on the ef-
fect of spurious ambiguity, e.g. Variational Decod-
ing (Li et al, 2009). Yet, in the case of our model,
there is also a conceptual explanation for the need to
aggregate over different derivations of the same sen-
tence pair. The decomposition of a word alignment
into hierarchical decomposition trees has a interest-
ing property: the simpler (less reordering) a word
alignment, the more (binary) decomposition trees ?
and in our model derivations ? it will have. Hence,
aggregating over the derivations is a way to gather
evidence for the complexity of alignment patterns
that our model can fit in between a given source-
target sentence pair. However, in the current exper-
imental setting, where final tuning with Mira is cru-
cial, and where the use of MBR within Moses is still
not standard, we cannot reap full benefit of our the-
oretical analysis concerning the fit of MBR for our
models? alignment labels.
6 Conclusion
We presented a novel method for labeling Hiero
variables with nonterminals derived from the hierar-
chical patterns found in recursive decompositions of
word alignments into tree representations. Our ex-
periments based on a first instantiation of this idea
with a fixed set of labels, not optimized to the train-
ing data, show promising performance. Our early
experiments suggested that these labels have merit,
whereas later experiments with more varied training
and decoder settings showed these results to be un-
stable.
Empirical results aside, our approach opens up a
whole new line of research to improve the state of
the art of hierarchical SMT by learning these la-
tent alignment labels directly from standard word
alignments without special use of syntactic or other
parsers. The fact that such labels are in principle
complementary with monolingual information is an
exciting perspective which we might explore in fu-
ture work.
Acknowledgements
This work is supported by The Netherlands Organi-
zation for Scientific Research (NWO) under grant nr.
612.066.929. This work was sponsored by the BIG
Grid project for the use of the computing and storage
facilities, with financial support from the Nether-
lands Organization of Scientific Research (NWO)
under grant BG-087-12. The authors would like to
thank the people from the Joshua team at John Hop-
kins University, in particular Yuan Cao, Jonathan
Weese, Matt Post and Juri Ganitkevitch, for their
helpful replies to questions regarding Joshua and its
PRO and Packing implementations.
26
References
Alfred V. Aho and Jeffrey D. Ullman. 1969. Syntax
directed translations and the pushdown assembler. J.
Comput. Syst. Sci., 3(1):37?56.
Hala Almaghout, Jie Jiang, and Andy Way. 2011. Ccg
contextual labels in hierarchical phrase-based smt. In
Proceedings of the 15th Annual Conference of the Eu-
ropean Association for Machine Translation (EAMT-
2011), May.
Stanley F. Chen and Joshua T. Goodman. 1998. An
empirical study of smoothing techniques for language
modeling. Technical Report TR-10-98, Computer Sci-
ence Group, Harvard University.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In HLT-
NAACL, pages 427?436.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the ACL, pages 263?270,
June.
David Chiang. 2006. An introduction to synchronous
grammars.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 1443?1452.
Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post,
and Chris Callison-Burch. 2012. Joshua 4.0: Pack-
ing, pro, and paraphrases. In Proceedings of the
Seventh Workshop on Statistical Machine Translation,
pages 283?291, Montre?al, Canada, June. Association
for Computational Linguistics.
Hany Hassan, Khalil Sima?an, and Andy Way. 2007. Su-
pertagged phrase-based statistical machine translation.
In Proceedings of ACL 2007, page 288295.
Hieu Hoang, Alexandra Birch, Chris Callison-burch,
Richard Zens, Rwth Aachen, Alexandra Constantin,
Marcello Federico, Nicola Bertoldi, Chris Dyer,
Brooke Cowan, Wade Shen, Christine Moran, and
Ondrej Bojar. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, pages 177?180.
Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1352?1362.
Shankar Kumar and William Byrne. 2004. Minimum
bayes-risk decoding for statistical machine translation.
In HLT-NAACL, page 16917.
Zhifei Li, Jason Eisner, and Sanjeev Khudanpur. 2009.
Variational decoding for statistical machine transla-
tion. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP: Volume 2 - Volume 2, pages 593?
601.
Junhui Li, Zhaopeng Tu, Guodong Zhou, and Josef van
Genabith. 2012. Using syntactic head information in
hierarchical phrase-based translation. In Proceedings
of the Seventh Workshop on Statistical Machine Trans-
lation, pages 232?242.
Yuval Marton, David Chiang, and Philip Resnik. 2012.
Soft syntactic constraints for arabic?english hierar-
chical phrase-based translation. Machine Translation,
26(1-2):137?157.
Markos Mylonakis and Khalil Sima?an. 2011. Learning
hierarchical translation structure with linguistic anno-
tations. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Hu-
man Language Technologies, pages 642?652.
Markos Mylonakis. 2012. Learning the Latent Struc-
ture of Translation. Ph.D. thesis, University of Ams-
terdam.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, pages 160?167.
Khalil Sima?an and Gideon Maillette de Buy Wenniger.
2011. Hierarchical translation equivalence over word
alignments. Technical Report PP-2011-38, Institute
for Logic, Language and Computation.
Roy W. Tromble, Shankar Kumar, Franz Och, and Wolf-
gang Macherey. 2008. Lattice minimum bayes-risk
decoding for statistical machine translation. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 620?629.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference grammars: soft-
ening syntactic constraints to improve statistical ma-
chine translation. In Proceedings of Human Language
Technologies: The 2009 Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 236?244.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23:377?404.
Hao Zhang, Daniel Gildea, and David Chiang. 2008. Ex-
tracting synchronous grammar rules from word-level
alignments in linear time. In Proceedings of the 22nd
International Conference on Computational Linguis-
tics - Volume 1, pages 1081?1088.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
augmented machine translation via chart parsing. In
27
NAACL 2006 - Workshop on statistical machine trans-
lation, June.
Andreas Zollmann. 2011. Learning Multiple-
Nonterminal Synchronous Grammars for Statistical
Machine Translation. Ph.D. thesis, Carnegie Mellon
University.
28
Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 58?67,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
A Formal Characterization of Parsing Word Alignments by Synchronous
Grammars with Empirical Evidence to the ITG Hypothesis
Gideon Maillette de Buy Wenniger?
University of Amsterdam
gemdbw@gmail.com
Khalil Sima?an?
University of Amsterdam
k.simaan@uva.nl
Abstract
Deciding whether a synchronous grammar
formalism generates a given word alignment
(the alignment coverage problem) depends on
finding an adequate instance grammar and
then using it to parse the word alignment. But
what does it mean to parse a word align-
ment by a synchronous grammar? This is for-
mally undefined until we define an unambigu-
ous mapping between grammatical deriva-
tions and word-level alignments. This pa-
per proposes an initial, formal characteriza-
tion of alignment coverage as intersecting two
partially ordered sets (graphs) of translation
equivalence units, one derived by a gram-
mar instance and another defined by the word
alignment. As a first sanity check, we report
extensive coverage results for ITG on auto-
matic and manual alignments. Even for the
ITG formalism, our formal characterization
makes explicit many algorithmic choices of-
ten left underspecified in earlier work.
1 Introduction
The training data used by current statistical machine
translation (SMT) models consists of source and
target sentence pairs aligned together at the word
level (word alignments). For the hierarchical and
syntactically-enriched SMT models, e.g., (Chiang,
2007; Zollmann and Venugopal, 2006), this training
data is used for extracting statistically weighted Syn-
chronous Context-Free Grammars (SCFGs). For-
mally speaking, a synchronous grammar defines a
set of (source-target) sentence pairs derived syn-
chronously by the grammar. Contrary to common
? Institute for Logic, Language and Computation.
belief, however, a synchronous grammar (see e.g.,
(Chiang, 2005; Satta and Peserico, 2005)) does not
accept (or parse) word alignments. This is because
a synchronous derivation generates a tree pair with
a bijective binary relation (links) between their non-
terminal nodes. For deciding whether a given word
alignment is generated/accepted by a given syn-
chronous grammar, it is necessary to interpret the
synchronous derivations down to the lexical level.
However, it is formally defined yet how to unam-
biguously interpret the synchronous derivations of
a synchronous grammar as word alignments. One
major difficulty is that synchronous productions, in
their most general form, may contain unaligned ter-
minal sequences. Consider, for instance, the rela-
tively non-complex synchronous production
?X ? ? X(1) ? X(2) ? X(3), X ? ? X(2) ? X(1) ? X(3)?
where superscript (i) stands for aligned instances
of nonterminal X and all Greek symbols stand for
arbitrary non-empty terminals sequences. Given a
word aligned sentence pair it is necessary to bind
the terminal sequence by alignments consistent with
the given word alignment, and then parse the word
alignment with the thus enriched grammar rules.
This is not complex if we assume that each of the
source terminal sequences is contiguously aligned
with a target contiguous sequence, but difficult if we
assume arbitrary alignments, including many-to-one
and non-contiguously aligned chunks.
One important goal of this paper is to propose
a formal characterization of what it means to syn-
chronously parse a word alignment. Our formal
characterization is borrowed from the ?parsing as in-
tersection" paradigm, e.g., (Bar-Hillel et al, 1964;
Lang, 1988; van Noord, 1995; Nederhof and Satta,
58
2004). Conceptually, our characterization makes use
of three algorithms. Firstly, parse the unaligned sen-
tence pair with the synchronous grammar to obtain a
set of synchronous derivations, i.e., trees. Secondly,
interpret a word alignment as generating a set of
synchronous trees representing the recursive trans-
lation equivalence relations of interest1 perceived in
the word alignment. And finally, intersect the sets
of nodes in the two sets of synchronous trees to
check whether the grammar can generate (parts of)
the word alignment. The formal detail of each of
these three steps is provided in sections 3 to 5.
We think that alignment parsing is relevant for
current research because it highlights the differ-
ence between alignments in training data and align-
ments accepted by a synchronous grammar (learned
from data). This is useful for literature on learn-
ing from word aligned parallel corpora (e.g., (Zens
and Ney, 2003; DeNero et al, 2006; Blunsom et al,
2009; Cohn and Blunsom, 2009; Riesa and Marcu,
2010; Mylonakis and Sima?an, 2011; Haghighi et
al., 2009; McCarley et al, 2011)). A theoretical,
formalized characterization of the alignment pars-
ing problem is likely to improve the choices made in
empirical work as well. We exemplify our claims by
providing yet another empirical study of the stability
of the ITG hypothesis. Our study highlights some of
the technical choices left implicit in preceding work
as explained in the next section.
2 First application to the ITG hypothesis
A grammar formalism is a whole set/family of syn-
chronous grammars. For example, ITG (Wu, 1997)
defines a family of inversion-transduction gram-
mars differing among them in the exact set of syn-
chronous productions, terminals and non-terminals.
Given a synchronous grammar formalism and an
input word alignment, a relevant theoretical ques-
tion is whether there exists an instance synchronous
grammar that generates the word alignment exactly.
We will refer to this question as the alignment cover-
age problem. In this paper we propose an approach
to the alignment coverage problem using the three-
step solution proposed above for parsing word align-
1The translation equivalence relations of interest may vary
in kind as we will exemplify later. The known phrase pairs are
merely one possible kind.
ments by arbitrary synchronous grammars.
Most current use of synchronous grammars is
limited to a subclass using a pair of nonterminals,
e.g., (Chiang, 2007; Zollmann and Venugopal, 2006;
Mylonakis and Sima?an, 2011), thereby remain-
ing within the confines of the ITG formalism (Wu,
1997). On the one hand, this is because of computa-
tional complexity reasons. On the other, this choice
relies on existing empirical evidence of what we will
call the ?ITG hypothesis", freely rephrased as fol-
lows: the ITG formalism is sufficient for represent-
ing a major percentage of reorderings in translation
data in general.
Although checking whether a word alignment can
be generated by ITG is far simpler than for arbi-
trary synchronous grammars, there is a striking vari-
ation in the approaches taken in the existing litera-
ture, e.g., (Zens and Ney, 2003; Wellington et al,
2006; S?gaard and Wu, 2009; Carpuat and Wu,
2007; S?gaard and Kuhn, 2009; S?gaard, 2010).
S?gaard and Wu (S?gaard and Wu, 2009) observe
justifiably that the literature studying the ITG align-
ment coverage makes conflicting choices in method
and data, and reports significantly diverging align-
ment coverage scores. We hypothesize here that
the major conflicting choices in method (what to
count and how to parse) are likely due to the ab-
sence of a well-understood, formalized method for
parsing word alignments even under ITG. In this pa-
per we apply our formal approach to the ITG case,
contributing new empirical evidence concerning the
ITG hypothesis.
For our empirical study we exemplify our ap-
proach by detailing an algorithm dedicated to ITG in
Normal-Form (NF-ITG). While our algorithm is in
essence equivalent to existing algorithms for check-
ing binarizability of permutations, e.g.,(Wu, 1997;
Huang et al, 2009), the formal foundations pre-
ceding it concern nailing down the choices made
in parsing arbitrary word alignments, as opposed to
(bijective) permutations. The formalization is our
way to resolve some of the major points of differ-
ences in existing literature.
We report new coverage results for ITG parsing
of manual as well as automatic alignments, showing
the contrast between the two kinds. While the latter
seems built for phrase extraction, trading-off preci-
sion for recall, the former is heavily marked with id-
59
iomatic expressions. Our coverage results make ex-
plicit a relevant dilemma. To hierarchically parse the
current automatic word alignments exactly, we will
need more general synchronous reordering mecha-
nisms than ITG, with increased risk of exponential
parsing algorithms (Wu, 1997; Satta and Peserico,
2005). But if we abandon these word alignments,
we will face the exponential problem of learning re-
ordering arbitrary permutations, cf. (Tromble and
Eisner, 2009). Our results also exhibit the impor-
tance of explicitly defining the units of translation
equivalence when studying (ITG) coverage of word
alignments. The more complex the choice of trans-
lation equivalence relations, the more difficult it is to
parse the word alignments.
3 Translation equivalence in MT
In (Koehn et al, 2003), a translation equivalence
unit (TEU) is a phrase pair: a pair of contiguous
substrings of the source and target sentences such
that the words on the one side align only with words
on the other side (formal definitions next). The hier-
archical phrase pairs (Chiang, 2005; Chiang, 2007)
are extracted by replacing one or more sub-phrase
pairs, that are contained within a phrase pair, by
pairs of linked variables. This defines a subsumption
relation between hierarchical phrase pairs (Zhang et
al., 2008). Actual systems, e.g., (Koehn et al, 2003;
Chiang, 2007) set an upperbound on length or the
number of variables in the synchronous productions.
For the purposes of our theoretical study, these prac-
tical limitations are irrelevant.
We give two definitions of translation equivalence
for word alignments.2 The first one makes no as-
sumptions about the contiguity of TEUs, while the
second does require them to be contiguous sub-
strings on both sides (i.e., phrase pairs).
As usual, s = s1...sm and t = t1...tn are source and
target sentences respectively. Let s? be the source
word at position ? in s and t? be the target word at
position ? in t. An alignment link a ? a in a word
alignment a is a pair of positions ??, ?? such that 1 ?
2Unaligned words tend to complicate the formalization un-
necessarily. As usual we also require that unaligned words must
first be grouped with aligned words adjacent to them before
translation equivalence is defined for an alignment. This stan-
dard strategy allows us to informally discuss unaligned words
in the following without loss of generality.
? ? m and 1 ? ? ? n. For the sake of brevity, we
will often talk about alignments without explicitly
mentioning the associated source and target words,
knowing that these can be readily obtained from the
pair of positions and the sentence pair ?s, t?. Given
a subset a? ? a we define wordss(a?) = {s? | ?X :
??, X? ? a?} and wordst(a?) = {t? | ?X : ?X, ?? ? a?}.
Now we consider triples (s?, t?, a?) such that
a? ? a, s? = wordss(a?) and t? = wordst(a?). We
define the translation equivalence units (TEUs) in
the set TE(s, t, a) as follows:
Definition 3.1 (s?, t?, a?) ? TE(s, t, a) iff ??, ?? ? a?
? (for all X, if ??, X? ? a then ??, X? ? a?) ? (for
all X, if ?X, ?? ? a then ?X, ?? ? a?)
In other words, if some alignment involving source
position ? or ? is included in a?, then all alignments
in a containing that position are in a? as well. This
definition allows a variety of complex word align-
ments such as the so-called Cross-serial Discontigu-
ous Translation Units and Bonbons (S?gaard and
Wu, 2009).
We also define the subsumption relation (partial
order) <a as follows:
Definition 3.2 A TEU u2 = (s2, t2, a2) subsumes
(<a) a TEU u1 = (s1, t1, a1) iff a1 ? a2. The sub-
sumption order will be represented by u1 <a u2.
Based on the subsumption relation we can par-
tition TE(s, t, a) into two disjoint sets : atomic
TEAtom(s, t, a) and composed TEComp(s, t, a).
Definition 3.3 u1 ? TE(s, t, a) is atomic iff @ u2 ?
TE(s, t, a) such that (u2 <a u1).
Now the set TEAtom(s, t, a) is simply the set
of all atomic translation equivalents, and
the set of composed translation equivalents
TEComp(s, t, a) = (TE(s, t, a) \ TEAtom(s, t, a)).
Based on the general definition of translation
equivalence, we can now give a more restricted
definition that allows only contiguous translation
equivalents (phrase pairs):
Definition 3.4 (s?, t?, a?) constitutes a contiguous
translation equivalent iff:
1. (s?, t?, a?) ? TE(s, t, a) and
60
2. Both s? and t? are contiguous substrings of s
and t? respectively.
This set of translation equivalents is the unlimited
set of phrase pairs known from phrase-based ma-
chine translation (Koehn et al, 2003). The relation
<a as well as the division into atomic and composed
TEUs can straightforwardly be adapted to contigu-
ous translation equivalents.
4 Grammatical translation equivalence
The derivations of a synchronous grammar can be
interpreted as deriving a partially ordered set of
TEUs as well. A finite derivation S ?+ ?s, t, aG?
of an instance grammar G is a finite sequence of
term-rewritings, where at each step of the sequence a
single nonterminal is rewritten using a synchronous
production of G. The set of the finite derivations
of G defines a language, a set of triples ?s, t, aG?
consisting of a source string of terminals s, a target
string of terminals t and an alignment between their
grammatical constituents. Crucially, the alignment
aG is obtained by recursively interpreting the align-
ment relations embedded in the synchronous gram-
mar productions in the derivation for all constituents
and concerns constituent alignments (as opposed to
word alignments).
Grammatical translation equivalents TEG(s, t)
A synchronous derivation S ?+ ?s, t, aG? can be
viewed as a deductive proof that ?s, t, aG? is a gram-
matical translation equivalence unit (grammatical
TEU). Along the way, a derivation also proves other
constituent-level (sub-sentential) units as TEUs.
We define a sub-sentential grammatical TEU of
?s, t, aG? to consist of a triple ?sx, tx, ax?, where sx
and tx are two subsequences3 (of s and t respec-
tively), derived synchronously from the same con-
3A subsequence of a string is a subset of the word-position
pairs that preserves the order but do not necessarily constitute
contiguous substrings.
Figure 2: Alignment with both contiguous and dis-
contiguous TEUs (example from Europarl En-Ne).
stituent X in some non-empty ?tail" of a derivation
S ?+ ?s, t, aG?; importantly, by the workings of G,
the alignment ax ? aG fulfills the requirement that a
word in sx or in tx is linked to another by aG iff it is
also linked that way by ax (i.e., no alignments start
out from terminals in sx or tx and link to terminals
outside them). We will denote with TEG(s, t) the set
of all grammatical TEUs for the sentence pair ?s, t?
derived by G.
Subsumption relation <G(s,t) Besides deriving
TEUs, a derivation also shows how the different
TEUs compose together into larger TEUs according
to the grammar. We are interested in the subsump-
tion relation: one grammatical TEU/constituent (u1)
subsumes another (u2) (written u2 <G(s,t) u1) iff the
latter (u2) is derived within a finite derivation of the
former (u1).4
The set of grammatical TEUs for a finite set of
derivations for a given sentence pair is the union of
the sets defined for the individual derivations. Simi-
larly, the relation between TEU?s for a set of deriva-
tions is defined as the union of the individual rela-
tions.
5 Alignment coverage by intersection
Let a word aligned sentence pair ?s, t, a? be given,
and let us assume that we have a definition of an or-
dered set TE(s, t, a) with partial order <a. We will
say that a grammar formalism covers a iff there ex-
ists an instance grammar G that fulfills two intersec-
tion equations simultaneously:5
(1) TE(s, t, a) ? TEG(s, t) = TE(s, t, a)
(2) <a ? <G(s,t)=<a
In the second equation, the intersection of partial or-
ders is based on the standard view that these are in
essence also sets of ordered pairs. In practice, it
is sufficient to implement an algorithm that shows
4Note that we define this relation exhaustively thereby defin-
ing the set of paths in synchronous trees derived by the grammar
for ?s, t?. Hence, the subsumption relation can be seen to define
a forest of synchronous trees.
5In this work we have restricted this definition to full cover-
age (i.e., subset) version but it is imaginable that other measures
can be based on the cardinality (size) of the intersection in terms
of covered TEUs, in following of measures found in (S?gaard
and Kuhn, 2009; S?gaard and Wu, 2009). We leave this to fu-
ture work.
61
Figure 1: Alignment with only contiguous TEUs (example from LREC En-Fr).
that G derives every TEU in TE(s, t, a), and that
the subsumption relation <a between TEUs in a
must be realized by the derivations of G that de-
rive TE(s, t, a). In effect, this way every TEU that
subsumes other TEUs must be derived recursively,
while the minimal, atomic units (not subsuming any
others) must be derived using the lexical produc-
tions (endowed with internal word alignments) of
NF-ITG. Again, the rationale behind this choice is
that the atomic units constitute fixed translation ex-
pressions (idiomatic TEUs) which cannot be com-
posed from other TEUs, and hence belong in the lex-
icon. We will exhibit coverage algorithms for doing
so for NF-ITG for the two kinds of semantic inter-
pretations of word alignments.
A note on dedicated instances of NF-ITG Given
a translation equivalence definition over word align-
ments TE(s, t, a), the lexical productions for a ded-
icated instance of NF-ITG are defined6 by the set
{X ? u | u ? TEAtom(s, t, a)}. This means that the
lexical productions have atomic TEUs at the right-
hand side including alignments between the words
of the source and target terminals. In the sequel, we
will only talk about dedicated instances of NF-ITG
and hence we will not explicitly repeat this every
time.
Given two grammatical TEUs u1 and u2, an NF-
ITG instance allows their concatenation either in
monotone [] or inverted <> order iff they are ad-
jacent on the source and target sides. This fact
implies that for every composed translation equiv-
alent u ? TE(s, t, a) we can check whether it is
derivable by a dedicated NF-ITG instance by check-
ing whether it recursively decomposes into adjacent
pairs of TEUs down to the atomic TEUs level. Note
that by doing so, we are also implicitly checking
6Unaligned words add one wrinkle in this scheme: infor-
mally, we consider a TEU u formed by attaching unaligned
words to an atomic TEU also as atomic iff u is absolutely needed
to cover the aligned sentence pair.
whether the subsumption order between the TEUs
in TE(s, t, a) is realized by the grammatical deriva-
tion (i.e, <G(s,t)?<a). Formally, an aligned sentence
pair ?s, t, a? is split into a pair of TEUs ?s1, t1, a1?
and ?s2, t2, a2? that can be composed back using
the [] and <> productions. If such a split exists,
the splitting is conducted recursively for each of
?s1, t1, a1? and ?s2, t2, a2? until both are atomic TEUs
in TE(s, t, a). This recursive splitting is the check
of binarizability and an algorithm is described in
(Huang et al, 2009).
6 A simple algorithm for ITG
We exemplify the grammatical coverage for (nor-
mal form) ITG by employing a standard tabular al-
gorithm based on CYK (Younger, 1967). The al-
gorithm works in two phases creating a chart con-
taining TEUs with associated inferences. In the ini-
tialization phase (Algorithm 1), for all source spans
that correspond to translation equivalents and which
have no smaller translation equivalents they contain,
atomic translation equivalents are added as atomic
inferences to the chart. In the second phase, based
on the atomic inferences, the simple rules of NF-
ITG are applied to add inferences for increasingly
larger chart entries. An inference is added (Algo-
rithms 2 and 3) iff a chart entry can be split into two
sub-entries for which inferences already exist, and
furthermore the union of the sets of target positions
for those two entries form a consecutive range.7 The
addMonotoneInference and addInvertedInference in
Algorithm 3 mark the composit inferences by mono-
tone and inverted productions respectively.
7We are not treating unaligned words formally here. For un-
aligned source and target words, we have to generate the differ-
ent inferences corresponding to different groupings with their
neighboring aligned words. Using pre-processing we set aside
the unaligned words, then parse the remaining word alignment
fully. After parsing, by post-processing, we introduce in the
parse table atomic TEUs that include the unaligned words.
62
InitializeChart
Input : ?s, t, a?
Output: Initialized chart for atomic units
for spanLength? 2 to n do
for i? 0 to n ? spanLength + 1 do
j? i + spanLength ? 1
u? {?X,Y? : X ? {i... j}}
if (u ? TEAtom(s, t, a)) then
addAtomicIn f erence(chart[i][ j],u)
end
end
end
Algorithm 1: Algorithm that initializes the Chart
with atomic sub-sentential TEUs. In order to be
atomic, a TEU may not contain smaller TEUs that
consist of a proper subset of the alignments (and
associated words) of the TEU.
ComputeTEUsNFITG
Input : ?s, t, a?
Output: TRUE/FALSE for coverage
InitializeChart(chart)
for spanLength? 2 to n do
for i? 0 to n ? spanLength + 1 do
j? i + spanLength ? 1
if chart[i][ j] ? TE(s, t, a) then
continue
end
for splitPoint ? i + 1 to j do
a? ? (chart[i][k ? 1] ? chart[k][ j])
if (chart[i][k ? 1] ? TE(s, t, a)) ?
(chart[k][ j] ? TE(s, t, a)) ?
(a? ? TE(s, t, a)) then
addT EU(chart, i, j, k, a?)
end
end
end
if (chart[0][n ? 1] , ?) then
return TRUE
else
return FALSE
end
end
Algorithm 2: Algorithm that incrementally builds
composite TEUs using only the rules allowed by
NF-ITG
addTEU
Input :
chart - the chart
i,j,k - the lower, upper and split point indices
a? - the TEU to be added
Output: chart with TEU a? added in the
intended entry
if MaxYt ({Yt : ?Xs,Yt? ? chart[i][k ? 1]})
< MaxYt ({Yt : ?Xs,Yt? ? chart[k][ j]}) then
addMonotoneIn f erence(chart[i][ j], a?)
else
addInvertedIn f erence(chart[i][ j], a?)
end
Algorithm 3: Algorithm that adds a TEU and as-
sociated Inference to the chart
7 Experiments
Data Sets We use manually and automatically
aligned corpora. Manually aligned corpora come
from two datasets. The first (Grac?a et al,
2008) consists of six language pairs: Portuguese?
English, Portuguese?French, Portuguese?Spanish,
English?Spanish, English?French and French?
Spanish. These datasets contain 100 sentence pairs
each and distinguish Sure and Possible alignments.
Following (S?gaard and Kuhn, 2009), we treat these
two equally. The second manually aligned dataset
(Pad? and Lapata, 2006) contains 987 sentence pairs
from the English-German part of Europarl anno-
tated using the Blinker guidelines (Melamed, 1998).
The automatically aligned data comes from Europarl
(Koehn, 2005) in three language pairs (English?
Dutch, English?French and English?German). The
corpora are automatically aligned using GIZA++
(Och and Ney, 2003) in combination with the grow-
diag-final-and heuristic. With sentence length cut-
off 40 on both sides these contain respectively 945k,
949k and 995k sentence pairs.
Grammatical Coverage (GC) is defined as the
percentage word alignments (sentence pairs) in a
parallel corpus that can be covered by an instance
of the grammar (NF-ITG) (cf. Section 5). Clearly,
GC depends on the chosen semantic interpretation
of word alignments: contiguous TE?s (phrase pairs)
or discontiguous TE?s.
63
Alignments Set GC contiguous TEs GC discontiguous TEs
Hand aligned corpora
English?French 76.0 75.0
English?Portuguese 78.0 78.0
English?Spanish 83.0 83.0
Portuguese?French 78.0 74.0
Portuguese?Spanish 91.0 91.0
Spanish?French 79.0 74.0
LREC Corpora Average 80.83?5.49 79.17?6.74
English?German 45.427 45.325
Automatically aligned Corpora
English?Dutch 45.533 43.57
English?French 52.84 49.95
English?German 45.59 43.72
Automatically aligned corpora average 47.99?4.20 45.75?3.64
Table 1: The grammatical coverage (GC) of NF-ITG for different corpora dependent on the interpretation
of word alignments: contiguous Translation Equivalence or discontiguous Translation Equivalence
Results Table 1 shows the Grammatical Coverage
(GC) of NF-ITG for the different corpora depen-
dent on the two alternative definitions of translation
equivalence. The first thing to notice is that there
is just a small difference between the Grammatical
Coverage scores for these two definitions. The dif-
ference is in the order of a few percentage points,
the largest difference is seen for Portuguese?French
(79% v.s 74% Grammatical Coverage), for some
language pairs there is no difference. For the au-
tomatically aligned corpora the absolute difference
is on average about 2%. We attribute this to the fact
that there are only very few discontiguous TEUs that
can be covered by NF-ITG in this data.
The second thing to notice is that the scores are
much higher for the corpora from the LREC dataset
than they are for the manually aligned English?
German corpus. The approximately double source
and target length of the manually aligned English?
German corpus, in combination with somewhat less
dense alignments makes this corpus much harder
than the LREC corpora. Intuitively, one would
expect that more alignment links make alignments
more complicated. This turns out to not always be
the case. Further inspection of the LREC alignments
also shows that these alignments often consist of
parts that are completely linked. Such completely
linked parts are by definition treated as atomic
TEUs, which could make the alignments look sim-
pler. This contrasts with the situation in the man-
ually aligned English?German corpus where on av-
erage less alignment links exist per word. Exam-
ples 1 and 2 show that dense alignments can be sim-
pler than less dense ones. This is because sometimes
the density implies idiomatic TEUs which leads to
rather flat lexical productions. We think that id-
iomatic TEUs reasonably belong in the lexicon.
When we look at the results for the automati-
cally aligned corpora at the lowest rows in the ta-
ble, we see that these are comparable to the results
for the manually aligned English?German corpus
(and much lower than the results for the LREC cor-
pora). This could be explained by the fact that the
manually aligned English?German is not only Eu-
roparl data, but possibly also because the manual
alignments themselves were obtained by initializa-
tion with the GIZA++ alignments. In any case, the
manually and automatically acquired alignments for
this data are not too different from the perspective of
NF-ITG. Further differences might exist if we would
employ another class of grammars, e.g., full SCFGs.
One the one hand, we find that manual align-
ments are well but not fully covered by NF-ITG.
On the other, the automatic alignments are not cov-
ered well but NF-ITG. This suggests that these au-
tomatic alignments are difficult to cover by NF-ITG,
and the reason could be that these alignments are
built heuristically by trading precision for recall cf.
64
(Och and Ney, 2003). Sogaard (S?gaard, 2010) re-
ports that full ITG provides a few percentage points
gains over NF-ITG.
Overall, we find that our results for the LREC data
are far higher Sogaard?s (S?gaard, 2010) results but
lower than the upperbounds of (S?gaard and Wu,
2009). A similar observation holds for the English?
German manually aligned EuroParl data, albeit the
maximum length (15) used in (S?gaard and Wu,
2009; S?gaard, 2010) is different from ours (40). We
attribute the difference between our results and So-
gaard?s approach to our choice to adopt lexical pro-
ductions of NF-ITG that contain own internal align-
ments (the detailed version) and determined by the
atomic TEUs of the word alignment. Our results
differ substantially from (S?gaard and Wu, 2009)
who report upperbounds (indeed our results still fall
within these upperbounds for the LREC data).
8 Related Work
The array of work described in (Zens and Ney,
2003; Wellington et al, 2006; S?gaard and Wu,
2009; S?gaard and Kuhn, 2009; S?gaard, 2010) con-
centrates on methods for calculating upperbounds
on the alignment coverage for all ITGs, including
NF-ITG. Interestingly, these upperbounds are deter-
mined by filtering/excluding complex alignment phe-
nomena known formally to be beyond (NF-)ITG.
None of these earlier efforts discussed explicitly the
dilemmas of instantiating a grammar formalism or
how to formally parse word alignments.
The work in (Zens and Ney, 2003; S?gaard and
Wu, 2009), defining and counting TEUs, provides
a far tighter upperbound than (Wellington et al,
2006), who use the disjunctive interpretation of
word alignments, interpreting multiple alignment
links of the same word as alternatives. We adopt the
conjunctive interpretation of word alignments like a
majority of work in MT, e.g., (Ayan and Dorr, 2006;
Fox, 2002; S?gaard and Wu, 2009; S?gaard, 2010).
In deviation from earlier work, the work in (S?-
gaard and Kuhn, 2009; S?gaard and Wu, 2009;
S?gaard, 2010) discusses TEUs defined over word
alignments explicitly, and defines evaluation metrics
based on TEUs. In particular, Sogaard (S?gaard,
2010) writes that he employs "a more aggressive
search" for TEUs than earlier work, thereby leading
to far tighter upperbounds on hand aligned data. Our
results seem to back this claim but, unfortunately, we
could not pin down the formal details of his proce-
dure.
More remotely related, the work described in
(Huang et al, 2009) presents a binarization algo-
rithm for productions of an SCFG instance (as op-
posed to formalism). Although somewhat related,
this is different from checking whether there exists
an NF-ITG instance (which has to be determined)
that covers a word alignment.
In contrast with earlier work, we present the align-
ment coverage problem as an intersection of two par-
tially ordered sets (graphs). The partial order over
TEUs as well as the formal definition of parsing as
intersection in this work are novel elements, mak-
ing explicit the view of word alignments as automata
generating partially order sets.
9 Conclusions
In this paper we provide a formal characterization
for the problem of determining the coverage of a
word alignment by a given grammar formalism as
the intersection of two partially ordered sets. These
partially ordered set of TEUs can be formalized in
terms of hyper-graphs implementing forests (packed
synchronous trees), and the coverage as the intersec-
tion between sets of synchronous trees generalizing
the trees of (Zhang et al, 2008).
Practical explorations of our findings for the bene-
fit of models of learning reordering are underway. In
future work we would like to investigate the exten-
sion of this work to other limited subsets of SCFGs.
We will also investigate the possibility of devising
ITGs with explicit links between terminal symbols
in the productions, exploring different kinds of link-
ing.
Acknowledgements We thank reviewers for their
helpful comments, and thank Mark-Jan Nederhof for
illuminating discussions on parsing as intersection.
This work is supported by The Netherlands Orga-
nization for Scientific Research (NWO) under grant
nr. 612.066.929.
65
References
Nacip Ayan and Bonnie Dorr. 2006. Going beyond AER:
an extensive analysis of word alignments and their im-
pact on MT. In Proc. of the 21st International Confer-
ence on Computational Linguistics and the 44th An-
nual Meeting of the ACL, pages 9?16, Morristown, NJ,
USA.
Yehoshua Bar-Hillel, Micha Perles, and Eli Shamir.
1964. On formal properties of simple phrase struc-
ture grammars. In Y. Bar-Hillel, editor, Language and
Information: Selected Essays on their Theory and Ap-
plication, chapter 9, pages 116?150. Addison-Wesley,
Reading, Massachusetts.
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-
borne. 2009. A gibbs sampler for phrasal synchronous
grammar induction. In ACL/AFNLP, pages 782?790.
Marine Carpuat and Dekai Wu. 2007. Improving statisti-
cal machine translation using word sense disambigua-
tion. In Proc. of the Joint Conference on Empirical
Methods in Natural Language Processing and Compu-
tational Natural Language Learning (EMNLP-CoNLL
2007), page 61?72.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the ACL, pages 263?270,
June.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
Trevor Cohn and Phil Blunsom. 2009. A bayesian model
of syntax-directed tree to string grammar induction. In
EMNLP, pages 352?361.
John DeNero, Daniel Gillick, James Zhang, and Dan
Klein. 2006. Why generative phrase models underper-
form surface heuristics. In Proceedings of the work-
shop on SMT, pages 31?38.
Heidi J. Fox. 2002. Phrasal cohesion and statistical
machine translation. In Proceedings of the ACL-02
conference on Empirical methods in natural language
processing - Volume 10, Proceedings of EMNLP,
pages 304?311, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Joao Grac?a, Joana Pardal, Lu?sa Coheur, and Diamantino
Caseiro. 2008. Building a golden collection of paral-
lel multi-language word alignment. In LREC?08, Mar-
rakech, Morocco. European Language Resources As-
sociation (ELRA).
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with supervised
itg models. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing of the AFNLP, pages 923?931, Suntec, Singa-
pore, August. Association for Computational Linguis-
tics.
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559?595.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of the Human Language Technology Conference, HLT-
NAACL, May.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of MT Summit.
Bernard Lang. 1988. Parsing incomplete sentences. In
Proceedings of COLING, pages 365?371.
J. Scott McCarley, Abraham Ittycheriah, Salim Roukos,
Bing Xiang, and Jian-Ming Xu. 2011. A correc-
tion model for word alignments. In Proceedings of
EMNLP, pages 889?898.
Dan Melamed. 1998. Annotation style guide for the
blinker project, version 1.0. Technical Report IRCS
TR #98-06, University of Pennsylvania.
Markos Mylonakis and Khalil Sima?an. 2011. Learning
hierarchical translation structure with linguistic anno-
tations. In Proceedings of the HLT/NAACL-2011.
Mark-Jan Nederhof and Giorgio Satta. 2004. The lan-
guage intersection problem for non-recursive context-
free grammars. Inf. Comput., 192(2):172?184.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Sebastian Pad? and Mirella Lapata. 2006. Optimal con-
stituent alignment with edge covers for semantic pro-
jection. In ACL-COLING?06, ACL-44, pages 1161?
1168, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Jason Riesa and Daniel Marcu. 2010. Hierarchical
search for word alignment. In Proceedings of ACL,
pages 157?166.
Giorgio Satta and Enoch Peserico. 2005. Some com-
putational complexity results for synchronous context-
free grammars. In Proceedings of Human Language
Technology Conference and Conference on Empirical
Methods i n Natural Language Processing, pages 803?
810, Vancouver, British Columbia, Canada, October.
Association for Computational Linguistics.
Anders S?gaard and Jonas Kuhn. 2009. Empirical lower
bounds on alignment error rates in syntax-based ma-
chine translation. In SSST ?09, pages 19?27, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Anders S?gaard and Dekai Wu. 2009. Empirical lower
bounds on translation unit error rate for the full class
of inversion transduction grammars. In Proceedings of
the 11th International Workshop on Parsing Technolo-
gies (IWPT-2009), 7-9 October 2009, Paris, France,
66
pages 33?36. The Association for Computational Lin-
guistics.
Anders S?gaard. 2010. Can inversion transduction
grammars generate hand alignments? In Proccedings
of the 14th Annual Conference of the European Asso-
ciation for Machine Translation (EAMT).
Roy Tromble and Jason Eisner. 2009. Learning linear or-
dering problems for better translation. In Proceedings
of EMNLP?09, pages 1007?1016, Singapore.
Gertjan van Noord. 1995. The intersection of finite state
automata and definite clause grammars. In Proceed-
ings of ACL, pages 159?165.
Benjamin Wellington, Sonjia Waxmonsky, and I. Dan
Melamed. 2006. Empirical lower bounds on the com-
plexity of translational equivalence. In Proceedings of
the Annual Meeting of the Association for Computa-
tional Linguistics (ACL).
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 3(23):377?403.
D.H. Younger. 1967. Recognition and parsing of
context-free languages in time n3. Information and
Control, 10(2):189?208.
Richard Zens and Hermann Ney. 2003. A comparative
study on reordering constraints in statistical machine
translation. In Proceedings of the Annual Meeting of
the ACL, pages 144?151.
Hao Zhang, Daniel Gildea, and David Chiang. 2008. Ex-
tracting synchronous grammar rules from word-level
alignments in linear time. In Proceedings of COLING,
pages 1081?1088.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart parsing.
In Proceedings of the North-American Chapter of the
ACL (NAACL?06), pages 138?141.
67
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 11?21,
October 25, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Bilingual Markov Reordering Labels for Hierarchical SMT
Gideon Maillette de Buy Wenniger and Khalil Sima?an
Institute for Logic, Language and Computation
University of Amsterdam
Science Park 107, 1098 XG Amsterdam, The Netherlands
gemdbw AT gmail.com, k.simaan AT uva.nl
Abstract
Earlier work on labeling Hiero grammars
with monolingual syntax reports improved
performance, suggesting that such label-
ing may impact phrase reordering as well
as lexical selection. In this paper we ex-
plore the idea of inducing bilingual labels
for Hiero grammars without using any
additional resources other than original
Hiero itself does. Our bilingual labels
aim at capturing salient patterns of phrase
reordering in the training parallel corpus.
These bilingual labels originate from hier-
archical factorizations of the word align-
ments in Hiero?s own training data. In this
paper we take a Markovian view on syn-
chronous top-down derivations over these
factorizations which allows us to extract
0
th
- and 1
st
-order bilingual reordering la-
bels. Using exactly the same training
data as Hiero we show that the Marko-
vian interpretation of word alignment fac-
torization offers major benefits over the
unlabeled version. We report extensive
experiments with strict and soft bilingual
labeled Hiero showing improved perfor-
mance up to 1 BLEU points for Chinese-
English and about 0.1 BLEU points for
German-English.
Phrase reordering in Hiero (Chiang, 2007) is mod-
elled with synchronous rules consisting of phrase
pairs with at most two nonterminal gaps, thereby
embedding ITG permutations (Wu, 1997) in lexi-
cal context. It is by now recognized that Hiero?s
reordering can be strengthened either by labeling
(e.g., (Zollmann and Venugopal, 2006)) or by sup-
plementing the grammar with extra-grammatical
reordering models, e.g., (Xiao et al., 2011; Huck
et al., 2013; Nguyen and Vogel, 2013). In this
paper we concentrate on labeling approaches.
Conceptually, labeling Hiero rules aims at in-
troducing preference in the SCFG derivations for
frequently occurring lexicalized ordering constel-
lations over rare ones which also affects lexical se-
lection. In this paper, we present an approach for
distilling phrase reordering labels directly from
alignments (hence bilingual labels).
To extract bilingual labels from word
alignments we must first interpret the alignments
as a hierarchy of phrases. Luckily, every
word alignment factorizes into Normalized
Decomposition Trees (NDTs) (Zhang et al.,
2008), showing explicitly how the word alignment
recursively decomposes into phrase pairs. Zhang
et al. (2008) employ NDTs for extracting Hiero
grammars. In this work, we extend NDTs
with explicit phrase permutation operators also
extracted from the original word alignment
(Sima?an and Maillette de Buy Wenniger, 2013);
Every node in the NDT is equipped with a
node operator that specifies how the order of
the target phrases (children of this node) is
produced from the corresponding source phrases.
Subsequently, we cluster the node operators
in these enriched NDTs according to their
complexity, e.g., monotone (straight), inverted,
non-binary but one-to-one, and the more complex
case of discontinuous (Maillette de Buy Wenniger
and Sima?an, 2013).
Inspired by work on parsing (Klein and Man-
ning, 2003), we explore a vertical Markovian
labeling approach: intuitively, 0
th
-order labels
signify the reordering of the sub-phrases inside the
phrase pair (Zhang et al., 2008), 1
st
-order labels
signify reordering aspects of the direct context
(an embedding, parent phrase pair) of the phrase
pair, and so on. Like the phrase orientation
models this labeling approach does not employ
external resources (e.g., taggers, parsers) beyond
the training data used by Hiero.
We empirically explore this bucketing for 0
th
-
11
and 1
st
-order labels both as hard and soft labels.
In experiments on German-English and Chinese-
English we show that this extension of Hiero of-
ten significantly outperforms the unlabeled model
while using no external data or monolingual la-
beling mechanisms. This suggests the viability
of automatically inducing bilingual labels follow-
ing the Markov labeling approach on operator-
labelled NDTs as proposed in this paper.
1 Hierarchical models and related work
Hiero SCFGs (Chiang, 2005; Chiang, 2007) allow
only up to two (pairs of) nonterminals on the right-
hand-side (RHS) of synchronous rules. The types
of permissible Hiero rules are:
X ? ??, ?? (1)
X ? ?? X
1
?, ? X
1
?? (2)
X ? ?? X
1
? X
2
? , ? X
1
? X
2
? ? (3)
X ? ?? X
1
? X
2
? , ? X
2
? X
1
? ? (4)
Here ?, ?, ?, ?, ?, ? are terminal sequences, possi-
bly empty. Equation 1 corresponds to a normal
phrase pair, 2 to a rule with one gap and 3 and 4
to the monotone- and inverting rules respectively.
Given an Hiero SCFG G, a source sentence s is
translated into a target sentence t by synchronous
derivations d, each is a finite sequence of well-
formed substitutions of synchronous productions
from G, see (Chiang, 2006). Existing phrase-
based models score a derivation der with linear
interpolation of a finite set of feature functions
(?(d)) of the derivation d, mostly working with
local feature functions ?
i
of individual produc-
tions, the target side yield string t of d (target
language model features) and other features (see
experimental section): arg max
d?G
P(t,d | s) ?
arg max
d?G
?
|?(d)|
i=1
?
i
? ?
i
. The parameters {?
i
} are
optimized on a held-out parallel corpus by direct
error-minimization (Och, 2003).
A range of (distantly) related work exploits
syntax for Hiero models, e.g. (Liu et al., 2006;
Huang et al., 2006; Mi et al., 2008; Mi and
Huang, 2008; Zollmann and Venugopal, 2006;
Wu and Hkust, 1998). In terms of labeling
Hiero rules, SAMT (Zollmann and Venugopal,
2006; Mylonakis and Sima?an, 2011) exploits a
?softer notion? of syntax by fitting the CCG-like
syntactic labels to non-constituent phrases. The
work of (Xiao et al., 2011) adds a lexicalized
orientation model to Hiero, akin to (Tillmann,
2004) and achieves significant gains. The work
of (Huck et al., 2013; Nguyen and Vogel, 2013)
overcomes technical limitations of (Xiao et al.,
2011), making necessary changes to the decoder,
which involves delayed (re-)scoring at hypernodes
up in the derivation of nodes lower in the chart
whose orientations are affected by them. This
goes to show that phrase-orientation models are
not mere labelings of Hiero.
Soft syntactic constraints has been around for
some time now (Zhou et al., 2008; Venugopal et
al., 2009; Chiang, 2010). In (Zhou et al., 2008)
Hiero is reinforced with a linguistically motivated
prior. This prior is based on the level of syntactic
homogeneity between pairs of non-terminals
and the associated syntactic forests rooted at
these nonterminals, whereby tree-kernels are
applied to efficiently measure the amount of
overlap between all pairs of sub-trees induced
by the pairs of syntactic forests. Crucially, the
syntactic prior encourages derivations that are
more syntactically coherent but does not block
derivations when they are not. In (Venugopal
et al., 2009) the authors associate distributions
over compatible syntactic labelings with grammar
rules, and combine these preference distributions
during decoding, thus achieving a summation
rather than competition between compatible label
configurations. The latter approach requires
significant changes to the decoder and comes at a
considerable computational cost. An alternative
approach (Chiang, 2010) uses labels similar to
(Zollmann and Venugopal, 2006) together with
boolean features for rule-label and substituted-
label combinations; using discriminative training
(MIRA) it is learned what combinations are
associated with better translations.
The labeling approach presented next differs
from existing approaches. It is inspired by soft
labeling but employs novel, non-linguistic bilin-
gual labels. And it shares the bilingual intuition
with phrase orientation models but it is based on
a Markov approach for SCFG labeling, thereby
remaining within the confines of Hiero SCFG,
avoiding the need to make changes inside the
decoder.
1
1
Soft constraint decoding can easily be implemented
without adapting the decoder, through a smart application of
?label bridging? unary rules. In practice however, adapting
the decoder turns out to be computationally more efficient,
therefore we used this solution in our experiments.
12
13
76
2
54
1
we
2
should
3
tailor
4
our
5
policy
6
accordingly
darauf
1
m?usen
2
wir
3
unsere
4
politik
5
ausrichten
6
Figure 1: Example alignment from Europarl
([1, 6], [1, 6], 1 )
([1, 2], [2, 3], 2 )
([1, 1], [3, 3], 4 ) ([2, 2], [2, 2], 5 )
([4, 5], [4, 5], 3 )
([4, 4], [4, 4], 6 ) ([5, 5], [5, 5], 7 )
Figure 2: Normalized Decomposition Tree (Zhang
et al., 2008) extended with pointers to original
alignment structure from Figure 1
2 Bilingual reordering labels for Hiero
Figure 1 shows an alignment from Europarl
German-English (Koehn, 2005) along with a tree
showing corresponding maximally decomposed
phrase pairs. Phrase pairs can be grouped into a
maximally decomposed tree (called Normalized
Decomposition Tree ? NDT) (Zhang et al., 2008).
Figure 2 shows the NDT for Figure 1, extended
with pointers to the original alignment structure
in Figure 2. The numbered boxes indicate how
the phrases in the two representations correspond.
In an NDT every phrase pair is recursively split
up at every level into a minimum number (two
or greater) of contiguous parts. In this example
the root node splits into three phrase pairs, but
these phrase pairs together do not cover the entire
parent phrase pair because of the discontinuity:
?tailor ... accordingly/ darauf ... ausrichten?.
Following (Zhang et al., 2008), we use the
NDT factorizations of word alignments in the
training data for extracting phrases. Every NDT
shows the hierarchical structuring into phrases
embedded in larger phrases, which together with
the context of the original alignment exposes the
reordering complexity of every phrase (Sima?an
and Maillette de Buy Wenniger, 2013). We will
exploit these elaborate distinctions based on the
complexity of reordering for Hiero rule labels as
explained next.
Phrase-centric (0
th
-order) labels are based on
the view of looking inside a phrase pair to see
how it decomposes into sub-phrase pairs. The op-
erator signifying how the sub-phrase pairs are re-
ordered (target relative to source) is bucketted into
a number of ?permutation complexity? categories.
Straightforwardly, we can start out by using the
two well known cases of Inversion Transduction
Grammars (ITG) {Monotone, Inverted} and label
everything
2
that falls outside these two category
with a default label ?X? (leaving some Hiero
nodes unlabeled). This leads to the following
coarse phrase-centric labeling scheme, which we
name 0
th
ITG+
: (1) Monotonic(Mono): binarizable,
fully monotone plus non-decomposable phrases
(2) Inverted(Inv): binarizable, fully inverted (3) X:
decomposable phrases that are not binarizable.
A clear limitation of the above ITG-like label-
ing approach is that all phrase pairs that decom-
pose into complex non-binarizable reordering pat-
terns are not further distinguished. Furthermore,
non-decomposable phrases are lumped together
with decomposable monotone phrases, although
they are in fact quite different. To overcome these
problems we extend ITG in a way that further
distinguishes the non-binarizable phrases and also
distinguishes non-decomposable phrases from the
rest. This gives a labeling scheme we will call
simply 0
th
-order labeling, abbreviated 0
th
, con-
sisting of a more fine-grained set of five cases,
ordered by increasing complexity (see examples
in Figure 4): (1) Atomic: non-decomposable
phrases, (2) Monotonic(Mono): binarizable, fully
monotone, (3) Inverted(Inv): binarizable, fully
inverted (4) Permutation(Perm): factorizes into a
permutation of four or more sub-phrases (5) Com-
plex(Comp): does not factorize into a permutation
and contains at least one embedded phrase.
In Figure 3, we show a phrase-complexity la-
beled derivation for the example of Figure 1.
Observe how the phrase-centric labels reflect the
relative reordering at the node. For example, the
2
Non-decomposable phrases will still be grouped
together with Monotone, since they are more similar to this
category than to the catchall ?X? category.
13
S0
accordingly
policy
our
tailor
should
we
COMPLEX TOP
1
INVERTED E.F.D.
2
ATOMIC R.B.I.
4
MONO E.F.D.
3
ATOMIC L.B.M.
7
S
0
ausrichten
politik
unsere
wir
m?ussen
darauf
COMPLEX TOP
1
INVERTED E.F.D.
2
ATOMIC R.B.I.
4
MONO E.F.D.
3
ATOMIC L.B.M.
7
Figure 3: Synchronous trees (implicit derivations end results) based on differently labelled Hiero
grammars. The figure shows alternative labeling for every node: Phrase-Centric (0
th
-order) (light gray)
and Parent-Relative (1
st
-order) (dark gray).
this is an important matter
das ist ein wichtige angelegenheit
1
1
2
2
Monotone
we all agree on this
das sehen wir alle
1
1
2
2
Inversion
i want to stress two points
auf zwei
punkte
m?ochte ich hinweisen
1
1
2
2
3
3
4
4
Permutation
we owe this to our citizens
das sind wir unsern burgern schuldig
1
1
2
2
3
3
Complex
it would be possible
kann mann
1
1
Atomic
Figure 4: Different types of Phrase-Centric Alignment Labels
Inverted label of node-pair 2 corresponds to the
inversion in the alignment of ?we should, m?usen
wir?; in contrast, node-pair 1 is complex and
discontinuous and the label is Complex.
Parent-relative (1
st
-order) labels capture the re-
ordering that a phrase undergoes relative to an
embedding parent phrase.
1. For a binarizable mother phrase with orien-
tation X
o
? {Mono, Inv}, the phrase itself can
either group to the left only Left-Binding-
X
o
, right only Right-Binding-X
o
, or with both
sides (Fully-X
o
).
2. Fully-Discontinuous: Any phrase within
a non-binarizable permutation or complex
alignment containing discontinuity.
3. Top: phrases that span the entire aligned
sentence pair.
In cases were multiple labels are applicable, the
simplest applicable label is chosen according to
the following preference order:
{Fully-Monotone, Left/Right-Binding-Monotone,
Fully-Inverted, Left/Right-Binding-Inverted,
Fully-Discontinuous, TOP}.
In Figure 3 the parent-relative labels in the
derivation reflect the reordering taking place at the
phrases with respect to their parent node. Node 4
has a parent node that inverts the order and the
sibling node it binds is on the right, therefore it
14
is labeled ?right-binding inverted? (R.B.I.); E.F.D.
and L.B.M. are similar abbreviations for ?embed-
ded fully discontinuous? and ?left-binding mono-
tone? respectively. As yet another example node
7 in Figure 3 is labeled ?left-binding monotone?
(L.B.M.) since it is monotone, but the alignment
allows it only to bind to the left at the parent node,
as opposed to only to the right or to both sides
which cases would have yielded ?right-binding
monotone? R.B.M. and ?(embedded) fully mono-
tone? (E.F.M.) parent-relative reordering labels
respectively.
Note that for parent-relative labels the binding
direction of monotone and inverted may not be
informative. We therefore also form a set of
coarse parent-relative labels (?1
st
Coarse
?) by col-
lapsing the label pairs Left/Right-Binding-Mono
and Left/Right-Binding-Inverted into single labels
One-Side-Binding-Mono and One-Side-Binding-
Inv
3
.
3 Features for soft bilingual labeling
Labels used in hierarchical Statistical Machine
Translation (SMT) are typically adapted from ex-
ternal resources such as taggers and parsers. Like
in our case, these labels are typically not fitted to
the training data ? with very few exceptions e.g.,
(Mylonakis and Sima?an, 2011; Mylonakis, 2012;
Hanneman and Lavie, 2013). Unfortunately this
means that the labels will either overfit or underfit,
and when they are used as strict constraints on
SCFG derivations they are likely to underperform.
Experience with mismatch between syntactic la-
bels and the data is abundant (Venugopal et al.,
2009; Marton et al., 2012; Chiang, 2010), and
using soft constraint decoding with suitable label
substitution features has been shown to be an
effective workaround solution. The intuition be-
hind soft constraint decoding is that even though
heuristic labels are not perfectly tailored to the
data, they do provide useful information provided
the model is ?allowed to learn? to use them only
in as far as they can improve the final evaluation
metric (usually BLEU).
3
We could also further coarsen the 1
st
labels by
removing entirely all sub-distinctions of binding-type for
the binarizable cases, but that would make the labeling
essentially equal to the earlier mentioned 0
th
ITG+
except for
looking at the reordering occurring at the parent rather than
inside the phrase itself. We did not explore this variant in this
work, as the high similarity to the already explored 0
th
ITG+
variant made it not seem to add much extra information.
???
LHS
10
N1
11
N2
12
GAP1
11
GAP2
12
Substituting rule
Decoder chart
Label Substitution Features
Figure 5: Label substitution features, schematic
view. Labels/Gaps with same filling in the figures
correspond to the situation of a nonterminal/gap
whose labels correspond (for N1/GAP1). Fillings
of different shades (as for N2/GAP2 on the right
in the two figures) indicates the situation were the
label of the nonterminal and the gap is different.
Next we introduce the set of label substitution
features used in our experiments.
Label substitution features consist of a unique
feature for every pair of labels ?L
?
, L
?
? in the
grammar, signifying a rule with left-hand-side
label L
?
substituting on a gap labeled L
?
. These
features are combined with two more coarse
features, ?Match? and ?Nomatch?, indicating if
the substitution involves labels that match or not.
Figure 5 illustrates the concept of label substi-
tution features schematically. In this figure the
substituting rule is substituted onto two gaps in
the chart, which induces two label substitution
features indicated by the two ellipses. The sit-
uation is analogous for rules with just one gap.
To make things concrete, lets assume that both
the first nonterminal of the rule N1 as well as
the first gap it is substituted onto GAP1 have
label MONO. Furthermore lets assume the second
nonterminal N2 has label COMPLEX while the
label of the gap GAP2 it substitutes onto is INV .
This situation results in the following two specific
label substitution features:
? subst(MONO,MONO)
? subst(INV ,COMPLEX)
Canonical labeled rules. Typically when la-
beling Hiero rules there can be many different
labeled variants of every original Hiero rule. With
soft constraint decoding this leads to prohibitive
computational cost. This also has the effect of
making tuning the features more difficult. In
practice, soft constraint decoding usually exploits
15
Systen Name Matching Type Label Order Label Granularity
Hiero-0
th
ITG+
Strict 0
th
order Coarse
Hiero-0
th
Strict 0
th
order Fine
Hiero-1
st
Coarse
Strict 1
th
order Coarse
Hiero-1
st
Strict 1
th
order Fine
Hiero-0
th
ITG+
-Sft Soft 0
th
order Coarse
Hiero-0
th
-Sft Soft 0
th
order Fine
Hiero-1
st
Coarse
-Sft Soft 1
th
order Coarse
Hiero-1
st
-Sft Soft 1
th
order Fine
Table 1: Experiment names legend
System Name
DEV TEST
BLEU ? METEOR ? TER ? KRS ? BLEU ? METEOR ? TER ? KRS ?
German-English
Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44
SAMT 27.76 32.67 58.05 66.84
N
28.32 32.88 57.70
NN
67.63
Hiero-0
th
ITG+
27.85 32.70 58.04
NN
66.27 28.36 32.90
H
57.83
NN
67.30
Hiero-0
th
27.82 32.75 57.92
NN
66.66 28.39 33.03
NN
57.75
NN
67.55
Hiero-1
st
Coarse
27.86 32.66 58.23 66.37 28.22
H
32.90 57.93 67.47
Hiero-1
st
27.74
H
32.60
HH
58.11 66.44 28.27 32.80
HH
57.95 67.39
Chinese-English
Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03
Hiero-0
th
ITG+
31.54 30.97
NN
62.79
HH
59.54
NN
31.94
NN
30.84
NN
60.76
HH
59.45
NN
Hiero-0
th
31.66 30.95
NN
62.20
HH
60.00
NN
31.90
NN
30.79
NN
60.11
HH
59.68
NN
Hiero-1
st
Coarse
31.64 30.75 61.37 59.48
NN
31.57 30.57 59.58
HH
59.13
NN
Hiero-1
st
31.74 30.79 61.94
HH
60.22
NN
31.77 30.62 60.13
HH
59.89
NN
Table 2: Mean results bilingual labels with strict matching.
4
a single labeled version per Hiero rule, which
we call the ?canonical labeled rule?. Following
(Chiang, 2010), this canonical form is the most
frequent labeled variant.
4 Experiments
We evaluate our method on two language pairs:
using German/Chinese as source and English as
target. In all experiments we decode with a
4-gram language model smoothed with modified
Knesser-Ney discounting (Chen and Goodman,
1998). The data used for training the language
models differs per language pair, details are given
in the next paragraphs. All data is lowercased as
a last pre-processing step. In all experiments we
use our own grammar extractor for the generation
of all grammars, including the baseline Hiero
grammars. This enables us to use the same
features (as far as applicable given the grammar
formalism) and assure true comparability of the
grammars under comparison.
German-English
4
Statistical significance is dependent on variance of
resampled scores, and hence sometimes different for same
mean scores across different systems.
The data for our German-English experiments
is derived from parliament proceedings sourced
from the Europarl corpus (Koehn, 2005), with
WMT-07 development and test data. We used a
maximum sentence length of 40 for filtering the
training data. We employ 1M sentence pairs for
training, 1K for development and 2K for test-
ing (single reference per source sentence). Both
source and target of all datasets are tokenized
using the Moses(Hoang et al., 2007) tokenization
script. For these experiments both the baseline
and our method use a language model trained
on the target side of the full original training set
(approximately 1M sentences).
Chinese-English
The data for our Chinese-English experiments is
derived from a combination of MultiUn(Eisele
and Chen, 2010; Tiedemann, 2012)
5
data and
Hong Kong Parallel Text data from the Linguistic
Data Consortium
6
. The Hong Kong Parallel Text
data is in traditional Chinese and is thus first
converted to simplified Chinese to be compatible
5
Freely available and downloaded from
http://opus.lingfil.uu.se/
6
The LDC catalog number of this dataset is LDC2004T08
16
System Name
DEV TEST
BLEU ? METEOR ? TER ? KRS ? BLEU ? METEOR ? TER ? KRS ?
German-English
Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44
SAMT 27.76 32.67 58.05 66.84
N
28.32 32.88 57.70
NN
67.63
Hiero-0
th
ITG+
-Sft 28.00
N
32.76
NN
57.90
NN
66.17 28.48 32.98 57.79
NN
67.32
Hiero-0
th
-Sft 28.01
N
32.71 57.95
NN
66.24 28.45 32.98 57.73
NN
67.51
Hiero-1
st
Coarse
-Sft 27.94 32.69 57.91
NN
66.26 28.45
N
32.94 57.75
NN
67.36
Hiero-1
st
-Sft 28.13
NN
32.80
NN
57.92
NN
66.32 28.45 33.00
N
57.79
NN
67.45
Chinese-English
Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03
Hiero-0
th
ITG+
-Sft 31.88
N
30.46
HH
60.64
NN
57.82
H
31.93
NN
30.37
HH
58.86
NN
57.60
H
Hiero-0
th
-Sft 32.04
NN
30.90
NN
61.47
HH
59.36
NN
32.20
NN
30.74
NN
59.45
H
58.92
NN
Hiero-1
st
Coarse
-Sft 32.39
NN
31.02
NN
61.56
HH
59.51
NN
32.55
NN
30.86
NN
59.57
HH
59.03
NN
Hiero-1
st
-Sft 32.63
NN
31.22
NN
62.00
HH
60.43
NN
32.61
NN
30.98
NN
60.19
HH
59.84
NN
Table 3: Mean results bilingual labels with soft matching.
4
with the rest of the data
7
. We used a maximum
sentence length of 40 for filtering the training
data. The combined dataset has 7.34M sentence
pairs. The MulitUN dataset contains translated
documents from the United Nations, similar in
genre to the parliament domain. The Hong Kong
Parallel Text in contrast contains a richer mix
of domains, namely Hansards, Laws and News.
For the dev and test set we use the Multiple-
Translation Chinese datasets from LDC, part 1-4
8
,
which contain sentences from the News domain.
We combined part 2 and 3 to form the dev set
(1813 sentence pairs) and part 1 and 4 to form the
test set (1912 sentence pairs). For both develop-
ment and testing we use 4 references. The Chinese
source side of all datasets is segmented using the
Stanford Segmenter(Chang et al., 2008)
9
. The
English target side of all datasets is tokenized
using the Moses tokenization script.
For these experiments both the baseline and
our method use a language model trained on
5.4M sentences of domain specific
10
news data
taken from the ?Xinhua? subcorpus of the English
Gigaword corpus of LDC.
11
7
Using a simple conversion script downloaded from
http://www.mandarintools.com/zhcode.html
8
LDC catalog numbers: LDC2002T01, DC2003T17,
LDC2004T07 and LDC2004T07
9
Downloaded from
http://nlp.stanford.edu/software/segmenter.shtml
10
For Chinese-English translation the different domain of
the train data (mainly parliament) and dev/test data (news)
requires usage of a domain specific language model to get
optimal results. For German-English, all data is from the
the parliament domain, so a language model trained on the
(translation model) training data is already domain-specific.
11
The LDC catalog number of this dataset is LDC2003T05
4.1 Experimental Structure
In our experiments we explore the influence of
three dimensions of bilingual reordering labels on
translation accuracy. These dimensions are:
? label granularity : granularity of the labeling
{Coarse,Fine}
? label order : the type/order of the labeling
{0
th
, 1
st
}
? matching type : the type of label matching
performed during decoding {Strict,Soft}
Combining these dimensions gives 8 different
reordering labeled systems per language pair.
On top of that we use two baseline systems,
namely Hiero and Syntax Augmented Machine
Translation (SAMT) to measure these systems
against. An overview of the naming of our
reordering labeled systems is given in Table 1.
Training and decoding details Our experiments
use Joshua (Ganitkevitch et al., 2012) with Viterbi
best derivation. Baseline experiments use nor-
mal decoding whereas soft labeling experiments
use soft constraint decoding. For training we
use standard Hiero grammar extraction constraints
(Chiang, 2007) (phrase pairs with source spans
up to 10 words; abstract rules are forbidden).
During decoding maximum span 10 on the source
side is maintained. Following common practice,
we use relative frequency estimates for phrase
probabilities, lexical probabilities and generative
rule probability.
We train our systems using (batch-kbest) Mira
as borrowed by Joshua from the Moses codebase,
allowing up to 30 tuning iterations. Following
17
standard practice, we tune on BLEU, and after
tuning we use the configuration with the highest
scores on the dev set with actual (corpus level)
BLEU evaluation. We report lowercase BLEU
(Papineni et al., 2002), METEOR (Denkowski
and Lavie, 2011) and TER (Snover et al., 2006)
scores for the tuned test set and also for the tuned
dev set, the latter mainly to observe any possible
overfitting. We use Multeval version 0.5.1.
12
for
computing these metrics. We also use MultEval?s
implementation of statistical significance testing
between systems, which is based on multiple
optimizer runs and approximate randomization.
Multeval (Clark et al., 2011) randomly swaps
outputs between systems and estimates the prob-
ability that the observed score difference arose by
chance. Differences that are statistically signif-
icant and correspond to improvement/worsening
with respect to the baseline are marked with
N
/
H
at
the p ? .05 level and
NN
/
HH
at the p ? .01 level. We
also report the Kendall Reordering Score (KRS),
which is the reordering-only variant of the LR-
score (Birch and Osborne, 2010) (without the
optional interpolation with BLEU) and which is
a sentence-level score. For the computation of
statistical significance of this metric we use our
own implementation of the sign test
13
(Dixon and
Mood, 1946), as also described in (Koehn, 2010).
In our experiments we repeated each experi-
ment three times to counter unreliable conclusions
due to optimizer variance. Scores are averages
over three runs of tuning plus testing. Scores
marked with
N
are significantly better than the
baseline, those marked with
H
are significantly
worse; according to the resampling test of Mul-
teval (Clark et al., 2011).
Preliminary experiment with strict matching
Initial experiments concerned 0
th
-order reorder-
ing labels in a strict matching approach (no soft
constraints). The results are shown in Table 2 for
both language pairs. The results for the Hiero and
SAMT
14
baselines (Hiero and SAMT) are shown
in the first rows. Below it results for the 0
th
-order
(phrase-centric) bilingual labeled systems with
either the Coarse (Hiero-0
th
ITG+
) or Fine label
12
https://github.com/jhclark/multeval
13
To make optimal usage of the 3 runs we computed
equally weighted improvement/worsening counts for all
possible 3 ? 3 baseline output / system output pairs and use
those weighted counts in the sign test.
14
SAMT could only be ran for German-English and not
for Chinese-English, due to memory constraints.
variant (Hiero-0
th
) are shown, followed by the
results for Coarse and Fine variant of the 1
th
-order
(parent-relative) bilingual labeled systems (Hiero-
1
st
Coarse
and Hiero-1
st
). All these systems use the
default decoding with strict label matching.
For German-English the effect of strict bilin-
gual labels is mostly positive: although we have
no improvement for BLEU we do achieve sig-
nificant improvements for METEOR and TER
on the test set. For Chinese-English, overall
Hiero-0
th
ITG+
shows the biggest improvements,
namely significant improvements of +0.31 BLEU,
+0.28 METEOR and +1.42 KRS. TER is the
only metric that worsens, and considerably so
with +1.48 point. Hiero-1
st
achieves the highest
improvement of KRS, namely 1.86 point higher
than the Hiero baseline. Overall, this preliminary
experiment shows that strict labeling sometimes
gives improvements over Hiero, but sometimes it
leads to worsening in terms of some of the metrics.
Results with soft bilingual constraints Our ini-
tial experiments with strict bilingual labels in
combination with strict matching by the decoder
gave some hope such constraints could be useful.
At the same time the results showed no stable
improvements across language pairs, and thus
does not allow us to draw definite conclusions
about the merit of bilingual labels.
Results for experiments with soft bilingual la-
beling are shown in Table 3. Here Hiero corre-
sponds to the Hiero baseline. Below it are shown
the systems that use soft constraint decoding (
SCD). Hiero-0
th
ITG+
-Sft and Hiero-0
th
-Sft using
phrase-centric labels (0
th
-order) in Coarse or Fine
form. Similarly, Hiero-1
st
Coarse
-Sft and Hiero-
1
st
-Sft correspond to the analog systems with
1
st
-order, parent-relative labels. For German-
English there are only minor improvements for
BLEU and METEOR, with somewhat bigger im-
provements for TER. For Chinese-English how-
ever the improvements are considerable, +0.98
BLEU improvement over the Hiero baseline for
Hiero-1
st
-Sft as well as +0.42 METEOR and
+1.81 KRS. TER is worsening with +0.85 for this
system. For Chinese-English the Fine version of
the labels gives overall superior results for both
0
th
-order and 1
st
-order labels.
Discussion Our best soft bilingual labeling system
for German-English shows small but significant
improvements of METEOR and TER while im-
18
proving BLEU and KRS as well, but not signifi-
cantly. The results with soft-constraint matching
are better than those for strict-matching in general,
while there is no clear winner between the Coarse
and Fine variant of labels.
For Chinese-English we see considerable
improvements and overall the best results for
the combination of soft-constraint matching,
with the Fine 1
st
-order variant of the labeled
systems (Hiero-1
st
-Sft). For Chinese-English the
improvement of the word-order is also particularly
clear as indicated by the +1.81 KRS improvement
for this best system. Furthermore the negative
effects in terms of worsening of TER are also
reduced in the soft-matching setting, dropping
from +1.48 TER to +0.85 TER. The results for
Hiero-0
th
-Sft are also competitive, since though
it gives somewhat lower improvements of BLEU
and METEOR, it gives an improvement of +1.89
KRS, while TER only worsens by +0.17 for this
system.
We conclude that bilingual Markov labels can
make a big difference in improvement of hier-
archical SMT. We observe that going beyond
the basic reordering labels of ITG, refining the
cases not captured by ITG and even more ef-
fective: taking a 1
st
-order rather than o
th
-order
perspective on reordering are major factors for
the success of including reordering information to
hierarchical SMT through labeling. Crucial to the
success of this undertaking is also the usage of
a soft-constraint approach to label matching, as
opposed to strict-matching. Finally, comparison
of the German-English results with results for
Syntax-Augmented Machine Translation (SAMT)
reveals that SAMT loses performance compared
to the Hiero baseline for BLEU, the metric upon
which tuning is done, as well as METEOR, while
only TER and KRS show improvement. Since
the best bilingual labeled system for German-
English (Hiero-1
st
-Sft) improves METEOR and
TER significantly, while also improving BLEU
and KRS, though not significant, we believe our
labeling is highly competitive with syntax-based
labeling approaches, without the need for any
additional resources in the form of parsers or
taggers, as syntax-based systems require. Likely
complementarity of reordering information, and
(target) syntax, which improves fluency, makes
combining both a promising possibility we would
like to explore in future work.
5 Conclusion
We presented a novel method to enrich Hierarchi-
cal Statistical Machine Translation with bilingual
labels that help to improve the translation quality.
Considerable and significant improvements of the
BLEU, METEOR and KRS are achieved simul-
taneously for Chinese-English translation while
tuning on BLEU, where the Kendall Reordering
Score is specifically designed to measure im-
provement of reordering in isolation. For German-
English more modest, statistically significant im-
provements of METEOR and TER (simultane-
ously) or BLEU (separately) are achieved. Our
work differs from related approaches that use
syntactic or part-of-speech information in the for-
mation of reordering constraints in that it needs no
such additional information. It also differs from
related work on reordering constraints based on
lexicalization in that it uses no such lexicaliza-
tion but instead strives to achieve more globally
coherent translations, afforded by global, holistic
constraints that take the local reordering history
of the derivation directly into account. Our exper-
iments also once again reinforce the established
wisdom that soft, rather than strict constraints,
are a necessity when aiming to include new in-
formation to an already strong system without the
risk of effectively worsening performance through
constraints that have not been directly tailored
to the data through a proper learning approach.
While lexicalized constraints on reordering have
proven to have great potential, un-lexicalized soft
bilingual constraints, which are more general and
transcend the rule level have their own place in
providing another agenda of improving transla-
tion which focusses more on the global coher-
ence direction by directly putting soft alignment-
informed constraints on the combination of rules.
Finally, while more research is necessary in this
direction, there are strong reasons to believe that
in the right setup these different approaches can be
made to further reinforce each other.
Acknowledgements
This work is supported by The Netherlands Or-
ganization for Scientific Research (NWO) under
grant nr. 612.066.929. The authors would like to
thank Matt Post and Juri Ganitkevitch, for their
support with respect to the integration of Fuzzy
Matching Decoding into the Joshua codebase.
19
References
Alexandra Birch and Miles Osborne. 2010. Lrscore
for evaluating lexical and reordering quality in mt.
In Proceedings of the Joint Fifth Workshop on
Statistical Machine Translation and MetricsMATR,
pages 327?332.
Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing chinese word
segmentation for machine translation performance.
In Proceedings of the Third Workshop on Statistical
Machine Translation, pages 224?232.
Stanley F. Chen and Joshua T. Goodman. 1998.
An empirical study of smoothing techniques for
language modeling. Technical Report TR-10-98,
Computer Science Group, Harvard University.
David Chiang. 2005. A hierarchical phrase-
based model for statistical machine translation. In
Proceedings of the 43rd Annual Meeting of the ACL,
pages 263?270, June.
David Chiang. 2006. An introduction to synchronous
grammars.
David Chiang. 2007. Hierarchical phrase-based
translation. Computational Linguistics, 33(2):201?
228.
David Chiang. 2010. Learning to translate with
source and target syntax. In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics, pages 1443?1452.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing
for statistical machine translation: Controlling
for optimizer instability. In Proceedings of
the 49th Annual Meeting of the Association
for Computational Linguistics: HLTTechnologies:
Short Papers - Volume 2, pages 176?181.
Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization
and evaluation of machine translation systems. In
Proceedings of the Sixth Workshop on Statistical
Machine Translation, pages 85?91.
W. J. Dixon and A. M. Mood. 1946. The statistical
sign test. Journal of the American Statistical
Association, pages 557?566.
Andreas Eisele and Yu Chen. 2010. Multiun: A
multilingual corpus from united nation documents.
In Proceedings of the 7th International Conference
on Language Resources and Evaluation (LREC
2010), pages 2868?2872.
Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt
Post, and Chris Callison-Burch. 2012. Joshua
4.0: Packing, pro, and paraphrases. In Proceedings
of the Seventh Workshop on Statistical Machine
Translation, pages 283?291, Montr?eal, Canada,
June. Association for Computational Linguistics.
Greg Hanneman and Alon Lavie. 2013. Improving
syntax-augmented machine translation by coarsen-
ing the label set. In HLT-NAACL, pages 288?297.
Hieu Hoang, Alexandra Birch, Chris Callison-burch,
Richard Zens, Rwth Aachen, Alexandra Constantin,
Marcello Federico, Nicola Bertoldi, Chris Dyer,
Brooke Cowan, Wade Shen, Christine Moran, and
Ondrej Bojar. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, pages 177?
180.
Liang Huang, Kevin Knight, and Aravind Joshi.
2006. A syntax-directed translator with extended
domain of locality. In Proceedings of the Workshop
on Computationally Hard Problems and Joint
Inference in Speech and Language Processing,
pages 1?8.
Matthias Huck, Joern Wuebker, Felix Rietig, and
Hermann Ney. 2013. A phrase orientation
model for hierarchical machine translation. In
ACL 2013 Eighth Workshop on Statistical Machine
Translation, pages 452?463.
Dan Klein and Christopher D. Manning. 2003.
Accurate unlexicalized parsing. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, pages 423?
430.
P. Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of MT
Summit.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York, NY, USA.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of the 21st International
Conference on Computational Linguistics and
the 44th Annual Meeting of the Association for
Computational Linguistics, pages 609?616.
Gideon Maillette de Buy Wenniger and Khalil
Sima?an. 2013. Hierarchical alignment decomposi-
tion labels for hiero grammar rules. In Proceedings
of the Seventh Workshop on Syntax, Semantics and
Structure in Statistical Translation, pages 19?28.
Yuval Marton, David Chiang, and Philip Resnik.
2012. Soft syntactic constraints for arabic?english
hierarchical phrase-based translation. Machine
Translation, 26(1-2):137?157.
Haitao Mi and Liang Huang. 2008. Forest-based
translation rule extraction. In Proceedings of
EMNLP.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of ACL: HLT,
June.
20
Markos Mylonakis and Khalil Sima?an. 2011.
Learning hierarchical translation structure with
linguistic annotations. In Proceedings of the
49th Annual Meeting of the Association for
Computational Linguistics: Human Language
Technologies, pages 642?652.
Markos Mylonakis. 2012. Learning the Latent
Structure of Translation. Ph.D. thesis, University
of Amsterdam.
ThuyLinh Nguyen and Stephan Vogel. 2013.
Integrating phrase-based reordering features into a
chart-based decoder for machine translation. In
Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1587?1596.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, pages 160?
167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting on Association for
Computational Linguistics, pages 311?318.
Khalil Sima?an and Gideon Maillette de Buy Wen-
niger. 2013. Hierarchical alignment trees:
A recursive factorization of reordering in word
alignments with empirical results. Internal Report.
Matthew Snover, Bonnie Dorr, Richard Schwartz,
Linnea Micciulla, and John Makhoul. 2006. A
study of translation edit rate with targeted human
annotation. In In Proceedings of Association for
Machine Translation in the Americas, pages 223?
231.
Jrg Tiedemann. 2012. Parallel data, tools and
interfaces in opus. In Proceedings of the 8th
International Conference on Language Resources
and Evaluation (LREC 2012), pages 2868?2872.
Christoph Tillmann. 2004. A unigram orientation
model for statistical machine translation. In
Proceedings of HLT-NAACL 2004: Short Papers,
pages 101?104.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference grammars:
softening syntactic constraints to improve statistical
machine translation. In Proceedings of Human Lan-
guage Technologies: The 2009 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 236?244.
Dekai Wu and Hongsing Wong Hkust. 1998. Machine
translation with a stochastic grammatical channel.
In Proceedings of the 36th Annual Meeting of
the Association for Computational Linguistics and
17th International Conference on Computational
Linguistics - Volume 2, pages 1408?1415.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23:377?404.
Xinyan Xiao, Jinsong Su, Yang Liu, Qun Liu, and
Shouxun Lin. 2011. An orientation model
for hierarchical phrase-based translation. In
Proceedings of the 2011 International Conference
on Asian Language Processing, pages 165?168.
Hao Zhang, Daniel Gildea, and David Chiang.
2008. Extracting synchronous grammar rules
from word-level alignments in linear time. In
Proceedings of the 22nd International Conference
on Computational Linguistics - Volume 1, pages
1081?1088.
Bowen Zhou, Bing Xiang, Xiaodan Zhu, and Yuqing
Gao. 2008. Prior derivation models for formally
syntax-based translation using linguistically syntac-
tic parsing and tree kernels. In Proceedings of
the ACL-08: HLT Second Workshop on Syntax and
Structure in Statistical Translation (SSST-2), pages
19?27.
Andreas Zollmann and Ashish Venugopal. 2006.
Syntax augmented machine translation via chart
parsing. In NAACL 2006 - Workshop on statistical
machine translation, June.
21
