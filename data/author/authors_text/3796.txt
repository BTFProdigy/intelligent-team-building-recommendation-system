Domain-Specific Query Translation for Multilingual Information Access
using Machine Translation Augmented With Dictionaries
Mined from Wikipedia
Gareth J. F. Jones, Fabio Fantino, Eamonn Newman, Ying Zhang
Centre for Digital Video Processing
Dublin City University
Dublin 9, Ireland
{gjones,enewman,yzhang}@computing.dcu.ie
Abstract
Accurate high-coverage translation is a vi-
tal component of reliable cross language in-
formation access (CLIA) systems. While
machine translation (MT) has been shown
to be effective for CLIA tasks in previous
evaluation workshops, it is not well suited
to specialized tasks where domain specific
translations are required. We demonstrate
that effective query translation for CLIA can
be achieved in the domain of cultural her-
itage (CH). This is performed by augment-
ing a standard MT system with domain-
specific phrase dictionaries automatically
mined from the online Wikipedia. Exper-
iments using our hybrid translation system
with sample query logs from users of CH
websites demonstrate a large improvement
in the accuracy of domain specific phrase de-
tection and translation.
1 Introduction
Reliable translation is a key component of effective
Cross Language Information Access (CLIA) sys-
tems. Various approaches to translation have been
explored at evaluation workshops such as TREC1,
CLEF2 and NTCIR3. Experiments at these work-
shops have been based on laboratory collections
consisting of news articles or technical reports with
?TREC? style queries with a minimum length of a
1trec.nist.gov
2http://www.clef-campaign.org/
3http://research.nii.ac.jp/ntcir/
full sentence. Test collection design at these work-
shops often ensures that there are a reasonable num-
ber of relevant documents available for each query.
In such cases general purpose translation resources
based on bilingual dictionaries and standard ma-
chine translation (MT) have been shown to be ef-
fective for translation in CLIA. However, this is less
likely to be the case when translating the very short
queries typically entered by general users of search
engines, particularly when they are seeking informa-
tion in a specific domain.
Online cultural heritage (CH) content is currently
appearing in many countries produced by organisa-
tions such as national libraries, museums, galleries
and audiovisual archives. Additionally, there are in-
creasing amounts of CH relevant content available
more generally on the World Wide Web. While
some of this material concerns national or regional
content only of local interest, much material relates
to items involving multiple nations and languages,
for example concerning events or groups encom-
passing large areas of Europe or Asia. In order to
gain a full understanding of such things, including
details contained in different collections and explor-
ing different cultural perspectives, often requires ef-
fective multilingual search technologies.
CH content encompasses various different media,
including of course text documents, but also im-
ages, videos, and audio recordings which may only
be described by very limited metadata labels. Such
metadata may include simple factual details such as
date of creation, but also descriptive details relat-
ing to the contents of the item and interpretation
and contextualization of the content. Multilingual
searching using metadata content requires that ei-
ther the metadata be translated into a language with
which the user is able to search or that the search
query be translated into the language of the meta-
data. This alternative of document or query trans-
lation is a well rehearsed argument in CLIA, which
has generally concerned itself with full text docu-
ment searching. However, the features of metadata
require a more careful analysis. Metadata is typi-
cally dense in search terms, while lacking the lin-
guistic structure and information redundancy of full
text documents. The absence of linguistic struc-
ture makes precise translation of content problem-
atic, while the lack of redundancy means that accu-
rate translation of individual words and phrases be-
tween the query and document is vital to minimize
mismatch between query and document terms. De-
veloping reliable and robust approaches to transla-
tion for metadata search is thus an important com-
ponent of search for many CH archives.
The EU FP6 MultiMatch4 project is concerned
with information access for multimedia and multi-
lingual content for a range of European languages.
In this paper we report on the MultiMatch query
translation methods we are developing to deal with
domain-specific language in the CH domain. We
demonstrate the effectiveness of these techniques
using example query logs from CH sites in English,
Spanish and Italian. We translate the queries and ex-
amine the quality of these translations using human
annotation. We show how a domain-specific phrase
dictionary can be used to augment traditional gen-
eral MT systems to improve the coverage and relia-
bility of translation of these queries. We also show
how retrieval performance on CH image metadata is
improved with the use of these improved, domain-
specific translations.
The remainder of this paper is organized as fol-
lows: Section 2 introduces the translation resources
used for this study, Section 3 describes our experi-
mental setup and results, Section 4 summarizes our
conclusions, and Section 5 gives details of our on-
going work.
4www.multimatch.org
2 Query Translation Techniques
The MT approach to query translation for CLIA
uses an existing MT system to provide automatic
translation. Using MT systems for query transla-
tion is widely used in CLIA when such a system
is available for the particular language pair under
consideration. Results reported at the standard re-
trieval evaluation workshops have often shown it
to be competitive with other translation methods.
However, while MT systems can provide reasonable
translations for general language expressions, they
are often not sufficient for domain-specific phrases
that contain personal names, place names, techni-
cal terms, titles of artworks, etc. In addition, cer-
tain words and phrases hold special meanings in a
specific domain. For example, the Spanish phrase
?Canto general? is translated into English as ?gen-
eral song?, which is arguably correct. However, in
the CH domain, ?Canto general? refers to a book ti-
tle from Pablo Neruda?s book of poems and should
be translated directly into English as the phrase
?Canto general?. Multiple-word phrases are more
information-bearing and more unambiguously rep-
resented than single words. They are often domain-
specific and typically absent from static lexicons.
Effective translation of such phrases is therefore par-
ticularly critical for short queries that are typically
entered by non-expert users of search engines.
The focus of the research reported in this paper
is a method to improve translation effectiveness of
phrases previously untranslated or inappropriately
translated by a standard MT system. In this work we
combine an MT system with domain-specific phrase
dictionaries mined from the online Wikipedia. The
next sections describe the construction of our dictio-
naries and their combination with the MT system.
2.1 Phrase Dictionary Construction
Our phrase translation system uses domain-specific
phrase dictionaries built by mining the online
Wikipedia5. As a multilingual hypertext medium,
Wikipedia has been shown to be a valuable new
source of translation information (Adafre and de
Rijke, 2005; Adafre and de Rijke, 2006; Bouma
et al, 2006; Declerck et al, 2006). Wikipedia is
structured as an interconnected network of articles,
5http://wikipedia.org
Figure 1: An example of Italian?English query translation.
in particular, wikipedia page titles in one language
are often linked to a multilingual database of cor-
responding terms. Unlike the web, most hyper-
links in wikipedia have a more consistent pattern
and meaningful interpretation. For example, the En-
glish wikipedia page http://en.wikipedia.org/
wiki/Cupid_and_Psyche hyperlinks to its counter-
part written in Italian http://it.wikipedia.org/
wiki/Amore_e_Psiche, where the basenames of
these two URLs (?Cupid and Psyche? and ?Amore e
Psiche?) are an English?Italian translation pair. The
URL basename can be considered to be a term (sin-
gle word or multiple-word phrase) that should be
translated as a unit.
Utilizing the multilingual linkage feature of
Wikipedia, we implement a three-stage automatic
process to mine wikipedia pages as a translation
source and construct phrase dictionaries in the cul-
ture heritage domain.
1. First, we performed a web crawl from the En-
glish wikipedia, Category: Culture. This cate-
gory contains links to articles and subcategories
concerning arts, religions, traditions, entertain-
ment, philosophy, etc. The crawl process is re-
stricted to the category of culture including all
of its recursive subcategories. In total, we col-
lected 458, 929 English pages.
2. For each English page obtained, we extracted
the hyperlinks to each of the query languages
(Italian and Spanish).
3. We then selected the basenames of each
pair of hyperlinks (English?Italian, English?
Spanish) as translations and added them into
our domain-specific dictionaries. The multiple-
word phrases were added into the phrase dictio-
nary for each language. These phrase dictionar-
ies are later used for dictionary-based phrase
identification.
The dictionaries we compiled contain about 90, 000,
70, 000, and 80, 000 distinct multiple-word phrases
in English, Italian, and Spanish respectively. The
majority of the phrases extracted are CH domain-
specific named entities and the rest of them are
general noun-based phrases, such as ?Music of Ire-
land? and ?Philosophy of history?. We did not ap-
ply any classifier to filter out the general noun-based
phrases, since such phrases play an equally impor-
tant role in the query translation process as domain-
specific named entities.
2.2 Improved MT-based Translation
Figure 1 shows our query translation process which
proceeds as follows:
Lexical rule-based phrase identification Given a
query, the first task is to locate phrases. Three meth-
ods of multiple-word phrase identification have been
commonly used: lexical rule-based (Ballesteros and
Croft, 1997; Hull and Grefenstette, 1996), statisti-
cal (Coenen et al, 2007; Gao et al, 2001), and syn-
tactical methods (Sharma and Raman, 2003; Gel-
bukh et al, 2004; Van de Cruys and Villada Moiro?n,
2007). The lexical rule-based approach with max-
imum forward matching was adopted in our query
translation process due to its robust performance and
computational simplicity. The query is sequentially
scanned to match the phrase dictionary. The longest
matched subsequence is taken as a phrase and trans-
lated via a domain-specific dictionary lookup. This
process is recursively invoked on the remaining part
of the query until no matches are found. The per-
formance of this approach depends strongly on the
completeness of the coverage of the adopted dictio-
nary. Our experimental results showed that at least
one phrase is detected in 90% of the testing queries,
for example, personal names, geographic locations,
and titles of various types of artworks. This indicates
that the phrase dictionaries we compiled can be used
to accurately identify phrases in web queries.
WorldLingo machine translation We translate
the original query into the target language using the
WorldLingo6 MT system. WorldLingo was selected
for the MultiMatch project because it generally pro-
vides good translation between English, Spanish,
Italian, and Dutch ? the languages relevant to the
Multimatch project. In addition, it provides a useful
API that can be used to translate queries in real-time
via HTTP transfer protocol.
Phrase translation validation For each of the
phrases previously recognized, we again pass it to
the MT system and the translation Tmt of this phrase
is returned by WorldLingo. Tmt is then replaced in
theWorldLingo translation of the query by the trans-
lations(s) Tdict from our domain-specific dictionary,
if Tmt 6= Tdict. This allows us to correct unreliable
phrase translations generated by the MT system.
3 Experimental Investigation
The goal of our experiments was to evaluate the
usefulness and the accuracy of the domain-specific
translation dictionaries. Instead of using queries
from a standard information retrieval test collection,
we experimented with queries explicitly seeking CH
information from real query log data provided by
CH organisations.
3.1 Query Log
The query log data used in this investigation was
provided by three European CH organisations par-
6http://worldlingo.com
# Detected # Untranslated
Proportionby dictionaries by WorldLingo
EN?IT 14 11 79%
EN?ES 19 11 58%
IT?EN 83 33 40%
ES?EN 74 33 45%
Table 1: Number of detected phrases using the
domain-specific dictionaries.
Total
# Exactly # + Extra # + Minor
correct translations noise
EN?IT 14 13 1 0
EN?ES 19 17 1 1
IT?EN 83 40 43 0
ES?EN 74 37 5 32
Table 2: Correctness of the translations of detected
domain-specific phrases.
ticipating in the MultiMatch project, and is taken
from their archives of real user queries. The data
consists of 100 English, 1048 Italian, and 1088
Spanish distinct web queries and the number of hits
of each query. The top 200 most popular multiple-
word queries in Italian and Spanish were selected as
the queries for testing. Due to the smaller size of
the English query log, we only obtained English 53
phrasal queries.
We used two methods of evaluation: first, the dic-
tionary usefulness and the translation effectiveness
are judged extrinsically by human assessment; and
second, evaluation using a parallel Italian?English
metadata document set explored how translation af-
fects the retrieval performance of an information re-
trieval system.
3.2 Human Judgement Evaluation
The WorldLingo MT system was used to translate
Spanish and Italian queries into English and vice
versa. Our domain-specific dictionaries were used
to translate phrases within the queries into the same
target languages. It should be noted that it is not pos-
sible to directly compare the lexical coverage of our
domain-specific dictionaries and the built-in phrase
dictionaries of WorldLingo since we don?t have ac-
cess to the internal WorldLingo dictionaries.
To evaluate the usefulness of our dictionaries, we
observed the proportion of domain-specific phrases
in the various query sets that can be translated us-
ing our domain-specific dictionaries mined from the
web, but are incorrectly translated by WorldLingo.
Original Query WorldLingo Translation Improved Machine Translation
EN?IT
turner east sussex Turner Sussex orientale Turner East Sussex
still life flowers fiori di vita tranquilla fiori di Natura morta
francis bacon Francis Bacon Francesco Bacone
pop art arte di schiocco Pop art
m c escher escher di m. c Maurits Cornelis Escher
american 60?s americano 60?s americano Anni 1960
EN?ES
vanessa bell campana del vanessa Vanessa Bell
turner east sussex Turner sussex del este Turner East Sussex
henry moore moore del Henrio Henry Moore
still life flowers flores de la vida inmo?vil flores de Bodego?n
guerrilla girls muchachas del guerrilla Guerrilla Girls
IT?EN
leonardo da vinci leonardo from you win Da Vinci, Leonardo da Vinci,
Leonardo daVinci, Leonardo de Vinci
duomo di milano dome of Milan Cathedral of Milan, Duomo di Milan,
Duomo di Milano, Duomo of Milan, Milan Cathedral
beni culturali cultural assets Cultural heritage
arte povera poor art Arte povera
san lorenzo saint lorenzo Lawrence of Rome, Saint Lawrence, St Lawrence,
gentile da fabriano kind from fabriano Gentile da Fabriano
statua della liberta statue of the freedom Statue of Liberty
aldo rossi aldo red Aldo Rossi
arnaldo pomodoro arnaldo tomato Arnaldo Pomodoro
la cattura di cristo di caravaggio the capture of caravaggio Christ The Taking of Christ caravaggio
ES?EN
lope de vega lope of fertile valley Lope de Vega
literatura infantil infantile Literature Children?s book, Children?s books,Children?s literature
cantar de mio cid to sing of mine cid Cantar de mio Cid, Lay of the Cid, The Lay of the Cid
el quijote de la mancha quijote of the spot quijote of La Mancha
dulce maria loynaz candy Maria loynaz Dulce Mar??a Loynaz
andres bello andres beautiful Andre?s Bello
filosofia del derecho philosophy of the right Philosophy of law
elogio de la locura praise of madness In Praise of Folly, Praise of Folly, The Praise of Folly
la regenta it runs it La Regenta
cristobal colon cristobal colon Christopher Colombus, Christopher Columbus,
Cristopher Columbus
Table 3: Some examples of improved translations using the domain-specific dictionaries. (The corrected
phrase translations are in italic.)
Namely, we tested the ability of our system to
detect and correct the presence of unreliable MT
translations for domain-specific phrases. Translated
phrases for these queries can generally be judged
unambiguously as correct or incorrect by a bilin-
gual speaker of the languages involved, and so we
are confident that assessment of translation accuracy
here does not involve significant degrees of subjec-
tivity.
As shown in Table 1, we can see that 79%, 58%,
40%, and 45% of incorrect MT-translated phrases
were able to be corrected using the domain-specific
dictionaries mined from wikipedia, in EN?IT, EN?
ES, IT?EN, and ES?EN translation tasks, respec-
tively. Our system leads to a large improvement in
MT translation for domain-specific phrases. Some
examples of improved query translations are shown
in Table 3.
We also conducted an investigation on the cor-
rectness of the translation mined from wikipedia,
as shown in Table 2. Exact correct translation is
strictly-correct single translation. Extra translation
refers to strictly-correct multiple translations, for
example, ?Cathedral of Milan, Duomo di Milan,
Duomo di Milano, Duomo of Milan, Milan Cathe-
dral? (Italian: Duomo di Milano). It is interesting to
observe that about 50% of Italian phrases are found
to have multiple correct English translations due to
multiple English wikipedia pages being redirected
to the same Italian pages. Some minor noise is ob-
served when the correct translation contains some
related additional words, such as ?Alfonso XII of
Spain? (Spanish: Alfonso XII). When used for in-
formation retrieval, this additional information can
sometimes improve effectiveness.
We are not able to manually evaluate the accuracy
of all translation pairs in our bilingual dictionaries
due to limited resources. However, our results for
sample queries from user logs demonstrate that our
translations are generally highly accurate.
3.3 Intrinsic Evaluation Using IR System
Our information retrieval experiments were per-
formed on a database of metadata associated with a
collection of 5000 CH photographs. The metadata to
describe each artifact in the collection is available in
English and in Italian. Each photograph is described
identically in both languages. We formed a separate
search index for English and Italian. Search was car-
ried out using the Lucene search engine7. We carried
out an evaluation based on this collection which pro-
ceeded as follows:
1. Submit the original queries to the index and
record the ranked list of references returned.
2. Submit the translated queries to the appropriate
index and record the ranked list of references
returned.
3. Find the correlation between the lists returned
for the native language queries and the queries
translated to that language.
4. The better translation will have the stronger
correlation with the native language list.
Due to the fact that the corpus was only complete
in the Italian and English versions, we were unable
to include the Spanish queries in this part of the eval-
uation. Also, while this collection is based in the CH
domain, some of the queries yield no relevant docu-
ments due to their specialist nature. The collection
of queries for which meaningful retrieval results are
7http://lucene.apache.org/
returned is too small to allow for a quantitative anal-
ysis of retrieval effectiveness. Therefore, we present
a qualitative analysis of some of the more interesting
cases.
3.3.1 Italian?English translations
The Italian queries cover a wide range of Italian
interests in CH. We present here a sample of some
of the more interesting results.
Arnaldo Pomodoro This refers to an Italian artist,
but the name ?Pomodoro? is translated to ?Tomato?
in English by WorldLingo. While there were no
references to the artist in the collection, all docu-
ments returned contained the term ?tomato? (refer-
ring to the vegetable) which are irrelevant to the
query. The dictionary-based translation recognized
the name and therefore left it untranslated. It is
preferable to retrieve no documents rather than to
retrieve irrelevant ones.
Amore e Psiche This refers to the sculpture en-
titled ?Cupid and Psyche? in English. This phrase
was matched in our phrase dictionary and translated
correctly. The MT system translated this as ?Love,
Psyche?. The dictionary translation was observed
to retrieve relevant documents with greater precision
since it matched against the more specific term ?Cu-
pid?, as opposed to the more general term ?Love?.
David Michaelangelo This query provided a
counterexample. The phrase dictionary added the
term ?statue? to the translated query. This led to re-
trieval of a large number of non-relevant documents.
3.3.2 English?Italian translations
As with the Italian queries, there was not much
overlap between the query log and the document col-
lection. Some of the interesting translations include:
pop art This phrase was recognized by our
domain-specific dictionary, and so was left in its
original form for searching in Italian. Interestingly,
this led to an improvement in search accuracy for the
query compared to that in the English language col-
lection. For the English index, this phrase matched
many non-relevant documents which contained the
word ?art?. However, when searching in the Italian
index, where ?art? is not a word encountered in the
general vocabulary, the phrase retrieves only 7 doc-
uments, of which 5 were relevant.
Turner East Sussex The place name ?East Sus-
sex? was correctly recognized and translated by our
phrase dictionary. However the MT system again
failed to recognise it and translated the partial term
?East? to ?Orientale?. The presence of the term
?Orientale? in the translated query resulted in many
non-relevant documents being retrieved, reducing
the precision of the query.
The examples given in this section provide anec-
dotal evidence to support the view that the auto-
matically mined domain-specific phrase dictionary
improves the performance of the retrieval system.
Query sets and relevance judgements are being cre-
ated for the MultiMatch document set by domain ex-
perts who compiled the original collections. Thus
we will be able to ensure that the query sets are a
good representative sample of the information needs
of the typical user. These test collections will allow
us to conduct full quantitative analysis of our sys-
tem.
4 Conclusions
We have presented an automatic mining system de-
veloped for construction of domain-specific phrase
dictionaries. Phrases not translated by a general
MT system are shown to be translated effectively
using these dictionaries. The extracted translations
were evaluated by human assessment and shown to
be highly accurate. We have also demonstrated a
way to combine these dictionaries with MT for top-
ical phrases in the culture heritage domain. Our ex-
perimental results show that we were able to detect
and correct a large proportion of domain-specific
phrases unsuccessfully translated by MT, and thus
improve information retrieval effectiveness and fa-
cilitate MLIA.
5 Ongoing Work
In our ongoing work we plan to further extend the
coverage of our dictionaries by exploring the min-
ing of other translations pairs from within the linked
Wikipedia pages. While the method described in this
paper has been shown to be effective for query trans-
lation, we have so far only demonstrated its behav-
ior for a very small number of queries to our CLIA
system. We are currently developing test collections
based on several CH data sets to evaluate the effec-
tiveness of our hybrid query translation method.
Acknowledgement
Work partially supported by European Community
under the Information Society Technologies (IST)
programme of the 6th FP for RTD ? project Mul-
tiMATCH contract IST?033104. The authors are
solely responsible for the content of this paper. It
does not represent the opinion of the European Com-
munity, and the European Community is not respon-
sible for any use that might be made of data appear-
ing therein.
References
Sisay Fissaha Adafre and Maarten de Rijke. 2005. Dis-
covering missing links in Wikipedia. In Proceedings
of the 3rd International Workshop on Link Discovery,
pages 90?97, Chicago, Illinois, United States. ACM
Press.
Sisay Fissaha Adafre and Maarten de Rijke. 2006. Find-
ing similar sentences across multiple languages in
Wikipedia. In Proceedings of the 11th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 62?69, Trento, Italy.
Lisa Ballesteros and W. Bruce Croft. 1997. Phrasal
translation and query expansion techniques for cross-
language information retrieval. In Proceedings of the
20th Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval,
pages 84?91, Philadelphia, PA, USA. ACM Press.
Gosse Bouma, Ismail Fahmi, Jori Mur, Gertjan van No-
ord, Lonneke van der Plas, and Jorg Tiedemann. 2006.
The University of Groningen at QA@CLEF 2006 us-
ing syntactic knowledge for QA. In Working Notes
for the Cross Language Evaluation Forum 2006 Work-
shop, Alicante, Spain.
Frans Coenen, Paul H. Leng, Robert Sanderson, and
Yanbo J. Wang. 2007. Statistical identification of key
phrases for text classification. In Machine Learning
and Data Mining in Pattern Recognition, volume 4571
of Lecture Notes in Computer Science, pages 838?853.
Springer.
Thierry Declerck, Asuncio`n Go`mez Pe`rez, Ovidiu Vela,
Zeno Gantner, and David Manzano-Macho. 2006.
Multilingual lexical semantic resources for ontology
translation. In Proceedings of the 5th International
Conference on Language Resources and Evaluation,
Genoa, Italy. ELDA.
Jianfeng Gao, Jian-Yun Nie, Endong Xun, Jian Zhang,
Ming Zhou, and Changning Huang. 2001. Improv-
ing query translation for cross-language information
retrieval using statistical models. In Proceedings of the
24th Annual International ACM SIGIR conference on
Research and Development in information retrieval,
pages 96?104, New Orleans, Louisiana, United States.
ACM Press.
Alexander F. Gelbukh, Grigori Sidorov, Sang-Yong Han,
and Erika Herna?ndez-Rubio. 2004. Automatic syn-
tactic analysis for detection of word combinations. In
Proceedings of the 5th International Conference on
Computational Linguistics and Intelligent Text Pro-
cessing, volume 2945 of Lecture Notes in Computer
Science, pages 243?247. Springer.
David A. Hull and Gregory Grefenstette. 1996. Query-
ing across languages: a dictionary-based approach to
multilingual information retrieval. In Proceedings of
the 19th Annual International ACM SIGIR Confer-
ence on Research and Development in Information Re-
trieval, pages 49?57, Zurich, Switzerland. ACM Press.
Rupali Sharma and S. Raman. 2003. Phrase-based text
representation for managing the web documents. In
Proceedings of the International Conference on Infor-
mation Technology: Computers and Communications,
page 165, Washington, DC, USA. IEEE Computer So-
ciety.
Tim Van de Cruys and Begon?a Villada Moiro?n. 2007.
Semantics-based multiword expression extraction. In
Proceedings of the Workshop on A Broader Perspec-
tive on Multiword Expressions, pages 25?32, Prague,
Czech Republic, June. Association for Computational
Linguistics.
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 61?64,
New York, June 2006. c?2006 Association for Computational Linguistics
Investigating Cross-Language Speech Retrieval for a  
Spontaneous Conversational Speech Collection  
 
Diana Inkpen, Muath Alzghool Gareth J.F. Jones Douglas W. Oard 
School of Info. Technology and Eng. School of Computing College of Info. Studies/UMIACS  
University of Ottawa Dublin City University University of Maryland 
Ottawa, Ontario, Canada, K1N 6N5 Dublin 9, Ireland College Park, MD 20742, USA 
{diana,alzghool}@site.uottawa.ca Gareth.Jones@computing.dcu.ie oard@umd.edu 
 
  
Abstract 
Cross-language retrieval of spontaneous 
speech combines the challenges of working 
with noisy automated transcription and lan-
guage translation. The CLEF 2005 Cross-
Language Speech Retrieval (CL-SR) task 
provides a standard test collection to inves-
tigate these challenges. We show that we 
can improve retrieval performance: by care-
ful selection of the term weighting scheme; 
by decomposing automated transcripts into 
phonetic substrings to help ameliorate tran-
scription errors; and by combining auto-
matic transcriptions with manually-assigned 
metadata. We further show that topic trans-
lation with online machine translation re-
sources yields effective CL-SR. 
1 Introduction 
The emergence of large collections of digitized 
spoken data has encouraged research in speech re-
trieval. Previous studies, notably those at TREC 
(Garafolo et al 2000), have focused mainly on 
well-structured news documents. In this paper we 
report on work carried out for the Cross-Language 
Evaluation Forum (CLEF) 2005 Cross-Language 
Speech Retrieval (CL-SR) track (White et al 2005). 
The document collection for the CL-SR task is a 
part of the oral testimonies collected by the USC 
Shoah Foundation Institute for Visual History and 
Education (VHI) for which some Automatic Speech 
Recognition (ASR) transcriptions are available 
(Oard et al, 2004). The data is conversional spon-
taneous speech lacking clear topic boundaries; it is 
thus a more challenging speech retrieval task than 
those explored previously. The CLEF data is also 
annotated with a range of automatic and manually 
generated sets of metadata. While the complete VHI 
dataset contains interviews in many languages, the 
CLEF 2005 CL-SR task focuses on English speech. 
Cross-language searching is evaluated by making 
the topic statements (from which queries are auto-
matically formed) available in several languages. 
This task raises many interesting research ques-
tions; in this paper we explore alternative term 
weighting methods and content indexing strategies.  
The remainder of this paper is structured as fol-
lows: Section 2 briefly reviews details of the CLEF 
2005 CL-SR task; Section 3 describes the system 
we used to investigate this task; Section 4 reports 
our experimental results; and Section 5 gives con-
clusions and details for our ongoing work.   
2 Task description 
The CLEF-2005 CL-SR collection includes 8,104 
manually-determined topically-coherent segments 
from 272 interviews with Holocaust survivors, wit-
nesses and rescuers, totaling 589 hours of speech. 
Two ASR transcripts are available for this data, in 
this work we use transcripts provided by IBM Re-
search in 2004 for which a mean word error rate of 
38% was computed on held out data. Additional, 
metadata fields for each segment include: two sets 
of 20 automatically assigned thesaurus terms from 
different kNN classifiers (AK1 and AK2), an aver-
age of 5 manually-assigned thesaurus terms (MK), 
and a 3-sentence summary written by a subject mat-
ter expert. A set of 38 training topics and 25 test 
topics were generated in English from actual user 
requests. Topics were structured as Title, Descrip-
tion and Narrative fields, which correspond roughly 
to a 2-3 word Web query, what someone might first 
say to a librarian, and what that librarian might ul-
timately understand after a brief reference inter-
view. To support CL-SR experiments the topics 
were re-expressed in Czech, German, French, and 
Spanish by native speakers in a manner reflecting 
61
the way questions would be posed in those lan-
guages. Relevance judgments were manually gener-
ated using by augmenting an interactive search-
guided procedure and purposive sampling designed 
to identify additional relevant segments. See (Oard 
et al 2004) and (White et al 2005) for details.  
3 System Overview 
Our Information Retrieval (IR) system was built 
with off-the-shelf components.  Topics were trans-
lated from French, Spanish, and German into Eng-
lish using seven free online machine translation 
(MT) tools. Their output was merged in order to 
allow for variety in lexical choices. All the transla-
tions of a topic Title field were combined in a 
merged Title field of the translated topics; the same 
procedure was adopted for the Description and Nar-
rative fields. Czech language topics were translated 
using InterTrans, the only web-based MT system 
available to us for this language pair. Retrieval was 
carried out using the SMART IR system (Buckley 
et al 1993) applying its standard stop word list and 
stemming algorithm.  
In system development using the training topics we 
tested SMART with many different term weighting 
schemes combining collection frequency, document 
frequency and length normalization for the indexed 
collection and topics (Salton and Buckley, 1988). In 
this paper we employ the notation used in SMART 
to describe the combined schemes: xxx.xxx. The 
first three characters refer to the weighting scheme 
used to index the document collection and the last 
three characters refer to the weighting scheme used 
to index the topic fields. For example, lpc.atc means 
that lpc was used for documents and atc for queries. 
lpc would apply log term frequency weighting (l) 
and probabilistic collection frequency weighting (p) 
with cosine normalization to the document collec-
tion (c). atc would apply augmented normalized 
term frequency (a), inverse document frequency 
weight (t) with cosine normalization (c). 
One scheme in particular (mpc.ntn) proved to 
have much better performance than other combina-
tions. For weighting document terms we used term 
frequency normalized by the maximum value (m) 
and probabilistic collection frequency weighting (p) 
with cosine normalization (c). For topics we used 
non-normalized term frequency (n) and inverse 
document frequency weighting (t) without vector 
normalization (n). This combination worked very 
well when all the fields of the query were used; it 
also worked well with Title plus Description, but 
slightly less well with the Title field alone. 
4 Experimental Investigation 
In this section we report results from our experi-
mental investigation of the CLEF 2005 CL-SR task. 
For each set of experiments we report Mean unin-
terpolated Average Precision (MAP) computed us-
ing the trec_eval script. The topic fields used are 
indicated as: T for title only, TD for title + descrip-
tion, TDN for title + description + narrative. The 
first experiment shows results for different term 
weighting schemes; we then give cross-language 
retrieval results. For both sets of experiments, 
?documents? are represented by combining the 
ASR transcription with the AK1 and AK2 fields. 
Thus each document representation is generated 
completely automatically. Later experiments ex-
plore two alternative indexing strategies. 
4.1 Comparison of Term Weighting Schemes 
The CLEF 2005 CL-SR collection is quite small by 
IR standards, and it is well known that collection 
size matters when selecting term weighting schemes 
(Salton and Buckley, 1988).  Moreover, the docu-
ments in this case are relatively short, averaging 
about 500 words (about 4 minutes of speech), and 
that factor may affect the optimal choice of weight-
ing schemes as well.  We therefore used the training 
topics to explore the space of available SMART 
term weighting schemes.  Table 1 presents results 
for various weighting schemes with  English topics. 
There are 3,600 possible combinations of weighting 
schemes available: 60 schemes (5 x 4 x 3) for 
documents and 60 for queries. We tested a total of 
240 combinations. In Table 1 we present the results 
for 15 combinations (the best ones, plus some oth-
ers to illustate  the diversity of the results). mpc.ntn 
is still the best for the test topic set; but, as shown, a 
few other weighting schemes achieve similar per-
formance. Some of the weighting schemes perform 
better when indexing all the topic fields (TDN), 
some on TD, and some on title only (T). npn.ntn 
was best for TD and lsn.ntn and lsn.atn are best for 
T. The mpc.ntn weighting scheme is used for all 
other experiments in this section.  We are investi-
gating the reasons for the effectiveness of this 
weighting scheme in our experiments. 
62
TDN TD T  Weighting 
scheme Map Map Map 
1 Mpc.mts 0.2175 0.1651 0.1175 
2 Mpc.nts 0.2175 0.1651 0.1175 
3 Mpc.ntn  0.2176 0.1653 0.1174 
4 npc.ntn 0.2176 0.1653 0.1174 
5 Mpc.mtc 0.2176 0.1653 0.1174 
6 Mpc.ntc 0.2176 0.1653 0.1174 
7 Mpc.mtn 0.2176 0.1653 0.1174 
8 Npn.ntn 0.2116 0.1681 0.1181 
9 lsn.ntn 0.1195 0.1233 0.1227 
10 lsn.atn 0.0919 0.1115 0.1227 
11 asn.ntn 0.0912 0.0923 0.1062 
12 snn.ntn 0.0693 0.0592 0.0729 
13 sps.ntn 0.0349 0.0377 0.0383 
14 nps.ntn 0.0517 0.0416 0.0474 
15 Mtc.atc 0.1138 0.1151 0.1108 
Table 1. MAP, 25 English test topics. Bold=best scores. 
4.2 Cross-Language Experiments 
Table 2 shows our results for the merged ASR, 
AK1 and AK2 documents with multi-system topic 
translations for French, German and Spanish, and 
single-system Czech translation. We can see that 
Spanish topics perform well compared to monolin-
gual English. However, results for German and 
Czech are much poorer. This is perhaps not surpris-
ing for the Czech topics where only a single transla-
tion is available. For German, the quality of 
translation was sometimes low and some German 
words were retained untranslated. For French, only 
TD topic fields were available.  In this case we can 
see that cross-language retrieval effectiveness is 
almost identical to monolingual English. Every re-
search team participating in the CLEF 2005 CL-SR 
task submitted at least one TD English run, and 
among those our mpc.ntn system yielded the best 
MAP (Wilcoxon signed rank test for paired sam-
ples, p<0.05). However, as we show in Table 4, 
manual metadata can yield better retrieval effec-
tiveness than automatic description.  
 
Topic 
Language 
System Map Fields 
English Our system 0.1653 TD 
English Our system 0.2176 TDN 
Spanish Our system 0.1863 TDN 
French Our system 0.1685 TD 
German Our system 0.1281 TDN 
Czech Our system 0.1166 TDN 
Table 2. MAP, cross-language, 25 test topics 
Language Map Fields Description 
English 0.1276 T Phonetic 
English 0.2550 TD Phonetic 
English 0.1245 T Phonetic+Text 
English 0.2590 TD Phonetic+Text 
Spanish 0.1395 T Phonetic 
Spanish 0.2653 TD Phonetic 
Spanish 0.1443 T Phonetic+Text 
Spanish 0.2669 TD Phonetic+Text 
French 0.1251 T Phonetic 
French 0.2726 TD Phonetic 
French 0.1254 T Phonetic+Text 
French 0.2833 TD Phonetic+Text 
German 0.1163 T Phonetic 
German 0.2356 TD Phonetic 
German 0.1187 T Phonetic+Text 
German 0.2324 TD Phonetic+Text 
Czech 0.0776 T Phonetic 
Czech 0.1647 TD Phonetic 
Czech 0.0805 T Phonetic+Text 
Czech 0.1695 TD Phonetic+Text 
Table 3. MAP, phonetic 4-grams, 25 test topics. 
4.3 Results on Phonetic Transcriptions 
In Table 3 we present results for an experiment 
where the text of the collection and topics, without 
stemming, is transformed into a phonetic transcrip-
tion. Consecutive phones are then grouped into 
overlapping n-gram sequences (groups of n sounds, 
n=4 in our case) that we used for indexing. The 
phonetic n-grams were provided by Clarke (2005), 
using NIST?s text-to-phone tool1. For example, the 
phonetic form for the query fragment child survi-
vors is: ch_ay_l_d s_ax_r_v ax_r_v_ay r_v_ay_v 
v_ay_v_ax ay_v_ax_r v_ax_r_z. 
The phonetic form helps compensate for the 
speech recognition errors. With TD queries, the re-
sults improve substantially compared with the text 
form of the documents and queries (9% relative). 
Combining phonetic and text forms (by simply in-
dexing both phonetic n-grams and text) yields little 
additional improvement. 
4.4 Manual summaries and keywords 
Manually prepared transcripts are not available 
for this test collection, so we chose to use manually 
assigned metadata as a reference condition.  To ex-
plore the effect of merging automatic and manual 
fields, Table 4 presents the results combining man-
                                                          
1 http://www.nist.gov/speech/tools/ 
63
ual keywords and manual summaries with ASR 
transcripts, AK1, and AK2. Retrieval effectiveness 
increased substantially for all topic languages. The 
MAP score improved with 25% relative when add-
ing the manual metadata for English TDN.  
Table 4 also shows comparative results between 
and our results and results reported by the Univer-
sity of Maryland at CLEF 2005 using a widely used 
IR system (InQuery) that has a standard term 
weighting algorithm optimized for large collections. 
For English TD, our system is 6% (relative) better 
and for French TD 10% (relative) better.  The Uni-
versity of Maryland results with only automated 
fields are also lower than the results we report in 
Table 2 for the same fields. 
 
Table 4. MAP, indexing all fields (MK, summaries, 
ASR transcripts, AK1 and AK2), 25 test topics. 
Language System Map Fields 
English Our system 0.4647 TDN 
English Our system 0.3689 TD 
English InQuery 0.3129 TD 
English Our system 0.2861 T 
Spanish Our system 0.3811 TDN 
French Our system 0.3496 TD 
French InQuery 0.2480 TD 
French Our system 0.3496 TD 
German Our system 0.2513 TDN 
Czech Our system 0.2338 TDN 
5 Conclusions and Further Investigation 
The system described in this paper obtained the best 
results among the seven teams that participated in 
the CLEF 2005 CL-SR track. We believe that this 
results from our use of the 38 training topics to find 
a term weighting scheme that is particularly suitable 
for this collection. Relevance judgments are typi-
cally not available for training until the second year 
of an IR evaluation; using a search-guided process 
that does not require system results to be available 
before judgments can be performed made it possi-
ble to accelerate that timetable in this case.  Table 2 
shows that performance varies markedly with the 
choice of weighting scheme.  Indeed, some of the 
classic weighting schemes yielded much poorer 
results than the one  we ultimately selected. In this 
paper we presented results on the test queries, but 
we observed similar effects on the training queries. 
On combined manual and automatic data, the 
best MAP score we obtained for English topics is 
0.4647. On automatic data, the best MAP is 0.2176. 
This difference could result from ASR errors or 
from terms added by human indexers that were not 
available to the ASR system to be recognized. In 
future work we plan to investigate methods of re-
moving or correcting some of the speech recogni-
tion errors in the ASR transcripts using semantic 
coherence measures. 
In ongoing further work we are exploring the re-
lationship between properties of the collection and 
the weighting schemes in order to better understand 
the underlying reasons for the demonstrated effec-
tiveness of the mpc.ntn weighting scheme.  
The challenges of CLEF CL-SR task will con-
tinue to expand in subsequent years as new collec-
tions are introduced (e.g., Czech interviews in 
2006). Because manually assigned segment bounda-
ries are available only for English interviews, this 
will yield an unknown topic boundary condition 
that is similar to previous experiments with auto-
matically transcribed broadcast news the Text Re-
trieval Conference (Garafolo et al 2000), but with 
the additional caveat that topic boundaries are not 
known for the ground truth relevance judgments.    
References 
Chris Buckley, Gerard Salton, and James Allan. 1993. 
Automatic retrieval with locality information using 
SMART. In Proceedings of the First Text REtrieval 
Conference (TREC-1), pages 59?72. 
Charles L. A. Clarke. 2005. Waterloo Experiments for 
the CLEF05 SDR Track, in Working Notes for the 
CLEF 2005 Workshop, Vienna, Austria 
John S. Garofolo, Cedric G.P. Auzanne and Ellen M. 
Voorhees. 2000. The TREC Spoken Document Re-
trieval Track: A Success Story. In Proceedings of the 
RIAO Conference: Content-Based Multimedia Infor-
mation Access, Paris, France, pages 1-20. 
Douglas W. Oard, Dagobert Soergel, David Doermann, 
Xiaoli Huang, G. Craig Murray, Jianqiang Wang, 
Bhuvana Ramabhadran, Martin Franz and Samuel 
Gustman. 2004. Building an Information Retrieval 
Test Collection for Spontaneous Conversational 
Speech, in  Proceedings of SIGIR, pages 41-48. 
Gerard Salton and Chris Buckley. 1988. Term-weighting 
approaches in automatic retrieval. Information Proc-
essing and Management, 24(5):513-523. 
Ryen W. White, Douglas W. Oard, Gareth J. F. Jones, 
Dagobert Soergel and Xiaoli Huang. 2005. Overview 
of the CLEF-2005 Cross-Language Speech Retrieval 
Track, in Working Notes for the CLEF 2005 Work-
shop, Vienna, Austria 
64
Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007), pages 81?88,
Prague, 28 June 2007. c?2007 Association for Computational Linguistics
Multilingual Search for Cultural Heritage Archives via Combining Multiple
Translation Resources
Gareth J. F. Jones, Ying Zhang, Eamonn Newman, Fabio Fantino
Centre for Digital Video Processing
Dublin City University
Dublin 9, Ireland
{gjones,yzhang,enewman,ffantino}
@computing.dcu.ie
Franca Debole
ISTI-CNR
Pisa
Italy
franca.debole
@isti.cnr.it
Abstract
The linguistic features of material in Cul-
tural Heritage (CH) archives may be in var-
ious languages requiring a facility for ef-
fective multilingual search. The specialised
language often associated with CH content
introduces problems for automatic transla-
tion to support search applications. The
MultiMatch project is focused on enabling
users to interact with CH content across
different media types and languages. We
present results from a MultiMatch study ex-
ploring various translation techniques for
the CH domain. Our experiments ex-
amine translation techniques for the En-
glish language CLEF 2006 Cross-Language
Speech Retrieval (CL-SR) task using Span-
ish, French and German queries. Re-
sults compare effectiveness of our query
translation against a monolingual baseline
and show improvement when combining a
domain-specific translation lexicon with a
standard machine translation system.
1 Introduction
Online Cultural Heritage (CH) content is being pro-
duced in many countries by organisations such as
national libraries, museums, galleries and audiovi-
sual archives. Additionally, there are increasing
amounts of CH relevant content available more gen-
erally on the World Wide Web. While some of this
material concerns national or regional content only
of local interest, much material relates to items in-
volving multiple nations and languages, for exam-
ple concerning events in Europe or Asia. In order to
gain a full understanding of such events, including
details contained in different collections and explor-
ing different cultural perspectives requires effective
multilingual search technologies. Facilitating search
of this type requires translation tools to cross the lan-
guage barrier between users and the available infor-
mation sources.
CH content encompasses various different media,
including of course text documents, images, videos,
and audio recordings. Search of text documents be-
tween languages forms the focus of cross-language
information retrieval (CLIR) research, while search
for images is the concern of content-based image re-
trieval. However, whatever the media of the items
they are accompanied by metadata. Such metadata
may include simple factual details such as date of
creation, but also descriptive details relating to the
contents of the item. Multilingual searching using
metadata content requires that either the metadata
be translated into a language with which the user is
able to search or that the search query be translated
into the language of the metadata. This alternative
of document or query translation is a well rehearsed
argument in CLIR, which has generally concerned
itself with full text document searching. However,
the features of metadata require a more careful anal-
ysis. Metadata is typically dense in search terms,
while lacking the linguistic structure and informa-
tion redundancy of full text documents. The absence
of linguistic structure makes precise translation of
content problematic, while the lack of redundancy
means that accurate translation of individual words
81
and phrases is vital to minimise mismatch between
query and document terms. Furthermore, CH con-
tent is typically in specialised domains requiring do-
main specific resources for accurate translation. De-
veloping reliable and robust approaches to transla-
tion for metadata search is thus an important com-
ponent of search for many CH archives.
The EU FP6 MultiMatch1 project is concerned
with information access for multimedia and multi-
lingual content for a range of European languages.
In the investigation reported in this paper we intro-
duce the first stage multilingual search functional-
ity of the MultiMatch system, and describe its use
in an investigation for multilingual metadata search.
Since at present we do not have a search test collec-
tion specifically developed for MultiMatch we use
data from the CLEF 2006 Cross-Language Speech
Retrieval (CL-SR) task for our experiments (Oard et
al., 2006).
The remainder of this paper is organised as fol-
lows: Section 2 gives an overview of the MultiMatch
search architecture, Section 3 outlines the experi-
mental search task, Section 4 describes the trans-
lation resources used for this study, Section 5 and
6 concern our experimental setup and results, and
finally Section 7 summarises our conclusions and
gives details of our ongoing work.
2 MultiMatch Search System
The MultiMatch search system is centered on the
MILOS Multimedia Repository system (Amato et
al., 2004) which incorporates free-text search using
Lucene (Hatcher and Gospodnetic, 2004) and im-
age search using an open source image retrieval sys-
tem GIFT (Mu?ller et al, 2001). In order to support
multilingual searching a number of translation tools
are being developed based on standard online ma-
chine translation tools and dictionaries augmented
with domain-specific resources gathered from the
WWW and elsewhere. In this section we briefly in-
troduce the relevant details of MILOS and Lucene.
Since this paper focuses on text search within Mul-
tiMatch, we do not describe the multimedia features
of the MultiMatch system.
1www.multimatch.org
2.1 MILOS: Multimedia Repository
MILOS (Multimedia dIgital Library for On-line
Search) is a repository system conceived to support
the distributed storage and retrieval of multimedia
objects. This Multimedia Content Management Sys-
tem (MCMS) is able to manage not only structured
data, as in databases, but also textual data (using
information retrieval technologies), semi-structured
data (typically in XML), mixed-mode data, and mul-
timedia data. In MultiMatch, we use MILOS as a
metadata repository to enable querying on the struc-
ture of the data stored.
MILOS has a three-tier architecture composed of
three main components:
1. the XML Search Engine (XMLSE) component
which manages the metadata;
2. the MultiMedia Server (MMS) component
which manages the documents; and
3. the MultiMedia Digital Library service
(MMDLS) component MMDLS which pro-
vides application developers with a uniform
and integrated way of accessing MMS and
XMLSE.
Each of these components is implemented using
solutions providing flexibility, scalability, and effi-
ciency.
2.1.1 XMLSE
XMLSE is an enhanced native XML
database/repository system with special features
for digital library applications. This is especially
justified by the well known and accepted advantages
of representing metadata as XML documents.
Metadata represented with XML can have arbitrary
complex structures, which allows it to handle with
complex metadata schemas, and can easily be
exported and imported. Our XML database can
store and retrieve any valid XML document. No
metadata schema or XML schema definition is
needed before inserting an XML document, except
optional index definitions for performance boosting.
Once an arbitrary XML document has been inserted
in the database it can be immediately retrieved using
XQuery. This allows digital library applications to
use arbitrary (XML encoded) metadata schemas
82
and to deal with heterogeneous metadata, without
any constraint on schema design and/or overhead
due to metadata translation. Thus, the native XML
database/repository system is simpler than a general
purpose XML database system, but offers signif-
icant improvements in specific areas: it supports
standard XML query languages such as XPath and
XQuery, and offers advanced search and indexing
functionality on arbitrary XML documents. It
supports high performance search and retrieval on
heavily structured XML documents, relying on
specific index structures.
Moreover XMLSE provides the possibility of us-
ing particular indexes. For example, using the con-
figuration file of XMLSE the system administrator
can associate the <abstract> elements of a doc-
ument with a full-text index and to the MPEG-7
<VisualDescriptor> elements can be associated
with a similarity search index. XMLSE uses Apache
Lucene2 to provide partial (or approximate) text
string matching, effectively providing information
retrieval functionality within MILOS. This allows
XMLSE to use the ranked searching and wildcard
queries of Lucene to solve queries like ?find all the
articles whose title contains the word XML? and
so on. This application allows users to interrogate
the dataset combining full text, and exact or partial
match search. For example the user can look for
documents whose <metadata> element contains the
word ?Switzerland?. MILOS generates and submits
to XMLSE the following XQuery query:
for $a in /document where
$a//metadata ? ?Switzerland?
return
<result>
{$a//title}, {$a//author}
</result>
The query will return a list of results which con-
sist of the title and author of all documents whose
metadata contains the term ?Switzerland?.
2.2 Lucene
Full text search in MILOS is provided by using
Lucene as a plugin. Ranked retrieval uses the
standard tf ? idf vector-space method provided in
Lucene (Hatcher and Gospodnetic, 2004). Lucene
also provides additional functionality to improve re-
2http://lucene.apache.org
trieval effectiveness by providing various query ex-
pansion services using techniques such as relevance
feedback, although these are not used in the current
investigation. Documents and search requests are
preprocessed to remove stop words and stemming is
applied using the standard resources supplied with
Lucene.
3 Evaluation Task
The MultiMatch system will enable search from a
number of CH repository sources including formally
published documents, images and video, as well
as material gathered from relevant WWW sources.
However, in order to explore metadata search is-
sues and evaluate our approaches to addressing re-
lated translation problems, a test collection includ-
ing sample user search topics and relevance judge-
ments is required. Since MultiMatch does not yet
have such a collection available, for our current ex-
periments we made use of the data provided for the
CLEF 2006 CL-SR track (Oard et al, 2006).
The document collection comprises 8104 En-
glish documents that are manually-determined
topically-coherent segments taken from 272 in-
terviews with Holocaust survivors, witnesses and
rescuers, totaling 589 hours of speech. Sev-
eral automatic speech recognition transcripts are
available for these interviews. However, for this
study we focus on the metadata fields provided
for each document: two sets of 20 automati-
cally assigned keywords (<AUTOKEYWORD2004A1>
and <AUTOKEYWORD2004A2>) determined using two
different kNN classifiers, denoted by AKW1 and
AKW2 respectively; a set of a varying number of
manually-assigned keywords (<MANUALKEYWORD>),
denoted by MKW; and a manual three-sentence
summary written by an expert in the field
(<SUMMARY>), denoted by SUMMARY.
The CLEF collection includes a set of 33 search
topics in standard TREC format created in English,
and translated into Czech, German, French, and
Spanish by native speakers. Since we wish to in-
vestigate topics with minimal redundancy, for our
experiments we used only the topic Title fields as
our search request. Relevance judgments were gen-
erated using a search guided procedure and standard
pooling methods were also provided with the collec-
83
tion. Full details of the this collection can be found
in (Oard et al, 2006; White et al, 2005).
To explore metadata field search, we used various
methods, described in the next section, to automati-
cally translate the French, German, and Spanish top-
ics into English3.
4 Translation Techniques
The MultiMatch translation resources are based on
the WorldLingo machine translation system aug-
mented with domain-specific dictionary resources
gathered automatically from the WWW. This section
briefly reviews WorldLingo4, and then describes
construction of our augmentation translation lexi-
cons and their application for query translation in
multilingual metadata search.
4.1 Machine translation system
There are a number of commercial machine transla-
tion systems currently available. After evaluation of
several candidate systems, WorldLingo was selected
for the MultiMatch project because it generally gives
good translation well between the English, Spanish,
Italian, and Dutch, languages relevant to the Mul-
timatch project5. In addition, it provides a useful
API that can be used to translate queries on the fly
via HTTP transfer protocol. The usefulness of such
a system is that it can be integrated into any appli-
cation and present translations in real-time. It al-
lows users to select the source/target languages and
specify the text format (e.g. plain text file or html
file) of their input files. The WorldLingo translation
system also provides various domain-specific dictio-
naries that can be integrated with translation system.
A particularly useful feature of WorldLingo with re-
spect to for MultiMatch, and potentially applications
within CH in general, is that to improve the qual-
ity of translations, additional locally developed cus-
tomized dictionaries can be uploaded. This enables
the WorldLingo dictionaries to be extended to con-
tain special terms for a specific domain.
3Due to a lack of translation resources, we did not use the
Czech translations in these experiments
4http://www.worldlingo.com/
5Additionally, it translates well between French and En-
glish, as used in this paper
4.2 Translation lexicon construction
To extend the standard dictionaries provided with
WorldLingo we used the current online wikipedia.
Wikipedia6 is the largest multilingual free-content
encyclopedia on the Internet. As of March 21 2007,
there are approximately 6.8 million articles written
in 250 languages available on the web, according
to Wiki Stats7. Wikipedia is structured as an in-
terconnected network of articles. Each wikipedia
page can hyperlink to several other wikipedia pages.
Wikipedia page titles in one language are also linked
to a multilingual database of corresponding terms.
Unlike the web, most hyperlinks in wikipedia have
a more consistent and semantically meaningful in-
terpretation and purpose. The comprehensive liter-
ature review presented by Adafre and Rijke (2005)
describes the link structure of wikipedia. As a mul-
tilingual hypertext medium, wikipedia presents a
valuable new source of translation information. Re-
cently, researchers have proposed techniques to ex-
ploit this opportunity. Adafre and Rijke (2006) de-
veloped a technique to identify similar text across
multiple languages in wikipedia using page content-
based features. Boumaet et al (2006) utilized
wikipedia for term recognition and translation in
order to enhance multilingual question answering
systems. Declerck et al (2006) showed how the
wikipedia resource can be used to support the su-
pervised translation of ontology labels.
In order to improve the effectiveness of multilin-
gual metadata search, we mine wikipedia pages as
a translation source and construct translation lex-
icons that can be used to reduce the errors intro-
duced by unknown terms (single words and multi-
word phrases) during query translation. The major
difference in our proposal is that the translations are
extracted on the basis of hyperlinks, meta keywords,
and emphasized concepts ? e.g. anchor text, bold-
face text, italics text, and text within special punc-
tuation marks ? appearing in the first paragraph of
wikipedia articles.
Meta keywords Wikipedia pages typically contain
meta keywords assigned by page editors. This
meta keywords can be used to assist in the iden-
6http://www.wikipedia.org/
7http://s23.org/wikistats/wikipedias
html.php?sort=good desc
84
tification of the associated terms on the same
topic.
Emphasized concepts In common with standard
summarization studies, we observed that the
first paragraph of a wikipedia document is usu-
ally a concise introduction to the article. Thus,
concepts emphasized in the introductory sec-
tion are likely to be semantically related to the
title of the page.
In our study we seek to use these features from
multilingual wikipedia pages to compile a domain-
specific word and phrase translation lexicon. Our
method in using this data is to augment the queries
with topically related terms in the document lan-
guage through a process of post-translation query
expansion. This procedure was performed as fol-
lows:
1. An English vocabulary for the domain of the
test collection was constructed by performing a
limited crawl of the English wikipedia8, Cate-
gory:World War II. This category contains links
to pages and subcategories concerning events,
persons, places, and organizations pertaining
to war crimes or crimes against humanity es-
pecially during WWII. It should be noted that
this process was neither an exhaustive crawl
nor a focused crawl. The purpose of our cur-
rent study is to explore the effect of translation
expansion on metadata retrieval effectiveness.
In total, we collected 7431 English web pages.
2. For each English wikipedia page, we extracted
its hyperlinks to German, Spanish, and French.
The basename of each hyperlink is considered
as a term (single word or multi-word phrase
that should be translated as a unit). This pro-
vided a total of 4446 German terms, 3338
Spanish terms, and 4062 French terms. As an
alternative way of collecting terms in German,
Spanish, and French, we are able to crawl the
wikipedia in a specific language. However, a
page with no link pointing to its English coun-
terpart will not provide enough translation in-
formation.
8en.wikipedia.org
RUN ID
Augmented lexicon using all terms
appearing in the following fields
Title Meta Emphasized
terms keywords concepts
RUNmt+t
?
? ?
RUNmt+m ?
?
?
RUNmt+c ? ?
?
RUNmt+m+c ?
? ?
Table 1: Run descriptions.
3. For each of the German, Spanish, and French
terms obtained, we used the title term, the meta
keywords, and the emphasized concepts ob-
tained from the same English wikipedia page
as its potential translations.
For example, consider an English page titled as
?World War II?9. The title term, the meta keywords,
the emphasized concepts in English, and the hyper-
links (to German, Spanish, and French) associated
are shown in Figure 1. We first extract the base-
names ?Zweiter Weltkrieg? (in German), ?Segunda
Guerra Mundial? (in Spanish), and ?Seconde Guerre
mondiale? (in French) using the hyperlink feature.
To translate these terms into English, we replace
them using the English title term, all the English
meta keywords and/or all the English emphasized
concepts occurring in the same English wikipedia
page. This is a straightforward approach to au-
tomatic post-translation query expansion by using
meta keywords and/or emphasized concepts as ex-
panded terms. The effects of the features described
above are investigated in this work, both separately
and in combination, as shown in Table 1,
5 Experimental Setup
In this section we outline the design of our exper-
iments. We established a monolingual reference
(RUNmono) against which we can measure multilin-
gual retrieval effectiveness. To provide a baseline
for our multilingual results, we used the standard
WorldLingo to translate the queries (RUNmt). We
then tested the MT integrated with different lexicons
compiled using wikipedia. Results of these experi-
ments, shown in Table 1, enable us gauge the effect
of each of our additional translation resources gen-
erated using wikipedia.
9http://en.wikipedia.org/wiki/World War
II
85
Title: World War II
Hyperlink to German: http://de.wikipedia.org/wiki/Zweiter_Weltkrieg
Hyperlink to Spanish: http://es.wikipedia.org/wiki/Segunda_Guerra_Mundial
Hyperlink to French: http://fr.wikipedia.org/wiki/Seconde_Guerre_mondiale
Meta keywords:
World War II, WWII history by nation, WWII history by nation, 101st Airborne 
Division, 11th SS Volunteer Panzergrenadier Division Nordland, 15th Army Group,
1937, 1939, 1940
Emphasized concepts:
World War II (abbreviated WWII), or the Second World War, was a worldwide conflict
which lasted from 1939 to 1945. World War II was the amalgamation of two 
conflicts, one starting in Asia as the Second Sino-Japanese War, and the other 
beginning in Europe with the Invasion of Poland. The war was caused by the 
expansionist and hegemonic ambitions of Germany, Italy, and Japan and economic 
tensions between all major powers.
Figure 1: Title, hyperlinks, meta keywords, and emphasized concepts (underlined terms) extracted from the
English wikipedia page http://en.wikipedia.org/wiki/World War II.
The focus of this paper is not on optimising ab-
solute retrieval performance, but rather to explore
the usefulness of our translation resources. Thus
we do not apply retrieval enhancement techniques
such as relevance feedback which would make it
more difficult to observe the impact of differences
in behaviour of the translation resources. The ex-
periments use the SUMMARY field, as an exam-
ple of concise natural language descriptions of CH
objects; and the AKW1 and AKW2 fields as exam-
ples of automatically assigned keyword labels with-
out linguistic structure, with the MKW field provid-
ing similar manually assigned for keyword labels.
Retrieval effectiveness is evaluated using standard
TREC mean average precision (MAP) and the pre-
cision at rank 10 (P@10).
6 Results and Discussion
The results of our query translation experiments are
shown in Table 2, 3, 4, and 5. For search using SUM-
MARY and MKW fields, the lexicon compiled us-
ing title terms provided an improvement of 7? 9%,
7 ? 19%, and 20 ? 30%, in German?English,
Spanish?English, and French?English retrieval task,
respectively. These improvements are statistically
significant at the 95% confidence level, and empha-
size the importance of a good domain-specific trans-
lation lexicon.
The addition of meta keywords or emphasized
concepts also improves results in most cases relative
to the RUNmt results. However, we can see that re-
trieval performance degrades when the query is ex-
panded to contain terms from both meta keywords
and emphasized concepts. This occurs despite the
fact that the additional terms are often closely re-
lated to the original query terms. While the addition
of all these terms generally produces an increase in
the number of retrieved documents, there is little or
no increase in the number of relevant documents re-
trieved, and the combination of the two sets of terms
in the queries leads on average to a slight reduce in
the rank of relevant documents.
The results show that RUNmt+t runs provide the
best results when averaged across a query set. How-
ever, when analysed at the level of individual queries
different combined translation resources are more
effective for different queries, examples of this ef-
fect are shown in Table 6. This suggests that it may
be possible to develop a more sophisticated transla-
tion expansion methods to select the best terms from
different lexicons. At the very least, it should be pos-
sible to use ?context-sensitive filtering? and ?com-
bination of evidence? (Smets, 1990) approaches to
improve the overall translation quality. We plan to
explore this method in further investigations.
7 Conclusion and Future Work
This paper reports experiments with techniques de-
veloped for domain-specific lexicon construction to
facilitate multilingual metadata search for a CH re-
86
RUN ID German?English Spanish?English French?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.0750 0.1233 0.0756 0.1250 0.0652 0.1152
RUNmt+t 0.0815 0.1516 0.0899 0.1545 0.0783 0.1333
RUNmt+m 0.0775 0.1266 0.0797 0.1364 0.0690 0.1030
RUNmt+c 0.0669 0.1000 0.0793 0.1303 0.0770 0.1152
RUNmt+m+c 0.0668 0.0968 0.0737 0.1212 0.0646 0.0970
RUNmono MAP = 0.1049 P@10 = 0.1818
Table 2: Results for SUMMARY field search. (RUNmt+t run provides the best results in all cases.)
RUN ID German?English French?English Spanish?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.1158 0.1750 0.1000 0.1677 0.0903 0.1677
RUNmt+t 0.1235 0.2100 0.1071 0.2031 0.1171 0.2194
RUNmt+m 0.1171 0.1393 0.1023 0.2000 0.0983 0.1903
RUNmt+c 0.1084 0.1500 0.0958 0.1636 0.1089 0.1667
RUNmt+m+c 0.1069 0.1600 0.0947 0.1727 0.0940 0.1742
RUNmono MAP = 0.1596 P@10 = 0.2812
Table 3: Results for MKW field search. (RUNmt+t run provides the best results in all cases.)
RUN ID German?English French?English Spanish?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.0264 0.0731 0.0247 0.0548 0.0316 0.0767
RUNmt+t 0.0273 0.0828 0.0274 0.0656 0.0406 0.0867
RUNmt+m 0.0268 0.0633 0.0258 0.0606 0.0357 0.0613
RUNmt+c 0.0266 0.0667 0.0266 0.0636 0.0383 0.0839
RUNmt+m+c 0.0259 0.0633 0.0260 0.0606 0.0328 0.0677
RUNmono MAP = 0.0388 P@10 = 0.1000
Table 4: Results for AKW1 field search. (RUNmt+t run provides the best results in all cases.)
RUN ID German?English French?English Spanish?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.0279 0.0375 0.0347 0.0625 0.0205 0.0483
RUNmt+t 0.0279 0.0481 0.0351 0.0680 0.0238 0.0433
RUNmt+m 0.0302 0.0448 0.0361 0.0556 0.0223 0.0484
RUNmt+c 0.0275 0.0414 0.0332 0.0593 0.0268 0.0548
RUNmt+m+c 0.0299 0.0448 0.0351 0.0536 0.0273 0.0581
RUNmono MAP = 0.0420 P@10 = 0.0821
Table 5: Results for AKW2 field search. (The best results are in bold.)
trieval tasks. The results show that our techniques
can provide a statistically significant improvement
in the retrieval effectiveness. Using a tailored trans-
lation lexicon enables us to achieve (77%, 78%),
(86%, 67%) and (75%, 63%) of the monolingual ef-
fectiveness in German?English, Spanish?English,
and French?English multilingual metadata SUM-
MARY, MKW field search tasks. In addition, the
multilingual wikipedia proved to be a rich resource
of translations for domain-specific terms.
Intuitively, document translation is superior to
query translation. Documents provide more context
for resolving ambiguities (Oard, 1998) and the trans-
lation of source documents into all the languages
supported by the retrieval system effectively reduces
CLIR to a monolingual IR task. Furthermore, it has
the added advantage that document content is acces-
sible to users in their native languages. In our future
work, we will compare the effectiveness of these two
approaches to metadata search in a multilingual en-
vironment.
87
Query ID
MT Augmented lexicon using all terms appearing in the following fields
WorldLingo Title terms Meta keyword Emphasized concepts Meta keyword +Emphasized concepts
German?English 1133 0.6000 0.6000 0.6195 0.6092 0.6400
1325 0.0000 0.0003 0.0020 0.0020 0.0018
1623 0.2210 0.2210 0.3203 0.0450 0.0763
3007 0.0000 0.0003 0.0025 0.0047 0.0054
3012 0.0087 0.0087 0.0073 0.0073 0.0097
3025 0.0052 0.0052 0.0060 0.0052 0.0060
Spanish?English 1623 0.0063 0.0063 0.1014 0.0084 0.0334
3007 0.0000 0.0004 0.0028 0.0048 0.0057
French?English 1133 0.6000 0.6000 0.6195 0.6092 0.6400
1345 0.0600 0.0667 0.0809 0.0495 0.0420
1623 0.0750 0.0798 0.1810 0.0228 0.0528
3005 0.0200 0.0232 0.0226 0.2709 0.1063
3007 0.0003 0.0003 0.0024 0.0025 0.0037
3025 0.0173 0.0173 0.0178 0.0173 0.0178
Table 6: Examples of MAP values obtained using different translation combinations for SUMMARY field
search. (The best results are in bold.)
Acknowledgement
Work partially supported by European Community
under the Information Society Technologies (IST)
programme of the 6th FP for RTD - project Mul-
tiMATCH contract IST- 033104. The authors are
solely responsible for the content of this paper. It
does not represent the opinion of the European Com-
munity, and the European Community is not respon-
sible for any use that might be made of data appear-
ing therein.
References
Sisay Fissaha Adafre and Maarten de Rijke. 2005. Discovering
missing links in wikipedia. In Proceedings of the 3rd inter-
national workshop on Link discovery, pages 90?97, Chicago,
Illinois. ACM Press.
Sisay Fissaha Adafre and Maarten de Rijke. 2006. Finding
similar sentences across multiple languages in wikipedia. In
Proceedings of the 11th Conference of the European Chapter
of the Association for Computational Linguistics, pages 62?
69, Trento, Italy.
Giuseppe Amato, Claudio Gennaro, Fausto Rabitti, and
Pasquale Savino. 2004. Milos: A multimedia content man-
agement system for digital library applications. In Proceed-
ings of the 8th European Conference on Research and Ad-
vanced Technology for Digital Libraries, Lecture Notes in
Computer Science, pages 14?25. Springer-Verlag.
Gosse Bouma, Ismail Fahmi, Jori Mur, Gertjan van Noord, Lon-
neke van der Plas, and Jorg Tiedemann. 2006. The univer-
sity of groningen at QA@CLEF 2006 using syntactic knowl-
edge for QA. In Working Notes for the Cross Language
Evaluation Forum 2006 Workshop, Alicante, Spain.
Thierry Declerck, Asuncio`n Go`mez Pe`rez, Ovidiu Vela, Zeno
Gantner, and David Manzano-Macho. 2006. Multilingual
lexical semantic resources for ontology translation. In Pro-
ceedings of the 5th International Conference on Language
Resources and Evaluation, Genoa, Italy.
Erik Hatcher and Otis Gospodnetic. 2004. Lucene in Action (In
Action series). Manning Publications Co., Greenwich, CT,
USA.
Henning Mu?ller, Wolfgang Mu?ller, and David McG. Squire.
2001. Automated benchmarking in content-based image re-
trieval. In Proceedings of the 2001 IEEE International Con-
ference on Multimedia and Expo, Tokyo, Japan. IEEE Com-
puter Society.
Douglas W. Oard, Jianqiang Wang, Gareth J. F. Jones, Ryen W.
White, Pavel Pecina, Dagobert Soergel, Xiaoli Huang, and
Izhak Shafran. 2006. Overview of the CLEF-2006 cross-
language speech retrieval track. In Working Notes for the
Cross Language Evaluation Forum 2006 Workshop, Ali-
cante, Spain.
Douglas W. Oard. 1998. A comparative study of query
and document translation for cross-language information re-
trieval. In Proceedings of the 3rd Conference of the Associ-
ation for Machine Translation in the Americas on Machine
Translation and the Information Soup, pages 472?483, Lon-
don, UK. Springer-Verlag.
Philippe Smets. 1990. The combination of evidence in the
transferable belief model. IEEE Transaction on Pattern
Analysis and Machine Intelligence, 12(5):447?458.
Ryen W. White, Douglas W. Oard, Gareth J. F. Jones, Dagobert
Soergel, and Xiaoli Huang. 2005. Overview of the CLEF-
2005 cross-language speech retrievaltrack. In Carol Pe-
ters, Fredric C. Gey, Julio Gonzalo, Henning Mu?ller, Gareth
J. F. Jones, Michael Kluck, Bernardo Magnini, and Maarten
de Rijke, editors, CLEF, volume 4022 of Lecture Notes in
Computer Science, pages 744?759. Springer.
88
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 905?916, Dublin, Ireland, August 23-29 2014.
Automatic Prediction of Text Aesthetics and Interestingness
Debasis Ganguly
CNGL,
School of Computing,
Dublin City University,
Dublin 9, Ireland
dganguly@computing.dcu.ie
Johannes Leveling
CNGL,
School of Computing,
Dublin City University,
Dublin 9, Ireland
jleveling@computing.dcu.ie
Gareth J.F. Jones
CNGL,
School of Computing,
Dublin City University,
Dublin 9, Ireland
gjones@computing.dcu.ie
Abstract
This paper investigates the problem of automated text aesthetics prediction. The avail-
ability of user generated content and ratings, e.g. Flickr, has induced research in aesthet-
ics prediction for non-text domains, particularly for photographic images. This problem,
however, has yet not been explored for the text domain. Due to the very subjective
nature of text aesthetics, it is difficult to compile human annotated data by methods
such as crowd sourcing with a fair degree of inter-annotator agreement. The availability
of the Kindle ?popular highlights? data has motivated us to compile a dataset com-
prised of human annotated aesthetically pleasing and interesting text passages. We then
undertake a supervised classification approach to predict text aesthetics by constructing
real-valued feature vectors from each text passage. In particular, the features that we use
for this classification task are word length, repetitions, polarity, part-of-speech, semantic
distances; and topic generality and diversity. A traditional binary classification approach
is not effective in this case because non-highlighted passages surrounding the highlighted
ones do not necessarily represent the other extreme of unpleasant quality text. Due to the
absence of real negative class samples, we employ the MC algorithm, in which training
can be initiated with instances only from the positive class. On each successive iteration
the algorithm selects new strong negative samples from the unlabeled class and retrains
itself. The results show that the mapping convergence (MC) algorithm with a Gaussian
and a linear kernel used for the mapping and convergence phases, respectively, yields the
best results, achieving satisfactory accuracy, precision and recall values of about 74%,
42% and 54% respectively.
1 Introduction
Since their inception, Amazon Kindle device
1
and Apps for other general purpose hand-held
devices, have led to a massive increase in the trend of reading e-books over paper printed ones.
The Amazon Kindle and the Kindle Apps provide a very simple mechanism for highlighting a
piece of text and sharing it on social media. The most popular highlighted pieces of text are
shown in the Kindle device with an intention to help readers focus on passages that are pleasing or
interesting to the greatest number of people. Every month, Kindle customers highlight millions
of book passages that are meaningful to them
2
. The general trend among Kindle readers, while
reading the classic English literary works, is to highlight text passages that are associated with
a high aesthetic quality. An example highlighted passage is shown in Figure 1.
With the availability of such highlighted text, which may be considered as text passages which
most readers find pleasing to read, an interesting research problem is to attempt automatic
prediction of highlighted pieces of text. In other words, given a text passage, the objective is to
This work is licensed under Creative Commons Attribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1
https://kindle.amazon.com/
2
https://kindle.amazon.com/most_popular
905
It was the best of times, it was the worst of times, it was the age of wisdom, it was
the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was
the season of Light, it was the season of Darkness, it was the spring of hope, it was the
winter of despair.
Figure 1: Passage from A tale of two cities (Charles Dickens), highlighted by 6843 Kindle
readers.
determine the likelihood of it being aesthetically pleasing and interesting. Such an automated
approach of identifying aesthetically pleasing text passages may potentially be used to endorse
a newly released book on e-commerce websites with an aim to increase its sales. Moreover, such
an approach may also, in principle, be used as a tool by an author to determine how likely it is
for readers to appreciate a newly written text passage.
The key challenge in solving this problem is to determine the characteristic attributes of a
popular highlighted text passage. An intuitive assumption is that the popularity of a high-
lighted passage depends on its aesthetic quality. Generally speaking, passages inclined towards
expressing an author?s view on a subject, which may often be philosophical in nature, with
considerable application of atypical figures of speech, e.g. anaphora, alliteration, antithesis,
metaphor, simile, personification etc., are more likely to be highlighted than a straight-forward
story narrative passage. For example, the highlighted passage in Figure 1 is rich in anaphora
(repetition of the same word or group of words in a paragraph, e.g. ?times?, ?age?, ?epoch?
etc.) and antithesis (juxtaposition of opposing or contrasting ideas, e.g. ?best of times?, ?worst
of times?; ?wisdom?, ?foolishness? etc). An automated approach of aesthetic quality prediction
thus has to take into account these different features of a text passage. The idea of using these
features for text aesthetics prediction, in fact, forms a core part of our work.
It is particularly interesting to see that this problem of automatically predicting text aes-
thetics is largely different from the standard well researched problem of document text classi-
fication (Sebastiani, 2002). The reason is as follows. The problem of text categorization can
effectively be solved by the application of discrete categorical features, such as character n-gram
frequencies and word frequencies. In other words, the presence of characteristic words from a
particular domain is a good indicator of the class of a document, e.g. the presence of the words
?soccer?, ?goal? etc. in a document is a good indicator that the document is of the sports
genre, whereas the presence of words such as ?money?, ?bank? etc. would indicate that the
genre is finance. Consequently, the generative framework of a multinomial Naive Bayes (NB)
model with character n-gram and word n-grams based features works effectively for this class of
problems (McCallum and Nigam, 1998).
In the case of aesthetic quality prediction, however, the mere presence of a particular word or
character n-gram can hardly be a good indicator of the inherent literary quality of the text. The
output classes of this classification problem, namely aesthetic or not aesthetic, do not comprise
a small vocabulary of domain-specific representative terms such as in the case of the sports or
finance domains. The vocabularies of the respective classes in this classification problem are
largely unrestricted and mutually indistinguishable.
The rest of the paper is organized as follows. Section 2 presents related research. In Section 3,
we present our proposed approach to solve the text aesthetics problem. Section 4 describes our
experimental settings, following which Section 5 presents the results. In Section 6, we investigate
the contribution from individual features and then the relative importance of the features when
used in combination. Finally, Section 7 concludes the paper.
2 Related Work
A computational viewpoint of aesthetic quality, in general, takes into account the subjectivity of
an observer and postulates that among several observations, the aesthetically most pleasing one
906
is the one with the shortest description, given the observer?s previous knowledge (Schmidhuber,
2010). An agent driven reinforcement based learning algorithm can then be used in principle to
produce creative (novel and interesting) outputs (Schmidhuber, 2010). Our work in this paper
is largely different from the general reinforcement learning paradigm, because we focus on the
particular problem of text aesthetics viewing the problem as a supervised classification task.
Moreover, the proposition of minimum description length as an attribute of aesthetic quality
(Schmidhuber, 2010) is counter-intuitive for literary works.
There has been considerable research interest in automatically predicting visual aesthetic
quality of images (Dhar et al., 2011) and layout of web pages (Reinecke et al., 2013). Most
empirically successful approaches to image aesthetics prediction first transform an image into a
feature vector of characteristic attributes that play a pivotal role in differentiating an interesting
image from a non-interesting one. Generally speaking, some of these attributes which determine
whether an image is aesthetically pleasing are the presence of salient objects (indicated by a low
depth of field), compositional attributes (e.g. the rule of thirds), the effect of light in natural
landscapes, etc. The next step is to apply a supervised learning algorithm, e.g. support vector
machine (SVM), to learn a two-class prediction model. Useful features, extracted from images
for this classification task include: i) colourfulness, contrast, symmetry, vanishing point and
facial features (Jiang et al., 2010); ii) face poses, between-face distances, and the consistency
of expressions on multiple faces (Li et al., 2010); iii) high level describable attributes, such as
compositional attributes (e.g. rule of thirds image layout), content attributes related to the
presence of people, animals, sky illumination attributes etc. (Dhar et al., 2011).
Our proposed method of text aesthetics prediction is similarly based on extracting character-
istic features from the text passages. However, in the case of literature, it is worth mentioning
that in contrast to image aesthetics it is more difficult to describe the subtle attributes which
differentiate an aesthetically pleasing text from its counterpart.
Although the authors are not aware of any reported research on text aesthetics, there has
been a considerable amount of research in the somewhat closely related problem of detect-
ing metaphors in text. Automated approaches to metaphor detection involve both supervised
and unsupervised approaches, some of which include: i) supervised classification on extracted
verbal target feature vectors of sentences (Gedigian et al., 2006); ii) expectation maximization
(EM) based unsupervised approach to non-literal word sense detection (Birke and Sarkar, 2006);
iii) unsupervised approach using hierarchical graph factorization clustering (Shutova and Sun,
2013).
In general, it is intuitive to assume that metaphorical or figurative parts of text are aestheti-
cally pleasing and interesting, which makes the problem of text aesthetics prediction somewhat
similar to that of metaphor detection. Unfortunately, this assumption is not often true, and
this is particularly the case for literary works due to the availability of a large number of figures
of speech at an author?s disposal (metaphor just being one of them). For example, the sample
Kindle highlighted passage shown in Section 1 has an obvious aesthetic appeal to a large number
of readers, in spite of it being not metaphorical.
3 Our Approach to the Text Aesthetics Prediction Problem
In this section, we describe the details of our approach to text aesthetics prediction. We hy-
pothesize that a NB classifier with word or character n-gram based features is not suitable for
this particular problem due to the mutual overlap and lack of domain specific restriction in the
vocabulary of the output classes (i.e. aesthetic and non-aesthetic). One thus needs to extract a
set of characteristic features from the text passages which may be useful to solve the classifica-
tion problem. We describe the features used in our approach in Section 3.1. In Section 3.2, we
propose to use the mapping convergence (MC) algorithm for the text aesthetics problem, where
the intention is to learn a classifier only from positive samples.
907
The truth is rarely pure and never simple. Modern life would be very tedious if it were
either, and modern literature a complete impossibility!
Figure 2: Passage from The Importance of Being Earnest (Oscar Wilde).
3.1 Feature Vector Encoding of Text Passages
In this section, we introduce the various features used for the text aesthetics classification task.
Each feature is a function which maps a passage of text P = {w
1
. . . w
N
} comprising N words
into a real number.
3.1.1 Word-based Features
In Section 1, we illustrated that that an anaphora is a rheoteric device used by authors to
emphasize a text passage, which in turn indicates that such a passage is likely to attract the
attention of readers and hence are likely to be highlighted by them. Moreover, the closer the
repetitions are, the stronger is the emphasis.
On the basis of this reasoning, we employ an average positional difference weighted count of
word repetitions in a passage. To be more precise, for each word in a passage we compute the
number of times a word w
i
is repeated, divide this count by the difference between the repeating
position (say at position j), and average the sum of counts for all repeating words over the
passage length, as shown in Equation 1. In Equation 1, 1(w
i
= w
j
) is the indicator function
which is 1 if and only if w
i
= w
j
and 0 otherwise.
The second word level feature which we use, is the average length of words in a passage.
The reasoning behind using this feature is that authors tend to use relatively longer words (e.g.
superlatives) to emphasize a passage. Equation 2 shows how this is computed.
W
1
(P ) =
2
N(N ? 1)
N
?
i=1
N
?
j=i+1
1(w
i
= w
j
)
j ? i
(1)
W
2
(P ) =
1
N
N
?
i=1
len(w
i
) (2)
3.1.2 Topic-based Features
An attribute which can be considered responsible for the aesthetic quality of a text passage is
the diversity of topics it expresses. It is reasonable to assume that a text passage expressing a
broad idea or opinion of an author, often philosophical in nature, is likely to be appealing to
readers. Such general themed text passages typically cover a broad range of topics, as a result
of which the constituent words of such text passages involve collocation of seemingly unrelated
terms. For example, in the text passage shown in Figure 2, the word pairs (truth, tedious), and
(literature, impossibility) would typically appear in different topic classes, where by a topic we
mean a set of words with high co-ocurrence likelihood estimated from a collection of documents
by standard topic modelling techniques such as the Latent Dirichlet allocation (LDA) (Blei et
al., 2003). To encode this diversity of topics as a real valued feature function, we use Equation 3.
T
1
(P ) =
2
N(N ? 1)
N
?
i=1
N
?
j=i+1
1[z(w
i
) 6= z(w
j
)]
(j ? i)
(3)
In Equation 3, z(w) denotes the topic class of the word w obtained with the help of LDA. A
mismatch in the topic class is divided by the distance between the mismatches to assign more
weight to the close mismatches. As an example, the mismatch between (literature, impossibility)
bears more importance than the mismatch between (modern, impossibility).
The second topic-based feature which we use pertains to predicting the abstractness of the
content of a passage. It has been reported that words highly representative of topics are generally
908
not metaphorical. We apply a similar reasoning to hypothesize that since an interesting piece of
text is more likely to be philosophical or abstract in nature in comparison to a story narrative,
the constituent words are less likely to be the representatives of their topic classes. Formally
speaking in terms of LDA, these words are expected to have smaller values of max
k
?
k
(w). Recall
that a topic representative word in LDA exhibits a skewed distribution with a peak for one topic
class (with a high value of max
k
?
k
(w)), whereas a less representative word exhibits a more
uniform distribution of ?
k
(w) values over the topic classes (thus a low value of max
k
?
k
(w)). We
use Equation 4 to compute the average topic concreteness of a text passage.
T
2
(P ) =
1
N
N
?
i=1
max
k
?
k
(w
i
) (4)
3.1.3 Part of Speech Feature
We hypothesize that another attribute of an aesthetic passage is that it is likely to contain a
rich usage of adjectives (mostly of superlative type for the sake of emphasis) and adverbs. We
therefore employ the part of speech tag (POS) information of the constituent words of a text
passage as one of our features. To be more specific, we use the average number of adjectives
and adverbs of a text passage as the feature value. This is shown in Equation 5.
POS(P ) =
1
N
N
?
i=1
(#adjectives+ #adverbs) (5)
3.1.4 Sentiment Feature
We pointed out in Section 1 that authors often use the antithesis figure of speech to express con-
trasting concepts. Thus, another feature which we can use is the aggregated absolute difference
values between the sentiment polarities of words in a text paragraph. This again is weighted
by the difference in position between a positive sentiment word and its negative counterpart to
assign more importance to closely occurring opposite sentiment concepts.
To obtain the sentiment values of the constituent words, we used the SentiWordNet
3
. To
illustrate with an example, consider the closely occurring opposite sentiment word pairs (best
(0.75), worst (-0.75)), (wisdom (0.375), foolishness (-0.375)) etc. of Figure 1 and the word pairs
(complete (0.625), impossibility (-0.25)) of Figure 2, where the numbers in the parentheses show
the positive or the negative sentiment value (a normalized number between 0 and 1). Equation 6
shows the real-valued function derived from the sentiment information of word pairs, where the
function s(w) denotes the sentiment value associated with the word w.
SENT (P ) =
2
N(N ? 1)
N
?
i=1
N
?
j=i+1
|s(w
i
)? s(w
j
)|
(j ? i)
(6)
3.1.5 Inter-word Semantic Distance Feature
An alternative way to represent the topic diversity is to capture the likelihood of the event
of occurrence of two words in close vicinity. The higher this likelihood is, the better is the
semantic relation or coherence between the words. We make use of the DISCO
4
tool to compute
the semantic relation between two words in a word pair. In DISCO, these semantic relations
between the words are precomputed on the basis of co-occurrence likelihoods from a large corpus,
e.g. the Wikipedia (Kolb, 2008). DISCO provides two similarity measurements (named the first
order and the second order similarities) between two input words. While the first order similarity
between two input words is computed based on their collocation sets, the second order similarity
is computed based on their sets of distributionally similar words (Kolb, 2008). We denote the
3
http://sentiwordnet.isti.cnr.it/
4
http://www.linguatools.de/disco/disco_en.html
909
first order and the second order similarities between words w
i
and w
j
respectively as ds
1
(w
i
, w
j
)
and ds
2
(w
i
, w
j
) respectively.
In relation to text aesthetics, we expect a small value of average first order and second order
similarity values between word pairs in a highlighted piece of text in comparison to a non-
highlighted one. Similar to our earlier features, we divide these similarity values by the positional
difference between the words in order to put more emphasis on semantic diversity between closely
occurring words. Equation 7 shows the two features extracted making use of these similarity
values.
SD
k
(P ) =
2
N(N ? 1)
N
?
i=1
N
?
j=i+1
|ds
k
(w
i
)? ds
k
(w
j
)|
(j ? i)
, k = {1, 2} (7)
3.2 Learning from Positive Examples: The MC Algorithm
Binary classifiers, such as SVMs, work particularly well with a sufficient number of both positive
and negative class instances for training. In the case of text aesthetics prediction problem, the
passages highlighted by Kindle readers serve as the positive class samples. Although it might
be intuitive to use the non-highlighted passages as instances of the negative type, there can be
problems associated with this approach.
Firstly, the non-highlighted passages are not essentially instances of the negative class because
the non-highlighted passages are not necessarily aesthetically unpleasing. Secondly, there is an
element of cognitive bias associated with the highlighting process because a reader, who can
already see popular highlights while reading a page, may be biased to highlight the same passage
himself, and may not in fact highlight some other passage which he himself found interesting.
Note that this observation in fact makes our problem more challenging to solve in comparison
to aesthetics prediction in other domains, such as images, where information such as Flickr
5
photo ratings can be used as strong positive or negative indicators of an image interestingness
or aesthetic quality, leading to effective classification results using a standard binary classification
approach (Dhar et al., 2011).
Due to the presence of incompletely labeled examples, we apply the mapping convergence
(MC) algorithm (Yu et al., 2003) for this task. The objective of the MC algorithm is to predict
the positive samples from a test data, given a mixture of positive and unlabeled samples. These
unlabeled samples in the MC algorithm can be treated as instances of either the positive or the
negative class in order to obtain maximum classification effectiveness.
The two stages of the MC algorithm are summarized as follows.
1. The mapping stage identifies from the unlabeled samples the strong negative ones, i.e. the
points distinctly different from the positive samples.
2. The convergence stage is an iterative step to learn a binary classification model, e.g. SVM,
using the positive and the strong negative samples. Each iterative step of convergence
classifies the remaining unlabeled samples to collect more strong negative samples. The
convergence step is repeated until no more strong negative samples are found.
The objective of the convergence step of the MC algorithm is to maximize margin to make
progressively better approximation of the negative data. At the end of the iteration, the class
boundary eventually converges to the boundary around the positive data set in the feature
space (Yu et al., 2003).
In our approach to the text aesthetics prediction task, we implement the mapping stage of
the MC algorithm with the help of standard one-class classifiers, namely the one class SVM
(OSVM) (Scho?lkopf et al., 1999) and the support vector data descriptor (SVDD) (Tax and
Duin, 2004). The OSVM separates all the data points in the feature space from the origin, with
the help of a separating hyperplane with maximum distance from the origin. The OSVM is thus
5
https://www.flickr.com/
910
able to separate out regions in the input space with high probability densities (Scho?lkopf et al.,
1999). SVDD, on the other hand, instead of a planar, takes a spherical approach to the one
class problem. The algorithm obtains a spherical boundary in feature space around the data.
The volume of this hypersphere is minimized to minimize the effect of incorporating outliers in
the solution (Tax and Duin, 2004).
It is worth mentioning here that although the OSVM and the SVDD can be trained with
positive samples only, these models are prone to over-fitting or under-fitting due to a small
number of support vectors modeled from a small number of positive samples (Yu et al., 2003).
In contrast, a binary SVM can model data more robustly due to the presence of the additional
negative samples. Hence, OSVM and the SVDD are typically used as a weak classifier to obtain
a set of initial strong negative samples in order to initiate the convergence step of the MC
algorithm.
4 Experiment Settings
In this section, we describe the dataset and the tools used for our experiments.
4.1 Dataset Construction
The standard practice to evaluate the metaphor detection problem, which is somewhat similar
to the text aesthetics prediction, is to make extensive use of manually annotated data typically
obtained under controlled user-based studies, where the users or the participants are instructed
to perform some given objectives, such as manually label metaphors in a collection of documents,
e.g. (Hovy et al., 2013). The main difficulties with this approach are that: i) it takes a
considerable amount of time to collect data; ii) the quality of the data depends largely on
controlled experimental settings, e.g. the data quality may be susceptible to errors caused by
targeted, malicious work efforts, since there is often a financial incentive to complete tasks
quickly rather than effectively (Ipeirotis et al., 2010); and iii) it is very difficult to compare the
effectiveness of two methods on two different datasets obtained under different controlled user
study settings.
The availability of fairly large amounts of highlighted text on the Amazon website has ensured
a reliable and fast way to construct the dataset for carrying out the text aesthetics experiments.
The advantages are as follows. Firstly, it is not necessary to conduct crowd sourcing experiments
for data collection. Secondly, since the data is not generated by controlled crowd sourcing, the
quality of the data is more reliable because there is no financial incentive to complete tasks
quickly. Thirdly, since the data is publicly available, it is possible to achieve a fair comparison
between different problem solving approaches.
The Amazon ?Popular Highlights?
6
web page presents a ranked list of the most highlighted
passages, sorted in descending order by the number of highlights. However, at the time of writing
this paper, Amazon has neither made the data publicly downloadable nor provided an API to
access it. For conducting our experiments with this data, we therefore had to automatically
crawl data from the Popular Highlights web page.
In addition to the highlighted passages (serving as the positive class samples in our dataset),
we also need the non-highlighted ones (meant to serve as the unlabeled samples). The text from
the non-highlighted passages, however, are not available in the Popular Highlights web page.
This data was thus extracted from those books, the passages of which are popularly highlighted.
In order to ensure free access to book content, we had to restrict our dataset to the 50 most
popular highlighted classic English fictions.
More precisely speaking, for every highlighted passage found while crawling the Amazon
Popular Highlights page, our crawler checks if the book is available on project Gutenberg
7
. If
not, then we examine the next highlighted passage, otherwise we craw the full text of the book,
6
https://kindle.amazon.com/most_popular/highlights_all_time/
7
http://www.gutenberg.org/
911
in which the current highlighted passages belongs, from project Gutenberg website. The crawler
continued to run until we had collected highlighted passages from 50 different literature classics.
The dataset for the prediction task is then constructed as follows. First, we add the text of
all highlighted passages as instances of the positive class. Next, for each highlighted passage,
we add the paragraph preceding and succeeding it into the dataset as the unlabeled samples.
Note that selecting the unlabeled samples this way is better than random selection of non-
highlighted passages from full text, because this way of choosing negative samples ensures a
meaningful representation of reader judgments to highlight a particular passage of text from
within a surrounding context.
We then partition the dataset comprised of the positive and unlabeled samples into equal
sized training and test sets. In Table 1, we outline the characteristics of the dataset.
Dataset # Books Vocab. # Passages
Size Highlighted Unhighlighted Total
Train 25 9560 168 305 473
Test 25 7883 169 319 488
Total 50 13496 337 624 961
Table 1: Dataset characteristics
4.2 Implementation Details
For each passage in the dataset, we extract the features described in Section 3.1. To compute
the topic modeling based features we used Mallet
8
. The number of topics (K) in LDA was set
to 100. The POS tag feature was extracted with the help of the Stanford POS tagger
9
. For
extracting the sentiment feature, we made use of the Java API of the SentiWordNet
10
. For the
semantic word distance feature, we used the DISCO Java API
11
.
For the naive Bayes experiment, we used the Stanford classifier
12
. The SVM experiments
(binary SVM, one-class SVM, SVDD) were conducted with the libSVM software
13
.
4.3 Evaluation Metrics
For all the experiments reported in this paper, the classification effectiveness mainly focuses on
precision and recall with respect to the positive class. Consequently, precision, recall and the
F-score measures, shown in Tables 2 and 3, are measured with respect to the positive class only.
Ideally, for this problem one would want to obtain a high recall, i.e. identify as many high-
lighted passages correctly as possible. In this situation, recall is thus more important than
precision. Achieving a good precision is desirable, nonetheless, to minimize the false positives.
Although we report accuracy, we emphasize that accuracy alone is not a good measure of clas-
sification effectiveness in this case, because correct identification of negative instances is not
important for this problem.
5 Results
Before conducting experiments with the MC algorithm, we obtained baseline results by classify-
ing the dataset using NB and SVMs. In the case of NB, instead of using the real valued features
from the text passages (as proposed in Section 3.1), we simply used the character n-gram and
word n-gram features (maximum value of n was set to 5) from the text, automatically extracted
8
http://mallet.cs.umass.edu/
9
http://nlp.stanford.edu/software/tagger.shtml
10
http://sentiwordnet.isti.cnr.it/code/SentiWordNetDemoCode.java
11
http://www.linguatools.de/disco/disco_en.html
12
http://nlp.stanford.edu/software/classifier.shtml
13
http://www.csie.ntu.edu.tw/
~
cjlin/libsvmtools/
912
Classifier Kernel Accuracy Precision Recall F-score
NB N/A 67.40 54.40 36.70 43.80
BSVM Linear 66.19 35.71 5.92 10.15
BSVM Gaussian 67.00 39.39 15.38 22.13
OSVM Linear 38.32 32.46 51.48 39.82
OSVM Gaussian 53.68 41.87 50.29 45.70
SVDD Linear 35.04 34.77 100.00 51.60
SVDD Gaussian 37.91 35.56 97.63 52.13
Table 2: Text aesthetics prediction results with Naive Bayes and SVM.
Classifier Kernel Accuracy Precision Recall F-score
Mapping Convergence Mapping Convergence
OSVM BSVM Linear Linear 66.18 35.71 5.92 10.15
OSVM BSVM Linear Gaussian 64.96 40.26 36.69 38.39
OSVM BSVM Gaussian Linear 66.80 44.44 11.83 18.69
OSVM BSVM Gaussian Gaussian 64.34 36.87 39.05 37.93
SVDD BSVM Linear Linear 40.98 35.76 92.90 51.64
SVDD BSVM Linear Gaussian 43.44 36.17 90.53 51.69
SVDD BSVM Gaussian Linear 56.76 42.90 74.64 54.42
SVDD BSVM Gaussian Gaussian 47.34 38.60 88.17 53.69
Table 3: Text aesthetics prediction results by the MC algorithm with different settings.
by the Stanford classifier. The result of this experiment (see Table 2) shows that the recall value
is very low, which in turn indicates that word vocabulary based features, typically used for text
categorization, are not effective for this task.
The next classification method that we employ is standard binary class SVM (denoted as
BSVM). The training phase of the BSVM used the non-highlighted passages as negative class
instances. We experimented with both linear and Gaussian kernels. For all reported results
which use the Gaussian kernel, the parameter ? was set to the default value of 1/(#features)
as per the libSVM implementation. Although the accuracy achieved is comparable to NB, the
recall achieved is worse, which shows that treating non-highlighted passages as negative class
instances is not reasonable for this problem (see Section 6.2 for an illustration).
The recall value is significantly increased with the help of one-class SVM (OSVM). SVDD
performs even better in terms of recall. However, SVDD significantly underfits the data because
it classifies almost every test data point as an instance of the positive class, thus achieving low
accuracy and precision due to the presence of too many false positives.
Our next set of experiments involves the MC algorithm for classification. Since, the mapping
phase makes use of only the positive data, we employed both the one-class classifiers used in the
experiments of Table 2, i.e. OSVM and SVDD, for this purpose. Mapping with OSVM results
in an improvement in the accuracy at the cost of sacrificing recall, which is not desirable for
this problem. However, note that the negative samples obtained with the OSVM mapping (with
Gaussian kernel) improves the classification effectiveness of the BSVM (compare the fourth row
of Table 3 with the second row of Table 2), which indicates that the MC algorithm does improve
the classification effectiveness, confirming our hypothesis that it is reasonable not to consider
every non-highlighted passage as negative samples.
The problem of SVDD underfitting (as evident from the SVDD results of Table 2) is alleviated
by the MC approach. The most effective MC approach uses Gaussian/linear kernels for map-
ping/convergence (see the seventh row of Table 3). Accuracy is increased to around 56% with
a satisfactory recall of around 74%. The use of Gaussian kernel during both the mapping and
convergence steps yields a higher recall but at the cost of more false positives (lower accuracy,
precision and F-score).
913
Feature combination vector Evaluation Metrics
Word Topics POS/Polarity Semantic Accuracy Precision Recall F-score
1 0 0 0 36.06 34.88 97.63 51.40
0 1 0 0 37.91 35.74 99.40 52.58
0 0 1 0 36.05 35.01 98.81 51.70
0 0 0 1 42.41 37.03 94.67 53.24
1 1 1 1 56.76 42.90 74.64 54.42
Table 4: Individual feature contributions for identifying text aesthetics.
Feature igain
Topic diversity (T
1
) 0.3684
Sentiment (SENT ) 0.2685
Word repetition (W
1
) 0.2509
First-order semantic distance (SD
1
) 0.1543
Part-of-speech (POS) 0.1448
Second-order semantic distance (SD
2
) 0.1141
Word length (W
2
) 0.0732
Topic abstractness (T
2
) 0.0526
Table 5: Ranking features by their igain values.
6 Posthoc Analysis
In this section, we comment on the importance of the features used for classification, and also
illustrate how the MC algorithm helps in increasing the separability between the classes.
6.1 Feature Importance
First, we investigate the importance of the different features by a selective choice of only one
group of features at at time for the classification. The classifier we use for this experiment is
MC with a Gaussian SVDD kernel for mapping and a linear SVM kernel for convergence (as per
the best settings of Table 3). The results are shown in Table 4 from which it can be seen that
the best accuracy is obtained with the use of the semantic distance features.
It can be observed that the accuracy values obtained with a single category of features, such
as word-based (length and repetition), topic-based (generality and diversity) and so on, are
considerably lower than the accuracy value obtained with a combination of all the features (the
last row of Table 4. The precision values achieved with these individual feature groups are also
considerably lower than the precision of 42.90% of the overall combination.
Next, we find out the relative importance of each feature in their overall combination by
ranking the features with the help of a standard feature quality estimator, called information
gain (igain) (Quinlan, 1986). The results are presented in Table 5. It can be seen that the topic
diversity is the most discriminative feature having an igain value significantly higher than the
second most important one in the list. This observation verifies our hypothesis that aesthetically
appealing passages are those constituting terms from diverse topics.
The sentiment and the word repetition features, having close igain values, are second and
third respectively in the list. The usefulness of the sentiment feature suggests that contrasting
concepts packed in close vicinity of a sentence are likely to be aesthetically pleasing to read.
The word repetition feature, on the other hand, suggests that the anaphora figure of speech is
likely to be be associated with aesthetically pleasing text.
6.2 Illustration of the usefulness of the MC Algorithm
This section investigates the usefulness of the MC algorithm for the text aesthetics classification.
In particular, we show that for this one class classification problem, the MC algorithm can
selectively refine the set of unlabeled samples and retrain the model for better separability
914
1-1 0  
0.94
-1
-0.031
(a) Before MC.
1-1 0  
0.94
-1
-0.031
(b) After MC convergence (5 iterations).
Figure 3: Visualization of the training set in the two most discriminating dimensions, i.e. topic
diversity (Y-axis) and sentiment (X-axis).
between the positive and the unlabeled classes.
To illustrate our claim, we first plot the initial training set in two dimensional subspace
before the application of MC, i.e. when all the unlabelled instances are treated as negative class
samples; this is shown in Figure 3a. The two dimensions that we use for plotting this figure,
are the two features having the highest igain values, i.e. the topic diversity (T
1
) and sentiment
(SENT ) features. Figure 3a shows that the highlighted text passages (shown in blue) are not
well separated from the non-highlighted ones (shown in red).
Next, in Figure 3b, we plot the training set with a reduced number of samples from the negative
(non-aesthetic) class obtained after running the MC algorithm. Figure 3b clearly shows that
after convergence the MC algorithm has retained only the strong negative samples for training,
as is evident from a better visual separation between the classes. A binary classifier, trained on
the dataset of Figure 3b, is thus likely to be more effective than that trained with Figure 3a.
7 Conclusions
This paper investigated the problem of automated text aesthetics prediction. As distinguishing
features for text aesthetics identification, we applied different statistical features such as word
repetitions, topic diversity, part-of-speech, word polarity etc. We collected aesthetically pleasing
text passages from the Kindle ?popular highlights? website for conducting our experiments. Due
to the presence of only positive class samples, i.e. the highlighted passages, in this dataset, we
apply the MC algorithm to iteratively train a binary classifier with the strongly negative samples.
The results of our experiments show that the MC algorithm with a Gaussian and a linear ker-
nel applied for the mapping and convergence phases respectively, yields the best results achieving
satisfactory recall, precision and F-score values of about 74%, 42% and 54% respectively. More-
over, the results also demonstrate that the topic diversity, word polarity and word repetition are
the three most distinguishing features for text aesthetics identification. Furthermore, our results
are comparable to those of a somewhat similar problem of figurative text detection where the
best reported F-score values achieved are about 54% (Birke and Sarkar, 2006) and 64% (Shutova
and Sun, 2013).
Acknowledgments
This research is supported by Science Foundation Ireland (SFI) as a part of the CNGL Centre
for Global Intelligent Content at DCU (Grant No: 12/CE/I2267).
915
References
Julia Birke and Anoop Sarkar. 2006. A clustering approach for nearly unsupervised recognition of
nonliteral language. In EACL 2006, 11st Conference of the European Chapter of the Association
for Computational Linguistics, Proceedings of the Conference, April 3-7, 2006, Trento, Italy. The
Association for Computer Linguistics.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of
Machine Learning Research, 3:993?1022, March.
Sagnik Dhar, Vicente Ordonez, and Tamara L. Berg. 2011. High level describable attributes for predict-
ing aesthetics and interestingness. In The 24th IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2011, Colorado Springs, CO, USA, 20-25 June 2011, pages 1657?1664.
Matt Gedigian, John Bryant, Srini Narayanan, and Branimir Ciric. 2006. Catching metaphors. In
Proceedings of the Third Workshop on Scalable Natural Language Understanding, ScaNaLU ?06, pages
41?48, Stroudsburg, PA, USA. Association for Computational Linguistics.
Dirk Hovy, Shashank Shrivastava, Sujay Jauhar, Mrinmaya Sachan, Kartik Goyal, Huying Li, Whit-
ney Sanders, and Eduard Hovy. 2013. Identifying metaphorical expressions with tree kernels. In
Proceedings of NAACL-HLT Meta4NLP Workshop.
Panagiotis G. Ipeirotis, Foster Provost, and Jing Wang. 2010. Quality management on amazon mechani-
cal turk. In Proceedings of the ACM SIGKDD Workshop on Human Computation, HCOMP ?10, pages
64?67, New York, NY, USA. ACM.
Wei Jiang, Alexander C. Loui, and Cathleen Daniels Cerosaletti. 2010. Automatic aesthetic value
assessment in photographic images. In Proceedings of the 2010 IEEE International Conference on
Multimedia and Expo, ICME 2010, 19-23 July 2010, Singapore, pages 920?925.
Peter Kolb. 2008. DISCO: A Multilingual Database of Distributionally Similar Words. In KONVENS
2008 ? Erga?nzungsband: Textressourcen und lexikalisches Wissen, pages 37?44.
Congcong Li, Alexander C. Loui, and Tsuhan Chen. 2010. Towards aesthetics: A photo quality assess-
ment and photo selection system. In Proceedings of the International Conference on Multimedia, MM
?10, pages 827?830, New York, NY, USA. ACM.
Andrew McCallum and Kamal Nigam. 1998. A comparison of event models for naive bayes text classifi-
cation. In AAAI/ICML Workshop on Learning for Text Categorization, pages 41?48.
J. R. Quinlan. 1986. Induction of decision trees. Mach. Learn., 1(1):81?106, March.
Katharina Reinecke, Tom Yeh, Luke Miratrix, Rahmatri Mardiko, Yuechen Zhao, Jenny Liu, and
Krzysztof Z. Gajos. 2013. Predicting users? first impressions of website aesthetics with a quantifi-
cation of perceived visual complexity and colorfulness. In Proceedings of the SIGCHI Conference on
Human Factors in Computing Systems, CHI ?13, pages 2049?2058, New York, NY, USA. ACM.
Ju?rgen Schmidhuber. 2010. Formal theory of creativity, fun, and intrinsic motivation (1990-2010). IEEE
T. Autonomous Mental Development, 2(3):230?247.
Bernhard Scho?lkopf, Robert C. Williamson, Alex J. Smola, John Shawe-Taylor, and John C. Platt. 1999.
Support vector method for novelty detection. In Advances in Neural Information Processing Systems
12, [NIPS Conference, Denver, Colorado, USA, November 29 - December 4, 1999, pages 582?588. The
MIT Press.
Fabrizio Sebastiani. 2002. Machine learning in automated text categorization. ACM Comput. Surv.,
34(1):1?47, March.
Ekaterina Shutova and Lin Sun. 2013. Unsupervised metaphor identification using hierarchical graph
factorization clustering. In Human Language Technologies: Conference of the North American Chapter
of the Association of Computational Linguistics, Proceedings, June 9-14, 2013, Westin Peachtree Plaza
Hotel, Atlanta, Georgia, USA, pages 978?988. The Association for Computational Linguistics.
David M. J. Tax and Robert P. W. Duin. 2004. Support vector data description. Mach. Learn., 54(1):45?
66, January.
Hwanjo Yu, ChengXiang Zhai, and Jiawei Han. 2003. Text classification from positive and unlabeled
documents. In Proceedings of the 2003 ACM CIKM International Conference on Information and
Knowledge Management, New Orleans, Louisiana, USA, November 2-8, 2003, pages 232?239. ACM.
916
