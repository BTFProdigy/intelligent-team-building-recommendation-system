Incremental Construction of Minimal 
Acyclic Finite-State Automata 
Jan Daciuk* 
Technical University of Gdafisk 
Bruce W. Watson  ~ 
University of Pretoria 
S toyan  Mihov  t 
Bulgarian Academy of Sciences 
R ichard  E. Watson~ 
In this paper, we describe a new method for constructing minimal, deterministic, acyclic finite- 
state automata from a set of strings. Traditional methods consist of two phases: the first to construct 
a trie, the second one to minimize it. Our approach is to construct a minimal automaton in a 
single phase by adding new strings one by one and minimizing the resulting automaton on-the- 
fly. We present ageneral algorithm as well as a specialization that relies upon the lexicographical 
ordering of the input strings. Our method is fast and significantly lowers memory requirements 
in comparison to other methods. 
1. Introduction 
Finite-state automata are used in a variety of applications, including aspects of natural 
language processing (NLP). They may store sets of words, with or without annotations 
such as the corresponding pronunciation, base form, or morphological categories. The 
main reasons for using finite-state automata in the NLP domain are that their repre- 
sentation of the set of words is compact, and that looking up a string in a dictionary 
represented by a finite-state automaton is very fast--proportional to the length of the 
string. Of particular interest o the NLP community are deterministic, acyclic, finite- 
state automata, which we call dictionaries. 
Dictionaries can be constructed in various ways--see Watson (1993a, 1995) for a 
taxonomy of (general) finite-state automata construction algorithms. A word is simply 
a finite sequence of symbols over some alphabet and we do not associate it with 
a meaning in this paper. A necessary and sufficient condition for any deterministic 
automaton to be acyclic is that it recognizes a finite set of words. The algorithms 
described here construct automata from such finite sets. 
The Myhill-Nerode theorem (see Hopcroft and Ullman \[1979\]) states that among 
the many deterministic automata that accept a given language, there is a unique au- 
tomaton (excluding isomorphisms) that has a minimal number of states. This is called 
the minimal deterministic automaton of the language. 
The generalized algorithm presented in this paper has been independently devel- 
oped by Jan Daciuk of the Technical University of Gdafisk, and by Richard Watson 
? Department of Applied Informatics, Technical University of Gdafisk, U1. G. Narutowicza 11/12, 
PL80-952 Gdafisk, Poland. E-mail: jandac@pg.gda.pl 
Linguistic Modelling Laboratory, LPDP--Bulgarian Academy ofSciences, Bulgaria. E-mail: 
stoyan@lml.bas.bg 
:~ Department of Computer Science, University of Pretoria, Pretoria 0002, South Africa. E-mail: 
watson@cs.up.ac.za 
? E-mail: watson@OpenFIRE.org 
(~) 2000 Association for Computational Linguistics 
Computational Linguistics Volume 26, Number 1 
and Bruce Watson (then of the IST Technologies Research Group) at Ribbit Software 
Systems Inc. The specialized (to sorted input data) algorithm was independently de- 
veloped by Jan Daciuk and by Stoyan Mihov of the Bulgarian Academy of Sciences. 
Jan Daciuk has made his C++ implementations of the algorithms freely available 
for research purposes at www.pg.gda.pl/~jandac/fsa.html. 1 Stoyan Mihov has imple- 
mented the (sorted input) algorithm in a Java package for minimal acyclic finite-state 
automata. This package forms the foundation of the Grammatical Web Server for Bul- 
garian (at origin2000.bas.bg) and implements operations on acyclic finite automata, 
such as union, intersection, and difference, as well as constructions for perfect hash- 
ing. Commercial C++ and Java implementations are available via www.OpenFIRE.org. 
The commercial implementations include several additional features uch as a method 
to remove words from the dictionary (while maintaining minimality). The algorithms 
have been used for constructing dictionaries and transducers for spell-checking, mor- 
phological analysis, two-level morphology, restoration of diacritics, perfect hashing, 
and document indexing. The algorithms have also proven useful in numerous prob- 
lems outside the field of NLP, such as DNA sequence matching and computer virus 
recognition. 
An earlier version of this paper, authored by Daciuk, Watson, and Watson, ap- 
peared at the International Workshop on Finite-state Methods in Natural Language 
Processing in 1998--see Daciuk, Watson, and Watson (1998). 
2. Mathematical Preliminaries 
We define a deterministic finite-state automaton to be a 5-tuple M = (Q, ~, 6, q0, F), 
where Q is a finite set of states, q0 E Q is the start state, F C Q is a set of final states, 
is a finite set of symbols called the alphabet, and 6 is a partial mapping 6: Q x G ~ Q 
denoting transitions. When 6(q,a) is undefined, we write ~(q,a) = _L. We can extend 
the 6 mapping to partial mapping 6*: Q x ~* ~ Q as follows (where a E Y,, x E ~*): 
= q 
6*(q, ax) = {6*(6(q,a),x) ifotherwise6(q,a) ~ J_ 
Let DAFSA be the set of all deterministic finite-state automata in which the transition 
function 6 is acyclic--there is no string w and state q such that 6" (q, w) = q. 
We define ?(M) to be the language accepted by automaton M: 
?(M) = {xE I 6*(q0,x) 
The size of the automaton, IMI, is equal to the number of states, IQ\[. ~(G*) is the set 
of all languages over G. Define the function 2: Q ~ 7~(G *) to map a state q to the 
set of all strings on a path from q to any final state in M. More precisely, 
Z (q) = {x 16"(q,x) c F} 
? (q) is called the right language of q. Note that ?(M) =? (q0). The right language of 
1 The algorithms inDaciuk's implementation differ slightly from those presented here, as he uses 
automata with final transitions, not final states. Such automata h ve fewer states and fewer transitions 
than traditional ones. 
4 
Daciuk, Mihov, Watson, and Watson Incremental Construction of FSAs 
a state can also be defined recursively: 
(q)= {a?  (6 (q ,a ) ) \ [ac~A6(q ,a )~ _L } U {{~ } i fqEF  otherwise 
One may ask whether such a recursive definition has a unique solution. Most texts on 
language theory, for example Moll, Arbib, and Kfoury (1988), show that the solution 
is indeed unique--it is the least fixed-point of the equation. 
We also define a property of an automaton specifying that all states can be reached 
from the start state: 
Reachable(M) = Vq~Q 3xc ~, (6* ( qo, x) = q) 
The property of being a minimal automaton is traditionally defined as follows (see 
Watson \[1993b, 1995\]): 
Min(M) = VM, EDAFSA(~(M ) = ?(M') ~ IMI ~ IM'I) 
We will, however, use an alternative definition of minimality, which is shown to be 
equivalent: 
Minimal(M) = (Vq,q, cQ(q ~ q' ~? (q) #? (q'))) A Reachable(M) 
A general treatment ofautomata minimization can be found in Watson (1995). A formal 
proof of the correctness of the following algorithm can be found in Mihov (1998). 
3. Construct ion from Sorted Data 
A trie is a dictionary with a tree-structured transition graph in which the start state 
is the root and all leaves are final states. 2 An example of a dictionary in a form of a 
trie is given in Figure 1. We can see that many subtrees in the transition graph are 
isomorphic. The equivalent minimal dictionary (Figure 2) is the one in which only 
one copy of each isomorphic subtree is kept. This means that, pointers (edges) to 
all isomorphic subtrees are replaced by pointers (edges) to their unique representa- 
tive. 
The traditional method of obtaining a minimal dictionary is to first create a (not 
necessarily minimal) dictionary for the language and then minimize it using any one 
of a number of algorithms (again, see Watson \[1993b, 1995\] for numerous examples of 
such algorithms). The first stage is usually done by building a trie, for which there are 
fast and well-understood algorithms. Dictionary minimization algorithms are quite ef- 
ficient in terms of the size of their input dictionary--for some algorithms, the memory 
and time requirements are both linear in the number of states. Unfortunately, even such 
good performance is not sufficient in practice, where the intermediate dictionary (the 
trie) can be much larger than the available physical memory. (Some effort towards 
decreasing the memory requirement has been made; see Revuz \[1991\].) This paper 
presents a way to reduce these intermediate memory requirements and decrease the 
2 There may also be nonleaf, inother words interior, states that are final. 
Computational Linguistics Volume 26, Number 1 
Figure 1 
A trie whose language is the French regular endings of verbs of the first group. 
Figure 2 
The unique minimal dictionary whose language is the French regular endings of verbs of the 
first group. 
total construction time by constructing the minimal dictionary incrementally (word by 
word, maintaining an invariant of minimality), thus avoiding ever having the entire 
trie in memory. 
Daciuk, Mihov, Watson, and Watson Incremental Construction of FSAs 
The central part of most automata minimization algorithms is a classification 
of states. The states of the input dictionary are partitioned such that the equiva- 
lence classes correspond to the states of the equivalent minimal automaton. Assum- 
ing the input dictionary has only reachable states (that is, Reachable is true), we can 
deduce (by our alternative definition of minimality) that each state in the minimal 
dictionary must have a unique right language. Since this is a necessary and suffi- 
cient condition for minimality, we can use equality of right languages as the equiv- 
alence relation for our classes. Using our definition of right languages, it is easily 
shown that equality of right languages is an equivalence relation (it is reflexive, 
symmetric, and transitive). We will denote two states, p and q, belonging to the 
same equivalence class by p = q (note that = here is different from its use for log- 
ical equivalence of predicates). In the literature, this relation is sometimes written 
as E. 
To aid in understanding, letus traverse the trie (see Figure 1) with the postorder 
method and see how the partitioning can be performed. For each state we encounter, 
we must check whether there is an equivalent state in the part of the dictionary that 
has already been analyzed. If so, we replace the current state with the equivalent 
state. If not, we put the state into a register, so that we can find it easily. It follows 
that the register has the following property: it contains only states that are pairwise 
inequivalent. We start with the (lexicographically) first leaf, moving backward through 
the trie toward the start state. All states up to the first forward-branching state (state 
with more than one outgoing transition) must belong to different classes and we im- 
mediately place them in the register, since there will be no need to replace them by 
other states. Considering the other branches, and starting from their leaves, we need to 
know whether or not a given state belongs to the same class as a previously registered 
state. For a given state p (not in the register), we try to find a state q in the register 
that would have the same right language. To do this, we do not need to compare the 
languages themselves---comparing setsof strings is computationally expensive. We 
can use our recursive definition of the right language. State p belongs to the same 
class as q if and only if: 
. 
2. 
3. 
4. 
they are either both final or both nonfinal; and 
they have the same number of outgoing transitions; and 
corresponding outgoing transitions have the same labels; and 
corresponding outgoing transitions lead to states that have the same 
right languages. 
Because the postorder method ensures that all states reachable from the states al- 
ready visited are unique representatives of their classes (i.e., their right languages 
are unique in the visited part of the automaton), we can rewrite the last condition 
as :  
4'. corresponding transitions lead to the same states. 
If all the conditions are satisfied, the state p is replaced by q. Replacing p simply in- 
volves deleting it while redirecting all of its incoming transitions to q. Note that all 
Computational Linguistics Volume 26, Number 1 
leaf states belong to the same equivalence class. If some of the conditions are not sat- 
isfied, p must be a representative of a new class and therefore must be put into the 
register. 
To build the dictionary one word at a time, we need to merge the process of 
adding new words to the dictionary with the minimization process. There are two 
crucial questions that must be answered. First, which states (or equivalence classes) 
are subject o change when new words are added? Second, is there a way to add new 
words to the dictionary such that we minimize the number of states that may need to 
be changed uring the addition of a word? Looking at Figures 1 and 2, we can repro- 
duce the same postorder traversal of states when the input data is lexicographically 
sorted. (Note that in order to do this, the alphabet G must be ordered, as is the case 
with ASCII and Unicode). To process a state, we need to know its right language. Ac- 
cording to the method presented above, we must have the whole subtree whose root 
is that state. The subtree represents endings of subsequent (ordered) words. Further 
investigation reveals that when we add words in this order, only the states that need 
to be traversed to accept he previous word added to the dictionary may change when 
a new word is added. The rest of the dictionary remains unchanged, because a new 
word either 
begins with a symbol different from the first symbols of all words 
already in the automaton; the beginning symbol of the new word is 
lexicographically placed after those symbols; or 
it shares ome (or even all) initial symbols of the word previously added 
to the dictionary; the algorithm then creates a forward branch, as the 
symbol on the label of the transition must be later in the alphabet than 
symbols on all other transitions leaving that state. 
When the previous word is a prefix of the new word, the only state that is to be 
modified is the last state belonging to the previous word. The new word may share 
its ending with other words already in the dictionary, which means that we need to 
create links to some parts of the dictionary. Those parts, however, are not modified. 
This discovery leads us to Algorithm 1, shown below. 
Algorithm 1. 
Register := ~; 
do there is another word --* 
Word := next word in lexicographic order; 
CommonPrefix := common_prefix(Word); 
LastS tate := 6*(q0, CommonPrefix ) ; 
CurrentSuffix := Word\[length(CommonPrefix)+ l. . . length(Word)l; 
if has_children(LastState) --, 
replace ~r_register(Last S tate) 
fi; 
add_suffix(LastState, CurrentSuffix) 
od; 
replace_or_register(qo) 
8 
Daciuk, Mihov, Watson, and Watson Incremental Construction of FSAs 
func common_prefix(Word) 
return the longest prefix w of Word such that ~* (q0, w) ~ 3_ 
cnuf 
func replace_or_register(State) --~ 
Child := last_child(State); 
if has_children(Child) 
replace_or_register(Child) 
fi; 
if 3qEQ( q E Register A q = Child) --, 
last_child(State) :-- q: (q E Register A q = Child); 
delete(Child) 
else 
Register := Register U {Child} 
fi 
cnuf 
The main loop of the algorithm reads subsequent words and establishes which 
part of the word is already in the automaton (the CommonPrefix), and which is not 
(the CurrentSuffix). An  important step is determining what the last state (here called 
LastState) in the path of the common prefix is. If LastState already has children, it 
means that not all states in the path of the previously added word are in the path of 
the common prefix. In that case, by calling the function replace_or_register, we can let 
the minimization process work on those states in the path of the previously added 
word that are not in the common prefix path. Then we can add to the LastState a chain 
of states that would recognize the CurrentSuffix. 
The function common_prefix finds the longest prefix (of the word to be added) 
that is a prefix of a word already in the automaton. The prefix can be empty (since 
= q).  
The function add_suffix creates a branch extending out of the dictionary, which 
represents he suffix of the word being added (the maximal suffix of the word which 
is not a prefix of any other word already in the dictionary). The last state of this branch 
is marked as final. 
The function last_child returns a reference to the state reached by the lexicographi- 
cally last transition that is outgoing from the argument s ate. Since the input data is lex- 
icographically sorted, last_child returns the outgoing transition (from the state) most re- 
cently added (during the addition of the previous word). The function replace_or_register 
effectively works on the last child of the argument state. It is called with the argu- 
ment that is the last state in the common prefix path (or the initial state in the last 
call). We need the argument state to modify its transition in those instances in which 
the child is to be replaced with another (equivalent) state. Firstly, the function calls 
itself recursively until it reaches the end of the path of the previously added word. 
Note that when it encounters a state with more than one child, it takes the last one, 
as it belongs to the previously added word. As the length of words is limited, so is 
the depth of recursion. Then, returning from each recursive call, it checks whether a
state equivalent to the current state can be found in the register. If this is true, then 
the state is replaced with the equivalent state found in the register. If not, the state is 
registered as a representative of a new class. Note that the function replace-or_register 
processes only the states belonging to the path of the previously added word (a part, 
or possibly all, of those created with the previous call to add_suffix), and that those 
Computational Linguistics Volume 26, Number 1 
states are never reprocessed. Finally, has_children returns true if, and only if, there are 
outgoing transitions from the state. 
During the construction, the automaton states are either in the register or on the 
path for the last added word. All the states in the register are states in the resulting 
minimal automaton. Hence the temporary automaton built during the construction 
has fewer states than the resulting automaton plus the length of the longest word. 
Memory is needed for the minimized ictionary that is under construction, the call 
stack, and for the register of states. The memory for the dictionary is proportional 
to the number of states and the total number of transitions. The memory for the 
register of states is proportional to the number of states and can be freed once con- 
struction is complete. By choosing an appropriate implementation method, one can 
achieve a memory complexity O(n) for a given alphabet, where n is the number 
of states of the minimized automaton. This is an important advantage of our algo- 
rithm. 
For each letter from the input list, the algorithm must either make a step in the 
function common_prefix or add a state in the procedure add_suyqx. Both operations can 
be performed in constant time. Each new state that has been added in the procedure 
add~ufix has to be processed exactly once in the procedure replace_or_register. The num- 
ber of states that have to be replaced or registered is clearly smaller than the number 
of letters in the input list. 3 The processing of one state in the procedure consists of 
one register search and possibly one register insertion. The time complexity of the 
search is ?(log n),where n is the number of states in the (minimized) dictionary. The 
time complexity of adding a state to the register is also O(log n). In practice, however, 
by using a hash table to represent the register (and equivalence r lation), the average 
time complexity of those operations can be made almost constant. Hence the time 
complexity of the whole algorithm is 0(I log n), where l is the total number of letters 
in the input list. 
4. Construct ion from Unsorted Data 
Sometimes it is difficult or even impossible to sort the input data before constructing 
a dictionary. For example, there may be insufficient time or storage space to sort the 
data or the data may originate in another program or physical source. An incremental 
dictionary-building algorithm would still be very useful in those situations, although 
unsorted ata makes it more difficult o merge the trie-building and the minimization 
processes. We could leave the two processes disjoint, although this would lead to 
the traditional method of constructing a trie and minimizing it afterwards. A better 
solution is to minimize verything on-the-fly, possibly changing the equivalence classes 
of some states each time a word is added. Before actually constructing a new state 
in the dictionary, we first determine if it would be included in the equivalence class 
of a preexisting state. Similarly, we may need to change the equivalence classes of 
previously constructed states ince their right languages may have changed. This leads 
to an incremental construction algorithm. Naturally, we would want to create the states 
for a new word in an order that would minimize the creation of new equivalence 
classes. 
As in the algorithm for sorted data, when a new word w is added, we search 
for the prefix of w already in the dictionary. This time, however, we cannot assume 
3 The exact number of the states that are processed in the procedure replace-or_register is equal to the 
number of states in the trie for the input language. 
10 
Daciuk, Mihov, Watson, and Watson Incremental Construction of FSAs 
a \b 
Figure 3 
The result of blindly adding the word bae to a minimized ictionary (appearing on the left) 
containing abd and bad. The rightmost dictionary inadvertently contains abe as well. The lower 
dictionary is correct--state 3 had to be cloned. 
that the states traversed by this common prefix will not be changed by the addition 
of the word. If there are any preexisting states traversed by the common prefix that 
are already targets of more than one in-transition (known as confluence states), then 
blindly appending another transition to the last state in this path (as we would in the 
sorted algorithm) would accidentally add more words than desired (see Figure 3 for 
an example of this). 
To avoid generation of such spurious words, all states in the common prefix path 
from the first confluence state must be cloned. Cloning is the process of creating a new 
state that has outgoing transitions on the same labels and to the same destination states 
as a given state. If we compare the minimal dictionary (Figure 1) to an equivalent trie 
(Figure 2), we notice that a confluence state can be seen as a root of several original, 
isomorphic subtrees merged into one (as described in the previous section). One of 
the isomorphic subtrees now needs to be modified (leaving it no longer isomorphic), 
so it must first be separated from the others by cloning of its root. The isomorphic 
subtrees hanging off these roots are unchanged, so the original root and its clone have 
the same outgoing transitions (that is, transitions on the same labels and to the same 
destination states). 
In Algorithm 1, the confluence states were never traversed uring the search for 
the common prefix. The common prefix was not only the longest common prefix of the 
word to be added and all the words already in the automaton, it was also the longest 
common prefix of the word to be added and the last (i.e., the previous) word added to 
the automaton. As it was the function replace_or_register hat created confluence states, 
and that function was never called on states belonging to the path of the last word 
added to the automaton, those states could never be found in the common prefix 
path. 
Once the entire common prefix is traversed, the rest of the word must be appended. 
If there are no confluence states in the common prefix, then the method of adding the 
rest of the word does not differ from the method used in the algorithm for sorted 
data. However, we need to withdraw (from the register) the last state in the common 
prefix path in order not to create cycles. This is in contrast o the situation in the 
algorithm for sorted data where that state is not yet registered. Also, CurrentSuffix 
could be matched with a path in the automaton containing states from the common 
prefix path (including the last state of the prefix). 
11 
Computational Linguistics Volume 26, Number 1 
b 
C 
a d e a ~  
Figure 4 
Consider an automaton (shown in solid lines on the left-hand figure) accepting abcde and 
fghde. Suppose we want to add fgh@de. As the common prefix path (shown in thicker lines) 
contains a confluence state, we clone state 5 to obtain state 9, add the suffix to state 9, and 
minimize it. When we also consider the dashed lines in the left-hand figure, we see that state 
8 became a new confluence state earlier in the common prefix path. The right-hand figure 
shows what could happen if we did not rescan the common prefix path for confluence states. 
State 10 is a clone of state 4. 
When there is a confluence state, then we need to clone some states. We start with 
the last state in the common prefix path, append the rest of the word to that clone and 
minimize it. Note that in this algorithm, we do not wait for the next word to come, so 
we can minimize (replace or register the states of) CurrentSuffix state by state as they 
are created. Adding and minimizing the rest of the word may create new confluence 
states earlier in the common prefix path, so we need to rescan the common prefix path 
in order not to create cycles, as illustrated in Figure 4. Then we proceed with cloning 
and minimizing the states on the path from the state immediately preceding the last 
state to the current first confluence state. 
Another, less complicated but also less economical, method can be used to avoid 
the problem of creating cycles in the presence of confluence states. In that solution, we 
proceed from the state immediately preceding the confluence state towards the end of 
the common prefix path, cloning the states on the way. But first, the state immediately 
preceding the first confluence state should be removed from the register. At the end 
of the common prefix path, we add the suffix. Then, we call replace_or_register with the 
predecessor f the state immediately preceding the first confluence state. The following 
should be noted about this solution: 
memory requirements are higher, as we keep more than one isomorphic 
state at a time, 
the function replace_or_register must remain recursive (as in the sorted 
version), and 
the argument to replace_or_register must be a string, not a symbol, in 
order to pass subsequent symbols to children. 
When the process of traversing the common prefix (up to a confluence state) and 
adding the suffix is complete, further modifications follow. We must recalculate the 
equivalence class of each state on the path of the new word. If any equivalence class 
changes, we must also recalculate the equivalence classes of all of the parents of all 
of the states in the changed class. Interestingly, this process could actually make the 
new dictionary smaller. For example, if we add the word abe to the dictionary at the 
bottom of Figure 3 while maintaining minimality, we obtain the dictionary shown in 
12 
Daciuk, Mihov, Watson, and Watson Incremental Construction of FSAs 
the right of Figure 3, which is one state smaller. The result ing algor i thm is shown in 
A lgor i thm 2. 
A lgor i thm 2. 
Register := 0; 
do there is another word  --* 
Word := next word;  
CommonPrefix := common_prefix(Word); 
CurrentSuffix := Word\[length(CommonPrefix) + 1 ... length(Word)I; 
if CurrentSuffix = c A 6" (qo, CommonPrefix) E F --* 
continue 
fi; 
FirstState := first_state( CommonPrefix); 
if FirstState = 0 --* 
LastState := 6* (q0, CommonPrefix) 
else 
LastState := clone( 6* ( qo, CommonPrefix ) ) 
fi; 
add_suffix(LastState, CurrentSuffix); 
if FirstState ~ ~ --, 
FirstState := first~state(CommonPrefix); 
Currentlndex := (length(x): 6* (q0, x) = FirstState); 
for i from length(CommonPrefix) - 1 downto  Currentlndex --+ 
CurrentState := clone( 6* ( qo, CommonPrefix\[1. . . i\])); 
6( CurrentState, CommonPrefixli\]) := LastState; 
replace_or_register( CurrentState); 
LastState := CurrentState 
rof 
else 
Currentlndex := length( CommonPrefix) 
fi; 
Changed := true; 
do Changed 
Currentlndex := Currentlndex - 1; 
CurrentState := 6* (q0, Word\[1... Currentlndex\]); 
OldState := LastState; 
if Currentlndex > 0 --* 
Register := Register - {LastState} 
fi; 
replace_or_register( CurrentState); 
Changed := OldState ~ LastState 
od 
if ~Changed A Currentlndex > 0 --~ 
Register := Register U {CurrentState} 
fi 
od 
func replace Jar_register(State, Symbol) 
Child := 6(State, Symbol); 
if 3q E Q(q c Register A q = Child) 
13 
Computational Linguistics Volume 26, Number 1 
cnuf 
delete(Child); 
last_child(State) := q: (q E Register A q -- Child) 
else 
Register := Register u{Child} 
fi 
The main loop reads the words, finds the common prefix, and tries to find the 
first confluence state in the common prefix path. Then the remaining part of the word 
(CurrentSuf-fi'x) is added. 
If a confluence state is found (i.e., FirstState points to a state in the automaton), all 
states from the first confluence state to the end of the common prefix path are cloned, 
and then considered for replacement or registering. Note that the inner loop (with i as 
the control variable) begins with the penultimate state in the common prefix, because 
the last state has already been cloned and the function replace~r_register acts on a child 
of its argument state. 
Addition of a new suffix to the last state in the common prefix changes the right 
languages of all states that precede that state in the common prefix path. The last part 
of the main loop deals with that situation. If the change resulted in such modification 
of the right language of a state that an equivalent state can be found somewhere lse 
in the automaton, then the state is replaced with the equivalent one and the change 
propagates towards the initial state. If the replacement of a given state cannot take 
place, then (according to our recursive definition of the right language) there is no 
need to replace any preceding state. 
Several changes to the functions used in the sorted algorithm are necessary to 
handle the general case of unsorted ata. The replace~r_register procedure needs to be 
modified slightly. Since new words are added in arbitrary order, one can no longer 
assume that the last child (lexicographically) of the state (the one that has been added 
most recently) is the child whose equivalence class may have changed. However, we 
know the label on the transition leading to the altered child, so we use it to access that 
state. Also, we do not need to call the function recursively. We assume that add~uffix 
replaces or registers the states in the CurrentSuffix n the correct order; later we process 
one path of states in the automaton, starting from those most distant from the initial 
state, proceeding towards the initial state q0. So in every situation in which we call 
replace_or_register, all children of the state Child are already unique representatives of 
their equivalence classes. 
Also, in the sorted algorithm, add_suffix is never passed ~ as an argument, whereas 
this may occur in the unsorted version of the algorithm. The effect is that the LastState 
should be marked as final since the common prefix is, in fact, the entire word. In the 
sorted algorithm, the chain of states created by add_suffix was left for further treatment 
until new words are added (or until the end of processing). Here, the automaton is
completely minimized on-the-fly after adding a new word, and the function add~suffix 
can call replace_or_register fo each state it creates (starting from the end of the suffix). 
Finally, the new function first_state simply traverses the dictionary using the given 
word prefix and returns the first confluence state it encounters. If no such state exists, 
first_state returns 0. 
As in the sorted case, the main loop of the unsorted algorithm executes m times, 
where m is the number of words accepted by the dictionary. The inner loops are exe- 
cuted at most Iwl times for each word. Putting a state into the register takes O(logn), 
although it may be constant when using a hash table. The same estimation is valid 
14 
Daciuk, Mihov, Watson, and Watson Incremental Construction of FSAs 
for a removal from the register. In this case, the time complexity of the algorithm 
remains the same, but the constant changes. Similarly, hashing can be used to pro- 
vide an efficient method of determining the state equivalence classes. For sorted data, 
only a single path through the dictionary could possibly be changed each time a 
new word is added. For unsorted ata, however, the changes frequently fan out and 
percolate all the way back to the start state, so processing each word takes more 
time. 
4.1 Extending the Algorithms 
These new algorithms can also be used to construct transducers. The alphabet of the 
(transducing) automaton would be G1 x G2, where G1 and ~2 are the alphabet of 
the levels. Alternatively, elements of G~ can be associated with the final states of the 
dictionary and only output once a valid word from G~ is recognized. 
5. Related Work 
An algorithm described by Revuz \[1991\] also constructs a dictionary from sorted data 
while performing a partial minimization on-the-fly. Data is sorted in reverse order 
and that property is used to compress the endings of words within the dictionary as 
it is being built. This is called a pseudominimization a d must be supplemented by 
a true minimization phase afterwards. The minimization phase still involves finding 
an equivalence relation over all of the states of the pseudominimal dictionary. It is 
possible to use unsorted data but it produces a much bigger dictionary in the first 
stage of processing. However, the time complexity of the minimization can be reduced 
somewhat by using knowledge of the pseudominimization process. Although this 
pseudominimization technique is more economic in its use of memory than traditional 
techniques, we are still left with a subminimal dictionary that can be a factor of 8 times 
larger than the equivalent minimal dictionary (Revuz \[1991, page 33\], reporting on the 
DELAF dictionary). 
Recently, a semi-incremental lgorithm was described by Watson (1998) at the 
Workshop on Implementing Automata. That algorithm requires the words to be sorted 
in any order of decreasing length (this sorting process can be done in linear time), 
and takes advantage of automata properties imilar to those presented in this paper. 
In addition, the algorithm requires a final minimization phase after all words have 
been added. For this reason, it is only semi-incremental and does not maintain full 
minimality while adding words--although it usually maintains the automata close 
enough to minimality for practical applications. 
6. Conclusions 
We have presented two new methods for incrementally constructing a minimal, deter- 
ministic, acyclic finite-state automaton from a finite set of words (possibly with corre- 
sponding annotations). Their main advantage is their minimal intermediate memory 
requirements. 4 The total construction time of these minimal dictionaries is dramati- 
cally reduced from previous algorithms. The algorithm constructing a dictionary from 
sorted data can be used in parallel with other algorithms that traverse or utilize the 
dictionary, since parts of the dictionary that are already constructed are no longer 
subject o future change. 
4 It is minimal in asymptotic erms; naturally compact data structures can also be used. 
15 
Computational Linguistics Volume 26, Number 1 
Acknowledgments 
Jan Daciuk would like to express his 
gratitude to the Swiss Federal Scholarship 
Commission for providing a scholarship 
that made possible the work described here. 
Jan would also like to thank friends from 
ISSCO, Geneva, for their comments and 
suggestions on early versions of the 
algorithms given in this paper. 
Bruce Watson and Richard Watson 
would like to thank Ribbit Software 
Systems Inc. for its continued support in 
these fields of applicable research. 
All authors would like to thank the 
anonymous reviewers and Nanette Saes for 
their valuable comments and suggestions 
that led to significant improvements in the 
paper. 
References 
Daciuk, Jan, Bruce W. Watson, and 
Richard E. Watson. 1998. Incremental 
construction of minimal acyclic finite state 
automata nd transducers. In Proceedings 
of the International Workshop on Finite State 
Methods in Natural Language Processing, 
pages 48-56, Ankara, Turkey, 30 June-1 
July. 
Hopcroft, John E. and Jeffrey D. Ullman. 
1979. Introduction to Automata Theory, 
Languages, and Computation. 
Addison-Wesley, Reading, MA. 
Mihov, Stoyan. 1998. Direct building of 
minimal automaton for given list. In 
Annuaire de l'Universitd e Sofia "St. KI. 
Ohridski', volume 91, book 1, pages 38-40. 
Facult4 de Mathematique etInformatique, 
Sofia, Bulgaria, livre 1 edition, February. 
Available at http://lml.bas.bg/,-~stoyan/ 
publications.html. 
Moll, Robert N., Michael A. Arbib, and A. J. 
Kfoury. 1988. Introduction to Formal 
Language Theory. Springer Verlag, New 
York, NY. 
Revuz, Dominique. 1991. Dictionnaires et 
lexiques: mdthodes talgorithmes. Ph.D. 
thesis, Institut Blaise Pascal, Paris, France. 
LITP 91.44. 
Watson, Bruce W. 1993a. A taxonomy of 
finite automata construction algorithms. 
Computing Science Note 93/43, 
Eindhoven University of Technology, The 
Netherlands. Available at 
www.OpenFIRE.org. 
Watson, Bruce W. 1993b. A taxonomy of 
finite automata minimization algorithms. 
Computing Science Note 93/44, 
Eindhoven University of Technology, The 
Netherlands. Available at 
www.OpenFIRE.org. 
Watson, Bruce W. 1995. Taxonomies and 
Toolkits of Regular Language Algorithms. 
Ph.D. thesis, Eindhoven University of 
Technology, the Netherlands. Available at 
www.OpenFIRE.org. 
Watson, Bruce W. 1998. A fast new 
semi-incremental algorithm for 
construction of minimal acyclic DFAs. In 
Proceedings ofthe Third International 
Workshop on Implementing Automata, pages 
121-32, Rouen, France, 17-19 September. 
16 
c? 2004 Association for Computational Linguistics
Squibs and Discussions
Comments on ?Incremental Construction and
Maintenance of Minimal Finite-State
Automata,? by Rafael C. Carrasco and Mikel
L. Forcada
Jan Daciuk?
Gdan?sk University of Technology
In a recent article, Carrasco and Forcada (June 2002) presented two algorithms: one for incremental
addition of strings to the language of a minimal, deterministic, cyclic automaton, and one for
incremental removal of strings from the automaton. The first algorithm is a generalization of the
?algorithm for unsorted data??the second of the two incremental algorithms for construction
of minimal, deterministic, acyclic automata presented in Daciuk et al (2000). We show that the
other algorithm in the older article?the ?algorithm for sorted data??can be generalized in a
similar way. The new algorithm is faster than the algorithm for addition of strings presented in
Carrasco and Forcada?s article, as it handles each state only once.
1. Introduction
Carrasco and Forcada (2002) present two algorithms: one algorithm for incremental
addition of strings into a minimal, cyclic, deterministic, finite-state automaton, and
another for removal of strings from such an automaton. The algorithm for addition of
strings can be seen as an extension to cyclic automata of the algorithm for unsorted
data, the second algorithm in Daciuk et al (2000). It turns out that not only the al-
gorithm for unsorted data (the second algorithm in Daciuk et al [2000]), but also the
algorithm for sorted data (the first one in that article) can be extended in the same
way. That extension is presented in Section 3 of this article.
Carrasco and Forcada emphasize on-line maintainance of dictionaries. Their dictio-
naries are constantly updated. In a different model, dictionaries are mostly consulted
and are updated much less frequently. In such a model, it is more convenient to re-
build the dictionary off-line each time it is updated. By taking the process off-line, one
saves much memory, as certain structures needed for construction are not needed for
consultation, and other structures can be very efficiently compressed (Kowaltowski,
Lucchesi, and Stolfi 1993; Daciuk, 2000). The data for dictionaries can be kept sorted;
adding a few new (sorted) entries can be done in linear time. Although Carrasco and
Forcada?s string addition algorithm can be used in this particular model, an algorithm
specialized for sorted data can perform the construction process faster than its more
general equivalent.
The rest of the article is organized as follows. Section 2 introduces mathematical
preliminaries. Section 3 presents an incremental algorithm for addition of sorted strings
to a cyclic automaton. First, the role of a data structure called the register is explained
in detail in Section 3.1, then necessary modifications to the algorithm in Carrasco and
? Deptartment of Knowledge Engineering, Ul. G. Narutowicza 11/12, 80-952 Gdan?sk, Poland. E-mail:
jandac@eti.pg.gda.pl.
228
Computational Linguistics Volume 30, Number 2
Forcada (2002) are introduced in Section 3.2, and the final algorithm is presented in
Section 3.3. The algorithm is then analyzed in Section 4 and evaluated in Section 5.
Section 6 gives conclusions.
2. Mathematical Preliminaries
We define a deterministic finite-state automaton as M = (Q, ?, ?, q0, F), where Q is a
finite set of states, ? is a finite set of symbols called the alphabet, q0 ? Q is the start (or
initial) state, and F ? Q is a set of final (accepting) states. As in Carrasco and Forcada
(2002), we define ? : Q ?? ? Q as a total mapping. In other words, if the automaton
is not complete, that is, if ?q ? Q ? ?a ? ? : ?(q, a) ? Q, then an absorption state ? ? F
such that ?a ? ? : ?(?, a) = ? must be added to Q. A complete acyclic automaton
always has an absorption state. The extended mapping is defined as
??(q, ) = q
??(q, ax) = ??(?(q, a), x)
The right language of a state q is defined as
?
L (q) = {x ? ?? : ??(q, x) ? F}
The language of the automaton L(M) =
?
L (q0). The right language can be defined
recursively:
?
L (q) =
?
a??:?(q,a) =?
a?
?
L (?(q, a)) ?
{
{} if q ? F
? otherwise
Equality of right languages is an equivalence relation that partitions the set of
states into abstraction classes (equivalence classes). The minimal automaton is the
unique automaton (up to isomorphisms) that has the minimal number of states among
automata recognizing the same language. It is also the automaton in which all states
are useful (i.e., they are reachable from the start state, and from them a final state can
be reached), and each equivalence class has exactly one member.
The length of a string w ? ?? is denoted |w|, and the ith symbol (starting from
one) in the string w is denoted wi.
3. Incremental Addition of Sorted Strings
3.1 The Role of the Register
Carrasco and Forcada (2002) derive their algorithm for addition of strings from the
union of an automaton M = (Q, ?, ?, q0, F) with a single-string automaton Mw = (Qw, ?,
?w, q0w, Fw). In a single-string automaton, Qw = Pr(w) ? {?w}, where Pr(w) is the set
of all prefixes of w, which also serve as names of states, ?w is the absoption state,
Fw = {w}, and q0w = .
States in the automaton M? = M?Mw that is the result of the union can be divided
into four groups:
? Intact states of the form (q,?w) with q ? Q ? {?}, states that are not
affected by the union.
229
Daciuk Comments on Carrasco and Forcada
? Cloned states of the form (q, x) with q ? Q?{?} and x ? Pr(w) such that
??(q0, x) = q. All other states in (Q ? {?})? Pr(x) can be safely
discarded. The new initial state (q0, ) is a cloned state.
? Queue states of the form (?, x), with x ? Pr(w).
? The new absorption state ?? = (?,?w) ? F. It is present only if M has an
absoption state.
In Carrasco and Forcada, (2002), the algorithm for addition of strings proceeds by
minimizing the queue states and cloned states, arriving at the minimal automaton.
All states of M are put into a set called a register of states, which holds all unique
states in the automaton. States unreachable from the new initial state are removed
from the automaton and from the register. Then, starting from the states that are the
most distant from the initial state, queue states and cloned states are compared against
those in the register. If an equivalent state is found in the register, it replaces the state
under investigation. If not, the state under investigation is added to the register.
Before we go further, we have to look at the role of the register of states in greater
detail. It is explained in Daciuk et al (2000) and omitted in Carrasco and Forcada
(2002). Carrasco and Forcada do not have to examine the register closely, as they
clone all states that they call cloned states. Incremental construction consists of two
synchronized processes: One that adds new states, and another that minimizes the
automaton. In minimization, it is important to check whether two states are equivalent.
The Myhill-Nerode theorem tells us that two states are equivalent when they have the
same right languages. Computing right languages can take much time. However, what
we need to check is whether two states have the same right language, and not what
that language actually is. We can use the recursive definition of the right language.
If the target states of all outgoing transitions are unique in the automaton, that is, if
they are already in the register, then instead of comparing their right languages, we
can compare their identity (e.g., their addresses in memory). The assumption in the
previous statement can be made true by enforcing a particular order in which states
are compared against those in the register. When states are on a path representing a
finite string, they should be processed from the end of the string toward the beginning.
The queue states should be processed in that order. If an equivalent state is found
in the register, it replaces the current state. Otherwise, the current state is added to
the register.
The register can be organized as a hash table. Finality of the state, the number
of transitions, labels on transitions, and targets of transitions are treated together as a
key?an argument to a hash function. The register does not store right languages. It
stores pointers to states. If the right language of a state changes, the key of that state
does not have to. Therefore, we do not need to take a state out from the register and
put it back there if the key of the state does not change.
3.2 Necessary Modifications
We divide the set of cloned states into two groups: prefix states (up to, but excluding
the first state with more than one incoming transition) and the proper cloned states.
Proper cloned states are modified copies of other states. They are new states; they were
created by adding a new string. In Carrasco and Forcada (2002), the prefix states are
also cloned. However, it is usually not necessary to clone them (Carrasco and Forcada
mention that on page 215). They all change their right languages as the result of adding
a new string, but only the last prefix state (the most distant from the initial state) is
sure to change its transitions. Therefore, it should be removed from the register before
230
Computational Linguistics Volume 30, Number 2
adding a new string. Other prefix states should be removed from the register only if
they change their key features. This can happen only if the next prefix state in the path
is replaced by another state. In that case, the current prefix state is removed from the
register and reevaluated. If an equivalent state is found in the register, it replaces the
current state, and the previous prefix state should be considered. Otherwise the state
is put back into the register, and no further reevaluation is necessary.
If strings are added in an ordered way, the minimization process can be optimized
in the same way as in the ?sorted data algorithm,? the first algorithm described in
Daciuk et al (2000). We introduce two changes to the string addition algorithm in
Carrasco and Forcada (2002):
? Prefix states are not cloned when not necessary.
? States are never minimized (i.e., compared against the register and either
put there or replaced by other states) more than once.
The first modification is described above. The second one requires more explanation.
Let us consider an automaton in which no minimization takes place after a new string
has been added. That automaton has form of a trie. If a set of strings is lexicographically
sorted, then the paths in the automaton recognizing two consecutive strings w? and
w share some prefix states (at least the initial state, the root of the trie). We denote
the longest common prefix of w and w? as lcp(w, w?). If w? is a prefix of w, then all
states in the path recognizing w? are also in the path of w. Otherwise, there will be
states in the path recognizing w? that are not shared with the path recognizing w. Note
that no subsequent words will have these states in the common prefix path either, as
the shared initial part of paths of w? and subsequent words can only become shorter
because of sorting. Therefore, the states after lcp(w, w?) will never change their right
language, so they can be minimized without any further need of reevaluation. As soon
as we add w, we know which states in the path of w? can be minimized. Instead of a
trie, we keep a minimal automaton except for the path of the last string added to the
automaton.
If we start from scratch and add strings in the manner just described, proper
cloned states will never be created. Proper cloned states are created only when the
common prefix of two words contains states with more than one incoming transition.
Additional transitions coming to states are created when the states are in the register
and they are found to be equivalent to some other states. But the states can be put
into the register only when they are no longer in the common prefix path.
In case of a cyclic automaton, we do not start from scratch. There is an initial
(minimal) automaton that contains cycles. No new cycles are created by adding mere
strings one by one (as opposed to regular expressions, infinite sets of strings, etc.).
As the automaton already contains some strings, and it can contain states with more
than one incoming transition, proper cloned states can be created. However, no proper
cloned states will be created in the common prefix path, because the path recognizing
the previous string does not contain any states with more than one incoming transition.
3.3 The Algorithm
1: func build automaton;
2: R ? Q;
3: if (fanin(q0) > 0) then
4: q0 ? clone(q0);
5: fi;
231
Daciuk Comments on Carrasco and Forcada
6: w? ? ;
7: while ((w ? nextword) = ) do
8: p ? lcp(w, w?);
9: M ? minim path(M, w?, p);
10: M ? add suffix(M, w, p);
11: w? ? w;
12: end;
13: minim path(M, w?, q0);
14: if ?r ? R : equiv(r, q0) ?
15: delete q0; q0 ? r;
16: fi;
17: cnuf
18: func lcp(M, w, w?);
19: j ? max(i : ?k?j wk = wk?);
20: return w1 . . .wj;
21: cnuf
22: func minim path(M, w, p);
23: q ? ??(q0, p);
24: i ? |p|; j ? i;
25: while i ? |w| do
26: path[i ? j] ? q;
27: q ? ?(q, wi); i ? i + 1;
28: end;
29: path[i ? j] ? q;
30: while i > j do
31: if ?r ? R : equiv(r, q) then
32: ?(path[i ? j ? 1], wi?1) ? r;
33: delete q;
34: else
35: R ? R ? {q};
36: fi;
37: i ? i ? 1;
38: end;
39: return M;
40: cnuf
41: func add suffix(M, w, p);
42: q ? ??(q0, p);
43: i ? |p|+ 1;
44: while i ? |w| and ?(q, wi) = ? and fanin(?(q, wi)) ? 1 do
45: q ? ?(q, wi); R ? R ? {q}; i ? i + 1;
46: end;
47: while i ? |w| and ?(q, wi) = ? do
48: ?(q, wi) ? clone(?(q, wi));
49: q ? ?(q, wi); i ? i + 1;
50: end;
51: while i < |w| do
52: ?(q, wi) ? newstate;
53: q ? ?(q, wi); i ? i + 1;
232
Computational Linguistics Volume 30, Number 2
54: end;
55: F ? F ? {q};
56: return M;
57: cnuf
Function fanin(q) returns the number of incoming transition for a state q. If the
initial state has more than one incoming transition, it must be cloned (lines 3?5) to
prevent prepending of unwanted prefixes to words to be added. Function nextword
simply returns the next word in lexicographical order from the input, or  if there are
no more words. Function lcp (lines 18?21) returns the longest common prefix of two
words. It is called with the last string added to the automaton and the string to be
added to the automaton as the arguments. For the first string, the previous string is
empty. Function minim path (lines 22?40) minimizes that part of the path recognizing
the string previously added to the automaton that is not in the longest common prefix.
This is done by going to the back of the path representing the string (lines 23?29) and
checking the states one by one starting from the last state in the path (lines 30?38).
The register is represented as variable R.
While function minim path is not much different from an analogical function for
the acyclic case, function add suffix (lines 41?57) does introduce some new elements. It
resembles more closely a similar function from the algorithm for unsorted data (Daciuk
et al 2000). The longest prefix common to the string to be added and the last string
added to the automaton is not necessarily the same as the longest prefix common to
the string to be added to the automaton and all strings already in the automaton. The
latter can be longer, and the path recognizing it may contain states with more than
one incoming transition. Those states have to be cloned (lines 47?50).
4. Analysis
The algorithm correctly adds new strings to the automaton, while maintaining its
minimality. We assume that all states in the initial automaton are in the register, that
there are no pairs of states with the same right language, that all states are reachable
from the initial state, and that there is a path from every state to one of the final states.
The absorption state and transitions that lead to it are not explicitly represented.
To prove that the algorithm is correct, we need to show that
1. the language of the automaton after the addition of the string contains
that string;
2. no other strings are added to the automaton;
3. no strings are removed from the automaton;
4. the automaton remains minimal except for the path of the newly added
string, that is, the states covered by the path of the newly added string
are representatives of the only equivalence classes that may have more
than one member.
It is easy to show that strings are indeed added to the language of the automaton.
First, transitions with subsequent symbols from the strings are followed from the initial
state. When there are no transitions with appropriate symbols, new ones are created.
The state reachable with the string is made final. Minimization done by minim path
233
Daciuk Comments on Carrasco and Forcada
replaces states with other states that have the same right language. That operation
does not change the language of the automaton.
If the initial state has any incoming transitions, it is cloned, and the clone becomes
the new initial state. That operation does not change the language of the automaton?
the right language of the new initial state is exactly the same as of the old one. The
old initial state is still reachable, because it has incoming transitions from either the
new initial state (the old initial state had a loop) or other states that are reachable. The
cloning creates a new state that is not in the register and that is equivalent to another
state in the automaton. Lines 14?16 of the algorithm check whether after addition of
new strings, the new initial state is equivalent to some other state in the automaton.
If it is, the new initial state is replaced with the equivalent state.
Since the automaton is deterministic, it cannot hold more than one copy of the
same string. Therefore, we need only to show that no other strings are erroneously
added to the automaton. Such erroneous addition could happen by creating or redi-
recting transitions. New transitions are created to store some suffixes of new strings
that are not present in the automaton. This could lead to addition of new, superflous
strings, provided the states that to which we add transitions are reentrant/confluence.
However, the algorithm excludes such cases. All states in the path of the previously
added string have only one incoming transition. All reentrant/confluence states not in
the longest common prefix path are cloned in line 48 of function add suffix. Function
minim path can redirect transitions only to states not in the longest common prefix
path.
Since states that are deleted in line 33 in function minim path (the only place in
the algorithm where states are deleted) are always replaced as targets of transitions
by equivalent states, strings could be deleted from the automaton only by making
parts of it unreachable. However, all targets of transitions going out from a state to be
deleted go to states that have more than one incoming transition?states that replaced
previous targets of those transitions. This includes the case of states with no outgoing
transitions.
To show that the automaton remains minimal except for the path of the newly
added string, we first note that all existing states are in the register before we start
adding new strings. Adding a new string creates a single chain of states not in the
register. The chain is added in its entirety with function add suffix, as the ?previous?
string for the first string is assumed to be empty. If w is the string to be added, and
?i>0?q?Q ??(q0, w1 ? ? ?wi) = ?, then non-reentrant states not following any reentrant
states in the path from q0 to q are removed from the register, and reentrant states (and
states that follow them) are cloned. For wi+1 ? ? ?w|w|, new states and transitions are
created. This concludes forming a path for the first string. That path consists entirely
of states that are not in the register and that can have an equivalent state somewhere
in the rest of the automaton.
When next strings are added, they are divided into two parts by function lcp.
It divides both the previous and the next string. The first part (the longest common
prefix) is shared between the previous and the next string, and it remains outside the
register. This also means that for each state in that part, there may be an equivalent
state in the remaining part of the automaton. The second part of the next string will
form the rest of the path of states outside the register. The second part of the path of the
previous string will be subject to minimization, as no further outgoing transitions will
be added to any of its states in the future. Minimization replaces with their equivalent
states those states in the path of the suffix of the previous string that are not unique.
Since minimization is performed from the end of the string toward the longest common
prefix, we can use the register and compare the states using the recursive definition
234
Computational Linguistics Volume 30, Number 2
of the right language, replacing right languages of target states with their addresses.
At the end of the process, we have an automaton that is minimal except for the path
of the last string added to it. We return to the start situation.
The algorithm has the same asymptotic complexity as the corresponding algo-
rithms in Carrasco and Forcada (2002) and Daciuk et al (2000). However, it is faster
than algorithms for unsorted data, because it does not have to reprocess the states
over and over again. Each time the original algorithm clones a state, that state is re-
processed. Cloning in the new version is limited to the part of the automaton built
before addition of new strings. No state created by the algorithm is cloned afterward.
5. Evaluation
Two experiments have been performed to compare the new algorithm with the algo-
rithm for adding strings to a minimal, deterministic, cyclic automaton presented in
Carrasco and Forcada (2002). In both experiments, a cyclic automaton was created. It
recognized any sequence of words from one set and any word from another set. The
first set was used to construct an initial cyclic automaton recognizing any sequence of
words from the first set. Then the second set was used to measure the relative speed
of the algorithms being compared. In the first experiment, the first set consisted of
German words beginning with Latin letters from A to M, and the second set consisted
of German words beginning with letters from N to Z. This was the ?easier? task, since
only the initial state of the automaton had to be cloned. In the second experiment,
odd-numbered German words beginning with letters A to Z formed the first set, and
even-numbered ones, the second set. In this task, many paths in the automaton were
shared between words from both sets. A total of 69,669 German words were used in
the experiments.
In the first experiment, the new algorithm was 4.96 times faster, and in the second
one, 2.53. Most of the speedup was not the result of using an algorithm optimized
for sorted data?an improvement to the algorithm for adding strings in Carrasco
and Forcada (2002) consisting in avoiding unnecessary cloning of prefix states (as
described in section 3.2 and mentioned on page 215 in Carrasco and Forcada [2002] as
a suggestion from one of Carrasco and Forcada?s reviewers) was 3.12 and respectively
2.35 times faster than the original algorithm. However, the new algorithm is still the
fastest.
6. Conclusions
An algorithm for adding strings to a cyclic automaton has been presented. It is faster
than the algorithm for adding strings presented in Carrasco and Forcada (2002), but
it operates on sorted input data. The new algorithm is a generalized version of the
first algorithm presented in Daciuk et al (2000). The relation between the algorithm
presented here and the first algorithm in Daciuk et al (2000) is the same as that
between the algorithm for adding strings in Carrasco and Forcada (2002) and the
second algoritm in Daciuk et al (2000).
Acknowledgments
This research was carried out within the
framework of the PIONIER Project
Algorithms for Linguistic Processing,
funded by NWO (Dutch Organization for
Scientific Research) and the University of
Groningen. The author wishes to thank the
anonymous reviewers for valuable
suggestions and corrections.
235
Daciuk Comments on Carrasco and Forcada
References
Carrasco, Rafael C. and Mikel L. Forcada.
2002. Incremental construction and
maintenance of minimal finite-state
automata. Computational Linguistics, 28(2):
207?216.
Daciuk, Jan. 2000. Experiments with
automata compression. In M. Daley, M. G.
Eramian, and S. Yu, editors, Conference on
Implementation and Application of Automata
(CIAA?2000), pages 113?119, London,
Ontario, Canada, July.
Daciuk, Jan, Stoyan Mihov, Bruce Watson,
and Richard Watson. 2000. Incremental
construction of minimal acyclic finite state
automata. Computational Linguistics,
26(1):3?16.
Kowaltowski, Tomasz, Cla?udio L. Lucchesi,
and Jorge Stolfi. 1993. Minimization of
binary automata. In First South American
String Processing Workshop, Belo Horizonte,
Brazil.
