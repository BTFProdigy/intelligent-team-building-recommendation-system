Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 305?310,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Towards Tracking Semantic Change by Visual Analytics
Christian Rohrdantz1 Annette Hautli2 Thomas Mayer2
Miriam Butt2 Daniel A. Keim1 Frans Plank2
Department of Computer Science1 Department of Linguistics2
University of Konstanz
Abstract
This paper presents a new approach to detect-
ing and tracking changes in word meaning by
visually modeling and representing diachronic
development in word contexts. Previous stud-
ies have shown that computational models
are capable of clustering and disambiguat-
ing senses, a more recent trend investigates
whether changes in word meaning can be
tracked by automatic methods. The aim of our
study is to offer a new instrument for inves-
tigating the diachronic development of word
senses in a way that allows for a better under-
standing of the nature of semantic change in
general. For this purpose we combine tech-
niques from the field of Visual Analytics with
unsupervised methods from Natural Language
Processing, allowing for an interactive visual
exploration of semantic change.
1 Introduction
The problem of determining and inferring the sense
of a word on the basis of its context has been the
subject of quite a bit of research. Earlier investiga-
tions have mainly focused on the disambiguation of
word senses from information contained in the con-
text, e.g. Schu?tze (1998) or on the induction of word
senses (Yarowsky, 1995). Only recently, the field
has added a diachronic dimension to its investiga-
tions and has moved towards the computational de-
tection of sense development over time (Sagi et al,
2009; Cook and Stevenson, 2010), thereby comple-
menting theoretical investigations in historical lin-
guistics with information gained from large corpora.
These approaches have concentrated on measuring
general changes in the meaning of a word (e.g., nar-
rowing or pejoration), whereas in this paper we deal
with cases where words acquire a new sense by ex-
tending their contexts to other domains.
For the scope of this investigation we restrict our-
selves to cases of semantic change in English even
though the methodology is generally language in-
dependent. Our choice is on the one hand moti-
vated by the extensive knowledge available on se-
mantic change in English. On the other hand, our
choice was driven by the availability of large cor-
pora for English. In particular, we used the New
York Times Annotated Corpus.1 Given the variety
and the amount of text available, we are able to track
changes from 1987 until 2007 in 1.8 million news-
paper articles.
In order to be able to explore our approach in a
fruitful manner, we decided to concentrate on words
which have acquired a new dimension of use due
to the introduction of computing and the internet,
e.g., to browse, to surf, bookmark. In particular,
the Netscape Navigator was introduced in 1994 and
our data show that this does indeed correlate with a
change in use of these words.
Our approach combines methods from the fields
of Information Visualization and Visual Analyt-
ics (Thomas and Cook, 2005; Keim et al, 2010)
with unsupervised techniques from Natural Lan-
guage Processing (NLP). This combination provides
a novel instrument which allows for tracking the di-
achronic development of word meaning by visual-
izing the contexts in which the words occur. Our
overall aim is not to replace linguistic analysis in
1http://http://www.ldc.upenn.edu/
305
this field with an automatic method, but to guide re-
search by generating new hypotheses about the de-
velopment of semantic change.
2 Related work
The computational modeling of word senses is based
on the assumption that the meaning of a word can
be inferred from the words in its immediate con-
text (?context words?). Research in this area mainly
focuses on two related tasks: Word Sense Disam-
biguation (WSD) and Word Sense Induction (WSI).
The goal of WSD is to classify occurrences of pol-
ysemous words according to manually predefined
senses. One popular method for performing such
a classification is Latent Semantic Analysis (LSA)
(Deerwester et al, 1990), with other methods also
suitable for the task (see Navigli (2009) for an ex-
tensive survey).
The aim of WSI is to learn word senses from
text corpora without having a predefined number of
senses. This goal is more difficult to achieve, as it
is not clear beforehand how many senses should be
extracted and how a sense could be described in an
abstract way. Recently, however, Brody and Lapata
(2009) have shown that Latent Dirichlet Allocation
(LDA) (Blei et al, 2003) can be successfully applied
to perform word sense induction from small word
contexts.
The original idea of LSA and LDA is to learn ?top-
ics? from documents, whereas in our scenario word
contexts rather than documents are used, i.e., a small
number of words before and after the word under
investigation (bag of words). Sagi et al (2009)
have demonstrated that broadening and narrowing
of word senses can be tracked over time by applying
LSA to small word contexts in diachronic corpora.
In addition, we will use LDA, which has proven even
more reliable in the course of our investigations.
In general, the aim of our paper is to go beyond
the approach of Sagi et al (2009) and analyze se-
mantic change in more detail. Ideally, a starting
point of change is found and the development over
time can be tracked, paired with a quantitative com-
parison of prevailing senses. We therefore suggest
to visualize word contexts in order to gain a better
understanding of diachronic developments and also
generate hypotheses for further investigations.
3 An interactive visualization approach to
semantic change
In order to test our approach, we opted for a large
corpus with a high temporal resolution. The New
York Times Annotated Corpus with 1.8 million
newspaper articles from 1987 to 2007 has a rather
small time depth of 20 years but provides a time
stamp for the exact publication date. Therefore,
changes can be tracked on a daily basis.
The data processing involved context extraction,
vector space creation, and sense modeling. As
Schu?tze (1998) showed, looking at a context win-
dow of 25 words before and after a key word pro-
vides enough information in order to disambiguate
word senses. Each extracted context is comple-
mented with the time stamp from the corpus. To
reduce the dimensionality, all context words were
lemmatized and stop words were filtered out.
For the set of all contexts of a key word, a global
LDA model was trained using the MALLET toolkit2
(McCallum, 2002). Each context is assigned to its
most probable topic/sense, complemented by a spe-
cific point on the time scale according to its time
stamp from the corpus. Contexts for which the high-
est probability was less than 40% were omitted be-
cause they could not be assigned to a certain sense
unambiguously. The distribution of senses over time
was then visualized.
3.1 Visualization
Different visualizations provide multidimensional
views on the data and yield a better understanding
of the developments. While plotting every word oc-
currence individually offers the opportunity to detect
and inspect outliers, aggregated views on the data
are able to provide insights on overall developments.
Figure 1 provides a view where the percentages of
word contexts belonging to different senses are plot-
ted over time. For the verbs to browse and to surf
seven senses are learned with LDA. Each sense cor-
responds to one row and is described by the top five
terms identified by LDA. The higher the gray area
at a certain x-axis point, the more of the contexts of
the corresponding year belong to the specific sense.
Each shade of gray represents 10% of the overall
data, i.e., three shades of gray mean that between
2http://mallet.cs.umass.edu/
306
to browse to surf
time, library, 
student, music, 
people
shop, street, 
book, store, art
book, read, 
bookstore, find, 
year
deer, plant, 
tree, garden, 
animal
software, microsoft, 
internet, netscape, 
windows
web, internet, 
site, mail , 
computer
store, shop, 
buy, day, 
customer
sport, wind, 
water, ski, offer
wave, surfer, 
board, year, 
sport
channel,  
television, 
show, watch, tv
web, internet, 
site, computer, 
company
film, boy, 
movie, show, 
ride
year, day, time, 
school, friend
beach, wave, 
surfer, long, 
coast
a
b
c
d
e
f
g
h
i
j
k
l
m
n
Figure 1: Temporal development of different senses concerning the verbs to browse (left) and to surf (right)
20% and 30% of the contexts can be attributed to
that sense. For each year one value has been gener-
ated and values between two years are linearly inter-
polated.
Figure 2 shows the development of contexts over
time, with each context plotted individually. The
more recent the context, the darker the color.3 Each
axis represents one sense of to browse, in each sub-
figure different combinations of senses are plotted.
A random jitter has been introduced to avoid over-
laps. Contexts in the middle (not the lower left cor-
ner, but the middle of the graph, e.g., see e vs. f)
belong to both senses with at least 40% probabil-
ity. Senses that share many ambiguous contexts are
usually similar. By mousing over a colored dot, its
context is shown, allowing for an in depth analysis.
3.2 Case studies
In order to be able to judge the effectiveness of our
new approach, we chose key words that are likely
candidates for a change in use in the time from 1987
to 2007. That is, we concentrated on terms relat-
ing to the relatively recent introduction of the inter-
net. The advantage of these terms is that the cause
of change can be located precisely in time.
Figure 1 shows the temporal sense development
of the verbs to browse and to surf, together with
the descriptive terms for each sense. Sense e for to
3The pdf version of this paper contains a bipolar color map.
browse and sense k for to surf pattern quite similarly.
Inspecting their contexts reveals that both senses ap-
pear with the invention of web browsers, peaking
shortly after the introduction of Netscape Navigator
(1994). For to browse, another broader sense (sense
f) concerning browsing in both the internet and dig-
ital media collections shows a continuous increase
over time, dominating in 2007.
The first occurrences assigned to sense f in 1987
are ?browse data bases?, ?word-by-word brows-
ing? in databases and ?browsing files in the cen-
ter?s library?, referring to physical files, namely pho-
tographs. We speculate that the sense of browsing
physical media might haven given rise to the sense
which refers to browsing electronic media, which in
turn becomes the dominating sense with the advent
of the web.
Figure 2 shows pairwise comparisons of word
senses with respect to the contexts they share, i.e.,
contexts that cannot unambiguously be assigned to
one or the other. Each context is represented by
one dot colored according to its time stamp. It can
be seen that senses d (animals that browse) and e
(browsing the web) share no contexts at all. Senses
d (animals that browse) and f (browsing files) share
only few contexts. In turn, senses e and f share a
fair number of contexts, which is to be expected, as
they are closely related. Single contexts, each rep-
resented by a colored dot, can be inspected via a
307
Figure 2: Pairwise comparisons of different senses for the verb ?to browse?. In each subfigure different combinations
of LDA dimensions are mapped on the axes.
LSA dimensions
1 web 0.40, internet 0.38, software 0.36, microsoft 0.28, win-
dows 0.18
2 microsoft 0.24, software 0.23, windows 0.13, internet 0.13,
netscape 0.12
3 microsoft 0.27, store 0.22, shop 0.20, windows 0.19, software
0.16
4 shop 0.32, netscape 0.23, web 0.23, store 0.19, software 0.19
5 book 0.48, netscape 0.26, software 0.17, world 0.13, commu-
nication 0.12
6 internet 0.58, shop 0.25, service 0.16, computer 0.13, people
0.11
7 make 0.39, shop 0.34, site 0.16, windows 0.13, art 0.08
... ...
15 find 0.30, people 0.22, year 0.19, deer 0.16, day 0.15
Table 1: Descriptive terms for the top LSA dimensions for
the contexts of to browse. For each dimension the top 5
positively associated terms were extracted, together with
their value in the corresponding dimension.
mouse roll over. This allows for an in-depth look at
specific data points and a better understanding how
the data points relate to a sense.
3.3 LSA vs. LDA
In comparison, Table 1 shows the LSA dimensions
learned from the contexts of the verb to browse. The
top five associated terms for each dimension have
been extracted as descriptor. The dimensions are
heavily dominated by senses strongly represented
in the corpus (e.g., browsing the web). Infrequent
senses (e.g., animals that browse) only occur in very
low-ranked dimensions and are mixed with other
senses (see the bold term deer in dimension 15).
4 Evaluation
We compared the findings provided by our visual-
ization with word sense information coming from
various resources, namely the 2007 Collins dictio-
nary (COLL), the English WordNet4 (WN) (Fell-
baum, 1998) and the Longman Dictionary (LONG)
from 1987. Senses that evolved later than 1987
should not appear in LONG, but should appear in
later dictionaries.
However, we are well aware that dictionaries are
by no means good gold standards as lexicogra-
phers themselves vary greatly when assigning word
senses. Nevertheless, this comparison can provide a
first indication as to whether the results of our tool
is in line with other methods of identifying senses.
In the case of to browse, COLL and WordNet
suggest the senses ?shopping around; not necessar-
ily buying?, ?feed as in a meadow or pasture? and
?browse a computer directory, surf the internet or the
world wide web.? These senses are also identified in
our visualizations, which even additionally differen-
tiate between the senses of ?browsing the web? and
?browsing a computer directory.? A WordNet sense
that cannot be detected in the data is the meaning ?to
eat lightly and try different dishes.?
Table 2 shows the results of comparing dictionary
word senses (DIC) with the results from our visual-
ization (VIS). What can be seen is that our method
is able to track semantic change diachronically and
4http://wordnetweb.princeton.edu
308
to browse to surf messenger bug bookmark
# of word senses # of word senses # of word senses # of word senses # of word senses
DIC VIS DIC VIS DIC VIS DIC VIS DIC VIS
1987 (LONG) 2 3 1 1 1 2 6 3 1 1
1998 (WN) 5 4 3 3 1 3 5 3 1 2
2007 (COLL) 3 4 3 2 1 3 5 3 2 2
Table 2: A comparison of different word senses as given in dictionaries with the visualization results across time
in the majority of cases, the number of our senses
correspond to the information coming from the dic-
tionaries. In some cases we are even more accurate
in discriminating them. In the case of ?messenger?,
the visualizations suggest another sense related to
?instant messaging? that arises with the advent of
the AOL instant messenger in 1997. This leads us to
the conclusion that our method is appropriate from a
historical linguistic point of view.
5 Discussion and conclusions
When dealing with a complex phenomenon such as
semantic change, one has to be aware of the limita-
tions of an automatic approach in order to be able
to draw the right conclusions from its results. The
first results of the case studies presented in this pa-
per show that LDA is useful for distinguishing dif-
ferent word senses on the basis of word contexts and
performs better than LSA for this task. Further, it
has been demonstrated by exemplary cases that the
emergence of a new word sense can be detected by
our new methodology
One of the main reasons for an interactive visu-
alization approach is the possibility of being able to
detect conspicuous patterns at-a-glance, yet at the
same time being able to delve into the details of the
data by zooming in on the occurrences of particu-
lar words in their contexts. This makes it possible
to compensate for one of the major disadvantages
of generative and vector space models, namely their
functioning as ?black boxes? whose results cannot
be tracked easily.
The biggest problem in dealing with a corpus-
based method of detecting meaning change is the
availability of suitable corpora. First, computing se-
mantic information on the basis of contexts requires
a large amount of data in order to be able to infer re-
liable results. Second, the words in the context from
which the meanings will be distinguished should be
both semantically and orthographically stable over
time so that comparisons between different stages in
the development of the language can be made. Un-
fortunately, both requirements are not always met.
On the one hand words do change their meaning,
after all this is what the present study is all about.
However, we assume that the meanings in a certain
context window are stable enough to infer reliable
results provided it is possible that the forms of the
same words in different periods can be linked. This
of course limits the applicability of the approach to
smaller time ranges due to changes in the phonetic
form of words. Moreover, in particular for older pe-
riods of the language, different variants for the same
word, either due to sound changes or different (or
rather no) spelling conventions, abound. For now,
we circumvent this problem by testing our tool on
corpora where the drawbacks of historical texts are
less severe but at the same time interesting develop-
ments can be detected to prove our approach correct.
For future research, we want to test our methodol-
ogy on a broader range of terms, texts and languages
and develop novel interactive visualizations to aid
investigations in two ways. As a first aim, the user
should be allowed to check the validity and quality
of the visualizations by experimenting with param-
eter settings and inspecting their outcome. Second,
the user is supposed to gain a better understanding of
semantic change by interactively exploring a corpus.
Acknowledgments
This work has partly been funded by the Research
Initiative ?Computational Analysis of Linguistic
Development? at the University of Konstanz and by
the German Research Society (DFG) under the grant
GK-1042, Explorative Analysis and Visualization of
Large Information Spaces, Konstanz. The authors
would like to thank Zdravko Monov for his program-
ming support.
309
References
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet alocation. Journal of Machine
Learning Research, 3:993?1022.
Samuel Brody and Mirella Lapata. 2009. Bayesian word
sense induction. In Proceedings of the 12th Con-
ference of the European Chapter of the Association
for Computational Linguistics, EACL ?09, pages 103?
111, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Paul Cook and Suzanne Stevenson. 2010. Automati-
cally Identifying Changes in the Semantic Orientation
of Words. In Proceedings of the Seventh conference
on International Language Resources and Evaluation
(LREC?10), pages 28?34, Valletta, Malta.
Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by latent semantic analysis. Journal of the
American Society for Information Science, 41:391?
407.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, MA.
Daniel A. Keim, Joern Kohlhammer, Geoffrey Ellis, and
Florian Mansmann, editors. 2010. Mastering The In-
formation Age - Solving Problems with Visual Analyt-
ics. Goslar: Eurographics.
Andrew Kachites McCallum. 2002. MALLET:
A Machine Learning for Language Toolkit.
http://mallet.cs.umass.edu.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACMComputing Surveys (CSUR), 41(2):1?69.
Eyal Sagi, Stefan Kaufmann, and Brady Clark. 2009.
Semantic Density Analysis: Comparing Word Mean-
ing across Time and Phonetic Space. In Proceedings
of the EACL 2009 Workshop on GEMS: GEometical
Models of Natural Language Semantics, pages 104?
111, Athens, Greece.
Hinrich Schu?tze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97?123.
James J. Thomas and Kristin A. Cook. 2005. Illuminat-
ing the Path The Research and Development Agenda
for Visual Analytics. National Visualization and Ana-
lytics Center.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In Proceed-
ings of the 33rd annual meeting on Association for
Computational Linguistics (ACL ?95), pages 189?196,
Cambridge, Massachusetts.
310
Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 70?78,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
Consonant Co-occurrence in Stems Across Languages: Automatic
Analysis and Visualization of a Phonotactic Constraint
Thomas Mayer1, Christian Rohrdantz2, Frans Plank1,
Peter Bak2, Miriam Butt1, Daniel A. Keim2
1Department of Linguistics, 2Department of Computer Science
University of Konstanz, Germany
{thomas.mayer,christian.rohrdantz}@uni-konstanz.de
Abstract
In this paper, we explore the phenomenon
of Similar Place Avoidance (SPA), ac-
cording to which successive consonants
within stems sharing the same place of
articulation are avoided. This principle
has recently been hypothesized as a uni-
versal tendency although evidence from
only a few languages scattered across the
world has been considered. Using meth-
ods taken from the field of Visual Analyt-
ics, which have demonstrably been shown
to help with understanding complex in-
teractions across large data sets, we in-
vestigated a large crosslinguistic lexical
database (comprising data on more than
4,500 languages) and found that a univer-
sal tendency can indeed be maintained.
1 Introduction
Linguistic knowledge has traditionally been ac-
quired by analyzing a manageable set of data, on
the basis of which generalizations are posited that
can then be tested on an extended set of data from
the same language or comparative data from other
languages. Tendencies, rather than absolute prin-
ciples, are difficult to detect under this approach.
This is true especially when they are obscured by
counterexamples that happen to occur with high
frequency, but that may be restricted to just a
small minority of the overall pattern. This may
prompt a researcher to discard a valid generaliza-
tion from the outset. In recent years, a plethora of
statistical and stochastic methods have therefore
been pursued within linguistic research, leading to
approaches such as stochastic Optimality Theory
(Boersma and Hayes, 2001) or the use of statis-
tics to detect crosslinguistic tendencies (Bickel, in
press).
However, although the various statistical meth-
ods deal with data which exhibit very complex and
often ill-understood interactions, analyses have
not to date availed themselves of methodology
currently being developed in the field of Visual
Analytics, which allows us to use our powerful vi-
sual processing ability to understand and evaluate
complex data sets (Keim et al, 2008; Thomas and
Cook, 2005).
In this paper, we present an interdisciplinary
effort whereby linguistically interesting patterns
are automatically extracted, analyzed and visually
presented so that an at-a-glance evaluation of lin-
guistically significant patterns is made possible. In
order to demonstrate that this technique is espe-
cially useful with phenomena that do not mani-
fest themselves in absolute principles, but rather
in statistical tendencies, we investigated a phe-
nomenon that, on the basis of a comparatively
sparse and unrepresentative data set, has recently
been claimed to be a universal tendency (Pozdni-
akov and Segerer, 2007): Similar Place Avoidance
(SPA). In this paper, we conduct a more represen-
tative study of about 4,500 languages. Our results
allow an at-a-glance evaluation which shows that
SPA indeed seems to be a valid language universal
tendency.
Our work on SPA is part of a more widespread
effort currently being conducted with respect to vi-
sually representing crosslinguistic sound patterns.
In Rohrdantz et al (2010), we already showed that
phonological patterns in languages can be auto-
matically extracted and visualized from corpora.
Figure 1 displays the vowel harmony patterns that
were extracted for Turkish in comparison with the
lack of such patterns in a non-harmonic language
like Spanish.
The remainder of this article is organized as fol-
lows. Section 2 introduces SPA. Section 3 pro-
vides an overview of the material that was used. A
description of the calculations and statistical anal-
yses is given in Section 4. Section 5 presents
the results of the geo-spatial visualizations, partly
70
Figure 1: Turkish vowel harmony patterns (left).
The matrix visualizaton was generated on the
basis of the Turkish Bible text and shows the
palatal (front/back) and labial (rounding) harmony
blocks. Rows and columns are automatically
sorted according to the similarity of vowels. For
non-harmonic languages, such as Spanish (right),
no such patterns can be detected.
with respect to a WALS map (Haspelmath et al,
2005). In the final section, we consider some im-
plications of our findings and raise some questions
for future research.
2 Similar Place Avoidance (SPA)
It has long been noted in studies on Semitic lan-
guages, especially Arabic, that there are con-
straints on the structure of triliteral consonant
roots (
?
CCC) with respect to the phonological
features of the individual consonants (Greenberg,
1950). The basic observation is that consonants
with a similar place of articulation are avoided
in non-derived forms. A similar observation has
also been made with respect to the Proto-Indo-
European (PIE) roots. Among other things, Iver-
son and Salmons (1992) note that Stop-V-Stop
roots were very rare in PIE, representing only
3.5% of a lexicon of more than 2,000 items. Plank
(1981:221f) observes that Modern German tends
to avoid verbal stems with identical consonants
in initial and final positions (allowing for differ-
ences in voicing), and that those verbs with iden-
tical initial and final consonants which do exist
are all morphologically regular. This indicates that
they are not basic verbs, but represent a technique
of word formation, perhaps derivative of redupli-
cation as especially common in child or child-
directed language.1
1Note that the early speech of children is characterized by
the opposite effect of SPA: both consonants and vowels tend
to share the same place of articulation (Fikkert and Levelt,
2010), with greater and greater differentiation being achieved
in the course of language acquisition. The reasons for this
remain to be investigated.
Looking at suprasegmental features, Leben
(1973) argued that a similar restriction holds for
the co-occurrence of tones in underlying repre-
sentations. In the framework of Autosegmental
Phonology this has become known as the Oblig-
atory Contour Principle (OCP), which precludes
sequences of identical tones from underlying rep-
resentations. This principle has since been under-
stood more generally as a prohibition on similar
items and has thus also been used in relation with
the SPA bias in Semitic radicals.
More recently, the application of SPA with
respect to stem-internal consonants has been
claimed for other non-Semitic languages as well.
Pozdniakov and Segerer (2007) found impres-
sive support for it in their sample of Atlantic
and Bantu languages of Niger-Congo and fur-
ther tested its crosslinguistic validity for some
more languages or language groups (Mande, Kwa,
Ubangi, Sara-Bongo-Bagirmi, Chadic, Malagasy,
Indo-European, Nostratic, Mongolian, Basque,
Quechua, Kamilaroi, Port Moresby Pidgin En-
glish) with similar results. Table 1 shows their
findings across all 31 languages in their sample.
It can be seen that the highest negative numbers
are in the main diagonal of the matrix, which is
exactly what SPA would predict.
P T C K
P ?15 +11 +5 ?5
T +12 ?10 ?5 +13
C +8 ?5 ?6 +8
K ?3 +8 +5 ?15
Table 1: Results in Pozdniakov and Segerer
(2007). The numbers indicate the overall sum of
cells with negative vs. positive values with regard
to successions of places of articulation (see Sec-
tion 3 for a description of the labels P, T, C and K)
for all languages in their sample. Positive and neg-
ative values have been assigned if the observed ab-
solute value was at least 15% above (respectively
below) the expected value. Compare their results
with the left matrix in Figure 3.
3 Database and methodology
The data that underlies all the subsequent work
presented in this paper have been taken from the
Automated Similarity Judgment Program (ASJP;
Wichmann et al, 2010), which aims at achiev-
71
ing a computerized lexicostatistical analysis of the
world?s languages. To this end, Wichmann and his
collaborators have collected Swadesh list items for
over 4,500 languages. The so-called Swadesh list
was developed by Morris Swadesh in the 1940?
50s with the aim of having a basic set of vocabu-
lary items which are culturally neutral and which
one would expect to be stable over time. The orig-
inal idea of a Swadesh list was to be able to com-
pare and test languages with respect to genealogi-
cal relations.
The Swadesh items in the Wichmann et al
database are transcribed in the ASJP orthogra-
phy, which uses standard ASCII characters to en-
code the sounds of the world?s languages, but does
merge some of the distinctions made by the IPA.
Furthermore, stress, tone and vowel length are not
recorded in the database. However, for the pur-
pose of our investigation the transcription is suit-
able because place of articulation is sufficiently
distinguished.
We decided to experiment with two different ap-
proaches for dividing up the place of articulation
features. One approach (PTCK) is based on the ar-
rangement in Pozdniakov and Segerer (2007) and
distinguishes four places of articulation for labial
(P), dental (and alveolar) (T), (alveo-)palatal (C)
and velar (K) consonants. A second grouping
(LCD) only distinguishes three places of articula-
tion: labial (L), coronal (C) and dorsal (D).2 Ac-
cording to this classification the consonants of all
the items in the database can be assigned to one of
these symbols, as shown in Table 2.
LCD PTCK ASJP IPA
L P
p, b, m, f, v, w p, F, b, B, m,
f, v, w
C
T
8, 4, t, d, s, z,
c, n, S, Z
T, D, n
?
, t, d, s,
z, ts, dz, n, S,
Z
C
C, j, T, l, L, r,
y
?, ?, c, ?, l, L,
?, L, r, R, j
D K
5, k, g, x, N,
q, G, X, 7, h
?, k, g, x, G, N,
q, G, X, K, ?,
Q, P, h, H,
Table 2: Assignment of consonants to symbols.
All varieties of ?click?-sounds have been ignored.
2Radical and laryngeal, which are commonly employed
in the phonological literature as yet another place distinction,
are subsumed under dorsal.
Experiments with using the four-way distinc-
tion vs. the three-way distinction showed that T
and C in the four-way grouping behave very simi-
larly with respect to the transitions to other places
of articulation (see Section 4.2). We therefore de-
cided to use the three-way distinction for the bulk
of our calculations and visualizations and only
sporadically resort to the four-way grouping when
a more fine-grained distinction is needed.
Furthermore, we decided to only include those
cases where the first and second consonants are
preceded (or followed, respectively) by another
vowel or a word boundary and are therefore not
part of a consonant cluster. We mainly did this in
order to minimize the noise caused by consonants
of inflectional markers that tend to assimilate in
such clusters.
In the literature on root morphemes in Semitic,
it has been noted that the consonants within trilit-
eral radicals behave differently with respect to
OCP. Greenberg (1950:162) remarks that while
the first and second consonants are usually not
identical, the same does not hold for the sec-
ond and third consonants, which frequently consti-
tute the well-known geminate subtype of Semitic
verbs. However, for our work we understand OCP
as it was later formulated within the framework
of autosegmental phonology (Leben, 1973; Mc-
Carthy, 1986; Goldsmith, 1976) in that adjacent
identical elements (here in the sense of identical
with respect to place of articulation) are prohib-
ited, under the assumption that consonants are ad-
jacent to each other (on the C tier) even when they
are separated by vowels in the linear sequence of
phonemes within the word.
For the purposes of our experiment, we con-
sidered the relevant context for adjacency to be
one where consonants are separated by exactly one
vowel.3 Note that since the basis for our calcula-
tions were not stems in the language but the cita-
tion forms that are used in the Swadesh lists, we
also get noise from inflectional markers that are
attached to these forms and might have the same
place of articulation irrespective of the stem to
which they attach.4
Finally, there are several shortcomings of the
3Since vowel length is not marked in the ASJP database,
long vowels are also included.
4Assimilation processes are far more frequent than dis-
similation processes in this context so that it is more likely
that the same place of articulation features are to be expected
when an inflectional marker is present.
72
material in the database with respect to our investi-
gation which must be kept in mind. OCP/SPA has
been claimed to apply with respect to underlying
or non-derived representations. Previous work has
been done on the basis of stem (or root) lists. De-
pending on the language, Swadesh list items are
not always stems, but whole words in their cita-
tion forms. For instance, while both English and
German use the infinitive as the citation form for
verbal stems, in English the infinitive is identical
to the stem whereas in German it is marked with
the suffix -en. In other languages, verbs can also
be cited by inflected forms other than the infinitive
(e.g., the 3rd person singular perfective in Arabic,
or the first person singular indicative present in
Latin). The same holds for nouns or other word
classes that are included in the Swadesh list. An-
other problematic aspect is the fact that it also con-
tains items (such as personal pronouns) that are
not lexical in the strict sense of the meaning and
are realized as bound forms in many languages.
Apart from that, the number of items for each
language in the ASJP database varied greatly from
only a few to one hundred. Moreover, the num-
ber of CVC sequences within the items differed
greatly from one language to another, depending
on the phonotactic properties of the languages.
Previous statistical studies have relied on a much
larger number of stems and consonant sequences.
Pozdniakov and Segerer?s (2007) statistics, for ex-
ample, were calculated on the basis of 495 to
17,944 CVC successions for the languages in their
sample.5 In contrast, our statistics are based on
much fewer CVC successions, ranging from 21 to
246 per language. Nevertheless, our results actu-
ally correspond to the main findings of their study
so that we think that the data are good enough for
our purposes.
4 Automated statistical analysis
4.1 Methodology
In a first step, for each language in the sample
an elementary statistical processing is performed.
Thereby, all successions of places of articulation
occurring in the Swadesh list items are identified
and counted. To do so, we define a succession of
5Note that they also included cases where the first and
second consonant are part of a consonant cluster, which we
ignored for our calculations. Furthermore, those languages
where the number of consonant successions in the data was
20 or below were not included in our visualizations, thereby
reducing the number of languages from about 4,500 to 3,200.
places of articulation as a binary sequence of con-
sonants (C-C). These consonants have to appear
within a word and have to be separated by exactly
one vowel (V). Before and after the succession ei-
ther word boundaries (#) or vowels have to ap-
pear. Hence, the following regular expression is
used to extract C-C successions (marked in bold):
[#|V ]CV C[#|V ]. Next, each consonant is as-
signed to one of the three major articulation place
categories labial, coronal and dorsal. The succes-
sion counts are summarized in a quadratic matrix
where the rows represent the preceding place of ar-
ticulation and the columns the following place of
articulation. Each matrix cell contains the number
of times the respective place of articulation suc-
cession could be observed in the corpus. Subse-
quently, for each of the 9 possible successions a
contingency table was created (Table 3).
P2 ?P2
P1 A : n(P1 ? P2) B: n(P1 ? ?P2)
?P1 C : n(?P1 ? P2) D : n(?P1 ? ?P2)
Table 3: Contingency table for the articulation
place (P) succession from P1 to P2.
The succession counts were used to calculate ?
coefficients, where A,B,C and D correspond to
the four cells in Table 3.
? =
?
?2
(A+B + C +D)
(1)
The ? coefficient is a measure for the degree
of association between two variables which can
be derived from the fourfold ?2 statistical signif-
icance test (see Rummel, 1970:298f for details).
Sample ? values for the place of articulation suc-
cessions of Egyptian Arabic can be seen in Table
4. A visual representation of the same matrix is
provided in Figure 2. Note the at-a-glance analy-
sis made possible by Figure 2 vs. Table 4.
labial coronal dorsal
labial ?0.360 +0.187 +0.183
coronal +0.259 ?0.243 ?0.068
dorsal ?0.010 +0.097 ?0.121
Table 4: Matrix of ? values for Egyptian Arabic.
Figure 2 shows an example in which all diag-
onal values (self-successions of places of articu-
lation) have negative associations. This tendency
73
Figure 2: Visualization of the ? matrix from Ta-
ble 4 (Egyptian Arabic), L stands for labial, C for
coronal and D for dorsal. It can be seen that all di-
agonal values (successions of the same place of ar-
ticulation) have negative associations (red color).
to alternate places of articulation can be observed
in most languages and in the overall matrix visu-
alizations including all data from all languages in
the database (Figure 4).
4.2 General relations among places of
articulation
As already mentioned, we tested whether it is use-
ful to distinguish the two different subcategories
dental (and alveolar) (T), and (alveo-)palatal (C).
Figure 3 shows the resulting association values ?
of place successions.
It can clearly be seen that T and C behave very
similarly. A further interesting observation is that
places of articulation tend to alternate (negative di-
agonal values for self-successions). As revealed in
the succession graph of Figure 3, the places of ar-
ticulation do not remain the same, but change to
the closest alternative(s). In the case of P and K
the closest distinct places of articulation (T and C)
are preferred. In the case of T and C, however, this
is somewhat different. Apparently, direct alterna-
tions between both are less probable. One plau-
sible explanation could be that they are not dis-
tinct enough and thus either K or P are preferred
as a following place of articulation, both having
roughly the same distance. These observations
led us to merge the places T and C in our further
analyses and distinguish labial, coronal and dorsal
consonants only, as in Figure 4.
Note that the cross pattern on the left in Figure
4, which now emerges very clearly, reinforces the
hypothesis that the closest distinct place of articu-
lation is preferred as successor.
Figure 4: The ? matrix considering only the three
main categories for all the data across languages.
In the left figure, the categories are sorted accord-
ing to their position in the oral cavity. In the
right figure, the categories are sorted automati-
cally, which shows that D and L are more similar
to each other than D and C.
4.3 Distribution across languages
Next, we examined the distribution of ? values for
self-successions of places of articulation in about
3,200 languages. Self-successions correspond to
the diagonal values of the ? matrices from the up-
per left to the lower right. As can be seen in the
histogram in Figure 6, the peak of the distribution
is clearly located in the area of negative associa-
tion values. In the box-plots of Figure 5, which
show the distributions for all three places of ar-
ticulation separately, it is clearly visible that for
each of the three places of articulation at least 75%
of the languages included show negative associa-
tions. Furthermore, it can be seen that most out-
liers disappear when taking only the languages for
which most data is available and thus statistics are
more reliable. The same can be seen in the scat-
ter plot in Figure 6, where the average ? value is
always negative if the number of successions ex-
ceeds a certain threshold. For all three categories,
the figures demonstrate that the same place of ar-
ticulation is generally less frequently maintained
than expected if there were no interdependencies
between consonant co-occurrences.
5 Visualization of geo-spatial patterns
The most common approach to visually represent
crosslinguistic information on areal (or genealog-
ical) patterns is to put each language as a single
pixel or a small icon to its location on a map.
For instance, the WALS database (Haspelmath et
al., 2005) includes 141 maps on diverse structural
(phonological, grammatical, lexical) properties of
languages. We transformed the results of our SPA
statistics for each language in the ASJP database
74
P
T C
K
Figure 3: Successions of P, T, C and K in all languages. The ?+? and ??? signs indicate the polarity
of a succession (going from row to column category). The color saturation of the background indicates
the strength of association. In the left figure, places of articulation are sorted according to their position
in the oral cavity, in the middle figure an automatic similarity sorting of matrix rows and columns was
applied. The right part of the figure shows an alternative view only on those successions that have a
positive association.
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
lll
l
l
l
l
l
l
ll
l
l
l
l
l
l
Labial?Labial Coronal?Coronal Dorsal?Dorsal
?
1.0
?
0.5
0.0
0.5
1.0
Distribution of association values across languages (all)
ll
l
l
ll
Labial?Labial Coronal?Coronal Dorsal?Dorsal
?
1.0
?
0.5
0.0
0.5
1.0
Distribution of association values across languages (top)
Figure 5: Boxplots showing the distribution of association strength values (?) for self-successions of
places of articulation. For the left boxplots about 3,200 languages were considered for which the
Swadesh lists contained more than 20 successions. For the right boxplots only the top 99 languages
were considered for which the Swadesh lists contained at least 100 successions, thereby removing most
outliers and reducing the variance.
that is also included in the WALS database into a
WALS map (Figure 7). The matrix visualization
has been simplified in that the color of the icon
represents the number of cells in the diagonal of
the matrix whose value was below zero, i.e., the
higher the number (0-3) the better the language
conforms to SPA.
Some of the drawbacks of these maps include a
high degree of overlap of data points in densely
populated areas and the lack of correlation be-
tween information content and area size. In Figure
7, the fact that those languages with fewer negative
diagonal cells are plotted on top of those with a
higher number slightly distorts the overall picture
that most languages adhere to the principle.6 Be-
sides that, the overall pattern in the densely popu-
lated areas is hardly visible, while sparsely popu-
lated areas waste space and hide the informational
6Likewise, the visualization would suggest to much ad-
herence to the principle if those languages with more nega-
tive diagonal cells were plotted on top of those with fewer
negative cells.
75
ll
lll
l
ll
l
l
l
ll
l
l
l
ll
lll
l
l
l
l
l
l
l
l
l
l
l
l
lll
ll
l
l
l
l
lll
l
l
l
l
l
l
l
l
ll
l
l
ll
l
l
l
l
lll
ll
l
l
l
l
llll
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
ll
l
ll
ll
lll
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
ll
l
ll
l
lll
l
l
lll
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
lll
ll
lll
l
l
l
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
ll
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
llll
l
l
lll
l
l
l
l
l
l
l
ll
ll
l
l
ll
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
llll
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
ll
ll
l
l
l
ll
l
lll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
llll
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
ll
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
l
l
l
ll
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
ll
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
ll
l
l
ll
l
lll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
l
lll
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
lll
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
llll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
50 100 150 200
?
0.4
?
0.2
0.0
0.2
0.4
Average phi values in dependence of data amount
Number of consonant successions in dataset
Ave
rage
 phi 
valu
e
Labial, Coronal and Dorsal
Distribution of association values for all self?successions across languages
Freq
uen
cy
?1.0 ?0.5 0.0 0.5 1.0
0
100
200
300
400
500
600
Figure 6: The scatter plot on the left displays the average ? values for self-successions of all places of
articulation depending on the number of consonant successions (CVC) for each language in the sample.
The histogram on the right shows the distribution of association strength values (?) for self-successions
of places of articulation in more than 3200 languages.
details. Finally, small clusters are difficult to find
? they are not noticeable, and are sometimes even
obscured by large clusters.
In order to avoid overlapping pixels we used
a circular arrangement around the original loca-
tion in the current analysis, taking the given order-
ing of elements into account (Bak et al, 2009a).
The ordering usually corresponds to the coloring
attribute starting with colors that occur least fre-
quently. With this arrangement a natural looking
visualization without artifacts is generated.
A way to obtain more space for regions with a
high point density are Cartograms, which distort
regions such that their size corresponds to a statis-
tical attribute (Bak et al, 2009b; Tobler, 2004), in
this case the number of languages in the database.
The advantage is that more space is reserved to
plot all important information on the map. In Fig-
ure 8, we show the density equalized distortion by
cartograms and the overlap-free representation of
the data points using pixel placement. Neighbor-
hood relations and region shapes are at the same
time maintained as accurately as possible in order
to guarantee recognizability despite of distortion.
The visualization reveals several clusters of non-
conforming languages (marked with boxes). It re-
mains for future work to investigate whether these
clusters are an artifact of the database that we used
or if they manifest an areal feature. Figure 8, in
contrast to Figure 7, shows the 3,200 languages
we investigated more closely and not just the ones
included in WALS.
The representation thereby enables investigat-
ing spatial patterns free of hidden data and distri-
butional biases.
6 Conclusions and future work
Our crosslinguistic investigation of SPA has con-
firmed the hypothesis that the phenomenon of
Similar Place Avoidance is not a particular trait
of Semitic languages, for which it was previously
described, but is a linguistic universal tendency
which can be observed in languages which are
both genealogically and geographically unrelated.
This can clearly be seen in the visualizations that
display the conformity of each language in the
database with respect to SPA. The overall pic-
ture for all languages not only shows that succes-
sive consonants with the same place of articulation
tend to be avoided, but also that there is a tendency
to avoid places of articulation that are too far away
from the preceding place (cf. Figures 3 and 4).
We combine methods from statistics, NLP and
Visual Analytics to provide a novel way of auto-
matically assessing and visualizing linguistic fea-
tures across a wide range of languages, thus al-
76
Figure 7: WALS map of the languages and their behavior with respect to SPA. The color indicates the
number of self-succession ? values which are negative, i.e., which adhere to the SPA principle. Color
mapping is from blue (conforming to SPA) to red. The numbers in square brackets indicate the number
of languages in this group.
Figure 8: Density equalized distribution of the languages with respect to SPA. The area of the geographic
regions corresponds to the number of languages in that location ? represented by dots. Overlap is avoided
using pixel-placement. The color mapping corresponds to the one used in the WALS map (Figure 7). Lo-
cations of nonconforming languages are highlighted with red boxes. Note that the number of languages
in this map is about twice the number in the WALS map (7).
77
lowing for a gain of new insights and raising fur-
ther interesting research questions that otherwise
might easily go unrecognized.
With respect to SPA a more detailed exploration
of the intricacies of phonological interdepencies is
needed as part of our more widespread study of
visually representing sound patterns in languages.
As already hinted at in Pozdniakov and Segerer
(2007), there are various other fascinating phe-
nomena that are worth looking at, especially in re-
gard to the interaction of vowels and consonants or
vowel dependencies (such as vowel harmony) and
consonant dependencies (such as SPA or conso-
nant harmony). In particular, one could investigate
why some languages apparently do not conform to
SPA and if there is any co-variation to be uncov-
ered between the adherence to the principle and
other factors that might be interesting to explore
and possibly reveal new insights into the structure
of languages.
Acknowledgments
This work has been funded by the research ini-
tiative ?Computational Analysis of Linguistic De-
velopment? at the University of Konstanz. The
authors would like to thank Aditi Lahiri and two
anonymous reviewers for valuable comments and
suggestions.
References
Peter Bak, Florian Mansmann, Halldor Janetzko, and
Daniel Keim. 2009a. Spatiotemporal analysis of
sensor logs using growth ring maps. IEEE Trans-
actions on Visualization and Computer Graphics,
15(6):913?920.
Peter Bak, Matthias Schaefer, Andreas Stoffel, Daniel
Keim, and Itzhak Omer. 2009b. Density equalizing
distortion of large geographic point sets. Journal of
Cartographic and Geographic Information Science
(CaGIS), 36(3):237?250.
Balthasar Bickel. in press. Absolute and statistical uni-
versals. In Patrick C. Hogan, editor, The Cambridge
Encyclopedia of the Language Sciences. Cambridge:
Cambridge University Press.
Paul Boersma and Bruce Hayes. 2001. Empirical tests
of the gradual learning algorithm. Linguistic In-
quiry, 32:45?86.
Paula Fikkert and Clara C. Levelt. 2010. How does
place fall into place? The lexicon and emergent con-
straints in the developing phonological grammar. In
Peter Avery, B. Elan Dresher, and Keren Rice, edi-
tors, Contrast in Phonology: Perception and Acqui-
sition. Berlin: Mouton de Gruyter.
John Goldsmith. 1976. Autosegmental phonology.
Ph.D. thesis, Massachusetts Institute of Technology.
Joseph H. Greenberg. 1950. The patterning of root
morphemes in Semitic. Word, 6:161?182.
Martin Haspelmath, Matthew S. Dryer, David Gil, and
Bernard Comrie. 2005. The World Atlas of Lan-
guage Structures Online. URL: http://wals.
info/.
Gregory K. Iverson and Joseph C. Salmonts. 1992.
The phonology of the Proto-Indo-European root
structure constraint. Lingua, 87:293?320.
Daniel A. Keim, Florian Mansmann, Joern Schnei-
dewind, Jim Thomas, and Hartmut Ziegler. 2008.
Visual analytics: Scope and challenges. In Visual
Data Mining: Theory, Techniques and Tools for Vi-
sual Analytics, Lecture Notes in Computer Science,
pages 76?91. Springer.
Wiliam R. Leben. 1973. Suprasegmental phonology.
Ph.D. thesis, Massachusetts Institute of Technology.
John J. McCarthy. 1986. OCP effects: Gemination and
antigemination. Linguistic Inquiry, 17:207?263.
Frans Plank. 1981. Morphologische (Ir-)Regularita?-
ten: Aspekte der Wortstrukturtheorie. Tu?bingen:
Gunter Narr Verlag.
Konstantin Pozdniakov and Guillaume Segerer. 2007.
Similar Place Avoidance: A statistical universal.
Linguistic Typology, 11(2):307?348.
Christian Rohrdantz, Thomas Mayer, Miriam Butt,
Frans Plank, and Daniel A. Keim. 2010. Compar-
ative visual analysis of cross-linguistic features. In
Proceedings of the International Symposium on Vi-
sual Analytics Science and Technology (EuroVAST
2010), pages 27?32.
Rudolph J. Rummel. 1970. Applied Factor Analysis.
Evanston, IL: Nortwestern University Press.
James J. Thomas and Kristin A. Cook. 2005. Illu-
minating the Path: The Research and Development
Agenda for Visual Analytics. National Visualization
and Analytics Ctr.
Waldo Tobler. 2004. Thirty five years of computer
cartograms. Association of American Geographer,
94(1):58?73.
78
