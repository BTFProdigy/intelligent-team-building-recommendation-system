Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 189?195,
24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational Linguistics
Sentimatrix ? Multilingual Sentiment Analysis Service 
 
Alexandru-Lucian G?nsc?1, Emanuela Boro?1, Adrian Iftene1, Diana Trandab??1,  
Mihai Toader2, Marius Cor?ci2, Cenel-Augusto Perez1, Dan Cristea1, 3 
1
?Al. I. Cuza? University, Faculty of Computer Science, Iasi, Romania 
2Intelligentics, Cluj-Napoca, Romania 
3Institute of Computer Science, Romanian Academy, Iasi, Romania 
{lucian.ginsca, emanuela.boros, adiftene, dtrandabat, augusto.perez, 
dcristea}@info.uaic.ro, {mtoader, marius}@intelligentics.ro 
 
 
Abstract 
This paper describes the preliminary results 
of a system for extracting sentiments 
opinioned with regard with named entities. 
It also combines rule-based classification, 
statistics and machine learning in a new 
method. The accuracy and speed of 
extraction and classification are crucial. 
The service oriented architecture permits 
the end-user to work with a flexible 
interface in order to produce applications 
that range from aggregating consumer 
feedback on commercial products to 
measuring public opinion on political 
issues from blog and forums. The 
experiment has two versions available for 
testing, one with concrete extraction results 
and sentiment calculus and the other with 
internal metrics validation results. 
1 Motivation 
Nowadays, big companies and organizations spend 
time and money in order to find users? opinions 
about their products, the impact of their marketing 
decisions, or the overall feeling about their support 
and maintenance services. This analysis helps in 
the process of establishing new trends and policies 
and determines in which areas investments must be 
made. One of the focuses of our work is helping 
companies build such analysis in the context of 
users? sentiment identification. Therefore, the 
corpus we work on consists of articles of 
newspapers, blogs, various entries of forums, and 
posts in social networks. 
Sentiment analysis, i.e. the analysis and 
classification of the opinion expressed by a text on 
its subject matter, is a form of information 
extraction from text, which recently focused a lot 
of research and growing commercial interest. 
This paper describes Sentimatrix, a sentiment 
analysis service, doing sentiment extraction and 
associating these analyses with named entities, in 
different languages. We seek to explore how 
sentiment analysis methods perform across 
languages, especially Romanian. The main 
applications that this system experiments with are 
monitoring the Internet before, during and after a 
campaign/message release and obtaining consumer 
feedback on different topics/products. 
In Section 2 we briefly discuss a state of the art 
in sentiment analysis, the system?s architecture is 
described in Section 3 and in Section 4 we focus 
on identifying opinions on Romanian. 
Subsequently, we present the experiment results, 
analysis and discussion in Sections 5 and 6. Future 
work and conclusions are briefly described in 
Section 7. 
2 Sentimatrix compared with state-of-
the-art 
A comprehensive state of the art in the field of 
sentiment analysis, together with potential 
applications of such opinion identification tools, is 
presented in (Pang and Lee, 2008). 
Starting from the early 1990s, the research on 
sentiment-analysis and point of views generally 
assumed the existence of sub-systems for rather 
sophisticated NLP tasks, ranging from parsing to 
the resolution of pragmatic ambiguities (Hearst, 
1992; Wiebe 1990 and 1994). In Sentimatrix, in 
order to identify the sentiment a user expresses 
about a specific product or company, the company 
name must be first identified in the text. Named 
189
entity recognition (NER) systems typically use 
linguistic grammar-based techniques or statistical 
models (an overview is presented in (Nadeau and 
Satoshi Sekine. 2007)). Hand-crafted grammar-
based systems typically obtain better precision, but 
at the cost of lower recall and months of work by 
experienced computational linguists. Besides, the 
task is hard to adapt to new domains. Various 
sentiment types and levels have been considered, 
starting from the ?universal? six level of emotions 
considered in (Ovesdotter Alm, 2005; Liu et al, 
2003; Subasic and Huettner, 2001): anger, disgust, 
fear, happiness, sadness, and surprise. For 
Sentimatrix, we adapted this approach to five 
levels of sentiments: strong positive, positive, 
neutral, negative and strong negative.  
The first known systems relied on relatively 
shallow analysis based on manually built 
discriminative word lexicons (Tong 2001), used to 
classify a text unit by trigger terms or phrases 
contained in a lexicon. The lack of sufficient 
amounts of sentiment annotated corpora led the 
researchers to incorporate learning components 
into their sentiment analysis tools, usually 
supervised classification modules, (e.g., 
categorization according to affect), as initiated in 
(Wiebe and Bruce 1995). 
Much of the literature on sentiment analysis has 
focused on text written in English. Sentimatrix is 
designed to be, as much as possible, language 
independent, the resources used being easily 
adaptable for any language. 
Some of the most known tools available 
nowadays for NER and Opinion Mining are: 
Clarabridge (www.clarabridge.com), RavenPack 
(ravenpack.com), Lexalytics (www.lexalytics.com) 
OpenAmplify (openamplify.com), Radian6 
(www.radian6.com), Limbix (lymbix.com), but 
companies like Google, Microsoft, Oracle, SAS, 
are also deeply involved in this task. 
3 System components 
In Figure 1, the architecture and the main modules 
of our system are presented: preprocessing, named 
entity extraction and opinion identification 
(sentiment extraction per fragment).  
The final production system is based on service 
oriented architecture in order to allow users 
flexible customization and to enable an easier way 
for marketing technology. Each module of the 
system (Segmenter, Tokenizer, Language Detector, 
Entity Extractor, and Sentiment Extractor) can be 
exposed in a user-friendly interface.  
 
Figure 1. System architecture 
3.1 Preprocessing 
The preprocessing phase is made out of a text 
segmentator and a tokenizer. Given a text, we 
divide it into paragraphs, every paragraph is split 
into sentences, and every phrase is tokenized. Each 
token is annotated with two pieces of information: 
its lemma (for Romanian it is obtained from our 
resource with 76,760 word lemmas corresponding 
to 633,444 derived forms) and the normalized form 
(translated into the proper diacritics1). 
3.2 Language Detection 
Language detection is a preprocessing step 
problem of classifying a sample of characters 
based on its features (language-specific models). 
Currently, the system supports English, Romanian 
and Romanian without Diacritics. This step is 
needed in order to correctly identify a sentiment or 
a sentiment modifier, as the named entity detection 
depends on this. We combined three methods for 
                                                          
1
 In Romanian online texts, two diacritics are commonly used, 
but only one is accepted by the official grammar. 
190
identifying the language: N-grams detection, 
strictly 3-grams detection and lemma correction.  
The 3-grams classification method uses corpus 
from Apache Tika for several languages. The 
Romanian 3-gram profile for this method was 
developed from scratch, using our articles archive. 
The language detection in this case performs 
simple distance measurement between every 
language profile that we have and the test 
document profile. The N-grams classification 
method implies, along with computing frequencies, 
a posterior Naive Bayes implementation. The third 
method solves the problematic issue of short 
phrases language detection and it implies looking 
through the lemmas of several words to obtain the 
specificity of the test document. 
3.3 Named Entity Recognition 
The Named Entity Recognition component for 
Romanian language is created using linguistic 
grammar-based techniques and a set of resources. 
Our component is based on two modules, the 
named entity identification module and the named 
entity classification module. After the named entity 
candidates are marked for each input text, each 
candidate is classified into one of the considered 
categories, such as Person, Organization, Place, 
Country, etc. 
 
Named Entity Extraction: After the pre-
processing step, every token written with a capital 
letter is considered to be a named entity candidate.  
For tokens with capital letters which are the first 
tokens in phrases, we consider two situations:  
1. this first token of a phrase is in our stop word 
list (in this case we eliminate it from the 
named entities candidate list),  
2. the first token of a phrase is in our common 
word list. In the second situation there are 
considered two cases:  
a. this common word is followed by lowercase 
words (then we check if the common word 
can be found in the list of trigger words, like 
university, city, doctor, etc.),  
b. this common word is followed by uppercase 
words (in this case the first word of the 
sentence is kept in the NEs candidate list, 
and in a further step it will be decided if it 
will be combined with the following word in 
order to create a composed named entity).  
Named Entities Classification: In the 
classification process we use some of rules utilized 
in the unification of NEs candidates along with the 
resource of NEs and several rules specifically 
tailored for classification. Thus, after all NEs in the 
input text are identified and, if possible, compound 
NEs have been created, we apply the following 
classification rules: contextual rules (using 
contextual information, we are able to classify 
candidate NEs in one of the categories 
Organization, Company, Person, City and Country 
by considering a mix between regular expressions 
and trigger words) and resource-based rules (if no 
triggers were found to indicate what type of entity 
we have, we start searching our databases for the 
candidate entity). 
 
Evaluation: The system?s Upper Bound and its 
performance in real context are evaluated for each 
of the two modules (identification and 
classification) and for each named entity type. The 
first part of the evaluation shows an upper bound 
of 95.76% for F-measure at named entity 
extraction and 95.71% for named entity 
classification. In real context the evaluation shows 
a value of 90.72% for F-measure at named entity 
extraction and a value of 66.73% for named entity 
classification. The results are very promising, and 
they are being comparable with the existing 
systems for Romanian, and even better for Person 
recognition. 
4 Identify users opinions on Romanian 
4.1 Resources 
In such a task as sentiment identification, linguistic 
resources play a very important role. The core 
resource is a manually built list of words and 
groups of words that semantically signal a positive 
or a negative sentiment. From now on, we will 
refer to such a word or group of words as 
?sentiment trigger?. Certain weights have been 
assigned to these words after multiple revisions. 
The weights vary from -3, meaning strong negative 
to +3, which translates to a strong positive. There 
are a total of 3,741 sentiment triggers distributed to 
weight groups as can be observed in Figure 2. The 
triggers are lemmas, so the real number of words 
that can be identified as having a sentiment value 
is much higher. 
191
This list is not closed and it suffers modifications, 
especially by adding new triggers, but in certain 
cases, if a bad behavior is observed, the weights 
may also be altered.  
 
 
Figure 2. Number of sentiment words by weight groups 
 
We define a modifier as a word or a group of 
words that can increase or diminish the intensity of 
a sentiment trigger. We have a manually built list 
of modifiers. We consider negation words a special 
case of modifiers that usually have a greater impact 
on sentiment triggers. So, we also built a small list 
of negation words.   
4.2 Formalism 
General definitions: We define a sentiment 
segment as follows: 
  = (	
, , 		) 
 
sSG is a tuple in which the first two elements are 
optional.  
Let NL be the set of negation words that we use, 
ML the set of modifiers and TL the set of sentiment 
triggers.  We define two partially ordered sets: 
  = (, ?), 