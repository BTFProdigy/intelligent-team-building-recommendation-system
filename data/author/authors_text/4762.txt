HMMand CRF Based Hybrid Model for Chinese Lexical Analysis
	
				
	
Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 72?78,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Hybrid Models 
for Chinese Named Entity Recognition 
 
Lishuang Li, Tingting Mao, Degen Huang, Yuansheng Yang 
Department of Computer Science and Engineering 
Dalian University of Technology 
116023 Dalian, China 
{computer, huangdg, yangys}@dlut.edu.cn  
maotingting1007@sohu.com 
 
Abstract 
This paper describes a hybrid model and 
the corresponding algorithm combining 
support vector machines (SVMs) with 
statistical methods to improve the per-
formance of SVMs for the task of Chi-
nese Named Entity Recognition (NER). 
In this algorithm, a threshold of the dis-
tance from the test sample to the hyper-
plane of SVMs in feature space is used to 
separate SVMs region and statistical 
method region. If the distance is greater 
than the given threshold, the test sample 
is classified using SVMs; otherwise, the 
statistical model is used. By integrating 
the advantages of two methods, the hy-
brid model achieves 93.18% F-measure 
for Chinese person names and 91.49% F-
measure for Chinese location names. 
1 Introduction 
Named entity (NE) recognition is a fundamental 
step to many language processing tasks such as 
information extraction (IE), question answering 
(QA) and machine translation (MT). On its own, 
NE recognition can also provide users who are 
looking for person or location names with quick 
information. Palma and Day (1997) reported that 
person (PER), location (LOC) and organization 
(ORG) names are the most difficult sub-tasks as 
compared to other entities as defined in Message 
Understanding Conference (MUC). So we focus 
on the recognition of PER, LOC and ORG enti-
ties. 
Recently, machine learning approaches are 
widely used in NER, including the hidden 
Markov model (Zhou and Su, 2000; Miller and 
Crystal, 1998), maximum entropy model 
(Borthwick, 1999), decision tree (Qin and Yuan, 
2004), transformation-based learning (Black and 
Vasilakopoulos, 2002), boosting (Collins, 2002; 
Carreras et al, 2002), support vector machine 
(Takeuchi and Collier, 2002; Yu et al, 2004; 
Goh et al, 2003), memory-based learning (Sang, 
2002). SVM has given high performance in vari-
ous classification tasks (Joachims, 1998; Kudo 
and Matsumoto, 2001). Goh et al (2003) pre-
sented a SVM-based chunker to extract Chinese 
unknown words. It obtained higher F-measure 
for person names and organization names. 
Like other classifiers, the misclassified testing 
samples by SVM are mostly near the decision 
plane (i.e., the hyperplane of SVM in feature 
space). In order to increase the accuracy of SVM, 
we propose a hybrid model combining SVM 
with a statistical approach for Chinese NER, that 
is, in the region near the decision plane, statisti-
cal method is used to classify the samples instead 
of SVM, and in the region far away from the de-
cision plane, SVM is used. In this way, the mis-
classification by SVM near the decision plane 
can be decreased significantly. A higher F-
measure for Chinese NE recognition can be 
achieved. 
In the following sections, we shall describe 
our approach in details. 
2 Recognition of Chinese Named Entity 
Using SVM 
Firstly, we segment and assign part-of-speech 
(POS) tags to words in the texts using a Chinese 
lexical analyzer. Secondly, we break segmented 
words into characters and assign each character 
its features. Lastly, a model based on SVM to 
identify Chinese named entities is set up by 
choosing a proper kernel function. 
In the following, we will exemplify the person 
names and location names to illustrate the identi-
fication process. 
72
2.1 Support Vector Machines 
Support Vector Machines first introduced by 
Vapnik (1996) are learning systems that use a 
hypothesis space of linear functions in a high 
dimensional feature space, trained with a learn-
ing algorithm from optimization theory that im-
plements a learning bias derived from statistical 
theory. SVMs are based on the principle of struc-
tural risk minimization. Viewing the data as 
points in a high-dimensional feature space, the 
goal is to fit a hyperplane between the positive 
and negative examples so as to maximize the 
distance between the data points and the hyper-
plane. 
Given training examples: 
},1,1{,)},,(),...,,(),,{( 2211 +???= iill ynRxyxyxyxS  (1) 
ix is a feature vector (n dimension) of the i-th 
sample.  is the class (positive(+1) or nega-
tive(-1) class) label of the i-th sample. l  is the 
number of the given training samples. SVMs find 
an ?optimal? hyperplane:  to sepa-
rate the training data into two classes. The opti-
mal hyperplane can be found by solving the fol-
lowing quadratic programming problem (we 
leave the details to Vapnik (1998)): 
iy
0)( =+ bwx
.,...,2,1,0    ,0           tosubject
),(
2
1
               max
1 11
licy
Kyy   
ii
l
1i
i
l
i
l
j
jjii
l
i
i
=???=?
????
?
? ??
=
= ==
ji xx    (2) 
The function  is called 
kernel function, is the mapping from pri-
mary input space to feature space. Given a test 
example, its label y is decided by the following 
function: 
)()()( jiji xxx,x ???=K
)(x?
.]),(sgn[)( ?
?
+?=
sv
ii bKyf
ix
i xxx            (3) 
Basically, SVMs are binary classifiers, and 
can be extended to multi-class classifiers in order 
to solve multi-class discrimination problems. 
There are two popular methods to extend a bi-
nary classification task to that of K classes: one 
class vs. all others and pairwise. Here, we em-
ploy the simple pairwise method. This idea is to 
build  classifiers considering all 
pairs of classes, and final decision is given by 
their voting. 
2/)1( ?? KK
2.2 Recognition of Chinese Person Names 
Based on SVM 
We use a SVM-based chunker, YamCha (Kudo 
and Masumoto, 2001), to extract Chinese person 
names from the Chinese lexical analyzer. 
1) Chinese Person Names Chunk Tags 
We use the Inside/Outside representation for 
proper chunks: 
I    Current token is inside of a chunk. 
O   Current token is outside of any chunk. 
B   Current token is the beginning of a chunk. 
A chunk is considered as a Chinese person 
name in this case. Every character in the training 
set is given a tag classification of B, I or O, that 
is, },,{ OIByi ? . Here, the multi-class decision 
method pairwise is selected. 
2) Features Extraction for Chinese Person 
Names 
Since Chinese person names are identified 
from the segmented texts, the mistakes of word 
segmentation can result in error identification of 
person names. So we must break words into 
characters and extract features for every charac-
ter. Table 1 summarizes types of features and 
their values. 
 
Type of feature Value 
POS tag n-B, v-I, p-S 
Whether a character 
is a surname  Y or N 
Character surface form of the  character itself 
The frequency of a 
character in person 
names table 
Y or N 
Previous BIO tag B-character, I-character, O-character 
Table 1. Summary of Features and Their Values 
The POS tag from the output of lexical analy-
sis is subcategorized to include the position of 
the character in the word. The list of POS tags is 
shown in Table 2. 
 
POS tag Description of the position of the character in a word 
<POS>-S One-character word 
<POS>-B first character in a multi-character word 
<POS>-I intermediate character in a multi-character word 
<POS>-E last character in a multi-character word 
Table 2.  POS Tags in A Word 
If the character is a surname, the value is as-
signed to Y, otherwise assigned to N. 
The ?character? is surface form of the charac-
ter in the word. 
We extract all person names in January 1998 
of the People?s Daily to set up person names ta-
ble and calculate the frequency of every charac-
73
ter (F) of person names table in the training cor-
pus. The frequency of F is defined as 
,)(
  F of number  total  the
names person of character a as F of number the
FP = (4) 
if P(F) is greater than the given threshold, the 
value is assigned to Y, otherwise assigned to N.  
We also use previous BIO-tags as features. 
Whether a character is inside a person name or 
not, it depends on the context of the character. 
Therefore, we use contextual information of two 
previous and two successive characters of the 
current character as features. 
Figure 1 shows an example of features extrac-
tion for the i-th character. When training, the fea-
tures of the character ?Min? contains all the fea-
tures surrounded in the frames. If the same sen-
tence is used as testing, the same features are 
used. 
 
Position 
Character 
POS tags 
The frequency of a character in 
the person names table 
Previous BIO tags 
-2    -1    0   +1   +2
Jiang  Ze   Min  zhu  xi
n-S  n-B  n-E  n-B  n-E
Y     Y    Y    N    N
B     I    I    O    O
  i 
Whether the character 
is a surname 
Y     N    N    N    Y
 Figure 1.  An example of features extraction
 
3) Choosing Kernel Functions 
Here, we choose polynomial kernel functions: 
to build an optimal 
separating hyperplane. 
d
ii xxxxK ]1)[(),( +?=
2.3 Recognition of Chinese Location Names 
Based on SVM 
The identification process of location names is 
the same as that of person names except for the 
features extraction. Table 3 summarizes types of 
features and their values of location names ex-
traction. 
Type of feature Value 
POS tag n-B, v-I, p-S 
Whether a character 
appears in location names 
characteristic table 
Y or N 
Character surface form of the character itself 
Previous BIO tag 
B-character, I-
character, O-
character 
Table 3. Summary of Features and Their Values 
The location names characteristic table is set 
up in advance, and it includes the characters or 
words expressing the characteristics of location 
names such as ?sheng (province)?, ?shi (city)?, 
?xian (county)?etc. If the character is in the loca-
tion names characteristic table, the value is as-
signed to Y, otherwise assigned to N. 
3 Statistical Models 
Many statistical models for NER have been pre-
sented (Zhang et al, 1992; Huang et al, 2003 
etc). In this section, we proposed our statistical 
models for Chinese person names recognition 
and Chinese location names recognition.     
3.1 Chinese Person Names 
We define a function to evaluate the person name 
candidate PN. The evaluated function Total-
Probability(PN) is composed of two parts: the 
lexical probability LP(PN) and contextual prob-
ability CP(PN) based on POS tags. 
),()1()()( PNCPPNLPPNbilityTotalProba ??+?=  (5) 
where PN is the evaluated person name and ? is 
the balance cofficient. 
1) lexical probability LP(PN)    
We establish the surname table (SurName) and 
the first name table (FirstName) from the 
students of year 1999 in a university (containing 
9986 person names). 
Suppose PN=LF1F2, where L is the surname 
of the evaluated person name PN, Fi (i=1,2) is the 
i-th first name of the evaluated person name PN. 
The probability of the surname Pl(L) is defined 
as 
,
)(
)(
)(
0
0?
?
=
SurNamey
l
l
l yP
LP
LP                                (6) 
where ,  is the 
number of L as the single or multiple surname of 
person names in the SurName. 
)2)((log)( 20 += LNLPl )(LN
The probability of the first name Pf(F) is 
defined as 
,
)(
)(
)(
0
0
?
?
=
FirstNamey
f
f
f yP
FP
FP                                 (7) 
where ,  is the 
number of F in the FirstName. 
)2)((log)( 20 += FNFPf )(FN
The lexical probability of the person name PN 
is defined as 
 ,)FLFif(PN       FP   FPCLPPNLP
)LFif(PN                                FPLPPNLP
ffbl
fl
2121
11
))()(()()(
)()()(
=+??=
=?=  (8) 
74
where Cb is the balance cofficient between the 
single name and the double name. Here, 
Cb=0.844 (Huang et al, 2001). 
2) contextual probability based on POS tags 
CP(PN) 
Chinese person names have characteristic 
contexual POS tags in real Chinese texts, for 
example, in the phrase ?dui Zhangshuai shuo 
(say to Zhangshuai)?, the POS tag before the 
person name ?Zhangshuai? is prepnoun and verb 
occurs after the person name. We define the 
bigram contextual probability CP(PN) of the 
person name PN as the following equation: 
CP(PN)= ,),,(
TotalPOS
rposPNlposPersonPOS ><            (9) 
where lpos is the POS tag of the character before 
PN (called POS forward), rpos is the POS tag of 
the character after PN (called POS backward), 
and is the number 
of PN as a pereson name whose POS forward is 
lpos and POS backward is rpos in training corpus. 
 is the total number of the contexual 
POS tags of every person name in the whole 
training corpus. 
),,( >< rposPNlposPersonPOS
TotalPOS
3.2 Chinese Location Names 
We also define a function to evaluate the location 
name candidate LN. The evaluated function To-
talProbability(LN) is composed of two parts: the 
lexical probability LP (LN) and contextual prob-
ability CP (LN) based on POS tags. 
),()1()()( LNCPLNLPLNbilityTotalProba ??+?= (10) 
where LN is the evaluated location name and?  is 
the balance cofficient. 
1) lexical probability LP (LN) 
Suppose LN=F0F+S, F+=F1?Fn, (i=1,?,n), 
where F0 is the first character of the evaluated 
location name LN, F+ is the middle characters of 
the evaluated location name LN, S is the last 
character of the evaluated location name LN. 
The probability of the first character of the 
evaluated location name is defined as )( 0FPh
,
)(
)(
)(
00
00
0 FP
FP
FP
h
h
h ?=                                      (11) 
where ,  is the 
number of F
)2)((log)( 0200 += FCFPh )( 0FC
0 as the first character of location 
names in the Chinese Location Names Record.  
)2)((log)( 0200 +?=? FCFPh ,  is the total 
number of F
)( 0FC ?
0 in the Chinese Location Names 
Record. 
The probability of the middle character of the 
evaluated location name is defined as )( +FPf
,
)(
)(
)(
1
?
=
+
?=
n
i if
if
f FP
FP
FP                                  (12) 
where ,  is the 
number of F
)2)((log)( 2 += iif FCFP )( iFC
i as the i-th middle character of loca-
tion names in the Chinese Location Names Re-
cord. 
)2)((log)( 2 +?=? iif FCFP ,  is the total 
number of F
)( iFC ?
i in the Chinese Location Names 
Record. 
 The probability of the last character of the 
evaluated location name is defined as )(SPl
,
)(
)(
)(
SP
SP
SP
l
l
l ?=                                          (13) 
where ,  is the 
number of  S as the last character of location 
names in the Chinese Location Names Record. 
)2)((log)( 2 +?= SCSPl )(SC
)2)((log)( 2 +?=? SCSPl , )(SC ?  is the total number 
of S in the Chinese Location Names Record. 
The lexical probability of the location name 
LN is defined as                           
),(/))()()(( 0 LNLenSPFPFPLN lfh ++= +    (14) 
where Len(LN) is the length of the evaluated lo-
cation name LN.                                 
2) contextual probability based on POS tags CP 
(LN) 
Location names also have characteristic 
contexual POS tags in real Chinese texts, for 
example, in the phrase ?zai Chongqing shi 
junxing (to be held in Chongqing)?, the POS tag 
before the location name ?Chongqing?is 
prepnoun and verb occurs after the location name. 
We define the bigram contextual probability 
CP(LN) of the location name LN similar to that 
of the person name PN in equation (9), where PN 
is replaced with LN. 
4 Recognition of Chinese Named Entity 
Using Hybrid Model 
Analyzing the classification results (obtained by 
sole SVMs described in section 2) between B 
and I, B and O, I and O respectively, we find that 
the error is mainly caused by the second classifi-
cation. The samples which attribute to B class 
are misclassified to O class, which leads to B 
class vote?s diminishing and the corresponding 
named entities are lost. Therefore the Recall is 
lower. In the meantime, the number of the mis-
classified samples whose function distances to 
the hyperplane of SVM in feature space are less 
than 1 can reach over 83% of the number of total 
misclassified samples. That means the misclassi-
75
fication of a classifier is occurred in the region of 
two overlapping classes. Considering this fact, 
we can expect to improve SVM using the follow-
ing hybrid model. 
The hybrid model includes the following 
procedure: 
1) compute the distance from the test sample 
to the hyperplane of SVM in feature space.  
2) compare the distance with given threshold. 
The algorithm of hybrid model can be de-
scribed as follows: 
Suppose T is the testing set, 
(1) if  ??T , select Tx? , else stop; 
(2) compute  ?
=
+?= l
i
ii bxxKyxg
1
),()(
(3) if ?>)(xg , output 
, else use the statistic 
models and output the returned results. 
[ ]1,0??
))(sgn()( xgxf =
(4) , repeat(1) { }xTT ??
5 Experiments 
Our experimental results are all based on the 
corpus of Peking University. 
5.1 Extracting Chinese Person Names 
We use 180 thousand characters corpus of year 
1998 from the People?s Daily as the training cor-
pus and extract other sentences (containing 1526 
Chinese person names) as testing corpus to con-
duct an open test experiment. The results are ob-
tained as follows based on different models. 
1) Based on Sole SVM 
An experiment is carried out to recognize Chi-
nese person names based on sole SVM by the 
method as described in Section 2. The Recall, 
Precision and F-measure using different number 
of degree of polynomial kernel function are 
given in Table 4. The best result is obtained 
when d=2. 
 
 Recall Precision F-measure 
d=1 87.22% 94.26% 90.61% 
d=2 87.16% 96.10% 91.41% 
d=3 84.67% 95.14% 89.60% 
Table 4. Results for Person Names Extraction 
Based on Sole SVM 
 
2) Using Hybrid Model 
As mentioned in section 4, the test samples 
which attribute to B class are misclassified to O 
class and therefore the Recall for person names 
extraction from sole SVM is lower. So we only 
deal with the test samples (B class and O class) 
whose function distances to the hyperplane of 
SVM in feature space (i.e. g(x)) is between 0 and 
? . We move class-boundary learned by SVM 
towards the O class, that is, the O class samples 
are considered as B class in that area. 93.64% of 
the Chinese person names in testing corpus are 
recalled when ? =0.9 (Here, ?  also represents 
how much the boundary is moved). However, a 
number of non-person names are also identified 
as person names wrongly and the Precision is 
decreased correspondingly. Table 5 shows the 
Recall and Precision of person names extraction 
with different ? .  
 
 Recall Precision F-measure
? =1 93.05% 75.17% 83.16% 
? =0.9 93.64% 81.75% 87.29% 
? =0.8 93.51% 85.91% 89.55% 
? =0.7 93.05% 88.31% 90.62% 
? =0.6 92.39% 90.21% 91.29% 
? =0.5 91.81% 91.87% 91.84% 
? =0.4 91.02% 93.28% 92.13% 
? =0.3 90.56% 95.05% 92.75% 
? =0.2 90.03% 95.48% 92.68% 
? =0.1 88.66% 95.82% 92.10% 
Table 5. Results for Person Names Extraction 
with Different ?  
 
We use the evaluated function TotalProbabil-
ity(PN) as described in section 3 to filter the 
wrongly recalled person names using SVM. We 
tune?  in equation (5) to obtain the best results. 
The results based on the hybrid model with dif-
ferent ?  are listed in Table 6 (when d=2). We 
can observe that the result is best when ? =0.4. 
Table 7 shows the results based on the hybrid 
model with different ?  when =0.4. We can 
observe that the Recall rises and the Precision 
drops on the whole when 
?
?  increases. The syn-
thetic index F-measures are improved when ?  is 
between 0.1 and 0.8 compared with sole SVM. 
The best result is obtained when ? =0.3. The Re-
call and the F-measure increases 3.27% and 
1.77% respectively. 
 
 Recall Precision F-measure
? =0.1 90.37% 95.76% 92.99% 
? =0.2 90.37% 96.03% 93.11% 
? =0.3 90.43% 96.03% 93.15% 
? =0.4 90.43% 96.10% 93.18% 
? =0.5 90.63% 95.76% 93.13% 
? =0.6 90.43% 95.97% 93.12% 
76
? =0.7 90.43% 95.90% 93.09% 
? =0.8 90.43% 95.90% 93.09% 
? =0.9 90.37% 95.90% 93.05% 
Table 6. Results for Person Names Extraction 
Based on The Hybrid Model with Different?  
 
 Recall Precision F-measure
? =1 92.53% 84.96% 88.58% 
? =0.9 93.05% 88.81% 90.88% 
? =0.8 92.86% 90.95% 91.89% 
? =0.7 92.46% 92.04% 92.25% 
? =0.6 91.93% 93.22% 92.58% 
? =0.5 91.48% 94.26% 92.85% 
? =0.4 90.76% 95.25% 92.95% 
? =0.3 90.43% 96.10% 93.18% 
? =0.2 90.04% 96.15% 92.99% 
? =0.1 88.73% 96.23% 92.32% 
Table 7. Results for Person Names Extraction 
Based on The Hybrid Model ( =0.4) ?
5.2 Extracting Chinese Location Names 
We use 1.5M characters corpus of year 1998 
from the People?s Daily as the training corpus 
and extract sentences of year 2000 from the Peo-
ple?s Daily (containing 2919 Chinese location 
names) as testing corpus to conduct an open test 
experiment. The results are obtained as follows 
based on different models. 
1) Based on Sole SVM 
The Recall, Precision and F-measure using 
different number of degree of polynomial kernel 
function are given in Table 8. The best result is 
obtained when d=2. 
 
 Recall Precision F-measure 
d=1 84.66% 91.95% 88.16% 
d=2 86.69% 93.82% 90.12% 
d=3 86.27% 94.23% 90.07% 
Table 8. Results for Location Names Extraction 
Based on Sole SVM 
 
2) Using Hybrid Model 
The results for Chinese location names extrac-
tion based on the hybrid model are listed in Ta-
ble 9 (when d=2; ? =0.2 in equation (10)). We 
can observe that the Recall rises and the Preci-
sion drops on the whole when ?  increases. The 
synthetic index F-measures are improved when 
?  is between 0.1 and 0.7 compared with sole 
SVM. The best result is obtained when ? =0.3. 
The Recall increases 3.55%, the Precision de-
creases 1.05% and the F-measure increases 
1.37%. 
 Recall Precision F-measure
? =1 90.75% 83.00% 86.71% 
? =0.9 90.85% 85.33% 88.01% 
? =0.8 91.42% 87.42% 89.37% 
? =0.7 91.65% 89.05% 90.33% 
? =0.6 91.75% 90.38% 91.06% 
? =0.5 91.32% 90.98% 91.15% 
? =0.4 90.66% 91.87% 91.26% 
? =0.3 90.24% 92.77% 91.49% 
? =0.2 89.10% 93.28% 91.15% 
? =0.1 87.83% 93.38% 90.52% 
Table 9. Results for Location Names Extraction 
Based on The Hybrid Model (?=0.2) 
6 Comparison with other work 
The same corpus was also tested using statistics-
based approach to identify Chinese person names 
(Huang et al 2001) and location names (Huang 
and Yue, 2003). In their systems, lexical reliabil-
ity and contextual reliability were used to iden-
tify person names and location names calculated 
from statistical information drawn from a train-
ing corpus. The results of our models and the 
statistics-based methods (Huang 2001; Huang 
2003) are shown in Table 10 for comparison. We 
can see that the Recall and F-measure in our 
method all increase a lot.  
 
 Recall Precision F-measure
Our 
models 90.10% 96.15% 93.03%Person 
names Huang
(2001) 88.62% 92.37% 90.46%
Our 
models 90.24% 92.77% 91.49%Location 
names Huang
(2003) 86.86% 91.48% 89.11%
Table 10. Results of Our Method and Huang 
(2001; 2003) for Comparison 
7 Conclusions and Future work 
We recognize Chinese named entities using a 
hybrid model combining support vector ma-
chines with statistical methods. The model inte-
grates the advantages of two methods and the 
experimental results show that it can achieve 
higher F-measure than the sole SVM and indi-
vidual statistical approach. 
  Future work includes optimizing statistical 
models, for example, we can add the probability 
information of Chinese named entities in real 
texts to compute lexical probability, and we can 
77
also use trigram models to compute contextual 
probability. 
The hybrid model is expected to extend to for-
eign names in transliteration to obtain improved 
results by sole SVMs. The identification of trans-
literated names by SVMs has been completed (Li 
et al, 2004). The future work includes: set up 
statistical models for transliterated names and 
combine statistical models with SVMs to identify 
transliterated names. 
References 
William J. Black and Argyrios Vasilakopoulos. 2002. 
Language Independent Named Entity Classifica-
tion by Modified Transformation-based Learning 
and by Decision Tree Induction. The 6th Confer-
ence on Natural Language Learning, Taipei. 
Andrew Eliot Borthwick. 1999. A Maximum Entropy 
Approach to Named Entity Recognition. PhD Dis-
sertation. New York University. 
Xavier Carreras, Lluis Marquez, and Lluis Padro. 
2002. Named Entity Extraction Using AdaBoost. 
The 6th Conference on Natural Language Learning, 
Taipei. 
Michael Collins. 2002. Ranking Algorithms for 
Named-entity Extraction: Boosting and the Voted 
Perceptron. Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL-2002), Philadelphia, 489-496. 
Chooi-Ling Goh, Masayuki Asahara and Yuji Ma-
tsumoto. 2003. Chinese Unknown Word Identifica-
tion Based on Morphological Analysis and Chunk-
ing. The Companion Volume to the Proceedings of 
41st Annual Meeting of the Association for Compu-
tational Linguistics (ACL-2003), Sapporo, 197-200. 
De-Gen Huang, Yuan-Sheng Yang, and Xing Wang. 
2001. Identification of Chinese Names Based on 
Statistics. Journal of Chinese Information Process-
ing, 15(2): 31-37. 
De-Gen Huang and Guang-Ling Yue. 2003. Identifi-
cation of Chinese Place Names Based on Statistics. 
Journal of Chinese Information Processing, 17(2): 
46-52. 
Thorsten Joachims. 1998. Text Categorization with 
Support Vector Machines: Learning with Many 
Relevant Features. In Proceedings of the European 
Conference on Machine Learning, 1398:137-142. 
Taku Kudo and Yuji Matsumoto. 2001. Chunking 
with Support Vector Machines. In Proceedings of 
NAACL 2001. 
Li-Shuang Li, Chun-Rong Chen, De-Gen Huang and 
Yuan-Sheng Yang. 2004. Identifying Pronuncia-
tion-Translated Names from Chinese Texts Based 
on Support Vector Machines. Advances in Neural 
Networks-ISNN 2004, Lecture Notes in Computer 
Science, Berlin Heidelberg, 3173: 983-988. 
Scott Miller and Michael Crystal. 1998. BBN: De-
scription of the SIFT System as Used for MUC-7. 
Proceedings of 7th Message Understanding Con-
ference, Washington. 
David D. Palmer. 1997. A Trainable Rule-Based Al-
gorithm for Word Segmentation. In Proc of 35th of 
ACL & 8th conf. of EACL, 321-328. 
Wen Qin and Chun-Fa Yuan. 2004. Identification of 
Chinese Unknown Word Based on Decision Tree. 
Journal of Chinese Information Processing, 18(1): 
14-19. 
Erik Tjong Kim Sang. 2002. Memory-based Named 
Entity Recognition. The 6th Conference on Natural 
Language Learning, Taipei. 
Koichi Takeuchi and Nigel Collier. 2002. Use of 
Support Vector Machines in Extended Named En-
tity Recognition. The 6th Conference on Natural 
Language Learning, Taipei. 
Vladimir N. Vapnik. 1995. The Nature of Statistical 
Learning Theory. Springer-Verlag, Berlin. 
Vladimir N. Vapnik. 1998. Statistical Learning The-
ory. John Wiley & Sons, New York. 
Ying Yu, Xiao-Long Wang, Bing-Quan Liu, and Hui 
Wang. 2004. Efficient SVM-based Recognition of 
Chinese Personal Names. High Technology Letters, 
10(3): 15-18. 
Jun-Sheng Zhang, Shun-De Chen, Ying Zheng, Xian-
Zhong Liu and Shu-Jin Ke. 1992. Large-Corpus-
Based Methods for Chinese Personal Name. Jour-
nal of Chinese Information Processing, 6(3): 7-15. 
Guo-Dong Zhou and Jian Su. 2002. Named Entity 
Recognition Using an HMM-based Chunk Tagger. 
Proceedings of the 40th Annual Meeting of the 
ACL, Philadelphia, 473-480. 
 
 
78
Coling 2010: Poster Volume, pages 472?480,
Beijing, August 2010
Mining Large-scale Comparable Corpora from Chinese-English 
News Collections 
Degen Huang1                Lian Zhao2                Lishuang Li 3               Haitao Yu4 
Department of Computer Science and Technology 
Dalian University of Technology 
1huangdg@dlut.edu.cn              3lils@dlut.edu.cn 
2zhaolian@mail.dlut.edu.cn        4gengshenspirit@163.com 
 
Abstract 
In this paper, we explore a CLIR-based  
approach to construct large-scale Chi-
nese-English comparable corpora, which 
is valuable for translation knowledge 
mining. The initial source and target 
document sets are crawled from news 
website and standardized uniformly. 
Keywords are extracted from the source 
document firstly, and then the extracted 
keywords are translated and combined as 
query words through certain criteria to 
retrieve against the index created using 
target document set. Meanwhile, the 
mapping correlations between source and 
target documents are developed accord-
ing to the value of similarity calculated 
by the retrieval tool. Two methods are 
evaluated to filter the comparable docu-
ment pairs so as to ensure the quality of 
the comparable corpora. Experimental re-
sults indicate that our approach is effec-
tive on the construction of Chinese-
English comparable corpora. 
1 Introduction 
Parallel corpora are key resource for statistical 
machine translation, in which machine learning 
techniques are used to learn translation knowl-
edge. Sufficient data is necessary for the data-
driven approaches to estimate the model parame-
ters reliably. However, as Munteanu (2006) 
stated, beyond a few resource-rich language pairs 
such as English-Chinese or English-French and a 
small number of contexts like parliamentary de-
                                                 
 This work was supported by Microsoft Research Asia. 
bates or legal texts, parallel corpora remain a 
scarce resource, despite the proposition of auto-
mated methods to collect parallel corpora from 
the Web. Researches on comparable corpora are 
motivated by the scarcity of parallel corpora. 
Compared with parallel corpora, comparable 
corpora are more abundant, up-to-date and ac-
cessible. 
Comparable corpora are defined as pairs of 
monolingual corpora selected according to the 
same set of criteria, but in different languages or 
language varieties. When creating comparable 
corpora, the key process is to align the source 
document with relevant target documents. Early 
work by Braschler and Sc?uble (1998) employed 
content descriptors and publication dates to align 
German and Italian news stories. Resnik (1999) 
mined comparable corpora on the assumption 
that the pages which are comparable of each 
other share a similar structure (headers, para-
graphs, etc.) when text is presented in many lan-
guages in the Web. Tao and Zhai (2005) acquired 
comparable bilingual text corpora based on the 
observation that terms that are translations of 
each other or share the same topic tend to co-
occur in the comparable corpora at the 
same/similar time periods. Recently, Talvensaari 
et al (2007) introduced a CLIR-based approach 
to align two document collections with different 
languages. All the target documents were in-
dexed with Lemur. Then appropriate keywords 
were extracted from the source language docu-
ments and translated into the target language as 
query words to retrieve similar target documents. 
As we know, the problems may vary with the 
language of documents when using CLIR-based 
approach to construct comparable corpora, such 
as keyword extraction, out-of-vocabulary key-
word translation and so on. This paper is a fur-
ther endeavor to CLIR-based approach for com- 
472
 
Figure 1. The general architecture of comparable corpora construction 
parable corpora construction. We focus on the 
construction of Chinese-English comparable cor-
pora, explore and address the issues during the 
construction. Experimental results show that our 
method is better through a rough comparison 
with Talvensaari et al (2007) and it also outper-
forms our reconstruction of Tao and Zhai (2005) 
in respect to the quality of comparable corpora. 
This paper is organized as follows. In section 2, 
the general architecture of our system is de-
scribed, and each module is illuminated in detail. 
Section 3 reports and analyzes the experimental 
results followed by conclusions in section 4.  
2 System Architecture 
Figure 1 shows the general architecture of our 
comparable corpora construction system. It con-
sists of two components: component I and com-
ponent II. Component I is mainly composed by a 
web crawler, which is used to harvest source and 
target documents from selected web sites. We 
can get the final source and target document sets 
through content extraction and noise filtering. 
The core of the system is component II, which 
aligns a source document with target documents 
having comparable contents. It implements on 
the two document sets generated by component I. 
Component II is composed of three modules: 
keyword extraction, keyword translation, and 
retrieval & filtering. The methods for three mod-
ules are detailed respectively. 
2.1 Keyword Extraction 
A keyword is described as a meaningful and sig-
nificant expression containing one or more words. 
Appropriate keywords briefly describe the theme 
of a document. In this paper, keywords are 
viewed as basic units of search indexes in order 
to retrieve closely related documents. Generally, 
phrases can capture the main idea of a document 
more effectively, inasmuch as they have more 
information than single words (an independent 
linguistic unit after word segmentation for Chi-
nese). 
Existing approaches for keyword extraction 
could be distinguished into two main categories: 
supervised or unsupervised methods. Supervised 
machine learning algorithms were widely used in 
keyword extraction such as Na?ve Bayes (Frank 
et al, 1999; Witten et al, 1999), SVM (Zhang et 
al., 2006), CRF (Zhang et al, 2008), etc. These 
approaches had excellent stability. However, it 
was difficult for us to construct a big-enough 
golden annotated corpus to train a good classifier, 
especially for news web pages. Unsupervised 
methods hinged on evaluating various features to 
select keywords, such as word frequency (Luhn, 
1957), word co-occurrence (Matsuo and Ishizuka, 
2004), and TF*IDF (Li et al, 2007). The inher-
ent problem in these methods was that most of 
their work came in the judgment whether a can-
didate was a keyword or not, but they had not 
paid sufficient attention to the identification of 
phrase candidates. Wan and Xiao (2008) pro-
posed a method for keyphrase extraction from 
single document. However, it simply combined 
the adjacent candidate words to a multi-word 
phrase. 
Based on the above observation, our approach 
for keyword extraction focuses more on the con-
struction of phrasal candidates. It is mainly based 
on MWE (Multi-Word Expression) extraction 
together with relevant word ranking method. 
473
MWE is a special lexical unit including com-
pound terms, idioms and collocations, etc. The 
process of keyword extraction in this paper 
mainly depends on the following stages. 
Stage 1: The generation of phrasal candidates 
(1) The extraction of MWEs from the preproc-
essed document 
Document preprocessing is a procedure of 
morphological analysis including segmentation 
and part of speech tagging for Chinese. The 
method based on the marginal probabilities de-
tailed in (Luo and Huang, 2009) is adopted in 
this part. 
We extract MWEs using LocalMaxs selection 
algorithm together with a relevance measure cal-
culation method (FSCP) proposed by Silva et al 
(1999). Suffix arrays and related structures in 
(Aires et al, 2008) are used to compute the FSCP 
value so as to raise efficiency. And the initial col-
lection of MWEs named G for the document is 
generated after filtered by stopword list. 
(2) The acquisition of new MWEs through the 
modification for segmentation 
As a matter of fact, the results of segmentation 
for the document usually have some errors espe-
cially for out-of-vocabulary (OOV) words which 
are segmented to single Chinese characters in 
most cases. Inaccurate segmentation leads to 
some faults for keyword extraction. As stated in 
(Liu et al, 2007), OOV words can be identified 
by the method of MWEs extraction mentioned 
above. Therefore, we modify the segmentation 
like this: any MWE in G is merged to one word 
if it only consists of single Chinese characters 
and its frequency > freq. The changes before and 
after merging are shown in Table 1. Because the 
method of MWE extraction is based on statistical 
techniques, so low frequency of MWE will result 
in poor performance. But large value for freq 
means that very few MEWs can satisfy the fre-
quency restriction. In our experiments, we set 
freq=2. The extraction process is called again to 
identify MWEs from the document with modi-
fied segmentation. Consequently, new collection 
of MWEs is acquired. 
Additionally, some simple rules are defined 
according to language features to filter MWEs. 
In this paper, our method is tailored to extract 
keywords from news web pages which contain 
some special symmetric marks like ??, ??. The 
words in a specially marked area are usually im-
portant to the document. So we extract words 
within each paired marks and view them as a 
MWE on the condition that it contains two or 
more than two words. All of the MWEs are 
viewed as phrasal candidates and filtered by 
stopword list. 
Stage 2: The generation of single words candi-
dates 
Our method also generates single word candi-
dates with the account that both phrase and sin-
gle word can be served as a keyword. The proc-
ess of single word selection is independent of 
MWE extraction. The candidate words are re-
stricted to nouns, verbs, strings (like WTO) and 
merged words as discussed in the previous stage. 
But the word will be removed if it only appears 
once in the document or is contained in the 
stopword list. 
Stage 3: Keyword selection based on candidates 
ranking 
As for MWE candidates, we calculate the 
weight for them using Formula 1 which refers to 
the formula used to sort NP phrases in (Brace-
well et al, 2008). But the weight of len is re-
duced. 
1
( ) log(
1 ( ))
MWE
len
ii
Weight MWE len f
tf w
len =
= + +
??        (1) 
Where len is the length of MWE (in number of 
words); fMWE is the frequency of the MWE within 
in the document; tf(wi) is the frequency of word 
wi. The following rules are used to rank MWEs: 
MWE Segmentation before merging 
Segmentation 
after merging 
Pos  
before merging 
Pos  
after merging 
? ? ?/ ?/ ?/ ?/ ?/ ??/ ?/ ?/ 
?/ ?/ ??/ ?/  
??/ ?/ ?/ 
?/n ?/n ?/n ?/n 
?/vl ??/n ?/us 
?/a 
?/n ?/n ??/oov 
?/vl ??/n ?/us  
?/a 
? ? ?/ ?/ ??/ ?/ ??/ ??/ ?/ ? /jb ? /n ?? /b ?/n 
??/oov ??/b  
?/n 
Table 1. Changes before and after merging 
474
(a) more frequent MWEs are ranked higher; (b) 
MWEs with larger weight are ranked higher. In 
order to avoid redundancy, we remove the re-
dundant MWEs with lower rank. 
Single word candidates are ranked as follows: 
(a) the single word w with larger TF*IDF value 
is ranked higher; (b) the pos score for w in de-
scending order is: named entity, merged words, 
nouns, strings, verbs. In the end, top-a MWEs 
and top-b single words are chosen to form the 
keyword set of the document. 
Stage 4: Parameters evaluation and experimental 
results 
The max number of keywords extracted from 
each document is limited to ten (a+b=10) and we 
run our approach on the dataset which include 
one hundred Chinese documents from the corpus 
of NTCIR-5 since they are also news articles. 
For evaluation of the results, the keywords ex-
tracted by our method are compared with the 
manually extracted keywords (at most ten key-
words are assigned to each document). The F-
measure is used as evaluation metric. It is de-
fined like this: F=(P+R)/2; P=nummatch/numsystem; 
R=nummatch/nummanual. Where nummatch is the 
count of keywords extracted by our method 
matching with manually extracted keywords; 
numsystem is the count of keywords extracted by 
our method; nummanual is the count of keywords 
assigned by human. 
Figure 2 shows the performance curves for our 
extraction method. In this figure, a ranges from 0 
to 10 while b is 10 to 0. It performs best when a 
= 4 and b = 6. So the two values are adopted in 
this paper. 
 
Figure 2. F-measure varies with the value of a 
We test our approach on another dataset which 
also contains one hundred documents. In the ex-
periments, the max number of keywords is set to 
ten. Table 2 shows the results of keyword extrac-
tion under three different conditions respectively. 
(A) Only extracts single words as keywords 
while just MWEs with (B). (C) The method pre-
sented in this paper which makes a proper com-
bination of MWEs and single words. 
 P R F 
A (single words)  24.2% 28.5% 26.4% 
B (MWEs)  18.1% 23.0% 20.6% 
C (A+B)  34.2% 43.6% 38.9% 
Table 2. Keyword extraction results 
2.2 Keyword Translation 
As for keyword translation, there are three main 
approaches: translation based on dictionary, par-
allel corpora and machine translation. Dictionary 
based approach is adopted in our system by tak-
ing the acquisition of translation resource into 
account. 
Word Sense Disambiguation (WSD) and OOV 
problem are the main difficulties in CLIR (Cross 
Language Information Retrieval) task. A typical 
bilingual dictionary will provide a set of alterna-
tive translations for a given keyword, so how to 
choose the optimal translation is called Word 
Sense Disambiguation. Actually some keywords 
can not be found and translated due to the cover-
age limitation of a bilingual dictionary, which is 
called OOV problem. 
In this paper, the keyword is given up if its 
size of translations gained from the bilingual dic-
tionary is larger than two for the convenience of 
WSD. Additionally, both of the translations are 
treated as synonyms and equal weight is assigned 
to them when retrieval. 
To address the OOV problem, researchers pro-
posed methods using snippets returned by a 
search engine. For example, Wang et al (2004) 
introduced a statistics-based approach called 
SCPCD to mine translations from the returned 
snippets. Different from (Wang et al, 2004), 
Zhou et al (2007) used a pattern-based approach 
to analyze the mixed-languages snippets. 
Leveraging on previous work, we analyze the 
co-occurrence mode of the OOV term and the 
corresponding translation in the returned snippets. 
Table 3 shows the typical co-occurrence modes 
collected during experiments, where the English 
words in bold are the corresponding translations 
of the underlined Chinese OOV terms. From Ta-
ble 3, we can see the translations in number 1, 2 
and 3 are included in the symmetric symbols, 
like bracket, quotation marks. However, the 
475
Serial  
number Segments extracted from the returned snippets 
1 ???????????????The Bridges of Madison County??????? 
2 ???????????The Bridges of Madison County?-52???... 
3 ???????????????cowboy diplomacy????????????? 
4 ...???????????? Bayesian Network for Data Mining-????... 
5 ?????????????The End of Cowboy Diplomacy????????? 
6 ?????????. The Bridges of Madison County. Forrest Gump ????... 
Table 3. Chinese OOV and the corresponding translation in returned snippets 
translations in number 4, 5, and 6 are embedded 
in the partial sentence while there are noise Eng-
lish words. In order to get the correct translation, 
the partial sentence needs to be segmented. By 
above analysis, we integrate the SCPCD method 
and the pattern-based method so as to extract 
more correct translations. The SCPCD method 
can be used to determine the boundaries for 
OOVs like number 4, 5, and 6; while pattern-
based method makes use of the symmetric sym-
bols like number 1, 2 and 3. Table 4 shows the 
experimental results for OOV translation meth-
ods. The average top-n inclusion rate is adopted 
as a metric. For a set of test OOV terms, its top-n 
inclusion rate is defined as the percentage of the 
OOVs whose translations can be found in the 
first n extracted translations. 
 Pattern SCPCD Pattern + SCPCD 
Top-1 40.0% 49.2% 68.1% 
Top-3 41.5% 55.4% 70.2% 
Table 4. The performance comparison of differ-
ent OOV translation methods 
The test dataset used is the Chinese topic 
terms in CLIR task of NTCIR-5. The search en-
gine is Google. The bilingual dictionary used by 
us is LDC_CE_DICT 2.0. And we only adapt the 
pattern with symmetric symbols, which has the 
highest precision proposed by Cao et al (2007). 
2.3 Retrieval and Filtering 
The process of retrieval is to construct the align-
ment relationship between source and target 
document pairs. It is a core module in our system 
since the quality of comparable corpora is greatly 
influenced by alignment level which depends on 
the relevance between document pairs. Our in-
tention here is to retrieve high relevant target 
documents for the source documents. Open-
source toolkit Indri is introduced to assist the 
retrieval process. Indri is a part of the Lemur pro-
ject1. On the basis of Lemur, it combines infer-
ence networks with language modeling. And it?s 
widely adopted by institution for scientific re-
search since it is effective, flexible, usable and 
powerful. So it is employed by us to retrieve re-
lated documents. A query for each source docu-
ment is formed by the translated keywords with 
Indri query language and then run against the 
target collection. 
The essential of alignment is to compare the 
similarity between source and target document 
pairs. In order to reduce the workload of compar-
ing, Pooling method is applied to assist the com-
paring process. We choose the top r documents 
returned by Indri retrieval system to build the 
related document pool. And g (g<=r) documents 
in the pool are selected to form the alignment 
document pairs together with the source docu-
ment. In our experiments, we set r=10 and g=1. 
In the process of alignment, three features are 
used to filter the alignment pairs for the sake of 
pruning the low relevant pairs. The first is publi-
cation date contained in documents. The second 
is similarity calculated by Indri between the 
query and the target document when retrieval. 
The last is KSD (Keyword similarity between 
document pairs) which is defined by our system. 
In this paper, we propose two methods to filter 
the alignment pairs by using various features. 
(1) DSF filtering 
This method depends on two features: date 
and similarity. At first, we give a priority to the 
target documents that have the closest date to the 
source document during the top-r documents 
searching. A date-window size d is defined to 
measure the date difference. We set d=1 in this 
paper. That is to say, the target documents with 
                                                 
1 Lemur toolkit is developed by Carnegie Mellon University 
and University of Massachusetts. The open source code is 
available at http://www.lemurproject.org. 
476
exactly the same date as the source document, 
and one day earlier or later are considered to be 
closest. Then, we select g documents with larger 
similarity from the related document pool. Fi-
nally, we rank all of the alignment pairs with the 
score of similarity and set a similarity threshold s 
to filter further. It should be noted that there are 
n ? g alignment pairs, where n is the number of 
source documents having non-empty related 
document pool. 
(2) DSKF filtering 
This method utilizes all of the features: date, 
similarity and KSD. As for KSD, it integrates 
two factors. One is NTK, namely the number of 
translated keywords appeared in the target 
document, since the target document is more 
similar to the source document as increasing of 
NTK. The other is FIS, namely frequency infor-
mation score. Inspired by paper (Tao and Zhai, 
2005), we use the score of FIS to measure the 
correlations between the keywords in source 
document and translated keywords in target 
document which represent the matching for 
source and target document pair. We define ds as 
the source document, dt as the target document, 
ks as the set of keywords extracted from ds, kts as 
the set of translated keywords. Formula 2 is used 
to compute the score of FIS: 
 1 ( 25( , ) ( )
25( , ) ( ) / ( ( , )))
ktsLen
FIS i s ii
i t i i i
Score BM x d IDF x
BM y d IDF y norm Dif x y
=
= ? ?
?
?  (2) 
Where, ktsLen is the size of kts, yi is an element 
in kts, xi is the element in ks while yi is the trans-
lation of xi. Moreover, BM25(w, d) is the normal-
ized frequency of word w in document d. It has 
been considered as one of the most effective 
matching functions for retrieval. IDF stands for 
Inverse Document Frequency which is also 
commonly used in information retrieval. Dif(x, y) 
is defined as the difference between BM25(x, ds) 
and BM25(y, dt). Formula 2 penalizes large dif-
ference due to the conditions like this: any key-
word in source document appears many times 
while its translation appears rarely in target 
document. The process of its normalization is run 
by Formula 3 which makes the score less sensi-
tive to the absolute value: 
1, 1( ) ,
scorenorm score score else
<?
= ??       (3) 
Furthermore, the final KSD score is got by 
simply adding the normalized scores of NTK and 
FIS which are dealt with Formula 3. Actually, the 
two filtering methods differ principally in the last 
step. DSKF sorts all of the alignment pairs ac-
cording to the KSD score while it is similarity in 
DSF. We also set a KSD threshold k for DSKF 
method to filter further. The values for s and k 
will be investigated in the following experiments. 
3 Experiments 
In this section, we first introduce how to acquire 
the source and target document sets. Then our 
system is tested on the two sets. The experimen-
tal results are reported and analyzed finally. 
3.1 Experiment Setup 
To test the effectiveness of the proposed system, 
large-scale of Chinese and English news web 
pages are crawled respectively from XinHuaNet 
and used as the document resource. The reasons 
for choosing news pages are: 
(1) Many websites, like portal website, news 
agency, government and so on, provide large-
scale news reports. At the same time, a large pro-
portion of the reports can be crawled politely, so 
document acquisition is relatively easy. 
(2) The news pages include various contents, 
such as politics, economy, sports, so the corpora 
made up of news pages can avoid the limitations 
of domain-specific corpora. 
All the news pages are processed uniformly. 
The core content of each web page crawled is 
extracted and several tags describing the headline 
and publication date are added. Meanwhile, the 
original contents are kept with no change. Table 
5 shows the basic information of document sets.  
Year Number of source documents 
Number of target 
documents 
2003 23747 3390 
2004 25660 2943 
2005 47333 11578 
2006 28572 25320 
2007 25036 25247 
2008 14021 24292 
2009 7476 10887 
Total 171845 103657 
Table 5. The composition of source document set 
and target document set 
3.2 Results and Discussion 
The quality of comparable corpora highly de-
477
pends on the alignment level between source and 
target document pairs. Braschler and Sc?uble 
(1998) used five levels of relevance to assess the 
alignments as follows: 
(1) Same story. The two documents deal with 
the same event.  
(2) Related story. The two documents deal 
with the same event or topic from a slightly dif-
ferent viewpoint. Alternatively, the other docu-
ment may concern the same event or topic, but 
the topic is only a part of a broader story or the 
article is comprised of multiple stories. 
(3) Shared aspect. The documents deal with 
related events. They may share locations or per-
sons. 
(4) Common terminology. The events or topics 
are not directly related, but the documents share 
a considerable amount of terminology. 
(5) Unrelated. The similarities between the 
documents are slight or nonexistent.  
We randomly select 500 source documents 
published in 2009 as the test dataset. Experi-
ments with different parameters are constructed 
based on this dataset. The quality of each align-
ment pair is manually assessed using the five-
level relevance as discussed above. What should 
to be pointed out is that parameter s and k are not 
absolute values, but percentile rank level in our 
work. For instance, k = 10 means that we only 
choose the alignment pairs whose KSD score 
rank in top ten percent among all of the results. 
Table 6 shows the results filtered by DSF 
method with different values of s (s1 < s2 < s3 < 
s4 ). Table 7 shows the results filtered by DSKF 
method with various values of k (k1 < k2 < k3 < 
k4). In order to evaluate the results conveniently, 
two standards are established: (a) the number of 
high relevant pairs created, which is the count of 
document pairs in Level 1 and 2; (b) the quality 
of the whole alignments, that is to say the per-
centage of alignment pairs with Level 1 and 2. 
Seen from Table 6 and 7, DSKF is better than 
DSF by considering the two standards. Com-
pared with DSF, more high relevant pairs are left 
filtered by DSKF when they have the same total 
number of pairs. In other words, the DSKF 
method is more powerful to make high relevant 
pairs in higher rank so as to reduce alignment 
pairs which are rarely relevant. Therefore, DSKF 
is adopted in our system. Taking the first crite-
rion into account, we give up the parameter k1, k2. 
Parameter k4 is not the best considering the sec-
ond criterion. Ultimately, k3 is chosen as the final 
value for k. At this point, the number of align-
ment pairs in Level 1 and 2 is close to the maxi-
mum. Meanwhile, the percentage of high align-
ments reaches 68.5%. 
Among the surveyed related work, Talvensaari 
et al (2007) created Swedish-English compara-
ble corpora based on CLIR techniques and its 
framework of construction is similar to ours. 
However, the two systems are different in the 
following aspects: 
s1 = 10 s2 = 30 s3 =50 s4 =70 Level Number % Number % Number % Number % 
Leve1 1 23 46.9% 54 36.5% 83 33.5% 96 27.7% 
Level 2 18 36.7% 43 29.1% 62 25.0% 81 23.3% 
Level 3 4 8.2% 21 14.2% 40 16.1% 57 16.4% 
Level 4 4 8.2% 19 12.8% 41 16.5% 60 17.3% 
Level 5 0 0.0% 11 7.4% 22 8.9% 53 15.3% 
Total 49 100% 148 100% 248 100% 347 100% 
Table 6. The distribution results filtered by DSF with different s parameters 
k1 = 10 k2 = 30 k3 = 50 k4 =70 Level Number % Number % Number % Number % 
Level 1 33 67.3% 78 52.7% 93 37.5% 98 28.2% 
Level 2 15 30.6% 52 35.1% 77 31.0% 89 25.6% 
Level 3 1 2.0% 9 6.1% 37 14.9% 62 17.9% 
Level 4 0 0.0% 9 6.1% 34 13.7% 60 17.3% 
Level 5 0 0.0% 0 0.0% 7 2.8% 38 11.0% 
Total 49 100% 148 100% 248 100% 347 100% 
Table 7. The distribution results filtered by DSKF with different k parameters 
478
(1) The language is different. We focus on 
building comparable corpora of Chinese-English 
while they were Swedish-English. 
(2) A series of sub problems are different due 
to language difference. As for keyword extrac-
tion, we propose a method to select both key 
phrases and single words, while they used RATF 
(Relative Average Term Frequency) method. For 
OOV problem, we combine the SCPCD method 
with the pattern-based method to extract OOV 
translations from snippets returned by a search 
engine. However, the classified s-gram matching 
technique was utilized by Talvensaari et al (2007) 
to translate OOV words. 
(3) Talvensaari et al (2007) filtered their 
alignment pairs mainly depending on date and 
similarity, while we introduce new feature KSD 
to extend the original feature set. 
Talvensaari et al (2007) also randomly chose 
500 source documents and assessed the quality 
of alignments using the same five-level relevance. 
In addition to this, we implement the method 
of Tao and Zhai (2005) which is a purely statisti-
cal-based and language independent approach. 
The source and target documents published in 
2009 are employed to test the method. The same 
sample as our system including 500 Chinese 
documents is chosen to make a further compari-
son with our work. We align each source docu-
ment with one target document through the 
BM25Corr model in (Tao and Zhai, 2005). The 
alignment pairs are ranked according to mapping 
scores calculated by the BM25Corr model. And 
we select the top N (N = 248) alignment pairs for 
the benefit of comparison.  
Table 8 shows the distribution results for the 
three systems. As illustrated in Table 8, we can 
roughly conclude that our approach creates more 
alignment pairs with the same number of source 
documents when compared with Talvensaari et al 
(2007). Meanwhile, the percentage of high rele-
vant document pairs is larger.  
Likewise, our system outperforms BM25Corr 
in that it aligns more high relevant documents 
pairs when they use the same sample of test cor-
pora and create the same total number of pairs. 
Obviously, the quality of comparable corpora 
gained by our system is better than BM25Corr. 
All the experimental results and analysis men-
tioned above indicate that our method is effective 
to create alignment pairs. Up to now, both the 
source and target documents published in 2007-
2009 years are used to build comparable corpora 
through our proposed system. It includes 23102 
alignment pairs after filtered by DSKF. 
Talvensaari et al  
(2007) 
Our System 
(DSKF filtering) 
BM25Corr 
(Top N = 248) Level 
Number % Number % Number % 
Level 1 21 21.6% 93 37.5% 1 0.4% 
Level 2 20 20.6% 77 31.0% 2 0.8% 
Level 3 33 34.0% 37 14.9% 3 1.2% 
Level 4 19 19.6% 34 13.7% 5 2.0% 
Level 5 4 4.1% 7 2.8% 237 95.6% 
Total 97 100% 248 100% 248 100% 
Table 8. The distribution results for Talvensaari et al (2007), Our System, and BM25Corr 
4 Conclusions 
In this paper, we propose a CLIR-based approach 
to create large-scale Chinese-English comparable 
corpora. Firstly, we harvest the original source 
and target document sets from news website us-
ing open-source crawler. Then the core content 
of each document is extracted through discrimi-
nating noise contents. Next, we delve into the 
approaches of problems such as keyword extrac-
tion and OOV translation followed by the proc-
ess of retrieval to develop mapping correlations 
between source and target documents. Finally, 
three features as publication date, similarity 
score and KSD value are used to filter the 
aligned document pairs. Experimental results 
show that our approach is effective to mine Chi-
nese-English document pairs with comparable 
contents. In the future, we will optimize the ap-
proach for every module in the construction of 
comparable corpora for the sake of improving 
the performance of the whole system. What?s 
more, it will be worth consideration to mine 
mappings between terms which can be served as 
a feature for the process of developing mappings 
between document pairs in turn. 
479
References 
Aires, Jos?, Gabriel Lopes, and Joaquim Ferreira 
Silva. 2008. Efficient Multi-word Expressions Ex-
tractor Using Suffix Arrays and Related Structures. 
In Proceeding of the 2nd ACM workshop on Imp-
roving non english web searching, pp. 1-8.  
Bracewell, David B., Fuji Ren, and Shingo Kuroiwa. 
2008. Mining News Sites to Create Special Do-
main News Collections. International Journal of 
Computational Intelligence, 4(1): 56-63. 
Braschler, Martin, and Peter Sc?uble. 1998. Multilin-
gual Information Retrieval Based on Document 
Alignment Techniques. In Proceedings of the 2nd 
European Conference on Research and Advanced 
Technology for Digital Libraries, pp. 183-197. 
Cao Guihong, Jianfeng Gao, and Jianyun Nie. A Sys-
tem to Mine Large-Scale Bilingual Dictionaries 
from Monolingual Web pages. 2007. In Proceed-
ings of Machine Translation Summit XI, pp. 57-64. 
Frank, Eibe, Gordon W. Paynter, and Ian H. Witten. 
1999. Domain-Specific Keyphrase Extraction. In 
Proceedings of the 16th International Joint Con-
ference on Artificial Intelligence, pp. 668-673. 
Li Juanzi, Qi?na Fan, and Kuo Zhang. 2007. Keyword 
Extraction Based on tf/idf for Chinese News 
Document. Wuhan University Journal of Natural 
Sciences, 12(5): 917-921. 
Liu Tao, Bingquan Liu, Xiaolong Wang, and Minghui 
Li. 2007. The Effectiveness Study of Local Maxi-
mum Feature for Chinese Unknown Word Identifi-
cation. Journal of Chinese Language and Comput-
ing, 17(1): 15-26. 
Luhn, Hans Peter. 1957. A Statistical Approach to 
Mechanized Encoding and Searching of Literary 
Information. IBM Journal of Research and Devel-
opment, 1(4): 309-317. 
Luo Yanyan, and Degen Huang. 2009. Chinese Word 
Segmentation Based on the Marginal Probabilities 
Generated by CRFs. Journal of Chinese Informa-
tion Processing, 23(5): 3-8. 
Matsuo, Yutaka and Mitsuru Ishizuka. 2004. Key-
word Extraction from a Single Document Using 
Word Co-occurrence Statistical Information. Inter-
national Journal on Artificial Intelligence Tools, 
13(1): 157-169. 
Munteanu, Dragos Stefan. 2006. Exploiting Compa-
rable Corpora. Doctoral Thesis. UMI Order 
No.3257825. University of Southern California. 
Resnik, Philip. 1999. Mining the web for bilingual 
text. In Proceedings of the 37th Annual Meeting of 
the Association for Computational Linguistics, pp. 
527-534. 
Silva, Joaquim Ferreira, Ga?l Dias, Sylvie Guillor?, 
and Jos? Gabriel Pereira Lopes. 1999. Using Lo-
calMaxs Algorithm for the Extraction of Contigu-
ous and Non-contiguous Multiword Lexical Units. 
In Proceedings of the 9th Portuguese Conference 
on Artificial Intelligence, pp. 113-132. 
Talvensaari, Tuomas, Jorma Laurikkala, Kalervo 
J?rvelin, Martti Juhola and Heikki Keskustalo. 
2007. Creating and Exploiting a Comparable Cor-
pus in Cross-Language Information Retrieval. 
ACM Transactions on Information Systems, 
25(1):1-21. 
Tao Tao, and Chengxiang Zhai. 2005. Mining Com-
parable Bilingual Text Corpora for Cross-
Language Information Integration. In Proceedings 
of the 11th ACM SIGKDD international conference 
on Knowledge discovery in data mining, pp. 691-
696. 
Wan Xiaojun, and Jianguo Xiao. 2008. CollabRank: 
Towards a Collaborative Approach to Single-
Document Keyphrase Extraction. In Proceeding of 
the 22nd International Conference on Computa-
tional Linguistics, pp. 969-976. 
Wang Jenq Haur, Jie Wen Teng, Pu Jen Cheng, Wen 
Hsiang Lu, and Lee Feng Chien. 2004. Translating 
Unknown Cross-Lingual Queries in Digital Librar-
ies using a Web-based Approach. In Proceedings 
of the 4th ACM/IEEE-CS joint Conference on Digi-
tal Libraries, pp. 108-116. 
Witten, Ian H., Gordon W. Paynter, Eibe Frank, Carl 
Gutwin, and Craig G. Nevill-Manning. 1999. KEA: 
Practical automatic keyphrase extraction. In Pro-
ceedings of the 4th ACM Conference on Digital Li-
braries, pp. 254-255.  
Zhang Chengzhi, Huilin Wang, Yao Liu, Dan Wu, Yi 
Liao, and Bo Wang. 2008. Automatic Keyword 
Extraction from Documents Using Conditional 
Random Fields. Journal of Computational Infor-
mation Systems, 4(3): 1169-1180. 
Zhang Kuo, Hui Xu, Jie Tang, and Juanzi Li. 2006. 
Keyword Extraction Using Support Vector Ma-
chines. In Proceedings of the 7th International 
Conference on Web-Age Information Management, 
pp. 85-96. 
Zhou Dong, Mark Truran, Tim Brailsford, and Helen 
Ashman. 2007. NTCIR-6 Experiments Using Pat-
tern Matched Translation Extraction. In Proceed-
ings of 6th NTCIR Workshop Meeting, pp. 145-151. 
480
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 109?115,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Improving Feature-Based Biomedical Event Extraction System by In-
tegrating Argument Information 
Lishuang Li, Yiwen Wang, Degen Huang 
School of Computer Science and Technology 
Dalian University of Technology 
116023 Dalian, China 
lilishuang314@163.com yeevanewong@gmail.com 
huangdg@dlut.edu.cn 
 
Abstract 
We describe a system for extracting biomedi-
cal events among genes and proteins from 
biomedical literature, using the corpus from 
the BioNLP?13 Shared Task on Event Extrac-
tion. The proposed system is characterized by 
a wide array of features based on dependency 
parse graphs and additional argument informa-
tion in the second trigger detection. Based on 
the Uturku system which is the best one in the 
BioNLP?09 Shared Task, we improve the per-
formance of biomedical event extraction by 
reducing illegal events and false positives in 
the second trigger detection and the second ar-
gument detection. On the development set of 
BioNLP?13, the system achieves an F-score of 
50.96% on the primary task. On the test set of 
BioNLP?13, it achieves an F-score of 47.56% 
on the primary task obtaining the 5th place in 
task 1, which is 1.78 percentage points higher 
than the baseline (following the Uturku sys-
tem), demonstrating that the proposed method 
is efficient. 
1 Introduction 
Extracting knowledge from unstructured text is 
one of the most important goals of Natural Lan-
guage Processing and Artificial Intelligence. Re-
sources in the internet are expanding at an expo-
nential speed, especially in the biomedical do-
main. Due to the astronomical growth of biomed-
ical scientific literature, it is very important and 
urgent to develop automatic methods for know-
ledge extraction system. 
In the past few years, most researchers in the 
field of Biomedical Natural Language Processing 
focused on extracting information with simple 
structure, such as named entity recognition 
(NER), protein-protein interactions (PPIs) (Air-
ola et al, 2008; Miwa et al, 2009) and disease-
gene association (Chun et al, 2006). While PPIs 
concern the flat relational schemas with no 
nested structures, bio-molecular events describe 
the detailed behavior of bio-molecules, which 
capture the biomedical phenomena from texts 
well. The BioNLP?09 shared task (Kim et al, 
2009) provides the first entry to bio-event extrac-
tion. As described in BioNLP?09, a bio-event 
consists of a trigger and one or more arguments, 
where a trigger is a contiguous textual string con-
taining one or more tokens and an argument is a 
participant (event or protein) with a correspond-
ing type. For example, in the snippet ?interferon 
regulatory factor 4 gene expression?, the event 
trigger is ?expression? which is tagged by the 
event type ?Gene_expression? and the event ar-
gument is ?interferon regulatory factor 4?. Not-
ably, bio-events may have arbitrary arguments 
and even contain other events as arguments, re-
sulting in nested events. 
The complex event structure makes this task 
particularly attractive, drawing initial interest 
from many researchers. Bj?rne et al's (2009) 
system (referred to hereinafter as Uturku system) 
was the best pipeline system in BioNLP?09, 
achieving an F-score of 51.95% on the test data 
sets. After that, Miwa et al (2010a, 2010b) com-
pared different parsers and dependency represen-
tations on bio-event extraction task and obtained 
an F-score of 57.79% on development data sets 
and 56.00% on test data sets with parser ensem-
ble. In contrast to the pipeline system which di-
vided the event process into three stages, triggers 
detection, arguments detection and post 
processing, Poon and Vanderwende?s (2010) and 
Riedel et al?s (2009) joint models combined 
trigger recognition and argument detection by 
using a Markov logic network learning approach. 
After the BioNLP?09, the Genia event task (Bi-
oNLP?11 task 1, hereafter) in the BioNLP?11 
Shared Task (Kim et al, 2011) introduced a 
same event extraction task on a new dataset. 
There were still some pipeline systems applied to 
Genia task 1, e.g. Bj?rne et al?s (2011) system 
and Quirk et al?s (2011) system. To the best of 
109
our knowledge, Miwa et al?s (2012) pipeline 
system incorporating domain adaptation and co-
reference resolution, is the best biomedical event 
extraction system on BioNLP'11 task 1 so far. 
The Genia event extraction task (BioNLP'13 
task 1, hereafter) (Kim et al, 2013) in Bi-
oNLP'13 Shared Task is consistent with the Ge-
nia task in BioNLP'11 Shared task. Nevertheless, 
BioNLP'13 task 1 focuses on event extraction 
from full texts while BioNLP?11 task 1 contains 
abstracts and full texts. Furthermore, the corefe-
rence resolution task separated from event ex-
traction task in BioNLP'11 is integrated to Bi-
oNLP'13 task 1, and there are more event types 
in the BioNLP'13 task 1 than those in BioNLP'11 
task 1. The BioNLP?13 shared task contains 
three parts, the training corpus, the development 
corpus and the test corpus. The training corpus 
consists of 10 full texts containing 2792 events. 
The development corpus for optimizing the pa-
rameters involves 10 full texts containing 3184 
events, while the test corpus is composed of 14 
full texts including 3301 events. To avoid the 
researchers optimizing parameters on the test 
corpus, it is not published, and we have the per-
mission to combine the training corpus and the 
development corpus as training set. However, we 
extend BioNLP'13 training set by adding the ab-
stracts of training set and development set in Bi-
oNLP'11 task 1 rather than merging the devel-
opment set of BioNLP'13 into the training set.  
Our system generally follows the Uturku sys-
tem reported by Bj?rne et al (2009), and uses a 
simple but efficient way to reduce the cascading 
errors. The Uturku system was a pipeline of trig-
ger detection, argument detection and post-
processing. Each of its components was simple  
to implement by reducing event extraction task 
into independent classification of triggers and 
arguments. Moreover, the Uturku system devel-
oped rich features and made extensive use of 
syntactic dependency parse graphs, and the rules 
in the post-processing step were efficient and 
simple. However, the stages of the pipeline in-
troduced cascading errors, meaning that the trig-
ger missed in the trigger detection would never 
be recalled in the following stages. By changing 
the pipeline and adding argument information in 
trigger detection, we construct a model for ex-
tracting complex events using rich features and 
achieve better performance than the baseline sys-
tem implemented according to Bj?rne et al's 
(2009) paper. 
2 Our Event Extraction System  
Fig.1 shows the overall architecture of the pro-
posed system. Since 97% of all annotated events 
are fully contained within a single sentence, our 
system deals with one sentence at a time, which 
does not incur a large performance penalty but 
greatly reduces the size and complexity of the 
machine learning problems (Bj?rne et al, 2009). 
The system?s components are different from 
those of the Uturku system by adding a second 
trigger detection component and a second edge 
detection component (argument detection). Trig-
ger detection component is used to recognize the 
trigger words that signify the event, and edge 
detection component is used to identify the ar-
guments that undergo the change. Semantic post-
processing component generates events consis-
tent with the restrictions on event argument types 
and combinations defined in the shared task. 
 
Input data
Sentence splitting
Token zation
Parsing
First Trigger 
detection
(multi-class SVM)
First Edge detection
(multi-class SVM)
Second Trigger 
detection
(multi-class SVM)
Second Edge 
detection
(multi-class SVM)
Semantic
 post-processing
(Rule based)
Output data
 
Figure 1. The flow chart of our system. 
In the following sections, we present the im-
plementation for these stages in our biomedical 
event extraction system in detail and evaluate our 
system on the BioNLP?13 data sets. 
2.1 Trigger Detection 
nuclear extracts showed decreased or absent p65 protein levels
Neg_reg Pro
Theme
 
Figure 2. An example of the trigger consisting of two 
head tokens 
Trigger detection assigns each token an event 
class or a negative class (if the token is not a 
trigger). The head token is chosen when the real 
trigger consists of several tokens, which does not
110
Type Feature 
Primary features The token 
Part-Of-Speech of the token 
Base form 
The rest part of the token, getting rid of the stem word 
Token feature Token has a capital letter 
Token has a first letter of the sentence 
Token has a number 
Token has a symbol like ?-?,?/?,?\? 
N-grams (n = 2, 3) of characters 
Govern and Dependent feature Dependency type 
Part-Of-Speech (POS) of the other token 
Combine the POS and the dependency type 
The word form of the other token 
Frequency features Number of named entities in the sentence 
Bag-of-word counts of token texts in the sentence 
Shortest path Token features of the token in the path 
N-grams of dependencies (n =2, 3, 4) 
N-grams of words (base form + POS) (n =2, 3, 4) 
N-grams of consecutive words (base form + POS) representing 
Governor-dependent relationships (n =1, 2, 3) 
Table 1: Features for the first trigger detection 
Type Feature 
Path feature The token in the path 
The POS of the token in the path 
The dependency type of edges in the path 
(all these features are combined with direction, length and the entity type) 
Table 2: Added feature for the second trigger detection 
incur performance penalty with the approximate 
span matching/approximate recursive matching 
mode (Kim et al, 2009).  Two head tokens may 
be chosen from one trigger when the trigger con-
sists of two appositives. For example, for the 
snippets ?decreased or absent p65 protein le-
vels?, both ?decreased? and ?absent? are the 
head token of the trigger ?decreased or absent?, 
shown in Fig 2. Rich features are extracted for 
the first trigger detection, shown in Table 1. 
To remove the erroneous events and correct 
the event type assigned in the first trigger detec-
tion, a second trigger detection is added in our 
system. Thus the second trigger detection is dif-
ferent from the first one. Uturku system shows 
that the trigger information improves the edge 
detection because of the constraints on the type 
of arguments. Naturally, the edge information is 
helpful for trigger detection with the same reason. 
As a result, this method can improve the preci-
sion of trigger performance. 
In order to leverage the argument information, 
we explore a lot of features of the edges which 
are the arguments detected in the first edge de-
tection. The edge information concerns the fea-
tures of the edges attached to the token. In the 
second trigger detection, we add all the path fea-
tures between the candidate trigger and argu-
ments attached to the candidate trigger detected 
in the first edge detection. These features contain 
the entity information of the argument, the de-
pendency path between the trigger and the argu-
ment and so on. Specially, the added features 
cannot contain any trigger type information ob-
tained in the first trigger detection, or the added 
features cannot do any help. The reason is that 
SVM classifier will classify samples only relying 
on the label feature if it is in the feature set. The 
added features are shown in Table 2. 
 
 
111
Type Features 
N-grams N-grams of consecutive tokens(n=2,3,4) in the path 
N-grams of vertex walks 
Terminal node feature Token feature of the terminal nodes 
The entity type of the terminal nodes 
Re-normalized confidences of all event class 
Frequency feature The length of the path 
The number of entities in the sentence 
Edges feature in the path Dependency type of the edges in the path 
The POS of the tokens in the path 
The tokens in the path 
Table 3: Features for edge detection 
2.2 Edge Detection 
Similar to the trigger detector, the edge detector 
is based on a multi-class SVM classifier. An 
edge is from a trigger to a trigger or from a trig-
ger to a protein. The edge detector classifies each 
candidate edge as a theme, a cause, or a negative 
denoting the absence of an edge between the two 
nodes in the given direction. The features in edge 
detection are shown in Table 3. As the trigger 
information is helpful in edge detection, the ter-
minal node feature contains it. Additionally?the 
first edge detection is completely the same as the 
second one, that is, they share the same features 
and machine learning strategy. 
2.3 Semantic Post-processing 
After the trigger detection and edge detection, 
the biomedical event cannot be produced directly. 
Some simple events may be attached with sever-
al proteins, and complex events may form circles. 
We develop a custom rule-based method to gen-
erate events that are consistent with the restric-
tions on event argument types and combinations 
defined in the shared task. For details, Bj?rne et 
al.?s (2009) paper can be referred to. 
3 Tools and Component Combination  
We use the support vector machine (SVM) mul-
ti-class classifier (Crammer and Singer (2002),  
Tsochantaridis et al (2004)) in the trigger detec-
tion and edge detection. Besides, the dependency 
parser used in our system is McClosky-Charniak 
domain-adapted parser (McClosky and  Charniak 
(2008)) and the dependency parse was provided 
in the share task1 . To optimize the precision-
recall trade-off, we introduce ? that decreases the 
classifier confidence score given to the negative 
                                                 
1 http://2013.bionlp-st.org/supporting-resources 
trigger class as formula (1) as the Uturku system 
does (2009).  
score = score-(1-?)*abs(score)       (1) 
where abs(score) means the absolute value of 
score and ??[0,1]. 
4 Evaluations and Discussion 
4.1 Evaluations 
Firstly, our system is evaluated on the develop-
ment set. Table 4 compares the performance be-
tween our system and the baseline. The baseline 
is implemented based on Bj?rne et al?s (2009) 
paper. Compared to baseline, the precision of our 
system is 6.08 percentage points higher while the 
recall increases 0.91 percentage points. From 
Table 4 we can see that our system is 2.85 F-
score higher than the baseline system. 
 
 Recall  Precision F-score 
Baseline  43.15 54.37 48.12 
Ours 44.06 60.45 50.97 
Table 4: Performance comparison on the development 
set using approximate span and recursive matching 
Secondly, the performance of our system is 
evaluated on the test data set with online evalua-
tion2. Table 5 shows the results for the baseline 
and the proposed system with argument informa-
tion to evaluate the importance of argument in-
formation. Integrating argument information, our 
system archives 1.78% F-score improvement. 
Compared to the baseline, the performance for 
complex events is very encouraging with about 
7.5 percentage points improvement in the Phos-
phorylation events, 1.77 percentage points im-
provement in the regulation events, 2.91 percen- 
                                                 
2 http://bionlp-st.dbcls.jp/GE/2013/eval-test/ 
112
Event type # Our system Baseline 
R/P/F-score R/P/F-score 
Gene_expression 619 77.54/82.76/80.07 79.48/78.10/78.78 
Transcription 101 49.50/65.79/56.50 53.47/62.79/57.75 
Protein_catabolism 14 78.57/55.00/64.71 78.57/45.83/57.89 
Localization 99 35.35/89.74/50.72 38.38/84.44/52.78 
=[SIMPLE ALL]= 833 69.15/80.56/74.42 71.43/75.80/73.55 
Binding 333 40.84/44.16/42.43 42.64/44.65/43.63 
Protein_modification 1 0.00/0.00/0.00 0.00/0.00/0.00 
Phosphorylation 160 75.00/77.42/76.19 69.38/68.10/68.73 
Ubiquitination 30 0.00/0.00/0.00 0.00/0.00/0.00 
Acetylation 0 0.00/0.00/0.00 0.00/0.00/0.00 
Deacetylation 0 0.00/0.00/0.00 0.00/0.00/0.00 
=[PROT-MOD ALL]= 191 62.83/77.42/69.36 58.12/68.10/62.71 
Regulation 288 15.28/42.72/22.51 14.58/35.90/20.74 
Positive_regulation 1130 29.20/44.47/35.26 26.11/42.51/32.35 
Negative_regulation 526 26.81/41.47/32.56 25.10/35.11/29.27 
=[REGULATION ALL]= 1944 26.49/43.46/32.92 24.13/39.51/29.96 
==[EVENT TOTAL]== 3301 40.81/57.00/47.56 39.90/53.69/45.78 
Table 5: Approximate span matching/approximate recursive matching on test data set. 
Th(E1)
Triggering of the human interleukin-6 gene by interferon-gamma and tumor necrosis factor-alpha 
Binding Pro Pro Pro
Th(E2) Th(E1)Th(E2)
  
(a) Th(E1)
Triggering of the human interleukin-6 gene by interferon-gamma and tumor necrosis factor-alpha 
Pos-Reg Pro Pro Pro
Cause(E2) Cause(E1)Th(E2)
 
(b) 
Figure 3: (a) A result of a fragment using the first trigger detection. (b) A result of a fragment using the second 
trigger detection. 
tage points improvement in the positive regula-
tion events and 3.29 percentage points increase 
in the negative regulation events, but not much 
loss in other events. As a consequence, the total 
F-score of our system is 47.56%, 1.78 percentage 
points higher than the baseline system and ob-
tains the 5th place in BioNLP'13 task 1. 
4.2 Discussion 
Our system achieves better performance than the 
baseline thanks to the second trigger detection. 
The second trigger detection improves the per-
formance of event extraction in two ways. Firstly, 
the triggers that cannot form events are directly 
deleted, and therefore the corresponding errone-
ous events are deleted. Secondly, since the erro-
neous triggers are deleted or the triggers recog-
nized in the first trigger detection are given the 
right types in the second trigger detection, the 
corresponding arguments are reconstructed to 
form right events. Fig.3 shows an example. In 
the first trigger detection, the trigger ?triggering? 
is recognized as the illegal type of ?binding? so 
that ?interferon-gamma? and ?tumor necrosis 
factor-alpha? are illegally detected as theme ar-
guments of ?triggering?, resulting in erroneous 
events. However, in the second trigger detection, 
113
?triggering? is correctly revised as the type of 
positive regulation, so the arguments are recon-
structed, which makes the positive regulation 
events (E1 and E2) right. As a result, the preci-
sion of event detection increases as well as the 
recall. 
The proposed method is an efficient way to 
reduce cascading errors in pipeline system. 
Moreover, Riedel and McCallum (2011) pro-
posed a dual decomposition-based model, anoth-
er efficient method to get around cascading er-
rors. Following Riedel et al?s (2011) paper, we 
implement a dual decomposition-based system 
using the same features in our system. Table 6 
shows the performance comparison on the devel-
opment set of BioNLP?09 between our system 
and dual decomposition-based system. The com-
parison indicates that the proposed method is 
comparable to the stat-of-the-art systems.  
 
 Recall  Precision F-score 
Dual Decom-
position 
50.08 63.66 56.06 
Ours 53.88 59.67 56.63 
Table 6: Performance comparison on the development 
set of BioNLP?09 using approximate span and recur-
sive matching based on different methods 
5 Conclusions 
We proposed a simple but effective method to 
improve event extraction by boosting the trigger 
detection. The added edge information in the 
second trigger detection improves the perfor-
mance of trigger detection. Features from the 
dependency parse graphs are the main features 
we use for event extraction. 
The future work includes: the first trigger de-
tection should classify a token into three classes: 
simple event type, complex event type and none 
event type; discovering some more helpful edge 
features in the second trigger detection; solving 
coreference problem with coreference resolution 
approach. Besides, the dual decomposition-based 
method will be improved and further compared 
with the pipeline system. 
 
Acknowledgments 
 
This work is supported by grant from the Nation-
al Natural Science Foundation of China (no. 
61173101, 61173100). 
References  
Antti Airola, Sampo Pyysalo, Jari Bj?rne, Tapio Pa-
hikkala, Filip Ginter, and Tapio Salakoski. 2008. 
All-paths graph kernel for protein-protein interac-
tion extraction with evaluation of cross-corpus 
learning. BMC Bioinformatics, 9(Suppl 11):S2. 
Chris Quirk, Pallavi Choudhury, Michael Gamon, and 
Lucy Vanderwend. 2011. MSR-NLP Entry in Bi-
oNLP Shared Task 2011. In Proceedings of the Bi-
oNLP 2011 Workshop Companion Volume for 
Shared Task, Portland, Oregon, June. Association 
for Computational Linguistics. 
David McClosky and Eugene Charniak. 2008. Self-
training for biomedical parsing. In Proceedings of 
ACL-08: HLT, Short Papers, pages 101?104. Asso-
ciation for Computational Linguistics. 
Hoifung Poon, Lucy Vanderwende. 2010. Joint Infe-
rence for Knowledge Extraction from Biomedical 
Literature. In Proceedings of the North American 
Chapter of the Association for Computational Lin-
guistics-Human Language Technologies 2010 con-
ference. 
Hong-Woo Chun, Yoshimasa Tsuruoka, Jin-Dong 
Kim, Rie Shiba, Naoki Nagata, Teruyoshi Hishiki, 
and Jun?ichi Tsujii. 2006. Extraction of gene-
disease relations from medline using domain dic-
tionaries and machine learning. In Proceedings of 
the Pacific Symposium on Biocomputing (PSB?06), 
pages 4?15. 
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten 
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and struc-
tured output spaces. In Proceedings of the Twenty-
first International Conference on Machine Learn-
ing (ICML?04), pages 104?111. ACM. 
Jari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airola, 
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP 
2009 Workshop Companion Volume for Shared 
Task, pages 10?18, Boulder, Colorado, June. Asso-
ciation for Computational Linguistics.  
Jari Bj?rne and Tapio Salakoski. 2011. Generalizing 
biomedical event extraction. In Proceedings of the 
BioNLP 2011 Workshop Companion Volume for 
Shared Task, Portland, Oregon, June. Association 
for Computational Linguistics. 
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yo-
shinobu Kano, and Junichi Tsujii. 2009. Overview 
of BioNLP?09 Shared Task on event extraction. In 
Proceedings of the NAACL-HLT 2009 Workshop 
on Natural Language Processing in Biomedicine 
(BioNLP?09). ACL. 
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert 
Bossy, and Jun?ichi Tsujii. 2011. Overview of Bi-
114
oNLP Shared Task 2011. In Proceedings of the Bi-
oNLP 2011 Workshop Companion Volume for 
Shared Task, Portland, Oregon, June. Association 
for Computational Linguistics. 
Jin-Dong Kim, Yue Wang and Yamamoto Yasunori. 
2013. The Genia Event Extraction Shared Task, 
2013 Edition - Overview. In Proceedings of the Bi-
oNLP Shared Task 2013 Workshop, Sofia, Bulgaria, 
Aug. Association for Computational Linguistics. 
Koby Crammer and Yoram Singer. 2002. On the al-
gorithmic implementation of multiclass kernel-
based vector machines. Journal of Machine Learn-
ing Research, 2:265?292. 
Makoto Miwa, Rune S?tre, Yusuke Miyao, and-
Jun?ichi Tsujii. 2009. A rich feature vector for 
protein?protein interaction extraction from mul-
tiple corpora. In EMNLP?09: Proceedings of the 
2009 Conference on Empirical Methods in Natu-
ral Language Processing, pages 121?130, Morris-
town, NJ, USA. Association for Computational 
Linguistics. 
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and 
Jun?ichi Tsujii. 2010a . A comparative study of 
syntactic parsers for event extraction. In Proceed-
ings of BioNLP?10  p. 37?45. 
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and 
Jun?ichi Tsujii. 2010b. Evaluating dependency re-
presentation for event extraction. In Proceedings of 
the 23rd International Conference on Computa-
tional Linguistics, COLING ?10, Association for 
Computational Linguistics, 2010; p. 779?787. 
Makoto Miwa, Paul Thompson, and Sophia Anania-
dou. 2012. Boosting automatic event extraction 
from the literature using domain adaptation and co-
reference resolution. Bioinformatics.  
Sebastian Riedel, Hong-Woo Chun, Toshihisa Taka-
gi,and Jun?ichi Tsujii. 2009. A Markov logic ap-
proach to bio-molecular event extraction. In Bi-
oNLP?09: Proceedings of the Workshop on BioNLP, 
pages 41-49, Morristown, NJ, USA. Association 
for Computational Linguistics. 
Sebastian Riedel and Andrew McCallum. 2011. Ro-
bust Biomedical Event Extraction with Dual De-
composition and Minimal Domain Adaptation. In 
Proceedings of the BioNLP 2011 Workshop Com-
panion Volume for Shared Task, Portland, Oregon, 
June. Association for Computational Linguistics. 
115
