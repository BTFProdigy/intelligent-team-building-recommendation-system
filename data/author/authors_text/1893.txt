Event Detection and Summarization in Weblogs with Temporal Collocations 
Chun-Yuan Teng and Hsin-Hsi Chen 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, Taiwan 
{r93019, hhchen}@csie.ntu.edu.tw 
Abstract 
 
This paper deals with the relationship between weblog content and time. With the proposed temporal mutual information, we analyze 
the collocations in time dimension, and the interesting collocations related to special events. The temporal mutual information is 
employed to observe the strength of term-to-term associations over time. An event detection algorithm identifies the collocations that 
may cause an event in a specific timestamp. An event summarization algorithm retrieves a set of collocations which describe an event. 
We compare our approach with the approach without considering the time interval. The experimental results demonstrate that the 
temporal collocations capture the real world semantics and real world events over time. 
 
1. 
2. 
Introduction 
Compared with traditional media such as online news 
and enterprise websites, weblogs have several unique 
characteristics, e.g., containing abundant life experiences 
and public opinions toward different topics, highly 
sensitive to the events occurring in the real world, and 
associated with the personal information of bloggers. 
Some works have been proposed to leverage these 
characteristics, e.g., the study of the relationship between 
the content and bloggers? profiles (Adamic & Glance, 
2005; Burger & Henderson, 2006; Teng & Chen, 2006), 
and content and real events (Glance, Hurst & Tornkiyo, 
2004; Kim, 2005; Thelwall, 2006; Thompson, 2003). 
In this paper, we will use temporal collocation to 
model the term-to-term association over time.  In the past, 
some useful collocation models (Manning & Sch?tze, 
1999) have been proposed such as mean and variance, 
hypothesis test, mutual information, etc. Some works 
analyze the weblogs from the aspect of time like the 
dynamics of weblogs in time and location (Mei, et al, 
2006), the weblog posting behavior (Doran, Griffith & 
Henderson, 2006; Hurst, 2006), the topic extraction (Oka, 
Abe & Kato, 2006), etc. The impacts of events on social 
media are also discussed, e.g., the change of weblogs after 
London attack (Thelwall, 2006), the relationship between 
the warblog and weblogs (Kim, 2005; Thompson, 2003), 
etc. 
This paper is organized as follows. Section 2 defines 
temporal collocation to model the strength of term-to-term 
associations over time.  Section 3 introduces an event 
detection algorithm to detect the events in weblogs, and 
an event summarization algorithm to extract the 
description of an event in a specific time with temporal 
collocations. Section 4 shows and discusses the 
experimental results.  Section 5 concludes the remarks. 
Temporal Collocations 
We derive the temporal collocations from Shannon?s 
mutual information (Manning & Sch?tze, 1999) which is 
defined as follows (Definition 1). 
Definition 1 (Mutual Information) The mutual 
information of two terms x and y is defined as: 
)()(
),(log),(),(
yPxP
yxPyxPyxI =  
where P(x,y) is the co-occurrence probability of x and y, 
and P(x) and P(y) denote the occurrence probability of x 
and y, respectively. 
Following the definition of mutual information, we 
derive the temporal mutual information modeling the 
term-to-term association over time, and the definition is 
given as follows.  
 Definition 2 (Temporal Mutual Information) Given 
a timestamp t and a pair of terms x and y, the temporal 
mutual information of x and y in t is defined as: 
)|()|(
)|,(log)|,()|,(
tyPtxP
tyxPtyxPtyxI =
where P(x,y|t) is the probability of co-occurrence of terms 
x and y in timestamp t, P(x|t) and P(y|t) denote the 
probability of occurrences of x and y in timestamp t, 
respectively. 
To measure the change of mutual information in time 
dimension, we define the change of temporal mutual 
information as follows. 
Definition 3 (Change of Temporal Mutual 
Information) Given time interval [t1, t2], the change of 
temporal mutual information is defined as: 
12
12
21
)|,()|,(),,,(
tt
tyxItyxIttyxC ?
?=  
where C(x,y,t1,t2) is the change of temporal mutual 
information of terms x and y in time interval [t1, t2], I(x,y| 
t1) and I(x,y| t2) are the temporal mutual information in 
time t1 and t2, respectively. 
3. Event Detection 
Event detection aims to identify the collocations 
resulting in events and then retrieve the description of 
events. Figure 1 sketches an example of event detection. 
The weblog is parsed into a set of collocations. All 
collocations are processed and monitored to identify the 
plausible events.  Here, a regular event ?Mother?s day? 
and an irregular event ?Typhoon Chanchu? are detected.  
The event ?Typhoon Chanchu? is described by the words  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: An Example of Event Detection
?Typhoon?, ?Chanchu?, ?2k?, ?Eye?, ?Path? and 
?chinaphillippine?.  
The architecture of an event detection system includes 
a preprocessing phase for parsing the weblogs and 
retrieving the collocations; an event detection phase 
detecting the unusual peak of the change of temporal 
mutual information and identifying the set of collocations 
which may result in an event in a specific time duration; 
and an event summarization phase extracting the 
collocations related to the seed collocations found in a 
specific time duration. 
The most important part in the preprocessing phase is 
collocation extraction. We retrieve the collocations from 
the sentences in blog posts. The candidates are two terms 
within a window size. Due to the size of candidates, we 
have to identify the set of tracking terms for further 
analysis. In this paper, those candidates containing 
stopwords or with low change of temporal mutual 
information are removed. 
In the event detection phase, we detect events by 
using the peak of temporal mutual information in time 
dimension.  However, the regular pattern of temporal 
mutual information may cause problems to our detection. 
Therefore, we remove the regular pattern by seasonal 
index, and then detect the plausible events by measuring 
the unusual peak of temporal mutual information. 
If a topic is suddenly discussed, the relationship 
between the related terms will become higher. Two 
alternatives including change of temporal mutual 
information and relative change of temporal mutual 
information are employed to detect unusual events. Given 
timestamps t1 and t2 with temporal mutual information 
MI1 and MI2, the change of temporal mutual information 
is calculated by (MI2-MI1). The relative change of 
temporal mutual information is calculated by (MI2-
MI1)/MI1. 
For each plausible event, there is a seed collocation, 
e.g., ?Typhoon Chanchu?. In the event description 
retrieval phase, we try to select the collocations with the 
highest mutual information with the word w in a seed 
collocation. They will form a collocation network for the 
event.  Initially, the seed collocation is placed into the 
network.  When a new collocation is added, we compute 
the mutual information of the multiword collocations by 
the following formula, where n is the number of 
collocations in the network up to now. 
?= n iMInInformatioMutualMultiwo  
If the multiword mutual information is lower than a 
threshold, the algorithm stops and returns the words in the 
collocation network as a description of the event.  Figure 
2 sketches an example.  The collocations ?Chanchu?s 
path?, ?Typhoon eye?, and ?Chanchu affects? are added 
into the network in sequence based on their MI. 
We have two alternatives to add the collocations to 
the event description. The first method adds the 
collocations which have the highest mutual information 
as discussed above. In contrast, the second method adds 
the collocations which have the highest product of mutual 
information and change of temporal mutual information. 
 
 
 
 
 
 
Figure 2: An Example of Collocation network 
4. 
4.1. 
Experiments and Discussions 
Temporal Mutual Information versus 
Mutual Information 
In the experiments, we adopt the ICWSM weblog data 
set (Teng & Chen, 2007; ICWSM, 2007). This data set 
collected from May 1, 2006 through May 20, 2006 is 
about 20 GB. Without loss of generality, we use the 
English weblog of 2,734,518 articles for analysis. 
To evaluate the effectiveness of time information, we 
made the experiments based on mutual information 
(Definition 1) and temporal mutual information 
(Definition 2). The former called the incremental 
approach measures the mutual information at each time 
point based on all available temporal information at that 
time. The latter called the interval-based approach 
considers the temporal mutual information in different 
time stamps.  Figures 3 and 4 show the comparisons 
between interval-based approach and incremental 
approach, respectively, in the event of Da Vinci Code.   
We find that ?Tom Hanks? has higher change of 
temporal mutual information compared to ?Da Vinci 
Code?. Compared to the incremental approach in Figure 4, 
the interval-based approach can reflect the exact release 
date of ?Da Vinci Code.? 
 rd
=i 1 4.2. Evaluation of Event Detection 
We consider the events of May 2006 listed in 
wikipedia1 as gold standard. On the one hand, the events 
posted in wikipedia are not always complete, so that we 
adopt recall rate as our evaluation metric.  On the other 
hand, the events specified in wikipedia are not always 
discussed in weblogs.  Thus, we search the contents of 
blog post to verify if the events were touched on in our 
blog corpus. Before evaluation, we remove the events 
listed in wikipedia, but not referenced in the weblogs. 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Interval-based Approach in Da Vinci Code  
 
 
 
 
 
 
 
 
Figure 4: Incremental Approach in Da Vinci Code 
gure 5 sketches the idea of evaluation.  The left side 
of t s figure shows the collocations detected by our event 
dete tion system, and the right side shows the events 
liste  in wikipedia.  After matching these two lists, we 
can find that the first three listed events were correctly 
identified by our system.  Only the event ?Nepal Civil 
War? was listed, but not found. Thus, the recall rate is 
75% in this case. 
 
 
 
 
 
 
 
Figure 5: Evaluation of Event Detection Phase 
As discussed in Section 3, we adopt change of 
temporal mutual information, and relative change of 
temporal mutual information to detect the peak. In Figure 
6, we compare the two methods to detect the events in 
weblogs. The relative change of temporal mutual 
information achieves better performance than the change 
of temporal mutual information. 
                                                     
1 http://en.wikipedia.org/wiki/May_2006 
Table 1 and Table 2 list the top 20 collocations based 
on these two approaches, respectively. The results of the 
first approach show that some collocations are related to 
the feelings such as ?fell left? and time such as ?Saturday 
night?. In contrast, the results of the second approach 
show more interesting collocations related to the news 
events at that time, such as terrorists ?zacarias 
moussaoui? and ?paramod mahajan.? These two persons 
were killed in May 3. Besides, ?Geena Davis? got the 
golden award in May 3. That explains why the 
collocations detected by relative change of temporal 
mutual information are better than those detected by 
change of temporal mutual information. 
-20
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6: Performance of Event Detection Phase 
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
Collocations CMI Collocations CMI 
May 03 9276.08 Current music 1842.67
Illegal immigrants 5833.17 Hate studying 1722.32
Feel left 5411.57 Stephen Colbert 1709.59
Saturday night 4155.29 Thursday night 1678.78
Past weekend 2405.32 Can?t believe 1533.33
White house 2208.89 Feel asleep 1428.18
Red sox 2208.43 Ice cream 1373.23
Album tool 2120.30 Oh god 1369.52
Sunday morning 2006.78 Illegalimmigration 1368.12
16.56
f 
CMI
32.50
31.63
29.09
28.45
28.34
28.13Sunday night 1992.37 Pretty cool 13
Table 1: Top 20 collocations with highest change o
temporal mutual information 
Collocations CMI Collocations 
casinos online 618.36 Diet sodas 
zacarias moussaoui 154.68 Ving rhames 
Tsunami warning 107.93 Stock picks 
Conspirator zacarias 71.62 Happy hump 
Artist formerly 57.04 Wong kan 
Federal  
Jury 
41.78 Sixapartcom 
movabletype Wed 3 39.20 Aaron echolls 27.48
Pramod mahajan 35.41 Phnom penh 25.78
BBC  
Version 
35.21 Livejournal 
sixapartcom 
23.83  Fi
hi
c
dGeena davis 33.64 George yeo 20.34
Table 2: Top 20 collocations with highest relative change 
of mutual information 
4.3. Evaluation of Event Summarization 
As discussed in Section 3, we have two methods to 
include collocations to the event description. Method 1 
employs the highest mutual information, and Method 2 
utilizes the highest product of mutual information and 
change of temporal mutual information. Figure 7 shows 
the performance of Method 1 and Method 2. We can see 
that the performance of Method 2 is better than that of 
Method 1 in most cases. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Overall Performance of Event Summarization 
The results of event summarization by Method 2 are 
shown in Figure 8. Typhoon Chanchu appeared in the 
Pacific Ocean on May 10, 2006, passed through 
Philippine and China and resulted in disasters in these 
areas on May 13 and 18, 2006.  The appearance of the 
typhoon Chanchu cannot be found from the events listed 
in wikipedia on May 10.  However, we can identify the 
appearance of typhoon Chanchu from the description of 
the typhoon appearance such as ?typhoon named? and 
?Typhoon eye.  In addition, the typhoon Chanchu?s path 
can also be inferred from the retrieved collocations such 
as ?Philippine China? and ?near China?. The response of 
bloggers such as ?unexpected typhoon? and ?8 typhoons? 
is also extracted.   
 
 
 
 
 
 
 
 
 
 
Figure 8: Event Summarization for Typhoon Chanchu 
5. Concluding Remarks 
This paper introduces temporal mutual information to 
capture term-term association over time in weblogs. The 
extracted collocation with unusual peak which is in terms 
of relative change of temporal mutual information is 
selected to represent an event.  We collect those 
collocations with the highest product of mutual 
information and change of temporal mutual information 
to summarize the specific event.  The experiments on 
ICWSM weblog data set and evaluation with wikipedia 
event lists at the same period as weblogs demonstrate the 
feasibility of the proposed temporal collocation model 
and event detection algorithms. 
Currently, we do not consider user groups and 
locations. This methodology will be extended to model 
the collocations over time and location, and the 
relationship between the user-preferred usage of 
collocations and the profile of users. 
Acknowledgments 
Research of this paper was partially supported by 
National Science Council, Taiwan (NSC96-2628-E-002-
240-MY3) and Excellent Research Projects of National 
Taiwan University (96R0062-AE00-02). 
References 
Adamic, L.A., Glance, N. (2005). The Political 
Blogosphere and the 2004 U.S. Election: Divided 
They Blog. In: Proceedings of the 3rd International 
Workshop on Link Discovery, pp. 36--43. 
Burger, J.D., Henderson J.C. (2006). An Exploration of 
Observable Features Related to Blogger Age. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
15--20. 
Doran, C., Griffith, J., Henderson, J. (2006). Highlights 
from 12 Months of Blogs. In: Proceedings of AAAI 
2006 Spring Symposium on Computational 
Approaches to Analysing Weblogs, pp. 30--33. 
Glance, N., Hurst, M., Tornkiyo, T. (2004). Blogpulse: 
Automated Trend Discovery for Weblogs. In: 
Proceedings of WWW 2004 Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Hurst, M. (2006). 24 Hours in the Blogosphere. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
73--77. 
ICWSM (2007). http://www.icwsm.org/data.html 
Kim, J.H. (2005). Blog as an Oppositional Medium? A 
Semantic Network Analysis on the Iraq War Blogs. In: 
Internet Research 6.0: Internet Generations. 
 
Manning, C.D., Sch?tze, H. (1999). Foundations of 
Statistical Natural Language Processing, The MIT 
Press, London England. 
Mei, Q., Liu, C., Su, H., Zhai, C. (2006). A Probabilistic 
Approach to Spatiotemporal Theme Pattern Mining on 
Weblogs. In: Proceedings of the 15th International 
Conference on World Wide Web, Edinburgh, Scotland, 
pp. 533--542. 
Oka, M., Abe, H., Kato, K. (2006). Extracting Topics 
from Weblogs Through Frequency Segments. In: 
Proceedings of WWW 2006 Annual Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Teng, C.Y., Chen, H.H. (2006). Detection of Bloggers? 
Interest: Using Textual, Temporal, and Interactive 
Features. In: Proceeding of IEEE/WIC/ACM 
International Conference on Web Intelligence, pp. 
366--369. 
Teng, C.Y., Chen, H.H. (2007). Analyzing Temporal 
Collocations in Weblogs. In: Proceeding of 
International Conference on Weblogs and Social 
Media, 303--304. 
Thelwall, M. (2006). Blogs During the London Attacks: 
Top Information Sources and Topics. In: Proceedings 
of 3rd Annual Workshop on the Weblogging 
Ecosystem: Aggregation, Analysis and Dynamics. 
Thompson, G. (2003). Weblogs, Warblogs, the Public 
Sphere, and Bubbles. Transformations, 7(2). 
Proceedings of the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky, pages 29?36,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Attribution and the (Non-)Alignment of Syntactic and Discourse Arguments
of Connectives
Nikhil Dinesh and Alan Lee and Eleni Miltsakaki and Rashmi Prasad and Aravind Joshi
University of Pennsylvania
Philadelphia, PA 19104 USA
fnikhild,aleewk,elenimi,rjprasad,joshig@linc.cis.upenn.edu
Bonnie Webber
University of Edinburgh
Edinburgh, EH8 9LW Scotland
bonnie@inf.ed.ac.uk
Abstract
The annotations of the Penn Discourse
Treebank (PDTB) include (1) discourse
connectives and their arguments, and (2)
attribution of each argument of each con-
nective and of the relation it denotes. Be-
cause the PDTB covers the same text as
the Penn TreeBank WSJ corpus, syntac-
tic and discourse annotation can be com-
pared. This has revealed significant dif-
ferences between syntactic structure and
discourse structure, in terms of the argu-
ments of connectives, due in large part to
attribution. We describe these differences,
an algorithm for detecting them, and fi-
nally some experimental results. These re-
sults have implications for automating dis-
course annotation based on syntactic an-
notation.
1 Introduction
The overall goal of the Penn Discourse Treebank
(PDTB) is to annotate the million word WSJ cor-
pus in the Penn TreeBank (Marcus et al, 1993) with
a layer of discourse annotations. A preliminary re-
port on this project was presented at the 2004 work-
shop on Frontiers in Corpus Annotation (Miltsakaki
et al, 2004a), where we described our annotation
of discourse connectives (both explicit and implicit)
along with their (clausal) arguments.
Further work done since then includes the an-
notation of attribution: that is, who has expressed
each argument to a discourse connective (the writer
or some other speaker or author) and who has ex-
pressed the discourse relation itself. These ascrip-
tions need not be the same. Of particular interest is
the fact that attribution may or may not play a role
in the relation established by a connective. This may
lead to a lack of congruence between arguments at
the syntactic and the discourse levels. The issue of
congruence is of interest both from the perspective
of annotation (where it means that, even within a
single sentence, one cannot merely transfer the an-
notation of syntactic arguments of a subordinate or
coordinate conjunction to its discourse arguments),
and from the perspective of inferences that these an-
notations will support in future applications of the
PDTB.
The paper is organized as follows. We give a brief
overview of the annotation of connectives and their
arguments in the PDTB in Section 2. In Section 3,
we describe the annotation of the attribution of the
arguments of a connective and the relation it con-
veys. In Sections 4 and 5, we describe mismatches
that arise between the discourse arguments of a con-
nective and the syntactic annotation as provided by
the Penn TreeBank (PTB), in the cases where all the
arguments of the connective are in the same sen-
tence. In Section 6, we will discuss some implica-
tions of these issues for the theory and practice of
discourse annotation and their relevance even at the
level of sentence-bound annotation.
2 Overview of the PDTB
The PDTB builds on the DLTAG approach to dis-
course structure (Webber and Joshi, 1998; Webber
et al, 1999; Webber et al, 2003) in which con-
nectives are discourse-level predicates which project
predicate-argument structure on a par with verbs at
29
the sentence level. Initial work on the PDTB has
been described in Miltsakaki et al (2004a), Milt-
sakaki et al (2004b), Prasad et al (2004).
The key contribution of the PDTB design frame-
work is its bottom-up approach to discourse struc-
ture: Instead of appealing to an abstract (and arbi-
trary) set of discourse relations whose identification
may confound multiple sources of discourse mean-
ing, we start with the annotation of discourse con-
nectives and their arguments, thus exposing a clearly
defined level of discourse representation.
The PDTB annotates as explicit discourse connec-
tives all subordinating conjunctions, coordinating
conjunctions and discourse adverbials. These pred-
icates establish relations between two abstract ob-
jects such as events, states and propositions (Asher,
1993).1
We use Conn to denote the connective, and Arg1
and Arg2 to denote the textual spans from which the
abstract object arguments are computed.2 In (1), the
subordinating conjunction since establishes a tem-
poral relation between the event of the earthquake
hitting and a state where no music is played by a
certain woman. In all the examples in this paper, as
in (1), Arg1 is italicized, Arg2 is in boldface, and
Conn is underlined.
(1) She hasn?t played any music since the earthquake
hit.
What counts as a legal argument? Since we take
discourse relations to hold between abstract objects,
we require that an argument contains at least one
clause-level predication (usually a verb ? tensed or
untensed), though it may span as much as a sequence
of clauses or sentences. The two exceptions are
nominal phrases that express an event or a state, and
discourse deictics that denote an abstract object.
1For example, discourse adverbials like as a result are dis-
tinguished from clausal adverbials like strangely which require
only a single abstract object (Forbes, 2003).
2Each connective has exactly two arguments. The argument
that appears in the clause syntactically associated with the con-
nective, we call Arg2. The other argument is called Arg1. Both
Arg1 and Arg2 can be in the same sentence, as is the case for
subordinating conjunctions (e.g., because). The linear order of
the arguments will be Arg2 Arg1 if the subordinate clause ap-
pears sentence initially; Arg1 Arg2 if the subordinate clause ap-
pears sentence finally; and undefined if it appears sentence me-
dially. For an adverbial connective like however, Arg1 is in the
prior discourse. Hence, the linear order of its arguments will be
Arg1 Arg2.
Because our annotation is on the same corpus as
the PTB, annotators may select as arguments textual
spans that omit content that can be recovered from
syntax. In (2), for example, the relative clause is
selected as Arg1 of even though, and its subject can
be recovered from its syntactic analysis in the PTB.
In (3), the subject of the infinitival clause in Arg1 is
similarly available.
(2) Workers described ?clouds of blue dust? that hung
over parts of the factory even though exhaust fans
ventilated the air.
(3) The average maturity for funds open only to institu-
tions, considered by some to be a stronger indicator
because those managers watch the market closely,
reached a high point for the year ? 33 days.
The PDTB also annotates implicit connectives be-
tween adjacent sentences where no explicit connec-
tive occurs. For example, in (4), the two sentences
are contrasted in a way similar to having an explicit
connective like but occurring between them. Anno-
tators are asked to provide, when possible, an ex-
plicit connective that best describes the relation, and
in this case in contrast was chosen.
(4) The $6 billion that some 40 companies are looking to
raise in the year ending March 21 compares with only
$2.7 billion raise on the capital market in the previous
year. IMPLICIT - in contrast In fiscal 1984, before
Mr. Gandhi came into power, only $810 million
was raised.
When complete, the PDTB will contain approxi-
mately 35K annotations: 15K annotations of the 100
explicit connectives identified in the corpus and 20K
annotations of implicit connectives.3
3 Annotation of attribution
Wiebe and her colleagues have pointed out the
importance of ascribing beliefs and assertions ex-
pressed in text to the agent(s) holding or making
them (Riloff and Wiebe, 2003; Wiebe et al, 2004;
Wiebe et al, 2005). They have also gone a consid-
erable way towards specifying how such subjective
material should be annotated (Wiebe, 2002). Since
we take discourse connectives to convey semantic
predicate-argument relations between abstract ob-
jects, one can distinguish a variety of cases depend-
ing on the attribution of the discourse relation or its
3The annotation guidelines for the PDTB are available at
http://www.cis.upenn.edu/pdtb.
30
arguments; that is, whether the relation or arguments
are ascribed to the author of the text or someone
other than the author.
Case 1: The relation and both arguments are at-
tributed to the same source. In (5), the concessive
relation between Arg1 and Arg2, anchored on the
connective even though is attributed to the speaker
Dick Mayer, because he is quoted as having said
it. Even where a connective and its arguments are
not included in a single quotation, the attribution can
still be marked explicitly as shown in (6), where only
Arg2 is quoted directly but both Arg1 and Arg2 can
be attibuted to Mr. Prideaux. Attribution to some
speaker can also be marked in reported speech as
shown in the annotation of so that in (7).
(5) ?Now, Philip Morris Kraft General Foods? parent
company is committed to the coffee business and to
increased advertising for Maxwell House,? says Dick
Mayer, president of the General Foods USA division.
?Even though brand loyalty is rather strong for cof-
fee, we need advertising to maintain and strengthen
it.?
(6) B.A.T isn?t predicting a postponement because the
units ?are quality businesses and we are en-
couraged by the breadth of inquiries,? said Mr.
Prideaux.
(7) Like other large Valley companies, Intel also noted
that it has factories in several parts of the nation,
so that a breakdown at one location shouldn?t leave
customers in a total pinch.
Wherever there is a clear indication that a relation
is attributed to someone other than the author of the
text, we annotate the relation with the feature value
SA for ?speaker attribution? which is the case for
(5), (6), and (7). The arguments in these examples
are given the feature value IN to indicate that they
?inherit? the attribution of the relation. If the rela-
tion and its arguments are attributed to the writer,
they are given the feature values WA and IN respec-
tively.
Relations are attributed to the writer of the text by
default. Such cases include many instances of re-
lations whose attribution is ambiguous between the
writer or some other speaker. In (8), for example,
we cannot tell if the relation anchored on although
is attributed to the spokeswoman or the author of the
text. As a default, we always take it to be attributed
to the writer.
Case 2: One or both arguments have a different at-
tribution value from the relation. While the default
value for the attribution of an argument is the attribu-
tion of its relation, it can differ as in (8). Here, as in-
dicated above, the relation is attributed to the writer
(annotated WA) by default, but Arg2 is attributed to
Delmed (annotated SA, for some speaker other than
the writer, and other than the one establishing the
relation).
(8) The current distribution arrangement ends in March
1990 , although Delmed said it will continue to pro-
vide some supplies of the peritoneal dialysis prod-
ucts to National Medical, the spokeswoman said.
Annotating the corpus with attribution is neces-
sary because in many cases the text containing the
source of attribution is located in a different sen-
tence. Such is the case for (5) where the relation
conveyed by even though, and its arguments are at-
tributed to Dick Mayer.
We are also adding attribution values to the anno-
tation of the implicit connectives. Implicit connec-
tives express relations that are inferred by the reader.
In such cases, the author intends for the reader to
infer a discourse relation. As with explicit connec-
tives, we have found it useful to distinguish implicit
relations intended by the writer of the article from
those intended by some other author or speaker. To
give an example, the implicit relation in (9) is at-
tributed to the writer. However, in (10) both Arg1
and Arg2 have been expressed by the speaker whose
speech is being quoted. In this case, the implicit re-
lation is attributed to the speaker.
(9) Investors in stock funds didn?t panic the week-
end after mid-October?s 190-point market plunge.
IMPLICIT-instead Most of those who left stock
funds simply switched into money market funds.
(10) ?People say they swim, and that may mean they?ve
been to the beach this year,? Fitness and Sports. ?It?s
hard to know if people are responding truthfully.
IMPLICIT-because People are too embarrassed to
say they haven?t done anything.?
The annotation of attribution is currently under-
way. The final version of the PDTB will include an-
notations of attribution for all the annotated connec-
tives and their arguments.
Note that in the Rhetorical Structure Theory
(RST) annotation scheme (Carlson et al, 2003), at-
tribution is treated as a discourse relation. We, on
the other hand, do not treat attribution as a discourse
31
relation. In PDTB, discourse relations (associated
with an explicit or implicit connective) hold between
two abstracts objects, such as events, states, etc. At-
tribution relates a proposition to an entity, not to an-
other proposition, event, etc. This is an important
difference between the two frameworks. One conse-
quence of this difference is briefly discussed in Foot-
note 4 in the next section.
4 Arguments of Subordinating
Conjunctions in the PTB
A natural question that arises with the annotation
of arguments of subordinating conjunctions (SUB-
CONJS) in the PDTB is to what extent they can be
detected directly from the syntactic annotation in the
PTB. In the simplest case, Arg2 of a SUBCONJ is its
complement in the syntactic representation. This is
indeed the case for (11), where since is analyzed as
a preposition in the PTB taking an S complement
which is Arg2 in the PDTB, as shown in Figure 1.
(11) Since the budget measures cash flow, a new $1 di-
rect loan is treated as a $1 expenditure.
Furthermore, in (11), since together with its com-
plement (Arg2) is analyzed as an SBAR which mod-
ifies the clause a new $1 direct loan is treated as a
$1 expenditure, and this clause is Arg1 in the PDTB.
Can the arguments always be detected in this
way? In this section, we present statistics showing
that this is not the case and an analysis that shows
that this lack of congruence between the PDTB and
the PTB is not just a matter of annotator disagree-
ment.
Consider example (12), where the PTB requires
annotators to include the verb of attribution said
and its subject Delmed in the complement of al-
though. But although as a discourse connective de-
nies the expectation that the supply of dialysis prod-
ucts will be discontinued when the distribution ar-
rangement ends. It does not convey the expectation
that Delmed will not say such things. On the other
hand, in (13), the contrast established by while is be-
tween the opinions of two entities i.e., advocates and
their opponents.4
4This distinction is hard to capture in an RST-based pars-
ing framework (Marcu, 2000). According to the RST-based an-
notation scheme (Carlson et al, 2003) ?although Delmed said?
and ?while opponents argued? are elementary discourse units
(12) The current distribution arrangement ends in March
1990, although Delmed said it will continue to pro-
vide some supplies of the peritoneal dialysis prod-
ucts to National Medical, the spokeswoman said.
(13) Advocates said the 90-cent-an-hour rise, to $4.25 an
hour by April 1991, is too small for the working poor,
while opponents argued that the increase will still
hurt small business and cost many thousands of
jobs.
In Section 5, we will identify additional cases. What
we will then argue is that it will be insufficient to
train an algorithm for identifying discourse argu-
ments simply on the basis of syntactically analysed
text.
We now present preliminary measurements of
these and other mismatches between the two corpora
for SUBCONJS. To do this we describe a procedural
algorithm which builds on the idea presented at the
start of this section. The statistics are preliminary in
that only the annotations of a single annotator were
considered, and we have not attempted to exclude
cases in which annotators disagree.
We consider only those SUBCONJS for which both
arguments are located in the same sentence as the
connective (which is the case for approximately 99%
of the annotated instances). The syntactic configura-
tion of such relations pattern in a way shown in Fig-
ure 1. Note that it is not necessary for any of Conn,
Arg1, or Arg2 to have a single node in the parse tree
that dominates it exactly. In Figure 1 we do obtain a
single node for Conn, and Arg2 but for Arg1, it is
the set of nodes fNP; V Pg that dominate it exactly.
Connectives like so that, and even if are not domi-
nated by a single node, and cases where the annota-
tor has decided that a (parenthetical) clausal element
is not minimally necessary to the interpretation of
Arg2 will necessitate choosing multiple nodes that
dominate Arg2 exactly.
Given the node(s) in the parse tree that dominate
Conn (fINg in Figure 1), the algorithm we present
tries to find node(s) in the parse tree that dominate
Arg1 and Arg2 exactly using the operation of tree
subtraction (Sections 4.1, and 4.2). We then discuss
its execution on (11) in Section 4.3.
annotated in the same way: as satellites of the relation Attribu-
tion. RST does not recognize that satellite segments, such as
the ones given above, sometimes participate in a higher RST
relation along with their nuclei and sometimes not.
32
S12
SBAR NP
A new $1 direct
loan
VP
is treated as a
$1 expenditure
IN S
2
the budget mea-
sures cash flowsince
Given N
Conn
= fINg, our goal is to find N
Arg1
=
fNP; V Pg, and N
Arg2
= fS
2
g. Steps:
 h
Conn
= IN
 x
Conn+Arg2
= SBAR  parent(h
Conn
)
 x
Conn+Arg1+Arg2
= S
12
 lowest Ancestor
parent(x
Conn+Arg2
)
with la-
bel S or SBAR. Note that x 2 Ancestor
x
 N
Arg2
= x
Conn+Arg2
 N
Conn
= SBAR  fINg
= fS
2
g
 N
Arg1
= x
Conn+Arg1+Arg2
  fx
Conn+Arg2
g
= S
12
  fSBARg
= fNP; V Pg
Figure 1: The syntactic configuration for (11), and the execution of the tree subtraction algorithm on this configuration.
4.1 Tree subtraction
We will now define the operation of tree subtraction
the graphical intuition for which is given in Figure
2. Let T be the set of nodes in the tree.
Definition 4.1. The ancestors of any node t 2 T ,
denoted by Ancestor
t
 T is a set of nodes such
that t 2 Ancestor
t
and parent(u; t) ) ([u 2
Ancestor
t
] ^ [Ancestor
u
Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 31?38,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Annotating Attribution in the Penn Discourse TreeBank
Rashmi Prasad and Nikhil Dinesh and Alan Lee and Aravind Joshi
University of Pennsylvania
Philadelphia, PA 19104 USA
 
rjprasad,nikhild,aleewk,joshi  @linc.cis.upenn.edu
Bonnie Webber
University of Edinburgh
Edinburgh, EH8 9LW Scotland
bonnie@inf.ed.ac.uk
Abstract
An emerging task in text understanding
and generation is to categorize information
as fact or opinion and to further attribute
it to the appropriate source. Corpus an-
notation schemes aim to encode such dis-
tinctions for NLP applications concerned
with such tasks, such as information ex-
traction, question answering, summariza-
tion, and generation. We describe an anno-
tation scheme for marking the attribution
of abstract objects such as propositions,
facts and eventualities associated with dis-
course relations and their arguments an-
notated in the Penn Discourse TreeBank.
The scheme aims to capture the source and
degrees of factuality of the abstract ob-
jects. Key aspects of the scheme are anno-
tation of the text spans signalling the attri-
bution, and annotation of features record-
ing the source, type, scopal polarity, and
determinacy of attribution.
1 Introduction
News articles typically contain a mixture of infor-
mation presented from several different perspec-
tives, and often in complex ways. Writers may
present information as known to them, or from
some other individual?s perspective, while further
distinguishing between, for example, whether that
perspective involves an assertion or a belief. Re-
cent work has shown the importance of recogniz-
ing such perspectivization of information for sev-
eral NLP applications, such as information extrac-
tion, summarization, question answering (Wiebe
et al, 2004; Stoyanov et al, 2005; Riloff et al,
2005) and generation (Prasad et al, 2005). Part of
the goal of such applications is to distinguish be-
tween factual and non-factual information, and to
identify the source of the information. Annotation
schemes (Wiebe et al, 2005; Wilson and Wiebe,
2005; PDTB-Group, 2006) encode such distinc-
tions to facilitate accurate recognition and repre-
sentation of such perspectivization of information.
This paper describes an extended annotation
scheme for marking the attribution of discourse re-
lations and their arguments annotated in the Penn
Discourse TreeBank (PDTB) (Miltsakaki et al,
2004; Prasad et al, 2004; Webber et al, 2005), the
primary goal being to capture the source and de-
grees of factuality of abstract objects. The scheme
captures four salient properties of attribution: (a)
source, distinguishing between different types of
agents to whom AOs are attributed, (b) type, re-
flecting the degree of factuality of the AO, (c) sco-
pal polarity of attribution, indicating polarity re-
versals of attributed AOs due to surface negated
attributions, and (d) determinacy of attribution, in-
dicating the presence of contexts canceling the en-
tailment of attribution. The scheme also describes
annotation of the text spans signaling the attri-
bution. The proposed scheme is an extension of
the core scheme used for annotating attribution
in the first release of the PDTB (Dinesh et al,
2005; PDTB-Group, 2006). Section 2 gives an
overview of the PDTB, Section 3 presents the ex-
tended annotation scheme for attribution, and Sec-
tion 4 presents the summary.
2 The Penn Discourse TreeBank (PDTB)
The PDTB contains annotations of discourse rela-
tions and their arguments on the Wall Street Jour-
nal corpus (Marcus et al, 1993). Following the
approach towards discourse structure in (Webber
et al, 2003), the PDTB takes a lexicalized ap-
31
proach towards the annotation of discourse rela-
tions, treating discourse connectives as the an-
chors of the relations, and thus as discourse-level
predicates taking two abstract objects (AOs) as
their arguments. For example, in (1), the subordi-
nating conjunction since is a discourse connective
that anchors a TEMPORAL relation between the
event of the earthquake hitting and a state where
no music is played by a certain woman. (The 4-
digit number in parentheses at the end of examples
gives the WSJ file number of the example.)
(1) She hasn?t played any music since the earthquake
hit. (0766)
There are primarily two types of connectives
in the PDTB: ?Explicit? and ?Implicit?. Explicit
connectives are identified form four grammati-
cal classes: subordinating conjunctions (e.g., be-
cause, when, only because, particularly since),
subordinators (e.g., in order that), coordinating
conjunctions (e.g., and, or), and discourse adver-
bials (e.g., however, otherwise). In the examples
in this paper, Explicit connectives are underlined.
For sentences not related by an Explicit connec-
tive, annotators attempt to infer a discourse rela-
tion between them by inserting connectives (called
?Implicit? connectives) that best convey the in-
ferred relations. For example, in (2), the inferred
CAUSAL relation between the two sentences was
annotated with because as the Implicit connective.
Implicit connectives together with their sense clas-
sification are shown here in small caps.
(2) Also unlike Mr. Ruder, Mr. Breeden appears to
be in a position to get somewhere with his agenda.
Implicit=BECAUSE (CAUSE) As a former White
House aide who worked closely with Congress, he
is savvy in the ways of Washington. (0955)
Cases where a suitable Implicit connective
could not be annotated between adjacent sentences
are annotated as either (a) ?EntRel?, where the
second sentence only serves to provide some fur-
ther description of an entity in the first sentence
(Example 3); (b) ?NoRel?, where no discourse re-
lation or entity-based relation can be inferred; and
(c) ?AltLex?, where the insertion of an Implicit
connective leads to redundancy, due to the rela-
tion being alternatively lexicalized by some ?non-
connective? expression (Example 4).
(3) C.B. Rogers Jr. was named chief executive officer of
this business information concern. Implicit=EntRel
Mr. Rogers, 60 years old, succeeds J.V. White, 64,
who will remain chairman and chairman of the ex-
ecutive committee (0929).
(4) One in 1981 raised to $2,000 a year from $1,500
the amount a person could put, tax-deductible,
into the tax-deferred accounts and widened cov-
erage to people under employer retirement plans.
Implicit=AltLex (consequence) [This caused] an ex-
plosion of IRA promotions by brokers, banks, mu-
tual funds and others. (0933)
Arguments of connectives are simply labelled
Arg2, for the argument appearing in the clause
syntactically bound to the connective, and Arg1,
for the other argument. In the examples here, Arg1
appears in italics, while Arg2 appears in bold.
The basic unit for the realization of an AO ar-
gument of a connective is the clause, tensed or un-
tensed, but it can also be associated with multiple
clauses, within or across sentences. Nominaliza-
tions and discourse deictics (this, that), which can
also be interpreted as AOs, can serve as the argu-
ment of a connective too.
The current version of the PDTB also contains
attribution annotations on discourse relations and
their arguments. These annotations, however, used
the earlier core scheme which is subsumed in the
extended scheme described in this paper.
The first release of the Penn Discourse
TreeBank, PDTB-1.0 (reported in PDTB-
Group (2006)), is freely available from
http://www.seas.upenn.edu/?pdtb.
PDTB-1.0 contains 100 distinct types of Explicit
connectives, with a total of 18505 tokens, anno-
tated across the entire WSJ corpus (25 sections).
Implicit relations have been annotated in three
sections (Sections 08, 09, and 10) for the first
release, totalling 2003 tokens (1496 Implicit
connectives, 19 AltLex relations, 435 EntRel
tokens, and 53 NoRel tokens). The corpus also
includes a broadly defined sense classification for
the implicit relations, and attribution annotation
with the earlier core scheme. Subsequent releases
of the PDTB will include Implicit relations
annotated across the entire corpus, attribution
annotation using the extended scheme proposed
here, and fine-grained sense classification for both
Explicit and Implicit connectives.
3 Annotation of Attribution
Recent work (Wiebe et al, 2005; Prasad et al,
2005; Riloff et al, 2005; Stoyanov et al, 2005),
has shown the importance of recognizing and rep-
resenting the source and factuality of information
in certain NLP applications. Information extrac-
tion systems, for example, would perform better
32
by prioritizing the presentation of factual infor-
mation, and multi-perspective question answering
systems would benefit from presenting informa-
tion from different perspectives.
Most of the annotation approaches tackling
these issues, however, are aimed at performing
classifications at either the document level (Pang
et al, 2002; Turney, 2002), or the sentence or word
level (Wiebe et al, 2004; Yu and Hatzivassiloglou,
2003). In addition, these approaches focus primar-
ily on sentiment classification, and use the same
for getting at the classification of facts vs. opin-
ions. In contrast to these approaches, the focus
here is on marking attribution on more analytic se-
mantic units, namely the Abstract Objects (AOs)
associated with predicate-argument discourse re-
lations annotated in the PDTB, with the aim of
providing a compositional classification of the fac-
tuality of AOs. The scheme isolates four key prop-
erties of attribution, to be annotated as features:
(1) source, which distinguishes between different
types of agents (Section 3.1); (2) type, which en-
codes the nature of relationship between agents
and AOs, reflecting the degree of factuality of the
AO (Section 3.2); (3) scopal polarity, which is
marked when surface negated attribution reverses
the polarity of the attributed AO (Section 3.3), and
(4) determinacy, which indicates the presence of
contexts due to which the entailment of attribu-
tion gets cancelled (Section 3.4). In addition, to
further facilitate the task of identifying attribution,
the scheme also aims to annotate the text span
complex signaling attribution (Section 3.5)
Results from annotations using the earlier attri-
bution scheme (PDTB-Group, 2006) show that a
significant proportion (34%) of the annotated dis-
course relations have some non-Writer agent as
the source for either the relation or one or both ar-
guments. This illustrates the simplest case of the
ambiguity inherent for the factuality of AOs, and
shows the potential use of the PDTB annotations
towards the automatic classification of factuality.
The annotations also show that there are a variety
of configurations in which the components of the
relations are attributed to different sources, sug-
gesting that recognition of attributions may be a
complex task for which an annotated corpus may
be useful. For example, in some cases, a rela-
tion together with its arguments is attributed to the
writer or some other agent, whereas in other cases,
while the relation is attributed to the writer, one
or both of its arguments is attributed to different
agent(s). For Explicit connectives. there were 6
unique configurations, for configurations contain-
ing more than 50 tokens, and 5 unique configura-
tions for Implicit connectives.
3.1 Source
The source feature distinguishes between (a) the
writer of the text (?Wr?), (b) some specific agent
introduced in the text (?Ot? for other), and (c)
some generic source, i.e., some arbitrary (?Arb?)
individual(s) indicated via a non-specific reference
in the text. The latter two capture further differ-
ences in the degree of factuality of AOs with non-
writer sources. For example, an ?Arb? source for
some information conveys a higher degree of fac-
tuality than an ?Ot? source, since it can be taken
to be a ?generally accepted? view.
Since arguments can get their attribution
through the relation between them, they can be an-
notated with a fourth value ?Inh?, to indicate that
their source value is inherited from the relation.
Given this scheme for source, there are broadly
two possibilities. In the first case, a relation
and both its arguments are attributed to the same
source, either the writer, as in (5), or some other
agent (here, Bill Biedermann), as in (6). (At-
tribution feature values assigned to examples are
shown below each example; REL stands for the
discourse relation denoted by the connective; At-
tribution text spans are shown boxed.)
(5) Since the British auto maker became a takeover
target last month, its ADRs have jumped about
78%. (0048)
REL Arg1 Arg2
[Source] Wr Inh Inh
(6) ?The public is buying the market when in re-
ality there is plenty of grain to be shipped,?
said Bill Biedermann  (0192)
REL Arg1 Arg2
[Source] Ot Inh Inh
As Example (5) shows, text spans for im-
plicit Writer attributions (corresponding to im-
plicit communicative acts such as I write, or I say),
are not marked and are taken to imply Writer attri-
bution by default (see also Section 3.5).
In the second case, one or both arguments have
a different source from the relation. In (7), for
example, the relation and Arg2 are attributed to
the writer, whereas Arg1 is attributed to another
agent (here, Mr. Green). On the other hand, in (8)
and (9), the relation and Arg1 are attributed to the
writer, whereas Arg2 is attributed to another agent.
33
(7) When Mr. Green won a $240,000 verdict in a land
condemnation case against the state in June 1983,
he says Judge O?Kicki unexpectedly awarded him
an additional $100,000. (0267)
REL Arg1 Arg2
[Source] Wr Ot Inh
(8) Factory orders and construction outlays were largely
flat in December while purchasing agents said
manufacturing shrank further in October. (0178)
REL Arg1 Arg2
[Source] Wr Inh Ot
(9) There, on one of his first shopping trips, Mr.
Paul picked up several paintings at stunning prices.
 Afterward, Mr. Paul is said by Mr. Guterman
to have phoned Mr. Guterman, the New York de-
veloper selling the collection, and gloated. (2113)
REL Arg1 Arg2
[Source] Wr Inh Ot
Example (10) shows an example of a generic
source indicated by an agentless passivized attri-
bution on Arg2 of the relation. Note that pas-
sivized attributions can also be associated with
a specific source when the agent is explicit, as
shown in (9). ?Arb? sources are also identified
by the occurrences of adverbs like reportedly, al-
legedly, etc.
(10) Although index arbitrage is said to add liquidity to
markets, John Bachmann,  says too much liq-
uidity isn?t a good thing. (0742)
REL Arg1 Arg2
[Source] Wr Ot Arb
We conclude this section by noting that ?Ot?
is used to refer to any specific individual as the
source. That is, no further annotation is provided
to indicate who the ?Ot? agent in the text is. Fur-
thermore, as shown in Examples (11-12), multiple
?Ot? sources within the same relation do not indi-
cate whether or not they refer to the same or differ-
ent agents. However, we assume that the text span
annotations for attribution, together with an inde-
pendent mechanism for named entity recognition
and anaphora resolution can be employed to iden-
tify and disambiguate the appropriate references.
(11) Suppression of the book, Judge Oakes observed ,
would operate as a prior restraint and thus involve
the First Amendment. Moreover, and
here Judge Oakes went to the heart of the question ,
?Responsible biographers and historians con-
stantly use primary sources, letters, diaries, and
memoranda. (0944)
REL Arg1 Arg2
[Source] Wr Ot Ot
(12) The judge was considered imperious, abrasive and
ambitious, those who practiced before him say .
Yet, despite the judge?s imperial bearing, no one
ever had reason to suspect possible wrongdoing,
says John Bognato, president of Cambria  .(0267)
REL Arg1 Arg2
[Source] Wr Ot Ot
3.2 Type
The type feature signifies the nature of the rela-
tion between the agent and the AO, leading to dif-
ferent inferences about the degree of factuality of
the AO. In order to capture the factuality of the
AOs, we start by making a three-way distinction
of AOs into propositions, facts and eventualities
(Asher, 1993). This initial distinction allows for
a more semantic, compositional approach to the
annotation and recognition of factuality. We de-
fine the attribution relations for each AO type as
follows: (a) Propositions involve attribution to an
agent of his/her (varying degrees of) commitment
towards the truth of a proposition; (b) Facts in-
volve attribution to an agent of an evaluation to-
wards or knowledge of a proposition whose truth
is taken for granted (i.e., a presupposed proposi-
tion); and (c) Eventualities involve attribution to
an agent of an intention/attitude towards an even-
tuality. In the case of propositions, a further dis-
tinction is made to capture the difference in the de-
gree of the agent?s commitment towards the truth
of the proposition, by distinguishing between ?as-
sertions? and ?beliefs?. Thus, the scheme for the
annotation of type ultimately uses a four-way dis-
tinction for AOs, namely between assertions, be-
liefs, facts, and eventualities. Initial determination
of the degree of factuality involves determination
of the type of the AO.
AO types can be identified by well-defined se-
mantic classes of verbs/phrases anchoring the at-
tribution. We consider each of these in turn.
Assertions are identified by ?assertive predi-
cates? or ?verbs of communication? (Levin, 1993)
such as say, mention, claim, argue, explain etc.
They take the value ?Comm? (for verbs of Com-
munication). In Example (13), the Ot attribution
on Arg1 takes the value ?Comm? for type. Im-
plicit writer attributions, as in the relation of (13),
also take (the default) ?Comm?. Note that when an
argument?s attribution source is not inherited (as
in Arg1 in this example) it also takes its own inde-
pendent value for type. This example thus conveys
that there are two different attributions expressed
within the discourse relation, one for the relation
and the other for one of its arguments, and that
both involve assertion of propositions.
34
(13) When Mr. Green won a $240,000 verdict in a land
condemnation case against the state in June 1983,
he says Judge O?Kicki unexpectedly awarded him
an additional $100,000. (0267)
REL Arg1 Arg2
[Source] Wr Ot Inh
[Type] Comm Comm Null
In the absence of an independent occurrence of
attribution on an argument, as in Arg2 of Exam-
ple (13), the ?Null? value is used for the type on
the argument, meaning that it needs to be derived
by independent (here, undefined) considerations
under the scope of the relation. Note that unlike
the ?Inh? value of the source feature, ?Null? does
not indicate inheritance. In a subordinate clause,
for example, while the relation denoted by the sub-
ordinating conjunction may be asserted, the clause
content itself may be presupposed, as seems to be
the case for the relation and Arg2 of (13). How-
ever, we found these differences difficult to deter-
mine at times, and consequently leave this unde-
fined in the current scheme.
Beliefs are identified by ?propositional attitude
verbs? (Hintikka, 1971) such as believe, think, ex-
pect, suppose, imagine, etc. They take the value
?PAtt? (for Propostional Attitude). An example of
a belief attribution is given in (14).
(14) Mr. Marcus believes spot steel prices will continue
to fall through early 1990 and then reverse them-
selves. (0336)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] PAtt Null Null
Facts are identified by the class of ?factive and
semi-factive verbs? (Kiparsky and Kiparsky, 1971;
Karttunen, 1971) such as regret, forget, remember,
know, see, hear etc. They take the value ?Ftv?
(for Factive) for type (Example 15). In the current
scheme, this class does not distinguish between
the true factives and semi-factives, the former in-
volving an attitute/evaluation towards a fact, and
the latter involving knowledge of a fact.
(15) The other side , he argues knows Giuliani has al-
ways been pro-choice, even though he has personal
reservations. (0041)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] Ftv Null Null
Lastly, eventualities are identified by a class of
verbs which denote three kinds of relations be-
tween agents and eventualities (Sag and Pollard,
1991). The first kind is anchored by verbs of influ-
ence like persuade, permit, order, and involve one
agent influencing another agent to perform (or not
perform) an action. The second kind is anchored
by verbs of commitment like promise, agree, try,
intend, refuse, decline, and involve an agent com-
mitting to perform (or not perform) an action. Fi-
nally, the third kind is anchored by verbs of ori-
entation like want, expect, wish, yearn, and in-
volve desire, expectation, or some similar mental
orientation towards some state(s) of affairs. These
sub-distinctions are not encoded in the annotation,
but we have used the definitions as a guide for
identifying these predicates. All these three types
are collectively referred to and annotated as verbs
of control. Type for these classes takes the value
?Ctrl? (for Control). Note that the syntactic term
control is used because these verbs denote uni-
form structural control properties, but the primary
basis for their definition is nevertheless semantic.
An example of the control attribution relation an-
chored by a verb of influence is given in (16).
(16) Eward and Whittington had planned to leave the bank
earlier, but Mr. Craven had persuaded them to re-
main until the bank was in a healthy position.
(1949)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] Ctrl Null Null
Note that while our use of the term source ap-
plies literally to agents responsible for the truth of
a proposition, we continue to use the same term
for the agents for facts and eventualities. Thus,
for facts, the source represents the bearers of atti-
tudes/knowledge, and for considered eventualities,
the source represents intentions/attitudes.
3.3 Scopal Polarity
The scopal polarity feature is annotated on re-
lations and their arguments to primarily identify
cases when verbs of attribution are negated on the
surface - syntactically (e.g., didn?t say, don?t think)
or lexically (e.g., denied), but when the negation in
fact reverses the polarity of the attributed relation
or argument content (Horn, 1978). Example (17)
illustrates such a case. The ?but? clause entails an
interpretation such as ?I think it?s not a main con-
sideration?, for which the negation must take nar-
row scope over the embedded clause rather than
the higher clause. In particular, the interpretation
of the CONTRAST relation denoted by but requires
that Arg2 should be interpreted under the scope
of negation.
35
(17) ?Having the dividend increases is a supportive ele-
ment in the market outlook, but I don?t think it?s a
main consideration,? he says. (0090)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] Comm Null PAtt
[Polarity] Null Null Neg
To capture such entailments with surface nega-
tions on attribution verbs, an argument of a con-
nective is marked ?Neg? for scopal polarity when
the interpretation of the connective requires the
surface negation to take semantic scope over the
lower argument. Thus, in Example (17), scopal
polarity is marked as ?Neg? for Arg2.
When the neg-lowered interpretations are not
present, scopal polarity is marked as the default
?Null? (such as for the relation and Arg1 of Ex-
ample 17).
It is also possible for the surface negation of at-
tribution to be interpreted as taking scope over the
relation, rather than an argument. We have not ob-
served this in the corpus yet, so we describe this
case with the constructed example in (18). What
the example shows is that in addition to entailing
(18b) - in which case it would be annotated par-
allel to Example (17) above - (18a) can also en-
tail (18c), such that the negation is intrepreted as
taking semantic scope over the ?relation? (Lasnik,
1975), rather than one of the arguments. As the
scopal polarity annotations for (18c) show, low-
ering of the surface negation to the relation is
marked as ?Neg? for the scopal polarity of the re-
lation.
(18) a. John doesn?t think Mary will get cured because
she took the medication.
b.   John thinks that because Mary took the
medication, she will not get cured.
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] PAtt Null Null
[Polarity] Null Neg Null
c.   John thinks that Mary will get cured
not because she took the medication (but be-
cause she has started practising yoga.)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] PAtt Null Null
[Polarity] Neg Null Null
We note that scopal polarity does not capture
the appearance of (opaque) internal negation that
may appear on arguments or relations themselves.
For example, a modified connective such as not
because does not take ?Neg? as the value for sco-
pal polarity, but rather ?Null?. This is consistent
with our goal of marking scopal polarity only for
lowered negation, i.e., when surface negation from
the attribution is lowered to either the relation or
argument for interpretation.
3.4 Determinacy
The determinacy feature captures the fact that the
entailment of the attribution relation can be made
indeterminate in context, for example when it ap-
pears syntactically embedded in negated or condi-
tional contexts.. The annotation attempts to cap-
ture such indeterminacy with the value ?Indet?.
Determinate contexts are simply marked as the de-
fault ?Null?. For example, the annotation in (19)
conveys the idea that the belief or opinion about
the effect of higher salaries on teachers? perfor-
mance is not really attributed to anyone, but is
rather only being conjectured as a possibility.
(19) It is silly libel on our teachers to think they would
educate our children better if only they got a few
thousand dollars a year more. (1286)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] PAtt Null Null
[Polarity] Null Null Null
[Determinacy] Indet Null Null
3.5 Attribution Spans
In addition to annotating the properties of attribu-
tion in terms of the features discussed above, we
also propose to annotate the text span associated
with the attribution. The text span is annotated as
a single (possibly discontinuous) complex reflect-
ing three of the annotated features, namely source,
type and scopal polarity. The attribution span also
includes all non-clausal modifiers of the elements
contained in the span, for example, adverbs and
appositive NPs. Connectives, however, are ex-
cluded from the span, even though they function
as modifiers. Example (20) shows a discontinu-
ous annotation of the attribution, where the paren-
thetical he argues is excluded from the attribution
phrase the other side knows, corresponding to the
factive attribution.
(20) The other side , he argues knows Giuliani has al-
ways been pro-choice, even though he has personal
reservations. (0041)
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] Ftv Null Null
[Polarity] Null Null Null
[Determinacy] Null Null Null
Inclusion of the fourth feature, determinacy,
is not ?required? to be included in the current
scheme because the entailment cancelling contexts
36
can	 be very complex. For example, in Exam-
ple (19), the conditional interpretation leading to
the indeterminacy of the relation and its arguments
is due to the syntactic construction type of the en-
tire sentence. It is not clear how to annotate the
indeterminacy induced by such contexts. In the
example, therefore, the attribution span only in-
cludes the anchor for the type of the attribution.
Spans for implicit writer attributions are left un-
marked since there is no corresponding text that
can be selected. The absence of a span annota-
tion is simply taken to reflect writer attribution,
together with the ?Wr? value on the source fea-
ture.
Recognizing attributions is not trivial since they
are often left unexpressed in the sentence in which
the AO is realized, and have to be inferred from the
prior discourse. For example, in (21), the relation
together with its arguments in the third sentence
are attributed to Larry Shapiro, but this attribution
is implicit and must be inferred from the first sen-
tence.
(21) ?There are certain cult wines that can command these
higher prices,? says Larry Shapiro of Marty?s, 
?What?s different is that it is happening with young
wines just coming out. We?re seeing it partly because
older vintages are growing more scarce.? (0071)
REL Arg1 Arg2
[Source] Ot Inh Inh
The spans for such implicit ?Ot? attributions
mark the text that provides the inference of the
implicit attribution, which is just the closest occur-
rence of the explicit attribution phrase in the prior
text.
The final aspect of the span annotation is that
we also annotate non-clausal phrases as the an-
chors attribution, such as prepositional phrases
like according to X, and adverbs like reportedly,
allegedly, supposedly. One such example is shown
in (22).
(22) No foreign companies bid on the Hiroshima project,
according to the bureau . But the Japanese prac-
tice of deep discounting often is cited by Ameri-
cans as a classic barrier to entry in Japan?s mar-
ket. (0501)
REL Arg1 Arg2
[Source] Wr Ot Inh
[Type] Comm Comm Null
[Polarity] Null Null Null
[Determinacy] Null Null Null
Note that adverbials are free to pick their own type
of attribution. For example, supposedly as an at-
tribution adverb picks ?PAtt? as the value for type.
3.6 Attribution of Implicit Relations
Implicit connectives and their arguments in the
PDTB are also marked for attribution. Implicit
connectives express relations that are inferred by
the reader. In such cases, the writer intends for
the reader to infer a discourse relation. As with
Explicit connectives, implicit relations intended
by the writer of the article are distinguished from
those intended by some other agent introduced by
the writer. For example, while the implicit rela-
tion in Example (23) is attributed to the writer, in
Example (24), both Arg1 and Arg2 have been
expressed by someone else whose speech is be-
ing quoted: in this case, the implicit relation is at-
tributed to the other agent.
(23) The gruff financier recently started socializing in
upper-class circles. Implicit = FOR EXAMPLE
(ADD.INFO) Although he says he wasn?t keen on go-
ing, last year he attended a New York gala where
his daughter made her debut. (0800)
REL Arg1 Arg2
[Source] Wr Inh Inh
[Type] Comm Null Null
[Polarity] Null Null Null
[Determinacy] Null Null Null
(24) ?We asked police to investigate why they are
allowed to distribute the flag in this way.
Implicit=BECAUSE (CAUSE) It should be con-
sidered against the law,?
said Danny Leish, a spokesman for the association .
REL Arg1 Arg2
[Source] Ot Inh Inh
[Type] Comm Null Null
[Polarity] Null Null Null
[Determinacy] Null Null Null
For implicit relations, attribution is also anno-
tated for AltLex relations but not for EntRel and
NoRel, since the former but not the latter refer to
the presense of discourse relations.
4 Summary
In this paper, we have proposed and described an
annotation scheme for marking the attribution of
both explicit and implicit discourse connectives
and their arguments in the Penn Discourse Tree-
Bank. We discussed the role of the annotations for
the recognition of factuality in natural language
applications, and defined the notion of attribution.
The scheme was presented in detail with exam-
ples, outlining the ?feature-based annotation? in
terms of the source, type, scopal polarity, and
determinacy associated with attribution, and the
?span annotation? to highlight the text reflecting
the attribution features.
37
Ackno


wledgements
The Penn Discourse TreeBank project is partially
supported by NSF Grant: Research Resources,
EIA 02-24417 to the University of Pennsylva-
nia (PI: A. Joshi). We are grateful to Lukasz
Abramowicz and the anonymous reviewers for
useful comments.
References
Nicholas. Asher. 1993. Reference to Abstract Objects
in Discourse. Kluwer, Dordrecht.
Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Rashmi
Prasad, Aravind Joshi, and Bonnie Webber. 2005.
Attribution and the (non)-alignment of syntactic and
discourse arguments of connectives. In Proceedings
of the ACL Workshop on Frontiers in Corpus Anno-
tation II: Pie in the Sky, Ann Arbor, Michigan.
Jaakko Hintikka. 1971. Semantics for propositional at-
titudes. In L. Linsky, editor, Reference and Modal-
ity, pages 145?167. Oxford.
Laurence Horn. 1978. Remarks on neg-raising. In
Peter Cole, editor, Syntax and Semantics 9: Prag-
matics. Academic Press, New York.
Lauri Karttunen. 1971. Some observations on factiv-
ity. Papers in Linguistics, 4:55?69.
Carol Kiparsky and Paul Kiparsky. 1971. Fact. In
D. D. Steinberg and L. A. Jakobovits, editors, Se-
mantics: An Interdisciplinary Reader in Philosophy,
Linguistics and Psychology, pages 345?369. Cam-
bridge University Press, Cambridge.
Howard Lasnik. 1975. On the semantics of nega-
tion. In Contemporary Research in Philosophi-
cal Logic and Linguistic Semantics, pages 279?313.
Dordrecht: D. Reidel.
Beth Levin. 1993. English Verb Classes And Alter-
nations: A Preliminary Investigation. University of
Chicago Press.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of english: The Penn Treebank. Computa-
tional Linguistics, 19(2):313?330.
Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and
Bonnie Webber. 2004. Annotating discourse con-
nectives and their arguments. In Proceedings of the
HLT/NAACL Workshop on Frontiers in Corpus An-
notation, pages 9?16, Boston, MA.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP-2002), pages 79?86.
Rashmi Prasad, Eleni Miltsakaki, Aravind Joshi, and
Bonnie Webber. 2004. Annotation and data mining
of the Penn Discourse Treebank. In Proceedings of
the ACL Workshop on Discourse Annotation, pages
88?95, Barcelona, Spain.
Rashmi Prasad, Aravind Joshi, Nikhil Dinesh, Alan
Lee, Eleni Miltsakaki, and Bonnie Webber. 2005.
The Penn Discourse TreeBank as a resource for nat-
ural language generation. In Proceedings of the
Corpus Linguistics Workshop on Using Corpora for
NLG.
Ellen Riloff, Janyce Wiebe, and Willian Phillips. 2005.
Exploiting subjectivity classification to improve in-
formation extraction. In Proceedings of the 20th Na-
tional Conference on Artificial Intelligence (AAAI-
2005).
Ivan A. Sag and Carl Pollard. 1991. An integrated
theory of complement control. Language, 67(1):63?
113.
The PDTB-Group. 2006. The Penn Discourse Tree-
Bank 1.0 Annotation Manual. Technical Report
IRCS-06-01, Institute for Research in Cognitive Sci-
ence, University of Pennsylvania.
Veseli Stoyanov, Claire Cardie, and Janyce Wiebe.
2005. Multi-perspective question answering using
the OpQA corpus. In Proceedings of HLT-EMNLP.
Peter D. Turney. 2002. Thumbs up or thumbs down?
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of ACL 2002,
pages 417?424.
Bonnie Webber, Aravind Joshi, M. Stone, and Alis-
tair Knott. 2003. Anaphora and discourse structure.
Computational Linguistics, 29(4):545?587.
Bonnie Webber, Aravind Joshi, Eleni Miltsakaki,
Rashmi Prasad, Nikhil Dinesh, Alan Lee, and
K. Forbes. 2005. A short introduction to the PDTB.
In Copenhagen Working Papers in Language and
Speech Processing.
Janyce Wiebe, Theresa Wilson, Rebecca Bruce,
Matthew Bell, and Melanie Martin. 2004. Learn-
ing subjective language. Computational Linguistics,
30(3):277?308.
Janyce Wiebe, Theresa Wilson, , and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language Resources and Evalu-
ation, 1(2).
Theresa Wilson and Janyce Wiebe. 2005. Annotating
attributions and private states. In Proceedings of the
ACL Workshop on Frontiers in Corpus Annotation
II: Pie in the Sky, Ann Arbor, Michigan.
Hon Yu and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: separating facts
from opinions and identifying the polarity of opinion
sentences. In Proceedings of EMNLP-2003, pages
129?136, Saporo, Japan.
38
Extracting Formal Specifications from Natural
Language Regulatory Documents
Nikhil Dinesh, Aravind Joshi, and Insup Lee
Department of Computer Science, Univeristy of Pennsylvania,
Philadelphia, PA - 19104 USA
nikhild,joshi,lee@cis. upenn.edu
Bonnie Webber
University of Edinburgh, Edinburgh, EH8 9LW Scotland
bonnie@inf.ed. ac. uk
Abstract
Formal verification techniques provide a way to determine whether regulatory doc-
uments are consistent and whether implementations conform to them. To apply
these techniques a formal description of the regulation needs to be extracted. We
present a framework, under which NLP techniques can be brought to bear, to aid
a requirements engineer in extracting the formal description.
1 Introduction
Regulatory documents, which include the vast bodies of legislation, operating
procedures and organizational policy, are meant to be accessible to the people
affected by them. Hence, they have to be in natural language (NL). On
the other hand, regulations are expected to be consistent, and the governed
entities/events are expected to conform to the regulation.
For example, the Food and Drug Administration?s Code of Federal Reg-
ulations (FDA CFR) governs the bloodbanks in America. 1 The bloodbanks
perform safety-critical functions like the testing of blood for communicable
disease agents (like HIV). It is highly desirable to determine whether (a) the
CFR is consistent, and (b) a bloodbank?s implementation of such a function
conforms to the CFR.
? This research was supported in part by NSF CCF-0429948 and ARO 911NF-05-1-0158
1 http://www.gpoaccess.gov/cfr/index.html
The problem of creating descriptions of regulation which can be checked
for consistency has been explored by several authors [1,8], but the challenge of
checking an implementation for conformance has not been addressed, and this
is the main goal of our work. The conformance guarantees can be obtained
if formal descriptions of regulation and implementations are available, and if
verification techniques [4] can be applied to these descriptions. But extracting
a formal description of regulation is expensive, as regulatory bases like the
CFR are large (about a million words) and complex.
Formal descriptions of regulation are usually extracted by an individual
who has a background in logic, e.g., [1,8]. We will call this individual the
requirements engineer. In this paper, we describe a framework to assist a
requirements engineer in extracting a formal description of regulation for use
in conformance checking.
An overview of the framework, the theoretical background and the various
constraints that apply is given in Section 2. This lets us determine the nature
of the description that needs to be extracted from the regulation. We then
turn to the question of how these descriptions might be composed. In Section
3, we attempt to map the denotations of sentences assigned by Kratzer [12]
to a form that can be used for the task at hand. Some difficulties arise in
this mapping, mainly because notions of obligation (that which is required)
and permission (that which is allowed) are not captured in the denotations.
We argue that an account of these notions is essential to the task at hand.
Section 4 describes a semantic representation, and composition procedure to
assist the requirements engineer in extracting the required description. By
treating obligations and permissions as different dimensions of the description
computed, the difficulties encountered in Section 3 are addressed.
The approach is motivated by our case study of the FDA CFR, and we
use (1) and (2) as examples through the course of this paper. 2 (1) conveys
an obligation to perform a test for HIV and Hepatitis B, and (2) conveys a
permission not to test source plasma (a blood component) for Hepatitis B.
(1) Except as specified in (2), you must test each donation of human blood or blood
component, for evidence of infection due to the Human immunodeficiency virus,
and the Hepatitis B virus.
(2) You are not required to test donations of Source Plasma for evidence of infection
due to the Hepatitis B virus.
2 A Framework
To determine whether an implementation (bloodbank) conforms to the regu-
lation (CFR), we extract specifications in the Computation Tree Logic (CTL)
from the CFR. Then, given a description of a bloodbank?s procedure (as a
finite transition system, or model) there is an efficient search procedure to
2 (1) and (2) are modified versions of sentences that appear in the FDA CFR 610.40. The
actual sentences are very long, and the modifications are made in the interests of space.
determine if the model conforms to the CTL specification [3]. This is known
as temporal model checking [2,13]. The problem of conformance checking is
thus split into three steps:
(1) Extract CTL specifications from the regulation - This is done by a
requirements engineer, and our goal is to assist her. We use CTL as the
specification language, because it allows for efficient model checking [3].
(2) Obtain a model of an implementation - We assume the availability of
models. There are tools that aid in extracting models from software [5], and
in creating models if they cannot be extracted directly [11].
(3) Apply model checking to determine if the model conforms to the CTL
specification.
Formally, a model can be defined as follows:
Definition 2.1 A model M is the five-tuple (S, I, ?, pi,?), where:
(a) S is a set of states, I ? S is a non-empty set of initial states,
(b) ? ? S ? S is a total transition relation (that is, ?s ? S : [?t ? S : (s, t) ? ?]),
(c) pi is a set of propositions (with power set 2pi), and
(d) ? : S ? 2pi is a function from states to sets of propositions. ?(s) for s ? S can be
thought of as the propositions true at s.
Figure 1(a) and 1(b) show models of two different bloodbanks. The left-
most state is the initial state. Each state is labeled with ?(s). The propo-
sitions have the following interpretation: d? is true (d? ? ?(s)) iff a donation
of blood or blood component is being processed, sp? is true iff a donation of
source plasma is being processed, thiv? is true iff a test for HIV has been per-
formed, and thepb? is true iff a test for Hepatitis B has been performed. The
use of the propositions deo (denoting deontic accessibility) and app1 (denoting
the application of a permission) is explained in later sections.
deo, d?,
sp?,
thiv?,
thepb?
deo, d?,
thiv?,
thepb?
(a) A model of a bloodbank
which tests all donations
deo, d?,
sp?,
thiv?,
app1
deo, d?,
thiv? ,
thepb?
(b) A model of a bloodbank
which does not test dona-
tions of source plasma for
Hepatitis B
Fig. 1. Two models of bloodbanks
Definition 2.2 Given a finite set of propositions pi, CTL formulas are defined induc-
tively as follows:
(a) p ? pi is a formula,
(b) Boolean combinations and negations of formulas are formulas,
(c) if ?, and ? are formulas, then AG(?) (on all paths, globally ?), AX(?) (on all
paths, at the next state ?), and ?AU?) (on all paths, ? until ?) are formulas.
The only temporal operator in CTL that we use is AG (for reasons that
we describe below), and hence rather than define the interpretation formally,
we will give some examples. Let M1 be the model in Figure 1(a), and M2 be
the model in Figure 1(b). The CTL specification AG(deo ? (d? ? thiv?)) holds
of both models, since on all paths (from the initial state, the leftmost one in
Figures 1(a), and 1(b)), globally, in all deontically accessible states deo, if a
donation of blood or blood component is being processed d?, it is tested for HIV
thiv?. Hence, we write M1  AG(deo ? (d? ? thiv?)), and M2  AG(deo ? (d? ?
thiv?)). Also, M1  AG(deo ? (sp? ? thepb?)). But, M2 6 AG(deo ? (sp? ? thepb?))
(since there is a state s with sp? ? ?(s), and thepb? 6? ?(s)).
2.1 Approaches to extracting specifications
The central problem we face is that CTL and other temporal logics that lend
themselves to model checking are not expressive enough for a compositional
semantic procedure to be defined for natural language. One reason is that
CTL, like propositional logic, cannot express relations between entities.
There are several routes one might take to address this problem, i.e., design
more expressive logics that allow for tractable model checking, focus on a
subset of NL from which an automatic translation is guaranteed, or make
the procedure machine-assisted. While the design of more expressive logics
makes the composition of specifications easier, using them for model checking
needs the creation of more expressive models (which requires more effort).
As a result, there is a trade-off between amount of effort spent in obtaining
models, and that in obtaining the specifications. Our decision to work with
less expressive models is motivated by the extensive tool support available
for creating and extracting such models [5,11]. Further, subsets of NL for
which automatic translation is guaranteed, such as the one derived by Holt
and Klein [10], assume (among other things) that references are resolved and
hence cannot be directly applied to regulatory documents. We are thus left
with the choice of making the procedure machine-assisted.
There have been two kinds of machine-assisted approaches to extracting
temporal logic specifications: (a) composing the semantics in a general seman-
tic framework which is then mapped to temporal logic [7], and (b) attempting
to compose the semantics in the temporal logic directly [6]. In the latter ap-
proach, a human specifies denotations for a portion of the sentence, and the
rest of the composition happens automatically. We attempt to compose the
semantics in a temporal logic directly like [6], as it lends itself to defining
semantic representations with which a requirements engineer can interact in
well-defined ways.
2.2 Constraints on the CTL specifications
We apply two constraints to the CTL specifications:
(i) The specifications extracted should hold of all and only the valid mod-
els. There may be several implementations that aim to conform to a single
base of regulation. Given (1) and (2), the models in Figures 1(a) and 1(b) are
both valid. This is an important difference from the NL sentences considered
in previous approaches, which were elicited from appropriate users by pre-
senting them with a single model. For example, Holt and Klein [10] obtained
specifications by asking users to describe a particular timing diagram.
(ii) To account for the variation between models, all temporal information
about the governed entities/events is modelled through propositions. The only
use of the temporal operators in CTL is to obtain a quantification over paths
and states. A mapping will need to be performed so that the propositions
used in the specifications can be evaluated at a states in different models, and
the critical assumption is that this mapping will be very easy to specify.
3 From Sets of Worlds to Sets of Models
Several approaches in formal semantics take sentences to denote sets of worlds.
For normative statements, we assume (following Kratzer [12]) that worlds are
connected by an accessibility relation. Consider (1) in Section 1 which among
other things requires a test for Hepatitis B if no exceptions apply. A denotation
of this requirement is given in (3), and is the set of worlds w0, such that for
every deontically accessible world w, for every entity x such that x is a donation
in that world d?(x,w), if no exception holds of that donation ?e?(x,w), a test
for Hepatitis B is carried out for that donation thepb?(x,w). We will assume
that negation has the highest precedence. Therefore ?a ? b ? (?a) ? b, and
brackets are used to resolve other ambiguities.
(3) ?w0.?w : (w ? deo(w0)? (?x : (d?(x,w) ? (?e?(x,w)? thepb?(x,w)))))
A difference between worlds in Kratzer?s denotations and states in a model
is that: in a state there is no notion of entities and relations between them.
All that is available at a state s is the set of propositions which are true at
that state ?(s). To map (3) to a form that is useful for checking conformance,
we need two assumptions.
First, we assume that regulation denotes the set of models that conform to
it. Intuitively speaking, w0 in (3) can be thought of as a model in its entirety,
and w ? deo(w0) correspond to special states in the model. A universal quan-
tification over accessible worlds can be replaced with the CTL AG operator.
We then obtain the denotation in (4), read as : on every path in M, if a state is
deontically accessible, for each donation x at that state, if no exception holds,
a test is carried out. In a model, only special states (like when the bloodbank
has finished processing all the donations it has received) need to conform to
the regulation, and deo can be thought of as marking those states.
(4) ?M. M  AG(deo? (?x : (d?(x)? (?e?(x)? thepb?(x)))))
(4) is still not in CTL because of the universal quantification over enti-
ties x at a state. The universal quantifier can be eliminated by assuming a
serial processing model. This has the effect that at the deontically accessible
states, exactly one donation is under consideration (e.g. the models in Fig-
ures 1(a) and 1(b)). In the sections of the CFR that we examined, a universal
quantification over entities is absolutely essential when these entities corre-
spond to inputs of an implemenation. This assumption lets us tie the inputs
to states, and use the quantification over states to achieve the quantification
over entities. Thus (4) can be reduced to (5).
(5) ?M. M  AG(deo? (d? ? (?e? ? thepb?)))
A problem that is encountered in taking this approach is that there is no
distinction between obligations, and permissions (both of which stem from the
Hohfeldian legal conceptions of right, duty, privilege, and no right [9]). While
this did not cause a problem for the obligation in (1), if one were to follow the
same procedure for the permission in (2), we would get the denotation in (6).
(6) ?M. M  ?(AG(deo ? (sp? ? thepb?)))
A model satisfies (6) only if there is some path in which there is a state that
is deontically accessible, and if a donation of source plasma is being processed
it is not tested. This is too strong a requirement, because an organization may
choose not to do what it is permitted to do. The model in Figure 1(a) is a
valid model, which would be declared invalid if (6) were required of it.
Another problem is that it is not clear how one would use (6) in interpreting
the exemption e? in (5). A reasonable candidate is e? ? deo ? (sp? ? ?thepb?).
But this is not the exemption because it is true in every deontically accessible
state in which a donation of source plasma is not being processed. Consider a
state s at which sp? = false (sp? 6? ?(s)). At s, e? ? (deo ? (false ? ?thepb?)) ?
(deo? true) ? true. The specification in (5), at s is: AG(deo? (?e? ?thepb?)) ?
AG(deo ? (?true ? ?thepb?)) ? AG(deo ? true) ? AG(true) ? true . Therefore, a
model that doesn?t test any donation for Hepatitis B would conform to (5).
We now turn to the task of addressing these problems by revising how the
specifications are composed.
4 Extracting the specifications
To aid the requirements engineer in extracting the specifications, the idea
is to present her with intermediate semantic representations of the sentence
with which she interacts. The intermediate representations that we use fall
into the category of abstract syntax trees (ASTs). ASTs are generally used as
intermediate representations in compiling code in a high-level programming
language to machine dependant code. The internal nodes in ASTs are oper-
ators (predicates/meta-predicates), the subtrees they dominate are operands
(arguments), and leaf nodes correspond to variables or constants (the require-
ments engineer specifies the denotation of the leaves). An AST encodes the
resolution of scope ambiguities, i.e., if p1 dominates p2 in the AST, then p1
outscopes p2.
Section 4.1 describes some phenomena in natural language that can be
used in the construction of the ASTs, and how these ASTs can be interpreted.
In Section 4.2, we describe how the ASTs and their interpretation for (1) and
(2) (in Figures 3 and 4) address the problems described in Section 3. 3
4.1 Abstract Syntax Trees (ASTs) and their interpretation
To capture the distinction between obligations and permissions, the denotation
of each node N in an AST is given by the 3-tuple: [[N ]] =
0
@
?N
ON
PN
1
A , where ON
is a set of propositional logic formulas which correspond to the obligations
that have been satisified, and PN is a set of propositional logic formulas that
correspond to the permissions that have been taken, and ?N is a propositional
logic formula which can be thought of as indicating whether N is true at a
state. The set of obligations O obtained from the policy base is the union
of the obligations obtained at the root of the AST for each sentence. The
denotation of the policy base is then given by: ?M. M  AG
0
@deo ?
^
??O
?
1
A . We
now identify various linguistic constructions that can be used to obtain ASTs.
Copy
p i z T l1, l2....ln
p
T :
[
z ? l1, i ? 1
]
... T :
[
z ? ln, i ? n
]
Fig. 2. Semantics of the Copy meta-predicate
Copy
and i z each
x is a donation of hu-
man blood or blood com-
ponent ?(1). i .1
except as
specified in (2) -
?(1). i .2
must
you, test x , for evi-
dence of infection due
to z - ?(1). i .3
the Human immuno-
deficiency vius
the Hepatitis B virus
and
?
?
?(1).1.1 ? (??(1).1.2 ? ?(1).1.3)
{?(1).1.1 ? (??(1).1.2 ? ?(1).1.3)}
{}
?
?
?
?
?(1).1.1
{}
{}
?
?
?
?
??(1).1.2 ? ?(1).1.3
{??(1).1.2 ? ?(1).1.3}
{}
?
?
?
?
?(1).1.2
{}
{}
?
?
?
?
?(1).1.3
{?(1).1.3}
{}
?
?
?
?
?(1).1.3
{}
{}
?
?
...
Fig. 3. AST and its interpretation for (1)
Distributive readings and the Copy meta-predicate: (1) is ambigu-
ous between a collective reading (where there is a single test for both the
3 We assume that obligation and permission denoting categories, e.g. must, do not occur
in contexts like antecedent clauses of subordinating conjunctions (like if), and restrictors of
determiners. Handling these cases requires an extension to CTL which is beyond the scope
of this paper.
every
x is a donation of Source
Plasma - ?2.1
not
are required
you to test x for evidence of
infection due to the Hepatitis B
virus z of this section - ?2.2
?
?
?(2).1 ? app1 ? ??(2).2
{}
{?(2).1 ? app1 ? ??(2).2}
?
?
?
?
?(2).1
{}
{}
?
?
?
?
app1 ? ??(2).2
{}
{app1 ? ??(2).2}
?
?
?
?
?(2).2
{?(2).2}
{}
?
?
?
?
?(2).2
{}
{}
?
?
Fig. 4. AST and its interpretation for (2)
diseases), and a distributive reading (where there are separate tests for each
disease). However, (2) gives an exemption to a test for one of the diseases, and
this suggests that a distributive reading may be more appropriate in the spec-
ifications extracted, and that the distributivity has scope over the exception.
Hence Copy dominates except in Figure 3.
The interpretation of the Copy meta-predicate is given in Figure 2. It is
called a meta-predicate because it is a function from an AST to another AST,
by simple variable substitution. For the AST for (1) shown in Figure 3, this
results in an AST rooted with and with subtrees corresponding to each of the
tests. The interpretation of and in this context is given by:
and
0
@
?1A
O1A
P1A
1
A ...
0
@
?nA
OnA
PnA
1
A =
0
@
?ni=1?iA
?ni=1OiA
?ni=1PiA
1
A
The RHS of the equation corresponds to the denotation of the node labeled
and in the AST (shaded in gray in Figure 3).
Universally Quantified NPs correponding to inputs: As mentioned
in Section 3, the universal quantification over inputs (donations) is achieved
by associating states with unique inputs. The interpretation of the determiner
each is designed with idea that the obligations will be evaluated at each state.
each
0
@
?A
{}
{}
1
A
0
@
?B
OB
PB
1
A =
0
@
?A ? ?B
{?A ? ?BO.j |?BO.j ? OB}
{?A ? ?BP.j |?BP.j ? PB}
1
A
The interpretation of the determiner no is similar to that of each/every,
except that a negation needs to be applied to the nuclear scope. We discuss
the interpretation of negation in what follows.
Conditional and Exceptive constructions: There are several predi-
cates that denote conditions and exceptions. For example, the subordinat-
ing conjunctions if , unless, and except as, coordinating conjunctions like
except that or but. The interpretation of if is the same as that for every. The
interpretation of predicates like except as, and unless are similar, the only
difference being that ??A is used instead of ?A in the RHS.
Modals and Negation: The semantics of modals and negation are given
below:
must
0
@
?A
{}
{}
1
A =
0
@
?A
{?A}
{}
1
A may
0
@
?A
{}
{}
1
A =
0
@
appi ? ?A
{}
{appi ? ?A}
1
A
not
0
@
?A
OA
PA
1
A =
0
@
??A
{??AP.j |?AP.j ? PA}
{appj ? ??AO.j |?AO.j ? OA}
1
A , where ??A =
?
appj ? ??A ?A ? ?AO.j ? OA
??A otherwise
must(A) results in the interpretation that ?A is an obligation. may(A)
results in the interpretation that appi ? ?A is a permission, where appi is
a variable introduced which the implementation must set to true when the
permission is applied (we discuss its use in Section 4.2). And intuitively, the
interpretation of negation captures the idea that may(?A) ? not(must(A)).
4.2 Discussion
There are two obligations obtained at the root of the AST for (1): ?(1).1.1 ?
(??(1).1.2 ? ?(1).1.3) ? d? ? (?e?1 ? thiv?) and ?(1).2.1 ? (??(1).2.2 ? ?(1).2.3) ?
d? ? (?e?2 ? thepb?) , where d? is true iff the donation is one of blood or blood
component, e?1 and e?2 are the exceptions to the required test for each disease,
and thiv? and thepb? are true iff tests for HIV and Hepatitis B respectively
have been performed. The computation of the second obligation is not shown
in Figure 3, and is obtained from the second child of and (in the AST shaded
in gray). Note that the individual propositions like d? need to be specified by
the requirements engineer at the leaf nodes of the AST.
Figure 4 shows the AST and its interpretation for (2). The permission
obtained at the root node is : ?(2).1?app1???(2).2 ? sp??app1??thepb? where sp?
is true iff a donation of source plasma is being processed, and thepb? is true iff
a test for the Hepatitis B virus has been carried out.
The use of the app1 proposition is as follows. It is possible for the regula-
tion to cancel the permission given in (2), but there may be several cases in
which permission not to test a donation of source plasma for Hepatitis B is
given. Suppose the case under consideration is one where the permission in
(2) is cancelled, but the organization doesn?t test a donation of source plasma
for Hepatitis B because a different permission can be applied. Since the per-
mission being applied sets thepb? to false, and sp? is true, the only way for the
implementation to indicate that the permission in (2) is not being applied is
by setting app1 to false. Setting e?1 ? false, and e?2 ? sp? ? app1 ? ?thepb?:
?O.1 ? d? ? (?false? thiv?), and ?O.2 ? d? ? (?(sp? ? app1 ? ?thepb?)? thepb?)
Considering just these obligations, the denotation of the regulatory doc-
ument would be: ?M. M  AG(deo ? (?O.1 ? ?O.2)) . Therefore, a bloodbank
could decide not to test a donation of source plasma for Hepatitis B, but they
would always have to test a donation for HIV.
5 Conclusions and Future Work
We have described a framework to assist a requirements engineer in extracting
CTL specifications from regulatory documents. An account of obligations and
permissions turns out to be essential in composing the specifications. The
composition procedure (defined in Section 4) was applied to a large part of
the FDA CFR 610.40. While it does seem to scale well, providing tool support
to extract and interact with the ASTs is vital. To this end, we plan to conduct
a small scale annotation of ASTs which will let us determine the accuracy with
which these representations can be computed. On the user interface side, we
are working on ways of presenting the ASTs to the requirements engineer.
References
[1] Breuker, J. and N. den Haan, Separating world and regulation knowledge: where is the
logic?, in: M. Sergot, editor, Proceedings of the third international conference on AI
and Law (1991), pp. 41?51.
[2] Clarke, E. M. and E. A. Emerson, Synthesis of synchronization skeletons for branching
time temporal logic, in: Logic of Programs: Workshop, 1981.
[3] Clarke, E. M., E. A. Emerson and A. P. Sistla, Automatic verification of finite-
state concurrent systems using temporal logic specifications, ACM Transactions on
Programming Languages and Systems 8 (1986), pp. 244?263.
[4] Clarke, E. M. and J. M. Wing, Formal methods: State of the art and future directions,
ACM Computing Surveys 28 (1996), pp. 626?643.
[5] Corbett, J. C., M. B. Dwyer, J. Hatcliff, S. Laubach, C. S. Pasareanu, Robby and
H. Zheng, Bandera: Extracting finite-state models from java source code, in: Proceedings
of the International Conference on Software Engineering (ICSE), 2000.
[6] Fantechi, A., S. Gnesi, G. Ristori, M. Carenini, M. Marino and M. Moreschini, Assisting
requirements formalization by means of natural language translation, Formal Methods
in System Design 4 (1994), pp. 243?263.
[7] Fuchs, N. and R. Schwitter, Attempto controlled english (ace), in: First International
Workshop on Controlled Language Applications, 1996.
[8] Glasse, E., T. V. Engers and A. Jacobs, Power: An integrated method for legislation and
regulations from their design to their use in e-government services and law enforcement,
in: M.-F. Moens, editor, Digitale Wetgeving, Digital Legislation, Die Keure Brugge, 2003
pp. 175?204, iSBN 90 5958 039 7.
[9] Hohfeld, W. N., Fundamental legal conceptions as applied in judicial reasoning, Yale
Law Journal 23 (1913), pp. 16?59.
[10] Holt, A. and E. Klein, A semantically-derived subset of English for hardware
verification, in: 37th Annual Meeting of the ACL, 1999.
[11] Holzmann, G., The Spin model checker, IEEE Trans. on Software Engineering 23
(1997), pp. 279?295.
[12] Kratzer, A., The notational category of modality, in: H.-J. Eikmeyer and H. Rieser,
editors, Words, Worlds, and Contexts. New approaches to Word Semantics, deGruyter,
Berlin, 1981 .
[13] Queille, J. P. and J. Sifakis, Specification and verification of concurrent systems in
CAESAR, in: Proceeding of the Fifth ISP, 1981.
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1202?1212,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Computing Logical Form on Regulatory Texts?
Nikhil Dinesh
Artificial Intelligence Center
SRI International
Menlo Park, CA - 94025
dinesh@ai.sri.com
Aravind Joshi and Insup Lee
Department of Computer Science
University of Pennsylvania
Philadelphia, PA - 19104
{joshi,lee}@seas.upenn.edu
Abstract
The computation of logical form has been pro-
posed as an intermediate step in the translation
of sentences to logic. Logical form encodes
the resolution of scope ambiguities. In this
paper, we describe experiments on a modest-
sized corpus of regulation annotated with a
novel variant of logical form, called abstract
syntax trees (ASTs). The main step in com-
puting ASTs is to order scope-taking opera-
tors. A learning model for ranking is adapted
for this ordering. We design features by study-
ing the problem of comparing the scope of one
operator to another. The scope comparisons
are used to compute ASTs, with an F-score of
90.6% on the set of ordering decisons.
1 Introduction
May (1985) argued for a level of logical form as a
prelude to translating sentences to logic. Just as a
parse tree determines the constituent structure of a
sentence, a logical form of a sentence represents one
way of resolving scope ambiguities. The level of
logical form is an appealing layer of modularity; it
allows us to take a step beyond parsing in studying
scope phenomenon, and yet, avoid the open problem
of fully translating sentences to logic.
Data-driven analyses of scope have been of in-
terest in psycholinguistics (Kurtzman and MacDon-
ald, 1993) and more recently in NLP (Srinivasan
and Yates, 2009). The focus has typically been
?This research was supported in part by ONR MURI
N00014-07-1-0907, NSF CNS-1035715, NSF IIS 07-05671,
and SRI International.
on predicting the preferred scopal ordering of sen-
tences with two quantifying determiners, for exam-
ple, in the sentence ?every kid climbed a tree?. In
the related problem of translating database queries
to logic, Zettlemoyer and Collins (2009) and Wong
and Mooney (2007) consider the scope of adjectives
in addition to determiners, for example the scope of
?cheapest? in the noun phrase ?the cheapest flights
from Boston to New York?. To our knowledge, em-
pirical studies of scope have been restricted to phe-
nomenon between and within noun phrases.
In this paper, we describe experiments on a novel
annotation of scope phenomenon in regulatory texts
? Section 610 of the Food and Drug Administra-
tion?s Code of Federal Regulations1 (FDA CFR).
Determiners, modals, negation, and verb phrase
modifiers are the main scope-taking operators. We
have annotated 195 sentences with a variant of log-
ical form, called abstract syntax trees (ASTs). Our
focus is on the problem of computing the AST, given
a (variant of a) parse tree of a sentence.
The long term goal of this work is to assist in the
translation of regulation to logic, for the application
of conformance checking. The problem is to for-
mally determine whether an organization conforms
to regulation, by checking the organization?s records
using the logical translation of regulation. Confor-
mance checking has been of interest in a variety of
regulatory contexts, and examples include privacy
policy (Barth et al, 2006; Jones and Sergot, 1992;
Anderson, 1996) and business contracts (Governa-
tori et al, 2006; Grosof et al, 1999).
We now discuss some problems that arise in defin-
1http://www.gpoaccess.gov/cfr/index.html
1202
ing logical form and the assumptions that we make
to circumvent these problems.
1.1 Problems and Assumptions
A key assumption of logical form is that the trans-
lation from language to logic is syntax-based. As
a result, the logic needs to be expressive enough to
accomodate a syntactic translation. There is no con-
sensus logic for constructs, such as, plurals, purpose
clauses, and certain modals. This leads to the fol-
lowing problem in defining logical form.
How do we define the logical form of a sentence,
without defining the logic? We adopt a specific for-
malism that accomodates a subset of the constructs
found in regulation. We generalize from the formal-
ized constructs to other constructs. Some of these
generalizations may need revision in the future.
We assume that sentences in regulation are trans-
lated to statements in logic of the form:
(id) ?(x1, ..., xn) 7? ?(x1, ..., xn)
where, ?id? is an identifier, ? is the precondition,
? is the postcondition, and x1, ..., xn are free vari-
ables. The distinction between pre and postcondi-
tions has been adopted by most logics for regula-
tion, to accomodate exceptions to laws (Sergot et al,
1986; Makinson and van der Torre, 2000; Governa-
tori et al, 2006). The pre and postconditions are
expressed in a modal logic that we designed in prior
work (Dinesh et al, 2011). In describing the logi-
cal form, we will sketch how the logical form can
be mapped to logic. But, we do not assume that the
reader has a detailed understanding of the logic.
Given the assumptions about the logic, our goal
is to transform a regulatory sentence into a structure
that lets us determine: (I) the constituents of a sen-
tence that contribute to the pre/postcondition, and
(II) the scope of operators in the pre/postcondition.
The structures that we use are called abstract syn-
tax trees (ASTs), which can be understood as a re-
stricted kind of logical form for regulatory texts.
1.2 Contributions and Outline
In this paper, we focus on the problem of computing
the AST given a (kind of) parse tree for a sentence.
The main step is is to order or rank scope-taking
operators. A learning model for ranking is adapted
for this ordering. We design features by studying the
problem of comparing the scope of one operator to
another. The pairwise scope comparisons are then
used to compute ASTs, with an F-score of 90.6% on
the set of ordering decisons.
The rest of this paper is organized as follows. We
define ASTs using an example in Section 2, and
setup the learning problem in Section 3. We then de-
scribe the corpus using statistics about operators in
Section 4. In Section 5, we describe experiments on
comparing the scope of an operator to another. We
use the pairwise scope comparisons, in Section 6 to
comput the AST. We discuss related work in Sec-
tion 7 and conclude in Section 8.
2 Abstract Syntax Trees
We describe abstract syntax trees (ASTs) using an
example from CFR Section 610.11:
(1) A general safety test for the detection of extra-
neous toxic contaminants shall be performed on
biological products intended for administration
to humans.
We discuss the translation in logic and the AST
for the fragment of (1) that appears in black. In or-
der to keep figures to a manageable size, we restrict
attention to fragments of sentences, by graying out
portions. The term AST is borrowed from compil-
ers (Aho et al, 1986), where it is used as an interme-
diate step in the semantic interpretation of programs.
Translation in Logic: The sentence (1) is formally
expressed as:
(1) bio prod(x) 7? Om(x)(?y : test(y) ? ?(x, y))
where, ?(x, y) = gensaf(y)?ag(y,m(x))?ob(y, x)
The predicates and function symbols are read as
follows. bio prod(x) - ?x is a biological product?.
m(x) denotes the manufacturer of x. The modal op-
erator O stands for ?obligation?. test(y) - ?y is a
test (event)?. gensaf(y) - ?y is a general safety pro-
cedure?. ag(y,m(x)) - ?the agent of y ism(x)?, and
ob(y, x) - ?the object of the event y is x?. The for-
malized version of the law is read as follows: ?If x
is a biological product, then the manufacturer m(x)
is required/obligated to perform a general safety test
y which has x as its object?. We refer the reader
to (Dinesh et al, 2011) for details on the logic.
1203
The distinction between pre and postconditions
is a non-trivial assumption. As with all logic-
programming formalisms, only free variables are
?shared? between pre and postconditons. This im-
plies that all existential quantification, modals, and
negation appear within the pre or postcondition. In
the example above, the existential quantifier (?y)
and the modal (O) appear within the postcondition.
Abstract Syntax Tree: The AST for (1) is shown in
Figure 1. The main nodes of interest are the inter-
nal nodes labeled ? . An internal node with n + 1
children corresponds to an n-ary operator. The first
child of the internal node is the operator. Opera-
tors are labeled with a part-of-speech tag, for exam-
ple, ?D? for determiner, ?M? for modal, and ?O? for
other. The remaining n children are its arguments.
We use the term nuclear scope to refer to the last
(nth) argument of the operator, and the term restric-
tor to refer to any other argument. We borrow these
terms from the literature on quantifier scope for de-
terminers (Heim and Kratzer, 1998, Chapter 7).
For example, the phrase ?general safety test? is in
the restrictor of the operator A, and the variable y
is in its nuclear scope. The modal shall is a unary
operator, and doesn?t have a restrictor. Non-unary
operators bind the variable displayed on the internal
node. The variable y is bound by the operator A.
Implicit operators are inserted when there is no
overt word or phrase. In Figure 1, the implicit oper-
ators are underlined. The generic noun phrase ?bi-
ological products? is associated with the implicit de-
terminer all. Similarly, we use the implicit operator
Post to mark the position of the postcondition.
?x
D
all
R
bio. prod.
?
O
Post
?
M
shall
?
M
be
?y
D
A
R
gen. saf. test
.
y performed on x
Figure 1: Example of an abstract syntax tree (AST).
We conclude this section with some notation for
describing ASTs. Given an AST for a sentences, we
say that an operator oi scopes over oj, denoted oi 
oj, if oj appears in the nuclear scope of oi. For ex-
ample, in Figure 1, we have all  Post, all  shall,
all  A, Post  A, and shall  A. In addition, we
say that the restrictor of oi scopes over oj, denoted
R(oi)  oj, if oj appears in the restrictor of oi. Such
configurations occur with PP-modification of NPs,
and we discuss examples in later sections.
3 Computing ASTs ? Overview
In this section, we give an overview of our approach
to computing ASTs. We will assume as given a Pro-
cessed Parse Tree (PPT) of a sentence, with the op-
erators and their restrictors identified. An example
is discussed in Section 3.1. Given such a PPT, the
AST is computed in two steps: (1) finding the preter-
minal at which an operator takes scope, and (2) or-
dering the operators associated with a preterminal.
We describe the second step in Section 3.2, and then
briefly outline the first step in Section 3.3. The steps
are described in reverse order, because in most cases,
the operators associated with a preterminal are deter-
mined directly by syntactic attachment.
3.1 Processed Parse Trees
We compute ASTs from processed parse trees
(PPTs) of sentences. Figure 2 gives the PPT cor-
responding to the AST in Figure 1.
.
?
P
Post
?y
D
A
R
gen. saf. test
?
M
shall
?
M
be
.
performed on
?x
D
IMP
R
bio. prod.
Figure 2: Processed parse tree (PPT) for (1).
A PPT provides the set of operators in a sen-
tence, associated with their restrictors. For exam-
ple, the determiner ?a? has the restrictor general
safety test. The phrase biological products has no
explicit determiner associated with it, and the cor-
responding operator in the PPT is labeled ?IMP?
for implicit. In addition, the postcondition marker
?Post? is also identified. Except for the postcon-
1204
dition marker, annotator-specified implicit operators
are not given in the PPT.
There are two main types of nodes in the PPT ?
operators and preterminals. The nodes labeled with
the symbol ?, e.g., ? and ?x , correspond to op-
erators. The root of the PPT and the restrictors of
the operators, are the preterminals. Based on this
example, it may seem that a sentence just has a list
of operators. While this is true of example (1), em-
bedded operators arise, for example, in the context
of PP-modification of NPs and relative clauses. We
will discuss an example in Section 3.3.
In this work, the PPTs are obtained by removing
all scope decisions from the AST. To a first approxi-
mation, we start by removing all operators from the
AST, and then, replace the corresponding variables
by the operators. Implicit unary operators (such as
the postcondition marker) are placed at the start of
the preterminal.
It is worthwhile to consider whether it is rea-
sonable to assume PPTs as given. We believe that
this assumption is (slightly) stronger than assuming
perfect parse trees. Although the PPT leaves cer-
tain chunks of the sentence unprocessed, in most
cases, the unprocessed chunks correspond to base
NPs. The main additional piece of information is the
existence of a postcondition marker for each main
clause of a sentence. We believe that computation
of PPTs is better seen as a problem of syntax rather
than scope, and we set it aside to future work. Our
focus here is on converting a PPT to an AST.
3.2 Ordering Operators
The problem of learning to order a set of items is
not new. Cohen et al (1998) give a learning theo-
retic perspective, and Liu (2009) surveys informa-
tion retrieval applications. The approach that we use
can be seen as a probabilistic version of the boosting
approach developed by Cohen et al (1998). We ex-
plain the step of ordering operators, by revisiting the
example of the general safety test, from Section 2.
Given the PPT in Figure 2, we compute the AST
in Figure 1 by ordering or ranking the operators. For
example, we need to determine that the implicit de-
terminer associated with biological products is uni-
versal, and hence, we have IMP  Post. However,
the determiner ?A? associated with general safety
test is existential, and hence, we have Post  A.
We now develop some notation to describe the
scopal ordering of operators. A PPT ? is viewed
as a set of preterminal nodes, and we will write ?
(a) p ? ? to denote that p occurs in ? , and (b)
|? | to denote the number of preterminals in ? . A
preterminal p is viewed as an ordered set of oper-
ators p = (o1, ..., o|p|). For example, in Figure 2,
the root preterminal p has |p| = 5, and the operators
o1 = Post, o2 = A, o3 = shall, and so on.
An AST ? contains a ranking of operators asso-
ciated with each preterminal, denoted r?(p). The
ranks of operators are denoted by subscripts. Let
p = (o1, ..., o5) be the root preterminal of the PPT
in Figure 2. The ranking associated with the AST in
Figure 1 is given by r?(p) = (o12, o25, o33, o44, o51). For
example, o25 = A denotes that the determiner ?A? ap-
pears second in the surface order (Figure 2) and fifth
or lowest in the scope order (Figure 1). Similarly,
o51 = IMP denotes that the implicit determiner ap-
pears fifth or last in the surface order (Figure 2) and
first or highest in the scope order (Figure 1). Note
that the subscript suffices to identify the position of
an operator in the AST.
Model: We now describe the learning model for or-
dering operators. Given a PPT ? , let A(?) be the set
of all possible ASTs. Our goal is to find the AST
which has the highest probability given the PPT:
?? = arg max
??A(?)
P (?|?)
The conditional probability of an AST is defined as:
P (?|?) =
?
p??
P (r?(p)|?)
P (r?(p)|?) =
|p|?1?
i=1
|p|?
j=i+1
P (oi  oj|?)
In other words, P (?|?) is modeled as the product
of the probabilities of the ranking of each pretermi-
nal, which is in turn expressed as the product of the
probabilities of the pairwise ordering decisions. The
model falls under the class of pairwise ranking ap-
proaches (Liu, 2009). We will consider the problem
of estimating the probabilities in Section 5, and the
problem of searching for the best AST in Section 6.
1205
.?
P
Post
?x3
D
IMP
R
samp. of
?x1
D
any
R
.
lot of
?x2
D
a
R
lic. prod.
?
M
may
?
M
be
.
...
Figure 3: PPT for (2)
?x1
D
any
R
?x2
D
a
R
lic. prod.
.
lot of x2
?
P
Post
?
M
may
?
M
be
?x3
D
some
R
samp. of x1
.
...
Figure 4: AST for (2)
3.3 Finding the Scope Preterminal
In the example that we discussed in the previous sec-
tion, there were no embedded operators, i.e., an op-
erator or its variable located in the restrictor of an-
other. An embedded operator can either ? (a) take
scope within the restrictor of the embedding oper-
ator, or (b) outscope the embedding operator. To
account for the second case, we need to determine
whether it is appropriate to lift an embedded opera-
tor to a higher preterminal than the one to which it
is associated syntactically.
We discuss an example of inverse linking (Larson,
1985) to illustrate the problem. Consider the follow-
ing sentence:
(2) Samples of any lot of a licensed product, except
for radioactive biological products, together with
the protocols showing results of applicable tests,
may at any time be required to be sent to the Di-
rector, Center for Biologics Evaluation and Re-
search.
The PPT and AST for (2) are shown in Figures 3
and 4 respectively. Consider the noun phrase ?IMP
samples of any lot of a licensed product? in the
.
?
P
Post
?x1
D
any
R
.
lot of
?x2
D
a
R
lic. prod.
?x3
D
IMP
R
samp. of x1
?
M
may
?
M
be
.
...
Figure 5: Second PPT for (2), obtained from the PPT in
Figure 3, by raising any to the root preterminal.
PPT. The implicit determiner IMP in the PPT is in-
terpreted as the existential determiner some in the
AST. The three operators are related as follows in
the AST: any  some and R(any)  a, i.e., any
outscopes the implicit determiner, and a appears in
the restrictor of any. Observe that the variables x1
and x2 , which are associated with any and a, ap-
pear in the restrictors of some and any respectively.
As a result, in the PPT, in Figure 3, any and a appear
in the restrictor of IMP and any. The PPT provides
a standard parse of PP-modification of NPs.
The important feature of this example is that
the determiner ?any? is syntactically embedded in
the restrictor of IMP in the PPT (Figure 4), but it
outscopes the implicit determiner in the AST (Fig-
ure 3). As a result, the PPT in Figure 3 cannot be
converted to the AST in Figure 4 simply by ranking
sibling operators (as we did in the previous section).
To handle such cases, we convert the PPT in Fig-
ure 3 to a second PPT (shown in Figure 5). The only
allowed operation during this conversion is to raise
an embedded operator to a higher preterminal. The
PPT in Figure 5 is obtained by raising any to the
root preterminal, making it a sibling of the implicit
determiner IMP in the PPT in Figure 5. This second
PPT can be converted to the AST by reordering sib-
ling operators. The learning model used for this step
is similar to the one used to order operators, and in
the interests of space, we omit the details.
4 Brief Overview of the Corpus
We have annotated 195 sentences from the FDA
CFR Section 610 with ASTs. The operators are di-
vided into the following types ? determiners (e.g.,
1206
every, a, at least), modal auxiliaries (e.g., must,
be), VP modifiers (e.g., if, for, after), negation and
coordinating conjunctions (e.g., and, but, or). The
majority of the corpus was annotated by a single an-
notator. However, to estimate inter-annotator agree-
ment, a set of 32 sentences was annotated by a
second annotator. In this section, we restrict our-
selves to presenting statistics that highlight part of
the guidelines and motivate the features that we use
to order operators. An example-based justification
of guidelines, and a discussion of inter-annotator
agreement can be found in (Dinesh, 2010).
De Re vs De Dicto: We narrow our focus to one part
of the annotation, the de re vs de dicto distinction.
Informally, operators with de re scope occur in the
precondition of the logical translation of a sentence,
while those with de dicto scope occur in the post-
condition. This distinction is of key importance in
the application of conformance checking, as it helps
determine the facts that need to be provided by an
organization (de re), and the actions that an organi-
zation is required to take (de dicto).
For simplicity, we further restrict attention to op-
erators that are siblings of the postcondition in the
AST, and ignore the operators embedded in preposi-
tional phrases and clauses, for example. A (main
clause) operator o is said to have de re scope iff
it outscopes the postcondition marker (o  Post).
Otherwise, the operator is said to have de dicto scope
(Post  o). In the example of the general safety test
from Section 2, the implicit determiner associated
with ?biological products? has de re scope, while all
other operators in the sentence have de dicto scope.
Operator Number of De Re Scope
Type Instances Percentage
Determiner 277 59.9%
Modal Aux 268 0%
VP Modifier 132 68.2%
CC 36 22.2%
Neg 33 0%
Other 74 17.6%
Table 1: De Re scope distribution. An operator has de re
scope iff it outscopes the postcondition marker.
Table 1 shows the percentage of each type of op-
erator that has de re scope. Modal auxiliaries and
negation are umambigous to this distinction, and al-
ways have de dicto scope. Note that a type of opera-
tor with 50% occuring de re is ambiguous, while 0%
or 100% are unambiguous. Thus, from Table 1, we
can conclude that determiners, and VP modifiers are
the most ambiguous types. And, more features are
needed to disambiguate them.
Determiner Number of De Re Scope
Type Instances Percentage
Universal 74 100%
Existential 12 0%
Ambiguous 50 28%
Deictic 127 53.5%
Other 14 35.7%
Table 2: De Re scope distribution for determiners.
Determiners: We divide the determiners into the
following subtypes: universal/generic (e.g., every,
all), existential (some), ambiguous (e.g., a, an), de-
ictic (e.g., the, those), and other (e.g., at least, at
most). The guidelines for annotation were as fol-
lows ? (a) universal determiners have de re scope,
(b) existential determiners have de dicto scope, and
(c) for other determiners, the annotator needs to de-
cide whether a particular use is interpreted existen-
tially or universally. Table 2 shows de re scope dis-
tribution for each of these subtypes. As expected,
universal and existential determiners are unambigu-
ous, while ambiguous and deictic determiners show
more variety. For example, the deictic determiner
the can refer to a specific entity (?the FDA?) or have
a universal interpretation (?the products?).
Thus, to disambiguate between de re and de dicto
interpretations for determiners, we need two types of
features ? (1) Features to predict whether ambiguous
and deictic determiners are universal or not, and (2)
Features to determine the type of implicit determin-
ers. In Table 2, we assume that the type of implicit
determiners are given. This assumption is unreal-
istic. Rather, we need to predict the type of such
determiners, during the computation of the AST.
VP Modifier Number of De Re Scope
Type Instances Percentage
Temporal and Conditional 73 100%
Purpose 8 0%
References to Laws 33 0.9%
Other 29 65.5%
Table 3: De Re scope distribution for VP modifiers.
1207
VP Modifiers: We divide the VP modifiers into the
following subtypes: temporal and conditional (e.g.,
after, if), purpose (for), references to laws (which
are a special type of modifier in the legal domain,
e.g., ?as specified in paragraph (c)?), and other (e.g.,
regardless, notwithstanding). Table 3 shows the
percentage of each subtype of modifier that has de
re scope. Following the guidelines for annotation,
the temporal and conditional modifiers are always de
re, the purpose modifiers and modifiers conveying
references to laws are always de dicto.
5 Comparing the Scope of Operators
We now consider a subproblem in computing the
AST ? comparing the scope of pairs of operators.
In Section 6, we will use the classifiers that perform
comparisons, to compute the AST. All experiments
in this section use the MAXENT implentation from
the MALLET toolkit (McCallum, 2002). We begin
by revisiting de re-de dicto distinction from Sec-
tion 4. Then, we generalize to other comparisons.
De Re vs De Dicto: The (binary) classification
problem is as follows. Our observations are triples
x = (o, o?, ?) are such that there is a preterminal
p ? ? , {o, o?} ? p, and o? = Post. In other words,
we are considering operators (o) that are siblings of
the postcondition marker (o?). An observation has
the label 1 if o  o? (de re scope), and a label of 0
otherwise (de dicto scope).
Features: We use the following (classes of) fea-
tures for an observation x = (o, o?, ?):
? TYPE - The type and subtype of the operator.
We use the subtypes from Section 4 only for
explicit operators.
? PRE-VERB - Tracks whether o and o? appear
before or after the main verb of the sentence.
? PRE-VERB + PERF - Conjunction of the previ-
ous feature with whether the main verb is per-
form. The verb perform is frequent in the CFR,
and its subject is typically given de dicto scope,
as it is the main predicate of the sentence.
? POS - The part-of-speech of the head word. For
example, for the noun phrase biological prod-
ucts, the head word is products, and the POS is
NNS (plural common noun). And, this POS tag
may indicate a generic/universal interpretation.
Count MAJORITY TYPE ALL
All 823 66.2% 84.1% 89.2%
No MD 522 53.2% 74.9% 83.7%
DT 277 59.9% 62.9% 81.2%
Imp. DT 100 69% 76%
Table 4: De Re vs De Dicto classification. Average accu-
racies over 10-fold cross-validation. The rows describe
the subset of observations considered, and the columns
describe the subset of features used.
Experiments: We evaluate the features by perform-
ing 10-fold cross-validation. The results are summa-
rized in Table 4. The rows describe the subset of ob-
servations used. ?All? includes all observations, ?No
MD? excludes the modal auxiliaries, ?DT? includes
only the determiners, and ?Imp. DT? includes only
implicit determiners. The columns describe the fea-
tures used. MAJORITY is the majority baseline, i.e.,
the accuracy obtained by predicting the most fre-
quent class or the majority class. The majority class
is de dicto when all operators are considered (the
first row), and de re in all other rows. The TYPE
column gives the accuracy when only the type and
subtypes are used as features. This column does not
apply to implicit determiners, as the subtype infor-
mation is unavailable. And, finally, the ALL column
gives the accuracy when all features are used.
From Table 4, we can conclude that the TYPE fea-
ture is useful in making the de re-de dicto distinc-
tion, and further gains are obtained by using ALL
features. The most dramatic improvement is for de-
terminers, and indeed, our features were designed
for this case. However, the performance gains are
not very high for implicit determiners, and further
investigation is needed.
Next, we apply the features to more general oper-
ator comparisons. The first row of Table 5 considers
observations x = (o, o?, ?), where o and o? are sib-
lings, and predicts whether o  o?. The second row
considers observations where o? is embedded syn-
tactically within o, and predicts whether R(o)  o?.
In other words, the problem is to determine whether
a syntactically embedded operator remains scopally
embedded, or whether it has inverse scope (see Sec-
tion 3.3).
1208
Count MAJORITY TYPE ALL
Siblings 2793 76.1% 83.3% 87.5%
Embedded 5081 95% 95.3% 96.4%
Table 5: Ordering siblings and embedded operators.
Average accuracies over 10-fold cross-validation. The
columns describe the subset of features used.
6 From Operator Comparisons to ASTs
We now consider the problem of computing the
AST given the classifiers for comparing operators.
Section 6.1 describes the algorithms used. In Sec-
tion 6.2, we develop metrics to evaluate the com-
putation of ASTs. We conclude, in Section 6.3, by
evaluating different algorithms using the metrics.
6.1 Algorithms
We begin by discussing the intractability of the prob-
lem of ranking or ordering operators. Then, we
sketch the search heuristics used.
Intractability: The decision version of the rank-
ing problem is NP-complete. A similar result is es-
tablished by Cohen et al (1998) in the context of a
boosting approach to ranking.
Theorem 1. The following problem is NP-complete:
Input: A PPT ? , a preterminal p ? ? , probabilities
P (oi  oj|?), and c ? [0, 1]
Output: Yes, if there is an ordering r such that
P (r(p)|?) ? c
The proof is by reduction from ACYCLIC SUB-
GRAPH (Karp, 1972) ? finding a subgraph which is
acyclic and has at least k edges.
Heuristics: To order operators, we use a beam
search procedure. Each search state consists preter-
minal, in which the first i ranks have been assigned
to operators. We then search over next states by as-
signing the rank i+1 to one of the remaining opera-
tors. We used a beam size of 104 in our experiments.
In most cases, the number of operators per preter-
minal is less than 7. As a result, the total number
of possible orderings is typically less than 7!, and a
beam size of 104 is sufficient to compute an exact or-
dering. In other words, due to the size restrictions, in
most cases, beam search is equivalent to exact (ex-
haustive) search.
To handle embedded operators, we use a simple
greedy heuristic. We enumerate the operators in the
initial PPT, corresponding to an in-order traversal.
For each operator, we attach it to the most likely an-
cestor, given the attachment decisions for the previ-
ous operators. This heuristic is optimal for the case
where the depth of embedding is at most 1, which is
the common case.
6.2 Metrics
In this section, we describe metrics used to evaluate
the computation of ASTs. Let ? be the initial PPT,
? the correct AST, and ?? the computed AST. We
define accuracy at various levels.
The simplest metric is to define accuracy at the
level of ASTs, i.e., by computing the fraction of cases
for which ? = ??. However, this metric is harsh,
in the sense that it does not give algorithms partial
credit for getting a portion of the AST correct.
The next possible metric is to define accuracy at
the level of preterminals. Let p be a preterminal.
Note that ? , ? and ?? share the same set of preter-
minals, but may associate different operators with
them. We say that p is correct in ??, if it is asso-
ciated with the same set of operators as in ?, and
for all {o, o?} ? p, we have o  o? w.r.t. ?? iff
o  o? w.r.t. ?. In other words, the preterminals
are identical, both in terms of the set of operators
and the ordering between pairs of operators. While
preterminal-level accuracy gives partial credit, it is
still a little harsh, in the sense that an algorithm
which makes one ordering mistake at a preterminal
is penalized the same as an algorithm which makes
multiple mistakes.
Finally, we consider metrics to define accuracy at
the level of pairs of operators. Let p be a preter-
minal. The set Pairs(p, ?) consists of pairs of op-
erators (o, o?) such that o and o? are both associ-
ated with p in ?, and o = o? or o  o?. The set
Pairs(p, ??) is defined similarly using ?? instead of
?. Given the sets Pairs(p, ?) and Pairs(p, ??), pre-
cision, recall, and f-score are defined in the usual
way. We leave the details to the reader.
6.3 Results
We evaluate the following algorithms:
1. No Embedding ? The AST is computed purely
by reordering operators within a preterminal in
the PPT.
1209
(a) SURFACE ? No reordering is performed,
i.e., the order of operators in the AST re-
spects the surface order
(b) TYPE ? Using only type and subtype in-
formation for the operators
(c) ALL ? Using all the features described in
Section 5
2. ALL+ ? The initial PPT is transformed into a
second PPT before reordering (as described in
Section 3.3). All features are used.
Prec. Rec. F p ?
SURF. 86.9% 82.7% 84.6% 81% 4.2%
TYPE 90.4% 86% 88.1% 83.6% 24.7%
ALL 92% 87.6% 89.8% 85.1% 33.5%
ALL+ 91.9% 89.4% 90.6% 85.9% 36.2%
Table 6: Performance of the algorithms in computing the
ASTs. Averaged over 10-fold cross-validation. 195 ASTs
in total, an average of 8.6 preterminals per AST, and 1.8
operators per preterminal.
Table 6 summarizes the performance of the al-
gorithms, under the various metrics. The accura-
cies are averaged over 10-fold cross-validation. A
total of 195 ASTs are used. The average number
of preterminals per AST is 8.6, with an average of
1.8 operators per preterminal. The best number un-
der each metric is shown in bold-face. By adding
features, we improve the precision from 86.9% to
90.4% to 92% in moving from SURFACE to TYPE
to ALL. By handling embedded operators, we im-
prove the recall from 87.6% to 89.4% in moving
from ALL to ALL+. As we saw in Section 5, in 95%
of the cases, the embedded operators respects syn-
tactic scope, and as a result, we obtain only modest
gains from handling embedded operators.
The reader may feel that the F-score of 90.6% is
quite high given the size of our training data. This
score is inflated by inclusion of reflexive pairs, of
the form (o, o). Such pairs are included for the
following (technical) reasons. The algorithm that
handles embedded operators (ALL+) usually raises
them from a single operator node (as in Figure 3) to
a multi-operator node (as in Figure 5). If it makes
an incorrect decision to raise an operator it takes a
precision hit, at the multi-operator node (because
it has some false positives). By contrast, an algo-
rithm loses precision for failing to correctly raise,
only when we encounter the single operator node.
For these reasons, it is better to consider the rela-
tive improvement in F-score over the baseline. The
relative improvement of ALL+ over SURFACE in
terms of F-score is 36.6%. We believe that the
preterminal-level accuracy is more indicative in an
absolute sense. Furthermore, when we restrict atten-
tion to those preterminals with two or more opera-
tors in the PPT, the accuracy of ALL+ is 69.4%.
7 Related Work
ASTs can be seen as a middle ground between two
lines of research in translating sentences to logic.
At one end of the spectrum, we have methods
that achieve good accuracy on restricted texts. The
two main corpora that have been considered are the
GEOQUERY corpus (Thompson et al, 1997) and
the ATIS-3 corpus (Dahl et al, 1994). The GEO-
QUERY corpus consists of queries to a geographical
database. The queries were collected from students
participating in a study and the average sentence
length is 8 words. The ATIS corpus is collected
from subjects? interaction with a database of flight
information, using spoken natural language. The ut-
terances have be transcribed, and the average sen-
tence length is 10 words (Berant et al, 2007). Algo-
rithms, which achieve good accuracy, have been de-
veloped to compute the logical translation for these
queries (Zettlemoyer and Collins, 2005; Wong and
Mooney, 2007; Zettlemoyer and Collins, 2009). The
annotated sentences in the FDA CFR Section 610.40
are longer (about 30 words on average), and contain
modalities which are not present in these corpora.
At the other end of the spectrum, Bos et al (Bos et
al., 2004) have developed a broad-coverage parser to
translate sentences to a logic based on discourse rep-
resentation theory. Here, there is no direct method to
evaluate the correctness of the translation. However,
indirect evaluations are possible, for example, by
studying improvement in textual entailment tasks.
To summarize, there are techniques that either
produce an accurate translation for sentences in a
limited domain, or produce some translation for sen-
tences in a broader range of texts. ASTs offer a mid-
dle ground in two ways. First, we focus on regula-
1210
tory texts which are less restricted than the database
queries in the GEOQUERY and ATIS corpora, but do
not exhibit anaphoric phenomenon found in genres,
such as, newspaper text. In (Dinesh et al, 2007), we
discuss lexical statistics that show significant differ-
ences in the distribution of anaphoric items in the
CFR and Wall Street Journal (WSJ) corpora. For ex-
ample, the frequency of pronouns and anaphoric dis-
course connectives is significantly lower in the CFR
than in the WSJ. Instead, the CFR has an idiosyn-
cratic mechanism for referring to sentences, using
phrases such as ?except as specified in paragraph
(c) and (d)?. A question of interest is whether the
GEOQUERY and ATIS corpora show similar pecu-
liarities in terms of anaphora. The second difference
between our approach and others is that we do not
attempt to translate all the way to logic. The level of
logical form lets us obtain a direct evaluation, while
leaving open the design of parts of the logic.
8 Conclusions
We described experiments on a modest-sized cor-
pus of regulatory sentences, annotated with a novel
variant of logical form, called abstract syntax trees
(ASTs). An example from the corpus was presented
in Section 2 and some statistics, describing the cor-
pus, were discussed in Section 4. In Sections 3, 5,
and 6, we developed and tested algorithms to con-
vert a processed parse tree (PPT) to an AST. The
main step in this conversion was to rank or order the
operators at a preterminal. We presented a proba-
bilistic model for ranking, investigated the design of
features, and developed search heuristics. The best
algorithm, which uses all features and handles em-
bedded operators, achieves an F-score of 90.6%.
An important direction for further inquiry is in the
design of better features. Various types of features
have been proposed for the scopal ordering of deter-
miners. Examples include syntactic features (Ioup,
1975; Reinhart, 1983), such as position and voice,
semantic features (Grimshaw, 1990; Jackendoff,
1972), such as thematic roles. More recently, Srini-
vasan and Yates (2009) showed how pragmatic in-
formation, for example ?there are more people than
cities?, can be leveraged for scope disambiguation.
We experimented with lexico-syntactic features in
this work, and leave an investigation of semantic and
pragmatic features to future work.
Acknowledgements
We thank Claire Cardie, Steve Kimbrough, Annie
Louis, Fernando Pereira, Emily Pitler, Oleg Sokol-
sky, and the anonymous reviewers for helpful com-
ments on earlier versions of this paper.
References
A. Aho, R. Sethi, and J. Ullman. 1986. Compilers: Prin-
ciples, Techniques, and Tools. Addison-Wessley.
R. J. Anderson. 1996. A security policy model for clin-
cial information systems. In Proceedings of the IEEE
Symposium on Security and Privacy.
A. Barth, A. Dutta, J. C. Mitchell, and H. Nissenbaum.
2006. Privacy and contextual integrity: Framework
and applications. In Proceedings IEEE Symposium on
Security and Privacy.
J. Berant, Y. Gross, M. Mussel, B. Sandbank, E. Ruppin,
and S. Edelman. 2007. Boosting unsupervised gram-
mar induction by splitting complex sentences on func-
tion words. In Proceedings of the Boston University
Conference on Language Development.
J. Bos, S. Clark, M. Steedman, J. R. Curran, and J. Hock-
enmaier. 2004. Wide-coverage semantic representa-
tions from a CCG parser. In Proceedings of COLING.
W. W. Cohen, R. E. Schapire, and Y. Singer. 1998.
Learning to order things. Journal of Artificial Intel-
ligence Research, 10:243?270.
D. Dahl, M. Bates, M. Brown, W. Fisher, K. Hunicke-
Smith, D. Pallett, C. Pao, A. Rudnicky, and
E. Shriberg. 1994. Expanding the scope of the ATIS
task: the ATIS-3 corpus. In Proceedings of the ARPA
HLT Workshop.
N. Dinesh, A. Joshi, I. Lee, and O. Sokolsky. 2007.
Logic-based regulatory conformance checking. In
Proceedings of the 14th Monterey Workshop.
N. Dinesh, A. Joshi, I. Lee, and O. Sokolsky. 2011. Per-
mission to speak: A logic for access control and con-
formance. Journal of Logic and Algebraic Program-
ming, 80(1):50?74.
N. Dinesh. 2010. Regulatory Conformance Checking:
Logic and Logical Form. Ph.D. thesis, University of
Pennsylvania.
G. Governatori, Z. Milosevic, and S. Sadiq. 2006. Com-
pliance checking between business processes and busi-
ness contracts. In 10th International Enterprise Dis-
tributed Object Computing Conference (EDOC).
J. Grimshaw. 1990. Argument Structure. MIT Press.
1211
B. Grosof, Y. Labrou, and H. Y. Chan. 1999. A declar-
ative approache to business rules in contracts: Cour-
teous logic programs in xml. In ACM Conference on
Electronic Commerce.
Irene Heim and Angelika Kratzer. 1998. Semantics in
Generative Grammar. Blackwell.
G. Ioup. 1975. Some universals for quantifier scope.
Syntax and Semantics, 4:37?58.
R. Jackendoff. 1972. Semantic Interpretation in Genera-
tive Grammar. MIT Press.
A. J. I. Jones and M. J. Sergot. 1992. Formal spec-
ification of security requirements using the theory
of normative positions. In European Symposium on
Reasearch in Computer Security (ESORICS).
R. M. Karp. 1972. Reducibility among combinatorial
problems. In R. E. Miller and J. W. Thatcher, editors,
Complexity of Computer Computations, pages 85?103.
Plenum Press.
H. S. Kurtzman and M. C. MacDonald. 1993. Resolution
of quantifier scope ambiguities. Cognition, 48:243?
279.
R. K. Larson. 1985. Quantifying to np. Manuscript,
MIT.
T. Liu. 2009. Learning to rank for information retrieval.
Foundations and Trends in Information Retrieval, 3(3).
D. Makinson and L. van der Torre. 2000. Input/output
logics. Journal of Philosophical Logic, 29:383?408.
R. May. 1985. Logical Form: Its structure and deriva-
tion. MIT Press.
A. McCallum. 2002. MALLET: A machine learning for
language toolkit. http://mallet.cs.umass.edu.
T. Reinhart. 1983. Anaphora and Semantic Interpreta-
tion. Croom Helm.
M.J. Sergot, F.Sadri, R.A. Kowalski, F.Kriwaczek,
P.Hammond, and H.T. Cory. 1986. The british na-
tionality act as a logic program. Communications of
the ACM, 29(5):370?86.
P. Srinivasan and A. Yates. 2009. Quantifier scope
disambiguation using extracted pragmatic knowledge:
Preliminary results. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP).
C. A. Thompson, R. J. Mooney, and L. R. Tang. 1997.
Learning to parse natural language database queries
into logical form. In Proceedings of the Workshop on
Automata Induction, Grammatical Inference and Lan-
guage Acquisition.
Y. W. Wong and R. J. Mooney. 2007. Learning syn-
chronous grammars for semantic parsing with lambda
calculus. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics (ACL).
L. S. Zettlemoyer and M. Collins. 2005. Learning to
map sentences to logical form: Structured classifica-
tion with probabilistic categorial grammars. In Pro-
ceedings of UAI.
L. S. Zettlemoyer and M. Collins. 2009. Learning
context-dependent mappings from sentences to logi-
cal form. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics (ACL).
1212
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 125?127,
Utica, May 2012. c?2012 Association for Computational Linguistics
Natural Language Generation for a Smart Biology Textbook
Eva Banik1, Eric Kow1, Vinay Chaudhri2, Nikhil Dinesh2, and Umangi Oza3
1{ebanik,kowey}@comp-ling.co.uk, Computational Linguistics Ltd, London, UK
2 {chaudhri,dinesh}@ai.sri.com, SRI International, Menlo Park, CA
3umangi.oza@evalueserve.com, Evaluserve, New Delhi, India
1 Application Context
In this demo paper we describe the natural lan-
guage generation component of an electronic
textbook application, called Inquire1. Inquire
interacts with a knowledge base which encodes
information from a biology textbook. The
application includes a question-understanding
module which allows students to ask questions
about the contents of the book, and a question-
answering module which retrieves the corre-
sponding answer from the knowledge base. The
task of the natural language generation mod-
ule is to present specific parts of the answer in
English. Our current generation pipeline han-
dles inputs that describe the biological func-
tions of entities, the steps of biological processes,
and the spatial relations between parts of enti-
ties. Our ultimate goal is to generate paragraph-
length texts from arbitrary paths in the knowl-
edge base. We describe here the natural lan-
guage generation pipeline and demonstrate the
inputs and generated texts. In the demo pre-
sentation we will show the textbook application
and the knowledge base authoring environment,
and provide an opportunity to interact with the
system.
2 The Knowledge Base
The knowledge base contains information from
a college-level biology textbook2, encoded by bi-
1The work described in this paper and presented in
the demo is funded by Vulcan Inc.
2 Reece et al 2010. Campbell biology. Pearson
Publishing.
ologists as part of project HALO at SRI3. The
core of the knowledge base is the CLIB ontol-
ogy4, which is extended with biology-specific in-
formation. The knowledge base encodes entity-
to-event relations (similar to thematic roles in
linguistics), event-to-event relations (discourse
relations), various property values and relations
between properties, spatial relations, cardinality
constraints, and roles that participants play in
events. The input to the generation pipeline is a
set of triples extracted from the biology knowl-
edge base. Currently our content selection in-
cludes either an event and the entities that par-
ticipate in the event, or a set of entities and
spatial relations between them.
3 Generation Grammar and Lexicon
Our generation grammar consists of a set of Tree
Adjoining Grammar (TAG) elementary trees.
Each tree is associated with either a single rela-
tion, or a set of relations in the knowledge base.
As an example, Fig 1 illustrates the mapping
between elementary trees and event participant
relations in the KB for the above input. We
currently associate up to three different elemen-
tary trees with each event and the connected
set of participant relations: an active senten-
tial tree, a passive sentential tree and a complex
noun phrase.
The knowledge base provides concept-to-word
3 Gunning Et al, 2010. Project halo update
progress toward digital aristotle. AI Magazine Fall:33-
58. See also http://www.projecthalo.com/
4http://www.cs.utexas.edu/users/mfkb/RKF/clib.html
125
Figure 1: The grammar of the surface realizer
mappings (a list of synonyms) for every concept,
and the words are used in the generation lexi-
con to anchor elementary TAG trees. Our gen-
eration grammar consists of a set of TAG tree
templates, which are defined as combinations of
tree fragments and are compiled using the XMG
metgrammar toolkit5.
These underspecified elementary trees are fur-
ther specified in the generation lexicon, which
maps concepts onto elementary tree templates,
and associates a word (an anchor) with the
tree, along with other idiosynchratic information
(e.g., preposition choice). We create a genera-
tion lexicon dynamically at run-time, by map-
ping tree templates onto concepts based on the
number and types of participants, and the lexi-
cal information associated with the event (e.g.,
the preposition requirements of the verb).
Concept names for entities are included in
the elementary trees as features on the corre-
sponding NP nodes. These features form part
of the input to the referring expression genera-
tion module, which looks up the concept name
5https://sourcesup.renater.fr/xmg/
in the concept-to-word mapping to obtain a list
of possible noun phrases.
4 Realization
Our natural language generation pipeline is cen-
tered around the GenI surface realizer6,7. The
set of triples yielded by content selection are first
aggregated and converted to GenI?s input for-
mat, a set of flat semantic literals. We then feed
this input to GenI to produce an underspecified
surface form in which referring expressions are
still underspecified:
NP is detach from NP resulting in NP at NP
NP detach from NP resulting in NP at NP
Detachment of NP from NP resulting in NP at NP
A post-processing module carries out refer-
ring expression generation and morphological re-
alization to produce the fully specified output.
6 Kow, Eric. 2007. Surface realisation: ambiguity
and determinism. Doctoral Dissertation, Universite de
Henri Poincare - Nancy 1.
7 Banik, Eva 2010. A minimalist approach to gen-
erating coherent texts. Phd thesis, Department of Com-
puting, The Open University
126
Question Answering & Reasoning Algorithms
Event Instance 
Content Selection
Set of triples
Input aggregation and conversion +Stylistic control
Knowledge Base
Realization with GenI
Morphology &referring expression generation
Semantic literals +input parameters
Ranking
Underspecified realizations
Linguistic Resources
Generation Lexicon
Grammar: Description of TAG tree templates
Concept-to-Wordmappings
Mapping of KB relationsto TAG tree templates
Morphological lexicon
Verb frames (preposition choice)
NLG Pipeline
Figure 2: Linguistic resources and the generation pipeline
Our referring expression realization algorithm
performs further semantic aggregation where
necessary to produce cardinals (?two chromo-
somes?), and decides on a suitable determiner
based on previous mentions of instance names
and subclasses in the discourse context (def-
inite/indefinite determiner, ?another? or ?the
same?). For the input shown in Fig 1, our sys-
tem will produce the following three realizations:
1. A sister chromatid detaches from another sister chro-
matid resulting in two chromosomes at a kinetochore.
2. A sister chromatid is detached from another sister
chromatid resulting in two chromosomes at a kinetochore.
3. Detachment of a sister chromatid from another sister
chromatid resulting in two chromosomes at a kinetochore
We rank the generated outputs based on their
linguistic properties using optimality theoretic
constraints (e.g., active sentences are ranked
above passive sentences), where each constraint
corresponds to a (set of) tree fragments that
contributed to building the tree that appears in
the output. Our system also allows for extra in-
put parameters to be sent to GenI to restrict the
set of generated outputs to fit a specific context
(e.g., syntactic type or focused discourse entity).
Our full natural language generation pipeline is
illustrated in Fig 2.
5 Future Work
We are currently working on extending the sys-
tem to handle more relations and other data
types in the knowledge base. This involves ex-
tending the grammar to new sentence types and
other linguistic constructions, and extending the
content selection module to return more triples
from the knowledge base. Our ultimate goal is
to be able to generate arbitrary ? but in some
sense well-formed ? paths from the knowledge
base as coherent paragraphs of text.
127
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 141?145,
Utica, May 2012. c?2012 Association for Computational Linguistics
KBGen ? Text Generation from Knowledge Bases as a New Shared Task
Eva Banik1, Claire Gardent2, Donia Scott3, Nikhil Dinesh4, and Fennie Liang5
1ebanik@comp-ling.co.uk, Computational Linguistics Ltd, London, UK
2claire.gardent@loria.fr, CNRS, LORIA, Nancy, France
3D.R.Scott@sussex.ac.uk, School of Informatics, University of Sussex, Brighton, UK
4dinesh@ai.sri.com, SRI International, Menlo Park, CA
5fennie.liang@cs.man.ac.uk, School of Computer Science, University of Manchester, UK
1 Introduction
In this paper we propose a new shared task, KB-
Gen, where the aim is to produce coherent descrip-
tions of concepts and relationships in a frame-based
knowledge base (KB). We propose to use the AURA
knowledge base for the shared task which contains
information about biological entities and processes.
We describe how the AURA KB provides an appli-
cation context for NLG and illustrate how this ap-
plication context generalizes to other biology KBs.
We argue that the easy availability of input data and
a research community ? both domain experts and
knowledge representation experts ? which actively
uses these knowledge bases, along with regular eval-
uation experiments, creates an ideal scenario for a
shared task.
2 Application Context and Motivation
One of the research challenges in the knowledge rep-
resentation community is to model complex knowl-
edge in order to be able to answer complex ques-
tions from a knowledge base (see e.g. the Deep
Knowledge Representation Challenge Workshop at
KCAP 20111). There are several applications of
such knowledge bases, perhaps most recently and
most prominently in the bioinformatics and educa-
tional informatics domain, where there are available
knowledge bases and reasoners that help scientists
answer questions, explain connections between con-
cepts, visualize complex processes, and help stu-
dents learn about biology. These uses of a knowl-
edge base are however difficult to implement with-
1http://sites.google.com/site/dkrckcap2011/home
out presenting the resulting answers and explana-
tions to the user in a clear, concise and coherent way,
which often requires using natural language.
2.1 The AURA Knowledge Base
The AURA biology knowledge base developed by
SRI International (Gunning et al, 2010) encodes in-
formation from a biology textbook (Reece et al,
2010)2. The purpose of this knowledge base is
to help students understand biological concepts by
allowing them to ask questions about the material
while reading the textbook. The KB is built on top
of a generic library of concepts (CLIB, Barker et al,
2001), which are specialized and/or combined to en-
code biology-specific information, and it is orga-
nized into a set of concept maps, where each con-
cept map corresponds to a biological entity or pro-
cess. The KB is being encoded by biologists and
currently encodes over 5,000 concept maps.
The AURA KB and its question answering sys-
tem is integrated with an electronic textbook appli-
cation3. The applicaton allows the students to ask
complex questions about relationships between con-
cepts, which are answered by finding a possible path
between the two concepts. The results are presented
to the students as graphs, for example the answer
produced by the system in response to the question
?what is the relationship between glycolysis and glu-
cose?? is illustrated in Fig 1.
These graphs are simplified representations of
2The development of the AURA knowledge base and related
tools and applications was funded by Vulcan Inc.
3A demo of the application will be presented in the demo
session at INLG 2012
141
Figure 1: Relationship between glycolysis and glucose
a path in the knowledge base that connects two
concepts, because presenting the full concept map
where the path was found would make it difficult for
the students to clearly see the relationship. However,
this simplification often obscures the connection by
not showing relevant information.
Given the inclusion of a few more relations from
the concept map of glycolysis (Fig 2), the answer to
the question could be generated as a complex sen-
tence or a paragraph of text, for example: ?Phos-
phorylation of glucose is the first step of the energy
investment phase of glycolysis? or ?In the first step
of the energy investment phase of glycolysis, called
phosphorylation, hexokinase catalyses the synthesis
of glucose-6-phosphate from glucose and a phos-
phate ion.?
2.2 BioCyc
Another situation in which graph-based representa-
tions are presented to the user is metabolic pathway
and genome databases, such as the BioCyc knowl-
edge base. BioCyc describes the genome, metabolic
pathways, and other important aspects of organisms
such as molecular components and their interactions
and currently contains information from 1,763 path-
Figure 2: Concept map of glycolysis
way/genome databases4.
When users query parts of the BioCyc knowledge
base, the system automatically produces a graph
to visualize complex biological processes. For ex-
ample, Fig 3 illustrates an automatically generated
graph from the knowledge base which shows the
process of glycolysis in an E. coli cell. Hovering the
mouse over the ? and 	 signs on the graph brings
up popups with additional information about gene
expressions , detailed chemical reactions in the pro-
cess, enzymes activated by certain chemicals, etc..
Figure 3: The process of glycolysis in E.coli
3 Input Data for Generation
Although there is a clear benefit from visualizing
complex processes in a graph form, one also has to
4http://www.biocyc.org
142
be well-versed in the notation and details of biolog-
ical processes in order to make sense of these rep-
resentations. Students of biology and non-experts
would certainly benefit from a more detailed ex-
planation of the process, presented as a few para-
phraphs of text along with graphs to emphasize the
most salient features of processes.
The paths and relations returned by reasoning al-
gorithms also present a good opportunity to pro-
vide inputs for natural language generation. These
chunks of data typically contain the right amount of
data because they consist of the information needed
to answer a question or describe a concept. Ad-
ditionally, many knowledge bases (including both
BioCyc and AURA) are encoded in a frame-based
representation, which has the advantage that frames
naturally correspond to linguistic units.
Frame-based systems (Minsky, 1981) are based
around the notion of frames or classes which repre-
sent collections of concepts. Each frame has an as-
sociated set of slots or attributes which can be filled
either by specific values or by other frames. Intu-
itively, frames correspond to situations, and each ter-
minal in the frame corresponds to answers to ques-
tions that could be asked about the situation, in-
cluding the participants in the situation, causes and
consequences, preceding and following situations,
purpose, etc. Frame-based representations may ei-
ther contain frames of generic concepts or instance
frames which represent information about particular
instances. Frames also have a kind-of slot, which
allows the assertion of a frame taxonomy, and the
inheritance of slots.
In the knowledge representation community,
frame-based representations are popular because
they make the encoding process more intuitive.
From a natural language generation perspective,
each frame (or a set of slots) corresponds to a lin-
guistic unit (sentence, noun phrase, clause, verb
phrase, etc), depending on the type of the frame and
the slots it contains. This organization of concepts
and relations in the knowledge base makes it easier
to select chunks of data from which coherent texts
can be generated.
Slots in these frame-based representations also
naturally correspond to the kind of flat semantic
representations and dependency structures that have
served as input to surface realization (Koller and
Striegnitz, 2002; Carroll and Oepen, 2005; White,
2006; Gardent and Kow, 2007; Nakatsu and White,
2010).
4 The shared task
We propose two tracks for the KBGen shared task: a
?complex surface realization? track, where the task
is to generate complex sentences from shorter in-
puts, and a ?discourse generation? track, where the
task is to generate longer texts made up from several
paragraphs. In the following, we describe the data
set from which the input to generation will be se-
lected; the methology we plan to use to extract text
size input for the generation challenge; and the two
tracks making up the KBGen challenge.
4.1 The AURA knowledge base as Input
Dataset
We propose to use the AURA knowledge base as
input data for the shared task for several reasons.
AURA contains a number of relations and therefore
provides varied input for generation5. The AURA
knowledge base contains linguistic resources that
can be used for generation (a morphological lexi-
con and a list of synonyms for each concept) and
the electronic textbook provides an application con-
text to evaluate the generated texts. There are regular
evaluation efforts to assess the educational benefits
of using the textbook application, and the next round
of these experiments will involve over 400 students
and biology teachers who will use the application
over an extended period of time. The evaluation of
the outputs generated for the shared task could form
part of these experiments.
4.2 Selecting Text Size Content for the Shared
Task
We propose to select data from the knowledge base
manually or semi-automatically, by selecting a set
of concepts to be described and including relevant
relations associated with the concepts. We would
first select a set of concept maps that are encoded in
most detail and have been reviewed by the encoders
for quality assurance. The input data for each con-
cept will then be a manually selected set of frames
5If there is interest, the systems developed to generate from
AURA could also be applied to the BioCyc data, which has a
more restricted set of relations.
143
from the concept map. The selected relations will be
reviewed one more time for quality and consistency
to filter out any errors in the data.
If there is interest in the community, we can
also envision a content selection challenge which
could provide input to the generation task. Although
frames in the knowledge base correspond well to
chunks of data for generation of descriptions, con-
tent selection for other communicative goals is far
from a trivial problem. One such challenge could
be for example comparing two concepts, or explain-
ing the relation between a process and its sub-type
(another process that is taxonomically related, but
different in certain parts).
4.3 Complex Surface Realization Track
For the complex surface realization track, a small
number of frames would be selected from the knowl-
edge base along with a small number of other rel-
evant relations (e.g., important parts or properties
of certain event participants, or certain relations be-
tween them, depending on the context). The output
texts to be generated would be complex sentences
describing the central entity/event in the data, or the
relationship between two concepts, such as the gly-
colysis example in section 2.1. This task would
involve aggregation and generating intrasentential
pronouns governed by syntax where necessary, but
it would not require the generation of any discourse
anaphora or referring expressions.
This track will differ from the deep generation
track of the Surface Realization Shared Task both in
form and in content. The form of the KBGen input
is a concept map extracted from an ontology rather
than a deep semantics extracted by conversion from
dependency parse trees. Similarly, its content is that
of a biology knowledge base rather than that of the
Penn Treebank textual corpus.
4.4 Discourse Generation Track
Inputs for the discourse generation task would in-
clude most frames from the concept map of an entity
or process. The output would be longer paragraphs
or 2-3 paragraphs of text, typically a description of
the subevents, results, etc, of a biological process,
or the description of the structure and function of an
entity. This task would involve text structuring and
the generation of pronouns.
4.5 Lexical Resources and potential
multilingual tracks
The knowledge base provides a mapping from con-
cepts to lexical items and a list of synonyms. It
also provides information about how specific slots
in event frames are mapped onto prepositions.
If there is interest in the community, the lex-
ical resources corresponding to the selected con-
tent could be translated to different languages semi-
automatically: the translation could be attempted
first automatically, with the help of available biol-
ogy/medical lexicons, and then the output would be
hand-corrected. Candidate languages for a multilin-
gual challenge would be French and Spanish. To
run the multilingual tracks we would need to create
multilingual development and test data and would
need to have access to French/Spanish speaking bi-
ologists.
5 Evaluation
Evaluation of the generated texts could be done both
with automatic evaluation metrics and using human
judgements. Automatic evaluation metrics could in-
clude BLUE (Papineni et al, 2002) or measuring
Levenshtein distance (Levenshtein, 1966) from hu-
man written texts. To obtain human judgements, bi-
ologists will be asked to compose texts conveying
the same content as the input for the generated texts.
The human-written texts will be presented to sub-
jects along with the generated outputs to obtain flu-
ency judgements, but the subjects will not be told
which kind of text they are judging. The evaluation
campaign could be coordinated with the evaluation
of the knowledge base and the electronic textbook
application, and/or publicized on social networking
sites or mechanical turk.
6 Next Steps
We invite feedback on this proposal with the aim
of refining our plan and discussing a suitable input
representation for the shared task in the next few
months. If there is sufficient interest in the shared
task, we would make the input data available in the
agreed format in late 2012, with the first evaluation
taking place in 2013. We would like to hear any
comments/suggestions/critisisms about the plan and
we are actively looking for people who would be in-
144
terested in getting involved in planning and running
the challenge.
References
Barker, K., B. Porter, and P. Clark. 2001. A library of
generic concepts for composing knowledgebases.
In Proceedings of the 1st Int Conf on Knowledge
Capture (K-Cap?01), 14?21.
Carroll, J., and S. Oepen. 2005. High efficiency real-
ization for a wide-coverage unification grammar.
2nd IJCNLP .
Gardent, C., and E. Kow. 2007. A symbolic ap-
proach to near-deterministic surface realisation
using tree adjoining grammar. In In 45th Annual
Meeting of the ACL.
Gunning, D., V. K. Chaudhri, P. Clark, K. Barker,
Shaw-Yi Chaw, M. Greaves, B. Grosof, A. Leung,
D. McDonald, S. Mishra, J. Pacheco, B. Porter,
A. Spaulding, D. Tecuci, and J. Tien. 2010.
Project halo update - progress toward digital aris-
totle. AI Magazine Fall:33?58.
Koller, Alexander, and Kristina Striegnitz. 2002.
Generation as dependency parsing. In Proceed-
ings of ACL.
Levenshtein, Vladimir I. 1966. Binary codes capable
of correcting deletions, insertions, and reversals.
Soviet Physics Doklady 10:707?710.
Minsky, Marvin. 1981. Mind design, chapter A
Framework for Representing Knowledge, 95?
128. MIT Press.
Nakatsu, Crystal, and Michael White. 2010. Gen-
erating with discourse combinatory categorial
grammar. submitted to Linguistic Issues in Lan-
guage Technology .
Papineni, Kishore, Salim Roukos, Todd Ward, and
Wei jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. 311?318.
Reece, Jane B., Lisa A. Urry, Michael L. Cain,
Steven A. Wasserman, Peter V. Minorsky, and
Robert B. Jackson. 2010. Campbell biology. Pear-
son Publishing.
White, Michael. 2006. Ccg chart realization from
disjunctive inputs. In Proceedings of the Fourth
International Natural Language Generation Con-
ference, 12?19. Sydney, Australia: Association
for Computational Linguistics.
145
