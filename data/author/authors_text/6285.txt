Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 73?78,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Extraction of Tree Adjoining Grammars from a Treebank for Korean  
 
 
 Jungyeul Park 
UFR Linguistique  
Laboratoire de linguistique formelle 
Universit? Paris VII - Denis Diderot 
jungyeul.park@linguist.jussieu.fr 
 
 
  
 
Abstract 
We present the implementation of a system 
which extracts not only lexicalized gram-
mars but also feature-based lexicalized 
grammars from Korean Sejong Treebank. 
We report on some practical experiments 
where we extract TAG grammars and tree 
schemata. Above all, full-scale syntactic 
tags and well-formed morphological analy-
sis in Sejong Treebank allow us to extract 
syntactic features. In addition, we modify 
Treebank for extracting lexicalized gram-
mars and convert lexicalized grammars into 
tree schemata to resolve limited lexical 
coverage problem of extracted lexicalized 
grammars. 
1 Introduction  
An electronic grammar is an interface between the 
complexity and the diversity of natural language 
and the regularity and the effectiveness of a lan-
guage processing, and it is one of the most impor-
tant elements in the natural language processing. 
Since traditional manual grammar development is 
a time-consuming and labor-intensive task, many 
efforts for automatic and semi-automatic grammar 
development have been taken during last decades.  
Automatic grammar development means that a 
system extracts a grammar from a Treebank which 
has an implicit Treebank grammar. The grammar 
extraction system takes syntactically analyzed sen-
tences as an input and produces a target grammar. 
The extracted grammar would be same as the 
Treebank grammar or be different depending on 
the user?s specific purpose. The automatically ex-
tracted grammar has the advantage of the coher-
ence of extracted grammars and the rapidity of its 
development. However, as it always depends on 
the Treebank which the extraction system uses, its 
coverage could be limited to the scale of a Tree-
bank. Moreover, the reliable Treebank would be 
hardly found, especially in public domain.  
Semi-automatic grammar development means 
that a system generates the grammar using the de-
scription of the language-specific syntactic (or lin-
guistic) variations and its constraints. A meta-
grammar in Candito (1999) and a tree description 
in Xia (2001) are good examples of a semi-
automatic grammar development. Even using 
semi-automatic grammar development, we need 
the good description of linguistic phenomena for 
specific language which requires very high level 
knowledge of linguistics and the semi-
automatically generated grammars would easily 
have an overflow problem. 
Since we might extract the grammar automati-
cally without many efforts if a reliable Treebank is 
provided, in this paper we implement a system 
which extracts a Lexicalized Tree Adjoining 
Grammar and a Feature-based Lexicalized Tree 
Adjoining Grammar from Korean Sejong Treebank 
(SJTree). SJTree contains 32,054 eojeols (the unity 
of segmentation in the Korean sentence), that is, 
2,526 sentences. SJTree uses 43 part-of-speech 
tags and 55 syntactic tags.  
Even though there are many previous works for 
extracting grammars from a Treebank, extracting 
syntactic features is tried for the first time. 55 full-
scale syntactic tags and well-formed morphologi-
cal analysis in SJTree allow us to extract syntactic 
features automatically and to develop FB-LTAG. 
73
First, we briefly present features structures 
which are focused on FB-LTAG and other previ-
ous works for extracting a grammar from a Tree-
bank. Then, we explain our grammar extraction 
scheme and report experimental results. Finally, 
we discuss the conclusion. 
2 Feature structures and previous works 
on extracting grammars from a Tree-
bank  
A feature structure is a way of representing gram-
matical information. Formally feature structure 
consists of a specification of a set of features, each 
of which is paired with a particular value (Sag et 
al., 2003). In a unification frame, a feature struc-
ture is associated with each node in an elementary 
tree (Vijay-Shanker and Joshi, 1991). This feature 
structure contains information about how the node 
interacts with other nodes in the tree. It consists of 
a top part, which generally contains information 
relating to the super-node, and a bottom part, 
which generally contains information relating to 
the sub-node (Han et al, 2000).  
In FB-LTAG, the feature structure of a new 
node created by substitution inherits the union of 
the features of the original nodes. The top feature 
of new node is the union of the top features (f1 ? f) 
of the two original nodes, while the bottom feature 
of the new node is simply the bottom feature (g1) 
of the top node of the substituting tree since the 
substitution node has no bottom feature as shown 
in Figure 1.  
 
Y X
Y?
X
Y
t:f1
b:g1
t:f
t:f1 ? f
b:g1
?
 
Figure 1. Substitution in FB-LTAG 
 
The node being adjoined into splits and its top fea-
ture (f) unifies with the top feature (f1) of the root 
adjoining node, while its bottom feature (g) unifies 
with the bottom feature (g2) of the foot adjoining 
node as shown in Figure 2.  
 
X Y
Y*
?
t:f1
b:g1
t:f2
b:g2
Y
t:f
b:g
X
Y
Y
t:f1 ? f
b:g1
t:f2
b:g2 ? g  
Figure 2. Adjunction in FB-LTAG 
Several works for extracting grammars, especially 
for TAG formalism are proposed. Chen (2001) 
extracted lexicalized grammars from English Penn 
Treebank and there are other works based on 
Chen?s procedure such as Johansen (2004) and 
Nasr (2004) for French and Habash and Rambow 
(2004) for Arabic. Chiang (2000) used Tree Inser-
tion Grammars, one variation of TAG formalism 
for his extraction system from English Penn Tree-
bank. Xia et al (2000) developed the uniform 
method of a grammar extraction for English, Chi-
nese and Korean. Neumann (2003) extracted Lexi-
calized Tree Grammars from English Penn 
Treebank for English and from NEGRA Treebank 
for German. As mentioned above, none of these 
works tried to extract syntactic features for FB-
LTAG. 
3 Grammar extraction scheme  
Before extracting a grammar automatically, we 
transform the bracket structure sentence in SJTree 
into a tree data structure. Afterward, using depth-
first algorithm for a tree traverse, we determine a 
head and the type of operations (substitution or 
adjunction) for children nodes of the given node if 
the given node is a non-terminal node.  
3.1 Determination of a head  
For the determination of a head, we assume the 
right-most child node as a head among its sibling 
nodes in end-focus languages like Korean. For in-
stance, the second NP is marked as a head in [NP 
NP] composition while the first NP is marked for 
adjunction operation for the extracted grammar G1 
which uses eojeols directly without modification of 
SJTree (see the section 4 for the detail of extrac-
tion experiments). Likewise, in [VP@VV 
VP@VX] composition where the first VP has a 
VV (verb) anchor and the last VP has a VX (auxil-
iary verb) anchor, a principal verb in the first VP 
could be marked for adjunction operation and an 
auxiliary verb in the second VP would be a head, 
that is, the extracted auxiliary verb tree has every 
argument of whole sentence. This phenomenon 
could be explained by argument composition. 
Head nodes of the extracted grammar for a verb 
balpyoha.eoss.da (?announced?) in (1) are in bold 
face in Figure 3 which represents bracketed sen-
tence structure in SJTree  
 
74
(1) ?? ???? ?? ?? ??? ????. 
 ilbon oimuseong.eun  
 Japan ministy_of_foreign_affairs.Nom 
 jeukgak  haemyeng  
 immediately elucidation 
 seongmyeng.eul balpyo.ha.eoss.da 
 declaration.Acc announce.Pass.Ter 
 ?The ministry of foreign affairs in Japan im-
mediately announced their elucidation.? 
  
(S (NP_SBJ (NP ilbon/NNP) 
  (NP_SBJ oimuseong/NNG+eun/JX)) 
 (VP (AP jeukgak/MAG) 
  (VP (NP_OBJ (NP haemyeng/NNG) 
                        (NP_OBJ seonmyeng/NNG+eul/JKO)) 
   (VP balpyo/NNG+ha/XSV+eoss/EP+da/EF+./SF)))) 
Figure 3. Bracketed sentence in SJTree for (1) 
3.2 Distinction between substitution and ad-
junction operations  
Unlike other Treebank corpora such as English 
Penn Treebank and French Paris 7 Treebank, full-
scale syntactic tags in SJTree allow us to easily 
determine which node would be marked for substi-
tution or adjunction operations. Among 55 syntac-
tic tag in SJTree, nodes labeled with NP (noun 
phrase), S (sentence), VNP (copular phrase) and 
VP (verb phrase) which end with _CMP (attribute), 
_OBJ (object), and _SJB (subject) would be 
marked for substitution operation, and nodes la-
beled with the other syntactic tags except a head 
node would be marked for adjunction operation. In 
this distinction, some VNP and VP phrases might 
be marked for substitution operation, which means 
that VNP and VP phrases are arguments of a head, 
because SJTree labels VNP and VP instead of NP 
for the nominalization forms of VNP and VP. In 
Figure 4, for example, NP_SBJ and NP_OBJ 
nodes are marked for substitution operation and 
AP node is marked for adjunction operation.  
Children nodes marked for substitution opera-
tion are replace by substitution terminal nodes (e.g. 
NP_SBJ?) and calls recursively the extraction pro-
cedure with its subtree where a root node is the 
child node itself. Children nodes marked for ad-
junction operation are removed from the main tree 
and also calls recursively the extraction procedure 
with its subtree where we add its parent node of a 
given child node as a root node and a sibling node 
as a foot node (e.g. VP*). As defined in the TAG 
formalism, the foot node has the same label as the 
root node of the subtree for an adjunction operation.  
 
 
3.3 Reducing trunk  
Extracted grammars as explained above are not 
always ?correct? TAG grammar. Since nodes 
marked for adjunction operation are removed, 
there remain intermediate nodes in the main tree. 
In this case, we remove these redundant nodes. 
Figure 4 shows how to remove the redundant in-
termediate nodes from the extracted tree for a verb 
balpyoha.eoss.da (?announced?) in (1).  
 
VP
NP_SBJ ? VP
S
NP_OBJ ? VP
balpyoha.eoss.da
VPNP_SBJ ?
S
NP_OBJ ? VP
balpyoha.eoss.da
?
 
Figure 4. Removing redundant intermediate nodes 
from extracted trees 
3.4 Extracting features  
55 full-scale syntactic tags and morphological 
analysis in SJTree allow us to extract syntactic fea-
tures automatically and to develop FB-LTAG. 
Automatically extracted FB-LTAG grammars 
eventually use reduced tagset because FB-LTAG 
grammars contain their syntactic information in 
features structures. For example, NP_SBJ syntactic 
tag in LTAG is changed into NP and a syntactic 
feature <case=subject> is added. Therefore, we use 
actually 13 reduced tagset for FB-LTAG gram-
mars. From full-scale syntactic tags which end 
with _SBJ (subject), _OBJ (object) and _CMP (at-
tribute), we extract <case> features which describe 
argument structures in the sentence.  
Alongside <case> features, we also extract 
<mode> and <tense> from morphological analyses 
in SJTree. Since however morphological analyses 
for verbal and adjectival endings in SJTree are 
simply divided into EP, EF and EC which mean 
non-final endings, final endings and conjunctive 
endings, respectively, <mode> and <tense> fea-
tures are not extracted directly from SJTree. In this 
paper, we analyze 7 non-final endings (EP) and 77 
final endings (EF) used in SJTree to extract auto-
matically <mode> and <tense> features. In gen-
eral, EF carries <mode> inflections, and EP carries 
<tense> inflections. Conjunctive endings (EC) are 
not concerned with <mode> and <tense> features 
and we only extract <ec> features with its string 
value. <ef> and <ep> features are also extracted 
75
with their string values. Some of non-final endings 
like si are extracted as <hor> features which have 
honorary meaning. In extracted FB-LTAG gram-
mars, we present their lexical heads in a bare in-
finitive with morphological features such as <ep>, 
<ef> and <ec> which make correspond with its 
inflected forms.  
<det> is another automatically extractable fea-
ture in SJTree and it is extracted from both syntac-
tic tag and morphological analysis unlike other 
extracted features. For example, while <det=-> is 
extracted from dependant nouns which always 
need modifiers (extracted by morphological analy-
ses), <det=+> is extracted from _MOD phrases 
(extracted by syntactic tags). From syntactic tag 
DP which contains MMs (determinative or demon-
strative), <det=+> is also extracted1.  
The actual procedure of feature extraction is im-
plemented by 2 phases. In the first phase, we con-
vert syntactic tags and morphological analysis into 
feature structure as explained above. In the second 
phase, we complete feature structure onto nodes of 
dorsal spine. For example, we put the same feature 
of VV bottom onto VV top, VP top/bottom and S 
bottom because nodes in dorsal spine share certain 
number of feature of VV bottom. The initial tree 
for a verb balpyoha.eoss.da is completed like Fig-
ure 5 for a FB-LTAG (see Park (2006) for details).  
                                                          
1 Korean does not need features <person> as in English and 
<gender > or <number> as in French. Han et al (2000) pro-
posed several features for Korean FBLTAG which we do not 
use in this paper, such as <adv-pp>, <top> and < aux-pp> for 
nouns and <clause-type> for predicates. While postpositions 
are separated from eojeol during our grammar extraction pro-
cedure, Han el al. considered them as ?one? inflectional mor-
phology of noun phrase eojeol. As we will explain the reason 
why we separate postpositions from eojeol in the section 4, the 
separation of postpositions would be much efficient for the 
lexical coverage of extracted grammars. In Han et al <adv-
pp> simply contains string value of adverbial postpositions. 
<aux-pp> adds semantic meaning of auxiliary postpositions 
such as only, also etc. which we can not extract automatically 
from SJTree or other Korean Treebank corpora because syn-
tactically annotated Treebank corpora generally do not contain 
such semantic information. <top> marks the presence or ab-
sence of a topic marker in Korean like neun, however topic 
markers are annotated like a subject in SJTree which means 
that only <case=subject> is extracted for topic markers. 
<clause-type> indicates the type of the clause which has its 
values such as main, coord(inative), subordi(native), ad-
nom(inal), nominal, aux-connect. Since the distinction of the 
type of the clause is very vague except main clause in Korea, 
we do not adopt this feature. Instead <ef> is extracted if a 
clause type is a main clause and <ec> is extracted for other 
type.  
S
NP? VP
VPNP?
VV
balpyoha
b: <ep> = eoss
b: <ef> = da
b: <mode> = decl
b: <tense> = past
t:  <ep> = x, <ef> = y, <mode> = i, <tense> = j
t:  <ep> = x, <ef> = y, <mode> = i, <tense> = j
b: <ep> = x, <ef> = y, <mode> = i, <tense> = j
t:  <ep> = x, <ef> = y, <mode> = i, <tense> = j
b: <ep> = x, <ef> = y, <mode> = i, <tense> = j
t:  -
b: <ep> = x, <ef> = y, <mode> = i, <tense> = j
<cas> = nom
<det> = +
<cas> = acc
<det> = +
 
Figure 5. Extracted FB-LTAG grammar for 
balpyoha.eoss.da (?announced?) 
4 Extraction experiments and results   
4.1 Extraction of lexicalized trees  
In this paper, we extract not only lexicalized trees 
without modification of a Treebank, but also ex-
tract grammars with modifications of a Treebank 
using some constraints to improve the lexical cov-
erage in extracted grammars. 
 
? G1: Using eojeols directly without modifi-
cation of SJTree. 
? G2: Separating symbols and postpositions 
from eojeols. Separated symbols are ex-
tracted and divided into ? and ? trees 
based on their types. Every separated post-
position is ? tree. Complex postpositions 
consisted of two or more postpositions are 
extracted like one ? tree2. Finally, convert-
ing NP ? trees into ? trees and removing 
syntactic tag in NP ? trees. 
 
Figure 6 and 7 show extracted lexicalized gram-
mars G1 and G2 from (1) respectively. Theoreti-
cally extracting order is followed by word order in 
the sentence. 
  
VP
AP VP*
jeukgak/MAG
?3:
S
NP_SBJ? VP
VPNP_OBJ?
?3:
NP_SBJ
?1:
oimuseong/NNG
+eun/JX
?1:
seongmyeng/NNG
+eul/JKO
balpyo/NNG+ 
ha/XSV+eoss/EP
+da/EF+./SF
NP_SBJ*
NP_SBJ
NP_OBJ
?2: ?2:
NP_OBJ*
NP_OBJ
haemyeng/NNG
NP
ilbon/NNP 
NP
 
Figure 6. Extracted lexicalized grammars G1 
                                                          
2  For extracting trees of symbols and of postposition, we 
newly add SYM and POSTP syntactic tags which SJTree does 
not use. See Figure 11 for extracted symbol and postposition 
trees. 
76
VP
AP VP*
jeukgak/MAG
?1:
S
NP_SBJ? VP
VPNP_OBJ?
?5:
POSTPNP_SBJ?
NP_SBJ
eun/JX
?6:
POSTPNP_OBJ?
NP_OBJ
eul/JKO
?7:
ilbon/NNP
NP
?1:
oimuseong/NNG
NP
?2:
haemyeng/NNG
NP
?3:
seongmyeng/NNG
NP
?4:
SYMS*
S
.
SF
?2:
balpyo/NNG+ 
ha/XSV+eoss/EP
+da/EF  
Figure 7. Extracted lexicalized grammars G2  
4.2 Extraction of feature-based lexicalized 
trees 
We extract feature-based lexicalized trees using 
reduced tagset because FB-LTAG grammars con-
tain their syntactic information in features struc-
tures. Extracted grammars G3 remove syntactic 
tags, eventually use reduced tagset, add extracted 
feature structures and use infinitive forms as lexi-
cal anchor.  
 
? G3: Using reduced tagset and a lexical an-
chor is an infinitive and adding extracted 
feature structures.   
 
G3 row in Table 1 below shows the results of ex-
traction procedures above. Figure 8 shows ex-
tracted feature-based lexicalized grammars G3 
from (1) 
VP
ADVP VP*
jeukgak
ADV
?1:
POSTPNP?
NP
eun
JX
?6:
POSTPNP?
NP
eul
JKO
?7:
ilbon
NP
?1:
NNP
haemyeng
NP
?3:
NNG
seongmyeng
NP
?4:
NNG
SYMS*
S
.
SF
?2:
S
NP? VP
VPNP?
VV
balpyoha
<cas> = nom
<det> = +
<cas> = acc
<det> = +
b: <ep> = eoss
b: <ef> = da
b: <mode> = decl
b: <tense> = past
<cas> = x
oimuseong
NP
?2:
NNG
<cas> = x <cas> = x <cas> = x
<cas> = nom <cas> = acc
<cas> = x <cas> = x
?5:
 
Figure 8. Extracted feature-based lexicalized 
grammars G3 3.  
 
 # of ltrees 
(lexicalized tree) 
Average frequen-
cies per ltrees
G1 18,080 1.38
G2 15,551 2.57
G3 12,429 3.21
Table 1. Results of experiments in extracting lexi-
calized and feature-based lexicalized grammars 
                                                          
3 To simplify the figure, we note only feature structure which 
is necessary to understand.  
4.3 Extraction of tree schemata 
As mentioned in the Introduction, one of the most 
serious problems in automatic grammar extraction 
is its limited lexical coverage. To resolve this prob-
lem, we enlarge our extracted lexicalized gram-
mars using templates which we call tree schemata. 
The lexical anchor is removed from extracted 
grammars and anchor mark is replaced to form tree 
schemata (for example, @NNG where the lexical-
ized anchor in extracted lexicalized grammars is a 
common noun). The number of tree schemata is 
much reduced against that of lexicalized grammars. 
Table 2 shows the number of template trees and 
the average frequency for each template grammars. 
T1 means G1?s tree schemata. 
 
 # of tree schemata Average frequencies 
per tree schemata
T1 1,158 21.55
T2 1,077 37.05
T3 385 103.65
Table 2. Results of experiments in converting 
template grammars 
5 Evaluations 
First of all, the lexical coverage for G1 and G2 is 
tested on the part of Sejong corpus which contains 
about 770,000 ?morphologically analyzed? eojeols. 
After modification of SJTree, the extracted gram-
mar G2 is increased to 17.8 % compared with G1 
for its lexical coverage. G2 and G3 have same lexi-
cal coverage since they have same lexical entries.  
Extracted grammars in this paper are evaluated 
by its size and its coverage. The size of grammars 
means tree schemata according to the number of 
sentences as shown in Figure 9. The coverage of 
grammar is the number of occurrences of unknown 
tree schemata in the corpus by the total occur-
rences of tree schemata as shown in Table 3.  
 
 
(a) Threshold =1  (b) Threshold =2 
Figure 9. The size of grammars 
 
 
77
 Threshold = 1 Threshold = 2
G1 0.9326 0.9591
G2 0.9326 0.9525
G3 0.9579 0.9638
Table 3. Coverage of grammars: 90% of training 
set (2,273 sentences) and 10% of test set (253 sen-
tences) 
 
We manually overlap our 163 tree schemata for 
predicates from T3, which contain 14 subcategori-
zation frames with 11 subcategorization frames of 
a FB-LTAG grammar proposed in Han et al 
(2000) to evaluate the coverage of hand-crafted 
grammars 4 . Our extracted template grammars 
cover 72.7 % of their hand-crafted subcategoriza-
tion frames5.  
6 Conclusion 
In this paper, we have presented a system for 
automatic grammar extraction that produces lexi-
calized and feature-based lexicalized grammars 
from a Treebank. Also, to resolve the problem of 
limited lexical coverage of extracted grammars, we 
separated symbols and postposition, and then con-
verted these grammars into template grammars. 
Extracted grammars and lexical-anchor-less tem-
plate grammars might be used for parsers to ana-
lyze the Korean sentences and frequency 
information might be used to remove ambiguities 
among possible syntactic analyses of parsers. 
References  
Candito, Marie-H?l?ne. 1999. Organisation modulaire 
et param?trable de grammaire ?lectronique lexicali-
s?es. Ph.D. thesis, Universit? Paris 7. 
                                                          
4 Our extracted tree schemata contain not only subcategoriza-
tion frames but also some phenomena of syntactic variations, 
the number of lexicalized trees and the frequency information 
while Han el al. (2000) only presents subcategorization frames 
and some phenomena.  
5 Three subcategorization frames in Han el al. (2000) which 
contain prepositional phrases are not covered by our extracted 
tree schemata. Generally, prepositional phrases in SJTree are 
labeled with _AJT which is marked for adjunction operation.  
Since there is no difference between noun adverbial phrase 
and prepositional phrases in SJTree like [S na.neun [NP_AJT 
ojeon.e ?morning?] [NP_AJT hakgyo.e ?to school?] ga.ss.da] (?I 
went to school this morning?), we do not consider _AJT 
phrases as arguments.  
Chen, John. 2001. Towards Efficient Statistical Parsing 
Using Lexicalized Grammatical Information. Ph.D. 
thesis, University of Delaware. 
Chiang, David. 2000. Statistical Parsing with an Auto-
matically-Extracted Tree Adjoining Grammar. In 
Data Oriented Parsing, CSLI Publication, pp. 299-
316. 
Habash, Nizar and Owen Rambow. 2004. Extracting a 
Tree Adjoining Grammar from the Penn Arabic 
Treebank. In Proceedings of Traitement Automatique 
du Langues Naturelles (TALN-04). Fez, Morocco, 
2004. 
Han, Chunghye, Juntae Yoon, Nari Kim, and Martha 
Palmer. 2000. A Feature-Based Lexicalized Tree Ad-
joining Grammar for Korean. IRCS Technical Re-
port 00-04. University of Pennsylvania. 
Johansen, Ane Dybro. 2004. Extraction des grammaires 
LTAG ? partir d?un corpus ?tiquette syntaxiquement. 
DEA m?moire, Universit? Paris 7. 
Nasr, Alexis. 2004. Analyse syntaxique probabiliste 
pour grammaires de d?pendances extraites automa-
tiquement. Habilitation ? diriger des recherches, Uni-
versit? Paris 7. 
Neumann, G?nter. 2003. A Uniform Method for Auto-
matically Extracting Stochastic Lexicalized Tree 
Grammar from Treebank and HPSG, In A. Abeill? 
(ed) Treebanks: Building and Using Parsed Corpora, 
Kluwer, Dordrecht. 
Park, Jungyeul. 2006. Extraction d?une grammaire 
d?arbres adjoints ? partir d?un corpus arbor? pour le 
cor?en. Ph.D. thesis, Universit? Paris 7. 
Sag, Ivan A., Thomas Wasow, and Emily M. Bender. 
2003. Syntactic Theory: A Formal Introduction, 2nd 
ed. CSLI Lecture Notes. 
Vijay-Shanker, K. and Aravind K. Joshi. 1991. Unifica-
tion Based Tree Adjoining Grammar, in J. Wedekind 
ed., Unification-based Grammars, MIT Press, Cam-
bridge, Massachusetts. 
Xia, Fei, Martha Palmer, and Aravind K. Joshi. 2000. A 
Uniform Method of Grammar Extraction and Its Ap-
plication. In The Joint SIGDAT Conference on Em-
pirical Methods in Natural Language Processing and 
Very Large Corpora (EMNLP/VLC-2000), Hong 
Kong, Oct 7-8, 2000.  
Xia, Fei. 2001. Automatic Grammar Generation from 
Two Different Perspectives. Ph.D. thesis, University 
of Pennsylvania, PA. 
 
78
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 133?136,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Extracting Syntactic Features from a Korean Treebank 
 
 
Jungyeul Park 
UFR Linguistique  
Laboratoire de linguistique formelle 
Universit? Paris VII - Denis Diderot 
jungyeul.park@linguist.jussieu.fr 
 
  
 
Abstract 
In this paper, we present a system which 
can extract syntactic feature structures 
from a Korean Treebank (Sejong Tree-
bank) to develop a Feature-based Lexi-
calized Tree Adjoining Grammars.  
1 Introduction 
In a Tree Adjoining Grammar, a feature structure 
is associated with each node in an elementary 
tree (Vijay-Shanker and Joshi, 1991). This fea-
ture structure contains information about how the 
node interacts with other nodes in the tree. It 
consists of a top part, which generally contains 
information relating to the super-node, and a bot-
tom part, which generally contains information 
relating to the sub-node.  
In this paper, we present a system which can 
extract syntactic feature structures from a Tree-
bank to develop a Feature-based Lexicalized 
Tree Adjoining Grammars. Several works have 
been on extracting grammars, especially using 
TAG formalism proposed. Chen (2001) has ex-
tracted lexicalized grammars from English Penn 
Treebank and there are other works based on 
Chen?s procedure such as Nasr (2004) for French 
and Habash and Rambow (2004) for Arabic. Xia 
et al (2000) developed the uniform method of a 
grammar extraction for English, Chinese and 
Korean. Neumann (2003) extracted Lexicalized 
Tree Grammars from English Penn Treebank for 
English and from NEGRA Treebank for German. 
However, none of these works have tried to ex-
tract syntactic features for FB-LTAG. 
We use with Sejong Treebank (SJTree) which 
contains 32 054 eojeols (the unity of segmenta-
tion in the Korean sentence), that is, 2 526 sen-
tences. SJTree uses 43 part-of-speech tags and 55 
syntactic tags (Sejong Project 2003). 
2 Extracting a Feature structure for 
FB-LTAG  
FB-LTAG grammars eventually use reduced 
tagset because FB-LTAG grammars contain their 
syntactic information in features structures. For 
example, NP_SBJ syntactic tag in LTAG is 
changed into NP and a syntactic feature 
<case=nominative> is added. Therefore, we use 
actually a 13 reduced tagset for FB-LTAG gram-
mars compared with a 55 syntactic tagset for an 
LTAG without features. From full-scale syntactic 
tags which end with _SBJ (subject), _OBJ (ob-
ject) and _CMP (attribute), we extract <case> 
features which describe argument structures in 
the sentence.  
Alongside <case> features, we also extract 
<mode> and <tense> from morphological analy-
ses in SJTree. Since however morphological 
analyses for verbal and adjectival endings in 
SJTree are simply divided into EP, EF and EC 
which mean non-final endings, final endings and 
conjunctive endings, respectively, <mode> and 
<tense> features are not extracted directly from 
SJTree. In this paper, we analyze 7 non-final 
endings (EP) and 77 final endings (EF) used in 
SJTree to extract automatically <mode> and 
<tense> features. In general, EF carries <mode> 
inflections, and EP carries <tense> inflections. 
Conjunctive endings (EC) are not concerned with 
<mode> and <tense> features and we only ex-
tract <ec> features with its string value. <ef> and 
<ep> features are also extracted with their string 
values. Some of non-final endings like si are ex-
tracted as <hor> features which have honorary 
meaning. In extracted FB-LTAG grammars, we 
present their lexical heads in a bare infinitive 
with morphological features such as <ep>, <ef> 
and <ec> which make correspond with its in-
flected forms.  
133
<det> is another automatically extractable fea-
ture in SJTree and it is extracted from both syn-
tactic tag and morphological analysis unlike 
other extracted features. For example, while 
<det=-> is extracted from dependant nouns 
which always need modifiers (extracted by mor-
phological analyses), <det=+> is extracted from 
_MOD phrases (extracted by syntactic tags). 
From syntactic tag DP which contains MMs (de-
terminative or demonstrative), <det=+> is also 
extracted. See Table 1 for all the extractable fea-
tures from SJTree.  
 
Feature Description Values 
<case> a case feature 
assigned by 
predicate 
nom(inative), 
acc(usative), 
attr(ibut) 
<det> determiner, 
modifier 
+/- 
<mode> mode ind(icative), 
imp(erative), 
int(errogative), 
exc(lamatory) 
<temps> tense pre(sent), past, 
fut(ure) 
<ep>, <ef>, 
<ec> 
a feature 
marked for 
different ways 
of instantiating 
mode and tense 
string values 
like eoss, da, 
go, etc. 
<hor> honorific +/- 
Table 1. Extractable Features from SJTree 
 
Korean does not need features <person> or 
<number> as in English. Han et al (2000) pro-
posed several features for Korean FBLTAG 
which we do not use in this paper, such as <adv-
pp>, <top> and <aux-pp> for nouns and <clause-
type> for predicates. While postpositions are 
separated from eojeol during our grammar ex-
traction procedure, Han et al considered them as 
?one? inflectional morphology of noun phrase 
eojeol. <aux-pp> adds semantic meaning of aux-
iliary postpositions such as only, also etc. which 
we can not extract automatically from SJTree or 
other Korean Treebank corpora because syntacti-
cally annotated Treebank corpora generally do 
not contain such semantic information. <top> 
marks the presence or absence of a topic marker 
in Korean like neun, however topic markers are 
annotated like a subject in SJTree which means 
that only <case=nominative> is extracted for 
topic markers. <clause-type> indicates the type 
of the clause which has its values such as main, 
coord(inative), subordi(native), adnom(inal), 
nominal, aux-connect. Since the distinction of 
the type of the clause is very vague except main 
clause in Korea, we do not adopt this feature. 
Instead, <ef> is extracted if a clause type is a 
main clause and for <ec> is extracted for other 
types.  
3 Experimentations  
The actual procedure of feature extraction is 
implemented by two phases. In the first phase, 
we convert syntactic tags and morphological 
analysis into feature structure as explained above 
(see Table 2 for our conversion scheme for 
syntactic tags and see Table 3 for morphological 
analyses). In the second phase, we complete 
feature structure onto nodes of the ?spine (path 
between root and anchor, node in an initial tree 
and path between root and foot node in an 
auxiliary tree)?. For example, we put the same 
feature of VV bottom in Figure 1a onto VV top, 
VP top/bottom and S bottom because nodes in 
dorsal spine share certain number of feature of 
VV bottom. The initial tree for a verb 
balpyoha.eoss.da (?announced?) in (1) is 
completed like Figure 1b for a FB-LTAG. 
 
(1) ?? ???? ?? ?? ??? ????. 
(1)  ilbon    oimuseong.eun  
(1)  Japan   ministy_of_foreign_affairs.Nom  
(1)  jeukgak   haemyeng seongmyeng.eul 
(1)  immediately   elucidation declaration.Acc 
(1)  balpyo.ha.eoss.da 
(1)  announce.Pass.Ter 
(1) ?The ministry of foreign affairs in Japan 
(1) immediately announced their elucidation? 
S
NP? VP
VPNP?
VV
balpyoha
<cas> = nom
<cas> = acc
b: <ep> = eoss
b: <ef> = da
b: <mode> = decl
b: <tense> = past
 
a. First phase 
S
NP? VP
VPNP?
VV
balpyoha
b: <ep> = eoss
b: <ef> = da
b: <mode> = decl
b: <tense> = past
t:  <ep> = x, <ef> = y, <mode> = i, <tense> = j
t:  <ep> = x, <ef> = y, <mode> = i, <tense> = j
b: <ep> = x, <ef> = y, <mode> = i, <tense> = j
t:  <ep> = x, <ef> = y, <mode> = i, <tense> = j
b: <ep> = x, <ef> = y, <mode> = i, <tense> = j
t:  -
b: <ep> = x, <ef> = y, <mode> = i, <tense> = j
<cas> = nom
<det> = +
<cas> = acc
<det> = +
 
b. Second phase 
Figure 1. Extracted FB-LTAG grammar for 
balpyoha.eoss.da (?announced?) 
 
134
Table 4 shows the results of experiments in ex-
tracting feature-based lexicalized grammars. See 
Park (2006) for the detail extraction scheme.  
4 Evaluations 
Finally, extracted grammars are evaluated by its 
size (see Figure 2) and its coverage (see Table 5). 
The number of tree schemata is not stabilized at 
the end of the extraction process, which seems to 
indicate that the size of Treebank is not enough 
to reach the convergence of extracted grammars. 
However, the number of tree schemata appearing 
at least twice and three times (threshold = 2 and 
3) in Treebank is much stabilized at the end of 
the extraction process than that of tree schemata 
appearing only once (threshold = 1).  
The coverage of extracted grammars is calcu-
lated not only by the frequency of tree schemata 
but also by the number of tree schemata. 
 
 
Figure 2. Size of tree schemata 
 
We manually overlap our 163 tree schemata for 
predicates, which contain 14 subcategorization 
frames with 11 subcategorization frames of a 
FB-LTAG grammar proposed in Han et al 
(2000) to evaluate the coverage of hand-crafted 
grammars 1 . Our extracted template grammars 
cover 72.7 % of their hand-crafted subcategori-
zation frames2.  
                                                 
1  Our extracted tree schemata contain not only 
subcategorization frames but also some phenomena of 
syntactic variations, the number of lexicalized trees and the 
frequency information while Han el al. (2000) only presents 
subcategorization frames and some phenomena.  
2 Three subcategorization frames in Han el al. (2000) which 
contain prepositional phrases are not covered by our ex-
tracted tree schemata. Generally, prepositional phrases in 
SJTree are labeled with _AJT which is marked for adjunc-
tion operation.  Since there is no difference between noun 
adverbial phrase and prepositional phrases in SJTree like [S 
na.neun [NP_AJT ojeon.e ?morning?] [NP_AJT hakgyo.e ?to 
school?] ga.ss.da] (?I went to school this morning?), we do 
not consider _AJT phrases as arguments.  
5 Conclusion  
In this paper, we have presented a system for 
automatic grammar extraction that produces fea-
ture-based lexicalized grammars from a Tree-
bank. Also, we evaluated by its size and its cov-
erage, and overlap our automatically extracted 
tree schemata from a Treebank with a manually 
written subcategorization frames to evaluate the 
coverage of hand-crafted grammars. 
References 
Alexis Nasr. 2004. Analyse syntaxique probabiliste 
pour grammaires de d?pendances extraites auto-
matiquement. Habilitation ? diriger des recherches, 
Universit? Paris 7. 
Chunghye Han, Juntae Yoon, Nari Kim, and Martha 
Palmer. 2000. A Feature-Based Lexicalized Tree 
Adjoining Grammar for Korean. IRCS Technical 
Report 00-04. University of Pennsylvania. 
Fei Xia, Martha Palmer, and Aravind K. Joshi. 2000. 
A Uniform Method of Grammar Extraction and Its 
Application. In The Joint SIGDAT Conference on 
Empirical Methods in Natural Language Process-
ing and Very Large Corpora (EMNLP/VLC-2000), 
Hong Kong, Oct 7-8, 2000.  
G?nter Neumann. 2003. A Uniform Method for 
Automatically Extracting Stochastic Lexicalized 
Tree Grammar from Treebank and HPSG, In A. 
Abeill? (ed) Treebanks: Building and Using 
Parsed Corpora, Kluwer, Dordrecht. 
John Chen. 2001. Towards Efficient Statistical Pars-
ing Using Lexicalized Grammatical Information. 
Ph.D. thesis, University of Delaware. 
Jungyeul Park. 2006. Extraction automatique d?une 
grammaire d?arbres adjoints ? partir d?un corpus 
arbor? pour le cor?en. Ph.D. thesis, Universit? 
Paris 7.  
K. Vijay-Shanker and Aravind K. Joshi. 1991. Unifi-
cation Based Tree Adjoining Grammar, in J. 
Wedekind ed., Unification-based Grammars, MIT 
Press, Cambridge, Massachusetts. 
Nizar Habash and Owen Rambow. 2004. Extracting a 
Tree Adjoining Grammar from the Penn Arabic 
Treebank. In Proceedings of Traitement Auto-
matique du Langage Naturel (TALN-04). Fez, Mo-
rocco, 2004. 
Sejong Project. 2003. Final Report of Sejong Korean 
Treebank. Ministry of Education & Human Re-
sources Development in Korea. 
 
135
Anchor Tree type Syntactic tag Node type Conversion exam-
ple 
verb ? NP_SBJ subst NP  
[<cas> = nom  
<det> = +] 
verb ?|? VP, VP_MOD - VP  
[<ep> <ef>  
<mode> <tense>] 
anchored by 
_MOD phrase 
? NP|NP_CMP|NP_MOD
|NP_OBJ||NP_SBJ 
root NP  
[<det> = +] 
postposition ? NP_SBJ root NP  
[<cas> = nom] 
postposition ? NP_SBJ subst NP  
[<cas> = NONE] 
Table 2. Conversion example for syntactic tags 
 
Verbal ending Ending type Conversion example 
eoss EP <ep> = eoss, <tense> = past  
si EP <ep> = si, <hor> = + 
da EF <ef> = da, <mode> = ind 
Table 3. Conversion example for morphological analyses 
 
 # of lexicalized 
tree 
(? + ?) 
Average fre-
quencies per lexi-
calized tree
# of tree sche-
mata (? + ?) 
Average fre-
quencies per tree 
schemata
G 12 239 
(7 315 + 4 766) 
3.26 338  
(109 + 229)  
118.1
Table 4. Results of experiments in extracting feature-based lexicalized grammars 
 
 Coverage of grammars by the fre-
quency of tree schemata 
Coverage of grammars by the number 
of tree schemata 
Threshold 1 2 3 1 2 3 
60 % of 
training set 
60.75 % 60.7 % 60.66 % 81.66 % 83.83 % 83.5 % 
90 % of 
training set 
91.14 % 91.14 % 91.11 % 95.86 % 98.3 % 96.5 % 
Table 5. Coverage of grammars: 60% of training set (1511 sentences) and 90% of training set (2265 
sentences) 
 
 
136
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 178?181,
Uppsala, Sweden, 15-16 July 2010.
c?2010 Association for Computational Linguistics
UNPMC: Na??ve Approach to Extract Keyphrases from Scientific Articles
Jungyeul Park
LINA,
Universit?e de Nantes
Nantes, France
jungyeul.park
@univ-nantes.fr
Jong Gun Lee
LIP6-CNRS,
UPMC (Paris 6)
Paris, France
jonggun.lee
@lip6.fr
B
?
eatrice Daille
LINA,
Universit?e de Nantes
Nantes, France
beatrice.daille
@univ-nantes.fr
Abstract
We describe our method for extracting
keyphrases from scientific articles which
we participate in the shared task of
SemEval-2 Evaluation Exercise. Even
though general-purpose term extractors
along with linguistically-motivated analy-
sis allow us to extract elaborated morpho-
syntactic variation forms of terms, a na??ve
statistic approach proposed in this paper
is very simple and quite efficient for ex-
tracting keyphrases especially from well-
structured scientific articles. Based on
the characteristics of keyphrases with sec-
tion information, we obtain 18.34% for
f-measure using top 15 candidates. We
also show further improvement without
any complications and we discuss this at
the end of the paper.
1 Introduction
1
Key phrases are a set of words to capture the main
topic of the document. Since key phrases con-
tain the substance of the document, they are used
in the large spectrum of areas; from applications
which explicitly use key phrases such as automatic
indexing, documents classification and search en-
gine optimization in information retrieval, to ap-
plications which implicitly use key phrases such as
summarization and question-answering systems.
During the last decade, many previous works have
dealt with the various methods for automatically
extracting key phrases (e.g., Frank et al, 1999;
Barker and Corrnacchia, 2000; Turney, 2003;
Medelyan and Witten, 2006; Nguyen and Kan,
2007; Wan and Xiao, 2008).
1
UNPMC means the collaborative team from Laboratoire
d?Informatique de Nantes Atlantique of the Universit?e de
Nantes and Laboratoire d?Informatique de Paris 6 of the Uni-
versit?e Pierre et Marie Curie.
The task of extracting key phrases would be
considered as a subtask of extracting terminology
if key phrases are a kind of terms. Typical ap-
proaches for automatically extracting terms use
linguistic preprocessing which involves morpho-
syntactic analysis such as part-of-speech tagging
and phrase chunking, and statistical postprocess-
ing such as log likelihood which compares the
term frequencies in a document against their ex-
pected frequencies derived in a bigger text. Be-
sides, extracting terms prefers syntactically plau-
sible noun phrases (NPs) which are mainly multi-
words terms. Kim and Kan (2009) report that most
of key phrases are often simple words than less of-
ten compound words
2
.
The task for extracting key phrases tend to in-
clude analyzing the document structure. Espe-
cially, extracting key phrases from well-structured
scientific articles should consider cross-section in-
formation (Nguyen and Kan, 2007). This informa-
tion has been explored to assess the suitability of
features during learning in Kim and Kan (2009).
Extracting key phrases, however, is more than to
extracting terminology or analyzing the document
structure. While terms are words which appear in
specific contexts and analyse concept structures in
domains of human activity, key phrases are words
that capture the key idea of documents. In addi-
tion, while terms usually occur in the given doc-
ument more often than we would expect to occur,
key phrases do not necessarily occur frequently or
key phrases do not occur at all in the document.
Consequently, the task for extracting key phrases
should not be considered as the subtask of extract-
ing terminology and we are not able to directly ap-
ply general-purpose term extractors to extract key
phrases.
In this paper, we describe our method for ?Au-
tomatic Keyphrase Extraction from Scientific Ar-
2
In training data, only 23.4% of keyphrases, however, are
single words.
178
ticles?, the shared task of SemEval-2 Evalua-
tion Exercise which we participated in. Al-
though term extractors along with linguistically-
motivated analysis allow us to extract even elab-
orated morpho-syntactic variation forms of terms,
the na??ve statistic approach proposed in this pa-
per is very simple and quite efficient for extracting
keyphrases especially from well-structured scien-
tific articles. In a nutshell, our method is based
on empirical rules without any linguistically-
motivated preprocessing. Empirical rules are ob-
tained from the analysis of the characteristics of
keyphrases by observing training data.
The remaining of this paper is organized as fol-
lows: Section 2 explains the characteristics of
keyphrases in scientific articles. Section 3 and 4
detail our na??ve statistic approach and experiment,
respectively. We conclude this paper and discuss a
further improvement in Section 6.
2 Characteristics of Keyphrases in
Scientific Articles
In this section, we investigate the characteristics of
keyphrases in training data. Table 1 shows statis-
tics of training data. In Table 1, D-author means
the keyphrases assigned by authors, D-reader the
keyphrases assigned by readers, and D-combined
the combined keyphrases assigned by both of au-
thors and readers.
# of papers (p) # of key phrases (k) k / p
D-author 144 563 3.91
D-reader 144 1,865 12.95
D-combined 144 2,265 15.73
Table 1: Statistics of training data
2.1 Word length of keyphrases
We measure the distribution of word length of key
phrases in training data and present it in Figure 1.
Over half of key phrases are two-word key phrases
in both author- and reader-assigned key phrases.
Differently with Kim and Kan (2009) which they
reported that most of key phrases are often sim-
ple words than less often compound words, only
29.7% and 17.7% of key phrases are one-word key
phrases. There are also more than four-word key
phrases which hold 4.3% and 7.2% of author and
reader assigned key phrases, respectively.
2.2 Occurrences of keyphrases
In which section do keyphrases occur frequently?
To answer this question, we count the number of
length=1(29.7%)
length=2(51.3%) length=3(14.7%)
length=4+(4.3%)
(a) D-author
length=1(17.7%)length=2(53.2%)
length=3(21.8%)
length=4+(7.2%)
(b) D-reader
Figure 1: Word length of keyphrases in training
data
occurrences of keyphrases of each section. Due
to the variation of the naming of the section,
we divide sections into title and abstract, intro-
duction, conclusion, and the rest including refer-
ences. Table 2 and 3 show the number of occur-
rences and the accumulative number of unique oc-
currences of keyphrases in each section, respec-
tively. We also show the accumulative number
of words in each section in Table 4. Including
the rest sections exponentially diminishes the ra-
tio of the number of gold keyphrases to the number
of candidate keyphrases. Note that m words pro-
duce
?
n?1
i=0
(m ? i) candidate keyphrases for up
to n-word keyphrases by supposing that candidate
keyphrases are simple n-word terms.
Note also that both author- and reader-assigned
keyphrases hold only 75.49% and 89.44%, re-
spectively. Even some keyphrases are different
with surface forms in the document and our na??ve
method with no linguistic intervention is not able
to recognize them. For example, one of reader-
assigned keyphrases distributed real-time embed-
ded system for C-41 actually appears as distributed
real-time and embedded (DRE) systems.
D-author D-reader
Title and Abstract 277 802
Introduction 215 491
Conclusion 313 982
Other 387 1,210
Table 2: Number of occurrences of keyphrases in
each section
D-author D-reader
Total 563 (100.0%) 1,865 (100.0%)
Title and Abstract 277 (49.20%) 802 (43.00%)
?+? Introduction 317 (56.30%) 937 (50.24%)
?+? Conclusion 367 (65.19%) 1,311 (70.29%)
?+? Other 425 (75.49%) 1,668 (89.44%)
Table 3: Accumulative number of unique occur-
rences of keyphrases in each section
179
# words (W) # gold (G) G/W
Title and Abstract 28435 802 0.0282
?+? Introduction 72729 937 0.0128
?+? Conclusion 178473 1311 0.0073
?+? Other 948007 1668 0.0018
Table 4: Number of words in training data and
gold data (D-reader)
2.3 Coincidence of keyphrases
Figure 2 shows the coincidence of keyphrases
3
.
Almost half of keyphrases (58.44% and 45.74%
for author- and reader-assigned keyphrases, re-
spectively) occur coincidentally in keysections
and the rest sections. Keysections hold 65.19%
and 70.29% of keyphrases and the rest sections
besides keysections hold 68.74% and 64.88% of
whole keyphrases. Note that the rest sections oc-
cupy over 70% of the document on the average.
(a) D-author (b) D-reader
Figure 2: Coincidence of keyphrases
3 Methodology
From training data, we observe and decide the fol-
lowings:
? More than four-word keyphrases hold only
4.3% and 7.2% of whole keyphrases. We
decide that our approach limits the word
length as three for extracting keyphrases.
Thus we extract only up to three-word
keyphrases. This choice might lead the per-
formance degradation of our method because
we explicitly exclude more than four-word
keyphrases.
? Keysections hold 65.19% and 70.29% of
keyphrases. We decide that our approach
limits keysections from which we extract
keyphrases. Including the rest sections may
3
We denote title and abstract as A, introduction as I, con-
clusion as C, and the rest sections including references as
Other.
improve recall, but probably diminish preci-
sion since the rest sections occupy over 70%
of the document.
? Almost half of keyphrases occur coinciden-
tally in keysections and the rest sections. We
decide that our approach limits coincident
keyphrases in both of them. This decision is
made empirically and improve precision.
The following procedure explains and details
our approach for extracting keyphrases.
? Extract up to three-word terms from keysec-
tions as candidate keyphrases.
? Filter them out if they contain one or more of
stop words or non-content-containing words
(see Table 5 for non-content-containing
words).
? Count the number of occurrences of extracted
terms from each keysection.
? Check the coincidence whether candidate
keyphrases occurs in more than two keysec-
tions. If so, we assign weight.
? Calculate a score for candidate keyphrases
and list them by order of the score.
4 Experiment results
This section shows the experiment results with
training and test data.
4.1 Training data
To optimize our results, we use various thresholds
for the number of n-word keyphrases and weight.
We try to find the (i : j : k) pattern which
means i one-word, j two-word, and K three-
word keyphrases to produce the best results. We
also try to find the threshold for weight d to cal-
culate the score as follows: if keyphrases ap-
pear in more than two keysections, score =
d ? # of total occurences, otherwise score =
# of total occurences. Table 6 shows our best
results for training data where (i : j : k) = (3 :
9 : 3) and d = 2. Empirically, we found these
thresholds from training data by iterating several
possibilities
4
.
4.2 Test data
Table 7 shows our test data results published by
organizers of the shared task of SemEval-2 Evalu-
ation Exercise.
4
These thresholds will be more examined in future work.
180
Type Examples
Noun section, abstract, introduction, conclusion, reference, future work, figure, paper, result, laboratory, university
Verb present, how, introduce, become, improve, find, help, improve, consider, call, yield, allow, give, assume
Adverb always, formally, necessarily, successfully, previously, usually,mainly, final, essentially, ultinately, commonly,
severely, significantly, dramatically, clearly, still, well, who, whose, whom, which, whether, therefore,
Other POSs that, this, those, these, many, several, more, over, less, behind, above, below, each, few, different, under,
both, within, through, prior, various, better, following, between, possible, via, before,even, such, if, new,
show, important, simple, good, tranditional, current, varying, necessary, previous, clear
Table 5: Example of (heuristically obtained) non-content-containing terms
AUTHOR.STEM.FINAL
# Gold: 559 Match Precision Recall F-score
Top 05 43 5.97% 7.69% 6.72%
Top 10 101 7.01% 18.07% 10.10%
Top 15 139 6.44% 24.87% 10.23%
READER.STEM.FINAL
# Gold: 1824 Match Precision Recall F-score
Top 05 118 16.39% 6.47% 9.28%
Top 10 249 17.29% 13.65% 15.26%
Top 15 361 16.71% 19.79% 18.12%
COMBINED.STEM.FINAL
# Gold: 2223 Match Precision Recall F-score
Top 05 143 19.86% 6.43% 9.71%
Top 10 309 21.46% 13.90% 16.87%
Top 15 441 20.42% 19.84% 20.13%
Table 6: Training data results
READER.STEM.FINAL
# Gold: 1204 Precision Recall Fscore
Top 05 13.80% 5.73% 8.10%
Top 10 15.10% 12.54% 13.70%
Top 15 14.47% 18.02% 16.05%
COMBINED.STEM.FINAL
# Gold: 1466 Precision Recall Fscore
Top 05 18.00% 6.14% 9.16%
Top 10 19.00% 12.96% 15.41%
Top 15 18.13% 18.55% 18.34%
Table 7: Test data results
5 Conclusion and Discussion
In this paper, we described our simple method
for extracting keyphrases from scientific arti-
cles which we participate in the shared task of
SemEval-2 Evaluation Exercise. The na??ve ap-
proach was proposed. This approach turned
out very simple and quite efficient for extracting
keyphrases from well-structured scientific articles.
Based on learning the distribution of keyphrases
with section information, we obtain 18.34% for f-
measure using top 15 candidates.
Our na??ve approach still has much room for
improvement. For example, we are able to im-
prove the result for same test data up to 20.71%
and 25.55% for f-measure using top 15 candidates
simply by adding the rest sections and normaliz-
ing the number of occurrences of terms from each
section
5
.
5
The result is not improved only by adding the rest sec-
tions.
Moreover, our n-word terms based extraction
can be benefited by linguistic preprocessing such
as normalizing surface forms. Handcrafted regu-
lar expression rules along with part-of-speech tag-
ging and phrase chunking would be also intro-
duced to improve candidate selection. We have
not explored thoroughly feature engineering, nei-
ther. For example, more fine-grained section infor-
mation and weight re-assignment might help filter
out irrelevant candidates. We leave these possibil-
ities for future work.
References
Ken Barker and Nadia Cornacchia. 2000. Using noun phrase
heads to extract document keyphrases. In Proceedings
of the 13th Biennial Conference of the Canadian Soci-
ety on Computational Studies of Intelligence: Advances
in Artificial Intelligence, pages 40-52. May 14-17, 2000.
Montr?eal, Quebec, Canada.
Eibe Frank , Gordon W. Paynter , Ian H. Witten , Carl Gutwin,
and Craig G. Nevill-Manning. 1999. Domain-Specific
Keyphrase Extraction. In Proceedings of the 16th Inter-
national Joint Conference on Artificial Intelligence, pages
668-673. July 31-August 6, 1999. Stockholm, Sweden.
Su Nam Kim and Min-Yen Kan. 2009. Re-examining Auto-
matic Keyphrase Extraction Approaches in Scientific Ar-
ticles. In Proceedings of the Workshop on Multiword Ex-
pressions: Identification, Interpretation, Disambiguation
and Applications (MWE 2009), ACL-IJCNLP 2009, pages
9-12. August 6, 2009. Singapore.
Olena Medelyan and Ian H. Witten. 2006. Thesaurus based
automatic keyphrase indexing. In Proceedings of the
6th ACM/IEEE-CS joint conference on Digital libraries,
pages 296-297. June 11-15, 2006. Chapel Hill, NC, USA.
Thuy Dung Nguyen and Min-Yen Kan. 2007. Key phrase
Extraction in Scientific Publications. Asian Digital Li-
braries. Looking Back 10 Years and Forging New Fron-
tiers, pages 317-326. Springer Berlin, Heidelberg.
Peter D. Turney. 2003. Coherent keyphrase extraction via
Web mining. In Proceedings of the 18th International
Joint Conference on Artificial Intelligence, pages 434-
439. August 9-15, 2003. Acapulco, Mexico.
Xiaojun Wan and Jianguo Xiao. 2008. CollabRank: towards
a collaborative approach to single-document keyphrase
extraction. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling 2008),
pages 969-976. 18-22 August, 2008. Manchester, UK.
181
Proceedings of the 2nd Workshop on Cognitive Aspects of the Lexicon (CogALex 2010), pages 48?55,
Beijing, August 2010
Conceptual Structure of Automatically Extracted Multi-Word Terms
from Domain Specific Corpora: a Case Study for Italian
Elisa Lavagnino
LCI - Te?le?com Bretagne &
CeRTeM - Universita` degli Studi di Genova
elisa.lavagnino
@telecom-bretagne.eu
Jungyeul Park
LINA
Universite? de Nantes
jungyeul.park
@univ-nantes.fr
Abstract
This paper is based on our efforts on
automatic multi-word terms extraction
and its conceptual structure for multi-
ple languages. At present, we mainly
focus on English and the major Ro-
mance languages such as French, Span-
ish, Portuguese, and Italian. This pa-
per is a case study for Italian language.
We present how to build automatically
conceptual structure of automatically ex-
tracted multi-word terms from domain
specific corpora for Italian. We show
the experimental results for extracting
multi-word terms from two domain cor-
pora (?natural area? and ?organic agri-
culture?). Since this work is still on-
going, we discuss our future direction at
the end of the paper.
1 Introduction
Great progress has been recently obtained on us-
ing text analysis to extract terms in a specific
field. The study of texts helps in finding and or-
ganizing textual segments representing concep-
tual units. A corpus is a collection of texts stored
in an electronic database. Texts have been se-
lected to be representative of a particular goal.
A corpus must be balanced in quality and quan-
tity contents: in order to be representative of a
domain, texts have to cover all the possible com-
municative situations. Generally, in a specialised
domain, users share contents and they normally
can understand and communicate with each oth-
ers without ambiguities. However, when differ-
ent communities get in touch the possibility of
misunderstanding arises because of terminolog-
ical variation. This variation can be detected at
a conceptual level or at the formal one. Our ap-
proach tries to overcome this problem by collect-
ing different text typologies. Texts may be ex-
tracted from different sources which can be clas-
sified as their specialisation level, their contents,
their pragmatic application, etc. In our case, we
are interested in using different texts, in order to
analysis the result of automatic extraction in dif-
ferent communicative situations to improve its
functioning.
A term can be simple if composed by one
word, or complex if composed by several words.
This paper focuses on extracting and concep-
tually structuring multi-word terms for Italian.
Collet (2000) affirmed that a complex term
(multi-word term in our terminology) is a com-
plex unit whose components are separated by a
space and are syntactically connected. The re-
sulting unit denominates a concept which be-
longs to the language for special purposes (LSP).
Texts on any domain are easily available on the
Web these days. To create a corpus represent-
ing a field, materials should be, however anal-
ysed and re-elaborated in order to resolve even-
tual problems arising the transfer of data. In
particular, a corpus have to be processed in or-
der to classify the composing units. This clas-
sification represents the first step towards termi-
nological extraction. Terminologists must often
look through many texts before finding appropri-
ate ones (Agbago and Barrire, 2005). L?Homme
(2004) presents guidelines for choosing termi-
nology such as domain specificity, language
originality, specialization level, type, date, data
48
evaluation.1
Since interaction between domains increases
consistently, domain specificity is a crucial point
to considerer during the creation of a corpus.
Text typologies and communicative situations
reflect their peculiarity to terms. A concept can
be represented differently if the level of special-
isation of a text or the context changes. Here,
we consider the context as the frame in which
the communication takes place. For example,
the domain of ?natural area?, Italian language is
really interesting because terms register a high
level of variations due to the different contexts.
The LSP changes as the society evolves.
Terms can register the diachronic variation due
to the development of a certain domain. The
evolution of a domain influences also the termi-
nologies which form LSP. Terminological evolu-
tion generates variations in the conceptual rep-
resentation which should be observed in order
to detect terms and their variants and to estab-
lish relations between them. For example, the
domain of ?organic agriculture? is now evolving
and changing because of political choices. This
affects the terminology and the eventual creation
of new forms. The affix bio- which can be use
as a variant of almost all multi-word terms con-
cerning the biological production such as metodo
di produzione biologica (?method of organic pro-
duction?) becomes metodo bio and prodotto bio-
logico (?organic product?) becomes prodotto bio
or just bio.
In this paper, we present an approach for ex-
tracting automatically multi-word terms (MWT)
from domain specific corpora for Italian. We
also try to conceptually structure them, that is we
build the ?conceptual? structure of variations of
multi-word terms where we can learn dynamics
of terms (Daille, 2002). Conceptual structure in
this paper limits to the semantic relationships be-
tween terms such as Hyperonomy, Antony, Set
of, and Result between multi-word terms and we
currently implement only hyperonomy relations.
Actually, this paper is based on our efforts
on automatic multi-word terms extraction and its
1The translated text is adapted from Agbago and Barrire
(2005)
conceptual structure for multiple languages. At
present, we mainly focus on English and the ma-
jor Romance languages such as French, Span-
ish, Portuguese, and Italian. This paper is a case
study for Italian language. The remaining of this
paper is organized as follows: We explain how
to automatically extract and conceptually struc-
ture multi-word terms from domain specific cor-
pora in the next section. We also describe some
implementation issues and current advancement.
Since this work is still on-going, we discuss our
future direction in the last section.
2 Automatically Extracting and
Conceptually Structuring
Multi-Word Terms
2.1 ACABIT
To extract automatically multi-word terms from
domain specific corpora and conceptually struc-
ture them for Italian, we adapt existing ACABIT
which is a general purpose term extractor. It
takes as input a linguistically annotated corpus
and proposes as output a list of multi-word term
candidates ranked from the most representative
of the corpus to the least using the log-likelihood
estimation.2 ACABIT is currently available for
English and French as different programs for
each language. Fundamentally, ACABIT works
as two stages: stat and tri. At the stat,
it allows us to identify multi-word terms in cor-
pora to calculate the statistic. At the tri, it al-
lows us to sort and conceptually structure them
based on base terms. For the moment, we reim-
plement universal stat for major Romance lan-
guages. We explain the more detailed issues of
our reimplementation of ACABIT for Italian in
Section 2.3.
2.2 Base Term and its Variations
For automatic multi-word term identification, it
is necessary to define first the syntactic struc-
tures which are potentially lexicalisable (Daille,
2003). We refer to these complex sequences as
base terms. For Italian, the syntactic structure of
base terms is as follows (where Noun1 is a head):
2http://www.bdaille.fr
49
Noun1 Adj area protetta (?protected area?),
azienda agricola (?agricultural company?)
Noun1 Noun2 zona tampone (?buffer area?)
Noun1 di (Det) Noun2 sistema di controllo
(?control system?), conservazione dei
biotopi (?biotope conservation?)
Besides these base term structures, there is
also [Noun1 a` Vinf ] for example for French. For
Italian, there might be [Noun1 da Vinf ] such as
prodotto biologico da esportare (?organic prod-
uct to export?) which is rather phraseology and
not a term. Consequently, we define only three
base term structures for Italian for now.
ACABIT for Italian should spot variations of
base terms and puts them together. For exam-
ple, there are graphical variations such as case
differences and the presence of an optional hy-
phen inside of base term structures, inflexional
variations where aree protette (?protected ar-
eas?) should be considered as the variation of
area protetta (?protected area?), or shallow syn-
tactic variations which only modifies function
words of the base terms, such as optional charac-
ter of the preposition and article such as sistema
di informazione and sistema informativo (?infor-
mation system?).
To conceptually structure identified multi-
word terms, ACABIT for Italian should put to-
gether syntactic variations which modify the in-
ternal structure of the base term: internal mod-
ification and coordination. Internal modifica-
tion variations introduce the modifier such as
the adjective in [Noun1 di Noun2] structure or
a nominal specifier inside of [Noun1 Adj] struc-
ture. For example, qualita` ambientale (?envi-
ronmental quality?) and elevata qualita` ambien-
tale (?high environmental quality?) for [Noun1 di
Noun2] structure and ingrediente biologico (?or-
ganic ingredient?) and ingrediente d?origine bi-
ologico (?organic origin ingredient?) for [Noun1
Adj] structure . Coordination variations coordi-
nate or enumerate the base term structure, for
example habitat ntaurali (?natural habitat?) and
habitat naturali e quasi naturali (?natural and al-
most natural habitat?)
2.3 Implementation
To keep consistent with the original ACABIT and
to take an advantage of by directly using a certain
part of existing modules, we use the input and the
output formats of ACABIT. The input format of
ACABIT requires the lemmatized forms of words
for detecting inflexional variations of multi-word
terms. For example, putting together inflexional
variations such as area protetta and aree protette
(?protected area(s)?) is easily predictable by us-
ing their lemmatized forms. The original ver-
sion of ACABIT for French uses BRILL?s POS
tagger3 for POS tagging and FLEMM4 for restor-
ing morpho-syntactic information and lemma-
tized forms. And for English, it uses BRILL?s
POS tagger and CELEX lexical database5 as a
lemmatiser.
Since we are reimplementing ACABIT for
multiple languages and we want to use the ho-
mogeneous preprocessing for ACABIT, we use
TREETAGGER6 which annotates both of part-of-
speech tags and lemma information as prepro-
cessor for . Moreover, TREETAGGER is avail-
able for several languages. We, then adapt the
result of TREETAGGER for the input format for
ACABIT. We use French POS tagger?s tagset
(E?tiquettes de Brill94 Franc?ais INALF/CNRS)
for every language, we convert TREETAGGER
tagset into BRILL?s tagset.7
Figure 1 shows the example of the input for-
mat of ACABIT in XML makes use of which
conforms to Document Type Definition (DTD)
in Figure 2. In Figure 1, POS tags are followed
by morpho-syntactic information and the lem-
matized form of a token in each <PH>.8 TREE-
TAGGER provide only lemmatized forms with
POS information, instead of providing its main
3http://www.atilf.fr
4http://www.univ-nancy2.fr/pers/namer/
Telecharger Flemm.htm
5http://www.ldc.upenn.edu/
6http://www.ims.uni-stuttgart.de/
projekte/corplex/TreeTagger/
7http://www.lirmm.fr/?mroche/
Enseignements/FdD M2P old/Etiqueteur/
tags.html#francais inalf
8For the convenience of the notations, accented charac-
ters are sometimes presented as ?e and ?a for e` and a`,
respectively in the Figure.
50
morphological features such as gender, number,
person and case as FLEMM in the previous ver-
sion of ACABIT. We simply introduce dummy
morphological information because it is not ac-
tually used in ACABIT. Note that e`/SYM/e` in
Figure 1 is not correctly POS-tagged by TREE-
TAGGER. It is one of flexional forms of essere
(?be?) instead of the symbol (SYM). However, we
do not perform any post-processing to correct er-
rors and we leave it as it is analyzed for the mo-
ment.
In Figure 2, <CORPUS> is for the name of
the corpus, <RECORD> is for different texts
which are usually from separate files, <INFO>
has a format like <INFO>00/CAR/00 -/-
0001800/SBC/0001800</INFO> with the
year of text creation 00 and the file identifica-
tion 0001800. <TITLE> is for the title, <AB>
is for the text body, and <PH NB="num"> is for
sentence identification.
ACABIT proposes as output a list of multi-
word terms ranked from the most representa-
tive of the corpus using log-likelihood estima-
tion (Dunning, 1993) and their variations in the
corpus. It also shows the semantic relation be-
tween multi-word terms. The example of the
output is given in Figure 3. A base term, for
example area protetto (?protected area?) is put
together with its syntactic variations ?area nat-
urale protetto (?natural protected area?) and area
marino protetto (?marine protected area?). We
can rewrite them as Hyperonomy (area natu-
rale protetto) = area protetto? or Hyperonomy
(area marino protetto) = area protetto because
ACABIT identifies that area protetto is a hyper-
nym of area naturale protetto and area marino
protetto as <MODIF>ied terms of <BASE>
terms . Likewise, a base term prodotto bio-
logico (?organic product?) has its syntactic varia-
tion: internal modification such as prodotto non
biologico (?non-organic product?), prodotto ali-
mentare non biologico (?non-organic alimentary
product?), and prodotto ittico biologico (?organic
fishing product?), and coordination like prodotto
biologico e non biologico (?organic and non-
organic product?). Moreover, there are Antonym
relation described as LINK type="Neg" be-
tween the base terms and some of its syntactic
variations such as prodotto non biologico and
prodotto alimentare non biologico. Note that
output of ACABIT in Figure 3 only contains
canonical forms of multi-word terms.
2.4 Experiments
Creation of domain specific corpora: For our
experiments we crawl two domain corpora of
?natural area? domain which consists of 17,291
sentences and 543,790 tokens from Gli E-
Quaderni9 and 47,887 sentences and 1,857,914
tokens from Parchi10. We also crawl in the Inter-
net to create the corpus of ?organic agriculture?
which consists of 5,553 sentences and 150,246
tokens from National legislations and European
legislations for organic agriculture11.
Automatic evaluation: Table 1 shows the statis-
tics of experimental results from each domain.
Since our domain corpora are mutually related,
we count the common multi-word terms and
there are 600 unique terms (base terms + vari-
ations) shared in both corpora. This is 18.74%
of the number of terms in ?organic agriculture?.
Figure 4 shows example of these common terms.
2.5 Current advancement
Till now, we reimplement only stat for multi-
ple languages. To conceptually struture them, we
still borrow tri of the previous ACABIT. We
have not implemented yet full features of stat
for Italian neither because of the lack of morpho-
syntactic rules.
For example, the preposition inside of the term
of [Noun1 di Noun2] structure might be equiva-
lent to a prefix-added Noun2 such as deteriora-
mento dopo la raccolta (?rot after harvest?) vs.
deterioramento post-raccolta (?post-harvesting
rot?). Likewise, the morphological derivation
9http://www.parks.it/ilgiornaledei
parchi/e-quaderni-federparchi.html
10http://www.parks.it/federparchi
/rivista/
11http://www.sinab.it/index.php?mod
=normative politiche&smod=comunitarie
&m2id=189&navId=196 and http://www.sinab.
it/index.php?mod=normative politiche
&smod=nazionali&m2id=189&navId=197,
respectively.
51
<?xml version="1.0" encoding="UTF-8"?>
<CORPUS>
<RECORD>
<INFO>00/CAR/00 -/- 0001800/SBC/0001800</INFO>
<TITLE> </TITLE>
<AB>
<PH NB="0"> La/DTN:_:s/la presente/ADJ:_:p/presente Ricerca/SBP:_:s/Ricerca
?e/SYM/?e frutto/SBC:_:s/frutto di/PREP/di un/DTN:_:s/un lavoro/SBC:_:s/lavoro
realizzato/ADJ2PAR:_:s/realizzare da/PREP/da una/DTN:_:s/una
pluralit?a/ADJ:_:s/pluralit?a di/PREP/di soggetti/SBC:_:p/soggetto -/SYM/-
pubblici/ADJ:_:p/pubblico ,/, privati/ADJ:_:p/privato ,/, del/DTN:_:s/del
mondo/SBC:_:s/mondo della/DTN:_:s/della ricerca/SBC:_:s/ricerca e/COO/e
dell?/DTN:_:s/dell? associazionismo/SBC:_:s/associazionismo -/SYM/-
sul/DTN:_:s/sul tema/SBC:_:s/tema agricoltura/SBC:_:s/agricoltura ,/,
ambiente/SBC:_:p/ambiente ,/, aree/SBC:_:p/area protette/ADJ:_:p/protetto ,/,
occupazione/SBC:_:p/occupazione ./.
</PH>
...
</AB>
</RECORD>
<RECORD>
...
</RECORD>
</CORPUS>
Figure 1: Example of the input of ACABIT
<!ELEMENT CORPUS (RECORD)*>
<!ELEMENT RECORD (DATE?, TITLE?, INFO?, AB)>
<!ELEMENT DATE (#PCDATA)>
<!ELEMENT INFO (#PCDATA)>
<!ELEMENT TITLE (#PCDATA)>
<!ELEMENT AB (PH)*>
<!ELEMENT PH (#PCDATA)>
<!ATTLIST PH NB CDATA #IMPLIED>
Figure 2: DTD for the input format of ACABIT
Domain Total # of Unique # of terms Unique # of terms
extracted (base terms + variations) (base terms + variations)
multi-word terms without hapax
?Natural Area? 34,665 21,119 (16,182+4,937) 4,131 (3,724+407)
120,633 63,244 (46,421+16,823) 12,674 (11,481+1,193)
?Organic Agriculture? 10,071 3,201 (2,509+692) 1,737 (1,431+306)
Table 1: Experimental results
52
<?xml version="1.0" encoding="UTF-8"?>
<LISTCAND>
...
<SETCAND new_ident="3" loglike="4839.794" freq="183">
<LINK type="Neg" old_ident1="3" old_ident2="3_0"></LINK>
<LINK type="Neg" old_ident1="3" old_ident2="3_1"></LINK>
<CAND old_ident="3_0">
<NA freq="38">
<MODIF> <TERM> prodotto non biologico </TERM>
</MODIF>
</NA>
</CAND>
<CAND old_ident="3_1">
<NA freq="4">
<MODIF> <TERM> prodotto alimentare non biologico </TERM>
</MODIF>
</NA>
</CAND>
<CAND old_ident="3">
<NA freq="2">
<COORD> <TERM> prodotto biologico e non biologico </TERM>
</COORD>
</NA>
<NA freq="1">
<MODIF> <TERM> prodotto ittico biologico </TERM>
</MODIF>
</NA>
<NA freq="138">
<BASE> <TERM> prodotto biologico </TERM>
</BASE>
</NA>
</CAND>
</SETCAND>
...
<SETCAND new_ident="6" loglike="6757.769" freq="260">
<CAND old_ident="6">
<NA freq="234">
<BASE> <TERM> area protetto </TERM>
</BASE>
</NA>
<NA freq="23">
<MODIF> <TERM> area naturale protetto </TERM>
</MODIF>
</NA>
<NA freq="3">
<MODIF> <TERM> area marino protetto </TERM>
</MODIF>
</NA>
</CAND>
</SETCAND>
<SETCAND new_ident="881" loglike="1855.26" freq="39">
<CAND old_ident="881">
<NA freq="39">
<BASE> <TERM> pratica agricolo </TERM>
</BASE>
</NA>
</CAND>
</SETCAND>
...
</LISTCAND>
Figure 3: Example of the output
53
attivita? economiche sostenibili (?economical sustainable activity?)
conservazione del paesaggio (?landscape preservation?)
danno ambientale (?environmental damage?)
elemento naturalistico (?naturalistic element?)
equilibrio naturale (?natural equilibrium?)
denominazione d?origine protetta (?protected origin denomination?)
denominazione d?origine controllata (?controlled origin denomination?)
Figure 4: Example of common terms shared in both ?natural area? and ?organic agriculture?
of Noun2 in [Noun1 di Noun2] structure might
imply a relational adjective such as acidita` del
sangue (?acidity of the blood?) vs. acidita` san-
guigna (?blood acidity?). Figure 5 shows exam-
ples of rules of morpho-syntatic variations be-
tween noun and adjectival endings for Italian,
which they are independently provided as ex-
ternal properties file for Italian. In Figure 5,
endings -zione (nominal) and -tivo (adjec-
tival) mean that if there are adjective ended with
-tivo like affermativo, the system searches for
the morphological derivation of a noun ended
with -zione like affermazione and put them
together. Only partial rules of morpho-syntatic
variations for Italian are presently integrated. We
try to find the exhaustive list in near future.
3 Discussion, Conclusion and Future
Work
In general, manual retrieval and validation of
terms is labor intensive and time consuming.
The automatic or semi-automatic methods which
works on text in order to detect single or multi-
word terms relevant to a subject field is referred
to as term extraction. Term extraction produces
the raw material for terminology databases. It
is a process which is likely to produce signifi-
cant benefits in terms individuation. The reasons
which justify term extractions are:
1. building glossaries, thesauri, terminologi-
cal dictionaries, and knowledge bases; au-
tomatic indexing; machine translation; and
corpus analysis rapidly.
2. Indexing to automatize information re-
trieval or document retrieval.
3. Finding neologism and new concepts.
Term extraction systems are usually catego-
rized into two groups. The first group is repre-
sented by the linguistically-based or rule-based
approaches use linguistic information such as
POS and chunk information to detect stop words
and to select candidate terms to predefined syn-
tactic patterns. The second group is represented
by the statistical corpus-based approaches se-
lect n-gram sequences as candidate terms. The
terms are selected by applying statistical mea-
sures. Recently, these two approach are com-
bined.
We implement ACABIT for Italian, which
uses the combined method to extract multi-word
terms and structure them automatically. We in-
troduce base term structures and their linguistic
variation such as graphical, inflexional, and shal-
low syntactic variations. We also consider the
modification of the structure of base terms such
as internal modification using adjective and co-
ordinate variations. We evaluate on two domain
specific corpora mutually related ?natural area?
and ?organic agriculture? to extract multi-words
terms and we find 600 unique terms shared in
both copora. This paper is based on our efforts
on automatic multi-word terms extraction and its
conceptual structure for multiple languages and
this is a case study for Italian language. For
the moment, we reimplement universal stat for
major Romance languages. Most of previous
work on extracting terms, especially for multiple
languages are focusing on single-word terms and
they are also often based on statistical approach
with simple morphological patterns, for exam-
ple Bernhard (2006), and Velupillai and Dalianis
(2008).
54
Nominal ending Adjectival ending Examples
-zione -tivo affermazione (?affirmation?) / affermativo (?affirmative?)
-zione -ante comunicazione (?communication?) / comunicante (?communicable?)
-logia -metrico ecologia (?ecology?) / econometrico (?econometric?)
-gia -gico enologia (?enology?) / enologico (?enologic?)
-a -ante cura (?treat?) / curante (?treating?)
- -bile cura (?treat?) / curabile (?treatable?)
-ia -peutico terapia (?therapy?) / terapeutico (?therapeutic?)
- -le vita (?life?) / vitale (?vital?)
- -tico acqua (?water?) / acquatico (?aquatic?)
Figure 5: Example of rules of morpho-syntatic variations (noun-adjective)
Since this work is still on-going, we con-
sider only Hyperonomy relations as the con-
ceptual relation where a relative adjective mod-
ifies inside of the base term with [Noun1 Adj]
or [Noun1 di Noun2] structures. We also con-
sider Antonym only with negative adverbs like
non. There are still Antonym (e.g. solubilita`
micellare (?micellar solubilization?) vs. insolu-
bilita` micellare (?micellar insolubilisation?)), Set
of (e.g. piuma d?anatra (?duck feather?) vs. pi-
umaggio dell?anatra (?duck feathers?)), Result
(e.g. filettaggio del salmone (?salmon filleting?)
vs. filetto di salmone (?salmon fillet?)) rela-
tionships. ACABIT for French detects concep-
tual relations by using morphological conflating
which implements stripping-recording morpho-
logical rules. We are planning to add these con-
ceptual relationships in ACABIT for Italian in
near future.
Acknowledgment
The authors would like to thank Be?atrice Daille
who kindly provide to us with ACABIT, for her
valuable remarks on an earlier version of this pa-
per. We also thank the four anonymous reviewer
for their constructive comments.
References
Agbago, Akakpo and Caroline Barrie`re. 2005. Cor-
pus Construction for Terminology. Corpus Lin-
guistics 2005. Birmingham, United Kingdom,
July 14-17, 2005.
Bernhard, Delphine. 2006. Multilingual Term
Extraction from Domain-specific Corpora Using
Morphological Structure. In 11th Conference of
the European Chapter of the Association for Com-
putational Linguistics. Trento, Italy, April 3-7,
2006.
Collet, Tanja. 2000. La re?duction des unite?s ter-
minologiques complexes de type syntagmatique.
Ph.D. Dissertation. Universite? de Montre?al.
Daille, Be?atrice. 2002. De?couvertes linguistiques en
corpus. Habilitation a` diriger des recherches. Uni-
versite? de Nantes.
Daille, Be?atrice. 2003. Conceptual structuring
through term variations. In Proceedings of the
ACL 2003 Workshop on Multiword Expressions:
Analysis, Acquisition and Treatment. Sapporo,
Japan. July 7-12, 2003.
Dunning, Ted. 1993. Accurate methods for the
statistics of surprise and coincidence. Computa-
tional Linguistics, 19(1):61-74.
L?Homme, Marie-Claude. 2004. La terminolo-
gie : principes et techniques, Les Presses de
l?Universite? de Montre?al.
Velupillai and Dalianis (2008).
Velupillai, Sumithra and Hercules Dalianis. 2008.
Automatic Construction of Domain-specific Dic-
tionaries on Sparse Parallel Corpora in the Nordic
Languages. In Proceedings of the workshop on
Multi-source Multilingual Information Extraction
and Summarization. Manchester, United King-
dom. August 23, 2008.
Williams, Geoffrey Clive. 2003. From mean-
ing to words and back: Corpus linguistics
and specialised lexicography. ASp 39-40.
http://asp.revues.org/1320.
55
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 78?88,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Korean Treebank Transformation for Parser Training
DongHyun Choi
Dept. of Computer Science
KAIST
Korea
cdh4696@world.kaist.ac.kr
Jungyeul Park
Les Editions
an Amzer Vak
France
park@amzer-vak.fr
Key-Sun Choi
Dept. of Computer Science
KAIST
Korea
kschoi@cs.kaist.ac.kr
Abstract
Korean is a morphologically rich language in
which grammatical functions are marked by
inflections and affixes, and they can indicate
grammatical relations such as subject, object,
predicate, etc. A Korean sentence could be
thought as a sequence of eojeols. An eo-
jeol is a word or its variant word form ag-
glutinated with grammatical affixes, and eo-
jeols are separated by white space as in En-
glish written texts. Korean treebanks (Choi
et al, 1994; Han et al, 2002; Korean Lan-
guage Institute, 2012) use eojeol as their fun-
damental unit of analysis, thus representing
an eojeol as a prepreterminal phrase inside
the constituent tree. This eojeol-based an-
notating schema introduces various complex-
ity to train the parser, for example an en-
tity represented by a sequence of nouns will
be annotated as two or more different noun
phrases, depending on the number of spaces
used. In this paper, we propose methods to
transform eojeol-based Korean treebanks into
entity-based Korean treebanks. The methods
are applied to Sejong treebank, which is the
largest constituent treebank in Korean, and the
transformed treebank is used to train and test
various probabilistic CFG parsers. The experi-
mental result shows that the proposed transfor-
mation methods reduce ambiguity in the train-
ing corpus, increasing the overall F1 score up
to about 9 %.
1 Introduction
The result of syntactic parsing is useful for many
NLP applications, such as named entity recogni-
tion (Finkel and Manning, 2009), semantic role la-
beling (Gildea and Jurafsky, 2002), or sentimental
analysis (Nasukawa and Yi, 2003). Currently most
of the state-of-the-art constituent parsers take statis-
tical parsing approach (Klein and Manning, 2003;
Bikel, 2004; Petrov and Klein, 2007), which use
manually annotated syntactic trees to train the prob-
abilistic models of each consituents.
Even though there exist manually annotated Ko-
rean treebank corpora such as Sejong Treebank (Ko-
rean Language Institute, 2012), very few research
projects about the Korean parser, especially using
phrase structure grammars have been conducted. In
this paper, we aim to transform the treebank so that it
could be better used as training data for the already-
existing English constituent parsers.
Most of Korean treebank corpora use eojeols as
their fundamental unit of analysis. An eojeol is
a word or its variant word form agglutinated with
grammatical affixes, and eojeols are separated by
white space as in English written texts (Choi et al,
2011). Figure 1 is one of the example constituent
tree from the Sejong Treebank. As can be observed,
an eojeol is always determined as a prepretermi-
nal phrase 1. But this kind of bracketing guideline
could cause ambiguities to the existing algorithms
for parsing English, because: (1) English does not
have the concept of ?eojeol?, and (2) an eojeol
can contain two or more morphemes with different
grammatical roles. For example, Korean case par-
1A node is a prepreterminal if all the children of this node
are preterminals (Part-Of-Speech tags such as NNP and JKG).
Preterminal is defined to be a node with one child which is itself
a leaf (Damljanovic et al, 2010).
78
Figure 1: An example constituent tree and morphological analysis result from the Sejong treebank
ticles (?josa?) are normally written inside the same
eojeol with their argument nouns, but the whole eo-
jeol is always considered as a prepreterminal noun
phrase in the Korean treebank, as can be seen in the
eojeol Ungaro-GA. Considering that the case parti-
cles in Korean play important role in determining
the syntactic structure of a sentence, this could cause
loss of information during the training phase. More-
over, Emanuel Ungaro is considered as two different
noun phrases, because they simply belong to the two
different eojeols (that is, a space exists between eo-
jeols Emanuel and Ungaro-GA).
In this paper, we propose methods to refine the
Sejong treebank which is currently the largest Ko-
rean treebank corpus. The methods are aimed at de-
creasing the ambiguities during the training phase
of parsers, by separating phrases which are inte-
grated into the same prepreterminal phrase due to
the reason that they happen to be in the same eojeol,
and integrating phrases into the same prepretermi-
nal phrase which are separated because they hap-
pen to be in different eojeols. The refined datasets
are trained and tested against three state-of-the-art
parsers, and the evaluation results for each dataset
are reported.
In section 2, the work about Korean parsers are
briefly introduced. Sejong treebank is described
with more detailed explanation in section 3, while
the methods to transform the treebank are introduced
in section 4. In section 5 the evaluation results of the
transformed treebank using the three existing state-
of-the-art parsers are introduced with an error report,
and we discuss conclusions in section 6.
2 Related Work
There were some trials to build Korean constituent
parsers, but due to the lack of appropriate corpus
those trials were not able to acheive a good re-
sult. (Smith and Smith, 2004) tried to build a Ko-
rean parser by bilingual approach with English, and
achieved labeled precision/recall around 40 % for
Korean. More recently, (Park, 2006) tried to extract
tree adjoining grammars from the Sejong treebank,
and (Oh et al, 2011) build a system to predict a
phrase tag for each eojeol.
Due to the partial free word order and case pari-
cles which can decide the grammatical roles of noun
phrases, there exist some works to build statistical
dependency parsers for Korean. (Chung, 2004) pre-
sented a dependency parsing model using surface
contextual model. (Choi and Palmer, 2011) con-
verted the Sejong treebank into the dependency tree-
bank, and applied the SVM algorithm to learn the
dependency model.
79
NNG General noun IC Interjection JKQ Quotational CP XSV Verb DS
NNP Proper noun MM Adnoun JX Auxiliary PR XSA Adjective DS
NNB Bound noun MAG General adverb JC Conjunctive PR XR Base morpheme
NP Pronoun MAJ Conjunctive adverbEP Prefinal EM SN Number
NR Numeral JKS Subjective CP EF Final EM SL Foreign word
VV Verb JKC Complemental CP EC Conjunctive EM SH Chinese word
VA Adjective JKG Adnomial CP ETN Nominalizing EM NF Noun-like word
VX Auxiliary predicateJKO Objective CP ETM Adnominalizing EMNV Verb-like word
VCP Copula JKB Adverbial CP XPN Noun prefix NA Unknown word
VCN Negation adjective JKV Vocative CP XSN Noun DS SF,SP,SS,SE,SO,SW
Table 1: POS tags used in Sejong treebank (CP: case particle, EM: ending marker, DS: derivational suffix, PR: particle,
SF SP SS SE SO: different types of punctuations, SW: currency symbols and mathematical symbols. Table borrowed
from (Choi and Palmer, 2011))
Apart from the Sejong Treebank, there are few
other Korean treebanks available. The KAIST tree-
bank (Choi et al, 1994) contains constituent trees
about approximately 30K sentences from newspa-
pers, novels and textbooks. Also, the Penn Ko-
rean Treebank (Han et al, 2002) contains 15K
constituent trees constructed from the sentences of
newswire and military domains. The proposed
methods are evaluated using the Sejong treebank be-
cause it is the most recent and the largest Korean
treebank among those which is currently available.
3 Sejong Treebank
The Sejong treebank is the largest constituent
treebank in Korean. It contains approximately
45K manually-annotated constituent trees, and their
sources cover various domains including newspa-
pers, novels and cartoon texts. Figure 1 shows an
example of the Sejong constituent tree.
The tree consists of phrasal nodes and their func-
tional tags as described in table 2. Each eojeol
could contain one or more morphemes with different
POS tags (Table 1 shows the POS tagset). In most
cases, eojeols are determined by white spaces. As
stated in its bracketing guidelines, the Sejong tree-
bank uses eojeols as its fundamental unit of analy-
sis 2. This means that an eojeol is always treated as
one prepreterminal phrase. This could cause confu-
sions to the training system, because an eojeol could
contain many morphemes which have very different
2The bracketing guidelines could be requested from the Se-
jong project, but available only in Korean
grammatical roles, as can be seen in the example
of Ungaro-GA - word Ungaro is a noun, where the
nominative case particle GA suggests that this eojeol
is used as a subject.
Table 2 shows phrase tags and functional tags
used to construct the Sejong treebank. Some phrases
are annotated with functional tags to clarify their
grammatical role inside the sentence. There are
three special phrase tags beside those in table 2:
X indicates phrases containing only case particles
or ending markers, L and R indicate left and right
parenthesis.
Phrase-level tags Functional tags
S Sentence SBJ Subject
Q Quotative clause OBJ Object
NP Noun phrase CMP Complement
VP Verb phrase MOD Modifier
VNP Copula phrase AJT Adjunct
AP Adverb phrase CNJ Conjunctive
DP Adnoun phrase INT Vocative
IP Interjection phrasePRN parenthetical
Table 2: Phrase tags used in Sejong treebank.
4 Transforming Methods: from
Eojeol-based to Entity-based
In this section, we describe the methods to transform
the annotation schema of the Korean treebank from
eojeol-based to entity-based using the examples of
the Sejong treebank.
4.1 Method 1: POS Level Preprocessing
Before starting the actual transforming process, the
system first detects emails, phone numbers and dates
80
based on their unique POS patterns. If the system
detects a sequence of morphemes matching with one
of predefined POS patterns inside an eojeol, then it
groups those morphemes into one entity and tags it
as a noun. This procedure aims to reduce the ambi-
guity of the corpus by reducing many miscellaneous
mrophemes which in fact forms one phone num-
ber, email address or date information into one en-
tity. Figure 2 shows an example of an eojeol whose
five morphemes toghether represent one date, and its
transformation result.
Figure 2: Example of an eojeol containing date: five mor-
phemes are merged into one morpheme representing date.
Also, the morphemes representing chinese char-
acters (POS: SH) and other foreign characters (POS:
SL) are considered as nouns, since they are normally
used to rewrite Korean nouns that have their foreign
origin such as Sino-Korean nouns.
4.2 Method 2: Detecting NPs inside an Eojeol
Although an eojeol is considered to be one prepreter-
minal phrase as a whole, many eojeols contain sep-
arated noun components inside them. For exam-
ple, a noun phrase Ungaro-GA in Figure 3 con-
sists of a separated noun component Ungaro in it,
plus josa GA. The system separates noun compo-
nents from other endings and case particles, creates
a new phrase containing those words and tags it as
an NP. By doing so, the boundaries of the NP are
more clarified - before transforming prepreterminal
NPs could contain case particles and endings, but
after the transformation it is not possible. Also the
internal syntactic structures of phrases are revealed,
providing more information to the parser.
4.3 Method 3: Finding Arguments of Josa
In this step, the system tries to find out the actual ar-
gument of each josa. For example, in figure 4 the
Figure 3: Detecting NP inside an eojeol: Case of a verb
phrase
actual argument of the nominative josa GA is the
whole person name Emanuel Ungaro, not only Un-
garo. The system tries to find out the actual argu-
ment of each josa by using a rather simple heuristic:
1. Traverse the constituent parse tree in bottom-up, right-to-
left manner.
2. If a phrase node is NP, its parent is also NP, and it directly
dominates josa(s), then:
(a) Create a new NP.
(b) Attach the node to that NP, except the josa(s).
(c) Attach all the other children of the parent node to the
newly-created NP.
(d) Remove all the children of the parent, and attach the
new NP and remaining josa part to the parent node.
3. After the procedure ends, find and remove redundant NPs,
if exist.
Figure 4: Example of applying the transformation heuris-
tic
Method 3 is dependent on method 2, since method
2 first determines boundary of NPs which do not in-
clude any case particles.
4.4 Method 4: Integrating a Sequence of
Nouns into One NP
Some of entities represented as sequences of nouns
are considered as two or more separated noun
81
phrases since their components belong to the dif-
ferent eojeols. This could be problematic because
an entity could sometimes be written without any
whitespace between its component nouns. Figure 5
shows one of the case: person name Emanuel Un-
garo is considered as two separated NPs since there
exists a whitespace between a noun Emanual and a
noun Ungaro. In this step, we aim to solve this prob-
lem.
Figure 5: Integrating sequence of nouns representing one
entity into one prepreterminal noun phrase
The system finds out an NP which has two NP
children which dominates only the noun pretermi-
nal children. If the system finds such an NP, then it
removes NP children and attaches their children di-
rectly to the found NP. Figure 5 shows an application
example of the method.
This method is dependent on method 3, since this
method assumes that an NP with its parent also NP
does not have any case particles - which cannot be
hold if method 3 is not applied.
4.5 Method 5: Dealing with Noun
Conjunctions
The system tries to enumerate the noun conjunc-
tions, rather than expressing those conjunctions in
binary format. Current Sejong treebank expresses
noun conjunctions in binary format - that is, to ex-
press the constituent tree for noun conjunctions, the
nonterminal node has one NP child on its left which
contains information about the first item of the con-
junction, and the rest of conjunctions are expressed
on the right child. Figure 63 shows an example of
the Sejong constituent tree expressing the noun con-
junctions, and its transformed version.
3Mike-WA (CNJ) Speaker-GA (NOM) Jangchak-DOI-UH
IT-DA. (?Microphone and speaker are installed.?)
Figure 6: Enumerating Noun Conjunctions
By converting noun conjunctions into rather the
?enumerated? forms, two benefits could be gained:
first, the resultant constituent tree will resemble
more to the Penn-treebank constituent trees. Since
most of the existing English parsers are trained on
the Penn Treebank, we can expect that the enumer-
ated form of conjunctions will more ?fit? to those
parsers. Second, the conjunctions are expressed in
much more explicit format, so the human users can
more easily understand the conjunctive structures in-
side the constituent trees.
4.6 Method 6: Re-tagging Phrase Tags
In this step, the system re-tags some of phrase tags
to clarify their types and to decrease training ambi-
guities. For example, a noun phrase with and with-
out case particles should be distinguished. The sys-
tem re-tags those noun phrases with case particles to
JSP 4 to distinguish them from the pure noun phrases
which consist of only nouns. Also, VP-MOD and
VNP-MOD are re-tagged to DP, since they have very
similar lexical formats with existing DPs. NP-MOD
is converted into JSP-MOD - most of them consist
of a NP with josa JKG, forming possesive cases. S-
MOD remains as S-MOD if its head is JSP-MOD:
4It stands for a ?Josa Phrase?.
82
otherwise, it is also re-tagged to a DP. Figure 75
shows a re-tagging example.
Figure 7: Example of retagging phrase tags: VP-MOD to
DP, NP-MOD to JSP-MOD, and NP-SBJ to JSP-SBJ.
5 Evaluations
In this section, several experiment results using the
standard F1 metric (2PR/(P + R)) are introduced
to show the effect of each transforming method, and
the most frequently shown error cases are explained.
5.1 Experiments using the Sejong Treebank
The proposed transformation methods are applied to
the Sejong treebank, and the converted treebanks are
used to train and test three different well-known sta-
tistical parsers, namely Stanford parser (Klein and
Manning, 2003), Bikel-Collins parser (Bikel, 2012)
and Berkeley parser (Petrov et al, 2006). To figure
out the effect of each method, all six methods are
sequentially applied one by one, and each version of
the treebank is used to train and test each parser. The
baseline treebank is the original Sejong treebank
without any transformations. For the Korean head
word extraction which will be used during parsing,
the head percolation rule of (Choi and Palmer, 2011)
is adapted. According to that paper, particles and
endings were the most useful morphemes to deter-
mine dependencies between eojeols. Based on the
observation, their rules are changed so that they give
the best priorities on those morphemes. We use
the preprocessing method described in (Park, 2006)
for training trees. It replaces symboles with Penn-
Treebank-like tags and corrects wrong morpheme
5See Figure 1 for its transcription and translation.
boundary marks within the eojeol. Methods are ap-
plied cumulatively; for example, symbol ?M 1-6?
means the version of a treebank to which method
1, 2, 3, 4, 5 and 6 are applied cumulatively.6
System Corpus P R F1
Stan.
Baseline 67.88% 61.77% 64.69%
M 1 68.34% 61.93% 64.98%
M 1-2 71.78% 67.50% 69.58%
M 1-3 71.28% 67.91% 69.56%
M 1-4 71.06% 67.08% 69.01%
M 1-5 71.35% 67.27% 69.26%
M 1-6 75.85% 72.07% 73.92%
Bikel.
Baseline 74.81% 70.39% 72.53%
M 1 74.87% 70.45% 72.59%
M 1-2 77.05% 73.84% 75.41%
M 1-3 75.87% 72.88% 74.34%
M 1-4 75.33% 72.10% 73.68%
M 1-5 75.29% 72.18% 73.70%
M 1-6 73.70% 71.05% 72.35%
Berk.
Baseline 75.25% 72.72% 73.96%
M 1 74.54% 71.97% 73.23%
M 1-2 77.27% 75.05% 76.14%
M 1-3 75.60% 73.19% 74.38%
M 1-4 75.69% 73.32% 74.49%
M 1-5 76.53% 74.30% 75.40%
M 1-6 78.60% 76.03% 77.29%
Table 3: Evaluation results of parsers, with various trans-
formed versions of the Sejong treebank.
Table 3 shows the experimental results on each
version of the treebanks using each parser. Since
the corpus covers various domains (i.e. the style of
sentences is not homogeneous.), we perform 10-fold
cross-validation for our experiments. Stan. rep-
resents Stanford parser, Bikel. represents Bikel-
Collins parser, and Berk. means Berkeley parser.
For the Berkeley parser, we set the number of itera-
tion as two for latent annotations. In this set of ex-
periments, only phrase tags are the target of training
and testing, not including functional tags.
As can be observed from the evaluation result, the
performance is improved due to methods 2 and 6
are quite big compared to the effect of other four
6As pointed out by reviewers, we are planning the reversibil-
ity of transformations to be evaluated on the same trees for
meaning comparison.
83
System Corpus P R F1
Stan.
Baseline 71.48% 69.40% 70.43%
M 1 71.89% 69.75% 70.81%
M 1-2 75.90% 73.44% 74.65%
M 1-3 72.32% 69.76% 71.02%
M 1-4 72.37% 69.97% 71.16%
M 1-5 72.80% 70.28% 71.52%
M 1-6 72.32% 69.81% 71.05%
Bikel.
Baseline 69.65% 66.80% 68.19%
M 1 69.73% 66.97% 68.32%
M 1-2 74.33% 71.90% 73.09%
M 1-3 63.94% 64.57% 64.25%
M 1-4 63.95% 65.04% 64.49%
M 1-5 64.09% 65.05% 64.57%
M 1-6 62.94% 64.16% 63.54%
Berk.
Baseline 76.82% 75.28% 76.04%
M 1 76.73% 75.06% 75.89%
M 1-2 79.59% 77.91% 78.74%
M 1-3 75.24% 72.16% 73.67%
M 1-4 75.02% 73.01% 74.00%
M 1-5 75.58% 73.61% 74.58%
M 1-6 74.37% 71.93% 73.13%
Table 4: Evaluation results of parsers, with phrase tags
and functional tags together as learning target.
methods. Especially, the performance increase due
to the method 6 strongly suggests that Sejong phrase
tagsets are not enough to distinguish the types of
phrases effectively. Except those two methods,
only the method 5 increases the overall performance
slightly, and methods 1, 3 and 4 do not have any
significant effect on the performance or even some-
times decrease the overall performance.
Although the usage of functional tags is different
from that of phrase tags, the Sejong treebank has
a very rich functional tag set. Considering the re-
sults of the previous experiments, it is highly likely
that some of phrasal information is encoded into the
functional tags. To prove that, another set of experi-
ments is carried out. In this time, parsers are trained
not only on phrase tags but also on functional tags.
Table 4 shows the evaluation results.
As can be observed, by keeping functional tags
to train and test parsers, the baseline performance
increases 3 to 6 % for the Stanford and Berkeley
parsers. Only the performance of the Bikel parser
is decreased - it is highly possible that the parser
fails to find out the appropriate head word for each
possible tag, because the number of possible tags is
increased greatly by using the functional tags along
with the phrase tags.
In both set of experiments, the method 3 decreases
the overall performance. This strongly suggests that
finding the actual argument of josa directly is quite a
challenging work. The performance drop is consid-
ered mainly because the branching problem at the
higher level of the constituent tree is counted twice
due to the josa.
5.2 Experiments using the Penn Korean
Treebank
To show the effect of the transformation methods
more clearly, the Penn Korean Treebank (Han et al,
2002) is used as another treebank for experimen-
tation: (Chung et al, 2010) describes about major
difficulties of parsing Penn Korean Treebank. The
same three parsers are trained and tested using the
treebank. Due to the different annotation guidelines
and different tagsets, transformation methods 1, 5
and 6 cannot be applied on the treebank. Thus, only
method 2, 3 and 4 are used to transform the treebank.
Table 5 shows the evaluation results.
System Corpus P R F1
Stan.
Baseline 82.84% 80.28% 81.54%
M 2 85.29% 83.25% 84.26%
M 2-3 84.52% 82.71% 83.61%
M 2-4 84.52% 82.92% 83.72%
Bikel.
Baseline 81.49% 78.20% 79.81%
M 2 75.82% 74.47% 75.13%
M 2-3 73.50% 69.66% 71.53%
M 2-4 73.45% 69.66% 71.51%
Berk.
Baseline 85.11% 81.90% 83.47%
M 2 83.40% 81.04% 82.20%
M 2-3 82.36% 80.52% 81.43%
M 2-4 82.97% 81.28% 82.12%
Table 5: Evaluation on Penn Korean Treebank.
The overall performance of training the Penn Ko-
rean treebank is higher than that of the Sejong tree-
bank. There could be two possible explanations.
First one is, since the Penn Korean treebank tries
to follow English Penn treebank guidelines as much
84
as possible, thus annotation guidelines of the Ko-
rean Penn treebank could be much ?familiar? to the
parsers than that of the Sejong treebank. The second
explanation is, since the domain of the Penn Korean
treebank is much more restricted than that of the Se-
jong treebank, the system could be trained for the
specific domain. The best performance was gained
with the Stanford parser, with the treebank trans-
formed by method 2. Actually, (Chung et al, 2010)
also investigated parsing accuracy on the Penn Ko-
rean treebank; the direct comparison could be very
difficult because parsing criteria is different.
5.3 Error Analysis
In this section, some of the parsing error cases are
reported. Berkeley parser trained with the Sejong
treebank is used for error analysis. Both phrase tags
and functional tags are used to train and test the sys-
tem.
5.3.1 Locating Approximate Positions of
Errors
As the first step to analyze the errors, we tried to
figure out at which points of the constituent tree er-
rors frequently occur ? do the errors mainly occur at
the bottom of the trees? Or at the top of the trees?
If we can figure out approximate locations of errors,
then the types of errors could be predicted.
Figure 8: Example of assigning levels to each phrasal
node.
To define the level of each nonterminal node of
the constituent tree, the following rules are used:
? The level of prepreterminal node is 0.
? The levels of other phrasal nodes are defined
as: the maximal level of their children + 1.
? Once the levels of all the phrasal nodes are cal-
culated, normalize the levels so that they have
the values between 0 and 1.
Figure 8 shows an example of constituent tree
with levels assigned to its phrasal nodes. All the
prepreterminal nodes have level value 0, and the top-
most node has level 1.
Figure 9: Performance of the system on each level of the
parse tree
Once the levels are assigned to each constituent
tree, only those constituents with levels larger than
or equal to the predefined threshold ? are used to
evaluate the system. ? are increased from 0 to 1 with
value 0.01. Higher ? value means that the system is
evaluated only for those constituents positioned at
the top level of the constituent tree.
Figure 9 shows the evaluation results. X-axis rep-
resents the value of ?, and Y-axis represents the F1-
score. As can be observed, most of the errors oc-
cur at the mid-level of the constituent trees. Also,
the effects of some methods are explicitly shown
on the graph. For example, method 2 greatly in-
creases the performance at low level of the con-
stituent tree, suggesting improved consistency in de-
temining prepreterminal NP nodes. Also, it is shown
that the proposed methods does not affect the perfor-
mance of mid-level and top-level constituent deci-
sions - this suggests that the future works should be
more focused on providing more information about
those mid-level decision to the treebank annotation.
85
Figure 10: Example of NP boundary detection error. Part
of parse tree as well as name of the enumerated products
are omitted to more clearly show the example itself.
5.3.2 Frequent Error Cases
In this section, four major parsing error cases are
described.
Detecting Boundaries of NP. Although the
method 4 tries to find and gather the sequence of
nouns which actually belong to one NP, it misses
some of the cases. Figure 10 shows such example.
Some parts of the tree are omitted using the notation
?...? to show the example more simply. Although it
is counted as the parser error, the result of the parser
is more likely to be an answer - the number of those
products is 8, not their action. The Sejong treebank
tree is annotated in that way because the number ?8?
and bound noun Gae (?unit?), representing as units,
are separated by a space. To detect such kind of sep-
arated NPs and transform them into one NP will be
our next task.
Finding an AppropriateModifee. Some phrases
modifying other phrases were failed to find their ap-
propriate modifees. Figure 11 shows an example of
such kind of error case.
Detecting an Appropriate Subject of the Sen-
tence. This case frequently occurs when a sentence
is quotated inside the other sentence. In this case,
the subject of quotated sentence is often considered
as the subject of the whole sentence, because the
quotated sentences in Korean are usually first stated
Figure 11: Example of a phrase (JSP-AJT) which failed
to find its right modifee.
and then the subject of the whole sentence shows up.
Figure 12 shows an example of the erroneously de-
tected subject.
The Wrongly-tagged Topmost Node. Some of
Sejong treebank trees have phrases which are not
tagged as S as their topmost nodes. This could cause
confusion during the training. Figure 13 shows such
example.
6 Conclusion and Future Work
Although there exist some manually-annotated
large-enough constituent treebanks such as Sejong
treebank, it was hard to apply the algorithms for En-
glish parsers to Korean treebanks, because they were
annotated in eojeol-based scheme, which concept
does not exist in English. In this paper, we showed
the possibility of acquiring good training and testing
results with the existing parsers trained using the ex-
isting Korean treebanks, if it undergoes some simple
transforming procedures. The error analysis result
shows that, indeed the proposed method improves
the performance of parser at the lower level of con-
stituent tree.
86
Figure 12: Example of a wrongly-detected subject.
Although there exists a performance gain due to
the transforming methods, there are still many gaps
for improvement. The evaluation results and er-
ror analysis results suggests the need to define the
phrase tagset of Sejong treebank in more detail.
Also, the transforming methods themselves are not
perfect yet - we believe still they could be improved
more to increase consistency of the resultant tree-
banks.
We will continuously develop our transforming
methods to improve the parsing result. Furthermore,
we are planning to investigate methods to determine
the appropriate ?detailedness? of phrase tag set, so
that there are no missing information due to too
small number of tags as well as no confusion due
to too many tags.
Acknowledgement
This research was supported by Basic Science
Research Program through the National Research
Foundation of Korea (NRF) funded by the Ministry
of Education, Science and Technology (No. 2011-
Figure 13: Example of the wrongly-tagged topmost node.
Some trees in the treebank have Non-S topmost phrase
nodes.
0026718)
References
Dan Bikel. 2004. On the Parameter Space of Generative
Lexicalized Statistical Parsing Models. Ph.D. thesis,
University of Pennsylvania.
Dan Bikel. 2012. Bikel parser. http://www.cis.
upenn.edu/?dbikel/software.html.
Jinho D. Choi and Martha Palmer. 2011. Statistical de-
pendency parsing in Korean: From corpus generation
to automatic parsing. In The Second Workshop on Sta-
tistical Parsing of Morphologically Rich Languages,
pages 1?11.
Key-Sun Choi, Young S. Han, Young G. Han, and Oh W.
Kwon. 1994. KAIST tree bank project for Korean:
Present and future development. In Proceedings of
the International Workshop on Sharable Natural Lan-
guage Resources, pages 7?14.
Key-Sun Choi, Isahara Hitoshi, and Maosong Sun. 2011.
Language resource management ? word segmentation
of written texts ? part 2: Word segmentation for Chi-
nese, Japanese and Korean. In ISO 24614-2. ISO.
Tagyoung Chung, Matt Post, and Daniel Gildea. 2010.
Factors affecting the accuracy of korean parsing. In
Proceedings of the NAACL HLT 2010 First Workshop
on Statistical Parsing of Morphologically-Rich Lan-
guages, pages 49?57, Los Angeles, CA, USA, June.
Association for Computational Linguistics.
87
Hoojung Chung. 2004. Statistical Korean Dependency
Parsing Model based on the Surface Contextual Infor-
mation. Ph.D. thesis, Korea University.
Danica Damljanovic, Milan Agatonovic, and Hamish
Cunningham. 2010. Identification of the question fo-
cus: Combining syntactic analysis and ontology-based
lookup through the user interaction. In Proceedings of
7th Language Resources and Evaluation Conference
(LREC), pages 361?368.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In NAACL
?09 Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics, pages 326?334.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic la-
beling of semantic roles. Computational Linguistics,
28(3):245?288.
Chung-Hye Han, Na-Rae Han, Eon-Suk Ko, Heejong Yi,
and Martha Palmer. 2002. Penn Korean treebank:
Development and evaluation. In Proceedings of the
16th Pacific Asia Conference on Language, Informa-
tion and Computation.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the 41st
Meeting of the Association for Computational Linguis-
tics, pages 423?430.
Korean Language Institute. 2012. Sejong treebank.
http://www.sejong.or.kr.
Tetsuya Nasukawa and Jeonghee Yi. 2003. Sentiment
analysis: capturing favorability using natural language
processing. In Proceedings of the 2nd international
conference on Knowledge capture, pages 70?77.
Jin Young Oh, Yo-Sub Han, Jungyeul Park, and Jeong-
Won Cha. 2011. Predicting phrase-level tags using
entropy inspired discriminative models. In 2011 Inter-
national Conference on Information Science and Ap-
plications (ICISA), pages 1?5.
Jungyeul Park. 2006. Extraction of tree adjoining gram-
mars from a treebank for Korean. In Proceedings of
the 21st International Conference on computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics: Student Research
Workshop, pages 73?78.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Human Language Tech-
nologies 2007: The Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics; Proceedings of the Main Conference, pages
404?411, Rochester, New York, April. Association for
Computational Linguistics.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In Proceedings of the
COLING-ACL 2006, pages 433?440.
David A. Smith and Noah A. Smith. 2004. Bilingual
parsing with factored estimation: Using English to
parse Korean. In Proceedings of the EMNLP, pages
49?56.
88
