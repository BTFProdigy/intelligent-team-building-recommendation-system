PolyphraZ : a tool for the management of parallel corpora
Najeh HAJLAOUI
GETA, CLIPS, IMAG
Universit? Joseph Fourier, BP 53
38041 Grenoble, France
Najeh.Hajlaoui@imag.fr
Christian BOITET
GETA, CLIPS, IMAG
Universit? Joseph Fourier, BP 53
38041 Grenoble, France
Christian.Boitet@imag.fr
Abstract
The PolyphraZ tool is being developed in the
framework of the TraCorpEx project
(Translation of Corpora of Examples), to
manage parallel multilingual corpora through
the web. Corpus files (monolingual or
multilingual) are firstly converted to a
standard coding (CXM.dtd, UTF8). Then, they
are assembled (CPXM.dtd) to visualize them
in parallel through the web. In a third stage,
they are put in a Multilingual Polyphraz
Memory (MPM). A "polyphrase" is a structure
containing an original sentence and various
proposals of equivalent sentences, in the same
and other languages. An MPM stores one or
more corpora of polyphrazes. The MPM part
of PolyphraZ has 3 main web interfaces. One
is a web-oriented translator workstation
(TWS), where suggestions or translations
come from the MPM itself, which functions as
its own translation memory, and from calls to
MT systems. Another serves to send sentences
to MT systems with appropriate parameters,
and to run various evaluation measures (NIST,
BLEU, and distance computations) in order to
propose to the translator a "best" proposal. A
third interface is planned for giving feedbacks
to the developers of the MT systems, in the
form of lists of unknown or wrongly translated
words, with suggestions for correct
translations, and of parallel presentation of
pairs of translations showing the "editing
work" to be done to get one from the other.
The first 2 stages are operational, and used for
experimentation and MT evaluation on the
CSTAR 5-lingual BTEC corpus and on the
Japanese-English Tanaka corpus used as a
source of examples in electronic dictionaries
(JDict, Papillon). A main goal of this effort is
to offer occasional and volunteer translators
and posteditors access to a free TWS and to
sharable translation memories put in the MPM
format.
1 Introduction
Due to Internet grow, the number of available
documents grows dramatically. There is a strategic
need for companies to produce and manage
information written in more than 30 languages
(HP, IBM, MS, Caterpillar). This requires
powerful tools to manage multilingual documents.
Current techniques for handling multilingual
documents use large-grained linking (at the level
of HTML pages), but don't allow fine-grained
synchronization (at paragraph or sentence level)
and don't permit bilingual or multilingual editing
through the Web.
The interest to synchronize at least at the level of
sentences is double:
? make it possible to use Machine Aided Human
Translation (MAHT) techniques, in particular
translation memories, for translating and
postediting multilingual documents.
? add UNL tags at sentence level to store the
translations as well as UNL hypergraphs
(anglosemantic interlingual representations),
from which raw (or rough!) translations into
other languages can be obtained from distant
"deconversion" servers.
Here, we are not concerned with the problem of
aligning parallel monolingual documents, or
realigning them after they have been modified, a
frequent need in the case of leaflets and booklets.
(Assimi,2000) proposed a tool to handle the non-
centralized management of the evolution of
multilingual parallel documents. We consider the
case, frequent in the industry, where documents are
managed centrally, even if they are distributed on
several sites. What happens in general is that they
are aligned at the level of large blocks, with one
file per block and language (fileXXX.en.htm,
fileXXX.fr.htm etc. for HTML pages).
What we propose is to align them at the level of
sentences, but of course not to have one file per
sentence. Rather, if there are N languages, for a
given "block" corresponding to some unit of
processing (e.g. visualization), we will have either
N monolingual sentence-aligned files, or 1
multilingual file. In both cases, sentences or place
holders for sentences will be linked to a MPM to
manage translation and postedition.
We began to build PolyphraZ in the context of
the TraCorpEx project (Translation of Corpora of
Examples). A more recent motivation is to extend
the BTEC corpus of CSTAR III (163000 sentences
in tourism) to French and Arabic, and to evaluate
various Chinese-English MT systems on it.
We will first present the data we start with, and
our goals in more detail. In a second part, we will
describe the architecture of PolyphraZ, starting
from scenarios of use and types of users. Lastly,
we will describe the current status of this work.
2 TraCorpEx and PolyphraZ
2.1 Context
The TraCorpEx project has several contexts: the
Papillon project (Papillon) of co-operative
construction of a large multilingual lexical base on
the Web, the C-STAR III project (C-STAR III) of
translation of spoken dialogues, a French and
Tunisian project (Hajlaoui, Boitet, 2003b), the
UNL project (UNL) of communication and
multilingual information system, and the PhD
research of the various participants in this project.
2.2 Current data and problems
We have initially 2 "parallel" corpora, structured
differently.
? The BTEC corpus of C-STAR is made of 5
sets of 163 files of 12K to 40K, each
containing 1000 sentences, in English,
Japanese (coded in EUC), Chinese and
Korean, for a total of 6.1 Mo per language.
? The TANAKA corpus (Japanese-English),
given to the Papillon project a few months
before the death of its author in 2002, is made
of 45 files for a total of 18.4 Mo. It contains
sentences of newspapers or teaching works of
NHK for the training of English by the
Japanese. Each file is bilingual.
We have also corpora from the UNL project,
where each document is a multilingual file
containing for each sentence its text in source
language, a UNL graph, the result of
deconversions in a certain number of languages,
and possibly their revisions, or direct manual
translations.
All these "parallel" corpora are aligned at the
level of sentences. As it would be interesting to
show correspondences at finer levels (syntagms,
chunks, words), we design PolyphraZ to later add
tools for subsential alignement such as the one
developed by Ch. Chenon for his Ph.D.
In other corpora, we may be obliged to go up to
the level of paragraphs, because sentences will not
be aligned perfectly. That will not be done
completely in PolyphraZ, but at the level of the
structure of the multilingual document itself: if 2
sentences are translated by 3, each of the 5
sentences will be in a different polyphrase, with
their individual translations, and there will be
another polyphrase, of "n-m" type, to contain the 2
complete segements.
The first problem we encounter with the
available parallel corpora it is that there is no tool
to visualize their contents at a glance, sentence by
sentence, nor to show the fine correspondences
between subsentential segments. In addition, in the
case of UNL documents, we cannot visualize at the
same time a sentences in several languages and its
corresponding UNL graph. Lastly, it is not possible
to see successive versions in parallel.
When it comes to evaluation, we can only see
the monolingual files, and associated statistical
measurements (NIST, BLEU...), but we can never
confront them with the real translations and make a
direct subjective evaluation.
2.3 Detailed objectives
The objectives of TraCorpEx project are as
follows.
2.3.1 Construction of a software platform
We want to build an environment, which
supports the import and the export of parallel
corpora, the preparation of the data for automatic
translators, the postedition (HAMT), the evaluation
(various feedbacks methods) and finally a
preparation of "feedbacks" to the developers of
used MT systems.
2.3.2 Addition of new languages
Starting from parallel corpora, we want to add
one or more languages (those of the Papillon
project for the Tanaka corpus, French and Arabic
for the BTEC corpus).
2.3.3 Evaluation of MT systems
 We also wish that the same platform makes it
possible to evaluate automatic translators with
automatic methods such as NIST, BLEU, PER, and
to use this possibility in CSTAR, to evaluate the
Chinese-English and Japanese-English translations.
To evaluate the results of various MT systems will
also enable us to determine "the best" (or less bad!)
translation, proposable to a contributor as a starting
point for revision.
We also want to test a hypothesis by the second
author: the quality of the translations could also be
evaluated using calculations of distances between
sentences and reverse translations.
2.3.4 Feedbacks to developers of MT systems
We also want to give feedbacks to the
developers of the systems used (unknown words,
badly translated sentences...), and a comparative
presentation between the various translation
systems.
 The whole of the objectives of this project led
us to propose interactive Web interfaces allowing
us to chooses, use, compare, publish machine
translations corresponding to several language
pairs, and to contribute to the improvement of the
results by sending feedbacks to the developers of
these systems.
2.4 The PolyphraZ platform
PolyphraZ is a software platform making it
possible at the same time to visualize the available
corpora on the Web by showing several languages,
with the choice of the user and to work on a basis
of "polyphrases" initialised from these corpora
while making it possible to control all functions
described above (call of MT systems, distance
computation,  collaborative postedit ion,
evaluation).
2.4.1 General architecture
We follow the software architecture of the
Papillon platform.
 We classify the objects to handle in three types
?  Raw corpus sources
? Sources transformed into our XML format
CXM. (Common Example Markup) and
coded in UTF-8, for visualization "just as
they are", then in CPXM format, DTD for
parallel visualization.
? MPM: multilingual polyphrase memory
Figure 1: objects of the PolyphraZ platform
2.4.2 Intended users of PolyphraZ
We distinguish four principal users: the preparer,
the reader ("normal" user), the posteditor and the
manager.
?  The preparer
His role consists in calling translation systems,
thereby parameterizing them as well as pos-
sible, which supposes a certain linguistic
ability (to compare the results of various
parameter settings, and of various segmenta-
tions in "blocks", each corresponding to some
parameter settings).
The preparer can also call objective evaluation
methods (NIST, BLEU...) on the results of
translation, tune with parameters to compute
distances between sentences (results of
translation and/or reverse translations), and
post the results. The distance computation
produces, in addition to a value, a XML string
from which a ?track changes? presentation can
be generated. The preparer can also set the
parameters determining "the best" suggestion
among the various translation candidates.
? The reader (normal user)
A reader can visualize the data (the original,
various translations, and distances between the
character strings) through Web interfaces, but
is not allowed to edit the translations.
?  The translator-posteditor
The translator-posteditor is a contributor who
translates from scratch or revises proposed
translations (MT results or translations of
similar sentences found in the MPM or in other
TM put in CPXM or MPM format). There is
an editable area to modify the active sentence.
One can also ask for global modifications (ex:
"SVP" changed into "s'il vous plait" in tran-
scribed spoken utterances) and correct or sup-
plement the local dictionary attached to the
MPM. The system uses the reference sentences
already produced like a translation memory.
PolyphraZ is thus also a system of assistance
to the translator, limited to the translation of
sets of sentences (or titles), with less function-
alities than commercial TWS, but usable for
collaborative volunteer work by non-
professionals.
? The manager
The last type of user is the manager, who will
produce from a MPM "feedbacks" for the de-
velopers of the MT systems used. A manager
cans himself be a developer of an MT system.
He can draw up a list of unknown words and
words badly translated by each system (pro-
duced from the traces of distance computa-
tions). A second function is to propose for
these words suggestions of translation from the
"reference" translations obtained after human
!
 
Corpus
=
Tanaka
Corpus
=
CSTAR
Corpus
=
BTEC-CH
Corpus
=
BTEC-EN
Raw corpus
sources
initial versions
Various formats
 Various codings
 Visualization on 
several documents 
CXM 
  (Commun   Example  
 Markup)
Single format XML
 coding = UTF-8
Parallel visualisation
CXM
MPM!:
 (Multilingual Polyphase
 Memory 
)
Correspondence
Versioning
LD : Local Dictionary
MPM
LD
Export
Import
External
 resources
Internet
CPXM
CPXM 
(Common Parallel Example 
   Markup)
Corpus
 =
 set of polyphrases
  
BTEC-JPN
Format= texte
Coding= EUC
BTEC-JPN
Format =XML
DTD=CXM
Coding= UTF-8
revision. Finally, it is possibile to provide a
presentation of the evaluations and compari-
sons between the results of the various systems
used and/or their various parameter settings.
2.4.3 Implementation of PolyphraZ
Programmed in standard Java under the Enhydra
development environment used for the dynamic
and multilingual Papillon web site, PolyphraZ is
multi-platform (MacOS-X/Unix/Linux, Windows).
2.5 Scenarios
The use of  PolyphraZ can be divided in 3 parts:
setting of the data under three different formats
(CXM, CPXM, MPM).
Figure 2 : scenarios for using PolyphraZ
2.5.1 CXM (Common eXample Markup)
In order to manipulate a single format (XML)
and a single encoding (UTF-8), we automatically
convert into the CXM format the imported data
(corpus, text aligned...). CDM is defined in the
same spirit as the CDM (Common Dictionnary
Markup) of the Papillon project.
Figure 3: example XML file conforming to the
CXM.dtd
2.5.2 CPXM.dtd (Common Parallel eXample
Markup)
A second Java program transforms all CXM files
corresponding to a given multilingual parallel
corpus of sentences to the CPXM format (see
appendix 2). In this format, we introduce the
"polyphrase" XML element, which is a set of
monolingual components, each containing possibly
one or more proposals.
2.5.3 MPM.dtd (Multilingual Polyphrase
Memory)
The MPM data structure is under construction. It
is intended for the management of the
correspondences between the various linguistic
versions as well as the modifications which can be
made, and to keep the history of the modified files.
As shown in the following figure, a MPM of
PolyphraZ can contain a set of versions and
alternatives of the sentences, as well as the results
of various computations.
Figure 4 : logical view of a MPM
We give a first version of the MPM DTD in
appendix 3.
2.5.4 Parallel visualization
PolyphraZ can visualize polyphrases in parallel
from corpora in CPXM or MPM formats. This
functionality is useful to compare translations, and
is made available to readers; translators revisors,
and managers.
Initialisation 
Of LD
On the Web
local (server)
preparer
Contributors
 (translator or
posteditor)
Visitors 
Manager (on local or on
the Web)
ftp
Initial 
document
 
CXM
Recovery
Basic tools 
TextEdit, BBEdit
Tools ?
Methods ?
multilinguals 
corpora in 
CXM
CPXM
 
Corpora
 in
CPXM
LD(Local
Dictionary)
Initialisation 
of the MPM
monolinguals 
corpora in 
CXM
Papillon
Parallel Visualisation of data
MPM (Multilingual
Polyphrase Memory )
Distance
calculation
Translation
Automatic
evaluation 
2.2
1.3
1.2
2.1
1.1
Proposal
2
11.11
2.2
1.3
1.2
2.12
Proposal N?of
 version
N?of
version
XL1,L2(1.1,1.1)
XL1,L2(1.2,1.2)
??..
D
L1
(1.1,1.2)
D
L2
(1.1,1.3)
???.
VersionVersionVersion
CorespondancesDistance
calculation
?
?
.
Language 3
(L3)
Language 2
(L2)
Language 1
(L1)
Hierarchy 1
H
i
e
r
a
r
c
h
y
 
 
2
Figure 5: parallel visualisation of the BTEC (extract)
2.6 Evaluation of translation results
 We have programmed and integrad in
PolyphraZ three evaluation methods (NIST, BLEU
and distance calculation). NIST and BLEU are
well known. Let us give more details about
distance calculation between 2 sentences.
The distance we compute between two strings is
a linear combination of two edit distances, one at
the level of characters, the other at the level of
words. In general, the edit distance between two
strings P1 and P2 of atoms (characters or words
here) is the minimal number of suppressions,
insertions or replacements of atoms necessary to
transform P1 into P2 or, equivalently, P2 into P1.
To compute the edit distance between P1 and P2 at
the level of words, one segments them into words,
computes the character distances between words of
P1 and words of P2, and then computes the word
distance using words as "large characters".
We use the well-known dynamic programming
algorithm of (Wagner, Fischer, 1974). To combine
the two levels (characters and words), we use the
formula:
D = (aD
char
 +bD
word
)/(a+b)   ; a +b=1
Figure 6:trace of the Wagner and Fischer
algorithm
2.6.1 ?Track changes? visualisation
This representation corresponds to the
presentation used by Microsoft Word in
"Track changes" mode. It is very readable. In
certain cases, the representation at the level of
the characters is more compact and readable
that at the level of words, while it is the
opposite in other cases. In fact, this
representation is not "faithful" to the trace,
because a sequence of exchanges is
transformed into a sequence of suppressions
and a sequence of insertions.
aisympablthique
Figure 7:?Track changes? display
One interesting and today unsolved problem is
how to merge the 2 levels: given 2 sentences and
their character and word edit distances, necessarily
both minimal, how to produce a trace which would
be "the best" or "a best" combination of the 2
traces?
2.6.2 Representation with 3 lines
Figure 8 : 3 lines representation
This representation is simpler to understand, but
takes more space.
?  represents the exchange of a character by
another,
 || represents the equality between two characters
 ? represent the suppression of the 1st character,
Figure 9 : XML representation
3 Conclusion
The CXM and CPXM levels of PolyphraZ are
already used. They have allow us to import the
BTEC multilingual corpus of parallel sentences
(into the common CPM format), to transform it
(163000 sentenes in 5 languages) into files in
CPXM formats, and to visualize it
1
 on the web.
The Tanaka corpus should be available when this
paper will be presented. The "inner" level of MPM
(Multilingual Polyphrase Memory) is almost
completed. It will also support versioning.
In the future, we plan to use MPMs not only to
handle multilingual corpora of parallel sentences,
but also like "pivots", to establish the sentence-
level correspondence between parallel monolingual
structured documents. If no high quality TWS (like
Trados, TM2, D?j? Vu; Transit, etc.) is available,
PolyphraZ could be used as a "bare bone" TWS,
directly through the web, in the Montaigne
2
 spirit.
We are also studying how to integrate into a
MPM structure "generators" specifying classes of
sentences (automata for messages with variables
and variants, regular expressions for CSTAR IF
expressions, etc.), and to use them to extend a
MPM not only "in width" (addition of new
languages), but also "in height", by the automatic
creation of new "statements", natural and/or
formal.
R?f?rences
A-B.Assimi (Assimi,2000). Gestion de l??volution
non centralis?e de documents parall?les
multilingues, Nouvelle th?se, UJF, Grenoble,
31/10/00, 200!p.
A-B.Assimi & C.Boitet (Assimi&Boitet,2001)
Management of Non-Centralized Evolution of
Parallel Multilingual Documents. P r o c .
Internationalization Track, 10th International
World Wide Web Conference, Hong Kong, May
1-5, 2001, 7 p.
Ch.Boitet (Boitet, 2003) Approaches to enlarge
bilingual corpora of example sentences to more
languages,  Papillon-03 seminar, Sapporo, 3-5
July 2003 12!p.
Ch .Boitet & Tsai W.-J (Boitet & W-J 2002).
Coedition to share text revision across
languages. Proc. COLING-02 WS on MT,
Taipeh, 1/9/2002, 8 p.
                                                       
1
  The full corpus is only accessible to members of
CSTAR-III, so that we show only extracts
corresponding to parts which are or will be published
for the open evaluation of various MT systems to be
presented at IWSLT-04.
2
 Mutualization Of Nomadic Translation Aids
for Groups on the NEt (Mutualisation d'Outils
Nomades de Traduction avec Aides Informatiques
pour des Groupes sur le NEt).
H.Vo-trung (Vo-trung, 2004) R?utilisation de
traducteurs gratuits pour d?velopper des
syst?mes multilingues, accept? ? la conf?rence
RECITAL 2004, avril 2004, F?s, Maroc.
N.Hajlaoui, Ch .Boitet (Hajlaoui, Boitet, 2003a), A
"pivot" XML-based architecture for multilingual,
multiversion documents!: parallel monolingual
documents aligned through a central
correspondence descriptor and possible use of
U N L , Convergences?03, Alexandria, 2-6
December 2003.
N.Hajlaoui, Ch.Boitet (Hajlaoui, Boitet, 2003b),
Mod?lisation de la production de phrases,
projet franco-tunisien entre l??quipe GETA,
CLIPS, UJF, Grenoble et universit? de Sousse,
Tunisie, 25 p.
N.Hajlaoui (2002) Gestion des versions des
composants ?lectroniques virtuels. Rapport de
DEA, CSI, INPG, juin 2002, 80 p.
R.Wagner & Michael.Fischer (Wagner, Fischer
,1974)  The String-to-String Correction Problem
ACM Journal of the Association for Computing
Machinery, Vol. 21, No 1, Janvier 1974.
W.-J.Tsai (Tsai,2001) SWIIVRE a web site for the
Initiation, Information, Validation, Research and
Experimentation on UNL. Proc. First UNL Open
Conference - Building Global Knowledge with
UNL, Suzhou, China, 18-20 Nov. 2001, 8 p.
(C-STAR-III) C-STAR project, http://www.c-
star.org/
(Papillon) Projet PAPILLON de construction
coop?rative d'une base lexicale multilingue et de
c o n s t r u c t i o n  d e  d i c t i o n n a i r e s ,
http://www.papillon-dictionary.org/
(TraCorpEx) projet TraCorpEx
http://www-
clips.imag.fr/geta/User/najeh.hajlaoui/tracorpex/i
ndex.html
(UNL) Universal Networking Langage (UNL)
project, http://www.undl.org/
Appendices
<!-- CXM.dtd  (Common eXample Markup ) is a
DTD  which  describes the corpora
(multilingual or monolingual), it is the
simplest format for imported data.
$Author:  Najeh Hajlaoui
najeh.hajlaoui@imag.fr
$Date: 2003/12/10 01:28:30 $ -->
<!ELEMENT document (information, sentence*) >
<!ELEMENT information (#PCDATA) >
<!ATTLIST information document-name  CDATA
#REQUIRED>
<!ATTLIST information   creation-date
CDATA #IMPLIED>
<!ATTLIST information modification-date
CDATA #IMPLIED>
<!ATTLIST information   coding-set    CDATA
#IMPLIED>
<!ATTLIST information number-of-languages
CDATA     #IMPLIED>
<!ATTLIST information   number-of-sentences
CDATA #IMPLIED>
<!ATTLIST sentence   sentence-id    CDATA
#REQUIRED>
<!ATTLIST sentence xml:lang CDATA #REQUIRED>
<!ELEMENT sentence (segment*) >
<!ATTLIST segment   segment-id    CDATA
#REQUIRED>
<!ELEMENT segment (#PCDATA) >
<!-- Document is a set of sentences, each
sentence is defined
by an identifier called sentence-id and also
by an attribute which indicates the
language -->
<!-- number-of-languages is the total number
of languages constituting the document; if
the document is monolingual, number-of-
languages =1   -->
<!-- number-of-sentences is the total number
of sentences constituting the document -->
<!-- Each sentence is a set of one or more
possible  segment; each segment is
identified by an attribute called  segment-
id -->
Appendix 1 : CXM.dtd (Common eXample
Markup)
<!-- CPXM.dtd  (Common Parallel eXample
Markup ) is a  DTD  which  describes the
multilingual documents (m languages),
multiversions (n versions) (n>m), it
allows the description of a collection of
polyphrases in a single format and
encoding.
$Author:  Najeh Hajlaoui
najeh.hajlaoui@imag.fr
$Date: 2003/06/10 01:28:30 $ -->
<!ELEMENT document (information,
polyphrase*) >
<!ELEMENT information (#PCDATA) >
<!ATTLIST information document-name  CDATA
#REQUIRED>
<!ATTLIST information   creation-date
CDATA #IMPLIED>
<!ATTLIST information modification-date
CDATA #IMPLIED>
<!ATTLIST information   coding-set
CDATA #IMPLIED>
<!ATTLIST information number-of-languages
CDATA                 #IMPLIED>
<!ATTLIST information number-of-
polyphrases CDATA #IMPLIED>
<!ELEMENT polyphrase (monolingual-
component*) >
<!ATTLIST polyphrase   polyphrase-id
CDATA #REQUIRED>
<!ELEMENT  monolingual-component
(segment*) >
<!ATTLIST monolingual-component xml:lang
CDATA #REQUIRED>
<!ELEMENT  segment (proposal) >
<!ATTLIST proposal   proposal-id    CDATA
#REQUIRED>
<!ELEMENT  proposal (#PCDATA) >
<!-- number-of-languages is the total
number of languages appearing in the
document; if the document is monolingual,
number-of-languages =1   -->
<!-- number-of-polyphrases is the total
number of polyphrases constituting the
document -->
<!-- A polyphrase is a set of monolingual
components, each containing 1 or more
possible proposals. Every polyphrase is
identified by a number called polyphrase-
id -->
<!-- Each monolingual component is a set
of one or more possible renderings of the
segment in question; it is identified by
an attribute which indicates the language
-->
<!-- Segment represents the level of
alignment, it is usually a sentence -->
Appendix 2 : CPXM.dtd (Common Parallel
eXample Markup)
<!-- MPM.dtd  (Multilingual Polyphrases
Memory ) is a  DTD  which  allows the
generation of sentences aligned in
several languages and the management of
the correspondence between these
sentences.
$Author:  Najeh Hajlaoui
najeh.hajlaoui@imag.fr
$Date: 2003/01/28 21:28:30 $ -->
<!ELEMENT document (information,
generator*, node-of-correspondence*) >
<!ELEMENT information (#PCDATA) >
<!ATTLIST information document-name
CDATA #REQUIRED>
<!ATTLIST information   creation-date
CDATA #IMPLIED>
<!ATTLIST information modification-date
CDATA #IMPLIED>
<!ATTLIST information   coding-set
CDATA #IMPLIED>
<!ATTLIST information number-of-languages
CDATA #IMPLIED>
<!ATTLIST information number-of-generator
CDATA #IMPLIED>
<!ELEMENT generator (instance*) >
<!ATTLIST generator   original    CDATA
#REQUIRED>
<!ATTLIST generator   context    CDATA
#REQUIRED>
<!ELEMENT  instance (segment*) >
<!ATTLIST instance xml:lang CDATA
#REQUIRED>
<!ATTLIST segment node-of-corespondance-
id CDATA #REQUIRED>
<!ELEMENT  segment (proposal) >
<!ELEMENT  proposal (#PCDATA) >
<!-- number-of-languages is the total
number of languages appearing in the
document; if the document is
monolingual, number-of-languages = 1 -->
<!-- number-of-generator is the total
number of generator appearing in the
document -->
<!-- A generator is a set of original
sentences and  their instance  -->
<!-- A instance is a set of one or more
possible renderings of the segment in
question; it is identified by an
attribute which indicates the language
-->
<!-- Segment represents the level of
alignment, it is usually a sentence -->
<!-- A node-of-correspondence-id
represents the link of corespondance
between the dif?rents proposals of
translation -->
Appendix 3 : MPM.dtd (Multilingual Polyphrase
Memory)
Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 79?87,
Beijing, August 2010
Multilinguization and Personalization of NL-based Systems Najeh Hajlaoui GETALP, LIG, UJF 385 rue de la Biblioth?que, BP n? 53 38041 Grenoble, cedex 9, France Najeh.Hajlaoui@imag.fr Christian Boitet GETALP, LIG, UJF 385 rue de la Biblioth?que, BP n? 53 38041 Grenoble, cedex 9, France Christian.Boitet@imag.fr  Abstract Linguistic porting of content manage-ment services processing spontaneous ut-terances in natural language has become important. In most situations, such utter-ances are noisy, but are constrained by the situation, thus constituting a restricted sublangage. In previous papers, we have presented three methods to port such sys-tems to other languages. In this paper, we study how to also personalize them by making them capable of automatic per-ception adaptation, using fuzzy evalu-ation functions. We have reengineered IMRS, a music retrieval NL-based sys-tem, to implement that idea, and ported it to French, English and Arabic using an enhanced version of our external porting method, building a unique content extrac-tor for these three languages. More than 30 persons participated in a preliminary on-line qualitative evaluation of the sys-tem.  1 Introduction Multilingualizing systems handling content ex-pressed in spontaneous natural language is an important but difficult problem, and very few multilingual services are available today.  The choice of a particular multilingualization process depends on the translational situation: types and levels of possible accesses, available resources, and linguistic competences of participants in-volved in the multilingualization task. Three main strategies are possible in principle for multilingualization, by translation, and by inter-nal or external adaptation.  We consider here the 
subproblem of linguistic porting, where the con-tent is adapted to another language, but not ne-cessarily to a different cultural environment. We also try to add some level of personalization, by automatic perception adaptation, based on the use of fuzzy evaluation functions. We use the example of IMRS, an Impression-based Music-Retrieval System (Kumamoto, 2004), with a na-tive interface in Japanese, which we have reengi-neered and ported to French, English and Arabic.   The context and objectives of our work are pre-sented in the second section. The third section presents the IMRS original prototype and the possible strategies to achieve porting and person-alization. In the fourth section, we give detailed specifications of our reengineered music retrieval system, IMRS-g. In the fifth section, we present the implementation of five music retrieval modes. Finally, we report on the multilingual porting of this system. 2 Methods for porting NL-based con-tent processing systems The choice of a method for multilingualizing e-commerce services based on content extraction from spontaneous texts depends on two aspects of the translational situation: ? The level of access to resources of the initial application. Four cases are possible: complete access to the source code, access limited to the internal representation, access limited to the dictionary, and no access. In the case of IMRS, the access was limited to the internal representation, visible as a non-linguistic interface in the original prototype (a set of 10 impressions manipulate by a set of 7 check-box).  ? The linguistic qualification level of the per-sons involved in the process (level of know-
79
ledge of the source language, competence in NLP) and the resources (corpora, dictionaries) available for the new language(s), in particu-lar for the sublanguages at hand. We concentrate on NLP-based systems that perform specific tasks in restricted domains. Figure 1 shows the general structure of these sys-tems. Examples of such applications and services are: categorization of various documents such as AFP (Agence France Presse) flash reports or cus-tomer messages on an ASS (After Sale Service) server, and information extraction to feed or con-sult a database (e.g. classified ads, FAQ, auto-mated hotlines). 
 Figure 1: general structure of an NLP-based CMS  We first studied linguistic porting of e-commerce systems handling spontaneous utter-ances in natural languages, that are often noisy, but constrained by the situation, and constitute a more or less restricted sub-language (Kittredge, 1982), (Harris, 1968) (Grishman and Kittredge, 1986). This kind of system uses a specific content representation on which the functional kernel works. In most cases, this content representation is generated from the native language L1 by a content extractor. In our PhD, we have identified three possible methods of linguistic porting, and have illustrated them by porting to French CATS (Daoud, 2006), a Classified Ads Transaction System in SMS (Arabic) deployed in Amman on Fastlink, as well as IMRS, mentioned above. The three possible strategies for linguistic porting are internal porting, external porting and porting by machine translation. Figure 2 shows an example of the car domain with the output of the content extractor (CRL-CATS).  In CRL-CATS (Content Representation Lan-guage for CATS), a posted SMS is represented as a set of binary relations between objects. It is a kind of semantic graph with a UNL-like syntax (Uchida and Zhu 2005-2006). There are no vari-
ables, but the dictionary is used as a type lattice allowing specialization and generalization.  ;Selling Renault Megane m 2000 [S] sal(saloon:00,sale:00) mak(saloon:00,RENAULT(country<France, county<europe):07) mod(saloon:00,Megane(country<France, country <europe,make<RENAULT):0C) yea(saloon:00,2000:0K) [/S] Figure 2: Example of SMS  2.1 Internal porting The first possibility consists in adapting the ori-ginal content extractor of the application from L1 to the target language L2 (see Figure 3); but that is viable only if : ? the developers agree to open their code and tools,  ? the code and tools are relatively easy to un-derstand, ? the resources are not too heavy to create (in particular the dictionary).  That method requires of course training the lo-calization team with the tools and methods used. Under these conditions, adaptation can be done at a very reasonable cost, and further main-tenance. 
 Figure 3: internal porting We have previously experimented this method (Hajlaoui, 2008) by porting CATS from Arabic to French: for that, we adapted its native Arabic content extractor, written in EnCo1 (Uchida and Zhu 1999), by translating its dictionary, and modifying a few analysis rules.                                                  1 EnCo is a tool based on rules and dictionaries used for content extraction in original version of CATS system. 
80
2.2 External porting If there is access only to the internal content rep-resentation, the solution consists in adapting an available content extractor for L2 to the sublan-guage at hand, and to compile its results into the original content representation (see Figure 4). For a company wanting to offer multilinguali-zation services, it would indeed be an ideal situa-tion to have a generic content extractor, and to adapt it to each situation (language, sublanguage, domain, content representation, task, other con-straints).  However, there is still no known ge-neric content extractor of that power, and not even a generic content extractor for particular languages, so that this approach cannot be con-sidered at present. Our approach is then to adapt an existing content extractor, developed for L2 and a different domain/task, or for another lan-guage and the same domain/task.  We also applied this method to port CATS from Arabic to French, and experimentation are described in (Hajlaoui, 2008). 
 Figure 4: external porting 2.3 Porting by machine translation If there is no access to the code, dictionary, and internal content representation of the original application, the only possible approach to port it from L1 to L2 is to develop an MT system to automatically translate its (spontaneous) inputs from L2 into L1 (see Figure 5).   Porting CATS from Arabic to French by stat-istical translation gave a very good performance, and that with a very small training corpus (less than 10 000 words). This proves that, in the case of very small sub-languages, statistical transla-tion may be of sufficient quality, starting from a corpus 100 to 500 smaller than for the general language. 
 Figure 5: porting by machine translation 2.4 Results and evaluation  We translated manually the evaluation corpus used for the evaluation of CATS Arabic version. It contains 200 real SMS (100 SMS to buy + 100 SMS to sale) posted by real users in Jordan.  We spent 289 mn to translate the 200 Arabic SMS (2082 words is equivalent to 10 words/SMS, approximately 8 standard pages2) into a French translation, or about 35 mn per page, and 10 mn per standard page to pass from raw translation to functional translation.  We obtained 200 French SMS considered to be functional (1361 words, or about 6,8 words/SMS, approximately 5 standard pages). We then computed the recall R, the precision P and the F-measure F for each most important property (action ?sale or buy?, ?make?, ?model?, ?year?, ?price?). P = |correct entities identified by the system| / |entities identified by the system|;  R = |correct entities identified by the system| / |entities identified by the human|;  F-measure = 2PR/(P+R) Table 1 summarizes the percentage (F-measure ratio) of the Arabic-French porting of CATS and shows details in (Hajlaoui, 2008). Properties having numbers as values, like price and year, lower the percentage of porting by ex-ternal porting, but the advantage is that method requires only accessing the internal representa-tion of the application.  Minimum Average Maximum Internal porting 95% 98% 100% External porting 46% 77% 99% Porting by statis-tical translation 85% 93% 98% Table 1: evaluation of three methods used for porting CATS_Cars from Arabic to French.                                                  2 Standard page = 250 words 
81
In the third part of this article, we describe the multilinguization of IMRS, IMRS-g, which in-cludes a module of queries management, where the queries are expressed either in a natural lan-guage or in a graphical interface showing 10 vec-tors corresponding to the internal content repre-sentation. In response to a query, the user re-ceives a set of music pieces that correspond to her/his desired selection criteria.  In addition to the original design, where the NL expressions of the 10 measures are mapped in a fixed way to the integers in the real interval [1, 7], we have tried to apply a small part of the theory of fuzzy sets to improve the representa-tion and evaluation of human perceptions. 3 Multilinguization of IMRS To port IMRS to several languages, we used the external porting method and we built a new con-tent extractor, which treats simple utterances re-lated to the music domain. 3.1 IMRS IMRS (Kumamoto and Ohta, 2003) is a non-deployed Web service prototype, developed as an experimental base for a PhD. It allows to re-trieve music pieces either by using Japanese queries, or by manipulating a graphical interface with 10 criteria settable by knobs (speed, noise, rhythm...), and showing remarkable values (inte-gers between 1 and 7) expressed by English la-bels. In IMRS, an utterance processed by the sys-tem is a spontaneous sentence or fragment of a sentence. The content extractor transforms it into a vector of 10 real numbers in the interval [1, 7]. The symbol nil means don?t care.  The 10 components are called Noisy-Quiet, Calm-Agitated, Bright-Dark, Refreshing-Depressing, Solemn-Flippant, Leisurely-Restricted, Pretty-unattractive, Happy-Sad, Re-laxed-Aroused, The mind is restored-The mind is vulnerable. Each has associated grades (inter-preted as "concepts" below). For example, the component Happy-Sad is characterized by the seven grades: very happy, happy, a little happy, medium, a little sad, sad and very sad. In the ori-ginal IMRS, these values always correspond to the integers in the [1, 7] interval, respectively 7.0, 6.0, 5.0, 4.0, 3.0, 2.0 and 1.0.  
A request to find a piece of music that gives a happy impression (happy) corresponds to the 10-dimensional vector as follows: (nil nil nil nil nil nil nil 6.0 nil nil) (Kumamoto, 2007), but the music pieces can be described by vectors having non-integer components.  Although we had a quite precise description of the internal representation used by IMRS. We could not find information on the rest of the sys-tem. Hence, we recreated it to emulate the func-tions described in the original publications. That includes the system architecture, the design and implementation of the database, the management of requests, and the programming of actually much more than the originally proposed service. By definition, linguistic porting consists in making an application existing in some language L1 available in another language L2, within the same context. Evaluation of the linguistic porting of a content management application can be done at two levels.  ? Evaluation at the internal representation level. It is an evaluation at the level of com-ponents.  ? Evaluation at the task level. It is an end-to-end evaluation of the new version (in L2) of the application.   To make an end-to-end evaluation of IMRS, an IMRS Web-based simulator was developed. It makes it possible to evaluate in context the result of linguistic porting (Japanese ! French, Arabic, English). A real database with real music pieces, characterized by 10-dimensional vectors as in IMRS, was also created.  The aim of the multilinguization was however not to develop an application strictly equivalent to IMRS, with the addition of being able to han-dle queries expressed in French, English and Arabic, but to develop an upward compatible, extended application. In particular, we wanted to add other dimensions corresponding to the type of music, the composer, the period of compo-sition, the instruments used, etc. We also wanted to experiment the possibility to associate to each impression such as happy a fuzzy set over [1,7] expressed by a membership function (into [0,1]). More details are given below. 3.2 Our IMRS-g system  With the help of a Master student in computer science, Xiang Yin, we have programmed in 
82
PHP/MySQL a Web service called IMRS-g, re-implementing as accurately as possible the sys-tem IMRS, and generalizing it. Not having sufficient expertise in Japanese, we replaced Japanese by French. We also ad-apted the NLP part to English and Arabic, using the same strategy to handle the three languages. We then generalized the internal representa-tion by adding other search criteria (such as the type of music, the composer, the period of com-position, and the instruments used), and using fuzzy sets. A large set of music pieces was loaded into the database, and labelled by vectors in a collabor-ative way. An evaluation of the French version was then conducted as part of a realistic use, with students listening to music. The first part of the linguistic porting has been very rapid, since it consisted only in translating into French and Arabic the NL labels expressing impressions (Noisy/Quiet, Calm/Agitated, Sad/Happy, etc.), by associating them the same values as in IMRS. The content extractor processes simple utter-ances and extracts from them a 10-dimensional IMRS vector, and the additional information in the form (lists of) of items. As in IMRS, a request for a music piece can be made either by typing a query in natural lan-guage, or through a graphical interface allowing to manipulate a 10-dimensional vector, and to fill fields for the other types of information.  In response, the user receives a list of links to music pieces corresponding to its selection cri-teria. Clicking on a link starts the playing of the corresponding music piece. 3.3 Generalization by fuzzying the interpre-tation of the NL labels  The original representation of IMRS seems too rigid to express utterances like quite calm or to change the current request using an utterance like a little slower. Even if we agree that each term corresponds to an interval of length 1 centred on its reference value, e.g. [5.5, 6.5[ for happy, [6.5, 7.5] for very happy, etc., there are problems at the extremities. Therefore we studied the possi-bility of better modelling and better processing the requests by using fuzzy logic (Zadeh, 1965).  In order to reason from imperfect knowledge, in contrast to classical logic, fuzzy logic pro-
poses to replace the Boolean variables used in classical logic by fuzzy variables, and the classi-cal crisp sets by fuzzy sets.  Let U be a universe of elements. A fuzzy set A over U is defined by its membership function (fA). An element x of U is in A with a degree of membership fA(x) " [0, 1]. If fA(x) " {0, 1}, A reduces to a classic set, where x " A if fA(x)=1 and x # A if fA(x)=0 (fA is then simply the char-acteristic function of A).  In a fuzzy set, an element x more or less be-longs to the concept associated to A, or to the concept attached to A (such as happy). A fuzzy set is defined by all values of its membership function on its definition domain (which may be discrete or continuous). For example, the concept young might be de-fined over the universe U of possible (integer) ages U = [0, 120] by the discrete fuzzy set A = ((10 1), (20 0.8), (30 0.6), (40 0.2), (50, 0.1), (60 0), (70 0), (80 0)). The first pair means that a 10-year old is 100% young, and the fifth that a 50-year old is 10% young.  Using fuzzy logic, we could say that a piece of music is 100% rapid if its tempo is 100 (100 crotchets (quarter notes) per minute), with a bell-shaped curve for the membership function, rising from 0 to 1 and then falling, in the range [84, 112]. Then, rapid might be understood as im-pression of rapidity. As the impression of ra-pidity may differ from person to person, that curve may differ accordingly.   Figure 6. Representation of the rapidity impression  We propose to incorporate the possibility to move from the perceptions to digital measure-ments and to personalize the system by learning parameters of each curve of this type for each user. Such a curve can be characterized by a small number of significant points, such as the maximum, 2 points at the 10% below the maxi-mum, 2 minima on each side, and 2 points at 10% above the global minimum.  
 
rapide  0  40 60 84 100 112 140 160 176 1   0 
83
To find the criteria for each piece of music, we have developed a website to ask a group of peo-ple to listen to music pieces and to give their opinions in terms of impressions, knowing that they will not have the same taste and the same perception. For example, for the same piece, a first listener will say that it is rapid, and a second will find it very rapid. The question here is how to merge these different views into a single im-pression. We propose two solutions: (1) con-struct a fuzzy set which is the average of those of annotators, possibly by giving greater weight to the annotations of confirmed annotators, (2) build several perception types, i.e. several fuzzy sets corresponding to subgroups of users with similar perceptions. We know that the Japanese persons find only slow pieces of music that Wes-terners find very slow. In this work, we have taken into account pre-vious queries of users or the history of users. For example, if a user requests a piece a little less noisy, or a little more calm, we should be able to use the information saved in his history, and cal-culate the new request taking into account the perceptions associated to the last piece of music listened to.  4 Specification and implementation We specified and implemented a multimedia database for storing music pieces, as well as in-formation representing the impressions of each piece. As said above, we added to the 10 features of IMRS other information types:  singer, poet, composer, genre, album and duration, for each music piece. Moreover, to evaluate music, we stored the values of the impressions recorded by contributing users for each piece. These values were used to produce the final values stored in the database. To analyze the impressions of users, we requested further information from each user, as gender and age. We loaded our database with a set of 354 pieces (89 Western, 265 Eastern) and all infor-mation related to each piece (artist, album, genre...). The duration of individual pieces varies between 48 seconds and 22 minutes. The website has a login page that allows a se-cured access for each user. For a first connection, the user must register and fill some information from which we compute and store a profile.  
If the connection is successful, a list of pieces is displayed. For each piece, a link allows listen-ing to the music and also opens a new page pro-viding an adapted evaluation interface appropri-ate to the evaluation task.  In the evaluation phase, the user can listen to the selected piece and evaluate it according to the 10 IMRS basic criteria (soft, calm, happy...). For each criterion, we offer a range of values and the user can move a cursor and put it on the value that represents its perception. Next, we propose several ways to search for music pieces. The cost of multilinguization of the IMRS sys-tem was 3 man-months. To this cost, we add 1 man-month for the development and integration task of the content extractor for the three lan-guages (French, Arabic, English). 5 Music retrieval modes  After registering and connecting, users listen to and evaluate music. The evaluation information is recorded directly in the database.  For each dimension, we compute the average of the obtained values. This phase is temporary pending further evaluations to draw the curves associated to each dimension and to each piece. We defined and implemented five possibilities to search music: by user profile, by impressions, by selecting criteria, by input utterances, and by history. 5.1 Search by user profile  We propose to users music adapted to their pre-ferences recorded in their profiles. The method follows the following steps:  ? Find the user profile (ten values that represent his basic impressions) in the database.  ? Compute the Euclidean distance between the two vectors formed by the 10 values of profile and the 10 values of each music piece (see ex-ample below).  ? Sort pieces by distances in ascending order.  ? View the nearest 10 pieces.  Here is an example: User profile: impressions vector  Profile = (Nil 6  3 Nil 2  1  3  5 Nil Nil)  Piece impressions (existing impressions vector):  Piece1 =  (3.5 Nil 2.3 5.0 3.2 Nil 2.6 Nil 6.0  1.4)  
84
Euclidian distance (d):  d= ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )2222222222 4.1464456.23412.32543.23465.34 !+!+!+!+!+!+!+!+!+!   => d = 5.3,  Note: if  value = ?Nil?, we put value :=  4. 5.2 Search by impressions We ask the user to place the cursors on the values that represent his perception. We can limit ourselves to a particular type of music (Western music, Eastern music or light music). The search method has the following steps:  ? Choose the kind of music (Western music, Eastern music or light music).  ? Place one or more cursors on the values that represent user?s perception.  ? Compute the Euclidean distance between the two vectors formed by the 10 values of search and the 10 values of each piece. ? Sort pieces by distances in ascending order. ? View the nearest 10 pieces.  Here is an example: we search a noisy (fort) and somewhat calm (assez calme) piece (see Figure 7).   
 Figure 7. Example of search by impressions  The result of the previous request is a set of 10 music pieces. 5.3 Search by selection criteria  We offer four search criteria: artist, album, genre and creation date. The search methods for each of these criteria are similar.  For example, the search by artist follows the following steps:  ? Search all artists (singers) existing in the database.  ? Choose an artist from this list.  ? Search all pieces performed by this artist and show them (by links). 
5.4 Search by input utterances  The content extractor works for French, Arabic and English, and handles simple utterances re-lated to the music domain. This program takes as input a corpus of music pieces and gives as out-put a file containing the corresponding vector representations.  The search method has the following steps:  ? Enter an utterance in natural language repre-senting impressions of music search.  ? Call a content extractor. The result, which contains a vector representing the desired per-ceptions, is stored in a text file.  ? Extract the vector from the text file.  ? For each value of the vector (Vv), if one of the symbols (+, + +, -, --,?) appears, then we extract the value of the last search of the con-cerned user (Vo: old value) from the database to compute the new value of search (Vn: new value).  Here are some examples of utterances that cor-respond to the precedent symbols. +: more noisy, ++: still more noisy, -: less noisy, --: still less noisy, ?: not noisy.  We treat these symbols with the following rules:  If (Vv == ?+?) {Vn = Vo + $ ;} If (Vv == ?++?) {Vn = Vo + 2$ ;} If (Vv == ?-?) {Vn = Vo - $ ;} If (Vv == ?--?) {Vn = Vo - 2$ ;} If (Vv == ??x?) {Vn = 7 - x ;} If (Vn > 7) {Vn = 7 ;} ? Compute the Euclidean distance between the two vectors formed by the 10 desired values and the 10 values of each piece. ? Sort music by distances in ascending order. ? View the nearest 10 pieces. 5.5 Search by history We extract from the history of each user five types of information:  (a) the kind of desired pieces, (b) their creation date, (c) the artists (per-formers), (d) the liked albums, (e) the favourite impressions.  The search method has the following steps:  ? Search the user?s history in the database and check if the user has already searched with the five previous conditions. ?  If the user has searched for condition (a) or (b) or (c) or (d), we extract the last value of found for each of them. 4 values are obtained. 
85
 If the user searches by impressions (condition (e)), we compute for each dimension the aver-age that represents the history of the searches.  ? Search for music using the values obtained at step 2.   If (e) is verified, we compute the Euclidean distance between the average of impressions representing the history and impressions exist-ing in the database.  If (e) is not verified, we look for pieces, using only the 4 values obtained by the conditions ((a), (b), (c), (d)).  Here an example of a history of one user. For condition (a), the latest search value is ?Pop?. For condition (b), there is no value, i.e. the user did not search by creation date. For condition (c), the latest search value is ?1? (number of the ar-tist). For condition (d), the latest search value is ?2? (number of the album). For condition (e), there are 3 vectors in the search history: V1=(2 5 Nil 3 Nil 2 7 1 Nil Nil) V2=(3 Nil 4.5 2.5 Nil 3.1 6.4 Nil 5 2) V3=(3.5 4.3 Nil 2.1 Nil Nil Nil 3 Nil Nil)  We compute the average of the history, Vm:  Vm=(2.83 4.65 4.5 2.53 Nil 2.55 6.7 2 5 2)  We search for pieces that verify the complex condition: (Kind of music = 'Pop') AND (Num-ber of the artist ='1') AND (Album ID ='2') AND (Impressions vector is closest to Vm according to the Euclidean distance). If the search is successful, then the result is optimal. Otherwise, we search pieces that corres-pond to the second condition: ((Kind of music = 'Pop') OR (Number of the artist ='1') OR (Album ID ='2')) AND (Impressions vector is closest to Vm according to the Euclidean distance). We refined this search through other combina-tions formed by the conditions (a), (b), (c), (d) and (e) and differentiated by the OR and AND operators. 6 Multilingual porting To build our content extractor, we started from a content extractor for French we had previously develop for the same domain, integrated it into IMRS-g, and extended it as explained above (more information type, and fuzzy sets). We then ported it to English and to Arabic, using the sec-
ond technique of external porting (when one has access to the internal representation). Seeing the large percentage of common code to the 3 content extractors obtained, we factor-ised it and obtained a unique content extractor handling input utterances in the music domain in our 3 target languages: French, English and Ara-bic. This technique is perhaps not generalizable, but it works for this sub-language, which is very small, and for the simple task of extracting in-formation representable in very small textual fragments. Here are some examples of results for Arabic, French and English: Exemple_Ar 1 : //je veux un morceau de musique tr?s calme Musique_Ar 1: musique-spec=(nil 7,0 nil nil nil nil nil nil nil nil) Exemple_Ar 2 : //je veux un morceau de musique un peu bruit? Musique_Ar 2: musique-spec=(3,0 nil nil nil nil nil nil nil nil nil) Exemple_Fr 1:je veux un morceau de musique calme et tr?s solennel Musique_Fr 1: musique-spec=(nil 6,0 nil nil 7,0 nil nil nil nil nil) Exemple_Fr 2:je veux un morceau de musique assez fort et clair Musique_Fr 2: musique-spec=(3,0 nil nil 6,0 nil nil nil nil nil nil) Exemple_En 1:I want a calm and very solemn music Musique_En 1: music-spec=(nil 6,0 nil nil 7,0 nil nil nil nil nil) Exemple_En 2:I want a little noisy and bright music Musique_En 2: music-spec=(3,0 nil nil 6,0 nil nil nil nil nil nil) Tableau 1: Examples of results of IMRS-g for Arabic, French and English Conclusion We have presented several possible methods for "porting" applications based on handling the con-tent of spontaneous NL messages in a "native" language L1 into another language, L2.  In a pre-vious paper, we described experiments and evaluations of these methods. We tried to do an ?end-to-end? evaluation of porting IMRS by building a website that pro-poses to engage people in evaluation of a set of music pieces, thereby offering them to search for 
86
music in different possible modes. To that effect, we have produced a functional Web site  (http://www-clips.imag.fr/geta/User/najeh.hajlaoui/Musique/). To date, the evaluation has been done only for French. More than 30 users have participated, perhaps because they were rewarded in a sense: as a kind of compensation, each user could listen to appropriate music adapted to his way of per-ception and taste. The use of fuzzy logic proved useful and was perhaps even necessary to give some freedom of choice of impressions to users. Acknowledgments  We thank Yin Xiang, who dedicated his TER internship during his master in CS to the study and implemention of the IMRS-g system. We would also like to thank our reviewers, who made many constructive remarks and sug-gestions, which we gladly incorporated in this new version of the paper. References  Daoud, D. M. (2006). It is necessary and possible to build (multilingual) NL-based restricted e-commerce systems with mixed sublanguage and contend-oriented methods. Th?se. Universit? Jo-seph Fourier. Grenoble, France. September 23, 2006. 296 p. Grishman, R. and R. Kittredge. (1986). Analyzing language in restricted domains. Hillsdale NJ. Law-rence Erlbaum Associates. 248 p.  Hajlaoui, N. (2008) Multilingu?sation de syst?mes de e-commerce traitant des ?nonc?s spontan?s en langue naturelle. Th?se. Universit? Joseph Fourier. Grenoble. 25 septembre 2008. 318 p. Harris, Z. (1968). Mathematical structures of lan-guage. in The Mathematical Gazette. Vol. 54(388): pp. 173-174. May, 1970. Kittredge, R. (1978). Textual cohesion within sublan-guages: implications for automatic analysis and synthesis. Proc. Coling-78. Bergen, Norv?ge. Au-gust 14-18, 1978. Vol. 1/1.  Kittredge, R. (1982). Variation and Homogeneity of Sublanguages. in Sublanguage - Studies of Lan-guage in Restricted Semantic Domains. Walter de Gruyter. Berlin / New York. 20 p.   Kittredge, R. (1993). Sublanguage Analysis for Natu-ral Language Processing. Proc. First Symposium 
on Natural Language Processing. Thailand, Bang-kok pp. 69-83.  Kittredge, R. and J. Lehrberger (1982a). Sublanguage - Studies of language in restricted semantic do-main. Walter de Gruyter. Berlin / New York. Kumamoto, T. (2004). Design and Implementation of Natural Language Interface for Impression-based Music-Retrieval Systems. Knowledge-Based Intel-ligent Information and Engineering Systems. Springer Berlin / Heidelberg. October 14, 2004. Vol. 3214/2004:  pp. 139-147.  Kumamoto, T. (2007). A Natural Language Dialogue System for Impression-based Music-Retrieval.  Proc. CICLING-07 (Computational Linguistics and Intelligent Text Processing). Mexico. February 12-24, 2007. 12 p.  Kumamoto, T. and K. Ohta (2003). Design and De-velopment of Natural Language Interface for an Impression-based Music Retrieval System. in Joho Shori Gakkai Kenkyu Hokoku. Vol. 4(NL-153): pp. 97-104. Kurohashi, S. and M. Nagao (1999) Manual for Japa-nese Morphological Analysis System JUMAN. Rap. Language Media Lab. School of Informatics, Kyoto University. Kyoto, Japan. November 1999. Uchida, H., M. Zhu, et al (2005-2006). Universal Networking Language 10 2-8399-0128-5. 218 p. Uchida, H. and M. Zhu (1999). Enconverter Specifications, UNU/IAS UNL Center, 33 p. Zadeh, L. A. (1965). Fuzzy sets. Information and Con-trol 8: pp. 338-353. 
87
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 408?413,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Are ACT?s scores increasing with better translation quality?
Najeh Hajlaoui
Idiap Research Institute
Rue Marconi 19
CH-1920 Martigny Switzerland
Najeh.Hajlaoui@idiap.ch
Abstract
This paper gives a detailed description of
the ACT (Accuracy of Connective Trans-
lation) metric, a reference-based metric
that assesses only connective translations.
ACT relies on automatic word-level align-
ment (using GIZA++) between a source
sentence and respectively the reference
and candidate translations, along with
other heuristics for comparing translations
of discourse connectives. Using a dictio-
nary of equivalents, the translations are
scored automatically or, for more accu-
racy, semi-automatically. The accuracy of
the ACT metric was assessed by human
judges on sample data for English/French,
English/Arabic, English/Italian and En-
glish/German translations; the ACT scores
are within 2-5% of human scores.
The actual version of ACT is available
only for a limited language pairs. Conse-
quently, we are participating only for the
English/French and English/German lan-
guage pairs. Our hypothesis is that ACT
metric scores increase with better transla-
tion quality in terms of human evaluation.
1 Introduction
Discourse connectives should preserve their sense
during translation, as they are often ambiguous
and may convey more than one sense depending
on the inter-sentential relation (causality, conces-
sion, contrast or temporal). For instance, since
in English can express temporal simultaneity, but
also a causal sense.
In this paper, we present results of different Ma-
chine Translation systems for English-to-French
and English-to-German pairs. More specifically,
we measure the quality of machine translations
of eight English discourse connectives: although,
even though, meanwhile, since, though, while,
however, and yet, adopting different approaches.
This quality is measured using a dedicated met-
ric named ACT (Accuracy of Connective Transla-
tion), a reference-based metric that assesses only
connective translations.
The paper is organized as follows. In Section 2,
we present the ACT metric and its error rate. In
section 3, we compare the ACT metric to previous
machine translation evaluation metrics. Finally,
we present the results of the different English-to-
German and English-to-French MT systems (Sec-
tion 4).
2 ACT Metric
We described the ACT metric in (Hajlaoui and
Popescu-Belis, 2013) and (Hajlaoui and Popescu-
Belis, 2012). Its main idea is to detect, for a given
explicit source discourse connective, its transla-
tion in a reference translation and in a candidate
translation. ACT then compares and scores these
translations. To identify the translations, ACT first
uses a dictionary of possible translations of each
discourse connective type, collected from training
data and validated by humans. If a reference or a
candidate translation contains more than one pos-
sible translation of the source connective, align-
ment information is used to detect the correct con-
nective translation. If the alignment information is
irrelevant (not equal to a connective), it then com-
pares the word position (word index) of the source
connective alignment with the index in the trans-
lated sentence (candidate or reference) and the set
of candidate connectives to disambiguate the con-
nective?s translation. Finally, the nearest connec-
tive to the alignment is taken.
ACT proceeds by checking whether the refer-
ence translation contains one of the possible trans-
lations of the connective in question. After that, it
similarly checks if the candidate translation con-
tains a possible translation of the connective. Fi-
408
nally, it checks if the reference connective found
is equal (case 1), synonymous (case 2) or incom-
patible 1(case 3) to the candidate connective. Dis-
course relations can be implicit in the candidate
(case 4), or in the reference (case 5) translation or
in both of them (case 6). These different compar-
isons can be represented by the following 6 cases:
? Case 1: same connective in the reference
(Ref) and candidate translation (Cand).
? Case 2: synonymous connective in Ref and
Cand.
? Case 3: incompatible connective in Ref and
Cand.
? Case 4: source connective translated in Ref
but not in Cand.
? Case 5: source connective translated in Cand
but not in Ref.
? Case 6: the source connective neither trans-
lated in Ref nor in Cand.
Based on the connective dictionary categorised
by senses, ACT gives one point for identical (case
1) and equivalent translations (case 2), otherwise
zero. ACT proposes a semi-automatic option by
manually checking instances of case 5 and case
62.
ACT returns the ratio of the total number of
points to the number of source connectives ac-
cording to the three versions: (1) ACTa counts
only case 1 and case 2 as correct and all others
cases as wrong, (2) ACTa5+6 excludes case 5 and
case 6 and (3) ACTm considers the correct transla-
tions found by manual scoring of case 5 and case 6
noted respectively case5corr and case6corr to bet-
ter consider these implicit cases.
ACTa = (| case1 | + | case2 |)/
6?
i=1
| casei | (1)
ACTa5 + 6 = (| case1 | + | case2 |)/
4?
i=1
| casei | (2)
ACTm = ACTa + (| case5corr | + | case6corr | /
6?
i=1
| casei |)
(3)
1In terms of connective sense.
2We do not check manually case 4 because we observed
that its instances propose generally explicit translations that
do not belong to our dictionary, it means the SMT system
tends to learn explicit translations for explicit source connec-
tive.
2.1 Configurations of ACT metric
As shown in Figure 1, ACT can be configured to
use an optional disambiguation module. Two ver-
sions of this disambiguation module can be used:
(1) without training, which means without sav-
ing an alignment model and only using GIZA++
as alignment tool; (2) with training and saving
an alignment model using MGIZA++ (a multi-
threaded version of GIZA++) trained on an exter-
nal corpus to align the (Source, Reference) and the
(Source, Candidate) data.
Figure 1: ACT architecture
ACT is more accurate using the disambiguation
module. We encourage to use the version without
training since it only requires the installation of
the GIZA++ tool. Based on its heuristics and on
its connective dictionaries categorised by senses,
ACT has a higher precision to detect the right con-
nective when more than one translation is possible.
The following example illustrates the usefulness
of the disambiguation module when we have more
than one possible translation of the source con-
nective. Without disambiguation, ACT detects the
same connective si in both target sentences (wrong
case 1), while the right translation of the source
connective although is bien que and me?me si re-
spectively in the reference and the candidate sen-
tence (case 2).
Without disambiguation, case 1: Csrc= although,
Cref = si, Ccand = si
With disambiguation, case 2: Csrc= although
(concession), Cref = bien que, Ccand = me?me si
? SOURCE: we did not have it so bad in ireland
this time although we have had many serious
wind storms on the atlantic .
409
? REFERENCE: cette fois-ci en irlande . ce n?
e?tait pas si grave . bien que de nombreuses
tempe?tes violentes aient se?vi dans l? atlan-
tique .
? CANDIDATE: nous n? e?tait pas si mauvaise
en irlande . cette fois . me?me si nous avons
eu vent de nombreuses graves tempe?tes sur
les deux rives de l? atlantique .
In the following experiments, we used the rec-
ommended configuration of ACT (without train-
ing).
2.2 Error rate of the ACT metric
ACT is a free open-source Perl script licensed un-
der GPL v33. It has a reasonable and accept-
able error score when comparing its results to
human judgements (Hajlaoui and Popescu-Belis,
2013). Its accuracy was assessed by human judges
on sample data for English-to-French, English-to-
Arabic, English-to-Italian and English-to-German
translations; the ACT scores are within 2-5% of
human scores.
2.3 Multilingual architecture of ACT Metric
The ACT architecture is multilingual: it was ini-
tially developed for the English-French language
pair, then ported to English-Arabic, English-
Italian and English-German.
The main resource needed to port the ACT met-
ric to another language pair is the dictionary of
connectives matching possible synonyms and clas-
sifying connectives by sense. To find these pos-
sible translations of a given connective, we pro-
posed an automatic method based on a large cor-
pus analysis (Hajlaoui and Popescu-Belis, 2012).
This method can be used for any language pair.
Estimating the effort that would have to be taken
to port the ACT metric to new language pairs fo-
cusing on the same linguistic phenomena mainly
depends on the size of parallel data sets contain-
ing the given source connective. The classifi-
cation by sense depends also on the number of
possible translations detected for a given source
connective. This task is sometimes difficult, as
some translations (target connectives) can be as
ambiguous as the source connective. Native lin-
guistic knowledge of the target language is there-
fore needed in order to complete a dictionary with
the main meanings and senses of the connectives.
3Available from https://github.com/idiap/
act.
We think that the same process and the same
effort can be taken to adapt ACT to new linguistic
phenomena (verbs, pronouns, adverbs, etc).
3 Related works
ACT is different from existing MT metrics. The
METEOR metric (Denkowski and Lavie, 2011)
uses monolingual alignment between two trans-
lations to be compared: a system translation and
a reference one. METEOR performs a mapping
between unigrams: every unigram in each trans-
lation maps to zero or one unigram in the other
translation. Unlike METEOR, the ACT metric
uses a bilingual alignment (between the source and
the reference sentences and between the source
and the candidate sentences) and the word posi-
tion information as additional information to dis-
ambiguate the connective situation in case there is
more than one connective in the target (reference
or candidate) sentence. ACT may work without
this disambiguation.
The evaluation metric described in (Max et al,
2010) indicates for each individual source word
which systems (among two or more systems or
system versions) correctly translated it according
to some reference translation(s). This allows car-
rying out detailed contrastive analyses at the word
level, or at the level of any word class (e.g. part
of speech, homonymous words, highly ambiguous
words relative to the training corpus, etc.). The
ACT metric relies on the independent compari-
son of one system?s hypothesis with a reference.
An automatic diagnostics of machine translation
and based on linguistic checkpoints (Zhou et al,
2008), (Naskar et al, 2011) constitute a different
approach from our ACT metric. The approach es-
sentially uses the BLEU score to separately eval-
uate translations of a set of predefined linguis-
tic checkpoints such as specific parts of speech,
types of phrases (e.g., noun phrases) or phrases
with a certain function word. A different ap-
proach was proposed by (Popovic and Ney, 2011)
to study the distribution of errors over five cate-
gories (inflectional errors, reordering errors, miss-
ing words, extra words, incorrect lexical choices)
and to examine the number of errors in each cat-
egory. This proposal was based on the calcu-
lation of Word Error Rate (WER) and Position-
independent word Error Rate (PER), combined
with different types of linguistic knowledge (base
forms, part-of-speech tags, name entity tags, com-
410
pound words, suffixes, prefixes). This approach
does not allow checking synonym words having
the same meaning like the case of discourse con-
nectives.
4 ACT-based comparative evaluation
We used the ACT metric to assess connective
translations for 21 English-German systems and
23 English-French systems. It was computed on
tokenized and lower-cased text using its second
configuration ?without training? (Hajlaoui and
Popescu-Belis, 2013).
Table 1 shows only ACTa scores for the
English-to-German translation systems since
ACTa5+6 gives the same rank as ACTa. Table 2
present the same for the English-to-French sys-
tems. We are not presenting ACTm either because
we didn?t check manually case 5 and case 6.
Metric System Value Avg SD
AC
Ta
cu-zeman.2724 0.772
rbmt-3 0.772
TUBITAK.2633 0.746
KITprimary.2663 0.737
StfdNLPG.2764 0.733
JHU.2888 0.728
LIMSI-N-S-p.2589 0.720
online-G 0.720
Shef-wproa.2748 0.720
RWTHJane.2676 0.711 0.697 0.056
uedin-wmt13.2638 0.707
UppslaUnv.2698 0.707
online-A 0.698
rbmt-1 0.694
online-B 0.677
uedin-syntax.2611 0.672
online-C 0.664
FDA.2842 0.664
MES-reorder.2845 0.664
PROMT.2789 0.621
rbmt-4 0.513
Table 1: Metric scores for all En-De systems:
ACTa and ACTa5+6 scores give the same rank;
ACT V1.7. SD is the Standard Deviation.
5 Conclusion
The connective translation accuracy of the can-
didate systems cannot be measured correctly by
current MT metrics such as BLEU and NIST. We
therefore developed a new distance-based metric,
ACT, to measure the improvement in connective
translation. ACT is a reference-based metric that
only compares the translations of discourse con-
nectives. It is intended to capture the improvement
of an MT system that can deal specifically with
discourse connectives.
Metric System Value Avg SD
AC
Ta
cu-zeman.2724 0.772
online-B 0.647
LIMSI-N-S.2587 0.647
MES.2802 0.647
FDA.2890 0.638
KITprimary.2656 0.638
cu-zeman.2728 0.634
online-G 0.634
PROMT.2752 0.634
uedin-wmt13.2884 0.634
MES-infl-pr.2672 0.629
StfdNLPGPTP.2765 0.629 0.608 0.04
DCUprimary.2827 0.625
JHU.2683 0.625
online-A 0.621
OmniFTEn-to-Fr.2647 0.616
RWTHph-Janepr.2639 0.612
OFlTEnFr.2645 0.591
rbmt-1 0.586
Its-LATL.2667 0.565
rbmt-3 0.565
rbmt-4 0.543
Its-LATL.2652 0.543
online-C 0.500
Table 2: Metric scores for all En-Fr systems:
ACTa and ACTa5+6 scores give the same rank;
ACT V1.7. SD is the Standard Deviation.
ACT can be also used semi-automatically. Con-
sequently, the scores reflect more accurately the
improvement in translation quality in terms of dis-
course connectives.
Theoretically, a better system should preserve
the sense of discourse connectives. Our hypothe-
sis is thus that ACT scores are increasing with bet-
ter translation quality. We need access the human
rankings of this task to validate if ACT?s scores
indeed correlate with overall translation quality
rankings.
Acknowledgments
We are grateful to the Swiss National Sci-
ence Foundation for its support through the
COMTIS Sinergia Project, n. CRSI22 127510
(see www.idiap.ch/comtis/).
References
Marine Carpuat and Dekai Wu. 2005. Word sense dis-
ambiguation vs. statistical machine translation. In
Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics (ACL), pages
387?394, Sydney, Australia.
Marine Carpuat, Yihai Shen, Xiaofeng Yu, and Dekai
Wu. 2006. Toward integrating word sense and en-
tity disambiguation into statistical machine transla-
411
tion. In Proceedings of the 3rd International Work-
shop on Spoken Language Translation (IWSLT),
pages 37?44, Kyoto, Japan.
Bruno Cartoni and Thomas Meyer. 2012. Extracting
Directional and Comparable Corpora from a Multi-
lingual Corpus for Translation Studies. In Proceed-
ings of the eighth international conference on Lan-
guage Resources and Evaluation (LREC), Istanbul,
Turkey.
Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007. Word sense disambiguation improves statisti-
cal machine translation. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics (ACL), pages 33?40, Prague, Czech Re-
public.
Jonathan Clark, Chris Dyer, Alon Lavie, and Noah
Smith. 2011. Better hypothesis testing for statis-
tical machine translation: Controlling for optimizer
instability. In Proceedings of ACL-HLT 2011 (46th
Annual Meeting of the ACL: Human Language Tech-
nologies), Portland, OR.
Laurence Danlos and Charlotte Roze. 2011. Traduc-
tion (automatique) des connecteurs de discours. In
Actes de la 18e` Confe?rence sur le Traitement Au-
tomatique des Langues Naturelles (TALN), Montpel-
lier, France.
Laurence Danlos, Die?go Antolinos-Basso, Chloe?
Braud, and Charlotte Roze. 2012. Vers le
fdtb : French discourse tree bank. In Actes de
la confe?rence conjointe JEP-TALN-RECITAL 2012,
volume 2: TALN, pages 471?478, Grenoble, France.
Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic Metric for Reliable Optimization
and Evaluation of Machine Translation Systems. In
Proceedings of the EMNLP 2011 Workshop on Sta-
tistical Machine Translation, Edinburgh, UK.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an open source toolkit for
handling large scale language models. In Proceed-
ings of Interspeech, Brisbane, Australia.
Najeh Hajlaoui and Andrei Popescu-Belis. 2012.
Translating english discourse connectives into ara-
bic: A corpus-based analysis and an evaluatoin met-
ric. In Proceedings of the 4th Workshop on Com-
putational Approaches to Arabic Script-based Lan-
guages (CAASL) at AMTA 2012, San Diego, CA.
Najeh Hajlaoui and Andrei Popescu-Belis. 2013. As-
sessing the accuracy of discourse connective trans-
lations: Validation of an automatic metric. In Pro-
ceedings of the 14th International Conference on
Intelligent Text Processing and Computational Lin-
guistics, Samos, Greece.
Hugo Hernault, Danushka Bollegala, and Ishizuka Mit-
suru. 2010a. A semi-supervised approach to im-
prove classification of infrequent discourse relations
using feature vector extension. In Proceedings of
the 2010 Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 399?409,
Cambridge, MA.
Hugo Hernault, Helmut Prendinger, David A. duVerle,
and Mitsuru Ishizuka. 2010b. HILDA: A discourse
parser using Support Vector Machine classification.
Dialogue and Discourse, 3(1):1?33.
Alistair Knott and Chris Mellish. 1996. A feature-
based account of the relations signalled by sentence
and clause connectives. Language and Speech,
39(2?3):143?183.
Philipp Koehn and Hieu Hoang. 2007. Factored
Translation Models. In Proceedings of the Joint
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP) and Computational
Natural Language Learning (CONLL), pages 868?
876, Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbs. 2007. Moses:
Open Source Toolkit for Statistical Machine Trans-
lation. In Proceedings of 45th Annual Meeting of the
Association for Computational Linguistics (ACL),
Demonstration Session, pages 177?180, Prague,
Czech Republic.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of
MT Summit X, pages 79?86, Phuket, Thailand.
S. Kolachina, R. Prasad, D. Sharma, and A. Joshi.
2012. Evaluation of discourse relation annotation in
the hindi discourse relation bank. In Proceedings of
the eighth international conference on Language Re-
sources and Evaluation (LREC), Instanbul, Turkey.
A. Max, J. M. Crego, and Yvon F. 2010. Contrastive
lexical evaluation of machine translation. In Pro-
ceedings of the International Conference on Lan-
guage Resources and Evaluation (LREC), Valletta,
Malta.
K. Naskar, S., A. Toral, F. Gaspari, and A. Way. 2011.
A framework for diagnostic evaluation of mt based
on linguistic checkpoints. In Proceedings of MT
Summit XIII, Xiamen, China.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting of the Association for
Computational Linguistics (ACL), pages 160?167,
Sapporo, Japan.
M. Popovic and H. Ney. 2011. Towards automatic
error analysis of machine translation output. Com-
putational Linguistics, 37(4):657?688.
M. Zhou, B. Wang, S. Liu, M. Li, D. Zhang, and
T. Zhao. 2008. Diagnostic evaluation of ma-
chine translation systems using automatically con-
structed linguistic check-points. In Proceedings
412
of the 22rd International Conference on Compu-
tational Linguistics (COLING), pages 1121?1128,
Manchester, UK.
413
