Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 362?370,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Better Synchronous Binarization for Machine Translation 
 
 
Tong Xiao*, Mu Li+, Dongdong Zhang+, Jingbo Zhu*, Ming Zhou+ 
 
*Natural Language Processing Lab 
Northeastern University 
Shenyang, China, 110004 
xiaotong@mail.neu.edu.cn 
zhujingbo@mail.neu.edu.cn 
 
+Microsoft Research Asia 
Sigma Center 
Beijing, China, 100080 
muli@microsoft.com 
dozhang@microsoft.com 
mingzhou@microsoft.com 
 
  
 
Abstract 
Binarization of Synchronous Context Free 
Grammars (SCFG) is essential for achieving 
polynomial time complexity of decoding for 
SCFG parsing based machine translation sys-
tems. In this paper, we first investigate the 
excess edge competition issue caused by a left-
heavy binary SCFG derived with the method 
of Zhang et al (2006). Then we propose a new 
binarization method to mitigate the problem 
by exploring other alternative equivalent bi-
nary SCFGs. We present an algorithm that ite-
ratively improves the resulting binary SCFG, 
and empirically show that our method can im-
prove a string-to-tree statistical machine trans-
lations system based on the synchronous bina-
rization method in Zhang et al (2006) on the 
NIST machine translation evaluation tasks. 
1 Introduction 
Recently Statistical Machine Translation (SMT) 
systems based on Synchronous Context Free 
Grammar (SCFG) have been extensively investi-
gated (Chiang, 2005; Galley et al, 2004; Galley 
et al, 2006) and have achieved state-of-the-art 
performance. In these systems, machine transla-
tion decoding is cast as a synchronous parsing 
task. Because general SCFG parsing is an NP-
hard problem (Satta and Peserico, 2005), practic-
al SMT decoders based on SCFG parsing re-
quires an equivalent binary SCFG that is directly 
learned from training data to achieve polynomial 
time complexity using the CKY algorithm (Ka-
sami, 1965; Younger, 1967) borrowed from CFG 
parsing techniques. Zhang et al (2006) proposed 
synchronous binarization, a principled method to 
binarize an SCFG in such a way that both the 
source-side and target-side virtual non-terminals 
have contiguous spans. This property of syn-
chronous binarization guarantees the polynomial 
time complexity of SCFG parsers even when an 
n-gram language model is integrated, which has 
been proved to be one of the keys to the success 
of a string-to-tree syntax-based SMT system. 
However, as shown by Chiang (2007), SCFG-
based decoding with an integrated n-gram lan-
guage model still has a time complexity of  
?(?3 ? 4(??1)), where m is the source sentence 
length, and  ?  is the vocabulary size of the lan-
guage model. Although it is not exponential in 
theory, the actual complexity can still be very 
high in practice. Here is an example extracted 
from real data. Given the following SCFG rule: 
     VP   ?   VB  NP  ?  JJR  , 
               VB  NP  will be  JJR 
we can obtain a set of equivalent binary rules 
using the synchronous binarization method 
(Zhang et al, 2006)  as follows: 
        VP ? V1  JJR ,   V1  JJR 
            V1 ? VB  V2 ,   VB  V2 
        V2 ? NP ? ,   NP  will be 
This binarization is shown with the solid lines as 
binarization (a) in Figure 1. We can see that bi-
narization (a) requires that ?NP ?? should be 
reduced at first. Data analysis shows that ?NP ?? 
is a frequent pattern in the training corpus, and 
there are 874 binary rules of which the source 
language sides are ?NP ??. Consequently these 
binary rules generate a large number of compet-
ing edges in the chart when ?NP ?? is matched 
in decoding. To reduce the number of edges pro-
362
posed in decoding, hypothesis re-combination is 
used to combine the equivalent edges in terms of 
dynamic programming. Generally, two edges can 
be re-combined if they satisfy the following two 
constraints:  1) the LHS (left-hand side) non-
terminals are identical and the sub-alignments 
are the same (Zhang et al, 2006); and 2) the 
boundary words 1  on both sides of the partial 
translations are equal between the two edges 
(Chiang, 2007). However, as shown in Figure 2, 
the decoder still generates 801 edges after the 
hypothesis re-combination. As a result, aggres-
sive pruning with beam search has to be em-
ployed to reduce the search space to make the 
decoding practical. Usually in beam search only 
a very small number of edges are kept in the 
beam of each chart cell (e.g. less than 100). 
These edges have to compete with each other to 
survive from the pruning. Obviously, more com-
peting edges proposed during decoding can lead 
to a higher risk of making search errors.  
 
VB NP ? JJR
(a)(b)
V2
V1
V2'
V1'
VP
VB NP will be JJR
 
Figure 1: Two different binarizations (a) and 
(b) of the same SCFG rule distinguished by the 
solid lines and dashed lines 
 
??   ??   ??   ?   ?? ?
(We hope the situation will be better .)
??   ??   NP   ?   JJR   ?
decoding
match 874 rules match 62 rules
competing edges: 801 competing edges: 57
Figure 2: Edge competitions caused by different 
binarizations 
 
The edge competition problem for SMT de-
coding is not addressed in previous work (Zhang 
et al, 2006; Huang, 2007) in which each SCFG 
rule is binarized in a fixed way. Actually the re-
sults of synchronous binarization may not be the 
only solution. As illustrated in Figure 1, the rule 
                                                 
1 For the case of n-gram language model integration, 
2 ? (? ? 1) boundary words needs to be examined. 
can also be binarized as binarization (b) which is 
shown with the dashed lines.  
We think that this problem can be alleviated 
by choosing better binarizations for SMT decod-
ers, since there is generally more than one bina-
rization for a SCFG rule. In our investigation, 
about 96% rules that need to be binarized have 
more than one binarization under the contiguous 
constraint. As shown in binarization (b) (Figure 
1), ?? JJR? is reduced first. In the decoder, the 
number of binary rules with the source-side ?? 
JJR? is 62, and the corresponding number of 
edges is 57 (Figure 2). The two numbers are both 
much smaller than those of ?NP ?? in (a). This 
is an informative clue that the binarization (b) 
could be better than the binarization (a) based on 
the following: the probability of pruning the rule 
in (a) is higher than that in (b) as the rule in (b) 
has fewer competitors and has more chances to 
survive during pruning. 
In this paper we propose a novel binarization 
method, aiming to find better binarizations to 
improve an SCFG-based machine translation 
system. We formulate the binarization optimiza-
tion as a cost reduction process, where the cost is 
defined as the number of rules sharing a common 
source-side derivation in an SCFG. We present 
an algorithm, iterative cost reduction algorithm, 
to obtain better binarization for the SCFG learnt 
automatically from the training corpus. It can 
work with an efficient CKY-style binarizer to 
search for the lowest-cost binarization. We apply 
our method into a state-of-the-art string-to-tree 
SMT system. The experimental results show that 
our method outperforms the synchronous binari-
zation method (Zhang et al, 2006) with over 0.8 
BLEU scores on both NIST 2005 and NIST 2008 
Chinese-to-English evaluation data sets. 
2 Related Work 
The problem of binarization originates from the 
parsing problem in which several binarization 
methods are studied such as left/right binariza-
tion (Charniak et al, 1998; Tsuruoka and Tsujii, 
2004) and head binarization (Charniak et al, 
2006). Generally, the pruning issue in SMT de-
coding is unnecessary for the parsing problem, 
and the accuracy of parsing does not rely on the 
binarization method heavily. Thus, many efforts 
on the binarization in parsing are made for the 
efficiency improvement instead of the accuracy 
improvement (Song et al, 2008). 
Binarization is also an important topic in the 
research of syntax-based SMT. A synchronous 
363
binarization method is proposed in (Zhang et al, 
2006) whose basic idea is to build a left-heavy 
binary synchronous tree (Shapiro and Stephens, 
1991) with a left-to-right shift-reduce algorithm. 
Target-side binarization is another binarization 
method which is proposed by Huang (2007). It 
works in a left-to-right way on the target lan-
guage side. Although this method is compara-
tively easy to be implemented, it just achieves 
the same performance as the synchronous binari-
zation method (Zhang et al, 2006) for syntax-
based SMT systems. In addition, it cannot be 
easily integrated into the decoding of some syn-
tax-based models (Galley et al, 2004; Marcu et 
al., 2006), because it does not guarantee conti-
guous spans on the source language side. 
3 Synchronous Binarization Optimiza-
tion by Cost Reduction 
As discussed in Section 1, binarizing an SCFG in 
a fixed (left-heavy) way (Zhang et al, 2006) may 
lead to a large number of competing edges and 
consequently high risk of making search errors. 
Fortunately, in most cases a binarizable SCFG 
can be binarized in different ways, which pro-
vides us with an opportunity to find a better solu-
tion than the default left-heavy binarization. An 
ideal solution to this problem could be that we 
define an exact edge competition estimation 
function and choose the best binary SCFG based 
on it. However, even for the rules with a com-
mon source-side, generally it is difficult to esti-
mate the exact number of competing edges in the 
dynamic SCFG parsing process for machine 
translation, because in order to integrate an n-
gram language model, the actual number of 
edges not only depends on SCFG rules, but also 
depends on language model states which are spe-
cific to input sentences. Instead, we have to em-
ploy certain kinds of approximation of it. First 
we will introduce some notations frequently used 
in later discussions. 
3.1 Notations 
We use ? = {?? ?  ?? ? ?? ,??}  to denote an 
SCFG, where ??  is the ?
??  rule in ? ; ??  is the 
LHS (left hand side) non-terminal of ?? ; ??  and 
??  are the source-side and target-side RHS (right 
hand side) derivations of ??  respectively. We use 
? ?  to denote the set of equivalent binary 
SCFG of ?. The goal of SCFG binarization is to 
find an appropriate binary SCFG ?? ? ? ? . For 
?? , ? ?? = {??? } ? ?? ? ? ?  is the set of 
equivalent binary rules based on ?? , where ???  is 
the ???  binary rule in ? ?? . Figure 3 illustrates 
the meanings of these notations with a sample 
grammar. 
 
VP ?  VB NP ? JJR  ,   VB NP will be JJR
S   ?  NP ? VP  ,           NP will VP
R1 :
R2 :
G
VP ? V
12
 JJR ,    V
12
 JJR
 (R1)
G? 
V
12
 ? VB V
13
 ,     VB V
13
V
13
 ? NP ? ,       NP  will be
v
11 
:
v
12 
:
v
13 
:
S   ? V
22
 VP ,      V
22
 VP
V
22
 ? NP ? ,      NP will
v
21 
:
v
22 
:
 (R2)
binarization
...
v
11 
v
12 
v
22 
S(?VB NP ? JJR ?, G?) S(?VB NP ??, G?) S(?NP ??, G?)
L(v12)=?VB NP ??
v
13 
rule bucket
 
 
Figure 3: Binarization on a sample grammar 
 
The function ?(?) is defined to map a result-
ing binary rule ??? ??? to the sub-sequence in ??  
derived from ??? . For example, as shown in Fig-
ure 3, the binary rule ?13 covers the source sub-
sequence ?NP ?? in ?1 , so ? ?13 = "NP ?". 
Similarly, ? ?12 = "VB NP ?".  
The function ?(?) is used to group the rules in 
?? with a common right-hand side derivation for 
source language. Given a binary rule ? ? ??, we 
can put it into a bucket in which all the binary 
rules have the same source sub-sequence ?(?). 
For example (Figure 3), as ? ?12 = "VB NP ?", 
?12 is put into the bucket indexed by ?VB NP ??. 
And ?13  and ?22  are put into the same bucket, 
since they have the same source sub-sequence 
?NP ??. Obviously, ?? can be divided into a set 
of mutual exclusive rule buckets by ?(?). 
In this paper, we use ?(?(?),??) to denote the 
bucket for the binary rules having the source sub-
sequence ?(?). For example, ?("?? ?",??) de-
notes the bucket for the binary rules having the 
source-side ?NP ??. For simplicity, we also use 
?(?,??) to denote ? ? ? ,?? .  
3.2 Cost Reduction for SCFG Binarization 
Given a binary SCFG ??, it can be easily noticed 
that if a rule ? in  the bucket ?(?,??) can be ap-
plied to generate one or more new edges in 
SCFG parsing, any other rules in this bucket can 
also be applied because all of them can be re-
duced from the same underlying derivation ?(?). 
364
Each application of other rules in the bucket 
?(?,??) can generate competing edges with the 
one based on ? . Intuitively, the size of bucket 
can be used to approximately indicate the actual 
number of competing edges on average, and re-
ducing the size of bucket could help reduce the 
edges generated in a parsing chart by applying 
the rules in the bucket. Therefore, if we can find 
a method to greedily reduce the size of each 
bucket ?(?,??), we can reduce the overall ex-
pected edge competitions when parsing with ??. 
However, it can be easily proved that the 
numbers of binary rules in any ?? ? ? ?  are 
same, which implies that we cannot reduce the 
sizes of all buckets at the same time ? removing 
a rule from one bucket means adding it to anoth-
er. Allowing for this fact, the excess edge com-
petition example shown in Section 1 is essential-
ly caused by the uneven distribution of rules 
among different buckets ? ? . Accordingly, our 
optimization objective should be a more even 
distribution of rules among buckets. 
In the following, we formally define a metric 
to model the evenness of rule distribution over 
buckets. Given a binary SCFG ?? and a binary 
SCFG rule ? ? ?? , ?(?) is defined as the cost 
function that maps ?  to the size of the bucket  
? ?,?? : 
? ? =  ? ?,??   (1) 
Obviously, all the binary rules in ? ?,??  share a 
common cost value  ? ?,??  . For example (Fig-
ure 3), both ?13  and ?22  are put into the same 
bucket ? "?? ?",?? , so ? ?13 = ? ?22 = 2. 
The cost of the SCFG ??  is computed by 
summing up all the costs of SCFG rules in it: 
? ?? = ?(?)
??? ?
 (2) 
Back to our task, we are to find an equivalent 
binary SCFG ??  of ?  with the lowest cost in 
terms of the cost function ?(. ) given in Equation 
(2): 
?? = argmin???? ? ?(??) (3) 
Next we will show how ??  is related to the 
evenness of rule distribution among different 
buckets. Let ? ?? = {?1,? , ??}  be the set of 
rule buckets containing rules in ??, then the value 
of ?(??) can also be written as: 
? ?? =  ?? 
2
1????
 (4) 
Assume ?? =  ??  is an empirical distribution of a 
discrete random variable ?, then the square devi-
ation of the empirical distribution is: 
?2 =
1
?
 ( ?? ? ? )
2
?
 (5) 
Noticing that ? ?? =  ?
?   and ? =  ?? /?, Equ-
ation (5) can be written as: 
?2 =
1
?
 ? ? ? ?
 ?? 2
?
  (6) 
Since both ? and |??| are constants, minimizing 
the cost function ?(??) is equivalent to minimiz-
ing the square deviation of the distribution of 
rules among different buckets. A binary SCFG 
with the lower cost indicates the rules are more 
evenly distributed in terms of derivation patterns 
on the source language side. 
3.3 Static Cost Reduction 
Before moving on discussing the algorithm 
which can optimize Equation (3) based on rule 
costs specified in Equation (1), we first present 
an algorithm to find the optimal solution to Eq-
uation (3) if we have known the cost setting of 
?? and can use the costs as static values during 
binarization. Using this simplification, the prob-
lem of finding the binary SCFG  ?? with minim-
al costs can be reduced to find the optimal bina-
rization ??(??) for each rule ??  in ?. 
To obtain ??(??) , we can employ a CKY-
style binarization algorithm which builds a com-
pact binarization forest for the rule ??  in bottom-
up direction. The algorithm combines two adja-
cent spans of ??  each time, in which two spans 
can be combined if and only if they observe the 
BTG constraints? their translations are either 
sequentially or reversely adjacent in ?? , the tar-
get-side derivation of ?? . The key idea of this 
algorithm is that we only use the binarization tree 
with the lowest cost of each span for later com-
bination, which can avoid enumerating all the 
possible binarization trees of ??  using dynamic 
programming. 
Let ??
?
 be the sub-sequence spanning from p 
to q on the source-side, ?[?, ?] be optimal bina-
rization tree spanning ??
?
, ??[?, ?] be the cost of 
?[?, ?], and ?? [?, ?] be the cost of any binary 
rules whose source-side is ??
?
, then the cost of 
optimal binarization tree spanning ??
?
 can be 
computed as: 
??[?, ?] = min
??????1
(?? [?, ?] + ??[?,?] + ??[? + 1, ?]) 
365
The algorithm is shown as follows: 
CYK-based binarization algorithm 
Input: a SCFG rule ??  and the cost function ?(. ).  
Output: the lowest cost binarization on ??  
1:  Function CKYBINARIZATION(?? , ?) 
2:      for l = 2 to n do  ?  Length of span 
3:        for p = 1 to n ? l + 1 do ?  Start of span 
4:               q = p + l  ?  End of span 
5:             for k = p to q ? 1 do ?  Partition of span  
6:               if not CONSECUTIVE(? ?, ? , ? ? + 1,? )  
                         then next loop 
7:                   ?? [?, ?] ? ?(??
?)    
8:                   curCost ? ?? ?, ? +?? ?, ? +??[? + 1,?] 
9:                 if curCost  <  minCost then 
10:                   minCost ? curCost 
11:                    ?[?, ?] ? COMBINE(?[?, ?], ?[? + 1,?]) 
12:             ?? ?, ?  ? minCost 
13:    return ?[1,?]     
14: Function CONSECUTIVE(( a, b), (c, d)) 
15:    return (b = c ? 1) or (d = a ? 1)   
where n is the number of tokens (consecutive 
terminals are viewed as a single token) on the 
source-side of ?? . COMBINE(?[?, ?], ?[? + 1,?]) 
combines the two binary sub-trees into a larger 
sub-tree over ??
?
. ? ?, ? = (?, ?) means that the 
non-terminals covering ??
?
 have the consecutive 
indices ranging from a to b on the target-side. If 
the target non-terminal indices are not consecu-
tive, we set ? ?, ? = (?1,?1). ? ??
?
 = ?(??) 
where ?? is any rule in the bucket ? ??
? ,?? . 
In the algorithm, lines 9-11 implement dynam-
ic programming, and the function CONSECUTIVE 
checks whether the two spans can be combined. 
VB NP ?
V[1,2] V[3,4]
VP
JJR
V[2,3]
V[1,3] V[2,4]
c=6619 c=874 c=62
c=884 c=876 c=64c=6629
c=885
c=6682
c=65
VB NP will be JJR
lowest cost
c=0 c=0 c=0 c=0
 
Figure 4: Binarization forest for an SCFG rule 
 
?(?) ?(?) ?(?) ?(?) 
 VB NP 6619 VB NP ? 10 
 NP ? 874 NP ? JJR 2 
 ? JJR 62 VB NP ? JJR 1 
Table 1: Sub-sequences and corresponding costs 
Figure 4 shows an example of the compact 
forest the algorithm builds, where the solid lines 
indicate the optimal binarization of the rule, 
while other alternatives pruned by dynamic pro-
gramming are shown in dashed lines. The costs 
for binarization trees are computed based on the 
cost table given in Table 1. 
The time complexity of the CKY-based bina-
rization algorithm is ?(n3), which is higher than 
that of the linear binarization such as the syn-
chronous binarization (Zhang et al, 2006). But it 
is still efficient enough in practice, as there are 
generally only a few tokens (n < 5) on the 
source-sides of SCFG rules. In our experiments, 
the linear binarization method is just 2 times 
faster than the CKY-based binarization. 
3.4 Iterative Cost Reduction 
However, ?(?) cannot be easily predetermined in 
a static way as is assumed in Section 3.3 because 
it depends on ?? and should be updated whenever 
a rule in ? is binarized differently. In our work 
this problem is solved using the iterative cost 
reduction algorithm, in which the update of ?? 
and the cost function ?(?) are coupled together. 
Iterative cost reduction algorithm 
Input: An SCFG ? 
Output: An equivalent binary SCFG ?? of ? 
1: Function ITERATIVECOSTREDUCTION(?) 
2:   ?? ? ?0 
3:   for each ? ? ?0do 
4:        ?(?) =  ? ?,?0   
5:   while ?(??) does not converge do 
6:        for each ?? ? ? do 
7:            ?[???] ? ?? ?  ?(??) 
8:            for each ? ? ?(??) do 
9:                for each ?? ? ? ?,??  do 
10:                  ? ?? ? ? ?? ? 1 
11:          ?(??) ? CKYBINARIZATION(?? , ?) 
12:          ?? ? ?[???] ?  ?(??) 
13:          for each ? ? ?(??) do 
14:              for each ?? ? ? ?,??  do 
15:                  ? ?? ? ? ?? + 1 
16: return ?? 
In the iterative cost reduction algorithm, we 
first obtain an initial binary SCFG ?0 using the 
synchronous binarization method proposed in 
(Zhang et al, 2006). Then ?0 is assigned to an 
iterative variable ??. The cost of each binary rule 
in ?0 is computed based on ?0 according to Equ-
ation (1) (lines 3-4 in the algorithm). 
After initialization, ?? is updated by iteratively 
finding better binarization for each rule in ?. The 
basic idea is: for each ??  in ? , we remove the 
current binarization result for ??  from ?? (line 7), 
while the cost function ?(?)  is updated accor-
dingly since the removal of binary rule ? ? 
?(??) results in the reduction of the size of the 
corresponding bucket ? ?,?? . Lines 8-10 im-
366
plement the cost reduction of each binary rule in 
the bucket ? ?,? ? . 
Next, we find the lowest cost binarization for 
??  based on the updated cost function ?(?) with 
the CKY-based binarization algorithm presented 
in Section 3.3 (line 11).  
At last, the new binarization for ??  is added 
back to ?? and ?(?) is re-updated to synchronize 
with this change (lines 12-15). Figure 5 illu-
strates the differences between the static cost 
reduction and the iterative cost reduction. 
Ri
Ri-1
Ri+1
...
...
the i
th
 
rule
G
binarizer
Q(?)
binarize
(a) static cost reduction
Ri
Ri-1
Ri+1
...
...
the i
th
 
rule
G
binarizer
Q(?)
G0
(b) iterative cost reduction
update
static
dynamic
binarize
 
Figure 5: Comparison between the static cost 
reduction and the iterative cost reduction 
 
The algorithm stops when ?(??) does not de-
crease any more. Next we will show that ?(??)  
is guaranteed not to increase in the iterative 
process. 
For any ?(??) on ?? , we have 
               ?  ?[???] ?  ? ??   
        = 2 ? ? ? ??  +  ? ??  + ? ?[???]  
As both  ? ??   and ? ?[???]  are constants with 
respect to ?(? ?? ), ?  ?[???] ?  ? ??   is a li-
near function of ?(? ?? ), and the correspond-
ing slope is positive. Thus ?  ?[???] ?  ? ??   
reaches the lowest value only when ?(? ?? ) 
reaches the lowest value. So ?  ?[???] ?  ? ??   
achieves the lowest cost when we replace the 
current binarization with the new binarization  
??(??)  (line 12). Therefore ?  ?[???] ?  ? ??   
does not increase in the processing on each ??  
(lines 7-15), and ?(??) will finally converge to a 
local minimum when the algorithm stops. 
4 Experiments 
The experiments are conducted on Chinese-to-
English translation in a state-of-the-art string-to-
tree SMT system. All the results are reported in 
terms of case-insensitive BLEU4(%). 
4.1 Experimental Setup 
Our bilingual training corpus consists of about 
350K bilingual sentences (9M Chinese words + 
10M English words)2 . Giza++ is employed to 
perform word alignment on the bilingual sen-
tences. The parse trees on the English side are 
generated using the Berkeley Parser3. A 5-gram 
language model is trained on the English part of 
LDC bilingual training data and the Xinhua part 
of Gigaword corpus. Our development data set 
comes from NIST2003 evaluation data in which 
the sentences of more than 20 words are ex-
cluded to speed up the Minimum Error Rate 
Training (MERT). The test data sets are the 
NIST evaluation sets of 2005 and 2008. 
Our string-to-tree SMT system is built based 
on the work of (Galley et al, 2006; Marcu et al, 
2006), where both the minimal GHKM and 
SPMT rules are extracted from the training cor-
pus, and the composed rules are generated by 
combining two or three minimal GHKM and 
SPMT rules. Before the rule extraction, we also 
binarize the parse trees on the English side using 
Wang et al (2007) ?s method to increase the 
coverage of GHKM and SPMT rules. There are 
totally 4.26M rules after the low frequency rules 
are filtered out. The pruning strategy is similar to 
the cube pruning described in (Chiang, 2007). To 
achieve acceptable translation speed, the beam 
size is set to 50 by default. The baseline system 
is based on the synchronous binarization (Zhang 
et al, 2006).  
4.2 Binarization Schemes 
Besides the baseline (Zhang et al, 2006) and 
iterative cost reduction binarization methods, we 
also perform right-heavy and random synchron-
ous binarizations for comparison. In this paper, 
the random synchronous binarization is obtained 
by: 1) performing the CKY binarization to build 
the binarization forest for an SCFG rule; then 2) 
performing a top-down traversal of the forest. In 
the traversal, we randomly pick a feasible binari-
zation for each span, and then go on the traversal 
in the two branches of the picked binarization. 
Table 2 shows the costs of resulting binary 
SCFGs generated using different binarization 
methods. The costs of the baseline (left-heavy) 
                                                 
2 LDC2003E14, LDC2003E07, LDC2005T06 and 
LDC2005T10 
3 http://code.google.com/p/berkeleyparser/ 
367
and right-heavy binarization are similar, while 
the cost of the random synchronous binarization 
is lower than that of the baseline method4. As 
expected, the iterative cost reduction method ob-
tains the lowest cost, which is much lower than 
that of the other three methods.  
 
Method cost of binary SCFG ?? 
Baseline 4,897M 
Right-heavy 5,182M 
Random 3,479M 
Iterative cost reduction    185M 
Table 2: Costs of the binary SCFGs generated 
using different binarization methods. 
4.3 Evaluation of Translations 
Table 3 shows the performance of SMT systems 
based on different binarization methods. The 
iterative cost reduction binarization method 
achieves the best performance on the test sets as 
well as the development set. Compared with the 
baseline method, it obtains gains of 0.82 and 
0.84 BLEU scores on NIST05 and NIST08 test 
sets respectively. Using the statistical signific-
ance test described by Koehn (2004), the im-
provements are significant  (p < 0.05). 
 
Method Dev NIST05 NIST08 
Baseline 40.02 37.90 27.53  
Right-heavy 40.05 37.87 27.40 
Random 40.10 37.99 27.58 
Iterative cost 
reduction 
40.97* 38.72* 28.37* 
Table 3: Performance (BLUE4(%)) of different 
binarization methods. * = significantly better than 
baseline (p < 0.05).  
 
The baseline method and the right-heavy bina-
rization method achieve similar performance, 
while the random synchronous binarization me-
thod performs slightly better than the baseline 
method, which agrees with the fact of the cost 
reduction shown in Table 2. A possible reason 
that the random synchronous binarization me-
thod can outperform the baseline method lies in 
that compared with binarizing SCFG in a fixed 
way, the random synchronous binarization tends 
to give a more even distribution of rules among 
buckets, which alleviates the problem of edge 
competition. However, since the high-frequency 
source sub-sequences still have high probabilities 
to be generated in the binarization and lead to the 
                                                 
4 We perform random synchronous binarization for 5 
times and report the average cost. 
excess competing edges, it just achieves a very 
small improvement. 
4.4 Translation Accuracy vs. Cost of Binary 
SCFG 
We also study the impacts of cost reduction on 
translation accuracy over iterations in iterative 
cost reduction. Figure 6 and Figure 7 show the 
results on NIST05 and NIST08 test sets. We can 
see that the cost of the resulting binary SCFG 
drops greatly as the iteration count increases, 
especially in the first iteration, and the BLEU 
scores increase as the cost decreases. 
 
Figure 6: Cost of binary SCFG vs. BLEU4 (NIST05) 
 
 
Figure 7: Cost of binary SCFG vs. BLEU4 (NIST08) 
4.5 Impact of Beam Size 
In this section, we study the impacts of beam 
sizes on translation accuracy as well as compet-
ing edges. To explicitly investigate the issue un-
der large beam sizes, we use a subset of NIST05 
and NIST08 test sets for test, which has 50 Chi-
nese sentences of no longer than 10 words. 
Figure 8 shows that the iterative cost reduction 
method is consistently better than the baseline 
method under various beam settings. Besides the 
experiment on the test set of short sentences, we 
also conduct the experiment on NIST05 test set. 
To achieve acceptable decoding speed, we range 
the beam size from 10 to 70. As shown in Figure 
9, the iterative cost reduction method also out-
performs the baseline method under various 
beam settings on the large test set. 
Though enlarging beam size can reduce the 
search errors and improve the system perfor-
mance, the decoding speed of string-to-tree SMT 
drops dramatically when we enlarge the beam 
size. The problem is more serious when long 
1.0E+08
1.0E+09
1.0E+10
37.8
38
38.2
38.4
38.6
38.8
0 1 2 3 4 5
performance(BLEU4) cost
iteration
BLEU4(%) cost of G'
1.0E+08
1.0E+09
1.0E+10
27.4
27.6
27.8
28
28.2
28.4
0 1 2 3 4 5
performance(BLEU4) cost
BLEU4(%) cost of G'
iteration
368
sentences are translated. For example, when the 
beam size is set to a larger number (e.g. 200), our 
decoder takes nearly one hour to translate a sen-
tence whose length is about 20 on a 3GHz CPU. 
Decoding on the entire NIST05 and NIST08 test 
sets with large beam sizes is impractical. 
 
Figure 8: BLEU4 against beam size (small test set) 
 
 
Figure 9: BLEU4 against beam size (NIST05) 
 
Figure 10 compares the baseline method and 
the iterative cost reduction method in terms of 
translation accuracy against the number of edges 
proposed during decoding. Actually, the number 
of edges proposed during decoding can be re-
garded as a measure of the size of search space. 
We can see that the iterative cost reduction me-
thod outperforms the baseline method under var-
ious search effort.  
 
Figure 10: BLEU4 against competing edges  
 
The experimental results of this section show 
that compared with the baseline method, the iter-
ative cost reduction method can lead to much 
fewer edges (about 25% reduction) as well as the 
higher BLEU scores under various beam settings. 
4.6 Edge Competition vs. Cost of Binary 
SCFG 
In this section, we study the impacts of cost re-
duction on the edge competition in the chart cells 
of our CKY-based decoder. Two metrics are 
used to evaluate the degree of edge competition. 
They are the variance and the mean of the num-
ber of competing edges in the chart cells, where 
high variance means that in some chart cells the 
rules have high risk to be pruned due to the large 
number of competing edges. The same situation 
holds for the mean as well. Both of the two me-
trics are calculated on NIST05 test set, varying 
with the span length of chart cell. 
Figure 11 shows the cost of resulting binary 
SCFG and the variance of competing edges 
against iteration count in iterative cost reduction. 
We can see that both the cost and the variance 
reduce greatly as the iteration count increases. 
Figure 12 shows the case for mean, where the 
reduction of cost also leads to the reduction of 
the mean value. The results shown in Figure 11 
and Figure 12 indicate that the cost reduction is 
helpful to reduce edge competition in the chart 
cells.  
 
Figure 11: Cost of binary SCFG vs. variance of 
competing edge number (NIST05) 
 
 
Figure 12: Cost of binary SCFG vs. mean of 
competing edge number (NIST05) 
 
We also perform decoding without pruning 
(i.e. beam size = ?) on a very small set which 
has 20 sentences of no longer than 7 words. In 
this experiment, the baseline system and our iter-
ative cost reduction based system propose 
14,454M and 10,846M competing edges respec-
tively. These numbers can be seen as the real 
numbers of the edges proposed during decoding 
instead of an approximate number observed in 
the pruned search space. It suggests that our me-
thod can reduce the number of the edges in real 
search space effectively. A possible reason to 
32
34
36
38
40
42
10 50 100 500 1000 5000
baseline
cost reduction
BLEU4(%)
beam 
size 
35
36
37
38
39
10 20 30 40 50 70
baseline
cost reduction
beam
size
BLEU4(%)
32
34
36
38
40
42
1E+07 1E+08 1E+09 1E+10
baseline
cost reduction
BLEU4(%)
# of
edges
1.0E+5
1.0E+6
1.0E+7
1.0E+8
1.0E+9
1.0E+10
1.0E+7
1.0E+8
1.0E+9
1.0E+10
0 1 2 3 4 5
span=2
span=3
span=5
span=7
span=10
span=20
cost
iteration
variance cost of G'
1.0E+6
1.0E+7
1.0E+8
1.0E+9
1.0E+10
8.0E+3
1.0E+5
0 1 2 3 4 5
span=2
span=3
span=5
span=7
span=10
span=20
cost
iteration
mean cost of G'
369
this result is that the cost reduction based binari-
zation could reduce the probability of rule mis-
matching caused by binarization, which results in 
the reduction of the number of edges proposed 
during decoding. 
5 Conclusion and Future Work 
This paper introduces a new binarization method, 
aiming at choosing better binarization for SCFG-
based SMT systems. We demonstrate the effec-
tiveness of our method on a state-of-the-art 
string-to-tree SMT system. Experimental results 
show that our method can significantly outper-
form the conventional synchronous binarization 
method, which indicates that better binarization 
selection is very beneficial to SCFG-based SMT 
systems. 
In this paper the cost of a binary rule is de-
fined based on the competition among the binary 
rules that have the same source-sides. However, 
some binary rules with different source-sides 
may also have competitions in a chart cell. We 
think that the cost of a binary rule can be better 
estimated by taking the rules with different 
source-sides into account. We intend to study 
this issue in our future work. 
Acknowledgements 
The authors would like to thank the anonymous 
reviewers for their pertinent comments, and Xi-
nying Song, Nan Duan and Shasha Li for their 
valuable suggestions for improving this paper. 
References 
Eugene Charniak,  Mark Johnson, Micha Elsner, Jo-
seph Austerweil, David Ellis, Isaac Haxton, Cathe-
rine Hill, R. Shrivaths, Jeremy Moore, Michael Po-
zar, and Theresa Vu. 2006. Multilevel Coarse-to-
Fine PCFG Parsing. In Proc. of HLT-NAACL 2006, 
New York, USA, 168-175.  
Eugene Charniak, Sharon Goldwater, and Mark John-
son. 1998. Edge-Based Best-First Chart Parsing. In 
Proc. of the Six Workshop on Very Large Corpora, 
pages: 127-133. 
David Chiang. 2005. A Hierarchical Phrase-Based 
Model for Statistical Machine Translation. In Proc. 
of ACL 2005, Ann Arbor, Michigan, pages: 263-
270. 
David Chiang. 2007. Hierarchical Phrase-based 
Translation. Computational Linguistics. 33(2): 
202-208. 
Michel Galley, Jonathan Graehl, Kevin Knight, Da-
niel Marcu, Steve DeNeefe, Wei Wang, and Igna-
cio Thayer. 2006. Scalable Inference and Training 
of Context-Rich Syntactic Translation Models. In 
Proc. of ACL 2006, Sydney, Australia, pages: 961-
968. 
Michel Galley, Mark Hopkins, Kevin Knight, and 
Daniel Marcu. 2004. What?s in a translation rule? 
In Proc. of HLT-NAACL 2004, Boston, USA, pag-
es: 273-280. 
Liang Huang. 2007. Binarization, Synchronous Bina-
rization, and Target-side binarization.  In Proc. of 
HLT-NAACL 2007 / AMTA workshop on Syntax 
and Structure in Statistical Translation, New York, 
USA, pages: 33-40. 
Tadao Kasami. 1965. An Efficient Recognition and 
Syntax Analysis Algorithm for Context-Free Lan-
guages. Technical Report AFCRL-65-758, Air 
Force Cambridge Research Laboratory, Bedford, 
Massachusetts. 
Philipp Koehn. 2004. Statistical Significance Tests for 
Machine Translation Evaluation. In Proc. of 
EMNLP 2004, Barcelona, Spain , pages: 388?395. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language phras-
es. In Proc. of EMNLP 2006, Sydney, Australia, 
pages: 44-52. 
Giorgio Satta and Enoch Peserico. 2005. Some Com-
putational Complexity Results for Synchronous 
Context-Free Grammars. In Proc. of HLT-EMNLP 
2005, Vancouver, pages: 803-810. 
L. Shapiro and A. B. Stephens. 1991. Bootstrap per-
colation, the Sch? oder numbers, and the n-kings 
problem. SIAM Journal on Discrete Mathematics, 
4(2):275-280. 
Xinying Song, Shilin Ding and Chin-Yew Lin. 2008. 
Better Binarization for the CKY Parsing. In Proc. 
of EMNLP 2008, Hawaii, pages: 167-176. 
Yoshimasa Tsuruoka and Junichi Tsujii. 2004. Itera-
tive CKY Parsing for Probabilistic Context-Free 
Grammars. In Proc. of IJCNLP 2004, pages: 52-
60. 
Wei Wang  and  Kevin Knight and Daniel Marcu. 
2007. Binarizing Syntax Trees to Improve Syntax-
Based Machine Translation Accuracy. In Proc. of 
EMNLP-CoNLL 2007, Prague, Czech Republic, 
pages: 746-754. 
D. H. Younger. 1967. Recognition and Parsing of 
Context-Free Languages in Time n3. Information 
and Control, 10(2):189-208. 
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin 
Knight. 2006. Synchronous Binarization for Ma-
chine Translation. In Proc. of HLT-NAACL 2006, 
New York, USA, pages: 256- 263. 
370
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1096?1104,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
The Feature Subspace Method for SMT System Combination 
 
Nan Duan1, Mu Li2, Tong Xiao3, Ming Zhou2 
  1Tianjin University       2Microsoft Research Asia       3Northeastern University 
     Tianjin, China                    Beijing, China                     Shenyang, China 
{v-naduan,muli,v-toxiao,mingzhou}@microsoft.com 
 
 
Abstract 
Recently system combination has been shown 
to be an effective way to improve translation 
quality over single machine translation sys-
tems. In this paper, we present a simple and ef-
fective method to systematically derive an en-
semble of SMT systems from one baseline li-
near SMT model for use in system combina-
tion. Each system in the resulting ensemble is 
based on a feature set derived from the fea-
tures of the baseline model (typically a subset 
of it). We will discuss the principles to deter-
mine the feature sets for derived systems, and 
present in detail the system combination mod-
el used in our work. Evaluation is performed 
on the data sets for NIST 2004 and NIST 2005 
Chinese-to-English machine translation tasks. 
Experimental results show that our method can 
bring significant improvements to baseline 
systems with state-of-the-art performance. 
1 Introduction 
Research on Statistical Machine Translation 
(SMT) has shown substantial progress in recent 
years. Since the success of phrase-based methods 
(Och and Ney, 2004; Koehn, 2004), models 
based on formal syntax (Chiang, 2005) or lin-
guistic syntax (Liu et al, 2006; Marcu et al, 
2006) have also achieved state-of-the-art perfor-
mance. As a result of the increasing numbers of 
available machine translation systems, studies on 
system combination have been drawing more and 
more attention in SMT research. 
 There have been many successful attempts to 
combine outputs from multiple machine transla-
tion systems to further improve translation quali-
ty. A system combination model usually takes n-
best translations of single systems as input, and 
depending on the combination strategy, different 
methods can be used. Sentence-level combina-
tion methods directly select hypotheses from 
original outputs of single SMT systems (Sim et 
al., 2007; Hildebrand and Vogel, 2008), while 
phrase-level or word?level combination methods 
are more complicated and could produce new 
translations different from any translations in the 
input (Bangalore et al, 2001; Jayaraman and La-
vie, 2005; Matusov et al, 2006; Sim et al, 
2007). 
 Among all the factors contributing to the suc-
cess of system combination, there is no doubt 
that the availability of multiple machine transla-
tion systems is an indispensable premise. Al-
though various approaches to SMT system com-
bination have been explored, including enhanced 
combination model structure (Rosti et al, 2007), 
better word alignment between translations 
(Ayan et al, 2008; He et al, 2008) and improved 
confusion network construction (Rosti et al, 
2008), most previous work simply used the en-
semble of SMT systems based on different mod-
els and paradigms at hand and did not tackle the 
issue of how to obtain the ensemble in a prin-
cipled way. To our knowledge the only work 
discussed this problem is Macherey and Och 
(2007), in which they experimented with build-
ing different SMT systems by varying one or 
more sub-models (i.e. translation model or dis-
tortion model) of an existing SMT system, and 
observed that changes in early-stage model train-
ing introduced most diversities in translation 
outputs.  
In this paper, we address the problem of build-
ing an ensemble of diversified machine transla-
tion systems from a single translation engine for 
system combination. In particular, we propose a 
novel Feature Subspace method for the ensemble 
construction based on any baseline SMT model 
which can be formulated as a standard linear 
function. Each system within the ensemble is 
based on a group of features directly derived 
from the baseline model with minimal efforts 
(which is typically a subset of the features used 
in the baseline model), and the resulting system 
is optimized in the derived feature space accor-
dingly. 
We evaluated our method on the test sets for 
NIST 2004 and NIST 2005 Chinese-to-English 
1096
machine translation tasks using two baseline 
SMT systems with state-of-the-art performance. 
Experimental results show that the feature sub-
space method can bring significant improve-
ments to both baseline systems. 
The rest of the paper is organized as follows. 
The motivation of our work is described on Sec-
tion 2. In Section 3, we first give a detailed de-
scription about feature subspace method, includ-
ing the principle to select subspaces from all 
possible options, and then an n-gram consensus ?
based sentence-level system combination method 
is presented. Experimental results are given in 
Section 4. Section 5 discusses some related is-
sues and concludes the paper. 
2 Motivation 
Our motivations for this work can be described 
in the following two aspects. 
The first aspect is related to the cost of build-
ing single systems for system combination. In 
previous work, the SMT systems used in combi-
nation differ mostly in two ways. One is the un-
derlying models adopted by individual systems. 
For example, using an ensemble of systems re-
spectively based on phrase-based models, hierar-
chical models or even syntax-based models is a 
common practice. The other is the methods used 
for feature function estimation such as using dif-
ferent word alignment models, language models 
or distortion models. For the first solution, build-
ing a new SMT system with different methodol-
ogy is by no means an easy task even for an ex-
perienced SMT researcher, because it requires 
not only considerable effects to develop but also 
plenty of time to accumulate enough experiences 
to fine tune the system. For the second alterna-
tive, usually it requires time-consuming re-
training for word alignment or language models. 
Also some of the feature tweaking in this solu-
tion is system or language specific, thus for any 
new systems or language pairs, human engineer-
ing has to be involved. For example, using dif-
ferent word segmentation methods for Chinese 
can generate different word alignment results, 
and based on which a new SMT system can be 
built. Although this may be useful to combina-
tion of Chinese-to-English translation, it is not 
applicable to most of other language pairs. 
Therefore it will be very helpful if there is a 
light-weight method that enables the SMT sys-
tem ensemble to be systematically constructed 
based on an existing SMT system. 
 
Source 
sentence 
?? ?? ?? ? ?? ?? 
?? ?? ?? 
Ref 
translation 
China's largest sea water desalini-
zation project settles in Zhoushan 
Default 
translation 
China 's largest desalination  
project in Zhoushan 
??????  
translation 
China 's largest sea water  
desalination project in Zhoushan 
Table 1: An example of translations generated 
from the same decoder but with different feature 
settings. 
 Chinese English ? ? ?  
1 ?? ?? desalination 0.4000 
2 ?? sea water 0.1748 
3 ?? desalination 0.0923 
Table 2: Parameters of related phrases for exam-
ples in Table 1. 
The second aspect motivating our work comes 
from the subspace learning method in machine 
learning literature (Ho, 1998), in which an en-
semble of classifiers are trained on subspaces of 
the full feature space, and final classification re-
sults are based on the vote of all classifiers in the 
ensemble. Lopez and Resnik (2006) also showed 
that feature engineering could be used to over-
come deficiencies of poor alignment. To illu-
strate the usefulness of feature subspace in the 
SMT task, we start with the example shown in 
Table 1. In the example, the Chinese source sen-
tence is translated with two settings of a hierar-
chical phrase-based system (Chiang, 2005). In 
the default setting all the features are used as 
usual in the decoder, and we find that the transla-
tion of the Chinese word ??  (sea water) is 
missing in the output. This can be explained with 
the data shown in Table 2. Because of noises and 
word alignment errors in the parallel training 
data, the inaccurate translation phrase 
?? ?? ? ????????????  is assigned with a 
high value of the phrase translation probability 
feature ?(?|?). Although the correct translation 
can also be composed by two phrases ?? ?
??? ????? and ?? ? ????????????, its over-
all translation score cannot beat the incorrect one 
because the combined phrase translation proba-
bility of these two phrases are much smaller 
than  ?(????????????|?? ??) . However, if 
we intentionally remove the ?(?|?) feature from 
the model, the preferred translation can be gener-
ated as shown in the result of ??????  because in 
1097
this way the bad estimation of ?(?|?)  for this 
phrase is avoided. 
This example gives us the hint that building 
decoders based on subspaces of a standard model 
could help with working around some negative 
impacts of inaccurate estimations of feature val-
ues for some input sentences. The subspace-
based systems are expected to work similarly to 
statistical classifiers trained on subspaces of a 
full feature space ? though the overall accuracy 
of baseline system might be better than any indi-
vidual systems, for a specific sentence some in-
dividual systems could generate better transla-
tions. It is expected that employing an ensemble 
of subspace-based systems and making use of 
consensus between them will outperform the 
baseline system. 
3 Feature Subspace Method for SMT 
System Ensemble Construction 
In this section, we will present in detail the me-
thod for systematically deriving SMT systems 
from a standard linear SMT model based on fea-
ture subspaces for system combination. 
3.1 SMT System Ensemble Generation 
Nowadays most of the state-of-the-art SMT sys-
tems are based on linear models as proposed in 
Och and Ney (2002). Let ?? (?, ?) be a feature 
function, and ??  be its weight, an SMT model ? 
can be formally written as: 
?? = argmax
?
 ???? (?, ?)
?
 (1) 
Noticing that Equation (1) is a general formu-
lation independent of any specific features, tech-
nically for any subset of features used in ? , a 
new SMT system can be constructed based on it, 
which we call a sub-system. 
Next we will use ? to denote the full feature 
space defined by the entire set of features used 
in ?, and ? ? ? is a feature subset that belongs 
to ?(?), the power set of ?. The derived sub-
system based on subset ? ? ? is denoted by ?? . 
Although in theory we can use all the sub-
systems derived from every feature subset 
in ?(?), it is still desirable to use only some of 
them in practice. The reasons for this are two-
fold. First, the number of possible sub-systems 
(2 ? ) is exponential to the size of ?. Even when 
the number of features in ? is relatively small, 
i.e. 10, there will be up to 1024 sub-systems in 
total, which is a large number for combination 
task. Larger feature sets will make the system 
combination practically infeasible. Second, not 
every sub-system could contribute to the system 
combination. For example, feature subsets only 
containing very small number of features will 
lead to sub-systems with very poor performance; 
and the language model feature is too important 
to be ignored for a sub-system to achieve reason-
ably good performance. 
In our work, we only consider feature sub-
spaces with only one difference from the features 
in ?. For each non- language model feature ?? , a 
sub-system ??  is built by removing ??  from  ? . 
Allowing for the importance of the language 
model (LM) feature to an SMT model, we do not 
remove any LM feature from any sub-system. 
Instead, we try to weaken the strength of a LM 
feature by lowering its n-gram order. For exam-
ple, if a 4-gram language model is used in the 
baseline system ?, then a trigram model can be 
used in one sub-system, and a bigram model can 
be used in another. In this way more than one 
sub-system can be derived based on one LM fea-
ture. When varying a language model feature, the 
one-feature difference principle is still kept: if 
we lower the order of a language model feature, 
no other features are removed or changed.  
The remaining issue of using weakened LM 
features is that the resulting ensemble is no long-
er strictly based on subspace of ?. However, this 
theoretical imperfection can be remedied by in-
troducing ?? , a super-space of ? to include all 
lower-order LM features. In this way, an aug-
mented baseline system ??  can be built based 
on  ?? , and the baseline system ? itself can also 
be viewed as a sub-system of ??. We will show 
in the experimental section that ??  actually per-
forms even slightly better than the original base-
line system ?, but results of sub-system combi-
nation are significantly better that both ? and ?? . 
After the sub-system ensemble is constructed, 
each sub-system tunes its feature weights inde-
pendently to optimize the evaluation metrics on 
the development set. 
Let ? = {?1 ,? ,??} be the set of sub-systems 
obtained by either removing one non-LM feature 
or changing the order of a LM feature, and ??  be 
the n-best list produced by ?? . Then ?(?), the 
translation candidate pool to the system combi-
nation model can be written as: 
?(?) = ??
?
 (2) 
The advantage of this method is that it allows 
us to systematically build an ensemble of SMT 
systems at a very low cost. From the decoding 
1098
perspective, all the sub-systems share a common 
decoder, with minimal extensions to the baseline 
systems to support the use of specified subset of 
feature functions to compute the overall score for 
translation hypotheses. From the model training 
perspective, all the non-LM feature functions can 
be estimated once for all sub-systems. The only 
exception is the language model feature, which 
may be of different values across multiple sub-
systems. However, since lower-order models 
have already been contained in higher-order 
model for the purpose of smoothing in almost all 
statistical language model implementations, there 
is also no extra training cost. 
3.2 System Combination Scheme 
In our work, we use a sentence-level system 
combination model to select best translation hy-
pothesis from the candidate pool  ?(?) . This 
method can also be viewed to be a hypotheses re-
ranking model since we only use the existing 
translations instead of performing decoding over 
a confusion network as done in the word-level 
combination method (Rosti et al, 2007). 
The score function in our combination model 
is formulated as follows: 
?? = ??????
??? ? 
?????? ? + ??? + ?(?,?(?)) 
(3) 
where ??? ?  is the language model score for ?, 
? is the length of ?, and ?(?,?(?)) is a transla-
tion consensus ?based scoring function. The 
computation of ?(?,?(?))  is further decom-
posed into weighted linear combination of a set 
of n-gram consensus ?based features, which are 
defined in terms of the order of n-gram to be 
matched between current candidate and other 
translation in ?(?). 
Given a translation candidate  ? , the n-gram 
agreement feature between ?  and other transla-
tions in the candidate pool is defined as: 
??
+(?,? ? ) =  ?? ?, ?
? 
? ? ?? ? ,? ???
 (4) 
where the function  ?? ?, ?
?  counts the occur-
rences of n-grams of ? in ? ? : 
?? ?, ?
? = ?(??
?+??1, ? ?)
 ? ??+1
?=1
 (5) 
    Here ?(?,?)  is the indicator function - 
? ??
?+??1 , ? ?  is 1 when the n-gram ??
?+??1  ap-
pears in ? ? , otherwise it is 0. 
In order to give the combination model an op-
portunity to penalize long but inaccurate transla-
tions, we also introduce a set of n-gram disa-
greement features in the combination model: 
??
?(?,? ? ) =  ( ? ? ? + 1? ??(?, ?
?))
? ? ?? ? ,? ???
 
(6) 
Because each order of n-gram match introduc-
es two features, the total number of features in 
the combination model will be 2? + 2 if ? or-
ders of n-gram are to be matched in computing 
?(?,?(?)). Since we also adopt a linear scor-
ing function in Equation (3), the feature weights 
of our combination model can also be tuned on a 
development data set to optimize the specified 
evaluation metrics using the standard Minimum 
Error Rate Training (MERT) algorithm (Och 
2003). 
Our method is similar to the work proposed by 
Hildebrand and Vogel (2008). However, except 
the language model and translation length, we 
only use intra-hypothesis n-gram agreement fea-
tures as Hildebrand and Vogel did and use addi-
tional intra-hypothesis n-gram disagreement fea-
tures as Li et al (2009) did in their co-decoding 
method. 
4 Experiments 
4.1 Data 
Experiments were conducted on the NIST evalu-
ation sets of 2004 (MT04) and 2005 (MT05) for 
Chinese-to-English translation tasks. Both corpo-
ra provide 4 reference translations per source 
sentence. Parameters were tuned with MERT 
algorithm (Och, 2003) on the NIST evaluation 
set of 2003 (MT03) for both the baseline systems 
and the system combination model. Translation 
performance was measured in terms of case-
insensitive NIST version of BLEU score which 
computes the brevity penalty using the shortest 
reference translation for each segment, and all 
the results will be reported in percentage num-
bers. Statistical significance is computed using 
the bootstrap re-sampling method proposed by 
Koehn (2004). Statistics of the data sets are 
summarized in Table 3. 
 
Data set #Sentences #Words 
MT03 (dev) 919 23,782 
MT04 (test) 1,788 47,762 
MT05 (test) 1,082 29,258 
Table 3: Data set statistics. 
1099
We use the parallel data available for the 
NIST 2008 constrained track of Chinese-to-
English machine translation task as bilingual 
training data, which contains 5.1M sentence 
pairs, 128M Chinese words and 147M English 
words after pre-processing. GIZA++ toolkit (Och 
and Ney, 2003) is used to perform word align-
ment in both directions with default settings, and 
the intersect-diag-grow method is used to gener-
ate symmetric word alignment refinement. The 
language model used for all systems is a 5-gram 
model trained with the English part of bilingual 
data and Xinhua portion of LDC English Giga-
word corpus version 3. In experiments, multiple 
language model features with the order ranging 
from 2 to 5 can be easily obtained from the 5-
gram one without retraining. 
4.2 System Description 
Theoretically our method is applicable to all li-
near model ?based SMT systems. In our experi-
ments, two in-house developed systems are used 
to validate our method. The first one (SYS1) is a 
system based on the hierarchical phrase-based 
model as proposed in (Chiang, 2005). Phrasal 
rules are extracted from all bilingual sentence 
pairs, while hierarchical rules with variables are 
extracted from selected data sets including 
LDC2003E14, LDC2003E07, LDC2005T06 and 
LDC2005T10, which contain around 350,000 
sentence pairs, 8.8M Chinese words and 10.3M 
English words. The second one (SYS2) is a re-
implementation of a phrase-based decoder with 
lexicalized reordering model based on maximum 
entropy principle proposed by Xiong et al 
(2006). All bilingual data are used to extract 
phrases up to length 3 on the source side. 
    In following experiments, we only consider 
removing common features shared by both base-
line systems for feature subspace generation. 
Rule penalty feature and lexicalized reordering 
feature, which are particular to SYS1 and SYS2, 
are not used. We list the features in consideration 
as follows: 
? PEF and PFE: phrase translation probabili-
ties ? ? ?  and ? ? ?  
? PEFLEX and PFELEX: lexical weights 
????  ? ?  and ????  ? ?  
? PP: phrase penalty 
? WP: word penalty 
? BLP: bi-lexicon pair counting how many 
entries of a conventional lexicon co-
occurring in a given translation pair 
? LM-n: language model with order n 
    Based on the principle described in Section 
3.1, we generate a number of feature subspaces 
for each baseline system as follows:  
? For non-LM features (PEF, PFE, PEFLEX, 
PFELEX, PP, WP and BLP), we remove one 
of them from the full feature space each 
time. Thus 7 feature subspaces are generated, 
which are denoted as  ?????? , ?????? , 
????????? , ????????? , ????? , ?????  and 
??????  respectively. The 5-gram LM feature 
is used in each of them. 
? For LM features (LM-n), we change the or-
der from 2 to 5 with all the other non-LM 
features present. Thus 4 LM-related feature 
subspaces are generated, which are denoted 
as ?????2, ?????3 , ?????4  and ?????5 re-
spectively. ?????5 is essentially the full fea-
ture space of  baseline system. 
   For each baseline system, we construct a total 
of 11 sub-systems by using above feature sub-
spaces. The baseline system is also contained 
within them because of using ?????5. We call 
all sub-systems are non-baseline sub-systems 
except the one derived by using ?????5. 
    By default, the beam size of 60 is used for all 
systems in our experiments. The size of n-best 
list is set to 20 for each sub-system, and for base-
line systems, this size is set to 220, which equals 
to the size of the combined n-best list generated 
by total 11 sub-systems. The order of n-gram 
agreement and disagreement features used in 
sentence-level combination model ranges from 
unigram to 4-gram. 
4.3 Evaluation of Oracle Translations 
We first evaluate the oracle performance on the 
n-best lists of baseline systems and on the com-
bined n-best lists of sub-systems generated from 
each baseline system. 
The oracle translations are obtained by using 
the metric of sentence-level BLEU score (Ye et 
al., 2007). Table 4 shows the evaluation results, 
in which Baseline stands for baseline system 
with a 5-gram LM feature, and FS stands for 11 
sub-systems derived from the baseline system.  
 
 SYS1 SYS2 
 BLEU/TER BLEU/TER 
MT04 
Baseline  49.68/0.6411 49.50/0.6349 
FS 51.05/0.6089 50.53/0.6056 
MT05 
Baseline 48.89/0.5946 48.37/0.5944 
FS 50.69/0.5695 49.81/0.5684 
Table 4: Oracle BLEU and TER scores on base-
line systems and their generated sub-systems. 
1100
For both SYS1 and SYS2, feature subspace 
method achieves higher oracle BLEU and lower 
TER scores on both MT04 and MT05 test sets, 
which gives the feature subspace method more 
potential to achieve higher performance than the 
baseline systems. 
We then investigate the ratio of translation 
candidates in the combined n-best lists of non-
baseline sub-systems that are not included in the 
baseline?s n-best list. Table 5 shows the statistics. 
 
 MT04 MT05 
SYS1 69.71% 69.69% 
SYS2 59.07% 58.54% 
Table 5: Ratio of unique translation candidates 
from non-baseline sub-systems. 
From Table 5 we can see that only less than 
half of the translation candidates of sub-systems 
overlap with those the of baseline systems. This 
result, together with the oracle BLEU and TER 
score estimation, helps eliminate the concern that 
no diversities or better translation candidates can 
be obtained by using sub-systems. 
4.4 Feature Subspace Method on Single 
SMT System 
Next we validate the effect of feature subspace 
method on single SMT systems. 
Figure 1 shows the evaluation results of dif-
ferent systems on the MT05 test set. From the 
figure we can see that the overall accuracy of 
baseline systems is better than any of their de-
rived sub-systems, and except the sub-system 
derived by using ?????2, the performance of all 
the systems are fairly similar. 
 
 
Figure 1: Performances of different systems. 
We then evaluate the system combination me-
thod proposed in Section 3.2 with all the sub-
systems for each baseline system. Table 6 shows 
the results on both MT04 and MT05 data sets, in 
which FS-Comb denotes the system combination 
using 11 sub-systems.  
From Table 6 we can see that by using FS-
Comb we obtain about 1.1~1.3 points of BLEU 
gains over baseline systems. We also include in 
Table 6 the results for Baseline+mLM, which 
stands for the augmented baseline system as de-
scribed in Section 3.1 using a bunch of LM fea-
tures from bigram to 5-gram. It can be seen that 
both augmented baseline systems outperform 
their corresponding baseline systems slightly but 
consistently on both data sets. 
 
 MT04 MT05 
SYS1 
Baseline 39.07 38.72 
Baseline+mLM 39.34+ 39.14+ 
FS-Comb 40.43++ 39.79++ 
SYS2 
Baseline 38.84 38.30 
Baseline+mLM 38.95* 38.63+ 
FS-Comb 39.92++ 39.49++ 
Table 6: Translation results of Baseline, Base-
line+mLM and FS-Comb (+: significant better 
than baseline system with ? < 0.05; ++: signifi-
cant better than baseline system with ? < 0.01; *: 
no significant improvement). 
We also investigate the results when we in-
crementally add the n-best list of each sub-
system into a candidate pool to see the effects 
when different numbers of sub-systems are used 
in combination. In order to decide the sequence 
of sub-systems to add, we first evaluate the per-
formance of pair-wise combinations between 
each sub-system and its baseline system on the 
development set. That is, for each sub-system, 
we combine its n-best list with the n-best list of 
its baseline system and perform system combina-
tion for MT03 data set. Then we rank the sub-
systems by the pair-wise combination perfor-
mance from high to low, and use this ranking as 
the sequence to add n-best lists of sub-systems. 
Each time when a new n-best list is added, the 
combination performance based on the enlarged 
candidate pool is evaluated. Figure 2 shows the 
results on both MT04 and MT05 test sets, in 
which SYS1-fs and SYS2-fs denote the sub-
systems derived from SYS1 and SYS2 respec-
tively, and X-axis is the number of sub-systems 
used for combination each time and Y-axis is the 
BLEU score. From the figure we can see that 
although in some cases the performance slightly 
drops when a new sub-system is added, generally 
using more sub-systems always leads to better 
results.  
31
32
33
34
35
36
37
38
39
SYS1 SYS2
Baseline
FS-PEF
FS-PFE
FS-PEFLEX
FS-PFELEX
FS-PP
FS-WP
FS-BLP
FS-LM-2
FS-LM-3
FS-LM-4
1101
Next we examine the performance of baseline 
systems when different beam sizes are used in 
decoding. The results on MT05 test set are 
shown in Figure3, where X-axis is the beam size. 
In Figure 3, SYS1+mLM and SYS2+mLM de-
note augmented baseline systems of SYS1 and 
SYS2 with multiple LM features. 
From Figure 3 we can see that augmented 
baseline systems (with multiple LM features) 
outperform the baseline systems (with only one 
LM feature) for all beam sizes ranging from 20 
to 220. In this experiment we did not observe any 
significant performance improvements when us-
ing larger beam sizes than the default setting, but 
using more sub-systems in combination almost 
always bring improvements. 
 
 
Figure 2: Performances on different numbers of 
sub-systems.  
 
Figure 3: Performances on different beam sizes. 
 MT04 MT05 
SYS1-fs 44.63% 46.12% 
SYS2-fs 47.54% 44.73% 
Table 7: Ratio of final translations coming from 
non-baseline sub-systems. 
Finally, we investigate the ratio of final trans-
lations coming from the n-best lists of non-
baseline sub-systems only. Table 7 shows the 
results on both MT04 and MT05 test sets, which 
indicate that almost half of the final translations 
are contributed by the non-baseline sub-systems. 
4.5 The Impact of n-best List Size 
In order to find the optimal size of n-best list for 
combination, we compare the combination re-
sults of using list sizes from 10-best up to 500-
best for each sub-system. 
In this experiment, system combination was 
performed on the combined n-best list from total 
11 sub-systems with different list size each time. 
Figure 4 shows the results on the MT03 dev set 
and the MT04 and MT05 test sets for both SYS1 
and SYS2. X-axis is the n-best list size of each 
sub-system. 
 
 
Figure 4: Performances on different n-best sizes. 
    We can see from the figure that for all data 
sets the optimal n-best list size is around 50, but 
the improvements are not significant over the 
results when 20-best translations are used. The 
reason for the small optimal n-best list size could 
be that the low-rank hypotheses might introduce 
more noises into the combined translation candi-
date pool for sentence-level combination (Hasan 
et al, 2007; Hildebrand and Vogel, 2008).  
4.6 Feature Subspace Method on Multiple 
SMT Systems 
In the last experiment, we investigate the effect 
of feature subspace method when multiple SMT 
systems are used in system combination.  
Evaluation results are reported in Table 8. The 
system combination method described in Section 
3.2 is used to combine outputs from two baseline 
systems (with only one 5-gram LM feature) and 
sub-systems generated from both baseline sys-
tems (22 in total), with their results denoted as 
Baseline Comb (both) and FS Comb (both) re-
spectively. We also include the combination re-
sults of sub-systems based on one baseline sys-
tem for reference in the table. 
 
38.0
38.5
39.0
39.5
40.0
40.5
1 2 3 4 5 6 7 8 9 10 11
SYS1-fs-05
SYS2-fs-05
SYS1-fs-04
SYS2-fs-04
38.0
38.5
39.0
39.5
2
0
4
0
6
0
8
0
1
0
0
1
2
0
1
4
0
1
6
0
1
8
0
2
0
0
2
2
0
SYS1
SYS2
SYS1-mLM
SYS2-mLM
39.0
39.5
40.0
40.5
41.0
41.5
42.0
10 20 50 100 200 500
SYS1-fs-05
SYS2-fs-05
SYS1-fs-04
SYS2-fs-04
SYS1-fs-03
SYS2-fs-03
1102
On both MT04 and MT05 test sets, the results 
of system combination based on sub-systems are 
significantly better than those of baseline sys-
tems, which show that our method can also help 
with system combination when more than one 
system are used. We can also see that using mul-
tiple systems based on different SMT models and 
using our subspace based method can help each 
other: the best performance can only be achieved 
when both are employed. 
 
 MT04 MT05 
Baseline Comb (both) 39.98 39.43 
FS-Comb (SYS1) 40.43 39.79 
FS-Comb (SYS2) 39.92 39.49 
FS Comb (both) 40.96 40.38 
Table 8: Performances of sentence-level combi-
nation on multiple SMT systems. 
5 Conclusion 
In this paper, we have presented a novel and ef-
fective Feature Subspace method for the con-
struction of an ensemble of machine translation 
systems based on a baseline SMT model which 
can be formulated as a standard linear function. 
Each system within the ensemble is based on a 
subset of features derived from the baseline 
model, and the resulting ensemble can be used in 
system combination to improve translation quali-
ty. Experimental results on NIST Chinese-to-
English translation tasks show that our method 
can bring significant improvements to two base-
line systems with state-of-the-art performance, 
and it is expected that our method can be em-
ployed to improve any linear model -based SMT 
systems. There is still much room for improve-
ments in the current work. For example, we still 
use a simple one-feature difference principle for 
feature subspace generation. In the future, we 
will explore more possibilities for feature sub-
spaces selection and experiment with our method 
in a word-level system combination model. 
 
References  
Necip Fazil Ayan, Jing Zheng, and Wen Wang. 2008. 
Improving alignments for better confusion net-
works for combining machine translation systems. 
In Proc. COLING, pages 33-40. 
Srinivas Bangalore, German Bordel, and Giuseppe 
Riccardi. 2001. Computing consensus translation 
from multiple machine translation systems. In 
Proc. ASRU, pages 351-354. 
David Chiang. 2005. A hierarchical phrase-based 
model for statistical machine translation. In Proc. 
ACL, pages 263-270. 
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick 
Nguyen, and Robert Moore. 2008. Indirect-hmm-
based hypothesis for combining outputs from ma-
chine translation systems. In Proc. EMNLP, pages 
98-107. 
Almut Silja Hildebrand and Stephan Vogel. 2008. 
Combination of machine translation systems via 
hypothesis selection from combined n-best lists. In 
8th AMTA conference, pages 254-261. 
Tin Kam Ho. 1998. The random subspace method for 
constructing decision forests. In IEEE Transactions 
on Pattern Analysis and Machine Intelligence, 
pages 832-844. 
Sasa Hasan, Richard Zens, and Hermann Ney. 2007. 
Are very large n-best lists useful for SMT? In 
Proc. NAACL, Short paper, pages 57-60. 
S. Jayaraman and A. Lavie. 2005. Multi-Engine Ma-
chine Translation Guided by Explicit Word Match-
ing. In 10th EAMT conference, pages 143-152. 
Philipp Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proc. EMNLP, 
pages 388-395. 
Philipp Koehn. 2004. Phrase-based Model for SMT. 
In Computational Linguistics, 28(1): pages 114-
133. 
Mu Li, Nan Duan, Dongdong Zhang, Chi-Ho Li, and 
Ming Zhou. 2009. Collaborative Decoding: Partial 
Hypothesis Re-Ranking Using Translation Consen-
sus between Decoders. In Proc. ACL-IJCNLP. 
Adam Lopez and Philip Resnik. 2006. Word-Based 
Alignment, Phrase-Based Translation: What?s the 
link? In 7th AMTA conference, pages 90-99. 
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine 
Translation. In Proc. ACL, pages 609-616. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language phras-
es. In Proc. EMNLP, pages 44-52. 
Wolfgang Macherey and Franz Och. 2007. An Empir-
ical Study on Computing Consensus Translations 
from Multiple Machine Translation Systems. In 
Proc. EMNLP, pages 986-995. 
Evgeny Matusov, Nicola Ueffi ng, and Hermann Ney. 
2006. Computing consensus translation from mul-
tiple machine translation systems using enhanced 
hypotheses alignment. In Proc. EACL, pages 33-
40. 
Franz Och and Hermann Ney. 2002. Discriminative 
training and maximum entropy models for statis-
1103
tical machine translation. In Proc. ACL, pages 295-
302. 
Franz Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proc. ACL, pages 
160-167. 
Franz Och and Hermann Ney. 2003. A systematic 
comparison of various statistical alignment models. 
Computational Linguistics, 29(1): pages 19-51. 
Franz Och and Hermann Ney. 2004. The alignment 
template approach to statistical machine transla-
tion. Computational Linguistics, 30(4): pages 417-
449. 
Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, 
Spyros Matsoukas, Richard Schwartz, and Bonnie 
Dorr. 2007. Combining outputs from multiple ma-
chine translation systems. In Proc. NAACL, pages 
228-235. 
Antti-Veikko Rosti, Spyros Matsoukas, and Richard 
Schwartz. 2007. Improved Word-Level System 
Combination for Machine Translation. In Proc. 
ACL, pages 312-319. 
Antti-Veikko Rosti, Bing Zhang, Spyros Matsoukas, 
and Richard Schwartz. 2008. Incremental hypothe-
sis alignment for building confusion networks with 
application to machine translation system combina-
tion. In Proc. Of the Third ACL Workshop on Sta-
tistical Machine Translation, pages 183-186. 
K.C. Sim, W. Byrne, M. Gales, H. Sahbi, and P. 
Woodland. 2007. Consensus network decoding for 
statistical machine translation system combination. 
In ICASSP, pages 105-108. 
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Max-
imum entropy based phrase reordering model for 
statistical machine translation. In Proc. ACL, pages 
521-528. 
Yang Ye, Ming Zhou, and Chin-Yew Lin. 2007. Sen-
tence level Machine Translation Evaluation as a 
Ranking Problem: One step aside from BLEU. In 
Proc. Of the Second ACL Workshop on Statistical 
Machine Translation, pages 240-247. 
1104
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1344?1352,
Beijing, August 2010
Heterogeneous Parsing via Collaborative Decoding
Muhua Zhu Jingbo Zhu Tong Xiao
Natural Language Processing Lab.
Northeastern University
zhumuhua@gmail.com
{zhujingbo, xiaotong}@mail.neu.edu.cn
Abstract
There often exist multiple corpora for the
same natural language processing (NLP)
tasks. However, such corpora are gen-
erally used independently due to distinc-
tions in annotation standards. For the pur-
pose of full use of readily available hu-
man annotations, it is significant to simul-
taneously utilize multiple corpora of dif-
ferent annotation standards. In this pa-
per, we focus on the challenge of con-
stituent syntactic parsing with treebanks
of different annotations and propose a col-
laborative decoding (or co-decoding) ap-
proach to improve parsing accuracy by
leveraging bracket structure consensus be-
tween multiple parsing decoders trained
on individual treebanks. Experimental re-
sults show the effectiveness of the pro-
posed approach, which outperforms state-
of-the-art baselines, especially on long
sentences.
1 Introduction
Recent years have seen extensive applications of
machine learning methods to natural language
processing problems. Typically, increase in the
scale of training data boosts the performance of
machine learning methods, which in turn en-
hances the quality of learning-based NLP systems
(Banko and Brill, 2001). However, annotating
data by human is expensive in time and labor. For
this reason, human-annotated corpora are consid-
ered as the most valuable resource for NLP.
In practice, there often exist more than one cor-
pus for the same NLP tasks. For example, for
constituent syntactic parsing (Collins, 1999; Char-
niak, 2000; Petrov et al, 2006) in Chinese, in ad-
dition to the most popular treebank Chinese Tree-
bank (CTB) (Xue et al, 2002), there are also
other treebanks such as Tsinghua Chinese Tree-
bank (TCT) (Zhou, 1996). For the purpose of
full use of readily available human annotations
for the same tasks, it is significant if such cor-
pora can be used jointly. At first sight, a di-
rect combination of multiple corpora is a way to
this end. However, corpora created for the same
NLP tasks are generally built by different orga-
nizations. Thus such corpora often follow dif-
ferent annotation standards and/or even different
linguistic theories. We take CTB and TCT as
a case study. Although both CTB and TCT are
Chomskian-style treebanks, they have annotation
divergences in at least two dimensions: a) CTB
and TCT have dramatically different tag sets, in-
cluding parts-of-speech and grammar labels, and
the tags cannot be mapped one to one; b) CTB
and TCT have distinct hierarchical structures. For
example, the words ??? (Chinese) ?? (tradi-
tional) ?? (culture)? are grouped as a flat noun
phrase according to the CTB standard (right side
in Fig. 1), but in TCT, the last two words are in-
stead grouped together beforehand (left side in
Fig. 1). The differences cause such treebanks
of different annotations to be generally used in-
dependently. This paper is dedicated to solving
the problem of how to use jointly multiple dis-
parate treebanks for constituent syntactic parsing.
Hereafter, treebanks of different annotations are
1344
called heterogeneous treebanks, and correspond-
ingly, the problem of syntactic parsing with het-
erogeneous treebanks is referred to as heteroge-
neous parsing.
Previous work on heterogeneous parsing is of-
ten based on treebank transformation (or treebank
conversion) (Wang et al, 1994; Niu et al, 2009).
The basic idea is to transform annotations of one
treebank (source treebank) to fit the standard of
another treebank (target treebank). Due to diver-
gences of treebank annotations, such transforma-
tion is generally achieved in an indirect way by
selecting transformation results from the output of
a parser trained on the target treebank. A com-
mon property of all the work mentioned above is
that transformation accuracy is heavily dependent
on the performance of parsers trained on the tar-
get treebank. Sometimes transformation accuracy
is not so satisfactory that techniques like instance
pruning are needed in order to refine transforma-
tion results (Niu et al, 2009).
We claim there exists another way, interesting
but less studied for heterogeneous parsing. The
basic idea is that, although there are annotation
divergences between heterogenous treebanks, ac-
tually we can also find consensus in annotations
of bracket structures. Thus we would like to train
parsers on individual heterogeneous treebanks and
guide the parsers to gain output with consensus in
bracket structures as much as possible when they
are parsing the same sentences.
To realize this idea, we propose a generic col-
laborative decoding (or co-decoding) framework
where decoders trained on heterogeneous tree-
banks can exchange consensus information be-
tween each other during the decoding phase. The-
oretically the framework is able to incorporate a
large number of treebanks and various functions
that formalize consensus statistics.
Our contributions can be summarized: 1) we
propose a co-decoding approach to directly uti-
lizing heterogeneous treebanks; 2) we propose a
novel function to measure parsing consensus be-
tween multiple decoders. We also conduct ex-
periments on two Chinese treebanks: CTB and
TCT. The results show that our approach achieves
promising improvements over baseline systems
which make no use of consensus information.
np
nS
??
np
a
??
n
??
NP
NR
??
NN
??
NN
??
??????
(Chinese) (traditional) (culture)
Figure 1: Example tree fragments with TCT (left)
and CTB (right) annotations
2 Collaborative Decoding-based
Heterogeneous Parsing
2.1 Motivation
This section describes the motivation to use
co-decoding for heterogeneous parsing. We first
use the example in Fig. 1 to illustrate what con-
sensus information exists between heterogenous
treebanks and why such information might help
to improve parsing accuracy. This figure contains
two partial parse trees corresponding to the
words ??? (Chinese) ?? (traditional) ??
(culture)?, annotated according to the TCT (left
side) and CTB (right side) standards respectively.
Despite the distinctions in tag sets and bracket
structures, these parse trees actually have partial
agreements in bracket structures. That is, not all
bracket structures in the parse trees are different.
Specifically put, although the internal structures
of the parse trees are different, both CTB and
TCT agree to take ??? ?? ??? as a noun
phrase. Motivated by this observation, we would
like to guide parsers that are trained on CTB and
TCT respectively to verify their output interac-
tively by using consensus information implicitly
contained in these treebanks. Better performance
is expected when such information is considered.
A feasible framework to make use of consensus
information is n-best combination (Henderson
and Brill, 1999; Sagae and Lavie, 2006; Zhang et
al., 2009; Fossum and Knight, 2009). In contrast
1345
to previous work on n-best combination where
multiple parsers, say, Collins parser (Collins,
1999) and Berkeley parser (Petrov et al, 2006)
are trained on the same training data, n-best
combination for heterogeneous parsing is instead
allowed to use either a single parser or multiple
parsers which are trained on heterogeneous
treebanks. Consensus information can be incor-
porated during the combination of the output
(n-best list of full parse trees following distinct
annotation standards) of individual parsers. How-
ever, despite the success of n-best combination
methods, they suffer from the limited scope of
n-best list. Taking this into account, we prefer
to apply the co-decoding approach such that
consensus information is expected to affect the
entire procedure of searching hypothesis space.
2.2 System Overview
The idea of co-decoding is recently extensively
studied in the literature of SMT (Li et al, 2009;
Liu et al, 2009). As the name shows, co-decoding
requires multiple decoders be combined and pro-
ceed collaboratively. As with n-best combination,
there are at least two ways to build multiple de-
coders: we can either use multiple parsers trained
on the same training data (use of diversity of mod-
els), or use a single parser on different training
data (use of diversity of datasets) 1. Both ways
can build multiple decoders which are to be inte-
grated into co-decoding. For the latter case, one
method to get diverse training data is to use dif-
ferent portions of the same training set. In this
study we extend the case to an extreme situation
where heterogeneous treebanks are used to build
multiple decoders.
Fig. 2 represents a basic flow chart of heteroge-
neous parsing via co-decoding. Note that here we
discuss the case of co-decoding with only two de-
coders, but the framework is generic enough to in-
tegrate more than two decoders. For convenience
of reference, we call a decoder without incorpo-
rating consensus information as baseline decoder
1To make terminologies clear, we use parser as its regular
sense, including training models (ex. Collins model 2) and
parsing algorithms (ex. the CKY algorithm used in Collins
parser), and we use decoder to represent parsing algorithms
with specified parameter values
treebank1 treebank2
decoder1 decoder2
co-decoding
test data
Figure 2: Basic flow chart of co-decoding
and correspondingly refer to a decoder augmented
with consensus information as member decoder.
So the basic steps of co-decoding for heteroge-
neous parsing is to first build baseline decoders on
heterogeneous treebanks and then use the baseline
decoders to parse sentences with consensus infor-
mation exchanged between each other.
To complete co-decoding for heterogeneous
parsing, three key components should be consid-
ered in the system:
? Co-decoding model. A co-decoder con-
sists of multiple member decoders which are
baseline decoders augmented with consen-
sus information. Co-decoding model de-
fines how baseline decoders and consensus
information are correlated to get member de-
coders.
? Decoder coordination. Decoders in the co-
decoding model cannot proceed indepen-
dently but should have interactions between
each other in order to exchange consensus in-
formation. A decoder coordination strategy
decides on when, where, and how the inter-
actions happen.
? Consensus-based score function. Consensus-
based score functions formalize consensus
information between member decoders. Tak-
ing time complexity into consideration, con-
sensus statistics should be able to be com-
puted efficiently.
1346
In the following subsections, we first present
the generic co-decoding model and then describe
in detail how member decoders collaborate. Fi-
nally we introduce a novel consensus-based score
function which is used to quantify consensus in-
formation exchanged between member decoders.
2.3 Generic Co-decoding Model
The generic co-decoding model described here is
also used in (Li et al, 2009) for co-decoding of
machine translators. For a given sentence S, a
parsing algorithm (decoder) seeks a parse tree T ?
which is optimal in the sense that it maximizes
some score function F (T ), as shown in Eq. 1.
T ? = argmax
Ts.t.S=yield(T )
F (T ) (1)
where Ts.t.S = yield(T ) represents the set of
parse trees that yield the input sentence S. For
baseline decoders, the score function F (T ) is
generally just the inside probability P (T ) 2 of
a tree T , defined as the product of probabili-
ties of grammar rules appearing in parse tree T :?
r?R(T ) P (r). In the co-decoding framework,
F (T ) is extended so as to integrate consensus-
based score functions which measure consensus
information between member decoders, as shown
in Eq. 2.
Fm(T ) = Pm(T ) +
n?
k,k 6=m
?k(Hk(S), T ) (2)
We use dk to denote the kth decoder and use
Hk(S) to denote corresponding parsing hypoth-
esis space of decoder dk. Moreover, Pm(T ) is
referred to as baseline score given by baseline
decoders and ?k(Hk(S), T ) is consensus score
between decoders dm and dk, which is defined
as a linear combination of consensus-based score
functions, as shown in Eq. 3.
?k(Hk(S), T ) =
?
l
?k,lfk,l(Hk(S), T ) (3)
where fk,l(Hk(S), T ) represents a consensus-
based score function between T and Hk(S),
and ?k,l is the corresponding weight. Index l
2Actually, the joint probability P(S,T) of sentence S and
parse tree T is used, but we can prove that P (S, T ) = P (T ).
ranges over all consensus-based score functions
in Eq. 3. Theoretically we can define a variety
of consensus-based score functions.
For the simplest case where there are only two
member decoders and one consensus-based score
function, Eq. 2 and Eq. 3 can be combined and
simplified into the equation
Fi(T ) = Pi(T ) + ?1?if(H1?i(S), T ) (4)
where index i is set to the value of either 1 or 0.
This simplified version is used in the experiments
of this study.
2.4 Decoder Coordination
This subsection discusses the problem of decoder
coordination. Note that although Eq. 2 is defined
at sentence level, the co-decoding model actu-
ally should be applied to the parsing procedure
of any subsequence (word span) of sentence S.
So it is natural to render member decoders col-
laborate when they are processing the same word
spans. To this end, we would like to adopt best-
first CKY-style parsing algorithms as baseline de-
coders, since CKY-style decoders have the prop-
erty that they process word spans in the ascend-
ing order of span sizes. Moreover, the hypothe-
ses 3 spanning the same range of words are read-
ily stacked together in a chart cell before CKY-
style decoders move on to process other spans.
Thus, member decoders can process the same
word spans collaboratively from small ones to big
ones until they finally complete parsing the entire
sentence.
A second issue in Eq. 2 is that consensus-
based score functions are dependent on hypoth-
esis space Hk(S). Unfortunately, the whole hy-
pothesis space is not available most of the time.
To address this issue, one practical method is to
approximate Hk(S) with a n-best hypothesis list.
For best-first CKY parsing, we actually retain all
unpruned partial hypotheses over the same span
as the approximation. Hereafter, the approxima-
tion is denoted as H?k(S)
Finally, we notice in Eq. 2 that consensus score
3In the literature of syntactic parsing, especially in chart
parsing, hypotheses is often called edges. This paper will
continue to use the terminology hypothesis when no ambigu-
ity exists.
1347
?k(Hk(S), T ) and Hk(S) form a circular depen-
dency: searching for Hk(S) requires both base-
line score and consensus score; on the other hand,
calculating consensus score needs Hk(S) (its ap-
proximation in practice) to be known beforehand.
Li et al (2009) solves this dilemma with a boot-
strapping method. It starts with seedy n-best lists
generated by baseline decoders and then alter-
nates between calculating consensus scores and
updating n-best hypothesis lists. Such bootstrap-
ping method is a natural choice to break down the
circular dependency, but multi-pass re-decoding
might dramatically reduce decoding efficiency.
Actually, Li et al (2009) restricts the iteration
number to two in their experiments. In this paper,
we instead use an alternative to the bootstrapping
method. The process is described as follows.
1. In traditional best-first CKY-style parsing al-
gorithms, hypotheses over the same word
spans are grouped according to some crite-
rion of hypothesis equivalence 4. Among
equivalent hypotheses, only a single optimal
hypothesis is retained. In this paper, we in-
stead keep top k of equivalent hypotheses in
a data structure called best-first cache.
2. Use hypotheses in best-first caches to ap-
proximate Hk(S), and calculate consensus
score ?k(Hk(S), T ) between decoders.
3. Use baseline score and consensus score to lo-
cally rerank hypotheses in best-first caches.
Then remove hypotheses in caches except the
top one hypothesis.
In this study, we choose the best-first CKY-style
parsing algorithm used in Collins parser (Collins,
1999). Algorithm 1 extends this algorithm for co-
decoding. The first two steps initialize baseline
decoders and assign appropriate POS tags to sen-
tence St. Since baseline decoders are built on het-
erogeneous treebanks, POS taggers correspond-
ing to each baseline decoder are demanded, unless
gold POS tags are provided. The third step is the
core of the co-decoding algorithm. Here the com-
plete procedure invokes baseline decoders to com-
4the simplest criterion of equivalence is whether hypothe-
ses have the same grammar labels.
Algorithm 1 CKY-style Co-decoding
Argument: dk{the set of baseline decoders}
St{a sentence to be parsed}
Begin
Steps:
1. assign POS tags to sentence St
2. initialize baseline decoders dk
3. for span from 2 to sentence length do
for start from 1 to (sentence length-span+1) do
end := (start + span - 1)
for each base decoder dk do
complete(dk , start, end)
do co-decoding(start, end)
End
Subroutine:
complete(dk, start, end): base decoder dk generates
hypotheses over the span (begin.end), and fills in best-
first caches.
co-decoding(start, end): calculate consensus score
and rerank hypotheses in best-first caches. The top 1 is
chosen to be the best-first hypothesis.
plete parsing on the span [start, end] and gener-
ates H?k(s). The co-decoding procedure calculates
consensus score and locally reranks hypotheses in
best-first caches.
2.5 Consensus-based Score Function
There are at least two feasible ways to mea-
sure consensus between constituency parse trees.
By viewing parse trees from diverse perspectives,
we can either use functions on bracket structures
of parse trees, as in (Wang et al, 1994), or
use functions on head-dependent relations by first
transforming constituency trees into dependency
trees, as in (Niu et al, 2009). Although the co-
decoding model is generic enough to integrate var-
ious consensus-based score functions in a uniform
way, this paper only uses a bracket structure-based
function.
As mentioned above, the function proposed in
(Wang et al, 1994) is based on bracket struc-
tures. Unfortunately, that function is not appli-
cable in the situation of this paper. The reason is
that, the function in (Wang et al, 1994) is de-
fined to work on two parse trees, but this paper
instead needs a function on a tree T and a set of
trees (the approximation H?k(S)). To this end, we
first introduce the concept of constituent set (CS)
of a parse tree. Conceptually, CS of a parse tree is
a set of word spans corresponding to all the sub-
1348
64
1
5
2 3
[1,3],[2,3],[1,1]
[1,1]
[2,3],[2,2],[3,3]
[1,1]
[2,2]
[3,3]
Figure 3: Constituent set of a synthetic parse tree
trees of the tree, as illustrated in Fig. 3. For exam-
ple, the constituent set of the tree rooted at node
6 has three elements: [1, 1], [1, 3], and [1, 2]. For
H?k(S), the constituent set is defined as the union
of constituent sets of all elements it contains.
CS(H?k(S)) =
?
T?H?k(S)
CS(T )
In practice, we need to cut off elements in
CS(H?k(S)) in order to retain most confident
word spans.
With the concept of constituent set, a
consensus-based score function on T and H?k(S)
can be defined as follows.
f(H?k(S), T ) =
?
c?CS(T ) I(c, CS(H?k(S)))
|CS(T )| (5)
where I(c, CS(H?k(S))) is an indicator function
which returns one if c ? CS(T ) is compatible
with all the elements in CS(H?k(S)), zero oth-
erwise. Two spans, [a, b] and [i, j] are said to
be compatible if they satisfy one of the following
conditions: 1) i > b; 2) a > j; 3) a ? i ? b and
j ? b; 4) i ? a ? j and b ? j. Fig 4 uses two
example to illustrate the concept of compatibility.
3 Experiments
3.1 Data and Performance Metric
The most recent version of the CTB corpus, CTB
6.0 and the CIPS ParsEval data are used as hetero-
geneous treebanks in the experiments. Following
the split utilized in (Huang et al, 2007), we di-
vided the dataset into blocks of 10 files. For each
w1 w2 w3 w4 w1 w2 w3 w4
Figure 4: left) two spans conflict; right) two spans
are compatible
block, the first file was added to the CTB develop-
ment data, the second file was added to the CTB
testing data, and the remaining 8 files were added
to the CTB training data. For the sake of parsing
efficiency, we randomly sampled 1,000 sentences
of no more than 40 words from the CTB test set.
CTB-Partitions Train Dev Test
#Sentences 22,724 2,855 1,000
#Words 627,833 78,653 25,100
Ave-Length 30.1 30.0 20.3
TCT-Partitions Train Dev Test
#Sentences 32,771 N/A 1,000
#Words 354,767 N/A 10,400
Ave-Length 10.6 N/A 10.4
Table 1: Basic statistics on the CTB and TCT data
CIPS-ParsEval data is publicly available for the
first Chinese syntactic parsing competition, CIPS-
ParsEval 2009. Compared to CTB, sentences in
CIPS-ParsEval data are much shorter in length.
We removed sentences which have words less
than three. CIPS-ParsEval test set has 7,995 sen-
tences after sentence pruning. As with the CTB
test set, we randomly sampled 1,000 sentences
for evaluating co-decoding performance. Since
CIPS-ParsEval data is actually a portion of the
TCT corpus, for convenience of reference, we will
refer to CIPS-ParsEval data as TCT in the follow-
ing sections. Table 1 contains statistics on CTB
and TCT.
The two training sets are used individually to
build baseline decoders. With regard to the test
sets, each sentence in the test sets should have
two kinds of POS tags, according to the CTB and
TCT standards respectively. To this end, we ap-
plied a HMM-based method for POS annotation
transformation (Zhu and Zhu, 2009). During the
POS transformation, the divergences of word seg-
mentation are omitted.
For all experiments, bracketing F1 is used as
the performance metric, provided by EVALB 5.
5http://nlp.cs.nyu.edu/evalb
1349
3.2 Baseline Decoders
As already mentioned above, we apply Collins
parser in this paper. Specifically speaking, two
CKY-style baseline decoders to participate co-
decoding are built on CTB and TCT respectively
with Collins model two. For the CTB-based de-
coder, we use the CTB training data with slight
modifications: we replaced POS tags of punctua-
tions with specific punctuation symbols.
To get the TCT-based decoder, we made follow-
ing modifications. Firstly, TCT is available with
manually annotated head indices for all the con-
stituents in parse trees. For example, a grammar
label, say, np-1, means that the constituent is a
noun phrase with the second child being its head
child. In order to relax context independence as-
sumptions made in PCFG, we appended head in-
dices to grammar labels to get new labels, for ex-
ample np1. Secondly, since Collins parser is a
lexicalized parser, head rules specific to the TCT
corpus were manually created, which are used to-
gether with readily available head indices. Such
adaptation is also used in (Chen et al, 2009);
3.3 Parsing Results
We conduct experiments on both CTB and TCT
test sets. Two parameters need to be set: the cut-
off threshold for constructing constituent set of
H?k(S) and the weight ? 6 of consensus score in
Eq. 4. We tuned the parameters on the CTB de-
velopment set and finally set them to 5 and 20
respectively in the experiments. Table 2 presents
bracketing F1 scores of baseline systems and the
co-decoding approach. Here, the row of baseline
represents the performance of individual baseline
decoders, and the comparison of baseline and co-
decoding on a test set, say CTB, demonstrates
how much boosting the other side, say TCT, can
supply. For the co-decoding approach, the size
of best-first cache is set to 5 which achieves the
best result among the cache sizes we have experi-
mented.
As the results show, co-decoding achieves
promising improvements over baseline systems
on both test sets. Interestingly, we see that the
improvement on the TCT test set is larger than
6We use the same ? for both member decoders.
Test Set CTB TCT
Baseline 79.82 81.02
Co-decoding 80.33 81.77
Table 2: Baseline and Co-decoding on the CTB
and TCT test sets
that on the CTB test set. In general, a relatively
strong decoder can improve co-decoding perfor-
mance more than a relatively weak decoder does.
At the first sight, the TCT-based decoder seems to
have better performance than the CTB-based de-
coder. But if taking sentence length into consid-
eration, we can find that the TCT-based decoder
is actually relatively weak. Table 3 shows the
performance of the CTB-based decoder on short
sentences.
3.4 Analysis
Fig. 5 shows the bracketing F1 on the CTB test set
at different settings of the best-first cache size C .
F1 scores reach the peak before C increases to 6.
As a result, we set C to 5 in all our experiments.
 79
 79.5
 80
 80.5
 81
 0  1  2  3  4  5  6
br
ac
ke
tin
g 
F1
size of best-first cache
CTB
Figure 5: Bracketing F1 with varying best-first
cache size
To evaluate the effect of sentence length on co-
decoding, Table 3 presents F1 scores on portions
of the CTB test set, partitioned according to sen-
tence length. From the results we can see that
co-decoding performs better on long sentences.
One possible reason is that member decoders have
more consensus on big spans. Taking this obser-
vation into consideration, one enhancement to the
co-decoding approach is to enable co-decoding
only on long sentences. This way, parsing ef-
1350
Partitions [0,10] (10,20] (20,30] (30,40]
# Sentence 276 254 266 204
Ave-Length 6.07 15.64 25.43 35.20
Baseline 92.83 84.34 78.98 76.69
Co-decoding 92.84 84.36 79.43 77.65
Table 3: Effect of sentence length on co-decoding
performance
ficiency of co-decoding can be improved. It is
worth emphasizing that co-decoding is still help-
ful for parsers whose performance on short sen-
tences is not satisfactory, as shown in Table 2.
Another interesting analysis is to check how
many parsing results are affected by co-decoding,
compared to baseline decoders. Table 4 shows
the statistics.
Test Set # All # Improved # Decreased
CTB 1000 225 109
TCT 1000 263 92
Table 4: Statistics on sentences of test data
As the table shows, although overall accuracy is
increased, we find that on some sentences, co-
decoding instead worsens parsing accuracy. In
order to get insights on error sources, we manu-
ally analyzed 20 sentences on which co-decoding
achieves negative results. We find a large por-
tion (14 of 20) of sentences are short sentences
(of words less than 20). Actually, due to high ac-
curacy of the CTB-based decoder on short sen-
tences, co-decoding is indifferent when this de-
coder is processing short sentences. And we also
find that some errors are derived from differences
in annotation standards. Fortunately, the diver-
gence of annotations mainly exists in relatively
small spans. So one solution to the problem is to
enable co-decoding on relatively big spans. These
will be done in our future work.
4 Related Work
4.1 System Combination
In the literature of syntactic parsing, n-best com-
bination methods include parse selection, con-
stituent recombination, production recombina-
tion, and n-best reranking. Henderson and Brill
(1999) performs parse selection by maximizing
the expected precision of selected parse with re-
spect to the set of parses to be combined. Sagae
and Lavie (2006) proposes to recombine con-
stituents from the output of individual parsers.
More recently, Fossum and Knight (2009) studies
a combination method at production level. Zhang
et al (2009) reranks n-best list of one parser with
scores derived from another parser.
Compared to n-best combination, co-decoding
(Li et al, 2009; Liu et al, 2009) combines sys-
tems during decoding phase. Theoretically, sys-
tem combination during decoding phase helps de-
coders to select better approximation to hypothe-
sis space, since pruning is practically unavoidable.
To the best of our knowledge, co-decoding meth-
ods have not been applied to syntactic parsing.
4.2 Treebank Transformation
The focus of this study is heterogeneous parsing.
Previous work on this challenge is generally based
on treebank transformation. Wang et al (1994)
describes a method for transformation between
constituency treebanks. The basic idea is to train
a parser on a target treebank and generate a n-best
list for each sentence in source treebank(s). Then,
a matching metric which is a function on the num-
ber of the same word spans between two trees is
defined to select a best parse from each n-best list.
Niu et al (2009) applies a closely similar frame-
work as with (Wang et al, 1994) to transform a
dependency treebank to a constituency one.
5 Conclusions
This paper proposed a co-decoding approach to
the challenge of heterogeneous parsing. Com-
pared to previous work on this challenge, co-
decoding is able to directly utilize heterogeneous
treebanks by incorporating consensus information
between partial output of individual parsers dur-
ing the decoding phase. Experiments demonstrate
the effectiveness of the co-decoding approach, es-
pecially the effectiveness on long sentences.
Acknowledgments
This work was supported in part by the National
Science Foundation of China (60873091). We
would like to thank our anonymous reviewers for
their comments.
1351
References
Banko, Michele and Eric Brill. 2001. Scaling to
very very large corpora for natural language dis-
ambiguation. In Proc. of ACL 2001, pages 26-33.
Chen, Xiao, Changning Huang, Mu Li, and Chunyu
Kit. 2009. Better Parser Combination. Technique
Report of CIPS-ParsEval 2009.
Collins, Michael. 1999. Head-driven statistical mod-
els for natural language parsing. Ph.D. thesis, Uni-
versity of Pennsylvania.
Charniak, Eugene. 2000. A maximum-entropy-
inspired parser. In Proc. of NAACL 2000, pages
132-139.
Fossum, Victoria and Kevin Knight. 2009. Combin-
ing constituent parsers. In Proc. of NAACL 2009,
pages 253-256.
Henderson, John and Eric Brill. 1999. Exploiting di-
versity in natural language processing. In Proc. of
SIGDAT-EMNLP 1999, pages 187-194.
Huang, Zhongqiang, Mary P. Harper, and Wen Wang.
2007. Mandarin part-of-speech tagging and dis-
criminative reranking. In Proc. of EMNLP-CoNLL
2007, pages 1093-1102.
Li, Mu, Nan Duan, Dongdong Zhang, Chi-Ho Li, and
Ming Zhou. 2009. Collaborative decoding: par-
tial hypothesis re-ranking using trnaslationconsen-
sus between decoders. In Proc. of ACL 2009, pages
585-592.
Liu, Yang, Haitao Mi, Yang Feng, and Qun Liu. 2009.
Joint Decoding with Multiple Translation Models.
In Proc. of ACL 2009, pages 576-584.
Niu, Zheng-Yu, Haifeng Wang, Hua Wu. 2009. Ex-
ploiting heterogeneous treebanks for parsing. In
Proc. of ACL 2009, pages 46-54.
Petrov, Slav, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In Proc. of COLING-
ACL 2006, pages 433-440.
Sage, Kenji and Alon Lavie. 2006. Parser combina-
tion by reparsing. In Proc. of NAACL 2006, pages
129-132.
Xue, Nianwen, Fu dong Chiou, and Martha Palmer.
2002. Building a large-scale Annotated Chinese
corpus. In Proc. of COLING 2002, pages 1-8.
Wang, Jong-Nae, Jing-Shin Chang, and Keh-Yih Su.
1994. An automatic treebank conversion algorithm
for corpus sharing. In Proc. of ACL 1994, pages
248-254.
Zhang, Hui, Min Zhang, Chew Lim Tan, and Haizhou
Li. 2009. K-best combination of syntactic parsers.
In Proc. of EMNLP 2009, pages 1552-1560.
Zhou, Qiang. 1996. Phrase bracketing and annotating
on Chinese language corpus. (in Chinese) Ph.D.
thesis, Beijing University.
Zhu, Muhua and Jingbo Zhu. 2009. Label Corre-
spondence Learning for Part-of-Speech Annotation
Transformation. In Proc. of CIKM 2009, pages
1461-1464.
1352
Coling 2010: Poster Volume, pages 1345?1353,
Beijing, August 2010
An Empirical Study of Translation Rule Extraction with Multiple 
Parsers 
 
Tong Xiao??, Jingbo Zhu??, Hao Zhang?, Muhua Zhu?? 
 
?Natural Language Processing Lab., Northeastern University 
?Key Laboratory of Medical Image Computing, Ministry of Education 
{xiaotong,zhujingbo}@mail.neu.edu.cn 
zhanghao@ics.neu.edu.cn, zhumuhua@gmail.com 
 
Abstract 
Translation rule extraction is an impor-
tant issue in syntax-based Statistical Ma-
chine Translation (SMT). Recent studies 
show that rule coverage is one of the key 
factors affecting the success of syntax-
based systems. In this paper, we first 
present a simple and effective method to 
improve rule coverage by using multiple 
parsers in translation rule extraction, and 
then empirically investigate the effec-
tiveness of our method on Chinese-
English translation tasks. Experimental 
results show that extracting translation 
rules using multiple parsers improves a 
string-to-tree system by over 0.9 BLEU 
points on both NIST 2004 and 2005 test 
corpora. 
1 Introduction 
Recently various syntax-based models have been 
extensively investigated in Statistical Machine 
Translation (SMT), including models between 
source trees and target strings (Quirk et al, 2005; 
Liu et al, 2006; Huang et al, 2006), source 
strings and target trees (Yamada and Knight, 
2001; Galley et al, 2006; Shen et al, 2008), or 
source trees and target trees (Eisner, 2003; Ding 
and Palmer, 2005; Cowan et al, 2006; Zhang et 
al., 2008; Liu et al, 2009). In these models, au-
tomatic extraction of translation rules is an im-
portant issue, in which translation rules are typi-
cally extracted using parse trees on 
source/target-language side or both sides of the 
bilingual text. Exploiting the syntactic informa-
tion encoded in translation rules, syntax-based 
systems have shown to achieve comparable per-
formance with phrase-based systems, even out-
perform them in some cases (Marcu et al, 2006). 
Among all the factors contributing to the suc-
cess of syntax-based systems, rule coverage has 
been proved to be an important one that affects 
the translation accuracy of syntax-based systems 
(DeNeefe et al, 2007; Shen et al, 2008). How-
ever, these systems suffer from a problem that 
translation rules are extracted using only 1-best 
parse tree generated by a single parser, which 
generally results in relatively low rule coverage 
due to the limited scope in rule extraction (Mi 
and Huang, 2008). To alleviate this problem, a 
straightforward solution is to enlarge the scope 
of rule extraction, and obtain translation rules by 
using a group of diversified parse trees instead 
of a single parse tree. For example, Mi and 
Huang (2008) used k-best parses and forest to 
extract translation rules for improving the rule 
coverage in their forest-based SMT system, and 
achieved promising results. However, most pre-
vious work used the parse trees generated by 
only one parser, which still suffered somewhat 
from the relatively low diversity in the outputs 
of a single parser. 
Addressing this issue, we investigate how to 
extract diversified translation rules using multi-
ple parsers. As different parsers (or parsing 
models) can provide us with parse trees having 
relatively large diversity, we believe that it is 
beneficial to employ multiple different parsers to 
obtain diversified translation rules and thus en-
large the rule coverage. Motivated by this idea, 
we propose a simple and effective method to 
improve rule coverage by using multiple parsers 
1345
in rule extraction. Furthermore, we conduct an 
empirical study to investigate the effectiveness 
of our method on Chinese-English translation in 
a string-to-tree system. Experimental results 
show that our method improves the baseline sys-
tem by over 0.9 BLEU points on both NIST 
2004 and 2005 test corpora, even achieves a +1 
BLEU improvement when working with the k-
best extraction method. More interestingly, we 
observe that the MT performance is not very 
sensitive to the parsing performance of the pars-
ers used in rule extraction. Actually, the MT sys-
tem does not show different preferences for dif-
ferent parsers. 
2 Related Work 
In machine translation, some efforts have been 
made to improve rule coverage and advance the 
performance of syntax-based systems. For ex-
ample, Galley et al (2006) proposed the idea of 
rule composing which composes two or more 
rules with shared states to form a larger, com-
posed rule. Their experimental results showed 
that the rule composing method could signifi-
cantly improve the translation accuracy of their 
syntax-based system. Following Galley et al 
(2006)?s work, Marcu et al (2006) proposed 
SPMT models to improve the coverage of phras-
al rules, and demonstrated that the system per-
formance could be further improved by using 
their proposed models. Wang et al (2007) de-
scribed a binarization method that binarized 
parse trees to improve the rule coverage on non-
syntactic mappings. DeNeefe et al (2007) analy-
ized the phrasal coverage problem, and com-
pared the phrasal coverage as well as translation 
accuracy for various rule extraction methods 
(Galley et al, 2006; Marcu et al, 2006; Wang et 
al., 2007). 
As another research direction, some work is 
focused on enlarging the scope of rule extraction 
to improve rule coverage. For example, (Venu-
gopal et al, 2008) and (Mi and Huang, 2008) 
extracted rules from the k-best parses and forest 
generated by a single parser to alleviate the 
problem of the limited scope of 1-best parse, and 
achieved promising results. 
Our work differs from previous work in that 
we are concerned with obtaining diversified 
translation rules using multiple different parsers 
(or parsing models) instead of a single parser (or 
parsing model). It can be regarded as an en-
hancement of previous studies. As shown in the 
following parts of this paper, it works very well 
with the existing techniques, such as rule com-
posing (Galley et al, 2006), SPMT models 
(Marcu et al, 2006) and rule extraction with k-
best parses (Venugopal et al, 2008). 
3 Translation Rule Extraction 
In this work, the issue of translation rule extrac-
tion is studied in the string-to-tree model pro-
posed by Galley et al (2006).  We choose this 
model because it has been shown to be one of 
the state-of-the-art syntax-based models, and has 
been adopted in the most successful systems in 
NIST 2009 MT evaluation.  
Typically, (string-to-tree) translation rules are 
learned from the word-aligned bilingual text 
whose target-side has been parsed using a syn-
tactic parser. As the basic unit of translation, a 
translation rule consists of sequence words or 
variables in the source language, and a syntax 
tree in the target language having words (termi-
nals) and variables (non-terminals) at leaves. 
Figure 1 shows the translation rules extracted 
from a word-aligned sentence pair with a target-
side parse tree. 
 
Figure 1: Translation rules extracted from a 
string-tree pair. 
1346
 
Figure 2: Rule extraction using two different parsers (Berkeley Parser and Collins Parser). The 
shaded rectangles denote the translation rules that can be extracted from the parse tree generated by 
one parser but cannot be extracted from the parse tree generated by the other parser. 
 
To obtain basic translation rules, the (minimal) 
GHKM extraction method proposed in (Galley 
et al 2004) is utilized. The basic idea of GHKM 
extraction is to compute the set of the mini-
mally-sized translation rules that can explain the 
mappings between source-language string and 
target-language tree while respecting the align-
ment and reordering between the two languages. 
For example, from the string-tree pair shown at 
the top of Figure 1, we extract the minimal 
GHKM translation rules r1-6. In addition to 
GHKM extraction, the SPMT models (Marcu et 
al., 2006) are employed to obtain phrasal rules 
that are not covered by GHKM extraction.  For 
example, rule r8  in Figure 1 is a SPMT rule that 
is not obtained in GHKM extraction. Finally, the 
rule composing method (Galley et al, 2006) is 
used to compose two or more minimal GHKM 
or SPMT rules having shared states to form lar-
ger rules. For example, rule r7 in Figure 1 is gen-
erated by composing rules r2 and r6. 
4 Differences in Coverage between Rule 
Extractions with Different Parsers 
As described above, translation rule extraction 
relies on the outputs (parse trees) of parsers. As 
different parsers generally have large diversity 
between their outputs, rule extractions with dif-
ferent parsers generally result in very different 
sets of rules. For example, Figure 2 shows the 
rule extractions on a word-aligned sentence pair 
having two target-trees generated by Berkeley 
Parser and Collins Parser, respectively. It is ob-
served that Figure 2 (a) and (b) cover different 
sets of rule due to the different target-trees used 
in rule extraction. Particularly, well-formed rules 
ra7-a9 are extracted in Figure 2 (a), while they do 
not appear in Figure 2 (b). Also, rules rb7-b9 in 
Figure 2 (b) have the similar situation. This ob-
servation gives us an intuition that there is a 
?complementarity? between the rules extracted 
using different parsers. 
1347
We also conduct a quantitative study to inves-
tigate the impact of using different parsers 
(Berkeley Parser and Collins Parser) on rule 
coverage. Tables 1 shows the statistics of the 
rules extracted from 370K Chinese-English par-
allel sentence pairs1 using the method described 
in Section 3. In addition to the total number of 
rules extracted, the numbers of phrasal rules and 
useful rules are also reported to indicate the rule 
coverage of a rule set. Here phrasal rule refers 
to the rule whose source-side and the yield of its 
target-side contains only one phrase each, with 
optional surrounding variables. According to 
(DeNeefe et al, 2007), the number of phrasal 
rules is a good indicator of the coverage of a rule 
set. useful rule refers to the rule that can be ap-
plied when decoding the test sentences 2 . As 
shown in Table 1, the two resulting rule sets on-
ly have about 70% overlaps (Column 4), and the 
rule coverage increases by about 20% when we 
combine them together (Column 5). This finding 
confirms that the rule coverage can be improved 
by using multiple different parsers in rule extrac-
tion. 
 # of rules # of phrasal 
rules 
# of  
useful rules
Berkeley 3,538,332 2,515,243 549,783 
Collins 3,526,166 2,481,195 553,893 
Overlap 2,542,380 1,907,521 386,983 
Union 4,522,118 3,088,920 716,693 
Table 1: Comparison of rule coverage between 
different rule sets. 
5 Translation Rule Extraction with 
Multiple Parsers 
5.1 Rule Extraction Algorithm 
Motivated by the above observations, we pro-
pose a rule extraction method to improve the 
rule coverage by using multiple parsers.  
Let <f, e, a> be a tuple of <source sentence, 
target sentence, bi-directional word alignments>, 
                                                 
1 LDC2005T10, LDC2003E07, LDC2003E14 and 
LDC2005T06 
2 In this experiment, the test sentences come from 
NIST 2004 and 2005 MT evaluation sets. It should be 
noted that due to the pruning in decoding we cannot 
count the exact number of rules that can be used dur-
ing decoding. In this work, we use an alternative ? 
the number of rules matched with test sentences ? to 
estimate an upper-bound approximately. 
and {P1, ..., PN} be N syntactic parsers in target-
language. The following pseudocode formulizes 
the algorithm for extracting translation rules 
from <f, e, a> using parsers {P1, ..., PN}, where 
Pi(e) returns the parse tree generated by the i-th 
parser Pi. Function GENERATERULES() com-
putes the set of rules for <f, ti, a> by using vari-
ous rule extraction methods, such as  the method 
described in Section 3. 
Multi-Parser based Rule Extraction  
Input: <f, e, a> and P = {P1, ..., PN} 
Output: rule set R 
1 Function MULTIPAREREXTRACTOIN(<f, e, a>, P )
2     for i = 1 to N do                           <  for each parser
3        ti = Pi(e)                                      <  target-tree 
4       Ri = GENERATERULES (f, ti, a) <  rule extraction 
5       R.append(Ri) 
6     return R 
7 Function GENERATERULES ( f, ti, a ) 
8     return rules extracted from <f, ti, a> 
5.2 Learning Rule Probabilities 
In multi-parser based rule extraction, more than 
one parse trees are used, and each of them is as-
sociated with a parsing confidence (e.g. genera-
tive probability of the tree). Ideally, if the parse 
trees used in rule extraction can be accurately 
weighted, the rule probabilities will be better 
estimated according to the parse weights, for 
example, the rules extracted from a parse tree 
having a low weight should be penalized accord-
ingly in the estimation of rule probabilities. Un-
fortunately, the tree probabilities are generally 
incomparable between different parsers due to 
the different parsing models used and ways of 
implementation. Thus we cannot use the poste-
rior probability of a rule?s target-side to estimate 
the fractional count (Mi and Huang, 2008; Liu et 
al., 2009), which is used in maximum-likelihood 
estimation of rule probabilities. In this work, to 
simplify the problem, we assume that all the 
parsers have the same and maximum degrees of 
confidence on their outputs. For a rule r ex-
tracted from a string-tree pair, the count of r is 
defined to be: 
1
( , )
( )
N
i
r i
c r
N
?== ?                     (1) 
where ( , )r i? is 1 if r is extracted by using the i-
th parser, otherwise 0.  
1348
Following Mi and Huang (2008)?s work, three 
conditional rule probabilities are employed for 
experimenting with our method. 
': ( ') ( )
( )Pr( | ( ))
( )
r root r root r
c rr root r
c r=
= ?        (2) 
': ( ') ( )
( )Pr( | ( ))
( )
r lhs r lhs r
c rr lhs r
c r=
= ?             (3) 
': ( ') ( )
( )Pr( | ( ))
( )
r rhs r rhs r
c rr rhs r
c r=
= ?            (4) 
where lhs(r) and rhs(r) are the source-hand and 
target-hand sides of r respectively, and root(r) is 
the root of r?s target-tree. 
5.3 Parser Indicator Features 
For each rule, we define N indicator features (i.e. 
( , )r i? ) to indicate a rule is extracted by using 
which parsers, and add them into the translation 
model. By training the feature weights with Min-
imum Error Rate Training (MERT), the system 
can learn preferences for different parsers auto-
matically. 
6 Experiments 
The experiments are conducted on Chinese-
English translation in a state-of-the-art string-to-
tree SMT system.  
6.1 Experimental Setup 
Our bilingual data consists of 370K sentence 
pairs (9M Chinese words + 10M English words) 
which have been used in the experiment in Sec-
tion 4. GIZA++ is employed to perform the bidi-
rectional word alignment between the source and 
target sentences, and the final word alignment is 
generated using the inter-sect-diag-grow method. 
A 5-gram language model is trained on the tar-
get-side of the bilingual data and the Xinhua 
portion of English Gigaword corpus. The devel-
opment data set comes from NIST MT 2003 
evaluation set. To speed up MERT, sentences 
with more than 20 Chinese words are removed. 
The test sets are the NIST MT evaluation sets of 
2004 and 2005.  
Our baseline MT system is built based on the 
string-to-tree model proposed in (Galley et al, 
2006). In this system, both of minimal GHKM 
(Galley et al, 2004) and SPMT rules (Marcu et 
al., 2006) are extracted from the bilingual corpus, 
and the composed rules are generated by com-
posing two or three minimal GHKM and SPMT 
rules3. We use a CKY-style decoder with cube 
pruning (Huang and Chiang, 2007) and beam 
search to decode new Chinese sentences. By de-
fault, the beam size is set to 30. For integrating 
n-gram language model into decoding efficiently, 
rules containing more than two variables or 
source word sequences are binarized using the 
synchronous binarization method (Zhang et al, 
2006; Xiao et al, 2009).  
The system is evaluated in terms of the case-
insensitive NIST version BLEU (using the 
shortest reference length), and statistical signifi-
cant test is conducted using the re-sampling me-
thod proposed by Koehn (2004). 
6.2 The Parsers 
Four syntactic parsers are chosen for the ex-
periments. They are Stanford Parser4, Berkeley 
Parser 5 , Collins Parser (Dan Bikel?s reimple-
mentation of Collins Model 2) 6  and Charniak 
Parser7. The former two are state-of-the-art non-
lexicalized parsers, while the latter two are state-
of-the-art lexicalized parsers. All the parsers are 
trained on sections 02-21 of the Wall Street 
Journal (WSJ) Treebank, and tuned on section 
22. Table 2 summarizes the performance of the 
parsers. 
Parser Recall Precision F1 
Stanford 86.29% 87.21% 86.75% 
Berkeley 90.18% 90.45% 90.32% 
Collins 89.14% 88.85% 88.99% 
Charniak 89.99% 90.28% 90.13% 
Table 2: Performance of the four parsers on sec-
tion 23 of the WSJ Treebank. 
We parse the target-side of the bilingual data 
using the four parsers individually. From the 1-
best parses generated by these parsers, we obtain 
four baseline rule sets using the method de-
scribed in Section 3, as well as the rule sets usi- 
                                                 
3 Generally a higher baseline can be obtained by 
combining more (unit) rules. However, we find that 
using more composed rules does not affect the impact 
of using multiple parsers. Thus, we choose this set-
ting in order to finish all experiments in time. 
4 http://nlp.stanford.edu/software/lex-parser.shtml 
5 http://code.google.com/p/berkeleyparser/ 
6 http://www.cis.upenn.edu/~dbikel/download.html 
7 http://www.cs.brown.edu/people/ec/#software 
1349
Rule Coverage BLEU4 (%)  Rule set 
# of rules # of  
phrasal rules
# of  
useful rules 
Dev. MT04 MT05 
Stanford (S) 3,679 K 2,581 K 573 K 39.36 36.02 36.98 
Berkeley (B) 3,538 K 2,515 K 549 K 39.32 36.05 36.98 
Collins (Co) 3,526 K 2,481 K 553 K 39.16 36.07 36.91 
B
as
el
in
e 
Charniak (Ch) 3,450 K 2,435 K 540 K 39.24 35.90 36.89 
S + B 4,567 K 3,105 K 726 K 39.87+ 36.57+ 37.47+ 
S + Co 4,734 K 3,202 K 752 K 39.94+ 36.57+ 37.52+ 
S + Ch 4,764 K 3,258 K 751 K 40.01+ 36.51 37.59+ 
B + Co 4,522 K 3,088 K 716 K 39.84+ 36.60+ 37.46+ 
B +  Ch 4,562 K 3,129 K 717 K 39.81+ 36.49 37.41 
2 
pa
rs
er
s 
Co + Ch 4,592 K 3,125 K 727 K 39.75 36.55+ 37.43+ 
S + B + Co 5,331 K 3,543 K 852 K 40.14++ 36.83++ 37.78++ 
S + B + Ch 5,380 K 3,590 K 854 K 40.05+ 36.82++ 37.70+ 
S + Co + Ch 5,551 K 3,663 K 877 K 40.35++ 36.70+ 37.70+ 3 p
ar
se
rs
 
B + Co + Ch 5,294 K 3,544 K 840 K 40.04+ 36.76+ 37.65+ 
4 S + B + Co + Ch 6,005 K 3,940 K 958 K 40.28++ 36.99++ 37.89++ 
Table 5: Evaluation results. + or ++ = significantly better than all the baseline systems (using single 
parser) at the 95% or 99% confidence level. 
 
 Stanford Berkeley Collins Charniak
Stanford 100% 76.72% 73.32% 74.89% 
Berkeley 76.72% 100% 75.69% 76.76% 
Collins 73.32% 75.69% 100% 74.84% 
Charniak 74.89% 76.76% 74.84% 100% 
Table 3: Agreement between different parsers. 
 
ng the multi-parser based rule extraction method.  
Before conducting primary experiments, we first 
investigate the differences between the 1-best 
outputs of the parsers. Table 3 shows the agree-
ment between each pair of parsers. Here the de-
gree of agreement shown in each cell is com-
puted by using one parser?s output as a good 
standard to evaluate the other parser?s output in 
terms of F1 score, and a higher agreement score 
(i.e. F1 score) means that the 1-best outputs of 
the two parsers are more similar to each other. 
We see that the agreement scores between dif-
ferent parsers are always below 80%. This result 
reflects a large diversity in parse trees generated 
by different parsers, and thus confirms our ob-
servations in Section 4. 
We also examine the ?complementarity? be-
tween the baseline rule sets generated by using 
different parsers individually. Table 4 shows the 
results, where the degree of ?complementarity? 
between two rule sets is defined as the percent-
age of the rules in one rule set that are not cov-
ered by the other rule set. It can be regarded as a 
measure of the disagreement between two rule 
sets, and a higher number indicates large ?com-
plementarity?. For example, in Row 2, Column 3 
(Table 4), ?25.09%? means that 25.09% rules in 
the first rule set (using Stanford Parser) are not 
covered by the second rule set (using Berkeley 
Parser). Table 4 shows that there is always a dis-
agreement of over 25% between different rule 
sets. These results indicate that using different 
parsers can lead to a relatively large ?comple-
mentarity? between the rule sets.  
 Stanford Berkeley Collins Charniak
Stanford 0% 25.09% 29.91% 31.43% 
Berkeley 27.98% 0% 27.90% 29.68% 
Collins 32.84% 28.15% 0% 30.89% 
Charniak 35.70% 31.43% 32.37% 0% 
Table 4: Disagreement between the rule sets ob-
tained using different parsers individually. 
6.3 Evaluation of Translations 
We then study the impact of multi-parser based 
rule extraction on translation accuracy.  Table 5 
shows the BLEU scores as well as the rule cov-
erage for various rule extraction methods. We 
see, first of all, that the rule coverage is im-
proved significantly by multi-parser based rule 
extraction. Compared to the baseline method (i.e. 
single-parser based rule extraction), the multi-
parser based rule extraction achieves over 20% 
coverage improvements when only two parsers 
are used, even yields gains of over 50 percentage 
1350
points when all the four parsers are used together. 
Also, BLEU score is improved by multi-parser 
based rule extraction. When two parsers are em-
ployed in rule extraction, there is generally a 
gain of over 0.4 BLEU points on both MT04 and 
MT05 test sets. Further improvements are 
achieved when more parsers are involved. On 
both test sets, using three parsers in rule extrac-
tion generally yields a +0.7 BLEU improvement, 
and using all the parsers together yields a +0.9 
BLEU improvement which is the biggest im-
provement achieved in this set of experiment. 
All these results show that multi-parser based 
rule extraction is an effective way to improve the 
rule coverage as well as the BLEU score of the 
syntax-based MT system. 
An interesting finding is that there seems no 
significant differences in BLEU scores between 
the baseline systems (using single parsers), 
though the parsing performance of the corre-
sponding parsers is very different from each 
other. For example, the MT performance corre-
sponding to Berkeley Parser is very similar to 
that corresponding to Stanford Parser despite a 
4-point difference in F1 score between the two 
parsers. Another example is that Charniak parser 
performs slightly worse than the other three on 
MT task, though it achieves the 2nd best parsing 
performance in all the parsers. This interesting 
finding shows that the performance of syntax-
based MT systems is not very sensitive to the 
parsing performance of the parsers used in rule 
extraction. 
6.4 Preferences for Parsers 
We also investigate the preferences for different 
parsers in our system. Table 6 shows the weights 
of the parser indicator features learned by 
MERT, as well as the number of edges gener-
ated by applying the rules corresponding to dif-
ferent parsers during decoding. Both of the met-
rics are used to evaluate the contributions of the 
parsers to MT decoding. We see that though 
Stanford Parser and Berkeley Parser are shown 
to be relatively more preferred by the decoder, 
there are actually no significant differences in 
the degrees of the contributions of different 
parsers. This result also confirms the fact ob-
served in Table 5 that the MT system does not 
have special preferences for different parsers. 
 
Indicator Weight # of edges 
(Dev.) 
# of edges 
 (MT04) 
# of edges 
(MT05) 
Stanford 0.1990 7.7 M 169.2 M 101.7 M
Berkeley 0.1982 7.7 M 166.3 M 100.2 M
Collins 0.1690 6.9 M 149.9 M   93.1 M
Charniak 0.1729 7.1 M 156.5 M   97.2 M
Table 6: Preferences for different parsers. 
Though Table 6 provides some information 
about the contributions of different parsers, it 
still does not answer how often these rules are 
really used to generate final (1-best) translation. 
Table 7 gives an answer to this question. We see 
that, following the similar trend in Table 5, dif-
ferent parsers have nearly equal contributions in 
generating final translation. 
Indicator # of rules 
used in 1-best  
(Dev.) 
# of rules 
used in 1-best  
(MT04) 
# of rules 
used in 1-best  
(MT05) 
Stanford     2,410 23,513 14,357 
Berkeley     2,455 23,878 14,670 
Collins     2,309 22,654 13,815 
Charniak     2,269 22,406 13,731 
Table 7: Numbers of rules used in generating 
final (1-best) translation. 
6.5 Rule Extraction with k-best Parses 
We also conduct experiments to compare the 
effectiveness of multi-parser based rule extrac-
tion and rule extraction with k-best parses gener-
ated by a single parser. As Berkeley parser is 
one of the best-performing parsers in previous 
experiments, we employ it to generate k-best 
parses in this set of experiment. As shown in 
Figure 3, both of the methods improve the 
BLEU scores by enlarging the set of parse trees 
used in rule extraction. Compared to k-best ex-
traction, multi-parser extraction shows consiste- 
 36.8
 37
 37.2
 37.4
 37.6
 37.8
 38
 38.2
3.5 5.0 6.5
B
LE
U
4(
%
)
# of rules (million)
1-best
4-best
10-best
20-best
30-best 50-best
2 parsers
3 parsers
4 parsers
multi-parser extraction
k-best extraction
 
Figure 3: Multi-parser based rule extraction vs. 
rule extraction with k-best parses (MT05). 
1351
ntly better BLEU scores. Using 4 different pars-
ers, it achieves an improvement of 0.6 BLEU 
points over k-best extraction where even 50-best 
parses are used. 
Finally, we extend multi-parser based rule ex-
traction to extracting rules from the k-best parses 
generated by multiple parsers. Figure 4 shows 
the results on ?S + B + Co + Ch? system. We see 
that multi-parser based rule extraction can bene-
fit from k-best parses, and yields a modest (+0.2 
BLEU points) improvement when extracting 
from 10-best parses. However, since k-best ex-
traction generally results in much slower extrac-
tion speed, it might not be a good choice to use 
k-best parses to improve our method in practice. 
 37.7
 37.8
 37.9
 38
 38.1
 38.2
 38.3
 38.4
 38.5
5.5 6.5 7.5 8.5
B
LE
U
4(
%
)
# of rules (million)
1-best
2-best
5-best
10-best
multi-parser + k-best extraction
 
Figure 4: Multi-parser based rule extraction & 
rule extraction with k-best parses (MT05). 
7 Discussion and Future Work 
In this work, all the parsers are trained using the 
same treebank. To obtain diversified parse trees 
for multi-parser based rule extraction, an alterna-
tive way is to learn parsers on treebanks anno-
tated by different organizations (e.g. Penn Tree-
bank and ICE-GB corpus). Since different tree-
banks can provide us with more diversity in 
parsing, we believe that our system can benefit a 
lot from the parsers that are learned on multiple 
different treebanks individually. But here is a 
problem that due to the different annotation 
standards used, there is generally an incompati-
bility between treebanks annotated by different 
organizations. It will result in that we cannot 
straightforwardly mix the resulting rule sets (or 
heterogeneous grammars for short) for probabil-
ity estimation as well as the use for decoding. To 
solve this problem, a simple solution might be 
that we transform the incompatible rules into a 
unified form. Alternatively, we can use hetero-
geneous decoding (or parsing) techniques (Zhu 
et al, 2010) to make use of heterogeneous 
grammars in the stage of decoding. Both topics 
are very interesting and worth studying in our 
future work.  
Besides k-best extraction, our method can also 
be applied to other rule extraction schemes, such 
as forest-based rule extraction. As (Mi and 
Huang, 2008) has shown that forest-based ex-
traction is more effective than k-best extraction 
in improving translation accuracy, it is expected 
to achieve further improvements by using multi-
parser based rule extraction and forest-based rule 
extraction together. 
8 Conclusions  
In this paper, we present a simple and effective 
method to improve rule coverage by using mul-
tiple parsers in translation rule extraction. Ex-
perimental results show that  
z Using multiple parsers in rule extraction 
achieves large improvements of rule cover-
age over the baseline method where only a 
single parser is used, as well as a +0.9 
BLEU improvement on both NIST 2004 
and 2005 test corpora. 
z The MT system can be further improved by 
using multiple parsers and k-best parses to-
gether. However, with the consideration of 
extraction speed, it might not be a good 
choice to use k-best parses to improve mul-
ti-parser based rule extraction in practice. 
z The MT performance is not influenced by 
the parsing performance of the parsers used 
in rule extraction very much. Actually, the 
MT system does not show different prefer-
ences for different parsers. 
Acknowledgements 
This work was supported in part by the National 
Science Foundation of China (60873091) and 
the Fundamental Research Funds for the Central 
Universities (N090604008). The authors would 
like to thank the anonymous reviewers and Ton-
gran Liu for their pertinent comments for im-
proving the early version of this paper, and Ru-
shan Chen for building parts of the baseline sys-
tem. 
1352
References 
Brooke Cowan, Ivona Ku?erov? and Michael Collins. 
2006. A discriminative model for tree-to-tree 
translation. In Proc. of EMNLP 2006, pages 232-
241. 
Steve DeNeefe, Kevin Knight, Wei Wang and Daniel 
Marcu. 2007. What Can Syntax-based MT Learn 
from Phrase-based MT? In Proc. of EMNLP 2007, 
pages 755-763. 
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency 
insertion grammars. In Proc. of ACL 2005, Ann 
Arbor, Michigan, pages 541-548. 
Jason Eisner. 2003. Learning non-isomorphic tree 
mappings for machine translation. In Proc. of ACL 
2003, pages 205-208. 
Michel Galley, Mark Hopkins, Kevin Knight and 
Daniel Marcu. 2004. What's in a translation rule? 
In Proc. of HLT-NAACL 2004, Boston, USA, 
pages 273-280. 
Michel Galley, Jonathan Graehl, Kevin Knight, Da-
niel Marcu, Steve DeNeefe, Wei Wang and Igna-
cio Thayer. 2006. Scalable inferences and training 
of context-rich syntax translation models. In Proc. 
of COLING/ACL 2006, Sydney, Australia, pages 
961-968. 
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language 
models. In Proc. of ACL 2007, Prague, Czech Re-
public, pages 144-151. 
Liang Huang, Kevin Knight and Aravind Joshi. 2006. 
Statistical syntax-directed translation with ex-
tended domain of locality. In Proc. of AMTA 2006, 
pages 66-73. 
Philipp Koehn. 2004. Statistical Significance Tests 
for Machine Translation Evaluation. In Proc. of 
EMNLP 2004, Barcelona, Spain, pages 388-395. 
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine 
translation. In Proc. of COLING/ACL 2006, Syd-
ney, Australia, pages 609-616. 
Yang Liu, Yajuan L? and Qun Liu. 2009. Improving 
Tree-to-Tree Translation with Packed Forest. In 
Proc. of ACL 2009, pages 558-566. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language phras-
es. In Proc. of EMNLP 2006, Sydney, Australia, 
pages 44-52. 
Haitao Mi and Liang Huang. 2008. Forest-based 
Translation Rule Extraction. In Proc. of EMNLP 
2008, pages 206-214. 
Chris Quirk, Arul Menezes and Colin Cherry. 2005. 
Dependency treelet translation: Syntactically in-
formed phrasal SMT. In Proc. of ACL 2005, pages 
271-279. 
Libin Shen, Jinxi Xu and Ralph Weischedel. 2008. A 
new string-to-dependency machine translation al-
gorithm with a target dependency language model. 
In Proc. of ACL/HLT 2008, pages 577-585. 
Ashish Venugopal, Andreas Zollmann, Noah A. 
Smith and Stephan Vogel. 2008. Wider Pipelines: 
K-best Alignments and Parses in MT Training. In 
Proc. of AMTA 2008, pages 192-201. 
Wei Wang, Kevin Knight and Daniel Marcu. 2007. 
Binarizing Syntax Trees to Improve Syntax-Based 
Machine Translation Accuracy. In Proc. of 
EMNLP-CoNLL 2007, Prague, Czech Republic, 
pages 746-754. 
Tong Xiao, Mu Li, Dongdong Zhang, Jingbo Zhu and 
Ming Zhou. 2009. Better Synchronous Binariza-
tion for Machine Translation. In Proc. of EMNLP 
2009, Singapore, pages 362-370. 
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical machine translation model. In 
Proc. of ACL 2001, pages 132-139. 
Hao Zhang, Liang Huang, Daniel Gildea and Kevin 
Knight. 2006. Synchronous Binarization for Ma-
chine Translation. In Proc. of HLT-NAACL 2006, 
New York, USA, pages 256- 263. 
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, 
Chew Lim Tan and Sheng Li. 2008. A Tree Se-
quence Alignment-based Tree-to-Tree Translation 
Model. In Proc. of ACL/HLT 2008, pages 559-567. 
Muhua Zhu, Jingbo Zhu and Tong Xiao. 2010. Het-
erogeneous Parsing via Collaborative Decoding. In 
Proc. of COLING 2010. 
1353
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 2064?2074, Dublin, Ireland, August 23-29 2014.
Effective Incorporation of Source Syntax into
Hierarchical Phrase-based Translation
Tong Xiao??, Adri
`
a de Gispert?, Jingbo Zhu??, Bill Byrne?
? Northeastern University, Shenyang 110819, China
? Hangzhou YaTuo Company, Hangzhou 310012, China
? University of Cambridge, CB2 1PZ Cambridge, U.K.
{xiaotong,zhujingbo}@mail.neu.edu.cn
{ad465,wjb31}@eng.cam.ac.uk
Abstract
In this paper we explicitly consider source language syntactic information in both rule extraction
and decoding for hierarchical phrase-based translation. We obtain tree-to-string rules by the
GHKM method and use them to complement Hiero-style rules. All these rules are then employed
to decode new sentences with source language parse trees. We experiment with our approach in
a state-of-the-art Chinese-English system and demonstrate +1.2 and +0.8 BLEU improvements
on the NIST newswire and web evaluation data of MT08 and MT12.
1 Introduction
Synchronous context free grammars (SCFGs) are widely used in statistical machine translation (SMT),
with hierarchical phrase-based translation (Chiang, 2005) as the dominant approach. Hiero grammars
are easily extracted from word-aligned parallel corpora and can capture complex nested translation re-
lationships. Hiero grammars are formally syntactic, but rules are not constrained by source or target
language syntax. This lack of constraint can lead to intractable decoding and bad performance due to
the over-generation of derivations in translation. To avoid these problems, the extraction and application
of SCFG rules is typically constrained by a source language span limit; (non-glue) rules are lexicalised;
and rules are limited to two non-terminals which are not allowed to be adjacent in the source language.
These constraints can yield good performing translation systems, although at a sacrifice in the ability to
model long-distance movement and complex reordering of multiple constituents.
By contrast, the GHKM approach to translation (Galley et al., 2006) relies on a syntactic parse on
either the source or target language side to guide SCFG extraction and translation. The parse tree provides
linguistically-motivated constraints both in grammar extraction and in translation. This allows for looser
span constraints; rules need not be lexicalised; and rules can have more than two non-terminals to model
complex reordering multiple constituents. There are also modelling benefits as more meaningful features
can be used to encourage derivations with ?well-formed? syntactic tree structures. However, GHKM can
have robustness problems in that translation relies on the quality of the parse tree and the diversity of
rule types can lead to sparsity and limited coverage.
In this paper we describe a simple but effective approach to introducing source language syntax into
hierarchical phrase-based translation to get the benefits of both approaches. Unlike previous work, we
do not resort to soft/hard syntactic constraints (Marton and Resnik, 2008; Li et al., 2013) or Hiero-style
rule extraction algorithms for incorporating syntactic annotation into SCFGs (Zollmann and Venugopal,
2006; Zhao and Al-Onaizan, 2008; Chiang, 2010). We instead use GHKM syntactic rules to augment the
baseline Hiero grammar and decoder. Our approach uses GHKM rules if possible and Hiero rules if not.
We report performance on a state-of-the-art Chinese-English system. In a large-scale NIST evaluation
task, we find significant improvements of over 1.2 and 0.8 BLEU relative to a strong Hiero baseline on
the newswire and web evaluation data of MT08 and MT12. We also investigate variations in the GHKM
formalism and find, for example, that our approach works well with binarized trees.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
2064
IP
NP
PN
?
VP
PP
P
?
NP
NN
??
VP
VV
??
NN
??
he
was
satisfied with the
answer
Hiero-style SCFG Rules
h
1
X? ??, he?
h
2
X? ??, with?
h
3
X? ???, the answer?
h
4
X? ?????, was satisfied?
h
5
X? ?X
1
????, was satisfied X
1
?
h
6
X? ?X
1
?? X
2
, was X
2
X
1
?
h
7
X? ?X
1
? X
2
????,
X
1
was satisfied with X
2
?
Tree-to-String Rules
r
1
NP(PN(?))? he
r
2
P(?)? with
r
3
NP(NN(??))? the answer
r
4
VP(VV(??) NN(??))? was satisfied
r
5
PP(x
1
:P x
2
:NP)? x
1
x
2
r
6
VP(x
1
:PP x
2
:VP)? x
2
x
1
r
7
IP(x
1
:NP x
2
:VP)? x
1
x
2
r
8
VP(PP(P(?) x
1
:NP) x
2
:VP)? x
2
with x
1
Figure 1: Hiero-syle and tree-to-string rules extracted from a pair of word-aligned Chinese-English
sentences with a source language (Chinese) parse tree.
2 Background
2.1 Hierarchical Phrase-based Translation
In the hierarchical phrase-based approach, translation is modelled using SCFGs. In general, probabilistic
SCFGs can be learned from word-aligned parallel data using heuristic methods (Chiang, 2007). We can
first extract initial phrase pairs and then obtain hierarchical phrase rules (i.e., rules with non-terminals
on the right hand side). Once the SCFG is obtained, new sentences can be decoded by finding the most
likely derivation of SCFG rules. See Figure 1 for example rules extracted from a sentence pair with word
alignments. A sequence of such rules covering the words of the source sentence is a SCFG derivation,
e.g., rules h
7
, h
1
and h
3
generate a derivation for the sentence pair.
The Hiero SCFG allows vast numbers of derivations which can make unconstrained decoding in-
tractable. In practice, several constraints are applied to control the model size and reduce ambiguity.
Typically these are: (a) a rule span limit to be applied in decoding and sometimes also in rule extraction,
set to 10; (b) a limit on the rank of the grammar (number of non-terminals that can appear on a rule), set
to 2; and (c) a prohibition of consecutive non-terminals on the source language side of a rule (except the
glue rules).
2.2 Tree-to-String Translation
Instead of modelling the problem based on surface strings, tree-to-string systems model the translation
equivalency relations from source language syntactic trees to target language strings using derivations
of tree-to-string rules (Liu et al., 2006; Mi et al., 2008; Huang and Mi, 2010; Feng et al., 2012). A
tree-to-string rule is a tuple ?s
r
, t
r
,??, where s
r
is a source language tree-fragment with terminals and
non-terminals at leaves; t
r
is a string of target-language terminals and non-terminals; and ? is a 1-to-1
alignment between the non-terminals of s
r
and t
r
, for example, VP(VV(??) x
1
:NN)? increases x
1
is a tree-to-string rule, where the non-terminals labeled with the same index x
1
indicate the alignment.
To obtain tree-to-string rules, a popular way is to perform the GHKM rule extraction (Galley et al.,
2006) on the bilingual sentences with both word alignment and source (or target) language phrase-
structure tree annotations. In GHKM extraction, we first compute the set of the minimally-sized transla-
tion rules that can explain the mappings between source language tree and target-language string while
respecting the alignment and reordering between the two languages. More complex rules are then learned
by composing two or more minimal rules. See Figure 1 for rules extracted using GHKM.
One of the advantages of the above model is that non-terminals in tree-to-string rules are linguistically
2065
rule
match
decoding
input
string
Hiero
SCFG
ouput
string
(a) decoding with Hiero rules only
rule
match
decoding
input
string&tree
larger
SCFG
Hiero
SCFG
t-to-s
rules
ouput
string
(b) decoding with Hiero and tree-to-string rules
Figure 2: Overview of the Hiero baseline (a) and
our approach (b). ?means input or output of the
decoder. t-to-s is a short for tree-to-string.
VP
PP
P
?
x
1
:NP
x
2
:VP
x
2
with
x
1
X
?
?
?
X
1
X
2
, X
2
with
X
1
?
tree-to-string:
Hiero:
Figure 3: Converting the tree-to-string rule r
8
from Figure 1 to a Hiero-style rule.
motivated and can span word sequences with arbitrary length. Also, one can use rules with consecutive
(or more than two) source language non-terminals when the source language parse tree is available. For
example, r
8
in Figure 1 has a good Chinese syntactic structure indicating the reordered translations of NP
and VP. However, such a rule would not normally be included in a Hiero grammar, as it would require
consecutive source language non-terminals (see Figure 3).
3 The Proposed Approach
Both the tree-to-string model and the hierarchical phrase-based model have their own strengths and
weaknesses. For example, tree-to-string systems are good at modelling long distance reordering, while
hierarchical phrase-based systems are relatively more powerful in handling ill-formed sentences
1
and
free translations (Zhao and Al-Onaizan, 2008; Vilar et al., 2010). Here we present a method to enhance
hierarchical phrase-based systems with tree-to-string rules and benefit from both models. The idea is
simple: we obtain both the tree-to-string grammar and the Hiero-style SCFG from the training data, and
then use tree-to-string rules as additional rules in decoding with the SCFG.
Figure 2 shows an overview of our approach and the usual hierarchical phrase-based approach. Our
approach requires source language parse trees to be input in both rule extraction and decoding. In rule
extraction, we acquire tree-to-string rules using the GHKM method and Hiero-style rules using the Hiero-
style rule extraction method to form a larger SCFG. Then, we make use of both the input string and parse
tree to decode with the SCFG rules. We now describe our approach.
3.1 Transforming Tree-to-String Rules into SCFG Rules
As described in Section 2, tree-to-string rules have a different form from that of SCFG rules. We will use
tree-to-string rules in our hierarchical phrase-based systems by converting each tree-to-string rule into an
SCFG rule. The purpose of doing this is to make tree-to-string rules directly accessible to the Hiero-style
decoder which performs decoding with SCFG rules.
The rule mapping is straightforward: given a tree-to-string rule ?s
r
, t
r
,??, we take the frontier nodes
of s
r
as the source language part of the right hand side of the resulting SCFG rule, and keep t
r
and
? unchanged. Then we replace the non-terminal label with that used in the hierarchical phrase-based
system (e.g., X). See Figure 3 for rule mapping of rule r
8
of Figure 1.
In this way, every tree-to-string rule is associated with exactly one SCFG rule. Therefore we can
obtain a larger SCFG by combining the rules from the original Hiero-style SCFG and the transformed
tree-to-string rules. As explained next, to prevent computational problems we will apply these new rules
1
For example, the parser fails for 4% of the sentences in our training corpus, and 3% and 6% of the newswire and web
development/test sentences, indicating that the data is sometimes ill-formed.
2066
only on the spans that are consistent with the input parse trees. The main goal is to use the tree and the
adapted tree-to-string rules to provide the decoder with new linguistically-sensible translation hypotheses
that may be prevented by the usual Hiero constraints, and to do so without incurring a computational
explosion.
We categorize SCFG rules into two categories based on their availability in Hiero and GHKM extrac-
tion. If an SCFG rule is obtained from Hiero extraction, it is a type 1 rule; If not (i.e., this rule is only
available in GHKM extraction), it is a type 2 rule. E.g., the SCFG rule in Figure 3 is a type 2 rule because
it is not available in the original Hiero-style SCFG but can be generated from the tree-to-string rule.
Next we describe how each of these rule types are applied in decoding. We also describe which
features are used and how they are computed for each rule type.
3.2 Decoding
Both types of SCFG rules can be employed by usual Hiero decoders with a slight modification. Here
we follow the description of Hiero decoding by Iglesias et al. (2011). The source sentence is parsed
under the Hiero grammar using the CYK algorithm. Each cell in the CYK grid has associated with it a
list of rules that apply to its span; these rules are used to construct a recursive transition network (RTN)
which represents all translations of the source sentence under the grammar. The RTN is expanded to a
weighted finite state automaton for composition with n-gram language models (de Gispert et al., 2010).
Translations are produced via shortest path computation.
This procedure accommodates type 1 rules directly. For tree-to-string rules associated with type 2, we
attempt to match rules to the source syntactic tree. If a match is found: the source span of the matching
tree fragment is noted and the CYK cell for that span is selected; the tree-to-string rule is converted to
a Hiero-style rule; and that rule is added to the list of rules in the selected CYK cell. Once this process
is finished, RTN construction, expansion, and language model composition proceeds as usual. Similar
modifications could be made to incorporate these rules into cube pruning (Chiang, 2007), cube growing
(Huang and Chiang, 2007), and PDT intersection and expansion (Iglesias et al., 2011). We now elaborate
on the rule matching strategy.
Type 1 Rules The source sentence is parsed as is usual in Hiero-style translation, with the exception
that we impose no span limit on rule applications for source spans corresponding to constituents in the
Chinese syntactic tree. Rule matching, the procedure that determines if a rule applies to a source span, is
based on string matching (see Figure 4(a)). For example, the type 1 rule h
9
in Figure 4(c) can be applied
to spans (1,13) and (2,13) since both of them agree with tree constituents (see Figure 4(b)). But h
9
is
not applied to span (3,13) because that span is longer than 10 words and agrees with no syntactic tree
constituent.
Type 2 Rules If the source side of a tree-to-string rule matches an input tree fragment: 1) that rule
is converted to a Hiero-style SCFG rule (Section 3.1); and 2) the Hiero-style rule is added to the rules
linked with the CYK grid cell associated with the span of the source syntactic tree fragment. Here, rules
are applied via tree matching. For example, rule h
11
in Figure 4(b) matches the tree fragment spanning
positions (2,13).
It is worth noting that some type 1 rules may be found via both Hiero-style and tree-to-string grammar
extraction. In this case we monitor whether a rule can be applied as a tree-to-string rule using tree-
matching so that features (Section 3.3) and weights can be set appropriately. As an example, rule h
10
in
Figure 4 is available in both extraction methods. For span (2,11), this rule can be matched via both string
matching and tree matching. We then note that we can apply h
10
as a tree-to-string rule for span (2, 11)
and activate the corresponding features defined in Section 3.3. For other spans (e.g., spans (2,3)-(2,10)),
no tree fragments can be matched and the baseline features are used for h
10
.
3.3 Features
The baseline feature set used in this work consists of 12 features (Pino et al., 2013), including a 4-gram
language model, a strong 5-gram language model, bidirectional translation probabilities, bidirectional
lexical weights, a word count, a phrase count, a glue rule count, a frequency-1 rule count, a frequency-2
2067
h9
: X? ?
X
1
?? , satisfied with X1 ?
???
1
?
2
??
3
?
4
?
5
?
6
?
7
??
8
?
9
??
10
??
11
??
12
??
13
. . .
.
.
.
.
.
.
.
.
.
Chart Used in Decoding
span
(10,13)
matching
(a) matching a type 1 rule (h
9
) with the input string
IP
NP
NR
???
1
VP
PP
P
?
2
NP
??
3
?
4
?
5
?
6
?
7
??
8
?
9
??
10
??
11
VP
VV
??
12
NN
??
13
VP(PP(P(?) x
1
:NP) x
2
:VP)
? x
2
with x
1
h
11
: X? ?? X
1
X
2
,
X
2
with X
1
?
converting
. . .
.
.
.
.
.
.
.
.
.
Chart Used in Decoding
matching
span
(2,13)
(b) matching a type 2 rule (h
11
) with the input parse tree
ID Type Hiero-style Rule Tree-to-string Rule Applicable Spans
h
8
type 1 X? ?????, is satisfied ? N/A (12,13)
h
9
type 1 X? ? X
1
??, satisfied with X
1
? N/A (i,13), i = 1, 2 or 4 ? i ? 12
h
10
type 1 X? ?? X
1
, with X
1
? PP(P(?) x
1
NP)? with NPx
1
(2,j), 3 ? j ? 11 or j = 13
h
11
type 2 X? ?? X
1
X
2
, X
2
with X
1
? VP(PP(P(?) x
1
:NP) x
2
:VP) (2,13)
? x
2
with x
1
(c) example rules used in decoding
Figure 4: Decoding with both Hiero-style and tree-to-string grammars (span limit = 10). A span (i,j)
means spanning from position i to position j.
rule count, and a larger-than-frequency-2 rule count
2
. In addition, we introduce several features for
applying tree-to-string rules.
? Rule type indicators. We consider four indicator features, indicating tree-to-string rules, lexicalized
tree-to-string rules, rules with consecutive non-terminals, and non-lexicalized rules. Note that the tree-
to-string rule indicator feature is in principle a generalization of the soft syntactic features (Marton and
Resnik, 2008), in that a bonus (or penalty) is applied when a rule application is consistent with a source
tree constituent. The difference lies in that the tree-to-string rule indicator feature does not distinguish
between different syntactic labels, whereas soft syntactic features do.
? Features in syntactic MT. In general tree-to-string rules have their own features which are different
from those used in Hiero-style systems. For example, the features in syntactic MT systems can be
defined as the generation probabilities conditioned on the root symbol of the tree-fragment. Here we
choose five popular features used in syntactic MT systems, including the bi-directional phrase-based
conditional translation probabilities (Marcu et al., 2006) and three syntax-based conditional probabil-
ities (Mi and Huang, 2008). All these probabilities can be computed by relative-frequency estimates.
For example, the phrase-based features are the probabilities of translating between the frontier nodes
of s
r
and t
r
. The syntax-based features are the probabilities of generating r conditioned on its root,
2
We experimented with soft syntactic features (Marton and Resnik, 2008) but found no improvement over our baseline
system.
2068
source and target language sides, respectively. More formally, we use the following estimates for these
probabilities:
P
phr
(t
r
| s
r
) =
?
r
??
:?(s
r
??
)=?(s
r
)?t
r
??
=t
r
c(r
??
)
?
r
?
:?(s
r
?
)=?(s
r
)
c(r
?
)
P
phr
(s
r
| t
r
) =
?
r
??
:?(s
r
??
)=?(s
r
)?t
r
??
=t
r
c(r
??
)
?
r
?
:t
r
?
=t
r
c(r
?
)
P(r | root(r)) =
c(r)
?
r
?
:root(r
?
)=root(r)
c(r
?
)
P(r | s
r
) =
c(r)
?
r
?
:s
r
?
=s
r
c(r
?
)
P(r | t
r
) =
c(r)
?
r
?
:t
r
?
=t
r
c(r
?
)
where c(r) is the count of r, and root(?) and ?(?) are functions that return the source root symbol for
a tree-to-string rule and the sequence of leaf nodes for a tree-fragment respectively.
4 Evaluation
4.1 Experimental Setup
We report results in the NIST MT12 Chinese-English task, where our baseline system was among the top
academic systems. The parallel training corpus consists of 9.2 million sentence pairs which are provided
within the NIST Chinese-English MT12 track. Word alignments are obtained using MTTK (Deng and
Byrne, 2008) in both Chinese-to-English and English-to-Chinese directions, and then unioning the links.
The data from newswire and web genres was used for tuning and test. The development sets contain
1,755 sentences and 2160 sentences for the two genres respectively. The test sets (newswire: 1,779
sentences, web: 1768 sentences) contain all newswire and web evaluation data of MT08 (mt08), MT12
(mt12), and MT08 progress test (mt08.p). All Chinese sentences in the training, development and test
sets were parsed using the Berkeley parser (Petrov and Klein, 2007). A Kneser-Ney 4-gram language
model was trained on the AFP and Xinhua portions of the English Gigaword in addition to the English
side of the parallel corpus. A stronger 5-gram language model was trained on all English data of NIST
MT12 and the Google counts corpus using the ?stupid? backoff method (Brants et al., 2007).
For decoding we use HiFST, which is implemented with weighted finite state transducers (de Gispert
et al., 2010). A two-pass decoding strategy is adopted; first, only the 4-gram language model and the
translation model are activated; and then, the 5-gram language model is applied for second-pass rescoring
of the translation lattices generated by the first-pass decoding stage. We extracted SCFG rules from
the parallel corpus using the standard heuristics (Chiang, 2007) and filtering strategies (Iglesias et al.,
2009). The span limit was set to 10 in extracting basic phrases and decoding. All features weights were
optimized using lattice-based minimum error rate training (Macherey et al., 2008).
For tree-to-string extraction, we used a reimplementation of the GHKM method (Xiao et al., 2012) and
extracted rules from a 600K-sentence portion of the parallel data. To prune the tree-to-string rule set, we
restricted the extraction to rules with at most 5 frontier non-terminals and 5 terminals. Also, we discarded
lexicalized rules with a Chinese-to-English translation probability of < 0.02 and non-lexicalized rules
with a Chinese-to-English translation probability of < 0.10.
4.2 Results
We report MT performance in Table 1 by case-insensitive BLEU (Papineni et al., 2002). The experiments
are organized as follows:
? Baseline and Span Limits (exp01 and exp02)
First we study the effect of removing the span limit for tree constituents, that is, SCFG rules can be
2069
Entry System Newswire Web
tune mt08 mt12 mt08.p all test tune mt08 mt12 mt08.p all test
(1755) (691) (400) (688) (1779) (2160) (666) (420) (682) (1768)
exp01 baseline 35.84 35.85 35.47 35.50 35.63* 29.98 25.15 23.07 27.19 25.33*
exp02 += no span limit 36.05 36.08 35.70 35.54 35.79* 30.11 25.28 23.08 27.17 25.37*
exp03 += t-to-s rules 36.63 36.51 36.08 36.09 36.25* 30.80 26.00 23.08 27.80 25.83*
exp04 += t-to-s features 36.82 36.49 36.53 36.16 36.38* 30.91 26.03 23.27 27.85 25.98*
exp05 t-to-s baseline 34.63 34.44 34.87 33.66 34.25* 28.30 23.40 21.38 25.30 23.56*
exp06 exp04 on spans > 10 36.17 36.11 35.71 35.86 35.92* 30.18 25.30 23.12 27.36 25.45*
exp07 exp04 with null trans. 36.10 36.03 35.35 34.86 35.42* 29.96 25.32 22.58 23.33 24.12*
exp08 exp04 + left binariz. 37.11 37.46 37.03 36.30 36.91* 31.18 26.15 23.54 27.98 26.13*
exp09 exp04 + right binariz. 36.58 36.56 36.41 35.70 36.20* 31.06 25.94 23.47 27.48 25.88*
exp10 exp04 + forest binariz. 37.03 37.27 37.09 36.62 36.98* 31.20 25.99 23.59 28.09 26.15*
Table 1: Case-insensitive BLEU[%] scores of various systems. += means incrementally adding method-
s/features to the previous system. * means that a system is significantly different than the exp01 baseline
at p < 0.01.
applied to any spans when they respect the tree constituents of the input tree. It can be regarded as
the simplest way of using source syntax in Hiero-style systems. Seen from Table 1, removing the
span limit shows modest BLEU improvements. It agrees with the previous result that loosening the
constraints on spans is helpful to systems based on the hard syntactic constraints (Li et al., 2013).
? GHKM+Hiero (exp03 and exp04)
The results of our proposed approach (w/o new features) are reported in exp03 and exp04. We see that
incorporating tree-to-string rules yields +0.6 and +0.5 improvements on the collected newswire and
web test sets (exp03 vs exp01). The new features (Section 3.3) give a further improvement (exp04 vs
exp03). This result confirms that the system can learn a preference for certain types of rules using the
new features.
? Impact of Search Space (exp05)
We also study the impact of search space on system performance. To do this, we force the improved
system (exp04) to respect source tree constituents and to discard any hypotheses which violate the
tree constituent constraints. Seen from exp05, this system has a lower BLEU score than both the
Hiero baseline (exp01) and GHKM+Hiero system (exp04), strongly suggesting that restricting MT
systems to a smaller space of hypotheses is harmful.
? GHKM+Hiero, Spans > 10 Only (exp06)
Another interesting question is whether tree-to-string rules and features are more helpful to larger
spans. We restricted our approach to spans > 10 only and conducted another experiment. As is shown
in exp06, applying tree-to-string rules and features for large spans is beneficial (exp06 vs. exp01). But
it underperforms the system with the full use of tree-to-string rules (exp06 vs. exp04). This interesting
observation implies that applying tree-to-string rules on smaller spans introduces good hypotheses that
can be selected with our additional features.
? Impact of Failed Parses (exp07)
As noted in Section 3, the parser fails to parse some of the sentences in our experiments. In this case
our approach generates the baseline result using the Hiero model (i.e., type 1 rules only). To investigate
the effect of failed parse trees on system performance, we also report the BLEU score including null
translations for which the parser fails. As shown in exp07, there are significantly lower BLEU scores
when null translations are included. It indicates that our approach is more robust than standard tree-
to-string systems which would generate an empty translation if the source language parser fails.
? Results on Binarization (exp08-10)
Tree binarization is a widely used method to improve syntactic MT systems (Wang et al., 2010).
exp08-10 show the results of our improved system with left-heavy, right-heavy and forest-based bina-
2070
Reference: After North Korea demanded concessions from U.S. again before the start of a new round of six-nation talks , ...
Baseline: In the new round of six-nation talks on North Korea again demanded that U.S. in the former promise concessions , ...
GHKM+Hiero: After
North Korea again demanded that U.S. promised concessions before the new round of six-nation talks
, ...
a Hiero rule X? ?? X
1
?, after X
1
? is applied on span (1,15)
Input:
IP
PP
P
?
1
LCP
IP
??
2
??
3
??
4
??
5
?
6
?
7
??
8
?
9
?
10
??
11
?
12
??
13
??
14
LC
?
15
PU
,
VP
...
Reference: The Chinese star performance troupe presented a wonderful Peking opera as well as singing and dancing
Reference: performance to Hong Kong audience .
Baseline: Star troupe of China, highlights of Peking opera and dance show to the audience of Hong Kong .
GHKM+Hiero: Chinese star troupe presented a wonderful Peking opera singing and dancing
to
Hong Kong audience
.
Input:
A tree-to-string rule is applied:
(VP BA(?) x
1
:NP x
2
:VP PP(P(?) x
3
:NP))
? x
2
x
1
to x
3
IP
NP
??
1
??
2
???
3
VP
BA
?
4
NP
?
5
?
6
??
7
?
8
??
9
??
10
VP
VV
??
11
PP
P
?
12
NP
??
13
??
14
.
Figure 5: Comparison of translations generated by the baseline and improved systems.
rization
3
. We see that left-heavy binarization is very helpful and exp08 achieves overall improvements
of 1.2 and 0.8 BLEU points on the newsire and web data. In contrast, right-heavy binarization does
not yield promising performance. This agrees with the previous report (Wang et al., 2010) that MT
systems prefer to use certain ways of binarization in most cases. exp10 shows that the additional trees
introduced in our forest-based scheme are not sufficient to make a big impact on BLEU scores. Pos-
sibly larger gains can be obtained if taking a forest of parse trees from the source parser, but this is
outside the scope of this paper.
4.3 Analysis
We then analyse rule usage in the 1-best derivations for our improved system on the tuning set. We find
that type 2 rules represent 13.97% of the rules used in the 1-best derivations. Also, 44.45% of the applied
rules are available from the tree-to-string model (i.e., rules that use the features described in Section 3.3).
These numbers indicate that the tree-to-string rules are beneficial and our decoder likes to use them.
Finally, we discuss two real translation examples from our tuning set. See Figure 5 for translations
generated by different systems. In the first example, the Chinese input sentence contains? ...? which
is usually translated into after ... (i.e., a Hiero rule X? ?? X
1
?, after X
1
?). However, because the
?? ...?? pattern spans 15 words and that is beyond the span limit, our baseline is unable to apply this
desired rule and chooses a wrong translation in for the Chinese word ?. When the source parse tree
3
We found that the CTB-style parse trees usually have a very flat top-level IP (i.e., single clause) tree structure. As the IP
structure in Chinese is very complicated, the system might prefer a flexible binarization scheme. Thus we considered both left
and right-heavy binarization to form a binarization forest for IPs in Chinese parse trees, and binarized other tree constituents in
a left-heavy fashion.
2071
is available, our approach removes the span limit for spans that agree with the tree constituents. In this
case, the MT system successfully applies the rule on span (1, 15) and generates a much better translation.
In the second example, the translation of the input sentence requires complex reordering of adjacent
constituents. The baseline system cannot handle this case and generates a monotonic translation using
the glue rules. This results in a wrong order for the translation of Chinese verb?? (show). By contrast,
the improved system chooses a tree-to-string rule with three non-terminals (some of which are adjacent
in the source language) and perfectly performs a syntactic movement of the required tree constituents.
5 Related Work
Recently linguistically-motivated models have been intensively investigated in MT. In particular, source
tree-based models (Liu et al., 2006; Huang et al., 2006; Eisner, 2003; Zhang et al., 2008; Liu et al.,
2009a; Xie et al., 2011) have received growing interest due to their good abilities in modelling source
language syntax for better lexicon selection and reordering. Alternatively, the hierarchical phrase-based
approach (Chiang, 2005) considers the underlying hierarchical structures of sentences but does not re-
quire linguistically syntactic trees on either language side.
There are several lines of work for augmenting hierarchical phrase-based systems with the use of
source language phrase-structure trees. Liu et al. (2009b) describe novel approaches to translation under
multiple translation grammars. Their approach is very much motivated by system combination, and they
develop procedures for joint decoding and optimisation within a single system that give the benefit of
combining hypotheses from multiple systems. They demonstrate their approach by combining full tree-
to-string and Hiero systems. Our approach is much simpler and emphasises changes to the grammar
rather than the decoder or its parameter optimisation (MERT). Our aim is to augment the search space
of Hiero with linguistically-motivated hypotheses, and not to develop a new decoder that is capable of
translation under multiple grammars. Moreover, we consider Hiero as the backbone model and only
introduce tree-to-string rules where they can contribute; we show that extracting tree-to-string rules from
just 10% of the data suffices to get good gains. This results in a small number of tree-to-string rules and
does not slow down the decoder.
Another related line of work is to introduce syntactic constraints or annotations to hierarchical phrase-
based systems. Marton and Resnik (2008) and Li et al. (2013) proposed several soft or hard constraints to
model syntactic compatibility of Hiero derivations and input source language parse trees. We note that,
despite significant development effort, we were not able to improve our baseline through the use of these
soft syntactic constraints; it was this experience that led us to develop the hybrid approach described in
this paper.
Several research groups used syntactic labels as non-terminal symbols in their SCFG rules and develop
new features (Zollmann and Venugopal, 2006; Zhao and Al-Onaizan, 2008; Chiang, 2010; Hoang and
Koehn, 2010). However, all these methods still resort to rule extraction procedures similar to that of the
standard phrase/hierarchical rule extraction method. In contrast, we use the GHKM method which is a
mature technique to extract rules from tree-string pairs but does not impose those Hiero-style constraints
on rule extraction. More importantly, we consider the hierarchical syntactic tree structure to make use of
well-formed rules in decoding, while such information is not used in standard SCFG-based systems. We
also keep to the simpler non-terminals of Hiero, and do not ?decorate? any non-terminals with syntactic
or other information.
6 Conclusion
We have presented an approach to improving Hiero-style systems by augmenting the SCFG with tree-
to-string rules and syntax-based features. The input parse trees are used to introduce new linguistically-
sensible hypotheses into the translation search space while maintaining the Hiero robustness qualities
and avoiding computational explosion. We obtain significant improvements over a strong Hiero baseline
in Chinese-to-English. Further improvements are achieved when applying tree binarization.
2072
Acknowledgements
This work was done while the first author was visiting the speech group at University of Cambridge, and
was supported in part by the National Science Foundation of China (Grants 61272376 and 61300097),
and the China Postdoctoral Science Foundation (Grant 2013M530131). We would like to thank the
anonymous reviewers for their pertinent and insightful comments. We also would like to thank Juan
Pino, Rory Waite, Federico Flego and Gonzalo Iglesias for building parts of the baseline system.
References
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. 2007. Large Language Models in
Machine Translation. In Proceedings of EMNLP-CoNLL, pages 858?867, Prague, Czech Republic.
David Chiang. 2005. A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proceedings of
ACL, pages 263?270, Ann Arbor, Michigan, USA.
David Chiang. 2007. Hierarchical Phrase-Based Translation. Computational Linguistics, 33:45?60.
David Chiang. 2010. Learning to Translate with Source and Target Syntax. In Proceedings of ACL, pages 1443?
1452, Uppsala, Sweden.
Adri`a de Gispert, Gonzalo Iglesias, Graeme Blackwood, Eduardo R. Banga, and William Byrne. 2010. Hierarchi-
cal Phrase-Based Translation with Weighted Finite-State Transducers and Shallow-n Grammars. Computational
Linguistics, 36(3):505?533.
Yonggang Deng and William Byrne. 2008. HMM Word and Phrase Alignment for Statistical Machine Translation.
IEEE Transactions on Audio, Speech & Language Processing, 16(3):494?507.
Jason Eisner. 2003. Learning Non-Isomorphic Tree Mappings for Machine Translation. In Proceedings of ACL,
pages 205?208, Sapporo, Japan.
Yang Feng, Yang Liu, Qun Liu, and Trevor Cohn. 2012. Left-to-Right Tree-to-String Decoding with Prediction.
In Proceedings of EMNLP-CoNLL, pages 1191?1200, Jeju Island, Korea.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thay-
er. 2006. Scalable Inference and Training of Context-Rich Syntactic Translation Models. In Proceedings of
COLING-ACL, pages 961?968, Sydney, Australia.
Hieu Hoang and Philipp Koehn. 2010. Improved translation with source syntax labels. In Proceedings of the Joint
Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 409?417, Uppsala, Sweden.
Liang Huang and David Chiang. 2007. Forest Rescoring: Faster Decoding with Integrated Language Models. In
Proceedings of ACL, pages 144?151, Prague, Czech Republic.
Liang Huang and Haitao Mi. 2010. Efficient Incremental Decoding for Tree-to-String Translation. In Proceedings
of EMNLP, pages 273?283, Cambridge, MA, USA.
Liang Huang, Knight Kevin, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain
of locality. In Proceedings of AMTA, pages 66?73, Cambridge, MA, USA.
Gonzalo Iglesias, Adri`a de Gispert, Eduardo R. Banga, and William Byrne. 2009. Rule Filtering by Pattern for
Efficient Hierarchical Translation. In Proceedings of EACL, pages 380?388, Athens, Greece.
Gonzalo Iglesias, Cyril Allauzen, William Byrne, Adri`a de Gispert, and Michael Riley. 2011. Hierarchical Phrase-
based Translation Representations. In Proceedings of EMNLP, pages 1373?1383, Edinburgh, Scotland, UK.
Junhui Li, Philip Resnik, and Hal Daum?e III. 2013. Modeling Syntactic and Semantic Structures in Hierarchical
Phrase-based Translation. In Proceedings of NAACL-HLT, pages 540?549, Atlanta, Georgia.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-String Alignment Template for Statistical Machine Transla-
tion. In Proceedings of COLING-ACL, pages 609?616, Sydney, Australia.
Yang Liu, Yajuan L?u, and Qun Liu. 2009a. Improving Tree-to-Tree Translation with Packed Forests. In Proceed-
ings of ACL-IJCNLP, pages 558?566, Suntec, Singapore.
2073
Yang Liu, Haitao Mi, Yang Feng, and Qun Liu. 2009b. Joint decoding with multiple translation models. In
Proceedings of ACL-IJCNLP, pages 576?584, Suntec, Singapore.
Wolfgang Macherey, Franz Och, Ignacio Thayer, and Jakob Uszkoreit. 2008. Lattice-based Minimum Error Rate
Training for Statistical Machine Translation. In Proceedings of EMNLP, pages 725?734, Honolulu, Hawaii.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin Knight. 2006. SPMT: Statistical Machine Translation
with Syntactified Target Language Phrases. In Proceedings of EMNLP, pages 44?52, Sydney, Australia.
Yuval Marton and Philip Resnik. 2008. Soft Syntactic Constraints for Hierarchical Phrased-Based Translation. In
Proceedings of ACL-HLT, pages 1003?1011, Columbus, Ohio.
Haitao Mi and Liang Huang. 2008. Forest-based Translation Rule Extraction. In Proceedings of EMNLP, pages
206?214, Honolulu, Hawaii, USA.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-Based Translation. In Proceedings of ACL-HLT, pages
192?199, Columbus, Ohio.
Kishore Papineni, Salim Roukos, Todd Ward, and Weijing Zhu. 2002. Bleu: a Method for Automatic Evaluation
of Machine Translation. In Proceedings of ACL, pages 311?318, Philadelphia, PA, USA.
Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of HLT-NAACL,
pages 404?411, Rochester, New York, USA.
Juan Pino, Aurelien Waite, Tong Xiao, Adri`a de Gispert, Federico Flego, and William Byrne. 2013. The University
of Cambridge Russian-English system at WMT13. In Proceedings of WMT, pages 200?205, Sofia, Bulgaria.
David Vilar, Daniel Stein, Stephan Peitz, and Hermann Ney. 2010. If i only had a parser: poor man?s syntax for
hierarchical machine translation. In Proceedings of IWSLT, pages 345?352.
Wei Wang, Jonathan May, Kevin Knight, and Daniel Marcu. 2010. Re-structuring, Re-labeling, and Re-aligning
for Syntax-Based Machine Translation. Computational Linguistics, 36(2):247?277.
Tong Xiao, Jingbo Zhu, Hao Zhang, and Qiang Li. 2012. NiuTrans: An Open Source Toolkit for Phrase-based
and Syntax-based Machine Translation. In Proceedings of ACL: System Demonstrations, pages 19?24, Jeju
Island, Korea.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel dependency-to-string model for statistical machine translation.
In Proceedings of EMNLP, pages 216?226, Edinburgh, Scotland.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew Lim Tan, and Sheng Li. 2008. A Tree Sequence
Alignment-based Tree-to-Tree Translation Model. In Proceedings of ACL-HLT, pages 559?567, Columbus,
Ohio, USA.
Bing Zhao and Yaser Al-Onaizan. 2008. Generalizing Local and Non-Local Word-Reordering Patterns for Syntax-
Based Machine Translation. In Proceedings of EMNLP, pages 572?581, Honolulu, Hawaii.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax Augmented Machine Translation via Chart Parsing. In
Proceedings of WMT, pages 138?141, New York City.
2074
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 739?748,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Boosting-based System Combination for Machine Translation 
 
Tong Xiao, Jingbo Zhu, Muhua Zhu, Huizhen Wang 
 
Natural Language Processing Lab.  
Northeastern University, China 
{xiaotong,zhujingbo,wanghuizhen}@mail.neu.edu.cn 
zhumuhua@gmail.com 
 
 
Abstract 
In this paper, we present a simple and effective 
method to address the issue of how to generate 
diversified translation systems from a single 
Statistical Machine Translation (SMT) engine 
for system combination. Our method is based 
on the framework of boosting. First, a se-
quence of weak translation systems is gener-
ated from a baseline system in an iterative 
manner. Then, a strong translation system is 
built from the ensemble of these weak transla-
tion systems. To adapt boosting to SMT sys-
tem combination, several key components of 
the original boosting algorithms are redes-
igned in this work. We evaluate our method on 
Chinese-to-English Machine Translation (MT) 
tasks in three baseline systems, including a 
phrase-based system, a hierarchical phrase-
based system and a syntax-based system. The 
experimental results on three NIST evaluation 
test sets show that our method leads to signifi-
cant improvements in translation accuracy 
over the baseline systems. 
1 Introduction 
Recent research on Statistical Machine Transla-
tion (SMT) has achieved substantial progress. 
Many SMT frameworks have been developed, 
including phrase-based SMT (Koehn et al, 2003), 
hierarchical phrase-based SMT (Chiang, 2005), 
syntax-based SMT (Eisner, 2003; Ding and 
Palmer, 2005; Liu et al, 2006; Galley et al, 2006; 
Cowan et al, 2006), etc. With the emergence of 
various structurally different SMT systems, more 
and more studies are focused on combining mul-
tiple SMT systems for achieving higher transla-
tion accuracy rather than using a single transla-
tion system. 
The basic idea of system combination is to ex-
tract or generate a translation by voting from an 
ensemble of translation outputs. Depending on 
how the translation is combined and what voting 
strategy is adopted, several methods can be used 
for system combination, e.g. sentence-level com-
bination (Hildebrand and Vogel, 2008) simply 
selects one from original translations, while 
some more sophisticated methods, such as word-
level and phrase-level combination (Matusov et 
al., 2006; Rosti et al, 2007), can generate new 
translations differing from any of the original 
translations. 
One of the key factors in SMT system combi-
nation is the diversity in the ensemble of transla-
tion outputs (Macherey and Och, 2007). To ob-
tain diversified translation outputs, most of the 
current system combination methods require 
multiple translation engines based on different 
models. However, this requirement cannot be 
met in many cases, since we do not always have 
the access to multiple SMT engines due to the 
high cost of developing and tuning SMT systems. 
To reduce the burden of system development, it 
might be a nice way to combine a set of transla-
tion systems built from a single translation en-
gine. A key issue here is how to generate an en-
semble of diversified translation systems from a 
single translation engine in a principled way. 
Addressing this issue, we propose a boosting-
based system combination method to learn a 
combined translation system from a single SMT 
engine. In this method, a sequence of weak trans-
lation systems is generated from a baseline sys-
tem in an iterative manner. In each iteration, a 
new weak translation system is learned, focusing 
more on the sentences that are relatively poorly 
translated by the previous weak translation sys-
tem. Finally, a strong translation system is built 
from the ensemble of the weak translation sys-
tems. 
Our experiments are conducted on Chinese-to-
English translation in three state-of-the-art SMT 
systems, including a phrase-based system, a hier-
archical phrase-based system and a syntax-based 
739
Input:   a model u, a sequence of (training) samples {(f1, r1), ..., (fm, rm)} where fi is the 
i-th source sentence, and ri is the set of reference translations for fi. 
Output: a new translation system 
Initialize: D1(i) = 1 / m for all i = 1, ..., m 
For t = 1, ..., T 
1. Train a translation system u(?*t) on {(fi, ri)} using distribution Dt 
2. Calculate the error rate t? of u(?*t) on {(fi, ri)} 
3. Set 
1 1ln( )
2
t
t
t
?? ?
+=                                                         (3)
4. Update weights 
1
( )( )
t il
t
t
t
D i eD i
Z
? ?
+ =                                                    (4)
            where li is the loss on the i-th training sample, and Zt is the normalization factor. 
Output the final system:  
v(u(?*1), ..., u (?*T)) 
Figure 1: Boosting-based System Combination 
system. All the systems are evaluated on three 
NIST MT evaluation test sets. Experimental re-
sults show that our method leads to significant 
improvements in translation accuracy over the 
baseline systems. 
2 Background 
Given a source string f, the goal of SMT is to 
find a target string e* by the following equation. 
* arg max(Pr( | ))
e
e e f=                (1) 
where Pr( | )e f is the probability that e is the 
translation of the given source string f. To model 
the posterior probability Pr( | )e f , most of the 
state-of-the-art SMT systems utilize the log-
linear model proposed by Och and Ney (2002), 
as follows, 
1
' 1
exp( ( , ))
Pr( | )
exp( ( , '))
M
m m
m
M
m m
e m
h f e
e f
h f e
?
?
=
=
?= ?
?
? ?      (2) 
where {hm( f, e ) | m = 1, ..., M} is a set of fea-
tures, and ?m is the feature weight corresponding 
to the m-th feature. hm( f, e ) can be regarded as a 
function that maps every pair of source string f 
and target string e into a non-negative value, and 
?m can be viewed as the contribution of hm( f, e ) 
to the overall score Pr( | )e f . 
In this paper, u denotes a log-linear model that 
has M fixed features {h1( f ,e ), ..., hM( f ,e )}, ? = 
{?1, ..., ?M} denotes the M parameters of u, and 
u(?) denotes a SMT system based on u with pa-
rameters ?. Generally, ? is trained on a training 
data set1 to obtain an optimized weight vector ?* 
and consequently an optimized system u(?*). 
3 Boosting-based System Combination 
for Single Translation Engine  
Suppose that there are T available SMT systems 
{u1(?*1), ..., uT(?*T)}, the task of system combina-
tion is to build a new translation system 
v(u1(?*1), ..., uT(?*T)) from {u1(?*1), ..., uT(?*T)}. 
Here v(u1(?*1), ..., uT(?*T)) denotes the combina-
tion system which combines translations from the 
ensemble of the output of each ui(?*i). We call 
ui(?*i) a member system of v(u1(?*1), ..., uT(?*T)). 
As discussed in Section 1, the diversity among 
the outputs of member systems is an important 
factor to the success of system combination. To 
obtain diversified member systems, traditional 
methods concentrate more on using structurally 
different member systems, that is u1? u2 ?...? 
uT. However, this constraint condition cannot be 
satisfied when multiple translation engines are 
not available.  
In this paper, we argue that the diversified 
member systems can also be generated from a 
single engine u(?*) by adjusting the weight vector 
?* in a principled way. In this work, we assume 
that u1 = u2 =...= uT  = u. Our goal is to find a se-
ries of ?*i and build a combined system from 
{u(?*i)}. To achieve this goal, we propose a 
                                                 
1 The data set used for weight training is generally called 
development set or tuning set in the SMT field. In this paper, 
we use the term training set to emphasize the training of 
log-linear model. 
740
boosting-based system combination method (Fig-
ure 1). 
Like other boosting algorithms, such as 
AdaBoost (Freund and Schapire, 1997; Schapire, 
2001), the basic idea of this method is to use 
weak systems (member systems) to form a strong 
system (combined system) by repeatedly calling 
weak system trainer on different distributions 
over the training samples. However, since most 
of the boosting algorithms are designed for the 
classification problem that is very different from 
the translation problem in natural language proc-
essing, several key components have to be redes-
igned when boosting is adapted to SMT system 
combination. 
3.1 Training 
In this work, Minimum Error Rate Training 
(MERT) proposed by Och (2003) is used to es-
timate feature weights ? over a series of training 
samples. As in other state-of-the-art SMT sys-
tems, BLEU is selected as the accuracy measure 
to define the error function used in MERT. Since 
the weights of training samples are not taken into 
account in BLEU2, we modify the original defi-
nition of BLEU to make it sensitive to the distri-
bution Dt(i) over the training samples. The modi-
fied version of BLEU is called weighted BLEU 
(WBLEU) in this paper. 
Let E = e1 ... em be the translations produced 
by the system, R = r1 ... rm be the reference trans-
lations where ri = {ri1, ..., riN}, and Dt(i) be the 
weight of the i-th training sample (fi, ri). The 
weighted BLEU metric has the following form: 
{ }
( )
11 1
11
1/ 4
m
4 1 1
m
1
1
  WBLEU( , )
( ) min | ( ) |
exp 1 max 1,
( ) | ( ) |
( ) ( ) ( )
     (5)
( ) ( )
m
ijti j N
m
iti
N
i ijt n ni j
in t ni
E R
D i g r
D i g e
D i g e g r
D i g e
= ? ?
=
= =
= =
? ?? ?? ?? ?= ? ?? ?? ?? ?? ?? ?? ?
? ?? ?? ?? ?? ?
?
?
?? ?
I U
 
where ( )ng s  is the multi-set of all n-grams in a 
string s. In this definition, n-grams in ei and {rij} 
are weighted by Dt(i). If the i-th training sample 
has a larger weight, the corresponding n-grams 
will have more contributions to the overall score 
WBLEU( , )E R . As a result, the i-th training 
sample gains more importance in MERT. Obvi-
                                                 
2 In this paper, we use the NIST definition of BLEU where 
the effective reference length is the length of the shortest 
reference translation. 
ously the original BLEU is just a special case of 
WBLEU when all the training samples are 
equally weighted. 
As the weighted BLEU is used to measure the 
translation accuracy on the training set, the error 
rate is defined to be: 
1 WBLEU( , )t E R? = ?               (6) 
3.2 Re-weighting 
Another key point is the maintaining of the dis-
tribution Dt(i) over the training set. Initially all 
the weights of training samples are set equally. 
On each round, we increase the weights of the 
samples that are relatively poorly translated by 
the current weak system so that the MERT-based 
trainer can focus on the hard samples in next 
round. The update rule is given in Equation 4 
with two parameters t?  and li in it. 
t?  can be regarded as a measure of the im-
portance that the t-th weak system gains in boost-
ing. The definition of t?  guarantees that t?  al-
ways has a positive value3. A main effect of t?  
is to scale the weight updating (e.g. a larger t?  
means a greater update). 
li is the loss on the i-th sample. For each i, let 
{ei1, ..., ein} be the n-best translation candidates 
produced by the system. The loss function is de-
fined to be: 
*
1
1BLEU( , ) BLEU( , )ki i i ij i
j
l e e
k =
= ? ?r r  (7) 
where BLEU(eij, ri) is the smoothed sentence-level 
BLEU score (Liang et al, 2006) of the transla-
tion e with respect to the reference translations ri, 
and ei* is the oracle translation which is selected 
from {ei1, ..., ein} in terms of BLEU(eij, ri). li can 
be viewed as a measure of the average cost that 
we guess the top-k translation candidates instead 
of the oracle translation. The value of li counts 
for the magnitude of weight update, that is, a lar-
ger li means a larger weight update on Dt(i). The 
definition of the loss function here is similar to 
the one used in (Chiang et al, 2008) where only 
the top-1 translation candidate (i.e. k = 1) is 
taken into account. 
3.3 System Combination Scheme 
In the last step of our method, a strong transla-
tion system v(u(?*1), ..., u(?*T)) is built from the 
                                                 
3 Note that the definition of t?  here is different from that in 
the original AdaBoost algorithm (Freund and Schapire, 
1997; Schapire, 2001) where t?  is a negative number when 
0.5t? > . 
741
ensemble of member systems {u(?*1), ..., u(?*T)}. 
In this work, a sentence-level combination 
method is used to select the best translation from 
the pool of the n-best outputs of all the member 
systems.  
Let H(u(?*t)) (or Ht for short) be the set of the 
n-best translation candidates produced by the t-th 
member system u(?*t), and H(v) be the union set 
of all Ht (i.e. ( ) tH v H=U ). The final translation 
is generated from H(v) based on the following 
scoring function: 
*
1
( )
arg max ( ) ( , ( ))T t tt
e H v
e e e H v? ? ?=?= ? +?    (8) 
where ( )t e?  is the log-scaled model score of e in 
the t-th member system, and t?  is the corre-
sponding feature weight. It should be noted that 
ie H?  may not exist in any 'i iH ? . In this case, 
we can still calculate the model score of e in any 
other member systems, since all the member sys-
tems are based on the same model and share the 
same feature space. ( , ( ))e H v?  is a consensus-
based scoring function which has been success-
fully adopted in SMT system combination (Duan 
et al, 2009; Hildebrand and Vogel, 2008; Li et 
al., 2009). The computation of ( , ( ))e H v?  is 
based on a linear combination of a set of n-gram 
consensuses-based features.  
( , ( )) ( , ( ))n n
n
e H v h e H v? ? + += ? +?  
( , ( ))n n
n
h e H v? ? ???            (9) 
For each order of n-gram, ( , ( ))nh e H v
+ and 
( , ( ))nh e H v
?  are defined to measure the n-gram 
agreement and disagreement between e and other 
translation candidates in H(v), respectively. n? +  
and n? ? are the feature weights corresponding to 
( , ( ))nh e H v
+ and ( , ( ))nh e H v
? . As ( , ( ))nh e H v
+ and 
( , ( ))nh e H v
?  used in our work are exactly the 
same as the features used in (Duan et al, 2009) 
and similar to the features used in (Hildebrand 
and Vogel, 2008; Li et al, 2009), we do not pre-
sent the detailed description of them in this paper. 
If p orders of n-gram are used in computing 
( , ( ))e H v? , the total number of features in the 
system combination will be 2T p+ ? (T model-
score-based features defined in Equation 8 and 
2 p?  consensus-based features defined in Equa-
tion 9). Since all these features are combined 
linearly, we use MERT to optimize them for the 
combination model. 
4 Optimization 
If implemented naively, the translation speed of 
the final translation system will be very slow. 
For a given input sentence, each member system 
has to encode it individually, and the translation 
speed is inversely proportional to the number of 
member systems generated by our method. For-
tunately, with the thought of computation, there 
are a number of optimizations that can make the 
system much more efficient in practice. 
A simple solution is to run member systems in 
parallel when translating a new sentence. Since 
all the member systems share the same data re-
sources, such as language model and translation 
table, we only need to keep one copy of the re-
quired resources in memory. The translation 
speed just depends on the computing power of 
parallel computation environment, such as the 
number of CPUs. 
Furthermore, we can use joint decoding tech-
niques to save the computation of the equivalent 
translation hypotheses among member systems. 
In joint decoding of member systems, the search 
space is structured as a translation hypergraph 
where the member systems can share their trans-
lation hypotheses. If more than one member sys-
tems share the same translation hypothesis, we 
just need to compute the corresponding feature 
values only once, instead of repeating the com-
putation in individual decoders. In our experi-
ments, we find that over 60% translation hy-
potheses can be shared among member systems 
when the number of member systems is over 4. 
This result indicates that promising speed im-
provement can be achieved by using the joint 
decoding and hypothesis sharing techniques. 
Another method to speed up the system is to 
accelerate n-gram language model with n-gram 
caching techniques. In this method, a n-gram 
cache is used to store the most frequently and 
recently accessed n-grams. When a new n-gram 
is accessed during decoding, the cache is 
checked first. If the required n-gram hits the 
cache, the corresponding n-gram probability is 
returned by the cached copy rather than re-
fetching the original data in language model. As 
the translation speed of SMT system depends 
heavily on the computation of n-gram language 
model, the acceleration of n-gram language 
model generally leads to substantial speed-up of 
SMT system. In our implementation, the n-gram 
caching in general brings us over 30% speed im-
provement of the system. 
742
5 Experiments  
Our experiments are conducted on Chinese-to-
English translation in three SMT systems. 
5.1 Baseline Systems 
The first SMT system is a phrase-based system 
with two reordering models including the maxi-
mum entropy-based lexicalized reordering model 
proposed by Xiong et al (2006) and the hierar-
chical phrase reordering model proposed by Gal-
ley and Manning (2008). In this system all 
phrase pairs are limited to have source length of 
at most 3, and the reordering limit is set to 8 by 
default4. 
The second SMT system is an in-house reim-
plementation of the Hiero system which is based 
on the hierarchical phrase-based model proposed 
by Chiang (2005).  
The third SMT system is a syntax-based sys-
tem based on the string-to-tree model (Galley et 
al., 2006; Marcu et al, 2006), where both the 
minimal GHKM and SPMT rules are extracted 
from the bilingual text, and the composed rules 
are generated by combining two or three minimal 
GHKM and SPMT rules. Synchronous binariza-
tion (Zhang et al, 2006; Xiao et al, 2009) is per-
formed on each translation rule for the CKY-
style decoding. 
In this work, baseline system refers to the sys-
tem produced by the boosting-based system 
combination when the number of iterations (i.e. 
T ) is set to 1. To obtain satisfactory baseline per-
formance, we train each SMT system for 5 times 
using MERT with different initial values of fea-
ture weights to generate a group of baseline can-
didates, and then select the best-performing one 
from this group as the final baseline system (i.e. 
the starting point in the boosting process) for the 
following experiments. 
5.2 Experimental Setup 
Our bilingual data consists of 140K sentence 
pairs in the FBIS data set5. GIZA++ is employed 
to perform the bi-directional word alignment be-
tween the source and target sentences, and the 
final word alignment is generated using the inter-
sect-diag-grow method. All the word-aligned 
bilingual sentence pairs are used to extract 
phrases and rules for the baseline systems. A 5-
gram language model is trained on the target-side 
                                                 
4 Our in-house experimental results show that this system 
performs slightly better than Moses on Chinese-to-English 
translation tasks. 
5 LDC catalog number: LDC2003E14 
of the bilingual data and the Xinhua portion of 
English Gigaword corpus. Berkeley Parser is 
used to generate the English parse trees for the 
rule extraction of the syntax-based system. The 
data set used for weight training in boosting-
based system combination comes from NIST 
MT03 evaluation set. To speed up MERT, all the 
sentences with more than 20 Chinese words are 
removed. The test sets are the NIST evaluation 
sets of MT04, MT05 and MT06. The translation 
quality is evaluated in terms of case-insensitive 
NIST version BLEU metric. Statistical signifi-
cant test is conducted using the bootstrap re-
sampling method proposed by Koehn (2004). 
Beam search and cube pruning (Huang and 
Chiang, 2007) are used to prune the search space 
in all the three baseline systems. By default, both 
of the beam size and the size of n-best list are set 
to 20. 
In the settings of boosting-based system com-
bination, the maximum number of iterations is 
set to 30, and k (in Equation 7) is set to 5. The n-
gram consensuses-based features (in Equation 9) 
used in system combination ranges from unigram 
to 4-gram. 
5.3 Evaluation of Translations 
First we investigate the effectiveness of the 
boosting-based system combination on the three 
systems.  
Figures 2-5 show the BLEU curves on the de-
velopment and test sets, where the X-axis is the 
iteration number, and the Y-axis is the BLEU 
score of the system generated by the boosting-
based system combination. The points at itera-
tion 1 stand for the performance of the baseline 
systems. We see, first of all, that all the three 
systems are improved during iterations on the 
development set. This trend also holds on the test 
sets. After 5, 7 and 8 iterations, relatively stable 
improvements are achieved by the phrase-based 
system, the Hiero system and the syntax-based 
system, respectively. The BLEU scores tend to 
converge to the stable values after 20 iterations 
for all the systems. Figures 2-5 also show that the 
boosting-based system combination seems to be 
more helpful to the phrase-based system than to 
the Hiero system and the syntax-based system. 
For the phrase-based system, it yields over 0.6 
BLEU point gains just after the 3rd iteration on 
all the data sets.  
Table 1 summarizes the evaluation results, 
where the BLEU scores at iteration 5, 10, 15, 20 
and 30 are reported for the comparison. We see 
that the boosting-based system method stably ac- 
743
 33
 34
 35
 36
 37
 38
 0  5  10  15  20  25  30
B
LE
U
4[
%
]
iteration number
BLEU on MT03 (dev.)
phrase-based
hiero
syntax-based
Figure 2: BLEU scores on the development set 
 33
 34
 35
 36
 37
 38
 0  5  10  15  20  25  30
B
LE
U
4[
%
]
iteration number
BLEU on MT04 (test)
phrase-based
hiero
syntax-based
Figure 3: BLEU scores on the test  set of MT04 
 32
 33
 34
 35
 36
 37
 0  5  10  15  20  25  30
B
LE
U
4[
%
]
iteration number
BLEU on MT05 (test)
phrase-based
hiero
syntax-based
Figure 4: BLEU scores on the test set of MT05 
 30
 31
 32
 33
 34
 35
 0  5  10  15  20  25  30
B
LE
U
4[
%
]
iteration number
BLEU on MT06 (test)
phrase-based
hiero
syntax-based
Figure 5: BLEU scores on the test set of MT06 
 
Phrase-based Hiero Syntax-based 
Dev. MT04 MT05 MT06 Dev. MT04 MT05 MT06 Dev. MT04 MT05 MT06 
Baseline 33.21 33.68 32.68 30.59 33.42 34.30 33.24 30.62 35.84 35.71 35.11 32.43 
Baseline+600best 33.32 33.93 32.84 30.76 33.48 34.46 33.39 30.75 35.95 35.88 35.23 32.58 
Boosting-5Iterations 33.95* 34.32* 33.33* 31.33* 33.73 34.48 33.44 30.83 36.03 35.92 35.27 33.09 
Boosting-10Iterations 34.14* 34.68* 33.42* 31.35* 33.75 34.65 33.75* 31.02 36.14 36.39* 35.47 33.15*
Boosting-15Iterations 33.99* 34.78* 33.46* 31.45* 34.03* 34.88* 33.98* 31.20* 36.36* 36.46* 35.53* 33.43*
Boosting-20Iterations 34.09* 35.11* 33.56* 31.45* 34.17* 35.00* 34.04* 31.29* 36.44* 36.79* 35.77* 33.36*
Boosting-30Iterations 34.12* 35.16* 33.76* 31.59* 34.05* 34.99* 34.05* 31.30* 36.52* 36.81* 35.71* 33.46*
Table 1: Summary of the results (BLEU4[%]) on the development and test sets. * = significantly better 
than baseline (p < 0.05). 
  
hieves significant BLEU improvements after 15 
iterations, and the highest BLEU scores are gen-
erally yielded after 20 iterations.  
Also as shown in Table 1, over 0.7 BLEU 
point gains are obtained on the phrase-based sys-
tem after 10 iterations. The largest BLEU im-
provement on the phrase-based system is over 1 
BLEU point in most cases. These results reflect 
that our method is relatively more effective for 
the phrase-based system than for the other two 
systems, and thus confirms the fact we observed 
in Figures 2-5. 
We also investigate the impact of n-best list 
size on the performance of baseline systems. For 
the comparison, we show the performance of the 
baseline systems with the n-best list size of 600 
(Baseline+600best in Table 1) which equals to 
the maximum number of translation candidates 
accessed in the final combination system (combi- 
ne 30 member systems, i.e. Boosing-30Iterations). 
744
 15
 20
 25
 30
 35
 40
 0  5  10  15  20  25  30
D
iv
er
si
ty
 (T
E
R
[%
])
iteration number
Diversity on MT03 (dev.)
phrase-based
hiero
syntax-based
Figure 6: Diversity on the development set 
 10
 15
 20
 25
 30
 35
 0  5  10  15  20  25  30
D
iv
er
si
ty
 (T
E
R
[%
])
iteration number
Diversity on MT04 (test)
phrase-based
hiero
syntax-based
Figure 7: Diversity on the test set of MT04 
 15
 20
 25
 30
 35
 0  5  10  15  20  25  30
D
iv
er
si
ty
 (T
E
R
[%
])
iteration number
Diversity on MT05 (test)
phrase-based
hiero
syntax-based
Figure 8: Diversity on the test set of MT05 
 15
 20
 25
 30
 35
 40
 0  5  10  15  20  25  30
D
iv
er
si
ty
 (T
E
R
[%
])
iteration number
Diversity on MT06 (test)
phrase-based
hiero
syntax-based
Figure 9: Diversity on the test set of MT06 
 
As shown in Table 1, Baseline+600best obtains 
stable improvements over Baseline. It indicates 
that the access to larger n-best lists is helpful to 
improve the performance of baseline systems. 
However, the improvements achieved by Base-
line+600best are modest compared to the im-
provements achieved by Boosting-30Iterations. 
These results indicate that the SMT systems can 
benefit more from the diversified outputs of 
member systems rather than from larger n-best 
lists produced by a single system. 
5.4 Diversity among Member Systems 
We also study the change of diversity among the 
outputs of member systems during iterations. 
The diversity is measured in terms of the Trans-
lation Error Rate (TER) metric proposed in 
(Snover et al, 2006). A higher TER score means 
that more edit operations are performed if we 
transform one translation output into another 
translation output, and thus reflects a larger di-
versity between the two outputs. In this work, the 
TER score for a given group of member systems 
is calculated by averaging the TER scores be-
tween the outputs of each pair of member sys-
tems in this group. 
Figures 6-9 show the curves of diversity on 
the development and test sets, where the X-axis 
is the iteration number, and the Y-axis is the di-
versity. The points at iteration 1 stand for the 
diversities of baseline systems. In this work, the 
baseline?s diversity is the TER score of the group 
of baseline candidates that are generated in ad-
vance (Section 5.1). 
We see that the diversities of all the systems 
increase during iterations in most cases, though a 
few drops occur at a few points. It indicates that 
our method is very effective to generate diversi-
fied member systems. In addition, the diversities 
of baseline systems (iteration 1) are much lower 
745
than those of the systems generated by boosting 
(iterations 2-30). Together with the results shown 
in Figures 2-5, it confirms our motivation that 
the diversified translation outputs can lead to 
performance improvements over the baseline 
systems. 
Also as shown in Figures 6-9, the diversity of 
the Hiero system is much lower than that of the 
phrase-based and syntax-based systems at each 
individual setting of iteration number. This inter-
esting finding supports the observation that the 
performance of the Hiero system is relatively 
more stable than the other two systems as shown 
in Figures 2-5. The relative lack of diversity in 
the Hiero system might be due to the spurious 
ambiguity in Hiero derivations which generally 
results in very few different translations in trans-
lation outputs (Chiang, 2007). 
5.5 Evaluation of Oracle Translations 
In this set of experiments, we evaluate the oracle 
performance on the n-best lists of the baseline 
systems and the combined systems generated by 
boosting-based system combination. Our primary 
goal here is to study the impact of our method on 
the upper-bound performance.  
Table 2 shows the results, where Base-
line+600best stands for the top-600 translation 
candidates generated by the baseline systems, 
and Boosting-30iterations stands for the ensem-
ble of 30 member systems? top-20 translation 
candidates. As expected, the oracle performance 
of Boosting-30Iterations is significantly higher 
than that of Baseline+600best. This result indi-
cates that our method can provide much ?better? 
translation candidates for system combination 
than enlarging the size of n-best list naively. It 
also gives us a rational explanation for the sig-
nificant improvements achieved by our method 
as shown in Section 5.3. 
 
Data 
Set 
Method Phrase-
based 
Hiero Syntax-
based 
Baseline+600best 46.36 46.51 46.92 Dev. 
Boosting-30Iterations 47.78* 47.44* 48.70* 
Baseline+600best 43.94 44.52 46.88 MT04 
Boosting-30Iterations 45.97* 45.47* 49.40* 
Baseline+600best 42.32 42.47 45.21 MT05 
Boosting-30Iterations 44.82* 43.44* 47.02* 
Baseline+600best 39.47 39.39 40.52 MT06 
Boosting-30Iterations 41.51* 40.10* 41.88* 
Table 2: Oracle performance of various systems. 
* = significantly better than baseline (p < 0.05). 
6 Related Work 
Boosting is a machine learning (ML) method that 
has been well studied in the ML community 
(Freund, 1995; Freund and Schapire, 1997; 
Collins et al, 2002; Rudin et al, 2007), and has 
been successfully adopted in natural language 
processing (NLP) applications, such as document 
classification (Schapire and Singer, 2000) and 
named entity classification (Collins and Singer, 
1999). However, most of the previous work did 
not study the issue of how to improve a single 
SMT engine using boosting algorithms. To our 
knowledge, the only work addressing this issue is 
(Lagarda and Casacuberta, 2008) in which the 
boosting algorithm was adopted in phrase-based 
SMT. However, Lagarda and Casacuberta 
(2008)?s method calculated errors over the 
phrases that were chosen by phrase-based sys-
tems, and could not be applied to many other 
SMT systems, such as hierarchical phrase-based 
systems and syntax-based systems. Differing 
from Lagarda and Casacuberta?s work, we are 
concerned more with proposing a general 
framework which can work with most of the cur-
rent SMT models and empirically demonstrating 
its effectiveness on various SMT systems. 
There are also some other studies on building 
diverse translation systems from a single transla-
tion engine for system combination. The first 
attempt is (Macherey and Och, 2007). They em-
pirically showed that diverse translation systems 
could be generated by changing parameters at 
early-stages of the training procedure. Following 
Macherey and Och (2007)?s work, Duan et al 
(2009) proposed a feature subspace method to 
build a group of translation systems from various 
different sub-models of an existing SMT system. 
However, Duan et al (2009)?s method relied on 
the heuristics used in feature sub-space selection. 
For example, they used the remove-one-feature 
strategy and varied the order of n-gram language 
model to obtain a satisfactory group of diverse 
systems. Compared to Duan et al (2009)?s 
method, a main advantage of our method is that 
it can be applied to most of the SMT systems 
without designing any heuristics to adapt it to the 
specified systems. 
7 Discussion and Future Work 
Actually the method presented in this paper is 
doing something rather similar to Minimum 
Bayes Risk (MBR) methods. A main difference 
lies in that the consensus-based combination 
method here does not model the posterior prob-
ability of each hypothesis (i.e. all the hypotheses 
are assigned an equal posterior probability when 
we calculate the consensus-based features). 
746
Greater improvements are expected if MBR 
methods are used and consensus-based combina-
tion techniques smooth over noise in the MERT 
pipeline. 
In this work, we use a sentence-level system 
combination method to generate final transla-
tions. It is worth studying other more sophisti-
cated alternatives, such as word-level and 
phrase-level system combination, to further im-
prove the system performance. 
Another issue is how to determine an appro-
priate number of iterations for boosting-based 
system combination. It is especially important 
when our method is applied in the real-world 
applications. Our empirical study shows that the 
stable and satisfactory improvements can be 
achieved after 6-8 iterations, while the largest 
improvements can be achieved after 20 iterations. 
In our future work, we will study in-depth prin-
cipled ways to determine the appropriate number 
of iterations for boosting-based system combina-
tion. 
8 Conclusions 
We have proposed a boosting-based system com-
bination method to address the issue of building 
a strong translation system from a group of weak 
translation systems generated from a single SMT 
engine. We apply our method to three state-of-
the-art SMT systems, and conduct experiments 
on three NIST Chinese-to-English MT evalua-
tions test sets. The experimental results show that 
our method is very effective to improve the 
translation accuracy of the SMT systems. 
Acknowledgements 
This work was supported in part by the National 
Science Foundation of China (60873091) and the 
Fundamental Research Funds for the Central 
Universities (N090604008). The authors would 
like to thank the anonymous reviewers for their 
pertinent comments, Tongran Liu, Chunliang 
Zhang and Shujie Yao for their valuable sugges-
tions for improving this paper, and Tianning Li 
and Rushan Chen for developing parts of the 
baseline systems. 
References  
David Chiang. 2005. A hierarchical phrase-based 
model for statistical machine translation. In Proc. 
of ACL 2005, Ann Arbor, Michigan, pages 263-
270. 
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201-228. 
David Chiang, Yuval Marton and Philip Resnik. 2008. 
Online Large-Margin Training of Syntactic and 
Structural Translation Features. In Proc. of 
EMNLP 2008, Honolulu, pages 224-233. 
Michael Collins and Yoram Singer. 1999. Unsuper-
vised Models for Named Entity Classification. In 
Proc. of EMNLP/VLC 1999, pages 100-110. 
Michael Collins, Robert Schapire and Yoram Singer. 
2002. Logistic Regression, AdaBoost and Bregman 
Distances. Machine Learning, 48(3): 253-285. 
Brooke Cowan, Ivona Ku?erov? and Michael Collins. 
2006. A discriminative model for tree-to-tree trans-
lation. In Proc. of EMNLP 2006, pages 232-241. 
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency 
insertion grammars. In Proc. of ACL 2005, Ann 
Arbor, Michigan, pages 541-548. 
Nan Duan, Mu Li, Tong Xiao and Ming Zhou. 2009. 
The Feature Subspace Method for SMT System 
Combination. In Proc. of EMNLP 2009, pages 
1096-1104. 
Jason Eisner. 2003. Learning non-isomorphic tree 
mappings for machine translation. In Proc. of ACL 
2003, pages 205-208. 
Yoav Freund. 1995. Boosting a weak learning algo-
rithm by majority. Information and Computation, 
121(2): 256-285. 
Yoav Freund and Robert Schapire. 1997. A decision-
theoretic generalization of on-line learning and an 
application to boosting. Journal of Computer and 
System Sciences, 55(1):119-139. 
Michel Galley, Jonathan Graehl, Kevin Knight, 
Daniel Marcu, Steve DeNeefe, Wei Wang and 
Ignacio Thayer. 2006. Scalable inferences and 
training of context-rich syntax translation models. 
In Proc. of ACL 2006, Sydney, Australia, pages 
961-968. 
Michel Galley and Christopher D. Manning. 2008. A 
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proc. of EMNLP 2008, Hawaii, 
pages 848-856. 
Almut Silja Hildebrand and Stephan Vogel. 2008. 
Combination of machine translation systems via 
hypothesis selection from combined n-best lists. In 
Proc. of the 8th AMTA conference, pages 254-261. 
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language 
models. In Proc. of ACL 2007, Prague, Czech Re-
public, pages 144-151. 
747
Philipp Koehn, Franz Och and Daniel Marcu. 2003. 
Statistical Phrase-Based Translation. In Proc. of 
HLT-NAACL 2003, Edmonton, USA, pages 48-54. 
Philipp Koehn. 2004. Statistical Significance Tests for 
Machine Translation Evaluation. In Proc. of 
EMNLP 2004, Barcelona, Spain, pages 388-395. 
Antonio Lagarda and Francisco Casacuberta. 2008. 
Applying Boosting to Statistical Machine Transla-
tion. In Proc. of the 12th EAMT conference, pages 
88-96. 
Mu Li, Nan Duan, Dongdong Zhang, Chi-Ho Li and 
Ming Zhou. 2009. Collaborative Decoding: Partial 
Hypothesis Re-Ranking Using Translation Consen-
sus between Decoders. In Proc. of ACL-IJCNLP 
2009, Singapore, pages 585-592. 
Percy Liang, Alexandre Bouchard-C?t?, Dan Klein 
and Ben Taskar. 2006. An end-to-end discrimina-
tive approach to machine translation. In Proc. of 
COLING/ACL 2006, pages 104-111. 
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine 
Translation. In Proc. of ACL 2006, pages 609-616. 
Wolfgang Macherey and Franz Och. 2007. An Em-
pirical Study on Computing Consensus Transla-
tions from Multiple Machine Translation Systems. 
In Proc. of EMNLP 2007, pages 986-995. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language 
phrases. In Proc. of EMNLP 2006, Sydney, Aus-
tralia, pages 44-52. 
Evgeny Matusov, Nicola Ueffing and Hermann Ney. 
2006. Computing consensus translation from mul-
tiple machine translation systems using enhanced 
hypotheses alignment. In Proc. of EACL 2006, 
pages 33-40. 
Franz Och and Hermann Ney. 2002. Discriminative 
Training and Maximum Entropy Models for Statis-
tical Machine Translation. In Proc. of ACL 2002, 
Philadelphia, pages 295-302. 
Franz Och. 2003. Minimum Error Rate Training in 
Statistical Machine Translation. In Proc. of ACL 
2003, Japan, pages 160-167. 
Antti-Veikko Rosti, Spyros Matsoukas and Richard 
Schwartz. 2007. Improved Word-Level System 
Combination for Machine Translation. In Proc. of 
ACL 2007, pages 312-319. 
Cynthia Rudin, Robert Schapire and Ingrid Daube-
chies. 2007. Analysis of boosting algorithms using 
the smooth margin function.  The Annals of Statis-
tics, 35(6): 2723-2768. 
Robert Schapire and Yoram Singer. 2000. BoosTexter: 
A boosting-based system for text categorization. 
Machine Learning, 39(2/3):135-168. 
Robert Schapire. The boosting approach to machine 
learning: an overview. 2001. In Proc. of MSRI 
Workshop on Nonlinear Estimation and Classifica-
tion, Berkeley, CA, USA, pages 1-23. 
Matthew Snover, Bonnie Dorr, Richard Schwartz, 
Linnea Micciulla and John Makhoul. 2006. A 
Study of Translation Edit Rate with Targeted Hu-
man Annotation. In Proc. of the 7th AMTA confer-
ence, pages 223-231. 
Tong Xiao, Mu Li, Dongdong Zhang, Jingbo Zhu and 
Ming Zhou. 2009. Better Synchronous Binarization 
for Machine Translation. In Proc. of EMNLP 2009, 
Singapore, pages 362-370. 
Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maxi-
mum Entropy Based Phrase Reordering Model for 
Statistical Machine Translation. In Proc. of ACL 
2006, Sydney, pages 521-528. 
Hao Zhang, Liang Huang, Daniel Gildea and Kevin 
Knight. 2006. Synchronous Binarization for Ma-
chine Translation. In Proc. of HLT-NAACL 2006, 
New York, USA, pages 256- 263. 
748
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 418?423,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Improving Decoding Generalization for Tree-to-String Translation 
 
 
Jingbo Zhu 
 
Tong Xiao 
Natural Language Processing Laboratory Natural Language Processing Laboratory 
Northeastern University, Shenyang, China Northeastern University, Shenyang, China 
zhujingbo@mail.neu.edu.cn xiaotong@mail.neu.edu.cn 
 
 
 
 
Abstract 
To address the parse error issue for tree-to-
string translation, this paper proposes a 
similarity-based decoding generation (SDG) 
solution by reconstructing similar source 
parse trees for decoding at the decoding 
time instead of taking multiple source parse 
trees as input for decoding. Experiments on 
Chinese-English translation demonstrated 
that our approach can achieve a significant 
improvement over the standard method, 
and has little impact on decoding speed in 
practice. Our approach is very easy to im-
plement, and can be applied to other para-
digms such as tree-to-tree models.  
1 Introduction 
Among linguistically syntax-based statistical ma-
chine translation (SMT) approaches, the tree-to-
string model (Huang et al 2006; Liu et al 2006) is 
the simplest and fastest, in which parse trees on 
source side are used for grammar extraction and 
decoding. Formally, given a source (e.g., Chinese) 
string c and its auto-parsed tree T1-best, the goal of 
typical tree-to-string SMT is to find a target (e.g., 
English) string e* by the following equation as 
),|Pr(maxarg 1
*
best
e
Tcee ?=                  (1) 
where Pr(e|c,T1-best) is the probability that e is the 
translation of the given source string c and its T1-best. 
A typical tree-to-string decoder aims to search for 
the best derivation among all consistent derivations 
that convert source tree into a target-language 
string. We call this set of consistent derivations the 
tree-to-string search space. Each derivation in the 
search space respects the source parse tree.  
Parsing errors on source parse trees would cause 
negative effects on tree-to-string translation due to 
decoding on incorrect source parse trees. To ad-
dress the parse error issue in tree-to-string transla-
tion, a natural solution is to use n-best parse trees 
instead of 1-best parse tree as input for decoding, 
which can be expressed by 
),|Pr(maxarg* bestn
e
Tcee ?=              (2) 
where <Tn-best> denotes a set of n-best parse trees 
of c produced by a state-of-the-art syntactic parser. 
A simple alternative (Xiao et al 2010) to generate 
<Tn-best> is to utilize multiple parsers, which can 
improve the diversity among source parse trees in 
<Tn-best>. In this solution, the most representative 
work is the forest-based translation method (Mi et 
al. 2008; Mi and Huang 2008; Zhang et al 2009) 
in which a packed forest (forest for short) structure 
is used to effectively represent <Tn-best> for decod-
ing. Forest-based approaches can increase the tree-
to-string search space for decoding, but face a non-
trivial problem of high decoding time complexity 
in practice. 
In this paper, we propose a new solution by re-
constructing new similar source parse trees for de-
coding, referred to as similarity-based decoding 
generation (SDG), which is expressed as 
}),{,|Pr(maxarg
),|Pr(maxarg
1
1
*
simbest
e
best
e
TTce
Tcee
?
?
?
=
       (3) 
where <Tsim> denotes a set of similar parse trees of 
T1-best that are dynamically reconstructed at the de-
418
coding time. Roughly speaking, <Tn-best> is a sub-
set of {T1-best, <Tsim>}. Along this line of thinking, 
Equation (2) can be considered as a special case of 
Equation (3).  
In our SDG solution, given a source parse tree 
T1-best, the key is how to generate its <Tsim> at the 
decoding time. In practice, it is almost intractable 
to directly reconstructing <Tsim> in advance as in-
put for decoding due to too high computation com-
plexity. To address this crucial challenge, this 
paper presents a simple and effective technique 
based on similarity-based matching constraints to 
construct new similar source parse trees for decod-
ing at the decoding time. Our SDG approach can 
explicitly increase the tree-to-string search space 
for decoding without changing any grammar ex-
traction and pruning settings, and has little impact 
on decoding speed in practice.  
2 Tree-to-String Derivation 
We choose the tree-to-string paradigm in our study 
because this is the simplest and fastest among syn-
tax-based models, and has been shown to be one of 
the state-of-the-art syntax-based models. Typically, 
by using the GHKM algorithm (Galley et al 2004), 
translation rules are learned from word-aligned 
bilingual texts whose source side has been parsed 
by using a syntactic parser. Each rule consists of a 
syntax tree in the source language having some 
words (terminals) or variables (nonterminals) at 
leaves, and sequence words or variables in the tar-
get language. With the help of these learned trans-
lation rules, the goal of tree-to-string decoding is to 
search for the best derivation that converts the 
source tree into a target-language string. A deriva-
tion is a sequence of translation steps (i.e., the use 
of translation rules).  
Figure 1 shows an example derivation d that 
performs translation over a Chinese source parse 
tree, and how this process works. In the first step, 
we can apply rule r1 at the root node that matches a 
subtree {IP[1] (NP[2] VP[3])}. The corresponding 
target side {x1 x2} means to preserve the top-level 
word-order in the translation, and results in two 
unfinished subtrees with root labels NP[2] and VP[3], 
respectively. The rule r2 finishes the translation on 
the subtree of NP[2], in which the Chinese word 
???? is translated into an English string ?the 
Chinese side?. The rule r3 is applied to perform 
translation on the subtree of VP[3], and results in an  
 
An example tree-to-string derivation d consisting of five 
translation rules is given as follows: 
r1: IP[1] (x1:NP[2] x2:VP[3]) ? x1 x2 
r2: NP[2] (NN (??)) ? the Chinese side 
r3: VP[3] (ADVP(AD(??)) VP(VV(??) AS(?) 
x1:NP[4])) ? highly appreciated x1 
r4: NP[4] (DP(DT(?) CLP(M(?))) x1:NP[5]) ? this x1 
r5: NP[5] (NN(??)) ? talk 
Translation results: The Chinese side highly appreciated 
this talk. 
 
Figure 1. An example derivation performs translation 
over the Chinese parse tree T.  
 
unfinished subtree of NP[4]. Similarly, rules r4 and 
r5 are sequentially used to finish the translation on 
the remaining. This process is a depth-first search 
over the whole source tree, and visits every node 
only once. 
3 Decoding Generalization 
3.1 Similarity-based Matching Constraints 
In typical tree-to-string decoding, an ordered se-
quence of rules can be reassembled to form a deri-
vation d whose source side matches the given 
source parse tree T. The source side of each rule in 
d should match one of subtrees of T, referred to as 
matching constraint. Before discussing how to ap-
ply our similarity-based matching constraints to 
reconstruct new similar source parse trees for de-
coding at the decoding time, we first define the 
similarity between two tree-to-string rules. 
 
Definition 1 Given two tree-to-string rules t and u, 
we say that t and u are similar such that their 
source sides ts and us have the same root label and 
frontier nodes, written as ut ? , otherwise not.  
419
 
Figure 2: Two similar tree-to-string rules. (a) rule r3 
used by the example derivation d in Figure 1, and (b) a 
similar rule ?3 of r3.  
 
Here we use an example figure to explain our 
similarity-based matching constraint scheme (simi-
larity-based scheme for short). 
 
 
Figure 3: (a) a typical tree-to-string derivation d using 
rule t, and (b) a new derivation d* is generated by the 
similarity-based matching constraint scheme by using 
rule t* instead of rule t, where t* t? . 
 
Given a source-language parse tree T, in typical 
tree-to-string matching constraint scheme shown in 
Figure 3(a), rule t used by the derivation d should 
match a substree ABC of T. In our similarity-based 
scheme, the similar rule t* ( t? ) is used to form a 
new derivation d* that performs translation over 
the same source sentence {w1 ... wn}. In such a case, 
this new derivation d* can yield a new similar 
parse tree T* of T. 
Since an incorrect source parse tree might filter 
out good derivations during tree-to-string decoding, 
our similarity-based scheme is much more likely to 
recover the correct tree for decoding at the decod-
ing time, and does not rule out good (potentially 
correct) translation choices. In our method, many 
new source-language trees T* that are similar to but 
different from the original source tree T can be re-
constructed at the decoding time. In theory our 
similarity-based scheme can increase the search 
space of the tree-to-string decoder, but we did not 
change any rule extraction and pruning settings.  
In practice, our similarity-based scheme can ef-
fectively keep the advantage of fast decoding for 
tree-to-string translation because its implementa-
tion is very simple. Let?s revisit the example deri-
vation d in Figure 1, i.e., d=r1?r2?r3?r4?r51. In 
such a case, the decoder can effectively produce a 
new derivation d* by simply replacing rule r3 with 
its similar rule ?3 ( 3r? ) shown in Figure 2, that is, 
d*=r1?r2??3?r4?r5.  
With beam search, typical tree-to-string decod-
ing with an integrated language model can run in 
time2 O(ncb2) in practice (Huang 2007). For our 
decoding time complexity computation, only the 
parameter c value can be affected by our similar-
ity-based scheme. In other words, our similarity-
based scheme would result in a larger c value at 
decoding time as many similar translation rules 
might be matched at each node. In practice, there 
are two feasible optimization techniques to allevi-
ate this problem. The first technique is to limit the 
maximum number of similar translation rules 
matched at each node. The second one is to prede-
fine a similarity threshold to filter out less similar 
translation rules in advance.  
In the implementation, we add a new feature 
into the model: similarity-based matching counting 
feature. This feature counts the number of similar 
rules used to form the derivation. The weight ?sim 
of this feature is tuned via minimal error rate train-
ing (MERT) (Och 2003) with other feature weights. 
3.2 Pseudo-rule Generation 
In the implementation of tree-to-string decoding, 
the first step is to load all translation rules matched 
at each node of the source tree T. It is possible that 
some nonterminal nodes do not have any matched 
rules when decoding some new sentences. If the 
root node of the source tree has no any matched 
rules, it would cause decoding failure. To tackle 
this problem, motivated by ?glue? rules (Chiang 
2005), for some node S without any matched rules, 
we introduce a special pseudo-rule which reassem-
bles all child nodes with local reordering to form 
new translation rules for S to complete decoding. 
                                                          
1 The symbol?denotes the composition (leftmost substitution) 
operation of two tree-to-string rules. 
2 Where n is the number of words, b is the size of the beam, 
and c is the number of translation rules matched at each node.   
420
               S                S(x1:A x2:B x3:C x4:D)?x1 x2 x3 x4               
                                 S(x1:A x2:B x3:C x4:D)?x2 x1 x3 x4           
                                 S(x1:A x2:B x3:C x4:D)?x1 x3 x2 x4 
    A     B     C     D   S(x1:A x2:B x3:C x4:D)?x1 x2 x4 x3 
              (a)                                         (b) 
Figure 4: (a) An example unseen substree, and (b) its 
four pseudo-rules. 
 
Figure 4 (a) depicts an example unseen substree 
where no any rules is matched at its root node S.  
Its simplest pseudo-rule is to simply combine a 
sequence of S?s child nodes. To give the model 
more options to build partial translations, we util-
ize a local reordering technique in which any two 
adjacent frontier (child) nodes are reordered during 
decoding. Figure 4(b) shows four pseudo-rules in 
total generated from this example unseen substree.   
In the implementation, we add a new feature to 
the model: pseudo-rule counting feature. This fea-
ture counts the number of pseudo-rules used to 
form the derivation. The weight ?pseudo of this fea-
ture is tuned via MERT with other feature weights.   
4 Evaluation 
4.1 Setup 
Our bilingual training data consists of 140K Chi-
nese-English sentence pairs in the FBIS data set. 
For rule extraction, the minimal GHKM rules (Gal-
ley et al 2004) were extracted from the bitext, and 
the composed rules were generated by combining 
two or three minimal GHKM rules. A 5-gram lan-
guage model was trained on the target-side of the 
bilingual data and the Xinhua portion of English 
Gigaword corpus. The beam size for beam search 
was set to 20. The base feature set used for all sys-
tems is similar to that used in (Marcu et al 2006), 
including 14 base features in total such as 5-gram 
language model, bidirectional lexical and phrase-
based translation probabilities. All features were 
linearly combined and their weights are optimized 
by using MERT. The development data set used 
for weight training in our approaches comes from 
NIST MT03 evaluation set. To speed up MERT, 
sentences with more than 20 words were removed 
from the development set (Dev set). The test sets 
are the NIST MT04 and MT05 evaluation sets. The 
translation quality was evaluated in terms of case-
insensitive NIST version BLEU metric. Statistical 
significance test was conducted by using the boot-
strap re-sampling method (Koehn 2004). 
4.2 Results 
MT04 MT05  DEV
MT03 <=20 ALL <=20 ALL 
Baseline 32.99 36.54 32.70 34.61 30.60 
This 
work 
34.67*
(+1.68)
36.99+
(+0.45)
35.03* 
(+2.33) 
35.16+ 
(+0.55) 
33.12*
(+2.52)
Table 1. BLEU4 (%) scores of various methods on Dev 
set (MT03) and two test sets (MT04 and MT05). Each 
small test set (<=20) was built by removing the sen-
tences with more than 20 words from the full set (ALL). 
+ and * indicate significantly better on performance 
comparison at p < .05 and p < .01, respectively. 
 
Table 1 depicts the BLEU scores of various meth-
ods on the Dev set and four test sets. Compared to 
typical tree-to-string decoding (the baseline), our 
method can achieve significant improvements on 
all datasets. It is noteworthy that the improvement 
achieved by our approach on full test sets is bigger 
than that on small test sets. For example, our 
method results in an improvement of 2.52 BLEU 
points over the baseline on the MT05 full test set, 
but only 0.55 points on the MT05 small test set. As 
mentioned before, tree-to-string approaches are 
more vulnerable to parsing errors. In practice, the 
Berkeley parser (Petrov et al 2006) we used yields 
unsatisfactory parsing performance on some long 
sentences in the full test sets. In such a case, it 
would result in negative effects on the performance 
of the baseline method on the full test sets. Ex-
perimental results show that our SDG approach 
can effectively alleviate this problem, and signifi-
cantly improve tree-to-string translation.  
 
 Another issue we are interested in is the decod-
ing speed of our method in practice. To investigate 
this issue, we evaluate the average decoding speed 
of our SDG method and the baseline on the Dev set 
and all test sets.  
 
Decoding Time 
(seconds per sentence) 
  
<=20 ALL 
Baseline 0.43s 1.1s 
This work 0.50s 1.3s 
Table 2. Average decoding speed of various methods on 
small (<=20) and full (ALL) datasets in terms of sec-
onds per sentence. The parsing time of each sentence is 
not included. The decoders were implemented in C++ 
codes on an X86-based PC with two processors of 
2.4GHZ and 4GB physical memory.  
 
421
Table 2 shows that our approach only has little 
impact on decoding speed in practice, compared to 
the typical tree-to-string decoding (baseline). No-
tice that in these comparisons our method did not 
adopt any optimization techniques mentioned in 
Section 3.1, e.g., to limit the maximum number of 
similar rules matched at each node. It is obviously 
that the use of such an optimization technique can 
effectively increase the decoding speed of our 
method, but might hurt the performance in practice.  
Besides, to speed up decoding long sentences, it 
seems a feasible solution to first divide a long sen-
tence into multiple short sub-sentences for decod-
ing, e.g., based on comma. In other words, we can 
segment a complex source-language parse tree into 
multiple smaller subtrees for decoding, and com-
bine the translations of these small subtrees to form 
the final translation. This practical solution can 
speed up the decoding on long sentences in real-
world MT applications, but might hurt the transla-
tion performance. 
For convenience, here we call the rule ?3 in Fig-
ure 2(b) similar-rules. It is worth investigating how 
many similar-rules and pseudo-rules are used to 
form the best derivations in our similarity-based 
scheme. To do it, we count the number of similar-
rules and pseudo-rules used to form the best deri-
vations when decoding on the MT05 full set. Ex-
perimental results show that on average 13.97% of 
rules used to form the best derivations are similar-
rules, and one pseudo-rule per sentence is used. 
Roughly speaking, average five similar-rules per 
sentence are utilized for decoding generalization.  
5 Related Work 
String-to-tree SMT approaches also utilize the 
similarity-based matching constraint on target side 
to generate target translation. This paper applies it 
on source side to reconstruct new similar source 
parse trees for decoding at the decoding time, 
which aims to increase the tree-to-string search 
space for decoding, and improve decoding gener-
alization for tree-to-string translation.  
The most related work is the forest-based trans-
lation method (Mi et al 2008; Mi and Huang 2008; 
Zhang et al 2009) in which rule extraction and 
decoding are implemented over k-best parse trees 
(e.g., in the form of packed forest) instead of one 
best tree as translation input. Liu and Liu (2010) 
proposed a joint parsing and translation model by 
casting tree-based translation as parsing (Eisner 
2003), in which the decoder does not respect the 
source tree. These methods can increase the tree-
to-string search space. However, the decoding time 
complexity of their methods is high, i.e., more than 
ten or several dozen times slower than typical tree-
to-string decoding (Liu and Liu 2010).  
Some previous efforts utilized the techniques of 
soft syntactic constraints to increase the search 
space in hierarchical phrase-based models (Marton 
and Resnik 2008; Chiang et al 2009; Huang et al 
2010), string-to-tree models (Venugopal et al 
2009) or tree-to-tree (Chiang 2010) systems. These 
methods focus on softening matching constraints 
on the root label of each rule regardless of its in-
ternal tree structure, and often generate many new 
syntactic categories3. It makes them more difficult 
to satisfy syntactic constraints for the tree-to-string 
decoding.  
6 Conclusion and Future Work 
This paper addresses the parse error issue for tree-
to-string translation, and proposes a similarity-
based decoding generation solution by reconstruct-
ing new similar source parse trees for decoding at 
the decoding time. It is noteworthy that our SDG 
approach is very easy to implement. In principle, 
forest-based and tree sequence-based approaches 
improve rule coverage by changing the rule extrac-
tion settings, and use exact tree-to-string matching 
constraints for decoding. Since our SDG approach 
is independent of any rule extraction and pruning 
techniques, it is also applicable to forest-based ap-
proaches or other tree-based translation models, 
e.g., in the case of casting tree-to-tree translation as 
tree parsing (Eisner 2003). 
Acknowledgments 
We would like to thank Feiliang Ren, Muhua Zhu 
and Hao Zhang for discussions and the anonymous 
reviewers for comments. This research was sup-
ported in part by the National Science Foundation 
of China (60873091; 61073140), the Specialized 
Research Fund for the Doctoral Program of Higher 
Education (20100042110031) and the Fundamental 
Research Funds for the Central Universities in 
China. 
                                                          
3 Latent syntactic categories were introduced in the method of 
Huang et al (2010). 
422
References  
Chiang David. 2005. A hierarchical phrase-based model 
for statistical machine translation. In Proc. of 
ACL2005, pp263-270 
Chiang David. 2010. Learning to translate with source 
and target syntax. In Proc. of ACL2010, pp1443-
1452 
Chiang David, Kevin Knight and Wei Wang. 2009. 
11,001 new features for statistical machine transla-
tion. In Proc. of NAACL2009, pp218-226  
Eisner Jason. 2003. Learning non-isomorphic tree map-
pings for machine translation. In Proc. of ACL 2003, 
pp205-208. 
Galley Michel, Mark Hopkins, Kevin Knight and Daniel 
Marcu. 2004. What's in a translation rule? In Proc. of 
HLT-NAACL 2004, pp273-280. 
Huang Liang. 2007. Binarization, synchronous binariza-
tion and target-side binarization. In Proc. of NAACL 
Workshop on Syntax and Structure in Statistical 
Translation.  
Huang Liang and David Chiang. 2007. Forest rescoring: 
Faster decoding with integrated language models. In 
Proc. of ACL 2007, pp144-151. 
Huang Liang, Kevin Knight and Aravind Joshi. 2006. 
Statistical syntax-directed translation with extended 
domain of locality. In Proc. of AMTA 2006, pp66-73. 
Huang Zhongqiang, Martin Cmejrek and Bowen Zhou. 
2010. Soft syntactic constraints for hierarchical 
phrase-based translation using latent syntactic distri-
bution. In Proc. of EMNLP2010, pp138-147 
Koehn Philipp. 2004. Statistical Significance Tests for 
Machine Translation Evaluation. In Proc. of EMNLP 
2004, pp388-395. 
Liu Yang and Qun Liu. 2010. Joint parsing and transla-
tion. In Proc. of Coling2010, pp707-715 
Liu Yang, Qun Liu and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine 
translation. In Proc. of COLING/ACL 2006, pp609-
616. 
Marcu Daniel, Wei Wang, Abdessamad Echihabi and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language phrases. 
In Proc. of EMNLP 2006, pp44-52. 
Marton Yuval and Philip Resnik. 2008. Soft syntactic 
constraints for hierarchical phrase-based translation. 
In Proc. of ACL08, pp1003-1011 
Mi Haitao and Liang Huang. 2008. Forest-based Trans-
lation Rule Extraction. In Proc. of EMNLP 2008, 
pp206-214. 
Mi Haitao, Liang Huang and Qun Liu. 2008. Forest-
based translation. In Proc. of ACL2008.  
Och Franz Josef. 2003. Minimum error rate training in 
statistical machine translation. In Proc. of ACL2003. 
Petrov Slav, Leon Barrett, Roman Thibaux and Dan 
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proc. of ACL2006, 
pp433-440. 
Xiao Tong, Jingbo Zhu, Hao Zhang and Muhua Zhu. 
2010. An empirical study of translation rule extrac-
tion with multiple parsers. In Proc. of Coling2010, 
pp1345-1353 
Venugopal Ashish, Andreas Zollmann, Noah A. Smith 
and Stephan Vogel. 2009. Preference grammars: sof-
tening syntactic constraints to improve statistical ma-
chine translation. In Proc. of NAACL2009, pp236-
244 
Zhang Hui, Min Zhang, Haizhou Li, Aiti Aw and Chew 
Lim Tan. 2009. Forest-based tree sequence to string 
translation model. In Proc. of ACL-IJCNLP2009, 
pp172-180 
 
423
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 280?284,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Learning Better Rule Extraction with Translation Span Alignment 
Jingbo Zhu    Tong Xiao   Chunliang Zhang 
Natural Language Processing Laboratory 
Northeastern University, Shenyang, China 
{zhujingbo,xiaotong,zhangcl}@mail.neu.edu.cn 
 
 
 
 
Abstract 
This paper presents an unsupervised ap-
proach to learning translation span align-
ments from parallel data that improves 
syntactic rule extraction by deleting spuri-
ous word alignment links and adding new 
valuable links based on bilingual transla-
tion span correspondences. Experiments on 
Chinese-English translation demonstrate 
improvements over standard methods for 
tree-to-string and tree-to-tree translation.  
1 Introduction 
Most syntax-based statistical machine translation 
(SMT) systems typically utilize word alignments 
and parse trees on the source/target side to learn 
syntactic transformation rules from parallel data. 
The approach suffers from a practical problem that 
even one spurious (word alignment) link can pre-
vent some desirable syntactic translation rules from 
extraction, which can in turn affect the quality of 
translation rules and translation performance (May 
and Knight 2007; Fossum et al 2008). To address 
this challenge, a considerable amount of previous 
research has been done to improve alignment qual-
ity by incorporating some statistics and linguistic 
heuristics or syntactic information into word 
alignments (Cherry and Lin 2006; DeNero and 
Klein 2007; May and Knight 2007; Fossum et al 
2008; Hermjakob 2009; Liu et al 2010).  
Unlike their efforts, this paper presents a simple 
approach that automatically builds the translation 
span alignment (TSA) of a sentence pair by utiliz-
ing a phrase-based forced decoding technique, and 
then improves syntactic rule extraction by deleting 
spurious links and adding new valuable links based 
on bilingual translation span correspondences. The 
proposed approach has two promising properties.  
S
VP
ADVPNNS
imports
VBZ
have
DT
VBNRB
fallendrasticallythe
??
jianshao
???
dafudu
??
jinkou
?
le
NN
VV AS
AD VP
VP
S
NP Frontier node
Word alignment
 
Figure 1. A real example of Chinese-English sentence 
pair with word alignment and both-side parse trees.  
 
Some blocked Tree-to-string Rules: 
r1: AS(?) ? have 
r2: NN(??) ? the imports 
r3: S (NN:x1 VP:x2) ? x1 x2
Some blocked Tree-to-tree Rules: 
r4: AS(?) ? VBZ(have) 
r5: NN(??) ? NP(DT(the) NNS(imports)) 
r6: S(NN:x1 VP:x2) ? S(NP:x1 VP:x2) 
r7: VP(AD:x1 VP(VV:x2 AS:x3)) 
            ? VP(VBZ:x3 ADVP(RB:x1 VBN:x2)) 
Table 1. Some useful syntactic rules are blocked due to 
the spurious link between ??? and ?the?.  
 
Firstly, The TSAs are constructed in an unsuper-
vised learning manner, and optimized by the trans-
lation model during the forced decoding process, 
without using any statistics and linguistic heuristics 
or syntactic constraints. Secondly, our approach is 
independent of the word alignment-based algo-
rithm used to extract translation rules, and easy to 
implement. 
2 Translation Span Alignment Model 
Different from word alignment, TSA is a process 
of identifying span-to-span alignments between 
parallel sentences. For each translation span pair,  
280
1. Extract phrase translation rules R from the parallel 
corpus with word alignment, and construct a phrase-
based translation model M.  
2. Apply M to implement phrase-based forced decoding 
on each training sentence pair (c, e), and output its 
best derivation d* that can transform c into e.  
3. Build a TSA of each sentence pair (c, e) from its best 
derivation d*, in which each rule r in d* is used to 
form a translation span pair {src(r)<=>tgt(r)}.  
Figure 2. TSA generation algorithm. src(r) and tgt(r) 
indicate the source and target side of rule r.  
 
its source (or target) span is a sequence of source 
(or target) words. Given a source sentence c=c1...cn, 
a target sentence e=e1...em, and its word alignment 
A, a translation span pair ? is a pair of source span 
(ci...cj) and target span (ep...eq)  
)( qp
j
i ec ?=?  
where ? indicates that the source span (ci...cj) and 
the target span (ep...eq) are translational equivalent. 
We do not require that ? must be consistent with 
the associated word alignment A in a TSA model.  
Figure 2 depicts the TSA generation algorithm 
in which a phrase-based forced decoding tech-
nique is adopted to produce the TSA of each sen-
tence pair. In this work, we do not apply syntax-
based forced decoding (e.g., tree-to-string) because 
phrase-based models can achieve the state-of-the-
art translation quality with a large amount of train-
ing data, and are not limited by any constituent 
boundary based constraints for decoding.  
Formally, given a sentence pair (c, e), the 
phrase-based forced decoding technique aims to 
search for the best derivation d* among all consis-
tent derivations that convert the given source sen-
tence c into the given target sentence e with respect 
to the current translation model induced from the 
training data, which can be expressed by 
)|)((Prmaxarg
)(),(
* cdTGTd
edTGTecDd
?=??
=          (1) 
where D(c,e) is the set of candidate derivations that 
transform c to e, and TGT(d) is a function that out-
puts the yield of a derivation d. ? indicates parame-
ters of the phrase-based translation model learned 
from the parallel corpus.  
The best derivation d* produced by forced de-
coding can be viewed as a sequence of translation 
steps (i.e., phrase translation rules), expressed by 
krrrd ???= ...* 21 , 
c = ?? ??? ?? ? 
e =  the imports have drastically fallen 
The best derivation d* produced by forced decoding: 
r1: ?? ? the imports 
r2: ??? ?? ? drastically fallen 
r3: ? ? have 
Generating TSA from d*: 
[??]<=>[the imports]  
[??? ??]<=>[drastically fallen]   
[?]<=>[have] 
Table 2. Forced decoding based TSA generation on the 
example sentence pair in Fig. 1. 
 
where ri indicates a phrase rule used to form d*. 
?is a composition operation that combines rules 
{r1...rk} together to produce the target translation.  
As mentioned above, the best derivation d* re-
spects the input sentence pair (c, e). It means that 
for each phrase translation rule ri used by d*, its 
source (or target) side exactly matches a span of 
the given source (or target) sentence. The source 
side src(ri) and the target side tgt(ri) of each phrase 
translation rule ri in d* form a translation span pair 
{src(ri)<=>tgt(ri)} of (c,e). In other words, the 
TSA of (c,e) is a set of translation span pairs gen-
erated from phrase translation rules used by the 
best derivation d*. The forced decoding based TSA 
generation on the example sentence pair in Figure 
1 can be shown in Table 2. 
3 Better Rule Extraction with TSAs 
To better understand the particular task that we 
will address in this section, we first introduce a 
definition of inconsistent with a translation span 
alignment. Given a sentence pair (c, e) with the 
word alignment A and the translation span align-
ment P, we call a link (ci, ej)?A inconsistent with 
P, if  ci and ej are covered respectively by two dif-
ferent translation span pairs in P and vice versa. 
(ci, ej)?A inconsistent with P  ?
)()(:  
)()(:       
???
???
tgtesrccPOR
tgtesrccP
ji
ji
?????
?????
 
where src(?) and tgt(?) indicate the source and tar-
get span of a translation span pair ?.  
By this, we will say that a link (ci, ej)?A is a 
spurious link if it is inconsistent with the given 
TSA. Table 3 shows that an original link (4?1) 
are covered by two different translation span pairs  
281
Source Target WA TSA 
1: ?? 1: the 1?2 [1,1]<=>[1,2] 
2: ??? 2: imports 2?4 [2,3]<=>[4,5] 
3: ?? 3: have 3?5 [4,4]<=>[3,3] 
4: ? 4: drastically 4?1  
 5: fallen (null)?3  
Table 3. A sentence pair with the original word align-
ment (WA) and the translation span alignment (TSA).  
 
([4,4]<=>[3,3]) and ([1,1] <=>[1,2]), respectively. 
In such a case, we think that this link (4?1) is a 
spurious link according to this TSA, and should be 
removed for rule extraction.   
Given a resulting TSA P, there are four different 
types of translation span pairs, such as one-to-one, 
one-to-many, many-to-one, and many-to-many 
cases. For example, the TSA shown in Table 3 
contains a one-to-one span pair ([4,4]<=>[3,3]), a 
one-to-many span pair ([1,1]<=>[1,2]) and a 
many-many span pair ([2,3]<=>[4,5]). In such a 
case, we can learn a confident link from a one-to-
one translation span pair that is preferred by the 
translation model in the forced decoding based 
TSA generation approach. If such a confident link 
does not exist in the original word alignment, we 
consider it as a new valuable link.  
Until now, a natural way is to use TSAs to di-
rectly improve word alignment quality by deleting 
some spurious links and adding some new confi-
dent links, which in turn improves rule quality and 
translation quality. In other words, if a desirable 
translation rule was blocked due to some spurious 
links, we will output this translation rule. Let?s 
revisit the example in Figure 1 again. The blocked 
tree-to-string r3 can be extracted successfully after 
deleting the spurious link (?, the), and a new tree-
to-string rule r1 can be extracted after adding a new 
confident link (?, have) that is inferred from a 
one-to-one translation span pair [4,4]<=>[3,3].  
4 Experiments 
4.1 Setup 
We utilized a state-of-the-art open-source SMT 
system NiuTrans (Xiao et al 2012) to implement 
syntax-based models in the following experiments. 
We begin with a training parallel corpus of Chi-
nese-English bitexts that consists of 8.8M Chinese 
words and 10.1M English words in 350K sentence 
pairs. The GIZA++ tool was used to perform the  
Method Prec% Rec% F1% Del/Sent Add/Sent
Baseline 83.07 75.75 79.25 - - 
TSA 84.01 75.46 79.51 1.5 1.1 
Table 4. Word alignment precision, recall and F1-score 
of various methods on 200 sentence pairs of Chinese-
English data. 
 
bi-directional word alignment between the source 
and the target sentences, referred to as the baseline 
method. For syntactic translation rule extraction, 
minimal GHKM (Galley et al, 2004) rules are first 
extracted from the bilingual corpus whose source 
and target sides are parsed using the Berkeley 
parser (Petrov et al 2006). The composed rules are 
then generated by composing two or three minimal 
rules. A 5-gram language model was trained on the 
Xinhua portion of English Gigaword corpus. Beam 
search and cube pruning techniques (Huang and 
Chiang 2007) were used to prune the search space 
for all the systems. The base feature set used for all 
systems is similar to that used in (Marcu et al 
2006), including 14 base features in total such as 5-
gram language model, bidirectional lexical and 
phrase-based translation probabilities. All features 
were log-linearly combined and their weights were 
optimized by performing minimum error rate train-
ing (MERT) (Och 2003). The development data set 
used for weight training comes from NIST MT03 
evaluation set, consisting of 326 sentence pairs of 
less than 20 words in each Chinese sentence. Two 
test sets are NIST MT04 (1788 sentence pairs) and 
MT05 (1082 sentence pairs) evaluation sets. The 
translation quality is evaluated in terms of the case-
insensitive IBM-BLEU4 metric.  
4.2 Effect on Word Alignment 
To investigate the effect of the TSA method on 
word alignment, we designed an experiment to 
evaluate alignment quality against gold standard 
annotations. There are 200 random chosen and 
manually aligned Chinese-English sentence pairs 
used to assert the word alignment quality. For 
word alignment evaluation, we calculated precision, 
recall and F1-score over gold word alignment.  
Table 4 depicts word alignment performance of 
the baseline and TSA methods. We apply the TSAs 
to refine the baseline word alignments, involving 
spurious link deletion and new link insertion op-
erations. Table 4 shows our method can yield im-
provements on precision and F1-score, only 
causing a little negative effect on recall.  
282
4.3 Translation Quality 
Method # of Rules MT03 MT04 MT05 
Baseline (T2S) 33,769,071 34.10 32.55 30.15 
TSA (T2S) 32,652,261 
34.61+
(+0.51) 
33.01+
(+0.46)
30.66+
(+0.51)
     
Baseline (T2T) 24,287,206 34.51 32.20 31.78 
TSA (T2T) 24,119,719 
34.85 
(+0.34) 
32.92*
(+0.72)
32.22+ 
(+0.44)
Table 5. Rule sizes and IBM-BLEU4 (%) scores of 
baseline and our method (TSA) in tree-to-string (T2S) 
and tree-to-tree (T2T) translation on Dev set (MT03) 
and two test sets (MT04 and MT05). + and * indicate 
significantly better on performance comparison at p<.05 
and p<.01, respectively.  
 
Table 5 depicts effectiveness of our TSA method 
on translation quality in tree-to-string and tree-to-
tree translation tasks. Table 5 shows that our TSA 
method can improve both syntax-based translation 
systems. As mentioned before, the resulting TSAs 
are essentially optimized by the translation model. 
Based on such TSAs, experiments show that spuri-
ous link deletion and new valuable link insertion 
can improve translation quality for tree-to-string 
and tree-to-tree systems.  
5 Related Work 
Previous studies have made great efforts to incor-
porate statistics and linguistic heuristics or syntac-
tic information into word alignments (Ittycheriah 
and Roukos 2005; Taskar et al 2005; Moore et al 
2006; Cherry and Lin 2006; DeNero and Klein 
2007; May and Knight 2007; Fossum et al 2008; 
Hermjakob 2009; Liu et al 2010). For example, 
Fossum et al (2008) used a discriminatively 
trained model to identify and delete incorrect links 
from original word alignments to improve string-
to-tree transformation rule extraction, which incor-
porates four types of features such as lexical and 
syntactic features. This paper presents an approach 
to incorporating translation span alignments into 
word alignments to delete spurious links and add 
new valuable links.  
Some previous work directly models the syntac-
tic correspondence in the training data for syntactic 
rule extraction (Imamura 2001; Groves et al 2004; 
Tinsley et al 2007; Sun et al 2010a, 2010b; Pauls 
et al 2010). Some previous methods infer syntac-
tic correspondences between the source and the 
target languages through word alignments and con-
stituent boundary based syntactic constraints. Such 
a syntactic alignment method is sensitive to word 
alignment behavior. To combat this, Pauls et al 
(2010) presented an unsupervised ITG alignment 
model that directly aligns syntactic structures for 
string-to-tree transformation rule extraction. One 
major problem with syntactic structure alignment 
is that syntactic divergence between languages can 
prevent accurate syntactic alignments between the 
source and target languages.  
May and Knight (2007) presented a syntactic re-
alignment model for syntax-based MT that uses 
syntactic constraints to re-align a parallel corpus 
with word alignments. The motivation behind their 
methods is similar to ours. Our work differs from 
(May and Knight 2007) in two major respects. 
First, the approach proposed by May and Knight 
(2007) first utilizes the EM algorithm to obtain 
Viterbi derivation trees from derivation forests of 
each (tree, string) pair, and then produces Viterbi 
alignments based on obtained derivation trees. Our 
forced decoding based approach searches for the 
best derivation to produce translation span align-
ments that are used to improve the extraction of 
translation rules. Translation span alignments are 
optimized by the translation model. Secondly, their 
models are only applicable for syntax-based sys-
tems while our method can be applied to both 
phrase-based and syntax-based translation tasks.  
6 Conclusion 
This paper presents an unsupervised approach to 
improving syntactic transformation rule extraction 
by deleting spurious links and adding new valuable 
links with the help of bilingual translation span 
alignments that are built by using a phrase-based 
forced decoding technique. In our future work, it is 
worth studying how to combine the best of our ap-
proach and discriminative word alignment models 
to improve rule extraction for SMT models.  
Acknowledgments 
This research was supported in part by the National 
Science Foundation of China (61073140), the Spe-
cialized Research Fund for the Doctoral Program 
of Higher Education (20100042110031) and the 
Fundamental Research Funds for the Central Uni-
versities in China. 
283
References  
Colin Cherry and Dekang Lin. 2006. Soft syntactic con-
straints for word alignment through discriminative 
training. In Proc. of ACL. 
John DeNero and Dan Klein. 2007. Tailoring word 
alignments to syntactic machine translation. In Proc. 
of ACL. 
Victoria Fossum, Kevin Knight and Steven Abney. 
2008. Using syntax to improve word alignment pre-
cision for syntax-based machine translation. In Proc. 
of the Third Workshop on Statistical Machine Trans-
lation, pages 44-52. 
Michel Galley, Mark Hopkins, Kevin Knight and Daniel 
Marcu. 2004. What's in a translation rule? In Proc. of 
HLT-NAACL 2004, pp273-280. 
Declan Groves, Mary Hearne and Andy Way. 2004. 
Robust sub-sentential alignment of phrase-structure 
trees. In Proc. of COLING, pp1072-1078. 
Ulf Hermjakob. 2009. Improved word alignment with 
statistics and linguistic heuristics. In Proc. of EMNLP, 
pp229-237 
Liang Huang and David Chiang. 2007. Forest rescoring: 
Faster decoding with integrated language models. In 
Proc. of ACL, pp144-151. 
Kenji Imamura. 2001. Hierarchical Phrase Alignment 
Harmonized with Parsing. In Proc. of NLPRS, 
pp377-384. 
Abraham Ittycheriah and Salim Roukos. 2005. A maxi-
mum entropy word aligner for Arabic-English ma-
chine translation. In Proc. of HLT/EMNLP. 
Yang Liu, Qun Liu and Shouxun Lin. 2010. Discrimina-
tive word alignment by linear modeling. Computa-
tional Linguistics, 36(3):303-339 
Daniel Marcu, Wei Wang, Abdessamad Echihabi and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language phrases. 
In Proc. of EMNLP, pp44-52. 
Jonathan May and Kevin Knight. 2007. Syntactic re-
alignment models for machine translation. In Proc. of 
EMNLP-CoNLL.  
Robert C. Moore, Wen-tau Yih and Andreas Bode. 2006. 
Improved discriminative bilingual word alignment. 
In Proc. of ACL 
Franz Josef Och. 2003. Minimum error rate training in 
statistical machine translation. In Proc. of ACL. 
Adam Pauls, Dan Klein, David Chiang and Kevin 
Knight. 2010. Unsupervised syntactic alignment with 
inversion transduction grammars. In Proc. of NAACL, 
pp118-126 
Slav Petrov, Leon Barrett, Roman Thibaux and Dan 
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proc. of ACL, pp433-440. 
Jun Sun, Min Zhang and Chew Lim Tan. 2010a. Explor-
ing Syntactic Structural Features for Sub-Tree 
Alignment Using Bilingual Tree Kernels. In Proc. of 
ACL, pp306-315. 
Jun Sun, Min Zhang and Chew Lim Tan. 2010b. Dis-
criminative Induction of Sub-Tree Alignment using 
Limited Labeled Data. In Proc. of COLING, pp1047-
1055. 
Ben Taskar, Simon Lacoste-Julien and Dan Klein. 2005. 
A discriminative matching approach to word align-
ment. In Proc. of HLT/EMNLP 
John Tinsley, Ventsislav Zhechev, Mary Hearne and 
Andy Way. 2007. Robust language pair-independent 
sub-tree alignment. In Proc. of MT Summit XI. 
Tong Xiao, Jingbo Zhu, Hao Zhang and Qiang Li. 2012. 
NiuTrans: An Open Source Toolkit for Phrase-based 
and Syntax-based Machine Translation. In Proceed-
ings of ACL, demonstration session 
284
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 19?24,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
NiuTrans: An Open Source Toolkit for  
Phrase-based and Syntax-based Machine Translation  
 
Tong Xiao? ? , Jingbo Zhu? ? , Hao Zhang?  and Qiang Li?  
?Natural Language Processing Lab, Northeastern University 
?Key Laboratory of Medical Image Computing, Ministry of Education 
{xiaotong,zhujingbo}@mail.neu.edu.cn 
{zhanghao1216,liqiangneu}@gmail.com 
 
 
 
Abstract 
We present a new open source toolkit for 
phrase-based and syntax-based machine 
translation. The toolkit supports several 
state-of-the-art models developed in 
statistical machine translation, including 
the phrase-based model, the hierachical 
phrase-based model, and various syntax-
based models. The key innovation provided 
by the toolkit is that the decoder can work 
with various grammars and offers different 
choices of decoding algrithms, such as 
phrase-based decoding, decoding as 
parsing/tree-parsing and forest-based 
decoding. Moreover, several useful utilities 
were distributed with the toolkit, including 
a discriminative reordering model, a simple 
and fast language model, and an 
implementation of minimum error rate 
training  for weight tuning. 
1 Introduction 
We present NiuTrans, a new open source machine 
translation toolkit, which was developed for 
constructing high quality machine translation 
systems. The NiuTrans toolkit supports most 
statistical machine translation (SMT) paradigms 
developed over the past decade, and allows for 
training and decoding with several state-of-the-art 
models, including: the phrase-based model (Koehn 
et al, 2003), the hierarchical phrase-based model 
(Chiang, 2007), and various syntax-based models 
(Galley et al, 2004; Liu et al, 2006). In particular, 
a unified framework was adopted to decode with 
different models and ease the implementation of 
decoding algorithms. Moreover, some useful 
utilities were distributed with the toolkit, such as: a 
discriminative reordering model, a simple and fast 
language model, and an implementation of 
minimum error rate training that allows for various 
evaluation metrics for tuning the system. In 
addition, the toolkit provides easy-to-use APIs for 
the development of new features. The toolkit has 
been used to build translation systems that have 
placed well at recent MT evaluations, such as the 
NTCIR-9 Chinese-to-English PatentMT task (Goto 
et al, 2011). 
We implemented the toolkit in C++ language, 
with special consideration of extensibility and 
efficiency. C++ enables us to develop efficient 
translation engines which have high running speed 
for both training and decoding stages. This 
property is especially important when the programs 
are used for large scale translation. While the 
development of C++ program is slower than that of 
the similar programs written in other popular 
languages such as Java, the modern compliers 
generally result in C++ programs being 
consistently faster than the Java-based counterparts. 
The toolkit is available under the GNU general 
public license 1 . The website of NiuTrans is   
http://www.nlplab.com/NiuPlan/NiuTrans.html. 
2 Motivation 
As in current approaches to statistical machine 
translation, NiuTrans is based on a log-linear 
                                                          
1 http://www.gnu.org/licenses/gpl-2.0.html 
19
model where a number of features are defined to 
model the translation process. Actually NiuTrans is 
not the first system of this kind. To date, several 
open-source SMT systems (based on either phrase-
based models or syntax-based models) have been 
developed, such as Moses (Koehn et al, 2007), 
Joshua (Li et al, 2009), SAMT (Zollmann and 
Venugopal, 2006), Phrasal (Cer et al, 2010), cdec 
(Dyer et al, 2010), Jane (Vilar et al, 2010) and 
SilkRoad 2 , and offer good references for the 
development of the NiuTrans toolkit. While our 
toolkit includes all necessary components as 
provided within the above systems, we have 
additional goals for this project, as follows: 
z It fully supports most state-of-the-art SMT 
models. Among these are: the phrase-based 
model, the hierarchical phrase-based model, 
and the syntax-based models that explicitly 
use syntactic information on either (both) 
source and (or) target language side(s). 
z It offers a wide choice of decoding 
algorithms. For example, the toolkit has 
several useful decoding options, including: 
standard phrase-based decoding, decoding 
as parsing, decoding as tree-parsing, and 
forest-based decoding. 
z It is easy-to-use and fast. A new system can 
be built using only a few commands. To 
control the system, users only need to 
modify a configuration file. In addition to 
the special attention to usability, the 
running speed of the system is also 
improved in several ways. For example, we 
used several pruning and multithreading 
techniques to speed-up the system. 
3 Toolkit 
The toolkit serves as an end-to-end platform for 
training and evaluating statistical machine 
translation models. To build new translation 
systems, all you need is a collection of word-
aligned sentences 3 , and a set of additional 
sentences with one or more reference translations 
for weight tuning and test. Once the data is 
prepared, the MT system can be created using a 
                                                          
2 http://www.nlp.org.cn/project/project.php?proj_id=14 
3 To obtain word-to-word alignments, several easy-to-use 
toolkits are available, such as GIZA++ and Berkeley Aligner. 
sequence of commands. Given a number of 
sentence-pairs and the word alignments between 
them, the toolkit first extracts a phrase table and 
two reordering models for the phrase-based system, 
or a Synchronous Context-free/Tree-substitution 
Grammar (SCFG/STSG) for the hierarchical 
phrase-based and syntax-based systems. Then, an 
n-gram language model is built on the target-
language corpus. Finally, the resulting models are 
incorporated into the decoder which can 
automatically tune feature weights on the 
development set using minimum error rate training 
(Och, 2003) and translate new sentences with the 
optimized weights. 
In the following, we will give a brief review of 
the above components and the main features 
provided by the toolkit. 
3.1 Phrase Extraction and Reordering Model 
We use a standard way to implement the phrase 
extraction module for the phrase-based model. 
That is, we extract all phrase-pairs that are 
consistent with word alignments. Five features are 
associated with each phrase-pair. They are two 
phrase translation probabilities, two lexical weights, 
and a feature of phrase penalty. We follow the 
method proposed in (Koehn et al, 2003) to 
estimate the values of these features. 
Unlike previous systems that adopt only one 
reordering model, our toolkit supports two 
different reordering models which are trained 
independently but jointly used during decoding. 
z The first of these is a discriminative 
reordering model. This model is based on 
the standard framework of maximum 
entropy. Thus the reordering problem is 
modeled as a classification problem, and 
the reordering probability can be efficiently 
computed using a (log-)linear combination 
of features. In our implementation, we use 
all boundary words as features which are 
similar to those used in (Xiong et al, 2006). 
z The second model is the MSD reordering 
model4 which has been successfully used in 
the Moses system. Unlike Moses, our 
toolkit supports both the word-based and 
phrase-based methods for estimating the 
                                                          
4 Term MSD refers to the three orientations (reordering types), 
including Monotone (M), Swap (S), and Discontinuous (D). 
20
probabilities of the three orientations 
(Galley and Manning, 2008). 
3.2 Translation Rule Extraction 
For the hierarchical phrase-based model, we follow 
the general framework of SCFG where a grammar 
rule has three parts ? a source-side, a target-side 
and alignments between source and target non-
terminals. To learn SCFG rules from word-aligned 
sentences, we choose the algorithm proposed in 
(Chiang, 2007) and estimate the associated feature 
values as in the phrase-based system. 
For the syntax-based models, all non-terminals 
in translation rules are annotated with syntactic 
labels. We use the GHKM algorithm to extract 
(minimal) translation rules from bilingual 
sentences with parse trees on source-language side 
and/or target-language side5 . Also, two or more 
minimal rules can be composed together to obtain 
larger rules and involve more contextual 
information. For unaligned words, we attach them 
to all nearby rules, instead of using the most likely 
attachment as in (Galley et al, 2006). 
3.3 N-gram Language Modeling 
The toolkit includes a simple but effective n-gram 
language model (LM). The LM builder is basically 
a ?sorted? trie structure (Pauls and Klein, 2011), 
where a map is developed to implement an array of 
key/value pairs, guaranteeing that the keys can be 
accessed in sorted order. To reduce the size of 
resulting language model, low-frequency n-grams 
are filtered out by some thresholds. Moreover, an 
n-gram cache is implemented to speed up n-gram 
probability requests for decoding. 
3.4 Weight Tuning 
We implement the weight tuning component 
according to the minimum error rate training 
(MERT) method (Och, 2003). As MERT suffers 
from local optimums, we added a small program 
into the MERT system to let it jump out from the 
coverage area. When MERT converges to a (local) 
optimum, our program automatically conducts the 
MERT run again from a random starting point near 
the newly-obtained optimal point. This procedure 
                                                          
5 For tree-to-tree models, we use a natural extension of the 
GHKM algorithm which defines admissible nodes on tree-
pairs and obtains tree-to-tree rules on all pairs of source and 
target tree-fragments. 
is repeated for several times until no better weights 
(i.e., weights with a higher BLEU score) are found. 
In this way, our program can introduce some 
randomness into weight training. Hence users do 
not need to repeat MERT for obtaining stable and 
optimized weights using different starting points.  
3.5 Decoding 
Chart-parsing is employed to decode sentences in 
development and test sets. Given a source sentence, 
the decoder generates 1-best or k-best translations 
in a bottom-up fashion using a CKY-style parsing 
algorithm. The basic data structure used in the 
decoder is a chart, where an array of cells is 
organized in topological order. Each cell maintains 
a list of hypotheses (or items). The decoding 
process starts with the minimal cells, and proceeds 
by repeatedly applying translation rules or 
composing items in adjunct cells to obtain new 
items. Once a new item is created, the associated 
scores are computed (with an integrated n-gram 
language model). Then, the item is added into the 
list of the corresponding cell. This procedure stops 
when we reach the final state (i.e., the cell 
associates with the entire source span). 
The decoder can work with all (hierarchical) 
phrase-based and syntax-based models. In 
particular, our toolkit provides the following 
decoding modes. 
z Phrase-based decoding. To fit the phrase-
based model into the CKY paring 
framework, we restrict the phrase-based 
decoding with the ITG constraint (Wu, 
1996). In this way, each pair of items in 
adjunct cells can be composed in either 
monotone order or inverted order. Hence 
the decoding can be trivially implemented 
by a three-loop structure as in standard 
CKY parsing. This algorithm is actually the 
same as that used in parsing with 
bracketing transduction grammars. 
z Decoding as parsing (or string-based 
decoding). This mode is designed for 
decoding with SCFGs/STSGs which are 
used in the hierarchical phrase-based and 
syntax-based systems. In the general 
framework of synchronous grammars and 
tree transducers, decoding can be regarded 
as a parsing problem. Therefore, the above 
chart-based decoder is directly applicable to 
21
the hierarchical phrase-based and syntax-
based models. For efficient integration of n-
gram language model into decoding, rules 
containing more than two variables are 
binarized into binary rules. In addition to 
the rules learned from bilingual data, glue 
rules are employed to glue the translations 
of a sequence of chunks.  
z Decoding as tree-parsing (or tree-based 
decoding). If the parse tree of source 
sentence is provided, decoding (for tree-to-
string and tree-to-tree models) can also be 
cast as a tree-parsing problem (Eisner, 
2003). In tree-parsing, translation rules are 
first mapped onto the nodes of input parse 
tree. This results in a translation tree/forest 
(or a hypergraph) where each edge 
represents a rule application. Then 
decoding can proceed on the hypergraph as 
usual. That is, we visit in bottom-up order 
each node in the parse tree, and calculate 
the model score for each edge rooting at the 
node. The final output is the 1-best/k-best 
translations maintained by the root node of 
the parse tree. Since tree-parsing restricts 
its search space to the derivations that 
exactly match with the input parse tree, it in 
general has a much higher decoding speed 
than a normal parsing procedure. But it in 
turn results in lower translation quality due 
to more search errors. 
z Forest-based decoding. Forest-based 
decoding (Mi et al, 2008) is a natural 
extension of tree-based decoding. In 
principle, forest is a data structure that can 
encode exponential number of trees 
efficiently. This structure has been proved 
to be helpful in reducing the effects caused 
by parser errors. Since our internal 
representation is already in a hypergraph 
structure, it is easy to extend the decoder to 
handle the input forest, with little 
modification of the code. 
4 Other Features 
In addition to the basic components described 
above, several additional features are introduced to 
ease the use of the toolkit. 
4.1 Multithreading 
The decoder supports multithreading to make full 
advantage of the modern computers where more 
than one CPUs (or cores) are provided. In general, 
the decoding speed can be improved when multiple 
threads are involved. However, modern MT 
decoders do not run faster when too many threads 
are used (Cer et al, 2010). 
4.2 Pruning 
To make decoding computational feasible, beam 
pruning is used to aggressively prune the search 
space. In our implementation, we maintain a beam 
for each cell. Once all the items of the cell are 
proved, only the top-k best items according to 
model score are kept and the rest are discarded. 
Also, we re-implemented the cube pruning method 
described in (Chiang, 2007) to further speed-up the 
system. 
In addition, we develop another method that 
prunes the search space using punctuations. The 
idea is to divide the input sentence into a sequence 
of segments according to punctuations. Then, each 
segment is translated individually. The MT outputs 
are finally generated by composing the translations 
of those segments. 
4.3 APIs for Feature Engineering 
To ease the implementation and test of new 
features, the toolkit offers APIs for experimenting 
with the features developed by users. For example, 
users can develop new features that are associated 
with each phrase-pair. The system can 
automatically recognize them and incorporate them 
into decoding. Also, more complex features can be 
activated during decoding. When an item is created 
during decoding, new features can be introduced 
into an internal object which returns feature values 
for computing the model score. 
5 Experiments 
5.1 Experimental Setup 
We evaluated our systems on NIST Chinese-
English MT tasks. Our training corpus consists of 
1.9M bilingual sentences. We used GIZA++ and 
the ?grow-diag-final-and? heuristics to generate 
word alignment for the bilingual data. The parse 
trees on both the Chinese and English sides were 
22
BLEU4[%] Entry 
 Dev  Test 
Moses: phrase  36.51  34.93
Moses: hierarchical phrase  36.65  34.79
 phrase  36.99  35.29
 hierarchical phrase  37.41  35.35
 parsing  36.48  34.71
 tree-parsing  35.54  33.99
 t2s 
 forest-based  36.14  34.25
 parsing  35.99  34.01
 tree-parsing  35.04  33.21
 t2t 
 forest-based  35.56  33.45
   
   
   
 N
iu
Tr
an
s 
 s2t  parsing  37.63  35.65
Table 1: BLEU scores of various systems. t2s, t2t, 
and s2t represent the tree-to-string, tree-to-tree, and 
string-to-tree systems, respectively. 
 
generated using the Berkeley Parser, which were 
then binarized in a head-out fashion 6. A 5-gram 
language model was trained on the Xinhua portion 
of the Gigaword corpus in addition to the English 
part of the LDC bilingual training data. We used 
the NIST 2003 MT evaluation set as our 
development set (919 sentences) and the NIST 
2005 MT evaluation set as our test set (1,082 
sentences). The translation quality was evaluated 
with the case-insensitive IBM-version BLEU4. 
For the phrase-based system, phrases are of at 
most 7 words on either source or target-side. For 
the hierarchical phrase-based system, all SCFG 
rules have at most two variables. For the syntax-
based systems, minimal rules were extracted from 
the binarized trees on both (either) language-
side(s). Larger rules were then generated by 
composing two or three minimal rules. By default, 
all these systems used a beam of size 30 for 
decoding. 
5.2 Evaluation of Translations 
Table 1 shows the BLEU scores of different MT 
systems built using our toolkit. For comparison, 
the result of the Moses system is also reported. We 
see, first of all, that our phrase-based and 
hierarchical phrase-based systems achieve 
competitive performance, even outperforms the 
Moses system over 0.3 BLEU points in some cases. 
Also, the syntax-based systems obtain very  
                                                          
6 The parse trees follow the nested bracketing format, as 
defined in the Penn Treebank. Also, the NiuTrans package 
includes a tool for tree binarization. 
BLEU4[%] Entry 
Dev Test 
Speed
(sent/sec)
Moses: phrase  36.69  34.99    0.11
+ cube pruning   36.51  34.93    0.47
NiuTrans: phrase  37.14  35.47    0.14
+ cube pruning  36.98  35.39    0.60
+ cube & punct pruning  36.99  35.29    3.71
+ all pruning & 8 threads  36.99  35.29  21.89
+ all pruning & 16 threads  36.99  35.29  22.36
Table 2: Effects of pruning and multithreading 
techniques. 
 
promising results. For example, the string-to-tree 
system significantly outperforms the phrase-based 
and hierarchical phrase-based counterparts. In 
addition, Table 1 gives a test of different decoding 
methods (for syntax-based systems). We see that 
the parsing-based method achieves the best BLEU 
score. On the other hand, as expected, it runs 
slowest due to its large search space. For example, 
it is 5-8 times slower than the tree-parsing-based 
method in our experiments. The forest-based 
decoding further improves the BLEU scores on top 
of tree-parsing. In most cases, it obtains a +0.6 
BLEU improvement but is 2-3 times slower than 
the tree-parsing-based method. 
5.3 System Speed-up 
We also study the effectiveness of pruning and 
multithreading techniques. Table 2 shows that all 
the pruning methods implemented in the toolkit is 
helpful in speeding up the (phrase-based) system, 
while does not result in significant decrease in 
BLEU score. On top of a straightforward baseline 
(only beam pruning is used), cube pruning and 
pruning with punctuations give a speed 
improvement of 25 times together7. Moreover, the 
decoding process can be further accelerated by 
using multithreading technique. However, more 
than 8 threads do not help in our experiments. 
6 Conclusion and Future Work 
We have presented a new open-source toolkit for 
phrase-based and syntax-based machine translation. 
It is implemented in C++ and runs fast. Moreover, 
it supports several state-of-the-art models ranging 
from phrase-based models to syntax-based models, 
                                                          
7 The translation speed is tested on Intel Core Due 2 E8500 
processors running at 3.16 GHz. 
23
and provides a wide choice of decoding methods. 
The experimental results on NIST MT tasks show 
that the MT systems built with our toolkit achieve 
state-of-the-art translation performance. 
The next version of NiuTrans will support 
ARPA-format LMs, MIRA for weight tuning and a 
beam-stack decoder which removes the ITG 
constraint for phrase decoding. In addition, a 
Hadoop-based MapReduce-parallelized version is 
underway and will be released in near future.  
Acknowledgments  
This research was supported in part by the National 
Science Foundation of China (61073140), the 
Specialized Research Fund for the Doctoral 
Program of Higher Education (20100042110031) 
and the Fundamental Research Funds for the 
Central Universities in China. 
References  
Daniel Cer, Michel Galley, Daniel Jurafsky and 
Christopher D. Manning. 2010. Phrasal: A Toolkit 
for Statistical Machine Translation with Facilities for 
Extraction and Incorporation of Arbitrary Model 
Features. In Proc. of HLT/NAACL 2010 
demonstration Session, pages 9-12. 
David Chiang. 2007. Hierarchical phrase-based 
translation. Computational Linguistics, 33(2):201?
228. 
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan 
Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, 
Vladimir Eidelman, Philip Resnik. 2010. cdec: A 
Decoder, Alignment, and Learning Framework for 
Finite-State and Context-Free Translation Models. In 
Proc. of ACL 2010 System Demonstrations, pages 7-
12. 
Jason Eisner. 2003. Learning non-isomorphic tree 
mappings for machine translation. In Proc. of ACL 
2003, pages 205-208. 
Michel Galley, Mark Hopkins, Kevin Knight and Daniel 
Marcu. 2004. What's in a translation rule? In Proc. of 
HLT-NAACL 2004, pages 273-280. 
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel 
Marcu, Steve DeNeefe, Wei Wang and Ignacio 
Thayer. 2006. Scalable inferences and training of 
context-rich syntax translation models. In Proc. of 
COLING/ACL 2006, pages 961-968. 
Michel Galley and Christopher D. Manning. 2008. A 
Simple and Effective Hierarchical Phrase Reordering 
Model. In Proc. of EMNLP2008, pages 848-856. 
Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita and 
Benjamin K. Tsou. 2011. Overview of the Patent 
Machine Translation Task at the NTCIR-9 Workshop. 
In Proc. of NTCIR-9 Workshop Meeting, pages 559-
578. 
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. 
Statistical phrase-based translation. In Proc. of 
HLT/NAACL 2003, pages 127-133. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. In 
Proc. of ACL 2007, pages 177?180. 
Zhifei Li, Chris Callison-Burch, Chris Dyer, Sanjeev 
Khudanpur, Lane Schwartz, Wren Thornton, 
Jonathan Weese, and Omar Zaidan. 2009. Joshua: An 
Open Source Toolkit for Parsing-Based Machine 
Translation. In Proc. of the Workshop on Statistical 
Machine Translation, pages 135?139. 
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine 
Translation. In Proc. of ACL 2006, pages 609-616. 
Haitao Mi, Liang Huang and Qun Liu. 2008. Forest-
Based Translation. In Proc. of ACL 2008, pages 192-
199. 
Franz Josef Och. 2003. Minimum error rate training in 
statistical machine translation. In Proc. of ACL 2003, 
pages 160-167. 
Adam Pauls and Dan Klein. 2011. Faster and Smaller 
N-Gram Language Models. In Proc. of ACL 2011, 
pages 258?267. 
David Vilar, Daniel Stein, Matthias Huck and Hermann 
Ney. 2010. Jane: Open Source Hierarchical 
Translation, Extended with Reordering and Lexicon 
Models. In Proc. of the Joint 5th Workshop on 
Statistical Machine Translation and MetricsMATR, 
pages 262-270. 
Dekai Wu. 1996. A polynomial-time algorithm for 
statistical machine translation. In Proc. of ACL1996, 
pages 152?158. 
Deyi Xiong, Qun Liu and Shouxun Lin. 2006. 
Maximum Entropy Based Phrase Reordering Model 
for Statistical Machine Translation. In Proc. of ACL 
2006, pages 521-528. 
Andreas Zollmann and Ashish Venugopal. 2006. Syntax 
Augmented Machine Translation via Chart Parsing. 
In Proc. of HLT/NAACL 2006, pages 138-141. 
24
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 110?114,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Easy-First POS Tagging and Dependency Parsing with Beam Search 
Ji Ma?   JingboZhu?  Tong Xiao?   Nan Yang? 
?Natrual Language Processing Lab., Northeastern University, Shenyang, China 
?MOE-MS Key Lab of MCC, University of Science and Technology of China, 
Hefei, China 
majineu@outlook.com 
{zhujingbo, xiaotong}@mail.neu.edu.cn 
nyang.ustc@gmail.com 
 
Abstract 
In this paper, we combine easy-first de-
pendency parsing and POS tagging algo-
rithms with beam search and structured 
perceptron. We propose a simple variant 
of ?early-update? to ensure valid update 
in the training process. The proposed so-
lution can also be applied to combine 
beam search and structured perceptron 
with other systems that exhibit spurious 
ambiguity. On CTB, we achieve 94.01% 
tagging accuracy and 86.33% unlabeled 
attachment score with a relatively small 
beam width. On PTB, we also achieve 
state-of-the-art performance. 
1 Introduction 
The easy-first dependency parsing algorithm 
(Goldberg and Elhadad, 2010) is attractive due to 
its good accuracy, fast speed and simplicity. The 
easy-first parser has been applied to many appli-
cations (Seeker et al, 2012; S?ggard and Wulff, 
2012). By processing the input tokens in an easy-
to-hard order, the algorithm could make use of 
structured information on both sides of the hard 
token thus making more indicative predictions. 
However, rich structured information also causes 
exhaustive inference intractable. As an alterna-
tive, greedy search which only explores a tiny 
fraction of the search space is adopted (Goldberg 
and Elhadad, 2010). 
 To enlarge the search space, a natural exten-
sion to greedy search is beam search. Recent 
work also shows that beam search together with 
perceptron-based global learning (Collins, 2002) 
enable the use of non-local features that are help-
ful to improve parsing performance without 
overfitting (Zhang and Nivre, 2012). Due to the-
se advantages, beam search and global learning 
has been applied to many NLP tasks (Collins and 
Roark 2004; Zhang and Clark, 2007). However, 
to the best of our knowledge, no work in the lit-
erature has ever applied the two techniques to 
easy-first dependency parsing.  
While applying beam-search is relatively 
straightforward, the main difficulty comes from 
combining easy-first dependency parsing with 
perceptron-based global learning. In particular, 
one needs to guarantee that each parameter up-
date is valid, i.e., the correct action sequence has 
lower model score than the predicted one1. The 
difficulty in ensuring validity of parameter up-
date for the easy-first algorithm is caused by its 
spurious ambiguity, i.e., the same result might be 
derived by more than one action sequences.  
For algorithms which do not exhibit spurious 
ambiguity, ?early update? (Collins and Roark 
2004) is always valid: at the k-th step when the 
single correct action sequence falls off the beam, 
                                                 
1 As shown by (Huang et al, 2012), only valid update guar-
antees the convergence of any perceptron-based training. 
Invalid update may lead to bad learning or even make the 
learning not converge at all. 
Figure 1: Example of cases without/with spurious 
ambiguity. The 3 ? 1 table denotes a beam. ?C/P? 
denotes correct/predicted action sequence. The 
numbers following C/P are model scores. 
 
110
its model score must be lower than those still in 
the beam (as illustrated in figure 1, also see the 
proof in (Huang et al, 2012)). While for easy-
first dependency parsing, there could be multiple 
action sequences that yield the gold result (C1 and 
C2 in figure 1). When all correct sequences fall 
off the beam, some may indeed have higher 
model score than those still in the beam (C2 in 
figure 1), causing invalid update. 
For the purpose of valid update, we present a 
simple solution which is based on early update. 
The basic idea is to use one of the correct action 
sequences that were pruned right at the k-th step 
(C1 in figure 1) for parameter update.  
The proposed solution is general and can also 
be applied to other algorithms that exhibit spuri-
ous ambiguity, such as easy-first POS tagging 
(Ma et al, 2012) and transition-based dependen-
cy parsing with dynamic oracle (Goldberg and 
Nivre, 2012). In this paper, we report experi-
mental results on both easy-first dependency 
parsing and POS tagging (Ma et al, 2012). We 
show that both easy-first POS tagging and de-
pendency parsing can be improved significantly 
from beam search and global learning. Specifi-
cally, on CTB we achieve 94.01% tagging accu-
racy which is the best result to date2 for a single 
tagging model. With a relatively small beam, we 
achieve 86.33% unlabeled score (assume gold 
tags), better than state-of-the-art transition-based 
parsers (Huang and Sagae, 2010; Zhang and 
Nivre, 2011). On PTB, we also achieve good 
results that are comparable to the state-of-the-art. 
2 Easy-first dependency parsing 
The easy-first dependency parsing algorithm 
(Goldberg and Elhadad, 2010) builds a depend-
ency tree by performing two types of actions 
LEFT(i) and RIGHT(i) to a list of sub-tree struc-
tures p1,?, pr. pi is initialized with the i-th word  
                                                 
2 Joint tagging-parsing models achieve higher accuracy, but 
those models are not directly comparable to ours.  
Algorithm 1: Easy-first with beam search 
Input:     sentence   of n words,  beam width s 
Output:  one best dependency tree 
     (     )        
         ( )   
    (  ) 
            // top s extensions from the beam 
1                     // initially, empty beam 
2 for    1   1 do 
3             (        ) 
4 return        ( )   // tree built by the best sequence  
 
of the input sentence. Action LEFT(i)/RIGHT(i) 
attaches pi to its left/right neighbor and then re-
moves pi from the sub-tree list. The algorithm 
proceeds until only one sub-tree left which is the 
dependency tree of the input sentence (see the 
example in figure 2). Each step, the algorithm 
chooses the highest score action to perform ac-
cording to the linear model: 
     ( )     ( ) 
Here,  is the weight vector and  is the feature 
representation. In particular,  (    ( ) 
     ( )) denotes features extracted from pi. 
The parsing algorithm is greedy which ex-
plores a tiny fraction of the search space. Once 
an incorrect action is selected, it can never yield 
the correct dependency tree. To enlarge the 
search space, we introduce the beam-search ex-
tension in the next section. 
3 Easy-first with beam search  
In this section, we introduce easy-first with beam 
search in our own notations that will be used 
throughout the rest of this paper.  
For a sentence x of n words, let   be the action 
(sub-)sequence that can be applied, in sequence, 
to x and the result sub-tree list is denoted by 
 ( )  For example, suppose x is ?I am valid? and 
y is [RIGHT(1)], then y(x) yields figure 2(b). Let 
   to be LEFT(i)/RIGHT(i) actions where    1   . 
Thus, the set of all possible one-action extension 
of   is: 
     ( )            ( )   
Here, ? ? means insert   to the end of  . Follow-
ing (Huang et al, 2012), in order to formalize 
beam search, we also use the          
    ( ) 
operation which returns the top s action sequenc-
es in   according to   ( ). Here,  denotes a 
set of action sequences,   ( ) denotes the sum of 
feature vectors of each action in    
Pseudo-code of easy-first with beam search is 
shown in algorithm 1. Beam search grows s 
(beam width) action sequences in parallel using a  
Figure 2: An example of parsing ?I am valid?. Spu-
rious ambiguity: (d) can be derived by both 
[RIGHT(1), LEFT(2)] and [LEFT(3), RIGHT(1)]. 
111
Algorithm 2: Perceptron-based training over one 
training sample (   ) 
Input:    (   ), s, parameter   
Output: new parameter    
    (       )        
     (      ( ))   
   (  ) 
 // top correct extension from the beam 
1         
2 for    1   1 do 
3     ?      (          ) 
4            (        ) 
5    if           // all correct seq. falls off the beam 
6             ( ?)   (     ) 
7         break 
8 if        ( )      // full update 
9         ( ?)   (       )  
10 return  
 
beam  , (sequences in   are sorted in terms of 
model score, i.e.,   (    )     (  1 ) ). 
At each step, the sequences in   are expanded in 
all possible ways and then   is filled up with the 
top s newly expanded sequences (line 2 ~ line 3). 
Finally, it returns the dependency tree built by 
the top action sequence in      . 
4 Training  
To learn the weight vector , we use the percep-
tron-based global learning3 (Collins, 2002) which 
updates  by rewarding the feature weights fired 
in the correct action sequence and punish those 
fired in the predicted incorrect action sequence. 
Current work (Huang et al, 2012) rigorously 
explained that only valid update ensures conver-
gence of any perceptron variants. They also justi-
fied that the popular ?early update? (Collins and  
Roark, 2004) is valid for the systems that do not 
exhibit spurious ambiguity4.  
However, for the easy-first algorithm or more 
generally, systems that exhibit spurious ambigui-
ty, even ?early update? could fail to ensure valid-
ity of update (see the example in figure 1). For 
validity of update, we propose a simple solution 
which is based on ?early update? and which can 
accommodate spurious ambiguity. The basic idea 
is to use the correct action sequence which was  
                                                 
3 Following (Zhang and Nivre, 2012), we say the training 
algorithm is global if it optimizes the score of an entire ac-
tion sequence. A local learner trains a classifier which dis-
tinguishes between single actions. 
4 As shown in (Goldberg and Nivre 2012), most transition-
based dependency parsers (Nivre et al, 2003; Huang and 
Sagae 2010;Zhang and Clark 2008) ignores spurious ambi-
guity by using a static oracle which maps a dependency tree 
to a single action sequence.  
Features of (Goldberg and Elhadad, 2010) 
for p in pi-1, pi, pi+1 wp-vlp, wp-vrp, tp-vlp,  
tp-vrp, tlcp, trcp, wlcp, wlcp 
for p in pi-2, pi-1, pi, pi+1, pi+2 tp-tlcp,  tp-trcp, tp-tlcp-trcp 
for p, q, r in (pi-2, pi-1, pi), (pi-
1, pi+1, pi), (pi+1, pi+2 ,pi) 
tp-tq-tr, tp-tq-wr 
for p, q in (pi-1, pi) tp-tlcp-tq,   tp-trcp-tq,   ,tp-tlcp-wq,, 
 tp-trcp-wq,   tp-wq-tlcq,  tp-wq-trcq 
 
Table 1: Feature templates for English dependency 
parsing. wp denotes the head word of p, tp denotes the 
POS tag of wp. vlp/vrp denotes the number p?s of 
left/right child. lcp/rcp denotes p?s leftmost/rightmost 
child. pi denotes partial tree being considered. 
 
pruned right at the step when all correct sequence 
falls off the beam (as C1 in figure 1).  
Algorithm 2 shows the pseudo-code of the 
training procedure over one training sample 
(   ), a sentence-tree pair. Here we assume   to 
be the set of all correct action sequences/sub-
sequences. At step k, the algorithm constructs a 
correct action sequence  ? of length k by extend-
ing those in      (line 3). It also checks whether 
   no longer contains any correct sequence. If so, 
 ? together with       are used for parameter up-
date (line 5 ~ line 6). It can be easily verified that 
each update in line 6 is valid. Note that both 
?TOPC? and the operation in line 5 use   to check 
whether an action sequence y is correct or not. 
This  can  be  efficiently  implemented   (without 
explicitly enumerating  ) by checking if each 
LEFT(i)/RIGHT(i) in y are compatible with (   ): 
pi already collected all its dependents according 
to t; pi is attached to the correct neighbor sug-
gested by t.  
5 Experiments 
For English, we use PTB as our data set. We use 
the standard split for dependency parsing and the 
split used by (Ratnaparkhi, 1996) for POS tag-
ging. Penn2Malt5 is used to convert the bracket-
ed structure into dependencies. For dependency 
parsing, POS tags of the training set are generat-
ed using 10-fold jack-knifing.  
For Chinese, we use CTB 5.1 and the split 
suggested by (Duan et al, 2007) for both tagging 
and dependency parsing. We also use Penn2Malt 
and the head-finding rules of (Zhang and Clark 
2008) to convert constituency trees into depend-
encies. For dependency parsing, we assume gold 
segmentation and POS tags for the input.  
                                                 
5 http://w3.msi.vxu.se/~nivre/research/Penn2Malt.html 
112
Features used in English dependency parsing 
are listed in table 1. Besides the features in 
(Goldberg and Elhadad, 2010), we also include 
some trigram features and valency features 
which are useful for transition-based dependency 
parsing (Zhang and Nivre, 2011). For English 
POS tagging, we use the same features as in 
(Shen et al, 2007). For Chinese POS tagging and 
dependency parsing, we use the same features as 
(Ma et al, 2012). All of our experiments are 
conducted on a Core i7 (2.93GHz) machine, both 
the tagger and parser are implemented using C++.  
5.1 Effect of beam width 
Tagging/parsing performances with different 
beam widths on the development set are listed in 
table 2 and table 3. We can see that Chinese POS  
tagging, dependency parsing as well as English 
dependency parsing greatly benefit from beam 
search. While tagging accuracy on English only 
slightly improved. This may because that the 
accuracy of the greedy baseline tagger is already 
very high and it is hard to get further improve-
ment. Table 2 and table 3 also show that the 
speed of both tagging and dependency parsing 
drops linearly with the growth of beam width. 
5.2 Final results 
Tagging results on the test set together with some 
previous results are listed in table 4. Dependency 
parsing results on CTB and PTB are listed in ta-
ble 5 and table 6, respectively. 
On CTB, tagging accuracy of our greedy base-
line is already comparable to the state-of-the-art. 
As the beam size grows to 5, tagging accuracy 
increases to 94.01% which is 2.3% error reduc-
tion. This is also the best tagging accuracy com-
paring with previous single tagging models (For 
limited space, we do not list the performance of 
joint tagging-parsing models).  
Parsing performances on both PTB and CTB 
are significantly improved with a relatively small 
beam width (s = 8). In particular, we achieve 
86.33% uas on CTB which is 1.54% uas im-
provement over the greedy baseline parser. 
Moreover, the performance is better than the best 
transition-based parser (Zhang and Nivre, 2011) 
which adopts a much larger beam width (s = 64).  
6 Conclusion and related work 
This work directly extends (Goldberg and El-
hadad, 2010) with beam search and global learn-
ing. We show that both the easy-first POS tagger 
and dependency parser can be significantly impr- 
s PTB CTB speed  
1 97.17 93.91 1350 
3 97.20 94.15 560 
5 97.22 94.17 385 
 
Table 2: Tagging accuracy vs beam width vs. Speed is 
evaluated using the number of sentences that can be 
processed in one second 
 
s 
PTB CTB 
speed 
uas compl uas compl 
1 91.77 45.29 84.54 33.75 221 
2 92.29 46.28 85.11 34.62 124 
4 92.50 46.82 85.62 37.11 71 
8 92.74 48.12 86.00 35.87 39 
 
Table 3: Parsing accuracy vs beam width. ?uas? and 
?compl? denote unlabeled score and complete match 
rate respectively (all excluding punctuations). 
 
PTB CTB 
(Collins, 2002) 97.11 (Hatori et al, 2012) 93.82 
(Shen et al, 2007) 97.33 (Li et al, 2012) 93.88 
(Huang et al, 2012) 97.35 (Ma et al, 2012) 93.84 
this work   1 97.22 this work   1 93.87 
this work     97.28 this work     94.01? 
 
Table 4: Tagging results on the test set. ??? denotes 
statistically significant over the greedy baseline by 
McNemar?s test (      ) 
 
Systems s uas compl 
(Huang and Sagae, 2010) 8 85.20 33.72 
(Zhang and Nivre, 2011) 64 86.00 36.90 
(Li et al, 2012) ? 86.55 ? 
this work 1 84.79 32.98 
this work 8 86.33
?
 36.13 
 
Table 5: Parsing results on CTB test set. 
  
Systems s uas compl 
(Huang and Sagae, 2010) 8 92.10 ? 
(Zhang and Nivre, 2011) 64 92.90 48.50 
(Koo and Collins, 2010) ? 93.04 ? 
this work 1 91.72 44.04 
this work 8 92.47
?
 46.07 
 
Table 6: Parsing results on PTB test set.  
 
oved using beam search and global learning. 
This work can also be considered as applying 
(Huang et al, 2012) to the systems that exhibit 
spurious ambiguity. One future direction might 
be to apply the training method to transition-
based parsers with dynamic oracle (Goldberg and 
Nivre, 2012) and potentially further advance per-
formances of state-of-the-art transition-based 
parsers. 
113
Shen et al, (2007) and (Shen and Joshi, 2008) 
also proposed bi-directional sequential classifica-
tion with beam search for POS tagging and 
LTAG dependency parsing, respectively. The 
main difference is that their training method aims 
to learn a classifier which distinguishes between 
each local action while our training method aims 
to distinguish between action sequences. Our 
method can also be applied to their framework. 
Acknowledgments 
We would like to thank Yue Zhang, Yoav Gold-
berg and Zhenghua Li for discussions and sug-
gestions on earlier drift of this paper. We would 
also like to thank the three anonymous reviewers 
for their suggestions. This work was supported in 
part by the National Science Foundation of Chi-
na (61073140; 61272376), Specialized Research 
Fund for the Doctoral Program of Higher Educa-
tion (20100042110031) and the Fundamental 
Research Funds for the Central Universities 
(N100204002). 
References  
Collins, M. 2002. Discriminative training methods for 
hidden markov models: Theory and experiments 
with perceptron algorithms. In Proceedings of 
EMNLP. 
Duan, X., Zhao, J., , and Xu, B. 2007. Probabilistic 
models for action-based Chinese dependency pars-
ing. In Proceedings of ECML/ECPPKDD. 
Goldberg, Y. and Elhadad, M. 2010 An Efficient Al-
gorithm for Eash-First Non-Directional Dependen-
cy Parsing. In Proceedings of NAACL 
Huang, L. and Sagae, K. 2010. Dynamic program-
ming for linear-time incremental parsing. In Pro-
ceedings of ACL. 
Huang, L. Fayong, S. and Guo, Y. 2012. Structured 
Perceptron with Inexact Search. In Proceedings of 
NAACL. 
Koo, T. and Collins, M. 2010. Efficient third-order 
dependency parsers. In Proceedings of ACL. 
Li, Z., Zhang, M., Che, W., Liu, T. and Chen, W. 
2012. A Separately Passive-Aggressive Training 
Algorithm for Joint POS Tagging and Dependency 
Parsing. In Proceedings of COLING 
Ma, J., Xiao, T., Zhu, J. and Ren, F. 2012. Easy-First 
Chinese POS Tagging and Dependency Parsing. In 
Proceedings of COLING 
Rataparkhi, A. (1996) A Maximum Entropy Part-Of-
Speech Tagger. In Proceedings of EMNLP 
Shen, L., Satt, G. and Joshi, A. K. (2007) Guided 
Learning for Bidirectional Sequence Classification. 
In Proceedings of ACL. 
Shen, L. and  Josh, A. K. 2008. LTAG Dependency 
Parsing with Bidirectional Incremental Construc-
tion. In Proceedings of  EMNLP. 
Seeker, W., Farkas, R. and Bohnet, B. 2012 Data-
driven Dependency Parsing With Empty Heads. In 
Proceedings of COLING 
S?ggard, A. and Wulff, J. 2012. An Empirical Study 
of Non-lexical Extensions to Delexicalized Trans-
fer. In Proceedings of COLING 
Yue Zhang and Stephen Clark. 2007 Chinese Seg-
mentation Using a Word-based Perceptron Algo-
rithm. In Proceedings of ACL.  
Zhang, Y. and Clark, S. 2008. Joint word segmenta-
tion and POS tagging using a single perceptron. In 
Proceedings of ACL. 
Zhang, Y. and Nivre, J. 2011. Transition-based de-
pendency parsing with rich non-local features. In 
Proceedings of ACL. 
Zhang, Y. and Nivre, J. 2012. Analyzing the Effect of 
Global Learning and Beam-Search for Transition-
Based Dependency Parsing. In Proceedings of 
COLING. 
114
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 563?568,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
A Hybrid Approach to Skeleton-based Translation
Tong Xiao??, Jingbo Zhu??, Chunliang Zhang??
? Northeastern University, Shenyang 110819, China
? Hangzhou YaTuo Company, 358 Wener Rd., Hangzhou 310012, China
{xiaotong,zhujingbo,zhangcl}@mail.neu.edu.cn
Abstract
In this paper we explicitly consider sen-
tence skeleton information for Machine
Translation (MT). The basic idea is that
we translate the key elements of the input
sentence using a skeleton translation mod-
el, and then cover the remain segments us-
ing a full translation model. We apply our
approach to a state-of-the-art phrase-based
system and demonstrate very promising
BLEU improvements and TER reductions
on the NIST Chinese-English MT evalua-
tion data.
1 Introduction
Current Statistical Machine Translation (SMT) ap-
proaches model the translation problem as a pro-
cess of generating a derivation of atomic transla-
tion units, assuming that every unit is drawn out
of the same model. The simplest of these is the
phrase-based approach (Och et al, 1999; Koehn
et al, 2003) which employs a global model to
process any sub-strings of the input sentence. In
this way, all we need is to increasingly translate
a sequence of source words each time until the
entire sentence is covered. Despite good result-
s in many tasks, such a method ignores the roles
of each source word and is somewhat differen-
t from the way used by translators. For exam-
ple, an important-first strategy is generally adopt-
ed in human translation - we translate the key ele-
ments/structures (or skeleton) of the sentence first,
and then translate the remaining parts. This es-
pecially makes sense for some languages, such as
Chinese, where complex structures are usually in-
volved.
Note that the source-language structural infor-
mation has been intensively investigated in recent
studies of syntactic translation models. Some of
them developed syntax-based models on complete
syntactic trees with Treebank annotations (Liu et
al., 2006; Huang et al, 2006; Zhang et al, 2008),
and others used source-language syntax as soft
constraints (Marton and Resnik, 2008; Chiang,
2010). However, these approaches suffer from
the same problem as the phrase-based counterpart
and use the single global model to handle differ-
ent translation units, no matter they are from the
skeleton of the input tree/sentence or other not-so-
important sub-structures.
In this paper we instead explicitly model the
translation problem with sentence skeleton infor-
mation. In particular,
? We develop a skeleton-based model which
divides translation into two sub-models: a
skeleton translation model (i.e., translating
the key elements) and a full translation model
(i.e., translating the remaining source words
and generating the complete translation).
? We develop a skeletal language model to de-
scribe the possibility of translation skeleton
and handle some of the long-distance word
dependencies.
? We apply the proposed model to Chinese-
English phrase-based MT and demonstrate
promising BLEU improvements and TER re-
ductions on the NIST evaluation data.
2 A Skeleton-based Approach to MT
2.1 Skeleton Identification
The first issue that arises is how to identify the
skeleton for a given source sentence. Many ways
are available. E.g., we can start with a full syntac-
tic tree and transform it into a simpler form (e.g.,
removing a sub-tree). Here we choose a simple
and straightforward method: a skeleton is obtained
by dropping all unimportant words in the origi-
nal sentence, while preserving the grammaticali-
ty. See the following for an example skeleton of a
Chinese sentence.
563
Original Sentence (subscripts represent indices):
z
[1]
per
?
[2]
ton
?Yz
[3]
seawater desalination
?n
[4]
treatment

[5]
of
?
[6]
the cost
3
[7]
5
[8]
5

[9]
yuan

[10]
of
?:
[11]
from
?
[12]
???
[13]
has been further
e?
[14]
reduced
"
[15]
.
(The cost of seawater desalination treatment has
been further reduced from 5 yuan per ton.)
Sentence Skeleton (subscripts represent indices):
?
[6]
the cost
???
[13]
has been further
e?
[14]
reduced
"
[15]
.
(The cost has been further reduced.)
Obviously the skeleton used in this work can be
viewed as a simplified sentence. Thus the prob-
lem is in principle the same as sentence simpli-
fication/compression. The motivations of defin-
ing the problem in this way are two-fold. First,
as the skeleton is a well-formed (but simple) sen-
tence, all current MT approaches are applicable
to the skeleton translation problem. Second, ob-
taining simplified sentences by word deletion is
a well-studied issue (Knight and Marcu, 2000;
Clarke and Lapata, 2006; Galley and McKeown,
2007; Cohn and Lapata, 2008; Yamangil and
Shieber, 2010; Yoshikawa et al, 2012). Many
good sentence simpliciation/compression methods
are available to our work. Due to the lack of space,
we do not go deep into this problem. In Section
3.1 we describe the corpus and system employed
for automatic generation of sentence skeletons.
2.2 Base Model
Next we describe our approach to integrating
skeleton information into MT models. We start
with an assumption that the 1-best skeleton is pro-
vided by the skeleton identification system. Then
we define skeleton-based translation as a task of
searching for the best target string
?
t given the
source string and its skeleton ? :
?
t = argmax
t
P(t|?, s) (1)
As is standard in SMT, we further assume that
1) the translation process can be decomposed in-
to a derivation of phrase-pairs (for phrase-based
models) or translation rules (for syntax-based
models); 2) and a linear function g(?) is used to
assign a model score to each derivation. Let d
s,?,t
(or d for short) denote a translation derivation. The
above problem can be redefined in a Viterbi fash-
ion - we find the derivation
?
dwith the highest mod-
el score given s and ? :
?
d = argmax
d
g(d) (2)
In this way, the MT output can be regarded as the
target-string encoded in
?
d.
To compute g(d), we use a linear combination
of a skeleton translation model g
skel
(d) and a full
translation model g
full
(d):
g(d) = g
skel
(d) + g
full
(d) (3)
where the skeleton translation model handles the
translation of the sentence skeleton, while the full
translation model is the baseline model and han-
dles the original problem of translating the whole
sentence. The motivation here is straightforward:
we use an additional score g
skel
(d) to model the
problem of skeleton translation and interpolate it
with the baseline model. See Figure 1 for an exam-
ple of applying the above model to phrase-based
MT. In the figure, each source phrase is translated
into a target phrase, which is represented by linked
rectangles. The skeleton translation model focus-
es on the translation of the sentence skeleton, i.e.,
the solid (red) rectangles; while the full transla-
tion model computes the model score for all those
phrase-pairs, i.e., all solid and dashed rectangles.
Another note on the model. Eq. (3) provides a
very flexible way for model selection. While we
will restrict ourself to phrase-based translation in
the following description and experiments, we can
choose different models/features for g
skel
(d) and
g
full
(d). E.g., one may introduce syntactic fea-
tures into g
skel
(d) due to their good ability in cap-
turing structural information; and employ a stan-
dard phrase-based model for g
full
(d) in which not
all segments of the sentence need to respect syn-
tactic constraints.
2.3 Model Score Computation
In this work both the skeleton translation model
g
skel
(d) and full translation model g
full
(d) resem-
ble the usual forms used in phrase-based MT, i.e.,
the model score is computed by a linear combina-
tion of a group of phrase-based features and lan-
guage models. In phrase-based MT, the transla-
tion problem is modeled by a derivation of phrase-
pairs. Given a translation model m, a language
model lm and a vector of feature weights w, the
model score of a derivation d is computed by
564
z? ?Yz ?n  ? 3 5   ?: ? ??? e? "
the cost
p
h
r
a
s
e
1
p
1
Skeleton:
Full:
g(d
?
;w
?
,m, lm
?
) = w
?
m
? f
m
(p
1
) + w
?
lm
? lm
?
(?the cost?)
g(d;w,m, lm) = w
m
? f
m
(p
1
) + w
lm
? lm(?the cost?)
z? ?Yz ?n  ? 3 5   ?: ? ??? e? "
the cost of seawater desalination treatment
p
h
r
a
s
e
s
2
&
3
p
1
p
2
p
3
Skeleton:
Full:
g(d
?
;w
?
,m, lm
?
) = w
?
m
? f
m
(p
1
) + w
?
lm
? lm
?
(?the cost X?)
g(d;w,m, lm) = w
m
? f
m
(p
1
? p
2
? p
3
) + w
lm
? lm(?the cost of seawater desalination treatment?)
z? ?Yz ?n  ? 3 5   ?: ? ??? e? "
the cost of seawater desalination treatment has been further reduced
p
h
r
a
s
e
s
4
&
5
p
1
p
2
p
3
p
4
p
5
Skeleton:
Full:
g(d
?
;w
?
,m, lm
?
) = w
?
m
? f
m
(p
1
? p
4
? p
5
)+
w
?
lm
? lm
?
(?the cost X has been further reduced?)
g(d;w,m, lm) = w
m
? f
m
(p
1
? p
2
? ... ? p
5
) + w
lm
? lm(?the cost of seawater ... further reduced?)
z? ?Yz ?n  ? 3 5   ?: ? ??? e? "
the cost of seawater desalination treatment has been further reduced from
5 yuan
per ton
.
p
h
r
a
s
e
s
6
-
9
p
1
p
2
p
3
p
4
p
5
p
6
p
7
p
8
p
9
Skeleton:
Full:
g(d
?
;w
?
,m, lm
?
) = w
?
m
? f
m
(p
1
? p
4
? p
5
? p
9
)+
w
?
lm
? lm
?
(?the cost X has been further reduced X .?)
g(d;w,m, lm) = w
m
? f
m
(p
1
? p
2
? ... ? p
9
) + w
lm
? lm(?the cost of seawater ... per ton .?)
Figure 1: Example derivation and model scores for a sentence in LDC2006E38. The solid (red) rect-
angles represent the sentence skeleton, and the dashed (blue) rectangles represent the non-skeleton seg-
ments. X represents a slot in the translation skeleton. ? represents composition of phrase-pairs.
g(d;w,m, lm) = w
m
? f
m
(d)+w
lm
? lm(d) (4)
where f
m
(d) is a vector of feature values defined
on d, and w
m
is the corresponding weight vector.
lm(d) andw
lm
are the score and weight of the lan-
guage model, respectively.
To ease modeling, we only consider skeleton-
consistent derivations in this work. A deriva-
tion d is skeleton-consistent if no phrases in d
cross skeleton boundaries (e.g., a phrase where t-
wo of the source words are in the skeleton and
one is outside). Obviously, from any skeleton-
consistent derivation d we can extract a skeleton
derivation d
?
which covers the sentence skeleton
exactly. For example, in Figure 1, the deriva-
tion of phrase-pairs {p
1
, p
2
, ..., p
9
} is skeleton-
consistent, and the skeleton derivation is formed
by {p
1
, p
4
, p
5
, p
9
}.
Then, we can simply define g
skel
(d) and
g
full
(d) as the model scores of d
?
and d:
g
skel
(d) , g(d
?
;w
?
,m, lm
?
) (5)
g
full
(d) , g(d;w,m, lm) (6)
This model makes the skeleton translation and
full translation much simpler because they per-
form in the same way of string translation in
phrase-based MT. Both g
skel
(d) and g
full
(d) share
the same translation model m which can easily
learned from the bilingual data
1
. On the other
hand, it has different feature weight vectors for in-
dividual models (i.e., w and w
?
).
For language modeling, lm is the standard n-
gram language model adopted in the baseline sys-
tem. lm
?
is a skeletal language for estimating the
well-formedness of the translation skeleton. Here
a translation skeleton is a target string where all
segments of non-skeleton translation are general-
ized to a symbol X. E.g., in Figure 1, the trans-
1
In g
skel
(d), we compute the reordering model score on
the skeleton though it is learned from the full sentences. In
this way the reordering problems in skeleton translation and
full translation are distinguished and handled separately.
565
lation skeleton is ?the cost X has been further re-
duced X .?, where two Xs represent non-skeleton
segments in the translation. In such a way of string
representation, the skeletal language model can be
implemented as a standard n-gram language mod-
el, that is, a string probability is calculated by a
product of a sequence of n-gram probabilities (in-
volving normal words and X). To learn the skele-
tal language model, we replace non-skeleton parts
of the target sentences in the bilingual corpus to
Xs using the source sentence skeletons and word
alignments. The skeletal language model is then
trained on these generalized strings in a standard
way of n-gram language modeling.
By substituting Eq. (4) into Eqs. (5) and (6),
and then Eqs. (3) and (2), we have the final model
used in this work:
?
d = argmax
d
(
w
m
? f
m
(d) + w
lm
? lm(d) +
w
?
m
? f
m
(d
?
) + w
?
lm
? lm
?
(d
?
)
)
(7)
Figure 1 shows the translation process and as-
sociated model scores for the example sentence.
Note that this method does not require any new
translation models for implementation. Given a
baseline phrase-based system, all we need is to
learn the feature weights w and w
?
on the devel-
opment set (with source-language skeleton anno-
tation) and the skeletal language model lm
?
on
the target-language side of the bilingual corpus.
To implement Eq. (7), we can perform standard
decoding while ?doubly weighting? the phrases
which cover a skeletal section of the sentence, and
combining the two language models and the trans-
lation model in a linear fashion.
3 Evaluation
3.1 Experimental Setup
We experimented with our approach on Chinese-
English translation using the NiuTrans open-
source MT toolkit (Xiao et al, 2012). Our bilin-
gual corpus consists of 2.7M sentence pairs. Al-
l these sentences were aligned in word level us-
ing the GIZA++ system and the ?grow-diag-final-
and? heuristics. A 5-gram language model was
trained on the Xinhua portion of the English Gi-
gaword corpus in addition to the target-side of the
bilingual data. This language model was used
in both the baseline and our improved system-
s. For our skeletal language model, we trained a
5-gram language model on the target-side of the
bilingual data by generalizing non-skeleton seg-
ments to Xs. We used the newswire portion of the
NIST MT06 evaluation data as our developmen-
t set, and used the evaluation data of MT04 and
MT05 as our test sets. We chose the default fea-
ture set of the NiuTrans.Phrase engine for building
the baseline, including phrase translation proba-
bilities, lexical weights, a 5-gram language mod-
el, word and phrase bonuses, a ME-based lexical-
ized reordering model. All feature weights were
learned using minimum error rate training (Och,
2003).
Our skeleton identification system was built
using the t3 toolkit
2
which implements a state-
of-the-art sentence simplification system. We
used the NEU Chinese sentence simplification
(NEUCSS) corpus as our training data (Zhang
et al, 2013). It contains the annotation of sen-
tence skeleton on the Chinese-language side of
the Penn Parallel Chinese-English Treebank (LD-
C2003E07). We trained our system using the Parts
1-8 of the NEUCSS corpus and obtained a 65.2%
relational F1 score and 63.1% compression rate in
held-out test (Part 10). For comparison, we also
manually annotated the MT development and test
data with skeleton information according to the
annotation standard provided within NEUCSS.
3.2 Results
Table 1 shows the case-insensitive IBM-version
BLEU and TER scores of different systems. We
see, first of all, that the MT system benefits from
our approach in most cases. In both the manual
and automatic identification of sentence skeleton
(rows 2 and 4), there is a significant improvemen-
t on the ?All? data set. However, using different
skeleton identification results for training and in-
ference (row 3) does not show big improvements
due to the data inconsistency problem.
Another interesting question is whether the
skeletal language model really contributes to the
improvements. To investigate it, we removed the
skeletal language model from our skeleton-based
translation system (with automatic skeleton iden-
tification on both the development and test sets).
Seen from row ?lm
?
of Table 1, the removal of
the skeletal language model results in a significan-
t drop in both BLEU and TER performance. It
indicates that this language model is very benefi-
cial to our system. For comparison, we removed
2
http://staffwww.dcs.shef.ac.uk/people/T.Cohn/t3/
566
Entry MT06 (Dev) MT04 MT05 All
system dev-skel test-skel BLEU TER BLEU TER BLEU TER BLEU TER
baseline - - 35.06 60.54 38.53 61.15 34.32 62.82 36.64 61.54
SBMT manual manual 35.71 59.60 38.99 60.67 35.35 61.60 37.30 60.73
SBMT manual auto 35.72 59.62 38.75 61.16 35.02 62.20 37.03 61.19
SBMT auto auto 35.57 59.66 39.21 60.59 35.29 61.89 37.33 60.80
?lm
?
auto auto 35.23 60.17 38.86 60.78 34.82 62.46 36.99 61.16
?m
?
auto auto 35.50 59.69 39.00 60.69 35.10 62.03 37.12 60.90
s-space - - 35.00 60.50 38.39 61.20 34.33 62.90 36.57 61.58
s-feat. - - 35.16 60.50 38.60 61.17 34.25 62.88 36.70 61.58
Table 1: BLEU4[%] and TER[%] scores of different systems. Boldface means a significant improvement
(p < 0.05). SBMT means our skeleton-based MT system. ?lm
?
(or ?m
?
) means that we remove the
skeletal language model (or translation model) from our proposed approach. s-space means that we
restrict the baseline system to the search space of skeleton-consistent derivations. s-feat. means that we
introduce an indicator feature for skeleton-consistent derivations into the baseline system.
the skeleton-based translation model from our sys-
tem as well. Row ?m
?
of Table 1 shows that the
skeleton-based translation model can contribute to
the overall improvement but there is no big differ-
ences between baseline and ?m
?
.
Apart from showing the effects of the skeleton-
based model, we also studied the behavior of the
MT system under the different settings of search
space. Row s-space of Table 1 shows the BLEU
and TER results of restricting the baseline sys-
tem to the space of skeleton-consistent derivation-
s, i.e., we remove both the skeleton-based trans-
lation model and language model from the SBMT
system. We see that the limited search space is a
little harmful to the baseline system. Further, we
regarded skeleton-consistent derivations as an in-
dicator feature and introduced it into the baseline
system. Seen from row s-feat., this feature does
not show promising improvements. These results
indicate that the real improvements are due to the
skeleton-based model/features used in this work,
rather than the ?well-formed? derivations.
4 Related Work
Skeleton is a concept that has been used in several
sub-areas in MT for years. For example, in confu-
sion network-based system combination it refer-
s to the backbone hypothesis for building confu-
sion networks (Rosti et al, 2007; Rosti et al,
2008); Liu et al (2011) regard skeleton as a short-
ened sentence after removing some of the function
words for better word deletion. In contrast, we de-
fine sentence skeleton as the key segments of a
sentence and develop a new MT approach based
on this information.
There are some previous studies on the use of
sentence skeleton or related information in MT
(Mellebeek et al, 2006a; Mellebeek et al, 2006b;
Owczarzak et al, 2006). In spite of their good
ideas of using skeleton skeleton information, they
did not model the skeleton-based translation prob-
lem in modern SMT pipelines. Our work is a fur-
ther step towards the use of sentence skeleton in
MT. More importantly, we develop a complete ap-
proach to this issue and show its effectiveness in a
state-of-the-art MT system.
5 Conclusion and Future Work
We have presented a simple but effective approach
to integrating the sentence skeleton information
into a phrase-based system. The experimental re-
sults show that the proposed approach achieves
very promising BLEU improvements and TER re-
ductions on the NIST evaluation data. In our fu-
ture work we plan to investigate methods of inte-
grating both syntactic models (for skeleton trans-
lation) and phrasal models (for full translation) in
our system. We also plan to study sophisticated
reordering models for skeleton translation, rather
than reusing the baseline reordering model which
is learned on the full sentences.
Acknowledgements
This work was supported in part by the Nation-
al Science Foundation of China (Grants 61272376
and 61300097), and the China Postdoctoral Sci-
ence Foundation (Grant 2013M530131). The au-
thors would like to thank the anonymous reviewers
for their pertinent and insightful comments.
567
References
David Chiang. 2010. Learning to Translate with
Source and Target Syntax. In Proc. of ACL 2010,
pages 1443-1452.
James Clarke and Mirella Lapata. 2006. Models for
Sentence Compression: A Comparison across Do-
mains, Training Requirements and Evaluation Mea-
sures. In Proc. of ACL/COLING 2006, pages 377-
384.
Trevor Cohn and Mirella Lapata. 2008. Sentence
Compression Beyond Word Deletion. In Proc. of
COLING 2008, pages 137-144.
Jason Eisner. 2003. Learning Non-Isomorphic Tree
Mappings for Machine Translation. In Proc. of ACL
2003, pages 205-208.
Michel Galley and Kathleen McKeown. 2007. Lex-
icalized Markov Grammars for Sentence Compres-
sion. In Proc. of HLT:NAACL 2007, pages 180-187.
Liang Huang, Kevin Knight and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proc. of AMTA 2006, pages
66-73.
Kevin Knight and Daniel Marcu. 2000. Statistical-
based summarization-step one: sentence compres-
sion. In Proc. of AAAI 2000, pages 703-710.
Philipp Koehn, Franz J. Och and Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proc. of
NAACL 2003, pages 48-54.
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine
Translation. In Proc. of ACL/COLING 2006, pages
609-616.
Shujie Liu, Chi-Ho Li and Ming Zhou. 2011. Statistic
Machine Translation Boosted with Spurious Word
Deletion. In Proc. of Machine Translation Summit
XIII, pages 72-79.
Yuval Marton and Philip Resnik. 2008. Soft Syntactic
Constraints for Hierarchical Phrased-Based Transla-
tion. In Proc. of ACL:HLT 2008, pages 1003-1011.
Bart Mellebeek, Karolina Owczarzak, Josef van Gen-
abith and Andy Way. 2006. Multi-Engine Machine
Translation by Recursive Sentence Decomposition.
In Proc. of AMTA 2006, pages 110-118.
Bart Mellebeek, Karolina Owczarzak, Declan Groves,
Josef Van Genabith and Andy Way. 2006. A Syn-
tactic Skeleton for Statistical Machine Translation.
In Proc. of EAMT 2006, pages 195-202.
Franz J. Och, Christoph Tillmann and Hermann Ney.
1999. Improved Alignment Models for Statistical
Machine Translation. In Proc. of EMNLP/VLC
1999, pages 20-28.
Franz J. Och. 2003. Minimum error rate training in s-
tatistical machine translation. In Proc. of ACL 2003,
pages 160-167.
Karolina Owczarzak, Bart Mellebeek, Declan Groves,
Josef van Genabith and Andy Way. 2006. Wrapper
Syntax for Example-Based Machine Translation. In
Proc. of AMTA2006, pages 148-155.
Antti-Veikko I. Rosti, Spyros Matsoukas and Richard
Schwartz. 2007. Improved Word-Level System
Combination for Machine Translation. In Proc. of
ACL 2007, pages 312-319.
Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2008. Incremental hypothe-
sis alignment for building confusion networks with
application to machine translation system combina-
tion. In Proc. of Third Workshop on Statistical Ma-
chine Translation, pages 183?186.
Tong Xiao, Jingbo Zhu, Hao Zhang and Qiang Li
2012. NiuTrans: An Open Source Toolkit for
Phrase-based and Syntax-based Machine Transla-
tion. In Proc. of ACL 2012, system demonstrations,
pages 19-24.
Elif Yamangil and Stuart M. Shieber. 2010. Bayesian
Synchronous Tree-Substitution Grammar Induction
and Its Application to Sentence Compression. In
Proc. of ACL 2010, pages 937-947.
Katsumasa Yoshikawa, Ryu Iida, Tsutomu Hirao and
Manabu Okumura. 2012. Sentence Compression
with Semantic Role Constraints. In Proc. of ACL
2012, pages 349-353.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew
Lim Tan and Sheng Li. 2008. A Tree Sequence
Alignment-based Tree-to-Tree Translation Model.
In Proc. of ACL:HLT 2008, pages 559-567.
Chunliang Zhang, Minghan Hu, Tong Xiao, Xue Jiang,
Lixin Shi and Jingbo Zhu. 2013. Chinese Sentence
Compression: Corpus and Evaluation. In Proc.
of Chinese Computational Linguistics and Natural
Language Processing Based on Naturally Annotated
Big Data, pages 257-267.
568
NEUNLPLab Chinese Word Sense Induction System for 
SIGHAN Bakeoff 2010 
Hao Zhang Tong Xiao Jingbo Zhu 
1. Key Laboratory of Medical Image Computing (Northeastern University), Ministry 
of Education 
2. Natural Language Processing Laboratory, Northeastern University 
zhanghao1216@gmail.com 
{xiaotong, zhujingbo}@mail.neu.edu.cn 
 
Abstract 
This paper describes a character-based 
Chinese word sense induction (WSI) sys-
tem for the International Chinese Lan-
guage Processing Bakeoff 2010. By 
computing the longest common sub-
strings between any two contexts of the 
ambiguous word, our system extracts 
collocations as features and does not de-
pend on any extra tools, such as Chinese 
word segmenters. We also design a con-
strained clustering algorithm for this task. 
Experiemental results show that our sys-
tem could achieve 69.88 scores of 
FScore on the development data set of 
SIGHAN Bakeoff 2010. 
1 Introduction 
The goal of word sense induction (WSI) is to 
group occurrences containing a given ambiguous 
word into clusters with respect to sense. Most 
researchers take the problem of word sense in-
duction as a clustering problem. Pantel & Lin 
(2002) clustered words on the basis of the dis-
tances of their co-occurrence vectors, and used 
global clustering as a solution. Neill (2002) used 
local clustering, and determined the senses of a 
given word by clustering its close associations. 
In this paper, we propose a simple but effec-
tive method to extract collocations as features 
from texts without pre-segmentations, and de-
sign a constrained clustering algorithm to ad-
dress the issue of Chinese word sense induction. 
By using our collocation extraction method, our 
Chinese WSI system is independent of any extra 
natural language processing tools, such as Chi-
nese word segmenters. On the development set 
of SIGHAN 2010 WSI task, the experimental 
results show that our system could achieve 69.88 
scores of FScore. In addition, the official results 
show that the performance of our system is 
67.15 scores of FScore on the test set of 
SIGHAN Bakeoff 2010. 
The rest of this paper is organized as follows. 
In Section 2, we present the task description of 
Chinese word sense induction. In Section 3, we 
first give an overview of our Chinese WSI sys-
tem, and then propose our feature extraction 
method and constrained clustering algorithm. In 
Section 4, we describe the evaluation method 
and show the experimental results on the devel-
opment and test data sets of the Bakeoff 2010. In 
Section 5, we conclude our work. 
2 Task Description 
Given the number of senses S and occurrences of 
the ambiguous word w, a word sense induction 
system is supposed to cluster the occurrences 
into S clusters, with each cluster representing a 
sense of the ambiguous word w. For example, 
suppose that there are some sentences containing 
the ambiguous word ???? (gloomy), and the 
sense number S is 2, the job of WSI system is to 
cluster these sentences into 2 clusters, with each 
cluster representing a sense of ????. Based on 
this task description, it is obvious to regard the 
problem of WSI as a clustering problem. 
Figures 1-2 shows example input and output 
of our WSI system , where there are 6 sentences 
and 2 resulting clusters. In Figure 1, the first 
column are the identifiers of sentences contain-
ing the word ????, and the second column are 
part of the sentences. In Figure 2, the first col-
umn represents the identifiers of sentences, and 
the second column represents the identifiers of 
clusters generated by our Chinese WSI system. 
 
Figure 1 Part of input of word ???? for our 
WSI system 
 
Figure 2 Output of our WSI system for word 
???? 
3 NEU Chinese WSI System 
3.1 System overview 
Our Chinese word sense induction system is 
built based on clustering work-frame. There are 
four major modules in the system, including 
data pre-processing, feature extraction, cluster-
ing and data post-processing modules. The ar-
chitecture of our Chinese WSI system is illus-
trated in Figure 3. 
3.2 Feature extraction 
Since there is no separators in Chinese like 
?space? in English to mark word boundaries, 
most Chinese natural language processing appli-
cations need to first apply a Chinese word seg-
menter to segment Chinese sentences. In our 
Chinese word sense induction system, we extract 
collocations from sentences containing the am-
biguous word as features. To extract collocations, 
we might first segment the sentences into word 
sequences, and then conduct feature extraction 
on the word-segmented corpus. However, errors 
might be induced in the procedure due to un-
avoidable incorrect segmentation results. Ad-
dressing this issue, we propose a method to di-
rectly extract collocations from sentences with-
out pre-segmentations. 
In our method, we extract two kinds of collo-
cations, namely ?global collocation? and ?local 
collocation?. Here global collocations are de-
fined to be the words (or character sequences) 
that frequently co-occur with the ambiguous 
word, and local collocations are defined to be 
the characters adjacent to the ambiguous word1. 
 
Figure 3 Architecture of our system 
To extract global collocations, we first com-
pute all the longest common substrings between 
any two of the sentences containing the ambigu-
ous word to form the set of candidate global col-
locations. For each candidate global collocation, 
we count the number of sentences containing it. 
We then reduce the size of the candidate set by 
eliminating candidates which contain only one 
character or functional words. We also remove 
the candidate with other candidates as its sub-
strings. Finally, we eliminate the candidates 
whose count of the number of sentences is below 
a certain threshold. The threshold equals to two 
in our experiments. We regard the candidates 
after the above processing as global collocations 
for WSI. 
To extract local collocations, we simply ex-
tract one character on both left and right sides of 
the ambiguous word to form the set of candidate 
local collocations. We then refine the candidate 
set by eliminating candidates which are func-
tional words or whose frequency is below a cer-
tain threshold. The threshold is set to two in our 
experiments. 
After extracting global collocations and local 
collocations, we put them together to form the 
                                                 
1
 Definitions of global collocation and local collocation 
might be different from those in other papers. 
start 
data pre-processing 
feature extraction 
clustering 
data post-processing 
end 
final set of collocations and use them as features 
of our system. For each collocation (or feature), 
we compute the list of indices of sentences that 
containing the collocation. Thus, every element 
of the set of collocations has the data structure of 
pair of ?key? and ?value?, where ?key? is the 
collocation itself, and the ?value? is the list of 
indices. 
3.3 Clustering algorithm 
We find that the high-confidence collocation is a 
very good indicator to distinguish the senses of 
an ambiguous word. However, the traditional 
clustering methods are based on the vector rep-
resentations of features, which probably de-
creases the effect of dominant features (i.e. high-
confidence collocations). To alleviate the prob-
lem, a nice way is to incorporate collocations 
into the clustering process as constraints. Moti-
vated by this idea, we design a constrained clus-
tering algorithm. In this algorithm, we could en-
sure that some occurrences of the ambiguous 
word must be in one cluster and some must not 
be in one cluster. The input for our constrained 
clustering algorithm is the set of collocations 
described in the previous section and the process 
of our clustering algorithm is shown in Table 1. 
Here the notation starting with character ?C? 
represents a collocation, and the notations of 
?Sin? and ?Srlt? represent the collocation set and 
the result set, respectively. 
Every element in the result set Srlt is regarded 
as one cluster for a given ambigous word, and 
the list of the element records the indices of the 
sentences belonging to the cluster. 
4 Evaluation of Our System 
The evaluation method is F-score which is pro-
vided within the Bakeoff 2010 (Zhao and 
Karypis, 2005). Suppose Cr is a class of the gold 
standard, and Si is a cluster of our system gener-
ated. FScore is computed with the formulas be-
low. 
( , ) 2 * * / ( )F score Cr Si P R P R? = +          (1) 
( ) max( ( , ))
Si
FScore Cr F score Cr Si= ?         (2) 
1
( )
c
r
nr
FScore FScore Cr
n
=
=?                (3) 
We evaluate our Chinese word sense induc-
tion system on the development data set and the 
test data set of the Bakeoff 2010. The details of 
the development data set and the test data set are 
summarized in Table 2. 
For comparison, we develop a baseline system 
that also uses the collocations as features and 
clustering based on the vector representations of 
features. On the development data set, we test 
our system and compare it with the baseline sys-
tem. The performance of our Chinese WSI sys-
tem and the baseline system are shown in Table 
3. From Table 3, we see that using our con-
strained clustering algorithm is better than using 
the traditional hierarchical clustering methods by 
7.06 scores of FScore for our Chinese WSI sys-
tem. It indicates that our constrained clustering 
algorithm could avoid reducing the effect of  
Input: collocation set Sin 
while there is available collocation Ci in the 
input set Sin 
 for each collocation Ct in the set Sin 
 if Ct not equals to Ci, and Ct is avail-
able 
 if list of Ct has intersection with 
that of Ci, or Ct and Ci have a 
meaningful substring (word or 
character), compose list of Ct into 
list of Ci, and mark Ct to be un-
available 
 end if 
 end if 
 end for 
 store Ci and its list into result set Srlt, and 
mark Ci to be unavailable 
end while 
if there are available collocations in the input 
set Sin 
 if the size of result set Srlt does not sat-
isfy the given cluster number, devide the 
rest collocations in Sin evenly into the 
rest clusters, and append their lists to 
their own clusters? lists respectively 
 else add the rest collocations into the last 
cluster, and append their list to the list of 
the last cluster 
 end if 
end if 
return the result set Srlt 
Output: result set Srlt 
Table 1 Constrained clustering algorithm 
high-confidence features (i.e. high-confidence 
collocations) and lead to better clustering results. 
This conclusion is also ensured by the compari-
son between our constrained clustering algo-
rithm and the traditional K-means clustering al-
gorithm. 
In addition, our system achieves 67.15 scores 
of FScore on the test data set reported by the 
SIGHAN Bakeoff 2010. 
data descriptions 
Dev set 
containing 50 ambiguous words, 
about 50 sentences for each am-
biguous word 
Test set 
containing 100 ambiguous words, 
about 50 sentences for each am-
biguous word 
Table 2 Data sets of SIGHAN Bakeoff 2010 
clustering methods 
FScore of 
our system 
(%) 
traditional hierarchical cluster-
ing 62.82 
traditional K-means clustering 62.48 
our constrained clustering 69.88 
Table 3 System performance on dev set of 
Bakeoff 2010 using different clustering methods 
5 Conclusions 
In this paper, we propose a collocation extrac-
tion method and a constrained clustering algo-
rithm for Chinese WSI task. By using the collo-
cation extraction method and the clustering algo-
rithm, our Chinese word sense induction system 
is independent of any extra tools. When tested 
on the test data set of the Bakeoff 2010, our sys-
tem achieves 67.15 scores of FScore. 
References 
Vickrey, David, Luke Biewald, Marc Teyssler, and 
Daphne Koller. 2005. Word-sense disambiguation 
for machine translation. In Proceedings of the con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing, 
Morristown, NJ, USA, pages 771-778. 
Yarowsky, David. 1995. Unsupervised word sense 
disambiguation rivaling supervised methods. In 
Proceedings of 33rd Meeting of the Association for 
Computational Linguistics, Cambridge, MA, 189-
196. 
Schutze, Hinrich. 1998. Automatic word sense dis-
crimination. Computational Linguistics, Montreal, 
Canada, 24(1):97?123. 
Ng, Hwee Tou, Hian Beng Lee. 1996. Integrating 
Multiple Knowledge Sources to Disambiguate 
Word Sense: An Exemplar-Based Approach. In 
Proceedings of the 34th Meeting of the Association 
for Computational Linguistics, California, USA, 
pages 40-47. 
Daniel, Neill. 2002. Fully Automatic Word Sense 
Induction by Semantic Clustering. In Computer 
Speech, Cambridge University, Master?s Thesis. 
Pantel, Patrick, Dekang Lin. 2002. Discovering word 
senses from text. In Proceedings of ACM SIGKDD, 
Edmonton, 613-619. 
Rapp, Reinhard. 2004. A Practical Solution to the 
Problem of Automatic Word Sense Induction. In 
Proceedings of the 42nd Meeting of the Association 
for Computational Linguistics, Barcelona, Spain. 
Zhao, Ying, George Karypis. 2005. Hierarchical 
Clustering Algorithms for Document Datasets. 
Data Mining and Knowledge Discovery, 10:141-
168. 
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 200?205,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
The University of Cambridge Russian-English System at WMT13
Juan Pino Aurelien Waite Tong Xiao
Adria` de Gispert Federico Flego William Byrne
Department of Engineering, University of Cambridge, Cambridge, CB2 1PZ, UK
{jmp84,aaw35,tx212,ad465,ff257,wjb31}@eng.cam.ac.uk
Abstract
This paper describes the University of
Cambridge submission to the Eighth
Workshop on Statistical Machine Transla-
tion. We report results for the Russian-
English translation task. We use mul-
tiple segmentations for the Russian in-
put language. We employ the Hadoop
framework to extract rules. The decoder
is HiFST, a hierarchical phrase-based de-
coder implemented using weighted finite-
state transducers. Lattices are rescored
with a higher order language model and
minimum Bayes-risk objective.
1 Introduction
This paper describes the University of Cam-
bridge system submission to the ACL 2013
Eighth Workshop on Statistical Machine Transla-
tion (WMT13). Our translation system is HiFST
(Iglesias et al, 2009), a hierarchical phrase-based
decoder that generates translation lattices directly.
Decoding is guided by a CYK parser based on a
synchronous context-free grammar induced from
automatic word alignments (Chiang, 2007). The
decoder is implemented with Weighted Finite
State Transducers (WFSTs) using standard op-
erations available in the OpenFst libraries (Al-
lauzen et al, 2007). The use of WFSTs allows
fast and efficient exploration of a vast translation
search space, avoiding search errors in decoding.
It also allows better integration with other steps
in our translation pipeline such as 5-gram lan-
guage model (LM) rescoring and lattice minimum
Bayes-risk (LMBR) decoding (Blackwood, 2010).
We participate in the Russian-English transla-
tion shared task in the Russian-English direction.
This is the first time we train and evaluate a sys-
tem on this language pair. This paper describes the
development of the system.
The paper is organised as follows. Section 2
describes each step in the development of our sys-
tem for submission, from pre-processing to post-
processing and Section 3 presents and discusses
results.
2 System Development
2.1 Pre-processing
We use all the Russian-English parallel data avail-
able in the constraint track. We filter out non
Russian-English sentence pairs with the language-
detection library.2 A sentence pair is filtered out if
the language detector detects a different language
with probability more than 0.999995 in either the
source or the target. This discards 78543 sen-
tence pairs. In addition, sentence pairs where the
source sentence has no Russian character, defined
by the Perl regular expression [\x0400-\x04ff],
are discarded. This further discards 19000 sen-
tence pairs.
The Russian side of the parallel corpus is to-
kenised with the Stanford CoreNLP toolkit.3 The
Stanford CoreNLP tokenised text is additionally
segmented with Morfessor (Creutz and Lagus,
2007) and with the TreeTagger (Schmid, 1995).
In the latter case, we replace each token by its
stem followed by its part-of-speech. This of-
fers various segmentations that can be taken ad-
vantage of in hypothesis combination: CoreNLP,
CoreNLP+Morfessor and CoreNLP+TreeTagger.
The English side of the parallel corpus is tokenised
with a standard in-house tokeniser. Both sides of
the parallel corpus are then lowercased, so mixed
case is restored in post-processing.
Corpus statistics after filtering and for various
segmentations are summarised in Table 1.
2http://code.google.com/p/language-detection/
3http://nlp.stanford.edu/software/corenlp.shtml
200
Lang Segmentation # Tokens # Types
RU CoreNLP 47.4M 1.2M
RU Morfessor 50.0M 0.4M
RU TreeTagger 47.4M 1.5M
EN Cambridge 50.4M 0.7M
Table 1: Russian-English parallel corpus statistics
for various segmentations.
2.2 Alignments
Parallel data is aligned using the MTTK toolkit
(Deng and Byrne, 2008). We train a word-
to-phrase HMM model with a maximum phrase
length of 4 in both source-to-target and target-to-
source directions. The final alignments are ob-
tained by taking the union of alignments obtained
in both directions.
2.3 Rule Extraction and Retrieval
A synchronous context-free grammar (Chiang,
2007) is extracted from the alignments. The con-
straints are set as in the original publication with
the following exceptions:
? phrase-based rule maximum number of
source words: 9
? maximum number of source element (termi-
nal or nonterminal): 5
? maximum span for nonterminals: 10
Maximum likelihood estimates for the transla-
tion probabilities are computed using MapReduce.
We use a custom Hadoop-based toolkit which im-
plements method 3 of Dyer et al (2008). Once
computed, the model parameters are stored on disk
in the HFile format (Pino et al, 2012) for fast
querying. Rule extraction and feature computa-
tion takes about 2h30. The HFile format requires
data to be stored in a key-value structure. For the
key, we use shared source side of many rules. The
value is a list of tuples containing the possible tar-
gets for the source key and the associated param-
eters of the full rule. The query set of keys for
the test set is all possible source phrases (includ-
ing nonterminals) found in the test set.
During HFile querying we add other features.
These include IBM Model 1 (Brown et al, 1993)
lexical probabilities. Loading these models in
memory doesn?t fit well with the MapReduce
model so lexical features are computed for each
test set rather than for the entire parallel corpus.
The model parameters are stored in a client-server
based architecture. The client process computes
the probability of the rule by querying the server
process for the Model 1 parameters. The server
process stores the model parameters completely
in memory so that parameters are served quickly.
This architecture allows for many low-memory
client processes across many machines.
2.4 Language Model
We used the KenLM toolkit (Heafield et al, 2013)
to estimate separate 4-gram LMs with Kneser-Ney
smoothing (Kneser and Ney, 1995), for each of the
corpora listed in Tables 2 (self-explanatory abbre-
viations). The component models were then in-
terpolated with the SRILM toolkit (Stolcke, 2002)
to form a single LM for use in first-pass trans-
lation decoding. The interpolation weights were
optimised for perplexity on the news-test2008,
newstest2009 and newssyscomb2009 development
sets. The weights reflect both the size of the com-
ponent models and the genre of the corpus the
component models are trained on, e.g. weights are
larger for larger corpora in the news genre.
Corpus # Tokens
EU + NC + UN + CzEng + Yx 652.5M
Giga + CC + Wiki 654.1M
News Crawl 1594.3M
afp 874.1M
apw 1429.3M
cna + wpb 66.4M
ltw 326.5M
nyt 1744.3M
xin 425.3M
Total 7766.9M
Table 2: Statistics for English monolingual cor-
pora.
2.5 Decoding
For translation, we use the HiFST decoder (Igle-
sias et al, 2009). HiFST is a hierarchical decoder
that builds target word lattices guided by a prob-
abilistic synchronous context-free grammar. As-
suming N to be the set of non-terminals and T the
set of terminals or words, then we can define the
grammar as a set R = {R} of rules R : N ?
??,?? / p, where N ? N, ?, ? ? {N ?T}+ and p
the rule score.
201
HiFST translates in three steps. The first step
is a variant of the CYK algorithm (Chappelier and
Rajman, 1998), in which we apply hypothesis re-
combination without pruning. Only the source
language sentence is parsed using the correspond-
ing source-side context-free grammar with rules
N ? ?. Each cell in the CYK grid is specified
by a non-terminal symbol and position: (N, x, y),
spanning sx+y?1x on the source sentence s1...sJ .
For the second step, we use a recursive algo-
rithm to construct word lattices with all possi-
ble translations produced by the hierarchical rules.
Construction proceeds by traversing the CYK grid
along the back-pointers established in parsing. In
each cell (N, x, y) of the CYK grid, we build a
target language word lattice L(N, x, y) containing
every translation of sx+y?1x from every derivation
headed by N . For efficiency, this lattice can use
pointers to lattices on other cells of the grid.
In the third step, we apply the word-based LM
via standard WFST composition with failure tran-
sitions, and perform likelihood-based pruning (Al-
lauzen et al, 2007) based on the combined trans-
lation and LM scores.
We are using shallow-1 hierarchical gram-
mars (de Gispert et al, 2010) in our experiments.
This model is constrained enough that the decoder
can build exact search spaces, i.e. there is no prun-
ing in search that may lead to spurious undergen-
eration errors.
2.6 Features and Parameter Optimisation
We use the following standard features:
? language model
? source-to-target and target-to-source transla-
tion scores
? source-to-target and target-to-source lexical
scores
? target word count
? rule count
? glue rule count
? deletion rule count (each source unigram, ex-
cept for OOVs, is allowed to be deleted)
? binary feature indicating whether a rule is ex-
tracted once, twice or more than twice (Ben-
der et al, 2007)
No alignment information is used when com-
puting lexical scores as done in Equation (4) in
(Koehn et al, 2005). Instead, the source-to-target
lexical score is computed in Equation 1:
s(ru, en) = 1(E + 1)R
R?
r=1
E?
e=0
pM1(ene|rur)
(1)
where ru are the terminals in the Russian side of
a rule, en are the terminals in the English side of
a rule, including the null word, R is the number
of Russian terminals, E is the number of English
terminals and pM1 is the IBM Model 1 probability.
In addition to these standard features, we also
use provenance features (Chiang et al, 2011). The
parallel data is divided into four subcorpora: the
Common Crawl (CC) corpus, the News Commen-
tary (NC) corpus, the Yandex (Yx) corpus and the
Wiki Headlines (Wiki) corpus. For each of these
subcorpora, source-to-target and target-to-source
translation and lexical scores are computed. This
requires computing IBM Model 1 for each sub-
corpus. In total, there are 28 features, 12 standard
features and 16 provenance features.
When retrieving relevant rules for a particular
test set, various thresholds are applied, such as
number of targets per source or translation prob-
ability cutoffs. Thresholds involving source-to-
target translation scores are applied separately for
each provenance and the union of all surviving
rules for each provenance is kept. This strategy
gives slight gains over using thresholds only for
the general translation table.
We use an implementation of lattice minimum
error rate training (Macherey et al, 2008) to op-
timise under the BLEU score (Papineni et al,
2001) the feature weights with respect to the odd
sentences of the newstest2012 development set
(newstest2012.tune). The weights obtained match
our expectation, for example, the source-to-target
translation feature weight is higher for the NC cor-
pus than for other corpora since we are translating
news.
2.7 Lattice Rescoring
The HiFST decoder is set to directly generate
large translation lattices encoding many alterna-
tive translation hypotheses. These first-pass lat-
tices are rescored with second-pass higher-order
LMs prior to LMBR.
202
2.7.1 5-gram LM Lattice Rescoring
We build a sentence-specific, zero-cutoff stupid-
backoff (Brants et al, 2007) 5-gram LMs esti-
mated over the data described in section 2.4. Lat-
tices obtained by first-pass decoding are rescored
with this 5-gram LM (Blackwood, 2010).
2.7.2 LMBR Decoding
Minimum Bayes-risk decoding (Kumar and
Byrne, 2004) over the full evidence space of the 5-
gram rescored lattices is applied to select the trans-
lation hypothesis that maximises the conditional
expected gain under the linearised sentence-level
BLEU score (Tromble et al, 2008; Blackwood,
2010). The unigram precision p and average re-
call ratio r are set as described in Tromble et al
(2008) using the newstest2012.tune development
set.
2.8 Hypothesis Combination
LMBR decoding (Tromble et al, 2008) can also be
used as an effective framework for multiple lattice
combination (Blackwood, 2010). We used LMBR
to combine translation lattices produced by sys-
tems trained on alternative segmentations.
2.9 Post-processing
Training data is lowercased, so we apply true-
casing as post-processing. We used the disam-
big tool provided by the SRILM toolkit (Stolcke,
2002). The word mapping model which contains
the probability of mapping a lower-cased word
to its mixed-cased form is trained on all avail-
able data. A Kneser-Ney smoothed 4-gram lan-
guage model is also trained on the following cor-
pora: NC, News Crawl, Wiki, afp, apw, cna, ltw,
nyt, wpb, xin, giga. In addition, several rules are
manually designed to improve upon the output of
the disambig tool. First, casing information from
pass-through translation rules (for OOV source
words) is used to modify the casing of the output.
For example, this allows us to get the correct cas-
ing for the word Bundesrechnungshof. Other rules
are post-editing rules which force some words
to their upper-case forms, such as euro ? Euro.
Post-editing rules are developed based on high-
frequency errors on the newstest2012.tune devel-
opment set. These rules give an improvement of
0.2 mixed-cased NIST BLEU on the development
set.
Finally, the output is detokenised before sub-
mission and Cyrillic characters are transliterated.
We assume for human judgment purposes that it
is better to have a non English word in Latin al-
phabet than in Cyrillic (e.g. uprazdnyayushchie);
sometimes, transliteration can also give a correct
output (e.g. Movember), especially in the case of
proper nouns.
3 Results and Discussion
Results are reported in Table 3. We use the inter-
nationalisation switch for the NIST BLEU scor-
ing script in order to properly lowercase the hy-
pothesis and the reference. This introduces a
slight discrepancy with official results going into
the English language. The newstest2012.test de-
velopment set consists of even sentences from
newstest2012. We observe that the CoreNLP
system (A) outperforms the other two systems.
The CoreNLP+Morfessor system (B) has a much
smaller vocabulary but the model size is compa-
rable to the system A?s model size. Translation
did not benefit from source side morphological de-
composition. We also observe that the gain from
LMBR hypothesis combination (A+B+C) is mini-
mal. Unlike other language pairs, such as Arabic-
English (de Gispert et al, 2009), we have not yet
found any great advantage in multiple morpho-
logical decomposition or preprocessing analyses
of the source text. 5-gram and LMBR rescoring
give consistent improvements. 5-gram rescoring
improvements are very modest, probably because
the first pass 4-gram model is trained on the same
data. As noted, hypothesis combination using the
various segmentations gives consistent but modest
gains over each individual system.
Two systems were submitted to the evalua-
tion. System A+B+C achieved a mixed-cased
NIST BLEU score of 24.6, which was the top
score achieved under this measure. System A sys-
tem achieved a mixed-cased NIST BLEU score of
24.5, which was the second highest score.
4 Summary
We have successfully trained a Russian-English
system for the first time. Lessons learned include
that simple tokenisation is enough to process the
Russian side, very modest gains come from com-
bining alternative segmentations (it could also be
that the Morfessor segmentation should not be per-
formed after CoreNLP but directly on untokenised
data), and reordering between Russian and En-
glish is such that a shallow-1 grammar performs
203
Configuration newstest2012.tune newstest2012.test newstest2013
CoreNLP(A) 33.65 32.36 25.55
+5g 33.67 32.58 25.63
+5g+LMBR 33.98 32.89 25.89
CoreNLP+Morfessor(B) 33.21 31.91 25.33
+5g 33.28 32.12 25.44
+5g+LMBR 33.58 32.43 25.78
CoreNLP+TreeTagger(C) 32.92 31.54 24.78
+5g 32.94 31.85 24.97
+5g+LMBR 33.12 32.12 25.05
A+B+C 34.32 33.13 26.00
Table 3: Translation results, shown in lowercase NIST BLEU. Bold results correspond to submitted
systems.
competitively.
Future work could include exploring alterna-
tive grammars, applying a 5-gram Kneser-Ney
smoothed language model directly in first-pass de-
coding, and combining alternative segmentations
that are more diverse from each other.
Acknowledgments
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7-ICT-2009-4) under grant
agreement number 247762. Tong Xiao was sup-
ported in part by the National Natural Science
Foundation of China (Grant 61073140 and Grant
61272376) and the China Postdoctoral Science
Foundation (Grant 2013M530131).
References
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-
jciech Skut, and Mehryar Mohri. 2007. OpenFst: A
general and efficient weighted finite-state transducer
library. In Proceedings of CIAA, pages 11?23.
Oliver Bender, Evgeny Matusov, Stefan Hahn, Sasa
Hasan, Shahram Khadivi, and Hermann Ney. 2007.
The RWTH Arabic-to-English spoken language
translation system. In Proceedings of ASRU, pages
396?401.
Graeme Blackwood. 2010. Lattice rescoring meth-
ods for statistical machine translation. Ph.D. thesis,
Cambridge University Engineering Department and
Clare College.
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.
Och, and Jeffrey Dean. 2007. Large language
models in machine translation. In Proceedings of
EMNLP-ACL, pages 858?867.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational linguistics,
19(2):263?311.
Jean-Ce?dric Chappelier and Martin Rajman. 1998. A
generalized CYK algorithm for parsing stochastic
CFG. In Proceedings of TAPD, pages 133?137.
David Chiang, Steve DeNeefe, and Michael Pust.
2011. Two easy improvements to lexical weighting.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies, pages 455?460, Portland,
Oregon, USA, June. Association for Computational
Linguistics.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228.
Mathias Creutz and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and mor-
phology learning. ACM Transactions on Speech and
Language Processing (TSLP), 4(1):3.
Adria` de Gispert, Sami Virpioja, Mikko Kurimo, and
William Byrne. 2009. Minimum Bayes Risk Com-
bination of Translation Hypotheses from Alterna-
tive Morphological Decompositions. In Proceed-
ings of HLT/NAACL, Companion Volume: Short Pa-
pers, pages 73?76.
Adria` de Gispert, Gonzalo Iglesias, Graeme Black-
wood, Eduardo R. Banga, and William Byrne. 2010.
Hierarchical phrase-based translation with weighted
finite state transducers and shallow-n grammars. In
Computational Linguistics.
Yonggang Deng and William Byrne. 2008. Hmm word
and phrase alignment for statistical machine trans-
lation. IEEE Transactions on Audio, Speech, and
Language Processing, 16(3):494?507.
Chris Dyer, Aaron Cordova, Alex Mont, and Jimmy
Lin. 2008. Fast, easy, and cheap: Construc-
tion of statistical machine translation models with
204
MapReduce. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 199?207,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, Sofia, Bulgaria,
August.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009. Hierarchical phrase-
based translation with weighted finite state transduc-
ers. In Proceedings of NAACL, pages 433?441.
Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. In Pro-
ceedings of ICASSP, volume 1, pages 181?184.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh system description
for the 2005 iwslt speech translation evaluation. In
International Workshop on Spoken Language Trans-
lation, volume 8.
Shankar Kumar and William Byrne. 2004. Minimum
Bayes-risk decoding for statistical machine transla-
tion. In Proceedings of HLT-NAACL, pages 169?
176.
Wolfgang Macherey, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum er-
ror rate training for statistical machine translation.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
725?734, Honolulu, Hawaii, October. Association
for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of ACL, pages 311?318.
Juan Pino, Aurelien Waite, and William Byrne. 2012.
Simple and efficient model filtering in statistical ma-
chine translation. The Prague Bulletin of Mathemat-
ical Linguistics, 98(1):5?24.
Helmut Schmid. 1995. Improvements in part-of-
speech tagging with an application to German. In
Proceedings of the ACL SIGDAT-Workshop, pages
47?50.
Andreas Stolcke. 2002. SRILM?An Extensible Lan-
guage Modeling Toolkit. In Proceedings of ICSLP,
volume 3, pages 901?904.
Roy W. Tromble, Shankar Kumar, Franz Och, and
Wolfgang Macherey. 2008. Lattice Minimum
Bayes-Risk decoding for statistical machine trans-
lation. In Proceedings of EMNLP, pages 620?629.
205
