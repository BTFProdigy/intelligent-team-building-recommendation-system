Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 530?540, Dublin, Ireland, August 23-29 2014.
Jointly or Separately: Which is Better for
Parsing Heterogeneous Dependencies?
Meishan Zhang
?
, Wanxiang Che
?
, Yanqiu Shao
?
, Ting Liu
??
?
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{mszhang, car, tliu}@ir.hit.edu.cn
?
Beijing Language and Culture University
yqshao163@163.com
Abstract
For languages such as English, several constituent-to-dependency conversion schemes are pro-
posed to construct corpora for dependency parsing. It is hard to determine which scheme is
better because they reflect different views of dependency analysis. We usually obtain dependen-
cy parsers of different schemes by training with the specific corpus separately. It neglects the
correlations between these schemes, which can potentially benefit the parsers. In this paper, we
study how these correlations influence final dependency parsing performances, by proposing a
joint model which can make full use of the correlations between heterogeneous dependencies,
and finally we can answer the following question: parsing heterogeneous dependencies jointly
or separately, which is better? We conduct experiments with two different schemes on the Penn
Treebank and the Chinese Penn Treebank respectively, arriving at the same conclusion that joint-
ly parsing heterogeneous dependencies can give improved performances for both schemes over
the individual models.
1 Introduction
Dependency parsing has been intensively studied in recent years (McDonald et al., 2005; Nivre, 2008;
Zhang and Clark, 2008; Huang et al., 2009; Koo and Collins, 2010; Zhang and Nivre, 2011; Sartorio et
al., 2013; Choi and McCallum, 2013; Martins et al., 2013). Widely-used corpus for training a dependen-
cy parser is usually constructed according to a specific constituent-to-dependency conversion scheme.
Several conversion schemes for certain languages have been available. For example, the English lan-
guage has at least four schemes based on the Penn Treebank (PTB), including the Yamada scheme (Ya-
mada and Matsumoto, 2003), the CoNLL 2007 scheme (Nilsson et al., 2007), the Stanford scheme
(de Marneffe and Manning, 2008) and the LTH scheme (Johansson and Nugues, 2007). There are dif-
ferent conversion schemes for the Chinese Penn Treebank (CTB) as well, including the Zhang scheme
(Zhang and Clark, 2008) and the Stanford scheme (de Marneffe and Manning, 2008). It is hard to
judge which scheme is more superior, because each scheme reflects a specific view of dependency analy-
sis, and also there is another fact that different natural language processing (NLP) applications can prefer
different conversion schemes (Elming et al., 2013).
Traditionally, we get dependency parsers of different schemes by training with the specific corpus
separately. The method neglects the correlations between these schemes, which can potentially help
different dependency parsers. On the one hand, there are many consistent dependencies across heteroge-
neous dependency trees. Some dependency structures remain constant in different conversion schemes.
Taking the Yamada and the Stanford schemes as an example, overall 70.27% of the dependencies are
identical (ignoring the dependency labels), according to our experimental analysis. We show a concrete
example for the two heterogeneous dependency trees in Figure 1, where six of the twelve dependencies
are consistent in the two dependency trees (shown by the solid arcs).
On the other hand, differences between heterogeneous dependencies can possibly boost the ev-
idences of the consistent dependencies. For example in Figure 1, the dependencies ?do
VC
xthink?
?
Corresponding author.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
530
We do n?t think at this point anything need to be said
SUB
ROOT
VMOD
VC
VMOD NMOD
PMOD
SUB
VMOD
VMOD
VMOD
VC
nsubj
aux
neg
root
prep det
pobj
nsubj
ccomp
aux
auxpass
xcomp
Figure 1: An example to show the differences and similarities of two dependency schemes. The above
dependency tree is based on the Yamada scheme, while the below dependency tree is based on the
Stanford scheme. The solid arcs show the consistent dependencies between the two dependency
trees, while the dashed arcs show the differences between the two trees.
and ?We
nsubj
x think? from the two trees can both be potential evidences to support the dependency
?thinkyat?. Another example, the label ?PMOD? from the Yamada scheme and the label ?pobj? from
the Stanford scheme on a same dependency ?atypoint? can make it more reliable than one alone.
In this paper, we investigate the influences of the correlations between different dependency schemes
on parsing performances. We propose a joint model to parse heterogeneous dependencies from two
schemes simultaneously, so that the correlations can be fully used by their interactions in a single model.
Joint models have been widely studied to enhance multiple tasks in NLP community, including joint
word segmentation and POS-tagging (Jiang et al., 2008; Kruengkrai et al., 2009; Zhang and Clark,
2010), joint POS-tagging and dependency parsing (Li et al., 2011; Hatori et al., 2011), and the joint word
segmentation, POS-tagging and dependency parsing (Hatori et al., 2012). These models are proposed
over pipelined tasks. We apply the joint model into parallel tasks, and parse heterogeneous dependencies
together. To our knowledge, we are the first work to investigate joint models on parallel tasks.
We exploit a transition-based framework with global learning and beam-search decoding to imple-
ment the joint model (Zhang and Clark, 2011). The joint model is extended from a state-of-the-art
transition-based dependency parsing model. We conduct experiments on PTB with the Yamada and the
Stanford schemes, and also on CTB 5.1 with the Zhang and the Stanford schemes. The results
show that our joint model gives improved performances over the individual baseline models for both
schemes on both English and Chinese languages, demonstrating positive effects of the correlations be-
tween the two schemes. We make the source code freely available at http://sourceforge.net/
projects/zpar/,version0.7.
2 Baseline
Traditionally, the dependency parsers of different schemes are trained with their corpus separately, using
a state-of-the-art dependency parsing algorithm (Zhang and Clark, 2008; Huang et al., 2009; Koo and
Collins, 2010; Zhang and McDonald, 2012; Choi and McCallum, 2013). In this work, we exploit a
transition-based arc-standard dependency parsing model combined with global learning and beam-search
decoding as the baseline. which is initially proposed by Huang et al. (2009). In the following, we give a
detailed description of the model.
In a typical transition-based system for dependency parsing, we define a transition state, which consists
of a stack to save partial-parsed trees and a queue to save unprocessed words. The parsing is performed
incrementally via a set of transition actions. The transition actions are used to change contents of the
stack and the queue in a transition state. Initially, a start state has an empty stack and all words of a
sentence in its queue. Then transition actions are applied to the start state, and change states step by step.
Finally, we arrive at an end state with only one parsed tree on the stack and no words in the queue. We
score each state by its features generated from the historical actions.
531
S1
? ? ?
? ? ?
S
0
? ? ?
S
AR(l)
AL(l)
P
R
Q
0
Q
1
? ? ?
Q
SH
(a) Arc-standard dependency parsing model for a single dependency tree
S
a
1
? ? ?
? ? ?
S
a
0
? ? ?
S
a
AR
a
(l)
AL
a
(l)
P
R
a
Q
a
0
Q
a
1
? ? ?
Q
a
SH
a
S
b
1
? ? ?
? ? ?
S
b
0
? ? ?
S
b
AR
b
(l)
AL
b
(l)
P
R
b
Q
b
0
Q
b
1
? ? ?
Q
b
SH
b
G
u
i
d
e
d
a
G
u
i
d
e
d
b
(b) The joint model based on arc-standard dependency parsing for two dependency trees
Figure 2: Illustrations for the baseline dependency parsing model and our proposed joint model.
In the baseline arc-standard transition system, we define four kinds of actions, as shown in Figure 2(a).
They are shift (SH), arc-left with dependency label l (AL(l)), arc-right with dependency label l (AR(l))
and pop-root (PR), respectively. The shift action shifts the first element Q
0
of the queue onto the stack;
the action arc-left with dependency label l builds a left arc between the top element S
0
and the second
top element S
1
on the stack, with the dependency label being specified by l; the action arc-right with
dependency label l builds a right arc between the top element S
0
and the second top element S
1
on the
stack, with the dependency label being specified by l; and the pop-root action defines the root node of a
dependency tree when there is only one element on the stack and no element in the queue.
During decoding, each state may have several actions. We employ a fixed beam to reduce the search
space. The low-score states are pruned from the beam when it is full. The feature templates in our
baseline are shown by Table 1, referring to baseline feature templates. We learn the feature weights by
the averaged percepron algorithm with early-update (Collins and Roark, 2004; Zhang and Clark, 2011).
3 The Proposed Joint Model
The aforementioned baseline model can only handle a single dependency tree. In order to parse multiple
dependency trees for a sentence, we usually use individual dependency parsers. This method is not
able to exploit the correlations across different dependency schemes. The joint model to parse multiple
dependency trees with a single model is an elegant way to exploit these correlations fully. Inspired by
this, we make a novel extension to the baseline arc-standard transition system, arriving at a joint model
to parse two heterogeneous dependency trees for a sentence simultaneously.
In the new transition system, we double the original transition state of one stack and one queue into
two stacks and two queues, as shown by Figure 2(b). We use stacks S
a
and S
b
and queues Q
a
and Q
b
to save partial-parsed dependency trees and unprocessed words for two schemes a and b, respectively.
Similarly, the transition actions are doubled as well. We have eight transition actions, where four of them
are aimed for scheme a, and the other four are aimed for scheme b. The concrete action definitions are
similar to the original actions, except an additional constraint that actions should be operated over the
corresponding stack and queue of scheme a or b.
We assume that the actions to build a specific tree of scheme a are A
a
1
A
a
2
? ? ?A
a
n
, and the actions to
532
Baseline feature templates
Unigram features
S
0
w S
0
t S
0
wt S
1
w S
1
t S
1
wt N
0
w N
0
t N
0
wt N
1
w N
1
t N
1
wt
Bigram features
S
0
w?S
1
w S
0
w?S
1
t S
0
t?S
1
w S
0
t?S
1
t S
0
w?N
0
w S
0
w?N
0
t S
0
t?N
0
w S
0
t?N
0
t
Second-order features
S
0l
w S
0r
w S
0l
t S
0r
t S
0l
l S
0r
l S
1l
w S
1r
w S
1l
t S
1r
t S
1l
l S
1r
l
S
0l2
w S
0r2
w S
0l2
t S
0r2
t S
0l2
l2 S
0r2
l2 S
1l2
w S
1r2
w S
1l2
t S
1r2
t S
1l2
l2 S
1r2
l2
Third-order features
S
0
t?S
0l
t?S
0l2
t S
0
t?S
0r
t?S
0r2
t S
1
t?S
1l
t?S
1l2
t S
1
t?S
1r
t?S
1r2
t
S
0
t?S
1
t?S
0l
t S
0
t?S
1
t?S
0l2
t S
0
t?S
1
t?S
0r
t S
0
t?S
1
t?S
0r2
t
S
0
t?S
1
t?S
1l
t S
0
t?S
1
t?S
1l2
t S
0
t?S
1
t?S
1r
t S
0
t?S
1
t?S
1r2
t
Valancy features
S
0
wv
l
S
0
tv
l
S
0
wv
r
S
0
tv
r
S
1
wv
l
S
1
tv
l
S
1
wv
r
S
1
tv
r
Label set features
S
0
ws
r
S
0
ts
r
S
0
ws
l
S
0
ts
l
S
1
ws
l
S
1
ts
l
Proposed new feature templates for the joint model
Guided head features
S
0
w?h
guide
S
0
t?h
guide
S
0
wt?h
guide
S
1
w?h
guide
S
1
t?h
guide
h
guide
Guided label features
S
0
w?S
0
l
guide
S
0
t?S
0
l
guide
S
0
wt?S
0
l
guide
S
1
w?S
0
l
guide
S
1
t?S
0
l
guide
S
0
l
guide
S
0
w?S
1
l
guide
S
0
t?S
1
l
guide
S
0
wt?S
1
l
guide
S
1
w?S
1
l
guide
S
1
t?S
1
l
guide
S
1
l
guide
Table 1: Feature templates for the baseline and joint models, where w denotes the word; t denotes the
POS tag; v
l
and v
r
denote the left and right valencies; l denotes the dependency label; s
l
and s
r
denotes
the label sets of the left and right children; the subscripts l and r denote the left-most and the right-most
children, respectively; the subscripts l2 and r2 denote the second left-most and the second right-most
children, respectively; h
guide
denotes the head direction of the top two elements on the processing stack
in the other tree; l
guide
denotes the label of the same word in the other tree.
build a specific tree of scheme b for the same sentence are A
b
1
A
b
2
? ? ?A
b
n
. We use ST
a
0
ST
a
1
? ? ? ST
a
n
and
ST
b
0
ST
b
1
? ? ? ST
b
n
to denote the historical states for the two action sequences, respectively. A sequence of
actions should consist of A
a
1
A
a
2
? ? ?A
a
n
and A
b
1
A
b
2
? ? ?A
b
n
in a joint model. However, one question that
needs to be answered is that, for a joint state (ST
a
i
,ST
b
j
), which action should be chosen as the next step
to merge the two action sequences into one sequence, A
a
i+1
or A
b
j+1
? To resolve the problem, we employ
a parameter t to limit the next action in the joint model. When t is above zero, an action for scheme b
can be applied only if the last action of scheme a is t steps in advance. For example, the action sequence
is A
a
1
A
b
1
A
a
2
A
b
2
? ? ?A
a
n
A
b
n
when t = 1. t can be negative as well, denoting the reverse constraints.
In the joint model, we extract features separately for the two dependency schemes. When the next
action is aimed for scheme a, we will extract features from S
a
and Q
a
, according to baseline feature
templates in Table 1. In order to make use of the correlations between the two dependency parsing trees,
we introduce several new feature templates, shown in Table 1 referring to proposed new feature templates
for the joint model. The new features are based on two kinds of atomic features: the guided head h
guide
and the guided dependency label l
guide
. Assuming that the currently processing scheme is a, when the
top two elements (S
a
0
and S
a
1
) have both found their heads in Guided
b
(the partial-parsed trees of scheme
b), we can fire the atomic feature h
guide
, which denotes the arc direction between S
0
and S
1
in Guide
b
(S
x
0
S
1
, S
y
0
S
1
or other). When S
a
0
or S
a
1
has its dependency label in Guided
b
, we can fire the atomic
feature l
guide
, which denotes the dependency label of S
a
0
or S
a
1
in Guided
b
. Similarly we can extract the
h
guide
and l
guide
from Guide
a
when we are processing scheme b. When t is infinite, we always have
533
the two atomic features, because the other tree is already parsed. Thus the proposed new features can be
the most effective when t = ? and t = ??. In other conditions, the other tree may not be ready for
the new feature extracting. Similar to the baseline model, we use the beam-search decoding strategy to
reduce the search space, and use the averaged perceptron with early-update to learn the feature weights.
We are especially interested in two cases of the joint models when t is infinite (t =? and t = ??),
where the tree of one specified scheme is always processed after the other tree is finished, because the
new features can be most effectively exploited according to the above analysis. We assume that the first
and second processing schemes are s
1
and s
2
respectively, to facilitate the below descriptions. We can see
that the joint model behaves similarly to a pipeline reranking model, in optimizing scheme s
1
?s parsing
performances. First we get K-best (K equals the beam size of the joint model) candidates for scheme s
1
,
and then employ additional evidences from scheme s
2
?s result, to rerank the K-best candidates, obtaining
a better result. The joint model also behaves similarly to a pipeline feature-based stacking model (Li et
al., 2012), in optimizing scheme s
2
?s parsing performances. After acquiring the best result of scheme
s
1
, we can use it to generate guided features to parse dependencies of scheme s
2
. Thus additional
information from scheme s
1
can be imported into the parsing model of scheme s
2
. Different with the
pipeline reranking and the feature-based stacking models, we employ a single model to achieve the two
goals, making the interactions between the two schemes be better performed.
4 Experiments
4.1 Experimental Settings
In order to evaluate the baseline and joint models, we conduct experiments on English and Chinese da-
ta. For English, we obtain heterogeneous dependencies by the Yamada and the Stanford schemes,
respectively. We transform the bracket constituent trees of English sentences into the Yamada dependen-
cies with the Penn2Malt tool,
1
and into the Stanford dependencies with the Stanford parser version
3.3.1.
2
Following the standard splitting of PTB, we use sections 2-21 as the training data set, section 22 as
the development data set, and section 23 as the final test data set. For Chinese, we obtain heterogeneous
dependencies by the Zhang and the Stanford schemes, respectively. The Zhang dependencies are
obtained by the Penn2Malt tool using the head rules from Zhang and Clark (2008), while the Stanford
dependencies are obtained by the Stanford parser version 3.3.1 similar to English.
We use predicted POS tags in all the experiments. We utilize a linear-CRF POS tagger to obtain
automatic POS tags for English and Chinese datasets.
3
We use a beam size of 64 to train dependency
parsing models. We train the joint models with the Yamada or Zhang dependencies being handled
on stack S
a
and queue Q
a
, and the Stanford dependencies being handled on stack S
b
and queue Q
b
,
referring to Section 3. We follow the standard measures of dependency parsing to evaluate the baseline
and joint models, including unlabeled attachment score (UAS), labeled attachment score (LAS) and
complete match (CM). We ignore the punctuation words for all these measures.
4.2 Development Results
4.2.1 Baseline
Table 2 at the subtable ?Baseline? shows the baseline results on the development data set. The perfor-
mances of the Yamada scheme are better than those of the Stanford scheme. The UAS and LAS of
the Yamada scheme are 92.83 and 91.73 respectively, while they are 92.85 and 90.49 for the Stanford
scheme respectively. The results demonstrate that parsing the Stanford dependencies is more difficult
than parsing the Yamada dependencies because of the lower performances of the Stanford scheme.
1
http://stp.lingfil.uu.se/
?
nivre/research/Penn2Malt.html.
2
The tool is available on http://nlp.stanford.edu/software/lex-parser.shtml. We use three options to
perform the conversion: ?-basic? and ?-keepPunct?, respectively.
3
The tagging accuracies are 97.30% on the English test dataset and 93.68% on the Chinese test dataset. We thank Hao
Zhang for sharing the data used in Martins et al. (2013) and Zhang et al. (2013a).
534
Model
Yamada Stanford
UAS LAS CM UAS LAS CM
Baseline 92.83 91.73 47.35 92.85 90.49 50.06
The joint models,
where the Yamada dependencies are processed with priority
t = 1 92.65 91.55 46.35 93.11 90.75 50.24
t = 2 92.65 91.57 46.71 93.15 90.77 50.59
t = 3 92.82 91.74 47.12 93.19 90.82 50.76
t = 4 92.89 91.78 47.35 93.27 90.93 51.29
t =? 93.04 92.01 48.65 93.52 91.15 52.59
The joint models,
where the Stanford dependencies are processed with priority
t = ?1 92.62 91.54 46.71 93.10 90.70 50.76
t = ?2 92.50 91.41 46.18 93.06 90.74 51.12
t = ?3 92.57 91.42 47.00 93.10 90.68 51.35
t = ?4 92.74 91.60 47.41 93.15 90.72 51.29
t = ?? 93.04 91.95 47.88 93.19 90.91 50.71
Table 2: The main results on the development data set of the baseline and proposed joint models.
4.2.2 Parameter Tuning
The proposed joint model has one parameter t to adjust. The parameter t is used to control the decoding in
a joint model, determining which kind of dependencies should be processed at the next step. In our joint
model, if t is larger than zero, scheme a (the Yamada scheme) should be handled t steps in advance,
while when t is smaller than zero, scheme b (the Stanford scheme) should be handled in advance.
When the value of t is infinite, the dependency tree of one scheme is handled until the dependency tree
of the other scheme is finished for a sentence.
As shown by Table 2, we have two major findings. First, the joint models are slightly better when t is
above zero, by decoding with the Yamada scheme in advance. The phenomenon demonstrates that the
decoding sequence is important in the joint parsing models. Second, no matter when t is above or below
zero, the performances arrive at the peak when t is infinite. One benefit of the joint models is that we
can use the correlations between different dependency trees, through the new features proposed by us.
The new features can be the most effective when t is infinite according to the analysis Section 3. Thus
this finding indicates that the new features are crucial in the joint models, since the ineffective utilization
would decrease the model performances a lot. Actually, when the absolute value of t is small, the features
can sometimes be fired and in some other times are not able to be fired, making the training insufficient
and also inconsistent for certain word-pair dependencies when their distances can differ (when t = 1 for
example, the joint model can fire the new features only if the dependency distance equals 1). This would
make the final model deficient, and can even hurt performances of the Yamada scheme.
According to the results on the development data set, we use the t = ? for the final joint model,
which first finishes the Yamada tree and then the Stanford tree for each sentence. Our final model
achieves increases of 0.21 on UAS and 0.28 on LAS for the Yamada scheme, and increases 0.67 on
UAS and 0.66 on LAS for the Stanford scheme.
4.2.3 Feature Ablation
In order to test the effectiveness of the proposed new features, we conduct a feature ablation experiment.
Table 3 shows the results, where the mark ?/wo? denotes the model without the new features proposed
by us. For the Yamada scheme, losses of 0.15 on UAS and 0.21 on LAS are shown without the new
features. While for Stanford scheme, larger decreases are shown by 0.57 on UAS and 0.58 on LAS,
respectively. The results demonstrate the new features are effective in the joint model.
535
Model
Yamada Stanford
UAS LAS CM UAS LAS CM
Our joint model 93.04 92.01 48.65 93.52 91.15 52.59
Our joint model/wo 92.89 91.80 48.25 92.95 90.57 50.62
? -0.15 -0.21 -0.40 -0.57 -0.58 -1.97
Table 3: Feature ablation results.
Model
Yamada Stanford
UAS LAS CM UAS LAS CM
Baseline 92.71 91.67 47.48 92.72 90.61 47.76
Our joint model 92.89 91.86 48.39 93.30
?
91.19
?
50.37
Zhang and Nivre (2011) 92.9 91.8 48.0 ? ? ?
Rush and Petrov (2012) ? ? ? 92.7
?
? ?
Martins et al. (2013) 93.07 ? ? 92.82
?
? ?
Zhang et al. (2013a) 93.50 92.41 ? 93.64
?
91.28
?
?
Zhang and McDonald (2014) 93.57 92.48 ? 93.71
?
/93.01
??
91.37
?
/90.64
??
?
Kong and Smith (2014) ? ? ? 92.20
??
89.67
??
?
Table 4: The final results on the test data set, where the results with mark
?
demonstrates that the p-value
is below 10
?3
using t-test. Our Stanford dependencies are slightly different with previous works, where
the results with mark
?
show the numbers for the Stanford dependencies from Stanford parser version
2.0.5 and the results with mark
??
show the numbers for the Stanford dependencies from Stanford parser
version 3.3.0.
4.3 Final Results
Table 4 shows our final results on the English test dataset. The final joint model achieves better per-
formances than the baseline models for both the Yamada and the Stanford schemes, by increases
of 0.18 on UAS and 0.19 on LAS for the Yamada scheme, and increases of 0.58 on UAS and 0.58
on LAS for the Stanford scheme. The results demonstrate that the interactions between the two de-
pendency schemes are useful, and the joint model is superior to separately trained models in handling
heterogeneous dependencies.
We compare our results with some representative previous work of dependency parsing as well. Zhang
and Nivre (2011) is a feature-rich transition-based dependency parser using the arc-eager transition sys-
tem. Rush and Petrov (2012), Zhang et al. (2013a) and Zhang and McDonald (2014) are state-of-the-art
graph-based dependency parsers. Martins et al. (2013) and Kong and Smith (2014) report their results
with the full TurboParser. TurboParser is also a graph-based dependency parser but its decoding algo-
rithm has major differences with the general MST-style decoding.
4.4 Analysis
To better understand the joint model, we conduct analysis work on the Chinese development dataset.
First, we make a comparison to see whether the consistent dependencies give larger increases by the
joint model. As mentioned before, the consistent dependencies can be supported by different evidences
from heterogeneous dependencies. We compute the proportion of the consistent dependencies (ignoring
the dependency labels) between the Yamada and the Stanford dependencies, finding that 70.27% of
the overall dependencies are consistent. Table 5 shows the comparison results. The joint model shows
improvements for the consistent dependencies. However, it does not always show positive effectiveness
for the inconsistent dependencies. The results support our initial motivation that consistent dependencies
can benefit much in joint models .
We also make a comparison between the baseline and joint models with respect to dependency dis-
tance. We use the F-measure value to evaluate the performances. The dependency distances are normal-
536
Yamada Stanford
Consistent Inconsistent Consistent Inconsistent
UAS LAS UAS LAS UAS LAS UAS LAS
Baseline 93.43 92.39 91.44 90.17 93.74 91.35 90.75 88.47
Our joint model 93.81 92.85 91.21 90.02 94.58 92.15 91.01 88.78
? +0.38 +0.46 -0.23 -0.15 +0.84 +0.80 +0.36 +0.31
Table 5: Performances of the baseline and joint models by whether the dependencies are consistent
across the Yamada and the Stanford schemes, where the bold numbers denote the larger increases by
comparisons of consistent and inconsistent dependencies for each scheme.
1 2 3 4 5 6 7
75
80
85
90
95
F
-
m
e
a
s
u
r
e
(
%
)
Baseline Joint
(a) Yamada
1 2 3 4 5 6 7
65
75
85
95
F
-
m
e
a
s
u
r
e
(
%
)
Baseline Joint
(b) Stanford
Figure 3: F-measures of the two heterogeneous dependencies with respect to dependency distance.
ized to a max value of 7. Figure 3 shows the comparison results. We find that the joint model can achieve
consistent better performances for the dependencies of different dependency distance, demonstrating the
robustness of the joint model in improving parsing performances. The joint model performs slightly
better for long-distance dependencies, which is more obvious for the Stanford scheme.
4.5 Parsing Heterogeneous Chinese Dependencies
Table 6 shows our final results on the Chinese test data set. For Chinese, the joint model achieves better
performances with Stanford dependencies being parsed first. The final joint model achieves better
performances than the baseline models for both the Zhang and the Stanford schemes, by increases
of 1.13 on UAS and 0.99 on LAS for the Zhang scheme, and increases of 0.30 on UAS and 0.36 on
LAS for the Stanford scheme. The results also demonstrate similar conclusions with the experiments
on English dataset.
5 Related Work
Our work is mainly inspired by the work of joint models. There are a number of successful studies
on joint modeling pipelined tasks where one task is a prerequisite step of another task, for example,
the joint model of word segmentation and POS-tagging (Jiang et al., 2008; Kruengkrai et al., 2009;
Zhang and Clark, 2010), the joint model of POS-tagging and parsing (Li et al., 2011; Hatori et al., 2011;
Bohnet and Nivre, 2012), the joint model of word segmentation, POS-tagging and parsing (Hatori et
Model
Zhang Stanford
UAS LAS CM UAS LAS CM
Baseline 79.07 76.08 27.96 80.33 75.29 31.14
Our joint model 80.20
?
77.07
?
30.10 80.63 75.65 31.20
Table 6: The final results on the test data set, where the results with mark
?
demonstrates that the p-value
is below 10
?3
using t-test.
537
al., 2012; Zhang et al., 2013b; Zhang et al., 2014), and the joint model of morphological and syntactic
analysis tasks (Bohnet et al., 2013). In our work, we propose a joint model on parallel tasks, to parse two
heterogeneous dependency trees simultaneously.
There has been a line of work on exploiting multiple treebanks with heterogeneous dependencies to
enhance dependency parsing. Li et al. (2012) proposed a feature-based stacking model to enhance a
specific target dependency parser with the help of another treebank. Zhou and Zhao (2013) presented
a joint inference framework to combine the parsing results based on two different treebanks. All these
work are case studies of annotation adaptation from different sources, which have been done for Chinese
word segmentation and POS-tagging as well (Jiang et al., 2009; Sun and Wan, 2012). In contrast to their
work, we study the heterogeneous annotations derived from the same source. We use a unified model to
parsing heterogeneous dependencies together.
Our joint parsing model exploits a transition-based framework with global learning and beam-search
decoding (Zhang and Clark, 2011), extended from a arc-standard transition-based parsing model (Huang
et al., 2009). The transition-based framework is easily adapted to a number of joint models, including
joint word segmentation and POS-tagging (Zhang and Clark, 2010), the joint POS-tagging and parsing
(Hatori et al., 2012; Bohnet and Nivre, 2012), and also joint word segmentation, POS-tagging and parsing
(Hatori et al., 2012; Zhang et al., 2013b; Zhang et al., 2014).
6 Conclusions
We studied the effectiveness of the correlations between different constituent-to-dependency schemes
for dependency parsing, by exploiting these information with a joint model to parse two heterogeneous
dependency trees simultaneously. We make a novel extension to a transition-based arc-standard depen-
dency parsing algorithm for the joint model. We evaluate our baseline and joint models on both English
and Chinese datasets, based on the Yamada/Zhang and the Stanford dependency schemes. Final
results demonstrate that the joint model which handles two heterogeneous dependencies can give im-
proved performances for dependencies of both schemes. The source code for the joint model is publicly
available at http://sourceforge.net/projects/zpar/,version0.7.
Acknowledgments
We thank Yue Zhang and the anonymous reviewers for their constructive comments, and grateful-
ly acknowledge the support of the National Basic Research Program (973 Program) of China via
Grant 2014CB340503, the National Natural Science Foundation of China (NSFC) via Grant 61133012,
61170144 and 61370164.
References
Bernd Bohnet and Joakim Nivre. 2012. A transition-based system for joint part-of-speech tagging and labeled
non-projective dependency parsing. In Proceedings of the EMNLP-CONLL, pages 1455?1465, Jeju Island,
Korea, July.
Bernd Bohnet, Joakim Nivre, Igor Boguslavsky, Rich?ard Farkas Filip Ginter, and Jan Hajic. 2013. Joint morpho-
logical and syntactic analysis for richly inflected languages. TACL, 1.
Jinho D. Choi and Andrew McCallum. 2013. Transition-based dependency parsing with selectional branching. In
Proceedings of ACL, pages 1052?1062, August.
Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of the
ACL, pages 111?118, Barcelona, Spain, July.
Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representa-
tion. In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,
pages 1?8, Manchester, UK, August.
Jakob Elming, Anders Johannsen, Sigrid Klerke, Emanuele Lapponi, Hector Martinez Alonso, and Anders
S?gaard. 2013. Down-stream effects of tree-to-dependency conversions. In Proceedings of the NAACL, pages
617?626, Atlanta, Georgia, June.
538
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii. 2011. Incremental joint POS tagging and
dependency parsing in Chinese. In Proceedings of 5th IJCNLP, pages 1216?1224, Chiang Mai, Thailand,
November.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii. 2012. Incremental joint approach to word
segmentation, POS tagging, and dependency parsing in Chinese. In Proceedings of the 50th ACL, pages 1045?
1053, Jeju Island, Korea, July.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In
Proceedings of the EMNLP, pages 1222?1231.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?u. 2008. A cascaded linear model for joint Chinese word
segmentation and part-of-speech tagging. In Proceedings of ACL-08, pages 897?904, Columbus, Ohio, June.
Wenbin Jiang, Liang Huang, and Qun Liu. 2009. Automatic adaptation of annotation standards: Chinese word
segmentation and POS tagging: a case study. In Proceedings of the ACL-IJCNLP, pages 522?530.
Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for english. In
Proceedings of NODALIDA 2007, Tartu, Estonia.
Lingpeng Kong and Noah A Smith. 2014. An empirical comparison of parsing methods for stanford dependencies.
arXiv preprint arXiv:1404.4314.
Terry Koo and Michael Collins. 2010. Efficient third-order dependency parsers. In Proceedings of the 48th Annual
Meeting of the ACL, pages 1?11.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichi Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi Isahara.
2009. An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging. In
Proceedings of the ACL-IJCNLP, pages 513?521, Suntec, Singapore, August.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang Chen, and Haizhou Li. 2011. Joint models for
Chinese POS tagging and dependency parsing. In Proceedings of the EMNLP, pages 1180?1191, Edinburgh,
Scotland, UK., July.
Zhenghua Li, Ting Liu, and Wanxiang Che. 2012. Exploiting multiple treebanks for parsing with quasi-
synchronous grammars. In Proceedings of the 50th ACL, pages 675?684, Jeju Island, Korea, July.
Andre Martins, Miguel Almeida, and Noah A. Smith. 2013. Turning on the turbo: Fast third-order non-projective
turbo parsers. In Proceedings of the 51st ACL, pages 617?622, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency
parsers. In Proceedings of ACL, number June, pages 91?98, Morristown, NJ, USA.
Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In
Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL, pages 915?932.
Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics,
34(4):513?553.
Alexander M Rush and Slav Petrov. 2012. Vine pruning for efficient multi-pass dependency parsing. In Proceed-
ings of the NAACL, pages 498?507.
Francesco Sartorio, Giorgio Satta, and Joakim Nivre. 2013. A transition-based dependency parser using a dynamic
parsing strategy. In Proceedings of the 51st ACL, pages 135?144, Sofia, Bulgaria, August.
Weiwei Sun and Xiaojun Wan. 2012. Reducing approximation and estimation errors for Chinese lexical processing
with heterogeneous annotations. In Proceedings of the 50th ACL, pages 232?241, Jeju Island, Korea, July.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In
Proceedings of IWPT, volume 3.
Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings of EMNLP, pages 562?571, Honolulu, Hawaii, October.
Yue Zhang and Stephen Clark. 2010. A fast decoder for joint word segmentation and POS-tagging using a single
discriminative model. In Proceedings of the EMNLP, pages 843?852, Cambridge, MA, October.
539
Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search.
Computational Linguistics, 37(1):105?151.
Hao Zhang and Ryan McDonald. 2012. Generalized higher-order dependency parsing with cube pruning. In
Proceedings of the EMNLP, pages 320?331.
Hao Zhang and Ryan McDonald. 2014. Enforcing structural diversity in cube-pruned dependency parsing. In
Proceedings of ACL. Association for Computational Linguistics.
Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Pro-
ceedings of the 49th ACL, pages 188?193, Portland, Oregon, USA, June.
Hao Zhang, Liang Huang, Kai Zhao, and Ryan McDonald. 2013a. Online learning for inexact hypergraph search.
In Proceedings of the EMNLP, pages 908?913, Seattle, Washington, USA, October. Association for Computa-
tional Linguistics.
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu. 2013b. Chinese parsing exploiting characters. In
Proceedings of the 51st ACL, pages 125?134, Sofia, Bulgaria, August.
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu. 2014. Character-level Chinese Dependency Parsing.
In Proceedings of the 52st ACL.
Guangyou Zhou and Jun Zhao. 2013. Joint inference for heterogeneous dependency parsing. In Proceedings of
the 51st ACL, pages 104?109, Sofia, Bulgaria, August.
540
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 588?597,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
Type-Supervised Domain Adaptation for Joint Segmentation and
POS-Tagging
Meishan Zhang
?
, Yue Zhang
?
, Wanxiang Che
?
, Ting Liu
??
?
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{mszhang, car, tliu}@ir.hit.edu.cn
?
Singapore University of Technology and Design
yue zhang@sutd.edu.sg
Abstract
We report an empirical investigation on
type-supervised domain adaptation for
joint Chinese word segmentation and
POS-tagging, making use of domain-
specific tag dictionaries and only un-
labeled target domain data to improve
target-domain accuracies, given a set of
annotated source domain sentences. Pre-
vious work on POS-tagging of other lan-
guages showed that type-supervision can
be a competitive alternative to token-
supervision, while semi-supervised tech-
niques such as label propagation are
important to the effectiveness of type-
supervision. We report similar findings
using a novel approach for joint Chinese
segmentation and POS-tagging, under a
cross-domain setting. With the help of un-
labeled sentences and a lexicon of 3,000
words, we obtain 33% error reduction in
target-domain tagging. In addition, com-
bined type- and token-supervision can lead
to improved cost-effectiveness.
1 Introduction
With accuracies of over 97%, POS-tagging of
WSJ can be treated as a solved problem (Man-
ning, 2011). However, performance is still well
below satisfactory for many other languages and
domains (Petrov et al., 2012; Christodoulopoulos
et al., 2010). There has been a line of research on
using a tag-dictionary for POS-tagging (Merialdo,
1994; Toutanova and Johnson, 2007; Ravi and
Knight, 2009; Garrette and Baldridge, 2012). The
idea is compelling: on the one hand, a list of lex-
icons is often available for special domains, such
as bio-informatics; on the other hand, compiling a
?
Corresponding author.
lexicon of word-tag pairs appears to be less time-
consuming than annotating full sentences.
However, success in type-supervised POS-
tagging turns out to depend on several subtle fac-
tors. For example, recent research has found that
the quality of the tag-dictionary is crucial to the
success of such methods (Banko and Moore, 2004;
Goldberg et al., 2008; Garrette and Baldridge,
2012). Banko and Moore (2004) found that the
accuracies can drop from 96% to 77% when a
hand-crafted tag dictionary is replaced with a raw
tag dictionary gleaned from data, without any hu-
man intervention. These facts indicate that careful
considerations need to be given for effective type-
supervision. In addition, significant manual work
might be required to ensure the quality of lexicons.
To compare type- and token-supervised tagging,
Garrette and Baldridge (2013) performed a set of
experiments by conducting each type of annota-
tion for two hours. They showed that for low-
resource languages, a tag-dictionary can be rea-
sonably effective if label propagation (Talukdar
and Crammer, 2009) and model minimizations
(Ravi and Knight, 2009) are applied to expand and
filter the lexicons. Similar findings were reported
in Garrette et al. (2013).
Do the above findings carry over to the Chi-
nese language? In this paper, we perform an
empirical study on the effects of tag-dictionaries
for domain adaptation of Chinese POS-tagging.
We aim to answer the following research ques-
tions: (a) Is domain adaptation feasible with only
a target-domain lexicon? (b) Can we further im-
prove type-supervised domain adaptation using
unlabeled target-domain sentences? (c) Is craft-
ing a tag dictionary for domain adaptation more
effective than manually annotating target domain
sentences, given similar efforts?
Our investigations are performed under two
Chinese-specific settings. First, unlike low-
resource languages, large amounts of annotation
588
are available for Chinese. For example, the Chi-
nese Treebank (CTB) (Xue et al., 2005) contains
over 50,000 manually tagged news sentences.
Hence rather than studying purely type-supervised
POS-tagging, we make use of CTB as the source
domain, and study domain adaptation to the Inter-
net literature.
Second, one uniqueness of Chinese POS-
tagging, in contrast to the POS-tagging of alpha-
betical languages, is that word segmentation can
be performed jointly to avoid error propagation
(Ng and Low, 2004; Zhang and Clark, 2008; Kru-
engkrai et al., 2009; Zhang and Clark, 2010). We
adopt this approach for a strong baseline. Previous
studies showed that unsupervised domain adap-
tation can give moderate improvements (Liu and
Zhang, 2012). We show that accuracies can be
much more significantly improved by using target-
domain knowledge in the form of lexicons.
Both token-supervised and type-supervised do-
main adaptation rely on a set of source-domain
annotations; while the former makes additional
use of a small set of target annotations, the lat-
ter leverages a target-domain lexicon. We take
a feature-based method, analogous to that of
Daume III (2007), which tunes domain-dependent
versions of features using domain-specific data.
Our method tunes a set of lexicon-based features,
so that domain-dependent models are derived from
inserting domain-specific lexicons.
The conceptually simple method worked highly
effectively on a test set of 1,394 sentences from
the Internet novel ?Zhuxian?. Combined with
the use of unlabeled data, a tag lexicon of 3,000
words gave a 33% error reduction when com-
pared with a strong baseline system trained using
CTB data. We observe that joint use of type- and
token-supervised domain adaptation is more cost-
effective than pure type- or token-supervision.
With 10 hours of annotation, the best error reduc-
tion reaches 47%, with F-score increasing from
80.81% to 89.84%.
2 Baseline
We take as the baseline system a discriminative
joint segmentation and tagging model, proposed
by Zhang and Clark (2010), together with simple
self-training (Liu and Zhang, 2012). While the
baseline discriminative model gives state-of-the-
art joint segmentation and tagging accuracies on
CTB data, the baseline self-training makes use of
unlabeled target domain data to find improved tar-
get domain accuracies over bare CTB training.
2.1 The Baseline Discriminative Chinese
POS-Tagging Model
The baseline discriminative model performs
segmentation and POS-tagging simultaneously.
Given an input sentence c
1
? ? ? c
n
(c
i
refers to the
ith character in the sentence), it operates incre-
mentally, from left to right. At each step, the cur-
rent character can either be appended to the last
word of the existing partial output, or seperated as
the start of a new word with tag p. A beam is used
to maintain the N-best partial results at each step
during decoding. At step i (0 ? i < n), each
item in the beam corresponds to a segmentation
and POS-tagging hypothesis for the first i?1 char-
acters, with the last word being associated with a
POS, but marked as incomplete. When the next
character c
i
is processed, it is combined with all
the partial results from the beam to generate new
partial results, using two types of actions: (1) Ap-
pend, which appends c
i
to the last (partial) word
in a partial result; (2) Separate(p), which makes
the last word in the partial result as completed and
adds c
i
as a new partial word with a POS tag p.
Partial results in the beam are scored globally
over all actions used to build them, so that the N-
best can be put back to the agenda for the next step.
For each action, features are extracted differently.
We use the features from Zhang and Clark (2010).
Discriminative learning with early-update (Collins
and Roark, 2004; Zhang and Clark, 2011) is used
to train the model with beam-search.
2.2 Baseline Unsupervised Adaptation by
Self-Training
A simple unsupervised approach for POS-tagging
with unlabeled data is EM. For a generative model
such as HMM, EM can locally maximize the like-
lihood of training data. Given a good start, EM
can result in a competitive HMM tagging model
(Goldberg et al., 2008).
For discriminative models with source-domain
training examples, an initial model can be trained
using the source-domain data, and self-training
can be applied to find a locally-optimized model
using raw target domain sentences. The training
process is sometimes associated with the EM al-
gorithm. Liu and Zhang (2012) used perplexities
of character trigrams to order unlabeled sentences,
and applied self-training to achieve a 6.3% error
589
Common
Lexicon
Source
Lexicon
Source
Corpus
Training
Model
Target
Sentences
Target
Lexicon
Common
Lexicon
Tagging
Tagging
Results
Training Tagging
Figure 1: Architecture of our lexicon-based model for domain adaptation.
reduction on target-domain data when compared
with source domain training. Their method is sim-
ple to implement, and we take it as our baseline.
3 Type-Supervised Domain Adaptation
To give a formal definition of the domain adap-
tation tasks, we denote by C
s
a set of anno-
tated source-domain sentences, C
t
a set of anno-
tated target-domain sentences, and L
t
an anno-
tated target-domain lexicon. The form of L
t
is a
list of target-domain words, each associated with
a set of POS tags. Token-supervised domain adap-
tation is the task of making use of C
s
and C
t
to
improve target-domain performances, while type-
supervised domain adaptation is to make use of C
s
and L
t
instead for the same purpose.
As described in the introduction, type-
supervised domain adaptation is useful when
annotated sentences are absent, but lexicons are
available. In addition, it is an interesting question
which type of annotation is more cost-effective
when neither is available. We empirically com-
pare the two approaches by proposing a novel
method for type-supervised domain adaptation of
a discriminate tagging model, showing that it can
be a favourable choice in practical situation.
In particular, we split Chinese words into
domain-independent and domain-specific cate-
gories, and define unlexicalized features for
domain-specific words. We train lexicalized
domain-independent and unlexicalized domain-
specific features using the source domain anno-
tated sentences and a source-domain lexicon, and
then apply the resulting model to the target do-
main by replacing the source-domain lexicon with
a target domain lexicon. Combined with unsu-
pervised learning with unlabeled target-domain
of sentences, the conceptually simple method
worked highly effectively. Following Garrette and
Baldridge (2013), we address practical questions
on type-supervised domain adaptation by compar-
ison with token-supervised methods under similar
human annotation efforts.
3.1 System Architecture
Our method is based on the intuition that domain-
specific words of certain types (e.g. proper names)
can behave similarly across domains. For exam-
ple, consider the source-domain sentence ???
?|NR (Jiang Zemin) ??|AD (afterwards) ?
?|VV (visit) ??|NR (Shanghai Automobiles
Corp.)? and the target-domain sentence ??
?|NR (Biyao) ??|AD (afterwards) ??|VV
(arrive) ???|NR (the Bamboo Mountains)?.
???? (Jiang Zemin)? and ??? (Biyao)? are
person names in the two domains, respectively,
whereas ??? (Shanghai Automobiles Corp.)?
and ???? (the Bamboo Mountains)? are loca-
tion names in the two domains, respectively. If the
four words are simply treated as domain-specific
nouns, the two sentences both have the pattern
??domain-NR? AD VV ?domain-NR??, and hence
source domain training data can be useful in train-
ing the distributions of the lexicon-based features
for both domains.
Further, we assume that the syntax structures
and the usage of function words do not vary sig-
nificantly across domains. For example, verbs, ad-
jectives or proper nouns can be different from do-
main to domain, but the subject-verb-object sen-
tence structure does not change. In addition, the
usage of closed-set function words remains sta-
ble across different domains. In the CTB tagset,
closed-set POS tags are the vast majority. Under
this assumption, we introduce a set of unlexical-
ized features into the discriminative model, in or-
der to capture the distributions of domain-specific
dictionary words. Unlexicalized features trained
for source domain words can carry over to the tar-
get domain. The overall architecture of our sys-
590
Action Lexicon Feature templates
Separate in-lex(w
?1
), l(w
?1
) ? in-lex(w
?1
),
in-lex(w
?1
, t
?1
), l(w
?1
) ? in-lex(w
?1
, t
?1
)
Table 1: Dictionary features of the type-
supervised model, where w
?1
and t
?1
denote the
last word and POS tag of a partial result, re-
spectively; l(w) denotes the length of the word
w; in-lex(w, t) denotes whether the word-tag pair
(w, t) is in the lexicon.
tem is shown in Figure 1, where lexicons can be
treated as ?plugins? to the model for different do-
mains, and one model trained from the source do-
main can be applied to many different target do-
mains, as long as a lexicon is available.
The method can be the most effective
when there is a significant amount of domain-
independent words in the data, which provide rich
lexicalized contexts for estimating unlexicalized
features for domain-specific words. For scientific
domains (e.g. the biomedical domain) which
share a significant proportion of common words
with the news domain, and have most domain
specific words being nouns (e.g. ???? (dia-
betes)?), the method can be the most effective.
We choose a comparatively difficult domain pair
(e.g. modern news v.s. ancient style novel),
for which the use of many word types are quite
different. Results on this data can be relatively
more indicative of the usefulness of the method.
3.2 Lexicon-Based Features
Table 1 shows the set of new unlexicalized fea-
tures for the domain-specific lexicons. In addition
to words and POS tags, length information is also
encoded in the features, to capture different dis-
tributions of different word sizes. For example,
a one-character word in the dictionary might not
be identified as confidently using the lexicon as a
three-character word in the dictionary.
To acquire a domain-specific lexicon for the
source domain, we use HowNet (Dong and
Dong, 2006) to classify CTB words into domain-
independent and domain-specific categories. Con-
sisting of semantic information for nearly 100,000
common Chinese words, HowNet can serve as a
resource of domain-independent Chinese words.
We choose out of all words in the source domain
training data those that also occur in HowNet for
domain-independent words, and out of the remain-
ing words those that occur more than 3 times for
words specific to the source domain. We assume
that the domain-independent lexicon applies to all
target domains also. For some target domains,
we can obtain domain-specific terminologies eas-
ily from the Internet. However, this can be a very
small portion depending on the domain. Thus, it
may still be necessary to obtain new lexicons by
manual annotation.
3.3 Lexicon and Self-Training
The lexicon-based features can be combined with
unsupervised learning to further improve target-
domain accuracies. We apply self-training on top
of the lexicon-based features in the following way:
we train a lexicon-based model M using a lexi-
con L
s
of the source domain, and then apply M
together with a target-domain lexicon L
t
to auto-
matically label a set of target domain sentences.
We combine the automatically labeled target sen-
tences with the source-domain training data to ob-
tain an extended set of training data, and train a
final model M
self
, using the lexicon L
s
and L
t
for
source- and target-domain data, respectively.
Different numbers of target domain sentences
can be used for self-training. Liu and Zhang
(2012) showed that an increased amount of tar-
get sentences do not constantly lead to improved
development accuracies. They use character per-
plexity to order target domain sentences, taking
the top K sentences for self-training. They eval-
uate the optimal development accuracies using a
range of different Kvalues, and select the best K
for a final model. This method gave better results
than using sentences in the internet novel in their
original order (Liu and Zhang, 2012). We follow
this method in ranking target domain sentences.
4 Experiments
4.1 Setting
We use annotated sentences from the CTB5 for
source-domain training, splitting the corpus into
training, development and test sections in the same
way as previous work (Kruengkrai et al., 2009;
Zhang and Clark, 2010; Sun, 2011).
Following Liu and Zhang (2012), we use the
free Internet novel ?Zhuxian? (henceforth referred
to as ZX; also known as ?Jade dynasty?) as our tar-
get domain data. The writing style of the novel is
in the literature genre, with the style of Ming and
Qing novels, very different from news in CTB. Ex-
591
CTB sentences ZX sentences
?????????? ??????????????????????
(Qiaoshi meets the Russian delegates.) (The world was big. It held everything. There were fascinating
?????????????? landscapes. There were haunting ghosts.)
(Lipeng stressed on speeding the reform of official regulations.) ??????????????
?????????????? (No time left. Let me call out Zhuxian, the ancient sword.)
(Chinese chemistry industry increases the pace of opening up.) ???????????????(There came suddenly
a gust of wind, out of which was laughters and magic flashes.)
Table 2: Example sentences from CTB and ZX to illustrate the differences between news and novel.
Data Set Chap. IDs # sents # words
CTB5
Train 1-270, 400-931, 10,086 493,930
1001-1151
Devel 301-325 350 6,821
Test 271-300 348 8,008
ZX
Train 6.6-6.10, 2,373 67,648
7.6-7.10, 19
Devel 6.1-6.5 788 20,393
Test 7.1-7.5 1,394 34,355
Table 3: Corpus statistics.
ample sentences from the two corpora are shown
in Table 2. Liu and Zhang (2012) manually anno-
tated 385 sentences as development and test data,
which we download from their website.
1
These
data follow the same annotation guidelines as the
Chinese Treebank (Xue et al., 2000).
To gain more reliable statistics in our results,
we extend their annotation work to a total 4,555
sentences, covering the sections 6, 7 and 19 of the
novel. The annotation work is based on the auto-
matically labeled sentences by our baseline model
trained with CTB5 corpus. It took an experienced
native speaker 80 hours, about one minute on av-
erage to annotate one sentence. We use chapters
1-5 of section 6 as the development data, chap-
ters 1-5 of section 7 as the test data, and the re-
maining data for target-domain training,
2
in order
to compare type-supervised methods with token-
supervised methods. Under permission from the
author of the novel, we release our annotation for
future reference. Statistics of both the source and
the target domain data are shown in Table 3. The
rest of the novel is treated as unlabeled sentences,
used for type-annotation and self-training.
We perform the standard evaluation, using F-
scores for both the segmentation accuracy and the
1
http://faculty.sutd.edu.sg/?yue zhang/emnlp12yang.zip
2
We only use part of the training sentences in our experi-
ments, and the remaining can be used for further research.
overall segmentation and POS tagging accuracy.
4.2 Baseline Performances
The baseline discriminative model can achieve
state-of-the-art performances on the CTB5, with
a 97.62% segmentation accuracy and a 93.85% on
overall segmentation and tagging accuracy. Using
the CTB model, the performance on ZX drops sig-
nificantly, to a 87.71% segmentation accuracy and
a 80.81% overall accuracy. Applying self-training,
the segmentation and overall F-scores can be im-
proved to 88.62% and 81.94% respectively.
4.3 Development Experiments
In this section, we study type-supervised domain
adaptation by conducting a series of experiments
on the development data, addressing the follow-
ing questions. First, what is the influence of tag-
dictionaries through lexicon-based features? Sec-
ond, what is the effect of type-supervised domain
adaptation in contrast to token-supervised domain
adaptation under the same annotation cost? Third,
what is the interaction between tag-dictionary and
self-training? Finally, what is the combined effect
of type- and token-supervised domain adaptation?
4.3.1 The Influence of The Tag Dictionary
We investigate the effects of two different tag dic-
tionaries. The first dictionary contains names of
characters (e.g. ?? (Guili)) and artifacts (e.g.
swords such as?? (Dragonslayer)) in the novel,
which are obtained from an Internet Encyclope-
dia,
3
and requires little human effort. We ex-
tracted 159 words from this page, verified them,
and put them into a tag dictionary. We associate
every word in this tag dictionary with the POS
?NR (proper noun)?, and name the lexicon by NR.
The second dictionary was constructed man-
ually, by first employing our baseline tagger to
tag the unlabeled ZX sentences automatically,
3
http://baike.baidu.com/view/18277.htm
592
Model
Target-Domain
Cost
Supervised +Self-Training
Resources SEG POS SEG POS ER
Baseline ? 0 89.77 82.92 90.35 83.95 6.03
Type-Supervision
NR(T) 0 89.84 83.91 91.18 85.22 8.14
3K(T) 5h 91.93 86.53 92.86 87.67 8.46
ORACLE(T) ? 93.10 88.87 94.00 89.91 9.34
Token-Supervision
300(S) 5h 92.59 86.86 93.33 87.85 7.53
600(S) 10h 93.19 88.13 93.81 89.01 7.41
900(S) 15h 93.53 88.53 94.15 89.33 6.97
Combined 3K(T) + 300(S) 10h 93.49 88.54 94.00 89.21 5.85
Type- and Token-Supervision 3K(T) + 600(S) 15h 93.98 89.27 94.61 89.87 5.59
Table 4: Development test results, where Cost denotes the cost of type- or token-annotation measured
by person hours, ER denotes the error reductions of overall performances brought by self-training, T
denotes type-annotation and S denotes token-annotation.
and then randomly selecting the words that are
not domain-independent for an experienced native
speaker to annotate. To facilitate comparison with
token-supervision, we spent about 5 person hours
in annotating 3,000 word-tag pairs, at about the
same cost as annotating 300 sentences. Finally we
conjoined the 3,000 word-tag pairs with the NR
lexicon, and name the resulting lexicon by 3K.
For the target domain, we mark the words from
both NR and 3K as the domain-specific lexicons.
In all experiments, we use the same domain-
independent lexicon, which is extracted from the
source domain training data by HowNet matching.
The accuracies are shown in Table 4, where
the NR lexicon improved the overall F-score
slightly over the baseline, and the larger lexicon
3K brought more significant improvements. These
experiments agree with the intuition that the size
and the coverage of the tag dictionary is impor-
tant to the accuracies. To understand the extent to
which a lexicon can improve the accuracies, we
perform an oracle test, in which lexicons in the
gold-standard test outputs are included in the dic-
tionary. The accuracy is 88.87%.
4.3.2 Comparing Type-Supervised and
Token-Supervised Domain Adaptation
Table 4 shows that the accuracy improvement by
3,000 annotated word-tag pairs (86.53%) is close
to that by 300 annotated sentences (86.86%). This
suggest that using our method, type-supervised
domain adaptation can be a competitive choice to
the token-supervised methods.
The fact that the token-supervised model gives
slightly better results than our type-annotation
method under similar efforts can probably be ex-
0.6 0.7 0.8 0.9 1
0.6
0.7
0.8
0.9
1
Token-Supervision with 300(S)
T
y
p
e
-
S
u
p
e
r
v
i
s
i
o
n
w
i
t
h
3
K
(
T
)
Figure 2: Sentence accuracy comparisons for
type- and token-supervision with equal cost.
plained by the nature of domain differences. Texts
in the Internet novel are different with CTB news
in not only the vocabulary, but also POS n-gram
distributions. The latter cannot be transferred from
the source-domain training data directly. Texts
from domains such as modern-style novels and
scientific articles might have more similar POS
distributions to the CTB data, and can potentially
benefit more from pure lexicons. We leave the ver-
ification of this intuition to future work.
4.3.3 Making Use of Unlabeled Sentences
Both type- and token-supervised domain adapta-
tion methods can be further improved via unla-
beled target sentences. We apply self-training to
both methods, and find improved results across the
board in Table 4. The results indicate that unla-
beled data is useful in further improving both type-
and token-supervised domain adaptation.
593
Interestingly, the effects of the two methods
on self-training are slightly different. The er-
ror reduction by self-training improves from 6.0%
(baseline) to averaged 7.3% and 8.6% for token-
and type-supervised adaptation, respectively. The
better effect for the type-supervised method may
result from comparatively more uniform cover-
age of the lexicon on sentences, since the target-
domain lexicon is annotated by selecting words
from much more than 300 sentences.
4.3.4 Combined Model of Type- and
Token-Supervision
Figure 2 shows the F-scores of each development
test sentence by type- and token-supervised do-
main adaptation with 5 person hours, respectively.
It indicates that the two methods make different
types of errors, and can potentially be used jointly
for better improvements. We conduct a set of ex-
periments as shown in Table 4, finding that the
combined type- and token-supervised model with
lexicon 3K and 300 labeled sentences achieves
an overall accuracy of 88.54%, exceeding the ac-
curacies of both the type-supervised model with
lexicon 3K and the token-supervised model with
300 labeled sentences. Similar observation can
be found for the combined model with lexicon 3K
and 600 labeled sentences. If combined with self-
training, the same fact can be observed.
More interestingly, the combined model also
exceeds pure type- and token-supervised mod-
els with the same annotation cost. For exam-
ple, the combined model with 3K and 300 la-
beled sentences gives a better accuracy than the
token-supervised model with 600 sentences, with
or without self-training. Similar observations hold
between the combined model with 3K and 600 la-
beled sentences and the token-supervised model
with 900 sentences. The results suggest that the
most cost-effective approach for domain adapta-
tion can be combined type- and token-supervision:
after annotating a set of raw sentences, one could
stop to annotate some words, rather than continu-
ing sentence annotation.
4.4 Final Results
Table 5 shows the final results on test corpus
within ten person hours? annotation. With five per-
son hours (lexicon 3K), the type-supervised model
gave an error reduction of 32.99% compared with
the baseline. The best result was obtained by the
combined type- and token-supervised model, with
SEG POS ER Time
Baseline 87.71 80.81 0.00 0
Baseline+Self-Training 88.62 81.94 5.89 0
Type-Supervision
NR(T) 88.34 82.54 9.02 0
NR(T)+ Self-Training 89.52 83.93 16.26 0
3K(T) 91.11 86.04 27.25 5h
3K(T)+Self-Training 92.11 87.14 32.99 5h
Token-Supervision
300(S) 92.44 86.87 31.58 5h
300(S)+Self-Training 93.24 87.48 34.76 5h
600(S) 93.09 88.05 37.73 10h
600(S)+Self-Training 93.77 88.78 41.53 10h
Combined Type- and Token-Supervision
3K(T)+300(S) 93.27 89.03 42.83 10h
3K(T)+300(S)+Self-Training 93.98 89.84 47.06 10h
Table 5: Final results on test set within ten per-
son hours? annotation, where ER denotes the over-
all error reductions compared with the baseline
model, Time denotes the cost of type- or token-
annotation measured by person hours, T denotes
type-annotation and S denotes token-annotation.
an error reduction of 47.06%, higher than that the
token-supervised model with the same cost under
the same setting (the model of 600 labeled sen-
tences with an error reduction of 41.53%). The
results confirm that the type-supervised model
is a competitive alternative for joint segmenta-
tion and POS-tagging under the cross-domain set-
ting. Combined type- and token-supervised model
yields better results than single models.
5 Related Work
As mentioned in the introduction, tag dictionaries
have been applied to type-supervised POS tagging
of English (Toutanova and Johnson, 2007; Gold-
water and Griffiths, 2007; Ravi and Knight, 2009;
Garrette and Baldridge, 2012), Hebrew (Goldberg
et al., 2008), Kinyarwanda and Malagasy (Gar-
rette and Baldridge, 2013; Garrette et al., 2013),
and other languages (T?ackstr?om et al., 2013).
These methods assume that lexicon can be ob-
tained by manual annotation or semi-supervised
learning, and use the lexicon to induce tag se-
quences on unlabeled sentences. We study type-
supervised Chinese POS-tagging, but under the
setting of domain adaptation. The problem is
how to leverage a target domain lexicon and an
available annotated resources in a different source
domain to improving POS-tagging. Consistent
594
with Garrette et al. (2013), we also find that the
type-supervised method is a competitive choice to
token-supervised adaptation.
There has been a line of work on using graph-
based label propagation to expand tag-lexicons for
POS-tagging (Subramanya et al., 2010; Das and
Petrov, 2011). Similar methods have been ap-
plied to character-level Chinese tagging (Zeng et
al., 2013). We found that label propagation from
neither the source domain nor auto-labeled target
domain sentences can improve domain adaptation.
The main reason could be significant domain dif-
ferences. Due to space limitations, we omit this
negative result in our experiments.
With respect to domain adaptation, existing
methods can be classified into three categories.
The first category does not explicitly model dif-
ferences between the source and target domains,
but use standard semi-supervised learning meth-
ods with labeled source domain data and unla-
beled target domain data (Dai et al., 2007; Raina
et al., 2007). The baseline self-training ap-
proach (Liu and Zhang, 2012) belongs to this cat-
egory. The second considers the differences in the
two domains in terms of features (Blitzer et al.,
2006; Daume III, 2007), classifying features into
domain-independent source domain and target do-
main groups and training these types consistently.
The third considers differences between the dis-
tributions of instances in the two domains, treat-
ing them differently (Jiang and Zhai, 2007). Our
type-supervised method is closer to the second cat-
egory. However, rather than splitting features into
domain-independent and domain-specific types,
we use domain-specific dictionaries to capture do-
main differences, and train a model on the source
domain only. Our method can be treated as an ap-
proach specific to the POS-tagging task.
With respect to Chinese lexical analysis, lit-
tle previous work has been reported on using a
tag dictionary to improve joint segmentation and
POS-tagging. There has been work on using a
lexicon in improving segmentation in a Chinese
analysis pipeline. Peng et al. (2004) used fea-
tures from a set of Chinese words and characters
to improve CRF-based segmentation; Low et al.
(2005) extracted features based on a Chinese lex-
icon from Peking University to help a maximum
segmentor; Sun (2011) collected 12,992 idioms
from Chinese dictionaries, and used them for rule-
based pre-segmentation; Hatori et al. (2012) col-
lected Chinese words from HowNet and the Chi-
nese Wikipedia to enhance segmentation accura-
cies of their joint dependency parsing systems. In
comparison with their work, our lexicon contain
additional POS information, and are used for word
segmentation and POS-tagging simultaneously. In
addition, we separate domain-dependent lexicons
for the source and target lexicons, and use a novel
framework to perform domain adaptation.
Wang et al. (2011) collect word-tag statistics
from automatically labeled texts, and use them as
features to improve POS-tagging. Their word-tag
statistics can be treated as a type of lexicon. How-
ever, their efforts differ from ours in several as-
pects: (1) they focus on in-domain POS-tagging,
while our concern is cross-domain tagging; (2)
they study POS-tagging on segmented sentences,
while we investigate joint segmentation and POS-
tagging for Chinese; (3) their tag-dictionaries are
not tag-dictionaries literally, but statistics of word-
tag associations.
6 Conclusions
We performed an empirical study on the use of
tag-dictionaries for the domain adaptation of joint
Chinese segmentation and POS-tagging, showing
that type-supervised methods can be a compet-
itive alternative to token-supervised methods
in cost-effectiveness. In addition, combination
of the two methods gives the best cost-effect.
Finally, we release our annotation of over 4,000
sentences in the Internet literature domain on-
line at http://faculty.sutd.edu.sg/
?
yue_zhang/eacl14meishan.zip as a
free resource for Chinese POS-tagging.
Acknowledgments
We thank the anonymous reviewers for their con-
structive comments. We gratefully acknowl-
edge the support of the National Key Basic
Research Program (973 Program) of China via
Grant 2014CB340503 and the National Natural
Science Foundation of China (NSFC) via Grant
61133012 and 61370164, the National Basic Re-
search Program (973 Program) of China via Grant
2014CB340503, the Singaporean Ministration of
Education Tier 2 grant T2MOE201301 and SRG
ISTD 2012 038 from Singapore University of
Technology and Design.
595
References
Michele Banko and Robert C. Moore. 2004. Part-of-
speech tagging in context. In COLING.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Language
Processing, pages 120?128, Sydney, Australia, July.
Association for Computational Linguistics.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsu-
pervised POS induction: How far have we come?
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
575?584, Cambridge, MA, October. Association for
Computational Linguistics.
Michael Collins and Brian Roark. 2004. Incremen-
tal parsing with the perceptron algorithm. In Pro-
ceedings of the 42nd Meeting of the Association for
Computational Linguistics (ACL?04), Main Volume,
pages 111?118, Barcelona, Spain, July.
Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and Yong
Yu. 2007. Transferring Naive Bayes Classifiers for
Text Classification. In AAAI, pages 540?545.
Dipanjan Das and Slav Petrov. 2011. Unsuper-
vised part-of-speech tagging with bilingual graph-
based projections. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
600?609, Portland, Oregon, USA, June. Association
for Computational Linguistics.
Hal Daume III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
256?263, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
Zhendong Dong and Qiang Dong. 2006. Hownet And
the Computation of Meaning. World Scientific Pub-
lishing Co., Inc., River Edge, NJ, USA.
Dan Garrette and Jason Baldridge. 2012. Type-
supervised hidden markov models for part-of-speech
tagging with incomplete tag dictionaries. In
EMNLP-CoNLL, pages 821?831.
Dan Garrette and Jason Baldridge. 2013. Learning a
part-of-speech tagger from two hours of annotation.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 138?147, Atlanta, Georgia, June. Association
for Computational Linguistics.
Dan Garrette, Jason Mielens, and Jason Baldridge.
2013. Real-world semi-supervised learning of pos-
taggers for low-resource languages. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 583?592, Sofia, Bulgaria, August. As-
sociation for Computational Linguistics.
Yoav Goldberg, Meni Adler, and Michael Elhadad.
2008. EM can find pretty good HMM POS-taggers
(when given a good start). In Proceedings of ACL-
08: HLT, pages 746?754, Columbus, Ohio, June.
Association for Computational Linguistics.
Sharon Goldwater and Tom Griffiths. 2007. A fully
bayesian approach to unsupervised part-of-speech
tagging. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 744?751, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun?ichi Tsujii. 2012. Incremental joint approach
to word segmentation, pos tagging, and dependency
parsing in chinese. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1045?
1053, Jeju Island, Korea, July. Association for Com-
putational Linguistics.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An error-driven word-character hy-
brid model for joint chinese word segmentation and
pos tagging. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 513?521,
Suntec, Singapore, August. Association for Compu-
tational Linguistics.
Yang Liu and Yue Zhang. 2012. Unsupervised domain
adaptation for joint segmentation and POS-tagging.
In Proceedings of COLING 2012: Posters, pages
745?754, Mumbai, India, December. The COLING
2012 Organizing Committee.
Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo. 2005.
A maximum entropy approach to chinese word seg-
mentation. In Proceedings of the Fourth SIGHAN
Workshop on Chinese Language Processing, pages
161?164.
Christopher D. Manning. 2011. Part-of-speech tag-
ging from 97% to 100%: is it time for some linguis-
tics? In Proceeding of CICLing?11.
Bernard Merialdo. 1994. Tagging english text with
a probabilistic model. Computational Linguistics,
20(2).
Hwee Tou Ng and Jin Kiat Low. 2004. Chinese part-
of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based? In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 277?284, Barcelona, Spain, July. Association
for Computational Linguistics.
596
Fuchun Peng, Fangfang Feng, and Andrew McCallum.
2004. Chinese segmentation and new word detec-
tion using conditional random fields. In Proceedings
of Coling 2004, pages 562?568, Geneva, Switzer-
land, Aug 23?Aug 27. COLING.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
LREC, May.
Rajat Raina, Alexis Battle, Honglak Lee, Benjamin
Packer, and Andrew Y. Ng. 2007. Self-taught learn-
ing: transfer learning from unlabeled data. In ICML,
pages 759?766.
Sujith Ravi and Kevin Knight. 2009. Minimized
models for unsupervised part-of-speech tagging. In
ACL/IJCNLP, pages 504?512.
Amarnag Subramanya, Slav Petrov, and Fernando
Pereira. 2010. Efficient graph-based semi-
supervised learning of structured tagging models.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
167?176, Cambridge, MA, October. Association for
Computational Linguistics.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1385?
1394, Portland, Oregon, USA, June. Association for
Computational Linguistics.
Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, McDon-
ald Ryan, and Joakim Nivre. 2013. Token and type
constraints for cross-lingual part-of-speech tagging.
In Transactions of the ACL. Association for Compu-
tational Linguistics, March.
Partha Pratim Talukdar and Koby Crammer. 2009.
New regularized algorithms for transductive learn-
ing. In ECML/PKDD (2), pages 442?457.
Kristina Toutanova and Mark Johnson. 2007. A
bayesian lda-based model for semi-supervised part-
of-speech tagging. In NIPS.
Yiou Wang, Jun?ichi Kazama, Yoshimasa Tsuruoka,
Wenliang Chen, Yujie Zhang, and Kentaro Tori-
sawa. 2011. Improving chinese word segmentation
and pos tagging with semi-supervised methods using
large auto-analyzed data. In Proceedings of 5th In-
ternational Joint Conference on Natural Language
Processing, pages 309?317, Chiang Mai, Thailand,
November. Asian Federation of Natural Language
Processing.
Nianwen Xue, Fei Xia, Shizhe Huang, and Tony Kroch.
2000. The bracketing guidelines for the chinese
treebank. Technical report, University of Pennsyl-
vania.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Xiaodong Zeng, Derek F. Wong, Lidia S. Chao, and Is-
abel Trancoso. 2013. Graph-based semi-supervised
model for joint chinese word segmentation and part-
of-speech tagging. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 770?
779, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Yue Zhang and Stephen Clark. 2008. Joint word seg-
mentation and POS tagging using a single percep-
tron. In Proceedings of ACL-08: HLT, pages 888?
896, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Yue Zhang and Stephen Clark. 2010. A fast decoder
for joint word segmentation and POS-tagging using
a single discriminative model. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 843?852, Cambridge,
MA, October. Association for Computational Lin-
guistics.
Yue Zhang and Stephen Clark. 2011. Syntactic pro-
cessing using the generalized perceptron and beam
search. Computational Linguistics, 37(1):105?151.
597
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 125?134,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Chinese Parsing Exploiting Characters
Meishan Zhang?, Yue Zhang??, Wanxiang Che?, Ting Liu?
?Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{mszhang, car, tliu}@ir.hit.edu.cn
?Singapore University of Technology and Design
yue zhang@sutd.edu.sg
Abstract
Characters play an important role in the
Chinese language, yet computational pro-
cessing of Chinese has been dominated
by word-based approaches, with leaves in
syntax trees being words. We investigate
Chinese parsing from the character-level,
extending the notion of phrase-structure
trees by annotating internal structures of
words. We demonstrate the importance
of character-level information to Chinese
processing by building a joint segmen-
tation, part-of-speech (POS) tagging and
phrase-structure parsing system that inte-
grates character-structure features. Our
joint system significantly outperforms a
state-of-the-art word-based baseline on the
standard CTB5 test, and gives the best
published results for Chinese parsing.
1 Introduction
Characters play an important role in the Chinese
language. They act as basic phonetic, morpho-
syntactic and semantic units in a Chinese sentence.
Frequently-occurring character sequences that ex-
press certain meanings can be treated as words,
while most Chinese words have syntactic struc-
tures. For example, Figure 1(b) shows the struc-
ture of the word ???? (construction and build-
ing industry)?, where the characters ?? (construc-
tion)? and ?? (building)? form a coordination,
and modify the character ?? (industry)?.
However, computational processing of Chinese
is typically based on words. Words are treated
as the atomic units in syntactic parsing, machine
translation, question answering and other NLP
tasks. Manually annotated corpora, such as the
Chinese Treebank (CTB) (Xue et al, 2005), usu-
ally have words as the basic syntactic elements
?Email correspondence.
?? ???
??
? ??
NR NN
VV
JJ NN
NP NP
NPADJP
NP
VPNP
IP
NP NP
NPADJP
NP
VPNP
IP
NN
?
NR-e
?
NR-b
JJ
?
JJ-s
VV
?
VV-e
?
VV-bNN
?
NN-e
?
NN-m
?
NN-b
NR
?
NR-eNR-b
?
NP NP
NPADJP
NP
VPNP
IP
NN-c
?
NR-i
?
NR-b
JJ-t
?
JJ-b
VV-c
?
VV-i
?
VV-bNR-r
?
NR-iNR-b
?
NR-t
NN-r
?
NN-i
?
NN-i
?
NN-b
NN-c
NN-t
VV-t
NN-t
(a) CTB-style word-based syntax tree for ??? (China) ?
?? (architecture industry) ?? (show) ? (new) ??
(pattern)?.
?? ???
??
? ??
NR NN
VV
JJ NN
NP NP
NPADJP
NP
VPNP
IP
NP NP
NPADJP
NP
VPNP
IP
NN
?
NR-e
?
NR-b
JJ
?
JJ-s
VV
?
VV-e
?
VV-bNN
?
NN-e
?
NN-m
?
NN-b
NR
?
NR-eNR-b
?
NP NP
NPADJP
NP
VPNP
IP
NN-c
?
NN-i
?
NN-b
JJ-t
?
JJ-b
VV-c
?
VV-i
?
VV-bNR-r
?
NR-iNR-b
?
NR-t
NN-r
?
NN-i
?
NN-i
?
NN-b
NN-c
NN-t
VV-t
NN-t
(b) character-level syntax tree with hierarchal word structures
for ?? (middle) ? (nation) ? (construction) ? (building)
? (industry) ? (present) ? (show) ? (new) ? (style) ?
(situation)?.
Figure 1: Word-based and character-level phrase-
structure trees for the sentence ????????
??? (China?s architecture industry shows new
patterns)?, where ?l?, ?r?, ?c? denote the direc-
tions of head characters (see section 2).
(Figure 1(a)). This form of annotation does not
give character-level syntactic structures for words,
a source of linguistic information that is more fun-
damental and less sparse than atomic words.
In this paper, we investigate Chinese syn-
tactic parsing with character-level information
by extending the notation of phrase-structure
125
(constituent) trees, adding recursive structures of
characters for words. We manually annotate the
structures of 37,382 words, which cover the entire
CTB5. Using these annotations, we transform
CTB-style constituent trees into character-level
trees (Figure 1(b)). Our word structure corpus,
together with a set of tools to transform CTB-style
trees into character-level trees, is released at
https://github.com/zhangmeishan/wordstructures.
Our annotation work is in line with the work of
Vadas and Curran (2007) and Li (2011), which
provide extended annotations of Penn Treebank
(PTB) noun phrases and CTB words (on the
morphological level), respectively.
We build a character-based Chinese parsing
model to parse the character-level syntax trees.
Given an input Chinese sentence, our parser pro-
duces its character-level syntax trees (Figure 1(b)).
With richer information than word-level trees, this
form of parse trees can be useful for all the afore-
mentioned Chinese NLP applications.
With regard to task of parsing itself, an impor-
tant advantage of the character-level syntax trees is
that they allow word segmentation, part-of-speech
(POS) tagging and parsing to be performed jointly,
using an efficient CKY-style or shift-reduce algo-
rithm. Luo (2003) exploited this advantage by
adding flat word structures without manually an-
notation to CTB trees, and building a generative
character-based parser. Compared to a pipeline
system, the advantages of a joint system include
reduction of error propagation, and the integration
of segmentation, POS tagging and syntax features.
With hierarchical structures and head character in-
formation, our annotated words are more informa-
tive than flat word structures, and hence can bring
further improvements to phrase-structure parsing.
To analyze word structures in addition to phrase
structures, our character-based parser naturally
performs joint word segmentation, POS tagging
and parsing jointly. Our model is based on the
discriminative shift-reduce parser of Zhang and
Clark (2009; 2011), which is a state-of-the-art
word-based phrase-structure parser for Chinese.
We extend their shift-reduce framework, adding
more transition actions for word segmentation and
POS tagging, and defining novel features that cap-
ture character information. Even when trained
using character-level syntax trees with flat word
structures, our joint parser outperforms a strong
pipelined baseline that consists of a state-of-the-
NN-c
NN-iNN-b
?
(science)
?
(technology)
VV-l
VV-iVV-b
?
(burn)
?
(up)
NN-r
NN-iNN-b
?
(repository)
?
(saving)
NN-l
VV-iVV-b
?
(investigate)
?
(ancient)
NN-r
NN-iNN-b
?
(bad)
?
(kind)
AD-l
AD-iAD-b
?
(vain)
?
(so)
NN-r
NN-iNN-b
?
(crouching)
?
(tiger)
NN-r
NN-iNN-i
?
(hidden)
?
(dragon)
NN-c
VV-r
VV-iVV-b
?
(fiercely)
?
(sweep)
VV-r
VV-iVV-i
?
(thousands)
?
(troops)
VV-l
NN-c
NN-iNN-b
?
(teach)
?
(education)
NN-i
?
(field)
NN-r
NN
NN-fNN-f
??
(education)
?
(field)
NN-c
NN-iNN-b
?
(friend)
?
(friend)
NN-i
?
(plural)
NN-l
NN
NN-fNN-f
??
(friend)
?
(plural)
(a) subject-predicate.
NN-c
NN-iNN-b
?
(science)
?
(technology)
VV-l
VV-iVV-b
?
(burn)
?
(up)
NN-r
NN-iNN-b
?
(repository)
?
(saving)
NN-l
VV-iVV-b
?
(investigate)
?
(ancient)
NN-r
NN-iNN-b
?
(bad)
?
(kind)
AD-l
AD-iAD-b
?
(vain)
?
(so)
NN-r
NN-iNN-b
?
(crouching)
?
(tiger)
NN-r
NN-iNN-i
?
(hidden)
?
(dragon)
NN-c
VV-r
VV-iVV-b
?
(fiercely)
?
(sweep)
VV-r
VV-iVV-i
?
(thousands)
?
(troops)
VV-l
NN-c
NN-iNN-b
?
(teach)
?
(education)
NN-i
?
(field)
NN-r
NN
NN-fNN-f
??
(education)
?
(field)
NN-c
NN-iNN-b
?
(friend)
?
(friend)
NN-i
?
(plural)
NN-l
NN
NN-fNN-f
??
(friend)
?
(plural)
(b) verb-object.
NN-c
NN-iNN-b
?
(science)
?
(technology)
VV-l
VV-iVV-b
?
(burn)
?
(up)
NN-r
NN-iNN-b
?
(repository)
?
(saving)
NN-l
VV-iVV-b
?
(investigate)
?
(ancient)
NN-r
NN-iNN-b
?
(bad)
?
(kind)
AD-l
AD-iAD-b
?
(vain)
?
(so)
NN-r
NN-iNN-b
?
(crouching)
?
(tiger)
NN-r
NN-iNN-i
?
(hidden)
?
(dragon)
NN-c
VV-r
VV-iVV-b
?
(fiercely)
?
(sweep)
VV-r
VV-iVV-i
?
(thousands)
?
(troops)
VV-l
NN-c
NN-iNN-b
?
(teach)
?
(education)
NN-i
?
(field)
NN-r
NN
NN-fNN-f
??
(education)
?
(field)
NN-c
NN-iNN-b
?
(friend)
?
(friend)
NN-i
?
(plural)
NN-l
NN
NN-fNN-f
??
(friend)
?
(plural)
(c) coordination.
NN-c
NN-iNN-b
?
(science)
?
(technology)
VV-l
VV-iVV-b
?
(burn)
?
(up)
NN-r
NN-iNN-b
?
(repository)
?
(saving)
NN-l
VV-iVV-b
?
(investigate)
?
(ancient)
NN-r
NN-iNN-b
?
(bad)
?
(kind)
AD-l
AD-iAD-b
?
(vain)
?
(so)
NN-r
NN-iNN-b
?
(crouching)
?
(tiger)
NN-r
NN-iNN-i
?
(hidden)
?
(dragon)
NN-c
VV-r
VV-iVV-b
?
(fiercely)
?
(sweep)
VV-r
VV-iVV-i
?
(thousands)
?
(troops)
VV-l
NN-c
NN-iNN-b
?
(teach)
?
(education)
NN-i
?
(field)
NN-r
NN
NN-fNN-f
??
(education)
?
(field)
NN-c
NN-iNN-b
?
(friend)
?
(friend)
NN-i
?
(plural)
NN-l
NN
NN-fNN-f
??
(friend)
?
(plural)
(d) modifier-noun.
Figure 2: Inner word structures of ??? (reper-
tory)?,??? (archaeology)?, ??? (science and
technology)? and ??? (degenerate)?.
art joint segmenter and POS tagger, and our base-
line word-based parser. Our word annotations lead
to further improvements to the joint system, espe-
cially for phrase-structure parsing accuracy.
Our parser work falls in line with recent work
of joint segmentation, POS tagging and parsing
(Hatori et al, 2012; Li and Zhou, 2012; Qian
and Liu, 2012). Compared with related work,
our model gives the best published results for
joint segmentation and POS tagging, as well as
joint phrase-structure parsing on standard CTB5
evaluations. With linear-time complexity, our
parser is highly efficient, processing over 30 sen-
tences per second with a beam size of 16. An
open release of the parser is freely available at
http://sourceforge.net/projects/zpar/, version 0.6.
2 Word Structures and Syntax Trees
The Chinese language is a character-based lan-
guage. Unlike alphabetical languages, Chinese
characters convey meanings, and the meaning of
most Chinese words takes roots in their charac-
ter. For example, the word ???? (computer)? is
composed of the characters ?? (count)?, ?? (cal-
culate)? and ?? (machine)?. An informal name of
?computer? is ????, which is composed of ??
(electronic)? and ?? (brain)?.
Chinese words have internal structures (Xue,
2001; Ma et al, 2012). The way characters inter-
act within words can be similar to the way words
interact within phrases. Figure 2 shows the struc-
tures of the four words ??? (repertory)?, ???
126
NN-c
NN-iNN-b
?
(science)
?
(technology)
VV-l
VV-iVV-b
?
(burn)
?
(up)
NN-r
NN-iNN-b
?
(repository)
?
(saving)
NN-l
VV-iVV-b
?
(investigate)
?
(ancient)
NN-r
NN-iNN-b
?
(bad)
?
(kind)
AD-l
AD-iAD-b
?
(vain)
?
(so)
NN-r
NN-iNN-b
?
(crouching)
?
(tiger)
NN-r
NN-iNN-i
?
(hidden)
?
(dragon)
NN-c
VV-r
VV-iVV-b
?
(fiercely)
?
(sweep)
VV-r
VV-iVV-i
?
(thousands)
?
(troops)
VV-l
NN-c
NN-iNN-b
?
(teach)
?
(education)
NN-i
?
(field)
NN-r
NN
NN-fNN-f
??
(education)
?
(field)
NN-c
NN-iNN-b
?
(friend)
?
(friend)
NN-i
?
(plural)
NN-l
NN
NN-fNN-f
??
(friend)
?
(plural)
Figure 3: Character-level word structure of ???
?? (crouching tiger hidden dragon)?.
(archaeology)?, ??? (science and technology)?
and ??? (degenerate)?, which demonstrate
four typical syntactic structures of two-character
words, including subject-predicate, verb-object,
coordination and modifier-noun structures. Multi-
character words can also have recursive syntac-
tic structures. Figure 3 illustrates the structure
of the word ????? (crouching tiger hidden
dragon)?, which is composed of two subwords ??
? (crouching tiger)? and ??? (hidden dragon)?,
both having a modifier-noun structure.
The meaning of characters can be a useful
source of information for computational process-
ing of Chinese, and some recent work has started
to exploit this information. Zhang and Clark
(2010) found that the first character in a Chinese
word is a useful indicator of the word?s POS. They
made use of this information to help joint word
segmentation and POS tagging.
Li (2011) studied the morphological structures
of Chinese words, showing that 35% percent of
the words in CTB5 can be treated as having mor-
phemes. Figure 4(a) illustrates the morphological
structures of the words ? ??? (friends)? and
???? (educational world)?, in which the char-
acters ?? (plural)? and ?? (field)? can be treated
as suffix morphemes. They studied the influence
of such morphology to Chinese dependency pars-
ing (Li and Zhou, 2012).
The aforementioned work explores the influ-
ence of particular types of characters to Chinese
processing, yet not the full potentials of complete
word structures. We take one step further in this
line of work, annotating the full syntactic struc-
tures of 37,382 Chinese words in the form of Fig-
ure 2 and Figure 3. Our annotation covers the
entire vocabulary of CTB5. In addition to dif-
ference in coverage (100% vs 35%), our annota-
tion is structurally more informative than that of
Li (2011), as illustrated in Figure 4(b).
Our annotations are binarized recursive word
NN-c
NN-iNN-b
?
(science)
?
(technology)
VV-l
VV-iVV-b
?
(burn)
?
(up)
NN-r
NN-iNN-b
?
(repository)
?
(saving)
NN-l
VV-iVV-b
?
(investigate)
?
(ancient)
NN-r
NN-iNN-b
?
(bad)
?
(kind)
AD-l
AD-iAD-b
?
(vain)
?
(so)
NN-r
NN-iNN-b
?
(crouching)
?
(tiger)
NN-r
NN-iNN-i
?
(hidden)
?
(dragon)
NN-c
VV-r
VV-iVV-b
?
(fiercely)
?
(sweep)
VV-r
VV-iVV-i
?
(thousands)
?
(troops)
VV-l
NN-c
NN-iNN-b
?
(teach)
?
(education)
NN-i
?
(field)
NN-r
NN
NN-fNN-f
??
(education)
?
(field)
NN-c
NN-iNN-b
?
(friend)
?
(friend)
NN-i
?
(plural)
NN-l
NN
NN-fNN-f
??
(friend)
?
(plural)
(a) morphological-level word structures, where ?f? de-
notes a special mark for fine-grained words.
NN-c
NN-iNN-b
?(science) ?(technology)
VV-l
VV-iVV-b
?(burn) ?(up)
NN-r
NN-iNN-b
?(repository) ?(saving)
NN-l
VV-iVV-b
?(investigate) ?(ancient)
NN-r
NN-iNN-b
?(bad) ?(kind)
AD-l
AD-iAD-b
?(vain) ?(so)
NN-r
NN-iNN-b
?(crouching) ?(tiger)
NN-r
NN-iNN-i
?(hidden) ?(dragon)
NN-c
VV-r
VV-iVV-b
?(fiercely) ?(sweep)
VV-r
VV-iVV-i
?(thousands) ?(troops)
VV-l
NN-c
NN-iNN-b
?(teach) ?(education)
NN-i
?(field)
NN-r
NN
NN-fNN-f
??(education) ?(field)
NN-c
NN-iNN-b
?(friend) ?(friend)
NN-i
?(plural)
NN-l
NN
NN-fNN-f
??(friend) ?(plural)
(b) character-level word structures.
Figure 4: Comparison between character-level and
morphological-level word structures.
structures. For each word or subword, we spec-
ify its POS and head direction. We use ?l?, ?r?
and ?c? to indicate the ?left?, ?right? and ?coordi-
nation? head directions, respectively. The ?coor-
dination? direction is mostly used in coordination
structures, while a very small number of translit-
eration words, such as ???? (Obama)? and ??
?? (Los Angeles)?, have flat structures, and we
use ?coordination? for their left binarization. For
leaf characters, we follow previous work on word
segmentation (Xue, 2003; Ng and Low, 2004), and
use ?b? and ?i? to indicate the beginning and non-
beginning characters of a word, respectively.
The vast majority of words do not have struc-
tural ambiguities. However, the structures of some
words may vary according to different POS. For
example, ???? means ?dominate? when it is
tagged as a verb, of which the head is the left char-
acter; the same word means ?uniform dress? when
tagged as a noun, of which the head is the right
character. Thus the input of the word structure
annotation is a word together with its POS. The
annotation work was conducted by three persons,
with one person annotating the entire corpus, and
the other two checking the annotations.
Using our annotations, we can extend CTB-
style syntax trees (Figure 1(a)) into character-
level trees (Figure 1(b)). In particular, we mark
the original nodes that represent POS tags in CTB-
style trees with ?-t?, and insert our word structures
as unary subnodes of the ?-t? nodes. For the rest
of the paper, we refer to the ?-t? nodes as full-word
nodes, all nodes above full-word nodes as phrase
127
nodes, and all nodes below full-word nodes as sub-
word nodes.
Our character-level trees contain additional syn-
tactic information, which are potentially useful to
Chinese processing. For example, the head char-
acters of words can be populated up to phrase-
level nodes, and serve as an additional source of
information that is less sparse than head words. In
this paper, we build a parser that yields character-
level trees from raw character sequences. In addi-
tion, we use this parser to study the effects of our
annotations to character-based statistical Chinese
parsing, showing that they are useful in improving
parsing accuracies.
3 Character-based Chinese Parsing
To produce character-level trees for Chinese
NLP tasks, we develop a character-based parsing
model, which can jointly perform word segmen-
tation, POS tagging and phrase-structure parsing.
To our knowledge, this is the first work to develop
a transition-based system that jointly performs the
above three tasks. Trained using annotated word
structures, our parser also analyzes the internal
structures of Chinese words.
Our character-based Chinese parsing model is
based on the work of Zhang and Clark (2009),
which is a transition-based model for lexicalized
constituent parsing. They use a beam-search de-
coder so that the transition action sequence can be
globally optimized. The averaged perceptron with
early-update (Collins and Roark, 2004) is used to
train the model parameters. Their transition sys-
tem contains four kinds of actions: (1) SHIFT,
(2) REDUCE-UNARY, (3) REDUCE-BINARY and
(4) TERMINATE. The system can provide bina-
rzied CFG trees in Chomsky Norm Form, and they
present a reversible conversion procedure to map
arbitrary CFG trees into binarized trees.
In this work, we remain consistent with their
work, using the head-finding rules of Zhang and
Clark (2008), and the same binarization algo-
rithm.1 We apply the same beam-search algorithm
for decoding, and employ the averaged perceptron
with early-update to train our model.
We make two extensions to their work to en-
able joint segmentation, POS tagging and phrase-
structure parsing from the character level. First,
we modify the actions of the transition system for
1We use a left-binarization process for flat word structures
that contain more than two characters.
S2
sta ck
. . .
. . .
q u eu e
Q0 Q1 . . .S1
S1l S1r
. . . . . .
S0
S0l S0r
. . . . . .
Figure 5: A state in a transition-based model.
parsing the inner structures of words. Second, we
extend the feature set for our parsing problem.
3.1 The Transition System
In a transition-based system, an input sentence is
processed in a linear left-to-right pass, and the
output is constructed by a state-transition pro-
cess. We learn a model for scoring the transi-
tion Ai from one state STi to the next STi+1. As
shown in Figure 5, a state ST consists of a stack
S and a queue Q, where S = (? ? ? , S1, S0) con-
tains partially constructed parse trees, and Q =
(Q0, Q1, ? ? ? , Qn?j) = (cj , cj+1, ? ? ? , cn) is the
sequence of input characters that have not been
processed. The candidate transition action A at
each step is defined as follows:
? SHIFT-SEPARATE(t): remove the head
character cj from Q, pushing a subword node
S?
cj
2 onto S, assigning S?.t = t. Note that the
parse tree S0 must correspond to a full-word
or a phrase node, and the character cj is the
first character of the next word. The argu-
ment t denotes the POS of S?.
? SHIFT-APPEND: remove the head character
cj from Q, pushing a subword node S?cj onto
S. cj will eventually be combined with all the
subword nodes on top of S to form a word,
and thus we must have S?.t = S0.t.
? REDUCE-SUBWORD(d): pop the top two
nodes S0 and S1 off S, pushing a new sub-
word node S?S1 S0 onto S. The argument ddenotes the head direction of S?, of which
the value can be ?left?, ?right? or ?coordi-
nation?.3 Both S0 and S1 must be subword
nodes and S?.t = S0.t = S1.t.
2We use this notation for a compact representation of a
tree node, where the numerator represents a father node, and
the denominator represents the children.
3For the head direction ?coordination?, we extract the
head character from the left node.
128
Category Feature templates When to Apply
Structure S0ntl S0nwl S1ntl S1nwl S2ntl S2nwl S3ntl S3nwl, All
features Q0c Q1c Q2c Q3c Q0c ?Q1c Q1c ?Q2c Q2c ?Q3c,
S0ltwl S0rtwl S0utwl S1ltwl S1rtwl S1utwl,
S0nw ? S1nw S0nw ? S1nl S0nl ? S1nw S0nl ? S1nl,
S0nw ?Q0c S0nl ?Q0c S1nw ?Q0c S1nlQ0c,
S0nl ? S1nl ? S2nl S0nw ? S1nl ? S2nl S0nl ? S1nw ? S2nl S0nl ? S1nl ? S2nw,
S0nw ? S1nl ?Q0c S0nl ? S1nw ?Q0c S0nl ? S1nl ?Q0c,
S0ncl S0nct S0nctl S1ncl S1nct S1nctl,
S2ncl S2nct S2nctl S3ncl S3nct S3nctl,
S0nc ? S1nc S0ncl ? S1nl S0nl ? S1ncl S0ncl ? S1ncl,
S0nc ? Q0c S0nl ? Q0c S1nc ? Q0c S1nl ? Q0c,
S0nc ? S1nc ? Q0c S0nc ? S1nc ? Q0c ? Q1c
start(S0w) ? start(S1w) start(S0w) ? end(S1w), REDUCE-SUBWORD
indict(S1wS0w) ? len(S1wS0w) indict(S1wS0w, S0t) ? len(S1wS0w)
String t?1 ? t0 t?2 ? t?1t0 w?1 ? t0 c0 ? t0 start(w?1) ? t0 c?1 ? c0 ? t?1 ? t0, SHIFT-SEPARATE
features w?1 w?2 ? w?1 w?1,where len(w?1) = 1 end(w?1) ? c0, REDUCE-WORD
start(w?1) ? len(w?1) end(w?1) ? len(w?1) start(w?1) ? end(w?1),
w?1 ? c0 end(w?2) ? w?1 start(w?1) ? c0 end(w?2) ? end(w?1),
w?1 ? len(w?2) w?2 ? len(w?1) w?1 ? t?1 w?1 ? t?2 w?1 ? t?1 ? c0,
w?1 ? t?1 ? end(w?2) c?2 ? c?1 ? c0 ? t?1,where len(w?1) = 1 end(w?1) ? t?1,
c ? t?1 ? end(w?1),where c ? w?1 and c 6= end(w?1)
c0 ? t?1 c?1 ? c0 start(w?1) ? c0t?1 c?1 ? c0 ? t?1 SHIFT-APPEND
Table 1: Feature templates for the character-level parser. The function start(?), end(?) and len(?) denote
the first character, the last character and the length of a word, respectively.
? REDUCE-WORD: pop the top node S0 off S,
pushing a full-word node S?S0 onto S. This re-duce action generates a full-word node from
S0, which must be a subword node.
? REDUCE-BINARY(d, l): pop the top two
nodes S0 and S1 off S, pushing a binary
phrase node S?S1 S0 onto S. The argument ldenotes the constituent label of S?, and the ar-
gument d specifies the lexical head direction
of S?, which can be either ?left? or ?right?.
Both S0 and S1 must be a full-word node or
a phrase node.
? REDUCE-UNARY(l): pop the top node S0
off S, pushing a unary phrase node S?S0 onto
S. l denotes the constituent label of S?.
? TERMINATE: mark parsing complete.
Compared to set of actions in our baseline
transition-based phrase-structure parser, we have
made three major changes. First, we split the orig-
inal SHIFT action into SHIFT-SEPARATE(t)
and SHIFT-APPEND, which jointly perform the
word segmentation and POS tagging tasks. Sec-
ond, we add an extra REDUCE-SUBWORD(d) op-
eration, which is used for parsing the inner struc-
tures of words. Third, we add REDUCE-WORD,
which applies a unary rule to mark a completed
subword node as a full-word node. The new node
corresponds to a unary ?-t? node in Figure 1(b).
3.2 Features
Table 1 shows the feature templates of our model.
The feature set consists of two categories: (1)
structure features, which encode the structural in-
formation of subwords, full-words and phrases.
(2) string features, which encode the information
of neighboring characters and words.
For the structure features, the symbols S0, S1,
S2, S3 represent the top four nodes on the stack;
Q0, Q1, Q2, Q3 denote the first four characters
in the queue; S0l, S0r, S0u represent the left,
right child for a binary branching S0, and the sin-
gle child for a unary branching S0, respectively;
S1l, S1r, S1u represent the left, right child for
a binary branching S1, and the single child for
a unary branching S1, respectively; n represents
the type for a node; it is a binary value that indi-
cates whether the node is a subword node; c, w,
t and l represent the head character, word (or sub-
word), POS tag and constituent label of a node, re-
spectively. The structure features are mostly taken
129
from the work of Zhang and Clark (2009). The
feature templates in bold are novel, are designed
to encode head character information. In particu-
lar, the indict function denotes whether a word is
in a tag dictionary, which is collected by extract-
ing all multi-character subwords that occur more
than five times in the training corpus.
For string features, c0, c?1 and c?2 represent
the current character and its previous two charac-
ters, respectively; w?1 and w?2 represent the pre-
vious two words to the current character, respec-
tively; t0, t?1 and t?2 represent the POS tags of
the current word and the previous two words, re-
spectively. The string features are used for word
segmentation and POS tagging, and are adapted
from a state-of-the-art joint segmentation and tag-
ging model (Zhang and Clark, 2010).
In summary, our character-based parser con-
tains the word-based features of constituent parser
presented in Zhang and Clark (2009), the word-
based and shallow character-based features of
joint word segmentation and POS tagging pre-
sented in Zhang and Clark (2010), and addition-
ally the deep character-based features that encode
word structure information, which are the first pre-
sented by this paper.
4 Experiments
4.1 Setting
We conduct our experiments on the CTB5 cor-
pus, using the standard split of data, with sections
1?270,400?931 and 1001?1151 for training, sec-
tions 301?325 for system development, and sec-
tions 271?300 for testing. We apply the same pre-
processing step as Harper and Huang (2011), so
that the non-terminal yield unary chains are col-
lapsed to single unary rules.
Since our model can jointly process word seg-
mentation, POS tagging and phrase-structure pars-
ing, we evaluate our model for the three tasks, re-
spectively. For word segmentation and POS tag-
ging, standard metrics of word precision, recall
and F-score are used, where the tagging accuracy
is the joint accuracy of word segmentation and
POS tagging. For phrase-structure parsing, we
use the standard parseval evaluation metrics on
bracketing precision, recall and F-score. As our
constituent trees are based on characters, we fol-
low previous work and redefine the boundary of
a constituent span by its start and end characters.
In addition, we evaluate the performance of word
6570
7580
8590
95
0 10 20 30 40
64b16b4b1b
(a) Joint segmentation and
POS tagging F-scores.
3040
5060
7080
90
0 10 20 30 40
64b16b4b1b
(b) Joint constituent parsing
F-scores.
Figure 6: Accuracies against the training epoch
for joint segmentation and tagging as well as joint
phrase-structure parsing using beam sizes 1, 4, 16
and 64, respectively.
structures, using the word precision, recall and F-
score metrics. A word structure is correct only if
the word and its internal structure are both correct.
4.2 Development Results
Figure 6 shows the accuracies of our model using
different beam sizes with respect to the training
epoch. The performance of our model increases
as the beam size increases. The amount of in-
creases becomes smaller as the size of the beam
grows larger. Tested using gcc 4.7.2 and Fedora
17 on an Intel Core i5-3470 CPU (3.20GHz), the
decoding speeds are 318.2, 98.0, 30.3 and 7.9 sen-
tences per second with beam size 1, 4, 16 and 64,
respectively. Based on this experiment, we set the
beam size 64 for the rest of our experiments.
The character-level parsing model has the ad-
vantage that deep character information can be ex-
tracted as features for parsing. For example, the
head character of a word is exploited in our model.
We conduct feature ablation experiments to eval-
uate the effectiveness of these features. We find
that the parsing accuracy decreases about 0.6%
when the head character related features (the bold
feature templates in Table 1) are removed, which
demonstrates the usefulness of these features.
4.3 Final Results
In this section, we present the final results of our
model, and compare it to two baseline systems, a
pipelined system and a joint system that is trained
with automatically generated flat words structures.
The baseline pipelined system consists of the
joint segmentation and tagging model proposed by
130
Task P R F
Pipeline Seg 97.35 98.02 97.69
Tag 93.51 94.15 93.83
Parse 81.58 82.95 82.26
Flat word Seg 97.32 98.13 97.73
structures Tag 94.09 94.88 94.48
Parse 83.39 83.84 83.61
Annotated Seg 97.49 98.18 97.84
word structures Tag 94.46 95.14 94.80
Parse 84.42 84.43 84.43
WS 94.02 94.69 94.35
Table 2: Final results on test corpus.
Zhang and Clark (2010), and the phrase-structure
parsing model of Zhang and Clark (2009). Both
models give state-of-the-art performances, and are
freely available.4 The model for joint segmen-
tation and POS tagging is trained with a 16-
beam, since it achieves the best performance. The
phrase-structure parsing model is trained with a
64-beam. We train the parsing model using the
automatically generated POS tags by 10-way jack-
knifing, which gives about 1.5% increases in pars-
ing accuracy when tested on automatic segmented
and POS tagged inputs.
The joint system trained with flat word struc-
tures serves to test the effectiveness of our joint
parsing system over the pipelined baseline, since
flat word structures do not contain additional
sources of information over the baseline. It is also
used to test the usefulness of our annotation in im-
proving parsing accuracy.
Table 2 shows the final results of our model
and the two baseline systems on the test data.
We can see that both character-level joint mod-
els outperform the pipelined system; our model
with annotated word structures gives an improve-
ment of 0.97% in tagging accuracy and 2.17% in
phrase-structure parsing accuracy. The results also
demonstrate that the annotated word structures are
highly effective for syntactic parsing, giving an ab-
solute improvement of 0.82% in phrase-structure
parsing accuracy over the joint model with flat
word structures.
Row ?WS? in Table 2 shows the accuracy of
hierarchical word-structure recovery of our joint
system. This figure can be useful for high-level ap-
plications that make use of character-level trees by
4http://sourceforge.net/projects/zpar/, version 0.5.
our parser, as it reflects the capability of our parser
in analyzing word structures. In particular, the per-
formance of parsing OOV word structure is an im-
portant metric of our parser. The recall of OOV
word structures is 60.43%, while if we do not con-
sider the influences of segmentation and tagging
errors, counting only the correctly segmented and
tagged words, the recall is 87.96%.
4.4 Comparison with Previous Work
In this section, we compare our model to previous
systems on the performance of joint word segmen-
tation and POS tagging, and the performance of
joint phrase-structure parsing.
Table 3 shows the results. Kruengkrai+ ?09
denotes the results of Kruengkrai et al (2009),
which is a lattice-based joint word segmentation
and POS tagging model; Sun ?11 denotes a sub-
word based stacking model for joint segmenta-
tion and POS tagging (Sun, 2011), which uses a
dictionary of idioms; Wang+ ?11 denotes a semi-
supervised model proposed by Wang et al (2011),
which additionally uses the Chinese Gigaword
Corpus; Li ?11 denotes a generative model that
can perform word segmentation, POS tagging and
phrase-structure parsing jointly (Li, 2011); Li+
?12 denotes a unified dependency parsing model
that can perform joint word segmentation, POS
tagging and dependency parsing (Li and Zhou,
2012); Li ?11 and Li+ ?12 exploited annotated
morphological-level word structures for Chinese;
Hatori+ ?12 denotes an incremental joint model
for word segmentation, POS tagging and depen-
dency parsing (Hatori et al, 2012); they use exter-
nal dictionary resources including HowNet Word
List and page names from the Chinese Wikipedia;
Qian+ ?12 denotes a joint segmentation, POS tag-
ging and parsing system using a unified frame-
work for decoding, incorporating a word segmen-
tation model, a POS tagging model and a phrase-
structure parsing model together (Qian and Liu,
2012); their word segmentation model is a combi-
nation of character-based model and word-based
model. Our model achieved the best performance
on both joint segmentation and tagging as well as
joint phrase-structure parsing.
Our final performance on constituent parsing is
by far the best that we are aware of for the Chinese
data, and even better than some state-of-the-art
models with gold segmentation. For example, the
un-lexicalized PCFG model of Petrov and Klein
131
System Seg Tag Parse
Kruengkrai+ ?09 97.87 93.67 ?
Sun ?11 98.17* 94.02* ?
Wang+ ?11 98.11* 94.18* ?
Li ?11 97.3 93.5 79.7
Li+ ?12 97.50 93.31 ?
Hatori+ ?12 98.26* 94.64* ?
Qian+ ?12 97.96 93.81 82.85
Ours pipeline 97.69 93.83 82.26
Ours joint flat 97.73 94.48 83.61
Ours joint annotated 97.84 94.80 84.43
Table 3: Comparisons of our final model with
state-of-the-art systems, where ?*? denotes that
external dictionary or corpus has been used.
(2007) achieves 83.45%5 in parsing accuracy on
the test corpus, and our pipeline constituent pars-
ing model achieves 83.55% with gold segmenta-
tion. They are lower than the performance of our
character-level model, which is 84.43% without
gold segmentation. The main differences between
word-based and character-level parsing models are
that character-level model can exploit character
features. This further demonstrates the effective-
ness of characters in Chinese parsing.
5 Related Work
Recent work on using the internal structure of
words to help Chinese processing gives impor-
tant motivations to our work. Zhao (2009) stud-
ied character-level dependencies for Chinese word
segmentation by formalizing segmentsion task in
a dependency parsing framework. Their results
demonstrate that annotated word dependencies
can be helpful for word segmentation. Li (2011)
pointed out that the word?s internal structure is
very important for Chinese NLP. They annotated
morphological-level word structures, and a unified
generative model was proposed to parse the Chi-
nese morphological and phrase-structures. Li and
Zhou (2012) also exploited the morphological-
level word structures for Chinese dependency
parsing. They proposed a unified transition-based
model to parse the morphological and depen-
dency structures of a Chinese sentence in a unified
framework. The morphological-level word struc-
5We rerun the parser and evaluate it using the publicly-
available code on http://code.google.com/p/berkeleyparser
by ourselves, since we have a preprocessing step for the
CTB5 corpus.
tures concern only prefixes and suffixes, which
cover only 35% of entire words in CTB. Accord-
ing to their results, the final performances of their
model on word segmentation and POS tagging are
below the state-of-the-art joint segmentation and
POS tagging models. Compared to their work,
we consider the character-level word structures
for Chinese parsing, presenting a unified frame-
work for segmentation, POS tagging and phrase-
structure parsing. We can achieve improved seg-
mentation and tagging performance.
Our character-level parsing model is inspired
by the work of Zhang and Clark (2009), which
is a transition-based model with a beam-search
decoder for word-based constituent parsing. Our
work is based on the shift-reduce operations of
their work, while we introduce additional opera-
tions for segmentation and POS tagging. By such
an extension, our model can include all the fea-
tures in their work, together with the features for
segmentation and POS tagging. In addition, we
propose novel features related to word structures
and interactions between word segmentation, POS
tagging and word-based constituent parsing.
Luo (2003) was the first work to introduce the
character-based syntax parsing. They use it as
a joint framework to perform Chinese word seg-
mentation, POS tagging and syntax parsing. They
exploit a generative maximum entropy model for
character-based constituent parsing, and find that
POS information is very useful for Chinese word
segmentation, but high-level syntactic information
seems to have little effect on segmentation. Com-
pared to their work, we use a transition-based dis-
criminative model, which can benefit from large
amounts of flexible features. In addition, in-
stead of using flat structures, we manually anno-
tate hierarchal tree structures of Chinese words
for converting word-based constituent trees into
character-based constituent trees.
Hatori et al (2012) proposed the first joint work
for the word segmentation, POS tagging and de-
pendency parsing. They used a single transition-
based model to perform the three tasks. Their
work demonstrates that a joint model can improve
the performance of the three tasks, particularly
for POS tagging and dependency parsing. Qian
and Liu (2012) proposed a joint decoder for word
segmentation, POS tagging and word-based con-
stituent parsing, although they trained models for
the three tasks separately. They reported better
132
performances when using a joint decoder. In our
work, we employ a single character-based dis-
criminative model to perform segmentation, POS
tagging and phrase-structure parsing jointly, and
study the influence of annotated word structures.
6 Conclusions and Future Work
We studied the internal structures of more than
37,382 Chinese words, analyzing their structures
as the recursive combinations of characters. Using
these word structures, we extended the CTB into
character-level trees, and developed a character-
based parser that builds such trees from raw char-
acter sequences. Our character-based parser per-
forms segmentation, POS tagging and parsing
simultaneously, and significantly outperforms a
pipelined baseline. We make both our annotations
and our parser available online.
In summary, our contributions include:
? We annotated the internal structures of Chi-
nese words, which are potentially useful
to character-based studies of Chinese NLP.
We extend CTB-style constituent trees into
character-level trees using our annotations.
? We developed a character-based parsing
model that can produce our character-level
constituent trees. Our parser jointly performs
word segmentation, POS tagging and syntac-
tic parsing.
? We investigated the effectiveness of our joint
parser over pipelined baseline, and the effec-
tiveness of our annotated word structures in
improving parsing accuracies.
Future work includes investigations of our
parser and annotations on Chinese NLP tasks.
Acknowledgments
This work was supported by National Natural
Science Foundation of China (NSFC) via grant
61133012, the National ?863? Major Projects
via grant 2011AA01A207, the National ?863?
Leading Technology Research Project via grant
2012AA011102, and SRG ISTD 2012 038 from
Singapore University of Technology and Design.
References
Michael Collins and Brian Roark. 2004. Incremen-
tal parsing with the perceptron algorithm. In Pro-
ceedings of the 42nd Meeting of the Association for
Computational Linguistics (ACL?04), Main Volume,
pages 111?118, Barcelona, Spain, July.
Mary Harper and Zhongqiang Huang. 2011. Chinese
statistical parsing. Handbook of Natural Language
Processing and Machine Translation.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun?ichi Tsujii. 2012. Incremental joint approach
to word segmentation, pos tagging, and dependency
parsing in chinese. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1045?
1053, Jeju Island, Korea, July. Association for Com-
putational Linguistics.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An error-driven word-character hy-
brid model for joint chinese word segmentation and
pos tagging. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 513?521,
Suntec, Singapore, August. Association for Compu-
tational Linguistics.
Zhongguo Li and Guodong Zhou. 2012. Unified de-
pendency parsing of chinese morphological and syn-
tactic structures. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 1445?1454, Jeju Island, Ko-
rea, July. Association for Computational Linguistics.
Zhongguo Li. 2011. Parsing the internal structure of
words: A new paradigm for chinese word segmen-
tation. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies, pages 1405?1414,
Portland, Oregon, USA, June. Association for Com-
putational Linguistics.
Xiaoqiang Luo. 2003. A maximum entropy Chi-
nese character-based parser. In Michael Collins and
Mark Steedman, editors, Proceedings of the 2003
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 192?199.
Jianqiang Ma, Chunyu Kit, and Dale Gerdemann.
2012. Semi-automatic annotation of chinese word
structure. In Proceedings of the Second CIPS-
SIGHAN Joint Conference on Chinese Language
Processing, pages 9?17, Tianjin, China, December.
Association for Computational Linguistics.
Hwee Tou Ng and Jin Kiat Low. 2004. Chinese part-
of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based? In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 277?284, Barcelona, Spain, July. Association
for Computational Linguistics.
Slav Petrov and Dan Klein. 2007. Improved infer-
ence for unlexicalized parsing. In Human Language
133
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 404?411, Rochester, New York, April.
Association for Computational Linguistics.
Xian Qian and Yang Liu. 2012. Joint chinese word
segmentation, pos tagging and parsing. In Pro-
ceedings of the 2012 Joint Conference on Empiri-
cal Methods in Natural Language Processing and
Computational Natural Language Learning, pages
501?511, Jeju Island, Korea, July. Association for
Computational Linguistics.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1385?
1394, Portland, Oregon, USA, June. Association for
Computational Linguistics.
David Vadas and James Curran. 2007. Adding noun
phrase structure to the penn treebank. In Proceed-
ings of the 45th Annual Meeting of the Associa-
tion of Computational Linguistics, pages 240?247,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Yiou Wang, Jun?ichi Kazama, Yoshimasa Tsuruoka,
Wenliang Chen, Yujie Zhang, and Kentaro Tori-
sawa. 2011. Improving chinese word segmentation
and pos tagging with semi-supervised methods using
large auto-analyzed data. In Proceedings of 5th In-
ternational Joint Conference on Natural Language
Processing, pages 309?317, Chiang Mai, Thailand,
November. Asian Federation of Natural Language
Processing.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Nianwen Xue. 2001. Defining and Automatically
Identifying Words in Chinese. Ph.D. thesis, Univer-
sity of Delaware.
Nianwen Xue. 2003. Chinese word segmentation as
character tagging. International Journal of Compu-
tational Linguistics and Chinese Language Process-
ing, 8(1).
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based
and transition-based dependency parsing. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 562?
571, Honolulu, Hawaii, October. Association for
Computational Linguistics.
Yue Zhang and Stephen Clark. 2009. Transition-
based parsing of the chinese treebank using a global
discriminative model. In Proceedings of the 11th
International Conference on Parsing Technologies
(IWPT?09), pages 162?171, Paris, France, October.
Association for Computational Linguistics.
Yue Zhang and Stephen Clark. 2010. A fast decoder
for joint word segmentation and POS-tagging using
a single discriminative model. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 843?852, Cambridge,
MA, October. Association for Computational Lin-
guistics.
Yue Zhang and Stephen Clark. 2011. Syntactic pro-
cessing using the generalized perceptron and beam
search. Computational Linguistics, 37(1):105?151.
Hai Zhao. 2009. Character-level dependencies in chi-
nese: Usefulness and learning. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 879?887, Athens, Greece,
March. Association for Computational Linguistics.
134
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1326?1336,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
Character-Level Chinese Dependency Parsing
Meishan Zhang
?
, Yue Zhang
?
, Wanxiang Che
?
, Ting Liu
??
?
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{mszhang, car, tliu}@ir.hit.edu.cn
?
Singapore University of Technology and Design
yue zhang@sutd.edu.sg
Abstract
Recent work on Chinese analysis has led
to large-scale annotations of the internal
structures of words, enabling character-
level analysis of Chinese syntactic struc-
tures. In this paper, we investigate the
problem of character-level Chinese depen-
dency parsing, building dependency trees
over characters. Character-level infor-
mation can benefit downstream applica-
tions by offering flexible granularities for
word segmentation while improving word-
level dependency parsing accuracies. We
present novel adaptations of two ma-
jor shift-reduce dependency parsing algo-
rithms to character-level parsing. Exper-
imental results on the Chinese Treebank
demonstrate improved performances over
word-based parsing methods.
1 Introduction
As a light-weight formalism offering syntactic
information to downstream applications such as
SMT, the dependency grammar has received in-
creasing interest in the syntax parsing commu-
nity (McDonald et al, 2005; Nivre and Nilsson,
2005; Carreras et al, 2006; Duan et al, 2007; Koo
and Collins, 2010; Zhang and Clark, 2008; Nivre,
2008; Bohnet, 2010; Zhang and Nivre, 2011; Choi
and McCallum, 2013). Chinese dependency trees
were conventionally defined over words (Chang et
al., 2009; Li et al, 2012), requiring word segmen-
tation and POS-tagging as pre-processing steps.
Recent work on Chinese analysis has embarked
on investigating the syntactic roles of characters,
leading to large-scale annotations of word internal
structures (Li, 2011; Zhang et al, 2013). Such an-
notations enable dependency parsing on the char-
acter level, building dependency trees over Chi-
nese characters. Figure 1(c) shows an example of
?
Corresponding author.
??? ??? ? ? ??
forestry administration deputy director meeting in make a speech
(a) a word-based dependency tree
? ? ? ? ? ? ? ? ? ?
woods industry office deputy office manager meeting in make speech
(b) a character-level dependency tree by Zhao (2009) with
real intra-word and pseudo inter-word dependencies
? ? ? ? ? ? ? ? ? ?
woods industry office deputy office manager meeting in make speech
(c) a character-level dependency tree investigated in this pa-
per with both real intra- and inter-word dependencies
Figure 1: An example character-level dependency
tree. ????????????? (The deputy
director of forestry administration make a speech
in the meeting)?.
a character-level dependency tree, where the leaf
nodes are Chinese characters.
Character-level dependency parsing is interest-
ing in at least two aspects. First, character-level
trees circumvent the issue that no universal stan-
dard exists for Chinese word segmentation. In the
well-known Chinese word segmentation bakeoff
tasks, for example, different segmentation stan-
dards have been used by different data sets (Emer-
son, 2005). On the other hand, most disagreement
on segmentation standards boils down to disagree-
ment on segmentation granularity. As demon-
strated by Zhao (2009), one can extract both fine-
grained and coarse-grained words from character-
level dependency trees, and hence can adapt to
flexible segmentation standards using this formal-
ism. In Figure 1(c), for example, ???? (deputy
1326
director)? can be segmented as both ?? (deputy)
| ?? (director)? and ???? (deputy direc-
tor)?, but not ?? (deputy) ? (office) | ? (man-
ager)?, by dependency coherence. Chinese lan-
guage processing tasks, such as machine transla-
tion, can benefit from flexible segmentation stan-
dards (Zhang et al, 2008; Chang et al, 2008).
Second, word internal structures can also be
useful for syntactic parsing. Zhang et al (2013)
have shown the usefulness of word structures in
Chinese constituent parsing. Their results on the
Chinese Treebank (CTB) showed that character-
level constituent parsing can bring increased per-
formances even with the pseudo word structures.
They further showed that better performances can
be achieved when manually annotated word struc-
tures are used instead of pseudo structures.
In this paper, we make an investigation of
character-level Chinese dependency parsing using
Zhang et al (2013)?s annotations and based on
a transition-based parsing framework (Zhang and
Clark, 2011). There are two dominant transition-
based dependency parsing systems, namely the
arc-standard and the arc-eager parsers (Nivre,
2008). We study both algorithms for character-
level dependency parsing in order to make a com-
prehensive investigation. For direct comparison
with word-based parsers, we incorporate the tra-
ditional word segmentation, POS-tagging and de-
pendency parsing stages in our joint parsing mod-
els. We make changes to the original transition
systems, and arrive at two novel transition-based
character-level parsers.
We conduct experiments on three data sets, in-
cluding CTB 5.0, CTB 6.0 and CTB 7.0. Exper-
imental results show that the character-level de-
pendency parsing models outperform the word-
based methods on all the data sets. Moreover,
manually annotated intra-word dependencies can
give improved word-level dependency accuracies
than pseudo intra-word dependencies. These re-
sults confirm the usefulness of character-level
syntax for Chinese analysis. The source codes
are freely available at http://sourceforge.
net/projects/zpar/, version 0.7.
2 Character-Level Dependency Tree
Character-level dependencies were first proposed
by Zhao (2009). They show that by annotat-
ing character dependencies within words, one can
adapt to different segmentation standards. The
dependencies they study are restricted to intra-
word characters, as illustrated in Figure 1(b). For
inter-word dependencies, they use a pseudo right-
headed representation.
In this study, we integrate inter-word syntactic
dependencies and intra-word dependencies using
large-scale annotations of word internal structures
by Zhang et al (2013), and study their interac-
tions. We extract unlabeled dependencies from
bracketed word structures according to Zhang et
al.?s head annotations. In Figure 1(c), the depen-
dencies shown by dashed arcs are intra-word de-
pendencies, which reflect the internal word struc-
tures, while the dependencies with solid arcs are
inter-word dependencies, which reflect the syntac-
tic structures between words.
In this formulation, a character-level depen-
dency tree satisfies the same constraints as the
traditional word-based dependency tree for Chi-
nese, including projectivity. We differentiate intra-
word dependencies and inter-word dependencies
by the arc type, so that our work can be com-
pared with conventional word segmentation, POS-
tagging and dependency parsing pipelines under a
canonical segmentation standard.
The character-level dependency trees hold to a
specific word segmentation standard, but are not
limited to it. We can extract finer-grained words
of different granulities from a coarse-grained word
by taking projective subtrees of different sizes. For
example, taking all the intra-word modifier nodes
of ?? (manager)? in Figure 1(c) results in the
word ???? (deputy director)?, while taking the
first modifier node of ?? (manager)? results in the
word ??? (director)?. Note that ??? (deputy
office)? cannot be a word because it does not form
a projective span without ?? (manager)?.
Inner-word dependencies can also bring bene-
fits to parsing word-level dependencies. The head
character can be a less sparse feature compared
to a word. As intra-word dependencies lead to
fine-grained subwords, we can also use these sub-
words for better parsing. In this work, we use
the innermost left/right subwords as atomic fea-
tures. To extract the subwords, we find the inner-
most left/right modifiers of the head character, re-
spectively, and then conjoin them with all their de-
scendant characters to form the smallest left/right
subwords. Figure 2 shows an example, where the
smallest left subword of ???? (chief lawyer)?
is ??? (lawyer)?, and the smallest right subword
1327
? ? ?
big law officer
(a) smallest left subword
? ? ?
agree with law ize
(b) smallest right subword
Figure 2: An example to illustrate the innermost
left/right subwords.
of ???? (legalize)? is ??? (legal)?.
3 Character-Level Dependency Parsing
A transition-based framework with global learn-
ing and beam search decoding (Zhang and Clark,
2011) has been applied to a number of natural lan-
guage processing tasks, including word segmen-
tation, POS-tagging and syntactic parsing (Zhang
and Clark, 2010; Huang and Sagae, 2010; Bohnet
and Nivre, 2012; Zhang et al, 2013). It models
a task incrementally from a start state to an end
state, where each intermediate state during decod-
ing can be regarded as a partial output. A num-
ber of actions are defined so that the state ad-
vances step by step. To learn the model param-
eters, it usually uses the online perceptron algo-
rithm with early-update under the inexact decod-
ing condition (Collins, 2002; Collins and Roark,
2004). Transition-based dependency parsing can
be modeled under this framework, where the state
consists of a stack and a queue, and the set of ac-
tions can be either the arc-eager (Zhang and Clark,
2008) or the arc-standard (Huang et al, 2009)
transition systems.
When the internal structures of words are an-
notated, character-level dependency parsing can
be treated as a special case of word-level depen-
dency parsing, with ?words? being ?characters?.
A big weakness of this approach is that full words
and POS-tags cannot be used for feature engineer-
ing. Both are crucial to well-established features
for word segmentation, POS-tagging and syntactic
parsing. In this section, we introduce novel exten-
sions to the arc-standard and the arc-eager tran-
sition systems, so that word-based and character-
based features can be used simultaneously for
character-level dependency parsing.
3.1 The Arc-Standard Model
The arc-standard model has been applied to joint
segmentation, POS-tagging and dependency pars-
ing (Hatori et al, 2012), but with pseudo word
structures. For unified processing of annotated
word structures and fair comparison between
character-level arc-eager and arc-standard sys-
tems, we define a different arc-standard transition
system, consistent with our character-level arc-
eager system.
In the word-based arc-standard model, the tran-
sition state includes a stack and a queue, where
the stack contains a sequence of partially-parsed
dependency trees, and the queue consists of un-
processed input words. Four actions are defined
for state transition, including arc-left (AL, which
creates a left arc between the top element s
0
and
the second top element s
1
on the stack), arc-right
(AR, which creates a right arc between s
0
and s
1
),
pop-root (PR, which defines the root node of a de-
pendency tree when there is only one element on
the stack and no element in the queue), and the last
shift (SH, which shifts the first element q
0
of the
queue onto the stack).
For character-level dependency parsing, there
are two types of dependencies: inter-word depen-
dencies and intra-word dependencies. To parse
them with both character and word features, we
extend the original transition actions into two cat-
egories, for inter-word dependencies and intra-
word dependencies, respectively. The actions for
inter-word dependencies include inter-word arc-
left (AL
w
), inter-word arc-right (AR
w
), pop-root
(PR) and inter-word shift (SH
w
). Their definitions
are the same as the word-based model, with one
exception that the inter-word shift operation has
a parameter denoting the POS-tag of the incoming
word, so that POS disambiguation is performed by
the SH
w
action.
The actions for intra-word dependencies in-
clude intra-word arc-left (AL
c
), intra-word arc-
right (AR
c
), pop-word (PW) and inter-word shift
(SH
c
). The definitions of AL
c
, AR
c
and SH
c
are
the same as the word-based arc-standard model,
while PW changes the top element on the stack
into a full-word node, which can only take inter-
word dependencies. One thing to note is that, due
to variable word sizes in character-level parsing,
the number of actions can vary between differ-
ent sequences of actions corresponding to differ-
ent analyses. We use the padding method (Zhu
et al, 2013), adding an IDLE action to finished
transition action sequences, for better alignments
between states in the beam.
In the character-level arc-standard transition
1328
step action stack queue dependencies
0 - ? ? ? ? ? ? ?
1 SH
w
(NR) ?/NR ? ? ? ? ? ?
2 SH
c
?/NR ?/NR ? ? ? ? ? ?
3 AL
c
?/NR ? ? ? ? ? A
1
= {?x?}
4 SH
c
?/NR ?/NR ? ? ? ? ? A
1
5 AL
c
?/NR ? ? ? ? ? A
2
= A
1
?
{?x?}
6 PW ???/NR ? ? ? ? ? A
2
7 SH
w
(NN) ???/NR ?/NN ? ? ? ? ? A
2
? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
12 PW ???/NR ???/NN ? ? ? ? ? A
i
13 AL
w
???/NN ? ? ? ? ? A
i+1
= A
i
?
{???/NRx???/NN}
? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
(a) character-level dependency parsing using the arc-standard algorithm
step action stack deque queue dependencies
0 - ? ? ? ? ? ?
1 SH
c
(NR) ? ?/NR ? ? ? ? ? ?
2 AL
c
? ? ?/NR ? ? ? ? A
1
= {?x?}
3 SH
c
? ?/NR ? ? ? ? ? A
1
4 AL
c
? ? ?/NR ? ? ? ? A
2
= A
1
?
{?x?}
5 SH
c
? ?/NR ? ? ? ? ? A
2
6 PW ? ???/NR ? ? ? ? ? A
2
7 SH
w
???/NR ? ? ? ? ? ? A
2
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
13 PW ???/NR ???/NN ? ? ? ? ? A
i
14 AL
w
? ???/NN ? ? ? ? ? A
i+1
= A
i
?
{???/NRx???/NN}
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
(b) character-level dependency parsing using the arc-eager algorithm, t = 1
Figure 3: Character-level dependency parsing of the sentence in Figure 1(c).
system, each word is initialized by the action SH
w
with a POS tag, before being incrementally mod-
ified by a sequence of intra-word actions, and fi-
nally being completed by the action PW. The inter-
word actions can be applied when all the elements
on the stack are full-word nodes, while the intra-
word actions can be applied when at least the top
element on the stack is a partial-word node. For
the actions AL
c
and AR
c
to be valid, the top two
elements on the stack are both partial-word nodes.
For the action PW to be valid, only the top ele-
ment on the stack is a partial-word node. Figure
3(a) gives an example action sequence.
There are three types of features. The first two
types are traditionally established features for the
dependency parsing and joint word segmentation
and POS-tagging tasks. We use the features pro-
posed by Hatori et al (2012). The word-level
dependency parsing features are added when the
inter-word actions are applied, and the features
for joint word segmentation and POS-tagging are
added when the actions PW, SH
w
and SH
c
are ap-
plied. Following the work of Hatori et al (2012),
we have a parameter ? to adjust the weights for
joint word segmentation and POS-tagging fea-
tures. We apply word-based dependency pars-
ing features to intra-word dependency parsing as
well, by using subwords (the conjunction of char-
acters spanning the head node) to replace words in
word features. The third type of features is word-
structure features. We extract the head charac-
ter and the smallest subwords containing the head
character from the intra-word dependencies (Sec-
tion 2). Table 1 summarizes the features.
3.2 The Arc-Eager Model
Similar to the arc-standard case, the state of a
word-based arc-eager model consists of a stack
and a queue, where the stack contains a sequence
of partial dependency trees, and the queue con-
sists of unprocessed input words. Unlike the arc-
standard model, which builds dependencies on the
top two elements on the stack, the arc-eager model
builds dependencies between the top element of
the stack and the first element of the queue. Five
actions are defined for state transformation: arc-
left (AL, which creates a left arc between the top
element of the stack s
0
and the first element in
the queue q
0
, while popping s
0
off the stack),
arc-right (AR, which creates a right arc between
1329
Feature templates
Lc, Lct, Rc, Rct, L
lc1
c, L
rc1
c, R
lc1
c,
Lc ?Rc, L
lc1
ct, L
rc1
ct, R
lc1
ct,
Lc ?Rw, Lw ?Rc, Lct ?Rw,
Lwt ?Rc, Lw ?Rct, Lc ?Rwt,
Lc ?Rc ? L
lc1
c, Lc ?Rc ? L
rc1
c,
Lc ?Rc ? L
lc2
c, Lc ?Rc ? L
rc2
c,
Lc ?Rc ?R
lc1
c, Lc ?Rc ?R
lc2
c,
Llsw, Lrsw, Rlsw, Rrsw, Llswt,
Lrswt, Rlswt, Rrswt, Llsw ?Rw,
Lrsw ?Rw, Lw ?Rlsw, Lw ?Rrsw
Table 1: Feature templates encoding intra-word
dependencies. L and R denote the two elements
over which the dependencies are built; the sub-
scripts lc1 and rc1 denote the left-most and right-
most children, respectively; the subscripts lc2 and
rc2 denote the second left-most and second right-
most children, respectively; w denotes the word;
t denotes the POS tag; c denotes the head charac-
ter; lsw and rsw denote the smallest left and right
subwords respectively, as shown in Figure 2.
s
0
and q
0
, while shifting q
0
from the queue onto
the stack), pop-root (PR, which defines the ROOT
node of the dependency tree when there is only
one element on the stack and no element in the
queue), reduce (RD, which pops s
0
off the stack),
and shift (SH, which shifts q
0
onto the stack).
There is no previous work that exploits the
arc-eager algorithm for jointly performing POS-
tagging and dependency parsing. Since the first
element of the queue can be shifted onto the stack
by either SH or AR, it is more difficult to assign
a POS tag to each word by using a single action.
In this work, we make a change to the configu-
ration state, adding a deque between the stack and
the queue to save partial words with intra-word de-
pendencies. We divide the transition actions into
two categories, one for inter-word dependencies
(AR
w
, AL
w
, SH
w
, RD
w
and PR) and the other
for intra-word dependencies (AR
c
, AL
c
, SH
c
, RD
c
and PW), requiring that the intra-word actions be
operated between the deque and the queue, while
the inter-word actions be operated between the
stack and the deque.
For character-level arc-eager dependency pars-
ing, the inter-word actions are the same as the
word-based methods. The actions AL
c
and AR
c
are the same as AL
w
and AR
w
, except that they
operate on characters, but the SH
c
operation has a
parameter to denote the POS tag of a word. The
PW action recognizes a full-word. We also have
an IDLE action, for the same reason as the arc-
standard model.
In the character-level arc-eager transition sys-
tem, a word is formed in a similar way with that
of character-level arc-standard algorithm. Each
word is initialized by the action SH
c
with a POS
tag, and then incrementally changed a sequence of
intra-word actions, before being finalized by the
action PW. All these actions operate between the
queue and deque. For the action PW, only the
first element in the deque (close to the queue) is
a partial-word node. For the actions AR
c
and AL
c
to be valid, the first element in the deque must be
a partial-word node. The action SH
c
have a POS
tag when shifting the first character of a word,but
does not have such a parameter when shifting the
next characters of a word. For the action SH
c
with
a POS tag to be valid, the first element in the deque
must be a full-word node. Different from the arc-
standard model, at any stage we can choose either
the action SH
c
with a POS tag to initialize a new
word on the deque, or the inter-word actions on
the stack. In order to eliminate the ambiguity, we
define a new parameter t to limit the max size of
the deque. If the deque is full with t words, inter-
word actions are performed; otherwise intra-word
actions are performed. All the inter-word actions
must be applied on full-word nodes between the
stack an the deque. Figure 3(b) gives an example
action sequence.
Similar to the arc-standard case, there are three
types of features, with the first two types being
traditionally established features for dependency
parsing and joint word segmentation and POS-
tagging. The dependency parsing features are
taken from the work of Zhang and Nivre (2011),
and the features for joint word segmentation and
POS-tagging are taken from Zhang and Clark
(2010)
1
. The word-level dependency parsing fea-
tures are triggered when the inter-word actions are
applied, while the features of joint word segmenta-
tion and POS-tagging are added when the actions
SH
c
, AR
c
and PW are applied. Again we use a pa-
rameter ? to adjust the weights for joint word seg-
mentation and POS-tagging features. The word-
level features for dependency parsing are applied
to intra-word dependency parsing as well, by us-
ing subwords to replace words. The third type of
features is word-structure features, which are the
1
Since Hatori et al (2012) also use Zhang and Clark
(2010)?s features, the arc-standard and arc-eager character-
level dependency parsing models have the same features for
joint word segmentation and POS-tagging.
1330
CTB50 CTB60 CTB70
Training
#sent 18k 23k 31k
#word 494k 641k 718k
Development
#sent 350 2.1k 10k
#word 6.8k 60k 237k
#oov 553 3.3k 13k
Test
#sent 348 2.8k 10k
#word 8.0k 82k 245k
#oov 278 4.6k 13k
Table 2: Statistics of datasets.
same as those of the character-level arc-standard
model, shown in Table 1.
4 Experiments
4.1 Experimental Settings
We use the Chinese Penn Treebank 5.0, 6.0 and 7.0
to conduct the experiments, splitting the corpora
into training, development and test sets according
to previous work. Three different splitting meth-
ods are used, namely CTB50 by Zhang and Clark
(2010), CTB60 by the official documentation of
CTB 6.0, and CTB70 by Wang et al (2011). The
dataset statistics are shown in Table 2. We use
the head rules of Zhang and Clark (2008) to con-
vert phrase structures into dependency structures.
The intra-word dependencies are extracted from
the annotations of Zhang et al (2013)
2
.
The standard measures of word-level precision,
recall and F1 score are used to evaluate word seg-
mentation, POS-tagging and dependency parsing,
following Hatori et al (2012). In addition, we use
the same measures to evaluate intra-word depen-
dencies, which indicate the performance of pre-
dicting word structures. A word?s structure is cor-
rect only if all the intra-word dependencies are all
correctly recognized.
4.2 Baseline and Proposed Models
For the baseline, we have two different pipeline
models. The first consists of a joint segmentation
and POS-tagging model (Zhang and Clark, 2010)
and a word-based dependency parsing model us-
ing the arc-standard algorithm (Huang et al,
2009). We name this model STD (pipe). The
second consists of the same joint segmentation
and POS-tagging model and a word-based depen-
dency parsing model using the arc-eager algorithm
2
https://github.com/zhangmeishan/
wordstructures; their annotation was conducted
on CTB 5.0, while we made annotations of the remainder of
the CTB 7.0 words. We also make the annotations publicly
available at the same site.
(Zhang and Nivre, 2011). We name this model
EAG (pipe). For the pipeline models, we use a
beam of size 16 for joint segmentation and POS-
tagging, and a beam of size 64 for dependency
parsing, according to previous work.
We study the following character-level depen-
dency parsing models:
? STD (real, pseudo): the arc-standard model
with annotated intra-word dependencies and
pseudo inter-word dependencies;
? STD (pseudo, real): the arc-standard model
with pseudo intra-word dependencies and
real inter-word dependencies;
? STD (real, real): the arc-standard model with
annotated intra-word dependencies and real
inter-word dependencies;
? EAG (real, pseudo): the arc-eager model
with annotated intra-word dependencies and
pseudo inter-word dependencies;
? EAG (pseudo, real): the arc-eager model
with pseudo intra-word dependencies and
real inter-word dependencies;
? EAG (real, real): the arc-eager model with
annotated intra-word dependencies and real
inter-word dependencies.
The annotated intra-word dependencies refer to
the dependencies extracted from annotated word
structures, while the pseudo intra-word depen-
dencies used in the above models are similar
to those of Hatori et al (2012). For a given
word w = c
1
c
2
? ? ? c
m
, the intra-word depen-
dency structure is c
x
1
c
x
2
? ? ?
x
c
m
3
. The real inter-
word dependencies refer to the syntactic word-
level dependencies by head-finding rules from
CTB, while the pseudo inter-word dependencies
refer to the word-level dependencies used by Zhao
(2009) (w
x
1
w
x
2
? ? ?
x
w
n
). The character-level
models with annotated intra-word dependencies
and pseudo inter-word dependencies are compared
with the pipelines on word segmentation and POS-
tagging accuracies, and are compared with the
character-level models with annotated intra-word
dependencies and real inter-word dependencies
on word segmentation, POS-tagging and word-
structure predicating accuracies. All the proposed
3
We also tried similar structures with right arcs, which
gave lower accuracies.
1331
STD (real, real) SEG POS DEP WS
? = 1 95.85 91.60 76.96 95.14
? = 2 96.09 91.89 77.28 95.29
? = 3 96.02 91.84 77.22 95.23
? = 4 96.10 91.96 77.49 95.29
? = 5 96.07 91.90 77.31 95.21
Table 3: Development test results of the character-
level arc-standard model on CTB60.
EAG (real, real) SEG POS DEP WS
? = 1
t = 1 96.00 91.66 74.63 95.49
t = 2 95.93 91.75 76.60 95.37
t = 3 95.93 91.74 76.94 95.36
t = 4 95.91 91.71 76.82 95.33
t = 5 95.95 91.73 76.84 95.40
t = 3
? = 1 95.93 91.74 76.94 95.36
? = 2 96.11 91.99 77.17 95.56
? = 3 96.16 92.01 77.48 95.62
? = 4 96.11 91.93 77.40 95.53
? = 5 96.00 91.84 77.10 95.43
Table 4: Development test results of the character-
level arc-eager model on CTB60.
models use a beam of size 64 after considering
both speeds and accuracies.
4.3 Development Results
Our development tests are designed for two pur-
poses: adjusting the parameters for the two pro-
posed character-level models and testing the effec-
tiveness of the novel word-structure features. Tun-
ing is conducted by maximizing word-level depen-
dency accuracies. All the tests are conducted on
the CTB60 data set.
4.3.1 Parameter Tuning
For the arc-standard model, there is only one pa-
rameter ? that needs tuning. It adjusts the weights
of segmentation and POS-tagging features, be-
cause the number of feature templates is much less
for the two tasks than for parsing. We set the value
of ? to 1 ? ? ? 5, respectively. Table 3 shows the
accuracies on the CTB60 development set. Ac-
cording to the results, we use ? = 4 for our final
character-level arc-standard model.
For the arc-eager model, there are two parame-
ters t and ?. t denotes the deque size of the arc-
eager model, while ? shares the same meaning as
the arc-standard model. We take two steps for pa-
rameter tuning, first adjusting the more crucial pa-
rameter t and then adjusting ? on the best t. Both
parameters are assigned the values of 1 to 5. Ta-
SEG POS DEP WS
STD (real, real) 96.10 91.96 77.49 95.29
STD (real, real)/wo 95.99 91.79 77.19 95.35
? -0.11 -0.17 -0.30 +0.06
EAG (real, real) 96.16 92.01 77.48 95.62
EAG (real, real)/wo 96.09 91.82 77.12 95.56
? -0.07 -0.19 -0.36 -0.06
Table 5: Feature ablation tests for the novel word-
structure features, where ?/wo? denotes the corre-
sponding models without the novel intra-word de-
pendency features.
ble 4 shows the results. According to results, we
set t = 3 and ? = 3 for the final character-level
arc-eager model, respectively.
4.3.2 Effectiveness of Word-Structure
Features
To test the effectiveness of our novel word-
structure features, we conduct feature ablation ex-
periments on the CTB60 development data set for
the proposed arc-standard and arc-eager models,
respectively. Table 5 shows the results. We can
see that both the two models achieve better accu-
racies on word-level dependencies with the novel
word-structure features, while the features do not
affect word-structure predication significantly.
4.4 Final Results
Table 6 shows the final results on the CTB50,
CTB60 and CTB70 data sets, respectively. The
results demonstrate that the character-level depen-
dency parsing models are significantly better than
the corresponding word-based pipeline models,
for both the arc-standard and arc-eager systems.
Similar to the findings of Zhang et al (2013), we
find that the annotated word structures can give
better accuracies than pseudo word structures. An-
other interesting finding is that, although the arc-
eager algorithm achieves lower accuracies in the
word-based pipeline models, it obtains compara-
tive accuracies in the character-level models.
We also compare our results to those of Hatori
et al (2012), which is comparable to STD (pseudo,
real) since similar arc-standard algorithms and
features are used. The major difference is the
set of transition actions. We rerun their system
on the three datasets
4
. As shown in Table 6, our
arc-standard system with pseudo word structures
4
http://triplet.cc/. We use a different
constituent-to-dependency conversion scheme in com-
parison with Hatori et al (2012)?s work.
1332
Model
CTB50 CTB60 CTB70
SEG POS DEP WS SEG POS DEP WS SEG POS DEP WS
The arc-standard models
STD (pipe) 97.53 93.28 79.72 ? 95.32 90.65 75.35 ? 95.23 89.92 73.93 ?
STD (real, pseudo) 97.78 93.74 ? 97.40 95.77
?
91.24
?
? 95.08 95.59
?
90.49
?
? 94.97
STD (pseudo, real) 97.67 94.28
?
81.63
?
? 95.63
?
91.40
?
76.75
?
? 95.53
?
90.75
?
75.63
?
?
STD (real, real) 97.84 94.62
?
82.14
?
97.30 95.56
?
91.39
?
77.09
?
94.80 95.51
?
90.76
?
75.70
?
94.78
Hatori+ ?12 97.75 94.33 81.56 ? 95.26 91.06 75.93 ? 95.27 90.53 74.73 ?
The arc-eager models
EAG (pipe) 97.53 93.28 79.59 ? 95.32 90.65 74.98 ? 95.23 89.92 73.46 ?
EAG (real, pseudo) 97.75 93.88 ? 97.45 95.63
?
91.07
?
? 95.06 95.50
?
90.36
?
? 95.00
EAG (pseudo, real) 97.76 94.36
?
81.70
?
? 95.63
?
91.34
?
76.87
?
? 95.39
?
90.56
?
75.56
?
?
EAG (real, real) 97.84 94.36
?
82.07
?
97.49 95.71
?
91.51
?
76.99
?
95.16 95.47
?
90.72
?
75.76
?
94.94
Table 6: Main results, where the results marked with ? denote that the p-value is less than 0.001 compared
with the pipeline word-based models using pairwise t-test.
brings consistent better accuracies than their work
on all the three data sets.
Both the pipelines and character-level mod-
els with pseudo inter-word dependencies perform
word segmentation and POS-tagging jointly, with-
out using real word-level syntactic information. A
comparison between them (STD/EAG (pipe) vs.
STD/EAG (real, pseudo)) reflects the effectiveness
of annotated intra-word dependencies on segmen-
tation and POS-tagging. We can see that both the
arc-standard and arc-eager models with annotated
intra-word dependencies can improve the segmen-
tation accuracies by 0.3% and the POS-tagging ac-
curacies by 0.5% on average on the three datasets.
Similarly, a comparison between the character-
level models with pseudo inter-word dependen-
cies and the character-level models with real inter-
word dependencies (STD/EAG (real, pseudo) vs.
STD/EAG (real, real)) can reflect the effectiveness
of annotated inter-word structures on morphology
analysis. We can see that improved POS-tagging
accuracies are achieved using the real inter-word
dependencies when jointly performing inner- and
inter-word dependencies. However, we find that
the inter-word dependencies do not help the word-
structure accuracies.
4.5 Analysis
To better understand the character-level parsing
models, we conduct error analysis in this section.
All the experiments are conducted on the CTB60
test data sets. The new advantage of the character-
level models is that one can parse the internal
word structures of intra-word dependencies. Thus
we are interested in their capabilities of predict-
ing word structures. We study the word-structure
accuracies in two aspects, including OOV, word
length, POS tags and the parsing model.
4.5.1 OOV
The word-structure accuracy of OOV words re-
flects a model?s ability of handling unknown
words. The overall recalls of OOV word structures
are 67.98% by STD (real, real) and 69.01% by
EAG (real, real), respectively. We find that most
errors are caused by failures of word segmenta-
tion. We further investigate the accuracies when
words are correctly segmented, where the accura-
cies of OOV word structures are 87.64% by STD
(real, real) and 89.07% by EAG (real, real). The
results demonstrate that the structures of Chinese
words are not difficult to predict, and confirm the
fact that Chinese word structures have some com-
mon syntactic patterns.
4.5.2 Parsing Model
From the above analysis in terms of OOV, word
lengths and POS tags, we can see that the EAG
(real, real) model and the STD (real, real) mod-
els behave similarly on word-structure accuracies.
Here we study the two models more carefully,
comparing their word accuracies sentence by sen-
tence. Figure 4 shows the results, where each
point denotes a sentential comparison between
STD (real, real) and EAG (real, real), the x-axis
denotes the sentential word-structure accuracy of
STD (real, real), and the y-axis denotes that of
EAG (real, real). The points at the diagonal show
the same accuracies by the two models, while oth-
ers show that the two models perform differently
on the corresponding sentences. We can see that
most points are beyond the diagonal line, indicat-
1333
0.6 0.7 0.8 0.9 1
0.6
0.7
0.8
0.9
1
STD (real, real)
E
A
G
(
r
e
a
l
,
r
e
a
l
)
Figure 4: Sentential word-structure accuracies of
STD (real, real) and EAG (real, real).
ing that the two parsing models can be comple-
mentary in parsing intra-word dependencies.
5 Related Work
Zhao (2009) was the first to study character-level
dependencies; they argue that since no consistent
word boundaries exist over Chinese word segmen-
tation, dependency-based representations of word
structures serve as a good alternative for Chinese
word segmentation. Thus their main concern is
to parse intra-word dependencies. In this work,
we extend their formulation, making use of large-
scale annotations of Zhang et al (2013), so that the
syntactic word-level dependencies can be parsed
together with intra-word dependencies.
Hatori et al (2012) proposed a joint model
for Chinese word segmentation, POS-tagging and
dependency parsing, studying the influence of
joint model and character features for parsing,
Their model is extended from the arc-standard
transition-based model, and can be regarded as
an alternative to the arc-standard model of our
work when pseudo intra-word dependencies are
used. Similar work is done by Li and Zhou (2012).
Our proposed arc-standard model is more concise
while obtaining better performance than Hatori et
al. (2012)?s work. With respect to word structures,
real intra-word dependencies are often more com-
plicated, while pseudo word structures cannot be
used to correctly guide segmentation.
Zhao (2009), Hatori et al (2012) and our
work all study character-level dependency pars-
ing. While Zhao (2009) focus on word internal
structures using pseudo inter-word dependencies,
Hatori et al (2012) investigate a joint model using
pseudo intra-word dependencies. We use manual
dependencies for both inner- and inter-word struc-
tures, studying their influences on each other.
Zhang et al (2013) was the first to perform Chi-
nese syntactic parsing over characters. They ex-
tended word-level constituent trees by annotated
word structures, and proposed a transition-based
approach to parse intra-word structures and word-
level constituent structures jointly. For Hebrew,
Tsarfaty and Goldberg (2008) investigated joint
segmentation and parsing over characters using a
graph-based method. Our work is similar in ex-
ploiting character-level syntax. We study the de-
pendency grammar, another popular syntactic rep-
resentation, and propose two novel transition sys-
tems for character-level dependency parsing.
Nivre (2008) gave a systematic description of
the arc-standard and arc-eager algorithms, cur-
rently two popular transition-based parsing meth-
ods for word-level dependency parsing. We extend
both algorithms to character-level joint word seg-
mentation, POS-tagging and dependency parsing.
To our knowledge, we are the first to apply the arc-
eager system to joint models and achieve compar-
ative performances to the arc-standard model.
6 Conclusions
We studied the character-level Chinese depen-
dency parsing, by making novel extensions to
two commonly-used transition-based dependency
parsing algorithms for word-based dependency
parsing. With both pseudo and annotated word
structures, our character-level models obtained
better accuracies than previous work on seg-
mentation, POS-tagging and word-level depen-
dency parsing. We further analyzed some im-
portant factors for intra-word dependencies, and
found that two proposed character-level pars-
ing models are complementary in parsing intra-
word dependencies. We make the source code
publicly available at http://sourceforge.
net/projects/zpar/, version 0.7.
Acknowledgments
We thank the anonymous reviewers for their
constructive comments, and gratefully acknowl-
edge the support of the National Basic Re-
search Program (973 Program) of China via Grant
2014CB340503, the National Natural Science
Foundation of China (NSFC) via Grant 61133012
and 61370164, the Singapore Ministry of Educa-
tion (MOE) AcRF Tier 2 grant T2MOE201301
and SRG ISTD 2012 038 from Singapore Univer-
sity of Technology and Design.
1334
References
Bernd Bohnet and Joakim Nivre. 2012. A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing. In Pro-
ceedings of the EMNLP-CONLL, pages 1455?1465,
Jeju Island, Korea, July.
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd COLING, number August, pages
89?97.
Xavier Carreras, Mihai Surdeanu, and Llu??s M`arquez.
2006. Projective dependency parsing with per-
ceptron. In Proceedings of the Tenth Confer-
ence on Computational Natural Language Learning
(CoNLL-X), pages 181?185, New York City, June.
Pi-Chuan Chang, Michel Galley, and Chris Manning.
2008. Optimizing chinese word segmentation for
machine translation performance. In ACL Workshop
on Statistical Machine Translation.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, , and
Christopher D. Manning. 2009. Discriminative
reordering with chinese grammatical relations fea-
tures. In Proceedings of the Third Workshop on Syn-
tax and Structure in Statistical Translation.
Jinho D. Choi and Andrew McCallum. 2013.
Transition-based dependency parsing with selec-
tional branching. In Proceedings of ACL, pages
1052?1062, August.
Michael Collins and Brian Roark. 2004. Incremen-
tal parsing with the perceptron algorithm. In Pro-
ceedings of the 42nd Meeting of the Association for
Computational Linguistics (ACL?04), Main Volume,
pages 111?118, Barcelona, Spain, July.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the 7th EMNLP.
Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Proba-
bilistic models for action-based chinese dependency
parsing. In Proceedings of ECML/ECPPKDD, vol-
ume 4701 of Lecture Notes in Computer Science,
pages 559?566.
Thomas Emerson. 2005. The second international chi-
nese word segmentation bakeoff. In Proceedings
of the Second SIGHAN Workshop on Chinese Lan-
guage Processing, pages 123?133.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun?ichi Tsujii. 2012. Incremental joint approach
to word segmentation, pos tagging, and dependency
parsing in chinese. In Proceedings of the 50th ACL,
pages 1045?1053, Jeju Island, Korea, July.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In
Proceedings of the 48th ACL, pages 1077?1086, Up-
psala, Sweden, July.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing: Volume 3-Volume 3, pages 1222?1231. Asso-
ciation for Computational Linguistics.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the
48th Annual Meeting of the ACL, pages 1?11.
Zhongguo Li and Guodong Zhou. 2012. Unified de-
pendency parsing of chinese morphological and syn-
tactic structures. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 1445?1454, Jeju Island, Ko-
rea, July.
Zhenghua Li, Ting Liu, and Wanxiang Che. 2012. Ex-
ploiting multiple treebanks for parsing with quasi-
synchronous grammars. In Proceedings of the 50th
ACL, pages 675?684, Jeju Island, Korea, July.
Zhongguo Li. 2011. Parsing the internal structure of
words: A new paradigm for chinese word segmenta-
tion. In Proceedings of the 49th ACL, pages 1405?
1414, Portland, Oregon, USA, June.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Proceedings of ACL, number
June, pages 91?98, Morristown, NJ, USA.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-
projective dependency parsing. In Proceedings of
ACL.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Computational Lin-
guistics, 34(4):513?553.
Reut Tsarfaty and Yoav Goldberg. 2008. Word-based
or morpheme-based? annotation strategies for mod-
ern hebrew clitics. In LREC. European Language
Resources Association.
Yiou Wang, Jun?ichi Kazama, Yoshimasa Tsuruoka,
Wenliang Chen, Yujie Zhang, and Kentaro Tori-
sawa. 2011. Improving chinese word segmenta-
tion and pos tagging with semi-supervised methods
using large auto-analyzed data. In Proceedings of
5th IJCNLP, pages 309?317, Chiang Mai, Thailand,
November.
Yue Zhang and Stephen Clark. 2008. A tale of
two parsers: Investigating and combining graph-
based and transition-based dependency parsing. In
Proceedings of EMNLP, pages 562?571, Honolulu,
Hawaii, October.
Yue Zhang and Stephen Clark. 2010. A fast decoder
for joint word segmentation and POS-tagging using
a single discriminative model. In Proceedings of the
EMNLP, pages 843?852, Cambridge, MA, October.
1335
Yue Zhang and Stephen Clark. 2011. Syntactic pro-
cessing using the generalized perceptron and beam
search. Computational Linguistics, 37(1):105?151.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th ACL, pages 188?193, Port-
land, Oregon, USA, June.
Ruiqiang Zhang, Keiji Yasuda, and Eiichiro Sumita.
2008. Chinese word segmentation and statistical
machine translation. IEEE Transactions on Signal
Processing, 5(2).
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting
Liu. 2013. Chinese parsing exploiting characters.
In Proceedings of the 51st ACL, pages 125?134,
Sofia, Bulgaria, August.
Hai Zhao. 2009. Character-level dependencies in chi-
nese: Usefulness and learning. In Proceedings of
the EACL, pages 879?887, Athens, Greece, March.
Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,
and Jingbo Zhu. 2013. Fast and accurate shift-
reduce constituent parsing. In Proceedings of the
51st ACL, pages 434?443, Sofia, Bulgaria, August.
1336
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: Tutorials, pages 13?15,
Baltimore, Maryland, USA, 22 June 2014.
c?2014 Association for Computational Linguistics
Incremental Structured Prediction Using a Global Learning and
Beam-Search Framework
Yue Zhang
?
, Meishan Zhang
?
, Ting Liu
?
?
Singapore University of Technology and Design
yue zhang@sutd.edu.sg
?
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{mszhang, tliu}@ir.hit.edu.cn
Abstract
This tutorial discusses a framework for in-
cremental left-to-right structured predica-
tion, which makes use of global discrimi-
native learning and beam-search decoding.
The method has been applied to a wide
range of NLP tasks in recent years, and
achieved competitive accuracies and effi-
ciencies. We give an introduction to the
algorithms and efficient implementations,
and discuss their applications to a range of
NLP tasks.
1 Introduction
This tutorial discusses a framework of online
global discriminative learning and beam-search
decoding for syntactic processing (Zhang and
Clark, 2011b), which has recently been applied
to a wide variety of natural language processing
(NLP) tasks, including word segmentation (Zhang
and Clark, 2007), dependency parsing (Zhang and
Clark, 2008b; Huang and Sagae, 2010; Zhang and
Nivre, 2011; Bohnet and Kuhn, 2012), context
free grammar (CFG) parsing (Collins and Roark,
2004; Zhang and Clark, 2009; Zhu et al., 2013),
combinational categorial grammar (CCG) parsing
(Zhang and Clark, 2011a; Xu et al., 2014) and
machine translation (Liu, 2013), achieving state-
of-the-art accuracies and efficiencies. In addition,
due to its high efficiencies, it has also been ap-
plied to a range of joint structural problems, such
as joint segmentation and POS-tagging (Zhang
and Clark, 2008a; Zhang and Clark, 2010), joint
POS-tagging and dependency parsing (Hatori et
al., 2011; Bohnet and Nivre, 2012), joint mor-
phological analysis, POS-tagging and dependency
parsing (Bohnet et al., 2013), and joint segmenta-
tion, POS-tagging and parsing (Zhang et al., 2013;
Zhang et al., 2014).
In addition to the aforementioned tasks, the
framework can be applied to all structural pre-
diction tasks for which the output can be con-
structed using an incremental process. The advan-
tage of this framework is two-fold. First, beam-
search enables highly efficient decoding, which
typically has linear time complexity, depending on
the incremental process. Second, free from DP-
style constraints and Markov-style independence
assumptions, the framework allows arbitrary fea-
tures to be defined to capture structural patterns.
In addition to feature advantages, the high accura-
cies of this framework are also enabled by direct
interactions between learning and search (Daum?e
III and Marcu, 2005; Huang et al., 2012; Zhang
and Nivre, 2012).
2 Tutorial Overview
In this tutorial, we make an introduction to the
framework, illustrating how it can be applied to
a range of NLP problems, giving theoretical dis-
cussions and demonstrating a software implemen-
tation. We start with a detailed introduction of
the framework, describing the averaged percep-
tron algorithm (Collins, 2002) and its efficient im-
plementation issues (Zhang and Clark, 2007), as
well as beam-search and the early-update strategy
(Collins and Roark, 2004). We then illustrate how
the framework can be applied to NLP tasks, in-
cluding word segmentation, joint segmentation &
POS-tagging, labeled and unlabeled dependency
parsing, joint POS-tagging and dependency pars-
ing, CFG parsing, CCG parsing, and joint segmen-
tation, POS-tagging and parsing. In each case, we
illustrate how the task is turned into an incremen-
tal left-to-right output-building process, and how
rich features are defined to give competitive accu-
racies. These examples can serve as guidance in
applying the framework to other structural predic-
tion tasks.
In the second part of the tutorial, we give
some analysis on why the framework is effective.
We discuss several alternative learning algorithms,
13
and compare beam-search with greedy search on
dependency parsing. We show that accuracy bene-
fits from interaction between learning and search.
Finally, the tutorial concludes with an introduction
to ZPar, an open source toolkit that provides op-
timized C++ implementations of of all the above
tasks.
3 Outline
1 Introduction (0.5 hours)
1.1 An overview of the syntactic processing
framework and its applications
1.2 An introduction to the beam-search
framework and comparison to dynamic
programming
1.3 Algorithm in details
1.3.1 Online discriminative learning using
the perceptron
1.3.2 Beam-search decoding
1.3.3 The integrated framework
2 Applications (1.25 hours)
2.1 Overview
2.2 Word segmentation
2.3 Joint segmentation and POS-tagging
2.4 Dependency parsing
2.5 Context free grammar parsing
2.6 Combinatory categorial grammar pars-
ing
2.7 Joint segmentation, POS-tagging and
parsing
3 Analysis of the framework (0.75 hours)
3.1 The influence of global learning
3.2 The influence of beam-search
3.3 Benefits from the combination
3.4 Related discussions
4 The ZPar software tool (0.5 hours)
4 About the Presenters
Yue Zhang is an Assistant Professor at Singapore
University of Technology and Design (SUTD).
Before joining SUTD in 2012, he worked as a
postdoctoral research associate at University of
Cambridge. He received his PhD and MSc degrees
from University of Oxford, and undergraduate de-
gree from Tsinghua University, China. Dr Zhang?s
research interest includes natural language pars-
ing, natural language generation, machine trans-
lation and machine learning.
Meishan Zhang is a fifth-year Phd candidate at
Research Center for Social Computing and Infor-
mation Retrieval, Harbin Institute of Technology,
China (HIT-SCIR). His research interest includes
Chinese morphological and syntactic parsing, se-
mantic representation and parsing, joint modelling
and machine learning.
Ting Liu is a professor at HIT-SCIR. His re-
search interest includes social computing, infor-
mation retrieval and natural language processing.
References
Bernd Bohnet and Jonas Kuhn. 2012. The best of
bothworlds ? a graph-based completion model for
transition-based parsers. In Proceedings of EACL,
pages 77?87, Avignon, France, April. Association
for Computational Linguistics.
Bernd Bohnet and Joakim Nivre. 2012. A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing. In Pro-
ceedings of EMNLP, pages 1455?1465, Jeju Island,
Korea, July. Association for Computational Linguis-
tics.
Bernd Bohnet, Joakim Nivre, Igor Boguslavsky,
Richard Farkas, Filip Ginter, and Jan Hajic. 2013.
Joint morphological and syntactic analysis for richly
inflected languages. Transactions of the Association
for Computational Linguistics, 1:415?428.
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceed-
ings of ACL 2004, Main Volume, pages 111?118,
Barcelona, Spain, July.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings
of EMNLP, pages 1?8. Association for Computa-
tional Linguistics, July.
Hal Daum?e III and Daniel Marcu. 2005. Learning
as search optimization: Approximate large margin
methods for structured prediction. In International
Conference on Machine Learning (ICML), Bonn,
Germany.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun?ichi Tsujii. 2011. Incremental joint pos tagging
and dependency parsing in chinese. In Proceedings
of IJCNLP, pages 1216?1224, Chiang Mai, Thai-
land, November. Asian Federation of Natural Lan-
guage Processing.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In
Proceedings of ACL 2010, pages 1077?1086, Upp-
sala, Sweden, July. Association for Computational
Linguistics.
14
Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Pro-
ceedings of NAACL 2012, pages 142?151, Montr?eal,
Canada, June. Association for Computational Lin-
guistics.
Yang Liu. 2013. A shift-reduce parsing algorithm for
phrase-based string-to-dependency translation. In
Proceedings of the ACL, pages 1?10, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.
Wenduan Xu, Yue Zhang, and Stephen Clark. 2014.
Shift-reduce ccg parsing with a dependency model.
In Proceedings of the ACL.
Yue Zhang and Stephen Clark. 2007. Chinese segmen-
tation with a word-based perceptron algorithm. In
Proceedings of ACL 2007, pages 840?847, Prague,
Czech Republic, June. Association for Computa-
tional Linguistics.
Yue Zhang and Stephen Clark. 2008a. Joint word seg-
mentation and POS tagging using a single percep-
tron. In Proceedings of ACL-08: HLT, pages 888?
896, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Yue Zhang and Stephen Clark. 2008b. A tale of
two parsers: Investigating and combining graph-
based and transition-based dependency parsing. In
Proceedings of EMNLP, pages 562?571, Honolulu,
Hawaii, October. Association for Computational
Linguistics.
Yue Zhang and Stephen Clark. 2009. Transition-
based parsing of the chinese treebank using a global
discriminative model. In Proceedings of IWPT?09,
pages 162?171, Paris, France, October. Association
for Computational Linguistics.
Yue Zhang and Stephen Clark. 2010. A fast decoder
for joint word segmentation and POS-tagging us-
ing a single discriminative model. In Proceedings
of EMNLP 2010, pages 843?852, Cambridge, MA,
October. Association for Computational Linguistics.
Yue Zhang and Stephen Clark. 2011a. Shift-reduce
ccg parsing. In Proceedings of ACL 2011, pages
683?692, Portland, Oregon, USA, June. Association
for Computational Linguistics.
Yue Zhang and Stephen Clark. 2011b. Syntactic pro-
cessing using the generalized perceptron and beam
search. Computational Linguistics, 37(1):105?151.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of ACL 2011, pages 188?193, Portland,
Oregon, USA, June. Association for Computational
Linguistics.
Yue Zhang and Joakim Nivre. 2012. Analyzing
the effect of global learning and beam-search on
transition-based dependency parsing. In Proceed-
ings of COLING 2012: Posters, pages 1391?1400,
Mumbai, India, December. The COLING 2012 Or-
ganizing Committee.
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting
Liu. 2013. Chinese parsing exploiting characters.
In Proceedings of ACL 2013.
Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting
Liu. 2014. Character-level chinese dependency
parsing. In Proceedings of the ACL.
Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,
and Jingbo Zhu. 2013. Fast and accurate shift-
reduce constituent parsing. In Proceedings of ACL
2013.
15
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 378?384,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
SemEval-2012 Task 5: Chinese Semantic Dependency Parsing
Wanxiang Che?, Meishan Zhang?, Yanqiu Shao?, Ting Liu?
?Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
{car, mszhang, tliu}@ir.hit.edu.cn
?Beijing City University, China
yqshao@bcu.edu.cn
Abstract
The paper presents the SemEval-2012 Shared
Task 5: Chinese Semantic Dependency Pars-
ing. The goal of this task is to identify the de-
pendency structure of Chinese sentences from
the semantic view. We firstly introduce the
motivation of providing Chinese semantic de-
pendency parsing task, and then describe the
task in detail including data preparation, data
format, task evaluation, and so on. Over ten
thousand sentences were labeled for partici-
pants to train and evaluate their systems. At
last, we briefly describe the submitted systems
and analyze these results.
1 Introduction
Semantic analysis is a long-term goal of Natural
Language Processing, and as such, has been re-
searched for several decades. A number of tasks
for encoding semantic information have been devel-
oped over the years, such as entity type recognition
and word sense disambiguation. Recently, sentence-
level semantics ? in particular, semantic role label-
ing ? has received increasing attention. However,
some problems concerning the semantic representa-
tion method used in semantic role labeling continue
to exist (Xue and Palmer, 2005).
1. Semantic role labeling only considers
predicate-argument relations and ignores
the semantic relations between a noun and its
modifier.
2. The meaning of semantic roles is related to spe-
cial predicates. Therefore, there are infinite se-
mantic roles to be learned, as the number of
predicates is not fixed. Although the Prop-
Bank (Xue and Palmer, 2003) normalizes these
semantic roles into certain symbols, such as
Arg0-Arg5, the same symbol can have different
semantic meanings when paired with different
predicates, and thus cannot be learned well.
Semantic dependency parsing is therefore pro-
posed to solve the two problems above for Chinese.
Firstly, the proposed method analyzes all the words?
semantic roles in a sentence and specifies the con-
crete semantic relation of each word pair. After-
ward, this work analyzes and summarizes all the
possible semantic roles, obtaining over 100 of them,
and then uses these semantic roles to specify the se-
mantic relation for each word pair.
Dependency parsing (Ku?bler et al, 2009) is based
on dependency grammar. It has several advantages,
such as concise formalization, easy comprehension,
high efficiency, and so on. Dependency parsing
has been studied intensively in recent decades, with
most related work focusing on syntactic structure.
Many research papers on Chinese linguistics demon-
strate the remarkable difference between semantics
and syntax (Jin, 2001; Zhou and Zhang, 2003).
Chinese is a meaning-combined language with very
flexible syntax, and semantics are more stable than
syntax. The word is the basic unit of semantics,
and the structure and meaning of a sentence consists
mainly of a series of semantic dependencies between
individual words (Li et al, 2003). Thus, a reason-
able endeavor is to exploit dependency parsing for
semantic analysis of Chinese languages. Figure 1
shows an example of Chinese semantic dependency
parsing.
378
??International ??Monetary ??Fund ??organization ??turn down ?for ??global ??economy ??increasing ?of ??prediction
d-genetived-restrictive d-restrictive agent prep-dependd-genetive d-domain aux-depend
d-restrictivecontent
root
Figure 1: An example of Chinese Semantic Dependency Parsing.
Figure 1 shows that Chinese semantic dependency
parsing looks very similar to traditional syntax-
dominated dependency parsing. Below is a compar-
ison between the two tasks, dealing with three main
points:
1. Semantic relations are more fine-grained than
syntactic ones: the syntactic subject can either
be the agent or experiencer, and the syntactic
object can be the content, patient, possession,
and so on. On the whole, the number of seman-
tic relations is at least twice that of syntactic
relations.
2. Semantic dependency parsing builds the depen-
dency structure of a sentence in terms of se-
mantics, and the word pairs of a dependency
should have a direct semantic relation. This
criterion determines many sizeable differences
between semantics and syntax, especially in
phrases formed by ?XP+DEG?, ?XP+DEV?
and prepositional phrases. For example, in ??
? ? ??? (beautiful country), the head of
???? (beautiful) is ???? (country) in se-
mantic dependency parsing, whereas the head
is ??? (de) in syntax dependency parsing.
3. Semantic relations are independent of position.
For example, in ??? ? ??? (the air is
contaminated) and ??? ? ??? (contami-
nate the air), the patient ???? (the air) can be
before or behind a predicate ???? (contami-
nate).
The rest of the paper is organized as follows. Sec-
tion 2 gives a short overview of data annotation.
Section 3 focuses on the task description. Section
4 describes the participant systems. Section 5 com-
pares and analyzes the results. Finally, Section 6
concludes the paper.
2 Data Annotation
2.1 Corpus Section
10,068 sentences were selected from the Penn Chi-
nese Treebank 6.01 (Xue et al, 2005) (1-121, 1001-
1078, 1100-1151) as the raw corpus from which to
create the Chinese Semantic Dependency Parsing
corpus. These sentences were chosen for the anno-
tation for three reasons. First, gold syntactic depen-
dency structures can be of great help in semantic de-
pendency annotation, as syntactic dependency arcs
are often consistent with semantic ones. Second, the
semantic role labels in PropBank2 can be very use-
ful in the present annotation work. Third, the gold
word segmentation and Part-Of-Speech can be used
as the annotation input in this work.
2.2 Semantic Relations
The semantic relations in the prepared Chinese se-
mantic dependency parsing corpus came mostly
from HowNet3 (Dong and Dong, 2006), a fa-
mous Chinese semantic thesaurus. We also referred
to other sources. Aside from the relations from
HowNet, we defined two kinds of new relations: re-
verse relations and indirect relations. When a verb
modifies a noun, the relation between them is a re-
verse relation, and r-XXX is used to indicate this
kind of relation. For instance, in ???????
?? (the little boy who is playing basketball), the se-
mantic relation between the head word ???? (boy)
1http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalog\\Id=LDC2007T36
2http://verbs.colorado.edu/chinese/cpb/
3http://www.keenage.com/
379
and ??? (playing) is the r-agent. When a verbal
noun is the head word, the relation between it and
the modifier is the indirect relation j-XXX. For in-
stance, in ?????? (business management), the
head word is ???? (management) and the modifier
is ???? (business), their relation is j-patient.
Finally, we defined 84 single-level semantic re-
lations. The number of multi-level semantic rela-
tions that actually appear in the labeled corpus in
this work is 39.
Table 1 summarizes all of the semantic relations
used for annotation.
2.3 Annotation Flow
Our corpus annotation flow can be divided into the
following steps.
1. Conversion of the sentences? constituent struc-
tures into dependency structures according to
a set of rules similar with those used by the
syntactic community to find the head of a
phrase (Collins, 1999).
2. Labeling of the semantic relations for each de-
pendency relation according to another set of
rules using the functional tags in the Penn Chi-
nese Treebank and the semantic roles in the
Chinese PropBank.
3. Six human annotators are asked to check and
adjust the structure and semantic relation errors
introduced in Step 2.
The first two steps were performed automatically
using rules. A high accuracy may be achieved with
dependency structures when semantic labels are not
considered. However, accuracy declines remarkably
when the semantic label is considered. Unlabeled
Attachment Score (UAS) and Labeled Attachment
Score (LAS) can be used to evaluate the perfor-
mance of the automatic conversion. Table 2 gives
the detailed results.
UAS LAS
Conversion Result 90.53 57.38
Table 2: Accuracy after conversion from gold ProbBank.
3 Task Description
3.1 Corpus Statistics
We annotated 10,068 sentences from the Penn Chi-
nese TreeBank for Semantic Dependency Parsing,
and these sentences were divided into training, de-
velopment, and test sections. Table 3 gives the de-
tailed statistical information of the three sections.
Data Set CTB files # sent. # words.
1-10; 36-65;81-121; 8301
Training 1001-1078; 250311
1100-1119;
1126-1140
Devel 66-80; 1120-1125 534 15329
Test 11-35; 1141-1151 1233 34311
Total 1-121; 1001-1078 10068 299951
1100-1151
Table 3: Statistics of training, development and test data.
3.2 Data Format
The data format is identical to that of a syntactic de-
pendency parsing shared task. All the sentences are
in one text file, with each sentence separated by a
blank line. Each sentence consists of one or more to-
kens, and each token is represented on one line con-
sisting of 10 fields. Buchholz and Marsi (2006) pro-
vide more detailed information on the format. Fields
are separated from each other by a tab. Only five of
the 10 fields are used: token id, form, pos tagger,
head, and deprel. Head denotes the semantic depen-
dency of each word, and deprel denotes the corre-
sponding semantic relations of the dependency. In
the data, the lemma column is filled with the form
and the cpostag column with the postag. Figure 2
shows an example.
3.3 Evaluation Method
LAS, which is a method widely used in syntactic
dependency parsing, is used to evaluate the perfor-
mance of the semantic dependency parsing system.
LAS is the proportion of ?scoring? tokens assigned
to both the correct head and correct semantic depen-
dency relation. Punctuation is disregarded during
the evaluation process. UAS is another important
indicator, as it reflects the accuracy of the semantic
dependency structure.
380
Main Semantic Roles
Subject Roles agent, experiencer, causer, possessor, existent, whole, relevant
Object Roles isa, content, possession, patient, OfPart, beneficiary, contrast,
partner, basis, cause, cost, scope, concerning
Auxiliary Semantic Roles
Time Roles duration, TimeFin, TimeIni, time, TimeAdv
Location and State Roles LocationFin, LocationIni, LocationThru, StateFin, state,
StateIni, direction, distance, location
Others Verb Modifiers accompaniment, succeeding, frequency, instrument, material,
means, angle, times, sequence, sequence-p, negation, degree,
modal, emphasis, manner, aspect, comment
Attribute Roles
Direct modifiers d-genetive, d-category, d-member, d-domain, d-quantity-p, d-
quantity, d-deno-p, d-deno, d-host, d-TimePhrase, d-LocPhrase,
d-InstPhrase, d-attribute, d-restrictive, d-material, d-content, d-
sequence, d-sequence-p, qp-mod
Verb Phrase r-{Main Semantic Roles}, eg: r-agent, r-patient, r-possessor
Verb Ellipsis c-{Main Semantic Roles}, eg: c-agent, c-content, c-patient
Noun as Predication j-{Main Semantic Roles}, eg: j-agent, j-patient, j-target
Syntactic Roles and Others
Syntactic Roles s-cause, s-concession, s-condition, s-coordinate, s-or, s-
progression, s-besides, s-succession, s-purpose, s-measure, s-
abandonment, s-preference, s-summary, s-recount, s-concerning,
s-result
Others aux-depend, prep-depend, PU, ROOT
Table 1: Semantic Relations defined for Chinese Semantic Dependency Parsing.
ID FORM LEMMA CPOS PPOS FEAT HEAD REL PHEAD PREL
1 ??? ??? NR NR 2 agent
2 ? ? VV VV 0 ROOT
3 ?? ?? NR NR 4 d-genetive
4 ?? ?? NN NN 7 s-coordinate
5 ? ? CC CC 7 aux-depend
6 ?? ?? NR NR 7 d-genetive
7 ?? ?? NN NN 2 content
Figure 2: Data format of the Chinese Semantic Dependency Parsing corpus.
381
4 Participating Systems
Nine organizations were registered to participate in
the Chinese Semantic Dependency Parsing task. Fi-
nally, nine systems were received from five different
participating teams. These systems are as follows:
1. Zhou Qiaoli-1, Zhou Qiaoli-2, Zhou Qiaoli-3
These three systems propose a divide-and-
conquer strategy for semantic dependency
parsing. The Semantic Role (SR) phrases are
identified (Cai et al, 2011) and then replaced
by their head or the SR of the head. The orig-
inal sentence is thus divided into two types of
parts that can be parsed separately. The first
type is SR phrase parsing, and the second in-
volves the replacement of SR phrases with ei-
ther their head or the SR of the head. Finally,
the paper takes a graph-based parser (Li et al,
2011) as the semantic dependency parser for all
parts. These three systems differ in their phrase
identification strategies.
2. NJU-Parser-1, NJU-Parser-2
The NJU-Parser is based on the state-of-the-
art MSTParser (McDonald, 2006). NJU-Parser
applies three methods to enhance semantic de-
pendency parsing. First, sentences are split
into sub-sentences using commas and semi-
colons: (a) sentences are split using only com-
mas and semicolons, as in the primary sys-
tem, and (b) classifiers are used to determine
whether a comma or semicolon should be used
to split the sentence. Second, the last character
in a Chinese word is extracted as the lemma,
since it usually contains the main sense or se-
mantic class. Third, the multilevel-label is in-
troduced into the semantic relation, for exam-
ple, the r-{Main Semantic Roles}, with NJU-
Parser exploiting special strategies to handle it.
However, this third method does not show pos-
itive performance.
3. Zhijun Wu-1
This system extends the second-order of the
MSTParser by adding third-order features, and
then applying this model to Chinese semantic
dependency parsing. In contrast to Koo and
Collins (2010) this system does not implement
the third-order model using dynamic program-
ming, as it requires O(n4) time. It first first ob-
tained the K-best results of second-order mod-
els and then added the third-order features into
the results.
4. ICT-1
The ICT semantic dependency parser employs
a system-combining strategy to obtain the de-
pendency structure and then uses the classifier
from Le Zhang?s Maximum Entropy Model-
ing Toolkit4 to predict the semantic relation for
each dependency. The system-combining strat-
egy involves three steps:
? Parsing each sentence using Nivre?s arc
standard, Nivre?s arc eager (Nivre and
Nilsson, 2005; Nivre, 2008), and Liang?s
dynamic algorithm (Huang and Sagae,
2010);
? Combining parses given by the three
parsers into a weighted directed graph;
? Using the Chu-Liu-Edmonds algorithm to
search for the final parse for each sen-
tence.
5. Giuseppe Attardi-SVM-1-R, Giuseppe Attardi-
SVM-1-rev
We didn?t receive the system description of
these two systems.
5 Results & Analysis
LAS is the main evaluation metric in Chinese Se-
mantic Dependency Parsing, whereas UAS is the
secondary metric. Table 4 shows the results for these
two indicators in all participating systems.
As shown in Table 4, the Zhou Qiaoli-3 system
achieved the best results with LAS of 61.84. The
LAS values of top systems are very closely. We per-
formed significance tests5 for top six results. Table
5 shows the results , from which we can see that
the performances of top five results are comparative
(p > 0.1) and the rank sixth system is significantly
(p < 10?5) worse than top five results.
4http://homepages.inf.ed.ac.uk/s0450736/
maxenttoolkit.html
5http://www.cis.upenn.edu/?dbikel/
download/compare.pl
382
NJU-Parser-2 NJU-Parser-1 Zhijun Wu-1 Zhou Qiaoli-1 Zhou Qiaoli-2
Zhou Qiaoli-3 ? ? ? ? >
NJU-Parser-2 ? ? ? ? >
NJU-Parser-1 ? ? ? ? >
Zhijun Wu-1 ? ? ? ? >
Zhou Qiaoli-1 ? ? ? ? >
Table 5: Significance tests of the top five systems. ? denotes that the two systems are comparable (p > 0.1), and >
means the system of this row is significantly (p < 10?5) better than the system of this column.
System LAS UAS
Zhou Qiaoli-3 61.84 80.60
NJU-Parser-2 61.64 80.29
NJU-Parser-1 61.63 80.35
Zhijun Wu-1 61.58 80.64
Zhou Qiaoli-1 61.15 80.41
Zhou Qiaoli-2 57.55 78.55
ICT-1 56.31 73.20
Giuseppe Attardi-SVM-1-R 44.46 60.83
Giuseppe Attardi-SVM-1-rev 21.86 40.47
Average 54.22 72.82
Table 4: Results of the submitted systems.
The average LAS for all systems was 54.22.
Chinese Semantic Dependency Parsing performed
much more poorly than Chinese Syntactic Depen-
dency Parsing due to the increased complexity
brought about by the greater number of semantic re-
lations compared with syntactic relations, as well as
greater difficulty in classifying semantic relations.
In general, all the systems employed the tradi-
tional syntax-dominated dependency parsing frame-
works. Some new methods were proposed for
this task. Zhou Qiaoli?s systems first identified
the semantic role phrase in a sentence, and then
employed graph-based dependency parsing to ana-
lyze the semantic structure of the sentence. NJU-
Parser first split the sentence into sub-sentences,
then trained and parsed the sentence based on these
sub-sentences; this was shown to perform well. In
addition, ensemble models were also proposed to
solve the task using ICT systems.
6 Conclusion
We described the Chinese Semantic Dependency
Parsing task for SemEval-2012, which is designed to
parse the semantic structures of Chinese sentences.
Nine results were submitted by five organizations,
with the best result garnering an LAS score of 61.84,
which is far below the performance of Chinese Syn-
tax. This demonstrates that further research on the
structure of Chinese Semantics is needed.
In the future, we will check and improve the anno-
tation standards while building a large, high-quality
corpus for further Chinese semantic research.
Acknowledgments
We thank the anonymous reviewers for their help-
ful comments. This work was supported by Na-
tional Natural Science Foundation of China (NSFC)
via grant 61133012 and 61170144, and the Na-
tional ?863? Leading Technology Research Project
via grant 2012AA011102.
References
Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared
task on multilingual dependency parsing. In Proceed-
ings of the Tenth Conference on Computational Nat-
ural Language Learning (CoNLL-X), pages 149?164,
New York City, June. Association for Computational
Linguistics.
Dongfeng Cai, Ling Zhang, Qiaoli Zhou, and Yue Zhao.
2011. A collocation based approach for prepositional
phrase identification. IEEE NLPKE.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Pennsyl-
vania University.
Zhendong Dong and Qiang Dong. 2006. Hownet And the
Computation of Meaning. World Scientific Publishing
Co., Inc., River Edge, NJ, USA.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In Pro-
ceedings of the 48th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 1077?1086,
383
Uppsala, Sweden, July. Association for Computational
Linguistics.
Guangjin Jin. 2001. Theory of modern Chinese verb se-
mantic computation. Beijing University Press.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the 48th
Annual Meeting of the ACL, number July, pages 1?11.
Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. In Synthesis Lectures on
Human Language Technologies.
Mingqin Li, Juanzi Li, Zhendong Dong, Zuoying Wang,
and Dajin Lu. 2003. Building a large chinese corpus
annotated with semantic dependency. In Proceedings
of the second SIGHAN workshop on Chinese language
processing - Volume 17, SIGHAN ?03, pages 84?91,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
chinese pos tagging and dependency parsing. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1180?
1191, Edinburgh, Scotland, UK., July. Association for
Computational Linguistics.
Ryan McDonald. 2006. Discriminative learning and
spanning tree algorithms for dependency parsing.
Ph.D. thesis, University of Pennsylvania.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective
dependency parsing. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL).
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34(4):513?553.
Nianwen Xue and Martha Palmer. 2003. Annotating
the propositions in the penn chinese treebank. In Pro-
ceedings of the Second SIGHAN Workshop on Chinese
Language Processing.
Nianwen Xue and Martha Palmer. 2005. Automatic se-
mantic role labeling for chinese verbs. In Proceedings
of the 19th International Joint Conference on Artificial
Intelligence.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Guoguang Zhou and Linlin Zhang. 2003. The theory
and method of modern Chinese grammar. Guangdong
Higher Education Press.
384
