Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 433?440
Manchester, August 2008
Generation of Referring Expressions: Managing Structural
Ambiguities
?
Imtiaz Hussain Khan and Kees van Deemter and Graeme Ritchie
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, U.K.
{i.h.khan,k.vdeemter,g.ritchie}@abdn.ac.uk
Abstract
Existing algorithms for the Generation
of Referring Expressions tend to gen-
erate distinguishing descriptions at the
semantic level, disregarding the ways
in which surface issues can affect their
quality. This paper considers how these
algorithms should deal with surface am-
biguity, focussing on structural ambi-
guity. We propose that not all ambigu-
ity is worth avoiding, and suggest some
ways forward that attempt to avoid un-
wanted interpretations. We sketch the
design of an algorithm motivated by our
experimental findings.
1 Introduction
A Noun Phrase (np) is a referring expression
if its communicative purpose is to identify an
object to a hearer. The Generation of Refer-
ring Expressions (gre) is an integral part of
most Natural Language Generation (nlg) sys-
tems (Reiter and Dale, 2000). The gre task
can informally be stated as follows. Given an
intended referent (i.e., the object to be identi-
fied) and a set of distractors (i.e., other objects
that can be confused with the referent), find a
description that allows a hearer to identify its
referent uniquely (Dale, 1992). Such a descrip-
tion is called a Distinguishing Description
(dd). In practice, however, most gre algo-
rithms build sets of semantic properties avail-
able in a Knowledge Base (kb), rather than
descriptions in natural language; surface issues
are often ignored (exceptions are: (Stone and
?
This work is supported by a University of Ab-
erdeen Sixth Century Studentship, and EPSRC grant
EP/E011764/1.
?
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported.
Some rights reserved.
Webber, 1998; Krahmer and Theune, 2002;
Siddharthan and Copestake, 2004)). This is
an important limitation, for example because
ambiguities can be introduced in the step from
properties to language descriptions. Such ?sur-
face ambiguities? take centerstage in this pa-
per. More specifically, we shall be investigating
situations where they lead to referential ambi-
guity, that is, unclarity as to what the intended
referent of a referring expression is.
Example 1: Consider a scenario in which
there are sheep and goats along with other an-
imals, grazing in a meadow; some of the sheep
and goats are black while others are either
brown or yellow. Suppose our task is to single
out the black sheep and black goats from the
rest of the animals. Suppose an algorithm has
generated the logical form
1
(Black ? Sheep) ?
(Black ? Goats), which could be realised as
either the black sheep and the black goats or,
more briefly, as the black sheep and goats. The
latter np expresses two non-equivalent logical
formulae: (i) (Black ? Sheep) ? Goats, and
(ii) (Black ? Sheep) ? (Black ? Goats). Since
both formulae correspond with a set of animals
in the domain, referential ambiguity can result.
On the other hand, the black sheep and goats
is shorter and possibly more fluent. This ex-
ample highlights the possible tension between
brevity and lack of ambiguity. The question
facing us in this paper is how to balance them.
This paper examines how gre should deal
with structural ambiguity, focussing on ambi-
guity of the form the Adj Noun1 and Noun2,
also known as coordination ambiguity. We
call referring expressions of this form scopally
ambiguous, as the scope of Adj is unclear be-
tween wide scope (Adj applies to both nouns)
and narrow scope (Adj applies only to Noun1).
1
In this paper, we use set-theoretic operators instead
of logical connectives to represent logical forms.
433
2 Approach
A cursory view of corpora such as the British
National Corpus (bnc) reveals that there are
many instances of coordination ambiguity:
1. the black cats and dogs
2. the bearded men and women
3. the old men and women in the hats
Psycholinguistic evidence suggests that, in
many cases, these ambiguities could cause con-
fusion for a hearer (Tanenhaus and Trueswell,
1995). Hence, it seems justifiable to have gre
avoid such kind of ambiguities. However, it
also seems plausible that some readings may
be very unlikely. For example, in (2) a wide-
scope reading is, arguably, very unlikely. Ab-
ney and others have argued that every sentence
is potentially ambiguous between many parses,
even though we may not even notice this ambi-
guity (Abney, 1996; Wasow et al, 2005). This
suggests that, in gre as well, it might not be
feasible to avoid all referential ambiguities all
the time, and that the choice of referring ex-
pression should sometimes involve a balancing
act in which degree of ambiguity is balanced
against other properties of the generated ex-
pression, such as its length or fluency.
Building on earlier work by Inui et al (Inui
et al, 1992), Neumann (Neumann, 1994) sug-
gested a general generate-parse-revise model
for nlg, based on a reversible grammar. His
generator generates a string which is then
parsed to detect any structural ambiguities. If
a string is found to be ambiguous then revi-
sion is used to produce an alternative, non-
ambiguous string instead (if such a string ex-
ists). The likelihood of the different interpre-
tations is not taken into account, however.
Our approach to the problem is to find out
the likelihood of each interpretation of an np,
and to tailor gre to avoid all distractor in-
terpretations (i.e., interpretations that can
be confused with the intended one) as sug-
gested in (van Deemter, 2004). An interpre-
tation can be confused with the intended one
if it is more likely or almost as likely as the in-
tended one. The problem is, how to determine
the likelihood of different interpretations.
3 Getting likelihood from the bnc
In scopally ambiguous referring expressions,
there is a tension between wide- and narrow-
scope interpretations. This can be viewed in
terms of two competing forces: a Coordination
Force, whereby Noun1 and Noun2 attract each
other to form a syntactic unit, and a Modifi-
cation Force, whereby Adj and Noun1 attract
each other to form a syntactic unit. Computa-
tional linguists have proposed using language
corpora to estimate the likelihood of an inter-
pretation (Wu and Furugori, 1998; Chantree
et al, 2006). Chantree et al used information
from the Sketch Engine database (Kilgarriff,
2003) operating on the bnc to resolve coor-
dination ambiguity. The Sketch Engine con-
tains grammatical triples in the form of Word
Sketches for each word, with each triple ac-
companied by a salience value indicating the
likelihood of occurrence of the word with its
argument in a grammatical relation. Word
Sketches summarise the words? grammatical
and collocational behavior.
Chantree et al gathered a dataset of am-
biguous phrases from a corpus of requirements
specifications, and collected human judge-
ments about their interpretations. They then
used machine learning techniques combined
with various heuristics to determine the most
likely interpretation of a coordination. They
identified two heuristics as particularly useful.
One was the Coordination-Matches Heuristic:
if a coordination between two head nouns oc-
curs (at all) within the corpus, then a wide-
scope reading is likely. The other was the
Collocation-Frequency Heuristic: if a modi-
fier is collocated more frequently with the near-
est head word than with the head word further
away, then a narrow-scope reading is likely.
The best performance was achieved by combin-
ing the two heuristics: wide-scope reading is
likely if Coordination-Matches heuristic gives
a positive result and Collocation-Frequency
heuristic gives a negative result. We decided
to modify Chantree et al?s approach in two
ways and apply the modified approach to nlg.
Firstly, it seemed unlikely to us in the gen-
eral case that the deciding factor is always
whether two words co-occur at all. We there-
fore decided to separate cooccurence percent-
ages into ones that are very high and ones
that are very low. Secondly, we observed that
Chantree et al take Coordination Force into
account when they predict wide scope, but not
434
when they predict narrow scope. It would
be more systematic ? and more useful to an
nlg system, which has to cope with all possi-
ble inputs ? to consider all four combinations,
of strong and weak, coordination and modifi-
cation force. We define that there will be a
Strong Coordination Force (SCF) if the collo-
cational frequency between the two nouns is
high, and a Weak Coordination Force (WCF)
otherwise. Similarly, we define that there
will be a Strong Modification Force (SMF) if
the collocational frequency of Adj is high with
Noun1 and low with Noun2, and a Weak Mod-
ification Force (WMF) otherwise.
After a preliminary investigation of the data,
we decided to operationalise high collocational
frequency between two words as meaning that
either of the two words appears among the top
30% collocates of the other word in a gram-
matical relation (of interest); low collocational
frequency means that neither of the two words
appears among the top 70% collocates of the
other word in a grammatical relation. The hy-
potheses resulting from the above changes are
investigated in the following section.
4 Empirical Studies
We conducted three experiments. The first
two experiments ask what interpretation of
a scopally ambiguous np is the most plau-
sible, thereby testing our generalisation of
Chantree?s hypotheses. Knowing how an np
is interpreted is useful for an nlg system but
not sufficient, because ambiguity needs to be
traded off against other factors. For this rea-
son, our third experiment asks which of several
nps are preferred by a reader.
4.1 Interpreting nps
We use all four possible combinations of coor-
dination and modification forces to predict an
interpretation of a scopally ambiguous refer-
ring expression (see Table-1). An SMF would
make a wide-scope reading highly unlikely (cf.
(Wu and Furugori, 1998)). For instance, in the
bearded men and women there is an SCF and
an SMF, but in fact this phrase would be in-
terpreted as a narrow-scope reading because of
the scarcity of bearded women. On the other
hand, a WMF could be in favor of a wide-scope
reading. We expect that human readers would
opt for wide- and narrow-scope readings ac-
cording to Table 1.
Table 1: Predicting an interpretation
Hypothesis 1: SCF ? SMF ? NS
Hypothesis 2: SCF ? WMF ? WS
Hypothesis 3: WCF ? SMF ? NS
Hypothesis 4: WCF ? WMF ? WS
WS: Wide scope; NS: Narrow scope
To test these hypotheses, we conducted two
interpretation experiments, and rather than
asking expert linguists to annotate the strings,
we examined how ordinary readers interpret
structurally ambiguous strings. In these ex-
periments, given a referential domain and an
English np which attempts to identify a sub-
set of objects in the domain, participants were
asked to find the referent set of the np.
4.1.1 Experiment 1
In this experiment, referential domains were
constructed using real photographs of animals
with some of the features printed alongside
each photograph. Features were printed be-
cause 1) in a pilot study, we observed that
some participants had difficulty in discerning
some features in some of the photographs, and
2) we attribute some unusual features to some
objects, e.g., we attributed cats with the fea-
ture barking although cats don?t bark in re-
ality. Two pairs of nouns were used: one with
SCF, and the other with WCF. For each pair
of nouns, four different adjectives were used:
two with SMF, and two with WMF. A trial
in this experiment consists of a set of 9 pic-
tures (placed in a 3 x 3 grid), and an English
np underneath these pictures. A sample trial
is shown in Figure 1. Participants? task was
to remove the pictures (by mouse clicks on the
pictures) that were referred to by the np. A
removed picture was immediately replaced by
a blank rectangle (of the same size).
In each trial, we made sure that both wide-
and narrow-scope readings are applicable. For
example, for the instruction Please, remove the
red lions and horses, in the domain there were
2 red lions, 2 red horses, and some (at least
one) non-red horses. If a participant removes
2 red lions and 2 red horses, we count it as a
wide-scope reading. However, if (s)he removes
all the horses we count it as a narrow-scope
reading. We also used 8 fillers, which do not
435
Figure 1: Interpreting an np (using pictures)
contain a coordination in the np (e.g., the dogs
on the left). 60 self-reported native or fluent
speakers of English, students from various UK
universities, did the experiment on the web.
2
Results and Discussion: Results were anal-
ysed according to whether a participant opted
for a wide- or narrow-scope reading. The par-
ticipants? responses are shown in Table 2. A
two-tailed sign binomial test was used to cal-
culate statistical significance. The data indi-
cate that word distribution information can re-
liably predict a wide-scope reading. However,
our predictions for a narrow-scope reading are
not confirmed. This may have been because
of an intrinsic bias in favour of wide-scope in-
terpretations. Another potential problem with
the experiment is that some of the nps shown
to participants were rather unusual, involving
bearded women, etc. Although the printed fea-
tures underneath the pictures forced partici-
pants to take these unusual cases seriously, the
clash between the picture (of a woman) and the
printed feature (?bearded?) that arose in such
cases may have made participants? responses
unreliable. To avoid this problem we now turn
to an experimental setup where we use Euler
diagrams instead of iconic pictures.
4.1.2 Experiment 2
This experiment mirrors experiment 1, but
we used Euler diagrams instead of pictures
2
Here and in the other experiments reported in this
paper, we ascertained that no important differences ex-
isted between the two groups of subjects. Focussing on
Experiment 1, for example, no significant difference in
the percentages of wide scope interpretations was found
between native speakers and subjects who were merely
fluent in English.
Table 2: Response proportions: Experiment 1
Force PR PJ p-value
SCF SMF NS NS (25/60) 0.52
SCF WMF WS WS (57/60) < 0.001
WCF SMF NS NS (26/60) 0.12
WCF WMF WS WS (53/60) < 0.001
PR: Predicted Reading; PJ: Participants? Judgement
to represent domain entities. Participants re-
ceived a mini-tutorial on our version of Eu-
ler diagrams, where shaded areas denote the
sets to which an NP might refer. The pur-
pose of this tutorial was to make sure that
the participants understand the semantics of
these diagrams. A sample trial is shown in
Figure 2 (where we expect that participants
would remove the diagram on the right, which
is counted as a wide-scope response). 60 self-
reported native or fluent speakers of English,
students from various UK universities, took
part in this web-based experiment.
Figure 2: Interpreting an np (Euler diagrams)
Results and Discussion: Results were
recorded according to whether a participant
opted for a wide- or narrow-scope reading. The
participants? responses are shown in Table 3.
A two-tailed sign binomial test was used to
calculate statistical significance of the results.
This time, all four hypotheses are confirmed.
We also observed, however, that in scopally
ambiguous expressions, a narrow-scope read-
ing tends to be particularly frequent in the ex-
treme case where Adj has a zero co-occurrence
with Noun2 (in the bnc). We note that these
results are in line with Chantree et al
A critic might argue that the problem that
was noted in connection with Experiment 1
applies to Experiment 2 as well, because it
shows diagrams involving a ?problematic? in-
436
Table 3: Response proportions: Experiment 2
Force PR PJ p-value
SCF SMF NS NS (51/60) < 0.001
SCF WMF WS WS (55/60) < 0.001
WCF SMF NS NS (46/60) < 0.001
WCF WMF WS WS (54/60) < 0.001
tersection between, for example, bearded and
women. The fact that women (arguably) can-
not be bearded could cause subjects to re-
ject these diagrams (choosing the other dia-
gram instead, as in the diagram included in
Fig. 3, which does not involve such an inter-
section). We would argue, however, that this
does not cause an unwanted bias. The scarcity
of bearded women is a legitimate reason for
subjects to believe that a diagram that asserts
their existence cannot be a proper interpreta-
tion of ?bearded men and women?; it is just
one of the many things that the corpus-based
approach captures indirectly, without repre-
senting it explicitly. It is equally applicable to
expressions like ?handsome men and women?,
where the corpus tells us that ?handsome? and
?women? do not go together well (even though
one probably would not say they do not exist).
We have seen that Word Sketches can make
reasonable predictions concerning the likeli-
hood of the different interpretations of the nps.
But an np that is clear (i.e., not likely to be
misunderstood) may have other disadvantages.
For example, it may lack fluency or it may be
perceived as unnecessarily lengthy. For this
reason, we also conducted an additional exper-
iment in which we tested readers? preferences.
4.2 Choosing the best np
The question of how to choose between differ-
ent nps could be approached in a number of
different ways: asking hearers which of sev-
eral descriptions they prefer, asking hearers
to rate several descriptions, measuring inter-
pretation effort (time), measuring hearers? er-
rors etc.. We conducted a readers? preference
experiment where participants were asked to
compare pairs of natural language descriptions
of one and the same target set, selecting the
one they found more appropriate. Brief de-
scriptions took the form the Adj Noun1 and
Noun2. Non-brief descriptions took the forms
the Adj Noun1 and the Noun2 (for NS) and the
Adj Noun1 and the Adj Noun2 (for WS). A de-
scription is said to be clear if its predicted read-
ing is the same as the intended one. By def-
inition a non-brief description is always clear.
Each description could either be brief or not
(?b) and also clear or not (?c) (but not (?b,
?c), as this combination is not applicable in
the present setting). We expected to find that:
Hypothesis 5: (+c,+b) descriptions are pre-
ferred over ones that are (+c,?b).
Hypothesis 6: (+c,?b) descriptions are pre-
ferred over ones that are (?c,+b).
4.2.1 Experiment 3
In this experiment, referential domains were
represented using Euler diagrams. In each
trial, participants were shown an Euler dia-
gram, with some of its area filled to indicate
the target referent. They were also shown two
English nps, which attempted to identify the
filled area. A sample trial, where the intended
reading is narrow scope, is shown in Figure
3. Each hypothesis was tested under two con-
Figure 3: Sample Trial: Choosing the best np
ditions: 1) where the intended reading (IR)
was WS; and 2) where the IR was NS. The 4
comparisons thus corresponded to 4 conditions
(where PR stands for predicted reading):
C1. IR = WS & PR = WS
(+c,+b) vs. (+c,?b)
C2. IR = NS & PR = NS
(+c,+b) vs. (+c,?b)
C3. IR = WS & PR = NS
(?c,+b) vs. (+c,?b)
C4. IR = NS & PR = WS
(?c,+b) vs. (+c,?b)
46 self-reported native or fluent speakers of En-
437
glish, students from various UK universities,
did the experiment on the web.
Results and Discussion: Results were
coded according to whether a participant?s
choice was ?b and/or ?c. Table 4 displays
response proportions. A two-tailed sign bino-
mial test was used to calculate statistical sig-
nificance of the results. The results confirm
our hypotheses in all conditions, being highly
statistically significant (p < 0.001).
Table 4: Response proportions: Experiment 3
C1 C2 C3 C4
+b 91.3% 67.9% 26.1 14.5
+c - - 73.9% 88.5%
4.3 Summary of the Empirical Data
As hypothesised, Kilgarriff?s Word Sketches
can be used to predict the most likely read-
ing of a scopally ambiguous expression. It is
also important to note that it is the Modifi-
cation Force which is the deciding factor for
a particular reading. Moreover, other things
being equal, brief descriptions are preferred
over longer ones. Since Experiment 2 (and,
to an extent, Experiment 1) confirmed our hy-
potheses, we could have based our algorithm
on these. As was noted in section 4.1.2, how-
ever, our data also suggest a slight modifica-
tion of Hypotheses 1 and 3, because a pref-
erence for narrow scope existed mainly when
the Adjective and the second Noun co-occurred
very rarely. Therefore, we shall use a modified
version of Strong Modification Force (SMF):
SMF
?
will mean that Adj and Noun2 have zero
(rather than below 30%) cooccurrence in the
bnc.
5 Applying results to gre
In this section, we show how the results of
the previous sections can be exploited in gre.
The patterns explored in the above correspond
to disjunctive plural references. Disjunction is
required whenever there is no conjunction of
atomic properties that sets the elements of a
set of referents apart from all the other ob-
jects in the domain. Recall example 1 (from
?1), where the aim is to single out the black
sheep and black goats from the rest of the an-
imals. This task cannot be performed by a
simple conjunction (i.e., of the form ?the X?,
where X contains adjectives and nouns only),
so disjunctions become unavoidable.
Various proposals have been made for al-
lowing gre algorithms to produce referring
expressions of this kind (Stone, 2000; van
Deemter, 2002; Gardent, 2002; Horacek,
2004). Here we take as our starting point the
approach of (Gatt, 2007) (henceforth Gatt?s
Algorithm with Partitioning or gap). gap is
the only algorithm that produces a dd in Dis-
junctive Normal Form (dnf) while also guar-
anteeing that every ?part? of the partition
contains a noun. The dnf takes the form:
S
1
? S
2
... ? S
n
, where each S
i
itself expresses
a conjunction of atomic properties. (For ex-
ample, S
1
might be Sheep ? Black, while S
2
is Goat ? Black.) We sketch two extensions of
this approach: the first, purely formal exten-
sion ensures that a set of such logical formulae
is generated, rather than just one formula; all
of these formulae are unambiguous, and logi-
cally equivalent with each other; but they all
map to different strings of words. This is be-
cause we assume a very direct Linguistic Real-
isation strategy in which, for example, ((Black
? Sheep) ? Goats) is worded as the black sheep
and goats; syntactic ambiguity results from the
lack of brackets in the English np. The sec-
ond, empirically based extension is to choose
the ?best? element of the set (of formulae) by
making use of our experimental outcomes so as
to balance clarity and brevity.
Since our predictions are based on words,
we propose a model that constructs descrip-
tions from words and in which the description
building process is driven by words. We com-
pute the extension (where the extension of a
word w consists of all objects to which w ap-
plies) of a potentially ambiguous word by uni-
fying the extensions of all its interpretations.
Let p
1
, p
2
, ..., p
n
be the properties that a word
w can express. Then the extension of w is:
[[ w ]] =
i=n
?
i=1
[[ p
i
]] (1)
In what follows, a domain consists of a set D
of objects, and a set P of properties applicable
to objects in D. Given a set of target referents
R ? D, the proposed algorithm will:
? lexicalise each p ? P into words; Lexi-
calisation takes a property as input and
438
returns the set of possible realisations of
that property. For example, a property,
say, aged will be realised as (a set of)
words {old, aged, senior}.
? build a dd in dnf using words, where the
extension of a word is computed as indi-
cated in equation 1. Each S
i
must contain
a head noun. For example, in the sce-
nario presented in Example 1 under ?1, it
would produce a dd like: (black ? sheep)
? (black ? goats).
? apply transformation rules on the dd to
construct a set of dds that are logically
equivalent to the dd. (See below.)
? realise each description in the set as En-
glish nps using appropriate syntax. Each
description is realised as one and only one
np, using the above realisation strategy.
? determine the most likely reading of each
np, by making use of Word Sketches.
? select the np that is optimal given our em-
pirical findings. (See below.)
Transformation Rules: In connection with
reference to sets, it has been proposed to use
the Q-M algorithm (McCluskey, ) to find the
shortest formula equivalent to a given input
formula (van Deemter, 2002). In the present
setting, the shortest formula might lead to a
confusing np after linguistic realisation. For
example, the formula Black ? (Cats ? Dogs)
might be realised as the black cats and dogs,
which could easily be misunderstood as (Black
? Cats) ? Dogs. For this purpose, we propose
to use a set of transformation rules that allow
us to find a set of formulae logically equivalent
to the original formula; the aim is to make the
set large enough that all the relevant expres-
sive choices (as investigated in this paper) are
represented. In particular, we need the follow-
ing rules that operate on dnfs (where A is an
adjective; B
1
and B
2
are nouns; X and Y are
combinations of adjectives and nouns).
1. ((A ?B
1
) ? (A ?B
2
)) ? (A ? (B
1
?B
2
))
2. (X ? Y ) ? (Y ?X)
After application of these transformation
rules, the original description ? (i.e., the for-
mula produced by an algorithm such as gap)
is replaced by a set of formulae F all of whose
elements are logically equivalent to ?. The el-
ements of F are then realised as nps. The clar-
ity of each np is determined as follows (where
PR and IR stand for predicted reading and in-
tended reading, respectively).
If SMF? then PR is NS
Else If WMF then PR is WS
Else PR is {NS, WS}
EndIf
If (PR = IR) then NP is clear
Else NP is unclear
EndIf
If, after transformations, several of the re-
sulting descriptions are clear then the choice
between them needs to be taken on other
grounds. To do this, we give preference to the
shortest of all descriptions that are clear (mea-
sured in terms of number of words in the np).
If ties still arise then we suggest that fluency
is taken into account, for example by prefer-
ring np whose structure is most frequent in
the bnc. This procedure will often result in
nps that are ?clear? even though they are syn-
tactically ambiguous.
Example 2: Let the domain be repre-
sented as: {man(e
1
, e
2
, e
6
), woman(e
3
, e
4
, e
5
),
young(e
5
, e
6
), old(e
1
, e
2
, e
3
, e
4
)}. Our task
is to single out {e
1
, e
2
, e
3
, e
4
} from rest of
the entities. First, properties are lexicalised
into words. Suppose the relevant words are
the ones in the list Q = ?man, woman, old,
young?. Then, the algorithm takes each word
w ? Q in turn and constructs a dd: (old ?
man) ? (old ? woman). The transformation
rules then produce {old?(man?woman), old?
(woman?man), (old?man)? (old?woman),
(old?woman)? (old?man)}. These formulae
are realised as: (1) the old men and women, (2)
the old women and men, (3) the old men and
the old women and (4) the old women and the
old men. The nps (1) and (2) are structurally
ambiguous, but the Word Sketches rule out the
unintended reading of both nps (with narrow
scope for the adjective), so they are both clear.
The nps (3) and (4) are structurally unam-
biguous. All nps are therefore clear, but (1)
and (2) are preferred because they are shorter
than (3) and (4). Corpus frequency suggests
that the tie between (1) and (2) is resolved by
opting for the more frequent pattern (1).
6 Conclusions and future work
We highlighted that structural ambiguity,
which is often ignored in the gre could cause
439
confusion for a hearer and, therefore, should be
dealt with. Based on psycholinguistic evidence
that avoidance of all ambiguity is hard, we sug-
gested an approach that avoids referring ex-
pressions that have distractor interpretations.
We did: (1) interpretation experiments and
found that Word Sketches can be used to make
distractor interpretation precise; and (2) an
experiment with human readers that trades-
off clarity and brevity. A gre algorithm is
sketched that balances these factors based on
our experimental findings.
We aim to extend this work in two direc-
tions. First, we hypothesise that our ap-
proach can help nlg systems handle other sur-
face ambiguities, for instance involving PP-
attachment. Second, we realise that contex-
tual factors are likely to affect people?s inter-
pretive and generative inclinations. Therefore,
in light of the work reported in this paper, it
would be interesting to explore the effect of
co-occurrences in a given text upon the inter-
pretation of nps occurring later in that same
text, since the effect of such earlier occurrences
on readers? interpretation could conceivably
?drown out? the generic likelihoods based on
Word Sketches that have formed the main sub-
ject matter of this paper.
References
Abney, S. 1996. Statistical methods and linguis-
tics. In Klavans, Judith and Philip Resnik, ed-
itors, The Balancing Act: Combining Symbolic
and Statistical Approaches to Language, pages 1?
26. The MIT Press, Cambridge, Massachusetts.
Chantree, F., B. Nuseibeh, A. de Roeck, and
A. Willis. 2006. Identifying nocuous ambigui-
ties in requirements specifications. In Proceed-
ings of 14th IEEE International Requirements
Engineering conference, Minnesota, U.S.A.
Dale, R. 1992. Generating Referring Expressions:
Building Descriptions in a Domain of Objects
and Processes. MIT Press.
Gardent, C. 2002. Generating minimal definite
descriptions. In Proceedings of the 40th Annual
Meeting of the ACL, Philadelphia, USA.
Gatt, A. 2007. Generating Coherent References
to Multiple Entities. Ph.D. thesis, University of
Aberdeen, Aberdeen, Scotland.
Horacek, H. 2004. On referring to sets of objects
naturally. In Proceedings of the 3rd International
Conference on NLG, pages 70?79, UK.
Inui, K., T. Tokunaga, and H. Tanaka. 1992. Text
revision: A model and its implementation. In
Proceedings of the 6th International Workshop
on NLG, pages 215?230, Berlin, Heidelberg.
Kilgarriff, A. 2003. Thesauruses for natural lan-
guage processing. In Proceedings of NLP-KE,
pages 5?13, Beijing, China.
Krahmer, E. and M. Theune. 2002. Efficient
context-sensitive generation of referring expres-
sions. In van Deemter, K. and R. Kibble, editors,
Information Sharing: Reference and Presupposi-
tion in Language Generation and Interpretation,
CSLI Publications, pages 223?264.
McCluskey, E. J. Introduction to the Theory of
Switching Circuits. McGraw-Hill Book Co.
Neumann, G. 1994. A Uniform Computational
Model for Natural Language Parsing and Gener-
ation. Ph.D. thesis, University of the Saarland.
Reiter, E. and R. Dale. 2000. Building Natural
Language Generation Systems. Cambridge Uni-
versity Press.
Siddharthan, A. and A. Copestake. 2004. Gener-
ating referring expressions in open domains. In
Proceedings of the 42nd Annual Meeting of the
ACL, Barcelona, Spain.
Stone, M. and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics.
In Proceedings of the 9th International Workshop
on NLG, pages 178?187, New Brunswick, New
Jersey.
Stone, M. 2000. On identifying sets. In Proceed-
ings of the 1st INLG Conference, pages 116?123,
Mitzpe Ramon.
Tanenhaus, M.K. and J.C. Trueswell. 1995. Sen-
tence comprehension. In Miller, J. and P. Eimas,
editors, Handbook of Perception and Cognition,
Vol. 11: Speech, Language and Communication,
pages 217?262. New York: Academic Press.
van Deemter, K. 2002. Generating referring ex-
pressions: Boolean extensions of the incremental
algorithm. Comp. Linguistics, 28(1):37?52.
van Deemter, K. 2004. Towards a probabilistic
version of bidirectional OT syntax and seman-
tics. Journal of Semantics, 21(3):251?281.
Wasow, T., A. Perfors, and D. Beaver. 2005. The
puzzle of ambiguity. In Orgun, O. and P. Sells,
editors, Morphology and The Web of Grammar:
Essays in Memory of Steven G. Lapointe. CSLI
Publications.
Wu, H. and T. Furugori. 1998. A computational
method for resolving ambiguities in coordinate
structures. In Proceedings of PACLIC-12, pages
263?270, National University of Singapore.
440
Computational Mechanisms for Pun Generation
Graeme Ritchie
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE
Scotland
gritchie@csd.abdn.ac.uk
Abstract
Computer pun-generators have so far relied on arbi-
trary semantic content, not linked to the immediate
context. The mechanisms used, although tractable,
may be of limited applicability. Integrating puns
into normal text may involve complex search.
1 Introduction
Recently, there has been a growing interest in computational
humour, as indicated by two international workshops [Hul-
stijn and Nijholt, 1996; Stock et al, 2002]. A number of com-
puter programs (mostly quite small) have been constructed
which generated very short humorous texts (see Section 4 be-
low). All but one of these programs generate some form of
pun, where we take a pun, informally and pre-theoretically,
to be a supposedly humorous written or spoken text which
relies crucially on phonetic similarity for its humorous effect.
There is no accepted strict definition of a pun, even amongst
humour scholars, but the computer-generated examples are
almost certainly puns by any reasonable definition; whether
they are funny or not is a separate question.
The purpose of this paper is to consider the task of pun
generation from the wider perspective of NLG, particularly
applied NLG, and to discuss the following:
? how the mechanisms used in pun generation systems
compare with conventional NLG;
? two classes of pun, with different potential roles in NLG;
? the computations that might achieve such puns;
? possible limitations of these computations.
We shall start with the claims made for the usefulness of
computer-generated jokes, give a very brief summary of past
work and then present some observations and arguments.
2 Motivation
It could be argued that computer modelling of humour is
worthwhile because it might shed light on human use of hu-
mour, and hence could contribute to a cognitive model of hu-
mour. Here we shall leave that aside, and consider a case
which has been more explicitly argued: that certain practical
computer systems will be more effective, or more pleasant to
use, if they display humour.
It has been claimed for some time that humour enhances
communication in various ways. In one study, subjects
were persuaded more effectively by material including hu-
mour [Lyttle, 2001]. In another, human subjects gave more
favourable reports of working with computer systems which
employed humour (albeit pre-coded, rather than computer-
generated) [Morkes et al, 1999].
Binsted [1995] argues that a user-interface which used hu-
mour would be more congenial to interact with. Stock [Stock,
2002; 2003] suggests that computerised humour will have
even wider applicability, in advertising, entertainment and
education. Nijholt [2002] points out that if virtual agents
are to show rich ?personalities? in their interactions with hu-
mans, some form of humour is essential. McKay [2002] sug-
gests the use of automated humour in a system for second-
language learning, and O?Mara and Waller [2003] propose
that machine-assisted communication by those with language
disabilities (particularly children) could be helped by some
software support for humour.
So far, no computer system for humour-generation has yet
been shown to have these benefits. Nevertheless, for the
purposes of this paper we shall assume, from the writings
cited above, that a case can be made for the desirability of
computer-generated humour in practical applications.
These authors have argued generally for the practical use
of humour, not merely puns. However, the type of humour-
generation that is likely to be available in the near future is
pun-generation. In the following sections, therefore, we shall
focus solely on puns, considering the ways in which they
might be generated within a broader NLG system.
3 Two classes of puns
There are various ways in which puns, or jokes in general,
could be classified, depending on the aspects which are of in-
terest. For the discussion here, we wish to make a distinction
between two loose groupings (not usually distinguished in the
literature):
Self-contained puns: These are pieces of text which can be
used as humorous items in a wide variety of circum-
stances. Any semantic links which they might have to
the context are not directly part of the joke structure, and
their only preconditions for use are general knowledge
(of the surrounding culture, etc.) and a social situation
in which joke-making is acceptable. Example (1) (from
[Binsted, 1996]) is a self-contained pun, as are all of the
puns ((5) ? (13)) shown in Section 4.1 below.
(1) What do you get when you cross a murderer with a
breakfast food? A cereal killer.
Contextually integrated puns: This type of pun occurs
within some broader discourse, with the use of a text
which, in addition to conveying some information or
emotion, has further linguistic properties which make it
a pun (and may thereby augment the effects of the text,
either emotionally, persuasively or otherwise). Also, the
status of the text as a pun may depend on contextual
(possibly non-linguistic) factors. Ritchie [2004, p.115]
offers (2) and (3) as puns; both of these, when first de-
livered, were contextually integrated puns.
(2) A shopper is walking along, and a leek falls from
his shopping bag to the ground, unnoticed. Another
shopper calls out, ?Hey! Your bag?s leaking!?
(3) A minor football team known informally as ?Caley
Thistle? (where Caley rhymes with alley) soundly
defeats Celtic (then the top team in the country) in
a major competition. The next day, a newspaper
headline reads: ?Super Caley Go Ballistic, Celtic
Are Atrocious?. (The Sun, 9 February 2000)
In (2), the pun status depends upon the substring leak be-
ing phonetically similar (identical) to the word leek, and
the latter word being directly related to the surrounding
context. In (3) the whole headline has some phonetic
similarity to the song-title Supercalifragilisticexpialido-
cious. In both cases, the utterance conveys contextually
appropriate information.
For both these types of puns, the text?s status as a pun is in
addition to a full set of normal linguistic properties: the pun-
ning texts are usually syntactically well formed texts which
have an internally consistent semantics.
The difference between the two classes can be viewed as
follows: in self-contained puns the semantic content is arbi-
trary, and of secondary importance to the features that make
the text a pun, whereas in contextually integrated puns the se-
mantic message is non-arbitrary, and the pun features have to
be compatible with it.
There are some puns which might seem to be borderline
examples. In everyday social situations, someone may make
a remark simply in order to make a pun, which might seem
therefore to count as a self-contained pun, but such an utter-
ance is very rarely completely unconnected to the context,
even if its sole purpose is humour. For example, someone
who moves their position in a room to avoid cold air from an
open window might make the remark in (4), punning on the
USA expression draft-dodger, ?someone who avoids military
conscription?.
(4) I?m just a draught-dodger.
Although this remark may communicate little useful infor-
mation, and is made solely as an attempt at humour, it is still a
contextually integrated pun, in the sense that what it conveys
relates to the context, and it would not be a pun without this
connection ? if the speaker had not moved to avoid cold air,
it would not be felicitous, and if someone later recounted the
remark alone, with no account of the context, that would not
count as a joke.
4 Previous work: self-contained puns
4.1 The programs
Since 1992, there have been a small number of programs
which created puns (cf. [Ritchie, 2004, Ch 10]). (Jokes de-
pend on cultural knowledge, and puns rely heavily on linguis-
tic knowledge, so some of these examples may be puzzling to
readers from other cultural or linguistic backgrounds.)
Lessard and Levison [1992] devised a program which cre-
ated a type of pun, the Tom Swifty, exemplified by (5).
(5) ?Turn up the heat,? said Tom coldly.
The form consists of a quoted utterance, and an adverbially
modified attribution of this remark to Tom. The meaning of
the utterance, or some subpart of it, is semantically linked to
the adverb. The generation is based on finding a configuration
of a root word (e.g. cold) which can be made into an adverb
(coldly) and a sentence somehow linked to the root word.
The JAPE program [Binsted, 1996; Binsted and Ritchie,
1997] generated punning riddles of certain types, illustrated
by (1), (6), (7), (8) (cf. [Lessard and Levison, 1993]).
(6) How is a nice girl like a sugary bird?
Each is a sweet chick.
(7) What is the difference between leaves and a car?
One you brush and rake, the other you rush and brake
(8) What do you call a strange market?
A bizarre bazaar.
This was achieved by various rules which specified allow-
able combinations of lexical entries and surface words; more
details are given in Section 4.2 below.
The HCPP [Venour, 1999] could create two-utterance texts,
where the second part was always a short noun phrase, as in
(9) (punning on doc/dock) and (10) (carrel/carol).
(9) The surgeon digs a garden. A doc yard.
(10) Joan hears wailing in the booth. Carrel singing.
Venour describes his method in terms which borrow both
from Binsted and from Lessard and Levison.
The puns produced by the WISCRAIC program [McKay,
2002] came in three forms, exemplified by (11), (12), (13).
(11) Who broke the woman?s hart?
The cruel deer-keeper.
(12) The performing lumberjack took a bough.
(13) Your mate Johnny is a hard-up deer-keeper. He really
needs doe!
Like the earlier programs, WISCRAIC operated by finding
sets of items (e.g. take a bow, bough, lumberjack, perform-
ing) which were related in specific ways, then slotting them
into stock textual forms.
The output of all these programs consists of self-contained
puns in the sense given in Section 3 above.
4.2 An architecture for self-contained puns
Some of the pun-generators (Lessard and Levison, Venour)
reviewed above were implemented using the Vinci language
generator [Levison and Lessard, 1992], others (Binsted,
McKay) using various Prolog facilities, including definite
clause grammars [Pereira and Warren, 1980]. However, the
general flow of processing in these systems is broadly the
same, and can be described using the model used by [Bin-
sted, 1996] (see also [Ritchie, 2003]). We will look at it in
more detail, partly to make more concrete some aspects of
these puns, and partly to show how these mechanisms relate
to more conventional NLG.
The JAPE processing falls into three stages: content selec-
tion, constituent building, surface string construction, each
of which is controlled by particular types of symbolic rule.
(Binsted calls the constituent-building stage SAD generation,
where ?SAD? stands for small adequate description, because
in JAPE it leads to short descriptive noun phrases.)
We shall describe each of these stages in turn.
Content selection
In this phase, a small number of items are selected from the
lexicon as the core of the pun. The generator has rules about
suitable combinations of lexical items and/or surface words,
and uses these to search for a cluster of workable items.
Binsted calls the content selection rules schemas. A pun-
generator program would have a number of schemas (JAPE-
3 had 15), each corresponding to some subclass of pun. A
schema contains two rather different types of information:
Precondition. A schema has a condition which a sequence
of lexical entries or surface strings (intuitively, the parame-
ters for the schema) must meet in order for this type of pun to
be generated. The precondition consists of a conjunction of
terms, where each term is a predicate (e.g. homophone) ap-
plied to variable arguments, and all variables are existentially
quantified. (None of the programs appear to need constant
values as arguments to predicates.) For example, one schema
(from [Ritchie, 2003]) has the precondition:
noun_phrase(NPLex),
component_lexemes(NPLex, LexA, LexB),
written_form([LexA], WordA),
homophone(WordA, HomWord),
written_form([HomLex], HomWord)
where some of the variables (NPLex, LexA, LexB, HomLex)
are to be matched against lexemes (abstract identifiers for
lexical entries) and others (WordA,HomWord) are matched
against surface strings. One possible set of bindings is NPLex
= serial killer, LexA = serial, LexB = killer, WordA
= ?serial?, HomWord = ?cereal?, HomLex = cereal.
Although many examples can be produced using predi-
cates which are computable using standard lexical informa-
tion (e.g. homophone), some of the puns (particularly those
in McKay?s system) need semantic relationships which, while
not seriously problematic, might not be standard lexical rela-
tions; for example an action ? take a bow ? which is ?typical?
of an entity with a particular property ? performing. Covering
these might need a more encyclopaedic knowledge base.
Interface to later stages. This part of a schema specifies
what is to be done with (some or all of) the values which sat-
isfy the preconditions. It contains a formula indicating how
further processing of the items is to be carried out, specifi-
cally what sorts of constituents they are to be built into.
For example, the JAPE schema illustrated immediately
above has the output specification (taking some liberties with
notation to save space):
<same, sad(share_properties, [HomLex, NPLex]),
sad(make_phrase, [HomLex, LexB]) >
This (rather obscurely) indicates that the values HomLex,
NPLex are to be used to create a phrase which, semantically,
has some mix of their properties (e.g. a murderer with fi-
bre), and that HomLex, LexB, are to be made directly into
a phrase (hence cereal killer). Also, the final text should con-
vey that the abstract relation same holds between these two
constituents. That is, the output specification of a schema pro-
vides a recipe for producing a structure which, while not ac-
tually a text, is much closer to the eventual surface form. The
various building procedures (e.g. share properties) have
a certain amount of non-deterministic freedom (see below),
so that there may be more than one way in which the linguis-
tic form of the phrase can be constructed, without affecting
the basic joke; for example, share properties might cre-
ate a crunchy murderer.
Constituent building
Given the items found in content selection, it may be nec-
essary to form constituents (noun phrases, verb phrases, sen-
tences) which either contain these items or bear some system-
atic relationship to them. In this stage, linguistic representa-
tions of these chunks are constructed, following the output
specification of the schema.
The constituent building stage is a relatively arbitrary map-
ping from the formulae provided by the schema to something
which is more of a surface semantic structure. This is done
by pattern-action rules which match against the various ?out-
put specifications? that can be come from the schema handler,
and produces something either in surface linguistic form (e.g.
a string of words) or some skeletal linguistic item whose ex-
act details (e.g. person, number) are left to the final (surface
string) stage. Thus some variation is possible in the linguistic
form of phrases, within the limits set by the initial schema
match. That is why Binsted introduced this middle stage (not
present in an earlier version of JAPE): to allow some linguis-
tic variety where this does not alter the underlying joke. For
example, (14) requires the same schema (and surface tem-
plate) as (8), but uses a different constituent for the question;
this difference would occur in the constituent-building phase.
(14) What do you call an odd mall?
A bizarre bazaar.
Surface string construction
In the third and final stage, a complete surface text is built
by transforming the semantic constituents into surface strings
and concatenating them, in some order, with various fixed
strings of words. Minor adjustments such as number agree-
ment, or choosing between a and an, are carried out. All this
is driven by templates, which are like DCG rules with some
pre-conditions attached.
4.3 Discussion of the mechanisms
The mechanisms summarised here were designed solely to
produce puns, but the notions of ?schema? and ?template?
are not radically (or interestingly) different from those estab-
lished within mainstream NLG (e.g. [McKeown, 1985], [Ku-
kich, 1983]). However, the way that this whole architecture
is deployed is unusual. Normally in NLG, we can reason-
ably make a distinction between some background knowledge
base (e.g. linguistic rules, lexicon, general facts about the do-
main) and some message which is to be conveyed. A typ-
ical schema-based system then matches its schemas against
the message to determine applicability, with the background
knowledge being called upon only as needed in the match.
In contrast, the pun generators have only a knowledge base,
and do not start from a message to be conveyed: they are
random generators of arbitrary puns. Hence the schemas
are tested against the whole lexical knowledge base, to see
if any sequence of items will meet the stated preconditions.
Rather than asking, as in informative NLG, ?is the message
of this general shape??, the pun generator asks ?are there any
items which can be put together in this way??. Thus con-
tent selection (which, conventionally, would precede schema-
matching) is inherent in this search for matching items.
Also, the remits passed from the schema-instantiator to the
constituent builder may be extremely vague, and not directly
related to any communicative goals. For example, generating
?Tom Swifties? requires, for the utterance part of the text, a
constituent to be constructed which is, roughly speaking, ?any
sentence which uses this specific word?.
These processing characteristics follow naturally from the
fact that the pun generators produce self-contained puns, and
hence have no communicative goals: any text will do, regard-
less of content, providing it constitutes a pun.
Hence, although schemas and templates are standard NLG
notions, the freedom allowed to the processing model is less
normal. Is this model of wider use? One possible applica-
tion where this arrangement (arbitrary content but constrained
form) might be of use is a language-teaching tool in which the
illustrative examples are not all pre-programmed by hand but
are machine-generated (either in advance or in response to
the interaction with the human learner). It is conceivable that
a such a system might need to create phrases or sentences
which are not embedded in any real context, and for which
the information conveyed is not critical, but whose linguistic
structure must manifest some particular property (e.g. using
some specific word, or being in passive voice). In that case,
the unusual priorities embodied in the JAPE-style architecture
(linguistic form over content) might be relevant.
The three-stage pun generation architecture allows quite
efficient processing, but the initial lexicon search could be
costly if done crudely. However, given the well-defined na-
ture of that search, it can be optimised in various ways;
preliminary unpublished results on the STANDUP project
[Waller et al, 2005] suggest that fast schema-instantiation
from a realistically large lexical database is quite feasible.
4.4 Usefulness of self-contained puns
Although a self-contained pun is of use only where it would
be helpful to interject a joke for its own sake, it could have
a limited degree of contextual connection, in the following
way. The status of the text as a pun is not context-dependent
(otherwise it would be a contextually integrated pun), but it
could mention topics which are currently salient. For exam-
ple, Loehr [1996] describes a very small prototype system in
which the user interface occasionally tells the user a (JAPE-
generated) joke. Loehr explores limited contextual linking,
based on keywords (for example, using a joke involving the
word aid when help was needed).
Such loose subject matter links do not require computer
joke-generation, but could be achieved from an database of
jokes which had been thoroughly cross-indexed. This might
be a viable way to add humour to a user-interface. Some
investigation would be needed of what types of semantic
links give rise to the most appropriate jokes, and the cross-
indexing, to be automated, would have to depend on well-
defined mechanisable relations (e.g. from a lexical database).
The main weakness of using self-contained puns in practi-
cal applications (such as those suggested by writers cited in
Section 2) is the lack of a subtle connection to what is go-
ing on at the moment of delivery. Nevertheless, isolated or
random jokes could still play a role in some applications:
Virtual agents: If a life-like image is to have a facetious
?personality?, then producing the occasional joke (even
a bad one) might be fitting (as in Loehr?s system).
Teaching language: An interactive system for assisting lan-
guage learners might use jokes as subject matter to be
studied or played with (as proposed by McKay, or by
[Manurung et al, 2004]). In such cases, the jokes might
not need to be tightly related to context.
Again, both these applications could meet the joking re-
quirements using a database of jokes, although proponents of
the educational application might argue that the effect will
be enhanced if the learner can experiment with joke-building
using an interactive system; cf. [Waller et al, 2005].
Notice that even a witty advertising slogan, although typ-
ically used in an isolated, context-independent fashion, is
more sophisticated than the types of self-contained pun that
have so far been computer generated, in that the content of a
slogan is not arbitrary: it has to convey a particular message.
In contrast, the systems reviewed in Section 4.1 above give
no regard to the communicative content of the output text.
5 A general definition
From (2), (3) and other examples, Ritchie [2004] argues that
there is a relatively well-defined, but large, subclass of puns
which can be summarised thus:
(i) part of the utterance is phonetically similar (perhaps
identical) to some other string not present in the utter-
ance;
(ii) either the utterance, or the utterance with that other
string substituted in, is contextually appropriate;
(iii) if the two substrings are identical, then they should be
lexically analysable in different ways, and the lexical
analysis of the one not in the utterance should either
be linked semantically to the context, or should involve
grouping together words which are separate within the
utterance;
(iv) if the two substrings are merely similar, then the un-
spoken one should form a complete and recognisable
linguistic unit (e.g. a complete word or an established
phrase). [Ritchie, 2004, pp.125-126]
This is probably the best available formal definition of this
kind of pun (see [Davies, 2004]), but it has some limitations
(which Ritchie documents) and some weaknesses:
(i) This covers only paradigmatic puns, where the com-
parison is between two strings, only one of which ac-
tually appears in the text. There are also syntagmatic
puns where both the similar/identical strings appear in
the text; (7) and (8) are very simple examples.
(ii) Where a sequence of words is involved in the pun, even
the unspoken sequence must ?make sense? in some way;
that is, a pun is not formed when a contextually appropri-
ate remark has a portion which is phonetically identical
to some random sequence of words (unless the individ-
ual words qualify as puns separately). We shall assume
this further condition in our discussions.
(iii) In the case where the two strings are merely similar
(but not identical) the definition puts no restriction on
which should appear in the actual text (providing the
non-present text forms a well-known phrase). However,
consider an example like (3), above. The headline would
not have worked as a pun had it simply read ?Super-
califragilisticexpialidocious?, as this would not have al-
lowed recovery of the contextually-appropriate message
(even though it would still conform to Ritchie?s defini-
tion). The correct condition may be better stated in terms
of the ease with which the absent string can be sum-
moned up or reconstructed, although this is not an un-
problematic notion [Hempelmann, 2003]. It may be that
there is a trade-off between the degree of phonetic simi-
larity and the extent to which the string outside the text
is a well-known phrase. Ritchie also cites the headline
(15), but this may work because un-bolivia-ble is not a
valid word, which may draw attention to the possibility
that another word or phrase should be considered.
(15) Some South American stamps are un-bolivia-ble
The word unbelievable is not a well-known item in the
sense of being famous, but it is cohesive as a morpho-
logically complex word.
(iv) The previous point suggests that the condition stipulat-
ing that either one of the two similar strings should form
a contextually appropriate part of the utterance may, in
some cases, be too loose.
(v) Ritchie adopts the widespread assumption that puns are
defined on phonetic strings, as this allows a natural de-
scription of the central relationship (phonetic similarity).
However, many puns are conveyed in written text, and
most NLG systems produce textual rather than spoken
output. When a pun involves two phonetically identical
strings, the question of which string appears in the ac-
tual utterance is moot when all the representations are
phonetic; when the text is orthographically represented,
the choice of string may affect whether the pun is notice-
able to the reader. It is arguable that (2) would be more
obviously a pun if the final sentence were Your bag?s
leeking! That is, it may improve the effectiveness of the
pun to use the textual form which is not completely lin-
guistically appropriate (here, there is no verb to leek).
Ritchie [2004, p. 199] gives a more formal version of his
definition, which makes it clearer what primitive concepts it
depends upon. These are:
Phonetic similarity. Study of an extensive range of puns
(e.g. [Sobkowiak, 1991]) shows that the degree (and na-
ture) of similarity required for punning is not obvious.
Contextually appropriate. Puns are part of a text which
?makes sense in context?. Although this is not unprob-
lematic, it is a condition which an NLG system should
aim for, even if no punning is intended; that is, it is not
a further condition imposed by the aim of punning.
Linked to the context. This is a looser notion than ?contex-
tually appropriate?. The linking just means that some
concepts which are salient in the context are some-
how related to the concept(s) mentioned in the word or
phrase; e.g. in a situation where cooking is being dis-
cussed, words like grill or baste would be linked to the
context.
Forming a recognisable word/phrase. Puns can depend on
a sequence of words being matched against a single
word, or a well-known idiom, motto or quotation. It
is not clear when a phrase is sufficiently established to
qualify.
The above definition covers contextually integrated puns
relatively naturally ? see (2), (4) and the examples in [Ritchie,
2004, Ch 9] ? and is therefore directly relevant to the possible
generation of such puns. Less obviously, the definition could
be seen as covering self-contained puns (and hence the puns
in Section 4), as follows. The early part of the text (e.g. the
question in a riddle) can be treated as the ?context?, and the
latter part (e.g. the answer to a riddle) as forming the pun
utterance proper. That is, self-contained puns can be seen as
puns with their own ?context? built in, rather than linking to
some context outside the text.
6 Computing contextually integrated puns
6.1 The usefulness of contextually integrated puns
Many of the advocates of useful computational humour seem
to have in mind some form of ?wit? by the computer system,
rather than the mere spouting of jokes. The hypothetical il-
lustrations given by Binsted[1995], for example, involve droll
observations by the computer about what is happening at the
moment. Such goals take us in the direction of contextually
integrated puns. More concretely, if puns delivered within a
quasi-natural dialogue are not contextually appropriate in a
non-trivial way, there is little point in wasting time with com-
puter generation; as noted earlier, a large and well-indexed
database of jokes would be much more straightforward.
Let us consider what would be needed for a system to pro-
duce a text which met al the pun conditions given in Sec-
tion 5. We assume that the NLG system will already be
striving for a text which makes sense (in context), so we
need only consider how the further pun conditions might be
achieved. All of these requirements are decidable in princi-
ple, although (as noted above) there are non-trivial problems
in defining what should count as sufficient phonetic similar-
ity, what counts as an established phrase, and what counts as
linkage to a context.
6.2 Detecting puns
Suppose some communicative system is to enhance its verbal
output with puns. It seems reasonable to propose that such
a system (particularly in cases where this behaviour is to be
part of a life-like ?personality?) should be ?aware? of having
made a pun. That is, if the system makes a pun, it should have
some record of that having happened, so that it can respond
appropriately to, or even anticipate, the user?s reaction. Ide-
ally, the system should also be able to avoid humour when
this would be socially inappropriate.
This suggests that the most minimal form of pun-
computation would be checking textual output to see if it
contains accidental puns. The system would then be in the
position to make sense of any reaction by the user to the pun
(or to eliminate any accidental but undesirable humour). This
would not involve any special-purpose text construction ? the
system would merely check the output it had designed to meet
its current (non-punning) goals. If unwanted humour is to be
eliminated, this is more difficult, as it would require some
form of revision component, which is not trivial.
Such a scheme could be seen as a special case of a more
general post-checking approach, which tests for other desir-
able or undesirable properties, such as accidental ambiguity.
(General ambiguity might even constitute a form of fortuitous
humour, but that goes beyond the basic punning we are cur-
rently considering.)
As we shall discuss below, the full pun definition might
lead to complex computations. A simplification which should
be more tractable (but might miss more complex puns) would
be merely to check each lexical item in the text to determine
whether it had a homophone which was linked to the context.
In order to ensure that the user was aware of the pun, the
homophone might have to be substituted into the text (as in
our method below, Substitution with identity).
Notice that incomplete coverage is something of a flaw in
a checking mechanism like this, as the aim is for the system
to spot every occasion on which it makes a pun; if it misses
some, then the user might respond to a pun in a way which the
system cannot easily interpret (or an unwanted joke might slip
through). On the other hand, a pun-production mechanism,
like those discussed below, need not be comprehensive, as
long as it can produce some puns (and does not cause the text
to become faulty in other respects).
6.3 The search problem
Our working definition (Section 5) involves a combination
of conditions, some of which result in considerable search:
finding some substring of the utterance, finding some string
not in the utterance (a very large set!), finding some lexical
analysis of the non-utterance string which meets certain con-
ditions, finding some well-known word or phrase which is
similar. The definition also has a few disjunctions, to further
increase the search. Hence, even a non-constructive check
(Section 6.2) would involve a significant amount of search-
ing, particularly if na??vely implemented.
Some of the simpler cases considered below (e.g. substi-
tuting a contextually-linked homophone) might fit naturally
into a NLG system based on constraint-satisfaction (CS) (cf.
[Power, 2000]). However, CS methods would not completely
remove the complexity problems involved in implementing
the entire definition from Section 5. CS reduces process-
ing in cases where the possible values of the variables are
well-defined and easily enumerable, and evaluating individ-
ual constraints is relatively cheap; i.e. where the main com-
putational load is in testing compatibility among chains of
values. Here, the main work is elsewhere. Conditions such as
testing whether some substring of some possible output string
is similar to some well-known phrase would require compu-
tationally expensive enumeration of the basic values (possible
substrings of possible output texts), and non-trivial conditions
(phonetic similarity) involving very large sets (all words and
well-known phrases). CS might be slightly better than a na??ve
search, but it would not be a panacea.
One complicating factor is that the pun criteria are largely
surface constraints which apply to what, in a conventional
pipeline NLG architecture [Reiter and Dale, 2000], would be
the final output of the generator. Hence, it may be difficult
for high-level (early) stages of a pipeline generator to make
syntactic or lexical decisions which will result in puns, nor
is it simple to effect ?revisions? to a surface text which has
been the outcome of much high-level processing. There is
not space here to explore the large issue of surface-level con-
straints and their consequences for NLG architecture, but see
[Reiter, 2000] for some discussion.
Puns are not the only forms in which surface constraints are
central: poetry generation [Manurung et al, 2000; Gerva?s,
2002] makes comparably awkward demands.
6.4 Some possible devices
We can consider some possible ways in which an NLG sys-
tem might include contextually integrated puns.
Substitution with identity. The crudest approach to actual
pun-generation would be to attach a punning module as a final
stage. This module would review the entire text as generated
and see whether it could be edited to form a pun, while mak-
ing as few revisions as possible ? preferably none ? to pre-
vious higher-level decisions. The simplest tactic here would
be the substitution of a phonetically similar (and internally
coherent) string for some subpart of the message, where the
substituted string does not represent the same lexical items
as those in the original message, and either the content of
the substituted string is somehow linked to the context or the
substituted version should represent a finer segmentation of
the material into words. Even for this very basic method, the
search is considerable. A simplified version could be limited
to looking for homophones of words in the message, and sub-
stituting these providing they were contextually linked; this
is probably the most tractable option.
Substitution with similarity. A slight extension of the pre-
vious method would be to relax the condition from phonetic
identity to phonetic similarity. However, some care would
be needed in deciding under what conditions this should be
permitted, in view of the point raised earlier about the ?re-
coverability? of the contextually appropriate string. (This ex-
tension worsens the search problem.)
Minor rephrasing. It is conceivable that a surface-based
editing component could detect that a minor re-wording
would fulfil the pun conditions. However, such changes
should not impair the overall message of the text, which
means that this is not an easy solution.
Lexical preference. Rather than using a post-editing stage,
we could build the pun facilities into a higher level of
the NLG system. One possibility would be some form of
amended lexical choice, within the NLG process (i.e. not
post-editing as in the above mechanisms). The system could,
when choosing a lexical item, give preference (if it would not
distort the intended message) to a word which has a homo-
phone which is in some way linked to the context. It might
also be helpful to use that homophone in the text, to make the
pun obvious to the reader, as noted previously. An extension
would be to have the lexical choice system seek a phoneti-
cally similar item (not a strict homophone) which is associ-
ated with the context. In this case, inserting that other word
in the text (in place of the more directly correct one) would
be not just helpful but necessary.
Rephrasing for lexical preference. The previous device
could perhaps be generalised, depending on how the genera-
tor organises lexical choice, to giving preference to a phrasing
(not just the choice of a single word in isolation) which con-
tains a word with a homophone/similar word which meets the
pun conditions. This increases the amount of searching that
the NLG system would require.
Matching against phrases. A further generalisation would
be for the system to seek not an identical/similar word, but
a phrase (similar/identical to a valid wording of the intended
message) which met the pun conditions (perhaps, as in exam-
ple (3), matching one word against several). These conditions
(Section 5) for a phrase are slightly different from those for a
word. To consider matching all possible well-known phrases
(assuming such a database were available) when constructing
a sentence would lead to high search costs.
Some of these processes could be quite open-ended, as
puns (human-constructed) sometimes involve quite global re-
phrasing in order to achieve the punning effect. The subeditor
who created (3) must have planned the entire headline with
the word Supercalifragilisticexpialidocious in mind.
The later tactics (Rephrasing for lexical preference, Match-
ing against phrases) would be more easily incorporated into
a generator which was opportunistic about what material to
include. For example, the ILEX text generator [Oberlander et
al., 1998] has a content selection stage in which the knowl-
edge base is traversed to gather facts to be expressed. This
is not as free as the process in Section 4.2 above, as ILEX
starts from a particular knowledge base object which is to be
described, and the search is for facts relevant to that object.
The STREAK system [Robin, 1994] can produce variants of
a text in which different amounts of supporting information
(for the central proposition) are included. The choice of this
additional information could allow more freedom to a pun-
devising algorithm (although still with significant search).
Even if any of these pun-creating schemes were imple-
mented, it is quite likely that in many cases no suitable match
would be found, and text realisation would have to proceed as
normal. That is, the pun-condition checking might be wasted
effort, just adding to the generation time for the text.
7 Conclusions
We have seen that existing pun generators assume a relatively
simple rule-based generation architecture, but the way that
this architecture has been used is not typical of NLG tasks.
These generators produce self-contained puns, but such jokes
would be of potential use only in certain applications (where
bald joke-telling is acceptable, or where language is to be
studied rather than used in natural communication). The case
for using contextually integrated puns to enhance computer
systems is more plausible, but in the most general case this
could lead to computational complexity. Nevertheless, there
may be some tractable ?tricks? which an NLG system could
use to produce very simple contextually-integrated puns.
Acknowledgements: This paper benefitted from comments
from the Aberdeen NLG group, and from Ruli Manurung.
References
[Binsted and Ritchie, 1997] Kim Binsted and Graeme
Ritchie. Computational rules for generating punning rid-
dles. Humor: International Journal of Humor Research,
10(1):25?76, 1997.
[Binsted, 1995] Kim Binsted. Using humour to make natural
language interfaces more friendly. In Hiroaki Kitano, ed-
itor, Proceedings of the International Joint Conference on
Artificial Intelligence Workshop on AI and Entertainment,
pages 55?57, Montreal, 1995.
[Binsted, 1996] Kim Binsted. Machine humour: An imple-
mented model of puns. PhD thesis, University of Edin-
burgh, Edinburgh, Scotland, October 1996.
[Davies, 2004] Christie Davies. Review of ?The linguis-
tic analysis of jokes?. Journal of Literary Semantics,
33(2):196?197, 2004.
[Gerva?s, 2002] Pablo Gerva?s. Exploring quantitative evalua-
tions of the creativity of automatic poets. In Carlos Bento,
Amilcar Cardoso, and Geraint Wiggins, editors, 2nd Work-
shop on Creative Systems, Approaches to Creativity in
Artificial Intelligence and Cognitive Science, ECAI 2002,
Lyon, France, 2002.
[Hempelmann, 2003] Christian Hempelmann. Paronomasic
Puns: Target Recoverability Towards Automatic Genera-
tion. PhD thesis, Purdue University, 2003.
[Hulstijn and Nijholt, 1996] Joris Hulstijn and Anton Ni-
jholt, editors. Proceedings of the International Workshop
on Computational Humor, number 12 in Twente Work-
shops on Language Technology, Enschede, Netherlands,
September 1996. University of Twente.
[Kukich, 1983] Karen Kukich. Design of a knowledge-
based report generator. In Proceedings of the 21st Annual
Meeting of the Association for Computational Linguistics,
pages 145?150. ACL, 1983.
[Lessard and Levison, 1992] Greg Lessard and Michael Lev-
ison. Computational modelling of linguistic humour: Tom
Swifties. In ALLC/ACH Joint Annual Conference, Oxford,
pages 175?178, 1992.
[Lessard and Levison, 1993] Greg Lessard and Michael Lev-
ison. Computational modelling of riddle strategies. In
ALLC/ACH Joint Annual Conference, Georgetown Uni-
versity, Washington, DC, pages 120?122, 1993.
[Levison and Lessard, 1992] Michael Levison and Greg
Lessard. A system for natural language generation. Com-
puters and the Humanities, 26:43?58, 1992.
[Loehr, 1996] Dan Loehr. An integration of a pun genera-
tor with a natural language robot. In Hulstijn and Nijholt
[1996], pages 161?172.
[Lyttle, 2001] Jim Lyttle. The effectiveness of humor in per-
suasion: The case of business ethics training. Journal of
General Psychology, 128(3):206?216, April 2001.
[Manurung et al, 2000] Hisar Maruli Manurung, Graeme
Ritchie, and Henry Thompson. A flexible integrated
architecture for generating poetic texts. In Proc of
the Fourth Symposium on Natural Language Processing
(SNLP 2000), pages 7?22, Chiang Mai, Thailand, 2000.
[Manurung et al, 2004] Ruli Manurung, Alistair Low, Lu-
cia Trujillo-Dennis, David O?Mara, Helen Pain, Graeme
Ritchie, and Annalu Waller. Interactive computer genera-
tion of jokes for language skill development. Talk at An-
nual Conference of the International Society for Humor
Studies, June 2004. Dijon, France.
[McKay, 2002] Justin McKay. Generation of idiom-based
witticisms to aid second language learning. In Stock et al
[2002], pages 77?87.
[McKeown, 1985] Kathleen McKeown. Text Generation.
Studies in Natural Language Processing. Cambridge Uni-
versity Press, Cambridge, UK, 1985.
[Morkes et al, 1999] John Morkes, Hadyn K. Kernal, and
Clifford Nass. Effects of humor in task-oriented human-
computer interaction and computer-mediated communica-
tion: A direct test of srct theory. Human-Computer Inter-
action, 14(4):395?435, 1999.
[Nijholt, 2002] Anton Nijholt. Embodied agents: A new im-
petus to humor research. In Stock et al [2002], pages 101?
111.
[Oberlander et al, 1998] Jon Oberlander, Mick O?Donnell,
Alistair Knott, and Chris Mellish. Conversation in the mu-
seum: experiments in dynamic hypermedia with the intel-
ligent labelling explorer. New Review of Hypermedia and
Multimedia, pages 11?32, 1998.
[O?Mara and Waller, 2003] Dave A. O?Mara and Annalu
Waller. What do you get when you cross a communica-
tion aid with a riddle? The Psychologist, 16(2):78?80,
2003.
[Pereira and Warren, 1980] F. Pereira and D. H. D. Warren.
Definite clause grammars for language analysis ? a survey
of the formalism and a comparison with augmented tran-
sition networks. Artificial Intelligence, 13:231?278, 1980.
[Power, 2000] Richard Power. Planning texts by constraint
satisfaction. In Proceedings of the 18th International Con-
ference on Computational Linguistics (COLING-2000),
pages 642?648, Saarbru?cken, Germany, 2000.
[Reiter and Dale, 2000] Ehud Reiter and Robert Dale. Build-
ing Natural Language Generation Systems. Cambridge
University Press, Cambridge, UK, 2000.
[Reiter, 2000] Ehud Reiter. Pipelines and size constraints.
Computational Linguistics, 26(2):251?259, June 2000.
[Ritchie, 2003] Graeme Ritchie. The JAPE riddle genera-
tor: technical specification. Informatics Research Report
EDI-INF-RR-0158, School of Informatics, University of
Edinburgh, Edinburgh, February 2003.
[Ritchie, 2004] Graeme Ritchie. The Linguistic Analysis of
Jokes. Routledge, London, 2004.
[Robin, 1994] Jacques Robin. Revision-Based Generation of
Natural Language Summaries Providing Historical Back-
grouns: Corpus-Based Analysis, Design, Implementation
and Evaluation. PhD thesis, Columbia University, 1994.
[Sobkowiak, 1991] Wlodzimierz Sobkowiak. Metaphonol-
ogy of English Paronomasic Puns, volume 26 of Univer-
sity of Bamberg Studies in English Linguistics. Peter Lang,
Frankfurt, 1991.
[Stock et al, 2002] Oliviero Stock, Carlo Strapparava, and
Anton Nijholt, editors. Proceedings of the April Fools?
Day Workshop on Computational Humor, number 20 in
Twente Workshops on Language Technology, Enschede,
Netherlands, April 2002. University of Twente.
[Stock, 2002] Oliviero Stock. Computational humor. In Ste-
fano A. Cerri, Guy Gouarde`res, and Fa?bio Paraguac?u, ed-
itors, Intelligent Tutoring Systems: Proceedings of the 6th
International Conference, Lecture Notes in Computer Sci-
ence, pages 2?3, Berlin, 2002. Springer. Invited talk.
[Stock, 2003] Oliviero Stock. ?Password Swordfish?: Verbal
humor in the interface. Humor: International Journal of
Humour Research, pages 281?295, 2003.
[Venour, 1999] Chris Venour. The computational generation
of a class of puns. Master?s thesis, Queen?s University,
Kingston, Ontario, 1999.
[Waller et al, 2005] Annalu Waller, Dave O?Mara, Ruli Ma-
nurung, Helen Pain, and Graeme Ritchie. Facilitating user
feedback in the design of a novel joke generation system
for people with severe communication impairment. In
Proceedings of 11th International Conference on Human-
Computer Interaction, Las Vegas, July 2005.
Proceedings of the Fourth International Natural Language Generation Conference, pages 89?91,
Sydney, July 2006. c?2006 Association for Computational Linguistics
The Clarity-Brevity Trade-off in Generating Referring Expressions ?
Imtiaz Hussain Khan and Graeme Ritchie and Kees van Deemter
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, U.K.
{ikhan,gritchie,kvdeemte}@csd.abdn.ac.uk
Abstract
Existing algorithms for the Generation of
Referring Expressions (GRE) aim at gen-
erating descriptions that allow a hearer to
identify its intended referent uniquely; the
length of the expression is also considered,
usually as a secondary issue. We explore
the possibility of making the trade-off be-
tween these two factors more explicit, via
a general cost function which scores these
two aspects separately. We sketch some
more complex phenomena which might be
amenable to this treatment.
1 Introduction
Until recently, GRE algorithms have focussed on
the generation of distinguishing descriptions that
are either as short as possible (e.g. (Dale, 1992;
Gardent, 2002)) or almost as short as possible (e.g.
(Dale and Reiter, 1995)). Since reductions in am-
biguity are achieved by increases in length, there
is a tension between these factors, and algorithms
usually resolve this in some fixed way. However,
the need for a distinguishing description is usually
assumed, and typically built in to GRE algorithms.
We will suggest a way to make explicit this bal-
ance between clarity (i.e. lack of ambiguity) and
brevity, and we indicate some phenomena which
we believe may be illuminated by this approach.
The ideas in this paper can be seen as a loosen-
ing of some of the many simplifying assumptions
often made in GRE work.
?This work is supported by a University of Aberdeen
Sixth Century Studentship, and the TUNA project (EPSRC,
UK) under grant number GR/S13330/01. We thank Ielka van
der Sluis and Albert Gatt for valuable comments.
2 Clarity, Brevity and Cost
We consider only simple GRE, where the aim is to
construct a conjunction of unary properties which
distinguish a single target object from a set of po-
tential distractors. Our notation is as follows. A
domain consists of a set D of objects, and a set P
of properties applicable to objects in D. A descrip-
tion is a subset of P. The denotation of S, written
[[ S ]], is {x ? D | ?p ? S : p(x)}.
(Krahmer et al, 2003) describe an approach to
GRE in which a cost function guides search for a
suitable description, and show that some existing
GRE algorithms fit into this framework. However,
they follow the practice of concentrating solely on
distinguishing descriptions, treating cost as a mat-
ter of brevity. We suggest that decomposing cost
into two components, for the clarity and brevity
of descriptions, permits the examination of trade-
offs. For now, we will take the cost of a description
S to be the sum of two terms:
cost(S) = fC(S) + fB(S).
where fC counts ambiguity (lack of clarity) and
fB counts size (lack of brevity). Even with this
decomposition of cost, some existing algorithms
can still be seen as cost-minimisation. For exam-
ple, the cost functions:
fC(S) =| P | ? | [[ S ]] |
fB(S) = | S |
allow the Full Brevity algorithm (Dale, 1992) to
be viewed as minimising cost(S), and the in-
cremental algorithm (Dale and Reiter, 1995) as
hill-climbing (strictly, hill-descending), guided by
the property-ordering which that algorithm re-
quires. Whereas Krahmer et al?s cost functions
are (brevity-based) heuristic guidance functions,
our alternative here is a global quantity for opti-
misation. Hence their simulation of Full Brevity
89
relies on the details of their algorithm (rather than
cost) to ensure clarity, while our own cost function
ensures both brevity and clarity.
3 Exploring the Trade-off
3.1 Varying penalties for distractors
Imagine the following situation. You are prepar-
ing a meal in a friend?s house, and you wish to
obtain, from your own kitchen, a bottle of Italian
extra virgin olive oil which you know is there. The
only way open to you is to phone home and ask
your young child to bring it round for you. You
know that also in your kitchen cupboard are some
distractors: one bottle each of Spanish extra virgin
olive oil, Italian non-virgin olive oil, cheap veg-
etable oil, linseed oil (for varnishing) and cam-
phorated oil (medicinal). It is imperative that you
do not get the linseed or camphorated oil, and
preferable that you receive olive oil. A full ex-
pression, Italian extra virgin olive oil, guarantees
clarity, but may overload your helper?s abilities. A
very short expression, oil, is risky. You might well
settle for the intermediate olive oil.
To model this situation, fC could take a much
higher value if [[ S ]] contains a distractor which
must not be selected (e.g. varnish rather than cook-
ing oil). That is, instead of a simple linear function
of the size of [[ S ]], there is a curve where the cost
drops more steeply as the more undesirable dis-
tractors are excluded. For example, each object
could be assigned a numerical rating of how unde-
sirable it is, with the target having a score of zero,
and the fC value for a set A could be the maxi-
mum rating of any element of A. (This would, of
course, require a suitably rich domain model.)
The brevity cost function fB could still be a rel-
atively simple linear function, providing fB values
do not mask the effect of the shape of the fC curve.
3.2 Fuzziness of target
Suppose Mrs X has dropped a piece of raw
chicken meat on the kitchen table, and immedi-
ately removed the meat. She would now like Mr
X to wipe the area clean. The meat leaves no visi-
ble stain, so she has to explain where it was. In this
case, it appears that there is no such thing as a dis-
tinguishing description (i.e. a description that pins
down the area precisely), although Mrs X can ar-
bitrarily increase precision, by adding properties:
? the edge of the table,
? the edge of the table, on the left (etc.)
The ideal description would describe the dirty area
and nothing more, but a larger area will also do,
if not too large. Here, the domain D is implic-
itly defined as all conceivable subareas of the ta-
ble, the target is again one element of D, but ? un-
like the traditional set-up with discrete elements ?
a description (fuzzily) defines one such area, not
a disjoint collection of individual items. Our fC
operates on the description S, not just on the num-
ber of distractors, so it can assess the aptness of
the denotation of any potential S. However, it has
to ensure that this denotation (subarea of the sur-
face) contains the target (contaminated area), and
does not contain too much beyond that. Hence,
we may need to augment our clarity cost function
with another argument: the target itself. In gen-
eral, more complex domains may need more com-
plicated functions.
3.3 Underspecification in dialogue
Standard GRE algorithms assume that the speaker
knows what the hearer knows (Dale and Reiter,
1995). In practice, speakers can often only guess.
It has been observed that speakers sometimes pro-
duce referring expressions that are only disam-
biguated through negotiation with the hearer, as
exemplified in the following excerpt (quoted in
(Hirst, 2002)).
1. A: What?s that weird creature over there?
2. B: In the corner?
3. A: [affirmative noise]
4. B: It?s just a fern plant.
5. A: No, the one to the left of it.
6. B: That?s the television aerial. It pulls out.
A and B are in the same room, in an informal set-
ting, so A can be relatively interactive in convey-
ing information. Also, the situation does not ap-
pear to be highly critical, in comparison to a mil-
itary officer directing gunfire, or a surgeon guid-
ing an incision. Initially, A produces an expres-
sion which is not very detailed. It may be that he
thinks this is adequate (the object is sufficiently
salient that B will uniquely determine the refer-
ent), or he doesn?t really know, but is willing to
make an opening bid in a negotiation to reach the
goal of reference. In the former case, a GRE algo-
rithm which took account of salience (e.g. (Krah-
mer and Theune, 1999)), operating withA?s model
of B?s knowledge, should produce this sort of ef-
fect. (A dialogue model might also be needed.) In
the latter case, we need an algorithm which can
90
relax the need for complete clarity. This could be
arranged by having fC give similar scores to deno-
tations where there are no distractors and to deno-
tations where there are just a few distractors, with
fB making a large contribution to the cost.
3.4 Over-specification
Recently, interest has been growing in ?overspec-
ified? referring expressions, which contain more
information than is required to identify their in-
tended referent. Some of this work is mainly or ex-
clusively experimental (Jordan and Walker, 2000;
Arts, 2004), but algorithmic consequences are also
being explored (Horacek, 2005; Paraboni and van
Deemter, 2002; van der Sluis and Krahmer, 2005).
Over-specification could also arise in a dialogue
situation (comparable to that in Section 3.3) if a
speaker is unclear about the hearer?s knowledge,
and so over-specifies (relative to his own knowl-
edge) to increase the chances of success.
This goes beyond the classical algorithms,
where the main goal is total clarity, with no rea-
son for the algorithm to add further properties to
an already unambiguous expression. That is, such
algorithms assume that every description S for
which | [[ S ]] |= 1 has the same level of clarity
(fC value). This assumption could be relaxed. For
example, the approach of (Horacek, 2005) to GRE
allows degrees of uncertainty about the effective-
ness of properties to affect their selection. Within
such a framework, one could separately compute
costs for clarity (e.g. likelihood of being under-
stood) and brevity (which might include the com-
plexity of expressing the properties).
4 Conclusion and Future Work
We have argued that the GRE task becomes very
different when some commonly-made assump-
tions are abandoned: some distractors might be
worse than others (section 3.1); the target may be
impossible to distinguish precisely (section 3.2);
the speaker may be unsure what the hearer knows
(section 3.3); or there may be a need for over-
specification (section 3.4)). As a result, it may be
necessary to consider other aspects of the descrip-
tions and their denotations, not simply counting
distractors or numbers of properties. Some effects
could perhaps be modelled using costs which are
not simple linear functions, but which give varying
importance to particular aspects of the denotation
of a description, or of its content. We hope that
this approach will ultimately shed light not only
on the effect of the discourse situation, but also
some aspects of generating indefinite descriptions.
References
Anja Arts. 2004. Overspecification in Instructive Text.
Ph.D. thesis, Tilburg University, The Netherlands.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
18:233?263.
Robert Dale. 1992. Generating Referring Expres-
sions: Building Descriptions in a Domain of Objects
and Processes. MIT Press.
Claire Gardent. 2002. Generating minimal distin-
guishing descriptions. In Proceedings of the 40th
Annual Meeting of the ACL (ACL?02), Philadelphia,
USA.
Graeme Hirst. 2002. Negotiation, compromise, and
collaboration in interpersonal and human?computer
conversations. In Proceedings of Workshop on
Meaning Negotiation, 18th National Conference
on Artificial Intelligence, pages 1?4, Edmonton,
Canada.
Helmut Horacek. 2005. Generating referential de-
scriptions under conditions of uncertainty. In Gra-
ham Wilcock, Kristiina Jokinen, Chris Mellish, and
Ehud Reiter, editors, Proceedings of the 10th Eu-
ropean Workshop on Natural Language Generation
(ENLG-05), pages 58?67.
Pamela Jordan and Marilyn Walker. 2000. Learning
attribute selections for non-pronominal expressions.
In Proceedings of the 38th Annual Meeting of the
ACL (ACL-00), pages 181?190.
Emiel Krahmer and Marie?t Theune. 1999. Efficient
generation of descriptions in context. In Proceed-
ings of the ESSLLI workshop on the generation of
nominals, Utrecht, The Netherlands.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Ivandre? Paraboni and Kees van Deemter. 2002. Gener-
ating easy references: the case of document deixis.
In Proceedings of the Second International Confer-
ence on Natural Language Generation, New York,
USA.
Ielka van der Sluis and Emiel Krahmer. 2005. Towards
the generation of overspecified multimodal referring
expressions. In Proceedings of the Symposium on
Dialogue Modelling and Generation at the 15th An-
nual Meeting of the ST & D (STD-05), Amsterdam,
The Netherlands.
91
Proceedings of the 12th European Workshop on Natural Language Generation, pages 98?101,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
A Hearer-oriented Evaluation of Referring Expression Generation ?
Imtiaz H. Khan, Kees van Deemter, Graeme Ritchie, Albert Gatt, Alexandra A. Cleland
University of Aberdeen, Aberdeen, Scotland, United Kingdom
{i.h.khan,k.vdeemter,g.ritchie,a.gatt,a.cleland}@abdn.ac.uk
Abstract
This paper discusses the evaluation of a
Generation of Referring Expressions algo-
rithm that takes structural ambiguity into
account. We describe an ongoing study
with human readers.
1 Introduction
In recent years, the NLG community has seen a
substantial number of studies to evaluate Gener-
ation of Referring Expressions (GRE) algorithms,
but it is still far from clear what would constitute
an optimal evaluation method. Two limitations
stand out in the bulk of existing work. Firstly,
most existing evaluations are essentially speaker-
oriented, focussing on the degree of ?human-
likeness? of the generated descriptions, disre-
garding their effectiveness (e.g. Mellish and Dale
(1998), Gupta and Stent (2005), van Deemter et al
(2006), Belz and Kilgarriff (2006), Belz and Re-
iter (2006), Paris et al (2006), Viethen and Dale
(2006), Gatt and Belz (2008)). The limited num-
ber of exceptions to this rule indicate that the dif-
ferences between the two approaches to evaluation
can be substantial (Gatt and Belz, 2008). Sec-
ondly, most evaluations have focussed on the se-
mantic content of the generated descriptions, as
produced by the Content Determination stage of
a GRE algorithm; this means that linguistic re-
alisation (i.e. the choice of words and linguistic
constructions) is usually not addressed (exceptions
are: Stone and Webber (1998), Krahmer and The-
une (2002), Siddharthan and Copestake (2004)).
Our aim is to build GRE algorithms that produce
referring expressions that are of optimal benefit to
a hearer. That is, we are interested in generating
descriptions that are easy to read and understand.
But the readability and intelligibility of a descrip-
tion can crucially depend on the way in which it is
? This work is supported by a University of Aberdeen
Sixth Century Studentship, and EPSRC grant EP/E011764/1.
worded. This happens particularly when there is
potential for misunderstanding, as can happen in
the case of attachment and scope ambiguities.
Suppose, for example, one wants to make it
clear that all radical students and all radical teach-
ers are in agreement with a certain idea. It might
be risky to express this as ?the radical students and
teachers are agreed?, since the reader1 might be
inclined to interpret this as pertaining to all teach-
ers rather than only the radical ones. For this rea-
son, a GRE program might opt for the longer noun
phrase ?the radical students and the radical teach-
ers?. But because this expression is lengthier, the
choice involves a compromise between compre-
hensibiliity and brevity, a special case of a diffi-
cult trade-off that is typical of generation as well
as interpretation of language (van Deemter, 2004).
We previously reported the design of an algo-
rithm (based on an earlier work on expressions re-
ferring to sets (Gatt, 2007)), which was derived
from experiments in which readers were asked to
express their preference between different descrip-
tions and to respond to instructions which used a
variety of phrasings (Khan et al, 2008). Here we
discuss the issues that arise when such an algo-
rithm is evaluated in terms of its benefits for read-
ers.
2 Summary of the algorithm
In order to study specific data, we have focussed
on the construction illustrated in Section 1 above:
potentially ambiguous Noun Phrases of the gen-
eral form the Adj Nouni and Nounj . For such
phrases, there are potentially two interpretations:
wide scope (Adj modifies both Nouni and Nounj)
or narrow scope (Adj modifies Nouni but not
Nounj).
Our algorithm starts from an unambiguous set-
theoretic formula over lexical items (i.e. words
1In this paper, we use the word reader and hearer inter-
changeably.
98
have already been chosen), and thus has to choose
between a number of different realisations. The
possible phrasings for the wide scope meaning are:
(1) the Adj Noun1 and Noun2, (2) the Adj Noun2
and Noun1, (3) the Adj Noun1 and the Adj Noun2,
and (4) the Adj Noun2 and the Adj Noun1. For nar-
row scope, the possibilities are: (1) the Adj Noun1
and Noun2, (2) the Noun2 and Adj Noun1, (3) the
Adj Noun1 and the Noun2, and (4) the Noun2 and
the Adj Noun1. For our purposes, (1) and (2) are
designated as ?brief?, (3) and (4) as ?non-brief?
(that is, ?brevity? has a specialised sense involv-
ing the presence/absence of ?the? and possibly Adj
before the second Noun). Importantly, the ?non-
brief? expressions are syntactically unambiguous,
but the ?brief? NPs are potentially ambiguous, and
hence are the focus of attention in this work.
Our algorithm is based on certain specific hy-
potheses (from the earlier experiments) which
make crucial use of corpus data concerning the
frequency of two types of collocations: the col-
location between an adjective and a noun, and the
collocation between two nouns. At a broader level,
we hypothesise: the most likely reading of an NP
can be predicted using corpus data (Word Sketches
(Kilgarriff, 2003)). The more specific hypotheses
derive from earlier work by Kilgarriff (2003) and
Chantree et al (2006), and were further developed
and tested in our previous experiments. The cen-
tral idea is that this statistical information can be
used to predict a ?most likely? scoping (and hence
interpretation) for the adjective in the ?brief? (i.e.
potentially ambiguous) NPs. We define an NP to
be predictable if our model predicts a single read-
ing for it; otherwise it is unpredictable. Hence, all
?non-brief? NPs are predictable (being unambigu-
ous), but only some of the ?brief? ones are pre-
dictable.
In a nutshell, the model underlying our algo-
rithm prefers predictable expressions to unpre-
dictable ones, but if several of the expressions are
predictable then brief expressions are preferred
over non-brief.
3 Aims of the study
We want to find out whether our generator
makes the best possible choices (for hearers) from
amongst the different ways in which a given de-
scription can be realised. But although our al-
gorithm uses sophisticated strategies for avoiding
noun phrases that it believes to be liable to mis-
understanding, misunderstandings cannot be ruled
out, and if a hearer misunderstands a noun phrase
then secondary aspects such as reading (and/or
comprehension) speed are of little consequence.
We therefore plan first to find out the likelihood of
misunderstanding. For this reason, we will report
on the degree of accuracy, as a percentage of times
that a participant?s understanding of an expression
that we label as predictable fails to match the in-
terpretation assigned by our model. Additionally,
we shall statistically test two hypotheses:
Comprehension Accuracy 1: Predictable ex-
pressions are more often interpreted in
agreement than in disagreement with the
model.
Comprehension Accuracy 2: There is more
agreement among participants on the inter-
pretation of predictable expressions than of
unpredictable expressions.
We will not only test the comprehensibility of the
expressions generated by our algorithm, but their
readability and intelligibility as well. This is nec-
essary because the experiments which led to the
algorithm design considered only certain aspects
of the hearer?s reaction to NPs (e.g. metalinguistic
judgements about a participant?s preferences) and
we wish to check these comprehensibility/brevity
facets from a different, perhaps psycholinguisti-
cally more valid, perspective. It is also necessary
because avoidance of misunderstandings is not the
only decisive factor: if several of the expressions
are predictable then our algorithm chooses be-
tween them by preferring brevity. But why is brief
better than non-brief? Taking readability and intel-
ligibility together as ?processing speed?, our third
hypothesis is:
Processing speed: Subjects process
predictable brief expressions more
quickly than predictable non-brief ones.
Confirmation of this hypothesis would be a strong
indication that our algorithm is on the right track,
particularly if the degree of accuracy (see above)
turns out to be high. Processing speed is a com-
plex concept, but we could decompose it as ?read-
ing speed? and ?comprehension speed?, permitting
us to examine reading and comprehension sepa-
rately. We intend to see what evidence there is for
the following additional propositions, which will
be tested solely to aid our understanding.
99
Reading Speed:
RS1: Subjects read predictable brief NPs more
quickly than unpredictable brief ones.
RS2: Subjects read unpredictable brief NPs more
quickly than predictable non-brief ones.
RS3: Subjects read predictable brief NPs more
quickly than predictable non-brief ones.
Comprehension Speed:
CS1: Subjects comprehend predictable brief NPs
more quickly than unpredictable brief ones.
CS2: Subjects comprehend predictable non-brief
NPs more quickly than unpredictable brief ones.
CS3: Subjects do not comprehend predictable
non-brief NPs more quickly than predictable brief
ones.
(Remember that, in our restricted set of NPs, a
phrase cannot be both ?unpredictable? and ?non-
brief?.) Rejection of any of these statements will
not count against our algorithm.
4 Sketch of experimental procedure
Participants will be presented with a sequence of
trials (on a computer screen), each of which con-
sists of a lead-in sentence followed by a target sen-
tence and a comprehension question that relates to
the two sentences together. The target sentence
might for example say ?the radical students and
teachers were waving their hands?. The compre-
hension question in this case could be ?Were the
moderate teachers waving their hands??. As both
the target sentence and the comprehension ques-
tion make use of definite NPs (e.g. ?the moderate
teachers?), it is necessary to ensure any presuppo-
sitions about the existence of the referent set are
met, without biasing the answer. For this reason,
the target sentence is preceded by a lead-in sen-
tence to establish the existence of the sets within
the discourse (here, ?there were radical and mod-
erate people in a rally?).
Given this set-up we are confident that we
can identify, from a participant?s yes/no answer,
whether the NP in the target sentence was assigned
a narrow-scope or a wide-scope reading for the ad-
jective. The computer will record the participant?s
response as well as the length of time that the par-
ticipant took to answer the question. We will use
Linger2 for presentation of stimuli. Pilots sug-
gest that the complexity of the trials makes it ad-
visable to use masked sentence-based self-paced
2http://tedlab.mit.edu/?dr/Linger/
reading, in which every press of the space bar re-
veals the next sentence and the previous sentence
is replaced by dashes.
The choice of nouns and adjectives (to construct
NPs) is motivated by the fact that there is a bal-
anced distribution of NPs in each of the follow-
ing three classes. Wide scope class is the one for
which our model predicts a wide-scope reading;
narrow scope class is the one for which our model
predicts a narrow-scope reading; and ambiguous
class is the one for which our model fails to pre-
dict a single reading (Khan et al, 2008).
5 Issues emerging from this study
The design of this experiment raised some difficult
questions, some quite unexpected:
1. The quality of the output of a generation al-
gorithm might appear to be a simple and well-
understood concept. However, output quality is
multi-faceted, because an expression may be easy
to read but difficult to process semantically, or the
other way round. A thorough output evaluation
should address both aspects of quality, in our view.
2. If both reading and understanding are ad-
dressed, this raises the question of how these
two dimensions should be traded off against each
other. If one algorithm?s output was read more
quickly than that of another, but understood more
slowly than the second, which of the two should be
preferred? Perhaps there is a legitimate role here
for metalinguistic judgments after all, in which
participants are asked to express their preference
between expressions (see Paraboni et al (2006) for
discussion)? An alternative point of view is that
these questions are impossible to answer indepen-
dent of a realistic setting in which participants ut-
ter sentences with a concrete communicative pur-
pose in mind. If utterances were made in order to
accomplish a concrete task (e.g., to win a game)
then task-based evaluation would be possible.
3. Even though this paper has not focussed on de-
tails of experimental design and analysis, one diffi-
culty is worth mentioning: given the grammatical
options between which the generator is choosing,
only three types of situations are represented: a de-
scription can be brief and predictable (e.g. using
?the old men and women? to convey wide scope,
since the adjective is predicted by our algorithm
to have wide scope), brief and unpredictable (e.g.
?the rowing boats and ships? for wide scope, given
100
a prediction of narrow scope), or non-brief and
predictable (e.g. ?the old men and the old women?
for wide scope). It might appear that there exists
a fourth option: non-brief and unpredictable. But
this is ruled out by our technical sense of ?non-
brief?: as noted earlier, ?non-brief? NPs do not
have the scope ambiguity. Because of this ?miss-
ing cell?, it will not be possible to analyse our data
using an ANOVA test, which would have automat-
ically taken care of all possible interactions be-
tween comprehensibility and brevity. A number
of different tests will be used instead, with Bon-
ferroni corrections where necessary.
6 Conclusion
Human-based evaluation is gaining considerable
popularity in the NLG community. Whereas eval-
uation of GRE has mostly been speaker-oriented,
the present paper has explored a plan for an ex-
perimental hearer-oriented evaluation. The main
conclusion is that hearer-based evaluation is diffi-
cult because the quality of a generated expression
can be measured in different ways, whose results
cannot be assumed to match. One factor we have
not examined is the notion of fluency: it is possible
that our algorithm will sometimes choose a word
order (e.g. ?the women and old men?) that is rela-
tively infrequent, and therefore lacking in fluency.
Such situations might lead to longer reading times.
References
A. Belz and A. Kilgarriff. 2006. Shared-task evalu-
ations in HLT: Lessons for NLG. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation, pages 133?135.
A. Belz and E. Reiter. 2006. Comparing automatic
and human evaluation of NLG systems. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 313?320, Trento, Italy, 3-7 April.
F. Chantree, B. Nuseibeh, A. de Roeck, and A. Willis.
2006. Identifying nocuous ambiguities in require-
ments specifications. In Proceedings of 14th IEEE
International Requirements Engineering conference
(RE?06), Minneapolis/St. Paul, Minnesota, U.S.A.
A. Gatt and A. Belz. 2008. Attribute selection for re-
ferring expression generation: New algorithms and
evaluation methods. In Proceedings of the 5th Inter-
national Conference on NLG.
A. Gatt. 2007. Generating Coherent References to
Multiple Entities. Ph.D. thesis, University of Ab-
erdeen, Aberdeen, Scotland.
S. Gupta and A. Stent. 2005. Automatic evaluation
of referring expression generation using corpora. In
Proceedings of the Workshop on Using Corpora for
Natural Language Generation, pages 1?6.
I. H. Khan, K. van Deemter, and G. Ritchie. 2008.
Generation of referring expressions: Managing
structural ambiguities. In Proceedings of the 22nd
International Conference on Computational Lin-
guistics (COLING-8), pages 433?440, Manchester.
A. Kilgarriff. 2003. Thesauruses for natural language
processing. In Proceedings of NLP-KE, pages 5?13,
Beijing, China.
E. Krahmer and M. Theune. 2002. Efficient context-
sensitive generation of referring expressions. In
K. van Deemter and R. Kibble, editors, Information
Sharing: Reference and Presupposition in Language
Generation and Interpretation, CSLI Publications,
pages 223?264.
C. Mellish and R. Dale. 1998. Evaluation in the
context of natural language generation. Computer
Speech and Language, 12(4):349?373.
I. Paraboni, J. Masthoff, and K. van Deemter. 2006.
Overspecified reference in hierarchical domain:
measuring the benefits for readers. In Proceedings
of the Fourth International Conference on Natural
Language Generation(INLG), pages 55?62.
C. Paris, N. Colineau, and R. Wilkinson. 2006. Eval-
uations of NLG systems: Common corpus and tasks
or common dimensions and metrics? In Proceed-
ings of the 4th International Conference on Natural
Language Generation, pages 127?129.
A. Siddharthan and A. Copestake. 2004. Generating
referring expressions in open domains. In Proceed-
ings of the 42nd Meeting of the Association for Com-
putational Linguistics Annual Conference (ACL-04).
M. Stone and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics. In
Proceedings of the Ninth International Workshop on
Natural Language Generation, pages 178?187, New
Brunswick, New Jersey.
K. van Deemter, I. van der Sluis, and A. Gatt. 2006.
Building a semantically transparent corpus for the
generation of referring expressions. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation, pages 130?132.
K. van Deemter. 2004. Towards a probabilistic version
of bidirectional OT syntax and semantics. Journal
of Semantics, 21(3):251?281.
J. Viethen and R. Dale. 2006. Towards the evaluation
of referring expression generation. In Proceedings
of the 4th Australasian Language Technology Work-
shop, pages 115?122, Sydney, Australia.
101
