Proceedings of the Fourth International Natural Language Generation Conference, pages 55?62,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Overspecified reference in hierarchical domains:
measuring the benefits for readers
Ivandre? Paraboni
University of Sao Paulo
EACH - Av.Arlindo Bettio, 1000
03828-000 Sao Paulo, Brazil
ivandre@usp.br
Judith Masthoff
University of Aberdeen
Dep.of Computing Science
Aberdeen AB24 3UE, Scotland, UK
jmasthoff@csd.abdn.ac.uk
Kees van Deemter
University of Aberdeen
Dep.of Computing Science
Aberdeen AB24 3UE, Scotland, UK
kvdeemte@csd.abdn.ac.uk
Abstract
It is often desirable that referring expres-
sions be chosen in such a way that their
referents are easy to identify. In this paper,
we investigate to what extent identification
becomes easier by the addition of logically
redundant properties.We focus on hierar-
chically structured domains, whose con-
tent is not fully known to the reader when
the referring expression is uttered.
Introduction
Common sense suggests that speakers and writ-
ers who want to get their message across should
make their utterances easy to understand. Broadly
speaking, this view is confirmed by empirical
research (Deutsch 1976, Mangold 1986, Levelt
1989, Sonnenschein 1984, Clark 1992, Cremers
1996, Arts 2004, Paraboni and van Deemter 2002,
van der Sluis, 2005). The present paper follows in
the footsteps of Paraboni and van Deemter (2002)
by focussing on hierarchically structured domains
and asking whether any benefits are obtained when
an algorithm for the generation of referring ex-
pressions (GRE) builds logical redundancy into the
descriptions that it generates. Where Paraboni and
van Deemter (2002) reported on the results of a
simple experiment in which subjects were asked
to say which description they preferred in a given
context, the present paper describes a much more
elaborate experiment, measuring how difficult it is
for subjects to find the referent of a description.
1 Background
Let us distinguish between two aspects of the ?un-
derstanding? of a referring expression, which we
shall denote by the terms interpretation and reso-
lution. We take interpretation to be the process
whereby a hearer/reader determines the meaning
or logical form of the referring expression; we take
resolution to be the identification of the referent of
the expression once its meaning has been deter-
mined. It is resolution that will take centerstage in
our investigation.
Difficulty of resolution and interpretation do not
always go hand in hand. Consider sentences (1a)
and (1b), uttered somewhere in Brighton but not
on Lewes Road.
(1a) 968 Lewes Road
(1b) number 968
Assume that (1a) refers uniquely. If other streets
in Brighton do not have numbers above 900, then
even (1b) is a unique description ? but a pretty
useless one, since it does not help you to find the
house unless your knowledge of Brighton is ex-
ceptional. The description in (1a) is longer (and
might therefore take more time to read and in-
terpret) than (1b), but the additional material in
(1a) makes resolution easier once interpretation is
successfully completed. We explore how an GRE
program should make use of logically redundant
properties so as to simplify resolution (i.e., the
identification of the referent).
In corpus-based studies, it has been shown that
logically redundant properties tend to be included
when they fulfill one of a number of pragmatic
functions, such as to indicate that a property is of
particular importance to the speaker, or to high-
light the speaker?s awareness that the referent has
the property in question (Jordan 2000). However,
redundancy has been built into GRE algorithms
55
only to a very limited extent. Perhaps the most in-
teresting account of overspecification so far is the
one proposed by Horacek (2005), where logically
redundant properties enter the descriptions gener-
ated when the combined certainty of other prop-
erties falls short of what is contextually required.
Uncertainty can arise, for example, if the hearer
does not know about a property, or if she does not
know whether it applies to the target referent.
Our own work explores the need for overspecifi-
cation in situations where each of the properties
in question is unproblematic (i.e., certain) in prin-
ciple, but where the reader has to make an effort
to discover their extension (i.e., what objects are
truthfully described by the property). We ask how
a generator can use logically redundant informa-
tion to reduce the search space within which a
reader has to ?find? a referent. (Cf., Edmonds 1994
for a related set of problems.)
2 Hierarchical domains
Existing work on GRE tends to focus on fairly
simple domains, dominated by one-place proper-
ties. When relations (i.e., two-place properties)
are taken into account at all (e.g., Dale and Had-
dock 1991, Krahmer and Theune 2002), the mo-
tivating examples are kept so small that it is rea-
sonable to assume that speaker and hearer know
all the relevant facts in advance. Consequently,
search is not much of an issue (i.e., resolution is
easy): the hearer can identify the referent by sim-
ply intersecting the denotations of the properties
in the description. While such simplifications per-
mit the study of many aspects of reference, other
aspects come to the fore when larger domains are
considered.
Interesting questions arise, for example, when a
large domain is hierarchically ordered. We con-
sider a domain to be hierarchically ordered if its
inhabitants can be structured like a tree in which
everything that belongs to a given node n be-
long to at most one of n?s children, while every-
thing that belongs to one of n?s children belongs
to n. Examples include countries divided into
provinces which, in turn, may be divided into re-
gions, etc.; years into months then into weeks
and then into days; documents into chapters then
sections then subsections; buildings into floors
then rooms. Clearly, hierarchies are among our
favourite ways of structuring the world.
A crucial question, in all such cases, is what
knowledge is shared between speaker and hearer
at utterance time. It will be convenient to start by
focussing on the extreme case where, before the
start of resolution, knows nothing about the do-
main. When the utterance is made, the hearer?s
blindfold is removed, so to speak, and resolution
can start. No similar assumption about the speaker
is made: we assume that the speaker knows every-
thing about the domain, and that he knows that the
hearer can achieve the same knowledge. Many of
our examples will be drawn from a simple model
of a University campus, structured into buildings
and rooms; the intended referent will often be a
library located in one of the rooms. The location
of the library is not known to the hearer, but it is
known to the speaker. Each domain entity r will be
(d)
   library                                         
Watts building                                                        Cockcroft building
  room100       ...       room120     ...        room140  room100       ...       room110     ...        room120   
University of Brighton
Figure 1: A hierarchically structured domain.
associated with a TYPE (e.g., the type ?room?), and
with some additional attributes such as its ROOM
NUMBER or NAME, and we will assume that it is
always possible to distinguish r from its siblings
in the tree structure by using one or more of these
properties. (For example, ?R.NUMBER=102? iden-
tifies a room uniquely within a given building) 1.
3 Obstacles for resolution
Generating a uniquely referring expression is not
always enough, because such an expression can
leave the hearer with an unnecessarily large search
space. But the issue is an even starker one, es-
pecially when the locations of speaker and hearer
are taken into account. (For simplicity, we assume
that the locations coincide.)
Suppose a hierarchically-ordered domain D con-
tains only one entity whose TYPE is LIBRARY.
Consider the following noun phrases, uttered in
the position marked by d in Figure 1. (The first
three have the same intended referent.)
1This is a useful assumption, since the existence of a dis-
tinguishing description cannot be otherwise guaranteed.
56
(2a) the library, in room 120 in the Cockcroft bld.
(2b) the library, in room 120
(2c) the library
(2d) room 120
Utterances like (2a) and (2b) make use of the hi-
erarchical structure of the domain. Their content
can be modelled as a list
L = ?(x1, P1), (x2, P2)...(xn, Pn)?,
where x1 = r is the referent of the referring ex-
pression and, for every j > 1, xj is an ances-
tor (not necessarily the parent) of xj?1 in D. For
every j, Pj is a set of properties that jointly iden-
tify xj within xj+1 or, if j = n, within the whole
domain. For example, (2a) is modelled as
L = ?(r, {type = library}),
(x2, {type = room, r.number = 120}),
(x3, {type = building,
name = Cockcroft})?
We focus on the search for xn because, under the
assumptions that were just made this is the only
place where problems can occur (since no parent
node is available).
Even though each of (2a)-(2d) succeeds in char-
acterising their intended referent uniquely, some
of these descriptions can be problematic for the
hearer. One such problem occurs in (2d). The
expression is logically sufficient. But, intuitively
speaking, the expression creates an expectation
that the referent may be found nearby, within the
Watts building whereas, in fact, a match can only
be found in another building. In this case we will
speak of Lack of Orientation (LO).
Even more confusion might occur if another li-
brary was added to our example, e.g., in Watts 110,
while the intended referent was kept constant. In
this case, (2c) would fail to identify the referent, of
course. The expression (2b), however, would suc-
ceed, by mutually using two parts of the descrip-
tion (?the library? and ?room 120?) to identify an-
other: there are two libraries, and two rooms num-
bered 120, but there is only one pair (a, b) such
that a is a library and b is a room numbered 120,
while a is located in b. Such cases of mutual iden-
tification are unproblematic in small, transparent,
domains where search is not an issue, but in large
hierarchical domains, they are not. For, like (2d),
(2b) would force a reader to search through an un-
necessarily large part of the domain; worse even,
the search ?path? that the reader is likely to follow
leads via an obstacle, namely room 120 Watts, that
matches a part of the description, while not being
the intended referent of the relevant part of the de-
scription (i.e., room 120 Cockcroft). Confusion
could easily result. In cases like this, we speak of
a Dead End (DE).
In section 5 we will present evidence suggesting
that instances of Dead End and Lack of Orienta-
tion may disrupt search in a sufficiently large or
complex domain. For a theoretical discussion we
refer to Paraboni and van Deemter (2002).
4 Generation algorithms
What kinds of expression would existing GRE al-
gorithms produce in the situations of interest?
Since hierarchies involve relations, the first al-
gorithm that comes to mind is the one pro-
posed by Dale and Haddock (1991). Essen-
tially, this algorithm combines one- and two-
place predicates, until a combination is found that
pins down the target referent. A standard ex-
ample involves a domain containing two tables
and two bowls, while only one of the two tables
has a bowl on it. In this situation, the combi-
nation {bowl(x), on(x, y), table(y)} identifies x
(and, incidentally, also y) uniquely, since only one
value of x can be used to verify the three pred-
icates; this justifies the description ?the bowl on
the table?. This situation can be ?translated? di-
rectly into our university domain. Consider Fig-
ure 2, with one additional library in room 110
of the Watts building. In this situation, the com-
University of Brighton
   
  room100       ...       room110     ...        room120   room100       ...       room120     ...        room140
Watts building                                                        Cockcroft building
   library                                         
(d)
   library                                         
Figure 2: A university campus with two libraries.
bination {library(x), in(x, y), room(y), room ?
number(y) = 2} identifies x (and, incidentally,
also y) uniquely, because no other library is lo-
cated in a room with number 120 (and no other
room numbered 120 contains a library). Thus, the
standard approach to relational descriptions allows
precisely the kinds of situation that we have de-
scribed as DE. Henceforth, we shall describe this
57
as the Minimal Description (MD) approach to ref-
erence because, in the situations of interest, it uses
the minimum number of properties by which the
referent can be distinguished.
Paraboni and van Deemter (2002) have sketched
two GRE algorithms, both of which are guaran-
teed to prevent DE and LO by including logi-
cally redundant information into the generated de-
scriptions so as to reduce the reader?s search space.
These algorithms, called Full Inclusion (FI) and
Scope-Limited (SL), are not the only ways in
which resolution may be aided, but we will see that
they represent two natural options. Both take as
input a hierarchical domain D, a location d where
the referring expression will materialise, and an
intended referent r.
Briefly, the FI algorithm represents a straightfor-
ward way of reducing the length of search paths,
without particular attention to DE or LO. It lines
up properties that identify the referent uniquely
within its parent node, then moves up to identify
this parent node within its parent node, and so on
until reaching a subtree that includes the starting
point d 2. Applied to our earlier example of a ref-
erence to room 120, FI first builds up the list
L = ?(r, {type = room, r.number = 120})?,
then expands it to
L = ?(r, {type = room, r.number = 120}),
(x1, {type = building,
buildingname = Cockcroft})?.
Now that Parent(X) includes d , r has been iden-
tified uniquely within D and we reach STOP. L
might be realised as e.g., ?room 120 in Cockcroft?.
FI gives maximal weight to ease of resolution.
But something has to give, and that is brevity:
By conveying logical redundancy, descriptions are
lengthened, and this can have drawbacks. The
second algorithm in Paraboni and van Deemter
(2002), called SCOPE-LIMITED (SL), constitutes
a compromise between brevity and ease of resolu-
tion. SL prevents DE and LO but opts for brevity
when DE and LO do not occur. This is done
by making use of the notion of SCOPE, hence the
name of the algorithm.
2The idea behind not moving up beyond this subtree is
a natural extension of Krahmer and Theune?s treatment of
salience in GRE: see Paraboni and van Deemter (2002).
The difference between FI and SL becomes ev-
ident when we consider a case in which the min-
imally distinguishing description does not lead to
DE or LO. For example, a reference to r = li-
brary would be realised by FI as ?the library in
room 120 in Cockcroft?. By using SL, however,
the same description would be realised by the SL
algorithm simply as ?the library?, since there is no
risk of DE or LO. With the addition of a second
library in the Watts building, the behaviour of the
SL algorithm would change accordingly, produc-
ing ?the library in Cockcroft?. Similarly, had we
instead included the second library under another
room of Cockcroft, SL would describe r as ?the li-
brary in room 120 of Cockcroft?, just like FI . For
details of both algorithms we refer to Paraboni and
van Deemter (2002).
5 The new experiment
In Paraboni and van Deemter (2002) an experi-
ment was described to find out what types of ref-
erences are favoured by human judges when their
opinion about these references is asked. As an
example of a hierarchically ordered domain, the
experiment made use of a document structured in
sections and subsections. This allowed Paraboni
and van Deemter (2002) to show their subjects the
domain itself, rather than, for example, a pictorial
representation (as it would be necessary in most
other cases such as that of a University campus,
which motivated many of our examples so far).
The experiment investigated the choice of so-
called document-deictic references, such as ?the
picture in part x of section y? made by authors of
documents to check whether they choose to avoid
potential DE and LO situations by adding redun-
dant properties (favouring ease of resolution) and,
conversely, whether they choose shorter descrip-
tions when there is no such risk (favouring ease
of interpretation). The results suggested that hu-
man authors often prefer logically redundant ref-
erences, particularly when DE and LO can arise.
While this approach had the advantage that sub-
jects could compare different expressions (per-
haps balancing ease of interpretation with ease
of resolution), the method is limited in other re-
spects. For example, meta-linguistic judgements
are sometimes thought to be an unreliable pre-
dictor of people?s linguistic behaviour (e.g., van
Deemter 2004). Perhaps more seriously, the ex-
58
periment fails to tell us how difficult a given type
of reference (for example, one of the DE type)
would actually be for a reader. Therefore, in this
paper we report on a second experiment investigat-
ing the effect of the presence or absence of logical
redundancy on the performance of readers. We are
primarily interested in understanding the search
process, so resolution rather than interpretation.
5.1 Experiment design
Subjects: Forty-two computing science students
participated in the experiment, as part of a sched-
uled practical.
Procedure: A within-subjects design was used.
Each subject was shown twenty on-line docu-
ments, in a random order. The entire document
structure was always visible, and so was the con-
tent of the current document part. A screenshot of
an example document providing this level of infor-
mation is shown in Figure 3. Each document was
Figure 3: Fragment of the experiment interface.
initially opened in Part B of either Section 2 or
3, where a task was given of the form ?Let?s talk
about [topic]. Please click on [referring expres-
sion]? . For instance ?Let?s talk about elephants.
Please click on picture 5 in part A?. Subjects
could navigate through the document by clicking
on the names of the parts (e.g. Part A as visi-
ble under Section 3). As soon as the subject had
correctly clicked on the picture indicated, the next
document was presented. Subjects were reminded
throughout the document about the task to be ac-
complished, and the location at which the task
was given. All navigation actions were recorded.
At the start of the experiment, subjects were in-
structed to try to accomplish the task with a mini-
mal number of navigation actions.
We assume that readers do not have complete
knowledge of the domain. So, they do not know
which pictures are present in each part of each sec-
tion. If readers had complete knowledge, then a
minimal description would suffice. We do, how-
ever, not assume readers to be completely ignorant
either3: we allowed them to see the current doc-
ument part (where the question is asked) and its
content, as well as the hierarchical structure (sec-
tions and parts) of the remainder of the document
as in Figure 3 above.
Research Questions: We want to test whether
longer descriptions indeed help resolution, partic-
ularly in so-called problematic situations. Table 1
shows the types of situation (potential DE, LO,
and non-problematic)4 , reader and referent loca-
tion, and descriptions used.
Hypothesis 1: In a problematic (DE/LO) situ-
ation, the number of navigation actions required
for a long (FI /SL) description is smaller than
that required for a short (MD) description.
We will use the DE and LO situations in Ta-
ble 1 to test this hypothesis, comparing for each
situation the number of navigation actions of the
short, that is, minimally distinguishing (MD) and
long (FI/SL) expressions. In Paraboni and van
Deemter (2002) there was an additional hypothe-
sis about non-problematic situations, stating that
MD descriptions would be preferred to long de-
scriptions in non-problematic situations. We can-
not use this hypothesis in this experiment, as it is
highly unlikely that a shorter description will lead
to fewer navigation actions. (Note that the experi-
ment in Paraboni and van Deemter (2002) looked
at the combination of interpretation and resolution,
while we are now focussing on resolution only).
Instead, we will look at gain: the number of navi-
gation actions required for a short description mi-
nus the number required for a long description.
3Readers will always have some knowledge: if in Part B
of Section 2, then they would know (by convention) that there
will also be a Section 1, and a Part A in Section 2 etc.
4In DE situations, there is another picture with the same
number as the referent, but not in a part with the same name
as the part in which the referent is. In LO situations, there
is no other picture with the same number as the referent, and
the reader location contains pictures. In non-problematic sit-
uations, there is another picture with the same number as the
referent, but not in a part with the same name as the part in
which the referent is.
59
Sit. Type Reader Loc. Referent Loc. Short (MD) Long (FI/SL) Long (other)
1 DE Part B Sec 3 Part A Sec 2 Pic 3 in Part A Pic 3 in Part A Sec 2
2 DE Part B Sec 2 Part C Sec 3 Pic 4 in Part C Pic 4 in Part C Sec 3
3 LO Part B Sec 3 Part A Sec 3 Pic 5 Pic 5 in Part A Pic 5 in Part A Sec 3
4 LO Part B Sec 2 Part C Sec 2 Pic 4 Pic 4 in Part C Pic 4 in Part C Sec 2
5 LO Part B Sec 3 Part A Sec 4 Pic 5 Pic 5 in Part A Sec 4 Pic 5 in Part A
6 LO Part B Sec 2 Part C Sec 1 Pic 4 Pic 4 in Part C Sec 1 Pic 4 in Part C
7 NONE Part B Sec 2 Part A Sec 2 Pic 3 in Part A Pic 3 in Part A Sec 2
8 NONE Part B Sec 3 Part C Sec 3 Pic 4 in Part C Pic 4 in Part C Sec 3
Table 1: Situations of reference
Hypothesis 2: The gain achieved by a long
description over an MD description will be
larger in a problematic situation than in a non-
problematic situation.
We will use the DE and non-problematic situa-
tions in Table 1 to test this hypothesis, comparing
the gain of situation 1 with that of situation 7, and
the gain of situation 2 with that of situation 8.
Longer descriptions may always lead to fewer nav-
igation actions, and it can be expected that com-
plete descriptions of the form picture x in Part y of
Section z will outperform shorter descriptions in
any situation. So, from a resolution point of view,
an algorithm that would always give a complete
description may produce better results than the al-
gorithms we proposed, which do not always give
complete descriptions (e.g. situation 3 in Table 1).
The aim of our algorithms is to make the descrip-
tions complete enough to prevent DE and LO in
resolution, but not overly redundant as this may
affect interpretation. We would like to show that
the decisions taken by FI and SL are sensible, i.e.
that they produce descriptions that are neither too
short nor too long. Therefore:
S1: We want to consider situations in which FI
and SL have produced an incomplete descrip-
tion, and investigate how much gain could have
been made by using a complete description in
those cases. We would like this gain to be negli-
gible. We will use situations 3 and 4 for this, cal-
culating the gain of the long, complete descrip-
tions (namely, long (other) in Table 1) over the
short, incomplete descriptions generated by our
algorithms (long (FI /SL) in Table 1).
S2: We want to consider situations in which FI
and SL have produced a complete description,
and investigate how much gain has been made by
using this compared to a less complete descrip-
tion that is still more complete than MD. We
would like this gain to be large. We will use situ-
ations 5 and 6 for this, calculating the gain of the
long complete descriptions generated by our al-
gorithms (long (FI /SL) in Table 1) over the less
complete descriptions (long (other) in Table 1).
Introducing separate hypotheses for cases S1 and
S2 poses the problem of defining when a gain is
?negligible? and when a gain is ?large?. Instead,
we will compare the gain achieved in S1 with the
gain achieved in S2, expecting that the gain in S2
(which we believe to be large) will be larger than
the gain in S1 (which we believe to be negligible).
Hypothesis 3: The gain of a complete descrip-
tion over a less complete one will be larger for
situations in which FI and SL generated the
complete one, than for situations in which they
generated the less complete one.
Materials: Twenty on-line documents were pro-
duced, with the same document structure (sec-
tions 1 to 5 with parts A to C) and containing
10 pictures. Documents had a unique background
colour, title and pictures appropriate for the title.
The number of pictures in a section or part varied
per document. All of this was done to prevent sub-
jects relying on memory.
Documents were constructed specifically for the
experiment. Using real-world documents might
have made the tasks more realistic, but would have
posed a number of problems. Firstly, documents
needed to be similar enough in structure to allow
a fair comparison between longer and shorter de-
scriptions. However, the structure should not al-
low subjects to learn where pictures are likely to be
(for instance, in patient information leaflets most
pictures tend to be at the beginning). Secondly,
the content of documents should not help subjects
find a picture: e.g., if we were using a real docu-
ment on animals, subjects might expect a picture
of a tiger to be near to a picture of a lion. So,
60
Short Long (FI/SL) Long (Other)
Sit. Type Mean STDEV Mean STDEV Mean STDEV
1 DE 3.58 2.14 1.10 0.50
2 DE 3.85 3.28 1.30 1.31
3 LO 5.60 4.84 1.93 1.29 1.23 1.27
4 LO 2.50 1.97 1.60 1.28 1.38 2.07
5 LO 8.53 4.15 1.15 0.53 5.65 6.74
6 LO 7.38 5.49 1.25 1.03 4.08 2.35
7 NONE 1.58 0.98 1.63 2.61
8 NONE 1.48 0.96 1.05 0.32
Table 2: Number of clicks used to complete the tasks.
Sit. Type Mean STDEV
1 DE 2.48 2.24
7 NONE -0.05 2.77
2 DE 2.55 3.62
8 NONE 0.43 1.04
Table 3: Gain as used for Hypothesis 2.
we do not want subjects to use semantic informa-
tion or their background knowledge of the domain.
Thirdly, real documents might not have the right
descriptions in them, so we would need to change
their sentences by hand.
5.2 Results and discussion
Forty subjects completed the experiment. Table
2 shows descriptive statistics for the number of
clicks subjects made to complete each task. To
analyse the results with respect to Hypothesis 1,
we used a General Linear Model (GLM ) with re-
peated measures. We used two repeated factors:
Situation (sit. 1 to 6) and Description Length
(short and long(FI/SL) ). We found a highly sig-
nificant effect of Description Length on the num-
ber of clicks used to complete the task (p<.001).
In all potential problematic situations the number
of clicks is smaller for the long than for the short
description. This confirms Hypothesis 1.
Table 3 shows descriptive statistics for the gain as
used for Hypothesis 2. We again used a GLM
with repeated measures, using two repeated fac-
tors: Descriptions Content (that of situations 1 and
7, and that of situations 2 and 8) and Situation
Type (potential DE and non-problematic). We
found a highly significant effect of Situation Type
on the gain (p<.001). In the non-problematic situ-
ations the gain is smaller than in the potential DE
situations. This confirms Hypothesis 2.
Table 4 shows descriptive statistics for the gain as
used for Hypothesis 3. We again used a GLM
Sit. FI Decision Mean STDEV
3 NOT COMPLETE 0.70 1.40
5 COMPLETE 4.50 6.67
4 NOT COMPLETE 0.23 2.51
6 COMPLETE 2.83 2.16
Table 4: Gain as used for Hypothesis 3.
with repeated measures, using two repeated fac-
tors: Descriptions Content (that of situations 3 and
5, and that of 4 and 6) and FI Decision (with 2
levels: complete and not complete). We found
a highly significant effect of FI Decision on the
gain (p<.001). The gain is smaller for situations
were our algorithm decided to use an incomplete
description than in situations were it chose a com-
plete description. This confirms Hypothesis 3.
6 Conclusion
We have discussed generation strategies that facil-
itate resolution of referring expressions by adding
logically redundant information to the descriptions
generated. Redundancy has a role to play in dif-
ferent kinds of situation (see Introduction for ref-
erences), but we have focussed on a class of cases
that we believe to be widespread, namely where
the domain is hierarchical. We have argued that,
in such situations, minimally distinguishing de-
scriptions can sometimes be useless. Various al-
gorithms for generating logically redundant ref-
erences have been implemented. The extensive
experiment of section 5 indicates that these algo-
rithms are fundamentally on the right track.
The new algorithms discussed in this paper are an
alternative to classical GRE algorithms. This raises
the question how one knows whether to use the
new FI or SL instead of one of its competitors?
Let us compare the predictions made by our al-
gorithms with those made by Dale and Haddock
(1991). Suppose their description ?the bowl on the
table? was said when there are two tables and two
61
bowls, while (only) the table furthest away from
the hearer has a bowl on it. In this situation, FI
and SL would generate something redundant like
the bowl on the far-away table. Which of the two
descriptions is best? We submit that it depends on
the situation: when all the relevant facts are avail-
able to the hearer without effort (e.g., all the do-
main objects are visible at a glance) then minimal
descriptions are fine. But in a huge room, where
it is not obvious to the hearer what is on each ta-
ble, search is required. It is this type of situation
that there is a need for the kind of ?studied? redun-
dancy embodied in FI and SL, because the min-
imally ?the bowl on the table? would not be very
helpful. The new algorithms are designed for situ-
ations where the hearer may have to make an effort
to uncover the relevant facts.
By focussing on the benefits for the reader (in
terms of the effort required for identifying the ref-
erent), we have not only substantiated the claims
in Paraboni and van Deemter (2002), to the effect
that it can be good to add logically redundant in-
formation to a referring expression; we have also
been able to shed light on the reason why redun-
dant descriptions are sometimes preferred (com-
pared with the experiment in Paraboni and van
Deemter (2002), which did not shed light on the
reason for this preference): we can now say with
some confidence that, in the circumstances speci-
fied, the generated redundant descriptions are re-
solved with particular ease. By counting the num-
ber of clicks that subjects need to find the referent,
we believe that we may have achieved a degree of
insight into the ?resolution? processes in the head
of the reader, not unlike the insights coming out
of the kind of eye-tracking experiments that have
been popular in psycholinguistics for a number of
years now. It would be interesting to see whether
our ideas can be confirmed using such a more en-
trenched experimental paradigm.
7 References
Arts, Anja. 2004. Overspecification in instructive
texts. PhD. Tilburg University, The Netherlands.
Wolf Publishers, Nijmegen.
Cremers, Anita. 1996. Reference to Objects;
an empirically based study of task-oriented dia-
logues. Ph.D. thesis, University of Eindhoven.
Dale, Robert and Nicholas Haddock. 1991. Gen-
erating Referring Expressions involving Relations.
EACL, Berlin, pp.161-166.
Dale, Robert and Ehud Reiter. 1995. Computa-
tional Interpretations of the Gricean Maxims in the
Generation of Referring Expressions. Cognitive
Science 18:pp.233-263.
Deutsch, W. 1976. ?Sprachliche Redundanz und
Objectidentifikation.? Unpublished PhD disserta-
tion, University of Marburg.
Edmonds, Philip G. 1994. Collaboration on ref-
erence to objects that are not mutually known.
COLING-1994, Kyoto, pp.1118-1122.
Krahmer, E. and Theune, M. 2002. Efficient
Context-Sensitive Generation of Referring Ex-
pressions. In K. van Deemter and R. Kibble (eds.)
Information Sharing. CSLI Publ., Stanford.
Horacek, Helmut. 2005. Generating referential
descriptions under conditions of uncertainty. 10th
European workshop on Natural Language Gener-
ation (ENLG-2005). Aberdeen, pp.58-67.
Jordan, Pamela W. 2000. Can Nominal Expres-
sions Achieve Multiple Goals?: An Empirical
Study. ACL-2000, Hong Kong.
Levelt, W.J.M. 1989. Speaking: From Intention to
Articulation. MIT Press, Cambridge.
Mangold, Roland. 1986. Sensorische Faktoren
beim Verstehen ueberspezifizierter Objektbenen-
nungen. Frankfurt: Peter Lang Verlag.
Paraboni, Ivandre. 2000. An algorithm for gen-
erating document-deictic references. INLG-2000
Workshop Coherence in Generated Multimedia,
Mitzpe Ramon, pp.27-31.
Paraboni, Ivandre and van Deemter, K. (2002).
Generating Easy References: the Case of Docu-
ment Deixis. INLG-2002, New York, pp.113-119.
Sonnenschein, Susan. 1984. The effect of redun-
dant communication on listeners: Why different
types may have different effects. Journal of Psy-
cholinguistic Research 13, pp.147-166.
van Deemter, Kees. 2004. Finetuning an NLG
system through experiments with human subjects:
the case of vague descriptions. INLG-04, Brock-
enhurst, UK, pp.31-40.
van der Sluis, I. 2005. Multimodal Reference,
Studies in Automatic Generation of Multimodal
Referring Expressions. Ph.D. thesis, Tilburg Uni-
versity, the Netherlands.
62
Proceedings of the 12th European Workshop on Natural Language Generation, pages 189?190,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
USP-EACH: Improved Frequency-based Greedy Attribute Selection 
 
 
Diego Jesus de Lucena 
University of S?o Paulo 
S?o Paulo - Brazil 
diego.si@usp.br 
Ivandr? Paraboni 
University of S?o Paulo 
S?o Paulo - Brazil 
ivandre@usp.br 
 
  
 
Abstract 
 
We present a follow-up of our previous fre-
quency-based greedy attribute selection strate-
gy. The current version takes into account also 
the instructions given to the participants of 
TUNA trials regarding the use of location in-
formation, showing an overall improvement 
on string-edit distance values driven by the re-
sults on the Furniture domain. 
1 Introduction 
In previous work (Lucena & Paraboni, 2008) we 
presented a frequency-based greedy attribute se-
lection strategy submitted to the TUNA Chal-
lenge 2008. Presently we further the issue  by 
taking additional information into account - 
namely, the trial condition information available 
from the TUNA data - and report improved re-
sults for string-edit distance as required for the 
2009 competition. 
2 Background 
In Lucena & Paraboni (2008) we presented a 
combined strategy based on attribute frequency 
and certain aspects of a greedy attribute selection 
strategy for referring expressions generation. A 
list P of attributes sorted by frequency is the cen-
tre piece of the following selection strategy: 
 
? select all attributes whose relative frequency 
falls above a threshold value t  (t was esti-
mated to be 0.8 for both Furniture and 
People domains.) 
? if the resulting description uniquely de-
scribes the target object, then finalizes.  
? if not, starting from the most frequent 
attribute in P, search exhaustively for an 
attribute g such that g, if selected, would rule 
out all remaining distractors in the context. 
 
The overall effect obtained is twofold: on the 
one hand, in a complex situation of reference (in 
which many attributes may rule out many dis-
tractors, but more than one will be required to 
achieve uniqueness) the algorithm simply selects 
frequent attributes. This may be comparable to a 
human speaker who has to single out the target 
object but who does not have the means to come 
up with the ?right? attribute straight away.  
On the other hand, as the number of distractors 
decreases, a single attribute capable of ruling out 
all distractors will eventually emerge, forcing the 
algorithm to switch to a greedy strategy and fi-
nalize. Once again, this may be comparable to 
what a human speaker may do when an appropri-
ate attribute becomes sufficiently salient and all 
distractors in the context can be ruled out at 
once. 
The above approach performed fairly well (at 
least considering its simplicity) as reported in 
Lucena & Paraboni (2008). However, there is 
one major source of information available from 
the TUNA data that was not taken into account 
in the above strategy: the trial condition 
represented by the +/- LOC feature. Because this 
feature distinguishes the very kinds of instruction 
given to each participant to complete the TUNA 
task, the information provided by -/+ LOC is 
likely to have a significant impact on the overall 
results. This clear gap in our previous work 
represents an opportunity for improvement dis-
cussed in the next section. 
3 Algorithm  
The present work is a refined version of the 
original frequency-based greedy attribute selec-
tion strategy submitted to the TUNA Challenge 
2008 (Lucena & Paraboni, 2008), now taking 
also the trial condition (+/-LOC) into account.  
189
 In the TUNA data, +LOC indicates the in-
stances of the experiment in which participants 
were told that they were allowed to refer to the 
X,Y coordinates of the screen (i.e., selecting the 
X- and/or Y-DIMENSION attributes), whereas 
-LOC indicates the trials in which they were dis-
couraged (but not prevented) to do so. In prac-
tice, references in +LOC trials are more likely to 
convey the X- and Y-DIMENSION attributes 
than those in which the -LOC condition was ap-
plied.  
Our modified algorithm simply consists of 
computing separated frequency lists for +LOC 
and -LOC trial conditions, and then using the 
original frequency-based greedy approach with 
each list accordingly. In practice, descriptions are 
now generated in two different ways, depending 
on the trial condition, which may promote the X- 
and Y-DIMENSION attributes to higher posi-
tions in the list P when +LOC applies. 
Using the TUNA Challenge 2009 develop-
ment data set, the attribute selection task was 
performed as above. For the surface realisation 
task, we have reused the English language sur-
face realisation module provided by Irene Lang-
kilde-Geary for the TUNA Challenge 2008.  
4 Results  
The following Figure 1 shows mean sting-edit 
distance and BLEU-3 scores computed using the 
evaluation tool provided by the TUNA Challenge 
team. For ease of comparison with our previous 
work, we also present Dice and MASI scores 
computed as in the previous TUNA Challenge, 
although these scores were not required for the 
current competition. 
 The most relevant comparison with our previ-
ous work is observed in the overall string-edit 
distance values in Figure 1: considering that in 
Lucena & Paraboni (2008) we reported 6.12 edit-
distance for Furniture and 7.38 for People, the 
overall improvement (driven by the descriptions 
in the Furniture domain) may be explained by the 
fact that the current version makes more accurate 
decisions as to when to use these attributes ac-
cording to the instructions given to the partici-
pants of the TUNA trials (the trial condition +/-
LOC. ) 
 On the other hand, the divide between +LOC 
and -LOC strategies does not have a significant 
effect on the results based on the semantics of 
the description (i.e., Dice and MASI scores), 
which remain the same as those obtained previ-
ously. This may be explained by the fact that us-
ing location information inappropriately counts 
as one single error in Dice/MASI calculations, 
but it may have a much greater impact on the 
wording of the surface string (e.g., one single use 
of the X-DIMENSION attribute may be realized 
as ?on the far left?, adding four words to the de-
scriptions.) 
 
 
 Overall Furniture People 
String-edit distance 6.03 4.78 7.50 
BLEU-3 0.19 0.31 0.04 
Dice 0.74 0.82 0.65 
MASI 0.53 0.63 0.41 
Figure 1. Results (TUNA Challenge 2009 development data set) 
 
 
5 Conclusion  
We have presented a refined version of our pre-
vious frequency-based greedy attribute selection 
strategy. The current version takes into account 
the instructions given to the participants of 
TUNA trials regarding the use of location infor-
mation (the trial condition +/-LOC.)  
 Results obtained using the TUNA Challenge 
2009 development data set show improvements 
on string-edit distance, suggesting that the gener-
ated descriptions resemble more closely those 
seen in the TUNA corpus. 
 
Acknowledgments 
This work has been supported by CNPq-Brazil 
(484015/2007-9) and FAPESP (2006/03941-7). 
References  
Lucena, Diego Jesus de, and Ivandr? Paraboni (2008) 
USP-EACH Frequency-based Greedy Attribute Se-
lection for Referring Expressions Generation. 
Proc. of INLG-2008 (TUNA Challenge 2008). Salt 
Fork, US, pp.219-220. 
190
Generating Referring Expressions:
Making Referents Easy to Identify
Ivandre? Paraboni?
EACH, University of Sa?o Paulo
Kees van Deemter??
Computing Science Department,
University of Aberdeen
Judith Masthoff?
Computing Science Department,
University of Aberdeen
It is often desirable that referring expressions be chosen in such a way that their referents are easy
to identify. This article focuses on referring expressions in hierarchically structured domains,
exploring the hypothesis that referring expressions can be improved by including logically
redundant information in them if this leads to a significant reduction in the amount of search
that is needed to identify the referent. Generation algorithms are presented that implement this
idea by including logically redundant information into the generated expression, in certain well-
circumscribed situations. To test our hypotheses, and to assess the performance of our algorithms,
two controlled experiments with human subjects were conducted. The first experiment confirms
that human judges have a preference for logically redundant expressions in the cases where our
model predicts this to be the case. The second experiment suggests that readers benefit from the
kind of logical redundancy that our algorithms produce, as measured in terms of the effort needed
to identify the referent of the expression.
1. Introduction
Common sense suggests that speakers and writers who want to get their message across
should make their utterances easy to understand. Broadly speaking, this view is con-
firmed by empirical research (Deutsch 1976; Mangold 1986; Levelt 1989; Sonnenschein
1982, 1984; Clark 1992; Cremers 1996; Arts 2004). The present article will examine its
consequences for the generation of referring expressions (GRE). In doing this, we dis-
tinguish between two aspects of the ?understanding? of a referring expression, which
we shall denote by the terms interpretation and resolution. We take interpretation to
be the process whereby a hearer/reader determines the meaning or logical form of the
? Av.Arlindo Bettio, 1000 - 03828-000, Sa?o Paulo, Brazil. E-mail: ivandre@usp.br.
?? King?s College, Meston building, Aberdeen AB24 3UE, Scotland, UK. E-mail: kvdeemte@csd.abdn.ac.uk.
? King?s College, Meston building, Aberdeen AB24 3UE, Scotland, UK. E-mail: jmasthoff@csd.abdn.ac.uk.
Submission received: 17 February 2004; revised submission received: 27 July 2006; accepted for publication:
7 December 2006.
? 2007 Association for Computational Linguistics
Computational Linguistics Volume 33, Number 2
referring expression; we take resolution to be the identification of the referent of the
expression once its meaning has been determined. It is resolution that will take center
stage in our investigation.
Difficulty of resolution and interpretation do not always go hand in hand. Consider
sentences (1a)?(1c), uttered somewhere in Brighton but not on Lewes Road. The de-
scription in (1a) is longer (and might take more time to read and interpret) than (1b), but
the additional material in (1a) makes resolution easier once interpretation is successfully
completed.
(1a) 968 Lewes Road, Moulsecoomb area
(1b) 968 Lewes Road
(1c) number 968
The first two of these descriptions refer uniquely. As for the third: Lewes Road is a long
street. Supposing that other streets in Brighton do not have numbers above 900, then
even (1c) is a unique description?but a pretty useless one, because it does not help you
to find the house unless your knowledge of Brighton is exceptional. We will explore how
a natural-language-generation (NLG) program should make use of logically redundant
properties so as to simplify resolution (i.e., the identification of the referent). When we
write about identifying or ?finding? the referent of a referring expression, we mean this
in the sense of determining which object is the intended referent. This conceptual goal
may or may not require the hearer to make a physical effort, for example by turning the
pages of a book, or more dramatically by walking and waiting for traffic lights.
The fact that referring expressions tend to contain logically redundant information
has been observed in many empirical studies. Levelt (1989), for example, mentions
the need for redundancy in situations of ?degraded communication? (e.g., background
noise); and even in normal situations, redundant nondiscriminating information can
help the addressee identify the referent (Deutsch 1976; Mangold 1986; Sonnenschein
1982, 1984; Arts 2004). In Levelt?s words, psycholinguistic experiments show that
[l]isteners apparently create a ?gestalt? of the object for which they have to search. It is
harder to search for ?something red? than for ?a big red bird?, even if the color would be
sufficiently discriminating. Information about the kind of object to be looked for (e.g., a
bird) is especially helpful for constructing such a gestalt. (Levelt 1989, page 131)
Although early GRE algorithms have often followed the Gricean maxim, ?be brief?
(Grice 1975), by minimizing the number of properties in a generated description, Dale
and Reiter (1995) proposed an algorithm that allows certain redundancies, for example,
by guaranteeing that each generated description expresses the ontological ?type? of the
referent, in the form of a noun, a move that addresses Levelt?s claim to some extent.1
In corpus-based studies, it has been shown that logically redundant properties tend
to be included when their inclusion fulfils one of a number of pragmatic functions,
such as to indicate that a property is of particular importance to the speaker (i.e., it
constitutes one of her reasons for being interested in the referent) or to highlight the
1 Dale and Reiter (1995, Section 5) also mention the use of ?navigational? (or ?attention-directing?)
information in referring expressions, which they distinguish from ?discrimination information,? and
whose function appears to be to move the attention of the reader/hearer towards an object. The concept
is not defined precisely and it is not clear how navigational information should be used in GRE.
230
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
speaker?s awareness that the referent has the property in question (Jordan 2000, 2002).
Implementations of such findings in NLG are not difficult to envisage.
The present article takes this reader-oriented perspective on the redundancy of
referring expressions a step further, by asking how a generator can use logically re-
dundant information to reduce the search space within which a reader has to ?find? a
referent; this will be specifically useful when referents need to be found in situations
where the extensions of some of the properties are not known to the reader/hearer
in advance (cf., Edmonds [1994] for a related set of problems) and where some effort
may be needed to identify the referent. By focusing on the information needs of the
hearer/reader, our work, a further development of Paraboni and van Deemter (2002a)
that also takes the results of Paraboni, Masthoff, and van Deemter (2006) into account,
addresses an issue that lies close to the heart of NLG as a practical enterprise, whose
purpose is, after all, to make information accessible to people. These issues originally
came to the fore while studying references to parts of documents (Paraboni 2000, 2003;
Paraboni and van Deemter 2002a, 2002b) but their relevance extends to many other
situations. Our findings will also shed light on the egocentricity debate among psy-
cholinguists about the extent to which speakers take hearer?s knowledge into account
when they speak (Keysar, Lin, and Barr 2003). Throughout the article, we shall focus
on issues of Content Determination (as opposed to, for example Lexical Choice), and
on the situations in which individuals are first mentioned (as opposed to ones in
which linguistic context allows them to be shortened [e.g., Krahmer and Theune 2002;
Siddharthan and Copestake 2004]).
2. Ease of Resolution in the Incremental Algorithm
Generation of referring expressions (GRE) is a key task of NLG systems (e.g., Reiter and
Dale 2000, Section 5.4). An important aspect of GRE is to find combinations of properties
that allow the generator to refer uniquely to an entity, called the target. Crucially, GRE
algorithms only use properties whose denotations are part of the common knowledge
of writer and reader.2 These algorithms are typically designed in such a way that gener-
ation is performed quickly (e.g., their worst-case running time tends to be linear [Dale
and Reiter 1995; van Deemter 2002]) but the processing effort of the reader is not taken
into account. Some algorithms do make a point of generating descriptions that are as
brief as possible (Dale 1989), and this can be argued to make interpretation easier. As we
have seen, however, in relation to Examples (1a?c), brevity can make resolution difficult.
For concreteness, let us focus on one of the best-known algorithms in this area. The
Incremental Algorithm (Dale and Reiter 1995) starts by arranging attributes in a list, af-
ter which they are considered one by one, to see if any of their values contributes some-
thing to the description, by removing ?distractors? (i.e., objects other than the referent);
if an attribute (e.g., COLOR) can contribute something, then a suitable value (e.g., RED)
for this attribute is selected as part of the description. This is repeated incrementally un-
til the logical conjunction of all selected attribute?value combinations results in a unique
identification of the referent. There is no backtracking, and this is what keeps the com-
plexity of the algorithm linear; it is also what causes the algorithm to sometimes express
a property P even when properties that are added later make P logically redundant.
2 A good example of a description failing this requirement occurs in Get off one stop before I do, in an
exchange between two people who have just met, as a description of where the hearer should get off the
bus (Appelt 1985, cited in Dale and Reiter 1995).
231
Computational Linguistics Volume 33, Number 2
Suppose a referring expression identifies its referent uniquely. Then at least two
things can stand in the way of finding its referent: the ?difficulty? of the individual
properties used in the description (i.e., the fact that it may be difficult to ascertain which
objects have the property in question [Horacek 2005]), or the size and structure of the
search space. To exemplify the first factor, suppose you are queuing up for a concert and
want to explain to a friend that a girl further ahead in the queue has his ticket. Color is
an attribute that speakers like to use, even if it leads to logical redundancy (Pechmann
1989). This might be done by describing the referent as the girl in a yellow dress, or as
the girl with green eyes, for example. But arguably, the first property contributes more
towards your friend?s search, because the color of a person?s eyes may not leap out
at him from afar. In the Incremental Algorithm, the fact that DRESS COLOR is more
useful than EYE COLOR could be tackled by letting it precede EYE COLOR in the list
of attributes. As a consequence, EYE COLOR would only be considered if the referent
cannot be identified uniquely without using a combination of more preferred attributes,
including DRESS COLOR. Arguably, this is exactly as it should be, and it shows much of
what is good about the Incremental Algorithm. It is not so obvious, however, how the
algorithm should deal with the second of the two possible obstacles to resolution: the
size and structure of the domain.
3. Problems for Resolution
In this section we shall introduce a class of domains (Section 3.1) and a class of problems
for resolution that can arise when objects in these domains are identified using a distin-
guishing description (Section 3.2). Section 4 will relate these problems to a simple model
of the resolution process and propose a remedy, which consists of generating logically
redundant descriptions (in two different ways). Sections 5 and 6 provide examples of
putting our ideas to the test: first, by investigating what kind of description is preferred
by subjects who are given the choice (Section 5); then, more elaborately, by investigating
the effect of redundant descriptions on readers (Section 6).
3.1 Hierarchical Domains
Existing work on GRE tends to focus on fairly simple domains, dominated by one-place
properties. When relations (i.e., two-place properties) are taken into account at all (e.g.,
Dale and Haddock 1991; Krahmer and Theune 2002), the motivating examples are kept
so small that it is reasonable to assume that speaker and hearer know all the relevant
facts in advance. Consequently, search is not much of an issue (i.e., resolution is easy):
The hearer can identify the referent by simply intersecting the denotations of the proper-
ties in the description, for example, intersecting the set of girls with the set of individuals
who wear a yellow dress (both in the domain). Although such simplifications permit
the study of many aspects of reference, other aspects come to the fore when larger, and
subtly structured, domains are considered.
Interesting questions arise, for example, when a large domain is hierarchically
ordered. For the purpose of this article, we consider a domain to be hierarchically
ordered if its inhabitants can be structured like a tree in which everything that belongs
to a given node n belongs to at most one of n?s children, and everything that belongs
to one of n?s children belongs to n. Examples include countries divided into provinces,
which, in turn, may be divided into regions, and so on; years into months, then into
weeks, and then into days; documents into chapters, then sections, then subsections;
232
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
buildings into floors, then rooms. Clearly, hierarchies are among our favorite ways of
structuring the world.3
A crucial question, in all such cases, is what knowledge is shared between speaker
and hearer at utterance time. Later on (most explicitly in Section 6), we shall focus on
more realistic situations but, to get the idea, it will be useful to think about the extreme
case where, before the start of resolution (i.e., before consulting the ?knowledge in the
world,? as opposed to the hearer?s ?knowledge in the head? [Norman 1988]), the hearer
knows nothing about the domain. When the utterance is made, the hearer?s blindfold is
removed, so to speak, and resolution can start. No similar assumption about the speaker
is made: We assume that the speaker knows everything about the domain, and that he
knows that the hearer can achieve the same knowledge. Many of our examples will
be drawn from a simple model of a University campus, structured into buildings and
rooms; the intended referent will often be a library located in one of the rooms. The
location of the library is not known to the hearer, but it is known to the speaker.
Each domain entity r will be associated with a TYPE (e.g., the type ?room?), and with
some additional attributes such as its ROOM NUMBER or NAME, and we will assume
that it is always possible to distinguish r from its siblings in the tree structure by
using one or more of these properties. (For example, ROOM NUMBER = 120 identifies
a room uniquely within a given building; BUILDINGNAME = Watts identifies a building
within the university.) This is a useful assumption, because without it, the existence of
a distinguishing description cannot be guaranteed.
The kinds of referring expression that we are interested in (see Section 5 for motiva-
tion) take the form of a list
L = ?(x1, P1), (x2, P2) . . . (xn, Pn)?
where x1 = r is the referent of the referring expression and, for every j > 1, xj is an
ancestor (not necessarily the parent) of xj?1 in the domain D. For every j, Pj is a set of
properties that jointly identify xj within xj+1 or, if j = n, within the whole domain. The
reference the library in room 120 of Cockcroft building, for example, is modeled as
L = ?(r, {type = library}), (x2, {type = room, roomnumber = 120}), (x3, {type =
building, buildingname = Cockcroft})?
3.2 Obstacles for Resolution
We have argued that generating a uniquely referring expression is not always enough,
because such an expression can leave the hearer with an unnecessarily large search
space. But the issue is an even starker one, especially?as we shall soon see?when
it is taken into account that references in hierarchically structured domains can make
use of the position of the speaker and hearer in the domain. (For simplicity, we assume
that these two locations coincide.)
Let us start with some informal observations, to be corroborated in Section 4. Sup-
pose a hierarchically ordered domain D contains only one entity whose TYPE is LIBRARY.
3 If everything that belongs to a given node n belongs to exactly one of n?s children, then nodes can be
thought of as being partitioned by its children. Note that this is not always the case. Not everything
on a given floor of a building, for example, has to be in a room (the corridors are not).
233
Computational Linguistics Volume 33, Number 2
Figure 1
A hierarchically structured domain; d is where the reference is uttered.
Consider the following noun phrases, uttered in the position marked by d in Figure 1.
(The first three have the same intended referent.)
(2a) the library, in room 120 in the Cockcroft building
(2b) the library, in room 120
(2c) the library
(2d) room 140
Utterances like Examples (2a) and (2b) make use of the hierarchical structure of the
domain.4 We focus on the search for xn (i.e., the highest hierarchical level referred to
in the description) because, under the assumptions that were just made (in particular
the fact that xj be identified uniquely in xj+1 by the properties Pj), this is the only place
where problems can be expected (because no parent node is available).
Even though each of Examples (2a)?(2d) succeeds in characterizing their intended
referent uniquely, some of these descriptions can be problematic for the hearer. One
type of problem occurs in Example (2d). The expression is logically sufficient (i.e., there
is only one room labeled 140 in the entire university). But, intuitively speaking, the ex-
pression creates an expectation that the referent may be found nearby, within the
Watts building, whereas, in fact, a match can only be found in another building. In a
case like this, we will speak of Lack of Orientation (LO). Even more confusion might
occur if another library was added to our example, for instance in Watts 110, whereas
the intended referent was the other library (i.e., in room 120 Cockcroft). In this case,
Example (2c) would misfire, of course. The expression (2b), however, would succeed, by
mutually using two parts of the description (the library and room 120) to identify another:
There are two libraries, and two rooms numbered 120, but there is only one pair (a, b)
such that a is a library and b is a room numbered 120, with a located in b. Such cases of
4 Recall that we focus on Content Determination, bypassing issues to do with lexical choice, linguistic
realization, and so on. For example, we shall not worry whether it is better to say (i) the library, in room
120, (ii) the library in room 120 (without a comma), or (iii) the library (room 120). The difference is not trivial,
because (ii), for example, might be viewed as having the unwanted implicature that there is more than
one library in the Watts building (Robert Dale, personal communication, August 2005.)
234
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
mutual identification5 are unproblematic in small, transparent, domains where search is
not an issue, but in large hierarchical domains, they are awkward (see the Conclusion).
For, like Example (2d), (2b) would force a reader to search through an unnecessarily
large part of the domain; worse even, the search ?path? that the reader is likely to follow
leads via an obstacle (namely, room 120 Watts) that matches a part of the description, al-
though not being the intended referent of the relevant part of the description (i.e., room
120 Cockcroft). Confusion could easily result. For even if the reader eventually finds the
library, she has no simple way of knowing whether it is the right one. (Perhaps a library
in Watts 120 has been overlooked.) In cases like this, we speak of a Dead End (DE).
Suppose the domain D is represented as a finite tree whose nodes have attributes
associated with them, one of which is the TYPE attribute. As before, we shall assume
that the attributes and values suffice to identify every node within its parent node.
Before defining LO and DE more precisely, we describe the related notions of SCOPE and
SCOPEGROUP, and the notion of a search path. We write x ? D to say that x is a node in
the tree D; if A is an attribute applicable to x then A(x) denotes the value of A for x.
Scope: Suppose x ? D, and A1, . . . , An are attributes associated with x.
Then SCOPE(x, {A1, . . .An}) is the largest subtree S of D such that x ? S
while, for every y, z ? S, the conjunction A1(y) = A1(z) & . . .& An(y) =
An(z) implies y = z.
SCOPE(x, {A1, . . .An}) is the largest subtree of D in which the values for the attributes
A1, . . . An jointly succeed in pinning down the referent. In practice, we shall usually
focus on situations where n = 1, in which case we shall write SCOPE(x, A1), omitting the
brackets. In our University domain, let x be room 140 of Cockcroft, then SCOPE(x, ROOM
NUMBER) is the subtree rooted in Cockcroft, because within Cockcroft, all room numbers
are unique, whereas at the level of the entire university (the next level up), this is not
the case (even though the room number 140 itself happens to be unique at that level).
The notion of SCOPE gives rise to the notion of SCOPEGROUP in a straightforward
way. Assuming, once again, that x ? D, and letting U stand for a set of attributes
associated with x, we define:
SCOPEGROUP(x, U) = {y ? D | y ? SCOPE(x, U) & TYPE(x) = TYPE(y)}
Thus, SCOPEGROUP (x, {A1, . . .An}) is the set of those elements of SCOPE(x, {A1, . . .
An}) that are of the same TYPE as x. Again, we shall focus on cases where n = 1, and
omit brackets. Thus, in the example domain, SCOPEGROUP(x,ROOM NUMBER), where x
is any room in Cockcroft, is the set of all the rooms in Cockcroft. TYPE is kept constant in
the definition of SCOPEGROUP because it tends to be the only non-structural attribute
that is used to identify domain objects (i.e., the only attribute that is not intended for
designating a node of the domain tree).6 Non-structural attributes will be assumed to
be unproblematic, operating like a filter on the set of possible referents. For example,
a reader of the description the library in room 110 will only be looking for libraries
(although they might be looking for them in the wrong building).
5 A well-known example is the description the bowl on the table, in a domain that contains several tables and
several bowls, but only one bowl on a table (Dale and Haddock 1991).
6 For example, we have seldom found descriptions like ?the section containing tables,? ?the italicized
section? in the PILs corpus (ABPI 1997).
235
Computational Linguistics Volume 33, Number 2
We are now in a position to define DE and LO more precisely, relative to a search
path. A search path is a series of steps in the search for a referent, representing
visits to nodes in the domain tree D. The path will be modeled by an ordered list
of visited nodes: O = ?n1, n2, . . . nm?. The node n1 is visited first, then n2, and so on,
until either the referent is found (success) or the reader gives up (failure). As before,
let L = ?(x1, P1), (x2, P2) . . . (xn, Pn)? model the semantic structure of the description, in
which xn is the entity of highest hierarchical level referred to in L. Furthermore, let
A1,. . . ,Aj be the set of all attributes in Pn. Then we predict problems for resolution
to occur if some y occurs prior to xn in O, for which TYPE(xn) = TYPE(y) and y 	?
SCOPEGROUP(xn, A1, . . .Aj). Calling such y an obstacle, there are two types of obstacle:
the obstacles for which all the properties in Pn are true (these are perhaps the worst
kind, because they can be mistaken for the intended referent), and the ones for which
this is not the case. If only obstacles of the latter kind arise then we will speak of
Lack of Orientation (LO). If there is at least one obstacle of the former, more serious
kind, we will speak of Dead End (DE). For example, in the case of the DE Exam-
ple (2b) (the library in room 120), the description itself can be modeled as the list L =
?(r, {type = library}), (x2, {type = room, roomnumber = 120})?, where Pn is the property
ROOM NUMBER = 120 and xn is the room where the library is. Suppose that the search
path for xn corresponds to the following sequence (because referents are always found
in leaf nodes, other nodes appear in brackets):
O = ?Watts100, (Watts, )Watts110, (Watts, )Watts120, (Watts, )(University, )
(Cockcroft, )Cockcroft100, (Cockcroft, )Cockcroft120?
Part of this sequence is the obstacle y = Watts 120, which is of the same TYPE as xn (i.e.,
both are rooms), and which does not belong to SCOPEGROUP(xn, ROOM NUMBER) (i.e.,
it does not belong to the Cockcroft building).
Because the property Pn (ROOM NUMBER = 120) is true of y, this constitutes a case
of DE. If the room Watts 120 is removed from the domain, there no longer exists an
obstacle of the most serious kind (because there is only one room whose room number
is 120), but rooms 100 and 110 in the Watts building are obstacles of the less serious kind,
making this an example of LO.
It seems likely that DEs and LO can disrupt search in sufficiently large or complex
domain structures. In principle, DE and LO could result even in the most unlikely
regions of the domain. Suppose the cup on the table is uttered in a room d, which
contains the intended referent. Now suppose (rather perversely perhaps) the hearer
started searching in another room, say the kitchen, before looking at the nearest table
(in d). If the kitchen happens to contain a table as well, and this table does not support
any cups, DE would result. Search, however, seems unlikely to proceed in this way.
To make testable predictions, we will make some assumptions concerning the way in
which referring expressions are resolved by hearers. To explain what these assumptions
are, let us return to the examples in Section 3, repeated here for convenience.
(2a) the library in room 120 in the Cockcroft building
(2b) the library in room 120
(2c) the library
(2d) room 140
236
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
We assume that these sentences are uttered in the University, say at the location d, and
that d determines the starting point of the search for a referent. Henceforth the starting
point s will be assumed to be the parent node of d. The intuition behind this assumption
is simple: When searching, start looking nearby.
It will often be useful to assume that resolution adheres to a principle that we will
call Ancestral Search. In formulating this principle, we will use d? as a name for the
referring expression (which, as we know, takes place at location d); we will use Ref(d?)
as short for the intended referent of d?.
Ancestral Search: First, search for Ref(d?) in the subtree dominated by the starting point
s. If Ref(d?) is not found there then search for Ref(d?) in the subtree dominated by the
parent of s, which is called s?. If Ref(d?) is not found there then move up to the parent s??
of s?,. . . , and so forth, until the root is reached. [If, at this point, Ref(d?) is still not found,
search fails.]
Ancestral Search (AS) says that the hearer of a referring expression searches exhaus-
tively through the current search space (e.g., the building in which the expression is
uttered, or the current document section containing the expression) before inspecting a
larger subtree. AS does not say how the search within each subtree (i.e., the one dominated
by s or s?) is carried out. We do not claim that readers always adhere exactly to AS,
especially not when they are confronted with unusual situations (as we shall see in our
second experiment). Rather, AS can be seen as an ?ideal model,? much like a straight line
could be seen as an ideal model of how a pedestrian walks from one point to another.
We shall see later that AS makes surprisingly accurate predictions in terms of what
references are found difficult by readers.
4. Generation Algorithms
What kinds of expression would existing GRE algorithms produce in the situations of
interest? Because hierarchies involve relations, the first algorithm that comes to mind
is the one proposed by Dale and Haddock (1991). Essentially, this algorithm combines
one- and two-place predicates, until a combination is found that pins down the target
referent. A standard example involves a domain containing two tables and two bowls,
although only one of the two tables has a bowl on it. In this situation, the combination
{bowl(x), on(x, y), table(y)} identifies x (and y as well), because only one value of x can
verify the three predicates, and this justifies the description the bowl on the table. Now
consider Figure 2, with one additional library in room 110 of the Watts building. Here
the combination {library(x), in(x, y), room(y), roomnumber(y) = 120} identifies x (and y
too), because no other library is located in a room with room number 120 (and no
other room numbered 120 contains a library). Thus, the standard approach to relational
descriptions allows precisely the kinds of situation that we have described as DE.
Henceforth, we shall describe this as the Minimal Description (MD) approach to refer-
ence because, in the situations of interest, it uses the minimum number of properties by
which the referent can be distinguished.
Another option would be to treat a relation like ?being in room 120? as a one-place
property of the library, and to use the Incremental Algorithm (Dale and Reiter 1995) to
generate the descriptions in question. This, however, would not produce results that are
interestingly different from MD. Suppose, for example, that the TYPE attribute is most
preferred (i.e., considered first by the algorithm), with values such as ?library?, ?room?,
and so on. Suppose, furthermore, that the attribute ROOM NUMBER is preferred over
237
Computational Linguistics Volume 33, Number 2
Figure 2
A university campus with two libraries in different buildings.
the attribute BUILDING NAME and, crucially, that a property such as ROOM NUMBER =
x is interpreted as true of all those objects in the university (regardless in which building)
that are located in something whose room number is x. Then the Incremental Algorithm
starts selecting TYPE = library, followed by ROOM NUMBER = 120, at which stage
a distinguishing description is reached. In other words, the same description would
be generated by this algorithm as by Dale and Haddock (1991) and, once, again, the
infamous LO and DE would occur. Choosing a preference order in which building
names are preferred over room numbers would produce the library in Cockcroft. Al-
though this description seems defensible in this case, it is easy to see that this preference
order would produce excessively lengthy descriptions in other situations. No single
preference order produces acceptable results in all cases.
We will now sketch two GRE algorithms, both of which are guaranteed to prevent
DE and LO if AS holds. (These algorithms will be investigated empirically in Sections 5
and 6.) They operate by reducing the reader?s search space, including logically redun-
dant information into the descriptions that they generate. These algorithms, called Full
Inclusion (FI) and Scope-Limited (SL), are not the only ways in which resolution may
be aided, but we will see that they represent two natural options. Both take as input a
hierarchical domain D, a location d where the referring expression will materialize, and
an intended referent r. The output is a list of properties L to be turned into an English
description by a language realization program.
The first algorithm, FI, represents a straightforward way of reducing the length
of search paths, without particular attention to LO or DE. It lines up properties that
identify the referent uniquely within its parent node, then moves up to identify this
parent node within its parent node, and so on until reaching a subtree that includes
the starting point d.7 FI may be likened to existing treatments of salience. In Krahmer
and Theune?s (2002) approach to GRE, for example, distractors that have lower salience
than the intended referent do not have to be removed. We apply this idea to hierarchical
domains using the assumption that from the point d where the utterance was made all
nodes within d?s parent node are as salient as d itself, while more ?distant? nodes are
gradually less salient. As in Krahmer and Theune, salience sometimes allows for shorter
7 ?Includes? is taken to be reflexive: a includes b iff a is an ancestor of b or a = b.
238
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
descriptions, as when room 110 replaces room 110 in Watts when said in Watts building
(but outside room 110).
Full Inclusion(r):
L := ?? { Initialize L as the empty list }
FI.Identify(r)
The function FI.Identify is defined recursively: (For simplicity, L does not contain the
individual referents x1,. . . ,xj, but only their properties.)
FI.Identify(X):
L := L + P, where P identifies X uniquely within Parent(X)
X := Parent(X)
IF X includes d THEN STOP ELSE FI.Identify(X)
Applied to our earlier example of a reference to room 120, FI first builds up the list L =
?(type = room, roomnumber = 120)?, then expands it to L = ?(type = room, roomnumber =
120), (buildingname = Cockcroft)?. Now that Parent(X) includes d , r has been identified
uniquely within D and we reach STOP. L might be realized as room 120 in Cockcroft, for
example.
FI gives maximal weight to ease of resolution. But something has to give, and that
is brevity: By conveying logically redundant information, descriptions are lengthened,
and this can have drawbacks, most evidently when there are limitations of space or
time. The second algorithm, called SL, constitutes a compromise between brevity and
ease of resolution. SL prevents DE and LO but opts for brevity when DE and LO do
not occur. Put differently, SL favors ease of resolution when there is a risk of DE or
LO, but ease of interpretation when there is no such risk. This is done by making use
of the notion of SCOPE, which was used in the definition of DE and LO. It may be
recalled that a description (x, P) in which P conveys attributes A1, . . . Aj leads to DE or
LO when its hearer comes across a node of the same type as x that is not a member
of SCOPEGROUP(x, {A1, . . .Aj}). It follows that when the hearer is searching within
SCOPE(x, {A1, . . .Aj}), the description (x, P), even if minimally distinguishing, cannot
lead to DE or LO. Consequently, (x, P) can be uttered in any position d within the subtree
denoted by SCOPE(x, {A1, . . .Aj}) with no risk of leading to DE or LO situations. In other
words, if SCOPE(x, {A1, . . .An}) contains d, and if A1, . . .An are the attributes conveyed
in a description (x, P), then this description does not lead to DE or LO. This allows SL to
use logically redundant properties more sparingly:
Scope-Limited(r):
L := ?? { Initialize L as the empty list }
SL.Identify(r)
SL.Identify(X):
L := L + P, where P identifies X uniquely within Parent(X)
239
Computational Linguistics Volume 33, Number 2
X := Root(Scope(X, {A1, . . . , Aj})), where A1, . . . , Aj are the attributes
associated with P
IF X includes d THEN STOP ELSE SL.Identify(X)
Whereas FI only terminates the generation of the description when a node that includes
d is reached, SL concludes potentially much earlier, when an attribute (or a combination
of attributes) is used that is guaranteed to identify all objects of the relevant type
uniquely throughout a tree that includes d. By taking scope into account, SL avoids
the inclusion of any hierarchical levels not strictly required for preventing DE and LO.
Consider a description uttered in the position d = room 100 of Watts, with r =
room 140 (in Cockcroft) as the intended referent. Existing GRE approaches such as Dale
and Reiter (1995) would tend to produce a minimally distinguishing description such
as room 140, causing LO. SL, by contrast, would produce the description room 140 in
Cockcroft,8 which in this case is the same description produced by FI. The difference
between FI and SL becomes evident when we consider a case in which the minimally
distinguishing description does not lead to DE/LO?that is, when AS predicts that
the reader will meet no DE or LO obstacles. For example, let?s return to the situation
depicted in Figure 1, from Section 3.1, where there is only one library in the whole
university. A reference to r = library would be realized by FI as the library in room 120 in
Cockcroft. By using SL, however, the same description would be realized simply as the
library, because the SCOPE of the attribute TYPE is the whole domain tree [more precisely,
SCOPE(LIBRARY,ROOM NUMBER)= D] because there is only one entity of TYPE ?library?
in the domain and hence no other properties are added. Note that the addition of a
second library in the Watts building would reduce SCOPE(r,TYPE) to the subtree rooted
in the ?building? node (i.e., each library would be defined by the building to which it
belongs). The behavior of the SL algorithm would change accordingly, producing the
library in Cockcroft. Similarly, had we instead included the second library under another
room of Cockcroft, the SCOPE would have been reduced even further, causing SL to
describe r as the library in room 120 of Cockcroft, just like the FI algorithm.
5. First Experiment: Measuring Reader?s Preferences
In this section we start putting the intuition that LO and DE are better avoided to the
test. We report on a small experiment with human subjects, which involved a document
structured in sections and subsections as an example of a hierarchically ordered domain.
We chose this domain because, unlike most other domains, it allows us to show subjects
the domain itself (i.e., a real document), rather than, for example, a pictorial represen-
tation of it. More specifically, we investigated the choice of so-called document-deictic
references, such as the picture in part x of section y (Paraboni 2003), to check whether
they avoid potential DE and LO situations by adding logically redundant properties
(favoring ease of resolution) and, conversely, whether they choose shorter descriptions
when there is no such risk (favoring ease of interpretation).
8 The reason is that Root(Scope(r,ROOM NUMBER)) = Cockcroft, which does not include d. This causes the
algorithm to have to identify the Cockcroft building before the algorithm stops.
240
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
5.1 Experiment Design
Subjects. 15 academics with considerable practice in the authoring of papers on compu-
tational linguistics.
Procedure. A within-subjects design was used. All subjects were shown a printed doc-
ument containing 18 incomplete statements. Subjects were asked to put themselves in
the shoes of the author and to choose the description that they found more suitable for
each situation:
Suppose you and a colleague are currently collaborating on this document. Fortunately
he/she did almost all the work for you, and now all that you have to do is complete
certain parts of the existing text [. . . ]
Subjects completed the statements by choosing one of two alternatives provided: one
?minimally distinguishing? description and the other conveying logical redundancy
(corresponding to the output of the FI or SL algorithms). Both alternatives are un-
ambiguous references to the same object. Figure 3 shows a number of descriptions
of this kind (whose intended referents are elsewhere in the document) and objects
(referred to by descriptions elsewhere). Statement 11 gives a choice between a logically
redundant description as generated by FI or SL (Part C of Section 2) and its minimally
distinguishing alternative Part C. Both alternatives are unambiguous because there is
only one part labeled as ?C? in the document, but the shorter one may potentially lead
to LO because the current document section does not contain a part labeled as ?C?.
Similarly, Statement 12 gives a choice between a minimally distinguishing description
as generated by MD or SL, and a logically redundant alternative as generated by
FI, but in this case none of the alternatives can lead to DE or LO because there is
only one ?table 2? in the entire document. The presentational order of alternatives
Figure 3
Fragment of the document used in the experiment.
241
Computational Linguistics Volume 33, Number 2
Table 1
Situations of reference for Experiment 1.
Sit. Type Reader Loc. Referent Loc. MD Redundant
2 DE Part A Sec 1 Part B Sec 3 Pic 2 in Part B Pic 2 in Part B Sec 3
9 DE Part C Sec 2 Part B Sec 3 Pic 3 in Part B Pic 3 in Part B Sec 3
13 DE Part B Sec 3 Part A Sec 2 Pic 4 in Part A Pic 4 in Part A Sec 2
15 DE Part B Sec 3 Part A Sec 2 Pic 3 in Part A Pic 3 in Part A Sec 2
5 LO Part B Sec 1 Part A Sec 2 Pic 5 Pic 5 in Part A Sec 2
7 LO Part B Sec 1 Part C Sec 2 Part C Part C Sec 2
11 LO Part A Sec 3 Part C Sec 2 Part C Part C Sec 2
16 LO Part B Sec 3 Part A Sec 2 Pic 6 Pic 6 in Part A Sec 2
4 NONE Part A Sec 1 Part B Sec 3 Table 6 Table 6 in Part B Sec 3
10 NONE Part C Sec 2 Part A Sec 3 Table 5 Table 5 in Part A Sec 3
12 NONE Part A Sec 3 Part B Sec 2 Table 2 Table 2 in Part B Sec 2
18 NONE Part B Sec 3 Part A Sec 1 Table 1 Table 1 in Part A Sec 1
(i.e., short versus redundant descriptions) was evenly distributed, to control for order
effects.
Research questions. We were interested in seeing whether readers prefer longer (i.e.,
logically redundant) descriptions when there is a risk of DE or LO and, conversely,
whether they prefer minimally distinguishing descriptions when there is no such risk.
Table 1 shows the type of situation (potential DE, LO, and non-problematic), the reader
and referent location, and the descriptions used. To break the monotony of the task
and to disguise the purpose of the experiment, another six situations were used that
were not relevant to the experiment. Half of the situations, in each of the types,
involved backward references, the other half involved forward references. Pictures were
enumerated per part so that we could compare short and long versions of potentially
problematic descriptions (e.g., Picture 5 in which the intended referent is not in the
current document part, which may or may not contain other pictures). Within the LO
situations, two of the four statements involved references to pictures, whereas the other
two involved references to sections. This was done in order to test whether the type of
referent had any influence on the choices made by the subjects. All the questions related
to potential DE situations involved references to pictures, because using DE references
to sections would have led to highly artificial structures.
Hypothesis 1.1: In a problematic DE situation, descriptions generated by FI or SL are
preferred over minimally distinguishing (MD) descriptions.
We will use the DE situations in Table 1 to test this hypothesis, investigating how often
subjects prefer FI/SL descriptions to MD ones.
Hypothesis 1.2: In a problematic LO situation, descriptions generated by FI or SL are
preferred over minimally distinguishing (MD) descriptions.
We will use the LO situations in Table 1 to test this hypothesis, investigating how often
subjects prefer FI/SL descriptions to MD ones. Note that in problematic situations, SL
generates the same descriptions as FI.
242
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
We also wanted to investigate whether subjects would prefer descriptions gen-
erated by FI or SL in non-problematic situations (i.e., those not involving potential
DE or LO). We did not use pictures as we did in the problematic cases because in
these cases both FI and SL would produce the same descriptions (e.g., Picture 5).9
In order to compare these algorithms in non-problematic situations we used tables
enumerated throughout the document, in which case descriptions produced by SL are
short (e.g., Table 5) and descriptions produced by FI are longer (e.g., Table 5 in Part C of
Section 2).
Hypothesis 1.3: In a non-problematic situation (i.e., a situation not involving DE or
LO), SL or MD descriptions are preferred over those generated by FI.
We will use the non-problematic situations in Table 1 to test this hypothesis, investigat-
ing how often subjects prefer FI descriptions to MD/SL ones. Note that in these non-
problematic situations, SL generates the same descriptions as MD.
Hypotheses 1.1 and 1.2 investigate whether ease of resolution (as in logically re-
dundant descriptions generated by FI or SL) is favored over ease of interpretation (as
in minimally distinguishing descriptions) when the description may lead to DE or LO.
Hypothesis 1.3 investigates whether ease of interpretation (as in MD or SL descriptions)
is favored over ease of resolution (as in descriptions generated by FI) when the former
does not lead to DE or LO situations.
Materials. DEs and LO can only occur in fairly complex domains. Instead of trying to
find a large number of such documents, we made use of a specially designed schematic
document. The document was presented in a printed version (3 pages long), divided
into sections (1?3) and subsections (?A? and ?B?); Section 2 contained also a subsection
labelled ?C?.10
References to pictures can be realized in many different ways. For example, the
referent can be called Picture or Figure or just Fig.; the reference can be constructed from
the bottom up (Picture 3 in Section 4) or from the top downwards (Section 4, Picture 3);
punctuation varies as well, as does the use of capitals. In our experiments, we have
made one fairly arbitrary choice from among all these possibilities, motivated by the
types of reference that we observed most frequently in an informal study of a collection
of patient information leaflets from the PILs corpus (ABPI 1997): We always used the
word Picture, we constructed the references bottom up (going up one level at a time),
and never used commas or semicolons. Thus, for example, we asked subjects to compare
Picture 3 in Part B of Section 3 with Picture 3 in Part B.11 Even though it is possible that a
different realization choice would produce different experimental outcomes, this does
not seem likely.
Every description d and its referent r were always on different pages. Had d and r
occurred on the same page then physical proximity might have obscured navigational
9 In the second experiment reported in Section 6 this was no longer an issue as we focus on ease of
resolution only, that is, it did not compare FI with SL.
10 See Paraboni (2003), appendix 1, for the actual document.
11 To get a feeling for the frequency of the expressions involved, one might enter ?picture OR figure OR fig
1. . . 9 in part OR section 1. . . 9? into Google, using Advanced Search. In July 2006, this produced as many as
77, 000 hits, the great majority of which are of the intended kind. (Because Advanced Search disregards
punctuation and capitalization, this includes a very small percentage of false positives, for example of the
form ?Figure x. In section y . . . ?.) The materials of our second experiment (Section 6) were essentially the
same as the present ones, except for the use of capitals.
243
Computational Linguistics Volume 33, Number 2
issues, causing a bias towards the shortest alternative. Reference d and referent r were
always in document parts whose layout properties differed from each other (e.g., not
both in subsections labeled as ?C? in different sections of the document). Had d and r
occurred in document parts with similar layout properties, there might have been a bias
towards the most complete (i.e., the longest) description.
5.2 Results
Hypotheses 1.1 and 1.2 were confirmed; hypothesis 1.3 was not. In fact, DE was
avoided in 100% of all subjects? decisions. In situations involving LO, the FI version
was chosen on average in 93% of cases (stdev = 15%), which is highly significant
(Wilcoxon signed ranks test, Z = ?3.56, p < .0001). In the cases not involving DE or
LO, there was no significant preference for or against logical redundancy (Wilcoxon
signed ranks test Z = ?0.51, p = .61). The trend is in the predicted direction (mean
of 57% for MD descriptions), but the variation between subjects was very large
(stdev = 41%).
5.3 Discussion of First Experiment
This first experiment supported the hypothesis that subjects prefer references that
include logically redundant information where there is a risk of DE/LO. Arguably,
it is precisely this kind of information that is needed for the construction of NLG
algorithms. Where logically redundant information does not make the referent easier
to identify, the results of the experiment are less clear, with the subjects being divided
between logically minimal and logically redundant descriptions. In other words, while
supporting the informal observations reported in Sections 2 and 3, the experiment
does not point to a generic preference of one of the two GRE algorithms presented in
Section 4.
Evidently, there are many factors that this experiment did not address, such as
the ?distance? between objects. For example, if tables are enumerated throughout the
document, is the brief, SL-type description Table 5 easy enough to resolve? It depends:
If there are tables on virtually every page then resolution is easy, because the table
numbers support browsing not unlike page numbers; if tables are sparse, however,
then searching through the entire document may take unacceptably long, and a more
redundant, FI-type description such as Table 5 in Section 4.3 is likely to be preferred. The
nature of the domain is bound to matter as well. For example, in a large spatial domain
in which navigation requires physical effort, short, SL-style descriptions are probably
less acceptable than in a situation where the domain can be surveyed at a glance. To
exemplify the first type of situation, let us return briefly to Examples (1a)?(1c), assuming
that a city is divided into areas, and an area into streets:
(1a) 968 Lewes Road, Moulsecoomb area (FI-style)
(1b) 968 Lewes Road (SL-style)
(1c) number 968 (MD-style)
If these are uttered somewhere in Brighton but not on Lewes Road then AS predicts
that utterance (1c) leads to LO, because the hearer will start looking for a number 968 in
the street where the description is uttered. Consequently, utterance (1c) is infelicitous
244
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
anywhere except on Lewes Road. But how about Examples (1a) and (1b)? Both descrip-
tions avoid LO and DE, because Brighton has only one Lewes Road. Yet if the hearer
does not know that Lewes Road is in Moulsecoomb, then the resolution of Example (1b)
may involve more work than Example (1a).
This experiment attempted to find out what types of references are favored by
human judges when their opinion about these references is asked. Although this has the
advantage that subjects were in a position to make trade-offs between the advantages
and disadvantages of the different expressions (perhaps balancing ease of interpreta-
tion with ease of resolution), the method is limited in other respects. One limitation
arises from the fact that meta-linguistic judgments are sometimes thought to be an
unreliable predictor of people?s linguistic behavior (e.g., van Deemter 2004). Perhaps
more seriously, the experiment fails to tell us how difficult a given type of reference (for
example, one of the DE type) would actually be for a reader, and whether the difficulty
is a matter of interpretation or resolution. For these reasons, we decided to perform
another experiment.
6. Second Experiment: Measuring Search Effort
In the previous experiment, we found that human authors often prefer logically redun-
dant references, particularly when DE and LO can arise. In a follow-up experiment,
we investigate the effect of logical redundancy on the performance of readers. We
are primarily interested in understanding the search process, so resolution rather than
interpretation. It will become clear that the new experiment necessitates a more careful
design and a more complex analysis than the previous one.
6.1 Experiment Design
Subjects. Forty-two students on a first-year Computing Science course participated in
the experiment as part of a scheduled practical.
Procedure. A within-subjects design was used. All subjects were shown 20 on-line
documents. The order of the documents was randomized per subject, to control for
order effects. The document structure was always visible, and so was the content of
the current document part. A screenshot of an example document providing this level
of information is shown in Figure 4. Each document was initially opened in Part B
of either Section 2 or 3, where a task was given of the form ?Let?s talk about [topic].
Please click on [referring expression];? for instance: Let?s talk about elephants. Please click
on picture 5 in part A. Subjects could navigate through the document by clicking on the
names of the parts (e.g. Part A as visible under Section 3). As soon as the subject had
correctly clicked on the picture indicated, the next document was presented. Subjects
were reminded throughout the document about the task to be accomplished, and the
location at which the task was given. All navigation actions were recorded. At the start
of the experiment, subjects were instructed to try to accomplish the task with a minimal
number of navigation actions.
Reader?s Knowledge. We assume that readers do not have complete knowledge of the
domain. So, they do not know which pictures are present in each part of each section.
If readers had complete knowledge, then a minimal description would suffice: For
example, if readers knew that there is only one picture 5 in the document, located in
245
Computational Linguistics Volume 33, Number 2
Figure 4
Fragment of the experiment interface.
part B of section 3, then the description picture 5 would probably be completely clear.
We do not, however, assume readers to be completely ignorant, either. We assume that
they have some knowledge of the domain, particularly of its hierarchical structure. This
brings us to the question of how much knowledge we should assume our readers to
have. In practice (unlike Section 3.1, where the hearer was pictured as blindfolded until
the description is uttered) readers will always have some knowledge: If in Part B of
Section 2, then they would know (by convention) that there will also be a Section 1, and
a Part A in Section 2, and so on. It is also likely that being in Part B of Section 2 and
seeing pictures 1, 2, 3, readers will infer that sections can have parts, that parts can
contain pictures, and that pictures are numbered (though not necessarily per part).
Because of these kinds of consideration, it seems appropriate to give our readers
knowledge about the entire document structure (the 5 sections and their parts) and
the content (i.e., the existing pictures) in the current document part (but crucially, no
knowledge about pictures elsewhere in the document, which require navigation to be
discovered). A navigation structure like the one in Figure 4 provides this knowledge to
the readers.
Research Questions. We want to test whether longer descriptions indeed help resolution,
particularly in so-called problematic situations. Table 2 shows the types of situation
(potential DE, LO, and non-problematic),12 reader and referent location, and descrip-
tions used.
Hypothesis 2.1: In a problematic (DE/LO) situation, the number of navigation actions
required for a long (FI/SL) description is smaller than that required for a short (MD)
description.
12 In DE situations, there is another picture with the same number as the referent, but not in a part with the
same name as the part in which the referent is. In LO situations, there is no other picture with the same
number as the referent, and the reader location contains pictures. In non-problematic situations, there is
another picture with the same number as the referent, but not in a part with the same name as the part in
which the referent is.
246
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
Table 2
Situations of reference for Experiment 2.
Sit. Type Reader Loc. Referent Loc. Short (MD) Long (FI/SL) Long (other)
1 DE Part B Part A Pic 3 in Pic 3 in Part A
Sec 3 Sec 2 Part A Sec 2
2 DE Part B Part C Pic 4 in Pic 4 in Part C
Sec 2 Sec 3 Part C Sec 3
3 LO Part B Part A Pic 5 Pic 5 in Part A Pic 5 in Part A
Sec 3 Sec 3 Sec 3
4 LO Part B Part C Pic 4 Pic 4 in Part C Pic 4 in Part C
Sec 2 Sec 2 Sec 2
5 LO Part B Part A Pic 5 Pic 5 in Part A Pic 5 in Part A
Sec 3 Sec 4 Sec 4
6 LO Part B Part C Pic 4 Pic 4 in Part C Pic 4 in Part C
Sec 2 Sec 1 Sec 1
7 NONE Part B Part A Pic 3 in Pic 3 in Part A
Sec 2 Sec 2 Part A Sec 2
8 NONE Part B Part C Pic 4 in Pic 4 in Part C
Sec 3 Sec 3 Part C Sec 3
This hypothesis is similar to hypotheses 1.1 and 1.2 of the previous experiment. We
will use the DE and LO situations in Table 2 to test this hypothesis, comparing for each
situation the number of navigation actions of the short, that is, minimally distinguishing
(MD) and long (FI/SL) expressions.
In the previous experiment, we had an additional hypothesis about non-
problematic situations, stating that MD descriptions would be preferred to long de-
scriptions in non-problematic situations. This is not a natural hypothesis in the new
experiment, because it might not happen very often that a shorter description will lead
to fewer navigation actions (pace Cremers 1996). (Note that in the previous experiment
we looked at the combination of interpretation and resolution, whereas we are now
focusing on resolution only). Instead, we will look at gain: the number of navigation
actions required for a short description minus the number of navigation actions required
for a long description.
For situation s, short description sd of s, and long description ld of s, Gain(s, sd, ld) = the
number of navigation actions required in s for description sd minus the number of
navigation actions required in s for description ld.
Hypothesis 2.2: The gain achieved by a long description over an MD description will
be larger in a problematic situation than in a non-problematic situation, that is, for
problematic situation ps, non-problematic situation nps, MD description md of both ps
and nps, and long description ld of ps and nps: Gain(ps, md, ld) > Gain(nps, md, ld).
We will use the DE and non-problematic situations in Table 2 to test this hypothesis,
comparing the gain of situation 1 with that of situation 7, and the gain of situation 2
with that of situation 8.
Longer descriptions may always lead to fewer navigation actions, and it can be
expected that complete descriptions of the form picture x in part y of section z will
outperform shorter descriptions in any situation. So, from a resolution point of view,
an algorithm that would always give a complete description may produce better results
247
Computational Linguistics Volume 33, Number 2
than the algorithms we proposed (e.g., situations 3 and 4 in Table 2). The aim of our
algorithms is to make the descriptions complete enough to prevent DE and LO in
resolution, but not overly redundant as this may affect interpretation. We would like
to show that the decisions taken by FI and SL are sensible, that is, that they produce
descriptions that are neither too short nor too long. Therefore:
S1: We want to consider situations in which FI and SL have produced an incomplete
description, and investigate how much gain could have been made by using a complete
description in those cases. We would like this gain to be negligible. We will use
situations 3 and 4 for this, calculating the gain of the long, complete descriptions
(namely, long (other) in Table 2) over the shorter, incomplete descriptions generated by
our algorithms (long (FI/SL) in Table 2).
S2: We want to consider situations in which FI and SL have produced a complete
description, and investigate how much gain has been made by using this compared to a
less complete description that is still more complete than MD. We would like this gain
to be large. We will use situations 5 and 6 for this, calculating the gain of the long
complete descriptions generated by our algorithms (long (FI/SL) in Table 2) over the
less complete descriptions (long (other)).
Introducing separate hypotheses for cases S1 and S2 poses the problem of defining
when a gain is ?negligible? and when a gain is ?large.? Instead, we will compare the
gain achieved in S1 with the gain achieved in S2, expecting that the gain in S2 (which we
believe to be large) will be larger than the gain in S1 (which we believe to be negligible).
Hypothesis 2.3: The gain of a complete description over a less complete one will be
larger for situations in which FI and SL generated the complete one, than for situations
in which they generated the less complete one. More formally, for situations S1 and S2,
descriptions cd and ld, with cd a complete description of S1 and S2 that has been
generated by FI and SL for S2, and with ld an incomplete but longer-than-MD
description of S1 and S2 that has been generated by FI and SL for S1:
Gain(S1, ld, cd) < Gain(S2, ld, cd).
Materials. Twenty on-line documents were produced,13 with the same document struc-
ture (sections 1 to 5 with parts A to C) and containing 10 pictures. Documents had
a unique background color, title, and pictures appropriate for the title. The number
of pictures in a section or part varied per document. All of this was done to prevent
subjects relying on memory. For instance, if we had used the same document for all
tasks, subjects might have remembered where a particular picture was located. If we had
used documents that looked similar, subjects might have assumed that they were the
same. If we had kept the distribution of images the same, subjects might have learned
that a particular part always contained many pictures.
Controlled experiments have advantages and disadvantages. Instead of using arti-
ficial, hand-crafted materials, we could have used real-world documents, like patient
information leaflets, in order to make the tasks as realistic as possible. However, it
would have been extremely difficult to find real-world documents that contain the
right phenomena in a well-balanced way. Firstly, real documents might not have the
right descriptions in them, so we would probably have needed to change sentences
in the documents by hand. Secondly, we need a set of documents that are sufficiently
13 http://www.csd.abdn.ac.uk/?jmasthof/RefStudy/Intro.php.
248
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
Table 3
Number of clicks used to complete the tasks.
Short Long (FI/SL) Long (Other)
Sit. Type Mean STDEV Mean STDEV Mean STDEV
1 DE 3.58 2.14 1.10 0.50
2 DE 3.85 3.28 1.30 1.31
3 LO 5.60 4.84 1.93 1.29 1.23 1.27
4 LO 2.50 1.97 1.60 1.28 1.38 2.07
5 LO 8.53 4.15 1.15 0.53 5.65 6.74
6 LO 7.38 5.49 1.25 1.03 4.08 2.35
7 NONE 1.58 0.98 1.63 2.61
8 NONE 1.48 0.96 1.05 0.32
similar in structure that one can make a fair comparison between longer and shorter
descriptions. Moreover, the structure should not allow subjects to learn where in the
document pictures are most likely to be located. Thirdly, semantic information or their
background knowledge of the domain should be irrelevant. (For example, if we were
using a real document on animals, and subjects read a section on lions, then they might
expect a picture of a tiger to be in a nearby section, and a picture of an elephant to be
closer than a picture of a pigeon.)
6.2 Results
Forty subjects completed the experiment. Table 3 shows descriptive statistics for the
number of clicks subjects made to complete each task. To analyze the results with respect
to Hypothesis 2.1, we used a General Linear Model (GLM) with repeated measures. We
used two repeated factors: Situation (situations 1 to 6) and Description Length (short
and long(FI/SL) ). We found a highly significant effect of Description Length on the
number of clicks used to complete the task (F1,39 = 262.46, p < .001, ?2p = .87). In all
potentially problematic situations, the number of clicks is smaller for the long than for
the short description. This confirms Hypothesis 2.1. We also found significant effects
of Situation (F5,35 = 13.11, p < .001, ?2p = .65), and of the interaction between Situation
and Description Length (F5,35 = 18.02, p < .001, ?2p = .72).
Table 4 shows descriptive statistics for the gain as used for Hypothesis 2.2. We again
used a GLM with repeated measures, using two repeated factors: Description Content
(that of situations 1 and 7, and that of situations 2 and 8) and Situation Type (potential
DE and non-problematic).14 We found a highly significant effect of Situation Type on
the gain (F1,39 = 26.62, p < .001, ?2p = .41). In the non-problematic situations the gain is
smaller than in the potential DE situations. This confirms Hypothesis 2.2.
Table 5 shows descriptive statistics for the gain as used for Hypothesis 2.3. We again
used a GLM with repeated measures, using two repeated factors: Description Content
(that of situations 3 and 5, and that of situations 4 and 6) and FI Decision (with 2 levels:
14 There were no significant effects of Description Content and of the interaction between Description
Content and Situation Type. From here on, we will focus on effects that were significant.
249
Computational Linguistics Volume 33, Number 2
Table 4
Gain as used for Hypothesis 2.2.
Sit. Type Mean STDEV
1 DE 2.48 2.24
7 NONE ?0.05 2.77
2 DE 2.55 3.62
8 NONE 0.43 1.04
complete and not complete). We found a highly significant effect of FI Decision on
the gain (F1,39 = 24.10, p < .001, ?2p = .38). The gain is smaller for situations where our
algorithm decided to use an incomplete description than in situations where it chose a
complete one. This confirms Hypothesis 2.3.
6.3 Discussion of Second Experiment
What does the second experiment teach us, over and above what we learned from the
first one? First of all, the experiment suggests an explanation of why it was that, in
problematic situations, subjects (in the first experiment) preferred redundant descrip-
tions: The new experiment suggests that the reason may lie in the fact that, in the
potentially problematic situations, the addition of structural information reduces the
effort involved in resolution. This is, of course, exactly in line with the way in which
DE and LO were introduced in Section 3, and with the assumptions about ease of
resolution that were formulated in Paraboni and Van Deemter (2002a) and in the present
Section 2.
Do our experiments, taken together, tell us how much redundancy is optimal in any
given situation? In answering this question, let us first realize that pragmatic factors
relating to the utterance situation are likely to affect how much redundancy is needed.
At one end of the spectrum, there may be highly fault-critical settings, where flawless
understanding is essential; at the other end, there may be discourse settings where
accurate understanding is not important, and where the speaker/writer is under time
pressure. Surely, redundant information must be more common in the former than in
the latter. No one algorithm can cater to all types of settings.
On the other hand, our data do suggest quite strongly that, at least in the situation in
which our subjects found themselves, a law of diminishing returns is in operation. To see
this, let us first focus on the two non-problematic situations (Table 2): Averaging numbers
Table 5
Gain as used for Hypothesis 2.3.
Sit. FI Decision Mean STDEV
3 NOT COMPLETE 0.70 1.40
5 COMPLETE 4.50 6.67
4 NOT COMPLETE 0.23 2.51
6 COMPLETE 2.83 2.16
250
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
of clicks of all subjects over all relevant situations, short descriptions required a mere
1.53 clicks; by adding redundant information (unlike SL/FI), this number gets reduced
to an average of 1.34 clicks (long(other), in situations 7 and 8). This very slight gain
(0.19 clicks) is not statistically significant (F1,39 = .60, p = .44, ?2p = .02) and is bought at
the price of a description that is one and a half times longer, which makes it likely to
take more time during interpretation. As for the more interesting problematic situations,
perhaps the best comparison is between situations 3 and 4 (where long(other) exists and
is longer than long(FI/SL)). Here, short descriptions lead to a pretty dismal average
of 4.05 clicks. If we lengthen the descriptions as prescribed by FI/SL (long(FI/SL))
then this figure is lowered drastically to what looks like a pretty acceptable 1.77 clicks,
which constitutes a gain of 2.28. By adding even more information (as in long(other)),
the figure is lowered further, to 1.31 clicks. Although this does represent a gain, it is
not statistically significant (F1,39 = 2.94, p = .095, ?2p = .07), and besides it is so small
(at 0.46 clicks) that it seems likely to be more than offset by the disadvantages for
interpretation that are implied by the increased length of the description. Needless to say,
these effects can only become stronger if more complex documents are considered, and
with descriptions that are even longer. Really excessive redundancy might have detri-
mental effects on resolution as well as interpretation, because it confuses hearers. (A
hearer might wonder, along Gricean lines, ?Why are they saying ?Picture 5 in Part A of
Section 3, printed in black and white?. Surely if they have to give so much information,
they cannot simply mean Picture 5??.)
Finally, we also explored the searching behavior of our subjects, focusing on the
12 documents in which incomplete descriptions were given. Ancestral Search predicts
that subjects will search the current section (where the question is asked) exhaustively,
before moving on to another section. Figure 5 shows subjects? compliance with An-
cestral Search in their first navigation action. (Eight of the 12 documents contained a
description of the form Picture 5 in Part A, so for these it suffices to look at the first
navigation action.) Four subjects complied perfectly. Half the subjects complied almost
perfectly, deviating in at most 2 of the 12 cases. However, five subjects deviated almost
completely (10 or more times). Closer inspection showed that these latter subjects
seemed to navigate randomly, not following any obvious pattern (e.g., top to bottom).
It may well be that these subjects did not take the experiment seriously. Nevertheless,
we still have more deviation from Ancestral Search than expected.
There are two possible explanations. First, some subjects may have started using
Ancestral Search, and then found that it was not effective when they encountered
some documents in which the referent turned out to be in some far-away section, after
which they changed to a more random strategy. (Recall that our experiment deliberately
Figure 5
Compliance with Ancestral Search during first navigation action.
251
Computational Linguistics Volume 33, Number 2
included some unreasonably short descriptions.) Our data seem to confirm this. For
instance, subject S11 started in compliance with Ancestral Search until encountering a
document asking, in Section 2, to find a picture in Part C. The subject clicked as many
as 6 times on Part C of Section 2, before finally finding the referent in Section 3. He went
on to deviate four times from Ancestral Search.
A second explanation for deviating from Ancestral Search is the kind of navigation
that we allowed. Subjects could go directly from, say, Part C in Section 2, to part A in
Section 3, without an extra navigation step to go into Section 3. In fact, it may even
be faster to navigate to another section than within the current one, depending on
the position of the mouse pointer. (This contrasts with the university domain, where
one could not go directly from room 120 in Watts building to room 140 in Cockcroft
building without first having to walk between the buildings.) It should be noted that
this problem may be more pronounced after the first navigation action has been made.
For instance, if one clicks on Part A in Section 2, then the mouse pointer is about as
close to Part C in Section 1 as to Part C in Section 2. To explore this idea, we looked at
the four documents in which a description of the form picture 5 was given. In 83 cases,
subjects who complied with Ancestral Search for the first navigation action needed to
perform a second action; in 77% of these cases, they also complied with Ancestral Search
in the second action. Now in as many as 68% of the cases in which they did not comply,
they clicked on the closest link in an adjacent section (e.g., Part A of the next section
after having first clicked on Part C). This confirms our suspicion that the lack of effort
required to deviate may have been a reason for deviation. With hindsight, we should
probably have made the distance between the relevant sections larger.
7. Conclusion
This article has discussed generation strategies that facilitate resolution of a referring
expression by adding logically redundant properties. We have shown that this can
be of crucial importance, especially in large domains, where minimally distinguishing
descriptions can sometimes be completely useless (witness, e.g., Example [1c]). Two
algorithms for generating logically redundant references along the lines described in
this article have been implemented. The experiments reported in the previous sections
indicate that these algorithms are fundamentally on the right track.
We recently learned of an interesting series of experiments that investigate the role
of logically redundant properties in referring expressions (Arts 2004). One of the out-
comes of these experiments was that certain types of logically redundant information
almost consistently led to accelerated resolution. This was particularly true for informa-
tion concerning the location of an object. For example, a logically minimal description
like the white button on the left took readers longer to resolve than a redundant one like
the white button at the top left (our emphasis). It is interesting to note that these results
were obtained in situations where neither LO nor DE could occur.
This article has described an alternative to classical algorithms for GRE. Suppose you
are designing an NLG system and want to give it a GRE component; how do you know
whether to use the new algorithm, instead of one of its predecessors? Redundancy has
a role to play in different kinds of situations (see the Introduction of this article), but
our algorithms focus on a class of cases that we believe to be particularly widespread,
namely where the domain is hierarchical in the sense of Section 3. Because hierarchies
involve relations, let us once again compare the predictions made by our algorithms
with those made by Dale and Haddock (1991). Suppose their description the bowl on the
252
Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify
table was said when there are two tables and two bowls, while (only) the table furthest
away from the hearer has a bowl on it. FI and SL, by contrast, would generate something
redundant like the bowl on the far-away table. Which of the two descriptions is best?
The answer is that it depends on the situation: When all the relevant facts are
available to the reader without effort (e.g., all the domain objects are visible at a glance)
then Dale and Haddock?s minimal descriptions are fine, but when search is required,
the kind of ?studied? redundancy embodied in FI and SL becomes necessary. Consider
the example again. If the tables and bowls are visible at a glance, then resolving the
DE-inducing description the bowl on the table is unproblematic, because there is nothing
here to discover: The crucial part of the domain is directly available, and no search is
needed. Consequently, it is superfluous to say anything about the location of the table.
But suppose we are in a huge room, where it is not obvious for the hearer what is on
each table. In this situation, the bowl on the table would be a rather unhelpful description,
compared to the bowl on the far-away table (or the bowl on the table in the corner), as
would be consistent with our algorithms. (The example can be made more dramatic
by hiding the table with the bowl on it in another room.) What this example highlights
is the distinction between the things that speaker and hearer know when a referring
expression is uttered, and the things they can discover. It is in the latter case that search
becomes an issue. We have shown how this idea can be made precise and incorporated
into a GRE algorithm, and we have demonstrated that this can improve the generated
descriptions from the perspective of the hearer.
Recent work in psycholinguistics, focusing on spontaneous speech in dialogue,
has shown that speakers and hearers often act as if they are completely oblivious of
the epistemic limitations of their interlocutors, even when these limitations have been
made perfectly obvious to them (e.g., Keysar, Lin, and Barr 2003). These widely known
results have caused some researchers to expect language users to behave with unbridled
descriptive ?egocentricity? in all situations. The first of our two experiments suggests
that human writers (as opposed, perhaps, to speakers) can be highly altruistic in their
descriptions of objects. The second experiment demonstrates how descriptive altruism
can benefit readers.
By exploring the benefits for the hearer (in terms of the effort required for identify-
ing the referent), we have not only shown that it can be good to add logically redundant
information to a referring expression; we have arguably also shed some light on the
reason why redundant descriptions are sometimes preferred. By counting the number of
clicks that subjects need in order to find the referent, and relating these to predictions
stemming from our Ancestral Search model, we believe that we have achieved a degree
of insight into the ?resolution? processes in the head of the reader, not unlike the
way in which insights in human language processing can be produced by eye-tracking
experiments. It would be interesting to see whether the ideas discussed here can be
confirmed using such a more entrenched psycholinguistic paradigm.
Acknowledgments
The authors are grateful for insightful
comments from Emiel Krahmer, Richard
Power, Sebastian Varges, the Aberdeen NLG
group, and the anonymous reviewers. The
second author acknowledges support from
the UK?s EPSRC TUNA project, grant
GR/S13330/01.
References
Appelt, Douglas E. 1985. Planning English
referring expressions. Artificial Intelligence,
26:1?33.
Arts, Anja. 2004. Overspecification in
Instructive Texts. Ph.D. thesis, Tilburg
University, The Netherlands. Wolf
Publishers, Nijmegen.
253
Computational Linguistics Volume 33, Number 2
Association of the British Pharmaceutical
Industry (ABPI). 1997. 1996?1997 ABPI
Compendium of Patient Information Leaflets.
ABPI, London.
Clark, Herbert. 1992. Arenas of Language Use.
CSLI Publications, Stanford, CA.
Cremers, Anita. 1996. Reference to Objects; an
Empirically Based Study of Task-oriented
Dialogues. PhD. thesis, University of
Eindhoven.
Dale, Robert. 1989. Cooking up referring
expressions. In Proceedings of the 27th
Annual Meeting of the Association for
Computational Linguistics (ACL-1989),
pages 68?75, Vancouver, Canada.
Dale, Robert and Nicholas Haddock. 1991.
Generating referring expressions involving
relations. In Proceedings of EACL-1991,
pages 161?166, Berlin.
Dale, Robert and Ehud Reiter. 1995.
Computational interpretations of the
Gricean maxims in the generation of
referring expressions. Cognitive Science,
18:233?263.
Deutsch, W. 1976. Sprachliche Redundanz
und Objectidentifikation. Ph.D.
dissertation, University of Marburg.
Edmonds, Philip G. 1994. Collaboration on
reference to objects that are not mutually
known. In Proceedings of COLING-1994,
pages 1118?1122, Kyoto.
Grice, Herbert P. 1975. Logic and conversation.
In P. Cole and J. Morgan, editors, Syntax
and Semantics: Vol 3, Speech Acts. Academic
Press, New York, pages 43?58.
Horacek, Helmut. 2005. Generating
referential descriptions under conditions
of uncertainty. In 10th European Workshop
on Natural Language Generation (ENLG-2005),
pages 58?67, Aberdeen, Scotland.
Jordan, Pamela W. 2000. Can nominal
expressions achieve multiple goals?
An empirical study. In ACL-2000,
pages 142?149, Hong Kong.
Jordan, Pamela W. 2002. Contextual influences
on attribute selection for repeated
descriptions. In K. van Deemter and
R. Kibble, editors, Information Sharing. CSLI
Publications, Stanford, CA, pages 295?328.
Keysar, Boaz, Shuhong Lin, and Dale J. Barr.
2003. Limits on theory of mind use in
adults. Cognition 89:25?41.
Krahmer, Emiel and Marie?t Theune. 2002.
Efficient context-sensitive generation of
referring expressions. In K. van Deemter
and R. Kibble, editors, Information
Sharing. CSLI Publications, Stanford, CA,
pages 223?264.
Levelt, Willem J. M. 1989. Speaking: From
Intention to Articulation. MIT Press,
Cambridge, MA.
Mangold, Roland. 1986. Sensorische Faktoren
beim Verstehen ueberspezifizierter
Objektbenennungen. Peter Lang Verlag,
Frankfurt.
Norman, Donald. 1988. The Design of
Everyday Things. Doubleday, London.
Paraboni, Ivandre?. 2000. An algorithm for
generating document-deictic references. In
Proceedings of INLG-2000, ?Coherence in
Generated Multimedia,? pages 27?31,
Mitzpe Ramon, Israel.
Paraboni, Ivandre?. 2003. Generating References
in Hierarchical Domains: The Case of
Document Deixis. Ph.D thesis, University of
Brighton, U.K.
Paraboni, Ivandre?, Judith Masthoff, and Kees
van Deemter. 2006. Overspecified reference
in hierarchical domains: Measuring the
benefits for readers. In Proceedings of
INLG-2006, pages 55?62, Sydney.
Paraboni, Ivandre? and Kees van Deemter.
2002a. Generating easy references: the case
of document deixis. In Proceedings of
INLG-2002, pages 113?119, New York.
Paraboni, Ivandre? and Kees van Deemter.
2002b. Towards the generation of
document-deictic references. In K. van
Deemter and R. Kibble, editors, Information
Sharing. CSLI Publications, Stanford,
pages 329?354.
Pechmann, Thomas. 1989. Incremental
speech production and referential
overspecification. Linguistics, 27:98?110.
Reiter, Ehud and Robert Dale. 2000. Building
Natural Language Generation Systems.
Cambridge University Press, Cambridge.
Siddharthan, Advaith and Ann Copestake.
2004. Generating referring expressions in
open domains. In Proceedings of 42nd ACL,
pages 408?415, Barcelona, Spain.
Sonnenschein, Susan. 1982. The effects of
redundant communications on listeners:
When more is less. Child Development,
53:717?729.
Sonnenschein, Susan. 1984. The effect of
redundant communication on listeners:
Why different types may have different
effects. Psycholinguistic Research, 13:147?166.
van Deemter, Kees. 2002. Generating
referring expressions: Boolean
extensions of the incremental algorithm.
Computational Linguistics, 28(1):37?52.
van Deemter, Kees. 2004. Finetuning an NLG
system through experiments with human
subjects: The case of vague descriptions.
In Proceedings of INLG-2004, pages 31?40,
Brockenhurst, UK.
254
USP-EACH Frequency-based Greedy Attribute Selection for 
Referring Expressions Generation 
 
 
 
Diego Jesus de Lucena Ivandr? Paraboni 
Escola de Artes, Ci?ncias e Humanidades Escola de Artes, Ci?ncias e Humanidades 
University of S?o Paulo ? USP University of S?o Paulo ? USP 
Av. Arlindo Bettio, 1000 - S?o Paulo, Brazil Av. Arlindo Bettio, 1000 - S?o Paulo, Brazil 
diego.si@usp.br ivandre@usp.br 
 
 
 
 
 
 
Abstract 
Both greedy and domain-oriented REG algo-
rithms have significant strengths but tend to 
perform poorly according to humanlikeness 
criteria as measured by, e.g., Dice scores. In 
this work we describe an attempt to combine 
both perspectives into a single attribute selec-
tion strategy to be used as part of the Dale & 
Reiter Incremental algorithm in the REG 
Challenge 2008, and the results in both Furni-
ture and People domains. 
1 Introduction 
Minimality and Humanlikeness in REG are often 
conflicting goals. Greedy algorithms tend to favour 
shorter descriptions, but in doing so their output 
may look unnatural. On the other hand, domain-
oriented algorithms that arguably favour more 
?human-like? strategies (e.g., selecting the most 
typical attributes first) pay little or no attention to 
minimality, and as a result the generated descrip-
tions may become overly long or clumsy. 
Which strategy might a human speaker favour? 
In this work we describe an algorithm that disre-
gards minimality entirely and attempts to select 
?typical? attributes based on two simple assump-
tions: first, when facing a complex context with a 
large number of objects, an attempt to compute the 
precise attribute capable of ruling out the largest 
possible number of distractors is not only hard 
(from the computational point of view), but also 
less natural than simply using typical (e.g., fre-
quent) attributes. On the other hand, as the number 
of distractors decreases, it may become gradually 
clearer for the speaker which attributes are most 
helpful to achieve uniqueness, up to the point in 
which she may naturally switch to a ?greedy? strat-
egy and finalize the description. These assump-
tions are implemented as an attribute selection 
strategy to be used with the Incremental algorithm 
(Dale & Reiter, 1995) described below. 
2 System Description 
We take a simple view of humanlikeness in which 
the list of preferred attributes is sorted by relative 
frequency1 as seen in the training data. The result-
ing list P is the centre piece of the following attrib-
ute selection strategy: 
(1) select all attributes whose relative frequency 
falls above a trainable threshold value t  (in our 
experiments t is estimated to be 0.8 for both 
Furniture and People domains.) 
(2) if the resulting description uniquely describes 
the target object, then finalizes.  
(3) if not, starting from the most frequent attribute 
in P, search exhaustively for an attribute g 
such that g, if selected, would rule out all re-
maining distractors in the context. 
                                                          
1 This contrasts the work in Kelleher (2007), which takes into 
account absolute counts seen in the training data. 
219
(4) if such attribute g exists, then g is selected and 
the algorithm finalizes. 
(5)  if not, select the most frequent attribute f that 
can rule out at least one distractor, and repeat 
steps (3-5). 
 
The selection of attribute g stands for the greedy 
component of our approach, whilst the initial at-
tributes in step 1 and the attribute f account for our 
?humanlikeness as frequency? assumption. The 
overall effect attempted is the following:  
- Highly frequent attributes are always selected. 
In our tests this means that the attributes type 
and colour were always included in Furniture 
descriptions, and type was always included in 
People descriptions (in both cases this is so re-
gardless of discriminatory power.) As a result, 
we can only produce minimal descriptions by 
chance.  
- In a complex situation of reference (in which 
many attributes may rule out many distractors, 
but more than one will be required to achieve 
uniqueness) the algorithm simply selects the 
most frequent attributes, perhaps not unlike a 
human speaker who has to single out the target 
object but who does not have the time or re-
sources to come up with the ?best? attribute 
straight away.  
- As the number of distractors decreases, a sin-
gle attribute capable of ruling out all distrac-
tors will eventually emerge, forcing the 
algorithm to switch to a greedy strategy and fi-
nalize. Once again, this might be just what 
humans do when  a suitable (i.e., economical) 
attribute becomes sufficiently salient and all 
distractors in the context can be ruled out at 
once. 
3 Results  
Below we summarize our results for Task 1 (At-
tribute Selection) and also for Task 3 (Attribute 
Selection and Surface Realisation combined) for 
the REG 2008 development data set (80 instances 
for Furniture and 68 instances for People.) As ex-
pected, our algorithm is heavily penalized in the 
Minimality criteria but performs reasonably well in 
Humanlikeness (Dice and MASI.) if compared to 
the systems presented in the previous GRE Chal-
lenge. 
 
 
 
 Overall Furniture People 
 Mean SD Mean SD Mean SD 
Dice 0.75 0.25 0.82 0.22 0.66 0.26 
MASI 0.53 0.39 0.62 0.39 0.42 0.35 
Accuracy 0.37 0.48 0.49 0.50 0.24 0.43 
Uniqueness 1.00 - 1.00 - 1.00 - 
Minimality - - - - - - 
String-edit distance 6.70 3.09 6.13 3.28 7.38 2.72 
String-accuracy 0.02 0.14 0.04 0.19 - - 
Figure 1. Attribute Selection and Surface Realisation results 
 
Acknowledgments 
This work has been supported by CNPq-Brazil 
(484015/2007-9) and FAPESP (2006/03941-7). 
References  
Dale, Robert and Ehud Reiter. 1995. Computational 
interpretations of the Gricean maxims in the genera-
tion of referring expressions. Cognitive Science (19). 
Kelleher, J.D. (2007) DIT - Frequency Based Incre-
mental Attribute Selection for GRE. MT Summit XI 
Workshop Using Corpora for Natural Language 
Generation: Language Generation and Machine 
Translation, pp. 90-91. 
220
From TUNA Attribute Sets to Portuguese Text: a First Report 
 
 
Daniel Bastos Pereira Ivandr? Paraboni 
Escola de Artes, Ci?ncias e Humanidades Escola de Artes, Ci?ncias e Humanidades 
University of S?o Paulo ? USP University of S?o Paulo - USP 
Av. Arlindo Bettio, 1000 - S?o Paulo, Brazil Av. Arlindo Bettio, 1000 - S?o Paulo, Brazil 
daniel.bastos@usp.br ivandre@usp.br 
 
 
 
 
 
 
Abstract 
This document describes the development of a 
surface realisation component for the Portu-
guese language that takes advantage of the 
data and evaluation tools provided by the 
REG-2008 team. At this initial stage, our 
work uses simple n-gram statistics to produce 
descriptions in the Furniture domain, with lit-
tle or no linguistic variation. Preliminary re-
sults suggest that, unlike the generation of 
English descriptions, contextual information 
may be required to account for Portuguese 
word order. 
1 Introduction 
In this work we describe a surface realisation com-
ponent for Portuguese definite descriptions using 
the data and evaluation tool provided as part of the 
REG-2008 Challenge. However, given the differ-
ences between language and a number of project 
decisions discussed below, the present results are 
not suitable for comparison with the work done by 
the actual task participants, and it should be re-
garded simply as an ongoing effort to generate and 
evaluate Portuguese descriptions using similar 
standards. 
2 System Description 
Our work is a simple application of n-gram statis-
tics to surface realisation. Two independent anno-
tators started by producing individual lists of the 
most likely phrases that could possibly be associ-
ated with every attribute?value pair in the corpus. 
Since at this initial stage we are only considering 
1-to-n relations (i.e., each phrase is the realisation 
of exactly one attribute-value pair) the mapping 
annotation was straightforward. More complex (m-
to-n) cases ? those in which two or more properties 
may combine to form a single text unit (e.g., the 
properties of being human, young and male may be 
realised simply as ?a young man? or even as ?a 
boy?) ? will be discussed elsewhere. 
Given a TUNA attribute set as an input, we 
compute all (unordered) sets of phrases that corre-
spond to a possible description, including gender 
variations. Next, we compute all possible permuta-
tions of each phrase set that matched a pre-defined 
description template suitable to Portuguese phrase 
order, once again with gender variation. As a re-
sult, even a simple attribute set as in ?the large red 
table? would have at least eight possible realisa-
tions in Portuguese, although only a few can be 
considered well-formed and likely to be uttered for 
the purpose of identification. The final task of se-
lecting the most likely output string is left to a 
simple bigram language model built from a 40-
million words corpus of Brazilian Portuguese 
newspaper articles. 
3 Preliminary Evaluation  
We produced a surface realisation form for each of 
the 80 instances of Portuguese descriptions in the 
REG-2008 development data. Overall, 32 instances 
(40%) of descriptions were incorrectly generated. 
The major source of errors was the lack of com-
plete gender agreement, since our simple bigram-
based model cannot handle long-distance depend-
232
encies appropriately, as in ?o sof? grande ver-
melha?, in which the gender agreement between 
?sof?? (masculine) and ?vermelha? (feminine) 
could not be established. We believe that this could 
be easily fixed had we used a more expressive lan-
guage model instead. 
Two independent annotators built a Portuguese 
reference set by manually translating each of the 
80 descriptions in the development data set and 
taking into account the possible phrase realisations 
defined earlier. More specifically, we produced a 
?normalized? reference set, removing much of the 
noise that naturally occurs in the raw data. This 
included a number of likely errors (e.g., ?red chair 
in center red?), meta-attributes (e.g., ?first picture 
on third row?), illegal attributes (e.g.., ?the grey 
desk with drawers?), differences in specificity 
(e.g., ?shown from the side? as a less specific al-
ternative to both ?facing left? and ?facing right? 
values) and synonymy (e.g., ?facing the viewer? as 
an alternative to ?facing forward?). Moreover, 
given that definiteness cannot be worked out from 
the attribute set alne, all indefinite descriptions 
were changed to definite. 
Regarding the usefulness of this modified refer-
ence set, there are a number of due observations: 
firstly, given the differences between languages, 
our reference data set is not to be regarded as a 
resource for investigating language use as the 
original TUNA data set is intended to be, but rather 
as a standard of acceptable performance for a prac-
tical Portuguese NLG system. Moreover, since the 
translated descriptions were not produced in real 
situations of reference, we are aware that our re-
sults are  not directly comparable to, e.g., the work 
carried out in the REG-2008 challenge for evaluat-
ing English descriptions, and that would remain the 
case even without normalization.  
On the other hand, although the result of both 
translation and normalization tasks is a somewhat 
simplified set of Portuguese descriptions, this is 
not to say that these descriptions are tailored to 
match those that we intend to generate. In fact, one 
of the goals in the normalization task was to retain 
the most appropriate instances of reference, which 
included a large number of cases that we are not 
presently able to produce, e.g., those combining 
the x-dimension and y-dimension attributes in sin-
gle references to corners, as in ?in the upper right 
corner?. Figure 1 summarizes our findings for the 
80 instances of descriptions in the Furniture do-
main. 
 
 Furniture 
String Accuracy 0.26 
String-edit dist. 3.26 
Figure 1. Portuguese descriptions (Furniture domain) 
4 Final Remarks 
One striking difference between system descrip-
tions and the reference set was the word order of 
Portuguese adjectives. To our surprise, it is not 
clear in which order attributes such as colour and 
size should be combined in Portuguese definite 
descriptions. For example, ?a large red table? 
could be realised either as type + colour + size 
(e.g., ?a mesa vermelha, grande? ) or as type + size 
+ colour (e.g., ?a mesa grande, vermelha?). As 
both alternatives seem equally acceptable, the 
choice may depend on which property contrasts 
each of the distractors in the situation of reference. 
Whilst the present ambiguity reveals a weakness in 
our artificially-built reference set, it may also sug-
gest that a much more sophisticated approach to 
Portuguese realisation is called-for, especially if 
compared to the generation of English descriptions 
whose word order seems fairly standard. We be-
lieve that further investigation on this issue is still 
required 
Acknowledgments 
This work has been partially supported by CNPq-
Brazil (484015/2007-9), FAPESP (2006/03941-7) 
and Ensinar com Pesquisa / USP. 
References  
Gatt, A.; I. van der Sluis, and K. van Deemter (2007) 
Evaluating algorithms for the generation of referring 
expressions using a balanced corpus. 11th European 
Workshop on Natural Language Generation 49?56. 
van Deemter, K.; I. van der Sluis and A. Gatt (2006) 
Building a semantically transparent corpus for the 
generation of referring expressions. 4th International 
Conference on Natural Language Generation. 
233
Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 125?131, Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Text Generation for Brazilian Portuguese:  
the Surface Realization Task 


Eder Miranda de Novais Thiago Dias Tadeu Ivandr? Paraboni 
University of S?o Paulo - School of Arts, Sciences and Humanities (USP-EACH) 
Av. Arlindo Bettio, 1000, Ermelino Matarazzo 
S?o Paulo, Brazil - 03828-000 
eder.novais@usp.br tdtadeu@gmail.com ivandre@usp.br 
 
 
 
 
 
 
Abstract 
Despite the growing interest in NLP focused 
on the Brazilian Portuguese language in recent 
years, its obvious counterpart ? Natural Lan-
guage Generation (NLG) ? remains in that 
case a little-explored research field. In this 
paper we describe preliminary results of a first 
project of this kind, addressing the issue of 
surface realization for Brazilian Portuguese. 
Our approach, which may be particularly suit-
able to simpler NLG applications in which a 
domain corpus of the most likely output sen-
tences happens to be available, is in principle 
adaptable to many closely-related languages, 
and paves the way to further NLG research 
focused on Romance languages in general. 
1 Introduction 
Data-to-Text Natural Language Generation (NLG) 
systems produce text or speech from a given non-
linguistic input. Systems of this kind usually fol-
low a pipelined architecture (Reiter, 2007) com-
prising data interpretation, document planning, 
sentence planning and surface realization tasks. In 
this work we discuss the latter, that is, the task of 
producing surface word strings from a non-
linguistic input specification.  
Existing approaches to surface realization may 
vary greatly in their input requirements and, con-
sequently, in the level of control over the output 
text. On the one hand, more sophisticated, gram-
mar-based surface realization systems such as 
KPML (Bateman, 1997) allow maximum flexibili-
ty and productive coverage. These advantages, 
however, are only useful if the underlying applica-
tion is capable of providing a detailed semantic 
specification as an input to the surface realization 
module in the first place.  
As an alternative to surface realization gram-
mars, NLG systems may also rely on template-
based surface realization, that is, the use of prede-
fined structures with a number of variable fields 
(or slots) to be filled in with values provided by the 
application. For a comparison between templates 
and other approaches to NLG, see for instance van 
Deemter et. al. (2005). 
Adapting an existing application to a template-
based realization system  is usually much simpler 
than in a grammar-based approach. Yet, in order to 
take full advantage of template definitions and to 
obtain a degree of control over the output text that 
is comparable to what a grammar-based system 
would allow, it is still necessary to master the use 
of templates and their rules to fill in each slot ade-
quately.  
The problem of input specification to surface 
realization has been discussed at length in the lite-
rature in the field - see for example Langkilde 
(2000) ? and we of course do not dispute that more 
sophisticated NLG systems will require a detailed 
input specification. However, given that the avail-
able semantics may not be provide in this level of 
detail, in this paper we discuss an alternative that 
125
may be suitable to simpler applications, namely, 
those cases in which it is known in advance what 
the most likely output sentence structures are, for 
example, because a corpus on that particular do-
main happens to be available. In these cases, we 
will argue that it may be possible to take advantage 
of the available knowledge to quickly deploy a 
surface realization component based on existing 
corpora.  
The underlying assumption in our work is that 
there are simpler NLG applications for which it 
may be sufficient to select a sentence that resem-
bles the desired output, and then modify some or 
all of its constituents as needed to achieve the de-
sired output. For instance, an application that is not 
linguistically-oriented may produce its output re-
sults as natural language text by selecting a stan-
dard imperative sentence as in ?Please reply to this 
message? and, leaving all other sentence constitu-
ents unchanged, specify that the action to be rea-
lized in the output is ?delete?, and that its patient 
object is ?file?. This will have the effect of produc-
ing the output sentence ?Please delete this file?.  
In this introductory work we intend to outline 
our ongoing efforts to develop one such approach 
to surface realization for the Brazilian Portuguese 
language. In doing so, we shall focus on the gener-
al principles that guide our research, leaving much 
of the theoretical details to be discussed elsewhere. 
The present work has been developed within the 
context of a query-and-answer application under 
investigation, in which questions sent by undergra-
duate students enrolled in a particular course will 
be matched to existing entries in a large database 
of standard replies written by the professors in 
charge to the most frequently asked questions 
made by the students, and tailored to each particu-
lar context accordingly. Details of this particular 
application will not be dealt with in this paper ei-
ther. 
The reminder of this paper is structured as fol-
lows. Section 2 briefly discusses related work on 
surface realization; Section 3 provides an overview 
of our system?s architecture; Sections 4 describes 
the extraction of syntactically-structured templates 
from a target corpus and Section 5 presents the 
current features of our template-based surface rea-
lization engine. Finally, Section 6 draws prelimi-
nary conclusions and describes ongoing work, and 
Section 7 hints at possible collaboration with the 
wider NLP research community in Latin America 
and elsewhere.  
2 Related work 
Mapping an application semantics to surface 
strings usually involves the use of surface realiza-
tion grammars or similar resources, which can be 
either built manually (e.g., Bateman, 1997) or ac-
quired automatically from a corpus (Ratnaparkhi, 
2000; Zhong & Stent, 2005; DeVault et. al., 2008).  
The surface realization task proper can be di-
vided into two relatively independent procedures: a 
domain-dependant mapping from the application 
semantics onto linguistic structures (including, 
e.g., lexical choice), and a language-oriented task 
of linearization. As pointed out in Gatt & Reiter 
(2009), most of the existing systems tend to per-
form both tasks, but in some cases they focus on 
the latter, assuming that all lexical choices and 
other domain-dependent decisions have already 
been made. This is the case for example of Sim-
pleNLG (Gatt & Reiter, 2009), a surface realiza-
tion engine implemented as a Java library for 
sentence linearization.  
Central to the development and use of a surface 
realization system is the kind of input specification 
that will be expected from the application. In order 
to take full advantage of grammar-based surface 
realization, it is usually necessary to provided de-
tailed linguistic knowledge as an input. This is the 
case, for example, of a number of corpus-based 
approaches to grammar acquisition, which may 
take logical forms as an input (e.g., Smets et. al., 
2003; Zhong & Stent, 2005; Marciniak & Strube, 
2005). The Amalgam system, for instance (Smets 
et. al., 2003), takes as an input a graph conveying 
fixed content words (lemmas) and detailed linguis-
tic information such as verb tense and mode, gend-
er, number and definiteness of all its constituents, 
and additional semantic features (e.g., ?human?, 
?animated? etc.)  
Detailed input specification as required in 
grammar-based surface realization is however of-
ten unavailable from the semantics of the applica-
tion. As an alternative, template-based surface 
realization makes use of predefined structures 
(e.g., syntactically-structured sentence templates) 
with slots to be filled in with values provided by 
the application. A prominent example of template-
based surface realization system is YAG (McRoy 
126
et. al., 2003), which may accept both feature struc-
tures and propositional semantics as an input. The 
following is an example of input feature structure 
in YAG, taken from McRoy et. al. (2003). In this 
example, the structure represents the fact that a 
discourse subject (George) performs an act (under-
stand) on a particular object (a book), in which 
both subject and object happened to be realized as 
pronouns as ?He understands it?. 
 
    ((template clause 
     (process ?understand?) 
     (agent   ((template noun-phrase) 
               (np-type PROPER) 
               (head ?George?) 
                 (gender MASCULINE) 
                 (pronominal YES))) 
     (object ((template noun-phrase) 
              (head ?book?) 
              (pronominal YES))) ) 
Input feature structure in YAG. 
 
The input requirements of a template-based sur-
face realization system are obviously much simpler 
? and more likely to be available from the applica-
tion ? than a full set of linguistic instructions on 
how to generate the desired output. Still, in this 
work we would like to produce surface strings us-
ing even less knowledge, namely, by using sen-
tence-level templates extracted from a domain 
corpus as a basis to generate original and modified 
versions of the corpus sentences.  
We will refer to this as an example-based ap-
proach to surface realization1, although this is not 
to be mistaken for example-based learning tech-
niques to perform automatic grammar induction as 
in DeVault et. al., (2008), or other forms of gram-
mar acquisition as in Zhong & Stent (2005). Our 
work is more related to Ratnaparkhi (2000) in the 
sense that we also use a large collection of genera-
tion templates for surface realization, but still dis-
tinct in that we intend to generate text from 
minimal input.  
3 Project Overview 
Template-based surface realization systems such as 
YAG (McRoy et. al., 2003) make use of a relative-
ly small number of template definitions and some 
kind of descriptive language to provide fine-
grained input sentence specification with flexibility 
                                                         
1 Perhaps ?select-and-modify? would be closer to our current 
purposes. 
and wide coverage. However, if a corpus on the 
application domain happens to be available, and 
assuming that the corpus sentences resemble those 
that we intend to generate, then it may be conve-
nient (at least for applications that are not linguisti-
cally-motivated in the first place) to simply use the 
corpus sentences as examples, and allow an input 
specification that makes explicit only the changes 
that need to take place to convert the selected ex-
ample into the desired output.  
For example, in order to produce the sentence 
?He understands it? we may select an example 
such as ?People will understand it? from the cor-
pus, and then redefine its agent head type as a pro-
noun, and its action tense as present. The 
difference may not seem so dramatic if compared 
to, e.g., an input specification to YAG, but it will 
obviously grow as more complex sentence struc-
tures are considered.  
If the selected example differs greatly from the 
target sentence, then a large number of modifica-
tions will have to take place, and in that case our 
example-based approach may not seem very use-
ful. On the other hand, if the corpus is representa-
tive of the sentences that are likely to be generated, 
then little or no additional modifications will be 
required, in which case new sentences may be gen-
erated indeed from a minimally specified input. In 
either case, we notice that since the examples are 
represented directly in natural language in the cor-
pus, new instances can be easily added to expand 
the system coverage. 
In our present approach to the surface realization 
task, syntactically-structured templates are selected 
from a target corpus on the application domain and 
used as a basis to produce original and modified 
versions of the corpus sentences by a combination 
of canned text and basic dependency-tree opera-
tions. Each sentence in the target corpus makes a 
sentence template in which the agent, patient and 
action constituents may be modified or replaced by 
the application by combining lower-order tem-
plates (e.g., for NPs and VPs), and new sentences 
may be supported by adding the corresponding 
examples directly to the corpus.  
Our current work can be divided into two main 
tasks: the extraction of syntactically-structured 
templates from corpora and the actual development 
of the surface realization engine. The following 
sections 4 and 5 discuss each of these tasks in turn.  
127
4 Template Extraction 
Using a collection of emails sent to undergraduate 
students by their professors in reply to their most 
frequent questions regarding a particular project, 
we developed a database conveying 597 instances 
of surface realization templates for Brazilian Por-
tuguese NLG as follows. 
After sentence segmentation, the corpus was 
tagged and parsed using PALAVRAS (Bick, 
2000). A number of critical parsing errors were 
removed, and thus we arrived at a set of 578 sen-
tence-level templates represented in XML format.  
In our example-based approach to surface reali-
zation we consider two kinds of structure: sentence 
and constituent templates. Sentence templates are 
high-level representations of the sample sentences 
taken from our target corpus, and they contain a 
number of variable fields (the constituents) to be 
filled in with application data (in most cases hav-
ing an agent, action and patient fields.)  
Everything else within the sentence is simply 
canned text as seen in the corpus, and cannot be 
modified by the application. In other words, if the 
application needs to generate a sentence that dif-
fers from the template in any constituent other than 
its NPs and VPs, it is necessary to define a new 
template by adding a new example to the corpus. 
Sentence templates are highly redundant in the 
sense that many of them keep a similar syntactic 
structure in which only the surrounding text might 
change significantly. For example, many sentence 
templates in our domain represent a simple piece 
of advice in the form agent + action followed by 
some canned text, as in ?You should enroll by Fri-
day? and ?All smokers are supposed to quit by the 
end of the month?.  
Although we could have defined a smaller (and 
more flexible) set of templates by generalizing 
over these structures, in practice this would in-
crease the complexity of the required input (e.g., 
with the addition of a ?time? field to a common 
template to be shared by both examples above.) As 
mentioned in the previous section, we intend to 
keep input specification as simple as possible (i.e., 
in natural language format) by allowing the target 
sentences to be specified directly in the corpus. 
The contents of the variable fields in a sentence 
template act as default values for the surface reali-
zation algorithm, and they may be changed indivi-
dually (e.g., by setting a different tense or gender 
value for a particular field) or replaced by another 
constituent template entirely. We notice that de-
fault values are acquired automatically from corpo-
ra, i.e., they do not need to be hard-coded as in 
McRoy et. al., (2003). 
Unlike sentence templates, constituent templates 
are not extracted from corpora. Instead, constitu-
ents are dependency-trees generated by a small set 
of grammar rules that covers the instances of VPs 
and NPs found in our corpus, including support to 
relative clauses and the most common forms of PP 
attachment. The choice for a grammar representa-
tion for the more fine-grained constituents was 
mainly motivated by the need to achieve wider 
coverage and to support linguistic variation beyond 
what the actual phrases found in the corpus would 
allow. In doing so we are able to fill in sentence 
templates with phrases of arbitrary complexity, as 
in the NP ?You should enroll by the end of the 
month in which you are expected to complete your 
current assignment?, and not simply using those 
NPs found in the target corpus.  
The set of mappings from domain concepts to 
their dependency-trees (i.e., constituent templates) 
makes a dictionary of realizations in the applica-
tion domain. As in related work in the field (e.g., 
Gatt & Reiter, 2009), we presently assume that the 
actual mappings are to be provided by the applica-
tion.  
Concept-to-strings mappings are usually 
handcrafted, but may also be acquired automatical-
ly from corpora, as in Bangalore & Rambow 
(2000). For testing purposes, we have extracted 
1,548 instances of concept-to-string mappings 
from the target corpus, being 1,298 mappings from 
agent/patient entities to descriptions, pronouns and 
proper  names, and 250 mappings from actions to 
VPs, even though many of them will not be of 
practical use from the point of view of our in-
tended application. 
5 Surface Realization 
Using the template definitions from the previous 
section, we designed a simple corpus-based surface 
realization component for our ongoing project.  
Our surface realization module is currently able 
to accept as an input a template id (to be taken as a 
sample structure with inherited default values for 
the output sentence) and, optionally, parameters 
representing the alternative semantics of its agent, 
128
patient and action constituents. Alternatively, it is 
also possible to specify a sentence from scratch 
(that is, without using any existing template as a 
basis) in a standard NP VP NP format. The latter 
choice was added to the system as we noticed that 
simpler sentence structures may be specified more 
conveniently in this way, as opposed to looking up 
an example in the corpus. In our project, this is the 
case of short reply sentences as in ?Yes, of 
course?, ?Thank you? and others, in which there is 
hardly any point in selecting a template from the 
corpus and then commanding the required changes. 
The underlying application selects a target tem-
plate and provides a set of values to fill in the tem-
plate variable fields. These input values overwrite 
the default values provided by the template (that is, 
those values that were inherited from the corpus 
data) and adjusted by basic agreement rules to 
reestablish grammaticality if necessary, as we will 
discuss later.  
The currently supported variable fields for NPs 
are determiner type, gender, number, person, de-
terminer lemma, pre and post modifiers, the NP 
head, an attached pp-list and relative clause (which 
may recursively convey NPs within themselves.) 
As for VPs, the variable fields are VP type (finite 
vs. infinite etc.), person, mode, verb type, verb 
tense and adverbial modifiers. Verbal gender and 
number are not specified directly but simply inhe-
rited from the subject?s own data to avoid a possi-
bly conflicting input specification. 
The most obvious limitation to this kind of ap-
proach is the case in which there is a need to gen-
erate a sentence that does not resemble any 
example in the corpus at all. Yet again, we notice  
that this difficulty may be overcome by simply 
adding a natural language example directly to the 
corpus, a method that is arguably simpler than pro-
viding detailed instructions on how to select and 
combine template structures in a traditional tem-
plate-based approach, and even simpler than pro-
viding a full sentence specification in grammar-
based surface realization. 
The following is a complete example of how the 
example-based approach is expected to work. In its 
simplest form, the application may select the re-
quired template to produce the desired output ver-
batim as in (a); with some extra knowledge 
available, the application may also change some of 
the values of the variable template fields as in (b); 
finally, with even more complete linguistic know-
ledge available, the original structure may be 
changed even further as in (c), in which case only 
the original sentence structure remained (besides 
the canned text component ?on Friday?). 
 
Input Expected output 
 
(a) template #17 
 
[You]agent  
[should deliver]action 
[your results]patient 
on Friday. 
 
(b) template #17,  
patient=essay,  
action=not_complete 
 
[You]agent  
[did not complete]action 
[your essay]patient 
on Friday. 
 
(c) template #17, 
agent=teacher,  
determiner=possess,  
action=give, 
tense=future,  
patient=talk,  
determiner=indefinite 
 
 
[Our teacher]agent 
[will give]action 
[a talk]patient 
on Friday. 
Table 1. Examples of (semantic) input and expected 
(surface text) output. 
 
Depending on the changes in the constituent 
values requested by the application, a number of 
agreement rules may be invoked to re-establish 
fluency and grammaticality. In our work this is 
aided by a Brazilian Portuguese lexicon presented 
in Muniz et. al. (2005) and a thesaurus. For exam-
ple, if a sentence template as (d) below is selected, 
and then the value of the agent head field is 
changed to represent a singular concept as in (e), 
agreement rules are required to modify the verb 
number as in (f). 
 
(d) [All students]agent [have submitted]action  
[their papers]patient 
 
(e) [Your teacher] agent [#have submitted]action  
[their papers]patient 
 
(f) [Your teacher] agent [has submitted]action  
[their papers]patient 
 
Table 2. An original example (d) reused with a new 
agent head value (e) and agreement (f). 
 
More complex or fine-grained dependencies 
(e.g., the anaphoric reference ?their? in Table 2 
129
above) are not currently implemented. One possi-
ble approach to this is a standard generate-and-
select approach to NLG as in Langkilde (2000), Oh 
& Rudnicky (2000) and others. More specifically, 
we may over-generate all possible realization al-
ternatives and then use a statistical language model 
to select the most likely output. In our work we 
intend to apply a similar approach also to handle 
the lexical choice task, i.e., by selecting the most 
likely wording for each concept based on a lan-
guage model. 
6 Discussion 
In this paper we have described a simple approach 
to surface realization based on the reuse of syntac-
tically-structured templates acquired from corpora. 
Although not nearly as flexible as a full NLG ap-
proach, our system may represent a straightforward 
solution to the problem of input specification, 
which in our case is simply based on natural lan-
guage. Our corpus-based approach is able to gen-
erate single sentences from an input conveying 
various degrees of semantic knowledge, which 
may be suitable to a wide range of NLG applica-
tions that are able to support only less detailed in-
put specification. 
Much of the present work is however to be re-
garded as tentative. One major issue that is yet to 
be discussed is how far we can go with an exam-
ple-based approach to surface realization without 
compromising the quality of the output text. For 
instance, it is not clear what it means for the NLG 
system if the application selects a sentence tem-
plate that (in Portuguese) does not have a subject 
field (e.g., ?Please send it now?) and then attempts 
to specify a subject. A similar conflict arises, for 
example,  if the application specifies an action that 
is semantically incompatible with the selected 
template, in which case the output sentence could 
become ungrammatical. In both cases, we believe 
that more research is still needed. 
Being currently functional at a prototype level 
only, our system is undergoing a number of im-
provements. First, we are expanding the possible 
lexical choices by making use of a thesaurus, and 
then we intend to use a language model to handle 
synonymy. 
 Second, the mappings from semantic concepts 
to surface strings still need to be revised and 
adapted to the domain (questions and answers 
about students? undergraduate projects) in order to 
deploy a fully functional application.  
Finally, template selection needs improvement 
to allow for a truly minimal input specification in 
an application-friendly fashion. 
With these tasks accomplished, we will be able 
to attach a surface realization component to our 
ongoing Q&A project and generate context-
sensitive replies to students? most frequent ques-
tions. 
7 Final Remarks 
In the context of  the NAACL-HLT Young Inves-
tigators Workshop on Computational Approaches 
to Languages of the Americas, there are a number 
of ways in which our work could benefit from co-
operation with researchers in Latin America, and 
also help the development of NLP research in these 
countries. 
At the current stage, our work still relies heavily 
on a Portuguese parsed corpus and grammar, 
which may be seen being of limited interest outside 
the Brazilian NLP research community. However, 
given the close relation between Portuguese and 
other languages spoken in the region (e.g., Spanish 
and its variations), we believe that it would be a 
rewarding experience to adapt similar language 
resources (e.g., sentence templates, phrase gram-
mars etc.) that have been developed elsewhere, and 
use these resources to deploy a multilingual NLG 
application to validate our current approach.  
Beyond the usefulness to the research communi-
ties involved, we would expect that this kind of co-
operation would be an effective means of sharing 
costs and spreading the interest in NLG research 
across the region, and a much-needed motivation 
for young researchers to join the field. 
Acknowledgments 
The authors acknowledge support by FAPESP and 
CNPq. We are also thankful to the anonymous re-
viewers of the original submission, and to the or-
ganizers of the NAACL-HLT Young Investigators 
Workshop on Computational Approaches to Lan-
guages of the Americas for the travel award given 
for this presentation. 
130
References  
Bangalore, S. and O. Rambow (2000) Corpus-based 
lexical choice in natural language generation. Pro-
ceedings of the 38th Meeting of the ACL, Hong 
Kong, pp.  464-471. 
Bateman, J.A. (1997) Enabling technology for multilin-
gual natural language generation: the KPML devel-
opment environment. Natural Language Engineering, 
3(1):15?55. 
Bick, E. (2000) The parsing system PALAVRAS: au-
tomatic grammatical analysis of Portuguese in a con-
straint grammar framework. PhD Thesis, Aarhus 
University. 
DeVault, David, David Traum and Ron Arstein (2008) 
Practical Grammar-Based NLG from Examples. Pro-
ceedings of the 5th International Natural Language 
Generation Conference (INLG-2008) Columbus, 
USA. 
Gatt, Albert and Ehud Reiter (2009) SimpleNLG: A 
realization engine for practical applications. Proceed-
ings of the European Natural Language Generation 
workshop (ENLG-2009.) 
Langkilde, Irene (2000) Forest-based statistical sentence 
generation. Proceedings of the 6th Applied Natural 
Language Processing Conference and 1st Meeting of 
the North American Chapter of the Association of 
Computational Linguistics (ANLP-NAACL?00), pp. 
170?177. 
Marciniak, T. and M. Strube (2005) Using an Annotated 
Corpus As a Knowledge Source For Language Gen-
eration. Proceedings of the Corpus Linguistics?05 
Workshop Using Corpora for NLG (UNNLG-2005), 
pp. 19-24. 
McRoy, Susan, Songsak Channarukul and Syed S. Ali 
(2003) An augmented template-based approach to 
text realization. Natural Language Engineering 9 (4) 
pp. 381?420. Cambridge University Press. 
Muniz, M. C., Laporte, E., Nunes, M.G.V (2005) 
UNITEX-PB, a set of flexible language resources for 
Brazilian Portuguese. Proceedings of the III Informa-
tion and Language Technology Workshop 
(TIL-2005). 
Oh, A. and A. Rudnicky (2000) Stochastic language 
generation for spoken dialogue systems. Proceedings 
of the ANLP-NAACL 2000 Workshop on Conversa-
tional Systems, pp. 27?32. 
Ratnaparkhi, A. (2000) Trainable methods for surface 
natural language generation. Proceedings of ANLP-
NAACL 2000, pp.194?201. 
Reiter, E. (2007) An Architecture for Data-to-Text Sys-
tems. Proceedings of the European Natural Language 
Generation workshop (ENLG-2007), pp. 97-104. 
Smets, M., M.Gamon, S.Corston-Oliver and E. Ringger 
(2003) French Amalgam: A machine-learned sen-
tence realization system. Proceedings of the TALN-
2003 Conference, Batz sur-Mer, 
van Deemter, K., Emiel Krahmer and Mari?t Theune 
(2005) Real versus template-based NLG: a false op-
position? Computational Linguistics 31(1). 
Zhong, Huayan and A. J. Stent (2005) Building Surface 
Realizers Automatically from Corpora. Proceedings 
of the Corpus Linguistics?05 Workshop Using Cor-
pora for NLG, pp. 49-54. 
131
