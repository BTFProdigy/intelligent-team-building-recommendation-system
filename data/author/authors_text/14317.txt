Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 78?83,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Exploiting Rich Features for Detecting Hedges and Their Scope 
Xinxin Li, Jianping Shen, Xiang Gao, Xuan Wang 
Harbin Institute of Technology Shenzhen Graduate School 
Shenzhen, Guangdong, China 
{lixxin2, jpshen2008}@gmail.com,  
sky0306201@163.com, wangxuan@insun.hit.edu.cn 
 
Abstract 
This paper describes our system about 
detecting hedges and their scope in natural 
language texts for our participation in CoNLL-
2010 shared tasks. We formalize these two 
tasks as sequence labeling problems, and 
implement them using conditional random 
fields (CRFs) model. In the first task, we use a 
greedy forward procedure to select features for 
the classifier. These features include part-of-
speech tag, word form, lemma, chunk tag of 
tokens in the sentence. In the second task, our 
system exploits rich syntactic features about 
dependency structures and phrase structures, 
which achieves a better performance than only 
using the flat sequence features. Our system 
achieves the third score in biological data set 
for the first task, and achieves 0.5265 F1 score 
for the second task. 
1 Introduction 
In recent years, a fair amount of approaches have 
been developed on detecting speculative and 
negative information from biomedical and 
natural language texts, for its benefit to the 
applications like information extraction. These 
approaches evolve from hand-crafted rule-based 
approaches, which use regular expressions to 
match the sentences or its grammatical parsing, 
such as NegEx (Chapman et al, 2001), 
Negfinder (Mutalik et al, 2001), and 
NegExpander (Aronow et al, 1999), to machine 
learning approaches, including semi-supervised 
methods (Medlock and Briscoe, 2007; Szarvas, 
2008), and supervised methods (Morante and 
Daelemans, 2009).  
In this paper, we describe the machine 
learning system submitted to CoNLL-2010 
Shared task (Farkas et al, 2010). Our system 
formalizes these two tasks as consecutive 
sequence labeling problems, and learns the 
classifiers using conditional random fields 
approach. In the first task, a model is trained to 
identify the hedge cues in sentences, and in the 
second task, another model is used to find the 
corresponding scope for each hedge cue 
generated in the first task. Our system follows 
the study of Morante and Daelemans (2009), but 
applies more refined feature selection. In the first 
task, we use a greedy forward procedure to select 
features for the classifier. In the second task, we 
exploit rich syntactic information to improve the 
performance of the model, from dependency 
structures and phrase structures. A rule-based 
post processing procedure is used to eliminate 
the errors brought by the classifier for each task. 
The remainder of the paper is organized as 
follows. In section 2, we briefly describe the task 
and the details of our system, including how to 
select features for the hedge cue detection 
system, and how to find the corresponding scope 
for each hedge cue. The experimental results are 
discussed in section 3. In section 4 we put 
forward some conclusion. 
2 System Description  
We model these two tasks for identifying the 
hedge cues and finding their scope as two 
consecutive sequence labeling problems, such as 
chunking, segmentation and named entity 
recognition, and train the classifiers using 
conditional random fields approach (Lafferty et 
al., 2001). For each task, a post-processing 
procedure is used to refine the results from the 
classifier. 
In the first task, we detect the hedge cue by 
classifying the tokens of a sentence as being at 
the beginning of, inside or outside of the hedge 
signal. In the second task, we find the scope of a 
hedge cue by classifying the tokens of a sentence 
as being the first one of, the last one or neither of 
the scope.  
A sentence from biological full articles data 
set omitting the id number is shown below in 
Figure 1. In this sentence, there is only one 
hedge cue, the phrase ?raises an interesting 
question?, and its corresponding scope is the 
sequence from token ?raises? to token ?acid?. 
78
<sentence>This <xcope><cue>raises an 
interesting question</cue>: "Is there a 23rd 
amino acid</xcope>?".</sentence> 
 
Figure 1: A sentence with hedge cue and scope 
annotation in biological full articles data set 
2.1 Hedge detection 
Since hedge cues usually consist of one or more 
tokens, we predict the tokens in BIO 
representation, whether the token is the first 
token of a hedge cue (B-cue), inside a hedge cue 
(I-cue), or outside of the hedge cue (O-cue). For 
the sentence in Figure 1, token ?raises? is 
denoted as B-cue, tokens ?an interesting 
question? all as I-cue, and the other tokens in the 
sentence as O-cue. 
The classifier is trained using conditional 
random fields (Lafferty et al, 2001), which 
combines the benefits of conditional models with 
the global normalization of random field models, 
and avoid the label bias problem that exists in 
maximum entropy Markov models (MEMMs). 
The CRF model we use is implemented as 
CRF++ 0.51 1 . The parameters of the CRF 
classifier are set as defaults. 
We use a greedy forward procedure to select a 
better feature sets for the classifier according to 
the evaluation results in the development set. We 
first start from a basic feature set, and then add 
each feature outside the basic set and remove 
each feature inside the basic set one by one to 
check the effectiveness of each feature by the 
performance change in the development set. This 
procedure is repeated until no feature is added or 
removed or the performance is not improved. 
The selected features are listed below: 
? Cn (n=-2,-1, 0, 1, 2) 
? CnCn+1 (n=-1,0) 
? Cn-1CnCn+1 (n=-1,0,1) 
? Cn-2Cn-1CnCn+1  (n=0,1) 
Where C denote features of each token, 
including FORM, LEMMA, and POS (in Table 
1), C0 represents the feature of current token and 
Cn(C-n) represents the feature of the token n 
positions to the right (left) of current token. 
CnCn+1 denote the combination of Cn and Cn+1. So 
are Cn-1CnCn+1 and Cn-2Cn-1CnCn+1. 
 
 
                                                 
1
 http://crfpp.sourceforge.net/ 
Feature 
Name 
Description 
FORM Word form or punctuation symbol. 
LEMMA Lemma or stem of word form. 
POS Part-of-speech tag of the token. 
CHUNK Chunk tag of the token, e.g. B_NP, 
B_ SBAR, and I_NP. 
TCHUNK Chunk type of the token, e.g. NP. 
 
Table 1: Description of features of each token 
 
Although our system is based on token, chunk 
features are also important. Analyzing the 
training data set, it is shown that if one token in a 
chunk is in the hedge cue, the other tokens in the 
chunk are usually in the same hedge cue. The 
chunk feature can provide more information for 
the multiword hedge cues. The LEMMA, POS, 
and CHUNK of each token used in our system 
are determined using GENIA tagger (Tsuruoka et 
al., 2005).  
The selected CHUNK features in our system 
are listed as follows: 
? Cn (n=-3, -2,-1, 0, 1, 2, 3 ) 
? CnCn+1 (n=-3, -2,-1, 0, 1, 2, 3 ) 
? Cn-1CnCn+1  (n=-2,-1,0,1,-2) 
? Cn-2Cn-1CnCn+1 (n=-1,0,1,2) 
We can obtain the preliminary results using 
the CRF model-based classifier, but there are 
some missed or incorrectly classified hedge cues 
which can be recognized by rule-based patterns. 
Through statistical analysis on the training and 
development data sets, we obtain some effective 
rules for post processing, including: 
 
? If the first token of a NP chunk tag is 
annotated as I-cue, the whole NP chunk is 
in the hedge cues. 
? If the B-VP chunk tag of a token is 
followed by a B-SBAR chunk tag, the 
token is annotated as B-cue. 
? If token ?that? follows token ?indicate? 
and the POS of token ?that? is IN, the 
chunk tag of token ?that? is B-SBAR, then 
the ?indicate? will be annotated with B-
cue and ?that? will be annotated with I-
cue. 
? If token ?indicate? is followed by token 
?an? or token ?a?, then the token 
?indicate? is annotated as B-cue. 
79
2.2 Scope finding 
In this task, we train a classifier to predict 
whether each token in the sentence is in the 
scope by classifying them as the first one (F-
scope), the last one (L-scope), or neither 
(NONE) of the scope, which is the same as 
Morante and Daelemans (2009). For the sentence 
in Figure 1, token ?raises? is denoted as F-scope, 
token ?acid? as L-scope, and the other tokens in 
the sentence as NONE.  
After the classification, a post processing 
procedure is used to match the scope to each 
hedge, guaranteeing that each hedge has only one 
corresponding scope sequence, and must be 
inside its scope sequence. There is no cross 
between different scope sequences, but inclusion 
is allowed. The hedges are selected from the first 
task. 
The classifier is also implemented using 
conditional random fields model, and the 
parameters of the CRF classifier are set as 
defaults. We first build a set of baseline sequence 
features for the classifier, some borrowed from 
Morante and Daelemans (2009). The selected 
baseline sequence features are: 
? Of the token in focus: FORM, POS, 
LEMMA, CHUNK, TCHUNK, 
combination of FORM and POS; POS, 
LEMMA, CHUNK, TCHUNK of two 
tokens to the left and three tokens to the 
right; first word, last word, chain of 
FORM, POS of two chunks to the left and 
two chunks to the right; All combination 
of POS in the window of length less than 3; 
All combination of CHUNK in the 
window of length 2. 
? Of the left closest hedge: chain of the 
FORM, POS, LEMMA, CHUNK, and 
TCHUNK; All combination of POS and 
FORM in the window of length 2. 
? Of the right closest hedge: chain of the 
FORM, POS, LEMMA, CHUNK, and 
TCHUNK; All combination of POS and 
FORM in the window of length 2. 
? Of the tokens between the left closest 
hedge and the token in focus: chain of 
FORM, POS, LEMMA, CHUNK and 
TCHUNK; the number. 
? Of the tokens between the right closest 
hedge and the token in focus: chain of 
FORM, POS, LEMMA, CHUNK and 
TCHUNK; the number. 
? Others: the number of hedge cues in the 
sentence; the sequence relation between 
the token in focus and hedge cues (LEFT, 
RIGHT, MIDDLE, IN, NULL) 
Besides the sequence features listed above, 
syntactic features between the token in focus and 
hedge cues are explored in our classifier. Huang 
and Low (2007) notes that structure information 
stored in parse trees helps identifying the scope 
of negative hedge cues, and Szarvas (2008) 
points out that the scope of a keyword can be 
determined on the basic of syntax. Thus we 
believe that a highly accurate extraction of 
syntactic structure would be beneficial for this 
task.  
For sentences in the dataset, their dependency 
structures are extracted using GENIA 
Dependency parser (Sagae and Tsujii, 2007), and 
phrase structure using Brown self-trained 
biomedical parser (McClosky, 2009). Figure 2 
shows the corresponding dependency tree and 
Figure 3 shows the corresponding phrase 
structure tree for the sentence in Figure 1. In the 
following part in the section, we will illustrate 
these syntactic features and give examples for 
their value. We take the token ?acid? as the token 
in focus, to determine whether it is classified as 
F-scope, L-scope or NONE. 
 
 
 
Figure 2: Dependency tree of the sentence in 
Figure 1 
 
For the token ?acid? in the dependency trees 
in Figure 2, its father node is the token ?there?, 
and the dependency relation between these two 
token is ?NMOD?. 
Dependency features between the token in 
focus and the left closest hedge cue are: 
? Dependency relation of the token in 
focus to its father, left closest hedge to its 
80
father and the dependency relation pair: 
NOMD, ROOT, ROOT+NMOD. 
? Chain of POS: ->VBZ<-VBZ<-EX<-NN 
? Chain of POS without consecutive 
redundant POS: ->VBZ <-EX<-NN 
? POS of their nearest co-father: VBZ 
? Whether it is a linear relation (self, up , 
down, no): up 
? Kinship (grandfather, grandson, father, 
son, brother, self, no): no. 
? The number of tokens in the chain: 4 
Similar features are extracted for dependency 
relation between the token in focus and its right 
closest hedge cue. There is no right hedge cue for 
token ?acid?. Thus these features are set as 
?NULL?. 
 
This raises an interesting question :  " Is there a 23rd amino acid ? " .
DT VBZ DT JJ NN : NN VBZ RB DT NN NN NN . RB .
NP NP NP ADVP NP
VP
S
NP
ADVP
NP
VP
S
S
 
 
Figure 3: Phrase structure tree of the sentence in 
Figure 1 
 
Phrase structure features between the token in 
focus and its left closest hedge cue are: 
? Chain of syntactic categories: VBZ-
>VP<- NP <-NP <-S<-VP <-NP<-NN 
? syntactic categories without consecutive 
redundant ones: VBZ->VP<-NP<-S<-
VP<- NP<-NN 
? Syntactic category of their nearest co-
father: VP 
? The number of syntactic categories in the 
chain: 8 
The phrase structure features between the 
token in focus and the nearest right hedge cue are 
similar, setting as ?NULL?. 
Scope finding requires each hedge cue has 
only one corresponding scope. A hedge-scope 
pair is true positive only if the hedge cue and its 
corresponding scope are correctly identified. We 
perform the post processing procedure in 
sequence: 
? For each hedge cue from the beginning 
to the end of the sentence, find its left 
closest F-scope which has not been 
identified by other hedge cues, and 
identify it as its F-scope. 
? For each hedge cue from the end to the 
beginning of the sentence, find its right 
closest L-scope which has not been 
identified by other hedge cues, and 
identify it as its L-scope. 
? For each hedge:  
 If both its F-scope and L-scope is 
identified, then done;  
 If only its F-scope is identified, then 
its L-scope is set as L-scope of the 
last hedge cue in the sentence if it 
exists or according to the dictionary 
which we build with training data 
set; 
 If only its L-scope is identified, then 
its F-scope is set as its first token; 
 If none of its F-scope and L-scope is 
identified, then discard the hedge 
cue. 
3 Overall Results 
In this section we will present our experimental 
results for these two tasks. In the first task, the 
chief evaluation is carried on sentence level: 
whether a sentence contains hedge/weasel cue or 
not. Our system compares the performance of 
different machine learning algorithm, CRF and 
SVM-HMM on hedge cue detection. A post 
processing procedure is used to increase the 
recall measure for our system. 
In the second task, three experiments are 
performed. The first experiment is used to 
validate the benefit of dependency features and 
phrase structure features for scope finding. The 
second experiment is designed to evaluate the 
effect of abstract dataset on full article dataset. 
These two experiments are all performed using 
gold hedge cues. The performance of our scope 
finding system with predicted hedge cues is 
presented in the third experiment. 
81
3.1 Hedge detection 
The first experiment is used to compare two 
machine learning algorithms, SVM-HMM and 
CRF. We train the classifiers on abstract and full 
articles data sets. The results of the classifier on 
evaluation data set are shown in Table 2. 
 
Model Precision Recall F1 
SVM-HMM 88.71 81.52 84.96 
CRF 90.4 81.01 85.45 
 
Table 2: Results of hedge cues detection using 
CRF and SVM-HMM 
 
From Table 1, it is shown that CRF model 
outperforms SVM-HMM model in both 
precision and recall measure. The results are 
obtained without post processing. The 
experimental result with post processing is 
shown in Table 3. 
 
Feature Precision Recall F1 
Without Post 
processing 
90.4 81.01 85.45 
Post  
processing 
90.1 82.05 85.89 
 
Table 3: Result of biological evaluation data set 
without/with post processing 
 
By post processing, some mislabeled or 
incorrectly classified hedge cues can be 
recognized, especially the recall of the I-cue 
improved largely, from 55.26% to 68.51%. 
Though the precision is a little lower, the F1 
measure increases 0.44%. 
3.2 Scope finding 
To measure the benefit of syntactic features on 
scope finding task, we perform the experiment 
with different features on abstract data set, of 
which we split two-thirds as training data, and 
the other one third as testing data. The results are 
presented in Table 4. 
We take the classifier with sequence features 
as baseline classifier. From Table 4, it is shown 
that adding dependency features achieves a 
slightly better performance than the baseline 
classifier, and adding phrase structure features 
improve much better, about 1.2% F1-score. The 
classifier with all syntactic features achieves the 
best F1-score, 2.19% higher than baseline 
classifier. However, in later experiment on 
evaluation dataset after the shared task, we 
observed that dependency features actually 
harmed the performance for full articles dataset. 
 
Feature set Precision Recall F1 
Sequence  
(Baseline) 
82.20 81.61 81.90 
Sequence + 
Dependency 
82.28 82.09 82.19 
Sequence  
+ Phrase structure 
83.14 83.04 83.09 
All 84.19 83.99 84.09 
 
Table 4: Results of scope finding system with 
different feature sets on abstract data set 
 
Three experiments are designed to evaluate 
the benefit of abstract dataset for full articles 
dataset. The first one is performed on full articles 
data set, of which we split two-thirds for training, 
and the other one third for testing. The second 
experiment is trained on abstract data set, and 
evaluated on full articles data set. In the third 
experiment, we take abstract data set and one 
third of full articles as training data, and evaluate 
on the remaining full articles data set. The results 
are shown below in Table 5. 
 
Training 
data 
Testing 
data 
Prec. Recall F1 
Part Art. Part Art. 53.14 51.80 52.46 
Abs. Full Art. 54.32 54.64 54.48 
Mix Part Art. 59.59 59.74 59.66 
 
Table 5: Results of scope finding system with 
gold-standard hedge cues 
 
Results in Table 5 reveal that more abstract 
and full article dataset are added to the classifier 
as training data, better performance the system 
achieve. Thus we use the combination of abstract 
and full articles as training data for the final 
evaluation.  
Table 6 presents the results of our scope 
finding system with or without dependency 
features, using both gold-standard hedge cues 
and predicated hedge cues generated by our 
hedge cue finding system. 
Comparing the results in Table 4, 5, and 6, we 
observe that the performance of scope finding 
classifier on full article dataset is much lower 
than on abstract dataset, and dependency features 
are beneficial for the abstract dataset, but useless 
for full article dataset. We ascribe this 
phenomenon to the lack of enough full articles 
training data and the different properties of 
82
abstract and full articles data sets. Deep research 
is expected to continue. 
 
Hedge 
cues 
Dep. 
features 
Prec. Recall F1 
with 57.42 47.92 52.
24 
Predicted 
without 58.13 48.11 52.
65 
with 59.43 58.28 58.
85 
Gold 
standard 
without 60.20 58.86 59.
52 
 
Table 6: Results of scope finding system 
with/without dependency features using both 
gold-standard and predicated hedge cues 
4 Conclusion 
In this paper, we describe a machine learning 
system for detecting hedges and their scope in 
natural language texts. These two tasks are 
formalized as sequence labeling problems, and 
implemented using conditional random fields 
approach. We use a greedy forward procedure to 
select features for the classifier, and exploit rich 
syntactic features to achieve a better performance. 
In the in-domain evaluation, our system achieves 
the third score in biological data set for the first 
task, and achieves 0.5265 F1 score for the second 
task. 
 
Acknowledgments 
The authors would like to thank Buzhou Tang for 
useful discussions of the paper. This work is 
supported by the National High-tech R&D 
Program of China (863 Program, No. 
2007AA01Z194). 
References  
David B. Aronow, Fangfang Feng, and W. Bruce 
Croft. 1999. Ad Hoc Classification of Radiology 
Reports. Journal of the American Medical 
Informatics Association, 6(5):393?411. 
Wendy W. Chapman, Will Bridewell, Paul Hanbury, 
Gregory F. Cooper, and Bruce G. Buchanan. 2001. 
A Simple Algorithm for Identifying Negated 
Findings and Diseases in Discharge Summaries. 
Journal of Biomedical Informatics, 34:301?310. 
Rich?rd Farkas, Veronika Vincze, Gy?rgy M?ra, 
J?nos Csirik, and Gy?rgy Szarvas. 2010. The 
CoNLL-2010 Shared Task: Learning to Detect 
Hedges and their Scope in Natural Language Text. 
In Proceedings of the Fourteenth Conference 
on Computational Natural Language Learning 
(CoNLL-2010): Shared Task, pages 1?12.  
Yang Huang, and Henry J. Lowe. 2007. A novel 
hybrid approach to automated negation detection in 
clinical radiology reports. Journal of the 
American Medical Informatics Association, 
14(3):304?311. 
John Lafferty, Andrew McCallum, and Fernando 
Pereira. 2001. Conditional random fields: 
Probabilistic models for segmenting and labeling 
sequence data. In Proceedings of the Eighteenth 
International Conference on Machine 
Learning, pages 282?289. 
David McClosky. 2009. Any Domain Parsing: 
Automatic Domain Adaptation for Natural 
Language Parsing. Ph.D. thesis, Department of 
Computer Science, Brown University. 
Ben Medlock, and Ted Briscoe. 2007. Weakly 
supervised learning for hedge classification in 
scientific literature. In Proc. of ACL 2007, pages 
992?999. 
Roser Morante, and Walter Daelemans. 2009. 
Learning the scope of hedge cues in biomedical 
texts. In Proceedings of the Workshop on 
BioNLP, pages 28?36.  
Pradeep G. Mutalik, Aniruddha Deshpande, and 
Prakash M. Nadkarni. 2001. Use of general-
purpose negation detection to augment concept 
indexing of medical documents: a quantitative 
study using the UMLS. Journal of the American 
Medical Informatics Association, 8(6):598?609. 
Kenji Sagae, and Jun?ichi Tsujii. 2007. Dependency 
parsing and domain adaptation with LR models 
and parser ensembles. In Proceedings of the 
CoNLL-2007 Shared Task, pages 82?94 
Gy?rgy Szarvas. 2008. Hedge classification in 
biomedical texts with a weakly supervised 
selection of keywords. In Proc. of ACL 2008, 
pages 281?289, Columbus, Ohio, USA. ACL. 
Gy?rgy Szarvas, Veronika Vincze, Rich?rd Farkas, 
and J?nos Csirik. 2008. The BioScope corpus: 
annotation for negation, uncertainty and their scope 
in biomedical texts. In Proc. of BioNLP 2008, 
pages 38?45, Columbus, Ohio. ACL. 
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, 
Tomoko Ohta, John McNaught, Sophia Ananiadou, 
and Jun'ichi Tsujii. 2005. Developing a Robust 
Part-of-Speech Tagger for Biomedical Text. 
Advances in Informatics - 10th Panhellenic 
Conference on Informatics, LNCS 3746, pages 
382?392. 
83
Chinese Word Segmentation based on Mixing Multiple Preprocessor 
and CRF 
 
Jianping Shen, XuanWang, Hainan Zhao,Wenxiao Zhang  
Computer Application Research Center, Shenzhen Graduate School 
Harbin Institute of Technology Shenzhen, China, 518055 
Email: {jpshen, wangxuan,hnzhao@cs.hitsz.edu.cn}  Email: { xiaohit@126.com} 
 
Abstract 
This paper describes the Chinese Word 
Segmenter for our participation in CIPS-
SIGHAN-2010 bake-off task of Chinese 
word segmentation. We formalize the tasks 
as sequence tagging problems, and 
implemented them using conditional random 
fields (CRFs) model. The system contains two 
modules: multiple preprocessor and basic 
segmenter. The basic segmenter is designed as 
a problem of character-based tagging, and 
using named entity recognition and chunk 
recognition based on boundary to preprocess. 
We participated in the open training on 
Simplified Chinese Text and Traditional 
Chinese Text, and our system achieved one 
Rank#5 and four Rank#2 best in all four 
domain corpus. 
1 Introduction 
Word is a logical semantic and syntactic unit 
in natural language (Zhenxing Wang, 2008).  
Chinese word segmentation is very important for 
Chinese language processing, which aims to 
recognize the implicit word boundaries in 
Chinese text.  It is the foundation of most 
Chinese NLP tasks. In past decades, great 
success has been achieved in Chinese word 
segmentation (Nie, et al 1995; Wang et al 
2000;Zhang, et al 2002). But there still exist 
many problems, such as cross-domain 
performance of Chinese word segmentation 
algorithms. As the development of the internet, 
more and more new word has been appearing, 
Improving the  performance of Chinese word 
segmentation algorithms on OOV (Out-Of-
Vocabulary Word, is a word which occurs in the 
reference corpus but does not occur in the 
labeled training corpus) is the important research 
direction. Our system participated in the CIPS-
SIGHAN-2010 bake-off task of Chinese word 
segmentation. And we have done work in dealing 
with two main sub-tasks: (1) Word Segmentation 
for Simplified Chinese Text, (2) Word 
Segmentation for Traditional Chinese Text. Our 
system formalizes these tasks as consecutive 
sequence tagging problems, and learns the 
segmentation using conditional random fields 
approach. Our system contains two modules, a 
multiple preprocessor and a basic segmenter. The 
multiple preprocessor first finds chunks based on 
boundary dictionary and then uses named entity 
recognition technology to extract the person, 
location, organization and special time. The basic 
segmenter using CRF model is trained to 
segment the sentence to word which contains one 
or more characters. The basic segmenter follows 
the study of Zhenxing Wang, Changning Huang 
and Jingbo Zhu (2008), but applies more refined 
features and tags.  
The reminder of the paper is organized as 
follows. In section 2, we briefly describe the task 
and the details of our system. The experimental 
results are discussed in section 3. In section 4 we 
put forward our conclusion. 
2 System Description  
In this section we describe our system in more 
detail. The Figure1 is the frame of our system. It 
contains two modules: multiple preprocessor and 
basic segmenter. 
 
2.1 Multiple Preprocessor 
The preprocessor contain two modules: 
chunking based on boundary dictionary and NE 
Reorganization.  
2.1.1 Chunking 
In one sentence, there are always some  
characters or  words, such as ???, ???,???,?
?? ?, the character adjacent them can not  
together with them. We define these characters 
or words as boundary word. We built a boundary 
dictionary manual, which contains about 100 
words. Once a  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure1. Chinese Word Segmenter 
 
sentence input, our system finds boundary words 
in the sentence first. For example, such as, ???
??????????????? 15?? 16
?????????????. In this sentence 
we can find the boundary word??? ??? ??? ?
?? ? ???. Then chunking result is shown 
below in Figure 2. Using ?[ ]? to mark up the 
chunks. 
 
[???]  ?  [?????]  ?  [????] 
??  ?  [15?]  ?  [16?]  ?  [????] 
[??????] 
Figure 2. a sentence with chunk in data set 
 
Chunking is very useful to improve the precision 
of segmentation. Especially when lacking 
enough training corpus for training CRF model. 
It can improve the out-of-vocabulary (OOV) 
word Recall and Precision on cross-domain 
Chinese word segmentation. 
 
2.1.2 NE Recognition 
We will recognize the named entities such as 
persons, locations organizations. We perform a 
process of the named entities recognition with 
forward-backward maximum matching algorithm 
based on entity dictionary. The dictionary 
contain location dictionary, person dictionary, 
family name dictionary, organization dictionary, 
country dictionary (Jianping Shen and Xuan 
Wang, 2010). For example, a sentence, ????
???????????????????
???????????. And  the processor 
will find out the location????,????, the 
family name ??? and person ????. The NE 
recognition result is shown below in Figure 3. 
String 
Sentence 
Multiple preprocess 
Chunking 
NE Recognition 
Training data 
Train system
CRF model
System CRF 
model 
Tagging 
segmenter 
Result 
 
[??]/loc  ?????  [?]/fam  [?
?]/per  ????????  [??]/  [?
?]/org  ??????????. 
Figure 3.sentence with NE recognition in data set 
 
The location tag with ?[ ]/loc?, family name tag 
with ?[ ]/fam?, person tag with ?[ ]/per?, 
organization tag with ?[ ]/org?. 
 
2.2 Basic Segmenter 
We model the segment task as the consecutive 
sequence labeling problems, such as chunking, 
and named entity recognition, and train the basic 
segmenter using conditional random fields 
approach (Lafferty et al, 2001). 
 
2.2.1 Conditional Random Fields 
CRF models are conditional probabilistic 
sequence and undirected graphical models 
CRF models hold two natures. First is the 
conditional nature, second the exponential nature. 
The conditional nature of the distribution over 
label sequence allows CRF models to model 
real-world data in which the conditional 
probability of a label sequence can depend on 
non-independent and interacting features of the 
observation sequence. The exponential nature of 
the distribution enables features of different 
states to be traded off against each other, 
weighting some states in a sequence as being 
more important than other states. Following 
Lafferty et al and Hanna Wallach, the 
exponential distribution chosen by John Lafferty 
et al is shown as follow: 
( ) (
,
| exp( , | ,k k e
e E k
p y x f e y x? ?
?
? )?
 ( )
,
, | , )k k v
v V k
g v y x?
?
                   + ?
 
1exp( ( , , )k k i i
i k
f y y x? ?= ??
 
,( )k k i
i k
g y x?   +?? )
     (1) 
Where 
( )', 1 ', , 0 u vy y u v
if y y and y y
f y y x
otherwise
    =   =?= ?                      ?  
And 
( ), 1, 0 v vy x v
if y y and x x
g y x
otherwirse
    =   =?= ?                   ?  
In this situation, the parameters ',y y
?
and 
,y x? corresponding to these features are 
equivalent to the logarithms of the HMM 
transition and emission probabilities 
and . The parameter of the 
model can be estimated in many ways, such as 
GIS, IIS, L-BFGS etc. 
( )' |p y y ( )|p x y
 
2.2.2 Segment base on CRF model 
When a sentence or chunk (which get from the 
preprocessor) input, it will be split to the 
sequences shown in Figure 4. 
 
chunk sequence 
 
????? 
 
 
? 
? 
? 
? 
? 
Figure  4. Chunk and sequence 
Every character in input sentences will be 
given a label which indicates whether this 
character is a word boundary. Our basic 
segmenter is almost the same as the system 
described in (Zhao et al, 2006) which is learned 
from training corpus. The CRF model we use is 
implemented with CRF++ 0.51. The parameters 
of the CRF segmenter are set as defaults. 
Under the CRF tagging scheme, each 
character in one sentence will be given a label by 
CRF model to indicate which position this 
character occupies in a word. In our system, CRF 
tag set is proposed to distinguish different 
positions in the multi-character words when the 
word length is less than 6, namely 6-tag set {B, 
B2, B3, M, E, O}( Zhenxing Wang ,2008).We 
defined that B stands for the first and  E stands 
for  the last position in a multi-character word. S 
stands up a single-character word. B2 and B3 
stand for the second and the third position in a 
multi-character word. M stands for the fourth or 
more rear position in a multi-character word, 
whose length is larger than four-character. Then 
we add the entity tag set {B-entity, I-entity, E-
entity}. B-entity stands for the first character in a 
named entity, E-entity stands for the last 
character in a named entity, and I-entity stands 
for the other character in a named entity. 
We use a greedy forward procedure to select a 
better feature sets for the segementer according 
to the evaluation results in the development set. 
We first start from a basic feature set, and then 
add each feature outside the basic set and remove 
each feature inside the basic set one by one to 
check the effectiveness of each feature by the 
performance change in the development set. This 
procedure is repeated until no feature is added or 
removed or the performance is not improved. 
The selected features are listed below:  
? Cn (n=-2,-1, 0, 1, 2) 
? CnCn+1 (n=-1,0) 
? Cn-1CnCn+1 (n=-1,0,1) 
? Cn-2Cn-1CnCn+1  (n=0,1) 
Where C refer to the tag of each character, and 
C0 denotes current character and Cn(C-n) 
denotes the character n positions to the right (left) 
of current character.  
 
2.2.3 Post-processing 
We can obtain the preliminary results through 
the CRF model-based Segment, but there are 
some missed or incorrect cases for the digit, 
English word. For example ?the sighan? maybe 
segment to ?th e sig han?, so we will re-segment 
the ?th e sig han? as ?the sighan?. 
 
3 Performance and Analysis 
In this section we will present our 
experimental results for these two subtasks. For 
the Word Segmentation for Simplified Chinese 
Text subtask, comparing the performance of 
these four domains, we find that the performance 
of computer and finance are better than literature 
and medical.  We can find that the OOV RR of 
literature and medical are lower than the 
computer and finance. In the test data set, there 
are many Out-of-vocabulary(OOV), especially 
the disease. In medical domain, there are many 
diseases which do not appear in the corpus, and 
there is the proper name. The segment often 
can?t recognize disease well, so we add a post-
processing procedure, using domain dictionary 
for medicine, is used to increase the recall 
measure. The result for medical is shown in 
Table 2. 
 
 
 
domain 
 
R 
 
P 
 
F1 
 
OOV
RR 
IV 
RR 
literature 0.836 0.841 0.838 0.609 0.853
computer 
 
0.951 
 
0.951
 
0.932 
 
0.77 
 
0.983
 
medical 
 
0.839 
 
0.832
 
0.836 
 
0.796
 
0.866
 
finance 
 
0.893 
 
0.896
 
0.894 
 
0.796
 
0.902
 
 
Table  1: Performance of the four domain 
Simplified Chinese  test data set 
 
R P F1 
OOV 
RR IV RR
0.894 0.882 0.888 0.683 0.901
Table 2: Performance of medical test data set 
with post-processing using domain dictionary 
 
Word Segmentation for Traditional Chinese 
Text subtask. We use a Traditional and 
Simplified Dictionary to translate the named 
entity dictionary, boundary dictionary from 
Simplified to Traditional. And then we use our 
system to segment the traditional test data set. 
The results are shown in Table 3.  
 
domain 
 
R 
 
P 
 
F1 
 
OOV
RR 
IV 
RR 
literature 0.868 0.802 0.834 0.503 0.905
computer 
 
0.875 
 
0.829
 
0.851 
 
0.594
 
0.904
 
medical 
 
0.879 
 
0.814
 
0.846 
 
0.480
 
0.912
 
finance 
 
0.832 
 
0.760
 
0.794 
 
0.356
 
0.866
 
 
Table 3: Performance of four domain Traditional 
Chinese test data set 
4 Conclusion 
Through the CIPS-SIGHAN bakeoff, we find 
our system is effective. And at the same time, we 
also find some problems of us. Our system still 
can?t performance very good in cross-domain. 
Especially the Out-of-vocabulary (OOV) 
recognition. From the experiment we can see that 
using domain dictionary is a good idea. In the 
future we will do more work in post-processing. 
The bakeoff points out the direction for us to 
improve our system. 
 
References  
Huipeng Zhang, Ting Liu, Jinshan Ma, Xiantao 
Liao,Chinese Word Segmentation with Multiple 
Postprocessors  in HIT-IRLab, Proceedings of the 
Fourth SIGHAN Workshop on Chinese Language 
Processing, Jeju Island, Republic of Korea  
October 11-13, 2005 
Hai Zhao, Changning Huang et al 2006. Effective Tag  
Set Selection in Chinese Word Segmentation via 
Conditional Random Field Modeling. In 
Proceedings of PACLIC-20. pages 87-94. Wuhan, 
China, Novemeber. 
Zhenxing Wang; Changning Huang; Jingbo Zhu. The 
Character-based CRF Segmenter of MSRA&NEU 
for the 4th Bakeoff. The Sixth SIGHAN Workshop 
for Chinese Language was be held in conjunction 
with IJCNLP 2008, in Hyderabad, India, January 
11-12, 2008. 
Wei Jiang Jian Zhao Yi Guan Zhiming Xu. Chinese 
Word Segmentation based on Mixing Model. 
Proceedings of the Fourth SIGHAN Workshop on 
Chinese Language Processing, Jeju Island, 
Republic of Korea  October 11-13, 2005 
Nie, Jian-Yuan, M.-L. Hannan and W.-Y. Jin. 
1995.Unknown word detection and segmentation 
ofChinese using statistical and heuristic 
knowledge.Communication of COLIPS, 5(1&2): 
47-57. 
Wang, Xiaolong, Fu Guohong, Danial S.Yeung, 
James N.K.Liu, and Robert Luk. 2000. Models and 
algorithms of Chinese word segmentation. In: 
Proceedings of the International Conference on 
Artificial Intelligence (IC-AI?2000), Las Vegas, 
Nevada, USA, 1279-1284. 
Lafferty, J. and McCallum, A. and Pereira, F. 
Conditional random fields: Probabilistic models 
for segmenting and labeling sequence data. 
MACHINE LEARNING-INTERNATIONAL 
WORKSHOP THEN CONFERENCE. 2001, 282-
289 
Hanna Wallach, Efficient Training of Conditional 
Random Fields, In Proceedings of the 6th Annual 
CLUK Research Colloquium, 2002. 
