KCAT : A Korean Corpus Annotating Tool Minimizing Human 
Intervention 
Won-He Ryu, Jin-Dong Kim, l ine-Chang Rim 
Dept. of Computer Science & Engineering, 
Natural Language Processing Lab, 
Korea University 
Anam-dong 5-ga, Seongbuk-gu, Seoul, Korea 
whryu, jin, rim @nlp.korea.ac.kr 
Abstract 
While large POS(part-of-speech) annotated 
corpora play an important role in natural 
language processing, the annotated corpus 
requires very high accuracy and consistency. 
To build such an accurate and consistent 
corpus, we often use a manual tagging 
method. But the manual tagging is very 
labor intensive and expensive. Furthernaore, 
it is not easy to get consistent results from 
the humari experts. In this paper, we present 
an efficient tool lbr building large accurate 
and consistent corpora with minimal human 
labor. The proposed tool supports semi- 
automatic tagging. Using disambiguation 
rules acquired from human experts, it 
minimizes the human intervention in both 
the manual tagging and post-editing steps. 
1. Introduction 
The POS annotated corpora are very 
important as a resource of usefiil information tbr 
natural language processing. A problem for 
corpus annotation is tile trade-off between 
efficiency and accuracy. 
Although manual POS ta,,<,in,,==  is very 
reliable, it is labor intcnsive and hard to make a 
consistent POS tagged corpus. On the other hand, 
automatic ta,-,in,,>~  is prone to erroi-s Ibr 
infrequently occurring words duo to tile lack el" 
overall linguistic information. At present, it is 
ahnost impossible to construct a highly accurate 
corptls by usin<,~ an automatic taggcr~ alone. 
/ks a consequence, a semi-autonmtic ta,,,,in,~== 
method is proposed IBi corpus annotation. In 
Heui-.Seok Lira 
Information Communications Department, 
Natural Language Processing Lab, 
Chonan University 
85-1, Anseo-Dong, Chonan City, 
ChungChong-NamDo Province, Korea 
timhs@inli~com.chonan.ac.kr 
ordiriary semi-automatic tagging, an automatic 
tagger tags each word and human experts correct 
the rots-tagged words in the post-editing step. 
But, in the post-editing step, as the human expert 
cannot know which word has been annotated 
incorrectly, he must check every word in the 
whole corpus. And he lnust do the same work 
again and again for the same words in the same 
context. This situation causes as Inuch 
labor-intensive work as in manual ta<+<qlw 
In this paper, we propose a semi-automatic 
tagging method that can reduce the human labor 
and guarantee the consistent tagging. 
2o System Requivemer~ts 
To develop ari efficient tool that attempts to 
build a large accurately armotated corpus with 
minimal human labor~ we must consider the 
following requirements: 
? In order to minimize human labor, the same 
human intervention to tag and to correct the 
same word in tile same context should not be 
repeated. 
* There may be a word which was tagged 
inconsistently in the same context becatlse it 
was tagged by different human experts or at a 
different ask time. As an elticient tool, it can 
prevent tile inconsistency of tile annotated 
( I  results and ~uarantec the consistency of the 
annotated results. 
* It must provide an effective annotating 
capability lbr many unknown words in the 
whole corpus. 
1096 
3. Proposed POS Tagging ToohKCAT 
The proposed POG tagging tool is used to 
combine the manual tagging method and the 
automatic tagging method. They are integrated 
to increase the accuracy o\[" the automatic tagging 
method and to minimize the amount of tile 
human labor of thc manual tagging method. 
Figure 1 shows the overall architecture of the 
proposed tagging tool :KCAT. 
I . . . . . . . . .  I I I ~ I P I Raw (..rpus ILI 
Pos t -Fn Jcess  ~t  I re - l rocess  
( ' c J r rec t  an  ~ . . . . . . . . . . .  :~  ; . . . .  ,R  s " " . . . . . . . . . .  
- -7 - -~ i - -g  
~____~ " : . 
i ~'f::: 2aa' :ii,:n~ ...... 
Figure 1. System Architecture of KCAT 
As shown in figm'e 1, KCAT consists of 
three modules: the pre-processing module, the 
automatic tagging module, and the 
post-processing module. In the prcoprocessing 
module, the disambiguation rules are acquired 
I%m human experts. The candidate words are 
Ihe target words whose disambiguation rules are 
acquired. The candidate words can be unknown 
words and also very frequent words. In addition, 
the words with problematic ambiguity for tlle 
automatic tagger can become candidates. 
l)lsamblguation rules are acquired with minimal 
human labor using tile tool t:n'oposed in 
(Lee, 1996). In the automatic tagging naodule, the 
disambiguation rules resolve the ambiguity of 
{,'very word to which they can be applied. 
I lowever, tile rules are certainly not sufficient o 
resolve all the ambiguity of the whole words in 
file corpus. The proper tags are assigned to the 
remaining ambiguous words by a stochastic 
< t~"  c, hL l l l l an  lagger. After the automatic t, m~, a 
expert corrects tile onors o\[ the stochastic ta,me, 
The system presents the expert with the results 
of the stochastic tagger. If the result is incorrect, 
tile hulllan expel1 corrects the error and 
generates a disambiguation rule ~br the word. 
The rule is also saved in the role base in order to 
bc used later. 
3. I. l.exical Rules for Disambiguation 
There are many ambiguous words that are 
extremely difficult to resolve alnbiguities by 
using a stochastic tagger. Due to the problematic 
words, manual tagging and manual correction 
must be done to build a correct coqms. Such 
human intervention may be repeated again and 
again to tag or to correct tile same word in the 
same context. 
For example, a human expert should assign 
'Nal(flying)/Verb+Neun/Ending' to every 
'NaNemf repeatedly in the following sentences: 
" Keu-Nyeo-Neun Ha-Neul-Eul Na-Neun 
Pi-Haeng-Ki-Reul Port Ceok-i Iss-Ta." (she has 
seen a flying plane) 
"Keu-Netm lht-Nc'ul-Eul NaoNeun 
t'i-Itaeng--Ki-Reul Port Ceok-i Eops-Ta." (he has 
never seen a flying phme) 
"Keu-Netm tta-Ne,tl-Eul Na-Neun 
Pi--ttaeng--Ki-Reul Pal-Myeong-tlaess- Ta." (he 
invented a flying plane) 
In the above sentences, human experts can 
resolve the word, 'Na-Nemf with only the 
previous and ttle next lexical information: 
'fla-Neul-Eul' and 'Pi-tlaeng- Ki-Reul'. In other 
words, tile human expert has to waste time on 
tagging the same word in tile same context 
repeatedly. This inefficiency can also be 
happened in the manual correction of the 
ntis-tagged words. So, if the human expert can 
make a rule with his disambiguation knowledge 
and use it for tile same words in tile same 
context, such inefficiency can be minimized. We 
define the disambiguation rule as a lexical rule. 
Its template is as follows. 
\[P:N\] \[Current Word\] \[Context\] = \[Tagging 
P, esuh\] 
Context ? Previous words?p * Next Words?,, 
Ill tile above template, p and n mean tile 
previous and the next context size respectively. 
For the present, p and n are limited to 3. '*' 
1097 
represents the separating mark between the 
previous and next context. For example, tile rule 
\[1:1\] \[Na-,'\:lten\] \[Ha-Neul-Eld * Pi-Haeng-Ki- 
Reul\] = \[Na/(flying)/Verb i- Neun/Ending \]says 
the tag 'Nal(flying)/Verb +Neun/Ending' should 
be assigned to the word 'Na-Neun' when the 
previous word and the next word is 
'Ha-Neul-Eul' and 'Pi-Haeng-Ki-Reul'. 
Although these lexical rules cannot always 
correctly disambiguate all Korean words, they 
are enough to cover many problematic 
ambignous words. We can gain some advantages 
of using the lexical rule. First, it is very accurate 
because it refers to the very specific lexical 
information. Second, the possibility of rule 
conflict is very little even though the number of 
the rules is increased. Third, it can resolve 
problematic ambiguity that cannot be resolved 
without semantic inf'onnation(Lim, 1996). 
3.2. Lexicai Rule Acquisition 
Lexical rules are acquired for the unknown 
words and the problematic words that are likely 
to be tagged erroneously by an automatic tagger. 
Lexical rule acquisition is perlbrmed by 
following steps: 
1. The system builds a candidate list of 
words li)r which the lexical rules would be 
acquired. The candidate list is the collection 
of all examples of unknown words and 
problematic words for an automatic tagger. 
2. A human expert selects a word from the 
list and makes a lexical rule for the word. 
3. The system applies tile lexical rule to all 
examples of the selected word with same 
context and also saves the lexical rule in the 
rule base. 
4. P, epeat tile steps 2 and 3 until all 
examples of the candidate words can be 
tagged by the acquired lexical rules. 
3.3. Automatic Ta,,, in,,  
In the automatic ta,,~dn-oo ~ phase, words are 
disambiguated by using the lexical rules and a 
stochastic tagger. To armotate a word in a raw 
corpus, the rule-based tagger first searches the 
lexical rule base to find a lexical rule that can be 
nlatched with tile given context. If a matching 
rnle is found, the system assigns the result of the 
rule to the word. According to the corresponding 
rule, a proper tag is assigned to a word. With tile 
lexical rules~ a very precise tag can be assigned 
to a word. However, because the lexical rules do 
not  resolve all the ambiguity of the whole corpus, 
we must make use of a stochastic tagger. We 
employ an HMM--based POS tagger for this 
purpose(Kim,1998). The stochastic tagger 
assigns the proper tags to the ambiguous words 
afier the rule application. 
Alter disambiguating the raw corpus using 
the lexical rules and the atttomatic tagger, we 
arrive at the frilly disambiguated result. But the 
word tagged by the stochastic tagger may have a 
chance to be mis-tagged. Therefore, the 
post-processing for error correction is required 
for the words tagged by the stochastic tagger. 
3.4. Error Correction 
The human expert carries out the error 
correction task for the words tagged by a 
stochastic tagger. This error correction also 
requires tile repeatecl human labor as in the 
manual tagging. We employ the similar way of 
the rule acquisition to reduce the human labor 
needed for manual error cmTection. The results 
of the automatic tagger are marked to be 
distinguished from tile results of the rule-based 
tagger. The human expert checks the marked 
words only. If an error is found, the ht/man 
expert assigns a correct tag to the word. When 
tile expert corrects the erroneous word, tile 
system automatically generates a lexicat rule and 
stores it in tile rnle base. File newly acquired 
rule is autoinatically applied to the rest of tile 
corpus. Thus, the expert does not need to correct 
the repeated errors. 
1098 
B ........ 
A . . . J  
:~ ,?  "~; ~ ~'J ~'Y,I .:'l~ll,k! G'~(~ ~:)':'fl,q ! ! !~l))L" , l ' ) l  ,q';'.%ll.q !ll~ ~. "?1 )~:d~ 
:':} 'k L '  ~i~ tl ? r31 ,31 ?2 :~ '2'.' :~ ,:,i\[ .~ YZ. "?! :'J q l :'112j X,"~ ?t ) I -@ ~! ? I 
".'.20 t~'~tJ 2: .c Ul I '3t3b!:! I ~ :~ '~ (IM{3tl *,1 N ~ :31 ,'q ~?i ::i ; '  ?,,3 ~ :~ ~J g~ "JH G 
r.NwO}.lx* I '?v?et~a5 : !~31 W~'gf f l l  Y '~a!  t l t~0 l  adlTll ' , lLr'9~. 
r ,~ wU,t.l:<t E : '?t:S eft ~1:" 
E(';'.hTF ~ I '~ t 
,iH,'.t CH.q',~'~ Ncrs icTc~ 
, : ' I~L . IOF ' , I~qEA ~x~.'qlOL }~M~?-"-- '?I I~ "~. 
=i~I  'q 
:" Gt~i!~} 5"3~d~/t,\]HP*~:}IJ'2 
J, kt21 ~t X}el/tlt'l!3 ? N,,'JF O 
:" h!T;UIHOII !,~T?~I'I/f'g'dG.OII/JC 
:. *.;9 E ,~;.,V~.,*?.L.'EP* /EF -  GF  
~.~n ~ 7;/I, iN p .  ~,,d X 
:, ~la~ At ~I"~INhII\]-.Lt/JFB 
> @~(~,~ .. @~iNNP- ( /SS ,~ ' I /SH.  
g~ ~ 11 t,'(I ~J L~ .~,!/N N P ? Ilt Xl ~I/ JK G 
> ZI~01 M XI~/NN,-~*OtlM/Ji:B 
?H ;~?I  01 ~/NN,5 .  ~I,/.JK6 
G' Xtl ~ 7? .~tl / r,~ N 6 ? ~ ,/o K o " - . _ "  
> ~'\[?8101 gd,l> ~t' *~alDN G-0~/J  
> ~.~.  $t lVV*92/EP-~niEF - zSP 
i'~ 92XI g, ol  S'!gMtaNG.XI%VNN,3.?I/. 
> ~Xl2 J~ ~XI? J /NN? '~ I JF .O  
~ )I a~ IJ}:?_k ~ ) I /NNG -8 }/XSV-OHjLnt 
; ~.E}. 8t/VV*?)\[EP.E~/EF*/SF 
\] ~,J '_'6&}; .3} .~4j~q <?Jr 't ~r~? j  ~.II?41~.L ~> k12I > 3~t?ItG'?3 )ldlt ~"/q'41'lG.?l ', KG 
. . . . . . . . .  21 x oH,~t'~011:,11 ~,,ki~_~ ~HYj9 : ; ' .3o  x ~,-a4 ~,i1,,'i~bJ 3* /SP  ? 
. . . .  2\[_ '. f~ l _  ___ -~-~A Xll, ) lge.  131Ct1~21 2N.~gJ ~,{~0"IIM)~- . . . . . . . . . . . . .  I . . . . . . . . . .  ;111~ J 
::,~2!;,7~,-~ -~. ,~, ,~.~.  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  ~ ,~_  . . . . . .  
Figure 2. Bu i ld ing  Annotated  Corpus Usiug KCAT 
4. Application to Build Large Corpora 
Based on the proposed method~ we have 
imrdemented, a corpus--annotating tool for 
Koreart which is named as KCAT(Korean 
Corpus Annotating 'Fool). The process of 
building large corpora with KCAT is as lbllows: 
1. The lexical roles in the rule base are 
applied to a raw corpu::,. If the rule base i!; 
empty, nothing will be done. 
2. The sy,~;tem akes a candidate li';t. 
3. Ilunmn expert produces the lexical 1.ules 
for the words in the candidate list. 
4. The .~;ystem tags the corpus by using the 
lexical rHles and a stochastic t,l~,~.c~. 
5. Hunmn manually con?cots errors caused by 
the stochastic tagger, and lexical rules for 
those errors are also stored in the 
role--base. 
6. For other corpus, repeat the steps 1 
through 5. 
Figure 2 shows a screenshot f KCAT. In this 
figure, "A' window represents the list of raw 
corpus arm a "B' window contains the contcnt of 
the selected raw corpus in the window A. The 
tagging result is displayed in the window 'C'. 
Words beginning with ">' are tagged by a 
stocha,,;tic la-<,e, and the other words are ta~Eed 
by lexical rules. 
We can -et the more lexical rules as the 
ta,,,,itw process is prom-esscd. Therefore, we can 
expect that the aecunu-y and the reduction rate 
C 
of human htbor are increased a~ long as the 
tagging process is corltilmed. 
5. Experimental Results 
In order to estimate tim experimental results 
of our system, we collected the highly 
ambiguous words and frequently occurring 
words in our test corpus with 50,004 words. 
\]able I shows reductions in human intervention 
required to armotate the raw coums when we use 
lexical rules lbr the highly ambiguous words and 
the frequently occurring words respectively. The 
second colurnn shows that we examined the 
4,081 OCCLirrences of 2,088 words with tag 
choices above 7 and produced 4,081 lexical 
rules covering 4,832 occurrences of the corpl_lS. 
In this case, the reduction rate of human 
intervention is 1.5%. ~ The third column shows 
that we exalnined thc 6,845 occurrences of 511 
words with ficqucncy above 10 and produced 
6,845 lexical rules covering 15,4 l 8 occurrences 
of the corpus. In tiffs case, the reduction rate of 
human intervention is 17%. 2 
The last row in the table shows how 
intbrnmtive the rules are. We measured it by the 
inq-~iovement rate of stochastic tagging ;_!.l'l.el- the 
rules arc applied. From these experimental 
result.~;, wc can judge that rule-acquisition from 
flcquelatly occurring words is preferable. 
i (4,~., _4,(),v; l ) / 50,004 
~. ( 15,41 x-6,g~b ) / 50,004 
1099 
Table 1. Reduction in human Intervention 
I Type of word 
lbr rule 
acquisition 
Number of 
words 
Ambiguous 
words (_>7) 
Frequently 
occurring 
words (_>10) 
4832(9.6?/,,) 15418(30%) 
Number of 408 l 6845 
lexical rules 
Decrement of 1.5% 17% 
h u lll a 11 
intervention 
hnprovement 1.6% 3.7% 
of tagging 
accttracy (94.1-92.5%) (95.2-92.5%) 
Table 2 shows the results of our experiments on 
tile applicability of lexical rules. We measure it 
by the improyement rate of stochastic tagging 
alter the rules acquired from other corpus are 
applied. 
The third row shows that we annotate a training 
corpus with 10,032 words and produce 631 
lexieal rules, which can be applied to another 
test corpus to reduce tile number of the 
stochastic ta-,,in,, errors frorn 697 to 623. 3 
The ~brth and fifth row show that as the number 
of lexical rules is increased, the number of the 
errors of the tagger is decreased on the test 
corpus. 
These experilnental results demonstrate tile 
promise of gradual decrement of human 
intervention and improvement of tagging 
accuracy in annotating corpora. 
Table 2. Applicability of Lexical Rules 
Size of tile The nunaber The number of 
corpus of lexical stochastic 
roles errors 
0 0 697 
10,032 631 62.3 
20,047 136l 565 
_~( ,049 2091 538 
6. Conclusion 
The main goal of our work is to dcvelop an 
efficiclat tool which supports to build a very 
3 Our test corpus includes 10,015 words 
accurately and consistently POS annotated 
corpus with nlinilnal hunmn labor. To achieve 
the goal, we have proposed a POS ta,,-in- tool 
named KCAT which can use human linguistic 
knowledge as a lexical rule form. Once a lexical 
role is acquired, the hutnan expert doesn't need 
to spend titne in tagging the same word in the 
same context. By using the lexical roles, we 
could have very accurate and consistent results 
as well its reducing the amount of the hurnan 
labor. 
It is obvious that the more lexical roles the 
tool acquires the higher accuracy and 
consistency it achieves. But it still requires a lot 
of human labor and cost to acquire many lexical 
rules. And, as the number of the lexical rules is 
increased, the speed of rule application is 
decreased. To overcome the barriers, we try to 
find a way of rule generalization and a more 
efficient way of rule encoding scheme like the 
finite-state atttomata(Roche, 1995). 
Furthermore, we will use the distance of the 
best and second tag's probabilities to classify 
reliable automatic tagging result and unreliable 
ta,,,,in,, result(Brants, 1999). 
Refere\[Ices 
Brants~ T. Skut, W. and Uszkoreit, H. (1999) 
A),ntac'tic /hmotatio/1 of  a German N~.-*lri'Spal)e\]" 
Coums. In "Jourrlees ATALA", pp.69?76. 
Kim, J. D. Lira, H. S. and Rim, H. C. (1998) 
Morl)henle-Unit POS Tagging Mode/ 
Considering Eojeol-Spacing. In "Proc. of the 
10th ttangul and Korean Information 
Processing Conference", pp.3-8. 
Lee, J. K. (1996) Eojeol-tmit rule Based POS 
tag~in?~ with minimal human intervention. M. 
S dissertation, Dept. of Computer Science and 
Engineering, Korea Univ. 
Lira, H. S. Kim, J. D. and Rim, H. C. (1996) .4 
Korean 1)'an.@)rmation-I~axed POS Tagger 
with Lexical h!fi)rmation ojmi.vtag,4ed Eojeo\[. 
In "Proc. of the 2nd Korea-China Joint 
Symposium on Oriental Language 
Computing", pp. 119-124. 
Roche, E. and Schabes, Y. (1995)Determini.s'tic 
Part-o.f-St)eect~ Taggi/Ig with Fi//te-State 
7?aHsduc'er. Computational Linguistics, 21/2, 
pp. 227-253. 
1100 
A Syllable Based Word Recognition Model
for Korean Noun Extraction
Do-Gil Lee and Hae-Chang Rim
Dept. of Computer Science & Engineering
Korea University
1, 5-ka, Anam-dong, Seongbuk-ku
Seoul 136-701, Korea
dglee, rim@nlp.korea.ac.kr
Heui-Seok Lim
Dept. of Information & Communications
Chonan University
115 AnSeo-dong
CheonAn 330-704, Korea
limhs@infocom.chonan.ac.kr
Abstract
Noun extraction is very important for
many NLP applications such as informa-
tion retrieval, automatic text classification,
and information extraction. Most of the
previous Korean noun extraction systems
use a morphological analyzer or a Part-
of-Speech (POS) tagger. Therefore, they
require much of the linguistic knowledge
such as morpheme dictionaries and rules
(e.g. morphosyntactic rules and morpho-
logical rules).
This paper proposes a new noun extrac-
tion method that uses the syllable based
word recognition model. It finds the
most probable syllable-tag sequence of
the input sentence by using automatically
acquired statistical information from the
POS tagged corpus and extracts nouns by
detecting word boundaries. Furthermore,
it does not require any labor for construct-
ing and maintaining linguistic knowledge.
We have performed various experiments
with a wide range of variables influenc-
ing the performance. The experimental
results show that without morphological
analysis or POS tagging, the proposed
method achieves comparable performance
with the previous methods.
1 Introduction
Noun extraction is a process to find every noun in
a document (Lee et al, 2001). In Korean, Nouns
are used as the most important terms (features) that
express the document in NLP applications such as
information retrieval, document categorization, text
summarization, information extraction, and etc.
Korean is a highly agglutinative language and
nouns are included in Eojeols. An Eojeol is a sur-
face level form consisting of more than one com-
bined morpheme. Therefore, morphological anal-
ysis or POS tagging is required to extract Korean
nouns.
The previous Korean noun extraction methods are
classified into two categories: morphological analy-
sis based method (Kim and Seo, 1999; Lee et al,
1999a; An, 1999) and POS tagging based method
(Shim et al, 1999; Kwon et al, 1999). The mor-
phological analysis based method tries to generate
all possible interpretations for a given Eojeol by
implementing a morphological analyzer or a sim-
pler method using lexical dictionaries. It may over-
generate or extract inaccurate nouns due to lexical
ambiguity and shows a low precision rate. Although
several studies have been proposed to reduce the
over-generated results of the morphological analy-
sis by using exclusive information (Lim et al, 1995;
Lee et al, 2001), they cannot completely resolve the
ambiguity.
The POS tagging based method chooses the most
probable analysis among the results produced by the
morphological analyzer. Due to the resolution of the
ambiguities, it can obtain relatively accurate results.
But it also suffers from errors not only produced by a
POS tagger but also triggered by the preceding mor-
phological analyzer.
Furthermore, both methods have serious deficien-
???(Cheol-Su-neun) ????(sa-lam-deul-eul) ??(bwass-da)
??(Cheol-Su) ?(neun) ???(sa-lam-deul) ?(eul) ??(bwass-da)
??(Cheol-Su) ??(sa-lam) ?(deul) ?(eul) ?(bo) ?(ass) ?(da)
eojeol
word
morpheme
proper
 noun
 :
 
person
 name
postposition
noun
 :
 person
noun
 suffix:
 plural
postposition
verb
 :
 see
prefinal
 ending
ending
?(neun)
Figure 1: Constitution of the sentence ?(Cheol-Su saw the persons)?
cies in that they require considerable manual la-
bor to construct and maintain linguistic knowledge
and suffer from the unknown word problem. If
a morphological analyzer fails to recognize an un-
known noun in an unknown Eojeol, the POS tagger
would never extract the unknown noun. Although
the morphological analyzer properly recognizes the
unknown noun, it would not be extracted due to the
sparse data problem.
This paper proposes a new noun extraction
method that uses a syllable based word recognition
model. The proposed method does not require labor
for constructing and maintaining linguistic knowl-
edge and it can also alleviate the unknown word
problem or the sparse data problem. It finds the most
probable syllable-tag sequence of the input sentence
by using statistical information and extracts nouns
by detecting the word boundaries. The statistical in-
formation is automatically acquired from a POS an-
notated corpus and the word boundary can be de-
tected by using an additional tag to represent the
boundary of a word.
This paper is organized as follows. In Section 2,
the notion of word is defined. Section 3 presents
the syllable based word recognition model. Section
4 describes the method of constructing the training
data from existing POS tagged corpora. Section 5
discusses experimental results. Finally, Section 6
concludes the paper.
2 A new definition of word
Korean spacing unit is an Eojeol, which is delimited
by whitespace, as with word in English. In Korean,
an Eojeol is made up of one or more words, and a
word is made up of one or more morphemes. Figure
1 represents the relationships among morphemes,
words, and Eojeols with an example sentence. Syl-
lables are delimited by a hyphen in the figure.
All of the previous noun extraction methods re-
gard a morpheme as a processing unit. In order to
extract nouns, nouns in a given Eojeol should be
segmented. To do this, the morphological analysis
has been used, but it requires complicated processes
because of the surface forms caused by various mor-
phological phenomena such as irregular conjugation
of verbs, contraction, and elision. Most of the mor-
phological phenomena occur at the inside of a mor-
pheme or the boundaries between morphemes, not a
word. We have also observed that a noun belongs to
a morpheme as well as a word. Thus, we do not have
to do morphological analysis in the noun extraction
point of view.
In Korean linguistics, a word is defined as a mor-
pheme or a sequence of morphemes that can be used
independently. Even though a postposition is not
used independently, it is regarded as a word because
it is easily segmented from the preceding word. This
definition is rather vague for computational process-
ing. If we follow the definition of the word in lin-
guistics, it would be difficult to analyze a word like
the morphological analysis. For this reason, we de-
fine a different notion of a word.
According to our definition of a word, each un-
inflected morpheme or a sequence of successive
inflected morphemes is regarded as an individual
word. 1 By virtue of the new definition of a word,
we need not consider mismatches between the sur-
face level form and the lexical level one in recogniz-
ing words.
The example sentence ?  
(Cheol-Su saw the persons)? represented in Fig-
ure 1 includes six words such as ?(Cheol-Su)?,
?(neun)?, ?(sa-lam)?, ?(deul)?, ?(eul)?,
and ?(bwass-da)?. Unlike the Korean linguis-
tics, a noun suffix such as ?(nim)?, ?(deul)?, or
?(jeog)? is also regarded as a word because it is
an uninflected morpheme.
3 Syllable based word recognition model
A Korean syllable consists of an obligatory onset
(initial-grapheme, consonant), an obligatory peak
(nuclear grapheme, vowel), and an optional coda
(final-grapheme, consonant). In theory, the number
of syllables that can be used in Korean is the same as
the number of every combination of the graphemes.
2 Fortunately, only a fixed number of syllables is
frequently used in practice. 3 The amount of in-
formation that a Korean syllable has is larger than
that of an alphabet in English. In addition, there are
particular characteristics in Korean syllables. The
fact that words do not start with certain syllables
is one of such examples. Several attempts have
been made to use characteristics of Korean sylla-
bles. Kang (1995) used syllable information to re-
duce the over-generated results in analyzing conju-
gated forms of verbs. Syllable statistics have been
also used for automatic word spacing (Shim, 1996;
Kang and Woo, 2001; Lee et al, 2002).
The syllable based word recognition model is rep-
resented as a function  like the following equations.
It is to find the most probable syllable-tag sequence


 

 

  

, for a given sentence  consist-
ing of a sequence of  syllables 

 

 

  

.
1Korean morphemes can be classified into two types: un-
inflected morphemes having fixed word forms (such as noun,
unconjugated adjective, postposition, adverb, interjection, etc.)
and inflected morphemes having conjugated word forms (such
as a morpheme with declined or conjugated endings, predicative
postposition, etc.)
2
 (   ) of pure Korean syllables are pos-
sible
3Actually,   of syllables are used in the training data,
including Korean characters and non-Korean characters (e.g. al-
phabets, digits, Chinese characters, symbols).





	


 

 

 (1)
 	





 

 

 

 

(2)
Two Markov assumptions are applied in Equation
2. One is that the probability of a current syllable tag


conditionally depends on only the previous sylla-
ble tag. The other is that the probability of a cur-
rent syllable 

conditionally depends on the current
tag. In order to reflect word spacing information in
Equation 2, which is very useful in Korean POS tag-
ging, Equation 2 is changed to Equation 3 which can
consider the word spacing information by calculat-
ing the transition probabilities like the equation used
in Kim et al (1998).


  	





 

 

 	 

 

 (3)
In the equation, 	 becomes zero if the transition oc-
curs in the inside of an Eojeol; otherwise 	 is one.
Word boundaries can be detected by an additional
tag. This method has been used in some tasks such
as text chunking and named entity recognition to
represent a boundary of an element (e.g. individual
phrase or named entity). There are several possi-
ble representation schemes to do this. The simplest
one is the BIO representation scheme (Ramshaw and
Marcus, 1995), where a ?B? denotes the first item of
an element and an ?I? any non-initial item, and a
syllable with tag ?O? is not a part of any element.
Because every syllable corresponds to one syllable
tag, ?O? is not used in our task. The representation
schemes used in this paper are described in detail in
Section 4.
The probabilities in Equation 3 are estimated by
the maximum likelihood estimator (MLE) using rel-
ative frequencies in the training data. 4
The most probable sequence of syllable tags in a
sentence (a sequence of syllables) can be efficiently
computed by using the Viterbi algorithm.
4Since the MLE suffers from zero probability, to avoid zero
probability, we just assign a very low value such as 		
for an unseen event in the training data.
Table 1: Examples of syllable tagging by BI, BIS, IE, and IES representation schemes
surface level lexical level BI BIS IE IES(syllable) (morpheme/POS tag)
(yak)
(yak-sok)/nc B-nc B-nc I-nc I-nc
(sok) I-nc I-nc E-nc E-nc
(jang)
(jang-so)/nc B-nc B-nc I-nc I-nc
(so) I-nc I-nc E-nc E-nc
(in) (i)/co+ (n)/etm B-co etm S-co etm E-co etm S-co etm
(Sin)
(Sin-la-ho-tel)/nc
B-nc B-nc I-nc I-nc
(la) I-nc I-nc I-nc I-nc
(ho) I-nc I-nc I-nc I-nc
(tel) I-nc I-nc E-nc E-nc
	
(keo)
	
(keo-pi-syob)/nc
B-nc B-nc I-nc I-nc
(pi) I-nc I-nc I-nc I-nc
(syob) I-nc I-nc E-nc E-nc
(e) (e)/jc B-jc S-jc E-jc S-jc
(Jai)
(Jai-Ok)/nc B-nc B-nc I-nc I-nc
(Ok) I-nc I-nc E-nc E-nc
(i) (i)/jc B-jc S-jc E-jc S-jc
	(meon)
	(meon-jeo)/mag B-mag B-mag I-mag I-mag
(jeo) I-mag I-mag E-mag E-mag
(wa) (o)/pv+(a)/ec B-pv ec S-pv ec E-pv ec S-pv ec
(gi)
(gi-da-li)/pv+Automatic Word Spacing Using Hidden Markov Model
for Rening Korean Text Corpora
Do-Gil Lee and Sang-Zoo Lee and Hae-Chang Rim
NLP Lab., Dept. of Computer Science and Engineering, Korea University
1, 5-ka, Anam-dong, Seongbuk-ku, Seoul 136-701, Korea
Heui-Seok Lim
Dept. of Information and Communications, Chonan University
115 AnSeo-dong, CheonAn 330-704, Korea
Abstract
This paper proposes a word spacing model using
a hidden Markov model (HMM) for rening Ko-
rean raw text corpora. Previous statistical ap-
proaches for automatic word spacing have used
models that make use of inaccurate probabilities
because they do not consider the previous spac-
ing state. We consider word spacing problem as
a classication problem such as Part-of-Speech
(POS) tagging and have experimented with var-
ious models considering extended context. Ex-
perimental result shows that the performance
of the model becomes better as the more con-
text considered. In case of the same number
of parameters are used with other method, it
is proved that our model is more eective by
showing the better results.
1 Introduction
Automatic word spacing is a process to de-
cide correct boundaries between words in a sen-
tence containing spacing errors. In Korean,
word spacing is very important to increase the
readability and to communicate the accurate
meaning of a text. For example, if a sentence
\!Qt  ~??\? [?t#Q $4(Father entered the
room)" is written as \!Qt  ~??\? [?t#Q $4
(Father entered the bag)", then its meaning
is changed a lot.
There are many word spacing errors in doc-
uments on the Internet, which is the principal
source of information. To deal with these docu-
ments properly, an automatic word spacing sys-
tem is absolutely necessary. Besides, it plays
an important role as a preprocessor of a mor-
phological analyzer that is a fundamental tool
for natural language processing applications, a
postprocessor to restore line boundaries from
an OCR, a postprocessor for continuous-syllable
sentence from a speech recognition system, and
one module for an orthographic error revision
system.
In Korean, spacing unit is Eojeol. Each Eo-
jeol consists of one or more words and a word
consists of one or more morphemes. Figure
1 represents their relationships for a sentence
\o^=??  sl???`? {9%3". According to the
rules of Korean spelling, the main principle for
word spacing is to split every word in a sen-
tence. Because one morpheme may form a word
and several morphemes too, there are confusing
cases to distinguish among words. Even though
postpositions belong to words, they should be
concatenated with the preceding word. Besides,
there are many conicting (but can be permit-
ted) cases with the principles. For example,
spacing or concatenating individual nouns in-
cluding a compound noun are both considered
as right. As mentioned, word spacing is impor-
tant for some reasons, but it is di?cult for even
man to space words correctly by spelling rules
because of the characteristics of Korean and the
inconsistent rules. Especially, it is much more
confused in the case of having no inuence on
understanding the meaning of a sentence.
In this paper, we propose a word spacing
model
1
using an HMM. HMM is a widely used
statistical model to solve various NLP prob-
lems such as POS tagging(Charniak et al, 1993;
Merialdo, 1994; Kim et al, 1998a; Lee, 1999).
We regard the word spacing problem as a classi-
cation problem such as the POS tagging prob-
lem. When using an HMM for automatic word
spacing task, raw texts can be used as training
1
Strictly speaking, our model described here is an Eo-
jeol spacing model rather than a word spacing model
because spacing unit of Korean is Eojeol. But we in
this paper do not distinguish between Eojeol and word
for convenience. Therefore, we use the term \word" as
word, spacing unit in English.
  	

    	

     	 
 
Eojeol
word
morpheme
proper noun :
person name
postposition
noun : story
noun : book
postposition
verb : read
prefinal ending
ending
Figure 1: Constitution of the sentence \o^=??  sl???`? {9%3"
data. Therefore, we expect that HMM can be
applied to the task eectively without bothering
to construct training data.
2 Related Works
Previous approaches for automatic word spac-
ing can be classied into two groups: rule based
approach and statistical approach. The rule-
based approach uses lexical information and
heuristic rules(Choi, 1997; Kim et al, 1998b;
Kang, 1998; Kang, 2000). Lexical information
consists of postposition and Eomi
2
information,
a list of spaced word examples, etc. Heuristic
rules are composed of longest match or short-
est match rule, morphological rules, and error
patterns. This approach has disadvantage re-
quiring higher computational complexity than
the statistical approach. It also costs too much
in constructing and maintaining lexical informa-
tion. Most of rule-based systems use a morpho-
logical analyzer to recognize word boundaries.
Another disadvantages of rule-based approach
are resulted from using morphological analyzer.
First, if ambiguous analyses are possible, fre-
quent backtracking may be caused and many
errors are propagated by an erroneous analy-
sis. Second, results of automatic word spacing
are highly dependent on the morphological an-
alyzer; false word boundary recognition occurs
if morphological analysis fails due to unknown
words. In addition, if an erroneous word is suc-
cessfully analyzed through overgeneration, the
error cannot even be detected. Finally, if a word
2
Eomi is a grammatical morpheme of Korean which
is attached to verbal root
spacing system is used as a preprocessor of a
morphological analyzer, the same morphologi-
cal analyzing process should be repeated twice.
The statistical approach uses syllable statis-
tics extracted from large amount of corpora to
decide whether two adjacent syllables should be
spaced or not(Shim, 1996; Shin and Park, 1997;
Chung and Lee, 1999; Jeon and Park, 2000;
Kang and Woo, 2001). In contrast to the rule-
based approach, it does not require many costs
to construct and to maintain statistics because
they can be acquired automatically. It is more
robust against unknown words than rule-based
approach that uses a morphological analyzer.
A statistical method proposed in Kang and
Woo (2001) has shown the best performance so
far. In this method, word spacing probability
P (x
i
; x
i+1
), between two adjacent syllables x
i
and x
i+1
, is in Equation 1. If the probability is
greater than 0:375, a space is inserted between
x
i
and x
i+1
.
P (x
i
; x
i+1
) = 0:25  P
R
(x
i 1
; x
i
) +
0:5  P
M
(x
i
; x
i+1
) +
0:25  P
L
(x
i+1
; x
i+2
) (1)
In Equation 1, P
R
, P
M
, and P
L
denote the
probability of a space being inserted in the right,
middle, and left of the two syllables, respec-
tively. They are calculated as follows:
P
R
(x
i 1
; x
i
) =
freq(x
i 1
; x
i
; SPACE)
freq(x
i 1
; x
i
)
P
M
(x
i
; x
i+1
) =
freq(x
i
; SPACE; x
i+1
)
freq(x
i
; x
i+1
)
PL
(x
i+1
; x
i+2
) =
freq(SPACE; x
i+1
; x
i+2
)
freq(x
i+1
; x
i+2
)
In the above equations, freq(x) denotes a fre-
quency of a string x from training data, and
SPACE denotes a white space.
Similar to this method, other statistical sys-
tems usually use the word spacing probability
estimated from every syllable bigram
3
in the
corpora. They calculate the probability by com-
bining P
R
, P
M
, and P
L
and compare it with a
certain threshold. If the probability is higher
than the threshold, then a space is inserted be-
tween two syllables.
It is reported that the performance is so sensi-
tive to training data: it shows somewhat dier-
ent performance according to similarity between
input document and training data. And there is
a crucial problem in the statistical method re-
sulted from not considering the previous spacing
state. For example, consider a sentence \/BN??
?+???e?" of which correctly word spaced sen-
tence is \/BN???+? ?? e?". According to Equa-
tion 1, the word spacing probability of \??" and
\e?" will be calculated as follows:
P (??;e?) = 0:25  P
R
(?+?;??) + 0:5  P
M
(??;e?)
+ 0:25  P
L
(e?;)
The probability P
R
(?+?;??) as follows:
P
R
(?+?;??) =
freq(?+?;??; SPACE)
freq(?+?;??)
But a space should have been inserted be-
tween \?+?" and \??" in the correct sentence,
we should use freq(SPACE;??; SPACE) in-
stead of freq(?+?;??; SPACE) in order to get
the correct word spacing probability. This phe-
nomenon comes from not considering the previ-
ous spacing state. To alleviate this problem, we
can consider the previous spacing state that the
system has decided before. But errors can be
propagated from the previous false word spac-
ing result. Eventually, to avoid such propagated
errors, the system has to generate all possible in-
terpretations from a given sentence and choose
the best one. To choose the best state from all
possible states, we use an HMM in this paper.
3
syllable bigram is dened to be any combination of
two syllables with or without a space.
3 Word Spacing Model based on
Hidden Markov Model
POS tagging is the most representative area
for HMM. Before explaining our word spacing
model using HMM, let's consider the POS tag-
ging model using an HMM. POS tagging func-
tion  (W ) is to nd the most likely sequence
of POS tags T = (t
1
; t
2
; : : : ; t
n
) for a given sen-
tence of words W = (w
1
; w
2
; : : : ; w
n
) and is de-
ned in Equation 2:
 (W )
def
=
argmax
T
P (T j W ) (2)
= argmax
T
P (T )P (W j T )
P (W )
(3)
= argmax
T
P (T )P (W j T ) (4)
= argmax
T
P (T;W ) (5)
Using Bayes' rule, Equation 2 becomes Equa-
tion 3. Since P (W ) is a constant for T , Equa-
tion 3 is transformed into Equation 4.
The probability P (T;W ) is broken down into
the following equations by using the chain rule:
P (T;W ) = P (t
1;n
; w
1;n
) (6)
=
n
Y
i=1
 
P (t
i
j t
1;i 1
; w
1;i 1
)
P (w
i
j t
1;i
; w
1;i 1
)
!
(7)

n
Y
i=1
P (t
i
j t
i K;i 1
)P (w
i
j t
i
) (8)
Markov assumptions (conditional indepen-
dence) used in Equation 8 are that the prob-
ability of a current tag t
i
conditionally depends
on only the previous K tags and that the prob-
ability of a current word w
i
conditionally de-
pends on only the current tag. In Equation 8,
P (t
i
j t
i K;i 1
) is called transition probability
and P (w
i
j t
i
) is called lexical probability. Mod-
els are classied in terms of K. The larger K
is, the more context can be considered. Because
of the data sparseness problem, bigram model
(K is 1) and trigram model (K is 2) are used in
general.
The word spacing problem can be consid-
ered similar to POS tagging. We dene a
word spacing task as a task to nd the most
likely sequence of word spacing tags T =
(t
1
; t
2
; : : : ; t
n
) for a given sentence of syllables
S = (s
1
; s
2
; : : : ; s
n
). Our word spacing model is
dened as in Equation 9:
argmax
T
P (T j S) (9)
Word spacing tag is a tag to indicate whether
the current syllable and the next one should
be spaced or not. Tag, 1 means that a space
should be put after the current syllable. Tag,
0 means that the current and the next syllable
should not be spaced. For example, if we at-
tach the word spacing tags to a sentence \/BN??
?+? ?? e?. (I can study)", then it is tagged as
\/BN/0+??/0+?+?/1+??/1+e?/0+/0+./1".
Our proposed word spacing model is to nd
the tag sequence T for maximizing the proba-
bility P (T; S).
P (T; S )
= P (t
1;n
; s
1;n
) (10)
=

P (t
1
)  p(s
1
j t
1
)



P (t
2
j t
1
; s
1
)  P (s
2
j t
1;2
; s
1
)


 
P (t
3
j t
1;2
; s
1;2
)
P (s
3
j t
1;3
; s
1;2
)
!
   

 
P (t
n
j t
1;n 1
; s
1;n 1
)
P (s
n
j t
1;n
; s
1;n 1
)
!
(11)
=
n
Y
i=1
 
P (t
i
j t
1;i 1
; s
1;i 1
)
P (s
i
j t
1;i
; s
1;i 1
)
!
(12)

n
Y
i=1
 
P (t
i
j t
i K;i 1
; s
i J;i 1
)
P (s
i
j t
i L;i
; s
i I;i 1
)
!
(13)
There are two Markov assumptions in Equa-
tion 13. One is that the probability of a current
tag t
i
conditionally depends on only the previ-
ous K (word spacing) tags and the previous J
syllables. The other is that the probability of
a current syllable s
i
conditionally depends on
only the previous L tags, the current tag t
i
, and
the previous I tags. This model is denoted by
(T
(K:J)
; S
(L:I)
). Similar to the POS tagging
model, P (t
i
j t
i K;i 1
; s
i J;i 1
) is called tran-
sition probability, and P (s
i
j t
i L;i
; s
i I;i 1
) is
called syllable probability in Equation 13. On
the other hand, our word spacing model uses
less strict Markov assumptions to consider a
larger context. The larger the values of K, J ,
L, and I are, the more context can be consid-
ered. In order to avoid the data sparseness and
excessively increasing parameters of a model, it
is important to select proper values. In our cur-
rent work, they are restricted as follows:
0  K;J; L; I  2
Thus, 3333 = 81 models are possible. But
we do not use the case of (K;J) = (0; 0) in the
trasition probabilities. As a result, we actually
use 72 models. It has not yet been known that
which model is the best. We can verify this only
by means of experiments. Some possible models
and their equations are listed in Table 1.
Probabilities can be estimated simply by the
maximum likelihood estimator (MLE) from raw
texts. The syllable probabilities and the tran-
sition probabilities of the model (T
(1:2)
; S
(1:2)
)
are estimated as follows:
P
MLE
(t
i
j t
i 1
; s
i 2;i 1
)
=
freq(s
i 2
; t
i 1
; s
i 1
; t
i
)
freq(s
i 2
; t
i 1
; s
i 1
)
P
MLE
(s
i
j t
i 1;i
; s
i 2;i 1
)
=
freq(s
i 2
; t
i 1
; s
i 1
; t
i
; s
i
)
freq(s
i 2
; t
i 1
; s
i 1
; t
i
)
To avoid zero probability, we just set very low
value such as 0:00001 if an estimated probability
is 0.
The probability that the model
(T
(1:1)
; S
(0:1)
) outputs \/BN/0+??/0+?+?/1+
??/1+e?/0+/0+./1" from a sentence \/BN??
?+???e?." is calculated as follows:
P (T; S) = P (t
0
= 0 j s
 1
= $; t
 1
= 1)
 P (s
0
=/BN j s
 1
= $; t
0
= 0)
 P (t
1
= 0 j s
0
=/BN; t
0
= 0)
 P (s
1
=?? j s
0
=/BN; t
1
= 0)
 P (1 j??0)  P (?+? j??1)
 P (1 j?+?1)  P (?? j?+?1)
 P (0 j??1)  P (e? j??0)
 P (0 je?0)  P ( je?0)
 P (1 j0)  P (. j1)
\$" is a pseudo syllable which denotes the start
of a sentence, and its tag is always 1.
4
The
4
Because any two adjacent sentences should always
be spaced.
Table 1: Some models and their equations
Model Equation
(T
(1:0)
; S
(0:0)
)
Q
n
i=1
P (t
i
j t
i 1
)  P (s
i
j t
i
)
(T
(1:1)
; S
(0:1)
)
Q
n
i=1
P (t
i
j t
i 1
; s
i 1
)  P (s
i
j t
i
; s
i 1
)
(T
(1:1)
; S
(1:1)
)
Q
n
i=1
P (t
i
j t
i 1
; s
i 1
)  P (s
i
j t
i 1;i
; s
i 1
)
(T
(1:2)
; S
(1:2)
)
Q
n
i=1
P (t
i
j t
i 1
; s
i 2;i 1
)  P (s
i
j t
i 1;i
; s
i 2;i 1
)
(T
(2:2)
; S
(2:2)
)
Q
n
i=1
P (t
i
j t
i 2;i 1
; s
i 2;i 1
)  P (s
i
j t
i 2;i
; s
i 2;i 1
)
most probable sequence of word spacing tags is
e?ciently computed by using the Viterbi algo-
rithm.
4 Experimental Results
We used balanced 21st Century Sejong Project's
raw corpus of 26 million word size. As the bal-
anced corpus is used as training data, we ex-
pect that the performance would not be sensi-
tive too much to a certain document genre. The
ETRI POS tagged corpus of 288,269 word size
was used for evaluation. We modied the cor-
pus with no word boundary form for automatic
word spacing evaluation.
We used three kinds of evaluation measures:
syllable-unit accuracy (P
syl
), word-unit recall
(R
word
), and word-unit precision (P
word
). The
word-unit recall is the rate of the number of cor-
rectly spaced words compared to the number of
total words in a test document. The word-unit
precision measures how accurate the system's
results are. The reason why we do not divide the
syllable-unit accuracy as recall and precision is
that the number of syllables in a document and
that of the system created are the same. Each
measure is dened as follows:
P
syl
=
S
correct
S
total
 100(%)
R
word
=
W
correct
W
Dtotal
 100(%)
P
word
=
W
correct
W
Stotal
 100(%)
Where, S
correct
is the number of correctly
spaced syllables, S
total
is the total number of
syllables in a document, W
correct
is the number
of correctly spaced words, W
Dtotal
is the total
number of words in a document, and W
Stotal
is
the total number of words created by a system.
To investigate every model, we calculated the
two accuracies for dierent K, J , L, and I. Ac-
curacies for each model are listed in Table 2.
According to the experimental results, we
are sure that models considering more contexts
show better results. The model (T
(2:2)
; S
(1:2)
)
is the best for all measures.
Note that some models show the better ac-
curacies than the model (T
(2:2)
; S
(2:2)
), which
uses the largest context. It seems that this is
caused by sparseness of data. After evaluat-
ing the method of Kang and Woo (2001) for
our training and test data, it shows 93:06%
syllable-unit accuracy, 76:71% word-unit recall,
and 67:80% word-unit precision. Compared
with these results, our model shows much better
performance. If I is two in (S
(K:J)
; T
(L:I)
), syl-
lable trigrams are used. Although I is less than
two (such as the model (T
(2:1)
; S
(1:1)
, which
uses syllable bigrams), our model is better than
Kang and Woo (2001)'s. This fact tells us that
our model is also more eective even when used
the same number of parameters of the model.
There are two questions that we want to
know about the word spacing models: First,
how much training data is required to get the
best performance of a given model. Second,
which model best ts a given training cor-
pus. To answer these questions, we compare
the performance of various models according to
the size of training corpus in Figure 2. The
left plot shows the syllable-unit precision and
the right plot shows the word-unit precision.
In the gure, \HMM" denotes the proposed
model, and its number decides the model's
type. \Kang" denotes Kang and Woo (2001)'s
model. \HMM2110" uses syllable unigrams,
\HMM2111" and \Kang" use syllable bigrams,
and \HMM2212" uses syllable trigrams. The
models used here are the models that show the
best accuracies among the models that use same
Table 2: Experimental results according to (K, J , L, I)
Model P
syl
R
word
P
word
Model P
syl
R
word
P
word
Model P
syl
R
word
P
word
(0,1,0,0) 84.26 41.28 44.06 (0,1,0,1) 88.93 55.38 57.10 (0,1,0,2) 88.45 53.83 55.88
(0,1,1,0) 89.44 56.91 61.34 (0,1,1,1) 95.58 79.31 82.58 (0,1,1,2) 95.74 79.76 83.68
(0,1,2,0) 84.44 42.15 47.02 (0,1,2,1) 92.86 70.26 71.63 (0,1,2,2) 94.97 76.90 79.45
(0,2,0,0) 85.48 45.65 47.52 (0,2,0,1) 88.93 56.24 57.21 (0,2,0,2) 89.59 58.23 59.88
(0,2,1,0) 90.22 59.12 63.74 (0,2,1,1) 95.60 79.26 82.94 (0,2,1,2) 95.92 80.41 84.56
(0,2,2,0) 86.46 47.62 52.15 (0,2,2,1) 93.44 72.06 73.90 (0,2,2,2) 95.22 77.84 80.59
(1,0,0,0) 85.75 47.05 48.96 (1,0,0,1) 90.24 60.73 62.20 (1,0,0,2) 89.74 58.68 61.09
(1,0,1,0) 89.28 59.80 59.98 (1,0,1,1) 95.64 81.17 81.81 (1,0,1,2) 95.90 81.50 83.56
(1,0,2,0) 82.85 45.10 45.38 (1,0,2,1) 93.30 73.04 73.39 (1,0,2,2) 94.94 77.52 78.88
(1,1,0,0) 85.83 49.95 50.43 (1,1,0,1) 90.96 63.18 64.89 (1,1,0,2) 90.21 62.99 62.58
(1,1,1,0) 89.85 61.47 62.80 (1,1,1,1) 96.15 82.88 84.10 (1,1,1,2) 96.17 82.67 84.86
(1,1,2,0) 84.21 49.44 49.29 (1,1,2,1) 94.07 75.54 76.87 (1,1,2,2) 95.62 80.32 82.13
(1,2,0,0) 87.21 54.25 54.85 (1,2,0,1) 90.83 63.34 64.59 (1,2,0,2) 91.54 66.39 67.00
(1,2,1,0) 90.74 64.14 65.63 (1,2,1,1) 96.07 82.44 84.09 (1,2,1,2) 96.39 83.51 85.91
(1,2,2,0) 86.96 55.50 55.95 (1,2,2,1) 94.67 77.53 79.28 (1,2,2,2) 95.90 81.39 83.42
(2,0,0,0) 86.18 50.25 51.42 (2,0,0,1) 90.44 61.97 63.61 (2,0,0,2) 89.77 61.52 62.17
(2,0,1,0) 89.49 61.07 61.32 (2,0,1,1) 95.83 82.11 82.73 (2,0,1,2) 95.91 82.09 83.39
(2,0,2,0) 83.37 46.52 47.15 (2,0,2,1) 93.55 73.91 74.63 (2,0,2,2) 95.03 78.36 78.96
(2,1,0,0) 86.51 52.60 53.46 (2,1,0,1) 91.10 64.81 65.85 (2,1,0,2) 90.69 65.11 65.10
(2,1,1,0) 90.34 64.04 64.90 (2,1,1,1) 96.29 83.73 84.74 (2,1,1,2) 96.28 83.43 85.21
(2,1,2,0) 85.07 52.32 52.63 (2,1,2,1) 94.31 76.69 77.82 (2,1,2,2) 95.91 81.51 83.45
(2,2,0,0) 88.58 58.94 59.84 (2,2,0,1) 91.78 67.07 68.32 (2,2,0,2) 92.44 69.88 70.54
(2,2,1,0) 91.65 67.82 69.14 (2,2,1,1) 96.26 83.46 84.88 (2,2,1,2) 96.69 84.93 86.82
(2,2,2,0) 88.97 61.20 62.28 (2,2,2,1) 95.01 78.99 80.60 (2,2,2,2) 96.04 82.05 83.96
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
10000 100000 1e+06 1e+07
sy
lla
bl
e-
un
it 
pr
ec
isi
on
 (%
)
size of training corpus (# of words)
HMM2110
HMM2111
HMM2212
Kang
20
25
30
35
40
45
50
55
60
65
70
75
80
85
10000 100000 1e+06 1e+07
w
o
rd
-u
ni
t p
re
cis
io
n 
(%
)
size of training corpus (# of words)
HMM2110
HMM2111
HMM2212
Kang
Figure 2: Accuracies according to the size of training corpus
syllable ngrams.
We can observe the changes of the accura-
cies according to the size of the training data.
\HMM2110" using syllable unigrams converges
quickly on small training data. \HMM2111"
and \Kang" using syllable bigrams converge
on much more training data. Note that
\HMM2212" does not converge in these plots.
Therefore, there is a possibility of improve-
ment of this model's performance on more large
training data. \HMM2212" shows lower per-
formance than other models on small training
data. The reason is that the data sparseness
problem occurs.
5 Conclusion
Recently, text resources available from the In-
ternet have been rapidly increased. However,
there are many word spacing errors in those re-
sources, which cannot be used before correct-
ing errors. Therefore, the need for automatic
word spacing system to rene text corpora has
been raised. In this paper, we have proposed an
automatic word spacing model using an HMM.
Our method is a statistical approach and does
not require complex processes and costs in con-
structing and maintaining lexical information
as in the rule-based approach. The proposed
model can eectively solve the word spacing
problem by using only syllable statistics auto-
matically extracted from raw corpora. Accord-
ing to the experimental results, our model shows
higher performance than the previous method
even when using the same number of parame-
ters. We used just MLE to estimate probability,
but the more a model extends the context; the
more the data sparseness problem may arise.
In future work, we plan to adopt a smoothing
technique to increase the performance. Further
research on an eective evaluation method for
conicting cases is also necessary.
References
E. Charniak, C. Hendrickson, N. Jacobson, and
M. Perkowitz. 1993. Equations for part-of-
speech tagging. In National Conference on
Articial Intelligence, pages 784{789.
J.-H. Choi. 1997. Automatic Korean spacing
words correction system with bidirectional
longest match strategy. In Proceedings of the
9th Conference on Hangul and Korean Infor-
mation Processing, pages 145{151.
Y.-M. Chung and J.-Y. Lee. 1999. Automatic
word-segmentation at line-breaks for Korean
text processing. In Proceedings of the 6th
Conference of Korea Society for Information
Mangement, pages 21{24.
N.-Y. Jeon and H.-R. Park. 2000. Automatic
word-spacing of syllable bi-gram information
for Korean OCR postprocessing. In Proceed-
ings of the 12th Conference on Hangul and
Korean Information Processing, pages 95{
100.
S.-S. Kang and C.-W. Woo. 2001. Automatic
segmentation of words using syllable bigram
statistics. In Proceedings of the 6th Natural
Language Processing Pacic Rim Symposium,
pages 729{732.
S.-S. Kang. 1998. Automatic word-
segmentation for Hangul sentences. In
Proceedings of the 10th Conference on
Hangul and Korean Information Processing,
pages 137{142.
S.-S. Kang. 2000. Eojeol-block bidirectional
algorithm for automatic word spacing of
Hangul sentences. Journal of the Korea In-
formation Science Society, 27(4):441{447.
J.-D. Kim, H.-S. Lim, S.-Z. Lee, and H.-C. Rim.
1998a. Twoply hidden markov model: A Ko-
rean pos tagging model based on morpheme-
unit with word-unit context. Computer Pro-
cessing of Oriental Languages, 11(3):277{290.
K.-S. Kim, H.-J. Lee, and S.-J. Lee. 1998b.
Three-stage spacing system for Korean in
sentence with no word boundaries. Journal
of the Korea Information Science Society,
25(12):1838{1844.
S.-Z. Lee. 1999. New statistical models for au-
tomatic part-of-speech tagging. Ph.D. thesis,
Korea University.
B. Merialdo. 1994. Tagging english text with a
probabilistic model. Computational Linguis-
tics, 20(2):155{172.
Kwangseob Shim. 1996. Automated word-
segmentation for Korean using mutual infor-
mation of syllables. Journal of the Korea In-
formation Science Society, 23(9):991{1000.
J.-H. Shin and H.-R. Park. 1997. A statisti-
cal model for Korean text segmentation using
syllable-level bigrams. In Proceedings of the
9th Conference on Hangul and Korean Infor-
mation Processing, pages 255{260.
