Reconciling Initiative and Discourse Structure
Susan E. Strayer and Peter A. Heeman
Department of Computer Science and Engineering
OGI School of Science and Engineering
Oregon Health & Science University
20000 NW Walker Rd Beaverton, OR 97006, USA
susan strayer@yahoo.com heeman@cse.ogi.edu
Abstract
In this paper we consider how ini-
tiative is managed in dialogue. We
propose that initiative is subordi-
nate to the intentional hierarchy of
discourse structure. In dialogues
from the TRAINS corpus we nd
that inside a segment initiated by
one speaker, the other speaker only
makes two types of contributions: a
special kind of acknowledgment we
call forward acknowledgments, and
short contributions that add content
to the segment. The proposal has
important implications for dialogue
management: a system only needs
to model intentional structure, from
which initiative follows.
1 Introduction
The dialogue manager of a spoken language
system is responsible for determining what
contributions a system can make and when it
can make them. The question is, what should
the dialogue manager pay attention to in or-
der to accomplish this? Two areas of research
have shaped our understanding of what hap-
pens in dialogue: research in dialogue struc-
ture and in mixed initiative.
Grosz and Sidner (1986) proposed a theory
of discourse structure to account for why an
utterance was said and what was meant by it.
Their theory has three components: linguis-
tic structure, intentional structure and atten-
tional state. Intentions are key to accounting
for discourse structure, dening discourse co-
herence, and \providing a coherent conceptu-
alization of the term `discourse' itself." The
intentional structure describes the purpose of
the discourse as a whole, and the relation-
ship of the purpose of each discourse seg-
ment to the main discourse purpose or other
discourse segment purposes. All utterances
within a segment contribute to the purpose
of that segment. This theory, however, does
not comment on initiative within the segment.
Nor does it specify when and how speakers
should start a segment or end the current one.
Hence, it underspecies what speakers can do
in dialogue.
Research in initiative works to account for
which speaker is driving the conversation at
any given point. For example, in a question-
answer pair, the speaker asking the question
is said to have the initiative (Whittaker and
Stenton, 1988; Walker and Whittaker, 1990;
Novick and Sutton, 1997). Whittaker and
Stenton segmented dialogues where initiative
shifts from one speaker to the other. They
found that initiative "did not alternate from
speaker to speaker on a turn by turn basis,
but that there were long sequences of turns in
which [initiative] remained with one speaker.
In a mixed initiative system, the dialogue
manager needs to track initiative in order to
know when the system should add signicant
content, and when it should let the user take
over. However, no theory has oered a good
account of why a speaker would want to take
the initiative, or keep it once they have it.
In the rest of this paper we rst describe
previous work in discourse structure and in
initiative and describe our coding of them.
Next, we explore the relationship between dis-
course structure and initiative. As previous
studies have found (Whittaker and Stenton,
1988; Walker and Whittaker, 1990), there is
a close correlation between them, but the re-
lationship is not direct. We then explore how
initiative can shift within a subdialogue and
nd two types of contributions that a speaker
can make in a discourse segment: a special
kind of acknowledgment we call forward ac-
knowledgment, and short contributions that
add content to the segment. We propose that
initiative is subordinate to intentional struc-
ture. Additionally, our proposal is better able
to account for question-answer pairs and how
initiative returns to the original speaker after
an embedded subdialogue. It will have impor-
tant implications for dialogue management: a
system only needs to model intentional struc-
ture, from which initiative follows.
2 Discourse Structure and
Initiative Analysis
Our proposal for managing initiative builds
on two main areas of research, discourse struc-
ture and initiative. We start by discussing
the work of Grosz and Sidner (1986), which
ties speaker's intentions to linguistic struc-
ture, then discuss the work of Whittaker, et
al. in initiative. We introduce our coding
of three dialogues in the TRAINS corpus,
a corpus of human-human task-oriented di-
alogues, in which two participants work to-
gether to formulate a plan involving the man-
ufacture and transportation of goods (Allen et
al., 1995; Heeman and Allen, 1995). In these
dialogues, one speaker is the user (u), who has
a goal to solve, and the other speaker is the
system (s), who knows the detailed informa-
tion involved in how long it takes to ship and
manufacture goods.
2.1 Discourse Structure
Discourse structure is used to analyze dia-
logue from the top down, starting with the
purpose of the discourse as a whole, then the
purpose of each discourse segment, in order to
understand how each utterance ts into the
dialogue. The theory of discourse structure
developed by Grosz and Sidner (1986) pro-
poses that discourse structure is made up of
three components: linguistic structure, inten-
tional structure, and attentional state. Our
work focuses on the rst two components.
The linguistic structure is a hierarchical seg-
mentation of the dialogue into discourse seg-
ments. Segment boundaries are identied by
changes in tense and aspect, pause lengths,
speech rate, and discourse markers, such as
\anyway," \by the way," \so," and \rst of
all." The intentional structure is a hierarchy
of segment purposes. Each discourse segment
has a purpose, and the purpose of each seg-
ment contributes to the purpose of its parent.
Intentional structure is key to understanding
what the discourse is about and explains its
coherency.
Subdialogue coding: In our study, the
rst author segmented dialogues into subdi-
alogues based on the purpose of the utter-
ance (Smith and Gordon, 1997; Traum and
Hinkelman, 1992). We established two classes
of subdialogues: task subdialogues, segments
that describe subtasks in the dialogue, and
clarication subdialogues, local segments that
clarify a gap in understanding, either to re-
quest missing information or to supply miss-
ing information to the other speaker. The seg-
ment initiator gives the rst utterance in the
segment and establishes its purpose.
1
The
left side of Figure 1 gives an example of a
discourse segment (or subdialogue) with two
embedded clarication subdialogues, and the
segment initiator for each subdialogue. Gen-
erally, we found the dialogue structure in the
dialogues we analyzed to be quite at, with
few embedded structures. Typically, task
subdialogues occurred at the same level, and
clarication subdialogues were embedded in
a task subdialogue, as seen in the example in
Figure 1.
2.2 Initiative
Initiative is held by the speaker who is driv-
ing the conversation at any given point in the
conversation (Whittaker and Stenton, 1988,
1
The segment initiator corresponds to the initi-
ating conversational participant (ICP) of Grosz and
Sidner's theory. The non-initiator corresponds to the
other conversational participant (OCP).
Segment
Initiator Speaker Utterance Initiative
u u where pick up um one of the tankers there umph- with uh oranges that
will be used
u
s mm-hm
u for the t- u
s s okay to move the oranges we need a boxcar s
u okay
u we'll bring a boxcar from Elmira with the engine three u
s okay
u um so we'll get to Corning with the engine three and the boxcar will get
to Corning and we'll pick up uh
u
u u can a tanker and a boxcar be pulled by an engine u
s yes
u so okay so we'll pick up a tank of uh the tanker of OJ orange- oranges u
s ok- right
Figure 1: Example of Discourse Structure and Initiative Segments (d921-5.2: utt25-utt36).
Walker and Whittaker, 1990; Novick and Sut-
ton, 1997). It has been used to analyze dis-
course from the bottom up, starting with
utterances. We start with adjacency pairs
(Scheglo and Sacks, 1973), which consist of a
rst part, uttered by one of the speakers, and
a second part, uttered by the other. The rst
part sets up expectations for the second part,
and hence the speaker of the rst part can be
viewed as being in control of the dialogue dur-
ing both parts of the adjacency pair. Below
we give the annotation scheme used by Whit-
taker, et al (Whittaker and Stenton, 1988;
Walker and Whittaker, 1990) for annotating
initiative based on utterance type.
Assertions: Declarative utterances used to
state facts. The speaker has initiative,
except when it is a response to a ques-
tion.
Questions: Utterances intended to elicit in-
formation from others. The speaker has
initiative, except when it follows a ques-
tion or command.
Commands: Intended to induce actions in
others. The speaker has initiative.
Prompts: Utterances with no propositional
content (e.g., \yeah," \okay"). These ut-
terances do not exhibit initiative.
Whittaker and Stenton used the initiative
codings as a basis for segmenting dialogues.
They used dialogues between an expert and
a client about diagnosing and repairing soft-
ware faults. They found that not only did
initiative pass back and forth between the
speakers (unlike single-initiative dialogues),
but that initiative often stayed with a speaker
for on average of eight speaker turns.
Whittaker and Stenton (1988) looked at the
correlation of control boundaries to discourse
markers, and Walker and Whittaker (1990)
looked at anaphoric reference. These are the
same kinds of linguistic evidence that Grosz
and Sidner (1986) said marks discourse seg-
ment boundaries. In fact, Walker and Whit-
taker claimed that initiative segments are the
discourse segments of Grosz and Sidner's the-
ory, with the speaker with initiative being the
initiator of the segment, who establishes the
discourse segment purpose. However, they ac-
knowledged that \there can be topic shifts
without change of initiation, change of [ini-
tiative] without topic shift." In fact, when
we look at the dialogue excerpt given in Fig-
ure 1, we see that the initiative segmentation
identied the rst subdialogue, but not the
second. However, Walker and Whittaker did
not specify the relationship between initiative
and discourse structure.
Initiative coding In our study, the rst
author coded initiative using the annotation
scheme of Whittaker and Stenton (1988). The
right side of Figure 1 shows the annotation for
utterances where speakers demonstrate initia-
tive. For utterances where the speaker does
Table 1: Correlation of Segment Boundaries
Initiative vs Segment Initiator Initiative vs
Subdialogue vs Subdialogue Segment Initiator
Boundaries 113 113 46
Hits 47 46 41
Misses 66 67 5
False Positives 35 0 41
Recall 42% 41% 89%
Precision 57% 100% 50%
not demonstrate initiative, initiative is said to
belong to the last speaker that demonstrated
it. Hence, when the system uttered \mm-
hm" in the second utterance, which does
not demonstrate initiative, initiative does not
change from the user. We also show initia-
tive segment boundaries, which are identied
by changes in initiative. Here, we see that
initiative swings back and forth between the
system and the user several times, leading to
three initiative segments.
3 Relationship between Initiative
and Discourse Structure
Walker and Whittaker (1990) suggested that
changes in initiative correspond to changes
in discourse structure, but they did not de-
termine the exact relationship between them.
In this section we analyze the dierences be-
tween initiative segments and discourse struc-
ture for three dialogues from the TRAINS
corpus. We nd that there is a close rela-
tionship, but not a direct one.
3.1 Segment Boundary Comparison
In this section, we compare initiative bound-
aries (where initiative shifts from one speaker
to the next) to subdialogue boundaries (where
a new subdialogue begins) using recall and
precision.
2
An initiative boundary is scored
as a hit if there is a corresponding subdia-
logue boundary. It is scored as a false posi-
tive if there is no subdialogue boundary. A
subdialogue boundary is scored as a miss if
it has no initiative boundary. For example,
2
Recall = Hits / (Hits + Misses )
Precision = Hits / ( Hits + False Positives )
in Figure 1, there are two hits (the bound-
ary between the 3rd and 4th utterances and
the boundary between the 5th and 6th utter-
ances), two misses (the boundary between the
8th and 9th utterances and the boundary be-
tween the 10th and 11th utterances), and no
false positives. The second column of Table
1, \Initiative versus Subdialogues", gives the
results. We see that both recall and precision
are very low for initiative boundaries relative
to discourse boundaries. However, compar-
ing initiative segments to discourse segments
is not fair. The misses in Figure 1 should be
expected since the initiator of the last subdi-
alogue is the same as the higher level subdia-
logue.
To show the eect of the unfairness, we
contrast changes in segment initiator to dis-
course segment boundaries in the third col-
umn of Table 1, \Segment Initiator versus
Subdialogue." Not surprisingly, we obtained
a precision of 100%: by denition, the seg-
ment initiator is only set at the beginning of
each discourse segment. However, we only ob-
tained a recall rate of 41%. This means only
41% of discourse segment boundaries are ini-
tiated by a dierent speaker. We should not
expect these boundaries to have a change in
initiative, since there is no change in segment
initiator. A fair comparison should contrast
changes in initiative only to changes in dis-
course segment initiator. The results of doing
this is shown in the fourth column, \Initia-
tive versus Segment Initiator." Here we see
much better results for recall; however, pre-
cision is still very low. We will return to the
low precision rates in Section 4.
Table 2: Initiative Held by Segment Initiator
Clarication Task
Total Subdialogues Subdialogues
Subdialogues 91 45 46
First utterance 91 (100%) 45 (100%) 46 (100%)
Whole subdialogue 77 (85%) 45 (100%) 32 (70%)
Segment
Initiator Initiative Speaker Utterance
u u u okay so we have to take oranges from Corning and
bring them to Elmira
s right
u u and then back to Bath by
s s + by noon +
u u + mid- + by noon
Figure 2: Forward acknowledgment (d92a-5.2: utt14-18).
3.2 Shifts Within Discourse Segments
Although the recall rate in the last column
of Table 1 is very good, it shows there are
some changes in discourse segment initiator
that are not matched by changes in initia-
tive. The question is, does this happen at the
beginning of the segment, the end, or in the
middle? We looked at how often the segment
initiator is the same as the speaker with ini-
tiative for the rst utterance in each discourse
segment. As seen in Table 2, this does give us
a 100% correct rate, meaning that a discourse
segment can only be initiated by the speaker
also taking the initiative. This is not unex-
pected, since the speaker needs to contribute
something new, otherwise it would not count
as the beginning of a new discourse segment.
However, the initiative does not always stay
with the initiator for the entire segment, as
seen in the last row of Table 2.
4 Reconciling Initiative Inside
Discourse Segments
The rst utterance of each discourse segment
shows perfect agreement between the initiator
of the segment and speaker with initiative, as
seen in Table 2. But what happens during
the course of the segment? In this section we
focus on subdialogues where the non-initiator
makes a contribution and the initiator nishes
the segment.
4.1 Forward Acknowledgments
In the TRAINS corpus there are times
when listeners were so synchronized with the
speaker that could they anticipate what the
speaker was going to say and ll it in be-
fore the he said it. Figure 2 gives an exam-
ple, where the system lled in \by noon" for
the user. Typical acknowledgments are utter-
ances that indicate understanding of an ut-
terance made by the other speaker and do
not contribute content. Our phenomena of
forward acknowledgments also indicate under-
standing, but of what the other speaker is
about to say, even before he says it. By ll-
ing in what the other speaker was about to
say, the speaker indicates understanding and
also moves the conversation forward. In both
examples of forward acknowledgments in the
three dialogues, the initiator nished the ut-
terance of the other speaker.
Forward acknowledgments are coded as
demonstrating initiative, because they add
content. However, this initiative is subordi-
nate to the initiative of the main segment, so
they are show as being embedded in the par-
ent segment.
Segment
Initiator Initiative Speaker Utterance
u u u and then take those uh t- to Dan- and then go to
Dansville
s s so that's + uh let's see and + that's one one more hour
u + and +
u u yeah and we can un- we can
s s drop o at + the +
u u + drop + o th- that boxcar and take well
dr-
u yeah drop o the boxcar + of +
s s + and then + take two empty
ones
u u right two empty ones down to Avon
s + oh +
u u + and + pick up the the bananas
s right
Figure 3: Other contribution (d93-19.5, utt83-utt93)
4.2 Other-Contributions
The rest of the utterances coded with initia-
tive made by the non-initiator of the segment
were more substantial contributions. Here,
the speaker added content to the discourse
segment that is not predicted from the ini-
tiator's speech. We refer to these as other-
contributions, and they often occur where the
two speakers are closely collaborating and are
highly synchronized.
3
In Figure 3, we show a
dialogue excerpt in which the two speakers
are so closely synchronized that they pick up
parts of each others utterances and build on
it. Initiative shifts back and forth between the
two speakers, but, in fact, we think this phe-
nomenon of other-contributions is related to
the phenomena that Schirin (1987) referred
to as shared turns.
4.3 Eect on Initiative
Table 3 shows what happens to initiative af-
ter the non-initiator makes a contribution
demonstrating initiative. There were 25 of
3
It is interesting to note the amount of overlapping
speech (marked with a '+') in these examples of other-
contributions. It might be the case that when speak-
ers are highly synchronized, they are more bound to
loosen the restrictions on turn-taking. This is some-
thing we hope to investigate in the future.
Table 3: After Contribution by Non-Initiator
Contributions by Non-Initiator 25
New subdialogue 7
Embedded subdialogue 1
Initiative returns to segment initiator 14
Initiative held by non-initiator 3
these cases. In 7 of them, the next utter-
ance demonstrating initiative occurred in a
new subdialogue, and in one case it occurred
in an embedded subdialogue. We focus on the
remaining 17 cases where the next utterance
demonstrating initiative occurred within the
same discourse segment. In 14 of these, initia-
tive returned to the segment initiator, usually
in the very next utterance (13 out of 14). In
only 3 cases does initiative stay with the non-
initiator. This result is contrary to previous
theories of initiative (Walker and Whittaker,
1990; Chu-Carroll and Brown, 1997), which
would expect initiative to stay with the non-
initiator.
4.4 Discussion
Forward acknowledgments and other-
contributions are exceptions to the general
rule that initiative tends to reside with the
same speaker. Based on the results of our
small preliminary study, we propose that
initiative is subordinate to the intentional
structure of the discourse theory of Grosz
and Sidner. Initiative is held by the segment
initiator. The non-initiator can make utter-
ances that contribute to the purpose of the
current discourse segment, namely forward
acknowledgments and other-contributions,
but initiative remains with the segment
initiator. Hence, initiative does not need to
be tracked, because it is held by the initiator
of the discourse segment.
This proposal allows either speaker to con-
tribute to the purpose of a discourse segment,
which accounts not only for forward acknowl-
edgments and other-contributions, but also
can account for embedded subdialogues and
the answer to a question in a question-answer
pair. It can be argued that embedded subdi-
alogues initiated by either speaker contribute
to the purpose of its parent subdialogue. For
example, in Figure 1, the subdialogue initi-
ated by the system (s) contributes to the pur-
pose of the parent subdialogue by pointing
out a problem with the user's plan to move
oranges, which the user then adjusts. The
clarication subdialogue initiated by the user
(u) checks that the plan the user is developing
will work, and so it also supports the general
purpose of developing the plan.
The proposal also can also be used to sim-
plify how initiative is used in question-answer
pairs. Whittaker and Stenton (1988) assigned
initiative to the speaker of statements, except
when it was the answer to a question, in which
case it belonged to the speaker asking the
question. In our view, a question-answer pair
is a subdialogue with the initiative belonging
to the questioner. The answer is coded with
initiative, but it is an other-contribution, and
so this initiative is subordinate to the ques-
tioner's initiative.
Other researchers have struggled with
structure in initiative. Chu-Carroll and
Brown (1997) referred to initiative as dialogue
initiative, and proposed a second level, task
initiative, to model who is adding domain
actions. In contrast to our proposal, which
makes initiative subordinate to intentional
structure, they proposed that dialogue ini-
tiative is subordinate to their task initiative.
Hence, their model could incorrectly pre-
dict who has initiative after the non-initiator
makes a contribution. As was shown in Ta-
ble 3, after the non-initiator makes an other-
contribution within a subdialogue, generally
initiative returns to the segment initiator of
the subdialogue, instead of staying with the
non-initiator. Chu-Carroll and Brown also
used task initiative to model how cooperative
a system should be. With novice users, the
system would tend to have task initiative and
thus make domain actions, but not so with ex-
perts. This is similar to Smith and Gordon's
(1997) use of four levels of initiative, which
set how much initiative was given to the sys-
tem and how much was given to the user in
one of four levels. Although a system needs
to reason about how helpful it needs to be, it
is unclear whether this can be done through
a single variable that is tied to dialogue ini-
tiative.
5 Conclusion
In this paper, we have proposed that initia-
tive is subordinate to intentional structure in
dialogue. We have backed up this claim by ex-
amining utterances that demonstrate initia-
tive made by the non-initiator of the discourse
segment. We found that after these utter-
ances, initiative returns to the segment initia-
tor in almost all cases. The reconciliation of
initiative and discourse segments means that
we now understand how initiative and dia-
logue level intentions are related and have a
clearer picture of how both participants can
contribute to discourse intentions.
Based on our results, initiative in itself does
not need to be tracked. Initiative belongs to
the speaker who started the current discourse
segment. Therefore, a dialogue manager only
needs to model intentional structure.
6 Future Work
Our preliminary study was based on a small
set of data coded by one of the authors. Plans
for future work include annotating more dia-
logues with multiple coders to ensure the re-
sults reported here are reproducible. We also
intend to analyze what happens to initiative
after an embedded subdialogue is completed
to verify that initiative stays with the seg-
ment initiator of the parent segment. We also
want to better understand the few cases where
stays with the non-initiator (the three cases in
Table 3).
In addition to more TRAINS dialogues,
we will code dialogues from other corpora,
such as Maptask (Anderson et al, 1991) and
Switchboard (Godfrey et al, 1992). This
will help ensure that we do not introduce id-
iosyncrasies of the TRAINS corpus into our
theory. Rather than just code initiative, we
will use the DAMSL annotation scheme (Core
and Allen, 1997). This scheme annotates
the forward and backward-looking functions of
each utterance, from which initiative can be
derived. Reliable intercoder agreement has
been obtained with this coding scheme. For
coding discourse structure, several schemes
have been proposed (Passonneau and Litman,
1997; Flammia, 1998; Nakatani et al, 1995;
Traum and Nakatani, 1999) ranging from cod-
ing at segmentation on monologues to hier-
archical segmentation of dialogues. We will
use these annotation schemes as a foundation,
and monitor our annotation results to ensure
we achieve good intercoder reliability.
Our theory necessitates that we better un-
derstand the structure of discourse, how it is
built, and the actions and rules that a dis-
course manager can use to aect the discourse
structure. We also need to understand the
reasoning process that determines whether a
participant will make an other-contribution or
start a new subdialogue. Since dialogue is
a collaborative eort (Cohen and Levesque,
1994; Clark and Wilkes-Gibbs, 1986), we also
need to explore how the participants collabo-
rate on the discourse structure.
7 Acknowledgments
The authors gratefully acknowledge funding
from the Intel Research Council. The au-
thors also thank David Traum and members
of the Centers for Spoken Language Under-
standing and Human Computer Communica-
tion at OGI for helpful discussions and com-
ments.
References
J. Allen, L. Schubert, G. Ferguson, P. Heeman,
C. Hwang, T. Kato, M. Light, N. Martin, B.
Miller, M. Poesio, and D. Traum. 1995. The
Trains project: A case study in building a con-
versational planning agent. Journal of Experi-
mental and Theoretical AI, 7:7{48.
A. Anderson, M. Bader, E. Bard, E. Boyle, G. Do-
herty, S. Garrod, S. Isard, J. Kowtko, J. McAl-
lister, J. Miller, C. Sotillo, H. Thompson, and
R. Weinert. 1991. The HCRC map task corpus.
Language and Speech, 34(4):351{366.
J. Chu-Carroll and M. Brown. 1997. Tracking
initiative in collaborative dialogue interaction.
In Proceedings of the 35th Annual Meeting of
the Association for Computational Linguistics,
Madrid, Spain, July.
H. Clark and D. Wilkes-Gibbs. 1986. Referring
as a collaborative process. Cognition, 22:1{39.
P. Cohen and H. Levesque. 1994. Preliminaries
to a collaborative model of dialogue. Speech
Communications, 15(3{4):265{274, December.
M. Core and J. Allen. 1997. Coding dialogs with
the DAMSL annotation scheme. In Working
notes of the AAAI Fall Symposium on Com-
municative Action in Humans and Machines.
G. Flammia. 1998. Discourse segmentation of
spoken dialogue: an empirical approach. Doc-
toral dissertation, Department of Electrical and
Computer Science, Massachusetts Institute of
Technology.
J. Godfrey, E. Holliman, and J. McDaniel. 1992.
SWITCHBOARD: Telephone speech corpus for
research and development. In Proceedings of
the International Conference on Audio, Speech
and Signal Processing (ICASSP), pages 517{
520.
B. Grosz and C. Sidner. 1986. Attention, inten-
tions, and the structure of discourse. Compu-
tational Linguistics, 12(3):175{204.
P. Heeman and J. Allen. 1995. The Trains spo-
ken dialog corpus. CD-ROM, Linguistics Data
Consortium, April.
C. Nakatani, B. Grosz, D. Ahn, and J. Hirschberg.
1995. Instructions for annotating discourse.
Technical Report 21-95, Center for Research
in Computing Technology, Harvard University,
Cambridge MA, September.
D. Novick and S. Sutton. 1997. What is
mixed-initiative interaction? In 1997 AAAI
Spring Symposium on Computational Models
for Mixed Initiative Interaction, pages 24{26,
Stanford University, March. AAAI Press.
R. Passonneau and D. Litman. 1997. Discourse
segmentation by human and automated means.
Computational Linguistics, 103{139.
E. Scheglo and H. Sacks. 1973. Opening up clos-
ings. Semiotica, 7:289{327.
D. Schirin. 1987. Discourse Markers. Cam-
bridge University Press, New York.
R. Smith and S. Gordon. 1997. Eects of vari-
able initiative on linguistic behavior in human-
computer spoken natural language dialogue.
Computational Linguistics, 23(1):141{168.
D. Traum and E. Hinkelman. 1992. Conversation
acts in task-oriented spoken dialogue. Compu-
tational Intelligence, 8(3):575{599. Special Is-
sue on Non-literal language.
D. Traum and C. Nakatani. 1999. A two-level ap-
proach to coding dialogue for discourse struc-
ture: Activities of the 1998 working group
on higher-level structures. In Proceedings of
the ACL'99 Workshop Towards Standards and
Tools for Discourse Tagging, pages 101{108,
June.
M. Walker and S. Whittaker. 1990. Mixed initia-
tive in dialogue: An investigation into discourse
segmentation. In Proceedings of the 28th An-
nual Meeting of the Association for Computa-
tional Linguistics, pages 70{78.
S. Whittaker and P. Stenton. 1988. Cues and con-
trol in expert client dialogues. In Proceedings
of the 26th Annual Meeting of the Association
for Computational Linguistics, pages 123{130.
DialogueView: An Annotation Tool for Dialogue
Peter A. Heeman and Fan Yang and Susan E. Strayer
Computer Science and Engineering
OGI School of Science and Engineering
Oregon Health & Science University
20000 NW Walker Rd., Beaverton OR, 97006
heeman@cse.ogi.edu yangf@cse.ogi.edu susan strayer@yahoo.com
Abstract
This paper describes DialogueView, a
tool for annotating dialogues with utter-
ance boundaries, speech repairs, speech
act tags, and discourse segments. The
tool provides several views of the data,
including a word view that is time-
aligned with the audio signal, and an ut-
terance view that shows the dialogue as
if it were a script for a play. The ut-
terance view abstracts away from lower
level details that are coded in the word
view. This allows the annotator to have
a simpler view of the dialogue when cod-
ing speech act tags and discourse struc-
ture, but still have access to the details
when needed.
1 Introduction
There is a growing interest in annotating human-
human dialogue. Annotated dialogues are useful
for formulating and verifying theories of dialogue
and for building statistical models. In addition to
orthographic word transcription, one might want
the following dialogue annotations.
 Annotation of the speech repairs. Speech re-
pairs are a type of disuency where speakers
go back and change or repeat something they
just said.
 Segmentation of the speech of each speaker
into utterance units, with a single ordering of
the utterances. We refer to this as linearizing
the dialogue (Heeman and Allen, 1995a).
 Each utterance tagged with its speech act
function.
 The utterances grouped into hierarchical dis-
course segments.
There are tools that address subsets of the above
tasks. However, we feel that doing dialogue an-
notation is very di?cult. Part of this di?culty
is due to the interactions between the annotation
tasks. An error at a lower level can have a large
impact on the higher level annotations. For in-
stance, there can be ambiguity as to whether an
\okay" is part of a speech repair; this will im-
pact the segmentation of the speech into utter-
ance units and the speech act coding. Sometimes,
it is only by considering the higher level annota-
tions that one can make sense of what is going on
at the lower levels, especially when there is over-
lapping speech. Hence, a tool is needed that lets
users examine and code the dialogue at all lev-
els. The second reason why dialogue annotation
is di?cult is because it is di?cult to follow what
is occurring in the dialogue, especially for coding
discourse structure. A dialogue annotation tool
needs to help the user deal with this overload.
In this paper, we describe our dialogue anno-
tation tool, DialogueView. This tool displays the
dialogue at three dierent levels of abstraction.
The word level shows the words time-aligned with
the audio signal. The utterance level shows the
dialogue as a sequence of utterance, as if it were a
script for a play. It abstracts away from the exact
timing of the words and even skips words that do
not impact the progression of the dialogue. The
block level shows the dialogue as a hierarchy of
discourse segment purposes, and abstracts away
from the exact utterances that were said. Anno-
tations are done at the view that is most appropri-
ate for what is being annotated. The tool allows
the user to easily navigate between the three views
and automatically updates the higher level views
when changes are made in the lower level views.
Because the higher levels abstract away lower level
details, it is easier for the user to understand what
is happening in the dialogue.
1
Yet, the user can
easily refer to the lower level views to see what
1
This approach bears resemblance to the work of
Jonsson and Dahlback (2000) in which they distill
human-human dialogues by removing those parts that
would not occur in human-computer dialogue. They
do this to create training data for their spoken dia-
logue systems.
       Philadelphia, July 2002, pp. 50-59.  Association for Computational Linguistics.
                  Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
actually occurred when necessary.
In the rest of this paper, we rst discuss other
annotation tools. We then describe the three lev-
els of abstraction in our annotation tool. We then
discuss audio playback. Next, we discuss how the
tool can be customized for dierent annotation
schemes. Finally, we discuss the implementation
of the tool.
2 Existing Tools
There are a number of tools that let users annotate
speech audio les. These include Emu (Cassidy
and Harrington, 2001), SpeechView (Sutton et al,
1998) and Waves+ (Ent, 1993). These tools often
allow multiple text annotation les to be associ-
ated with the waveform and allow users an easy fa-
cility to capture time alignments. For instance, for
the ToBI annotation scheme (Pitrelli et al, 1994),
one can have the word alignment in one text le,
intonation features in a second, break indices in a
third, and miscellaneous features in a fourth. The
audio annotation tools often have powerful signal
analysis packages for displaying such phenomena
as spectrograms and voicing. These tools, how-
ever, do not have any built-in facility to group
words into utterances nor group utterances into
hierarchical discourse segments.
Several tools allow users to annotate higher
level structure in dialogue. The annotation tool
DAT from the University of Rochester (Fergu-
son, 1998) allows users to annotate utterances or
groups of utterances with a set of hard-coded an-
notation tags for the DAMSL annotation scheme
(Allen and Core, 1997; Core and Allen, 1997).
The tool Nb from MIT (Flammia, 1995; Flammia,
1998) allows users to impose a hierarchical group-
ing on a sequence of utterances, and hence anno-
tate discourse structure. Both DAT and Nb take
as input a linearization of the speaker utterances.
Mistakes in this input cannot be xed. Whether
there are errors or not, users cannot see the exact
timing interactions between the speakers' words or
the length of pauses. This simplication can make
it di?cult for the annotator to truly understand
what is happening in the dialogue, especially for
overlapping speech, where speakers ght over the
turn or make back-channels.
The tools Transcriber (Barras et al, 2001) and
Mate (McKelvie et al, 2001) allow multiple views
of the data: a word view with words time-aligned
to the audio signal and an utterance view. How-
ever, Transcriber is geared to single channel data
and has a weak ability to handle overlapping
speech and Mate only allows one view to be shown
at a time. The author of a competing tool has
remarked that \speed and stability of [Mate] are
both still problematic for real annotation. Also,
the highly generic approach increases the initial
eort to set up the tool since you basically have
to write your own tool using the Mate style-sheet
language" (Kipp, 2001). Hence, he developed a
new tool Anvil that he claims is a better trade-o
among generality, functionality, and complexity.
This tool oers multi-modal annotation support,
but like Transcriber, does not allow detailed an-
notation of dialogue phenomena, such as overlap-
ping speech and abandoned speech, and has no
abstraction mechanism.
3 Word View
Our dialogue annotation tool, DialogueView,
gives the user three views of the data. The low-
est level view is called WordView and takes as
input the words said by each speaker and their
start and stop times and shows them time-aligned
with the audio signal. Figure 1 shows an ex-
cerpt from the Trains corpus (Heeman and Allen,
1995b) in WordView. This view is ideal for view-
ing the exact timing of speech, especially overlap-
ping speech. As will be discussed below, we use
it for segmenting the speech into utterances, and
annotating communicative status and speech re-
pairs.
2
These annotations will allow us to build a
simpler representation of what is happening in the
speech for the utterance view, which is discussed
in the next section.
3.1 Utterance Segmentation
As can be seen in Figure 1, WordView shows the
words segmented into utterances, which for our
purpose is simply a grouping of consecutive words
by a single speaker, in which there is minimal
eect from the other speaker. Consider the ex-
change in Figure 1, where the upper speaker says
\and then take the remaining boxcar down to" fol-
lowed by the lower speaker saying \right, to du-",
followed by the upper speaker saying \Corning".
Although one could consider the upper speaker's
speech as one utterance, we preclude that due to
the interaction from the lower speaker. A full def-
inition of `utterance' is beyond the scope of this
paper, and is left to the users to specify in their
annotation scheme.
Utterance boundaries in WordView are only
shown by their start times. The end of the utter-
ance is either the start of the next utterance by the
2
There currently is no support for changing the
word transcription. There are already a number of
tools that do an excellent job at this task. Hence,
adding this capability is a low priority for us.
Figure 1: Utterance Segmentation in WordView
same speaker or the end of the le. With Word-
View, the user can easily move, insert or delete
utterance boundaries. The tool ensures that the
boundaries never fall in the middle of a word by
the speaker.
The start times of the utterances are used to
derive a single ordering of the utterances of the
two speakers. This linearization of the dialogue
captures how the speakers are sequentially adding
to the dialogue. The linearization is used by the
next view to give an abstraction away from the
exact timing of the speech.
3.2 Communicative Status
WordView allows features of the utterances to be
annotated. In practice, however, we only anno-
tate features related to its communicative status,
based on the DAMSL annotation scheme (Allen
and Core, 1997). Below, we give the utterance
tags that we assign in WordView.
Abandoned: The speaker abandoned what
they were saying and it had no impact on the rest
of the dialogue. This mainly happens where one
speaker loses the ght over who speaks next. Fig-
ure 2 gives an example where the upper speaker
tries to take the turn by saying \takes," and than
abandons this eort.
Incomplete: The speaker did not make a com-
plete utterance, either prosodically, syntactically,
or semantically. Unlike the previous category, the
partial utterance did impact the dialogue behav-
ior. Figure 1 gives two examples. The rst is
where the upper speaker says \and than take the
remaining boxcar down to", and the second is
where the lower speaker said \to du-," which was
than completed by the upper speaker.
Overlap: The speech in the utterance overlaps
with the speech from the prior utterance. For
instance, in Figure 1, the lower speaker utters
\okay" during the middle of an utterance, perhaps
to tell the upper speaker that they are understand-
ing everything so far. However, a simple lineariza-
tion would make it seem that the \okay" is an
acknowledgment of the entire utterance, which is
not the case. Hence, we tag the \okay" utterance
with the overlap tag. The next view, Utterance-
View, will take the overlap tag into account in
displaying the utterances, as will be discussed in
Section 4.3.
Not all overlapping speech needs to be anno-
tated with the overlap tag. In Figure 1, the sec-
ond instance of \Corning" overlaps slightly with
the rst instance of \Corning". However, viewing
it sequentially does not alter the analysis of the
exchange.
3.3 Reordering Overlapping Speech
Consider the example in Figure 2. Before the ex-
cerpt shown, the lower speaker had just nished
an utterance and then paused for over a second.
The upper speaker then acknowledged the utter-
ance with \okay", but this happened a fraction of
a second after the bottom speaker started speak-
ing again. A simple linearization of the dialogue
would have the \okay" following the wrong stretch
of speech|\and than th(at)- takes w- what three
hours." A solution to this would be to anno-
Figure 2: Utterance Ordering and Speech Repairs in WordView
tate the \okay" with the overlap tag. However,
this \Okay" is more similar to the overlapping in-
stances of \Corning" in Figure 1. The fact that
\Okay" overlaps with the start of the next utter-
ance is not critical to understanding what is oc-
curring in the dialogue, as long as we linearize
the \Okay" to occur before the other utterance.
WordView allows the user to change the lineariza-
tion by moving the start times of utterances. This
can be done provided that the speaker was silent
in the time interval preceding where the other per-
son started talking.
In summary, overlapping speech can be handled
in three ways. The utterance can be explicitly
tagged as overlapping; the overlap can be ignored
if it is not critical in understanding what is going
on in the dialogue; or the start time of the utter-
ance can be changed so that the overlap does not
need to be tagged.
3.4 Speech Repairs
WordView also allows users to annotate speech
repairs. A speech repair is where a user goes back
and repeats or changes something that was just
said (Heeman and Allen, 1999). Below we give an
example of a speech repair and show its principle
components: reparandum, interruption point, and
editing term.
Example 1
why don't we take
|{z}
reparandum
"
ip
um
|{z}
et
take two boxcars
The reparandum is the speech that is being re-
placed, the interruption point is the end of the
reparandum, and the editing term consists of
words such as \um", \uh", \okay", \let's see" that
help signal the repair.
To annotate a repair, the user highlights a se-
quence of words and then tags it as a reparandum
or an editing term of a repair. The user can also
specify the type of repair. Figure 2 shows how
speech repairs are displayed in WordView. The
words in the reparandum and editing term are un-
derlined and displayed in a special color.
3.5 Speech Repairs and Utterances
Some phenomena can be marked as either a speech
repair, or could be marked using the utterance
tags of incomplete or abandon. This is especially
true for fresh starts (Heeman and Allen, 1999),
where a speaker abandons the current utterance
and starts over. To avoid having multiple ways of
annotating the same phenomena, we impose the
following restrictions in our annotation scheme.
 There cannot be an utterance boundary in-
side of a reparandum, inside of an editing
term, at the interruption point, nor at the
end of the editing term. Hence, something
annotated as a reparandum cannot also be
annotated as an abandoned utterance.
 Abandoned or incomplete utterances cannot
be followed by an utterance by the same
speaker.
 All word fragments must either be the last
word of a reparandum or the last word of an
utterance that is marked as abandoned or in-
complete.
Figure 3: UtteranceView: Segmented Utterances in UtteranceView
 Abandoned or incomplete utterances can end
with an editing term, which would be marked
as the editing term of an abridged repair.
3.6 Summary
There are a number of reasons why we annotate
utterance boundaries, speech repairs, and commu-
nicative status in WordView. Annotating utter-
ance boundaries and overlapping speech requires
the user to take into account the exact timing of
the utterances, which is best done in this view.
Speech repairs also require ne tuned listening to
the speech and have strong interactions with ut-
terance boundaries. Furthermore, all three types
of annotations can be used to build a simpler view
of what is happening in the dialogue, as will be ex-
plained in the next section.
4 Utterance View
The annotations from the word view are used to
build the next view, which we refer to as Utter-
anceView. The dialogue excerpts from Figures 1
and 2 are shown in the utterance view in Figures 3
and 4, respectively. The utterance view abstracts
away from the detailed timing information and in-
dividual words that were spoken. Instead, it fo-
cuses on the sequence of utterances between the
speakers. By removing details that were anno-
tated in the word view, we still preserve the im-
portant details that are needed to annotate speech
act types for the utterances and to annotate dis-
course segments. Of course, if the user wants to
see the exact timing of the words in the utter-
ances, they can examine the word view, as it is
Figure 4: UtteranceView: Reordered and Abandoned Utterances in UtteranceView
displayed alongside the utterance view. There are
also navigation buttons on each view that allow
the user to easily reposition the portion of the di-
alogue in the other view. Furthermore, changes
made in the word view are immediately propa-
gated into the utterance view, and hence the user
will immediately see the impact of their annota-
tions.
4.1 Utterance Ordering
Utterance ordering in the utterance view is deter-
mined by the start times of the utterances as spec-
ied in WordView. As was explained earlier, alter-
ing the start time of an utterance can be used to
simplify some cases of overlapping speech, where
the overlap is not critical to understanding the
role of the utterance in the dialogue. Figure 2
gave the word view of such an example. Rather
than code it as an overlap, we moved the start
time of the \okay" utterance so that it precedes
the overlapping speech by the other speaker. Fig-
ure 4 shows how this looks in the utterance view.
Here, the annotator would view the \okay" as an
acknowledgment that occurred between the two
utterances of the lower speaker.
4.2 Speech Repairs
In the word view, the user annotates the reparan-
dum and editing term of speech repairs. If the
reparandum and editing term are removed, the
resulting utterance reects what the speaker in-
tended to say. Speech repairs do carry informa-
tion.
 Their occurrence can signal a lack of certainty
of the speaker.
 The reparandum of a repair can have an
anaphoric reference, as in \Peter was, well
he was red."
However, removing the reparandum and editing
term of speech repairs from utterances in the ut-
terance view leads to a simpler representation of
what is occurring in the dialogue. Hence, in the
utterance view, we clean up the speech repairs, as
shown in Figures 2 and 4. Figure 2, which shows
the word view, contains the utterance \and then
th(at) that takes w- what three hours"; whereas
Figure 4, which shows the utterance view, con-
tains \and then that takes what three hours." Of
course, a user can always refer to the word view
when annotating in the utterance view if they
want to see the exact speech that was said. In
most cases, we feel that this will not be neces-
sary for annotating speech act tags and discourse
segments.
4.3 Communicative Status
The communicative status coded in the word view
is used in formatting the utterance view. Utter-
ances tagged as overlapping are indented and dis-
played with `+' on either side, as shown in Fig-
ure 3. Utterances tagged as abandoned are not
shown, as can be seen in Figure 4, in which the
abandoned utterance \takes" made by the upper
speaker is not included. Utterances tagged as in-
complete are shown with a trailing \..." as shown
in Figure 3.
4.4 Annotating Utterance Tags
In the utterance view, one can also annotate the
utterances with various tags. For our work, we
use a subset of the DAMSL tags corresponding
to forward and backward functions (Allen and
Core, 1997). Forward functions include state-
ment, request information, and suggestion. Back-
ward functions include answer, acknowledgment,
and agreement. Although these utterance tags
could be annotated in the word view, doing it in
the utterance view allows us to see more context,
which is needed to give the utterance the proper
tags. When necessary, the annotator can easily
refer to the word view to see the exact local con-
text.
4.5 Annotating Blocks of Utterances
In the utterance view, the user can also annotate
hierarchical groupings of utterances.
3
We use the
utterance blocks to annotate discourse structure
(Grosz and Sidner, 1986). This is similar to what
Flammia's tool allows (Flammia, 1995). Rather
than showing it with indentation and color, we
draw boxes around segments. Figure 3 shows a
dialogue excerpt with three utterance blocks in-
side of a larger block. To create a segment, the
user highlights a sequence of utterances and then
presses the \make segment" button. The user can
change the boundaries of the blocks by simply
dragging either the top or bottom edge of the box.
Blocks can also be deleted. The tool ensures that
if two blocks have utterances in common then one
block is entirely contained in the other.
Tags can also be assigned to the blocks. We
have just started using the tool for discourse seg-
mentation, and so we are still rening these tags.
In Grosz and Sidner's theory of discourse struc-
ture (1986), the speaker who initiates the block
does so to accomplish a certain purpose. We have
a tag for annotating this purpose. We also have
tags to categorize the block as a greeting, spec-
ify goal, construct plan, summarize plan, verify
plan, give info, request info, or other (Strayer and
Heeman, 2001).
The utterance view also allows the user to open
or close a block. When a block is open (the de-
fault), all of its utterances and sub-blocks are dis-
3
We do not allow segments to be interleaved. It is
unclear if such phenomena actually occur.
played. When it is closed, its utterances and sub-
blocks are replaced by the single line purpose.
Opening and closing blocks is useful as it allows
the user to control the level of detail that is shown.
Consider the third embedded block shown in Fig-
ure 3, in which the conversants take seven utter-
ances to jointly make a suggestion. After we have
analyzed it, we can close it and just see the pur-
pose. This will make it easier to determine the
segmentation of the blocks that contain it.
We are experimenting with a special type of
dialogue block. Consider the example from the
previous paragraph, in which the conversants
take seven utterances to jointly make a sugges-
tion. This is related to the shared turns of
Schirin (1987), the co-operative completions of
Linell (1998), and the grounding units of Traum
and Nakatani (1999). We are experimenting with
how to support the annotation of such phenom-
ena. We have added a tag to indicate whether the
utterances in the block are being used to build a
single contribution. For these single contributions,
we also supply a concise paraphrase of what was
said. We have found that this paraphrase can be
built from a sequential subset of the words in the
utterances of the block. For instance, the para-
phrase of our example block is \and then take the
remaining boxcar down to Corning."
5 Block View
We are experimenting with a third view of the
dialogue. This view, which we refer to as Block-
View, abstracts away from the individual utter-
ances, and shows the hierarchical structure of the
discourse segments. This gives a very concise view
of the dialogue. The block view is also convenient
for it provides an index to the whole dialogue.
This allows the user to quickly move around the
dialogue.
6 Audio Playback
Each view gives the user the ability to select a re-
gion of the dialogue and to play it. In the word
view, the user can play each speaker channel indi-
vidually or both combined.
4
This ability is espe-
cially useful for overlapping speech, where the an-
notator would want to listen to what each speaker
said individually, as well as hear the timing be-
tween the speaker utterances.
Just as each view provides a visual abstraction
from the previous one, we also do the same with
audio playback. In the word view, which has
4
In order to play each speaker individually, we re-
quire a separate audio channel for each speaker.
wordViewUtt => atmostoneof abandoned incomplete overlap
uttViewUtt => anyof forward backward comment
uttViewUtt.forward => oneof statement question suggestion other
uttViewUtt.backward => oneof agreement understanding answer other
uttViewUtt.comment => other
Figure 5: Sample Specication of Utterance Tags
Figure 6: Sample Utterance Annotation Panel
the speech repairs annotated, the user can play
back the speech cleanly of either speaker, where
the stretches of speech annotated as the reparan-
dum or editing term of a repair are skipped. We
have found this to be of great assistance in verify-
ing if something should be annotated as a repair
or not. It gives us an audio means to verify the
speech repair annotations. If we have annotated
the repair correctly, the edited audio signal should
sound fairly natural.
In formatting the utterance view, we take into
account whether utterances have been marked as
abandoned or overlapped. We provide a special
playback in the utterance view that takes this
into account. We build an audio le in which we
skip over repairs, skip over abandoned speech, and
shorten large silences. If there is overlap that is
not marked as signicant, we linearize it by con-
catenating the utterances together. If the overlap
is marked as signicant, we keep the overlap. We
are nding that this gives us an audio means to
ensure that our markings of abandonment, over-
lap and our linearization is correct.
We are also experimenting with even further
simplifying the audio output. For blocks that have
a paraphrase, and the block is closed, we play the
paraphrase by constructing it from the words said
in the block. For blocks that are closed that do
not have a paraphrase, we use the text-to-speech
engine in the CSLU toolkit (Colton et al, 1996;
Sutton et al, 1997) to say the purpose, as if there
was a narrator.
7 Customizations
Some aspects of the tool are built in, such as the
notion of utterances, speech repairs, and hierar-
chical grouping of utterances into blocks. How-
ever, the annotations of these phenomena and how
they are displayed can be customized through a
conguration le. This allows us to easily exper-
iment as we revise our annotation scheme; to use
domain specic tags; and to make the tool useful
for other researchers who might use dierent tags.
Speech repair tags, utterance tags, and block
tags are specied in the conguration le. Fig-
ure 5 gives a sample of how the annotation
tags for an utterance are specied. The two top
level entries in the gure are \wordViewUtt" and
\uttViewUtt", which specify the utterance anno-
tation tags in WordView and UtteranceView, re-
spectively. The decomposition can be of one of
three types.
atmostoneof: at most one of the attributes can
be specied
oneof: exactly one of the attributes must be spec-
ied
anyof: there is no restriction on which attributes
can be specied
The subcomponents can either be terminals as is
the case for the decomposition of \wordViewUtt",
or can be non-terminals, as is the case for each
of the three subcomponents of \uttViewUtt".
Hence, hierarchical tags are supported. Termi-
nals are assumed to be of binary type, except for
\other", which is assumed to be a string. The
conguration le determines how the annotation
panel is generated. For the annotation scheme
specied in Figure 5, Figure 6 shows the annota-
tion panel that would be automatically generated
for the utterance view.
As we explained earlier, some of the utterance
tags aect how the word view and utterance view
are formatted. Rather than hard code this func-
tionality, it is specied in the conguration le.
We are still experimenting with the best way to
code this functionality. Figure 7 gives an exam-
ple of how we code the utterance tag function-
ality. The rst line indicates that the utterance
wordViewUtt.abandoned do wordView color red
wordViewUtt.abandoned uttView ignore
wordViewUtt.incomplete wordView color yellow
wordViewUtt.incomplete uttView trailsoff
wordViewUtt.overlap wordView color blue
wordViewUtt.overlap uttView overlap
Figure 7: Sample Utterance Display Specication
tag of \abandoned" coded in WordView should
be displayed in red in WordView. The second line
indicates that it should not be displayed in Utter-
anceView.
8 Implementation
DialogueView is written in Tcl/Tk. We also use
utilities from the CSLU Speech Toolkit (Colton
et al, 1996; Sutton et al, 1997), including audio
and wave handling and speech synthesis. We have
rewritten the tool to use an object-oriented exten-
sion of Tcl called Tclpp, designed and developed
by Stefan Simnige. This is allowing us to better
manage the growing complexity of the tool as well
as reuse pieces of the software in our annotation
comparison tool (Yang et al, 2002). It should also
help in expanding the tool so that it can handle
any number of speakers.
9 Conclusion
In this paper, we described a dialogue annotation
tool that we are developing for segmenting dia-
logue into utterances, annotating speech repairs,
tagging speech acts, and segmenting dialogue into
hierarchical discourse segments. The tool presents
the dialogue at dierent levels of abstraction al-
lowing the user to both see in detail what is go-
ing on and see the higher level structure that is
being built. The higher levels not only abstract
away from the exact timing, but also can skip over
words, whole utterances, and even simplify seg-
ments to a single line paraphrase. Along with the
visual presentation, the audio can also be played
at these dierent levels of abstraction. We feel
that these capabilities should help annotators bet-
ter code dialogue.
This tool is still under active development. In
particular, we are currently rening how blocks
are displayed, improving the ability to customize
the tool for dierent tagsets, and improving the
audio playback facilities. As we develop this tool,
we are also doing dialogue annotation, and ren-
ing our scheme for annotating dialogue in order to
better capture the salient features of dialogue and
improve the inter-coder reliability.
10 Acknowledgments
The authors acknowledgment funding from the In-
tel Research Council.
References
James F. Allen and Mark G. Core. 1997. Damsl:
Dialog annotation markup in several layers.
Unpublished Manuscript.
Claude Barras, Edouard Georois, Zhibiao Wu,
and Mark Liberman. 2001. Transcriber: devel-
opment and use of a tool for assisting speech
corpora production. Speech Communications,
33:5{22.
Steve Cassidy and Jonathan Harrington. 2001.
Multi-level annotation in the Emu speech
database management system. Speech Commu-
nications, 33:61{77.
Don Colton, Ron Cole, David G. Novick, and
Stephen Sutton. 1996. A laboratory course
for designing and testing spoken dialogue sys-
tems. In Proceedings of the International Con-
ference on Audio, Speech and Signal Processing
(ICASSP), pages 1129{1132.
Mark G. Core and James F. Allen. 1997. Coding
dialogs with the DAMSL annotation scheme.
In Working notes of the AAAI Fall Symposium
on Communicative Action in Humans and Ma-
chines.
Entropic Research Laboratory, Inc., 1993.
WAVES+ Reference Manual. Version 5.0.
George Ferguson. 1998. DAT: Dialogue annota-
tion tool. Available from www.cs.rochester.edu
in the subdirectory research/speech/damsl.
Giovanni Flammia. 1995. N.b.: A graphical user
interface for annotating spoken dialogue. In
AAAI Spring Symposium on Empirical Meth-
ods in Discourse Interpretation and Generation,
pages pages 40{46, Stanford, CA.
Giovanni Flammia. 1998. Discourse segmenta-
tion of spoken dialogue: an empirical approach.
Doctoral dissertation, Department of Electrical
and Computer Science, Massachusetts Institute
of Technology.
Barbara J. Grosz and Candace L. Sidner. 1986.
Attention, intentions, and the structure of dis-
course. Computational Linguistics, 12(3):175{
204.
Peter A. Heeman and James Allen. 1995a. Dia-
logue transcription tools. Trains Technical Note
94-1, Department of Computer Science, Univer-
sity of Rochester, March. Revised.
Peter A. Heeman and James F. Allen. 1995b. The
Trains spoken dialog corpus. CD-ROM, Lin-
guistics Data Consortium, April.
Peter A. Heeman and James F. Allen. 1999.
Speech repairs, intonational phrases and dis-
course markers: Modeling speakers' utterances
in spoken dialog. Computational Linguistics,
25(4):527{572.
Arne Jonsson and Nils Dahlback. 2000. Distill-
ing dialogues | a method using natural di-
alogue corpora for dialogue systems develop-
ment. In Proceedings of the 6th Applied Natural
Language Processing Conference, pages 44{51,
Seattle.
Michael Kipp. 2001. Anvil: A generic annotation
tool for multimodal dialogue. In Proceedings of
the 7th European Conference on Speech Com-
munication and Technology (Eurospeech).
Per Linell. 1998. Approaching Dialogue: Talk,
Interaction and Contexts in Dialogical Perspec-
tives. John Benjamins Publishing.
David McKelvie, Amy Isard, Andreas Mengel,
Morten Baun Muller, Michael Grosse, and Mar-
ion Klein. 2001. The MATE workbench | an
annotation tool for XML coded speech corpora.
Speech Communications, 33:97{112.
John F. Pitrelli, Mary E. Beckman, and Ju-
lia Hirschberg. 1994. Evaluation of prosodic
transcription labeling reliability in the ToBI
framework. In Proceedings of the 3rd Interna-
tional Conference on Spoken Language Process-
ing (ICSLP-94), Yokohama, September.
Deborah Schirin. 1987. Discourse Markers.
Cambridge University Press, New York.
Susan E. Strayer and Peter A. Heeman. 2001.
Dialogue structure and mixed initiative. In
Second workshop of the Special Interest Group
on Dialogue, pages 153{161, Aalborg Denmark,
September.
Stephen Sutton, Ed Kaiser, Andrew Cronk, and
Ronald Cole. 1997. Bringing spoken language
systems to the classroom. In Proceedings of the
5th European Conference on Speech Commu-
nication and Technology (Eurospeech), Rhodes,
Greece.
S. Sutton, R. Cole, J. de Villiers, J. Schalkwyk,
P. Vermeulen, M. Macon, Y. Yan, E. Kaiser,
R. Rundle, K. Shobaki, P. Hosom, A. Kain,
J. Wouters, M. Massaro, and M. Cohen. 1998.
Universal speech tools: the cslu toolkit. In Pro-
ceedings of the 5th International Conference on
Spoken Language Processing (ICSLP-98), pages
3221{3224, Sydney Australia, November.
David R. Traum and Christine H. Nakatani. 1999.
A two-level approach to coding dialogue for dis-
course structure: Activities of the 1998 working
group on higher-level structures. In Proceed-
ings of the ACL'99 Workshop Towards Stan-
dards and Tools for Discourse Tagging, pages
101{108, June.
Fan Yang, Susan E. Strayer, and Peter A. Hee-
man. 2002. ACT: a graphical dialogue anno-
tation comparison tool. Submitted for publica-
tion.
