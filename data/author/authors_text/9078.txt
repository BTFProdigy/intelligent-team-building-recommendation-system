49
Statistics Learning and Universal Grammar:
Modeling Word Segmentation
Timothy Gambell
59 Bishop Street
New Haven, CT 06511
USA
timothy.gambell@aya.yale.edu
Charles Yang
Department of Linguistics, Yale University
New Haven, CT 06511
USA
charles.yale.edu@yale.edu
Abstract
This paper describes a computational model of word
segmentation and presents simulation results on re-
alistic acquisition In particular, we explore the ca-
pacity and limitations of statistical learning mecha-
nisms that have recently gained prominence in cog-
nitive psychology and linguistics.
1 Introduction
Two facts about language learning are indisputable.
First, only a human baby, but not her pet kitten, can
learn a language. It is clear, then, that there must
be some element in our biology that accounts for
this unique ability. Chomsky?s Universal Grammar
(UG), an innate form of knowledge specific to lan-
guage, is an account of what this ability is. This po-
sition gains support from formal learning theory [1-
3], which sharpens the logical conclusion [4,5] that
no (realistically efficient) learning is possible with-
out priori restrictions on the learning space. Sec-
ond, it is also clear that no matter how much of a
head start the child has through UG, language is
learned. Phonology, lexicon, and grammar, while
governed by universal principles and constraints, do
vary from language to language, and they must be
learned on the basis of linguistic experience. In
other words?indeed a truism?both endowment and
learning contribute to language acquisition, the re-
sult of which is extremely sophisticated body of
linguistic knowledge. Consequently, both must be
taken in account, explicitly, in a theory of language
acquisition [6,7].
Controversies arise when it comes to the relative
contributions by innate knowledge and experience-
based learning. Some researchers, in particular lin-
guists, approach language acquisition by charac-
terizing the scope and limits of innate principles
of Universal Grammar that govern the world?s lan-
guage. Others, in particular psychologists, tend to
emphasize the role of experience and the child?s
domain-general learning ability. Such division of
research agenda understandably stems from the di-
vision of labor between endowment and learning?
plainly, things that are built in needn?t be learned,
and things that can be garnered from experience
needn?t be built in.
The important paper of Saffran, Aslin, & New-
port [8] on statistical learning (SL), suggests that
children may be powerful learners after all. Very
young infants can exploit transitional probabilities
between syllables for the task of word segmenta-
tion, with only minimum exposure to an artificial
language. Subsequent work has demonstrated SL
in other domains including artificial grammar learn-
ing [9], music [10], vision [11], as well as in other
species [12]. This then raises the possibility of
learning as an alternative to the innate endowment
of linguistic knowledge [13].
We believe that the computational modeling of
psychological processes, with special attention to
concrete mechanisms and quantitative evaluations,
can play an important role in the endowment vs.
learning debate. Linguists? investigations of UG are
rarely developmental, even less so corpus-oriented.
Developmental psychologists, by contrast, often
stop at identifying components in a cognitive task
[14], without an account of how such components
work together in an algorithmic manner. On the
other hand, if computation is to be of relevance
to linguistics, psychology, and cognitive science in
general, being merely computational will not suf-
fice. A model must be psychological plausible, and
ready to face its implications in the broad empirical
contexts [7]. For example, how does it generalize
to typologically different languages? How does the
model?s behavior compare with that of human lan-
guage learners and processors?
In this article, we will present a simple compu-
tational model of word segmentation and some of
its formal and developmental issues in child lan-
guage acquisition. Specifically we show that SL
using transitional probabilities cannot reliably seg-
ment words when scaled to a realistic setting (e.g.,
child-directed English). To be successful, it must
be constrained by the knowledge of phonological
50
structure. Indeed, the model reveals that SL may
well be an artifact?an impressive one, nonetheless?
that plays no role in actual word segmentation in
human children.
2 Statistics does not Refute UG
It has been suggested [15, 8] that word segmenta-
tion from continuous speech may be achieved by
using transitional probabilities (TP) between ad-
jacent syllables A and B, where , TP(A?B) =
P(AB)/P(A), with P(AB) being the frequency of B
following A, and P(A) the total frequency of A.
Word boundaries are postulated at local minima,
where the TP is lower than its neighbors. For ex-
ample, given sufficient amount of exposure to En-
glish, the learner may establish that, in the four-
syllable sequence ?prettybaby?, TP(pre?tty) and
TP(ba?by) are both higher than TP(tty?ba): a
word boundary can be (correctly) postulated. It
is remarkable that 8-month-old infants can extract
three-syllable words in the continuous speech of an
artificial language from only two minutes of expo-
sure [8].
To be effective, a learning algorithm?indeed any
algorithm?must have an appropriate representation
of the relevant learning data. We thus need to be
cautious about the interpretation of the success of
SL, as the authors themselves note [16]. If any-
thing, it seems that the findings strengthen, rather
than weaken, the case for (innate) linguistic knowl-
edge. A classic argument for innateness [4, 5,
17] comes from the fact that syntactic operations
are defined over specific types of data structures?
constituents and phrases?but not over, say, linear
strings of words, or numerous other logical possibil-
ities. While infants seem to keep track of statistical
information, any conclusion drawn from such find-
ings must presuppose children knowing what kind
of statistical information to keep track of. After all,
an infinite range of statistical correlations exists in
the acoustic input: e.g., What is the probability of a
syllable rhyming with the next? What is the proba-
bility of two adjacent vowels being both nasal? The
fact that infants can use SL to segment syllable se-
quences at all entails that, at the minimum, they
know the relevant unit of information over which
correlative statistics is gathered: in this case, it is
the syllables, rather than segments, or front vowels.
A host of questions then arises. First, How do
they know so? It is quite possible that the primacy
of syllables as the basic unit of speech is innately
available, as suggested in neonate speech perception
studies [18]? Second, where do the syllables come
from? While the experiments in [8] used uniformly
CV syllables, many languages, including English,
make use of a far more diverse range of syllabic
types. And then, syllabification of speech is far
from trivial, which (most likely) involve both in-
nate knowledge of phonological structures as well
as discovering language-specific instantiations [14].
All these problems have to be solved before SL for
word segmentation can take place.
3 The Model
To give a precise evaluation of SL in a realis-
tic setting, we constructed a series of (embarrass-
ingly simple) computational models tested on child-
directed English.
The learning data consists of a random sam-
ple of child-directed English sentences from the
CHILDES database [19] The words were then pho-
netically transcribed using the Carnegie Mellon Pro-
nunciation Dictionary, and were then grouped into
syllables. Spaces between words are removed; how-
ever, utterance breaks are available to the modeled
learner. Altogether, there are 226,178 words, con-
sisting of 263,660 syllables.
Implementing SL-based segmentation is straight-
forward. One first gathers pair-wise TPs from the
training data, which are used to identify local min-
ima and postulate word boundaries in the on-line
processing of syllable sequences. Scoring is done
for each utterance and then averaged. Viewed as an
information retrieval problem, it is customary [20]
to report both precision and recall of the perfor-
mance.
The segmentation results using TP local minima
are remarkably poor, even under the assumption
that the learner has already syllabified the input per-
fectly. Precision is 41.6%, and recall is 23.3%; over
half of the words extracted by the model are not ac-
tual English words, while close to 80% of actual
words fail to be extracted. And it is straightfor-
ward why this is the case. In order for SL to be
effective, a TP at an actual word boundary must
be lower than its neighbors. Obviously, this con-
dition cannot be met if the input is a sequence of
monosyllabic words, for which a space must be pos-
tulated for every syllable; there are no local min-
ima to speak of. While the pseudowords in [8]
are uniformly three-syllables long, much of child-
directed English consists of sequences of monosyl-
labic words: corpus statistics reveals that on aver-
age, a monosyllabic word is followed by another
monosyllabic word 85% of time. As long as this
is the case, SL cannot, in principle, work.
51
4 Statistics Needs UG
This is not to say that SL cannot be effective
for word segmentation. Its application, must be
constrained?like that of any learning algorithm
however powerful?as suggested by formal learning
theories [1-3]. The performance improves dramat-
ically, in fact, if the learner is equipped with even
a small amount of prior knowledge about phono-
logical structures. Specifically, we assume, uncon-
troversially, that each word can have only one pri-
mary stress. (This would not work for functional
words, however.) If the learner knows this, then
it may limit the search for local minima only in
the window between two syllables that both bear
primary stress, e.g., between the two a?s in the
sequence ?languageacquisition?. This assumption
is plausible given that 7.5-month-old infants are
sensitive to strong/weak prosodic distinctions [14].
When stress information suffices, no SL is em-
ployed, so ?bigbadwolf? breaks into three words
for free. Once this simple principle is built in, the
stress-delimited SL algorithm can achieve the pre-
cision of 73.5% and 71.2%, which compare favor-
ably to the best performance reported in the litera-
ture [20]. (That work, however, uses an computa-
tionally prohibitive and psychological implausible
algorithm that iteratively optimizes the entire lexi-
con.)
The computational models complement the ex-
perimental study that prosodic information takes
priority over statistical information when both are
available [21]. Yet again one needs to be cautious
about the improved performance, and a number of
unresolved issues need to be addressed by future
work. It remains possible that SL is not used at
all in actual word segmentation. Once the one-
word-one-stress principle is built in, we may con-
sider a model that does not use any statistics, hence
avoiding the computational cost that is likely to
be considerable. (While we don?t know how in-
fants keep track of TPs, there are clearly quite some
work to do. Syllables in English number in the
thousands; now take the quadratic for the potential
number of pair-wise TPs.) It simply stores previ-
ously extracted words in the memory to bootstrap
new words. Young children?s familiar segmenta-
tion errors??I was have? from be-have, ?hiccing up?
from hicc-up, ?two dults?, from a-dult?suggest that
this process does take place. Moreover, there is ev-
idence that 8-month-old infants can store familiar
sounds in the memory [22]. And finally, there are
plenty of single-word utterances?up to 10% [23]?
that give many words for free. The implementation
of a purely symbolic learner that recycles known
words yields even better performance: a precision
of 81.5% and recall of 90.1%.
5 Conclusion
Further work, both experimental and computational,
will need to address a few pressing questions, in or-
der to gain a better assessment of the relative contri-
bution of SL and UG to language acquisition. These
include, more pertinent to the problem of word seg-
mentation:
? Can statistical learning be used in the acquisi-
tion of language-specific phonotactics, a pre-
requisite to syllabification and a prelude to
word segmentation?
? Given that prosodic constraints are critical for
the success of SL in word segmentation, future
work needs to quantify the availability of stress
information in spoken corpora.
? Can further experiments, carried over realistic
linguistic input, further tease apart the multi-
ple strategies used in word segmentation [14]?
What are the psychological mechanisms (algo-
rithms) that integrate these strategies?
? How does word segmentation, statistical or
otherwise, work for agglutinative (e.g., Turk-
ish) and polysynthetic languages (e.g. Mo-
hawk), where the division between words,
morphology, and syntax is quite different from
more clear-cut cases like English?
Computational modeling can make explicit the
balance between statistics and UG, and are in the
same vein as the recent findings [24] on when/where
SL is effective/possible. UG can help SL by
providing specific constraints on its application,
and modeling may raise new questions for fur-
ther experimental studies. In related work [6,7],
we have augmented traditional theories of UG?
derivational phonology, and the Principles and Pa-
rameters framework?with a component of statisti-
cal learning, with novel and desirable consequences.
Yet in all cases, statistical learning, while perhaps
domain-general, is constrained by what appears to
be innate and domain-specific knowledge of linguis-
tic structures, such that learning can operate on spe-
cific aspects of the input evidence
References
1. Gold, E. M. (1967). Language identification in
the limit. Information and Control, 10:447-74.
2. Valiant, L. (1984). A theory of the learnable.
Communication of the ACM. 1134-1142.
52
3. Vapnik, V. (1995). The Nature of Statistical
Learning Theory. Berlin: Springer.
4. Chomsky, N. (1959). Review of Verbal Behav-
ior by B.F. Skinner. Language, 35, 26-57.
5. Chomsky, N. (1975). Reflections on Language.
New York: Pantheon.
6. Yang, C. D. (1999). A selectionist theory of
language development. In Proceedings of 37th
Meeting of the Association for Computational
Linguistics. Maryland, MD. 431-5.
7. Yang, C. D. (2002). Knowledge and Learning
in Natural Language. Oxford: Oxford Univer-
sity Press.
8. Saffran, J.R., Aslin, R.N., & Newport, E.L.
(1996). Statistical learning by 8-month old in-
fants. Science, 274, 1926-1928.
9. Gomez, R.L., & Gerken, L.A. (1999). Artifi-
cial grammar learning by one-year-olds leads
to specific and abstract knowledge. Cognition,
70, 109-135.
10. Saffran, J.R., Johnson, E.K., Aslin R.N. &
Newport, E.L. (1999). Statistical learning of
tone sequences by human infants and adults.
Cognition, 70, 27-52.
11. Fiser, J., & Aslin, R.N. (2002). Statistical
learning of new visual feature combinations by
infants. PNAS, 99, 15822-6.
12. Hauser, M., Newport, E.L., & Aslin, R.N.
(2001). Segmentation of the speech stream in
a non-human primate: Statistical learning in
cotton-top tamarins. Cognition, 78, B41-B52.
13. Bates, E., & Elman, J. (1996). Learning redis-
covered. Science, 274, 1849-50.
14. Jusczyk, P.W. (1999). How infants begin to ex-
tract words from speech. Trends in Cognitive
Sciences, 3, 323-8.
15. Chomsky, N. (1955/1975). The Logical Struc-
ture of Linguistic Theory. Manuscript, Har-
vard University and Massachusetts Institute of
Technology. Published in 1975 by New York:
Plenum.
16. Saffran, J.R., Aslin, R.N., & Newport, E.L.
(1997). Letters. Science, 276, 1177-1181
17. Crain, S., & Nakayama, M. (1987). Structure
dependency in grammar formation. Language,
63:522-543.
18. Bijeljiac-Babic, R., Bertoncini, J., & Mehler,
J. (1993). How do four-day-old infants cate-
gorize multisyllabic utterances. Developmen-
tal psychology, 29, 711-21.
19. MacWhinney, B. (1995). The CHILDES
Project: Tools for Analyzing Talk. Hillsdale:
Lawrence Erlbaum.
20. Brent, M. (1999). Speech segmentation and
word discovery: a computational perspective.
Trends in Cognitive Science, 3, 294-301.
21. Johnson, E.K. & Jusczyk, P.W. (2001) Word
segmentation by 8-month-olds: When speech
cues count more than statistics. Journal of
Memory and Language, 44, 1-20.
22. Jusczyk, P. W., & Hohne, E. A. (1997). In-
fants? memory for spoken words. Science, 277,
1984-6.
23. Brent, M.R., & Siskind, J.M. (2001). The role
of exposure to isolated words in early vocabu-
lary development. Cognition, 81, B33-44.
24. Newport, E.L., & Aslin, R.N. (2004). Learn-
ing at a distance: I. Statistical learning of non-
adjacent dependencies. Cognitive Psychology,
48, 127-62.
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 88?97,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Recession Segmentation: Simpler Online Word Segmentation Using
Limited Resources?
Constantine Lignos, Charles Yang
Dept. of Computer and Information Science, Dept. of Linguistics
University of Pennsylvania
lignos@cis.upenn.edu, charles.yang@ling.upenn.edu
Abstract
In this paper we present a cognitively plau-
sible approach to word segmentation that
segments in an online fashion using only
local information and a lexicon of pre-
viously segmented words. Unlike popu-
lar statistical optimization techniques, the
learner uses structural information of the
input syllables rather than distributional
cues to segment words. We develop a
memory model for the learner that like a
child learner does not recall previously hy-
pothesized words perfectly. The learner at-
tains an F-score of 86.69% in ideal condi-
tions and 85.05% when word recall is un-
reliable and stress in the input is reduced.
These results demonstrate the power that a
simple learner can have when paired with
appropriate structural constraints on its hy-
potheses.
1 Introduction
The problem of word segmentation presents an
important challenge in language acquisition. The
child learner must segment a continuous stream of
sounds into words without knowing what the in-
dividual words are until the stream has been seg-
mented. Computational models present an op-
portunity to test the potentially innate constraints,
structures, and algorithms that a child may be us-
ing to guide her acquisition. In this work we de-
velop a segmentation model from the constraints
suggested by Yang (2004) and evaluate it in ideal-
ized conditions and conditions that better approx-
imate the environment of a child learner. We seek
to determine how these limitations in the learner?s
input and memory affect the learner?s performance
and to demonstrate that the presented learner is ro-
bust even under non-ideal conditions.
?Portions of this work were adapted from an earlier
manuscript, Word Segmentation: Quick But Not Dirty.
2 Related Work
Most recent work in word segmentation of child-
directed speech has operated within statistical op-
timization frameworks, particularly Bayesian ap-
proaches (Goldwater et al, 2009; Johnson and
Goldwater, 2009). These models have established
the state-of-the-art for the task of selecting appro-
priate word boundaries from a stream of unstruc-
tured phonemes. But while these models deliver
excellent performance, it is not clear how they in-
form the process of acquisition.
Trying to find cognitive insight from these types
of models is difficult because of the inherent mis-
match in the quality and types of hypotheses they
maintain during learning. Children are incremen-
tal learners (Brown, 1973), and learners relying
on statistical optimization are generally not. A
child?s competence grows gradually as she hears
and produces more and more utterances, going
through predictable changes to her working gram-
mar (Marcus et al, 1992) that statistical optimiza-
tion techniques typically do not go through and do
not intend to replicate.
Statistical models provide excellent information
about the features, distributional cues, and priors
that can be used in learning, but provide little in-
formation about how a child learner can use this
information and how her knowledge of language
develops as the learning process evolves. Previ-
ous simulations in word segmentation using the
same type of distributional information as many
statistical optimization-based learners but without
an optimization model suggest that statistics alone
are not sufficient for learning to succeed in a com-
putationally efficient online manner; further con-
straints on the search space are needed (Yang,
2004).
Previous computational models have demanded
tremendous memory and computational capacity
from human learners. For example, the algorithm
88
of Brent & Cartwright (1996) produces a set of
possible lexicons that describe the learning cor-
pus, each of which is evaluated as the learner it-
erates until no further improvement is possible. It
is unlikely that an algorithm of this type is some-
thing a human learner is capable of using given the
requirement to remember at the very least a long
history of recent utterances encountered and con-
stantly reanalyze them to find a optimal segmenta-
tion. Work in this tradition makes no claims, how-
ever, that these methods are actually the ones used
by human learners.
On the other hand, previous computational
models often underestimate the human learner?s
knowledge of linguistic representations. Most of
these models are ?synthetic? in the sense of Brent
(1999): the raw material for segmentation is a
stream of segments, which are then successively
grouped into larger units and eventually, conjec-
tured words. This assumption may make the child
learner?s job unnecessarily hard; since syllables
are hierarchical structures consisting of segments,
treating the linguistic data as unstructured segment
sequences makes the problem harder than it actu-
ally is. For a given utterance, there are fewer sylla-
bles than segments, and hence fewer segmentation
possibilities.
Modeling the corpus using hierarchical gram-
mars that can model the input at varying levels
(word collocations, words, syllables, onsets, etc.)
provide the learner the most flexibility, allowing
the learner to build structure from the individual
phonemes and apply distributions at each level of
abstraction (Johnson and Goldwater, 2009). While
this results in state-of-the-art performance for seg-
mentation performed at the phoneme level, this
approach requires significant computational re-
sources as each additional level of representation
increases the complexity of learning. In addition,
it is not clear that some of the intermediate levels
in such an approach, such as word level colloca-
tions which are not syntactic constituents, would
have any linguistic or psychological reality to a
human learner.
A number of psychologically-motivated mod-
els of word segmentation rely on the use of syl-
labic transitional probabilities (TPs), basing the
use of TPs on experimental work in artificial lan-
guage learning (Saffran et al, 1996a; Saffran et
al., 1996b) and in corpus studies (Swingley, 2005).
The identification of the syllable as the basic unit
of segmentation is supported research in experi-
mental psychology using infants as young as 4-
days-old (Bijeljac-Babic et al, 1993), but when
syllable transitional probabilities are evaluated in
online learning procedures that only use local in-
formation (Yang, 2004), the results are surpris-
ingly poor, even under the assumption that the
learner has already syllabified the input perfectly.
Precision is 41.6%, and recall is 23.3%, which
we will show is worse than a simple baseline of
assuming every syllable is a word. The below-
baseline performance is unsurprising given that in
order for this type of model to posit a word bound-
ary, a transitional probability between syllables
must be lower than its neighbors. This condition
cannot be met if the input is a sequence of mono-
syllabic words for which a boundary must be pos-
tulated for every syllable; it is impossible to treat
every boundary as a local minimum.
While the pseudo-words used in infant stud-
ies measuring the ability to use transitional prob-
ability information are uniformly three-syllables
long, much of child-directed English consists of
sequences of monosyllabic words. Corpus statis-
tics reveal that on average a monosyllabic word
is followed by another monosyllabic word 85%
of time (Yang, 2004), and thus learners that use
only local transitional probabilities without any
global optimization are unlikely to succeed. This
problem does not affect online approaches that
use global information, such as computing the
maximum likelihood of the corpus incrementally
(Venkataraman, 2001). Since these approaches do
not require each boundary be a local minimum,
they are able to correctly handle a sequence of
monosyllable words.
We believe that the computational modeling of
psychological processes, with special attention to
concrete mechanisms and quantitative evaluations,
can play an important role in identifying the con-
straints and structures relevant to children?s acqui-
sition of language. Rather than using a prior which
guides the learner to a desired distribution, we ex-
amine learning with respect to a model in which
the hypothesis space is constrained by structural
requirements.
In this paper we take a different approach than
statistical optimization approaches by exploring
how well a learner can perform while processing
a corpus in an online fashion with only local in-
formation and a lexicon of previously segmented
89
words. We present a simple, efficient approach
to word segmentation that uses structural informa-
tion rather than distributional cues in the input to
segment words. We seek to demonstrate that even
in the face of impoverished input and limited re-
sources, a simple learner can succeed when it op-
erates with the appropriate constraints.
3 Constraining the Learning Space
Modern machine learning research (Gold, 1967;
Valiant, 1984; Vapnik, 2000) suggests that con-
straints on the learning space and the learning
algorithm are essential for realistically efficient
learning. If a domain-neutral learning model fails
on a specific task where children succeed, it is
likely that children are equipped with knowledge
and constraints specific to the task at hand. It
is important to identify such constraints to see to
what extent they complement, or even replace, do-
main neutral learning mechanisms.
A particularly useful constraint for word seg-
mentation, introduced to the problem of word
segmentation by Yang (2004) but previously dis-
cussed by Halle and Vergnaud (1987), is as fol-
lows:
Unique Stress Constraint (USC): A word can
bear at most one primary stress.
A simple example of how adult learners might
use the USC is upon hearing novel names or
words. Taking Star Wars characters as an exam-
ple, it is clear that chewbacca is one word but
darthvader cannot be as the latter bears two pri-
mary stresses.
The USC could give the learner many isolated
words for free. If the learner hears an utterance
that contains exactly one primary stress, it is likely
it is a single word. Moreover, the segmenta-
tion for a multiple word utterance can be equally
straightforward under USC. Consider a sequence
W1S1S2S3W2, where W stands for a weak sylla-
ble and S stands for a strong syllable. A learner
equipped with USC will immediately know that
the sequence consists of three words: specifically,
W1S1, S2, and S2W2.
The USC can also constrain the use of other
learning techniques. For example, the syllable
consequence S1W1W2W3S2 cannot be segmented
by USC alone, but it may still provide cues that
facilitate the application of other segmentation
strategies. For instance, the learner knows that the
sequence consists of at least two words, as indi-
cated by two strong syllables. Moreover, it also
knows that in the window between S1 and S2 there
must be one or more word boundaries.
Yang (2004) evaluates the effectiveness of the
USC in conjunction with a simple approach to us-
ing transitional probabilities. The performance of
the approach presented there improves dramati-
cally if the learner is equipped with the assump-
tion that each word can have only one primary
stress. If the learner knows this, then it may
limit the search for local minima to only the win-
dow between two syllables that both bear primary
stress, e.g., between the two a?s in the sequence
languageacquisition. This assumption is plau-
sible given that 7.5-month-old infants are sensi-
tive to strong/weak prosodic distinctions (Jusczyk,
1999). Yang?s stress-delimited algorithm achieves
the precision of 73.5% and recall of 71.2%, a sig-
nificant improvement over using TPs alone, but
still below the baseline presented in our results.
The improvement of the transitional
probability-based approach when provided
with a simple linguistic constraint suggests
that structural constraints can be powerful in
narrowing the hypothesis space so that even
sparse, local information can prove useful and
simple segmentation strategies can become more
effective.
It should be noted that the classification of every
syllable as ?weak? or ?strong? is a significant sim-
plification. Stress is better organized into hierar-
chical patterns constructed on top of syllables that
vary in relative prominence based on the domain
of each level of the hierarchy, and generally lan-
guages avoid adjacent strong syllables (Liberman
and Prince, 1977). We later discuss a manipula-
tion of the corpus used by Yang (2004) to address
this concern.
Additionally, there are significant challenges
in reconstructing stress from an acoustic signal
(Van Kuijk and Boves, 1999). For a child learner
to use the algorithm presented here, she would
need to have mechanisms for detecting stress in
the speech signal and categorizing the gradient
stress in utterances into a discrete level for each
syllable. These mechanisms are not addressed in
this work; our focus is on an algorithm that can
succeed given discrete stress information for each
syllable. Given the evidence that infants can dis-
tinguish weak and strong syllables and use that in-
90
formation to detect word boundaries (Jusczyk et
al., 1999), we believe that it is reasonable to as-
sume that identifying syllabic stress is a task an
infant learner can perform at the developmental
stage of word segmentation.
4 A Simple Algorithm for Word
Segmentation
We now present a simple algebraic approach to
word segmentation based on the constraints sug-
gested by Yang (2004). The learner we present is
algebraic in that it has a lexicon which stores pre-
viously segmented words and identifies the input
as a combination of words already in the lexicon
and novel words. No transitional probabilities or
any distributional data are calculated from the in-
put. The learner operates in an online fashion, seg-
menting each utterance in a primarily left-to-right
fashion and updating its lexicon as it segments.
The USC is used in two ways by the learner.
First, if the current syllable has primary stress and
the next syllable also has primary stress, a word
boundary is placed between the current and next
syllable. Second, whenever the algorithm is faced
with the choice of accepting a novel word into the
lexicon and outputting it as a word, the learner
?abstains? from doing so if the word violates USC,
that is if it contains more than one primary stress.
Since not all words are stressed, if a word contains
no primary stresses it is considered an acceptable
word; only a word with more that one primary
stress is prohibited. If a sequence of syllables has
more than one primary stress and cannot be seg-
mented further, the learner does not include that
sequence in its segmentation of the utterance and
does not add it to the lexicon as it cannot be a valid
word.
The algorithm is as follows, with each step ex-
plained in further detail in the following para-
graphs.
For each utterance in the corpus, do the following:
1. As each syllable is encountered, use Initial
Subtraction and USC Segmentation to seg-
ment words from the beginning of the utter-
ance if possible.
2. If unsegmented syllables still remain, apply
Final Subtraction, segmenting words itera-
tively from the end of the utterance if pos-
sible.
3. If unsegmented syllables still remain, if those
syllables constitute a valid word under the
USC, segment them as a single word and add
them to the lexicon. Otherwise, abstain, and
do not include these syllables in the segmen-
tation of the sentence and do not add them to
the lexicon.
Initial Subtraction. If the syllables of the utter-
ance from the last segmentation (or the start of the
utterance) up to this point matches a word in the
lexicon but adding one more syllable would result
in it not being a known word, segment off the rec-
ognized word and increase its frequency. This iter-
atively segments the longest prefix word from the
utterance.
USC Segmentation. If the current and next syl-
lables have primary stress, place a word bound-
ary after the current syllable, treating all syllables
from the last segmentation point up to and and in-
cluding the current syllable as a potential word. If
these syllables form a valid word under the USC,
segment them as a word and add them to the lex-
icon. Otherwise, abstain, not including these syl-
lables in the segmentation of the sentence and not
adding them to the lexicon.
Final Subtraction. After initial subtraction and
USC Segmentation have been maximally applied
to the utterance, the learner is often left with a
sequence of syllables that is not prefixed by any
known word and does not have any adjacent pri-
mary stresses. In this situation the learner works
from right to left on the remaining utterance, iter-
atively removing words from the end of the utter-
ance if possible. Similar to the approach used in
Initial Subtraction, the longest word that is a suf-
fix word of the remaining syllables is segmented
off, and this is repeated until the entire utterance is
segmented or syllables remain that are not suffixed
by any known word.
The ability to abstain is a significant difference
between this learner and most recent work on this
task. Because the learner has a structural descrip-
tion for a word, the USC, it is able to reject any
hypothesized words that do not meet the descrip-
tion. This improves the learner?s precision and
recall because it reduces the number of incorrect
predictions the learner makes. The USC also al-
lows the learner keep impossible words out of its
lexicon.
91
0 20 40 60 80 100
0.0
0.2
0.4
0.6
0.8
1.0
Count
Prob
abili
ty of
 Rec
all
Figure 1: The selected probabilistic memory func-
tion for ? = 0.05. The dashed line at 0.05 rep-
resents the threshold above which a word is more
likely than not to be recalled, occurring at a count
of approximately 14.
5 A Probabilistic Lexicon
To simulate the imperfect memory of a child
learner, we use a simple exponential function to
generate the probability with which a word is re-
trieved from the lexicon:
pr(word) = 1.0? e
??c(word)
pr(word) is the probability of a word being re-
trieved, ? is a constant, and c(word) is the number
of times the word has been identified in segmen-
tations thus far. This type of memory function is
a simplified representation of models of humans?
memory recall capabilities (Anderson et al, 1998;
Gillund and Shiffrin, 1984). This memory func-
tion for the value of ? = 0.05, the value used in
our experiments, is given in Figure 1. We later
show that the choice of ? has little impact on the
learner?s segmentation performance, and thus the
more or less arbitrary selection of a value for ? is
of little consequence.
When the algorithm attempts to subtract words
from the beginning or end of an utterance, it may
miss words in the lexicon due to this probabilis-
tic retrieval. The learner only has one opportu-
nity to recall a word in a given utterance. For ex-
ample, in the utterance P.EH1.N S.AH0.L (pencil),
if the learner has P.EH1.N and P.EH1.N S.AH0.L
in its lexicon but P.EH1.N is more frequent, it
may fail to recall P.EH1.N S.AH0.L when exam-
ining the second syllable but succeed in recog-
nizing P.EH1.N in the first. Thus it will break
off P.EH1.N instead of P.EH1.N S.AH0.L. This
means the learner may fail to reliably break off
the longest words, instead breaking off the longest
word that is successfully recalled.
While probabilistic memory means that the
learner will fail to recognize words it has seen be-
fore, potentially decreasing recall, it also provides
the learner the benefit of probabilistically failing
to repeat previous mistakes if they occur rarely.
Probabilistic word recall results in a ?rich
get richer? phenomenon as the learner segments;
words that are used more often in segmentations
are more likely to be reused in later segmentations.
While recent work from Bayesian approaches has
used a Dirichlet Process to generate these distri-
butions (Goldwater et al, 2006), in this learner the
reuse of frequent items in learning is a result of
the memory model rather than an explicit process
of reusing old outcomes or generating new ones.
This growth is an inherent property of the cogni-
tive model of memory used here rather than an ex-
ternally imposed computational technique.
6 Evaluation
Our computational model is designed to process
child-directed speech. The corpus we use to eval-
uate it is the same corpus used by Yang (2004).
Adult utterances were extracted from the Brown
(1973) data in the CHILDES corpus (MacWhin-
ney, 2000), consisting of three children?s data:
Adam, Eve, and Sarah. We obtained the pho-
netic transcriptions of words from the Carnegie
Mellon Pronouncing Dictionary (CMUdict) Ver-
sion 0.6 (Weide, 1998), using the first pronunci-
ation of each word. In CMUdict, lexical stress
information is preserved by numbers: 0 for un-
stressed, 1 for primary stress, 2 for secondary
stress. For instance, cat is represented as K.AE1.T,
catalog is K.AE1.T.AH0.L.AO0.G, and catapult is
K.AE1.T.AH0.P.AH2.L.T. We treat primary stress
as ?strong? and secondary or unstressed syllables
as ?weak.?
For each word, the phonetic segments were
grouped into syllables. This process is straightfor-
ward by the use of the principle ?Maximize On-
set,? which maximizes the length of the onset as
long as it is valid consonant cluster of English, i.e.,
92
it conforms to the phonotactic constraints of En-
glish. For example, Einstein is AY1.N.S.T.AY0.N
as segments and parsed into AY1.N S.T.AY0.N as
syllables: this is because /st/ is the longest valid
onset for the second syllable containing AY0 while
/nst/ is longer but violates English phonotac-
tics. While we performed syllabification as a pre-
processing step outside of learning, a child learner
would presumably learn the required phonotac-
tics as a part of learning to segment words. 9-
month old infants are believed to have learned
some phonotactic constraints of their native lan-
guage (Mattys and Jusczyk, 2001), and learning
these constraints can be done with only minimal
exposure (Onishi et al, 2002).
Finally, spaces and punctuation between
words were removed, but the boundaries be-
tween utterances?as indicated by line breaks in
CHILDES?are retained. Altogether, there are
226,178 words, consisting of 263,660 syllables.
The learning material is a list of unsegmented
syllable sequences grouped into utterances, and
the learner?s task is to find word boundaries that
group substrings of syllables together, building a
lexicon of words as it segments.
We evaluated the learner?s performance to ad-
dress these questions:
? How does probabilistic memory affect
learner performance?
? How much does degrading stress information
relied on by USC segmentation reduce per-
formance?
? What is the interaction between the proba-
bilistic lexicon and non-idealized stress infor-
mation?
To evaluate the learner, we tested configurations
that used a probabilistic lexicon and ones with per-
fect memory in two scenarios: Dictionary Stress,
and Reduced Stress. We create the Reduced Stress
condition in order to simulate that stress is of-
ten reduced in casual speech, and that language-
specific stress rules may cause reductions or shifts
in stress that prevent two strong syllables from oc-
curring in sequence. The difference between the
scenarios is defined as follows:
Dictionary Stress. The stress information is
given to the learner as it was looked up in CMU-
dict. For example, the first utterance from the
Adam corpus would be B.IH1.G D.R.AH1.M (big
drum), an utterance with two stressed monosyl-
lables (SS). In most languages, however, condi-
tions where two stressed syllables are in sequence
are handled by reducing the stress of one syllable.
This is simulated in the reduced stress condition.
Reduced Stress. The stress information ob-
tained from CMUdict is post-processed in the con-
text of each utterance. For any two adjacent pri-
mary stressed syllables, the first syllable is re-
duced from a strong syllable to a weak one. This is
applied iteratively from left to right, so for any se-
quence of n adjacent primary-stress syllables, only
the nth syllable retains primary stress; all others
are reduced. This removes the most valuable clue
as to where utterances can be segmented, as USC
segmentation no longer applies. This simulates the
stress retraction effect found in real speech, which
tries to avoid adjacent primary stresses.
Learners that use probabilistic memory were al-
lowed to iterate over the input two times with ac-
cess to the lexicon developed over previous iter-
ations but no access to previous segmentations.
This simulates a child hearing many of the same
words and utterances again, and reduces the effect
of the small corpus size used on the learning pro-
cess. Because the probabilistic memory reduces
the algorithm?s ability to build a lexicon, perfor-
mance in a single iteration is lower than perfect
memory conditions. In all other conditions, the
learner is allowed only a single pass over the cor-
pus.
The precision and recall metrics are calculated
for the segmentation that the learner outputs and
the lexicon itself. For an utterance, each word
in the learner?s segmentation that also appears in
the gold standard segmentation is counted as cor-
rect, and each word in the learner?s segmentation
not present in the gold standard segmentation is
a false alarm. F-score is computed using equally
balanced precision and recall (F0). The correct
words, false words, and number of words in the
gold standard are summed over the output in each
iteration to produce performance measures for that
iteration.
Precision, recall, and F-score are similarly com-
puted for the lexicon; every word in the learner?s
lexicon present in the gold standard is counted as
correct, and every word in the learner?s lexicon not
present in the gold standard is a false alarm. These
computations are performed over word types in
the lexicon, thus all words in the lexicon are of
93
equal weight in computing performance regard-
less of their frequency. In the probabilistic mem-
ory conditions, however, the memory function de-
fines the probability of each word being recalled
(and thus being considered a part of the lexicon)
at evaluation time.
In addition to evaluating the learner, we also im-
plemented three baseline approaches to compare
the learner against. The Utterance baseline seg-
menter assumes every utterance is a single word.
The Monosyllabic baseline segmenter assumes ev-
ery syllable is a single word. The USC segmenter
inserts word boundaries between all adjacent syl-
lables with primary stress in the corpus.
6.1 Results
The performance of the learner and baseline seg-
menters is given in Table 1. While the Utterance
segmenter provides expectedly poor performance,
the Monosyllabic segmenter sets a relatively high
baseline for the task. Because of the impoverished
morphology of English and the short words that
tend to be used in child-directed speech, assuming
each syllable is a word proves to be an excellent
heuristic. It is unlikely that this heuristic will per-
form as well in other languages. Because the USC
segmenter only creates segmentation points where
there are words of adjacent primary stress, it is
prone to attaching unstressed monosyllabic func-
tion words to content words, causing very low lex-
icon precision (13.56%).
With both perfect memory and dictionary stress
information, the learner attains an F-score of
86.69%, with precision (83.78%) lower than re-
call (89.81%). First, we consider the effects of
probabilistic memory on the learner. In the Dictio-
nary Stress condition, using probabilistic memory
decreases Fo by 1.15%, a relatively small impact
given that with the setting of ? = 0.05 the learner
must use a word approximately 14 times before it
can retrieve it with 50% reliability and 45 times
before it can retrieve it with 90% reliability. In the
first iteration over the data set, 17.87% of lexicon
lookups for words that have been hypothesized be-
fore fail. The impact on F0 is caused by a drop in
recall, as would be expected for a such a memory
model.
To examine the effect of the ? parameter for
probabilistic memory on learner performance, we
plot the utterance and lexicon F0 after the learner
iterates over the corpus once in the Probabilistic
0.0 0.2 0.4 0.6 0.8 1.0
0.0
0.2
0.4
0.6
0.8
1.0
Memory Parameter
F?S
core
l l l l l l l l l l l
l UtteranceLexicon
Figure 2: Learner utterance and lexicon F-scores
after two iterations when ? is varied in the Proba-
bilistic Memory, Dictionary Stress condition
Perfect
Memory,
Dictionary
Stress
Perfect
Memory,
Reduced
Stress
USC Seg. 114,333 0
Initial Sub. 65,800 164,989
Final Sub. 5,690 14,813
Total 185,823 179,802
Table 2: Number of segmentations performed by
each operation: USC Segmentation, Initial Sub-
traction, and Final Subtraction.
Memory, Dictionary Stress condition. As Figure 2
shows, the choice of ? has little effect on the ut-
terance F0 through most of a broad range from
0.01 to 0.9. Because the setting of ? determines
the number of times a word must be hypothesized
before it can reliably be recalled, it expectedly
has a significant effect on lexicon F0. The selec-
tion of ? = 0.05 for our experiments is thus un-
likely to have had any significant bearing on the
utterance segmentation performance, although for
lower values of ? precision is favored while for
larger values recall is favored. Larger values of
? imply the learner is able to recall items after
fewer exposures. While a larger value of ? would
have yielded higher performance in lexicon per-
formance, it also assumes much more about the
learner?s memory capabilities.
The Reduced Stress condition also has only a
94
Utterances Lexicon
Segmenter Precision Recall F0 Precision Recall F0
Utterance 18.61% 4.67% 7.47% 3.57% 30.35% 6.39%
Monosyllabic 73.29% 85.44% 78.90% 55.41% 43.88% 48.97%
USC 81.06% 61.52% 69.95% 13.56% 66.97% 22.55%
Perfect Memory, Dictionary Stress 83.78% 89.81% 86.69% 67.72% 58.60% 62.83%
Perfect Memory, Reduced Stress 82.32% 85.81% 84.03% 39.18% 50.08% 43.97%
Prob. Memory, Dictionary Stress 84.05% 87.07% 85.54% 72.34% 30.01% 42.42%
Prob. Memory, Reduced Stress 84.85% 85.24% 85.05% 41.13% 22.91% 29.43%
Table 1: Baseline and Learner Performance. Performance is reported after two iterations over the corpus
for probabilistic memory learners and after a single iteration for all other learners.
small impact on utterance segmentation perfor-
mance. This suggests that the USC?s primary
value to the learner is in constraining the contents
of the lexicon and identifying words in isolation as
good candidates for the lexicon. In the Reduced
Stress condition where the USC is not directly re-
sponsible for any segmentations as there are no
adjacent primary-stressed syllables, the learner re-
lies much more heavily on subtractive techniques.
Table 2 gives the number of segmentations per-
formed using each segmentation operation. The
total number of segmentations is very similar be-
tween the Dictionary and Reduced Stress condi-
tions, but because USC Segmentation is not effec-
tive on Reduced Stress input, Initial and Final Sub-
traction are used much more heavily.
7 Discussion
The design of the segmenter presented here sug-
gests that both the quality of memory and the
structural purity of the input would be critical fac-
tors in the learner?s success. Our results suggest,
however, that using probabilistic memory and a
less idealized version of stress in natural language
have little impact on the performance of the pre-
sented learner. They do cause the learner to learn
much more slowly, causing the learner to need to
be presented with more material and resulting in
worse performance in the lexicon evaluation. But
this slower learning is unlikely to be a concern for
a child learner who would be exposed to much
larger amounts of data than the corpora here pro-
vide.
Cognitive literature suggests that limited mem-
ory during learning may be essential to a learner in
its early stages (Elman, 1993). But we do not see
any notable improvement as a result of the prob-
abilistic memory model used in our experiments,
although the learner does do better in the Reduced
Stress condition with Probabilistic Memory than
Perfect Memory. This should not be interpreted
as a negative result as we only analyze a single
learner and memory model. Adding decay to the
model such that among words of equal frequency
those that have not been used in segmentation re-
cently are less likely to be remembered may be
sufficient to create the desired effect.
The success of this learner suggests that the
type of ?bootstrapping? approaches can succeed
in word segmentation. The learner presented uses
USC to identify utterances that are likely to be
lone words, seeding the lexicon with initial infor-
mation. Even if these first items in the lexicon are
of relatively low purity, often combining function
words and content words into one, the learner is
able to expand its lexicon by using these hypothe-
sized words to segment new input. As the learner
segments more, these hypotheses become more re-
liable, allowing the learner to build a lexicon of
good quality.
The subtraction approaches presented in this
work provide a basic algorithm for to handling
segmentation of incoming data in an online fash-
ion. The subtractive heuristics used here are of
course not guaranteed to result in a perfect seg-
mentation even with a perfect lexicon; they are
presented to show how a simple model of pro-
cessing incoming data can be paired with struc-
tural constraints on the hypothesis space to learn
word segmentation in a computationally efficient
and cognitively plausible online fashion.
8 Conclusions
The learner?s strong performance using minimal
computational resources and unreliable memory
suggest that simple learners can succeed in un-
95
supervised tasks as long as they take advantage
of domain-specific knowledge to constrain the hy-
pothesis space. Our results show that, even in ad-
versarial conditions, structural constraints remain
powerful tools for simple learning algorithms in
difficult tasks.
Future work in this area should focus on learn-
ers that can take advantage of the benefits of a
probabilistic lexicon and memory models suited
to them. Also, a more complex model of the type
of stress variation present in natural speech would
help better determine a learner that uses USC?s
ability to handle realistic variation in the input.
Our model of stress reduction is a worst-case sce-
nario for USC segmentation but is unlikely to be
an accurate model of real speech. Future work
should adopt a more naturalistic model to deter-
mine whether the robustness found in our results
holds true in more realistic stress permutations.
Acknowledgements
We thank Kyle Gorman, Josef Fruehwald, and
Dan Swingley for their helpful discussions regard-
ing this work. We are grateful to and Mitch Mar-
cus and Jana Beck for their feedback on earlier
versions of this paper.
References
J.R. Anderson, D. Bothell, C. Lebiere, and M. Matessa.
1998. An integrated theory of list memory. Journal
of Memory and Language, 38(4):341?380.
R. Bijeljac-Babic, J. Bertoncini, and J. Mehler. 1993.
How do 4-day-old infants categorize multisyllabic
utterances? Developmental Psychology, 29:711?
711.
M.R. Brent and T.A. Cartwright. 1996. Distributional
regularity and phonotactic constraints are useful for
segmentation. Cognition, 61(1-2):93?125.
M.R. Brent. 1999. An efficient, probabilistically
sound algorithm for segmentation and word discov-
ery. Machine Learning, 34(1):71?105.
R. Brown. 1973. A First Language: The Early
Stages. Harvard Univ. Press, Cambridge, Mas-
sachusetts 02138.
J.L. Elman. 1993. Learning and development in neural
networks: The importance of starting small. Cogni-
tion, 48(1):71?99.
G. Gillund and R.M. Shiffrin. 1984. A retrieval model
for both recognition and recall. Psychological Re-
view, 91(1):1?67.
E.M. Gold. 1967. Language identification in the limit.
Information and control, 10(5):447?474.
S. Goldwater, T. Griffiths, and M. Johnson. 2006. In-
terpolating between types and tokens by estimating
power-law generators. Advances in Neural Informa-
tion Processing Systems, 18:459.
S. Goldwater, T.L. Griffiths, and M. Johnson. 2009.
A Bayesian framework for word segmentation: Ex-
ploring the effects of context. Cognition.
M. Halle and J.R. Vergnaud. 1987. An essay on stress.
MIT Press.
M. Johnson and S. Goldwater. 2009. Improving non-
parameteric Bayesian inference: experiments on un-
supervised word segmentation with adaptor gram-
mars. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 317?325. Association for
Computational Linguistics.
P.W. Jusczyk, D.M. Houston, and M. Newsome. 1999.
The Beginnings of Word Segmentation in English-
Learning Infants. Cognitive Psychology, 39(3-
4):159?207.
P.W. Jusczyk. 1999. How infants begin to extract
words from speech. Trends in Cognitive Sciences,
3(9):323?328.
M. Liberman and A. Prince. 1977. On stress and lin-
guistic rhythm. Linguistic Inquiry, 8(2):249?336.
B. MacWhinney. 2000. The CHILDES Project: Tools
for Analyzing Talk. Lawrence Erlbaum Associates.
G.F. Marcus, S. Pinker, M. Ullman, M. Hollander, T.J.
Rosen, F. Xu, and H. Clahsen. 1992. Overregular-
ization in language acquisition. Monographs of the
Society for Research in Child Development, 57(4).
S.L. Mattys and P.W. Jusczyk. 2001. Phonotactic cues
for segmentation of fluent speech by infants. Cogni-
tion, 78(2):91?121.
K.H. Onishi, K.E. Chambers, and C. Fisher. 2002.
Learning phonotactic constraints from brief auditory
experience. Cognition, 83(1):B13?B23.
J.R. Saffran, R.N. Aslin, and E.L. Newport. 1996a.
Statistical Learning by 8-month-old Infants. Sci-
ence, 274(5294):1926.
J.R. Saffran, E.L. Newport, and R.N. Aslin. 1996b.
Word Segmentation: The Role of Distributional
Cues. Journal of Memory and Language,
35(4):606?621.
D. Swingley. 2005. Statistical clustering and the con-
tents of the infant vocabulary. Cognitive Psychol-
ogy, 50(1):86?132.
LG Valiant. 1984. A theory of the learnable. Commu-
nications of the ACM, 27(11):1142.
96
D. Van Kuijk and L. Boves. 1999. Acoustic char-
acteristics of lexical stress in continuous telephone
speech. Speech Communication, 27(2):95?111.
V.N. Vapnik. 2000. The nature of statistical learning
theory. Springer.
A. Venkataraman. 2001. A statistical model for word
discovery in transcribed speech. Computational
Linguistics, 27(3):351?372.
R.L. Weide. 1998. The Carnegie Mellon Pronouncing
Dictionary [cmudict. 0.6].
C.D. Yang. 2004. Universal Grammar, statistics or
both? Trends in Cognitive Sciences, 8(10):451?456.
97
Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics, pages 30?38,
Portland, Oregon, June 2011. c?2011 Association for Computational Linguistics
A Statistical Test for Grammar
Charles Yang
Department of Linguistics & Computer Science
Institute for Research in Cognitive Science
University of Pennsylvania
charles.yang@ling.upenn.edu
Abstract
We propose a statistical test for measuring
grammatical productivity. We show that
very young children?s knowledge is consistent
with a systematic grammar that independently
combines linguistic units. To a testable extent,
the usage-based approach to language and lan-
guage learning, which emphasizes the role of
lexically specific memorization, is inconsis-
tent with the child language data. We also dis-
cuss the connection of this research with de-
velopments in computational and theoretical
linguistics.
1 Introduction
Eistein was a famously late talker. The great physi-
cist?s first words, at the ripe age of three, were to pro-
claim ?The soup is too hot.? Apparently he hadn?t
had anything interesting to say.
The moral of the story is that one?s linguistic be-
havior may not be sufficiently revealing of one?s lin-
guistic knowledge. The problem is especially acute
in the study of child language since children?s lin-
guistic production is often the only, and certainly
the most accessible, data on hand. Much of the tra-
ditional research in language acquisition recognizes
this challenge (Shipley et al 1969, Slobin 1971,
Bowerman 1973, Brown 1973) and has in general
advocated the position that child language be inter-
preted in terms of adult-like grammatical devices.
This tradition has been challenged by the usage-
based approach to language (Tomasello 1992,
2000a) which, while reviving some earlier theories
of child grammar (Braine 1964), also reflects a cur-
rent trend in linguistic theorizing that emphasizes
the storage of specific linguistic forms and con-
structions at the expense of general combinatorial
linguistic principles and overarching points of lan-
guage variation (Goldberg 2003, Sag 2010, etc.).
Child language, especially in the early stages, is
claimed to consist of specific usage-based schemas,
rather than productive linguistic system as pre-
viously conceived. The main evidence for this
approach comes from the lack of combinatorial
diversity?the hallmark of a productive grammar?
in child language data (Tomasello 2000a). For
instance, verbs in young children?s language tend
to appear in very few frames rather than across
many; this ?uneveness? has been attributed to the
verb-specific predicate structures rather than gen-
eral/categorical rules. Similar observations have
been made in the acquisition of inflectional mor-
phology, where many stems are used only in rel-
atively few morphosyntactic contexts (e.g., person,
number). Another concrete example comes from
the syntactic use of the determiners ?a? and ?the?,
which can be interchangeably used with singular
nouns.1 An overlap metric has been defined as the
ratio of nouns appearing with both ?a? and ?the?
out of those appearing with either. Pine & Lieven
(1997) find that overlap values are generally low in
child language, in fact considerably below chance
level. This finding is taken to support the view that
the child?s determiner use is bound with specific
nouns rather than reflecting a productive grammar
defined over the abstract categories of determiners
and nouns (Valian 1986).
1Although ?a? is typically described as combining with
countable nouns, instances such as ?a water?, ?a sun? and ?a
floor? are frequently attested in both child and adult speech from
CHILDES.
30
The computational linguistics literature has seen
the influence of usage-based approach: computa-
tional models have been proposed to proceed from
an initial stage of lexicalized constructions toward
a more general grammatical system (Felman 2004,
Steels 2004, cf. Wintner 2009). However, as far as
we can tell, the evidence for an unproductive stage
of grammar as discussed above was established on
the basis of intuition rather than rigorous assess-
ments. We are not aware of a statistical test against
which the predictions of usage-based learning can
be verified. Nor are we of any demonstration that
the child language data described above is inconsis-
tent with the expectation of a fully productive gram-
mar, the position rejected in usage-based learning.
It is also worth noting that while the proponents of
the grammar based approach have often produced
tests for the quality of the grammar?e.g., the errors
in child language are statistically significantly low?
they have likewise failed to provide tests for the exis-
tence of the grammar. As has been pointed out in the
usage-based learning literature, low error rates could
be the result of rote memorization of adult linguistic
forms.
In this paper, we provide statistical analysis of
grammar to fill these gaps. The test is designed
to show whether a corpus of linguistic expressions
can be accounted for as the output of a produc-
tive grammar that freely combines linguistic units.
We demonstrate through case studies based on
CHILDES (MacWhinney 2000) that children?s lan-
guage shows the opposite of the usage-based view,
and it is the productivity hypothesis that is con-
firmed. We also aim to show that the child data
is inconsistent with the memory-and-retrieval ap-
proach in usage-based learning (Tomasello 2000b).
Furthermore, through empirical data and numerical
simulations, we show that our statistical test (cor-
rectly) over-predicts productivity for linguistic com-
binations that are subject to lexical exceptions (e.g.,
irregular tense inflection). We conclude by drawing
connections between this work and developments in
computational and theoretical linguistics.
0
2
4
6
8
10
12
0 1 2 3 4 5 6 7 8 9
log(freq)
log(rank)
Figure 1: The power law frequency distribution of Tree-
bank rules.
2 Quantifying Productivity
2.1 Zipfian Combinatorics
Zipf?s law has long been known to be an om-
nipresent feature of natural language (Zipf 1949,
Mendelbrot 1954). Specifically, the probability pr
of the word nr with the rank r among N word types
in a corpus can be expressed as follows:
pr =
(
C
r
)/( N?
i=1
C
i
)
=
1
rHN
, HN =
N?
i=1
1
i
(1)
Empirical tests show that Zipf?s law provides an ex-
cellent fit of word frequency distributions across lan-
guages and genres (Baroni 2008).
It has been noted that the linguistic combinations
such as n-grams show Zipf-like power law distribu-
tions as well (Teahna 1997, Ha et al 2002), which
contributes to the familiar sparse data problem in
computational linguistics. These observations gen-
eralize the combination of morphemes (Chan 2008)
and grammatical rules. Figure 1 plots the ranks and
frequencies syntactic rules (on log-log scale) from
the Penn Treebank (Marcus et al 1993); certain
rules headed by specific functional words have been
merged.
Claims of usage-based learning build on the
31
premise that linguistic productivity entails diver-
sity of usage: the ?unevenness? in usage distribu-
tion such as the low overlap in D(eterminer)-N(oun)
combinations is taken to be evidence against a sys-
tematic grammar. Paradoxically, however, Valian et
al. (2008) find that the D-N overlap values in moth-
ers? speech to children do not differ significantly
from those in children?s speech. In fact, when ap-
plied to the Brown corpus, we find that ?a/the? over-
lap for singular nouns is only 25.2%: almost three
quarters that could have appeared with both deter-
miners only appeared with one exclusively. The
overlap value of 25.2% is actually lower than those
of some children reported in Pine & Lieven (1997):
the language of the Brown corpus, which draws
from various genres of professional print materials,
must be regarded as less productive and more usage-
based than that of a toddler?which seems absurd.
Consider the alternative to the usage based view,
a fully productive rule that combines a determiner
and a singular noun, or ?DP? D N?, where ?D?
a|the? and ?N? cat|book|desk|...?. Other rules
can be similarly formulated: e.g., ?VP? V DP?,
?Vinflection ? Vstem + Person + Number + Tense?.
Suppose a linguistic sample contains S determiner-
noun pairs, which consist of D and N unique deter-
miners and nouns. (In the present case D = 2 for
?a? and ?the?.) The full productivity of the DP rule,
by definition, means that the two categories combine
independently. Two observations, one obvious and
the other novel, can be made in the study of D-N
usage diversity. First, nouns will follow zipf?s law.
For instance, the singular nouns that appear in the
form of ?DP? D N? in the Brown corpus show a
log-log slope of -0.97. In the CHILDES speech tran-
scripts of six children (see section 3.1 for details for
data analysis), the average value of log-log slope is
-0.98. Thus, relatively few nouns occur often but
many will occur only once?which of course cannot
overlap with more than one determiners.
Second, while the combination of D and N in the
DP rule is syntactically interchangeable, N ?s may
favor one of the two determiners, a consequence of
pragmatics and indeed non-linguistic factors. For in-
stance, we say ?the bathroom? more often than ?a
bathroom? but ?a bath? more often than ?the bath?,
even though all four DPs are perfectly grammatical.
As noted earlier, about 75% of distinct nouns in the
Brown corpus occur with exclusively ?the? or ?a?
but not both. Even the remaining 25% which do oc-
cur with both tend to have favorites: only a further
25% (i.e. 12.5% of all nouns) are used with ?a? and
?the? equally frequently, and the remaining 75% are
unbalanced. Overall, for nouns that appear with both
determiners as least once (i.e. 25% of all nouns), the
frequency ratio between the more over the less fa-
vored determiner is 2.86:1. These general patterns
hold for child and adult speech data as well. In the
six children?s transcripts (section 3), the average per-
centage of balanced nouns among those that appear
with both ?the? and ?a? is 22.8%, and the more fa-
vored vs. less favored determiner has an average
frequency ratio of 2.54:1. As a result, even when
a noun appears multiple times in a sample, there is
still a significant chance that it has been paired with
a single determiner in all instances.
We now formalize the overlap measure under the
assumption of a rule and Zipfian frequencies of
grammatical combinations.
2.2 Theoretical analysis
Consider a sample (N,D, S), which consists of
N unique nouns, D unique determiners, and S
determiner-noun pairs. The nouns that have ap-
peared with more than one (i.e. two, in the case
of ?a? and ?the?) determiners will have an overlap
value of 1; otherwise, they have the overlap value of
0. The overlap value for the entire sample will be
the number of 1?s divided by N .
Our analysis calculates the expected value of the
overlap value for the sample (N,D, S) under the
productive rule ?DP?D N?; let it be O(N,D, S).
This requires the calculation of the expected over-
lap value for each of the N nouns over all possible
compositions of the sample. Consider the noun nr
with the rank r out of N . Following equation (1), it
has the probability pr = 1/(rHN ) of being drawn at
any single trial in S. Let the expected overlap value
of nr be O(r,N,D, S). The overlap for the sample
can be stated as:
O(D,N, S) =
1
N
N?
r=1
O(r,N,D, S) (2)
Consider now the calculation O(r,N,D, S).
Since nr has the overlap value of 1 if and only if
32
it has been used with more than one determiner in
the sample, we have:
O(r,N,D, S) = 1? Pr{nr not sampled during S trials}
?
D?
i=1
Pr{nr sampled ith exclusively}
= 1? (1? pr)
S
?
D?
i=1
[
(dipr + 1? pr)
S ? (1? pr)
S
]
(3)
The last term above requires a brief comment.
Under the hypothesis that the language learner has
a productive rule ?DP?D N?, the combination of
determiner and noun is independent. Therefore, the
probability of noun nr combining with the ith deter-
miner is the product of their probabilities, or dipr.
The multinomial expression
(p1 + p2 + ...+ pr?1 + dipr + pr+1 + ...+ pN )
S (4)
gives the probabilities of all the compositions of
the sample, with nr combining with the ith deter-
miner 0, 1, 2, ... S times, which is simply (dipr +
1? pr)S since (p1 + p2 + pr?1 + pr + pr+1 + ...+
pN ) = 1. However, this value includes the proba-
bility of nr combining with the ith determiner zero
times?again (1? pr)S?which must be subtracted.
Thus, the probability with which nr combines with
the ith determiner exclusively in the sample S is
[(dipr + 1 ? pr)S ? (1 ? pr)S ]. Summing these
values over all determiners and collecting terms, we
have:
O(r,N,D, S) = 1+(D?1)(1?pr)
S?
D?
i=1
[
(dipr+1?pr)
S
]
(5)
The formulations in (2)?(5) allow us to calculate
the expected value of overlap using only the sample
size S, the number of unique noun N and the num-
ber of unique determiners D.2 We now turn to the
2For the present case involving only two determiners ?the?
and ?a?, d1 = 2/3 and d2 = 1/3. As noted in section 2.1, the
empirical probabilities of the more vs. less frequent determiners
deviate somewhat from the strict Zipfian ratio of 2:1, numerical
results show that the 2:1 ratio is a very accurate surrogate for
a wide range of actual rations in the calculation of (2)?(5).
This is because most of average overlap value comes from the
relatively few and high frequent nouns.
empirical evaluations of the overlap test (2).
3 Testing Grammar Productivity
3.1 Testing grammar in child language
To study the determiner system in child language,
we consider the data from six children Adam, Eve,
Sarah, Naomi, Nina, and Peter. These are the all and
only children in the CHILDES database with sub-
stantial longitudinal data that starts at the very begin-
ning of syntactic development (i.e, one or two word
stage) so that the usage-based stage, if exists, could
be observed. For comparison, we also consider the
overlap measure of the Brown corpus (Kucera &
Francis 1967), for which the writers? productivity is
not in doubt.
We applied a variant of the Brill tagger (1995)
(http://gposttl.sourceforge.net/) to prepare the child
data before extracting adjacent pairs of determiners
followed by singular nouns. While no tagger works
perfectly, the determiners ?a? and ?the? are not am-
biguous which reliably contribute the tagging of the
following word. The Brown Corpus is already man-
ually tagged and the D-N pairs are extracted directly.
In an additional test, we pooled together the first
100, 300, and 500 D-N pairs from the six children
and created three hypothetical children in the very
earliest, and presumably least productive, stage of
learning.
For each child, the theoretical expectation of over-
lap is calculated based on equations in (2)?(5),
that is, only with the sample size S and the num-
ber of unique nouns N in determiner-noun pairs
while D = 2. These expectations are then com-
pared against the empirical overlap values computed
from the determiner-noun samples extracted with
the methods above; i.e., the percentage of nouns ap-
pearing with both ?a? and ?the?. The results are
summarized in Table 1.
The theoretical expectations and the empirical
measures of overlap agree extremely well (column
5 and 6 in Table 1). Neither paired t- nor paired
Wilcoxon test reveal significant difference between
the two sets of values. A linear regression produces
empirical = 1.08 ? theoretical, R2 = 0.9716: a
perfect fit between theory and data would have the
slope of 1.0. Thus we may conclude that the deter-
miner usage data from child language is consistent
33
Subject
Sample
Size (S)
a or the Noun
types (N )
Overlap%
(expected)
Overlap%
(empirical)
S
N
Naomi (1;1-5;1) 884 349 21.8 19.8 2.53
Eve (1;6-2;3) 831 283 25.4 21.6 2.94
Sarah (2;3-5;1) 2453 640 28.8 29.2 3.83
Adam (2;3-4;10) 3729 780 33.7 32.3 4.78
Peter (1;4-2;10) 2873 480 42.2 40.4 5.99
Nina (1;11-3;11) 4542 660 45.1 46.7 6.88
First 100 600 243 22.4 21.8 2.47
First 300 1800 483 29.1 29.1 3.73
First 500 3000 640 33.9 34.2 4.68
Brown corpus 20650 4664 26.5 25.2 4.43
Table 1: Empirical and expected determiner-noun overlaps in child speech and the Brown corpus (last row).
with the productive rule ?DP? D N?.
The results in Table 1 also reveal considerable in-
dividual variation in the overlap values, and it is in-
structive to understand why. As the Brown corpus
result shows (Table 1 last row), sample size S, the
number of nouns N , or the language user?s age alone
is not predictive of the overlap value. The variation
can be roughly analyzed as follows. Given N unique
nouns in a sample of S, greater overlap value can be
obtained if more nouns occur more than once. Zipf?s
law (1) allows us to express this cutoff line in terms
with ranks, as the probability of the noun nr with
rank r has the probability of 1/(rHN ). The deriva-
tion below uses the fact that the HN =
?N
i=1 1/i
can be approximated by lnN .
S
1
rHN
= 1
r =
S
HN
?
S
lnN
(6)
That is, only nouns whose ranks are lower than
S/(lnN) can be expected to be non-zero overlaps.
The total overlap is thus a monotonically increas-
ing function of S/(N lnN) which, given the slow
growth of lnN , is approximately S/N , a term that
must be positively correlated with overlap measures.
This result is strongly confirmed: S/N is a near
perfect predictor for the empirical values of over-
lap (last two columns of Table 1): r = 0.986,
p < 0.00001.
3.2 Testing usage-based learning
We turn to the question whether children?s deter-
miner usage data can be accounted for equally well
by the usage based approach. In the limiting case,
the usage-based child learner could store the input
data in its entirety and simply retrieve these memo-
rized determiner-noun pairs in production.
Our effort is hampered by the lack of concrete pre-
dictions about child language from the usage-based
literature. Explicit models in usage-based learning
and similar approaches (e.g., Chang et al 2005,
Freudenthal et al 2007, etc.) generally involve
programming efforts for which no analytical results
such as (2)?(5) are possible. Nevertheless, a plau-
sible approach can be construed based on a central
tenet of usage-based learning, that the child does not
form grammatical generalizations but rather mem-
orizes and retrieves specific and item-based combi-
nations. For instance, Tomasello (2000b) suggests
?(w)hen young children have something they want
to say, they sometimes have a set expression read-
ily available and so they simply retrieve that expres-
sion from their stored linguistic experience.? Fol-
lowing this line of reasoning, we consider a learning
model that memorizes jointly formed, as opposed to
productively composed, determiner-noun pairs from
the input. These pairs will then be sampled; for
each sample, the overlap values can be calculated
and compared against the empirical values in Table
1.
We consider two variants of the memory model.
The first can be called a global memory learner in
which the learner memorizes all past linguistic ex-
34
Child sample % (global) % (local) % (emp.)
Eve 831 16.0 17.8 21.6
Naomi 884 16.6 18.9 19.8
Sarah 2453 24.5 27.0 29.2
Peter 2873 25.6 28.8 40.4
Adam 3729 27.5 28.5 32.3
Nina 4542 28.6 41.1 46.7
First 100 600 13.7 17.2 21.8
First 300 1800 22.1 25.6 29.1
First 500 3000 25.9 30.2 34.2
Table 2: The comparison of determiner-noun overlap be-
tween two variants of usage-based learning and empirical
results.
perience. To implement this, we extracted all D-N
pairs from about 1.1 million child directed English
utterances in CHILDES. The second model is a local
memory learner, which is construed to capture the
linguistic experience of a particular child. The lo-
cal memory learner only memorizes the determiner-
noun pairs from the adult utterances in that partic-
ular child?s CHILDES transcripts. In both models,
the memory consists of a list of jointly memorized
D-N pairs, which are augmented with their frequen-
cies in the input.
For each child with a sample size of S (see Table
1, column 2), and for each variant of the memory
model, we use Monte Carlo simulation to randomly
draw S pairs from the memorized lists. The proba-
bility with which a pair is drawn is proportional to its
frequency. We then calculate the D-N overlap value,
i.e, the the percentage of nouns that appear with both
?a? and ?the?, for each sample. The results are aver-
aged over 1000 draws and presented in Table 2.
Both sets of overlap values from the two variants
of usage-based learning (column 3 and 4) differ sig-
nificantly from the empirical measures (column 5):
p < 0.005 for both paired t-test and paired Wilcoxon
test. This suggests that children?s use of determiners
does not follow the predictions of the usage-based
learning approach. This conclusion is tentative, of
course, as we reiterate the need for the usage-based
approach to provide testable quantitative predictions
about child language. At the minimum, child lan-
guage does not appear to stem from frequency sensi-
tive retrieval of jointly stored determiner-noun con-
structions (Tomasello 2000b).
Similar considerations apply to other linguistic
examples. For instance, it is often noted (Lieven,
Pine & Baldwin 1997) that child language is dom-
inated by a small number of high frequency frozen
frames (e.g, ?give me (a) X?).3 True, but that appears
no more than the reflection of the power law dis-
tribution of linguistic units. In the Harvard corpus
of child English (Brown 1973), the frequencies of
?give me?, ?give him? and ?give her? are 93:15:12,
or 7.75:1.23:1, and the frequencies of ?me?, ?him?
and ?her? are 2870:466:364, or the virtually identi-
cal 7.88:1.28:1.
3.3 Testing for Unproductivity
Any statistical test worth its salt should be able to
distinguish occurrences from non-occurrences of the
pattern which it is designed to detect. If the produc-
tivity test predicts higher overlap values than em-
pirically attested?assuming that these classes and
their combinations follow Zipfian distribution?then
there would be reason to suspect that the linguistic
types in question do not combine completely inde-
pendently, and that some kind of lexically specific
processes are at work.
We test the utility of the productivity test on in-
flectional morphology. In English, the -ing suffix
can attach to all verb stems, only some of which
can take the -ed suffix?the rest are irregulars. Chan
(2008) shows that in morphological systems across
languages, stems, affixes, and their combinations
tend to show Zipf-like distributions. Therefore, if
we apply the productivity test to -ing and -ed in-
flected forms (i.e, assuming that -ing and -ed were
fully interchangeable), then the predicted overlap
value should be higher than the empirical value. Ta-
ble 3 gives the results based on the verbal morphol-
ogy data from the Brown corpus and the six chil-
dren studied in section 3.1. Clearly there are very
significant discrepancies between the empirical and
predicted overlap values.
It can be reasonably objected that English irreg-
ular paste tense forms are highly frequent, which
may contribute to the large discrepancies observed
in Table 3. To address this concern, we created an
artificial morphological system in which 100 stems
3Thanks to an anonymous reviewer for bringing up this ex-
ample.
35
Subject sample # stems % emp. % pred.
Adam 6774 263 31.3 75.6
Eve 1028 120 20.0 61.7
Sarah 3442 230 28.7 76.8
Naomi 1797 192 32.3 61.9
Peter 2112 139 25.9 78.8
Nina 2830 191 34.0 77.2
Brown 62807 3044 45.5 75.6
Table 3: Empirical vs. predicted overlap values for -ing
and -ed inflections.
Histogram of (Theory-Emprical)
Fre
que
ncy
-0.05 0.00 0.05 0.10
0
2
4
6
8
Figure 2: Overlap test applied to linguistic combinations
with lexical exceptions.
may take two affixes A and B: A can attach to all
stems but B can only attach to 90 while the other
10, randomly chosen from the 100, are exceptions.
Again, we assume that frequencies of the stems and
their combinations with affixes follow Zipfian distri-
bution. We random combine stems with affixes 1000
times obtaining a sample size of 1000, and count the
percentage of stems that are combined with both A
and B. We then compare this value against the calcu-
lation from (2) which assumes A and B are fully in-
terchangeable (where in this case they are not). The
histogram of the difference between the theoretical
and empirical values from 100 such simulations are
given in Figure 3. The overlap test correctly over-
predicts (p < 10?15).
4 Discussion
For the study of child language acquisition, our re-
sults show that the usage-based approach to lan-
guage learning is not supported by the child data
once the statistical properties of linguistic units and
their combinations are taken into account. A gram-
mar based approach is supported (section 3.1) These
results do not resolve the innateness debate in lan-
guage acquisition: they only point to the very early
availability of an abstract and productive grammar.
The simulation results on the inadequacy of the
memory-and-retrieval approach to child language
(section 3.2) show the limitations of lexically spe-
cific approach to language learning. These results
are congruent with the work in statistical parsing that
also demonstrates the diminishing returns of lexical-
ization (Gildea 2001, Klein & Manning 2003, Bikel
2004). They are also consistent with previous statis-
tical studies (Buttery & Korhonen 2005) that child
directed language data appear to be even more lim-
ited in syntactic usage diversity. The ?uneveness? in
verb islands (Tomasello 1992) is to be expected es-
pecially when the language sample is small as in the
case of most child language acquisition studies. It
thus seems necessary for the child learner to derive
syntactic rules with overarching generality in a rel-
atively short period of time (and with a few million
utterances).
Finally, we envision the overlap test to be one
of many tests for the statistical properties of gram-
mar. Similar tests may be constructed to include a
wider linguistic context (e.g., three or more words
instead of two, but the sparse data problem becomes
far more severe). The ability to detect lexicalized
processes (section 3.3) may prove useful in the au-
tomatic induction of grammars. Such tests would be
a welcome addition to the quantitative analysis tools
in the behavioral study of language, which tend to
establish mismatches between observations and null
hypotheses; the favored hypotheses are those that
cannot be rejected (though cannot be confirmed ei-
ther). The present work shows that it is possible to
test for statistical matches between observations and
well formulated hypotheses.
References
36
Baroni, M. (2008). Distributions in text. In
Lu?delign, A. & Kyto?, M. (Eds.) Corpus linguis-
tics: An international hanbook. Berlin: Mouton
de Gruyter.
Bikel, D. (2004) Intricacies of Collins? parsing
model. Computational Linguistics, 30, 479?
511.
Bowerman, M. (1973). Early syntactic develop-
ment: A cross-linguistic study with special ref-
erence to Finnish. Cambridge: Cambridge Uni-
versity Press.
Braine, M. (1963). The ontogeny of English phrase
structure: The first phase. Language, 39, 3-13.
Brill, E. (1995). Transformation-based error-driven
learning and natural language processing: A
case study in part-of-speech tagging. Compu-
tational Linguistics, 21 (4), 543?565.
Brown, R. (1973). A first language. Cambridge,
MA: Harvard University Press.
Buttery, P. & Korhonen, A. (2005). Large-scale
analysis of verb subcategorization differences
between child directed speech and adult speech.
Interdisciplinary Workshop on the Identifica-
tion and Representation of Verb Features and
Verb Classes, Saarland University.
Chan, E. (2008). Structures and distributions in
morphology learning. Ph.D. Dissertation. De-
partment of Computer and Information Science.
University of Pennsylvania. Philadelphia, PA.
Chang, F., Lieven, E., & Tomasello, M. (2006). Us-
ing child utterances to evaluate syntax acquisi-
tion algorithms. In Proceedings of the 28th An-
nual Conference of the Cognitive Science Soci-
ety. Vancouver, Canada
Feldman, J. (2004). Computational cognitive lin-
guistics. In COLING 2004.
Freudenthal, D., Pine, J. M., Aguado-Orea, J. &
Gobet, F. (2007). Modelling the developmen-
tal patterning of finiteness marking in English,
Dutch, German and Spanish using MOSAIC.
Cognitive Science, 31, 311-341.
Gildea, D. (2001) Corpus variation and parser per-
formance. In 2001 Conference on Empiri-
cal Methods in Natural Lan- guage Processing
(EMNLP).
Goldberg, A. (2003). Constructions. Trends in Cog-
nitive Science, 219?224.
Ha, Le Quan, Sicilia-Garcia, E. I., Ming, Ji. &
Smith, F. J. (2002). Extension of Zipf?s law to
words and phrases. Proceedings of the 19th In-
ternational Conference on Computational Lin-
guistics. 315-320.
Klein, D. & Manning, C. (2003). Accurate unlexi-
calized parsing. In ACL 2003. 423-430.
Kuc?era, H & Francis, N. (1967). Computational
analysis of present-day English. Providence,
RI: Brown University Press.
Lieven, E., Pine, J. & Baldwin, G. (1997).
Lexically-based learning and early grammatical
development. Journal of Child Language, 24,
187-219.
MacWhinney, B. (2000). The CHILDES Project.
Lawrence Erlbaum.
Mandelbrot, B. (1954). Structure formelle des textes
et communication: Deux e?tudes. Words, 10, 1?
27.
Marcus, M., Marcinkiewicz, M. & Santorini, B.
(1993). Building a large annotated corpus of
English: the Penn Treebank. Computational
Linguistics, 19, 313-330.
Pine, J. & Lieven, E. (1997). Slot and frame patterns
in the development of the determiner category.
Applied Psycholinguistics, 18, 123-138.
Sag, I. (2010). English filler-gap constructions. Lan-
guage, 486?545.
Shipley, E., Smith, C. & Gleitman, L. (1969). A
study in the acquisition of language: Free re-
ponses to commands. Language, 45, 2: 322-
342.
Slobin, Dan. (1971). Data for the symposium. In
Slobin, Dan (Ed.) The Ontogenesis of gram-
mar. New York: Academic Press. 3-14.
Steels, L. (2004). Constructivist development of
grounded construction grammars. In ACL
2004.
Teahan, W. J. (1997). Modeling English text. DPhil
thesis. University of Waikato, New Zealand.
37
Tomasello, M. (1992). First verbs: A case study
of early grammatical development. Cambridge,
MA: Harvard University Press.
Tomasello, M. (2000a). Do young children have
adult syntactic competence. Cognition, 74,
209-253.
Tomasello, M. (2000b). First steps toward a usage-
based theory of language acquisition. Cognitive
Linguistics, 11, 61-82.
Valian, V. (1986). Syntactic categories in the speech
of young children. Developmental Psychology,
22, 562-579.
Valian, V., Solt, S. & Stewart, J. (2008). Abstract
categories or limited-scope formulae? The case
of children?s determiners. Journal of Child
Language, 35, 1-36.
Wintner, S. (2009). What science underlies natural
language engineering. Computational Linguis-
tics, 641?644.
Zipf, G. K. (1949). Human behavior and the prin-
ciple of least effort: An introduction to human
ecology. Addison-Wesley.
38
